<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Sat, 06 Sep 2025 17:02:23 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Stock buybacks are stock swindles]]></title>
            <link>https://pluralistic.net/2025/09/06/computer-says-huh/#invisible-handcuffs</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45150749</guid>
            <content:encoded><![CDATA[
	

	
	
	
		

Today's links

Stock buybacks are stock swindles: Raising the value of a stock without raising the value of the company.

Hey look at this: Delights to delectate.

Object permanence: Marshmellow longtermism; Physicists are not epidemiologists; CO asphyxiation accounts for half of Hurricane Laura deaths.

Upcoming appearances: Where to find me.

Recent appearances: Where I've been.

Latest books: You keep readin' em, I'll keep writin' 'em.

Upcoming books: Like I said, I'll keep writin' 'em.

Colophon: All the rest.






Stock buybacks are stock swindles (permalink)
Trump's doing a lot of oligarch shit, and while some of it very visible and obvious, other moves, like throwing the door open to "stock buybacks" are technical and obscure, but it's worth paying attention to this, because this form of stock swindle stands to make billionaires a lot richer (and thus more powerful).
American companies are headed for the stock buying-backest year on record, having already pissed away $1.1 trillion in 2025:
https://www.baystreet.ca/stockstowatch/21522/Stock-Buybacks-Surpass-1-Trillion
So what's a stock buyback, then? On the surface, it's pretty straightforward: during a stock buyback, the company uses its cash reserves to buy its own stock. When they do this, the supply of shares goes down, so the price per share goes up.
Say a company has issued 1,000 shares, and they're selling at $1,000 per share. That company has a "market cap" of $1,000,000 (1,000 x 1,000). Now the company takes $500,000 out of its bank account and buys half of those shares. Now you have a million-dollar company with only 500 shares, so each of those shares is now worth $2,000 (1,000,000/500 = 2,000).
Why is this so bad?
Let's start with what capitalism's advocates claim about the power of markets. Markets, they say, are a kind of alchemist's crucible, a vessel that transforms self-interest to a public good. Capitalism's theory is that if we let people pursue their own profit, they will chase efficiency, because anything that lowers costs will leave more profit for capitalists to reap. But as those capitalists discover better, more productive ways to get goods and services to market, they face competition, who force them to accept lower profits, which makes everything cheaper and more abundant for us. That means that even the greediest capitalists have to find new ways to increase efficiency in order to recapture their profits. Lather, rinse, repeat, and capitalism can make more material abundance available that we can dream of.
This isn't just what capitalists say â€“ it's also the thesis of Chapter One of The Communist Manifesto:
https://www.nytimes.com/2022/10/31/books/review/a-spectre-haunting-china-mieville.html?unlocked_article_code=1.j08.a1xP.KLkhosG_PxkP&amp;smid=url-share
Marx and Engels were seriously impressed by the productive power of capitalism, but they had a prescient suspicion that capitalists hate capitalism, and would do whatever they could to interrupt this process. After all, if you can prevent competitors from entering the market, you can innovate just once, find a new way to make something that's cheaper and better, and never share those profits with your customers or workers, because you won't have to outbid your competitors. The alchemical reaction is halted at the point where capitalists are rewarded for their efficiency, and they are never forced to repeat that performance.
Monopoly isn't the only way that capitalists can thwart this transformation of greed into abundance. The finance sector is awash in illegal scams that let capitalists get rich without increasing efficiency or making anyone except for themselves better off.
Take "wash-trading": this is when a seller buys their own products, sometimes using an alias, other times using a shill. The idea is to trick people into thinking that something is valuable and liquid (that is, that you can easily find buyers for it), when it is really worthless and undesirable. Remember all those multi-million-dollar NFT sales? Almost every one was a wash trade, a way to pump and dump.
The problem here isn't just that the buyer is getting defrauded. It's also that the seller is being "allocated capital" (getting money) that gives them power â€“ power to decide what else should be bought and sold in our society.
Remember the alchemy theory of markets: if you're a productive capital allocator (if you make things that lots of people desire), you are given more capital to allocate further. This is the market's "invisible hand": elevating the people with proven track records to positions of power over their neighbors and their society, on the basis that they have shown themselves capable of enriching us all, because (the theory goes), capitalism rewards people whose greed translates into a common benefit. As Adam Smith wrote:

  It is not from the benevolence of the butcher, the brewer, or the baker, that we expect our dinner, but from their regard to their own interest. We address ourselves, not to their humanity but to their self-love, and never talk to them of our own necessities but of their advantages.

Wash trading creates misallocations of capital. It makes stupid people rich, and lets them allocate capital to projects that make us all worse off. The whole theory of markets â€“ the reason we're all supposed to leave money that we could all use to make ourselves better off in the hands of the wealthy â€“ is that wealth is the payoff for efficiency, and we are all better off when the most efficient allocators make investment decisions.
Modern theorists of capitalism tell us that this isn't alchemy, it's computing. The market is a giant "information-processing" system that incorporates trillions of "price signals" (how much we are willing to spend and how much we are willing to accept, for goods, services and labor). The market processes all these signals to direct allocation and production, ensuring that shortages are met with increases in supply, and that overproduction is tamped down by falling prices, and that inefficiencies provoke investment in process improvements.
Which brings me back to stock buybacks. Stock buybacks are a way to make a company's shares more valuable, even as the company itself becomes less valuable.
Think of it this way: imagine you've got a company with 1,000 shares, worth $1,000 each, and this company has $500,000 in the bank. The company is valued at $1,000,000 (1,000 x $1,000), and half of that valuation is based on its cash reserves ($500,000 in the bank), which means the other half must be reflected in the company's physical plant and "intangibles" (knowledge, contracts, efficient team structures, copyrights, patents, etc).
The company announces a stock buyback: they will withdraw the $500,000 from its bank account and buy half the shares. The company is now $500,000 poorer, which means that its shares should go down in value. After all, that $500,000 is capital that could have been mobilized to make the company more profitable: it could have been spent to hire new people, do R&D, or buy machines that lower the price of making the company's products. That $500,000 represented the company's future growth potential, and the company has just pissed away that potential.
This is a company whose future growth has gotten much more expensive, because it will have to borrow in order to fund any expansion. Its shares should be worth less than before. By zeroing out its cash reserves, the company has actually reduced its value by more than the value of those reserves, because it is now stuck in place, forced to fund expansion with debt rather than capital. It is at risk from "shocks" like higher rents or higher energy prices. It's a brittle, hollow vessel for the intangibles that made up the other $500,000 in valuation before the buyback. It will be worse at turning those intangibles into profits in the future.
But the buyback hasn't reduced the price of the company's shares: it has doubled that price. The company has made its shares more valuable while making itself less valuable. If you think that markets are a computer that calculates efficient allocation based on prices, this should freak you the fuck out, because as we all know, the iron law of computing is "garbage in, garbage out." The company is feeding an objectively â€“ and grossly â€“ false price signal into the computer's input hopper.
That's why stock buybacks were illegal until 1982, when Ronald Reagan's SEC changed its Rule 10-b to legitimize this form of stock manipulation and turn stock swindlers into billionaires:
https://pluralistic.net/2024/09/09/low-wage-100/#executive-excess
At root, stock buybacks are just wash-trading, the company buying its own shares to move their price, without doing anything to justify that price movement. Before Reagan legalized stock buybacks, companies returned capital to their investors through dividends. Why would companies prefer buybacks to dividends? Because corporate executives hold tons of shares in their employer's company, and it's much better for them to push those share prices higher even as they gut the company's ability to function.
So why should you care about this? After all, statistically you own either very little or no stock. The richest 10% of US households own more than 93% of all stocks held by Americans:
https://inequality.org/article/stock-ownership-concentration/
Your 401(k) account might see a small boost from this stock swindle, but again, statistically, that 401(k) is unmeasurably infinitesimal compared to the holdings of America's oligarchs.
Stock buybacks are a way of making the stock owning class much richer, by swindling everyday investors â€“ who don't understand that companies who drain their cash reserves are less valuable â€“ into buying shares in the companies they loot.
And that's why you should care: in the first 8 months of 2025, Trump has allowed America's oligarchs to get $1.1 trillion richer. That's money that you don't have â€“ you won't get the lower prices and higher wages and superior goods that $1.1t would have paid for if companies had spent it on process improvements. It's money they have, which they can spend on things that make you worse off â€“ buying everything from Twitter to the presidency.
There's a lot to be furious about right now, like the masked fascist goons kidnapping our neighbors off the street, and the upside-down health system that is reviving the vaccine-controlled deadly pandemics of yesteryear. But the reason those fascist goons and antivaxers are able to decide how we all live our lives is that a very small number of very rich people converted their stolen wealth to illegitimate power, which they wield over us.
Anyone who lived through the 2008 crisis knows that finance is a deadly weapon. Let the finance sector run your economy and they will steal everything and leave you jobless, homeless and hungry. Trump is a casino guy, and he knows that the only guy making money in a casino is the owner, who gets to set the odds at the machines and tables. By opening the floodgates to trillions in stock buybacks, Trump is turning us all into the suckers at the table, and turning his oligarch investors into little autocrats, with the power to degrade our lives and steal our future.


Hey look at this (permalink)


Five for 50 â€“ Anil Dash https://www.anildash.com/2025/09/05/five-for-fifty/


How To Touch Grass https://www.kickstarter.com/projects/powerandmagic/how-to-touch-grass


Why This Economy Feels Weird and Scary https://www.thebignewsletter.com/p/why-this-economy-feels-weird-and


A Navajo weaving of an integrated circuit: the 555 timer https://www.righto.com/2025/09/marilou-schultz-navajo-555-weaving.html





Object permanence (permalink)
#20yrsago Interview with mom who wonâ€™t pay off the RIAA shakedown https://web.archive.org/web/20051204021157/https://p2pnet.net/story/6134
#5yrsago Political ads have very small effect-sizes https://pluralistic.net/2020/09/04/elusive-mind-control/#persuadables
#5yrsago CO asphyxiation accounts for half of Hurricane Laura deaths https://pluralistic.net/2020/09/04/elusive-mind-control/#co
#5yrsago Trump is a salesman https://pluralistic.net/2020/09/04/elusive-mind-control/#cialdinism
#5yrsago Physicists overestimate their epidemiology game https://pluralistic.net/2020/09/04/elusive-mind-control/#hubris
#1yrago Marshmallow Longtermism https://pluralistic.net/2024/09/04/deferred-gratification/#selective-foresight


Upcoming appearances (permalink)


Ithaca: Enshittification at Buffalo Street Books, Sept 11
https://buffalostreetbooks.com/event/2025-09-11/cory-doctorow-tcpl-librarian-judd-karlman


Ithaca: AD White keynote (Cornell), Sep 12
https://deanoffaculty.cornell.edu/events/keynote-cory-doctorow-professor-at-large/


Ithaca: Enshittification at Autumn Leaves Books, Sept 13
https://www.autumnleavesithaca.com/event-details/enshittification-why-everything-got-worse-and-what-to-do-about-it


Ithaca: Radicalized Q&A (Cornell), Sept 16
https://events.cornell.edu/event/radicalized-qa-with-author-cory-doctorow


DC: Enshittification at Politics and Prose, Oct 8
https://politics-prose.com/cory-doctorow-10825


NYC: Enshittification with Lina Khan (Brooklyn Public Library), Oct 9
https://www.bklynlibrary.org/calendar/cory-doctorow-discusses-central-library-dweck-20251009-0700pm


New Orleans: DeepSouthCon63, Oct 10-12
http://www.contraflowscifi.org/


Chicago: Enshittification with Anand Giridharadas (Chicago Humanities), Oct 15
https://www.oldtownschool.org/concerts/2025/10-15-2025-kara-swisher-and-cory-doctorow-on-enshittification/


San Francisco: Enshittification at Public Works (The Booksmith), Oct 20
https://app.gopassage.com/events/doctorow25


Madrid: Conferencia EUROPEA 4D (Virtual), Oct 28
https://4d.cat/es/conferencia/


Miami: Enshittification at Books & Books, Nov 5
https://www.eventbrite.com/e/an-evening-with-cory-doctorow-tickets-1504647263469





Recent appearances (permalink)

Nerd Harder! (This Week in Tech)
https://twit.tv/shows/this-week-in-tech/episodes/1047


Techtonic with Mark Hurst
https://www.wfmu.org/playlists/shows/155658


Cory Doctorow DESTROYS Enshittification (QAA Podcast)
https://soundcloud.com/qanonanonymous/cory-doctorow-destroys-enshitification-e338





Latest books (permalink)

"Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).


"The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (the-bezzle.org).


"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).


"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).


"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books http://redteamblues.com.


"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com





Upcoming books (permalink)

"Canny Valley": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025


"Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025
https://us.macmillan.com/books/9780374619329/enshittification/


"Unauthorized Bread": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026


"Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026


"The Memex Method," Farrar, Straus, Giroux, 2026


"The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, 2026





Colophon (permalink)
Today's top sources:
Currently writing: 

"The Reverse Centaur's Guide to AI," a short book for Farrar, Straus and Giroux about being an effective AI critic. FIRST DRAFT COMPLETE AND SUBMITTED.


A Little Brother short story about DIY insulin PLANNING




This work â€“ excluding any serialized fiction â€“ is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.
https://creativecommons.org/licenses/by/4.0/
Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.

How to get Pluralistic:
Blog (no ads, tracking, or data-collection):
Pluralistic.net
Newsletter (no ads, tracking, or data-collection):
https://pluralistic.net/plura-list
Mastodon (no ads, tracking, or data-collection):
https://mamot.fr/@pluralistic
Medium (no ads, paywalled):
https://doctorow.medium.com/
Twitter (mass-scale, unrestricted, third-party surveillance and advertising):
https://twitter.com/doctorow
Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):
https://mostlysignssomeportents.tumblr.com/tagged/pluralistic
"When life gives you SARS, you make sarsaparilla" -Joey "Accordion Guy" DeVilla
READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.
ISSN: 3066-764X

	

	
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Oldest Recorded Transaction]]></title>
            <link>https://avi.im/blag/2025/oldest-txn/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45149626</guid>
            <description><![CDATA[The oldest recorded transaction was in 3100 BC]]></description>
            <content:encoded><![CDATA[The other day I posted a tweet with this image which I thought was funny:This is the oldest transaction database from 3100 BC - recording accounts of malt and barley groats. Considering this thing survived 5000 years (holy shit!) with zero downtime and has stronger durability guarantees than most databases today.I call it rock solid durability.This got me thinking, can I insert this date in todayâ€™s database? What is the oldest timestamp a database can support?So I checked the top three databases: MySQL, Postgres, and SQLite:MySQL1000 ADPostgres4713 BCSQLite4713 BCToo bad you cannot use MySQL for this. Postgres and SQLite support the Julian calendar and the lowest date is Jan 01, 4713 BC:sales=# INSERT INTO orders VALUES ('4713-01-01 BC'::date);
INSERT 0 1
sales=# SELECT * FROM orders;
   timestamp
---------------
 4713-01-01 BC
(1 row)
sales=# INSERT INTO orders VALUES ('4714-01-01 BC'::date);
ERROR:  date out of range: "4714-01-01 BC"
I wonder how people store dates older than this. Maybe if Iâ€™m a British Museum manager, and I want to keep theft inventory details. How do I do it? As an epoch? Store it as text? Use some custom system? How do I get it to support all the custom operations that a typical TIMESTAMP supports?Thanks to aku, happy_shady, Mr. Bhat, and General Bruh for reading an early draft of this post.1. Source of the image: Sumer civilization2. I found this from the talk 1000x: The Power of an Interface for Performance by
Joran Dirk Greef, CEO of TigerBeetle, timestamped @ 38:10.3. The talk has other bangers too, like this or this.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DuckDuckGo founder: AI surveillance should be banned]]></title>
            <link>https://gabrielweinberg.com/p/ai-surveillance-should-be-banned</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45149281</guid>
            <description><![CDATA[All the same privacy harms with online tracking are also present with AI, but worse.]]></description>
            <content:encoded><![CDATA[Original cartoon by Dominique Lizaambard (left), updated for AI, by AI (right).All the same privacy harms with online tracking are also present with AI, but worse.While chatbot conversations resemble longer search queries, chatbot privacy harms have the potential to be significantly worse because the inference potential is dramatically greater. Longer input invites more personal information to be provided, and people are starting to bare their souls to chatbots. The conversational format can make it feel like youâ€™re talking to a friend, a professional, or even a therapist. While search queries reveal interests and personal problems, AI conversations take their specificity to another level and, in addition, reveal thought processes and communication styles, creating a much more comprehensive profile of your personality. This richer personal information can be more thoroughly exploited for manipulation, both commercially and ideologically, for example, through behavioral chatbot advertising and models designed (or themselves manipulated through SEO or hidden system prompts) to nudge you towards a political position or product. Chatbots have already been found to be more persuasive than humans and have caused people to go into delusional spirals as a result. I suspect weâ€™re just scratching the surface, since they can become significantly more attuned to your particular persuasive triggers through chatbot memory features, where they train and fine-tune based on your past conversations, making the influence much more subtle. Instead of an annoying and obvious ad following you around everywhere, you can have a seemingly convincing argument, tailored to your personal style, with an improperly sourced â€œfactâ€ that youâ€™re unlikely to fact-check or a subtle product recommendation youâ€™re likely to heed. That is, all the privacy debates surrounding Google search results from the past two decades apply one-for-one to AI chats, but to an even greater degree. Thatâ€™s why we (at DuckDuckGo) started offering Duck.ai for protected chatbot conversations and optional, anonymous AI-assisted answers in our private search engine. In doing so, weâ€™re demonstrating that privacy-respecting AI services are feasible. But unfortunately, such protected chats are not yet standard practice, and privacy mishaps are mounting quickly. Grok leaked hundreds of thousands of chatbot conversations that users thought were private. Perplexityâ€™s AI agent was shown to be vulnerable to hackers who could slurp up your personal information. Open AI is openly talking about their vision for a â€œsuper assistantâ€ that tracks everything you do and say (including offline). And Anthropic is going to start training on your chatbot conversations by default (previously the default was off). I collected these from just the past few weeks!It would therefore be ideal if Congress could act quickly to ensure that protected chats become the rule rather than the exception. And yet, Iâ€™m not holding my breath because itâ€™s 2025 and the U.S. still doesnâ€™t have a general online privacy law, let alone privacy enshrined in the Constitution as a fundamental right, as it should be. However, there does appear to be an opening right now for AI-specific federal legislation, despite the misguided attempts to ban state AI legislation.Time is running out because every day that passes further entrenches bad privacy practices. Congress must move before history completely repeats itself and everything that happened with online tracking happens again with AI tracking. AI surveillance should be banned while there is still time. No matter what happens, though, we will still be here, offering protected services, including optional AI services, to consumers who want to reap the productivity benefits of online tools without the privacy harms. Share]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[996]]></title>
            <link>https://lucumr.pocoo.org/2025/9/4/996/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45149049</guid>
            <description><![CDATA[There is cost to your lifestyle.]]></description>
            <content:encoded><![CDATA[
        
  

  
  written on September 04, 2025
  

  
â€œAmazing salary, hackerhouse in SF, crazy equity.
996. Our mission is
OSS.â€ â€” Gregor Zunic
â€œThe current vibe is no drinking, no drugs, 9-9-6, [â€¦].â€ â€” Daksh
Gupta
â€œThe truth is, Chinaâ€™s really doing â€˜007â€™ nowâ€”midnight to midnight, seven
days a week [â€¦] if you want to build a $10 billion company, you have to work
seven days a week.â€ â€” Harry Stebbings

I love work.  I love working late nights, hacking on things.  This week I
didnâ€™t go to sleep before midnight once.  And yetâ€¦
I also love my wife and kids. I love long walks, contemplating life over good
coffee, and deep, meaningful conversations.  None of this would be possible if
my life was defined by 12 hour days, six days a week.  More importantly, a
successful company is not a sprint, itâ€™s a marathon.
And this is when this is your own company!  When you devote 72 hours a week to
someone elseâ€™s startup, you need to really think about that arrangement a few
times.  I find it highly irresponsible for a founder to promote that model.  As
a founder, you are not an employee, and your risks and leverage are
fundamentally different.
I will always advocate for putting the time
in because it is what brought me happiness.
Intensity, and giving a shit about what Iâ€™m doing, will always matter to me.
But you donâ€™t measure that by the energy you put in, or the hours youâ€™re
sitting in the office, but the output you produce.  Burning out on twelve-hour
days, six days a week, has no prize at the end.  Itâ€™s unsustainable, it
shouldnâ€™t be the standard and it sure as hell should not be seen as a positive
sign of a company.
Iâ€™ve pulled many all-nighters, and Iâ€™ve enjoyed them.  I still do.  But theyâ€™re
enjoyable in the right context, for the right reasons, and when that is a
completely personal choice, not the basis of company culture.
And that all-nighter?  It comes with a fucked up and unproductive morning the
day after.
When someone promotes a 996 work culture, we should push back.


  
  This entry was tagged
    
      thoughts
  

  
    copy as / view markdown
  
  
  

      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[We Hacked Burger King: How Auth Bypass Led to Drive-Thru Audio Surveillance]]></title>
            <link>https://bobdahacker.com/blog/rbi-hacked-drive-thrus/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45148944</guid>
        </item>
        <item>
            <title><![CDATA[Qwen3 30B A3B Hits 13 token/s on 4xRaspberry Pi 5]]></title>
            <link>https://github.com/b4rtaz/distributed-llama/discussions/255</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45148237</guid>
            <description><![CDATA[qwen3_30b.mov Setup [ğŸ”€ TP-Link LS1008G Switch] | | | | | | | |_______ ğŸ”¸ raspberrypi2 (ROOT) 10.0.0.2 | | |_________ ğŸ”¹ raspberrypi1 (WORKER 1) 10.0.0.1 | |___________ ğŸ”¹ raspberrypi3 (WORKER 2) 10.0....]]></description>
            <content:encoded><![CDATA[
      



    
      Skip to content

      
    




  
  
  






      

          

              





  Navigation Menu

  

  
          
            
                
      

      
        
            

                  
                      
  
      
      
        
          GitHub Copilot

        

        Write better code with AI
      

    


                      
  
      
      
        
          GitHub Spark

            
              New
            
        

        Build and deploy intelligent apps
      

    


                      
  
      
      
        
          GitHub Models

            
              New
            
        

        Manage and compare prompts
      

    


                      
  
      
      
        
          GitHub Advanced Security

        

        Find and fix vulnerabilities
      

    


                      
  
      
      
        
          Actions

        

        Automate any workflow
      

    


                  
                
            

                  
                      
  
      
      
        
          Codespaces

        

        Instant dev environments
      

    


                      
  
      
      
        
          Issues

        

        Plan and track work
      

    


                      
  
      
      
        
          Code Review

        

        Manage code changes
      

    


                      
  
      
      
        
          Discussions

        

        Collaborate outside of code
      

    


                      
  
      
      
        
          Code Search

        

        Find more, search less
      

    


                  
                
            
        

          
            
              View all features
              
          
      



                
      

      



                
      

      

                      Explore
                      
  
      Learning Pathways

    


                      
  
      Events & Webinars

    


                      
  
      Ebooks & Whitepapers

    


                      
  
      Customer Stories

    


                      
  
      Partners

    


                      
  
      Executive Insights

    


                  
                



                
      

      
                

                  
                      
  
      
      
        
          GitHub Sponsors

        

        Fund open source developers
      

    


                  
                
                

                  
                      
  
      
      
        
          The ReadME Project

        

        GitHub community articles
      

    


                  
                
                
            



                
      

      

                  
                      
  
      
      
        
          Enterprise platform

        

        AI-powered developer platform
      

    


                  
                



                
    Pricing


            
          

        
                



  
  
  
    

  
    
    
      
        Provide feedback
      
        
    
    
  
      
        
      
      


    
    

  
    
    
      
        Saved searches
      
        Use saved searches to filter your results more quickly
    
    
  
      
        
      
      

    
  



            

              
                Sign up
              
    
      Appearance settings

      
    
  

          
      


      
    

  








    


    






  
    
      
  




    

      






  
  

      
            
    
      

  
                Notifications
    You must be signed in to change notification settings

  

  
              Fork
    168

  

  
        
            
          Star
          2.4k

  



        

        


          

  
    


  

  




    

        
  


            
    
      
    
  
        
  
    
    qwen3_30b.mov
    
  

  

  


Setup
[ğŸ”€ TP-Link LS1008G Switch]
      | | | |
      | | | |_______ ğŸ”¸ raspberrypi2 (ROOT)     10.0.0.2
      | | |_________ ğŸ”¹ raspberrypi1 (WORKER 1) 10.0.0.1
      | |___________ ğŸ”¹ raspberrypi3 (WORKER 2) 10.0.0.3
      |_____________ ğŸ”¹ raspberrypi4 (WORKER 3) 10.0.0.4

Device: 4 x Raspberry Pi 5 8GB
Distributed Llama version: 0.16.0
Model: qwen3_30b_a3b_q40
Benchmark




Evaluation
Prediction




4 x Raspberry Pi 5 8GB
14.33 tok/s
13.04 tok/s



b4rtaz@raspberrypi2:~/distributed-llama $ ./dllama inference --prompt "<|im_start|>user
Please explain me where is Poland as I have 1 year<|im_end|>
<|im_start|>assistant
" --steps 128 --model models/qwen3_30b_a3b_q40/dllama_model_qwen3_30b_a3b_q40.m --tokenizer models/qwen3_30b_a3b_q40/dllama_tokenizer_qwen3_30b_a3b_q40.t --buffer-float-type q80 --nthreads 4 --max-seq-len 4096 --workers 10.0.0.1:9999 10.0.0.3:9999 10.0.0.4:9999
ğŸ“„ AddBos: 0
ğŸ“„ BosId: 151643 (<|endoftext|>)
ğŸ“„ EosId: 151645 (<|im_end|>) 
ğŸ“„ RegularVocabSize: 151643
ğŸ“„ SpecialVocabSize: 26
Tokenizer vocab size (151669) does not match the model vocab size (151936)
ğŸ’¡ Arch: Qwen3 MoE
ğŸ’¡ HiddenAct: Silu
ğŸ’¡ Dim: 2048
ğŸ’¡ HeadDim: 128
ğŸ’¡ QDim: 4096
ğŸ’¡ KvDim: 512
ğŸ’¡ HiddenDim: 6144
ğŸ’¡ VocabSize: 151936
ğŸ’¡ nLayers: 48
ğŸ’¡ nHeads: 32
ğŸ’¡ nKvHeads: 4
ğŸ’¡ OrigSeqLen: 262144
ğŸ’¡ nExperts: 128
ğŸ’¡ nActiveExperts: 8
ğŸ’¡ MoeHiddenDim: 768
ğŸ’¡ SeqLen: 4096
ğŸ’¡ NormEpsilon: 0.000001
ğŸ’¡ RopeType: Falcon
ğŸ’¡ RopeTheta: 10000000
ğŸ“€ RequiredMemory: 5513 MB
â­• Socket[0]: connecting to 10.0.0.1:9999 worker
â­• Socket[0]: connected
â­• Socket[1]: connecting to 10.0.0.3:9999 worker
â­• Socket[1]: connected
â­• Socket[2]: connecting to 10.0.0.4:9999 worker
â­• Socket[2]: connected
â­• Network is initialized
ğŸ§  CPU: neon dotprod fp16
ğŸ’¿ Loading weights...
ğŸ’¿ Weights loaded
ğŸš Network is in non-blocking mode
<|im_start|>user
Please explain me where is Poland as I have 1 year<|im_end|>
<|im_start|>assistant

ğŸ”·ï¸ Eval  996 ms Sync  330 ms | Sent 12084 kB Recv 20085 kB | (19 tokens)
ğŸ”¶ Pred   49 ms Sync   37 ms | Sent   636 kB Recv  1057 kB | Of
ğŸ”¶ Pred   50 ms Sync   94 ms | Sent   636 kB Recv  1057 kB |  course
ğŸ”¶ Pred   60 ms Sync   37 ms | Sent   636 kB Recv  1057 kB | !
ğŸ”¶ Pred   60 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |  Let
ğŸ”¶ Pred   59 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |  me
ğŸ”¶ Pred   49 ms Sync   27 ms | Sent   636 kB Recv  1057 kB |  explain
ğŸ”¶ Pred   49 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |  where
ğŸ”¶ Pred   49 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |  Poland
ğŸ”¶ Pred   49 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |  is
ğŸ”¶ Pred   49 ms Sync   18 ms | Sent   636 kB Recv  1057 kB | ,
ğŸ”¶ Pred   53 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |  in
...
ğŸ”¶ Pred   70 ms Sync   15 ms | Sent   636 kB Recv  1057 kB | zech
ğŸ”¶ Pred   53 ms Sync   24 ms | Sent   636 kB Recv  1057 kB |  Republic
ğŸ”¶ Pred   69 ms Sync   14 ms | Sent   636 kB Recv  1057 kB | **
ğŸ”¶ Pred   59 ms Sync   16 ms | Sent   636 kB Recv  1057 kB |  â€“
ğŸ”¶ Pred   55 ms Sync   20 ms | Sent   636 kB Recv  1057 kB |  to
ğŸ”¶ Pred   64 ms Sync   16 ms | Sent   636 kB Recv  1057 kB |  the
ğŸ”¶ Pred   53 ms Sync   36 ms | Sent   636 kB Recv  1057 kB |  south
ğŸ”¶ Pred   62 ms Sync   18 ms | Sent   636 kB Recv  1057 kB |   

ğŸ”¶ Pred   61 ms Sync   16 ms | Sent   636 kB Recv  1057 kB | 3

Evaluation
   nBatches: 32
    nTokens: 19
   tokens/s: 14.33 (69.80 ms/tok)
Prediction
    nTokens: 109
   tokens/s: 13.04 (76.69 ms/tok)
â­• Network is closed

    
    


          

        

         







  

  

  

  

  

  

  

  


    




    
  

          



    



  

    

    

    





    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Software Development Methodology for Disciplined LLM Collaboration]]></title>
            <link>https://github.com/Varietyz/Disciplined-AI-Software-Development</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45148180</guid>
            <description><![CDATA[This methodology provides a structured approach for collaborating with AI systems on software development projects. It addresses common issues like code bloat, architectural drift, and context dilu...]]></description>
            <content:encoded><![CDATA[

Disciplined AI Software Development - Collaborative
A structured approach for working with AI on development projects. This methodology addresses common issues like code bloat, architectural drift, and context dilution through systematic constraints.
The Context Problem
AI systems work on Question â†’ Answer patterns. When you ask for broad, multi-faceted implementations, you typically get:

Functions that work but lack structure
Repeated code across components
Architectural inconsistency over sessions
Context dilution causing output drift
More debugging time than planning time

How This Works
The methodology uses four stages with systematic constraints and validation checkpoints. Each stage builds on empirical data rather than assumptions.
Planning saves debugging time. Planning thoroughly upfront typically prevents days of fixing architectural issues later.
The Four Stages
Stage 1: AI Configuration
Set up your AI model's custom instructions using AI-PREFERENCES.md. This establishes behavioral constraints and uncertainty flagging with âš ï¸ indicators when the AI lacks certainty.
Stage 2: Collaborative Planning
Share METHODOLOGY.md with the AI to structure your project plan. Work together to:

Define scope and completion criteria
Identify components and dependencies
Structure phases based on logical progression
Generate systematic tasks with measurable checkpoints

Output: A development plan following dependency chains with modular boundaries.
Stage 3: Systematic Implementation
Work phase by phase, section by section. Each request follows: "Can you implement [specific component]?" with focused objectives.
File size stays â‰¤150 lines. This constraint provides:

Smaller context windows for processing
Focused implementation over multi-function attempts
Easier sharing and debugging

Implementation flow:
Request specific component â†’ AI processes â†’ Validate â†’ Benchmark â†’ Continue

Stage 4: Data-Driven Iteration
The benchmarking suite (built first) provides performance data throughout development. Feed this data back to the AI for optimization decisions based on measurements rather than guesswork.
Why This Approach Works
Decision Processing: AI handles "Can you do A?" more reliably than "Can you do A, B, C, D, E, F, G, H?"
Context Management: Small files and bounded problems prevent the AI from juggling multiple concerns simultaneously.
Empirical Validation: Performance data replaces subjective assessment. Decisions come from measurable outcomes.
Systematic Constraints: Architectural checkpoints, file size limits, and dependency gates force consistent behavior.
Example Projects


Discord Bot Template - Production-ready bot foundation with plugin architecture, security, API management, and comprehensive testing. 46 files, all under 150 lines, with benchmarking suite and automated compliance checking. (View Project Structure)


PhiCode Runtime - Programming language runtime engine with transpilation, caching, security validation, and Rust acceleration. Complex system maintaining architectural discipline across 70+ modules. (View Project Structure)


PhiPipe - CI/CD regression detection system with statistical analysis, GitHub integration, and concurrent processing. Go-based service handling performance baselines and automated regression alerts. (View Project Structure)


You can compare the methodology principles to the codebase structure to see how the approach translates to working code.
Implementation Steps
Setup

Configure AI with AI-PREFERENCES.md as custom instructions
Share METHODOLOGY.md for planning session
Collaborate on project structure and phases
Generate systematic development plan

Execution

Build Phase 0 benchmarking infrastructure first
Work through phases sequentially
Implement one component per interaction
Run benchmarks and share results with AI
Validate architectural compliance continuously

Quality Assurance

Performance regression detection
Architectural principle validation
Code duplication auditing
File size compliance checking
Dependency boundary verification

Project State Extraction
Use the included project extraction tool systematically to generate structured snapshots of your codebase:
python scripts/project_extract.py
Configuration Options:

SEPARATE_FILES = False: Single THE_PROJECT.md file (recommended for small codebases)
SEPARATE_FILES = True: Multiple files per directory (recommended for large codebases and focused folder work)
INCLUDE_PATHS: Directories and files to analyze
EXCLUDE_PATTERNS: Skip cache directories, build artifacts, and generated files

Output:

Complete file contents with syntax highlighting
File line counts with architectural warnings (âš ï¸ for 140-150 lines, â€¼ï¸ for >150 lines on code files)
Tree structure visualization
Ready-to-share

output examples can be found here
Use the tool to share a complete or partial project state with the AI system, track architectural compliance, and create focused development context.
What to Expect
AI Behavior: The methodology reduces architectural drift and context degradation compared to unstructured approaches. AI still needs occasional reminders about principles - this is normal.
Development Flow: Systematic planning tends to reduce debugging cycles. Focused implementation helps minimize feature bloat. Performance data supports optimization decisions.
Code Quality: Architectural consistency across components, measurable performance characteristics, maintainable structure as projects scale.

Frequently Asked Questions
Origin & Development

What problem led you to create this methodology?

I kept having to restate my preferences and architectural requirements to AI systems. It didn't matter which language or project I was working on - the AI would consistently produce either bloated monolithic code or underdeveloped implementations with issues throughout.
This led me to examine the meta-principles driving code quality and software architecture. I questioned whether pattern matching in AI models might be more effective when focused on underlying software principles rather than surface-level syntax. Since pattern matching is logic-driven and machines fundamentally operate on simple question-answer pairs, I realized that functions with multiple simultaneous questions were overwhelming the system.
The breakthrough came from understanding that everything ultimately transpiles to binary - a series of "can you do this? â†’ yes/no" decisions. This insight shaped my approach: instead of issuing commands, ask focused questions in proper context. Rather than mentally managing complex setups alone, collaborate with AI to devise systematic plans.



How did you discover these specific constraints work?

Through extensive trial and error. AI systems will always tend to drift even under constraints, but they're significantly more accurate with structured boundaries than without them. You occasionally need to remind the AI of its role to prevent deviation - like managing a well-intentioned toddler that knows the rules but sometimes pushes boundaries trying to satisfy you.
These tools are far from perfect, but they're effective instruments for software development when properly constrained.



What failures or frustrations shaped this approach?

Maintenance hell was the primary driver. I grew tired of responses filled with excessive praise: "You have found the solution!", "You have redefined the laws of physics with your paradigm-shifting script!" This verbose fluff wastes time, tokens, and patience without contributing to productive development.
Instead of venting frustration on social media about AI being "just a dumb tool," I decided to find methods that actually work. My approach may not help everyone, but I hope it benefits those who share similar AI development frustrations.


Personal Practice

How consistently do you follow your own methodology?

Since creating the documentation, I haven't deviated. Whenever I see the model producing more lines than my methodology restricts, I immediately interrupt generation with a flag: "â€¼ï¸ ARCHITECTURAL VIOLATION, ADHERE TO PRINCIPLES â€¼ï¸" I then provide the method instructions again, depending on how context is stored and which model I'm using.



What happens when you deviate from it?

I become genuinely uncomfortable. Once I see things starting to degrade or become tangled, I compulsively need to organize and optimize. Deviation simply isn't an option anymore.



Which principles do you find hardest to maintain?

Not cursing at the AI when it drifts during complex algorithms! But seriously, it's a machine - it's not perfect, and neither are we.


AI Development Journey

When did you start using AI for programming?

In August 2024, I created a RuneLite theme pack, but one of the plugin overlays didn't match my custom layout. I opened a GitHub issue (creating my first GitHub account to do so) requesting a customization option. The response was: "It's not a priority - if you want it, build it yourself."
I used ChatGPT to guide me through forking RuneLite and creating a plugin. This experience sparked intense interest in underlying software principles rather than just syntax.



How has your approach evolved over time?

I view development like a book: syntax is the cover, logic is the content itself. Rather than learning syntax structures, I focused on core meta-principles - how software interacts, how logic flows, different algorithm types. I quickly realized everything reduces to the same foundation: question and answer sequences.
Large code structures are essentially chaotic meetings - one coordinator fielding questions and answers from multiple sources, trying to provide correct responses without mix-ups or misinterpretation. If this applies to human communication, it must apply to software principles.



What were your biggest mistakes with AI collaboration?

Expecting it to intuitively understand my requirements, provide perfect fixes, be completely honest, and act like a true expert. This was all elaborate roleplay that produced poor code. While fine for single-purpose scripts, it failed completely for scalable codebases.
I learned not to feed requirements and hope for the best. Instead, I needed to collaborate actively - create plans, ask for feedback on content clarity, and identify uncertainties. This gradual process taught me the AI's actual capabilities and most effective collaboration methods.


Methodology Specifics

Why 150 lines exactly?

Multiple benefits: easy readability, clear understanding, modularity enforcement, architectural clarity, simple maintenance, component testing, optimal AI context retention, reusability, and KISS principle adherence.



How did you determine Phase 0 requirements?

From meta-principles of software: if it displays, it must run; if it runs, it can be measured; if it can be measured, it can be optimized; if it can be optimized, it can be reliable; if it can be reliable, it can be trusted.
Regardless of project type, anything requiring architecture needs these foundations. You must ensure changes don't negatively impact the entire system. A single line modification in a nested function might work perfectly but cause 300ms boot time regression for all users.
By testing during development, you catch inefficiencies early. Integration from the start means simply hooking up new components and running tests via command line - minimal time investment with actual value returned. I prefer validation and consistency throughout development rather than programming blind.


Practical Implementation

How do you handle projects that don't fit the methodology?

I adapt them to fit, or if truly impossible, I adjust the method itself. This is one methodology - I can generate countless variations as needed. Having spent 6700+ hours in AI interactions across multiple domains (not just software), I've developed strong system comprehension that enables creating adjusted methodologies on demand.



What's the learning curve for new users?

I cannot accurately answer this question. I've learned that I'm neurologically different - what I perceive as easy or obvious isn't always the case for others. This question is better addressed by someone who has actually used this methodology to determine its learning curve.



When shouldn't someone use this approach?

If you're not serious about projects, despise AI, dislike planning, don't care about modularization, or are just writing simple scripts. However, for anything requiring reliability, I believe this is currently the most effective method.
You still need programming fundamentals to use this methodology effectively - it's significantly more structured than ad-hoc approaches.



Workflow Visualization

  
      ---
config:
  layout: elk
  theme: neo-dark
---
flowchart TD
    A["Project Idea"] --> B["ğŸ¤– Stage 1: AI Configuration<br>AI-PREFERENCES.md Custom Instructions"]
    B --> C["Stage 2: Collaborative Planning<br>Share METHODOLOGY.md"]
    C --> D["Define Scope & Completion Criteria"]
    D --> E["Identify Components & Dependencies"]
    E --> F["Structure Phases Based on Logic"]
    F --> G["Document Edge Cases - No Implementation"]
    G --> H["Generate Development Plan with Checkpoints"]
    H --> I["ğŸ”§ Stage 3: Phase 0 Infrastructure<br>MANDATORY BEFORE ANY CODE"]
    I --> J["Benchmarking Suite + Regression Detection"]
    J --> K["GitHub Workflows + Quality Gates"]
    K --> L["Test Suite Infrastructure + Stress Tests"]
    L --> M["Documentation Generation System"]
    M --> N["Centralized Configuration + Constants"]
    N --> O["ğŸ“ project_extract.py Setup<br>Single/Multiple File Config"]
    O --> P["Initial Project State Extraction"]
    P --> Q["Share Context with AI"]
    Q --> R["Start Development Session<br>Pre-Session Compliance Audit"]
    R --> S{"Next Phase Available?"}
    S -- No --> Z["Project Complete"]
    S -- Yes --> T["Select Single Component<br>Target â‰¤150 Lines"]
    T --> U{"Multi-Language Required?"}
    U -- Yes --> V["Document Performance Justification<br>Measurable Benefits Required"]
    V --> W["Request AI Implementation"]
    U -- No --> W
    W --> X{"AI Uncertainty Flag?"}
    X -- âš ï¸ Yes --> Y["Request Clarification<br>Provide Additional Context"]
    Y --> W
    X -- Clear --> AA["Stage 3: Systematic Implementation"]
    AA --> BB{"Automated Size Check<br>validate-phase Script"}
    BB -- >150 Lines --> CC["AUTOMATED: Split Required<br>Maintain SoC Boundaries"]
    CC --> W
    BB -- â‰¤150 Lines --> DD["Incremental Compliance Check<br>DRY/KISS/SoC Validation"]
    DD --> EE{"Architectural Principles Pass?"}
    EE -- No --> FF["Flag Specific Violations<br>Reference Methodology"]
    FF --> W
    EE -- Yes --> GG["ğŸ“Š Stage 4: Data-Driven Iteration<br>Run Benchmark Suite + Save Baselines"]
    GG --> HH["Compare Against Historical Timeline<br>Regression Analysis"]
    HH --> II{"Performance Gate Pass?"}
    II -- Regression Detected --> JJ["Share Performance Data<br>Request Optimization"]
    JJ --> W
    II -- Pass --> KK["Integration Test<br>Verify System Boundaries"]
    KK --> LL{"Cross-Platform Validation?"}
    LL -- Fail --> MM["Address Deployment Constraints<br>Real-World Considerations"]
    MM --> W
    LL -- Pass --> NN{"More Components in Phase?"}
    NN -- Yes --> T
    NN -- No --> OO["ğŸš¦ Phase Quality Gate<br>Full Architecture Audit"]
    OO --> PP["Production Simulation<br>Resource Cleanup + Load Test"]
    PP --> QQ{"All Quality Gates Pass?"}
    QQ -- No --> RR["Document Failed Checkpoints<br>Block Phase Progression"]
    RR --> T
    QQ -- Yes --> SS["End Development Session<br>Technical Debt Assessment"]
    SS --> TT["ğŸ“ Extract Updated Project State<br>Generate Fresh Context"]
    TT --> UU["Phase Results Documentation<br>Metrics + Outcomes + Timeline"]
    UU --> VV["Update Development Plan<br>Mark Phase Complete"]
    VV --> S
    WW["validate-phase<br>AUTOMATED: File Size + Structure"] -.-> BB
    XX["dry-audit<br>AUTOMATED: Cross-Module Duplication"] -.-> DD
    YY["CI/CD Workflows<br>AUTOMATED: Merge Gates"] -.-> GG
    ZZ["Performance Timeline<br>AUTOMATED: Historical Data"] -.-> HH
    AAA["Dependency Validator<br>AUTOMATED: Import Boundaries"] -.-> KK
    BBB["Architecture Auditor<br>AUTOMATED: SoC Compliance"] -.-> OO
    WW -. BUILD FAILURE .-> CC
    YY -. MERGE BLOCKED .-> JJ
    BBB -. AUDIT FAILURE .-> RR
    style Y fill:#7d5f00
    style CC fill:#770000
    style FF fill:#7d5f00
    style JJ fill:#7d5f00
    style MM fill:#770000
    style RR fill:#770000

    
  
    
      Loading

  


]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Let us git rid of it, angry GitHub users say of forced Copilot features]]></title>
            <link>https://www.theregister.com/2025/09/05/github_copilot_complaints/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45148167</guid>
            <description><![CDATA[: Unavoidable AI has developers looking for alternative code hosting options]]></description>
            <content:encoded><![CDATA[
Among the software developers who use Microsoft's GitHub, the most popular community discussion in the past 12 months has been a request for a way to block Copilot, the company's AI service, from generating issues and pull requests in code repositories.
The second most popular discussion â€“ where popularity is measured in upvotes â€“ is a bug report that seeks a fix for the inability of users to disable Copilot code reviews.
Both of these questions, the first opened in May and the second opened a month ago, remain unanswered, despite an abundance of comments critical of generative AI and Copilot.Â 

    

The author of the first, developer Andi McClure, published a similar request to Microsoft's Visual Studio Code repository in January, objecting to the reappearance of a Copilot icon in VS Code after she had uninstalled the Copilot extension.

        


        

Microsoft and GitHub, not to mention rivals like Google, have gone all-in on a technology that a sizable or at least vocal portion of their customers simply don't want. And with billions in capital expenditures to recoup, they're making it difficult to avoid.
During Microsoft's July 30, 2025 earnings call, CEO Satya Nadella said GitHub Copilot continued to exhibit strong momentum and had reached 20 million users.

        

"GitHub Copilot Enterprise customers increased 75 percent quarter over quarter as companies tailor Copilot to their own codebases," said Nadella, noting that AI adoption has increased usage of GitHub over the past year.


I deeply resent that on top of Copilot seemingly training itself on my GitHub-posted code in violation of my licenses, GitHub wants me to look at (effectively) ads for this project I will never touch

"I've been for a while now filing issues in the GitHub Community feedback area when Copilot intrudes on my GitHub usage," McClure told The Register in an email. "I deeply resent that on top of Copilot seemingly training itself on my GitHub-posted code in violation of my licenses, GitHub wants me to look at (effectively) ads for this project I will never touch. If something's bothering me, I don't see a reason to stay quiet about it. I think part of how we get pushed into things we collectively don't want is because we stay quiet about it."
It's not just the burden of responding to AI slop, an ongoing issue for Curl maintainer Daniel Stenberg. It's the permissionless copying and regurgitation of speculation as fact, mitigated only by small print disclaimers that generative AI may produce inaccurate results. It's also GitHub's disavowal of liability if Copilot code suggestions happen to have reproduced source code that requires attribution.
It's what the Servo project characterizes in its ban on AI code contributions as the lack of code correctness guarantees, copyright issues, and ethical concerns. Similar objections have been used to justify AI code bans in GNOME's Loupe project, FreeBSD, Gentoo, NetBSD, and QEMU.
McClure said she has been filing requests to opt out of Copilot for a few years now, but in the last six months, her posts have been attracting more community support.Â 

        

Two issues, about the abovementioned Copilot menu in VS Code and the inability to block Copilot-generated issues and pull requests, she said, have continued to attract comments.
"People keep finding these issues somehow and tacking on to them," McClure said. "Although Microsoft's been forcing the Copilot 'asks' into more and more places in the interface for a while, sometime this year they hit an inflection point where mass numbers of people don't feel like ignoring it anymore, where before they could shrug and ignore it or find the off switch."
In the past month, she said, there's been a second change in the way people see GitHub â€“ GitHub's demotion from distinct subsidiary to part of Microsoft's CoreAI group.


Bot shots: US Army enlists AI startup to provide target-tracking

OpenAI eats jobs, then offers to help you find a new one at Walmart

Boffins build automated Android bug hunting system

Atlassian acquisition drives dream of AI-powered ChromeOS challenger

"Despite being a symbolic change, it seems to have galvanized the open source community from just complaining about Copilot to now actively moving away from GitHub," said McClure. "Many of my contacts in the open source community have been talking about plans to move from GitHub to Codeberg or a self-hosted Forgejo (Forgejo is the software used by Codeberg) over the last month, and the comments in those two always-busy GitHub threads have increasingly been people describing how Copilot is inspiring them to move to Codeberg as well."
Calls to shun Microsoft and GitHub go back a long way in the open source community, but moved beyond simmering dissatisfaction in 2022 when the Software Freedom Conservancy (SFC) urged free software supporters to give up GitHub, a position SFC policy fellow Bradley M. Kuhn recently reiterated.
Some of the developers participating in the issues raised by McClure and by others have said they intend to move away from GitHub over its stance on AI.
"Today I rejected two Copilot-generated code suggestions on my PR," wrote a developer who posted to McClure's thread under the name Constantine. "This was very disturbing, so I started googling and found this discussion. I refuse using AI in the same way I don't take drugs or steal things - for me it's a matter of principle. So if this continues and Microsoft does not provide a way to opt out of AI for my repositories soon, I will move my code to a self-hosted solution and won't ever return to GitHub."
McClure said she has been slowly shifting toward Codeberg over the past few months. "I haven't been proactively moving repos but whenever I make a change to a repo I clone it to Codeberg, post the change there, and replace my main branch on the GitHub repo with a relocation notice," she said.
"Microsoft as a company has a running problem where they won't take no for an answer, whether with 'AI' or with any other product they want to ship," said McClure. "A favorite tactic of theirs recently is they will enable a thing by default and put an off switch, wait six months, and then slightly change or rename the feature you turned off, and create a new off switch you have to separately turn off. They did this with Bing in Windows 10 and now they're doing it with Copilot in their developer tools (and presumably Windows 11, I don't know, I don't use Windows 11)."
McClure said that when Microsoft began adding Copilot to everything, starting with Android keyboard SwiftKey, she concluded that the situation would reprise the handling of Bing/Cortana in Windows 10 and turning it off would not be enough.


If you really find Copilot unacceptable â€“ and I do, Copilot is so much more noxious than Microsoft's previous forced bundlings â€“ the only option is to stop using any Microsoft product that Copilot shows up in

"If you really find Copilot unacceptable â€“ and I do, Copilot is so much more noxious than Microsoft's previous forced bundlings â€“ the only option is to stop using any Microsoft product that Copilot shows up in," she said. "I stopped using SwiftKey; I started migrating from desktop Windows to Linux when it became clear mandatory AI surveillance would be a core part of Win11. GitHub and, more sporadically, Visual Studio Code I have had to keep using because they're monopolies in a way even Windows isn't. The network effects (projects whose sole method of communication is GitHub, software whose only IDE integration is a VSCode plugin) are too strong."
Things have progressed as expected, McClure said, with Copilot buttons appearing in VS Code even when Copilot has been uninstalled and poorly labeled buttons that redirect to Copilot searches. She suggests people are starting to tire of the situation and that if it continues, it will weaken the network effects that keep developers tied to GitHub, accelerating further migration.
"When this happens I have no idea if Microsoft will notice or care," said McClure. "The Copilot push at Microsoft appears to be completely top-down and the people at the top seem to have completely forgotten about conventional goals like customer retention. They want to pump up those 'AI' numbers, for whatever reason, and they view their customer base as just a resource to burn to get those metrics up."
GitHub did not respond to a request for comment. Â®                                
                    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rug pulls, forks, and open-source feudalism]]></title>
            <link>https://lwn.net/SubscriberLink/1036465/e80ebbc4cee39bfb/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45146967</guid>
            <description><![CDATA[Like almost all human endeavors, open-source software development involves a range of power dyn [...]]]></description>
            <content:encoded><![CDATA[


Welcome to LWN.net

The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider subscribing to LWN.  Thank you
for visiting LWN.net!



Like almost all human endeavors, open-source software development involves
a range of power dynamics.  Companies, developers, and users are all
concerned with the power to influence the direction of the software â€” and,
often, to profit from it.  At the 2025 Open
Source Summit Europe, Dawn Foster talked about how those dynamics can
play out, with an eye toward a couple of tactics â€” rug pulls and forks â€” that
are available to try to shift power in one direction or another.
Power dynamics

Since the beginning of history, Foster began, those in power have tended to
use it against those who were weaker.  In the days of feudalism, control of
the land led to exploitation at several levels.  In the open-source world,
the large cloud providers often seem to have the most power, which they use
against smaller companies.  Contributors and maintainers often have less
power than even the smaller companies, and users have less power yet.  



We have built a world where it is often easiest to just use whatever a
cloud provider offers, even with open-source software.  Those providers may
not contribute back to the projects they turn into services, though,
upsetting the smaller companies that are, likely as not, doing the bulk of
the work to provide the software in question in the first place.  Those
companies can have a power of their own, however: the power to relicense
the software.  Pulling the rug out from under users of the software in this
way can change the balance of power with regard to cloud providers, but it
leaves contributors and users in a worse position than before.  But
there is a power at this level too: the power to fork the software,
flipping the power balance yet again.

Companies that control a software project have the power to carry out this
sort of rug pull, and they are often not shy about exercising it.
Single-company projects, clearly, are at a much higher risk of rug pulls;
the company has all the power in this case, and others have little
recourse.  So one should look at a company's reputation before adopting a
software project, but that is only so helpful.  Companies can change
direction without notice, be acquired, or go out of business, making
previous assessments of their reputation irrelevant.

The problem often comes down to the simple fact that companies have to
answer to their investors, and that often leads to pressure to relicense
the software they have created in order to increase revenue.  This is
especially true in cases where cloud providers are competing for the same
customers as the company that owns the project.  The result can be a switch
to a more restrictive license aimed at making it harder for other companies
to profit from the project.

A rug pull of this nature can lead to a fork of the project â€” a rebellious,
collective action aimed at regaining some power over the code.  But a fork
is not a simple matter; it is a lot of work, and will fail without people
and resources behind it.  The natural source for that is a large company;
cloud providers, too, can try to shift power via a fork, and they have the
ability to back their fork up with the resources it needs to succeed.



A relicensing event does not always lead to a popular fork; that did not
happen with MongoDB or Sentry, for example.  Foster said she had not looked
into why that was the case.  Sometimes rug pulls take other forms, such as
when Perforce, after acquiring Puppet in 2022, moved it development and
releases behind closed doors, with a reduced frequency of releases back to
the public repository.  That action kicked off the OpenVox fork.
Looking at the numbers

Foster has spent some time analyzing rug pulls, forks, and what happens
thereafter; a lot of the results are available
for download as Jupyter notebooks.  For each rug-pull event, she looked
at the contributor makeup of the project before and after the ensuing fork
in an attempt to see what effects are felt by the projects involved.

In 2021, Elastic relicensed Elasticsearch
under the non-free Server Side Public License (SSPL).  Amazon Web Services
then forked the project as OpenSearch.  Before the fork, most of
the Elasticsearch contributors were Elastic employees; that,
unsurprisingly, did not change afterward.  OpenSearch started with no
strong contributor base, so had to build its community from scratch.  As a
result, the project has been dominated by Amazon contributors ever since;
the balance has shifted slowly over time, but there was not a big uptick in
outside contributors even after OpenSearch became a Linux Foundation
project in 2024.  While starting a project under a neutral foundation can
help attract contributors, she said, moving a project under a foundation's
umbrella later on does not seem to provide the same benefit.

Terraform was
developed mostly by Hashicorp, which relicensed
the software under the non-free Business Source License in 2023.  One
month later, the OpenTofu fork was
started under the Linux Foundation.  While the contributor base for
Terraform, which was almost entirely Hashicorp employees, changed little
after the fork, OpenTofu quickly acquired a number of contributors from
several companies, none of whom had been Terraform contributors before.  In
this case, users drove the fork and placed it under a neutral foundation,
resulting in a more active developer community.

In 2024, Redis was relicensed under the
SSPL; the Valkey fork was quickly organized, under the Linux Foundation,
by Redis contributors.  The Redis project differed from the others
mentioned here in that, before the fork, it had nearly twice as many
contributors from outside the company as from within; after the fork, the
number of external Redis contributors dropped to zero.  All of the external
contributors fled to Valkey, with the result that Valkey started with a
strong community representing a dozen or so companies.

Looking at how the usage of these projects changes is harder, she
said, but there appears to be a correlation between the usage of a project
and the number of GitHub forks (cloned repository copies) it has.  There is
typically a spike in these clones after a relicensing event, suggesting
that people are considering creating a hard fork of the project.  In all
cases, the forks that emerged appeared to have less usage than the original
by the "GitHub forks" metric; both branches of the fork continue to go
forward.  But, she said, projects that are relicensed do tend to show
reduced usage, especially when competing forks are created under foundations.
What to do

This kind of power game creates problems for both contributors and users,
she said; we contribute our time to these projects, and need them to not be
pulled out from under us.  There is no way to know when a rug pull might
happen, but there are some warning signs to look out for.  At the top of
her list was the use of a contributor license agreement (CLA); these
agreements create a power imbalance, giving the company involved the power
to relicense the software.  Projects with CLAs more commonly are subject to
rug pulls; projects using a developers certificate of origin do not have the
same power imbalance and are less likely to be rug pulled.

One should also look at the governance of a project; while being housed
under a foundation reduces the chance of a rug pull, that can still happen,
especially in cases where the contributors are mostly from a single
company.  She mentioned the Cortex project, housed under
the Cloud Native Computing Foundation, which was controlled by Grafana; that
company eventually forked its own project to create Mimir.  To avoid this kind of
surprise, one should look for projects with neutral governance, with
leaders from multiple organizations.

Projects should also be evaluated on their contributor base; are there
enough contributors to keep things going?  Companies can help, of course,
by having their employees contribute to the projects they depend on,
increasing influence and making those projects more sustainable.  She
mentioned the CHAOSS project, which
generates metrics to help in the judgment of the viability of development
projects.  CHAOSS has put together a set of
"practitioner guides" intended to help contributors and maintainers
make improvements within a project.

With the sustained rise of the big cloud providers, she concluded, the
power dynamics around open-source software are looking increasingly feudal.
Companies can use relicensing to shift power away from those providers, but
they also take power from contributors when the pull the rug in this way.
Those contributors, though, are in a better position than the serfs of old,
since they have the ability to fork a project they care about, shifting
power back in their direction.


Hazel Weakly asked if there are other protections that contributors and
users might develop to address this problem.  Foster answered that at least
one company changed its mind about a planned relicensing action after
seeing the success of the Valkey and OpenTofu forks.  The ability to fork
has the effect of making companies think harder, knowing that there may be
consequences that follow a rug pull.  Beyond that, she reiterated that
projects should be pushed toward neutral governance.

Dirk Hohndel added that the best thing to do is to bring more outside
contributors into a project; the more of them there are, the higher the
risk associated with a rug pull.  Anybody who just sits back within a
project, he said, is just a passenger; it is better to be driving.

Foster's
slides are available for interested readers.

[Thanks to the Linux Foundation, LWN's travel sponsor, for supporting my
travel to this event.]
           Index entries for this article
           ConferenceOpen Source Summit Europe/2025
            

               
               
            ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Developing a Space Flight Simulator in Clojure]]></title>
            <link>https://www.wedesoft.de/software/2025/09/05/clojure-game/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45145794</guid>
            <description><![CDATA[Developing a Space Flight Simulator in Clojure]]></description>
            <content:encoded><![CDATA[
  
  05 Sep 2025    

In 2017 I discovered the free of charge Orbiter 2016 space flight simulator which was proprietary at the time and it inspired me to develop a space flight simulator myself.
I prototyped some rigid body physics in C and later in GNU Guile and also prototyped loading and rendering of Wavefront OBJ files.
I used GNU Guile (a Scheme implementation) because it has a good native interface and of course it has hygienic macros.
Eventually I got interested in Clojure because unlike GNU Guile it has multi-methods as well as fast hash maps and vectors.
I finally decided to develop the game for real in Clojure.
I have been developing a space flight simulator in Clojure for almost 5 years now.
While using Clojure I have come to appreciate the immutable values and safe parallelism using atoms, agents, and refs.

In the beginning I decided to work on the hard parts first, which for me were 3D rendering of a planet, an atmosphere, shadows, and volumetric clouds.
I read the OpenGL Superbible to get an understanding on what functionality OpenGL provides.
When Orbiter was eventually open sourced and released unter MIT license here, I inspected the source code and discovered that about 90% of the code is graphics-related.
So starting with the graphics problems was not a bad decision.

Software dependencies

The following software is used for development.
The software libraries run on both GNU/Linux and Microsoft Windows.


  Clojure the programming language
  LWJGL provides Java wrappers for various libraries
    
      lwjgl-opengl for 3D graphics
      lwjgl-glfw for windowing and input devices
      lwjgl-nuklear for graphical user interfaces
      lwjgl-stb for image I/O and using truetype fonts
      lwjgl-assimp to load glTF 3D models with animation data
    
  
  Jolt Physics to simulate wheeled vehicles and collisions with meshes
  Fastmath for fast matrix and vector math as well as spline interpolation
  Comb for templating shader code
  Instaparse to parse NASA Planetary Constant Kernel (PCK) files
  Gloss to parse NASA Double Precision Array Files (DAF)
  Coffi as a foreign function interface
  core.memoize for least recently used caching of function results
  Apache Commons Compress to read map tiles from tar files
  Malli to add schemas to functions
  Immuconf to load the configuration file
  Progrock a progress bar for long running builds
  Claypoole to implement parallel for loops
  tools.build to build the project
  clj-async-profiler Clojure profiler creating flame graphs
  slf4j-timbre Java logging implementation for Clojure


The deps.edn file contains operating system dependent LWJGL bindings.
For example on GNU/Linux the deps.edn file contains the following:

{:deps {; ...
        org.lwjgl/lwjgl {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl$natives-linux {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-opengl {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-opengl$natives-linux {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-glfw {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-glfw$natives-linux {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-nuklear {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-nuklear$natives-linux {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-stb {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-stb$natives-linux {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-assimp {:mvn/version "3.3.6"}
        org.lwjgl/lwjgl-assimp$natives-linux {:mvn/version "3.3.6"}}
        ; ...
        }

In order to manage the different dependencies for Microsoft Windows, a separate Git branch is maintained.

Atmosphere rendering


    

For the atmosphere, Brunetonâ€™s precomputed atmospheric scattering was used.
The implementation uses a 2D transmittance table, a 2D surface scattering table, a 4D Rayleigh scattering, and a 4D Mie scattering table.
The tables are computed using several iterations of numerical integration.
Higher order functions for integration over a sphere and over a line segment were implemented in Clojure.
Integration over a ray in 3D space (using fastmath vectors) was implemented as follows for example:

(defn integral-ray
  "Integrate given function over a ray in 3D space"
  {:malli/schema [:=> [:cat ray N :double [:=> [:cat [:vector :double]] :some]] :some]}
  [{::keys [origin direction]} steps distance fun]
  (let [stepsize      (/ distance steps)
        samples       (mapv #(* (+ 0.5 %) stepsize) (range steps))
        interpolate   (fn interpolate [s] (add origin (mult direction s)))
        direction-len (mag direction)]
    (reduce add (mapv #(-> % interpolate fun (mult (* stepsize direction-len))) samples))))

Precomputing the atmospheric tables takes several hours even though pmap was used.
When sampling the multi-dimensional functions, pmap was used as a top-level loop and map was used for interior loops.
Using java.nio.ByteBuffer the floating point values were converted to a byte array and then written to disk using a clojure.java.io/output-stream:

(defn floats->bytes
  "Convert float array to byte buffer"
  [^floats float-data]
  (let [n           (count float-data)
        byte-buffer (.order (ByteBuffer/allocate (* n 4)) ByteOrder/LITTLE_ENDIAN)]
    (.put (.asFloatBuffer byte-buffer) float-data)
    (.array byte-buffer)))

(defn spit-bytes
  "Write bytes to a file"
  {:malli/schema [:=> [:cat non-empty-string bytes?] :nil]}
  [^String file-name ^bytes byte-data]
  (with-open [out (io/output-stream file-name)]
    (.write out byte-data)))

(defn spit-floats
  "Write floating point numbers to a file"
  {:malli/schema [:=> [:cat non-empty-string seqable?] :nil]}
  [^String file-name ^floats float-data]
  (spit-bytes file-name (floats->bytes float-data)))

When launching the game, the lookup tables get loaded and copied into OpenGL textures.
Shader functions are used to lookup and interpolate values from the tables.
When rendering the planet surface or the space craft, the atmosphere essentially gets superimposed using ray tracing.
After rendering the planet, a background quad is rendered to display the remaining part of the atmosphere above the horizon.

Templating OpenGL shaders

It is possible to make programming with OpenGL shaders more flexible by using a templating library such as Comb.
The following shader defines multiple octaves of noise on a base noise function:

#version 410 core

float <%= base-function %>(vec3 idx);

float <%= method-name %>(vec3 idx)
{
  float result = 0.0;
<% (doseq [multiplier octaves] %>
  result += <%= multiplier %> * <%= base-function %>(idx);
  idx *= 2;
<% ) %>
  return result;
}

One can then for example define the function fbm_noise using octaves of the base function noise as follows:

(def noise-octaves
  "Shader function to sum octaves of noise"
  (template/fn [method-name base-function octaves] (slurp "resources/shaders/core/noise-octaves.glsl")))

; ...

(def fbm-noise-shader (noise-octaves "fbm_noise" "noise" [0.57 0.28 0.15]))

Planet rendering


    

To render the planet, NASA Bluemarble data, NASA Blackmarble data, and NASA Elevation data was used.
The images were converted to a multi resolution pyramid of map tiles.
The following functions were implemented for color map tiles and for elevation tiles:


  a function to load and cache map tiles of given 2D tile index and level of detail
  a function to extract a pixel from a map tile
  a function to extract the pixel for a specific longitude and latitude


The functions for extracting a pixel for given longitude and latitude then were used to generate a cube map with a quad tree of tiles for each face.
For each tile, the following files were generated:


  A daytime texture
  A night time texture
  An image of 3D vectors defining a surface mesh
  A water mask
  A normal map


Altogether 655350 files were generated.
Because the Steam ContentBuilder does not support a large number of files, each row of tile data was aggregated into a tar file.
The Apache Commons Compress library allows you to open a tar file to get a list of entries and then perform random access on the contents of the tar file.
A Clojure LRU cache was used to maintain a cache of open tar files for improved performance.

At run time, a future is created, which returns an updated tile tree, a list of tiles to drop, and a path list of the tiles to load into OpenGL.
When the future is realized, the main thread deletes the OpenGL textures from the drop list, and then uses the path list to get the new loaded images from the tile tree, load them into OpenGL textures, and create an updated tile tree with the new OpenGL textures added.
The following functions to manipulate quad trees were implemented to realize this:

(defn quadtree-add
  "Add tiles to quad tree"
  {:malli/schema [:=> [:cat [:maybe :map] [:sequential [:vector :keyword]] [:sequential :map]] [:maybe :map]]}
  [tree paths tiles]
  (reduce (fn add-title-to-quadtree [tree [path tile]] (assoc-in tree path tile)) tree (mapv vector paths tiles)))

(defn quadtree-extract
  "Extract a list of tiles from quad tree"
  {:malli/schema [:=> [:cat [:maybe :map] [:sequential [:vector :keyword]]] [:vector :map]]}
  [tree paths]
  (mapv (partial get-in tree) paths))

(defn quadtree-drop
  "Drop tiles specified by path list from quad tree"
  {:malli/schema [:=> [:cat [:maybe :map] [:sequential [:vector :keyword]]] [:maybe :map]]}
  [tree paths]
  (reduce dissoc-in tree paths))

(defn quadtree-update
  "Update tiles with specified paths using a function with optional arguments from lists"
  {:malli/schema [:=> [:cat [:maybe :map] [:sequential [:vector :keyword]] fn? [:* :any]] [:maybe :map]]}
  [tree paths fun & arglists]
  (reduce (fn update-tile-in-quadtree
            [tree [path & args]]
            (apply update-in tree path fun args)) tree (apply map list paths arglists)))

Other topics

Solar system

The astronomy code for getting the position and orientation of planets was implemented according to the Skyfield Python library.
The Python library in turn is based on the SPICE toolkit of the NASA JPL.
The JPL basically provides sequences of Chebyshev polynomials to interpolate positions of Moon and planets as well as the orientation of the Moon as binary files.
Reference coordinate systems and orientations of other bodies are provided in text files which consist of human and machine readable sections.
The binary files were parsed using Gloss (see Wiki for some examples) and the text files using Instaparse.

Jolt bindings

The required Jolt functions for wheeled vehicle dynamics and collisions with meshes were wrapped in C functions and compiled into a shared library.
The Coffi Clojure library (which is a wrapper for Javaâ€™s new Foreign Function & Memory API) was used to make the C functions and data types usable in Clojure.

For example the following code implements a call to the C function add_force:

(defcfn add-force
  "Apply a force in the next physics update"
  add_force [::mem/int ::vec3] ::mem/void)

Here ::vec3 refers to a custom composite type defined using basic types.
The memory layout, serialisation, and deserialisation for ::vec3 are defined as follows:

(def vec3-struct
  [::mem/struct
   [[:x ::mem/double]
    [:y ::mem/double]
    [:z ::mem/double]]])


(defmethod mem/c-layout ::vec3
  [_vec3]
  (mem/c-layout vec3-struct))


(defmethod mem/serialize-into ::vec3
  [obj _vec3 segment arena]
  (mem/serialize-into {:x (obj 0) :y (obj 1) :z (obj 2)} vec3-struct segment arena))


(defmethod mem/deserialize-from ::vec3
  [segment _vec3]
  (let [result (mem/deserialize-from segment vec3-struct)]
    (vec3 (:x result) (:y result) (:z result))))

Performance

The clj-async-profiler was used to create flame graphs visualising the performance of the game.
In order to get reflection warnings for Java calls without sufficient type declarations, *warn-on-reflection* was set to true.

(set! *warn-on-reflection* true)

Furthermore to discover missing declarations of numerical types, *unchecked-math* was set to :warn-on-boxed.

(set! *unchecked-math* :warn-on-boxed)

To reduce garbage collector pauses, the ZGC low-latency garbage collector for the JVM was used.
The following section in deps.edn ensures that the ZGC garbage collector is used when running the project with clj -M:run:

{:deps {; ...
        }
 :aliases {:run {:jvm-opts ["-Xms2g" "-Xmx4g" "--enable-native-access=ALL-UNNAMED" "-XX:+UseZGC"
                            "--sun-misc-unsafe-memory-access=allow"]
                 :main-opts ["-m" "sfsim.core"]}}}

The option to use ZGC is also specified in the Packr JSON file used to deploy the application.

Building the project

In order to build the map tiles, atmospheric lookup tables, and other data files using tools.build, the project source code was made available in the build.clj file using a :local/root dependency:

{:deps {; ...
        }
 :aliases {; ...
           :build {:deps {io.github.clojure/tools.build {:mvn/version "0.10.10"}
                          sfsim/sfsim {:local/root "."}}
                   :ns-default build
                   :exec-fn all
                   :jvm-opts ["-Xms2g" "-Xmx4g" "--sun-misc-unsafe-memory-access=allow"]}}}

Various targets were defined to build the different components of the project.
For example the atmospheric lookup tables can be build by specifying clj -T:build atmosphere-lut on the command line.

The following section in the build.clj file was added to allow creating an â€œUberjarâ€ JAR file with all dependencies by specifying clj -T:build uber on the command-line.

(defn uber [_]
  (b/copy-dir {:src-dirs ["src/clj"]
               :target-dir class-dir})
  (b/compile-clj {:basis basis
                  :src-dirs ["src/clj"]
                  :class-dir class-dir})
  (b/uber {:class-dir class-dir
           :uber-file "target/sfsim.jar"
           :basis basis
           :main 'sfsim.core}))

To create a Linux executable with Packr, one can then run java -jar packr-all-4.0.0.jar scripts/packr-config-linux.json where the JSON file has the following content:

{
  "platform": "linux64",
  "jdk": "/usr/lib/jvm/jdk-24.0.2-oracle-x64",
  "executable": "sfsim",
  "classpath": ["target/sfsim.jar"],
  "mainclass": "sfsim.core",
  "resources": ["LICENSE", "libjolt.so", "venturestar.glb", "resources"],
  "vmargs": ["Xms2g", "Xmx4g", "XX:+UseZGC"],
  "output": "out-linux"
}

In order to distribute the game on Steam, three depots were created:


  a data depot with the operating system independent data files
  a Linux depot with the Linux executable and Uberjar including LWJGLâ€™s Linux native bindings
  and a Windows depot with the Windows executable and an Uberjar including LWJGLâ€™s Windows native bindings


When updating a depot, the Steam ContentBuilder command line tool creates and uploads a patch in order to preserve storage space and bandwidth.

Future work

Although the hard parts are mostly done, there are still several things to do:


  control surfaces and thruster graphics
  launchpad and runway graphics
  sound effects
  a 3D cockpit
  the Moon
  a space station


It would also be interesting to make the game modable in a safe way (maybe evaluating Clojure files in a sandboxed environment?).

Conclusion


    

You can find the source code on Github.
Currently there is only a playtest build, but if you want to get notified, when the game gets released, you can wishlist it here.

Anyway, let me know any comments and suggestions.

Enjoy!




  Flight dynamics model for simulating Venturestar style spacecraft
  Test Driven Development with OpenGL
  Implementing GUIs using Clojure and LWJGL Nuklear bindings
  Procedural Volumetric Clouds
  Procedural generation of global cloud cover
  Reversed-Z Rendering in OpenGL
  Specifying Clojure function schemas with Malli
  Implement an Interpreter using Clojure Instaparse
  Orbits with Jolt Physics
  Getting started with the Jolt Physics Engine
  Create Blender bones and animate and import with Assimp



]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GLM 4.5 with Claude Code]]></title>
            <link>https://docs.z.ai/guides/llm/glm-4.5</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45145457</guid>
            <description><![CDATA[GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.
Both models share a similar training pipeline: an initial pretraining phase on 15 trillion tokens of general-domain data, followed by targeted fine-tuning on datasets covering code, reasoning, and agent-specific tasks. The context length has been extended to 128k tokens, and reinforcement learning was applied to further enhance reasoning, coding, and agent performance.
GLM-4.5 and GLM-4.5-Air are optimized for tool invocation, web browsing, software engineering, and front-end development. They can be integrated into code-centric agents such as Claude Code and Roo Code, and also support arbitrary agent applications through tool invocation APIs.
Both models support hybrid reasoning modes, offering two execution modes: Thinking Mode for complex reasoning and tool usage, and Non-Thinking Mode for instant responses. These modes can be toggled via the thinking.typeparameter (with enabled and disabled settings), and dynamic thinking is enabled by default.]]></description>
            <content:encoded><![CDATA[   Overview

GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.
Both models share a similar training pipeline: an initial pretraining phase on 15 trillion tokens of general-domain data, followed by targeted fine-tuning on datasets covering code, reasoning, and agent-specific tasks. The context length has been extended to 128k tokens, and reinforcement learning was applied to further enhance reasoning, coding, and agent performance.
GLM-4.5 and GLM-4.5-Air are optimized for tool invocation, web browsing, software engineering, and front-end development. They can be integrated into code-centric agents such as Claude Code and Roo Code, and also support arbitrary agent applications through tool invocation APIs.
Both models support hybrid reasoning modes, offering two execution modes: Thinking Mode for complex reasoning and tool usage, and Non-Thinking Mode for instant responses. These modes can be toggled via the thinking.typeparameter (with enabled and disabled settings), and dynamic thinking is enabled by default.
   GLM-4.5 Serials

   Capability

   Introducting GLM-4.5
Overview
The first-principle measure of AGI lies in integrating more general intelligence capabilities without compromising existing functions. GLM-4.5 represents our first complete realization of this concept. It combines advanced reasoning, coding, and agent capabilities within a single model, achieving a significant technological breakthrough by natively fusing reasoning, coding, and agent abilities to meet the complex demands of agent-based applications.
To comprehensively evaluate the modelâ€™s general intelligence, we selected 12 of the most representative benchmark suites, including MMLU Pro, AIME24, MATH 500, SciCode, GPQA, HLE, LiveCodeBench, SWE-Bench, Terminal-bench, TAU-Bench, BFCL v3, and BrowseComp. Based on the aggregated average scores, GLM-4.5 ranks second globally among all models, first among domestic models, and first among open-source models.

Higher Parameter Efficiency
GLM-4.5 has half the number of parameters of DeepSeek-R1 and one-third that of Kimi-K2, yet it outperforms them on multiple standard benchmark tests. This is attributed to the higher parameter efficiency of GLM architecture. Notably, GLM-4.5-Air, with 106 billion total parameters and 12 billion active parameters, achieves a significant breakthroughâ€”surpassing models such as Gemini 2.5 Flash, Qwen3-235B, and Claude 4 Opus on reasoning benchmarks like Artificial Analysis, ranking among the top three domestic models in performance.
On charts such as SWE-Bench Verified, the GLM-4.5 series lies on the Pareto frontier for performance-to-parameter ratio, demonstrating that at the same scale, the GLM-4.5 series delivers optimal performance.
Low Cost, High Speed
Beyond performance optimization, the GLM-4.5 series also achieves breakthroughs in cost and efficiency, resulting in pricing far lower than mainstream models: API call costs are as low as $0.2 per million input tokens and $1.1 per million output tokens.
At the same time, the high-speed version demonstrates a generation speed exceeding 100 tokens per second in real-world tests, supporting low-latency and high-concurrency deployment scenariosâ€”balancing cost-effectiveness with user interaction experience.
Real-World Evaluation
Real-world performance matters more than leaderboard rankings. To evaluate GLM-4.5â€™s effectiveness in practical Agent Coding scenarios, we integrated it into Claude Code and benchmarked it against Claude 4 Sonnet, Kimi-K2, and Qwen3-Coder.
The evaluation consisted of 52 programming and development tasks spanning six major domains, executed in isolated container environments with multi-turn interaction tests.
As shown in the results (below), GLM-4.5 demonstrates a strong competitive advantage over other open-source models, particularly in tool invocation reliability and task completion rate. While there remains room for improvement compared to Claude 4 Sonnet, GLM-4.5 delivers a largely comparable experience in most scenarios.
To ensure transparency, we have released all 52 test problems along with full agent trajectories for industry validation and reproducibility.
   Usage
Core Capability: Coding Skills â†’ Intelligent code generation | Real-time code completion | Automated bug fixing
Supports major languages including Python, JavaScript, and Java.
Generates well-structured, scalable, high-quality code based on natural language instructions.
Focuses on real-world development needs, avoiding templated or generic outputs.
Use Case: Complete refactoring-level tasks within 1 hour; generate full product prototypes in 5 minutes.
   Resources

API Documentation: Learn how to call the API.

    Quick Start
Thinking Mode
GLM-4.5 offers a â€œDeep Thinking Modeâ€ that users can enable or disable by setting the thinking.type parameter. This parameter supports two values: enabled (enabled) and disabled (disabled). By default, dynamic thinking is enabled.
Simple Tasks (No Thinking Required): For straightforward requests that do not require complex reasoning (e.g., fact retrieval or classification), thinking is unnecessary. Examples include:

When was Z.AI founded?
Translate the sentence â€œI love youâ€ into Chinese.


Moderate Tasks (Default/Some Thinking Required): Many common requests require stepwise processing or deeper understanding. The GLM-4.5 series can flexibly apply thinking capabilities to handle tasks such as:

Why does Jupiter have more moons than Saturn, despite Saturn being larger?
Compare the advantages and disadvantages of flying versus taking the high-speed train from Beijing to Shanghai.



Difficult Tasks (Maximum Thinking Capacity): For truly complex challengesâ€”such as solving advanced math problems, network-related questions, or coding issuesâ€”these tasks require the model to fully engage its reasoning and planning abilities, often involving many internal steps before arriving at an answer. Examples include:
Explain in detail how different experts in a Mixture-of-Experts (MoE) model collaborate.
Based on the recent weekâ€™s fluctuations of the Shanghai Composite Index and current political information, should I invest in a stock index ETF? Why?

Samples Code
Basic Callcurl -X POST "https://api.z.ai/api/paas/v4/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "glm-4.5",
    "messages": [
      {
        "role": "user",
        "content": "As a marketing expert, please create an attractive slogan for my product."
      },
      {
        "role": "assistant",
        "content": "Sure, to craft a compelling slogan, please tell me more about your product."
      },
      {
        "role": "user",
        "content": "Z.AI Open Platform"
      }
    ],
    "thinking": {
      "type": "enabled"
    },
    "max_tokens": 4096,
    "temperature": 0.6
  }'
Streaming Callcurl -X POST "https://api.z.ai/api/paas/v4/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "glm-4.5",
    "messages": [
      {
        "role": "user",
        "content": "As a marketing expert, please create an attractive slogan for my product."
      },
      {
        "role": "assistant",
        "content": "Sure, to craft a compelling slogan, please tell me more about your product."
      },
      {
        "role": "user",
        "content": "Z.AI Open Platform"
      }
    ],
    "thinking": {
      "type": "enabled"
    },
    "stream": true,
    "max_tokens": 4096,
    "temperature": 0.6
  }'
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Tesla changes meaning of 'Full Self-Driving', gives up on promise of autonomy]]></title>
            <link>https://electrek.co/2025/09/05/tesla-changes-meaning-full-self-driving-give-up-promise-autonomy/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45144900</guid>
            <description><![CDATA[Tesla has changed the meaning of â€œFull Self-Drivingâ€, also known as â€œFSDâ€, to give up on its original promise of...]]></description>
            <content:encoded><![CDATA[
					

	

Tesla has changed the meaning of â€œFull Self-Drivingâ€, also known as â€œFSDâ€, to give up on its original promise of delivering unsupervised autonomy.



Since 2016, Tesla has claimed that all its vehicles in production would be capable of achieving unsupervised self-driving capability.



CEO Elon Musk has claimed that it would happen by the end of every year since 2018.



Tesla has even sold a software package, known as â€œFull Self-Driving Capabilityâ€ (FSD), for up to $15,000 to customers, promising that the advanced driver-assist system would become fully autonomous through over-the-air software updates.	
	



Almost a decade later, the promise has yet to be fulfilled, and Tesla has already confirmed that all vehicles produced between 2016 and 2023 donâ€™t have the proper hardware to deliver unsupervised self-driving as promised.



Musk has been discussing the upgrade of the computers in these vehicles to appease owners, but thereâ€™s no concrete plan to implement it.



While thereâ€™s no doubt that Tesla has promised unsupervised self-driving capabilities to FSD buyers between 2016 and 2023, the automaker has since updated its language and now only sells â€œFull Self-Driving (Supervised)â€ to customers:







The fine print mentions that it doesnâ€™t make the vehicle â€œautonomousâ€ and doesnâ€™t promise it as a feature. 



In other words, people buying FSD today are not really buying the capability of unsupervised self-driving as prior buyers did.



Furthermore, Teslaâ€™s board has just submitted a new, unprecedented CEO compensation package for shareholdersâ€™ approval, which could give Musk up to $1 trillionÂ in stock options pending the achievement of certain milestones.



One of these milestones is Tesla having â€œ10 Million Active FSD Subscriptions.â€



At first glance, this would be hopeful for FSD buyers since part of Muskâ€™s compensation would be dependent on delivering on the FSD promises.



However, Tesla has changed the definition of FSD in the compensation package with an extremely vague oneâ€




â€œFSDâ€ means an advanced driving system, regardless of the marketing name used, that is capable of performing transportation tasks that provide autonomous or similar functionality under specified driving conditions.




Tesla now considers FSD only an â€œadvanced driving systemâ€ that should be â€œcapable of performing transportation tasks that prove autonomous or similar functionalityâ€.



The current version of FSD, which requires constant supervising by the driver, could easily fit that description.



Therefore, FSD now doesnâ€™t come with the inital promise of Tesla owners being able to go to sleep in their vehicles and wake up at their destination â€“ a promise that Musk has used to sell Tesla vehicles for years.



Electrekâ€™s Take



The way Tesla discusses autonomy with customers and investors versus how it presents it in its court filings and legally binding documents is strikingly different.



It should be worrying to anyone with an interest in this.



With this very vague description in the new CEO compensation package, Tesla could literally lower the price of FSD and even remove base Autopilot to push customers toward FSD and give Musk hundreds of billions of dollars in shares in the process.




	Thereâ€™s precedent for Tesla decreasing pricing on FSD. Initially, Musk said that Tesla would gradually increase the price of the FSD package as the features improved and approached unsupervised autonomy.



That was true for a while, but then Tesla started slashing FSD prices, which are now down $7,000 from their high in 2023:







The trend is quite apparent and coincidentally began when Teslaâ€™s sales started to decline.



FSD is now a simple ADAS system without any promise of unsupervised self-driving. This might quite honestly be one of the biggest cases of false advertising or bait-and-switch ever.
	
			
			
		
			
	FTC: We use income earning auto affiliate links. More.				]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Universe Within 12.5 Light Years]]></title>
            <link>http://www.atlasoftheuniverse.com/12lys.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45144337</guid>
            <description><![CDATA[This map shows all the star systems that lie within 12.5
light years of our Sun.  Most of the stars are red dwarfs - stars with a tenth of
the Sun's mass and less than one hundredth the luminosity.  Roughly eighty percent
of all the stars in the universe are red dwarfs, and the nearest star - Proxima - is
a typical example.]]></description>
            <content:encoded><![CDATA[
About the Map
This map shows all the star systems that lie within 12.5
light years of our Sun.  Most of the stars are red dwarfs - stars with a tenth of
the Sun's mass and less than one hundredth the luminosity.  Roughly eighty percent
of all the stars in the universe are red dwarfs, and the nearest star - Proxima - is
a typical example.

Epsilon Eridani is orbited by a large planet which might look like this.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Anthropic agrees to pay $1.5B to settle lawsuit with book authors]]></title>
            <link>https://www.nytimes.com/2025/09/05/technology/anthropic-settlement-copyright-ai.html?unlocked_article_code=1.jk8.bTTt.Zir9wmtPaTp2&amp;smid=url-share</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45142885</guid>
        </item>
        <item>
            <title><![CDATA[My Own DNS Server at Home â€“ Part 1: IPv4]]></title>
            <link>https://jan.wildeboer.net/2025/08/My-DNS-Part-1/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45142397</guid>
            <description><![CDATA[â€œItâ€™s always DNSâ€ is a famous meme among network people. Name resolution is technically quite simple. Itâ€™s â€œjustâ€ translating a hostname like jan.wildeboer.net to an IP address. What could possibly go wrong? I am a radical optimist and detail-obsessed knowledge collector, so I decided to find out. As part of my goal to make my home network a little island of Digital Sovereignty, meaning that everything at home should JustWorkâ„¢, even with no working internet connection, a DNS server is needed.]]></description>
            <content:encoded><![CDATA[
        â€œItâ€™s always DNSâ€ is a famous meme among network people. Name resolution is technically quite simple. Itâ€™s â€œjustâ€ translating a hostname like jan.wildeboer.net to an IP address. What could possibly go wrong? I am a radical optimist and detail-obsessed knowledge collector, so I decided to find out. As part of my goal to make my home network a little island of Digital Sovereignty, meaning that everything at home should JustWorkâ„¢, even with no working internet connection, a DNS server is needed.


  Based on and extended from my gist Bind on Fedora 42 as DNS server.


I admit, I have a lot of experience with DNS and BIND. But I still consider myself to be merely on the GoodEnoughâ„¢ side of things. I know how to get DNS configured for my domains. And I want you to feel fearless too. The best place to fail with DNS is the network at home. It limits the impact :)

So read this blog post either as report or as a HOWTO. Both ways can be fun!

In my homelab I have a Raspberry Pi 4 that runs infrastructure services. DNS is one of them, my private CA (Certificate Authority) another. The CA runs as a container on Podman. For DNS I use Bind. It thus has to serve 3 networks:


  192.168.1.0/24 My home IPv4 network
  172.16.0.0/16 IPv4 Network on the second ethernet ports of my homelab servers
  10.88.0.0/16 The (virtual) podman network


It uses my Fritz box (7490) as forwarder, so I can resolve all hosts, including the DHCP entries that the Fritz Box hands out under its default local domain name fritz.box. For my homelab however, I use the homelab.jhw domain name. Thatâ€™s what the Bind DNS server has to take care of.


  WARNING 
I really should use the official .internal TLD (Top Level Domain) for my homelab network, but I decided against it. This introduces the risk of name resolution problems, should someone offer a public .jhw TLD in future. Itâ€™s a risk I am willing to accept in exchange for using a 3 letter TLD at home. Donâ€™t be like me! Use .internal instead. With that out of the way, letâ€™s continue.


What we (well, I) have

Letâ€™s gather what I have in my home network.


  inf01.homelab.jhw at 192.168.1.10: A Raspberry Pi 4 4GB, running Fedora 42 and podman with my Certificate Authority as a container that should be reachable as ca.homelab.jhw. See Be the LetsEncrypt in your homelab with step-ca for more details.
  3 ThinkCentre Tiny PCs in the homelab.jhw zone, called hl01 (192.168.1.11), hl02 (192.168.1.12) and hl03 (192.168.1.13), running RHEL10 (Red Hat Enterprise Linux)
  A Fritz Box 7490 at 192.168.1.254


Letâ€™s install BIND on inf01

We need to do two things. Install BIND and some utilities on inf01 and open the firewall for DNS traffic.

dnf install bind bind-utils
firewall-cmd --add-service=dns --permanent


That was easy enough :)

Configure BIND

To run BIND in the correct way, we need to work on 4 configuration files.


  /etc/named.conf The main configuration file where we tell BIND on which networks it should listen and what zones it will serve.
  /var/named/forward.homelab.jhw The forward zone file that maps hostnames in the homelab.jhw domain to IP addresses on my home network
  /var/named/reverse.homelab.jhw The reverse zone for the 192.168.1.0/24 network range, that looks a bit confusing, that does the opposite. It maps IP addresses to hostnames.
  /var/named/reverse2.homelab.jhw The second reverse zone for the 172.16.0.0/16 network range.


Letâ€™s start with /etc/named.conf.

//
// named.conf
//

options {
  listen-on port 53 { 127.0.0.1; 192.168.1.10; 172.16.1.10; 10.88.0.1; };
  listen-on-v6 port 53 { ::1; fdda:a4da:69a5:0:2783:8c26:b2f1:a6f7; };
  allow-query     { localhost; 192.168.1.0/24; 172.16.0.0/16; 10.88.0.0/16; };

  directory       "/var/named";

  dump-file       "/var/named/data/cache_dump.db";
  statistics-file "/var/named/data/named_stats.txt";
  memstatistics-file "/var/named/data/named_mem_stats.txt";
  secroots-file   "/var/named/data/named.secroots";
  recursing-file  "/var/named/data/named.recursing";

  forwarders { 192.168.1.254; };
  recursion yes;

  dnssec-validation no;

  managed-keys-directory "/var/named/dynamic";
  geoip-directory "/usr/share/GeoIP";

  pid-file "/run/named/named.pid";
  session-keyfile "/run/named/session.key";

  /* https://fedoraproject.org/wiki/Changes/CryptoPolicy */
  include "/etc/crypto-policies/back-ends/bind.config";
};

logging {
        channel default_debug {
                file "data/named.run";
                severity dynamic;
        };
};

zone "." IN {
	type hint;
	file "named.ca";
};

zone "homelab.jhw" IN {
	type master;
	file "forward.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "1.168.192.in-addr.arpa" IN {
	type master;
	file "reverse.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "16.172.in-addr.arpa" IN {
        type master;
        file "reverse2.homelab.jhw";
        allow-update { none; };
        allow-query { any; };
};

include "/etc/named.rfc1912.zones";
include "/etc/named.root.key";


The first block declare the general options. Yes, it looks complicated and it is, but letâ€™s walk you through every relevant line (the lines not mentioned are default entries that donâ€™t need to be changed).

listen-on port 53 { 127.0.0.1; 192.168.1.10; 172.16.1.10; 10.88.0.1; };
listen-on-v6 port 53 { ::1; fdda:a4da:69a5:0:2783:8c26:b2f1:a6f7; };
allow-query     { localhost; 192.168.1.0/24; 172.16.0.0/16; 10.88.0.0/16; };


Here we tell BIND that it should listen for queries on port 53 on localhost, 192.168.1.10, the IPv4 address in my hoem network, 172.16.1.10, the second IPv4 address configured and 10.88.0.1, the virtual IPv4 address the Raspberry uses to bridge to the local podman containers.

The second line does the same for IPv6, but that is something we will discuss in Part 2.

The third line tells BIND from whom to accept queries. Essentially from everyone on the three IPv4 networks we are listening to.

directory       "/var/named";


This is the directory where BIND will look for its zone files, that we will define later.

forwarders { 192.168.1.254; };
recursion yes;


Now what if someone asks for a hostname that is outside of homelab.jhw? In that case we tell BIND to forward that question to 192.168.1.254, our Fritz Box. We will allow recursion and cache results we get from our Fritz box to avoid unneeded traffic.

dnssec-validation no;


Our simple setup will not bother with DNSSEC at the moment. Maybe we will have a Part 3 for that.

OK. That was the options part. We will ignore the logging part and the zone "." IN block.

Next (and finally) we define three zone entries (and zone files). A forward zone called homelab.jhw for our domain and two reverse zones for the IP addresses in the 192.168.1.0/24 range called 1.168.192.in-addr.arpa. Yep. Thatâ€™s 192.168.1 reversed. 1.168.192. Thatâ€™s why itâ€™s called the reverse zone ;) We also have 16.172.in-addr.arpa for the 172.16.0.0/16 range. Letâ€™s look at them.

zone "homelab.jhw" IN {
	type master;
	file "forward.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};


Itâ€™s a zone, all right. Itâ€™s the master for this zone, meaning that this DNS server will be the Source of Truth to  answer all queries for the homelab.jhw hostnames.

The exact mapping of all hostnames to IP addresses is in a file called forward.homelab.jhw in the directory /var/named. Remember how we defined that path at the beginning in the options part? Great! We also tell BIND that we do not allow dynamic updates for this zone, meaning that whatâ€™s in the file is all we will look at. Finally we tell BIND that any machine in the network is allowed to ask for a reply.

zone "1.168.192.in-addr.arpa" IN {
	type master;
	file "reverse.homelab.jhw";
	allow-update { none; };
	allow-query { any; };
};

zone "16.172.in-addr.arpa" IN {
        type master;
        file "reverse2.homelab.jhw";
        allow-update { none; };
        allow-query { any; };
};


The reverse zones with the weird looking zone names are almost the same, except that we define these in two files called reverse.homelab.jhw for the reverse lookup of the 192.168.1.0/24 range and reverse2.homelab.jhw for the 172.16.0.0/16 range. Why these zones have weird names will be explained later.

So now we go to the zone files!

Forward zone for homelab.jhw

The forward zone resolves names to IP addresses using A records (and other types like TXT, CAA and many more exist, but we wonâ€™t cover that in this post). It also contains CNAME entries, if you have services on one machine that should be reachable via more than one hostnames. In my homelab the CA (Certificate Authority) server is a container that runs on inf01.homelab.jhw, but should be reachable as ca.homelab.jhw in the home network. The CNAME entry does exactly that. It tells clients that when they want to talk to ca.homelab.jhw they can. By actually talking to inf01.homelab.jhw.

Now here is the big, important lessen for zone files. They have a serial number. Which MUST be incremented with every change. If you donâ€™t, weird things WILL happen. So:


  NEVER FORGET TO INCREASE THE SERIAL WITH EVERY CHANGE TO A ZONE FILE. OR RISK DNS HELL.


/var/named/forward.homelab.jhw

$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082706  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  A           192.168.1.10

inf01           IN  A     192.168.1.10
hl01            IN  A     192.168.1.11
hl02            IN  A     192.168.1.12
hl03            IN  A     192.168.1.13

ca              IN  CNAME inf01.homelab.jhw.

inf01-m         IN  A     172.16.1.10
hl01-m          IN  A     172.16.1.11
hl02-m          IN  A     172.16.1.12
hl03-m          IN  A     172.16.1.13


Again, letâ€™s go through this.

$TTL 3600


The default Time To Live (TTL) for DNS entries is set at 3600 seconds. Thatâ€™s 1 hour. This means that when a machine in the network gets a DNS reply, it will not ask again for the same thing until the TTL has passed.

@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082706  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)


The Start Of Authority (SOA) block. Here we say which DNS server is the owner of this domain. Itâ€™s inf01.homelab.jhw. (yes, that dot at the end is REALLY important). The root.homelab.jhw actually means root@homelab.jhw and is the email address responsible for this domain. Donâ€™t think to much about why and what :)

@       IN  NS          inf01.homelab.jhw.
@       IN  A           192.168.1.10


The first â€œrealâ€ DNS entries! They are special, as the @ indicates, which means they represent the domain itself. We first define the nameserver (again? yes, don*â€˜t ask) as NS record. And right after that we define the A record as the IP address 192.168.1.10.

Did you notice that . at the end of inf01.homelab.jhw.? Thatâ€™s another VERY important thing. The TL;DR is that this final . tells DNS to stop doing fancy recursion and lookups. Just look for the hostname `inf01.homelab.jhw. Period. (pun intended). Donâ€™t care too much about this. Just remember:

EVERY HOSTNAME RECORD ENDS WITH A . YOU WILL FORGET THIS. YOU WILL FIX THIS.

inf01           IN  A     192.168.1.10
hl01            IN  A     192.168.1.11
hl02            IN  A     192.168.1.12
hl03            IN  A     192.168.1.13


Here come the A records for 192.168.1.0/24! We finally get to map hostnames to IP addresses. For real! It now is quite self-explanatory, isnâ€™t it? The hostname gets an A record that is the IP address in my local network. And as these are IP addresses, no . is needed at the end.

ca              IN  CNAME inf01.homelab.jhw.


And here is the CNAME record. Which maps the hostname ca.homelab.jhw to the Canonical NAME (CNAME) inf01.homelab.jhw.. This is a hostname at the end! So it needs the . Period :)

inf01-m         IN  A     172.16.1.10
hl01-m          IN  A     172.16.1.11
hl02-m          IN  A     172.16.1.12
hl03-m          IN  A     172.16.1.13


And here we create another set of A records for the same machines, but this time in the 172.16.0.0/16 range. This range is used for management stuff, hence the -m.

And thatâ€™s the gist of it. If you add a new machine to your network, configure it with an IP address (statically or with DHCP) and add it as an A record to the forward zone. Increment the serial and tell DNS to read the updated zone with systemctl reload named. Done.

Reverse zones for 192.168.1.0/24 and 172.16.0.0/16

The reverse zone maps IP addresses to hostnames. Often called the PTR or pointer record. You have to make sure that the entries here are synced to the forward zone.


  NEVER FORGET TO INCREASE THE SERIAL WITH EVERY CHANGE TO A ZONE FILE. Or risk DNS hell.


Here is the reverse zone for the 192.168.1.0/24 range.

/var/named/reverse.homelab.jhw

$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082601  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  PTR         homelab.jhw.
10      IN  PTR         inf01.homelab.jhw.
11      IN  PTR         hl01.homelab.jhw.
12      IN  PTR         hl02.homelab.jhw.
13      IN  PTR         hl03.homelab.jhw.


As this is more or less the same but the other way round, I will not go through everything but instead explain the differences. Itâ€™s the reverse zone, so now we have PTR (pointer) entries that map an IPv4 address in the 192.168.1.0/24 range to hostnames. WITH A DOT AT THE END. DO NOT FORGET THE DOT!

As this is a /24 block, we only need to set the last digit of the IPv4 address.

You might wonder, where is ca here? Well, itâ€™s CNAME is info1.homelab.jhw and that already is in this reverse zone. That is good enough. No separate entry needed.

We also need the reverse zone for the 172.16.0.0/16 range:

/var/named/reverse2.homelab.jhw

$TTL 3600
@   IN  SOA     inf01.homelab.jhw. root.homelab.jhw. (
        2025082901  ;Serial
        3600        ;Refresh
        1800        ;Retry
        604800      ;Expire
        86400       ;Minimum TTL
)
@       IN  NS          inf01.homelab.jhw.
@       IN  PTR         homelab.jhw.
10.1      IN  PTR         inf01-m.homelab.jhw.
11.1      IN  PTR         hl01-m.homelab.jhw.
12.1      IN  PTR         hl02-m.homelab.jhw.
13.1      IN  PTR         hl03-m.homelab.jhw.


Looks deceivingly similar. But there is a big difference. This is a /16 network, so we have to define the last two parts of the IPv4 address. And as it is a reverse zone file, yep, we have to reverse it. So now we need 10.1 to define the entry for 172.16.1.10, which is the hostname inf01-m.homelab.jhw. WITH THE DOT AT THE END. AND DID YOU UPDATE THE SERIAL? :)

Phew. Thatâ€™s the config done!

A final check with the named-checkconf command, which should say nothing when all files are OK. If not, it will tell you what is wrong so you get the chance to fix stuff. You did add all the . at the end of hostnames and you did update the serial of that zone file after you made changes, yes?

Start Bind

The only thing remaining is to start BIND. And persist it as a service, so it starts after every boot. Itâ€™s DNS. It must always be available.

systemctl enable named
systemctl start named


You most likely will make typos in your config. So do check with named-checkconf  and systemctl status named and journalctl -u named. If something breaks, read this whole entry again. Find that missing . in a zone file. Increment the serial that you forgot to do. You will get there. Donâ€™t give up!

Result

Machines, containers etc can now be resolved in my home network. All with mow own DNS! Yay!

% nslookup jhwfritz.fritz.box
Server:		192.168.1.10
Address:	192.168.1.10#53

Non-authoritative answer:
Name:	jhwfritz.fritz.box
Address: 192.168.1.254

% nslookup ca.homelab.jhw    
Server:		192.168.1.10
Address:	192.168.1.10#53

ca.homelab.jhw	canonical name = inf01.homelab.jhw.
Name:	inf01.homelab.jhw
Address: 192.168.1.10


And now you should be able to ping the machines with their hostname. ssh into them. Get certificates with the CA that runs in the podman container. Life is good!

I hope you enjoyed this post and could learn something new! Feel free to comment or send corrections vie the Toot linked below that collects the comments!
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Making a font of my handwriting]]></title>
            <link>https://chameth.com/making-a-font-of-my-handwriting/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45141636</guid>
            <description><![CDATA[Recently Iâ€™ve been on a small campaign to try to make my personal website moreâ€¦ personal. Little ways to
            make it obvious itâ€™s mine and personal, not just another piece of the boring corporate
            dystopia that is most of the web these days. I donâ€™t quite want to fully regress to the Geocities era and
            fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.]]></description>
            <content:encoded><![CDATA[
          
            Recently Iâ€™ve been on a small campaign to try to make my personal website moreâ€¦ personal. Little ways to
            make it obvious itâ€™s mine and personal, not just another piece of the boring corporate
            dystopia that is most of the web these days. I donâ€™t quite want to fully regress to the Geocities era and
            fill the screen with animated under construction GIFs, but I do want to capture some of that vibe.
          
          
            Iâ€™d added some bits and pieces along those lines: floating images in articles now look like theyâ€™re stuck to
            the page with sellotape, related post links have a wavy border that animates when you hover over them, and
            so on. Next, I wanted to change the heading fonts from a monospace font to something cursive, to resemble
            handwriting. Less terminal output, more handwritten letter. I couldnâ€™t find one I liked, though. So why not
            make my own? It canâ€™t be that hard, right?
          
          Failing to do it myself
          
            I set out to try to make the font myself using open source tools. After doing a bit of research, it seemed
            like the general approach was to create vectors of each character and then import them into a font editor.
            That seems to mean either Adobe Illustrator and FontLab (if you have too much money) or Inkscape and
            FontForge (if you like open source). I fall firmly into the latter category, so I grabbed my graphics tablet
            and opened Inkscape.
          
          
            I wrote out my first three letters: capital A, B and C. Saved them in Inkscape, and attempted to import them
            into FontForge. Then I remembered one crucial thing that had slipped my mind: I absolutely loathe using
            FontForge. Itâ€™s a bit like when you open an old version of GIMP and get a bunch of weird looking windows
            floating all over the place; it feels like youâ€™re fighting against the tool to do even the most basic
            operations. The difference is I have cause to edit images a lot more than I edit fonts, and GIMP
            has actually significantly improved their UI over the years.
          
          Here are the rough steps I went through with FontForge:
          
            Launch Font Forge. It shows a weird bit of art in one window, and an open file dialog in another.
            I donâ€™t want to open a file, so I close that dialog. The program exits.
            Relaunch Font Forge, and realise that within the â€œOpen Fontâ€ dialog is a â€œNewâ€ button. Click it.
            
              Get to the standard font-editing UI. Right-click on the â€œAâ€ looking for a way to import an SVG. Donâ€™t see
              one.
            
            
              Click around a bit, exploring the menus. Everything feels a bit off. You canâ€™t open one menu then hover
              over the next to see its content, like basically every UI toolkit in existence. I think FontForge has
              eschewed QT and GTK in favour of doing things itself.
            
            Find the â€œImportâ€ option in the File menu. Hope itâ€™s for a single glyph not the whole font.
            
              A file picker opens. Again itâ€™s all a bit off from normal desktop conventions. Try to resize it, and just
              get blank gray space at the bottom.
            
            Type the absolute path I want to go to in the text field.
            Get a dialog saying â€œNot a bdf file /home/chris/etcâ€. Press OK.
            Get a dialog saying â€œCould not find a bitmap font inâ€. Press OK.
            
              Press Ctrl+L to see if that lets me enter a path. Click everything in the dialog to try to find a way to
              enter a path. Get annoyed. Give up. Click through folder-by-folder to get to where I want to be.
            
            
              Get to the folder and donâ€™t see any files. Change the format to â€œSVGâ€. Double-click the newly-visible SVG
              file.
            
            Get a dialog saying â€œYou must select a glyph before you can import an image into itâ€. Press OK.
            The import dialog goes away, having not imported.
            Select the glyph in the main tool area, then repeat the Fileâ†’Import dance.
            
              Itâ€™s actually there now! Open the glyph in the editor and see itâ€™s a complete mess of BÃ©zier curves. I
              canâ€™t click what I want without accidentally moving a handle for an adjacent curve.
            
            Rage-quit.
          
          
            Iâ€™m sure FontForge is less anger inducing once youâ€™re used to it. And you definitely could use it to build a
            font like this if you had much more patience than me. Iâ€™d had enough of death-by-a-thousand-paper-cuts
            though.
          
          
            I briefly tried Inkscapeâ€™s built-in support for making an SVG font. It annoyed me a lot less, but itâ€™s
            fiddly: it seemed like each font had to be a single path, so you had to convert the glyphs to paths, then
            merge them correctly. If you merge them incorrectly then the wrong bits of your letters end up filled (like
            the inside of the â€˜Bâ€™). Path manipulation is getting towards the limit of my knowledge of vector editing,
            and it took a bit of trial and error for each letter that had more than a single stroke. I didnâ€™t fancy
            doing that for every letter.
          
          
            Iâ€™m usually a big advocate of open source, but this was one of those painful times where it feels like it
            just falls short. Clunky, painful UI and processes where commercial tools just let you get on with your
            work.
          
          You can exchange money for goods and services
          
            When Iâ€™d been looking for open source tutorials, I found many mentions of a closed source, hosted tool:
            Calligraphr. It has a free version with limitations (no
            ligatures, no variations, 75 glyphs per font), and a pro version for Â£8/month. Iâ€™d normally balk at the idea
            of a subscription for this, but they have the perfect answer: you can make a one-time payment, and your
            account automatically downgrades back to free after a month. Itâ€™s not a hidden option, either, itâ€™s the most
            prominent button on the upgrade page. That made me happy to give them Â£8 to play around with the service for
            a month.
          
          
            Calligraphr works by having you print templates, write out the letters, then scan them in. It does some
            magical processing to extract the glyphs, provides tools to tidy them up, align them, etc, and then produces
            a TTF file for you. You can see some of my completed templates here:
          
          
            
              
              
              
            
            Most of the templates I used for the font
          
          
            Calligraphr has a nice UI to generate the templates, allowing you to select which glyphs to include. I added
            the â€œminimal Englishâ€, â€œbasic punctuationâ€ and â€œLigaturesâ€ sets. That gave me four pages to fill out, and I
            did them all twice. That let me filter out versions that didnâ€™t work well, and have variants for some
            letters so the font wasnâ€™t too repetitive. Later on, I went back and added some custom ligatures based on
            blog post titles that didnâ€™t look quite right: â€œReâ€, â€œToâ€, â€œersâ€, â€œeyâ€, â€œhyâ€, â€œraâ€, â€œreâ€ and â€œtyâ€. Ligatures
            like this help it look more natural: when we write we donâ€™t just stamp out identical letters regardless of
            their surroundings, instead they will connect to their neighbours, or overlap slightly, or even share a
            stroke.
          
          
            I filled these templates in with a Sharpie, as I wanted a fairly informal, scrap-booky look, and it would
            also give good solid shapes that should be easy to pick out of the template. I scanned them with the â€œScan
            Documentâ€ function on my iPhone, and uploaded the PDFs to Calligraphr.
          
          Iterating and tweaking
          
            The Calligraphr UI allows you to preview the font, but I found it a lot more useful to just download a copy
            and use it on a local copy of my website. That let me test it with real text, and see how itâ€™d look at the
            different font sizes I use on the site.
          
          
            The first version was not great. Despite the guidelines on the template, I apparently wasnâ€™t good at
            sticking to them. Some letters were floating way off the baseline, and some were sunken below. When those
            opposites met it looked terrible. Fortunately Calligraphr has a pretty easy tool to slide each letter up and
            down, and scale it up or down if needed, and you can see it next to other letters as you do it. It took a
            little bit of time to go through all the variants of all the letters, but the next version looked a lot
            better.
          
          
            Another tweak I ended up doing was reducing the spacing between letters. The defaults Calligraphr uses are
            probably good for a blocky font, but I wanted to put the letters close together to give it more of a
            joined-up look. Again, this is an easy tool to use, you just drag the sides in or out as desired. While
            these tweaking steps were probably as fiddly as some of the Inkscape steps I refused to do earlier, theyâ€™re
            a lot more rewarding as you see things improving with each one. Itâ€™s a lot easier for me to commit time and
            effort to improving something thatâ€™s already working reasonably, than put that time and energy into an
            unknown.
          
          
            Later, I noticed that occasionally there would be a huge gap in a title. Not â€œthe kerning is slightly offâ€
            but â€œthereâ€™s enough room to park a busâ€. It took me a while to figure out what was happening: a couple of
            glyphs hadnâ€™t been isolated perfectly and had picked up a few pixels from the template lines at the edge of
            their boxes. That meant the glyph had a width that covered the actual written glyph, a big gap, and then the
            rogue marks. At first, I fixed this by just adjusting the width, but that left the little pixels floating
            awkwardly down-sentence. The proper fix was to use the editing tool and simply delete them, and then
            Calligraphr snapped the width back to what it should be.
          
          
            These iterations took a while to do, but I just dipped in and out occasionally over the course of a week, so
            it didnâ€™t actually feel like too much work. I quite enjoy the process of refining things, too.
          
          Result and a surprise
          
            If youâ€™re viewing this post on my website[1], you can see the font in the headers, captions, and a few other places. Hereâ€™s how it compares to my
            actual handwriting:
          
          
            
              
              
              
            
            My handwriting vs my handwriting font
          
          
            Itâ€™s not close enough to forge documents, but I think it definitely gets across my style, and thatâ€™s exactly
            what I wanted. Itâ€™s surprisingly legible even at smaller font sizes â€” I think the weight of the Sharpie
            helps here â€” and at Â£8 and a bit of manual work was a lot more economical than spending days wresting with
            open source tools.
          
          
            A few weeks after I put the finishing touches on the font, I got an e-mail from Calligraphr. As my account
            had lapsed back to the free version, I was no longer eligible for the â€œserver-side backupâ€ feature. So what
            did they do? They e-mailed me an exported copy! Itâ€™s a JSON file with the properties of each glyph and a
            base64 encoded image. Not only can I re-upload this to Calligraphr if I resubscribe, I can probably hook
            something up to edit it should I ever need to. Iâ€™m blown away by how pro-user Calligraphrâ€™s business
            practices are. Theyâ€™re up-front about pricing, donâ€™t try and get you stuck on an auto-renewing subscription,
            and automatically export your data. Itâ€™s like a breath of fresh air compared to the barrage of dark patterns
            that other websites foist on us. If you want to make this kind of font, Iâ€™d definitely recommend them just
            because of how nice they are.
          
          
          
            
              
                
                  And I havenâ€™t changed everything since writing this postâ€¦
                  â†©ï¸
                
              
            
          
        ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MentraOS â€“ open-source Smart glasses OS]]></title>
            <link>https://github.com/Mentra-Community/MentraOS</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45140381</guid>
            <description><![CDATA[Smart glasses OS, with dozens of built-in apps. Users get AI assistant, notifications, translation, screen mirror, captions, and more. Devs get to write 1 app that runs on any pair of smart glases....]]></description>
            <content:encoded><![CDATA[

    
  
  
    
  

Supported Smart Glasses
Works with Even Realities G1, Mentra Mach 1, Mentra Live. See smart glasses compatibility list here.
Apps on Mentra Store
The Mentra Store already has a ton of useful apps that real users are running everyday. Here are some apps already published by developers on the Mentra Store:

Write Once, Run on Any Smart Glasses
MentraOS is how developers build smart glasses apps. We handle the pairing, connection, data streaming, and cross-compatibility, so you can focus on creating amazing apps. Every component is 100% open source (MIT license).
Why Build with MentraOS?

Cross Compatibility: Your app runs on any pair of smart glasses
Speed: TypeScript SDK means you're making apps in minutes, not months
Control: Access smart glasses I/O - displays, microphones, cameras, speakers
Distribution: Get your app in front of everyone using smart glasses

MentraOS Community
The MentraOS Community is a group of developers, companies, and users dedicated to ensuring the next personal computer is open, cross-compatible, and user-controlled. That's why we're building MentraOS.
To get involved, join the MentraOS Community Discord server.
Contact
Have questions or ideas? We'd love to hear from you!

Email: team@mentra.glass
Discord: Join our community
Twitter: Follow @mentralabs

Contributing
MentraOS is made by a community and we welcome PRs. Here's the Contributors Guide: docs.mentra.glass/contributing
License
MIT License Copyright 2025 MentraOS Community


  
  Â© 2025 Mentra Labs

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Protobuffers Are Wrong (2018)]]></title>
            <link>https://reasonablypolymorphic.com/blog/protos-are-wrong/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45139656</guid>
            <description><![CDATA[Iâ€™ve spent a good deal of my professional life arguing against using protobuffers. Theyâ€™re clearly written by amateurs, unbelievably ad-hoc, mired in gotchas, tricky to compile, and solve a problem that nobody but Google really has. If these problems of protobuffers remained quarantined in serialization abstractions, my complaints would end there. But unfortunately, the bad design of protobuffers is so persuasive that these problems manage to leak their way into your code as well.]]></description>
            <content:encoded><![CDATA[
    Iâ€™ve spent a good deal of my professional life arguing against using protobuffers. Theyâ€™re clearly written by amateurs, unbelievably ad-hoc, mired in gotchas, tricky to compile, and solve a problem that nobody but Google really has. If these problems of protobuffers remained quarantined in serialization abstractions, my complaints would end there. But unfortunately, the bad design of protobuffers is so persuasive that these problems manage to leak their way into your code as well.
Ad-Hoc and Built By Amateurs
Stop. Put away your email client that is half-way through writing me about how â€œGoogle is filled with the worldâ€™s best engineers,â€ and that â€œanything they build is, by definition, not built by amateurs.â€ I donâ€™t want to hear it.
Letâ€™s just get this out of the way. Full disclosure: I used to work at Google. It was the first (but unfortunately, not the last) place I ever used protobuffers. All of the problems I want to talk about today exist inside of Googleâ€™s codebase; itâ€™s not just a matter of â€œusing protobuffers wrongâ€ or some such nonsense like that.
By far, the biggest problem with protobuffers is their terrible type-system. Fans of Java should feel right at home with protobuffers, but unfortunately, literally nobody considers Java to have a well-designed type-system. The dynamic typing guys complain about it being too stifling, while the static typing guys like me complain about it being too stifling without giving you any of the things you actually want in a type-system. Lose lose.
The ad-hoc-ness and the built-by-amateurs-itude go hand-in-hand. So much of the protobuffer spec feels bolted on as an afterthought that it clearly was bolted on as an afterthought. Many of its restrictions will make you stop, scratch your head and ask â€œwat?â€ But these are just symptoms of the deeper answer, which is this:
Protobuffers were obviously built by amateurs because they offer bad solutions to widely-known and already-solved problems.
No Compositionality
Protobuffers offer several â€œfeaturesâ€, but none of them see to work with one another. For example, look at the list of orthogonal-yet-constrained typing features that I found by skimming the documentation.

oneof fields canâ€™t be repeated.
map<k,v> fields have dedicated syntax for their keys and values, but this isnâ€™t used for any other types.
Despite map fields being able to be parameterized, no user-defined types can be. This means youâ€™ll be stuck hand-rolling your own specializations of common data structures.
map fields cannot be repeated.
map keys can be strings, but can not be bytes. They also canâ€™t be enums, even though enums are considered to be equivalent to integers everywhere else in the protobuffer spec.
map values cannot be other maps.

This insane list of restrictions is the result of unprincipled design choices and bolting on features after the fact. For example, oneof fields canâ€™t be repeated because rather than resulting in a coproduct type, instead the code generator will give you a product of mutually-exclusive optional fields. Such a transformation is only valid for a singular field (and, as weâ€™ll see later, not even then.)
The restriction behind map fields being unable to be repeated is related, but shows off a different limitation of the type-system. Behind the scenes, a map<k,v> is desugared into something spiritually similar to repeated Pair<k,v>. And because repeated is a magical language keyword rather than a type in its own right, it doesnâ€™t compose with itself.
Your guess is as good as mine for why an enum canâ€™t be used as a map key.
Whatâ€™s so frustrating about all of this is a little understanding of how modern type-systems work would be enough to drastically simplify the protobuffer spec and simultaneously remove all of the arbitrary restrictions.
The solution is as follows:

Make all fields in a message required. This makes messages product types.
Promote oneof fields to instead be standalone data types. These are coproduct types.
Give the ability to parameterize product and coproduct types by other types.

Thatâ€™s it! These three features are all you need in order to define any possible piece of data. With these simpler pieces, we can re-implement the rest of the protobuffer spec in terms of them.
For example, we can rebuild optional fields:
product Unit {
  // no fields
}

coproduct Optional<t> {
  t    value = 0;
  Unit unset = 1;
}
Building repeated fields is simple too:
coproduct List<t> {
  Unit empty = 0;
  Pair<t, List<t>> cons = 1;
}
Of course, the actual serialization logic is allowed to do something smarter than pushing linked-lists across the networkâ€”after all, implementations and semantics donâ€™t need to align one-to-one.
Questionable Choices
In the vein of Java, protobuffers make the distinction between scalar types and message types. Scalars correspond more-or-less to machine primitivesâ€”things like int32, bool and string. Messages, on the other hand, are everything else. All library- and user-defined types are messages.
The two varieties of types have completely different semantics, of course.
Fields with scalar types are always present. Even if you donâ€™t set them. Did I mention that (at least in proto31) all protobuffers can be zero-initialized with absolutely no data in them? Scalar fields get false-y valuesâ€”uint32 is initialized to 0 for example, and string is initialized as "".
Itâ€™s impossible to differentiate a field that was missing in a protobuffer from one that was assigned to the default value. Presumably this decision is in place in order to allow for an optimization of not needing to send default scalar values over the wire. Presumably, though the encoding guide makes no mention of this optimization being performed, so your guess is as good as mine.
As weâ€™ll see when we discuss protobuffersâ€™ claim to being godâ€™s gift to backwards- and forwards-compatible APIs, this inability to distinguish between unset and default values is a nightmare. Especially if indeed itâ€™s a design decision made in order to save one bit (set or not) per field.
Contrast this behavior against message types. While scalar fields are dumb, the behavior for message fields is outright insane. Internally, message fields are either there or theyâ€™re notâ€”but their behavior is crazy. Some pseudocode for their accessor is worth a thousand words. Pretend this is Java or something similar:
private Foo m_foo;

public Foo foo {
  // only if `foo` is used as an expression
  get {
    if (m_foo != null)
      return m_foo;
    else
      return new Foo();
  }

  // instead if `foo` is used as an lvalue
  mutable get {
    if (m_foo = null)
      m_foo = new Foo();
    return m_foo;
  }
}
The idea is that if the foo field is unset, youâ€™ll see a default-initialized copy whenever you ask for it, but wonâ€™t actually modify its container. But if you modify foo, it will modify its parent as well! All of this just to avoid using a Maybe Foo type and the associated â€œheadachesâ€ of the nuance behind needing to figure out what an unset value should mean.
This behavior is especially egregious, because it breaks a law! Weâ€™d expect the assignment msg.foo = msg.foo; to be a no-op. Instead the implementation will actually silently change msg to have a zero-initialized copy of foo if it previously didnâ€™t have one.
Unlike scalar fields, at least itâ€™s possible to detect if a message field is unset. Language bindings for protobuffers offer something along the lines of a generated bool has_foo() method. In the frequent case of copying a message field from one proto to another, iff it was present, youâ€™ll need to write the following code:
if (src.has_foo(src)) {
  dst.set_foo(src.foo());
}
Notice that, at least in statically-typed languages, this pattern cannot be abstracted due to the nominal relationship between the methods foo(), set_foo() and has_foo(). Because all of these functions are their own identifiers, we have no means of programmatically generating them, save for a preprocessor macro:
#define COPY_IFF_SET(src, dst, field) \
if (src.has_##field(src)) { \
  dst.set_##field(src.field()); \
}
(but preprocessor macros are verboten by the Google style guide.)
If instead all optional fields were implemented as Maybes, youâ€™d get abstract-able, referentially transparent call-sites for free.
To change tack, letâ€™s talk about another questionable decision. While you can define oneof fields in protobuffers, their semantics are not of coproduct types! Rookie mistake my dudes! What you get instead is an optional field for each case of the oneof, and magic code in the setters that will just unset any other case if this one is set.
At first glance, this seems like it should be semantically equivalent to having a proper union type. But instead it is an accursed, unutterable source of bugs! When this behavior teams up with the law-breaking implementation of msg.foo = msg.foo;, it allows this benign-looking assignment to silently delete arbitrary amounts of data!
What this means at the end of the day is that oneof fields do not form law-abiding Prisms, nor do messages form law-abiding Lenses. Which is to say good luck trying to write bug-free, non-trivial manipulations of protobuffers. It is literally impossible to write generic, bug-free, polymorphic code over protobuffers.
Thatâ€™s not the sort of thing anybody likes to hear, let alone those of us who have grown to love parametric polymorphismâ€”which gives us the exact opposite promise.
The Lie of Backwards- and Forwards-Compatibility
One of the frequently cited killer features of protobuffers is their â€œhassle-free ability to write backwards- and forwards-compatible APIs.â€ This is the claim that has been pulled over your eyes to blind you from the truth.
What protobuffers are is permissive. They manage to not shit the bed when receiving messages from the past or from the future because they make absolutely no promises about what your data will look like. Everything is optional! But if you need it anyway, protobuffers will happily cook up and serve you something that typechecks, regardless of whether or not itâ€™s meaningful.
This means that protobuffers achieve their promised time-traveling compatibility guarantees by silently doing the wrong thing by default. Of course, the cautious programmer can (and should) write code that performs sanity checks on received protobuffers. But if at every use-site you need to write defensive checks ensuring your data is sane, maybe that just means your deserialization step was too permissive. All youâ€™ve managed to do is decentralize sanity-checking logic from a well-defined boundary and push the responsibility of doing it throughout your entire codebase.
One possible argument here is that protobuffers will hold onto any information present in a message that they donâ€™t understand. In principle this means that itâ€™s nondestructive to route a message through an intermediary that doesnâ€™t understand this version of its schema. Surely thatâ€™s a win, isnâ€™t it?
Granted, on paper itâ€™s a cool feature. But Iâ€™ve never once seen an application that will actually preserve that property. With the one exception of routing software, nothing wants to inspect only some bits of a message and then forward it on unchanged. The vast majority of programs that operate on protobuffers will decode one, transform it into another, and send it somewhere else. Alas, these transformations are bespoke and coded by hand. And hand-coded transformations from one protobuffer to another donâ€™t preserve unknown fields between the two, because itâ€™s literally meaningless.
This pervasive attitude towards protobuffers always being compatible rears its head in other ugly ways. Style guides for protobuffers actively advocate against DRY and suggest inlining definitions whenever possible. The reasoning behind this is that it allows you to evolve messages separately if these definitions diverge in the future. To emphasize that point, the suggestion is to fly in the face of 60 yearsâ€™ worth of good programming practice just in case maybe one day in the future you need to change something.
At the root of the problem is that Google conflates the meaning of data with its physical representation. When youâ€™re at Google scale, this sort of thing probably makes sense. After all, they have an internal tool that allows you to compare the finances behind programmer hours vs network utilization vs the cost to store \(x\) bytes vs all sorts of other things. Unlike most companies in the tech space, paying engineers is one of Googleâ€™s smallest expenses. Financially it makes sense for them to waste programmersâ€™ time in order to shave off a few bytes.
Outside of the top five tech companies, none of us is within five orders of magnitude of being Google scale. Your startup cannot afford to waste engineer hours on shaving off bytes. But shaving off bytes and wasting programmersâ€™ time in the process is exactly what protobuffers are optimized for.
Letâ€™s face it. You are not Google scale and you never will be. Stop cargo-culting technology just because â€œGoogle uses itâ€ and therefore â€œitâ€™s an industry best-practice.â€
Protobuffers Contaminate Codebases
If it were possible to restrict protobuffer usage to network-boundaries I wouldnâ€™t be nearly as hard on it as a technology. Unfortunately, while there are a few solutions in principle, none of them is good enough to actually be used in real software.
Protobuffers correspond to the data you want to send over the wire, which is often related but not identical to the actual data the application would like to work with. This puts us in the uncomfortable position of needing to choose between one of three bad alternatives:

Maintain a separate type that describes the data you actually want, and ensure that the two evolve simultaneously.
Pack rich data into the wire format for application use.
Derive rich information every time you need it from a terse wire format.

Option 1 is clearly the â€œrightâ€ solution, but its untenable with protobuffers. The language isnâ€™t powerful enough to encode types that can perform double-duty as both wire and application formats. Which means youâ€™d need to write a completely separate datatype, evolve it synchronously with the protobuffer, and explicitly write serialization code between the two. Seeing as most people seem to use protobuffers in order to not write serialization code, this is obviously never going to happen.
Instead, code that uses protobuffers allows them to proliferate throughout the codebase. True story, my main project at Google was a compiler that took â€œprogramsâ€ written in one variety of protobuffer, and spit out an equivalent â€œprogramâ€ in another. Both the input and output formats were expressive enough that maintaining proper parallel C++ versions of them could never possibly work. As a result, my code was unable to take advantage of any of the rich techniques weâ€™ve discovered for writing compilers, because protobuffer data (and resulting code-gen) is simply too rigid to do anything interesting.
The result is that a thing that could have been 50 lines of recursion schemes was instead 10,000 lines of ad-hoc buffer-shuffling. The code I wanted to write was literally impossible when constrained by having protobuffers in the mix.
While this is an anecdote, itâ€™s not in isolation. By virtue of their rigid code-generation, manifestations of protobuffers in languages are never idiomatic, nor can they be made to beâ€”short of rewriting the code-generator.
But even then, you still have the problem of needing to embed a shitty type-system into the targeted language. Because most of protobuffersâ€™ features are ill-conceived, these unsavory properties leak into our codebases. It means weâ€™re forced to not only implement, but also use these bad ideas in any project which hopes to interface with protobuffers.
While itâ€™s easy to implement inane things out of a solid foundation, going the other direction is challenging at best and the dark path of Eldrich madness at worst.
In short, abandon all hope ye who introduce protobuffers into your projects.



To this day, thereâ€™s a raging debate inside Google itself about proto2 and whether fields should ever be marked as required. Manifestos with both titles â€œoptional considered harmfulâ€ and â€œrequired considered harmful.â€ Good luck sorting that out.â†©ï¸




    
        â†
    
    
        â†’
    


]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Purposeful animations]]></title>
            <link>https://emilkowal.ski/ui/you-dont-need-animations</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45139088</guid>
            <description><![CDATA[Why you are animating more often than you should.]]></description>
            <content:encoded><![CDATA[When done right, animations make an interface feel predictable, faster, and more enjoyable to use. They help you and your product stand out.
But they can also do the opposite. They can make an interface feel unpredictable, slow, and annoying. They can even make your users lose trust in your product.
So how do you know when and how to animate to improve the experience?
Step one is making sure your animations have a purpose.
Purposeful animations
Before you start animating, ask yourself: whatâ€™s the purpose of this animation? As an example, whatâ€™s the purpose of this marketing animation we built at Linear?

This animation explains how Product Intelligence (Linearâ€™s feature) works. We could have used a static asset, but the animated version helps the user understand what this feature does, straight in the initial viewport of the page.
Another purposeful animation is this subtle scale down effect when pressing a button. Itâ€™s a small thing, but it helps the interface feel more alive and responsive.

Sonnerâ€™s enter animation, on the other hand, has two purposes:

- Having a toast suddenly appear would feel off, so we animate it in.
- Because it comes from and leaves in the same direction, it creates spatial consistency, making the swipe-down-to-dismiss gesture feel more intuitive.


But sometimes the purpose of an animation might just be to bring delight.
Morphing of the feedback component below helps make the experience more unique and memorable. This works as long as the user will rarely interact with it. Itâ€™ll then become a pleasant surprise, rather than a daily annoyance.
Press on the button to see it morph.
Used multiple times a day, this component would quickly become irritating. The initial delight would fade and the animation would slow users down.
How often users will see an animation is a key factor in deciding whether to animate or not. Letâ€™s dive deeper into it next.
Frequency of use
I use Raycast hundreds of times a day. If it animated every time I opened it, it would be very annoying. But thereâ€™s no animation at all. Thatâ€™s the optimal experience.
To see it for yourself, try to toggle the open state of the menu below by using the buttons belowpressing J and then K. Which one feels better if used hundreds of times a day?
Command MenuLinearApplicationChatGPTApplicationCursorApplicationFigmaApplicationObsidianApplicationClipboard HistoryCommandEmoji PickerCommand
When I open Raycast, I have a clear goal in mind. I donâ€™t expect to be â€œdelightedâ€, I donâ€™t need to be. I just want to do my work with no unnecessary friction.
Think about what the user wants to achieve and how often they will see an animation. A hover effect is nice, but if used multiple times a day, it would likely benefit the most from having no animation at all.
Imagine you interact with this list often during the day.
Imagine you interact with this list often during the day.The same goes for keyboard-initiated actions. These actions may be repeated hundreds of times a day, an animation would make them feel slow, delayed, and disconnected from the userâ€™s actions. You should never animate them.
Since we canâ€™t really use a keyboard on touch devices, you can press the buttons below to see how it feels with and without animation.
To see it for yourself, focus on the input below and use arrow keys to navigate through the list. Notice how the highlight feels delayed compared to the keys you press. Now press  (shift) and see how this interaction feels without animation.Command MenuLinearApplicationChatGPTApplicationCursorApplicationFigmaApplicationObsidianApplicationClipboard HistoryCommandEmoji PickerCommandPress shift to toggle the animation
But even if your animation wonâ€™t be used too often and it fulfills a clear purpose, you still have to think about its speedâ€¦
Perception of speed
Unless you are working on marketing sites, your animations have to be fast. They improve the perceived performance of your app, stay connected to userâ€™s actions, and make the interface feel as if itâ€™s truly listening to the user.
To give you an example, a faster-spinning spinner makes the app seem to load faster, even though the load time is the same. This improves perceived performance.
Which one works harder to load the data?
A 180ms dropdown animation feels more responsive than a 400ms one:
Click on the buttons to compare the speed.
As a rule of thumb, UI animations should generally stay under 300ms.
Another example of the importance of speed: tooltips should have a slight delay before appearing to prevent accidental activation. Once a tooltip is open however, hovering over other tooltips should open them with no delay and no animation.
This feels faster without defeating the purpose of the initial delay.
Radix UI and Base UI skip the delay once a tooltip is shown.
Radix UI and Base UI skip the delay once a tooltip is shown.Building great interfaces
The goal is not to animate for animationâ€™s sake, itâ€™s to build great user interfaces. The ones that users will happily use, even on a daily basis. Sometimes this requires animations, but sometimes the best animation is no animation.
Knowing when to animate is just one of many things you need to know in order to craft great animations. If youâ€™d like to dive deeper into the theory and practice of it, Iâ€™ve created a course that covers everything you need to know:
Check out "Animations on the Web"]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I ditched Docker for Podman]]></title>
            <link>https://codesmash.dev/why-i-ditched-docker-for-podman-and-you-should-too</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45137525</guid>
        </item>
    </channel>
</rss>