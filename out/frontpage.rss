<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Wed, 10 Sep 2025 09:09:25 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[News: Arm announces next Generation core family called Arm Lumex]]></title>
            <link>https://www.phoronix.com/news/Arm-Lumex-Platform-C1</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45194341</guid>
            <description><![CDATA[Arm this evening lifted the lid on Lumex, their new compute subsystem platform that is purpose-built around AI for next-gen PCs and smartphones.]]></description>
            <content:encoded><![CDATA[

Arm this evening lifted the lid on Lumex, their new compute subsystem platform that is purpose-built around AI for next-gen PCs and smartphones.

The Arm Lumex platform combines their latest AArch64 CPUs complete with Scalable Matrix Extensions 2 (SME2), the latest GPU IP, and other system IP along with an optimized software stack for a very comprehensive AI-focused platform.

The Arm Lumexp latform features SME2-enabled Armv9.3 CPUs such as the C1 Ultra and C1 Pro, a new C1 Premium lower-tier offering, the new Mali G1-Ultra GPU, the DynamIQ Shared Unit DSU, and deep software integration.


The Arm C1 Ultra CPU aims for +25% single-threaded performance and double-digit IPC gains YoY while below that are the C1 Premium, C1 Pro, and C1 Nano.

A big focus on the media presentation in advance was the guarantee that Arm Lumex will have Scalable Matrix Extensions 2 support widespread. About time seeing more SME hardware in the while and in turn will also help with increased software adoption. Just as AVX-512 and even AMX have proven very useful in the x86_64 ecosystem for AI workloads.



Those are the main Arm Lumex highlights for now. It will be much more interesting once having new Arm hardware in the lab for Linux testing and benchmarking.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Crimson (YC X25) is hiring founding engineers in London]]></title>
            <link>https://www.ycombinator.com/companies/crimson/jobs/kCikzj1-founding-engineer-full-stack</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45194223</guid>
            <description><![CDATA[Crimson is the AI platform for high-stakes litigation. We're working with top law firms in the UK and US to streamline how complex disputes are run. Our platform drafts pleadings and submissions, analyzes judgments and orders, summarizes transcripts and locates key evidence in seconds.
We're a team of three co-founders with deep technical and domain expertise. Our users are lawyers who trust us with their most sensitive case files. They care about security, accuracy, reliability and speed, and so do we.
We're looking for an exceptional full-stack engineer to join us as one of our first employees. You'll ship production code from day one and own major features end-to-end. That means talking to users, scoping the problem, building the solution and improving it over time.
What you'll do
Contribute to the entire stack, from cloud infrastructure to prompting to UX (Python backend, Next.js with TypeScript frontend, PostgreSQL, SOTA LLMs. Deployed to Azure via IaC (Bicep) with CI/CD pipelines powered by GitHub Actions)
Collaborate closely with users to understand how lawyers work and what they need
Architect and scale document ingestion and processing pipelines to power fast, accurate search and data extraction for large volumes of legal documents
Develop intelligent, multi-step agent workflows that can autonomously handle complex legal tasks - from surfacing key testimony across depositions to generating fact chronologies and auto-detecting inconsistencies in opposing counsel’s filings
Design and bring to life intuitive AI-native user experiences tailored to litigation workflows
Improve system performance, stability and observability as we scale
Help shape our engineering culture and team - from best practices to hiring and mentorship
This is for you if …
You’re driven, self-directed and exceptionally capable
You’re obsessed with building outstanding products for demanding users
You’re excited to work on hard problems, take ownership and push things through
You have high agency and a bias for shipping
You have excellent product judgement, communication skills and attention to detail
Bonus points if you have an interest in legal tech
Why join us
Over the next few years, the legal industry will change beyond recognition. You’ll be at the heart of that change, helping us build a category-defining company
We’re backed by YC and other top investors
We’re working with major UK and US law firms
You’ll get ownership, equity and the opportunity to shape the business and lead engineering teams
Details
Location: London/hybrid
Salary: £70-100k
Meaningful equity
Contact: tell us about things you’ve built by emailing founders [at] crimson [dot] law. We’ll get back to you within 24h.]]></description>
            <content:encoded><![CDATA[The AI Associate for Litigation LawyersFounding Engineer (Full Stack)£70K - £100K GBP•0.50% - 1.00%•London, England, GBJob typeFull-timeRoleEngineering, Full stackExperience3+ yearsVisaUS citizenship/visa not requiredSkillsNext.js, Python, TypeScriptConnect directly with founders of the best YC-funded startups.Apply to role ›About the roleCrimson is the AI platform for high-stakes litigation. We're working with top law firms in the UK and US to streamline how complex disputes are run. Our platform drafts pleadings and submissions, analyzes judgments and orders, summarizes transcripts and locates key evidence in seconds.
We're a team of three co-founders with deep technical and domain expertise. Our users are lawyers who trust us with their most sensitive case files. They care about security, accuracy, reliability and speed, and so do we.
We're looking for an exceptional full-stack engineer to join us as one of our first employees. You'll ship production code from day one and own major features end-to-end. That means talking to users, scoping the problem, building the solution and improving it over time.
What you'll do

Contribute to the entire stack, from cloud infrastructure to prompting to UX (Python backend, Next.js with TypeScript frontend, PostgreSQL, SOTA LLMs. Deployed to Azure via IaC (Bicep) with CI/CD pipelines powered by GitHub Actions)
Collaborate closely with users to understand how lawyers work and what they need
Architect and scale document ingestion and processing pipelines to power fast, accurate search and data extraction for large volumes of legal documents
Develop intelligent, multi-step agent workflows that can autonomously handle complex legal tasks - from surfacing key testimony across depositions to generating fact chronologies and auto-detecting inconsistencies in opposing counsel’s filings
Design and bring to life intuitive AI-native user experiences tailored to litigation workflows
Improve system performance, stability and observability as we scale
Help shape our engineering culture and team - from best practices to hiring and mentorship

This is for you if …

You’re driven, self-directed and exceptionally capable
You’re obsessed with building outstanding products for demanding users
You’re excited to work on hard problems, take ownership and push things through
You have high agency and a bias for shipping
You have excellent product judgement, communication skills and attention to detail
Bonus points if you have an interest in legal tech

Why join us

Over the next few years, the legal industry will change beyond recognition. You’ll be at the heart of that change, helping us build a category-defining company
We’re backed by YC and other top investors
We’re working with major UK and US law firms
You’ll get ownership, equity and the opportunity to shape the business and lead engineering teams

Details

Location: London/hybrid
Salary: £70-100k
Meaningful equity
Contact: tell us about things you’ve built by emailing founders [at] crimson [dot] law. We’ll get back to you within 24h.

About the interviewDetailed information about the interview process will be provided after the first interview.About CrimsonFounded:2025Batch:X25Team Size:3Status:ActiveFoundersSimilar Jobs]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A security incident that may involve your Plex account information]]></title>
            <link>https://forums.plex.tv/t/important-notice-of-security-incident/930523</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45194218</guid>
        </item>
        <item>
            <title><![CDATA[I replaced Animal Crossing's dialogue with a live LLM by hacking GameCube memory]]></title>
            <link>https://joshfonseca.com/blogs/animal-crossing-llm</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45192655</guid>
            <description><![CDATA[How I replaced Animal Crossing's dialogue with a live LLM by bridging GameCube memory to a cloud AI, with no game code changes required.]]></description>
            <content:encoded><![CDATA[
		
			
			A bridge from 2001 to today, with no game code changes required.
		

		
			
			Cookie: "Oh my gosh, Josh :)! I just had the weirdest dream, like, everything we do is a game! Arfer!"
		

		
			Animal Crossing. Infamous for its charming but ultimately repetitive dialogue. Having picked up the GameCube classic again, I was shocked (/s) to discover that the villagers still say the same things they did 23 years ago. Let's change that.
		
		
			The problem? The game runs on a Nintendo GameCube, a 24-year-old console with a 485 MHz PowerPC processor, 24MB of RAM, and absolutely no internet connectivity. It was fundamentally, physically, and philosophically designed to be an offline island.
		
		
			This is the story of how I built a bridge from 2001 to today, making a vintage game console talk to a cloud-based AI without modifying a single line of the original game's code.
		

		The First Hurdle: Speaking to the Game 🗣️
		
			My first stroke of luck was immense. The week I started this project, a massive effort by the Animal Crossing decompilation community reached completion. Instead of staring at PowerPC assembly, I had access to readable C code.
		
		
			Digging through the source, I quickly found the relevant functions under a file named m_message.c. This was it, the heart of the dialogue system. A simple test confirmed I could hijack the function call and replace the in-game text with my own string.
		

		C: A glimpse into the decompiled dialogue system
		// A glimpse into the decompiled Animal Crossing source code
// The function that changes message data in the dialogue system.
// My initial entry point for hijacking the text.

extern int mMsg_ChangeMsgData(mMsg_Window_c* msg_p, int index) {
    if (index >= 0 && index < MSG_MAX && mMsg_LoadMsgData(msg_p->msg_data, index, FALSE)) {
        msg_p->end_text_cursor_idx = 0;
        mMsg_Clear_CursolIndex(msg_p);
        mMsg_SetTimer(msg_p, 20.0f);
        return TRUE;
    }
    
    return FALSE;
}


		
			Easy win, right? But changing static text is one thing. How could I get data from an external AI into the game in real time?
		
		
			My first thought was to just add a network call. But that would mean writing an entire network stack for the GameCube from scratch (TCP/IP, sockets, HTTP) and integrating it into a game engine that was never designed for it. That was a non-starter.
		
		
			My second thought was to use the Dolphin emulator's features to write to a file on my host machine. The game would write a "request" file with context, and my Python script would see it, call the LLM, and write back a "response" file. Unfortunately, I couldn't get the sandboxed GameCube environment to access the host filesystem. Another dead end.
		

		The Breakthrough: The Memory Mailbox 📬
		
			The solution came from a classic technique in game modding: Inter-Process Communication (IPC) via shared memory. The idea is to allocate a specific chunk of the GameCube's RAM to act as a "mailbox." My external Python script can write data directly into that memory address, and the game can read from it.
		

		
			
				graph TD
					A[Python Script] -- "Writes LLM response" --> B{Memory Mailbox @ 0x81298360}
					B -- "Game reads new dialogue" --> C[Animal Crossing on Dolphin Emulator]
					C -- "Writes current speaker & context" --> B
			
		

		Python: The core of the "Memory Mailbox" interface
		# This is the bridge. These functions read from and write to GameCube RAM via Dolphin.
GAMECUBE_MEMORY_BASE = 0x80000000

def read_from_game(gc_address: int, size: int) -> bytes:
    """Reads a block of memory from a GameCube virtual address."""
    real_address = GAMECUBE_MEMORY_BASE + (gc_address - 0x80000000)
    return dolphin_process.read(real_address, size)

def write_to_game(gc_address: int, data: bytes) -> bool:
    """Writes a block of data to a GameCube virtual address."""
    real_address = GAMECUBE_MEMORY_BASE + (gc_address - 0x80000000)
    return dolphin_process.write(real_address, data)


		
			This was the path forward. But it created a new, painstaking task: I had to become a memory archaeologist. I needed to find the exact stable memory addresses for the active dialogue text and the current speaker's name.
		
		
			To do this, I wrote my own memory scanner in Python. The process was a tedious loop:
		
		
			Talk to a villager. The moment their dialogue box appeared, I'd freeze the emulator.
			Scan. I'd run my script to scan all 24 million bytes of the GameCube's RAM for the string of text on screen (e.g., "Hey, how's it going?").
			Cross-Reference. This often returned multiple addresses. So, I'd unfreeze, talk to a different villager, and scan for their name to figure out which memory block belonged to the active speaker.
		
		
			After hours of talking, freezing, and scanning, I finally nailed down the key addresses: 0x8129A3EA for the speaker's name and 0x81298360 for the dialogue buffer. I could now reliably read who was talking and, more importantly, write data back to the dialogue box.
		

		What About the GameCube Broadband Adapter? 🌐
		
			Yes, the GameCube had an official Broadband Adapter (BBA). But Animal Crossing shipped without networking primitives, sockets, or any game-layer protocol to use it. Using the BBA here would have required building a tiny networking stack and patching the game to call it. That means: hooking engine callsites, scheduling async I/O, and handling retries/timeouts, all inside a codebase that never expected the network to exist.
		
		
			Engine hooks: Hijack safe points in the message loop to send/receive packets.
			Driver/protocol: Provide a minimal UDP/RPC interface over BBA.
			Robustness: Handle timeouts, retries, and partial reads without stalling animations/UI.
		
		
			
				graph LR
					subgraph Option A: BBA Network Shim
						AC[Animal Crossing] --> Hooks[Net Shim Hooks]
						Hooks --> BBA[BBA Driver]
						BBA --> LAN[(LAN)]
						LAN --> Host[Host Bridge Server]
					end
					subgraph Option B: RAM Mailbox
						AC2[Animal Crossing] --> Mailbox[RAM Mailbox]
						Mailbox --> Py[Python Watcher]
						Py --> LLM[LLM]
					end
			
		
		
			I chose the RAM mailbox because it's deterministic, requires zero kernel/driver work, and stays entirely within the emulator boundary, with no binary network stack needed. That said, a BBA shim is absolutely possible (and a fun future project for real hardware via Swiss + homebrew).
		

		C: Minimal RPC envelope for a hypothetical BBA shim
		#include <stdint.h>

/* Minimal RPC envelope for a hypothetical BBA shim */
typedef struct {
    uint32_t magic;    // 'ACRP'
    uint16_t type;     // 1=Request, 2=Response
    uint16_t length;   // payload length
    uint8_t  payload[512];
} RpcMsg;

int ac_net_send(const RpcMsg* msg);         // sends via BBA
int ac_net_recv(RpcMsg* out, int timeoutMs); // polls with timeout


		Python: Host-side UDP bridge (very simplified)
		import socket, json
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.bind(("0.0.0.0", 19135))
while True:
    data, addr = sock.recvfrom(2048)
    msg = json.loads(data.decode("utf-8", "ignore"))
    # ... call Writer/Director LLMs ...
    reply = json.dumps({"ok": True, "text": "Hi from the cloud!"}).encode()
    sock.sendto(reply, addr)


		Speaking the Game's Secret Language 🤫
		
			I eagerly tried writing "Hello World" to the dialogue address and... the game froze. The character animations kept playing, but the dialogue wouldn't advance. I was so close, yet so far.
		
		
			The problem was that I was sending plain text. Animal Crossing doesn't speak plain text. It speaks its own encoded language filled with control codes.
		
		
			Think of it like HTML. Your browser doesn't just display words; it interprets tags like <b> to make text bold. Animal Crossing does the same. A special prefix byte, CHAR_CONTROL_CODE, tells the game engine, "The next byte isn't a character, it's a command!"
		
		
			These commands control everything: text color, pauses, sound effects, character emotions, and even the end of a conversation. If you don't send the <End Conversation> control code, the game simply waits forever for a command that never comes. That's why it was freezing.
		
		
			Once again, the decompilation community saved me. They had already documented most of these codes. I just needed to build the tools to use them.
		
		
			I wrote an encoder and a decoder in Python. The decoder could read raw game memory and translate it into a human-readable format, and the encoder could take my text with custom tags and convert it back into the exact sequence of bytes the GameCube understood.
		
		Python: A small sample of the control codes I had to encode/decode
		# A small sample of the control codes I had to encode/decode
CONTROL_CODES = {
    0x00: "<End Conversation>",
    0x03: "<Pause [{:02X}]>",        # e.g., <Pause [0A]> for a short pause
    0x05: "<Color Line [{:06X}]>",  # e.g., <Color Line [FF0000]> for red
    0x09: "<NPC Expression [Cat:{:02X}] [{}]>", # Trigger an emotion
    0x59: "<Play Sound Effect [{}]>",  # e.g., <Play Sound Effect [Happy]>
    0x1A: "<Player Name>",
    0x1C: "<Catchphrase>",
}

# The magic byte that signals a command is coming
PREFIX_BYTE = 0x7F


		
			With my new encoder, I tried again. This time, I wasn't just sending text. I was speaking the game's language. And it worked. The hardest part of the hack was done.
		

		Building the AI Brain 🧠
		
			With the communication channel established, it was time for the fun part: building the AI.
		
		
			My initial approach was to have a single LLM do everything: write dialogue, stay in character, and insert the technical control codes. The results were a mess. The AI was trying to be a creative writer and a technical programmer simultaneously and was bad at both.
		
		
			The solution was to split the task into a two-model pipeline: a Writer and a Director.
		
		
			The Writer AI: This model's only job is to be creative. It receives a detailed character sheet (which I generated by scraping the Animal Crossing Fan Wiki) and focuses on writing dialogue that is funny, in-character, and relevant to the context.
			The Director AI: This model receives the pure text from the Writer. Its job is purely technical. It reads the dialogue and decides how to "shoot the scene." It adds pauses for dramatic effect, emphasizes words with color, and chooses the perfect facial expression or sound effect to match the mood.
		
		
			This separation of concerns worked perfectly.
		

		
			
				graph LR
					subgraph Game World
						Dolphin(Dolphin Emulator)
					end

					subgraph Python Bridge
						Watcher(watch_dialogue.py)
						Encoder(Encoder/Decoder)
					end

					subgraph AI Core
						Writer(Writer LLM)
						Director(Director LLM)
					end

					subgraph External Data
						Wiki(Fan Wiki)
						News(RSS Feeds)
					end

					Dolphin <--> |IPC via RAM| Watcher
					Watcher --> |Context| Writer
					Wiki --> |Character Sheets| Writer
					News --> |Current Events| Writer

					Writer --> |Raw Dialogue| Director
					Director --> |Decorated Dialogue| Encoder
					Encoder --> |Encoded Bytes| Watcher
			
		

		Emergent Behavior 🤪
		
			First I piped in a lightweight news feed. Within minutes, villagers began weaving headlines into small talk, no prompts, just context.
		

		
			
			Mitzi: "About the news? European leaders are planning to meet with Trump and Zelenskyy!"
		

		
			Then I gave them a tiny shared memory for gossip, who said what, to whom, and how they felt. Predictably, it escalated into an anti-Tom Nook movement.
		

		
			
			Cookie: "Everything's going great in town, but sometimes I feel like Tom Nook is, like, taking all the bells!"
		

		
			And I was reminded that I used Fox News as the news feed.
		

		
			
			Cookie: "A woman was killed in a robbery in a blue city!"
		

		
			Now the game is a strange, hilarious, and slightly unsettling :)
		
		
			All the code for this project, including the memory interface, dialogue encoder, and AI prompting logic, is available on GitHub. It was one of the most challenging and rewarding projects I've ever tackled, blending reverse engineering, AI, and a deep love for a classic game.
			Watch the full video: Modern AI in a 24-Year-Old Game
	]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[R-Zero: Self-Evolving Reasoning LLM from Zero Data]]></title>
            <link>https://arxiv.org/abs/2508.05004</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45192194</guid>
            <description><![CDATA[Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.]]></description>
            <content:encoded><![CDATA[
    
    
                
    View PDF
    HTML (experimental)
            Abstract:Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.
    

    
    
      
          Subjects:
          
            Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
        
          Cite as:
          arXiv:2508.05004 [cs.LG]
        
        
           
          (or 
              arXiv:2508.05004v2 [cs.LG] for this version)
          
        
        
           
                        https://doi.org/10.48550/arXiv.2508.05004
              
                                arXiv-issued DOI via DataCite
            
          
        
    
  
      Submission history From: Chengsong Huang [view email]                  [v1]
        Thu, 7 Aug 2025 03:38:16 UTC (665 KB)
    [v2]
        Wed, 27 Aug 2025 02:33:55 UTC (10,672 KB)
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NASA finds Titan's lakes may be creating vesicles with primitive cell walls]]></title>
            <link>https://www.sciencedaily.com/releases/2025/08/250831112449.htm</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45191347</guid>
            <description><![CDATA[Saturn’s moon Titan may be more alive with possibilities than we thought. New NASA research suggests that in Titan’s freezing methane and ethane lakes, simple molecules could naturally arrange themselves into vesicles—tiny bubble-like structures that mimic the first steps toward life. These compartments, born from splashing droplets and complex chemistry in Titan’s atmosphere, could act like primitive cell walls.]]></description>
            <content:encoded><![CDATA[NASA research has shown that cell-like compartments called vesicles could form naturally in the lakes of Saturn's moon Titan.
Titan is the only world apart from Earth that is known to have liquid on its surface. However, Titan's lakes and seas are not filled with water. Instead, they contain liquid hydrocarbons like ethane and methane.
On Earth, liquid water is thought to have been essential for the origin of life as we know it. Many astrobiologists have wondered whether Titan's liquids could also provide an environment for the formation of the molecules required for life - either as we know it or perhaps as we don't know it - to take hold there.
New NASA research, published in the International Journal of Astrobiology, outlines a process by which stable vesicles might form on Titan, based on our current knowledge of the moon's atmosphere and chemistry. The formation of such compartments is an important step in making the precursors of living cells (or protocells).
The process involves molecules called amphiphiles, which can self-organize into vesicles under the right conditions. On Earth, these polar molecules have two parts, a hydrophobic (water-fearing) end and a hydrophilic (water-loving) end. When they are in water, groups of these molecules can bunch together and form ball-like spheres, like soap bubbles, where the hydrophilic part of the molecule faces outward to interact with the water, thereby 'protecting' the hydrophobic part on the inside of the sphere. Under the right conditions, two layers can form creating a cell-like ball with a bilayer membrane that encapsulates a pocket of water on the inside.
When considering vesicle formation on Titan, however, the researchers had to take into account an environment vastly different from the early Earth.
Uncovering Conditions on Titan 
Titan is Saturn's largest moon and the second largest in our solar system. Titan is also the only moon in our solar system with a substantial atmosphere.


The hazy, golden atmosphere of Titan kept the moon shrouded in mystery for much of human history. However, when NASA's Cassini spacecraft arrived at Saturn in 2004, our views of Titan changed forever.
Thanks to Cassini, we now know Titan has a complex meteorological cycle that actively influences the surface today. Most of Titan's atmosphere is nitrogen, but there is also a significant amount of methane (CH4). This methane forms clouds and rain, which falls to the surface to cause erosion and river channels, filling up the lakes and seas. This liquid then evaporates in sunlight to form clouds once again.
This atmospheric activity also allows for complex chemistry to happen. Energy from the Sun breaks apart molecules like methane, and the pieces then reform into complex organic molecules. Many astrobiologists believe that this chemistry could teach us how the molecules necessary for the origin of life formed and evolved on the early Earth.
Building Vesicles on Titan 
The new study considered how vesicles might form in the freezing conditions of Titan's hydrocarbon lakes and seas by focusing on sea-spray droplets, thrown upwards by splashing raindrops. On Titan, both spray droplets and the sea surface could be coated in layers of amphiphiles. If a droplet then lands on the surface of a pond, the two layers of amphiphiles meet to form a double-layered (or bilayer) vesicle, enclosing the original droplet. Over time, many of these vesicles would be dispersed throughout the pond and would interact and compete in an evolutionary process that could lead to primitive protocells.
If the proposed pathway is happening, it would increase our understanding of the conditions in which life might be able to form.
"The existence of any vesicles on Titan would demonstrate an increase in order and complexity, which are conditions necessary for the origin of life," explains Conor Nixon of NASA's Goddard Space Flight Center in Greenbelt, Maryland. "We're excited about these new ideas because they can open up new directions in Titan research and may change how we search for life on Titan in the future."
NASA's first mission to Titan is the upcoming Dragonfly rotorcraft, which will explore the surface of the Saturnian moon. While Titan's lakes and seas are not a destination for Dragonfly (and the mission won't carry the light-scattering instrument required to detect such vesicles), the mission will fly from location to location to study the moon's surface composition, make atmospheric and geophysical measurements, and characterize the habitability of Titan's environment.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hypervisor in 1k Lines]]></title>
            <link>https://1000hv.seiya.me/en</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45190777</guid>
            <description><![CDATA[Write your first hypervisor from scratch, in 1K LoC.]]></description>
            <content:encoded><![CDATA[WARNINGThis book is work in progress.Hey there (maybe again)! In this book, you'll learn how to build a minimal RISC-V hypervisor which can boot Linux-based operating systems.This is a sequel to the online book Operating System in 1,000 Lines. In that book, you have learned how to build a minimal operating system from scratch in C, but this time, we'll start from scratch (again) in your favorite language, Rust!From scratch means we'll start from the bare-metal programming in Rust, that is type-1 hypervisor, in 1000 lines of code like we did for the OS.However, this time we'll cheat a little bit, by relying on the power of Rust's ecosystem: third-party libraries ("crates") to avoid implementing things that don't really matter for learning hypervisors.You can download the implementation examples from GitHub.This book is available under the CC BY 4.0 license. The implementation examples and source code in the text are under the MIT license.Happy hypervisor hacking!]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Immunotherapy drug clinical trial results: half of tumors shrink or disappear]]></title>
            <link>https://www.rockefeller.edu/news/38120-immunotherapy-drug-eliminates-aggressive-cancers-in-clinical-trial/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45188945</guid>
            <description><![CDATA[The researchers demonstrate that an engineered antibody improves a class of drugs that has struggled to make good on its early promise.]]></description>
            <content:encoded><![CDATA[
    
Histology image of a patient whose metastatic cancer went into complete remission after receiving a new immunotherapy treatment (Ravetch lab)

Over the past 20 years, a class of cancer drugs called CD40 agonist antibodies have shown great promise—and induced great disappointment. While effective at activating the immune system to kill cancer cells in animal models, the drugs had limited impact on patients in clinical trials and caused dangerously systemic inflammatory responses, low platelet counts, and liver toxicity, among other adverse reactions—even at a low dose.
But in 2018, the lab of Rockefeller University’s Jeffrey V. Ravetch demonstrated it could engineer an enhanced CD40 agonist antibody so that it improved its efficacy and could be administered in a manner to limit serious side effects. The findings came from research on mice, genetically engineered to mimic the pathways relevant in humans. The next step was to have a clinical trial to see the drug’s impact on cancer patients.
Now the results from the phase 1 clinical trial of the drug, dubbed 2141-V11, have been published in Cancer Cell. Of 12 patients, six patients saw their tumors shrink, including two who saw them disappear completely.
“Seeing these significant shrinkages and even complete remission in such a small subset of patients is quite remarkable,” says first author Juan Osorio, a visiting assistant professor in Ravetch’s Leonard Wagner Laboratory of Molecular Genetics and Immunology and a medical oncologist at Memorial Sloan Kettering Cancer Center.
Notably, the effect wasn’t limited to tumors that were injected with the drug; tumors elsewhere in the body either got smaller or were destroyed by immune cells.
“This effect—where you inject locally but see a systemic response—that’s not something seen very often in any clinical treatment,” Ravetch notes. “It’s another very dramatic and unexpected result from our trial.”
Engineering enhancements
CD40 is a cell surface receptor and member of the tumor necrosis factor (TNF) receptor superfamily, proteins that are largely expressed by immune cells. When triggered, CD40 prompts the rest of immune system to spring into action, promoting antitumor immunity and developing tumor-specific T cell responses.
In 2018, Ravetch’s lab—which has been supported in this line of research by Rockefeller’s Therapeutic Development Fund, founded by trustee Julian Robertson and continued by the Black Family Foundation—engineered 2141-V11, a CD40 antibody that binds tightly to human CD40 receptors and is modified to enhance its crosslinking by also engaging a specific Fc receptor. It proved to be 10 times more powerful in its capacity to elicit an antitumor immune response.
They then changed how they administered the drug. The long-time approach had been to give it intravenously. But CD40 receptors are widespread, so too many non-cancerous cells pick it up, leading to the well-known toxic side effects. Instead, they injected the drug directly into tumors.
“When we did that, we saw only mild toxicity,” Ravetch says.
Those findings became the basis of the phase 1 clinical trial described in the current study, which aimed to determine a starting clinical dose of the drug and better understand the mechanisms underlying its effectiveness.
Inducing remission
The trial included 12 patients representing myriad metastatic cancer types: melanoma, renal cell carcinoma, and different types of breast cancer. Of those 12, none suffered the serious side effects seen with other CD40 drugs. Six experienced systemic tumor reduction, of which two had a complete response—meaning their cancer disappeared entirely.
The two patients who experienced complete remission had melanoma and breast cancer, respectively—both notoriously aggressive and recurring.
“The melanoma patient had dozens of metastatic tumors on her leg and foot, and we injected just one tumor up on her thigh,” Ravetch says. “After multiple injections of that one tumor, all the other tumors disappeared. The same thing happened in the patient with metastatic breast cancer, who also had tumors in her skin, liver, and lung. And even though we only injected the skin tumor, we saw all the tumors disappear.”
Tissue samples from the tumor sites revealed the immune activity that the drug stimulated. “We were quite surprised to see that the tumors became full of immune cells—including different types of dendritic cells, T cells, and mature B cells—that formed aggregates resembling something like a lymph node,” Osorio says. “The drug creates an immune microenvironment within the tumor, and essentially replaces the tumor with these tertiary lymphoid structures.”
The presence of tertiary lymphoid structures (TLS) is associated with improved prognosis and response to immunotherapy, Osorio notes.
They also found TLS in the tumors they didn’t inject. “Once the immune system identifies the cancer cells, immune cells migrate to the non-injected tumor sites,” he says.
Improving immunotherapy
The findings have sparked a number of other clinical trials that the Ravetch lab is currently collaborating on with researchers at Memorial Sloan Kettering and Duke University. Now in either phase 1 or phase 2 study, the trials are investigating 2141-V11’s effect on specific cancers, including bladder cancer, prostate cancer, and glioblastoma—all aggressive and hard to treat. Collectively, nearly 200 people are enrolled in the studies.
These studies will help to illuminate why some patients respond to 2141-V11 and others do not—and how to potentially change that.
For example, the two patients in the clinical trial whose cancer disappeared both had a high clonality of T cells—key cancer-cell killers—when they began the study. “This suggests there are some requirements from the immune system in order for this drug to work, and we’re in the process of dissecting these characteristics in more granular detail in these larger studies.”
“As a general rule, only 25 to 30% of patients will respond to immunotherapy, so the biggest challenge in the field is to try to determine which patients will benefit from it. What are the indicators or predictors of response? And how can we convert non-responders into responders?”

  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Memory Integrity Enforcement]]></title>
            <link>https://security.apple.com/blog/memory-integrity-enforcement/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186265</guid>
            <description><![CDATA[Memory Integrity Enforcement (MIE) is the culmination of an unprecedented design and engineering effort spanning half a decade that combines the unique strengths of Apple silicon hardware with our advanced operating system security to provide industry-first, always-on memory safety protection across our devices — without compromising our best-in-class device performance. We believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.]]></description>
            <content:encoded><![CDATA[Memory Integrity Enforcement (MIE) is the culmination of an unprecedented design and engineering effort, spanning half a decade, that combines the unique strengths of Apple silicon hardware with our advanced operating system security to provide industry-first, always-on memory safety protection across our devices — without compromising our best-in-class device performance. We believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.

There has never been a successful, widespread malware attack against iPhone. The only system-level iOS attacks we observe in the wild come from mercenary spyware, which is vastly more complex than regular cybercriminal activity and consumer malware. Mercenary spyware is historically associated with state actors and uses exploit chains that cost millions of dollars to target a very small number of specific individuals and their devices. Although the vast majority of users will never be targeted in this way, these exploit chains demonstrate some of the most expensive, complex, and advanced attacker capabilities at any given time and are uniquely deserving of study as we work to protect iPhone users against even the most sophisticated threats. Known mercenary spyware chains used against iOS share a common denominator with those targeting Windows and Android: they exploit memory safety vulnerabilities, which are interchangeable, powerful, and exist throughout the industry.
For Apple, improving memory safety is a broad effort that includes developing with safe languages and deploying mitigations at scale. (For a primer on how we think about memory safety, see the opening of this post.) We created Swift, an easy-to-use, memory-safe language, which we employ for new code and targeted component rewrites. In iOS 15, we introduced kalloc_type, a secure memory allocator for the kernel, followed in iOS 17 by its user-level counterpart, xzone malloc. These secure allocators take advantage of knowing the type — or purpose — of allocations so that memory can be organized in a way that makes exploiting most memory corruption vulnerabilities inherently difficult.
In 2018, we were the first in the industry to deploy Pointer Authentication Codes (PAC) in the A12 Bionic chip, to protect code flow integrity in the presence of memory corruption. The strong success of this defensive mechanism in increasing exploitation complexity left no doubt that the deep integration of software and hardware security would be key to addressing some of our greatest security challenges. With PAC behind us, we immediately began design and evaluation work to find the most effective way to build sophisticated memory safety capabilities right into Apple silicon.
Arm published the Memory Tagging Extension (MTE) specification in 2019 as a tool for hardware to help find memory corruption bugs. MTE is, at its core, a memory tagging and tag-checking system, where every memory allocation is tagged with a secret; the hardware guarantees that later requests to access memory are granted only if the request contains the correct secret. If the secrets don’t match, the app crashes, and the event is logged. This allows developers to identify memory corruption bugs immediately as they occur.
We conducted a deep evaluation and research process to determine whether MTE, as designed, would meet our goals for hardware-assisted memory safety. Our analysis found that, when employed as a real-time defensive measure, the original Arm MTE release exhibited weaknesses that were unacceptable to us, and we worked with Arm to address these shortcomings in the new Enhanced Memory Tagging Extension (EMTE) specification, released in 2022. More importantly, our analysis showed that while EMTE had great potential as specified, a rigorous implementation with deep hardware and operating system support could be a breakthrough that produces an extraordinary new security mechanism.
Consider that MTE can be configured to report memory corruption either synchronously or asynchronously. In the latter mode, memory corruption doesn’t immediately raise an exception, leaving a race window open for attackers. We would not implement such a mechanism. We believe memory safety protections need to be strictly synchronous, on by default, and working continuously. But supporting always-on, synchronous MTE across key attack surfaces while preserving a great, high-performance user experience is extremely demanding for hardware to support.
In addition, for MTE to provide memory safety in an adversarial context, we would need to finely tune the operating system to defend the new semantics and the confidentiality of memory tags on which MTE relies. Ultimately, we determined that to deliver truly best-in-class memory safety, we would carry out a massive engineering effort spanning all of Apple — including updates to Apple silicon, our operating systems, and our software frameworks. This effort, together with our highly successful secure memory allocator work, would transform MTE from a helpful debugging tool into a groundbreaking new security feature.
Today we’re introducing the culmination of this effort: Memory Integrity Enforcement (MIE), our comprehensive memory safety defense for Apple platforms. Memory Integrity Enforcement is built on the robust foundation provided by our secure memory allocators, coupled with Enhanced Memory Tagging Extension (EMTE) in synchronous mode, and supported by extensive Tag Confidentiality Enforcement policies. MIE is built right into Apple hardware and software in all models of iPhone 17 and iPhone Air and offers unparalleled, always-on memory safety protection for our key attack surfaces including the kernel, while maintaining the power and performance that users expect. In addition, we’re making EMTE available to all Apple developers in Xcode as part of the new Enhanced Security feature that we released earlier this year during WWDC.
The rest of this post dives into the intensive engineering effort required to design and validate Memory Integrity Enforcement.
Designing Memory Integrity Enforcement
Memory Integrity Enforcement starts with our secure memory allocators — kalloc_type, xzone malloc, and WebKit’s libpas — all of which use type information to decide how to organize memory allocations. With both use-after-free and out-of-bounds bugs, an attacker’s goal is to create overlapping interpretations of memory, which they achieve by controlling the precise position of certain allocations — of a specific type — that is advantageous to them. The type-aware placement policies of our secure memory allocators help thwart these memory corruption techniques, as we described in our kalloc_type post. Our secure allocators set a new high-water mark of software protection against memory corruption, while preserving the same or better performance as the allocators they replaced.
Allocators can apply protections only at the granularity of memory pages — 16KB on iOS — which is a natural fit for multi-page allocations. For smaller allocations, our secure allocators can use page-level protections to help prevent memory corruption attacks across different type buckets. However, page-level protections are too coarse to defend against attacks within the same type bucket, and we use memory tagging to close this gap.
Let’s look at how EMTE can be used to protect against two of the most common types of memory corruption: buffer overflows and use-after-free vulnerabilities. For buffer overflows, the allocator is responsible for using different tags for neighboring allocations. If a request to access memory spills over to adjacent memory that has a different tag, the hardware blocks it, and the operating system can take action and terminate the process. We represent this visually below with three adjacent allocations, tagged with three different secrets: ⏺️, 🔼, and ⏹️. Two access attempts with the 🔼 tag are permitted to 🔼-tagged memory, but the third attempt is blocked as it spills over into the adjacent, ⏹️-tagged allocation.
 Memory Integrity Enforcement blocks buffer overflows 

The allocator is also responsible for retagging memory as it gets reused for other purposes. In the image below, the 🔼 allocation is retagged as ⏹️ after it has been freed and reallocated by the system. If a request to the retagged memory is made with the older 🔼 tag, as would be seen in use-after-free exploits, the hardware blocks it and lets the operating system take further action.
 Memory Integrity Enforcement blocks use-after-free access

A key weakness of the original MTE specification is that access to non-tagged memory, such as global variables, is not checked by the hardware. This means attackers don’t have to face as many defensive constraints when attempting to control core application configuration and state. With Enhanced MTE, we instead specify that accessing non-tagged memory from a tagged memory region requires knowing that region’s tag, making it significantly harder for attackers to turn out-of-bounds bugs in dynamic tagged memory into a way to sidestep EMTE by directly modifying non-tagged allocations.
Finally, we developed Tag Confidentiality Enforcement to protect the implementation of our secure allocators from technical threats and to guard the confidentiality of EMTE tags — including against side-channel and speculative-execution attacks.
Our typed allocators and EMTE both rely on confidentiality of kernel data structures from user applications, and of the tags chosen by the allocator. Attackers might attempt to defeat EMTE, and in turn Memory Integrity Enforcement, by revealing these secrets. To protect the kernel allocator backing store and tag storage, we use the Secure Page Table Monitor, which provides strong guarantees even in the presence of a kernel compromise. We also ensure that when the kernel accesses memory on behalf of an application, it's subject to the same tag-checking rules as userspace.
Attacks based on speculative execution can also be used to expose secrets. To improve performance, modern CPUs predict the execution of instructions that follow prior, potentially longer latency instructions. If the prediction is correct, computation is very fast. If it’s wrong, the CPU discards the prediction, and computation is slower. Unfortunately, discarded predictions have observable effects that can reveal system state and data, and because speculative attacks never cause the system to crash or misbehave in observable ways during their use, they’re particularly useful for an attacker. For example, evaluating a pointer authentication instruction speculatively exposed timing differences in our original implementation of Pointer Authentication Codes (PAC), which would allow the valid signature to be isolated. During the design phase for Memory Integrity Enforcement, we identified and addressed the three speculative vulnerabilities that could undermine tag confidentiality.
First, when EMTE is active, requests to access memory cause the hardware to check tags. It's crucial that evaluating a tag-checking instruction speculatively doesn’t expose timing differences that would allow an attacker to isolate the valid tag. From the start, we designed the Apple silicon implementation so that tag values can’t influence speculative execution in any way. Recently published security research demonstrates that the MTE implementation on Google’s Pixel devices is vulnerable to this type of attack, allowing MTE to be bypassed in Google Chrome and the Linux kernel.
Second, allocators assign random tags to memory, and attackers must not be able to predict tag values that the system will choose. We address this issue by frequently re-seeding the underlying pseudo-random generator used to select new tags.
Third, Spectre variant 1 (V1) is a speculative-execution vulnerability that allows attackers to exploit conditional branches to leak data, including MTE tag values. To date, there has been no solution to this problem in consumer operating systems, because general Spectre V1 mitigations such as Speculative Load Hardening have a prohibitive CPU cost. The presence of EMTE leaves Spectre V1 as one of the last avenues available to attackers to help guide their attacks, so we designed a completely novel mitigation that limits the effective reach of Spectre V1 leaks — at virtually zero CPU cost — and forces attackers to contend with type segregation. This mitigation makes it impractical for attackers to use Spectre V1, as they would typically need 25 or more V1 sequences to reach more than 95 percent exploitability rate — unless one of these sequences is related to the bug being exploited, following similar reasoning as our kalloc_type analysis.
Our mission with Memory Integrity Enforcement is to protect all users by default and provide an extraordinary disruption to the exploitation of memory corruption vulnerabilities. To do so, we considered a wide set of threats, including some of the most challenging ones — such as side channels — and arrived at this extensive combination of features not present in other MTE implementations. Google took a great first step last year when they offered MTE to those who opt in to their program for at-risk users. But even for users who turn it on, the effectiveness of MTE on Android is limited by the lack of deep integration with the operating system that distinguishes Memory Integrity Enforcement and its use of EMTE on Apple silicon.
For the new A19 and A19 Pro chips to support Memory Integrity Enforcement, we dedicated an extraordinary amount of Apple silicon resources to security — more than ever before — including CPU area, CPU speed, and memory for tag storage. And to fully realize this hardware investment, we designed all of the new operating system elements of MIE jointly with our hardware work, including secure allocators, EMTE, and tag confidentiality protections.
Because EMTE tag checking imposes a performance cost, we designed Memory Integrity Enforcement to take advantage of our secure allocators first and use EMTE to protect only smaller individual allocations within a type bucket, which software allocators can’t defend on their own. Then, by knowing where and how we would deploy EMTE, we could accurately model the tag-checking demand of the operating system, and design our silicon to satisfy it. Our hardware implementation influenced additional software design decisions, reducing the overhead of tag checks even further. Importantly, deploying EMTE with this level of precision supports our strategy to provide as many memory safety improvements as possible to users on previous iPhone generations, which don’t support EMTE.
For the security evaluation of Memory Integrity Enforcement, we involved our offensive research team from the very beginning. From 2020 to 2025, they continuously analyzed and attacked the system — first conceptually, with theoretical exploitation avenues, then with practical attacks in simulated environments, and eventually on new hardware prototypes. Prolonged engagement from our offensive research team allowed us to identify and eradicate entire attack strategies and techniques before attackers could ever discover them, leading to a stronger, more mature feature from the outset.
Our offensive research team identified where and how attackers are most likely to break into the system, and our deployment of Memory Integrity Enforcement is deeply guided by their findings. Notably, this includes making sure that this powerful new protection is available to third-party apps that are likely entry points for attackers — such as social networks, messaging apps, or any other app where a specific user can be targeted. Starting immediately with the launch of MIE, any developer can begin testing this powerful protection for their app, including EMTE on hardware that supports it, using the Enhanced Security settings in Xcode.
The meticulous planning and implementation of Memory Integrity Enforcement made it possible to maintain synchronous tag checking for all the demanding workloads of our platforms, delivering groundbreaking security with minimal performance impact, while remaining completely invisible to users.
Security evaluation
Memory Integrity Enforcement started with a deeply ambitious goal: to make it immensely more expensive and difficult to develop and maintain mercenary spyware attacks based on memory corruption against our platforms. While there’s no such thing as perfect security, MIE is designed to dramatically constrain attackers and their degrees of freedom during exploitation.
Throughout the design and implementation of Memory Integrity Enforcement, our offensive research team evaluated our progress by looking at sophisticated exploit chains that were previously used against our platform, recent vulnerabilities, and our own internal research. First, we worked on rebuilding and adapting previously seen exploit chains to systems protected by MIE. But it’s not sufficient to consider only previous chains that were developed before MIE existed, because attackers will surely adapt in reaction to these new protections. We therefore also evaluated a selection of more recent vulnerabilities that we expected would have the best chance of surviving MIE. For these, we meticulously enumerated all possible exploitation opportunities, similar to our evaluation of SockPuppet against kalloc_type.
Both approaches revealed the same conclusion: Memory Integrity Enforcement vastly reduces the exploitation strategies available to attackers. Though memory corruption bugs are usually interchangeable, MIE cut off so many exploit steps at a fundamental level that it was not possible to restore the chains by swapping in new bugs. Even with substantial effort, we could not rebuild any of these chains to work around MIE. The few memory corruption effects that remained are unreliable and don’t give attackers sufficient momentum to successfully exploit these bugs.
Here’s a visual representation of what this looks like for an attacker. The chart below represents six of the real-world exploit chains that we evaluated and shows the steps where Memory Integrity Enforcement — the secure allocators, EMTE, or both — stops the attack.
 Memory Integrity Enforcement vs. real-world exploit chains

Notably, attackers confront Memory Integrity Enforcement early in the exploitation process. Although some issues are able to survive MIE — for example, intra-allocation buffer overflows — such issues are extremely rare, and even fewer will lend themselves to a full end-to-end exploit. Inevitably, attackers must face MIE at a stage where their capabilities are still very limited, leaving few viable avenues for exploitation. This leads to fragile chains where breaking just one step is often enough to invalidate the entire exploit strategy. When that happens, most of the chain’s components can’t be reused, and the attackers have to restart exploit development with entirely new bugs.
Conclusion
The industry-leading security of iPhone means that the vast majority of our users never face system-level attacks on their devices. Our work on memory safety is aimed primarily at the mercenary spyware and surveillance industry, which spends many millions of dollars to exploit memory corruption vulnerabilities and target a small number of individuals because of who they are and what they do. Over the past five years, we developed a comprehensive approach to memory safety that integrates the best of our hardware and software capabilities, and today’s announcement is the culmination of this ambitious vision. With the introduction of the iPhone 17 lineup and iPhone Air, we’re excited to deliver Memory Integrity Enforcement: the industry’s first ever, comprehensive, always-on memory-safety protection covering key attack surfaces — including the kernel and over 70 userland processes — built on the Enhanced Memory Tagging Extension (EMTE) and supported by secure typed allocators and tag confidentiality protections.
Based on our evaluations pitting Memory Integrity Enforcement against exceptionally sophisticated mercenary spyware attacks from the last three years, we believe MIE will make exploit chains significantly more expensive and difficult to develop and maintain, disrupt many of the most effective exploitation techniques from the last 25 years, and completely redefine the landscape of memory safety for Apple products. Because of how dramatically it reduces an attacker’s ability to exploit memory corruption vulnerabilities on our devices, we believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[iPhone Air]]></title>
            <link>https://www.apple.com/newsroom/2025/09/introducing-iphone-air-a-powerful-new-iphone-with-a-breakthrough-design/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186015</guid>
            <description><![CDATA[Apple today debuted the all-new iPhone Air, the thinnest iPhone ever made, with pro performance.]]></description>
            <content:encoded><![CDATA[


	
    







 

	
    
    
        




    
    
    
	
	







 




opens in new window








    
    
    









    





    
        
		
        
                    
                    
                        PRESS RELEASE
                    
                    
                        September 9, 2025
                    
                    
                

        
                
                
                
                    
                        
    
        Introducing iPhone Air, a powerful new iPhone  with a breakthrough design
    

                    
                
            

        
                
                
                    iPhone Air features an impossibly thin and light  design that is more durable than any previous model,  with innovative camera experiences and  remarkable all‑day battery life
                
            

        
            
    
    
    
    
    

        

    







    
    
    






  
    
    
    
    
      
        
      
    
  








    
    
    


     
     
    
    
        CUPERTINO, CALIFORNIA Apple today debuted the all-new iPhone Air, the thinnest iPhone ever made, with pro performance. iPhone Air features a breakthrough titanium design that is elegant and light yet strong, with an innovative internal architecture that enables the latest iPhone experiences. The back of iPhone Air is now protected with Ceramic Shield, and the front cover uses Ceramic Shield 2, delivering 3x better scratch resistance, making iPhone Air more durable than any previous iPhone. iPhone Air also features a stunning 6.5-inch Super Retina XDR display with ProMotion up to 120Hz.1 With the most Apple-designed chips in an iPhone — the powerhouse A19 Pro, N1, and C1X — iPhone Air is the most power-efficient iPhone ever made. Paired with the redesigned internal architecture and software optimizations, iPhone Air has fantastic all-day battery life. A powerful 48MP Fusion Main camera enables the equivalent of four lenses with incredible image quality, and the innovative 18MP Center Stage front camera takes selfies to the next level.

 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            iPhone Air is shown from the back in space black, cloud white, light gold, and sky blue.
                        
                    
                        
                            iPhone Air is shown from the side in sky blue, light gold, cloud white, and space black.
                        
                    
                        
                            A person holds up iPhone Air between two fingers, emphasizing with this side profile view how thin the device is.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
             
                 A Breakthrough Design

                 
             
                 Featuring a breakthrough design with pro performance, iPhone Air is the thinnest iPhone ever made at 5.6mm, and it is incredibly light, with a large, stunning display. The grade 5 titanium frame is strong, with an elegant high-gloss mirror finish, and a new plateau on the back that is precision-milled on both sides to house the cameras, speaker, and Apple silicon. This maximizes space for the battery to deliver remarkable all-day battery life. The thin design also features the Action button, so users can easily access a variety of functions with just a press, and Camera Control, to quickly launch the camera or enable visual intelligence.2

                 
             
         
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            An outdoor portrait of a person with curly hair taken with 2x Telephoto on iPhone Air.
                        
                    
                        
                            A photo of a towering rock formation taken in 48MP on iPhone Air.
                        
                    
                        
                            An outdoor photo of a person standing inside a hot air balloon billowing in the wind taken in 24MP on iPhone Air.
                        
                    
                        
                            A close-up photo of a stack of homemade waffles covered in colorful berries showing Focus Control on iPhone Air.
                        
                    
                        
                            An editorial-style photo of a person wearing all white against an abstract black-and-white backdrop showing Photographic Styles and taken on iPhone Air.
                        
                    
                        
                            An editorial-style photo of a person wearing all white sitting on a chair inside a dimly lit room taken on iPhone Air.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
             
                 eSIM: A Flexible, Convenient, and Secure Connection

                 
             
                 iPhone Air features an eSIM-only design that saves space internally, helping enable the unbelievably light and thin form factor.4 eSIM offers greater flexibility, better security, and seamless connectivity compared to traditional physical SIM cards. An industry standard, eSIM is supported by over 500 carriers worldwide, including AT&T, T-Mobile, Verizon, and more. eSIM also makes staying connected while traveling even more convenient, allowing continued connectivity through affordable international roaming plans from users’ home carriers or local prepaid options available with more than 200 carriers. For better security, eSIM cannot be physically removed if an iPhone is lost or stolen, and managing travel eSIMs is even easier with a new streamlined setup in iOS 26.

                 
             
                 Featuring iOS 26 with New Apple Intelligence Capabilities

                 
             
                 iOS 26 elevates the iPhone experience with a beautiful new design, powerful Apple Intelligence capabilities, and meaningful improvements to the apps users rely on every day. The new design with Liquid Glass makes apps and system experiences more expressive and delightful, bringing greater focus to content while keeping iOS instantly familiar. Apple Intelligence now translates text and audio on the go with Live Translation, helping users communicate across languages in Messages, FaceTime, and Phone.5 Updates to visual intelligence allow users to capture a screenshot and easily search or take action on anything they are viewing on their iPhone screen. The on-device foundation model at the core of Apple Intelligence is available to all developers, with apps already offering new intelligent, privacy-protected experiences that can even be used when offline. New screening tools for calls and messages help eliminate distractions so users can focus on the conversations that matter most. iOS 26 also introduces new features in CarPlay, Apple Music, Maps, and Wallet, as well as Apple Games, a brand-new app that gives players a single destination for all their games.

                 
             
         
 

    
    
    


    
        
        
        
        
            
                
            
        
    












    
    
    


     
     
    
    
        
             
                 Beautiful New Accessories

                 
             
                 
                 
             
                 
The iPhone Air Case with MagSafe — available in frost and shadow — has an ultra-thin translucent design with a lightly frosted interior, a high-gloss outer surface, and a reinforced polycarbonate frame to protect iPhone Air from scratches and drops.


                 
             
                 
The slim and lightweight iPhone Air Bumper — available in four matching colors — perfectly frames iPhone Air with a reinforced polycarbonate design for added edge protection.


                 
             
                 
Crafted from 100 percent recycled yarns, the Crossbody Strap drapes comfortably, with embedded flexible magnets and stainless steel sliding mechanisms to easily adjust the length and keep both straps securely aligned. The Crossbody Strap will be available in 10 colors: black, light gray, blue, light blue, purple, sienna, green, neon yellow, tan, and orange.


                 
             
                 
The iPhone Air MagSafe Battery has a thin and light design that seamlessly attaches to the back of the device. The MagSafe Battery quickly charges iPhone Air when the battery is low, and maximizes battery life when connected throughout the day, delivering up to 40 hours of video playback when used together.


                 
             
         
 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            iPhone Air is shown with the new MagSafe Case.
                        
                    
                        
                            iPhone Air is shown with the new Bumper.
                        
                    
                        
                            iPhone Air is shown with the new Crossbody Strap.
                        
                    
                        
                            iPhone Air is shown with the new MagSafe Battery.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
             
                 iPhone Air and the Environment

                 
             
                 Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. iPhone Air is made with 35 percent recycled content, including 80 percent recycled titanium, the highest ever for an iPhone, and 100 percent recycled cobalt in the battery. A new titanium USB-C port is 3D-printed to be thinner and stronger, fitting into the slim design while using 33 percent less material than a conventional forging process. iPhone Air is manufactured with 45 percent renewable electricity, like wind and solar, across the supply chain. It is designed to be durable, repairable, and offer industry-leading software support, while meeting Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled.

                 
             
         
 

    
    
    


     
     
    
    
        
             
                 
                 
             
                 
iPhone Air will be available in space black, cloud white, light gold, and sky blue, starting with 256GB storage, as well as 512GB and 1TB options. iPhone Air starts at $999 (U.S.) or $41.62 (U.S.) per month.6


                 
             
                 
Apple offers great ways to save and upgrade to the latest iPhone models. With Apple Trade In, customers can get $200 to $700 (U.S.) in credits when they trade in iPhone 13 or newer.7 Apple also partners with select carriers to offer incredible deals, and customers can get up to $1,100 (U.S.) in credits when they trade in iPhone 13 or newer — in any condition — to put toward iPhone 17 Pro. Customers can take advantage of carrier deals by visiting the Apple Store online or an Apple Store location. For carrier deal eligibility requirements and more details, see apple.com/shop/buy-iphone/carrier-offers. To see what their device is worth and for trade-in terms and conditions, customers can visit apple.com/shop/trade-in.


                 
             
                 
Customers in more than 63 countries and regions, including Australia, Canada, China, Colombia, France, Germany, India, Japan, Malaysia, Mexico, Singapore, South Korea, Thailand, Türkiye, the UAE, the UK, the U.S., and Vietnam, will be able to pre-order iPhone Air beginning at 5 a.m. PDT this Friday, September 12, with availability beginning Friday, September 19. iPhone Air will be available in 22 other countries and regions beginning Friday, September 26.


                 
             
                 
iOS 26 will be available as a free software update on Monday, September 15. Some features may not be available in all languages or regions, and availability may vary due to local laws and regulations. For more information about availability, visit apple.com.


                 
             
                 
Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. More languages will be coming by the end of this year: Danish, Dutch, Norwegian, Portuguese (Portugal), Swedish, Turkish, Chinese (traditional), and Vietnamese. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.


                 
             
                 
Apple is extending free access to satellite features for an additional year for existing iPhone 14 and iPhone 15 users. The free trial will be extended for iPhone 14 and iPhone 15 users who have activated their device in a country that supports Apple’s satellite features prior to 12 a.m. PT on September 9, 2025. For satellite feature availability, visit support.apple.com/en-us/105097.


                 
             
                 
iPhone Air MagSafe Battery will be available for $99 (U.S.). iPhone Air Case with MagSafe is available for $49 (U.S.), iPhone Air Bumper will be available for $39 (U.S.), and a Crossbody Strap will be available for $59 (U.S.). FineWoven Wallet with MagSafe will be available for $59 (U.S.) in black, navy, midnight, purple, fox orange, and moss.


                 
             
                 
The Apple-designed 40W Dynamic Power Adapter with 60W Max will be available for $39 (U.S.), and a Qi2 25W-certified MagSafe Charger will be available in a 1-meter length for $39 (U.S.) or a 2-meter length for $49 (U.S.).8


                 
             
                 
AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new iPhone, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple experts. For more information, visit apple.com/applecare.


                 
             
                 
iCloud+ plans start at just $0.99 (U.S.) per month, providing additional storage to keep photos, videos, files, and more safe in the cloud and accessible across devices. iCloud+ also gives access to premium features such as event creation in the Apple Invites app, as well as Private Relay, Hide My Email, custom email domains, and HomeKit Secure Video. With Family Sharing, users can share their subscription with five other family members at no extra cost.


                 
             
                 
Customers who purchase iPhone Air may receive three free months of Apple Arcade, Apple Fitness+, Apple Music, Apple News+, and Apple TV+ with a new subscription. Offer and services availability varies by region. See apple.com/promo for details.


                 
             
         
 

    
    
    




    
    
        
    


    
    
    


		
		
        
			
				
				
					Text of this article
					
				
			
			
                
                
                    Media in this article
                    
                
            

        
    

    
    
    




    




    
    
    





    
    
    
            
The display has rounded corners that follow a beautiful curved design, and these corners are within a standard rectangle. When measured as a standard rectangular shape, the screen is 6.55 inches diagonally. The actual viewable area is smaller.
Visual intelligence is available on any Apple Intelligence-enabled iPhone. Some capabilities may not be available in all languages and regions. For more details, see support.apple.com/en-us/121115#visual-intelligence.
The new Bright Photographic Style will be available in iOS 26 on iPhone 16, iPhone 16 Plus, iPhone 16 Pro, iPhone 16 Pro Max, iPhone 17, iPhone Air, iPhone 17 Pro, and iPhone 17 Pro Max.
Use of an eSIM requires a carrier that supports eSIM and a wireless service plan. See carrier for details. To learn more, visit apple.com/esim.
Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified). Live Translation in Phone and FaceTime is available for one-on-one calls in English (U.S., UK), French (France), German, Portuguese (Brazil), and Spanish (Spain).
Financing available to qualified customers, subject to credit approval and credit limit, and requires users to select Citizens One Apple iPhone Payments or Apple Card Monthly Installments (ACMI) as their payment type at checkout at Apple. They’ll need to select AT&T, Boost Mobile, T‑Mobile, or Verizon as their carrier when they check out. An iPhone purchased with ACMI is always unlocked, so they can switch carriers at any time, subject to their carrier’s terms. Taxes and shipping on items purchased using ACMI are subject to their card’s variable APR, not the ACMI 0 percent APR. ACMI is not available for purchases made online at special storefronts. The last month’s payment for each product will be the product’s purchase price, less all other payments at the monthly payment amount. ACMI financing is subject to change at any time for any reason, including but not limited to, installment term lengths and eligible products. See the Apple Card Customer Agreement for more information about ACMI. Additional Citizens One Apple iPhone Payments terms are available at apple.com/legal/sales-support/iphoneinstallments_us.
Trade-in values will vary based on the condition, year, and configuration of the eligible trade-in device.
The 40W Dynamic Power Adapter with 60W Max will be available in Canada, China mainland, Japan, Mexico, Taiwan, the Philippines, and the U.S.


        



    
    
    






    















	

		
		
			
























		
		











	

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Tomorrow's emoji today: Unicode 17.0]]></title>
            <link>https://jenniferdaniel.substack.com/p/tomorrows-emoji-today-unicode-170</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45185875</guid>
        </item>
        <item>
            <title><![CDATA[E-paper display reaches the realm of LCD screens]]></title>
            <link>https://spectrum.ieee.org/e-paper-display-modos</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45185756</guid>
            <description><![CDATA[E-Paper displays just got faster with Modos' 75 Hz refresh rate. How did they achieve it?]]></description>
            <content:encoded><![CDATA[E-paper displays are prized for their readability and low power use, but they’ve long been dismissed as too slow for everyday computing. Modos, a two-person startup with open-hardware roots, thinks it has cracked part of that problem with a development kit capable of driving an e-paper display at refresh rates up to a record 75 hertz.The Modos Paper Monitor and Dev Kit, now available for crowdfunding on Crowd Supply, combines standard e-paper panels with an open source FPGA-based display controller. While the kit provides enthusiasts and developers a complete package (with e-paper display, display driver, and hardware adapter), it’s also an entry point for experimenting with different e-paper displays.RELATED: How E Ink Developed Full-Color E-paper“I would say instead of our secret sauce, we have open sauce,” says cofounder Alexander Soto. “You don’t even need to use the panel we’re offering. You could use a different panel and still get [75 Hz].”E-paper at 75 HzMost e-paper panels update at a refresh rate of around 10 Hz or less. (E-paper is the generic term for screens that mimic the appearance of ink on paper—the most well-known brand being that made by the company E Ink.) Some displays don’t even quote a refresh rate and may require up to a full second to refresh. A better refresh rate means a display can show more frames each second, which in turn provides smoother, more lifelike motion. Modern digital video is usually delivered at 30 or 60 frames per second, which until recently was well beyond the reach of an e-paper display. This is an area where e-paper clearly lags LCD displays, which start at 60 Hz and go up from there.Modos is able to hit refresh rates of up to 75 Hz on a 13-inch e-paper panel with a 1,600 by 1,200 resolution. (a 6-inch e-paper panel with 1,448 by 1,072 resolution and the same refresh rate is available, too.) Bumping the refresh rate also reduces latency. That’s a key point, as it allows an e-paper display to be used in situations where latency matters, such as a computer or tablet display.“A lot of people default to thinking that with e-readers or e-paper, it’s slow, it’s going to be flashing all the time,” says Soto. “Our challenge has been going to conferences, going to events, and showing people…e-paper can be very fast.” Open Source E-Paper Display ControllerModos’s quoted 75-Hz refresh rate is the highest yet for an e-paper display, but it’s arguably not the key innovation. Several competitors already offer e-paper displays with refresh rates up to 60 Hz which, though lower, is close. But Modos has a not-so-secret weapon: Caster, an open-source e-paper display controller that’s compatible with a wide variety of e-paper panels. The display controller, which is based on the AMD Spartan-6 FPGA, departs from typical e-paper controllers with pixel-level display management. “Traditionally, the [e-paper display] controller used a single-state machine to control the entire panel, with only two states: static and updating,” says Modos cofounder Wenting Zhang. “Caster treats each pixel individually rather than as a whole panel, which allows localized control on the pixels.”The FPGA display controller is paired with Modos’s Glider Mega Adapter, which includes four different display connectors compatible with several dozen e-paper displays ranging in size from 4.3 to 13 inches. Soto says the adapter can be used to repurpose displays salvaged from older e-readers, like Amazon’s Kindle.  A 75-Hz refresh rate allows for smoother scrolling. Modos Modos also provides an application programming interface (API), written in the C programming language, that lets applications select display-driving modes dynamically. As the video above shows, a Linux window manager can be used to render text in a low-latency binary color mode, display maps in more detailed yet responsive gray scale, and display video with maximum-fidelity gray scale—all simultaneously on the same screen. The code and schematics for Caster, Glider, and the API are open source and available on Github. Crowdfunding for E-paper InnovationModos’s crowdfunding campaign is set to conclude on 18 September. Orders are expected to ship in January of 2026, although (as is often the case for crowdfunded projects) the shipping window is not guaranteed. Getting to this stage has taken several years. The company’s founders initially hoped to build an e-paper laptop, the Modos Paper Laptop, which was announced in January of 2022. However, the realities of electronics manufacturing complicated that project early in its life and the laptop was never made available to order. “Part of it was that the primary aspect ratio for the majority of [laptop] chassises are for 16:9 and 16:10. And when you look at e-paper displays, it was an aspect ratio of 4:3. So, we either had to make a custom chassis, or a custom panel, both of them being prohibitively expensive,” says Soto.Panel sourcing also remains a hurdle. E-paper’s production is geared toward e-readers and signage, which means most panels aren’t the right size for a computer. However, the Modos Paper Monitor and Dev Kit found a practical compromise in recently introduced 13-inch e-paper displays, many of which provide a resolution similar to LCD and OLED panels developed for laptops. In this way, the Dev Kit is a continuation of Modos’s original goal. While building a full-fledged e-paper laptop was impractical, the Dev Kit’s high refresh rate, open-source display controller, and API give ambitious users the opportunity to implement their own low-latency e-paper computer display—or anything else they put their mind to.This article was updated on 8 September 2025 to replace mentions of “E Ink” (the specific e-paper technology developed by the company of the same name) with “e-paper.”]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Microsoft is officially sending employees back to the office]]></title>
            <link>https://www.businessinsider.com/microsoft-send-employees-back-to-office-rto-remote-work-2025-9</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45184432</guid>
            <description><![CDATA[One of Big Tech's last remaining RTO holdouts is officially ending full remote work for many staff.]]></description>
            <content:encoded><![CDATA[
            
            
            
            
                
                
                    
                      
                      
                    
                
                  
                        
                          
                          
                            
                              
                                    
                  
                          
                            Microsoft CEO Satya Nadella
                            
                              
                                Max Cherney/REUTERS
                                        
                          
                        
                  
            
    
    
    
              
                
                
                
                  
                      2025-09-09T15:05:01Z
                    
                  
                
                
                        
      
            
      
              
              
              
              
                
                    Microsoft is sending employees back to the office at least three days a week.
                    The first phase will be for employees who live near its Seattle-area headquarters in February.
                    Business Insider reported last month that Microsoft's was considering a stricter RTO policy.
                
              
      
            
            
            
            
            
            
                One of Big Tech's last remaining RTO holdouts is officially sending employees back to the office.Microsoft is mandating employees work from offices at least three days a week, according to an internal email the company sent to staff on Tuesday.The mandate will happen in three phases, beginning at the end of February 2026, with Seattle-area employees who live within 50 miles of a Microsoft office. It will then expand to other US offices and eventually internationally, according to the email from Microsoft HR chief Amy Coleman. February 23 was one of the start dates Microsoft considered, but it hasn't been decided yet.Employees can request an exception by September 19. Coleman's email didn't include details about how such exceptions may work.Business Insider reported in August that Microsoft was considering a stricter RTO policy mandating three days a week in the office.Microsoft sells software that enables remote work, such as its popular Teams workplace chat and meeting app. It remained relatively lax compared to some other Big Tech companies when it comes to RTO, especially cross-town rival Amazon. Even Zoom sent its employees back to the office part-time in 2023.Microsoft first introduced a flexible work policy when it brought employees back to the office in late 2020 after pandemic-forced closures. That policy officially allowed employees to work from home at least half of the time without approval, but in practice it was even more flexible and most employees worked remotely most of the time.Now its policy is evolving to be similar to guidelines at Meta and Google, which generally require most employees to work in offices three days a week.Microsoft's new approach is the latest sign of the company increasing performance pressure on employees. It has fired thousands of employees deemed low performers this year and introduced a new performance improvement plan meant to exit low performers more quickly.While working on the new RTO policy, Microsoft appears to have scrubbed a blog post that once heralded the benefits of remote work for retaining employees and boosting their productivity.
              
              
              
            "Hybrid work is more than a change in technology—it's a change in mindset, a change in culture, and a change in the way you think about physical and virtual spaces to enable an inclusive and productive environment for all," Microsoft wrote, according to a snapshot of the blog retained by the Internet Archive. "The change isn't easy, but it's worth it. If you make the time to do it right, your employees will be more engaged, more productive, and more connected, even when they're miles away. And they'll be far less likely to leave for a competitor who has a more sophisticated and flexible model than you do."The link to that blog post now redirects to one published on July 31 calling out how "hybrid work created new challenges for employee engagement" and how AI can solve them.Read the full memo:"How we work has forever changed. I remember starting at Microsoft in the late '90s, always in the office, no laptops, and primarily working with the people right down the hall. As technology evolved and our business expanded, we became more open, more global, and able to scale in ways we couldn't have imagined. Then the pandemic reshaped everything. It pushed us to think differently about work, to connect like never before (thank you Teams!), reminded us of how much we value being together, and gave us focus and autonomy in the traditional workday. We're not going back, and we shouldn't. Instead, we should take the best of what we've learned and move forward.In the AI era, we are moving faster than ever, building world class technology that changes how people live and work, and how organizations everywhere operate. If you reflect on our history, the most meaningful breakthroughs happen when we build on each other's ideas together, in real time.We've looked at how our teams work best, and the data is clear: when people work together in person more often, they thrive—they are more energized, empowered, and they deliver stronger results. As we build the AI products that will define this era, we need the kind of energy and momentum that comes from smart people working side by side, solving challenging problems together.With that in mind, we're updating our flexible work expectations to three days a week in the office.We'll roll this out in three phases: 1) starting in Puget Sound at the end of February; 2) expanding to other US locations; 3) and then launching outside the US.Our goal with this change is to provide more clarity and consistency in how we come together, while maintaining the flexibility we know you value. We want you to continue to shape your schedule in ways that work best for you, making in-person time intentional and impactful. Importantly, this update is not about reducing headcount. It's about working together in a way that enables us to meet our customers' needs.For some of you, this is not a change. For others this may be a bigger adjustment, which is exactly why we're providing time to plan thoughtfully. As part of these updates, we're also enhancing our workplace safety and security measures so we can continue to provide a workplace where every employee can do their best work.What you need to know:Puget Sound-area employees: If you live within 50 miles of a Microsoft office, you'll be expected to work onsite three days a week by the end of February. You'll receive a personalized email today with more details. Please connect with your manager and team to understand your organization's plans. If needed, you can request an exception by Friday, September 19.Managers: You'll find actions to take, and the resources to support both you and your team on the Managers@Microsoft SharePoint.All employees: You'll hear from your EVP or organizational leadership today with specific guidance. Each business will do what is best for their team, which means some groups will deviate from our company-wide expectations. If you are outside of the Puget Sound area, you do not need to take any action at this time unless your EVP communicates otherwise.Timelines and details for additional US office locations will be announced soon. For employees outside the United States, we will begin planning in 2026. More information is available on the Flexible Work at Microsoft SharePoint.As always, we'll keep learning together to ensure Microsoft is the best place for you to grow and have a great career. Let's keep moving forward together.Thank you,Amy"Have a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.
            
            
            
            
            
            
            
              
            
    
    
    
    
      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ICE is using fake cell towers to spy on people's phones]]></title>
            <link>https://www.forbes.com/sites/the-wiretap/2025/09/09/how-ice-is-using-fake-cell-towers-to-spy-on-peoples-phones/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45184368</guid>
            <description><![CDATA[ICE is using a controversial spy tool to locate smartphones, court records show.]]></description>
            <content:encoded><![CDATA[This is the online edition of The Wiretap newsletter, your weekly digest of cybersecurity, internet privacy and surveillance news. To get it in your inbox, subscribe here.
ICE is using all manner of surveillance technologies in its deportation drive. (Photo by Smith Collection/Gado/Getty Images)Getty Images

It’s been some time since Immigration and Customs Enforcement (ICE) has been seen using a tool known as a Stingray, or a cell-site simulator, in its attempts to find and remove undocumented immigrants. The tool tricks a phone into thinking it’s a cell tower, and when a suspect’s device connects, the cops can trace its location. Its use is controversial because anyone in the same area as the target is at risk of having their information exposed.

In a recently-unsealed search warrant reviewed by Forbes, ICE used such a cell-site simulator in an attempt to track down an individual in Orem, Utah. The suspect had been ordered to leave the U.S. in 2023, but is believed to still be in the country. Investigators learned last month that before going to Utah, he’d escaped prison in Venezuela where he was serving a sentence for murder, according to the warrant. He’s also suspected of being linked to gang activity in the country, investigators said.

When the government got the target’s number, they first got a warrant to get its location. However, the trace wasn’t precise–it only told law enforcement that the target was somewhere in an area covering about 30 blocks. That led them to asking a court for a Stingray-type device to get an accurate location.

The warrant was issued at the end of last month and it’s not yet known if the fugitive was found.
But the case shows that, despite having been criticized by civil rights groups for using Stingrays during the last Trump administration, ICE continues to use the technology. Earlier this year, new media publication Straight Arrow News said it had analysed “mobile network anomalies” around a Washington state protest against ICE raids that were consistent with Stingray use.
Forbes found contract records showing ICE purchased nearly $1 million worth of “cell site simulator vehicles” in May this year, indicating it’s taking the surveillance tool fully mobile. That was part of a contract first signed under the Biden administration in 2024.
ICE also has an active contract worth up to $4.4 million with the original Stingray manufacturer, Harris Corporation, for unspecified “equipment to determine the location of targeted mobile handsets.” That deal was also signed during the Biden years.

Got a tip on surveillance or cybercrime? Get me on Signal at +1 929-512-7964.
THE BIG STORY:
This Billionaire’s AI Was Supposed To Speed Up Policing. It’s Not Going Well.Tom Siebel, chief executive officer of C3.AI, during a panel session at the World Economic Forum (WEF) in Davos, Switzerland. Photographer: Stefan Wermuth/Bloomberg© 2025 Bloomberg Finance LP
San Mateo County Sheriff’s Office spent $12 million on a sprawling AI surveillance system called Sherlock, designed to stitch together surveillance streams across as many as 16 different agencies in the jurisdiction.
Made by billionaire Tom Siebel’s C3 AI, it was supposed to drastically speed up police work, but three years into the project, cops tell Forbes they’re yet to see the benefits.
Per one staffer in 2023, “We’ve been working with them for two years and they have a barely functional product.” Since then, it’s unclear just how much the tech has progressed.
Stories You Have To Read Today
In a Forbes profile, Flock Safety shows off its drones, car tracking and AI-powered surveillance tools, all part of an effort to dislodge police tech giant Axon from the top of the market. “I plan to go take them out,” says CEO Garrett Langley.
ICE signed a contract with facial recognition company Clearview AI last week, worth nearly $10 million. It’ll be used, in part, to identify people assaulting ICE officers.
Former WhatsApp security lead Attaullah Baig has filed a lawsuit alleging Meta ignored big privacy and security problems within the messaging app. He claims thousands of Meta employees were able to view WhatsApp users’ profile pictures, location, group memberships and contact lists. Meta rejected the claims saying Baig was dismissed for poor performance and that his allegations were “distorted.”
Winner of the Week
Signal has launched encrypted backups for user chats. The feature will first be made available for Android phones, before being slowly rolled out to iPhone users. The archive requires a 64-character recovery key to access, but keep that code safe: Signal warns that if it’s lost, there’s no way to get it back.
Loser of the Week
Amnesty International claims that Pakistan is running one of the world’s most expansive domestic surveillance operations outside of China, using both Chinese and Western technology providers, who are enabling both mass snooping via the nation’s telecoms companies as well as widespread internet censorship.
More On ForbesForbesAmerica’s Richest Sports Team Owners 2025By Justin BirnbaumForbesPresidency Boosts Trump’s Net Worth By $3 Billion In A YearBy Dan AlexanderForbesThe 2025 Forbes 400 List Of Wealthiest Americans: Facts And FiguresBy Chase Peterson-Withorn]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[An attacker’s blunder gave us a look into their operations]]></title>
            <link>https://www.huntress.com/blog/rare-look-inside-attacker-operation</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183589</guid>
            <description><![CDATA[An attacker installed Huntress onto their operating machine, giving us a detailed look at how they’re using AI to build workflows, searching for tools like Evilginx, and researching targets like software development companies.]]></description>
            <content:encoded><![CDATA[Update Sept. 9 @ 3pm ETWhat you're about to read is something that all endpoint detection and response (EDR) companies perform as a byproduct of investigating threats. Because these services are designed to monitor for and detect threats, EDR systems by nature need the capability to monitor system activity, as is outlined in our product documentation, Privacy Policy, and Terms of Service.On the heels of questions around how and why Huntress released this information, we wanted to clarify several important aspects of our investigation. We have an obligation to 1) research and respond to security threats and investigate malware and 2) educate the broader community about those threats. These dual objectives played into our decision to develop and publish this blog post. When we first came across the host mentioned in this blog, it was because we were first responding to numerous alerts that were related to malware executing on it. Part of this process involves our SOC team closely investigating signals and collecting artifacts related to EDR telemetry on the host. It was only upon further investigation into this telemetry that we observed signals indicating malicious behavior. By this point, we also found that the unique machine name used by the individual was the same as one that we had tracked in several incidents prior to them installing the agent.At this point, we determined that the host that had installed the Huntress agent was, in fact, malicious. We wanted to serve the broader community by sharing what we learned about the tradecraft that the threat actor was using in this incident. In deciding what information to publish about this investigation, we carefully considered several factors, like strictly upholding our privacy obligations, as well as disseminating EDR telemetry that specifically reflected threats and behavior that could help defenders.Overall, this investigation is a result of what we strive to do best: transparency, education, and wrecking hackers. Read on to learn more.------------------------Summary
Here at Huntress, we love exposing adversary tradecraft, and we also love when threat actors make blunders. So imagine our delight when a threat actor installed Huntress onto their operating machine—after finding us via one of our advertising campaigns and starting a trial— giving us a sprawling inside look at how they’re using AI to build workflows, searching for tools like Evilginx, and more.
------------------------
We all know that security products are often downloaded by attackers for “evaluation,” but often we can only guess as to how they decided to target a particular technology, or the actions taken while trying out such software. We recently had the pleasure of getting a front seat view into what one attacker did, simply because they installed our agent and let us collect information directly from them. Here, we will cover this strange tale.

How did we get here?
Like most good stories, this one starts in the middle and works its way back and forth. Let’s start with how this person of interest got our attention. One of the tricks of the trade to get people interested in your products is through advertising. As such, we run ads to help lead potential customers to our products. An adverse effect here might be garnering some “unwanted” attention as well. Such is the setting for the beginning of this adventure: it all started with a nicely placed Google ad.
The attacker tripped across our ad while researching another security solution. We confirmed this is how they found us by examining their Google Chrome browser history. An example of how this may have appeared to them in the moment may be seen in Figure 1.

Figure 1: Google search for Bitdefender, leading to a Huntress ad

It appears that the attacker became interested in Huntress while simultaneously trying out Bitdefender. After hitting our comparison page, they could hardly contain themselves and started a trial immediately. We are able to follow their journey through their Chrome history, as seen in Figure 2 below.


    Figure 2: Browser history showing how a search for Bitdefender led to a Huntress trial





It’s no secret that threat actors may install security products for research purposes or even for legitimate use—and in fact, the adversary was interested in other security products in addition to Bitdefender and Huntress. We found evidence that they had bought a Malwarebytes subscription (including the Malwarebytes browser guard extension).

Figure 3: Attacker tries to stay safe with an installed Malwarebytes browser extension 🤣

Threat actor red flags—and our response
We knew this was an adversary, rather than a legitimate user, based on several telling clues. The standout red flag was that the unique machine name used by the individual was the same as one that we had tracked in several incidents prior to them installing the agent. Further investigation revealed other clues, such as the threat actor’s browser history, which appeared to show them trying to actively target organizations, craft phishing messages, find and access running instances of Evilginx, and more. We also have our suspicions that the operating machine where Huntress was installed is being used as a jump box by multiple threat actors—but we don’t have solid evidence to draw firm conclusions at this time.
Huntress analysts went to work evaluating the outstanding indicators of compromise found on the adversary’s host and how they related to data found within authentications to identities at Huntress. Retroactive hunts disclosed a further 20 identities which were compromised; many of which had been accessed by the adversary prior to Huntress’ deployment against the identity, whose activity was limited to refreshing session tokens to maintain access.
Overall, analysis of the adversary’s primary operating infrastructure, hosted on Autonomous System (AS) “12651980 CANADA INC.” (now known as VIRTUO) disclosed a pattern of access of over 2471 unique identities spanning the last two weeks– many of which were preemptively caught by additional detection capabilities such as malicious mail rule creation, or session token theft.
The intelligence gathered by the above has resulted in detections of high confidence against the adversary’s infrastructure; and equipped our systems and analysts to respond to these incidents in significantly less time and with extreme confidence in malice, eliminating adversarial attempts to evade our detections. 
All in all, we were able to see the threat actor’s specific day-to-day activities—from their methodologies to the specific types of organizations (and even individuals) they were interested in. We also saw them begin to tinker with tools and search for tutorials, attempting to learn more. For instance, after installing the Huntress agent, the threat actor took steps to better understand Autoruns.
Figure 4: The threat actor attempting to better understand Autoruns






Overall, over the course of three months we saw an evolution in terms of how the threat actor refined their processes, incorporated AI into their workflows, and targeted different organizations and vertical markets, as outlined in Figure 5 below.

Figure 5: An overview of some of the threat actor’s activities that we saw over the months


Below are some of the specific methodologies that we saw. 

Attacker methodologies
Use of AI for operational efficiency 
The Chrome browser history gave a first-hand look at how the adversary is using AI tools to increase the operational efficiency of their workflows. While there have previously been many reports on how cybercriminals are using AI (based on indicators in phishing messages or landing page content), this is the first time that we have a close-up view of a threat actor embedding AI into their operations in order to automate—and speed up—their workflow.
On May 25, the threat actor signed up for Make.com, which is legitimate workflow automation software, before researching the platform’s Telegram Bot integration feature as a way to launch automated processes (as seen in Figure 6 below). The threat actor then poked around several FAQ sites to better understand how Telegram Bot APIs work and how to set up webhooks.

Figure 6: Signing up for Make.com 



Figure 7: Digging deeper into Telegram Bot APIs


Over time, the threat actor started to get a better grasp of how they could use Make.com for specific workflows, and their browser history shows them starting to rely more heavily on the platform. By the time June 29 rolled around, the threat actor had fully developed their workflow with Make. As seen in Figure 8, the threat actor would first identify the organization of interest (typically after receiving a “tip” from Telegram) before using Google Translate to translate or craft messages related to these organizations. While we don’t have detailed insight into how the threat actor was using Make for these specific workflows, we can see that it was part of the process to automate specific functions. 



        Figure 8: Threat actor starts to rely on automated workflows
        The threat actor also appeared to be interested in other AI tools to help with data generation and writing. We saw multiple Google searches for “free ai no signup” and for “csv generator ai.” We also saw the threat actor using Toolbaz AI, which is a writing assistant; the CSV spreadsheet generator feature of DocsBot AI, which is an AI chatbot tool; and the AI data generator feature of Explo AI, which is an embedded analytics tool.
        
        Finding running instances of Evilginx
        We saw evidence of the threat actor searching for running instances of the Evilginx man-in-the-middle attack framework using Censys, and then attempting to access those instances.

        Figure 9: Using Censys to search for running instances of Evilginx

        
        
        Figure 10: One example of the Evilginx instance that the attacker tried to access

        
        In addition to Evilginx, we also found evidence of multiple installed tools on the threat actor’s system—or, in some cases, an interest in tools based on the threat actor browser history. These tools included recon and attack tool GraphSpy, open source tool Bloodhound, the TeamFiltration framework used for enumeration and exfiltration, and more.  

        Figure 11: Various tools that the attacker may have used


        
        Interest in residential proxy services
        The Chrome browser history also revealed visits by the threat actor to multiple residential proxy webpages, including LunaProxy and Nstbrowser (which bills itself as an anti-detect browser and supports the use of residential proxies). The threat actor visited the pricing plan page for LunaProxy, researched specific products, and looked up quick start guides throughout May, June, and July. Residential proxy services have become increasingly popular with threat actors as a way to route their traffic through residential IP addresses, allowing them to obscure malicious activity, like avoiding suspicious login alerts while using compromised credentials.

        Figure 12: A VirusTotal lookup of LunaProxy.exe, which was in the Chrome history


        
        Research and recon methods
        The Chrome browser history entries also gave us a close view of the attacker’s reconnaissance methods. The threat actor spent a lot of time researching companies across different sectors, from specific banks to “top real estate companies in the US” (also looking up “real estate agents in California”). 
        The threat actor didn’t just search for individual companies—they also looked at all parts of the ecosystem surrounding organizations of interest, from their customer bases to associated third-party companies across the supply chain. For example, the threat actor appeared to start targeting software companies in early July, searching for these types of companies via Google Search and using database marketing tools like ReadyContacts and InfoClutch to scope out how many customers they had and their market share. 
        The threat actor also used the BuiltWith platform, which lets users identify and analyze the technology stacks used by websites. On July 8, browser entries show the attacker conducting an extensive level of research on a prominent ecommerce vendor for managing payments and subscriptions, including a list of its customers, contacts, and market share. The threat actor then used BuiltWith to search for the websites relying on that vendor, before navigating to the BuiltWith sign up page, presumably to access that list.
        The threat actor conducted a fair amount of research into tools used to scrape Telegram group data, including looking at scraper tools like Apify, the Axiom Chrome extension, and the RapidAPI platform (Figure 13).

        Figure 13: While researching data scraping tools the threat actor came across RapidAPI  


        
        Use of Google Translate
        The threat actor used Google Translate extensively, and Chrome browser shows them first visiting bank websites, and then using the translation platform, likely to assist in crafting phishing-related messages, as seen in Figure 14. 

        Figure 14: The threat actor used Google Translate services extensively 



        The attacker often used urlscan to get information about various websites. Tips appear to have come in via Telegram using the getUpdates method.

        Figure 15: Part of the Chrome history around a particular tip

        
        
        Figure 16: Google Translate message

        
        
        Figure 17: Google Translate message: username and password

        
        
        Figure 18: Google Translate message: username and password

        
        There were several entries in the browser history that showed use of Google Translate to translate messages from Portuguese to English alongside browsing banks in Brazil, then evidence of crafting messages later on in their history. 

        
        


        


        
        
        Dark web: STYX market
        We also saw the threat actor express interest in STYX Market, a dark web forum that’s been around since 2023, and was recently called a “rising star for stealer logs, stolen creds, and laundering services” by researchers. After doing some initial research on STYX—as well as other Telegram chat groups and channels—they decided to check out the site for themselves, registering for an account before perusing the catalog of VoIP accounts, stealer logs, SIM cards, and more.

        Figure 19: The threat actor showed an interest in STYX Market


        
        Figure 20: A post from SOCRadar on STYX Market caught the threat actor’s attention 


        
        EDR activities
        Rarely do you ever get the chance to actually shoulder surf a real threat actor. We had such an opportunity when they installed our agent. It starts out mundane enough. We don’t know what they must have dreamed about after ending their shift at 2am UTC the previous night, but as mentioned earlier, you can see them start a trial, download the agent, and install it.

        Figure 21: At 2am UTC, after about 10 hours of inactivity, the threat actor suddenly showed an interest in Bitdefender, which led them to Huntress




        
        The most interesting activity for the start of their day on July 9, 2025 was browsing to urlscan.io to inspect login.incipientcroop[.]com. Shortly after, they logged into Make.com and began working on a project called Voltage_Office356bot (notice the typo). 

        Figure 22: Timeline of EDR and browser histories

        
        
        Figure 23: urlquery info for login.incipientcroop[.]com 

        
        
        Figure 24: Further down on the urlquery page for login.incipientcroop[.]com, there is evidence of Voltage_Office356bot

        
        There is evidence that the threat actor had access to cookie data for two different individuals, and accessed them via Notepad++. They proceeded to open the first file:
        C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram Desktop\Cookies_[victim1]@[redacted1][.].com.json
        Then they started looking around to see what they can find, with a Google search for “email osint”.

        Figure 25: Looking for “email osint”

        
        Next, they opened the second cookie file:
        C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram Desktop\Cookies_[victim2]@[redacted2][.].com.json
        They then started up Nstbrowser.exe and LunaProxy:
        C:\Program Files\Nstbrowser\Nstbrowser.exeC:\Program Files (x86)\LunaProxy_cata\socks5\LunaProxyDivert.exe  SOCK5 [snip]
        They browsed to an article titled Say Hello to your new cache flow by Synacktiv covering WHFB and Entra ID, followed by a Google search for “whfb prt”, which landed them on the website of a well-known researcher, Dirk-Jan Mollema. 
        They checked their IP address after this:
        C:\Windows\system32\curl.exe ipinfo[.]io
        And then checked their IP address again:
        C:\Windows\system32\curl.exe ipinfo[.]io
        They then tried to use a tool called ROADtools Token eXchange (roadtx):

        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe prtauth -r msgraph -c msteams
        And then erroneously tried to run the same tool (as an executable) via Python:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe  C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe prtauth -r msgraph -c msteams
        Then ran it again:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe describe
        And then tried to run it again, erroneously, using Python:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe  C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe describe
        They seemed to be having trouble. At this point they browsed to Dirk-jan Mollema’s post on Phishing for Microsoft Entra primary refresh tokens. 

        Figure 26: Searching for an answer with keyword whfb prt 

        
        While there, they gained some new inspiration, and discovered a handy little script that could make their life easier:

        Figure 27: Excerpt from Dirk-jan’s blog, pointing to a nifty little script

        
        At this point they went back to their Voltage_Office356bot project before running this new script they’ve downloaded.

        Figure 28: Accessing the Voltage_Office356bot project and running the attack script

        
        They started trying to run the Python script:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py -f roadtx.prt --wfb
        They checked the usage again:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py --wfb
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py -h
        Then, they started to run it against the original victim whose cookie file we saw earlier:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py --wfb -u [victim2]@[redacted2][.]com 
        They returned to the first victim’s cookie file:C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram Desktop\Cookies_[victim1]@[redacted1][.].com.json
        This is where our EDR data drops off, as they may have become aware of us and uninstalled the agent.
        
        Hours worked in a day
        The attacker’s browser history gives us an unprecedented level of insight into their everyday activity, searches, workflows, research, and more. The browser history shows the threat actor working intensively almost every day between the period of May 29, 2025 through July 9, 2025. 

        Figure 29: Chart of the number of hours per day (label alternates dates) worked based on browser activities


        On many of these days, the browser entries were seen across most hours of the day, logging 12 to 14 hours. But there was some variation, as seen in Figure 29, above: on several days, the threat actor worked as little as one to two hours.
        When we hone in on a few of the days when the most hours were put in, we can see some of the things that piqued the attacker’s interest in those days. We analyzed the urls to see what businesses, or categories they might have fallen into, and then looked to see how many times the attacker visited these sites. 
        We can see a few trends. During these days, the attacker spent a lot of time researching various banking entities and bank personnel. To further expand on some of the graph labels:
        
            
                Attack infra: Malicious websites or servers set up by an attacker (maybe not this one) hosting frameworks like Evilginx and other known tools.
            
            
                Banking: Various banking websites
            
            
                Browser extension: Various browser extensions like ad blockers, etc. installed by the attacker to protect themselves.
            
            
                Corporate & Business: Various business websites not housed under a different category.
            
            
                Crypto: Various cryptocurrency and blockchain websites.
            
            
                Cybersecurity: Various cybersecurity vendor websites. The attacker often signed up for trials at various vendors to test things.
            
            
                Government & military: Various official government or military websites.
            
            
                News, media & information: Various news websites like CNN etc.  The attacker often read articles related to various breaches.
            
            
                OSS: Open source projects, often housed at github or gitlab.
            
            
                Recon: Activities where the attacker was using Censys, Urlscan, Google, etc., to do reconnaissance for a particular target.
            
            
                Research: When the attacker was researching a particular vulnerability, tool, or attack.
            
            
                Sandbox: The attacker often seemed interested in various types of malware that were on VirusTotal, Joe’s Sandbox, and other online sandboxes.
            
            
                Social media: Various telegram, X, and other social media posts read by the attacker.
            
            
                Software: Various legitimate software, like 7zip.
            
            
                Telecommunications: A telecommunication website, like Verizon.
            
            
                Web & IT infrastructure: Various online hosting services, like Mega, Amazon AWS, and Azure. 
            
        

        Figure 30: Activities on May 29, 2025

        
        We can see that from May 29 to June 1, 2025, the attacker was mostly looking at various banking websites. Digging further into their activities, you see them researching various banks, reading about Telegram Bots, then downloading a blueprint from Make.

        Figure 31: A deeper look at some of the activities on May 29, 2025

        
        The next day, it seems that the attacker spent a little more time researching various attack infrastructure, in addition to focusing on banks, and similar activities seen previously.

        Figure 32: Activities on May 30, 2025

        
        On May 31, 2025 and June 1, 2025, the attacker switched their focus back to mostly researching banking websites.

        Figure 33: Activities on May 31, 2025

        
        
        Figure 34: Activities on June 1, 2025

        
        
        Figure 35: Regions Focused on by the Attacker from May 29 - June 1, 2025

        
        The other interesting thing was that the attacker was mostly focused on banks and sites that were in Nigeria during this time period, even looking for things like:“No. 1 regulated crypto exchange in Nigeria.”
        “top crypto companies nigeria”
        “Best Crypto Exchanges in Nigeria”“Top Cryptocurrency Companies in Nigeria”
        While we don’t know where the attacker is based, the machine they had installed our agent upon appeared to be based in the United States, on the West Coast, based on the machine’s internal time zone and IP address.

        Figure 36: Activities on July 9, 2025

        
        It seems that the attacker had spent quite some time looking at our various capabilities after they had started a trial with us. Figure 36 above shows just how much more time they spent interacting with the Huntress website, and particularly the account dashboard once they had started the trial.
        
        Lessons learned
        This incident gave us in-depth information about the day-to-day activities of a threat actor, from the tools they were interested in to the ways they conducted research and approached different aspects of attacks. 
        Upon confirming that the machine name was one used by an adversary, we decided to release these details because they give an invaluable understanding into the mindset and behaviors of threat actors behind attacks. For other defenders, we hope that this information can help add context around the ways that threat actors conduct research and launch attacks at the backend—and the different types of organizations, tools, and platforms that interest them. 
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Building a DOOM-like multiplayer shooter in pure SQL]]></title>
            <link>https://cedardb.com/blog/doomql/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183050</guid>
            <description><![CDATA[CedarDB is a database system that delivers unmatched performance for transactions and analytics, from small writes to handling billions of rows. Built on cutting-edge research to power today’s tools and tomorrow’s challenges.]]></description>
            <content:encoded><![CDATA[September 8, 2025 • 12 minutesDOOMQL: A DOOM-like multiplayer shooter in pure SQLI recently stumbled across Patrick’s excellent DOOM clone running in a browser powered by DuckDB-WASM.
Ever since I’ve read that, I wanted to push his awesome idea to the logical extreme: Build a multiplayer DOOM-like shooter entirely in SQL with CedarDB doing all the heavy lifting.
During a month of parental leave (i.e., a lot of sleepless nights), I tried exactly that.Here’s a sneak peek at DOOMQL:
Your browser does not support the video tag.DOOMQL in actionOkay, with the flashy demo out of the way, let’s talk about details.
What follows is a tour of the architecture, the SQL rendering pipeline, the game loop, and the fun metagame of cheating by issuing SQL commands against the database.Why even do this?Playing DuckDB DOOM in your browser is fun, but some things bugged me:
First of all, having parts of the rendering pipeline in Javascript felt like cheating. It worked well for DuckDB-Doom where everything is contained in a single HTML page, but I wanted to see if I could do everything in SQL. DuckDB-Doom is also a little bit stuttery with just 8 frames per second and has a pretty tiny viewport. I wanted to see if I could speed that up by switching over to CedarDB. I also wanted real sprites with transparency and they should move around believably in 3D space.
And most importantly, making the game multi-player should not just be possible, but easy, right? I got nerd-sniped by the perceived similarity of a database server to a traditional game server: Databases exist to synchronize shared state across clients. Thanks to transaction isolation, each player has a consistent view of the game world, no matter what the other clients are doing. Why not lean into that?
I would love to lie to you and claim I did it all to push CedarDB as an awesome database system but to be honest the database nerd in me just wanted to turn all knobs up to 11 and see what breaks.Architectural overviewAt a high levelState lives in tables (map, players, mobs, inputs, configs, sprites, …)Rendering is a stack of SQL views that implement raycasting and sprite projectionThe game loop is a tiny shell script that executes a SQL file ~ 30 times per second.The client is ~ 150 lines of Python: It polls for input and queries the database for your 3D view.You can play, observe other players and even cheat (by sending raw SQL).Game state, or: Let’s store everything in the databaseWith a database at hand, it’s natural to store all game configuration, state, and static data in the database:Config:CREATE TABLE config(
  player_move_speed NUMERIC DEFAULT 0.3, 
  player_turn_speed NUMERIC DEFAULT 0.2,
  ammo_max INT DEFAULT 10,
  ammo_refill_interval_seconds INT DEFAULT 2
  );
Map:CREATE TABLE map(x INT, y INT, tile CHAR);
Players and inputs:CREATE TABLE players (
  id INT REFERENCES mobs(id),
  score INT DEFAULT 0,
  hp INT DEFAULT 100,
  ammo INT DEFAULT 10,
  last_ammo_refill int default EXTRACT(EPOCH FROM (now()))::INT
);

CREATE TABLE inputs(
  player_id INT PRIMARY KEY REFERENCES players(id),
  action CHAR(1), -- 'w', 'a', 's', 'd', 'x' for shooting
  timestamp TIMESTAMP DEFAULT NOW()
);
Because everything is data, modding a running match is trivial:-- Change a setting
update config set ammo_max = 20;

 -- Add a player
insert into players values (...);

-- Move forward
update input set action = 'w' where player_id = <your_id>;

 -- Cheat (pls be smarter about it)
update players set hp = 100000 where player_id = <your_id>;

-- Ban cheaters (that weren't smart about it)
delete from players where hp > 100;
Renderer: When a VIEW becomes your 3D viewIf you squint enough, in DOOM, a 3D (or more correct: 2.5D) view is just a view over 2D state (i.e., the level map and any players/enemies on it).
Well, we’ve got VIEWS in SQL as well. They’re also just views on our (2D) state tables.
What’s stopping us from quite literally building a 3D “view” of our 2D map
using a simple raycasting algorithm?The pipeline:Send a set of rays from each player’s eye into the world, and see which map tiles are visibleCheck which walls the player sees, rendering them at the correct height and more or less solid based on the distanceProject mobs into the player’s camera spaceSelect sprite LODs based on depthExpand sprites into pixels, scaled to screen spaceOcclude against walls and other spritesAssemble frame buffer rows with string_aggBuild a minimap reusing the visible tiles calculation from earlierCombine the 3D view with minimap and HUD (HP/bullets/players) into a game viewLet’s take a more in-depth look at steps 2, 7, and 8.RaycastingThe recursive ray‑marching logic is adapted from Patrick’s DuckDB DOOM post. Here is a simplified excerpt, adapted for multiplayer:CREATE OR REPLACE VIEW visible_tiles AS  
WITH RECURSIVE raytrace AS (  
  -- Starting at the player's eye ...
  SELECT r.player_id, r.col, 1 AS step_count,  
         r.player_x + COS(r.angle)*s.step AS fx,  
         r.player_y + SIN(r.angle)*s.step AS fy,  
         r.angle, 0 AS dist  
  FROM rays r, settings s  -- rays are built in an earlier step
  UNION ALL  
  -- ... we recursively march along the rays, 1 "step" at a time ...
  SELECT rt.player_id, rt.col, rt.step_count + 1,  
         rt.fx + COS(rt.angle)*s.step,  
         rt.fy + SIN(rt.angle)*s.step,  
         rt.angle,  
         step_count * s.step * COS(rt.angle - m.dir) AS dist  
  FROM raytrace rt, settings s, players p, mobs m  
  WHERE rt.step_count < s.max_steps   -- ... stopping after our max render distance
    AND rt.player_id = p.id  
    AND m.id = p.id  
    AND NOT EXISTS (  -- or if we hit a wall
      SELECT 1 FROM map m  
      WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  
        AND m.tile = '#')  -- wall
)  
-- We then determine per player:
--  a) which tiles we hit
--  b) how far away these tiles are
--  c) the column of the screen each tile should correspond to
SELECT player_id, tile, CAST(fx AS INT) AS tile_x, CAST(fy AS INT) AS tile_y, col, MIN(dist) AS dist  
FROM raytrace rt, map m  
WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  -- We might hit the same tile multiple times, so we take the closest hit
GROUP BY player_id, tile_x, tile_y, tile, col;  
And that’s just the first step in the pipeline. For the rest, take a look at the code.Final frame assemblyAfter all the heavy lifting, the payoff is surprisingly simple:SELECT player_id, y, string_agg(ch, '' ORDER BY x) AS row  
FROM framebuffer  
GROUP BY player_id, y;  
This glues together character pixels into text rows.HUD + minimapThe same trick builds the HUD and minimap. Here is the health bar:'HP: [' ||
repeat('█', LEAST(20, ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
repeat(' ', GREATEST(0, 20 - ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
'] ' || GREATEST(0, p.hp)
Add ammo dots with repeat('•', p.ammo) and you’ve got a HUD entirely in SQL: 1: Lukas      (L) score: 1   HP: [█████████           ] 50    AMMO: ••••••••••
 2: Foobar     (F) score: 0   HP: [████████████████████] 100   AMMO: ••••••••  
We can also re-use our earlier visible_tiles view to build a minimap with a view cone:select * from minimap where player_id = 1 order by y;

 player_id | y  |                               row                                
-----------+----+------------------------------------------------------------------
         1 |  0 | ################################################################
         1 |  1 | ################################################################
         1 |  2 | ##.......      #####               #############################
         1 |  3 | ##.....F.      #####               #####                     ###
         1 |  4 | ##.......      #####               #####                     ###
         1 |  5 | ##  .....      #####               #####                     ###
         1 |  6 | ##   ...                                                     ###
         1 |  7 | ##    .L                                                     ###
         1 |  8 | ##             #####               #####                     ###
         1 |  9 | ##             #####               #####                     ###
         1 | 10 | ##             #############  ##########                     ###
         1 | 11 | ##########  ################  ##########                     ###
         1 | 12 | ##########  ################  ##########                     ###
         1 | 13 | ##########  ################  ######################  ##########
         1 | 14 | ####                 #######  ######################  ##########
         1 | 15 | ####                 #######  ######################  ##########
         1 | 16 | ####                 #####             #####                 ###
         1 | 17 | ####                 #####             #####                 ###
         1 | 18 | ####                 #####             #####                 ###
         1 | 19 | ####                 #####             #####                 ###
         1 | 20 | ####                 #####             #####                 ###
         1 | 21 | ####                                   #####                 ###
         1 | 22 | ####                                                         ###
         1 | 23 | ####                 #####                                   ###
         1 | 24 | ####                 #####             #####                 ###
         1 | 25 | ####                 #####             #####                 ###
         1 | 26 | ####                 #####             #####                 ###
         1 | 27 | ####                 #####             #####                 ###
         1 | 28 | ####                 #####             #####                 ###
         1 | 29 | ################################################################
         1 | 30 | ################################################################
         1 | 31 | ################################################################
The surprisingly elegant game loopThe loop is just a shell script running raw SQL against the database:# Game loop @ 30 ticks per second
while true; do
  psql -qtAX -U "$DB_USER" -d "$DB_NAME" -h "$DB_HOST" -p "$DB_PORT" -f gameloop.sql
  sleep 0.03
done
Inside gameloop.sql, actions like bullet movement, collisions, kills, and respawns run in a single transaction, which keeps state consistent even if something fails mid-tick.Here’s the part processing interactions with bullets:-- Process all bullets
BEGIN TRANSACTION;

-- Move bullets forward
UPDATE mobs 
SET x = x + cos(dir) * 0.5, y = y + sin(dir) * 0.5 
WHERE kind = 'bullet';

-- Delete bullets that are out of bounds
DELETE FROM mobs 
WHERE (x < 0 
OR x >= (select max(x) from map) 
OR y < 0 
OR y >= (select max(y) from map))
AND kind = 'bullet';

-- Delete bullets that hit walls
DELETE FROM mobs b 
WHERE EXISTS 
    (SELECT 1 
    FROM map m 
    WHERE m.x = CAST(b.x AS INT) 
    AND m.y = CAST(b.y AS INT) 
    AND m.tile = '#') 
AND kind = 'bullet';


-- Players hit by a bullet loses 50 HP
UPDATE players p SET hp = hp - 50
FROM collisions c
WHERE p.id = c.player_id;

-- If a player has 0 or less HP, the player killing them gets a point
UPDATE players p SET score = score + 1
FROM collisions c
WHERE p.id = c.bullet_owner
AND EXISTS (SELECT 1 FROM players p2 WHERE p2.id = c.player_id AND p2.hp <= 0);

-- Delete bullets that hit players
DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id;

-- Respawn players whose HP is 0 or less
UPDATE mobs m
SET x = r.x, y = r.y, dir = 0
FROM players p
CROSS JOIN (
  SELECT x, y
  FROM map
  WHERE tile = 'R'
  ORDER BY random()
  LIMIT 1
) AS r
WHERE m.id = p.id
  AND p.hp <= 0;

-- Reset players' HP to 100 and ammo to 10 after respawn
UPDATE players p SET
  hp = 100,
  ammo = 10
FROM mobs m
WHERE p.id = m.id
AND p.hp <= 0;

COMMIT;
On my machine, the game loop takes about 1 ms, so we could defintely improve the tick rate.
That might be a way to get the Counterstrike snobs who scoff at everything below 128 Hz.
It would require some refactoring on my part since I tied the movement speed to the game loop - a big no no in game design!While only someone insane could think a pure SQL raycasting renderer is a good idea in an actual game, I’ll happily defend this transactional game loop.
I don’t think this part would be much more concise or less brittle in a real game engine.Make it multiplayer in two queriesThe game client’s job description is simple:RenderSELECT full_row FROM screen WHERE player_id = <your_id> ORDER BY y
Send inputINSERT INTO inputs(player_id, action)
    VALUES (<your_id>, <pressed_key>)
    ON CONFLICT(player_id)
    DO UPDATE SET action = EXCLUDED.action
The game loop periodically checks the input table and moves all players accordingly - inside a transaction, of course, so we don’t run into any race conditions.That’s it (well, plus a one-time “create player” on first connect). The ~150 lines of Python in the client mostly handle keyboard input and reducing terminal flicker.
Bonus: The client provides an observer mode. All it has to do is swap the <player_id> in the render call.PerformanceAt 128 x 64 pixels, a single player view takes ~33 ms on my machine, which is enough for a breezy ~30 FPS, compared to DuckDB DOOM’s 8 FPS at just 32 x 16 pixels.
I’m actually quite proud of that performance and quite happy with CedarDB here.
I don’t think any other database system can keep up with that.
Let me know if you find one!You might worry that rendering the views of all players and filtering late would be very wasteful.
CedarDB’s query optimizer pushes the where player_id = <...> predicate through view boundaries, avoiding unncessary work.
You can easily check by running:select * from screen order by y; -- render both users
-- Time: 57,907 ms (~2x single player 33ms)
Because clients send raw SQL as superusers (I didn’t bother setting up any role based access control or row level security, don’t do that!), there’s an emergent metagame: Cheat creatively and try not to get caught.Low effort:update players set score = 0 where id != <your_id>;
update players set hp = 0 where id != <your_id>;
Mischievous:update inputs set action = null where player_id != <your_id>;
Steal kills:update mobs set owner = <your_id> where kind = 'bullet';
Attempted but didn’t work:DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id AND c.player_id = <your_id>;
This doesn’t work because moving bullets, checking for collisions, and respawn happens in the same transaction.
As transactions are atomic, you either see everything being applied at once, or nothing. By the time you see the hit, you’re already dead.
A property that’s very useful for database systems (and not just to prevent cheating).What I learnedI set out to see if I could push Patrick’s demo to an extreme: Doing the entire rendering pipeline in SQL.
And while it works, I have to admit that it is a pretty… bad idea? Fast enough, but horrible to maintain and debug.The surprise was how natural it felt to express game state and logic in SQL.
It even felt like accidentally re-invented the entity-component-system pattern.And multiplayer “just worked” because the database system which handles all the nasty concurrency is the source of truth.Try it yourself!All the code is on Github: DOOMQL RepoRun:docker pull cedardb/cedardb:latest
docker run --rm -p 5432:5432 -e CEDAR_PASSWORD=postgres --detach cedardb/cedardb:latest
# Wait a few seconds for CedarDB to start
./server.sh

# in a second terminal window, zoom way out to have no line wraping issues
python3 pyclient.py
Want to discuss DOOMQL with me or find like-minded database nerds? Join our Community Slack]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[We all dodged a bullet]]></title>
            <link>https://xeiaso.net/notes/2025/we-dodged-a-bullet/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183029</guid>
            <description><![CDATA[That NPM attack could have been so much worse.]]></description>
            <content:encoded><![CDATA[ Loading...Please wait a moment while we ensure the security of your connection.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A new experimental Go API for JSON]]></title>
            <link>https://go.dev/blog/jsonv2-exp</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182770</guid>
            <description><![CDATA[Go 1.25 introduces experimental support for encoding/json/jsontext and encoding/json/v2 packages.]]></description>
            <content:encoded><![CDATA[
      Joe Tsai, Daniel Martí, Johan Brandhorst-Satzkorn, Roger Peppe, Chris Hines,  and Damien Neil
      9 September 2025
      
Introduction
JavaScript Object Notation (JSON)
is a simple data interchange format. Almost 15 years ago,
we wrote about support for JSON in Go,
which introduced the ability to serialize and deserialize Go types to and from JSON data.
Since then, JSON has become the most popular data format used on the Internet.
It is widely read and written by Go programs,
and encoding/json now ranks as the 5th most imported Go package.
Over time, packages evolve with the needs of their users,
and encoding/json is no exception. This blog post is about Go 1.25’s new
experimental encoding/json/v2 and encoding/json/jsontext packages,
which bring long-awaited improvements and fixes.
This post argues for a new major API version,
provides an overview of the new packages,
and explains how you can make use of it.
The experimental packages are not visible by default and
may undergo future API changes.
Problems with encoding/json
Overall, encoding/json has held up well.
The idea of marshaling and unmarshaling arbitrary Go types
with some default representation in JSON, combined with the ability to
customize the representation, has proven to be highly flexible.
However, in the years since its introduction,
various users have identified numerous shortcomings.
Behavior flaws
There are various behavioral flaws in encoding/json:


Imprecise handling of JSON syntax: Over the years, JSON has seen
increased standardization in order for programs to properly communicate.
Generally, decoders have become stricter at rejecting ambiguous inputs,
to reduce the chance that two implementations will have different
(successful) interpretations of a particular JSON value.


encoding/json currently accepts invalid UTF-8,
whereas the latest Internet Standard (RFC 8259) requires valid UTF-8.
The default behavior should report an error in the presence of invalid UTF-8,
instead of introducing silent data corruption,
which may cause problems downstream.


encoding/json currently accepts objects with duplicate member names.
RFC 8259 does not specify how to handle duplicate names,
so an implementation is free to choose an arbitrary value,
merge the values, discard the values, or report an error.
The presence of a duplicate name results in a JSON value
without a universally agreed upon meaning.
This could be exploited by attackers in security applications
and has been exploited before (as in CVE-2017-12635).
The default behavior should err on the side of safety and reject duplicate names.




Leaking nilness of slices and maps: JSON is often used to communicate with
programs using JSON implementations that do not allow null to be unmarshaled
into a data type expected to be a JSON array or object.
Since encoding/json marshals a nil slice or map as a JSON null,
this may lead to errors when unmarshaling by other implementations.
A survey
indicated that most Go users prefer that nil slices and maps
are marshaled as an empty JSON array or object by default.


Case-insensitive unmarshaling: When unmarshaling, a JSON object member name
is resolved to a Go struct field name using a case-insensitive match.
This is a surprising default, a potential security vulnerability, and a performance limitation.


Inconsistent calling of methods: Due to an implementation detail,
MarshalJSON methods declared on a pointer receiver
are inconsistently called by encoding/json. While regarded as a bug,
this cannot be fixed as too many applications depend on the current behavior.


API deficiencies
The API of encoding/json can be tricky or restrictive:


It is difficult to correctly unmarshal from an io.Reader.
Users often write json.NewDecoder(r).Decode(v),
which fails to reject trailing junk at the end of the input.


Options can be set on the Encoder and Decoder types,
but cannot be used with the Marshal and Unmarshal functions.
Similarly, types implementing the Marshaler and Unmarshaler interfaces
cannot make use of the options and there is no way to plumb options down the call stack.
For example, the Decoder.DisallowUnknownFields option loses its effect
when calling a custom UnmarshalJSON method.


The Compact, Indent, and HTMLEscape functions write to a bytes.Buffer
instead of something more flexible like a []byte or io.Writer.
This limits the usability of those functions.


Performance limitations
Setting aside internal implementation details,
the public API commits it to certain performance limitations:


MarshalJSON: The MarshalJSON interface method forces the implementation
to allocate the returned []byte. Also, the semantics require that
encoding/json verify that the result is valid JSON
and also to reformat it to match the specified indentation.


UnmarshalJSON: The UnmarshalJSON interface method requires that
a complete JSON value be provided (without any trailing data).
This forces encoding/json to parse the JSON value to be unmarshaled
in its entirety to determine where it ends before it can call UnmarshalJSON.
Afterwards, the UnmarshalJSON method itself must parse the provided JSON value again.


Lack of streaming: Even though the Encoder and Decoder types operate
on an io.Writer or io.Reader, they buffer the entire JSON value in memory.
The Decoder.Token method for reading individual tokens is allocation-heavy
and there is no corresponding API for writing tokens.


Furthermore, if the implementation of a MarshalJSON or UnmarshalJSON method
recursively calls the Marshal or Unmarshal function,
then the performance becomes quadratic.
Trying to fix encoding/json directly
Introducing a new, incompatible major version of a package is a heavy consideration.
If possible, we should try to fix the existing package.
While it is relatively easy to add new features,
it is difficult to change existing features.
Unfortunately, these problems are inherent consequences of the existing API,
making them practically impossible to fix within the Go 1 compatibility promise.
We could in principle declare separate names, such as MarshalV2 or UnmarshalV2,
but that is tantamount to creating a parallel namespace within the same package.
This leads us to encoding/json/v2 (henceforth called v2),
where we can make these changes within a separate v2 namespace
in contrast to encoding/json (henceforth called v1).
Planning for encoding/json/v2
The planning for a new major version of encoding/json spanned years.
In late 2020, spurred on by the inability to fix issues in the current package,
Daniel Martí (one of the maintainers of encoding/json) first drafted his
thoughts on what a hypothetical v2 package should look like.
Separately, after previous work on the Go API for Protocol Buffers,
Joe Tsai was disapppointed that the protojson package
needed to use a custom JSON implementation because encoding/json was
neither capable of adhering to the stricter JSON standard that the
Protocol Buffer specification required,
nor of efficiently serializing JSON in a streaming manner.
Believing a brighter future for JSON was both beneficial and achievable,
Daniel and Joe joined forces to brainstorm on v2 and
started to build a prototype
(with the initial code being a polished version of the JSON serialization logic from the Go protobuf module).
Over time, a few others (Roger Peppe, Chris Hines, Johan Brandhorst-Satzkorn, and Damien Neil)
joined the effort by providing design review, code review, and regression testing.
Many of the early discussions are publicly available in our
recorded meetings and
meeting notes.
This work has been public since the beginning,
and we increasingly involved the wider Go community,
first with a
GopherCon talk and
discussion posted in late 2023,
formal proposal posted in early 2025,
and most recently adopting encoding/json/v2 as a Go experiment
(available in Go 1.25) for wider-scale testing by all Go users.
The v2 effort has been going on for 5 years,
incorporating feedback from many contributors and also gaining valuable
empirical experience from use in production settings.
It’s worth noting that it’s largely been developed and promoted by people
not employed by Google, demonstrating that the Go project is a collaborative endeavor
with a thriving global community dedicated to improving the Go ecosystem.
Building on encoding/json/jsontext
Before discussing the v2 API, we first introduce the experimental
encoding/json/jsontext package
that lays the foundation for future improvements to JSON in Go.
JSON serialization in Go can be broken down into two primary components:

syntactic functionality that is concerned with processing JSON based on its grammar, and
semantic functionality that defines the relationship between JSON values and Go values.

We use the terms “encode” and “decode” to describe syntactic functionality and
the terms “marshal” and “unmarshal” to describe semantic functionality.
We aim to provide a clear distinction between functionality
that is purely concerned with encoding versus that of marshaling.
This diagram provides an overview of this separation.
Purple blocks represent types, while blue blocks represent functions or methods.
The direction of the arrows approximately represents the flow of data.
The bottom half of the diagram, implemented by the jsontext package,
contains functionality that is only concerned with syntax,
while the upper half, implemented by the json/v2 package,
contains functionality that assigns semantic meaning to syntactic data
handled by the bottom half.
The basic API of jsontext is the following:
package jsontext

type Encoder struct { ... }
func NewEncoder(io.Writer, ...Options) *Encoder
func (*Encoder) WriteValue(Value) error
func (*Encoder) WriteToken(Token) error

type Decoder struct { ... }
func NewDecoder(io.Reader, ...Options) *Decoder
func (*Decoder) ReadValue() (Value, error)
func (*Decoder) ReadToken() (Token, error)

type Kind byte
type Value []byte
func (Value) Kind() Kind
type Token struct { ... }
func (Token) Kind() Kind

The jsontext package provides functionality for interacting with JSON
at a syntactic level and derives its name from
RFC 8259, section 2
where the grammar for JSON data is literally called JSON-text.
Since it only interacts with JSON at a syntactic level,
it does not depend on Go reflection.
The Encoder and
Decoder
provide support for encoding and decoding JSON values and tokens.
The constructors
accept variadic options
that affect the particular behavior of encoding and decoding.
Unlike the Encoder and Decoder types declared in v1,
the new types in jsontext avoid muddling the distinction between syntax and
semantics and operate in a truly streaming manner.
A JSON value is a complete unit of data and is represented in Go as
a named []byte.
It is identical to RawMessage in v1.
A JSON value is syntactically composed of one or more JSON tokens.
A JSON token is represented in Go as the opaque Token type
with constructors and accessor methods.
It is analogous to Token in v1
but is designed represent arbitrary JSON tokens without allocation.
To resolve the fundamental performance problems with
the MarshalJSON and UnmarshalJSON interface methods,
we need an efficient way of encoding and decoding JSON
as a streaming sequence of tokens and values.
In v2, we introduce the MarshalJSONTo and UnmarshalJSONFrom interface methods
that operate on an Encoder or Decoder, allowing the methods’ implementations
to process JSON in a purely streaming manner. Thus, the json package need not
be responsible for validating or formatting a JSON value returned by MarshalJSON,
nor would it need to be responsible for determining the boundaries of a JSON value
provided to UnmarshalJSON. These responsibilities belong to the Encoder and Decoder.
Introducing encoding/json/v2
Building on the jsontext package, we now introduce the experimental
encoding/json/v2 package.
It is designed to fix the aforementioned problems,
while remaining familiar to users of the v1 package.
Our goal is that usages of v1 will operate mostly the same if directly migrated to v2.
In this article, we will primarily cover the high-level API of v2.
For examples on how to use it, we encourage readers to
study the examples in the v2 package or
read Anton Zhiyanov’s blog covering the topic.
The basic API of v2 is the following:
package json

func Marshal(in any, opts ...Options) (out []byte, err error)
func MarshalWrite(out io.Writer, in any, opts ...Options) error
func MarshalEncode(out *jsontext.Encoder, in any, opts ...Options) error

func Unmarshal(in []byte, out any, opts ...Options) error
func UnmarshalRead(in io.Reader, out any, opts ...Options) error
func UnmarshalDecode(in *jsontext.Decoder, out any, opts ...Options) error

The Marshal
and Unmarshal functions
have a signature similar to v1, but accept options to configure their behavior.
The MarshalWrite
and UnmarshalRead functions
directly operate on an io.Writer or io.Reader,
avoiding the need to temporarily construct an Encoder or Decoder
just to write or read from such types.
The MarshalEncode
and UnmarshalDecode functions
operate on a jsontext.Encoder and jsontext.Decoder and
is actually the underlying implementation of the previously mentioned functions.
Unlike v1, options are a first-class argument to each of the marshal and unmarshal functions,
greatly extending the flexibility and configurability of v2.
There are several options available
in v2 which are not covered by this article.
Type-specified customization
Similar to v1, v2 allows types to define their own JSON representation
by satisfying particular interfaces.
type Marshaler interface {
    MarshalJSON() ([]byte, error)
}
type MarshalerTo interface {
    MarshalJSONTo(*jsontext.Encoder) error
}

type Unmarshaler interface {
    UnmarshalJSON([]byte) error
}
type UnmarshalerFrom interface {
    UnmarshalJSONFrom(*jsontext.Decoder) error
}

The Marshaler
and Unmarshaler interfaces
are identical to those in v1.
The new MarshalerTo
and UnmarshalerFrom interfaces
allow a type to represent itself as JSON using a jsontext.Encoder or jsontext.Decoder.
This allows options to be forwarded down the call stack, since options
can be retrieved via the Options accessor method on the Encoder or Decoder.
See the OrderedObject example
for how to implement a custom type that maintains the ordering of JSON object members.
Caller-specified customization
In v2, the caller of Marshal and Unmarshal can also specify
a custom JSON representation for any arbitrary type,
where caller-specified functions take precedence over type-defined methods
or the default representation for a particular type.
func WithMarshalers(*Marshalers) Options

type Marshalers struct { ... }
func MarshalFunc[T any](fn func(T) ([]byte, error)) *Marshalers
func MarshalToFunc[T any](fn func(*jsontext.Encoder, T) error) *Marshalers

func WithUnmarshalers(*Unmarshalers) Options

type Unmarshalers struct { ... }
func UnmarshalFunc[T any](fn func([]byte, T) error) *Unmarshalers
func UnmarshalFromFunc[T any](fn func(*jsontext.Decoder, T) error) *Unmarshalers

MarshalFunc and
MarshalToFunc
construct a custom marshaler that can be passed to a Marshal call
using WithMarshalers to override the marshaling of particular types.
Similarly,
UnmarshalFunc and
UnmarshalFromFunc
support similar customization for Unmarshal.
The ProtoJSON example
demonstrates how this feature allows serialization of all
proto.Message types
to be handled by the protojson package.
Behavior differences
While v2 aims to behave mostly the same as v1,
its behavior has changed in some ways
to address problems in v1, most notably:


v2 reports an error in the presence of invalid UTF-8.


v2 reports an error if a JSON object contains a duplicate name.


v2 marshals a nil Go slice or Go map as an empty JSON array or JSON object, respectively.


v2 unmarshals a JSON object into a Go struct using a
case-sensitive match from the JSON member name to the Go field name.


v2 redefines the omitempty tag option to omit a field if it would have
encoded as an “empty” JSON value (which are null, "", [], and {}).


v2 reports an error when trying to serialize a time.Duration,
which currently has no default representation,
but provides options to let the caller decide.


For most behavior changes, there is a struct tag option or caller-specified option
that can configure the behavior to operate under v1 or v2 semantics,
or even other caller-determined behavior.
See “Migrating to v2” for more information.
Performance optimizations
The Marshal performance of v2 is roughly at parity with v1.
Sometimes it is slightly faster, but other times it is slightly slower.
The Unmarshal performance of v2 is significantly faster than v1,
with benchmarks demonstrating improvements of up to 10x.
In order to obtain greater performance gains,
existing implementations of
Marshaler and
Unmarshaler should
migrate to also implement
MarshalerTo and
UnmarshalerFrom,
so that they can benefit from processing JSON in a purely streaming manner.
For example, recursive parsing of OpenAPI specifications in UnmarshalJSON methods
significantly hurt performance in a particular service of Kubernetes
(see kubernetes/kube-openapi#315),
while switching to UnmarshalJSONFrom improved performance by orders of magnitude.
For more information, see the
go-json-experiment/jsonbench
repository.
Retroactively improving encoding/json
We want to avoid two separate JSON implementations in the Go standard library,
so it is critical that, under the hood, v1 is implemented in terms of v2.
There are several benefits to this approach:


Gradual migration: The Marshal and Unmarshal functions in v1 or v2
represent a set of default behaviors that operate according to v1 or v2 semantics.
Options can be specified that configure Marshal or Unmarshal to operate with
entirely v1, mostly v1 with a some v2, a mix of v1 or v2,
mostly v2 with some v1, or entirely v2 semantics.
This allows for gradual migration between the default behaviors of the two versions.


Feature inheritance: As backward-compatible features are added to v2,
they will inherently be made available in v1. For example, v2 adds
support for several new struct tag options such as inline or format and also
support for the MarshalJSONTo and UnmarshalJSONFrom interface methods,
which are both more performant and flexible.
When v1 is implemented in terms of v2, it will inherit support for these features.


Reduced maintenance: Maintenance of a widely used package demands significant effort.
By having v1 and v2 use the same implementation, the maintenance burden is reduced.
In general, a single change will fix bugs, improve performance, or add functionality to both versions.
There is no need to backport a v2 change with an equivalent v1 change.


While select parts of v1 may be deprecated over time (supposing v2 graduates from being an experiment),
the package as a whole will never be deprecated.
Migrating to v2 will be encouraged, but not required.
The Go project will not drop support for v1.
Experimenting with jsonv2
The newer API in the encoding/json/jsontext and encoding/json/v2 packages are not visible by default.
To use them, build your code with GOEXPERIMENT=jsonv2 set in your environment or with the goexperiment.jsonv2 build tag.
The nature of an experiment is that the API is unstable and may change in the future.
Though the API is unstable, the implementation is of a high quality and
has been successfully used in production by several major projects.
The fact that v1 is implemented in terms of v2 means that the underlying implementation of v1
is completely different when building under the jsonv2 experiment.
Without changing any code, you should be able to run your tests
under jsonv2 and theoretically nothing new should fail:
GOEXPERIMENT=jsonv2 go test ./...

The re-implementation of v1 in terms of v2 aims to provide identical behavior
within the bounds of the Go 1 compatibility promise,
though some differences might be observable such as the exact wording of error messages.
We encourage you to run your tests under jsonv2 and
report any regressions on the issue tracker.
Becoming an experiment in Go 1.25 is a significant milestone on the road to
formally adopting encoding/json/jsontext and encoding/json/v2 into the standard library.
However, the purpose of the jsonv2 experiment is to gain broader experience.
Your feedback will determine our next steps, and the outcome of this experiment,
which may result in anything from abandonment of the effort, to adoption as stable packages of Go 1.26.
Please share your experience on go.dev/issue/71497, and help determine the future of Go.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[US High school students' scores fall in reading and math]]></title>
            <link>https://apnews.com/article/naep-reading-math-scores-12th-grade-c18d6e3fbc125f12948cc70cb85a520a</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182657</guid>
            <description><![CDATA[A decade-long slide in high school students’ performance in reading and math persisted during the COVID-19 pandemic, with 12th graders’ scores dropping to their lowest level in more than 20 years. That's according to results released Tuesday from an exam known as the nation’s report card. Eighth-grade students also lost significant ground in science skills, according to the results from the National Assessment of Education Progress. The assessments were the first since the pandemic for eighth graders in science and 12th graders in reading and math. They reflect a downward drift across grade levels and subject areas in previous releases from NAEP.]]></description>
            <content:encoded><![CDATA[
                                        WASHINGTON (AP) — A decade-long slide in high schoolers’ reading and math performance persisted during the COVID-19 pandemic, with 12th graders’ scores dropping to their lowest level in more than 20 years, according to results released Tuesday from an exam known as the nation’s report card.Eighth-grade students also lost significant ground in science skills, according to the results from the National Assessment of Education Progress.The assessments were the first since the pandemic for eighth graders in science and 12th graders in reading and math. They reflect a downward drift across grade levels and subject areas in previous releases from NAEP, which is considered one of the best gauges of the academic progress of U.S. schools.“Scores for our lowest-performing students are at historic lows,” said Matthew Soldner, the acting commissioner of the National Center for Education Statistics. “These results should galvanize all of us to take concerted and focused action to accelerate student learning.”
    
While the pandemic had an outsize impact on student achievement, experts said falling scores are part of a longer arc in education that cannot be attributed solely to COVID-19, school closures and related issues such as heightened absenteeism. Educators said potential underlying factors include children’s increased screen time, shortened attention spans and a decline in reading longer-form writing both in and out of school.



The dip in reading scores appeared alongside a shift in how English and language arts are taught in schools, with an emphasis on short texts and book excerpts, said Carol Jago, associate director of the California Reading and Literature Project at UCLA. As a high school English teacher 20 years ago, Jago said it was common for her high school students to read 20 books over the course of a year. Now, some English classes are assigning just three books a year.
    
    
    
“To be a good reader, you have to have the stamina to stay on the page, even when the going gets tough,” Jago said. “You have to build those muscles, and we’re not building those muscles in kids.”
    
    
    

    
Education Secretary Linda McMahon said the scores show why the Trump administration wants to give states more control of education spending.“Despite spending billions annually on numerous K-12 programs, the achievement gap is widening, and more high school seniors are performing below the basic benchmark in math and reading than ever before,” McMahon said.House Democrats said the Trump administration’s efforts to dismantle the Education Department will only hurt students. The declines show a need for federal investment in academic recovery and educational equity, said Democratic Rep. Bobby Scott of Virginia, ranking member of the House Committee on Education and Workforce.“Eliminating the very agency responsible for supporting public schools and enforcing civil rights protections of students will only deepen the achievement gaps identified by this assessment,” Scott said.
    
Fewer students show basic proficiency in math and readingThe test scores show more students are not reaching what would be considered “basic” achievement across subject areas, said Lesley Muldoon, executive director of the National Assessment Governing Board. While NAEP’s definition of “proficient” is a high bar, Muldoon said, it is not an unreasonable one, and it is based on what researchers believe students should be able to achieve by the end of high school.“These students are taking their next steps in life with fewer skills and less knowledge in core academics than their predecessors a decade ago,” she said. “This is happening at a time when rapid advancements in technology and society demands more of future workers and citizens, not less.”In reading, the average score in 2024 was the lowest score in the history of the assessment, which began in 1992. Thirty-two percent of high school seniors scored below “basic,” meaning they were not able to find details in a text to help them understand its meaning.In math, the average score in 2024 was the lowest since 2005, when the assessment framework changed significantly. On the test, 45% of high school seniors scored below “basic” achievement, the highest percentage since 2005. Only 33% of high school seniors were considered academically prepared for college-level math courses, a decline from 37% in 2019.
    
The high school reading and math assessments, and the eighth grade science test, are given less frequently than the biannual fourth and eighth grade reading tests, which were last released earlier this year. The new scores reflect tests taken in schools around the country between January and March 2024.
    
Achievement gaps are wideningThe gap between the highest- and lowest-performing students was its widest ever among eighth grade science students, reflecting growing inequality in the American school system. The achievement gap widened also in 12th grade math.The scores also reflect the re-emergence of a gender gap in science, technology, engineering and math courses. In 2019, boys and girls scored virtually the same on the NAEP science assessment. But in 2024, girls saw a steeper decline in scores. A similar pattern occurred in state math assessments, according to an Associated Press analysis.Schools had largely closed the gender gap in math and science, but it widened in the years following the pandemic as special programs to engage girls lapsed.On a NAEP survey of students, a shrinking percentage of eighth grade students said they regularly took part in inquiry-based learning activities in the classroom. The pandemic disrupted schools’ ability to create those hands-on learning experiences for students, which are often critical to understanding scientific concepts and processes, said Christine Cunningham, senior vice president of STEM learning at the Museum of Science in Boston.Still, she noted declines across subjects began well before schools closed in 2020.“We don’t know exactly what the cause of it is, but it would be incomplete to assume that if we hadn’t had COVID, the score would not have gone down,” Cunningham said. “That’s not what the data showed even before the pandemic.” ___Feathers reported from New York.___The Associated Press’ education coverage receives financial support from multiple private foundations. AP is solely responsible for all content. Find AP’s standards for working with philanthropies, a list of supporters and funded coverage areas at AP.org.
                                    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude now has access to a server-side container environment]]></title>
            <link>https://www.anthropic.com/news/create-files</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182381</guid>
            <description><![CDATA[Claude can now create and edit Excel spreadsheets, documents, PowerPoint slide decks, and PDFs directly in Claude.ai and the desktop app.]]></description>
            <content:encoded><![CDATA[Claude can now create and edit Excel spreadsheets, documents, PowerPoint slide decks, and PDFs directly in Claude.ai and the desktop app. This transforms how you work with Claude—instead of only receiving text responses or in-app artifacts, you can describe what you need, upload relevant data, and get ready-to-use files in return.File creation is now available as a preview for Max, Team, and Enterprise plan users. Pro users will get access in the coming weeks.What you can doClaude creates actual files from your instructions—whether working from uploaded data, researching information, or building from scratch. Here are just a few examples:Turn data into insights: Give Claude raw data and get back polished outputs with cleaned data, statistical analysis, charts, and written insights explaining what matters.Build spreadsheets: Describe what you need—financial models with scenario analysis, project trackers with automated dashboards, or budget templates with variance calculations. Claude creates it with working formulas and multiple sheets.Cross-format work: Upload a PDF report and get PowerPoint slides. Share meeting notes and get a formatted document. Upload invoices and get organized spreadsheets with calculations. Claude handles the tedious work and presents information how you need it.Whether you need a customer segmentation analysis, sales forecasting, or budget tracking, Claude handles the technical work and produces the files you need. File creation turns projects that normally require programming expertise, statistical knowledge, and hours of effort into minutes of conversation.How it works: Claude’s computerOver the past year we've seen Claude move from answering questions to completing entire projects, and now we're making that power more accessible. We've given Claude access to a private computer environment where it can write code and run programs to produce the files and analyses you need.This transforms Claude from an advisor into an active collaborator. You bring the context and strategy; Claude handles the technical implementation behind the scenes. This shows where we’re headed: making sophisticated multi-step work accessible through conversation. As these capabilities expand, the gap between idea and execution will keep shrinking.Getting startedTo start creating files:Enable "Upgraded file creation and analysis" under Settings > Features > ExperimentalUpload relevant files or describe what you needGuide Claude through the work via chatDownload your completed files or save directly to Google DriveStart with straightforward tasks like data cleaning or simple reports, then work up to complex projects like financial models once you're comfortable with how Claude handles files.This feature gives Claude internet access to create and analyze files, which may put your data at risk. Monitor chats closely when using this feature. Learn more.]]></content:encoded>
        </item>
    </channel>
</rss>