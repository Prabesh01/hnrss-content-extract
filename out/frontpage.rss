<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Sun, 14 Sep 2025 16:08:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Writing an operating system kernel from scratch]]></title>
            <link>https://popovicu.com/posts/writing-an-operating-system-kernel-from-scratch/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45240682</guid>
            <description><![CDATA[Exploring a minimal implementation of a time-sharing kernel on RISC-V, implemented in Zig, on top of OpenSBI.]]></description>
            <content:encoded><![CDATA[
      Follow @popovicu94
I recently implemented a minimal proof of concept time-sharing operating system kernel on RISC-V. In this post, I’ll share the details of how this prototype works. The target audience is anyone looking to understand low-level system software, drivers, system calls, etc., and I hope this will be especially useful to students of system software and computer architecture.
This is a redo of an exercise I did for my undergraduate course in operating systems, and functionally it should resemble a typical operating systems project. However, this experiment focuses on modern tooling, as well as the modern architecture of RISC-V. RISC-V is an amazing technology that is easy to understand more quickly than other CPU architectures, while remaining a popular choice for many new systems, not just an educational architecture.
Finally, to do things differently here, I implemented this exercise in Zig, rather than traditional C. In addition to being an interesting experiment, I believe Zig makes this experiment much more easily reproducible on your machine, as it’s very easy to set up and does not require any installation (which could otherwise be slightly messy when cross-compiling to RISC-V).
Table of contents
Open Table of contents


GitHub repo


Recommended reading


Unikernel


SBI layer


Goal for the kernel


Virtualization and what exactly is a thread

The stack and memory virtualization
Virtualizing a thread
Interrupt context



Implementation (high-level)

Leveraging the interrupt stack convention
Kernel/user space separation



Implementation (code)

Assembly startup
Main kernel file and I/O drivers
S-mode handler and the context switch
The user space threads
Running the kernel



Conclusion



GitHub repo
The final code for this experiment is on GitHub here. We’ll be referencing the code from it as we go.
GitHub should be the source of truth and may be slightly out of sync with the code below.
Recommended reading
The basic fundamentals of computer engineering and specifically computer architecture are assumed. Specifically, knowledge of registers, how the CPU addresses memory, and interrupts is all necessary.
Before diving deep into this experiment, it’s recommended to also review the following background texts:

Bare metal programming on RISC-V
RISC-V boot process with SBI
RISC-V interrupts with a timer example
Optional - Making a micro Linux distro - mainly for the brief philosophy on the kernel / user space split

Unikernel
We’ll be developing a type of unikernel. Simply put, this setup links the application code directly with the OS kernel it depends on. Essentially, everything is bundled into a single binary executable, and the user code is loaded into memory alongside the kernel.
This bypasses the need to separately load the user code at runtime, which is a complex field in itself (involving linkers, loaders, etc.).
SBI layer
RISC-V supports a layered permissions model. The system boots into machine mode (M), which is completely bare-metal, and then supports a couple of other less privileged modes. Please check the background texts for more details; below is a quick summary:

M-mode can do pretty much anything; it is fully bare-metal.
In the middle is S-mode, supervisor, which typically hosts the operating system kernel.
At the bottom is U-mode, user, where application code runs.

Lower privilege levels can send requests to higher privilege levels.
We’ll assume that at the bottom of our software stack is an SBI layer, specifically OpenSBI. Please study this text for the necessary background, as we’ll use the SBI layer to manage console printing and control the timer hardware. While manual implementation is possible, I wanted to add more value to this text by demonstrating a more portable approach with OpenSBI.
Goal for the kernel
We want to support a few key features for simplicity:

Statically define threads ahead of execution; i.e., dynamic thread creation is not supported. Additionally, for simplicity, threads are implemented as never-ending functions.
Threads operate in user mode and are able to send system calls to the kernel operating in S-mode.
Time is sliced and allocated among different threads. The system timer will be set to tick every couple of milliseconds, at which point a thread may be switched out.

Finally, development is targeted for a single-core machine.
Virtualization and what exactly is a thread
Before implementing threads, we should decide what they really are. The concept of threads in a time-sharing environment enables multiple workloads to run on a single core (as noted above, we’re focusing on single-core machines), while the programming model for each thread remains largely the same as if it were the sole software on the machine. This is a loose definition, which we will refine.
To understand time-sharing, let’s briefly consider its contrast: cooperative scheduling/threading. In cooperative scheduling/threading, a thread voluntarily yields CPU time to another workload. Eventually, the expectation is that another thread will yield control back to the first.
function thread():
  operation_1();
  operation_2();
  YIELD();
  operation_3();
  YIELD();
  ...
To be clear, this isn’t an “outdated” technique, despite being older. In fact, it’s alive and well in many modern programming languages and their runtimes (often abstracted from programmers). One good example is Go, which uses Goroutines to run multiple workloads on top of one operating system thread. While programmers don’t necessarily add explicit yield operations, the compiler and runtime can inject them into the workload.
Now, it should be clearer what it means for the programming model to remain largely the same in a time-sharing context. The thread would naturally look like this:
function thread():
  operation_1();
  operation_2();
  operation_3();
  ...
There are simply no explicit yield operations; instead, the kernel utilizes timers and interrupts to seamlessly switch between threads on the same core. This is precisely what we’ll implement in this experiment.
When multiple workloads run on the same resource, and each retains the same programming model as if it were the only workload, we can say the resource is virtualized. In other words, if we’re running 5 threads on the same core, each thread “feels” like it has its own core, effectively running on 5 little cores instead of 1 big core. More formally, each thread retains its own view of the core’s architectural registers (in RISC-V, x0-x31 and some CSRs, more on this below) and… some memory! Let’s look deeper into that.
The stack and memory virtualization
To begin, a thread has its own stack for reasons we’ll analyze shortly. The rest of the memory is “shared” with other threads, but this requires further investigation.
It’s important to understand that hardware virtualization exists on a spectrum, rather than as a few rigid options. Here are some of the options for virtualization:

Threads: virtualizes architectural registers and stacks, but not much else; i.e., different threads can share data elsewhere in memory.
Process: more heavyweight than threads, memory is virtualized such that each process “feels” like it has a dedicated CPU core and its own memory untouchable by other processes; additionally, a process houses multiple threads.
Container: virtualizes even more - each container has its own filesystem and potentially its own set of network interfaces; containers share the same kernel and underlying hardware.
VM: virtualizes everything.

There are many more shades in between, and each of these options likely has different subtypes. The point here is that all these approaches enable running different workloads with varying isolations, or more intuitively, different views of the machine and their environment.
Interestingly, if you examine the Linux kernel source code, you won’t find a construct explicitly called a container. What we popularly call containers isn’t a mechanism baked into the kernel, but rather a set of kernel mechanisms used together to form a specific view of the environment for our workload. For example, the chroot mechanism restricts filesystem visibility, while cgroups impose limits on workloads; together, these form what we call a container.
Furthermore, I believe (though don’t quote me on this) that the boundaries between threads and processes in Linux are somewhat blurred. To the best of my knowledge, both are implemented on top of tasks in the kernel, but when creating a task, the API allows different restrictions to be specified.
Ultimately, this is all to say that we’re always defining a workload with varying restrictions on what it can see and access. When and why to apply different restrictions is a topic for another day. Many questions arise when writing an application, ranging from the difficulty of an approach to its security.
Virtualizing a thread
In this experiment, we’ll implement minimal virtualization with very basic, time-sharing threads. Therefore, the goals are the following:

The programming model for a thread should remain mostly untouched. As long as a thread doesn’t interact with memory contents used by other threads, its programming model should remain consistent, powered by time-sharing.
A thread should have its own protected view of architectural registers, including some RISC-V CSRs.
A thread should be assigned its own stack.

It should be obvious why a thread needs its own view of the registers. If other threads could freely touch a thread’s registers, the thread wouldn’t be able to do any meaningful work. All (I believe) RISC-V instructions work with at least one register, so protecting a thread’s register view is essential.
Furthermore, assigning a private stack to a thread is necessary, though slightly less obvious. The answer is that different stacks are needed to manage different execution contexts. Namely, when a function is invoked, by convention, the stack is used to allocate function-private variables. Additionally, registers like ra can be pushed to the stack to retain the correct return address from a function (in case another function is invoked within it). In short, there are various reasons, per RISC-V convention, why the stack is needed to maintain the execution context. The details of RISC-V calling conventions will not be described here.
Interrupt context
It’s crucial to understand how interrupt code runs and what it should consist of, as this mechanism will be heavily exploited to achieve seamless time-sharing between threads. For a detailed, practical example, please check out this past text.
I’ll briefly include the assembly for the timer interrupt routine from that text:
s_mode_interrupt_handler:
        addi    sp,sp,-144
        sd      ra,136(sp)
        sd      t0,128(sp)
        sd      t1,120(sp)
        sd      t2,112(sp)
        sd      s0,104(sp)
        sd      a0,96(sp)
        sd      a1,88(sp)
        sd      a2,80(sp)
        sd      a3,72(sp)
        sd      a4,64(sp)
        sd      a5,56(sp)
        sd      a6,48(sp)
        sd      a7,40(sp)
        sd      t3,32(sp)
        sd      t4,24(sp)
        sd      t5,16(sp)
        sd      t6,8(sp)
        addi    s0,sp,144
        call    clear_timer_pending_bit
        call    set_timer_in_near_future
        li      a1,33
        lla     a0,.LC0
        call    debug_print
        nop
        ld      ra,136(sp)
        ld      t0,128(sp)
        ld      t1,120(sp)
        ld      t2,112(sp)
        ld      s0,104(sp)
        ld      a0,96(sp)
        ld      a1,88(sp)
        ld      a2,80(sp)
        ld      a3,72(sp)
        ld      a4,64(sp)
        ld      a5,56(sp)
        ld      a6,48(sp)
        ld      a7,40(sp)
        ld      t3,32(sp)
        ld      t4,24(sp)
        ld      t5,16(sp)
        ld      t6,8(sp)
        addi    sp,sp,144
        sret
This assembly was obtained by writing a C function tagged as an S-level interrupt in RISC-V. With this tag, the GCC compiler knew how to generate the prologue and epilogue of the interrupt routine. The prologue preserves architectural registers on the stack, and the epilogue recovers them (in addition to specifically returning from S-mode). All of this was generated by correctly tagging the C function’s invoking convention.
This somewhat resembles function calling, and that’s essentially what it is. Interrupts can be thought of (in a very simplified sense) as functions invoked by some system effect. Consequently, utilized registers must be carefully preserved on the stack and then restored at the routine’s exit; otherwise, asynchronous interrupts like timer interrupts would randomly corrupt architectural register values, completely blocking any practical software from running!
Implementation (high-level)
We’ll explore the implementation by first describing the high-level idea and then digging into the code.
Leveraging the interrupt stack convention
Adding an interrupt is, in a way, already introducing a form of threading to your application code. In a system with a timer interrupt, the main application code runs, which can occasionally be interleaved with instances of timer interrupt invocations. The core jumps to this interrupt routine when the timer signals, and it carefully restores the architectural state before control flow returns to the “main thread”. There are two control flows running concurrently here:

Main application code.
Repetitions of the interrupt routine.

This interleaving of the timer interrupt can be leveraged to implement additional control flows, and the main idea is outlined below.
The core of the interrupt routine is sandwiched between the prologue and the epilogue. That’s where the interrupt is serviced before control returns to the main application thread by restoring registers from the stack.
However, why must we restore the registers from the same stack location? If our interrupt logic swaps the stack pointer to some other piece of memory, we’ll end up with a different set of architectural register values recovered, thus entering a whole different flow. In other words, we achieve a context switch, and this is precisely how it’s implemented in this experiment. We’ll see the code for it shortly.
Kernel/user space separation
We can now delineate the kernel space and user space. With RISC-V, this naturally translates to kernel code running in supervisor (S) mode and user space code running in U-mode.
The machine boots into machine (M) mode, and since we want to leverage the SBI layer, we’ll allow OpenSBI to run there. Then, the kernel will perform some initial setup in S-mode before starting the U-mode execution of user space threads. Periodic timer interrupts will enable context switches, and the interrupt code will execute in S-mode. Finally, user threads will be able to make system calls to the kernel.
Implementation (code)
Please refer to the GitHub repository for the full code; we will only cover core excerpts below.
Assembly startup
As usual, a short assembly snippet is needed to start our S-mode code and enter the “main program” in Zig. This is in startup.S.
...
done_bss:

    # Jump to Zig main
    call main
...
The rest of the assembly startup primarily involves cleaning up the BSS section and setting up the stack pointer for the initial kernel code.
Main kernel file and I/O drivers
We’ll now examine kernel.zig, which contains the main function.
First, we probe the OpenSBI layer for console capabilities. We’ll only consider running on a relatively recent version of OpenSBI (from the last few years) that includes console capability. Otherwise, the kernel will halt and report an error.
export fn main() void {
    const initial_print_status = sbi.debug_print(BOOT_MSG);

    if (initial_print_status.sbi_error != 0) {
        // SBI debug console not available, fall back to direct UART
        const error_msg = "ERROR: OpenSBI debug console not available! You need the latest OpenSBI.\n";
        const fallback_msg = "Falling back to direct UART at 0x10000000...\n";

        uart.uart_write_string(error_msg);
        uart.uart_write_string(fallback_msg);
        uart.uart_write_string("Stopping... We rely on OpenSBI, cannot continue.\n");

        while (true) {
            asm volatile ("wfi");
        }

        unreachable;
    }
main is marked as export to conform to the C ABI.
Here, we have a lightweight implementation of a couple of I/O drivers. As you can see, writing can occur in one of two ways: either we go through the SBI layer (sbi.zig) or, if that fails, we use direct MMIO (uart_mmio.zig). The SBI method should theoretically be more portable, as it delegates output management details to the M-level layer (essentially what we do with MMIO), freeing us from concerns about exact memory space addresses.
Let’s quickly look at sbi.zig:
// Struct containing the return status of OpenSBI
pub const SbiRet = struct {
    sbi_error: isize,
    value: isize,
};

pub fn debug_print(message: []const u8) SbiRet {
    var err: isize = undefined;
    var val: isize = undefined;

    const msg_ptr = @intFromPtr(message.ptr);
    const msg_len = message.len;

    asm volatile (
        \\mv a0, %[len]
        \\mv a1, %[msg]
        \\li a2, 0
        \\li a6, 0x00
        \\li a7, 0x4442434E
        \\ecall
        \\mv %[err], a0
        \\mv %[val], a1
        : [err] "=r" (err),
          [val] "=r" (val),
        : [msg] "r" (msg_ptr),
          [len] "r" (msg_len),
        : .{ .x10 = true, .x11 = true, .x12 = true, .x16 = true, .x17 = true, .memory = true });

    return SbiRet{
        .sbi_error = err,
        .value = val,
    };
}
This is very straightforward; we’re simply performing the system call exactly as described in the OpenSBI documentation. Note that when I first wrote this code, I wasn’t fully familiar with Zig’s error handling capabilities, hence the somewhat non-idiomatic error handling.
However, this can be considered a first driver in this kernel, as it directly manages output to the device.
Next is uart_mmio.zig:
// UART MMIO address (standard for QEMU virt machine)
pub const UART_BASE: usize = 0x10000000;
pub const UART_TX: *volatile u8 = @ptrFromInt(UART_BASE);

// Direct UART write function (fallback when SBI is not available)
pub fn uart_write_string(message: []const u8) void {
    for (message) |byte| {
        UART_TX.* = byte;
    }
}
This is straightforward and self-explanatory.
Returning to kernel.zig and the main function, we create 3 user threads, each printing a slightly different message (the thread ID is the varying bit). At this point, the kernel setup is almost complete.
The final steps involve setting up and running the timer interrupt. Once that is done, kernel code will only run when the timer interrupts the system or when user space code requests a system call.
interrupts.setup_s_mode_interrupt(&s_mode_interrupt_handler);
_ = timer.set_timer_in_near_future();
timer.enable_s_mode_timer_interrupt();
We could request a context switch immediately, but for simplicity, we’ll wait until the timer activates and begins the actual work in the system.
S-mode handler and the context switch
While the Zig compiler could generate the adequate prologue and epilogue for our S-mode handler, we will do it manually. The reason is that we also want to capture some CSRs in the context that otherwise wouldn’t have been captured by the generated routine.
That’s why we use the naked calling convention in Zig. This forces us to write the entire function in assembly, though a quick escape hatch to this limitation is to call a Zig function whenever Zig logic is needed.
I won’t copy paste the whole prologue and epilogue here because they are very similar to what was done in the previous C experiment with RISC-V interrupts. Instead, I’ll just focus on the bit that is different:
...
        // Save S-level CSRs (using x5 as a temporary register)
        \\csrr x5, sstatus
        \\sd x5, 240(sp)
        \\csrr x5, sepc
        \\sd x5, 248(sp)
        \\csrr x5, scause
        \\sd x5, 256(sp)
        \\csrr x5, stval
        \\sd x5, 264(sp)

        // Call handle_kernel
        \\mv a0, sp
        \\call handle_kernel
        \\mv sp, a0

        // Epilogue: Restore context
        // Restore S-level CSRs (using x5 as a temporary register)
        \\ld x5, 264(sp)
        \\csrw stval, x5
        \\ld x5, 256(sp)
        \\csrw scause, x5
        \\ld x5, 248(sp)
        \\csrw sepc, x5
        \\ld x5, 240(sp)
        \\csrw sstatus, x5
...
As you can see, a couple more registers were added to the prologue and epilogue in addition to the core architectural registers.
Next, within this prologue/epilogue sandwich, we invoke the handle_kernel Zig function. This routes to the correct logic based on whether the interrupt source is a synchronous system call from user space or an asynchronous timer interrupt. The reason is that we land in the same S-level interrupt routine regardless of the interrupt source, and then we inspect the scause CSR for details.
To successfully work with the handle_kernel function, we need to be aware of the assembly-level calling conventions. This function takes a single integer parameter and returns a single integer parameter. Since the function signature is small, it works as simply as this:

The sole function parameter is passed through the a0 architectural register.
The same register also holds the function’s result upon return.

This is pretty easy. Let’s quickly look at the signature of this function:
export fn handle_kernel(current_stack: usize) usize {
...
It is slightly awkward but gets the job done. The input to this Zig logic is the stack top before invoking the Zig logic (which inevitably leads to some data added to the stack). The function’s output is where the stack top should be after the Zig logic is done. If it differs from the input, then we’re performing a context switch. If it’s the same, the same workload thread will continue running after the interrupt.
The rest of the logic is very simple. It inspects the interrupt source (system call from user space or timer interrupt) and performs accordingly.
In the case of a timer interrupt, a context switch is performed. The schedule function from scheduling.zig is invoked, and it potentially returns the other stack we should switch to:
const build_options = @import("build_options");
const sbi = @import("sbi");
const std = @import("std");
const thread = @import("thread");

pub fn schedule(current_stack: usize) usize {
    const maybe_current_thread = thread.getCurrentThread();

    if (maybe_current_thread) |current_thread| {
        current_thread.sp_save = current_stack;

        if (comptime build_options.enable_debug_logs) {
            _ = sbi.debug_print("[I] Enqueueing the current thread\n");
        }
        thread.enqueueReady(current_thread);
    } else {
        if (comptime build_options.enable_debug_logs) {
            _ = sbi.debug_print("[W] NO CURRENT THREAD AVAILABLE!\n");
        }
    }

    const maybe_new_thread = thread.dequeueReady();

    if (maybe_new_thread) |new_thread| {
        // TODO: software interrupt to yield to the user thread

        if (comptime build_options.enable_debug_logs) {
            _ = sbi.debug_print("Yielding to the new thread\n");
        }

        thread.setCurrentThread(new_thread);

        if (comptime build_options.enable_debug_logs) {
            var buffer: [256]u8 = undefined;
            const content = std.fmt.bufPrint(&buffer, "New thread ID: {d}, stack top: {x}\n", .{ new_thread.id, new_thread.sp_save }) catch {
                return 0; // Return bogus stack, should be more robust in reality
            };
            _ = sbi.debug_print(content);
        }

        return new_thread.sp_save;
    }

    _ = sbi.debug_print("NO NEW THREAD AVAILABLE!\n");

    while (true) {
        asm volatile ("wfi");
    }
    unreachable;
}
The code from the thread module is very simple, serving as boilerplate for a basic queue that manages structs representing threads. I won’t copy it here, as it’s mostly AI-generated. It is important to note, however, that the stacks are statically allocated in memory, and the maximum number of running threads is hardcoded.
The thread module also includes logic for setting up a new thread. This is where data is pushed onto the stack before the thread even runs. If you wonder why, it’s because when returning from the S-level trap handler, we need something on the stack to indicate where to go. The initial data does precisely that. We can seed the initial register values here as desired. In fact, in this experiment, we demonstrate passing a single integer parameter to the thread function by seeding the a0 register value (per calling convention) on the stack, which the thread function can then use immediately.
The user space threads
As mentioned in the introduction, we’ll bundle the user space and kernel space code into a single binary blob to avoid dynamic loading, linking, and other complexities. Hence, our user space code consists of regular functions:
/// Example: Create a simple idle thread
pub fn createPrintingThread(thread_number: usize) !*Thread {
    const thread = allocThread() orelse return error.NoFreeThreads;

    // Idle thread just spins
    const print_fn = struct {
        fn print(thread_arg: usize) noreturn {
            while (true) {
                var buffer: [256]u8 = undefined;
                const content = std.fmt.bufPrint(&buffer, "Printing from thread ID: {d}\n", .{thread_arg}) catch {
                    continue;
                };

                syscall.debug_print(content);

                // Simulate a delay
                var i: u32 = 0;
                while (i < 300000000) : (i += 1) {
                    asm volatile ("" ::: .{ .memory = true }); // Memory barrier to prevent optimization
                }
            }
            unreachable;
        }
    }.print;

    initThread(thread, @intFromPtr(&print_fn), thread_number);
    return thread;
}
Additionally, as mentioned above, we pre-seeded the stack such that when a0 is recovered from the stack upon the first interrupt return for a given thread, the function argument will be picked up. That’s how the print function accesses the thread_arg value and uses it in its logic.
To demonstrate the user/kernel boundary, we have syscall.debug_print(content);. This conceptually behaves more or less as printf from stdio.h in C. It performs prepares the arguments to the kernel and runs a system call with these arguments which should lead to some content getting printed on the output device. Here’s what the printing library looks like (from syscall.zig):
// User-level debug_print function
pub fn debug_print(message: []const u8) void {
    const msg_ptr = @intFromPtr(message.ptr);
    const msg_len = message.len;

    // Let's say syscall number 64
    // a7 = syscall number
    // a0 = message pointer
    // a1 = message length
    asm volatile (
        \\mv a0, %[msg]
        \\mv a1, %[len]
        \\li a7, 64
        \\ecall
        :
        : [msg] "r" (msg_ptr),
          [len] "r" (msg_len),
        : .{ .x10 = true, .x11 = true, .x17 = true, .memory = true });

    // Ignore return value for simplicity
}
System call 64 is served from the S-mode handler in kernel.zig. This is self-explanatory, and we won’t go into further details here.
Running the kernel
We will deploy the kernel on bare-metal, specifically on a virtual machine. In theory, this should also work on a real machine, provided an SBI layer is present when the kernel starts, and the linker script, I/O “drivers,” and other machine-specific constants are adapted.
To build, we simply run
zig build
To now run the kernel, we run:
qemu-system-riscv64 -machine virt -nographic -bios /tmp/opensbi/build/platform/generic/firmware/fw_dynamic.bin -kernel zig-out/bin/kernel
Refer to the previous text on OpenSBI for details on building OpenSBI. It is strongly recommended to use a freshly built OpenSBI, as QEMU may use an outdated version if no -bios flag is passed.
The output should begin with a big OpenSBI splash along with some OpenSBI data:
OpenSBI v1.7
   ____                    _____ ____ _____
  / __ \                  / ____|  _ \_   _|
 | |  | |_ __   ___ _ __ | (___ | |_) || |
 | |  | | '_ \ / _ \ '_ \ \___ \|  _ < | |
 | |__| | |_) |  __/ | | |____) | |_) || |_
  \____/| .__/ \___|_| |_|_____/|____/_____|
        | |
        |_|

Platform Name               : riscv-virtio,qemu
Platform Features           : medeleg
Platform HART Count         : 1
Platform IPI Device         : aclint-mswi
Platform Timer Device       : aclint-mtimer @ 10000000Hz
Platform Console Device     : uart8250
Platform HSM Device         : ---
Platform PMU Device         : ---
Platform Reboot Device      : syscon-reboot
Platform Shutdown Device    : syscon-poweroff
Platform Suspend Device     : ---
Platform CPPC Device        : ---
Firmware Base               : 0x80000000
Firmware Size               : 317 KB
Firmware RW Offset          : 0x40000
Firmware RW Size            : 61 KB
Firmware Heap Offset        : 0x46000
Firmware Heap Size          : 37 KB (total), 2 KB (reserved), 11 KB (used), 23 KB (free)
Firmware Scratch Size       : 4096 B (total), 400 B (used), 3696 B (free)
Runtime SBI Version         : 3.0
Standard SBI Extensions     : time,rfnc,ipi,base,hsm,srst,pmu,dbcn,fwft,legacy,dbtr,sse
Experimental SBI Extensions : none

Domain0 Name                : root
....
Following the OpenSBI splash, we’ll see the kernel output:
Booting the kernel...
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 0
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 1
Printing from thread ID: 2
Printing from thread ID: 2
Printing from thread ID: 2
The prints will continue running until QEMU is terminated.
If you want to build the kernel in an extremely verbose mode for debugging and experimentation, use the following command:
zig build -Ddebug-logs=true
After running the kernel with the same QEMU command, the output will appear as follows:
Booting the kernel...
DEBUG mode on
Interrupt source: Timer, Current stack: 87cffe70
[W] NO CURRENT THREAD AVAILABLE!
Yielding to the new thread
New thread ID: 0, stack top: 80203030
Interrupt source: Ecall from User mode, Current stack: 80202ec0
Printing from thread ID: 0
Interrupt source: Ecall from User mode, Current stack: 80202ec0
Printing from thread ID: 0
Interrupt source: Ecall from User mode, Current stack: 80202ec0
Printing from thread ID: 0
Interrupt source: Timer, Current stack: 80202ec0
[I] Enqueueing the current thread
Yielding to the new thread
New thread ID: 1, stack top: 80205030
Interrupt source: Ecall from User mode, Current stack: 80204ec0
Printing from thread ID: 1
Interrupt source: Ecall from User mode, Current stack: 80204ec0
Printing from thread ID: 1
Interrupt source: Ecall from User mode, Current stack: 80204ec0
Printing from thread ID: 1
Interrupt source: Timer, Current stack: 80204ec0
[I] Enqueueing the current thread
Yielding to the new thread
New thread ID: 2, stack top: 80207030
Interrupt source: Ecall from User mode, Current stack: 80206ec0
Printing from thread ID: 2
Interrupt source: Ecall from User mode, Current stack: 80206ec0
Printing from thread ID: 2
Interrupt source: Ecall from User mode, Current stack: 80206ec0
Printing from thread ID: 2
Interrupt source: Timer, Current stack: 80206ec0
...
Conclusion
Many educational OS kernels exist, but this experiment combines RISC-V, OpenSBI, and Zig, offering a fresh perspective compared to traditional C implementations.
The resulting code runs on a QEMU virtual machine, which can be easily set up, even by building QEMU from source.
To keep the explanation concise, error reporting was kept minimal. Should you modify the code and require debugging, sufficient clues are provided, despite some areas where the code is simplified (e.g., anonymous results after SBI print invocations like _ = ...). Much of the code in this example was AI-generated by Claude to save time, and it should function as intended. While some parts of the code are simplified, such as stack space over-allocation, these do not detract from the experiment’s educational value.
Overall, this experiment serves as a starting point for studying operating systems, assuming a foundational understanding of computer engineering and computer architecture. It likely has plenty of flaws for a practical application, but for now, we’re just hacking here!
I hope this was a useful exploration.
Please consider following on Twitter/X and LinkedIn to stay updated.
    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Website Is Just an SVG]]></title>
            <link>https://svg.nicubunu.ro/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45240391</guid>
            <content:encoded><![CDATA[
  
    
      
      
    
    
      
      
      
    
    
      
      
      
    
    
      
      
    
    
    
    
    
    
      
    
    
    
      
    
    
      
    
    
      
    
    
    
    
    
    
    
    
    
  
  
  
  
    
      
      
      Nicu's test website made with SVG
    
  
  
  
  
  Navigation Menu
  
  Experiment by:
  
    nicubunu.ro
  
  /
  
    nicubunu.blogspot.com
  
  This is a test page made to test Google's indexing abilities for SVG files.I am primarily interested in the following:- full text indexing - does Google index the text or will threat the file as an image?- links - will Google follow the links present in this SVG and index the linked files?There are more other things o test, but for the time being these two are blockers.The purpose of the test is to determine the effectiveness of using solely Inkscapefor authoring web sites.If you, as a reader of this page have more information on the subject and are willing to give me some more info, a contact address should be available in the About page linked in the right menu.This test website was made entirely with Inkscape.Notes: - I am fully aware about how the improper use of SVG could get a lot of bloat andinstatisfaction for the users;- SVG is a standard of the World Wide Web consortium;- This page use a few advanced SVG fatures (like Gaussian Blur) which are notfully supported by the current browsers (but will fall-back decently) and for the best experience you will need a browser powered by Geck 1.9 or later (like Firefox 3.0or later).Text to be found by search engines: lmtbk4mh.
  Home
  
    
      
      
      
    
  
  
    
      
      
        
          
          
          
          
          
          
          
          
          
          
            
            
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
        
      
    
  
  
    
    
    Home
  
  
    
      
      
      Stuf
    
  
  
    
      
      
      About
    
  
  lmtbk4mh

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Bank of Thailand Freezes 3M Accounts, Sets Daily Transfer Limits]]></title>
            <link>https://www.thaienquirer.com/57752/bot-freezes-3-million-accounts-sets-daily-transfer-limits-of-50000-200000-baht-to-curb-6-billion-baht-scam-losses/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45240304</guid>
        </item>
        <item>
            <title><![CDATA[The AI-Scraping Free-for-All Is Coming to an End]]></title>
            <link>https://nymag.com/intelligencer/article/ai-scraping-free-for-all-by-openai-google-meta-ending.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45240266</guid>
            <description><![CDATA[AI companies such as OpenAI, Google, Meta, and Anthropic have been scraping the web for years, taking content for free and often without permission. With the help of Cloudflare and Fastly and a new standard called RSL, the web is fighting back.]]></description>
            <content:encoded><![CDATA[  
    


  
  
  
  
    
          The AI-Scraping Free-for-All Is Coming to an End
            The web would like to make a deal.
            

            
                  
                    
                  
                
            
            By 
        John Herrman,
          a tech columnist at Intelligencer 
          Formerly, he was a reporter and critic at the New York Times and co-editor of The Awl.
      

              
          
        
    
      
                 
          
        Photo-Illustration: Intelligencer; Photo: Getty Images
        
  
  
    
    
      
          
                   
          
            
              Photo-Illustration: Intelligencer; Photo: Getty Images
              
            
              
        You can divide the recent history of LLM data scraping into a few phases. There was for years an experimental period, when ethical and legal considerations about where and how to acquire training data for hungry experimental models were treated as afterthoughts. Once apps like ChatGPT became popular and companies started commercializing models, the matter of training data became instantly and extremely contentious.

  Authors, filmmakers, musicians, and major publishers and internet companies started calling out AI firms and filing lawsuits. OpenAI started making individual deals with publishers and platforms — including Reddit and New York’s owner company, Vox Media — to ensure ongoing access to data for training and up-to-date chat content, while other companies, including Google and Amazon, entered into licensing deals of their own. Despite these deals and legal battles, however, AI scraping became only more widespread and brazen, leaving the rest of the web to wonder what, exactly, is supposed to happen next.

  They’re up against sophisticated actors. Lavishly funded start-ups and tech megafirms are looking for high-quality data wherever they can find it, offline and on, and web scraping has turned into an arms race. There are scrapers masquerading as search engines or regular users, and blocked companies are building undercover crawlers. Website operators, accustomed to having at least nominal control over whether search engines index their content, are seeing the same thing in their data: swarms of voracious machines making constant attempts to harvest their content, spamming them with billions of requests. Internet infrastructure providers are saying the same thing: AI crawlers are going for broke. A leaked list of sites allegedly scraped by Meta, obtained by Drop Site News, includes “copyrighted content, pirated content, and adult videos, some of whose content is potentially illegally obtained or recorded, as well as news and original content from prominent outlets and content publishers.” This is neither surprising nor unique to one company. It’s closer to industry-standard practice.

  For decades, the most obvious reason to crawl the web was to build a useful index or, later, a search engine like Google. A Google crawl meant you had a chance to show up in search results and actual people might visit your website. AI crawlers offer a different proposition. They come, they crawl, and they copy. Then they use that copied data to build products that in many cases compete with their sources (see: Wikipedia or any news site) and at most offer in return footnoted links few people will follow (see: ChatGPT Search and Google’s AI Mode). For an online-publishing ecosystem already teetering on the edge of collapse, such an arrangement looks profoundly grim. AI firms scraped the web to build models that will continue to scrape the web until there’s nothing left.

  In June, Cloudflare, an internet infrastructure firm that handles a significant portion of online traffic, announced a set of tools for tracking AI scraping and plans to build a “marketplace” that would allow sites to set prices for “accessing and taking their content to ingest into these systems.” This week, a group of online organizations and websites — including Reddit, Medium, Quora, and Cloudflare competitor Fastly — announced the RSL standard, short for Really Simply Licensing (a reference to RSS, or Really Simple Syndication, some co-creators of which are involved in the effort). The idea is simple: With search engines, publishers could indicate whether they wanted to be indexed, and major search engines usually obliged; now, under more antagonistic circumstances, anyone who hosts content will be able to indicate not just whether the content can be scraped but how it should be attributed and, crucially, how much they want to charge for its use, either individually or as part of a coordinated group.

  As far as getting major AI firms to pay up, not to mention the hundreds of smaller firms that are also scraping, RSL is clearly an aspirational effort, and I doubt the first step here is for Meta or OpenAI to instantly cave and start paying royalties to WebMD. Combined with the ability to use services like Cloudflare and Fastly to more effectively block AI firms, though, it does mark the beginning of a potentially major change. For most websites, AI crawling has so far been a net negative, and there isn’t much to lose by shutting it down (with the exception of Google, which crawls for its Search and AI products using the same tools). Now, with the backing of internet infrastructure firms that can actually keep pace with big tech’s scraping tactics, they can. (Tech giants haven’t been above scraping one another’s content, but they’re far better equipped to stop it if they want to.)

  A world in which a majority of public websites become invisible to AI firms by default is a world in which firms that have depended on relatively unfettered access to the web could start hurting for up-to-date information, be it breaking news, fresh research, new products, or just ambient culture and memes. They may not be inclined to pay everyone, but they may eventually be forced to pay someone, through RSL or otherwise.

  


    

      


          



      The AI-Scraping Free-for-All Is Coming to an End



    
      
        
  


      
      
      
        
  


      
    

  
  



  

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[We Spiral]]></title>
            <link>https://behavioralscientist.org/why-we-spiral/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45240146</guid>
            <description><![CDATA[Questions of who we are or what we’re worth can send us into a tailspin. But the very same processes that pull us down can propel us up, too.]]></description>
            <content:encoded><![CDATA[
          
    
  
    
Say you’re a senior member of your team at work. You’re 12 minutes late to the weekly staff Zoom. Once you’ve “joined audio,” the first thing you hear is your old friend’s voice. “There you are! So glad you could fit us in.” You laugh and explain the disastrous traffic, difficult drop-off at your kids’ school, or whatever it was that messed up your morning. The moment passes and the conversation moves on. You turn to the job at hand, focused and ready to go.



But what if you’re a junior staffer, still feeling your way. Same thing happens: You’re 12 minutes late to the weekly staff Zoom. Once you’ve “joined audio,” the first thing you hear is the boss’s voice. “There you are! So glad you could fit us in.” A few colleagues chuckle. You consider making excuses—about traffic, drop-off, whatever it was—but the moment passes, and the conversation moves on.






Your mind doesn’t, though. It’s still ruminating. Was that snark in my boss’s voice? Were they talking about me before I logged on? Do I fit in here? Am I any good at this job? You might not be fully aware of these questions. Your mind works quickly on multiple tracks at the same time. And those questions are nasty; they threaten your sense of belonging, your worth, and your value, at least at work. So you try to push them away, to suppress them. But they’re still there. And once they’ve been triggered, it might feel like the evidence keeps pouring in.



Someone makes an inside joke in the chat. You don’t get it. I don’t belong here. Someone rolls their eyes while you’re talking. They don’t respect me. The boss ignores you for the rest of the meeting. No one sees me. Again, these thoughts may not be fully conscious. But there’s no mistaking the fact that your motivation to get back to work has waned by the time you log off. What was it you were supposed to look into?




Was that snark in my boss’s voice? Were they talking about me before I logged on? Do I fit in here? Am I any good at this job?




Next thing you know, you’re idly messing around online when a text comes in from the person who rolled their eyes. “You okay? You seemed out of it at the meeting.” You ignore it. But your mind doesn’t. It’s busy composing possible replies. The full spectrum from passive-aggressive to career imperiling. Eventually you pick up your phone. What will you text back?



This is how self-defeating spirals start and how they gather speed. Let’s break down the moving parts:




A circumstance places a big question on the table—about identity, belonging, or adequacy: You’re new at work. You want to succeed and belong, but you wonder . . . That question looms, latent and inactive, but present.





A “bad” thing happens: Your boss is a little snarky.





That question gets triggered: You read the room for answers, drawing negative inferences from ambiguous evidence. You’re distracted from the task at hand. Your pessimistic hypothesis becomes more entrenched.





You act on that pessimistic hypothesis, making matters worse.




Maybe you send that colleague a snarky text back. And what do you know: When you see them a few days later, they’re cold to you.



Now you aren’t talking. Maybe you flub that assignment your boss gave you, and they lose confidence in you. Fast-forward a year and you’re at a new job. Tensions are emerging with the new coworkers. Or are they? How will this story end? Do you have any control over it?




When a core question is unsettled, it functions like a lens through which you see the world.




Yes, you do. We all do. Negative spirals or feedback loops like these aren’t inevitable. In fact, there are small things we can do both for ourselves and for others to nip them in the bud—and prevent catastrophic outcomes months and years into the future. Better yet, there are ways we can launch positive spirals—dramatically increasing our chances of future happiness, success, and flourishing. The very same processes can either propel us upward or pull us down.



To understand how all this is possible, let’s get more precise about sequences like 1–4 above. There are three key concepts at play: “core questions” (number 1), meaning making or “construal” (numbers 2 and 3), and “calcification” (number 4). Think of these as “the three Cs” of spirals—whether positive or negative.







Core questions. There are the fundamental questions all of us face, at one time or another. For example: Who am I? Do I belong? Am I enough? I think of these questions as “defining” because they help define you and your life: your sense of self, what relationships you’ll have, and whether you’ll be able to do and be the things you aspire to. There might be long stretches when you don’t think about a given question much because it’s settled for you then. But at critical junctures specific questions flare up, unsettle and preoccupy you. Then they begin to shape what you see and how you act.



Construal. It’s natural to think that we have an unfiltered view of the world. That light hits your eyes and you just see what’s out there. But it’s more that we read the world, interpret it, drawing inferences based on what’s already in our heads. We pick up on themes that seem relevant or important to us, not noticing or screening out other details.



A friend once told me of an ingenious class demonstration that helped her begin to understand this process. A professor split the class in two and then spoke to the first half alone, telling them of his love for travel and a recent trip to Libya. Next, he spoke to the second half about shopping and how hard it was to find the right size shoe. Last, he brought the class together and said a single word. He asked the students to write it down. Students in the first group wrote, “Tripoli.” Those in the second wrote, “Triple E.”



Construal is like a kind of focus. As you look out at the social scene, what snaps to attention? If you’re anything like me, one of the most powerful guides is whatever could pose a risk to you, could threaten you. If you’re walk­ing through a forest where a tiger is said to prowl, you might hear that tiger in every rustle of leaves, see it in every sway of reeds. But in the social world, we don’t all face the same threats. That’s why when you’re new at work and nervous about your place you might hear snark in your boss’s voice, but not if it’s your old friend.



When a core question is unsettled for a person, it functions like a lens through which you see the world. We seek answers that can help us resolve that question. Is it true? we ask. Are my doubts and fears well founded? Then, if a “bad” thing happens, it can seem like proof of your negative hypothesis. We aren’t neutral observers on the lookout for evidence one way or the other. We’re in the grip of confirmation bias, attuned to evidence that corroborates our preconceived theory, even if it’s the tiniest thing.



Calcification. Calcification happens when our negative thoughts and feelings get entrenched—often as a consequence of our own actions. You have a bad date and think, Am I unlovable? Will I be alone forever? Pretty soon your next date isn’t going well either. Rinse and repeat long enough, and you’re stuck in a romantic rut.



When you start to look, you can see spirals everywhere. You fail an important math test. You think you can’t succeed, and stop going to class. You feel sick from a treatment designed to help you overcome an illness. You think it means your illness is especially strong and resistant and so avoid treatment. You have a fight with your kids. You think you’re a “bad parent,” and then yell at them even more the next time. This is self-sabotage, and one step at a time it costs us our achievements, our health, our relationships, and our well-being.



Spiraling up



Yet if our struggles arise, in part, from the inferences we draw, we have an opportunity. In my work, my colleagues and I identify early moments where people could go one way or the other. By understanding the questions that come up at critical junctures, we can offer people better ways to think through challenges—ways that can help them spiral up, instead of down. 



That’s what we call “wise” interventions: graceful ways to offer people good answers to the questions that define our lives. It sure can seem like magic that 21 minutes could improve marriage a year later; that a one-page letter could keep kids out of jail; that a string of postcards could cut suicide rates by half over two years; or that an hour-long reflection on belonging in the first year of college could improve life satisfaction and career success a decade later. But this—this is ordinary magic.




Negative spirals or feedback loops aren’t inevitable. There are things we can do both for ourselves and for others to nip them in the bud.




In my first year of college, I was biking back through campus one lovely fall day when I saw a large group of fellow students gathered enthusiastically around a truck from the California burger chain In-N-Out. Maybe they craved a taste of home. But in Michigan, where I was from, there are no In-N-Outs. I’d never heard of it. Feeling excluded from the burger party, I biked off in a huff to eat my lunch in the dining hall alone. I remember thinking, I’m not standing in line for a burger!



What was my problem?



As an 18-year-old, I certainly didn’t want to think of myself as feeling that I did not belong in college. And I definitely didn’t want to think that an In-N-Out truck could trigger that feeling. How ridiculous that would be. Who thinks they don’t belong because of a burger truck?



It was ridiculous. After my brother experienced a particularly mysterious romantic disaster, it’s something we christened a “tifbit”—tiny fact, big theory. Of course not knowing about In-N-Out didn’t mean I didn’t belong in college. But that’s the point. For looking back now, I know the truth is I was homesick. I felt so far from home and all the people I knew and loved. So I wondered, Will I make friends in California? Will I fit in? Seeing all those classmates crowded together, eager to get lunch from a place I’d never even heard of, just triggered those anxieties.



With wisdom and kindness and a little distance, we can laugh at ourselves in situations like these. But we should pay attention. For beneath every tifbit is a real question, and it’s almost always a reasonable one. Big responses to small experiences can help us see what lies beneath the surface. For a tifbit is never just a tiny fact. It’s a clue to the bigger questions that define our lives.



With a little prompt, I could have known that almost everyone feels homesick at first in college, that we’re all in some sense far from home, even the kids from California, that everyone was trying to find new communities. Maybe then I would have joined the line at the In-N-Out truck. I could have asked someone to tell me what In-N-Out was. Why do they love it? What is “animal style”?



I’m sure they would have been glad to share. I know I would have had a better lunch. And maybe I would have made a friend, too.







Excerpted from Ordinary Magic copyright © 2025 by Gregory M. Walton. Used by permission of Harmony Books, an imprint of Random House, a division of Penguin Random House LLC, New York. All rights reserved. No part of this excerpt may be reproduced or reprinted without permission in writing from the publisher.




  


        ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[EPA Seeks to Eliminate Critical PFAS Drinking Water Protections]]></title>
            <link>https://earthjustice.org/press/2025/epa-seeks-to-roll-back-pfas-drinking-water-rules-keeping-millions-exposed-to-toxic-forever-chemicals-in-tap-water</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45239803</guid>
            <description><![CDATA[The move continues to expose communities across the country to toxic forever chemicals in tap water]]></description>
            <content:encoded><![CDATA[
	Washington, D.C. — The U.S. Environmental Protection Agency (EPA) announced it will no longer defend rules that protect people from unsafe levels of PFAS “forever chemicals” in drinking water, seeking to reverse legal protections put into place last year.
In its motion filed in federal court yesterday, EPA asked the court to axe its determinations to regulate and enforceable standards for four PFAS chemicals – GenX, PFHxS, PFNA, and PFBS. Separately, EPA previously announced that it will seek to extend the compliance deadline for PFOA and PFOS standards by two years from 2029 to 2031. PFAS have contaminated the drinking water for approximately 200 million people nationwide.
Environmental lawyers said EPA’s course of action is an attempt to evade limits that Congress imposed on the agency. The Safe Drinking Water Act has a strong anti-backsliding provision that prohibits the EPA from weakening any drinking water standard once it is set. In essence, EPA is asking the court to do what EPA itself is not allowed to do.
“Administrator Zeldin promised to protect the American people from PFAS-contaminated drinking water, but he’s doing the opposite,” said Katherine O’Brien, Earthjustice attorney. “Zeldin’s plan to delay and roll back the first national limits on these forever chemicals prioritizes chemical industry profits and utility companies’ bottom-line over the health of children and families across the country.”
“The EPA’s request to jettison rules intended to keep drinking water safe from toxic PFAS forever chemicals is an attempted end-run around the protections that Congress placed in the Safe Drinking Water Act. It is also alarming, given what we know about the health harms caused by exposure to these chemicals. No one wants to drink PFAS. We will continue to defend these common-sense, lawfully enacted standards in court,” said Jared Thompson, a senior attorney with NRDC (Natural Resources Defense Council).
Earthjustice is representing the following community groups: Buxmont Coalition for Safe Water, Clean Cape Fear, Clean Haw River, Concerned Citizens of WMEL Water Authority Grassroots, Environmental Justice Task Force, Fight for Zero, Merrimack Citizens for Clean Water, and Newburgh Clean Water Project. Working alongside NRDC, the organizations have intervened to defend the nation’s first-ever drinking water standards for PFAS in ongoing litigation brought by chemical companies and water utility associations, who are asking the U.S. Court of Appeals in Washington, D.C., to overturn the standards.
Background:
Per- and polyfluoroalkyl substances (PFAS) are a class of thousands of synthetic chemicals that are widely used in an array of consumer, commercial, and industrial products due to their ability to withstand heat and repel water and stains. Also known as “forever chemicals,” PFAS are extremely persistent in the environment and can accumulate in humans or animals. PFAS exposure is linked to many negative health effects at extremely low levels of exposure, including but not limited to kidney and testicular cancer, liver and kidney damage, changes in hormone and lipid levels, and harm to the nervous and reproductive systems.
After decades of advocacy on the part of environmental and public health advocates, the EPA proposed in March 2023 to regulate six PFAS chemicals in drinking water. PFAS can be removed from drinking water with existing technologies. In April 2024, the agency concluded there is no safe level of PFOA or PFOS exposure, and the final rule covered six PFAS chemicals in total, and set individual limits for five PFAS chemicals and a limit on mixtures of four PFAS chemicals. The rule also requires water systems to monitor for the six regulated PFAS chemicals and publicly communicate their compliance with the new limits, while giving them the law’s maximum compliance time of five years to comply by April 2029. The rule was a long overdue step to address a public health crisis that threatens millions of people nationwide.

		Earthjustice is the premier nonprofit environmental law organization. We wield the power of law and the strength of partnership to protect people's health, to preserve magnificent places and wildlife, to advance clean energy, and to combat climate change. We are here because the earth needs a good lawyer.
	]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Read to Forget]]></title>
            <link>https://mo42.bearblog.dev/read-to-forget/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45239601</guid>
            <description><![CDATA[I read to forget. Even when studying or working on papers for a PhD, I approach texts with the same mindset: I'm not a storage device that needs to save all ...]]></description>
            <content:encoded><![CDATA[
  
  
    
      
        Mo's Blog
      
    
    
      Home Blog

    
  
  
    

    
        
    

    
        

        
            
                
                    05 Jul, 2025
                
            
        
    

    I read to forget. Even when studying or working on papers for a PhD, I approach texts with the same mindset: I'm not a storage device that needs to save all bits of information. I am more of a system of Bayesian beliefs, constantly evolving and updating in small, incremental steps.
I remember co-workers highlighting large chunks of text, sometimes 40%. That doesn't make sense to me. We can only read a text once, given the number of compelling works and the limited time available to us.
So, I read to forget. When I start reading, I'm prepared to lose 98% of what's in front of me. From most texts, I only want two things: First, I want it to subtly alter my thinking, an incremental update that moves me towards a refined world model. Second, I want to pull out a few key pieces of information that I might use later in my writing. For instance, if I come across a well-written methodology section in a paper, I’ll save that.
Reading should stimulate my thinking and produce new ideas. I've found myself reading a paper, pausing midway, and immediately experimenting with some variation of the algorithm described, leading to new ideas or even a new paper.
If a non-fiction text doesn't spark new thoughts or actions, it may not even be worthwhile reading. Anything beyond that clutters my note-taking system. You can't possibly keep track of everything, nor can you work with hoarded pieces of information.


    

    
        

        
            


        
    


  
  

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CorentinJ: Real-Time Voice Cloning (2021)]]></title>
            <link>https://github.com/CorentinJ/Real-Time-Voice-Cloning</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45239016</guid>
            <description><![CDATA[Clone a voice in 5 seconds to generate arbitrary speech in real-time - CorentinJ/Real-Time-Voice-Cloning]]></description>
            <content:encoded><![CDATA[Real-Time Voice Cloning
This repository is an implementation of Transfer Learning from Speaker Verification to
Multispeaker Text-To-Speech Synthesis (SV2TTS) with a vocoder that works in real-time. This was my master's thesis.
SV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.
Video demonstration (click the picture):

Papers implemented



URL
Designation
Title
Implementation source




1806.04558
SV2TTS
Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis
This repo


1802.08435
WaveRNN (vocoder)
Efficient Neural Audio Synthesis
fatchord/WaveRNN


1703.10135
Tacotron (synthesizer)
Tacotron: Towards End-to-End Speech Synthesis
fatchord/WaveRNN


1710.10467
GE2E (encoder)
Generalized End-To-End Loss for Speaker Verification
This repo



Heads up
Like everything else in Deep Learning, this repo has quickly gotten old. Many SaaS apps (often paying) will give you a better audio quality than this repository will. If you wish for an open-source solution with a high voice quality:

Check out paperswithcode for other repositories and recent research in the field of speech synthesis.
Check out Chatterbox for a similar project up to date with the 2025 SOTA in voice cloning

Setup
1. Install Requirements

Both Windows and Linux are supported. A GPU is recommended for training and for inference speed, but is not mandatory.
Python 3.7 is recommended. Python 3.5 or greater should work, but you'll probably have to tweak the dependencies' versions. I recommend setting up a virtual environment using venv, but this is optional.
Install ffmpeg. This is necessary for reading audio files.
Install PyTorch. Pick the latest stable version, your operating system, your package manager (pip by default) and finally pick any of the proposed CUDA versions if you have a GPU, otherwise pick CPU. Run the given command.
Install the remaining requirements with pip install -r requirements.txt

2. (Optional) Download Pretrained Models
Pretrained models are now downloaded automatically. If this doesn't work for you, you can manually download them here.
3. (Optional) Test Configuration
Before you download any dataset, you can begin by testing your configuration with:
python demo_cli.py
If all tests pass, you're good to go.
4. (Optional) Download Datasets
For playing with the toolbox alone, I only recommend downloading LibriSpeech/train-clean-100. Extract the contents as <datasets_root>/LibriSpeech/train-clean-100 where <datasets_root> is a directory of your choosing. Other datasets are supported in the toolbox, see here. You're free not to download any dataset, but then you will need your own data as audio files or you will have to record it with the toolbox.
5. Launch the Toolbox
You can then try the toolbox:
python demo_toolbox.py -d <datasets_root>
or
python demo_toolbox.py
depending on whether you downloaded any datasets. If you are running an X-server or if you have the error Aborted (core dumped), see this issue.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[macOS Tahoe is certified Unix 03 [pdf]]]></title>
            <link>https://www.opengroup.org/openbrand/certificates/1223p.pdf</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45238930</guid>
        </item>
        <item>
            <title><![CDATA[Fukushima Insects Tested for Cognition]]></title>
            <link>https://news.cnrs.fr/articles/fukushima-insects-tested-for-cognition</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45238836</guid>
            <description><![CDATA[In the contaminated area around Fukushima, Japan, scientists are studying the impact of radioactivity on the cognitive abilities of pollinating insects such as honeybees and giant hornets.]]></description>
            <content:encoded><![CDATA[
      
  In the contaminated area around Fukushima, Japan, scientists are studying the impact of radioactivity on the cognitive abilities of pollinating insects such as honeybees and giant hornets.       
      
  Bees and hornets are known to have a wide range of cognitive skills, including the ability to recognise colours and navigate in space. However, pollution by substances released into the environment by humans, such as pesticides, can impair their performance.
Olivier Armant, from the radionuclide ecology and ecotoxicology laboratory at the French ASNR nuclear safety and radiation protection authority, and Mathieu Lihoreau, an ethologist from the Research Centre on Animal Cognition at the Centre for Integrative Biology1 wondered what effect ionising radiation might have on these pollinators. Armant works on the ecological impact of such radiation, carrying out long-term studies on the fauna and flora around Chernobyl (currently inaccessible, due to the war in Ukraine) and Fukushima, Japan, while Lihoreau focuses on bee intelligence and the factors that may interfere with it.
Assessing cognitive performance
 "A few years ago, a researcher in my lab came up with the idea of deploying various types of sensor to monitor, preferably automatically, the biological activity of certain species in the aftermath of the Fukushima disaster," Armant explains. "We had three projects in mind: connected nest boxes, a system that measured the biotic parameters of water and – the one we chose – the method developed by Mathieu Lihoreau." 2 For several years, the ethologist has been working on an automated system to assess the cognitive performance of these social insects. The device they use was designed in partnership with the Toulouse-based start-up BeeGuard, which manufactures connected beehives that enable real-time monitoring.

    
  
  
          A member of the team collecting bees from connected beehives            

  
"I study the learning and memory abilities of bees," Lihoreau explains. "Although this is primarily a fundamental research topic, it also has very concrete applications in ecotoxicology: if bees exhibit learning deficits in certain locations, it means there's a problem. For example, although many pesticides are used in doses that are low enough not to kill these insects, they end up as residues in the nectar they feed on and can have a neurotoxic effect. This results in cognitive disturbances that are difficult to observe, such as the inability to associate a reward with a specific colour or smell. Our system can measure these effects, which, although not lethal, are nonetheless serious, because they have a knock-on effect on the survival of colonies and, more generally, on pollination services."
When disturbed in this way, bees begin to forage on flowers of different species, instead of focusing on just one. As a result, they no longer bring the right pollen to the right plants, which affects the entire ecosystem. The device developed by Lihoreau's team (made up of biologists, engineers, modellers and ecologists) had until now only been tested near Toulouse (southwestern France), rather than in the extreme conditions of an area like Fukushima, which the scientists were able to enter with the help of their Japanese colleagues.

    
  
  
          Entrance to a beehive in a contaminated area. Some of the bees (circled in red) carry a QR code for identification.            

  
"We started collaborating with Japan just after the Fukushima disaster, in 2011," Armant explains. "We work in particular with Fukushima University's Institute of Environmental Radioactivity (IER), which help us to access the contaminated area. Our Japanese colleagues have extensive knowledge of the site and its forests, and they were able to direct us to the most interesting locations. This enabled us to carry out two field investigations in 2023 and 2024."
How do you go about testing bees?
The sites where the beehives were set up3 were selected on the basis of the soil contamination gradient for caesium-137. Local hornets, already present on the sites, were also included in the cognition study. Although it isn't clear whether these species are pollinators, they are worth studying, as they are descended from many generations of insects exposed to radiation.
But just how do you carry out cognitive tests on an insect? "The system is based on conventional experimental protocols developed in the laboratory over the past 50 years," Lihoreau says. It uses a Y-shaped maze, in which the insect can choose between two branches illuminated by coloured LEDs, either blue or yellow. The insect needs to understand that it will be rewarded with sugar water, dispensed by a pump at the end of the branch, only if it chooses the right colour (blue or yellow, depending on the tests).

    
  
  
          Automated maze equipped with a digital interface to visualise the data.            

  
A healthy bee needs 10 tests on average to find the correct path by following the right colours. "This figure enables us to establish learning curves, which can then be compared to see if there is an impact on their ability to solve the problem," Lihoreau adds.
Bees equipped with a QR Code
The protocol used at Fukushima is automated. Each bee is equipped with a 2-mm-wide QR Code which is read by a camera, activating the opening of the maze. This customisation makes it possible to test the learning process of each insect, whose behaviour is filmed, analysed and sent in real time to a server. The whole operation is powered by solar panels.
Giant hornets, which are too big to enter the system, were tested manually in more traditional mazes. "Our Japanese colleagues initially tried to dissuade us from handling them, because they are so dangerous," Lihoreau recalls. "However, the hornets are extremely useful for understanding the environmental impact of radioactive contamination, because these predators are at the top of the food chain and, unlike our honeybees, have always been present in the area, since well before the nuclear accident."

    
  
  
          Giant hornet fitted with a dosimeter.            

  
Although the results of the study have yet to be published, scientists are already reporting a decline in insect cognition in the contaminated area of Fukushima Prefecture. "We can see correlations," Armant says. "However, a causal link with radioactive contamination has not yet been established. But since the area is no longer inhabited, it is unlikely that the effect is due to factors such as pesticides."  ♦
See also
Of bees and men
Learning from the Fukushima decontamination
 
Footnotes
1. CRCA-CBI (CNRS / Université de Toulouse III – Paul Sabatier - EPE).
2. This work is the result of a joint call for projects between the CNRS, via its Mission for Transversal and Interdisciplinary Initiatives (MITI), and the former IRSN institute of radiation protection and nuclear safety, which has since merged with the ASN nuclear safety authority, forming the ASNR.
3. As part of the BEERAD project to assess the effects of ionising radiation on bees, funded by the French National Research Agency (ANR).


      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The PC was never a true 'IBMer']]></title>
            <link>https://thechipletter.substack.com/p/the-pc-was-never-a-true-ibmer</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45238567</guid>
        </item>
        <item>
            <title><![CDATA[Gemini (2023)]]></title>
            <link>https://geminiquickst.art/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45238536</guid>
            <description><![CDATA[A Quick Start Guide For New Gemini Users]]></description>
            <content:encoded><![CDATA[
        
         
            
    
        What is Gemini?

Gemini is a new way of using the Internet, separate from the World Wide
Web you are familiar with. Compared to the WWW, it is intended to be:

Simpler – Gemini pages aren’t programs that run in your browser like
most modern websites are; they’re just text with a little formatting,
so there are no surprises. Once you know how one Gemini page works,
you know how they all work.
Human Scale – Gemini servers and clients aren’t written by big,
monopolistic software companies the way web browsers are; the DIY
ethos of Gemini means that complete applications can be written by
individual developers or small groups in a reasonable amount of time.
That also means that you have more choices compared to web browsers.
Distraction Free – Gemini pages are text-only and have simple
typography. You can view images, watch video, or listen to music over
Gemini, but nothing will ever autoplay, pop over what you’re
reading, or jump out of the way of your mouse.
Privacy Protecting – Every Gemini request is independent of every
other, so there’s no way to track you between sites. Every site you
visit is protected by the same encryption used by banking and
eCommerce sites on the WWW.

More details are in the Official Gemini
FAQ. Be aware that it’s
targeted at a more technical audience than this quick start page, so you
might want to skip it for now and come back later. The main thing to
know is that you’re going to get a much more stripped-down experience
compared to the modern WWW, but that’s okay! Some of the choices made to
keep Gemini simple may seem too extreme, compared to even a bare-bones
web site, but there are hidden benefits that won’t be obvious at first.
How do I read pages on Gemini?
The first thing to do is to install a Gemini client. A Gemini client is
like a web browser, except instead of browsing the web, it browses
Geminispace. There are at least a couple of Gemini clients available for
most platforms. Here, I’m going to recommend just one, that I think will
feel most familiar or least surprising to new users. That doesn’t mean I
think the other ones are bad. A lot of it is just personal preference,
just like with web browsers. After you get used to Gemini with the
client I recommend, you may want to try some others.
You may be used to doing everything in the web browser, and find it
strange or uncomfortable to have to install a different program to read
Gemini pages. But you’ll get used to it; the WWW tries to be everything
to everyone, both a floor-wax and a toothpaste, while Gemini tries to
be good at just one thing.
Windows
You have several options for a Gemini browser on Windows, but I’m
going to recommend that you install
Geminaut, because of
its comfortable, Windows-native user interface. Download and run the
latest MSI file from the website. You will get a warning that the
installer isn’t signed, which is because the developer is an
independent hobbyist. If you downloaded it directly from the link
above, it should be safe to “run anyway”.








Lagrange is
another good option – it has more features and is lightweight, but the
user interface isn’t native like GemiNaut’s. There is also a nightly
build of Kristall.
MacOS
There are several Gemini clients that can be built for MacOS, but the
only one I know of that provides pre-built downloads for a released
version is
Lagrange. That’s
okay, because Lagrange is a very good browser. The UI doesn’t use
native controls, but it’s light and fast.


There may also be nightly builds of
Kristall, if you’re so
inclined.
iOS
There is one Gemini client on the app store, called
Elaho. There is another one
on TestFlight called
Rocketeer.








Android
For Android, I recommend
Ariane. The developer’s site
has several different download options, but if you are at all unsure,
you should install from Google
Play.
Deedum
is also a good client for Android, but its UI is not quite as simple.


Linux or Unix (desktop GUI)
If you’re able to compile programs from source, you are spoiled for
choice. Most Gemini clients are developed for Linux. The main GUI
choices are:

Lagrange
Kristall (QT5)
Castor (GTK)

If you need a binary release, you will probably need to install
Lagrange. Lagrange is on
FlatHub, so if
your distribution supports FlatPaks, you’re in luck. There is also a
nightly AppImage of Kristall, if you prefer.


Linux or Unix (terminal or console)
The situation here is similar to Linux GUI clients, but there are at
least two that have binary releases:

Bombadillo
Amfora

If you’re not sure which you want, go for Amfora; it has more familiar
keybindings than Bombadillo.
Other
If there’s no Gemini client for your platform, but there is a web
browser, you can use a proxy. Either
portal.mozz.us or
proxy.vulpes.one
should work for your needs.
You shouldn’t use a proxy just because you don’t want to install a
Gemini client, though! You will miss out on the experience of not
using the web browser.
Where do I point my Gemini client?
By now, you should have a Gemini client installed. If you’ve tried to install
one, but gotten stuck, please feel free to give me an email at
help@geminiquickst.art. I don’t mind! You can
do this next part using one of the web portals, but it would be better if you
had a real client installed.
First, open up your Gemini client, and arrange it so that you can see both the
Gemini client and the web browser you’re reading this in. You should be able to
follow the rest of this tutorial in Gemini. In your Gemini client, open
gemini://geminiquickst.art/. You may or may not
be able to click on that link from your web browser and have it open up in your
Gemini client, depending on a lot of nerd stuff that you don’t have to care
about now. If it doesn’t open up on click, copy and paste
gemini://geminiquickst.art/ into your Gemini client. You should get a page
that’s pretty much the same as this one, though the colors and fonts may be
different. Scroll it down until you reach this point, then read the rest of your
page in your Gemini client, rather than your web browser.
Where do I find things to read on Gemini?
Gemini is pretty new, so like the early web, there’s not as much content as
you’re used to on the modern web, and too much of it is tech stuff. But there’s
a lot of other stuff there too, if you’re willing to look.
Gemlogs (like blogs)
One of the main things people have been using Gemini for is blogging. And it
makes sense, because blogs are mostly text, it’s easy to find updates, and the
web has made a real mess of it, where it hasn’t completely abandoned it to
social media.
Several of the clients recommended above have built in feed-readers for
subscribing to gemlogs and staying informed about updates. If yours does, I
recommend that you take advantage of that feature as you find gemlogs you want
to read. It will be more flexible than depending on a feed aggregator hosted by
someone else, and easier than setting up your own feed aggregator.
But to find feeds to subscribe to, you’re best off starting with an aggregator
someone else is running. This is a list of well-known public aggregators in
Geminispace.

CAPCOM is run by Solderpunk, the
founder of the Gemini project. It knows about over 200 Gemini feeds, but picks
100 every month to display. It’s a good way of finding feeds to follow.
Spacewalk is an aggregator that
follows every update to the pages it follows. This makes it a little less
accurate than CAPCOM, but can follow pages that don’t announce their
updates.
gmisub aggregates over
100 feeds using the Gemini simple feed
specification.

Curated directories of interesting pages by topic
Because Geminispace is a lot smaller than the web, it’s still somewhat possible
to hand-curate a list of interesting sites. You may remember how Yahoo! got its
start as a curated index of links by topic.

Medusae.space is an index similar to the
old Yahoo!. You can browse by topic, or search.
Gemini Discovery is a
index of search engines and indices you can use to find things
you’re interested in.

Searching
You can also search Gemini, just like you can search the web. However,
it’s not indexed by Google or Bing or DuckDuckGo; we have our own
search engines. Or rather, search engine. There have been three search
engines built for Gemini, but only one is currently active:
Geminispace.info.
That said, search is not as important, currently, on Gemini as it
is on the WWW. Subscriptions and cross-site links are the main ways of
finding new things.

This part is a little harder, but people are busily working on making
it easier! The first thing that you should know is that there’s no
direct equivalent of the WWW’s social media sites on Gemini. Gemini
doesn’t have a built-in method for posting things, so most people posting
on Gemini right now are using separate tools to write their pages or
posts and to upload them to a server. And that’s leaving out
registering an account on the server, which is usually done manually
by the site owner! But that situation is going to get better. Right
now, there are a few Gemini sites where the “separate tools” for
registering an account and posting pages or updates are web
applications, and it’s likely that someone will make an integrated
native application.
Gemini sites with WWW applications for posting

The Midnight Pub is a hybrid Gemini site with a
“local pub” theme. Some people post regular gemlogs, some people
role-play the part of patrons at the pub. It’s kind of a slow-paced
social media site. Registration requires emailing the bartender to
ask them for a key, but don’t be shy – they just want to make sure
you’re not a spammer. People can subscribe to a feed of just your
posts, or a feed of everyone at the pub.
Gemlog.Blue is a site that makes it easy to
maintain a gemlog. You can register on the WWW side of the site, and
create, edit, or delete posts through the web interface, and view
them through Gemini. People can subscribe to a feed of your posts.
Flounder is another site with a web
application for posting. It’s more general-purpose than Gemlog.Blue
or the Midnight Pub. The registration page asks where you heard
about Flounder, but it’s really just a low-tech anti-spam
measure. Tell them this page sent you.

Gemini sites with public account signup
Shared hosting on Gemini today is pretty similar to shared hosting on
the WWW in 1999, but in general more community-oriented and
friendlier. If you think of these sites as being like GeoCities, but
without neon backgrounds and blinking “under construction” GIFs, you
won’t be too far wrong.
With these sites, you will sign up, either via the web or email, and
have a space that you can access with a native graphical file transfer
application such as FileZilla
(Windows, MacOS, or Linux). You’ll write
Gemtext
documents on your own computer, then copy them to your host with
Filezilla or a similar program. Some of these sites will want you to
send an SSH public key, which may sound too technical, but Digital
Ocean
has a pretty good guide to using them with FileZilla. It’s focused on
their own VPS service, but most of it should apply here, too.
One warning – if you’re on Windows and you’re not careful with how you
install Filezilla, you may end up with some additional bundled
software you don’t want. For Windows users, I recommend
Winscp as an alternative.

pollux.casa offers free Gemini hosting on
subdomains (like ‘yourname.pollux.casa’) that are also reachable by
http. Sign-up is by email to Adële, the host, and access to your
files is by SFTP or FTPS. Overall, this seems like one of the most
friendly site hosting options for newcomers.
If you are a French speaker, you might look at Un bon
café, a French Gemini hosting service that
aims to be simple and use sFTP for uploading content. They also
offer an email hosting service. The service is free.
koyu.space offers free
hosting. Unlike some of the others, your site gets automatically
updated from a git repository you maintain, so this one is probably
not best for non-technical people, unless you have a hankering to
learn git.
SourceHut Pages offers free Gemini
hosting. Their setup is probably more complex than non-technical
users will want to engage with, but it’s free, and it’s somewhat
less involved than running your own Gemini server.
Jae’s Gemini pod offers free hosting,
on a subdomain or your own domain. You’ll need to send the owner a
SSH public key, a name for your website, and the domain name or
subdomain you want to use.
Main Street in Nightfall
City offers
Gemini, Gopher, and WWW hosting at the center of downtown Nightfall
City, home of the Midnight Pub. The hosting here is a little more
hands-on, but more flexible. You’ll need an account name and SSH
public key. The online help focuses on terminal tools, but you
should be able to use FileZilla or similar to upload your pages.
si3t.ch offers free shared hosting. Your
capsule will have its own subdirectory. Instructions are on the
site.

Pubnixes and Tildes
A pubnix is a PUBlic uNIX server, a kind of shared computer for use by
members of a community. They’re usually used by logging in to a
terminal interface using an SSH (secure shell) client. That’s actually
a very good way to dip your toes into the more technical side of
Gemini (and Gopher, and WWW) hosting, but it’s understandable if it’s
not for you. Many pubnixes offer Gemini hosting to their members.
These are a few pubnixes with Gemini hosting:

The Mare Crisium Soviet Socialist
Regency
The Mare Tranquillitatis People’s Circumlunar
Zaibatsu
The Mare Serenitatis Circumlunar Corporate Republic
Ctrl-C Club
envs.net
heathens.club
Park City
RawTextClub
SDF Public Access UNIX System
tilde.pink

Self-hosting guides (here be monsters)
It’s not hard, as these things go to set up a Gemini server on a VPS
(Virtual Private Server), a collocated server, or a Raspberry Pi in a
shoebox under the bookshelf your router sits on. However “as these
things go” covers a lot of evils. You’ll generally need to be familiar
with the Unix or Linux command-line, installing software from a
distribution repository, and with compiling software from source.
I do not yet have any How-To documents collected for self-hosting a
Gemini server. Please let me know if you find or write one!
Conclusion
That’s it! Hopefully by this point you have found some things you want
to read on Gemini, ideally things you’ve subscribed to that will
keep you coming back. And if things have gone really well, you’ll have
established a foothold of your on in Geminispace, and I’ll be reading
something you’ve shared in not too long.
If any of the steps in this document were unclear or you need help for
another reason, please feel free to email
help@geminiquickst.art.
If you see something that’s missing (like a hosting site you want to
recommend), or something wrong, please mail
info@geminiquickst.art.
Thank you for reading! See you out there!

    

    


        
        
            

        
    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Models of European Metro Stations]]></title>
            <link>http://stations.albertguillaumes.cat/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45238055</guid>
            <description><![CDATA[A gallery of drawings depicting the topology of metro stations from different European cities.]]></description>
            <content:encoded><![CDATA[
            Station gallery
            Select a city and a station on the map or on the selectors:
          
             
                Alicante
                Alicante's rapid transit system is called TRAM, which is a train-tram and is operated by FGV, owned by the Valencian regional government. This system has an underground line in the city center, with three stations on it. The layout consists with one or two mezzanines on level -1 and two side or one island platforms at level -2. Luceros and Mercado stations have direct connection with the underground parking lots, which are located above the TRAM tunnel.
            
             
                Amsterdam
                Metro services in Amsterdam can be grouped in two groups. The North-South line (in Dutch, Noord/Zuidlijn) opened recently and M52 services run on it. The central part of the line is underground, running at a considerable depth with two parallel tunnels. The other group of lines consists of services M50, M51, M53 and M54. This line runs mostly overground or elevated, parallel to the Dutch Railways lines. In the city center this line goes underground but at a small depth.
                Most of the underground stations consist of a mezzannine at level -1 and a island platform at level -2. The vast majority of overground and elevated stations also have island platforms, but the hall where the turnstiles and ticket machines are found is located on the ground level.
                Taking into account that most of the metro network runs parallel to rail lines, transfers between these two modes of transport are quick and easy.
            
             
                Antwerp
                The Antwerp premetro (underground tramway) opened in 1975. One of the achievements consisted in linking both banks of the Scheldt river.
                Despite the tram network being huge, the Premetro is short but complex. Lines can be grouped in two. The first group consists in an east-west line with two branches on the eastern side. However, there is a tunnel allowing services between both branches, thus forming a triangle. The second group of lines consists in a tunnel opened in 2015, connecting the city center with the eastern suburbs with a fast service, since most of stations are not opened yet.
                The Central railway station is linked with Astrid and Diamant premetro stations, and together with an underground bike parking, they form a hub. The rail triangle is located in between those two stations. Since the premetro tunnels were built with metro standards, same-level track crossings are not allowed, therefore Astrid and Diamant stations had to be built with platforms at two different levels.
            
             
                Barcelona
                Barcelona is the queen of the long passageways. Until 1995, all transfer stations consisted of corridors with lenghts over 100 m, except for Sagrera and Catalunya.
                Among the reasons for having such long corridors there is the lack of planning or the vision of the metro network as a bunch of individual lines. As an example: line 1 and line 4 were extended to Urquinaona in 1932, but both lines were not connected until 1972, as they were originally operated by different companies. In Plaça de Sants station, the L5 platforms were built as close as possible to the existing ones from L1, which opened 43 years before. However, there is a gap of 150 m, with the national rail tracks located in between.
                Moreover, since the extension of the metro network was slower than the growth of the city, during the 60s and 70s, transfer stations were built 100-150 m apart, in order to increase the accessibility to the metro. Verdaguer is a good examples of this practice.
                Right after 1980, transfer stations were designed in a more proper way, being the L2 stations the best example. A new type of transfer appeared 15 years ago with the extension of the metro towards hilly areas of the city: the vertical transfers. In those stations (eg: Vall d'Hebron, Fondo, Zona Universitària, Collblanc), a big shaft was built in order to fit either high-capacity lifts or series of escalators to reach the platforms.
                The classic layout of metro stations in Barcelona is simple: on level -1 there is one or two mezzanines and in level -2 there are two side platforms, but since 2000 the new stations tend to have a central plafrom instead. In transfer stations, there is tipically a corridor linking the mezzanines of both lines.
                Mandatory to mention the so-called Barcelona solution or Spanish solution: stations with two tracks and three platforms, where passengers alight using one platform and board using the opposite one, improving the flow of passengers and reducing the dwell time. Barcelona was not the first city to implement it, but it was named after most of the stations built in the 30s, 40s and 50s were designed with such layout.
            
             
                Berlin
                The U-Bahn and the S-Bahn are the two rapid transit systems of Berlin. The city-state owns the first and the German railways own the second. The S-Bahn normally runs overground or elevated and the U-Bahn does it underground, as the name suggests in German, but this is not a norm since some parts of the U-Bahn are elevated and vice versa.
                The oldest lines were built either in elevated sections or underground, but very close to the surface, creating a direct connection between the street and the platforms in most of the cases. The lines built after World War I are a bit deeper, in order to fit mezzanines and corridors between the street and the platform levels.
                Transfer stations have a very easy tolopolgy, since stations are located close to the ground level and island platforms are predominant.
            
			 
                Bilbao
                Despite the metro opened in 1995, its layout follows former metric-gauge rail lines that were converted to metro, such as the Bilbao - Plentzia line. Metro Bilbao operates lines 1 and 2 and Euskotren operates line 3, together with other suburban and regional services.
                Due to the orography of the city, stations may have different layouts. The stations located in the city center are deep, since the Nerbion river is located nearby and there are plenty of hills located in the meanders of the river. The stations of the line 1 branch are located on surface, since they were part of the former Plentzia railway. 
                Line 3 benefits from having already existing stations, such as Bilbao-Aduana (currently called Zazpikaleak/Casco Viejo) and Matiko, both part of the former Plentzia line, despite the connection between those two stations is made through a new double-track tunnel.
				Some transfer stations have effective designs, such as Lutxana or the former Bolueta station.
            
             
                Boston
                
                All the rapid transit lines in Boston are centenary. Three of them originally opened as underground tramway tunnels in downtown Boston, but only two were converted to pure metro lines. The Green line is still an underground tram line.
                Most of the downtown stations are quite unusual, as they were built using early construction methods and most were designed to serve as tram stations. For instance, some stations in the Orange line have offset platforms. At State station, the Orange line platforms are in different levels.
                Underground stations tend to be located close to the surface. This can be appreciated at Government Center, where the Green line platform has a very particular shape because the streets located above ground were quite narrow when the line was constructed, and therefore impossible to dig wider tunnels.
                Despite being a city where the rapid transit lines were built without a network plan, transfer stations have a good layout, providing short and quick connections.
            
             
                Brussels
                The Brussels metro is a good example of a planned system. It was planned in the 60s, and the four existing lines were built following this criteria: if for practical reasons, the section to be opened was not long enough to be operated as a metro line, the section would open provisionally as a premetro (underground tram), with temporary low floor platforms and temporary ramps connecting the streets with the tunnel. Once the construction of the line is advanced, the premetro operation is cut and the line is converted into a full metro line, removing the ramps and elevating the platforms to metro standards. Currently lines 1, 2, 5 and 6 are fully metros and lines 3, 4 and 7 are premetros.
                The whole network has been built following the same plan. Transfer stations have a good design as well, with the notable exception of Dè Brouckère, where there is a long corridor. Cross-platform transfers can be found in Beekkant and Gare du Midi. Arts-Loi, Montgomery and Rogier have crossing interchanges.
                Most stations have side platforms located at level -2, whilst level -1 is reserved for mezzanines. Stations on line 6 have island platforms because trains run on the left side instead. Stations on lines 3/4 were built using the Spanish solution, where passengers board using the island platform (except in Gare du Midi).
                In order to reduce fare evasion, most stations have been equipped with turnstiles during the last decade, replacing the existing honor system which is still present in some stations due to the complexity of its layout.
                
            
             
                Budapest
                Budapest was the first city in continental Europe to have a metro. Line 1 opened in 1896. Similar to other systems opened around 1900, tunnels have a narrow profile. Trains are only 2.60 m high and 30 m long.
                Lines 2 and 3 have a similar style to other Eastern European metros, despite the decoration has nothing to do. Line 4 was built recently. In these three lines, tracks are laid in two parallel tunnels that cross Budapest at a considerable depth. Stations have island platforms in two parallel galleries, which are connected with the ticket hall through a long escalator. The ticket hall can either be located at ground level or just underground. In the latter case, there are direct staircases connecting the hall with the tramway platforms or bus stops.
                The northernmost and southernmost parts of line 3, tracks run underground but at a very little depth. Here stations have side platforms, which are located at level -2 (and a mezzanine at level -1) or directly at level -1, together with an independent booking hall for each direction.
                Transfers differ, depending on the station. In Deák Ferenc Tér and Kálvin Tér, transfers consist in a quick connection through two escalators and a short corridor. In other stations, transfers may be longer since one line might be running close to the surface while the other may be running very underground (eg: Keleti pályaudvar, Batthyány tér)
            
             
                Bucharest
                The Bucharest metro consists of 5 lines, despite lines M1 and M3 share their tracks and line M5 has two branches. The original plan from the 70s consisted of three lines: a east-west line (M3 and southern section of M1), a north-south line (M2) and a circle line circa 40 km long.
                Unlike other Eastern European metros, the Bucharest one was not built at a considerable depth but using cut-and-cover methods. The platforms are typically located at level -2 or -1 and tend to be central, despite some stations in line M1 have side platforms. 
            
             
                Buenos Aires
                
                The Subte is the oldest metro network in Latin America. It consists of 6 lines. 4 of them run east-west (A, B, D, E) and the other two are north-south (C, F).
                The entire network runs underground and except for line H, the tunnels were build close to the surface. Most of the stations have side platforms but those stations that are or had been terminus usually have island platforms.
                The lower level of an average station comprises the platforms. If there is enough space between the platform level and the street level, a mezzanine can be found, containing the ticket booths and turnstiles. In the opposite case, each platform has independent accesses and turnstiles are located at the platform level and there are no overpasses or underpasses.
                The Subte applies a bizarrenaming criteria. Station names are independent for each line. So, a transfer station will have multiple names, one for each line calling at it (eg: Pueyrredón (B) and Corrientes (F) are part of the same station). But there is also the opposite situation, where there are stations with the same name in different lines: Callao and Pueyrredón are four stations located in lines B and D, but they have nothing to do.
            
             
                Copenhagen
                Copenhagen has a modern and automatic metro. Both the Metro and the S-tog have an honor system and most underground stations look like the same: mezzanine with vending machines at level -1, a landing at level -2 and island platforms at level -3. The connection between the platform and the mezzanine is provided by lifts and escalators. Upbound escalators are separated from the downbound ones.
                Transfer corridors are connected to mezzanines in Frederiksberg and Kongens Nytorv, but not in Nørreport, where the corridor heading to the S-tog starts at the end of the Metro platform.
            
             
                Frankfurt
                Despite Frankfurt has officially a U-Bahn (pure metro), technically is a Stadtbahn (light rail), despite the platform level is high even for stops located at the street. The S-Bahn is also part of the basic rail network of the city.
                The main transportation hubs were desinged to provide quick transfers between the rail lines. Most transfer combinations involve passing through a staircase or an escalator, but in Hauptwache, a cross-platform is provided for transfers between S-Bahn and U-Bahn lines U6 and U7.
            
             
                Glasgow
                Glasgow has a very peculiar subway. It opened in 1896 as a circle line powered by cable, like the San Francisco cable cars. The subway was fully renovated between 1977 and 1980 in order to change its operation to electric power, build new workshops, relocate stations and refurbish the rest of stations.
                Before the renewal, all stations had a very narrow island platform. A staircase located at the end of one platform lead to the ticket hall and the exit, typically located inside the station building. Most of the stations retain this layout today. However, escalators have been installed in some stations, to connect the ticket hall with the street. The stations with the highest patronage were completely rebuilt: Buchanan Street has a central and a side platform nowadays. In St Enoch, two side platforms replace the former island platform. Partick station was built during the renewal works in order to allow transferring from the Subway to ScotRail.
            
             
                Hannover
                Hannover has a Stadtbahn, which is a mixture of a tramway that runs in a metro-like tunnel in the city centre.
                There are three trunk tunnels in Hannover (A, B, C) that meet in Kröpcke station. Tunnels B and C run overlapped between Kröpcke and Aegidientorplatz.
                The layout of an average station is simple and similar to the ones in other cities: a mezzanine at level -1 and side platforms at level -2.
                Kröpcke station is a huge complex with lots of accesses, escalators, staircases and mezzanines, since is the only point where the three tunnels meet. Hauptbahnhof station (main station) has elevated rail platforms and an underground station for the Stadtbahn, composed of two island platforms and four tracks. Aegidientorplatz station has a peculiar layout, since the mezzanine is at level -1, the northbound platform is at level -2 (with 2 tracks) and the southbound platform is at level -3 (with 2 tracks as well).
            
             
                Lyon
                The four lines of the Lyon metro are technically different. Lines A and B and D are rubber tired. Line A has manual conduction and line D was already opened with automatic trains. Line B switched from manual driving to automatic operation in 2022. 
                Line C partially follows the route of a former funicular that had a pent of 176‰. Therefore it operates as a rack railway between Hôtel de Ville and Croix Rousse, since normal metro lines have a maximum pent of 40‰.
                Lines A and B run at a very little depth. Even line A crosses the Rhone using the box girder of Pont Morand. The stations of this line only have one underground level, with side platforms and turnstiles on it. Some stations have underpasses, connecting both platforms. Line D tunnels are not located deep either, but most stations have a mezzanine between the street and platform levels. The latter situation also occurs in the eastern section of line A.
                Lyon had an honor system until two decades ago. Since some staion have secondary accesses connecting the streets with the platform, it is common to find turnstiles in the platforms.
                Most of the transfer stations have an efficient layout, such as Hôtel de Ville, Saxe-Gambetta or Charpennes. However, the links between at the two main railway stations (Part-Dieu and Perrache) are long.
            
             
                Lisbon
                Currently the Lisbon metro consists of four lines. Until the mid-90s, the network had a Y-shaped single line. This line was split into three (Blue, Yellow and Green) and the Red line was built as a completely new line. Therefore, all the internal metro transfers are less than 25 years old.
                The layout of the stations differs slightly: Baixa-Chiado and Campo Grande have parallel platforms for the two lines serving the stations. Saldanha, São Sebastião or Oriente allow quick transfers that involve climbing stairs or elevators. However, in Alameda or Entre Campos the transfer consists in a long passageway.
                The standard layout for the stations built before the Carnation Revolution consisted in two side platforms at level -2 and a mezzanine at level -1. These stations featured short platforms, that were extended years later to allow 6-car trainsets. Together with these platform extensions, secondary mezzanine and accesses were added. The stations built recently tend to have a single mezzanine and are located at deeper, since they were built in hilly areas.
            
             
                London
                
                The London Underground (or the Tube) is the oldest in the world and it consists of two different networks: the sub-surface lines (running close to the surface) and the deep tube lines (runing deep, with tunnels that ressemble a tube).
                The sub-surface lines are the ones inherited from the Metropolitan Railway and from the District Railway, two lines built using cut-and-cover methods or running elevated or at ground level, which were steam operated until the early 20th century. Stations consists in a building located at ground level, containing the ticket offices and fare gates, and the platforms placed at level -1. The stations were located inside a block of houses whenever possible and most of them had a canopy (still in place in Paddington, Bayswater or Earl's Court). With the electrification of the tracks and real estate speculation, most of the stations have been covered with concrete labs (such as in Gloucester Road or Mansion House).
                The deep tube lines began to be built in the last decades of the 19th century, when the boring methods were a bit developed. They were already planned to be operated with electric trains. The tunnels were bored at a depth of 20 m and until the construction of the Victoria Line, they followed the streets. Stations consists of a building hosting the ticket offices and the fare gates, which are connected with the platforms (most of them are island platforms) via lifts and spiral staircases located inside of shafts. In 1913 an escalator was installed at Earl's Court as part of a test to replace lifts. Since the result was favorable, the practice of building stations with lifts and spiral staircases in shafts was abandoned. From this moment on, the new stations were built with escalators, and the existing ones (especially those with a high ridership) were transformed.
                Initially each line was operated by a different company, so transfers between lines weres not granted. This was corrected after the nationalisation of the Tube.
                Some stations host huge flows of passengers. This obligated the local authorities to build wider or newer passageways and escalators in some transfer stations. That is the reason some transfer stations have one-way corridors as well, such as in Oxford Circus or Victoria.
            
             
                Madrid
                technically, the Madrid metro lines can be divided into two: the narrow profile lines (1-5 and the Ramal) and the wide profile lines (6-12). The narrow profile lines were the first to be built and were inspired by the Paris metro. That is why old stations have side platforms located at level -2 and one mezzanines at level -1. Decades after the opening, lines 1 and 3 got their platforms extended from 60 m to 90 m long and secondary mezzanines and accesses were added.
                The lines with a wider profile were built with the aim of fitting larger trains and larger stations. Moreover, these lines were built a highest depth in comparison to the narrow profile lines, at a depth of 15 to 25 m below surface level. The streets and the platforms are connected through 3 to 5 series of staircases and escalator, with the ticket hall in between. Therefore, access times are longer compared to narrow gauge lines.
                Since the 90s, the design and layout of new stations have been standadrised, with stations being built using cut-and-cover methods with slurry walls.
                Madrid has plenty of different layouts for transfer stations. In comparison with other cities, Madrid has a great amount of stations containing long corridors, but not at the level of Barcelona.
                Possibly the most prominent stations are the macrohubs built in the first decade of the 2000s, with huge mezzanines, wide staircases and lots of lifts and escalators, allowing quick connections between metro, commuter train and interurban buses as well. The best example is Nuevos Ministerios, but Chamartín, Sol, Príncipe Pío, Plaza de Castilla or Moncloa also need to be mentioned.
            
             
                Marseille
                The Marseille metro is formed by two lines that cross themselves in Saint-Charles and Castellane, both located in the city centre. The links between lines in these two stations are quick, since in Saint-Charles line 2 is between the two tracks of line 1 and in Castellane both lines have their platform very close to the intersect point.
                There are three kinds of stations, according to their layout: the suburban, which are elevated (eg: Bougainville, Ste-Margueritte, La Rose); the underground ones close to the surface, with the ticket hall at level -1 and side platforms at level -2 (eg: Baille, Périer); and the deep centric stations, which have island platforms and a single access consisting of long escalators connecting the street level with the mezzanine (eg: Cinq Avenues, Estrangin).
                Noailles station is the most particular since the former tram tunnel was diverted when metro line 2 was built. Currently the former tunnel serves as a passageway, and the former tram terminus is a ticket hall.
            
             
                Milan
                Line 1 opened in 1964 and was the first metro line in the world to be built using slurry walls. Line 2 opened four years, following the same design standards for line 1. Stations have a very functional layout, since passenger flows were seriously taken into account. Almost all stations have one-way staircases connecting the side platforms (located at level -2) and mezzanines (at level -1): one for passengers entering and another for passengers alighting.
                The same concept was latter aplied to lines 3 and 5, opened decades later, despite both having a radically different design in their stations, compared to lines 1 and 2. Most of their stations also have mezzanines at level -1 and side platforms at level -2.
                Engineers opted to superimpose the tracks in the central section of line 3, where tracks follow the narrow streets of the old city. As a result, the stations of this sections are a maze of lifts, one-way staircases and escalators, combined with a peculiar decoration.
                The transfers are typically short and quick, especially in Loreto, Centrale, Cadorna and Repubblica. The only two stations having long corridors are Lotto and Porta Venezia.
            
             
                Paris
                The Paris Metro has the most labyrinthine interchanges in Europe.
                Almost all the metro network was opened before World War 2. The first transfer stations, opened in the early 1900s, had simple transfers, with bidirectional passageways. Since 1920, the company responsible for the metro began to install portillons automatiques (automatic doors) in some stations. The portillons automatiques are doors located at the entrance of a platform, that blocks the access to it once a train enters the station, in order to reduce the dwell time and prevent last-second passenger boarding the trains. Therefore, in order to limit the access to platforms but not the exits, they decided to build two-directional corridors and staircases. That is how the stations began being underground mazes.
                In the 1970s the RER (suburban railway) was opened. This meant that some metro stations had to be partially rebuilt.
                Taking the advantade that the spacing between stations is one of the lowest in the world, some RER stations were placed between two metro stations, so both could be connected with the RER. The most extreme case is that 6 metro and RER stations are connected underground (St-Augustin, St-Lazare, Haussmann-St-Lazare, Havre-Caumartin, Auber and Opéra).
                The average metro station in Paris consists of a mezzanine at level -1 and two side platforms at level -2. The termini of the oldest lines used to have a loop (Place d'Italie M5, Étolie M6, Nation M6, Porte Dauphine M2). Some of these stations were actually doubled, since there was a station for the trains that terminate there and another one for the trains (and passengers) beginning their journey.
            
             
                New York
                
                The New York subway combines an extensive network of elevated trains (in Brooklyn and in the Bronx) with an underground train network that was built in the first half of the 20th century, especially in Manhattan. The subway links Manhattan with the other boroughs with tunnels or via the well known bridges, such as the Williamsburg Bridge or the Manhattan Bridge
                A characteristic feature of this subway is the existence of local and express services in separate but parallel tracks, so a tunnel can have 4 tracks (2 per direction and 2 for each type of service). The express trains run in the central tracks and the local trains run in the side ones. 
                The elevated sections have stations placed above the streets and they can be accessed via staircases located in the sidewalks. Ticket halls are located at level +1, inside the viaduct, and platforms are at level +2, partially covered by shelters. The stations with express services tend to have central two platforms.
                The underground lines run very close to the surface and they have plenty of piles of steel between the tracks and in the platforms. The stations that are served only by local services have side platforms at level -1, together with the ticket halls. Platforms are not linked via an underpass or an overpass. Express stations have two island platforms at level -2, allowing cross platform transfers between the local and express trains. In this kind of stations, mezzanines with the fare gates are located at level -1.
            
             
                Prague
                The three lines of the Prague metro form a radial network. All the lines cross at three selected stations in the city center. Almost the totality of the network is underground. The first line that was built (C) is the one running closer to the surface, especially at the city center and in the southern section. Lines A and B run much deeper.
                The deep stations have island platforms at the deepest point of the station. The ticket hall, which is located beneath the street level, is connected with the platforms through escalators. A few stations even have two mezzanines, one at each end of the station.
                Line C has not very deep stations at the southern part. They are composed of a island platform at level -1 and two ticket hall buildings located at ground level, each one at a different end of the platform.
                At Můstek i Florenc, both metro lines run at a considerable depth, so both stations are linked through a rather short corridor, located at a level between both metro lines. Hoewever, Muzeum station has line C located close to the surface, whilst line A station is deep. Both lines are connected through a series of escalators.
                Most of the metro stations have shops and stores in the ticket halls.
            
             
                Rome
                The Rome metro has few lines compared to the extent of the city. Until a few years ago, there were only two lines that intersected at Termini station, which is the central railway station as well. Because of it, Termini station is the one with the highest ridership of the city and most of the times it gets crowded. This station has one-way corridors for entering, exiting and even for transferring. A decade ago, the city had to build an extra set of escalators and corridors to decongest the existing link connecting lines A and B.
                The other interchange station is San Giovanni. Line C opened in 2018 but the final passageway between both lines is not completed yet. Currently, passengers need to exit through the faregates and enter again.
                The stations of the southern section of line B were opened in the 1950s and are very simple. The construction of the northeastern section of line B and the entire line A is much more recent and their stations were designed with one-way staircases and passageways.
            
             
                Rotterdam
                The Rotterdam metro has 5 different services that can be grouped into two lines. One of these services even arrives to the city of the Hague. The design of the stations is rather simple. For stations located underground, the layout consists of a mezzanine is located at level -1 and two side platforms at level -2. Elevated stations tend to have a island platform at an upper level and a mezzanine at the street level.
                Blaak and Beurs have layouts were two lines cross, one over the other. The connection is provided via direct staircases linking both platforms.
            
             
                São Paulo
                
                The metropolis of São Paulo has a rapid transit network operated by three different companies. This is a relatively new metro (it was opened in 1968, despite some lines were converted from existing railways), with a layout and design thought to hold huge flows of passengers. Trains can be up to 200 m long. 
                Stations are very wide. Some of them, such as Sé or Luz (line 1) have the Barcelona solution, in order to ease the passenger flows.
            
             
                Saragossa
                Saragossa does not have metro but the commuter line C-1 has an urban section with three underground stations. This section was covered when the high speed rail line arrived to the city.
                All the stations have a building at street level that hosts vending machines and the fare gates. Platforms are located at level -1, just under street level.
                Miraflores station has a temporary access to a car parking, since the urbanisation of the street over the rail line has not been finished and the station building cannot be used. This station also has an underpass to reach the secondary platform.
                Goya station has connection with the tramway, at Fernando el Católico station. The connection has to be performed by crossing two zebra crossings.
            
             
                Valencia
                The Valencia metro is actually the merge of different narrow gauge suburban railways that were connected via a tunnel crossing the city center. So this system is somehow the hybrid of a premetro and a rail, since in the city of Valencia is like a metro, but in the suburbs this works like a rail with lots of level crossings and single track sections.
                The vast majority of underground stations have one or two mezzanines at level -1 and two side platforms at level -2. There are some stations with a different layout compared to the others, especially in lines 3 and 5: Bailén, Avinguda del Cid, Àngel Guimerà and Colón have island platforms. Alameda has four tracks and three platforms (2 for the Rafelbunyol line and 2 for the Marítim line).
                Xàtiva station has a radically diferent layout, as the platforms are overlapped because there is the juntion of the line towards Bailén and Jesús just 20 m after the platform end (on the eastern side).
            
             
                Warsaw
                Line 1 has two types of stations: the ones located in the suburbs, having side platforms at level -1 and ticket halls at street level, and the ones located in the city centre, having a island platform at level -2 and a mezzanine at level -1.
                The stations on line 2 are similar to the ones with a island platform on line 1, with the difference that the platforms are located a bit deeper.
                There are two main transfer stations. Świętokrzyska is the crossing point of both metro lines and the transfer is quick. Half a kilometer to the south, there is the hub consisting of Centrum metro station, Śródmieście suburban rail station and the Central rail station. The latter two form a huge underground complex, combined with a shopping mall. The connection of Centrum and Śródmieście stations is done at street level.
            
             
                Vienna
                Part of the current metro network (U-Bahn) is inherited from a primitive urban rail network known as Stadtbahn that was steam-powered until the 1920s. Once the network was electrified, the rolling stock used was similar to the ones used for the tramways. Most of its network was elevated or ran at a street level, but without level crossings.
                During the 60s, the municipal government decided to build a couple of tram tunnels. At the same time, they also planned a metro network consisting of a basic network, with parts of it coming both from the Stadtbahn (U4) and from the newly tram tunnels (part of current U2), asides from the construction of line U1. In the 1980s the second phase took place: line U3 was built and line U6 was integrated from the Stadtbahn.
                The layout of the stations depends on the time they were built. The non-underground stations that were part of the Stadtbahn have side platforms and the access is made via the station buildings, which are in the Art Nouveau style. The stations that were part of the tram tunnel are located under street level and are quite simple: offset side platforms at level -1. The new stations built from the 1970s on typically have a island platform at the lower level and two mezzanines at the upper level, which can be either on street level or below, and is connected with the platforms via escalators or elevators. The depth of the latter stations is variable, but the ones located in the city center may be very deep.
                All the transfer stations have been built after 1970 and their layout reflects the idea of having efficient links. Except for Praterstern, all stations have quick transfers.
            
            
                Oslo
                The current Oslo T-bane system originated from an old network of suburban trams that developed in the western suburbs of the city during the first half of the 20th century, and a modern metro system built from the 1960s onwards in the eastern part of the city. Both networks were progressively merged and unified between the 1970s and the 2010s.
                The Oslo metro runs mostly elevated or on the surface, but there are also shallow underground sections. Surface stations usually have two side platforms. Access to the platforms is open, using an honor system, and access to the platforms is performed directly from street level through ramps. In some places, there is a Narvesen kiosk that serves as both a ticket reseller and a convenience store.
                The underground stations are located either in the city center or in the northeastern suburbs. Most stations are situated at a shallow depth and have two side platforms at the deepest level. At the immediately higher level, there is a lobby that can be either at street level or underground. The connection between levels is made through ramps and staircases.
                There are a few stations that are situated at considerable depth: Romsås, Ellingsrudåsen, Stortinget, Nydalen, and Vestli. Access to the first two is only possible through large-capacity elevators that connect the street to the concourse, in addition to a ramp of over 200 meters in length that also links the street to the concourse level.
            
            
                Gothenburg
                The Gothenburg tram has an underground station. Hammarkullen is located at a considerable depth, in a hilly suburb in the northeastern part of the city. The tracks pass through a dual tube tunnel. Trams run on the left only in this specific part, as the station has island platforms and the rolling stock only has doors on the right side. From the platform level, there is a flight of escalators and an inclined elevator that leads to the lobby, located at street level.
            
            
                Hamburg
                Hamburg has two rapid transit systems: the U-Bahn and the S-Bahn. The U-Bahn, which is the proper metro system, is one of the oldest in Europe. The first circular line was constructed combining elevated, at-grade and shallow underground sections. Subsequent extensions have also been built alternating these three typologies. However, the central section of U2 and the branch of U4 were constructed at a greater depth.
                In general, the underground stations are quite shallow and have a island platform (side platforms in the original U3 stations). Some stations have an intermediate level serving as a lobby. On the other hand, the elevated stations have a street-level building (where the lobby is located) and a island platform or two side platforms at level +1.
                The S-Bahn uses sections of the German railway network. The construction of the City S-Bahn (an underground line through the city center) started in the 1960s. Their stations have large island platforms located at level -2, generally with lobbies at level -1, standing at the ends of the platforms.
                As for interchanges, some have been designed to facilitate cross-transfer connections (Barmbek for U3-U3 connections, Wandsbek-Gartenstadt, Berliner Tor, Altona, Hauptbahnhof between S-Bahn trains, Norderstedt Mitte), with parallel platforms (Ohlsdorf, Barmbek for U3-S1 connections, Hauptbahnhof Süd, Elbbrücken) or with direct transfers via a single flight of stairs (Schlump, Jungfernstieg).
                There are other transfers that were poorly designed, such as the long passageway between Rathaus and Jungfernstieg, or the street-level transfer at Wandsbeker Chaussee, Dammtor/Stephansplatz, or Sternschanze.
            
            
                Essen
                Essen's Stadtbahn has two trunk lines. The one that runs through Rathaus station is a group of tram lines that run underground in the city center, with tram vehicles and low-level platforms. The lines that pass through Hirschlandplatz are light metros.
                There is a variety of station typologies. The shallower stations usually have side platforms, while the trunk line stations of the light metro have island platforms, which are situated at a considerable depth.
            
            
                Dortmund
                Dortmund's Stadtbahn consists of three trunk lines located in the city center. The east-west lines are operated with low-floor trams, while the other two are operated with high-floor light metros. Most stations are located at a shallow depth. The station vestibules are either at street level or at an intermediate level between the street and the platform.
                In Dortmund, there is also a monorail system (H-Bahn) that serves the Technical University of Dortmund (TU Dortmund). It consists of two lines. The track is single-track, but there are some stations with passing loops. All stations are elevated or at-grade.
                Bochum's Stadtbahn consists of a north-south line, as well as several tram lines that run through underground sections in the city center. Most Stadtbahn stations have island platforms and vestibules located at an intermediate level between the street and the platforms. In some stations, the platforms are situated at a higher depth, such as Rathaus Nord and Hauptbahnhof.
            
            
                Bochum
                The Bochum Stadtbahn consists of a north-south line, as well as several tram lines that run through underground sections in the city center. Most Stadtbahn stations have island platforms and entrances located at an intermediate level between the street and the platforms. In some stations, the platforms are situated at a higher depth, such as Rathaus Nord and Hauptbahnhof.
            
            
                Mülheim
                The Stadtbahn stations in Mülheim are different. The stations that are close to the Ruhr have platforms at a considerable depth to allow the tunnels to pass underneath the river. The remaining stations have a typical configuration of any Stadtbahn network in Germany, with a vestibule at level -1 and platforms (either side or central) at level -2.
                The Hauptbahnhof station is an intermodal hub that consist of elevated rail platforms, four underground Stadtbahn tracks with two island platforms and two underground bus platforms parallel to the Stadtbahn ones.
            
            
                Duisburg
                All Stadtbahn and underground tram stations in Duisburg have island platforms. These platforms are usually located at level -2, while level -1 is reserved for the lobbies.
                There are two stations with a particular layout: Hauptbahnhof and König-Heinrich-Platz, which are the transferring points for the north-south and east-west lines. These stations have two parallel platforms, stacked on different levels (-2 and -3). Different combinations of escalators and staircases allow for transfers, access, and exit from the station.
            
            
                Düsseldorf
                Düsseldorf has two Stadtbahn main lines (north-south and northeast-southeast), as well as an underground tram main line. Both Stadtbahn lines share tunnels between the central station (Hauptbahnhof) and the city center (Heinrich-Heine-Allee), with tracks running parallel to each other. At Hauptbahnhof and Heinrich-Heine-Allee, the platforms serving the four tracks are located at the same level. However, at the intermediate stations, platforms are overimposed, being the northbound one on the upper level.
                On the other hand, the underground tram stations have low side platforms at level -2 and a mezzanine at level -1.
            
            
                Turin
                Almost all metro stations in Turin follow a standard design consisting of two side platforms at level -3 and a lobby at level -1. The connection between the lobby and the platforms is made through escalators that go directly from the platforms to the lobby, elevators, or two flights of stairs.
                Porta Nuova is the central rail station and has a different layout: the lobby is located at level -1 and platforms are at level -2, which can be reached by stairs or an elevator. There is a direct connection from the metro mezzanine to the railway station original hall, which is now part of a shopping center.
                Porta Susa station has metro platforms at level -4, an intermediate level at -3, and an open hall located inside the large canopy that constits the railway station building. The railway station itself consists of three levels, with the eastern part of the station featuring a huge glass roof canopy measuring 380 meters long by 30 meters wide. Level -2 also contains the four rail platforms. On level -1 there are four passageways that connect the western accesses to the station and act as an intermediate level to connect crowds coming from the different platforms.
            
            
                Lausanne
                The Lausanne metro consists of a light metro line (m1) and an automated rubber-tired metro line (m2), which originated from a funicular that was later converted to rack railway operation.
                The stations on the m1 are either locatred underground or at street level. Some stations have only one platform with direct access to the street, as the track is single-track. Stations with passing loops usually have two side platforms. The terminal station at Renens CFF is part of the Swiss Federal Railways station.
                On the other hand, the stations on the m2 line are more varied. All stations have side platforms, except Sallaz. Some have platforms are located at street level, like Ouchy or Grancy. Others are very swallow and can be accessed via a staircase or ramp, such as Délices or CHUV.
                Finally, some stations have a unique layout due to the topography of the old town, particularly the deep and narrow Flon Valley. Flon station is a main hub. It is located at Place de l'Europe. The m1 station is at the same level as the square, while the LEB (railway) and m2 stations are at level -2. From level -2, five elevators ascend to the height of the Grand Pont, located about twenty meters above.
                Similarly, the Riponne station is situated in the Flon River Valley. The station is located at an intermediate level between the street following the valley and the Riponne Bridge. Four elevators (two per platform) connect the three levels.
            
            
                Porto
                The Porto metro is a newly constructed light metro. It has two trunk lines: one north-south and another east-west, with a section that follows the path of the former narrow-gauge lines that departed from Trindade, which now serves as a transfer station between the two trunk lines.
                The surface stations have the typical design of a modern tram station, with shelters and pedestrian crossings at the ends of the platforms to switch platforms or exit the station.
                The underground stations have side platforms at the deepest level, but there are differences in the layout of intermediate levels and the location of the booking hall.
            
            
                Munich
                The Munich U-Bahn is a metro system formed by 6 different lines, plus two that only operate during rush hours. The network has lots of spurs, but in the city center all those lines merge and form 3 trunk lines, in addition to an east-west trunk line of the S-Bahn, which, due to its frequency and performance, can be considered a metro, just like in Berlin and Hamburg.
                Most stations have island platforms located at level -2 and a couple of lobbies located at level -1, just above the ends of the platforms. Any station has turnstiles: a honor system is used instead. In some specific stations the platforms may be located at a greater depth, which has required the installation of long escalators, like the ones in the central part of the U4 and U5.
                One of the characteristics of the Munich metro is the presence of cross-platform transfers at many stations, with coordination on the arrivals and departures. Some examples include Scheidplatz, Innsbrucker Ring or Neuperlach Süd. Additionally, some other stations with terminating trains usually have three or four tracks, such as Hauptbahnhof (U1-U2), Münchner Freiheit, Olympiazentrum, Kolumbusplatz, Fröttmaning, or Implerstraße. Some of these stations have elevators that provide direct access between the platforms and the street.
                The most centric S-Bahn stations use the Barcelona solution. At Hauptbahnhof and Karlsplatz, passengers board using the island platform and alight via the side platforms; while at Marienplatz, due to narrow streets, the two tracks are overlapped: passengers aight from the train using the right hand side in the direction of travel, and board through the opposite doors. Along with the two levels dedicated to the S-Bahn (-2 and -3), there is also the U-Bahn station located at level -4, whose platforms are separated by nearly a hundred meters since the streets above are narrow and the City Hall building is inbetween.
                In other transfer stations, the line change is direct through a flight of stairs (Odeonsplatz, Hauptbahnhof, Sendlinger Tor) or through the vestibules in the case of most U-Bahn to S-Bahn transfers.
            
            
                Nuremberg
                The Nuremberg U-Bahn has three lines. Two of them, U2 and U3, share tracks in the central section and have automatic operation.
                The station layout for most of the stations is quite simple. First of all, the ticketing policy is based in an honor system, so there aren't turnstiles in any station. The platforms are always located at the lowest level of the station, usually at level -1 or -2 (if the station has a mezzanine at level -1). In some cases, there is direct access from the street to the platform. All stations have elevators.
                The two interchange stations between the U-Bahn lines are designed to provide quick transfers. At Hauptbahnhof, the U1 station is located one level below the U2 and U3 station, and only a short flight of stairs is needed to change. At Plärrer station, a cross-platform transfer is ensured in both directions, as the platforms of both lines are stacked.
            
            
                Stuttgart
                The Stuttgart Stadtbahn is quite complex, but its operation can be simplified into cross-valley lines and the valley lines. Outside the city center, tracks run on street level and most stations ressemble modern tramway stops. In the city center, stations are underground and have side platforms at level -2 and one or two lobbies at level -1.
                The stations in the central section of the S-Bahn have a island platform at level -2 and lobbies placed at both ends of the platforms, at an intermediate level between the platform and the street.
            
            
                Lille
                The Lille metro consists of two VAL (light automated vehicle) lines. A VAL system is characterized by very narrow and short vehicles that operate at a high frequency in order to accommodate the demand. The narrow gauge is a direct consequence of minimizing tunnel construction costs.
                Initially, the metro operated on an honor system, so the stations were designed to allow easy connections between streets and the plaforms. The subsequent installation of turnstiles means that some stations may only have them installed in certain accesses, while others may have a weird distribution turnstiles.
                The main station of the network is Gare de Flandre, which is the central railway station and also a common station for both metro lines and tram lines, whose platforms are underground. This station provides a cross-platform transfer between the metro lines. Additionally, the transfer between the metro and the tram is also very fast. As a curiosity, the tram station has a platform exclusively for passenger alighting, since it is the last station.
                The other interchange station between the two metro lines is Porte des Postes, where the platforms of the two lines intersect at different levels, but transfers are quick.
            
            
                Palma
                The Palma metro is a recent construction. The section closest to the city center was built by taking advantage of the underground section of the Palma-Inca line at the entrance to the city. Between the Intermodal Station at Plaça d'Espanya and Son Costa - Son Fortesa, the metro tracks run parallel to the aforementioned railway line.
                The Estació Intermodal is the main transportation hub in Palma. There is an underground bus station located next to the underground railway and metro station. In fact, this hub is the starting point for all the interurban bus lines and rail lines originating from Palma.
                All the underground section was built very shallow. In fact, the stations located on Gran Via Asima have the same design, with platforms and lobbies located at level -1 and an underground passage at level -2 equipped with escalators and elevators.
                The Son Sardina station is located on the surface and provides an interchange with the Palma-Sóller line. The UIB station, on the other hand, has a street-level passenger building, although it does not host any facilities.
            
            
                Brescia
                The Brescia metro consists of a single line that opened in 2013. The rolling stock comprises Ansaldobreda’s automatic trains, also in operation on Milan metro lines 4 and 5. The line runs shallowly in the northern section, deeply in the city center, and on surface level and elevated through the eastern suburbs. An honor system is employed, eliminating the need for turnstiles.
                Some of the deepest stations, such as Marconi, Ospedale, Stazione FS, Bresciadue, or Volta, follow a standard design with two side platforms at level -3. These platforms are connected to the mezzanine at level -2 via a staircase and two independent escalators. From the mezzanine, there is access to an intermediate level (-1) and a further flight of stairs leading to the street.
                Shallow stations typically consist of two side platforms directly accessible from the street, while elevated stations feature an island platform.
            
            
            
                Istanbul
                Despite having 10 lines in operation, the Istanbul metro is quite modern. Except for lines 1 and 2, built in the 80s and 90s, the rest of the network was constructed in the 21st century. Extensions are underway in both the European and Asian parts of the city. The tram network complements the metro, which incorporates turnstiles at each stop. Additionally, the public transportation network includes four funiculars, three of which are entirely underground.
                The metro lines exhibit significant differences in technical features, including train type, automation, track count, and electrification system. Construction methods for tunnels and stations vary from line to line, affecting station layouts. With the exception of line 1 which runs shallow or elevated, all lines run at considerable depths. Access and egress times are relatively high and some transfer layouts may result in long passageways or unnecessary multiple level changes. Moreover, transfers are not free, as passage through turnstiles is required.
                All lines were constructed with dual-tube tunnels at depths ranging from 20 to 45 meters below ground level, except for line 1, which is shallower, and line 6, which was built with a single track and with passing loops at each station. Some stations are located as deep as 70 meters, only accessible via elevators in certain cases.
            
            
            
                Malaga
                The Malaga metro comprises two lines operated with a tramway fleet. Line 2 is entirely underground. Line 1 is mostly underground, but the western section of line 1 was built as a light metro with level crossings. The underground sections are shallow, with most stations featuring a lobby at level -1 and an island platform at level -2.
                The common section is peculiar. Each line has its own tracks. The tunnel has two levels, with two tracks on each one. Between El Perchel and Guadalmedina stations, two tracks interchange their levels, in a section located within two curves. La Unión station on line 1 has also overlapped platforms. Atarazanas station only has a single platform.
            
            
            
                Seville
                The Seville metro consists of a single line that began construction in the 70s but was not opened until 2009. The rolling stock comprises tramway vehicles.
                The central section, built in the 70s, features a dual-tube tunnel constructed using TBMs. Stations generally have a lobby at level -1 or -2, followed by an intermediate level and an island platform at the lowest level. Platform screen doors protect the tracks.
                The western section, crossing the Guadalquivir river, includes elevated, surface, and underground sections. Ciudad Expo, the only station with both an island platform and a lobby at street level, stands out. Other stations have two side platforms, with the lobby located at either the upper or lower level, depending on the station's location.
                The line runs shallowly between Nervión and Cocheras, with all stations featuring side platforms and a single lobby.
            
            
            
                Palma
                The Palma metro comprises a single line connecting the city center and the university campus in the north. The majority of the line is underground, with a surface-level section around Son Sardina. The segment between Estació Intermodal and Son Costa – Son Fortesa features quadruple tracks for metro and mainline traffic.
                Estació Intermodal serves as a transportation hub with 10 platforms, a bus station at level -2, and a mezzanine at level -1. Jacint Verdaguer station has two island platforms at level -2 and a mezzanine at level -1. Son Costa – Son Fortesa station features two unconnected island platforms at level -1. The UIB station has two side platforms at level -1 and a ground-level hall. Son Sardina station is at ground level, with two side platforms connected by an underpass and linking to the Sóller Railway station. The remaining stations share a similar design, with side platforms at level -1, each directly accessible from the street, and an underpass connecting both platforms.
            
            
            
                Naples
                The Naples rail network comprises multiple lines operated by different agencies. The definition of what is part of the metro network varies.
                Line 1, opened in 1993, connects the old city by the sea with the upper districts. The line forms a loop to climb the hill. Most stations are at great depths, except the section between Colli Aminei and Piscninola. Connections to platforms vary by station, but the booking halls are commonly located at level -1. Some feature a single flight of parallel escalators (Montedonzelli, Policlinico), high-capacity lifts (Duomo), or two or three flights of stairs. Stations between Colli Amiei and Museo have island platforms, while those in the old city have side platforms. Quattro Giornate station has overlapped platforms.
                Line 2, owned by the Italian State, opened in 1925 with third rail electrification but was later converted to overhead lines. Montesanto and Cavour are the deepest stations, with a ground-level building comprising ticket office and turnstiles. Two flights of stairs and escalators connect to an intermediate level (-2), with two side platforms at level -3. Other stations, like Mergellina or Campi Flegei, are at ground level with grand station buildings. Piazza Garibaldi has two tracks and three platforms, with a recent layout change.
                Line 6, closed since 2013, featured a narrow profile with trains only 2.20 meters wide.
                The Arcobaleno line (Line 11) connects Piscinola with Aversa, built with cut-and-cover methods. The layouts resemble Milan metro lines 1 and 2 and Rome's southern section of line A. The Circumvesuviana and Circumflegrea lines are also part of Naples' rail network, with some underground stations.
            
            
            
                Rennes
                Rennes has two metro lines.
                Line A is a VAL, an automatic light metro using technology developed by Siemens. The trains have a width of 2.08 m. Most of the line runs underground, with two elevated stations (La Poterie and Pontchaillou). The layout of the stations varies considerably, but all stations have side platforms on the lowest level. The lobbies are either located at street level or at level -1. Anatole France and Jacques Cartier are the deepest stations on this line. Initially, the stations had an honor system, but turnstiles were installed in 2020. Due to this reason, some lobbies might have a peculiar placement of the turnstiles.
                Line B is a Neoval, an automatic line that uses more modern technology developed by Siemens. Trains operate in 2-car compositions, but stations allow for 3-car trains. The entire line runs underground except for the easternmost section, which is elevated. Platforms are located on the lowest level, normally at level -2 or -3. Mezzanines are located at level -1. Sainte-Anne is an interchange station located at the city center. Transfers, access, and egress are performed through a complex system of one-way corridors, stairs, and escalators.
            
            
            
                Donostia-San Sebastian
                Topo is a narrow-gauge rail line operated by Euskotren Trena, an agency owned by the Basque Government. This line runs through many tunnels, earning it the nickname "Topo," which means “mole” in Spanish. The line underwent a major renovation in the last 10 years, and a variant is being built both in the city center of San Sebastian and in the neighboring town of Pasaia. As a consequence, the current main station of Amara will be closed and dismantled.
                The layout of the stations differs. Lugaritz, Anoeta, and Herrera have a station building at ground level and two side platforms at level -1. Loiola and Pasaia stations are elevated. Intxaurrondo and Altza stations are located deep underground and have layouts and aesthetics similar to those of the Bilbao metro, once designed by Norman Foster.
            
            
            
                Sofia
                The Sofia metro consists of 4 different services that operate on 2 physical lines. Despite having rolling stock manufactured by a Russian company, the aesthetics and layouts differ from the Soviet-influenced metros of eastern European countries. Generally speaking, the average station has lobbies located at levels -1 and the platforms at level -2. Most stations have side platforms, but the oldest ones, located in the central part of lines 1 and 4, have side platforms. Stations in the common section of lines 1 and 4 have low-cost platform screen doors.
                All stations on line 3 have side platforms, normally located at level -2. Mezzanines are commonly located at level -1. The connection between platforms and the mezzanine is performed by multiple staircases or elevators. Most of the accesses to the stations are equipped with elevators.
            
            
            
                Toulouse
                The Toulouse metro is formed by two lines that form a cross-shaped network. Both lines use VAL technology and are automated. The layout of line A stations varies. In the city center, the line runs through a dual-tube tunnel at a great depth to cross the Garonne river. Long escalators reach the platforms at Capitole and Esquirol. Stations located outside the city center tend to have a lobby at level -1 and two side platforms at level -2 or -3. The western terminus at Basso Cambo is elevated.
                Most of the line B stations have a similar layout consisting of a lobby at level -1, an intermediate level used for entering passengers at level -2, and two side platforms at level -3. Passengers egressing the station can use escalators that connect directly the platforms with the lobbies. Jean Jaurès is the main hub on the network. The station was designed to have one-way passages and escalators. The line B station uses the Barcelona solution, boarding through the island platform. Passengers need to pass through turnstiles to change from one line to the other. These turnstiles are used only for statistical purposes and to manage flows, as the tariff system guarantees free transfers.
            
            
            
                Zurich
                In 1962, the citizens of Zurich rejected in a referendum the conversion of tram lines in the city center into a premetro. In 1973, the citizens rejected again the construction of a metro network. However, a short section of the tunnels was already being built to conduct rolling stock tests. In 1978, the citizens approved integrating the existing tunnel into the tram network, which was completed in 1986. These stations were built at a considerable depth, as they are located in a hill between the valleys of the Limmat and the Glatt rivers. All stations have island platforms. Since trams in Zurich only have doors on the right side, they run on the left side of the tunnel. All the stations have multiple accesses, some reachable only via elevators, others via a long flight of stairs and escalators, which in some cases have the lower side in a level located even below the platform level. 
            
            
                Liverpool
                Merseyrail is the suburban train network managed by the Liverpool City Region, and it is operated by a private company through a concession. The network consists of two directly operated lines.
                The Wirral Line connects central Liverpool with the Wirral peninsula, located south of the River Mersey, via a tunnel opened in 1886. The two stations adjacent to the river (James Street and Hamilton Square) have platforms located at a great depth. The connection between the street-level concourse and the pre-platform level is made through three high-capacity elevators, in addition to emergency stairs, which at Hamilton Square can also be used regularly. 
                The Northern Line is a north-south line created in 1977, after connecting by a tunnel two separate lines that departed from Exchange and Liverpool Central terminals. In the 1970s, the Wirral Line terminal, which ended in a double track at Liverpool Central, was also modified to become a one-way loop served by three stations spread throughout central Liverpool. These stations are very deep. The connection between platforms, intermediate levels and street-level concourses is made through two or three sets of escalators. All underground stations are accessible to people with reduced mobility.
            
            
                Genoa
                Genoa has a metro line that runs through the city, parallel to the coast. Due to the city's difficult topography, the construction methods for each section are different, resulting in a curvy route with very heterogeneous stations.
                Both terminals, Brin and Brignole, are located on viaducts. Additionally, Brignole metro station is integrated parallel to the railway station.
                Dinegro is the only station built using the cut-and-cover method and is the most shallow in the network. Both platforms are connected via an underpass. This station has múltiple tracks, three of them with platforms, in addition to other tracks that are used as workshops and depots.
                Darsena and San Giorgio stations have an island platform and are deeper than Dinegro but shallower than Sarzano-Sant’Agostino and De Ferrari stations, which have two side platforms each located in two different tunnels.
                The most complex station in the network is Principe: it consists of the metro station, an underground station national rail network, and the surface railway station. The surface station is nestled in a trench between mountains and has a yard with 5 platforms and 9 tracks. Corridors connect the underpass of the surface-level station with a concourse that either leads to the underground railway station, of which only one of the two tracks is in service, or to the metro station through a series of underground walkways. The metro station has a semi-underground concourse, which connects to the mezzanine, located at the upper level of the platform, via a staircase.

            
            
                Charleroi
                Charleroi's premetro consists of a circular line that encircles the city center and three branches towards the suburbs and nearby towns. The network is operated as four radial services, which start from the central loop.
                The central ring is a mix of tram with priority (between Tirou and Gare Centrale) and a fully segregated line, mostly underground but with an elevated section between Gare Centrale and Palais. Line 4 operates completely segregated outside the city ring, with trams running on the left side. Lines 1 and 2 run also segregated from the rest of traffic between the city center and Pétria, and then as a tram line between Pétria and Monument, just like line 3 once past Piges.
                The station layouts are rather simple. Regardless of whether they are on a viaduct or in a tunnel, almost all have a central platform, which is accessed directly from the street, sometimes via an intermediate level, without turnstiles.
                Palais station has four tracks: two of them are in service, a third without regular service, and the fourth leads to a loop that reverses the direction of trains. Waterloo station has two platforms and three tracks, but only the central platform is in operation.

            

             
                Montreal 
                The Montreal metro consists of a network of 4 lines with rubber-tired trains. Nearly all of the network was built during the 1960s, 70s, and 80s, and is entirely underground, with tunnels often (but not always) following the alignment of the streets.
                Each station has unique architecture and style. Station depth also varies. However, most stations feature two side platforms, each 500 feet long (152.4 m), and all entrances are equipped with enclosures to protect against winter temperatures. In some cases, these enclosures also host station lobbies.
                Transfer stations were designed to offer practical and fast connections. Snowdon and Lionel-Groulx stations feature overlapped platforms, allowing for cross-platform transfers, while at Berri-UQAM, the platforms for the green and orange lines intersect at adjacent levels. At Jean-Talon, transferring between the orange and blue lines is also quick, with the platforms arranged in a stacked layout.
                One unique feature of Montreal is that, in the city center, metro stations connect directly to the underground city known as RÉSO, which links city blocks underground.
            
            
             
                Ottawa 
                Ottawa’s rail transit system (O-Train) includes an east-west light rail line called the Confederation Line and a north-south rail line called the Trillium Line.
                The entire network is above ground, except for the central part of the Confederation Line, which runs at a depth of 17 to 25 meters below street level. The three underground stations have side platforms located on the lowest level. Each station has two independent entrances connecting the mezzanines located at either end of the platforms, which are accessible via multiple stair flights.
                Outside of the city center, stations may be located at street level, elevated, or in a trench, with most featuring side platforms. Some stations are transfer points between light rail and bus services, such as Tunney’s Pasture, Hurdman, and Blair. Ottawa also has several BRT lines, some of which have fully segregated infrastructure, including stops shaped like rail stations, with escalators, elevators, and lobbies with fare validators.
            
            
             
                Toronto 
                The Toronto subway has three lines. The network is relatively shallow, with some sections running above ground.
                In the oldest sections, the tunnel alignment is parallel to the street one but is shifted several meters toward the blocks of houses. Due to the cut-and-cover construction method used in these segments, it was necessary to expropriate and demolish existing buildings. Some of these clearings were used to build transfer hubs containing bus and streetcar bays, together with the passenger building, which also serves as the subway entrance. All bus and streetcar platforms are located within the paid area of the station, providing free transfers between the subway and surface transit.
                Regarding subway line transfers, Sheppard-Yonge, Bloor-Yonge, and St. George stations provide direct transfers via a single flight of stairs, while at Spadina, the transfer involves a walkway over 200 meters long.
            
            
             
                Calgary 
                Calgary has a light rail system called the C-Train. In the downtown area, it operates like a streetcar, with a low stop spacing, but in the suburbs, the spacing between stations is greater, and the trains have dedicated platforms, although some crossings still use level crossings.
                As for stations, there is only one underground station (Westbrook). Some other stations have platform access at ground level, while others use overpasses that lead to platforms through lobbies with waiting areas.
            
            
             
                Vancouver 
                Vancouver’s SkyTrain consists of three automated metro lines. The network has a radial layout, and only two of the three lines reach downtown. As the name suggests, most of the metro is elevated, with only the most central segments being underground.
                The Expo Line runs through downtown in a two-level tunnel, with stations located at significant depths. The Canada Line is much shallower, with each station featuring a different layout: Waterfront, Vancouver City Centre, Yaletown-Roundhouse, and Olympic Village have a lobby on level -1 and an island platform on level -2; King Edward has overlapped platforms; while Oakridge and Langara have platforms on level -1 connected by an underpass.
                The main interchange of the network, Waterfront, serves as the terminal for the Expo and Canada Lines, as well as the commuter train and the ferry to North Vancouver. The transfer here is not ideal, as the Canada Line is in an area with separate fare gates, and the distance between this line and the ferry terminal is 350 meters.
            
            
             
                Seattle 
                Seattle has a light rail line. Initially, a tunnel was built for buses and trolleybuses in the downtown area, running from International District / Chinatown to Westlake, which opened in 1990. Stations in this section had side platforms on level -2 and two lobbies on level -1, with platforms spaced widely enough to allow one bus to overtake another.
                The tunnel closed in 2005 for conversion to light rail, which opened in 2009. Until 2019, it operated as a mixed-use tunnel for both buses and light rail. In 2016, the network expanded northward, adding a segment with four underground stations and one elevated station. Platforms at the underground stations are more than 20 meters deep, and each one has a unique layout.
                On the southern section, there is Beacon Hill Station, accessible only via four high-capacity elevators that descend to the platforms, located about 50 meters below ground.
            
            
             
                Stockholm 
                Stockholm has three subway lines that cross the city center and split into two or three spurs at each end. The city itself is in an archipelago, so the metro lines were planned and built through a complex geography and geology, featuring surface stretches, elevated viaducts, shallow underground sections, and deep tunnels.
                The green line, the first to be built, is considered to be the shallowest. In the city center, it runs in shallow tunnels built using the cut-and-cover method, and in the suburbs, the line runs either elevated or at surface level. The red line combines deep underground segments in the north with a mix of surface and deep sections in the south. The blue line runs at great depth along nearly its entire length.
                All stations are accessible to persons with reduced mobility thanks to the installation of lifts. Deep stations typically feature two island platforms at the lowest level (-2), connecting to lobbies located at or near the surface (level -1) via a set of 3 or 4 parallel escalators, in addition to an inclined lift which also runs parallel. Stockholm has one of the highest numbers of inclined lifts in its subway system. Some deep stations have cavern-like platform designs.
            
             
                Leipzig 
                Leipzig has a tunnel that crosses the city centre, with four underground stations, all featuring island platforms at the deepest level. Although the tunnels are twin-tube and were built using tunnel boring machines, the stations were constructed using the cut-and-cover method, except for Hauptbahnhof, which was built using the mining method.
            
            
             
                Karlsruhe 
                Karlsruhe has a tram-train system. In 2021, a T-shaped underground line was opened, which is served by six stations, one of which is a double station. All stations have side platforms located on level -2, except for Kongresszentrum, which has its platforms on level -1. The -1 level of the other stations consists of various concourses.
                The platforms have sections with different heights to ensure compatibility with all rolling stock in terms of accessibility.
            

             
                Bielefeld
                The Bielefeld Stadtbahn consists of a north-south trunk line that branches into four lines, both in the north and in the south. The central section and a bunch of the northern spurs are underground. Most stations have island platforms on the deepest level, with accesses at both ends of each platform.
                Hauptbahnhof is the junction station on the northern side. The station has a concourse at level -1, two platforms and three tracks at level -2; plus one track and one platform at level -3, which crosses the station diagonally.
            

             
                Gelsenkirchen
                Gelsenkirchen has a Stadtbahn line operated with low-floor trains. Except for Heinrich-König-Straße, which is located at a junction, all stations have a platform at the lowest level. In some stations, access to the platforms is directly from the street; in others, access points converge in the concourse.
            

             
                Wuppertal
                The Wuppertal Schwebebahn is a suspended monorail opened in 1901, with a single line that follows the course of the Wupper River, except at the western end, where it follows a street.
                The stations are elevated and located above the river or the street. All stations have side platforms, so trains have doors on only one side. The platforms are around 30 meters long.
            

             
                Cologne
                Cologne has a Stadtbahn made up of different services that cross the city. Most of the underground sections are located in the center and in the north. Some of these lines are operated with low-floor trams, while others use high-floor trains. This results in some stations having platforms with two different heights.
                The stations typically have a simple structure with platforms at level -2 and one or two concourses at level -1, although some stations have platforms at level -1. The new north-south line, partially constructed and served by lines 5 and 17, runs deeper than the other lines and has central platforms at almost all stations. However, currently only one of the two tracks is operational. Finally, line 13, which runs along the Gürtel (ring road), includes an elevated section.
                As for transfer stations, some are designed for quick and short transfers, such as Friesenplatz or Ebertplatz. The central station is served by two different, adjacent Stadtbahn stations.
            

             
                Bonn
                Bonn has a Stadtbahn consisting of a line that runs parallel to both the Cologne – Mainz railway line and the Rhine River. It has two underground sections: one in the center and south of Bonn, and another in the Bad Godesberg district, plus a couple of isolated underground stations on a branch line.
                The stations are simple. All have side platforms at level -2 and one or two concourses at level -1.
            

             ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cat Aquariums]]></title>
            <link>https://cataquariums.com/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45237970</guid>
            <description><![CDATA[All cat-view fish tanks are crafted with ultra-clear glass to deliver an exceptional viewing experience for your cat. Enjoy free 2-day delivery on every order.]]></description>
            <content:encoded><![CDATA[
    


  
  
    
      
      Your browser does not support HTML5 video.
    
  



  
    200+ Happy Pet Owners
  

  
    4.9/5 Star Rating
  

  
    100% Customer Satisfaction
  



Safety First Cat Aquarium
Your pet’s well being is our top priority. We test every product for safety. The edges and openings of our cat view fish tank are carefully hand-polished, ensuring your feline can play freely without any risk. The materials used are non-toxic, so you can rest easy knowing that your space is both secure and comfortable for your pet.


Quality You Can Trust
These enclosures are made from ultra clear glass with 92% light transmittance. We use high-quality materials and great craftsmanship to create something that’s not only durable but also looks awesome. Every piece is designed to be both practical and stylish, making it a great addition to any space.



    
  

  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SpikingBrain 7B – More efficient than classic LLMs]]></title>
            <link>https://github.com/BICLab/SpikingBrain-7B</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45237754</guid>
            <description><![CDATA[Contribute to BICLab/SpikingBrain-7B development by creating an account on GitHub.]]></description>
            <content:encoded><![CDATA[SpikingBrain：Spiking Brain-inspired Large Models
📄 Technical Report: Chinese | English
🚀 Arxiv: arXiv:2509.05276
🧩 Models: Available Models

About SpikingBrain
Inspired by brain mechanisms, SpikingBrain integrates hybrid efficient attention, MoE modules, and spike encoding into its architecture, supported by a universal conversion pipeline compatible with the open-source model ecosystem. This enables continual pre-training with less than 2% of the data while achieving performance comparable to mainstream open-source models. We further adapt frameworks, operators, parallel strategies, and communication primitives for non-NVIDIA (MetaX) clusters, ensuring stable large-scale training and inference. SpikingBrain achieves over 100× speedup in TTFT for 4M-token sequences, while spiking delivers over 69% sparsity at the micro level. Combined with macro-level MoE sparsity, these advances provide valuable guidance for the design of next-generation neuromorphic chips.


Project Structure
This repository provides the full implementation and weights of SpikingBrain-7B, including the HuggingFace version, vLLM inference version, and quantized version, enabling flexible deployment and research across different scenarios.
SpikingBrain-7B/
├── hf_7B_model/ # HuggingFace version
├── run_model/   # Model run examples
├── vllm_hymeta/ # vLLM plugins and inference support
├── W8ASpike/    # Quantized inference version
├── setup.py
├── requirements.txt 
└── README.md 


vLLM-HyMeta
vllm-hymeta is the plugin adaptation of HyMeta (Hybrid Models built on MetaX GPUs) for the vLLM inference framework, providing efficient inference support on NVIDIA GPUs.
By leveraging the plugins mechanism in vLLM, hardware backends can be integrated in a modular fashion, bringing the following benefits:


Decoupled codebase: Backend-specific code remains independent, keeping the vLLM core cleaner.


Reduced maintenance cost: vLLM developers can focus on general functionality without being affected by backend-specific implementations.


Faster integration: New backends can be integrated quickly and evolve independently with less engineering effort.


Container Deployment (NVIDIA)
sudo docker run -itd \
    --entrypoint /bin/bash \
    --network host \
    --name hymeta-bench \
    --shm-size 160g \
    --gpus all \
    --privileged \
    -v /host_path:/container_path \
    docker.1ms.run/vllm/vllm-openai:v0.10.0
Plugin Installation
git clone https://github.com/BICLab/SpikingBrain-7B.git
cd SpikingBrain-7B
pip install .
Recommended environment for installing vllm-hymeta on NVIDIA GPUs:
decorator
pyyaml
scipy
setuptools
setuptools-scm
flash_attn==2.7.3
flash-linear-attention==0.1
vllm==0.10.0
torch==2.7.1
Run with vLLM
You can serve a model with vLLM in the simplest way using the following command:
vllm serve <your_model_path> \
  --served-model-name <model_name> \
  --gpu-memory-utilization <ratio> \
  --block-size <size> \
  --dtype bfloat16 \
  --port <port_number>
You may also set --tensor-parallel-size and --pipeline-parallel-size when launching if you want to run with multiple GPUs.

W8ASpike
W8ASpike is the quantized inference version of SpikingBrain-7B, aiming to reduce inference cost under low-precision settings and explore the potential of Spiking Neural Networks (SNNs).
The current implementation adopts pseudo-spiking, where activations are approximated as spike-like signals at the tensor level, rather than true asynchronous event-driven spiking on neuromorphic hardware.


Pseudo-spiking: Efficient approximation at the tensor level, suitable for prototyping and research.


True-spiking: Requires asynchronous hardware and event-driven operator support, which is beyond the scope of this repository.


The activation spike encoding process here is inspired by the pseudo-spiking interfaces from BICLab/Int2Spike. For additional PyTorch-based spiking interfaces, please refer to the Int2Spike library.

Available Models
The model weights are hosted on ModelScope. Please select the appropriate version based on your needs:

Pre-trained model (7B): https://www.modelscope.cn/models/Panyuqi/V1-7B-base
Chat model (7B-SFT): https://www.modelscope.cn/models/Panyuqi/V1-7B-sft-s3-reasoning
Quantized weights (7B-W8ASpike): https://www.modelscope.cn/models/Abel2076/SpikingBrain-7B-W8ASpike

Usage
Example scripts are provided in run_model/ for running the model with the released checkpoints.


Hugging Face
Load with AutoModelForCausalLM and use as a standard CausalLM (forward or generation); see run_model/run_model_hf.py.
For the SFT model, a chat template is used; see run_model/run_model_hf_chat_template.py.


vLLM
Perform inference using the provided vLLM Hymeta plugin; see run_model/run_model_vllm.py and the vLLM Hymeta section.


Performance Evaluation
Table 1: Performance evaluation of the SpikingBrain-7B pre-trained model. All models are tested with the HuggingFace framework and evaluated using a perplexity-based method. Except for Qwen2.5, the other baselines are trained on limited Chinese data, resulting in clear disadvantages on CMMLU and C-Eval.

Table 2: Performance evaluation of the SpikingBrain-76B pre-trained model. All models are tested with the vLLM framework and evaluated using a perplexity-based method. Except for Qwen2.5, the other baselines are trained on limited Chinese data, resulting in clear disadvantages on CMMLU and C-Eval.


Citation
If you find our work useful, please consider citing SpikingBrain:
@article{pan2025spikingbrain,
  title={SpikingBrain Technical Report: Spiking Brain-inspired Large Models},
  author={Pan, Yuqi and Feng, Yupeng and Zhuang, Jinghao and Ding, Siyu and Liu, Zehao and Sun, Bohan and Chou, Yuhong and Xu, Han and Qiu, Xuerui and Deng, Anlin and others},
  journal={arXiv preprint arXiv:2509.05276},
  year={2025}
}
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Refurb Weekend: Silicon Graphics Indigo² Impact 10000]]></title>
            <link>http://oldvcr.blogspot.com/2025/09/refurb-weekend-silicon-graphics-indigo.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45237717</guid>
            <description><![CDATA[It's one of my periodic downsizing cycles, which means checking the hardware inventory (and, intermittently, discovering things that were no...]]></description>
            <content:encoded><![CDATA[
It's one of my periodic downsizing cycles, which means checking the hardware inventory (and, intermittently, discovering things that were not on the hardware inventory) and deciding if I want to use it, store it or junk it. And so we come to this machine, which has been sitting in the lab as a practical objet d'art when I picked it up from a fellow collector for the cost of take-it-away almost exactly a decade ago.



This beautiful purple slab is the Silicon Graphics Indigo² (though, unlike its earlier namesake, not actually indigo coloured) with the upper-tier MIPS R10000 CPU and IMPACT graphics. My recollection was that it worked at the time, but I couldn't remember if it booted, and of course that was no guarantee that it could still power on. If this machine is to stay working and in the collection, we're gonna need a Refurb Weekend.

Counting this sucker, there are three SGI systems presently in the house. (I had a chance many years ago to land one of SGI's early 68K IRIS machines, I think an IRIS 3110, but I was still in a small apartment back then and hadn't the space. I've always regretted turning that one down.) The "big" one is a 900MHz R16000 SGI Fuel (codenamed "Asterix") with 4GB of RAM and a V12 DCD graphics card; the line was first introduced in 2002 and is best described as a single-node Origin 3000. This particular machine has a penchant for chewing up timekeeper batteries and power supplies, and true to form it's recently devoured another set (probably capacitors in the PSU's case), so a future Refurb Weekend will involve converting it to ATX. The Fuel certainly has its detractors, mostly Tezro owners, but I've already hit my quota for big, hot and loud RISC workstations with my trusty Power Mac Quad G5 (the Raptor Talos II is rather more tractable). The Fuel, by contrast, is reasonably quiet and for me powerful enough, I love the bright red tower case, and its more commodity PC-like design might seem chintzier but I find it also makes it easier to work on.

The other one you've met and is my personal favourite: the pizzabox SGI Indy (codenamed "Guinness"), introduced in 1993. This Indy's most recent appearance was as the Hyper-G server for the RDI PrecisionBook laptop, which was running the Hyper-G Harmony client. The Indy was the first SGI workstation I ever personally touched. I don't have the original IndyCam grab anymore, just this cropped picture, but here I am photographed using one of the Indys as an undergraduate at the Salk Institute circa 1995-ish:



Ostensibly they were there for X-ray crystallography rendering but they also played a lot of sgidoom. It didn't help my envy that the lower-end Indys were almost kinda vaguely affordable for a college student, criminal sidehustles or unsavoury loan terms notwithstanding. Though I never did buy one in college, this Indy I picked up later came with the Indybag to tote it in.

The SGI Indy makes a good segue into the Indigo2 — as I'll render it for the remainder of this article — because they have many similarities in their architecture since the Indy is in large part descended from it. In fact, the lowest-binned Indigo 2 systems, with a hardware IP ("Inhouse Processor") identifier of IP22, look the same as the Indy (IP24) to system software which also reports it out as an IP22. The Indy's more limited processor and graphics options, undoubtedly for purposes of market distinction, led to the common joke that the Indy was "an Indigo without the 'go'." While this Indy has 24-bit XL 2-D graphics and a 150MHz R4400SC (i.e., with L2 cache), a processor second only to the higher-tiered R4400s and R5000, all but the most anaemic contemporary configurations of the Indigo2 would have outclassed it.

The first Indigo 2 systems, in a teal case which also wasn't indigo, emerged in January 1993 and made up the IP22 family based on R4000-series CPUs, maxxing out in 1995 with the 250MHz R4400SC sporting 2MB of L2 cache. The launch configuration with a 100MHz R4000 would set you back about $35,000, an eye-watering $78,000+ in 2025 dollars. Initially the IP22 family shipped with Extreme graphics (codenamed "Ultra"), a three-card 24-bit 2D/3D rendering system that was roughly a doubled-up Elan ("Express" graphics) from the original Indigo with twice the Geometry Engines and Raster Engines (eight GE7 and two RE3.1 units respectively). Because the teal Indigo2s have only four card slots, the Extreme graphics board set ended up occupying most of them. Each slot has an EISA connector but only three of them also have GIO64 connectors for SGI's high-speed bus interconnect, and two of those are actually shared.

In mid-1993 additional lower-tier options were offered: "Newport" graphics, sold as the XL for speedy 2-D graphics but no 3-D, and two options both called XZ for cheaper 3-D, one identical to the Indigo Elan (four GEs, one RE) and one with half the GEs (two). The advantage of these lower-tier options, besides cost, was getting some card slots back if you didn't need Extreme-level acceleration. The four-GE XZ and the XL were also sold for the Indy, which came out around the same time, along with an even cheaper 8-bit-depth XL card for entry-level Indys.



The Indigo2 jumped a processor generation in October 1994 when SGI announced the POWER Indigo². This family (IP26) incorporated the R8000 from the high-end POWER Onyx, which was the first MIPS IV processor (the R4000 was the first MIPS III) and explicitly designed around floating point performance such that its codename was "TFP" for "Tremendous Floating-Point." Despite the moniker, however, the R8010 FPU was in fact a separate chip decoupled from the main CPU with a queue allowing for limited out-of-order execution of mixed FP and integer instructions. The R8000 itself was strictly in-order yet a superscalar design issuing up to four instructions per cycle on a five-stage integer pipeline (although also highly pipelined the R4000 and R4400 are merely scalar CPUs; by contrast the R4600 mostly did away with pipelining its FPU, which made a relatively weak core even worse). The main R8000 CPU has conventional on-die L1 caches plus external L2 cache. Interestingly, the L2 cache is all but obligatory because it ends up shared with the R8010 which uses it as L1. These are serviced by two separate identical "tag RAMs" containing the cache tags, and the external cache has its own five-stage pipeline.

The entire amalgamation made for a complex chipset to design, taking years of development time, and to the chagrin of MIPS management its release date slipped from 1993 when it might even have been a plausible Indigo2 launch configuration. By this point SGI had acquired MIPS Computer Systems as its subsidiary MIPS Technologies, Inc. (MTI) and made the R8000's completion an engineering priority. It was just as expensive to fabricate — Toshiba produced the R8000 and R8010 at 0.7μm, totaling over 3.4 million transistors between the two — and after the POWER Onyx launched in July 1994 the 75MHz POWER Indigo2 finally emerged in October for a cool $46,000 (over $105,000 in 2025 simoleons) with 2MB L2 cache, XZ graphics, 64MB of RAM, a 2GB SCSI disk, monitor, keyboard and mouse. Compare that to the 200MHz R4400SC configuration introduced at the same time with 24-bit XL graphics, 32MB of RAM, 1GB disk, monitor, keyboard and mouse for "just" $24,500 — you paid a lot for the special little front case badge these rather rare systems sported. And if you had to ask how much a POWER Onyx was, well, you couldn't afford it.

Meanwhile, the GE7 Geometry Engine's transform performance started to become a liability as CPUs increased in speed and could compute them faster, and the presently available Indigo 2 options lacked any support for hardware texture mapping. Indeed, texel-capable SGI graphics hardware had existed for at least several years, first on SGI's earlier Crimson systems using PowerVision VGX graphics, but it had yet to be deployed in any workstation. As a new faster graphics option for the Indigo2 SGI started with the GE10 from the Onyx's RealityEngine² and cranked up the new GE11 to 960,000 MFLOPs (compare to the eight GE7s in the Extreme that together produced about 256,000), and paired it with a new faster RE4 raster engine. For the upper-binned configurations, they also added a texture engine option with its own RAM ("TRAM"), and the highest of the three configurations had an extra GE11, RE4 and pixel processor for blending, depth and dithering. SGI called this new architecture IMPACT.



SGI made the case purple (still not indigo) for the IMPACT family, putting a special silver "IMPACT" badge on the front as shown in this 1995 ad I joined by hand from two magazine page scans. It was also somewhat internally different: to accommodate IMPACT graphics' greater power and bus demands, SGI reversed the four card slots' loadout so that there were only three EISA card connectors but four GIO64 ones (though still only two logical slots), and added individual supplemental power connectors to each. These in turn were backed by a beefier 385W power supply. A variation called "IMPACT Ready" had all the system upgrades but no IMPACT card, which could be bought separately and added later (the original graphics options would still mostly work).

Although the first Indigo2 IMPACTs were announced in July 1995, a conspicuous absence among them was an R8000 configuration: the systems weren't offered with one. While SGI had drivers for it internally, the company had quietly concluded the R8K was an engineering dead-end. Its design made it difficult to evolve and it ultimately topped out at just 90MHz (and the Indigo2 only had the 75MHz part); on top of that, it ran hot and power-hungry, pulling 13W at 75MHz while the R4400 could pull as little as eight watts at 200MHz, and Toshiba couldn't seem to make it any cheaper. Similarly, although it generally achieved the floating point dominance it was designed to, its integer performance improvements proved more modest and it was difficult for programmers to squeeze out optimum throughput.

SGI instead put MTI on finishing the processor generation after it. As far back as 1991 MIPS Computer Systems had been developing specifications for a "next-generation" RISC part which it grandiosely called the R10000 and planned to release in 1994. Codenamed "T5," MIPS prevailed upon its usual partners to contribute to its development, eventually receiving a reported $150 million in investments. The R10000's development was somewhat slowed by the R8000, causing SGI/MTI to fund Quantum Effect Design's R5000 in the meantime for their low end hardware (our Cobalt RaQ 2 uses a later derivative, and an R5000 option was offered for the Indy, though never for the Indigo2). Although announced in July 1995 in 175MHz and 195MHz speeds, significant production problems delayed its release until March 1996 for SGI's high-end servers and the NEC-fabbed ones had to be recalled in July because of unexpected shutdowns.



During the estimated $10 million recall for the faulty R10Ks, SGI finally introduced the chip (presumably fixed) to the Indigo2 IMPACT line as the IP28 at both the 175MHz and 195MHz speeds. (I'll talk more about the R10K when we get to the CPU module.) These last and mightiest IMPACT systems got their own silver badge that read "IMPACT 10000" — which brings us to our system today.



This machine here is actually the last variant of the IMPACT 10Ks, with Solid IMPACT graphics. Recall I mentioned three bins for IMPACT. As introduced initially SGI produced a High IMPACT R10000 system for $43,000 ($88,500 in 2025 dollars) which was the middle tier with texture mapping, and a Maximum IMPACT system for $55,000 ($113,300) with texture mapping and the extra rendering hardware. Solid IMPACT systems lack texture mapping and, as the lowest tier, were introduced shortly afterwards as a cheaper option (around $34,000 or in 2025 $70,000). Finally, an even less expensive variation called Killer IMPACT was also offered, which was nothing more than Solid IMPACT paired with the lesser 175MHz R10K and thus arguably unworthy of the name. There weren't many of these as the later Octane and O2 systems were more popular by then, but this is actually one of them that has been secondarily upgraded, and I'll show you that in a minute.

I should also mention that this thing weighs a ton (or more accurately a bit over 40 pounds) and was a real adventure dragging it out to the staging area.

There were a couple other minor variations on the Indigo2 that we won't talk further about here, though I mention them for reference. Like the Challenge S, which was a modified headless Indy used as a cheaper rackmount, there was a headless teal Challenge M with no graphics option (though one can be installed, making it a regular Indigo2). This variation was rebadged by Control Data Corporation and Siemens Nixdorf but is the same machine otherwise. The case was also used for the Challenge M Vault, an overgrown SCSI enclosure that added another 5.25" bay and two 3.5" bays, and repurposed the expansion card cage for four more 3.5" drives. Obviously the Vault isn't actually a workstation and I've never seen one myself.



Gratuitous shots of the case badges. SGI certainly made some physically striking systems. The "10000" on the case badge got a little banged-up prior to my acquisition but the whole setup still looks awfully cool.



The rear didn't clean up particularly well, but it's still instructive. There is only one card in the slots, the Solid IMPACT card itself, because pretty much everything else essential is on-board. It has a 13W3 video port, though this type of port never got a standardized pinout and only video cables and converters wired for SGI graphics will work properly with it (naturally I have some in stock). We'll have more to say about video output later on. The DE-9 next to it is for an active-shutter 3-D stereo viewer, which excites me as a 3-D enthusiast, though sadly I don't have anything that works with it right now.

Below that on either side are the external 50-pin SCSI port and the audio connectors for microphone, line in, line out, headphones, and serial digital stereo. This is what used to be called IEC958 and is now called IEC 60958, better known nowadays in its consumer-grade form as S/PDIF. The connection here transmits and receives AES3 (AES/BDU) stereo PCM audio over an unbalanced line at sampling rates up to 48kHz. All the jacks are 1/8" (3.5mm) TRS.



The other ports are two PS/2 ports for keyboard and mouse (a regular PC keyboard and mouse will do), two MiniDIN-8 serial ports (classic Mac serial port cables work), the AUI Ethernet connector and 25-pin IEEE-1284 parallel port, and at the base a 10BaseT Ethernet port. The AUI and 10bT connectors are the same NIC, and if both are connected then only the 10bT port is active. Additional NICs could be installed in the EISA slots with appropriate drivers. The manual cautions you not to "throw the mouse at co-workers."

This unit appears to have been upgraded aftermarket: the model number CMNB007AF175 corresponds to the 175MHz variant, and a 175MHz R10K plus Solid IMPACT graphics would be a Killer IMPACT system. However, it's actually got a 195MHz CPU module and I'll prove that when we bring the machine up. Machines that SGI upgraded or refurbished in-house have additional stickers on the Indigo² plate and the model number plate, though this one has neither, so it must have been added after the fact.

The copper coverplate is a bit of a mystery, but may have been intended for a ISDN port or something similar like the Indy's and was simply never populated on this board.



Finally, the power supply. These don't have a great reputation but are not trivially replaceable by an AT or ATX substitute, and it was one of the two components I was most expecting to have failed. It's possible to replace their capacitors if necessary but doing so involves several caps on the high-voltage side, which could be risky or dangerous depending on your skill set. (Mine sucks.)



To get to the other component I was pretty sure had failed, we need to get to the logic board now. The front door opens down, or it would if one of the hinges weren't broken, to reveal a 5.25" bay occupied by a(n apparent) CD-ROM caddy-fed drive and then a black 3.5" bay.  Next to the 5.25" bay is the master power button and a smaller reset button. At the top are two clips which we pull down.



These clips enable removing the entire front bezel, revealing not only the 5.25" bay but actually two hard disks. They are all on their own benighted little custom sleds that we'll have to do battle with later. For now, we slide their restraining clips to the left and pull the sleds from the system.



The hard disks and the optical drive do not appear to have been factory-issue either. (Note from the future: they weren't.) Notice the alignment prongs and the oversized rear connector which carries not only the SCSI bus, but also SCSI ID and power lines. SGI offered a DAT option which went in the top 3.5" bay, and there were also SCSI 3.5" floppy and QIC 5.25" options.



We then turn it horizontal and remove the feetsies, or what SGI staidly calls "workstation stands." These were 3D printed by someone on Nekochan (RIP) and while the colour doesn't quite match, they're reasonably robust and look a lot better than the scuffed-up O.G. ones you might pay a mint for on eBay. I got them a while ago when I still had immediate plans for this thing and they've been with it ever since. The feetsies are important because the side slats' vents must remain unobstructed when vertical, especially if you have one of the bigger video options.



With the bezel off and everything out, we can just undo its moorings and lift the top case up, which rotates back on little clips in the rear until it comes off. Keep that in the back of your head for when we reassemble it.



The naked chassis. You can see the card cage and riser (and cooling fan), the drive bays connected by a big stiff ribbon, the power supply, and (peeping out in the top middle section) a small portion of the logic board.



This was all very dusty, so the canned air came out at this point to clear away the bunnies and debris.



To expose more of the logic board we'll need to remove the 5.25" tray first. This is secured by two captive screws in front.



It then simply slides back out of its retaining clips and can be flipped over to the side (it isn't necessary to remove the flat connecting cable).



With the tray out of the way we now see the main CPU module and RAM SIMM slots. Let's talk a little more about the R10K.

The R10000 was MTI's first out-of-order core. The chip has a seven-stage pipeline and fetches four instructions every cycle from the I-cache for decoding. These (except for NOPs and jumps) in turn feed three instruction queues for integer, FP and address operations, each of which can accept up to four instructions themselves, which dispatch reordered operations to two integer (add/shift/move or multiply/divide), two FP (add or multiply/move) and one load/store execution unit. Up to 32 instructions can be in-flight. Each execution unit maintains its own multi-stage pipeline, except for high-latency division and square root units that hang off the FP multiplier, with integer instructions having the lowest latency. The address queue is uniquely a circular FIFO so that instruction order is preserved for tracking dependencies and maintaining sequential-memory consistency. Instruction reordering is assisted by 64-register rename files for both GPRs and FPRs, alongside a separate condition file recording in parallel if the result was non-zero so that conditional move instructions need only test a single bit instead of the whole register.



The R10K implements a 64-entry translation lookaside buffer and is also capable of speculative execution, predicting branches using a 512-entry history table and saving state in a four-entry branch stack. Unusually for such a design, it does not predict branch targets, relying on its out-of-order core to do useful work during the additional cycle required to compute them (a problem with branch-heavy code that could not be easily parallelized). It carried 32K of L1 instruction cache and two interleaved 16K L1 data caches, plus supporting L2 cache (called the "data streaming cache") anywhere from 512K to 16MB, and could be set up for "glueless" SMP out of the box with up to three other CPUs — or, with custom hardware, potentially hundreds. The CPU implements the Avalanche bus, a muxed 64-bit bus which directly interfaces with the L2, apparently unrelated to an earlier experimental bus for the PA-7100. In theory SGI Avalanche could run at CPU speed, but in practice its overhead limited it to 100MHz in uniprocessor configurations and 80MHz under SMP, or around 540 MB/s. While this was reportedly enough to keep a 4-CPU system fed, it paled in comparison to wider non-multiplexed buses like the PowerPC 620 which could maintain roughly twice the bandwidth.

Although the first iteration was intended to run up to 200MHz, poor yields caused problems above 180MHz and it was introduced at the slightly slower maximum speed of 195MHz as shown here. Despite being a third source for the R4400 IDT chose not to produce the R10000, so it was fabricated by NEC and Toshiba on a 350nm process with 6.8 million transistors and a die area of 298 square millimetres. NEC-fabbed units initially drew so much power that they caused unexpected system shutdowns and forced SGI into that very expensive recall I mentioned earlier. The R10K eventually reached 250MHz in 1997 with a process shrink to 250nm, though this wasn't ever offered for the Indigo2.

The R10000 turned out to be a far more significant microarchitectural landmark than SGI had intended. We'll come back to this when we finish the story at the end.



The chip speed is confirmed by the part number, a PMT5 030-0966-004 indicating an R10000 (technically an R10000SC) with 1MB of L2 cache. This chip runs rather hot as the huge heatsink and active cooling fan would indicate.



The part I was pretty sure was dead is (surprise surprise) a Dallas DS1286 timekeeper chip (top left/northwest corner). Dallas timekeepers have built-in batteries and last a fairly long time, but eventually crap out and are notoriously not intended to be user-refurbished. Despite the name they do other things as well such as provide a watchdog timer and a small amount of battery-backed "NVRAM."

The death of a timekeeper in an SGI has various effects depending on the machine. In most cases this just affects the clock, as is the case with my battery-munching Fuel, though at least in the Fuel's case the battery is external and can be replaced. However, in machines like the Indy, things like the on-board Ethernet MAC address are kept there as well and the network hardware won't function until the chip is refurbished and reprogrammed. It should be noted that the "NVRAM" in these things is nowhere near large enough to maintain the PROM environment variables; that is stored elsewhere.

Because this machine is related to the Indy I decided better safe than sorry (note from the future: it fortunately appears at least the IP28 Indigo2 doesn't keep the MAC address or any other vital system data in the DS1286 either). Unfortunately we can't just remove it because the riser card for the slots is in the way, so we'll need to get that free. At this point I removed the stiff blue power supply connector from the riser card, which also grants easier access to the 72-pin SIMM RAM slots.



RAM is installed in three groups of four identical SIMMs each. The spec is parity FPM — EDO reportedly doesn't work — 60ns or faster. This machine came with only the default 64MB of RAM (as four 16MB SIMMs), which isn't great, so I found someone selling a four-pack of 32MB SIMMs of the same spec with the plan to order it if we get this machine to power up.

Officially the IP26 and IP28 boards only accept up to 640MB of RAM, limited to eight 64MB SIMMs because of heat concerns. It turns out this isn't actually a problem with most SIMMs and virtually any IP28 can accept 768MB (all 64MB SIMMs) just fine. The little IP22 is limited to 32MB SIMMs, however, and thus 384MB of RAM. The situation is more complicated with the IP26 as the R8000 CPU card encroaches on some of the RAM slots, necessitating "low profile" SIMMs, and there is also some question over SGI's insistence that installing any 64MB SIMM will require at least one bank to consist of all 32MB SIMMs.

It is possible, at some expense, to cram 1GB of RAM into an IP28 using 128MB "32x36" parity SIMMs. The memory controller is hard-limited to 1GB, however, so you could only populate two of the banks this way to yield 1024MB from eight 128MB SIMMs. Here's a more thorough explanation.



To get the riser card up we'll need to take the Solid IMPACT card out. This is a single card, so it's a little bit less of a hassle than the stacked multicard graphics options. The card cage has a door which you can simply pull down on to open.



The Solid IMPACT card connects only to the GIO64 bus and the supplemental power connector (the EISA connector for that slot is open). Those huge heat sinks again should say something about how much work this card ends up doing.



The card is identified as an 030-0786-004.



Although I don't know for sure which is which, my guess is that the two chips labeled SGI/ISD 099-9028-001 ("V101 REVA") are the twin PP1 pixel processors that handle blending, depth and dithering, since they're next to the video output, and the chip labeled ADV7162KS170 is the single HQ3 command processor. The larger square of the two heat sinks would then most likely be for the GE11 Geometry Engine (because it has the most gates of any of the chips) and the smaller rectangular one for the RE4 Raster Engine and the SDRAM framebuffer.



The cards are securely held not only by the card edge and the usual screw in the slot, but also by this retention pin which slots down in front of the card edge by the door. 



The video card can now be pulled out (there are handy loops if you like) and set aside.



Now to pull up the riser card. This is secured in several places, so we'll start with the screw in the back.



Unfortunately this screw was pretty badly stripped. I'm not sure if someone had tried to do some other upgrade on this machine and mucked it up, but either way no screwdriver could turn it, so I grabbed a pair of pliers and cranked it off.



I also don't know who J. R. Vala is, but if you wanted his attention, this is the riser card for you.



Next we undo a little brass-coloured screw at the bottom which secures the riser card to the logic board.



Now we can pull the riser card up out of its connectors (but gently so as not to bend anything). 



We don't need to yank it up all the way to get the timekeeper out, but if you did want to remove it, you'll want to remove the twisted black-and-yellow cable as well as the stiff flat blue cable.



Now we can grab that chip, which is conveniently socketed.



Expecting I would have to do this at some point, I had already pre-purchased a repair board for the DS1286 that you could simply wrap the needed pins around to provide a proper battery holder. However, it should have been a tip-off to me that the repair board has a crystal on it, because the DS1286 has a crystal too. (I am not complaining: I bought a replacement DS1386 module for my Indy from the same seller and that has worked very well.)



There seem to be some DS1286s that lack the crystal and battery, which would actually make them more like a DS1284. Those chips (and the DS1284 generally) can be very easily converted with this board. However, as you can see here, the DS1286 in this machine already has those pins yanked back. Undoubtedly it was made out of a DS1284 with the battery and crystal epoxied onto the top in a similar fashion.



Because it was shot anyway I got out the Dremel and decided to see how far I could shave it down. Unfortunately the entire top chamber is epoxy; you can't just cut into it or dig out chunks.



I did grind down to the battery and what I thought was the crystal, but in the end all I ended up doing at that point was just making a mess, nor did I find any obvious metal portions I could solder the conversion board to. But it was only $10, so live and learn.



I dithered over buying a DS1284 to retrofit but the problem with buying ICs on eBay is getting re-marked crap or chips that are absolutely fraudulent. However, while looking at chips from dodgy international sellers I ran across an individual producing a small board for the Tektronix TDS524A digital scope, which also uses the DS1286. This board has a little replaceable coin cell on it plus a DS1284Q and crystal. More to the point it also has pads on top, so an alternative battery pack can be fitted.



Although it is twice as big as the original DS1284 (in area, anyway), it still fits.



Before installing it I soldered a 2AA battery holder to the battery pads so that when the lithium battery it came with craps out eventually, I can just put in lithium AAs (don't put alkaline in this, they'll leak) and not have to go through this whole disassembly again.



Sheathing it with electrical tape to ensure the upper pins and the battery pack won't short, it fits neatly in the socket.



At this point we should now make sure we can power on the system, so I put back down the riser card (leaving out the stripped rear screw) and reinstalled the video card and retention pin.



Although the machine will bring up a console on the serial ports, I also wanted to know if the video card is working, so I got out an SGI-wired 13W3 to VGA converter and connected one of my utility LCD panels. I then plugged it into the wall, crossed my fingers and pressed the power button.



To my delight the machine did indeed power up and make its little happy jingle chord! However, nothing appeared on the screen and the Indigo2's LED stayed amber, suggesting the video card was unhappy about something.

The "something" in this case was probably the monitor. One thing that 13W3-based video cards do have in common is that they're all sync-on-green, which is to say that the horizontal and vertical sync signals are mixed in with the green channel. Many monitors nowadays, including this particular ViewSonic LCD panel, don't understand sync-on-green anymore and won't be able to sync. Conversely, as an unusual case, I have a NEC multisync CRT monitor that does sync to such a signal, but still displays the green anyway, giving it the wrong colour.



There is a more definitive solution for this problem and we will address it later on, but fortunately it turned out my INOGENI USB VGA capture box does understand sync-on-green, and the PROM monitor display rate is 60Hz which the INOGENI will accept. For the time being, the M1 MacBook Air and VLC can thus serve as the monitor (and we can also take screen grabs).

With the Mac connected I reset the Indigo2, and this time the SGI's LED turned back to green and we got a picture. The picture said the machine was unbootable, though we already knew that because we pulled the drives out. I powered it off and plugged in a PS/2 keyboard and mouse. Normally you shouldn't operate the machine with the case off because it can't run its airflow normally, but there is sufficient ventilation here even though you can certainly feel the heat from the CPU module.



I then secured the battery holder to the metal back of the riser card with some Velcro. It fit perfectly.



With the battery holder in place and the timekeeper now working again, I installed the hard disks and the optical drive, and powered it on with the capture box connected. Now that I knew the machine was working, I went ahead and ordered the extra RAM, but we have other tasks to complete in the meantime. Let's switch to the screen grabs, which have been cropped and corrected for aspect ratio.



One of the things that made SGI MIPS (and its early PC hardware, but more on that later) interesting was the graphical boot PROMs. These are based on the Advanced RISC Compouting (ARC) specification modified for SGI's usage ("ARCS"). ARC came out of the Advanced Computing Environment (ACE) consortium originally founded by Compaq, Microsoft, MIPS (pre-acquisition), DEC and SCO in 1991, later joined by SGI, Control Data Corporation, Prime Computer, Zenith and others. Notably absent were Sun Microsystems, Hewlett-Packard and IBM, who never participated — nor Intel.

At this time in the industry RISC was believed to be the future — but so was Windows NT, or what was then referred to as OS/2 3.0 or "Portable OS/2," due to its planned wide portability and the existing software it supported. ACE concentrated on 32-bit x86 using conventional BIOS (due to Compaq's influence) and near-future RISC workstations using ARC; they identified two platforms, namely SCO UNIX and the future Windows NT, that would run on both. MIPS was heavily touted as the architecture for these workstations, both from SGI and MIPS' presence, and the absence of anyone else more powerful to say otherwise.

Within a year, however, ACE rapidly degenerated into squabble and collapsed: market appetite for the alternative ARC workstation didn't develop as planned, and SGI buying MIPS was the last straw for some participants who saw the purchase as SGI trying to corner the architecture. DEC, which was already working on what would become Alpha anyway, de-emphasized its MIPS offerings as a result and eventually got out of the business altogether. Intel, for its part, accelerated development on Pentium in response and made non-x86 alternatives comparatively even less desirable. Although ARC foundered, and no computer was ever fully compliant with its specification, it maintained a long-standing legacy presence in Windows NT which still specified it for boot devices until Windows Vista. Likewise, the RISC systems that could boot Windows NT generally used an ARC console to do so, even ones that weren't MIPS-based like various Alpha-based workstations in the form of AlphaBIOS, and some RS/6000s.

No SGI MIPS hardware ever booted NT natively, though through the influence of ACE where MIPS was supposed to reign supreme these boot PROMs implement ARC too, at least in their own fashion. But what makes them most outstanding to modern users is that they have a full mouse-based GUI congruent with IRIX and the ability to do some basic tasks built-in.



Messages appear as well-rendered dialogue boxes, sometimes extracted from console output and highlighted to the user. If you clicked the Stop For Maintenance button (or pressed Escape) you would enter the main menu right here before starting the OS.



Other output appeared in a text window where additional detail was required. However, our disks still don't boot and the message doesn't tell us why, so we proceed to the PROM menu.



The System Maintenance menu has six options accessible by button clicks or the numbers 1-6. Using the keyboard is particularly handy when your mouse doesn't work or if, as in our circumstance, you're struggling with screen lag due to the capture box. The most immediately useful is the Command Monitor, so we press 5.



This pops up in a new window. (That also means there was no password on the PROM. If one was set, and we don't know what it is, removing a jumper on the board under the CPU card will allow you to reset it.)



We first list our hinv, the hardware inventory, using the -v option for verbose output. This reports we have an IP28, 64MB of RAM, a 195MHz R10K and Solid IMPACT graphics, as expected. The Iris Audio Processor is the standard onboard audio codec used in many SGI-MIPS systems.



The environment (printenv) didn't look too interesting other than its apparently residual IP address, but the MAC address did appear and seemed valid, so we shouldn't need to worry about that like we would with an Indy. Nevertheless, just in case anything was corrupted, I did a resetenv at this point to force defaults.



With the default environment I tried to boot again, and this time got a marginally more useful message: Boot file not found on device: scsi(0)disk(1)rdisk(0)partition(8)/sash. This is an ARC path and should be fairly self-explanatory (basically SCSI bus 0, i.e., the internal bus, ID 1, LUN 0, partition 8). This partition is where the standalone shell should be found to bring up the IRIX kernel but it's not finding it.



hinv -t will show you the device tree. Most of it makes sense, but when we get to the internal SCSI bus (starting with adapter SCSI WD33C93B key 0, a Western Digital Fast SCSI-2 controller) it gets very weird. Note as background that the controller in SGI hardware has ID 0 (not 7 like, say, Macintoshes), so connected devices start at ID 1. One of the hard disks is indeed at ID 1 — and then the other one is sprayed over every other ID.



I also didn't see the optical drive anywhere in that list. Given that one of the hard disks got an ID despite the other one going nuts, this device should have gotten one also. Nevertheless, I decided to grab one of my caddies, stick an IRIX Tools CD in it and see if I could bring up a miniroot. This disc in particular is known good and readable by the Indy. The drive accepted the caddy and seemed to be fine with the disc ...



... but trying to bring up the miniroot from it (using the PROM menu install option) showed no bootable devices.



I shut down the system and pulled out all the devices again, then had a look at the optical drive specifically. The sleds carry power, SCSI and SCSI ID lines. It looked like it was hooked up correctly but it was strange to see a La Cie sticker on it. That sounded like a Mac drive which had been repurposed.



Extracting it from the sled, the drive revealed itself as a Sony CDU948S. I noticed that there was no parity jumper, and indeed the manual seems to indicate that parity can't even be enabled on this drive, which would make it unbootable. I imagine the prior owner simply went with what he had available. We'll replace that now.

On the shelf I had some old Toshiba XM-5401B SCSI CD-ROMs which I had purchased for another project long since forgotten. These are highly compatible and will generally boot just about anything, assuming they're working, which the first one wasn't (wouldn't eject its tray without a lot of force). I tried the second one.



While you don't need to connect the SCSI ID cable and can assign IDs manually, it's easier to let the machine do it. On this drive the SCSI ID cable goes on in this orientation. I installed the new old CD-ROM drive alone and booted the system back into the command monitor.



hinv -t shows the drive, on ID 1, and no more drives-all-over-the-place nonsense. This also means the SCSI controller wasn't likely at fault.



And the installer option sees it too, and will offer to boot from it, but, uh ...



... um, the CD's already in there ...



... so both drives are bad.

The only other internal SCSI CD-ROM I had at hand was a Nakamichi CD changer, but that seemed like a waste, so I scrounged around in the server room for alternatives. In the stack of parts for the Fuel I found a spare factory-issue SCSI DVD-ROM (Toshiba SD-M1711). I knew this was bootable in the Fuel, so it probably would also be bootable here.



I got it the ID cable upside down the first time, but the second time it went on cleanly and got assigned an ID.



In the Command Monitor it showed as ID 6 and was recognized as a CD-ROM. To make sure of what I was dealing with, I ran hinv this time with -t -p to give me ARC paths, showing the full ARC path for the device would be scsi(0)cdrom(6) — there is shorthand for this, I promise. I then tried to bring up the standalone shell from the tools CD with boot -f scsi(0)cdrom(6)partition(8)/sash64 and this time it worked! The Sony drive went on the parts shelf for another system to use some other time.



That took care of the optical drive, so I next looked at the IBM drive that had been spamming the SCSI bus (the one in the top bay).



The problem was obvious: the ID cable wasn't connected, so my best guess is the hard disk thought it was ID 0 and promptly clashed with the controller. In fact, the cable wasn't anywhere near long enough to have even reached the drive's ID pins — which also meant it couldn't possibly have been bootable either. I ejected its tray and turned my attention to the second drive.



With the drive installed by itself, it comes up once again as ID 1, so I put the DVD-ROM back in and decided to try system recovery to see what might be on it.



The optical drive is recognised and we insert the CD.



And, immediately, the PROM starts copying the installation tools to disk. This is notable: that means the hard disk has something the PROM recognizes as a swap partition, where the miniroot lives during system recovery operations.  



The crash recovery kernel successfully starts within the console and asks for the machine's hostname. As it happens I've already picked a name for the Indigo2, and it is ... purplehaze. Catchy, no?



This is what I meant by the PROM monitor intercepting certain strings on the console. Because I reset the environment way back when, it now has a 192.168.1.2/24 address which the kernel treats as unconfigured. This is a string the kernel simply emits, but as the PROM monitor services the console, it sees it arrive and promotes it to a dialogue box instead.



There isn't really anything to restore from, so I forced it into a shell at this point.



The fuller hinv available from an IRIX shell prompt shows everything we expect it to, and the miniroot's /dev shows that the remaining hard disk has partitions at 0, 1, 6, 7 and 15. This might suggest the disk was formatted XFS at some point, since 0 would be the root, 1 would be swap, 6 would be /usr, 7 would be the whole thing minus the partition volume header in 8, and 15 would be the XFS log. I didn't see a partition 10, but that could be an artifact of how the disk was imported by crash recovery. However, there was no partition 8 for the standalone shell and other tools at all.



The miniroot also didn't want to mount partition 0 as either XFS or EFS. There is a small chance this was due to an incompatible way the partition filesystem was made, but the Tools version here is 6.5.9 and should be recent enough to understand XFS version 2 directories. The most likely conclusion is that the disk was partitioned but no filesystems were actually created, which means this machine was never actually bootable when I received it.

That's no problem — we'll just start fresh. And, since we're going to have to install IRIX from scratch anyway, let's do it on solid state.



There are only two sleds, and since the second drive we were using could actually be installed and enumerated (just not mounted), I decided to take the sled from the first drive that had no working ID cable. We'll then replace it with a ZuluSCSI.



The particular ZuluSCSI I selected has a bottom plastic carrier that I attached the sled to.



Unfortunately the clip on these things is spring-loaded and said spring is not secured particularly well, which ended up getting loose while I tried to adjust the sled's position in the drive bay. This required taking the carrier off again to rethread it.



Leftover was a couple of prop bars which I didn't need to mount the ZuluSCSI, so those will be put in the junk drawer in case they're useful for something else.



To cable it, however, we'll need an extension: the sled's connector is meant for a hard disk extending all the way back and can't be pulled further without damaging it.



Happily, I found a little SCSI extender of the right size in the box of tricks and a Molex-to-Berg power connector. The last step was to create a big 18GB empty image on the 32GB SD card as our IRIX volume (something like dd if=/dev/zero of=HD1.img bs=1024 count=18874368 will do). We can't install the SCSI ID cable on the ZuluSCSI, but we know that the emulated disk can come up safely as device 1, so we'll tag the disk image as such.



With the ZuluSCSI's sled installed in the top bay, we obligingly see the lights of both the DVD-ROM and the ZuluSCSI flash as we power on the system ...



... and both devices are visible in the device tree in hinv -t -p.



If we were still working with the second partitioned disk we could simply start the installer at this point, but the disk image on the ZuluSCSI isn't partitioned yet. This requires manually bringing up the fx partitioner from the CD. To save my fingers I used the ARC shorthand for the device paths: instead of scsi(0)cdrom(6)partition(8) we can just say dksc(0,6,8), and likewise for scsi(0)cdrom(6)partition(7), making the boot command from the Command Monitor boot -f dksc(0,6,8)/sash64 dksc(0,6,7)/stand/fx.64 --x (the --x option starts expert mode). The partitioner duly starts from disc.



We accept the defaults, which would be dksc(0,1,0) for the image on the ZuluSCSI. fx immediately determines the image is unpartitioned and sets up a default configuration.



We'll then label the disk. We really just need it to create the sgiinfo portion (used for administrative purposes) but no harm in having it do the rest again. This is almost instantaneous.



From the label menu don't forget to sync it to disk to ensure the new disk label is written, which I almost did (!), after which you can exit.



Back in the PROM menu, we'll proceed with the IRIX installer.

IRIX, the primary Unix for SGI-MIPS, originated on their first MIPS systems, the SGI IRIS 4D (thus the name, derived from "IRIS UNIX," and not actually an acronym). Prior 68K systems ran "GL2," based on UniSoft's port of UNIX System V; IRIX is a true Unix as well, likewise descended originally from UNIX System V, though it wasn't actually badged as IRIX until 3.0 in 1988 which corresponded to SVR3 with components from 4.3BSD. This "first" release implemented a distinctive window manager called 4Sight designed to resemble their prior "multiple exposure" (mex) interface. Unfortunately for SGI 4Sight was implemented with Sun NeWS and NeWS lost to X11, so IRIX 4.0 switched to X11R4 and the similar Motif-based 4Dwm window manager, which ultimately became IRIX's most lasting visual signature. When people talk about using IRIX, most of the time they're really talking about 4Dwm, a notable contrast against other proprietary Unices which largely used the HP VUE-derived CDE.

IRIX 6.0 made the jump to 64-bit, and 6.5 was the last major version, based on SVR4 and released in 1998. SGI cut off support for earlier machines like the Indy and this Indigo2 at 6.5.22, which is the version we will install, and subsequently locked versions up to 6.5.30 behind a support contract requirement. 6.5.30 was the last official release of IRIX in August 2006, which still supports later machines like the Fuel, and thus the Fuel system here runs that instead. SGI has never ported IRIX to any other platform nor made IRIX open source, nor is the company's current incarnation likely to ever do so, though some portions of source code were officially made available such as the XFS file system (which yours truly uses for the boot volume in my Fedora Linux Raptor POWER9). Various clone window managers exist today that try to recapture the style and substance of 4Dwm on modern hardware, but they end up falling in the uncanny valley in various ways, and in the end there's still nothing like the original.

It is certainly possible to run other operating systems on SGI-MIPS, notably NetBSD up to IP32 and hacked versions of the former OpenBSD port, but I like IRIX too much to do that.



We now have a valid swap partition on the ZuluSCSI image, so we can actually start the installation miniroot this time.



Despite the new timekeeper our clock is a little off and we'll correct that from the NTP server when we get networking up, but we don't have a filesystem yet on the image, which the installer will now offer to create. (This step is what I suspect didn't happen with the second hard disk.) 



Again, this is very fast on the ZuluSCSI, and we go right into the installer from there.



From-scratch IRIX installations of later versions involve a lot of disk swapping and overlays. This article is long enough already without me trying to do a comprehensive IRIX installation guide, and it would be fruitless anyway because there are so many permutations. However, this install guide is pretty good for most intents and purposes. There are also various means of doing the installation from a network server, but I don't have this set up, and I try not to do so many IRIX installs that it would become worth it to do so.



Here we'll load up the install sets ...



... marvel at the cutting-edge included applications like Java 1.4, Acrobat Reader 4.05b and Netscape Navigator 4.8a ...



... and, after resolving the inevitable conflicts between packages, finally start the installation. I did this all manually with CDs. In the future I might try just loading them all as ISOs on the ZuluSCSI as well. 



A number of disc swaps later, we are "finished" ...



... except for having to re-quickstart all the ELF files that were just installed. Since this leaves us with a nice clean install of IRIX I could potentially use later, I powered the system off and backed up the disk image.



The new sticks of RAM had arrived, so I pulled the 5.25" tray one last time to install them.



This brings us to 192MB, but for some unexplained reason the system then put up the solid amber LED again when I tried to reboot. I got out a serial cable this time.
System Maintenance Menu

1) Start System
2) Install System Software
3) Run Diagnostics
4) Recover System
5) Enter Command Monitor

Option? 5
Command Monitor.  Type "exit" to return to the menu.
>> hinv
                   System: IP28
                Processor: 195 Mhz R10000, with FPU
     Primary I-cache size: 32 Kbytes
     Primary D-cache size: 32 Kbytes
     Secondary cache size: 1024 Kbytes
              Memory size: 192 Mbytes
                SCSI Disk: scsi(0)disk(1)
               SCSI CDROM: scsi(0)cdrom(6)
                    Audio: Iris Audio Processor: version A2 revision 1.1.0


For some horrible reason the Solid IMPACT card was suddenly not being seen. I decided to see what the diagnostics would say about that, since it was obviously just working and I hadn't messed with the graphics card or the riser. This can run from the new install of IRIX; we don't need the CD.
>> exit


System Maintenance Menu

1) Start System
2) Install System Software
3) Run Diagnostics
4) Recover System
5) Enter Command Monitor

Option? 3


                         Starting diagnostic program...

                       Press <Esc> to return to the menu.

              Checking for Distribution CD-ROM on scsi(0)cdrom(6).
dks0d6s8: Device not ready: Medium not present
dks0d6s8: drive is not ready

             Distribution CD-ROM not found.  Booting installed IDE.
SGI Version 6.5 IP28 IDE field  Oct  6, 2003

                   System: IP28
                Processor: 195 Mhz R10000, with FPU
     Primary I-cache size: 32 Kbytes
     Primary D-cache size: 32 Kbytes
     Secondary cache size: 1024 Kbytes
              Memory size: 192 Mbytes
                 Graphics: Solid Impact
                SCSI Disk: scsi(0)disk(1)
               SCSI CDROM: scsi(0)cdrom(6)
 
Testing Impact graphics.


Notice that when the diagnostics program started, it did see the board, and could drive it for testing.



The full diagnostics check took about a half hour to run, but in the end everything seemed fine ...
TEST RESULTS: 
CPU tests completed. 
FPU tests completed. 
Audio tests completed. 
SCSI tests completed. 
Impact graphics board tests completed. 
Diagnostics completed - press <Enter> to continue


... so I'm not sure what happened there. The system rebooted uneventfully and showed a proper green LED this time, though on the maiden boot of the operating system it switched to a non-60Hz mode the INOGENI didn't like and required me to hook up the Hall scan converter. These next few images are a bit fuzzy as a result. Sorry about that.



Yes, yes, we'll eventually fix the clock. Yes, yes, we'll eventually plug in the network.



Four default logins are created, root (duh), demos, guest and EZsetup. None of these have a password yet. Don't put this on an unprotected network exposed to the outside world, please.

I don't really need the easy setup, but for demonstration purposes here it is.



EZsetup's post-install wizard features four steps to greatness: security, networking (because nothing says security like networking), creating a non-root account, and customizing your work environment, which mostly means dumbing down 4Dwm and setting up Netscape.



Security, in this case, means creating passwords and setting permissions. This machine will spend the rest of its days with me only ever on the hardwired non-routable internal network, but this step is certinaly better than nothing for those of you who may not have the locked-down playground I have here for such machines.



After you've accomplished these trivial token tasks, you can quit, though the account remains available.



On our next boot the refresh rate issue sorted itself out and we come to the nice clean 4Dwm desktop of our new user account. I have more applications to install, but before we do that, we need to put its top case back on and find it a better place of lurkage than under that table.



Shutting IRIX down.



The top cover is reinstalled by fitting these rear plastic tabs into slots in the metal back panel and rotating it back down into position.



And, of course, they're old plastic, so they immediately tried to separate and snap off from the upper lid when I inserted them. Light-set high quality cyanoacrylate time.



Despite this, the top cover still wouldn't come all the way down onto its clips — it was getting stuck on the ZuluSCSI's plastic carrier, which needed to be pushed back a little. Of course, the minute I did that, the plastic clip on the drive sled snapped.



I got it glued back together but it had snapped at the very thinnest section, naturally, and the spring chose this moment to come loose again at the same time. After some screaming and infuriated reassembly the sled's clip was good for exactly one insertion before it snapped again in the same place, but only one insertion was required; the new position of the carrier allowed the top case to finally come down fully and lock. I'll deal with that if I ever have to take it out again, which comfortably should be never.

I also put back the second drive after disconnecting its power. I don't really have anywhere else to keep the sled and at least that drive is formatted and wired up, so it might as well stay there.



With the front bezel back on, we have a green LED and a clean boot into the system maintenance menu. It's time to assign it a home.



I found a nice cleared-out area where it could sit vertically next to homer, the HP 9000/350 rack in the server room, and dragged it on back.



As we won't be using the MacBook as its display anymore, we'll need to do something about the sync-on-green. Such boxes are not very common nowadays, but Software Integrators still sells brand-new active sync converters (model #7053) that filter out the sync signal from the green channel and turn it into composite sync which most monitors will recognize. I use one of them with my Indy and I keep a couple more in stock (not affiliated, just satisfied). They aren't cheap and they're active components that require their own power supply, but these boxes are probably the least expensive ones you'll find and they're still manufactured.



With the network up, files are obtained, and serious sgidoom and Mozilla 1.7 business ensues.



I was pleased to note that despite not having an external LED light to connect to, the internal activity LED of the ZuluSCSI can be easily seen through the bezel apertures with the front door down.



Shutting down. Now that I know the new RAM works, I think I'll fill up the other bank with an additional 128MB, plus I'm toying with tracking down a 10/100 Ethernet card for the EISA slots. It's stereo-capable, so I should figure out how that works, and of course if a High IMPACT or Max IMPACT card turns up at a decent price, I'd be a Fuel fool not to buy it. It's hotter and louder than the Indy, but it's a lot more powerful, and shouldn't everyone have a big purple time and money sink in their hobby? Plus, I got a powerful classic SGI system for free, and now that it's fully operational I really ought to make the most of it.

With our refurb complete, let's finish the story. The R10000 was only intended to be SGI's next processor architecture, but it ended up being their last. Originally, MIPS' market strategy was to create high-end chips and then shrink them, which it did successfully for the R3000 and R4000. However, that strategy fell apart with the R8000, and in the R10000 era MTI instead decided on tiered chips for multiple market points by continuing to iterate on earlier designs. This even progressed to the point that MTI planned on making a midrange "D2" follow-on to the R5000, which wasn't even their design, and a separate high-end "H1" chip codenamed the "Beast."

The revised strategy might have worked except that MTI didn't have enough design resources for multiple microarchitectures. So SGI went back to the old strategy: big powerful cores that could be scaled down.



In May 1997 SGI announced their new MIPS roadmap (here reproduced from Microprocessor Report May 12, 1997), starting with an enhancement of the R10K called the R12000. It would be built on the current 250nm process size, enlarge the number of instructions in flight to 48 from 32 and add a new pipeline stage, implement a new branch target address cache with 32 entries a la contemporary PowerPC, and expand the branch history table to 2048 entries from 512 (compensating for the longer pipeline's larger mispredict penalty) while doubling the size of the way-prediction table to better support large L2 caches. SGI expected the R12000 to hit 300MHz or better and would only need about ten percent more die space.

The "Beast" H1 remained in SGI's plans, now scheduled for 1999 at 250nm and 2000 at 180nm, to be followed by an even higher-performance "H2" core codenamed "Alien" somewhere around 2001. Along the way SGI-MTI gamely predicted a six-fold increase in integer performance from the 350nm R10K to the terminal H2. Although Alien was too far in the future to be definite, Beast had some lofty and specific goals; it was to be a MIPS V CPU with MDMX SIMD extensions, implementing a 256-bit cache bus and 256-bit main memory bus at speeds of 200MHz or higher. Alien, on the other hand, was intended for large NUMA multiprocessing systems and correspondingly with even higher bandwidth, by no means coincidentally similar to Cray that SGI had just bought out.

Industry analysts didn't find R12K particularly compelling against expected future competitors and expected Beast would provide a stronger punch. However, after about a year's worth of work — which was only three months after the roadmap announcement — SGI abruptly canned Beast to the market's general surprise, claiming that R12K would be more scalable than anticipated and they would redirect engineers to Alien instead. More ominous to customers was SGI's quieter simultaneous announcement of "Intel-based" Windows NT systems to emerge in 1998, which SGI called the "Visual PC" initiative. Indeed, in 1998 SGI shut down Alien development as well, something that had been all but openly expected, and spun off MTI as a separate company in March to focus on MIPS in the embedded market. The "Visual PC" emerged in August 1999 as the SGI Visual Workstation running Windows NT 4. The first two machines in the series were not fully standard Pentium II and III PCs; they maintained custom graphical boot PROMs and used SGI's bespoke Cobalt graphics, requiring a custom HAL for NT 4 and Windows 2000. Architecturally these early VWs were similar to the SGI O2, while later units were essentially commodity PC hardware with Nvidia Quadro GPUs.

As Itanium started looming over the market, SGI too lost its corporate mind and jumped on the IA-64 bandwagon. Meanwhile, despite vague noises about porting IRIX to x86 (or possibly even Itanic) or providing an emulation layer, the existing MIPS install base proved simply too large to ignore, and SGI did not want to lose existing customers with large ecosystem investments to other vendors — especially since the roadmap for Itanium was far from certain. For this legacy market SGI retained some of the MIPS engineers to continue refining the R10K core and produced new hardware around it. The R12000 finally started shipping in February 1999 initially at speeds up to 300MHz, fabbed by NEC and Toshiba at 250nm and reducing the 7.15 million transistor die to 229mm², though delays and the Osborne effect limited its availability until May. From the R12K to the R14000 and R16000 (codenamed "N0"), each generation had a corresponding "A" subtype with boosted clock speeds, but other than die and process shrinks few other microarchitectural improvements were made. In general these late CPUs were clocked relatively low to reduce heat and power usage. The last, mightiest and rarest R16000A, fabbed by NEC at 110nm in 2004, topped out at 1.0GHz and was only produced for specific customers in limited quantities. None of these chips ever made the jump to MIPS V.



SGI did consider two more chips in the series, though the company was increasingly in the weeds by this point and neither was produced. The best known of these was the R18000 (codenamed "N1"), which SGI presented an early version of in 2001. Specifically intended for SGI's ccNUMA servers, its core was recognizably based on the R10K but each FP unit now had independent multiply, add, divide and square root capability as well as multiply-add, and the core also got an additional load/store unit. A new "SysTF" bus used twin DDR links, one a large non-multiplexed 128-bit read path plus a smaller 64-bit multiplexed write and address path, as well as preserving Avalanche ("SysAD") compatibility. Up to 1MB of L2 cache was on chip, and up to 64MB of external L3 cache (with cache tags on-die) was supported. It was to be fabbed by NEC on a 130nm process in nine layers of copper, and planned for around 2004.

In 2002 SGI suggested N1 could be fabbed at 110nm and run up to 800MHz, but also mentioned an "N2" to appear in 2005 which was widely believed to be a future R20000. SGI promised speeds of 1GHz or more and up to 8 gigaflops of FP performance per core, though the company provided little other information. Both chips were quietly cancelled.

On the graphics side, the terminal VPro ("Odyssey" and "InfinitePerformance") architecture could at best only tread water: it had some very advanced lighting and colour features, but suffered from inordinately weak memory bandwidth and poor texture mapping performance, and was expensive to produce on top of that. SGI abandoned it for Nvidia GPUs which, despite some being badged as VPro cards, were not compatible with legacy MIPS. The MIPS server line offically came to an end with the Intel Itanium 2 (McKinley) Altix in January 2003, SGI's first Itanic systems, running Windows NT and Linux; the workstations were subsequently succeeded by the McKinley-based Prism in April 2005 using the same architecture and ATI FireGL GPUs. They were poorly priced and poorly performing, another nail in the coffin of Itanium, and consequently failed to restore SGI to its former glory. All MIPS product lines were finally terminated in December 2006.

I have some more machines to work on and disposition, by the way. You'll be seeing those soon.

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A single, 'naked' black hole confounds theories of the young cosmos]]></title>
            <link>https://www.quantamagazine.org/a-single-naked-black-hole-rewrites-the-history-of-the-universe-20250912/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45237442</guid>
            <description><![CDATA[The James Webb Space Telescope has found a lonely black hole in the early universe that’s as heavy as 50 million suns. A major discovery, the object confounds theories of the young cosmos.]]></description>
            <content:encoded><![CDATA[
    A black hole unlike any seen before has been spotted in the early universe. It’s huge and appears to be essentially on its own, with few stars circling it. The object, which may represent a whole new class of enormous “naked” black holes, upends the textbook understanding of the young universe.
“This is completely off the scale,” said Roberto Maiolino, an astrophysicist at the University of Cambridge who helped reveal the nature of the object in a preprint posted on August 29. “It’s terribly exciting. It’s highly informative.”
“It’s pushing the boundaries on what we think might be true, what we think might happen,” said Dale Kocevski, an astronomer at Colby College who was not involved in the new research.
Astronomers spied the bare black hole using the James Webb Space Telescope (JWST) — a mega-instrument built by NASA and its partners in part to reveal how galaxies formed during the universe’s first billion years. This new black hole, which is as heavy as 50 million suns and is dubbed QSO1, clashes with the old, provisional account of the galaxy formation process, which did not start with black holes. Black holes were thought to have come along only after a galaxy’s stars gravitationally collapsed into black holes that then merged and grew. But Maiolino and his colleagues described a solitary leviathan with no parent galaxy in sight.
The question now is how this black hole came to exist.

The most exciting — and controversial — possibility dates back to a 1971 proposal from the British physicist Stephen Hawking: that black holes arose in the primordial soup of the Big Bang itself. In that case, the object would have been sitting in the dark since the universe’s first moments, waiting for stars and galaxies to illuminate it.
QSO1 is one of hundreds of similar-looking objects nicknamed “little red dots” that JWST has spotted in its first few years of peering into the deepest recesses of time. Astrophysicists can’t say yet whether these dots are all black holes or not, and in general they’re still confused about the universe’s chaotic childhood. But the telescope’s snapshots suggest a rowdy young cosmos that fabricated big black holes and galaxies both together and independently, or maybe even a universe where black holes were among the first large structures in existence — dark tapioca bubbles in an otherwise smoothly blended cosmic tea.
QSO1 and the rest of the little red dots “tell us we don’t know anything,” said John Regan, a theorist at Maynooth University in Ireland. “It has been really exciting and very electrifying for the field.”
Pale Red Dots
Lukas Furtak, an astronomer at Ben-Gurion University in Israel, knew QSO1 was extraordinary the moment he saw it — or the moment he saw its three reflections hiding among a smattering of splotchy white galaxies in an image taken by JWST in 2023. It’s “something that pops out immediately,” Furtak said over Zoom, clicking on three nearly imperceptible red specks. “There are three red point sources here, here, this one up here.”
In the image, a fortuitous placement of galaxies and dark matter has bent light rays traveling from background objects just as a glass lens might; this “gravitational lens” reveals objects deeper in the early universe than the telescope could otherwise see. The lens magnifies and stretches the stuff behind it, sometimes creating multiple images of it. Furtak was mapping out the banana-shaped smears of galaxies that the lens had projected into multiple places when he spotted the three red dots of QSO1.
The dots caught his eye because they show no signs of stretching. He knew that the only thing that looks like a small, round point even after getting stretched out is an even smaller, rounder point. This was no galaxy, he figured; it must be a black hole, a concentration of mass so dense that its gravity creates an inescapable zone of space around it.
Over the next six months, Furtak and collaborators directed JWST to stare at each of the three red dots for 40 hours each to take a census of the colors of light coming from the object, known as a spectrum. That study concluded that QSO1 is very likely a glowing black hole packing a mass of tens of millions of suns into a span of at most 100 light-years across, seen as it appeared when the universe was just 750 million years old. (Today the cosmos is approaching 14 billion years old.)
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How the restoration of ancient Babylon is drawing tourists back to Iraq]]></title>
            <link>https://www.theartnewspaper.com/2025/09/12/how-the-restoration-of-ancient-babylon-is-helping-to-draw-tourists-back-to-iraq</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45236473</guid>
            <description><![CDATA[Work on the Temple of Ninmakh and walls at the Ishtar Gate is nearing completion at the Mesopotamian metropolis, a victim of centuries of damage and neglect]]></description>
            <content:encoded><![CDATA[Mentioned in the sacred texts of all three Abrahamic faiths, the ancient Mesopotamian city of Babylon, in modern-day Iraq, is today undergoing a revival. Two World Monuments Fund (WMF) projects are nearing completion and much-needed cultural tourism is returning.One project mitigates groundwater damage to the north retaining wall of the Ishtar Gate. The second is a restoration of the Temple of Ninmakh, dedicated to the Sumerian mother goddess. The team hopes there will be an official reopening for the temple this autumn, after which it will be available for gatherings such as weddings and concerts, as well as for the Babylon Festival, a celebration of international cultures that takes place every spring.Largely funded by the US embassy in Baghdad, the restoration of the temple and the north retaining wall are part of the Future of Babylon Project, initiated 15 years ago, which aims to document, waterproof and stabilise structures throughout the 2,500-acre site. (The US embassy cancelled funding for a planned walkway spanning the site of the Ishtar Gate in July due to budget cuts.)Visitor boomThe completion of these two projects coincides with a boom in tourism. Even in the midday heat, when tour guides refuse to emerge from their office, visitors from Romania, Russia and Iran enthusiastically explore attractions including the largely intact Lion of Babylon, the processional way and the museum next to a reconstructed Ishtar Gate.The return of heritage tourism is one of Iraq’s few recent success stories. Even as sectarian tensions simmer and the electrical grid has yet to be restored 22 years after it was destroyed in the US invasion, Babylon is being reborn.“We’ve had record numbers of visitors this year,” Raad Hamid Abdullah, Babylon’s antiquities and heritage inspector, tells The Art Newspaper. In 2024 Babylon hosted 43,530 Iraqi tourists and 5,370 foreign tourists, an increase from 36,957 Iraqi visitors and 4,109 foreigners in 2023, he says.“Now even locals from the adjoining city of Babil are coming,” Abdullah says. “It has once more become a popular place for family gatherings and wedding parties,” he says, adding proudly, “Babylon is a symbol of Iraq.”Babylon, the survivorAround 80km south of Baghdad, comprising both the ruins of the ancient city as well as surrounding villages and agricultural areas, Babylon is a survivor. From its peak as the Neo-Babylonian capital under King Nebuchadnezzar II through to the Iraq War, when American and Polish troops ran roughshod over its ruins and a decade later, Islamic State (Isis) threatened its very existence, the ancient city has witnessed empires come and go.Babylon has survived decades of looting and ongoing environmental challenges. Construction, too, has taken a toll over the years. In 1927 the British ran a railway line through the site, and in the 1980s Saddam Hussein built a highway through part of it, along with a palace for himself, complete with helipad. There are still three non-functioning oil pipelines, two built in the 1970s and 1980s and a more recent third one—work on it was blocked after Iraq’s General Authority for Antiquities and Heritage filed a lawsuit in 2012. Babylon was only recognised as a Unesco World Heritage Site in 2019.Now the Egyptian architect Ahmed Abdelgawad, an expert in mud brick buildings, is working with the WMF to train locals in the traditional art that befits the Temple of Ninmakh, named after the mother goddess associated with creation, birth and healing who breathed life into humankind via small clay figures in their likeness.Years of war-related damage and neglect combined with poorly executed mid-century “reconstruction” methods resulted in serious structural problems at the temple. Corrosion caused by the intrusion of increasingly salty groundwater is the product of prolonged droughts and soil erosion in climate-vulnerable Iraq.Traditional mud-brick techniquesThe archway at the entrance of Ninmakh’s inner sanctum—on the verge of collapse in 2022—was successfully restored at the end of May. “We had to totally dismantle the old arch,” Abdelgawad says. “It was full of cracks and worn by weather. So we took it apart and rebuilt it with mud bricks.”The traditional art of making special low-salt mud brick begins with sourcing soil with low salt levels, which is then mixed with sand, grit and straw.“This is the first arch in Iraq restored totally from mud bricks,” says Osama Hisham, the Future of Babylon project manager.A similar but saltier mix of mud brick and bitumen was used to repair the wooden roof of the temple, which was being eroded by termites.Hisham says the temple now comprises poplar timber from the forests of Mosul in northern Iraq, mud from Babylon and reeds from the marshes in the south. A place that has symbolised the heart of Iraq has now been restored with materials from across the nation.Groundwater zappingMeanwhile, the north retaining walls at the Ishtar Gate, reconstructed in the past century with cement that damaged the remains of the historical monument, were demolished and replaced with new retaining walls providing better water management. These new walls—essentially boxes filled with stones, based on an ancient Egyptian construction technique, Hisham says—absorb sunlight from the southern side and effectively vaporise groundwater coming from the northern side.The Babylonians, he says, dealt with groundwater intrusion by creating an elevation by“cutting the arch of the gate and burying it, then using it as a foundation for a new gate”. As a result of this technique, the Ishtar Gate built by Nebuchadnezzar II, where the WMF is currently finishing work on the north retaining wall, is seven metres below the ancient city, with only two metres remaining above.DisintegrationA subsequent spectacular blue-glazed gate Nebuchadnezzar II built on top of that gate gradually disintegrated in the aftermath of the fall of the Babylonian Empire in the sixth century BC. A replica installed in the 1950s now greets visitors to Babylon.Many Iraqis would like to see the reconstruction of the Ishtar Gate returned from the Pergamon Museum in Berlin. The gate is made of brick fragments from excavations carried out by the Deutsche Orient-Gesellschaft (German Oriental Society) from 1899 to 1917.But Hisham says that even the Ishtar Gate in Berlin is only 20% original. The gate in Babylon, he points out, is 80% original.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Two Slice, a font that's only 2px tall]]></title>
            <link>https://joefatula.com/twoslice.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45236263</guid>
            <description><![CDATA[A font that's only 2px tall, and somewhat readable!  Uppercase and lowercase have some different variants, in case you find one more readable than the other.  Numbers (sort of) and some punctuation marks are included.]]></description>
            <content:encoded><![CDATA[
		
		A font that's only 2px tall, and somewhat readable!  Uppercase and lowercase have some different variants, in case you find one more readable than the other.  Numbers (sort of) and some punctuation marks are included.
		You can probably read this, even if you wish you couldn't.It tends to be easier to read at smaller sizes.
		Try it out below, or download it (under CC BY-SA license, so you can use it commercially but you have to give credit).
		
	
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pass: Unix Password Manager]]></title>
            <link>https://www.passwordstore.org/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45236079</guid>
            <description><![CDATA[Pass is the standard unix password manager, a lightweight password manager that uses GPG and Git for Linux, BSD, and Mac OS X.]]></description>
            <content:encoded><![CDATA[

Introducing pass

Password management should be simple and follow Unix philosophy. With pass, each password lives inside of a gpg encrypted file whose filename is the title of the website or resource that requires the password. These encrypted files may be organized into meaningful folder hierarchies, copied from computer to computer, and, in general, manipulated using standard command line file management utilities.

pass makes managing these individual password files extremely easy. All passwords live in ~/.password-store, and pass provides some nice commands for adding, editing, generating, and retrieving passwords. It is a very short and simple shell script. It's capable of temporarily putting passwords on your clipboard and tracking password changes using git.

You can edit the password store using ordinary unix shell commands alongside the pass command. There are no funky file formats or new paradigms to learn. There is bash completion so that you can simply hit tab to fill in names and commands, as well as completion for zsh and fish available in the completion folder. The very active community has produced many impressive clients and GUIs for other platforms as well as extensions for pass itself.

The pass command is extensively documented in its man page.



Using the password store

We can list all the existing passwords in the store:

zx2c4@laptop ~ $ pass
Password Store
├── Business
│   ├── some-silly-business-site.com
│   └── another-business-site.net
├── Email
│   ├── donenfeld.com
│   └── zx2c4.com
└── France
    ├── bank
    ├── freebox
    └── mobilephone


And we can show passwords too:

zx2c4@laptop ~ $ pass Email/zx2c4.com
sup3rh4x3rizmynam3


Or copy them to the clipboard:

zx2c4@laptop ~ $ pass -c Email/zx2c4.com
Copied Email/jason@zx2c4.com to clipboard. Will clear in 45 seconds.


There will be a nice password input dialog using the standard gpg-agent (which can be configured to stay authenticated for several minutes), since all passwords are encrypted.

We can add existing passwords to the store with insert:

zx2c4@laptop ~ $ pass insert Business/cheese-whiz-factory
Enter password for Business/cheese-whiz-factory: omg so much cheese what am i gonna do


This also handles multiline passwords or other data with --multiline or -m, and passwords can be edited in your default text editor using pass edit pass-name.

The utility can generate new passwords using /dev/urandom internally:

zx2c4@laptop ~ $ pass generate Email/jasondonenfeld.com 15
The generated password to Email/jasondonenfeld.com is:
$(-QF&Q=IN2nFBx


It's possible to generate passwords with no symbols using --no-symbols or -n, and we can copy it to the clipboard instead of displaying it at the console using --clip or -c.

And of course, passwords can be removed:

zx2c4@laptop ~ $ pass rm Business/cheese-whiz-factory
rm: remove regular file ‘/home/zx2c4/.password-store/Business/cheese-whiz-factory.gpg’? y
removed ‘/home/zx2c4/.password-store/Business/cheese-whiz-factory.gpg’


If the password store is a git repository, since each manipulation creates a git commit, you can synchronize the password store using pass git push and pass git pull, which call git-push or git-pull on the store.

You can read more examples and more features in the man page.

Setting it up

To begin, there is a single command to initialize the password store:

zx2c4@laptop ~ $ pass init "ZX2C4 Password Storage Key"
mkdir: created directory ‘/home/zx2c4/.password-store’
Password store initialized for ZX2C4 Password Storage Key.


Here, ZX2C4 Password Storage Key is the ID of my GPG key. You can use your standard GPG key or use an alternative one especially for the password store as shown above. Multiple GPG keys can be specified, for using pass in a team setting, and different folders can have different GPG keys, by using -p.

We can additionally initialize the password store as a git repository:

zx2c4@laptop ~ $ pass git init
Initialized empty Git repository in /home/zx2c4/.password-store/.git/
zx2c4@laptop ~ $ pass git remote add origin kexec.com:pass-store


If a git repository is initialized, pass creates a git commit each time the password store is manipulated.

There is a more detailed initialization example in the man page.

Download

The latest version is 1.7.4.

Ubuntu / Debian

$ sudo apt-get install pass

Fedora / RHEL

$ sudo yum install pass

openSUSE

$ sudo zypper in password-store

Gentoo

# emerge -av pass

Arch

$ pacman -S pass

Macintosh

The password store is available through the Homebrew package manager:

$ brew install pass

FreeBSD

# pkg install password-store

Tarball


Version 1.7.4
Latest Git

The tarball contains a generic makefile, for which a simple sudo make install should do the trick.

Git Repository

You may browse the git repository or clone the repo:


$ git clone https://git.zx2c4.com/password-store

All releases are tagged, and the tags are signed with 0xA5DE03AE.

Data Organization

Usernames, Passwords, PINs, Websites, Metadata, et cetera

The password store does not impose any particular schema or type of organization of your data, as it is simply a flat text file, which can contain arbitrary data. Though the most common case is storing a single password per entry, some power users find they would like to store more than just their password inside the password store, and additionally store answers to secret questions, website URLs, and other sensitive information or metadata. Since the password store does not impose a scheme of it's own, you can choose your own organization. There are many possibilities.

One approach is to use the multi-line functionality of pass (--multiline or -m in insert), and store the password itself on the first line of the file, and the additional information on subsequent lines. For example, Amazon/bookreader might look like this:

Yw|ZSNH!}z"6{ym9pI
URL: *.amazon.com/*
Username: AmazonianChicken@example.com
Secret Question 1: What is your childhood best friend's most bizarre superhero fantasy? Oh god, Amazon, it's too awful to say...
Phone Support PIN #: 84719

This is the preferred organzational scheme used by the author. The --clip / -c options will only copy the first line of such a file to the clipboard, thereby making it easy to fetch the password for login forms, while retaining additional information in the same file.

Another approach is to use folders, and store each piece of data inside a file in that folder. For example Amazon/bookreader/password would hold bookreader's password inside the Amazon/bookreader directory, and Amazon/bookreader/secretquestion1 would hold a secret question, and Amazon/bookreader/sensitivecode would hold something else related to bookreader's account. And yet another approach might be to store the password in Amazon/bookreader and the additional data in Amazon/bookreader.meta. And even another approach might be use multiline, as outlined above, but put the URL template in the filename instead of inside the file.

The point is, the possibilities here are extremely numerous, and there are many other organizational schemes not mentioned above; you have the freedom of choosing the one that fits your workflow best.

Extensions for pass
In order to faciliate the large variety of uses users come up with, pass supports extensions. Extensions installed to /usr/lib/password-store/extensions (or some distro-specific variety of such) are always enabled. Extensions installed to ~/.password-store/.extensions/COMMAND.bash are enabled if the PASSWORD_STORE_ENABLE_EXTENSIONS environment variable is true Read the man page for more details.

The community has produced many such extensions:

	pass-tomb: manage your password store in a Tomb
	pass-update: an easy flow for updating passwords
	pass-import: a generic importer tool from other password managers
	pass-extension-tail: a way of printing only the tail of a file
	pass-extension-wclip: a plugin to use wclip on Windows
	pass-otp: support for one-time-password (OTP) tokens


Compatible Clients
The community has assembled an impressive list of clients and GUIs for various platforms:


	passmenu: an extremely useful and awesome dmenu script
	qtpass: cross-platform GUI client
	Android-Password-Store: Android app
	passforios: iOS app
	pass-ios: (older) iOS app
	passff: Firefox plugin
	browserpass: Chrome plugin
	Pass4Win: Windows client
	pext_module_pass: module for Pext
	gopass: Go GUI app
	upass: interactive console UI
	alfred-pass: Alfred integration
	pass-alfred: Alfred integration
	simple-pass-alfred: Alfred integration
	pass.applescript: OS X integration
	pass-git-helper: git credential integration
	password-store.el: an emacs package
	XMonad.Prompt.Pass: prompt for Xmonad


Migrating to pass
To free password data from the clutches of other (bloated) password managers, various users have come up with different password store organizations that work best for them. Some users have contributed scripts to help import passwords from other programs:


	1password2pass.rb: imports 1Password txt or 1pif data
	keepassx2pass.py: imports KeepassX XML data
	keepass2csv2pass.py: imports Keepass2 CSV data
	keepass2pass.py: imports Keepass2 XML data
	fpm2pass.pl: imports Figaro's Password Manager XML data
	lastpass2pass.rb: imports Lastpass CSV data
	kedpm2pass.py: imports Ked Password Manager data
	revelation2pass.py: imports Revelation Password Manager data
	gorilla2pass.rb: imports Password Gorilla data
	pwsafe2pass.sh: imports PWSafe data
	kwallet2pass.py: imports KWallet data
	roboform2pass.rb: imports Roboform data
	password-exporter2pass.py: imports password-exporter data
	pwsafe2pass.py: imports pwsafe data
	firefox_decrypt: full blown Firefox password interface, which supports exporting to pass


Credit & License

pass was written by Jason A. Donenfeld of zx2c4.com and is licensed under the GPLv2+.

Contributing

This is a very active project with a healthy dose of contributors. The best way to contribute to the password store is to join the mailing list and send git formatted patches. You may also join the discussion in #pass on Libera.Chat.


      ]]></content:encoded>
        </item>
    </channel>
</rss>