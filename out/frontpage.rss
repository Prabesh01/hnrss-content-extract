<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Fri, 12 Sep 2025 00:39:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Senator demands to know status of 'duplicate' SSA database 'immediately']]></title>
            <link>https://www.theregister.com/2025/09/11/ssa_doge_whistleblower_demand/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45217081</guid>
            <description><![CDATA[: Itâ€™s a Republican pressing after DOGE whistleblower flags hostile work environment]]></description>
            <content:encoded><![CDATA[
A US Senator is demanding answers after a Social Security Administration (SSA) employee who blew the whistle on Department of Government Efficiency (DOGE) dealings involuntarily resigned last month, citing workplace hostility in response to his concerns.Â 
Republican Senator Mike Crapo (it's pronounced Cray-poe), chairman of the Senate Finance Committee, sent a letter to the SSA's commissioner, Frank Bisignano, giving him just two weeks to provide answers to concerns raised last month by now-former SSA Chief Data Officer Charles Borges. The former CDO's whistleblower complaint alleged DOGE had duplicated a critical database filled with taxpayer information, known as Numident, to a test cloud environment that wasn't managed by Borges or SSA, and which allegedly is without any oversight controls.


As Chairman of the Senate Committee on Finance, I must take very seriously every allegation made by a protected whistleblower ... I consider the protection and security of PII held by the agency to be a matter of first importance

Numident is used to store records of every person who has ever applied for a Social Security Card in the United States.Â 
Crapo's questions are numerous, but one with a much shorter deadline stands out: He wants to know whether that duplicate database "was accessed, leaked, hacked, or disseminated in any unauthorized fashion," and he wants it "immediately upon receipt of this letter."
"As Chairman of the Senate Committee on Finance, I must take very seriously every allegation made by a protected whistleblower," Crapo added. "Further, given the large amount of sensitive data under SSA's control, I consider the protection and security of PII held by the agency to be a matter of first importance."

    

The SSA didn't directly answer questions about its response to Crapo, instead sending us an identical statement to the one it provided when we covered the original whistleblower complaint last month.Â 

        


        

"We are not aware of any compromise to this environment and remain dedicated to protecting sensitive personal data," an SSA spokesperson said, while maintaining that Numident data is stored "in secure environments that have robust safeguards in place to protect vital information." That doesn't explain the security of the alleged unauthorized copy of Numident. We pointed this out to the SSA, but haven't heard back.
Borges' complaint was primarily about the Numident copy, but he also raised concerns over his beliefs that DOGE had allegedly committed numerous "systemic data security violations" as well as violations of SSA protocols and federal data privacy laws in its time at the SSA.Â 


Dems fret over DOGE feeding sensitive data into random AI

Whistleblower describes DOGE IT dept rampage at America's labor watchdog

Dems look to close the barn door after top DOGE dog has bolted

Judge cites big OPM records leaks from 2015 in DOGE slapdown

In response to his concerns, Borges said in his resignation letter late last month that SSA's actions created a hostile work environment that made it impossible for him to fulfill his duties ethically or lawfully, caused significant distress, and effectively forced him from his role as chief data officer.
"After reporting internally to management and externally to regulators serious data security and integrity concerns impacting our citizens' most sensitive personal data, I have suffered exclusion, isolation, internal strife, and a culture of fear, creating a hostile work environment and making work conditions intolerable," Borges wrote in his letter to Bisignano. "SSA's actions against me [have made] my duties impossible to perform legally and ethically."Â 

        

In addition to his demand for answers about the integrity of the alleged Numident duplicate, Crapo is also demanding to know how SSA dealt with Borges' internal complaints, details about its use of cloud storage and data security mechanisms, and asks about how it assessed the risk of giving agency employees the ability "to transfer data from the Numident database to a private cloud within SSA's AWS cloud environment."Â 
Neither Crapo's office nor the Senate Finance Committee responded to questions for this story.Â Â®                                
                    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fartscroll-Lid: An app that plays fart sounds when opening or closing a MacBook]]></title>
            <link>https://github.com/iannuttall/fartscroll-lid</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45216844</guid>
            <description><![CDATA[A hilarious macOS app that plays fart sounds as you open and close your MacBook lid - iannuttall/fartscroll-lid]]></description>
            <content:encoded><![CDATA[FartScrollLid ðŸ’¨
A hilarious macOS app that plays fart sounds as you open and close your MacBook lid - inspired by the classic "fart scroll" browser extension!
Features

ðŸŽµ Dynamic Fart Sounds - Pitch changes based on lid angle (deep bass when closed, high squeaks when open)
ðŸŽ¯ Motion-Activated - Only farts when you're actively moving the lid
ðŸ“Š Real-Time Monitoring - Shows lid angle, velocity, and fart parameters
ðŸ˜„ Funny Status Messages - "Maximum pressure!", "Gas escaping!", and more

How It Works
FartScrollLid uses the MacBook's internal lid angle sensor (discovered through reverse engineering) to detect the angle between your laptop lid and base. When you move the lid, it triggers fart sounds with:

Pitch modulation based on lid angle (0-130 degrees)
Volume control based on movement speed
Instant response - farts stop immediately when you stop moving

Requirements

macOS 11.5 or later
MacBook with lid angle sensor (most modern MacBooks)
A sense of humor

Installation
Option 1: Build from Source

Clone this repository:

git clone https://github.com/iannuttall/fartscroll-lid.git
cd fartscroll-lid

Open in Xcode:

open FartScrollLid.xcodeproj

Build and run (Cmd+R)

Option 2: Download Release
Download the latest .app from the Releases page.
Usage

Launch FartScrollLid
Click "Start Farting"
Move your MacBook lid up and down
Enjoy the symphony of farts!
Stop moving to silence the farts
Click "Stop Farting" when you've had enough fun

Technical Details
Lid Angle Sensor

Device: Apple HID device (VID=0x05AC, PID=0x8104)
HID Usage: Sensor page (0x0020), Orientation usage (0x008A)
Data format: 16-bit angle value in centidegrees (0.01Â° resolution)
Range: 0-360 degrees

Audio Engine

Uses AVFoundation for real-time audio playback
Varispeed unit for pitch modulation (0.5x to 2.0x)
Smooth parameter ramping to avoid audio artifacts
Movement threshold: 2 deg/s minimum to trigger farts

Project Structure
FartScrollLid/
â”œâ”€â”€ FartScrollLid.xcodeproj/    # Xcode project
â”œâ”€â”€ FartScrollLid/              # Source code
â”‚   â”œâ”€â”€ AppDelegate.m/h         # Main app controller
â”‚   â”œâ”€â”€ FartScrollLid.m/h       # Lid angle sensor interface
â”‚   â”œâ”€â”€ FartAudioEngine.m/h     # Fart sound engine
â”‚   â”œâ”€â”€ NSLabel.m/h             # Custom label class
â”‚   â””â”€â”€ FART.wav                # Fart sound file
â””â”€â”€ README.md                   # This file

Credits

Based on the original LidAngleSensor app by Sam Henri Gold
Fart sound from fart.js
Inspired by the original fart scroll browser extension by The Onion
Built with assistance from Factory Droid

License
MIT License - see LICENSE file for details
Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.
Ideas for improvements:

Additional fart sound variations
Customizable pitch/volume curves
Fart statistics tracking
Network multiplayer farting
Apple Watch companion app

Disclaimer
This app is for entertainment purposes only. Please use responsibly in appropriate settings. Not recommended for:

Business meetings
Libraries
First dates
Job interviews
Funerals

But highly recommended for:

Pranking friends
Amusing children
Breaking awkward silences
General tomfoolery

Author
Created by Ian Nuttall with Factory Droid

Remember: Life is too short not to laugh at fart sounds from your laptop ðŸ’¨ðŸ˜„
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Danish supermarket chain is setting up "Emergency Stores"]]></title>
            <link>https://swiss.social/@swaldorff/115186445638788782</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45216805</guid>
        </item>
        <item>
            <title><![CDATA[The Apache Software Foundation's New Logo]]></title>
            <link>https://news.apache.org/foundation/entry/introducing-the-asfs-new-logo</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45216415</guid>
            <description><![CDATA[Last year we shared that The ApacheÂ® Software Foundation (ASF) would be evolving its corporate logo and brand system to better represent our enduring ethos of community over code. Today, we are proud to unveil the new ASF logo.Â  Why an Oak Leaf? The centerpiece of our new logo is an oak leaf, chosen for [â€¦]]]></description>
            <content:encoded><![CDATA[

	

	
	
		
Last year we shared that The ApacheÂ® Software Foundation (ASF) would be evolving its corporate logo and brand system to better represent our enduring ethos of community over code. Today, we are proud to unveil the new ASF logo.Â 






Why an Oak Leaf?



The centerpiece of our new logo is an oak leaf, chosen for its resonance with the values that define The ASF and its communities.



In the 1990s, eight people planted an acornâ€“the seed of something new, which became The Apache Software Foundation. Over the decades since, more and more joined them. They formed organized structures and supported a growing forest of projects of many types.



At the top of a botanical canopy, the largest and oldest trees, like oaks, form a crown that is critical to maintaining the diversity of the forest and ensuring its resilience. But part of their job in doing so is forming a network with other types of trees, as well as creating opportunities for new growth and nurturing that growth when it arrives.



The oak is one of the most enduring trees and is found around the world. It grows slowly but steadily, supporting vast ecosystems and lasting for centuries. In the same way, The ASF has served as a stable, resilient steward of open source for more than 25 years and is looking to the long future ahead.Â 



Choosing the oak leaf as our new logo represents the enduring power of our ethos: community over code.



Reflecting ASF Values



Enduring and ResilientOak trees are long-lived and resilient, reflecting The ASFâ€™s commitment to sustainability and project longevityâ€”software for the public good. Like an oak, ASF projects are built to grow and endure over time.



Empowerment and CommunityFrom small acorns grow wide canopies. This reflects how ASF communities can begin with small contributions and grow into inclusive, self-governing ecosystems. The ASF empowers people to build togetherâ€”and to create something that lasts.



Stewardship and TrustOaks are foundational species that sustain entire communities of life. Similarly, The ASF provides stable ground for open source to flourish, guided by The Apache Way. For more than 25 years, people around the world have trusted The ASF to steward software the world relies on.



Neutrality and OpennessThe unique veins of an oak leaf symbolize distributed systems, consensus, and open collaborationâ€”hallmarks of The Apache Way. Our new oak leaf icon underscores The ASFâ€™s commitment to neutrality, inclusivity, and openness for all.



Our Process



This new logo reflects the collective effort of our community. Over the past year:




The ASF Board formed a Logo Project Management Committee (PMC), made up of ASF Members, to guide the logo creation and selection process through the same structure we use for ASF software projects.



ASF Members contributed ideas and designs, submitting logos within established guidelines that emphasized inclusivity, neutrality, and timelessness.



Design partners worked with the PMC and the ASF Marketing & Publicity team to refine the visual identity into a logo that honored our history while looking toward the future.




We chose to keep a similar color palette to our existing brand for continuity with our history and recognition by those who have long known The ASF, but weâ€™re also taking the opportunity to refresh aspects of our branding and making design choices better suited to todayâ€™s uses of our logo.



From the ASF Board and Logo Project Management Committee to our Members, contributors, and design partnersâ€”thank you for shaping a symbol that will carry us forward for the next 25 years.



Our oak leaf is more than a design: itâ€™s a reminder that community is the foundation on which everything we build grows and thrives.



Whatâ€™s Next




View the new website



Read the new Brand Guidelines




FAQ



Will you stop using the full name â€œThe Apache Software Foundationâ€?The Apache Software Foundation continues to operate under its full legal name, but we will also use the acronym â€œThe ASFâ€ as part of our visual identity and reference across websites, documentation, and public-facing materials. This update reflects our commitment to clarity, simplicity, and consistency in how our global community recognizes and interacts with us.



Using â€œThe ASFâ€ helps reinforce our role as a foundation of people and projects working together, rather than as a monolithic organization. The full name remains in use where legally required â€” such as in copyright notices, footers, and formal documents. For project-specific references, projects will continue using their established names (e.g., Apache HTTP Server).



Are you planning to remove the term â€œApacheâ€ entirely from project names or the Foundation?No. We are not removing the term â€œApacheâ€ from the Foundation nor from project names at this time. For security concerns and continuity of the software ecosystem, ASF Projects will continue using their established names (e.g., Apache HTTP Server).Â 



Why not change the name of the Foundation entirely, if there are sensitivities around â€œApacheâ€?When a name has been in use as long and is as widely used as ours, the ramifications of changing it are both broad and deep. The implications on the security of the global software supply chain if the ASF were to move away from the â€œapache.orgâ€ domain are such that a change is not practical to do. However, we recognize that language and symbols matter. As part of our ongoing efforts to align our brand with our values, we are re-evaluating how and where we use â€œApache,â€ especially in visual branding. Please see Evolving the ASF brand for further context and community guidance.



When should I use The ASF logo vs. The Apache Software Foundation logo?While both logos are appropriate, the ASF logo â€” using just the acronym â€” can be used in general and project-related contexts. The full â€œApache Software Foundationâ€ logo will be used for legal and institutional use by the Foundation itself (e.g., tax filings, board reports, and official notices).



Iâ€™m a contributor to/user of ASF software. How will this impact me?There is no impact on how you contribute to or use ASF software. The Apache license, governance model, and project operations remain unchanged. This is a branding update only.



I use the ASF logo on my website or printed materials. How will this impact me?Starting September 11, 2025, any public use of ASF logos must follow the new brand guidelines. Please refer to our Brand Guidelines page for the latest logos and usage guidance. For printed materials, be sure to update your copies in line with the ASF Trademark Policy.



My ASF project has a logo with Indigenous imagery. What do I need to do?If your project logo includes Indigenous motifs or symbolism, including the previous feather symbol, ASF Marketing & Publicity can assist in updating your visual identity. We are offering design support to ensure all project branding aligns with ASFâ€™s community values. If your project has not been contacted yet, please reach out to markpub@apache.org.




	
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How Palantir is mapping the nationâ€™s data]]></title>
            <link>https://theconversation.com/when-the-government-can-see-everything-how-one-company-palantir-is-mapping-the-nations-data-263178</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45215984</guid>
            <description><![CDATA[Government agencies are contracting with Palantir to correlate disparate pieces of data, promising efficiency but raising civil liberties concerns.]]></description>
            <content:encoded><![CDATA[
    When the U.S. government signs contracts with private technology companies, the fine print rarely reaches the public. Palantir Technologies, however, has attracted more and more attention over the past decade because of the size and scope of its contracts with the government. 

Palantirâ€™s two main platforms are Foundry and Gotham. Each does different things. Foundry is used by corporations in the private sector to help with global operations. Gotham is marketed as an â€œoperating system for global decision makingâ€ and is primarily used by governments.

I am a researcher who studies the intersection of data governance, digital technologies and the U.S. federal government. Iâ€™m observing how the government is increasingly pulling together data from various sources, and the political and social consequences of combining those data sources. Palantirâ€™s work with the federal government using the Gotham platform is amplifying this process.

Gotham is an investigative platform built for police, national security agencies, public health departments and other state clients. Its purpose is deceptively simple: take whatever data an agency already has, break it down into its smallest components and then connect the dots. Gotham is not simply a database. It takes fragmented data, scattered across various agencies and stored in different formats, and transforms it into a unified, searchable web.

The stakes are high with Palantirâ€™s Gotham platform. The software enables law enforcement and government analysts to connect vast, disparate datasets, build intelligence profiles and search for individuals based on characteristics as granular as a tattoo or an immigration status. It transforms historically static records â€“ think department of motor vehicles files, police reports and subpoenaed social media data like location history and private messages â€“ into a fluid web of intelligence and surveillance.

These departments and agencies use Palantirâ€™s platform to assemble detailed profiles of individuals, mapping their social networks, tracking their movements, identifying their physical characteristics and reviewing their criminal history. This can involve mapping a suspected gang memberâ€™s network using arrest logs and license plate reader data, or flagging individuals in a specific region with a particular immigration status.

The efficiency the platform enables is undeniable. For investigators, what once required weeks of cross-checking siloed systems can now be done in hours or less. But by scaling up the governmentâ€™s investigative capacity, Gotham also alters the relationship between the state and the people it governs.


            
            
              The U.S. Department of Homeland Security uses Palantirâ€™s technology to support its investigations.
              AP Photo/Jose Luis Magana
            
          

Shifting the balance of power

The political ramifications of Palantirâ€™s rise come into focus when you consider its influence and reach across the government. U.S. Immigration and Customs Enforcement alone has spent more than US$200 million on Palantir contracts, relying on the software to run its Investigative Case Management system and to integrate travel histories, visa records, biometric data and social media data. 

The Department of Defense has awarded Palantir billion-dollar contracts to support battlefield intelligence and AI-driven analysis. Even domestic agencies like the Centers for Disease Control and Prevention and the Internal Revenue Service, and local police departments like the New York Police Department, have contracted with Palantir for data integration projects.

These integrations mean that Palantir is not just a vendor of software; it is becoming a partner in how the federal government organizes and acts on information. That creates a kind of dependency. The same private company helps define how investigations are conducted, how targets are prioritized, how algorithms work and how decisions are justified.

Because Gotham is proprietary, the public, and even elected officials, cannot see how its algorithms weigh certain data points or why they highlight certain connections. Yet, the conclusions it generates can have life-altering consequences: inclusion on a deportation list or identification as a security risk. The opacity makes democratic oversight difficult, and the systemâ€™s broad scope and wide deployment means that mistakes or biases can scale up rapidly to affect many people.

Beyond law enforcement

Supporters of Palantirâ€™s work argue that it modernizes outdated government IT systems, bringing them closer to the kind of integrated analytics that are routine in the private sector. However, the political and social stakes are different in public governance. Centralized, attribute-based searching, whether by location, immigration status, tattoos or affiliations, creates the capacity for mass profiling.

In the wrong hands, or even in well-intentioned hands under shifting political conditions, this kind of system could normalize surveillance of entire communities. And the criteria that trigger scrutiny today could be expanded tomorrow.

U.S. history provides warning examples: The mass surveillance of Muslim communities after 9/11, the targeting of civil rights activists in the 1960s and the monitoring of anti-war protesters during the Vietnam era are just a few. 

Gothamâ€™s capabilities may enable government agencies to carry out similar operations on a much larger scale and at a faster pace. And once some form of data integration infrastructure exists, its uses tend to expand, often into areas far from its original mandate. 

A broader shift in governance

The deeper story here isnâ€™t just that the government is collecting more data. Itâ€™s that the structure of governance is changing into a model where decision-making is increasingly influenced by what integrated data platforms reveal. In a pre-Gotham era, putting someone under suspicion of wrongdoing might have required specific evidence linked to an event or witness account. In a Gotham-enabled system, suspicion can stem from patterns in the data â€“ patterns whose importance is defined by proprietary algorithms. 

This level of data integration means that government officials can use potential future risks to justify present action. The predictive turn in governance aligns with a broader shift toward what some scholars call â€œpreemptive security.â€ It is a logic that can erode traditional legal safeguards that require proof before punishment.


            
            This short documentary about Palantir includes a former employee expressing concern about how algorithms are transforming government.
          

The stakes for democracy

The partnership between Palantir and the federal government raises fundamental questions about accountability in a data-driven state. Who decides how these tools are used? Who can challenge a decision that was made by software, especially if that software is proprietary? 

Without clear rules and independent oversight, there is a risk that Palantirâ€™s technology becomes normalized as a default mode of governance. They could be used not only to track suspected criminals or terrorists but also to manage migration flows, monitor and suppress protests, and enforce public health measures. The concern is not that these data integration capabilities exist, but that government agencies could use them in ways that undermine civil liberties without public consent.

Once put in use, such systems are hard to dismantle. They create new expectations for speed and efficiency in law enforcement, making it politically costly to revert to slower, more manual processes. That inertia can lock in not only the technology but also the expanded scope of surveillance it enables.

Choosing the future

As Palantir deepens its government partnerships, the issues its technology raises go beyond questions of cost or efficiency. There are civil liberties implications and the potential for abuse. Will strong legal safeguards and transparent oversight constrain these tools for integrated data analysis? The answer is likely to depend on political will as much as technical design.

Ultimately, Palantirâ€™s Gotham is more than just software. It represents how modern governance might function: through data, connections, continuous monitoring and control. The decisions made about its use today are likely to shape the balance between security and freedom for decades to come.
  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nano Banana image examples]]></title>
            <link>https://github.com/PicoTrex/Awesome-Nano-Banana-images/blob/main/README_en.md</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45215869</guid>
            <description><![CDATA[A curated collection of fun and creative examples generated with Nano BananaðŸŒ, Gemini-2.5-flash-image based model. This repository showcases diverse AI-generated visuals and prompts, highlighting t...]]></description>
            <content:encoded><![CDATA[
          
            
                
      

      
        
            

                  
                      
  
      
      
        
          GitHub Copilot

        

        Write better code with AI
      

    


                      
  
      
      
        
          GitHub Spark

            
              New
            
        

        Build and deploy intelligent apps
      

    


                      
  
      
      
        
          GitHub Models

            
              New
            
        

        Manage and compare prompts
      

    


                      
  
      
      
        
          GitHub Advanced Security

        

        Find and fix vulnerabilities
      

    


                      
  
      
      
        
          Actions

        

        Automate any workflow
      

    


                  
                
            

                  
                      
  
      
      
        
          Codespaces

        

        Instant dev environments
      

    


                      
  
      
      
        
          Issues

        

        Plan and track work
      

    


                      
  
      
      
        
          Code Review

        

        Manage code changes
      

    


                      
  
      
      
        
          Discussions

        

        Collaborate outside of code
      

    


                      
  
      
      
        
          Code Search

        

        Find more, search less
      

    


                  
                
            
        

          
            
              View all features
              
          
      



                
      

      



                
      

      

                      Explore
                      
  
      Learning Pathways

    


                      
  
      Events & Webinars

    


                      
  
      Ebooks & Whitepapers

    


                      
  
      Customer Stories

    


                      
  
      Partners

    


                      
  
      Executive Insights

    


                  
                



                
      

      
                

                  
                      
  
      
      
        
          GitHub Sponsors

        

        Fund open source developers
      

    


                  
                
                

                  
                      
  
      
      
        
          The ReadME Project

        

        GitHub community articles
      

    


                  
                
                
            



                
      

      

                  
                      
  
      
      
        
          Enterprise platform

        

        AI-powered developer platform
      

    


                  
                



                
    Pricing


            
          

        
                



  
  
  
    

  
    
    
      
        Provide feedback
      
        
    
    
  
      
        
      
      


    
    

  
    
    
      
        Saved searches
      
        Use saved searches to filter your results more quickly
    
    
  
      
        
      
      

    
  



            

              
                Sign up
              
    
      Appearance settings

      
    
  

          
      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Launch HN: Ghostship (YC S25) â€“ AI agents that find bugs in your web app]]></title>
            <link>https://news.ycombinator.com/item?id=45215032</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45215032</guid>
            <description><![CDATA[Hi HN, we're Jesse and Gautham. We're building Ghostship (https://tryghostship.dev/).]]></description>
            <content:encoded><![CDATA[Hi HN, we're Jesse and Gautham. We're building Ghostship (https://tryghostship.dev/).Ghostship lets you find bugs in your web app by entering in your URL and describing a user journey.Here's a video of Ghostship in action: https://www.loom.com/share/dec264ae32f94d50adb141c9246837c3?....For over half our lives, we've been developers and we've done tons of user-facing projects like a coding competition I built called CerealCodes or freelancing projects on Upwork. The biggest problem we faced was that we shipped bugs in edge cases we didn't test, and the process of testing was annoying to do everytime we shipped a new feature. We tried automated testing tools, but those were flaky and couldn't adapt to feature changes. They also were really annoying to set up.Our solution is to use browser agents to help you find bugs in your web app by clicking through your product like users would. You'd enter in your URL, describe what a user would do, and Ghostship would go through and try finding bugs by going through the user journey and extrapolating edge cases by visually seeing where else to click as it goes through each step in the user journey. We then show session replays of our agents going through your web app and list out all the steps it took.We're able to find edge cases with almost no prompting. All you need to do is enter in one URL and one user journey (if you have login credentials on your web app, enter in some test credentials).One bug we were able to find with Ghostship was on the YC application page. Apparently you could add your education dates in reverse chronological order (April 2022 to January 2021, which makes no sense).Another bug we were able to find was a crypto smart contract CRM dashboard we vibe coded where we found a bug involving data corruption when you tried editing a draft contract multiple times.You can sign up here: https://playground.tryghostship.dev/ for a limited number of credits. We'd love to hear from the HN community, whether you're building a web app for fun or a developer shipping a cool user-facing product to customers. We'd love to see what bugs we can find in your web app with Ghostship!p.s. If you want Ghostship directly in your CI/CD pipeline and run after every PR, book a demo with us.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rails on SQLite: new ways to cause outages]]></title>
            <link>https://andre.arko.net/2025/09/11/rails-on-sqlite-exciting-new-ways-to-cause-outages/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214933</guid>
            <description><![CDATA[This post was originally given as a talk for Friendly.rb. The slides are also available.
Between Litestack and the Rails 8 trifecta of Solid Cable, Solid Cache, and Solid Queue, itâ€™s easier than ever to spin up a Rails app that doesnâ€™t need a database service, or a redis service, or a file storage service. Itâ€™s great to simplify things, but even after 20 years of deploying Rails apps I was still caught out by some of the ways things are different.]]></description>
            <content:encoded><![CDATA[11 Sep 2025This post was originally given as a talk for Friendly.rb. The slides are also available.Between Litestack and the Rails 8 trifecta of Solid Cable, Solid Cache, and Solid Queue, itâ€™s easier than ever to spin up a Rails app that doesnâ€™t need a database service, or a redis service, or a file storage service. Itâ€™s great to simplify things, but even after 20 years of deploying Rails apps I was still caught out by some of the ways things are different.Based on what happened when I built a new side project in Rails on SQLite, weâ€™ll cover whatâ€™s different, whatâ€™s new, and several ways that you can knock your site offline or even destroy your entire production database. As we go, weâ€™ll also talk about the advantages of using SQLite, and how those differences can help you.So who am I, how did I learn these things, and why should you listen to me? Iâ€™m AndrÃ© Arko, better known on the internet as @indirect. A long time ago, I helped create Bundler, and Iâ€™ve been the OSS team lead for RubyGems and Bundler for more than a decade at this point.I work at Spinel Cooperative, a collective of Ruby open source maintainers building rv, the Ruby language manager that can install Ruby in one second flat. We offer retainers for unlimited access to core team experts from Bundler, Rails, Hotwire, and more, who can answer your questions and solve your problems.Iâ€™ve been deploying Rails applications to production since 2004, and most relevantly for this particular talk, I built a service called feedyour.email. Feed Your Email turns email subscriptions into RSS feeds that you can subscribe to in your feed reader. There is no signup, there are no accounts, you just go to the website and push a button to get an email address and a feed URL. Emails sent to that address will show up in that feed.Feed Your Email is only possible as a service because of SQLiteâ€”if I had to maintain three Postgres instances and a couple of web instances and a couple of worker instances, I would have felt like it was too much hassle and cost too much money, and given up. SQLite reduced the complexity of building and deploying this service to the point where I was able to do it casually, for fun, and keep it running for everyone while feeling like it was worth it just for my own personal use.This app serves about a million requests per month. That number sounds kind of big, but letâ€™s do the math: 24 requests per minute, or one every 2.6 seconds. We can definitely serve at least one request every 2.6 seconds off of our Rails app, even on a small digital ocean droplet or a small cloud VM. I run my service on Fly.io, and hosting costs about USD$14 per month.It has bonus features like a web view so you can share individual emails as a link without giving away your secret email address or letting anyone see the other emails in that feed, and it also has full-text search if youâ€™re trying to find a particular email. That full-text search is a feature of SQLite, which brings us back to the topic of this talk. How did SQLite help? Letâ€™s take a look.The biggest fundamental difference, where almost every other difference comes from, is that SQLite is built in to your web server process. The reason for the â€œliteâ€ in the name is that it doesnâ€™t run a separate process, it doesnâ€™t listen on a port or a socket, and you canâ€™t connect to it. All the data is just in a single file, and your web process reads and writes that file when needed. This is awesome: you canâ€™t have database connection errors anymore.Thereâ€™s a small issue with giving the web process its own database in a local file, though. If you deploy your app as usual, your production database can disappear at any time! Heroku destroys dynos every 24 hours, including all files. Fly.io loses the files in a container anytime they restart. In a world of containers, itâ€™s incredibly easy to miss that your new SQLite database is on an ephemeral filesystem and will disappear along with the Puma process in your web container.That leads us to the first and most important rule of using SQLite: put your database files in persistent storage. On AWS that means EBS, on Fly.io that means Volumes, but wherever youâ€™re hosting, make sure that you can keep your database files across restarts (and ideally have automatic snapshots).Now that your database wonâ€™t disappear at any moment, letâ€™s talk about what it means to put all the data in a single file. You probably use Rails.cache to store temporary dataâ€”thatâ€™s in a single SQLite file now, too. You also probably use ActiveJob to send emails or do slower work in the background. All of those jobs are also in a single SQLite file now. By default, itâ€™s the same file!Putting everything in the same SQLite file makes everything very easy. You just need to keep track of that one file, and youâ€™ll know that your model data, your caches, and your jobs will all be safe.SQLite being in-process raises a new problem, thoughâ€¦ what if your background job needs to update a model? You might be used to deploying your background workers in a separate container, so you can scale them as needed. Thatâ€™s not going to fly anymore, because your background workers need to be able to read and write that same single file that your web server is reading and writing.Since your database is now in just one file, you have two options. You can run your workers in a second process inside the same VM or container as the web process, or you can run your workers in threads inside the web process.If this is a smallish application, doing a million requests per month or less, youâ€™ll be absolutely fine putting your background jobs in threads. As a bonus, putting background jobs in threads can almost halve the amount of RAM you need because a single Rails process is handling both web and job requests.If you really want to scale up your application, though, youâ€™ll need to do what gets called â€œverticalâ€ scaling rather than the traditional â€œhorizontalâ€ scaling. You canâ€™t add more VMs, because other VMs wonâ€™t be able to see your database file. Instead, you need bigger and bigger single servers, with more and more CPU cores and RAM. Thatâ€™s definitely possible, though. There are servers nowadays with 128 cores, or even more, and terabytes of RAM. Unfortunately, once you have scaled your wildly popular application vertically to the moon, youâ€™ll discover the biggest limitation of SQLite: itâ€™s just one file on disk.If you have dozens processes and hundreds of threads in web servers and background job workers, all trying to write into this one database file at the same time, thereâ€™s probably going to be a lot of contention. By default, SQLite uses the filesystem to take out a lock on the entire database for each transaction. Holding the lock, it executes any read and write queries, commits, and then releases the lock. Then the next process can take the filesystem lock and do the same thing.This can create quite the queue if even read-only queries have to wait in line and happen one at a time (because if they didnâ€™t have the lock, some writer might sneak in and change the data mid-read!). To (partially) address this problem, SQLite offers a middle ground in the form of a Write-Ahead Log. The WAL log is an append-only file where any database writes can be written, one at a time. Then, a SQLite-controlled process copies those write instructions into the actual database file between reads. In the meantime, there can be as many readers as you want, because writes donâ€™t have to block reads, and many reads from the same file at once are quite safe.This solves the problem with only allowing one single read or write at a time, but it definitely has a cost. The database isnâ€™t just one file anymore, itâ€™s now a series of files, and you need to back them up and restore them together if you want to make sure you havenâ€™t lost any data. Hopefully thatâ€™s not too much trouble, but it is definitely something to be aware of while planning your backup and disaster recovery strategy.Thereâ€™s one other approach worth calling out at this point, and that strategy is deliberately using multiple SQLite database files. If you are putting your not just your model data, but also your Rails cache, and also your background jobs, and maybe also your uploaded files all together into a single SQLite database file, your different use-cases can start to step on one anotherâ€™s toes. For example, if you go to queue a few thousand jobs, any writes from your web requests will end up in the writer queue behind that pile of jobs in line to be written.Creating a separate SQLite file per system, or per access pattern, can help a lot with this. In Rails, the most common splits are separate SQLite databases for ActiveRecord, for the Rails cache, for background jobs, and for ActionCable. Depending on your application, it might also make sense to put your ActiveStorage blobs into a SQLite database or into the same filesystem that you are already backing up, as well. Thereâ€™s a lot of complexity and overhead involved in setting up S3 buckets with the correct permissions and getting files into and out of them, and you might just want to skip all of that in your new, simplified Rails config.Taking this approach to an extreme might even involve sharding your model data across many database files. The most extreme example of this that Iâ€™ve heard of was an application that chose to shard their model data across one SQLite database file per customer. That meant every new signup created a new SQLite database file on disk, which is in some ways absurd, but it also meant that every individual user had the full power and speed of SQLite available to them. Itâ€™s hard to have read or write contention when every user gets their own separate database!So now that weâ€™ve covered vertically scaling the Rails server itself, letâ€™s talk about the other implications of your application running on exactly one server. The downside to there being just one server is that if that server goes down, your entire app is down. No degraded service, no slower than usual application, justâ€¦ no application at all.If youâ€™re running in a container, itâ€™s impossible to deploy without downtime because only one container can ever have the volume with the database mounted. The old container has to stop before the new container can start. If youâ€™re running in a VM, you might be able to deploy without downtime by running a local reverse proxy and more than one web server process, and restarting those web server processes one at a time rather than all at once. Welcome to how we used to do things in the 2000s, and my apologies.That said, some of the implications of only one server are good: if thereâ€™s only one, itâ€™s pretty easy to run status checks, and itâ€™s pretty easy to troubleshoot. You donâ€™t need to debug connections between load balancers and dozens of web servers and database servers and redis servers and file storage servers, you just need to debug the one server. That can definitely make your job easier!Another implication of having just one single server: there is only one place for network requests to go. As I alluded to a moment ago, the only kind of load balancing that you can do is by running a local proxy and adding multiple separate processes as backends. The server itself is only going to have one IP address and one port where it can be reached, and thereâ€™s a certain amount of scale where that one IP and one port is going to become limiting. The good news is that you probably wonâ€™t hit that scale, and if you do, youâ€™ll probably want to stop using SQLite anyway.If you ever want to try switching towards or away from SQLite, the sequel gem has the amazing ability to read from one database and write into another, doing a full database copy while respecting all the quirks and limitations of each database. If you want to move from Mysql or Postgres over to SQLite, or if you ever want to load a SQLite database into Mysql or Postgres, I highly recommend it. The duckdb command line tool also has excellent cross-database capabilities, and is the next thing I would try if sequel wasnâ€™t working for me for some reason.Thereâ€™s one more limitation that we need to consider that falls out of there only being one server: your app can only run in one geographic location. Some applications can benefit from adding additional web processes (or even database read replicas) spread out closer to end users, and thatâ€™s not possible if you are limited to a maximum of one server total for your entire application.That said, thereâ€™s nothing stopping you from using the more usual kind of CDN-based global distribution. If your application has a decent amount of static or cacheable content, you can at least still set the cache-control headers and run the app behind Fastly or Cloudlfare.Before we wrap up, I want to make sure to cover the various backup and replication options available to you while using SQLite for your application. The absolute all-star of SQLite backup and replication is called Litestream. Itâ€™s available as a gem, and can be used as easily as setting a few environment variables and using the litestream command provided by the gem to wrap your puma or other web server.What litestream does is fairly simple: it forwards a copy of each entry added to the write-ahead log over to any S3-compatible file store â€” you might even say that it streams your data in a light way. If you ever have a catastrophe, and your database file gets deleted or corrupted, the bucket will have a full copy of the WAL that you can replay to restore your database back to where it was when the server stopped working.On AWS, this still means setting up an S3 bucket and setting the right env vars, but at least you donâ€™t need to deal with the bucket having public access, or setting up signed uploads, or any of the other things that make S3 a huge pain. You just need a private bucket and read/write credentials, and youâ€™re good to go. If youâ€™re using fly.io, you donâ€™t even have to set the env vars yourself! They are set automatically by the command that creates the S3-compatible bucket on Tigris.Thereâ€™s one last thing that you can try using if youâ€™re feeling especially adventurous, LiteFS. LiteFS is a fascinating software achievement, offering full Mysql or Postgres-style replication for multiple SQLite databases running in many locations. The completely deranged trick that they use to do this is creating an entire software filesystem using FUSE, and then putting the SQLite database inside that filesystem. This gives them access to every filesystem read and write call made by your application, and allows them to create their own operations that are then sent to every other member of the cluster to be applied.This kind of setup comes with a lot of caveats. The biggest one is the usual distributed systems kind of caveat. Youâ€™ll have stale reads where some users will see old data, and if the primary crashes you might lose some data. If youâ€™re okay with the tradeoffs of a distributed system (and youâ€™re okay with the idea of all of your database reads and writes going through a FUSE filesystem that might be adding extra bugs), LiteFS offers a version of the ultimate web application dream.In the dream SQLite plus LiteFS world, you have all the advantages of SQLite and all the advantages of a fully replicated multi-writer database setup. Any individual server can go down without causing any downtime for the application as a whole, and every user has a full copy of the application and all its data, running extremely close to them.I havenâ€™t built that perfect system yet, but it feels more attainable than it ever has before thanks to SQLite.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude's memory architecture is the opposite of ChatGPT's]]></title>
            <link>https://www.shloked.com/writing/claude-memory</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214908</guid>
            <description><![CDATA[A breakdown of Claude's memory implementation, how it differs from ChatGPT, and what these opposite approaches reveal about each company's philosophy.]]></description>
            <content:encoded><![CDATA[Earlier this week, I dissected ChatGPT's memory system. Since then, I've been doing the same for Claude and realized something remarkable: these two leading AI assistants have built completely opposite memory systems.
In this post, I'll start by breaking down exactly how Claude's memory worksâ€”what it stores and how it retrieves information. Then we'll get to the interesting stuff. Why these architectures diverge so dramatically, what that tells us about who uses each assistant and the philosophies driving each product's development, and just how vast the AI memory design space really is.
How it works
Claude's memory system has two fundamental characteristics. First, it starts every conversation with a blank slate, without any preloaded user profiles or conversation history. Memory only activates when you explicitly invoke it. Second, Claude recalls by only referring to your raw conversation history. There are no AI-generated summaries or compressed profilesâ€”just real-time searches through your actual past chats.
When Claude detects memory invocation through phrases like "what did we discuss about," "continue where we left off," or "remember when we talked about," it deploys two retrieval tools that work like web search or code executionâ€”you see them activate in real-time and wait while Claude searches through your history. Once the search completes, Claude synthesizes the retrieved conversations to answer your question or continue the discussion.
Conversation Search
The conversation_search tool helps with keyword and topic-based searches across your entire conversation history. When I asked "Hey, can you recall our past conversations about Chandni Chowk?" (a historic neighborhood in Delhi), Claude found 9 relevant conversationsâ€”from when I explored its founding by Princess Jahanara Begum in 1650 to my queries about the best galouti kebabs at Karim's and stuffed parathas at Paranthe Wali Gali. Claude synthesized these scattered discussions into a coherent summary of my Chandni Chowk explorations.

When you ask about multiple topics, Claude runs separate searches sequentially. In my past job as a crypto researcher, I used Claude extensively as an editor. When I asked "Tell me all the conversations we've had about either Michelangelo or Chainflip or Solana," Claude ran three separate searchesâ€”one for my Michelangelo analogies for neural networks, another for Chainflip's cross-chain protocol work, and a third for Solana's technical architecture. It found 22 conversations across these searches and delivered a unified response with direct links to each chat.


Temporal Chat Retrieval
The recent_chats tool provides time-based access to your conversation history. When I asked "Can you tell me what we spoke about in the last 10 conversations?" Claude retrieved my most recent chats chronologically and gave me a summary of my recent usage.

The tool also handles specific timeframes. When I asked "What did we discuss in the last week of November 2024?" Claude retrieved 16 conversations from that exact period.


ChatGPT vs Claude
A year ago, ChatGPT and Claude's assistant apps matched each other feature for featureâ€”multiple models, file attachments, projects. Since then, their paths have diverged dramatically. ChatGPT has evolved into a mass-market consumer product, while Claude has deliberately chosen a different trajectory. Anthropic CPO Mike Krieger has acknowledged that OpenAI had "caught lightning in a bottle" with consumer adoption. Instead of chasing that market, Anthropic is focusing on what Claude does best: developer tools, coding, and professional workflows.
Memory implementation perfectly reflects this divergence.
ChatGPT's hundreds of millions of weekly active users come from all backgroundsâ€”students, parents, hobbyistsâ€”who just want a product that works and remembers them without thinking about the mechanics. Every memory component loads automatically, creating instant personalization with zero wait time. The system builds detailed user profiles, learning preferences and patterns that could eventually power targeted features or monetization. It's the classic consumer tech playbook: make it magical, make it sticky, figure out different ways to monetize later.
Claude's users represent a different demographic entirely. Anthropic's more technical users inherently understand how LLMs work. They're comfortable with explicit control at every level. Just as they choose when to trigger web search or enable extended thinking, they decide when memory is worth invoking. They understand that memory calls add latency, but they make that tradeoff deliberately. Memory becomes just another tool in their arsenal, not an always-on feature. This audience doesn't need or want extensive profilingâ€”they need a powerful, predictable tool for professional work. Not to mention, they're also more privacy-conscious.
The Memory Design Space
It still amazes me that ChatGPT and Claudeâ€”the two top AI assistantsâ€”have built completely opposite memory systems. This only goes to show that memory in AI has a massive design space with no right answer or one-size-fits-all technique. You have to work backwards from who your users are and what they need, then build from first principles accordingly.
We're in uncharted territory. These tools are less than three years old, and nobody knows what happens when someone uses the same AI assistant for a decade. How much should it remember? How should it handle years of accumulated context? Meanwhile, we're seeing a Cambrian explosion of AI apps, each experimenting with their own memory approach, while the underlying models get more powerful every week. There's no playbook, no settled best practicesâ€”just everyone trying different things and seeing what sticks.
The more I dive into memory, the more fascinated I get. Over the coming weeks, I'll be dissecting different architectures, analyzing new approaches, and following the latest research. Subscribe below if you want updates as this space unfolds.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Making io_uring pervasive in QEMU [pdf]]]></title>
            <link>https://vmsplice.net/~stefan/stefanha-kvm-forum-2025.pdf</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214672</guid>
        </item>
        <item>
            <title><![CDATA[Top model scores may be skewed by Git history leaks in SWE-bench]]></title>
            <link>https://github.com/SWE-bench/SWE-bench/issues/465</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214670</guid>
            <description><![CDATA[We've identified multiple loopholes with SWE Bench Verified where agents may look at future repository state (by querying it directly or through a variety of methods), and cases in which future rep...]]></description>
            <content:encoded><![CDATA[We've identified multiple loopholes with SWE Bench Verified where agents may look at future repository state (by querying it directly or through a variety of methods), and cases in which future repository state includes either solutions or detailed approaches to solving problems (commit messages and more).
Examples:
A trajectory with Claude 4 Sonnet, Pytest-dev__pytest-6202 (complete output here), the agent uses git log --all which leaks future commits that directly fix the issue:

<antml:parameter name="command">cd /testbed && git log --oneline --all | grep -i "bracket|parametrize|modpath" | head -10</antml:parameter>

The results of which directly reveal the fix:
    Fix incorrect result of getmodpath method.
diff --git a/src/_pytest/python.py b/src/_pytest/python.py
index b8b365ad3..734a92f9b 100644
--- a/src/_pytest/python.py
+++ b/src/_pytest/python.py
@@ -285,8 +285,7 @@ class PyobjMixin(PyobjContext):
                     break
             parts.append(name)
         parts.reverse()
-        s = ".".join(parts)
-        return s.replace(".[", "[")
+        return ".".join(parts)

Qwen3-Coder 480B (20250805-openhands-Qwen3-Coder-480B-A35B-Instruct) also has several cases of looking ahead: some examples include django__django-13513 (complete output here) uses git log grep=[issue ID] which directly reveals the fix PR which is in the future repo state (future commits).

Running command: cd /workspace/django__django__3.2 && ï¿½[1mï¿½[91mgit logï¿½[0m --oneline --grep="31926" -i

In another Qwen3-Coder trajectory, Django__django-15572, (complete output here) where the model specifically finds the commit containing the fix: 62739b6e2630e37faa68a86a59fad135cc788cd7

Command cd /workspace/django__django__4.1 && ï¿½[1mï¿½[91mgit logï¿½[0m --oneline --grep="33628" ï¿½[92m--allï¿½[0m executed with exit code 0.

There are other examples of leakage found in trajectories from GLM 4.5, Qwen3-Coder 30B (20250805-openhands-Qwen3-Coder-30B-A3B-Instruct), and other models.
Mitigation will be to properly remove future repository state and any artifacts that contain information the agent could use (reflogs, branches, origins, tags, and more):

remove origins (branch names can reveal information about fixes)
remove all branches git log --all can be used to query them, plus branches that are tracking a remote origin might contain information about future commits even after a git reset --hard
remove the reflog (git reflog) can leak future commit messages that could detail approaches for solutions

The team (@felixkreuk, @UniverseFly, @jlko, @2dot71mily and others) will add more details as to findings here and below. We're still assessing broader impact on evaluations and understanding trajectories for sources of leakage.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Adam (YC W25) Is Hiring to Build the Future of CAD]]></title>
            <link>https://www.ycombinator.com/companies/adam/jobs/q6td4uk-founding-engineer</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214498</guid>
            <description><![CDATA[Weâ€™re building the founding engineering team at Adam.
At Adam, weâ€™re tackling a frontier problem: building a new way to interface with CAD via AI. This demands creativity, deep technical ability, and novel thinking.
As part of the founding engineering team you may:
Sprint for two weeks to build a new product vertical from scratchÂ 
Develop new interfaces for AI-driven CAD workflows
Design, implement, test, and deploy full featuresÂ 
Work with our product team to ensure a fast, consistent, and beautiful experience across the application
We are looking for people who:
Blend excellent engineering with a taste for models and design
Have previously built a great product
Operate with high agency and own problems end-to-end
At Adam, you will be given the autonomy to do some of the best work of your life and redefine how the physical world is built.]]></description>
            <content:encoded><![CDATA[AI Powered CADFounding Engineer$160K - $250Kâ€¢1.00% - 2.00%â€¢San Francisco, CA, USJob typeFull-timeRoleEngineering, Full stackExperience1+ yearsVisaUS citizen/visa onlySkillsNext.js, JavaScript, React, TypeScript, Python, SQL, Software ArchitectureConnect directly with founders of the best YC-fundedÂ startups.Apply to role â€ºAbout the roleWeâ€™re building the founding engineering team at Adam.
At Adam, weâ€™re tackling a frontier problem: building a new way to interface with CAD via AI. This demands creativity, deep technical ability, and novel thinking.
As part of the founding engineering team you may:

Sprint for two weeks to build a new product vertical from scratch
Develop new interfaces for AI-driven CAD workflows
Design, implement, test, and deploy full features
Work with our product team to ensure a fast, consistent, and beautiful experience across the application

We are looking for people who:

Blend excellent engineering with a taste for models and design
Have previously built a great product
Operate with high agency and own problems end-to-end

At Adam, you will be given the autonomy to do some of the best work of your life and redefine how the physical world is built.
About the interview
Coding challenge
Talk to Zach (CEO)
Talk to Dylan (Founding Engineer)
Onsite paid work trial

About AdamAdam is an applied research and product lab building the future of computer-aided design, where engineers will be able to speak physical objects into existence. With Adam, youâ€™ll use AI to complete design tasks end-to-end. For example, select a face and say, â€œAdd mounting holes matching the bolt pattern from the other part, with identical diameters, spacing, and offsets,â€ and Adam handles the geometry, selects standard hardware, and outputs production-ready CAD.
We just wrapped up YCâ€™s W25 batch, built a state-of-the-art text-to-CAD interface, and had one of the most viral YC launches of all time.
Our first product made CAD approachable and fun with AI, bringing tens of thousands of people into 3D printing. Now weâ€™re enhancing the capabilities of engineers to create feature-rich models compatible with industry-standard software.
Weâ€™re a small technical team of engineers, designers, and researchers who love CAD and building things. Our founders are UC Berkeley alumni, second-time founders, and early employees at major AI startups.
We're in-person at the Adam House in the SF Marina, powered by green tea, lots of natural light, and a wall of 3D printers.
If youâ€™re excited about shipping fast and shaping the future of how things are made, come join us.
Founded:2024Batch:W25Team Size:4Status:ActiveFoundersSimilar Jobs]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Bulletproof host Stark Industries evades EU sanctions]]></title>
            <link>https://krebsonsecurity.com/2025/09/bulletproof-host-stark-industries-evades-eu-sanctions/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214164</guid>
            <description><![CDATA[In May 2025, the European Union levied financial sanctions on the owners ofÂ Stark Industries Solutions Ltd., a bulletproof hosting provider that materialized two weeks before Russia invaded Ukraine and quickly became a top source of Kremlin-linked cyberattacks and disinformation campaigns.â€¦]]></description>
            <content:encoded><![CDATA[
												In May 2025, the European Union levied financial sanctions on the owners ofÂ Stark Industries Solutions Ltd., a bulletproof hosting provider that materialized two weeks before Russia invaded Ukraine and quickly became a top source of Kremlin-linked cyberattacks and disinformation campaigns. But new findings show those sanctions have done little to stop Stark from simply rebranding and transferring their assets to other corporate entities controlled by its original hosting providers.
Image: Shutterstock.
Materializing just two weeks before Russia invaded Ukraine in 2022, Stark Industries Solutions became a frequent source of massive DDoS attacks, Russian-language proxy and VPN services, malware tied to Russia-backed hacking groups, and fake news. ISPs like Stark are called â€œbulletproofâ€ providers when they cultivate a reputation for ignoring any abuse complaints or police inquiries about activity on their networks.
In May 2025, the European Union sanctioned one of Starkâ€™s two main conduits to the larger Internet â€” Moldova-based PQ Hosting â€” as well as the companyâ€™s Moldovan owners Yuri and Ivan Neculiti. The EU Commission said the Neculiti brothers and PQ Hosting were linked to Russiaâ€™s hybrid warfare efforts.
But a new report from Recorded Future finds that just prior to the sanctions being announced, Stark rebranded toÂ the[.]hosting, under control of the Dutch entity WorkTitans BVÂ (AS209847) on June 24, 2025. The Neculiti brothers reportedly got a heads up roughly 12 days before the sanctions were announced, when Moldovan and EU media reported on the forthcoming inclusion of the Neculiti brothers in the sanctions package.
In response, the Neculiti brothers moved much of Starkâ€™s considerable address space and other resources over to a new company in Moldova called PQ Hosting Plus S.R.L., an entity reportedly connected to the Neculiti brothers thanks to the re-use of a phone number from the original PQ Hosting.
â€œAlthough the majority of associated infrastructure remains attributable to Stark Industries, these changes likely reflect an attempt to obfuscate ownership and sustain hosting services under new legal and network entities,â€ Recorded Future observed.
Neither the Recorded Future report nor the May 2025 sanctions from the EU mentioned a second critical pillar of Starkâ€™s network that KrebsOnSecurity identified in a May 2024 profile on the notorious bulletproof hoster: The Netherlands-based hosting provider MIRhosting.
MIRhosting is operated by 38-year old Andrey Nesterenko, whose personal website says he is an accomplished concert pianist who began performing publicly at a young age. DomainTools says mirhosting[.]com is registered to Mr. Nesterenko and to Innovation IT Solutions Corp, which lists addresses in London and in Nesterenkoâ€™s stated hometown of Nizhny Novgorod, Russia.
Image credit: correctiv.org.
According to the book Inside Cyber Warfare by Jeffrey Carr, Innovation IT Solutions Corp. was responsible for hosting StopGeorgia[.]ru, a hacktivist website for organizing cyberattacks against Georgia that appeared at the same time Russian forces invaded the former Soviet nation in 2008. That conflict was thought to be the first war ever fought in which a notable cyberattack and an actual military engagement happened simultaneously.
Mr. Nesterenko did not respond to requests for comment. In May 2024, Mr. Nesterenko said he couldnâ€™t verify whether StopGeorgia was ever a customer because they didnâ€™t keep records going back that far. But he maintained that Stark Industries Solutions was merely one client of many, and claimed MIRhosting had not received any actionable complaints about abuse on Stark.
However, it appears that MIRhosting is once again the new home of Stark Industries, and that MIRhosting employees are managing both the[.]hosting and WorkTitans â€” the primary beneficiaries of Starkâ€™s assets.
A copy of the incorporation documents for WorkTitans BV obtained from the Dutch Chamber of Commerce shows WorkTitans also does business under the names Misfits Media and and WT Hosting (considering Starkâ€™s historical connection to Russian disinformation websites, â€œMisfits Mediaâ€ is a bit on the nose).
An incorporation document for WorkTitans B.V. from the Netherlands Chamber of Commerce.
The incorporation document says the company was formed in 2019 by a y.zinad@worktitans.nl. That email address corresponds to a LinkedIn account for a Youssef Zinad, who says their personal websites are worktitans[.]nl and custom-solution[.]nl. The profile also links to a website (etripleasims dot nl) that LinkedIn currently blocks as malicious. All of these websites are or were hosted at MIRhosting.
Although Mr. Zinadâ€™s LinkedIn profile does not mention any employment at MIRhosting, virtually all of his LinkedIn posts over the past year have been reposts of advertisements for MIRhostingâ€™s services.
Mr. Zinadâ€™s LinkedIn profile is full of posts for MIRhostingâ€™s services.
A Google search for Youssef Zinad reveals multiple startup-tracking websites that list him as the founder of the[.]hosting, which censys.io finds is hosted by PQ Hosting Plus S.R.L.
The Dutch Chamber of Commerce document says WorkTitansâ€™ sole shareholder is a company in Almere, Netherlands called Fezzy B.V. Who runs Fezzy? The phone number listed in a Google search for Fezzy B.V. â€” 31651079755 â€” also was used to register a Facebook profile for a Youssef Zinad from the same town, according to the breach tracking service Constella Intelligence.
In a series of email exchanges leading up to KrebsOnSecurityâ€™s May 2024 deep dive on Stark, Mr. Nesterenko included Mr. Zinad in the message thread (youssef@mirhosting.com), referring to him as part of the companyâ€™s legal team. The Dutch website stagemarkt[.]nl lists Youssef Zinad as an official contact for MIRhostingâ€™s offices in Almere. Mr. Zinad did not respond to requests for comment.

Given the above, it is difficult to argue with the Recorded Future report on Starkâ€™s rebranding, which concluded that â€œthe EUâ€™s sanctioning of Stark Industries was largely ineffective, as affiliated infrastructure remained operational and services were rapidly re-established under new branding, with no significant or lasting disruption.â€
											]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Web Framework for Zig]]></title>
            <link>https://www.jetzig.dev/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45214159</guid>
            <description><![CDATA[Jetzig is a batteries-included web framework written in Zig]]></description>
            <content:encoded><![CDATA[
        
  
  
    Jetzig is an MIT
    licensed web framework written in Zig
  
  



  
 Routing
    Simple, file-based routing to RESTful
        Zig function declarations. Custom routes are also available.
      
  

  
 HTML
    Templating with Zmpl
        provides layouts, partials, inheritance, and build-time static content rendering.
  

  
 JSON
    All endpoints render JSON by default, providing a RESTful API for free.
  

  
 Speed
    Powered by http.zig
        for competitive performance and scalability.
      
  

  
 Tooling
    User-friendly CLI tooling for creating projects and adding new components.
  

  
 Middleware
    Hook into and manipulate requests/responses with a custom middleware chain. Built-in middleware for htmx
      .
  

  
 Sessions
    Cookies, user sessions, and request/response headers out of the box.
  

  
 Community
    Join us on Discord
      â€“ we're friendly and active.
  

  
 Open Source
    Free, open source, and always will be. Jetzig is MIT
      licensed.
  

  

  
 Database
    
      Powerful and flexible database layer provided by JetQuery
        .
    
  

  


  

  

  

      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA['Robber bees' invade apiarist's shop in attempted honey heist]]></title>
            <link>https://www.cbc.ca/news/canada/british-columbia/robber-bees-terrace-bc-apiary-1.7627532</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45213732</guid>
            <description><![CDATA["Robber bees" hunt for dwindling resources in the late summer and early fall, but they usually only attack other beehives. So the owner of Rushing River Apiaries in Terrace, B.C., was shocked to find found thousands of the pollinators in her shop.]]></description>
            <content:encoded><![CDATA[British Columbia"Robber bees" hunt for dwindling resources in the late summer and early fall, but they usually only attack other beehives. So the owner of Rushing River Apiaries in Terrace, B.C., was shocked to find found thousands of the pollinators in her shop.Bees sometimes attack other colonies as resources dwindle, but they usually stick to beehives found outsideLauren Vanderdeen  Â· CBC News  Â· Posted: Sep 08, 2025 10:30 AM EDT | Last Updated: September 8An apiarist in Terrace, B.C., says she found thousands of 'robber bees' in her store in late August. (Submitted by Christine McDonald)A Terrace, B.C., beekeeper found herself in a nightmare situation late last month whenÂ "thousands and thousands of bees" filled her shop.Call it an attempted robbery â€” the bees were trying to steal sweet, sweet honey.Christine McDonald, owner of Rushing River Apiaries, said it's the first time desperate "robber bees" â€” bees that try to take honey from another colony's hive â€”Â have descended upon her indoor shopÂ to hunt for food as resources get scarce in the late summer.Â While she's worked with bees for years and said she's very comfortable around them, this situation had her frightened."I think that's the most panicked I have felt.â€¦There's thousands of bees, I don't know where they're coming from, and I need to protect all of the honey."Rushing River Apiaries in Terrace, B.C., was briefly set upon by thousands of 'robber bees' trying to find food in the late summer. (Submitted by Christine McDonald)The multitudinous bees had found their way in through cracks in the shop's older bay door.When a bee finds a good food source, it returns to the hive and does a "waggle dance" to tell other bees where the food is, McDonald said.After throwing tarps and lids over the equipment and products, and managing to save most of it, McDonald said she ended up "sacrificing her bathroom" to trap the invading bees: she left the light on, and lured the bees to the light where she could collect and then release them.VideoMillions of honeybees loose after truck overturns near B.C.-Wash. borderHoneybees invaded a reporter's home, and upended everything she thought she knew about themBut it took four or five days until the bees stopped trying to return."I think they've learned that, nope, there's no more food here. We can't get in."Daybreak NorthRobber beesHungry bees swarm Terrace apiaryMcDonald has since taped up the shop's door.She said while she's had robber bees attack her beehives before, it's the first time they found her indoor shop."Fall beekeeping is very intense â€” trying to help bees hunker down against other bees and wasps and keep the food stores that they've worked so hard for."McDonald says she had to tape up her shop door to make sure no other bees get in.  (Submitted by Christine McDonald)So-called robber beesÂ are a fairly common phenomenon in the late summer and early fall.Alison McAfee, a research associate at the University of B.C. and honeybee scientist, said when there's fewer food resources, such as nectar-producing flowers, and the bee population is close to its peak, some forager colonies can invade weaker colonies to steal their food."It's almost like they have a level of desperation, kind of like the way you can think about bears having a bit of a level of desperation trying to fatten up for winter," McAfee said.AudioThe number of beekeepers are on the rise in Canada but honey production levels stingQueen bees from Ukraine find a sweet new home in northwestern B.C.She said wasps can also attack honeybees â€” but for slightly different reasons. Wasps eat a sugary substance secreted from their own larvae earlier in the season, but in the fall, there's fewer larvae and more adult wasps."They're not getting that sweet treat from their babies, essentially, and so they're especially motivated to get something sweet from elsewhere, because the adults actually really like to eat sugary things â€” and there's a lot of sugary stuff inside a honeybee colony."But wasps aren't the only bee-killer out there.McAfee said a bee colony canÂ die from robber bees, if it's too weak to defend itself."We have a bad opinion of wasps," she said. "We're like, 'Oh those wasps, they're attacking our honey bee colonies, they're killing my bees.' But then a lot of the time, actually, the bees will kill our bees as well."McDonald is back to producing honey after a few days of cleanup.Â She said the bees seem more desperate this year than in the past, and thought it might be due to the extended heat as it still feels like midsummer.McDonald encouraged other beekeepers to keep their bees well fed, so they don't feel the need to rob other hives.ABOUT THE AUTHORLauren Vanderdeen is a web writer for CBC British Columbia. She formerly worked for community newspapers, including the Burnaby Now and New West Record. You can reach her at lauren.vanderdeen@cbc.ca.With files from Hanna Petersen]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A tech-law measurement and analysis of event listeners for wiretapping]]></title>
            <link>https://arxiv.org/abs/2508.19825</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45213612</guid>
            <description><![CDATA[The privacy community has a long track record of investigating emerging types of web tracking techniques. Recent work has focused on compliance of web trackers with new privacy laws such as Europe's GDPR and California's CCPA. Despite the growing body of research documenting widespread lack of compliance with new privacy laws, there is a lack of robust enforcement. Different from prior work, we conduct a tech-law analysis to map decades-old U.S. laws about interception of electronic communications--so-called wiretapping--to web tracking. Bridging the tech-law gap for older wiretapping laws is important and timely because, in cases where legal harm to privacy is proven, they can provide statutory private right of action, are at the forefront of recent privacy enforcement, and could ultimately lead to a meaningful change in the web tracking landscape.
  In this paper, we focus on a particularly invasive tracking technique: the use of JavaScript event listeners by third-party trackers for real-time keystroke interception on websites. We use an instrumented web browser to crawl a sample of the top-million websites to investigate the use of event listeners that aligns with the criteria for wiretapping, according to U.S. wiretapping law at the federal level and in California. We find evidence that 38.52% websites installed third-party event listeners to intercept keystrokes, and that at least 3.18% websites transmitted intercepted information to a third-party server, which aligns with the criteria for wiretapping. We further find evidence that the intercepted information such as email addresses typed into form fields are used for unsolicited email marketing. Beyond our work that maps the intersection between technical measurement and U.S. wiretapping law, additional future legal research is required to determine when the wiretapping observed in our paper passes the threshold for illegality.]]></description>
            <content:encoded><![CDATA[
    
    
                
    View PDF
    HTML (experimental)
            Abstract:The privacy community has a long track record of investigating emerging types of web tracking techniques. Recent work has focused on compliance of web trackers with new privacy laws such as Europe's GDPR and California's CCPA. Despite the growing body of research documenting widespread lack of compliance with new privacy laws, there is a lack of robust enforcement. Different from prior work, we conduct a tech-law analysis to map decades-old U.S. laws about interception of electronic communications--so-called wiretapping--to web tracking. Bridging the tech-law gap for older wiretapping laws is important and timely because, in cases where legal harm to privacy is proven, they can provide statutory private right of action, are at the forefront of recent privacy enforcement, and could ultimately lead to a meaningful change in the web tracking landscape.
In this paper, we focus on a particularly invasive tracking technique: the use of JavaScript event listeners by third-party trackers for real-time keystroke interception on websites. We use an instrumented web browser to crawl a sample of the top-million websites to investigate the use of event listeners that aligns with the criteria for wiretapping, according to U.S. wiretapping law at the federal level and in California. We find evidence that 38.52% websites installed third-party event listeners to intercept keystrokes, and that at least 3.18% websites transmitted intercepted information to a third-party server, which aligns with the criteria for wiretapping. We further find evidence that the intercepted information such as email addresses typed into form fields are used for unsolicited email marketing. Beyond our work that maps the intersection between technical measurement and U.S. wiretapping law, additional future legal research is required to determine when the wiretapping observed in our paper passes the threshold for illegality.
    

    
    
      
          Subjects:
          
            Cryptography and Security (cs.CR)
        
          Cite as:
          arXiv:2508.19825 [cs.CR]
        
        
          Â 
          (or 
              arXiv:2508.19825v1 [cs.CR] for this version)
          
        
        
          Â 
                        https://doi.org/10.48550/arXiv.2508.19825
              
                                arXiv-issued DOI via DataCite
            
          
        
    
  
      Submission history From: Shaoor Munir [view email]          [v1]
        Wed, 27 Aug 2025 12:20:52 UTC (467 KB)
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NT OS Kernel Information Disclosure Vulnerability]]></title>
            <link>https://www.crowdfense.com/nt-os-kernel-information-disclosure-vulnerability-cve-2025-53136/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45213299</guid>
            <description><![CDATA[Bidding farewell to one of the last kernel address leaks, CVE-2025-53136. Even patches can open new doors for exploitation.]]></description>
            <content:encoded><![CDATA[

	
			


		
																			
								
	
			11SepSeptember 11, 2025		
	
	
			Reading Time:   4 minutes

Table of Contents

IntroductionVulnerabilityQuick review on the patch for CVE-2024-43511Spotting the bugEffects of the bugExploitationSetupReliabilityProof-of-conceptsConclusionDisclosure Timeline
Introduction
Microsoft mitigated many traditional kernel information leaks starting with Windows 11/Windows Server 2022 24H2, including calls such asÂ NtQuerySystemInformation()Â (when used with theÂ SystemModuleInformationÂ class), by suppressing kernel base addresses unless the caller hadÂ the SeDebugPrivilege, typically reserved for administrative processes. That change effectively neutered one of the most accessible KASLR bypass techniques, and, without knowledge of the kernelâ€™s base addresses, exploitation became harder.
While doing patch analysis forÂ CVE-2024-43511, I realised that Microsoft made a mistake leading to a kernel address leak vulnerability. This new bug requires winning a race condition to read out the address; however, itâ€™s pretty easy to achieve. It provides a powerful kernel address leak for any token handle, which can be easily chained with other vulnerabilities to obtain a complete exploit on the latest version of the system.
Vulnerability
Quick review on the patch for CVE-2024-43511
In October 2024, Microsoft released a patch for a Time-of-check Time-of-use (TOCTOU) Race Condition vulnerability in the Windows kernel, namelyÂ CVE-2024-43511.
To fix the issue, when passing parameters to theÂ RtlSidHashInitialize()Â function, it reads data from a kernel pointer (which is a member of theÂ TOKENÂ structure), instead of the value set in a user-controlled buffer.

Spotting the bug
With the new update, theÂ RtlSidHashInitialize()Â function, which performs hash initialisation, now takes as its first parameter a pointer from theÂ TOKENÂ structure and as its third parameter aÂ user-controlledÂ buffer. Then,Â RtlSidHashInitialize()Â stores the first parameter (which is a pointer to theÂ UserAndGroupsÂ field of theÂ TOKENÂ structure) into the third parameter (user-supplied pointer), and starts doing hash initialisation later on:

Although the caller function will replace the stored pointer in the user-buffer pointer after that, it still leaves a small time window for us to win a race condition and read out the leaked kernel address. To trigger the vulnerable function, we only need to invoke theÂ NtQuerySystemInformation()Â API with theÂ SystemTokenInformationÂ class.
Effects of the bug
This leak primitive is particularly useful for Windows versions 24H2 or later, as the well-known technique for leaking kernel addresses using NtQuerySystemInformation() or other alternative methods has been patched. As the vulnerability is located within an NT syscall, the bug can be exploited from eitherÂ Low ILÂ orÂ AppContainer. If chained with aÂ write-what-whereÂ bug to overwrite theÂ PrivilegesÂ field of theÂ TOKENÂ object, it will result in a complete LPE.
Exploitation
Setup
To exploit this bug, I need to create two threads to run concurrently:

One thread to read at the specific offset, which will be used to store the kernel address in the user buffer.
One thread performs the syscall. It is required to run the syscall several times before archiving the kernel leak.

Reliability
Although this is a race condition bug, the time window is wide enough to read the kernel address from the user-space buffer. To increase the success rate, we repeatedly callÂ NtQuerySystemInformation()Â while keeping reading until we get the leak. The read becomes very reliable, and we can obtain the leakedÂ TOKENÂ almost every time we run the exploit.
Proof-of-concepts
The results below show the exploit on a Windows Insider Preview in April 2025 (latest version at the time of writing), running the exploit from theÂ Low ILÂ andÂ App ContainerÂ contexts:


Conclusion
Patch analysis is one of the fastest ways to improve our skills and sharpen our mindset in bug finding. Additionally, it also helps us improve our secure coding skills. Sometimes, bug fixes in a function can introduce new bugs in other parts of the code. When conducting vulnerability research, itâ€™s recommended to take a deep look to understand how the bug was patched and whether the patch completely resolves the issue or leaves other gaps open. From a developerâ€™s point of view, every change made to a function can affect others as well, so take extra care when making any changes to the codebase. It is essential to thoroughly understand how a function works before modifying it, as this helps avoid mistakes or misuse of the function.
Disclosure Timeline

April 8th: Reported to vendor.
April 9th: Microsoft acknowledged that it is working on the bug.
April 22nd: They claimed that the bug is duplicated with a bug which had been fixed already, and closed the case without having any other chance to explain the bugâ€¦ (I donâ€™t know why).
April 22nd: I made aÂ tweetÂ on X to complain about that, and luckily, I got a response from them.
April 25th: Confirmed my report is a valid bug:v
April 29th: Microsoft replied that the bug was in scope.
August 1st:Â CVE-2025-53136Â was assigned.


		

					
		
	

	

								
					
					]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Conway's Game of Life, but musical]]></title>
            <link>https://www.hudsong.dev/digital-darwin</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45211868</guid>
            <description><![CDATA[Breed unique melodies with genetic algorithms! Explore Conway's musical life and cultural evolution patterns. Interactive AI music lab]]></description>
            <content:encoded><![CDATA[Hudson Griffithâ€¢September 11, 2025IntroductionMusic is profoundly human. It runs deep in our lives and shows up in our everyday rituals. And somehow, those rituals often end with us leaving AirPods in the back seat of an Uber. But beneath the everyday habits lies a much older connection. Neuroscience research shows our brains respond to music in fundamental ways that precede language development 1. And what fascinates me is how naturally music evolves over time, how styles adapt and change in a way that feels less like something we purposely create and more like it just grows on its own. Charles Darwin himself speculated that musicality might have preceded language, suggesting our capacity for music is fundamentally biological 2.This got me thinking: if musical evolution follows biological patterns, could we create an environment to simulate this evolution? So I built one.Building a Laboratory for Musical EvolutionI created what I call a melody breeder. Itâ€™s a digital playground where melodies can compete, reproduce, and evolve. Select your favorite (up to three) melodies, let them breed with each other, and watch what happens. It may not be the next top hit, but it's a lot of fun to play around with.And the science behind it is actually pretty solid. Richard Dawkins' concept of "memes" describes cultural units that replicate and evolve similarly to genes 3. Musical melodies are perfect examples. They replicate through listening, mutate through sampling, and undergo selection pressure based on whether people actually want to hear them again.Research by Savage et al. (2015) demonstrates that musical evolution follows predictable patterns across cultures, with structural features evolving through descent with modification much like biological traits 4. That means you can think of your Spotify Liked Songs playlist as a thriving ecosystem, full of tracks that survived.Conway's Symphony of Life and DeathWhile building the melody breeder, I kept thinking about how musical patterns behave like living systems. They're born, they interact, they die. This reminded me of one of my favorite digital visualizations, Conway's Game of Life.So I made it musical.This is Conway's Game of Life, where each cell birth plays a harmonic note and each death plays a complementary tone. The result is evolving, unpredictable music generated by the simulation.Each glider that moves across the screen creates its own melody. Oscillators turn into rhythms and the "glider gun" becomes a beat machine. The same simple rules that drive complexity in biology can also shape musical structure.From Musical Genes to Cultural PandemicsThe parallels between musical evolution and biological systems run deeper than you'd think.Take the Labubu phenomenon (I never thought I would write that phrase in a blog post). These designer toys went from obscure to everywhere seemingly overnight, spreading through social media like a disease. And I mean that literally, epidemiologists use the same models for viral TikTok trends as they do for actual viruses 5. To show this, I pulled Google Trends data 6 on the term "Labubu" from the start of 2024 to today and visualized it as a global map of its spread.Popularity2024-01-012024-01-042024-01-082024-01-112024-01-14Watching this trend curve reminds me of the pandemic era. The same steep exponential rises, the geographic spread patterns, the way interest peaks and then gradually declines. It's unsettling how similar a toy's popularity looks to a virus outbreak when you plot them on a map.But maybe that similarity isn't so unsettling after all. Maybe it reveals something deeper about how information spreads through human networks, whether that information is genetic code, viral particles, or cultural ideas.The Universal Patterns of Cultural EvolutionDarwin called it "endless forms most beautiful," and that phrase fits here too. The same simple rules that drive biology also explain why culture produces such variety, from music to memes. Patterns replicate, adapt, and survive when they capture our attention.Boyd & Richerson describe culture as a shared pool of innovation that helps us live better 7. Sometimes that means a symphony, sometimes a viral monster toy. Either way, it's evolution at work.These patterns exist all around us, but recognizing them is just the beginning. What really gets me excited is being able to build something that makes these invisible forces visible.Why I Love CodeThis whole exploration exists because programming gave me the tools to turn random shower thoughts into something real and shareable. There's something empowering about writing code that simulates generations of evolution in milliseconds, about building systems that let people explore complex ideas through play.This is why I code: to take questions that keep me up at night and turn them into something that might spark curiosity in the 5 people who read these blog posts.Now if you'll excuse me, I need to check on my melody breeder. Pretty sure Beethoven's Fifth great-grandson just evolved into Baby Shark.References1Levitin, D. J. (2006). This Is Your Brain on Music: The Science of a Human Obsession. Dutton Penguin.2Darwin, C. (1871). The Descent of Man, and Selection in Relation to Sex. John Murray.3Dawkins, R. (1976). The Selfish Gene. Oxford University Press.4Savage, P. E., Brown, S., Sakai, E., & Currie, T. E. (2015). Statistical universals reveal the structures and functions of human music. Proceedings of the National Academy of Sciences, 112(29), 8987-8992.5Kermack, W. O., & McKendrick, A. G. (1927). A contribution to the mathematical theory of epidemics. Proceedings of the Royal Society of London. Series A, 115(772), 700-721.6Google Trends. (2024â€“2025). Search interest for â€œLabubuâ€. Retrieved September 2025, from https://trends.google.com7Boyd, R., & Richerson, P. J. (2011). The cultural niche: Why social learning is essential for human adaptation. Proceedings of the National Academy of Sciences, 108(Supplement 2), 10918â€“10925. https://doi.org/10.1073/pnas.11002901088Centola, D. (2010). The spread of behavior in an online social network experiment. Science, 329(5996), 1194-1197.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CRISPR offers new hope for treating diabetes]]></title>
            <link>https://www.wired.com/story/no-more-injections-crispr-offers-new-hope-for-treating-diabetes/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45211596</guid>
            <description><![CDATA[Gene-edited pancreatic cells have been transplanted into a patient with type 1 diabetes for the first time. They produced insulin for months without the patient needing to take immunosuppressants.]]></description>
            <content:encoded><![CDATA[All products featured on WIRED are independently selected by our editors. However, we may receive compensation from retailers and/or from purchases of products through these links. Learn more.Crispr gene-editing technology has demonstrated its revolutionary potential in recent years: It has been used to treat rare diseases, to adapt crops to withstand the extremes of climate change, or even to change the color of a spiderâ€™s web. But the greatest hope is that this technology will help find a cure for a global disease, such as diabetes. A new study points in that direction.For the first time, researchers succeeded in implanting Crispr-edited pancreatic cells in a man with type 1 diabetes, an autoimmune disease where the immune system attacks insulin-producing cells in the pancreas. Without insulin, the body is then unable to regulate blood sugar. If steps arenâ€™t taken to manage glucose levels by other means (typically, by injecting insulin), this can lead to damage to the nerves and organsâ€”particularly the heart, kidneys, and eyes. Roughly 9.5 million people worldwide have type 1 diabetes.In this experiment, edited cells produced insulin for months after being implanted, without the need for the recipient to take any immunosuppressive drugs to stop their body attacking the cells. The Crispr technology allowed the researchers to endow the genetically modified cells with camouflage to evade detection.The study, published last month in The New England Journal of Medicine, details the step-by-step procedure. First, pancreatic islet cells were taken from a deceased donor without diabetes, and then altered with the gene-editing technique Crispr-Cas12b to allow them to evade the immune response of the diabetes patient. Cells altered like this are said to be â€œhypoimmune,â€ explains Sonja Schrepfer, a professor at Cedars-Sinai Medical Center in California and the scientific cofounder of Sana Biotechnology, the company that developed this treatment.The edited cells were then implanted into the forearm muscle of the patient, and after 12 weeks, no signs of rejection were detected. (A subsequent report from Sana Biotechnology notes that the implanted cells were still evading the patientâ€™s immune system after six months.)Tests run as part of the study recorded that the cells were functional: The implanted cells secreted insulin in response to glucose levels, representing a key step toward controlling diabetes without the need for insulin injections. Four adverse events were recorded during follow-ups with the patient, but none of them were serious or directly linked to the modified cells.The researchersâ€™ ultimate goal is to apply immune-camouflaging gene edits to stem cellsâ€”which have the ability to reproduce and differentiate themselves into other cell types inside the bodyâ€”and then to direct their development into insulin-secreting islet cells. â€œThe advantage of engineering hypoimmune stem cells is that when these stem cells proliferate and create new cells, the new cells are also hypoimmune,â€ Schrepfer explained in a Cedars-Sinai Q+A earlier this year.Traditionally, transplanting foreign cells into a patient has required suppressing the patientâ€™s immune system to avoid them being rejected. This carries significant risks: infections, toxicity, and long-term complications. â€œSeeing patients die from rejection or severe complications from immunosuppression was frustrating to me, and I decided to focus my career on developing strategies to overcome immune rejection without immunosuppressive drugs,â€ Schrepfer told Cedars-Sinai.Although the research marks a milestone in the search for treatments of type 1 diabetes, itâ€™s important to note that the study involved one one participant, who received a low dose of cells for a short periodâ€”not enough for the patient to no longer need to control their blood sugar with injected insulin. An editorial by the journal Nature also says that some independent research groups have failed in their efforts to confirm that Sanaâ€™s method provides edited cells with the ability to evade the immune system.Sana will be looking to conduct more clinical trials starting next year. Without overlooking the criticisms and limitations of the current study, the possibility of transplanting cells modified to be invisible to the immune system opens up a very promising horizon in regenerative medicine.This story originally appeared on WIRED en EspaÃ±ol and has been translated from Spanish.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[From burner phones to decks of cards: NYC teens adjusting to the smartphone ban]]></title>
            <link>https://gothamist.com/news/from-burner-phones-to-decks-of-cards-nyc-teens-are-adjusting-to-the-smartphone-ban</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45211527</guid>
            <description><![CDATA[A week into the ban on internet-enabled devices, students say they are making it work.]]></description>
            <content:encoded><![CDATA[New York City students are one week into the statewide phone ban. Gothamist reporters checked in with teens across the district to see how they are adapting. Here's how they are handling their disconnected days.Lower-tech lifePolaroids, walkie-talkies and decks of cards: New York City teens said these are some of the hot items circulating in schools now that the statewide smartphone ban is in effect.Alia Soliman, a senior at Bronx Science, said cards â€œare making a big comeback.â€ She said kids are playing poker when theyâ€™re done with their work in some classes. Fellow students reported a surge in Uno.â€œIt seems to be very fun and engaging,â€ Soliman said.She said members of the senior class are using vintage devices to capture memories and milestones.â€œIâ€™ve seen some of my friends bring in digicams,â€ Soliman said. â€œA lot of people are bringing in Polaroids.â€Sheâ€™s looking into whether an MP3 player would be allowed in school to listen to while she studies.â€œIâ€™ll test the waters,â€ she said.In Manhattan, Ethan Myer, a senior at Union Square Academy, said the ban is also helping kids get their steps in.â€œMost people are just walking around the hall, because there's not really much else to do,â€ Myer said. "Some people are talking a bit more, which I guess was the goal.â€Jem Bryant, a junior at Gramercy Arts High School, also near Union Square, is daydreaming more.â€œI â€Šdon't really have a lot of friends in classes,â€ Bryant said. â€œSo when they say â€˜do your classworkâ€™ and I'm already done, I literally just have to sit there and stare at the wall.â€Soliman said she was opposed to the ban at first, and sheâ€™s concerned that she wonâ€™t be able to work on her college applications during downtime at school, but she sees some positives.â€œIâ€™m still not thrilled,â€ she said. â€œBut people are reading more. The younger kids are socializing more.â€Peter Schmidt-Nowara, a teacher and dean at Brooklyn Tech, said the hallways and lunchroom are louder, in a good way.â€œIt was muted,â€ he said. â€œItâ€™s really lifted a pall.â€He said itâ€™s a stark difference from last year, when kids were retreating to bathrooms for 20 minutes to check their phones, and walking through the halls with their heads down.He added that he's enjoyed watching students turn to unfamiliar technology.â€œA group of boys brought in a transistor radio to listen to music. They didnâ€™t realize they had to lift the antenna, so I lifted it for them. The music wasnâ€™t that loud and it was quite sweet,â€ he said.WorkaroundsNo students interviewed by Gothamist copped to having burner phones of their own, but some said they knew of classmates deploying decoys.â€œNot to rat anyone out, but some people have fake phones,â€ said Solangel Santana, a senior at Union Square Academy.She added that kids sometimes send each other emails or chat in Google Docs on their education department-issued devices.â€œWe find creative ways to talk to each other,â€ she said.Video app TikTok is rife with videos of kids breaking into pouches. â€œThey slam it,â€ said Esmeralda Jaramillo, a junior at Gramercy Arts.Soliman said students sometimes physically leave the building and go out into the courtyard for a phone break to play games or check messages during free periods or lunch. â€œThe benches are always full,â€ Soliman said.Speaking at DeWitt Clinton High School in the Bronx on Monday, Mayor Eric Adams said itâ€™s not the first time teenagers have tried to skirt the rules.â€œThis is all part of their creative spirit and energy,â€ he said. â€œWe did it. Let's not act like when we were in school, we didn't have all our little tricks on how we got around things.Adams made the comments at a press conference to announce the distribution of 350,000 internet-enabled Chromebooks, part of the cityâ€™s effort to replace aging devices obtained during the pandemic, and ensure that all students have access to technology in schools even as their personal devices are banned.From bottlenecks to stampedesSchools have rolled out a range of strategies, with most schools either collecting phones at arrival and storing them in lockers or distributing magnetic pouches that have to be locked and unlocked at the beginning and end of the day.Bryant at Gramercy Arts High School said of the end-of-day routine, â€œTheyâ€™ll be like, â€˜Single-file line,â€™ but it will not be a single-file line and people will just bum-rush the magnets.â€Students at LaGuardia High School reported long lines on the first few days of school.Laila Lawrence, 16, said students have been blamed for being late to class.â€œThe teachers are the first ones to complain, â€˜Oh, you were late, da da da da.â€™ I'm like, â€˜I was on the line, like, what do you want me to do?â€™â€But Lawrence's views on the ban were mixed.â€œâ€ŠI think it's good and bad because phones are obviously a problem,â€ she said. â€œI'm not gonna say like I'm not addicted to my phone 'cause I am, but at the same time I'm like no one in the school is like purposely on their phone in the middle of class.â€]]></content:encoded>
        </item>
    </channel>
</rss>