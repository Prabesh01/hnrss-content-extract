<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Tue, 02 Sep 2025 07:12:40 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Kapa.ai (YC S23) is hiring research and software engineers]]></title>
            <link>https://www.ycombinator.com/companies/kapa-ai/jobs</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45099939</guid>
            <description><![CDATA[Jobs at kapa.ai]]></description>
            <content:encoded><![CDATA[The fastest way to build AI assistants on technical contentJobs at kapa.aiGB / DE / FR / NO / DK / SE / FI / PT / ES / BE / NL / IT / CH / AT / CZ / PL / EE / LV / LT / SK / HU / SI / HR / RU / UA / Remote (GB; DE; FR; NO; DK; SE; FI; PT; ES; BE; NL; IT; CH; AT; CZ; PL; EE; LV; LT; SK; HU; SI; HR; RU; UA)$100K - $150K0.10% - 0.30%3+ yearsGB / EG / RU / UA / TR / FR / IT / ES / PL / RO / KZ / NL / BE / SE / CZ / GR / PT / HU / AT / CH / BG / DK / FI / NO / SK / LT / EE / DE / Remote (GB; EG; RU; UA; TR; FR; IT; ES; PL; RO; KZ; NL; BE; SE; CZ; GR; PT; HU; AT; CH; BG; DK; FI; NO; SK; LT; EE; DE)$100K - $150K0.10% - 0.30%3+ yearsWhy you should join kapa.aiWe make it easy for technical companies to build AI assistants. Companies like Docker, Grafana and Mixpanel deploy kapa in the following ways:

As chat interface on their public documentation to answer developer questions.
As first line of defense on their support forms to reduce tickets.
As internal assistant for their GTM teams to navigate their own complex product.

We leverage companies existing technical knowledge sources including documentation, tutorials, forum posts, Slack channels, GitHub issues and many more to generate AI assistants that can handle complicated technical questions. More than 200 companies use kapa and we have answered more than 10 million questions to date.
Founded:2023Batch:S23Team Size:19Status:ActiveFoundersFinn BauerFounderEmil SoerensenFounder]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vibe coding as a VC]]></title>
            <link>https://kevinkuipers.substack.com/p/vc-for-vibe-coding-a-fresh-new-start</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45099619</guid>
        </item>
        <item>
            <title><![CDATA[Collecting All Causal Knowledge]]></title>
            <link>https://causenet.org/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45099418</guid>
            <description><![CDATA[Collecting All Causal Knowledge]]></description>
            <content:encoded><![CDATA[
            Collecting All Causal Knowledge
            
                    CauseNet aims at creating a causal knowledge base that comprises all human causal knowledge and to separate it from mere causal beliefs, with the goal of enabling large-scale research into causal inference.
                
        

    

    Causal knowledge is seen as one of the key ingredients to advance artificial intelligence. Yet, few knowledge bases comprise causal knowledge to date, possibly due to significant efforts required for validation. Notwithstanding this challenge, we compile CauseNet, a large-scale knowledge base of claimed causal relations between causal concepts. By extraction from different semi- and unstructured web sources, we collect more than 11 million causal relations with an estimated extraction precision of 83\% and construct the first large-scale and open-domain causality graph. We analyze the graph to gain insights about causal beliefs expressed on the web and we demonstrate its benefits in basic causal question answering. Future work may use the graph for causal reasoning, computational argumentation, multi-hop question answering, and more.

    Download

    We provide three versions of our causality graph CauseNet:
    
      CauseNet-Full: The complete dataset
      CauseNet-Precision: A subset of CauseNet-Full with higher precision
      CauseNet-Sample: A small sample dataset for first explorations and experiments without provenance data
    

    Statistics

    
      
        
          Â 
          Relations
          Concepts
          File Size
        
      
      
        
          CauseNet-Full
          11,609,890
          12,186,195
          1.8GB
        
        
          CauseNet-Precision
          199,806
          80,223
          135MB
        
        
          CauseNet-Sample
          264
          524
          54KB
        
      
    

    Data Model

    The core of CauseNet consists of causal concepts which are connected by causal relations. Each causal relation has comprehensive provenance data on where and how it was extracted.

    

    Examples of Causal Relations

    Causal relations are represented as shown in the following example. Provenance data is omitted.

    {
    "causal_relation": {
        "cause": {
            "concept": "disease"
        },
        "effect": {
            "concept": "death"
        }
    }
}


    For CauseNet-Full and CauseNet-Precision, we include comprehensive provenance data. In the following, we give one example per source.

    For relations extracted from natural language sentences we provide:
    
      surface: the surface form of the sentence, i.e., the original string
      path_pattern: the linguistic path pattern used for extraction
    

    ClueWeb12 Sentences

    
      clueweb12_page_id: page id as provided in the ClueWeb12 corpus
      clueweb12_page_reference: page reference as provided in the ClueWeb12 corpus
      clueweb12_page_timestamp: page access data as stated in the ClueWeb12 corpus
    

    {
    "causal_relation":{
        "cause":{
            "concept":"smoking"
        },
        "effect":{
            "concept":"disability"
        }
    },
    "sources":[
        {
            "type":"clueweb12_sentence",
            "payload":{
                "clueweb12_page_id":"urn:uuid:4cbae00e-8c7f-44b1-9f02-d797f53d448a",
                "clueweb12_page_reference":"http://atlas.nrcan.gc.ca/site/english/maps/health/healthbehaviors/smoking",
                "clueweb12_page_timestamp":"2012-02-23T21:10:45Z",
                "sentence": "In Canada, smoking is the most important cause of preventable illness, disability and premature death.",
                "path_pattern":"[[cause]]/N\t-nsubj\tcause/NN\t+nmod:of\t[[effect]]/N"
            }
        }
    ]
}


    Wikipedia Sentences

    
      wikipedia_page_id: the Wikipedia page id
      wikipedia_page_title: the Wikipedia page title
      wikipedia_revision_id: the Wikipedia revision id of the last edit
      wikipedia_revision_timestamp: the timestamp of the Wikipedia revision id of the last edit
      sentence_section_heading: the section heading where the sentence comes from
      sentence_section_level: the level where the section heading comes from
    

    {
    "causal_relation":{
        "cause":{
            "concept":"human_activity"
        },
        "effect":{
            "concept":"climate_change"
        }
    },
    "sources":[
        {
            "type":"wikipedia_sentence",
            "payload":{
                "wikipedia_page_id":"13109",
                "wikipedia_page_title":"Global warming controversy",
                "wikipedia_revision_id":"860220175",
                "wikipedia_revision_timestamp":"2018-09-19T04:52:18Z",
                "sentence_section_heading":"Global warming controversy",
                "sentence_section_level":"1",
                "sentence": "The controversy is, by now, political rather than scientific: there is a scientific consensus that climate change is happening and is caused by human activity.",
                "path_pattern":"[[cause]]/N\t-nmod:agent\tcaused/VBN\t+nsubjpass\t[[effect]]/N"
            }
        }
    ]
}


    Wikipedia Lists

    
      list_toc_parent_title: The heading of the parent section the list appears in
      list_toc_section_heading: The heading of the section the list appears in
      list_toc_section_level: The nesting level of the section within the table of content (toc)
    

    {
    "causal_relation":{
        "cause":{
            "concept":"separation_from_parents"
        },
        "effect":{
            "concept":"stress_in_early_childhood"
        }
    },
    "sources":[
        {
            "type":"wikipedia_list",
            "payload":{
                "wikipedia_page_id":"33096801",
                "wikipedia_page_title":"Stress in early childhood",
                "wikipedia_revision_id":"859225864",
                "wikipedia_revision_timestamp":"2018-09-12T16:22:05Z",
                "list_toc_parent_title":"Stress in early childhood",
                "list_toc_section_heading":"Causes",
                "list_toc_section_level":"2"
            }
        }
    ]
}


    Wikipedia Infoboxes

    
      infobox_template: The Wikipedia template of the infobox
      infobox_title: The title of the Wikipedia infobox
      infobox_argument: The argument of the infobox (the key of the key-value pair)
    

    {
    "causal_relation":{
        "cause":{
            "concept":"alcohol"
        },
        "effect":{
            "concept":"cirrhosis"
        }
    },
    "sources":[
        {
            "type":"wikipedia_infobox",
            "payload":{
                "wikipedia_page_id":"21365918",
                "wikipedia_page_title":"Cirrhosis",
                "wikipedia_revision_id":"861860835",
                "wikipedia_revision_timestamp":"2018-09-30T15:40:21Z",
                "infobox_template":"Infobox medical condition (new)",
                "infobox_title":"Cirrhosis",
                "infobox_argument":"causes"
            }
        }
    ]
}


    Loading CauseNet into Neo4j

    We provide sample code to load CauseNet into the graph database Neo4j.

    The following figure shows an excerpt of CauseNet within Neo4j (showing a coronavirus causing the disease SARS):

    

    Concept Spotting Datasets

    For the construction of CauseNet, we employ a causal concept spotter as a causal concept can be composed of multiple words (e.g., âglobal warmingâ, âhuman activityâ, or âlack of exerciseâ). We determine the exact start and end of a causal
concept in a sentence with a sequence tagger. Our training and evaluation data is available as part of our concept spotting datasets: one for Wikipedia infoboxes, Wikipedia lists, and ClueWeb sentences. We split each dataset into 80% training, 10% development and 10% test set

    Paper

    CauseNet forms the basis for our CIKM 2020 paper CauseNet: Towards a Causality Graph Extracted from the Web. Please make sure to refer to it as follows:

    @inproceedings{heindorf2020causenet,
  author    = {Stefan Heindorf and
               Yan Scholten and
               Henning Wachsmuth and
               Axel-Cyrille Ngonga Ngomo and
               Martin Potthast},
  title     = {CauseNet: Towards a Causality Graph Extracted from the Web},
  booktitle = {{CIKM}},
  publisher = {{ACM}},
  year      = {2020}
}


    

    For questions and feedback please contact:

    Stefan Heindorf, Paderborn University
Yan Scholten, Technical University of Munich
Henning Wachsmuth, Paderborn University
Axel-Cyrille Ngonga Ngomo, Paderborn University
Martin Potthast, Leipzig University

    Licenses

    The code is licensed under a MIT license. The data is licensed under a Creative Commons Attribution 4.0 International license.
  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WinBoat: Run Windows apps on Linux with seamless integration]]></title>
            <link>https://github.com/TibixDev/winboat</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45099124</guid>
            <description><![CDATA[Run Windows apps on ð§ Linux with â¨ seamless integration - TibixDev/winboat]]></description>
            <content:encoded><![CDATA[
  
    
      
        
      
      
        WinBoat
        Windows for Penguins.
        Run Windows apps on ð§ Linux with â¨ seamless integration
      
    
  

Screenshots

  
  

â ï¸ Work in Progress â ï¸
WinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.
Features

ð¨ Elegant Interface: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience
ð¦ Automated Installs: Simple installation process through our interface - pick your preferences & specs and let us handle the rest
ð Run Any App: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment
ð¥ï¸ Full Windows Desktop: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow
ð Filesystem Integration: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle
â¨ And many more: Smartcard passthrough, resource monitoring, and more features being added regularly

Prerequisites
Before running WinBoat, ensure your system meets the following requirements:

RAM: At least 4 GB of RAM
CPU: At least 2 CPU threads
Storage: At least 32 GB free space in /var
Virtualization: KVM enabled in BIOS/UEFI

How to enable virtualization


Docker: Required for containerization

Installation Guide


Docker Compose v2: Required for compatibility with docker-compose.yml files

Installation Guide


Docker User Group: Add your user to the docker group

Setup Instructions


FreeRDP: Required for remote desktop connection (Please make sure you have Version 3.x.x with sound support included)

Installation Guide


Kernel Modules: iptables and iptable_nat modules must be loaded

Module loading instructions



Downloading
You can download the latest Linux builds under the Releases tab. We currently offer two variants:

AppImage: A popular & portable app format which should run fine on most distributions
Unpacked: The raw unpacked files, simply run the executable (linux-unpacked/winboat)

Known Issues About Container Runtimes

Podman is unsupported for now
Docker Desktop is unsupported for now
Distros that emulate Docker through a Podman socket are unsupported
Any rootless containerization solution is currently unsupported

Building WinBoat

For building you need to have NodeJS and Go installed on your system
Clone the repo (git clone https://github.com/TibixDev/WinBoat)
Install the dependencies (npm i)
Build the app and the guest server using npm run build:linux-gs
You can now find the built app under dist with an AppImage and an Unpacked variant

Running WinBoat in development mode

Make sure you meet the prerequisites
Additionally, for development you need to have NodeJS and Go installed on your system
Clone the repo (git clone https://github.com/TibixDev/WinBoat)
Install the dependencies (npm i)
Build the guest server (npm run build-guest-server)
Run the app (npm run dev)

Contributing
Contributions are welcome! Whether it's bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.
Please note: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let's keep things focused on making great software! ð
Feel free to:

Report bugs and issues
Submit feature requests
Contribute code improvements
Help with documentation
Share feedback and suggestions

Check out our issues page to get started, or feel free to open a new issue if you've found something that needs attention.
License
WinBoat is licensed under the MIT license
Inspiration / Alternatives
These past few years some cool projects have surfaced with similar concepts, some of which we've also taken inspirations from.
They're awesome and you should check them out:

WinApps
Cassowary
dockur/windows (ð Also used in WinBoat)

Socials & Contact

ð Website: winboat.app
ð¦ Twitter/X: @winboat_app
ð¦ Bluesky: winboat.app
ð¨ï¸ Discord: Join our community
ð§ Email: staff@winboat.app

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Wetware Crisis: The Thermocline of Truth (2008)]]></title>
            <link>https://brucefwebster.com/2008/04/15/the-wetware-crisis-the-themocline-of-truth/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45098867</guid>
            <description><![CDATA[[Updated 09/12/13 â fixed some links and added a few.]]]></description>
            <content:encoded><![CDATA[

							

							
							
							[Updated 09/12/13 â fixed some links and added a few.]
[Copyright 2008 by Bruce F. Webster. All rights reserved. Adapted from Surviving Complexity (forthcoming).]


A thermocline is a distinct temperature barrier between a surface layer of warmer water and the colder, deeper water underneath. It can exist in both lakes and oceans. A thermocline can prevent dissolved oxygen from getting to the lower layer and vital nutrients from getting to the upper layer.
In many large or even medium-sized IT projects, there exists a thermocline of truth, a line drawn across the organizational chart that represents a barrier to accurate information regarding the projectâs progress. Those below this level tend to know how well the project is actually going; those above it tend to have a more optimistic (if unrealistic) view.
Several major (and mutually reinforcing) factors tend to create this thermocline. First, the IT software development profession largely lacks â or fails to put into place â automated, objective and repeatable metrics that can measure progress and predict project completion with any reasonable degree of accuracy. Instead, we tend to rely on seat-of-the-pants (or, less politely, out-of-oneâs-butt) estimations by IT engineers or managers that a given subsystem or application is â80% doneâ. This, in turn, leads to the old saw that the first 90% of a software project takes 90% of the time, and the last 10% of a software projects takes the other 90% of the time. Iâll discuss the metrics issue at greater length in another chapter; suffice it to say that the actual state of completion of a major system is often truly unknown until an effort is made to put it into a production environment.

Second, IT engineers by nature tend to be optimists, as reflected in the common acronym SMOP: âsimple matter of programming.â Even when an IT engineer doesnât have a given subsystem completed, he tends to carry with him the notion that he whip everything into shape with a few extra late nights and weekends of effort, even though he may actually face weeks (or more) of work. (NOTE: my use of male pronouns is deliberate; it is almost always male IT engineers who have this unreasonable optimism. Female IT engineers in my experience are generally far more conservative and realistic, almost to a fault, which is why I prefer them. I just wish they werenât so hard to find.)
Third, managers (including IT managers) like to look good and usually donât like to give bad news, because their continued promotion depends upon things going well under their management. So even when they have problems to report, they tend to understate the problem, figuring they can somehow shuffle the work among their direct reports so as to get things back on track.
Fourth, upper management tends to reward good news and punish bad news, regardless of the actual truth content. Honesty in reporting problems or lack of progress is seldom rewarded; usually it is discouraged, subtly or at times quite bluntly. Often, said managers believe that true executive behavior comprises brow-beating and threatening lower managers in order to âmotivateâ them to solve whatever problems they might have.
As the project delivery deadline draws near, the thermocline of truth starts moving up the levels of management because it is becoming harder and harder to deny or hide just where the project stands. Even with that, the thermocline may not reach the top level of management until weeks or even just days before the project is scheduled to ship or go into production. This leads to the classic pattern of having a major schedule slip â or even outright project failure â happen just before the ship/production date.
Sometimes, even then management may not be willing to hear or acknowledge where things really are but instead insist on a âquick fixâ to get things done. Or management will order the project to be shipped or put into production, at which point all parties discover (a) that the actual business drivers and requirements never successfully made it down through the thermocline to those building the system, (b) that there are serious (and perhaps fatal) quality issues with the delivered systems, and thus (c) that the delivered project doesnât do what top management really requires.
[INSERTED â 04/30/08]
Since Jerry Weinberg (see comments) and others have disputed that the thermocline is âdistinctâ, let me insert two real-world examples that I have personal knowledge of from over a decade ago. Both examples involve Fortune 100 corporations that were undergoing Y2K remediation across the entire enterprise. In the first case, the corporate Y2K coordinator had a weekly meeting with the heads of ~20 divisions and departments within the corporation in which those senior executives would report on their division/departmentâs Y2K remediation status with a green/yellow/red code. Four weeks before Y2K remediation was scheduled to be completed, virtually all the division/departments were reporting green, with a few yellows. Just one week later â three weeks before remediation was to be completely â almost all the department/division heads suddenly reported their status to be yellow or red. The Y2K coordinator (who told me about the meeting right afterwards) looked around the room and asked, âSo, what do you know today that you didnât know a week ago?â No one had much of an answer.
A year later, I was asked by a major corporation to come in and review their Y2K remediation because almost exactly the same thing had happened: almost all the departments/division had been reporting each week that they were on schedule to complete their Y2K remediation until roughly two weeks before the remediation was supposed to be completed â and then suddenly about 70% of the departments/divisions said they werenât going to be done on time. The mass shift from âon scheduleâ to ânot on scheduleâ took place in exactly one week and happened just a few weeks before the deadline. I came in, interviewed some 40 people (under strict confidentiality, in spite of pressure from top management to reveal who said what), and wrote up an honest assessment of where things stood, with a plan for getting things done. The corporation then asked me to come in and implement that plan, so I ended up commuting over 2000 miles/week (back and forth) for 2-3 months to do just that.
I have seen the same pattern repeatedly in IT systems failure lawsuits I have worked on, particularly when Iâve had large numbers of internal e-mails and memos to review. At times, I can identify right where the thermocline is and how it creeps up the management chain as the deadline draws near. In such cases, it usually doesnât reach the top of the management chain (which, in the case of these lawsuits, means the developer notifying the customer) until shortly (<1 month) before the reported deadline. In fact, this syndrome goes hand-in-hand with the IT system failure lawsuit pattern I call âThe Never-Ending Storyâ.
[06/16/08]: In fact, hereâs a real-world IT project review memo, written several years ago, that described a âthermocline of truthâ with a very distinct and discrete boundary.
In short, Jerryâs arguments notwithstanding, Iâve seen the thermocline of truth, Iâve seen it be very distinct, and Iâve seen it work its way up the management chain â just as Iâve described. Iâm not writing this to be clever or glib; Iâm writing it because it really happens.
[END INSERTION]
Successful large-scale IT projects require active efforts to pierce the thermocline, to break it up, and to keep it from reforming. That, in turn, requires the honesty and courage at the lower levels of the project not just to tell the truth as to where things really stand, but to get up on the table and wave your arms until someone pays attention. It also requires the upper reaches of management to reward honesty, particularly when it involves bad news. That may sound obvious, but trust me â in many, many organizations that have IT departments, honesty is neither desired nor rewarded.
I know that first hand. I can think of one project â being developed by one firm (the one that retained me) for another company (the customer) â where I was in on a consulting basis as a chief architect. In the final planning meeting before submitting the bid to the customer, the project manager set forth an incredibly aggressive and unachievable schedule to be given to the customer. I objected forcefully in the meeting â after all, we didnât even have an architecture yet, much less a design, yet the project manager already had a fixed completion date â and later that afternoon, I wrote up a memo listing thirteen (13) major risks I saw to the project. While some of the engineers on the project cheered the memo, management told me in so many words to shut up and architect.
However, less that two months later, I wrote a new memo â based on the old one â and pointed out that 12 of the 13 risks I had pointed out had actually come to pass. Shortly after that, the project manager had to go back to the customer with a new delivery schedule that was twice as long as the original one. A month or two after that, my role as an architect came to an end. I had a final lunch with the two head honchos in upper management, and to their credit, they asked for my final assessment. I told them that many of the bumps and potholes were just part of the software development process â but that they should never have given that blatantly unrealistic schedule to the customer. As I told them, âWhen you do something like that, in the end you look either dishonest or incompetent or both. And thereâs no upside to that.â
A few months after I left, I got word that the schedule had slipped to three times the original length, and not long after that, I got word that the customer had canceled the project altogether. As I said: just no upside.
[UPDATE: 09/12/13]: Hereâs a $1 billion failed USAF project that appears to have largely foundered on the thermocline of truth.
[For a discussion of where the thermocline analogy originally came to me, see this post at And Still I Persist.]

							

							
							

							
		About the Author: bfwebster
		Webster is Principal and Founder at at Bruce F. Webster & Associates, as well as an Adjunct Professor for the BYU Computer Science Department. He works with organizations to help them with troubled or failed information technology (IT) projects. He has also worked in several dozen legal cases as a consultant and as a testifying expert, both in the United States and Japan. He can be reached at 303.502.4141 or at bwebster@bfwa.com.	

						]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[FreeDroidWarn]]></title>
            <link>https://github.com/woheller69/FreeDroidWarn</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45098722</guid>
            <description><![CDATA[Contribute to woheller69/FreeDroidWarn development by creating an account on GitHub.]]></description>
            <content:encoded><![CDATA[
      



    
      Skip to content

      
    



  
  
  






      

          

              




  Navigation Menu

  

  
          
            


                
      

      
          

                
                    
  
      
      
          
            GitHub Copilot
          
        Write better code with AI
      

    


                    
  
      
      
          
            GitHub Spark
              
                New
              
          
        Build and deploy intelligent apps
      

    


                    
  
      
      
          
            GitHub Models
              
                New
              
          
        Manage and compare prompts
      

    


                    
  
      
      
          
            GitHub Advanced Security
          
        Find and fix vulnerabilities
      

    


                    
  
      
      
          
            Actions
          
        Automate any workflow
      

    


                    
                
              
          

                
                    
  
      
      
          
            Codespaces
          
        Instant dev environments
      

    


                    
  
      
      
          
            Issues
          
        Plan and track work
      

    


                    
  
      
      
          
            Code Review
          
        Manage code changes
      

    


                    
  
      
      
          
            Discussions
          
        Collaborate outside of code
      

    


                    
  
      
      
          
            Code Search
          
        Find more, search less
      

    


                
              
          

      



                
      

      



                
      

      
                    Explore
                    
  
      Learning Pathways

    


                    
  
      Events & Webinars

    


                    
  
      Ebooks & Whitepapers

    


                    
  
      Customer Stories

    


                    
  
      Partners

    


                    
  
      Executive Insights

    


                
              



                
      

      
              

                
                    
  
      
      
          
            GitHub Sponsors
          
        Fund open source developers
      

    


                
              
              

                
                    
  
      
      
          
            The ReadME Project
          
        GitHub community articles
      

    


                
              
              
          



                
      

      

                
                    
  
      
      
          
            Enterprise platform
          
        AI-powered developer platform
      

    


                
              



                
    Pricing


            
          

        
                



  
  
  
    

  
    
    
      
        Provide feedback
      
        
    
    
  
      
        
      
      


    
    

  
    
    
      
        Saved searches
      
        Use saved searches to filter your results more quickly
    
    
  
      
        
      
      

    
  



            

              
                Sign up
              
    
      Appearance settings

      
    
  

          
      


      
    

  








    


    






  
    
      
  





    






  
  

      
            
    
      

  
                Notifications
    You must be signed in to change notification settings

  

  
              Fork
    1

  

  
        
            
          Star
          51

  



        

        


          

  
    


  

  




          



  
  
  Folders and filesNameNameLast commit messageLast commit dateLatest commitHistory9 Commitsgradle/wrappergradle/wrapperlibrarylibrary.gitignore.gitignoreLICENSELICENSEREADME.mdREADME.mdbuild.gradlebuild.gradlegradle.propertiesgradle.propertiesgradlewgradlewgradlew.batgradlew.batsettings.gradlesettings.gradleREADMEGPL-3.0 licenseFreeDroidWarn
Overview
This library shows an alert dialog with a deprecation warning informing that Google will require developer verification for Android apps outside the Play Store from 2026/2027 which the developer is not going to provide.
Google has announced that, starting in 2026/2027, all apps on certified Android devices
will require the developer to submit personal identity details directly to Google.
Since the developers of this app do not agree to this requirement, this app will no longer 
work on certified Android devices after that time.

https://www.androidauthority.com/android-developer-verification-requirements-3590911/
https://developer.android.com/developer-verification
Installation
Add the JitPack repository to your root build.gradle at the end of repositories:
allprojects {
  repositories {
    ...
    maven { url 'https://jitpack.io' }
  }
}
Add the library dependency to your build.gradle file.
dependencies {
    implementation 'com.github.woheller69:FreeDroidWarn:V1.3'
}
Usage
In onCreate of your app just add:
     FreeDroidWarn.showWarningOnUpgrade(this, BuildConfig.VERSION_CODE);


License
This library is licensed under the GPLv3.




      




    
  

          



    



  

    

    

    





    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apple pulls iPhone torrent app from AltStore PAL in Europe]]></title>
            <link>https://www.theverge.com/news/767344/apple-removes-itorrent-altstore-pal-ios-marketplace</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45098411</guid>
            <description><![CDATA[iTorrentâs developer has been blocked from distributing apps on alternative iOS stores.]]></description>
            <content:encoded><![CDATA[Jess Weatherbed is a news writer focused on creative industries, computing, and internet culture. Jess started her career at TechRadar, covering news and hardware reviews.Apple has removed the iPhone torrenting client, iTorrent, from AltStore PALâs alternative iOS marketplace in the EU, showing that it can still exert control over apps that arenât listed on the official App Store. iTorrent developer Daniil Vinogradov told TorrentFreak that Apple has revoked his distribution rights to publish apps in any alternative iOS stores, but it seems the issue is related to government sanctions, rather than a block on torrenting.In a statement to The Verge, Apple spokesperson Peter Ajemian said, âNotarization for this app was removed in order to comply with government sanctions-related rules in various jurisdictions. We have communicated this to the developer.âWhile Apple bans torrent apps on its own iOS store, the EUâs Digital Markets Act gave iPhone users within the bloc greater freedom to install apps from third-party app stores that the Cupertino company doesnât directly manage.Last month, Vinogradov said on iTorrentâs GitHub page that Apple âremoved Alternative Distribution functionality from iTorrentâs Developer Portal without any warning.â Apple didnât provide a reason for the removal, according Vinogradov, and distribution was revoked at the Apple Dev Account level.Update, August 28th: Added a statement from Apple.0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Jess Weatherbed]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kazeta: An operating system that brings the console gaming experience of 90s]]></title>
            <link>https://kazeta.org/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45098269</guid>
            <content:encoded><![CDATA[
    
        
            
                Download
                Discord
                Docs
                GitHub
            
        
    

    
        
		An operating system that brings the console gaming experience of the '90s to modern PC hardware and games: insert cart, power on, play.
                Explore Kazeta
            
        â
    

    
            
                Pure Gaming
                Insert a game cart, press power, and you're gaming instantly. Relive that nostalgic golden age where nothing stood between you and the games you love.
                
Zero setup
Direct to gameplay
Maximum performance
Distraction-free gaming
Classic '90s console experience
                
            
            
            
        

    
            
                Create Collect Play
                Transform your digital library into something tangible and permanent. Create physical game carts from your DRM-free titles and build a collection that you can play forever.
                
                    Turn any DRM-free game into a physical cart
                    Use SD cards or other external media as carts
                    Play without internet, accounts, or restrictions
                    Preserve your games as permanent, playable artifacts
                
            
	        
            
        

    
            
                Gaming Tranquility
                Say goodbye to the complexities of modern gaming and just play.
                
                    No DRM
                    No online
                    No servers
                    No updates
                    No accounts
                    No launchers
                    No subscriptions
                    No microtransactions
                
            
            
            
        

    
            
                Save Management
                Save data is captured automatically, so you never lose progress. When no cart is inserted, boot into a retro console inspired BIOS menu to manage your saves.
                
                    Retro-style BIOS screen
                    Automatic save capture
                    Playtime tracking
                    View and delete saves
                    Backup saves to external media
                
            
            
            
        

    
            
                Play It All
                Play almost any DRM-free game from platforms past or present.
                
                    AAA and indie games
                    Modern hits and old classics
                    GOG and itch.io games
                    Linux and Windows games
                    Classic console games with emulators
                
            
            
            
        

    
            
                Gaming For Everyone
                Bring back the family-friendly simplicity of gaming's distant past. Perfect for kids, parents, and grandparents who just want to play.
                
                    For kids who need a safe, offline environment
                    For older family members intimidated by modern gaming
                    For anyone craving gaming's simpler days
                
            
            
            
        

    
                Ready to game like it's 1995?
                
                    Download Kazeta today and rediscover the joy of pure gaming.
                
                Download Now
            


]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi 5 support (OpenBSD)]]></title>
            <link>https://marc.info/?l=openbsd-cvs&amp;m=175675287220070&amp;w=2</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45096585</guid>
            <content:encoded><![CDATA[
[prev in list] [next in list] [prev in thread] [next in thread] 

List:       openbsd-cvs
Subject:    CVS: cvs.openbsd.org: src
From:       Marcus Glocker <mglocker () cvs ! openbsd ! org>
Date:       2025-09-01 18:56:04
Message-ID: dd1203a530237b22 () cvs ! openbsd ! org
[Download RAW message or body]

CVSROOT:	/cvs
Module name:	src
Changes by:	mglocker@cvs.openbsd.org	2025/09/01 12:56:04

Modified files:
	distrib/arm64/iso: Makefile 
	distrib/arm64/ramdisk: Makefile install.md list 

Log message:
Add Raspberry Pi 5 Model B support for RAMDISK.

Known issues:
* Booting from PCIe storage HATs doesn't work because of missing U-Boot
support.
* WiFi on the Raspberry Pi 5 Model B "d0" boards doesn't work.
* The active cooler (fan) doesn't work because of missing pwm/clock
drivers (some work is in-progress).

ok kettenis@, deraadt@

[prev in list] [next in list] [prev in thread] [next in thread] 

  
    Configure | 

    About |
    News |
    AddÂ aÂ list |
    SponsoredÂ byÂ KoreLogic



]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The buyer-pull and seller-push theories of sales]]></title>
            <link>https://howtogrow.substack.com/p/the-physics-of-sales</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45096254</guid>
        </item>
        <item>
            <title><![CDATA[Patrick Winston: How to Speak (2018) [video]]]></title>
            <link>https://www.youtube.com/watch?v=Unzc731iCUY</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45095849</guid>
        </item>
        <item>
            <title><![CDATA[Amazon has mostly sat out the AI talent war]]></title>
            <link>https://www.businessinsider.com/amazon-ai-talent-wars-internal-document-2025-8</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45095603</guid>
            <description><![CDATA[Amazon has struggled to recruit top AI talent. An internal document and company insiders reveal the reasons.]]></description>
            <content:encoded><![CDATA[
            
            
            
            
                
                
                    
                      
                      
                    
                
                  
                        
                          
                          
                            
                              
                                    
                  
                          
                            Amazon CEO Andy Jassy
                            
                              
                                Fortune/Reuters Connect
                                        
                          
                        
                  
            
    
    
    
              
                
                
                
                  
                      2025-08-28T09:00:02Z
                    
                  
                
                
                        
      
            
      
              
              
              
              
                
                    Amazon struggles to attract AI talent due to its pay model and perception of falling behind others.
                    Amazon's compensation model has long caused complaints from employees.
                    Competitors like Meta and OpenAI offer more attractive packages for AI engineers.
                
              
      
            
            
            
            
            
            
                As the AI talent war sweeps across Silicon Valley, Amazon has largely sat on the sidelines. A confidential internal document, and accounts from people familiar with the matter, reveal why.The company has flagged its unique pay structure, lagging AI reputation, and rigid return-to-office rules as major hurdles. Now, the tech giant is being pushed to rethink its recruiting strategy as it scrambles to compete for top talent.The document, from late last year, was written by the HR team covering Amazon's non-retail businesses, including Amazon Web Services, advertising, devices, entertainment, and the newly formed artificial general intelligence team."GenAI hiring faces challenges like location, compensation, and Amazon's perceived lag in the space," the document noted. "Competitors often provide more comprehensive and aggressive packages." Business Insider obtained a copy of the document.Amazon's absence from recent splashy AI hires underscores those concerns. Meta has pulled in high-profile talent from ScaleAI, Apple, and OpenAI. Google and OpenAI continue to be top destinations for AI experts, while Microsoft has even drafted a wish list of Meta AI employees it hopes to recruit.Amazon's spokesperson initially told BI that the company continues to "adapt our approach to remain highly competitive, maintaining flexibility in both our compensation packages and work arrangements to attract and retain the best AI talent in this dynamic market."Hours later, the spokesperson updated the statement, saying the premise of the story was "wrong," without providing any specifics."We continue to attract and retain some of the best people in the world and they're building and deploying GenAI applications at a rapid clip. Our compensation is competitive, but we also want missionaries who are passionate about inventing things that will make a meaningful difference for customers â for those kinds of people, there's no better place in the world to build."Door desks and 'egalitarian' pay
              
              
              
              
                
            
              
              
              
            
              
              
                    
                      Amazon founder Jeff Bezos back in the 1990s
                      
              
              
              TNS/ABACA via Reuters Connect
              
              
                    
                  
              
            Amazon is famously frugal. One of its origin stories recounts how the company bought cheap doors from Home Depot and hacked them together as office desks. This became guiding symbol of Amazon's cautious spending, with founder Jeff Bezos still using door desks today.This penny-pinching culture has smashed straight into an AI hiring battle that's being fueled by unprecedented spending, putting Amazon in a tricky situation.The internal document described compensation as one of the "hotly debated topics" among Amazon recruiters, citing the company's strict use of fixed salary bands for each role. Amazon's "egalitarian philosophy" on pay leaves its offers "below par" compared with top rivals, it added."The lack of salary range increases for several key job families over the past few years does not position Amazon as an employer of choice for top tech talent," the document warned.For Amazon, missing out on top AI talent is a potential risk. ââThe pool of top-tier AI researchers and engineers is limited, and without experts with deep knowhow, it's hard to compete at the frontier of the field. Indeed, Amazon has yet to find a blockbuster AI product like OpenAI's ChatGPT or Anthropic's Claude, although its Bedrock AI cloud service has made progress.
              
              
              
            Amazon's pay structure has been a long-standing source of tension.Several people who spoke to Business Insider cited the 2020 departure of Amazon robotics VP Brad Porter as evidence of the company's frugal approach hampering talent recruitment and retention. Porter left in part after Amazon refused to raise his pay band.Amazon's stock vesting schedule is also heavily backloaded, a structure that can be less attractive to new hires. The policy extends even to top executives, who generally receive no cash bonuses.'Voting with their feet'
              
              
              
              
                
            
              
              
              
            
              
              
                    
                      Amazon CEO Andy Jassy
                      
              
              
              REUTERS/Brendan McDermid
              
              
                    
                  
              
            In addition to highlighting Amazon's "perceived lag in the AI space," the internal document said generative AI has further intensified the competition for specialized talent, particularly individuals with expertise in large language models.An August report from venture capital firm SignalFire shows Amazon is on the lower end of engineering retention, far below Meta, OpenAI, and Anthropic. Jarod Reyes, SignalFire's head of developer community, told Business Insider that Amazon rivals are making bigger strides in AI, across open models, foundational research, and developer tooling."Amazon hasn't clearly positioned itself as a leader in the generative AI wave," Reyes said. "Engineers are paying attention and they're voting with their feet."
              
              
              
              
                
            
              
              
              
            
              
              
                    
                      SignalFire chart on engineering talent retention
                      
              
              
              SignalFire
              
              
                    
                  
              
            Some investors share that view. On Amazon's earnings call last month, Morgan Stanley analyst Brian Nowak pressed CEO Andy Jassy on Wall Street's "narrative right now that AWS is falling behind" in AI and fears of losing market share to rivals. Jassy's response fell flat, sending Amazon's stock lower during the call.Amazon intends to tackle these concerns. According to the document, the company will refine its "compensation and location strategy" and host more events designed to highlight its generative AI capabilities. It also intends to set up dedicated recruiting teams for generative AI within business units like AWS to boost efficiency.'Hubs' constrain talent
              
              
              
              
                
            
              
              
              
            
              
              
                    
                      Hundreds of tech workers gathered outside Amazon's headquarters in Seattle.
                      
              
              
              REUTERS/Lindsey Wasson
              
              
                    
                  
              
            Another point of contention is Amazon's aggressive return-to-office mandate, which has already caused logistical issues.The company's new "hub" policy â which requires employees to relocate to a central office or risk termination â has further limited its access to "high-demand talent like those with GenAI skills," according to the internal document."Hubs constrain market availability," it stated.Amazon is exploring ways to allow for more "location-flexible" roles, the document added.Amazon's spokesperson told BI that the company is "always looking for ways to optimize our recruiting strategies and looking at alternate talent rich locations."Amazon hasn't been entirely on the sidelines. Last year, it brought on Adept CEO David Luan as part of a licensing deal with the AI startup. Luan now heads Amazon's AI agents lab. But the company has also seen departures, including senior AI leaders like chip designer Rami Sinno and VP Vasi Philomin, who worked on Bedrock.One Amazon recruiter told Business Insider that a growing number of job candidates started declining offers last year because of the company's RTO policy. Even if a competitor pays less, people are open to taking the job if they can stay remote, this person said."We are losing out on talent," this person added.Indeed, Bloomberg reported recently that Oracle has hired away more than 600 Amazon employees in the past two years because Amazon's strict RTO policy has made poaching easier.Staying the courseThe internal Amazon document dates to late last year, leaving open the possibility that the company has since adjusted its compensation approach to make exceptions for top AI talent.Still, multiple people familiar with the situation told Business Insider there haven't been any formal updates to internal pay guidelines. One current Amazon manager said it remains almost impossible for the company to enact sweeping changes, given its long track record of sticking to the existing system. The people who spoke with Business Insider asked not to be identified discussing sensitive matters."Based on how we run our business and what we have achieved, there are more risks than potential benefits from changing an approach that has been so successful for our shareholders over the past several decades," Amazon wrote this year about executive compensation in its annual proxy statement.Of course, the AI talent war may end up being an expensive and misguided strategy, stoked by hype and investor over-exuberance.Some of the high-profile recruits Meta recently lured have already departed.Have a tip? Contact this reporter via email at ekim@businessinsider.com or Signal, Telegram, or WhatsApp at 650-942-3061. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.
            
            
            
            
            
            
            
              
            
    
    
    
    
      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Thoughts on (Amazonian) leadership]]></title>
            <link>https://www.daemonology.net/blog/2025-09-01-Thoughts-on-Amazonian-Leadership.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45095545</guid>
            <description><![CDATA[Amazon's
Leadership
Principles are famous, not just within Amazon but also in the tech
world at large.  While they're frequently mocked â including by
Amazonians â they're also generally sensible rules by which to run
a company.  I've been an Amazon customer for over 25 years and an AWS
customer for almost 20 years, and also an
AWS Hero
for 6 years, and while I've never worked for Amazon I feel that I've seen
behind the curtain enough to offer some commentary on a few of these
principles.]]></description>
            <content:encoded><![CDATA[

Amazon's
Leadership
Principles are famous, not just within Amazon but also in the tech
world at large.  While they're frequently mocked â including by
Amazonians â they're also generally sensible rules by which to run
a company.  I've been an Amazon customer for over 25 years and an AWS
customer for almost 20 years, and also an
AWS Hero
for 6 years, and while I've never worked for Amazon I feel that I've seen
behind the curtain enough to offer some commentary on a few of these
principles.

Customer Obsession: Leaders start with the customer and work backwards.
They work vigorously to earn and keep customer trust. Although leaders pay
attention to competitors, they obsess over customers.

Customer Obsession is great, but I often see Amazonians taking this too
simplistically: "Start with the customer" doesn't have to mean "ask customers
what they want and then give them faster horses".  In the early days of AWS I
saw a lot of what I call "cool engineering driven" products: When EC2
launched, it wasn't really clear what people would do with it, but it was
very cool and it was clear that it could be a big deal in some form, sooner
or later.  Some time around 2012, the culture in AWS seemed to shift from
"provide cool building blocks" to "build what customers are asking for" and
in my view this was a step in the wrong direction (mind you, not nearly as
much as the ca. 2020 shift to "build what analysts are asking for in quarterly
earnings calls").

This tension of what customers are asking for vs what customers really need
shows up in areas like resilience.  Amazon's "Well-Architected Framework"
strongly exhorts customers to avoid building production workloads in a single
Availability Zone â but Amazon's cross-AZ bandwidth pricing is painful,
and Amazon doesn't provide useful tools for building durable multi-AZ
applications.  Most customers are not going to implement Paxos, and very few
customers â certainly not executives who are removed from actual
development processes â are going to ask Amazon for Paxos-as-a-service;
but if Amazonians sat down and asked themselves "what do customers need in
order to design their applications well" they could probably come up with
several services which Amazon already has internally.  AWS should
return to its roots and release important building blocks â the things
customers will need, not necessarily what they're asking for.

Ownership: Leaders are owners. They think long term and don't sacrifice
long-term value for short-term results. They act on behalf of the entire
company, beyond just their own team. They never say "that's not my job."

This principle is both too narrow, and not being fulfilled, in my view.  It's
not enough to simply act on behalf of the entire company: It's important to
act on behalf of the entire technological ecosystem.  Some Amazonians are great
at this â I recently commited patches to FreeBSD's bhyve because an
Amazonian was putting together a standard for interrupt handling in large VMs,
and even though Amazon doesn't make any use of bhyve (at least, I don't think
it does!)  he understood the importance of getting standards widely accepted
across the entire virtualization space rather than narrowly in the code Amazon
relied upon.  There's a saying in computer security, that anything which makes
one of us less secure makes all of us less secure: Attackers will leverage an
exploit against one system to allow them to attack another system.  While the
same does not directly apply in other fields, working with others to
produce the best results for everyone will be much better in the long-term
than focusing solely on what Amazon needs right now.

But in general Amazon doesn't even live up to its stated (narrow) promise of
having leaders acting on behalf of the entire company â it's simply too
siloed.  Amazon is famously secretive, and this applies internally as well as
externally: When AWS launches two similar services, it's often because two
teams didn't know what each other was working on.  How can leaders act across
the entire company if nobody knows what's happening outside of their team?
They can't; and if Amazon wants to allow its best people to be true Owners,
Amazon needs to start breaking down walls.

Bias for Action: Speed matters in business. Many decisions and actions
are reversible and do not need extensive study. We value calculated risk
taking.

Amazonians talk about "one-way doors" and "two-way doors", and it is quite
true that many decisions are can be reversed... but that doesn't always
mean that there is no cost associated with reversing a decision.  There
is a clear and widely recognized tension between "Bias for Action" and another
principle, "Insist on the Highest Standards"; but there is also a tension
between this and earning and keeping customer trust.  When AWS ships a service
which is half-baked, it diminishes customer trust in AWS as a whole; even if
the problems in that service ultimately get corrected (either by fixing them
or in some cases by simply getting rid of a service which should never have
existed in the first place) the memory of a failed launch will live on in
customers' minds for years to come.

During my seven-year tenure as FreeBSD Security Officer, people knew me as
the guy sending out security advisories; but the most important thing I did
was not to ship Security Advisories â that is, it was to stop the
train and say "no, we are not going to send this out yet".  I knew that for all
the importance of getting patches into people's hands in a timely manner, it
was even more important to establish trust: If I gave people a broken patch, even
once, they would be much slower to install security updates in the future.  My
team became familiar with the phrase "convince me that this is correct", and
I'd like to see more of that at senior levels of Amazon: Principal and
Distinguished Engineers need to step in with a bias for inaction, and
use the respect they have earned to stop projects which do not meet the
highest standards before they undermine trust.  Amazon's hiring process
famously includes "bar raisers" who can veto hiring decisions; they should
also have service bar raisers who can veto launches.

Werner Vogels famously said in his 2024 re:Invent keynote, "Listen to the AWS
Heroes".  I think he was talking about technical advice, and perhaps speaking
mainly to AWS customers; but I like to think that Amazon might also benefit
listening to some of what I've said here.  We criticize because we care. 




blog comments powered by Disqus
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The future of 32-bit support in the kernel]]></title>
            <link>https://lwn.net/SubscriberLink/1035727/4837b0d3dccf1cbb/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45095475</guid>
            <description><![CDATA[Arnd Bergmann started his Open Source Summit Europe 2025 talk with a clear statement of positio [...]]]></description>
            <content:encoded><![CDATA[


Welcome to LWN.net

The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider subscribing to LWN.  Thank you
for visiting LWN.net!



Arnd Bergmann started his Open
Source Summit Europe 2025 talk with a clear statement of position: 32-bit
systems are obsolete when it comes to use in any sort of new products.  The
only reason to work with them at this point is when there is existing
hardware and software to support.  Since Bergmann is the overall maintainer
for architecture support in the kernel, he is frequently asked whether
32-bit support can be removed.  So, he concluded, the time has come to talk
more about that possibility.


People naturally think about desktop machines first, he continued.  If you
were running Linux in the 1990s, you had a 32-bit, desktop system.  Unix
systems, though, moved to 64-bit platforms around 30Â years ago, and
the Linux desktop made that move about 20Â years ago.  Even phones and
related devices have been 64-bit for the last decade.  If those systems
were all that Linux had to support, 32-bit support would have long since
been removed from the kernel.  He summarized the situation with this slide,
showing how the non-embedded architectures have transitioned to either
64-bit or nonexistence over time:




The world is not all desktops â or servers â though; embedded Linux exists
as well.  About 90% of those systems are running on Arm processors.  The
kernel has accumulated a lot of devicetree files describing those systems
over the years; only in this last year has the number of devicetrees for
armv8 (64-bit) systems exceeded the number for armv7 (32-bit) systems.

For Arm processors with pre-armv7 architectures, there are only three for
which it is still possible to buy hardware, but a number are still
supported by the kernel community:






Many other pre-armv7 CPUs are out of production,
but the kernel still has support for them.  Of those, he said, there are
about ten that could be removed now.  It would be nice to be able to say
that support for the others will be removed after a fixed period, ten years
perhaps, but hardware support does not work that way.  Instead, one has to
think in terms of half lives; every so often, it becomes possible to remove
support for half of the platforms.  It all depends on whether there are
users for the processors in question.

The kernel is still adding support for some 32-bit boards, he said, but at
least ten new 64-bit boards gain support for each 32-bit one.

There are a number of non-Arm 32-bit architectures that still have support
in the kernel; these include arc, microblaze, nios2, openrisc, rv32,
sparc/leon, and xtensa.  All of them are being replaced by RISC-V
processors in new products.  RISC-V is what you use if you don't care about
Arm compatibility, he said.

Then, there is the dusty corner where nommu (processors without a
memory-management unit) live; these include armv7-m, m68k, superh, and
xtensa.  Nobody is building anything with this kind of hardware now, and
the only people who are working on them in any way are those who have to
support existing systems.  "Or to prove that it can be done."

There are still some people who need to run 32-bit applications that cannot
be updated; the solution he has been pushing people toward is to run a
32-bit user space on a 64-bit kernel.  This is a good solution for
memory-constrained systems; switching to 32-bit halves the memory usage of
the system.  Since, on most systems, almost all memory is used by user
space, running a 64-bit kernel has a relatively small cost.  Please, he
asked, do not run 32-bit kernels on 64-bit processors.




There are some definite pain points that come with maintaining 32-bit
support; most of the complaints, he said, come from developers in the
memory-management subsystem.  The biggest problem there is the need to
support high memory; it is complex, and requires support throughout the
kernel.  High memory is needed when the kernel lacks the address space to
map all of the installed physical memory; that tends to be at about 800MB
on 32-bit systems. (See this article for
more information about high memory).

Currently the kernel is able to support 32-bit systems with up to 16GB of
installed memory.  Such systems are exceedingly rare, though, and support
for them will be going away soon.  There are a few 4GB systems out there,
including some Chromebooks.  Systems with 2GB are a bit more common.  Even
these systems, he said, are "a bit silly" since the memory costs
more than the CPU does.  There are some use cases for such systems, though.
Most 32-bit systems now have less than 1GB of installed memory.  The
kernel, soon, will not try to support systems with more thanÂ 4GB.

There are some ideas out there for how to support the larger-memory 32-bit
systems without needing the high-memory abstraction.  Linus Walleij is
working on entirely separating the kernel and user-space address spaces,
giving each 4GB to work with; this is a variant on the "4G/4G" approach
that has occasionally been tried for many years.  It is difficult to make
such a system work efficiently, so this effort may never succeed, Bergmann
said.

Another approach is the proposed "densemem" memory model, which does some
fancy remapping to close holes in the physical address space.  Densemem can
support up to 2GB and is needed to replace the
SPARSEMEM memory model, the removal of which which will eventually be
necessary in any case.  This work has to be completed before high memory
can be removed; Bergmann said that he would be interested in hearing from
potential users of the densemem approach.

One other possibility is to drop high memory, but allow the extra physical
memory to be used as a zram swap
device.  That would not be as efficient as accessing the memory directly,
but it is relatively simple and would make it possible to drop the
complexity of high memory.

Then, there is the year-2038 problem, which
he spent several years working on.  The kernel-side work was finished in
2020; the musl C library was updated that same year, and the GNU C
Library followed the year after.  Some distributors have been faster than
others to incorporate this work; Debian and Ubuntu have only become
year-2038-safe this year.

The year-2038 problem is not yet completely solved, though; there are a lot
of packages that have unfixed bugs in this area.  Anything using futex(),
he said, has about a 50% chance of getting time handling right.  The legacy
32-bit system calls, which are not year-2038 safe, are still enabled in the
kernel, but they will go away at some point, exposing more bugs.  There are
languages, including Python and Rust, that have a lot of broken language
bindings.  Overall, he said, he does not expect any 32-bit desktop system to
survive the year-2038 apocalypse.

A related problem is big-endian support, which is also 32-bit only, and
also obsolete.  Its removal is blocked because IBM is still supporting
big-endian mainframe and PowerPC systems; as long as that support
continues, big-endian support will stay in the kernel.

A number of other types of support are under discussion.  There were once
32-bit systems with more than eight CPUs, but nobody is using those
machines anymore, so support could be removed.  Support for armv4
processors, such as the DEC StrongARM CPU,
should be removed.  Support for early armv6 CPUs, including the omap2 and
i.mx31, "complicates everything"; he would like to remove it, even
though there are still some Nokia
770 systems in the wild.  The time is coming for the removal of all
non-devicetree board files.  Removal of support for CortexÂ M CPUs,
which are nommu systems, is coming in a couple of years.  Developers are
eyeing i486 CPU support, but that will not come out yet.  Bergmann has sent
patches to remove support for KVM on 32-bit CPUs, but there is still
"one PowerPC user", so that support will be kept for now.

To summarize, he said, the kernel will have to retain support for armv7
systems for at least another ten years.  Boards are still being produced
with these CPUs, so even ten years may be optimistic for removal.
Everything else, he said, will probably fade away sooner than that.  The
removal of high-memory support has been penciled in for sometime around
2027, and nommu support around 2028.  There will, naturally, need to be
more discussion before these removals can happen.

An audience member asked how developers know whether a processor is still
in use or not; Bergmann acknowledged that it can be a hard question.  For
x86 support, he looked at a lot of old web pages to make a list of which
systems existed, then showed that each of those systems was already broken
in current kernels for other reasons; the lack of complaints showed that
there were no users.  For others, it is necessary to dig through the Git
history, see what kinds of changes are being made, and ask the developers
who have worked on the code; they are the ones who will know who is using
that support.

Another person asked about whether the kernel would support big-endian
RISC-V systems.  Bergmann answered that those systems are not supported
now, and he hoped that it would stay that way.  "With RISC-V, anybody
can do anything, so they do, but it is not always a good idea".  The
final question was about support for nommu esp32 CPUs; he answered that
patches for those CPUs exist, but have not been sent upstream.  Those
processors are "a cool toy", but he does not see any practical
application for them.

The slides
for this talk are available.  The curious may also want to look at Bergmann's 2020 take on this topic.


[Thanks to the Linux Foundation, LWN's travel sponsor, for supporting my
travel to this event.]
           Index entries for this article
           KernelArchitectures
            ConferenceOpen Source Summit Europe/2025
            

               
               
            ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Implementing a Foil Sticker Effect]]></title>
            <link>https://www.4rknova.com/blog/2025/08/30/foil-sticker</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45095460</guid>
            <description><![CDATA[A breakdown of how to build a custom Three.js shader that recreates the iridescent, sparkling look of foil stickers using vertex deformation, angle-based color shifts, and procedural flakes.]]></description>
            <content:encoded><![CDATA[In this post, Iâll walk you through how to create a custom shader in Three.js that simulates the look of a foil sticker, complete with angle-dependent iridescence and sparkling metallic flakes. The goal is to capture that premium, holographic effect you see on collectible stickers, trading cards, and high-end packaging, but to render it in real time directly in the browser.IridescenceIf youâve ever tilted a holographic sticker or watched sunlight catch on a soap bubble, youâve seen iridescence in action. In the real world, this rainbow shimmer comes from thin-film interference. When light waves bounce between layers of a surface, some wavelengths are reinforced while others cancel out, causing colors to shift depending on your viewing angle.In real-time computer graphics, we donât need to simulate the exact physics. Instead, we can approximate this by mapping view angle to hue, as the surface tilts relative to the camera, its color smoothly shifts through a spectrum. This gives that dynamic, âaliveâ quality you expect from foil stickers.Foil FlakesAlongside the shifting colors, thereâs another key detail: foil flakes. Real metallic foils have tiny reflective particles embedded in them, creating hundreds of bright, sharp highlights that twinkle as you move. These arenât smooth reflections but randomized sparkles, giving the surface its tactile, premium feel.To replicate this in a shader, weâll introduce procedural noise to generate small random patches of brightness across the surface. When combined with lighting, they look like metallic specks catching the light. Together, angular hue shifts and flake sparkles create a convincing illusion of printed holographic foil without expensive rendering tricks.ImplementationThis implementation simulates a peeling, iridescent sticker with foil flakes using Three.js. While I will borrow concepts such as metalness, roughness, and Fresnel from Physically Based Rendering (PBR), this shader is not physically based. The goal is to create a visually plausible, artistic effect.Below is a live demo of the shader, where you can modify its parameters and experiment with different configurations. Use your mouse to rotate the sticker around and see how the material reacts to the lighting.Vertex ShaderThe vertex shader handles the peel geometry and passes useful information to the fragment shader.Uniform / VaryingTypePurposeuPeelAmountfloatOverall peel strength (0 = flat, 1 = fully peeled).uPeelAnglefloatPeel direction in degrees.vUvvec2UV coordinates for texture mapping.vWorldPosvec3Vertex position in world space.vNormalvec3Transformed normal for lighting.vAOIntensityfloatDistance moved by vertex, used to darken lifted areas.The shader goes through the following simple steps:Compute vector from hinge to current vertex.Calculate the peel factor and angle.Define the rotation axis and apply Rodriguesâ rotation formula to rotate the vertex around that axis.Apply the same rotation to the normal.Calculate a fake ambient occlusion term.Hereâs the full vertex shader code:uniform float uPeelAmount;  // Strength of peel (0.0 â no peel, 1.0 â full peel)
uniform float uPeelAngle;   // Peel angle in degrees (converted to radians in shader)
varying vec2  vUv;          // UV coordinates
varying vec3  vWorldPos;    // Vertex position in world space
varying vec3  vNormal;      // Transformed vertex normal
varying float vAOIntensity; // Ambient occlusion or peel intensity factor

void main() {
    vUv = vec2(uv.x, 1.0 - uv.y);
    vec3 pos = position;

    // Define hinge point for peel
    vec3 hinge = vec3(0.0, 0.0, 0.0);

    // Vector from hinge to current vertex
    vec3 toVertex = pos - hinge;

    // Peel factor calculation
    // Interpolates peel strength diagonally
    // (bottom-left â top-right)
    float peelFactor = (uv.x + uv.y) * 0.5;

    // Convert peel angle to radians
    // Final angle is scaled by peelAmount
    // and per-vertex peelFactor
    float radAngle = radians(uPeelAngle);
    float angle = radAngle * uPeelAmount * peelFactor;

    // Define rotation axis for peel
    // Diagonal axis pointing from top-left 
    // to bottom-right
    vec3 axis = normalize(vec3(-1.0, 1.0, 0.0));
    float cosA = cos(angle);
    float sinA = sin(angle);

    // Apply Rodrigues' rotation formula
    // Rotates the vertex around the diagonal axis
    vec3 rotated = toVertex * cosA +
                   cross(axis, toVertex) * sinA +
                   axis * dot(axis, toVertex) * (1.0 - cosA);

    // Update vertex position after rotation
    pos = hinge + rotated;

    // Rotate vertex normal the same way to
    // ensure lighting matches the peeled
    // geometry
    vec3 rotatedNormal = normal * cosA +
                         cross(axis, normal) * sinA +
                         axis * dot(axis, normal) * (1.0 - cosA);

    // Transform normal into view space
    vNormal = normalize(normalMatrix * rotatedNormal);

    // Transform vertex to world space
    vec4 worldPos = modelMatrix * vec4(pos, 1.0);
    vWorldPos = worldPos.xyz;

    // Ambient Occlusion term based on distance moved
    // from original vertex position
    vAOIntensity = length(toVertex - rotated);

    // Final projection
    gl_Position = projectionMatrix * viewMatrix * worldPos;
}
Fragment ShaderThe fragment shader handles all lighting, reflections, iridescence, and foil flakes. It layers procedural effects to create a rich, dynamic look.UniformTypePurposemapsampler2DSticker albedo + alpha.envMap2Dsampler2DEnvironment map for reflections.uCameraPosvec3Camera position for view vector.uAlphaCutofffloatDiscard pixels below this alpha.uFlakesEnabledfloatToggle foil flakes.uFlakeSizefloatSize of flakes.uFlakeReductionfloatRandomness threshold for flakes.uFlakeThresholdfloatBrightness threshold to show flakes.uFlakeBrightnessfloatBase brightness of flakes.uMetalnessfloatPBR-like metal reflectivity control.uRoughnessfloatControls reflection sharpness.uEnvIntensityfloatScales environment contribution.uMetalmaskfloatMask controlling metallic regions.uIridescencefloatStrength of angle-dependent rainbow effect.uIriMin, uIriRangefloatRange for simulated film thickness.uPeelAmount, uPeelAnglefloatPeel geometry info for shading.This is how this works:Alpha cutoff to discard transparent pixels early.Back-face shading to render the rear surface as plain white or darkened, depending on peel.Foil flakes are computed using procedural noise. Normals are perturbed slightly to create sparkle variation. The environment map is sampled to get an iridescent tint.Iridescence (thin-film approximation) is calculated using sine-based waves to shift hue by view angle.Environment reflections are modulated by Fresnel.Final shading combines diffuse base, reflections, iridescence, and flakes.Hereâs the full vertex shader code:precision highp float;

#define PI  3.14159265

varying vec2 vUv;
varying vec3 vNormal;
varying vec3 vWorldPos;
varying float vAOIntensity;

uniform sampler2D map;      // sticker albedo + alpha
uniform sampler2D envMap2D; // LDR equirectangular environment

uniform vec3  uCameraPos;
uniform float uAlphaCutoff;
uniform float uMaxMip;
uniform float uFlakesEnabled;
uniform float uFlakeSize;
uniform float uFlakeReduction;
uniform float uFlakeThreshold;
uniform float uFlakeBrightness;
uniform float uPeelAmount;
uniform float uPeelAngle;
uniform float uMetalness;
uniform float uRoughness;
uniform float uEnvIntensity;
uniform float uMetalmask;
uniform float uIridescence;
uniform float uIriMin;
uniform float uIriRange;

float hash(vec2 p) {
    return fract(sin(dot(p, vec2(127.1, 311.7))) * 43758.5453123);
}

// Map 3D dir to 2D equirect UV
vec2 dirToEquirectUv(vec3 dir) {
    dir = normalize(dir);
    float phi = atan(dir.z, dir.x);
    float theta = acos(clamp(dir.y, -1.0, 1.0));
    return vec2((phi + 3.14159265) / (2.0 * 3.14159265), theta / 3.14159265);
}

vec3 sampleEnvRough(vec3 R, float roughness) {
    vec2 uv = dirToEquirectUv(R);

    // Map roughness to LOD level
    float lod = roughness * uMaxMip;
    vec3 color = texture2DLodEXT(envMap2D, uv, lod).rgb;

    return color;
}

// Iridescence / thin-film color
vec3 iridescenceColor(float cosTheta) {
    float thickness = uIriMin + uIriRange * (1.0 - cosTheta);
    float phase = 6.28318 * thickness * 0.01; // scaled for visuals
    vec3 rainbow = 0.5 + 0.5 * vec3(sin(phase), sin(phase + 2.094), sin(phase + 4.188));
    return mix(vec3(1.0), rainbow, uIridescence);
}

// Convert RGB to perceived luminance (Rec.709)
float luminance(vec3 color) {
    return dot(color, vec3(0.2126, 0.7152, 0.0722));
}

void main() {

    vec4 base = texture2D(map, vUv);
    if(base.a < uAlphaCutoff)
        discard;

    if(!gl_FrontFacing) {
        float col = 1.0;
        if(uPeelAngle > 0.0) {
            col = mix(1.0, 0.2, vAOIntensity);
        }
        // Render back side as white
        gl_FragColor = vec4(vec3(col), base.a);
        return;
    }

    vec3 N = normalize(vNormal);
    vec3 V = normalize(uCameraPos - vWorldPos);
    vec3 R = reflect(-V, N);

    // Ambient occlusion / peel shadow
    float peelShadow = 0.0;

    if(uPeelAngle < 0.0) {
        peelShadow = smoothstep(0.0, 0.3, vAOIntensity);
        base.rgb *= mix(1.0, 0.3, peelShadow);
    }

    // Flakes
    float flakeIntensity = 0.0;
    vec3 flakeEnv = vec3(0.0);

    float brightness = luminance(base.rgb);

    if(uFlakesEnabled > 0.5) {
        // Procedural flake mask
        float flake = hash(floor(vUv * uFlakeSize));
        float flakeMask = smoothstep(uFlakeReduction, 1.0, flake);

        // Base brightness influence
        float flakeBoost = smoothstep(uFlakeThreshold, 1.0, brightness);

        // Perturbed flake normal
        float angleOffset = (hash(vec2(flake, flake + 3.0)) - 0.5) * 0.25;
        vec3 perturbedNormal = normalize(N + vec3(angleOffset, 0.0, angleOffset));

        // Reflection for sparkle
        vec3 PR = reflect(-V, perturbedNormal);

        // Dynamic flicker factor (only brightens, never darkens)
        float flakePhase = hash(floor(vUv * uFlakeSize) + floor(PR.xy * 15.0));
        float phaseMod = mix(1.0, 1.8, flakePhase);
        
        // Core sparkle factor (glimmer preserved)
        float flakeSpec = pow(clamp(dot(perturbedNormal, V) * 0.5 + 0.5, 0.0, 1.0), 8.0);
        flakeSpec = max(flakeSpec, 0.15); // always visible

        // Environment tint (never too dark, controlled by uniform)
        float flakeRough = clamp(uRoughness * 0.4, 0.0, 1.0);
        flakeEnv = sampleEnvRough(PR, flakeRough) * mix(0.9, 1.2, brightness);
        flakeEnv = max(flakeEnv, vec3(uFlakeBrightness));

        vec3 flakeIri = iridescenceColor(dot(perturbedNormal, V));
        flakeEnv *= mix(vec3(1.0), flakeIri, 0.9);

        // Final intensity
        flakeIntensity = flakeMask * flakeBoost * flakeSpec * phaseMod * 18.0;
        flakeIntensity = clamp(flakeIntensity, 0.0, 1.0);
    }

    // Final roughness modulation
    float finalRough = clamp(mix(uRoughness, 1.0, flakeIntensity), 0.0, 1.0);

    // Environment reflection
    vec3 env = sampleEnvRough(R, finalRough) * uEnvIntensity;

    // Blend in flake environment contribution
    env = mix(env, flakeEnv, clamp(flakeIntensity, 0.0, 1.0));

    // Fresnel term
    float cosTheta = clamp(dot(N, V), 0.0, 1.0);
    float F0 = mix(0.04, 1.0, uMetalness);
    float fres = F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);

    // Iridescence
    float metalicMask = mix(uMetalmask, 1.0, brightness);
    vec3 iriCol = iridescenceColor(cosTheta) * metalicMask;

    // Final color
    vec3 diffuse = base.rgb * (1.0 - uMetalness);
    vec3 spec = env * fres * iriCol * (1.0 - finalRough * 0.85);
    vec3 color = diffuse + spec;

    gl_FragColor = vec4(color, base.a);
}
LicensingThe code in this page is licensed under Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0). Feel free to share and adapt the code for non-commercial purposes with proper attribution. If you wish to use the code commercially, please contact me for a separate license agreement.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[One of Britain's largest stocks of second-hand books ever amassed]]></title>
            <link>https://www.worldofinteriors.com/story/richard-axe-second-hand-books-yorkshire</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45094692</guid>
            <description><![CDATA[Bookseller Richard Axe has amassed 150,000 second-hand books and housed them in a vast youth hostel in the Yorkshire Dales. Now a buyer is sought]]></description>
            <content:encoded><![CDATA[Richard Axe is celebrated in the bookselling trade for owning one of the largest collections of antiquarian and second-hand volumes ever assembled. Since 2005, his stock has been arrayed in a huge former youth hostel in the Yorkshire Dales, but now his career is approaching its coda30 August 2025An American-themed section faces the viewer in a room devoted to Art and DesignOne of Britainâs largest stocks of second-hand books ever amassed can be found in the unlikeliest of locations: a vast former youth hostel in a pretty corner of the Yorkshire Dales. Meticulously sorted into subject areas, from naval history to 19th-century literature, architecture to zoology, over 150,000 volumes fill some 25 high-ceilinged rooms spread over four floors. To withstand the sheer weight of all those hardbacks, the building, which began life as a prep school in c1878, must surely be as strong as a Romanesque church.Certainly the collection has been assembled with an almost religious zeal by sole trader Richard Axe, a spry 70-something who spoke to me from the Philippines, where he lives with his wife roughly half the year. Unlike the more commercially oriented of his peers, he has sold books primarily so that he could acquire more for himself. Of the Harrogate shop he owned prior to his move here he says: âIts main purpose was not to sell at all, but rather to buy and increase my buying profile.â I had fondly imagined that Richard chose Aysgarth in order to lure customers from the nearby falls, a daytrippersâ magnet. But in fact, he says heâs never advertised, nor had more than four visitors per week, and all of them were by appointment. Yet very rarely did a week pass by without him shifting at least Â£1,000 worth of books.Stacked from floor to ceiling with second-hand books, the 25-room former youth hostel in Aysgarth, North Yorkshire, has been occupied by bookseller Richard Axe for two decades
So how did his business, which has been highly successful, operate? Most professionals in the field swim in the waters of either âgood quality but relatively ordinary second-hand booksâ or âvery specialist, expensive antiquarian booksâ; Richard has ended up being a big fish in both streams. In his heyday, he would reckon to drive some 25,000 miles a year, attending auctions from Plymouth to Glasgow. There heâd bid for large lots, sometimes whole libraries, subsequently selling a handful of important titles to private customers and international dealers, while creaming off books for his own collection. Hence, in part, the appeal of North Yorkshire. Far from being âthe back of beyondâ, the A1, M1 and East Coast mainline railway offer superb connections. âI like the idea of being in the middle of the country.âThe custom-built wooden shelves stretch to a combined length of over a mile
Art and design books, recently purchased, await shelving. Prominent in the pile is a book by the late artist and postcard aficionado Tom Phillips, whose house was featured in WoI Sept 2025
An armchair with access to plenty of light creates a reading nook between two stacks
For the eagle-eyed expert, the condition of a book is critical. Richard gives the example of Dickens â âincredibly popular in his own lifetime, and so a first edition in reasonably good nick might fetch Â£50. But a really fine copy could go for ten times that.â As is the case with all antiques, the internet has had a polarising effect. In the past, you might have traipsed round bookshops for a lifetime not finding the missing piece in your authorial jigsaw, but often such editions previously thought rare can now be quite easily unearthed via online search engines, and so their value has slumped. âBut whatâs transpired is that things that are genuinely uncommon have shot up.âA run of spines from Collinsâs âNew Naturalistâ series offers a burst of colour in a top-floor room devoted to zoology, topography and horticulture
The classic case is JK Rowlingâs Harry Potter and the Philosopherâs Stone. Given that it was the first in the sequence, Bloomsbury, with no inkling of the monster the brand would become, published the smallest viable number of copies â 500 â in its first edition. It is thus truly rare, says Richard, much more so than a Jane Austen equivalent. As a consequence: âA fine copy is worth, certainly, Â£50,000.â Similarly, photograph albums and manuscripts, by definition one-off items, have seen skyrocketing interest in cyberspace â and among a new, younger breed of collector to boot. Indeed, the most expensive item my interlocutor has ever sold was not a book at all, but a scrapbook owned by Cecil Beaton, which included the photographerâs own drawing of Mick Jagger, a personal friend, and sketches by Jean Cocteau.A map of York reflects the rolling dales in a room devoted to leather-bound antiquarian books
Richard Axe has deployed every little sliver of real estate to house his 150,000-plus books. A staircase makes the ideal spot for shelving titles about mountaineering and hiking
When Richard moved to his property in 2005, consolidating a warehouse, shop and large house in Harrogate, little structural work was required to the sturdily built edifice apart from new guttering, though he had to strip out rows of urinals and a few municipal-style kitchens. Inevitably, however, two men were employed full time for a year just building wooden shelves, which now stretch to a combined length of over a mile. The original plan was to carve out some domestic space in this behemoth of a building, but Richard states that mixing residence and business had potential VAT implications. And then there was the small issue of his ever-encroaching libraryâ¦ So he moved into the two-bedroom modern cottage previously inhabited by the youth-hostel manager. Presumably you had a no-book policy here, I ask Richard. âWell, if I did, it didnât last,â he replies ruefully. âLetâs just say it was restricted.âThis two-bedroom cottage, built in the 1980s, is where the youth-hostel manager used to live. Now Richard relaxes here after a hard day humping boxes, cataloguing and shelving
Philosophical follies, such as doorknobs surreally attached to tree trunks, dot the unusual sculpture garden that Richard has proudly created out of a capacious paddock thatâs part of the estate. In the middle of the pond sits an inaccessible table and chairs overhung with a metal fruit basket you also cannot reach. âItâs all about, you know, the unattainable.â This modern take on the Tantalus myth strikes me as the perfect symbol for the avid collector, feverishly hunting down the final piece of a set, mourning the rarities that slipped through oneâs fingers. The psychological make-up of the type emerged early on. Even as a Dulwich College scholarship boy, âI collected stamps rather more avidly than most.â Later, at Bristol University, âI bought books initially to read, but the physical possession of having quite a lot, of having a substantial range of bookshelves, became important as a manifestation of knowledge and understanding and culture.â Even now, he can find himself transfixed when, say, a history of signposts tumbles into his lap.Richardâs modern version of the Tantalus myth is a table and chairs in the middle of a pond, overhung with an unreachable fruit bowl. In the background lies the Grade I-listed St Andrewâs church, known as the âCathedral of the Dalesâ
The vast former hostel and its contents are now on the market. Richard is loath to break up his collection
The physical demands of his job, combined with declining health, mean Richard âmust face the facts of ageâ. With great reluctance, he is now selling his estate and collection, lock, stock and barrel, for around Â£1.5 million. His greatest fear is that the land, library and buildings get sold off bit by bit, âmy lifeâs work just disappearingâ. He is even prepared to play the role of Ã©minence grise to the putative lucky buyer, sharing his contacts and experience.A room devoted to British history. Richard employed two men full-time for a year to construct bookshelves
But what about the keepers? Surely, there are a few titles heâd like to hold on to? Well, thereâs his extensive collection of antiquarian books on Yorkshire; those on another great love, football (âthough the Philippines is pretty much the only country in the world that doesnât have an interestâ); books on the fluctuatingly fashionable Ruskin, as well as 18th- and 19th-century folding maps that the chin-stroking aesthete might have consulted himself while hiking in the Lakes. Oh, and letâs not forget the collection of 1750sâ1870s books in their original drab boards or cloth. âCheaper to buy at the time, because they were unbound, they are now valuable because of their fragility.â The booksellerâs eyes sparkle.To enquire about purchasing the property plus stock, ring Elaine Williams-Bird on 07798 818651 or email nellybirdpress@gmail.comIn your inbox: get our bi-weekly newsletter, featuring letters from the editor and exclusive featuresInterested in writing for The World of Interiors? Find out howRead More]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Adaptive LLM routing under budget constraints]]></title>
            <link>https://arxiv.org/abs/2508.21141</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45094421</guid>
            <description><![CDATA[Large Language Models (LLMs) have revolutionized natural language processing, but their varying capabilities and costs pose challenges in practical applications. LLM routing addresses this by dynamically selecting the most suitable LLM for each query/task. Previous approaches treat this as a supervised learning problem, assuming complete knowledge of optimal query-LLM pairings. However, real-world scenarios lack such comprehensive mappings and face evolving user queries. We thus propose to study LLM routing as a contextual bandit problem, enabling adaptive decision-making using bandit feedback without requiring exhaustive inference across all LLMs for all queries (in contrast to supervised routing). To address this problem, we develop a shared embedding space for queries and LLMs, where query and LLM embeddings are aligned to reflect their affinity. This space is initially learned from offline human preference data and refined through online bandit feedback. We instantiate this idea through Preference-prior Informed Linucb fOr adaptive rouTing (PILOT), a novel extension of LinUCB. To handle diverse user budgets for model routing, we introduce an online cost policy modeled as a multi-choice knapsack problem, ensuring resource-efficient routing.]]></description>
            <content:encoded><![CDATA[
    
    
                
    View PDF
    HTML (experimental)
            Abstract:Large Language Models (LLMs) have revolutionized natural language processing, but their varying capabilities and costs pose challenges in practical applications. LLM routing addresses this by dynamically selecting the most suitable LLM for each query/task. Previous approaches treat this as a supervised learning problem, assuming complete knowledge of optimal query-LLM pairings. However, real-world scenarios lack such comprehensive mappings and face evolving user queries. We thus propose to study LLM routing as a contextual bandit problem, enabling adaptive decision-making using bandit feedback without requiring exhaustive inference across all LLMs for all queries (in contrast to supervised routing). To address this problem, we develop a shared embedding space for queries and LLMs, where query and LLM embeddings are aligned to reflect their affinity. This space is initially learned from offline human preference data and refined through online bandit feedback. We instantiate this idea through Preference-prior Informed Linucb fOr adaptive rouTing (PILOT), a novel extension of LinUCB. To handle diverse user budgets for model routing, we introduce an online cost policy modeled as a multi-choice knapsack problem, ensuring resource-efficient routing.
    

    
    
              
          Comments:
          Accepted at EMNLP 2025 (findings)
        

          Subjects:
          
            Machine Learning (cs.LG)
        
          Cite as:
          arXiv:2508.21141 [cs.LG]
        
        
          Â 
          (or 
              arXiv:2508.21141v1 [cs.LG] for this version)
          
        
        
          Â 
                        https://doi.org/10.48550/arXiv.2508.21141
              
                                arXiv-issued DOI via DataCite (pending registration)
            
          
        
    
  
      Submission history From: Pranoy Panda [view email]          [v1]
        Thu, 28 Aug 2025 18:18:19 UTC (1,560 KB)
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ask HN: Who is hiring? (September 2025)]]></title>
            <link>https://news.ycombinator.com/item?id=45093192</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45093192</guid>
            <description><![CDATA[Please state the location and include REMOTE for remote work, REMOTE (US)
or similar if the country is restricted, and ONSITE when remote work is not an option.]]></description>
            <content:encoded><![CDATA[Ask HN: Who is hiring? (September 2025)186 points by whoishiring 15 hours ago  | hide | past | favorite | 158Â commentsPlease state the location and include REMOTE for remote work, REMOTE (US)
or similar if the country is restricted, and ONSITE when remote work is not an option.Please only post if you personally are part of the hiring companyâno
recruiting firms or job boards. One post per company. If it isn't a household name,
explain what your company does.Please only post if you are actively filling a position and are committed
to responding to applicants.Commenters: please don't reply to job posts to complain about
something. It's off topic here.Readers: please only email if you are personally interested in the job.Searchers: try https://dheerajck.github.io/hnwhoishiring/,
https://amber-williams.github.io/hackernews-whos-hiring/,
http://nchelluri.github.io/hnjobs/, https://hnresumetojobs.com,
https://hnhired.fly.dev, https://kennytilton.github.io/whoishiring/,
https://hnjobs.emilburzo.com, or this (unofficial) Chrome extension:
https://chromewebstore.google.com/detail/hn-hiring-pro/mpfal....Don't miss these other fine threads:Who wants to be hired? https://news.ycombinator.com/item?id=45093190Freelancer? Seeking freelancer? https://news.ycombinator.com/item?id=45093191
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloudflare Radar: AI Insights]]></title>
            <link>https://radar.cloudflare.com/ai-insights</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45093090</guid>
        </item>
        <item>
            <title><![CDATA[Bear is now source-available]]></title>
            <link>https://herman.bearblog.dev/license/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45092490</guid>
            <description><![CDATA[Updates to the Bear license]]></description>
            <content:encoded><![CDATA[
  
  
    
      
        á( á )á Herman's blog
      
    
    
      Home Now Projects Blog

    
  
  
    

    
        
    

    
        

        
            
                
                    01 Sep, 2025
                
            
        
    

    When I started building Bear I made the code available under an MIT license. I didn't give it much thought at the time, but knew that I wanted the code to be available for people to learn from, and to make it easily auditable so users could validate claims I have made about the privacy and security of the platform.
Unfortunately over the years there have been cases of people forking the project in the attempt to set up a competing service. And it hurts. It hurts to see something you've worked so hard on for so long get copied and distributed with only a few hours of modification. It hurts to have poured so much love into a piece of software to see it turned against you and threaten your livelihood. It hurts to believe in open-source and then be bitten by it.
After the last instance of this I have come to the difficult decision to change Bear's license from MIT to a version of copyleft called the Elastic Licenseâcreated by the Elastic Search people.
This license is almost identical to the MIT license but with the stipulation that the software cannot be provided as a hosted or managed service. You can view the specific wording here.
After spending time researching how other projects are handling this, I realise I'm not alone. Many other open-source projects have updated their licenses to prevent "free-ride competition" in the past few years.123456
We're entering a new age of AI powered coding, where creating a competing product only involves typing "Create a fork of this repo and change its name to something cool and deploy it on an EC2 instance".
While Bear's code is good, what makes the platform special is the people who use it, and the commitment to longevity.
I will ensure the platform is taken care of, even if it means backtracking on what people can do with the code itself.


    

    
        

        
            


        
    


  
  

]]></content:encoded>
        </item>
    </channel>
</rss>