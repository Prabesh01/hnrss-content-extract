<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Sun, 31 Aug 2025 16:50:41 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Family of MSFT employee who died warn tech companies not to overwork workers]]></title>
            <link>https://padailypost.com/2025/08/29/family-of-microsoft-employee-who-died-warn-tech-companies-not-to-overwork-workers/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45084370</guid>
            <description><![CDATA[BY BRADEN CARTWRIGHTDaily Post Staff Writer]]></description>
            <content:encoded><![CDATA[
	
		


Pratik Pandey



BY BRADEN CARTWRIGHTDaily Post Staff Writer



Relatives of a man who died at Microsoftâ€™s office in Mountain View are calling on tech companies to stop pressuring their employees to overwork themselves.



Pratik Pandey, 35, of Menlo Park, was found face down around 2 a.m. on Aug. 20 at 1045 La Avenida Ave.



Pandey had told his roommate and colleagues that he was under a lot of stress, juggling multiple projects at the same time, community leader Satish Chandra said in an interview Thursday.



The initial assessment by the Santa Clara County Medical Examiner indicated that Pandey suffered a heart attack, and he didnâ€™t have any known health issues leading up to his death, Chandra said.



Pandeyâ€™s uncle, Manoj Pandey, said Pandey was a very jubilant, hard-work-ing and successful young man.



His colleagues and classmates said he was always helpful, and he liked playing soccer, ping pong and cricket.



â€œOverall, a very positive person,â€ his uncle said.



Pandey was born in Indore, India, and immigrated to the United States a decade ago to get a masterâ€™s degree from San Jose State University.



Pandey worked as a software engineer at Apple, Illumina and Walmart Labs before landing at Microsoft in July 2020.



On the night of his death, Pandey scanned his badge to get into the office at 7:50 p.m., and he was found in the courtyard about six hours later, his uncle said.



Pandeyâ€™s roommates and friends relayed that he continuously worked late nights for a â€œvery extended period of time,â€ his uncle said.



Pandeyâ€™s uncle said tech companies should notice when employees are coming in late at night and do something to relieve their pressure and anxiety.



â€œThat will probably save a life,â€ he said.



Friends and family hosted a viewing for Pandey today (Friday, Aug. 29) in Fremont before sending his remains to India, where his parents and two sisters live. The viewing of the remains is important for their Hindu culture, his uncle said.



â€œItâ€™s a lot of pain for the family when a loved one passes away,â€ he said.
	]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[eBPF 101: Your First Step into Kernel Programming]]></title>
            <link>https://journal.hexmos.com/ebpf-introduction/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45084328</guid>
            <description><![CDATA[eBPF has revolutionized Linux observability and security by allowing sandboxed programs to run in the kernel without changing kernel source code or loading modules]]></description>
            <content:encoded><![CDATA[
            

I. What is this eBPF? It looks scary!

Have you wanted to write programs that act as drivers for Linux? Wanted programs to run at a kernel level? Wanted to monitor events, internal resources and get better observability? All you need to know is how to make good use of Linux eBPF.

eBPF is a technology in the Linux kernel that can run sandboxed programs in a privileged context (in the OS kernel). It is used to efficiently extend the capabilities of the kernel without changing kernel source code.

An operating system kernel is hard to modify due to its central role and high requirement towards stability and security. Innovation at the operating system level is lower compared to functionality implemented outside of the operating system. And developing drivers is difficult in general (I have tried that in Windows and failed).


link : https://ebpf.io/what-is-ebpf/

eBPF changes this formula fundamentally. It allows sandboxed programs to run within the operating system, which means that application developers can run eBPF programs to add additional capabilities to the operating system at runtime. The operating system then guarantees efficiency as if natively compiled with the aid of a Just-In-Time (JIT) compiler and verification engine.

This has led to a wave of eBPF-based projects covering a wide array of use cases, improving networking, observability, and security spaces.

Let's dive right into some practical scenario where we will build a simple firewall to block traffic from a particular ip like 8.8.8.8. And counts the incoming packets transfered each second. Follow through is you have an Ubuntu machine ready.

II. Developing with eBPF made Simple.

We need 2 files for a simple ePBF program.


A Python user space script for interacting with eBPF
A C code that uses eBPF functions and modules (core logic)


Let's download the requirements and setup a python virtual environment for smooth workflow.

Initial setup for ubuntu:

sudo apt-get update && sudo apt-get install -y bpfcc-tools libbpfcc-dev


Create a python virtual environment.

âžœ   python3 -m venv venv
âžœ   source venv/bin/activate


Here's what the 2 files that we are going to create:



probe.c:

eBPF program that runs in the Linux kernel
Counts all incoming packets on a network interface
Drops packets destined for IP 8.8.8.8 (Google DNS)



runner.py:

Python control program that:

Loads and compiles the eBPF program
Attaches it to a network interface
Monitors and prints packet counts per second
Handles graceful shutdown on SIGTERM/Ctrl+C
Prints debug messages when packets are dropped






To find the network interface try this command.

$ ip link show | grep -Po '(?<=: ).*(?=: <)'
lo
wlp0s20f3
docker0



The runner.py script is the user-space controller for our eBPF firewall. It's responsible for loading the eBPF program into the kernel, monitoring its activity, and cleaning up when it's done.

First, we import the necessary Python libraries. bcc is the core library that lets us interact with eBPF, while the others help with handling signals, time, file paths, and network data structures.

from bcc import BPF
from time import sleep
from pathlib import Path
import signal
import ctypes
import socket
import struct

To ensure the firewall can be shut down cleanly, we set up a custom signal handler. The TerminateSignal exception and handle_sigterm function work together to catch termination signals (like SIGTERM), allowing the script to proceed to the cleanup steps instead of stopping abruptly.

class TerminateSignal(Exception):
    pass

# Signal handler for SIGTERM
def handle_sigterm(signum, frame):
    raise TerminateSignal("Received SIGTERM, terminating...")

Loading and Managing the eBPF Program

The eBPF logic itself is written in C in probe.c. The load_bpf_program function reads this C code, and the BCC library compiles it into eBPF bytecode and loads it into the kernel. Once loaded, attach_xdp_program hooks the compiled code to a network interface using XDP (eXpress Data Path), allowing it to process packets at the earliest possible point in the network stack.

# Load and compile the eBPF program from the source file
def load_bpf_program():
    bpf_source = Path('probe.c').read_text()
    bpf = BPF(text=bpf_source)
    return bpf

# Attach the eBPF program to the specified interface
def attach_xdp_program(bpf, interface):
    xdp_fn = bpf.load_func("xdp_packet_counter", BPF.XDP)
    bpf.attach_xdp(interface, xdp_fn, 0)
    return bpf

When the script terminates, detach_xdp_program safely removes the eBPF program from the interface, ensuring the system returns to its normal state.

# Detach the eBPF program from the specified interface
def detach_xdp_program(bpf, interface):
    bpf.remove_xdp(interface, 0)

Monitoring and Event Handling

The main function orchestrates the entire process. It starts by registering the signal handler and defining the network interface to monitor (wlp0s20f3).

# Main function to execute the script
def main():
    # Register the signal handler for SIGTERM
    signal.signal(signal.SIGTERM, handle_sigterm)

    # Define the network interface to monitor
    INTERFACE = "wlp0s20f3"

Next, it loads and attaches the eBPF program. It then gains access to the packet_count_map (a shared data structure for counting packets) and opens a perf_buffer to receive real-time debug events from the kernel, such as notifications about dropped packets.

    # Load the eBPF program and attach it to the network interface
    bpf = load_bpf_program()
    attach_xdp_program(bpf, INTERFACE)

    # Access the BPF map and open the perf buffer for debug events
    packet_count_map = bpf.get_table("packet_count_map")
    bpf["debug_events"].open_perf_buffer(print_debug_event)

The print_debug_event function is a callback that processes these events. When the eBPF program drops a packet, this function formats the data and prints a message to the console.

def print_debug_event(cpu, data, size):
    dest_ip = ctypes.cast(data, ctypes.POINTER(ctypes.c_uint32)).contents.value
    print(f"Packet to {socket.inet_ntoa(struct.pack('!L', dest_ip))} dropped")

The script then enters an infinite loop to monitor packet counts. Every second, it reads the total count from the packet_count_map, calculates the packets-per-second rate, and prints it. It also polls for any new debug events.

    try:
        print("Counting packets, press Ctrl+C to stop...")
        prev_total_packets = 0
        while True:
            sleep(1)
            total_packets = sum(counter.value for counter in packet_count_map.values())
            
            packets_per_second = total_packets - prev_total_packets
            prev_total_packets = total_packets
            print(f"Packets per second: {packets_per_second}")
            bpf.perf_buffer_poll(1)

Graceful Shutdown

The try...except...finally block ensures that the program can be stopped cleanly with Ctrl+C or a SIGTERM signal. The finally block guarantees that the eBPF program is always detached from the network interface, preventing resource leaks.

    except (KeyboardInterrupt, TerminateSignal) as e:
            print(f"\n{e}. Interrupting eBPF runner.")
    finally:
        print("Detaching eBPF program and exiting.")
        detach_xdp_program(bpf, INTERFACE)

Finally, the if __name__ == "__main__": guard ensures the main function runs only when the script is executed directly.

# Execute the main function when the script is run directly
if __name__ == "__main__":
    main()

Next, the probe.c file contains the eBPF program that runs inside the Linux kernel. It uses XDP (eXpress Data Path) to inspect and filter network packets at the earliest possible pointâ€”right in the network driverâ€”making it extremely fast.

Kernel-Space Setup

First, we include kernel headers that provide access to eBPF helpers and network data structures. We then define two key BPF maps:


BPF_ARRAY: A single-element array named packet_count_map to store a global packet counter.
BPF_PERF_OUTPUT: A perf buffer named debug_events to send notifications about dropped packets to the user-space script.


#include <uapi/linux/bpf.h>
#include <uapi/linux/if_ether.h>
#include <uapi/linux/if_packet.h>
#include <uapi/linux/ip.h>
#include <linux/in.h>
#include <bcc/helpers.h>

BPF_ARRAY(packet_count_map, __u64, 1);
BPF_PERF_OUTPUT(debug_events);

The Main XDP Program

The xdp_packet_counter function is the entry point for our eBPF program. It runs for every single packet that arrives on the attached network interface.

Its first job is to increment the global packet counter. It looks up the counter from packet_count_map and atomically increments it. Using an atomic operation is crucial to prevent race conditions when multiple CPU cores process packets simultaneously.

int xdp_packet_counter(struct xdp_md *ctx) {
    __u32 key = 0;
    __u64 *counter;

    counter = packet_count_map.lookup(&key);
    if (!counter)
        return XDP_ABORTED; // Abort if map lookup fails

    // Atomically increment the counter
    __sync_fetch_and_add(counter, 1);

    // Define the blocked IP and call the filtering function
    __be32 blocked_ip = (8 << 24) | (8 << 16) | (8 << 8) | 8;
    return drop_packet_to_destination(ctx, blocked_ip);
}

Packet Filtering Logic

The drop_packet_to_destination function contains the firewall's core logic. It carefully inspects the packet to decide whether to drop it or let it pass.



Parse Headers: It starts by getting pointers to the packet's data and performs bounds checks to ensure the Ethernet and IP headers are safely accessible within the packet's memory region. This prevents the eBPF verifier from rejecting the program.


Check Protocol: It checks if the packet is an IP packet. If not, it's immediately passed through with XDP_PASS.



static int drop_packet_to_destination(struct xdp_md *ctx, __be32 blocked_ip) {
    void *data_end = (void *)(long)ctx->data_end;
    void *data = (void *)(long)ctx->data;
    struct ethhdr *eth = data;

    // Safety check: ensure Ethernet header is within packet bounds
    if ((void *)(eth + 1) > data_end)
        return XDP_PASS;

    // Pass non-IP packets
    if (eth->h_proto != bpf_htons(ETH_P_IP))
        return XDP_PASS;

    struct iphdr *iph = (struct iphdr *)(data + ETH_HLEN);
    // Safety check: ensure IP header is within packet bounds
    if ((void *)(iph + 1) > data_end)
        return XDP_PASS;

    // If the destination IP matches the blocked IP, drop the packet
    if (iph->daddr == blocked_ip) {
        __be32 daddr_copy = iph->daddr;
        debug_events.perf_submit(ctx, &daddr_copy, sizeof(daddr_copy));
        return XDP_DROP;
    }

    return XDP_PASS;
}

The code for this tutorial is taken from this beautiful talk. I recommend you to check it out.

Together they form a simple eBPF firewall that counts packets and blocks traffic to a specific IP address. The Python script manages the eBPF program lifecycle while the C code does the actual packet processing in kernel space.

$ sudo python3 runner.py 


Results after running the program.



Conclusion

Many tech giants Netflix, Dropbox, Yahoo, LinkedIn, Alibaba, Datadog, Shopify, DoorDash use eBPF for network observability, infrastructure debugging, pod networking/security in Kubernetes, intrusion detection. Its widely used in security monitoring and Incident Response.

It will be a big miss if you did not adopt or at least know something about it. I hope this article bridges the gap. For more articles follow the newsletter.


        ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[No Clicks, No Content: The Unsustainable Future of AI Search]]></title>
            <link>https://bradt.ca/blog/no-clicks-no-content/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45084016</guid>
            <description><![CDATA[AI companies are causing a content drought that will eventually starve them.]]></description>
            <content:encoded><![CDATA[


		
			
		
	



	
		

			
				

				
					August 31, 2025
					â€¢
					
				
			

			
				




AI companies are causing a content drought that will eventually starve them.



In a recent article, The Economist didnâ€™t mince words: â€œAI is killing the web.â€ Published last month, the piece raises urgent questions about how artificial intelligence is reshaping the internet as we know it: ChatGPT, Google, and its competitors are rapidly diverting traffic from publishers. Publishers are fightingÂ  to survive through lawsuits, partnerships, paywalls, and micropayments. Itâ€™s pretty bleak, but unfortunately I think the situation is far worse than it seems.



The article focuses mainly on the publishing industry, news and magazine sites that rely primarily on visits to their sites and selling ads. This is hardly new for the publishing industry. Televisions arrived in living rooms in the 60s disrupting print and radio media, in the late 90s and early 2000s the internet further devastated the print business, and social media was stealing attention well before the advent of AI. But itâ€™s not just the publishing industry. Thereâ€™s a much larger economy being disrupted by generative AI platforms.



For the past 25 years, online businesses have relied on people searching Google for information and clicking through to their sites to get the information. For example, a business that sells dirt bikes might create a comprehensive guide to winterize a cottage. People search for information on winterizing their cottage, click through to the dirt bike companyâ€™s guide, and are then exposed to the companyâ€™s brand, maybe join their email list, and maybe buy their products or services.



Now that ChatGPT and Google are serving the information up to people, thereâ€™s little reason to click through to the site. If youâ€™ve used Google search lately, youâ€™ll have noticed an AI blurb responding to your query before you even see a list of links. The result: less clicks on the links.



So the question follows, if fewer and fewer people are visiting your company site, whatâ€™s your incentive to produce and maintain high quality content?



Worse yet, ChatGPT and Google rely on the content produced by businesses to train their AI models. If businesses stop producing content, what happens to the answers provided by ChatGPT and Google?



Could AI companies be this short sighted?



In short: Yes. This is a gold rush mentality. And like any gold rush, thereâ€™s little attention paid to the long term. Itâ€™s get rich quick and weâ€™ll deal with the consequences later. Itâ€™s a race to become the dominant force in AI with no attention paid to the sustainability of their fuel source: the content.



However, Google doesnâ€™t fit this profile. Theyâ€™ve needed businesses and publishers to produce content all along and they know they still do.



We, the public, have greatly benefited from the symbiotic relationship between businesses and Google. You ask Google for something and it responds with links to the best content. Businesses want those visitors to their sites and so they want to have the best content. Although Googleâ€™s results pages have gotten worse for the public and businesses in recent years (half a page of ads at this point), the situation has largely been a win-win-win for them, businesses, and the public. 



Businesses produced and maintained quality content, Google rewarded the businesses with visitors while diverting some to their ads, and the public got the information they were searching for. Unfortunately this symbiotic relationship is breaking down. In their effort to stay relevant and compete with ChatGPT, Google is tearing up the contract theyâ€™ve had with publishers and businesses for the past 25 years.



Google knows this but they seem to be pretending that they donâ€™t. In fact, it seems that theyâ€™re scared and they donâ€™t know what else to do. They have no other option.



One solution here seems to be regulation. To many, it feels like an injustice that AI companies can scrape information from sites, combine it, and serve it up to their users. The bottom line is that if the content didnâ€™t exist to train their models, the AI companies wouldnâ€™t be able to produce an answer.



Unfortunately, lawsuits so far have been going in favor of AI companies. Copyright law doesnâ€™t seem to be a fit here, so perhaps we need new laws. I doubt theyâ€™ll come quickly enough though. Google search is rolling out AI Mode right now: no more AI blurb with links underneath. Just a ChatGPT-like interface when you do a Google search. It seems weâ€™re already well into this trap and there doesnâ€™t seem to be an escape.



Then again, thereâ€™s definitely an economic bubble here. ChatGPT is not profitable despite billions in revenue. The infrastructure is very expensive to run. Perhaps the bubble will burst, the money will dry up, and it wonâ€™t be feasible to employ generative AI for general search. Google and its competitors will use it for other things of course, but not for search. Itâ€™s hard to see this happening though. The genie is out of the bottle.

				
			

		

		

		


		
	







]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Jujutsu for Everyone]]></title>
            <link>https://jj-for-everyone.github.io/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45083952</guid>
            <description><![CDATA[A Jujutsu tutorial that requires no previous experience with Git or other version control systems.]]></description>
            <content:encoded><![CDATA[
    
            Keyboard shortcuts
            
                Press â† or â†’ to navigate between chapters
                Press S or / to search in the book
                Press ? to show this help
                Press Esc to hide this help
            
        
    
        
        

        
        

        

        
        

        
            
            
            
            
        

        

            
                    
                        Introduction
This is a tutorial for the Jujutsu version control system.
It requires no previous experience with Git or any other version control system.
At the time of writing, most Jujutsu tutorials are targeted at experienced Git users, teaching them how to transfer their existing Git skills over to Jujutsu.
This tutorial is my attempt to fill the void of beginner learning material for Jujutsu.
If you are already experienced with Git, I recommend Steve Klabnik's tutorial instead of this one.
This tutorial requires you to work in the terminal.
Don't worry, there's a chapter covering some terminal basics in case you're not 100% comfortable with that yet.
The commands I tell you to run will often only work on Unix-like operating systems like Linux and Mac.
If you're on Windows (and can't switch to Linux), consider using WSL.
How to read this tutorial
The tutorial is split into levels, which are the top-level chapters in the sidebar.
The idea is that once you complete a level, you should probably put this tutorial away for a while and practice what you've learned.
Once you're comfortable with those skills, come back for the next level.
There is one exception to this:
If you're here because you need to collaborate with other people, you should complete the levels 1 and 2 right away.
Here's an overview of the planned levels:
LevelDescription
1The bare minimum to get started. This is only enough for the simplest use cases where you're working alone. For example, students who track and submit their homework with a Git repository can get by with only this.
2The bare minimum for any sort of collaboration. Students who are working on a group project and professional software developers need to know this. Going further is highly recommended, but you can take a break after this.
3Basic problem solving skills like conflict resolution and restoring files from history. Without this knowledge, it's only a matter of time until you run into trouble. Completing this level is comparable to the skill level of the average software developer.
4History rewriting skills. These will allow you to iterate toward a polished version history, which pays dividends long-term. Some projects require you to have these skills in order to meet their quality standards.
5Productivity boosters, advanced workflows, lesser-known CLI functions and a little VCS theory. Completing this level means you have mastered Jujutsu.
6Additional topics that only come up in specific situations: tags, submodules, workspaces etc. Consider skimming the list of topics and come back once you have an actual need for it.


Only a few levels are complete right now, the rest are on the way.
Reset your progress
Throughout the tutorial, you will build an example repository.
Later chapters depend on the state of previous ones.
Losing the state of the example repo can therefore block you from making smooth progress.
This might happen for several reasons:

You use the example repo for practice and experimentation.
You switch to a different computer or reinstall the OS.
You intentionally delete it to clean up your home directory.
The tutorial is updated significantly while you're taking a break.

To solve this problem, there is a script which automates the task of resetting your progress to the start of any chapter.
To identify the chapter you want to continue with, the script expects a keyword as an argument.
Each chapter includes its precise reset command at the beginning, so you can easily copy-paste it.



Always be careful when executing scripts from the internet!




The script is not complicated, you can verify that it's not doing anything malicious.
Basically, it's just the list of commands I tell you to run manually.
For convenience, it's included in the expandable text box below.
You can also download the script here and then execute it locally once you have inspected it.





Source of reset script




#!/usr/bin/env bash
set -euxo pipefail

if [ "${1:-x}" = "x" ] ; then
    echo "Please provide the chapter keyword as the first argument."
    exit 1
fi
chapter="$1"

function success() {
    set +x
    echo "âœ…âœ…âœ… Reset script completed successfully! âœ…âœ…âœ…"
    exit 0
}

# Ensure existing user configuration does not affect script behavior.
export JJ_CONFIG=/dev/null

rm -rf ~/jj-tutorial

if ! command -v jj > /dev/null ; then
    echo "ERROR: Jujutsu doesn't seem to be installed."
    echo "       Please install it and rerun the script."
    exit 1
fi

if [ "$chapter" = initialize ] ; then success ; fi

mkdir -p ~/jj-tutorial/repo
cd ~/jj-tutorial/repo
jj git init --colocate

jj config set --repo user.name "Alice"
jj config set --repo user.email "alice@local"
jj describe --reset-author --no-edit

if [ "$chapter" = log ] ; then success ; fi

if [ "$chapter" = make_changes ] ; then success ; fi

echo "# jj-tutorial" > README.md
jj log -r 'none()' # trigger snapshot

if [ "$chapter" = commit ] ; then success ; fi

jj commit --message "Add readme with project title

It's common practice for software projects to include a file called
README.md in the root directory of their source code repository. As the
file extension indicates, the content is usually written in markdown,
where the title of the document is written on the first line with a
prefixed \`#\` symbol.
"

if [ "$chapter" = remote ] ; then success ; fi

git init --bare ~/jj-tutorial/remote
jj git remote add origin ~/jj-tutorial/remote
jj bookmark create main --revision @-
jj git push --bookmark main --allow-new

if [ "$chapter" = clone ] ; then success ; fi

cd ~
rm -rf ~/jj-tutorial/repo
jj git clone --colocate ~/jj-tutorial/remote ~/jj-tutorial/repo
cd ~/jj-tutorial/repo
jj config set --repo user.name "Alice"
jj config set --repo user.email "alice@local"
jj describe --reset-author --no-edit

if [ "$chapter" = github ] ; then success ; fi

if [ "$chapter" = update_bookmark ] ; then success ; fi

printf "\nThis is a toy repository for learning Jujutsu.\n" >> README.md
jj commit -m "Add project description to readme"

jj bookmark move main --to @-

jj git push

if [ "$chapter" = branch ] ; then success ; fi

echo "print('Hello, world!')" > hello.py

jj commit -m "Add Python script for greeting the world

Printing the text \"Hello, world!\" is a classic exercise in introductory
programming courses. It's easy to complete in basically any language and
makes students feel accomplished and curious for more at the same time."

jj git clone --colocate ~/jj-tutorial/remote ~/jj-tutorial/repo-bob
cd ~/jj-tutorial/repo-bob
jj config set --repo user.name Bob
jj config set --repo user.email bob@local
jj describe --reset-author --no-edit

echo "# jj-tutorial

The file hello.py contains a script that greets the world.
It can be executed with the command 'python hello.py'.
Programming is fun!" > README.md
jj commit -m "Document hello.py in README.md

The file hello.py doesn't exist yet, because Alice is working on that.
Once our changes are combined, this documentation will be accurate."

jj bookmark move main --to @-
jj git push

cd ~/jj-tutorial/repo
jj bookmark move main --to @-
jj git fetch

if [ "$chapter" = show ] ; then success ; fi

if [ "$chapter" = merge ] ; then success ; fi

jj new main@origin @-

jj commit -m "Merge code and documentation for hello-world"
jj bookmark move main --to @-
jj git push

if [ "$chapter" = ignore ] ; then success ; fi

cd ~/jj-tutorial/repo-bob

tar czf submission_alice_bob.tar.gz README.md

echo "
## Submission

Run the following command to create the submission tarball:

~~~sh
tar czf submission_alice_bob.tar.gz [FILE...]
~~~" >> README.md

echo "*.tar.gz" > .gitignore

jj file untrack submission_alice_bob.tar.gz

jj commit -m "Add submission instructions"

if [ "$chapter" = rebase ] ; then success ; fi

jj bookmark move main --to @-
jj git fetch
jj rebase --destination main@origin
jj git push

if [ "$chapter" = more_bookmark ] ; then success ; fi

cd ~/jj-tutorial/repo

echo "for (i = 0; i < 10; i = i + 1):
    print('Hello, world!')" > hello.py

jj commit -m "WIP: Add for loop (need to fix syntax)"

jj git push --change @-

if [ "$chapter" = navigate ] ; then success ; fi

jj git fetch
jj new main

if [ "$chapter" = undo ] ; then success ; fi

echo "print('Hallo, Welt!')" >> hello.py
echo "print('Bonjour, le monde!')" >> hello.py

jj commit -m "code improvements"

jj undo

jj commit -m "Print German and French greetings as well"

jj undo
jj undo
jj undo

jj redo
jj redo
jj redo

if [ "$chapter" = track ] ; then success ; fi

cd ~ # move out of the directory we're about to delete
rm -rf ~/jj-tutorial/repo
jj git clone --colocate ~/jj-tutorial/remote ~/jj-tutorial/repo
cd ~/jj-tutorial/repo

# roleplay as Alice
jj config set --repo user.name "Alice"
jj config set --repo user.email "alice@local"
jj describe --reset-author --no-edit

echo "print('Hallo, Welt!')" >> hello.py
echo "print('Bonjour, le monde!')" >> hello.py
jj commit -m "Print German and French greetings as well"

jj bookmark move main -t @-
jj git push

jj bookmark track 'glob:push-*@origin'

if [ "$chapter" = conflict ] ; then success ; fi

jj new 'description("WIP: Add for loop")'

echo "for _ in range(10):
    print('Hello, world!')" > hello.py

jj commit -m "Fix loop syntax"

jj new main @-

echo "for _ in range(10):
    print('Hello, world!')
    print('Hallo, Welt!')
    print('Bonjour, le monde!')" > hello.py

jj commit -m "Merge repetition and translation of greeting"
jj bookmark move main --to @-
jj git push

if [ "$chapter" = abandon ] ; then success ; fi

jj commit -m "Experiment: Migrate to shiny new framework"
jj git push --change @-
jj new main
jj commit -m "Experiment: Improve scalability using microservices"
jj git push --change @-
jj new main
jj commit -m "Experiment: Apply SOLID design patterns"
jj git push --change @-
jj new main

jj abandon 'description("Experiment")'

jj git push --deleted

if [ "$chapter" = restore ] ; then success ; fi

rm README.md
jj show &> /dev/null

jj restore README.md

jj restore --from 'description("Fix loop syntax")' hello.py

jj commit -m "Remove translations"
jj bookmark move main --to @-
jj git push

if [ "$chapter" = complete ] ; then success ; fi

set +x
echo "Error: Didn't recognize the chapter keyword: '$chapter'."
exit 1



Stay up to date
Both this tutorial and Jujutsu are still evolving.
In order to keep your Jujutsu knowledge updated, subscribe to releases of the tutorial's GitHub repo.
You will be notified of important changes:

A new level becomes available.
An existing level is changed significantly.

I especially intend to keep this tutorial updated as new version of Jujutsu come out with features and changes that are relevant to the tutorial's content.
I consider this tutorial up-to-date with the latest version of Jujutsu (0.32) as of August 2025.
If that's more than a couple months in the past, I probably stopped updating this tutorial.
You can subscribe to these updates by visiting the GitHub repo and clicking on "Watch", "Custom" and then selecting "Releases".

Help make this tutorial better
If you find a typo, you can suggest a fix directly by clicking on the "edit" icon in the top-right corner.
If you have general suggestions for improvement, please open an issue.
I am also very interested in experience reports, for example:

Do you have any frustrations with Jujutsu which the tutorial did not help you overcome?
Was there a section that wasn't explained clearly?
(If you didn't understand something, it's probably the tutorial's fault, not yours!)
Did you complete a level but didn't feel like you had the skills that were promised in the level overview?
Is there something missing that's not being taught but should?
Do you feel like the content could be structured better?

Thank you for helping me improve this tutorial!
What is version control and why should you use it?
I will assume you're using version control for software development, but it can be used for other things as well.
For example, authoring professionally formatted documents with tools like Typst.
The source of this tutorial is stored in version control too!
What these scenarios have in common is that a large body of work (mostly in the form of text) is slowly being expanded and improved over time.
You don't want to lose any of it and you want to be able to go back to previous states of your work.
Often, several people need to work on the project at the same time.
A general-purpose backup solution can keep a few copies of your files around.
A graphical document editor can allow multiple people to edit the text simultaneously.
But sometimes, you need a sharper knife.
Jujutsu is the sharpest knife available.
Why Jujutsu instead of Git?
Git is by far the most commonly used VCS in the software development industry.
So why not use that?
Using the most popular thing has undeniable benefits.
There is lots of learning material, lots of people can help you with problems, lots of other tools integrate with it etc.
Why make life harder on yourself by using a lesser-known alternative?
Here's my elevator pitch:


Jujutsu is compatible with Git.
You're not actually losing anything by using Jujutsu.
You can work with it on any existing project that uses Git for version control without issues.
Tools that integrate with Git mostly work just as well with Jujutsu.


Jujutsu is easier to learn than Git.
(That is, assuming I did a decent job writing this tutorial.)
Git is known for its complicated, unintuitive user interface.
Jujutsu gives you all the functionality of Git with a lot less complexity.
Experienced users of Git usually don't care about this, because they've paid the price of learning Git already.
(I was one of these people once.)
But you care!


Jujutsu is more powerful than Git.
Despite the fact that it's easier to learn and more intuitive, it actually has loads of awesome capabilities for power users that completely leave Git in the dust.
Don't worry, you don't have to use that power right away.
But you can be confident that if your VCS-workflow becomes more demanding in the future, Jujutsu will have your back.
This is not a watered-down "we have Git at home" for slow learners!


Learning Jujutsu instead of Git as your first VCS does have some downsides:


When talking about version control with peers, they will likely use Git-centric vocabulary.
Jujutsu shares a lot of Git's concepts, but there are also differences.
Translating between the two in conversation can add some mental overhead.
(solution: convince your peers to use Jujutsu ðŸ˜‰)


Jujutsu is relatively new and doesn't cover 100% of the features of Git yet.
When you do run into the rare problem where Jujutsu doesn't have an answer, you can always fall back to use Git directly, which works quite seamlessly.
Still, having to use two tools instead of one is slightly annoying.
I plan to teach such Git features in this tutorial in later levels.
The tutorial should be a one-stop-shop for all Jujutsu users.


The command line interface of Jujutsu is not yet stable.
That means in future versions of Jujutsu, some commands might work a little differently or be renamed.
I personally don't think this should scare you away.
Many people including me have used Jujutsu as a daily driver for a long time.
Whenever something did change, my reaction was usually:
"Great, that was one of the less-than-perfect parts of Jujutsu! Now it's even more intuitive than before!"
Consider subscribing to GitHub releases of this tutorial.
You will be notified if new versions of Jujutsu change something in a way that's relevant to what you learned in this tutorial.


Despite some downsides, I think the benefits are well worth it.

                    

                    
                        

                            
                                
                            

                        
                    
                

            

                    
                        
                    
            

        




        


        
        
        

        
        
        

        


    
    

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[FDA official demands removal of YouTube videos of himself criticizing vaccines]]></title>
            <link>https://www.theguardian.com/us-news/2025/aug/31/fda-official-youtube-videos</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45083845</guid>
            <description><![CDATA[Doctor who created now-defunct channel says he wanted to â€˜preserveâ€™ what Trump health officials said during Covid]]></description>
            <content:encoded><![CDATA[A top official at the Food and Drug Administration (FDA) demanded the removal of YouTube videos of himself that were published by a physician and writer who has been critical of medical misinformation and public health officials in the Trump administration, according to a YouTube notice that was seen by the Guardian.Jonathan Howard, a neurologist and psychiatrist in New York City, received an email from YouTube on Friday night, which stated that Vinay Prasad, who is the FDAâ€™s top vaccine regulator, had demanded the removal of six videos of himself from Howardâ€™s YouTube channel.Howardâ€™s entire channel has now been deleted by YouTube, which cited copyright infringement.The now-defunct channel contained about 350 videos of doctors and commentators, including Prasad, Robert F Kennedy Jr, the secretary of health and human services, and Jay Bhattacharya, the head of the National Institutes of Health, which had been collected by Howard from their social media accounts, interviews and podcasts.Creating the channel, Howard told Guardian in an interview, had been an attempt to â€œpreserveâ€ what these individuals had said during the early years of the pandemic, including comments that Howard said exaggerated the dangers of the Covid vaccine to children and â€“ in some cases â€“ minimized the risk of Covid infection, among other issues.â€œThese videos were nothing more than collections of what other doctors said during the pandemic, including doctors who are extremely influential and who are now the medical establishment,â€ he said.The Guardian requested a comment from the office of public affairs at the department of health and human services, and attempted to reach Prasad through personal email addresses and by a listed mobile phone number. No one responded to the request for comment.When YouTube notified Howard of the demand request, it included an email address for Prasad, which is identical to the email address that is linked to Prasadâ€™s now inactive podcast, called Plenary Session.Prasad, a former hematologist-oncologist at the University of California San Francisco, is now head of the FDAâ€™s Center for Biologics Evaluation and Research (CBER), which makes him the chief vaccine regulator in the US. He was a vocal critic of Peter Marks, who previously led CBER and was widely respected for his role in Operation Warp Speed, the initiative that developed, manufactured and helped distribute the Covid-19 vaccines. Marks was forced to resign by Kennedy.Prasad has also been critical of the use of Covid boosters in young people and vaccine mandates, and has defended cuts to health agencies and university research.â€œItâ€™s really important to remember [Prasadâ€™s] past words in order to gauge his current and future credibility, and that was the mission of my YouTube channel, to record what these doctors [Prasad and others] said,â€ Howard said.Although the videos Howard collected were often only viewed â€œdozensâ€ of times, Howard included them in his online articles that appeared on the Science Based Medicine blog. Now those video links are dead.He noted that snippets of Prasadâ€™s comments still appeared on anti-vaccine social media accounts, suggesting Prasad was directing his removal demand only at a critic and not anti-vaccine influencers. In the past, Prasad has complained about censorship by social media companies.Howard has been quoted in the New York Times, the Guardian, and other publications and is the author of a forthcoming book Everyone Else Is Lying to You, which he said examines how the medical establishment, which has come into power in Trumpâ€™s second term, normalized â€œquackeryâ€ during the Covid pandemic and undermined public health.â€œI had thought there was a policy that government officials shouldnâ€™t censor opposing perspectives, but I must be mistaken,â€ said John Moore, a scientist and colleague who is familiar with Howardâ€™s book and videos.Howard told the Guardian he wanted to emphasize that he was not a victim, and that the ordeal of having his YouTube channel deleted was nothing compared with the dire situation facing scientists and researchers whose funding is being cut by public health institutions.Prasad has had a rocky start in his FDA tenure. Jeremy Faust, a doctor at Brigham and Womenâ€™s Hospital Department of Emergency Medicine whose Substack newsletter Inside Medicine is widely followed, once described Prasad as having two sides.There was a 2010s Prasad who was a â€œrigorous and professorial cancer research methodology expert with hundreds of peer-reviewed publications, including well-reasoned analyses that often stood up against some slippery stuff from big pharmaâ€. And there was the â€œ2020s Prasadâ€, who Faust called â€œnewly famous and admired by the Right â€¦ [a] hot-headed firebrand who when asked about how we should move forward from the lessons of Covid-19 pandemic criticized the pro-masking contingent saying, â€œI donâ€™t believe in forgiveness because, in my opinion, these pieces of shit are still lying.â€Prasad briefly resigned this summer after he was the subject of an attack by the rightwing activist Laura Loomer, and then returned to his post at the FDA. He reportedly had a significant role in the FDAâ€™s decision to change rules around the Covid-19 vaccine, limiting its availability this fall to adults over 65 or those with certain medical conditions. Previously, Covid shots were recommended for everyone six months or older.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Older developers are down with the vibe coding vibe]]></title>
            <link>https://www.theregister.com/2025/08/28/older_developers_ai_code/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45083635</guid>
            <description><![CDATA[: They use AI more but also check it more]]></description>
            <content:encoded><![CDATA[
For those who thought AI vibe coding was just for the youngsters, newly published research shows that developers with over 10 years of experience are more than twice as likely to do it.
According to a July survey of 791 US developers from cloud services platform Fastly, around a third of senior developers with more than a decade of experience are using AI code-generation tools such as Copilot, Claude, and Gemini to produce over half of their finished software, compared to 13 percent for those devs who've only been on the job for up to two years.
Austin Spires, senior director of developer engagement at Fastly, explained to The Register that the difference doesnâ€™t necessarily mean older coders are slacking off. It's more a reflection of the demands on a senior developerâ€™s day.

    

"When you really zoom out and think about what a senior engineer does, they don't write code all day," he explained. "So if there's ways that people can test autonomously or move really quickly to get a prototype out that kind of hits, that visceral, fun dopamine hit that made coding so fun in the beginning. That's why we're seeing the pattern from that research."

        


        

In a way, seeing younger coders relying less on AI tools less was "heartening," he said, showing that those new to the field want to craft code the old-fashioned way. They appear to be looking at AI coding tools as handy, but not a replacement for baking your own software.


Not in my browser! Vivaldi capo doubles down on generative AI ban

UK unions want 'worker first' plan for AI as people fear for their jobs

Crims laud Claude to plant ransomware and fake IT expertise

Nx NPM packages poisoned in AI-assisted supply chain attack

A slight majority of older developers say AI tools help them ship software faster, although they do have to spend more time checking it for artificially developed bugs. By contrast, fewer than half of junior developers felt that way.
Spires speculates that this may be down to experience showing its benefits. Senior developers are more likely to be able to quickly scan code and spot flaws, whereas younger workers have a tougher time of software editing. Only 1.8 percent of respondents said they never use AI code generation tools.
Overall, over 70 percent of all developers questioned said that AI tools made their jobs more enjoyable, compared to less than 20 percent who said it made things harder. Over 30 percent of respondents said automatic coding made their work role "significantly more enjoyable."

        

One other standout from the survey was the degree to which coders are considering the environmental impact of software they write. Among younger devs, barely half said they considered the energy costs of running new code, but that rose to 80 percent of older programmers. Nearly one in ten respondents admitted they didnâ€™t know how much energy their software requires.
"There's not a lot of incentive for AI coding tools to disclose what the carbon footprint of these tools are," Spires said.
"More senior engineers understand the second and third effects of their code in how it relates to users and how it relates to their community. And I think it's just a matter of time before junior developers start to understand those ramifications a little bit further." Â®                                
                    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Replacing a Cache Service with a Database]]></title>
            <link>https://avi.im/blag/2025/db-cache/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45083495</guid>
            <description><![CDATA[Why do we use caches at all? Can databases fully replace them?]]></description>
            <content:encoded><![CDATA[Iâ€™ve been thinking about this: will we ever replace caches entirely with databases? In this post I will share some ideas and how we are moving towards it. tl;dr we are still not there, yet.Why do we even use caches?Caches solve one important problem: providing pre-computed data at insanely low latencies, compared to databases. I am talking about typical use cases where we use a cache along with the db (cache aside pattern), where the application always talks with cache and database, tries to keep the cache up to date with the db. There are other patterns where cache itself talks with DBs, but I think this is the more common pattern where application talks to both cache and database.Iâ€™d like to keep my systems simple, and try to reduce dependencies, if possible. If databases can provide the same benefits as cache, it can go a long way before we decide to add an external caching service.Instead of using a cache, like Valkey (or Redis), you could just set up a read replica and use it like a cache. Databases already keep some data in-memory (in buffer pool). Caches arenâ€™t expected to be strongly consistent with the DB, and neither are read replicas. As an added benefit, you can use the same SQL queries instead of whatever custom interface the cache provides. Not using a cache would make things operationally so much simpler; and Iâ€™d never have to worry about cache invalidation.If you use an embedded database (like SQLite, PGLite) with replication (like Litestream or libSQL), youâ€™d even get zero network latency.However, caches are still very prominent and canâ€™t be replaced with just read replicas. I often think about how we can bridge the gap, but I think the workloads are so different that itâ€™s not going to happen anytime soon. The closest weâ€™ve come, I think, is Noria + MySQL (now ReadySet).So why are caches still preferred? Comparatively, here are a few things caches do better than databases:Setting up and destroying a cache is cheap; both operationally and cost-wise.Most workloads only cache a subset of the data, and developers have control over what that subset is. It uses fewer resources. With a DB + buffer pool, that level of control doesnâ€™t exist today.Caches keep pre-computed data. I could do a complex join and then save the results in a cache. How could I achieve the same with a db?I donâ€™t know of any database that lets me assign priority to specific rows to always keep them in the buffer pool. Caches also provide eviction policies (and TTL), which I canâ€™t do with the DB buffer pool.Databases are orders of magnitude larger than caches. Using a full read replica that consumes terabytes of storage just to access a few gigabytes of hot data feels wasteful. Some cloud providers wonâ€™t even let you use larger SSDs without also upgrading CPU/memory.Cache services can handle hundreds of thousands of concurrent connections, whereas databases generally donâ€™t scale that way. Database connections are expensive.What needs to happen to close the gap?Since Iâ€™m only interested in a subset of the data, setting up a full read replica feels like overkill. It would be great to have a read replica with just partial data.I donâ€™t know of any database built to handle hundreds of thousands of read replicas constantly pulling data. Would they even behave sanely if I kept plugging in new replicas as if they were caches? Interestingly, with databases that use disaggregated storage, replicas could pull directly from storage without ever contacting the master.IVM (Incremental View Maintenance) is the hot new stuff. They can be used to precompute the results to cache. e.g. Noria saves results of a join query. So we also need some fancy data structures rather than a simple buffer pool. Iâ€™d also love to use WASM extensions to aid in pre computation. The trick is making this work without paying the full cost of query planning. And note: pre-computation does not really help if you have multiple data sources.Most mainstream databases donâ€™t let me fetch just the subset I care about. If IVM were easier, and we could combine it with partial read replicas, maybe then a replica could truly replace a cache*.If we look at this from another angle, we could use an IVM engine to populate and update an external cache service; but that might be a topic for another day.Thanks to Gowtham for reading a draft of this.1. This blog is a rehash of a tweet I wrote earlier, which itself was a rehash of a reply I made to Phil Eatonâ€™s tweet. FWIW, my fren thinks the tweet was better than this post.2. This of course does not fit all the use cases, majority of them yes3. Weirdly, thereâ€™s no Wikipedia page for â€˜buffer poolâ€™. btw, Andy Pavlo has a killer lecture video on them.4. Many new companies doing some insane stuff around IVM: ReadySet, Materialize, and Feldera5. If you are new to IVM / Materialized views, then Sophie Alpert has an excellent post on the topic Materialized views are obviously useful.*at least for my use cases]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Notes on Managing ADHD]]></title>
            <link>https://borretti.me/article/notes-on-managing-adhd</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45083134</guid>
            <description><![CDATA[Strategies and tactics for staying productive.]]></description>
            <content:encoded><![CDATA[
  The pleasure is in foreseeing it, not in bringing it to term.

   â€”  Jorge Luis Borges, Selected Non-Fictions 


This post is about managing ADHD. It is divided into two sections: â€œStrategiesâ€ describes the high-level control system, â€œTacticsâ€ is a list of micro-level improvements (really it should be called â€œstratagemsâ€, since most are essentially about tricking yourself).

Contents


  Strategies    
      Chemistry First
      Memory
      Energy
      Procrastination
      Introspection
      Time
    
  
  Tactics    
      Task Selection
      Visual Field Management
      Project Check-Ins
      Centralize Your Inboxes
      Inbox Zero
      Inbox Bankruptcy
      Do It On Your Own Terms
      Replace Interrupts with Polling
      Accountability Buddy
      Plan First, Do Later
      Derailment
      Using OCD to Defeat ADHD
      The Master of Drudgery
      Thrashing
      Put Travel in the Calendar
      Choice of Tools
    
  
  Resources
  Acknowledgements


Strategies

High-level advice, control systems.

Chemistry First

ADHD has a biological cause and drugs are the first-line treatment for good reasons. There is no virtue in trying to beat it through willpower alone.

The first-line treatment for ADHD is stimulants. Everything else in this post works best as a complement to, rather than as an alternative to, stimulant medication. In fact most of the strategies described here, I was only able to execute after starting stimulants. For me, chemistry is the critical node in the tech tree: the todo list, the pomodoro timers, etc., all of that was unlocked by the medication.

Some people canâ€™t tolerate a specific stimulant. But there are many stimulant and non-stimulant drugs for ADHD. I would prefer to exhaust all the psychiatric options before white-knuckling it.

A lot of people donâ€™t want to take medication for shame-based reasons. There is a lot of pill-shaming in the culture. You must learn to ignore it: we are automata, our minds are molecules in salt water.

Example: Melatonin

As a motivating example for the â€œsalt water automatonâ€ view: I struggled with sleep hygiene for a long time. It felt like WW1: throwing wave after wave of discipline at it and always failing. I would set an alarm, for, say, 10pm, that said: it is time to go to bed. How many times did I obey it? Never. I was always doing something more important.

What fixed it? Melatonin. I have an alarm that goes off at 8pm to remind me to take melatonin. The point of the alarm is not, â€œnow you must log offâ€, which is a very discipline-demanding task. The point of the alarm is simply: take this pill. It takes but a moment. Importantly, Iâ€™m not committing to anything other than taking a pill. Thirty, forty minutes later, I want to sleep. That is the key thing: the melatonin has changed my preferences. And then I donâ€™t need willpower to close the sixteen Wikipedia tabs or whatever, because I want to sleep more than I want to scroll, or watch YouTube.

Internal and External Change

The broader perspective here is that personal growth is a dialogue between internal changes and external changes.

Internal changes might come from medication, meditation, therapy, coaching, or practicing habits for a long enough time. External changes are the scaffolding around the brain: using a todo list, and using it effectively. Using a calendar. Clearing your desk so you donâ€™t get distracted by things. Journaling, so that you can introspect and notice patterns: which behaviours leads to a good workday, and which behaviours lead to a day being wasted.

Are internal changes more important? Kind of. Itâ€™s more a back and forth, where internal changes unlock external changes which unlock further internal changes.

Hereâ€™s an example: you (having undiagnosed ADHD) try to set a schedule, or use a todo list, or clean your bed every day, but it doesnâ€™t stick. So you get on medication, and the medication lets you form your first habit: which is using a todo list app consistently, checking it every morning. Then, with the todo list as a core part of your exocortex, you start adding recurring tasks, and forming other simple habits: you have a daily recurring task to make your bed, and so every morning when you check the todo list, you see the task, and make your bed, and in time, with your now-functioning dopamine system, you make a habit to make your bed every day, such that you no longer need to have that in the todo list.

So the timeline is:


  Internal change: starting medication unlocksâ€¦
  External change: using a todo list, which provides scaffolding (e.g. daily recurring tasks) for forming new habits, which unlocks
  Internal change: new habits formed (make bed, brush teeth in the morning)


Taking Ritalin with no plan for what you will do today/tomorrow/this week doesnâ€™t work. Dually, an ambitious todo list will sit idle if your brain wonâ€™t let you execute it. So personal growth comes from using both internal and external changes, like a ladder with alternating left-right steps.

Memory

A todo list is a neuroprosthesis that augments long-term memory for tasks.

I use Todoist on my desktop and my phone. The pro plan is worth it. I donâ€™t really think of it as an app, rather, itâ€™s a cognitive prosthesis.

The todo list provides three things:


  Memory: the list remembers things for me. Iâ€™m not at the mercy of my brain randomly pinging me that I forgot to do X or I want to someday do Y. The todo list remembers.
  Order: the todo list lets you drag and drop tasks around, so you can figure out the ordering in which youâ€™re going to do them.
  Hierarchy: the todo list lets you break tasks down hierarchically and without limit.


Of these, the most important is memory. The todolist is an action-oriented long term memory prosthesis.

This is especially useful for habit formation: my biggest blocker with forming habits was just remembered that Iâ€™d committed to doing something. If you think, i will make the bed every day, you might do it today, tomorrow, and by the third day you forget. Youâ€™re failing by simply forgetting to show up, which is a sad way to fail. By making something a recurring task on the todo list, it ensures I will see it. In a sense, the todo list turns many habits into one. You donâ€™t need to remember â€œI will make my bed every dayâ€, â€œI will floss my teeth every nightâ€, etc., because the todolist remembers all those things for you. You only need to form a single habit: checking the todo list.

Analogously, I often fail to finish projects simply because I forget about them. I start reading a book, but I donâ€™t write it down anywhere (say, in Goodreads) that â€œIâ€™m reading this bookâ€ is something I have committed to. I leave the book on a table where itâ€™s out of sight (and therefore out of mind) for all of my waking hours. I glance at it occasionally and think, oh, yeah, I was reading that book, and then Iâ€™m distracted by something else. And weeks later, when Iâ€™ve already started another book, I notice the first book, with the bookmark on page 20, abandoned.

The todolist prevents this failure mode: you create a project to represent reading the book, and that project is now tracked, and when you open the todo list, you can see it in the list of active projects.

How I Use Todoist

In Todoist, every task is part of a project (which really should just be called a list). My sidebar looks like this:



Tasks is the list for ad-hoc tasks. Mostly chores and things that donâ€™t fit in elsewhere. Unload the dishwasher, reply to this email, etc. The only rule for this list is that everything in it must be scheduled.

Groceries is self-explanatory.

Ideas is the where every half-formed goal, intention, project idea etc. goes. â€œGo deeper into mettaâ€ and â€œlearn how to use the slide ruleâ€ and â€œgo penguin watching in Manlyâ€ and â€œwrite a journalling appâ€ and â€œlearn PLT Redexâ€. I put these things here so that they donâ€™t live in my brain. And occasionally I go through the list and promote something into an actual, active project.

Blog is like the ideas list specifically ideas for blog posts.

Reading List is for media I want to consume. This is divided into: fiction books, non-fiction books, technical books, blog posts, papers, games, films.

Cycles is for recurring tasks. This one is divided into sections by period: daily, weekly, and above. The daily recurring tasks are things like â€œtake vitamin Dâ€, â€œmeditateâ€, and the inbox-clearing task.

Projects is a container for actual projects: an objective which takes multiple tasks to accomplish. Why lift projects into lists? Why not just use a top-level task to represent the projectâ€™s objective, and nested subtasks to represent the execution steps of the project? Because having the project in the sidebar is one mechanism I use to ensure I donâ€™t forget about it. Every time I glance at the todo list, I can see the list of active projects. I can notice if something has not been worked on for a while, and act on it. Otherwise: out of sight, out of mind.

Energy

The difficulty class of the tasks you can perform declines throughout the day.

There are many metaphors for the concept of mental energy. Spoon theory, for example. The usual metaphor is that â€œmental energyâ€ is like a battery that is drained through the day, in greater and lesser quantities, and is replenished by sleep.

To me, energy is less like a battery and more like voltage. Some machines require a threshold voltage to operate. Below that voltage they donâ€™t just operate slower, they donâ€™t operate at all. Analogously, different categories of activity have different threshold voltages. For me, itâ€™s like this:


  Things I am averse to, the things I intuitively want to put off because they bring up painful emotions, are high-voltage.
  Creative, open-ended work is high-voltage to start, but once you get started, keeping it going is medium-voltage.
  Simple chores like cleaning, throwing clothes in the washing machine, etc. are low-voltage.


And when I wake up I have the highest possible voltage, and throughout the course of the day the voltage declines. And thatâ€™s the key difference from spoon theory: spoons are fungible across time, voltage is not. For each category of activity, there is a span of the day when I can action it.

When I wake up, I do my morning routine, get some quick wins, and then I try to tackle the thing I dread the most, as early in the morning as possible, because thatâ€™s the time of day when I have the most energy and self-control. I get that done and I move on.

(Another reason to do the dreaded tasks first: if you put it off to, say, late morning, well, why not put it off again? And again and again. And then itâ€™s 7pm and you canâ€™t even think about the task, and itâ€™s late, and I donâ€™t have energy, so I couldnâ€™t even do it if I wanted to, so letâ€™s do it tomorrow.)

And then, when I have removed that burden, I work on projects. The creative, generative, intellectual things. The things that move some kind of needle, and arenâ€™t just pointless chores.

And when I run out of energy to create, I read.

And when I run out of energy to read, I clean and go to the gym and do the other things.

And when the sun goes down everything starts to unravel: I have zero energy and the lazy dopamine-seeking behaviour comes out. So I take melatonin, and try to be in bed before the instant gratification monkey seizes power.

Procrastination

Typology of procrastination, approaches.

In my ontology there are three types of procrastination:


  ADHD Procrastination: you want to do the task, but canâ€™t because of distraction/hyperactivity.
  Anxious Procrastination: you know you have to do the task, but you donâ€™t want to, because it triggers difficult emotions.
  Decision Paralysis Procrastination: you donâ€™t know how to execute the task, because it involves a decision and you have difficulty making the decision.


ADHD Procrastination

This is the easiest kind to address. The solution is pharmacological treatment for ADHD + having a productivity system and some tricks.

Anxious Procrastination

This one is harder. The good thing is you know, cognitively, what you have to do. The hard part is getting over the aversion.

In the short term, the way to fix this is to do it scared. Accept the anxiety. Asking for help also works, sometimes you just need someone in the room with you when you hit send on the email. You can also use techniques like CBT to rationally challenge the source of the anxiety and maybe overcome it.

In the long term: write down the things you procrastinate one due to anxiety, and find the common through-line, or the common ancestor. By identifying the emotional root cause, you can work on fixing it.

Decision Paralysis Procrastination

And this is the hardest, because you donâ€™t know, cognitively, what the right choice is, and also you probably have a lot of anxiety/aversion around it. Many things in life are susceptible to this: you have set of choices, thereâ€™s good arguments for/against each one, and you have a lot of uncertainty as to the outcomes. And so you ruminate on it endlessly.

I donâ€™t have a good general solution for this.

Talking to people helps: friends, therapists, Claude. This works because thinking by yourself has diminishing returns: you will quickly exhaust all the thoughts you will have about the problem, and start going in circles. Often people will bring up options/considerations I would never have thought of. Sometimes, if youâ€™re lucky, thatâ€™s all it takes: someone mentions an option you had not considered and you realize, oh, it was all so simple.

One thing to consider is that thinking in your head is inherently circular, because you have a limited working memory, and you will inevitably start going in circles. Writing things down helps here. Treat the decision, or the emotions behind it, like an object of study, or an engineering problem. Sit down and write an essay about it. Name the arguments, number the bullet points, refer back to things. Make the thoughts into real, physical, manipulable entities.

Introspection

Journaling is good for detecting maladaptive patterns and tracking your progress.

I keep a hierarchical journal in Obsidian. Hierarchical because I have entries for the days, weeks, months, and years. The directory tree looks like this:

Journal/
  Daily/
    YYYY/
      MM/
        YYYY-MM-DD.md
  Weekly/
    YYYY/
      YYYY-WW.md
  Monthly/
    YYYY/
      YYYY-MM.md
  Yearly/
    YYYY.md


In the morning I finish yesterdayâ€™s journal entry, and begin todayâ€™s. Every Sunday I write the review of the week, the first of each month I write the review of the previous month, the first of each year I review the past year. The time allotted to each review is in inverse proportion to its frequency: so a monthly review might take an hour while a yearly review might take up a whole morning.

The daily reviews are pretty freeform. Weekly and above thereâ€™s more structure. For example, for the weekly reviews I will write a list of the salient things that happened in the week. Then I list on what went well and what went poorly. And then I reflect on how I will change my behaviour to make the next week go better.

Journaling is a valuable habit. I started doing it for vague reasons: I wasnâ€™t sure what I wanted to get out of it, and it took a long time (and long stretches of not doing it) until it became a regular, daily habit. Iâ€™ve been doing it consistently now for three years, and I can identify the benefits.


  
    The main benefit is that to change bad patterns, you have to notice them. And it is very easy to travel in a fix orbit, day in, day out, and not notice it. Laying it out in writing helps to notice the maladaptive coping mechanisms. Reading back over the journal entries helps you notice: when an event of type X happens, I react with Y.
  
  
    Todayâ€™s journal entry is a good default place for writing ad-hoc notes or thoughts. Often I wanted to write something, but didnâ€™t know where I would file it (how do you even file these little scraps of thought?) and from not knowing where to put it, I would not do it. Nowadays I just begin writing in the journal. Later, if it is valuable to file it away, I do so.
  
  
    Creating a journal entry in the morning is a good opportunity to go over the goals and priorities for the day and explicitly restate them to myself.
  
  
    The final benefit is retrospection: I can look at the past and see how my life has changed. And this is often a positive experience, because the things that worried me didnâ€™t come to pass, the things I used to struggle with are now easy, or at least easier.

    Thereâ€™s a paradox with productivity: when you grind executive function enough, things that you used to struggle with become quotidian. And so what was once the ceiling becomes the new floor. You no longer feel proud that you did X, Y, Z because thatâ€™s just the new normal. Itâ€™s like the hedonic treadmill. You might feel that you never get to â€œproductiveâ€. Journaling helps to combat this because you can see how far youâ€™ve come.
  


Time

Manage time at the macro level with calendars, at the micro level with timers.

To manage time, you need a calendar (macro) and a timer (micro).

Macro

At the macro level, I use the calendar very lightly. Mostly for social things (to ensure I donâ€™t forget an event, and that I donâ€™t double-book things). I also use it to schedule the gym: if the goal is to lift, say, five times a week, I schedule five time blocks to lift. Lifting is special because it has a lot of temporal constraints:


  I lift exactly n times per week.
  I lift at most once a day.
  I lift in the evening, which potentially clashes with social things.
  There are adjacency constraints, e.g. doing shoulders the day before chest is bad.
  There is at least one rest day which has to be scheduled strategically (e.g. to have maximal distance between successive deadlift sessions).


But outside these two categories, my calendar is empty.

The calendar might be useful to you as a self-binding device. If you keep dragging some project along because you â€œhavenâ€™t made timeâ€ for it: consider making a time block in the calendar, and sticking to it. Creating a calendar event is, literally, making time: itâ€™s like calling malloc_time().

Some people use the calendar as their entire todo list. I think this kind of works if your todo list is very coarse grained: â€œbuy groceriesâ€ and â€œgo to the dentistâ€. But I have a very fine-grained todo list, and putting my tasks in the calendar would make it overwhelming.

Another problem with calendars is they are too time-bound: if I make a calendar block to do something, and I donâ€™t do it, the calendar doesnâ€™t know it. It just sits there, forgotten, in the past. In a todo list, everything gets dragged along until I explicitly complete it. Along the same lines, the calendar is not good for collecting vague ideas and plans for things you want to do in the future, while todo lists are ideal for this.

Micro

The problem with todo lists is that theyâ€™re timeless: there is no sense of urgency. You look at the list and think, I could do the next task now, or in five minutes, or in an hour. Thereâ€™s always some time left in the day. Or tomorrow. You need a way to manufacture urgency.

If you have ADHD youâ€™ve probably heard of the Pomodoro method, tried it, and bounced off it. The way itâ€™s framed is very neurotypical: itâ€™s scaffolding around doing, but ADHD people often have problems with the doing itself. And so the scaffolding is kind of pointless.

The method works well in three kinds of contexts:


  
    Overcoming Aversion: when you have a large number of microtasks, each of which takes a few seconds to a few minutes, but the number of them, and the uncertainty factor, makes the sum seem a lot larger. A classic example for me is having to reply to like ten different people. Realistically, each person can be handled in 15s. One or two might require a couple of minutes to compose a longer reply. But often I will avoid those tasks like the plague and drag them across the entire day.

    The pomodoro method works here because youâ€™re basically trading (up to) 25m of pain for an entire dayâ€™s peace and quiet. So you get all the annoying little tasks together, start a timer, and go through them. And usually youâ€™re done in maybe ten minutes. And you feel really good after, because all those annoying little tasks are done.

    It really is amazing what a little bit of fake urgency can do.
  
  
    Starting: sometimes the problem is just starting. It is very trite, but itâ€™s true. You have something you want to want to do, but donâ€™t want to do. I want to want to read this book, to learn this topic, to write this blog post, to work on this software project. But I donâ€™t want to do it. The pomodoro method helps you start.

    Youâ€™re not committing to finishing the project. Youâ€™re not committing to months or weeks or days or even hours of work. Youâ€™re committing to a half hour. And if you work just that half hour: great, promise kept. 30m a day, over the course of a single month, is 15h of work. And often I start a 30m timer and end up working four hours, and maybe thatâ€™s a good outcome.
  
  
    Stopping: dually, sometimes the problem is stopping. If youâ€™re trying to advance multiple projects at the same time, if you hyperfocus on one, it eats into the time you allocated for the others. And more broadly, spending too much time on one project can derail all your plans for the day. Maybe you meant to go to the gym at 6pm but you got so stuck in with this project that itâ€™s 8:30pm and youâ€™re still glued to the screen. So the gym suffers, your sleep schedule suffers, etc.

    Actually stopping when the pomodoro timer goes off can prevent excessive single-mindedness.

    Additionally, the five-minute break at the end of the pomodoro block is useful. Itâ€™s a time to get up from the computer, unround your shoulders, practice mindfulness, essentially, all those little things that you want to do a few times throughout the day.
  


Tactics

Stratagems, tricks.

Task Selection

To select the next task, pick either the shortest or the most-procrastinated task.

I donâ€™t like the word â€œprioritizeâ€, because it has two subtly different meanings:


  â€œWeak prioritizationâ€ means to sort a list of tasks by some unspecified criterion, that is, to establish an order where some things are prior to another.
  â€œStrong prioritizationâ€ is to sort a list specifically by importance.


â€œWeak prioritizationâ€ is something everyone should do: it takes a moment to go over the todo list and drag the tasks into more or less the order in which you will do them. This keeps the most relevant tasks near the top, which is where your eyes naturally go to.

â€œStrong prioritizationâ€ is a terrible job scheduling algorithm. Importance alone is not good enough.

Consider the case where you have a very important task A which takes a long time to finish, and a less important task B which takes 5m to finish. For example, writing an essay versus replying to an email. Which should you do first? I would execute B first, because doing so in turn unblocks Bâ€™s successor tasks. If you reply to the email and then get to work on task A, the other person has time to read your email and reply to you. And the conversation moves forward while you are otherwise engaged.

Of course, the pathological version of this is where you only action the quick wins: all the minute little chores get done instantly, but the big tasks, requiring long periods of concentration, get postponed perpetually.

My task-selection algorithm is basically: do the shortest task first, with two exceptions:


  Stalled tasks get a priority bump. If I created a task weeks ago, or if Iâ€™ve been postponing in for many days in a row, it has to be done now.
  Content-dependence: if Iâ€™m working on a particular project, Iâ€™d rather focus on tasks from that project, rather than from the global todo list.


Visual Field Management

To remember something, put it in your visual field. Dually: to forget, get it out of sight.

Out of sight, out of mind. The corollary: to keep something in mind, put it in your visual field; to keep it out, leave it out.

My desk is very spartan: thereâ€™s a monitor, a mouse, and a keyboard, and a few trinkets. My desktop is empty. There are no files in it. The dock has only the apps I use frequently. And at a higher level, I try to keep the apartment very clean and orderly. Because everything thatâ€™s out of place is a distraction, visual noise. Thatâ€™s the negative aspect: the things I remove.

The positive aspect, the things I keep in my visual field: most of the time, I have two windows open on my computer the todo list occupies the left third of the screen, the right two-thirds are occupied by whatever window I have open at the time, e.g.:



And so at a glance, I can see:


  What Iâ€™m currently working on.
  What I will work on next.
  The list of active projects, so that I donâ€™t forget they exist.


Project Check-Ins

Keep in regular contact with long-running projects.

A common failure mode I have is, I will fail to finish a project because I forget I even started it. Or, relatedly: I will let a project drag on and on until enough time has passed that my interests have shifted, the sun has set on it, and it is now a slog to finish.

One reason I do this is that creative/intellectual work often requires (or feels like it requires) long stretches of uninterrupted time. So I procrastinate working on something until I can find such a chunk of time. Which never comes. Time passes and the project begins to slip the moorings of my attention, as other new and shiny things arrive.

And sometimes I will pick the project back up after months or years, and I have lost so much context, itâ€™s impossible to know what I even intended. And then you procrastinate even more, because you donâ€™t want to feel the guilty of picking up a project and realizing it has become strange and unfamiliar to you.

One way to combat this is to make regular project checkins. This could be a daily or few-times-a-week recurring task on Todoist that just says â€œspend 30m on this projectâ€.

You donâ€™t even have to work on the thing: just allocate fifteen minutes to hold the project in your mind and nothing else. If itâ€™s creative writing, you might open the Word document and just look at it. If itâ€™s a programming project: read the Jira board and look at the code again. Donâ€™t write anything. Just read the code. You will likely come up with a few tasks to do, so write those down. Think. Plan. Build up the structures in your mind, refresh the caches. If you can do, do, otherwise, plan, and if you canâ€™t even do that, read.

When youâ€™re doing this regularly, when youâ€™re in regular contact with the project, when the shape of it is clear in your mind, you will have the tasks on the top of your mind, you will no longer feel that you need a giant empty runway of time to work on it, you will be able to work on it in shorter chunks.

To manage long-term creative work, keep in regular contact. That doesnâ€™t mean work on them every day, but maybe look at them every day.

The pomodoro method works here. Set a timer for just 25m to keep in touch with the project.

Centralize Your Inboxes

Bring all tasks, broadly defined, into one todo list.

Life is full of inboxes:


  Email
  DMs on Twitter, iMessage, WhatsApp, Signal, Discord, etc.
  Twitter bookmarks
  Browser bookmarks
  Your Downloads folder.
  Messages in my myGov inbox.
  The physical mailbox in my apartment.


These are inboxes because they fill up over time and need action to empty. You can also think of them as little domain-specific task lists. â€œCentralizing your inboxesâ€ means moving all these tasks from their silos into the one, central todo list.

For example, I have a daily task called â€œcatch upâ€ to clear the digital inboxes:


  Go through all my communication apps (email, Discord, Twitter DMs etc) and triage the unread conversations: if something needs replying to, I either reply immediately or make a task to reply later so I donâ€™t forget.
  File the contents of my Downloads folder.
  Go through Twitter/browser bookmarks and turn them into tasks (e.g., if I bookmark an article, the task is to read the article).


In this way I mostly manage to stay on top of comms.

Inbox Zero

All inboxes should be at zero.

You have probably heard of inbox zero. It sounds like LinkedIn-tier advice. But if you struggle with comms, with replying to people in a timely manner (or at all), inbox zero is a good strategy. There are two reasons, briefly:


  Inbox zero has no false negatives: if an inbox is empty, you know youâ€™ve handled everything.
  Important communications have a way of â€œcamouflagingâ€ themselves among irrelevance.


And, like everything: before you make it into a habit, it feels incredibly time-consuming and labour-intensive. But once you make it into a habit, itâ€™s almost effortless.

So, I will give you an example. I come in to work, and read four emails. Three couldâ€™ve been archived outright, one needed a reply from me. And I said, oh, Iâ€™ll get to it in a second. And then I got distracted with other tasks. And throughout the day I kept glancing at the email client, and thinking, yeah, I will get to it. Eventually I got used to those four emails: they are the â€œnew normalâ€, and whatâ€™s normal doesnâ€™t require action. I would think: if those emails are there, and I already looked at them, then itâ€™s probably fine. At the end of the day I looked at the inbox again and saw, wait, no, one of those emails was actually important. Thatâ€™s the failure mode of inbox greater-than-zero: the important stuff hides among the irrelevant stuff, such that a quick glance at the todo list doesnâ€™t show anything obviously wrong. Dually, with inbox zero, if you see a single email in the inbox, you know thereâ€™s work to do.

Inbox zero removes ambiguity. If thereâ€™s anything in the inbox, you know, unambiguously, you have a task to complete. If there is nothing in the inbox, you know, unambiguously, there is nothing to do. Inbox zero frees you from false negatives, where you think youâ€™ve handled your correspondence but thereâ€™s some important email, camouflaged among the trivial ones, that has not been replied to.

A problem with doing inbox zero is most communication apps (like Discord, Slack, iMessage etc.) donâ€™t have a concept of an inbox, just the read/unread flag on conversations. Since thereâ€™s no separation between the inbox and the archive, it takes more discipline to ensure every conversation is replied to.

Inbox Bankruptcy

If an inbox is overwhelmed, archive it in a recoverable way.

By the time I started to become organized Iâ€™d already accumulated thousands of bookmarks, unread emails, files in my downloads folder, papers in my physical inbox, etc. It would have been a Herculean effort to file these things away. So I didnâ€™t. All the disorganized files, I wrapped them up in a folder and threw them in my Attic folder. Emails? Archived. Bookmarks? Exported to HTML, archived the export, and deleted them from the browser.

Ideally you should do this once, at the start.

And by archiving things rather than deleting them, you leave open the possibility that as some point in the future, you might be able to action some of those things. Triage the old bookmarks, sort your filesystem, etc.

Do It On Your Own Terms

Bring aversion-causing tasks into an environment that you control.

If youâ€™re averse to doing something, for emotional reasons, one way to overcome the aversion is to do it as much as possible on your own terms.

An example: you have to fill out some government form. Youâ€™re averse to it because you worry about making a mistake. And just the thought of opening the form fills you with dread. So, take the boxes in the form, and make a spreadsheet for them. If fonts/colours/emojis/etc. if that makes it feel more personal, or like something you designed and created. Then fill out the form in the spreadsheet. And then copy the values to the form and submit.

This helps because instead of performing the task in this external domain where you feel threatened, youâ€™re performing the task in your own domain, in your own terms.

Another example: you have an email you have to reply to, and youâ€™re anxious about it. Just opening the email client gives you a bad feeling. Instead, try composing the email elsewhere, say, in a text editor. The change of environment changes the emotional connotation: youâ€™re not replying to an email, youâ€™re writing a text. You might even think of it as a work of fiction, a pseudoepigraphy.

Replace Interrupts with Polling

Turn off notifications, check comms as an explicit task.

â€œInterruptsâ€ means notifications, which arrive at unpredictable and often inconvenient times. â€œPollingâ€ means manually checking the source of the notifications for things to action.

The obvious benefit of replacing interrupts with polling is you donâ€™t get interrupted by a notification. The less obvious benefit is that when notifications are smeared throughout the day, it is easy for them to fall through the cracks. Something comes in when youâ€™re busy, and you swipe it away, and forget about it, and realize days later you forgot to respond to an important message. Polling is focused: youâ€™ve chosen a block of time, youâ€™re committed to going through the notifications systematically. Instead of random islands of interruptions throughout the day, you have a few short, focused blocks of going through your notifications. Often I get an email while Iâ€™m on my phone and think, well, I canâ€™t reply, typing on mobile is horrible, Iâ€™m on a train, etc. Polling usually happens at my desk so I have no excuses: Iâ€™m in the right environment and in the right mental state.

This is so trite. â€œPut your phone on Do Not Disturb and silence notificationsâ€. And yet it works. For a long time I resisted this because I aspire to be the kind of person who gets a message and replies within minutes. But I didnâ€™t notice how much notifications were impairing my focus until one day I accidentally put the phone/desktop on DND and had a wonderfully productive, distraction-free day.

Accountability Buddy

Get someone to sit next to you while you work.

If youâ€™re struggling to work on something, work next to another person. Set a timer and tell them what youâ€™re going to accomplish and when the timer ends tell them how you did. Just being around other people can make it easier to overcome aversion. This is why coworking spaces are useful.

If you donâ€™t have a person around, you might try Focusmate. It works for some people.

Sometimes Iâ€™ll start a conversation with Claude, lay out my plans for the day, and update Claude as I do things. If Iâ€™m stuck, or if I need help overcoming procrastination, I can ask Claude for help, and itâ€™s easier to do that in an on-going thread because Claude already has the necessary context, so I donâ€™t have to describe what Iâ€™m struggling with ab initio.

Plan First, Do Later

Separate planning from action, so if you get distracted while acting, you can return to the plans.

Separating planning from doing can be useful. Firstly because planning/doing require different kinds of mental energy. When youâ€™re too tired to do, you can often still plan. Secondly because by separating them you can look back and see how useful the plan was, how much you stuck to it, and then get better at planning.

Thirdly, and most importantly, because for ADHD people doing can be a source of distractions that impair other tasks. From Driven to Distraction:


  The first item on the list referred to a cough drop. As I read it, I asked her about it.

  â€œOh,â€ she answered, â€œthat is about a cough drop someone left on the dashboard of our car. The other day I saw the cough drop and thought, Iâ€™ll have to throw that away. When I arrived at my first stop, I forgot to take the cough drop to a trash can. When I got back into the car, I saw it and thought, Iâ€™ll throw it away at the gas station. The gas station came and went and I hadnâ€™t thrown the cough drop away. Well, the whole day went like that, the cough drop still sitting on the dashboard. When I got home, I thought, Iâ€™ll take it inside with me and throw it out. In the time it took me to open the car door, I forgot about the cough drop. It was there to greet me when I got in the car the next morning. [â€¦]

  It was such a classic ADD story that Iâ€™ve come to call it the â€œcough drop signâ€ when a person habitually has trouble following through on plans on a minute-to-minute, even second-to-second, basis. This is not due to procrastination per se as much as it is due to the busyness of the moment interrupting or interfering with oneâ€™s memory circuits. You can get up from your chair, go into the kitchen to get a glass of water, and then in the kitchen forget the reason for your being there.


Emphasis mine.

When I notice a micro-task like this, my instinct is not to do it, but to put it in the todo list. Then I try to do it immediately. And if I get distracted halfway through, itâ€™s still there, in the todo list.

A practical example is something I call the apartment survey. When I clean the apartment, I start by walking around, noticing everything that needs fixing, and creating a little task for it. Even something as simple as â€œmove the book from the coffee table to the bookshelfâ€. But I donâ€™t start anything until the survey is done. And when the survey is done, I execute it. And if I get distracted halfway through cleaning the apartment, I have the tasks in the list to go back to.

Derailment

Introspect to find the things that ruin your productivity and avoid them.

Through introspection you can discover the behaviours that derail your productivity.

Lifting in the morning derails the day. Cardio is fine, but if I lift weights in the morning, the rest of the day Iâ€™m running on -40 IQ points. The most cognitively demanding thing I can do is wash the dishes. Iâ€™m not sure what the physiology is: maybe itâ€™s exhaustion of the glycogen stores, or fatigue byproducts floating around in my brain, or the CNS is busy rewiring the motor cortex. The point is that I try to do the cognitively-demanding things in the morning and lift in the evening.

Motion also does this. I suppose itâ€™s the H in ADHD: hyperactivity. I used to be a big pacer: put on headphones, pace my room back and forth daydreaming for hours and hours. Some days I would pace so much my legs were sore. To think, I have to be in motion. But sometimes Iâ€™ve thought enough, and itâ€™s time to do.

Music, too, derails me. If I start listening to music very soon I start pacing the room and itâ€™s over. Music is almost like reverse methylphenidate: it makes me restless, mentally hyperactive, and inattentive.

So, to be productive I have to not move too much, and be in silence, and not have fried my brain with exercise.

Using OCD to Defeat ADHD

If being organized makes you feel good, spend more on organizing your productivity system.

In a sense, having a really complex productivity system is like trying to use OCD to defeat ADHD, to use high neuroticism to defeat low conscientiousness. Thereâ€™s an element of truth to that, sure (see mastery of drudgery).

But hereâ€™s the thing: you have to play to your strengths. You have to. If you are very OCD and you like order and systems and planning but you struggle with doing, then, yeah, it might work, for you, to spend more energy on the trappings of productivity (ensuring your todo list is properly formatted, organized, etc.) if that bleeds over into making it easier to do the real, meaningful things.

For example: I like emojis in my todo list. The chores have a ðŸ§¼ emoji, the comms tasks have an âœ‰ï¸ emoji. That kind of thing. Makes it easy to see at a glance what kind of things I have to do, to group them by category. But Todoist doesnâ€™t support emoji icons on tasks, unlike Notion, so adding the emojis takes a bit more effort: I have to open Raycast and search for the emoji I want and paste it into the task title. It adds a little friction each time I create a task, but the benefit is I enjoy using the todo list more.

The Master of Drudgery

Avoid spending too much productive time on worthless chores.

A productivity antipattern: indulging too much in â€œquick winsâ€.

Thereâ€™s this running joke, or meme, online, about the kind of person who has this huge, colossal productivity system, but they get nothing done. They have five todo list apps and everything is categorized and indexed and sorted, but their material output is zero. They complete a hundred tasks a day and when you interrogate what those tasks are they are â€œbrush my teethâ€ or â€œreorganize my bookshelfâ€. Thereâ€™s a lot of truth to that.

Every task falls into one of two categories: the quick wins, and everything else. Life is not made of quick wins. Creative, generative, open-ended work requires long periods of focused work. A lot of unpleasant, aversion-causing things have to be done. But the quick wins are infinite: thereâ€™s always some micro-chore to do around the house, for example.

I donâ€™t have advice specifically on avoiding this. But you should notice if youâ€™re doing it and course-correct.

Thrashing

Donâ€™t let procrastiation on one task derail everything else.

A bad failure mode I have is: I have a task T that I have to do, but I canâ€™t, because of some kind of aversion. But when I try to work on other things, the alarms are going off in my head, telling me to work on T because youâ€™ve been putting this off for so long and life is finite and the years are short and all that. The end result is that because one thing is blocked, everything grinds to a halt. Itâ€™s a very annoying state to be in.

And I donâ€™t have a perfect solution, but I try to manage it but applying a sense of proportionality, â€œrender unto Caesarâ€ etc. You canâ€™t ignore T forever, dually, you probably wonâ€™t solve it in the next ten minutes. But you can timebox T: allocate some block of time every day to try to advance it, or at least to work around it, e.g. to ask a friend for help, for example. And the rest of the day you can dedicate to moving other things forward.

Put Travel in the Calendar

Calculate travel time ahead of time to avoid being late.

I am chronically late. So if I have a calendar event like a party at someoneâ€™s home, I will go on Google Maps and measure the travel time (from my home or wherever Iâ€™m likely to be) to the destination, and make a time block for that. e.g., if it takes 30m to go to the dentist and back, this is what my calendar looks like:



This ensures I leave my home on time. If itâ€™s something especially important I often add 15m to the travel block as a buffer.

Choice of Tools

Use tools that are effective and you like.

What productivity app should I use? Reminders? Linear? Todoist? A bullet journal?

Use something that feels good and works. Thatâ€™s all. Personally I use Todoist. A lot of people think todo list apps are commodities, but when you have an app open for 98% of your screentime, the little subtleties really add up. Iâ€™ve tried using Reminders, Linear, as my todo lists, and building my own. My productivity always suffers and I always go back to Todoist.

One app is better than two: the more disjoint things you have to pay attention to, the worse it is.

If youâ€™re a software engineer I strongly advise against building your own, which is a terrible form of procrastination for creative types.

Resources


  How To Do Things describes an ADHD-friendly version of the Pomodoro method. Itâ€™s a 50 page PDF with no fluff, so itâ€™s worth buying to support writers who donâ€™t waste the readerâ€™s time.
  Getting Things Done has a lot of good advice (e.g. dump your entire brain into the todo list) but itâ€™s somewhat neurotypical in that itâ€™s assumed you wonâ€™t have any problems actually executing the tasks.


Acknowledgements

Thanks to Cameron Pinnegar for reviewing.

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google: 'Your $1000 phone needs our permission to install apps now' [video]]]></title>
            <link>https://www.youtube.com/watch?v=QBEKlIV_70E</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45082750</guid>
        </item>
        <item>
            <title><![CDATA["This telegram must be closely paraphrased before being communicated" Why?]]></title>
            <link>https://history.stackexchange.com/questions/79371/this-telegram-must-be-closely-paraphrased-before-being-communicated-to-anyone</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45082731</guid>
            <description><![CDATA[Some historical documents from WWII have a notice on them stating

This telegram must be closely paraphrased before being communicated to anyone.

The documents I've found were received by the United]]></description>
            <content:encoded><![CDATA[
It appears that it was US military communications doctrine to not send the exact same message twice using different encryption ("none" counting as one type of encryption), and the term of art for changing a message to avoid that was indeed "paraphrase".
I managed to dig up a US Army document on Cryptology from roughly that era that appears to discuss paraphrasing. The document in question is Department of the Army Technical Manual TM 32-220(pdf), dated 1950, titled "BASIC CRYPTOGRAPHY". It apparently supersedes previous documents TM-484 from March 1945 and TM 11-485 from June 1944. It would probably be more ideal to look at them, since they are closer to the time you are interested in, but I was not able to find them online.
Here's what this declassified manual had to say about "paraphrasing", from Chapter 7, in the section Fundamental Rules of Cryptographic Security, section 84, subsection b, rule 3 (titled "Text of messages")

(a) Never repeat in the clear the identical text of a message once
sent in cryptographic form, or repeat in cryptographic form  the text
of a message once sent in the clear. Anything which  will enable an
alert enemy to compare a given piece of plain  text with a cryptogram
that supposedly contains this plain  text is highly dangerous to the
safety of the cryptographic  system. Where information must be given
out for publicity,  or where information is handled by many persons,
the plain text version should be very carefully paraphrased before
distribution, to minimize the data an enemy might obtain  from an
accurate comparison of the cryptographic text with  the equivalent,
original plain text. To paraphrase a message  means to rewrite it so
as to change its original wording as  much as possible without
changing the meaning of the message. This is done by altering the
positions of sentences in  the message, by altering the positions of
subject, predicate,  and modifying phrases or clauses in the sentence,
and by  altering as much as possible the diction by the use of
synonyms and synonymous expressions. In this process, deletion  rather
than expansion of the wording of the message is  preferable, because
if an ordinary message is paraphrased  simply by expanding it along
its original lines, an expert can  easily reduce the paraphrased
message to its lowest terms, and  the resultant wording will be
practically the original message.  It is very important to eliminate
repeated words or proper  names, if at all possible, by the use of
carefully selected  pronouns; by the use of the words "former,"
"latter," "first-mentioned," "second-mentioned"; or by other means.
After  carefully paraphrasing, the message can be sent in the other
key or code.
(b) Never send the literal plain text or a paraphrased
version of  the plain text of a message which has been or will be
transmitted in cryptographed form except as specifically provided  in
appropriate regulations

(emphasis mine)
In fact the allies would have have known intimately about how this was possible, because this is one of the ways they ended up decrypting the stronger German Enigma cipher. Captured machines using simpler ciphers were used to break those simpler ciphers. The fact that the Germans were encrypting the exact same messages in both ciphers meant the allies could know (for those messages) what both the unencrypted and encrypted messages were, which allowed them to decrypt the stronger cyphers as well, or quickly figure out what today's code was.

Though Enigma had some cryptographic weaknesses, in practice it was
German procedural flaws, operator mistakes, failure to systematically
introduce changes in encipherment procedures, and Allied capture of
key tables and hardware that, during the war, enabled Allied
cryptologists to succeed.

    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[F-Droid site certificate expired]]></title>
            <link>https://gitlab.com/fdroid/fdroid-website/-/issues/883</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45082595</guid>
            <description><![CDATA[I got error when access f-droid.org on Edge and Chrome]]></description>
            <content:encoded><![CDATA[







Skip to content



GitLab

  
  
  
  









Why GitLab


Pricing


Contact Sales


Explore





Why GitLab


Pricing


Contact Sales


Explore




Sign in



Get free trial


















]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Why haven't quantum computers factored 21 yet?]]></title>
            <link>https://algassert.com/post/2500</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45082587</guid>
            <description><![CDATA[Craig Gidney's computer science blog]]></description>
            <content:encoded><![CDATA[

In 2001, quantum computers factored the number 15.
Itâ€™s now 2025, and quantum computers havenâ€™t yet factored the number 21.
Itâ€™s sometimes claimed this is proof thereâ€™s been no progress in quantum computers.
But thereâ€™s actually a much more surprising reason 21 hasnâ€™t been factored yet, which jumps out at you when contrasting the operations used to factor 15 and to factor 21.

The circuit (the series of quantum logic gates) that was run to factor 15 can be seen in Figure 1b of â€œExperimental realization of Shorâ€™s quantum factoring algorithm using nuclear magnetic resonanceâ€:


  


The important cost here is the number of entangling gates.
This factoring-15 circuit has 6 two-qubit entangling gates (a mix of CNOT and CPHASE gates).
It also has 2 Toffoli gates, which each decompose into 6 two-qubit entangling gates.
So thereâ€™s a total of 21 entangling gates in this circuit.

Now, for comparison, here is a circuit for factoring 21.
Sorry for rotating it, but I couldnâ€™t get it to fit otherwise.
Try counting the Toffolis:



(Hereâ€™s an OPENQASM2 version of the circuit, so you can test it produces the right distribution if youâ€™re inclined to do so.)

In case you lost count: this circuit has 191 cnot gates and 369 Toffoli gates, implying a total of 2405 entangling gates.
Thatâ€™s 115x more entangling gates than the factoring-15 circuit.
The factoring-21 circuit is more than one hundred times more expensive than the factoring-15 circuit.

When I ask people to guess how many times larger the factoring-21 circuit is, compared to the factoring-15 circuit, thereâ€™s a tendency for them to assume itâ€™s 25% larger.
Or maybe twice as large.
The fact that itâ€™s two orders of magnitude more expensive is shocking.
So Iâ€™ll try to explain why it happens.

(Quick aside: the amount of optimization that has gone into this factoring-21 circuit is probably unrepresentative of what would be possible when factoring big numbers.
I think a more plausible amount of optimization would produce a circuit with 500x the cost of the factoring-15 circuitâ€¦ but a 100x overhead is sufficient to make my point.
Regardless, special thanks to Noah Shutty for running expensive computer searches to find the conditional-multiplication-by-4-mod-21 subroutine used by this circuit.)

Where does the 100x come from?

A key background fact you need to understand is that the dominant cost of a quantum factoring circuit comes from doing a series of conditional modular multiplications under superposition.
To factor an $n$-bit number $N$, Shorâ€™s algorithm will conditionally multiply an accumulator by $m_k = g^{2^k} \pmod{N}$ for each $k < 2n$ (where $g$ is a randomly chosen value coprime to $N$).
Sometimes people also worry about the frequency basis measurement at the end of the algorithm, which is crucial to the algorithmâ€™s function, but from a cost perspective itâ€™s irrelevant.
(Itâ€™s negligible due by an optimization called â€œqubit recyclingâ€, which I also could have used to reduce the qubit count of the factoring-21 circuit, but in this post Iâ€™m just counting gates so meh).

There are three effects that conspire to make the factoring-15 multiplications substantially cheaper than the factoring-21 multiplications:


  All but two of the factoring-15 multiplications end up multiplying by 1.
  The first multiplication is always ~free, because its input is known to be 1.
  The one remaining factoring-15 multiplication can be implemented with only two CSWAPs.


Letâ€™s consider the case where $g=2$.
In that case, when factoring 15, the constants to conditionally multiply by would be:

>>> print([pow(2, 2**k, 15) for k in range(8)])
[2, 4, 1, 1, 1, 1, 1, 1]


First, notice that the last six constants are 1.
Multiplications by 1 can be implemented by doing nothing.
So the factoring-15 circuit is only paying for 2 of the expected 8 multiplications.

Second, notice that the first conditional multiplication (by 2) will either leave the accumulator storing 1 (when its control is off) or storing 2 (when its control is on).
This can be achieved much more cheaply by performing a controlled xor of $1 \oplus 2 = 3$ into the accumulator.

Third, notice that the only remaining multiplication is a multiplication by 4.
Because 15 is one less than a power of 2, multiplying by 2 modulo 15 can be implemented using a circular shift.
A multiplication by 4 is just two multiplications by 2, so it can also be implemented by a circular shift.
This is a very rare property for a modular multiplication to have, and here it reduces what should be an expensive operation into a pair of conditional swaps.
(If you go back and look at the factoring-15 circuit at the top of the post, the 2 three-qubit gates are being used to implement these two conditional swaps.)

You may worry that these savings are specific to the choice of $g=2$ and $N=15$.
And they are in fact specific to $N=15$.
But they arenâ€™t specific to $g=2$.
They occur for all possible choices of $g$ when factoring 15.

For contrast, letâ€™s now consider what happens when factoring 21.
Using $g=2$, the multiplication constants would be:

>>>  print([pow(2, 2**k, 21) for k in range(10)])
[2, 4, 16, 4, 16, 4, 16, 4, 16, 4]


This is going to be a lot more expensive.

First, thereâ€™s no multiplications by 1, so the circuit has to pay for every multiplication instead of only a quarter.
Thatâ€™s a ~4x relative cost blowup vs factoring 15.
Second, although the first-oneâ€™s-free trick does still apply, proportionally speaking itâ€™s not as good.
It cheapens 10% of the multiplications rather than 50%.
Thatâ€™s an extra ~1.8x cost blowup vs factoring 15.
Third, the multiplication by 4 and 16 canâ€™t be implemented with two CSWAPs.
The best conditionally-multiply-by-4-mod-21 circuit that I know is the one being used in the diagram above, and it uses 41 Toffolis.
These more expensive multiplications add a final bonus ~20x cost blowup vs factoring 15.

(Aside: multiplication by 16 mod 21 is the inverse of multiplying by 4 mod 21, and the circuits are reversible, so multiplying by 16 uses the same number of Toffolis as multiplying by 4.)

These three factors (multiplying-by-one, first-oneâ€™s-free, and multiplying-by-swapping) explain the 100x blowup in cost of factoring 21, compared to factoring 15.
And this 100x increase in cost explains why no one has factored 21 with a quantum computer yet.



Another contributor to the huge time gap between factoring 15 and factoring 21 is that the 2001 factoring of 15 was done with an NMR quantum computer.
These computers were known to have inherent scaling issues, and in fact itâ€™s debated whether NMR computers were even properly â€œquantumâ€.
If the 2001 NMR experiment doesnâ€™t count, I think the actually-did-the-multiplications runner-up is a 2015 experiment done with an ion trap quantum computer (discussed by Scott Aaronson at the time).

Yet another contributor is the overhead of quantum error correction.
Performing 100x more gates requires 100x lower error, and the most plausible way of achieving that is error corection.
Error correction requires redundancy, and could easily add a 100x overhead on qubit count.
Accounting for this, I could argue that factoring 21 will be ten thousand times more expensive than factoring 15, rather than â€œmerelyâ€ a hundred times more expensive.

There are papers that claim to have factored 21 with a quantum computer.
For example, hereâ€™s one from 2021.
But, as far as I know, all such experiments are guilty of using optimizations that imply the code generating the circuit had access to information equivalent to knowing the factors (as explained in â€œPretending to factor large numbers on a quantum computerâ€ by Smolin et al).
Basically: they donâ€™t do the multiplications, because the multiplications are hard, but the multiplications are what make it factoring instead of simpler forms of period finding.
So I donâ€™t count them.

There is unfortunately a trickle of bullshit results that claim to be quantum factoring demonstrations.
For example, I have a joke paper in this yearâ€™s sigbovik proceedings that cheats in a particularly silly way.
More seriously, I enjoyed â€œReplication of Quantum Factorisation Records with an 8-bit Home Computer, an Abacus, and a Dogâ€ making fun of some recent egregious papers.
I also recommend Scott Aaronsonâ€™s post â€œQuantum computing motte-and-baileysâ€, which complains about papers that benchmark â€œvariationalâ€ factoring techniques while ignoring the lack of any reason to expect them to scale.

Because of the large cost of quantum factoring numbers (that arenâ€™t 15), factoring isnâ€™t yet a good benchmark for tracking the progress of quantum computers.
If you want to stay abreast of progress in quantum computing, you should be paying attention to the arrival quantum error correction (such as surface codes getting more reliable as their size is increased) and to architectures solving core scaling challenges (such as lost neutral atoms being continuously replaced).


]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Channel3 (YC S25) Is Hiring a Founding Engineer, NYC]]></title>
            <link>https://channel3.notion.site/founding-engineer</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45082508</guid>
        </item>
        <item>
            <title><![CDATA[My Foray into Vlang]]></title>
            <link>https://kristun.dev/posts/my-foray-into-vlang/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45080808</guid>
            <description><![CDATA[Summary of the current state of Vlang and my experience writing an svg generator server]]></description>
            <content:encoded><![CDATA[ Table of contents
Open Table of contents

A little bit about Go
So, wtf is Vlang?

Maps
Struct-licious
WithOption pattern
Enums??? In this economy?
Lambda; the best kind of lamb


Some issues Iâ€™ve encountered

net.http
veb
More complex build system
Concurrency


</Thoughts>
Links


A little bit about Go
I like Go. I actually donâ€™t mind writing err != nil that much. Just set up a snippet and youâ€™re good to Go. Although, I never really felt like I had a honeymoon period with Go. I learned the language, learned about channels, wrote a bunch of CRUDs and parsers and CLIs. It always felt strictly business. I thought it was because of where I am in my career. But I was wrong.
Go is vanilla. It just werks. You build it, you ship it. The language is simple and you donâ€™t need to try hard to make it performant.
But sometimes you just want a little spiceðŸŒ¶ï¸ðŸ¥µ
Do you ever wonder what else is out there? Hobby programming is a great meme. But I feel like weâ€™re under too much pressure to produce the new unicorn SaaS with 10 million monthly active users.

You donâ€™t have to pick a tool then find the right job for it. You can just grab a hammer and start smashing stuff. The same nails youâ€™ve smashed before might feel different if you smash it with another hammer. Pick a Rusty hammer and you might end up obsessed with how important health and safety is.
So, wtf is Vlang?
I might have shot myself in the foot with the hammer analogy there, so letâ€™s talk about ice cream. Ok so hereâ€™s the gist: vanilla, drizzle some chocolate on top, peanuts? sure why not. You know this taste, you like it, it comes with more stuff on top. If you like vanilla then you might like vanilla++.
That how I see the current state of V. The syntax is similar to Go. It has extra features. The core of it is similar, you can cross compile, you have concurrency (which is also parallelism). Channels and message passing. Oh and defer as well. All my bros love using defer.
Anyway, letâ€™s see some cool stuff.

  External Link Globe
  
  
  
  
vlang
Maps
// So simple!
simple_languages := {"elixir": {"score": 100, "width": 30}}

// Alternatively
mut languages := map[string]map[string]int{"elixir": {"score": 100, "width": 30}}
languages["elixir"] = {"score": 100}
languages["elixir"]["width"] = 30
Pretty cool! Much like Go, the maps require a fixed type, dynamic objects like JSON or JavaScript requires either a DTO or a type switch.
Ok, but what about the error handling?
elixir_score := languages["elixir"]["score"] or { -1 }

if racket := languages['racket'] {
  println('racket score ${racket['score']}')
  racket_width := racket['width'] or { 0 }
  println('racket width ${racket_width}')
}

// Another way to skin the cat
if 'haskell' in languages {
  if 'score' !in languages['haskell'] {
    println('where is my haskell score??')
  }
}

// Zeroth value
languages['this_dont_exist'] // {}
languages['this_dont_exist']['score'] // 0
Donâ€™t you miss destructuring?
languages_with_racket_ocaml := {
  ...languages
  'racket': {'score': 99}
  'ocaml': {'score': 98}
}

  External Link Globe
  
  
  
  
vlang/maps
Struct-licious
module main

struct Language {
pub mut:
	score int = -1
	name  string @[required]
}

fn (lr []Language) total() int {
	mut total := 0
	for l in lr {
      if l.score > 0 {
        total += l.score
      }
	}

	return total
}

fn (lr []Language) average() int {
	return lr.total() / lr.len
}

fn main() {
	racket := Language{98, 'racket'}
    // Simple arrays too!
	langs_arr := [racket, Language{102, 'ocaml'}]
	println(langs_arr)
	println(langs_arr.total())
	println(langs_arr.average())
}
Isnâ€™t that cool? We can have receiver methods on array types. Wait - did you see that? We had a required tag on the struct, that means the program wonâ€™t compile if you donâ€™t initialise it. Thatâ€™s another cool thing I wish Go has. Not to mention, the initialiser value, Goâ€™s struct is quite predictable in how the value turns out. However, Vâ€™s struct allows you to be explicit. This came in very handy for my case!
@[xdoc: 'Server for GitHub language statistics']
@[name: 'v-gh-stats']
struct Config {
mut:
	show_help bool   @[long: help; short: h; xdoc: 'Show this help message']
	user      string = os.getenv('GH_USER')           @[long: user; short: u; xdoc: 'GitHub username env \$GH_USER']
	token     string = os.getenv('GH_TOKEN')          @[long: token; short: t; xdoc: 'GitHub personal access token env \$GH_TOKEN']
	debug     bool   = os.getenv('DEBUG') == 'true'   @[long: debug; short: d; xdoc: 'Enable debug mode env \$DEBUG']
	cache     bool   = os.getenv('CACHE') == 'true'   @[long: cache; short: c; xdoc: 'Enable caching env \$CACHE']
}
This example contains flags for running my SVG generation server, it allows you to define the flags yourself but if not, use the environmental value. Neato!

  External Link Globe
  
  
  
  
vlang/structs
WithOption pattern
Ahh yes, another thing I had to put up with. TBH, I did end up liking the pattern quite a bit. In Go, no default variables are allowed, you have to use variadics. You end up with an Option struct with zeroth value passing around a few functions to finally one last giant private receiver function that creates the struct, fills the value then finally build and check. Imagine a SQL repository pattern where you want to perform a List operation but optionally join or ensure some field is present in a query. Letâ€™s see how we can cook this.
module main

import time

@[params]
struct ListOption {
pub mut:
	created_since time.Time
}

@[params]
struct HeroListOption {
	ListOption
pub mut:
	universe string
	name     ?string
}

struct Hero {}

struct Repo[T] {}

struct Villain {}

fn (r Repo[T]) list(o ListOption) ![]T {
	$if T is Villain {
		return error('whoops you found Villain some how but its not implemented yet')
	}

	return error('whoops not implemented for ${T.name} use one of (Hero, ...)')
}

fn (r Repo[Hero]) list(o HeroListOption) ![]Hero {
	mut query := orm.build_query()

	if o.universe != '' {
		query.eq('universe', o.universe)
	}

	if o.created_since.unix() > 0 {
		query.gt('created_since', o.created_since)
	}

	if name := o.name {
		query.eq('name', name)
	}

	return r.psql(query.do()!)!
}

fn main() {
	r := Repo[Villain]{}
	r.list() or { println(err) }

	hero_repo := Repo[Hero]{}
	hero_repo.list()!
	hero_repo.list(name: 'bruce')!
	hero_repo.list(name: 'bruce', universe: 'dc')!
	hero_repo.list(name: 'bruce', universe: 'marvel')!
	hero_repo.list(created_since: time.Time{year: 1996})!
}
Thereâ€™s a lot to unpack here. Letâ€™s start with @[params] which tells the V compiler that the struct as a whole can be omitted entirely so you can write the empty function and it will still works. Secondly, since generics are a compile time thing we can use reflection to check for the name of the type itself. See link below to see what is possible. You can reflect and check for field existence and field types as well as attributes (remember @[required]?).
Alright, we keep seeing this bang (!) everywhere. So what is it? Short answer: Result type. Medium answer: (int, err) -> !int. You donâ€™t need the long answer. The bang can propagate although you must remember to handle this somewhere or it will cause a panic eventually. Finally, the optional type. I purposedly only use it for one of the field to show that it can be done, you can decide how you want to write your optionals. But damn! It feels great!

  External Link Globe
  
  
  
  
go-uber/functional-options

  External Link Globe
  
  
  
  
vlang/trailing-struct-args

  External Link Globe
  
  
  
  
vlang/compile-time-reflection

  External Link Globe
  
  
  
  
vlang/optional-and-result-type
Enums??? In this economy?
Enums are so back baby. We can totally replace the previous sectionâ€™s universe field as such.
enum Universe {
  dc
  marvel
  nil
}

fn (u Universe) str() ?string {
	return match u {
      // V knows the enum there's no need to type Universe.dc
      .dc { 'dc' }
      .marvel { 'marvel' }
      else {''}
	}
}

@[params]
struct HeroListOption {
	ListOption
pub mut:
	universe Universe = .nil
	name     ?string
}

fn (r Repo[Hero]) list(o HeroListOption) ![]Hero {
	...

	if o.universe != .nil {
		query.eq('universe', o.universe.str())
	}

	...
}

fn main() {
	hero_repo := Repo[Hero]{}
	hero_repo.list(name: 'bruce', universe: .dc)!

	// functions not expecting enum requires the full path
	// auto str() conversion here - see Go fmt.Stringer() or your __str__, __toString()
	println('${Universe.dc}')
}
Optional type might be better here. Iâ€™m okay with this though. There is backed enum as well but you can only have integer backed enums. Did you also notice? Receiver method on the backed enum baby.

  External Link Globe
  
  
  
  
vlang/enums
Lambda; the best kind of lamb
The array stucts have a set of methods you can use like the basic filter, map - there is a stdlib module called arrays as well that you need to import. It provides more complex methods like fold and the likes. I donâ€™t know about you but I am chuffed this exists.
import math

fn example() {
	// type hinting here to skip typing Universe.*
	mut universes := []Universe{}
	universes = [.dc, .marvel, .nil, .dc]
	dcs_or_marvel := universes.filter(it != .nil)
	nils := universes.filter(|u| u == .nil)

	// sorting in place
	[5, 2, 1, 3, 4].sort(a < b)
	sorted := [5, 2, 1, 3, 4].sorted(a < b)
}

struct XY {
	x int
	y int
}

fn (xy XY) dist_from_origin() f64 {
	return math.sqrt((xy.x * xy.x) + (xy.y * xy.y))
}

fn example2() {
	xys := [XY{1, 2}, XY{10, 20}, XY{-1, -69}]
	xys.sort(a.dist_from_origin() < b.dist_from_origin())
	y_asc := xys.sorted(a.y < b.y)
}
Thereâ€™s a few caveats here. You gotta make sure the function youâ€™re using actually allow for it or a < b expression, but lambda expression will work anywhere a function is accepted as an argument. However, you canâ€™t use lambda as a variable like x_asc := |a, b| a.x < b.x. Still, neat. Use the LSP to check what is accepted.

  External Link Globe
  
  
  
  
vlang/lambdas

  External Link Globe
  
  
  
  
vlang/array

  External Link Globe
  
  
  
  
vlang/arrays
Some issues Iâ€™ve encountered
As fun as it has been learning the language and building an 
  External Link Globe
  
  
  
  
svg service - it is not without problems. The language is on the immature side of things. It has had some time to cook since I last tried it in 2023 and I like it even more. Letâ€™s discuss some of the problems Iâ€™ve personally encountered.
net.http
When I was trying to call the GraphQL endpoint using the net.http module, I ran into issue where it would instantly timeout. This 
  External Link Globe
  
  
  
  
network issue described what is happening in my case precisely, adding the flag -d use_openssl completely fixed my problem. This seems to be the case when building for Ubuntu 22.4 - when building the exe for my Windows 11 I did not need this flag.
If you are wondering what the -d flag is about, it is a flag for compile-time code branching. See 
  External Link Globe
  
  
  
  
vlang/compiletime-code for more.

  External Link Globe
  
  
  
  
vlang/net.http
veb
Another weird quirk Iâ€™ve had when working with the veb HTTP server is refusing to build when trying to use gzip. Take a look at this build error message.
/root/.local/v/vlib/veb/middleware.v:129:11: error: field `Ctx.return_type` is not public
127 |         handler: fn [T](mut ctx T) bool {
128 |             // TODO: compress file in streaming manner, or precompress them?
129 |             if ctx.return_type == .file {
    |                    ~~~~~~~~~~~
130 |                 return true
131 |             }
What do you think the issue could be? Maybe my version of the language is incorrect or my build was faulty? I purged the local V install and got a fresh version straight from master branch. Yet the issue still persists. Another -d flag perhaps?
Luckily for me somebody already posted about this issue in GitHub, unluckily for me, I didnâ€™t search the error message first (whoops). Well, I canâ€™t really tell you what the issue is since I havenâ€™t delved into Vâ€™s codebase itself. But I can tell you the resolution.
In my main.v, since I was messing around with servers and running main with arguments I needed to import both modules. This was the head -n5 of my errorneous file.
module main

import os
import veb
The suggested fix?
module main

import veb
import os
Wow! The code now compiles! From a fresherâ€™s perspective I have no clue why the order of import would affect code in different modules. Namespace should be sacred and completely independent of each other. The order of import should not matter at all. Both packages seems to be unrelated so wtf happened?

  External Link Globe
  
  
  
  
vlang/veb

  External Link Globe
  
  
  
  
vlang/gzip-issue
More complex build system
I had alluded to this earlier, there is a cost to using V over Go. Vâ€™s main backend compiles to C and this comes with complexity. There are a bunch of performance optimisations you can do when building the binary itself. You can even build non-static binaries if you wish (in fact this is the default). This is a double-edged sword, with Go, you get what you got. With V, I got what I got but I wonder if what I got can be gotten differently.
This might also complicate cross-compilation, the Go team has done a lot of work to ensure things werk across different architectures and OSes. Iâ€™ve only tried compiling to Windows and Linux using the static flag. Hereâ€™s my build command:
v -prod -compress -d use_openssl -cflags '-static -Os -flto' -o main .
The -d flag would have to be optional here depending on where I am trying to target as well, Iâ€™d probably have to spend time learning whatâ€™s possible for Macs as well. I know those platforms are definitely supported since their GitHub actions page contains the CI pipelines for these, but I would personally need to check if my specific implemntation, order of imports as well as -d flags need to be there for those systems or not.
This is the one big point I have to give to Go. They really have the just werks philosophy down.

  External Link Globe
  
  
  
  
vlang/ci

  External Link Globe
  
  
  
  
vlang/performance-optimisation
Concurrency
I wondered how the performance of the concurrency is compared to Go. The model is almost identical (which is good) but surely the implementation details are different. Luckily, there is a programming benchmark that exists already that answers my questions.


  External Link Globe
  
  
  
  
benchmark/coro-sieve-v-vs-go
Since I brought up concurrency letâ€™s take a look at the code to see the implementation.
module main

import os
import strconv

fn main() {
	mut n := 100
	if os.args.len > 1 {
		n = strconv.atoi(os.args[1]) or { n }
	}

	mut ch := chan int{cap: 1}
	spawn generate(ch)
	for _ in 0 .. n {
		prime := <-ch
		println(prime)
		ch_next := chan int{cap: 1}
		spawn filter(ch, ch_next, prime)
		ch = ch_next
	}
}

fn generate(ch chan int) {
	mut i := 2
	for {
		ch <- i++
	}
}

fn filter(chin chan int, chout chan int, prime int) {
	for {
		i := <-chin
		if i % prime != 0 {
			chout <- i
		}
	}
}

  External Link Globe
  
  
  
  
benchmark/sieve.go

  External Link Globe
  
  
  
  
benchmark/sieve.v
tldr; itâ€™s finding prime numbers by computing a running channel of previous prime numbers to feed into n to check if n is divisible by any previous primes.
It seems weird to me that Vâ€™s version is timing out even though both implementation looks almost identical. So I ran the benchmark on my local machine. Hereâ€™s my justfile to run the benchmark using all I know so far about optimising V.
default:
    v -prod -gc boehm_full_opt -cc clang -cflags "-march=broadwell" -stats -showcc -no-rsp -o main_v 1.v
    go build -o main_go ./main.go
    hyperfine './main_v 100' './main_go 100' -N
And the result:
Benchmark 1: ./main_v 100
  Time (mean Â± Ïƒ):      32.1 ms Â±   2.9 ms    [User: 42.6 ms, System: 166.4 ms]
  Range (min â€¦ max):    22.1 ms â€¦  40.7 ms    99 runs

Benchmark 2: ./main_go 100
  Time (mean Â± Ïƒ):       1.8 ms Â±   0.2 ms    [User: 2.3 ms, System: 0.3 ms]
  Range (min â€¦ max):     1.2 ms â€¦   3.1 ms    1471 runs

Summary
  './main_go 100' ran
   18.18 Â± 2.81 times faster than './main_v 100'
This is exacerbated further when we run N=1000
Benchmark 1: ./main_v 1000
  Time (mean Â± Ïƒ):      1.189 s Â±  0.340 s    [User: 4.410 s, System: 8.144 s]
  Range (min â€¦ max):    0.806 s â€¦  1.830 s    10 runs

Benchmark 2: ./main_go 1000
  Time (mean Â± Ïƒ):      13.4 ms Â±   2.4 ms    [User: 132.5 ms, System: 12.3 ms]
  Range (min â€¦ max):     8.6 ms â€¦  21.2 ms    182 runs

Summary
  './main_go 1000' ran
   88.54 Â± 29.90 times faster than './main_v 1000'
Taking a look at the N=100 profiling we can see what happened exactly
âžœ cat prof.txt | sort --key 2n -n | tail -n 10
           202          0.256ms         -1.819ms           1267ns sync__new_spin_lock
           404          0.064ms         -2.664ms            158ns sync__Semaphore_init
          4387      10644.653ms        540.655ms        2426408ns sync__Semaphore_wait
          8128       5572.567ms        739.231ms         685601ns sync__Channel_try_push_priv
          8172       9062.871ms        941.089ms        1109015ns sync__Channel_try_pop_priv
         15959        406.167ms         87.435ms          25451ns sync__Semaphore_post
         16160          6.993ms        -38.159ms            433ns sync__SpinLock_lock
         16174          3.412ms          0.754ms            211ns sync__SpinLock_unlock
       1766049        380.257ms       -434.470ms            215ns sync__Semaphore_try_wait
There is a ton of calls going to Semaphore_try_wait with the actual Sempahore_wait execution itself taking over 10_000 ms in total.
This suggests to me that while the concurrency is there, it exists and work similarly to the end user. Though in the current state, itâ€™s no where near Goâ€™s maturity and optimisation.
</Thoughts>
I like V a lot. The abstraction over the syntax is so nice that made me enjoy writing the syntax as a whole. It makes me wish that Go could do more with what they have, but you and I know that Go would never. V isnâ€™t without itâ€™s problems though, the ecosystem is still quite immature, compiler flags need grokking over even if youâ€™re not a performance maximalist. IMO, the issue comes down to maturity, given enough time and contributor I believe the language will bloom beautifully. The syntax conveniences already had me sold. I know AI can write boilerplate but it feels good to not need it at all and write everything myself.
V has come a lot further than when I tried it in 2023. Iâ€™ll be actively using it from now on since my main job in Go leaves me wishing for more from time to time. If you enjoy Go anyway itâ€™s worth checking out. Life it too short to mainline one language. Oh and check out my SVG service 
  External Link Globe
  
  
  
  
ktunprasert/v-github-stats

Links
vlang - 
  External Link Globe
  
  
  
  
https://vlang.io
vlang/maps - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/v-types.html#maps
vlang/structs - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/structs.html
go-uber/functional-options - 
  External Link Globe
  
  
  
  
https://github.com/uber-go/guide/blob/master/style.md#functional-options
vlang/trailing-struct-args - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/structs.html#trailing-struct-literal-arguments
vlang/compile-time-reflection - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/conditional-compilation.html#compile-time-reflection
vlang/optional-and-result-type - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/type-declarations.html#optionresult-types-and-error-handling
vlang/enums - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/type-declarations.html#enums
vlang/lambdas - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/functions-2.html#lambda-expressions
vlang/array - 
  External Link Globe
  
  
  
  
https://modules.vlang.io/builtin.html#array
vlang/arrays - 
  External Link Globe
  
  
  
  
https://modules.vlang.io/arrays.html
svg service - 
  External Link Globe
  
  
  
  
https://github.com/ktunprasert/v-github-stats
network issue - 
  External Link Globe
  
  
  
  
https://github.com/vlang/v/issues/23717
vlang/compiletime-code - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/conditional-compilation.html#compile-time-code
vlang/net.http - 
  External Link Globe
  
  
  
  
https://modules.vlang.io/net.http.html
vlang/veb - 
  External Link Globe
  
  
  
  
https://modules.vlang.io/veb.html
vlang/gzip-issue - 
  External Link Globe
  
  
  
  
https://github.com/vlang/v/issues/20865#issuecomment-1955101657
vlang/ci - 
  External Link Globe
  
  
  
  
https://github.com/vlang/v/actions
vlang/performance-optimisation - 
  External Link Globe
  
  
  
  
https://docs.vlang.io/performance-tuning.html
benchmark/coro-sieve-v-vs-go - 
  External Link Globe
  
  
  
  
https://programming-language-benchmarks.vercel.app/v-vs-go
benchmark/sieve.go - 
  External Link Globe
  
  
  
  
https://github.com/hanabi1224/Programming-Language-Benchmarks/blob/main/bench/algorithm/coro-prime-sieve/1.go
benchmark/sieve.v - 
  External Link Globe
  
  
  
  
https://github.com/hanabi1224/Programming-Language-Benchmarks/blob/main/bench/algorithm/coro-prime-sieve/1.v ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Sheafification â€“ The optimal path to mathematical mastery: The fast track (2022)]]></title>
            <link>https://sheafification.com/the-fast-track/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45080388</guid>
        </item>
        <item>
            <title><![CDATA[Red: A programming language inspired by REBOL]]></title>
            <link>https://github.com/red/red</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45080051</guid>
            <description><![CDATA[Red is a next-generation programming language strongly inspired by Rebol, but with a broader field of usage thanks to its native-code compiler, from system programming to high-level scripting and c...]]></description>
            <content:encoded><![CDATA[



Red Programming Language

  

Red is a programming language strongly inspired by Rebol, but with a broader field of usage thanks to its native-code compiler, from system programming to high-level scripting, while providing modern support for concurrency and multi-core CPUs.
Red tackles the software building complexity using a DSL-oriented approach (we call them dialects) . The following dialects are built-in:

Red/System: a C-level system programming language compiled to native code
Parse: a powerful PEG parser
VID: a simple GUI layout creation dialect
Draw: a vector 2D drawing dialect
Rich-text: a rich-text description dialect

Red has its own complete cross-platform toolchain, featuring an encapper, a native compiler, an interpreter, and a linker, not depending on any third-party library, except for a Rebol2 interpreter, required during the alpha stage. Once 1.0 is reached, Red will be self-hosted. Currently, Red is still at alpha stage and 32-bit only.
Red's main features are:

Human-friendly syntax
Homoiconic (Red is its own meta-language and own data-format)
Functional, imperative, reactive and symbolic programming
Prototype-based object support
Multi-typing
Powerful pattern-matching Macros system
Rich set of built-in datatypes (50+)
Both statically and JIT-compiled(*) to native code
Cross-compilation done right
Produces executables of less than 1MB, with no dependencies
Concurrency and parallelism strong support (actors, parallel collections)(*)
Low-level system programming abilities through the built-in Red/System DSL
Powerful PEG parser DSL built-in
Fast and compacting Garbage Collector
Instrumentation built-in for the interpreter, lexer and parser.
Cross-platform native GUI system, with a UI layout DSL and a drawing DSL
Bridging to the JVM
High-level scripting and REPL GUI and CLI consoles included
Visual Studio Code plugin, with many helpful features
Highly embeddable
Low memory footprint
Single-file (~1MB) contains whole toolchain, full standard library and REPL (**)
No install, no setup
Fun guaranteed!

(*) Not implemented yet.
(**) Temporarily split in two binaries
More information at red-lang.org.
Running the Red REPL
Download a GUI or CLI console binary suitable for your operating system, rename it at your convenience, then run it from shell or by double-clicking on it (Windows). You should see the following output:
    ---== Red 0.6.5 ==--
    Type HELP for starting information.

    >>

A simple Hello World would look like:
    >> print "Hello World!"
    Hello World!

If you are on the GUI console, a GUI Hello World (prompt omitted):
    view [text "Hello World!"]


  

A more sophisticated example that retrieves the last commits from this repo and displays their log messages in a scrollable list:
    view [
        text-list data collect [
            foreach event load https://api.github.com/repos/red/red/commits [
                keep event/commit/message
            ]
        ]
    ]


  

Note: check also the following improved version allowing you to click on a given commit log and open the commit page on github.
You can now head to see and try some showcasing scripts here and there. You can run those examples from the console directly using Github's "raw" link. E.g.:
    >> do https://raw.githubusercontent.com/red/code/master/Showcase/calculator.red

Note: If you are using the Wine emulator, it has some issues with the GUI-Console. Install the Consolas font to fix the problem.
Generating a standalone executable
The Red toolchain comes as a single executable file that you can download for the big-3 platforms (32-bit only for now). Rename the file to redc (or redc.exe under Windows).


Put the downloaded redc binary in the working folder.


In a code or text editor, write the following Hello World program:
 Red [
     Title: "Simple hello world script"
 ]

 print "Hello World!"



Save it under the name: hello.red


Generate a compiled executable from that program: (first run will pre-compile libRedRT library)
 $ redc -c hello.red
 $ ./hello



Want to generate a compiled executable from that program with no dependencies?
 $ redc -r hello.red
 $ ./hello



Want to cross-compile to another supported platform?
 $ redc -t Windows hello.red
 $ redc -t Darwin hello.red
 $ redc -t Linux-ARM hello.red



The full command-line syntax is:
redc [command] [options] [file]

[file] any Red or Red/System source file.

The -c, -r and -u options are mutually exclusive.

[options]
-c, --compile                  : Generate an executable in the working
                                 folder, using libRedRT. (development mode)

-d, --debug, --debug-stabs     : Compile source file in debug mode. STABS
                                 is supported for Linux targets.

-dlib, --dynamic-lib           : Generate a shared library from the source
                                 file.

-e, --encap                    : Compile in encap mode, so code is interpreted
                                 at runtime. Avoids compiler issues. Required
                                 for some dynamic code.

-h, --help                     : Output this help text.

-o <file>, --output <file>     : Specify a non-default [path/][name] for
                                 the generated binary file.

-r, --release                  : Compile in release mode, linking everything
                                 together (default: development mode).

-s, --show-expanded            : Output result of Red source code expansion by
                                 the preprocessor.

-t <ID>, --target <ID>         : Cross-compile to a different platform
                                 target than the current one (see targets
                                 table below).

-u, --update-libRedRT          : Rebuild libRedRT and compile the input script
                                  (only for Red scripts with R/S code).

-v <level>, --verbose <level>  : Set compilation verbosity level, 1-3 for
                                 Red, 4-11 for Red/System.

-V, --version                  : Output Red's executable version in x.y.z
                                 format.

--config [...]                 : Provides compilation settings as a block
                                 of `name: value` pairs.

--no-compress                  : Omit Redbin format compression.

--no-runtime                   : Do not include runtime during Red/System
                                 source compilation.

--no-view                      : Do not include VIEW module in the CLI console
                                 and the libRedRT.

--view <engine>                : Select the VIEW engine (native, terminal, GTK, test)

--red-only                     : Stop just after Red-level compilation.
                                 Use higher verbose level to see compiler
                                 output. (internal debugging purpose)

--show-func-map                : Output an address/name map of Red/System
                                 functions, for debugging purposes.

[command]
build libRed [stdcall]         : Builds libRed library and unpacks the
                                 libRed/ folder locally.

clear [<path>]                 : Delete all temporary files from current
                                 or target <path> folder.

Cross-compilation targets:
MSDOS        : Windows, x86, console (+ GUI) applications
Windows      : Windows, x86, GUI applications
WindowsXP    : Windows, x86, GUI applications, no touch API
Linux        : GNU/Linux, x86, console (+ GUI) applications
Linux-GTK    : GNU/Linux, x86, GUI only applications
Linux-musl   : GNU/Linux, x86, musl libc
Linux-ARM    : GNU/Linux, ARMv5, armel (soft-float)
RPi          : GNU/Linux, ARMv7, armhf (hard-float)
RPi-GTK      : GNU/Linux, ARMv7, armhf (hard-float), GUI only applications
Pico         : GNU/Linux, ARMv7, armhf (hard-float), uClibc
Darwin       : macOS Intel, console-only applications
macOS        : macOS Intel, applications bundles
Syllable     : Syllable OS, x86
FreeBSD      : FreeBSD, x86
NetBSD       : NetBSD, x86
Android      : Android, ARMv5
Android-x86  : Android, x86

Note: The toolchain executable (redc.exe) relies on Rebol encapper which does not support being run from a location specified in PATH environment variable and you get PROGRAM ERROR: Invalid encapsulated data error. If you are on Windows try using PowerShell instead of CMD. You can also provide the full path to the executable, put a copy of it in your working folder or wrap a shell script (see relevant tickets: #543 and #1547).
Running Red from the sources (for contributors)
The compiler and linker are currently written in Rebol. Please follow the instructions for installing the compiler toolchain in order to run it from sources:


Clone this git repository or download an archive (ZIP button above or from tagged packages).


Download a Rebol interpreter suitable for your OS: Windows, Linux (or Linux), Mac OS X, FreeBSD, OpenBSD, Solaris.


Extract the rebol binary, put it in the root folder, that's all!


Let's test it: run ./rebol, you'll see a >> prompt appear. Windows users need to double-click on the rebol.exe file to run it.


From the REBOL console type:
 >> do/args %red.r "%tests/hello.red"



The compilation process should finish with a ...output file size message. The resulting binary is in the working folder. Windows users need to open a DOS console and run hello.exe from there.
You can compile the Red console from source:
    >> do/args %red.r "-r %environment/console/CLI/console.red"

To compile the Windows GUI console from source:
    >> do/args %red.r "-r -t Windows %environment/console/GUI/gui-console.red"

Note: the -c argument is not necessary when launching the Red toolchain from sources, as the default action is to compile the input script (the toolchain in binary form default action is to run the input script through the interpreter).
The -r argument is needed when compiling the Red console to make additional runtime functions available.
Note: The red git repository does not include a .gitignore file. If you run the automated tests, several files will be created that are not stored in the repository. Installing and renaming a copy of .git/.gitignore-sample file will ignore these generated files.
Contributing
If you want to contribute code to the Red project be sure to read the guidelines first.
It is usually a good idea to inform the Red team about what changes you are going to make in order to ensure that someone is not already working on the same thing. You can reach us through our chat room.
Satisfied with the results of your change and want to issue a pull request on Github?
Make sure the changes pass all the existing tests, add relevant tests to the test-suite, and please test on as many platforms as you can. You can run all the tests using (from Rebol console, at repository root):
    >> do %run-all-tests.r

Git integration with console built from sources
If you want git version included in your Red console built from sources, use this command:
call/show ""                                              ;-- patch call bug on Windows
save %build/git.r do %build/git-version.r                 ;-- lookup git version if available
do/args %red.r "-r %environment/console/CLI/console.red"  ;-- build Console
write %build/git.r "none^/"                               ;-- restore git repo status
Anti-virus false positive
Some anti-virus programs are a bit too sensitive and can wrongly report an alert on some binaries generated by Red (see here for the details). If that happens to you, please report it to your anti-virus vendor as a false positive.
License
Both Red and Red/System are published under BSD license, runtime is under BSL license. BSL is a bit more permissive license than BSD, more suitable for the runtime parts.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My phone is an ereader now]]></title>
            <link>https://www.davepagurek.com/blog/minimal-phone/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45079962</guid>
            <description><![CDATA[August 30, 2025]]></description>
            <content:encoded><![CDATA[


  



  August 30, 2025

  


  I got a Kobo in 2016 after borrowing my mom's old one for a year before that. It probably is responsible for getting me reading again after high school. I used to be an avid reader, the sort of kid who would have to be told to put down the book and go to sleep, and who would then creep slowly to the bookshelf to pick it up again without arousing suspicion after the light had been turned out. I think I slowed my reading for fun as the work load of school increased, and stopped when moving every four months for internships in university. Having something small and portable that I could load books onto changed that and got my momentum going again. I now loosely grade how much I'm thriving by how much I'm reading, as an indirect indicator of how not burnt out I am.It fared me quite well, but I had a few issues with it. Library books would randomly not work on it, even if they would show up on, for example, the Libby app on my phone. It also came with a way to sync articles to it via Pocket, but it always required a little too much forethought for me: I had to remember to find and save articles beforehand in order to then read them later. There were some services to do this automatically via RSS but the syncing process itself was just slow enough that I found myself rarely doing it. Also, Mozilla has now killed Pocket as a service. In the middle of writing this, they announced support for Instapaper instead, but it has the same workflow issues for me. My partner reads on her phone, but something about reading on a screen grates on me after a while, and makes it too easy to jump to something else.So I was intrigued when I heard about the Minimal Phone, an Android phone with an epaper display. It wasn't the first epaper Android device I'd seenâ€”I've seen reviews saying the Boox Palma is actually pretty greatâ€”but it was the idea of this being an actual phone that can take a sim card that really get me interested. What if I could read the news and blogs on what looks like paper while commuting, without having the forethought of downloading or syncing something? I might otherwise spend that time staring into space or looking at nothing on Bluesky. I'd probably rather be reading a bit of a book, or other longer-form writing. So I ordered one as a gift to myself.The MP01I figured I might be a good fit for this device. I don't really watch videos on my phone. I send messages a bit, but not urgently. Most of the time I'm at or near a full keyboard anyway. I take some photos, but not that many any more. I feel like the photo winds changed for me sometime in university and I now feel weird posting Nice Photos to social media. Who are those for, really? I now send quick photos directly to friends mostly, and they don't have to be print quality or anything. They just have to be visible.With that in mind, I went in treating it like an experiment. I still have my Kobo that has its annoyances but works. I still have a fully functional Pixel 8 phone. I don't need this to work. At worst, this could just be an alternate ereader for me. So when it arrived mid-July, I started testing it full-time to see how it'd go, with my normal phone in my bag just in case.Overall, I actually really like it! I absolutely would not recommend this device to everyoneâ€”I'll get into why laterâ€”but it's been working pretty well for me. How the Minimal Phone worksThis phone is around the same size of my Pixel 8. It's just a tad shorter and just a tad wider. I don't really feel the shortness, but I do feel the wideness a bit, which makes it more comfortable to read on. The bottom third of the height is taken up by a physical keyboard, and the top two thirds are an epaper display.It's just Android under there, with a black-and-white epaper display. It comes with a few launchers, and I use one that works like a pretty traditional launcher, but comes with some built in icon choices that look sharp on the display.There's a side button between the phone's volume keys that you can tap to flash the display to clear ghosting. I don't find myself doing this oftenâ€”ghosting is not that badâ€”but if you press and hold it, it opens the display settings. This is something I do all the time.The quick display settings screen, which you get to by pressing and holding the button between the volume keys.From the settings screen, you can turn on and off the light on the display and on the keyboard, and also change the display light's colour temperature. I mostly leave those off; I only need those if I'm outside after dark, and the controls are big enough that I can turn them on easily enough in low light.The most important setting is the refresh rate at the bottom. The slowest setting has the slowest refresh rate, but the highest quality visuals: always showing nice shades of grey, and with less ghosting but more flashing as it updates. The fastest setting (which, to be clear, is still not very fast) has much less flashing, a little more ghosting, and dithers pure black and white rather than showing any shades of grey. The middle setting, "hybrid" mode, is a combination of the two: it uses the faster setting while things are moving onscreen, and then updates to the slower, higher quality render when movement stops. I generally keep the phone in this hybrid mode, except for a few specific cases.The keyboard feels pretty good, and it's a comfortable size to type on with two thumbs. I can't really one-handed type on this phone; it's a tad too wide for that, but the width is worth it for easier reading. I really appreciate them including the keyboard here, as the display looks great but is definitely not all that responsive, so typing would be a lot more frustrating without this. The great partsThis thing is so nice to read on.I hate reading on screens. Something about dark mode especially messes with my eyes, but even without that, I've never enjoyed reading articles on my phone. Too easy to get distracted, the minor eye strain... This device though, the epaper display looks great. It's not especially high resolution or anything, but I could spend a long time reading on this without issue. I just spent two flights (Toronto to Vancouver and back again) just reading books on this, and I'd do it again. It's really crisp and visible in the sun too.A page of a book in the Libby app.It's super easy to queue up library book holds and read them all from the phone. I have had zero issues with that. Being able to add new things on-the-go has also made it really easy to grab another book on the spot once I finish one. I definitely have found myself reading more books this past month and a half.I also now am more likely to read people's blogs on an RSS reader than scroll through social media. I wasn't setting out to fully purge social media or anything, but I certainly feel a little more fulfilled after reading something that someone has clearly put time and effort into.Possibly as a consequence of the display technology, I also generally get 2 days of usage out of a charge. Most days I finish with 70% battery remaining, letting me go another day with some buffer room. On some really low usage days, I could maybe even go more, but already this is great. On a high usage day, I'll maybe end with 50%, which is still fine by me.This is secondary, by far, but I also feel now that I can fully turn off autocorrect, as this phone has a physical keyboard. Most of the time (with important caveats), I don't make typos. So I no longer have to suffer through autocorrect changing programming terms (which I still type a lot of), changing my capitalization, or doing its own insane capitalization (why would it format "city Hall" with just one capital? Commit to capitals or no capitals, don't do this awkward mix!)An article on The Verge. Hey, it was the top post in the feed when I took the photo!As another minor note, the fingerprint reader is actually quite fast. When it remembers my fingerprints, it's super reliable. ("What do you mean, when it remembers?" I'll get into it later, there's a pretty bad bug here. But in regular usage, it really does work well.)Everything else this phone does, it does a little worse than a normal phone, but not so much worse that it's a problem. I assume it would be a lot worse at watching videos but I never really did that much on my old phone anyway. So on the whole, this phone works really well where I want it to, and generally gets out of my way for the usual stuff. I keep using it without really worrying about it.The camera, once set up properly, is pretty passable. Well, the selfie camera is in a super awkward spot, but I don't really find myself using it anyway. But other photos look decent enough that I'm not embarrassed to send them to people!  My cat Pigeon looking out the window.  Toronto in the summer.  The selfie camera is a little sketchy, I wouldn't rely on it.  Phil Wizard breaking on Kits Beach in Vancouver. Growing painsEven though I do really like this thing, and am continuing to use it as my primary device, there are a lot of rough edges. This device is made by, primarily, two people (although they've been adding more developers in the past few weeks), so naturally there will be a lot of rough edges. You have to be willing to accept that if you're going to use this phone. They do make updates, but the pace is slow, and they are definitely bogged down by customer support and shipping/manufacturing logistics, so you need to not bank on fixes happening quickly.There's a double-tap-to-wake feature that you can't turn off, and it takes a sec once locked to stop responding to inputs. Consequently, I now put this in my pocket with the display facing out, which is opposite of what I used to do, in order to prevent accidentally disturbing it in my pocket. Doing that, I haven't had issues, but it's an adjustment you have to make for this phone right now.There are a few things you'll probably need to do to the device to make it work well for you. One of them involves the camera. By default, the camera super aggressively denoises its photos, resulting in images that look like they came off of my flip phone from 2008. However, if you use the Open Camera app, switch it to use the Camera 2 API, it then lets you turn off noise reduction in the settings. The resulting images look much crisper, and do have noise, but a tastefulâ€”dare I say aesthetic?â€”amount of noise. There is no Pixel-style HDR in these photos, but now that that look is everywhere, the resulting photos are... kind of refreshing.Taking a photo of fast a moving subject is quite hard on this thing due to the refresh rate of the screen. But then again, doesn't a photo like this capture the moment better? This is my aunt's cat Lexi.The phone also uses something called Duraspeed to aggressively turn off background apps. This works well in general, but it also can stifle some notifications that you do want, and also can affect background audio. I know some people fully turn Duraspeed off, but I've just turned it off for my messaging apps and my music/podcast apps. I've had no notification or background process related issues since doing so.I also found that the backlight was way too bright, and I didn't really want any lights on most of the time anyway. I found that when opening the display settings, it'd turn all the lights back on. But if I save a preset, then it'd stick. You can do that by changing the settings, and then pressing and holding on the wrench icon to save it to your custom preset.Finally, the hybrid refresh mode needs things to stop moving in order to lock in on a higher quality render. That means animated ads are somehow even more annoying than they normally are. Thankfully, Firefox for Android lets you install addons, such as uBlock Origin, to deal with that. BugsThe most annoying bug is that this phone will occasionally restart and forget your fingerprint, forcing you to enter your PIN. I don't know why this happens. I can go for a few weeks with it working fine, and then it'll just forget. I can still get in with the PIN, so it's not locking me out, but there's really never a good time to re-set up a fingerprint, and typing a PIN on the onscreen display is slow and cumbersome. This is the bug I hope gets fixed the most.Another bug has something to do with the screen refresh rate, and something to do with responding to keyboard input. If you're on a slower refresh rate and are typing quickly, sometimes it misses keypresses, and you have to go back and fix things. This is also quite annoying, but doesn't seem to happen on the highest screen refresh rate. As a workaround, when I'm sending messages, I switch to the fastest refresh setting. This one-or-the-other approach isn't great though (I still want photos sent to me in messaging apps to look nice!), so I'd love to see that improved over time.I also have to use the phone in the lowest refresh rate for Google Maps in order to see the streets on the map. The color scheme is just too low contrast for the high refresh rate's dithering. The hybrid setting doesn't work either: your location on the map is always slightly moving and so it never locks in and renders a higher-quality image. Arguably, this is a problem with Google Maps because they don't have a high contrast mode. Surely that would have accessibility benefits beyond just this weird device!Google Maps when in hybrid or fast mode. Where did the streets go??There's a software update that the Minimal team has been working on for almost two months that will apparently address the fingerprint forgetting issue, make double-tap-to-wake optional, significantly increase the refresh rate on the fast refresh mode, and let you save per-app refresh rate settings. That'll address some of my problems for sure! But it also hasn't shipped yet. To use this device is an exercise in patience, and being accepting of imperfections. Feature RequestsNone of these are dealbreakers for me, but here's what I'm hoping to see in the future:I feel like the vibration on the phone is a tad aggressive. Not every vibration is, thoughâ€”Facebook Messenger notifications feel like the right level. I'd love to be able to adjust the cap for vibration intensity!I would love emoji search in the keyboard. But I also don't use that many different emoji or symbols, and by now the ones I do use are in the recents list, so it's fine. But the one time I need to use a weird one, it'd be nice to have!I wish the hybrid refresh mode would work well with camera apps. As it is, I think too much of the screen is updating at once, so it flashes a large part of the display every frame, making it really hard to see. If I put the phone in fast mode, there's no flashing, which is great! But then when I take a photo and tap on the thumbnail to see it, I have to switch back to hybrid or slow mode to see a clearer, non-dithered version. This is a little annoying, and I feel could be improved, but then again I'm not really using this to take a lot of photos anyway. Concluding the experimentIt's been more than a month, and despite not everything being perfect, I'm going to continue using this phone. I do occasionally switch to my Pixel 8 though. I use my Pixel 8 for running for its better waterproofing. When I needed to get actual good, postable photos from SIGGRAPH two weeks ago, I just used my Pixel 8. When seeing LCD Soundsystem last weekend, rather than worry about weirdness with the Ticketmaster app, I just took my Pixel 8. But I've used normal boarding passes for airplanes on my MP01, and I regularly go out without a backup phone. I do mostly rely on my partner to do Google Maps navigation since that's a little bit smoother, although in a pinch I can still use it myself (and the Transit app is a little better in hybrid mode.)Basically, I use the right tool for the job, and this phone doesn't have to be that tool for all jobs. But it turns out I don't need my phone to do all that many jobs, and it's maybe a good thing for it to be doing less of them.There are enough quirks that I wouldn't automatically recommend this experience. But if you know what you're getting into and have the right expectations, this is a really great little device!
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[New research reveals longevity gains slowing, life expectancy of 100 unlikely]]></title>
            <link>https://lafollette.wisc.edu/news/new-research-reveals-longevity-gains-slowing-life-expectancy-of-100-unlikely/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45075813</guid>
            <description><![CDATA[A new study co-authored by a University of Wisconsin-Madison professor finds that life expectancy gains made by high-income countries in the first half of the 20th century have slowed significantly, and that none of the â€¦]]></description>
            <content:encoded><![CDATA[
	
		
			
			
			

	
		A new study co-authored by a University of Wisconsin-Madison professor finds that life expectancy gains made by high-income countries in the first half of the 20th century have slowed significantly, and that none of the generations born after 1939 will reach 100 years of age on average.
Published in the journal Proceedings of the National Academy of Sciences, the study by HÃ©ctor PifarrÃ© i Arolas of the La Follette School of Public Affairs, JosÃ© Andrade of the Max Planck Institute for Demographic Research, and Carlo Giovanni Camarda of the Institut national dâ€™Ã©tudes dÃ©mographiques analyzed life expectancy for 23 high-income and low-mortality countries using data from the Human Mortality Database and six different mortality forecasting methods.
Assistant Professor HÃ©ctor PifarrÃ© i Arolas
â€œThe unprecedented increase in life expectancy we achieved in the first half of the 20th century appears to be a phenomenon we are unlikely to achieve again in the foreseeable future,â€ according to PifarrÃ© i Arolas. â€œIn the absence of any major breakthroughs that significantly extend human life, life expectancy would still not match the rapid increases seen in the early 20th century even if adult survival improved twice as fast as we predict.â€
From 1900 to 1938, life expectancy rose by about five and a half months with each new generation. The life expectancy for an individual born in a high-income country in 1900 was an average of 62 years. For someone born just 38 years later in similar conditions, life expectancy had jumped to 80 years on average.
For those born between 1939 and 2000, the increase slowed to roughly two and a half to three and a half months per generation, depending on the forecasting method. Mortality forecasting methods are statistical techniques that make informed predictions about future lifespans based on past and current mortality information. These models enabled the research team to estimate how life expectancy will develop under a variety of plausible future scenarios.
Doctoral student JosÃ© Andrade of the Max Planck Institute for Demographic Research
â€œWe forecast that those born in 1980 will not live to be 100 on average, and none of the cohorts in our study will reach this milestone. This decline is largely due to the fact that past surges in longevity were driven by remarkable improvements in survival at very young ages,â€ according to corresponding author Andrade.
At the beginning of the 20th century, infant mortality fell rapidly due to medical advances and other improvements in quality of life for high-income countries. This contributed significantly to the rapid increase in life expectancy. However, infant and child mortality are now so low that the forecasted improvements in mortality in older age groups will not be enough to sustain the previous pace of longevity gains.
While mortality forecasts can never be certain as the future may unfold in unexpected ways â€“ by way of pandemics, new medical treatments or other unforeseen societal changes â€“ this study provides critical insight for governments looking to anticipate the needs of their healthcare systems, pension planning and social policies.
Although a population-level analysis, this research also has implications for individuals, as life expectancy influences personal decisions about saving, retirement and long-term planning. If life expectancy increases more slowly as this study shows is likely, both governments and individuals may need to recalibrate their expectations for the future.
Share on: 	

	


	
		Post navigation
		
	
	

	


]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You Have to Feel It]]></title>
            <link>https://mitchellh.com/writing/feel-it</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45075048</guid>
            <description><![CDATA[You see a series of checkboxes checked. Schedules met.
Requirements satisfied. Demos delivered.
It's a good day. Good job, you, good job! A promotion is in sight.]]></description>
            <content:encoded><![CDATA[You see a series of checkboxes checked. Schedules met.
Requirements satisfied. Demos delivered.
It's a good day. Good job, you, good job! A promotion is in sight.
But you didn't feel it. You didn't feel it.
We, as people, feel something with every interaction. Frustration, joy, relief,
confidence. A feeling. A person interacts with our work. Our work evokes
a feeling. The feeling matters. The feeling is part of the work. The
desired feeling is part of the requirements.
When you feel it, you know. The feature makes you smile when you use it.
It fits right in, like it was always meant to be there. You want to
use it again. You want to tell people about it.
This is the difference. This is what metrics, specifications, and demos
miss. They don't capture the feeling. For the people who will use and live
in the work, the feeling is part of their daily experience. Which means
you can't stop at checking the boxes on paper. You have to sit with it,
use it, live with it.
You have to feel it.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cognitive load is what matters]]></title>
            <link>https://github.com/zakirullin/cognitive-load</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45074248</guid>
            <description><![CDATA[ðŸ§  Cognitive Load is what matters. Contribute to zakirullin/cognitive-load development by creating an account on GitHub.]]></description>
            <content:encoded><![CDATA[Cognitive Load is what matters
Readable version | Chinese translation | Korean translation | Turkish translation
It is a living document, last update: August 2025. Your contributions are welcome!
Introduction
There are so many buzzwords and best practices out there, but most of them have failed. We need something more fundamental, something that can't be wrong.
Sometimes we feel confusion going through the code. Confusion costs time and money. Confusion is caused by high cognitive load. It's not some fancy abstract concept, but rather a fundamental human constraint. It's not imagined, it's there and we can feel it.
Since we spend far more time reading and understanding code than writing it, we should constantly ask ourselves whether we are embedding excessive cognitive load into our code.
Cognitive load

Cognitive load is how much a developer needs to think in order to complete a task.

When reading code, you put things like values of variables, control flow logic and call sequences into your head. The average person can hold roughly four such chunks in working memory. Once the cognitive load reaches this threshold, it becomes much harder to understand things.
Let's say we have been asked to make some fixes to a completely unfamiliar project. We were told that a really smart developer had contributed to it. Lots of cool architectures, fancy libraries and trendy technologies were used. In other words, the author had created a high cognitive load for us.


We should reduce the cognitive load in our projects as much as possible.

  Cognitive load and interruptions
  

Types of cognitive load
Intrinsic - caused by the inherent difficulty of a task. It can't be reduced, it's at the very heart of software development.
Extraneous - created by the way the information is presented. Caused by factors not directly relevant to the task, such as smart author's quirks. Can be greatly reduced. We will focus on this type of cognitive load.


Let's jump straight to the concrete practical examples of extraneous cognitive load.

We will refer to the level of cognitive load as follows:
ðŸ§ : fresh working memory, zero cognitive load
ðŸ§ ++: two facts in our working memory, cognitive load increased
ðŸ¤¯: cognitive overload, more than 4 facts

Our brain is much more complex and unexplored, but we can go with this simplistic model.

Complex conditionals
if val > someConstant // ðŸ§ +
    && (condition2 || condition3) // ðŸ§ +++, prev cond should be true, one of c2 or c3 has be true
    && (condition4 && !condition5) { // ðŸ¤¯, we are messed up by this point
    ...
}
Introduce intermediate variables with meaningful names:
isValid = val > someConstant
isAllowed = condition2 || condition3
isSecure = condition4 && !condition5 
// ðŸ§ , we don't need to remember the conditions, there are descriptive variables
if isValid && isAllowed && isSecure {
    ...
}
Nested ifs
if isValid { // ðŸ§ +, okay nested code applies to valid input only
    if isSecure { // ðŸ§ ++, we do stuff for valid and secure input only
        stuff // ðŸ§ +++
    }
} 
Compare it with the early returns:
if !isValid
    return
 
if !isSecure
    return

// ðŸ§ , we don't really care about earlier returns, if we are here then all good

stuff // ðŸ§ +
We can focus on the happy path only, thus freeing our working memory from all sorts of preconditions.
Inheritance nightmare
We are asked to change a few things for our admin users: ðŸ§ 
AdminController extends UserController extends GuestController extends BaseController
Ohh, part of the functionality is in BaseController, let's have a look: ðŸ§ +
Basic role mechanics got introduced in GuestController: ðŸ§ ++
Things got partially altered in UserController: ðŸ§ +++
Finally we are here, AdminController, let's code stuff! ðŸ§ ++++
Oh, wait, there's SuperuserController which extends AdminController. By modifying AdminController we can break things in the inherited class, so let's dive in SuperuserController first: ðŸ¤¯
Prefer composition over inheritance. We won't go into detail - there's plenty of material out there.
Too many small methods, classes or modules

Method, class and module are interchangeable in this context

Mantras like "methods should be shorter than 15 lines of code" or "classes should be small" turned out to be somewhat wrong.
Deep module - simple interface, complex functionality
Shallow module - interface is relatively complex to the small functionality it provides


Having too many shallow modules can make it difficult to understand the project. Not only do we have to keep in mind each module responsibilities, but also all their interactions. To understand the purpose of a shallow module, we first need to look at the functionality of all the related modules. Jumping between such shallow components is mentally exhausting, linear thinking is more natural to us humans.

Information hiding is paramount, and we don't hide as much complexity in shallow modules.

I have two pet projects, both of them are somewhat 5K lines of code. The first one has 80 shallow classes, whereas the second one has only 7 deep classes. I haven't been maintaining any of these projects for one year and a half.
Once I came back, I realised that it was extremely difficult to untangle all the interactions between those 80 classes in the first project. I would have to rebuild an enormous amount of cognitive load before I could start coding. On the other hand, I was able to grasp the second project quickly, because it had only a few deep classes with a simple interface.

The best components are those that provide powerful functionality yet have a simple interface.
John K. Ousterhout

The interface of the UNIX I/O is very simple. It has only five basic calls:
open(path, flags, permissions)
read(fd, buffer, count)
write(fd, buffer, count)
lseek(fd, offset, referencePosition)
close(fd)
A modern implementation of this interface has hundreds of thousands of lines of code. Lots of complexity is hidden under the hood. Yet it is easy to use due to its simple interface.

This deep module example is taken from the book A Philosophy of Software Design by John K. Ousterhout. Not only does this book cover the very essence of complexity in software development, but it also has the greatest interpretation of Parnas' influential paper On the Criteria To Be Used in Decomposing Systems into Modules. Both are essential reads. Other related readings: A Philosophy of Software Design vs Clean Code, It's probably time to stop recommending Clean Code, Small Functions considered Harmful.

P.S. If you think we are rooting for bloated God objects with too many responsibilities, you got it wrong.
Responsible for one thing
All too often, we end up creating lots of shallow modules, following some vague "a module should be responsible for one, and only one, thing" principle. What is this blurry one thing? Instantiating an object is one thing, right? So MetricsProviderFactoryFactory seems to be just fine. The names and interfaces of such classes tend to be more mentally taxing than their entire implementations, what kind of abstraction is that? Something went wrong.
We make changes to our systems to satisfy our users and stakeholders. We are responsible to them.

A module should be responsible to one, and only one, user or stakeholder.

This is what this Single Responsibility Principle is all about. Simply put, if we introduce a bug in one place, and then two different business people come to complain, we've violated the principle. It has nothing to do with the number of things we do in our module.
But even now, this rule can do more harm than good. This principle can be understood in as many different ways as there are individuals. A better approach would be to look at how much cognitive load it all creates. It's mentally demanding to remember that change in one place can trigger a chain of reactions across different business streams. And that's about it, no fancy terms to learn.
Too many shallow microservices
This shallow-deep module principle is scale-agnostic, and we can apply it to microservices architecture. Too many shallow microservices won't do any good - the industry is heading towards somewhat "macroservices", i.e., services that are not so shallow (=deep). One of the worst and hardest to fix phenomena is so-called distributed monolith, which is often the result of this overly granular shallow separation.
I once consulted a startup where a team of five developers introduced 17(!) microservices. They were 10 months behind schedule and appeared nowhere close to the public release. Every new requirement led to changes in 4+ microservices. It took an enormous amount of time to reproduce and debug an issue in such a distributed system. Both time to market and cognitive load were unacceptably high. ðŸ¤¯
Is this the right way to approach the uncertainty of a new system? It's enormously difficult to elicit the right logical boundaries in the beginning. The key is to make decisions as late as you can responsibly wait, because that is when you have the most information at hand. By introducing a network layer up front, we make our design decisions hard to revert right from the start. The team's only justification was: "The FAANG companies proved microservices architecture to be effective". Hello, you got to stop dreaming big.
The Tanenbaum-Torvalds debate argued that Linux's monolithic design was flawed and obsolete, and that a microkernel architecture should be used instead. Indeed, the microkernel design seemed to be superior "from a theoretical and aesthetical" point of view. On the practical side of things - three decades on, microkernel-based GNU Hurd is still in development, and monolithic Linux is everywhere. This page is powered by Linux, your smart teapot is powered by Linux. By monolithic Linux.
A well-crafted monolith with truly isolated modules is often much more flexible than a bunch of microservices. It also requires far less cognitive effort to maintain. It's only when the need for separate deployments becomes crucial, such as scaling the development team, that you should consider adding a network layer between the modules, future microservices.
Feature-rich languages
We feel excited when new features got released in our favourite language. We spend some time learning these features, we build code upon them.
If there are lots of features, we may spend half an hour playing with a few lines of code, to use one or another feature. And it's kind of a waste of time. But what's worse, when you come back later, you would have to recreate that thought process!
You not only have to understand this complicated program, you have to understand why a programmer decided this was the way to approach a problem from the features that are available. ðŸ¤¯
These statements are made by none other than Rob Pike.

Reduce cognitive load by limiting the number of choices.

Language features are OK, as long as they are orthogonal to each other.

  Thoughts from an engineer with 20 years of C++ experience â­ï¸
  
  I was looking at my RSS reader the other day and noticed that I have somewhat three hundred unread articles under the "C++" tag. I haven't read a single article about the language since last summer, and I feel great!
  I've been using C++ for 20 years for now, that's almost two-thirds of my life. Most of my experience lies in dealing with the darkest corners of the language (such as undefined behaviours of all sorts). It's not a reusable experience, and it's kind of creepy to throw it all away now.
  Like, can you imagine, the token || has a different meaning in requires ((!P<T> || !Q<T>)) and in requires (!(P<T> || Q<T>)). The first is the constraint disjunction, the second is the good-old logical OR operator, and they behave differently.
  You can't allocate space for a trivial type and just memcpy a set of bytes there without extra effort - that won't start the lifetime of an object. This was the case before C++20. It was fixed in C++20, but the cognitive load of the language has only increased.
  Cognitive load is constantly growing, even though things got fixed. I should know what was fixed, when it was fixed, and what it was like before. I am a professional after all. Sure, C++ is good at legacy support, which also means that you will face that legacy. For example, last month a colleague of mine asked me about some behaviour in C++03. ðŸ¤¯
  There were 20 ways of initialization. Uniform initialization syntax has been added. Now we have 21 ways of initialization. By the way, does anyone remember the rules for selecting constructors from the initializer list? Something about implicit conversion with the least loss of information, but if the value is known statically, then... ðŸ¤¯
  This increased cognitive load is not caused by a business task at hand. It is not an intrinsic complexity of the domain. It is just there due to historical reasons (extraneous cognitive load).
  I had to come up with some rules. Like, if that line of code is not as obvious and I have to remember the standard, I better not write it that way. The standard is somewhat 1500 pages long, by the way.
  By no means I am trying to blame C++. I love the language. It's just that I am tired now.Thanks to 0xd34df00d for writing.

Business logic and HTTP status codes
On the backend we return:
401 for expired jwt token
403 for not enough access
418 for banned users
The engineers on the frontend use backend API to implement login functionality. They would have to temporarily create the following cognitive load in their brains:
401 is for expired jwt token // ðŸ§ +, ok just temporary remember it
403 is for not enough access // ðŸ§ ++
418 is for banned users // ðŸ§ +++
Frontend developers would (hopefully) introduce some kind numeric status -> meaning dictionary on their side, so that subsequent generations of contributors wouldn't have to recreate this mapping in their brains.
Then QA engineers come into play:
"Hey, I got 403 status, is that expired token or not enough access?"
QA engineers can't jump straight to testing, because first they have to recreate the cognitive load that the engineers on the backend once created.
Why hold this custom mapping in our working memory? It's better to abstract away your business details from the HTTP transfer protocol, and return self-descriptive codes directly in the response body:
{
    "code": "jwt_has_expired"
}
Cognitive load on the frontend side: ðŸ§  (fresh, no facts are held in mind)
Cognitive load on the QA side: ðŸ§ 
The same rule applies to all sorts of numeric statuses (in the database or wherever) - prefer self-describing strings. We are not in the era of 640K computers to optimise for memory.

People spend time arguing between 401 and 403, making decisions based on their own mental models. New developers are coming in, and they need to recreate that thought process. You may have documented the "whys" (ADRs) for your code, helping newcomers to understand the decisions made. But in the end it just doesn't make any sense. We can separate errors into either user-related or server-related, but apart from that, things are kind of blurry.

P.S. It's often mentally taxing to distinguish between "authentication" and "authorization". We can use simpler terms like "login" and "permissions" to reduce the cognitive load.
Abusing DRY principle
Do not repeat yourself - that is one of the first principles you are taught as a software engineer. It is so deeply embedded in ourselves that we can not stand the fact of a few extra lines of code. Although in general a good and fundamental rule, when overused it leads to the cognitive load we can not handle.
Nowadays, everyone builds software based on logically separated components. Often those are distributed among multiple codebases representing separate services. When you strive to eliminate any repetition, you might end up creating tight coupling between unrelated components. As a result changes in one part may have unintended consequences in other seemingly unrelated areas. It can also hinder the ability to replace or modify individual components without impacting the entire system. ðŸ¤¯
In fact, the same problem arises even within a single module. You might extract common functionality too early, based on perceived similarities that might not actually exist in the long run. This can result in unnecessary abstractions that are difficult to modify or extend.
Rob Pike once said:

A little copying is better than a little dependency.

We are tempted to not reinvent the wheel so strong that we are ready to import large, heavy libraries to use a small function that we could easily write by ourselves.
All your dependencies are your code. Going through 10+ levels of stack trace of some imported library and figuring out what went wrong (because things go wrong) is painful.
Tight coupling with a framework
There's a lot of "magic" in frameworks. By relying too heavily on a framework, we force all upcoming developers to learn that "magic" first. It can take months. Even though frameworks enable us to launch MVPs in a matter of days, in the long run they tend to add unnecessary complexity and cognitive load.
Worse yet, at some point frameworks can become a significant constraint when faced with a new requirement that just doesn't fit the architecture. From here onwards people end up forking a framework and maintaining their own custom version. Imagine the amount of cognitive load a newcomer would have to build (i.e. learn this custom framework) in order to deliver any value. ðŸ¤¯
By no means do we advocate to invent everything from scratch!
We can write code in a somewhat framework-agnostic way. The business logic should not reside within a framework; rather, it should use the framework's components. Put a framework outside of your core logic. Use the framework in a library-like fashion. This would allow new contributors to add value from day one, without the need of going through debris of framework-related complexity first.

Why I Hate Frameworks

Layered architecture
There is a certain engineering excitement about all this stuff.
I myself was a passionate advocate of Hexagonal/Onion Architecture for years. I used it here and there and encouraged other teams to do so. The complexity of our projects went up, the sheer number of files alone had doubled. It felt like we were writing a lot of glue code. On ever changing requirements we had to make changes across multiple layers of abstractions, it all became tedious. ðŸ¤¯
Abstraction is supposed to hide complexity, here it just adds indirection. Jumping from call to call to read along and figure out what goes wrong and what is missing is a vital requirement to quickly solve a problem. With this architectureâ€™s layer uncoupling it requires an exponential factor of extra, often disjointed, traces to get to the point where the failure occurs. Every such trace takes space in our limited working memory. ðŸ¤¯
This architecture was something that made intuitive sense at first, but every time we tried applying it to projects it made a lot more harm than good. In the end, we gave it all up in favour of the good old dependency inversion principle. No port/adapter terms to learn, no unnecessary layers of horizontal abstractions, no extraneous cognitive load.

  Coding principles and experience
  
  @flaviocopes

If you think that such layering will allow you to quickly replace a database or other dependencies, you're mistaken. Changing the storage causes lots of problems, and believe us, having some abstractions for the data access layer is the least of your worries. At best, abstractions can save somewhat 10% of your migration time (if any), the real pain is in data model incompatibilities, communication protocols, distributed systems challenges, and implicit interfaces.

With a sufficient number of users of an API,
it does not matter what you promise in the contract:
all observable behaviors of your system
will be depended on by somebody.

We did a storage migration, and that took us about 10 months. The old system was single-threaded, so the exposed events were sequential. All our systems depended on that observed behaviour. This behavior was not part of the API contract, it was not reflected in the code. A new distributed storage didn't have that guarantee - the events came out-of-order. We spent only a few hours coding a new storage adapter, thanks to an abstraction. We spent the next 10 months on dealing with out-of-order events and other challenges. It's now funny to say that abstractions helps us replace components quickly.
So, why pay the price of high cognitive load for such a layered architecture, if it doesn't pay off in the future? Plus, in most cases, that future of replacing some core component never happens.
These architectures are not fundamental, they are just subjective, biased consequences of more fundamental principles. Why rely on those subjective interpretations? Follow the fundamental rules instead: dependency inversion principle, single source of truth, cognitive load and information hiding. Your business logic should not depend on low-level modules like database, UI or framework. We should be able to write tests for our core logic without worrying about the infrastructure, and that's it. Discuss.
Do not add layers of abstractions for the sake of an architecture. Add them whenever you need an extension point that is justified for practical reasons.
Layers of abstraction aren't free of charge, they are to be held in our limited working memory.


Domain-driven design
Domain-driven design has some great points, although it is often misinterpreted. People say, "We write code in DDD", which is a bit strange, because DDD is more about the problem space rather than the solution space.
Ubiquitous language, domain, bounded context, aggregate, event storming are all about problem space. They are meant to help us learn the insights about the domain and extract the boundaries. DDD enables developers, domain experts and business people to communicate effectively using a single, unified language. Rather than focusing on these problem space aspects of DDD, we tend to emphasise particular folder structures, services, repositories, and other solution space techniques.
Chances are that the way we interpret DDD is likely to be unique and subjective. And if we build code upon this understanding, i.e., if we create a lot of extraneous cognitive load - future developers are doomed. ðŸ¤¯
Team Topologies provides a much better, easier to understand framework that helps us split the cognitive load across teams. Engineers tend to develop somewhat similar mental models after learning about Team Topologies. DDD, on the other hand, seems to be creating 10 different mental models for 10 different readers. Instead of being common ground, it becomes a battleground for unnecessary debates.
Cognitive load in familiar projects

The problem is that familiarity is not the same as simplicity. They feel the same â€” that same ease of moving through a space without much mental effort â€” but for very different reasons. Every â€œcleverâ€ (read: â€œself-indulgentâ€) and non-idiomatic trick you use incurs a learning penalty for everyone else. Once they have done that learning, then they will find working with the code less difficult. So it is hard to recognise how to simplify code that you are already familiar with. This is why I try to get â€œthe new kidâ€ to critique the code before they get too institutionalised!
It is likely that the previous author(s) created this huge mess one tiny increment at a time, not all at once. So you are the first person who has ever had to try to make sense of it all at once.
In my class I describe a sprawling SQL stored procedure we were looking at one day, with hundreds of lines of conditionals in a huge WHERE clause. Someone asked how anyone could have let it get this bad. I told them: â€œWhen there are only 2 or 3 conditionals, adding another one doesnâ€™t make any difference. By the time there are 20 or 30 conditionals, adding another one doesnâ€™t make any difference!â€
There is no â€œsimplifying forceâ€ acting on the code base other than deliberate choices that you make. Simplifying takes effort, and people are too often in a hurry.
Thanks to Dan North for his comment.

If you've internalized the mental models of the project into your long-term memory, you won't experience a high cognitive load.


The more mental models there are to learn, the longer it takes for a new developer to deliver value.
Once you onboard new people on your project, try to measure the amount of confusion they have (pair programming may help). If they're confused for more than ~40 minutes in a row - you've got things to improve in your code.
If you keep the cognitive load low, people can contribute to your codebase within the first few hours of joining your company.
Examples

Our architecture is a standard CRUD app architecture, a Python monolith on top of Postgres
How Instagram scaled to 14 million users with only 3 engineers
The companies where we were like â€woah, these folks are smart as hellâ€ for the most part failed
One function that wires up the entire system. If you want to know how the system works - go read it

These architectures are quite boring and easy to understand. Anyone can grasp them without much mental effort.
Involve junior developers in architecture reviews. They will help you to identify the mentally demanding areas.
Maintaining software is hard, things break and we would need every bit of mental effort we can save.
Conclusion
Imagine for a moment that what we inferred in the second chapter isnâ€™t actually true. If thatâ€™s the case, then the conclusion we just negated, along with the conclusions in the previous chapter that we had accepted as valid, might not be correct either. ðŸ¤¯
Do you feel it? Not only do you have to jump all over the article to get the meaning (shallow modules!), but the paragraph in general is difficult to understand. We have just created an unnecessary cognitive load in your head. Do not do this to your colleagues.


We should reduce any cognitive load above and beyond what is intrinsic to the work we do.

LinkedIn, X, GitHub
Readable version

    Comments
    
    Rob PikeNice article.
    Andrej Karpathy (ChatGPT, Tesla)Nice post on software engineering. Probably the most true, least practiced viewpoint.
    Elon MuskTrue.
    Addy Osmani (Chrome, the most complex software system in the world)I've seen countless projects where smart developers created impressive architectures using the latest design patterns and microservices. But when new team members tried to make changes, they spent weeks just trying to understand how everything fits together. The cognitive load was so high that productivity plummeted and bugs multiplied.
    The irony? Many of these complexity-inducing patterns were implemented in the name of "clean code."
    What really matters is reducing unnecessary cognitive burden. Sometimes this means fewer, deeper modules instead of many shallow ones. Sometimes it means keeping related logic together instead of splitting it into tiny functions.
    And sometimes it means choosing boring, straightforward solutions over clever ones. The best code isn't the most elegant or sophisticated - it's the code that future developers (including yourself) can understand quickly.
    Your article really resonates with the challenges we face in browser development. You're absolutely right about modern browsers being among the most complex software systems. Managing that complexity in Chromium is a constant challenge that aligns perfectly with many of the points you made about cognitive load.
    One way we try to handle this in Chromium is through careful component isolation and well-defined interfaces between subsystems (like rendering, networking, JavaScript execution, etc.). Similar to your deep modules example with Unix I/O - we aim for powerful functionality behind relatively simple interfaces. For instance, our rendering pipeline handles incredible complexity (layout, compositing, GPU acceleration) but developers can interact with it through clear abstraction layers.
    Your points about avoiding unnecessary abstractions really hit home too. In browser development, we constantly balance between making the codebase approachable for new contributors while handling the inherent complexity of web standards and compatibility. 
    Sometimes the simplest solution is the best one, even in a complex system.
    antirez (Redis)Totally agree about it :) Also, what I believe is missing from mentioned "A Philosophy of Software Design" is the concept of "design sacrifice". That is, sometimes you sacrifice something and get back simplicity, or performances, or both. I apply this idea continuously, but often is not understood.
    A good example is the fact that I always refused to have hash items expires. This is a design sacrifice because if you have certain attributes only in the top-level items (the keys themselves), the design is simpler, values will just be objects. When Redis got hash expires, it was a nice feature but required (indeed) many changes to many parts, raising the complexity.
    Another example is what I'm doing right now, Vector Sets, the new Redis data type. I decided that Redis would not be the source of truth about vectors, but that it can just take an approximate version of them, so I was able to do on-insert normalization, quantization without trying to retain the large floats vector on disk, and so forth. May vector DBs don't sacrifice the fact of remembering what the user put inside (the full precision vector).
    These are just two random examples, but I apply this idea everywhere. Now the thing is: of course one must sacrifice the right things. Often, there are 5% features that account for a very large amount of complexity: that is a good thing to kill :D
    A developer from the internetYou would not hire me... I sell myself on my track record of released enterprise projects.
    I worked with a guy that could speak design patterns. I could never speak that way, though I was one of the few that could well understand him. The managers loved him and he could dominate any development conversation. The people working around him said he left a trail of destruction behind him. I was told that I was the first person that could understand his projects. Maintainability matters. I care most about TCO. For some firms, that's what matters.
    I logged into Github after not being there for a while and for some reason it took me to an article in a repository by someone that seemed random. I was thinking "what is this" and had some trouble getting to my home page, so I read it. I didn't really register it at the time, but it was amazing. Every developer should read it. It largely said that almost everything we've been told about programming best practices leads to excessive "cognitive load", meaning our minds are getting kicked by the intellectual demands. I've known this for a while, especially with the demands of cloud, security and DevOps.
    I also liked it because it described practices I have done for decades, but never much admit to because they are not popular... I write really complicated stuff and need all the help I can get.
    Consider, if I'm right, it popped up because the Github folks, very smart people, though that developers should see it. I agree.
    Comments on Hacker News (2)

]]></content:encoded>
        </item>
    </channel>
</rss>