<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Wed, 10 Sep 2025 14:08:20 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Guy is running a Google rival from his laundry room]]></title>
            <link>https://www.fastcompany.com/91396271/searcha-page-seekninja-diy-search-engines</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45197187</guid>
        </item>
        <item>
            <title><![CDATA[Windows 10 resists its end: usage share climbs while Windows 11's falls]]></title>
            <link>https://www.ghacks.net/2025/09/10/windows-10-resists-its-end-usage-share-climbs-while-windows-11s-falls/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45197066</guid>
            <description><![CDATA[Windows 10 usage share is climbing again, despite its end of support next month. Here is an explanation.]]></description>
            <content:encoded><![CDATA[
              Next month, Microsoft is ending support for home editions of its Windows 10 operating system officially. While users may extend support by one year -- business customers get three -- the number of users who will take up Microsoft's offer is unclear. The extension is more or less free, as you get it as a consumer when you enable the backup functionality during the signup process. There is even a tool for that that lets you do all that with a local account and as little interaction as possible.
Recently, Windows 11, the successor of Windows 10, has been gaining traction. While it led the leaderboard of the most popular operating system on Valve's highly influential Steam gaming platform for some time, it passed Windows 10 at Statcounter's monthly OS popularity ranking in July for the first time.
Being newer and with the advantage that its main competitor is on its last months of support, one could predict the trend easily. Windows 10 usage declines naturally, as users start to migrate to Windows 11, if their devices are compatible, upgrade by bypassing compatibility checks, or buy entirely new PCs.
But in August 2025, stats reversed seemingly, at least according to Statcounter. Windows 11 usage dropped by four points from 53 percent to 49 percent. Windows 10's usage jumped three points to 45 percent. Even the out-of-support Windows 7 operating system jumped by 1.5 points to more than three percent usage, according to Statcounter.
Does this mean that users moved back to Windows 10? Reverted the upgrade or even downgraded their machines, where possible? It seems highly unlikely that this is the main cause for the reversal. Statcounter claims to pull the statistics from billions of visits of users each month. While that sounds much, its stats are not a true reflection of the actual market share of each operating system or browser.
There is also the possibility that the calculation was off in a given month. We know more next month. We could see another reversal, Windows 11 climbing again, Windows 10 and falling.
Windows 10's usage share will decline in the coming months. While part of the userbase will extend support by joining the ESU program, another part will upgrade their machines to Windows 11 or buy new PCs entirely. Yes, some may also switch to Linux.
Now You: which version of Windows do you use, and why?

SummaryArticle NameWindows 10 resists its end: usage share climbs while Windows 11's fallsDescriptionWindows 10 usage share is climbing again, despite its end of support next month. Here is an explanation.AuthorMartin Brinkmann
							
							PublisherGhacks Technology News
							
							

							Logo
					
                              Advertisement
                
                          
            

                
          
                
                  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Tarsnap Is Cozy]]></title>
            <link>https://til.andrew-quinn.me/posts/tarsnap-is-cozy/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45196568</guid>
            <description><![CDATA[I have been aware of tarsnap for a long time, but only recently did I actually get around to using it for anything, as a result of my big personal digital resiliency audit for 2025. For those of you not in the know, tarsnap is &ldquo;online backups for the truly paranoid&rdquo;, and tarsnap the command-line program is the client-side tool you invoke to actually zip up and push your archives into the vault. Its creator, Dr. Colin Percival, is a really smart and interesting dude for a whole bunch of reasons. I&rsquo;m led to believe the whole business is basically a two-man show between him and his brother these days.]]></description>
            <content:encoded><![CDATA[I have been aware of
tarsnap
for a long time, but only recently did I actually
get around to using it
for anything, as a result of my big
personal digital resiliency audit for 2025.
For those of you not in the know, tarsnap is
“online backups for the truly paranoid”, and
tarsnap the command-line program is the client-side
tool you invoke to actually zip up and push your
archives into the vault. Its creator,
Dr. Colin Percival,
is a really smart and interesting dude for a whole
bunch of reasons. I’m led to believe the whole
business is basically a two-man show between him and
his brother these days.Tarsnap feels… cozy to use.
I know that’s a weird word to pick for something
most people use to back up, like, extreme
cryptocurrency wallet codes and the like, but
every single thing about it just feels well-considered
from both a Unix sysadmin’s usability standpoint
and from a general product standpoint. The client
side CLI tool is based off of how tar itself works.
The prepaid model means that at any point I can
effectively guarantee anonymity by just shredding
up my keyfiles and letting the $15.123412341234123412
or what have you I still have remaining in the account
quietly run out, at which point the digital noise that
corresponds to whatever I have in there will be
unceremoniously deleted. These two things mean I feel
extremely safe just sticking the whole thing into a
one-liner hourly cronjob if need be and let it rip.People have often complained they don’t have a good
sense for the pricing, so I
hacked together a little Tarsnap cost estimator here.
If you use it solely to back up the
few megabytes of
“crown jewels” data we all have lying around,
don’t be surprised if the calculator tells you
your initial $5 or such will last for over
1,000 years. About the only thing I could think
I might want more from a service like this is
the opportunity to use a hardware key instead of
a keyfile - I’m sure Colin has thought about this
possibility himself and has good reasons for or
against implementing it, however.Hats off to you, Dr. Percival. This truly is a
dream product.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kerberoasting]]></title>
            <link>https://blog.cryptographyengineering.com/2025/09/10/kerberoasting/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45196437</guid>
            <description><![CDATA[I learn about cryptographic vulnerabilities all the time, and they generally fill me with some combination of jealousy (“oh, why didn’t I think of that”) or else they impress me w…]]></description>
            <content:encoded><![CDATA[
	
	
		
I learn about cryptographic vulnerabilities all the time, and they generally fill me with some combination of jealousy (“oh, why didn’t I think of that”) or else they impress me with the brilliance of their inventors. But there’s also another class of vulnerabilities: these are the ones that can’t possibly exist in important production software, because there’s no way anyone could still do that in 2025.



Today I want to talk about one of those ridiculous ones, something Microsoft calls “low tech, high-impact”. This vulnerability isn’t particularly new; in fact the worst part about it is that it’s had a name for over a decade, and it’s existed for longer than that. I’ll bet most Windows people already know this stuff, but I only happened to learn about it today, after seeing a letter from Senator Wyden to Microsoft, describing how this vulnerability was used in the May 2024 ransomware attack on the Ascension Health hospital system.



The vulnerability is called Kerberoasting, and TL;DR it relies on the fact that Microsoft’s Active Directory is very, very old. And also: RC4. If you don’t already know where I’m going with this, please read on.



What’s Kerberos, and what’s Active Directory?



Microsoft’s Active Directory (AD) is a many-tentacled octopus that controls access to almost every network that runs Windows machines. The system uses centralized authentication servers to determine who gets access to which network resources. If an employee’s computer needs to access some network Service (a file server, say), an Active Directory server authenticates the user and helps them get securely connected to the Service.



This means that AD is also the main barrier ensuring that attackers can’t extend their reach deeper into a corporate network. If an attacker somehow gets a toehold inside an enterprise (for example, because an employee clicks on a malicious search result), they should absolutely not be able to move laterally and access critical network services. That’s because any such access would require the employee’s machine to have access to specialized accounts (sometimes called “service accounts”) with privileges to fully control those machines. A well-managed network obviously won’t allow this. This means that AD is the “guardian” that stands between most companies and total disaster.



Unfortunately, Active Directory is a monster dragged from the depths of time. It uses the Kerberos protocol, which was first introduced in early 1989. A lot of things have happened since 1989! In fairness to Microsoft, Active Directory itself didn’t actually debut until about 1999; but (in less fairness), large portions of its legacy cryptography from that time period appear to still be supported in AD. This is very bad, because the cryptography is exceptionally terrible. 



Let me get specific.



When you want to obtain access to some network resource (a “Service” in AD parlance), you first contact an AD server (called a KDC) to obtain a “ticket” (called a TGT) that you can send to the Service to authenticate. This ticket is encrypted using a long-term Service “password” established at the KDC and the Service itself, and it’s handed to the user making the call. 



Now, ideally, this Service password is not really a password at all: it’s actually a randomly-generated cryptographic key. Microsoft even has systems in place to generate and rotate these keys regularly. This means the encrypted ticket will be completely inscrutable to the user who receives it, even if they’re malicious. But occasionally network administrators will make mistakes, and one (apparently) somewhat common mistake is to set up a Service that’s connected to an ordinary user account, complete with a human-generated password. 



Since human passwords probably are not cryptographically strong, the tickets encrypted using them are extremely vulnerable to dictionary attacks. This is very bad, since any random user — including our hypothetical laptop malware hacker — can now obtain a copy of such a ticket, and attempt to crack the Service’s password by trying many candidate passwords using a dictionary attack. 



Isn’t that cute?



That doesn’t actually seem very cute?



Of course, it’s not. It’s actually a terrible design that should have been done away with decades ago. We should not build systems where any random attacker who compromises a single employee laptop can ask for a message encrypted under a critical password! This basically invites offline cracking attacks, which do not need even to be executed on the compromised laptop — they can be exported out of the network to another location and performed using GPUs and other hardware.



There are a few things that can stop this attack in practice. As we noted above, if the account has a long enough (random!) password, then cracking it should be virtually impossible. Microsoft could prevent users from configuring services with weak human-generated passwords, but apparently they don’t — at least because this is something that’s happened many times (including at Ascension Health.) 



So let’s say you did not use a strong cryptographic key as your Service’s password. Where are you?



Your best hope in this case is that the encrypted tickets are extremely challenging for an attacker to crack. That’s because at this point, the only thing preventing the attacker from accessing your Service is computing power. But — and this is a very weak “but” — computing power can still be a deterrent! In the “standard” authentication mode, TGT tickets are encrypted with AES, using a key derived using 4,096 iterations of PBKDF2 hashing, based on the Service password and a per-account salt. The salt means an attacker cannot pre-compute a dictionary of hashed passwords, and while the PBKDF2 (plus AES) isn’t an amazing defense, it puts some limits on the number of passwords that can be hashed in a given unit of time. 



This page by Chick3nman gives some excellent password cracking statistics computed using an RTX 5090. It gives numbers of 6.8 million passwords per second for cracking these tickets using AES-128 and PBKDF2.



So that’s not great. But also not terrible, right?



This isn’t the end of the story. In fact it’s self-evident that this is not the end of the story, because Active Directory was invented in 1999, which means at some point we’ll have to deal with RC4.



Here’s the thing. Anytime you see cryptography born in the 1990s and yet using AES, you cannot be dealing with the original. What you’re looking at is the modernized, “upgraded” version of the original. The original probably used an abacus and witchcraft, or (failing that) at least some combination of unsalted hash functions and RC4. And here’s the worst part: it turns out that in Active Directory, when a user does not configure a Service account to use a more recent mode, then Kerberos will indeed fall back to RC4, combined with unsalted NT hashes (basically, one iteration of MD4.)



The main implication of using RC4 (and NT hashing) is that tickets encrypted this way become hilariously, absurdly fast to crack. According to our friend Chick3nman, the same RTX 5090 can crack 4.18 billion (with a “b”) of these hashes every second. That’s roughly 1000x faster than the AES variant.



As an aside, the NT hashes are not salted, which means they’re vulnerable to pre-computation attacks that involve rainbow tables. I had been meaning to write about rainbow tables recently on this blog, but had convinced myself that they mostly don’t matter, given that these ancient unsalted hash functions are going away. I guess maybe I spoke too soon.



So what is Microsoft doing about this?



Clearly not enough. These “Kerberoasting” has been around for ages: the techniques is credited to Tim Medin who presented it in 2014 (and many popular blogs followed up on it) but the vulnerabilities themselves are much older. The fact that there are practical ransomware attacks using these ideas in 2024 indicates that (1) system administrators aren’t hardening things enough, but more importantly, (2) Microsoft is still not turning off the unsafe options that make these attacks possible.







To give some sense of where we are, in October 2024, Microsoft published a blog post on how to avoid Kerberos-based attacks (NB: I cannot say Kerberoasting again and take myself seriously). 



The recommendations are all kind of dismal. They recommend that administrators should use proper automated key assignment, and if they can’t do that, then to try to pick “really good long passwords”, and if they can’t do that, to pretty please shut off RC4. But Microsoft doesn’t seem to do anything proactive, like absolutely banning obsolete legacy stuff, or being completely obnoxious and forcing admins to upgrade their weird and bad legacy configurations. Instead this all seems much more like a reluctant and half-baked bit of vulnerability management.



I’m sure there are some reasons why this is, but I refuse to believe they’re good reasons, and Microsoft should probably try a lot harder to make sure these obsolete services go away. It isn’t 1999 anymore, and it isn’t even 2016. You can go ask Ascension Health if you don’t believe me.
	

			
	]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Infracost (YC W21) Is Hiring First Product Manager to Shift FinOps Left]]></title>
            <link>https://www.ycombinator.com/companies/infracost/jobs/ukwJ299-senior-product-manager</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45196433</guid>
            <description><![CDATA[Overview
We were the first to shift FinOps left, and we see a big opportunity to make the $600B/year spent on cloud proactively managed, instead of teams reacting to surprise cost spikes. Reactive is too late, we already tried that approach with our first startup.
Join us as our first PM 🚀
This is a high-impact role at the heart of our product and growth strategy. You’ll own critical parts of our roadmap, from early-stage discovery through to GTM, and shape how we scale. You’ll work directly with Ali (https://www.linkedin.com/in/alikhajeh1), co-founder who leads product and customer success, and your own dedicated team of senior engineers and a designer.
Check out this product announcement blog (https://www.infracost.io/blog/) for examples of the types of complex problems we’re solving for engineering and FinOps teams at large enterprises; while also obsessing over developer experience:
AutoFix pull requests to make it 10x easier for engineers to fix cloud cost issues, using static analysis + LLMs to generate actionable code fixes, tailored to each customer’s cloud discounts and policies.
Finding issues in the cloud, fixing them in the code. Recommendations are easy; implementation is hard. Infra updates are scattered across hundreds of repos and teams. We’re solving for decentralized action at scale, the blocker no one else touches.
Timezone
US timezone (ideally Eastern time) as we have have customers and team members in the US and Europe. We are fully remote.
Responsibilities
Be the voice of users: Infracost sits at the intersection of FinOps, Engineering, and Engineering Management—each with different goals, workflows, and technical depth. Your mission is to deeply understand their worlds: the challenges they face, the tools they use, and how they measure success. You'll spend time talking to users, listening to signals (and the silence), and turning insights into action. Metrics and customer conversations will be your compass.
Shape the product, end-to-end: You won’t just define features, you’ll define outcomes. You’ll lead product discovery, turn complex problems into clear specs, and work side-by-side with design and engineering to bring elegant, developer-friendly solutions to life. You’ll ruthlessly prioritize based on impact, drive roadmap decisions, and own your product areas from idea through launch and iteration.
Collaborate to drive growth: You’ll work across the company, from customer success to sales to marketing, to ensure what we build lands well and grows fast. That means helping write crisp product docs, release notes, and blogs too. You’ll equip go-to-market teams with the messaging and context they need, and stay close to the field to keep learning how we can serve users better.
Prior experience
Required: Prior experience of owning a product (or major area), in the B2B space, from discovery through delivery and iteration.
Required: Experience with DevOps tools, cloud provisioning or Infrastructure-as-Code.
Significant advantage: Experience working in a fast-growing startup or domain expertise with cloud costs.
What we value
Ustomer, not customer: It is all about seeing us and the customer as one. We like to be a part of the user’s team, and help them however we can. If the user is not successful, then we will not be either so we try to walk in their shoes. It's more than work - we build relationships and community with users and customers.
Open is our core: Put yourself out there. Show your learning. Transparency builds confidence. Encourage sharing the good and the bad. The best decisions are made when everyone has access to all the data. Be straightforward and kind, feedback is about your work not your person.
Let's JEDI: Let’s Just Effing Do It! Own it and move fast. A good plan fiercely executed now is better than a perfect plan later. We ask for help and unblock each other. The main thing, is to keep the main thing, the main thing.
Benefits
Fully remote team
Two meetups a year - last year we went to Croatia and Barcelona.
Employee-friendly equity terms, including a 10 year exercise window (https://www.abar.tech/articles/10yr-excercise-window/)
401k matching (US)
Health, dental, and vision insurance (US)
31 days paid leave per year (includes national holidays)
12 weeks paid parental leave
Compensation
In the United States, the starting base compensation range for this role is $150,000 - $200,000 (USD). Actual compensation may vary based on level, relevant experience, and skill set as assessed in the interview process, as well as market data by location. In addition to base salary, you will also receive equity in the company.]]></description>
            <content:encoded><![CDATA[Shift FinOps Left: Proactively Find & Fix Cloud Cost IssuesSenior Product Manager$150K - $250K•US / CA / Remote (US; CA)Job typeFull-timeRoleProductExperience6+ yearsVisaUS citizen/visa onlyConnect directly with founders of the best YC-funded startups.Apply to role ›About the roleOverview
We were the first to shift FinOps left, and we see a big opportunity to make the $600B/year spent on cloud proactively managed, instead of teams reacting to surprise cost spikes. Reactive is too late, we already tried that approach with our first startup.
Join us as our first PM 🚀
This is a high-impact role at the heart of our product and growth strategy. You’ll own critical parts of our roadmap, from early-stage discovery through to GTM, and shape how we scale. You’ll work directly with Ali, co-founder who leads product and customer success, and your own dedicated team of senior engineers and a designer.
Check out this product announcement blog for examples of the types of complex problems we’re solving for engineering and FinOps teams at large enterprises; while also obsessing over developer experience:

AutoFix pull requests to make it 10x easier for engineers to fix cloud cost issues, using static analysis + LLMs to generate actionable code fixes, tailored to each customer’s cloud discounts and policies.
Finding issues in the cloud, fixing them in the code. Recommendations are easy; implementation is hard. Infra updates are scattered across hundreds of repos and teams. We’re solving for decentralized action at scale, the blocker no one else touches.

Timezone
US timezone (ideally Eastern time) as we have have customers and team members in the US and Europe. We are fully remote.
Responsibilities

Be the voice of users: Infracost sits at the intersection of FinOps, Engineering, and Engineering Management—each with different goals, workflows, and technical depth. Your mission is to deeply understand their worlds: the challenges they face, the tools they use, and how they measure success. You'll spend time talking to users, listening to signals (and the silence), and turning insights into action. Metrics and customer conversations will be your compass.
Shape the product, end-to-end: You won’t just define features, you’ll define outcomes. You’ll lead product discovery, turn complex problems into clear specs, and work side-by-side with design and engineering to bring elegant, developer-friendly solutions to life. You’ll ruthlessly prioritize based on impact, drive roadmap decisions, and own your product areas from idea through launch and iteration.
Collaborate to drive growth: You’ll work across the company, from customer success to sales to marketing, to ensure what we build lands well and grows fast. That means helping write crisp product docs, release notes, and blogs too. You’ll equip go-to-market teams with the messaging and context they need, and stay close to the field to keep learning how we can serve users better.

Prior experience

Required: Prior experience of owning a product (or major area), in the B2B space, from discovery through delivery and iteration.
Required: Experience with DevOps tools, cloud provisioning or Infrastructure-as-Code.
Significant advantage: Experience working in a fast-growing startup or domain expertise with cloud costs.

What we value

Ustomer, not customer: It is all about seeing us and the customer as one. We like to be a part of the user’s team, and help them however we can. If the user is not successful, then we will not be either so we try to walk in their shoes. It's more than work - we build relationships and community with users and customers.
Open is our core: Put yourself out there. Show your learning. Transparency builds confidence. Encourage sharing the good and the bad. The best decisions are made when everyone has access to all the data. Be straightforward and kind, feedback is about your work not your person.
Let's JEDI: Let’s Just Effing Do It! Own it and move fast. A good plan fiercely executed now is better than a perfect plan later. We ask for help and unblock each other. The main thing, is to keep the main thing, the main thing.

Benefits

Fully remote team
Two meetups a year - last year we went to Croatia and Barcelona.
Employee-friendly equity terms, including a 10 year exercise window
401k matching (US)
Health, dental, and vision insurance (US)
31 days paid leave per year (includes national holidays)
12 weeks paid parental leave

Compensation
In the United States, the starting base compensation range for this role is $150,000 - $200,000 (USD). Actual compensation may vary based on level, relevant experience, and skill set as assessed in the interview process, as well as market data by location. In addition to base salary, you will also receive equity in the company.
About the interview
25 minute initial chat
55 minute interview about your PM experience
55 minute case-study focusing on Infracost customer problems
55 minute interview discussing interactions with sales and marketing

You’ll get to meet all 3 co-founders, so bring your questions 😃
About Infracost$600B is spent on cloud each year, but no one knows the cost until it's too late. We’re changing that.
Since launching Infracost in 2021, we’ve been pulled by engineers who all want to Shift FinOps Left. We enable them to proactively find and fix cloud cost issues before they hit production. We plug directly into developer workflows (like GitHub and Azure Repos), show cost impact in pull requests, enforce tagging and FinOps best practices, and even generate PRs to fix issues automatically.
We're backed by Sequoia, YC and trusted by Fortune 500 enterprises. You'll join a small, experienced, and supportive team that's shipping fast, solving real infrastructure problems, and having fun while doing it.
Whether you're an engineer tackling complex systems (e.g. parsing massive Terraform repos, scaling real-time systems), a product manager shaping strategy from real customer pain points, or a customer success lead working directly with users; there’s meaningful work here for you. If you care about cloud efficiency, great UX, and helping teams move faster and smarter, we’d love to work with you!
Founded:2020Batch:W21Team Size:20Status:ActiveFoundersSimilar Jobs]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Supabase OrioleDB Patent: now freely available to the Postgres community]]></title>
            <link>https://supabase.com/blog/orioledb-patent-free</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45196173</guid>
        </item>
        <item>
            <title><![CDATA[The subjective experience of coding in different programming languages]]></title>
            <link>https://interconnected.org/home/2023/12/05/code</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45196163</guid>
            <description><![CDATA[Posted on Tuesday 5 Dec 2023. 687 words, no links. By Matt Webb.]]></description>
            <content:encoded><![CDATA[
  Different programming languages feel viscerally different, right? I can’t be the only one. It’s so embodied.
When I’m deep in multiple nested parentheses in a C-like language, even Python, I feel precarious, like I’m walking a high wire or balancing things in my hands and picking my way down steep stairs. It’s a relief to close the braces.
Like if I’m trying to cover all the conditions in a complicated state machine or a conditional, I’m high up. I often hold my breath.
Functional languages are the opposite.
I haven’t done much Haskell but what I did felt like crawling underground through caves and tunnels. Writing a text adventure game engine felt similar. Like I was making a map in the dark, kinda, and having to hold it in my head.
When I’ve written firmware, counting ops in the interrupt, it was precision work while being squeezed. To be typed with first fingers only, deliberately.
When I’m ssh’d into a device on my shelf and I’m writing code actually on the board, my sense of self is teleported over there and also I’m really really small. Opening a terminal window to a distant server is like reaching through a hatch with my arm, but a long way; ssh tunnel is well named.
Writing code with GitHub Copilot and Typescript in full flight feels like, well, flying, or at least great bounding leaps like being on the Moon. Coming back to typeless Python after writing Typescript is like stumbling drunk. It makes me feel unreliable but also hilariously giddy.
I feel tense and unsteady if I venture too far over my skis from a git commit.

Is code synesthesia a thing? If so mine is visceral, kinaesthetic.
Look, this isn’t the strongest synesthesia in the world. Oliver Sacks wouldn’t have written a book about it. It’s faint. But it’s present, that connections between code and embodiment. And at least some forms of it are common, right?
When I’ve been underwater in code all day it takes time to return to the surface. But also, halfway in a function even briefly, it takes a while to get my head up if anyone asks me a question. It’s confusing if it’s too abrupt. The bends.
And that experience I know is shared! The annoyance at sudden context switching I mean. You need a minute to move your mental stack somewhere safe.
But the overall synesthesia? I have no idea. I assume that most people have some form of it? As unfounded as that is.
Does it help?
Ha, no.
I mean, I doubt it helps. The best physicist I knew during undergrad told me he saw equations in colour. He was brilliant. I feel claustrophobic in a while loop if I haven’t typed a break yet. But I’m a midwit engineer. So from my n=2 study there’s no correlation.
Then again: when I’m interviewing a founder or reviewing a pitch deck or otherwise working to understand how a startup works, the system hangs together like a clockwork or a loop of flows, and I feel like my ability to zero in on the critical part or recognise missing connections comes from a visceral sensation of the cogs clashing or the circuit not closing or the engine cycle not turning. I rely on that sense of rightness. And that systems understanding sense is a very embodied sense for me, in proxemics terms it sits in my “intimate” perimeter, right up close with my eyes and hands, and I don’t think I could do that kind of work without it.

Maybe really great engineers have a totally different way of seeing code, in the same way that great chess players feel patterns and potential fields on the board?
Maybe the design of my code editor should learn from great engineers and amplify whatever synesthetic intuitions they might have: inner loops should appear crisper on the screen; editing compound conditionals should wobble just enough to make you seasick.
Are there any studies of the subjective experience of programming?
I’d love to read some.
  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Made for People, Not Cars: Reclaiming European Cities]]></title>
            <link>https://www.greeneuropeanjournal.eu/made-for-people-not-cars-reclaiming-european-cities/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45195520</guid>
            <description><![CDATA[By prioritising residents over private vehicles, a Spanish municipality has overcome some of the biggest challenges facing Europe’s cities.]]></description>
            <content:encoded><![CDATA[
					
	
		
With the number of passenger vehicles rising across Europe, cities are grappling with air pollution, traffic accidents, and the loss of public space. In Spain, the city of Pontevedra has managed to overcome these challenges, surpassing national air quality standards and creating safer streets.  The key, according to the Galician municipality’s mayor, is an urban model that prioritises residents over cars – without imposing an outright ban on private vehicles. 



It is a bright summer evening in Pontevedra, a Galician city in the northwest of Spain. The air is filled with a contralto accompanying a live jazz show in a corner of the big town square. A few metres away, four teenagers play soccer with an orange ball that two younger children try to touch in vain. A family takes a selfie while, seated on a nearby bench, four elderly women are engaged in a lively conversation. The intervals between one jazz piece and another are filled with the chirping of birds that are attracted to the greenery around the fountain.  



Looking at the images of Pontevedra from the 1990s, with lines of cars stretching as far as the eye could see, it would be very difficult to predict a future like this. But since family doctor Miguel Anxo Fernández Lores was elected mayor in 1999, the Galician city has been implementing policies that go well beyond regulating vehicles in its streets. The goal, according to the 71-year-old mayor, is to recover public space for the people.  



“When we reclaim public space and guarantee universal accessibility, then people have autonomy,” the mayor says. A politician of the Galician Nationalist Bloc party (Bloque Nacionalista Galego, BNG), Lores is now serving his seventh mandate and is willing to run for an eighth in 2027. Galicia is mainly and historically ruled by the right-wing Popular Party, and is the birthplace of several of its national leaders, which makes the local leftist and nationalist BNG’s long rule in Pontevedra an exception in the region.  




When we reclaim public space and guarantee universal accessibility, then people have autonomy.




In December 2022, the Spanish government approved a royal decree requiring all municipalities with more than 50,000 inhabitants to have a Low Emission Zone (LEZ) in operation. To improve air quality for citizens and reduce carbon emissions, the decree recommends measures such as restricting access for more polluting vehicles based on their environmental label and introducing traffic-restricted areas where entry charges apply.  



Spain adopted this measure to comply with the legally binding requirements of the Paris Agreement – the international treaty on climate change – more than six years after it entered into force in November 2016.  



Nevertheless, since Pontevedra was already fully complying with the air quality parameters laid out in the national Law 7/2021 on Climate Change, the city council decided to take a much more ambitious step: declaring the entire urban area (about 490 hectares) as a “reduced traffic zone”. 



On a sunny, fresh noon at the end of June in his city-centre office, Lores recalls what Pontevedra looked like when he first took up his duties: “It was literally a cars’ warehouse and people, especially those with disabilities and the elderly, couldn’t go out on the streets, because everything was occupied by vehicles.” 



While he speaks, the mayor mentions the 19th-century Catalan engineer Ildefons Cerdà i Sunyer, best known for the urban reform of Barcelona’s central Eixample neighbourhood, with its distinctive grid layout and symmetrical structure. Just like Cerdà, he views public space as an extension of the home.



Cars: a continental problem



More than 75 per cent of the EU population lives in urban areas, and this figure is expected to rise to approximately 83 per cent by 2050. With air pollution widely recognised as the most pressing health risk in Europe, curbing road transport emissions – responsible for 37 per cent of nitrogen oxide pollution – is crucial.  



The European Union has launched a number of initiatives to encourage cities to become cleaner and healthier. One of the most notable is the Green City Accord, which invites towns with a population of 20,000 inhabitants or more to commit to improvements in areas such as air and water quality, noise reduction, biodiversity conservation, and advancing towards a circular economy. The initiative also calls on cities to connect with a wider European network to facilitate knowledge sharing.  



Another initiative is the Climate-Neutral and Smart Cities EU Mission, which is supporting 100 cities in the EU and 12 in countries associated with the Horizon Europe programme. The goal of the mission is to develop a pilot project to achieve climate neutrality by 2030. The solutions and models tested in these cities could then serve as an example, helping all European cities to follow suit by 2050, the year by which the EU has committed to achieving net-zero greenhouse gas emissions. 



There are also informal initiatives such as the Ciudades que caminan (“Walking Cities”) network in Spain, which is a non-profit open to city councils and other public administrations committed to walkability. The network provides participant cities with training and a forum for the exchange of information and experiences. It includes an online school of public space, and is responsible for managing and promoting Entornos escolares (“school environments”), Spain’s most important website dedicated to promoting child autonomy and urban mobility.  



Still, in spite of both top-down and bottom-up initiatives, the number of cars in our continent is growing: in 2024, the number of vehicles in the European Union exceeded 259 million, an increase of 5.9 per cent as compared to 2019. The country with the highest motorisation rate – that is, the number of cars per 1,000 inhabitants – is Italy (701), followed by Luxembourg (670) and Finland (666 cars). With a rate of 544 (although this is based on provisional data), Spain is below the EU average of 576. 







Defying the norm  



Meanwhile, in Pontevedra, the number of cars has consistently diminished in recent years. The city has also introduced regulations both restricting the purposes for which cars may circulate and adjusting the times when they are permitted to do so. 



When asked to name one of the best examples of what his administration has achieved in terms of prioritising pedestrians over vehicles, the mayor does not hesitate to mention the transformation of one of the main squares in Pontevedra. Next to the remains of the 14th-century Gothic convent of Santo Domingo lies the wide Praza de España, regarded as the city’s “kilometre zero” – the starting point of its main natural and historical routes. Nowadays, the site serves as a lively hub where on any summer day walkers, drawn by the frequent cultural events hosted in the city, meet with pilgrims of the St. James’ Way.  



Lores points out that at the end of the 1990s, about 26,000 cars passed by this square every day. Remarkably, many of these vehicles were simply trying to reach destinations out of town, such as the beaches of Sanxenxo – a touristic municipality some 30 kilometres away, as well as the mayor’s birthplace – and to do so they passed through Praza de España. But today, transit traffic and circling for parking are not allowed anywhere in the city, and according to Lores, only 800 cars reach the square on a daily basis. As he explains, the decision to prohibit passing traffic and divert it to beltways has led to a 40-per cent reduction in the city’s overall traffic.   



Only “necessary traffic” is allowed in Pontevedra: vehicles used for emergency and public safety, public services (including garbage and water trucks, etc.), transportation of people with reduced mobility, and accessing private garages are permitted 24/7. However, loading and unloading for commercial supplies, home delivery, transporting bulky objects, and house moving and related activities, are permitted only during certain hours. Free parking spaces are scattered all over the city so that people can temporarily stop while carrying out any of these activities. In case of violations, police have the option to issue fines of up to several hundred euros.  



“There is no place in town that can’t be reached by car, but only by those who need to, not those who feel like it,” Lores explains. And with his characteristic tone, direct yet polite, he adds: “The fact that you park your private car in a public space is crazy: if you don’t have room for your freezer, do you put it on the sidewalk?” 



In the order of priorities, all cars, including electric ones, come last in Pontevedra: “The entire pyramid of preferences was changed: pedestrians come first, then bicycles, scooters, public transportation, and only lastly private transportation.” Inspired by Jane Jacobs’ 1961 book The Death and Life of Great American Cities, Lores has placed maintaining a “compact city” at the heart of his administration’s policies on urban expansion: concentrating most activities in the city centre, discouraging large department stores on the outskirts, encouraging mixed-use neighbourhoods instead of single-purpose zones (such as a separate ‘city of justice’), like Barcelona’s law courts complex and improving public transport. The aim is not only to reduce unnecessary car travel, but also to bring life to neighbourhoods and strengthen social cohesion. 




The entire pyramid of preferences was changed: pedestrians come first, then bicycles, scooters, public transportation, and only lastly private transportation.




Wandering through the downtown area on any working day, it is surprising to see the large number and diversity of shops, especially for a provincial city. Local boutiques, jewellers, florists, and bookstores all thrive side by side. 



In addition to the Galician municipality, some other European cities are also taking steps towards more sustainability. Freiburg, for instance, is well known for its sustainable policies, including its regulation of car traffic. In the vibrant university city in southwest Germany, the urban planning process involves local people, bikes account for about 30 per cent of all journeys, and one district – Vauban – is almost entirely car-free. Moreover, in 2019, Oslo became the first European capital to completely ban cars in its central areas. The city has expanded the public transportation network and eliminated hundreds of parking spaces, replacing them with benches, green spaces, and bike paths. 







In Pontevedra, pedestrians clearly take precedence in the centre – and in roughly a third of the city overall. There, the roads and the sidewalks are indistinguishable. For those who see it for the first time, it is startling to witness people walking in the middle of the street, apparently unconcerned, while cars slowly wait behind them until they spontaneously move and let them pass. No one honks; no traffic light is there to tell people when they can or can’t move. And no parking is allowed in the whole area between 6 PM and 8 AM. 



In the rest of the city, streets are single-track roads with wide sidewalks. Cars can stop during working hours for a limited time (15 minutes for services and 30 for loading and unloading), and parking is allowed between 9 PM and 9 AM. Traffic lights can only be found on the two-lane avenues on the city’s external ring, where pedestrian overpasses and roundabouts remind vehicles to slow down. Only ten minutes away from the city centre, an open-air parking area offers an alternative to the roughly 4,500 private underground parking spaces available in the city. In total, Pontevedra has more than ten free municipal parking sites and approximately 3,500 free parking spaces, all located within a walking distance of 10-15 minutes maximum from the centre. This is especially useful for people who don’t live in the city but have to commute from surrounding areas for work. 



Safer, healthier, and more accessible  



In 2010, Pontevedra was the first Spanish city to enact a speed limit of 30 km/h on all roads in its urban territory. At present, the limit is 10 km/h in the downtown area, “but only if there is no one around”, explains Daniel Macenlle, an ex-local policeman and the current director general for protection of citizens at the city council. “If there are people, then it goes down to six.” In the rest of the centre, the maximum speed is 20 kilometres per hour, while in other neighbourhoods, vehicles can go as fast as 30. 



The result is that there have been no fatal accidents on municipal roads for a decade. Today, according to municipality data, 73 per cent of children walk to school (including 44 per cent who go accompanied, and 29 who take the journey on their own). A 2012 study conducted in Denmark, involving 20,000 children and part of a bigger project on the links between concentration, diet, and exercise, found that those who walk or bike to school have higher concentration levels than their peers up to four hours later.  In Pontevedra, as in other Spanish cities like Barcelona, “school routes” have been implemented for years. These spaces with specific signposts are located around schools to offer students the option of walking to and from school, alone or in groups. 



And the benefits extend to all residents: overall, the number of people who choose to walk or bike in the Galician municipality has risen from 66 per cent in 2011 to 90 per cent in 2021. Moreover, today about 70 per cent of all trips take place on foot or by bicycle. The city council also estimates that, since the end of the 1990s, CO2 emissions have been reduced by approximately 67 per cent. 



Road and the sidewalk are indistinguishable in the city center Credit: ©Elena Ledda



In order to know not only the distance by foot, but also the number of steps and the calories burnt to reach a location, people in Pontevedra can try to use Metrominuto.1 The synoptic map includes information about the city’s historic sites, news (e.g. on recent international studies on mobility), and service information (like national subsidies for electric cars).  



Though it may be assumed that geo-referenced camera checks, fines and towing in place are extensively used to ensure road rules are respected in Pontevedra, most people interviewed said that the system works simply because people find that it is convenient. 



This is also true for businesses: “A city that is kind to you invites you to explore it and enjoy it. And when you walk around, you also consume,” says Andrés Martínez, 48 and owner of an optical shop in calle de la Oliva, one of the city’s more commercial streets. Andrés lives in the same building where the shop is located and parks his private car in its communal parking. 




A city that is kind to you invites you to explore it and enjoy it. And when you walk around, you also consume.




Another resident is 57-year-old Santi Cachadas, who has been selling fish at the municipal market for 30 years. He points out a different benefit of the city’s model: “People who come to buy pick up and leave, and that means an empty space where a new client can park, and so on, which leads to more movement.” Santi lives about three kilometres away from where he works, and every morning he leaves his car in a free parking lot, built by the Lérez river, and walks for 500 metres to reach his market stall. 



Still, it must be noted that two out of five business owners interviewed for this story, one managing a newsstand and one running an eco-products shop, say that their clients often complain about the fact that they cannot find parking spots.  



When asked why he thinks Pontevedra’s policies have succeeded, the mayor points to several factors: clear communication and education about the city’s goals, networking “with the most proactive and dynamic people in town”, carrying out participatory processes, and the decision not to ban cars outright. And he adds: “We carried out many projects to expand sidewalks and pedestrian spaces; as soon as the project was completed, the space was automatically occupied by activities. We also allowed cars that needed it to enter, and people who had doubts were relieved.” 



Replicating Pontevedra’s success 



Over the years, the northwestern Spanish municipality has received numerous awards for its good practices, including the UN-Habitat’s 2014 Dubai International Best Practices Award for Sustainable Development for its city model centred on people, and the 2020 European Commission’s EU Urban Road Safety Award for “impressively achieving zero road deaths between 2011 and 2018”.  



When invited to answer whether he thinks Pontevedra’s success is exportable, Lores quickly replies that each city has to find its own model and strategy, and that every external example needs to be translated. And when asked if there is at least some lesson he believes could serve as an inspiration for other cities, and if so, for what type of city, without hesitation he states: “Changing the paradigm by moving away from a town imagined for the cars back to one for the people”.  



This article was produced as part of the PULSE collaborative cross-border journalism initiative (coordinated by n-ost and OBCT) and in collaboration with journalist Alice Facchini.






Although I sometimes experienced delays when I tried to use the platform.  ↩︎	

				]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Children and young people's reading in 2025]]></title>
            <link>https://literacytrust.org.uk/research-services/research-reports/children-and-young-peoples-reading-in-2025/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45194165</guid>
            <description><![CDATA[This report outlines findings from our 2025 Annual Literacy Survey, when children and young people's reading enjoyment and frequency were at an all-time low.]]></description>
            <content:encoded><![CDATA[
          
            
            
            This report is based on 114,970 responses to our Annual Literacy Survey from children and young people aged 5 to 18 in early 2025. It includes findings on reading enjoyment, frequency and motivation and explores responses by age, gender, socio-economic background and geographical region.Our surveys show that the reading crisis persists, with the number of children and young people who say they enjoy reading, and read daily, continuing to decline.Key findingsReading enjoyment:In 2025, the percentage of children and young people who told us they enjoyed reading was its lowest in 20 years.Just 1 in 3 (32.7%) children and young people aged 8 to 18 said that they enjoyed reading in their free time in 2025. This marks a 36% decrease in reading enjoyment levels since we started asking about this in 2005.The drop in reading enjoyment over the last year has been especially steep among primary-aged children and boys, particularly boys aged 11 to 16.Reading frequency:Fewer than 1 in 5 (18.7%) 8- to 18-year-olds told us that they read something daily in their free time in 2025, again, the lowest levels we've recorded, with daily reading levels decreasing by nearly 20 percentage points since 2005.Even among children aged 5 to 8, daily reading rates dropped by 3.4 percentage points in the past year to 44.5%, and have dropped by 9.1 percentage points since we started asking this age group in 2019.Girls continue to read daily at higher rates than boys, with the gender gap widening to 6.2 percentage points – the largest seen since 2023. More children not receiving FSMs read daily (19.4%) than those who receive FSMs (15.8%).What would motivate children and young people to read (8 to 18)An important way to address the decline in reading enjoyment and frequency is to shed light on what drives or deters reading among children and young people, particularly for those who tell us that they don’t enjoy it. In 2025:2 in 5 children and young people were motivated to read when material related to a favourite film or TV series (38.1%) or matched their interests or hobbies (37.1%)3 in 10 (30.9%) were drawn in by an interesting book cover or title.1 in 4 (26.6%) valued having the freedom to choose what they read.Children and young people who report low levels of reading enjoyment, though less engaged, still recognise reading’s educational value (nearly half said it helps them learn new words or new things). Many also chose to read song lyrics, news articles, fiction, comics and fan fiction in their free time, highlighting how we might re-engage this group with reading. Findings suggest that this group would benefit from reading being aligned with personal interests and other media that children and young people already recognise as part of their cultural life.With thanks to Twinkl for supporting this report.
          
        ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[I replaced Animal Crossing's dialogue with a live LLM by hacking GameCube memory]]></title>
            <link>https://joshfonseca.com/blogs/animal-crossing-llm</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45192655</guid>
            <description><![CDATA[How I replaced Animal Crossing's dialogue with a live LLM by bridging GameCube memory to a cloud AI, with no game code changes required.]]></description>
            <content:encoded><![CDATA[
		
			
			A bridge from 2001 to today, with no game code changes required.
		

		
			
			Cookie: "Oh my gosh, Josh :)! I just had the weirdest dream, like, everything we do is a game! Arfer!"
		

		
			Animal Crossing. Infamous for its charming but ultimately repetitive dialogue. Having picked up the GameCube classic again, I was shocked (/s) to discover that the villagers still say the same things they did 23 years ago. Let's change that.
		
		
			The problem? The game runs on a Nintendo GameCube, a 24-year-old console with a 485 MHz PowerPC processor, 24MB of RAM, and absolutely no internet connectivity. It was fundamentally, physically, and philosophically designed to be an offline island.
		
		
			This is the story of how I built a bridge from 2001 to today, making a vintage game console talk to a cloud-based AI without modifying a single line of the original game's code.
		

		The First Hurdle: Speaking to the Game 🗣️
		
			My first stroke of luck was immense. The week I started this project, a massive effort by the Animal Crossing decompilation community reached completion. Instead of staring at PowerPC assembly, I had access to readable C code.
		
		
			Digging through the source, I quickly found the relevant functions under a file named m_message.c. This was it, the heart of the dialogue system. A simple test confirmed I could hijack the function call and replace the in-game text with my own string.
		

		C: A glimpse into the decompiled dialogue system
		// A glimpse into the decompiled Animal Crossing source code
// The function that changes message data in the dialogue system.
// My initial entry point for hijacking the text.

extern int mMsg_ChangeMsgData(mMsg_Window_c* msg_p, int index) {
    if (index >= 0 && index < MSG_MAX && mMsg_LoadMsgData(msg_p->msg_data, index, FALSE)) {
        msg_p->end_text_cursor_idx = 0;
        mMsg_Clear_CursolIndex(msg_p);
        mMsg_SetTimer(msg_p, 20.0f);
        return TRUE;
    }
    
    return FALSE;
}


		
			Easy win, right? But changing static text is one thing. How could I get data from an external AI into the game in real time?
		
		
			My first thought was to just add a network call. But that would mean writing an entire network stack for the GameCube from scratch (TCP/IP, sockets, HTTP) and integrating it into a game engine that was never designed for it. That was a non-starter.
		
		
			My second thought was to use the Dolphin emulator's features to write to a file on my host machine. The game would write a "request" file with context, and my Python script would see it, call the LLM, and write back a "response" file. Unfortunately, I couldn't get the sandboxed GameCube environment to access the host filesystem. Another dead end.
		

		The Breakthrough: The Memory Mailbox 📬
		
			The solution came from a classic technique in game modding: Inter-Process Communication (IPC) via shared memory. The idea is to allocate a specific chunk of the GameCube's RAM to act as a "mailbox." My external Python script can write data directly into that memory address, and the game can read from it.
		

		
			
				graph TD
					A[Python Script] -- "Writes LLM response" --> B{Memory Mailbox @ 0x81298360}
					B -- "Game reads new dialogue" --> C[Animal Crossing on Dolphin Emulator]
					C -- "Writes current speaker & context" --> B
			
		

		Python: The core of the "Memory Mailbox" interface
		# This is the bridge. These functions read from and write to GameCube RAM via Dolphin.
GAMECUBE_MEMORY_BASE = 0x80000000

def read_from_game(gc_address: int, size: int) -> bytes:
    """Reads a block of memory from a GameCube virtual address."""
    real_address = GAMECUBE_MEMORY_BASE + (gc_address - 0x80000000)
    return dolphin_process.read(real_address, size)

def write_to_game(gc_address: int, data: bytes) -> bool:
    """Writes a block of data to a GameCube virtual address."""
    real_address = GAMECUBE_MEMORY_BASE + (gc_address - 0x80000000)
    return dolphin_process.write(real_address, data)


		
			This was the path forward. But it created a new, painstaking task: I had to become a memory archaeologist. I needed to find the exact stable memory addresses for the active dialogue text and the current speaker's name.
		
		
			To do this, I wrote my own memory scanner in Python. The process was a tedious loop:
		
		
			Talk to a villager. The moment their dialogue box appeared, I'd freeze the emulator.
			Scan. I'd run my script to scan all 24 million bytes of the GameCube's RAM for the string of text on screen (e.g., "Hey, how's it going?").
			Cross-Reference. This often returned multiple addresses. So, I'd unfreeze, talk to a different villager, and scan for their name to figure out which memory block belonged to the active speaker.
		
		
			After hours of talking, freezing, and scanning, I finally nailed down the key addresses: 0x8129A3EA for the speaker's name and 0x81298360 for the dialogue buffer. I could now reliably read who was talking and, more importantly, write data back to the dialogue box.
		

		What About the GameCube Broadband Adapter? 🌐
		
			Yes, the GameCube had an official Broadband Adapter (BBA). But Animal Crossing shipped without networking primitives, sockets, or any game-layer protocol to use it. Using the BBA here would have required building a tiny networking stack and patching the game to call it. That means: hooking engine callsites, scheduling async I/O, and handling retries/timeouts, all inside a codebase that never expected the network to exist.
		
		
			Engine hooks: Hijack safe points in the message loop to send/receive packets.
			Driver/protocol: Provide a minimal UDP/RPC interface over BBA.
			Robustness: Handle timeouts, retries, and partial reads without stalling animations/UI.
		
		
			
				graph LR
					subgraph Option A: BBA Network Shim
						AC[Animal Crossing] --> Hooks[Net Shim Hooks]
						Hooks --> BBA[BBA Driver]
						BBA --> LAN[(LAN)]
						LAN --> Host[Host Bridge Server]
					end
					subgraph Option B: RAM Mailbox
						AC2[Animal Crossing] --> Mailbox[RAM Mailbox]
						Mailbox --> Py[Python Watcher]
						Py --> LLM[LLM]
					end
			
		
		
			I chose the RAM mailbox because it's deterministic, requires zero kernel/driver work, and stays entirely within the emulator boundary, with no binary network stack needed. That said, a BBA shim is absolutely possible (and a fun future project for real hardware via Swiss + homebrew).
		

		C: Minimal RPC envelope for a hypothetical BBA shim
		#include <stdint.h>

/* Minimal RPC envelope for a hypothetical BBA shim */
typedef struct {
    uint32_t magic;    // 'ACRP'
    uint16_t type;     // 1=Request, 2=Response
    uint16_t length;   // payload length
    uint8_t  payload[512];
} RpcMsg;

int ac_net_send(const RpcMsg* msg);         // sends via BBA
int ac_net_recv(RpcMsg* out, int timeoutMs); // polls with timeout


		Python: Host-side UDP bridge (very simplified)
		import socket, json
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.bind(("0.0.0.0", 19135))
while True:
    data, addr = sock.recvfrom(2048)
    msg = json.loads(data.decode("utf-8", "ignore"))
    # ... call Writer/Director LLMs ...
    reply = json.dumps({"ok": True, "text": "Hi from the cloud!"}).encode()
    sock.sendto(reply, addr)


		Speaking the Game's Secret Language 🤫
		
			I eagerly tried writing "Hello World" to the dialogue address and... the game froze. The character animations kept playing, but the dialogue wouldn't advance. I was so close, yet so far.
		
		
			The problem was that I was sending plain text. Animal Crossing doesn't speak plain text. It speaks its own encoded language filled with control codes.
		
		
			Think of it like HTML. Your browser doesn't just display words; it interprets tags like <b> to make text bold. Animal Crossing does the same. A special prefix byte, CHAR_CONTROL_CODE, tells the game engine, "The next byte isn't a character, it's a command!"
		
		
			These commands control everything: text color, pauses, sound effects, character emotions, and even the end of a conversation. If you don't send the <End Conversation> control code, the game simply waits forever for a command that never comes. That's why it was freezing.
		
		
			Once again, the decompilation community saved me. They had already documented most of these codes. I just needed to build the tools to use them.
		
		
			I wrote an encoder and a decoder in Python. The decoder could read raw game memory and translate it into a human-readable format, and the encoder could take my text with custom tags and convert it back into the exact sequence of bytes the GameCube understood.
		
		Python: A small sample of the control codes I had to encode/decode
		# A small sample of the control codes I had to encode/decode
CONTROL_CODES = {
    0x00: "<End Conversation>",
    0x03: "<Pause [{:02X}]>",        # e.g., <Pause [0A]> for a short pause
    0x05: "<Color Line [{:06X}]>",  # e.g., <Color Line [FF0000]> for red
    0x09: "<NPC Expression [Cat:{:02X}] [{}]>", # Trigger an emotion
    0x59: "<Play Sound Effect [{}]>",  # e.g., <Play Sound Effect [Happy]>
    0x1A: "<Player Name>",
    0x1C: "<Catchphrase>",
}

# The magic byte that signals a command is coming
PREFIX_BYTE = 0x7F


		
			With my new encoder, I tried again. This time, I wasn't just sending text. I was speaking the game's language. And it worked. The hardest part of the hack was done.
		

		Building the AI Brain 🧠
		
			With the communication channel established, it was time for the fun part: building the AI.
		
		
			My initial approach was to have a single LLM do everything: write dialogue, stay in character, and insert the technical control codes. The results were a mess. The AI was trying to be a creative writer and a technical programmer simultaneously and was bad at both.
		
		
			The solution was to split the task into a two-model pipeline: a Writer and a Director.
		
		
			The Writer AI: This model's only job is to be creative. It receives a detailed character sheet (which I generated by scraping the Animal Crossing Fan Wiki) and focuses on writing dialogue that is funny, in-character, and relevant to the context.
			The Director AI: This model receives the pure text from the Writer. Its job is purely technical. It reads the dialogue and decides how to "shoot the scene." It adds pauses for dramatic effect, emphasizes words with color, and chooses the perfect facial expression or sound effect to match the mood.
		
		
			This separation of concerns worked perfectly.
		

		
			
				graph LR
					subgraph Game World
						Dolphin(Dolphin Emulator)
					end

					subgraph Python Bridge
						Watcher(watch_dialogue.py)
						Encoder(Encoder/Decoder)
					end

					subgraph AI Core
						Writer(Writer LLM)
						Director(Director LLM)
					end

					subgraph External Data
						Wiki(Fan Wiki)
						News(RSS Feeds)
					end

					Dolphin <--> |IPC via RAM| Watcher
					Watcher --> |Context| Writer
					Wiki --> |Character Sheets| Writer
					News --> |Current Events| Writer

					Writer --> |Raw Dialogue| Director
					Director --> |Decorated Dialogue| Encoder
					Encoder --> |Encoded Bytes| Watcher
			
		

		Emergent Behavior 🤪
		
			First I piped in a lightweight news feed. Within minutes, villagers began weaving headlines into small talk, no prompts, just context.
		

		
			
			Mitzi: "About the news? European leaders are planning to meet with Trump and Zelenskyy!"
		

		
			Then I gave them a tiny shared memory for gossip, who said what, to whom, and how they felt. Predictably, it escalated into an anti-Tom Nook movement.
		

		
			
			Cookie: "Everything's going great in town, but sometimes I feel like Tom Nook is, like, taking all the bells!"
		

		
			And I was reminded that I used Fox News as the news feed.
		

		
			
			Cookie: "A woman was killed in a robbery in a blue city!"
		

		
			Now the game is a strange, hilarious, and slightly unsettling :)
		
		
			All the code for this project, including the memory interface, dialogue encoder, and AI prompting logic, is available on GitHub. It was one of the most challenging and rewarding projects I've ever tackled, blending reverse engineering, AI, and a deep love for a classic game.
			Watch the full video: Modern AI in a 24-Year-Old Game
	]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[R-Zero: Self-Evolving Reasoning LLM from Zero Data]]></title>
            <link>https://arxiv.org/abs/2508.05004</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45192194</guid>
            <description><![CDATA[Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.]]></description>
            <content:encoded><![CDATA[
    
    
                
    View PDF
    HTML (experimental)
            Abstract:Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.
    

    
    
      
          Subjects:
          
            Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)
        
          Cite as:
          arXiv:2508.05004 [cs.LG]
        
        
           
          (or 
              arXiv:2508.05004v2 [cs.LG] for this version)
          
        
        
           
                        https://doi.org/10.48550/arXiv.2508.05004
              
                                arXiv-issued DOI via DataCite
            
          
        
    
  
      Submission history From: Chengsong Huang [view email]                  [v1]
        Thu, 7 Aug 2025 03:38:16 UTC (665 KB)
    [v2]
        Wed, 27 Aug 2025 02:33:55 UTC (10,672 KB)
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NASA finds Titan's lakes may be creating vesicles with primitive cell walls]]></title>
            <link>https://www.sciencedaily.com/releases/2025/08/250831112449.htm</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45191347</guid>
            <description><![CDATA[Saturn’s moon Titan may be more alive with possibilities than we thought. New NASA research suggests that in Titan’s freezing methane and ethane lakes, simple molecules could naturally arrange themselves into vesicles—tiny bubble-like structures that mimic the first steps toward life. These compartments, born from splashing droplets and complex chemistry in Titan’s atmosphere, could act like primitive cell walls.]]></description>
            <content:encoded><![CDATA[NASA research has shown that cell-like compartments called vesicles could form naturally in the lakes of Saturn's moon Titan.
Titan is the only world apart from Earth that is known to have liquid on its surface. However, Titan's lakes and seas are not filled with water. Instead, they contain liquid hydrocarbons like ethane and methane.
On Earth, liquid water is thought to have been essential for the origin of life as we know it. Many astrobiologists have wondered whether Titan's liquids could also provide an environment for the formation of the molecules required for life - either as we know it or perhaps as we don't know it - to take hold there.
New NASA research, published in the International Journal of Astrobiology, outlines a process by which stable vesicles might form on Titan, based on our current knowledge of the moon's atmosphere and chemistry. The formation of such compartments is an important step in making the precursors of living cells (or protocells).
The process involves molecules called amphiphiles, which can self-organize into vesicles under the right conditions. On Earth, these polar molecules have two parts, a hydrophobic (water-fearing) end and a hydrophilic (water-loving) end. When they are in water, groups of these molecules can bunch together and form ball-like spheres, like soap bubbles, where the hydrophilic part of the molecule faces outward to interact with the water, thereby 'protecting' the hydrophobic part on the inside of the sphere. Under the right conditions, two layers can form creating a cell-like ball with a bilayer membrane that encapsulates a pocket of water on the inside.
When considering vesicle formation on Titan, however, the researchers had to take into account an environment vastly different from the early Earth.
Uncovering Conditions on Titan 
Titan is Saturn's largest moon and the second largest in our solar system. Titan is also the only moon in our solar system with a substantial atmosphere.


The hazy, golden atmosphere of Titan kept the moon shrouded in mystery for much of human history. However, when NASA's Cassini spacecraft arrived at Saturn in 2004, our views of Titan changed forever.
Thanks to Cassini, we now know Titan has a complex meteorological cycle that actively influences the surface today. Most of Titan's atmosphere is nitrogen, but there is also a significant amount of methane (CH4). This methane forms clouds and rain, which falls to the surface to cause erosion and river channels, filling up the lakes and seas. This liquid then evaporates in sunlight to form clouds once again.
This atmospheric activity also allows for complex chemistry to happen. Energy from the Sun breaks apart molecules like methane, and the pieces then reform into complex organic molecules. Many astrobiologists believe that this chemistry could teach us how the molecules necessary for the origin of life formed and evolved on the early Earth.
Building Vesicles on Titan 
The new study considered how vesicles might form in the freezing conditions of Titan's hydrocarbon lakes and seas by focusing on sea-spray droplets, thrown upwards by splashing raindrops. On Titan, both spray droplets and the sea surface could be coated in layers of amphiphiles. If a droplet then lands on the surface of a pond, the two layers of amphiphiles meet to form a double-layered (or bilayer) vesicle, enclosing the original droplet. Over time, many of these vesicles would be dispersed throughout the pond and would interact and compete in an evolutionary process that could lead to primitive protocells.
If the proposed pathway is happening, it would increase our understanding of the conditions in which life might be able to form.
"The existence of any vesicles on Titan would demonstrate an increase in order and complexity, which are conditions necessary for the origin of life," explains Conor Nixon of NASA's Goddard Space Flight Center in Greenbelt, Maryland. "We're excited about these new ideas because they can open up new directions in Titan research and may change how we search for life on Titan in the future."
NASA's first mission to Titan is the upcoming Dragonfly rotorcraft, which will explore the surface of the Saturnian moon. While Titan's lakes and seas are not a destination for Dragonfly (and the mission won't carry the light-scattering instrument required to detect such vesicles), the mission will fly from location to location to study the moon's surface composition, make atmospheric and geophysical measurements, and characterize the habitability of Titan's environment.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hypervisor in 1k Lines]]></title>
            <link>https://1000hv.seiya.me/en</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45190777</guid>
            <description><![CDATA[Write your first hypervisor from scratch, in 1K LoC.]]></description>
            <content:encoded><![CDATA[WARNINGThis book is work in progress.Hey there (maybe again)! In this book, you'll learn how to build a minimal RISC-V hypervisor which can boot Linux-based operating systems.This is a sequel to the online book Operating System in 1,000 Lines. In that book, you have learned how to build a minimal operating system from scratch in C, but this time, we'll start from scratch (again) in your favorite language, Rust!From scratch means we'll start from the bare-metal programming in Rust, that is type-1 hypervisor, in 1000 lines of code like we did for the OS.However, this time we'll cheat a little bit, by relying on the power of Rust's ecosystem: third-party libraries ("crates") to avoid implementing things that don't really matter for learning hypervisors.You can download the implementation examples from GitHub.This book is available under the CC BY 4.0 license. The implementation examples and source code in the text are under the MIT license.Happy hypervisor hacking!]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Memory Integrity Enforcement]]></title>
            <link>https://security.apple.com/blog/memory-integrity-enforcement/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186265</guid>
            <description><![CDATA[Memory Integrity Enforcement (MIE) is the culmination of an unprecedented design and engineering effort spanning half a decade that combines the unique strengths of Apple silicon hardware with our advanced operating system security to provide industry-first, always-on memory safety protection across our devices — without compromising our best-in-class device performance. We believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.]]></description>
            <content:encoded><![CDATA[Memory Integrity Enforcement (MIE) is the culmination of an unprecedented design and engineering effort, spanning half a decade, that combines the unique strengths of Apple silicon hardware with our advanced operating system security to provide industry-first, always-on memory safety protection across our devices — without compromising our best-in-class device performance. We believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.

There has never been a successful, widespread malware attack against iPhone. The only system-level iOS attacks we observe in the wild come from mercenary spyware, which is vastly more complex than regular cybercriminal activity and consumer malware. Mercenary spyware is historically associated with state actors and uses exploit chains that cost millions of dollars to target a very small number of specific individuals and their devices. Although the vast majority of users will never be targeted in this way, these exploit chains demonstrate some of the most expensive, complex, and advanced attacker capabilities at any given time and are uniquely deserving of study as we work to protect iPhone users against even the most sophisticated threats. Known mercenary spyware chains used against iOS share a common denominator with those targeting Windows and Android: they exploit memory safety vulnerabilities, which are interchangeable, powerful, and exist throughout the industry.
For Apple, improving memory safety is a broad effort that includes developing with safe languages and deploying mitigations at scale. (For a primer on how we think about memory safety, see the opening of this post.) We created Swift, an easy-to-use, memory-safe language, which we employ for new code and targeted component rewrites. In iOS 15, we introduced kalloc_type, a secure memory allocator for the kernel, followed in iOS 17 by its user-level counterpart, xzone malloc. These secure allocators take advantage of knowing the type — or purpose — of allocations so that memory can be organized in a way that makes exploiting most memory corruption vulnerabilities inherently difficult.
In 2018, we were the first in the industry to deploy Pointer Authentication Codes (PAC) in the A12 Bionic chip, to protect code flow integrity in the presence of memory corruption. The strong success of this defensive mechanism in increasing exploitation complexity left no doubt that the deep integration of software and hardware security would be key to addressing some of our greatest security challenges. With PAC behind us, we immediately began design and evaluation work to find the most effective way to build sophisticated memory safety capabilities right into Apple silicon.
Arm published the Memory Tagging Extension (MTE) specification in 2019 as a tool for hardware to help find memory corruption bugs. MTE is, at its core, a memory tagging and tag-checking system, where every memory allocation is tagged with a secret; the hardware guarantees that later requests to access memory are granted only if the request contains the correct secret. If the secrets don’t match, the app crashes, and the event is logged. This allows developers to identify memory corruption bugs immediately as they occur.
We conducted a deep evaluation and research process to determine whether MTE, as designed, would meet our goals for hardware-assisted memory safety. Our analysis found that, when employed as a real-time defensive measure, the original Arm MTE release exhibited weaknesses that were unacceptable to us, and we worked with Arm to address these shortcomings in the new Enhanced Memory Tagging Extension (EMTE) specification, released in 2022. More importantly, our analysis showed that while EMTE had great potential as specified, a rigorous implementation with deep hardware and operating system support could be a breakthrough that produces an extraordinary new security mechanism.
Consider that MTE can be configured to report memory corruption either synchronously or asynchronously. In the latter mode, memory corruption doesn’t immediately raise an exception, leaving a race window open for attackers. We would not implement such a mechanism. We believe memory safety protections need to be strictly synchronous, on by default, and working continuously. But supporting always-on, synchronous MTE across key attack surfaces while preserving a great, high-performance user experience is extremely demanding for hardware to support.
In addition, for MTE to provide memory safety in an adversarial context, we would need to finely tune the operating system to defend the new semantics and the confidentiality of memory tags on which MTE relies. Ultimately, we determined that to deliver truly best-in-class memory safety, we would carry out a massive engineering effort spanning all of Apple — including updates to Apple silicon, our operating systems, and our software frameworks. This effort, together with our highly successful secure memory allocator work, would transform MTE from a helpful debugging tool into a groundbreaking new security feature.
Today we’re introducing the culmination of this effort: Memory Integrity Enforcement (MIE), our comprehensive memory safety defense for Apple platforms. Memory Integrity Enforcement is built on the robust foundation provided by our secure memory allocators, coupled with Enhanced Memory Tagging Extension (EMTE) in synchronous mode, and supported by extensive Tag Confidentiality Enforcement policies. MIE is built right into Apple hardware and software in all models of iPhone 17 and iPhone Air and offers unparalleled, always-on memory safety protection for our key attack surfaces including the kernel, while maintaining the power and performance that users expect. In addition, we’re making EMTE available to all Apple developers in Xcode as part of the new Enhanced Security feature that we released earlier this year during WWDC.
The rest of this post dives into the intensive engineering effort required to design and validate Memory Integrity Enforcement.
Designing Memory Integrity Enforcement
Memory Integrity Enforcement starts with our secure memory allocators — kalloc_type, xzone malloc, and WebKit’s libpas — all of which use type information to decide how to organize memory allocations. With both use-after-free and out-of-bounds bugs, an attacker’s goal is to create overlapping interpretations of memory, which they achieve by controlling the precise position of certain allocations — of a specific type — that is advantageous to them. The type-aware placement policies of our secure memory allocators help thwart these memory corruption techniques, as we described in our kalloc_type post. Our secure allocators set a new high-water mark of software protection against memory corruption, while preserving the same or better performance as the allocators they replaced.
Allocators can apply protections only at the granularity of memory pages — 16KB on iOS — which is a natural fit for multi-page allocations. For smaller allocations, our secure allocators can use page-level protections to help prevent memory corruption attacks across different type buckets. However, page-level protections are too coarse to defend against attacks within the same type bucket, and we use memory tagging to close this gap.
Let’s look at how EMTE can be used to protect against two of the most common types of memory corruption: buffer overflows and use-after-free vulnerabilities. For buffer overflows, the allocator is responsible for using different tags for neighboring allocations. If a request to access memory spills over to adjacent memory that has a different tag, the hardware blocks it, and the operating system can take action and terminate the process. We represent this visually below with three adjacent allocations, tagged with three different secrets: ⏺️, 🔼, and ⏹️. Two access attempts with the 🔼 tag are permitted to 🔼-tagged memory, but the third attempt is blocked as it spills over into the adjacent, ⏹️-tagged allocation.
 Memory Integrity Enforcement blocks buffer overflows 

The allocator is also responsible for retagging memory as it gets reused for other purposes. In the image below, the 🔼 allocation is retagged as ⏹️ after it has been freed and reallocated by the system. If a request to the retagged memory is made with the older 🔼 tag, as would be seen in use-after-free exploits, the hardware blocks it and lets the operating system take further action.
 Memory Integrity Enforcement blocks use-after-free access

A key weakness of the original MTE specification is that access to non-tagged memory, such as global variables, is not checked by the hardware. This means attackers don’t have to face as many defensive constraints when attempting to control core application configuration and state. With Enhanced MTE, we instead specify that accessing non-tagged memory from a tagged memory region requires knowing that region’s tag, making it significantly harder for attackers to turn out-of-bounds bugs in dynamic tagged memory into a way to sidestep EMTE by directly modifying non-tagged allocations.
Finally, we developed Tag Confidentiality Enforcement to protect the implementation of our secure allocators from technical threats and to guard the confidentiality of EMTE tags — including against side-channel and speculative-execution attacks.
Our typed allocators and EMTE both rely on confidentiality of kernel data structures from user applications, and of the tags chosen by the allocator. Attackers might attempt to defeat EMTE, and in turn Memory Integrity Enforcement, by revealing these secrets. To protect the kernel allocator backing store and tag storage, we use the Secure Page Table Monitor, which provides strong guarantees even in the presence of a kernel compromise. We also ensure that when the kernel accesses memory on behalf of an application, it's subject to the same tag-checking rules as userspace.
Attacks based on speculative execution can also be used to expose secrets. To improve performance, modern CPUs predict the execution of instructions that follow prior, potentially longer latency instructions. If the prediction is correct, computation is very fast. If it’s wrong, the CPU discards the prediction, and computation is slower. Unfortunately, discarded predictions have observable effects that can reveal system state and data, and because speculative attacks never cause the system to crash or misbehave in observable ways during their use, they’re particularly useful for an attacker. For example, evaluating a pointer authentication instruction speculatively exposed timing differences in our original implementation of Pointer Authentication Codes (PAC), which would allow the valid signature to be isolated. During the design phase for Memory Integrity Enforcement, we identified and addressed the three speculative vulnerabilities that could undermine tag confidentiality.
First, when EMTE is active, requests to access memory cause the hardware to check tags. It's crucial that evaluating a tag-checking instruction speculatively doesn’t expose timing differences that would allow an attacker to isolate the valid tag. From the start, we designed the Apple silicon implementation so that tag values can’t influence speculative execution in any way. Recently published security research demonstrates that the MTE implementation on Google’s Pixel devices is vulnerable to this type of attack, allowing MTE to be bypassed in Google Chrome and the Linux kernel.
Second, allocators assign random tags to memory, and attackers must not be able to predict tag values that the system will choose. We address this issue by frequently re-seeding the underlying pseudo-random generator used to select new tags.
Third, Spectre variant 1 (V1) is a speculative-execution vulnerability that allows attackers to exploit conditional branches to leak data, including MTE tag values. To date, there has been no solution to this problem in consumer operating systems, because general Spectre V1 mitigations such as Speculative Load Hardening have a prohibitive CPU cost. The presence of EMTE leaves Spectre V1 as one of the last avenues available to attackers to help guide their attacks, so we designed a completely novel mitigation that limits the effective reach of Spectre V1 leaks — at virtually zero CPU cost — and forces attackers to contend with type segregation. This mitigation makes it impractical for attackers to use Spectre V1, as they would typically need 25 or more V1 sequences to reach more than 95 percent exploitability rate — unless one of these sequences is related to the bug being exploited, following similar reasoning as our kalloc_type analysis.
Our mission with Memory Integrity Enforcement is to protect all users by default and provide an extraordinary disruption to the exploitation of memory corruption vulnerabilities. To do so, we considered a wide set of threats, including some of the most challenging ones — such as side channels — and arrived at this extensive combination of features not present in other MTE implementations. Google took a great first step last year when they offered MTE to those who opt in to their program for at-risk users. But even for users who turn it on, the effectiveness of MTE on Android is limited by the lack of deep integration with the operating system that distinguishes Memory Integrity Enforcement and its use of EMTE on Apple silicon.
For the new A19 and A19 Pro chips to support Memory Integrity Enforcement, we dedicated an extraordinary amount of Apple silicon resources to security — more than ever before — including CPU area, CPU speed, and memory for tag storage. And to fully realize this hardware investment, we designed all of the new operating system elements of MIE jointly with our hardware work, including secure allocators, EMTE, and tag confidentiality protections.
Because EMTE tag checking imposes a performance cost, we designed Memory Integrity Enforcement to take advantage of our secure allocators first and use EMTE to protect only smaller individual allocations within a type bucket, which software allocators can’t defend on their own. Then, by knowing where and how we would deploy EMTE, we could accurately model the tag-checking demand of the operating system, and design our silicon to satisfy it. Our hardware implementation influenced additional software design decisions, reducing the overhead of tag checks even further. Importantly, deploying EMTE with this level of precision supports our strategy to provide as many memory safety improvements as possible to users on previous iPhone generations, which don’t support EMTE.
For the security evaluation of Memory Integrity Enforcement, we involved our offensive research team from the very beginning. From 2020 to 2025, they continuously analyzed and attacked the system — first conceptually, with theoretical exploitation avenues, then with practical attacks in simulated environments, and eventually on new hardware prototypes. Prolonged engagement from our offensive research team allowed us to identify and eradicate entire attack strategies and techniques before attackers could ever discover them, leading to a stronger, more mature feature from the outset.
Our offensive research team identified where and how attackers are most likely to break into the system, and our deployment of Memory Integrity Enforcement is deeply guided by their findings. Notably, this includes making sure that this powerful new protection is available to third-party apps that are likely entry points for attackers — such as social networks, messaging apps, or any other app where a specific user can be targeted. Starting immediately with the launch of MIE, any developer can begin testing this powerful protection for their app, including EMTE on hardware that supports it, using the Enhanced Security settings in Xcode.
The meticulous planning and implementation of Memory Integrity Enforcement made it possible to maintain synchronous tag checking for all the demanding workloads of our platforms, delivering groundbreaking security with minimal performance impact, while remaining completely invisible to users.
Security evaluation
Memory Integrity Enforcement started with a deeply ambitious goal: to make it immensely more expensive and difficult to develop and maintain mercenary spyware attacks based on memory corruption against our platforms. While there’s no such thing as perfect security, MIE is designed to dramatically constrain attackers and their degrees of freedom during exploitation.
Throughout the design and implementation of Memory Integrity Enforcement, our offensive research team evaluated our progress by looking at sophisticated exploit chains that were previously used against our platform, recent vulnerabilities, and our own internal research. First, we worked on rebuilding and adapting previously seen exploit chains to systems protected by MIE. But it’s not sufficient to consider only previous chains that were developed before MIE existed, because attackers will surely adapt in reaction to these new protections. We therefore also evaluated a selection of more recent vulnerabilities that we expected would have the best chance of surviving MIE. For these, we meticulously enumerated all possible exploitation opportunities, similar to our evaluation of SockPuppet against kalloc_type.
Both approaches revealed the same conclusion: Memory Integrity Enforcement vastly reduces the exploitation strategies available to attackers. Though memory corruption bugs are usually interchangeable, MIE cut off so many exploit steps at a fundamental level that it was not possible to restore the chains by swapping in new bugs. Even with substantial effort, we could not rebuild any of these chains to work around MIE. The few memory corruption effects that remained are unreliable and don’t give attackers sufficient momentum to successfully exploit these bugs.
Here’s a visual representation of what this looks like for an attacker. The chart below represents six of the real-world exploit chains that we evaluated and shows the steps where Memory Integrity Enforcement — the secure allocators, EMTE, or both — stops the attack.
 Memory Integrity Enforcement vs. real-world exploit chains

Notably, attackers confront Memory Integrity Enforcement early in the exploitation process. Although some issues are able to survive MIE — for example, intra-allocation buffer overflows — such issues are extremely rare, and even fewer will lend themselves to a full end-to-end exploit. Inevitably, attackers must face MIE at a stage where their capabilities are still very limited, leaving few viable avenues for exploitation. This leads to fragile chains where breaking just one step is often enough to invalidate the entire exploit strategy. When that happens, most of the chain’s components can’t be reused, and the attackers have to restart exploit development with entirely new bugs.
Conclusion
The industry-leading security of iPhone means that the vast majority of our users never face system-level attacks on their devices. Our work on memory safety is aimed primarily at the mercenary spyware and surveillance industry, which spends many millions of dollars to exploit memory corruption vulnerabilities and target a small number of individuals because of who they are and what they do. Over the past five years, we developed a comprehensive approach to memory safety that integrates the best of our hardware and software capabilities, and today’s announcement is the culmination of this ambitious vision. With the introduction of the iPhone 17 lineup and iPhone Air, we’re excited to deliver Memory Integrity Enforcement: the industry’s first ever, comprehensive, always-on memory-safety protection covering key attack surfaces — including the kernel and over 70 userland processes — built on the Enhanced Memory Tagging Extension (EMTE) and supported by secure typed allocators and tag confidentiality protections.
Based on our evaluations pitting Memory Integrity Enforcement against exceptionally sophisticated mercenary spyware attacks from the last three years, we believe MIE will make exploit chains significantly more expensive and difficult to develop and maintain, disrupt many of the most effective exploitation techniques from the last 25 years, and completely redefine the landscape of memory safety for Apple products. Because of how dramatically it reduces an attacker’s ability to exploit memory corruption vulnerabilities on our devices, we believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[iPhone Air]]></title>
            <link>https://www.apple.com/newsroom/2025/09/introducing-iphone-air-a-powerful-new-iphone-with-a-breakthrough-design/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186015</guid>
            <description><![CDATA[Apple today debuted the all-new iPhone Air, the thinnest iPhone ever made, with pro performance.]]></description>
            <content:encoded><![CDATA[


	
    







 

	
    
    
        




    
    
    
	
	







 




opens in new window








    
    
    









    





    
        
		
        
                    
                    
                        PRESS RELEASE
                    
                    
                        September 9, 2025
                    
                    
                

        
                
                
                
                    
                        
    
        Introducing iPhone Air, a powerful new iPhone  with a breakthrough design
    

                    
                
            

        
                
                
                    iPhone Air features an impossibly thin and light  design that is more durable than any previous model,  with innovative camera experiences and  remarkable all‑day battery life
                
            

        
            
    
    
    
    
    

        

    







    
    
    






  
    
    
    
    
      
        
      
    
  








    
    
    


     
     
    
    
        CUPERTINO, CALIFORNIA Apple today debuted the all-new iPhone Air, the thinnest iPhone ever made, with pro performance. iPhone Air features a breakthrough titanium design that is elegant and light yet strong, with an innovative internal architecture that enables the latest iPhone experiences. The back of iPhone Air is now protected with Ceramic Shield, and the front cover uses Ceramic Shield 2, delivering 3x better scratch resistance, making iPhone Air more durable than any previous iPhone. iPhone Air also features a stunning 6.5-inch Super Retina XDR display with ProMotion up to 120Hz.1 With the most Apple-designed chips in an iPhone — the powerhouse A19 Pro, N1, and C1X — iPhone Air is the most power-efficient iPhone ever made. Paired with the redesigned internal architecture and software optimizations, iPhone Air has fantastic all-day battery life. A powerful 48MP Fusion Main camera enables the equivalent of four lenses with incredible image quality, and the innovative 18MP Center Stage front camera takes selfies to the next level.

 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            iPhone Air is shown from the back in space black, cloud white, light gold, and sky blue.
                        
                    
                        
                            iPhone Air is shown from the side in sky blue, light gold, cloud white, and space black.
                        
                    
                        
                            A person holds up iPhone Air between two fingers, emphasizing with this side profile view how thin the device is.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
             
                 A Breakthrough Design

                 
             
                 Featuring a breakthrough design with pro performance, iPhone Air is the thinnest iPhone ever made at 5.6mm, and it is incredibly light, with a large, stunning display. The grade 5 titanium frame is strong, with an elegant high-gloss mirror finish, and a new plateau on the back that is precision-milled on both sides to house the cameras, speaker, and Apple silicon. This maximizes space for the battery to deliver remarkable all-day battery life. The thin design also features the Action button, so users can easily access a variety of functions with just a press, and Camera Control, to quickly launch the camera or enable visual intelligence.2

                 
             
         
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            An outdoor portrait of a person with curly hair taken with 2x Telephoto on iPhone Air.
                        
                    
                        
                            A photo of a towering rock formation taken in 48MP on iPhone Air.
                        
                    
                        
                            An outdoor photo of a person standing inside a hot air balloon billowing in the wind taken in 24MP on iPhone Air.
                        
                    
                        
                            A close-up photo of a stack of homemade waffles covered in colorful berries showing Focus Control on iPhone Air.
                        
                    
                        
                            An editorial-style photo of a person wearing all white against an abstract black-and-white backdrop showing Photographic Styles and taken on iPhone Air.
                        
                    
                        
                            An editorial-style photo of a person wearing all white sitting on a chair inside a dimly lit room taken on iPhone Air.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
             
                 eSIM: A Flexible, Convenient, and Secure Connection

                 
             
                 iPhone Air features an eSIM-only design that saves space internally, helping enable the unbelievably light and thin form factor.4 eSIM offers greater flexibility, better security, and seamless connectivity compared to traditional physical SIM cards. An industry standard, eSIM is supported by over 500 carriers worldwide, including AT&T, T-Mobile, Verizon, and more. eSIM also makes staying connected while traveling even more convenient, allowing continued connectivity through affordable international roaming plans from users’ home carriers or local prepaid options available with more than 200 carriers. For better security, eSIM cannot be physically removed if an iPhone is lost or stolen, and managing travel eSIMs is even easier with a new streamlined setup in iOS 26.

                 
             
                 Featuring iOS 26 with New Apple Intelligence Capabilities

                 
             
                 iOS 26 elevates the iPhone experience with a beautiful new design, powerful Apple Intelligence capabilities, and meaningful improvements to the apps users rely on every day. The new design with Liquid Glass makes apps and system experiences more expressive and delightful, bringing greater focus to content while keeping iOS instantly familiar. Apple Intelligence now translates text and audio on the go with Live Translation, helping users communicate across languages in Messages, FaceTime, and Phone.5 Updates to visual intelligence allow users to capture a screenshot and easily search or take action on anything they are viewing on their iPhone screen. The on-device foundation model at the core of Apple Intelligence is available to all developers, with apps already offering new intelligent, privacy-protected experiences that can even be used when offline. New screening tools for calls and messages help eliminate distractions so users can focus on the conversations that matter most. iOS 26 also introduces new features in CarPlay, Apple Music, Maps, and Wallet, as well as Apple Games, a brand-new app that gives players a single destination for all their games.

                 
             
         
 

    
    
    


    
        
        
        
        
            
                
            
        
    












    
    
    


     
     
    
    
        
             
                 Beautiful New Accessories

                 
             
                 
                 
             
                 
The iPhone Air Case with MagSafe — available in frost and shadow — has an ultra-thin translucent design with a lightly frosted interior, a high-gloss outer surface, and a reinforced polycarbonate frame to protect iPhone Air from scratches and drops.


                 
             
                 
The slim and lightweight iPhone Air Bumper — available in four matching colors — perfectly frames iPhone Air with a reinforced polycarbonate design for added edge protection.


                 
             
                 
Crafted from 100 percent recycled yarns, the Crossbody Strap drapes comfortably, with embedded flexible magnets and stainless steel sliding mechanisms to easily adjust the length and keep both straps securely aligned. The Crossbody Strap will be available in 10 colors: black, light gray, blue, light blue, purple, sienna, green, neon yellow, tan, and orange.


                 
             
                 
The iPhone Air MagSafe Battery has a thin and light design that seamlessly attaches to the back of the device. The MagSafe Battery quickly charges iPhone Air when the battery is low, and maximizes battery life when connected throughout the day, delivering up to 40 hours of video playback when used together.


                 
             
         
 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            iPhone Air is shown with the new MagSafe Case.
                        
                    
                        
                            iPhone Air is shown with the new Bumper.
                        
                    
                        
                            iPhone Air is shown with the new Crossbody Strap.
                        
                    
                        
                            iPhone Air is shown with the new MagSafe Battery.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
             
                 iPhone Air and the Environment

                 
             
                 Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. iPhone Air is made with 35 percent recycled content, including 80 percent recycled titanium, the highest ever for an iPhone, and 100 percent recycled cobalt in the battery. A new titanium USB-C port is 3D-printed to be thinner and stronger, fitting into the slim design while using 33 percent less material than a conventional forging process. iPhone Air is manufactured with 45 percent renewable electricity, like wind and solar, across the supply chain. It is designed to be durable, repairable, and offer industry-leading software support, while meeting Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled.

                 
             
         
 

    
    
    


     
     
    
    
        
             
                 
                 
             
                 
iPhone Air will be available in space black, cloud white, light gold, and sky blue, starting with 256GB storage, as well as 512GB and 1TB options. iPhone Air starts at $999 (U.S.) or $41.62 (U.S.) per month.6


                 
             
                 
Apple offers great ways to save and upgrade to the latest iPhone models. With Apple Trade In, customers can get $200 to $700 (U.S.) in credits when they trade in iPhone 13 or newer.7 Apple also partners with select carriers to offer incredible deals, and customers can get up to $1,100 (U.S.) in credits when they trade in iPhone 13 or newer — in any condition — to put toward iPhone 17 Pro. Customers can take advantage of carrier deals by visiting the Apple Store online or an Apple Store location. For carrier deal eligibility requirements and more details, see apple.com/shop/buy-iphone/carrier-offers. To see what their device is worth and for trade-in terms and conditions, customers can visit apple.com/shop/trade-in.


                 
             
                 
Customers in more than 63 countries and regions, including Australia, Canada, China, Colombia, France, Germany, India, Japan, Malaysia, Mexico, Singapore, South Korea, Thailand, Türkiye, the UAE, the UK, the U.S., and Vietnam, will be able to pre-order iPhone Air beginning at 5 a.m. PDT this Friday, September 12, with availability beginning Friday, September 19. iPhone Air will be available in 22 other countries and regions beginning Friday, September 26.


                 
             
                 
iOS 26 will be available as a free software update on Monday, September 15. Some features may not be available in all languages or regions, and availability may vary due to local laws and regulations. For more information about availability, visit apple.com.


                 
             
                 
Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. More languages will be coming by the end of this year: Danish, Dutch, Norwegian, Portuguese (Portugal), Swedish, Turkish, Chinese (traditional), and Vietnamese. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.


                 
             
                 
Apple is extending free access to satellite features for an additional year for existing iPhone 14 and iPhone 15 users. The free trial will be extended for iPhone 14 and iPhone 15 users who have activated their device in a country that supports Apple’s satellite features prior to 12 a.m. PT on September 9, 2025. For satellite feature availability, visit support.apple.com/en-us/105097.


                 
             
                 
iPhone Air MagSafe Battery will be available for $99 (U.S.). iPhone Air Case with MagSafe is available for $49 (U.S.), iPhone Air Bumper will be available for $39 (U.S.), and a Crossbody Strap will be available for $59 (U.S.). FineWoven Wallet with MagSafe will be available for $59 (U.S.) in black, navy, midnight, purple, fox orange, and moss.


                 
             
                 
The Apple-designed 40W Dynamic Power Adapter with 60W Max will be available for $39 (U.S.), and a Qi2 25W-certified MagSafe Charger will be available in a 1-meter length for $39 (U.S.) or a 2-meter length for $49 (U.S.).8


                 
             
                 
AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new iPhone, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple experts. For more information, visit apple.com/applecare.


                 
             
                 
iCloud+ plans start at just $0.99 (U.S.) per month, providing additional storage to keep photos, videos, files, and more safe in the cloud and accessible across devices. iCloud+ also gives access to premium features such as event creation in the Apple Invites app, as well as Private Relay, Hide My Email, custom email domains, and HomeKit Secure Video. With Family Sharing, users can share their subscription with five other family members at no extra cost.


                 
             
                 
Customers who purchase iPhone Air may receive three free months of Apple Arcade, Apple Fitness+, Apple Music, Apple News+, and Apple TV+ with a new subscription. Offer and services availability varies by region. See apple.com/promo for details.


                 
             
         
 

    
    
    




    
    
        
    


    
    
    


		
		
        
			
				
				
					Text of this article
					
				
			
			
                
                
                    Media in this article
                    
                
            

        
    

    
    
    




    




    
    
    





    
    
    
            
The display has rounded corners that follow a beautiful curved design, and these corners are within a standard rectangle. When measured as a standard rectangular shape, the screen is 6.55 inches diagonally. The actual viewable area is smaller.
Visual intelligence is available on any Apple Intelligence-enabled iPhone. Some capabilities may not be available in all languages and regions. For more details, see support.apple.com/en-us/121115#visual-intelligence.
The new Bright Photographic Style will be available in iOS 26 on iPhone 16, iPhone 16 Plus, iPhone 16 Pro, iPhone 16 Pro Max, iPhone 17, iPhone Air, iPhone 17 Pro, and iPhone 17 Pro Max.
Use of an eSIM requires a carrier that supports eSIM and a wireless service plan. See carrier for details. To learn more, visit apple.com/esim.
Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified). Live Translation in Phone and FaceTime is available for one-on-one calls in English (U.S., UK), French (France), German, Portuguese (Brazil), and Spanish (Spain).
Financing available to qualified customers, subject to credit approval and credit limit, and requires users to select Citizens One Apple iPhone Payments or Apple Card Monthly Installments (ACMI) as their payment type at checkout at Apple. They’ll need to select AT&T, Boost Mobile, T‑Mobile, or Verizon as their carrier when they check out. An iPhone purchased with ACMI is always unlocked, so they can switch carriers at any time, subject to their carrier’s terms. Taxes and shipping on items purchased using ACMI are subject to their card’s variable APR, not the ACMI 0 percent APR. ACMI is not available for purchases made online at special storefronts. The last month’s payment for each product will be the product’s purchase price, less all other payments at the monthly payment amount. ACMI financing is subject to change at any time for any reason, including but not limited to, installment term lengths and eligible products. See the Apple Card Customer Agreement for more information about ACMI. Additional Citizens One Apple iPhone Payments terms are available at apple.com/legal/sales-support/iphoneinstallments_us.
Trade-in values will vary based on the condition, year, and configuration of the eligible trade-in device.
The 40W Dynamic Power Adapter with 60W Max will be available in Canada, China mainland, Japan, Mexico, Taiwan, the Philippines, and the U.S.


        



    
    
    






    















	

		
		
			
























		
		











	

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Tomorrow's emoji today: Unicode 17.0]]></title>
            <link>https://jenniferdaniel.substack.com/p/tomorrows-emoji-today-unicode-170</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45185875</guid>
        </item>
        <item>
            <title><![CDATA[E-paper display reaches the realm of LCD screens]]></title>
            <link>https://spectrum.ieee.org/e-paper-display-modos</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45185756</guid>
            <description><![CDATA[E-Paper displays just got faster with Modos' 75 Hz refresh rate. How did they achieve it?]]></description>
            <content:encoded><![CDATA[E-paper displays are prized for their readability and low power use, but they’ve long been dismissed as too slow for everyday computing. Modos, a two-person startup with open-hardware roots, thinks it has cracked part of that problem with a development kit capable of driving an e-paper display at refresh rates up to a record 75 hertz.The Modos Paper Monitor and Dev Kit, now available for crowdfunding on Crowd Supply, combines standard e-paper panels with an open source FPGA-based display controller. While the kit provides enthusiasts and developers a complete package (with e-paper display, display driver, and hardware adapter), it’s also an entry point for experimenting with different e-paper displays.RELATED: How E Ink Developed Full-Color E-paper“I would say instead of our secret sauce, we have open sauce,” says cofounder Alexander Soto. “You don’t even need to use the panel we’re offering. You could use a different panel and still get [75 Hz].”E-paper at 75 HzMost e-paper panels update at a refresh rate of around 10 Hz or less. (E-paper is the generic term for screens that mimic the appearance of ink on paper—the most well-known brand being that made by the company E Ink.) Some displays don’t even quote a refresh rate and may require up to a full second to refresh. A better refresh rate means a display can show more frames each second, which in turn provides smoother, more lifelike motion. Modern digital video is usually delivered at 30 or 60 frames per second, which until recently was well beyond the reach of an e-paper display. This is an area where e-paper clearly lags LCD displays, which start at 60 Hz and go up from there.Modos is able to hit refresh rates of up to 75 Hz on a 13-inch e-paper panel with a 1,600 by 1,200 resolution. (a 6-inch e-paper panel with 1,448 by 1,072 resolution and the same refresh rate is available, too.) Bumping the refresh rate also reduces latency. That’s a key point, as it allows an e-paper display to be used in situations where latency matters, such as a computer or tablet display.“A lot of people default to thinking that with e-readers or e-paper, it’s slow, it’s going to be flashing all the time,” says Soto. “Our challenge has been going to conferences, going to events, and showing people…e-paper can be very fast.” Open Source E-Paper Display ControllerModos’s quoted 75-Hz refresh rate is the highest yet for an e-paper display, but it’s arguably not the key innovation. Several competitors already offer e-paper displays with refresh rates up to 60 Hz which, though lower, is close. But Modos has a not-so-secret weapon: Caster, an open-source e-paper display controller that’s compatible with a wide variety of e-paper panels. The display controller, which is based on the AMD Spartan-6 FPGA, departs from typical e-paper controllers with pixel-level display management. “Traditionally, the [e-paper display] controller used a single-state machine to control the entire panel, with only two states: static and updating,” says Modos cofounder Wenting Zhang. “Caster treats each pixel individually rather than as a whole panel, which allows localized control on the pixels.”The FPGA display controller is paired with Modos’s Glider Mega Adapter, which includes four different display connectors compatible with several dozen e-paper displays ranging in size from 4.3 to 13 inches. Soto says the adapter can be used to repurpose displays salvaged from older e-readers, like Amazon’s Kindle.  A 75-Hz refresh rate allows for smoother scrolling. Modos Modos also provides an application programming interface (API), written in the C programming language, that lets applications select display-driving modes dynamically. As the video above shows, a Linux window manager can be used to render text in a low-latency binary color mode, display maps in more detailed yet responsive gray scale, and display video with maximum-fidelity gray scale—all simultaneously on the same screen. The code and schematics for Caster, Glider, and the API are open source and available on Github. Crowdfunding for E-paper InnovationModos’s crowdfunding campaign is set to conclude on 18 September. Orders are expected to ship in January of 2026, although (as is often the case for crowdfunded projects) the shipping window is not guaranteed. Getting to this stage has taken several years. The company’s founders initially hoped to build an e-paper laptop, the Modos Paper Laptop, which was announced in January of 2022. However, the realities of electronics manufacturing complicated that project early in its life and the laptop was never made available to order. “Part of it was that the primary aspect ratio for the majority of [laptop] chassises are for 16:9 and 16:10. And when you look at e-paper displays, it was an aspect ratio of 4:3. So, we either had to make a custom chassis, or a custom panel, both of them being prohibitively expensive,” says Soto.Panel sourcing also remains a hurdle. E-paper’s production is geared toward e-readers and signage, which means most panels aren’t the right size for a computer. However, the Modos Paper Monitor and Dev Kit found a practical compromise in recently introduced 13-inch e-paper displays, many of which provide a resolution similar to LCD and OLED panels developed for laptops. In this way, the Dev Kit is a continuation of Modos’s original goal. While building a full-fledged e-paper laptop was impractical, the Dev Kit’s high refresh rate, open-source display controller, and API give ambitious users the opportunity to implement their own low-latency e-paper computer display—or anything else they put their mind to.This article was updated on 8 September 2025 to replace mentions of “E Ink” (the specific e-paper technology developed by the company of the same name) with “e-paper.”]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Building a DOOM-like multiplayer shooter in pure SQL]]></title>
            <link>https://cedardb.com/blog/doomql/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183050</guid>
            <description><![CDATA[CedarDB is a database system that delivers unmatched performance for transactions and analytics, from small writes to handling billions of rows. Built on cutting-edge research to power today’s tools and tomorrow’s challenges.]]></description>
            <content:encoded><![CDATA[September 8, 2025 • 12 minutesDOOMQL: A DOOM-like multiplayer shooter in pure SQLI recently stumbled across Patrick’s excellent DOOM clone running in a browser powered by DuckDB-WASM.
Ever since I’ve read that, I wanted to push his awesome idea to the logical extreme: Build a multiplayer DOOM-like shooter entirely in SQL with CedarDB doing all the heavy lifting.
During a month of parental leave (i.e., a lot of sleepless nights), I tried exactly that.Here’s a sneak peek at DOOMQL:
Your browser does not support the video tag.DOOMQL in actionOkay, with the flashy demo out of the way, let’s talk about details.
What follows is a tour of the architecture, the SQL rendering pipeline, the game loop, and the fun metagame of cheating by issuing SQL commands against the database.Why even do this?Playing DuckDB DOOM in your browser is fun, but some things bugged me:
First of all, having parts of the rendering pipeline in Javascript felt like cheating. It worked well for DuckDB-Doom where everything is contained in a single HTML page, but I wanted to see if I could do everything in SQL. DuckDB-Doom is also a little bit stuttery with just 8 frames per second and has a pretty tiny viewport. I wanted to see if I could speed that up by switching over to CedarDB. I also wanted real sprites with transparency and they should move around believably in 3D space.
And most importantly, making the game multi-player should not just be possible, but easy, right? I got nerd-sniped by the perceived similarity of a database server to a traditional game server: Databases exist to synchronize shared state across clients. Thanks to transaction isolation, each player has a consistent view of the game world, no matter what the other clients are doing. Why not lean into that?
I would love to lie to you and claim I did it all to push CedarDB as an awesome database system but to be honest the database nerd in me just wanted to turn all knobs up to 11 and see what breaks.Architectural overviewAt a high levelState lives in tables (map, players, mobs, inputs, configs, sprites, …)Rendering is a stack of SQL views that implement raycasting and sprite projectionThe game loop is a tiny shell script that executes a SQL file ~ 30 times per second.The client is ~ 150 lines of Python: It polls for input and queries the database for your 3D view.You can play, observe other players and even cheat (by sending raw SQL).Game state, or: Let’s store everything in the databaseWith a database at hand, it’s natural to store all game configuration, state, and static data in the database:Config:CREATE TABLE config(
  player_move_speed NUMERIC DEFAULT 0.3, 
  player_turn_speed NUMERIC DEFAULT 0.2,
  ammo_max INT DEFAULT 10,
  ammo_refill_interval_seconds INT DEFAULT 2
  );
Map:CREATE TABLE map(x INT, y INT, tile CHAR);
Players and inputs:CREATE TABLE players (
  id INT REFERENCES mobs(id),
  score INT DEFAULT 0,
  hp INT DEFAULT 100,
  ammo INT DEFAULT 10,
  last_ammo_refill int default EXTRACT(EPOCH FROM (now()))::INT
);

CREATE TABLE inputs(
  player_id INT PRIMARY KEY REFERENCES players(id),
  action CHAR(1), -- 'w', 'a', 's', 'd', 'x' for shooting
  timestamp TIMESTAMP DEFAULT NOW()
);
Because everything is data, modding a running match is trivial:-- Change a setting
update config set ammo_max = 20;

 -- Add a player
insert into players values (...);

-- Move forward
update input set action = 'w' where player_id = <your_id>;

 -- Cheat (pls be smarter about it)
update players set hp = 100000 where player_id = <your_id>;

-- Ban cheaters (that weren't smart about it)
delete from players where hp > 100;
Renderer: When a VIEW becomes your 3D viewIf you squint enough, in DOOM, a 3D (or more correct: 2.5D) view is just a view over 2D state (i.e., the level map and any players/enemies on it).
Well, we’ve got VIEWS in SQL as well. They’re also just views on our (2D) state tables.
What’s stopping us from quite literally building a 3D “view” of our 2D map
using a simple raycasting algorithm?The pipeline:Send a set of rays from each player’s eye into the world, and see which map tiles are visibleCheck which walls the player sees, rendering them at the correct height and more or less solid based on the distanceProject mobs into the player’s camera spaceSelect sprite LODs based on depthExpand sprites into pixels, scaled to screen spaceOcclude against walls and other spritesAssemble frame buffer rows with string_aggBuild a minimap reusing the visible tiles calculation from earlierCombine the 3D view with minimap and HUD (HP/bullets/players) into a game viewLet’s take a more in-depth look at steps 2, 7, and 8.RaycastingThe recursive ray‑marching logic is adapted from Patrick’s DuckDB DOOM post. Here is a simplified excerpt, adapted for multiplayer:CREATE OR REPLACE VIEW visible_tiles AS  
WITH RECURSIVE raytrace AS (  
  -- Starting at the player's eye ...
  SELECT r.player_id, r.col, 1 AS step_count,  
         r.player_x + COS(r.angle)*s.step AS fx,  
         r.player_y + SIN(r.angle)*s.step AS fy,  
         r.angle, 0 AS dist  
  FROM rays r, settings s  -- rays are built in an earlier step
  UNION ALL  
  -- ... we recursively march along the rays, 1 "step" at a time ...
  SELECT rt.player_id, rt.col, rt.step_count + 1,  
         rt.fx + COS(rt.angle)*s.step,  
         rt.fy + SIN(rt.angle)*s.step,  
         rt.angle,  
         step_count * s.step * COS(rt.angle - m.dir) AS dist  
  FROM raytrace rt, settings s, players p, mobs m  
  WHERE rt.step_count < s.max_steps   -- ... stopping after our max render distance
    AND rt.player_id = p.id  
    AND m.id = p.id  
    AND NOT EXISTS (  -- or if we hit a wall
      SELECT 1 FROM map m  
      WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  
        AND m.tile = '#')  -- wall
)  
-- We then determine per player:
--  a) which tiles we hit
--  b) how far away these tiles are
--  c) the column of the screen each tile should correspond to
SELECT player_id, tile, CAST(fx AS INT) AS tile_x, CAST(fy AS INT) AS tile_y, col, MIN(dist) AS dist  
FROM raytrace rt, map m  
WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  -- We might hit the same tile multiple times, so we take the closest hit
GROUP BY player_id, tile_x, tile_y, tile, col;  
And that’s just the first step in the pipeline. For the rest, take a look at the code.Final frame assemblyAfter all the heavy lifting, the payoff is surprisingly simple:SELECT player_id, y, string_agg(ch, '' ORDER BY x) AS row  
FROM framebuffer  
GROUP BY player_id, y;  
This glues together character pixels into text rows.HUD + minimapThe same trick builds the HUD and minimap. Here is the health bar:'HP: [' ||
repeat('█', LEAST(20, ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
repeat(' ', GREATEST(0, 20 - ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
'] ' || GREATEST(0, p.hp)
Add ammo dots with repeat('•', p.ammo) and you’ve got a HUD entirely in SQL: 1: Lukas      (L) score: 1   HP: [█████████           ] 50    AMMO: ••••••••••
 2: Foobar     (F) score: 0   HP: [████████████████████] 100   AMMO: ••••••••  
We can also re-use our earlier visible_tiles view to build a minimap with a view cone:select * from minimap where player_id = 1 order by y;

 player_id | y  |                               row                                
-----------+----+------------------------------------------------------------------
         1 |  0 | ################################################################
         1 |  1 | ################################################################
         1 |  2 | ##.......      #####               #############################
         1 |  3 | ##.....F.      #####               #####                     ###
         1 |  4 | ##.......      #####               #####                     ###
         1 |  5 | ##  .....      #####               #####                     ###
         1 |  6 | ##   ...                                                     ###
         1 |  7 | ##    .L                                                     ###
         1 |  8 | ##             #####               #####                     ###
         1 |  9 | ##             #####               #####                     ###
         1 | 10 | ##             #############  ##########                     ###
         1 | 11 | ##########  ################  ##########                     ###
         1 | 12 | ##########  ################  ##########                     ###
         1 | 13 | ##########  ################  ######################  ##########
         1 | 14 | ####                 #######  ######################  ##########
         1 | 15 | ####                 #######  ######################  ##########
         1 | 16 | ####                 #####             #####                 ###
         1 | 17 | ####                 #####             #####                 ###
         1 | 18 | ####                 #####             #####                 ###
         1 | 19 | ####                 #####             #####                 ###
         1 | 20 | ####                 #####             #####                 ###
         1 | 21 | ####                                   #####                 ###
         1 | 22 | ####                                                         ###
         1 | 23 | ####                 #####                                   ###
         1 | 24 | ####                 #####             #####                 ###
         1 | 25 | ####                 #####             #####                 ###
         1 | 26 | ####                 #####             #####                 ###
         1 | 27 | ####                 #####             #####                 ###
         1 | 28 | ####                 #####             #####                 ###
         1 | 29 | ################################################################
         1 | 30 | ################################################################
         1 | 31 | ################################################################
The surprisingly elegant game loopThe loop is just a shell script running raw SQL against the database:# Game loop @ 30 ticks per second
while true; do
  psql -qtAX -U "$DB_USER" -d "$DB_NAME" -h "$DB_HOST" -p "$DB_PORT" -f gameloop.sql
  sleep 0.03
done
Inside gameloop.sql, actions like bullet movement, collisions, kills, and respawns run in a single transaction, which keeps state consistent even if something fails mid-tick.Here’s the part processing interactions with bullets:-- Process all bullets
BEGIN TRANSACTION;

-- Move bullets forward
UPDATE mobs 
SET x = x + cos(dir) * 0.5, y = y + sin(dir) * 0.5 
WHERE kind = 'bullet';

-- Delete bullets that are out of bounds
DELETE FROM mobs 
WHERE (x < 0 
OR x >= (select max(x) from map) 
OR y < 0 
OR y >= (select max(y) from map))
AND kind = 'bullet';

-- Delete bullets that hit walls
DELETE FROM mobs b 
WHERE EXISTS 
    (SELECT 1 
    FROM map m 
    WHERE m.x = CAST(b.x AS INT) 
    AND m.y = CAST(b.y AS INT) 
    AND m.tile = '#') 
AND kind = 'bullet';


-- Players hit by a bullet loses 50 HP
UPDATE players p SET hp = hp - 50
FROM collisions c
WHERE p.id = c.player_id;

-- If a player has 0 or less HP, the player killing them gets a point
UPDATE players p SET score = score + 1
FROM collisions c
WHERE p.id = c.bullet_owner
AND EXISTS (SELECT 1 FROM players p2 WHERE p2.id = c.player_id AND p2.hp <= 0);

-- Delete bullets that hit players
DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id;

-- Respawn players whose HP is 0 or less
UPDATE mobs m
SET x = r.x, y = r.y, dir = 0
FROM players p
CROSS JOIN (
  SELECT x, y
  FROM map
  WHERE tile = 'R'
  ORDER BY random()
  LIMIT 1
) AS r
WHERE m.id = p.id
  AND p.hp <= 0;

-- Reset players' HP to 100 and ammo to 10 after respawn
UPDATE players p SET
  hp = 100,
  ammo = 10
FROM mobs m
WHERE p.id = m.id
AND p.hp <= 0;

COMMIT;
On my machine, the game loop takes about 1 ms, so we could defintely improve the tick rate.
That might be a way to get the Counterstrike snobs who scoff at everything below 128 Hz.
It would require some refactoring on my part since I tied the movement speed to the game loop - a big no no in game design!While only someone insane could think a pure SQL raycasting renderer is a good idea in an actual game, I’ll happily defend this transactional game loop.
I don’t think this part would be much more concise or less brittle in a real game engine.Make it multiplayer in two queriesThe game client’s job description is simple:RenderSELECT full_row FROM screen WHERE player_id = <your_id> ORDER BY y
Send inputINSERT INTO inputs(player_id, action)
    VALUES (<your_id>, <pressed_key>)
    ON CONFLICT(player_id)
    DO UPDATE SET action = EXCLUDED.action
The game loop periodically checks the input table and moves all players accordingly - inside a transaction, of course, so we don’t run into any race conditions.That’s it (well, plus a one-time “create player” on first connect). The ~150 lines of Python in the client mostly handle keyboard input and reducing terminal flicker.
Bonus: The client provides an observer mode. All it has to do is swap the <player_id> in the render call.PerformanceAt 128 x 64 pixels, a single player view takes ~33 ms on my machine, which is enough for a breezy ~30 FPS, compared to DuckDB DOOM’s 8 FPS at just 32 x 16 pixels.
I’m actually quite proud of that performance and quite happy with CedarDB here.
I don’t think any other database system can keep up with that.
Let me know if you find one!You might worry that rendering the views of all players and filtering late would be very wasteful.
CedarDB’s query optimizer pushes the where player_id = <...> predicate through view boundaries, avoiding unncessary work.
You can easily check by running:select * from screen order by y; -- render both users
-- Time: 57,907 ms (~2x single player 33ms)
Because clients send raw SQL as superusers (I didn’t bother setting up any role based access control or row level security, don’t do that!), there’s an emergent metagame: Cheat creatively and try not to get caught.Low effort:update players set score = 0 where id != <your_id>;
update players set hp = 0 where id != <your_id>;
Mischievous:update inputs set action = null where player_id != <your_id>;
Steal kills:update mobs set owner = <your_id> where kind = 'bullet';
Attempted but didn’t work:DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id AND c.player_id = <your_id>;
This doesn’t work because moving bullets, checking for collisions, and respawn happens in the same transaction.
As transactions are atomic, you either see everything being applied at once, or nothing. By the time you see the hit, you’re already dead.
A property that’s very useful for database systems (and not just to prevent cheating).What I learnedI set out to see if I could push Patrick’s demo to an extreme: Doing the entire rendering pipeline in SQL.
And while it works, I have to admit that it is a pretty… bad idea? Fast enough, but horrible to maintain and debug.The surprise was how natural it felt to express game state and logic in SQL.
It even felt like accidentally re-invented the entity-component-system pattern.And multiplayer “just worked” because the database system which handles all the nasty concurrency is the source of truth.Try it yourself!All the code is on Github: DOOMQL RepoRun:docker pull cedardb/cedardb:latest
docker run --rm -p 5432:5432 -e CEDAR_PASSWORD=postgres --detach cedardb/cedardb:latest
# Wait a few seconds for CedarDB to start
./server.sh

# in a second terminal window, zoom way out to have no line wraping issues
python3 pyclient.py
Want to discuss DOOMQL with me or find like-minded database nerds? Join our Community Slack]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[We all dodged a bullet]]></title>
            <link>https://xeiaso.net/notes/2025/we-dodged-a-bullet/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183029</guid>
            <description><![CDATA[That NPM attack could have been so much worse.]]></description>
            <content:encoded><![CDATA[ Loading...Please wait a moment while we ensure the security of your connection.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[US High school students' scores fall in reading and math]]></title>
            <link>https://apnews.com/article/naep-reading-math-scores-12th-grade-c18d6e3fbc125f12948cc70cb85a520a</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182657</guid>
            <description><![CDATA[A decade-long slide in high school students’ performance in reading and math persisted during the COVID-19 pandemic, with 12th graders’ scores dropping to their lowest level in more than 20 years. That's according to results released Tuesday from an exam known as the nation’s report card. Eighth-grade students also lost significant ground in science skills, according to the results from the National Assessment of Education Progress. The assessments were the first since the pandemic for eighth graders in science and 12th graders in reading and math. They reflect a downward drift across grade levels and subject areas in previous releases from NAEP.]]></description>
            <content:encoded><![CDATA[
                                        WASHINGTON (AP) — A decade-long slide in high schoolers’ reading and math performance persisted during the COVID-19 pandemic, with 12th graders’ scores dropping to their lowest level in more than 20 years, according to results released Tuesday from an exam known as the nation’s report card.Eighth-grade students also lost significant ground in science skills, according to the results from the National Assessment of Education Progress.The assessments were the first since the pandemic for eighth graders in science and 12th graders in reading and math. They reflect a downward drift across grade levels and subject areas in previous releases from NAEP, which is considered one of the best gauges of the academic progress of U.S. schools.“Scores for our lowest-performing students are at historic lows,” said Matthew Soldner, the acting commissioner of the National Center for Education Statistics. “These results should galvanize all of us to take concerted and focused action to accelerate student learning.”
    
While the pandemic had an outsize impact on student achievement, experts said falling scores are part of a longer arc in education that cannot be attributed solely to COVID-19, school closures and related issues such as heightened absenteeism. Educators said potential underlying factors include children’s increased screen time, shortened attention spans and a decline in reading longer-form writing both in and out of school.



The dip in reading scores appeared alongside a shift in how English and language arts are taught in schools, with an emphasis on short texts and book excerpts, said Carol Jago, associate director of the California Reading and Literature Project at UCLA. As a high school English teacher 20 years ago, Jago said it was common for her high school students to read 20 books over the course of a year. Now, some English classes are assigning just three books a year.
    
    
    
“To be a good reader, you have to have the stamina to stay on the page, even when the going gets tough,” Jago said. “You have to build those muscles, and we’re not building those muscles in kids.”
    
    
    

    
Education Secretary Linda McMahon said the scores show why the Trump administration wants to give states more control of education spending.“Despite spending billions annually on numerous K-12 programs, the achievement gap is widening, and more high school seniors are performing below the basic benchmark in math and reading than ever before,” McMahon said.House Democrats said the Trump administration’s efforts to dismantle the Education Department will only hurt students. The declines show a need for federal investment in academic recovery and educational equity, said Democratic Rep. Bobby Scott of Virginia, ranking member of the House Committee on Education and Workforce.“Eliminating the very agency responsible for supporting public schools and enforcing civil rights protections of students will only deepen the achievement gaps identified by this assessment,” Scott said.
    
Fewer students show basic proficiency in math and readingThe test scores show more students are not reaching what would be considered “basic” achievement across subject areas, said Lesley Muldoon, executive director of the National Assessment Governing Board. While NAEP’s definition of “proficient” is a high bar, Muldoon said, it is not an unreasonable one, and it is based on what researchers believe students should be able to achieve by the end of high school.“These students are taking their next steps in life with fewer skills and less knowledge in core academics than their predecessors a decade ago,” she said. “This is happening at a time when rapid advancements in technology and society demands more of future workers and citizens, not less.”In reading, the average score in 2024 was the lowest score in the history of the assessment, which began in 1992. Thirty-two percent of high school seniors scored below “basic,” meaning they were not able to find details in a text to help them understand its meaning.In math, the average score in 2024 was the lowest since 2005, when the assessment framework changed significantly. On the test, 45% of high school seniors scored below “basic” achievement, the highest percentage since 2005. Only 33% of high school seniors were considered academically prepared for college-level math courses, a decline from 37% in 2019.
    
The high school reading and math assessments, and the eighth grade science test, are given less frequently than the biannual fourth and eighth grade reading tests, which were last released earlier this year. The new scores reflect tests taken in schools around the country between January and March 2024.
    
Achievement gaps are wideningThe gap between the highest- and lowest-performing students was its widest ever among eighth grade science students, reflecting growing inequality in the American school system. The achievement gap widened also in 12th grade math.The scores also reflect the re-emergence of a gender gap in science, technology, engineering and math courses. In 2019, boys and girls scored virtually the same on the NAEP science assessment. But in 2024, girls saw a steeper decline in scores. A similar pattern occurred in state math assessments, according to an Associated Press analysis.Schools had largely closed the gender gap in math and science, but it widened in the years following the pandemic as special programs to engage girls lapsed.On a NAEP survey of students, a shrinking percentage of eighth grade students said they regularly took part in inquiry-based learning activities in the classroom. The pandemic disrupted schools’ ability to create those hands-on learning experiences for students, which are often critical to understanding scientific concepts and processes, said Christine Cunningham, senior vice president of STEM learning at the Museum of Science in Boston.Still, she noted declines across subjects began well before schools closed in 2020.“We don’t know exactly what the cause of it is, but it would be incomplete to assume that if we hadn’t had COVID, the score would not have gone down,” Cunningham said. “That’s not what the data showed even before the pandemic.” ___Feathers reported from New York.___The Associated Press’ education coverage receives financial support from multiple private foundations. AP is solely responsible for all content. Find AP’s standards for working with philanthropies, a list of supporters and funded coverage areas at AP.org.
                                    ]]></content:encoded>
        </item>
    </channel>
</rss>