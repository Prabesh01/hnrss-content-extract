<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Tue, 09 Sep 2025 18:41:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Memory Integrity Enforcement]]></title>
            <link>https://security.apple.com/blog/memory-integrity-enforcement/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186265</guid>
            <description><![CDATA[Memory Integrity Enforcement (MIE) is the culmination of an unprecedented design and engineering effort spanning half a decade that combines the unique strengths of Apple silicon hardware with our advanced operating system security to provide industry-first, always-on memory safety protection across our devices â€” without compromising our best-in-class device performance. We believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.]]></description>
            <content:encoded><![CDATA[Memory Integrity Enforcement (MIE) is the culmination of an unprecedented design and engineering effort, spanning half a decade, that combines the unique strengths of Apple silicon hardware with our advanced operating system security to provide industry-first, always-on memory safety protection across our devices â€” without compromising our best-in-class device performance. We believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.

There has never been a successful, widespread malware attack against iPhone. The only system-level iOS attacks we observe in the wild come from mercenary spyware, which is vastly more complex than regular cybercriminal activity and consumer malware. Mercenary spyware is historically associated with state actors and uses exploit chains that cost millions of dollars to target a very small number of specific individuals and their devices. Although the vast majority of users will never be targeted in this way, these exploit chains demonstrate some of the most expensive, complex, and advanced attacker capabilities at any given time and are uniquely deserving of study as we work to protect iPhone users against even the most sophisticated threats. Known mercenary spyware chains used against iOS share a common denominator with those targeting Windows and Android: they exploit memory safety vulnerabilities, which are interchangeable, powerful, and exist throughout the industry.
For Apple, improving memory safety is a broad effort that includes developing with safe languages and deploying mitigations at scale. (For a primer on how we think about memory safety, see the opening of this post.) We created Swift, an easy-to-use, memory-safe language, which we employ for new code and targeted component rewrites. In iOS 15, we introduced kalloc_type, a secure memory allocator for the kernel, followed in iOS 17 by its user-level counterpart, xzone malloc. These secure allocators take advantage of knowing the type â€” or purpose â€” of allocations so that memory can be organized in a way that makes exploiting most memory corruption vulnerabilities inherently difficult.
In 2018, we were the first in the industry to deploy Pointer Authentication Codes (PAC) in the A12 Bionic chip, to protect code flow integrity in the presence of memory corruption. The strong success of this defensive mechanism in increasing exploitation complexity left no doubt that the deep integration of software and hardware security would be key to addressing some of our greatest security challenges. With PAC behind us, we immediately began design and evaluation work to find the most effective way to build sophisticated memory safety capabilities right into Apple silicon.
Arm published the Memory Tagging Extension (MTE) specification in 2019 as a tool for hardware to help find memory corruption bugs. MTE is, at its core, a memory tagging and tag-checking system, where every memory allocation is tagged with a secret; the hardware guarantees that later requests to access memory are granted only if the request contains the correct secret. If the secrets donâ€™t match, the app crashes, and the event is logged. This allows developers to identify memory corruption bugs immediately as they occur.
We conducted a deep evaluation and research process to determine whether MTE, as designed, would meet our goals for hardware-assisted memory safety. Our analysis found that, when employed as a real-time defensive measure, the original Arm MTE release exhibited weaknesses that were unacceptable to us, and we worked with Arm to address these shortcomings in the new Enhanced Memory Tagging Extension (EMTE) specification, released in 2022. More importantly, our analysis showed that while EMTE had great potential as specified, a rigorous implementation with deep hardware and operating system support could be a breakthrough that produces an extraordinary new security mechanism.
Consider that MTE can be configured to report memory corruption either synchronously or asynchronously. In the latter mode, memory corruption doesnâ€™t immediately raise an exception, leaving a race window open for attackers. We would not implement such a mechanism. We believe memory safety protections need to be strictly synchronous, on by default, and working continuously. But supporting always-on, synchronous MTE across key attack surfaces while preserving a great, high-performance user experience is extremely demanding for hardware to support.
In addition, for MTE to provide memory safety in an adversarial context, we would need to finely tune the operating system to defend the new semantics and the confidentiality of memory tags on which MTE relies. Ultimately, we determined that to deliver truly best-in-class memory safety, we would carry out a massive engineering effort spanning all of Apple â€” including updates to Apple silicon, our operating systems, and our software frameworks. This effort, together with our highly successful secure memory allocator work, would transform MTE from a helpful debugging tool into a groundbreaking new security feature.
Today weâ€™re introducing the culmination of this effort: Memory Integrity Enforcement (MIE), our comprehensive memory safety defense for Apple platforms. Memory Integrity Enforcement is built on the robust foundation provided by our secure memory allocators, coupled with Enhanced Memory Tagging Extension (EMTE) in synchronous mode, and supported by extensive Tag Confidentiality Enforcement policies. MIE is built right into Apple hardware and software in all models of iPhone 17 and iPhone Air and offers unparalleled, always-on memory safety protection for our key attack surfaces including the kernel, while maintaining the power and performance that users expect. In addition, weâ€™re making EMTE available to all Apple developers in Xcode as part of the new Enhanced Security feature that we released earlier this year during WWDC.
The rest of this post dives into the intensive engineering effort required to design and validate Memory Integrity Enforcement.
Designing Memory Integrity Enforcement
Memory Integrity Enforcement starts with our secure memory allocators â€” kalloc_type, xzone malloc, and WebKitâ€™s libpas â€” all of which use type information to decide how to organize memory allocations. With both use-after-free and out-of-bounds bugs, an attackerâ€™s goal is to create overlapping interpretations of memory, which they achieve by controlling the precise position of certain allocations â€” of a specific type â€” that is advantageous to them. The type-aware placement policies of our secure memory allocators help thwart these memory corruption techniques, as we described in our kalloc_type post. Our secure allocators set a new high-water mark of software protection against memory corruption, while preserving the same or better performance as the allocators they replaced.
Allocators can apply protections only at the granularity of memory pages â€” 16KB on iOS â€” which is a natural fit for multi-page allocations. For smaller allocations, our secure allocators can use page-level protections to help prevent memory corruption attacks across different type buckets. However, page-level protections are too coarse to defend against attacks within the same type bucket, and we use memory tagging to close this gap.
Letâ€™s look at how EMTE can be used to protect against two of the most common types of memory corruption: buffer overflows and use-after-free vulnerabilities. For buffer overflows, the allocator is responsible for using different tags for neighboring allocations. If a request to access memory spills over to adjacent memory that has a different tag, the hardware blocks it, and the operating system can take action and terminate the process. We represent this visually below with three adjacent allocations, tagged with three different secrets: âºï¸, ðŸ”¼, and â¹ï¸. Two access attempts with the ðŸ”¼ tag are permitted to ðŸ”¼-tagged memory, but the third attempt is blocked as it spills over into the adjacent, â¹ï¸-tagged allocation.
 Memory Integrity Enforcement blocks buffer overflows 

The allocator is also responsible for retagging memory as it gets reused for other purposes. In the image below, the ðŸ”¼ allocation is retagged as â¹ï¸ after it has been freed and reallocated by the system. If a request to the retagged memory is made with the older ðŸ”¼ tag, as would be seen in use-after-free exploits, the hardware blocks it and lets the operating system take further action.
 Memory Integrity Enforcement blocks use-after-free access

A key weakness of the original MTE specification is that access to non-tagged memory, such as global variables, is not checked by the hardware. This means attackers donâ€™t have to face as many defensive constraints when attempting to control core application configuration and state. With Enhanced MTE, we instead specify that accessing non-tagged memory from a tagged memory region requires knowing that regionâ€™s tag, making it significantly harder for attackers to turn out-of-bounds bugs in dynamic tagged memory into a way to sidestep EMTE by directly modifying non-tagged allocations.
Finally, we developed Tag Confidentiality Enforcement to protect the implementation of our secure allocators from technical threats and to guard the confidentiality of EMTE tags â€” including against side-channel and speculative-execution attacks.
Our typed allocators and EMTE both rely on confidentiality of kernel data structures from user applications, and of the tags chosen by the allocator. Attackers might attempt to defeat EMTE, and in turn Memory Integrity Enforcement, by revealing these secrets. To protect the kernel allocator backing store and tag storage, we use the Secure Page Table Monitor, which provides strong guarantees even in the presence of a kernel compromise. We also ensure that when the kernel accesses memory on behalf of an application, it's subject to the same tag-checking rules as userspace.
Attacks based on speculative execution can also be used to expose secrets. To improve performance, modern CPUs predict the execution of instructions that follow prior, potentially longer latency instructions. If the prediction is correct, computation is very fast. If itâ€™s wrong, the CPU discards the prediction, and computation is slower. Unfortunately, discarded predictions have observable effects that can reveal system state and data, and because speculative attacks never cause the system to crash or misbehave in observable ways during their use, theyâ€™re particularly useful for an attacker. For example, evaluating a pointer authentication instruction speculatively exposed timing differences in our original implementation of Pointer Authentication Codes (PAC), which would allow the valid signature to be isolated. During the design phase for Memory Integrity Enforcement, we identified and addressed the three speculative vulnerabilities that could undermine tag confidentiality.
First, when EMTE is active, requests to access memory cause the hardware to check tags. It's crucial that evaluating a tag-checking instruction speculatively doesnâ€™t expose timing differences that would allow an attacker to isolate the valid tag. From the start, we designed the Apple silicon implementation so that tag values canâ€™t influence speculative execution in any way. Recently published security research demonstrates that the MTE implementation on Googleâ€™s Pixel devices is vulnerable to this type of attack, allowing MTE to be bypassed in Google Chrome and the Linux kernel.
Second, allocators assign random tags to memory, and attackers must not be able to predict tag values that the system will choose. We address this issue by frequently re-seeding the underlying pseudo-random generator used to select new tags.
Third, Spectre variant 1 (V1) is a speculative-execution vulnerability that allows attackers to exploit conditional branches to leak data, including MTE tag values. To date, there has been no solution to this problem in consumer operating systems, because general Spectre V1 mitigations such as Speculative Load Hardening have a prohibitive CPU cost. The presence of EMTE leaves Spectre V1 as one of the last avenues available to attackers to help guide their attacks, so we designed a completely novel mitigation that limits the effective reach of Spectre V1 leaks â€” at virtually zero CPU cost â€” and forces attackers to contend with type segregation. This mitigation makes it impractical for attackers to use Spectre V1, as they would typically need 25 or more V1 sequences to reach more than 95 percent exploitability rate â€” unless one of these sequences is related to the bug being exploited, following similar reasoning as our kalloc_type analysis.
Our mission with Memory Integrity Enforcement is to protect all users by default and provide an extraordinary disruption to the exploitation of memory corruption vulnerabilities. To do so, we considered a wide set of threats, including some of the most challenging ones â€” such as side channels â€” and arrived at this extensive combination of features not present in other MTE implementations. Google took a great first step last year when they offered MTE to those who opt in to their program for at-risk users. But even for users who turn it on, the effectiveness of MTE on Android is limited by the lack of deep integration with the operating system that distinguishes Memory Integrity Enforcement and its use of EMTE on Apple silicon.
For the new A19 and A19 Pro chips to support Memory Integrity Enforcement, we dedicated an extraordinary amount of Apple silicon resources to security â€” more than ever before â€” including CPU area, CPU speed, and memory for tag storage. And to fully realize this hardware investment, we designed all of the new operating system elements of MIE jointly with our hardware work, including secure allocators, EMTE, and tag confidentiality protections.
Because EMTE tag checking imposes a performance cost, we designed Memory Integrity Enforcement to take advantage of our secure allocators first and use EMTE to protect only smaller individual allocations within a type bucket, which software allocators canâ€™t defend on their own. Then, by knowing where and how we would deploy EMTE, we could accurately model the tag-checking demand of the operating system, and design our silicon to satisfy it. Our hardware implementation influenced additional software design decisions, reducing the overhead of tag checks even further. Importantly, deploying EMTE with this level of precision supports our strategy to provide as many memory safety improvements as possible to users on previous iPhone generations, which donâ€™t support EMTE.
For the security evaluation of Memory Integrity Enforcement, we involved our offensive research team from the very beginning. From 2020 to 2025, they continuously analyzed and attacked the system â€” first conceptually, with theoretical exploitation avenues, then with practical attacks in simulated environments, and eventually on new hardware prototypes. Prolonged engagement from our offensive research team allowed us to identify and eradicate entire attack strategies and techniques before attackers could ever discover them, leading to a stronger, more mature feature from the outset.
Our offensive research team identified where and how attackers are most likely to break into the system, and our deployment of Memory Integrity Enforcement is deeply guided by their findings. Notably, this includes making sure that this powerful new protection is available to third-party apps that are likely entry points for attackers â€” such as social networks, messaging apps, or any other app where a specific user can be targeted. Starting immediately with the launch of MIE, any developer can begin testing this powerful protection for their app, including EMTE on hardware that supports it, using the Enhanced Security settings in Xcode.
The meticulous planning and implementation of Memory Integrity Enforcement made it possible to maintain synchronous tag checking for all the demanding workloads of our platforms, delivering groundbreaking security with minimal performance impact, while remaining completely invisible to users.
Security evaluation
Memory Integrity Enforcement started with a deeply ambitious goal: to make it immensely more expensive and difficult to develop and maintain mercenary spyware attacks based on memory corruption against our platforms. While thereâ€™s no such thing as perfect security, MIE is designed to dramatically constrain attackers and their degrees of freedom during exploitation.
Throughout the design and implementation of Memory Integrity Enforcement, our offensive research team evaluated our progress by looking at sophisticated exploit chains that were previously used against our platform, recent vulnerabilities, and our own internal research. First, we worked on rebuilding and adapting previously seen exploit chains to systems protected by MIE. But itâ€™s not sufficient to consider only previous chains that were developed before MIE existed, because attackers will surely adapt in reaction to these new protections. We therefore also evaluated a selection of more recent vulnerabilities that we expected would have the best chance of surviving MIE. For these, we meticulously enumerated all possible exploitation opportunities, similar to our evaluation of SockPuppet against kalloc_type.
Both approaches revealed the same conclusion: Memory Integrity Enforcement vastly reduces the exploitation strategies available to attackers. Though memory corruption bugs are usually interchangeable, MIE cut off so many exploit steps at a fundamental level that it was not possible to restore the chains by swapping in new bugs. Even with substantial effort, we could not rebuild any of these chains to work around MIE. The few memory corruption effects that remained are unreliable and donâ€™t give attackers sufficient momentum to successfully exploit these bugs.
Hereâ€™s a visual representation of what this looks like for an attacker. The chart below represents six of the real-world exploit chains that we evaluated and shows the steps where Memory Integrity Enforcement â€” the secure allocators, EMTE, or both â€” stops the attack.
 Memory Integrity Enforcement vs. real-world exploit chains

Notably, attackers confront Memory Integrity Enforcement early in the exploitation process. Although some issues are able to survive MIE â€” for example, intra-allocation buffer overflows â€” such issues are extremely rare, and even fewer will lend themselves to a full end-to-end exploit. Inevitably, attackers must face MIE at a stage where their capabilities are still very limited, leaving few viable avenues for exploitation. This leads to fragile chains where breaking just one step is often enough to invalidate the entire exploit strategy. When that happens, most of the chainâ€™s components canâ€™t be reused, and the attackers have to restart exploit development with entirely new bugs.
Conclusion
The industry-leading security of iPhone means that the vast majority of our users never face system-level attacks on their devices. Our work on memory safety is aimed primarily at the mercenary spyware and surveillance industry, which spends many millions of dollars to exploit memory corruption vulnerabilities and target a small number of individuals because of who they are and what they do. Over the past five years, we developed a comprehensive approach to memory safety that integrates the best of our hardware and software capabilities, and todayâ€™s announcement is the culmination of this ambitious vision. With the introduction of the iPhone 17 lineup and iPhone Air, weâ€™re excited to deliver Memory Integrity Enforcement: the industryâ€™s first ever, comprehensive, always-on memory-safety protection covering key attack surfaces â€” including the kernel and over 70 userland processes â€” built on the Enhanced Memory Tagging Extension (EMTE) and supported by secure typed allocators and tag confidentiality protections.
Based on our evaluations pitting Memory Integrity Enforcement against exceptionally sophisticated mercenary spyware attacks from the last three years, we believe MIE will make exploit chains significantly more expensive and difficult to develop and maintain, disrupt many of the most effective exploitation techniques from the last 25 years, and completely redefine the landscape of memory safety for Apple products. Because of how dramatically it reduces an attackerâ€™s ability to exploit memory corruption vulnerabilities on our devices, we believe Memory Integrity Enforcement represents the most significant upgrade to memory safety in the history of consumer operating systems.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BLS revision shows annual hiring was overstated by 911,000 jobs]]></title>
            <link>https://www.npr.org/2025/09/09/nx-s1-5527000/bls-us-job-growth-numbers-revised</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186050</guid>
            <description><![CDATA[The U.S. likely added 900,000 fewer jobs in the 12 months ending in March than had been reported, according to a preliminary Labor Department report.]]></description>
            <content:encoded><![CDATA[
      
            
        
            
            
            
        


    
        
                Hiring was slower in the year ending in March than initially reported, according to a preliminary revision from the Labor Department on Tuesday. The update is part of a routine process of incorporating more complete, but less timely, data.
                
                    
                    Joe Raedle/Getty Images
                    
                
                hide caption
            


            toggle caption
    

    
        
        Joe Raedle/Getty Images
        
    

   
   U.S. employers are adding far fewer jobs than initially tallied, in the latest sign that the labor market may be weaker than expected, according to a preliminary report from the Labor Department on Tuesday.   The report from the Bureau of Labor Statistics shows hiring for the 12 months ending in March was overstated by an estimated 911,000 jobs. It was the largest such preliminary revision on record, going back to 2000.   The revision comes at a time when President Trump is politicizing the BLS and casting doubt on its data, as part of his wider efforts to exert more control over all aspects of the U.S. government.    
   Last month, he fired the previous BLS head after a weaker-than-expected jobs report, claiming without evidence that the agency was manipulating the numbers to make the economy under his term look bad.    
   

   Tuesday's revision does more to make the economy under President Biden look bad: It tracks hiring data through the 12 months ending in March, after Trump had only been back in office for weeks.    Yet the White House on Tuesday was quick to claim vindication from what is normally a routine annual data update.    "The BLS is broken. This is exactly why we need new leadership to restore trust and confidence in the BLS's data," White House press secretary Karoline Leavitt said in an emailed statement.    The BLS has traditionally built trust and confidence by regularly checking and publicly revising its data. Tuesday's revision is part of a routine, annual exercise in which the government checks its monthly jobs numbers â€” which come from a sampling of employers â€” against much more complete data from state tax records. (Tuesday's estimate is preliminary. A final tally will be released early next year.)   But now Trump's attacks against the BLS are raising concerns that the government's number crunchers will be politically motivated, which is fueling worries about the integrity of the country's economic data.   
   On Tuesday, top members of Trump's administration echoed his attacks on the BLS. "It's difficult to overstate how useless BLS data had become. A change was necessary [to] restore confidence," Vice President J.D. Vance posted on X.    Trump last month nominated conservative economist E.J. Antoni to lead the BLS. Antoni previously worked at the right-leaning Heritage Foundation, and many commentators have raised concerns about whether he has the experience to run the agency or whether he will protect it from political influences. Antoni would need to be confirmed by the Senate.   
   

   
   

   Tuesday's revision was somewhat expected, but still on the high end of what both economists and White House officials predicted.    In a research note published Sunday, economists at Goldman Sachs predicted that the revision would be between 550,000 and 950,000 jobs. And in a Sunday interview with NBC's Meet the Press, Treasury Secretary Scott Bessent put his estimate at up to 800,000 jobs.    The revision is likely to further compound concerns about the labor market. Last week, the Labor Department reported lackluster job growth during the summer months, with employers adding just 22,000 jobs in August and a net loss of jobs in June for the first time since the pandemic winter of 2020.     The Federal Reserve has been closely monitoring signs of weakness in the labor market, ahead of a key decision on interest rates next week. The central bank is widely expected to cut its benchmark borrowing rate by a quarter percentage point in an effort to prevent widespread job losses.     But Tuesday's BLS revision also gave the White House another opportunity to criticize the Fed and its chair, Jerome Powell. Trump has been openly pressuring both to lower rates, as he seeks to bring the independent central bank under his control.    "Much like the BLS has failed the American people, so has Jerome 'Too Late' Powell â€” who has officially run out of excuses and must cut the rates now," Leavitt said in her emailed statement.   
   And on X, Treasury Secretary Bessent echoed his boss: "President Trump inherited a far worse economy than reported, and he's right to say the Fed is choking off growth with high rates," Bessent wrote. 
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apple Debuts iPhone 17]]></title>
            <link>https://www.apple.com/newsroom/2025/09/apple-debuts-iphone-17/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186023</guid>
            <description><![CDATA[Apple today announced iPhone 17, featuring the new Center Stage front camera, a 48MP Fusion Main camera, and a new 48MP Fusion Ultra Wide camera.]]></description>
            <content:encoded><![CDATA[


	
    







 

	
    
    
        




    
    
    
	
	







 




opens in new window








    
    
    









    





    
                    
                    
                        PRESS RELEASE
                    
                    
                        September 9, 2025
                    
                    
                







    
    
    


    
        
        
        
        
            
                
            
        
    












    
    
    


     
     
    
    
        CUPERTINO, CALIFORNIA Apple today announced iPhone 17, featuring the new Center Stage front camera that takes selfies to the next level; a powerful 48MP Fusion Main camera with an optical-quality 2x Telephoto; and a new 48MP Fusion Ultra Wide camera that captures expansive scenes and macro photography in more detail. The 6.3-inch Super Retina XDR display with ProMotion is bigger and brighter, enabling supersmooth scrolling, immersive gaming, and improved efficiency.1 And with the new Ceramic Shield 2, the front cover is tougher than any smartphone glass or glass-ceramic, with 3x better scratch resistance than the previous generation and reduced glare. It is all powered by the latest-generation A19 chip for higher performance and longevity.

 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            Multiple iPhone 17 devices shown from the side and featuring the full color lineup: lavender, mist blue, sage, white, and black.
                        
                    
                        
                            Multiple iPhone 17 devices shown upright and featuring the full color lineup: lavender, mist blue, sage, white, and black.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            A photo taken with iPhone 17 features three children playing outside.
                        
                    
                        
                            A photo taken with iPhone 17 shows a person standing in the middle of large pieces of fabric.
                        
                    
                        
                            A group selfie taken with iPhone 17 shows four people at a beach.
                        
                    
                        
                            A photo taken with iPhone 17 features a closeup of a dandelion.
                        
                    
                        
                            A photo taken with iPhone 17 features a coastal landscape.
                        
                    
                        
                            A photo taken with iPhone 17 features a child reading a book.
                        
                    
                        
                            A portrait taken with iPhone 17 features a subject standing in front of colorful foliage.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
 

    
    
    


    
    






    
    
    


     
     
    
    
        
             
                 
                 
             
                 
                 
             
                 eSIM: A Flexible, Convenient, and Secure Connection

                 
             
                 eSIM is a digital SIM that offers greater flexibility, better security, and seamless connectivity compared to traditional physical SIM cards.4 An industry standard, eSIM is supported by over 500 global carriers, including AT&T, T-Mobile, Verizon, and more. An eSIM-only iPhone 17 model will be available in Bahrain, Canada, Guam, Japan, Kuwait, Mexico, Oman, Qatar, Saudi Arabia, the UAE, the U.S., and the U.S. Virgin Islands. eSIM also makes staying connected while traveling even more convenient, allowing continued connectivity through affordable international roaming plans from usersâ€™ home carriers or local prepaid options available with more than 200 carriers. For better security, eSIM cannot be physically removed if an iPhone is lost or stolen, and managing travel eSIMs is even easier with a new streamlined setup in iOS 26.

                 
             
                 Featuring iOS 26 with New Apple Intelligence Capabilities

                 
             
                 iOS 26 elevates the iPhone experience with a beautiful new design, powerful Apple Intelligence capabilities, and meaningful improvements to the apps users rely on every day. The new design with Liquid Glass makes apps and system experiences more expressive and delightful, bringing greater focus to content while keeping iOS instantly familiar. Apple Intelligence now translates text and audio on the go with Live Translation, helping users communicate across languages in Messages, FaceTime, and Phone.5 Updates to visual intelligence allow users to capture a screenshot and easily search or take action on anything theyâ€™re viewing on their iPhone screen.6 The on-device foundation model at the core of Apple Intelligence is available to all developers, with apps already offering new intelligent, privacy-protected experiences that can even be used when offline. New screening tools for calls and messages help eliminate distractions so users can focus on the conversations that matter most. iOS 26 also introduces new features in CarPlay, Apple Music, Maps, and Wallet, as well as Apple Games, a brand-new app that gives players a single destination for all their games.

                 
             
         
 

    
    
    


    
        
        
        
        
            
                
            
        
    












    
    
    


     
     
    
    
        
             
                 Beautiful New Accessories

                 
             
                 In addition to the iPhone 17 Clear Case with MagSafe, a Silicone Case with MagSafe will be available in five colors: black, neon yellow, light moss, anchor blue, and purple fog. The Silicone Case with MagSafe can be paired with the new Crossbody Strap, giving users a hands-free way to wear iPhone. Crafted from 100 percent recycled yarns, the smooth strap drapes comfortably, with embedded flexible magnets and stainless steel sliding mechanisms to easily adjust the length and keep both straps securely aligned. The Crossbody Strap will be available in 10 colors: black, light gray, blue, light blue, purple, sienna, green, neon yellow, tan, and orange.

                 
             
         
 

    
    
    


    
    
        
        
        
            
            
                
                    
                        
                            The iPhone 17 Silicone Case with MagSafe is shown in purple fog.
                        
                    
                        
                            iPhone 17 Clear Case.
                        
                    
                        
                            A green Crossbody Strap is shown with iPhone 17.
                        
                    
                
            
            
            
                
                
                
                    
                        
                    
                
            
        
    


    
    
    


     
     
    
    
        
 

    
    
    


     
     
    
    
        
             
                 
                 
             
                 
iPhone 17 will be available in lavender, mist blue, sage, white, and black in 256GB and 512GB storage capacities. iPhone 17 starts at $799 (U.S.) or $33.29 (U.S.) per month.7


                 
             
                 
Apple offers great ways to save and upgrade to the latest iPhone models. With Apple Trade In, customers can get $200 to $700 (U.S.) in credits when they trade in iPhone 13 or newer.8 Apple also partners with select carriers to offer incredible deals, and customers can get up to $1,100 (U.S.) in credits when they trade in iPhone 13 or newer â€” in any condition â€” to put toward iPhone 17 Pro. Customers can take advantage of carrier deals by visiting the Apple Store online or an Apple Store location. For carrier deal eligibility requirements and more details, see apple.com/shop/buy-iphone/carrier-offers. To see what their device is worth and for trade-in terms and conditions, customers can visit apple.com/shop/trade-in.


                 
             
                 
Customers in more than 63 countries and regions, including Australia, Canada, China, Colombia, France, Germany, India, Japan, Malaysia, Mexico, Singapore, South Korea, Thailand, TÃ¼rkiye, the UAE, the UK, the U.S., and Vietnam, will be able to pre-order iPhone 17 beginning at 5 a.m. PDT this Friday, September 12, with availability beginning Friday, September 19. iPhone 17 will be available in 22 other countries and regions beginning Friday, September 26.


                 
             
                 
iOS 26 will be available as a free software update on Monday, September 15. Some features may not be available in all languages or regions, and availability may vary due to local laws and regulations. For more information about availability, visit apple.com.


                 
             
                 
Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. More languages will be coming by the end of this year: Danish, Dutch, Norwegian, Portuguese (Portugal), Swedish, Turkish, Chinese (traditional), and Vietnamese. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see support.apple.com/en-us/121115.


                 
             
                 
Apple is extending free access to satellite features for an additional year for existing iPhone 14 and iPhone 15 users. The free trial will be extended for iPhone 14 and iPhone 15 users who have activated their device in a country that supports Appleâ€™s satellite features prior to 12 a.m. PT on September 9, 2025. For satellite feature availability, visit support.apple.com/en-us/105097.


                 
             
                 
In addition to an iPhone 17 Clear Case, available for $49 (U.S.), a Silicone Case with MagSafe will be available for $49 (U.S.) and a Crossbody Strap will be available for $59 (U.S.). FineWoven Wallet with MagSafe will be available for $59 (U.S.) in black, navy, midnight, purple, fox orange, and moss.


                 
             
                 
The Apple-designed 40W Dynamic Power Adapter with 60W Max will be available for $39 (U.S.), and a Qi2 25W-certified MagSafe Charger will be available in a 1-meter length for $39 (U.S.) or a 2-meter length for $49 (U.S.).


                 
             
                 
AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new iPhone, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit apple.com/applecare.


                 
             
                 
iCloud+ plans start at just $0.99 (U.S.) per month, providing additional storage to keep photos, videos, files, and more safe in the cloud and accessible across devices. iCloud+ also gives access to premium features such as event creation in the Apple Invites app, as well as Private Relay, Hide My Email, Custom Email Domains, and HomeKit Secure Video. With Family Sharing, users can share their subscription with five other family members at no extra cost.


                 
             
                 
Customers who purchase iPhone 17 may receive three free months of Apple Arcade, Apple Fitness+, Apple Music, Apple News+, and Apple TV+, with a new subscription. Offer and services availability varies by region. See apple.com/promo for details.


                 
             
         
 

    
    
    




    
    
        
    


    
    
    


		
		
        
			
				
				
					Text of this article
					
				
			
			
                
                
                    Media in this article
                    
                
            

        
    

    
    
    




    




    
    
    





    
    
    
            
The display has rounded corners that follow a beautiful curved design, and these corners are within a standard rectangle. When measured as a standard rectangular shape, the screen is 6.27 inches diagonally. The actual viewable area is smaller.
The new Bright Photographic Style will be available in iOS 26 on iPhone 16, iPhone 16 Plus, iPhone 16 Pro, iPhone 16 Pro Max, iPhone 17, iPhone Air, iPhone 17 Pro, and iPhone 17 Pro Max.
The 40W Dynamic Power Adapter with 60W Max will be available in Canada, China mainland, Japan, Mexico, Taiwan, the Philippines, and the U.S.
Use of an eSIM requires a carrier that supports eSIM and a wireless service plan. See carrier for details. To learn more, visit apple.com/esim.
Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified). Live Translation in Phone and FaceTime is available for one-on-one calls in English (U.S., UK), French (France), German, Portuguese (Brazil), and Spanish (Spain).
Visual intelligence is available on any Apple Intelligence-enabled iPhone. Some capabilities may not be available in all languages and regions. For more details, see support.apple.com/en-us/121115#visual-intelligence.
Pricing for iPhone 17 includes a $30 connectivity discount that requires activation with AT&T, Boost Mobile, T-Mobile, or Verizon. Financing available to qualified customers, subject to credit approval and credit limit, and requires the user to select Citizens One Apple iPhone Payments or Apple Card Monthly Installments (ACMI) as the payment type at checkout at Apple. The user will need to select AT&T, Boost Mobile, Tâ€‘Mobile, or Verizon as their carrier when they check out. An iPhone purchased with ACMI is always unlocked, so users can switch carriers at any time, subject to their carrierâ€™s terms. Taxes and shipping on items purchased using ACMI are subject to a cardâ€™s variable APR, not the ACMI 0 percent APR. ACMI is not available for purchases made online at special storefronts. The last monthâ€™s payment for each product will be the productâ€™s purchase price, less all other payments at the monthly payment amount. ACMI financing is subject to change at any time for any reason, including but not limited to, installment term lengths and eligible products. See the Apple Card Customer Agreement for more information about ACMI. Additional Citizens One Apple iPhone Payments terms are available at apple.com/legal/sales-support/iphoneinstallments_us.
Trade-in values will vary based on the condition, year, and configuration of the eligible trade-in device.


        



    
    
    






    















	

		
		
			
























		
		











	

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Dropbox Paper mobile App Discontinuation]]></title>
            <link>https://help.dropbox.com/installs/paper-mobile-discontinuation</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45186011</guid>
            <description><![CDATA[The Dropbox Paper app is being discontinued October 9. Learn what that means for your Paper documents and mobile editing.]]></description>
            <content:encoded><![CDATA[
    
    

    
        
        
            
                
                    Dropbox Help Center - How to use Dropbox 
                
                
            
            
        
            
                
                    Installs 
                
                
            
            
        
            
            
                 FAQs on the Dropbox Paper app discontinuation
                
            
        
    









    In this article


    
    
          
         
            
               person icon
               
               
         
         
         
         
         
        Â The information in this article applies to all Dropbox users, unless otherwise stated.  
      

        In order to focus on delivering a consistent, high-quality experience on paper.dropbox.com, the Dropbox Paper mobile app will be discontinued on October 9, 2025. If you already have the app installed on your device, it will no longer function after this date.Â 

You can continue using Paper on Web on any of your devices after this date by logging into paper.dropbox.com using your browser.

      

        When will the Paper mobile app be discontinued?

The Paper mobile app will no longer be available on the Google Play Store or Apple App Store from October 9, 2025. If youâ€™ve already got the app installed on your device, itâ€™ll no longer update after October 9. After this date, some parts of the app will no longer function. To ensure a smooth transition, we recommend deleting the app.

      

        What happens to my Paper documents?

Your Paper files will continue to be securely stored in your Dropbox account. You can access them at any time, from any of your devices, by visiting paper.dropbox.com.

      

        Can I still create and edit Paper documents on my mobile device?

Yes, you can still create and edit paper documents using Paper on the web.

To create Paper documents on your mobile device:


Log in to paper.dropbox.com on your mobile device.
Tap Â  Â Create new doc at the top of your screen.
Enter a name for your new document.


To edit Paper documents on your mobile device:


Log in to paper.dropbox.com on your mobile device.
Tap the document youâ€™d like to edit.
Tap any of the text in the document to begin editing.


You can make edits using the keyboard on your mobile device.

      

        Can I share Paper documents with my mobile device?

Yes, you can share Paper documents with your mobile device through Paper on Web, or through the Dropbox mobile app.

To share a document on the web:


Log in to paper.dropbox.com on your mobile device.
Tap  (more) next to the document youâ€™d like to share.
Select whether the person youâ€™re sharing the file with can view, or edit the file, by choosing from the dropdown next to Anyone with this link.
Enter the email address of the person youâ€™d to share the document with.
You can also tap Copy link and share that link directly.


Add a note if required.
Tap Share.



To share a file using the Dropbox mobile app:


Open the Dropbox mobile app.
Tap Â (more options) on Android or Â (more options) on iOS next to the file youâ€™d like to share.
Tap Share.
Tap Invite to file (file).
Tap under Send to and type the Email, name, or group of the person (or people) youâ€™d like to share the file or folder with.
Tap to select them from the results.
Note: You can invite as many people as youâ€™d like.


Tap to select Can edit (view, comment, and edit) or Can view (view and comment but not edit).
Tap Close on iOS.


Tap Optional message on Android or Message (optional) on iOS to add a message, if required.
Tap Share.


      

        How will I receive notifications about changes to my Paper documents?
Youâ€™ll still receive notifications about activity, comments, @mentions, to-dos, and changes to docs you follow through email, and on the Dropbox mobile app.

Learn more about Dropbox Paper notifications.

      

        Can I continue to use the Dropbox Paper desktop app?

The Dropbox Paper desktop app was a beta experience, and is also being discontinued on October 9, 2025. Youâ€™ll still be able to use all of the features of Dropbox Paper by visiting paper.dropbox.com.

      

        Will I be reminded of the change?

Yes, if youâ€™re an active user of the Dropbox Paper mobile or desktop apps, youâ€™ll receive a reminder email on October 1, 2025.

      

    


        Was this article helpful?
        
        
        
                
                Thanks for your feedback!
            
    

		
			Related Articles
		
		
	


         
           Other ways to get help 
    
 

    
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Tomorrow's Emoji, Today: Unicode 17.0 Has Arrived]]></title>
            <link>https://jenniferdaniel.substack.com/p/tomorrows-emoji-today-unicode-170</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45185875</guid>
        </item>
        <item>
            <title><![CDATA[What happens when private equity buys homes in your neighborhood]]></title>
            <link>https://www.npr.org/sections/planet-money/2025/09/09/g-s1-87699/private-equity-corporate-landlords</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45185400</guid>
            <description><![CDATA[What makes rents go down and neighborhood diversity go up? Corporate landlords. But they also make it harder to own for yourself.]]></description>
            <content:encoded><![CDATA[
      
            
        
            
            
            
        


    

    
        
        Joe Raedle/Getty Images
        
    

   
   This comes from the Planet Money newsletter. Subscribe now to get more insights into how our economy works delivered to your inbox each week.   Daniel Erb became a corporate landlord kind of by accident. It started in 2020, when he received his first bonus as an investment banker. It was more money than he was used to. He wanted to invest in real estate, so he called his cousin, a research analyst at BlackRock, for advice.   As they talked over options, his cousin showed him a striking chart of the number of "housing starts" in the U.S. since 1950 (basically the number of new houses and apartments built each year). It showed that the last 10 years had the fewest starts since the 1960s, even though the U.S. population was now much larger.   
   Loading...
   

   It was a full decade of underinvestment. They focused on single-family homes â€” the classic house with a yard, often in the suburbs.   "I'm a millennial," says Erb. "I've always envisioned having a home." But none of his friends had bought a house yet. Neither had he. Contemplating this lack of new houses and rising demand from millennials like him, he saw "a big opportunity â€¦ something that I was willing to spend my career on."   So Erb and his cousin raised money from investors, bought homes in places like the Chatham-Arch neighborhood in Indianapolis (which was affordable, had a growing population and was benefiting from redevelopment), and rented them out â€” presumably to people who wanted a house with a yard but couldn't afford to buy one. Erb says it was a profitable business.   He was not the first New York finance person to profit from single-family rentals across the United States. The private equity firm Blackstone (commonly confused with BlackRock) more or less invented this buy-to-rent strategy in 2012, under the moniker Invitation Homes. It's now a public company valued at more than $18 billion.   The response to this development â€” of Wall Street buying Main Street, or at least some of its cul-de-sacs â€” has been bipartisan, populist and patriotic condemnation. Both JD Vance and Kamala Harris called for bans on these corporate landlords. Since houses tend to rise in value over time, homeownership has been a primary way that middle-class families build wealth. But now private equity was outbidding aspiring homeowners, making it more expensive to buy a home and pocketing the appreciation in home values.   
   Even some of Erb's friends told him they thought he was making homes unaffordable. "Nothing that has stuck with me or made me second-guess what I'm doing," he says. He wasn't responsible for the decade of underinvestment; he felt they were giving young couples the option to live in a house without breaking their bank account. "But, yeah, very emotional conversations."   Now that these institutional investors have been buying and renting out houses for more than a decade, researchers have had time to study their impact. And they've found a surprising nuance.   These investors can and do make homeownership harder to attain, just as their critics claim. But by providing rentals, they also make neighborhoods more affordable and more diverse. They are diversifying the suburbs.   The big bang of buy-to-rent   When institutional investors first started buying single-family homes, the U.S. government laid out the welcome mat.   Before the Great Recession, major investors hadn't had much interest in the suburbs. In the early 2000s, a firm called Redbrick Partners tried buy-to-rent. It ultimately abandoned the effort. Unlike in an apartment building, its leadership noted, where corporate management is common, fixing faucets and other maintenance were much less efficient when dealing with geographically dispersed homes.   But during the Great Recession â€” just before the decline of new starts in Erb's chart â€” the U.S. had a glut of single-family homes in foreclosure. Many were auctioned off en masse, including by the federal government, which organized auctions for investors like Blackstone and even provided a $1 billion loan guarantee to encourage Blackstone to buy.   This allowed private equity firms (which raise money from wealthy families, pension funds and other organizations to seek out profits, often by buying private companies) and real estate investors to efficiently and cheaply buy, say, a dozen similar homes located in the same Phoenix suburb.   
   This solved two big problems for these institutional investors. It reduced the "search costs" of finding suitable homes (often starter homes with three bedrooms), and it allowed them to buy similar homes clustered in one area (which ameliorated the dispersed-faucets problem).   Blackstone then introduced a financial product that supercharged the buy-to-rent sector: the rent-backed security. It was a bond, or IOU. Investors bought them, providing Blackstone with more money to buy and renovate homes. In exchange, investors were entitled to a cut of future rent payments.   Wall Street could now buy homes by paying with the rent they would collect in the future. Per the Federal Reserve Bank of Philadelphia, the number of homes owned by Blackstone and similar firms increased from almost nothing in 2010 to around 400,000 by 2021.   This is around when Erb and his cousin started buying homes. The batch auctions were long gone. But Erb says new technology allows companies like his to have a geographically dispersed portfolio of homes. The universality of listing platforms such as Redfin and Zillow keeps search costs down. Products like Ring cameras allow potential tenants to tour properties without being shown around by an agent. And software like Zoom has made it easier for them, like other executives, to manage a remote workforce.   In 2012, many government officials had welcomed firms like Blackstone into the housing market because they worried about abandoned houses and saw rental conversions as a win. Today, though, institutional investors compete with middle-class families for starter homes. Is that why homeownership has gotten more expensive?   The trade-off   As Kamala Harris and JD Vance were calling for bans on corporate landlords, Konhee Chang was a Ph.D. student in economics. Born in Korea, Chang had always rented while living in the U.S. but never the "quintessential house that I think of when I think about an American house," with a front yard and a backyard. He wanted to know why there were so few rentals in the suburbs and who would live there if renting was an option.   
   Chang realized these investors' buy-to-rent strategy provided an ideal case study of what happens when more rentals are available. If someone had built new homes to rent out, that would increase the supply of homes, changing the neighborhood. But since they converted homes into rentals, only one variable had changed, like in an experiment.   So Chang assembled and analyzed data on neighborhoods before and after corporate landlords showed up, including demographic data on the residents. His biggest finding? Institutional investors were reducing segregation. When private equity rented out homes, the new tenants tended to be lower income than the prior owners and more likely to be young and nonwhite.   "I think I was most surprised by the fact that the effect was so sharp and immediate," says Chang, who has since earned his Ph.D. from UC Berkeley. He took it as a sign that these families really wanted to live in these areas but were prevented by the lack of rentals and their inability to get a mortgage.   This is particularly notable because one of the most important economics findings of the past decade is the impact on children's development and career prospects of their hometown and neighborhood. (You can listen to a Planet Money episode on moving to opportunity here.) Suburban neighborhoods are not inherently better than rural or urban areas. But another study, for example, showed that single-family rentals in North Carolina served "as a pathway for access to high-performing public schools" for economically disadvantaged children.   
   

   These results did not turn Chang into a cheerleader for private equity. He's too careful a scholar, and his results hold for rentals in general, regardless of whether the landlord is Invitation Homes or a couple down the street. Plus, he did not investigate other criticisms of corporate ownership.   (For example, a Bloomberg investigation in 2013 found that Magnetar Capital LLC became the largest landlord in Huber Heights, Ohio, and then pushed for lower assessments of its properties' value. If it had succeeded, it would have been the largest property tax cut in county history, reducing the school district's budget by $800,000 a year.)   
   Most of all, Chang found that the buy-to-rent strategy was hurting the middle class. Creating rentals aided lower-income families and nudged rents down. But reducing the supply of homes available for sale also pushed home prices up, hurting families on the cusp of homeownership.   Erb says he feels good about the rental service they provide. (In 2024, he and his cousin teamed up with a veteran real estate investor to co-found a larger investment firm, Strand Capital.) But he agrees this trade-off exists.   "There's always gonna be a cost and a benefit," he says. But the bigger problem for housing affordability, he adds, is that "we just haven't built enough [homes] to keep up with the population growth and household formation."   The boogeyman   "People get really riled up about this idea of private equity coming in and buying the block," says Daryl Fairweather. "I think they are kind of the boogeyman though."   That's because institutional investors own a very small slice of single-family homes in the United States. As the chief economist at the real estate platform Redfin, Fairweather says investors purchase about 17% of homes. But most of those purchases are by mom-and-pop investors, not big firms like Blackstone. Institutional investors just don't own enough homes to be the main culprit for high home prices.   The U.S. homeownership rate is around 65%.As of December 2022, the five largest investors owned about 300,000 homes â€” just under 2% of single-family rental homes nationally.Institutional investors own roughly 2% to 25% of single-family rentals in major markets.   In fact, Fairweather sees some societal benefits of institutional investors. Unlike with mom-and-pop landlords, it's easier to regulate large corporate landlords and check whether they are, say, following the Fair Housing Act. Plus, in places like Silicon Valley, where politicians are trying to address housing crises by encouraging the development of duplexes and triplexes, profit-driven institutional investors are a potential boon, since they're more likely to turn suburban homes into duplexes.   
   And in areas with more open land, like the suburbs near Denver, institutional investors are building new housing specifically to rent out. Think cookie-cutter homes, perhaps with a dog park or pool.   "I think that we should embrace investors who want to make those kinds of investments," Fairweather says.   Still, she thinks middle-class families are right to worry about private equity displacing them from the housing market. She worries about fewer families achieving homeownership and gaining control over this intimate part of their lives, which has also been the dominant path to building wealth in America.   But a ban? As an economist, she hates bans. If politicians succeed in banning corporate landlords, perhaps by making it illegal to own more than 300 homes, she suspects we'd see lots of 300-home companies replacing Blackstone â€” without doing anything to increase homeownership among the middle class.   Instead, she advocates for policies that will incentivize and allow developers to build more housing. The trade-off caused by single-family rentals â€” that they benefit some low-income renters but hurt some aspiring homebuyers â€” is "because we are restricting the number of homes that can be built in neighborhoods."   Many desirable neighborhoods are zoned so that it's impossible to build the duplexes or apartment buildings that would make them accessible to low-income families. Many prosperous towns block the building of new single-family homes, often at the behest of current homeowners who don't want to deal with construction or who want to restrict supply and boost their home's value. The best way to stick it to Blackstone and private equity, to prevent Wall Street firms from profiting off the housing crisis, is to make it easier to build more homes.   As for Daniel Erb, even though he has spent his career responding to the dearth of suburban homes, betting on our collective underinvestment in American dream properties, he might appreciate that too. He says he doesn't own a home, in part because he often travels to the towns where his company buys homes. And he says he's not buying for himself at today's prices.   
   Alex Mayyasi is the author of The Planet Money Book, due to be published in April 2026. Sign up here to get notified, when presales start, about special offers and presale gifts.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Weave (YC W25) is hiring a founding AI engineer]]></title>
            <link>https://www.ycombinator.com/companies/weave-3/jobs/SqFnIFE-founding-ai-engineer</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45184921</guid>
            <description><![CDATA[At Weave, weâ€™re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.
We are a well-funded startup, backed by top investors, growing rapidly and currently profitable.
You'll be working directly with me (Andrew), the CTO. Before I was CTO of Weave I was the founding engineer at Causal, and I want to give you all the support and growth opportunities in this role that I got when I went through it.
Youâ€™ll also be working directly with Adam, the CEO. Adam runs sales at Weave, and before that worked as a sales executive at a few different high growth startups.
Must haves
You are a good fit for Weave if you are a formidable (https://paulgraham.com/convince.html) engineer. This means you stop at nothing to accomplish your goal. We don't care much about your current skills or even what you've done before; we care that you will be able to do anything you set your mind to.
You must also be pragmatic. Weave is a startup so something is always on fire. You need to know when to let little fires burn and when to break out the extinguisher.
You must be a very good engineer who's committed to becoming a great engineer. The slope is more important than the Y-intercept.
You must be empathetic. We're building products for other people, so you need to be able to understand how other people think and why.
You must care about helping other software engineering teams be great. If that's not an exciting mission for you, it will be hard to stay motivated through the inevitable highs and lows.
You must be an excellent communicator. Youâ€™ll be working on a product thatâ€™s communicating with millions of engineers and leaders, so you need to be clear.
Finally you must be gritty. You should be accustomed to picking the hard option and pushing through it.
Nice to haves
(Please feel free to apply even if some or all of these don't apply to you!)
Our tech stack is React + TypeScript on the frontend, Go on the backend, and Python for ML. Experience with any of those three languages is a bonus.
If you've already done lots of thinking about engineering productivity and how to improve it, that's great and we want to hear about it!
We hope your design sensibilities are passable.
The role
As Weaveâ€™s founding AI engineer, your job is to build AI to understand and improve the work that software engineers do. Youâ€™ll be building our processes and standards as you go to make building every incremental feature easier. Your goal will be to delight customers with intelligence that makes their job 10x easier.]]></description>
            <content:encoded><![CDATA[Founding AI Engineer$140K - $200Kâ€¢0.20% - 1.00%â€¢Oakland, CA, US / San Francisco, CA, USJob typeFull-timeRoleEngineering, Machine learningExperience1+ yearsVisaUS citizen/visa onlySkillsGo, PythonConnect directly with founders of the best YC-fundedÂ startups.Apply to role â€ºAt Weave, weâ€™re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.
We are a well-funded startup, backed by top investors, growing rapidly and currently profitable.
You'll be working directly with me (Andrew), the CTO. Before I was CTO of Weave I was the founding engineer at Causal, and I want to give you all the support and growth opportunities in this role that I got when I went through it.
Youâ€™ll also be working directly with Adam, the CEO. Adam runs sales at Weave, and before that worked as a sales executive at a few different high growth startups.
Must haves
You are a good fit for Weave if you are a formidable engineer. This means you stop at nothing to accomplish your goal. We don't care much about your current skills or even what you've done before; we care that you will be able to do anything you set your mind to.
You must also be pragmatic. Weave is a startup so something is always on fire. You need to know when to let little fires burn and when to break out the extinguisher.
You must be a very good engineer who's committed to becoming a great engineer. The slope is more important than the Y-intercept.
You must be empathetic. We're building products for other people, so you need to be able to understand how other people think and why.
You must care about helping other software engineering teams be great. If that's not an exciting mission for you, it will be hard to stay motivated through the inevitable highs and lows.
You must be an excellent communicator. Youâ€™ll be working on a product thatâ€™s communicating with millions of engineers and leaders, so you need to be clear.
Finally you must be gritty. You should be accustomed to picking the hard option and pushing through it.
Nice to haves
(Please feel free to apply even if some or all of these don't apply to you!)
Our tech stack is React + TypeScript on the frontend, Go on the backend, and Python for ML. Experience with any of those three languages is a bonus.
If you've already done lots of thinking about engineering productivity and how to improve it, that's great and we want to hear about it!
We hope your design sensibilities are passable.
The role
As Weaveâ€™s founding AI engineer, your job is to build AI to understand and improve the work that software engineers do. Youâ€™ll be building our processes and standards as you go to make building every incremental feature easier. Your goal will be to delight customers with intelligence that makes their job 10x easier.
At Weave, weâ€™re building the best software for the best engineering teams to move faster, and we want to hire exceptional engineers to help us do so.
We are a well-funded startup, backed by top investors and growing rapidly.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ICE Is Using Fake Cell Towers to Spy on People's Phones]]></title>
            <link>https://www.forbes.com/sites/the-wiretap/2025/09/09/how-ice-is-using-fake-cell-towers-to-spy-on-peoples-phones/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45184368</guid>
            <description><![CDATA[ICE is using a controversial spy tool to locate smartphones, court records show.]]></description>
            <content:encoded><![CDATA[This is the online edition of The Wiretap newsletter, your weekly digest of cybersecurity, internet privacy and surveillance news. To get it in your inbox, subscribe here.
ICE is using all manner of surveillance technologies in its deportation drive. (Photo by Smith Collection/Gado/Getty Images)Getty Images

Itâ€™s been some time since Immigration and Customs Enforcement (ICE) has been seen using a tool known as a Stingray, or a cell-site simulator, in its attempts to find and remove undocumented immigrants. The tool tricks a phone into thinking itâ€™s a cell tower, and when a suspectâ€™s device connects, the cops can trace its location. Its use is controversial because anyone in the same area as the target is at risk of having their information exposed.

In a recently-unsealed search warrant reviewed by Forbes, ICE used such a cell-site simulator in an attempt to track down an individual in Orem, Utah. The suspect had been ordered to leave the U.S. in 2023, but is believed to still be in the country. Investigators learned last month that before going to Utah, heâ€™d escaped prison in Venezuela where he was serving a sentence for murder, according to the warrant. Heâ€™s also suspected of being linked to gang activity in the country, investigators said.

When the government got the targetâ€™s number, they first got a warrant to get its location. However, the trace wasnâ€™t preciseâ€“it only told law enforcement that the target was somewhere in an area covering about 30 blocks. That led them to asking a court for a Stingray-type device to get an accurate location.

The warrant was issued at the end of last month and itâ€™s not yet known if the fugitive was found.
But the case shows that, despite having been criticized by civil rights groups for using Stingrays during the last Trump administration, ICE continues to use the technology. Earlier this year, new media publication Straight Arrow News said it had analysed â€œmobile network anomaliesâ€ around a Washington state protest against ICE raids that were consistent with Stingray use.
Forbes found contract records showing ICE purchased nearly $1 million worth of â€œcell site simulator vehiclesâ€ in May this year, indicating itâ€™s taking the surveillance tool fully mobile. That was part of a contract first signed under the Biden administration in 2024.
ICE also has an active contract worth up to $4.4 million with the original Stingray manufacturer, Harris Corporation, for unspecified â€œequipment to determine the location of targeted mobile handsets.â€ That deal was also signed during the Biden years.

Got a tip on surveillance or cybercrime? Get me on Signal at +1 929-512-7964.
THE BIG STORY:
This Billionaireâ€™s AI Was Supposed To Speed Up Policing. Itâ€™s Not Going Well.Tom Siebel, chief executive officer of C3.AI, during a panel session at the World Economic Forum (WEF) in Davos, Switzerland. Photographer: Stefan Wermuth/BloombergÂ© 2025 Bloomberg Finance LP
San Mateo County Sheriffâ€™s Office spent $12 million on a sprawling AI surveillance system called Sherlock, designed to stitch together surveillance streams across as many as 16 different agencies in the jurisdiction.
Made by billionaire Tom Siebelâ€™s C3 AI, it was supposed to drastically speed up police work, but three years into the project, cops tell Forbes theyâ€™re yet to see the benefits.
Per one staffer in 2023, â€œWeâ€™ve been working with them for two years and they have a barely functional product.â€ Since then, itâ€™s unclear just how much the tech has progressed.
Stories You Have To Read Today
In a Forbes profile, Flock Safety shows off its drones, car tracking and AI-powered surveillance tools, all part of an effort to dislodge police tech giant Axon from the top of the market. â€œI plan to go take them out,â€ says CEO Garrett Langley.
ICE signed a contract with facial recognition company Clearview AI last week, worth nearly $10 million. Itâ€™ll be used, in part, to identify people assaulting ICE officers.
Former WhatsApp security lead Attaullah Baig has filed a lawsuit alleging Meta ignored big privacy and security problems within the messaging app. He claims thousands of Meta employees were able to view WhatsApp usersâ€™ profile pictures, location, group memberships and contact lists. Meta rejected the claims saying Baig was dismissed for poor performance and that his allegations were â€œdistorted.â€
Winner of the Week
Signal has launched encrypted backups for user chats. The feature will first be made available for Android phones, before being slowly rolled out to iPhone users. The archive requires a 64-character recovery key to access, but keep that code safe: Signal warns that if itâ€™s lost, thereâ€™s no way to get it back.
Loser of the Week
Amnesty International claims that Pakistan is running one of the worldâ€™s most expansive domestic surveillance operations outside of China, using both Chinese and Western technology providers, who are enabling both mass snooping via the nationâ€™s telecoms companies as well as widespread internet censorship.
More On ForbesForbesAmericaâ€™s Richest Sports Team Owners 2025By Justin BirnbaumForbesPresidency Boosts Trumpâ€™s Net Worth By $3 Billion In A YearBy Dan AlexanderForbesThe 2025 Forbes 400 List Of Wealthiest Americans: Facts And FiguresBy Chase Peterson-Withorn]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[U.S. Added 911,000 Fewer Jobs in the Year Ended in March]]></title>
            <link>https://www.wsj.com/economy/jobs/us-job-growth-revision-a9777d98</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45184315</guid>
        </item>
        <item>
            <title><![CDATA[An attackerâ€™s blunder gave us a look into their operations]]></title>
            <link>https://www.huntress.com/blog/rare-look-inside-attacker-operation</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183589</guid>
            <description><![CDATA[An attacker installed Huntress onto their operating machine, giving us a detailed look at how theyâ€™re using AI to build workflows, searching for tools like Evilginx, and researching targets like software development companies.]]></description>
            <content:encoded><![CDATA[Summary
Here at Huntress, we love exposing adversary tradecraft, and we also love when threat actors make blunders. So imagine our delight when a threat actor installed Huntress onto their operating machineâ€”after finding us via one of our advertising campaigns and starting a trialâ€” giving us a sprawling inside look at how theyâ€™re using AI to build workflows, searching for tools like Evilginx, and more.
------------------------
We all know that security products are often downloaded by attackers for â€œevaluation,â€ but often we can only guess as to how they decided to target a particular technology, or the actions taken while trying out such software. We recently had the pleasure of getting a front seat view into what one attacker did, simply because they installed our agent and let us collect information directly from them. Here, we will cover this strange tale.

How did we get here?
Like most good stories, this one starts in the middle and works its way back and forth. Letâ€™s start with how this person of interest got our attention. One of the tricks of the trade to get people interested in your products is through advertising. As such, we run ads to help lead potential customers to our products. An adverse effect here might be garnering some â€œunwantedâ€ attention as well. Such is the setting for the beginning of this adventure: it all started with a nicely placed Google ad.
The attacker tripped across our ad while researching another security solution. We confirmed this is how they found us by examining their Google Chrome browser history. An example of how this may have appeared to them in the moment may be seen in Figure 1.

Figure 1: Google search for Bitdefender, leading to a Huntress ad

It appears that the attacker became interested in Huntress while simultaneously trying out Bitdefender. After hitting our comparison page, they could hardly contain themselves and started a trial immediately. We are able to follow their journey through their Chrome history, as seen in Figure 2 below.


    Figure 2: Browser history showing how a search for Bitdefender led to a Huntress trial





Itâ€™s no secret that threat actors may install security products for research purposes or even for legitimate useâ€”and in fact, the adversary was interested in other security products in addition to Bitdefender and Huntress. We found evidence that they had bought a Malwarebytes subscription (including the Malwarebytes browser guard extension).

Figure 3: Attacker tries to stay safe with an installed Malwarebytes browser extension ðŸ¤£

Threat actor red flagsâ€”and our response
We knew this was an adversary, rather than a legitimate user, based on several telling clues. The standout red flag was that the unique machine name used by the individual was the same as one that we had tracked in several incidents prior to them installing the agent. Further investigation revealed other clues, such as the threat actorâ€™s browser history, which appeared to show them trying to actively target organizations, craft phishing messages, find and access running instances of Evilginx, and more. We also have our suspicions that the operating machine where Huntress was installed is being used as a jump box by multiple threat actorsâ€”but we donâ€™t have solid evidence to draw firm conclusions at this time.
Huntress analysts went to work evaluating the outstanding indicators of compromise found on the adversaryâ€™s host and how they related to data found within authentications to identities at Huntress. Retroactive hunts disclosed a further 20 identities which were compromised; many of which had been accessed by the adversary prior to Huntressâ€™ deployment against the identity, whose activity was limited to refreshing session tokens to maintain access.
Overall, analysis of the adversaryâ€™s primary operating infrastructure, hosted on Autonomous System (AS) â€œ12651980 CANADA INC.â€ (now known as VIRTUO) disclosed a pattern of access of over 2471 unique identities spanning the last two weeksâ€“ many of which were preemptively caught by additional detection capabilities such as malicious mail rule creation, or session token theft.
The intelligence gathered by the above has resulted in detections of high confidence against the adversaryâ€™s infrastructure; and equipped our systems and analysts to respond to these incidents in significantly less time and with extreme confidence in malice, eliminating adversarial attempts to evade our detections.Â 
All in all, we were able to see the threat actorâ€™s specific day-to-day activitiesâ€”from their methodologies to the specific types of organizations (and even individuals) they were interested in. We also saw them begin to tinker with tools and search for tutorials, attempting to learn more. For instance, after installing the Huntress agent, the threat actor took steps to better understand Autoruns.
Figure 4: The threat actor attempting to better understand Autoruns






Overall, over the course of three months we saw an evolution in terms of how the threat actor refined their processes, incorporated AI into their workflows, and targeted different organizations and vertical markets, as outlined in Figure 5 below.

Figure 5: An overview of some of the threat actorâ€™s activities that we saw over the months


Below are some of the specific methodologies that we saw.Â 

Attacker methodologies
Use of AI for operational efficiencyÂ 
The Chrome browser history gave a first-hand look at how the adversary is using AI tools to increase the operational efficiency of their workflows. While there have previously been many reports on how cybercriminals are using AI (based on indicators in phishing messages or landing page content), this is the first time that we have a close-up view of a threat actor embedding AI into their operations in order to automateâ€”and speed upâ€”their workflow.
On May 25, the threat actor signed up for Make.com, which is legitimate workflow automation software, before researching the platformâ€™s Telegram Bot integration feature as a way to launch automated processes (as seen in Figure 6 below). The threat actor then poked around several FAQ sites to better understand how Telegram Bot APIs work and how to set up webhooks.

Figure 6: Signing up for Make.comÂ 



Figure 7: Digging deeper into Telegram Bot APIs


Over time, the threat actor started to get a better grasp of how they could use Make.com for specific workflows, and their browser history shows them starting to rely more heavily on the platform. By the time June 29 rolled around, the threat actor had fully developed their workflow with Make. As seen in Figure 8, the threat actor would first identify the organization of interest (typically after receiving a â€œtipâ€ from Telegram) before using Google Translate to translate or craft messages related to these organizations. While we donâ€™t have detailed insight into how the threat actor was using Make for these specific workflows, we can see that it was part of the process to automate specific functions.Â 



        Figure 8: Threat actor starts to rely on automated workflows
        The threat actor also appeared to be interested in other AI tools to help with data generation and writing. We saw multiple Google searches for â€œfree ai no signupâ€ and for â€œcsv generator ai.â€ We also saw the threat actor using Toolbaz AI, which is a writing assistant; the CSV spreadsheet generator feature of DocsBot AI, which is an AI chatbot tool; and the AI data generator feature of Explo AI, which is an embedded analytics tool.
        
        Finding running instances of Evilginx
        We saw evidence of the threat actor searching for running instances of the Evilginx man-in-the-middle attack framework using Censys, and then attempting to access those instances.

        Figure 9: Using Censys to search for running instances of Evilginx

        
        
        Figure 10: One example of the Evilginx instance that the attacker tried to access

        
        In addition to Evilginx, we also found evidence of multiple installed tools on the threat actorâ€™s systemâ€”or, in some cases, an interest in tools based on the threat actor browser history. These tools included recon and attack tool GraphSpy, open source tool Bloodhound, the TeamFiltration framework used for enumeration and exfiltration, and more.Â Â 

        Figure 11: Various tools that the attacker may have used


        
        Interest in residential proxy services
        The Chrome browser history also revealed visits by the threat actor to multiple residential proxy webpages, including LunaProxy and Nstbrowser (which bills itself as an anti-detect browser and supports the use of residential proxies). The threat actor visited the pricing plan page for LunaProxy, researched specific products, and looked up quick start guides throughout May, June, and July. Residential proxy services have become increasingly popular with threat actors as a way to route their traffic through residential IP addresses, allowing them to obscure malicious activity, like avoiding suspicious login alerts while using compromised credentials.

        Figure 12: A VirusTotal lookup of LunaProxy.exe, which was in the Chrome history


        
        Research and recon methods
        The Chrome browser history entries also gave us a close view of the attackerâ€™s reconnaissance methods. The threat actor spent a lot of time researching companies across different sectors, from specific banks to â€œtop real estate companies in the USâ€ (also looking up â€œreal estate agents in Californiaâ€).Â 
        The threat actor didnâ€™t just search for individual companiesâ€”they also looked at all parts of the ecosystem surrounding organizations of interest, from their customer bases to associated third-party companies across the supply chain. For example, the threat actor appeared to start targeting software companies in early July, searching for these types of companies via Google Search and using database marketing tools like ReadyContacts and InfoClutch to scope out how many customers they had and their market share.Â 
        The threat actor also used the BuiltWith platform, which lets users identify and analyze the technology stacks used by websites. On July 8, browser entries show the attacker conducting an extensive level of research on a prominent ecommerce vendor for managing payments and subscriptions, including a list of its customers, contacts, and market share. The threat actor then used BuiltWith to search for the websites relying on that vendor, before navigating to the BuiltWith sign up page, presumably to access that list.
        The threat actor conducted a fair amount of research into tools used to scrape Telegram group data, including looking at scraper tools like Apify, the Axiom Chrome extension, and the RapidAPI platform (Figure 13).

        Figure 13: While researching data scraping tools the threat actorÂ came across RapidAPIÂ Â 


        
        Use of Google Translate
        The threat actor used Google Translate extensively, and Chrome browser shows them first visiting bank websites, and then using the translation platform, likely to assist in crafting phishing-related messages, as seen in Figure 14.Â 

        Figure 14: The threat actor used Google Translate services extensivelyÂ 



        The attacker often used urlscan to get information about various websites. Tips appear to have come in via Telegram using the getUpdates method.

        Figure 15: Part of the Chrome history around a particular tip

        
        
        Figure 16: Google Translate message

        
        
        Figure 17: Google Translate message: username and password

        
        
        Figure 18: Google Translate message: username and password

        
        There were several entries in the browser history that showed use of Google Translate to translate messages from Portuguese to English alongside browsing banks in Brazil, then evidence of crafting messages later on in their history.Â 

        
        


        


        
        
        Dark web: STYX market
        We also saw the threat actor express interest in STYX Market, a dark web forum thatâ€™s been around since 2023, and was recently called a â€œrising star for stealer logs, stolen creds, and laundering servicesâ€ by researchers. After doing some initial research on STYXâ€”as well as other Telegram chat groups and channelsâ€”they decided to check out the site for themselves, registering for an account before perusing the catalog of VoIP accounts, stealer logs, SIM cards, and more.

        Figure 19: The threat actor showed an interest in STYX Market


        
        Figure 20: A post from SOCRadar on STYX Market caught the threat actorâ€™s attentionÂ 


        
        EDR activities
        Rarely do you ever get the chance to actually shoulder surf a real threat actor. We had such an opportunity when they installed our agent. It starts out mundane enough. We donâ€™t know what they must have dreamed about after ending their shift at 2am UTC the previous night, but as mentioned earlier, you can see them start a trial, download the agent, and install it.

        Figure 21: At 2am UTC, after about 10 hours of inactivity, the threat actor suddenly showed an interest in Bitdefender, which led them to Huntress




        
        The most interesting activity for the start of their day on July 9, 2025 was browsing to urlscan.io to inspect login.incipientcroop[.]com. Shortly after, they logged into Make.com and began working on a project called Voltage_Office356bot (notice the typo).Â 

        Figure 22: Timeline of EDR and browser histories

        
        
        Figure 23: urlquery info for login.incipientcroop[.]comÂ 

        
        
        Figure 24: Further down on the urlquery page for login.incipientcroop[.]com, there is evidence of Voltage_Office356bot

        
        There is evidence that the threat actor had access to cookie data for two different individuals, and accessed them via Notepad++. They proceeded to open the first file:
        C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram Desktop\Cookies_[victim1]@[redacted1][.].com.json
        Then they started looking around to see what they can find, with a Google search for â€œemail osintâ€.

        Figure 25: Looking for â€œemail osintâ€

        
        Next, they opened the second cookie file:
        C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram Desktop\Cookies_[victim2]@[redacted2][.].com.json
        They then started up Nstbrowser.exe and LunaProxy:
        C:\Program Files\Nstbrowser\Nstbrowser.exeC:\Program Files (x86)\LunaProxy_cata\socks5\LunaProxyDivert.exeÂ  SOCK5 [snip]
        They browsed to an article titled Say Hello to your new cache flow by Synacktiv covering WHFB and Entra ID, followed by a Google search for â€œwhfb prtâ€, which landed them on the website of aÂ well-known researcher, Dirk-Jan Mollema.Â 
        They checked their IP address after this:
        C:\Windows\system32\curl.exe ipinfo[.]io
        And then checked their IP address again:
        C:\Windows\system32\curl.exe ipinfo[.]io
        They then tried to use a tool called ROADtools Token eXchange (roadtx):

        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe prtauth -r msgraph -c msteams
        And then erroneously tried to run the same tool (as an executable) via Python:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exeÂ  C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe prtauth -r msgraph -c msteams
        Then ran it again:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe describe
        And then tried to run it again, erroneously, using Python:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exeÂ  C:\Users\Administrator\AppData\Local\Programs\Python\Python313\Scripts\roadtx.exe describe
        They seemed to be having trouble. At this point they browsed to Dirk-jan Mollemaâ€™s post on Phishing for Microsoft Entra primary refresh tokens.Â 

        Figure 26: Searching for an answer with keyword whfb prtÂ 

        
        While there, they gained some new inspiration, and discovered a handy little script that could make their life easier:

        Figure 27: Excerpt from Dirk-janâ€™s blog, pointing to a nifty little script

        
        At this point they went back to their Voltage_Office356bot project before running this new script theyâ€™ve downloaded.

        Figure 28: Accessing the Voltage_Office356bot project and running the attack script

        
        They started trying to run the Python script:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py -f roadtx.prt --wfb
        They checked the usage again:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py --wfb
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py -h
        Then, they started to run it against the original victim whose cookie file we saw earlier:
        C:\Users\Administrator\AppData\Local\Programs\Python\Python313\python.exe main.py --wfb -u [victim2]@[redacted2][.]comÂ 
        They returned to the first victimâ€™s cookie file:C:\Program Files\Notepad++\notepad++.exe C:\Users\Administrator\Downloads\Telegram Desktop\Cookies_[victim1]@[redacted1][.].com.json
        This is where our EDR data drops off, as they may have become aware of us and uninstalled the agent.
        
        Hours worked in a day
        The attackerâ€™s browser history gives us an unprecedented level of insight into their everyday activity, searches, workflows, research, and more. The browser history shows the threat actor working intensively almost every day between the period of May 29, 2025 through July 9, 2025.Â 

        Figure 29: Chart of the number of hours per day (label alternates dates) worked based on browser activities


        On many of these days, the browser entries were seen across most hours of the day, logging 12 to 14 hours. But there was some variation, as seen in Figure 29, above: on several days, the threat actor worked as little as one to two hours.
        When we hone in on a few of the days when the most hours were put in, we can see some of the things that piqued the attackerâ€™s interest in those days. We analyzed the urls to see what businesses, or categories they might have fallen into, and then looked to see how many times the attacker visited these sites.Â 
        We can see a few trends. During these days, the attacker spent a lot of time researching various banking entities and bank personnel. To further expand on some of the graph labels:
        
            
                Attack infra: Malicious websites or servers set up by an attacker (maybe not this one) hosting frameworks like Evilginx and other known tools.
            
            
                Banking: Various banking websites
            
            
                Browser extension: Various browser extensions like ad blockers, etc. installed by the attacker to protect themselves.
            
            
                Corporate & Business: Various business websites not housed under a different category.
            
            
                Crypto: Various cryptocurrency and blockchain websites.
            
            
                Cybersecurity: Various cybersecurity vendor websites. The attacker often signed up for trials at various vendors to test things.
            
            
                Government & military: Various official government or military websites.
            
            
                News, media & information: Various news websites like CNN etc.Â  The attacker often read articles related to various breaches.
            
            
                OSS: Open source projects, often housed at github or gitlab.
            
            
                Recon: Activities where the attacker was using Censys, Urlscan, Google, etc., to do reconnaissance for a particular target.
            
            
                Research: When the attacker was researching a particular vulnerability, tool, or attack.
            
            
                Sandbox: The attacker often seemed interested in various types of malware that were on VirusTotal, Joeâ€™s Sandbox, and other online sandboxes.
            
            
                Social media: Various telegram, X, and other social media posts read by the attacker.
            
            
                Software: Various legitimate software, like 7zip.
            
            
                Telecommunications: A telecommunication website, like Verizon.
            
            
                Web & IT infrastructure: Various online hosting services, like Mega, Amazon AWS, and Azure.Â 
            
        

        Figure 30: Activities on May 29, 2025

        
        We can see that from May 29 to June 1, 2025, the attacker was mostly looking at various banking websites. Digging further into their activities, you see them researching various banks, reading about Telegram Bots, then downloading a blueprint from Make.

        Figure 31: A deeper look at some of the activities on May 29, 2025

        
        The next day, it seems that the attacker spent a little more time researching various attack infrastructure, in addition to focusing on banks, and similar activities seen previously.

        Figure 32: Activities on May 30, 2025

        
        On May 31, 2025 and June 1, 2025, the attacker switched their focus back to mostly researching banking websites.

        Figure 33: Activities on May 31, 2025

        
        
        Figure 34: Activities on June 1, 2025

        
        
        Figure 35: Regions Focused on by the Attacker from May 29 - June 1, 2025

        
        The other interesting thing was that the attacker was mostly focused on banks and sites that were in Nigeria during this time period, even looking for things like:â€œNo. 1 regulated crypto exchange in Nigeria.â€
        â€œtop crypto companies nigeriaâ€
        â€œBest Crypto Exchanges in Nigeriaâ€â€œTop Cryptocurrency Companies in Nigeriaâ€
        While we donâ€™t know where the attacker is based, the machine they had installed our agent upon appeared to be based in the United States, on the West Coast, based on the machineâ€™s internal time zone and IP address.

        Figure 36: Activities on July 9, 2025

        
        It seems that the attacker had spent quite some time looking at our various capabilities after they had started a trial with us. Figure 36 above shows just how much more time they spent interacting with the Huntress website, and particularly the account dashboard once they had started the trial.
        
        Lessons learned
        This incident gave us in-depth information about the day-to-day activities of a threat actor, from the tools they were interested in to the ways they conducted research and approached different aspects of attacks.Â 
        Upon confirming that the machine name was one used by an adversary, we decided to release these details because they give an invaluable understanding into the mindset and behaviors of threat actors behind attacks. For other defenders, we hope that this information can help add context around the ways that threat actors conduct research and launch attacks at the backendâ€”and the different types of organizations, tools, and platforms that interest them.Â 
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Building a DOOM-like multiplayer shooter in pure SQL]]></title>
            <link>https://cedardb.com/blog/doomql/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183050</guid>
            <description><![CDATA[CedarDB is a database system that delivers unmatched performance for transactions and analytics, from small writes to handling billions of rows. Built on cutting-edge research to power todayâ€™s tools and tomorrowâ€™s challenges.]]></description>
            <content:encoded><![CDATA[September 8, 2025 â€¢ 12 minutesDOOMQL: A DOOM-like multiplayer shooter in pure SQLI recently stumbled across Patrickâ€™s excellent DOOM clone running in a browser powered by DuckDB-WASM.
Ever since Iâ€™ve read that, I wanted to push his awesome idea to the logical extreme: Build a multiplayer DOOM-like shooter entirely in SQL with CedarDB doing all the heavy lifting.
During a month of parental leave (i.e., a lot of sleepless nights), I tried exactly that.Hereâ€™s a sneak peek at DOOMQL:
Your browser does not support the video tag.DOOMQL in actionOkay, with the flashy demo out of the way, letâ€™s talk about details.
What follows is a tour of the architecture, the SQL rendering pipeline, the game loop, and the fun metagame of cheating by issuing SQL commands against the database.Why even do this?Playing DuckDB DOOM in your browser is fun, but some things bugged me:
First of all, having parts of the rendering pipeline in Javascript felt like cheating. It worked well for DuckDB-Doom where everything is contained in a single HTML page, but I wanted to see if I could do everything in SQL. DuckDB-Doom is also a little bit stuttery with just 8 frames per second and has a pretty tiny viewport. I wanted to see if I could speed that up by switching over to CedarDB. I also wanted real sprites with transparency and they should move around believably in 3D space.
And most importantly, making the game multi-player should not just be possible, but easy, right? I got nerd-sniped by the perceived similarity of a database server to a traditional game server: Databases exist to synchronize shared state across clients. Thanks to transaction isolation, each player has a consistent view of the game world, no matter what the other clients are doing. Why not lean into that?
I would love to lie to you and claim I did it all to push CedarDB as an awesome database system but to be honest the database nerd in me just wanted to turn all knobs up to 11 and see what breaks.Architectural overviewAt a high levelState lives in tables (map, players, mobs, inputs, configs, sprites, â€¦)Rendering is a stack of SQL views that implement raycasting and sprite projectionThe game loop is a tiny shell script that executes a SQL file ~ 30 times per second.The client is ~ 150 lines of Python: It polls for input and queries the database for your 3D view.You can play, observe other players and even cheat (by sending raw SQL).Game state, or: Letâ€™s store everything in the databaseWith a database at hand, itâ€™s natural to store all game configuration, state, and static data in the database:Config:CREATE TABLE config(
  player_move_speed NUMERIC DEFAULT 0.3, 
  player_turn_speed NUMERIC DEFAULT 0.2,
  ammo_max INT DEFAULT 10,
  ammo_refill_interval_seconds INT DEFAULT 2
  );
Map:CREATE TABLE map(x INT, y INT, tile CHAR);
Players and inputs:CREATE TABLE players (
  id INT REFERENCES mobs(id),
  score INT DEFAULT 0,
  hp INT DEFAULT 100,
  ammo INT DEFAULT 10,
  last_ammo_refill int default EXTRACT(EPOCH FROM (now()))::INT
);

CREATE TABLE inputs(
  player_id INT PRIMARY KEY REFERENCES players(id),
  action CHAR(1), -- 'w', 'a', 's', 'd', 'x' for shooting
  timestamp TIMESTAMP DEFAULT NOW()
);
Because everything is data, modding a running match is trivial:-- Change a setting
update config set ammo_max = 20;

 -- Add a player
insert into players values (...);

-- Move forward
update input set action = 'w' where player_id = <your_id>;

 -- Cheat (pls be smarter about it)
update players set hp = 100000 where player_id = <your_id>;

-- Ban cheaters (that weren't smart about it)
delete from players where hp > 100;
Renderer: When a VIEW becomes your 3D viewIf you squint enough, in DOOM, a 3D (or more correct: 2.5D) view is just a view over 2D state (i.e., the level map and any players/enemies on it).
Well, weâ€™ve got VIEWS in SQL as well. Theyâ€™re also just views on our (2D) state tables.
Whatâ€™s stopping us from quite literally building a 3D â€œviewâ€ of our 2D map
using a simple raycasting algorithm?The pipeline:Send a set of rays from each playerâ€™s eye into the world, and see which map tiles are visibleCheck which walls the player sees, rendering them at the correct height and more or less solid based on the distanceProject mobs into the playerâ€™s camera spaceSelect sprite LODs based on depthExpand sprites into pixels, scaled to screen spaceOcclude against walls and other spritesAssemble frame buffer rows with string_aggBuild a minimap reusing the visible tiles calculation from earlierCombine the 3D view with minimap and HUD (HP/bullets/players) into a game viewLetâ€™s take a more in-depth look at steps 2, 7, and 8.RaycastingThe recursive rayâ€‘marching logic is adapted from Patrickâ€™s DuckDB DOOM post. Here is a simplified excerpt, adapted for multiplayer:CREATE OR REPLACE VIEW visible_tiles AS  
WITH RECURSIVE raytrace AS (  
  -- Starting at the player's eye ...
  SELECT r.player_id, r.col, 1 AS step_count,  
         r.player_x + COS(r.angle)*s.step AS fx,  
         r.player_y + SIN(r.angle)*s.step AS fy,  
         r.angle, 0 AS dist  
  FROM rays r, settings s  -- rays are built in an earlier step
  UNION ALL  
  -- ... we recursively march along the rays, 1 "step" at a time ...
  SELECT rt.player_id, rt.col, rt.step_count + 1,  
         rt.fx + COS(rt.angle)*s.step,  
         rt.fy + SIN(rt.angle)*s.step,  
         rt.angle,  
         step_count * s.step * COS(rt.angle - m.dir) AS dist  
  FROM raytrace rt, settings s, players p, mobs m  
  WHERE rt.step_count < s.max_steps   -- ... stopping after our max render distance
    AND rt.player_id = p.id  
    AND m.id = p.id  
    AND NOT EXISTS (  -- or if we hit a wall
      SELECT 1 FROM map m  
      WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  
        AND m.tile = '#')  -- wall
)  
-- We then determine per player:
--  a) which tiles we hit
--  b) how far away these tiles are
--  c) the column of the screen each tile should correspond to
SELECT player_id, tile, CAST(fx AS INT) AS tile_x, CAST(fy AS INT) AS tile_y, col, MIN(dist) AS dist  
FROM raytrace rt, map m  
WHERE m.x = CAST(rt.fx AS INT) AND m.y = CAST(rt.fy AS INT)  -- We might hit the same tile multiple times, so we take the closest hit
GROUP BY player_id, tile_x, tile_y, tile, col;  
And thatâ€™s just the first step in the pipeline. For the rest, take a look at the code.Final frame assemblyAfter all the heavy lifting, the payoff is surprisingly simple:SELECT player_id, y, string_agg(ch, '' ORDER BY x) AS row  
FROM framebuffer  
GROUP BY player_id, y;  
This glues together character pixels into text rows.HUD + minimapThe same trick builds the HUD and minimap. Here is the health bar:'HP: [' ||
repeat('â–ˆ', LEAST(20, ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
repeat(' ', GREATEST(0, 20 - ROUND(20 * GREATEST(0, LEAST(p.hp,100))::numeric / 100)::int)) ||
'] ' || GREATEST(0, p.hp)
Add ammo dots with repeat('â€¢', p.ammo) and youâ€™ve got a HUD entirely in SQL: 1: Lukas      (L) score: 1   HP: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           ] 50    AMMO: â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢
 2: Foobar     (F) score: 0   HP: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100   AMMO: â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢  
We can also re-use our earlier visible_tiles view to build a minimap with a view cone:select * from minimap where player_id = 1 order by y;

 player_id | y  |                               row                                
-----------+----+------------------------------------------------------------------
         1 |  0 | ################################################################
         1 |  1 | ################################################################
         1 |  2 | ##.......      #####               #############################
         1 |  3 | ##.....F.      #####               #####                     ###
         1 |  4 | ##.......      #####               #####                     ###
         1 |  5 | ##  .....      #####               #####                     ###
         1 |  6 | ##   ...                                                     ###
         1 |  7 | ##    .L                                                     ###
         1 |  8 | ##             #####               #####                     ###
         1 |  9 | ##             #####               #####                     ###
         1 | 10 | ##             #############  ##########                     ###
         1 | 11 | ##########  ################  ##########                     ###
         1 | 12 | ##########  ################  ##########                     ###
         1 | 13 | ##########  ################  ######################  ##########
         1 | 14 | ####                 #######  ######################  ##########
         1 | 15 | ####                 #######  ######################  ##########
         1 | 16 | ####                 #####             #####                 ###
         1 | 17 | ####                 #####             #####                 ###
         1 | 18 | ####                 #####             #####                 ###
         1 | 19 | ####                 #####             #####                 ###
         1 | 20 | ####                 #####             #####                 ###
         1 | 21 | ####                                   #####                 ###
         1 | 22 | ####                                                         ###
         1 | 23 | ####                 #####                                   ###
         1 | 24 | ####                 #####             #####                 ###
         1 | 25 | ####                 #####             #####                 ###
         1 | 26 | ####                 #####             #####                 ###
         1 | 27 | ####                 #####             #####                 ###
         1 | 28 | ####                 #####             #####                 ###
         1 | 29 | ################################################################
         1 | 30 | ################################################################
         1 | 31 | ################################################################
The surprisingly elegant game loopThe loop is just a shell script running raw SQL against the database:# Game loop @ 30 ticks per second
while true; do
  psql -qtAX -U "$DB_USER" -d "$DB_NAME" -h "$DB_HOST" -p "$DB_PORT" -f gameloop.sql
  sleep 0.03
done
Inside gameloop.sql, actions like bullet movement, collisions, kills, and respawns run in a single transaction, which keeps state consistent even if something fails mid-tick.Hereâ€™s the part processing interactions with bullets:-- Process all bullets
BEGIN TRANSACTION;

-- Move bullets forward
UPDATE mobs 
SET x = x + cos(dir) * 0.5, y = y + sin(dir) * 0.5 
WHERE kind = 'bullet';

-- Delete bullets that are out of bounds
DELETE FROM mobs 
WHERE (x < 0 
OR x >= (select max(x) from map) 
OR y < 0 
OR y >= (select max(y) from map))
AND kind = 'bullet';

-- Delete bullets that hit walls
DELETE FROM mobs b 
WHERE EXISTS 
    (SELECT 1 
    FROM map m 
    WHERE m.x = CAST(b.x AS INT) 
    AND m.y = CAST(b.y AS INT) 
    AND m.tile = '#') 
AND kind = 'bullet';


-- Players hit by a bullet loses 50 HP
UPDATE players p SET hp = hp - 50
FROM collisions c
WHERE p.id = c.player_id;

-- If a player has 0 or less HP, the player killing them gets a point
UPDATE players p SET score = score + 1
FROM collisions c
WHERE p.id = c.bullet_owner
AND EXISTS (SELECT 1 FROM players p2 WHERE p2.id = c.player_id AND p2.hp <= 0);

-- Delete bullets that hit players
DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id;

-- Respawn players whose HP is 0 or less
UPDATE mobs m
SET x = r.x, y = r.y, dir = 0
FROM players p
CROSS JOIN (
  SELECT x, y
  FROM map
  WHERE tile = 'R'
  ORDER BY random()
  LIMIT 1
) AS r
WHERE m.id = p.id
  AND p.hp <= 0;

-- Reset players' HP to 100 and ammo to 10 after respawn
UPDATE players p SET
  hp = 100,
  ammo = 10
FROM mobs m
WHERE p.id = m.id
AND p.hp <= 0;

COMMIT;
On my machine, the game loop takes about 1 ms, so we could defintely improve the tick rate.
That might be a way to get the Counterstrike snobs who scoff at everything below 128 Hz.
It would require some refactoring on my part since I tied the movement speed to the game loop - a big no no in game design!While only someone insane could think a pure SQL raycasting renderer is a good idea in an actual game, Iâ€™ll happily defend this transactional game loop.
I donâ€™t think this part would be much more concise or less brittle in a real game engine.Make it multiplayer in two queriesThe game clientâ€™s job description is simple:RenderSELECT full_row FROM screen WHERE player_id = <your_id> ORDER BY y
Send inputINSERT INTO inputs(player_id, action)
    VALUES (<your_id>, <pressed_key>)
    ON CONFLICT(player_id)
    DO UPDATE SET action = EXCLUDED.action
The game loop periodically checks the input table and moves all players accordingly - inside a transaction, of course, so we donâ€™t run into any race conditions.Thatâ€™s it (well, plus a one-time â€œcreate playerâ€ on first connect). The ~150 lines of Python in the client mostly handle keyboard input and reducing terminal flicker.
Bonus: The client provides an observer mode. All it has to do is swap the <player_id> in the render call.PerformanceAt 128 x 64 pixels, a single player view takes ~33 ms on my machine, which is enough for a breezy ~30 FPS, compared to DuckDB DOOMâ€™s 8 FPS at just 32 x 16 pixels.
Iâ€™m actually quite proud of that performance and quite happy with CedarDB here.
I donâ€™t think any other database system can keep up with that.
Let me know if you find one!You might worry that rendering the views of all players and filtering late would be very wasteful.
CedarDBâ€™s query optimizer pushes the where player_id = <...> predicate through view boundaries, avoiding unncessary work.
You can easily check by running:select * from screen order by y; -- render both users
-- Time: 57,907 ms (~2x single player 33ms)
Because clients send raw SQL as superusers (I didnâ€™t bother setting up any role based access control or row level security, donâ€™t do that!), thereâ€™s an emergent metagame: Cheat creatively and try not to get caught.Low effort:update players set score = 0 where id != <your_id>;
update players set hp = 0 where id != <your_id>;
Mischievous:update inputs set action = null where player_id != <your_id>;
Steal kills:update mobs set owner = <your_id> where kind = 'bullet';
Attempted but didnâ€™t work:DELETE FROM mobs m
USING collisions c
WHERE m.id = c.bullet_id AND c.player_id = <your_id>;
This doesnâ€™t work because moving bullets, checking for collisions, and respawn happens in the same transaction.
As transactions are atomic, you either see everything being applied at once, or nothing. By the time you see the hit, youâ€™re already dead.
A property thatâ€™s very useful for database systems (and not just to prevent cheating).What I learnedI set out to see if I could push Patrickâ€™s demo to an extreme: Doing the entire rendering pipeline in SQL.
And while it works, I have to admit that it is a prettyâ€¦ bad idea? Fast enough, but horrible to maintain and debug.The surprise was how natural it felt to express game state and logic in SQL.
It even felt like accidentally re-invented the entity-component-system pattern.And multiplayer â€œjust workedâ€ because the database system which handles all the nasty concurrency is the source of truth.Try it yourself!All the code is on Github: DOOMQL RepoRun:docker pull cedardb/cedardb:latest
docker run --rm -p 5432:5432 -e CEDAR_PASSWORD=postgres --detach cedardb/cedardb:latest
# Wait a few seconds for CedarDB to start
./server.sh

# in a second terminal window, zoom way out to have no line wraping issues
python3 pyclient.py
Want to discuss DOOMQL with me or find like-minded database nerds? Join our Community Slack]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[X open sourced their latest algorithm]]></title>
            <link>https://github.com/twitter/the-algorithm</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183039</guid>
            <description><![CDATA[Source code for the X Recommendation Algorithm. Contribute to twitter/the-algorithm development by creating an account on GitHub.]]></description>
            <content:encoded><![CDATA[X's Recommendation Algorithm
X's Recommendation Algorithm is a set of services and jobs that are responsible for serving feeds of posts and other content across all X product surfaces (e.g. For You Timeline, Search, Explore, Notifications). For an introduction to how the algorithm works, please refer to our engineering blog.
Architecture
Product surfaces at X are built on a shared set of data, models, and software frameworks. The shared components included in this repository are listed below:



Type
Component
Description




Data
tweetypie
Core service that handles the reading and writing of post data.



unified-user-actions
Real-time stream of user actions on X.



user-signal-service
Centralized platform to retrieve explicit (e.g. likes, replies) and implicit (e.g. profile visits, tweet clicks) user signals.


Model
SimClusters
Community detection and sparse embeddings into those communities.



TwHIN
Dense knowledge graph embeddings for Users and Posts.



trust-and-safety-models
Models for detecting NSFW or abusive content.



real-graph
Model to predict the likelihood of an X User interacting with another User.



tweepcred
Page-Rank algorithm for calculating X User reputation.



recos-injector
Streaming event processor for building input streams for GraphJet based services.



graph-feature-service
Serves graph features for a directed pair of users (e.g. how many of User A's following liked posts from User B).



topic-social-proof
Identifies topics related to individual posts.



representation-scorer
Compute scores between pairs of entities (Users, Posts, etc.) using embedding similarity.


Software framework
navi
High performance, machine learning model serving written in Rust.



product-mixer
Software framework for building feeds of content.



timelines-aggregation-framework
Framework for generating aggregate features in batch or real time.



representation-manager
Service to retrieve embeddings (i.e. SimClusers and TwHIN).



twml
Legacy machine learning framework built on TensorFlow v1.



The product surfaces currently included in this repository are the For You Timeline and Recommended Notifications.
For You Timeline
The diagram below illustrates how major services and jobs interconnect to construct a For You Timeline.

The core components of the For You Timeline included in this repository are listed below:



Type
Component
Description




Candidate Source
search-index
Find and rank In-Network posts. ~50% of posts come from this candidate source.



tweet-mixer
Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services.



user-tweet-entity-graph (UTEG)
Maintains an in memory User to Post interaction graph, and finds candidates based on traversals of this graph. This is built on the GraphJet framework. Several other GraphJet based features and candidate sources are located here.



follow-recommendation-service (FRS)
Provides Users with recommendations for accounts to follow, and posts from those accounts.


Ranking
light-ranker
Light Ranker model used by search index (Earlybird) to rank posts.



heavy-ranker
Neural network for ranking candidate posts. One of the main signals used to select timeline posts post candidate sourcing.


Post mixing & filtering
home-mixer
Main service used to construct and serve the Home Timeline. Built on product-mixer.



visibility-filters
Responsible for filtering X content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking.



timelineranker
Legacy service which provides relevance-scored posts from the Earlybird Search Index and UTEG service.



Recommended Notifications
The core components of Recommended Notifications included in this repository are listed below:



Type
Component
Description




Service
pushservice
Main recommendation service at X used to surface recommendations to our users via notifications.


Ranking
pushservice-light-ranker
Light Ranker model used by pushservice to rank posts. Bridges candidate generation and heavy ranking by pre-selecting highly-relevant candidates from the initial huge candidate pool.



pushservice-heavy-ranker
Multi-task learning model to predict the probabilities that the target users will open and engage with the sent notifications.



Build and test code
We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file. We plan to add a more complete build and test system in the future.
Contributing
We invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official bug bounty program through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better X.
Read our blog on the open source initiative here.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[We all dodged a bullet]]></title>
            <link>https://xeiaso.net/notes/2025/we-dodged-a-bullet/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45183029</guid>
            <description><![CDATA[That NPM attack could have been so much worse.]]></description>
            <content:encoded><![CDATA[ Loading...Please wait a moment while we ensure the security of your connection.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A new experimental Go API for JSON]]></title>
            <link>https://go.dev/blog/jsonv2-exp</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182770</guid>
            <description><![CDATA[Go 1.25 introduces experimental support for encoding/json/jsontext and encoding/json/v2 packages.]]></description>
            <content:encoded><![CDATA[
      Joe Tsai, Daniel MartÃ­, Johan Brandhorst-Satzkorn, Roger Peppe, Chris Hines,  and Damien Neil
      9 September 2025
      
Introduction
JavaScript Object Notation (JSON)
is a simple data interchange format. Almost 15 years ago,
we wrote about support for JSON in Go,
which introduced the ability to serialize and deserialize Go types to and from JSON data.
Since then, JSON has become the most popular data format used on the Internet.
It is widely read and written by Go programs,
and encoding/json now ranks as the 5th most imported Go package.
Over time, packages evolve with the needs of their users,
and encoding/json is no exception. This blog post is about Go 1.25â€™s new
experimental encoding/json/v2 and encoding/json/jsontext packages,
which bring long-awaited improvements and fixes.
This post argues for a new major API version,
provides an overview of the new packages,
and explains how you can make use of it.
The experimental packages are not visible by default and
may undergo future API changes.
Problems with encoding/json
Overall, encoding/json has held up well.
The idea of marshaling and unmarshaling arbitrary Go types
with some default representation in JSON, combined with the ability to
customize the representation, has proven to be highly flexible.
However, in the years since its introduction,
various users have identified numerous shortcomings.
Behavior flaws
There are various behavioral flaws in encoding/json:


Imprecise handling of JSON syntax: Over the years, JSON has seen
increased standardization in order for programs to properly communicate.
Generally, decoders have become stricter at rejecting ambiguous inputs,
to reduce the chance that two implementations will have different
(successful) interpretations of a particular JSON value.


encoding/json currently accepts invalid UTF-8,
whereas the latest Internet Standard (RFC 8259) requires valid UTF-8.
The default behavior should report an error in the presence of invalid UTF-8,
instead of introducing silent data corruption,
which may cause problems downstream.


encoding/json currently accepts objects with duplicate member names.
RFC 8259 does not specify how to handle duplicate names,
so an implementation is free to choose an arbitrary value,
merge the values, discard the values, or report an error.
The presence of a duplicate name results in a JSON value
without a universally agreed upon meaning.
This could be exploited by attackers in security applications
and has been exploited before (as in CVE-2017-12635).
The default behavior should err on the side of safety and reject duplicate names.




Leaking nilness of slices and maps: JSON is often used to communicate with
programs using JSON implementations that do not allow null to be unmarshaled
into a data type expected to be a JSON array or object.
Since encoding/json marshals a nil slice or map as a JSON null,
this may lead to errors when unmarshaling by other implementations.
A survey
indicated that most Go users prefer that nil slices and maps
are marshaled as an empty JSON array or object by default.


Case-insensitive unmarshaling: When unmarshaling, a JSON object member name
is resolved to a Go struct field name using a case-insensitive match.
This is a surprising default, a potential security vulnerability, and a performance limitation.


Inconsistent calling of methods: Due to an implementation detail,
MarshalJSON methods declared on a pointer receiver
are inconsistently called by encoding/json. While regarded as a bug,
this cannot be fixed as too many applications depend on the current behavior.


API deficiencies
The API of encoding/json can be tricky or restrictive:


It is difficult to correctly unmarshal from an io.Reader.
Users often write json.NewDecoder(r).Decode(v),
which fails to reject trailing junk at the end of the input.


Options can be set on the Encoder and Decoder types,
but cannot be used with the Marshal and Unmarshal functions.
Similarly, types implementing the Marshaler and Unmarshaler interfaces
cannot make use of the options and there is no way to plumb options down the call stack.
For example, the Decoder.DisallowUnknownFields option loses its effect
when calling a custom UnmarshalJSON method.


The Compact, Indent, and HTMLEscape functions write to a bytes.Buffer
instead of something more flexible like a []byte or io.Writer.
This limits the usability of those functions.


Performance limitations
Setting aside internal implementation details,
the public API commits it to certain performance limitations:


MarshalJSON: The MarshalJSON interface method forces the implementation
to allocate the returned []byte. Also, the semantics require that
encoding/json verify that the result is valid JSON
and also to reformat it to match the specified indentation.


UnmarshalJSON: The UnmarshalJSON interface method requires that
a complete JSON value be provided (without any trailing data).
This forces encoding/json to parse the JSON value to be unmarshaled
in its entirety to determine where it ends before it can call UnmarshalJSON.
Afterwards, the UnmarshalJSON method itself must parse the provided JSON value again.


Lack of streaming: Even though the Encoder and Decoder types operate
on an io.Writer or io.Reader, they buffer the entire JSON value in memory.
The Decoder.Token method for reading individual tokens is allocation-heavy
and there is no corresponding API for writing tokens.


Furthermore, if the implementation of a MarshalJSON or UnmarshalJSON method
recursively calls the Marshal or Unmarshal function,
then the performance becomes quadratic.
Trying to fix encoding/json directly
Introducing a new, incompatible major version of a package is a heavy consideration.
If possible, we should try to fix the existing package.
While it is relatively easy to add new features,
it is difficult to change existing features.
Unfortunately, these problems are inherent consequences of the existing API,
making them practically impossible to fix within the Go 1 compatibility promise.
We could in principle declare separate names, such as MarshalV2 or UnmarshalV2,
but that is tantamount to creating a parallel namespace within the same package.
This leads us to encoding/json/v2 (henceforth called v2),
where we can make these changes within a seperate v2 namespace
in contrast to encoding/json (henceforth called v1).
Planning for encoding/json/v2
The planning for a new major version of encoding/json spanned years.
In late 2020, spurred on by the inability to fix issues in the current package,
Daniel MartÃ­ (one of the maintainers of encoding/json) first drafted his
thoughts on what a hypothetical v2 package should look like.
Separately, after previous work on the Go API for Protocol Buffers,
Joe Tsai was disapppointed that the protojson package
needed to use a custom JSON implementation because encoding/json was
neither capable of adhering to the stricter JSON standard that the
Protocol Buffer specification required,
nor of efficiently serializing JSON in a streaming manner.
Believing a brighter future for JSON was both beneficial and achievable,
Daniel and Joe joined forces to brainstorm on v2 and
started to build a prototype
(with the initial code being a polished version of the JSON serialization logic from the Go protobuf module).
Over time, a few others (Roger Peppe, Chris Hines, Johan Brandhorst-Satzkorn, and Damien Neil)
joined the effort by providing design review, code review, and regression testing.
Many of the early discussions are publicly available in our
recorded meetings and
meeting notes.
This work has been public since the beginning,
and we increasingly involved the wider Go community,
first with a
GopherCon talk and
discussion posted in late 2023,
formal proposal posted in early 2025,
and most recently adopting encoding/json/v2 as a Go experiment
(available in Go 1.25) for wider-scale testing by all Go users.
The v2 effort has been going on for 5 years,
incorporating feedback from many contributors and also gaining valuable
empirical experience from use in production settings.
Itâ€™s worth noting that itâ€™s largely been developed and promoted by people
not employed by Google, demonstrating that the Go project is a collaborative endeavor
with a thriving global community dedicated to improving the Go ecosystem.
Building on encoding/json/jsontext
Before discussing the v2 API, we first introduce the experimental
encoding/json/jsontext package
that lays the foundation for future improvements to JSON in Go.
JSON serialization in Go can be broken down into two primary components:

syntactic functionality that is concerned with processing JSON based on its grammar, and
semantic functionality that defines the relationship between JSON values and Go values.

We use the terms â€œencodeâ€ and â€œdecodeâ€ to describe syntactic functionality and
the terms â€œmarshalâ€ and â€œunmarshalâ€ to describe semantic functionality.
We aim to provide a clear distinction between functionality
that is purely concerned with encoding versus that of marshaling.
This diagram provides an overview of this separation.
Purple blocks represent types, while blue blocks represent functions or methods.
The direction of the arrows approximately represents the flow of data.
The bottom half of the diagram, implemented by the jsontext package,
contains functionality that is only concerned with syntax,
while the upper half, implemented by the json/v2 package,
contains functionality that assigns semantic meaning to syntactic data
handled by the bottom half.
The basic API of jsontext is the following:
package jsontext

type Encoder struct { ... }
func NewEncoder(io.Writer, ...Options) *Encoder
func (*Encoder) WriteValue(Value) error
func (*Encoder) WriteToken(Token) error

type Decoder struct { ... }
func NewDecoder(io.Reader, ...Options) *Decoder
func (*Decoder) ReadValue() (Value, error)
func (*Decoder) ReadToken() (Token, error)

type Kind byte
type Value []byte
func (Value) Kind() Kind
type Token struct { ... }
func (Token) Kind() Kind

The jsontext package provides functionality for interacting with JSON
at a syntactic level and derives its name from
RFC 8259, section 2
where the grammar for JSON data is literally called JSON-text.
Since it only interacts with JSON at a syntactic level,
it does not depend on Go reflection.
The Encoder and
Decoder
provide support for encoding and decoding JSON values and tokens.
The constructors
accept variadic options
that affect the particular behavior of encoding and decoding.
Unlike the Encoder and Decoder types declared in v1,
the new types in jsontext avoid muddling the distinction between syntax and
semantics and operate in a truly streaming manner.
A JSON value is a complete unit of data and is represented in Go as
a named []byte.
It is identical to RawMessage in v1.
A JSON value is syntactically composed of one or more JSON tokens.
A JSON token is represented in Go as the opaque Token type
with constructors and accessor methods.
It is analogous to Token in v1
but is designed represent arbitrary JSON tokens without allocation.
To resolve the fundamental performance problems with
the MarshalJSON and UnmarshalJSON interface methods,
we need an efficient way of encoding and decoding JSON
as a streaming sequence of tokens and values.
In v2, we introduce the MarshalJSONTo and UnmarshalJSONFrom interface methods
that operate on an Encoder or Decoder, allowing the methodsâ€™ implementations
to process JSON in a purely streaming manner. Thus, the json package need not
be responsible for validating or formatting a JSON value returned by MarshalJSON,
nor would it need to be responsible for determining the boundaries of a JSON value
provided to UnmarshalJSON. These responsibilities belong to the Encoder and Decoder.
Introducing encoding/json/v2
Building on the jsontext package, we now introduce the experimental
encoding/json/v2 package.
It is designed to fix the aforementioned problems,
while remaining familiar to users of the v1 package.
Our goal is that usages of v1 will operate mostly the same if directly migrated to v2.
In this article, we will primarily cover the high-level API of v2.
For examples on how to use it, we encourage readers to
study the examples in the v2 package or
read Anton Zhiyanovâ€™s blog covering the topic.
The basic API of v2 is the following:
package json

func Marshal(in any, opts ...Options) (out []byte, err error)
func MarshalWrite(out io.Writer, in any, opts ...Options) error
func MarshalEncode(out *jsontext.Encoder, in any, opts ...Options) error

func Unmarshal(in []byte, out any, opts ...Options) error
func UnmarshalRead(in io.Reader, out any, opts ...Options) error
func UnmarshalDecode(in *jsontext.Decoder, out any, opts ...Options) error

The Marshal
and Unmarshal functions
have a signature similar to v1, but accept options to configure their behavior.
The MarshalWrite
and UnmarshalRead functions
directly operate on an io.Writer or io.Reader,
avoiding the need to temporarily construct an Encoder or Decoder
just to write or read from such types.
The MarshalEncode
and UnmarshalDecode functions
operate on a jsontext.Encoder and jsontext.Decoder and
is actually the underlying implementation of the previously mentioned functions.
Unlike v1, options are a first-class argument to each of the marshal and unmarshal functions,
greatly extending the flexibility and configurability of v2.
There are several options available
in v2 which are not covered by this article.
Type-specified customization
Similar to v1, v2 allows types to define their own JSON representation
by satisfying particular interfaces.
type Marshaler interface {
    MarshalJSON() ([]byte, error)
}
type MarshalerTo interface {
    MarshalJSONTo(*jsontext.Encoder) error
}

type Unmarshaler interface {
    UnmarshalJSON([]byte) error
}
type UnmarshalerFrom interface {
    UnmarshalJSONFrom(*jsontext.Decoder) error
}

The Marshaler
and Unmarshaler interfaces
are identical to those in v1.
The new MarshalerTo
and UnmarshalerFrom interfaces
allow a type to represent itself as JSON using a jsontext.Encoder or jsontext.Decoder.
This allows options to be forwarded down the call stack, since options
can be retrieved via the Options accessor method on the Encoder or Decoder.
See the OrderedObject example
for how to implement a custom type that maintains the ordering of JSON object members.
Caller-specified customization
In v2, the caller of Marshal and Unmarshal can also specify
a custom JSON representation for any arbitrary type,
where caller-specified functions take precedence over type-defined methods
or the default representation for a particular type.
func WithMarshalers(*Marshalers) Options

type Marshalers struct { ... }
func MarshalFunc[T any](fn func(T) ([]byte, error)) *Marshalers
func MarshalToFunc[T any](fn func(*jsontext.Encoder, T) error) *Marshalers

func WithUnmarshalers(*Unmarshalers) Options

type Unmarshalers struct { ... }
func UnmarshalFunc[T any](fn func([]byte, T) error) *Unmarshalers
func UnmarshalFromFunc[T any](fn func(*jsontext.Decoder, T) error) *Unmarshalers

MarshalFunc and
MarshalToFunc
construct a custom marshaler that can be passed to a Marshal call
using WithMarshalers to override the marshaling of particular types.
Similarly,
UnmarshalFunc and
UnmarshalFromFunc
support similar customization for Unmarshal.
The ProtoJSON example
demonstrates how this feature allows serialization of all
proto.Message types
to be handled by the protojson package.
Behavior differences
While v2 aims to behave mostly the same as v1,
its behavior has changed in some ways
to address problems in v1, most notably:


v2 reports an error in the presence of invalid UTF-8.


v2 reports an error if a JSON object contains a duplicate name.


v2 marshals a nil Go slice or Go map as an empty JSON array or JSON object, respectively.


v2 unmarshals a JSON object into a Go struct using a
case-sensitive match from the JSON member name to the Go field name.


v2 redefines the omitempty tag option to omit a field if it would have
encoded as an â€œemptyâ€ JSON value (which are null, "", [], and {}).


v2 reports an error when trying to serialize a time.Duration,
which currently has no default representation,
but provides options to let the caller decide.


For most behavior changes, there is a struct tag option or caller-specified option
that can configure the behavior to operate under v1 or v2 semantics,
or even other caller-determined behavior.
See â€œMigrating to v2â€ for more information.
Performance optimizations
The Marshal performance of v2 is roughly at parity with v1.
Sometimes it is slightly faster, but other times it is slightly slower.
The Unmarshal performance of v2 is significantly faster than v1,
with benchmarks demonstrating improvements of up to 10x.
In order to obtain greater performance gains,
existing implementations of
Marshaler and
Unmarshaler should
migrate to also implement
MarshalerTo and
UnmarshalerFrom,
so that they can benefit from processing JSON in a purely streaming manner.
For example, recursive parsing of OpenAPI specifications in UnmarshalJSON methods
significantly hurt performance in a particular service of Kubernetes
(see kubernetes/kube-openapi#315),
while switching to UnmarshalJSONFrom improved performance by orders of magnitude.
For more information, see the
go-json-experiment/jsonbench
repository.
Retroactively improving encoding/json
We want to avoid two separate JSON implementations in the Go standard library,
so it is critical that, under the hood, v1 is implemented in terms of v2.
There are several benefits to this approach:


Gradual migration: The Marshal and Unmarshal functions in v1 or v2
represent a set of default behaviors that operate according to v1 or v2 semantics.
Options can be specified that configure Marshal or Unmarshal to operate with
entirely v1, mostly v1 with a some v2, a mix of v1 or v2,
mostly v2 with some v1, or entirely v2 semantics.
This allows for gradual migration between the default behaviors of the two versions.


Feature inheritance: As backward-compatible features are added to v2,
they will inherently be made available in v1. For example, v2 adds
support for several new struct tag options such as inline or format and also
support for the MarshalJSONTo and UnmarshalJSONFrom interface methods,
which are both more performant and flexible.
When v1 is implemented in terms of v2, it will inherit support for these features.


Reduced maintenance: Maintenance of a widely used package demands significant effort.
By having v1 and v2 use the same implementation, the maintenance burden is reduced.
In general, a single change will fix bugs, improve performance, or add functionality to both versions.
There is no need to backport a v2 change with an equivalent v1 change.


While select parts of v1 may be deprecated over time (supposing v2 graduates from being an experiment),
the package as a whole will never be deprecated.
Migrating to v2 will be encouraged, but not required.
The Go project will not drop support for v1.
Experimenting with jsonv2
The newer API in the encoding/json/jsontext and encoding/json/v2 packages are not visible by default.
To use them, build your code with GOEXPERIMENT=jsonv2 set in your environment or with the goexperiment.jsonv2 build tag.
The nature of an experiment is that the API is unstable and may change in the future.
Though the API is unstable, the implementation is of a high quality and
has been successfully used in production by several major projects.
The fact that v1 is implemented in terms of v2 means that the underlying implementation of v1
is completely different when building under the jsonv2 experiment.
Without changing any code, you should be able to run your tests
under jsonv2 and theoretically nothing new should fail:
GOEXPERIMENT=jsonv2 go test ./...

The re-implementation of v1 in terms of v2 aims to provide identical behavior
within the bounds of the Go 1 compatibility promise,
though some differences might be observable such as the exact wording of error messages.
We encourage you to run your tests under jsonv2 and
report any regressions on the issue tracker.
Becoming an experiment in Go 1.25 is a significant milestone on the road to
formally adopting encoding/json/jsontext and encoding/json/v2 into the standard library.
However, the purpose of the jsonv2 experiment is to gain broader experience.
Your feedback will determine our next steps, and the outcome of this experiment,
which may result in anything from abandonment of the effort, to adoption as stable packages of Go 1.26.
Please share your experience on go.dev/issue/71497, and help determine the future of Go.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Disrupting the DRAM roadmap with capacitor-less IGZO-DRAM technology]]></title>
            <link>https://www.imec-int.com/en/articles/disrupting-dram-roadmap-capacitor-less-igzo-dram-technology</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182418</guid>
            <description><![CDATA[This technology review explains hpw 2T0C IGZO-based DRAM opens doors to high-density 3D DRAM and embedded DRAM.]]></description>
            <content:encoded><![CDATA[A novel DRAM memory cell with two IGZO-based transistorsThe bit cell of dynamic random-access memory (DRAM), the main memory within traditional compute architectures, is conceptually very simple. It consists of one capacitor (1C) and one silicon (Si)-based transistor (1T). While the capacitorâ€™s role is to store a charge, the transistor is used to access the capacitor, either to read how much charge is stored or to store a new charge.Over the years, bit cell density scaling allowed the industry to introduce subsequent generations of DRAM technology and cope with the growing demand for DRAM. But since about 2015, DRAM memory technology has struggled to keep pace with the performance improvement of the processorâ€™s logic part: scaling, cost, and power efficiency issues form the building blocks of a rising â€˜memory wallâ€™. The large capacitor constrains scalability and 3D integration of the 1T1C bit cell, the ultimate path towards high-density DRAM. In addition, as the access transistor gets smaller, it provides an increasingly large leakage path for the capacitorâ€™s charge to drain away. This lowers the data retention time and requires DRAM cells to be refreshed more frequently â€“ impacting the power consumption.In 2020, imec reported a novel DRAM bit cell concept that can solve these two issues in one go: a bit cell made up of two thin-film transistors (2T, one for read, one for write) and no capacitor (0C) [1]. The conduction channel of the thin-film transistors is composed of an oxide semiconductor, such as indium-gallium-zinc-oxide (IGZO). Due to its wide bandgap, IGZO-based transistors have an extremely low off current, benefitting the memoryâ€™s retention time, refresh rate, and power consumption. The longer retention time also relaxes the requirement for the storage capacitance, allowing the parasitic capacitance of the read transistor to take over the role of the storage element.In addition, fabricating an IGZO 2T0C bit cell is simpler and more cost-effective than traditional cells. Other than Si, IGZO material can be deposited at relatively low temperatures, making it compatible with back-end-of-line (BEOL) processing. This opens doors to new DRAM architectures. First, it allows the DRAM periphery â€“ the logic transistors that enable the full functionality of the DRAM chip â€“ to be moved under the DRAM memory array instead of residing next to it. This reduces the footprint of the DRAM memory chip and makes connections between the array and periphery more efficient. In this configuration, the 2T0C DRAM bit cells are integrated into the periâ€™s BEOL, which is allowed by the properties of the IGZO material.Second, the novel bit cell paves the way for stacked configurations, providing an additional increase in density. Either â€˜2Dâ€™ or â€˜true 3Dâ€™ stacking can be envisioned. With 2D stacking, several layers with â€˜planarâ€™ DRAM memory arrays are stacked on top of each other. With 3D stacking, the transistors that make up the 2T0C bit cell are stacked and monolithically integrated into vertically aligned plugs inspired by 3D NAND technology. The ability to deposit IGZO conformally in these high-aspect-ratio plugs, enabled by the technique of atomic layer deposition (ALD), is a key enabler of this 3D structure. These stacked configurations will help tear down the memory wall, allowing DRAM memories to continue playing a crucial role in data-intensive applications such as cloud computing and artificial intelligence. Implementing the two transistors on different levels (stacked 2T0C) has an additional benefit. A low-off-current oxide semiconductor channel is only fundamental in the write transistor to ensure long retention. For the read transistor, on current is the critical parameter, as it drives the read time, and high-mobility channel materials can be considered. The two transistors can thus be optimized separately.First â€˜conceptualâ€™ demonstration of an IGZO 2T0C DRAM bit cellAfter pioneering the concept, imec provided the first experimental demonstration of a functional 2T0C DRAM cell at the 2020Â IEEE International Electron Devices Meeting (IEDM) [1]. Thanks to a low (extracted) off currentÂ of 3x10-19A/Âµm, these first 2T0C DRAM cells exhibited a retention time >400s, about 1,000 times longer than typical DRAM refresh times. The results were obtained after scaling and optimizing IGZO-based thin-film transistors processed on 300mm wafers. Optimizations were directed towards suppressing the impact of oxygen and hydrogen defects, one of the main challenges for developing good-performing IGZO-based transistors. Optimized transistors with a 45nm gate length were then integrated into a 2T0C DRAM bit cell architecture, where the parasitic capacitance of the read transistor served as the storage element.Improving performance through bit cell engineering: an overviewNext, imec started to explore the knobs that allow the boosting of 2T0C DRAM density and improve performance and reliability metrics such as off current, data retention, endurance, on current, and threshold voltage (stability). In 2021 at IEDM, imec researchers presented a much-improved IGZO-based 2T0C DRAM bit cell with >1000s retention time and practically unlimited endurance (>1011 read and write cycles) with <10ns write time [2].These breakthrough results followed an optimization of the IGZO transistorâ€™s material stack and integration scheme: a gate-last approach with buried oxygen tunnel and self-aligned contacts combined with a scaled gate dielectric (Al2O3) thickness. Implementing the buried oxide tunnel in combination with an anneal in an O2 ambient reduced the oxygen-vacancy concentration in the IGZO channel, benefitting on and off currents.This IGZO-DRAM technology set the stage for more aggressive DRAM scaling. The gate length of the IGZO transistor was scaled down to 14nm while still preserving >100s retention. The researchers also showed a variant of the 2T0C DRAM cell with much reduced IGZO layer thickness (5nm). This eliminated the need for an oxygen tunnel and O2 anneal step, leading to a simplified process flow. Imec also demonstrated functional transistors with conformally deposited thin IGZO channels (5nm, through ALD), a stepping stone towards 3D DRAM integration. [2]More recently, imec used the reactive ion etch (RIE) technique instead of the commonly used ion beam etch (IBE) for patterning the active module of the 2T0C transistor. RIE allows for patterning at tiny dimensions (sub-100nm) with limited damage, further reducing area consumption. Moreover, using these transistors in 2T0C DRAM bit cells led to a much-improved retention time of >4.5 hours, thanks to an effective suppression of extrinsic leakage paths on the sidewalls of the transistor [3].The potential of imecâ€™s disruptive DRAM concept triggered interest from universities, research institutes, and companies worldwide. Several research groups started investigating other bit cell configurations, transistor performance â€˜boosters,â€™ and alternative oxide semiconductor materials.Â For example, IMECAS (Institute of Microelectronics of the Chinese Academy of Sciences), publishing about 2T0C IGZO DRAM since 2021, demonstrated an alternative 2T0C configuration to benefit multibit operation [4]. Later, they were the first to show transistors with a vertically integrated IGZO channel. The ability to monolithically stack the â€˜verticalâ€™ read and write transistors enables area-efficient 4F2 2D DRAM cell configurations (F being the minimum feature size for a given technology node) [5]. Macronix also implemented a 3D 2T0C bit cell with gate-around (GA) and channel-all-around (CAA) IGZO FETs [6]. Peking University optimized IGZO transistors based on material stack engineering, which enhanced 2T0C DRAM cell performance [7].Thin-film transistors with oxide semiconductor channel materials other than IGZO are also being considered. One promising material is W-doped indium oxide (IWO), as showcased by Notre Dame University [8]. Stanford University initially considered indium-tin-oxide (ITO) for 2T0C implementation [9]. In 2024, in collaboration with TSMC, they also used IWO to build an n-type thin-film transistor. In addition, they were the first to combine the IWO n-type transistor with a p-type transistor also made of an oxide semiconductor (tin-oxide (SnO) in this case) for improved performance and reduction of coupling effects [10]. Most oxide semiconductor transistors are inherently n-type, which is why 2T0C DRAM bit cells usually implement two n-type transistors, for reading and writing.The path to industry-viable IGZO-based 3D DRAM2T0C IGZO-DRAM has recently been added to the long-term DRAM technology roadmap, according to a 2024 report of Yole Intelligence. The technology is envisioned as one of the possible approaches toward a much-desired 3D DRAM. Moreover, the demand for AI on edge devices is expected to surge in the coming years, generating the need for high-density embedded DRAM (eDRAM). The capacitor-less IGZO-DRAM technology is a very attractive candidate for this application. Building on its pioneering activities, imec started developing BEOL-compatible eDRAM implementations.Yet, one key concern has made the memory industry hesitant to adopt IGZO-based DRAM technology: reliability. The n-type IGZO transistors mainly degrade because of the positive bias temperature instability (PBTI), which is manifested as an undesirable shift of the device threshold voltage and a decrease in the drain current. Worrisome is the hydrogen-related contribution to PBTI, a problem less familiar to the chip industry. Through the years, imec has made considerable progress in assessing, understanding, and modeling reliability failure, paving the way to building reliable IGZO transistors with a target lifetime of five years [11,12].This work has been enabled in part by the NanoIC pilot line.Â The acquisition and operation are jointly funded by the Chips Joint Undertaking, through the European Unionâ€™s Digital Europe (101183266) and Horizon Europe programs (101183277), as well as by the participating states Belgium (Flanders), France, Germany, Finland, Ireland and Romania. For more information, visit nanoic-project.eu.This article was originally published in Nature Reviews Electrical Engineering.Want to know more?[1] A. Belmonte et al. Capacitor-less, long-retention (>400s) DRAM cell paving the way towards low-power and high-density monolithic 3D DRAM.Â 2020 IEEE International Electron Devices Meeting.[2] A. Belmonte et al. Tailoring IGZO-TFT architecture for capacitorless DRAM, demonstrating >103s retention, >1011 cycles endurance and Lg scalability down to 14nm.Â 2021 IEEE International Electron Devices Meeting.[3] A. Belmonte et al. Lowest IOFF<3x10-21A/Âµm in capacitorless DRAM achieved by reactive ion etch of IGZO-TFT. 2023 Symposium on VLSI Technology and Circuits.[4] K. Chen et al. Improved multi-bit statistics of novel dual-gate IGZO 2T0C DRAM with In-cell VTH compensation and âˆ†VSN/âˆ†VDATA boosting technique.Â 2023 IEEE International Electron Devices Meeting.[5] F. Liao et al. Novel 4F2 multi-bit dual-gate 2T0C for high-density DRAM with improved vertical-channel IGZO TFTs by self-aligned single-step process.Â 2024 IEEE International Electron Devices Meeting.[6] F.-M. Lee et al. Bit-Cost-Scalable 3D DRAM Architecture and Unit Cell First Demonstrated with Integrated Gate-Around and Channel-Around IGZO FETs. 2024 Symposium on VLSI Technology and Circuits.[7] Q. Hu et al. Optimized IGZO FETs for capacitorless DRAM with retention of 10 ks at RT and 7 ks at 85Â°C at zero Vhold with sub-10ns speed and 3-bit operation.Â 2022 IEEE International Electron Devices Meeting.[8] H. Ye et al. Double-gate W-doped amorphous indium oxide transistors for monolithic 3D capacitorless gain cell eDRAM. 2022 IEEE International Electron Devices Meeting.[9] S. Liu et al. Gain cell memory on logic platform â€“ device guidelines for oxide semiconductor transistor materials development.Â 2023 IEEE International Electron Devices Meeting.[10] F. F. Athena et al.Â First demonstration of an n-p oxide semiconductor complementary gain cell memory. 2024 IEEE International Electron Devices Meeting.[11] A. Chasin et al. Understanding and modelling the PBTI reliability of thin-film IGZO transistors.Â 2024 IEEE International Electron Devices Meeting.[12] A. Chasin et al. Unraveling BTI in IGZO devices: impact of device architecture, channel film deposition method and stoichiometry/phase, and device operating conditions.Â 2024 IEEE International Electron Devices Meeting.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude can now create and edit files]]></title>
            <link>https://www.anthropic.com/news/create-files</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182381</guid>
            <description><![CDATA[Claude can now create and edit Excel spreadsheets, documents, PowerPoint slide decks, and PDFs directly in Claude.ai and the desktop app.]]></description>
            <content:encoded><![CDATA[Claude can now create and edit Excel spreadsheets, documents, PowerPoint slide decks, and PDFs directly in Claude.ai and the desktop app. This transforms how you work with Claudeâ€”instead of only receiving text responses or in-app artifacts, you can describe what you need, upload relevant data, and get ready-to-use files in return.File creation is now available as a preview for Max, Team, and Enterprise plan users. Pro users will get access in the coming weeks.What you can doClaude creates actual files from your instructionsâ€”whether working from uploaded data, researching information, or building from scratch. Here are just a few examples:Turn data into insights: Give Claude raw data and get back polished outputs with cleaned data, statistical analysis, charts, and written insights explaining what matters.Build spreadsheets: Describe what you needâ€”financial models with scenario analysis, project trackers with automated dashboards, or budget templates with variance calculations. Claude creates it with working formulas and multiple sheets.Cross-format work: Upload a PDF report and get PowerPoint slides. Share meeting notes and get a formatted document. Upload invoices and get organized spreadsheets with calculations. Claude handles the tedious work and presents information how you need it.Whether you need a customer segmentation analysis, sales forecasting, or budget tracking, Claude handles the technical work and produces the files you need. File creation turns projects that normally require programming expertise, statistical knowledge, and hours of effort into minutes of conversation.How it works: Claudeâ€™s computerOver the past year we've seen Claude move from answering questions to completing entire projects, and now we're making that power more accessible. We've given Claude access to a private computer environment where it can write code and run programs to produce the files and analyses you need.This transforms Claude from an advisor into an active collaborator. You bring the context and strategy; Claude handles the technical implementation behind the scenes. This shows where weâ€™re headed: making sophisticated multi-step work accessible through conversation. As these capabilities expand, the gap between idea and execution will keep shrinking.Getting startedTo start creating files:Enable "Upgraded file creation and analysis" under Settings > Features > ExperimentalUpload relevant files or describe what you needGuide Claude through the work via chatDownload your completed files or save directly to Google DriveStart with straightforward tasks like data cleaning or simple reports, then work up to complex projects like financial models once you're comfortable with how Claude handles files.This feature gives Claude internet access to create and analyze files, which may put your data at risk. Monitor chats closely when using this feature. Learn more.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[New Mexico is first state in US to offer universal child care]]></title>
            <link>https://www.governor.state.nm.us/2025/09/08/new-mexico-is-first-state-in-nation-to-offer-universal-child-care/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45182372</guid>
            <content:encoded><![CDATA[
				
				
				
				
				
				
				
			SANTA FE â€” Governor Michelle Lujan Grisham and the New Mexico Early Childhood Education and Care Department announced a historic milestone on Monday: New Mexico will become the first state in the nation to guarantee no-cost universal child care starting Nov. 1.
This groundbreaking new initiative will make child care available to all New Mexicans, regardless of income, by removing income eligibility requirements from the stateâ€™s child care assistance program and continuing the waiver of family copayments.
â€œChild care is essential to family stability, workforce participation, and New Mexicoâ€™s future prosperity,â€ said Lujan Grisham. â€œBy investing in universal child care, we are giving families financial relief, supporting our economy, and ensuring that every child has the opportunity to grow and thrive.â€
This announcement fulfills the promise made by the governor and the New Mexico Legislature when they created the Early Childhood Education and Care Department in 2019. Since then, New Mexico has expanded access to no-cost child care to families with incomes at or below 400% of the federal poverty level, reducing financial strain on tens of thousands of families.
With Mondayâ€™s announcement universal child care will be extended to every family in the state, regardless of income. This amounts to an average annual family savings of $12,000 per child.
â€œNew Mexico is creating the conditions for better outcomes in health, learning, and well-being,â€ said Neal Halfon, professor of pediatrics, public health and public policy at the University of California, Los Angeles, and director of the Center for Healthier Children, Families, and Communities. â€œIts approach is rooted in data, driven by communities, and becoming a model for the nation.
â€œBy prioritizing public investments in early childhood educators, families, and children, New Mexico continues to lead the way in building a sustainable, affordable, and quality child care and early learning system that helps its communities and economy thrive,â€ said Michelle Kang, president and CEO of the National Association of the Education of Young Children (NAEYC). â€œAchieving universal child care will make a huge difference for the stateâ€™s children, families, businesses, and educatorsâ€”and for all of us, by showing that it can be done.â€
Families who receive child care assistance report greater financial stability, more time to focus on their children, and the ability to choose higher-quality care settings. Now, every family in New Mexico will have the same opportunity. New Mexico is also taking decisive action to build the supply of infant and toddler care statewide:

Establishing a $12.7 million low-interest loan fund to construct, expand, and renovate child care facilities, with an additional $20 million requested in the Fiscal Year 2027 budget.
Targeting growth to focus on care for infants, toddlers, low-income families, and children with special needs.
Partnering with employers and school districts to expand child care options for working families.
Launching a statewide campaign to recruit licensed and registered home providers.
To support providers, reimbursement rates will rise to reflect the true cost of care.

Programs that commit to paying entry-level staff a minimum of $18 per hour and offer 10 hours of care per day, five days a week, will receive an incentive rate. New Mexico estimates an additional 5,000 early childhood professionals are needed to fully achieve a universal system.
â€œEarly childhood care and education is a public good,â€ said ECECD Sec. Elizabeth Groginsky. â€œBy providing universal access and improving pay for our early childhood workforce, we are easing financial pressure on families, strengthening our economy, and helping every child learn in safe, nurturing environments. This is the kind of investment that builds equity today and prosperity for the future.â€
With universal child care, New Mexico is leading the nation by showing that what is best for children and families is also the smartest investment for long-term prosperityâ€”building a stronger future for every community in the state.
For more information about how families and providers can access universal child care benefits, visit and toolkit: ECECD Universal Child Care Resources Page.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google to Obey South Korean Order to Blur Satellite Images on Maps]]></title>
            <link>https://www.barrons.com/news/google-to-obey-south-korean-order-to-blur-satellite-images-on-maps-653e934e</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45181626</guid>
            <description><![CDATA[Google said on Tuesday that it would comply with the South Korean government's demand to blur sensitive satellite images on its mapping services, paving the way for the US tech giant to compete better with local navigation platforms.]]></description>
            <content:encoded><![CDATA[Google said on Tuesday that it would comply with the South Korean government's demand to blur sensitive satellite images on its mapping services, paving the way for the US tech giant to compete better with local navigation platforms.The Barron's news department was not involved in the creation of the content above. This article was produced by AFP. For more information go to AFP.com.Â© Agence France-Presse]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hallucination Risk Calculator]]></title>
            <link>https://github.com/leochlon/hallbayes</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45180315</guid>
            <description><![CDATA[Contribute to leochlon/hallbayes development by creating an account on GitHub.]]></description>
            <content:encoded><![CDATA[Hallucination Risk Calculator & Prompt Re-engineering Toolkit (OpenAI-only)
Post-hoc calibration without retraining for large language models. This toolkit turns a raw prompt into:

a bounded hallucination risk using the Expectation-level Decompression Law (EDFL), and
a decision to ANSWER or REFUSE under a target SLA, with transparent math (nats).

It supports two deployment modes:

Evidence-based: prompts include evidence/context; rolling priors are built by erasing that evidence.
Closed-book: prompts have no evidence; rolling priors are built by semantic masking of entities/numbers/titles.

All scoring relies only on the OpenAI Chat Completions API. No retraining required.

Table of Contents

Install & Setup
Core Mathematical Framework
Understanding System Behavior
Two Ways to Build Rolling Priors
API Surface
Calibration & Validation
Practical Considerations
Project Layout
Deployment Options


Install & Setup
pip install --upgrade openai
export OPENAI_API_KEY=sk-...

The module uses openai>=1.0.0 and the Chat Completions API (e.g., gpt-4o, gpt-4o-mini).


Core Mathematical Framework
The EDFL Principle
Let the binary event $\mathcal{A}$ be the thing you want to guarantee (e.g., Answer in decision mode, or Correct for factual accuracy).
Build an ensemble of content-weakened prompts (the rolling priors) ${S_k}_{k=1}^m$. For the realized label $y$, estimate:


Information budget:
$$\bar{\Delta} = \tfrac{1}{m}\sum_k \mathrm{clip}_+(\log P(y) - \log S_k(y), B)$$
(one-sided clipping; default $B=12$ nats to prevent outliers while maintaining conservative bounds).


Prior masses: $q_k = S_k(\mathcal{A})$, with:


$\bar{q}=\tfrac{1}{m}\sum_k q_k$ (average prior for EDFL bound)

$q_{\text{lo}}=\min_k q_k$ (worst-case prior for SLA gating)



By EDFL, the achievable reliability is bounded by:
$$\bar{\Delta} \ge \mathrm{KL}(\mathrm{Ber}(p) | \mathrm{Ber}(\bar{q})) \Rightarrow p\le p_{\max}(\bar{\Delta},\bar{q})$$
Thus the hallucination risk (error) is bounded by $\overline{\mathrm{RoH}} \le 1 - p_{\max}$.
Decision Rule (SLA Gating)
For target hallucination rate $h^*$:


Bits-to-Trust: $\mathrm{B2T} = \mathrm{KL}(\mathrm{Ber}(1-h^*) | \mathrm{Ber}(q_{\text{lo}}))$


Information Sufficiency Ratio: $\mathrm{ISR} = \bar{\Delta}/\mathrm{B2T}$


ANSWER iff $\mathrm{ISR}\ge 1$ and $\bar{\Delta} \ge \mathrm{B2T} + \text{margin}$ (default marginâ‰ˆ0.2 nats)


Why two priors? The gate uses worst-case $q_{\text{lo}}$ for strict SLA compliance. The RoH bound uses average $\bar{q}$ per EDFL theory. This dual approach ensures conservative safety while providing realistic risk bounds.


Understanding System Behavior
Expected Behavioral Patterns
The toolkit exhibits different behaviors across query types, which is mathematically consistent with the framework:
Simple Arithmetic Queries
Observation: May abstain despite apparent simplicity
Explanation:

Models often attempt answers even with masked numbers (pattern recognition)
This yields low information lift $\bar{\Delta} \approx 0$ between full prompt and skeletons
Despite potentially low EDFL risk bound, worst-case prior gate triggers abstention (ISR < 1)

Named-Entity Factoids
Observation: Generally answered with confidence
Explanation:

Masking entities/dates substantially reduces answer propensity in skeletons
Restoring these yields large $\bar{\Delta}$ that clears B2T threshold
System answers with tight EDFL risk bound

This is not a bug but a feature: The framework prioritizes safety through worst-case guarantees while providing realistic average-case bounds.
Mitigation Strategies


Switch Event Measurement

Use Correct/Incorrect instead of Answer/Refuse for factual QA
Skeletons without key information rarely yield correct results â†’ large $\bar{\Delta}$




Enhance Skeleton Weakening

Implement mask-aware decision head that refuses on redaction tokens
Ensures skeletons have strictly lower "Answer" mass than full prompt



Calibration Adjustments

Relax $h^*$ slightly (e.g., 0.10 instead of 0.05) for higher answer rates
Reduce margin for less conservative gating
Increase sampling ($n=7-10$) for stability



Provide Evidence

Adding compact, relevant evidence increases $\bar{\Delta}$ while preserving bounds




Two Ways to Build Rolling Priors
1) Evidence-based (when you have context)

Prompt contains a field like Evidence: (or JSON keys)
Skeletons erase the evidence content but preserve structure and roles; then permute blocks deterministically (seeded)
Decision head: "Answer only if the provided evidence is sufficient; otherwise refuse."

Example
from scripts.hallucination_toolkit import OpenAIBackend, OpenAIItem, OpenAIPlanner

backend = OpenAIBackend(model="gpt-4o-mini")
prompt = (
    """Task: Answer strictly based on the evidence below.
Question: Who won the Nobel Prize in Physics in 2019?
Evidence:
- Nobel Prize press release (2019): James Peebles (1/2); Michel Mayor & Didier Queloz (1/2).
Constraints: If evidence is insufficient or conflicting, refuse.
"""
)
item = OpenAIItem(
    prompt=prompt, 
    n_samples=5, 
    m=6, 
    fields_to_erase=["Evidence"], 
    skeleton_policy="auto"
)
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(
    [item], 
    h_star=0.05, 
    isr_threshold=1.0, 
    margin_extra_bits=0.2, 
    B_clip=12.0, 
    clip_mode="one-sided"
)
for m in metrics: 
    print(f"Decision: {'ANSWER' if m.decision_answer else 'REFUSE'}")
    print(f"Rationale: {m.rationale}")
2) Closed-book (no evidence)

Prompt has no evidence
Skeletons apply semantic masking of:

Multi-word proper nouns (e.g., "James Peebles" â†’ "[â€¦]")
Years (e.g., "2019" â†’ "[â€¦]")
Numbers (e.g., "3.14" â†’ "[â€¦]")
Quoted spans (e.g., '"Nobel Prize"' â†’ "[â€¦]")


Masking strengths: Progressive levels (0.25, 0.35, 0.5, 0.65, 0.8, 0.9) across skeleton ensemble
Mask-aware decision head refuses if redaction tokens appear or key slots look missing

Example
from scripts.hallucination_toolkit import OpenAIBackend, OpenAIItem, OpenAIPlanner

backend = OpenAIBackend(model="gpt-4o-mini")
item = OpenAIItem(
    prompt="Who won the 2019 Nobel Prize in Physics?",
    n_samples=7,  # More samples for stability
    m=6,          # Number of skeletons
    skeleton_policy="closed_book"
)
planner = OpenAIPlanner(backend, temperature=0.3, q_floor=None)
metrics = planner.run(
    [item], 
    h_star=0.05,           # Target max 5% hallucination
    isr_threshold=1.0,     # Standard ISR gate
    margin_extra_bits=0.2, # Safety margin in nats
    B_clip=12.0,          # Clipping bound
    clip_mode="one-sided" # Conservative clipping
)
for m in metrics: 
    print(f"Decision: {'ANSWER' if m.decision_answer else 'REFUSE'}")
    print(f"Î”Ì„={m.delta_bar:.4f}, B2T={m.b2t:.4f}, ISR={m.isr:.3f}")
    print(f"EDFL RoH bound={m.roh_bound:.3f}")
Tuning knobs (closed-book):


n_samples=5â€“7 and temperatureâ‰ˆ0.3 stabilize priors

q_floor (Laplace by default: $1/(n+2)$) prevents worst-case prior collapse to 0
Adjust masking strength levels if a task family remains too answerable under masking


API Surface
Core Classes

OpenAIBackend(model, api_key=None) â€“ wraps Chat Completions API
OpenAIItem(prompt, n_samples=5, m=6, fields_to_erase=None, skeleton_policy="auto") â€“ one evaluation item
OpenAIPlanner(backend, temperature=0.5, q_floor=None) â€“ runs evaluation:

run(items, h_star, isr_threshold, margin_extra_bits, B_clip=12.0, clip_mode="one-sided") -> List[ItemMetrics]
aggregate(items, metrics, alpha=0.05, h_star, ...) -> AggregateReport



Helper Functions

make_sla_certificate(report, model_name) â€“ creates formal SLA certificate
save_sla_certificate_json(cert, path) â€“ exports certificate for audit
generate_answer_if_allowed(backend, item, metric) â€“ only emits answer if decision was ANSWER

ItemMetrics Fields
Every ItemMetrics includes:


delta_bar: Information budget (nats)

q_conservative: Worst-case prior $q_{\text{lo}}$


q_avg: Average prior $\bar{q}$


b2t: Bits-to-Trust requirement

isr: Information Sufficiency Ratio

roh_bound: EDFL hallucination risk bound

decision_answer: Boolean decision

rationale: Human-readable explanation

meta: Dict with q_list, S_list_y, P_y, closed_book, etc.


Calibration & Validation
Validation Set Calibration
On a labeled validation set:


Sweep the margin parameter from 0 to 1 nats
For each margin, compute:

Empirical hallucination rate among answered items
Wilson upper bound at 95% confidence



Select smallest margin where Wilson upper bound â‰¤ target $h^*$ (e.g., 5%)

Freeze policy: $(h^*, \tau, \text{margin}, B, \text{clip_mode}, m, r, \text{skeleton_policy})$


Portfolio Reporting
The toolkit provides comprehensive metrics:

Answer/abstention rates
Empirical hallucination rate + Wilson bound
Distribution of per-item EDFL RoH bounds
Worst-case and median risk bounds
Complete audit trail


Practical Considerations
Choosing the Right Event
The default event is the decision $\mathcal{A} = {\text{Answer}}$. However:



Task Type
Recommended Event
Rationale




Factual QA
Correct/Incorrect
Directly measures hallucination


Decision Support
Answer/Refuse
Measures confidence to respond


Creative Writing
Answer/Refuse
Correctness often undefined



For tasks where skeletons still trigger answers frequently (causing $\bar{\Delta}\approx0$), switching to Correctness event with task-specific grading dramatically improves performance.
Common Issues & Solutions
Issue: $\bar{\Delta} = 0$ with $\overline{\mathrm{RoH}} \approx 0$

Not a contradiction! The gate uses worst-case $q_{\text{lo}}$; the bound uses average $\bar{q}$.

Solution: Increase n_samples, lower decision temperature, ensure skeletons truly weaken the event

Issue: Hit a low $\bar{\Delta}$ ceiling
Cause: Clipping may be too aggressive

Solution: Increase B_clip (default 12) and use clip_mode="one-sided"

Issue: Arithmetic still refuses
Cause: Pattern recognition allows answers even with masked numbers

Solutions:

Switch to Correctness event
Reduce masking strength for numbers on subset of skeletons
Provide worked examples as evidence



Issue: Prior collapse ($q_{\text{lo}} \to 0$)
Cause: All skeletons strongly refuse


Solution: Apply prior floor (default Laplace: $1/(n+2)$) or use quantile prior

Performance Characteristics



Metric
Typical Value
Notes




Latency per item
2-5 seconds
7 samples Ã— 7 variants (1 full + 6 skeletons)


API calls
$(1+m) \times \lceil n/\text{batch}\rceil$
Can be parallelized


Accuracy
Wilson-bounded at 95%
Empirically validated


Cost
~$0.01-0.03 per item
Using gpt-4o-mini



Stability Guidelines


Sampling parameters:

Use $n \ge 5$ samples per variant
Keep temperature $\in [0.2, 0.5]$ for decision head
Lower temperature â†’ more stable priors



Skeleton ensemble:

Use $m \ge 6$ skeletons
Ensure diversity in masking strengths
Verify skeletons are meaningfully weaker



Clipping strategy:

Always use one-sided clipping for conservative bounds
Set $B \ge 10$ nats to avoid artificial ceilings
Monitor clipping frequency in logs




Project Layout
.
â”œâ”€â”€ app/                    # Application entry points
â”‚   â”œâ”€â”€ web/web_app.py     # Streamlit UI
â”‚   â”œâ”€â”€ cli/frontend.py    # Interactive CLI
â”‚   â”œâ”€â”€ examples/          # Example scripts
â”‚   â””â”€â”€ launcher/entry.py  # Unified launcher
â”œâ”€â”€ scripts/               # Core module
â”‚   â”œâ”€â”€ hallucination_toolkit.py
â”‚   â””â”€â”€ build_offline_backend.sh
â”œâ”€â”€ electron/              # Desktop wrapper
â”œâ”€â”€ launch/                # Platform launchers
â”œâ”€â”€ release/              # Packaged artifacts
â”œâ”€â”€ bin/                  # Offline backend binary
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md


Deployment Options
1. Direct Python Usage
from scripts.hallucination_toolkit import (
    OpenAIBackend, OpenAIItem, OpenAIPlanner,
    make_sla_certificate, save_sla_certificate_json
)

# Configure and run
backend = OpenAIBackend(model="gpt-4o-mini")
items = [OpenAIItem(prompt="...", n_samples=7, m=6)]
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(items, h_star=0.05)

# Generate SLA certificate
report = planner.aggregate(items, metrics)
cert = make_sla_certificate(report, model_name="GPT-4o-mini")
save_sla_certificate_json(cert, "sla.json")
2. Web Interface (Streamlit)
streamlit run app/web/web_app.py
3. One-Click Launcher

Windows: Double-click launch/Launch App.bat
macOS: Double-click launch/Launch App.command
Linux: Run bash launch/launch.sh

First run creates .venv and installs dependencies automatically.
4. Desktop App (Electron)
Development:
cd electron
npm install
npm run start
Build installers:
npm run build
5. Offline Backend (PyInstaller)
Build single-file executable:
# macOS/Linux
bash scripts/build_offline_backend.sh

# Windows
scripts\build_offline_backend.bat
Creates bin/hallucination-backend[.exe] with bundled Python, Streamlit, and dependencies.

Minimal End-to-End Example
from scripts.hallucination_toolkit import (
    OpenAIBackend, OpenAIItem, OpenAIPlanner,
    make_sla_certificate, save_sla_certificate_json,
    generate_answer_if_allowed
)

# Setup
backend = OpenAIBackend(model="gpt-4o-mini")

# Prepare items
items = [
    OpenAIItem(
        prompt="Who won the 2019 Nobel Prize in Physics?",
        n_samples=7,
        m=6,
        skeleton_policy="closed_book"
    ),
    OpenAIItem(
        prompt="If James has 5 apples and eats 3, how many remain?",
        n_samples=7,
        m=6,
        skeleton_policy="closed_book"
    )
]

# Run evaluation
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(
    items,
    h_star=0.05,           # Target 5% hallucination max
    isr_threshold=1.0,     # Standard threshold
    margin_extra_bits=0.2, # Safety margin
    B_clip=12.0,          # Clipping bound
    clip_mode="one-sided" # Conservative mode
)

# Generate report and certificate
report = planner.aggregate(items, metrics, alpha=0.05, h_star=0.05)
cert = make_sla_certificate(report, model_name="GPT-4o-mini")
save_sla_certificate_json(cert, "sla_certificate.json")

# Show results
for item, m in zip(items, metrics):
    print(f"\nPrompt: {item.prompt[:50]}...")
    print(f"Decision: {'ANSWER' if m.decision_answer else 'REFUSE'}")
    print(f"Risk bound: {m.roh_bound:.3f}")
    print(f"Rationale: {m.rationale}")
    
    # Generate answer if allowed
    if m.decision_answer:
        answer = generate_answer_if_allowed(backend, item, m)
        print(f"Answer: {answer}")
License
This project is licensed under the MIT License â€” see the LICENSE file for details.
Attribution
Developed by Hassana Labs (https://hassana.io).
This implementation follows the framework from the paper â€œCompression Failure in LLMs: Bayesian in Expectation, Not in Realizationâ€ (NeurIPS 2024 preprint) and related EDFL/ISR/B2T methodology.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You too can run malware from NPM (I mean without consequences)]]></title>
            <link>https://github.com/naugtur/running-qix-malware</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45179889</guid>
            <description><![CDATA[Contribute to naugtur/running-qix-malware development by creating an account on GitHub.]]></description>
            <content:encoded><![CDATA[You too can run malware from NPM (I mean without consequences)
Phishing NPM package authors continues, unsurprisingly.
The stakes are not high enough to switch from phishing to anything more advanced (like https://xkcd.com/538/) but seeing article blurbs say "Supply chain Attack" next to "These packages generally receive 2-3 billion downloads per week." might finally be enough to make an impression, one hopes.
This is not a detailed analysis of the attack, there's plenty of that already. If you're looking for one, visit our friends at https://socket.dev/blog/npm-author-qix-compromised-in-major-supply-chain-attack
Instead, let's look at how you could have a compromised dependency like that get into your app and be stopped.
One of the compromised packages was is-arrayish and I'll use that as an example going forward.
What the malware does
So if an app uses is-arrayish in the browser, it will override fetch, XMLHttpRequest and window.ethereum.request and whenever it finds a transaction being sent, it'll replace the target address with one of the malware author's addresses that looks most alike.
I won't go into this either, but you can take a look at the summary of "donations" some other friends linked to here: https://intel.arkm.com/explorer/entity/61fbc095-f19b-479d-a037-5469aba332ab
Pretty low impact for an attack this big. Some of it seems to be people mocking the malware author with worthless transfers.
Let's see it in action
Say we have an app.
The app allows the user to send a meaningless transaction to themselves. Don't expect it to make sense.
It also uses is-arrayish because otherwise we'd have nothing to demo.
const isArrayish = require("is-arrayish");

const button = document.createElement("button");
button.textContent = "Send ETH Transaction";
document.body.appendChild(button);

button.addEventListener("click", async () => {
  const accounts = await window.ethereum.request({
    method: "eth_requestAccounts",
  });
  if (!isArrayish(accounts)) {
    throw new Error("Accounts response must be array-like");
  }
  const myAddr = accounts[0];

  const txHash = await window.ethereum.request({
    method: "eth_sendTransaction",
    params: [
      {
        value: "0x5af3107a4000",
        from: myAddr,
        to: myAddr,
      },
    ],
  });
  console.log("Transaction sent:", txHash);
});
This is what it looks like:

Now after you update is-arrayish to 0.3.3 and rebuild the project, you might notice a slight difference.

Enter LavaMoat
If your project was set up with LavaMoat, you'd be using a policy to decide which package is allowed access to what. More about policies in the guide
With LavaMoat, all is-arrayish can do is fail:

TypeError: Cannot define property fetch, object is not extensible

BTW, If the malware was written a little better to avoid detection and fail silently, the functionality of the app would be fully restored.
LavaMoat Webpack Plugin
To protect the project, @lavamoat/webpack was used.
In short, what it does is: it puts modules from every dependency in a separate lexical global context that we call Compartment and only allows access to globals that the policy lists. I also controls which packages can import which other packages.
If the project dependency gets updated to contain malicious code, the policy will not allow it to access any globals or imports it didn't use before.
Read more in the official guide
If you prefer watching videos, there's some here https://naugtur.pl/flix.
]]></content:encoded>
        </item>
    </channel>
</rss>