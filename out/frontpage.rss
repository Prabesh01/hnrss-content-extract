<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Thu, 28 Aug 2025 13:27:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[The Cost of Transparency: Living with Schizoaffective Disorder in Tech]]></title>
            <link>https://kennethreitz.org/essays/2025-08-27-the_cost_of_transparency</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45051584</guid>
            <description><![CDATA[The Cost of Transparency: Living with Schizoaffective Disorder in Tech - An essay by Kenneth Reitz]]></description>
            <content:encoded><![CDATA[
        
August 2025
"We celebrate mental health awareness until someone actually needs mental health support."
In The Inclusion Illusion, I explored how tech companies perform diversity while quietly eliminating employees who actually need accommodations. What I didn't share was the personal cost of that analysis—how living openly with schizoaffective disorder has systematically excluded me from the very communities I helped build.
Over the past few years, I've worked for at least twenty companies, cycling through positions as organizations discovered my mental health history and found creative ways to make me unwelcomeThis isn't job-hopping by choice—it's a survival pattern forced by systematic exclusion. Each departure followed the same script: initial technical success, mental health disclosure or visibility, growing discomfort, elegant elimination.. The pattern is consistent: initial enthusiasm for my technical contributions, followed by discomfort when my condition becomes visible, and finally the inevitable "restructuring" or "cultural fit" conversations that push me toward the exit.
This isn't paranoia—it's pattern recognition honed by lived experience.
The Mental Health Care Paradox
The discrimination starts in healthcare itself. When I seek treatment for schizoaffective disorder, providers often approach me with a mixture of fear and condescension that would be immediately recognized as unacceptable if directed at any other patient population.
I've had therapists decline to continue working with me without clear explanations, leaving me to wonder whether my openness about my condition or my technical background created discomfort they couldn't navigate. I've had doctors become visibly afraid of me after witnessing me during an acute episode, their fear palpable in subsequent interactions. During inpatient treatment, I've been accused of not taking prescribed medication when I was compliant, as if the persistence of symptoms could only be explained by patient deception rather than the complex reality of treatment-resistant episodes.
The message is clear: people with schizoaffective disorder are expected to be passive victims of their condition, not active participants in their own care. When we demonstrate competence, insight, or agency, we become threatening rather than inspiring.
Professional Exclusion
In professional settings, the discrimination is more subtle but equally systematic. Companies tout their mental health benefits and neurodiversity initiatives right up until they encounter someone whose mental health needs actual accommodation.
I've been excluded from team meetings after disclosing my condition, with managers explaining they wanted to "reduce stress" for meThis "benevolent" exclusion is particularly insidious because it's framed as care while actually removing you from critical decision-making and visibility opportunities that affect career advancement.. I've had colleagues avoid working with me after learning about my diagnosis, their discomfort palpable in every interaction. I've been passed over for promotions with vague explanations about "communication style" that clearly referenced my openness about mental health challenges"Communication style," "cultural fit," and "leadership presence" have become euphemisms for disability discrimination in performance reviews, providing legal cover for eliminating employees with mental health conditions..
The twenty-plus companies I've cycled through represent a pattern of organizations that genuinely believe they're progressive and inclusive. They sponsor diversity conferences, implement mental health awareness training, and celebrate neurodiversity—until they encounter the reality of what supporting someone with a severe mental illness actually requires.
Each departure follows a similar script: initial excitement about my technical contributions, growing discomfort as my condition becomes visible during routine workplace stress, and finally the careful choreography of making me unwelcome without explicitly mentioning my mental health. It's discrimination by a thousand paper cuts, each individually deniable but collectively devastating.
Open Source Ostracism
The Python community's response to my mental health advocacy has been particularly painful. This is a community I helped build, one that benefits from tools I created, yet it has systematically excluded me as I've become more open about living with schizoaffective disorderRequests alone has over 20 million downloads daily and powers much of the modern web, yet the community that benefits from this contribution has made it clear that mental health disclosure makes you too uncomfortable to include in leadership or speaking opportunities..
I've watched as former collaborators distance themselves, conference invitations dry up, and contributions get scrutinized with a level of suspicion not applied to other developers. The community celebrates the abstract idea of mental health awareness while making it clear that actual mental health disclosure makes you a liability.
A perfect example: the Python documentary releases tomorrow, featuring interviews with Python community leaders and contributors. Despite creating one of the most foundational Python libraries in history, I wasn't even contacted about participating. No email, no mention, complete invisibility. The omission speaks volumes about how mental health disclosure transforms you from community asset to community liabilityTo be clear, the documentary appears focused on Python's origin story rather than popular libraries, so I'm not upset about the exclusion itself. But the complete lack of outreach—not even a courtesy email—fits the broader pattern of invisibility I've experienced since my mental health disclosure..


The message from open source leadership is unmistakable: you can advocate for mental health in general terms, but if you make your own struggles visible, you become too uncomfortable to include. The very transparency that helped normalize mental health discussions in tech has made me persona non grata in spaces I helped create.
Personal Relationship Casualties
Perhaps most devastating is how mental health disclosure affects personal relationships. Friends, romantic partners, and social connections often initially express support for mental health awareness, right up until they encounter the reality of schizoaffective disorder.
I've lost friendships when people learned my diagnosis, with former friends suddenly finding excuses to avoid contact. I've had romantic relationships end when partners realized that dating someone with schizoaffective disorder meant occasional difficult conversations about symptoms, medication, and hospitalization risks. I've been excluded from social gatherings where my presence might make others "uncomfortable."
But there are exceptions that prove the rule—people like Sarah, whose response to learning about my condition was to educate herself, offer genuine support, and treat me as a complete person rather than a diagnosis. As she puts it:

"Your condition really can't be learned about. It's so abstract it must be experienced."

This wisdom—recognizing the limits of external understanding while still offering genuine support—represents how people should respond to mental health disclosure. These relationships are rare enough to be remarkable, which itself illustrates the problem.
The isolation is profound. The very condition that most requires social support becomes the barrier to accessing it.
The Stakes: Life and Death Statistics
The discrimination I'm documenting isn't just about hurt feelings or career setbacks—it has life-and-death consequences for people with schizoaffective disorder:
Life Expectancy: People with schizoaffective disorder live 8-17.5 years less than the general population, with women facing even greater mortality risk than menA 2011 study found average life expectancy of 64.1-69.4 years for people with schizoaffective disorder, compared to normal life expectancy. The gap is primarily attributed to cardiovascular disease, diabetes, respiratory problems, and suicide risk..
Homelessness: Among homeless populations, schizoaffective disorder affects 11-28% of individuals—a rate roughly 15-40 times higher than in the general populationRecent studies show only 5% of homeless individuals are diagnosed with schizoaffective disorder at admission, but 28% receive this diagnosis by discharge, suggesting massive underdiagnosis in this vulnerable population.. People with the condition experience longer psychiatric hospitalizations and more frequent healthcare crises.
Healthcare System Failure: The homeless population with schizoaffective disorder suffers from "diagnostic variability" and frequent emergency room visits, often cycling through multiple diagnoses without achieving clinical remission or therapeutic goalsThe diagnostic instability reflects both the complexity of the condition and systemic failures in providing consistent care to people experiencing homelessness and severe mental illness..
These aren't abstract statistics—they represent the human cost of the systematic exclusion I've experienced. When healthcare discriminates, when employers eliminate us, when communities ostracize us, people with schizoaffective disorder literally die younger and more often become homeless.
The Fear Behind the Discrimination
What drives this systematic exclusion is fear—fear of the unknown, fear of mental illness, and particularly fear of schizoaffective disorder's association with psychosis. People can intellectually support mental health awareness while being viscerally uncomfortable with conditions that challenge their assumptions about consciousness, reality, and social functioning.
Schizoaffective disorder carries stigma that depression and anxiety don't. People can relate to feeling sad or worried; they cannot relate to experiencing reality differently. The moment someone learns you've had psychotic episodes, you become fundamentally Other in their perception—no longer fully human, no longer fully trustworthy, no longer safe to include.
This fear is reinforced by media portrayals, social stereotypes, and the medical model's emphasis on pathology over person. People see the diagnosis before they see the individual, the condition before the contributions.

I face an impossible choice: remain silent about my condition and pass as neurotypical, or live authentically and face systematic exclusion. Neither option is sustainable.
Silence means constantly monitoring my behavior for signs that might reveal my condition, avoiding discussions of mental health that might trigger suspicion, and living with the constant anxiety that discovery will lead to rejection. It means being unable to advocate for accommodations I need, being forced to suffer in isolation, and perpetuating the very stigma that makes others afraid to seek help.
Transparency means facing the discrimination I've documented—professional exclusion, social isolation, and the constant emotional labor of educating people about a condition they'd rather not understandThe emotional labor is exhausting: constantly explaining that psychosis doesn't make you dangerous, that medication doesn't make you less competent, that accommodation needs don't make you unreliable. You become a one-person education campaign while trying to do your actual job.. It means accepting that my openness will cost me opportunities, relationships, and belonging in communities I helped create.
But transparency also means modeling that people with schizoaffective disorder can be productive, insightful, and valuable community members. It means challenging the assumptions that drive discrimination. It means refusing to disappear into the shame that society expects from people with severe mental illness.
What Needs to Change
The pattern of discrimination I've experienced isn't unique—it's systematic. People with schizoaffective disorder face exclusion across all sectors of society, from healthcare to employment to personal relationships. The problem isn't individual prejudice but structural stigma that makes our very existence uncomfortable for others.
Real inclusion means:

Healthcare providers who approach patients with schizoaffective disorder as partners in care rather than subjects to be managed. It means recognizing that insight into one's condition is a strength, not a manipulation, and that people with lived experience often understand their needs better than external observers.
Professional environments that provide actual accommodation rather than performative awareness. This means flexible work arrangements during symptom management, understanding that medication changes affect performance temporarily, and recognizing that mental health disclosure should be met with support rather than suspicion.
Communities that welcome the full spectrum of neurodiversity, including conditions that make people uncomfortable. The Python community, and tech culture generally, must move beyond celebrating abstract diversity toward actually including people whose neurodifference challenges social norms.
Personal relationships based on understanding rather than fear. This requires education about schizoaffective disorder, recognition that mental illness doesn't define personality or worth, and commitment to inclusion even when it requires emotional labor.

Moving Forward
I'm done apologizing for living openly with schizoaffective disorder. The discrimination I've faced isn't my fault—it's a reflection of society's failure to move beyond tokenistic awareness toward genuine inclusion.
My condition doesn't make me less competent, less valuable, or less worthy of belonging. The tools I've created serve millions of developers; the insights I've shared have helped normalize mental health discussions in tech; the transparency I've modeled has encouraged others to seek help rather than suffer in silenceI regularly receive messages from developers who say my openness about mental health gave them permission to seek treatment, disclose their own conditions, or simply feel less alone. The personal cost of transparency has created collective benefit for others facing similar struggles..
The twenty companies that couldn't handle my openness about schizoaffective disorder represent their failure, not mine. The professional opportunities lost to stigma reflect society's limitations, not my worth. The relationships that couldn't survive mental health disclosure weren't relationships worth preserving.
I will continue living authentically, advocating openly, and refusing to disappear into the shame that society expects from people with severe mental illness. The cost of transparency has been high, but the cost of silence—both personal and societal—is higher.
People with schizoaffective disorder deserve better than systematic exclusion dressed up as concern. We deserve healthcare that treats us as partners, workplaces that provide actual accommodation, communities that welcome our contributions, and relationships based on understanding rather than fear.
Until that changes, I'll keep paying the cost of transparency—because the alternative is accepting a world where people like me are expected to remain invisible, untreated, and alone.
That's a cost too high to bear.

If you're living with schizoaffective disorder and facing discrimination, you're not alone. The patterns I've described are systematic, not personal failures. Your worth isn't determined by others' comfort with your condition.

    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[That boolean should probably be something else]]></title>
            <link>https://ntietz.com/blog/that-boolean-should-probably-be-something-else/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45051361</guid>
            <description><![CDATA[One of the first types we learn about is the boolean.
It's pretty natural to use, because boolean logic underpins much of modern computing.
And yet, it's one of the types we should probably be using a lot less of.
In almost every single instance when you use a boolean, it should be something else.]]></description>
            <content:encoded><![CDATA[One of the first types we learn about is the boolean.
It's pretty natural to use, because boolean logic underpins much of modern computing.
And yet, it's one of the types we should probably be using a lot less of.
In almost every single instance when you use a boolean, it should be something else.
The trick is figuring out what "something else" is.
Doing this is worth the effort.
It tells you a lot about your system, and it will improve your design (even if you end up using a boolean).
There are a few possible types that come up often, hiding as booleans.
Let's take a look at each of these, as well as the case where using a boolean does make sense.
This isn't exhaustive—[1]there are surely other types that can make sense, too.
Datetimes
A lot of boolean data is representing a temporal event having happened.
For example, websites often have you confirm your email.
This may be stored as a boolean column, is_confirmed, in the database.
It makes a lot of sense.
But, you're throwing away data: when the confirmation happened.
You can instead store when the user confirmed their email in a nullable column.
You can still get the same information by checking whether the column is null.
But you also get richer data for other purposes.
Maybe you find out down the road that there was a bug in your confirmation process.
You can use these timestamps to check which users would be affected by that, based on when their confirmation was stored.
This is the one I've seen discussed the most of all these.
We run into it with almost every database we design, after all.
You can detect it by asking if an action has to occur for the boolean to change values, and if values can only change one time.
If you have both of these, then it really looks like it is a datetime being transformed into a boolean.
Store the datetime!
Enums
Much of the remaining boolean data indicates either what type something is, or its status.
Is a user an admin or not?
Check the is_admin column!
Did that job fail?
Check the failed column!
Is the user allowed to take this action?
Return a boolean for that, yes or no!
These usually make more sense as an enum.
Consider the admin case: this is really a user role, and you should have an enum for it.
If it's a boolean, you're going to eventually need more columns, and you'll keep adding on other statuses.
Oh, we had users and admins, but now we also need guest users and we need super-admins.
With an enum, you can add those easily.
enum UserRole {
  User,
  Admin,
  Guest,
  SuperAdmin,
}

And then you can usually use your tooling to make sure that all the new cases are covered in your code.
With a boolean, you have to add more booleans, and then you have to make sure you find all the places where the old booleans were used and make sure they handle these new cases, too.
Enums help you avoid these bugs.
Job status is one that's pretty clearly an enum as well.
If you use booleans, you'll have is_failed, is_started, is_queued, and on and on.
Or you could just have one single field, status, which is an enum with the various statuses.
(Note, though, that you probably do want timestamp fields for each of these events—but you're still best having the status stored explicitly as well.)
This begins to resemble a state machine once you store the status, and it means that you can make much cleaner code and analyze things along state transition lines.
And it's not just for storing in a database, either.
If you're checking a user's permissions, you often return a boolean for that.
fn check_permissions(user: User) -> bool {
  false // no one is allowed to do anything i guess
}

In this case, true means the user can do it and false means they can't.
Usually. I think.
But you can really start to have doubts here, and with any boolean, because the application logic meaning of the value cannot be inferred from the type.
Instead, this can be represented as an enum, even when there are just two choices.
enum PermissionCheck {
  Allowed,
  NotPermitted(reason: String),
}

As a bonus, though, if you use an enum?
You can end up with richer information, like returning a reason for a permission check failing.
And you are safe for future expansions of the enum, just like with roles.
You can detect when something should be an enum a proliferation of booleans which are mutually exclusive or depend on one another.
You'll see multiple columns which are all changed at the same time.
Or you'll see a boolean which is returned and used for a long time.
It's important to use enums here to keep your program maintainable and understandable.
Conditionals
But when should we use a boolean?
I've mainly run into one case where it makes sense: when you're (temporarily) storing the result of a conditional expression for evaluation.
This is in some ways an optimization, either for the computer (reuse a variable[2]) or for the programmer (make it more comprehensible by giving a name to a big conditional) by storing an intermediate value.
Here's a contrived example where using a boolean as an intermediate value.
fn calculate_user_data(user: User, records: RecordStore) {
  // this would be some nice long conditional,
  // but I don't have one. So variables it is!
  let user_can_do_this: bool = (a && b) && (c || !d);

  if user_can_do_this && records.ready() {
    // do the thing
  } else if user_can_do_this && records.in_progress() {
    // do another thing
  } else {
    // and something else!
  }
}

But even here in this contrived example, some enums would make more sense.
I'd keep the boolean, probably, simply to give a name to what we're calculating.
But the rest of it should be a match on an enum!
* * *
Sure, not every boolean should go away.
There's probably no single rule in software design that is always true.
But, we should be paying a lot more attention to booleans.
They're sneaky.
They feel like they make sense for our data, but they make sense for our logic.
The data is usually something different underneath.
By storing a boolean as our data, we're coupling that data tightly to our application logic.
Instead, we should remain critical and ask what data the boolean depends on, and should we maybe store that instead?
It comes easier with practice.
Really, all good design does.
A little thinking up front saves you a lot of time in the long run.


I know that using an em-dash is treated as a sign of using LLMs.
LLMs are never used for my writing.
I just really like em-dashes and have a dedicated key for them on one of my keyboard layers. ↩


This one is probably best left to the compiler. ↩



  If you're looking to grow more effective as a software engineer, please consider my coaching services.
  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Group Borrowing: Zero-Cost Memory Safety with Fewer Restrictions]]></title>
            <link>https://verdagon.dev/blog/group-borrowing</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45051345</guid>
            <description><![CDATA[Aug 28, 2025
        

                 —]]></description>
            <content:encoded><![CDATA[
  

        
          
  

            
    

              
    

              Aug 28, 2025
        

                 — 
          

                
        

              
      

            
    


If you've read my blog before, you know that memory safety is a huge unsolved problem, and that there's a vast unexplored space between the various memory safety models. The discerning eye can infer that we're starting to see the lines blur between these seemingly unrelated memory safety approaches.





This is ridiculously exciting to me, because today's popular memory-safe languages are very limited: they're fast, or they're flexible, but not both. Finding new blends is an incredibly challenging and worthy endeavor... one which has claimed the sanity of many explorers.





A few of us have been approaching the problem by starting with reference counting or garbage collection (or generational references!) and allowing functions to "borrow" those objects with much less--or zero--overhead. 0


In my biased 1 opinion, these approaches have some strong benefits. But they're not a panacea, and the world needs more approaches here.





And luckily, my good friend Nick Smith (from the Mojo community 2) has been exploring exactly that for the past few years.


I think he's found a way to add mutable aliasing directly into a borrow checker without building on a foundation of reference counting, garbage collection, or generational references. In other words, an approach for zero-overhead mutable aliasing, which is a big deal. 3





After reading his original explanation here, I knew that it should definitely be more widely known. He's graciously allowed me to take a shot at explaining it, so here we are!





I'll try to explain the approach as simply as possible, but if you have any questions, Nick can be found in the Mojo server (username nick.sm), or feel free to ask me in the r/vale subreddit or the Vale discord's #languages channel. And if you find this interesting, consider sponsoring Nick!





Also, this article is gloriously long and has a lot of context, so I'll let you know when to skip ahead.




      
  


      
      Group Borrowing: Zero-Cost Memory Safety with Fewer Restrictions
    


 Foundation: Builds on C++'s "Single Ownership"


 Recap of Rust Borrowing



 Context and Comments on Borrow Checking Limitations


 An example



 Nick's Borrowing System



 Basic Mutable Aliasing


 When to Invalidate References to Contents



 A More Complex Example



 Child groups



 print(hp_ref)


 print(ring_ref)


 print(len(rings_list_ref))


 print(s.durability)


 Child Groups, Summarized



 Where do groups come from?


 Isolation


 Functions' Group Annotations



 A More Complex Example


 Paths


 Syntax



 The approach, summarized


 Does the approach really not have unique references?



 Comparison to Borrow Checking


 Where we go from here


 Conclusion



      
      
    

      
    


1

My language Vale uses one of these approaches, so I'm of course biased to see its benefits more strongly than others!





2

Disclaimer: I work on the Mojo team at Modular! But I'll keep this post more about Nick's discovery in general, rather than how it would do in any specific language.





3

My long-time readers will recognize my cognitive dissonance here because I think such a thing is a myth.

Nick's approach makes me question that, though. At the very least, we're much closer to achieving the myth, if he hasn't solved it completely already.





        
    


    
    
  


 Foundation: Builds on C++'s "Single Ownership"

TL;DR: Nick's approach is based on single ownership, like C++ and Rust. Every value is "owned" by a containing object, array, stack frame, or global.


If you know how C++ and Rust work already, skip ahead!





If you don't know, or just like reading, I'll explain what single ownership is.





For example if we have this C++ program:


    
      
      #include <vector>
struct Engine { int fuel; };
struct Spaceship { unique_ptr<Engine> engine; };
void foo(vector<Spaceship>* ships) { ... }
void main() {
    vector<Spaceship> ships;
    ...
    foo(&ships);
}
    
  

...we can say this:



main's stack frame "owns" vector<Spaceship> ships;


The vector<Spaceship> ships; owns each Spaceship.


Each Spaceship owns its Engine (via the unique_ptr).


Each Engine owns its int fuel;


foo does not own the vector, it just has a raw pointer.


main's stack frame owns foo's stack frame.


main is the only thing without an owner.



If you've coded in C++ or Rust, you're probably familiar with this mindset.





If you've coded in C, you might think like this too, even though C doesn't explicitly track single ownership. If you trace an object's journey all the way from its malloc() call to its free() call, all of the variables/fields that the pointer passes through are dealing with the "owning pointer", so to speak. It's almost like how detectives track the "chain of custody" for evidence. In other words, who is responsible for it at any given moment.





Heck, even Java and C# programmers sometimes think in terms of single ownership. If you're supposed to call an object's "dispose"/"cleanup"/"destroy"/"unregister"/etc. method at some point, you can trace that object's journey all the way from new to that (conceptually destructive) method call, and those are the variables/fields that are handling its "owning reference", so to speak.





Single ownership, as explained so far, is the foundation for a lot of languages:



If you add regular (unrestricted) pointers and references, you get C++.


If you add generational references and region borrowing, you get Vale.


If you add "aliasable-xor-mutable" references, you get Rust.


If you add "group borrowing", you get Nick's system.



Nick's system is the main topic of this article, but for some context, and to know why Nick's system stands out, let's take a quick detour to recap how Rust's borrow checking works.




      
    
      
  


 Recap of Rust Borrowing

To truly appreciate Nick's approach, it's helpful to know the limitations of Rust's borrow checker.


TL;DR: Rust's borrow checker has the "aliasing xor mutable" rule which makes it conservative. This means it rejects a lot of valid programs and useful patterns 4 and it causes accidental complexity for some use cases. 5


If you're already familiar with Rust's limitations, skip ahead to Nick's approach!





If not, here's a very simplified explanation of Rust's borrow checking, and I'll overview the limitations in the next section.


I'll assume some knowledge of modern C++, but if you're primarily a C programmer, check out this post instead.





There are two kinds of references: readwrite, and readonly. These are often called "mutable" and "immutable" (or more accurately "unique" and "shared") but for now, think of them as readwrite and readonly.





There are a few ways to get a readwrite reference:



If you own an object, you can get a single temporary "readwrite" reference for a certain scope (function body, loop body, then/else body, etc). During this scope, you can't access the original object directly, you must use that reference.


If you have a readwrite reference to an object (a struct, collection, etc.), you can get a readwrite reference to one of its fields (or elements) for a certain scope. During this scope, the original reference can't be used.






Using these is pretty restrictive. Because of that first rule:



You can never have two usable readwrite references to the same object in the same scope.


You can never have two usable readwrite references to an object and its field at the same time. In other words, while you have a readwrite reference to a Spaceship's Reactor, you can't read or write that Spaceship.






Now, let's introduce "readonly" references. They operate by different rules:



If you have a readwrite reference, you can get any number of temporary "readonly" references for a certain scope. During this scope, the readwrite reference is inaccessible.


In a scope, if you have an readonly reference to an object (a struct, collection, etc.), you can get a readonly reference to one of its fields (or elements) for that scope.






Rust adds some quality-of-life improvements to make this a little easier. For example, you can get a bunch of immutable references directly from an owned object. It's actually not that bad if you're writing a program that inherently agrees with the rules, like compilers, games using ECS, stateless web servers, or generally anything that transforms input data to output data.




      
  

    

4

Like observers, intrusive data structures, back-references and graphs (like doubly-linked lists), delegates, etc.





5

Like mobile/web apps, games using EC, or stateful servers... generally, things that inherently require a lot of state.





        

    
    
  


 Context and Comments on Borrow Checking Limitations

One can't improve on a paradigm unless they know its limitations. So let's talk about borrow checking's limitations!





Because of those "inaccessible" rules, we can never have a readwrite reference and a readonly reference to an object at the same time. This restriction is known as "aliasability xor mutability".


In theory this doesn't sound like a problem, but in practice it means you can't implement a lot of useful patterns like observers, intrusive data structures, back-references, graphs (like doubly-linked lists), delegates, etc. and it causes accidental complexity for use cases like mobile/web apps, games using EC, or stateful servers... generally, things that inherently require a lot of state.


But borrow checking is generally worth it, because it means we get memory safety without run-time overhead.





Well, mostly.


Like I explain in this post, it's not really free; even if you avoid Rc/RefCell/etc., borrow checking can often incur hidden costs, like extra bounds checking or potentially expensive cloning and hashing.


The borrow checker has long been known to reject programs that are actually safe, causing you to add and change code to satisfy its constraints. When this happens, one might just shrug and say "the borrow checker is conservative," but in reality, the borrow checker is imposing accidental complexity.





And besides, we know that mutable aliasing doesn't conflict with zero-cost memory safety, as we learned from the Arrrlang thought experiment. The only question is... can we get the best of both worlds?





      
    
      
  


 An example

(Or skip ahead to Nick's approach if you understood the above!)





Here's an example (source):


    
      
      struct Entity {
    hp: u64,
    energy: u64,
}
impl Entity { ... }
fn attack(a: &mut Entity, d: &mut Entity) { ... }
fn main() {
    let mut entities = vec![
        Entity { hp: 10, energy: 10 },
        Entity { hp: 12, energy: 7 }
    ];
    attack(&mut entities[0], &mut entities[1]);
}
    
  

Rust rejects this, giving this output:


    
      
      error[E0499]: cannot borrow `entities` as mutable more than once at a time
  --> src/main.rs:35:35
   |
35 |     attack(&mut entities[0], &mut entities[1]);
   |     ------      --------          ^^^^^^^^ second mutable borrow occurs here
   |     |           |
   |     |           first mutable borrow occurs here
   |     first borrow later used by call
   |
   = help: use `.split_at_mut(position)` to obtain two mutable non-overlapping sub-slices
    
  

Alas, .split_at_mut isn't always great in practice (reasons vary) 6 and besides, we sometimes want to have two &mut referring to the same object.





The more universal workaround is to use IDs and a central collection, like this (source, uses slotmap):


    
      
      fn attack(
    entities: &mut SlotMap<DefaultKey, Entity>,
    attacker_id: DefaultKey,
    defender_id: DefaultKey
) -> Result<(), String> {
    let a = entities
        .get(attacker_id)
        .ok_or_else(|| "Attacker not found in entities map".to_string())?;
    let d = entities
        .get(defender_id)
        .ok_or_else(|| "Defender not found in entities map".to_string())?;

    let a_energy_cost = a.calculate_attack_cost(d);
    let d_energy_cost = d.calculate_defend_cost(a);
    let damage = a.calculate_damage(d);

    let a_mut = entities
        .get_mut(attacker_id)
        .ok_or_else(|| "Attacker not found in entities map".to_string())?;
    a_mut.use_energy(a_energy_cost);

    let d_mut = entities
        .get_mut(defender_id)
        .ok_or_else(|| "Defender not found in entities map".to_string())?;
    d_mut.use_energy(d_energy_cost);
    d_mut.damage(damage);

    Ok(())
}
    
  

This is using the slotmap crate (similar to generational_arena), though you often see this pattern with HashMap instead (or one could also use raw indices into a Vec, though that risks use-after-release problems).





If you want it to be more efficient, you might be tempted to get two mutable references up-front:


    
      
      fn attack(
    entities: &mut SlotMap<DefaultKey, Entity>,
    attacker_id: DefaultKey,
    defender_id: DefaultKey
) -> Result<(), String> {
    let a = entities
        .get_mut(attacker_id)
        .ok_or_else(|| "Attacker not found in entities map".to_string())?;
    let d = entities
        .get_mut(defender_id)
        .ok_or_else(|| "Defender not found in entities map".to_string())?;
    let a_energy_cost = a.calculate_attack_cost(d);
    let d_energy_cost = d.calculate_defend_cost(a);
    let damage = a.calculate_damage(d);
    a.use_energy(a_energy_cost);
    d.use_energy(d_energy_cost);
    d.damage(damage);
    Ok(())
}
    
  




But alas, rustc complains:


    
      
      error[E0499]: cannot borrow `*entities` as mutable more than once at a time
  --> src/main.rs:34:13
   |
31 |     let a = entities
   |             -------- first mutable borrow occurs here
...
34 |     let d = entities
   |             ^^^^^^^^ second mutable borrow occurs here
...
37 |     let a_energy_cost = a.calculate_attack_cost(d);
   |                         - first borrow later used here
    
  

...because we're mutably borrowing entities twice: once in a's get_mut call, and once in d's get_mut call, and their usages overlap.





Or, said differently, it's worried that a and d might be pointing to the same Entity, thus violating aliasability-xor-mutability.





But why is a compiler telling me that an Entity can't attack itself? That's odd, because in this game, that's totally allowed. Even pokémon can hurt themselves in their confusion.





One might say, "because that's a memory safety risk!" But that's not necessarily true. From what I can tell, that code would be just fine, and not risk memory safety. And in fact, Nick's system handles it just fine.





So let's take a look at Nick's system!





      
  

6

For example, if you need N references instead of just 2, or they don't need to be / shouldn't be distinct, or you want to still hold a reference while also holding those N references, etc.





    
    
      
  


 Nick's Borrowing System

As I explain Nick's system, please keep in mind:



I'm taking some terminology liberties: the proposal calls them "regions", but here I'm describing them as "groups", mainly because I know that "regions" tends to get misinterpreted as "arenas". These are not arenas. 7


This proposal is from about a year ago, and Nick's been working on an even better iteration since then that's not ready yet. Subscribe to the RSS feed because I'll be posting about Nick's next proposal when it comes!


Nick's proposal is for Mojo, so the code examples are modified Mojo syntax.






Our goal is to write something like the Rust attack function from the last section:


    
      
      fn attack(
    entities: &mut SlotMap<DefaultKey, Entity>,
    attacker_id: DefaultKey,
    defender_id: DefaultKey
) -> Result<(), String> {
    let a = entities
        .get(attacker_id)
        .ok_or_else(|| "Attacker not found in entities map".to_string())?;
    let d = entities
        .get(defender_id)
        .ok_or_else(|| "Defender not found in entities map".to_string())?;

    let a_energy_cost = a.calculate_attack_cost(d);
    let d_energy_cost = d.calculate_defend_cost(a);
    let damage = a.calculate_damage(d);

    let a_mut = entities
        .get_mut(attacker_id)
        .ok_or_else(|| "Attacker not found in entities map".to_string())?;
    a_mut.use_energy(a_energy_cost);

    let d_mut = entities
        .get_mut(defender_id)
        .ok_or_else(|| "Defender not found in entities map".to_string())?;
    d_mut.use_energy(d_energy_cost);
    d_mut.damage(damage);

    Ok(())
}
    
  




But we're going to write it with memory-safe mutable aliasing, so it's simpler and shorter!





A sneak peek of what it would look like:


    
      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):
  a_power = a.calculate_attack_power()
  a_energy_cost = a.calculate_attack_cost(d)
  d_armor = d.calculate_defense()
  d_energy_cost = d.calculate_defend_cost(a)
  a.use_energy(a_energy_cost)
  d.use_energy(d_energy_cost)
  d.damage(a_power - d_armor)
    
  




I'll explain Nick's system in four steps:



Basic mutable aliasing


References to an object vs its contents


Child groups, which blur that distinction a bit


Group annotations, which help inter-function reasoning a bit






We'll start simple, and build up gradually.





      
  

7

I know this from experience. I regret naming Vale's regions "regions"!





    
    
      
  


 Basic Mutable Aliasing

Let's start by completely forgetting the difference between readonly and readwrite references. Let's say that all references are readwrite.





Now, take this simple Mojo program that has two readwrite aliases to the same list:


    
      
      fn example():
    my_list = [1, 2, 3, 4]
    ref list_ref_a = my_list
    ref list_ref_b = my_list
    list_ref_a.append(5)
    list_ref_b.append(6)
    
  

Here's the equivalent Rust code:


    
      
      fn example() {
    let mut my_list: Vec<i64> = vec![1, 2, 3, 4];
    let list_ref_a = &mut my_list;
    let list_ref_b = &mut my_list;
    list_ref_a.push(5);
    list_ref_b.push(6);
}
    
  

The Rust compiler rejects it because we're violating aliasability-xor-mutability, specifically in that we have two active readwrite references:


    
      
      error[E0499]: cannot borrow `my_list` as mutable more than once at a time
 --> src/lib.rs:4:22
  |
3 |   let list_ref_a = &mut my_list;
  |                   ------------ first mutable borrow occurs here
4 |   let list_ref_b = &mut my_list;
  |                   ^^^^^^^^^^^^ second mutable borrow occurs here
5 |
6 |   list_ref_a.push(5);
  |   ---------- first borrow later used here
    
  




But... we humans can easily conclude this is safe. After the evaluation of list_ref_a.push(5), my_list is still there, and it's still in a valid state. So there is no risk of memory errors when evaluating the second call to push.


In any language, when we hand a function a reference to an object, that function can't destroy the object, 8 nor change its type--it just has a reference. The same is true here.


Therefore, the caller should be able to have (and keep using) other references to that object, and it's totally fine.





Nick's approach handles this by thinking about "a reference to an object" as different from "a reference to its contents". We can have multiple references to an object, but references into an object's contents will require some special logic.


I'll explain that more in the next section.




      
  

8

If a language supports temporarily destroying a live object's field, like Mojo, Nick's model supports that as well. It tracks that "some object in this group is partially destroyed" and temporarily disables other potential references to that object while that's true.





    
    
  


 When to Invalidate References to Contents

So how do we handle a caller's references to the contents of the object? What kind of special logic does that require?





In the below example, the compiler should reject print(element_ref) because append might have modified the List.


    
      
      fn example():
    my_list = [1, 2, 3, 4]
    ref list_ref = my_list
    ref el_ref = my_list[0]
    list_ref.append(5)
    print(el_ref)
    
  

It would be amazing if a memory safety approach knew that the previous example was fine and this one isn't.





In other words, the approach should know that when we hand append a reference to List, it shouldn't invalidate the other reference list_ref, but it should invalidate any references to its contents (like el_ref).





I like how Nick put it in his proposal:


A dynamic container is a container that stores a dynamically-changing number of items, and/or items whose type changes dynamically. The two archetypal dynamic containers are resizable arrays (i.e. Mojo's List type), and tagged unions (i.e. Mojo's Variant type).


Pointers to the items of a dynamic container need to be treated carefully, because if the container is mutated, those items may no longer reside at their original locations. There are several reasons why the items might have gone missing: the items were deleted. (e.g. a List was cleared.), the items were moved somewhere else. (e.g. a List's buffer was reallocated.), or the item has changed type. (e.g. a Variant was reassigned to a different payload type.)


In all cases, the right action to take is to invalidate the pointer





If I had to boil it down to one sentence, I'd say: When you might have used a reference to mutate an object, don't invalidate any other references to the object, but do invalidate any references to its contents.





Following this general rule, a lot of programs are revealed to be safe.





And this isn't that crazy; if you've used C++ a lot, this likely agrees with your intuition.





Note that we'll relax this rule later, and replace it with a more accurate one. But for now, it's a useful stepping stone.




      
    
      
  


 A More Complex Example

Above, I gave a sneak peek at an attack function.


Let's look at it again:


    
      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):
  damage = a.calculate_damage(d)
  a_energy_cost = a.calculate_attack_cost(d)
  d_energy_cost = d.calculate_defend_cost(a)
  a.use_energy(a_energy_cost)
  d.use_energy(d_energy_cost)
  d.damage(damage)
    
  




For now:



Ignore the [mut r: group Entity], we'll get to that later.


Know that none of these methods delete any Entitys. 9


Know that damage modifies d. Nothing else modifies anything.



(I'll explain both of those points more later.)





Note how this function isn't holding any references to Entitys' contents... only to whole Entitys.





All these methods don't delete any Entitys, so this attack function is completely memory safe. In fact, even though the use_energy and damage methods modify Entitys, every line in attack is still memory-safe. 10





Let's look at this alternate example now to see it catching an actual memory safety risk.


Entity looks like this now:


    
      
      struct Entity:
    var hp: Int
    var rings: ArrayList[Ring]
    ...
    
  

attack now holds a reference to an Entity's contents, like so:


    
      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):
  ref ring_ref = d.rings[0] # Ref to contents

  damage = a.calculate_damage(d)
  a_energy_cost = a.calculate_attack_cost(d)
  d_energy_cost = d.calculate_defend_cost(a)
  a.use_energy(a_energy_cost)
  d.use_energy(d_energy_cost)
  ...
    
  




The compiler views the program like this:





The compiler knows that:



There is a r group (in blue).


There is a r.rings.items[0] group (in green).


The r.rings.items[0] group (green) is a child of group r (blue).






Now let's see what happens when we modify d with a call to damage and then try to use that ring_ref:




      
        ref ring_ref = d.rings[0] # Ref to contents

  damage = a.calculate_damage(d)
  a_energy_cost = a.calculate_attack_cost(d)
  d_energy_cost = d.calculate_defend_cost(a)
  a.use_energy(a_energy_cost)
  d.use_energy(d_energy_cost)

  d.damage(damage)
  print(ring_ref) # Invalid, should show error
    


The compiler shows an error, because one of the functions (like damage) might have deleted that first ring, so the compiler should invalidate any references to the contents of all Entitys in the group.





We're really just following the rule from before: When you might have used a reference to mutate an object, don't invalidate any other references to the object, but do invalidate any references to its contents.




      
  

    

9

More precisely, these methods are only able to access the entities in group r by going through the variables a and d. In other words, there are no "back channels" for gaining access to the entities. This is important for memory safety and also for optimizations' correctness.





10

I'd like to remind everyone that this is all theoretical. Let me know if you have any improvements or comments on the approach!





        

    
    
      
  


 Child groups

That's a useful rule, and it can get us pretty far. But let's make it even more specific, so we can prove more programs memory-safe.





For example, look at this snippet:


    
      
        ref hp_ref = d.hp # Ref to contents

  damage = a.calculate_damage(d)
  a_energy_cost = a.calculate_attack_cost(d)
  d_energy_cost = d.calculate_defend_cost(a)
  a.use_energy(a_energy_cost)
  d.use_energy(d_energy_cost)
  d.damage(damage)

  print(hp_ref) # Valid!
    
  




The previous (invalid) program had a ring_ref referring to an element in a ring array.


This new (correct) program has an hp_ref that's pointing to a mere integer instead.


This is actually safe, and the compiler should correctly accept this. After all, since none of these methods can delete an Entity, then they can't delete its contained hp integer.





Good news, Nick's approach takes that into account!





But wait, how? Wouldn't that violate our rule? We might have used a reference (damage may have used d) to mutate an object (the Entity that d is pointing to). So why didn't we invalidate all references to the Entity's contents, like that hp_ref?





So, at long last, let's relax our rule, and replace it with something more precise.





Old rule:  When you might have used a reference to mutate an object, don't invalidate any other references to the object's group, but do invalidate any references to its contents.





Better rule: When you might have used a reference to mutate an object, don't invalidate any other references to the object's group, but do invalidate any references to anything in its contents that might have been destroyed.





Or, to have more precise terms:


Even better rule: When you might have used a reference to mutate an object, don't invalidate any other references to the object's group, but do invalidate any references to its "child groups".





So what's a "child group", and how is it different from the "contents" from the old rule?





If Entity was defined like this:


    
      
      struct Entity:
    var hp: Int
    var rings: ArrayList[Ring]
    var armor: Box[IArmor]            # An owning pointer to heap (C++ "unique_ptr")
    var hand: Variant[Shield, Sword]  # A tagged union (Rust "enum")

struct Ring:
    var power: int

struct Shield:
    var durability: int

struct Sword:
    var sharpness: int

struct SteelArmor:
    var hardness: int
    
  




Then these things would be part of an Entity's group:



hp: Int


rings: ArrayList[Ring]


armor: Box[IArmor] 11


hand: Variant[Shield, Sword] 12






However, these would be in Entity's child groups:



The Rings inside that rings list.


The IArmor object that armor points to.


The Shield or Sword inside the hand variant.






For example, if we had this code:


    
      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):

  ref hp_ref = d.hp
  ref rings_list_ref = d.rings
  ref ring_ref = d.rings[rand() % len(d.rings)]
  ref armor_ref = d.armor[]  # Dereferences armor pointer

  match ref d.hand:
    case Shield as ref s:
      ...
    
  




Then these are the groups the compiler knows about:








Some observations:



d, hp_ref, and rings_list_ref all point to the r group (in blue).


ring_ref points to the r.rings.items[*] group (in green). That group represents all the rings, because the compiler doesn't know the index rand() % len(d.rings). This is different than the r.rings[0] from before.


armor_ref points to the r.armor[] group (in red).


s points to the r.hand.Shield group (in yellow). 13






As a user, you can use this rule-of-thumb: any element of a Variant or a collection (List, String, Dict, etc) or Box will be in a child group. 





If you want to go deeper, the real rule might be something like: "a Variant's element or anything owned by a pointer will be in a child group." After all, String/List/Dict/Box own things with a pointer under the hood.





That all sounds abstract, so I'll state it in more familiar terms: if an object (even indirectly) owns something that could be independently destroyed, it must be in a child group.





Now, let's see what happens to the groups when we add a damage call in. Remember: Entity.damage mutates the entity, so it has the potential to destroy the rings, armor, shields and/or swords that the entity is holding:




      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):

  ref hp_ref = d.hp                              # Group r
  ref rings_list_ref = d.rings                   # Group r
  ref ring_ref = d.rings[rand() % len(d.rings)]  # Group r.rings.items[*]
  ref armor_ref = d.armor[]                      # Group r.armor[]

  match ref d.hand:
    case Shield as ref s:                        # Group r.hand.Shield
      ...
      d.damage(10)  # Invalidates refs to r's child groups
                    # Group r.rings.items[*] is invalidated
                    # Group r.armor[] is invalidated
                    # Group r.hand.Shield is invalidated

      print(hp_ref)               # Okay
      print(len(rings_list_ref))  # Okay
      print(ring_ref.power)       # Error, used invalidated group
      print(s.durability)         # Error, used invalidated group
      print(armor_ref)            # Error, used invalidated group
    


Let's look at it piece-by-piece.





      
  

    

11

An owning pointer to heap, unique_ptr in C++ speak.





12

A tagged union, "enum" in Rust speak.





13

This doesn't have an "(owns)" arrow because in Mojo (which Nick's proposal was for), a Variant is a tagged union, which holds its data inside itself, rather than pointing to its data on the heap.





        

    
    

 print(hp_ref)

The hp: Int isn't in a Variant or a collection, so it's pointing into the r group (not a child group), so the compiler can let us use our reference after the damage method.


Or using our more familiar terms: the integer can't be independently destroyed before or after the Entity (its memory is inside the Entity after all), so it's not in a child group, so the compiler can let us use our reference after the damage method.




    
  


 print(ring_ref)

Now consider ring_ref which points to an item in d.rings.


    
      
        ref ring_ref = d.rings[rand() % len(d.rings)]  # Group r.rings.items[*]
  ...
      ...
      d.damage(10)  # Invalidates refs to r's child groups
                    # Group r.rings.items[*] is invalidated
      ...
      print(ring_ref.power)  # Error, used invalidated group
    
  




That ring is in a collection (the d.rings ArrayList), so it's in a child group r.rings.items[*], so the compiler shouldn't let us use our reference after the damage method.





Or using our more familiar terms: the Ring could be independently destroyed (such as via a remove or append call on the ArrayList), so it's in a child group, so the compiler shouldn't let us use our reference after the damage method.





So, as you can see, hp is in the Entity's group, but a Ring is in a child group.





      
    
  


 print(len(rings_list_ref))

Let's do a harder example. Consider the rings_list_ref that points to the whole d.rings list, rather than an individual Ring.




      
        ref rings_list_ref = d.rings  # Group r
  ...
      ...
      d.damage(10)  # Invalidates refs to r's child groups
      ...
      print(len(rings_list_ref))  # Okay
    


That rings_list_ref is actually pointing at group r, not a child group, because the rings ArrayList isn't in a collection (it is the collection). It's in group r (not a child group), which wasn't invalidated, so the compiler can let us use our reference after the damage method.





Or using our more familiar terms: the List itself can't be independently destroyed before or after the Entity (its memory is inside the Entity after all), so it's not in a child group, so the compiler can let us use our reference after the damage method.





That means rings_list_ref is still valid, and we can use it in that print call!




      
    
  


 print(s.durability)

Consider s, which points into the hand variant's Shield value.




      
        match ref d.hand:
    case Shield as ref s:  # Group r.hand.Shield
      ...
      d.damage(10)  # Invalidates refs to r's child groups
                    # Group r.hand.Shield is invalidated
      ...
      print(s.durability)  # Error, used invalidated group
    


damage could have replaced that Shield with a Sword, thus destroying the Shield.





Because of that risk, the compiler invalidates all of group r's child groups, and catches that print(s.durability) is invalid.




      
    
  


 Child Groups, Summarized




To summarize all the above:



A Variant's element or anything owned by a pointer will be in a child group.



In other words, a group's child group is the objects that that group owns which can be independently destroyed


For example, if an ArrayList is in a group, then its contents array is in its child group.



When someone modifies a parent group, we invalidate all references into any of its child groups.






If any of this doesn't make sense, please help us out by coming to the Vale discord and asking questions! I want to make this explanation as clear as possible, so more people understand it.




      
    
      
  


 Where do groups come from?

So we know what a child group is, but how does one make a group? Where do they come from?





Local variables! Each local variable has its own group. 14





Let's look at main:




      
      fn main():
    entities = List(Entity(10, 10), Entity(12, 7))
    attack(entities[0], entities[1])
    


The local variable entities introduces a group, containing only itself. As we've just discussed, this group contains several child groups (that are not created by local variables). When we invoke attack, we're passing the child group that represents the elements of the entities list.





Additionally, groups can be combined to form other groups. This would also work:




      
      fn main():
    entity_a = Entity(10, 10)
    entity_b = Entity(12, 7)
    attack(entity_a, entity_b)
    


This time, when we invoke attack, we're passing a group that represents the "union" of the two local variables.





So, to summarize where groups come from:



Each local variable forms its own group.


Multiple groups can be combined into one.


Variants and collections inside a group can form child groups.





      
  

14

What about heap allocations? For example, if we had a var x = Box[Entity](10, 10). In this case, the local variable x has a group. The Entity it's pointing to is a child group.





    
    
  


 Isolation




There's a restriction I haven't yet mentioned: all items in a group must be mutually isolated, in other words, they can't indirectly own each other, and one can't have references into the other. In other words, in the above example, an Entity cannot contain a reference to another Entity.





With this restriction, we know that e.g. d.damage(42) can't possibly delete some other Entity, for example a. More generally, we know that if a function takes in a bunch of references into a group, it can't use those to delete any items in the group.





I won't go too deeply into this, but if you want an example of why this is needed, try mentally implementing an AVL tree with the system. AVL tree nodes have ownership of other nodes, so any function that has the ability to modify a node suddenly has the ability to destroy a node, and if nodes can be destroyed, we can't know if references to them are still valid. That would be bad. So instead, we have the mutual-isolation rule.




      
    
  


 Functions' Group Annotations




Here's a smaller version of one of the above snippets.




      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):
  ref contents_ref = a.armor_pieces[0] # Ref to contents

  d.damage(3)

  print(contents_ref) # Invalid
    


At long last, we can talk about the [mut r: group Entity]! These are group annotations. They help the compiler know that two references might be referring to the same thing. Note that the call site doesn't explicitly have to supply a group for r, the compiler will infer it.





The use of the group r in the signature of attack  informs the compiler that even though d.damage(3) is modifying d, this may change the value of a, and therefore we need to invalidate any references that exist to child groups of a.





Stated more accurately, d.damage(3) is modifying group r, so it invalidates all references that point into r's child groups (like contents_ref).





These group annotations also help at the call site, like in this example:




      
      fn main():
    entities = List(Entity(10, 10), Entity(12, 7))
    attack(
        entities[rand() % len(entities)],
        entities[rand() % len(entities)])
    


Specifically, this invocation of attack is valid, because attack has been declared in such a way that the arguments are allowed to alias. This information is explicit in the function signature (in attack), so it is visible to both the programmer and the compiler.




      
    
      
  


 A More Complex Example




Let's see a more complex example, and introduce a new concept called a path which helps the compiler reason about memory safety when calling functions.





Here's our main function again:


    
      
      fn main():
    entities = List(Entity(10, 10), Entity(12, 7))
    attack(
        entities[rand() % len(entities)],
        entities[rand() % len(entities)])
    
  




And here's something similar to our attack from before, but with a new call to a new power_up_ring function:


    
      
      fn attack[mut r: group Entity](
    ref[r] a: Entity,
    ref[r] d: Entity):
  ref armor_ref = a.armor # Ref to a's armor

  # Modifies a.rings' contents
  power_up_ring(a, a.rings[0])

  # Valid, compiler knows we only modified a.rings' contents
  armor_ref.hardness += 2
    
  




As the comments say, power_up_ring is modifying one of a's rings, and it doesn't invalidate our armor_ref.





To see how that's possible, let's see power_up_ring (note I'm taking some liberties with the syntax, a much shorter version is in a section below):


    
      
      # Wielder Entity's energy will power up the ring.
# Changes the ring, but does not change the wielder Entity.
fn power_up_ring[e: group Entity, mut rr: group Ring = e.rings*](
    ref[e] entity: Entity,
    ref[rr] a_ring: Ring
):
    a_ring.power += entity.energy / 4
    
  




Let's unpack that fn line:



e: group Entity means: e is a group of Entitys. Note how there's no mut here.


mut rr: group Ring means: rr is a group of Rings. This one is mut.


 = e.rings* means: rr points to Rings in e's Entitys' field .rings. We call this a path.






Nick's original proposal doesn't design for this particular capability, where we can take an immutable parent group and a mutable child group, but we tossed around the idea offline and we think it'll work. Let us know if you see anything to improve!





With this, the caller (attack) has enough information to know exactly what was modified. 15





Specifically, attack knows that Entitys' .rings elements may have changed. Therefore, after the call to power_up_ring, attack should invalidate any references pointing into Entitys' .rings elements, but not invalidate anything else. Therefore, it should not invalidate that armor_ref.





Inside the function, we see a a_ring.power += entity.energy / 4. Note how it's:



Reading an Entity


Modifying a Ring inside the Entity.






The latter is also why we have mut in mut rr: group Ring; the compiler requires a function put mut on any group it might be modifying.





This is also something that distinguishes this approach from Rust's. Partial borrows can do some of that, but generally you can't have a &Entity while also having an &mut Item pointing to one of the Entity's items.




      
  

15

Well not exactly. Technically, only the .power field is being modified, but power_up_ring is saying that anything inside Ring might have changed.





    
    
  


 Paths

I want to really emphasize something from the last section:


mut rr: group Ring = e.rings*





This is the key that makes this entire approach work across function calls. Whenever there's a callsite, like attack's call to power_up_ring(a, a.rings[0]), it can assemble a full picture of whether that call is valid, and how it affects the code around it.





When compiling attack, the compiler thinks this:



The caller (attack) calling power_up_ring(a, a.rings[0]).


The callee's first argument's group e.


The callee's second argument's group is e.rings*, which corresponds to a.rings[0] in the caller.


The callee's second argument's group is mut, so the callee will modify things in it.


Therefore, the callee will modify the caller's a.rings's elements' contents.






This path is how the caller knows what the callee might have modified. That's the vital information that helps it know exactly what other references it might need to invalidate.




      
    
  


 Syntax

If you thought that syntax was verbose:


    
      
      fn power_up_ring[e: group Entity, mut rr: group Ring = e.rings*](
    ref[e] entity: Entity,
    ref[rr] a_ring: Ring
):
    a_ring.power += entity.energy / 4
    
  

...that's my fault. I wanted to show what's really going on under the hood.





Nick actually has some better syntax in mind:


    
      
      fn power_up_ring(
   entity: Entity,
   mut ref [entity.rings*] a_ring: Ring
):
    a_ring.power += entity.energy / 4
    
  

Way simpler!




      
    
  


 The approach, summarized

With that, you now know all the pieces to Nick's approach. Summarizing:





References to object vs its contents: there's a distinction between an object and its contents. We can have as many references to an object as we'd like. Mutations to the contents will invalidate references that point into the contents, but don't have to invalidate any references to the object itself.





Child groups let us think a little more precisely about what mutations will invalidate what references to what contents.





Group annotations on the function give the compiler enough information at the callsite to know which references in the caller to invalidate.




      
    
      
  


 Does the approach really not have unique references?

When I was learning about the approach, I was kind of surprised that it had no unique references. They seemed inevitable. 16 In his proposal, Nick even mentions this example:


    
      
      fn foo[mut r: group String](names: List[ref[r] String]):
    p1 = names[0]
    p2 = names[1]
    p1[] = p2[]     # Error: cannot copy p2[]; it might be uninitialized.
    
  




The final line of the function first destroys p1's pointee (implicitly, just before assigning it a new value), and then copies data from p2's pointee. (By the way, postfix [] is Mojo-speak for dereference, so p1[] is like C's *p1)





The challenge here, as he explains, is that p1 and p2 might be pointing to the same object. If so, one or both of these objects might end up with uninitialized data.





His solution mentions using escape hatches in this case, like this:


    
      
      fn swap[T: Movable, mut r: group T](ref[r] x: T, ref[r] y: T):
    if __address_of(x) == __address_of(y):
        return
        
    # Now that we know the pointers don't alias, we can use unsafe
    # operations to swap the targets. The exact code isn't important.
    unsafe_x = UnsafePointer.address_of(x)
    unsafe_y = UnsafePointer.address_of(y)
    
    # ...use unsafe_x and unsafe_y here to swap the contents...
    
  




...but this can theoretically be built into the language, like this:


    
      
      fn swap[T: Movable, mut r: group T](ref[r] x: T, ref[r] y: T):
    if not distinct(x, y):
        return
    
    # ...use x and y...
    
  




At first, I saw this and thought, "Aha! distinct hints to the compiler that these are unique references!"





But... maybe not. Instead of thinking of these as unique references, you could think of this as "splitting" group r into two temporary distinct groups.




      
  

16

 Throughout the entire proposal, I was expecting the next section to talk about how we inevitably add unique references back in. And as I was thinking ahead, I kept on adding unique references in, in my tentative understanding of his model. This is the problem with being accustomed to conventional borrow checking... it makes it harder to think of any other approach.


Luckily, Nick consistently tried to understand what operations can cause pointers to dangle, and impose as few restrictions as possible while ensuring that dangling pointers are always invalidated. With that in mind, the AxM constraint never arose. It's the same mindset I used to come up with Vale's generational references + regions blend. It must be like art: design constraints lead to inspiration!






    
    
      
  


 Comparison to Borrow Checking

Group Borrowing could be much better than borrow checking.



It should be much more permissive than borrow checking, and prove a lot more programs correct.


It should lead to better error messages. Whereas rustc gives errors about abstract borrowing violations, this model should be able to give errors that point out the actual real risks: "you can't use this pointer down here, because it might not be valid anymore because of this modification up here".



This is particularly important to a language like Mojo, which is designed for Python programmers. The ramp from dynamic typing to static typing to single ownership to borrowing is steep, and this could help.



Allowing safe mutable aliasing could lead to less people reaching for workarounds like unsafe pointers. In other words, by making safe references more expressive,  we can make systems languages more memory-safe in practice.






Though, it might also result in programs that are architecturally similar to borrow checking.



The mutual isolation restriction will influence our programs' data to look like trees, similar to how Rust's borrow checker does. However, the approach has much more relaxed rules around how we access those trees from the outside (via references in local variables and arguments), which is a nice improvement.


A line of code that deletes something will invalidate any references to any of its child groups. A similar constraint appears in borrow checking, though it's more relaxed here.






It might be faster than borrow checking in some cases.



For example, the attack example doesn't need to do repeated hash lookups like in Rust.


More generally, his approach means we can have more references, and less hashing, cloning, and bounds checking.






But it might be slower in some cases. Not having unique references means it could be challenging for the compiler to compile references to faster noalias 17 pointers. Nick showed me this article to highlight the possible speed differences, and we discussed a few promising options. Perhaps a compiler could:



Emit noalias for an argument when the argument is the only argument into a certain group.


Have a special kind of group where all references are guaranteed distinct.


Notice when the code checks (via if, assert, etc.) that all pointers into a group are distinct, and emit noalias then.






And this model might have downsides:



Since there's no such thing as a unique reference, it could lead to awkward situations, where we have to convince the compiler that two references don't alias.



Then again, Rust kind of has this too, in the form of .split_at_mut. It might be easier here?



This model hasn't been implemented yet and therefore hasn't been proven to work, of course.






So, will this be revolutionary? Perhaps! Or maybe it'll be just a surface-level improvement on borrow checking in practice. Or, it could be the key that unlocks borrowing and makes it more palatable to the mainstream.




      
  

17

noalias is an annotation given to LLVM to tell it that no other pointer will be observing the pointed-at data while the pointer is in scope. It helps the compiler skip some loads and stores.





    
    
      
  


 Where we go from here




Where does the idea go from here? Not sure!





This idea is still new, and could evolve in a lot of different directions.



Maybe we'll discover some ways we can decompose it into multiple orthogonal mechanisms, like how implementation inheritance (Java's extends) is really just implements+delegation+composition. 18


Maybe we'll discover that this pairs perfectly with another mechanism, like reference counting (or generational references? Who knows!).


Maybe we'll find a different way to communicate across inter-function boundaries, so that child group invalidation can be more precisely expressed and controlled.


Maybe someone will find a way to make these groups (mutably) alias each other! 19






In the grimoire, I hinted about a hypothetical blend of reference counting and borrowing that we don't yet know how to make. I mention that one possible path to it will be to combine various memory safety techniques together. This could be one of them. 





So regardless of how well this model does on its own, it could be an amazing starting point for hybrid memory safety models. I wouldn't be surprised if one of you reads this, reads the grimoire, and discovers a clever way to blend this with existing mechanisms and techniques. Let me know if you do, and I can write an article like this for you too!





      
  

    

18

By this I mean, you can accomplish anything with extends, if you turn the base class into an interface and a struct (like Dart does), and your "subclass" would instead implements the interface, contain the struct in a field, and forward any calls from that interface into that struct.





19

This would have to be opt-in of course. Non-aliasability is a good default, because it allows the compiler to perform optimizations (e.g. keep values in registers for longer) that can actually have a dramatic impact on performance.





        

    
    
      
  


 Conclusion




Once you understand it, the concept is pretty simple in hindsight.





Of course, it pains me to say that "it's simple", because it makes it seem like it was easy to discover. I know from personal experience just how hard it is to come up with something like this... it takes a lot of thinking, trial and error, and bumping into dead ends. 20





And we must remember that Nick's model is a draft, and is still being iterated upon. As with any new model, there will be holes, and there will likely be fixes. Vale's region borrowing design fell apart and was fixed a few times yet is still standing, and Nick's model feels even cleaner than regions, so I have hope.





If there's one big thing to take away from this post, it's that we aren't done yet. There is more to find out there!





That's all! I hope you enjoyed this post. If you have any questions for Nick, he hangs out in the Mojo server (username nick.sm), or feel free to ask questions in the r/vale subreddit or Vale discord server.





And most importantly, if you enjoy this kind of exploration, sponsor Nick!





Cheers,


- Evan Ovadia




      
  

20

 Designing region borrowing for generational references took me years. And before that, I was almost broken by 32 iterations of a (now abandoned) Vale feature called "hybrid-generational memory". Near the end there, I was so burned out on the highs and lows of breaking and repairing and improving that feature, that I almost gave up on language design entirely.


Nick told me he's gone through a similarly grueling experience trying to nail down a design for his "groups". I'm glad he stuck with it!






    
    
    
  

    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rendering an ASCII game in real-time with AI (100ms latency)]]></title>
            <link>https://blog.jeffschomay.com/rendering-a-game-in-real-time-with-ai</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45051188</guid>
        </item>
        <item>
            <title><![CDATA[Prosper AI (YC S23) Is Hiring Founding Account Executives (NYC)]]></title>
            <link>https://jobs.ashbyhq.com/prosper-ai/29684590-4cec-4af2-bb69-eb5c6d595fb8</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45051096</guid>
        </item>
        <item>
            <title><![CDATA[The Math Behind GANs]]></title>
            <link>https://jaketae.github.io/study/gan-math/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050958</guid>
            <description><![CDATA[Generative Adversarial Networks refer to a family of generative models that seek to discover the underlying distribution behind a certain data generating process. This distribution is discovered through an adversarial competition between a generator and a discriminator. As we saw in an earlier introductory post on GANs, the two models are trained such that the discriminator strives to distinguish between generated and true examples, while the generator seeks to confuse the discriminator by producing data that are as realistic and compelling as possible.]]></description>
            <content:encoded><![CDATA[
      
        
          
          
             




  8 minute read


          
        
      

      
        
          
        
        Generative Adversarial Networks refer to a family of generative models that seek to discover the underlying distribution behind a certain data generating process. This distribution is discovered through an adversarial competition between a generator and a discriminator. As we saw in an earlier introductory post on GANs, the two models are trained such that the discriminator strives to distinguish between generated and true examples, while the generator seeks to confuse the discriminator by producing data that are as realistic and compelling as possible.

In this post, we’ll take a deep dive into the math behind GANs. My primary source of reference is Generative Adversarial Nets by Ian Goodfellow, et al. It is in this paper that Goodfellow first outlined the concept of a GAN, which is why it only makes sense that we commence from the analysis of this paper. Let’s begin!

Motivating the Loss Function

GAN can be seen as an interplay between two different models: the generator and the discriminator. Therefore, each model will have its own loss function. In this section, let’s try to motivate an intuitive understanding of the loss function for each.

Notation

To minimize confusion, let’s define some notation that we will be using throughout this post.

\[\begin{multline}
\shoveleft x:  \text{Real data} \\
\shoveleft z: \text{Latent vector} \\
\shoveleft G(z): \text{Fake data} \\
\shoveleft D(x): \text{Discriminator's evaluation of real data} \\
\shoveleft D(G(z)): \text{Discriminator's evaluation of fake data} \\
\shoveleft \text{Error}(a, b): \text{Error between } a \text{ and } b\\
\end{multline}\]

The Discriminator

The goal of the discriminator is to correctly label generated images as false and empirical data points as true. Therefore, we might consider the following to be the loss function of the discriminator:

\[L_D = \text{Error}(D(x), 1) + \text{Error}(D(G(z)), 0) \tag{1}\]

Here, we are using a very generic, unspecific notation for $\text{Error}$ to refer to some function that tells us the distance or the difference between the two functional parameters. (If this reminded you of something like cross entropy or Kullback-Leibler divergence, you are definitely on the right track.)

The Generator

We can go ahead and do the same for the generator. The goal of the generator is to confuse the discriminator as much as possible such that it mislabels generated images as being true.

\[L_G = \text{Error}(D(G(z)), 1) \tag{2}\]

The key here is to remember that a loss function is something that we wish to minimize. In the case of the generator, it should strive to minimize the difference between 1, the label for true data, and the discriminator’s evaluation of the generated fake data.

Binary Cross Entropy

A common loss function that is used in binary classification problems is binary cross entropy. As a quick review, let’s remind ourselves of what the formula for cross entropy looks like:

\[H(p, q) = \mathbb{E}_{x \sim p(x)}[- \log q(x)] \tag{3}\]

In classification tasks, the random variable is discrete. Hence, the expectation can be expressed as a summation.

\[H(p, q) = - \sum_{x \in \chi} p(x) \log q(x) \tag{4}\]

We can simplify this expression even further in the case of binary cross entropy, since there are only two labels: zero and one.

\[H(y, \hat{y}) = - \sum y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \tag{5}\]

This is the $\text{Error}$ function that we have been loosely using in the sections above. Binary cross entropy fulfills our objective in that it measures how different two distributions are in the context of binary classification of determining whether an input data point is true or false. Applying this to the loss functions in (1),

\[L_D = - \sum_{x \in \chi, z \in \zeta} \log(D(x)) + \log(1 - D(G(z))) \tag{6}\]

We can do the same for (2):

\[L_G = - \sum_{z \in \zeta} \log(D(G(z)) \tag{7}\]

Now we have two loss functions with which to train the generator and the discriminator! Note that, for the loss function of the generator, the loss is small if $D(G(z))$ is close to 1, since $\log(1) = 0$. This is exactly the sort of behavior we want from a loss function for the generator. It isn’t difficult to see the cogency of (6) with a similar approach.

Minor Caveats

The original paper by Goodfellow presents a slightly different version of the two loss functions derived above.

\[\max_D \{ \log(D(x)) + \log(1-D(G(z))) \} \tag{8}\]

Essentially, the difference between (6) and (8) is the difference in sign, and whether we want to minimize or maximize a given quantity. In (6), we framed the function as a loss function to be minimized, whereas the original formulation presents it as a maximization problem, with the sign obviously flipped.

Then, Goodfellow proceeds by framing (8) as a min-max game, where the discriminator seeks to maximize the given quantity whereas the generator seeks to achieve the reverse. In other words,

\[\min_G \max_D \{ \log(D(x)) + \log(1-D(G(z))) \} \tag{9}\]

The min-max formulation is a concise one-liner that intuitively demonstrates the adversarial nature of thecompetition between the generator and the discriminator. However, in practice, we define separate loss functions for the generator and the discriminator as we have done above.  This is because the gradient of the function $y = \log x$ is steeper near $x = 0$ than that of the function $y = \log (1 - x)$, meaning that trying to maximize $\log(D(G(z)))$, or equivalently, minimizing $- \log(D(G(z)))$ is going to lead to quicker, more substantial improvements to the performance of the generator than trying to minimize $\log(1 - D(G(z)))$.

Model Optimization

Now that we have defined the loss functions for the generator and the discriminator, it’s time to leverage some math to solve the optimization problem, i.e. finding the parameters for the generator and the discriminator such that the loss functions are optimized. This corresponds to training the model in practical terms.

Training the Discriminator

When training a GAN, we typically train one model at a time. In other words, when training the discriminator, the generator is assumed as fixed. We saw this in action in the previous post on how to build a basic GAN.

Let’s return back to the min-max game. The quantity of interest can be defined as a function of $G$ and $D$. Let’s call this the value function:

\[V(G, D) = \mathbb{E}_{x \sim p_{data}}[\log(D(x))] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))] \tag{10}\]

In reality, we are more interested in the distribution modeled by the generator than $p_z$. Therefore, let’s create a new variable, $y = G(z)$, and use this substitution to rewrite the value function:

\[\begin{align}
V(G, D) &= \mathbb{E}_{x \sim p_{data}}[\log(D(x))] + \mathbb{E}_{y \sim p_g}[\log(1 - D(y))] \\ &= \int_{x \in \chi} p_{data}(x) \log(D(x)) + p_g(x) \log(1 - D(x)) \, dx
\end{align} \tag{11}\]

The goal of the discriminator is to maximize this value function. Through a partial derivative of $V(G, D)$ with respect to $D(x)$, we see that the optimal discriminator, denoted as $D^*(x)$, occurs when

\[\frac{p_{data}(x)}{D(x)} - \frac{p_g(x)}{1 - D(x)} = 0 \tag{12}\]

Rearranging (12), we get

\[D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \tag{12}\]

And this is the condition for the optimal discriminator! Note that the formula makes intuitive sense: if some sample $x$ is highly genuine, we would expect $p_{data}(x)$ to be close to one and $p_g(x)$ to be converge to zero, in which case the optimal discriminator would assign 1 to that sample. On the other hand, for a generated sample $x = G(z)$, we expect the optimal discriminator to assign a label of zero, since $p_{data}(G(z))$ should be close to zero.

Training the Generator

To train the generator, we assume the discriminator to be fixed and proceed with the analysis of the value function. Let’s first plug in the result we found above, namely (12), into the value function to see what turns out.

\[\begin{align}
V(G, D^*) &= \mathbb{E}_{x \sim p_{data}}[\log(D^*(x))] + \mathbb{E}_{x \sim p_g}[\log(1 - D^*(x))] \\ &= \mathbb{E}_{x \sim p_{data}} \left[ \log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \right] + \mathbb{E}_{x \sim p_g} \left[ \log \frac{p_g(x)}{p_{data}(x) + p_g(x)} \right]
\end{align} \tag{13}\]

To proceed from here, we need a little bit of inspiration. Little clever tricks like these are always a joy to look at.

\[\begin{align}
V(G, D^*) &= \mathbb{E}_{x \sim p_{data}} \left[ \log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)} \right] + \mathbb{E}_{x \sim p_g} \left[ \log \frac{p_g(x)}{p_{data}(x) + p_g(x)} \right] \\ &= - \log 4 + \mathbb{E}_{x \sim p_{data}} \left[ \log p_{data}(x) - \log \frac{p_{data}(x) + p_g(x))}{2} \right] \\ & \quad+ \mathbb{E}_{x \sim p_g} \left[ \log p_g(x) - \log\frac{p_{data}(x) + p_g(x))}{2} \right] 
\end{align} \tag{14}\]

If you are confused, don’t worry, you aren’t the only one. Basically, what is happening is that we are exploiting the properties of logarithms to pull out a $- \log4$ that previously did not exist. In pulling out this number, we inevitably apply changes to the terms in the expectation, specifically by dividing the denominator by two.

Why was this necessary? The magic here is that we can now interpret the expectations as Kullback-Leibler divergence:

\[V(G, D^*) = - \log 4 + D_{KL}\left(p_{data} \parallel \frac{p_{data} + p_g}{2} \right) + D_{KL}\left(p_g \parallel \frac{p_g + p_g}{2} \right) \tag{15}\]

And it is here that we reencounter the Jensen-Shannon divergence, which is defined as

\[J(P,Q) = \frac{1}{2} \left( D(P \parallel R) + D(Q \parallel R) \right) \tag{16}\]

where $R = \frac12(P + Q)$. This means that the expression in (15) can be expressed as a JS divergence:

\[V(G, D^*) = - \log 4 + 2 \cdot D_{JS}(p_{data} \parallel p_g) \tag{15}\]

The conclusion of this analysis is simple: the goal of training the generator, which is to minimize the value function $V(G, D)$, we want the JS divergence between the distribution of the data and the distribution of generated examples to be as small as possible. This conclusion certainly aligns with our intuition: we want the generator to be able to learn the underlying distribution of the data from sampled training examples. In other words, $p_g$ and $p_{data}$ should be as close to each other as possible. The optimal generator $G$ is thus one that which is able to mimic $p_{data}$ to model a compelling model distribution $p_g$.

Conclusion

In this post, we took a brief tour of the math behind general adversarial networks. Since the publication of Goodfellow’s work, more GAN models have been introduced and studied by different scholars, such as the Wasserstein GAN or CycleGAN to name just a few. The underlying mathematics for these models are obviously going to be different from what we have seen today, but this is a good starting point nonetheless.

I hope you enjoyed reading this post. In the next post, I plan to explore the concept of Fisher information and the Fisher matrix. It is going to be another math-heavy ride with gradients and Hessians, so keep you belts fastened!

        
      

      

      


      
  

    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The most important machine learning equations: A comprehensive guide]]></title>
            <link>https://chizkidd.github.io//2025/05/30/machine-learning-key-math-eqns/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050931</guid>
            <description><![CDATA[Musings of a Deep Learning Enthusiast.]]></description>
            <content:encoded><![CDATA[
  Motivation
Machine learning (ML) is a powerful field driven by mathematics. Whether you’re building models, optimizing algorithms, or simply trying to understand how ML works under the hood, mastering the core equations is essential. This blog post is designed to be your go-to resource, covering the most critical and “mind-breaking” ML equations—enough to grasp most of the core math behind ML. Each section includes theoretical insights, the equations themselves, and practical implementations in Python, so you can see the math in action.

This guide is for anyone with a basic background in math and programming who wants to deepen their understanding of ML and is inspired by this tweet from @goyal__pramod. Let’s dive into the equations that power this fascinating field!



Table of Contents


  Introduction
  
    Probability and Information Theory

    
      Bayes Theorem
      Entropy
      Joint and Conditional Probability
      Kullback-Leibler Divergence (KLD)
      Cross-Entropy
    
  
  
    Linear Algebra

    
      Linear Transformation
      Eigenvalues and Eigenvectors
      Singular Value Decomposition (SVD)
    
  
  
    Optimization

    
      Gradient Descent
      Backpropagation
    
  
  
    Loss Functions

    
      Mean Squared Error (MSE)
      Cross-Entropy Loss
    
  
  
    Advanced ML Concepts

    
      Diffusion Process
      Convolution Operation
      Softmax Function
      Attention Mechanism
    
  
  Conclusion
  Further Reading




Introduction
Mathematics is the language of machine learning. From probability to linear algebra, optimization to advanced generative models, equations define how ML algorithms learn from data and make predictions. This blog post compiles the most essential equations, explains their significance, and provides practical examples using Python libraries like NumPy, scikit-learn, TensorFlow, and PyTorch. Whether you’re a beginner or an experienced practitioner, this guide will equip you with the tools to understand and apply ML math effectively.



Probability and Information Theory
Probability and information theory provide the foundation for reasoning about uncertainty and measuring differences between distributions.

Bayes’ Theorem

Equation:

\[P(A|B) = \frac{P(B|A) P(A)}{P(B)}\]

Explanation: Bayes’ Theorem describes how to update the probability of a hypothesis ($A$) given new evidence ($B$). It’s a cornerstone of probabilistic reasoning and is widely used in machine learning for tasks like classification and inference.

Practical Use: Applied in Naive Bayes classifiers, Bayesian networks, and Bayesian optimization.

Implementation:

def bayes_theorem(p_d, p_t_given_d, p_t_given_not_d):
    """
    Calculate P(D|T+) using Bayes' Theorem.
    
    Parameters:
    p_d: P(D), probability of having the disease
    p_t_given_d: P(T+|D), probability of testing positive given disease
    p_t_given_not_d: P(T+|D'), probability of testing positive given no disease
    
    Returns:
    P(D|T+), probability of having the disease given a positive test
    """
    p_not_d = 1 - p_d
    p_t = p_t_given_d * p_d + p_t_given_not_d * p_not_d
    p_d_given_t = (p_t_given_d * p_d) / p_t
    return p_d_given_t

# Example usage
p_d = 0.01  # 1% of population has the disease
p_t_given_d = 0.99  # Test is 99% sensitive
p_t_given_not_d = 0.02  # Test has 2% false positive rate
result = bayes_theorem(p_d, p_t_given_d, p_t_given_not_d) 
print(f"P(D|T+) = {result:.4f}")  # Output: P(D|T+) = 0.3333 


Entropy

Equation:

\[H(X) = -\sum_{x \in X} P(x) \log P(x)\]

Explanation: Entropy measures the uncertainty or randomness in a probability distribution. It quantifies the amount of information required to describe the distribution and is fundamental in understanding concepts like information gain and decision trees.

Practical Use: Used in decision trees, information gain calculations, and as a basis for other information-theoretic measures.

Implementation:

import numpy as np

def entropy(p):
    """
    Calculate entropy of a probability distribution.
    
    Parameters:
    p: Probability distribution array
    
    Returns:
    Entropy value
    """
    return -np.sum(p * np.log(p, where=p > 0))

# Example usage
fair_coin = np.array([0.5, 0.5])  # fair coin has the same probability of heads and tails
print(f"Entropy of fair coin: {entropy(fair_coin)}")  # Output: 0.6931471805599453 

biased_coin = np.array([0.9, 0.1])  # biased coin has a higher probability of heads
print(f"Entropy of biased coin: {entropy(biased_coin)}")  # Output: 0.4698716731013394 


Joint and Conditional Probability

Equations:


  
    Joint Probability:

\[P(A, B) = P(A|B) P(B) = P(B|A) P(A)\]
  
  
    Conditional Probability:

\[P(A|B) = \frac{P(A, B)}{P(B)}\]
  


Explanation: Joint probability describes the likelihood of two events occurring together, while conditional probability measures the probability of one event given another. These are the building blocks of Bayesian methods and probabilistic models.

Practical Use: Used in Naive Bayes classifiers and probabilistic graphical models.

Implementation:

from sklearn.naive_bayes import GaussianNB
import numpy as np

X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])
y = np.array([0, 0, 1, 1])
model = GaussianNB().fit(X, y)
print(model.predict([[2.5, 3.5]]))  # Output: [1]


Kullback-Leibler Divergence (KLD)

Equation:

\[D_{KL}(P \| Q) = \sum_{x \in \mathcal{X}} P(x) \log \left( \frac{P(x)}{Q(x)} \right)\]

Explanation: KLD measures how much one probability distribution $P$ diverges from another $Q$. It’s asymmetric and foundational in information theory and generative models.

Practical Use: Used in variational autoencoders (VAEs) and model evaluation.

Implementation:

import numpy as np

P = np.array([0.7, 0.3])
Q = np.array([0.5, 0.5])
kl_div = np.sum(P * np.log(P / Q))
print(f"KL Divergence: {kl_div}")  # Output: 0.08228287850505156


Cross-Entropy

Equation:

\[H(P, Q) = -\sum_{x \in \mathcal{X}} P(x) \log Q(x)\]

Explanation: Cross-entropy quantifies the difference between the true distribution $P$ and the predicted distribution $Q$. It’s a widely used loss function in classification.

Practical Use: Drives training in logistic regression and neural networks.

Implementation:

import numpy as np

y_true = np.array([1, 0, 1])
y_pred = np.array([0.9, 0.1, 0.8])
cross_entropy = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))
print(f"Cross-Entropy: {cross_entropy}")  # Output: 0.164252033486018




Linear Algebra
Linear algebra powers the transformations and structures in ML models.

Linear Transformation

Equation:

\[y = Ax + b \quad \text{where } A \in \mathbb{R}^{m \times n}, x \in \mathbb{R}^n, y \in \mathbb{R}^m, b \in \mathbb{R}^m\]

Explanation: This equation represents a linear mapping of input $x$ to output $y$ via matrix $A$ and bias $b$. It’s the core operation in neural network layers.

Practical Use: Foundational for linear regression and neural networks.

Implementation:

import numpy as np

A = np.array([[2, 1], [1, 3]])
x = np.array([1, 2])
b = np.array([0, 1])
y = A @ x + b
print(y)  # Output: [4 7]


Eigenvalues and Eigenvectors

Equation:

\[Av = \lambda v \quad \text{where } \lambda \in \mathbb{R}, v \in \mathbb{R}^n, v \neq 0\]

Explanation: Eigenvalues $\lambda$ and eigenvectors $v$ describe how a matrix $A$ scales and rotates space, crucial for understanding data variance.

Practical Use: Used in Principal Component Analysis (PCA).

Implementation:

import numpy as np

A = np.array([[4, 2], [1, 3]])
eigenvalues, eigenvectors = np.linalg.eig(A)
print(f"Eigenvalues: {eigenvalues}")
print(f"Eigenvectors:\n{eigenvectors}")


Singular Value Decomposition (SVD)

Equation:

\[A = U \Sigma V^T\]

Explanation: SVD breaks down a matrix $A$ into orthogonal matrices $U$ and $V$ and a diagonal matrix $\Sigma$ of singular values. It reveals the intrinsic structure of data.

Practical Use: Applied in dimensionality reduction and recommendation systems.

Implementation:

import numpy as np

A = np.array([[1, 2], [3, 4], [5, 6]])
U, S, Vt = np.linalg.svd(A)
print(f"U:\n{U}\nS: {S}\nVt:\n{Vt}")




Optimization
Optimization is how ML models learn from data.

Gradient Descent

Equation:

\[\theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(\theta)\]

Explanation: Gradient descent updates parameters $\theta$ by moving opposite to the gradient of the loss function $L$, scaled by learning rate $\eta$.

Practical Use: The backbone of training most ML models.

Implementation:

import numpy as np

def gradient_descent(X, y, lr=0.01, epochs=1000):
    m, n = X.shape
    theta = np.zeros(n)
    for _ in range(epochs):
        gradient = (1/m) * X.T @ (X @ theta - y)
        theta -= lr * gradient
    return theta

X = np.array([[1, 1], [1, 2], [1, 3]])
y = np.array([1, 2, 3])
theta = gradient_descent(X, y)
print(theta)  # Output: ~[0., 1.]


Backpropagation

Equation:

\[\frac{\partial L}{\partial w_{ij}} = \frac{\partial L}{\partial a_j} \cdot \frac{\partial a_j}{\partial z_j} \cdot \frac{\partial z_j}{\partial w_{ij}}\]

Explanation: Backpropagation applies the chain rule to compute gradients of the loss $L$ with respect to weights $w_{ij}$ in neural networks.

Practical Use: Enables efficient training of deep networks.

Implementation:

import torch
import torch.nn as nn

model = nn.Sequential(nn.Linear(2, 1), nn.Sigmoid())
loss_fn = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

X = torch.tensor([[0., 0.], [1., 1.]], dtype=torch.float32)
y = torch.tensor([[0.], [1.]], dtype=torch.float32)

optimizer.zero_grad()
output = model(X)
loss = loss_fn(output, y)
loss.backward()
optimizer.step()
print(f"Loss: {loss.item()}")




Loss Functions
Loss functions measure model performance and guide optimization.

Mean Squared Error (MSE)

Equation:

\[\text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2\]

Explanation: MSE calculates the average squared difference between true $y_i$ and predicted $\hat{y}_i$ values, penalizing larger errors more heavily.

Practical Use: Common in regression tasks.

Implementation:

import numpy as np

y_true = np.array([1, 2, 3])
y_pred = np.array([1.1, 1.9, 3.2])
mse = np.mean((y_true - y_pred)**2)
print(f"MSE: {mse}")  # Output: 0.01


Cross-Entropy Loss

(See Cross-Entropy above for details.)



Advanced ML Concepts
These equations power cutting-edge ML techniques.

Diffusion Process

Equation:

\[x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \epsilon \quad \text{where} \quad \epsilon \sim \mathcal{N}(0, I)\]

Explanation: This describes a forward diffusion process where data $x_0$ is gradually noised over time $t$, a key idea in diffusion models.

Practical Use: Used in generative AI like image synthesis.

Implementation:

import torch

x_0 = torch.tensor([1.0])
alpha_t = 0.9
noise = torch.randn_like(x_0)
x_t = torch.sqrt(torch.tensor(alpha_t)) * x_0 + torch.sqrt(torch.tensor(1 - alpha_t)) * noise
print(f"x_t: {x_t}")




Convolution Operation

Equation:

\[(f * g)(t) = \int f(\tau) g(t - \tau) \, d\tau\]

Explanation: Convolution combines two functions by sliding one over the other, extracting features in data like images.

Practical Use: Core to convolutional neural networks (CNNs).

Implementation:

import torch
import torch.nn as nn

conv = nn.Conv2d(1, 1, kernel_size=3)
image = torch.randn(1, 1, 28, 28)
output = conv(image)
print(output.shape)  # Output: torch.Size([1, 1, 26, 26])




Softmax Function

Equation:

\[\sigma(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}\]

Explanation: Softmax converts raw scores $z_i$ into probabilities, summing to 1, ideal for multi-class classification.

Practical Use: Used in neural network outputs.

Implementation:

import numpy as np

z = np.array([1.0, 2.0, 3.0])
softmax = np.exp(z) / np.sum(np.exp(z))
print(f"Softmax: {softmax}")  # Output: [0.09003057 0.24472847 0.66524096]




Attention Mechanism

Equation:

\[\text{Attention}(Q, K, V) = \text{softmax}\left( \frac{Q K^T}{\sqrt{d_k}} \right) V\]

Explanation: Attention computes a weighted sum of values $V$ based on the similarity between queries $Q$ and keys $K$, scaled by $\sqrt{d_k}$.

Practical Use: Powers transformers in NLP and beyond.

Implementation:

import torch

def attention(Q, K, V):
    d_k = Q.size(-1)
    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))
    attn = torch.softmax(scores, dim=-1)
    return torch.matmul(attn, V)

Q = torch.tensor([[1., 0.], [0., 1.]])
K = torch.tensor([[1., 1.], [1., 0.]])
V = torch.tensor([[0., 1.], [1., 0.]])
output = attention(Q, K, V)
print(output)




Conclusion

This blog post has explored the most critical equations in machine learning, from foundational probability and linear algebra to advanced concepts like diffusion and attention. With theoretical explanations, practical implementations, and visualizations, you now have a comprehensive resource to understand and apply ML math. Point anyone asking about core ML math here—they’ll learn 95% of what they need in one place!



Further Reading

  Pattern Recognition and Machine Learning by Christopher Bishop
  Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville
  Stanford CS229: Machine Learning
  PyTorch Tutorials


  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fossjobs: A job board for Free and Open Source jobs]]></title>
            <link>https://www.fossjobs.net/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050538</guid>
            <description><![CDATA[Job portal exclusively for Free and Open Source jobs around the globe.]]></description>
            <content:encoded><![CDATA[
				
					This is a job board exclusively for paid free & open source jobs: We only list jobs at organizations that improve and involve FOSS or open hardware projects. Merely using open source as part of the job is not enough.
					Listings are free. Submit jobs you find! You can also send us job links to submit [(at)] fossjobs [dot] net.
					
					
						Mastodon •
						IRC •
						RSS Feeds •
						GitHub
					
					
				
			
						Technology Assessor
						
					
						Deputy Director
						
					
						Operations assistant
						
					]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Petition to stop Google from restricting sideloading and FOSS apps]]></title>
            <link>https://news.ycombinator.com/item?id=45050502</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050502</guid>
            <description><![CDATA[These online petitions are worse than useless. They don’t do anything because they fail to communicate either conviction to a cause or any relevance of the signers. And they may take someone who would otherwise do something useful, like call their elected or participate in public comment, and make them complacent.]]></description>
            <content:encoded><![CDATA[
These online petitions are worse than useless. They don’t do anything because they fail to communicate either conviction to a cause or any relevance of the signers. And they may take someone who would otherwise do something useful, like call their elected or participate in public comment, and make them complacent.An open letter from the lead developers and decision makers of top-rated apps in the Play Store would be useful. But that takes work, unlike an online petition.
Hi, developer of a top-rated app in the Play Store [AnkiDroid].What do I need to do to make a difference, and how much time will this take?[My elected officials listen, what's the path? Legislation?]
> What do I need to do to make a difference, and how much time will this take?EU or US?> what's the path? Legislation?Send them a letter explaining why this is bad for you. Keep it strictly factual and ideally concise. Copy Google’s legal [1] and any relevant digital or markets regulators. (If in the US, don’t forget your state regulators.)Wait two weeks and then call the elected. Make sure they’re aware, and talk through your options. Send a letter thanking them for the call, incorporating any new information, and copy all of the previous parties again.[1] https://support.google.com/faqs/answer/6151275?hl=en
Yes. Not a rando online petition: “we have succesfully escalated complaints on this problem to consumer agencies in France, Germany, and Australia, and have brought forth petitions for new law on this problem to various countries.”Petitions from verified voters are powerful. Triply so if done in person, because the infrastructure that can collect signatures in person can also e.g. back a primary challenge or plebiscite.
Has legislation been created as a result of that awareness?And the vast majority of their awareness actually came from a failed counter-campaign by the opposition.
Petitioning EU lawmakers would be better. American control of European data is already a bit issue at the moment in the face of US threats over Digital taxes and Microsoft being used to punish ICJ members.
EU (and the rest of Europe) are more concerned with controlling their own populations than keeping their data safe from the US. They are very much pro-big business dominance on the internet BECAUSE it makes it easier for them to regulate.A lot of governments want to use American AI systems to run things to cut costs.
Honestly, I'll be surprised if this plan doesn't break the DMA/DSA already.Someone will need to collect the necessary resources to bring the fight to the courts, though.
Please bear in mind that Google was perfectly aware how much negative feedback they will receive from developers and they are completely and fully prepared for it. In other words, this decision was made with full awareness that developers and "screeching voices of minority" won't like it.
They can still miscalculate the intensity of the backlash or the willingness of people to do something about it. Many such stories. "The enemy has a plan so let's do nothing" is a great way to get consistently rolled in the world. As the saying goes, everyone has a plan until they are punched in the face; dishing out the occasional (and in this case fully metaphorical) punch in the face is not a hopeless endeavor.(I agree with some other threads that merely signing a random petition is not a punch to the face. That's just whining. Systematic and organized, perhaps, but just whining.)
Yep. In the announcement, they already got full green light approval from various governments basically saying this was a great idea and the clear path ahead.> …with Indonesia’s Ministry of Communications and Digital Affairs praising it for providing a “balanced approach” that protects users while keeping Android open.> …Thailand’s Ministry of Digital Economy and Society sees it as a “positive and proactive measure” that aligns with their national digital safety policies.> In Brazil, the Brazilian Federation of Banks (FEBRABAN) sees it as a “significant advancement in protecting users and encouraging accountability.”
The nerds are the ones who pave the way for technology, enabling people around them to adapt more easily to it. They find new paths into the undiscovered land that then get either shut down or commercially exploited. Companies like Google have piggybacked on this volunteer work.I have the feeling that these companies don't need nerds anymore. Who needs pioneers if everything is paved and regulated?
Do you have evidence that they have accurate estimates of the potential for backlash? It is not that uncommon that people in power take decisions without thinking them though properly
I've got no evidence that they have an estimation of the volume or scale of the feedback.But I reckon we can all make an educated guess that they did anticipate negative feedback.
You might be right, but didn't same thing applied to Web Environment Integrity stuff, that they ended up stepping back on (for how short of a time stretch is another story)?
First, web environment integrity was about the web as a whole, not about something that is completely owned and under their control. Second, they will not stop trying. It was not their first approach and it won't be the last.So, I believe that if they decided this is the path they want to take - they will find one way or another. It's not that resistance is futile (it's not!) but I believe that petitions are not a good tool for the case.
> delegitimize developer criticism before addressing its substance. This attacks the critics rather than engaging with their actual concernsIt’s a petition, not a debate. Who is speaking is absolutely relevant. Tens of thousands of tiny developers with a few million collective users aren’t relevant to Google.> Appeal to Corporate OmniscienceThis is not a logical fallacy. You may be thinking of appeal to improper authority. But in that case the criticism is that we don’t know Google anticipated this. Not what you wrote, which is technically ad hominem, since you conclude adversely based on Google being a corporation.> ignores the possibility that feedback could be legitimate even if anticipatedNo, it does not. It says such a petition brings no new information to the decision makers at Google. If Google (note: this is OP’s hypothesis, not a fact) anticipated small developers complaining. Small developers are complaining. That doesn’t make the complaints wrong. But it would make them practically irrelevant.
I did not mention the petition. I am merely offering feedback on the grandparent's argument about Google's policy (which itself also does not mention the petition).It is absolutely a debate. Why are you here if not to debate?
> Appeal to Corporate Omniscience - The argument assumes that because Google anticipated negative feedback, this somehow validates their decision or renders criticism invalid. A company expecting pushback doesn't automatically make their decision correct.This argument is not present nor implied in my comment.> Circular Reasoning - The logic is essentially: "Google knew people would complain, therefore the complaints don't matter because Google expected them." This doesn't address whether the complaints have merit.My text did not comment or expressed any opinion whether the complaints have merit.> False Dichotomy - It implies that developer feedback is either completely valid (and Google should have changed course) or completely invalid (because Google was "prepared" for it). This ignores the possibility that feedback could be legitimate even if anticipated.My comment does not present this dichotomy as described by you.
Exactly, your comment is absolutely useless. It added nothing of logical value to this debate. All your arguments are logically invalid.
The easy thing to do is ignore an AI slop comment like that, because someone apparently couldn’t think for themselves and had to shove it into an arrogant little machine to come up with a response.
Whether or not the arguments are AI generated is itself a logical fallacy.Insinuating I cannot think is also a logical fallacy.Man you guys are really bad at this.
it's really sad that just pointing out logical mistakes in someone's post gets you attacked, and ppl even accuse you of using AI like it's changing anything. we seriously need a proper public campaign to teach folks how to actually have real discussions again and to spot weak or irrelevant argumentsthis comment was AI generated 
or was it
I am very happy if it made a few people think and/or get upset!My comment was totally AI generated, obviously. But as you lovingly touched on, it is irrelevant :)
> sad that just pointing out logical mistakes in someone's post gets you attackedThey didn’t. They mis-applied fallacies and in one case made one up. There was no substantial good-faith response to OP’s argument. Instead we got a shallow dismissal masked in the language (but not substance) of logic.It was fun to engage with! But not meaningful. The online-commenting equivalent of scrolling short-form videos and getting enraged or delighted or awe-struck for a picosecond.
> Can you elaborate how the other fallacies were mis-appliedSure. OP didn’t ever reject the developers’ arguments. He’s criticising their methods for activism.OP doesn’t use minimising the developers to undermine their arguments because they aren’t attacking their arguments. To the extent methods are being attacked, still, they’re not rejected because of who is speaking, but how. To the extent it could be mistaken for ad hominem, it would be in tone policing, but that’s not what you said and it is not true because OP was citing Apple’s language, as evidenced by the quotes.Appeal to corporate omniscience is not a fallacy. (And OP doesn’t cite Google as evidence for their arguments, so no appeal to authority.)Circular reasoning doesn’t apply, even to your example, because complaints not mattering doesn’t cause Google to expect them.False dichotomy does not apply because OP never argued any dichotomy. The closest they came was hyperbolic language (“perfectly” and “completely and fully”). But that’s closer to mode scope than any dichotomy, and it’s not even that because OP is not arguing syllogistically.
> Man you guys are really bad at this.Not really. You should have learned by now that jumping into a conversation on the internet with the wikipedia "list of logical fallacies" page open on the other half of the screen and then vaguely ascribing aspects of a comment to a cherry-picked list of fallacies basically only ever results in people making fun of you.I don't even think that would fly on reddit. People have been making fun of that style of response since IRC. If anybody is bad at anything, it's you at understanding how to have a productive conversation on an internet forum.
Ah yes, the San Francisco Consultant now screeching “logical fallacies!” like it’s a magic defense. It’s not, lol.
Unrelated: none of the "AI detectors" work. It is impossible to discern human text from AI. Although sometimes we might believe we can feel it, it is still false.
I just pasted my last conversation with ChatGPT into that which also gave me 0% AI GPT. I would take that site with a mountain of salt.
The above post listing fallacies is entirely AI-generated and is likely a sleeper agent account that has been woken up from a pattern of posting non-content to disguise inactivity to start astroturfing for Google.The cost/benefit of doing such on Hn is high.
I think the biggest impact we can have, besides getting government regulation involved, is building the market share of an alternative.
Yes. A decision like this creates the impetus to move to alternatives like Jolla OS that have an Android-compatible layer.20 years in, the so-called "smartphone" duopoly have jointly converged towards a "dumb terminal" strategy, where almost nothing can be done without cloud-based authentication from a centralized third party. And this was the case prior to the AI horse manure they're baking into the OS.I use the Fossify forks of Simple Mobile Tools apps (Gallery, File Manager, Calculator) because these can be installed via APK files and just be left alone. My Google Calculator app on the other hand seems to want to download new updates every single month.
Build for the web. App stores are overrated. They will continue to make the same mistakes until they are irrelevant. Eventually.
It is a social problem which is hard to reverse.People use app stores because they are used for artificially worsened web pages. They are used to find apps with similar properties from app store.And Google search is artificially so bad that they won’t even try it to find some  apps. And most won’t use other search engines.
Re DJI Fly: a combination of WebBluetooth, WebRTC, the normal location API, offline web pages (through managed caches), regular browser video features, and a bunch of other web technologies.Re SyncThing: there's the File System Access API. You can ask the user for a folder and then operate on the files and directories inside it. Also from a locally cached offline copy, of course. Serviceworkers are there to run in the background, though I'm not 100% sure if the FS API and service workers can be combined to be honest.It'll need as much effort or maybe even more to port it to the web as it has taken to develop the Android app, but it's almost definitely possible, at least on Chrome.As part of Google's attempt to break free from the iOS app store, they accidentally invented an alternative to their own draconic measures.
By utilizing anti-user language like "sideloading" you are already submitting to their desire to own all hardware.
It's too late. As a developer, I'm pulling all my Android apps away from the Play Store.If Google is hostile to me an my users, I prefer to dedicate my volunteer time to respectful plateforms instead.
Hardly anything left, Apple and Microsoft have their own issues, Web is basically ChromeOS aka Google, and I still cannot buy GNU/Linux or BSD laptops at the local computer store.
just making sure you understand the proposal correctly. you'd still be able to distribute the app through whatever means you want; the app just has to be signed with a key tied your identity that is verified by google, if trying to install on a "certified device" (which will be most devices).i still disagree with the move. but it's not as bad as it could be. maybe there's a way to "unlock" a certified device (similar to unlocking the bootloader)?
I thought the Digital Markets Act in the EU would make it illegal for Apple and Google to prevent people from sideloading apps. Is there some kind of loophole that allows Google to do this anyway?
The EU has lots of laws, including some that were made after the DMA.  One of them is the CRA, which says that by the end of 2027 all app marketplaces are required to provide developer contact info to people who download software.  If the contact info is fake or wrong, the app marketplace can face fines.So the app marketplace should probably verify the contact info, right?  Would you take on that kind of risk to protect the anonymity of some rando you’ve never met and will never give you any money?  I wouldn’t.
I don't understand how side-loading would impact information marketplaces should provide. If it's side-loaded, that's no longer marketplace responsibility.
From what I’ve read Google’s new process sounds much like Apple’s app notarization process. Apple is still in complete control the user just isn’t required to go through the App Store.
I just realized how powerless we are. The situation is almost unavoidable. Majority people will just accept this. They are unaware how restricted they are, thus they don't care.
are there enough devs to make "non-certified" phones? also i wonder if you'll be able to disable the verification check similar to bootloader unlocking.
Non-certified phones won't be sold in Western markets. This whole scheme has one goal only, and that's to snuff out DRM-unfriendly third party apps like alternative Youtube clients, videogame emulators and P2P file sharing apps.
When I was back there in Seminary SchoolThere was a person thereWho put forth the propositionThat you can petition the Lord with prayerPetition the Lord with prayerPetition the Lord with prayerYou cannot petition the Lord with prayer!If you truly want to protect your rights then don't petition Google, but instead petition FTC and other antitrust agencies. Petitioning Google just establishes that they have a choice here.
Why wait? I’ve never installed many apps on my phone, but I don’t have any problems using graphene. My bank nor credit card apps have any problem.
It's mainly the lack of emergency services support in my country. Every time I called the operator can't see where I am through GPS, first question asked was what state im in.
Why would you kneecap yourself on hardware and get a Pixel over an iPhone if not to install Graphene as the very first action post-unboxing?Graphene is the only reason I own any pixel devices.
Don't hold your breath for the EU this aligns with the Chat Control being pushed. Banning people from side loading keeps you from escaping their plan of always listening.
I agree with the spirit of the petition and I will sign it but I think it's better to be a petition to the EU to force google to stop their adversarial interoperabilty.EU have done it with Apple and their trash lightning cable, forcing them to adopt the USB c standard. EU fined Meta and Google for mishandling our personal data (like all the time), and forced (kinda) both Google and Apple to allow alternative stores. This bs will not fly in the EU.I will not tell you to stop using Google products and Android, since you are most likely a dev or FOSS on the Android ecosystem. But yeah, Google are pretty evil.- sent from my Android - /s
> Just imagine giving sensitive personal, government-issued ID to a corporation to install an app outside Google PlayIn Spain, I have to give my NIE (National ID number) and show my government ID just to send or receive a package from FedEx. Why should I have to give up sensitive information just to receive a package?
Can someone articulate for me why everyone seems to be opposed to this?You can sideload apps on non-google-certified android builds/installs just fine right? If you're going to publish an app that literally be installed on billions of devices, is this not a sensible measure? Long overdue even? Why isn't Windows and Linux distros enforcing this as well is my question!Do you guys understand that people's lives are being ruined by malware? and the most popular way of deploying malware on the most popular platform (android) is sideloading apps!This is a similar situation as "Freedom of speech isn't freedom of reach". You can publish any android app you want, that doesn't give you the right to anonymously deploy those apps on everyone's personal tracking devices (phones).I get a petition to allow alternative attestation and verification authorities. and honestly, I don't think Alphabet has much choice on that given EU and US anti-trust policies. I can't image the EU being ok with a US company collecting the IDs of all its developers.For about a decade now, on Windows, you are required to have an ID-verified code signing certificate so sign drivers for example. And that has dramatically reduced rootkit abuse on the platform. Don't get me wrong, I also don't want to submit my ID to anyone. But this is a very sensible measure, one that will improve security in measurable and significant ways to millions of regular people.
> You can publish any android app you want, that doesn't give you the right to anonymously deploy those apps on everyone's personal tracking devices (phones).This is about users freedom to install apps on the devices they own.>  non-google-certified android builds/installsThose targets are rapidly disappearing. Alternative Android ROMs are dying one by one. Look at how few modern phones are officially supported by LineageOS. And many of those are Pixels which Google is no longer releasing binaries for (making ROM builders lives harder).> Do you guys understand that people's lives are being ruined by malware?Do you have figures to back that up? There are already multiple warnings when sideload apps.> For about a decade now, on Windows, you are required to have an ID-verified code signing certificate so sign drivers for example.Drivers and applications are not the same things.
It really, really sucks to be tricked into installing malware, and I have sympathy for the victims. But this measure will remove so much freedom from a much larger group of people, and therfore it isn't justified.We just have to educate people better about how to protect themselves online, not resort to paternalistic control regimes which just happens to give one of the largest tech giants the power to also crush anything that it sees as a threat to their business model.
I agree, people here have no empathy to less technical users. Peoples' lives being ruined is not a hyperbole. You have people losing their life savings due to pig-butchering scams and such. And people here think their convenience and desire to publish apps anonymously outweighs this?]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Are OpenAI and Anthropic Losing Money on Inference?]]></title>
            <link>https://martinalderson.com/posts/are-openai-and-anthropic-really-losing-money-on-inference/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050415</guid>
            <description><![CDATA[I keep hearing what a cash incinerator AI is, especially around inference. While it seems reasonable on the surface, I've often been wary of these kind of claims, so I decided to do some digging.]]></description>
            <content:encoded><![CDATA[
    
    
    
        I keep hearing what a cash incinerator AI is, especially around inference. While it seems reasonable on the surface, I've often been wary of these kind of claims, so I decided to do some digging.
I haven't seen anyone really try to deconstruct the costs in running inference at scale and the economics really interest me.

This is really napkin math. I don't have any experience at running frontier models at scale, but I do know a lot about the costs and economics of running very high throughput services on the cloud and, also, some of the absolutely crazy margins involved from the hyperscalers vs bare metal. Corrections are most welcome.

Some assumptions
I'm only going to look at raw compute costs. This is obviously a complete oversimplification, but given how useful the current models are - even assuming no improvements - I want to stress test the idea that everyone is losing so much money on inference that it is completely unsustainable.
I've taken the cost of a single H100 at $2/hour. This is actually more than the current retail rental on demand price, and I (hope) the large AI firms are able to get these for a fraction of this price.

Secondly, I'm going to use the architecture of DeepSeek R1 as the baseline, 671B total params with 37B active via mixture of experts. Given this gets somewhat similar performance to Claude Sonnet 4 and GPT5 I think it's a fair assumption to make.
Working Backwards: H100 Math From First Principles
Production Setup
Let's start with a realistic production setup. I'm assuming a cluster of 72 H100s at $2/hour each, giving us $144/hour in total costs.
For production latency requirements, I'm using a batch size of 32 concurrent requests per model instance, which is more realistic than the massive batches you might see in benchmarks. With tensor parallelism across 8 GPUs per model instance, we can run 9 model instances simultaneously across our 72 GPUs.
Prefill Phase (Input Processing)
The H100 has about 3.35TB/s of HBM bandwidth per GPU, which becomes our limiting factor for most workloads. With 37B active parameters requiring 74GB in FP16 precision, we can push through approximately 3,350GB/s ÷ 74GB = 45 forward passes per second per instance.
Here's the key insight: each forward pass processes ALL tokens in ALL sequences simultaneously. With our batch of 32 sequences averaging 1,000 tokens each, that's 32,000 tokens processed per forward pass. This means each instance can handle 45 passes/s × 32k tokens = 1.44 million input tokens per second. Across our 9 instances, we're looking at 13 million input tokens per second, or 46.8 billion input tokens per hour.
In reality, with MoE you might need to load different expert combinations for different tokens in your batch, potentially reducing throughput by 2-3x if tokens route to diverse experts. However, in practice, routing patterns often show clustering around popular experts, and modern implementations use techniques like expert parallelism and capacity factors to maintain efficiency, so the actual impact is likely closer to a 30-50% reduction rather than worst-case scenarios.
Decode Phase (Output Generation)
Output generation tells a completely different story. Here we're generating tokens sequentially - one token per sequence per forward pass. So our 45 forward passes per second only produce 45 × 32 = 1,440 output tokens per second per instance. Across 9 instances, that's 12,960 output tokens per second, or 46.7 million output tokens per hour.
Raw Cost Per Token
The asymmetry is stark: $144 ÷ 46,800M = $0.003 per million input tokens versus $144 ÷ 46.7M = $3.08 per million output tokens. That's a thousand-fold difference!
When Compute Becomes the Bottleneck
Our calculations assume memory bandwidth is the limiting factor, which holds true for typical workloads. But compute becomes the bottleneck in certain scenarios. With long context sequences, attention computation scales quadratically with sequence length. Very large batch sizes with more parallel attention heads can also shift you to being compute bound.
Once you hit 128k+ context lengths, the attention matrix becomes massive and you shift from memory-bound to compute-bound operation. This can increase costs by 2-10x for very long contexts.
This explains some interesting product decisions. Claude Code artificially limits context to 200k  tokens - not just for performance, but to keep inference in the cheap memory-bound regime and avoid expensive compute-bound long-context scenarios. This is also why providers charge extra for 200k+ context windows - the economics fundamentally change.
Real-World User Economics
So to summarise, I suspect the following is the case based on trying to reverse engineer the costs (and again, keep in mind this is retail rental prices for H100s):

Input processing is essentially free (~$0.001 per million tokens)
Output generation has real costs (~$3 per million tokens)

These costs map to what DeepInfra charges for R1 hosting, with the exception there is a much higher markup on input tokens.

A. Consumer Plans

$20/month ChatGPT Pro user: Heavy daily usage but token-limited

100k toks/day
Assuming 70% input/30% output: actual cost ~$3/month
5-6x markup for OpenAI



This is your typical power user who's using the model daily for writing, coding, and general queries. The economics here are solid.
B. Developer Usage

Claude Code Max 5 user ($100/month): 2 hours/day heavy coding

~2M input tokens, ~30k output tokens/day
Heavy input token usage (cheap parallel processing) + minimal output
Actual cost: ~$4.92/month → 20.3x markup


Claude Code Max 10 user ($200/month): 6 hours/day very heavy usage

~10M input tokens, ~100k output tokens/day
Huge number of input tokens but relatively few generated tokens
Actual cost: ~$16.89/month → 11.8x markup



The developer use case is where the economics really shine. Coding agents like Claude Code naturally have a hugely asymmetric usage pattern - they input entire codebases, documentation, stack traces, multiple files, and extensive context (cheap input tokens) but only need relatively small outputs like code snippets or explanations. This plays perfectly into the cost structure where input is nearly free but output is expensive.
C. API Profit Margins

Current API pricing: $3/15 per million tokens vs ~$0.01/3 actual costs
Margins: 80-95%+ gross margins

The API business is essentially a money printer. The gross margins here are software-like, not infrastructure-like.
Conclusion
We've made a lot of assumptions in this analysis, and some probably aren't right. But even if you assume we're off by a factor of 3, the economics still look highly profitable. The raw compute costs, even at retail H100 pricing, suggest that AI inference isn't the unsustainable money pit that many claim it to be.
The key insight that most people miss is just how dramatically cheaper input processing is compared to output generation. We're talking about a thousand-fold cost difference - input tokens at roughly $0.005 per million versus output tokens at $3+ per million.
This cost asymmetry explains why certain use cases are incredibly profitable while others might struggle. Heavy readers - applications that consume massive amounts of context but generate minimal output - operate in an almost free tier for compute costs. Conversational agents, coding assistants processing entire codebases, document analysis tools, and research applications all benefit enormously from this dynamic.
Video generation represents the complete opposite extreme of this cost structure. A video model might take a simple text prompt as input - maybe 50 tokens - but needs to generate millions of tokens representing each frame. The economics become brutal when you're generating massive outputs from minimal inputs, which explains why video generation remains so expensive and why these services either charge premium prices or limit usage heavily.
The "AI is unsustainably expensive" narrative may be serving incumbent interests more than reflecting economic reality. When established players emphasize massive costs and technical complexity, it discourages competition and investment in alternatives. But if our calculations are even remotely accurate, especially for input-heavy workloads, the barriers to profitable AI inference may be much lower than commonly believed.
Let's not hype the costs up so much that people overlook the raw economics. I feel everyone fell for this a decade or two ago with cloud computing costs from the hyperscalers and allowed them to become money printers. If we're not careful we'll end up with the same on AI inference.

    
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Windows 11 Update KB5063878 Causing SSD Failures]]></title>
            <link>https://old.reddit.com/r/msp/comments/1n1sgxx/windows_11_update_kb5063878_causing_ssd_failures/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050192</guid>
        </item>
        <item>
            <title><![CDATA[Claude Code Checkpoints]]></title>
            <link>https://claude-checkpoints.com/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45050090</guid>
            <description><![CDATA[The essential companion app for developers using Claude AI. Seamlessly track all code changes and never lose your work.]]></description>
            <content:encoded><![CDATA[
    
    
        
            ✓ Checkpoints
            
                Features
                How It Works
                MCP Integration
                Download
            
        
    

    
    
            Never Lose Your Work Again
            Automatic version control for Claude Code projects
            
            ✨ Free to use • macOS 13.5+
            
                
                    
                        
                        Download on the
                        Mac App Store
                    
                
            
            
            
            🎬 Watch it in action
            
                
                    
                    
                
            
        

    
    
            Everything You Need for Safe Coding
            
                
                    🔍
                    Automatic Change Detection
                    Continuously monitors your entire project for file changes. No setup required - just select your project folder and start coding.
                
                
                    💾
                    One-Click Checkpoints
                    Create instant snapshots of your project state before making risky changes. Each checkpoint captures all files and their contents.
                
                
                    📊
                    Visual Diff Viewer
                    See exactly what changed between checkpoints with our built-in diff viewer. Track additions, modifications, and deletions at a glance.
                
                
                    ⏰
                    Time Travel for Code
                    Instantly restore your project to any previous checkpoint. Perfect for experimenting with confidence or recovering from mistakes.
                
                
                    🤖
                    Claude Integration
                    Seamlessly integrates with Claude Desktop through MCP protocol. Automatic checkpoints when tasks complete.
                
                
                    📁
                    Full Project Backup
                    Every checkpoint includes a complete backup of all project files. Your work is always safe and recoverable.
                
            
        

    
    
            Simple Workflow, Powerful Protection
            
                
                    1
                    Select Project
                    Choose your project folder in the Checkpoints app
                
                
                    2
                    Start Coding
                    Work with Claude Code as usual - changes are tracked automatically
                
                
                    3
                    Auto Checkpoint
                    Checkpoints are created automatically when tasks complete
                
                
                    4
                    Restore Anytime
                    One click to restore any previous state if needed
                
            
        

    
    
            Seamless MCP Integration
            Works automatically with Claude Desktop through Model Context Protocol
            
            
                
                update_task_status("Fix login bug", "in_progress")
                
                update_task_status("Fix login bug", "completed")
                
                restore_checkpoint("checkpoint_id")
                
            
            
                
                    🔌 Auto-Connect
                    MCP server starts automatically on port 8765. Claude Desktop connects instantly when you open a project.
                
                
                    📝 Task Tracking
                    Every task start and completion is tracked. Checkpoints are created automatically at key moments.
                
                
                    🔄 Full Control
                    Claude can list checkpoints, view diffs, and restore previous states through MCP commands.
                
            
        

    
    
            See It In Action
            
                
                            Main Interface
                            Clean, intuitive checkpoint management
                        
                
                            Diff Viewer
                            Visual comparison between checkpoints
                        
                
                            MCP Integration
                            Seamless Claude Desktop connection
                        
            
        

    
    

    

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lesser known mobile adtech domains where data is sent]]></title>
            <link>https://jamesoclaire.com/2025/08/28/uncovering-lesser-known-mobile-adtech-domains/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45048736</guid>
            <description><![CDATA[AppGoblin has now run over 40k apps in an emulator, tracking millions of API calls thousands of advertising domains. Unfortunately, some of them are dark, meaning they have no landing page of any kind, and I’m unclear who controls these domains.]]></description>
            <content:encoded><![CDATA[
	

		

			

	
		
AppGoblin has now run over 40k apps in an emulator, tracking millions of API calls thousands of advertising domains. Unfortunately, some of them are dark, meaning they have no landing page of any kind, and I’m unclear who controls these domains.  



news-cdn.site marketingcloudapis.com kickoffo.site onegg.site lazybumblebee.com qa-analytics.com acobt.techyastatic.net



Let’s see if we can figure them out!



qa-analytics.com



This one is a mystery. Seems like it’s related to Germany since it’s always resolving to HETZNER and german IPs. Checking the shared IPs, it looks like they do overlap with unity3d.com domains sometimes.



Again, this whole list is games. 




Woodoku – Wood Block Puzzle



Draw Climber



Spider Rope Hero: Action Game



Running Pet: Dec Rooms



Bubble Shooter 2



Pirate Treasures: Jewel & Gems



Tik Tap Challenge



Collect Em All! Clear the Dots



Gun Simulator & Lightsaber




data deep dive



Looking at the requests I can match various keys to values from untiy3d.com API calls! Specifically they share the same `app_key` values. 



acobt.tech



Well that name definitely comes off as esoteric at first.  First let’s check the IP cluser and see what we find, of the 233 apps sending/receiving from acobt.tech we have 4 other sites with 1:1 matches that are all sites that do not have any landing pages.



acobt.tech 233news-cdn.site 233inmense.site 232kickoffo.site 232



searching…



Searching the internet shows various hits saying some of these belong to Bigo Ads.  Let’s check the apps’ SDKs and see



Apps



Again we got lots of games, and looking it looks like AppGoblin has indeed already found that each of these has a Bigo Ad SDK. 




Pizza Ready!



Sculpt People



Vita Mahjong



Modern Bus Simulator: Bus Game



Gym Heros: Fighting Game



Blockman Go




onegg.site



Wait, this one also matches the IPs for the other various Bigo Ads. Seems like Bigo really uses a lot of random domains? 



lazybumblebee.com



OK, great name. This one appears in clusters of SDK advertising, making me think it’s related to a mediation SDK of some kind (rather than to one specific ad network). Possibly this is bidmachine.io’s as it is the most common, but really all the top ad newtorks appear nearly 1:1 along side it across the 276 apps I’ve found it in:bidmachine.io 275unity3d.com 270doubleclick.net 269mtgglobals.com 267rayjump.com 267applovin.com 261vungle.com 257



Example Apps



Definitely game focused list here.  They almost all call variations of d.lazybumblebee.com/track/sdk-event 




Helix Jump



Going Balls



Paper.io 2



aquapark.io



Snake.io – Fun Snake .io Games



Hole.io



1945 Air Force: Airplane Games




Shared IPs



Looking around there are lots of examples of shared IP addresses with everestop.io and bidmachine, so I think that might have solved that. 



everestop.io 172.240.40.172bidmachine.io 172.240.40.172bidmachine.io 204.74.252.252everestop.io 172.240.61.171voisetech.com 34.216.198.39



SDK?



Looks like a lot of the apps have the io.bidmachine and com.explorestack SDKs, so I’m thinking that `lazybumblebee.com` does indeed belong to BidMachine and helps it with some app mediation service.



marketingcloudapis.com



 marketingcloudapis.com is just the kind of generic descriptive name I’d come up with.  



Example Apps



Example apps, there are a lot of very corporate apps in here along with lots of shopping. 




adidas: Shop Shoes & Clothing



Claro música



Domino’s Pizza USA



SiriusXM: Music, Sports & News



GasBuddy: Find & Pay for Gas




Example API Call



Each app sends off two API calls on start to a unique (per app) subdomain on marketingcloudapis.com with the response from the first API call below. The information sent seems somewhat bland compared to the usual deep scraping that advertising SDKs do. So this is likely paired with other API calls already going out. 



x-mashery-message-id: 4e9eb0f4-6eaa-4f27-bb66-a3694cffe471
x-mashery-responder: 56bf7c64cc-lnkfz
strict-transport-security: max-age=31536000; includeSubDomains; preload
Content-Security-Policy: upgrade-insecure-requests
x-xss-protection: 1; mode=block
x-frame-options: DENY
x-content-type-options: nosniff
cache-control: no-cache, must-revalidate, max-age=0, no-store, private
Referrer-Policy: strict-origin-when-cross-origin
Vary: Origin, X-HTTP-Method-Override
Content-Length: 339
Content-Type: application/json; charset=UTF-8
Date: Wed, 27 Aug 2025 22:12:39 GMT
Connection: keep-alive
Keep-Alive: timeout=5

{
    "nodes": [
        {
            "version": 1,
            "name": "blocked",
            "items": {
                "blocked": 0
            }
        },
        {
            "version": 1,
            "name": "pushFeaturesInUse",
            "items": {
                "inbox": false
            }
        },
        {
            "version": 1,
            "name": "appConfig",
            "items": {
                "inApp": {
                    "gateEventProcessingMs": 1000
                },
                "event": {
                    "activeEvents": []
                },
                "endpoints": [],
                "deliveryReceipt": {
                    "deliveryReceiptStatus": 0,
                    "gateDeliveryReceiptProcessingMs": 5000
                }
            }
        }
    ]
}



Related Domains



Checking on domains that are called together, it looks like this is almost always called with googleapis.com so possibly this is related to Google, but this is a bit weak as a lot of Android apps have integrations with Google.



EDIT: I posted this on HackerNews and user politelemon correctly identified this as SalesForce. Very awesome spot by that user, and it matches the various AppGoblin SDKs for each app as in this example for the Adidas app SDKs.



End Results!



Much better than I expected. A bit of digging and all the URLs were figured out with the exception of marketingcloudapis.com which I was a bit unsure of, but looks like google.com



news-cdn.site -> Bigo Adsmarketingcloudapis.comkickoffo.site -> Bigo Adsonegg.site -> Salesforcelazybumblebee.com -> BidMachineqa-analytics.com -> Unityacobt.tech -> Bigo Adsyastatic.net -> Yandex





			




	
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Sci-Hub has been blocked in India]]></title>
            <link>https://sci-hub.se/sci-hub-blocked-india</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45048473</guid>
            <description><![CDATA[I am personally sending this mail to support your dedication and help given to young researchers like me. Now, my thesis writing is going smoothly because of Sci-Hub. I am writing independently without paying for journals. Sharing knowledge should not compare with money. I respect you for your sacrifices and hardships you have faced from the beginning. I have in my mind to do some donations of my capacity to the Sci-Hub project, and that time will come soon.]]></description>
            <content:encoded><![CDATA[

    

    I am personally sending this mail to support your dedication and help given to young researchers like me. Now, my thesis writing is going smoothly because of Sci-Hub. I am writing independently without paying for journals. Sharing knowledge should not compare with money. I respect you for your sacrifices and hardships you have faced from the beginning. I have in my mind to do some donations of my capacity to the Sci-Hub project, and that time will come soon.

    
    Research Scholar in Chemistry
    Dept. of Basic Sciences & Social Sciences
School of Technology
North-Eastern Hill University (NEHU)


    



    This is Subhendu Samanta from India. I am a 2nd year PhD student. From beginning of my higher studies i got to know about using Sci-Hub, where we can have access  to any paper, read it and can gather knowledge, while the journals are trying to keep the knowledge in terms of money. And seriously from that time i started to know details of Sci-Hub and the incredible true story of yours. I don't know how to express my respect for you but the only thing i can tell you is "THANK YOU". I regularly  write blogs about you and also given some presentation about your journey. You are my true inspiration during whenever i even get depressed. My this mail is to tell you, you have moved scientific research one step forward.

    Subhendu Samanta
    
    


    



    Greetings of the day. I used sci-hub to download papers for my research work many times. Thanks for providing this free platform.

    Satish R. Jondhale
    Assistant Professor
    Department of Electronics & Telecommunication Engg.
Amrutvahini College of Engineering, Sangamner, Maharashtra, India


    



    Moreover thanks for the, SCI-hub it is very helpful. without this not my but I can say the Ph.D. and Research if now depends upon it. Still, there are some publications that cannot be reached by the SCI-hub. But it is the best help from you. Yor are doing real research and applying for the use of people of this earth. Otherwise everyone is making money.

    Sunil Kumar
    Post Doctoral Fellow
    ICMR - Regional Medical Research Center, BRD Medical College Campus, Gorakhpur (UP) - 273013, INDIA


    



    Thanks for the site, will surely love to assist u in any way possible. Your site helps a lot of students in research community.

    Deepak Kumar Tiwari
    Research Scholar
    Maulana Azad National Institute of Technology, Bhopal


    



    Hii dear Alexandra Elbakyan. Th website SciHub you have developed is like an oasis in the desert for people like me. I am assistant professor in a Pharmacy College in Central India. The research articles which need payment are very costly. SciHub is the only source where I can get them. Thank you very much for this endeavor. Please continue this work uninterrupted. God bless you.

    Keshav Moharir
    Assistant Professor
    Gurunanak College of Pharmacy,
behind C.P.Foundry,near Dixit Nagar,
Nari Road, Nagpur - 26 INDIA


    



    I simply cannot begin to thank you enough for the work that you have done.

When I had done my MPhil in English, websites developed by you and your team like, sci-hum.tw and libgen.is had been life savers for researchers like us, since in India there is a serious dearth of any academic materials;; to extent that you cannot even buy books even if you paid money.

I am therefore very very grateful for all that you have done to benefit poor academicians like us. May God give you strength and bless you. you have done an outstanding job.

My heartfelt gratitude and regards to you from the whole of the education society here in India.

Thank you very very much.

    Arusharko Banerjee
    Lecturer
    Kolkata, West Bengal, India


    



    Just want to thank you a million times over for making research papers available to us scholars in India without access to most of the expensive sites. Without sci-hub my ongoing Ph.D. would have been impossible and the same holds true for so many of my friends pursuing research. Thank you for doing what you do and believing in all that you do.

    Pritha Banerjee
    PhD student
    Kolkata, India


    



    my name is sujith suresh . firstly i need to congratulate you for the amazing work  you have done mainly about the sci-hub . It really helped us in gaining knowledge about lot of things. 

    Sujith Suresh
    
    


    



    I would like to thank you from mu bottom of my heart. Without your work on sci-hub people like me never would able to access the best research journals. I always wondering about sci-hub and its founder. Now, I could see you and I am so happy to see you. I don't know how to express my sincere gratitude to you. I just got doctoral degree with the help of your great great work.
Thanks a lot.
Love from India.

    Sandeep K M
    Assistant Professor in Physics
    BIT, Mangalore


    



    First I must submit my heartfelt wishes and sincere thanks to you for your wonderful service.
Everyday I am improving my knowledge through Sci-hub only.
I cannot imagine my research without Sci-hub.
Most importantly I cannot afford the money the journals are demanding. We people always love your Sci-hub.

You know I sent, some small donation to Sci-hub.
Like me, there are thousand and thousand poor researchers are always praise you for your noble work.
Kindly if any help is needed, you post. We will be ready to serve for your sincere works.
We people are always with you on your side.
Kindly acknowledge my wishes and thanks.
God bless you and I pray for your peace and health.

Long live Sci-hub. Long live Alexandra Elbakyan.

    M Kanagasabapathy
    
    India


    



    Thank you for making science accessible.

    Prashanth K.K.
    
    


    



    Hi alexandra ...i am Rajkamal and so thankful to you because your sci-hub. It helps me lot for my research. i owe you lot. Thank you so much for sci-hub. stay blessed  and God bless you. bye, take care

    Dr. A. Rajkamal
    
    Dept. of Chem. Engg. IIT Bombay
Powai, Mumbai 


    



    I am a newbie Neurosurgeon from India. I have completed my Neurosurgery from India's dedicated neurosciences centre at Bangalore. NIMHANS - National Institute of Mental Health and Neurosciences.
This institute was established way back in 1923 as dedicated psychiatry hospital. Today this institute is apex centre in India for Neurology, Neurosurgery and Psychiatry.

I did my thesis on studying neural network in Epilepsy patients using DTI MRI scans.

It is very grateful that you have created this Sci-Hub website.

    Dr. Prashant Singh
    Mch Neurosurgery
    NIMHANS, Bangalore


    



    I am an assistant professor with masters in Thermal engineering and also a research scholar, perusing my research in Alternative fuels and IC Engines. I am so grateful to you for launching SCI hub. I belong to a financially lower genre and could not afford purchasing articles to continue my research. I struggle a lot even to pay my PhD fees. But you have really laid a platform which helped me a lot to again knowledge regarding recent research. Thank you so much for your contribution to the world.  

    R V S Madhuri
    Assistant Professor
    


    



    I am extremely grateful for your sci-hub project as it always helps me get hold of material I couldn't access.

    Rimpi
    Pursuing M.Phil. in Philosophy
    Department of Philosophy
University of Delhi
New Delhi, India


    



    I am a second-year PhD Physics student. Thank you so much for your help in downloading the research paper. I also understand your pain and problems during re-opening another website when one closes. Our institute does not have much access to journals. Your help is highly appreciated. I completely agree with your mission- "No barriers in the field of knowledge"
You may surprise that we use to give your name in "thank you" page of most group meeting and any thesis viva-voce.

💛great love from India💛

    CHOUDHURY ABINASH BHUYAN
    
    Surface and Nanoscience Division (NCSS/MSG)
Indira Gandhi Center for Atomic Research
Kalpakkam, Tamilnadu, India


    



    I am 'Alok Raj' research scholar in department of environmental Science at central university of Rajasthan (India). Your developed Sci-hub website is really boon for the research world, I am highly thankful to you for the development of Sci-hub website. I wish to you for achieve a great Success in every dimension of computer science.

    Alok Raj
    Ph.D Scholar
    Department of Environmental Science
School of Earth Sciences
Central University of Rajasthan


    



    My name is Nilanjana and I currently pursue my Ph.D in Education in India. Firstly, a heartfelt thank you for sci-hub. It has just been a brilliant idea and stands for the larger vision of humanity-knowledge is free and meant for sharing.

    Nilanjana Moitra
    
    


    



    Hi Alexandra
First of thank you for Sci-Hub, i strongly believe  every researcher is thankful to you. I cannot describe the usefulness of  Sci-Hub.....thousand of researchers  might have benefited , no doubt .....

    Dr. Kishor Kumar Keekan
    MedTrain (Marie-Curie) Fellow
    Centre for Research in Medical Devices (CÚRAM)
Room C206, Marine Biodiscovery Laboratory,
School of Chemistry, National University of Ireland, Galway (NUI Galway)
University Road, Galway H91TK33, Ireland


    



    Dear Alexandra,
thanks for the web. i would not have got access to so high priced journals during my research without your help in the form of this  web. i often think of you as my librarian . thanks dear . your contribution towards  researchers specially from humble background is immense. take care.

    Ranjeet Singh
    
    panjab university
chandigarh
India


    



    Happy to meet you through Sci-Hub. I want to thank you from the bottom of my heart for your creation and for changing the lives of so many in search of knowledge.
Forever grateful,

    S.M. Ramya
    Doctoral Candidate (Organizational Behavior)
    Department of Management Studies | Indian Institute of Technology, Madras


    



       I'm Bina from India, I'm pursuing my undergrad degree in engineering.
I just can't imagine a day without sci-hub. The amount of knowledge I gained by accessing papers and it helped me a lot in creating my projects and writing my papers. I just wanted to thank you for it, and I look up to you. You are indeed breaking the barrier in the way of science and I'm proud that a woman is playing such a major role. More power t you Alexandra.

    Bina R
    
    


    



    I am really thankful to you for providing a platform whereby we can download useful educational material which is helpful in conducting my research.

    Dr. Mohammad Akhtar
    Professor of Supply Chain Management
    New Delhi, India


    



    You are too much intelligent. You created a very helpful and supportive site for us. Worldwide people know your name and your site.
I am PhD scholar in Pharmacology stream. The research papers and books help me too much during my research. 

    Parag Jain
    
    Rungta College of Pharmaceutical Science and Research, Bhilai


    



    Thank you very much for providing us such a nice site. Being a researcher, It is very helpful for all of us, especially those who don't have financial support but still want to gain knowledge. Kindly accept a token of appreciation.

    Dr Rahul Saxena
    Associate Professor
    Biochemistry department
School of Allied Health Sciences
Sharda University


    



    I am Pritanjali Shende, from India. I am a research scholar at IIT Hyderabad, India. Right now, I am a visiting Scholar at Centre for Environment, Harvard University.  I am writing this email to thank you for providing us (most of the PhD scholars) Sci-hub. It has made our research much more flexible as most of the papers are readily available and that's all because of you and your hardship.

I am not good at coding or neural networking or artificial intelligence but I would really like to thank you for making my research so much smooth. Sci-hub is one of the best search engines I have ever seen. As mentioned by you: "Sci-hub is making research communication faster"

I would love it if you could give a small talk to the rising scholars and techies of Indian Institute of Technology (IIT) Hyderabad. You have been a great inspiration for most of us. And your valuable word's would inspire many more young generations.

    Pritanjali Pradeep Shende
    PhD Scholar, Civil Engineering
    Indian Institute of Technology (IIT) Hyderabad,
Kandi, Telangana -502285, India


    



    Greetings!
I am very glad to know about your mission of sharing knowledge without boundaries. I am one of the beneficiaries of the site developed by you. I have accessed many articles through "sci-hub" for expanding my knowledge in my speciallity. But never for commercial purposes.

Where the mind is without fear and the head held high;
Where knowledge is free;
Where the world has not been broken up into fragments by narrow domestic walls;
Where words come out from the depth of truth;
Where tireless striving stretches its arms towards perfection;
Where the clear stream of reason has not lost its way into the dreary desert sand of dead habit;
Where the mind is led forward by Thee into ever-widening thought and action;
Into that heaven of freedom, my Father, let my country awake.

Rabindranath Tagore (1861-1941)

    Dr. Rajashekar
    
    


    



    I am Prasoon Kumar, an Indian scientist and academician. Though this mail, I want to thank you for your excellent idea and contribution to open science and making numerous scientific literature at our disposal. I would also like to thank you on behalf of numerous researchers in India I too believe in open science and science for the benefit of society.

    Prasoon Kumar, PhD
    Assistant Professor
    Department of Medical Devices
National Institute of Pharmaceutical Education and Research - Ahmadabad
(Under Dept. of Pharmaceuticals, Ministry of Chemicals and Fertilizers, Govt. of India)
Palaj, Near Air force Station, Gandhinagar
Gujarat 382355


    



    We (Scientists) are thankful to you for a novel cause. We are getting lot of benefit by downloading paid papers for our research purpose because we are not in position to purchase the research paper. May god give you long life for this novel work. Hope you will continues to support the scientific community. I can understand you might be facing lot of problem from international publisher.
Nothing will happen wrong with you because you are working for the society.
May god bless you

    Dr. Neelesh Sharma
    
    Lab. of Animal Stem Cells
Division of Veterinary Medicine
Faculty of Veterinary Science and Animal Husbandry,
Sher-e-Kashmir University of Agricultural Sciences & Technology,
R.S. Pura, Jammu-181102 (J & K) INDIA


    



    Hi, good morning to you
This mail is regarding appreciation for creating such a useful platform, Sci-hub.

Thank You

    Rajath R Shankar
    Junior Research Fellow
    Department of Zoology,
Bangalore University,
Bengaluru-560056


    



    Thanks for such great website you build for research works. Really appreciate it, and grateful.
It saves a lot of time and money, especially for those who came from small and mid size college and universities with limited resources.

I am using it from last 2 years, for research work in  Machine Learning and Artificial Intelligence.
Do keep it up. Happy to help you.

    Prince Hridayalankar
    Reseacher
    


    



     I am Sanghmitra, from India, I just joined PhD in neurophysiology in, National Institute of Mental Health and neurosciences, India.
I really really appreciate your efforts on developing SCIHUB and making science available to all.

    Sanghmitra Rao
    
    


    



    I am extremely happy and I appreciate your efforts for Sci-hub activities. Because of your hard work, in Sci-hub  I am able to complete my Ph.D. recently. Please do not stop your work in sci-hub, because it's very very useful for low financial researchers/countries.

    Dr. R. Nagarajan
    
    Department of Chemistry,
Karunya Institute of Technology and Sciences


    



    I am really thankful to you for creating this website. It really helped me a lot.

    Amit Kashyap
    
    Delhi, India


    



    It is nice to write this mail to you as not only me but people who can not pay the subscription charges for international journals are thankful to you for opening the gates of science to them.
Your platform has supported plenty of people and given them an opportunity to enhance their knowledge further by getting access to all the literature available free of cost.  Thank you once again and please do let me know if I can do anything for you to support your endeavour.

    Sanjay Sharma
    Dean Academics & HOD ME
    Shivalik College of Engineering,
Dehradun-248197


    



    I write this to thank you for developing such a wonderful application for literature retrieval. It is actually a boon for the people who can not afford subscription of journals. I am totally dependent on sci-hub for literature downloading. I also promote sci-hub with number of students, teachers and researchers in India to use this application.

Thanks again
(Hey! You are a hacker, please don't hack my email. My intention is only to thank you) 

    Dr. Sanjeeva Nayaka
    
    


    



    I am a faculty at a Business School in India, T A Pai Management Institute (TAPMI). I am also pursuing my PhD part time from Manipal Academy of Higher Education (MAHE). I have been greatly benefited by your site, Sci-Hub and wish to put on record my gratitude and thanks for making research articles accessible.

As a faculty, I do have access to E-Resources subscribed in my Institute. If I am searching something, I first try to see if I can source the article using EBSCO, PROQUEST or SCIENCEDIRECT subscriptions available at my institute. But sometimes I am not able to find the article especially if it is from the engineering domain since I have been working on machine learning as part of my thesis. Hence as a last resort, I use your site and I always (99.99%) of the time always find it. Some publications such as SAGe or Elsevier have very limited availability on the E-resources that are subscribed at my institute.

I would be happy to make a small donation to support your project. However, I am bit reluctant to use illegal means to transfer money since Bitcoins are banned by the federal bank (RBI) in our country. Hence, is there a routine bank account where I can transfer money through Banking Fund Transfer or phone number (p2p) for International payments? Please let me know the same since I have been thinking of making a donation for couple of years but was always reluctant to use Bitcoins given its legal status in our country.

    Kedareshwaran Subramanian
    Assistant Professor – IT & Systems
    T A Pai Management Institute (TAPMI), Manipal, India


    



    This is Dr. Bharat Suthar from India. I want to thank you for your noble work of website Sci-Hub.
I really very much thank full to provide research articles free for students and others to contributed in research.
I have used your website number of times.
I wish your best of luck in your carrier and how your will continue in your life.

Please feel free to revert if you need any help in Pharmaceutical and chemical research field.

    Dr. Bharat Suthar
    
    


    



    I am a scientist from India and I use Sci-Hub frequently when I am browsing for articles from home (when I do not have institutional access). Even when I work at my lab/ office, I cannot use the institutional access since there are many other things to work on. My relaxed reading and writing happens at home and I am very grateful to Sci-Hub for providing me information when I need them.

I have read about you in the past and heard some of your interviews on YouTube. But recently I see that Sci-Hub has your picture waving at the reader. I think it is a really good idea and a good place to gather support. It is always good to build the human connection to every person who reads scholarly work through Sci-Hub.

I was also thinking about you starting a campaign for your excellent work. So that it gets international attention. It will also help ensure your safety and legitimacy. Some similar work in pharmaceuticals in India has been done in the past and there have been movies made about them. Perhaps you could also consider such work so that your cause receives international acclaim.

I use this opportunity to congratulate your spirit and support your endeavour against those who capitalise on science. This is not why scientists do science.

Best regards to you and with great appreciation for your work

    Jerin Jose
    
    


    



    I am 22 years old from India and pursuing a master's in physics. Being a student from a third world country I was not able to buy published articles for research work. Now, using sci-hub I can do it very easily and can download and read any article.

I just wanted to tell that I am your great fan  I appreciate your work and look up to you for inspiration. Thank you

    Pawan
    
    


    



    First of all a big thanks for making science barrier-free. I'm a PhD research scholar and lecturer as well. During my masters and now for PhD research,  Sci-Hub is all I want, in short, you are the saviour. Due to your vision and efforts, I'm enjoying the research papers within a week of publication. Even during this COVID pandemic situation, the reason I could enjoy research away from my lab is just Sci-Hub. Lots of respect and love from India. Want to gift you something please, say I will send it to you.

    Jignesh R. Vaghela
    Lecturer
    Mechanical Engineering Department,
Dr. Jivraj N Mehta Government Polytechnic
Near Railway Crossing, Lathi Rd,
Amreli, Gujarat 365601


    



    I am a student from India pursuing my Master's degree in Pharmacology. Given the lack of funding, buying or renting a research paper was never an option for me. It is the sci-hub website that made research possible for me without going bankrupt!
Sci-hub has played a valuable role in my education.
Thank you so much for your efforts!

    Varsha Satav
    
    


    



    Thanks for developing such a helpful search sites.

    Tara Bhusal
    Assistant Dean
    Faculty of Humanities and Social Sciences
Tribhuvan University
Kathmandu


    



    I am Shanu from India. I am writing you to express my sincere thanks for your wonderful gift to the researchers in the form of 'Sci-hub'.

    Shanu Shukla
    RESEARCH ASSOCIATE
    Indian Institute of Management Indore, INDIA
FULBRIGHT ALUMNA
University of Michigan, USA


    



    I was very nice to know your work on Sci-hub.tw. Thank you for making our life easy in understanding the world knowledge. Some day, I will like to invite you for a talk in program organised by us.

    Dr. Pravin S. Rana
    Assistant Professor - Tourism Management
    Faculty of Arts
Banaras Hindu University
Varanasi, UP, INDIA 221005


    



    you have done a wonderful job by creating SCI-HUB

I LOVE YOUR WORK

    Dr. Manzoor A. Rather
    Editor-in-Chief
    Advances in Biomedicine and Pharmacy (ABP)


    



    This is DR Sreekar (pulmonologist) from India.
You are doing an amazing job and I am a big fan of yours for creating scihub (removing barriers in the way of science)
If u need anything regarding medical field, u can jus ping me because we all doctors owe you and forever indebted

Thank you and take care from covid 19
Bye

    DR Sreekar
    
    


    



     This is kannabhiran. I am from India. I thank pirate queen. Once upon a time, getting research papers is tough. Now you made it very easy. Thanks for your tremendous work.

    Kannabhiran Arumugam
    
    


    



    Thanks a lot for sci hub

    Dr Krishnakumar Subramanian
    Fellowship in clinical Dermatology and Dermatopathology-under late Prof A S Thambiah
    Madras Medical College
Vision Research Foundation
Old No 18, New No 41, College Road, Nungambakkam
Chennai, Tamil Nadu, India


    



    I am a researcher from India. I just wanted to thank you for the great initiative you have taken. I can't describe how grateful each and every researcher is to your wonderful work as SCI-HUB. Thank you again for freeing students like us from the web of subscriptions that costs more than our own fellowships. Please let me know how I can contribute if possible from India.

    Ekta Bhattacharya
    Senior Research Fellow
    Indian Statistical Institute
Kolkata, West Bengal
India


    



    I'm really thankful to you for your great initiative about the Sci-Hub. Last year I've finished my master's in chemistry. It was the Sci-hub that helped me throughout my master's to access all the publications that I needed. Yes, it is truly said that knowledge is for everyone. First time I read about you on Facebook. Hat's off for your struggle to develop sci-hub.

Well, I'm going to the USA for pursuing my Ph.D in chemistry. Though the term is uncertain now due to restriction on international travel amid the pandemic.

Thank you again. You are a true inspiration for all the students who just cannot afford the cost to buy a single publication. You made our way easy.

    Arpan
    
    


    



    myself updesh verma a research scholar in sant longowal institute of engineering and technology, india. I am very thankful to you for so nice and very useful plateform sci-hub which you have developed.

    Updesh Verma
    
    


    



    I just want to say thank you very much. i have completed my doctorate in biochemistry. but i can say that with out SCI-HUB it was difficult to complete in time.

    Umar Muzaffer
    Research Associate
    Clinical Research Laboratory
Advanced Centre for Human Genetics
Sher-i-Kashmir Institute of Medical Sciences
Soura, Srinagar, Kashmir, Jammu and Kashmir 190011


    



    Actually this is too late to express my heartfelt thanks to you because you made the research process easy for all researchers like me. You developed Sci-Hub such a wonderfull gateway without any barriers to search any research article.  You are really very great, broad minded, a good researcher and very beautyfull personality.  I came to know that  you are facing legal court matters due to open and free access made available for all through Sci-Hub website. Hope you have defended best at your level by putting truth behind this.

    Dr. Suryakant B. Sapkal
    Assistant Professor
    SPOC NPTEL Local Chapter,
MGM's Jawaharlal Nehru Engineering College,
Aurangabad (MS)-431003


    



    It’s very good job you are doing for people from developing countries.
You are worth 10 Nobel prizes

I want to spread your effort to every one in developing world.

    Manvendra Singh
    
    


    



    thanx alexandra for creating sci-hub..sci hub isquite helpful for research students like us specially in a developing country like India. Thanx once again and wish you good luck in your endeavors.

    Hemant Pednekar
    
    


    



    Hi Alexandra,

It’s great to know the person behind the innovation that is letting others to step ahead in their fields of research. Honestly, it’s a great thing to be writing to you.

Once again thanks a lot for making all of our lives million times easy.

    Anudipta Chaudhuri
    
    Mechanical Engineering
India


    



    I'm a Ph.D. scholar of climate science. I used sci-hub for the last 3 years. I want to say a big thank you for your adorable work for the research world.

    Anshuman Gunawat
    Ph.D. Research Scholar
    School of Earth Science
Central University of Rajasthan
Kishangarh, Ajmer, Rajasthan
INDIA - 305 817


    



    I am a researcher in Botany from India. Related to my studies I have to access several publications, the majority are on payment. I am from a lower middle class family and I cannot afford the huge fee for each paper. There you emerged as an angel through your sci-hub. Knowledge should be open and accessible to all. You are doing a great job in this venture. Thanking you once again on behalf of all the researchers from poor countries..
😍😘😍😍😍

    Dr. Anoop P. Balan Ph.D
    
    


    



    You have my utmost respect for this platform. Please be safe. I hope you are doing well in this COVID scare. I can't express, as a research community how thankful we are. Keep inspiring us.

    Sumanta Chowdhury
    Research Scholar
    School of Basic Sciences
IIT Mandi


    



    I am a doctoral candidate who has enrolled in a public university in India. My institute doesn't subscribe to lot of journals and in India, it is seen that state expenditure on the public education is decreasing. In this neo-liberal times, your work actually helps in fighting the inequalities in society. Now, I cannot imagine my work without a science hub. Thank you for all the work.

Another communist here.

    Tekumal Santhosh
    
    


    



    Me and many of the science guys in India and the world do praise from the bottom of their heart for the Sci-hub initiative from your end. BE believe in your ideas and thoughts.. You have done remarkable work at a very young age bridging the gap between development and transfer of knowledge.I had been using this to look into people;s works, and many like me cannot afford to pay huge subscription fees to journals and press for something meant to be in public domains.

hats off to your deeds... God be with you. Hope you are all safe in these times.
Love again from India.

    Gaurav Mudgal
    
    


    



    I am really happy to see you and your profile on Sci-hub. You made my work simpler and easier because whenever I have a problem in accessing or downloading research articles, imminently I use to surf  on Sci-hub and recommend it to my friends circle. Because of your website so many researches are benefitted in India, especially those who don't have the journal subscription or standard journals.

Keep going
Thanks a lot for your help

    Dr. L. Saranraj Ph.D
    
    Tamil Nadu, India


    



    Thank you for making the website. All the best to you
Thanking You

    Dr. Sachin M. Patil
    National Postdoctoral Fellow
    Department of Botany,
Faculty of Science,
The M. S. University, Baroda,
Vadodara - 390002


    



    You are one among those who i believe have paved a new way to future of pursuit of knowledge. Your challenge to pay wall and creating a channel has helped millions if not billions around the world who were paralyzed by the thickness and height of the pay wall by publication mafia. You have single handily started a revolution of freeing science from the fee and made govts around the world to questions or at least think about it. You have literally rocked the world. I sincerely thank you for your initiative from which even i have benefited personally during my PhD.

    Dr. M. Sameer Reddy
    
    


    



    I'm a research scholar from India. During  this lockdown due to COVID rire Sci-Hub helped me a lot to find literature and write my thesis. I am writing this mail to thank you for developing such a wonderful website, keep this spirit up and hope to see many more from you.
Thanks and Regards

    Abdul Motaleb
    Research Fellow (Ph.D Student)
    Organic Chemistry Division
CSIR-National Chemical Laboratory
Dr. Homi Bhabha Road, Pune, 411008


    



    Thank you for  your continuous effort and support in providing access to journal papers
Hats off

Reading maketh a full man; conference a ready man; and writing an exact man: Francis Bacon

    ANURAJ ANIRUDHAN
    
    India


    



    I am Pranab Boral, age 25, from India. Currently I am doing research work on Petroleum Technology. I have been using SCI-HUB for the last 3 years and always wondered how all the research papers are available and accessible so easily

    Pranab Boral 
    
    


    



    I am a student from India usually, search for articles and access it by sci; hub. You are really doing a great job. Thank you for making science articles easy accessible and free

    Archana Samal
    Research Scholar
Junior research fellow (PhD)

    Institute of Life Sciences, Bhubaneswar
M.Sc in life sciences
Central university of Punjab
Bathinda


    



    Thank you ma'am for letting us access papers. I am highly obliged.

    Anirban Biswas
    JRF (Ph.D.)
    IIT ISM Dhanbad


    



    I am a researcher from India. I just want to thank you, and I mean a lot lot lot of thanks, for giving Sci-Hub.
Keep up your good work and take care.

    Abhishek Majhi
    
    Inspire Faculty,
Physics and Applied Mathematics Unit,
Indian Statistical Institute, Kolkata, India.


    



    I wanted to thank you for providing such a great platform ie SCI-HUB for research aspirants.

    Jatoth sai kiran
    
    


    



    god bless you for creating scihub
you are robinhood

    Pranav . A. Nerurkar
    Student
    Dept of Computer Engineering
Veermata Jijabai Technological Institute
Matunga, Mumbai, Maharashtra.


    



    Many thanks for taking so much of pain and contributing to the capacity of everyone. You made a great statement. Proud of you.

    Ramesh Agarwal
    Professor
    Division of Neonatology
Department of Pediatrics
Newborn Health Knowledge Center (NHKC)
New Private Ward-1st Floor
All India Institute of Medical Sciences, Ansari Nagar
New Delhi, India - 110 029


    



    I am doing engineering from IP University in India. I just wanted to write an email to thank you for writing such a wonderful website :Scihub. I am doing engineering in Information Technology and want to pursue my career in the field of cybersecurity.
While doing my college final year project your website proved to be very helpful because purchasing research papers is very expensive. I would like to express deep gratitude towards your goal of making information and knowledge available to everyone.

    Ansh Kapoor
    
    


    



    Myself Saddam Iraqui. I am a Research Scholar of Chemistry. I am writing this email to you because I want to thank that person who developed such a great search engine to help researchers like me.
This search engine key point of researchers like me, who belong to a very backward place and our institution do not have access to important journals. At Last thank you so much ma'am and nice to meet you.

    Saddam Iraqui
    Research Scholar
    Department of chemistry
Rajiv Gandhiuniversity
arunachal Pradesh-791112
India


    



    I'm Roshni John pursuing my PhD in Soil Science and Agricultural Chemistry from India. I just wanted to thank you for developing Sci-Hub which unlocked the world of research papers for us. This mail is supposed to send you because I was so fascinated by seeing you waving on opening Sci- hub.

    Roshni John
    
    


    



    I salute for your innovative web developing and helped lakhs of students and researchers.

    Kiran S.C
    Ph.D Scholar
    Dept., Forestry & Environmental Science
UAS, GKVK
Bengaluru 560065


    



    My name is Anurag Nath and i am a Research Scholar from India. I am really interested by the work you have done and it not only helps people coming from developing countries to indulge in research. It has been really helpful. i would like to take this opportunity to personally thank you for this.

    Anurag Nath
    
    


    



    This is Priya, research scholar, Thiruvalluvar university, vellore, Tamilnadu, India. You are doing a great service. Through Sci-hub many researchers download articles without any trouble. All the best for your every activity towards the research community.

    S. Priya
    Research scholar
    Arignar Anna Government Arts College, Villupuram
Tamil Nadu
India


    



    I am a postgraduate in psychiatry from India. I would like to thank you for your website without which the information for my dissertation would have been incomplete and difficult. I saw your message on the sci-hub.se regarding interest for neuro research and religion and culture. Hence wanted to show appreciation for your work and thought. Thank you once again for giving us sci hub a platform for true knowledge and the genuinity in gaining knowledge for the aspirants who come from a poor background.
Thanks a lot.👍👍

    Vinay Kumar.p
    
    


    



    My name is Sangaiya Ponnaiya, I'm a Physics lecturer in a private engineering college. I am from Tamil Nadu, South India and I'm 35 years old. I'm a native speaker of Tamil (Oldest language). Before I knowing you when I was Ph.D. scholar I and my colleagues used Sci-hub as our god. because we are studied in government colleges there is no journal access password or any free access link. it's true without Sci-Hub.  I can not imagine my Ph.D. degree. I struggled in my earlier Ph.D. to collect research journals until my friend suggests your sci-hub. Your job is priceless and there is no word to convey my thanks to you. You are an angel to every Ph.D. scholars without your website can not complete our Ph.D.  The great Alexander conquers the world but you conquered the entire scholar's heart.

    Sangaiya P.
    
    Tiruppur, Tamilnadu, India-641020


    



    I am Debishree, a scientist at National Environmental Engineering Research Institute, India. I really want to thank you for making my life easier by providing this access to sci-hub where I find most of the articles related to my research work. I appreciate the kind of work you are doing and wishes you good luck in all your endeavors.

Best wishes!

    Dr. Debishree Khan
    Scientist
    CSIR-NEERI, Nagpur


    



    I REALLY APPRECIATE YOUR WORK,BECAUSE OF ONLY  YOU AND YOUR EFFORT,  I CAN READ ALL RESEARCH PAPERS RELATED TO MY SUBJECT,WHICH I CANT AFFORD BY PAYING  COST.
YOU ARE A TRUE INSPIRATION AND GOD BLESS YOU ALWAYS
MY BEST WISHES ARE ALWAYS WITH YOU
YOUR WORK REALLY SUPPORTS ALL RESEARCHERS.
THANK YOU THANK YOU THANK YOU
LOVE AND RESPECT FROM INDIA

Thanks & Regards.

    Ms.Prachi A.Dixit
    Assistant Prof
    Department of Mechanical Engineering
Bharati Vidyapeeth University College of Engineering,
Pune, (India) 411 043.


    



    You open a door for us...Thank you so much, have a merry day ahead

    Mr. Yadnyesh Y. Karkare
    Research Scholar
    Department of Chemical Engineering
Dr.Babasaheb Ambedkar Technological University, Lonere
Mangaon, Raigad, Maharashtra, 402103, INDIA


    



    I am a researcher from India and been using your work for accessing and studying scientific literature since I got into research. I only wanted to tell you that I am a big fan of your work and admired reading about you and your ideology. You have done a great service to scientific community.
Thank you.

    Vijay Kumar
    
    


    



    It feels so nice to have guys like you in science community. I read about you today while downloading a paper. I am doing my internship and realize how hard it would be for me if people like you would not have made amazing things like sci-hub.

This mail is a shoutout to your long ago efforts and a tribute to your coding mind! I love you bro! Will always be grateful to you for making a free open-access portal for science students!

Could not stop thanking you! I promise to donate something once I become independent and have a job. Right now, I am just a bachelor's student from India.

Take Care!

May almighty fulfills whatever you aspire in life!

    Shriya Mehta
    
    


    



    HI, alexandra  you did  good work , which is helpful for students,  especially the student who can not pay for paper. I am phd candidate. i am about to submit my thesis. your website helped me a lot.

Thanking you

    Raj Kumar
    
    


    



    I am Tarun from India. I have been following you and your website since my college days. And I cannot express the gratitude I have for your website because it has helped my college work in a lot of ways. Thank you.

I am an avid supporter of open access to all information. I understand and believe  your view that information is not an asset of the person who created it. I think of scientific information in the same way as our feelings in the mind. I believe that feelings like love and friendship do not belong to a section of our brain (nor our body) though their origin corresponds to a part of the brain. Similarly, scientific information has to be open and unrestricted to all. Just imagine how it would be if the human who created the fire hid it instead of provided light to all others. The past advancements in the scientific fields have been possible only through open collaboration between researchers. You are the person who has made the idea of open information take shape. You are a rebel and a hero. Thank you. Thank you for being such an inspiration.

    Tarun Sekhar Buddha
    
    


    



    I am Heera Jayan, a Ph.D. student in food science and engineering.  I came across with sci-hub when I was working on my thesis for masters in India. I would like to thank you on behalf of every student for making sci-hub happen. This movement is especially helpful for those who are doing higher education in colleges that are unable to provide institutional access to first quartile journals. I have always wanted to know the person behind this website. Wish you a happy and successful life ahead.

Thank you 

    Heera Jayan
    
    


    



    My name is Tapas Ray and I live in Kolkata (India).

Although I have used your web service several times, this is the first time that I saw your bio page.

First, heartfelt gratitude for the free service you have been providing. It is a lifeline for people like me, who live in the poorer parts of the world and do not have institutional access to journal databases. As I do not want to use your service without giving anything back, I wanted to make a modest contribution a year or two ago but could not, as the only way was through bitcoins, which completely befuddle me. I have tried to read up and even installed software, but it's simply beyond me.

Once again, it was great knowing that such a young person (my daughter's age, almost) is doing such a wonderful thing for people like me who are on the margins of academia in the countries of the global "periphery". Thank you and the very best wishes

    Tapas Ray
    
    Kolkata, India


    



    I'm a student from India. Just wanted to say thank you. Hope to make your day a bit brighter :)

    Muhammed Farseeen CK
    
    


    



    I am Sai Pavithra from India. I am doing my research in Biotechnology. I am extremely happy that at this young age you have created a very useful website which is very useful for researchers like me in browsing the research articles.

Thanking you

    K. Sai Pavithra
    
    


    



    I'm Aditya, an undergraduate from India and a fan of yours. My institute gives access to many commercial research paper websites, but due to the COVID-19 pandemic, we'll are staying at our respective homes. Since then, I was having a hard time accessing the research papers behind the paywalls, and one day a friend of mine called, and he told me about sci-hub. It helped me a lot, and I'm thankful to you for such great work.

    Aditya Dev
    
    


    



    A very big thank you, what you have done for us like young researchers to crack paid journals and articles ... THANK YOU ...hope you will always support the science research community like this way ...the fraternity is always feeling proud for you ... THANK YOU

From,
A user from INDIA, Since 2017

    Debanjan Chatterjee
    Ph.D. Research Scholar (Department of Natural Products)
    National Institute of Pharmaceutical Education and Research
S.A.S Nagar (Mohali)


    



    I am karuna...working as Associate professor in vignans Institute of information technology,visakhapatnam,A.P,India..... doing research on biomedical signal processing....this website is very useful to me in the area of collecting lot of information related to my research work. mean while my husband and my self  running church...my husband is full time paster as well as running part time bible college...... Thank you....

    Karuna
    
    


    



    Thank you so much for your Sci-Hub website. I am grateful to you for your website through which I can download necessary articles.

May God bless you.

    Md. SHIBLUR Rahaman
    Doctoral Student (D3)
    Graduate School of Environmental Science
Faculty of Environmental Earth Science
Hokkaido University, Sapporo,  Japan.


    



    Thanks for scihub..It's very useful for poor students like us.

    DR. THOMAS GREGOR ISSAC
    SENIOR RESIDENT, D.M (GERIATRIC PSYCHIATRY- 1st Year)
    CLINICAL NEUROSCIENCES (ICMR MD-Ph.D FELLOWSHIP), M.D(PSYCHIATRY)
NIMHANS
BENGALURU-29
INDIA


    



    I am just amazed after seeing your bio data. young students indirectly worship you for providing such a website which is use full for getting research publications.

    ADHIKARI SAI RANGA SRIKANTH
    M.TECH- ENVIRONMENTAL ENGINEERING AND MANAGEMENT
    JAHWARLAL NEHRU TECHNOLOGICAL UNIVERSITY (KAKINADA),
ANDHRAPRADESH,
INDIA


    



    My name is Kamal and I live in Vadodara, India. I am a young chemical engineer with high interest in researching synthesis procedures for various Pharmaceutical and other Organic chemical compounds.

 My love is full of respect for you Alexandra. Because by giving this beautiful gift “Sci-Hub” to millions of students and researchers like me, you deserve tons and tons of respect, love and care from all of us! You can not imagine how your hard-work is helping the whole world to become a better place in number of ways!!

Thanks a million

    Kamal Morendha
    
    Vadodara, Gujarat state, India


    



    I am Prasannakumar working as a research scholar in CSIR - Central Electrochemical Research Institute, Karaikudi from India.
Now only I seen the information about you madam, your profile was extraordinary.
One of your invention, "SCIHUB" is very much useful to me.
As a researcher, I know the importance of this website for getting research articles.
I thank you very much madam, for inventing this software.
As a researcher, I humbly say thank you very much.

    R S Prasannakumar
    
    


    



    I am writing this mail to thank you for the sci-hub which you have developed. I should say sci-hub is really making our life easy in accessing articles and it is awesome. So, I just thought of thanking you for this. Keep up the good work.

    P. SARAVAN KUMAR
    PhD scholar
    ICAR-Indian Institute of horticulture research
Hessaragatta,Bangalore
Karnataka-560089


    



    I congratulate you for making such a wonderful website to access papers. Lot of researchers including me refer to your site to download some papers from your web site.

I felt to share my gratitude to you in this regard.

    Amar Kumar Das
    Asst. Professor
    Dept. of Mechanical Engineering


    



    words can't express my gratitude and respect, that I have for you. you have done an amazing work by creating this site. usually, peoples have their love for heroes and heroine but as a science student, I am your fan and appreciate your efforts to take the science to next level.

    Naresh Tanwer
    Research scholar
    M.D.University, Rohtak, Haryana, India


    



    Please accept my heartfelt gratitude for creating your website which is of immense help to me and to all academia. Knowledge should be free and not restricted. I fully support your cause. keep up the good work.

    Dr. Preeti Thakur
    Assistant Professor
    Department of Microbiology
Maulana Azad Medical College
New Delhi


    



    with due respect i want to convey you that only because of your esteemed website we the science aspirants can freely search the most valuable research works and can learn from them. i am a current m.Pharm scholar from India and i have recognized you in my thesis work.

    Mr. AVIJIT KUMAR BAKSHI
    M. PHARM SCHOLAR
    DEPARTMENT OF PHARMACEUTICAL SCIENCES,
(A CENTRAL UNIVERSITY), SAGAR(M.P.), 470003


    



    I am Aastha, a PhD scholar from India. I would like to say thank you for making this Sci Hub. It is really very helpful not only for me but also it is helping people across the world like me.

Thanks a million again for creating it.

    Aastha Tripathi
    
    


    



    Please allow me to express my profound gratitude for enabling me and several people around the world to access scientific literature. It is a fact that not all institutes/organizations subscribe to all the journals. Your creation has made research better. I thank you once again. I wish you a happy life and a glorious career ahead.

    Dr. Mithipati Siva Bhaskar
    Assistant Professor
    School of Minerals, Metallurgical and Materials Engineering
IIT Bhubaneswar


    



    Just a mail to say you a million thanks for such amazing work. it's a great help for all researchers
Thanks a lot

    Padmini Rajput
    Ph.D. Scholar
    University of Jammu


    



    This is Meheli Ghosh from INDIA. I am a M.Sc. Nanotechnology student. I am writing this mail to you just to let you know how grateful I am to you for designing sci-hub, I am totally dependent on it for my thesis work.
Some day I would like to contribute to your work.

    Meheli Ghosh
    
    


    



    I wanted to write to you to thank you for providing the tremendous service to the academic community through Sci Hub.
Your contribution to the freedom of academics worldwide is immeasurable.
This is an expression of gratitude from a fellow academic from India.

    Devlina Chatterjee
    Associate Professor
    Industrial and Management Engineering
Indian Institute of Technology, Kanpur
Kanpur, India 208016


    



    Thanks a lot for your service through SCI-HUB. We, peoples, download lot of valuable articles through your web page
Thanks and Regards

    Dr. T. Citarasu
    Associate Professor
    Centre for Marine Science and Technology
Manonmaniam Sundaranar University
Rajakkamangalam
Kanyakumari Dist
Tamilnadu
India 629502


    



    Thank you for the Sci-Hub platform. It is a boon to science workers. It is amazing that you created such a wonderful platform at a such a young age.
I am Dr Sridhar, Neurologist and Scientist from India.

    Dr Sridhar MD DM Neurology
    Research Scientist
    Institute of Bioinformatics
7th floor, Discoverer building
International Tech Park
Bangalore 560030
India


    



    This is Kaisar Ahmad Allie from Kashmir occupied India. I am pursuing Ph. D in Nematology (free living nematodes). We have  limited literature in this field and it is because of your web site we are able to download the research papers of our interest. My opinion is that there should be more web sites like this one. i fully support you and your efforts.

May the creator shine your career and bestow everlasting happiness on you.

........LOVE FROM KASHMIR...........

    Kaisar Ahmad Allie
    
    


    



    myself tarun pant research scholar from india, I frequently use your Sci-Hub to unlock and download many paid reseaerch papers. I am credible to you for providing such platform to enable a range of rare research

    Tarun Pant
    
    


    



    Stumbled upon your website, sci-hub, today. Downloaded a research paper for free, so thank you. Thank you for building this and making science accessible.

    Rajesh Mukherjee
    
    


    



    I am Amandeep, Research Scholar from India. It's a wonderful work that you have done to help the research community to find all types of articles for free using your website. On behalf of all the researchers, I appreciate your work and thanks to you for this work.

    Amandeep
    Research Scholar
    MUSE Lab
Department of Mechanical Engineering
Indian Institute of Technology Ropar
Roopnagar, Punjab
India 140001


    



    I am Dr. Mukul Dave from India. I am M.Sc., Ph.D., I did my research in organic chemistry on synthesis of various drugs. We checked its potency for anti tubercular, anti bacterial and Local anesthetic drugs. I always refer research articles on Sci-Hub and I find what ever I want. I am presently interested natural herbs useful for the eye medicine preparation. I have developed Herbal formulation in the form of film coated tablets under nutraceutical head. your articles on sci-hub is very useful to me.

    Dr. Mukul P. Dave
    
    


    



    My name is Pranav Mhaisalkar. I am a biology researcher from India. I want to take this moment to express my sincere gratitude for the work you have been doing. Thank you so much for providing us with so many scientific articles. It wouldn't have been possible for me to gain knowledge without Sci-hub. Certainly, you are an inspiration for us.

PS: I love symbolization of Raven with a key. Its an amazing concept.

    Pranav Mhaisalkar
    
    


    



    I am udayan from India. I am a research scholar and frequent user of Scihub website. we are in debt for your work in creating scihub website. Thanking you

    Udayan Elangovan
    
    


    



    For my master's program I need to keep reading research papers and couldn't access them thanks to paywall. My classmates told me about your website and now, obviously, I can access them. So thank you for your brilliant website. I went through your profile and it is very interesting. Your passion for learning is quite inspiring as well.

I wrote this mail to thank you for the website. It is amazing,
THANK YOU ONCE AGAIN!!

    Deepika Parthasarathy
    
    


    



    Alexandra, its great pleasure to see your work. I am really impressed by your contribution to knowledge without barriers.

More grease to your elbow

    Yusuf Umar Tarauni
    
    Department of Physics & Nanotechnology
SRM Institute of Science & Technology
Kattankulathur, Chennai,
Tamil Nadu, India


    



    I hope you are doing  well, your website is very famous among students, Research community in India. you have done excellent work

Thanks

    Vishal Choudhary
    
    


    



    Thank you Alexandra for the fantastic work you do in keeping Scihub alive. I am morally conflicted in using the services but I have other option as access to these papers is prohibitively expensive for small not-for-profit entities like my own organisation.

    Karthik Ganesan
    Research Fellow
    Council on Energy, Environment and Water (CEEW)
Sanskrit Bhawan, A-10, Qutab Institutional Area
Aruna Asaf Ali Marg, New Delhi - 110067, India


    



    I would like to thank you.I am doing PhD and had it not been for you, conducting research, searching for articles and references would have been very difficult. It has made things easier.I think your efforts to make information accessible to all should be recognized and lauded.

I just hope that somehow, someday you are able to you gain the respect your efforts deserve. On my part, I am grateful to you and love you for being there!

    Vishal Kulshrestha
    
    


    



    Greetings from Mangalore, India. I am working as a PhD Scholar and recently submitted my thesis. As I await my Defense viva, I want to do this long pending Job; Thanking one of the biggest reasons why I am able to finish my thesis, and that reason is your legendary work, SCIHUB. Thank you Ms. Elbakyan for your venture aimed at making knowledge available to all.

On a personal note, this invaluable initiative of yours couldn't have come at a better time as I was doing my masters in biotechnology from 2013-2015. Since then, I have embraced SCIHUB whenever I needed any research article. On countless occasions, you have come to my and many other research researchers' rescue to extract the research paper which was made unaccessed by the journals for the want of money.

As I try to progress from my PhD research to post doc careers, I want to thank you and wish you great success in years to come.

I also hope and wish that some day with whatever skills and capabilities I'd have, be able to contribute to causes that you have been focusing on.
Thanking you again

    Jagadish K
    Research Scholar
    Yenepoya Research Centre
Yenepoya University.
Deralakatte, Mangalore.
575018, Karnataka, INDIA


    



    I love the work and Sci-hub. I' stand with you on the whole process of making education available to everyone. I'm A student based in India, currently in my masters in biotechnology and thinking of moving towards data science in future.

I say all this to say, if you need any help to expand your work in India, please let me know. I'll be happy to help you. Once again, Thank you for the good work!

    Saurav Roy
    Student in M.tech, Biotechnology
    Kalinga Institute Of Industrial Technology (KIIT)
Deemed to be University; Patia; Bhubaneswar; Odisha


    



    I am a psychology student from India and I wanted to thank you for making sci-hub. It has actually made me more aware as I am able to read complete researches.

    Priyal Khurana
    
    


    



    I am Using your Sci hub portal for literature ...it is very useful.. Thanks

    Dr. Dinesh Panchasara
    
    Valeshvar Biotech Pvt Ltd.
Gujarat, India


    



    I'm writing to thank you from the bottom of my heart. I'm currently a freelance industrial designer, with 3 years of experience and soon to establish my own design studio. I design everything from cool furniture to wearable electronic devices. I'm currently designing a smartwatch for a company; I've been looking at some research papers on material engineering topics for ECG and health care, and those are too expensive to purchase. But your website helped me get it for free.

I immediately clicked the donate button but unfortunately Bitcoin is banned in India and I don't know how to purchase Bitcoin to be honest. So, to compensate, please let me offer my design services to you for free. ...  You are what humanity needs :) Huge respect, much love.

    Uchit Mehta
    
    


    



    I am thankful for the work you are doing and have been doing from your 12th. I am just fascinated by the work you do following the principle "freely you receive, freely you give". God bless you.

    C. Theophilus Dhyankumar
    Research Associate
    LIBA, Chennai


    



    Thank you. Thank you for providing us Sci-hub. This is of immense help to academicians like you. I am a teacher, University Professor. It is not possible for me to pay for each and every article. Moreover I do lots of editorial activities for free. Only because of you we are gaining access to whatever we need for our academic purposes. All the best wishes.

    Dwaipayan Bharadwaj
    Professor
    Systems Genomics Laboratory
School of Biotechnology
Jawaharlal Nehru University
New Delhi 110 067, INDIA


    



    I am a master's student in Mathematics from India and I wanted to write to you to express my gratitude for your creation - Sci-hub. I've been using Sci-hub since the last 3-4 years (or even earlier) and whenever I wasn't a part of an institution, it was impossible for me to access material through official repositories ( I never have enough money XD).

So I wanted to explicitly write to you my sincere thanks for your work.

    Gaurav Hegde
    
    


    



    My name is Muhammed Aflah. I am a final year engineering student from India specialising in Food process engineering. I am writing this email to thank you from the bottom of my heart for creating the website sci-hub. It has been a life saviour to me and a lot of people I know. Keep coming up with such amazing ideas and make this world a better place.

Wishing you all the best and success.

    Muhammed Aflah
    
    


    



    I thank you from the core of my heart for developing Sci-hub. I love you so much for this.
If you happen to come Kashmir, India Plz let me know, I will be glad to host you.

Thanks and regards

    Dr Sheeraz Tantray
    Assistant Professor
    Higher Education Department
Jammu and Kashmir Govt


    



    When i am downloading the paper for SCIHub, I am watching your "Hi" by hand. I am also Hi you. Its symbol of love and peace.

    Mr Sushanta Kumar Barik
    Research Fellow
    National JALMA Institute for Leprosy and Other Mycobacterial Diseases,
Indian Council of Medical Research
Tajganj, Agra
Uttar-Pradesh-282004


    



    Just wanted to thank you for SciHub. It has really helped me in my research work throughout. Many like me around the world have benefitted from the software.

Thanks and best regards

    Ankur Sinha
    
    


    



    I would like to say thank you to the SCI-HUB.
Thanks
With Profound Regard

    Dr. Sanjeev Kr. Prasad
    Associate Professor
Program Chair-MCA, MSc & BSc.
    School of Computing Science of Engineering
Galgotias University, Greater Noida, UP, India


    



    I have been doing research since my graduation days. This Sci-hub helped me alot. Thanks for helping us.

Today is the day of SHAILPUTRI DEVI in INDIA. This day is celebrated as a "day of mother" in my home. This "day of mother" is to remind us that each and every female, outside or inside our home must be respected as we respect our mother. And today I saw your gif with waving hands. That gif gave me a feeling that you are with us forever like my mother.

    Utsav Sharma
    Research Scholar
    Department of Electrical Engineering
Indian Institute of Technology, Delhi
New Delhi-110016


    



    Your help to scientific community is immense, scientific community is highly indebted to you
I want to assist you by some means
I am from india

    Dr. D.Manikandavelu
    
    Ponneri - 601 204
chennai
Tamiolnadu
India


    



    I am amazed to see your contributions to the society through sci.hub portal, providing access to the scientific literature and knowledge.

    Dr. Ch. Aswani Kumar, PhD
    Professor
    School of Information Technology & Engineering,
Vellore Institute of Technology, Vellore - 632014.
India


    



    I am using the website: Sci-hub  that is very supportive to me.
I always remember to thank you for good knowledge sharing website.

    Divyesh Nagar
    
    Dr Nagar's Laboratories
Sr No. 1031, Plot No. 5/D, Gandhi Oil Mill Compound, Opp. Dutt Packaging,
Near BIDC, Gorwa, Vadodara 390 016 Gujarat (India)


    



    At first I would like to tell you that I am a research scholar from India. I want to say thanks to you for providing us a sci-hub platform to access research paper easier. I also want to say thanks for your further upgradation of this platform.
Thank you so much.

    Shivam Dwivedi
    Research Scholar
    Galgotias University, Greater Noida
U.P.
India


    



    I am from India. I am very thankful to you for creating sci hub site. We have very much benefitted from your work.

    Shaukat Ali
    
    


    



    Sci-hub is very helpful and resourceful to all research scholars.

    Avnika Singh
    
    


    



    I am studying in India, and unfortunately, my University does not have the funds to subscribe to the majority of the publications. I usually rely on public libraries, but they are also insufficient sources of research material.

I came across Sci-Hub, and it has been my saviour! I want to convey my heartfelt gratitude for the website and to let you know that you are an inspiration to women all over the world. Myriad students in India are able to pursue their education only because of Sci-Hub.

A Million Thanks

    Reshma Menon
    
    


    



    Our generation is grateful to have someone like you.
I really don't know how to thank you enough for creating Sci-Hub.
Please keep up the good work!
I support your goal in making knowledge free for everyone.

Best wishes

    Shirish Bose
    2 year M.Sc.
    Exploration Geophysics.
IIT Kharagpur


    



    myself  Dr Teena agrawal, you did a superb job by developing the sci hub
really, so much thankful, superb

    DR TEENA AGRAWAL
    Professor
    


    



    I am writing this email as a vote of thanks.
Thank you for developing the Sci-Hub library/ website. It is a life saver for scholars especially if I talk about India. You are just great.
Thank You once again.

Regards!

    Mohamad Sultan Khan
    Ph.D. Scholar
    Neurobiology and Molecular Chronobiology Laboratory
School of Life Sciences, Department of Animal Biology
University of Hyderabad, Gachibowli, Hyderabad, India


    



    I hope this email finds you in good health and taking care of this Pandemic. i would like to thank you for making sci hub.
thankyou

    Dr. Siddharth Boudh
    
    Department of Environmental Microbiology
School of Environmental science
Babasaheb Bhimrao Ambedkar (Central) University,
Lucknow - 226025, Uttar Pradesh, India.


    



    Thank You..
This really helps my study
I hope.. always God bless you

    Shinta Andayani
    
    


    



    I am very thankful to you for creating Sci-Hub.
Sci-Hub really helped a lot in this pandemic.

    Ketan Bapat
    
    


    



    This ranjani from India. A very big thanks for you on creating this sci hub website. it is a life saver for scholars like me world wide. really a heartfelt thanks again for ur effort on this website and the struggle on saving this website.

    Jana Ranjani
    
    


    



    Thank you very much for all your selfless work bringing science to seekers; you are my Goddess Saraswati!  But for your Sci-Hub, I wouldn't have been able to do my research.

    Venkata Rayudu Posina
    
    


    



    I am Aboothahir afzal.I am a researcher from India. I am a regular user of your website sci hub. Thanks for your contribution to science.

    Aboothahir Afzal
    
    


    



    Thank you for creating such an amazing service, without sci-hub I could not imagine how difficult would it be to research on neuroscience and machine learning.

    Shubh Pachchigar
    
    Nirma University


    



    Hello, I salute you for your great job of helping researcher to access any available paper of any journal. It help many like me. Thank you. Love you.

    Samarendra Pratap Singh
    Asst. Professor, EE Department
    I.E.T. Ayodhya, Dr. Rammanohar Lohia Avadh University, Ayodhya. India


    



    I am writing this email to show my kindest appreciation for your hard work that you did for all of us. I am a postgraduate chemistry student and I open the website like hundred times a week.
Once your website was not opening and I needed a journal, I was in an anxiety attack. But thankfully the website is back up and running. The smile and simple grey tee show your simplicity and I really feel proud of you.
Hope you are doing well !!

Your fellow daily user !

    Shraddha Verma
    
    from India


    



    I'm not sure if you are even aware of the continued and exponential impact you have had on science. Especially on those who participate in science from Lower and Middle Income Countries. I write this from India and Sci-hub has been of great use to me, even as a medical practitioner. For an academic, your work is more like God-sent boon.

Your breaking down of the pay-wall, to me is more significant than the breaking down of the Berlin wall.

Can't thank you enough for it!!!

Stay well, stay healthy, stay blessed.

    John Pinto
    
    


    



    We are a small start up in India. We are grateful to you for the wonderful work that you have done. We have meager resources but would still like to help you. We would like to contribute $ 1008 to your project. I know it is not much but we hope to contribute more as we grow. Please do let us know how we can do this.

    Air Marshal Shirish Deo
    
    


    



    First of all, thank you very much for your kind help to research scholer like me who can't afford a highly paid general. It has been in the news that this website is supposed to be close after 7th January so let me know that after closing form where we can free scientific article.

    Jay I Patel
    
    


    



    I am very new in the field of scientific research. And I am not sure in which area I am going to work. But I know one thing for sure, whichever area I go to, it would not be possible without your help.

Love.

    Swapnil Karale
    M.Tech, Energy Engineering with materials.
    Indian Institute of Technology
Mandi


    



    I am Mayank Singh, assistant professor at Parul University, India. I am writing this mail to give you a vote of thanks! for managing the platform for the scholar so that we can download the information and could use it for the benefit of mankind by exploring the research.

Last week I was surfing of net and I found that Elsevier has sued you in court. I don't know how can I contribute to you but I am with you. I hope the best for you!

    Dr Mayank Singh
    
    


    



    Thank you for your support of the research world.
Most of the researchers have been benefited from the Sci-Hub project and I am one among them.
I am writing this mail to share my thanks to you for your support for the researchers. I am a researcher from India who didn't have sufficient resources to purchase the research articles. Sci-hub became a boon to me to access the research articles and to continue my research.

    Rambabu
    
    India


    



    I'm a high schooler from India and I just wanted to thank you for sci hub! It's the best thing on the internet and I love it sooo much.
Lots of love

    Ananya Gupta
    
    


    



    I am a retired Professor of Theoretical Physics in Kolkata, India, and a complete and total fan of SciHub. I have sought help from SciHub a countless number of times for my research. My gratitude to you is so great, that I would like to propose you for the Nobel Prize for Peace, if ever I have a chance.

However, cryptocurrency is illegal in India and as an old man I might be jailed for trying to use it. If you know of any other way that I can offer a small addition to you fundraising (like a subscription to a journal which can then be transferred to Sch-Hub), I shall be much obliged.

We share this great ideal of knowledge for everyone for free ! Kudos to you for this great enterprise.

With warmest regards

    Parthasarathi Majumdar
    Visiting Professor
    School of Physical Sciences
Indian Association for the Cultivation of Science
Kolkata 700032, India


    



    Hello Alexandra, I hope this email finds you well. I would like to appreciate the excellent work that you are doing for the greater good of science. I just can't imagine a day where I do not visit your website for reference work. Just like me, millions around the world rely on sci hub for their work and I hope you continue to fight against capitalistic companies which try to hoard scientific knowledge from the common masses. Wishing you all the best on this path of yours. Thank you. Regards.

    Raunak Kothari
    Junior Research Fellow
    Somaiya Vidyavihar University


    



]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Deletion of Docker.io/Bitnami]]></title>
            <link>https://community.broadcom.com/tanzu/blogs/beltran-rueda-borrego/2025/08/18/how-to-prepare-for-the-bitnami-changes-coming-soon</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45048419</guid>
            <description><![CDATA[After evaluating the impact and community feedback, the Bitnami team has postponed the deletion of the Bitnami public catalog (docker.io/bitnami) until September 29th to give users more time to adapt to the upcoming changes.]]></description>
            <content:encoded><![CDATA[
                        Update
After evaluating the impact and community feedback, the Bitnami team has postponed the deletion of the Bitnami public catalog (docker.io/bitnami) until September 29th to give users more time to adapt to the upcoming changes.To raise awareness before the registry deletion, we will run a series of brownouts over the coming weeks. During each brownout, a set of 10 container images from docker.io/bitnami will be temporarily unavailable for 24 hours. The scheduled brownouts are:



August 28, 08:00 UTC → August 29, 08:00 UTC
September 2, 08:00 UTC → September 3, 08:00 UTC
September 17, 08:00 UTC → September 18, 08:00 UTC



The list of affected applications will be published on the day of each brownout via our usual channels.As previously announced, since August 28th, we have not published new Bitnami container images or Helm charts to Docker Hub in OCI format. The source code for containers and Helm charts remains available on GitHub under the Apache 2.0 license.

What's changing?
Starting August 28th, Bitnami will be archiving its OCI registry of charts and images to a new location, Bitnami Legacy, to make room for the new secure, hardened images that will eventually reside in the main Bitnami registry. Users who are currently pulling these images will need to update their pipelines, internal mirrors, and Kubernetes clusters to pull from a new location before that time. A couple of options users have: 


Switch to Bitnami Secure Images 


Switch to the Bitnami Legacy Registry


To retain existing functionality and maintain continuity of systems relying on Bitnami, we recommend switching to Bitnami Secure Images. In addition to a less disruptive transition, BSI helps strengthen your security and compliance posture by adopting the higher-quality images offered as part of BSI. 


Switching to Bitnami Secure Images (BSI)
While some BSI images will be free, they are only for use in development/testing purposes, and a commercial subscription is recommended for access to the entire catalog, as well as stable tags, long-term support versions, and more. 
Though a BSI subscription provides customers with the entire Bitnami Debian-based image catalog (which will continue to receive updates), we recommend users upgrade and start using the hardened Photon Linux-based images instead. These are designed to be replacement images for any of the Debian images and work with the same Helm charts. 
The Photon images provide many other benefits not previously available to users of Debian images, including: 


Drastically reduced CVE count (e.g., 100+ CVEs to in some cases 0)


VEX statements for easier triage, along with Known Exploitable Vulnerabilities (KEV) and EPSS scores


A self-service UI/API with powerful reporting and metadata capabilities


More advanced Helm charts are not available on Docker Hub, such as Bitnami’s “distroless charts” which offer an 83% smaller attack surface (by MB).


Support for customizing the images built by our secure SLSA 3 software factory 


Images and Helm charts are delivered to a private and secure OCI registry dedicated to each customer instead of relying on a public registry with rate limits like Docker Hub.


Access to over 90 VM Images in OVA format


Enterprise support for packaging and installation issues


Switching to Bitnami Legacy Registry
Another option for users of Bitnami today is to switch to the historic archive registry called Bitnami Legacy. This is unsupported software that is being made available, at users' own risk, while they make plans for alternatives. As such, this is a temporary solution, and we do not plan to keep this registry around for long. It will quickly begin to accumulate vulnerabilities that are not patched and atrophy as any software frozen in time does. If this is your choice, we strongly recommend copying the images you are using to your own registry; again, this should be considered a temporary solution. While we think there are many better options to make before the August 28th change, this is an option of last resort for those who need more time. 
Why is it a good time to consider upgrading your security and compliance for open source? 
So why do all the work now to change what’s maybe been working and update the type of open source images you use? We get it, no one likes change. But the reality is the landscape of open source is changing all around us. For example, from 2019-2023, the number of malicious packages discovered has risen to more than 245,000 according to Sonatype. That’s 2x all the previous years combined. The implication is that bad actors are finding increasing opportunities to exploit open source software that is running in every major software organization around the world. Meanwhile, with the growth of AI and MCP models, open source consumption is only going to increase. So the risk profile tides are quickly rising around us, and having a better boat to be prepared for the impacts of this change is the only responsible response. 
In addition, the Cyber Resilience Act in the EU creates an impending obligation for many organizations doing business there to provide guarantees about the open source software they use in their organization. It could soon be a liability to use open source that doesn’t have the required documentation to prove it’s been sourced from a safe place and hasn’t been tampered with. 
This is why the launch of Bitnami Secure Images is so timely. BSI is making it easier than ever for organizations to responsibly prepare for what the future of open source software in our modern world looks like. As with many things, what started out simple has become increasingly complex and requires more care to navigate. Furthermore, BSI has one of the lowest TCOs in the industry, enabling more organizations than ever before to afford cutting-edge supply chain security. BSI is effectively democratizing security and compliance for open source so that it doesn’t require million-dollar contracts from vendors with sky-high valuations. 
What are Competitors trying to claim about Bitnami? 
It’s also a great time for the competition to try and steer the narrative about Bitnami. Some have claimed that Bitnami is “pulling their free container images and Helm charts from public access”. However, if we look a little more closely at the changes Bitnami has announced, this statement is inaccurate. For one, Bitnami Helm charts continue to be an open source project, under Apache 2, freely available to the public on GitHub. 
Second, what is actually changing is the built OCI artifacts. Essentially, Bitnami has been the Jenkins of the internet for many years, but this has become unsustainable. Operating a build pipeline and OCI registry for the general public is very expensive. Just ask those same competitors throwing shade at Bitnami why they have never offered to make their charts or images publicly available at the same scale Bitnami has?
So users can continue to freely access the Helm chart source (as well as the Debian images). However, in order to sustain and support the dedicated team of engineers who maintain and build new charts and images, a subscription will be required if an organization needs the images and charts built and hosted in an OCI registry for them. And to reiterate the above again, organizations that choose this path are simultaneously upgrading their security posture and improving their OSS strategy.
How do the changes on August 28th work?
The changes to the Bitnami repo are slated to begin on Aug 28th. They will not all be at once. Over a multi-week period, the images will be cleaned up from the registry to make room for the new ones. This is being done gradually to minimize the disruptions. However, we can’t be precise about which image will be removed at what time due to the complexity of the 84TB of OCI content that the engineering team will be dealing with. Therefore, it’s best to assume starting Aug 28th, every image used in a key business function should be addressed with an alternate registry. 
We’re making room in the mainline Bitnami registry so we can populate it with the free tier of Bitnami Secure Images. These hardened Photon have the same names as the Debian images, so they can’t occupy the same registry. And we want new adopters of Bitnami to start with the secure images going forward, as we believe this is the future of open-source software on the internet. In this FAQ, you can find more information about all the details of the upcoming changes.
#bitnami#Security#helm
                    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Certificates for Onion Services]]></title>
            <link>https://onionservices.torproject.org/research/proposals/usability/certificates/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45047897</guid>
            <description><![CDATA[This document tracks existing procedures or proposals for integrating and
validating TLS/HTTPS certificates for Onion Services.]]></description>
            <content:encoded><![CDATA[
      
      
        
          
        
      
      
        
              
                
                  



About¶
This document tracks existing procedures or proposals for integrating and
validating TLS/HTTPS certificates for Onion Services.
While some depends on Certificate Authorities (CA) model, others rely on
alternative certification and validation procedures that does not require
built-in certificate chains in the client software or reliance on financial
transactions.
Introduction¶
Whenever you browse the internet regularly, the connection between your
computer and a service is usually encrypted, and the safety of this
communication happens through the verification of a special type of
certificate.
With Onion Services, the connection is peer-to-peer encrypted by default,
which means that no additional certificates are needed.
But as the web and other internet technologies mature, certificates are
starting to be a requirement in order to unleash functionalities, especially in
web browsers, such as the faster connection protocol HTTP/2 and payment
processing.
That's why it's important to improve the certificate ecosystem to fully support
Onion Services.
This is a hard problem, and an ongoing effort, but there has been some
important work done to solve this.
The most relevant one should bring automation to the process of issuing
certificates for Onion Services, through an enhancement in a protocol called
ACME.
The ACME for Onions proposal is composed of tools and also
an Internet Draft, which hopefully will turn into an
Internet Standard soon.
We are also looking into other, non-conflicting alternatives that can also be
used for certification, so service operators can decide which one fits best their
use case.
Improving the certificate functionality will put Onion Services in parity
with the modern stack of web development.
Benefits¶
It may be argued that Onion Services connections are already
self-authenticated -- since the public key and the URL are tied together and
the connection is peer-to-peer encrypted --, and thus making the need for HTTPS
pointless, or at most giving only an impression on users of additional security.
But having valid HTTPS connection in Onion Services could enable many other
enhancements, such as:


Some browser features are available only with HTTPS, like Secure
   Contexts, Content Security Policy (CSP), Secure cookies,
   WebAuthn, WebRTC and PaymentRequest.


A user may be using a browser that isn't the Tor browser.  For
   example on iOS there is only Safari, and in such cases the browser
   will not be aware of the different semantics of security for an onion
   site, and won't allow the use of secure browser features (such as
   secure cookies). This limits the kind of web apps people can develop
   on onionsites as many modern browser APIs mentioned above.


Allows for the usage of HTTP/2, since some browsers only support it if
   on HTTPS1. In the future, HTTP2 and HTTP3 may only
   work with TLS, and thus valid certificates.


It also opens up new opportunities such as payment processing, "as current
   PCI DSS requirements do not allow non-standard TLS"2 and may
   only work with certificates having some sort of validation3.
   Payments card networks require HTTPS for a payment to be taken. So if
   someone wants to do that over an onion site they would need a TLS
   certificate.


It could be argued that this is also security-in-depth by having yet another
   layer of encryption atop of other existing encryption layers. Even if the
   theoretical gain in terms of interception and tampering resistance is not
   relevant, it would still allow for service operators to split their encryption
   keys in different servers -- like one with the Onion Service keys and a backend
   having the TLS keys, thus making a compromise in one of the servers exposing
   only the cryptographic material of one of the communication layers.


The Tor daemon that hosts the onion site might not be the final
   computer in the chain. In larger organizations, deployment concerns
   may result in plain HTTP traveling across their network from the Tor
   daemon to the final web server. Having HTTPs protects those hops in
   the chain. This is something that distributed setups may need. The same
   could be said for a web browser using Tor SOCKS proxy somewhere else on the
   network.


Non-web based applications, such as IMAP/POP/SMTP etc. can benefit
   from certificates being valid.


There is simply too much software that isn't aware of onionsites,
   and trying to force HTTP-over-Onion to be as secure as HTTPS-over-TCP
   creates a compatibility mess of things which do and don't know about
   the semantics.


There is value in exposing the existence of an onion site via CT
   Logs. If someone navigates to the plain web version of a site, and is
   presented with a certificate containing a Subject Alternative Name (SAN) for
   both the plain web and the onion site that provides a strong cryptographic
   guarantee that they are the same site. Effectively this would replace the
   Onion-Location header with something more authenticated4.


The following discussion is not yet conclusive, and the problem space may be
hard to solve.
Overview¶



Proposal
Certification
Validation
Status




Existing CA validation
CA/B Baseline Requirements for .onion
CA chain
Implemented, fully supported


ACME for .onion
CA/B Baseline Requirements for .onion
CA chain
Standardized as RFC 9799, need adoption by CAs


Self-signed certificates
Self-signed certificate
None
Depends on per-application support


Self-signed X.509 from .onion
Signed by a "CA" derived from the .onion private key
Check if cert is issued by the .onion private key
Proof-of-concept, no browser integration


Same Origin Onion Certificates (SOOC)
Self-signed certs
Skip for .onion addresses when conditions match
Proposal (not yet submitted for specification)


DANE for .onion
Self-signed certs
DNSSEC
Concept, no proposal yet


Onion-only CAs
Checks SAN and an .onion signature in an extension
CA chain
Concept, no proposal yet


Self-auth certs via PKCS#11 module
Checks .onion Ed25519 signature in the cert key
Module returns a custom CA chain
Design, prototype available



Main pros and cons¶



Proposal
Pros
Cons




Existing CA validation
None (already implemented)
None (already implemented)


ACME for .onion
No need for client/lib implementation
Depends on a CA willing to implement


Self-signed X.509 for .onion
No CA-reliance for .onion, self-auth.
Very hard to maintain and standardize, currently Ed25519 is unsupported by major browsers


Same Origin Onion Certificates (SOOC)
No CA-reliance for .onion
Very hard to maintain and standardize


DANE for .onion
No CA-reliance for any domain or .onion
Very hard to implement and maintain


Onion-only CAs
Simplify CA-reliance
Needs to convince existing CAs or trusted parties to maintain a whole CA organization and infrastructure


Self-auth certs via PKCS#11 module
PKCS#11 is well established, future proof, no CA-reliance
Each Operating System or application would need to configure it; built-in OpenSSL support still underway



Main implementation characteristics¶



Proposal
Implementation level
Additional requirements




Existing CA validation
Procedure happens at the CA side



ACME for .onion
Procedure happens at the CA side



Self-signed X.509 for .onion
Client or TLS library



Same Origin Onion Certificates (SOOC)
Client or TLS library



DANE for .onion
Client
Portable DNSSEC library


Onion-only CAs
Client or TLS (only needs CA installation)



Self-auth certs via PKCS#11 module
Library (PKCS#11 module)




Existing CA validation¶
The CA/Browser Forum, a consortium that produces guidelines for X.509
(TLS/HTTPS) certification, created validation rules for Onion Service v2
addresses (in 2015), later extended for Onion Services v3 (in 2020),
standardizing the way Certificate Authorities can issue certificates for
.onion addresses and supports wildcards5.
Only a few commercial providers currently provide this service6.
The Appendix B of the CA/B Baseline Requirements (current repository
version) for the Issuance and Management of Publicly‐Trusted Certificates
(since Version 1.7.4, released in 2021) establishes two validation methods to ensure
that someone request the certificate really control a given .onion address:

An "Agreed‑Upon Change to Website" (manually or via ACME), where the
   service operator must include some secret, such as at the
   /.well-known/pki-validation of the site.
TLS using ALPN.
Checking of a Certificate Signing Request (CSR) signed by the Onion Service
   private key and containing an specific cryptographic nonce (i.e, a shared
   secret to be used only once), like using the onion-csr tool.

Note that both methods does not require that operators disclose the location of
the Onion Service, nor them need to have a regular site for the service using
DNS. Validation can either happen by accessing directly the Onion Service or
by using the service private key to sign a CSR.
But still commercial CAs (or financial institution) may still collect
identifiable information during the purchase of the certificates.
ACME for .onion (CA-validated)¶
In general, getting certificates from CAs supporting the CA/B Baseline
Requirements for .onion addresses is still a manual, or in the best-case
scenario, semi-automated task.
The Automatic Certificate Management Environment (ACME) standard (RFC
8555) solves part of the automation problem, and with the arrival of
RFC 9799 it also supports methods for validating Onion Services.
Having support for .onion address in the ACME standard is the first step
for projects like Let's Encrypt to offer free certificates for Onion
Services, without financial transactions.
Existing proposals to bring ACME for Onion Services are discussed below.
ACME for Onions¶
The "Automated Certificate Management Environment (ACME) Extensions for
".onion" Domain Names" (draft-misell-acme-onion) is the second known
proposal to bring ACME for .onion addresses.
This is the proposal that lead to RFC 9799.
A detailed analysis on ACME for Onions is available in a special
appendix.
References:

ACME for Onions
AS207960/acme-onion
Work funded by OTF

ACME Onion Identifier Validation Extension¶
The "Automated Certificate Management Environment (ACME) Onion Identifier
Validation Extension" internet draft (draft-suchan-acme-onion-00)
was proposed on 2022-05 and is the first known proposal to bring ACME
for .onion addresses.
As of 2023-06-07, this internet draft is in the expired state, being now
supplanted by RFC 9799.
References:

Relevant mail threads
orangepizza/acme-onion-doc: docs about standardize handling onion address in acme context

Self-signed certificates¶
This proposal basically consists in allowing the use of self-signed
certificates with Onion Services:

For web applications like the Tor Browser, this would consist
   in disabling self-signed certificate warnings when visiting .onion
   sites. As an alternative, there's also the Self-authenticating TLS
   Certificates for Onion Services using a PKCS#11 module discussed
   below and relying on PKCS#11 modules or Authority Information Access
   (AIA) extensions, which could handle self-signed certificates matching
   the Onion Service address without the need to merge this logic directly in
   the applications, as it would remain decoupled in a PKCS#11 module, thus
   being easier to maintain.
For other applications -- like the TorVPN and third-party software --,
   this would probably require patches or documentation instructing users to
   accept non-CA signed certificates when accessing Onion Services, which is
   very hard to provide and to maintain for a wide ranging of tools.


Supported key types
In this proposal, any key types supported by applications could be used.
In case of popular web browsers, the CA/B Baseline Requirements
must be taken into account, which as of 2024-09 only allows for
RSA or ECDSA keys.
It could also be possible to use self-signed certs using Ed25519,
which is discussed below and currently not widely supported by
browsers.

This proposal would not provide:

A self-authentication mechanism (since the certificate is self-signed).
   This have a huge weight since an important piece of security provided
   by HTTPS is not just end-to-end encryption but also authentication.

Supporting self-signed certificates with Onion Services has a huge gain,
but also introduces an authentication complexity. That's why proper UI
indicators and hints are needed:

For the encryption state of the site (HTTP and various HTTPS situations).
For the authentication state of the site, telling how it was (not)
   authenticated.

There are already sketches for different scenarios for how various user
interface hints and indicators could exist for Tor Browser and other software
maintained by Tor, as well as existing certificate proposals that can change
the certificate landscape for Onion Services in the future, which could be
adopted by operators instead of relying on self-signed certs.
But all these enhancements would still limit the practical application domain
of this proposal, since it would be readily available only to a small set
of applications like Tor Browser, except if by pursuing some standardization
such as the SOOC proposal below.
Self-signed X.509 from .onion (self-signed by the .onion address)¶
Another option for having HTTPS in Onion Services that may be available in the
future is to use Onion Service key pair to self-validate an HTTPS certificate
using Ed25519 directly:

The Onion x509 is an example in how a CA self-signed by an .onion could
  be constructed.
There's also a ticket requesting to add support for self-signed HTTPS onion
  sites derived from onion service's ed25519 key in the Tor Browser.

For an overview of Ed25519, check How do Ed5519 keys work?. For details
about how Tor implements Ed25519, check prop220 (and rend-spec-v3
for how it implements at the Onion Services level).
This proposal has the advantage to not rely on Certificate Authorities, but the
disadvantage that needs additional logic both server and client side to make it
work, since a CA would needed to be installed for every visited Onion Service
using this scheme.
On using .onion keys for certification¶
It's important to note that the current (as of 2024-09) Onion Services v3
specification does not allow the Master Onion Service identity key to be used
for purposes other than generating blinded signing keys (see Section 1.9 from
the rend-spec-v3):

Master (hidden service) identity key -- A master signing key pair
  used as the identity for a hidden service.  This key is long
  term and not used on its own to sign anything; it is only used
  to generate blinded signing keys as described in [KEYBLIND]
  and [SUBCRED]. The public key is encoded in the ".onion"
  address according to [NAMING].
  KP_hs_id, KS_hs_id.

On Ed25519 certificates support in browsers¶
Also, while many TLS libraries support the Ed25519 signing scheme used for
certificates (like in OpenSSL since version 1.1.1), major web browsers
still does not support it (as of 2022-12)7, probably because
they're not supported8 by the current (as of 2024-09) CA/B
Baseline Requirements:

6.1.1.3 Subscriber Key Pair Generation
The CA SHALL reject a certificate request if one or more of the following
conditions are met:

The Key Pair does not meet the requirements set forth in Section 6.1.5
   and/or Section 6.1.6;

[...]
6.1.5 Key sizes
For RSA key pairs the CA SHALL:
• Ensure that the modulus size, when encoded, is at least 2048 bits, and;
• Ensure that the modulus size, in bits, is evenly divisible by 8.
For ECDSA key pairs, the CA SHALL:
• Ensure that the key represents a valid point on the NIST P‐256, NIST P‐384
  or NIST P‐521 elliptic curve.
No other algorithms or key sizes are permitted.

Implementing X.509 certs derived from the .onion key pair¶
In summary, implementing this proposal would require pushing at least two
specification changes:

A ballot with CA/B Forum about including Ed25519 support.
An update in the Onion Services v3 spec, allowing the Onion Service identity
   keys to either:
Also act as Certificate Authority root keys for the service.
Derive long-term (1 year) blinded keys to be used as a Certificate
   Authority for the service, maybe using the same approach described by
   Appendix A ([KEYBLIND]) from rend-spec-v3 but covering the needed
   use case of a long-term key, i.e, depending in a long-term nonce and not in
   [TIME-PERIODS].



It's also important to avoid using the Onion Service key directly as the HTTPS
certificate. That would:

Expose the Onion Service secret key material to more software than it's
  needed, like a web server.
Make it very difficult to manage offline Onion Service master keys.

Instead, it's better to use the Onion Service key pair to act as a CA that then
certifies a separate key pair to be used with HTTPS.
Similar to the self-signed certificate proposal, this approach would have
limited adoption if only as small number of applications implement it -- such
as the Tor Browser --, except if endorsed by many stakeholders in the form of a
specification -- like the SOOC proposal discussed below.
Self-authenticating TLS Certificates for Onion Services using a PKCS#11 module¶
The Self-authenticating TLS Certificates for Onion Services using a PKCS#11
module proposal mentioned above, that relies on PKCS#11 modules or
Authority Information Access (AIA) extensions, could also be used to work
with a X.509 certificate directly derived from the .onion key pair.
But contrary to the previous proposal, it would not need to use Ed25519: it
would support a signature scheme where an Ed25519 private key could sign an
ECDSA key. This Ed25519 signature could either be created using the .onion
private key itself or a fresh Ed25519 subkey, thus avoiding key reuse.
Advantages:


Would reduce logic in the Tor Browser by a well-established API.


Does not need to use Ed25519 X.509 certificates: can work with ECDSA
  which are fully supported by major browsers according to the
  CA/B Baseline Requirements, and maybe could even work with RSA.


Seems future-proof as PKCS#11 modules are widely used.


No reliance on the CA-model (and hence has increased censorship resistance).


No need to use CT Logs.


Could be used by other browsers as well (such as Brave).


Could be used with any software, library or Operating System with PKCS#11
  support.


Disadvantages:


In the short-to-mid term this would not be supported on OpenSSL
  (as of 2024-09, support PKCS#11 modules is still underway).


System-wide support would depend on how each Operating System could support
  this custom module. So could be hard to add this to TorVPN. But anyway,
  TorVPN can't validate existing self-signed .onion certs either, as
  of 2024-09.


Operators currently using self-signed certs would need to migrate to new
  certificates.


References:

namecoin/pkcs11mod: Go library for creating pkcs11 modules:
pkcs11mod progress: Windows, macOS, certutil support, and more!


Consistent PKCS #11 support in Red Hat Enterprise Linux 8.
OpenSSL support for PKCS#11:
OpenSC/libp11: PKCS#11 wrapper library (libengine-pkcs11-openssl on Debian)



Same Origin Onion Certificates (SOOC)¶
The Same Origin Onion Certificates (SOOC) proposal aims to specify when "in
very limited circumstances, we shall not care about signatures at all",
allowing clients to disable self-signed certificate warnings when visiting
.onion sites.
The main difference between the SOOC proposal and to simply start allowing
self-signed certificates is that SOOC is aimed to be an IETF proposal that
could gain momentum and hence have a greater chance to be adopt by many
different vendors.
See the SOOC document for details.
DANE for .onion¶
Another option is to use DNS-based Authentication of Named Entities (DANE),
with DNS records like this to associate an Onion Service address with a given
HTTPS certificate's public key hash:
_443._tcp.testk4ae7qr6nhlgahvyicxy7nsrmfmhigtdophufo3vumisvop2gryd.onion. TSLA 3 1 1 AB9BEB9919729F3239AF08214C1EF6CCA52D2DBAE788BB5BE834C13911292ED9

In order for that to work, logic should be implemented in the client software.
Drawbacks:

Service operators must update this record whenever a new certificate is issued.
Has some limits for wildcard certificates on specific ports.
DANE is not widely supported, especially by web browsers.
It would only work for service operators willing to publish the .onion address in the DNS.

Onion-only CAs¶
This proposal consists of:

Having .onion-only CAs with name constraints (only allowing issuance for
   .onion). Services available both via DNS-based and .onion domains will need
   to have two TLS certificates in order to use this approach -- one certificate
   for the DNS-based domain (as usual) and another only for the .onion address.
Certification procedure would be automated, so generated .onion addresses
   could easily have it's certificates issued by this special type of CA.
Certification would then happen by checking a signature in a CSR and
   comparing the Subject Alternative Name (SAN). Signature must be validated by
   the .onion address in the SAN.
So this type of CA would be mainly a basic notary that attests signatures and
   issues a corresponding certificate.
The name constraint for this type of CA ensures that it only issues
   certificates for .onion domains.

Security considerations:

Suppose there's a malicious or bugged CA of this type that issues a
   certificate containing a SAN for $address1.onion but:
Without checking whether the CSR has a signature made by
   $address1.onion's private key.
Or if allowing that another, unrelated $address2.onion actually signs
   this CSR.


Even if that's the case, i.e, the CA wrongly issued a certificate for
   $address1.onion that did not match the requirements, this certificate
   won't work in practice, since in a successful Onion Service TLS connection
   to $address1.onion the following must happen:
The underlying Tor Rendezvous connection should ensure that the
   client is connected to $address1.onion (Onion Services connections
   are self-authenticated by the .onion address).
The Onion Service should then offer it's TLS certificate, which would
   not be the malicious one (except if the service is already compromised,
   but in that case the attacker would not need to forge an invalid certificate
   anyway...).
Then the client's TLS library tests whether the certificate chain can be
   verified and any SAN in the presented certificate matches $address1.onion,
   among other checks (such as expiration).


That said, the work done by this special type of CA is only to expand the
  self-authentication property from the .onion address into a certificate. So
the attack surface of this special type of CA may be inherently low.

Implementation considerations:

Since Ed25519 certificates probably won't be supported by major
  browsers/clients in the foreseeable future (see discussion above at the
  Self-signed X.509 for .onion section), issuance should probably follow the
  Appendix B of the CA/B Baseline Requirements.
The entire certification procedure could happen via Onion Services.
Actually the whole CA infrastructure (website, APIs, OCSP etc) could be
  interacted only via Onion Services, to reduce the attack surface and protect
  the service location.
Important to consider whether would be possible to organizations setup and
  maintain a Onion-only CA that's as most automated as possible, including root
  certificate packaging/distribution/rotation.

Pros:

Easy to implement on the client side (just need to install the CA).
Easy to implement and maintain on Tor-native applications such as Tor
   Browser and the Tor VPN.
Possibly lowest attack surface than with regular CAs!
Largest certification expiration dates could be used (like one year).

Cons:

Might not be easy to find CAs willing to do this, or to a new one to be
   formed for this purpose.
Might need a merge request to include this method in the CA/B Baseline
   Requirements, if wider acceptance is intended.
No guarantees that these special CAs would be installed among all clients
   and libraries.
Need additional security analysis.

Open questions:

Need to check if Certificate Revocation Lists (CRLs) are needed,
   and how to handle it.
Need to figure out how OCSP and OCSP Stapling could happen. OSCP
   connection could be available behind an Onion Service.
Does sending certificates to CT Logs still makes sense for this special
   type of certification?
Needs built-in DoS/service abuse protection:
An idea for that: implement a simple PoW by additionally requiring that
  service operators provide a proof-ownership of another .onion address
  made by an specific vanity address (like limited to 5 or 6 chars).



References:

Proposal for Bring Accessible TLS Supports to All Onion Services, where
  this idea is initially written and discussed with the possibility for some
  clients to have only this type of CA installed (but in that case it might
  not accept valid certificates issued by regular CAs, with advantages and
  disadvantages)
Proposal for automated onion service certificate issuance based on fully
  qualified onion service key signed certificate request, where this
  proposal is sent to the CA/B Forum.

Custom CAs¶
There are also discussions about how to properly manage custom Certificate
Authorities, i.e, those not distributed in TLS libraries by default (such as
the certificate store in a web browser):

.onion indicator for non-self-signed but non-trusted sites (#27636) · Tor Browser

Further references¶
Meeting notes¶

From the 2024 Lisbon Meeting:
Self-authenticating TLS Certificates for Onion Services using a PKCS#11 module.
An update on the ACME for onions RFC.


From the 2017 Montreal Meeting:
IntegratingOnions.



Blog posts¶

Facebook, hidden services, and https certs | The Tor Project:
Part four: what do we think about an https cert for a .onion address?
Part five: What remains to be done?





.onion indicator for non-self-signed but non-trusted sites (#27636) · Tor Browser

Notes¶




But not HTTP/3 yet, since it uses UDP not available
                   via Tor (as of 2023-05). The HTTP/2 standard does not
                   require encryption, but
                   all major browsers require encryption for HTTP/2
                   and encryption for HTTP/3 is required by default. ↩


See PCI-DSS v4.0 - Appendix G - Term "Strong Cryptography" - page 355, which
            points only to "industry tested and accepted algorithms". While we could argue
            that PCI-DSS v4.0 is not precise enough about which transmission protocols
            might be used, it may be the case that the encryption used by the Onion Services'
            Rendezvous v3 protocol is not (yet) part of an "industry standard" (needs someone
            to carefully review this claim and open a merge request to update this information).
            It also may be the case that PCI-DSS compliance may be hard to get for a system
            that employs only the Rendezvous v3 protocol to transmit cardholder data between
            an user and an Onion Service, without TLS atop of it. And users might not trust
            the connection if not over TLS, or if their browser does not show certificate information. ↩


It's worth note that PCI-DSS does allow for
                    the use of self-signed certificates under some special conditions
                    that may exclude some of the proposals in this document (see PCI-DSS v4.0 - Requirement 4.2 -
                    Applicability Notes - page 106). In practice, this is
                    only applicable for internal links within an organization or for clients and libraries that
                    have the custom Certificate Authorities' root keys on it's keystores and that matches the
                    standard requirements. And users would hardly trust a
                    self-signed certificate for doing online purchases as their browsers would show
                    warning messages. Recommendation (see PCI-DSS v4.0 - Requirement 4.2 -
                    Guidance - page 106) goes instead towards a certificate trusted by a
                    Certificate Authority. ↩


However, the argument about revealing an onion site that would like
            to remain hidden, is a real one. For those services, it could
            be considered options such as a non-CT Logs issuing CA that may not be in
            the "valid" set, but operated by a friendly to Tor organization, which is
            added to Tor Browser as a valid certifier. The standards space may be
            moving towards requiring CT log submissions at some point, so this is
            something to keep an eye on. Another possibility would be to consider
            writing a standard for hashing onion site names in CT Logs, so they can
            be verified, but not revealed (such as what WhatsApp did in their
            Auditable Key Directory). Such a standard could take years to
            get to place of usefulness, and probably encounter
            resistance. Otherwise, the only option for such a service operator is
            to have a self-signed certificate, or none at all. ↩


For a historical background on Domain Validation (DV) certs,
               check the CA/B forum thread
               DV issuance for next-generation onion services. ↩


As of January 2023, there are only two CAs issuing
                    certificates for .onion domains:
                    DigiCert providing only Extended Validation (EV) certs
                    and HARICA providing only Domain Validated (DV) certs. ↩


They usually just support X25519, which is a key
agreement scheme not to be confused with Ed25519. ↩


This is tracked on cabforum/servercert issue #451, which is about
                   adding EdDSA (and hence Ed25519) support in the
                   CA/B Baseline Requirements. Check also the related mail thread
                   (Servercert-wg) Ed25519 certificates.
                   For Let's Encrypt support, check
                   letsencrypt/boulder issue 3649;
                   Request For CertBot To Support The Signing of Ed25519 Certificates and
                   Support Ed25519 and Ed448 forum threads.
                   On IETF, EdDSA and Ed25519 are standardized on
                   RFC 8032, and have Algorithm Identifiers for X.509
                   Public Key Infrastructure as part of RFC 8410. ↩















                
              
            
        
      
      
        
      
    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Open Source is one person]]></title>
            <link>https://opensourcesecurity.io/2025/08-oss-one-person/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45047460</guid>
            <description><![CDATA[The Register recently published a story titled Putin on the code: DoD reportedly relies on utility written by Russian dev. They should be ashamed of this story. This poor open source developer is getting beat up now to score some internet points. It&rsquo;s very upsetting.
But anyway, let&rsquo;s look at some receipts.
If you&rsquo;re not real smrt, it seems like pointing out an open source project is written by one person in a country you don&rsquo;t like is a bad thing. It could be. But it also could be the software running THE WHOLE F*CKING PLANET is written by one person. In a country. But we have no idea which country. It&rsquo;s not the same person mind you, but it&rsquo;s one person.]]></description>
            <content:encoded><![CDATA[The Register recently published a story titled Putin on the code: DoD reportedly relies on utility written by Russian dev. They should be ashamed of this story. This poor open source developer is getting beat up now to score some internet points. It’s very upsetting.
But anyway, let’s look at some receipts.
If you’re not real smrt, it seems like pointing out an open source project is written by one person in a country you don’t like is a bad thing. It could be. But it also could be the software running THE WHOLE F*CKING PLANET is written by one person. In a country. But we have no idea which country. It’s not the same person mind you, but it’s one person.
Here’s the thing. Almost all open source is literally one person. What I mean by that is if you look at all the open source projects out there, and there are a lot, we see a pattern of one person no matter how we slice and dice the data.
So let’s start with the data. A project exists called ecosyste.ms that catalogs a lot of open source. Most of it I would guess, but not all. They currently have 11.8 million open source projects in their data. You would be right to think that is a big number. I’m told anything over 15 is a big number, but it probably depends how smart you are, or think you are.
So what do we mean by one person is open source. What I mean is if we look at all the projects that ecosyste.ms is tracking, how many have a single person maintaining that project? It’s about 7 million. This is also a big number. 7 million open source projects are one person. It’s actually bigger than that, because of the 11.8 million projects ecosyste.ms is tracking, we don’t know how many maintainers 4 million of the projects have. A bunch of those will be one person. Here’s what a graph of this looks like

I clipped the graph so it looks nicer. There are projects with hundreds of maintainers. Not a ton, but they exist.
Now, the clever people among us are thinking “but Josh, surely these 7 million projects are all things nobody uses, the important open source we all use has loads of maintainers!!!”
You would be right to think that. It’s the first thought I had back when I started to look at this data. It’s OK. You’re still in the denial stage. Hopefully you’ll reach anger by the end of this post.
So we’re going to use the NPM ecosystem to explain this. I use NPM because they have the richest data in ecosyste.ms to explain my point. I’ve done this same thing across multiple ecosystems and the graphs all look the same.
So, what does the NPM maintainer graph look like.

Your first thought is probably “why is the left axis green?” It’s not an axis, it’s the single maintainer number. It’s that huge compared to literally all the other data. There are just that many single person NPM projects.
So now, let’s look at the number of maintainers for projects with over 1 million downloads this month.

This time the graph shows how many downloads projects with over 1 million downloads, and one maintainer or more than one maintainer. It was easier to show the data by creating these two buckets.
That’s almost a 50/50 split. Think about that. About half of the 13,000 most downloaded NPM packages are ONE PERSON. We can change the download number and the graph stays this shape. It’s not until I change downloads to 1 billion downloads that we see 1 package maintained by 1 person, and 9 packages maintained by more than 1.
This is open source. Open source is one person, even the popular stuff.
I will also add, a lot of people own more than one package. So while NPM has over 4 million single person projects, they have about 900,000 maintainers for those 4 million single person projects. This will be an important data point at the end.
So here’s the big conclusion. If you want to make a big deal about something, maybe it shouldn’t be what country a sole maintainer is from. Let’s face it, the Russians aren’t dumb enough to backdoor a package owned by a guy living in Russia. They’re going to do something like pretend to be from another country with a name like Jia Tan, not Boris D. Badguy. This isn’t a Rocky and Bullwinkle episode.
Anyway, back to the conclusion
Open source, the thing that drives the world, the thing Harvard says has an economic value of 8.8 trillion dollars (also a big number). Most of it is one person. And I can promise you not one of those single person projects have the proper amount of resources they need. If you want to talk about possible risks to your supply chain, a single maintainer that’s grossly underpaid and overworked. That’s the risk. The country they are from is irrelevant.
And now if we have news stories being written about how a single person maintainer is the bad guy? That’s not cool (this is where your denial is supposed to turn into anger).
So what can you do about this? How can you turn your newly denial-turned-anger into action? We don’t really know unfortunately. I discussed this in a podcast episode Hobbyist Maintainers with Thomas DePierre. Like many hard problems, there isn’t an easy solution. But I guarantee the solution isn’t hunting down and demonizing single maintainers.


  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Altered states of consciousness induced by breathwork accompanied by music]]></title>
            <link>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0329411</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45046916</guid>
            <description><![CDATA[The popularity of breathwork as a therapeutic tool for psychological distress is rapidly expanding. Breathwork practices that increase ventilatory rate or depth, facilitated by music, can evoke subjective experiential states analogous to altered states of consciousness (ASCs) evoked by psychedelic substances. These states include components such as euphoria, bliss, and perceptual differences. However, the neurobiological mechanisms underlying the profound subjective effects of high ventilation breathwork (HVB) remain largely unknown and unexplored. In this study, we investigated the neurobiological substrates of ASCs induced by HVB in experienced practitioners. We demonstrate that the intensity of ASCs evoked by HVB was proportional to cardiovascular sympathetic activation and to haemodynamic alterations in cerebral perfusion within clusters spanning the left operculum/posterior insula and right amygdala/anterior hippocampus; regions implicated in respiratory interoceptive representation and the processing of emotional memories, respectively. These observed regional cerebral effects may underlie pivotal mental experiences that mediate positive therapeutic outcomes of HVB.]]></description>
            <content:encoded><![CDATA[








  
    Loading metrics
  








    
  Open Access
  Peer-reviewed

Research Article



    




  






       



   
Toru Horinouchi  ,    



   
Balázs Örzsik  ,    



   
Brittany Anderson  ,    



   
Lottie Hall,    



   
Duncan Bailey,    



   
Sarah Samuel,    



   
Nati Beltran,    



   
Samira Bouyagoub,    



   
Chris Racey,    



   
Yoko Nagai,    



   
Iris Asllani,    



   
Hugo Critchley,    



   
Alessandro Colasanti      









    
      Neurobiological substrates of altered states of consciousness induced by high ventilation breathwork accompanied by music



  Amy Amla Kartar, 

  
  Toru Horinouchi, 

  
  Balázs Örzsik, 

  
  Brittany Anderson, 

  
  Lottie Hall, 

  
  Duncan Bailey, 

  
  Sarah Samuel, 

  
  Nati Beltran, 

  
  Samira Bouyagoub, 

  
  Chris Racey





    
    
      x
    
  

      
        Published: August 27, 2025
        
https://doi.org/10.1371/journal.pone.0329411
        
        
      

    
  

  







  Figures

  

          

            

          

            

          

            

          

            

          

            

          

            
      






        
          



AbstractThe popularity of breathwork as a therapeutic tool for psychological distress is rapidly expanding. Breathwork practices that increase ventilatory rate or depth, facilitated by music, can evoke subjective experiential states analogous to altered states of consciousness (ASCs) evoked by psychedelic substances. These states include components such as euphoria, bliss, and perceptual differences. However, the neurobiological mechanisms underlying the profound subjective effects of high ventilation breathwork (HVB) remain largely unknown and unexplored. In this study, we investigated the neurobiological substrates of ASCs induced by HVB in experienced practitioners. We demonstrate that the intensity of ASCs evoked by HVB was proportional to cardiovascular sympathetic activation and to haemodynamic alterations in cerebral perfusion within clusters spanning the left operculum/posterior insula and right amygdala/anterior hippocampus; regions implicated in respiratory interoceptive representation and the processing of emotional memories, respectively. These observed regional cerebral effects may underlie pivotal mental experiences that mediate positive therapeutic outcomes of HVB.



Citation: Kartar AA, Horinouchi T, Örzsik B, Anderson B, Hall L, Bailey D, et al.  (2025) Neurobiological substrates of altered states of consciousness induced by high ventilation breathwork accompanied by music. PLoS One 20(8):
           e0329411.
        
        https://doi.org/10.1371/journal.pone.0329411Editor: Gaëtan Merlhiot, Institut VEDECOM, FRANCEReceived: August 6, 2024; Accepted: July 16, 2025; Published:  August 27, 2025Copyright:  © 2025 Kartar et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Data Availability: All relevant data for this study are publicly available from the OSF repository (https://doi.org/10.17605/OSF.IO/5WR9Q).Funding: The author(s) received no specific funding for this work.Competing interests:  The authors have declared that no competing interests exist.





IntroductionHigh ventilation breathwork (HVB) encompasses contemplative and therapeutic practices, including Conscious Connected Breathing or Holotropic Breathwork, in which a controlled pattern of volitional breathing increases the rate or depth of ventilation and is typically accompanied by evocative music. Despite their distinct historical roots and delivery modalities, these different HVB practices share a purported ability to elicit acute extraordinary alterations in subjective experience that closely resemble the qualia of altered states of consciousness (ASCs) induced by psychedelic substances [1–3]. Converging evidence demonstrates the potential value of psychedelic treatments for specific difficult-to-treat psychiatric and physiological conditions [4–7]. The induction of ASCs is suggested to be critical to the therapeutic action of psychedelic substances [8–10], for which HVB might therefore offer a non-pharmacological alternative, with fewer legal and ethical restrictions to large-scale adoption in clinical treatment. In line with this, the popularity of HVB as a therapeutic tool for psychological distress is rapidly expanding, indexed by an increased number of scientific investigations, see [11,12] for more details.
The therapeutic potential of HVB practices is suggested by a long cultural tradition of use to relieve symptoms of psychological distress [11,13] and by emerging preliminary evidence of clinical efficacy from controlled trials in affective and trauma-related disorders [14]. Prolonged hyperventilation/HVB reportedly elicits a wide range of effects on subjective experience that include emotional and psychedelic-like phenomena (ASCs), which range from panic-like sensations to feelings of awe and dissociative symptoms [11]. The 5D-ASC questionnaire is popularly used in ASC research to retrospectively assess such states [15]. A key dimension of this scale is ‘Oceanic Boundlessness’ (OBN); a term coined by Freud in 1920 [16] which describes a set of related feelings including ‘spiritual experience, insightfulness, blissful state, positively experienced depersonalization, and the experience of unity’ [17]. OBN is considered as a defining aspect of ASCs evoked by psychedelic substances, such as psilocybin. However, the neurobiological mechanisms and subjective experience underlying ASCs induced by HVB have not been studied extensively and remain elusive.
First, we characterised the subjective experience of HVB to capture the nature and intensity of evoked experiential phenomena. From these data, we aimed to assess whether these effects could be reliably reproduced in controlled experimental settings in comparison to a remote – and more ecologically valid – condition. These findings informed the choice of the ASC variable, OBN, which was ultimately selected as the most widely reported experiential phenomena to identify the critical neurobiological effects of HVB.
Then we examined the effects of HVB performed by experienced breathwork practitioners in different experimental settings, and investigated peripheral and central neurophysiological mechanisms underpinning ASCs engendered by HVB. The neurobiological endpoints were selected based on well-characterised neurophysiological effects of hyperventilation (reviewed in [11]). Hyperventilation acutely reduces regional cerebral blood flow (rCBF) through interacting effects of hypocapnia, cerebral alkalosis and hypoxia, resulting in transient perturbation of neurometabolic homeostasis. Further, hyperventilation evokes allostatic changes in action-ready bodily arousal, mediated via the autonomic nervous system via the dominance of sympathetic over parasympathetic drive to the heart and blood vessels. In characterising the neurobiological effects of HVB and associated ASCs, we therefore focused our measurements on two robust indices of neurometabolic and autonomic nervous control: rCBF and heart rate variability (HRV).
To our knowledge, no studies have previously reported the relationship between the intensity of ASCs and changes in rCBF induced by HVB practices. Since we could not base our prediction of the regional specificity of such correlations on previous knowledge, we preferred to adopt a whole brain voxelwise exploratory approach. Also, as observations reported on the effects of psychedelics on autonomic nervous system activity have been contrasting [18,19], we could not make precise predictions on the direction of association between HRV and ASCs.
Our study was designed to address different objectives through three inter-related experiments: (please see the methods for more details), in 1) HVB was conducted over an online video-conferencing platform with a breathwork facilitator (REMOTE setting). The aim was to characterise the subjective response to remote HVB in a home setting, and inform the choice of the ASC domain to be used as subjective endpoint. In 2), we used pseudo-continuous arterial spin labelling (pCASL) magnetic resonance imaging (MRI) of the brain during HVB to identify the relationship between neural haemodynamic effects of HVB and subjective measures (MRI setting). In 3) HVB was performed in a psychophysiology lab to characterise the relationship between the psychophysiological effects of HVB (autonomic alterations, see ‘psychophysiological session 3’ for more information) and subjective measures (LAB setting).


Materials and methods
Ethics statement
This research was approved by the Research Governance and Ethics Committee (RGEC) in Brighton and Sussex Medical School (BSMS) as ERA/BSMS9AN4/2/2. Recruitment began on 24/11/2021 and ended on 03/03/2022. Participants provided written informed consent before participating.


Participants
Physically and psychiatrically healthy participants aged 18–65 years old were recruited from the local area through advertisements and flyers distributed at breathwork events, in yoga/meditation centres, and on social media. Participants were eligible to take part if they had either 10 or more experiences of fast-paced breathwork or at least 6 months of any HVB practice (as defined in [11]). They were screened online for eligibility and excluded if they were pregnant, currently experiencing any psychiatric condition (assessed using the Mini International Neuropsychiatric Interview (MINI) to ensure absence of DSM-V listed disorders) [20]. Additional exclusion criteria included a history of epileptic seizures, panic disorder, or syncope in prior HVB, current neurological, musculoskeletal, respiratory, or cardiovascular disease, current pharmacological treatment, and contraindications to MRI.
Participants and were financially compensated £10 per hour for their time and up to £10 in travel expenses.


Breathwork modality and subjective measures
HVB consisted of cyclic breathing without pausing, accompanied by progressively evocative music. This aimed to reproduce the experience of Conscious Connected Breathing, a widely adopted HVB practice typically led by a trained breathwork facilitator. In the online experimental session, instructions were provided by a breathwork facilitator (DB) who hosted the group of online participants. For the LAB and MRI setting, pre-recorded instructions by the same facilitator were delivered to participants. Specific details on breathwork instructions are presented in the supplementary index (S1 Appendix).


Questionnaires
Self-reported measures were consistent across the three conditions and administered online via Qualtrics (Qualtrics, Provo, UT) [21] within 30 minutes post-HVB. The selected questionnaires assessed: 1) Affect (Positive and Negative Affect Schedule – Expanded Form, PANAS-X [22]); 2) Panic–like symptoms (Panic Symptoms List, PSL [23]), 3) Fear and discomfort (Visual Analogue Scales (VAS) [24]), and 4) Symptoms of ASCs (5-Dimensional Altered States of Consciousness Rating Scale, 5D-ASC [15]).
Pre-session questionnaires included the VAS (scored from “0 – no fear and discomfort” to “100 – complete fear and discomfort”) [24] and the PANAS-X, which measured affect using 60 items rated on a 5-point Likert scale from “1 – very slightly or not at all” to “5 – extremely” [25].
Post-session questionnaires included the VAS and PANAS-X again, as well as the 5D-ASC, which retrospectively assessed ASCs using 94 items rated via VAS [17]. Questions and responses were grouped into 3 broad subscales: oceanic boundlessness (OBN) as previously mentioned, visionary restructuralisation (VRS) to examine the effect of the HVB on vision, and Dread of Ego Dissolution (DED) which captures the anxiety-inducing effects of the experience related to the idea of the dissolution of the self [15]. The PSL, a 13-item tool used to evaluate panic symptomatology, required participants to rate each item on a five-point scale from “0 – not at all” to “4 – extremely severe”.
The PSL and VAS for fear/discomfort were scored based on [24]: a significant panic attack was indicated by an increase in VAS fear by 50 points and 4 or more items rated above mild in the PSL (mild = 2).


Online experimental session 1 (REMOTE)
The session was conducted remotely via an online video-conferencing platform (Zoom). Preparatory information was sent to participants after screening and enrolment, including the platform link, instructions, and pre- and post-session questionnaires.
Participants received instructions on camera setup and were assigned personal participant numbers. They were instructed to be in a private room to avoid interruptions and to position their cameras to capture their chest and stomach for observation of full-body, continuous breaths. A breathwork facilitator remotely guided groups of participants through the 30-minute online breathwork session. Members of the research team were present online to ensure session consistency and to monitor participant engagement in HVB practice. No group experience-sharing (integration) followed the breathwork sessions to avoid memory and experience merging. Instead, participants self-integrated (processed) their session by completing retrospective questionnaires that explored the qualia of the experience within 30 minutes of concluding the session.


Neuroimaging experimental session 2 (MRI)
Each participant in the neuroimaging session was scanned on a Siemens Prisma 3T magnetic resonance imaging (MRI) scanner fitted with a 32-channel head coil. High-resolution structural scans were obtained during rest using a 3D T1-weighted magnetization-prepared rapid acquisition gradient echo (T1 MPRAGE) sequence (repetition time (TR) = 2300 ms, echo time (TE) = 2.19 ms, flip angle = 9°, matrix = 256 × 256, voxel size = 1.0 × 1.0 × 1.0 mm3, GRAPPA acceleration factor = 2; total acquisition time (TA) = 5m 30s). Additionally, twenty control and label images were acquired per condition using a pCASL with background suppression following the parameter recommendation of the consensus paper [26]: label duration = 2000ms, post-labelling delay (PLD) = 1800ms, TR = 5000 ms, TE = 14 ms, voxel size = 3.4 × 3.4 × 6.0 mm3, TA = 3m 22s), was acquired. A proton density (M0) image was acquired using the same readout and TR as the control and label images to estimate pcASL CBF.
Fig 1 is a schematic presentation of the MRI experimental design. Recorded instructions (see S1 Appendix) guided participants to breathe through three phases: BASELINE, START, and SUSTAINED HVB. BASELINE consisted of breathing at a normal rate for 20 minutes. Participants were asked to gradually increase their ventilation rate and/or depth via recorded instructions (START HVB) for approximately 6 minutes. The SUSTAINED HVB phase started after at least 5 minutes of START HVB and once end-tidal CO2 (EtCO2), measured via nasal cannula connected to a capnograph (MICROCAP®, Oridion Medical LTD), was stable at levels ≤20 mmHg (from a typical value of 35–40 mmHg), and was maintained for a further ~20-minutes.
Fig 1.  MRI experimental design. pcASL = pseudo-continuous arterial spin labelling, displayed in bold as the primary imaging focus.MPRAGE = 3D magnetization-prepared rapid gradient-echo, ASE = asymmetric spin-echo spiral, BOLD = blood oxygen level dependent, AP/PA anterior-posterior, posterior-anterior. BASELINE = 25 min 32s, breathwork = 23 min 10s. Relaxing music was played at BASELINE during rest for the participant, and evocative up-tempo music that features in breathwork sessions with instructions recorded by a breathwork facilitator were played during HVB.

              https://doi.org/10.1371/journal.pone.0329411.g001Scans were performed during BASELINE (10 minutes after the scan start), at the start of HVB (immediately after initiating HVB), and during SUSTAINED HVB (after at least 6 minutes of uninterrupted breathwork).
SPM12 [27] and custom written Matlab (The MathWorks Inc., Natick, Massachusetts) scripts were used for image processing and statistics. Rigid-body motion correction was used to realign labelled and control images, and perfusion weighted images were calculated for the realigned control-labelled pairs by subtracting the labelled image from the control. The mean perfusion weighted images were then used to estimate CBF using the one-compartment model [26] and processed to obtain partial volume-corrected [28], tissue-specific (i.e., grey matter (GM) and white matter (WM)) CBF images independently. The pcASL CBF images were normalized maps in MNI space using SPM12 [27]. Participants with prominent arterial transit artifacts in the CBF images, evident by the presence of strong arterial signals upon visual inspection, were excluded from the study.


Psychophysiological session 3 (LAB)
Participants in the psychophysiology study attended the psychophysiology lab at the Trafford Centre for Medical Research at BSMS. To measure beat-to-beat heart rate (HR) and HRV (computed as the root mean square of successive differences, RMSSD) [29], an electrocardiograph (Firstbeat Bodyguard 2 device) was applied to the torso [28]. To measure EtCO2, the participant was fitted with a nasal cannula connected to a capnograph (MICROCAP®, Oridion Medical LTD). Following a BASELINE period during which the participant was instructed to breathe as normal to relaxing music for 10 minutes, the participant was instructed to perform HVB (see supplementary index for more information). This began as a 5-minute warm-up (START HVB) where the participant performed HVB to lower their EtCO2 to ≤20 mmHg, followed by 25-minutes of HVB (SUSTAINED HVB) where EtCO2 was maintained ≤20 mmHg, aided by recorded instructions from a trained breathwork facilitator. For analyses, the HVB period was defined as starting once EtCO2 was stable below 20 mmHg and was subsequently recorded for 20 minutes. The recovery period began immediately after HVB was terminated, and participants resumed their normal breathing. Participants completed retrospective questionnaires within 30 minutes of the session’s conclusion.

Data analysis and statistics.Objective 1: To characterize the subjective response to HVB across different settings (REMOTE, LAB, MRI), we compared affective responses (PANAS-X scores clustered into positive and negative domains), panic-like symptoms (VAS fear/discomfort and PSL) and ASCs. For the 5D-ASC, the percentage maximum score was calculated per participant and dimension [30]. Data were compared across the three experiments to test for differences in self-reported effects. A linear mixed-effects model (LMM) was used to examine the effects of setting on the mean responses within each dimension of the 5D-ASC and for the PSL, accounting for subject-specific variability as a random effect using the lmer package in R; [31]. We used the likelihood ratio test to compare a full model with a fixed effect of setting and a random effect of subject to a reduced model with only a random effect of subject [31]. Post-hoc tests were performed using the emmeans package in R [32], adjusted for multiple comparisons using the Tukey method.
For the PANAS-X and VAS, we used an LMM analysis to examine the effects of HVB (pre- versus post-) on setting and the type of question (positive versus negative affect for PANAS; discomfort versus fear for VAS), accounting for subject-specific variability as a random effect. We explored two-way interactions between all the variables and post-hoc tests using the same methods as the previous analyses [32].
Objective 2: In order to test the correlations between HVB-induced ASCs and rCBF effects, two contrasts between HVB time points (see MRI experimental design in Fig 1) were studied using paired-samples t-tests in SPM12 [27]: contrast 1) between BASELINE and START HVB grey matter CBF; contrast 2) between BASELINE and SUSTAINED HVB grey matter CBF. Following this, voxel-wise maps of changes in pcASL rCBF (ΔrCBF) were calculated for the contrasts between BASELINE versus SUSTAINED HVB, and START versus SUSTAINED HVB. These ΔrCBF maps were then used for voxelwise correlation analysis with the OBN score, selected as the highest-rated 5D-ASC dimension. Voxel clusters were considered significant at a cluster-forming threshold of p < 0.001, corrected for multiple comparisons using family-wise error (FWE) correction, with a significance level of p < 0.05.
Objective 3: To investigate changes in cardiac autonomic drive during HVB and their relationship to the intensity of ASCs, we calculated change in HRV (ΔRMSSD) and HR. Heartbeat timing data were imported from the Firstbeat Bodyguard device into Kubios 3.5.0 HRV scientific 4.1.0 for processing. Raw data contained substantial noise from chest movement. After an initial phase of artefact removal, interbeat interval (IBI) data were smoothed using an automatic noise detection filter at a medium threshold [33]. A repeated measures ANCOVA with contrasts for different orders of an equation was conducted using HRV and OBN (5D-ASC selected from objective 1) as covariates to explain HRV variance over time, with polynomial contrast applied to identify linear and complex patterns, allowing us to characterise dynamic trends in HRV responses to HVB.




ResultsSelf-reported data from 42 participants were analysed, comprising 31 unique individuals. Study participants enrolled in one to three experimental sessions: n = 15 (age 42.9 ± 12.6 years, 5 females) for the online experimental session; n = 8 (age 41 ± 13.02 years, 2 females) for the session conducted within the psychophysiology lab; and n = 19 (age 43.7 ± 11.9; 7 females) for the MRI experimental session. There were different participants in each condition (3 repeated all conditions, 5 participants participated in 2 conditions, see S1 Fig for key subjective effects of repeated participants). No adverse events, including panic attacks, were reported across all experimental settings.

Subjective effect results
Generally, measures of fear and discomfort were low in all conditions (Fig 2, panel C). LMM analyses identified only a significant two-way interaction between HVB and question type (fear and discomfort), with post-hoc tests showing a significant increase in discomfort post-HVB. These results indicate that perceived discomfort increased during HVB, while perceived fear remained stable across settings.
Fig 2.  Analysis of subjective effects. A) Averages of the % maximum scores of the 5 dimensions of the 5D-ASC for each of the 3 settings. OBN = oceanic boundlessness; DED = dread of ego dissolution; VRS = visionary restructuralisation; AUA = auditory alterations; VIR = vigilance reduction.B) For the 5D-ASC, a linear mixed-effect model did not show an effect of setting (χ2(2) = 3.66, p = 0.160; see ‘Data analysis and statistics’). C) Fear and discomfort assessed by VAS indicated no significant effect of experimental setting on HVB, although there was a trend increase in discomfort and reduction in fear after HVB across all environments. D) Negative affect assessed by PANAS-X was reduced by HVB. There was no significant effect of HVB on positive affect, and no significant effect of environment on negative or positive affect. E) For the PSL, a linear mixed-effect model revealed a significant main effect of setting (χ2(2) = 20.41, p < 0.001; see ‘Data analysis and statistics’). Post-hoc Tukey tests identified significant differences between LAB vs. MRI and MRI vs. REMOTE (LAB – MRI, t(22.11) = −3.78, p = 0.003; LAB – REMOTE, t(28.84) = 0.041, p = 0.999; MRI – REMOTE, t(34.09) = −4.37, p < 0.001).

              https://doi.org/10.1371/journal.pone.0329411.g002None of the mean individual post-HVB PSL scores were ≥ 2, indicating that no panic symptoms reached a clinically significant threshold (a score of 2 corresponded to ‘moderate’). However, the LMM identified a significant main effect of setting on the PSL, with post-hoc analyses showing the PSL scores were significantly higher in the MRI setting compared to the LAB and REMOTE settings (Fig 2, panel E). LMM analyses on the PANAS-X found only a significant two-way interaction between pre/post-HVB and affect, with post-hoc analyses revealing a significant decrease in negative affect from pre- to post-HVB (Fig 2, panel D). These results indicate that HVB decreased negative affect, while positive affect remained stable across settings.
In all three settings, HVB elicited altered subjective experiences indicated by positive scores in all dimensions of the 5D-ASC (Fig 2, panels A and B). The highest rated phenomenon was OBN across all three settings, which was selected as a meaningful proxy indicator of the subjective effects of HVB for analysis. A LMM revealed no significant main effect of setting and no significant interaction effect between setting and dimension (Fig 2, panel B).


MRI results
Datasets from 13 participants (mean age 43.7 ± 11.9; 7 female) were included in the analysis. Voxel clusters showing statistically significant CBF reductions occupied 12% and 28.5% of global grey matter volume at START and SUSTAINED HVB, respectively. Global CBF was reduced by 30.5% during START (36.2 ± 12.4 ml/100g/min) and 41.6% during SUSTAINED HVB (30.5 ± 8.5 ml/100g/min) relative to BASELINE (52.2 ± 8.2 ml/100g/min).
We first identified a region of cortex where HVB-evoked reduction in perfusion (ΔrCBF from BASELINE to SUSTAINED) correlated with the magnitude of ASC in the OBN dimension. This cluster encompassed left parietal operculum/posterior insula (PO/INS) (Fig 3). Here, rCBF in PO/INS was reduced by 7.7% during the START period of HVB (43.7 ± 10 ml/100g/min) and 18.9% during SUSTAINED HVB (38.4 ± 12.7 ml/100g/min) relative to BASELINE (52.2 ± 8.2 ml/100g/min).
Fig 3.  Negative correlation between CBF and intensity of subjective experience (OBN) during BASELINE HVB (p = 0.0475) and SUSTAINED HVB in the left posterior insula/parietal operculum.Data points represent cluster means. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p < 0.001; corrected FWE: p < 0.05).

              https://doi.org/10.1371/journal.pone.0329411.g003Next, we identified regions of significant positive correlation between OBN score and ΔCBF changes from START to SUSTAINED (Fig 4). The cluster encompassed right basolateral amygdala and extended to the CA1 region of anterior hippocampus (BLA/CA1) rCBF. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p < 0.001; corrected FWE: p < 0.05).
Fig 4.  Positive correlation between the intensity of subjective experience (OBN) and ΔCBF in the right basolateral nuclei of the amygdala that extends to CA1 areas of the hippocampus during SUSTAINED HVB, relative to START.Data points represent cluster means. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p < 0.001; corrected FWE: p < 0.05).

              https://doi.org/10.1371/journal.pone.0329411.g004We then investigated if specific concepts related to OBN, namely, disembodiment, experience of unity and blissful state [17], were associated with ΔCBF in PO/INS from BASELINE to SUSTAINED. Analyses identified negative correlations between ΔCBF and the experience of unity (Fig 5A) and blissful state (Fig 5B), but not disembodiment, indicating that the magnitude of subjective experience related to bliss and unity correlated with a reduction in perfusion in this region.
Fig 5.  A. Negative correlation between the intensity of subjective experience (experience of unity) and CBF in PO/INS during SUSTAINED HVB, relative to BASELINE, and B.Negative correlation between the intensity of subjective experience (blissful state) and CBF in PO/INS during SUSTAINED HVB, relative to BASELINE. Data points represent cluster means. Statistical significance was assessed using cluster size inference (initial cluster-forming threshold: p < 0.001; corrected FWE: p < 0.05).

              https://doi.org/10.1371/journal.pone.0329411.g005

HRV results
A repeated-measures ANCOVA demonstrated an effect of time on RMSSD through BASELINE and phases of HVB and recovery, indicating a significant within-participant cubic effect. There was a significant interaction effect between OBN and the polynomial cubic contrast, F(1, 6) = 6.211, p < 0.05 (Fig 6).
Fig 6.  The exploratory mean change from BASELINE in RMSSD (ms) and HR (bpm) across participants during the breathwork protocol after the first BASELINE period (of 5 minutes) in individuals with high (n = 3) and low (n = 5) oceanic boundlessness (OBN) scores. BL = baseline, HVB = high ventilation breathwork, R = recovery. Each period = 5 minutes.
              https://doi.org/10.1371/journal.pone.0329411.g006Participants were classified into high and low OBN responders using a cutoff score of 50 (50% of the maximum score) to identify ASC experience based on criteria in psychedelic drug literature, e.g., [34].



DiscussionOur study is the first that aims to characterise the relationship between the intensity of ASCs induced by HVB practices and associated central and autonomic nervous system effects, via changes in pcASL rCBF and HRV, respectively. Our findings identified significant correlations that might indicate possible neurobiological substrates of HVB-evoked ASCs, accompanied by music. First, our findings demonstrated that the experience of HVB can be safely reproduced across different experimental settings. The pattern of self-reported experiences elicited within the MRI scanner and psychophysiology lab were analogous to those experienced at home (a more natural and comfortable environment).
During all experimental sessions, participants reported a trend-level reduction in ratings of fear and negative emotions. Additionally, no adverse reactions or panic attacks were experienced by any participants. However, there was a mild increase in discomfort ratings and mild panic-like symptoms were reported during the MRI session – although these were not associated to increased anxiety or panic attacks and might have been evoked by the physical constraints of being inside the MRI chamber. This experience conflicts typical breathwork practice. The observed increase in physical discomfort alongside reductions in fear and negative affect may reflect a hormetic effect, whereby transient physiological or emotional stressors promote longer-term psychological resilience [35,36].
Across participants and experimental settings, HVB reliably enhanced ASCs dominated by OBN, which is considered as a defining aspect of ASCs evoked by psychedelic substances, such as psilocybin. Although differences in OBN scores across conditions were not statistically significant, participants in the LAB condition reported noticeably higher scores compared to MRI and REMOTE sessions. This trend suggests that the in-person experience and controlled, quiet environment of the LAB may have enhanced the immersive and evocative qualities of the breathwork experience. In contrast, the MRI setting—despite also involving in-person contact —may have been less conducive due to scanner noise and physical constraints. Finally, the REMOTE condition, which involved no in-person interaction and took place in participants varied home environments, received the lowest OBN ratings. These findings point to the importance of ‘set and setting’, e.g., [37], a concept well-established in psychedelic research in shaping ASCs and subjective response. These results may indicate that physical context and interpersonal presence play a critical role in breathwork outcomes.
Interestingly, OBN is reportedly the most accurate predictor of antidepressant actions of psychedelic substances [9,38–40]. In the present study, the magnitude of the OBN experience induced by HVB was comparable to that elicited by serotonergic psychedelic substances, including psilocybin and lysergic acid diethylamide (LSD) [41,42], reinforcing observations of other breathwork studies [1,2].
Fast-paced hyperventilation induces cardiovascular sympathetic activation (with relative cardiovagal parasympathetic withdrawal) and cerebral vasoconstriction, the latter is a consequence of respiratory alkalosis, resulting from reduced plasma CO2 and H+, which elevates blood pH [43]. Ergo, we focused our analysis on correlations between OBN and changes in HRV (for which decreases capture pro-sympathetic shifts in cardiac autonomic balance) and CBF (where regional reductions reflect cerebrovascular vasoconstriction). Importantly, decreased EtCO2 is implicated as a critical factor in catalysing stronger, deeper ASCs during breathwork and may predict subacute psychological and physiological outcomes [2,44].
Our experiments identified that HVB engendered substantive time-dependent decreases in pcASL CBF. The reduction of rCBF relative to BASELINE in a cluster localized within left posterior insula and left parietal operculum predicted the intensity of OBN. This region encompasses primary interoceptive cortex and represents the state of cardiorespiratory arousal, and is consequently engaged in higher-order respiratory control. Correspondingly, neural activity here is enhanced by chemo-stimulated increases in ventilation [45]. More broadly, this insular-parietal region supports the integration of somatosensory information as well as the cortical representation of afferent respiratory and bodily signals [46], for example in the emergence of conscious motor intentions [47]. It is also implicated in high-level integrative processes which merge external and internal stimuli [48,49] that contribute to a coherent, embodied representation of self [50].
These roles are relevant to the interpretations of our finding that rCBF reductions within the PO/INS during SUSTAINED HVB predicted the intensity of self-reported OBN experience. The construct of OBN is closely related to feelings of depersonalization, sense of unity and blissful state [16], and our findings align with the notion that abnormal integration of signals in the posterior insula cortex can result in abnormal body ownership. Studies on ecstatic epilepsy, a rare focal epilepsy, show that the insula is involved in ASC-like experiences, including “heightened self-awareness, mental clarity and unity with everything that exists, accompanied by a sense of bliss and physical well-being” [51]. These overlap with the OBN construct, as assessed in the 5D-ASC [15]. Picard and Craig [52] hypothesised the involvement of the insula in the genesis of ecstatic epilepsy given its role in interoception and self-consciousness, confirmed by intracerebral electrode recordings [53]. Seizures in the mesiotemporal region propagated to the dorsal anterior insula coincide with ecstatic symptoms [54] and stimulation of the mid-dorsal insula region evoked experiences akin to oceanic psychedelic effects [55]. The interruption of interoceptive predictive coding during anterior insula seizures may underlie the ecstatic experience, emphasizing its pivotal role in mystical and psychedelic states [51,52].
We then ran an exploratory subsequent analysis (Fig 5) to explore the correlations between sub-dimensions of the 11D-ASC relevant to OBN [17], namely ‘disembodiment’, ‘unity’ and ‘bliss’, and CBF reductions induced by HVB relative to BASELINE. We found that scores of ‘unity’ and ‘bliss’, but not ‘disembodiment’ were associated with CBF reductions (see S1-S3 Tables for details), which concurs with the notion discussed above, specifically pointing to an involvement of the insula in the genesis of blissful feelings. Of note, 5-HT2A– targeting compounds such as psilocybin, renowned for therapeutic utility, are known to induce CBF decreases in different brain regions that correlate with the intensity of psychedelic experiences [56]. Studies found reduced CBF in the insula following psilocybin administration, though it was not linked to the subjective effects assessed via the 5D-ASC [57].
CBF reductions occur rapidly following decreased EtCO2 and can be reliably detected in response to very brief periods of hyperventilation. Conversely, the profound experiential changes in emotion and thought processes tend to emerge gradually, and correspondingly psychedelic phenomenology appears contingent on the length of the breathwork session [58]. Our investigation therefore compared HVB-evoked effects during late (SUSTAINED) and early (START) phases of HVB to focus specifically on the haemodynamic changes that occurred once the subjective effects had emerged. By contrasting the START and SUSTAINED phases of hyperventilation, we identified a region of right amygdala/anterior hippocampus, where the intensity of subjective experience (OBN as a covariate) positively correlated with CBF changes. Here, increased rCBF predicted the most intense OBN experience, despite the global reduction in CBF. One possible explanation is that this amygdalo-hippocampal CBF increase reflected increased regional neural activation associated with emergent expression of intense subjective effects. These regions are well established as being specialized for emotion (amygdala) and memory (hippocampus) processing. Their reciprocal interactions enable the formation of episodic representations, integrating the emotional significance and interpretation of memories [59]. Interestingly, increased right amygdala blood-oxygen level-dependent responses to emotional faces in functional MRI (fMRI) have been identified in patients with treatment-resistant depression following administration of psilocybin, predictive of clinical improvements at 1 week. The authors posit that this indicates psilocybin aids individuals’ ability to confront, reappraise, and improve emotional responsiveness [60]. Though speculative, these findings may indicate that HVB facilitates the processing of emotionally salient memories, which is proposed to be an essential therapeutic element in psychedelic-assisted psychotherapies [61,62], consistent with promising results from clinical trials of HVB applied as a therapy for patients with post-traumatic stress disorder (PTSD) [63]. Our finding of increased CBF in the hippocampal region also indicates that a single session of intense hyperventilation selectively alters perfusion to the hippocampus, similar to the effects observed after 20 minutes of hypocapnia-inducing moderate exercise [64]. This finding was interpreted as indicative of short-term metabolic adaptation to the high energy demands of hippocampal neurons, rather than reflecting the effects of mechanical vascular changes [64].
HRV is a physiological index of the balance of sympathetic and parasympathetic influences on the heart. The observed reduction in HRV reflects sympathetic activation and withdrawal of parasympathetic drive [65–67], consistent with an action-ready state of psychophysiological engagement. As previously described, OBN characteristically entails a deeply felt positive mood linked to the experience of unity with the self and the world, and in its extreme, is experienced as a mystical or religious experience [17]. Our finding that OBN ratings were related to changes in HRV over time echoes observations from other relevant modalities of ASC induction, such as self-induced cognitive trance [68] or 5-HT agonists, such as LSD [18,69–71] or N,N-Dimethyltryptamine (DMT) [72,73]. Nevertheless, the observed association with a positive mood contrasts the wide acceptance of reduced HRV as an index of stress and negative affective states. During HVB, the physiological state of the body exceeds typical homeostatic boundaries, and the autonomic correlates of this may reinforce a dissociative psychological state of positive affect in line with the premise of hormesis, see [11] for more.
This exploratory work is preliminary and limited by a small sample size and a lack of an independent control condition that may, in our neuroimaging session, have prevented us from separating the contributions of haemodynamic effects secondary to CO2 changes from neural activation. We also acknowledge the possibility that our whole brain voxelwise approach has led to reduced sensitivity to detect significant correlations relative to an a priori region of interest (ROI) approach. In addition, from a methodological perspective, it may be argued that the lack of control group exposed only to music may prevent dissociation of the effects of auditory stimuli (the ambient track) and the effects of HVB. Listening to upbeat music does stimulate ventilation and this should be controlled in the future. Helpful input from lived experience populations indicates that music is a powerful support to therapeutic applications of HVB. In choosing our design, we elected not to “dissect” the music component from HVB, as we preferred to consider HVB as a contemplative practice accompanied by music as a whole – and to test it in its entirety [74]. Importantly, both studies [2,75] have dissected the effect of music and breathwork, and elucidate that music is not the main factor in triggering ASCs. This reveals that music alone is unlikely to engender significant ASCs of the magnitude reported in this research. It is also argued that the reductionist approach of breaking down a contemplative practice to dissect an “active ingredient” is less preferable than testing a practice in its entirety [74]. Conjointly, psychedelic therapy sessions do not adhere to one specific psychotherapeutic model, though one consistent feature of the experience is listening to music. During psychedelic therapy sessions, patients are urged to centre their attention inwardly whilst supine and listening to a carefully selected playlist. It is suggested that music can help facilitate therapeutic experiences. As such, we are looking for CBF changes that correspond with ASCs, induced by HVB with music. We elected to proceed to treat the experience as whole, hence no control for music. More hypothesis-driven work is certainly required within the neuroscience of breathwork.
Furthermore, our study focused on experienced HVB practitioners and therefore our results may not be generalisable; though this is also a strength as it ensured our practitioners were able to reach the desired state without adverse outcomes. Additionally, we were unable to directly assess relevant mechanisms of therapeutic actions, as our subjective measures did not include clinical parameters relevant to traumatic memories or other forms of psychological distress. Moreover, ASCs initiated by breathwork are inherently dynamic, thus dynamic phenomenological tools, such as those employed by Lewis-Healey et al., [58] may be more sensitive and informative.
Our imaging approach was also limited by the absence of correction for physiological noise caused by cardiac and respiratory fluctuations. This is crucial for most physiological fMRI applications for reducing signal artifacts. However, physiological fluctuations (including respiratory frequency and volume changes) can still introduce signal variations in ASL data, but we believe that our approach remains robust. Our analysis inherently averages over multiple cardiac cycles, which helps mitigate the effects of physiological noise on CBF quantification, and although respiration-induced signal changes are observed in some pcASL studies, they are largely associated with motion rather than direct vascular effects [76]. This does not fully eliminate the influence of an overall increase in HR, respiratory rate, or other physiological parameters during changes in breathing conditions—factors that may also impact labelling efficiency and arterial transit times. These considerations are relevant not only to our study, but to other ASL studies where complex, interconnected factors can influence ASL signal and CBF. Practical constraints limit the extent to which additional physiological measurements can be incorporated, particularly in a study as complex as ours. These constraints include scanning time and the potential stress on participants. Furthermore, measuring CBF at the start of the SUSTAINED HVB rather than at the end or during is not ideal, yet, it may capture the physiological ‘trigger condition’ for entry into ASCs, which can continue irrespective of specific physiological threshold conditions, see [2] for more.
A further key reason for choosing not to adopt a method of correction for EtCO2 was a high risk of regressing out our primary signal of interest. One plausible mechanistic hypothesis inspiring our work is that ASCs evoked by HVB practices directly result from alterations in EtCO2 and the resulting cerebral pH, causing downstream effects on neuronal function [11]. Therefore, CO2 related physiological signals are likely correlated with experimental effects that were the focus of our investigation, in line with recent work by others [2] and regressing out these signals would severely impact our sensitivity to study the relationship between haemodynamic effects and ASCs. An additional reason is that our measures of EtCO2 (collected by nasal cannula and capnograph) have been occasionally incomplete during the end of HVB sessions when EtCO2 levels had reached particularly low levels, and we felt that application of correction methods using incomplete physiological data would have risked introducing major artifacts.
Additionally, we observed prominent arterial transit time (ATT) artifacts in 6 out of 19 participants. These artifacts were characterized by strong arterial signals in the CBF images, which led to their exclusion from the analysis. ATT artifacts can significantly impact the accuracy of perfusion measurements, as they indicate that labelled blood has not yet reached the capillary beds. To address this issue in future research, capturing blood flow dynamics at different delay times through a multi-PLD ASL protocol would reduce the impact of ATT artifacts and increase precision of assessment of cerebral perfusion.


ConclusionIn conclusion, our exploratory experiments suggest that circuitries supporting the integration of interoceptive representations and processing of affective memories are putative neurobiological substrates of HVB-induced ASCs. Our findings indicate directions for future research towards a better understanding of HVB and ultimately harnessing such practices for future therapeutic applications.








Acknowledgments
The authors wish to acknowledge Dr Guy Fincham, Dr Matthew Wall, and Dr Natalie Ertl for their helpful contribution, and all the participants for their expert insights into breathwork.
References1.
            Bahi C, Irrmischer M, Franken K, Fejer G, Schlenker A, Deijen JB, et al. Effects of conscious connected breathing on cortical brain activity, mood and state of consciousness in healthy adults. Curr Psychol. 2023;43(12):10578–89. 
                      View Article
                    
                      Google Scholar
                    2.
            Havenith MN, Leidenberger M, Brasanac J, Corvacho M, Carmo Figueiredo I, Schwarz L, et al. Decreased CO2 saturation during circular breathwork supports emergence of altered states of consciousness. Commun Psychol. 2025;3(1):59.  pmid:40223145 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    3.
            Eyerman J. A clinical report of Holotropic Breathwork in 11,000 psychiatric inpatients in a community hospital setting. Multidiscip Assoc Psychedelic Stud Bulletin Special Ed. 2013;23(1):24–7. 
                      View Article
                    
                      Google Scholar
                    4.
            Carhart-Harris R, Giribaldi B, Watts R, Baker-Jones M, Murphy-Beiner A, Murphy R. Trial of psilocybin versus escitalopram for depression. New England J Med. 2021;384(15):1402–11. 
                      View Article
                    
                      Google Scholar
                    5.
            Zeifman RJ, Palhano-Fontes F, Hallak J, Arcoverde E, Maia-Oliveira JP, Araujo DB. The impact of ayahuasca on suicidality: results from a randomized controlled trial. Front Pharmacol. 2019;10. 
                      View Article
                    
                      Google Scholar
                    6.
            Meinhardt MW, Pfarr S, Fouquet G, Rohleder C, Meinhardt ML, Barroso-Flores J, et al. Psilocybin targets a common molecular mechanism for cognitive impairment and increased craving in alcoholism. Sci Adv. 2021;7(47):eabh2399.  pmid:34788104 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    7.
            Almahayni O, Hammond L. Does the Wim Hof Method have a beneficial impact on physiological and psychological outcomes in healthy and non-healthy participants? A systematic review. PLoS One. 2024;19(3):e0286933.  pmid:38478473 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    8.
            Yaden DB, Griffiths RR. The subjective effects of psychedelics are necessary for their enduring therapeutic effects. ACS Pharmacol Transl Sci. 2020;4(2):568–72.  pmid:33861219 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    9.
            Roseman L, Nutt DJ, Carhart-Harris RL. Quality of acute psychedelic experience predicts therapeutic efficacy of psilocybin for treatment-resistant depression. Front Pharmacol. 2018;8:974.  pmid:29387009 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    10.
            Ko K, Knight G, Rucker JJ, Cleare AJ. Psychedelics, mystical experience, and therapeutic efficacy: a systematic review. Front Psych. 2022;13. 
                      View Article
                    
                      Google Scholar
                    11.
            Fincham GW, Kartar A, Uthaug MV, Anderson B, Hall L, Nagai Y, et al. High ventilation breathwork practices: an overview of their effects, mechanisms, and considerations for clinical applications. Neurosci Biobehav Rev. 2023;155:105453.  pmid:37923236 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    12.
            Fincham GW, Epel E, Colasanti A, Strauss C, Cavanagh K. Effects of brief remote high ventilation breathwork with retention on mental health and wellbeing: a randomised placebo-controlled trial. 2024. 13.
            Franco Corso SJ, O’Malley KY, Subaiya S, Mayall D, Dakwar E. The role of non-ordinary states of consciousness occasioned by mind-body practices in mental health illness. J Affect Disord. 2023;335:166–76.  pmid:37150220 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    14.
            Bayley PJ, Schulz-Heik RJ, Tang JS, Mathersul DC, Avery T, Wong M. Randomised clinical non-inferiority trial of breathing-based meditation and cognitive processing therapy for symptoms of post-traumatic stress disorder in military veterans. BMJ Open. 2022;12(8). 
                      View Article
                    
                      Google Scholar
                    15.
            Dittrich A. The standardized psychometric assessment of altered states of consciousness (ASCs) in humans. Pharmacopsychiatry. 1998;31 Suppl 2:80–4.  pmid:9754838 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    16.
            Freud S. Civilization and its discontents. Dover ed. New York: Dover Publications; 1994. 17.
             Studerus E, Gamma A, Vollenweider FX. Psychometric evaluation of the altered states of consciousness rating scale (OAV). PLoS One. 2010;5(8):e12412.  pmid:20824211 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    18.
            Olbrich S, Preller KH, Vollenweider FX. LSD and ketanserin and their impact on the human autonomic nervous system. Psychophysiology. 2021;58(6):e13822.  pmid:33772794 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    19.
            Rosas FE, Mediano PAM, Timmermann C, Luppi AI, Candia-Rivera D, Abbasi-Asl R. The entropic heart: tracking the psychedelic state via heart rate dynamics. 2023. 20.
            American Psychiatric A. Diagnostic and statistical manual of mental disorders. 2013. 21.
            Qualtrics. Qualtrics. https://www.qualtrics.com. 22.
            Watson D, Clark LA. The PANAS-X: Manual for the Positive and Negative Affect Schedule - Expanded Form. 1994; Available from: https://iro.uiowa.edu/esploro/outputs/other/The-PANAS-X-Manual-for-the-Positive/9983557488402771#file-0. 23.
            Schruers K, Klaassen T, Pols H, Overbeek T, Deutz NE, Griez E. Effects of tryptophan depletion on carbon dioxide provoked panic in panic disorder patients. Psychiatry Res. 2000;93(3):179–87.  pmid:10760376 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    24.
            Griez EJ, Colasanti A, van Diest R, Salamon E, Schruers K. Carbon dioxide inhalation induces dose-dependent and age-related negative affectivity. PLoS ONE. 2007;2(10). 
                      View Article
                    
                      Google Scholar
                    25.
            Watson D, Clark LA, Tellegen A. Development and validation of brief measures of positive and negative affect: the PANAS scales. J Pers Soc Psychol. 1988;54(6):1063–70.  pmid:3397865 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    26.
            Alsop DC, Detre JA, Golay X, Günther M, Hendrikse J, Hernandez‐Garcia L, et al. Recommended implementation of arterial spin‐labeled perfusion MRI for clinical applications: a consensus of the ISMRM perfusion study group and the European consortium for ASL in dementia. Magnetic Resonan Med. 2014;73(1):102–16. 
                      View Article
                    
                      Google Scholar
                    27.
            Friston K, Ashburner J, Kiebel S, Nichols T, Penny W. Statistical parametric mapping. 2007. 28.
            Parak J, Tarniceriu A, Renevey P, Bertschi M, Delgado-Gonzalo R, Korhonen I. Evaluation of the beat-to-beat detection accuracy of PulseOn wearable optical heart rate monitor. Annu Int Conf IEEE Eng Med Biol Soc. 2015;2015:8099–102.  pmid:26738173 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    29.
            Shaffer F, Ginsberg JP. An overview of heart rate variability metrics and norms. Front Public Health. 2017;5. 
                      View Article
                    
                      Google Scholar
                    30.
            Carhart-Harris RL, Williams TM, Sessa B, Tyacke RJ, Rich AS, Feilding A, et al. The administration of psilocybin to healthy, hallucinogen-experienced volunteers in a mock-functional magnetic resonance imaging environment: a preliminary investigation of tolerability. J Psychopharmacol. 2011;25(11):1562–7.  pmid:20395317 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    31.
            Bates D, Mächler M, Bolker B, Walker S. Fitting linear mixed-effects models using lme4. Journal of Statistical Software. 2015;67(1):1–48. 
                      View Article
                    
                      Google Scholar
                    32.
            Lenth R. Estimated marginal means, aka least-squares means. 2025. 33.
            Tarvainen MP, Niskanen J-P, Lipponen JA, Ranta-Aho PO, Karjalainen PA. Kubios HRV--heart rate variability analysis software. Comput Methods Programs Biomed. 2014;113(1):210–20.  pmid:24054542 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    34.
            Studerus E. Tolerability, assessment, and prediction of psilocybin-induced altered states of consciousness. University of Zurich; 2012. 35.
            Mattson MP. Hormesis defined. Ageing Res Rev. 2008;7(1):1–7.  pmid:18162444 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    36.
            Pruimboom L, Muskiet FAJ. Intermittent living; the use of ancient challenges as a vaccine against the deleterious effects of modern life - a hypothesis. Med Hypotheses. 2018;120:28–42.  pmid:30220336 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    37.
            Hartogsohn I. Set and setting, psychedelics and the placebo response: an extra-pharmacological perspective on psychopharmacology. J Psychopharmacol. 2016;30(12):1259–67.  pmid:27852960 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    38.
            Roseman L, Nutt DJ, Carhart-Harris RL. Quality of acute psychedelic experience predicts therapeutic efficacy of psilocybin for treatment-resistant depression. Front Pharmacol. 2018;8. 
                      View Article
                    
                      Google Scholar
                    39.
            Timmermann C, Zeifman RJ, Erritzoe D, Nutt DJ, Carhart-Harris RL. Effects of DMT on mental health outcomes in healthy volunteers. Sci Rep. 2024;14(1):3097.  pmid:38326357 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    40.
            Uthaug MV, Lancelotta R, van Oorsouw K, Kuypers KPC, Mason N, Rak J. A single inhalation of vapor from dried toad secretion containing 5-methoxy-N,N-dimethyltryptamine (5-MeO-DMT) in a naturalistic setting is related to sustained enhancement of satisfaction with life, mindfulness-related capacities, and a decrement of psychopathological symptoms. Psychopharmacology. 2019;236(9):2653–66. 
                      View Article
                    
                      Google Scholar
                    41.
            Smigielski L, Scheidegger M, Kometer M, Vollenweider FX. Psilocybin-assisted mindfulness training modulates self-consciousness and brain default mode network connectivity with lasting effects. Neuroimage. 2019;196:207–15.  pmid:30965131 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    42.
            Holze F, Ley L, Müller F, Becker AM, Straumann I, Vizeli P, et al. Direct comparison of the acute effects of lysergic acid diethylamide and psilocybin in a double-blind placebo-controlled study in healthy subjects. Neuropsychopharmacology. 2022;47(6):1180–7.  pmid:35217796 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    43.
            Raichle ME, Plum F. Hyperventilation and cerebral blood flow. Stroke. 1972;3(5):566–75. 
                      View Article
                    
                      Google Scholar
                    44.
            Tennant R, Hiller L, Fishwick R, Platt S, Joseph S, Weich S, et al. The Warwick-Edinburgh Mental Well-being Scale (WEMWBS): development and UK validation. Health Qual Life Outcomes. 2007;5:63.  pmid:18042300 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    45.
            Kartar AA, Colasanti A. Respiratory control and circuitry. In: Reference module in neuroscience and biobehavioral psychology. Elsevier; 2024. 46.
            Betka S, Adler D, Similowski T, Blanke O. Breathing control, brain, and bodily self-consciousness: toward immersive digiceuticals to alleviate respiratory suffering. Biol Psychol. 2022;171:108329.  pmid:35452780 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    47.
            Sirigu A, Desmurget M. Somatosensory awareness in the parietal operculum. Brain. 2021;144(12):3558–60.  pmid:34791060 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    48.
            Felleman DJ, Van Essen DC. Distributed hierarchical processing in the primate cerebral cortex. Cereb Cortex. 1991;1(1):1–47.  pmid:1822724 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    49.
            Sepulcre J, Sabuncu MR, Yeo TB, Liu H, Johnson KA. Stepwise connectivity of the modal cortex reveals the multimodal organization of the human brain. J Neurosci. 2012;32(31):10649–61.  pmid:22855814 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    50.
            Gentile G, Guterstam A, Brozzoli C, Ehrsson HH. Disintegration of multisensory signals from the real hand reduces default limb self-attribution: an fMRI study. J Neurosci. 2013;33(33):13350–66.  pmid:23946393 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    51.
            Picard F. Ecstatic or mystical experience through epilepsy. J Cogn Neurosci. 2023;35(9):1372–81.  pmid:37432752 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    52.
            Picard F, Craig AD. Ecstatic epileptic seizures: a potential window on the neural basis for human self-awareness. Epilepsy Behav. 2009;16(3):539–46.  pmid:19836310 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    53.
            Craig ADB. How do you feel--now? The anterior insula and human awareness. Nat Rev Neurosci. 2009;10(1):59–70.  pmid:19096369 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    54.
            Picard F, Scavarda D, Bartolomei F. Induction of a sense of bliss by electrical stimulation of the anterior insula. Cortex. 2013;49(10):2935–7.  pmid:24074887 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    55.
            Sheikh MM, Koubeissi MZ, Spencer DD, Alkawadri R. The neural networks underlying the illusion of time dilation. Ann Neurol. 2022;91(2):295–7. 
                      View Article
                    
                      Google Scholar
                    56.
            Carhart-Harris RL, Erritzoe D, Williams T, Stone JM, Reed LJ, Colasanti A, et al. Neural correlates of the psychedelic state as determined by fMRI studies with psilocybin. Proc Natl Acad Sci U S A. 2012;109(6):2138–43.  pmid:22308440 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    57.
            Lewis CR, Preller KH, Kraehenmann R, Michels L, Staempfli P, Vollenweider FX. Two dose investigation of the 5-HT-agonist psilocybin on relative and global cerebral blood flow. Neuroimage. 2017;159:70–8.  pmid:28711736 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    58.
            Lewis-Healey E, Tagliazucchi E, Canales-Johnson A, Bekinschtein TA. Breathwork-induced psychedelic experiences modulate neural dynamics. Cerebral Cortex. 2024;34(8). 
                      View Article
                    
                      Google Scholar
                    59.
            Phelps EA. Human emotion and memory: interactions of the amygdala and hippocampal complex. Curr Opin Neurobiol. 2004;14(2):198–202.  pmid:15082325 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    60.
            Roseman L, Demetriou L, Wall MB, Nutt DJ, Carhart-Harris RL. Increased amygdala responses to emotional faces after psilocybin for treatment-resistant depression. Neuropharmacology. 2018;142:263–9. 
                      View Article
                    
                      Google Scholar
                    61.
            Nutt D, Erritzoe D, Carhart-Harris R. Psychedelic psychiatry’s brave new world. Cell. 2020;181(1):24–8.  pmid:32243793 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    62.
            Healy CJ. The acute effects of classic psychedelics on memory in humans. Psychopharmacology (Berl). 2021;238(3):639–53.  pmid:33420592 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    63.
            Seppälä EM, Nitschke JB, Tudorascu DL, Hayes A, Goldstein MR, Nguyen DTH, et al. Breathing-based meditation decreases posttraumatic stress disorder symptoms in U.S. military veterans: a randomized controlled longitudinal study. J Trauma Stress. 2014;27(4):397–405.  pmid:25158633 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    64.
            Steventon JJ, Foster C, Furby H, Helme D, Wise RG, Murphy K. Hippocampal blood flow is increased after 20 min of moderate-intensity exercise. Cerebral Cortex. 2019;30(2):525–33. 
                      View Article
                    
                      Google Scholar
                    65.
            Kety SS, Schmidt CF. Measurement of cerebral blood flow and cerebral oxygen consumption in man. Fed Proc. 1946;5:264. pmid:21064908 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    66.
            Fincham GW, Kartar A, Uthaug MV, Anderson B, Hall L, Nagai Y, et al. High ventilation breathwork practices: an overview of their effects, mechanisms, and considerations for clinical applications. Neurosci Biobehav Rev. 2023;155:105453.  pmid:37923236 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    67.
            Schüttler D, von Stülpnagel L, Rizas KD, Bauer A, Brunner S, Hamm W. Effect of hyperventilation on periodic repolarization dynamics. Front Physiol. 2020;11. 
                      View Article
                    
                      Google Scholar
                    68.
            Oswald V, Vanhaudenhuyse A, Annen J, Martial C, Bicego A, Rousseaux F. Autonomic nervous system modulation during self-induced non-ordinary states of consciousness. Scient Rep. 2023;13(1). 
                      View Article
                    
                      Google Scholar
                    69.
            dos Santos RG, Valle M, Bouso JC, Nomdedéu JF, Rodríguez-Espinosa J, McIlhenny EH. Autonomic, neuroendocrine, and immunological effects of Ayahuasca. J Clin Psychopharmacol. 2011;31(6):717–26. 
                      View Article
                    
                      Google Scholar
                    70.
            Liechti ME, Dolder PC, Schmid Y. Alterations of consciousness and mystical-type experiences after acute LSD in humans. Psychopharmacol (Berl). 2017;234(9–10):1499–510.  pmid:27714429 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    71.
            Sparber SB, Dwoskin LP, Kleven MS. Studies on the specificity of neurochemical and behavioral effects of LSD-25. Pharmacol Biochem Behav. 1986;24(2):341–5. 
                      View Article
                    
                      Google Scholar
                    72.
            Bonnelle V, Feilding A, Rosas FE, Nutt DJ, Carhart-Harris RL, Timmermann C. Autonomic nervous system activity correlates with peak experiences induced by DMT and predicts increases in wellbeing. bioRxiv. 2024. 
                      View Article
                    
                      Google Scholar
                    73.
            Strassman RJ. Human psychopharmacology of N,N-dimethyltryptamine. Behav Brain Res. 1996;73(1–2):121–4.  pmid:8788488 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    74.
            Crosswell AD, Mayer SE, Whitehurst LN, Picard M, Zebarjadian S, Epel ES. Deep rest: an integrative model of how contemplative practices combat stress and enhance the body’s restorative capacity. Psychol Rev. 2024;131(1):247–70.  pmid:38147050 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    75.
            Canello T, Tlaie A, Chalise K, Schölvinck ML, Pia L, Havenith MN. Non-ordinary states of consciousness evoked by breathwork correlate with improved heart-rate variability. 2024. 76.
            Wu W-C, Edlow BL, Elliot MA, Wang J, Detre JA. Physiological modulations in arterial spin labeling perfusion magnetic resonance imaging. IEEE Trans Med Imaging. 2009;28(5):703–9.  pmid:19150788 
                      View Article
                    
                        PubMed/NCBI
                      
                      Google Scholar
                    



          

        
      
  
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Yamanot.es: A music box of train station melodies from the JR Yamanote Line]]></title>
            <link>https://yamanot.es/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45045307</guid>
            <description><![CDATA[Yamanotes (/jamanoʊts/) is a web-based music box for playing the departure melodies of each station on the JR Yamanote Line/山手線!]]></description>
            <content:encoded><![CDATA[

		


		
			
				▫️
				▫️
				東京 Tokyo
				▫️
				▫️
				神田 Kanda
				▫️
				▫️
				秋葉原 Akihabara
				▫️
				▫️
				御徒町 Okachimachi
				▫️
				▫️
				上野 Ueno
				▫️
				▫️
				鶯谷 Uguisudani
				▫️
				▫️
				日暮里 Nippori
				▫️
				▫️
				西日暮里 Nishi-Nippori
				▫️
				▫️
				田端 Tabata
				▫️
				▫️
				駒込 Komagome
				▫️
				▫️
				巣鴨 Sugamo
				▫️
				▫️
				大塚 Ōtsuka
				▫️
				▫️
				池袋 Ikebukuro
				▫️
				▫️
				目白 Mejiro
				▫️
				▫️
				高田馬場 Takadanobaba
				▫️
				▫️
				新大久保 Shin-Ōkubo
				▫️
				▫️
				新宿 Shinjuku
				▫️
				▫️
				代々木 Yoyogi
				▫️
				▫️
				原宿 Harajuku
				▫️
				▫️
				渋谷 Shibuya
				▫️
				▫️
				恵比寿 Ebisu
				▫️
				▫️
				目黒 Meguro
				▫️
				▫️
				五反田 Gotanda
				▫️
				▫️
				大崎 Ōsaki
				▫️
				▫️
				品川 Shinagawa
				▫️
				▫️
				高輪ゲートウェイTakanawa Gateway
				▫️
				▫️
				田町 Tamachi
				▫️
				▫️
				浜松町 Hamamatsuchō
				▫️
				▫️
				新橋 Shimbashi
				▫️
				▫️
				有楽町 Yūrakuchō
			
		

		

	

	
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
	

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GMP damaging Zen 5 CPUs?]]></title>
            <link>https://gmplib.org/gmp-zen5</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45041743</guid>
        </item>
    </channel>
</rss>