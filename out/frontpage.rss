<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Hacker News: Front Page</title>
        <link>https://news.ycombinator.com/</link>
        <description>Hacker News RSS</description>
        <lastBuildDate>Fri, 29 Aug 2025 09:51:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>github.com/Prabesh01/hnrss-content-extract</generator>
        <language>en</language>
        <atom:link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/frontpage.rss" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[The Synology End Game]]></title>
            <link>https://lowendbox.com/blog/they-used-to-be-good-but-now-theyve-turned-to-evil-the-synology-end-game/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45060920</guid>
            <description><![CDATA[Synology has recently implemented some pretty user-hostile policies, which means my long-term love affair with them is going to end in heartbreak.]]></description>
            <content:encoded><![CDATA[I’ve been a Synology fan for many years.  I used to roll my own NAS servers for home, but eventually decided that quieter, more energy-friendly dedicated NAS solutions were a better path forward.  I don’t use a lot of their on-board apps, just basic file storage.Right now I’ve got a DS920, a DS418, and a DS1522…but I probably won’t be buying another Synology again.Why?Their abusive, customer-hostile policies.Samba LimitsI started getting queasy when I read earlier this year that on some models, they limit how many concurrent connections you can make.  I though this was just something setup by default in smb.conf, but in fact Synology has a proprietary wrapper around the daemon that artificially limits it.Whiskey.  Tango.  Foxtrot.You Must Buy Your Hard Drives From UsFor a long time, Synology has only officially supported certain hard drives.  I don’t have a problem with this, for three reasons.  First, it was a pretty extensive list and included all the major players (WD, Seagate, etc.).  Second, it’s unreasonable to expect Synology to certify every single hard drive from every maker on the planet.  And finally, it was just a support limit.  In other words, you could use whatever hard drives you wanted, but if there was a problem, they wouldn’t be able to support you if the drive wasn’t on their list.I could live with that.  What I can’t live with is the new policy, implemented this year, where you must buy your drives from Synology.  This only affects new models from this year forward.  Details still seem sketchy, but rumor is that it’s going to be along the lines of “we don’t recognize your WD Black hard drive, therefore we won’t use it.”And by the way, Synology’s hard drives aren’t all that great.  My WD Blacks come with a 5 year warranty.  Synology’s only come with 3 years.Golf.  Foxtrot.  Yankee.Where to Now?I could go back to building my own, with TrueNAS.  In the past, my home-build NAS boxes were hand-me-down gaming PCs (because they were big enough towers) but I have to imagine one can find a case that allows tons of drives and is still powered by something modest.Or I may look at UGREEN.  Or Buffalo.  Or someone else.Raindog308 is a longtime LowEndTalk community administrator, technical writer, and self-described techno polymath. With deep roots in the *nix world, he has a passion for systems both modern and vintage, ranging from Unix, Perl, Python, and Golang to shell scripting and mainframe-era operating systems like MVS. He’s equally comfortable with relational database systems, having spent years working with Oracle, PostgreSQL, and MySQL.As an avid user of LowEndBox providers, Raindog runs an empire of LEBs, from tiny boxes for VPNs, to mid-sized instances for application hosting, and heavyweight servers for data storage and complex databases. He brings both technical rigor and real-world experience to every piece he writes.Beyond the command line, Raindog is a lover of German Shepherds, high-quality knives, target shooting, theology, tabletop RPGs, and hiking in deep, quiet forests.His goal with every article is to help users, from beginners to seasoned sysadmins, get more value, performance, and enjoyment out of their infrastructure.You can find him daily in the forums at LowEndTalk under the handle @raindog308.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Strange CW Keys]]></title>
            <link>https://sites.google.com/site/oh6dccw/strangecwkeys</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45060161</guid>
            <description><![CDATA[Made by OH6DC
You can also use the Text-only index page (divided into useful categories).]]></description>
            <content:encoded><![CDATA[HomeStrange CW KeysMade by OH6DCYou can also use the Text-only index page (divided into useful categories).Lever arch file CW key Lambic pedals Valentine's day lollipop CW paddle Rubber stamp CW key Letter scale CW key Clamp cootie Code book Pepper mill CW key Lightsaber CW key Nutcracker CW key Straight(ener) key Smoke alarm CW key Teletubbygraph key Soap dispenser CW key Vinyl record player CW key Moomin triangle CW key Antiperspirant roll-on CW key Dual banana CW paddle Power twister CW key Power twister CW key Handsaw CW key Hole punch CW key Watering can CW key Toilet brush CW key CW glove Remote control CW key Tea bag CW key Eyebrow-raising CW key with optical transmitter Back scratcher CW key Whisk CW key Pliers CW key Liver casserole CW key Licorice pipe CW key Chocolate CW key Ski-W key Power drill CW keyer Six megapixel CW key Suspenders CW key Spirit bottle cap CW key Speed skate CW key Flower CW key Knee pad sideswiper CW key for portable operation QRP transmitter powered by a CW key Alarm clock CW key Hammer CW key CW gun Nail clipper CW key Ballpoint pen CW key Rotary dial CW key Hammock CW key Joystick CW key Rowing boat CW key Guitar CW key Wallet CW key Radio controlled CW key Amaryllis telegraphiensis Multi-function knife with CW key Toilet paper roll CW key Table ice hockey CW key Big toe CW key Waffle iron CW key Lego straight key Lego bug Pogo stick CW key Crutch CW key Smoke signal CW key CCW key Necktie CW key Toothbrush CW key Bench press CW key Handshake CW key Chopsticks CW key Trailer hitch CW key Typewriter CW keyboard Refrigerator CW key Mobile phone CW key Paper cup iambic paddles Morsetrap CW key Fingertips CW key Vacuum cleaner semi-automatic CW key Banana CW key Rolling pin CW key Toaster CW key Cheese slicer CW key Rocking chair CW key QLF pedal for left foot CW Cross-country ski shoe CW key CW insoles QRQ paddles Onion chopper CW key Beer can CW key Egg slicer CW key Stapler CW key Bicycle pump CW key Iron bar CW key Homebrew semi-automatic bug Hacksaw blade sideswiper CW key Plywood CW key Home  |  Homebrew QRP  Page updated Google SitesReport abuse]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PSA: Libxslt is unmaintained and has 5 unpatched security bugs]]></title>
            <link>https://vuxml.freebsd.org/freebsd/b0a3466f-5efc-11f0-ae84-99047d0a6bcc.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45060004</guid>
            <description><![CDATA[Alan Coopersmith reports:]]></description>
            <content:encoded><![CDATA[
Alan Coopersmith reports:

	  On 6/16/25 15:12, Alan Coopersmith wrote:
	  
	    BTW, users of libxml2 may also be using its sibling project, libxslt,
	    which currently has no active maintainer, but has three unfixed security issues
	    reported against it according to
	    
		https://gitlab.gnome.org/Teams/Releng/security/-/wikis/2025#libxml2-and-libxslt
	  
	  2 of the 3 have now been disclosed:
	  (CVE-2025-7424) libxslt: Type confusion in xmlNode.psvi between stylesheet and source nodes
	    https://gitlab.gnome.org/GNOME/libxslt/-/issues/139
	    https://project-zero.issues.chromium.org/issues/409761909
	  (CVE-2025-7425) libxslt: heap-use-after-free in xmlFreeID caused by `atype` corruption
	    https://gitlab.gnome.org/GNOME/libxslt/-/issues/140https://project-zero.issues.chromium.org/issues/410569369
	  Engineers from Apple & Google have proposed patches in the GNOME gitlab issues,
	  but neither has had a fix applied to the git repo since there is currently no
	    maintainer for libxslt.
	

Note that a fourth vulnerability was reported on June 18, 2025, which remains undisclosed to date (GNOME libxslt issue 148, link below), see
	  
	    https://gitlab.gnome.org/Teams/Releng/security/-/wikis/2025#libxml2-and-libxslt
	
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A deep dive into Debian 13 /tmp: What's new, and what to do if you don't like it]]></title>
            <link>https://lowendbox.com/blog/a-deep-dive-into-debian-13s-tmp-whats-new-and-what-to-do-if-you-dont-like-it/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45059470</guid>
            <description><![CDATA[Debian 13 "Trixie" comes with a whole new world of tmpfs, which is memory-based, and an automated cleanup process.  Let's take a look.]]></description>
            <content:encoded><![CDATA[Debian 13 “Trixie” introduces an important change to /tmp.  Traditionally, it’s been just another filesystem, albeit with some special permissions that allows everyone on the system to use it without being able to remove each other’s files.In Trixie, it’s been moved off the disk into memory – specifically a type of memory called tmpfs.  To quote the tmpfs man page:The  tmpfs  facility  allows  the  creation of filesystems whose contents reside in virtual memory. Since the files on such filesystems typically reside in RAM, file access is extremely fast.They’re also extremely temporary…which is what you really want.  There’s an old story about a user who was assigned to work on the Transportation Management Project.  He logged into the server where he was supposed to store his work, saw the /tmp directory, found he could upload files there, and happily spent a couple months putting all his work there.  Alas, when the server was rebooted…Now that is undoubtedly an urban legend, but it illustrates the true nature of /tmp.  It’s fine if you need a disposable log fine, a PHP session file, space for sorting something, etc.  But you shouldn’t be storing anything there.This isn’t a new thing in the Linux world.  RedHat and its ilk have used tmps for /tmp for some time.A more serious problem than people losing files is people who use too much /tmp.  The system needs /tmp to do basic functions, so if it hits 100%, things will break.  It’s really easy to think “I’m going to download and untar this big zip file into /tmp, and then I’ll remove it after I pull out the one file I need”…and forget to remove it.  Now you’re hogging /tmp and over time, /tmp can be filled up with junk.Debian 13’s tmpfs Comes With…Challenges.  And SolutionsNow instead of filling up disk, you’re filling up memory.  If you download a 300MB .zip file, expand it to 1GB, and forget it, now you’re chewing up 1GB of RAM.  Ouch.There are two mitigating factors.  First, by default, Debian will only allocate a maximum of 50% of RAM to the tmpfs for /tmp.  You can change this.  To do so, typesystemctl edit tmp.mountYou’ll be popped into your editor (controlled by the EDITOR environment variable) with a form to update the settings.  At the very bottom you’ll see a template, which you can copy and edit:# [Mount]
# What=tmpfs
# Where=/tmp
# Type=tmpfs
# Options=mode=1777,strictatime,nosuid,nodev,size=50%%,nr_inodes=1m
Go back up to the part before the line “Edits below this comment will be discarded” and paste in something like this:[Mount]
What=tmpfs
Where=/tmp
Type=tmpfs 
Options=mode=1777,strictatime,nosuid,nodev,size=25%%,nr_inodes=1mto change it to 25% or if you want a number:[Mount]
What=tmpfs
Where=/tmp
Type=tmpfs 
Options=mode=1777,strictatime,nosuid,nodev,size=1G,nr_inodes=1mto change it to 1GB.For example, I have a Debian 13 VPS with 4GB of RAM.  After a fresh install, I see it’s using 2GB max for tmpfs:# findmnt --target /tmp
TARGET SOURCE FSTYPE OPTIONS
/tmp   tmpfs  tmpfs  rw,nosuid,nodev,size=2007704k,nr_inodes=1048576,inode64Note that this is a maximum.  If there’s nothing in /tmp, /tmp does not use any memory.After doing the systemctl edit, like this:I get the message:Before this change, /tmp was at 2GB (half of the 4GB RAM):Now, after reloading systemd and restarting tmp.mount, I see /tmp is limited to 1GB:CleanupThe second mitigating factor is that /tmp is now automatically cleaned up.  Quoting the release notes:The new default behavior is for files in /tmp to be automatically deleted after 10 days from the time they were last used (as well as after a reboot). Files in /var/tmp are deleted after 30 days (but not deleted after a reboot).You can modify these policies, exclude certain files (why?  they’re temporary!), or even apply it to other directories.  Consult the fine manual but I think for 99% of people, the defaults are just fine.  I might be tempted to make the cleanup a little more aggressive, like 3 days.Thinking in a LowEnd ContextOne concern is for very low-memory systems.  While 1GB has become the smallest VM for a lot of people, 512s are still sold.  Allowing /tmp to consume 256MB out of 512 (which is really only 470-480 after the kernel and vital system processes are loaded) is a lot more impactful than consuming 256MB on a 10GB or 20GB filesystem.Fortunately, opting out of the new tmpfs world is easy if you don’t like it:systemctl mask tmp.mountand reboot.  I did that on the test box above:Now I can put 17GB of junk there.  Fortunately, it will be cleaned up as described above.So how are you planning to handle Debian 13’s new tmpfs-based /tmp?Raindog308 is a longtime LowEndTalk community administrator, technical writer, and self-described techno polymath. With deep roots in the *nix world, he has a passion for systems both modern and vintage, ranging from Unix, Perl, Python, and Golang to shell scripting and mainframe-era operating systems like MVS. He’s equally comfortable with relational database systems, having spent years working with Oracle, PostgreSQL, and MySQL.As an avid user of LowEndBox providers, Raindog runs an empire of LEBs, from tiny boxes for VPNs, to mid-sized instances for application hosting, and heavyweight servers for data storage and complex databases. He brings both technical rigor and real-world experience to every piece he writes.Beyond the command line, Raindog is a lover of German Shepherds, high-quality knives, target shooting, theology, tabletop RPGs, and hiking in deep, quiet forests.His goal with every article is to help users, from beginners to seasoned sysadmins, get more value, performance, and enjoyment out of their infrastructure.You can find him daily in the forums at LowEndTalk under the handle @raindog308.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lucky 13: a look at Debian trixie]]></title>
            <link>https://lwn.net/Articles/1033474/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45059160</guid>
            <description><![CDATA[After more than two years of development, the Debian Project has released its new stable versio [...]]]></description>
            <content:encoded><![CDATA[

We're bad at marketing

We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please subscribe today to help us keep doing that, and so
we don’t have to get good at marketing.


After more than two years of development, the Debian Project has released its new stable version, Debian 13 ("trixie"). The release comes with the usual bounty of
upgraded packages and more than 14,000 new packages; it also debuts Advanced Package Tool
(APT) 3.0 as the default package manager and makes 64-bit
RISC-V a supported architecture. There are few surprises with trixie,
which is exactly what many Linux users are hoping for—a free
operating system that just works as expected.

Debian's stable
releases are aptly named; the project prioritizes stability over
shipping the latest software. The freeze
schedule for trixie called for a soft freeze in April, which meant
that (for example) the KDE Plasma 6.4
release in June was too late to make the cut—even though trixie
was not released until August. Users who prefer to live on the edge
will want to run another distribution or follow Debian development by
running the testing release
that previews the next stable version—Debian 14 ("forky"). Truly
adventurous users may take their chances with the unstable ("sid")
release.

That said, trixie is up-to-date enough for many folks; it includes
GNOME 48, KDE Plasma 6.3, Xfce 4.20, GNU
Emacs 30.1, GnuPG 2.4.7, LibreOffice 25.2, and
more. Under the hood, it includes the most recent Linux LTS kernel
(6.12.41), GNU Compiler Collection (GCC) 14.2, GNU C Library (glibc)
2.41, LLVM/Clang 19, Python 3.13, Rust 1.85, and
systemd 257. The release notes have a section
for well-known software that compares the version in Debian 12
against Debian 13. While some of the versions lag a bit behind the
upstream, they are not woefully outdated.

The project now supports
six major hardware architectures: x86-64/amd64, 32-bit Arm with a
hardware FPU (armhf), 64-bit Arm (arm64), IBM POWER8 or newer
(ppc64el), IBM S/390 (s390x), and 64-bit RISC-V. The i386 architecture
is not supported for trixie, though the project continues to
build some i386 packages to run on 64-bit systems; users with i386 systems cannot upgrade to
trixie. The MIPS
architectures (mipsel and mis64el) have also been removed in trixie.

The Arm EABI
(armel) port that targets older 32-bit Arm devices prior to Arm v7 is
still supported with trixie, but this release is the end of the
line. There is no installation media for armel systems, but users who
have bookworm installed can upgrade to trixie if they have supported
hardware: the Raspberry Pi 1, Zero, and Zero W are the
only devices mentioned in
the release notes.

Upgrades from bookworm are supported, of course. The release
notes suggest that users convert APT source files to the DEB822 format
before the upgrade. APT 3.0
includes an "apt modernize-sources" command to convert APT data
source files to DEB822, but that is not available in bookworm. Users are
also expected to remove
all third-party packages prior to running the upgrade. I tested
the upgrade on one of my servers, after taking a snapshot to roll back
to if needed, and all went smoothly. Users who are considering an
upgrade should read the release notes carefully before forging ahead;
in particular, users should be aware that it's possible (but not
certain) for network interface names to change on upgrade.

Installation

For users who want to start fresh, Debian offers a
variety of installer images and download methods; users can choose
a 64MB minimal ISO image with the netboot
installer, all the way up to a set of Blu-ray images. The project
recommends using BitTorrent or Jigsaw
Download (jigdo) for the largest images. BitTorrent probably needs
no introduction, but jigdo is not as well-known. Jigdo is a method of
downloading all of the individual packages for an image from multiple
mirrors and then assembling them into an ISO image on the user's
machine. It was a bit fiddly to use jigdo to download an image, but
not overly so—and the speed of the whole process was comparable
to simply downloading an ISO of the same size.

Debian's network
install ("netinst") image is probably the best option for server
installations and for experienced Linux users; it includes the
packages required for a base install and then fetches the remaining
software from Debian mirrors. Unlike the tiny netboot image, it
includes the option of using either the graphical installer or the
text-based installer.

The installer is a bit of a throwback to an earlier era when users
were expected to know a lot more about the workings of a Linux system. 
Users who have only worked with distributions like Fedora and Ubuntu
will notice that installing Debian requires many more steps than other
popular distributions. For example, many desktop distributions have
eliminated the step of setting a password for the root
user—instead, it is generally assumed that the primary user will
also be the system administrator, so the default is to give the
primary user sudo privileges instead. Debian does not take that
approach; in fact, there is no way to give a user sudo privileges
during installation. Setting up sudo has to be done manually after
the installation is completed Update: Users can skip creation of a root account and the installer will then set up the regular user as an administrator with sudo permissions. Apologies for the error.

For some folks, installing Debian will be a bit of a chore and may
even be confusing for users who are new to Linux. For example, the
text-mode installer requires users to specify the device for GRUB boot
loader installation, without providing a default. If one chooses an
invalid partition, the installer tells the user that the operation has
failed and drops back to a menu listing all the installation
steps. Presumably if one picks the wrong partition it will
happily install GRUB to that and render the system unbootable. This is
not insurmountable for experienced Linux users, but it would no doubt
be a hurdle for many users.

More experienced Linux users are likely to appreciate the
amount of control offered by the installer. For example, Fedora's
recent web-based installer makes it difficult to even find the option to
perform custom partitioning. Debian has a guided partitioning option
for those who do not want to fuss with it, but the option to create
custom partitions is not hidden from the user.

Debian has a better installation option for newer Linux users,
though it is easy to miss: the live install images, which
use the Calamares installer. Its
workflow is more akin to the installation process one finds with
Fedora and Ubuntu; it also sets up the primary user with sudo
privileges rather than creating a root password. Unfortunately,
the live images are not listed on the main page for installer
images—though they are mentioned, briefly, in the release
notes.







The Debian installer also has the option of using a Braille display
and/or speech synthesizer voice for the installation. I have not tried
these options, but they are available for users who need them.

X.org

Many distributions are in the process of phasing out X.org support
for GNOME and KDE as the upstream projects have started doing so.
For example, Fedora will remove X.org session support
for GNOME in Fedora 43, and the plan is for Ubuntu to do the same
in its upcoming 25.10 release. GNOME will be completely removing X.org
support in GNOME 49, which is planned for September.

Much has already been said about this, of course, and there is
likely little new left to be said or that needs to be
said. However, for users who still need or want X.org support,
Debian 13 includes X.org sessions for GNOME and KDE. In testing
trixie, I've spent some time in the GNOME and KDE X.org sessions as
well as the Wayland sessions; if there are any gotchas or horrible
bugs, I haven't encountered them (yet). This might be a compelling
reason for some folks to switch to (or stick with) Debian.

Trying trixie

I use Debian for my personal web site and blogs, but it has been
quite some time since I used it as my primary desktop operating
system. Debian (and Ubuntu) derivatives, such as Linux Mint and Pop!_OS, yes—but it's been
several years since I've used vanilla Debian on the desktop for
more than casual tinkering.

The Debian release announcement boasts about the number of packages
included in trixie: 64,419 packages total, with 14,100 added and more
than 6,000 removed as obsolete
since bookworm. That is quite a few packages, but falls short of some
other distributions. For example, "dnf repoquery --repo=fedora
--available" shows more than 76,000 packages available for
Fedora 42.

After installing Debian, I went to install some of my preferred
software, such as aerc,
Ghostty, niri, and Speech Note. The aerc
packages in trixie are current, but Ghostty and niri are not packaged
for Debian at all. Ghostty is written in Zig, which is also not
available, so users who want to build it from source will need to
install Zig separately and then build Ghostty. Speech Note is packaged
as a Flatpak, but Debian does not enable Flatpaks or Flathub in the
GNOME Software Store by default. Users who want Flatpaks on Debian via
Flathub will need to install the flatpak package and manually
add the Flathub repo:

    flatpak remote-add --if-not-exists flathub \
      https://dl.flathub.org/repo/flathub.flatpakrepo


Users will need to add the gnome-software-plugin-flatpak
package for Flatpak support in GNOME Software, and
plasma-discover-backend-flatpak to add it to
KDE Discover.

Trixie ships with the Firefox extended-support release (ESR) by
default: Firefox
128, which was released in July 2024. Happily,
Mozilla offers a Debian
repository for those who want to run more current versions. Even
better, there is a little-advertised utility called extrepo that
has a curated list of external repositories users might want to enable
for Debian. To enable the Mozilla repository, for example, a user only
needs to install extrepo, run
"extrepo enable mozilla" as root (or with
sudo), update the package cache, and look for the regular
Firefox package. In all, extrepo includes more than 160 external
repositories for applications like Docker CE, Signal, and Syncthing. Unfortunately, the
extrepo utility does not have a separate "list" command to show the
available repositories, though running "extrepo search"
with no search parameter will return all of its DEB822-formatted
repository entries. Some of the software is
in an external repository due to a non-free license, other software (like
Firefox) just has a development cycle that outpaces Debian's.

As one might expect, the Debian desktop experience is not
dramatically different from other distributions; GNOME 48 on
Debian is little different than GNOME 48 on Fedora, and the same
is true for KDE, Xfce, etc. The primary difference is that users can
expect more or less the same desktop experience running Debian stable
in two years that they have today, which is not necessarily true for
other distributions.

Miscellaneous

One of the features in Debian 13 is something that most users
won't notice or appreciate at all: a transition to
64-bit time_t on 32-bit architectures, to avoid the Year 2038 problem. The
short version is that 32-bit integers cannot hold a Unix epoch
timestamp for dates after January 19, 2038. That may seem
like a distant concern, even irrelevant for Debian trixie; after all,
Debian 13 is only supported by the project until 2030. However,
the project expects that some 32-bit embedded systems will still be running
trixie in 2038, so Debian developers did the heavy lifting to complete
the transition to 64-bit time_t now. LWN covered the early planning
for this in 2023.

By now, most users have retired their DSA
SSH keys; if not, now is the time to do so. DSA keys were disabled by
default with OpenSSH in 2015, and they are entirely disabled now with
the openssh-client and openssh-server packages in
trixie. If there is a device that can, for some reason, only be
connected to with DSA, users can install the
openssh-client-ssh1 package and use ssh1 to make the
connection.

As we covered in
June 2024, Debian 13 has switched to using a tmpfs
filesystem for the /tmp directory. By default, Debian
allocates up to 50% of memory to /tmp, but this can be
changed by following the instructions
in the release notes. Note that this also applies to systems that
are upgraded to trixie from bookworm.

Forward to forky

Debian Project Leader (DPL) Andreas Tille recently
announced "Debian's 100000th birthday", so clearly the project has a
bit of experience with putting out solid releases. Granted, he was
reporting the number in binary, but even when converted to decimal 
numbers (32 years), it's an impressive track record.

While testing, I installed trixie on a couple of systems, including
a new Framework 12-inch laptop. My original intent was to just see
whether Debian had any problems with the new hardware (it didn't), but
now I'm leaning toward sticking with Debian on this system for a while
to see if stability suits me.

With trixie out the door, the Debian Project has already turned its
attention to working on forky, which has no release date set. Debian has
stuck to a loose schedule of a new stable release roughly every two
years. Most likely we will see Debian 14 sometime in 2027. After
the forky release, trixie will still receive updates from Debian's
security team through 2028, and then from its LTS team through 2030.

As of yet, there are no major new features or changes announced for
forky; it seems likely that those will be coming to light in the
coming months now that the project has trixie out the door. LWN will,
of course, be reporting on those developments as they happen.


            ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude Sonnet will ship in Xcode]]></title>
            <link>https://developer.apple.com/documentation/xcode-release-notes/xcode-26-release-notes</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45058688</guid>
        </item>
        <item>
            <title><![CDATA[Python: The Documentary [video]]]></title>
            <link>https://www.youtube.com/watch?v=GfH4QL4VqJ0</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45058171</guid>
        </item>
        <item>
            <title><![CDATA[Rupert's Property]]></title>
            <link>https://johncarlosbaez.wordpress.com/2025/08/28/a-polyhedron-without-ruperts-property/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45057561</guid>
            <description><![CDATA[You can cut a hole in a cube that’s big enough to slide an identical cube through that hole! Think about that for a minute—it’s kind of weird. Amazingly, nobody could prove any co…]]></description>
            <content:encoded><![CDATA[
				



You can cut a hole in a cube that’s big enough to slide an identical cube through that hole!   Think about that for a minute—it’s kind of weird.
Amazingly, nobody could prove any convex polyhedron doesn’t have this property!  It’s called ‘Rupert’s property’.
Until this week.
This week Steininger and Yurkevich proved there is a convex polyhedron that you can’t cut a hole in big enough to slide the entire polyhedron through the hole.  It has 90 vertices, and apparently 240 edges and 152 faces.




To prove that no such hole is possible, they had to do a computer search of 18 million different holes, plus use a lot of extra math to make sure they’d checked enough possibilities:
• Jakob Steininger and Sergey Yurkevich, A convex polyhedron without Rupert’s property.
To celebrate their discovery, they gave this polyhedron a silly name.  Since this polyhedron lacks Rupert’s property, they called it a ‘noperthedron’.
Why is this property called ‘Rupert’s property’?  Wikipedia explains:

In geometry, Prince Rupert’s cube is the largest cube that can pass through a hole cut through a unit cube without splitting it into separate pieces. Its side length is approximately 1.06, 6% larger than the side length 1 of the unit cube through which it passes. The problem of finding the largest square that lies entirely within a unit cube is closely related, and has the same solution.
Prince Rupert’s cube is named after Prince Rupert of the Rhine, who asked whether a cube could be passed through a hole made in another cube of the same size without splitting the cube into two pieces. A positive answer was given by John Wallis. Approximately 100 years later, Pieter Nieuwland found the largest possible cube that can pass through a hole in a unit cube.

Here Greg Egan shows how Rupert’s property works for the cube:


Here he shows how it works for the regular octahedron:


And finally, here’s a video by David Renshaw showing 26 polyhedra with Rupert’s property… and 5 polyhedra that might lack it:




The triakis tetrahedron is an extremely close call, but it does have Rupert’s property:




				
				
					
					This entry was posted  on Thursday, August 28th, 2025 at 7:50 am and is filed under mathematics.					You can follow any responses to this entry through the RSS 2.0 feed.
											You can leave a response, or trackback from your own site.
					
					
				

				
					Post navigation
					« Previous Post
					
				

			]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[An eyecare foundation model for clinical assistance]]></title>
            <link>https://www.nature.com/articles/s41591-025-03900-7</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45057513</guid>
            <description><![CDATA[In the context of an increasing need for clinical assessments of foundation models, we developed EyeFM, a multimodal vision–language eyecare copilot, and conducted a multifaceted evaluation, including retrospective validations, multicountry efficacy validation as a clinical copilot and a double-masked randomized controlled trial (RCT). EyeFM was pretrained on 14.5 million ocular images from five imaging modalities paired with clinical texts from global, multiethnic datasets. Efficacy validation invited 44 ophthalmologists across North America, Europe, Asia and Africa in primary and specialty care settings, highlighting its utility as a clinical copilot. The RCT—a parallel, single-center, double-masked study—assessed EyeFM as a clinical copilot in retinal disease screening among a high-risk population in China. A total of 668 participants (mean age 57.5 years, 79.5% male) were randomized to 16 ophthalmologists, equally allocated into intervention (with EyeFM copilot) and control (standard care) groups. The primary endpoint indicated that ophthalmologists with EyeFM copilot achieved higher correct diagnostic rate (92.2% versus 75.4%, P < 0.001) and referral rate (92.2% versus 80.5%, P < 0.001). Secondary outcome indicated improved standardization score of clinical reports (median 33 versus 37, P < 0.001). Participant satisfaction with the screening was similar between groups, whereas the intervention group demonstrated higher compliance with self-management (70.1% versus 49.1%, P < 0.001) and referral suggestions (33.7% versus 20.2%, P < 0.001) at follow-up. Post-deployment evaluations indicated strong user acceptance. Our study provided evidence that implementing EyeFM copilot can improve the performance of ophthalmologists and the outcome of patients. Chinese Clinical Trial Registry registration: ChiCTR2500095518 . Trained and validated on multimodal data from 14.5 million images from multicountry datasets, a foundation model is shown to increase diagnostic and referral accuracy of clinicians when used as an assistant in a trial involving 16 ophthalmologists and 668 patients.]]></description>
            <content:encoded><![CDATA[
                Data availabilityFor the reproduction of our algorithm code, we have also deposited a minimum dataset (https://zenodo.org/records/15546254; ref. 41), which is publicly available for scientific research and non-commercial use. The data supporting the findings of this trial are available within the paper and its supplementary information files. All requests for further data sharing will be reviewed by the data management committees from participating institutions and by the ethics committee of Shanghai Health and Medical Centre, China, to verify whether the request is subject to any intellectual property or confidentiality obligations and will be accessible with informed consents. Requests for access to deidentified individual-level data from this trial can be submitted via email to B.S. (shengbin@sjtu.edu.cn) with detailed proposals for approval and will be evaluated on a case-by-case basis and responded to within 60 days. Investigators who consent to the terms of the data transfer agreement, including, but not limited to, the use of these data only for academic purposes and to protect the confidentiality of the data and limit the possibility of identification of patients, will be granted access. Source data are provided with this paper.Code availability
            
            The code being used in the current study for developing the algorithm is provided at https://github.com/eyefm/EyeFM.
          ReferencesZhou, Y. et al. A foundation model for generalizable disease detection from retinal images. Nature 622, 156–163 (2023).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Chen, R. J. et al. Towards a general-purpose foundation model for computational pathology. Nat. Med. 30, 850–862 (2024).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Lu, M. Y. et al. A visual-language foundation model for computational pathology. Nat. Med. 30, 863–874 (2024).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Topol, E. J. High-performance medicine: the convergence of human and artificial intelligence. Nat. Med. 25, 44–56 (2019).CAS 
    PubMed 
    
                    Google Scholar 
                Tanno, R. et al. Collaboration between clinicians and vision–language models in radiology report generation. Nat. Med. 31, 599–608 (2025).CAS 
    PubMed 
    
                    Google Scholar 
                Norden, J, G. & Shah, N. R. What AI in health care can learn from the long road to autonomous vehicles. NEJM Catalyst https://catalyst.nejm.org/doi/abs/10.1056/CAT.21.0458 (2022).You, J. G., Hernandez-Boussard, T., Pfeffer, M. A., Landman, A. & Mishuris, R. G. Clinical trials informed framework for real world clinical implementation and deployment of artificial intelligence applications. NPJ Digit. Med. 8, 107 (2025).PubMed 
    PubMed Central 
    
                    Google Scholar 
                Longhurst, C. A., Singh, K., Chopra, A., Atreja, A. & Brownstein, J. S. A call for artificial intelligence implementation science centers to evaluate clinical effectiveness. NEJM AI https://doi.org/10.1056/AIp2400223 (2024).Article 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Gupta, A., Savarese, S., Ganguli, S. & Fei-Fei, L. Embodied intelligence via learning and evolution. Nat. Commun. 12, 5721 (2021).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Colunga-Lozano, L. E. et al. Clinical judgment shows similar and sometimes superior discrimination compared to prognostic clinical prediction models: a systematic review. J. Clin. Epidemiol. 165, 111200 (2024).
                    Google Scholar 
                Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at https://arxiv.org/abs/2108.07258 (2022).Howell, M. D., Corrado, G. S. & DeSalvo, K. B. Three epochs of artificial intelligence in health care. JAMA 331, 242–244 (2024).
                    Google Scholar 
                Lu, M. Y. et al. A multimodal generative AI copilot for human pathology. Nature 634, 466–473 (2024).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Future of Health: The Emerging Landscape of Augmented Intelligence in Health Care. https://www.ama-assn.org/system/files/future-health-augmented-intelligence-health-care.pdf (American Medical Association, 2024).Yang, J. et al. Generalizability assessment of AI models across hospitals in a low-middle and high income country. Nat. Commun. 15, 8270 (2024).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Avram, O. et al. Accurate prediction of disease-risk factors from volumetric medical scans by a deep vision model pre-trained with 2D scans. Nat. Biomed. Eng. 9, 507–520 (2024).PubMed 
    
                    Google Scholar 
                Street, A., Kersaudy Kerhoas, M. & Ndlovu, Z. From equitable access to equitable innovation: rethinking bioengineering for global health. Nat. Rev. Bioeng. 2, 444–446 (2024).CAS 
    
                    Google Scholar 
                Matheny, M. E., Whicher, D. & Thadaney Israni, S. Artificial intelligence in health care: a report from the National Academy of Medicine. JAMA 323, 509–510 (2020).PubMed 
    
                    Google Scholar 
                van de Sande, D. et al. To warrant clinical adoption AI models require a multi-faceted implementation evaluation. NPJ Digit. Med. 7, 58 (2024).PubMed 
    PubMed Central 
    
                    Google Scholar 
                Hadziahmetovic, M., Nicholas, P., Jindal, S., Mettu, P. S. & Cousins, S. W. Evaluation of a remote diagnosis imaging model vs dilated eye examination in referable macular degeneration. JAMA Ophthalmol. 137, 802–808 (2019).PubMed Central 
    
                    Google Scholar 
                Liu, H., Li, C., Wu, Q. & Lee, Y. J. Visual instruction tuning. In Advances in Neural Information Processing Systems 36 (eds Oh, A. et al.) https://papers.nips.cc/paper_files/paper/2023/file/6dcf277ea32ce3288914faf369fe6de0-Paper-Conference.pdf (Curran Associates, 2023).Touvron, H. et al. Llama 2: open foundation and fine-tuned chat models. Preprint at https://arxiv.org/abs/2307.09288 (2023).Bachmann, R., Mizrahi, D., Atanov, A. & Zamir, A. MultiMAE: Multi-modal Multi-task Masked Autoencoders. In Computer Vision – ECCV 2022 (eds Avidan, S. et al.) 348–367 (Springer-Verlag, 2022).Rafailov, R. et al. Direct preference optimization: your language model is secretly a reward model. In Proc. of the 37th International Conference on Neural Information Processing Systems (eds Oh, A. et al.) 53728–53741 (Curran Associates, 2023).McMahan, B., Moore, E., Ramage, D., Hampson, S. & Arcas, B. A. Y. Communication-efficient learning of deep networks from decentralized data. In Proc. of the 20th International Conference on Artificial Intelligence and Statistics (eds Singh, A. & Zhu, J.) 1273–1282 (PMLR, 2017).Chen, X. et al. FFA-GPT: an automated pipeline for fundus fluorescein angiography interpretation and question-answer. NPJ Digit. Med. 7, 111 (2024).PubMed 
    PubMed Central 
    
                    Google Scholar 
                Singhal, K. et al. Toward expert-level medical question answering with large language models. Nat. Med. 31, 943–950 (2025).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                McDuff, D. et al. Towards accurate differential diagnosis with large language models. Nature 642, 451–457 (2025).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Ting, D. S. W. et al. Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes. JAMA 318, 2211–2223 (2017).PubMed Central 
    
                    Google Scholar 
                Wang, W. et al. Learning two-stream CNN for multi-modal age-related macular degeneration categorization. IEEE J. Biomed. Health Inform. 26, 4111–4122 (2022).PubMed 
    
                    Google Scholar 
                He, M. et al. Prevalence and clinical characteristics of glaucoma in adult Chinese: a population-based study in Liwan District, Guangzhou. Invest. Opthalmol. Vis. Sci. 47, 2782–2788 (2006).
                    Google Scholar 
                Liu, X. et al. Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension. Nat. Med. 26, 1364–1374 (2020).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Bourne, R. et al. Trends in prevalence of blindness and distance and near vision impairment over 30 years: an analysis for the Global Burden of Disease Study. Lancet Glob. Health 9, e130–e143 (2021).
                    Google Scholar 
                Trott, M. et al. Eye disease and mortality, cognition, disease, and modifiable risk factors: an umbrella review of meta-analyses of observational studies. Eye 36, 369–378 (2022).PubMed 
    
                    Google Scholar 
                Xiong, K., Mao, H., Zhang, Q., Lei, C. & Liang, Y. Associations between vision impairment and multimorbidity among older Chinese adults: results from the China health and retirement longitudinal study. BMC Geriatr. 23, 688 (2023).PubMed 
    PubMed Central 
    
                    Google Scholar 
                Zheng, D. D. et al. Patterns of chronic conditions and their association with visual impairment and health care use. JAMA Ophthalmol. 138, 387–394 (2020).PubMed Central 
    
                    Google Scholar 
                Holden, B. A. et al. Global prevalence of myopia and high myopia and temporal trends from 2000 through 2050. Ophthalmology 123, 1036–1042 (2016).PubMed 
    
                    Google Scholar 
                Singhal, K. et al. Large language models encode clinical knowledge. Nature 620, 172–180 (2023).CAS 
    PubMed 
    PubMed Central 
    
                    Google Scholar 
                Lewis, J. R. & Sauro, J. in Human Centered Design (ed Kurosu, M.) 94–103 (Springer, 2009).Hillis, S. L. & Soh, B. P. Obuchowski-Rockette analysis for multi-reader multi-case (MRMC) readers-nested-in-test study design with unequal numbers of readers. Proc. SPIE Int. Soc. Opt. Eng. 12467, 124670F (2023).PubMed 
    PubMed Central 
    
                    Google Scholar 
                EyeFM study group EyeFM sample dataset. Zenodo https://zenodo.org/records/15546254 (2025).Download referencesAcknowledgementsWe thank H. Li and Z. Li for creating the illustrations and icons. This study was supported by the National Key R&D Program of China (2022YFC2502800), the National Natural Science Foundation of China (82388101) and the Beijing Natural Science Foundation (IS23096) to T.Y.W.; the National Natural Science Foundation of China (62272298), the Noncommunicable Chronic Diseases-National Science and Technology Major Project (2023ZD0509202 & 2023ZD0509201), the National Key Research and Development Program of China (2022YFC2407000) to B.S.; and the Noncommunicable Chronic Diseases-National Science and Technology Major Project (2023ZD0509202 & 2023ZD0509201), the Clinical Special Program of Shanghai Municipal Health Commission (20224044) and the Three-Year Action Plan to Strengthen the Construction of the Public Health System in Shanghai (2023-2025 GWVI-11.1-28) to T.C. These funders/sponsors had no role in the design or conduct of the study.Author informationAuthor notesThese authors contributed equally: Yilan Wu, Bo Qian, Tingyao Li, Yiming Qin, Zhouyu Guan, Tingli Chen, Yali Jia, Ping Zhang, Dian Zeng.These authors jointly supervised this work: Ya Xing Wang, Yih-Chung Tham, Ching-Yu Cheng, Tien Yin Wong, Bin Sheng.Authors and AffiliationsBeijing Visual Science and Translational Eye Research Institute (BERI), Beijing Tsinghua Changgung Hospital Eye Center, Tsinghua Medicine, Tsinghua University, Beijing, ChinaYilan Wu, Yiming Qin, Dian Zeng, Yixiao Jin, Hongwei Ji, Ya Xing Wang & Tien Yin WongSchool of Clinical Medicine, Tsinghua Medicine, Tsinghua University,  Beijing, ChinaYilan Wu, Yiming Qin, Dian Zeng, Hongwei Ji & Tien Yin WongShanghai Belt and Road International Joint Laboratory for Intelligent Prevention and Treatment of Metabolic Disorders, Department of Computer Science and Engineering, School of Electronic, Information, and Electrical Engineering, Institute for Proactive Healthcare, Shanghai Jiao Tong University, Department of Endocrinology and Metabolism, Shanghai Sixth People’s Hospital Affiliated to Shanghai Jiao Tong University School of Medicine, Shanghai Diabetes Institute, Shanghai Clinical Center for Diabetes, Shanghai Key Laboratory of Diabetes Mellitus, Shanghai, ChinaBo Qian, Tingyao Li, Yiming Qin, Zhouyu Guan, Huating Li, Ziyao Meng, Xiang Chen, Yuanqi Yao & Bin ShengMOE Key Laboratory of AI, School of Electronic, Information, and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, ChinaBo Qian, Tingyao Li, Yiming Qin, Ziyao Meng, Xiang Chen, Yuanqi Yao & Bin ShengCollege of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics, Key Laboratory of Brain-Machine Intelligence Technology, Ministry of Education, Nanjing, ChinaBo QianDepartment of Ophthalmology, Shanghai Health and Medical Centre, Wuxi, ChinaTingli Chen, Yi Huang, Xiyun Bian, Jing Wang, Xiaolong Yang, Haifang Zhang & Yihan LiCasey Eye Institute, Oregon Health and Science University, Portland, OR, USAYali Jia & Pengxiao ZangDepartment of Biomedical Engineering, Oregon Health and Science University, Portland, OR, USAYali Jia & Pengxiao ZangDepartment of Computer Science and Engineering, The Ohio State University, Columbus, OH, USAPing Zhang & Changchang YinDepartment of Biomedical Informatics, The Ohio State University, Columbus, OH, USAPing Zhang & Changchang YinDepartment of Ophthalmology & Visual Sciences, College of Medicine, The Ohio State University Wexner Medical Center, Columbus, OH, USASayoko Moroi, Joshua Evans, Alan Letson, Frederik Davidorf, Mona Adeli, Peter Chen & Thomas A. MendelDepartment of Ophthalmology, University of Florida College of Medicine, Jacksonville, FL, USARajiv Raman, Praveena Venkatakrishnan, Dhaivat Shah, Abhishek Kumar Tripathi, Dharshan Bhatt, Urvashi Kala & Abhishek KarraDepartment of Ophthalmology, Odense University Hospital, Odense, DenmarkBenjamin Sommer Thinggaard & Frederik PedersenOpen Patient Data Explorative Network, Odense University Hospital, Odense, DenmarkBenjamin Sommer Thinggaard, Benjamin Sommer Thinggaard, Frederik Pedersen, Bjarke Steenberg Smith, Andreas Abou Taha & Jakob GrauslundDepartment of Ophthalmology, Malabo Regional Hospital, Malabo, Equatorial GuineaJosé Alogo Obiang ÑeheDepartment of Ophthalmology, Faculty of Medicine, Universiti Malaya, Kuala Lumpur, MalaysiaTengku Ain Kamalden, José Alogo Obiang Ñehe & Celestino Edjang Nguema MikueUniversiti Malaya Medical Centre, Kuala Lumpur, MalaysiaTengku Ain Kamalden, Tengku Ain Kamalden, Tajunisah Iqbal, Penny Lott Pooi Wah, Marium Jamaluddin Ahmad, Nurul Najieha Amir & Irina Effendi-TenangNIHR Biomedical Research Centre, Moorfields Eye Hospital NHS Foundation Trust, London, UKYukun Zhou, Tengku Ain Kamalden, Tajunisah Iqbal, Penny Lott Pooi Wah, Marium Jamaluddin Ahmad, Nurul Najieha Amir & Irina Effendi-TenangInstitute of Ophthalmology, University College London, London, UKYukun Zhou, Sobha Sivaprasad & Pearse A. KeaneDepartment of Ophthalmology and Visual Sciences, The Chinese University of Hong Kong, Hong Kong Special Administrative Region, Hong Kong, ChinaAn Ran Ran, Dawei Yang, Simon K. H. Szeto, Julia Y. Y. Chan, Victor T. T. Chan, Sobha Sivaprasad & Pearse A. KeaneSingapore Eye Research Institute, Singapore National Eye Centre, Singapore, SingaporeQingsheng Peng, Chenxi Zhang, Carol Y. Cheung, Yih-Chung Tham, Ching-Yu Cheng & Tien Yin WongCentre for Innovation and Precision Eye Health and Department of Ophthalmology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, SingaporeQingsheng Peng, Gavin Siew Wei Tan, Yih-Chung Tham & Ching-Yu ChengState Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat‐sen University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual Science, Guangzhou, ChinaYing Feng ZhengDepartment of Ophthalmology, The Eighth Affiliated Hospital of Sun Yat-sen University, Shenzhen, ChinaDingqiao WangMedical Records and Statistics Office, Shanghai Sixth People’s Hospital Affiliated to Shanghai Jiao Tong University School of Medicine, Shanghai, ChinaJie Shen & Dingqiao WangKey Laboratory of Ocular Fundus Diseases, Chinese Academy of Medical Sciences, Beijing, ChinaYouxin Chen, Weihong Yu, Chenxi Zhang & Xinyu ZhaoDepartment of Ophthalmology, Peking Union Medical College Hospital, Peking Union Medical College, Chinese Academy of Medical Sciences, Beijing, ChinaYouxin Chen, Weihong Yu, Rongping Dai, Chenxi Zhang & Xinyu ZhaoBeijing Key Laboratory of Fundus Diseases Intelligent Diagnosis & Drug/Device Development and Translation, Beijing, ChinaYouxin Chen, Weihong Yu, Rongping Dai, Chenxi Zhang, Xinyu Zhao, Shiqun Lin & Yan ZhouDepartment of Ophthalmology, Shanghai Sixth People’s Hospital Affiliated to Shanghai Jiao Tong University School of Medicine, Shanghai, ChinaXiangning Wang, Yan Chen, Qiang Wu, Shiqun Lin & Yan ZhouShenzhen Eye Hospital, Shenzhen Eye Center, Southern Medical University, Shenzhen, ChinaHongbin XieDepartment of Ophthalmology, Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, ChinaHua-Tao XieDepartment of Ophthalmology, The Second Affiliated Hospital of Naval Medical University (Shanghai Changzheng Hospital), Shanghai, ChinaRuili WeiDepartment of Ophthalmology, Renji Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, ChinaJin LiInstitute for AI Industry Research, Tsinghua University, Beijing, ChinaWeizhi MaROAS Thrust, Hong Kong University of Science and Technology (Guangzhou), Guangzhou, ChinaLei Zhu & Hongqiu WangHong Kong University of Science and Technology, Hong Kong Special Administrative Region, Hong Kong, ChinaLei ZhuInstitute of High Performance Computing, Agency for Science, Technology and Research, Singapore, SingaporeHuazhu FuKey Laboratory of River Basic Digital Twinning of Ministry of Water Resources, Macau University of Science and Technology, Macao Special Administrative Region, Taipa, ChinaWenxiao WangWuhan Bright Eye Hospital, Wuhan, ChinaShan Lin, Zejun Xu & Nian GuanThe People’s Hospital of Sixian County, Anhui, ChinaXiao ZhangInstitute for Research in Ophthalmology, Foundation for Ophthalmology Development, Poznan, PolandAndrzej GrzybowskiDepartment of Ophthalmology, University of Warmia and Mazury, Olsztyn, PolandAndrzej GrzybowskiDepartment of Ophthalmology, Pomeranian Hospitals, Wejherowo, PolandMonika Gołębiowska-Bogaj & Maciej GawęckiDepartment of Pediatric Ophthalmology, Faculty of Medical Sciences in Katowice, Medical University of Silesia, Katowice, PolandAdrian SmedowskiDepartment of Pediatric Ophthalmology, Kornel Gibinski University Clinical Center, Medical University of Silesia, Katowice, PolandAdrian SmedowskiGlaucoTech Co., Katowice, PolandAdrian SmedowskiDepartment of Ophthalmology, Faculty of Medical Sciences in Katowice, Medical University of Silesia, Katowice, PolandWojciech SzaraniecDepartment of Ophthalmology, Kornel Gibinski University Clinical Center, Medical University of Silesia, Katowice, PolandWojciech SzaraniecSchool of Healthcare Management, Tsinghua Medicine, Tsinghua University, Beijing, ChinaYou WuInstitute for Hospital Management, Tsinghua University, Beijing, ChinaYou WuGuangdong Provincial Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University, Shenzhen, ChinaYang WenDepartment of Medicine, Faculty of Medicine, Universiti Malaya, Kuala Lumpur, MalaysiaLee-Ling LimDepartment of Medicine and Therapeutics, The Chinese University of Hong Kong, Prince of Wales Hospital, Hong Kong Special Administrative Region, Hong Kong, ChinaLee-Ling LimBaker Heart and Diabetes Insitute, Melbourne, Victoria, AustraliaLee-Ling LimDepartment of Ophthalmology, Rajavithi Hospital, College of Medicine, Rangsit University, Bangkok, ThailandPaisan RuamviboonsukOphthalmology and Visual Science Academic Clinical Program (Eye ACP), Duke-NUS Medical School, Singapore, SingaporeYih-Chung ThamBeijing Key Laboratory of Intelligent Diagnostic Technology and Devices for Major Blinding Eye Diseases, Tsinghua Medicine, Tsinghua University, Beijing, ChinaTien Yin WongDepartment of Ophthalmology, Peking University Third Hospital, Beijing, ChinaBo QuDepartment of Ophthalmology, The Seventh Affiliated Hospital of Sun Yat-sen University, Shenzhen, ChinaHongzhi YuanDepartment of Ophthalmology, Guangzhou Women and Children’s Medical Center, Guangzhou, ChinaMengxiang GuoDepartment of Ophthalmology, Jiangmen People’s Hospital, Jiangmen, ChinaMing ZhouDepartment of Ophthalmology, The First Affiliated Hospital of Guangzhou Medical University, Guangzhou, ChinaWen ShiDepartment of Ophthalmology, Vestfold Hospital, Tonsberg, NorwayLars Morten SkollerudAuthorsYilan WuBo QianTingyao LiYiming QinZhouyu GuanTingli ChenYali JiaPing ZhangDian ZengSayoko MoroiRajiv RamanBenjamin Sommer ThinggaardFrederik PedersenJosé Alogo Obiang ÑeheTengku Ain KamaldenYukun ZhouYixiao JinHuating LiAn Ran RanDawei YangZiyao MengQingsheng PengYing Feng ZhengDingqiao WangHongwei JiPengxiao ZangChangchang YinJie ShenYouxin ChenWeihong YuRongping DaiChenxi ZhangXinyu ZhaoXiangning WangYan ChenQiang WuHongbin XieSimon K. H. SzetoJulia Y. Y. ChanVictor T. T. ChanHua-Tao XieRuili WeiJin LiWeizhi MaLei ZhuHongqiu WangHuazhu FuWenxiao WangShan LinZejun XuNian GuanXiao ZhangAndrzej GrzybowskiMonika Gołębiowska-BogajMaciej GawęckiAdrian SmedowskiWojciech SzaraniecYou WuYang WenXiang ChenYuanqi YaoLee-Ling LimCarol Y. CheungGavin Siew Wei TanJakob GrauslundPaisan RuamviboonsukSobha SivaprasadPearse A. KeaneYa Xing WangYih-Chung ThamChing-Yu ChengTien Yin WongBin ShengConsortiaEyeFM Global Reader Study TeamJoshua Evans, Alan Letson, Frederik Davidorf, Mona Adeli, Peter Chen, Thomas A. Mendel, Yi Huang, Xiyun Bian, Jing Wang, Xiaolong Yang, Haifang Zhang, Yihan Li, Bo Qu, Hongzhi Yuan, Mengxiang Guo, Dingqiao Wang, Ming Zhou, Wen Shi, Shiqun Lin, Yan Zhou, Jakob Grauslund, Lars Morten Skollerud, Benjamin Sommer Thinggaard, Frederik Pedersen, Bjarke Steenberg Smith, Andreas Abou Taha, José Alogo Obiang Ñehe, Celestino Edjang Nguema Mikue, Praveena Venkatakrishnan, Dhaivat Shah, Abhishek Kumar Tripathi, Dharshan Bhatt, Urvashi Kala, Abhishek Karra, Tengku Ain Kamalden, Tajunisah Iqbal, Penny Lott Pooi Wah, Marium Jamaluddin Ahmad, Nurul Najieha Amir & Irina Effendi-TenangContributionsT.Y.W. and B.S. conceived and supervised the project. T.Y.W., B.S., Yilan Wu, Z.G., D.Z. and Y.F.Z. designed the study. B. Qian, Y.Q. and P.Z. designed the deep learning algorithm and the computational framework. T.Y.W., Yilan Wu, B. Qian, T.L, Y.Q., Z.G., D.Z. and Y.F.Z. contributed to the initial drafting of the manuscript. Y.J., P.Z., Y.Z., Q.P., C.Y., J.S., A.G., M.G.-B., M.G., A.S., W.S., L.Z. and You Wu helped with data collection. S.M., R.R., B.S.T., J.A.O.Ñ., T.A.K., H.L., Y.J., A.R.R., D.Y., Z.M., D.W., Y.C., W.Y., R.D., X. Zhao, C.Z., X.W., Y.C., Q.W., H.X., S.K.H.S., J.Y.Y.C., V.T.T.C., H.-T.X., R.W., J.L., Shan Lin, Z.X., N.G., J.E., A.L., F.D., MA., P.C., T.A.M., Y.H., Y.Z., Shiqun Lin, X.B., J.W., X.Y., H.Z., Y.L, B. Qu, H.Y., M.G., M.Z., W.S., L.M.S., F.P., B.S.S., A.A.T., C.E.N.M., P.V., D.S., A.K.T., D.B., U.K., A.K., T.I., P.L.P.W., M.J.A., N.N.A. and I.E.-T. participated in prospective validations. T.C., X. Zhang, Y.H., X.B., J.W., X.Y., H.Z. and Y.L. conducted the data collection and analysis in the RCT. J.G., P.R., S.S., P.A.K., L.-L.L., C.Y.C., G.S.W.T., Y.X.W., Y.-C.T., C.-Y.C., Y.F.Z., B.S. and T.Y.W. contributed to collaboration organization and provided critical revision of the manuscript for important intellectual content. All authors provided critical comments and reviewed the manuscript. All authors discussed the results and approved the final version before submission.Corresponding authorsCorrespondence to
                Tien Yin Wong or Bin Sheng.Ethics declarations
            
              Competing interests
              Y.J. is a patent holder of Optovue/Visionix, Inc., Optos plc and Genentech, Inc. She receives financial support from Genentech, Inc., and she receives financial compensation from Optovue/Visionix, Inc. and Genentech, Inc. P.A.K. is a co-founder of Cascader Ltd., has acted as a consultant for Retina Consultants of America, Roche, Boehringer Ingleheim and Bitfount and is an equity owner in Big Picture Medical. He has received speaker fees from Zeiss, Thea, Apellis and Roche. He has received travel support from Bayer and Roche. He has attended advisory boards for Topcon, Bayer, Boehringer Ingleheim and Roche. T.Y.W. is a consultant for AbbVie Pte Ltd., Aldropika Therapeutics, Bayer, Boehringer Ingelheim, Zeiss, Genentech, Iveric Bio, Novartis, Opthea Limited, Plano, Quaerite Biopharm Research Ltd., Roche, Sanofi and Shanghai Henlius. He is an inventor, holds patents and is a co-founder of start-up companies EyRiS and Visre, which have interests in, and develop digital solutions for, eye diseases. All potential conflicts of interests for consultancy, advisory boards and positions in the start-up companies and financial renumeration, if any, are managed by institutional policies under SingHealth and Tsinghua University. The other authors declare no competing interests.
            
          Peer review
            
            
              Peer review information
              Nature Medicine thanks Tae Keun Yoo and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Primary Handling Editor: Lorenzo Righetto, in collaboration with the Nature Medicine team.
            
          Additional informationPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Extended dataExtended Data Fig. 1 Envision the use case of EyeFM as a whole workflow copilot for eyecare under different clinical settings.For patients attending ocular disease screening in the primary care centre where only low-cost examination technics are available, EyeFM can use its single modality and cross-modality ability to assist disease detection, followed with screening report writing assisted by its vision-question answering ability. Then, some patients will be referred to specialty care settings for further examination, where EyeFM can use its integrated modality disease detection or even zero-shot ability to facilitate further diagnosis. The image-report writing ability and vision-question answering can also assist to improve the efficiency of clinical report and patient letter drafting in specialty care settings.Extended Data Fig. 2 The structural diagram of human-knowledge encoding in pretraining and application phase for EyeFM.a) The diagram of pretraining process for EyeFM. EyeFM was first pretrained for its image encoder with five modalities of images, then conducted vision-language joint pretraining. The image module includes one encoder and five decoders. The encoder comprises 24 Transformer blocks. Each decoder comprises two Transformer blocks. The linear projection layer is implemented with a single convolutional layer. In the vision-language module, the projection is implemented using a single linear layer, which serves to connect the image encoder with the language module. The language module is based on LLaMA 2 architecture with 7 billion parameters. b) The diagram of human-in-the-loop process for EyeFM. EyeFM human-in-the-loop utilized DPO and federated learning for distributed knowledge evolution.Extended Data Fig. 3 Glossary table and the clinical tasks related with each validation experiment.First, we conducted retrospective validations, comparing EyeFM with prior benchmarks of medical foundation models. This step serves as the foundation for evaluating the model’s performance and safety when progressing to clinical applications. Second, we conducted reader studies and real-world study prospectively to test the efficiency of EyeFM as a clinical copilot to assist ophthalmologists. This step bridged the gap between the performance of the model its own and its efficiency when applicated by clinicians. At last, we validated EyeFM with a Randomised Controlled Trial (RCT). Colored chart, above, validation experiments and their corresponding relationship with the functions of EyeFM. The x-axis represents different tasks of EyeFM and y-axis represents validation experiments. Cells were coloured if the experiments have validated corresponding functions. Below, glossary table of the tasks, clinical scenario and experiments. RCT, randomised controlled trial.Extended Data Fig. 4 Experiment 1 – Retrospective validation of EyeFM on multi-ethnic datasets.a) For disease detection on CFP, the sample sizes and P values are: DR (n = 1501, P = 0.042), glaucoma suspect (n = 405, P = 0.533), AMD suspect (n = 370, P = 0.627), MMD (n = 643, P = 0.030). For disease detection on OCT, the sample sizes and P values are: ciDME (n = 523, P = 0.002), glaucoma (n = 412, P = 0.333), AMD (n = 379, n = 0.036). The sample size for cataract detection on external eye photo was 198 and the P value was 0.102. Error bars represent 95% CI. b)Segmentation dice similarity coefficient. The sample size for segmentation on CFP are: HE (n = 13), SE (n = 14), HM (n = 27) and MA (n = 27). The P value for haemorrhages was 0.083. The sample size was 759 for OCT segmentation. Error bars represent 95% CI. c) Cross-modality disease detection of ciDME that usually need to be diagnosed by OCT with CFP inputs only (left), the sample size was 405 and the P value was <0.001. Cross-modality disease detection of wet-AMD that usually need to be diagnosed by CFP with external eye photo inputs (right) the sample size was 332 and the P value was 0.583. Boxes indicate quartile values and whiskers indicate 1.5×the interquartile range. d) Image-report generation, model performance was evaluated by automatic metrics labelled as the x-axis. The sample size was 500. Boxes indicate quartile values and whiskers indicate 1.5× the interquartile range. e) Head-to-head comparison of answers generated by EyeFM and ophthalmologists, the measurement was summed score for quality, safety and empathy, ranged from 3–15 scores. Presented as Kernel Density Plot. The sample size was 300 for EyeFM and 1200 for ophthalmologists. P values were calculated with two-sided t-test between EyeFM and the better-performed reference model. *** denotes P < 0.001, n.s. represents P > 0.05. CFP, colour fundus photo; OCT, optical coherence tomography; EEP, external eye photo; DR, diabetic retinopathy; DME, diabetic macular oedema; AMD, age-related macular degeneration; MMD, myopic macular degeneration; MA, microaneurysms; HE, hard exudates; HM, haemorrhages; SE, soft exudates.Source dataExtended Data Fig. 5 Workflow for the diagnostic study and management study in the RCT.Participants included in the trial will first receive diagnosis and report by ophthalmologists by CFP, then receive additional OCT examinations for consultant-level reviewers to assess and revise the diagnosis and report. All diagnosis and reports before revision by consultant-level reviewers will be included in the analysis for correct diagnosis rate, correct referral rate and standardization score of reports. Only participants that are correctly diagnosed as ‘with fundus abnormality’ will be included in the follow-up for patient compliance analysis. CFP, colour fundus photo; OCT, optical coherence tomography.Extended Data Table 1 Demographic characteristics of eyecare providers who participated in EyeFM validationFull size tableRights and permissionsSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.Reprints and permissionsAbout this articleCite this articleWu, Y., Qian, B., Li, T. et al. An eyecare foundation model for clinical assistance: a randomized controlled trial.
                    Nat Med  (2025). https://doi.org/10.1038/s41591-025-03900-7Download citationReceived: 24 October 2024Accepted: 16 July 2025Published: 28 August 2025DOI: https://doi.org/10.1038/s41591-025-03900-7
            ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Space Shuttle Columbia disaster and the over-reliance on PowerPoint (2019)]]></title>
            <link>https://mcdreeamiemusings.com/blog/2019/4/13/gsux1h6bnt8lqjd7w2t2mtvfg81uhx</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45057404</guid>
            <description><![CDATA[We’ve all sat in those presentations.  A speaker with a stream of slides full of text, monotonously reading them off as we read along.  We’re so used to it we expect it.  We accept it.  We even consider it ‘learning’. As an educator I push against ‘death by PowerPoint’ and I'm fascinated with how we]]></description>
            <content:encoded><![CDATA[

      

      

      
        
          
            
              
            
          
        
      


      
      
      

      
        
        

  
  

    

    

      

      
        
          
        
        

        
          
            
          
        

        
          
          
            The space shuttle Columbia disintegrating in the atmosphere (Creative Commons)
          
        
      
        
      

    
  We’ve all sat in those presentations.  A speaker with a stream of slides full of text, monotonously reading them off as we read along.  We’re so used to it we expect it.  We accept it.  We even consider it ‘learning’. As an educator I push against ‘death by PowerPoint’ and I'm fascinated with how we can improve the way we present and teach.  The fact is we know that PowerPoint kills.  Most often the only victims are our audience’s inspiration and interest.  This, however, is the story of a PowerPoint slide that actually helped kill seven people.January 16th 2003.  NASA Mission STS-107 is underway. The Space Shuttle Columbia launches carrying its crew of seven to low orbit.  Their objective was to study the effects of microgravity on the human body and on ants and spiders they had with them.  Columbia had been the first Space Shuttle, first launched in 1981 and had been on 27 missions prior to this one.  Whereas other shuttle crews had focused on work to the Hubble Space Telescope or to the International Space Station this mission was one of pure scientific research.  The launch proceeded as normal.  The crew settled into their mission.  They would spend 16 days in orbit, completing 80 experiments.  One day into their mission it was clear to those back on Earth that something had gone wrong.  As a matter of protocol NASA staff reviewed footage from an external camera mounted to the fuel tank.  At eighty-two seconds into the launch a piece of spray on foam insulation (SOFI) fell from one of the ramps that attached the shuttle to its external fuel tank.  As the crew rose at 28,968 kilometres per hour the piece of foam collided with one of the tiles on the outer edge of the shuttle’s left wing.  


      

      
        
          
        
        

        
          
            
          
        

        
          
          
            Frame of NASA launch footage showing the moment the foam struck the shuttle’s left wing (Creative Commons)
          
        
      
        
      

    
  It was impossible to tell from Earth how much damage this foam, falling nine times faster than a fired bullet, would have caused when it collided with the wing.   Foam falling during launch was nothing new.  It had happened on four previous missions and was one of the reasons why the camera was there in the first place.  But the tile the foam had struck was on the edge of the wing designed to protect the shuttle from the heat of Earth’s atmosphere during launch and re-entry.  In space the shuttle was safe but NASA didn’t know how it would respond to re-entry.  There were a number of options.  The astronauts could perform a spacewalk and visually inspect the hull.  NASA could launch another Space Shuttle to pick the crew up.  Or they could risk re-entry.  NASA officials sat down with Boeing Corporation engineers who took them through three reports; a total of 28 slides.    The salient point was whilst there was data showing that the tiles on the shuttle wing could tolerate being hit by the foam this was based on test conditions using foam more than 600 times smaller than that that had struck Columbia.  This is the slide the engineers chose to illustrate this point:

  NASA managers listened to the engineers and their PowerPoint.  The engineers felt they had communicated the potential risks.  NASA felt the engineers didn’t know what would happen but that all data pointed to there not being enough damage to put the lives of the crew in danger.  They rejected the other options and pushed ahead with Columbia re-entering Earth’s atmosphere as normal.  Columbia was scheduled to land at 0916 (EST) on February 1st 2003.  Just before 0900, 61,170 metres above Dallas at 18 times the speed of sound, temperature readings on the shuttle’s left wing were abnormally high and then were lost.  Tyre pressures on the left side were soon lost as was communication with the crew.  At 0912, as Columbia should have been approaching the runway, ground control heard reports from residents near Dallas that the shuttle had been seen disintegrating.  Columbia was lost and with it her crew of seven.  The oldest crew member was 48.  The shuttle programme was on lock down, grounded for two years as the investigation began.  The cause of the accident became clear: a hole in a tile on the left wing caused by the foam let the wing dangerously overheat until the shuttle disintegrated.  The questions to answer included a very simple one: Why, given that the foam strike had occurred at a force massively out of test conditions had NASA proceeded with re-entry?  Edward Tufte, a Professor at Yale University and expert in communication reviewed the slideshow the Boeing engineers had given NASA, in particular the above slide.  His findings were tragically profound.


 Firstly, the slide had a misleadingly reassuring title claiming that test data pointed to the tile being able to withstand the foam strike.  This was not the case but the presence of the title, centred in the largest font makes this seem the salient, summary point of this slide.  This helped Boeing’s message be lost almost immediately.























  Secondly, the slide contains four different bullet points with no explanation of what they mean.  This means that interpretation is left up to the reader.  Is number 1 the main bullet point?  Do the bullet points become less important or more?  It’s not helped that there’s a change in font sizes as well.  In all with bullet points and indents six levels of hierarchy were created.  This allowed NASA managers to imply a hierarchy of importance in their head: the writing lower down and in smaller font was ignored.  Actually, this had been where the contradictory (and most important) information was placed.  


Thirdly, there is a huge amount of text, more than 100 words or figures on one screen.   Two words, ‘SOFI’ and ‘ramp’ both mean the same thing: the foam.  Vague terms are used.  Sufficient is used once, significant or significantly, five times with little or no quantifiable data.  As a result this left a lot open to audience interpretation.  How much is significant?  Is it statistical significance you mean or something else?  
























Finally the single most important fact, that the foam strike had occurred at forces massively out of test conditions, is hidden at the very bottom.  Twelve little words which the audience would have had to wade through more than 100 to get to.  If they even managed to keep reading to that point.  In the middle it does say that it is possible for the foam to damage the tile.  This is in the smallest font, lost. 























  NASA’s subsequent report criticised technical aspects along with human factors.  Their report mentioned an over-reliance on PowerPoint: “The Board views the endemic use of PowerPoint briefing slides instead of technical papers as an illustration of the problematic methods of technical communication at NASA.”  Edward Tufte’s full report makes for fascinating reading. Since being released in 1987 PowerPoint has grown exponentially to the point where it is now estimated than thirty million PowerPoint presentations are made every day.  Yet, PowerPoint is blamed by academics for killing critical thought.  Amazon’s CEO Jeff Bezos has banned it from meetings.   Typing text on a screen and reading it out loud does not count as teaching.  An audience reading text off the screen does not count as learning.  Imagine if the engineers had put up a slide with just: “foam strike more than 600 times bigger than test data.”  Maybe NASA would have listened.  Maybe they wouldn’t have attempted re-entry.  Next time you’re asked to give a talk remember Columbia. Don’t just jump to your laptop and write out slides of text.  Think about your message.  Don’t let that message be lost amongst text.  Death by PowerPoint is a real thing.  Sometimes literally.Thanks for reading - Jamie 


      

      
        
          
        
        

        
          
            
          
        

        
          
          
            Columbia’s final crew (from https://www.space.com/19436-columbia-disaster.html)
          
        
      
        
      

    

    

    

  

  

  

  
  
  


        
        
      

      

      

    ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Sometimes CPU cores are odd]]></title>
            <link>https://anubis.techaro.lol/blog/2025/cpu-core-odd/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45057346</guid>
            <description><![CDATA[TL;DR: all the assumptions you have about processor design are wrong and if you are unlucky you will never run into problems that users do through sheer chance.]]></description>
            <content:encoded><![CDATA[Protected by Anubis From Techaro. Made with ❤️ in 🇨🇦.Mascot design by CELPHASE.This website is hosted by Techaro. If you have any complaints or notes about the service, please contact support@techaro.lol and we will assist you as soon as possible.
-- ImprintThis website is running Anubis version v1.22.0-pre1-8-g21c3e0c.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Expert: LSP for Elixir]]></title>
            <link>https://github.com/elixir-lang/expert</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45057322</guid>
            <description><![CDATA[Official Elixir Language Server Protocol implementation - elixir-lang/expert]]></description>
            <content:encoded><![CDATA[Expert
Expert is the official language server implementation for the Elixir programming language.
Installation
You can download Expert from the releases page for your
operating system and architecture. Put the executable somewhere on your $PATH, like ~/.local/bin/expert
For editor specific installation instructions, please refer to the Installation Instructions
Nightly Builds
If you want to try out the latest features, you can download a nightly build.
Using the GH CLI, you can run the following command to download the latest nightly build:
gh release download nightly --pattern 'expert_linux_amd64' --repo elixir-lang/expert
Then point your editor to the downloaded binary.
Building from source
To build Expert from source, you need Zig 0.14.1 installed on your system.
Then you can run the following command or follow the instructions in the Installation Instructions:
just release-local
This will build the Expert binary and place it in the apps/expert/burrito_out directory. You can then point your
editor to this binary.
Sponsorship
Thank you to our corporate sponsors! If you'd like to start sponsoring the project, please read more below.






Corporate
For companies wanting to directly sponsor full time work on Expert, please reach out to Dan Janowski: EEF Chair of Sponsorship WG at danj@erlef.org.
Individual
Individuals can donate using GitHub sponsors. Team members are listed in the sidebar.
Other resources

Architecture
Development Guide
Glossary
Installation Instructions

LICENSE
Expert source code is released under Apache License 2.0.
Check LICENSE file for more information.
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fuck up my site – Turn any website into beautiful chaos]]></title>
            <link>https://www.fuckupmysite.com/?url=https%3A%2F%2Fnews.ycombinator.com&amp;torchCursor=true&amp;comicSans=true&amp;fakeCursors=true&amp;peskyFly=true</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45057020</guid>
            <description><![CDATA[PARODY/ENTERTAINMENT ONLY: Transform any website into pure chaos. Add burning cursors, Comic Sans everything, fake cursors, and more chaos features to any site. A humorous parody tool - not for real use. Some people just want to watch the web burn.]]></description>
            <content:encoded><![CDATA[This tool is for parody and entertainment purposes only. It temporarily applies visual chaos effects to websites for comedic effect. We do not store, collect, or transmit any personal information.NEVER enter passwords, credit card details, or any sensitive information while using this tool. The proxied sites are not secure and should not be used for any real transactions or logins.By using this tool, you acknowledge that it's purely for entertainment and you will not enter any sensitive data. Banking, financial, healthcare, and government sites are blocked for safety.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[You no longer need JavaScript: an overview of what makes modern CSS so awesome]]></title>
            <link>https://lyra.horse/blog/2025/08/you-dont-need-js/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45056878</guid>
            <description><![CDATA[An overview of what makes modern CSS so awesome.]]></description>
            <content:encoded><![CDATA[
    
  
  2025-08-28  ¦ css


  So much of the web these days is ruined by the bloat that is modern JavaScript frameworks. React apps that take several seconds to load. NextJS sites that throw random hydration errors. The node_modules folder that takes up gigabytes on your hard drive.
It’s awful. And you don’t need it.




  
    
      Name
      Status
      Type
      Size
      Time
    
  
  
    app200document153.8 kB51 ms
    6920616d20612066-s.p.6f6e7421.woff2200font31.5 kB32 ms
    686579206d652074-s.p.6f6f2121.woff2200font28.5 kB116 ms
    77687920646f6573.css200stylesheet253 kB47 ms
    2074686520646566.js200script648 kB83 ms
    61756c74206e6578.js200script166 kB363 ms
    746a732074616b65.js200script83.3 kB46 ms
    turbopack-20757020302e354d.js200script38.0 kB95 ms
    423f207468617427.js200script414 B34 ms
    73206d6f72652074.js200script32.6 kB49 ms
    68616e206d792065.js200script15.1 kB71 ms
    6e7469726520626c.js200script143 kB48 ms
    6f6721 hey there!200script4.1 kB103 ms
  



The intro paragraph of this post is tongue-in-cheek. It’s there to get you to read the rest of the post. I suspect the megabytes of tracking scripts intertwined with bad code is far more likely to be the real culprit behind all the terrible sites out there. Web frameworks have their time and place. And despite my personal distaste for them, I know they are used by many teams to build awesome well-optimized apps.
Despite that, I think there’s some beauty in leaving it all behind. Not just the frameworks, but JavaScript altogether. Not every site needs JavaScript. Perhaps your e-commerce site needs it for its complex carts and data visualization dashboards, but is it really a necessity for most of what’s out there?
It’s actually pretty incredible what HTML and CSS alone can achieve.

So, what do you say?
My goal with this article is to share my perspectives on the web, as well as introduce many aspects of modern HTML/CSS you may not be familiar with. I’m not trying to make you give up JavaScript, I’m just trying to show you everything that’s possible, leaving it up to you to pick what works best for whatever you’re working on.
I think there’s a lot most web developers don’t know about CSS.
And I think JS is often used where better alternatives exist.
So, let me show you what’s out there.

“But CSS sucks”
I believe a lot of the negativity towards CSS stems from not really knowing how to use it. Many developers kind of just skip learning the CSS fundamentals in favor of the more interesting Java- and TypeScript, and then go on to complain about a styling language they don’t understand.
I suspect this is due to many treating CSS as this silly third wheel for adding borders and box-shadows to a webapp. It’s undervalued and often compared to glorified crayons, rather than what it really is - a powerful domain-specific programming language.
It’s telling when to this day the only CSS joke in the webdev circles is centering a div.


i am a div

body {  display: flex;  flex-direction: rowcolumnrow-reversecolumn-reverse;  flex-wrap: nowrapwrap;  align-content: centerflex-startflex-endspace-aroundspace-betweenstretch;  justify-content: centerflex-startflex-endspace-aroundspace-betweenspace-evenly;  align-items: centerflex-startflex-endstretchbaseline;}




Yes, the syntax isn’t the prettiest, but is it really that hard?
Besides, your devtools probably1 come with a fun little gadget that lets you fiddle with the flexbox by just clicking around. You don’t even need to remember the syntax.

I don’t think CSS is fundamentally any more difficult than JS, but if you skip the basics on one and only focus on the other, it’s no surprise it feels that way.
“But it’s painful to write”
Another source of disdain for CSS is how awful it has been to write in the past. This is very much true, and is probably why things like Sass and Tailwind2 exist.
But that’s the thing, it used to be bad.



🦊


Rebane@rebane2001
btw u should write css like

cool-thing {
    display: flex;
    &[shadow] {
        box-shadow: 1px 1px #0007;
    }
    @media (width < 480px) {
        flex-direction: column;
    }
}

and html like

<cool-thing shadow>wow</cool-thing>

because it's allowed & modern & neat!
11:58 AM · Apr 8, 2025

❤️ 1.5K


(yes! the code above is standards compliant3)
In the past few years, CSS has received a ton of awesome quality-of-life additions, making it nice to do stuff that has historically required preprocessors or JavaScript.
Nesting is definitely one of my favorite additions!
In the past, you’ve had to write code that looks like this:
:root {
  --like-color: #24A4F3;
  --like-color-hover: #54B8F5;
  --like-color-active: #0A6BA8;
}

.post {
  display: block;
  background: #EEE;
  color: #111;
}

.post .avatar {
  width: 48px;
  height: 48px;
}

.post > .buttons {
  display: flex;
}

.post > .buttons .label {
  font-size: 24px;
  padding: 8px;
}

.post > .buttons .like {
  cursor: pointer;
  color: var(--like-color);
}

.post > .buttons .like:hover {
  color: var(--like-color-hover);
}

.post > .buttons .like:active {
  color: var(--like-color-active);
}

@media screen (max-width: 800px) {
  .post > .buttons .label {
    font-size: 16px;
    padding: 4px;
  }
}

@media (prefers-color-scheme: dark) {
  .post {
    background: #222;
    color: #FFF;
  }
}


And yeah, that’s pretty awful to work with. For anything that involves multiple chained selectors, you kind of have to keep a mental map of how every parent selector relates to its children, and the more CSS you add the harder it gets.
But let’s try it with nesting:
:root {
  --like-color: #24A4F3;
  --like-color-hover: hsl(from var(--like-color) h s calc(l + 10));
  --like-color-active: hsl(from var(--like-color) h s calc(l - 20));
}

.post {
  display: block;
  background: #EEE;
  color: #111;
  @media (prefers-color-scheme: dark) {
    background: #222;
    color: #FFF;
  }
  .avatar {
    width: 48px;
    height: 48px;
  }
  & > .buttons {
    display: flex;
    .label {
      font-size: 24px;
      padding: 8px;
      @media (width <= 800px) {
        font-size: 16px;
        padding: 4px;
      }
    }
    .like {
      cursor: pointer;
      color: var(--like-color);
      &:hover { color: var(--like-color-hover); }
      &:active { color: var(--like-color-active); }
    }
  }
}

That is way nicer to read4! All the relevant parts are right next to each other, so it’s a lot easier to understand what’s going on. Seeing the &:hover and &:active right next to the .like button is especially nice imo.
And since you can sort of see the structure - the parent selectors “guarding” the child ones - it also makes it a lot easier to get away with short and simple class names (or even referring to elements themselves).
You may have noticed that I’m also making use of relative colors in the second example. I think the MDN article has a lot of awesome examples, but the jist of it is that you can take an existing color, modify it in many different ways across multiple color spaces, and mix it with other colors using color-mix().
/* remove blue from a color */
rgb(from #123456 r g 0);
/* make a color transparent */
rgb(from #123456 r g b / 0.5);
/* make a color lighter */
hsl(from #123456 h s calc(l + 10));
/* change the hue in oklch color space */
oklch(from #123456 l c calc(h + 10));
/* mix two colors in oklab color space */
color-mix(in oklab, #8CFFDB, #04593B 25%);

These snippets are really useful for when you want something to be just ever so slightly darker or brighter, such as a button hover effect or a matching border color, and they’re way nicer to use than doing all those color conversions in JavaScript. If you’re feeling particularly adventurous, you could even go ahead and generate your entire color scheme in just CSS.

100200300400500600700800900
-40°-20°0°+20°+40°
primarycomplimentarysecondary
successdangerwarninginfo

view-source


(yes! the color picker above is written in just css)
Safari is currently broken when handling of cqw/cqh units, therefore the demo above may not work correctly. If this happens, try using Firefox or Chrome instead.
There are so many cool new CSS features that make writing it just that little bit nicer. Things like letting you use (width <= 768px) instead of (max-width: 768px) in your @media query, the lh unit that matches the line-height, the scrollbar-gutter property that solves the little scrollbar-related layout shifts, or the ability to finally center stuff vertically without flex/grid.


Baseline
And all of this is brought together by the cherry on top that is Baseline. It’s a guarantee that a specific feature works in every major browser5, and it also lets you know since when - newly available features work in all the latest browsers, and widely available ones work in browsers up to 2.5 years old. Nesting, for example, has been fully supported in all browsers since December 2023, and thus will become widely available in June 2026. You can find the Baseline symbols in various places, such as the MDN docs6.
These are just a few examples of what makes modern CSS so much nicer to write than what we had even just 5 years ago. It almost feels like comparing ES37 to ECMAScript 2025 - and I wouldn’t blame your grudge if the former is what you’re used to.
Why bother?
Okay, so CSS has more quality-of-life stuff than before. Still, why would one choose to use it over something else? Doesn’t JavaScript already let us do everything just fine?
You need to disable JavaScript to run this app.
I think my reasons for using CSS fall into two main categories - because some users don’t want to use JavaScript, and because doing things in CSS can be genuinely better.
My blog, for example, focuses on infosec topics. Many security researchers (myself included) use a hardened browser configuration to protect themselves, which often means disabling JavaScript by default. I think it’s nice that they can fully experience my blog without changing their security settings or running a separate, sandboxed browser.
The same goes for privacy-conscious users, and it makes sense! As an experiment, I opened up a local Estonian news site in a web browser with JavaScript enabled. Can you guess how many js files it fetched? (answer in footnote8) That’s crazy! You do not want that running on your computer.
But surely, you are not one of the evil devs who loads a double-digit number of analytics scripts on your site - is there still any reason to reach for CSS?
Well, I think a lot of things are just plain nicer to make in HTML/CSS, both from the developer and end-user perspectives, be it for ease of use, accessibility, or performance.
Hover effects for your buttons? Toast animations? Input validation? All of these things just work in CSS, and you won’t have to reinvent the wheel, or throw kilobytes of someone else’s code at it. There will always be some cases where you do need that extra flexibility JavaScript often provides, but if you don’t need that, and doing it in CSS is easier, then why not save yourself the trouble?


  
  
  
  
  
  
  
  
  
  
  
  













And the performance of CSS is so much better! Every JavaScript interaction has to go through an event loop that wastes CPU cycles, eats some battery, and adds that tiny bit of stutter to everything.
Sure, in the grand scale of things it isn’t that bad, APIs like requestAnimationFrame are really good at keeping things smooth. But CSS animations run in the separate compositor thread, and aren’t affected by stutters and blocking in the event loop.
It makes quite a difference on low-end devices, but feels nice even on high-end ones. CSS animations on my 240hz monitor look amazing9 - JS can look pretty good too, but it has that tiny bit of stutter to it that keeps it from being perfect, especially if you plan on running other heavy code at the same time.
It also means you won’t have to worry as much about optimization, as the browser takes care of a lot more of the rendering side of things, and often runs your stuff on the GPU if possible.
Pro tip! Wanna trigger animations from JS anyways? Use the modern Web Animations API to easily play the smooth CSS animations from JS.
Transitioning

Speaking of which, I think it’s time I start showing you practical examples, and a good place to start showing the styles is well, @starting-style.
In the past it has been pretty annoying to add start animations (such as fade-ins) to elements. You’ve had to either set up an entire CSS animation with a separate @keyframes block to go with it, or do a transition using JavaScript where you first add an element to the page, then wait a frame, and then add a class to the element.
.toast {
  transition: opacity 1s, translate 1s;
  opacity: 1;
  translate: 0 0;
  @starting-style {
    opacity: 0;
    translate: 0 10px;
  }
}
Success!

But this has all changed thanks to the new @starting-style at-rule!
Pretty much all you have to do is set your properties as usual, add the initial transition states to @starting-style, and add those properties to a transition. It’s pretty simple and it kind of just works without having to trigger the animation in any way.
Lunalover
Another good example of where CSS shines is theming. Many sites need separate light and dark modes, and modern CSS makes dealing with that pretty easy.
:root {
  color-scheme: light dark;
  --text: light-dark(#000, #FFF);
  --bg: light-dark(#EEE, #242936);
}
hi there!you are awesome!i am!

By setting the color-scheme property to light dark, you are telling the browser to automatically pick the theme according to the user preference, and you can then make use of that by setting color values with the light-dark() function.
Not only does it set your own colors, but also those of the native components, such as the default buttons, form elements, and scrollbars. It kind of just makes stuff work by default, and that’s nice!
:root {
  color-scheme: light dark;
  &:has(#theme-light:checked) {
    color-scheme: light;
  }
  &:has(#theme-dark:checked) {
    color-scheme: dark;
  }
}

    Auto
    Light
    Dark
  

You can then add some way of overriding the color-scheme property to let the user pick a theme different from their system setting. Here I am using radio buttons to accomplish that.
Pro tip! CSS can’t save the theme preference, but you can still do progressive enhancement. Make the themes work CSS-only, and then add the saving/loading of preference as an optional extra in JavaScript or server-side code.
Lyres and accordions
“But those don’t look like radio buttons” I hear you cry.
Input elements such as radio buttons and checkboxes are a great foundation to build other stuff on top of - the example above consists of labels for the buttons and invisible radio buttons that can be checked for with the :checked pseudo-class.
<radio-picker aria-label="Radio buttons example" role="radiogroup">
  <label><input type="radio" name="demo" id="veni" checked>veni</label>
  <label><input type="radio" name="demo" id="vidi">vidi</label>
  <label><input type="radio" name="demo" id="vici">vici</label>
</radio-picker>
<style>
  radio-picker {
    display: flex;
    label {
      &:has(input:checked) {
        box-shadow: inset 0px 0px 8px 0px #888;
      }
      &:has(input:focus-visible) {
        outline: 2px solid #000;
      }
      box-shadow: inset 0px 0px 1.2px 0px #000;
      padding: 10px;
      cursor: pointer;
      background: #0002;
      &:hover { background: #0004; }
      &:active { background: #0006; }
    }
    input {
      /* To allow screen reader to still access these. */
      opacity: 0;
      position: absolute;
      pointer-events: none;
    }
  }
</style>


    veni
    vidi
    vici
  

This is how I made the theme selector from the previous example. I’ve made the radio buttons half-visible in the demo for clarity, but with the opacity: 0 they would not actually be visible.
There’s a whole lot going on here, so let’s break it down.
<radio-picker aria-label="Radio buttons example" role="radiogroup">

We start off with the radio-picker element - I just made it up, you can use a div instead if you’d prefer. We give it an aria-label to give the group an accessible name, and the aria role of radiogroup to make it work as a group for the radio buttons.
You could also use the fieldset element instead of doing the aria roles if that’d fit your use case better.
<label><input type="radio" name="demo" id="veni" checked>veni</label>
<label><input type="radio" name="demo" id="vidi">vidi</label>
<label><input type="radio" name="demo" id="vici">vici</label>

Next, we add the radio buttons with their respective labels - usually you’d have to use the for attribute on labels to define which element they’re referring to, but since we have the input inside the label we don’t have to do that.
All the type="radio" inputs should also have a name value set to the same thing so that they are grouped together (you still need10 the radiogroup though). And then you can give them values or ids however you want.
label {
  &:has(input:checked) {
    box-shadow: inset 0px 0px 8px 0px #888;
  }
  &:has(input:focus-visible) {
    outline: 2px solid #000;
  }
  box-shadow: inset 0px 0px 1.2px 0px #000;
  padding: 10px;
  cursor: pointer;
  background: #0002;
  &:hover { background: #0004; }
  &:active { background: #0006; }
}

We then style the labels as we wish - the :hover and :active pseudo-classes can be used to make the buttons more fun to click, the :has(input:checked) selector can be used to define the style of the selected button, and the :has(input:focus-visible) selector can be used to add an outline when someone tabs over to the button.
The difference between :focus and :focus-visible is that the former shows up even if you use your mouse, while the latter only shows up when you use keyboard navigation, so it’s often visually more clean to use the latter.
input {
  opacity: 0;
  position: absolute;
  pointer-events: none;
}

And last, we make the radio button input exist while not being visible. This is a bit hacky, but it’s how you can keep this control accessible to keyboard navigation and screen readers.
And that’s how we get the cool-looking radio buttons!
<radio-tabs>
  <div tabindex=0 id="tab-veni">veni...</div>
  <div tabindex=0 id="tab-vidi">vidi...</div>
  <div tabindex=0 id="tab-vici">vici...</div>
</radio-tabs>
<style>
  body:has(#veni:not(:checked)) #tab-veni,
  body:has(#vidi:not(:checked)) #tab-vidi,
  body:has(#vici:not(:checked)) #tab-vici {
    display: none;
  }
</style>

    veni
    vidi
    vici


  veni/ˈveɪni/(intransitive) to come
  vidi/ˈviːdi/(intransitive) to see
  vici/ˈviːt͡ʃi/(intransitive) to conquer


We can now use them in the CSS however we want by just seeing if they’re :checked. Here I made tabs with separate divs for the content by using a :has selector on a parent element to find out which radio button is currently selected.
The :has selector has to be on a parent element that contains both the radio button and the target element - you can simply use html or body if you want it to work across the entire page. You should never use something like :has(…) by itself as it’ll run the selector for every element of the page, which can cause performance issues (body:has(…) is okay).
<div>
  <details name="deets">
    <summary>What's your name?</summary>
    My name is Lyra Rebane.
  </details>
  <details name="deets">
    ...
  </details>
</div>
<style>
  div {
    border: 1px solid #AAA;
    border-radius: 8px;
    /* based on the MDN example */
    summary {
      font-weight: bold;
      margin: -0.5em -0.5em 0;
      padding: 0.5em;
      cursor: pointer;
    }
    details {
      &:last-child { border: none }
      border-bottom: 1px solid #aaa;
      padding: 0.5em 0.5em 0;
      &[open] {
        padding: 0.5em;
        summary {
          border-bottom: 1px solid #aaa;
          margin-bottom: 0.5em;
        }
      }
    }
  }
</style>

  
    
    What's your name?My name is Lyra Rebane.
    Cool name!I know ^_^
    Where can I learn more?On my website, lyra.horse!
  


Finally, before we move on, I want to give you a quick introduction to the details element. It’s great for if you want an accordion-style menu, such as for a FAQ section. The details open and close independently of each other, but you can set their name attribute to the same value to have only one open at a time.
Using them is pretty easy, put your content and a summary tag inside a details tag, and put the title inside the summary tag. The example above is a bit more convoluted for the visual flair, but all you really need is the html part of it.
The details elements are pretty stylable! You can add animations depending on the [open] state, and you can also get rid of the arrow by setting list-style: none on the summary.
Also, ctrl+f works with it, which is a big win in my book!
Validation
And lastly, I want to show you the power of input validation in HTML and CSS.
<label for="usrname">Username</label>
<input type="text" id="usrname" pattern="\w{3,16}" required>
<small>3-16 letters, only alphanum and _.</small>
<style>
 input:valid {
   border: 1px solid green;
 }
 input:invalid {
   border: 1px solid red;
 }
</style>

  Username
    
    3-16 letters, only alphanum and _.
  


This is a simple example of how you can validate an input field with a regex pattern. If you set a pattern attribute like above, a form that contains the input cannot be submitted unless the field matches the pattern. If you’re submitting something like an e-mail address, a phone number, or a url, it might make sense to use the respective input types instead of writing your own regex.
Now, where CSS comes in is styling the input to show whether its value is valid. In the example above, I’m using :valid and :invalid to set a border color, but that comes with the downside of always having your input marked, even if the user hasn’t entered anything yet.
input {
  border: none;
  border-radius: 2px;
  outline: 1px solid #000;
  &:focus { outline-width: 2px; }
  &:user-valid { outline-color: green; }
  &:user-invalid { outline-color: red; }
}

  Username
    
    3-16 letters, only alphanum and _.
  


An easy win here is to instead use :user-valid and :user-invalid - these pseudo-classes only become active once you’ve interacted with input field. I also made this example use an outline instead of a border, which I think looks a lot nicer.
It may sometimes even make sense to use a combination of :valid and :user-invalid.
And of course, you can use the :has selector to style other elements depending on the input too!


  Password
    
    The password must:
- be 8-16 characters
- contain at least ⅰ roman numeral
- not end with a letter

  


This one's just for fun ^_-! you win! yay!
I do want to mention that for some stuff, such as date pickers () or datalists (), there are built-in elements that do the job, but you may find them limited in one way or the other. If you’re making an input like that with specific requirements, you may still need to dip your feet in a bit of JavaScript.

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  


Do not the vw/vh
This section is kind of random but I wanted to include it here because I think a lot of people are messing this one up and I want more people to know how to do this stuff right.
So CSS has vw/vh units that correspond to 1% of the viewport width and height respectively, which makes perfect sense for desktop browsers.





  CBSignal chatAre you feeling encrypted?
  MMaratit smells of onions in here...
  bmblackle moriwhat's the scoop in yer smacker, horseberry?
  RRhynoraterCSS go BRRRRR
  PPatTheHyrulerI just lost the game
  MMalkI can't wait to taste the sorbet!


🔒lyra.horse/blog/•••

lyra's epic blog posts tags
You no longer need JavaScript
yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap yap




Where it becomes a bit more nuanced is on mobile devices. For example, mobile versions of both Firefox and Chrome will hide the URL bar when scrolling down on a page.
This causes the vw/vh units to be a bit ambigous - do they represent the entire available screen, only the area that’s visible with the URL bar, or something in between?
If it’s the first option, you might end up with buttons or links off-screen11! If it’s the second, you may end up with a background div that doesn’t cover the entire background.




  ppingotuxcss spec so good i transitioned
  mmayahi wife!!
  ZZvitlol. lmao, sogar.
  !!!! HAND !!yap yap yap
  JJonesGlory to KuK
  SSpaxim goop
  eenscribeI need a job


  lvh
  dvh
  svh











🔒lyra.horse/blog/•••




  lvh
  svh
  dvh
  lvh
  svh
  dvh
  lvh
  svh
  dvh
  lvh
  svh
  dvh
  lvh
  svh
  dvh

Your values

  
    
      Unit
      Value
    
  
  
    
      vh
      px
    
    
      lvh
      px
    
    
      dvh
      px
    
    
      svh
      px
    
  

Above is a table of values your browser reports - if you're on mobile, try scrolling the blogpost up and down so that the URL bar hides and see how the numbers change.
The values are multiplied by 100 (eg 100vh is used instead of 1vh).




The solution to this is to use the new responsive viewport units: lvh, svh, and dvh.
lvh stands for largest viewport height, and thus is useful for things like backgrounds that you’d want to cover the entire screen with, and wouldn’t care about getting cut off.
svh stands for smallest viewport height, and should be used for things that must always fit on the screen, such as buttons and links.
And dvh stands for dynamic viewport height - this one will update to whatever the current viewport height is. It might seem like the obvious choice, but it should not be used for elements you don’t want resizing or moving around as the user scrolls the page, as it could become quite annoying and possibly even laggy otherwise.
Of course, the respective lvw, svw, and dvw units exist too :).
Keyboard cat
By default, the viewport units do not account for the keyboard overlaying the page.
There are two ways to deal with that: the interactive-widget attribute, and the VirtualKeyboard API.
The former option is widely supported across browsers, works without JS, and goes in the meta viewport tag. It makes it so that opening the keyboard will change all of the viewport units.
<meta name="viewport" content="width=device-width, interactive-widget=resizes-content">

The latter option is currently only supported in Chromium-based browsers, and requires a single line of JavaScript to use:
navigator.virtualKeyboard.overlaysContent = true;

The advantage of the second option is that it allows you to use environment variables in CSS to get the position and size of the keyboard, which is pretty cool.
floating-button {
  margin-bottom: env(keyboard-inset-height, 0px);
}

But considering the fact that it doesn’t work cross-browser, I’d avoid it.
CSS wishlist
Alright, so this is a little different from the rest of the post, but I wanted to bring up some things that I wish were in CSS. I haven’t fully fleshed out all of them, so some definitely wouldn’t fit the spec as-is, but maybe they can inspire some other stuff at least.
They are just fun ideas, don’t take them too seriously.
Reusable blocks
I wish it was possible to put classes in other classes in CSS, so that you could write something like:
.border {
  border: 2px solid;
  border-radius: 4px;
}

.button {
  @apply border;
}

.card {
  @apply border;
}

This is something that Tailwind already has, and that makes me jealous.

Combined @media selectors
We can currently do nested @media queries, and also multiple selectors at the same time:
div {
  &.foo, &.bar {
    color: red;
    padding: 8px;
    font-size: 2em;
  }
  @media (width < 480px) {
    color: red;
    padding: 8px;
    font-size: 2em;
  }
}

But we cannot combine the two into a single selector:
div {
  @media (width < 480px), &.foo {
    color: red;
    padding: 8px;
    font-size: 2em;
  }
}

Which means if you want to do that you’ll inevitably have to repeat code or do some silly variable hacks, neither of which is ideal.
n-th child variable
For many of the CSS crimes I like to commit, I often end up writing code like:
div {
  span:nth-child(1) { --nth: 1; }
  span:nth-child(2) { --nth: 2; }
  span:nth-child(3) { --nth: 3; }
  span:nth-child(4) { --nth: 4; }
  span:nth-child(5) { --nth: 5; }
  ...
  span {
    top: calc(--nth * 24px);
    color: hsl(calc(var(--nth) * 90deg) 100 90);
  }
}

And I think it would be a lot nicer if we could instead just do:
div {
  span {
    --nth: nth-child();
    top: calc(--nth * 24px);
    color: hsl(calc(var(--nth) * 90deg) 100 90);
  }
}

n-th letter targeting
CSS has the ability to style the ::first-letter of text. It’d be cool if were was also a ::nth-letter(…) selector, similar to :nth-child. I suspect the reason this isn’t a thing is because the ::first-letter selector is a pseudo-element, which would be a bit tricky to implement with the nth-letter idea.
/* not a real feature */
p::nth-letter(2) {
  color: red;
}

hi there~


Blackle suggested that combining the nth-child() variable with :nth-letter targeting would also be fun for certain effects, such as putting the value in the sin() function to create wavy text.
div {
  /* not a real feature */
  --nth: nth-child(nth-letter);
  will-change: transform;
  translate: 0 calc(sin(var(--nth) * 0.35 - var(--wave) * 3) * 5px);
  color: color-mix(in oklch, #58C8F2, #EDA4B2 calc(sin(var(--nth) * 0.5 - var(--wave)) * 50% + 50%));
}

  
    untucknowqueen
  
  (taphover to play animation)


Unit removal
I wish you could easily remove units from values, for example by dividing them.

div {
  /* Turns into:  (no unit) */
  --screen-width: calc(100vw / 1px);
  color: hsl(var(--screen-width) 100, 50);
}
This would allow you to use the size of the viewport or container as a numeric variable for things other than length. For example, the color picker from earlier uses it to convert the location of the color picker dot to a number to be used in a color value instead.
Uh, but wait? Does that mean this feature already exists?
Yeah, lol! We already have the ability to get unitless values in CSS, but it involves doing hacky stuff such as tan(atan2(var(--vw), 1px)) with a custom @property. It’d be nice to have this as just a division, for example.
Oh, and good news, this one we might actually be getting soon!
Also if you do something like calc(1px + sqrt(1px * 1px)) your browser will crash12.
A better image function
The image() function exists, but no browsers implement it. It’s similar to just using url(), but adds some really cool features such as a fallback color, and image fragments to crop a smaller section out of a bigger image (think spritesheets).
We can already do both fallbacks and spritesheets with the various background properties, but it’d be nice to have this pretty syntax. I’d honestly love this syntax even more for <img> tags than CSS.
style tags in body
I make heavy use of <style> tags in <body> for my projects. On my blog, for example, I write the relevant CSS close to their graphics so that you can start reading the blog before the entire page (or the entire CSS) has finished loading13. And it works great!
But what’s unfortunate is that despite browsers supporting this, and major sites using this, it’s not officially spec-compliant. I suspect it’s in the spec to avoid the FOUC footgun, but there are so many reasons you would want/need style in body that I don’t think it justifies it.
I think an HTML validator should warn for this, but not error.
The art
I want to end this article by saying that to me, web development is an art, and thus, CSS is too. I often have a hard time relating to people who do webdev solely to earn money or build a startup - web development is very different when you’re on a team and are given tasks from above instead of having free will over what you create for fun.
It’s probably most apparent with things like AI14, that for me take all the fun and creativity out of my work. But it also applies to build chain tooling such as linters and minifiers - the way I write my code is part of the art, and I don’t want a tool to erase that. I don’t even use an IDE15.
Among the practical reasons for sticking to CSS listed throughout this post, there’s a secret extra reason I like to do everything in CSS, and that’s expression and art. Art isn’t always practical, and using CSS isn’t either. But it’s how I like to express myself, and it’s why I do what I do.
I tried to keep this post approachable and practical for all web developers. But there is so much more to CSS that I’d like to talk about, so expect another post about the stuff that isn’t practical, and is instead just cool as fuck. I think CSS is a programming language, and I made a game to prove it.
But that’s a topic for another time.
afterword
it’s been almost a year since my last post, but i hope it’s been worth the wait ^_^
as usual, this post is a self-contained html file with no javascript, images, or other external resources - everything on the page is handwritten html/css, weighing in at around 49kB gzipped. it was really fun creating all the little interactive widgets and visuals this time around, i think i’ve improved in css a lot since the last time i posted.
this entire post turned out to be a bit of a fun mess (as did i!), it’s almost like a chaotic gradient of tone throughout, i hope it was still interesting and enjoyable to read though.
i have a few new posts in the works: in addition to the second css one mentioned earlier, i also have one about a new web vulnerability subclass i discovered, and one about a trans topic. i’m not sure when these posts will come out, but we’ll see! make sure to add me to your rss reader if that sounds fun.
i’ll also be giving a talk at bsides tallinn in september! i’m hoping to also do css-related talks at the next ccc and disobey, but we’ll have to see whether i get accepted and have the travel budget for those.
thank you so much for reading <3
you're awesome!! (i can tell because you checked that checkbox from earlier)

If you’d like to reach out, feel free to message me on my socials or at lyra.horse [at] gmail.com.
Discuss this post on: twitter, mastodon, lobsters





Chrome’s DevTools come with the cool flexbox widget. Firefox’s however don’t seem to for some reason? I find that weird because Firefox does have really good tools for flexbox and grid development, so this seems like an odd omission. ↩︎


While I think what I said is true, Tailwind does have more to its existence, the core of which can be found in this post by its creator. ↩︎


You are allowed to just make up elements as long as their names contain a hyphen. Apart from the 8 existing tags listed at the link, no HTML tags contain a hyphen and none ever will. The spec even has <math-α> and <emotion-😍> as examples of allowed names. You are allowed to make up attributes on an autonomous custom element, but for other elements (built-in or extended) you should only make up data-* attributes. I make heavy use of this on my blog to make writing HTML and CSS nicer and avoid meaningless div-soup. ↩︎


Still not nice to read for you? I’m personally not a fan of BEM, but I’d definitely recommend reading up on it too if you just don’t vibe with the way I’m writing my examples. Also, my example intentionally shows off a lot of the syntax at once, but in the real world it might make sense to structure things a little differently. ↩︎


Baseline browsers are Safari (macOS/iOS), Chrome (desktop/Android), Edge (desktop), and Firefox (desktop/Android). ↩︎


The MDN docs of course also list detailed browser compatibility, but the Baseline symbols are nice for just getting a quick “yeah, we can use it and it’ll work for everyone” type overview. ↩︎


ES3 (1999) is the last “classic” version of JavaScript. In 2009 we got the first major revision known as ES5, and a few years later we kicked off the yearly spec updates with ES2015. Also ES4 was abandoned which makes me feel sad :c. ↩︎


93 files!! Seems like they’re 1/3 functionality, 1/3 ads, and 1/3 analytics. The site works just fine with JavaScript disabled - only stuff like the comments section and ads won’t load. It’s no longer a laggy mess either for some reason. ↩︎


I think the x3ctf challenges page looks really smooth on my computer - the marquee text animation and clicking on the challenges is buttery. And it also runs pretty well on the low-end hardware I have. Note that some browser performance recording tools can act a bit weird with CSS animations, so make sure your tools are working as expected before using them. Unrelated, but I made some other cool x3ctf web stuff too - check out the archive. ↩︎


There’s a bug in Chrome that requires you to use a fieldset/radiogroup for the radio button index to work correctly in screenreaders. Eg if you have 3 radio buttons with the same name, selecting one of them should read “radio button 1 of 3”, which is what Firefox does, but in Chrome it will instead read it as “radio button 4 of 9” or whatever if you don’t have a fieldset/radiogroup because it kind of just combines all the radio buttons on the page into a single index. ↩︎


A certain HR platform I have to use puts its action buttons at the very bottom of a 100vh container, leading to them not being visible/interactable on my phone - not a headache you want to go through when requesting sick days. It’s a good example of how just using the wrong unit can cause a pretty bad real world accessibility problem. ↩︎


Well, probably not. This is a bug I found while writing this post that only affects Chrome, and it’ll probably get fixed before it even manages to hit stable. Update: I took so long to get this blog post out that it has been fixed now. During the writing of this blog post I found another bug in Chrome though, which is pretty funny. Update 2: I found yet another Chrome bug while writing this post, this one is kinda weird, you should read it. ↩︎


This matters for people on slow connections, such as bad mobile data, satellite internet, tor, or iodine. While my blog posts are very small in size, the CSS alone can take up more than the first 14kB of a TCP round trip, so with blocking CSS in the head you might have to wait a few extra seconds (or minutes, in the case of iodine) just to start reading the first paragraph. Now, that 14kB number isn’t completely accurate in the modern world, but testing on my own server (HTTP/2, TLS 1.3), around ~16kB of the compressed html reaches the browser in the first batch of http data. ↩︎


By this I mean tools such as Copilot, Cursor, chatbots etc. I understand there is a huge difference between full-on vibe coding and just using the tab key, but I do not want to use or interact with any of those tools. Please respect that. ↩︎


I write all my code (and blogposts) in Sublime Text, which to me is just a glorified version of Notepad. The features over Notepad it gives me are syntax highlighting, multiple cursors, keyboard shortcuts, and a better visual design. It doesn’t do that much, and yet, it’s perfect. It’s so good I paid for it. ↩︎





  ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My startup banking story (2023)]]></title>
            <link>https://mitchellh.com/writing/my-startup-banking-story</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45056177</guid>
            <description><![CDATA[As a relatively new member of adult society, and an absolute infant of
the business world, I didn't think much about bank choice. I figured: you
put money in, you take money out, they're all the same. I also figured a local
branch of a global bank is just a fungible tentacle of the giant banking
machine, so also... who cares. Both incorrect assumptions, but let's relive and
rediscover the effect of these assumptions as I did.]]></description>
            <content:encoded><![CDATA[As a relatively new member of adult society, and an absolute infant of
the business world, I didn't think much about bank choice. I figured: you
put money in, you take money out, they're all the same. I also figured a local
branch of a global bank is just a fungible tentacle of the giant banking
machine, so also... who cares. Both incorrect assumptions, but let's relive and
rediscover the effect of these assumptions as I did.




I start my company. I am a 22 year old recent college graduate living in San
Francisco and pursuing the startup dream. I file my incorporation paperwork
and wait to receive the necessary information for one of the first
steps in the life of any new business: opening a bank account.
My filing is processed and I receive my EIN while visiting my parents
in a suburb of Los Angeles. I have time to kill during one of the days so
I drive down to the nearest Chase bank branch and open a business banking
account. We'll call the person who helped me at the local branch Alex (this
will be important later). I fund that account with a $20,000 personal loan which
was almost all of my savings. I get an account number, an online login, and
boom, we're in business!
About 6 months later, I raise a ~$1M seed round. I supply my Chase business
banking account information for the wire, and at close the funding is wired to
the account. I am sitting in a cafe in downtown San Francisco and I receive a
call from an unknown number -- it's Alex, the banker that
helped me open my account. He is being very casual, sort of like
"Hey, just wanted to check on things." "I noticed a big deposit and wanted
to make sure you had everything you needed." etc. For my side, I am
mostly confused: why is this person calling me? I mostly say things like
"yes yes I'm fine" and end the call quickly. Some wheels have started
turning in Southern California, and I just hadn't known it yet.
Someone out there is probably mentally screaming at me "you fool!"
at this point. With hindsight, I agree, but I will remind you
dear reader that I have only been legally allowed to purchase alcohol
for just over a year at this point in my life in the story.




The two years since 2012 -- from a banking perspective -- are quiet. Alex
doesn't call me again, and we have no changes in our banking setup. For two years,
the company was in heads-down building mode. We had shown significant product
traction and were now ready to ramp up hiring to continue building.
At the end of 2014, we raise a $10.2M series A. I once again provide the
same Chase business banking account and when the round closes, the funds are
wired. Surprise surprise, Alex calls me! I'm starting to realize banks get
an alert when there are major changes in account balances. Regardless,
I once again brush Alex off -- "everything is good thanks! bye!" -- and
continue on with my life.
At this point, I am bewildered that this guy I met at the random local branch
to sign some papers is the one calling me, but didn't think much more of
it at the time.




Once again, the two years since 2014 are mostly quiet from a banking
perspective. Alex called more regularly to "check in" but otherwise
nothing has changed. We still bank with Chase. I still have never gone
back into a branch. I do everything online.
In the fall of 2016, we raise a $24M series B. I once again provide the
same Chase business banking account and when the round closes, the funds
are wired. Again, Alex calls. Again, I brush him off. The bank is where I
plant money, I don't need anyone calling me. I just want to focus on building
the company.
Throughout 2016, we had been building out an executive team for the company.
And around the same time of the funding, we hire a Vice President of Finance. As he gets
up to speed with our financial footing, he notices we have ~$35M sitting in
cash in a Chase bank account. This is obviously not a smart thing to do,
so he suggests some financial plans for how to better safeguard and utilize
this mountain of cash.
As part of these plans, he suggests moving to Silicon Valley Bank (SVB).
They're local to the Bay Area, he's worked with them before, and their
bankers understand startups. It'll make accounts receivables, payables,
payroll, etc. easier. To me, a bank is a bank is a bank, and if it helps
make his job easier, I support his plan.
I log into the Chase online portal and initiate a wire for the full account
balance to SVB. I have to pay something like a $30 fee to wire $35M
(inconsequential to the story, but amusing nonetheless). Someone calls me for
verification -- not Alex -- and the wire processes. Boom, we're done with
Chase. Or so I think.
Alex calls me the next day. The day we initiated the wire was his day off.
He sounds slightly agitated. I wasn't rude to him, but I was short with him.
I switched banks, that's all there is to it. Thanks and goodbye. I never
talk to Alex ever again. A bank is a bank is a bank, you put money in,
you get money out, I don't understand why I would need to talk to someone.
I once again interrupt this story to appeal to the readers who are
screaming at me and thank you for joining me on this story recounting
my learning journey. Rest assured, at this point in the story, a professional
was now in charge of the company's finances. But the decisions of the
years leading up to this would have lingering effects for a few more years...




We now take a brief detour from the company, because this is where my
personal life becomes relevant to the story.
For the prior three years, I had been living in Los Angeles. At some
point during 2017, I had to go to a local Chase branch to make some
changes to my personal accounts. It has been close to a year since the company
stopped using Chase.
I visit the closest bank branch to my apartment. This bank branch is 20
miles north of where my parents live -- or the area with the branch where I
opened the original company business bank accounts. I'm going to Chase for
purely personal reasons, but this information is unfortunately relevant
to the story.
At my local branch, I walk up to the teller and provide some handwritten
information: my name, account number, desired transaction, etc. The teller looks at the paper,
then looks at me, then looks back at the paper, then asks "Are you the
HashiCorp guy?" What? HashiCorp is doing well but its not at all
something a random non-technical consumer would know about. What is going on?
I say yes and he acknowledges but doesn't automatically offer any more
information. I have to know, so I continue "How do you know that?" His
response is "Dude, everyone at Chase down here knows about HashiCorp." Huh?
Up to this point, everything in the story is what I know and experienced
first hand. What follows however is now second hand information as told
by this teller. I haven't verified it, but other employees (at other branches)
have said similar things to me over the years.
The teller proceeds to explain that Alex -- the guy I opened my original
company account with -- became a fast rising star in the area. He had
opened a business account in a small suburb that grew from $20,000 to
$35,000,000 in balances in just four years! Despite the business (my business)
not engaging in higher-revenue activities with the bank, the opportunity
this account represented to the small business wing of the small suburban
branch stirred up some excitement. It was just a matter of time.
And then, overnight, the account went to $0. Without talking to anyone,
without any prior warning, that account was gone. I used online banking
to transfer the entirety of the balance to another bank. The small suburban
branch viewed this as a huge loss and Alex came into work with some tough
questions and no answers. I instantly recalled feeling that Alex was agitated
when he called me the day after the transfer, and I now had an idea of why.
I don't know what happened to Alex, the teller said he was "no longer
working in the area" and said it with a noticably negative tone. I don't
know what this means and I never found out. Perhaps, he just moved.
Following this event, Chase began an educational series to other local
branches in the Los Angeles area explaining that there are these "startups"
and how their financial patterns do not match those of a typical business. This series
taught branches how to identify startups and how to consider their accounts.
The case study they used for this presentation: HashiCorp.




It has been two years since hiring our VP of Finance and our financial
department is in really healthy shape. I still have certain approval rights
but no longer directly manage the accounts of the company.
Given the recent events with Silicon Valley Bank, I feel it's important to
mention that at this point of the company, we had already begun diversifying
our balances across multiple banks. SVB will not be mentioned again for
the remainder of the story.
I'm working at my office at home in Los Angeles and I receive a phone
call from our finance department. That's weird, I rarely receive phone calls.
They tell me that during a routine internal audit, they realized there are
a few customer accounts that are still paying their bill into the old Chase
account.
I never closed that original Chase business account back in 2016. Let
me explain how that happens. To close an account, I had to do it in person at
any local Chase branch. Startups are busy, the account balance in 2016 was $0,
and so I just put it off. Well, a couple years passed, it was still open,
and a few customers were actually sending payments to it.
Worse, upon the realization that a few customers were paying into this account,
our finance team realized that there was also fraud. For over a year, someone
had been wiring thousands of dollars out every few weeks. We were short
over $100,000 due to fraud. The finance team immediately called Chase and
reported the fraud, locked down the account, and Chase started an investigation.
Meanwhile, the finance team wanted me to close the account and wire the
remaining balance to our actual business bank. With the fraud actively being
handled by Chase and the finance team, I take on the task of closing the
account. I immediately head to the nearest local Chase branch (once again
a branch I've never been to before) and explain the situation.
After waiting for 15 minutes, a manager walks up to me. I know this can't
be good. The branch manager explains that due to the actions taken to lock
down the account for fraud, electronic transfers are unavailable. It doesn't
matter that I'm provably the person who opened the account, electronic
transfers are "impossible."
I say okay, and ask how I am supposed to close the account and transfer
the remaining balance. He said I can close the account and withdraw the
remaining balance only in cash. Cash? At this point, I literally asked:
"like, green paper money cash?" He says yes. The balance in the account is
somewhere around $1M.
I spent another two hours at the bank, juggling between calling our
finance department, talking to this branch manager, and calling the Chase
business phone line. We determine that instead of literal green cash, I
can get a cashier's check. But there is a major problem: the amount the
cashier's check is made out for has to be available at that local branch
(or, whichever branch issues it).
And, well, local branches I guess don't usually have $1M cash lying around.
Or, if they do, its not enough to cover other business activities for the day
so they're not willing to part with it.
The bank manager gives me the phone number of another branch manager that
"may be able to help me." He literally writes down a phone number on a
piece of paper. This is all feeling so surreal. I call this number and
its for a slightly larger branch a few miles down the road. He says
"you're the HashiCorp guy right?" And I roll my eyes. My infamy in the
area is still well known.
This manager is very helpful, if not a bit gruff. He explains to me that
each local branch has some sort of performance metric based on inflows and
outflows at the given branch. Therefore, funding a $1M cash withdrawal was
not attractive to them. I'm learning a lot in a really condensed period of
time at this point. I don't even know if what he's telling me is true, or
legal, all I hear is "this is going to be hard to do if you want it all at
once."
But we do want it all at once. And we want to close the account. Now.
He is not happy, but he says he'll call me back in 24 to 48 hours. True
to his word, he calls me back the next day. He says that he had to coordinate
to ensure his branch had the proper funding to satisfy this transaction,
and that the funding would be available at a specific date a few days hence.
He said I have to do the withdrawal that day because his branch will not
hold that amount in cash for any longer.
He also subtly suggested I hire personal security or otherwise deposit
those funds somewhere with haste. I believe his exact words were "if you
lose that check, I can't help you." Again, this was a one time event, and
I don't know how true that all is, but it was said to me.
A few days later, I walk into the branch (I did not hire personal security).
I tell the teller my name and there is a flicker of immediate recognition.
The teller guides me to a cubicle, the account is successfully closed,
I'm issued a $1M cashier's check, and I walk out the door.
My business banking relationship with Chase is, at long last, complete.
I want to make it clear that Chase could've been an excellent
banking partner. I never gave them the chance. I never told them what
my business does or what I'd use the money for. I never talked to anyone
(besides saying what I needed to get off the phone). This story isn't
a cautionary tale about Chase, it is rather recounting my naivete
as a young, first-time startup founder.

Epilogue.
The cashier's check was uneventfully deposited into our primary business
banking account shortly after I walked out of the Chase branch.
The fraud investigation took a few months to complete but we were
able to recover all of the lost funds.
Enough time has passed and employees cycled that I'm no longer recognized at
any Los Angeles area Chase branches.
I look back on these events and there are many places I cringe. At the
same time, I can't imagine making different choices because I was acting in
good faith at all times with the knowledge I had. I think the choices I made were
reasonable for any new founder, and I know many founders who have made
similar choices.
Ultimately, there was no long term negative impact of the events that
transpired (except maybe for Alex, but I truly don't know) and I can now
look back on it with amusement.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Some thoughts on LLMs and software development]]></title>
            <link>https://martinfowler.com/articles/202508-ai-thoughts.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45055641</guid>
            <description><![CDATA[a short post]]></description>
            <content:encoded><![CDATA[I’m about to head away from looking after this site for a few weeks (part vacation, part work stuff). As I contemplate some weeks away from the daily routine, I feel an urge to share some scattered thoughts about the state of LLMs and AI.

                ❄                ❄                ❄                ❄

I’ve seen a few early surveys on the effect AI is having on software development, is it really speeding folks up, does it improve or wreck code quality? One of the big problems with these surveys is that they aren’t taking into account how people are using the LLMs. From what I can tell the vast majority of LLM usage is fancy auto-complete, often using co-pilot. But those I know who get the most value from LLMs reckon that auto-complete isn’t very useful, preferring approaches that allow the LLM to directly read and edit source code files to carry out tasks. My concern is that surveys that ignore the different work-flows of using LLMs will produce data that’s going to send people down the wrong paths.

(Another complication is the varying capabilities of different models.)

                ❄                ❄                ❄                ❄

I’m often asked, “what is the future of programming?” Should people consider entering software development now? Will LLMs eliminate the need for junior engineers? Should senior engineers get out of the profession before it’s too late? My answer to all these questions is “I haven’t the foggiest”. Furthermore I think anyone who says they know what this future will be is talking from an inappropriate orifice. We are still figuring out how to use LLMs, and it will be some time before we have a decent idea of how to use them well, especially if they gain significant improvements.

What I suggest, is that people experiment with them. At the least, read about what others are doing, but pay attention to the details of their workflows. Preferably experiment yourself, and do share your experiences.

                ❄                ❄               ❇                ❄

I’m also asked: “is AI a bubble”? To which my answer is “OF COURSE IT’S A BUBBLE”. All major technological advances have come with economic bubbles, from canals and railroads to the internet. We know with near 100% certainty that this bubble will pop, causing lots of investments to fizzle to nothing. However what we don’t know is when it will pop, and thus how big the bubble will have grown, generating some real value in the process, before that happens. It could pop next month, or not for a couple of years.

We also know that when the bubble pops, many firms will go bust, but not all. When the dot-com bubble burst, it killed pets.com, it killed Webvan… but it did not kill Amazon.

                ❄                ❄                ❄                ❄

I retired from public speaking a couple of years ago. But while I don’t miss the stress of giving talks, I do miss hanging out with my friends in the industry. So I’m looking forward to catching up with many of them at GOTO Copenhagen. I’ve been involved with the GOTO conference series since the 1990s (when it was called JAOO), and continue to be impressed with how they put together a fascinating program.

                ✢                ❄                ❄                ❄

My former colleague Rebecca Parsons, has been saying for a long time that hallucinations aren’t a bug of LLMs, they are a feature. Indeed they are the feature. All an LLM does is produce hallucinations, it’s just that we find some of them useful.

One of the consequences of this is that we should always consider asking the LLM the same question more than once, perhaps with some variation in the wording. Then we can compare answers, indeed perhaps ask the LLM to compare answers for us. The difference in the answers can be as useful as the answers themselves.

Certainly if we ever ask a hallucination engine for a numeric answer, we should ask it at least three times, so we get some sense of the variation. Furthermore we shouldn’t ask an LLM to calculate an answer than we can calculate deterministically (yes, I’ve seen this). It is OK to ask an LLM to generate code to calculate an answer (but still do it more than once).

                ❄                ❄                ❄                ❄

Other forms of engineering have to take into account the variability of the world. A structural engineer builds in tolerance for all the factors she can’t measure. (I remember being told early in my career that the unique characteristic of digital electronics was that there was no concept of tolerances.) Process engineers consider that humans are executing tasks, and will sometimes be forgetful or careless. Software Engineering is unusual in that it works with deterministic machines. Maybe LLMs mark the point where we join our engineering peers in a world on non-determinism.

                ❄                ❄                ❄                ❄

I’ve often heard, with decent reason, an LLM compared to a junior colleague. But I find LLMs are quite happy to say “all tests green”, yet when I run them, there are failures. If that was a junior engineer’s behavior, how long would it be before H.R. was involved?

                ❄                ❄                ❄                ❄

LLMs create a huge increase in the attack surface of software systems. Simon Willison described the The Lethal Trifecta for AI agents: an agent that combines access to your private data, exposure to untrusted content, and a way to externally communicate (“exfiltration”). That “untrusted content” can come in all sorts of ways, ask it to read a web page, and an attacker can easily put instructions on the website in 1pt white-on-white font to trick the gullible LLM to obtain that private data.

This is particularly serious when it comes to agents acting in a browser. Read an attacker’s web page, and it could trick the agent to go to your bank account in another tab and “buy you a present” by transferring your balance to the kind attacker. Willison’s view is that “the entire concept of an agentic browser extension is fatally flawed and cannot be built safely”.

]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Web Bot Auth]]></title>
            <link>https://developers.cloudflare.com/bots/reference/bot-verification/web-bot-auth/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45055452</guid>
            <description><![CDATA[Web Bot Auth is an authentication method that leverages cryptographic signatures in HTTP messages to verify that a request comes from an automated bot. Web Bot Auth is used as a verification method for verified bots and signed agents.]]></description>
            <content:encoded><![CDATA[          Web Bot Auth is an authentication method that leverages cryptographic signatures in HTTP messages to verify that a request comes from an automated bot. Web Bot Auth is used as a verification method for verified bots and signed agents.
It relies on two active IETF drafts: a directory draft ↗ allowing the crawler to share their public keys, and a protocol draft ↗ defining how these keys should be used to attach crawler's identity to HTTP requests.
This documentation goes over specific integration within Cloudflare.

You need to generate a signing key which will be used to authenticate your bot's requests.



Generate a unique Ed25519 ↗ private key to sign your requests. This example uses the OpenSSL ↗ genpkey command:
openssl genpkey -algorithm ed25519 -out private-key.pem


Extract your public key.
openssl pkey -in private-key.pem -pubout -out public-key.pem


Convert the public key to JSON Web Key (JWK) using a tool of your choice. This example uses jwker ↗ command line application.
go install github.com/jphastings/jwker/cmd/jwker@latestjwker public-key.pem public-key.jwk


By following these steps, you have generated a private key and a public key, then converted the public key to a JWK.


You need to host a key directory which creates a way for your bot to authenticate its requests to Cloudflare.
This directory should follow the definition from the active IETF draft draft-meunier-http-message-signatures-directory-01 ↗.


Host a key directory at /.well-known/http-message-signatures-directory (note that this is a requirement). This key directory should serve a JSON Web Key Set (JWKS) including the public key derived from your signing key.


Serve the web page over HTTPS (not HTTP).


Calculate the base64 URL-encoded JWK thumbprint ↗ associated with your Ed25519 public key.


Sign your HTTP response using the HTTP message signature specification by attaching one signature per key in your key directory. This ensures no one else can mirror your directory and attempt to register on your behalf. Your response must include the following headers:

Content-Type: This header must have the value application/http-message-signatures-directory+json.
Signature: Construct a Signature header ↗ over your chosen components.
Signature-Input: Construct a Signature-Input header ↗ over your chosen components. The header must meet the following requirements.

























Required component parameterRequirementtagThis should be equal to http-message-signatures-directory.keyidJWK thumbprint of the corresponding key in your directory.createdThis should be equal to a Unix timestamp associated with when the message was sent by your application.expiresThis should be equal to a Unix timestamp associated with when Cloudflare should no longer attempt to verify the message.


The following example shows the annotated request and response with required headers against https://example.com.
GET /.well-known/http-message-signatures-directory HTTP/1.1Host: example.comAccept: application/http-message-signatures-directory+jsonHTTP/1.1 200 OKContent-Type: application/http-message-signatures-directory+jsonSignature: sig1=:TD5arhV1ved6xtx63cUIFCMONT248cpDeVUAljLgkdozbjMNpJGr/WAx4PzHj+WeG0xMHQF1BOdFLDsfjdjvBA==:Signature-Input: sig1=("@authority");alg="ed25519";keyid="poqkLGiymh_W0uP6PZFw-dvez3QJT5SolqXBCW38r0U";nonce="ZO3/XMEZjrvSnLtAP9M7jK0WGQf3J+pbmQRUpKDhF9/jsNCWqUh2sq+TH4WTX3/GpNoSZUa8eNWMKqxWp2/c2g==";tag="http-message-signatures-directory";created=1750105829;expires=1750105839Cache-Control: max-age=86400{  "keys": [{    "kty": "OKP",    "crv": "Ed25519",    "x": "JrQLj5P_89iXES9-vFgrIy29clF9CC_oPPsw3c5D0bs", // Base64 URL-encoded public key, with no padding  }]}



You can use the Cloudflare-developed http-signature-directory CLI tool ↗ to assist you in validating your directory.

You need to register your bot and its key directory to add your bot to the list of verified bots.

Log in to the Cloudflare dashboard ↗, and select your account and domain.
Go to Manage Account > Configurations.
Go to the Verified Bots tab.
For Verification Method: select Request Signature.
For Validation Instructions: enter the URL of your key directory. You can additionally supply User Agents values (and their match patterns) that will be sent by your bot.
Select Submit.

Cloudflare accepts all valid Ed25519 keys found in your key directory. In the event a key already exists in Cloudflare's registered database, Cloudflare will work with you to supply a new key, or rotate your existing key.


After your bot has been successfully verified, your bot is ready to sign its requests. The signature protocol is defined in draft-meunier-web-bot-auth-architecture-02 ↗

Choose a set of components to sign.
A component is either an HTTP header, or any derived components ↗ in the HTTP Message Signatures specification. Cloudflare recommends the following:

Choose at least the @authority derived component, which represents the domain you are sending requests to. For example, a request to https://example.com will be interpreted to have an @authority of example.com.
Use components that only contain ASCII values. HTTP Message Signature specification disallows non-ASCII characters, which will result in failure to validate your bot's requests.




Calculate the base64 URL-encoded JWK thumbprint ↗ from the public key you registered with Cloudflare.

Construct the three required headers for Web Bot Auth.

Construct a Signature-Input header ↗ over your chosen components. The header must meet the following requirements.

























Required component parameterRequirementtagThis should be equal to web-bot-auth.keyidThis should be equal to the thumbprint computed in step 2.createdThis should be equal to a Unix timestamp associated with when the message was sent by your application.expiresThis should be equal to a Unix timestamp associated with when Cloudflare should no longer attempt to verify the message. A short expires reduces the likelihood of replay attacks, and Cloudflare recommends choosing suitable short-lived intervals.

Construct a Signature header ↗ over your chosen components.

Construct a Signature-Agent header ↗ that points to your key directory. Note that Cloudflare will fail to verify a message if:

The message includes a Signature-Agent header that is not an https://.
The message includes a valid URI but does not enclose it in double quotes. This is due to Signature-Agent being a structured field.
The message has a valid Signature-Agent header, but does not include it in the component list in Signature-Input.


Attach these three headers to your bot's requests.
An example request may look like this:
Signature-Agent: "https://signature-agent.test"Signature-Input: sig2=("@authority" "signature-agent") ;created=1735689600 ;keyid="poqkLGiymh_W0uP6PZFw-dvez3QJT5SolqXBCW38r0U" ;alg="ed25519" ;expires=1735693200 ;nonce="e8N7S2MFd/qrd6T2R3tdfAuuANngKI7LFtKYI/vowzk4lAZYadIX6wW25MwG7DCT9RUKAJ0qVkU0mEeLElW1qg==" ;tag="web-bot-auth"Signature: sig2=:jdq0SqOwHdyHr9+r5jw3iYZH6aNGKijYp/EstF4RQTQdi5N5YYKrD+mCT1HA1nZDsi6nJKuHxUi/5Syp3rLWBA==:


You may wish to refer to the following resources.

Bots FAQs.
Cloudflare blog: Message Signatures are now part of our Verified Bots Program ↗.
Cloudflare blog: Forget IPs: using cryptography to verify bot and agent traffic ↗.
Cloudflare's web-bot-auth library in Rust ↗.
Cloudflare's web-bot-auth npm package in Typescript ↗.
        Resources     API     New to Cloudflare?     Directory     Sponsorships     Open Source     Support     Help Center     System Status     Compliance     GDPR     Company     cloudflare.com     Our team     Careers     Tools     Cloudflare Radar     Speed Test     Is BGP Safe Yet?     RPKI Toolkit     Certificate Transparency     Community     X     Discord     YouTube     GitHub      ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Building your own CLI coding agent with Pydantic-AI]]></title>
            <link>https://martinfowler.com/articles/build-own-coding-agent.html</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45055439</guid>
            <description><![CDATA[How to build a CLI coding agent]]></description>
            <content:encoded><![CDATA[

The wave of CLI Coding Agents

If you have tried Claude Code, Gemini Code, Open Code or Simon
      Willison’s LLM CLI, you’ve experienced something fundamentally
      different from ChatGPT or Github Copilot. These aren’t just chatbots or
      autocomplete tools - they’re agents that can read your code, run your
      tests, search docs and make changes to your codebase async.

But how do they work? For me the best way to understand how any tool
      works is to try and build it myself. So that’s exactly what we did, and in
      this article I’ll take you through how we built our own CLI Coding Agent
      using the Pydantic-AI framework and the Model Context Protocol (MCP).
      You’ll see not just how to assemble the pieces but why each capability
      matters and how it changes the way you can work with code.

Our implementation leverages AWS Bedrock but with Pydantic-AI you could
      easily use any other mainstream provider or even a fully local LLM.



Why Build When You Can Buy?

Before diving into the technical implementation, let's examine why we
      chose to build our own solution.

The answer became clear very quickly using our custom agent, while
      commercial tools are impressive, they’re built for general use cases. Our
      agent was fully customised to our internal context and all the little
      eccentricities of our specific project. More importantly, building it gave
      us insights into how these systems work and the quality of our own GenAI
      Platform and Dev Tooling.

Think of it like learning to cook. You can eat at restaurants forever
      but understanding how flavours combine and techniques work makes you
      appreciate food differently - and lets you create exactly what you
      want.



The Architecture of Our Development Agent

At a high level, our coding assistant consists of several key
      components:


Core AI Model: Claude from Anthropic accessed through AWS Bedrock 

Pydantic-AI Framework: provides the agent framework and many helpful
        utilities to make our Agent more useful immediately 

MCP Servers: independent processes that give the agent specialised
        tools, MCP is a common standard for defining the servers that contain these
        tools. 

CLI Interface: how users interact with the assistant


The magic happens through the Model Context Protocol (MCP), which
      allows the AI model to use various tools through a standardized interface.
      This architecture makes our assistant highly extensible - we can easily
      add new capabilities by implementing additional MCP servers, but we’re
      getting ahead of ourselves.



Starting Simple: The Foundation

We started by creating a basic project structure and installing the
      necessary dependencies:

uv init
uv add pydantic_ai
uv add boto3


Our primary dependencies include:


pydantic-ai: Framework for building AI agents

boto3: For AWS API interactions


We chose Claude Sonnet 4 from Anthropic (accessed via AWS Bedrock) as
      our foundation model due to its strong code understanding and generation
      capabilities. Here's how we configured it in our main.py:

import boto3
from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerStdio
from pydantic_ai.models.bedrock import BedrockConverseModel
from pydantic_ai.providers.bedrock import BedrockProvider


bedrock_config = BotocoreConfig(
    read_timeout=300,
    connect_timeout=60,
    retries={"max_attempts": 3},
)
bedrock_client = boto3.client(
    "bedrock-runtime", region_name="eu-central-1", config=bedrock_config
)
model = BedrockConverseModel(
    "eu.anthropic.claude-sonnet-4-20250514-v1:0",
    provider=BedrockProvider(bedrock_client=bedrock_client),
)
agent = Agent(
    model=model,
)


if __name__ == "__main__":
  agent.to_cli_sync()


At this stage we already have a fully working CLI with a chat interface
      which we can use as you would a GUI chat interface, which is pretty cool
      for how little code this is! However we can definitely improve upon
      this.



First Capability: Testing!

Instead of running the tests ourselves after each coding iteration why
      not get the agent to do it? Seems simple right?

import subprocess


@agent.tool_plain()
def run_unit_tests() -> str:
    """Run unit tests using uv."""
    result = subprocess.run(
        ["uv", "run", "pytest", "-xvs", "tests/"], capture_output=True, text=True
    )
    return result.stdout


Here we use the same pytest command you would run in the terminal (I’ve
      shortened ours for the article). Now something magical happened. I could
      say “X isn’t working” and the agent would:


1. Run the test suite

2. Identify which specific tests were failing

3. Analyze the error messages

4. Suggest targeted fixes.


The workflow change: Instead of staring at test failures or copy
      pasting terminal outputs into ChatGPT we now give our agent super relevant
      context about any issues in our codebase.

However we noticed our agent sometimes “fixed” failing tests by
      suggesting changes to the tests, not the actual implementation. This led
      to our next addition.



Adding Intelligence: Instructions and intent

We realised we needed to teach our agent a little more about our
      development philosophy and steer it away from bad behaviours.

instructions = """
You are a specialised agent for maintaining and developing the XXXXXX codebase.

## Development Guidelines:

1. **Test Failures:**
   - When tests fail, fix the implementation first, not the tests
   - Tests represent expected behavior; implementation should conform to tests
   - Only modify tests if they clearly don't match specifications

2. **Code Changes:**
   - Make the smallest possible changes to fix issues
   - Focus on fixing the specific problem rather than rewriting large portions
   - Add unit tests for all new functionality before implementing it

3. **Best Practices:**
   - Keep functions small with a single responsibility
   - Implement proper error handling with appropriate exceptions
   - Be mindful of configuration dependencies in tests

Remember to examine test failure messages carefully to understand the root cause before making any changes.
"""


agent = Agent(
instructions=instructions,
model=model,
)


The workflow change: The agent now understands our values around
      Test Driven Development and minimal changes. It stopped suggesting large
      refactors where a small fix would do (Mostly).

Now while we could continue building everything from absolute scratch
      and tweaking our prompts for days we want to go fast and use some tools
      other people have built - Enter Model Context Protocol (MCP).



The MCP Revolution: Pluggable Capabilities

This is where our agent transformed from a helpful assistant to
      something approaching the commercial CLI agents. The Model Context
      Protocol (MCP) allows us to add sophisticated capabilities by running
      specialized servers.


MCP is an open protocol that standardizes how applications provide
        context to LLMs. Think of MCP like a USB-C port for AI applications.
        Just as USB-C provides a standardized way to connect your devices to
        various peripherals and accessories, MCP provides a standardized way to
        connect AI models to different data sources and tools. 

-- MCP Introduction


We can run these servers as a local process, so no data sharing, where
      we interact with STDIN/STDOUT to keep things simple and local. (More details on tools and MCP)



Sandboxed Python Execution

Using large language models to do calculations or executing arbitrary code they create is not effective and potentially very dangerous! To make our Agent more accurate and safe our first MCP addition was Pydantic Al’s default server for sandboxed Python code execution:

run_python = MCPServerStdio(
    "deno",
    args=[
        "run",
        "-N",
        "-R=node_modules",
        "-W=node_modules",
        "--node-modules-dir=auto",
        "jsr:@pydantic/mcp-run-python",
        "stdio",
    ],
)


agent = Agent(
    ...
    mcp_servers=[
        run_python
    ],
)


This gave our agent a sandbox where it could test ideas, prototype
      solutions, and verify its own suggestions.

NOTE: This is very different from running the tests where we need the
      local environment and is intended to be used to make calculations much
      more robust. This is because writing the code to output a number and then
      executing that code is much more reliable and understandable, scalable and
      repeatable than just generating the next token in a calculation. We have
      seen from frontier labs (including their leaked instructions) that this is
      a much better approach.

The workflow change: Doing calculations, even more complex ones,
      became significantly more reliable. This is useful for many things like
      dates, sums, counts etc. It also allows for a rapid iteration cycle of
      simple python code.



Up-to-Date library Documentation

LLMs are mostly trained in batch on historical data this gives a fixed
      cutoff while languages and dependencies continue to change and improve so
      we added Context7 for access to up to date python
      library documentation in LLM consumable format:

context7 = MCPServerStdio(
    command="npx", args=["-y", "@upstash/context7-mcp"], tool_prefix="context"
)


The workflow change: When working with newer libraries or trying to
      use advanced features, the agent could look up current documentation
      rather than relying on potentially outdated training data. This made it
      much more reliable for real-world development work.



AWS MCPs

Since this particular agent was built with an AWS platform in mind, we
      added the AWS Labs MCP servers for comprehensive cloud docs and
      integration:

awslabs = MCPServerStdio(
    command="uvx",
    args=["awslabs.core-mcp-server@latest"],
    env={"FASTMCP_LOG_LEVEL": "ERROR"},
    tool_prefix="awslabs",
)
aws_docs = MCPServerStdio(
    command="uvx",
    args=["awslabs.aws-documentation-mcp-server@latest"],
    env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_DOCUMENTATION_PARTITION": "aws"},
    tool_prefix="aws_docs",
)


The workflow change: Now when I mentioned “Bedrock is timing out”
      or “the model responses are getting truncated,” the agent could directly
      access AWS documentation to help troubleshoot configuration issues. While
      we've only scratched the surface with these two servers, this is the tip
      of the iceberg—the AWS Labs MCP
      collection includes servers for
      CloudWatch metrics, Lambda debugging, IAM policy analysis, and much more.
      Even with just documentation access, cloud debugging became more
      conversational and contextual.



Internet Search for Current Information

Sometimes you need information that's not in any documentation—recent
      Stack Overflow discussions, GitHub issues, or the latest best practices.
      We added general internet search:

internet_search = MCPServerStdio(command="uvx", args=["duckduckgo-mcp-server"])


The workflow change: When encountering obscure errors or needing to
      understand recent changes in the ecosystem, the agent could search for
      current discussions and solutions. This was particularly valuable for
      debugging deployment issues or understanding breaking changes in
      dependencies.



Structured Problem Solving

One of the most valuable additions was the code reasoning MCP, which
      helps the agent think through complex problems systematically:

code_reasoning = MCPServerStdio(
    command="npx",
    args=["-y", "@mettamatt/code-reasoning"],
    tool_prefix="code_reasoning",
)


The workflow change: Instead of jumping to solutions, the agent
      would break down complex problems into logical steps, explore alternative
      approaches, and explain its reasoning. This was invaluable for
      architectural decisions and debugging complex issues. I could ask “Why is
      this API call failing intermittently?” and get a structured analysis of
      potential causes rather than just guesses.



Optimising for Reasoning

As we added more sophisticated capabilities, we noticed that reasoning
      and analysis tasks often took much longer than regular text
      generation—especially when the output wasn't correctly formatted on the
      first try. We adjusted our Bedrock configuration to be more patient:

bedrock_config = BotocoreConfig(
    read_timeout=300,
    connect_timeout=60,
    retries={"max_attempts": 3},
)
bedrock_client = boto3.client(
    "bedrock-runtime", region_name="eu-central-1", config=bedrock_config
)


The workflow change: The longer timeouts meant our agent could work
      through complex problems without timing out. When analyzing large
      codebases or reasoning through intricate architectural decisions, the
      agent could take the time needed to provide thorough, well-reasoned
      responses rather than rushing to incomplete solutions.



Desktop Commander: Warning! With great power comes great responsibility!

At this point, our agent was already quite capable—it could reason
      through problems, execute code, search for information, and access AWS
      documentation. This MCP server transforms your agent from a helpful
      assistant into something that can actually do things in your development
      environment:

desktop_commander = MCPServerStdio(
    command="npx",
    args=["-y", "@wonderwhy-er/desktop-commander"],
    tool_prefix="desktop_commander",
)


Desktop Commander provides an incredibly comprehensive toolkit: file
      system operations (read, write, search), terminal command execution with
      process management, surgical code editing with edit_block, and even
      interactive REPL sessions. It's built on top of the MCP Filesystem Server
      but adds crucial capabilities like search-and-replace editing and
      intelligent process control.

The workflow change: This is where everything came together. I
      could now say “The authentication tests are failing, please fix the issue”
      and the agent would:


1. Run the test suite to see the specific failures

2. Read the failing test files to understand what was expected

3. Examine the authentication module code

4. Search the codebase for related patterns

5. Look up the documentation for the relevant library

6. Make edits to fix the implementation

7. Re-run the tests to verify the fix

8. Search for similar patterns elsewhere that might need updating


All of this happened in a single conversation thread, with the agent
      maintaining context throughout. It wasn't just generating code
      suggestions—it was actively debugging, editing, and verifying fixes like a
      pair programming partner.

The security model is thoughtful too, with configurable allowed
      directories, blocked commands, and proper permission boundaries. You can
      learn more about its extensive capabilities at the Desktop Commander
      documentation.



The Complete System

Here's our final agent configuration:

import asyncio


import subprocess
import boto3
from pydantic_ai import Agent
from pydantic_ai.mcp import MCPServerStdio
from pydantic_ai.models.bedrock import BedrockConverseModel
from pydantic_ai.providers.bedrock import BedrockProvider
from botocore.config import Config as BotocoreConfig

bedrock_config = BotocoreConfig(
    read_timeout=300,
    connect_timeout=60,
    retries={"max_attempts": 3},
)
bedrock_client = boto3.client(
    "bedrock-runtime", region_name="eu-central-1", config=bedrock_config
)
model = BedrockConverseModel(
    "eu.anthropic.claude-sonnet-4-20250514-v1:0",
    provider=BedrockProvider(bedrock_client=bedrock_client),
)
agent = Agent(
    model=model,
)


instructions = """
You are a specialised agent for maintaining and developing the XXXXXX codebase.

## Development Guidelines:

1. **Test Failures:**
   - When tests fail, fix the implementation first, not the tests
   - Tests represent expected behavior; implementation should conform to tests
   - Only modify tests if they clearly don't match specifications

2. **Code Changes:**
   - Make the smallest possible changes to fix issues
   - Focus on fixing the specific problem rather than rewriting large portions
   - Add unit tests for all new functionality before implementing it

3. **Best Practices:**
   - Keep functions small with a single responsibility
   - Implement proper error handling with appropriate exceptions
   - Be mindful of configuration dependencies in tests

Remember to examine test failure messages carefully to understand the root cause before making any changes.
"""


run_python = MCPServerStdio(
    "deno",
    args=[
        "run",
        "-N",
        "-R=node_modules",
        "-W=node_modules",
        "--node-modules-dir=auto",
        "jsr:@pydantic/mcp-run-python",
        "stdio",
    ],
)

internet_search = MCPServerStdio(command="uvx", args=["duckduckgo-mcp-server"])
code_reasoning = MCPServerStdio(
    command="npx",
    args=["-y", "@mettamatt/code-reasoning"],
    tool_prefix="code_reasoning",
)
desktop_commander = MCPServerStdio(
    command="npx",
    args=["-y", "@wonderwhy-er/desktop-commander"],
    tool_prefix="desktop_commander",
)
awslabs = MCPServerStdio(
    command="uvx",
    args=["awslabs.core-mcp-server@latest"],
    env={"FASTMCP_LOG_LEVEL": "ERROR"},
    tool_prefix="awslabs",
)
aws_docs = MCPServerStdio(
    command="uvx",
    args=["awslabs.aws-documentation-mcp-server@latest"],
    env={"FASTMCP_LOG_LEVEL": "ERROR", "AWS_DOCUMENTATION_PARTITION": "aws"},
    tool_prefix="aws_docs",
)
context7 = MCPServerStdio(
    command="npx", args=["-y", "@upstash/context7-mcp"], tool_prefix="context"
)

agent = Agent(
    instructions=instructions,
    model=model,
    mcp_servers=[
        run_python,
        internet_search,
        code_reasoning,
        context7,
        awslabs,
        aws_docs,
        desktop_commander,
    ],
)


@agent.tool_plain()
def run_unit_tests() -> str:
    """Run unit tests using uv."""
    result = subprocess.run(
        ["uv", "run", "pytest", "-xvs", "tests/"], capture_output=True, text=True
    )
    return result.stdout


async def main():
    async with agent.run_mcp_servers():
        await agent.to_cli()


if __name__ == "__main__":
    asyncio.run(main())


How it changes our workflow:


Debugging becomes collaborative: you have an intelligent partner
        that can analyze error messages, suggest hypotheses, and help test
        solutions.

Learning accelerates: when working with unfamiliar libraries or
        patterns, the agent can explain existing code, suggest improvements, and
        teach you why certain approaches work better.

Context switching reduces: rather than jumping between
        documentation, Stack Overflow, AWS Console, and your IDE, you have a
        single interface that can access all these resources while maintaining
        context about your specific problem.

Problem-solving becomes structured: rather than jumping to
        solutions, the agent can break down complex issues into logical steps,
        explore alternatives, and explain its reasoning. Like having a real life talking rubber duck!

Code review improves: the agent can review your changes, spot
        potential issues, and suggest improvements before you commit—like having a
        senior developer looking over your shoulder.




What We Learned About CLI Agents

Building our own agent revealed several insights about this emerging
      paradigm:


MCP is (almost) all you need: the magic isn't in any single
        capability, but in how they work together. The agent that can run tests,
        read files, search documentation, execute code, access AWS services, and
        reason through problems systematically becomes qualitatively different
        from one that can only do any single task.

Current information is crucial: having access to real-time search
        and up-to-date documentation makes the agent much more reliable for
        real-world development work where training data might be outdated.

Structured thinking matters: the code reasoning capability
        transforms the agent from a clever autocomplete into a thinking partner
        that can break down complex problems and explore alternative
        solutions.

Context is king: commercial agents like Claude Code are impressive
        partly because they maintain context across all these different tools.
        Your agent needs to remember what it learned from the test run when it's
        making file changes.

Specialisation matters: our agent works better for our specific
        codebase than general-purpose tools because it understands our patterns,
        conventions, and tool preferences. If it falls short in any area then we
        can go and make the required changes.




The Road Ahead

The CLI agent paradigm is still evolving rapidly. Some areas we're
      exploring:


AWS-specific tooling: the AWS Labs MCP servers
        (https://awslabs.github.io/mcp/) provide incredible depth for cloud-native
        development—from CloudWatch metrics to Lambda debugging to IAM policy
        analysis.

Workflow Enhancements: teaching the agent our common development
        workflows so it can handle routine tasks end-to-end. Connecting the agent
        to our project management tools so it can understand priorities and
        coordinate with team processes.

Benchmarking: Terminal Bench
        looks like a great dataset and leaderboard to test this toy agent against
        the big boys!




Why This Matters

CLI coding agents represent a fundamental
      shift from AI as a writing assistant to AI as a development partner.
      Unlike Copilot's autocomplete or ChatGPT's Q&A, these agents can:


Understand your entire project context

Execute tasks across multiple tools

Maintain state across complex workflows

Learn from your specific codebase and patterns


Building one yourself—even a simple version—gives you insights into
      where this technology is heading and how to make the most of commercial
      tools when they arrive.

The future of software development isn't just about writing code
      faster. It's about having an intelligent partner that understands your
      goals, your constraints, and your codebase well enough to help you think
      through problems and implement solutions collaboratively.

And the best way to understand that future? Build it yourself.



]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Uncertain<T>]]></title>
            <link>https://nshipster.com/uncertainty/</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45054703</guid>
            <description><![CDATA[GPS coordinates aren’t exact. Sensor readings have noise. User behavior is probabilistic. Yet we write code that pretends uncertainty doesn’t exist, forcing messy real-world data through clean Boolean logic.]]></description>
            <content:encoded><![CDATA[
              You know what’s wrong with people?
                They’re too sure of themselves.
              Better to be wrong and own it than be right with caveats.
                Hard to build a personal brand out of nuance these days.
                People are attracted to confidence — however misplaced.
              But can you blame them? (People, that is)
                Working in software,
                the most annoying part of reaching Senior level
                is having to say “it depends” all the time.
                Much more fun getting to say
                “let’s ship it and iterate” as Staff or
                “that won’t scale” as a Principal.
              Yet, for all of our intellectual humility,
                why do we write vibe code like this?
              if currentLocation.distance(to: target) < 100 {
    print("You've arrived!") // But have you, really? 🤨
}

              GPS coordinates aren’t exact.
                They’re noisy. They’re approximate. They’re probabilistic.
                That horizontalAccuracy property tucked away in your CLLocation object
              is trying to tell you something important:
              you’re probably within that radius.
              Probably.
            A Bool, meanwhile, can be only true or false.
              That if statement needs to make a choice one way or another,
              but code like this doesn’t capture the uncertainty of the situation.
              If truth is light,
              then current programming models collapse the wavefunction too early.
            
              Picking the Right Abstraction
            In 2014, researchers at the University of Washington and Microsoft Research
              proposed a radical idea:
              What if uncertainty were encoded directly into the type system?
              Their paper,
              Uncertain<T>: A First-Order Type for Uncertain Data
              introduced a probabilistic programming approach that’s both
              mathematically rigorous and surprisingly practical.
            
            As you’d expect for something from Microsoft in the 2010s,
              the paper is implemented in C#.
              But the concepts translate beautifully to Swift.
            You can find my port on GitHub:
            import Uncertain
import CoreLocation

let uncertainLocation = Uncertain<CLLocation>.from(currentLocation)
let nearbyEvidence = uncertainLocation.distance(to: target) < 100
if nearbyEvidence.probability(exceeds: 0.95) {
    print("You've arrived!") // With 2σ confidence 🤓
}

            When you compare two Uncertain values,
              you don’t get a definitive true or false.
              You get an Uncertain<Bool> that represents the probability of the comparison being true.
            
            The same is true for other operators, too:
            // How fast did we run around the track?
let distance: Double = 400 // meters
let time: Uncertain<Double> = .normal(mean: 60, standardDeviation: 5.0) // seconds
let runningSpeed = distance / time // Uncertain<Double>

// How much air resistance?
let airDensity: Uncertain<Double> = .normal(mean: 1.225, standardDeviation: 0.1) // kg/m³
let dragCoefficient: Uncertain<Double> = .kumaraswamy(alpha: 9, beta: 3) // slightly right-skewed distribution
let frontalArea: Uncertain<Double> = .normal(mean: 0.45, standardDeviation: 0.05) // m²
let airResistance = 0.5 * airDensity * frontalArea * dragCoefficient * (runningSpeed * runningSpeed)

            This code builds a computation graph,
              sampling only when you ask for concrete results.
              The library uses
              Sequential Probability Ratio Testing (SPRT)
              to efficiently determine how many samples are needed —
              maybe a few dozen times for simple comparisons,
              scaling up automatically for complex calculations.
            // Sampling happens only when we need to evaluate
if ~(runningSpeed > 6.0) {
    print("Great pace for a 400m sprint!")
}
// SPRT might only need a dozen samples for this simple comparison

let sustainableFor5K = (runningSpeed < 6.0) && (airResistance < 50.0)
print("Can sustain for 5K: \(sustainableFor5K.probability(exceeds: 0.9))")
// Might use 100+ samples for this compound condition

            Using an abstraction like Uncertain<T> forces you to deal with uncertainty as a first-class concept
              rather than pretending it doesn’t exist.
              And in doing so, you end up with much smarter code.
            To quote Alan Kay:
            
              Point of view is worth 80 IQ points
                
            
            Before we dive deeper into probability distributions,
              let’s take a detour to Monaco and talk about
              Monte Carlo sampling.
            
              The Monte Carlo Method
            Behold, a classic slot machine (or “fruit machine” for our UK readers 🇬🇧):
            enum SlotMachine {
    static func spin() -> Int {
        let symbols = [
            "◻️", "◻️", "◻️",  // blanks
            "🍒", "🍋", "🍊", "🍇", "💎"
        ]

        // Spin three reels independently
        let reel1 = symbols.randomElement()!
        let reel2 = symbols.randomElement()!
        let reel3 = symbols.randomElement()!

        switch (reel1, reel2, reel3) {
        case ("💎", "💎", "💎"): return 100  // Jackpot!
        case ("🍒", "🍒", "🍒"): return 10
        case ("🍇", "🍇", "🍇"): return 5
        case ("🍊", "🍊", "🍊"): return 3
        case ("🍋", "🍋", "🍋"): return 2
        case ("🍒", _, _), // Any cherry
             (_, "🍒", _),
             (_, _, "🍒"):
            return 1
        default:
            return 0  // Better luck next time
        }
    }
}

            Should we play it?
            
            Now, we could work out these probabilities analytically —
              counting combinations,
              calculating conditional probabilities,
              maybe even busting out some combinatorics.
            Or we could just let the computer pull the lever a bunch and see what happens.
            
            let expectedPayout = Uncertain<Int> {
    SlotMachine.spin()
}.expectedValue(sampleCount: 10_000)
print("Expected value per spin: $\(expectedPayout)")
// Expected value per spin: ≈ $0.56

            At least we know one thing for certain:
              The house always wins.
            
              Beyond Simple Distributions
            While one-armed bandits demonstrate pure randomness,
              real-world applications often deal with more predictable uncertainty.
            Uncertain<T> provides a
              rich set of probability distributions:
            // Modeling sensor noise
let rawGyroData = 0.85  // rad/s
let gyroReading = Uncertain.normal(
    mean: rawGyroData,
    standardDeviation: 0.05  // Typical gyroscope noise in rad/s
)

// User behavior modeling
let userWillTapButton = Uncertain.bernoulli(probability: 0.3)

// Network latency with long tail
let apiResponseTime = Uncertain.exponential(rate: 0.1)

// Coffee shop visit times (bimodal: morning rush + afternoon break)
let morningRush = Uncertain.normal(mean: 8.5, standardDeviation: 0.5)  // 8:30 AM
let afternoonBreak = Uncertain.normal(mean: 15.0, standardDeviation: 0.8)  // 3:00 PM
let visitTime = Uncertain.mixture(
    of: [morningRush, afternoonBreak],
    weights: [0.6, 0.4]  // Slightly prefer morning coffee
)

            
          Uncertain<T> also provides comprehensive
            statistical operations:
          // Basic statistics
let temperature = Uncertain.normal(mean: 23.0, standardDeviation: 1.0)
let avgTemp = temperature.expectedValue() // about 23°C
let tempSpread = temperature.standardDeviation() // about 1°C

// Confidence intervals
let (lower, upper) = temperature.confidenceInterval(0.95)
print("95% of temperatures between \(lower)°C and \(upper)°C")

// Distribution shape analysis
let networkDelay = Uncertain.exponential(rate: 0.1)
let skew = networkDelay.skewness() // right skew
let kurt = networkDelay.kurtosis() // heavy tail

// Working with discrete distributions
let diceRoll = Uncertain.categorical([1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1])!
diceRoll.entropy()  // Randomness measure (~2.57)
(diceRoll + diceRoll).mode() // Most frequent outcome (7, perhaps?)

// Cumulative probability
if temperature.cdf(at: 25.0) < 0.2 {  // P(temp ≤ 25°C) < 20%
    print("Unlikely to be 25°C or cooler")
}

          The statistics are computed through sampling.
            The number of samples is configurable, letting you trade computation time for accuracy.
          
            Putting Theory to Practice
          Users don’t notice when things work correctly,
            but they definitely notice impossible behavior.
            When your running app claims they just sprinted at 45 mph,
            or your IRL meetup app shows someone 500 feet away when GPS accuracy is ±1000 meters,
            that’s a bad look 🤡
          So where do we go from here?
            Let’s channel our Senior+ memes from before for guidance.
          That Staff engineer saying “let’s ship it and iterate”
            is right about the incremental approach.
            You can migrate uncertain calculations piecemeal
            rather than rewriting everything at once:
          extension CLLocation {
    var uncertain: Uncertain<CLLocation> {
        Uncertain<CLLocation>.from(self)
    }
}

// Gradually migrate critical paths
let isNearby = (
    currentLocation.uncertain.distance(to: destination) < threshold
).probability(exceeds: 0.68)

          And we should consider the Principal engineer’s warning of “that won’t scale”.
            Sampling has a cost, and you should understand the
            computational overhead for probabilistic accuracy:
          // Fast approximation for UI updates
let quickEstimate = speed.probability(
    exceeds: walkingSpeed,
    maxSamples: 100
)

// High precision for critical decisions
let preciseResult = speed.probability(
    exceeds: walkingSpeed,
    confidenceLevel: 0.99,
    maxSamples: 10_000
)

          
          Start small.
            Pick one feature where GPS glitches cause user complaints.
            Replace your distance calculations with uncertain versions.
            Measure the impact.
          Remember:
            the goal isn’t to eliminate uncertainty —
            it’s to acknowledge that it exists and handle it gracefully.
            Because in the real world,
            nothing is certain except uncertainty itself.
          And perhaps,
            with better tools,
            we can finally stop pretending otherwise.
        ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ask HN: The government of my country blocked VPN access. What should I use?]]></title>
            <link>https://news.ycombinator.com/item?id=45054260</link>
            <guid isPermaLink="false">https://news.ycombinator.com/item?id=45054260</guid>
            <description><![CDATA[If you need to bypass censorship, you'll need a tool specifically designed for anti-censorship, rather than any one repurposed for that.]]></description>
            <content:encoded><![CDATA[
If you need to bypass censorship, you'll need a tool specifically designed for anti-censorship, rather than any one repurposed for that.Since China has the most advanced network censorship, the Chinese have also invented the most advanced anti-censorship tools.The first generation is shadowsocks. It basically encrypts the traffic from the beginning without any handshakes, so DPI cannot find out its nature. This is very simple and fast and should suffice in most places.The second generation is the Trojan protocol. The lack of a handshake in shadowsocks is also a distinguishing feature that may alert the censor and the censor can decide to block shadowsocks traffic based on suspicions alone. Trojan instead tries to blend in the vast amount of HTTPS traffic over the Internet by pretending to be a normal Web server protected by HTTPS.After Trojan, a plethora of protocol based on TLS camouflaging have been invented.1. Add padding to avoid the TLS-in-TLS traffic characteristics in the original Trojan protocol. Protocols: XTLS-VLESS-VISION.2. Use QUIC instead of TCP+TLS for better performance (very visible if your latency to your tunnel server is high). Protocols: Hysteria2 and TUIC.3. Multiplex multiple proxy sessions in one TCP connection. Protocols: h2mux, smux, yamux.4. Steal other websites' certificates. Protocols: ShadowTLS, ShadowQUIC, XTLS-REALITY.Oh, and there is masking UDP traffic as ICMP traffic or TCP traffic to bypass ISP's QoS if you are proxying traffic through QUIC. Example: phantun.
Is WebRTC being blocked by China?  I'm wondering whether it'd be worthwile to implement an VPN that uses WebRTC as a transport.  With cover traffic, it could likely be made to look just like a video call.
No, it’s illegal to bring starlink devices here, and I heard that Elon Musk chooses to block China from accessing starlink too, to appease the Chinese authorities.
Hello! I've got experience working on censorship circumvention for a major VPN provider (in the early 2020s).- First things first, you have to get your hands on actual VPN software and configs. Many providers who are aware of VPN censorship and cater to these locales distribute their VPNs through hard-to-block channels and in obfuscated packages. S3 is a popular option but by no means the only one, and some VPN providers partner with local orgs who can figure out the safest and most efficient ways to distribute a VPN package in countries at risk of censorship or undergoing censorship.- Once you've got the software, you should try to use it with an obfuscation layer.Obfs4proxy is a popular tool here, and relies on a pre-shared key to make traffic look like nothing special. IIRC it also hides the VPN handshake. This isn't a perfectly secure model, but it's good enough to defeat most DPI setups.Another option is Shapeshifter, from Operator (https://github.com/OperatorFoundation). Or, in general, anything that uses pluggable transports. While it's a niche technology, it's quite useful in your case.In both cases, the VPN provider must provide support for these protocols.- The toughest step long term is not getting caught using a VPN. By its nature, long-term statistical analysis will often reveal a VPN connection regardless of obfuscation and masking (and this approach can be cheaper to support than DPI by a state actor). I don't know the situation on the ground in Indonesia, so I won't speculate about what the best way to avoid this would be, long-term.I will endorse Mullvad as a trustworthy and technically competent VPN provider in this niche (n.b., I do not work for them, nor have I worked for them; they were a competitor to my employer and we always respected their approach to the space).
Thanks for this, UK citizen/subject here I believe the UK government is likely to go down the path of banning vpns.
Can someone competent pull together a manual to set a vpn with obfuscation? I am sure it will be well received.A github repo would be ideal really
It will be done very soon...."Dame Rachel told BBC Newsnight: "Of course, we need age verification on VPNs - it's absolutely a loophole that needs closing and that's one of my major recommendations." - https://www.bbc.com/news/articles/cn438z3ejxyoThey phrase it as age verification, but what they mean is the VPN provider needs to provide them the client list...
> First things first, you have to get your hands on actual VPN software and configs.It would be nice if one of the big shortwave operators could datacast these packages to the world as a public service.
There isn't enough bandwidth in HF to transmit data. Digital HF audio is 20 kHz wide so maybe 50kbps. The entire HF band is only 3-30 MHz.
50 kb/s x 1000 bits/kb x 3600 s/hr x 24 hr/day x 1 byte/8 bits x 1 MB / 1000000 bytes = 540 MB/day. That's enough to download VPN software and a Linux distribution to run it on in a day.If you've already got a Linux system, the Debian openvpn package is under 1 MB and at 50 kb/s would take under 3 minutes to download. I don't know if openvpn in particular is suitable for people who are trying to evade their government, but would whatever features it is missing add substantially more size?
Yeah, you could use forward error correction too, so any n bits would be enough to reconstruct the input.Of course then you get into needing software to decode the more advanced encodings; maybe start with a voice transmission explaining in plain language how to decode the first layer, which gives you a program that can decode the second layer, or something.Starting to sound like an interesting project.
300 baud. Was enough to download grainy porn pics. With a proper download tool that continues after hangups etc you can just leave it on for a week and I have when downloading software end 70s. No problem. Also via the airwaves: we had software via the radio every sunday. Works fine. Modern software is shitty large: it would be nice if a VPN provider would just release the driver and a cli which should not weigh over a mega (far less but outside mr Whitney i am not sure if that type of software dev still exists) for this type of transfer.
Wireguard ships with the Linux kernel so you only need to receive ~60 bytes of configuration information.
Is that true? I thought wg-quick etc were just convenience functions and that it's relatively trivial to use iproute2 to configure a VPN link
sure there is, you can send files over HF, it may not be FAST, but once you get it into the country, you can just copy the file with a faster method (eg: usb drive), WINLINK supports attachments, so you could absolutely send these files over HF
btw, veracrypt is the name if the follow up project. truecrypt shut down over a decade ago rather abruptly, so anything labeled truecrypt today is suspect as either out of date or potential malware.
Nah, just drop a few thousand 1GB flash drives from a plane. Load them with a tor browser, a wireguard client, and instructions on finding a remote exit. Only one copy needs to survive and it can spread very quickly and irreversibly by foot.
Yeah, this is a great approach if you're already at war with a country.If you're not and they're still allowing your planes to fly through their airspace then this is a great way to ensure that they lock your (and your friends') planes out.
The problem is the countries, which censor Internet and block VPNs, also jam shortwave radio signals.
It's possible but also difficult to jam radio. That's part of why programs like Radio Free Asia[0,1] exist. Even if you can't broadcast from inside a territory you can broadcast from outside. It can be jammed but it is a tough cat and mouse game and jamming isn't precise. So when you jam there are causalities. Not to mention that jamming can be quite expensive.I'm not saying that makes the problem easy, but I'll say that jamming isn't a very strong defense.Though the bigger issue here is probably bandwith. It's hard to be both long range and data dense. There's probably easier ways to distribute this. Hell, both Koreas are known to transport different things via balloons.[0] https://en.wikipedia.org/wiki/Radio_Free_Asia[1] It is also why projects like Tor and Signal get funding from RFA. Maybe the US doesn't want encrypted services here, but if anything, it's for the same reason they do want encrypted services in other countries.
I’m not sure that’s super feasible any longer with the advent of cheap SDRs. Over-the-horizon HF broadcast can be heard with a simple speaker wire antenna inside your house. If anyone is interested in trying to deploy such an idea, I’d love to participate as an avid ham.
Could I ask for a source on that and how common it is?Seems like it was used way back in the cold war (and even then not blocked/jammed) and I'd guess that current authoritarian regimes would perhaps not bother considering how few could use it.
Source: trust me bro, but you can find HF jamming pretty easily on Internet connected SDRs, especially near "sensitive" countries.
The UK used to get around this with very powerful medium-wave signals, the site at Orfordness could put out the BBC World Service at 2 MW towards the USSR and the Eastern Bloc. This site was built on the remains of a 1960s UK/US over-the-horizon radar installation that never worked properly.These broadcasts were shut down in the early '10s but ironically one of the masts is still in use by Radio Caroline, the former pirate who broke the BBC's radio monopoly by putting their station just outside of UK territorial waters. Their 4 kW goes pretty far given the site's previous role, heard them as far away as the Lake District.
if it became a widespread practice, wouldnt even the countries that yet dont do it probably start doing it?
Streisand is extremely out of date and wouldn’t last long in China, but I don’t know how sophisticated Indonesia’s firewall is
i have a few chinese friends and they say it's always easy to get a working vpn. that might not be true in a Tien An Minh type crisis, i dunno, but month in month out year upon year they surf western sites, exchange winnie the pooh pictures, etc. i suppose the people i know could be relatively upper class, i have no idea what type difference that could make. i had a chinese gf in LA who would send... my >cough< pictures... to her mother in china because she enjoyed them
This is no 'nothing special' with Obfs4proxy. DPI sees it as random byte stream, thus your government can decide to block unknown protocols. Instead, you should trick DPI into thinking it sees HTTPS. Unless your government decides to block HTTPS.
Hi, posting from my main account (I'm also the poster of the GP comment)."Nothing special" in this case was meant to describe the fact that it's random data with no identifiable patterns inherent to the data; you're absolutely right that that's what obfs4 does. I understand the confusion though, this phrasing could be better.    > your government can decide to block unknown protocols

This does happen, though when I worked in the industry it wasn't common. Blocking of specific protocols was much more of an obstacle.    > you should trick DPI into thinking it sees HTTPS. Unless your government decides to block HTTPS

HTTPS blocking (typically based on either the presence of a specific SNI field value, or based on the use of the ESNI/ECH TLS extension) was prolific. I won't comment on whether this was effective or not in impeding efforts to get people in these places connected.I will say though, Operator's Replicant does something similar to what you're describing in that it can mimic unrelated protocols. It's a clever approach, unfortunately it was a bit immature when I was working in that area so the team didn't adopt it while I was around.
> your government can decide to block unknown protocolsHas any government ever done that? Seems like it would just break everything (because the world is full of devices that use custom protocols!) at great computational expense.
The only VPN technology I see that blends as HTTPS is MASQUE IP Proxying, and the only implementation I know that does this is iCloud Private Relay. It is also trivial to block because blocking 443/udp doesn't really affect accessing the Internet.
Exactly this. Hell, for OP's use case of accessing things like twitter, a good old fashioned https proxy would be entirely fine, and likely not even illegal.
what i was thinking. DPI might pick up on proxy headers.
alternatively, idk how far one would get just slapping wireguard or openvpn on a VPS somewhere on port 443. that used to work fairly well but i suppose my experience there is like 10+ years out of date by now.i know a US based tech firm i worked for around 2020 had a simple HTTPS proxy for chinese clients to download content updates. worked really well. it was hosted on some cloud provider and accessible via DNS name. so its not like it wasn't easy to block it. they just didn't bother or it was lost in a sea of other similar activities.that all being said, regarding oppressive regimes and political turmoil situations: 
if your health or freedom is at risk, don't rely on internet people's 'guesswork' (hard to tell where ppl get their info from, and what its based on etc.). be careful. if you are not confident, don't go forward with it. Try to get advice from local experts instead, who are familiar in the specific context you are dealing with.
Unless your government decides to block HTTPS.In which case you use stenography, but I believe even the Great Firewall of China doesn't block HTTPS completely.
Nit: you likely mean steganography, stenography is what court reporters do :)I encourage you and anyone else here to read into the GFW if you're interested. It's more like the Great Firewalls -- there's regional fragmentation with different vendors, operators, implementations and rules between different parts of the country.Predictably this means there's no one-size-fits-all solution to circumventing censorship on the Chinese internet, and research into this area's difficult since China has both the technical means to identify violations very efficiently as well as the bureaucratic infrastructure to carry out enforcement actions against a considerable portion of those people who violate the GFW rules (with enforcement action being anything from a "cooldown period" on your internet connection where you can't make any connections for some amount of time between minutes and days, fines, or imprisonment depending on the type of content you were trying to access).So, the ethics of digging into this get very muddy, very fast.
Thank you very much for a detailed answer. Might I rudely ask -- as you're knowledgeable in this space, what do you think of Mullvad's DAITA, which specifically aims to defeat traffic analysis by moving to a more pulsed constant bandwidth model?
DAITA was introduced after my time in the industry, but this isn't a new idea (though as far as I know, it's the first time this kind of thing's been commercialized).It's clever. It tries to defeat attacks against one of the tougher parts of VPN connections to reliably obfuscate, and the effort's commendable, but I'll stop short of saying it's a good solution for one big reason: with VPNs and censorship circumvention, the data often speaks for itself.A VPN provider working in this space will often have aggregate (and obviously anonymized, if they're working in good faith) stats about success rates and failure classes encountered from clients connecting to their nodes. Where I worked, we didn't publish this information. I'm not sure where Mullvad stands on this right now.In any case -- some VPN providers deploying new technology like this will partner with the research community (because there's a small, but passionate formal research community in this space!) and publish papers, studies, and other digests of their findings. Keep an eye out for this sort of stuff. UMD's Breakerspace in the US in particular had some extremely clever people working on this stuff when I was involved in the industry.
The "inspection" part of DPI isn't limited to encrypted payloads. It's straightforward enough to look at application-level protocol headers and identify e.g. a Wireguard or OpenVPN or SSH connection, even if you can't decrypt the payload. That could be used as sufficient grounds to either block the traffic or punish the user.
I thought OpenVPN simply opens a TLS encrypted connection. How does it look different than HTTPS?
Pushing certs to end user devices is simple. First you create your own national CA. Then you make all government services use TLS certificates signed by the national CA. Then you make phone vendors preinstall the root cert of the national CA into the trust store if they want to sell them in your country. Then you make your ISPs buy and install MITM appliances.
DPI refers to a broad class of products which attempt to find signals and categorize traffic according to a ruleset, either to block it or throttle the speeds, etc.While access to plaintext is useful, it's not required for other rules which are eg looking at the timing and frequency of packets.
Because you are leaking information left and right with TCP / DNS and all these basic protocols that powering the internet today. When these were designed people were happy that it worked at all and nobody really tought that it should be state actor proof. Except maybe DJB. https://www.curvecp.org/
There are a couple of ways.The main one is called an Eclipse Attack in cyber circles, and it can be done at any entity operating at the ASN layer so long as they can position themselves to relay your traffic.The adversary can invisibly (to victim PoV) modify traffic if they have a cooperating rootPKI cert (anywhere in the ecosystem) that isn't the originating content provider, so long as they recognize the network signature (connection handshake); solely by terminating encryption early.Without a cert, you can still listen in with traffic analysis, the fetched traffic that's already been encrypted with their key (bit for bit), as known plaintext the math quickly reduces. SNI and a few other artifacts referencing the resources/sites are not part of the encrypted payload.Its more commonly known in a crypto context, but that kind of attack can happen anywhere. It even works against TOR. One of the first instances (afaik) was disclosed by Princeton researches in 2015, under the Raptor paper.
I've studied and worked in computer security for over a decade and have never heard of an "eclipse attack" before. Is this blockchain specific terminology? It seems like an adversarial network partition?
I've been a SA Generalist for a decade, primarily in biopharma. This is the terminology the people I worked alongside used which included both Network and Computer Engineers.It was explained to me that its just another version of MITM, the only difference is the number of resilient paths that need to be compromised. Eclipse type of attacks focus on compromising multiple nodes and most deal with breaking consensus algorithmic based software, which is quite common of blockchain, but that isn't the only place.TL;DR 
In a single path graph you have MITM, in a N-path graph of connectivity you have Eclipse. Two heads of the same coin.Loosely I guess it would be considered an adversarial network partition at the ASN/BGP level. For active attacks you'd have to broadcast improperly, but for regional attacks at the ASN level you just have to be positioned correctly passively. That's why the whole AT&T room for the NSA back in the day was such a  big deal. A lot of these attacks have been known about for a long time.For instance, the same kind of attack could easily be done by compromising firmware within 1-step away from edge devices (Modems/Routers/ISP TFTP servers).Quite a lot of what was in the nationstate war-chest 10 years ago has been leaked, and is actively being used by non-state actors at this point.Its mad how sophisticated things are now. On some campuses, its not unheard of to see drones flying by to hack the radio logitech keyboards of campus computers; where they try to drop malware OTA through a powershell or tty keyboard spawned terminal prompt. Crazy stuff.
Patterns of data transmission (network behavioral analysis, I just made that term up), analyzing IP and ports, inspecting SSL handshakes for destination site. In short, metadata.
Obfs4proxy and Shapeshifter are an absolute PITA to install.Get your own VPS server (VPS in EU/US with 2GB of ram, 40GB of disk space and TBs/month of traffic go for $10 a year, it's that cheap). Never get anything in the UK and even USA is weird. I'd stick with EU.Install your software (wireguard + obsfuscation or even tailscale with your own DERP server)Another simpler alternative is just `ssh -D port` and use it as a SOCKS server. It's usually not blocked but very obvious.
I just spent 3 months in China this summer. The GFW has become much more sophisticated than I remember. I found only one method that reliably worked. That was to use Holafly (an international eSIM provider) and use its built-in VPN. China largely doesn’t care if foreigners get around the GFW, I guess.Another method that usually worked was ProtonVPN with protocol set to Wireguard. Not sure why this worked, it’s definitely a lot more detectable than other methods I tried. But as long as I rotated which US server I used every few days, this worked fine.No luck with shadowsocks, ProtonVPN “stealth” mode, Outline+Digital Ocean, or even Jump / Remote Desktop. Jump worked the longest at several hours before it became unbearably slow, I’m still not sure if I was actually throttled or my home computer started misbehaving.I didn’t get around to setting up a pure TLS proxy, or proxying traffic through a domain that serves “legitimate” traffic, so no idea if that still works.
That article seems bogus.IP blocks are routinely bought and sold, and hence their geo location database entries are not reliable.If you’re physically in the EU or the UK and your traffic is routed through China it would be unusably slow and immediately noticeable to non-technical users.
Exclusively use Shadowsocks here in the mainland. Was surprised to see Ngrok to work as well, but prolly not very long/reliable.
Regarding your usage:Organic Maps app can download all maps for offile and works OK in China.It uses openstreetmap data.1024 bit RSA keys is laughable. I'm inclined to think this was not by accident.Idea 1 and 2 are basically the same.
Which countries you need to avoid depends on your threat model. For example, there is need to avoid the USA if all you're trying to do is bypass the Chinese firewall. There might even be a legitimate use case for pretending to have a UK IP address.Since OP is in Southeast Asia, a VPS in JP or SG will probably hit a decent balance between latency and censorship avoidance.
There are some techniques like fragmented TLS and reordered packets that work in some cases. Also using vanilla HTTPS transport is a good start for many places. URnetwork is an open source, decentralized option that does all of these out of the box. You can get it on the major stores or F-Droid.
Mullvad is a bad choice for this particular case because they publish all their IPs, which makes them very easy to block. You should look into VPN providers that do not publish their IPs and that have a wide range of IP classes and multiple ASNs, which look like ordinary networks not associated with VPNs. In my experience, NordVPN and ExpressVPN have many of these.
Express and Nord are completely useless in China. Mullvad worked fine two years ago but is getting worse, not sure if it still works currently.
I wonder if it can be embedded in a video stream, like a video of a lava lamp that you always have open, but the lsb of ever byte is meaningful.
That's an interesting idea, and probably something you might be able to achieve with a tool like h26forge.It's also probably more useful to just have a connection be fully dedicated to a VPN, and have the traffic volume over time mimic what you'd see in a video, rather than embedding it in a video -- thanks to letsencrypt, much of the web's served over TLS these days (asterisks for countries like KZ and TM which force the use of a state-sponsored CA), so going to great lengths to embed your VPN in a video isn't really practical.
I’m curious about what makes it difficult to block a vpn provider long term. You said getting the software is difficult, but can a country not block known vpn ingress points?
A country can and absolutely will block known VPN ingress points. There are two tricks that we can use to circumvent this:- Host on a piece of infrastructure that's so big that you can't effectively block it without causing a major internet outage (think: S3, Cloudflare R2, etc). Bonus points if you can leverage something like ECH (ex-ESNI) to make it harder to identify a single bucket or subdomain.- Keep spawning new domains and subdomains to distribute your binaries.There are complications with both approaches. Some countries block ECH outright. Some have no problem shutting the internet down wholesale for a little bit. The domain-hopping approach presents challenges w/r/t establishing trust (though not insurmountable ones, much of the time).These are thing that have to be judged and balanced on a case-by-case basis, and having partners on the ground in these places really helps reduce risk to users trying to connect from these places, but then you have to be very careful talking to then since they could themselves get in trouble for trying to organize a VPN distribution network with you. It's layers on layers, and at some point it helps to just have someone on the team with a background in working with people in vulnerable sectors and someone else from a global affairs and policy background to try and keep things as safe as they can be for people living under these regimes.
you can also throttlefor instance AWS hosted things in China are typically just severly throttled and flaky. Github is the best example. it works but webpage assets often either dont load or load incredibly slowly. this pushes people to local services without breaking the web entirely
I've heard of domain fronting, where you host something on a subdomain of a large provider like Azure or Amazon. Is this what you're talking about when you say> - Host on a piece of infrastructure that's so big that you can't effectively block it without causing a major internet outage (think: S3, Cloudflare R2, etc).How can one bounce VPN traffic through S3? Or are you just talking about hosting client software, ingress IP address lists, etc?
That's generally for distribution, but yeah, it's a form of domain fronting.There are some more niche techniques that are _really_ cool but haven't gained widespread adoption, too, like refractive routing. The logistics of getting that working are particularly challenging since you need a willing partner who'll undermine some of their trustworthiness with some actors to support (what is, normally, to them) your project.
If I understand correctly, refractive routing basically just gets big trustworthy cloud providers to host the VPNs so that third world governments can't block them without blocking the cloud too. It's an unfortunate solution since tech platforms are international entities that should be neutral. When America asks them to take sides and prevent other countries from implementing their desired policies, America is spending the political capital and trust that tech companies worked hard to earn. It's also really foolish of those countries to just block things outright. They could probably achieve their policy goals simply by slowing down access to VPN endpoints.
ECH (Encrypted Client Hello) brings back a kind of domain fronting, except you don't need to front anything at all. the Client Hello itself is encrypted, so the SNI is hidden.hopefully ECH will catch on. I suspect the corporate backlash over domain fronting was them not wanting to be caught in the crossfire if their domain was used as a front. if e.g. Signal used "giphy.com" as a front, Russia might block giphy to block Signal. but if Signal is hosted on, say, AWS, and ECH was used, Russia would have no option other than blocking the entirety of AWS, since all TLS handshakes to AWS would look the same.though cloud providers (other than CloudFlare, respect!) don't seem to care about censorship or surveillance anymore, and might decline to adopt ECH if some lucrative market complains.
Sorry I’m referring to WireGuard/ovpn server IPs, not the binaries/configs used to setup a client. Unless you’re talking about fronting for both, but I imagine it is not economical to run a commercial -scale privacy vpn via a cloud provider.
This makes me wonder: are there "cloud drive virtual sneakernet" systems that will communicate e.g. by a client uploading URL request(s) as documents via OneDrive/SharePoint/Google Drive/Baidu etc., a server reacting to this via webhook and uploading (say) a PDF version of the rendered site, then allowing the client to download that PDF? You effectively use the CDN of that service as a (very slow) proxy.Of course, https://xkcd.com/538/ applies in full force, and I don't have any background in the space to make this a recommendation!
It doesn't apply imo as OP is probably not a high value target of the govt, he just wants to bypass his govt restrictions and I doubt the situation is so bad that the govt will send people physically to deal with people circumventing the block.Your solution could technically work over any kind of open connection / data transfer protocol that isn't blocked by the provider but it would be an absolute pain to browse the web that way and there are probably better solutions out there.
I also want to add here because a lot of people either mention Tor as a succesful solution, or mention why Tor is not a solution but state completely wrong reasons. And I have a good soapbox to stand once in a while.Number one reason why Tor is dead is Cloudflare.Let me digress here. In my opinion, Cloudflare does a lot more censoring than all state actors combined, because they singlehandedly decide if the IP you use is "trustworthy" or "not", and if they decided it is not, you're cut off from like half of the Internet, and the only thing you can do is to look for another one. I'd really like if their engineers understood what Orwellian mammoth have they created and resign, but for now they're only bragging without the realization. Or at least if any sane antitrust or comms agency shred their business in pieces.And Cloudflare by default makes browsing with Tor unusable. Either you're stuck with endless captchas, or you're banned outright.Number two reason why Tor is dead is all other antifraud protections combined. Try paying with Stripe through Tor. There is quite a big chance you'll get an "unknown error" of sorts on Stripe side. Try to watch Netflix in Tor - exit nodes are banned.Everyone kept shouting "Tor bad, Tor for criminals", and it became a self-fulfilling prophecy. It's really hard to do just browse web normally in Tor, because all "normal" sites consider it bad. The "wrong" sites, however, who expect Tor visitors...
it depends. I myself have some combination of browser extensions which make me a bad guy in Cloudflare opinion. I don't know exactly which one is the culprit because I added a lot of stuff over the years, but I really don't care: if Cloudflare blocks a website, I simply use another one. The good half of the internet will get my traffic.
I understand where you are coming from but there’s a flip side to this.Cloudflare obfuscating such a huge segment of origin servers gives a privacy advantage to anyone using a private DNS, since most of the IPs you can be seen connecting to are just…Cloudflare.
It's funny that the original idea for HTTPS was that there should be private communication between clients and service providers, and it somehow got turned on its head and now its just private communication between you and Cloudflare, and they can see all the traffic.We talk about end to end encryption all the time, but half the web is hosted by a single company with questionable ethics and everyone is like, we trust them! They write technical blog posts!Even Signal is hosted on Cloudflare...
As a long-standing supporter of Internet freedoms in Russia, I could advise you to use multiple tools at the same time, to avoid them being blocked.What would probably work UNLESS they roll out pretty sophisticated DPI that could block by signatures and do active probing:1. AmneziaVPN (https://amneziavpn.org) - they have the hosted option, or you could run your own on a cheap VPS (preferable). They use Xray/REALITY or a variant of Wireguard with extra padding that confuses DPIs. Should be good enough.2. Psiphon3. Lantern4. Sometimes Tailscale works surprisingly well (even in Russia where they have advanced DPI systems!)Here's a link to several Tor browser mirrors for you so you could download the VPN software itself:https://mirror.freedif.org/TorProject/https://mirrors.mit.edu/torproject/download/A couple of Tor bridges in case Tor is blocked:  webtunnel [2001:db8:9947:43ae:8228:97b7:7bd:2c2e]:443 6E6A3FCB09506A05CC8E0D05C7FEA1F5DA803412 url=https://nx2.nexusocean.link ver=0.0.1
  webtunnel [2001:db8:a436:6460:fa7b:318:4e8e:9de3]:443 F76C85011FD8C113AA00960BD9FC7F5B66F726A2 url=https://disobey.net/vM8i19mU4gvHOzRm33DaBNuM ver=0.0.2
I lived in China for a while and there were several waves of VPN blocks. Also very few VPN services even try to actively support VPN-blocking nations anymore. Any commercial offering will be blocked eventually.What I settled on for decent reliability and speeds was a free-tier EC2 hosted in an international region. I then setup a SOCKS5 server and connected my devices to it. You mentioned Cloudflare so whatever their VM service is might also work.It's very low profile as it's just your traffic and the state can't easily differentiate your host from the millions of others in that cloud region.LPT for surviving the unfree internet: GitHub won't be blocked and you'll find all the resources and downloads you need for this method and others posted by Chinese engineers.Edit: If you're worried about being too identifiable because of your static IP, well it's just a computer, you can use a VPN on there too if you want to!
The VM instance is good for setting up a VPN tunnel, but it's not good in terms of bandwidth if it's hosted in. Because of DPI capacity, China has a very limited amount of "real internet" bandwidth. A more capable setup is to have one VM on each side of the firewall on an hosting service with peering between inside and outside - Aliyun (Alibaba Cloud) is an example. The "inside" VM could be just "socat UDP4-RECVFROM:<port>,fork UDP4-SENDTO:<remote>:<port>" or something done using netfilter.Like others commented in this thread, having an obfuscator is a good idea to ensure the traffic is not dropped by DPI.When the inevitable ban comes and your VPN stops working, rotate the IP of the external VPN and update the firewall/socat config to reflect it. Usually, the internal VM's IP doesn't need to be updated.
When I worked in China (not for long periods but frequently enough that the Great Firewall became an irritant) I hosted an OpenVPN server on port 443 and/or port 22 of a server I owned. That worked sufficiently well most of the time.
This doesn't work anymore; the GFW no longer detects VPN connections by port but instead by performing deep packet inspection to characterize the type of traffic going over every connection. Using this technique in combination with some advanced ML systems, they're able to detect any encrypted VPN connection and cut it off; it's basically not possible to run any kind of outbound VPN connection (even to private servers) from inside of China anymore, and it's usually not even possible to _tunnel_ a VPN connection through some other protocol because the GFW now detects that too.Stepping back and looking at it from a purely technical perspective, it's actually insanely impressive.Here's a USENIX paper from a few years ago on how it is done: https://gfw.report/publications/usenixsecurity23/en/
So there's a disconnect between what you're saying and what others and myself have experienced in China even recently. You appear to be saying that it's not possible to use a VPN to bypass the GFW, but I apologise if I have misunderstood.The comments have multiple examples of people successfully bypassing the firewall. I personally just used Mullvad with wireguard + obfuscation (possibly also DAITA) and it just worked. No issues whatsoever.
This changes, not only over time, but also from region to region.A close friend of mine travels to China often, and they use Mullvad because of my recommendation. Last year it worked great for them, but earlier this year they went back to China, and it really didn't work.What I found most interesting is that they had different results in different places. Apparently, in the business areas of Shanghai and Beijing, were they had meetings and events, they could get Whatsapp and Slack messages; when they went back to the hotel, in a residential area where there were almost no offices or tourists, it didn't. In Chongqing even less stuff worked.I was very skeptical of this when they told me, but they could replicate this consistently over a couple of weeks. It wasn't related to hotel Wifi (that's a different can of worms), this was on mobile data.Everything worked when they switched to using https://letsvpn.world, at the recommendation of some chinese colleagues of them.This was with a basic Mullvad install on iOS and Mac, they're not technical enough to harden their VPN connection further; may be they could've easily obfuscated it more and it would've worked.
This is what IPsec TFS is for [https://datatracker.ietf.org/doc/rfc9347/]> the focus in this document is to enhance IP Traffic Flow Security (IP-TFS) by adding Traffic Flow Confidentiality (TFC) to encrypted IP-encapsulated traffic.  TFC is provided by obscuring the size and frequency of IP traffic using a fixed-size, constant-send-rate IPsec tunnel(If they block a constant rate stream, that'll hit a whole ton of audio/video streaming setups)
So they'll just block any constant rate stream that isn't containing AV data or a whilelisted streaming service.
I don’t think that’s possible. AV data is behind the TLS layer, all the DPI can see is a CBR stream that matches HTTPS signature. Unless it can do a MitM (Kyrgyzstan-style) they can’t really tell anything about the payload content save from what the TLS handshake may expose. Past it, observability stops at packet sizes and timings.As I understand it, modern DPIs try to fingerprint TLS traffic through feeding data that passed some pattern matching to ML models that try to predict how likely it’s between a genuine commonplace browser and a “normal” webserver (or a video streaming server or game server - whatever they trained it on). And in turn modern obfuscation software tries to match the behavior and be seen exactly as it’s your Chrome user watching some cat videos or something equally innocuous.
When I lived in China 10 years ago, GFW had a pretty effective way by slowing constant traffic that goes to an outside china ip address more and more over time. I had about 6 hours per ip (it starting to get slower and slower during that time) before having to rotate because even basic webpages didn't get through and ssh was unusable.
Assuming they don't MITM SSH, you should still be able to use something like wireguard over an SSH tunnel.  At least I would think.. it's all SSH traffic as far as any DPI listener is concerned, you'd of course need to ensure the connection signature through another vector though.
> it's basically not possible to run any kind of outbound VPN connection (even to private servers) from inside of China anymore.Really? Because the paper you linked says they don't block any TLS connections so you can just run a VPN over TLS:> TLS connections start with a TLS Client Hello message, and the first three bytes of this message cause the GFW to exempt the connection from blocking.
Worth noting is that OpenVPN’s TCP TLS mode does not work that way. It’s essentially the UDP protocol messages except wrapped into TCP. The initial handshake is not a normal TLS client hello.Not sure about other SSL VPNs.
Give it a try if you want; it doesn't work. For TLS traffic they track what the connection looks like over time; a TLS connection for normal web traffic versus a VPN connection tunneling through TLS apparently look different enough that they can detect and cut it off.
> it's basically not possible to run any kind of output VPN connection (even to private servers) from inside of China anymore.What if you run your own HTTPS server that look semi-legitimate and just encapsulate it in that traffic?Can they still detect it?What about a VPS in HK? Is this even doable?
v2ray and similar servers do exactly that, and I would assume they're still working as they're actively developed.
Which is ridiculous because OpenVPN is trivial to identify, even when over TCP since it's different from "regular" HTTPS/SSL traffic.Why they chose this I have no idea.You can even port share.443 -> Web server for HTTPS traffic
443 -> OpenVPN for OpenVPN trafficStill trivial to identify and not uncommon for even public WiFi to do so.Since I changed to tailscale+headscale with my own derp server all these issues have disappeared (for now).
It’s basically the same as the UDP mode, except wrapped into TCP. Presumably because that’s simpler than redesigning it from the ground up for TCP.So the handshake and such will not look like a normal TLS handshake.
GitHub was briefly blocked a couple of years ago in Indonesia. SSH was also blocked briefly by one of the largest mobile providers.
Isn't VPS's public IP blocks are well known and very easy to block? I read that this is not a viable solution in case of China's firewall.
I live in Indonesia, and I don't find any recent news that mention X (formerly Twittwr) and or Discord being blocked by the government. The only relevant news from a quick Google search I can find is about the government threatened to block X due to pornography content in 2024.
You can even check for yourself if a domain is blocked by visiting https://trustpositif.komdigi.go.id/.Also for your unability to access the VPN, as far as my experience goes, in the past some providers do block access to VPN. But, I am not experiencing that for at least the last 5 years.So, maybe you can try changing your internet provider and see if you can connect to VPN?
How can it be that one person living in Indonesia says everything is blocked and the country is in chaos and another, very calmly, is completely unaware and can't even find any news about it? This is so odd. What is the truth?
The context that was likely left out due to HN rules is, there are mass protests turned violent in the face of police brutality in several cities. The Indonesian government has a history of blocking/throttling internet access in immediate areas of the unrest to limit coverage.
Indonesia is a big country with over ten thousand islands and uneven coverage. What is blocked on one ISP might not be enforced on another (e.g. the state-owned ISP might block or use DNS poisoning on several "non-compliant" DNS providers but my current ISP doesn't). Also, in addition to what the sibling commenter (and another commenter regarding Cloudflare outage) said there might be a general overload on the mobile network near the affected areas since there are lots of users and limited bandwidth.
It's a 270 million people country with over 10K+ islands. Last year I visited Borobudur and was surprised that the Yogjakarta region is autonomous and they have their own king.
There was a reported outage of cloudflare in Jakarta, while simultaneously people can't access Twitter and Discord. The worst part is that it coincides with the time when people need the information to find a safe route to go home after the protest.
Australia and UK might soon go down this path.Something quite depressing is if we (HN crowd) find workarounds, most regular folks won't have the budget/expertise to do so, so citizen journalism will have been successfully muted by government / big media.
When ES leaked his info to the Guardian people, they could still (2013) use the Guardian's US base to publish, protected by the US' stronger freedom of speech laws. Now, in 2025, if the same were to happen again, I'm not sure that would work quite the same way, with Trump aggressively taking American citizens' rights away.Maybe The Guardian should open a branch in Sealand...
It was David Graeber that said we should be wary of places like The Guardian. They are a wolf in sheeps clothing. Used a lot of the more liberal momentum of the early 2010s combined with promoting some of the more left leaning writters to gain a fair bit of clout. But underneath, they will conform to the power structures if it comes down to survival. Alas, they nay not be a Sealand edition although that would be neat.
No American citizens’ rights have been taken away or can be taken away by a President.We have whistleblowers and leakers from the administration itself on a literal weekly basis, our own Department of State actively funds Signal and Tor, our media has been heavily criticizing Trump and his allies for years. A couple organizations got hit with lawsuits for publishing misinformation or skirting campaign law, but that’s about it.They tried to make flag burning illegal - which is illegal in Mexico, most of South America, all of Asia, and most of Europe - and it was shot down almost immediately as even that comes under 1st amendment rights.Please don’t lump us into the same bucket as the UK. We may have a sharply divided electorate but we don’t have a failing state!
America's Founders saw civil rights as inherent in the Constitution's framework, rooted in natural law. They added the Bill of Rights as an explicit bulwark. That's why we have the 1st Amendment's free speech, and if that falls, the 2nd Amendment ensures we have guns.
How's that working for you at the moment?Sorry for the snide comment, but considering the last 6 - 8 months in the US, at least from what is being reported in the outside world, the 1st amendment doesn't seem to be providing much in the way of protection, and unless I'm missing something the general public doesn't seem to have the level of interest that would be required for your 2nd amendment to play out in any meaningful way.
It’s working fantastic. US media is great at generating hysteria (competitive market pressures in the war for attention), but the US is at essentially very little risk for speech suppression at the level of the UK right now.
UK too, and concerned. I agree that amendment 1 and 2 provisions effectively underpin individual freedom in the US due to founder perspicacity. My fear re US constitutional provision is on separation of powers, and transfer of power. Fortunately Pence held to the constitution. Nobody ever willingly takes their hands of the levers of power!
Don't worry. You'll call us conspiracy theories once you get used to the new goalposts and we warn you about the next thing.How about instead of being depressed you start being vocal and defiant?
You know what, I think I've become lethargic after all the backwards garbage going on in my country attacking my way of life on all fronts - from rampant crime to government censorship. 
Your comment just gave me a kick up the ass. I'm gonna try and get some local stuff going in opposition to this lunacy.
In oz personally and yes, I warned folks of this a few years back, especially in the 12 months or so. Every time I was met with a fair bit of push back.They would argue back on technical merits, I was talking political, a politics doesn't give a damn about the tech. We have slowly been going down this path for a while now.“The laws of mathematics are very commendable, but the only law that applies in Australia is the law of Australia,” - PM Malcolm Turnbull in 2017.
Don't worry, you shouldn't underestimate the capability of society.I grew up in a pretty deprived area of the UK, and we all knew "a guy" who could get you access to free cable, or shim your electric line to bypass the meter, or get you pirated CD's and VHS' and whatever.There will always be "that guy down the pub" selling raspberry pi's with some deranged outdated firmware that runs a proxy for everything in the house or whatever. To be honest with you, I might end up being that guy for a bunch of people once I'm laid off from tech like the rest. :)
Normally I would agree with you, but the ability to pull this kind of thing off hinges on there being enough shadows that the Eye doesn't look at for prolonged periods of time. And the overall trajectory of technological advance lately is such that those shadows are rapidly shrinking. First it was the street cameras (and UK is already one of the most enthusiastic adopters in the world). And now comes AI which can automatically sift through all the mined data, performing sentiment analysis etc. I feel that the time will come pretty soon when "a guy" will need to be so adept at concealing the tracks in order to avoid detection that most people wouldn't have access to one.
I wouldn’t worry about it.They can barely handle wolf-whistlers let alone pedophile rape gangs consisting of the lowest IQ dregs of our society.I know it’s only painfully stupid people who think the law is stupid, but dodgy Dave down the way tends to fly under the radar. Otherwise there wouldn’t be so many of them.
One of the problems with authoritarianism is that even though most dodgy Daves will be fine because the political apparatus doesn't have the time or energy to arrest everyone for everything, they retain the ability to arrest anyone for anything.The moment your dodgy Dave offends your local cadre, even for reasons entirely other than being dodgy, they'll throw the book at him. And because there is now unpredictability around who will be arrested and for what reason, it acts as a chilling effect for everyone who values some degree of stability in their lives. So the arc of dodgy Daves bends toward compliance.
The eye doesn't care as long as you're not politically efficient in opposing their narratives or power.Authoritarianism in the UK doesn't correlate with crime.  The economy does.The point of these things is not really to help citizens. "there's no money for that" like there's no money for healthcare or education (although there is for bombings in foreign countries). The point is protecting power from any threat that could mount against it.
I think both sides of this are fair. Power is interested in stability of itself, to keeps its back to the wall so that nobody can sneak up on it. But also political power has teamed up with corporate power/determination to create a far more nasty beast.Seeing companies like Palantir (and many lesser known ones) buddy up to everyone that wants it, its a clear statement on how they want to monitor and control the populace.Long term I don't think it can be done, but the pain mid term can be vast.
That absolutely sounds like a world I should be worried about, where our only choices are dodgy ones
Don't worry, you shouldn't underestimate the capability of society.You should be worried. Don't underestimate the capabilities of the government bureaucrats. That "guys down the pub" will quickly disappear once they start getting jail time for their activities.
I think you really overestimate the capability of the UK to enforce laws. Yes, they can write them and yes they can fine large corporations, that's basically it.They cannot enforce laws against such "petty" crimes, the reason society mostly functions in the UK is because most people don't try to break the law.Pretty sure the local punters would kick the cops out if they came for one of their own, especially if he got them their porn back.
> They cannot enforce laws against such "petty" crimesNo, they aren't interested in enforcing laws against petty crimes. The establishment literally don't give a toss if someone breaks into your house and nicks your telly.They are very interested in enforcing the kinds of infringements we're talking about here.
What do you mean? They already arrest thousands of people a year for posting (or even retweeting) things online in the UK.What makes you think, if the Gov was to implement some sophisticated DPI firewall that blocks a million different things, they won't come after the people who circumvent it? They already enforce petty crimes. I could report you for causing me anxiety and you would have a copper show up at your door.
It's not just about UK abilities to enforce laws, but also about other factors. The described activities are extremely unattractive as criminal: small market, small margin, the need for planning, preparation and qualification.There is no need for special efforts to enforce the law. Put a few people in jail - and everyone else will quickly find safer and more legal ways to spend their time. No one will do something like that unless they are confident of their impunity.
Yes, it's also dystopian to pin one's future on such hopes. People need to stick it to the government and demand their freedoms. Far too many things are being forced on us in the West that go against fundamental values that have been established for centuries.Somehow, things that could be unifying protests where the working class of every political stripe are able to overlook their differences and push back against government never seem to happen. It is always polarized so that it's only ever one side at a time, and the other side is against them. How does that work?
Reflex. People's opinion on a subject changes if you tell them which political group supports it, sometimes even if they get asked twice in a row. Tribal identity determines ideology more than the other way around for a lot of people.So as soon as Labour comes out for something, Cons are inclined to be against it and so on. The only way to have neutral protests is if no one visibly backs them and they don't become associated with a side, but then how do they get support and organization?
> People need to stick it to the government and demand their freedoms.It will only work if they admit that they supported this and all forms of totalitarianism during COVID.  You can't fall for that and then be surprised when the world keeps going down that obvious path.
In matters of public health, you cannot trust the public to do the right thing.The problem with covid is that we weren't totalitarian enough. Regulations you could drive a coach & horses through and no way to enforce is a sop.The first lock down needed to be a proper 'papers, please' affair. When we get a properly lethal pandemic, we're fucked. Hopefully Laurence Fox and Piers Corbyn will catch it quickly and expire in a painful and televised way, it's the only hope of people complying with actual quarantine measures.
This type of thinking is why we are heading in a direction of authoritarianism everywhere.And COVID was not "totalitarian enough"? Yet people were forbidden from leaving their homes for a time.It was really amazing what fear could do to a population, how it rallied mostly together.
People assess real risk all the time.  The fact that you had to punish people and make them do performative acts was hygiene theater.You're the kind of person that said that "measures didn't work because we didn't close hard enough, if we do 2 weeks of REAL lockdown...".  It's ridiculous. You have absolutely no perspective of how the world work and how things break, people need health, food, working pipes.You have an absolutely authoritarian mindset and an inability to asses risk. You also have deep contempt for your fellow human being who are "not deserving of democracy".Lastly, it's funny to hear you admit this pandemic wasn't lethal because people don't actually comply the way you want, which means that the actions were theater and unneeded.
I suppose that for this case, an underground black market of VPN providers might emerge - average individuals setting up VPN software on a cloud service provider, and then selling monthly access to people. Aside from the obvious danger of getting ripped off (someone might put you on a slow shared VPN with many other people, or shut down the server at any time), there is also the possibility of someone monitoring all your Internet activity.
I'd default assume black market VPNs will monitor internet activity since it's both easy and profitable
I am just waiting for red states in the US to try this too since their current laws requiring ID verification for porn sites aren’t effective.
> red statesWell you'd be surprised to find out that this stupid policy (and many more) have been brought forward by Labour (Left).
At this point, anyone who has been watching politics for a few decades understands that the left/right dichotomy is primarily one designed to keep the majority of people within a certain set of bounds. We see it revealed when politicians and ideologies that should be in opposition to one another still cooperate on the same strategies, like this one.The goal right now is to make online anonymity impossible. Adult content is the wedge issue being used to make defending it unpalatable for any elected official, but nobody actually has it as a goal to prevent teenagers from looking at porn - if they did, they would be using more direct and efficient strategies.  No, it's very clear that anonymous online commentary is hurting politicians and they are striking back against it.
It has been my impression that in UK, both parties are strongly authoritarian, with the sole difference being what kinds of speech and expression, precisely, they want to police.
Both the major Australian parties (Liberal and Labor) seem as spineless as each other.They're being pushed by media conglomerates News Corp and Nine Entertainment [0] to crush competition (social media apps). With the soon-to-be-introduced 'internet licence' (euphemism: 'age verification'), and it's working. If they ban VPN's, it will make social media apps even more burdensome to access and use.[0] News Corp and Nine Entertainment together own 90% of Australian print media, and are hugely influential in radio, digital and paid and free-to-air TV. They have a lot to gain by removing access to social media apps, where many (especially young) people get their information now days.
How long until they produce an  generative AI version of Burt Newton to do new episodes of 20 to 1 based on some social media slop?Yep, not a great time line here.
Yep, here in Australia the social media age restriction was pushed through by both sides. Two sides of the same coin.
Hopefully, as a reader, you can see through the 90% and only really trust the 10% who provide factual reporting.As with any source, always question what you are being offered: is this video clip full, what preceded it, what followed it? Who else confirms this person said this or experienced that?
> 90% of “citizen journalism” is (trash)You're right. But compared to what?I guess 99% of mainstream "journalism" is irrelevant and/or inaccurate, hence citizen journalism is a 10x improvement in accuracy and relevancy! Not 10% better, 900% better! This makes a huge difference to our society as a whole and in our daily lives!But this misses the most important point which is that the user should have the right to choose for themselves what they say and read. Making citizen journalism unduly burdensome deprives everyone of that choice.
Preach comrade!Those citizen journalists with their primary sources, disgusting.Thats nothing but propaganda.Remember it doesnt matter what the video shows, it only matters who showed it to you.
> Remember it doesnt matter what the video shows, it only matters who showed it to you.Both matter.
>Remember it doesnt matter what the video shows, it only matters who showed it to youIn an age of mass media (where there's a video for anything) or now one step further synthetic media knowing who makes something is much more important than the content, given that what's being shown can be created on demand. Propaganda in the modern world is taking something that actually happened, and then framing it as an authentic piece of information found "on the street", twisting its context."what's in the video" is now largely pointless, and anyone who isn't gullible will obviously always focus on where the promoter of any material wants to direct the audiences attention to, or what they want to deflect from.
Citizen journalism avoids the main weakness of a centralised system: it's incredible suspectible to capture. A prime example of this is the mass opposition around the world to Israel's genocide in Gaza.  Israel committed such genocides prior to the event of social media, such as the Nakba, but it was rarely reported on, due to media ownership being concentrated in the hands of a few pro-Zionist individuals.
- Tor. Pros: Reasonably user friendly and easy to get online, strong anonymity, free. Cons: a common target for censorship, not very fast, exit nodes are basically universally distrusted by websites.- Tailscale with Mullvad exit nodes. Pros: little setup but not more than installing and configuring a program, faster than Got, very versatile. Cons: deep packet inspection can probably identify your traffic is using Mullvad, costs some money.- Your own VPSs with Wireguard/Tailscale. Pros: max control, you control how fast you want it, you can share with people you care about (and are willing to support). Cons: the admin effort isn't huge but requires some skill, cost is flexible but probably 20-30$ per month minimum in hosting.
> - Tailscale with Mullvad exit nodesTailscale is completely unnecessary here, unless OP can't connect to Mullvad.net in the first place to sign up. But if the Indonesian government blocks Mullvad nodes, they'll be out of luck either way.> - Your own VPSs with Wireguard/TailscaleKeep in mind that from the POV of any websites you visit, you will be easily identifiable due to your static IP.My suggestion would be to rent a VPS outside Indonesia, set up Mullvad or Tor on the VPS and route all traffic through that VPS (and thereby through Mullvad/Tor). The fastest way to set up the latter across devices is probably to use the VPS as Tailscale exit node.
Tailscale + Mullvad does have a privacy advantage over either one by itself: the party that could potentially spy on the VPN traffic (Mullvad) doesn’t know whose traffic it is beyond that it’s a Tailscale customer. Any government who wanted to trace specific traffic back to OP would need to get the cooperation of both Mullvad and Tailscale, which is a lot less likely than even the quite unlikely event of getting Mullvad to cooperate.
True, but OP's threat model doesn't involve state actors outside Indonesia, so traffic analysis of the "last mile" between Mullvad node and whatever non-Indonesian service OP is trying to use (Twitter, Discord, …) is not really relevant here. (Assuming Indonesia doesn't have capabilities we don't know of.)What might be more interesting is the case where the Indonesian government forces Twitter/Discord to give up IP addresses (which I find hard to believe but it's certainly not impossible). But then they'd still have to overcome Mullvad. It's much more likely that if OP has an account on Twitter/Discord, it is already tied to their person in many ways, and this would probably be the main risk here.
You don't need multiple vps at all time and can start them dynamically using the vps provider api.I regularly spawn temporary vps for a few hours to use as socks proxy and view sporting event from my country of origin. There is no reason one couldn't write a script that can spin a VPS choosing a provider and country randomly from a list of supported providers.
Sure, but ten servers is a bit too much redundancy, no? Depending on how many people you want to share it with it might make sense though.
And using another VPN like NordVPN or ProtonVPN is probably in the same category as Mullvad, but worth being cautious. If it's free, you are the product. If you pay, you're still sending your traffic to a publicly (usually) known server of a VPN. That metadata alone in some jurisdictions can still put you in danger.Stay safe
This is good overview, I just wanted to add that a VPS IP is not a residential IP. You will encounter roadblocks when you try to access services if you appear to be coming from a VPS. Not that I had a better solution, just to clarify what you can expect.
Tor also has anti-censorship mechanisms (snowflakes, ...). Depending on how aggressive the blocking is, Tor might be the most effective solution.
Wireguard is not censorship-resistant, and most VPN-averse countries block cross-border Wireguard. Why reply a practical question in an area in which you have no experience?
Yes. Fixed packet headers, predictable packet sizes. I don't know what "a common port" means in relation to wg.
Yeah. Tailscale uses 41641, and you can generally use whatever. I don't think there's any consensus, or majority.
Because Indonesia is new to the game and might still be catching up. They’re probably playing whackamole with the most common public VPN providers and might not be doing deep packet inspection yet. I worked with someone getting traffic out of Hong Kong a year ago and there was a lot trial and error figuring out what was blocked and what was not. Wireguard was one that worked.
They recommend Tailscale in particular. Tailscale control plane and DERPs (which are functionally required on mobile) will be among the first to go.Outline (shadowsocks-based) and amnezia (obfuscated wg and xray) both offer few-click install on your own VPS, which is easier than setting up headscale or static wg infrastructure, and will last you longer.Also, you did not answer my "why" question. I'm not sure what question you were answering.
IMO most people should have a VPS even if you don't need it for tunneling. Living without having a place to just leave services/files is very hard and often "free" services will hold your data hostage to manipulate your behavior which is annoying on a good day.
Yeah they can be cheap, but I would definitely recommend having at least 3 for redundancy. If one get shut down or it's IP blacklisted you still hopefully have a backup line to create a replacement.
No, unless you pay month to month. If you wait till BF you can find some really good deals on sites like lowendspirit
> cost is flexible but probably 20-30$ per month minimum in hosting.$4/month VPS from DigitalOcean is more than enough to handle a few users as per my experience. I have a Wireguard setup like this for more than a year. Didn't notice any issues.
Also sing-box [1]. I don't use it for its primary use case of censorship circumvention, but rather for some highly complex routing configurations it supports.My use case consists of passing some apps on my Android through interface A (e.g. banking apps through my 5G modem), some apps through US residential proxy (for US banks that don't like me visiting from abroad), and all the rest through VPN. And no root required!It's wild that GFW triggered creation of this and nothing like it existed / exists.[1]: https://github.com/SagerNet/sing-box
im curious, isn't ALL of your traffic appearing to be to just one website the most obvious giveaway?
*ray clients typically allow configuration of routing. So you can send only blocked stuff through the tunnel; or, in reverse, send some known-working stuff (e. g. local domain) direct. Also works as adblock.
I'm currently traveling in Uzbekistan and am surprised that wireguard as a protocol is just blocked. I use wireguard with my own server, because usually governments just block well known VPN providers and a small individual server is fine.It's the first time I've encountered where the entire protocol is just blocked. Worth checking what is blocked and how before deciding which VPN provider to use.
I should have mentioned that our use case isn't avoiding government firewalls, it's transiting through broken network environments.
WireGuard by itself has a pretty noticeable network pattern and I don't think they make obfuscating it a goal.There are some solutions that mimic the traffic and, say, route it through 443/TCP.
Wow, kinda crazy to think about a government blocking a protocol that just simply lets two computers talk securely over a tunnel.
Well, think about it - almost every other interaction you can have with an individual in another country is mediated by government. Physical interaction? You need to get through a border and customs. Phone call? Going through their exchanges, could be blocked, easy to spy on with wiretaps. Letter mail? Many cases historically of all letters being opened before being forwarded along.We lived through the golden age of the Internet where anyone was allowed to open a raw socket connection to anyone else, anywhere. That age is fading, now, and time may come where even sending an email to someone in Russia or China will be fraught with difficulty. Certainly encryption will be blocked.We're going to need steganographic tech that uses AI-hallucinated content as a carrier, or something.
On the contrary, it shows that they know very well what they're doing. Their goal is censorship. If that disrupts connectivity for some niche but valid use cases, so be it. The vast majority of people have never used a WireGuard tunnel, so they are unimpacted. Some corporate use cases that even that government would approve of are disrupted, but they can either lie with that or have a whitelist. Most non-corporate use of this and other similar protocols is not something the government would allow.So, given their nefarious goal, they are doing a great job by blocking WireGuard (and similar protocols, presumably).
Is it the protocol that's blocked as a result of DPI, or just the default 51820 UDP port that's blocked? If the latter, just changing your Wireguard server's port might work.
> surprised that wireguard as a protocol is just blocked.Honestly this is the route I'm sure the UK will decide upon in the not too distant future.The job of us hackers is going to become even more important...
A year ago I was traveling through Uzbekistan while also partly working remotely. IKEv2 VPN was blocked but thankfully I was able to switch to SSL VPN which worked fine. I didn't expect that, everything else (people, culture) in the country seemed quite open.
Cloak + wireguard should work fine on the server side. The problem is that I didn't find any clients for Android and I doubt there are clients for iOs that can (a) open a cloak tunnel and then (b) allow wireguard to connect to localhost...
XRay protocol based VPN worked for me in Uzbekistan when I were travelling there.Wireguard is indeed blocked.
how can they detect it is wireguard, I thought the traffic is encrypted?how does it differ from regular TLS 1.3 traffic?
It's UDP, not TCP (like TLS) and has a distinguishable handshake. Wireguard is not designed as a censorship prevention tool, it's purely a networking solution.The tunnel itself is encrypted, but the tunnel creation and existence is not obfuscated.
There are many instances of Mastodon, and due to its federated nature, you can use any of them to access it, and even host your own.
Sure, but if you have an account on a different server, you can still see things posted on mastodon.social if you have followed someone there.
It would be easy to block on protocol level. Countries that block VPNs usually progress to that level pretty fast once they discover that simple IP blocks don't work.
I doubt that is the case once you do statistical analysis of it.Advanced VPN tunneling protocols, for example, have to take a lot of special measures to conceal their nature from China's and Russia's deep packet inspecting firewalls.
Years ago, I created a very basic HTTP proxy using Google Cloud. The idea relies on Google Cloud wouldn't be blocked because the industry in that country probably also needs Google Cloud to function, so the government couldn't touch it.You can see it here: https://github.com/paddlesteamer/gcrproxy. I don't know whether it works or not (maybe something has changed; it is very old code), but the idea beneath it remains. And I think it is also applicable to other cloud services, too. Cheaper (even free to some point) than having your own VPS.
IMO, the safest route for an individual with tech competency is to setup a small instance server in the cloud outside your country and use ssh port forwarding and a proxy to get at information you want.For an example of a proxy service https://www.digitalocean.com/community/tutorials/how-to-set-...That will give you a hard to snoop proxy service that should completely circumvent a government blockaid (they likely aren't going to be watching or blocking ssh traffic).
That's a pretty strict censorship that basically locks your digital infrastructure into your country.
Well, mimicking China's GFW is seemingly the objective of some governments. But they are also able to allow some light (text-based) ssh usage and still prevent proxying.
Nations severing peoples connections to the world is awful. I'm so sorry for the chaos in general, and the state doing awful things both.Go on https://lowendbox.com and get a cheap cheap cheap VPS. Use ssh SOCKS proxy in your browser to send web traffic through it.Very unfancy, a 30+ year old solution, but uses such primitive internet basics that it will almost certainly never fail. Builtin to everything but Windows (which afaik doesn't have an ssh client built-in).Tailscale is also super fantastic.
>  uses such primitive internet basics that it will almost certainly never fail.It already fails in China and Russia. Simply tunneling HTTP through SSH is too easy to detect with DPI.> Windows (which afaik doesn't have an ssh client built-in)It has had both SSH client and SSH server built-in since Win10.
Looks like MacOS and iOS only, which is unfortunate. Support for at least Windows and Android is needed for wider adoption. Linux would also be nice.
Very possible, though many of our users are saying that in network environments where WireGuard is blocked they were able to use Obscura.
Hey, I went to take a look at Obscura and I like the ideas but I can't find the source code.You are making some bold claims but without the source I can't verify those claims.Any plans to open-source it?
Looks good, just one note: btc was never meant for anonymity, if you would add Monero as a payment option that would be great.
State censorship circumvention is exactly what Psiphon is for! So yes, try it.(Disclaimer: I work there.)
Tunneling via SSH (ssh -D) is super easy to detect. The government doesn't need any sophisticated analysis to tell SSH connections for tunneling from SSH connections where a human is typing into a terminal.Countries like China have blocked SSH-based tunneling for years.It can also block sessions based on packet sizes: a typical web browsing session involves a short HTTP request and a long HTTP response, during which the receiving end sends TCP ACKs; but if the traffic traffic mimics the above except these "ACKs" are a few dozen bytes larger than a real ACK, it knows you are tunneling over a different protocol. This is how it detects the vast majority of VPNs.
You could just run links or some text-based browser on the other side.Perhaps you could also write a script that would mimic typing over the link.
One alternative would be to set up a VPS, run VNC on it, run your browser on that to access the various web sites, and connect over an SSH tunnel to the VNC instance. Then it actually is an interactive ssh session.
15 years ago, I was using EC2 at work, and realized it was surprisingly easy to SSH into it in a way where all my traffic went through EC2. I could watch local Netflix when traveling. It was a de facto VPN.Details are not at the top of my mind these years later, but you can probably rig something up yourself that looks like regular web dev shit and not a known commercial VPN. I think there was a preference in Firefox or something.
The issue these days is that all of the EC2 IP ranges are well known, and are usually not very high-reputation IPs, so a lot of services will block them, or at least aggressively require CAPTCHAs to prevent botting.Source: used to work for a shady SEO company that searched Google 6,000,000 times a day on a huge farm of IPs from every provider we could find
I watched a season of Doctor Who that way back when the BBC were being precious about it. But Digital Ocean, so $5.
Hey there – greetings from one of the most heavily censored regions in the world.I once considered using an Indonesian VPS to bypass my country's censorship. However, the Indonesian VPS provider actually refused my direct connection request from my country. I was quite frustrated at the time, wondering why they refused me. But now I understand – it turns out these two countries are in cahoots.Emmm, if you want to break through the censorship, you can start here: https://github.com/free-nodes/v2rayfreeIt provides many free proxy nodes that are almost unusable in my country, but might work in Indonesia (although you may need a lot of patience to test which ones actually work).A good proxy software is Clash.Meta for Linux (you’ll need to install Linux on Windows using VMware, then set up Clash.Meta).You can start by installing the Windows version of the proxy client software (V2rayN) for a simple way to bypass censorship, but it's not a long-term solution.A special reminder: these free nodes are not secure (they could very well be "honeypot" lines, but if you're not from my country, the police should have no way of dealing with you). You need to quickly set up your own route by purchasing a U.S. VPS and setting up your own proxy nodes.Lastly, I recommend a good teacher: ChatGPT. It will solve all the problems you encounter on Linux. Also, use the Chrome browser with translation.Good luck!
The most effective solution is to use X-ray/V2ray with VLESS, or VMESS, or Trojan as a protocol.Another obfuscated solution is AmneziaIf you are not ready to set up your own VPN server and need any kind of connection right now, try Psiphon, but it's a proprietary centralized service and it's not the best solution.
WireGuard should still work. Tons of different providers. I trust Mullvad but ProtonVPN has a free tier. If they start blocking WireGuard, check out v2ray and xray-core. If those get blocked... that means somehow they're restricting all HTTPS traffic going out of the country
What I'm worried most are that most people are not even aware of what is DNS and how to change it.I can't imagine those who are caught in the chaos with only their phone and unable to access information that could help them to be safe.
Generally speaking, the general population that wants to use blocked services will develop enough technical know-how to circumvent it. The biggest risk is that there are bad actors giving malicious advice and to such learners, looking to defraud or otherwise exploit them.
Furthermore, you can always run another VPN on top of that if you don’t trust the outer one with the actual plaintext traffic.
VPN services are just someone else's computers. Any cloud provider with a low performance virtual machine can become a VPN gateway using Linux distribution of your choice for around $4.OpenVPN or WireGuard are my tools of choice. Professionally, I also use OpenVPN's EasyRSA PKI framework for certificates, but you can just generate your keys using any tutorial out there. "OpenVPN Cookbook" ebook from Packt is my go to source. For performance reasons, WireGuard is better.
In this scenario, Chinese have very rich experience.
you need to use the advance proxy tool like clash ,v2ray, shadowsocks etc.
shadowsocks was the winner of the state of the art I had to do at work. It address the "long-term statistical analysis will often reveal a VPN connection regardless of obfuscation and masking (and this approach can be cheaper to support than DPI by a stat)" comment.
Someone should create a vpn protocol that pretends to be a  command and control server exfiltrating US corporate secrets from hacked servers. The traffic pattern should be similar, and god forbid Xi blocks the real exfiltrations
I would rent a server in an outside jurisdiction and use it as proxy. It isn't too hard to setup and you can share it with others too. I believe it would be completely legal as well. As least it should be.That said, you are much less anonymous with that. But you could opt for your server using an additional VPN service to mitigate that.
I work often in China. I somehow haven’t had my WireGuard VPN back to my own home server blocked, yet. It’s pointed to a domain that also hosts some HTTPS web services so that might help.Prior to this, pre-Covid I used to use shadowsocks hosted on a DO droplet. Shadowsocks with obfs, or a newer equivalent (v2ray w/ vmess or vless protocol) and obfs (reality seems to be the current hotness) will probably work within Indonesia given their blocking will be way less sophisticated than China. The difference here is that it’s a proxy, not a VPN, but it makes it a lot easier to obfuscate its true nature than a VPN which stands out because obfuscation isn’t in its design.Hosting on big public VPSs can be double edged. On one hand, blocking DO or AWS is huge collateral. On the other, it’s an obvious VPN endpoint and can help identify the type of traffic as something to block.If you have access to reddit, r/dumbclub (believe it or not) has some relatively current info but it’s pretty poor signal to noise. Scratch around there for some leads though.Note that this stuff is all brittle as hell to set up and I usually have a nightmarish time duct-taping it all together. That’s why I’m overjoyed my WireGuard tunnel has worked whenever I’ve visited for a year now.One other left-field option, depending on your cost appetite, is a roaming SIM. Roaming by design tunnels all data back to your own ISP before routing out so even in China roaming SIMs aren’t blocked. It’s a very handy backup if you need a clear link to ssh into a box to set up the above, for example.
An expensive but functional option is to enable roaming on a foreign eSIM. Getting an eSIM is relatively easy. Roaming mobile traffic is routed from the country in which the SIM is from, not the country that you're in, meaning that an eSIM from e.g. an American carrier will not be subject to the censorship in your country.I've used this on multiple trips to China over the past decade (including a trip last year). You can find carriers that will charge very low (or even no) roaming rates.
Data-only eSIMs (e.g. ones you get from Airalo and apps like that) are not going to cut it though. You need a "full" eSIM that gives you a real number and even then, it's not a guarantee that your traffic will be routed via the country eSIM is from. Tello does route (or rather, exit) via US for example, but it's 2¢/MB.Chinese forums / blogs have a lot of information about this stuff. I usually ask ChatGPT to translate "Research topic re: some form of circumvention and give me forum posts and blog posts about it" to Chinese, then paste that into DeepSeek with search enabled and just let Chrome translate the responses. Does a really good job. At least better than what I can manage with Baidu.
I don't know if these work or not for the specific case mentioned here, but the cheapest eSIMs by a huge margin are from https://silent.link/ if anyone is interested. They definitely do work under normal internet circumstances.
Wireguard or OpenVPN might work, if someone has a server set up, set up your client to connect.If those don't work you can try something like wssocks (https://github.com/genshen/wssocks) or wstunnel (https://github.com/erebe/wstunnel). It tunnels connections through WebSockets, so you can make the connection look like a regular HTTPS connection. Another option would just be a regular-old HTTPS proxy (Nginx, Apache2, etc). Set up an HTTPS proxy somewhere on the internet, connect through it, but configure it to return a regular web page if someone tries to make a non-proxy connection through it. Another tool that may help setting up is chisel (https://github.com/jpillora/chisel). Those HTTPS ones may work if, when authorities connect to the host, it returns pages that look like some kind of private video server. (Maybe run an actual video server, in addition to the proxy...) Also, try to enforce TLS 1.3 for the HTTPS server.And another option, if all else fails, is to run a straight-up SOCKS proxy over the internet, on a weird port. It might be so obvious they aren't looking for it.To mask your DNS requests with the SOCKS proxy, use something like Tor-DNS (https://github.com/bfix/Tor-DNS), or set up a VPN through the SOCKS proxy and use DNS through that route. Another option is DNS-over-HTTPS.
there is a major protest currently happening due to the legislative body representative just giving themselves a monthly domicile stipend of ~$3300 on top of their salaries (yes, multiple), while the average people earned ~$330 monthly. the information about the protest are not broadcasted on local TVs, so the only spread of information is through social media. i guess since a lot of people went around it using VPN, the gov decided to block it too.
“Some demonstrators on Monday were seen on television footage carrying a flag from the Japanese manga series One Piece, which has become a symbol of protest against government policies in the country.”
The official word is to counter gambling. Lately the government is not really popular after some decisions that could be interpreted as authoritative, and as citizens have spoken out about it online, causing more voices to join and protests erupting..So well, my guess is they're trying to control it.
I’m in Indonesia at the moment for vacation.Just checked with NordVPN connected to their server Indonesia #54 (Borneo) and I was able to access twitter.com (via Chrome) and Discord (via app).I’m on iPhone.
I'd recommend using Outline - it's a one click setup that lets you provision your own VPN on a cloud provider (or your own hardware).Since you get to pick where the hardware is located and it is just you (or you and a small group of friends & family) using the VPN, blocking is more difficult.If you don't want the hassle of using your own hardware you can rent a Digital Ocean droplet for <$5 per month.https://getoutline.org/
I’ve set this up for friends in fairly heavily censored countries before, it has been working well so far, but as others have said, this is a cat and mouse game
What is going on if you don’t mind my asking? Our local news does not mention anything. Nor does ddging help? Any sources?
> the housing allowance for a month for a parliamentarian is now ten times the minimum wage for a month.I'm almost positive that everyone in the US Congress is making at least ten times the minimum wage in this country. The "housing allowance" being referred to is separate from their normal salary in Indonesia, but still, interesting to imagine how much more seriously people there would take that disparity than in many other countries.This caught my attention more:> Indonesia passed a law in March allowing for the military to assume more civilian posts, while this month the government announced 100 new military battalions that will be trained in agriculture and animal husbandry. In July the government said the military would also start manufacturing pharmaceuticals.They're replacing civilian industry with military, apparently not out of any emergency requirement but just to benefit the military with jobs (and the government with control over those sectors) at the expense of civilian jobs.
The ratio between Indonesian parliamentary income and the median Indonesian income is ~18x, while the ratio in the US is ~4x. As someone who wants US congressional income to be substantially higher, it's hard for me to be upset at that on its own. There are plenty of other variables at play, though, and a direct comparison of these ones might not be getting at the issue.
The thing about fighting against vpn blocks is that if you win, the govt can just turn off the internet. Something like starlink would be ideal in these circumstances, but you'd have to have the receivers in the country before lockdown.
Thereby entrusting your internet connectivity to the whims of an unhinged lunatic.
Assuming something like Starlink doesn't cooperate with shutting down in the country just like the land-based ISPs would.
A one way plane ticket, a rifle, or a drone swarm. (What I’d use if my country blocked VPNs)
Chinese have developed a significant amount of sophisticated tools countering internet censorship. V2ray as far as I recall is the state-of-the-art.To use them, one need to first rent a (virtual) server somewhere from a foreign cloud provider as long as the payment does not pose a problem. The first step sometimes proves difficult for people in China, but hopefully Indonesia is not at that stage yet. What follows is relatively easy as there are many tutorials for the deployment like: https://guide.v2fly.org/en_US/
I’m not sure this is the right conversation right now, but is this thread heading towards “how do we make totalitarian governments become liberal democracies?”It’s a nice technical question on how to run a VPN but the ultimate goal is not the best technical solution but the ability to avoid detection by the state. And that’s not a technical problem but an opsec oneIf someone is participating in online discussions (discord and twitter) to spread local news - then it’s hard to know who is who, and who to trust - and that’s kind of the why Arab spring did not spring “hey wear a red carnation and meet me by the corner” can become a death sentenceThe answer to opsec is avoid all digital comms - but at this point you are seriously into “regieme change”, or just as Eastern Europe did, keep your heads down for forty years and hope those who leave you economically behind will half bankrupt them selves bringing you back.I think in the end, a thriving middle class with a sufficient amount of land reform, wealth taxes which can over a generation push for liberalisation sounds a good idea.Our job in the very lucky liberal
West is to keep what our forefathers won, and then push it further to show why our values are worth the sacrifice in copying
> Our job in the very lucky liberal West is to keep what our forefathers won, and then push it further to show why our values are worth the sacrifice in copyingWould it be possible for you to 'keep what our forefathers won', and then just stay at home?
> Our job in the very lucky liberal West is to keep what our forefathers won, and then push it further to show why our values are worth the sacrifice in copyingIt was the liberal West who helped China build the Great Firewall – Cisco, Sun Microsystems, Nortel, Siemens and others.As long as a lucrative commercial opportunity was there, they seized upon it shoving the liberal values up the orifice where the sun does not shine.
Working from China, i've rented VPS outside of the country and set up tailscale exit nodes - as my private VPN. Speed is not always optimal but it mostly works.
As someone based in China, it's a bit surprising that techniques used by Chinese people get very few mentions here, while I do think they are quite effective against access blocking, especially after coevolving with GFW for the past decade. While I do hope blocking in Indonesia won't get to GFW level, I will leave this here in case it helps.I found this article [0] summarizing the history of censorship and anti-censorship measures in China, and I think it might be of help to you if the national censorship ever gets worse. As is shown in the article, access blocking in China can be categorized into several kinds: (sorted by severity)1. DNS poisoning by intercepting DNS traffic. This can be easily mitigated by using a DOT/DOH DNS resolver.2. Keyword-based HTTP traffic resetting. You are safe as long as you use HTTPS.3. IP blocking/unencrypted SNI header checking. This will require the use of a VPN/proxy.4. VPN blocking by recognizing traffic signatures. (VPNs with identifiable signatures include OpenVPN and WireGuard (and Tor and SSH forwards if you count those as VPNs), or basically any VPN that was designed without obfuscation in mind.) This really levels up the blocking: if the government don't block VPN access, then maybe any VPN provider will do; but if they do, you will have a harder time finding providers and configuring things.5. Many other ways to detect and block obfuscated proxy traffic. It is the worse (that I'm aware of), but it will also cost the government a lot to pull off, so you probably don't need to worry about this. But if you do, maybe check out V2Ray, XRay, Trojan, Hysteria, NaiveProxy and many other obfuscated proxies.But anyways, bypassing techniques always coevolve with the blocking measures. And many suggestions here by non-Indonesian (including mine!) might not be of help. My personal suggestion is to find a local tech community and see what techniques they are using, which could suit you better.[0] https://danglingpointer.fun/posts/GFWHistory
Thanks for the link!Is there any good DoT/DoH DNS resolver that works well in China? I know I can build one myself, but forwarding all DNS requests to my home server in NA slows down all connections...
nextdns recently created geo spoofing methods, I may be wrong, I usually am but I am curious as to if these censorship can be fixed by nextdns.I don't know if indonesia is becoming exactly like china/ so a complete crackdown as people are discussing things as if its for china, but I feel like that there are definitely some easier things than hosting your own server or using shadowsocks.Check if proton vpn/mullvad vpn are working once please, they are definitely plug n play and proton even offers a free tier.
Personally, I like Amnezia VPN, it has some ways to work around blocks: https://amnezia.org/en
You can very easily self-host it, their installer automatically works on major cloud platforms.Though if Indonesia has blocked VPNs only now, possibly they only block major providers and don't try to detect the VPN protocol itself, which would make self-hosting any VPN possible.
Starlink, by policy, connects you through a ground station in the same country. They wouldn't be allowed to operate otherwise.
Starlink is a legitimate business (ISP) that wants to make money from customers in that country. They will comply with all of the regulations and bans imposed by the government in that country or risk getting banned completely.
It's not about blocking the sky. Starlink sends the internet connection back down to the ground somewhere in the country you are in.That being said, if I have an American starlink account, and I go to Indonesia, what happens? Does my internet connection go back down through Indonesia or does it go through somewhere else?
Mullvad has some anti-censorship features (shadowsocks) that it will automatically use if regular connections fail and works reliably in China as well (and has for the last 2+ years). You could give it a shot.
Get a cheap VPS for less than $10/mo or a dedicated server for like $25/mo and ssh tunnel into it. You can also use it to be your devserver, run your blog, etc. I've been using french located OVH servers in France for many years, it just works.
This might not be the case for Indonesia currently, but for countries like Russia, China, Iran most of the mentioned solutions will not work. I've had to evade Russian censorship for years now - the censors (Roskomnadzor) use DPI and other means of classifying network traffic, and currently the following things are outright blocked:- Tor- Wireguard and derivatives (incl. Mullvad, Tailscale, ProtonVPN)- OpenVPN- Shadowsocks (incl. Outline)What still works is Xray-core [1] with vless and Reality protocols, whatever those mean. Xray-core is an innovation over v2ray [2]. v2ray might also still work, but I've never tried it. If you have the capacity to run your own VPS, the simplest solution would be to install the 3x-ui [3], which is something like "Xray-core with a simple to use UI in a single package ready-to-use", but you'd also need to setup some basic security measures and a firewall.For those technically inclined, here [4] is a rough ansible playbook to install 3x-ui on a blank Debian machine. Additional configuration will be needed in the UI itself, there is a lot of online tutorials, and I link to one of them in [5] (in Russian, unfortunately). Don't just trust me blindly, please review before running!There are also commercial xray-aware VPN providers, but I wouldn't publicly vouch for any of them.I found it very strange that there is not much info on HN about xray and v2ray, and I also hope it stays this way for most of the people here and not here. However, we live in a weird reality and have to actively engage in such an arms race now.As a side note, if anyone here has quality info about security of the xray-core implementation, I'd be happy to get familiar. I didn't look at the code myself and still am slightly suspicious, but oh well it works :shrug:[1]: https://github.com/XTLS/Xray-core[2]: https://github.com/v2fly/v2ray-core[3]: https://github.com/MHSanaei/3x-ui/[4]: https://pastebin.com/DjFQ8c6Z[5]: https://habr.com/ru/articles/731608/
You should use people power to work to make Indonesia a more open, democratic society.Yes, it's hard work. Yes, it will take a long time. Yes, you personally may not get very far with your efforts.But if Indonesians don't take responsibility for and work to improve Indonesia then the rest of it doesn't matter.
Part of that is knowing whats happening inside the country, of which they were previously using tools like discord, which have now been blocked. So the first step to using people power to make Indonesia a more open, democratic society would be to find a way to tunnel out to get and share that information. To that end the OP has created this Ask HN thread.
Nope. The outside doesn't matter. The problem is on the inside. External websites will never fix the internal problem.There are no technical solutions to what is fundamentally a problem of political culture.
>External websites will never fix the internal problem.Except the internal problem is censoring internal information sources. They can only trust external sites to remain neutral.Not to mention that, politically and historically speaking, there are so many examples of revolutionaries needing to go overseas to organize. The Bolshies literally got started in a London pub.
Nope. They can simply talk to each other. I talk to people inside Indonesia routinely. I do it via SMS, via the phone, via iMessage, via Microsoft Teams. It's not difficult.You're not understanding the circumstances on a practical level. All you're doing is running away from the work to solve the fundamental political problem and that avoidance won't solve anything.
>All you're doing is running away from the workI feel like you have some weird moral hangup with needing/using non local resources that wont be resolved with any application of logic or reference to facts. Its nice that you have formed some weird worldview but its not really reality and it doesnt fit into it, so no need to make it anyone elses problem really.Edit: Also last time I checked iMessage and Teams are also hosted outside of indonesia.
I'm saying slacktivism won't get you anywhere. There is no technical solution to cultivating a better political culture.
How do you propose they coordinate the political activities when they can't use external communications sites/tools, and internal sites are actively monitored by an authoritarian government?Step 1 is establishing a secure means of communication.
Hello! I use Octohide VPN - it has VLESS protocol that can bypass geo-blocks (in countries like Russia, China). Its fast, the connection to a server takes merely a second and I do not even have an account as there is no registration required. Try it and see whether it helps you.
Hi, not well educated on the details of VPNs and network security so this may be a basic question, but - VPNs are used regularly by corporates to enable secure intranet access to people offsite, etc - surely completely blocking VPNs or detecting and punishing VPN users is severely detrimental to business and not something countries would want to do carte blanche? How does this work?
Do you still have access to GitHub?If so you can run BrowserBox in a GitHub action runner exposed via IP or ngrok tunnel. That will give you a browser in a free region. Easy set up via workflow.You’ll need a ngrok API key and a BrowserBox key. Hit us up: sales@dosaygo.com for a short term key at a discount if it works for you.We will offer keys for free to any journalists in censored regions.
Aren't there local (online or print) newspapers to get news from, as an alternative to Discord? Hope I'm not asking a dumb question
In countries where it comes to government blocking/censoring internet traffic, traditional media is cleared of all dissent and fully controlled long before. Last stages of that are happening in my country, Serbia, currently.
Right, that makes sense. Did some looking up and nonfree press seems to be indeed the case for Indonesia: https://rsf.org/en/country/indonesiaIt's a mixed bag apparently, free press is technically legal since 1998 but selective prosecution and harassment of those actually uncovering issues (mainly becomes clear in the last section, "Safety")Tried looking up Serbia next on that website but got a cloudflare block. I'm a robot now...
It's not a dumb question at all. Level on hn really got down lately if you're getting downvoted.Think about it Aachen. If the government has enough power to censor internet traffic, that what was the first thing it censored? Which media is traditionally known for being censored or just speaking propaganda? That's the classical newspapers. It's not uncommon in authoritarian countries for editors to need state to sign off on the day's paper. And if not that, articles are signed and publishers are known. They will auto-censor to avoid problems. Just like creators on YouTube don't comment on this one country's treatment of civilians to avoid problems.
I live in Pakistan and two years back we had this exact same problem, (election interference) and frankly, you just try to scrape through solutions, but without an answerable government, there is little you can do.We tried things like Proton VPN and Windscribe VPN, as well as enabling MT proxy on Telegram, but soon govts find it easier to just mass ban internet access.Use Netblocks.org to analyse the level of internet blockage and try to react accordingly.
AmneziaWG is a decent option for censorship resistance, and it can be installed as a container on your own server.
Use a less-known DoH or DoT provider.They just "blocked" Reddit today, I selected another DoH provider from the menu in my browser settings, and continued.
May I suggest getting a cheap VPS in another country and using SSH to tunnel traffic, or even setup a window manager on the VPS.
A question related to the question, for which I apologize:It seems to me that using WireGuard (UDP) in conjunction with something like Raptor Forward Error Correction would be somewhat difficult to block. A client could send to and receive from a wide array of endpoints without ever establishing a session and communicate privately and reliably, is that correct?
It is not a real URI... lolThe point was to include something clowns can't filter without incurring collateral costs, and wrapping the ssh protocol in standard web traffic. =3
About VPNs I don't know but you could all start using Nostr instead of Twitter and Discord.Also Telegram using MTProto proxies (that you have to host, do not use those free ones out there), if those don't qualify as VPNs.
Get a Digitalocean droplet, and host your own Outline instance. Their manager app makes this a 1-click process.
I was wondering something like this but in a different capacity.What with certain countries (they know who they are) and their hatred for encryption, it got me wondering how people would communicate securely if - for example - Signal/WhatsApp/etc. pulled out and the country wound up disconnecting the submarine cables to "keep $MORAL_PANIC_OF_THE_DAY safe."How would people communicate securely and privately in a domestic situation like that?
In person or not at all.At that point you've essentially lost.You either hope another country sees value in spreading you some democracy, or you rise up and hope others join you.Or not and you accept the protection the state is graciously providing to you.
Your first option until you get settled is to use an SSH reverse proxy:    ssh -D 9999 user@my.server

Then configure your browser to use local port 9999 for your SOCKS5 proxy.This gets you a temporarily usable system and if you can tunnel this way successfully installing some WireGuard or OpenVPN stuff will likely work.EDIT: Thanks it's -D not -R
Use the Tor browser window in Brave. It's nowhere near as anonymous as the Tor browser, but the built in ad blocking makes browsing via Tor usable. And that's what you and your compatriots are interested in.Prepare to fill in Cloudflare captchas all day, but that's what it takes to have a bit of privacy nowadays.
Can you try both WireGuard and MASQUE? you can do that by using `warp-cli tunnel protocol set MASQUE'.  if you want to try WireGuard, `warp-cli tunnel protocol set WireGuard'
In this case the blockage will probably just be up for a few days, until the protests calmed down.Other than that: tor
Usually when countries block websites they don't block major cloud providers, like AWS and Google Cloud. Because most websites are hosted on them. So you can get a cheap VPS from AWS or GCP (always free VM is available) and host OpenVPN on it.
Try some of the more niche VPN protocols like IKEv2/IPSec or zinc.SSH over socks is another option or you can run your own proxy server, nobody will ever know... This makes me wonder if you cannot just run OpenVPN on a different port like 443 since it's also TLS based.
you can use anything that has a VM.let's say Github codespaces. Launch a new codespace, setup vpn or just squid. Use it.It will not stop working unless your gov. decides to block said service (GitHub) too.
Android doesn't come with system wide socks proxy support, and i couldn't find an open source app for it either. Is anyone aware of one?Nonetheless this is a surprisingly simple and bullet proof solution: SSH, that's not vpn boss, i need it for work.
Outline is an open source shadowsocks client, and you provision your own server to act as the proxy.  You can use it against any Shadowsocks server you want, and the protocol makes it look like regular https traffic.https://github.com/Jigsaw-Code/outline-appsAndroid & iOS & Linux & Mac & Windowstheir server installer will help set up a proxy for users that aren't familiar with shadowsocks, too
Set up a VM on AWS/azure/gcp/... in the desired cell, install a VPN server and done. Once you have automation in place it takes ~2 minutes to start, you can run it on demand so you can pay per minute.
All the various proxy solutions offered are good (although the simplest ones - like squid - haven't been mentioned yet). You can also use a remote desktop or even just ssh -Y me@remote-server "firefox"
The site is awful, and I couldn't find the technical description easily. I assume it runs an exit node for other people's traffic?
Try looking into tor bridges.You could also buy a VPS and use SSH tunneling to access a tor daemon running on a VPS. Host some sort of web service on the VPS so it looks inconspicuous
I like mullvad. You can buy a prepaid card off amazon. I figured out how to setup wireguard on various unixes Mac/linux/openbsd
Censorship circumvention tools specialize in this, and are extensively used in China, Iran, and Russia. I work on Lantern, and we're not seeing any significant interruptions to connections in Indonesia at the moment.
https://lantern.io/downloadHope it helps!
I'd recommend Obscura because it uses Wireguard over QUIC and it pretty good at avoiding these blocks. It's also open source.
Launch an EC2 instance in the US region (Ubuntu, open ports 22 and 1194), then connect via SSH and run the OpenVPN install script. Generate the .ovpn profile with the script and download it to your local machine. Finally, import the file into the OpenVPN client and connect to route traffic through the US server.
Make your own VPN using a VPS and something like openvpn.Not every website will allow it, but it should get you access to more than you have now.
A proxy service like shadow socks works. There are thousands of providers for $X/month for a decent amount of traffic
Depending on the circumstances, maybe ditch the landline local ISP for a satellite connection with a foreign ISP?
Yes, it's superseded by V* stuff and derivatives (VLess...), and probably by Trojan, but the latter is less popular.
Try a ssh socks5 proxy to a cheap vps.It worked well for me in UAE when other solutions didn’t
As an aside about professional and engineering ethics:If you’ve ever worked in the DPI space and actively participated in the development or installation of state surveillance and censorship products…Shame.Shame.Shame.
The best time to develop meshnets was 15 years ago. The second best time is now. What is actually holding us back here? Almost everyone has powerful radio equipment these days.
OP, you can rent a VPS from a reputable and cheap provider within the NA region - OVH, Vultr, Linode etc. are decent. Also check out lowendtalk.comThen, setup Tailscale on the server. You can VPN into it and essentially browse the internet as someone from NA.
From some of the comments here I get why you are downvoted. But tbh I would also have gone that route. So are we just inexperienced? I read here indeed that wireguard is very easily blocked. It was at the company I worked for but then I just set port 23 (who uses ftp anyways??). And it worked. But why is this still bad then?Obviously I have 0 real experience with this.
Well, I mean, Tailscale is pretty easy overall. When client apps get blocked, you can literally hook up your router into Tailscale if needed, or you can run a headless version of Tailscale on your home server or the very machine you are on.It should also be possible to use a tunnel to get around the blocking of WireGuard, for example.You can then use it as an exit node if needed. It should work in theory, I have never tried this though. I just speak as a very frequent user of Tailscale with a bunch of nodes that are geographically located in different cities around me.
Sure, I know and use it too. But I saw you being downvoted so I responded to that. I think, reading the rest of the thread, your response (as mine would be) does not work as signals 0 experience with actually oppressing regimes. Not?
The closest I've come to this is on an airplane where almost everything was blocked. SSTP to a server I spun up worked well.
I can relate to this because my country has an election soon and I'm sure we wont have internet for 3 - 5 days then.
Tor should be pretty good even for environments where they crack down on VPNs, although it can be a bit slow, at least it works.
Yeah, sucks, but really should find better places for people to gather regardless, if you're in that sort of environment.
How is this practical advice in a thread where someone mentions that the clampdown happened without notice?The "shoulda done..." advice isn't useful in the slightest, and I'd argue is malicious with how often it's done simply to satiate a poster's ego.
Full disclosure, I run a commercial VPN service (Windscribe).There are 2 paths you can take here:1. Roll your own VPN server on a VPS at a less common cloud provider and use it. If you're tech savvy and know what you're doing, you can get this going in <1hr. Be mindful of the downsides of being the sole user of your custom VPN server you pay for: cloud providers log all TCP flows and traffic correlation is trivial. You do something "bad", your gov subpoenas the provider who hands over your personal info. If you used fake info, your TCP flows are still there, which means your ISP's IP is logged, and deanonymizing you after that is a piece of cake (no court order needed in many countries).2. Get a paid commercial VPN service that values your privacy, has a diverse network of endpoints and protocols. Do not use any random free VPN apps from the Play/App stores, as they're either Chinese honeypots (https://www.bitdefender.com/en-us/blog/hotforsecurity/china-...) or total scams (https://www.tomsguide.com/computing/vpns/this-shady-vpn-has-...).Do not go with a VPN service that is "mainstream" (advertised by a Youtuber) or one that has an affiliate program. Doing/having both of these things essentially requires a provider to resort so dishonest billing practices where your subscription renews at 2-5x of the original price. This is because VPNs that advertise or run affiliate programs don't make a profit on the initial purchase for that amazing deal thats 27 months with 4 months free or whatever the random numbers are, they pay all of this to an affiliate, sometimes more. Since commercial VPNs are not charities, they need ROI and that comes only when someone rebills. Since many people cancel their subscriptions immediately after purchase (to avoid the thing that follows) the rebill price is usually significantly more than the initial "amazing deal". This is why both Nord and Express have multiple class action lawsuits for dishonest billing practices - they have to do it, to get their bag (back). It's a race to the bottom of who can offer the most $ to affiliates, and shaft their customers as the inevitable result.Billing quirks aside, a VPN you choose should offer multiple VPN protocols, and obfuscation techniques. There is no 1 magic protocol that just works everywhere, as every country does censorship differently, using different tools.- Some do basic DNS filtering, in which case you don't need a VPN at all, just use an encrypted DNS protocol like DOH, from any provider (Cloudflare, Google, Control D[I also run this company], NextDNS, Adguard DNS)- Then there is SNI filtering, where changing your DNS provider won't have any effect and you will have to use a VPN or a secure proxy (HTTPS forward proxy, or something fancier like shadowsocks or v2ray).- Finally there is full protocol aware DPI that can be implemented with various degrees of aggressiveness that will perform all kinds of unholy traffic inspection on all TCP and UDP flows, for some or all IP subnets.For this last type, having a variety of protocols and endpoints you can connect to is what's gonna define your chance of success to bypass restrictions. Beyond variety of protocols, some VPN providers (like Windscribe, and Mullvad) will mess with packets in order to bypass DPI engines, which works with variable degree of success and is very region/ISP specific. You can learn about some of these concepts in this very handy project: https://github.com/ValdikSS/GoodbyeDPI (we borrow some concepts from here, and have a few of our own).Soooo... what are good VPNs that don't do shady stuff, keeps your privacy in mind, have a reasonably sized server footprint and have features that go beyond basic traffic proxying? There is IVPN, Mullvad, and maybe even Windscribe. All are audited, have open source clients and in case of Windscribe, also court proven to keep no logs (ask me about that 1 time I got criminally charged in Greece for actions of a Windscribe user).If you have any questions, I'd be happy to answer them.
Shadowsocks used to be the thing that _really_ worked in CN. Not sure what's current there.AWS  ap-southeast-3 should still be up, and isn't in a different partition like CN, govcloud, iso etc. So a VM there and a vpc peer in the US should get you around a lot of stuff.
Shadowsocks isn't a viable method in 2025 it seems. Not by itself apparently. 
Shadowsocks generates high-entropy noise via packet analysis, which typically is easy to spot out as it looks irregular.
You could rent a cheapo instance at a cloud provider and tunnel https over ssh.That’s basically undetectable. Long lived ssh connection? Totally normal. Lots of throughput? Also normal. Bursts throughput? Same.Not sure how to do this on mobile.Tailscale might be an option too (they have a free account for individuals and an exit node out of country nearly bypasses your problem) It uses wireguard which might not be blocked and which comes with some plausible deniability. It’s a secure network overlay not a VPN. It just connects my machines, honest officer.
Just please be safe and necessarily paranoidOne way they tend to "solve" workarounds is making examples of people
Use an Actual Private Network? Radio links that you control. Peer with someone who owns a Starlink terminal. Rent instances in GCP's Jakarta datacenter.
DNS tunnels with iodine works well, it's easy to setup and work in a lot of place.You can also connect to some random corporate wifi and it's very likely that this will work (not necessary in "direct" mode).
Easy, you can just create any generic Linux Amazon EC2 instance (or just about any cloud provider of your choice; in fact, the smaller the provider, the better) and use it as a SOCKS5 proxy via SSH tunnel with -D flag... Then set one of your browsers (e.g. Firefox) to connect via that proxy.Indistinguishable from any other server on the internet.
You've come to a wrong place to ask. Most people here (judging by recommendations of own VPN instances, Tor, Tailscale/other Wireguard-based VPNs, and Mullvad) don't have any experience with censorship circumvention.Just look for any VPNs that are advertised specifically for China, Russia, or Iran. These are the cutting edge tech, they may not be so privacy-friendly as Mullvad, but they will certainly work.
Hmm. People who recommend widely used approaches, and well-known, well-established providers, "don't have any experience with cenorship circumvention".So the solution is no-name providers using random ad-hoc hackery, chosen according to a criterion more or less custom designed to lead you into watering hole attacks.Right.
@reisse is 100% right. Most people outside of heavily censored regions have no clue what technology is actually used in those countries. The well-known, well-established providers don't actually work in censored regions because:1) The problem is very difficult and requires a lot of engineering resources
2) It's very hard to make money in these countries for many reasons, including sanctions or the government restricting payments (Alipay, WeChatPay, etc)The immediate response would be: "If the problem is so difficult, how can it be solved if not be well-known, well-established providers?"The answer is simple: the crowdsourcing power of open source combined with billions of people with a huge incentive to get around government blocking.
> It's very hard to make money in these countries for many reasonsTor and I2P, for example, don't actually make money anywhere. Which is not to say that they work for any of the users in all of these places, or for all of the users in any of these places.> The answer is simple: the crowdsourcing power of open source combined with billions of people with a huge incentive to get around government blocking.The actual answer is that (a) they're using so many different weird approaches that the censors and/or secret police can't easily keep up with the whack-a-mole, and (b) they're relying on folklore and survivorship bias to tell them what "works", without really knowing when or how it might fail, or even whether it's already failing.Oh, and most of them are playing for the limited stakes of being blocked, rather than for the larger stakes of being arrested. Or at least they think they are.Maybe that's "solving" it, maybe not.
It's very sad that every sane and informed comment (like reisse's) has to meet this kind of snarky comment whose only purpose is being snarky on HN.Perhaps you should stop and think about why people living in countries where governments actually censor a lot hardly use these "well-established providers" to circumvent censorship. Tip: it's not because they're stupid.
Actually, my main original purpose was to call (more) attention to the fact that looking for somebody specifically advertising a VPN to your particular country, for a censorship-resistance purpose, has a vastly greater chance of getting you a honey pot than almost any other possible way of looking for a relay. Honey pots are particularly dangerous in one-hop protocols with cleartext exit.The part about the unreliable ad-hockery is also true, albeit less critical. The fact is that you don't know what your adversary is doing now, and you definitely don't know what they're going to to roll out next. You don't have to be stupid to decide to take that risk, but you also don't have to be particularly stupid to not think about that risk in the first place, especially when people are egging you on to take it.The greater purpose underlying both is to keep people from unknowingly getting in over their heads. I have seen lots of people do actually stupid things, up close and personal, especially when given instructions without the appropriate cautions.And "services and providers" doesn't necessarily mean commercial VPNs. In fact those were way down the list of what I had in mind. Your own VPS is a "provider". So is Tor or I2P (not that those won't usually run into problems). So is your personal friend in another country.
> Actually, my main original purpose was to call (more) attention to the fact that looking for somebody specifically advertising a VPN to your particular country, for a censorship-resistance purposePlease re-read my post then. I do not call to look for VPN for your or anyone's particular country, I call to look for VPNs for these specific countries because they have the current bleeding edge blocking tech, and if VPN works there now, it will 100% work in every other country. If you're in China, you don't have to look for Chinese VPNs, some of Russian ones will work there too.
None of the things I listed are "widely used approaches, and well-known, well-established providers" in the parts of the world where it does matter.Yeah, maybe V* and derivatives are random ad-hoc hackery, but they also are the well-known standard now.
> Yeah, maybe V* and derivatives are random ad-hoc hackery, but they also are the well-known standard now.A lot of people use Telegram and think it's private, too.What about the part about choosing your VPN provider in the way most likely to get you an untrustworthy one who's after you personally?
> What about the part about choosing your VPN provider in the way most likely to get you an untrustworthy one who's after you personally?That's the straw man of yours, please read my answer to another your comment.
At DefCon 26 (25?) I attended two presentations that scared me:1. there was a presentation about several admins in a hostile country who had been arrested because someone from Harvard pinged a server they ran as part of IPv4 measurement. The suggestion was to avoid measuring countries with strong censorship laws to prevent accidental imprisonment of innocent IT.2. similar presentation about ToR project struggling to find fresh egress/ingress addresses. Authoritarian countries were making lists of any IP addresses that were known ToR IPs and prosecuting/imprisoning users associated with them as a result of traffic on those addresses.I would be extremely careful trying to bypass authoritarian restrictions unless I was 110% confident what I was doing.
Yeah. If an authoritarian government controls the network infrastructure, there's no way to use that network infra without risk.To actually bypass this, you need your own network. Does anyone know of any sneakernet protocols that would be useful here?
> Just look for any VPNs that are advertised specifically for China, Russia, or Iran.If I was working for a secret service for these countries, I would set up many "VPNs that are advertised specifically for x" as honeypots to gather data about any dissidents.
It doesn't matter, he should look into the open source protocols that these services use. He doesn't have to use them.VLESS / v2ray works in Russia, as far as I know.
Mr. Kafka, suspicion is healthy. However, abstraction provides no way forward when faced with practicalities instead of theory. Creates a Kafka-esque situation - anything suitable is by definition unsuitable. Better to focus on practical technical advice.
Sir Night: may I ask, what should it mean to me that some businesses are fronts?I hope I do not present the presence of a dullard unfamiliar with this.
I don't see parent abstracting. They are simply pointing out a very real risk, which you don't provide any counter points to. Instead you seem to dismiss their point based on a strawman
Mullvad worked okay in China in June for me. I imagine it will be better in Indonesia with their less sophisticated blocking.
This makes no sense.On the one hand they do DPI with ML.On the other hand a major player is open!Something is not right here...
Spell out your argument more. Find some hard evidence. Even “major player” needs to be backed up.Do you even know how many users Mullvad has in CN? I don’t. Searching says the whole company apparently has ~500k users. I don’t think that’s enough to be a significant presence in China.
OP: look into VLESS (and similar).  And read up on ntc.party (through Google translate).  There are certain VPN providers that offer the protocol.
nah, vless is the protocol, reality is a newer obfuscation method that works over vlessedit: op, protonvpn has a free tier that works in russia, so likely works everywhere, or if you're comfortable with buying a vps, sshing into it and running some commands, look up x-ray, and use on of their gui panels
Wrong threat model. Solutions like mullvad/proton focus on privacy not breaking the blockade. They have well known entry points and therefore easily blocked. You can play cat and mouse game switching servers faster than censorship agency blocks them (e.g. Telegram vs Roskomnadzor circa 2018 [1]) but that gets expensive and not really focus of these companies.What you need is open protocols and hundreds of thousands of small servers only known to their owners and their family/friends1: https://archive.is/sxiha
I have a little, maybe enough to be dangerous. SSH won’t be sufficient to avoid all traffic analysis. Everyone can see how much traffic and the pattern of that traffic, which can leak info about the sort of things you’re doing.If you’re worried about ending up on a list, using things that look like VPNs while the VPNs are locked down is likely to do so.Also… your neighbors in Myanmar didn’t do a lockdown during the genocide and things got pretty fucking dire as a result. People have taken different lessons from this. I’m not sure what the right answer is, and which is the greater evil. Deplatforming and arresting people for inciting riots and hate speech is probably the best you can do to maintain life and liberty for the most people.
>Also… your neighbors in Myanmar didn’t do a lockdown during the genocide and things got pretty fucking dire as a resultThe genocide in Myanmar was incited _by_ the government there; giving it more power to censor it's citizens' communications would have done absolutely nothing to help the people being genocided. Genocides don't just suddenly happen; the vast majority of genocide over the past century (including Indonesian genocides against ethnically Chinese Indonesians) had the support of the state.
This has been simmering for a very long time. The first I heard of it was violence that broke out after the defacement of a Buddhist temple statue. That would have been almost 20 years ago. Buddhists murdering people tends to lead one to ask a lot of questions.At that time I think the government was hands off, let it happen rather than tried to stop it.Regardless of who was behind the violence, the whole region has thought about what to do in such situations and they aren’t the same answers the West would choose.
^ this comment is right on. The cutting edge of VPN circumvention is the one marketed to people in China. Last I poked at this there were a lot of options.
Mullvad worked OK in China for me recently. Sometimes I'd have to try a few different endpoints before it worked. Something built specifically to work in those places would probably be better, but it wasn't too much trouble. Not necessarily a recommendation, just sharing one data point.
I remember always needing obfuscation enabled in Mullvad, but it would work in the end (as you said, after trying a few endpoints).
VPNs that are advertised are for-profit products, which means:1. They are in most cases run by national spy agencies.2. They will at least appear to work, i.e., they will provide you with access to websites that are blocked by the country you are in.  Depending on which country's spies run the system, they may actually work in the sense of hiding your traffic from that country's spies, or they may mark you as a specific target and save all your traffic for later analysis.My inclination is to prefer free (open-source) software that isn't controlled by a company which can use that control against its users.
Well, you have to host your free open-source VPN software somewhere. And then, (N. B.: technical and usability stuff aside, I'm talking only about privacy bits here) everything boils down to two equally nightmarish options.First, you use well-known cloud or dedicated hoster. All your traffic is now tied to the single IP address of that hoster. It may be linked to you by visiting two different sites from the same IP address. Furthermore, this hoster is legally required to do anything with your VPN machine on demand of corresponding state actors (this is not a speculative scenario; i. e. Linode literally silently MitMed one of their customers on German request). Going ever further, residential and company IPs have quite different rules when it comes to law enforcement. Seeding Linux ISOs from your residential IP will be overlooked almost everywhere (sorry, Germany again), but seeding Linux ISOs from AWS can easily be a criminal offense.Second, you use some shady abuse-proof hosting company, which keeps no logs (or at least says that) and accepts payments in XMR. Now you're logging in to your bank account from an IP address that is used to seedbox pirate content or something even more illegal, and you still don't know if anyone meddles with your VPN instance looking for crypto wallet keys in your traffic.VPN services have a lot of "good" customers for a small amount of IP addresses, so even if they have some "bad" actors, their IPs as a whole remain "good enough". And, as the number of customers is big, each IP cannot be reliably tied to a specific customer without access logs.
Tor is a third option, at least as one layer, and seeding Linux ISOs is not, to my knowledge, a criminal offense in any jurisdiction, not even in China.  I don't know where you got that idea.
It is absolutely self-evident that VPNs are considered high-value targets and that all spy agencies invest a chunk of resources to go after high-value targets.
I would invite you to read again the two claims made, and consider whether your statement actually addresses the veracity of either.To be a little trite: we all agree that chickens like grain, but it does not follow that a majority of grain producers are secretly controlled by a cabal of poultry.
>... but it does not follow that a majority of grain producers are secretly controlled by a cabal of poultry.That's precisely what someone who's in on it would say.
From gemini.. (edited for brevity)Kape Technologies Owns: ExpressVPN, CyberGhost, Private Internet Access, Zenmate> is there any suspicion that Kape Technologies is influenced or has ties to the Mossad?Yes, there is significant suspicion and public discussion about Kape Technologies having ties to former Israeli intelligence personnel. While a direct operational link to Mossad has not been proven, the concerns stem from the company's history, its key figures, and their backgrounds....Kape Technologies is owned by Israeli billionaire Teddy Sagi. While Sagi himself does not have a documented intelligence background, his business history, which includes a conviction for insider trading in the 1990s, has been a point of concern for some privacy advocates. The consolidation of several major VPN providers under his ownership has raised questions about the potential for centralized data access.----Sure there isn't direct proof but there wasn't any proof the CIA was driving drug trade while it was happening. Proof materializes when the dust settles on such matters.
Blocking Twitter is a good start, now Facebook, Instagram, Whatsup and TikTok.This is a good start but more should be blocked. Then force ISP to block ads.Not just for Indonesia but all countries. But we still have a lot more to do to fix the web.
The issue with that is where do they draw the line. Next thing you know each country becomes North Korea.]]></content:encoded>
        </item>
    </channel>
</rss>