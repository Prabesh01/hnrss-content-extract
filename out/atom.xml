<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-28T17:08:52.928217+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46077136</id><title>The Math of Why You Can't Focus at Work</title><updated>2025-11-28T17:09:06.337686+00:00</updated><content>&lt;doc fingerprint="2423b0f51b270a71"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;When was the last time you had a good day of work? The kind where you got into flow and stayed there long enough to think deeply about a problem?&lt;/p&gt;
    &lt;p&gt;Paul Graham wrote about this in 2009: a single meeting can wreck an entire half-day for someone who needs uninterrupted time to build something. Sixteen years later, we’ve added Slack, Teams, always-on video calls, and a culture of instant responsiveness. The problem has gotten worse, with the pandemic turning things to 11 but the conversation stays frustratingly vague. We know focus is dying. We can’t say how bad it is or what would fix it.&lt;/p&gt;
    &lt;p&gt;In this post, I’ll show you what interruption-driven work looks like when you model it with math. Three simple parameters determine whether your day is productive or a write-off. We’ll simulate hundreds of days and build a map of the entire parameter space so you can see exactly where you are and what happens when you change.&lt;/p&gt;
    &lt;head rend="h2"&gt;One Day in Detail&lt;/head&gt;
    &lt;p&gt;Let’s start by drawing what one of those “lost days” actually looks like.&lt;/p&gt;
    &lt;p&gt;You managed 3h 58m of focus time and 1 deep work blocks (&amp;gt;60m), though 19 interruptions cost you 242 min of potential productivity, capping your longest uninterrupted stretch at 81 min.&lt;/p&gt;
    &lt;p&gt;The visualization above shows an 8-hour workday as a timeline. Green segments represent real, uninterrupted focus blocks—the time when you’re genuinely working on the problem. Red lines are interruptions: a Slack DM, a meeting, someone asking a question. The hatched gray zones are recovery time—you’re back at your desk, but you’re not back in the problem yet. The amber and red sections are where you’re partially in the zone—where your focus is broken before 30 or 15 minutes respectively. The goal is to be in the green (or blue).&lt;/p&gt;
    &lt;p&gt;Notice how often the red interruptions land. Notice how much of your 8 hours is actually gray recovery time, not green focus time. Count how many genuine 60-minute blocks you got: just one. You spent the whole day “working,” but very little of it was uninterrupted work.&lt;/p&gt;
    &lt;p&gt;And here’s a good day, for comparison’s sake:&lt;/p&gt;
    &lt;p&gt;You managed 6h 14m of focus time and 3 deep work blocks (&amp;gt;60m), though 10 interruptions cost you 106 min of potential productivity, capping your longest uninterrupted stretch at 137 min.&lt;/p&gt;
    &lt;p&gt;So, how do we go from the bad day to the good one? It comes down to three numbers: how often you’re interrupted, how long it takes to recover, and how much unbroken time your work requires.&lt;/p&gt;
    &lt;p&gt;Let’s walk through them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Three Knobs That Secretly Define Your Day&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Symbol&lt;/cell&gt;
        &lt;cell role="head"&gt;What it measures&lt;/cell&gt;
        &lt;cell role="head"&gt;Units&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;λ (lambda)&lt;/cell&gt;
        &lt;cell&gt;How often you get interrupted&lt;/cell&gt;
        &lt;cell&gt;per hour&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Δ (delta)&lt;/cell&gt;
        &lt;cell&gt;How long to regain focus after each interruption&lt;/cell&gt;
        &lt;cell&gt;minutes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;θ (theta)&lt;/cell&gt;
        &lt;cell&gt;Minimum block size for meaningful work&lt;/cell&gt;
        &lt;cell&gt;minutes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;λ (lambda): Interruptions&lt;/head&gt;
    &lt;p&gt;Lambda (λ) is your interruption rate, measured in interruptions per hour (modeled as a Poisson process). If λ = 2, you’re getting interrupted, on average, twice every hour. In the timeline above, lambda determines how many red spikes you see.&lt;/p&gt;
    &lt;p&gt;It’s a function of your environment: how many meetings you have, how many Slack channels you’re in, how many people feel entitled to “just a quick question,” whether your company culture treats every message as urgent. Some people, like managers and executives, get interrupted a lot. Others usually don’t, but their λ can spike during on-call rotations or triage weeks. We try to model that by randomness.&lt;/p&gt;
    &lt;p&gt;Most people dramatically underestimate their real λ, but we’ll get to that in a moment.&lt;/p&gt;
    &lt;head class="flex cursor-pointer items-center font-medium [&amp;amp;::-webkit-details-marker]:hidden"&gt;Note (On Poisson distributions)&lt;/head&gt;
    &lt;p&gt;Our simulations model interruptions as a Poisson process, which assumes they arrive randomly and uniformly throughout the day. In reality, interruptions tend to cluster. Think back-to-back meetings, Slack storms after a big announcement, email bursts when you return from lunch. This clustering cuts both ways: sometimes it leaves clean gaps (your afternoon block after a morning full of meetings), but often it makes things worse because clustered interruptions compound recovery time and eliminate any chance of regaining focus between hits.&lt;/p&gt;
    &lt;head rend="h3"&gt;Δ (delta): Recovery Period&lt;/head&gt;
    &lt;p&gt;Delta (Δ) is your recovery time in minutes. When someone interrupts you, you don’t instantly return to full productivity the moment they walk away. Your brain needs time to reload the context, reconstruct the mental model, and remember what you were doing. That’s delta. In the timeline, it’s the width of those hatched gray bars after every red spike.&lt;/p&gt;
    &lt;p&gt;Delta varies by person and by task. It’s shorter if you left yourself good breadcrumbs before the interruption. It’s longer if you’re doing deep, complex work. But it’s never zero. More depressingly, even a “quick two-minute question” can cost you 15–20 minutes of recovery time.&lt;/p&gt;
    &lt;head rend="h3"&gt;θ (theta): Focus Threshold&lt;/head&gt;
    &lt;p&gt;Theta (θ) is the minimum uninterrupted time required for a “unit” of real work. If you’re writing code, reviewing a design, or solving a hard problem, you probably need at least 30–60 minutes of continuous focus to make meaningful progress. That’s your theta.&lt;/p&gt;
    &lt;p&gt;It’s also why five 10-minute blocks don’t add up to one 50-minute block. When things are below your theta, things just don’t compound. Another way to think of this as fragmentation: interruptions can break your time into pieces too small to be useful, even if the total time is the same.&lt;/p&gt;
    &lt;p&gt;You managed 3h 44m of focus time and 1 deep work blocks (&amp;gt;60m), though 19 interruptions cost you 256 min of potential productivity, capping your longest uninterrupted stretch at 82 min.&lt;/p&gt;
    &lt;p&gt;In our timeline visualizations, theta is what we’re measuring the green and blue blocks against. If your theta is 60 minutes and you only have 45-minute blocks, you’re not getting any “real” work done by your own standards.&lt;/p&gt;
    &lt;p&gt;Capacity&lt;/p&gt;
    &lt;p&gt;I know I said three numbers, but capacity is just a result of all three so I’ll sneak this in.&lt;/p&gt;
    &lt;p&gt;Given what a day looks like based on these three parameters, we can write a simple formula that counts how many units of real work you accomplish in a day.&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;is the duration (in minutes) of focus block&lt;/item&gt;
      &lt;item&gt;is your minimum uninterrupted time for one “unit” of real work&lt;/item&gt;
      &lt;item&gt;is the floor function (round down to the nearest integer)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Based on all your focus blocks (the green and blue segments), we count how many theta-sized chunks fit. This is your day’s “capacity” for productive work. The higher the capacity, the more productive you are.&lt;/p&gt;
    &lt;p&gt;For illustration, here’s a high capacity day:&lt;/p&gt;
    &lt;p&gt;You managed 6h 30m of focus time and 3 deep work blocks (&amp;gt;60m), though 9 interruptions cost you 90 min of potential productivity, capping your longest uninterrupted stretch at 119 min.&lt;/p&gt;
    &lt;p&gt;Notice the long stretches of uninterrupted green. Multiple 60-minute blocks. This day has high capacity. The math is on your side.&lt;/p&gt;
    &lt;p&gt;The Capacity Formula in Action&lt;/p&gt;
    &lt;p&gt;But things can (and will) go sideways. Suppose you have a day with three focus blocks: 90 minutes, 45 minutes, and 20 minutes. Your total focus time is 155 minutes. But how much capacity do you have? It depends entirely on θ:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;θ&lt;/cell&gt;
        &lt;cell role="head"&gt;The Math&lt;/cell&gt;
        &lt;cell role="head"&gt;Final Capacity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;30&lt;/cell&gt;
        &lt;cell&gt;⌊90/30⌋ + ⌊45/30⌋ + ⌊20/30⌋&lt;/cell&gt;
        &lt;cell&gt;3 + 1 + 0 = 4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;45&lt;/cell&gt;
        &lt;cell&gt;⌊90/45⌋ + ⌊45/45⌋ + ⌊20/45⌋&lt;/cell&gt;
        &lt;cell&gt;2 + 1 + 0 = 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;60&lt;/cell&gt;
        &lt;cell&gt;⌊90/60⌋ + ⌊45/60⌋ + ⌊20/60⌋&lt;/cell&gt;
        &lt;cell&gt;1 + 0 + 0 = 1&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Same 155 minutes, yet the capacity slides all the way down from 4 to 1. This is why small changes in θ or block length can collapse your productivity. The floor function (⌊x⌋) is unforgiving. The math is not on your side this time.&lt;/p&gt;
    &lt;p&gt;Once we write your day as a function of these three parameters—λ for how noisy your environment is, Δ for how sticky interruptions are, and θ for how demanding your work is—we can stop treating bad days as vibes and start treating them as a model we can reason about.&lt;/p&gt;
    &lt;head rend="h2"&gt;100 Days Under the Same Conditions&lt;/head&gt;
    &lt;p&gt;So far, we’ve only looked at a single day, but one day can be a fluke—maybe you got lucky, or maybe you got unlucky. What happens if we simulate 100 days with the same λ, Δ, and θ?&lt;/p&gt;
    &lt;p&gt;Luckily, computers make simulating many days trivial. Let’s extend our model to actually simulate 100 days in a row and see all the visualizations together.&lt;/p&gt;
    &lt;p&gt;On the grid above, each cell is one simulated 8-hour workday. The color encodes the longest continuous focus block you got that day. Darker, richer colors mean longer focus blocks—those are the high-capacity days. Dim, washed-out cells are the low-capacity days, where you never got more than 15–30 minutes of uninterrupted time.&lt;/p&gt;
    &lt;p&gt;The above simulation was when things were cheery. But how about when things go sideways?&lt;/p&gt;
    &lt;p&gt;That above is what 100 days look like under relatively harsh conditions: λ = 3.0 (three interruptions per hour), Δ = 20 (20-minute recovery), θ = 60 (you need 60-minute blocks to count as “real work”):&lt;/p&gt;
    &lt;p&gt;OK, now that we’ve got our technology working, let’s ground things in reality. It’s time to dig into some research to feed our model some real λ and Δ.&lt;/p&gt;
    &lt;head rend="h2"&gt;What λ and Δ Look Like in Real Jobs&lt;/head&gt;
    &lt;p&gt;Nothing I’ve mentioned here is very new. People in both academia and industry have been studying these figures for years. We know, for example, that the rate of interruptions and recovery times vary significantly across industries and even across roles within an industry.&lt;/p&gt;
    &lt;p&gt;Interruption Frequency:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Finding&lt;/cell&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Every 2 minutes during core hours&lt;/cell&gt;
        &lt;cell&gt;Microsoft 2025 Work Trend Index&lt;/cell&gt;
        &lt;cell&gt;M365 telemetry; top 20% of users by volume&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Every 3 min 5 sec activity switch&lt;/cell&gt;
        &lt;cell&gt;González &amp;amp; Mark, CHI 2004&lt;/cell&gt;
        &lt;cell&gt;Field study shadowing tech workers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;7.5 alerts/hour (email + IM)&lt;/cell&gt;
        &lt;cell&gt;Iqbal &amp;amp; Horvitz, CHI 2007&lt;/cell&gt;
        &lt;cell&gt;27 information workers; 2,267 hours logged&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Recovery Time:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Finding&lt;/cell&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
        &lt;cell role="head"&gt;Method&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;10–16 minutes in resumption phase&lt;/cell&gt;
        &lt;cell&gt;Iqbal &amp;amp; Horvitz, CHI 2007&lt;/cell&gt;
        &lt;cell&gt;After email/IM interruptions&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The research paints a consistent, if not depressing, picture. González &amp;amp; Mark found workers switch activities every 3 minutes on average. Iqbal &amp;amp; Horvitz measured 7.5 email/IM alerts per hour, with 10–16 minutes needed to resume work after each. And those (well-cited) studies are from years ago! The more recent Microsoft Work Trend Index reports that heavy collaborators see interruptions every 2 minutes. That’s λ = 30!&lt;/p&gt;
    &lt;head rend="h3"&gt;What the Research Data Actually Looks Like&lt;/head&gt;
    &lt;p&gt;If those numbers sound crazy or too high to be real, you are not alone. Look back at the visualizations you’ve seen so far in this post. We looked at days where λ is between 0 and 4 per hour, and Δ between 5 and 30 minutes. These are the polite, toned-down versions of reality. If González &amp;amp; Mark see activity switches every 3 minutes and Microsoft sees λ = 30 for heavy collaborators, our λ = 2–3 examples are actually best-case scenarios for many real environments.&lt;/p&gt;
    &lt;p&gt;Here’s 100 days with λ = 15 (roughly matching the González &amp;amp; Mark activity-switching data) and Δ = 25 (moderate recovery time):&lt;/p&gt;
    &lt;p&gt;If you’re looking at this grid and thinking “is the visualization broken?”, you are not alone. I had the same reaction when I first generated it. The entire grid is gray. There’s simply no time to work.&lt;/p&gt;
    &lt;p&gt;But it’s not broken. Here’s what a single day with these parameters actually looks like. Make sure to browse back and forth to see if you can find a day with any focus blocks:&lt;/p&gt;
    &lt;p&gt;You managed 0h 5m of focus time and 0 deep work blocks (&amp;gt;60m), though 138 interruptions cost you 475 min of potential productivity, capping your longest uninterrupted stretch at 5 min.&lt;/p&gt;
    &lt;p&gt;Now you can see why the grid appears uniformly gray. There really is no focus time. In fact there’s not even any 15-minute block on almost any of the days. The day view is a dense wall of red interruptions, each triggering a gray recovery period. The tiny slivers of focus time are too short to even render at the grid scale. There are no greens, and there’s a sole amber and a sole red. When you zoom out to 100 days, every single day looks like this. All dim, no pun intended.&lt;/p&gt;
    &lt;p&gt;This is the modern workplace. González &amp;amp; Mark measured activity switches every 3 minutes. Microsoft reports λ = 30 for heavy collaborators. These researchers are describing millions of people’s actual working conditions. And at these parameters, the math is unambiguous: deep work is statistically near-impossible. We’ve normalized an environment where focus has been engineered out of the workday. No wonder everyone’s stressed!&lt;/p&gt;
    &lt;p&gt;Again, for the sake of argument, let’s just go back to a “sane” workday. Same 8-hour days, same θ = 60, but now λ = 1.0 (one interruption per hour) and Δ = 10 (10-minute recovery).&lt;/p&gt;
    &lt;p&gt;Look at that difference! Almost all days have more than three blocks of 60-minute work, meaning they light up like a Christmas tree. The dim “hopeless” days are much rarer. The distribution has shifted—not because you suddenly became more disciplined, but because the system’s parameters changed. The math has spoken.&lt;/p&gt;
    &lt;p&gt;If you take away one thing from this post, it’s this: the variability you experience across days is structural forces working against you. When λ and Δ are high, bad days are common. When λ and Δ are lower, good days become routine. Even small increases make conditions significantly worse.&lt;/p&gt;
    &lt;p&gt;Moreover, “thanks to” randomness, you have a lot less control over what your day looks like. For example, here’s a breezy day with almost no interruptions (λ = 1) and a short recovery period (Δ = 15). With not one, not two, but three 60+ minute blocks, this is a great day!&lt;/p&gt;
    &lt;p&gt;You managed 5h 25m of focus time and 3 deep work blocks (&amp;gt;60m), though 12 interruptions cost you 155 min of potential productivity, capping your longest uninterrupted stretch at 76 min.&lt;/p&gt;
    &lt;p&gt;Yet it’s also possible to have a bad day with the exact same parameters. Note that while you have multiple 45+ minute blocks, you simply can’t get a single 60-minute block on this day.&lt;/p&gt;
    &lt;p&gt;You managed 5h 19m of focus time and 0 deep work blocks (&amp;gt;60m), though 13 interruptions cost you 161 min of potential productivity, capping your longest uninterrupted stretch at 58 min.&lt;/p&gt;
    &lt;p&gt;You can’t eliminate variance, unfortunately, but you can shift the distribution. In a good regime, with high capacity days as the norm, great days become normal and bad days become the exception you can absorb. If you want to take away two things from this post, remember that you can control things! We’ll get to that later.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Map of Deep Work&lt;/head&gt;
    &lt;p&gt;OK, so far we’ve fixed the knobs (λ, Δ, θ) and watched the random outcomes (individual days, grids of 100 days) play out. But what if we could see the whole landscape at once—every combination of λ and Δ, and how they interact? Once again, computers to the rescue!&lt;/p&gt;
    &lt;p&gt;That’s what our heatmap does. The color shows the expected capacity (number of θ-minute blocks per day). Dark purple cells are hospitable to deep work. Light purple cells are hellish; you’re lucky to get even one θ-block per day. I’ve also highlighted some cells, based on the research data above.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The “good” world (green border, λ = 1.0, Δ = 10) is better than most real-world environments. It’s closer to a protected morning on a maker’s schedule, or a team that’s serious about focus time.&lt;/item&gt;
      &lt;item&gt;The “typical” world (amber border, λ = 2.0, Δ = 20) is still more generous than what González &amp;amp; Mark observed (activity switches every 3 minutes), but it’s already rough for 60-minute deep work.&lt;/item&gt;
      &lt;item&gt;The “terrible” world (red border, λ = 3.0, Δ = 25) is a softened version of the heavy-collaborator world (30 interruptions/hour). The actual PM/team-lead reality often lives off the right edge of this chart.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now use the threshold control to toggle θ between 30, 45, and 60 minutes. Watch what happens to the three highlighted cells:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The green cell stays relatively dark even at θ = 60. This is high capacity: you can expect multiple 60-minute blocks per day.&lt;/item&gt;
      &lt;item&gt;The amber cell looks dark at θ = 30, lightens at θ = 45, and nearly washes out at θ = 60. The capacity collapses as θ increases. This is why you feel like you can handle small tasks but never get to the hard problems.&lt;/item&gt;
      &lt;item&gt;The red cell is basically washed out at any θ that matters. You are ruined. With such low capacity, even 30-minute blocks are rare.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The point is that the capacity is very sensitive your theta. It’s significantly harder to finish a longer task that will take 60 minutes than it is to finish two tasks that will take 30 minutes each. This will inform some of the remediation we’ll get to later.&lt;/p&gt;
    &lt;head class="flex cursor-pointer items-center font-medium [&amp;amp;::-webkit-details-marker]:hidden"&gt;Explanation (Monte Carlo Estimation)&lt;/head&gt;
    &lt;p&gt;To create heatmaps, we calculate the expected capacity for each combination of .&lt;/p&gt;
    &lt;p&gt;Where:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;= expected capacity (what we’re estimating)&lt;/item&gt;
      &lt;item&gt;= number of simulations (typically 60)&lt;/item&gt;
      &lt;item&gt;= capacity observed in simulation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By the Law of Large Numbers, as , the sample mean converges to the true expected value:&lt;/p&gt;
    &lt;p&gt;With , we get a good approximation with reasonable computation time.&lt;/p&gt;
    &lt;head rend="h2"&gt;How a Better Day Actually Looks&lt;/head&gt;
    &lt;p&gt;Now let’s see what it means to actually move on the map. We’ll start in the “typical” world and watch what happens when we shift toward better territory.&lt;/p&gt;
    &lt;p&gt;Here’s the map with just the amber cell highlighted (λ = 2.0, Δ = 20):&lt;/p&gt;
    &lt;p&gt;And here’s what a day in that cell looks like:&lt;/p&gt;
    &lt;p&gt;You managed 3h 37m of focus time and 1 deep work blocks (&amp;gt;60m), though 21 interruptions cost you 263 min of potential productivity, capping your longest uninterrupted stretch at 61 min.&lt;/p&gt;
    &lt;p&gt;Lots of red interruptions. Wide gray recovery zones. Very few green blocks longer than 45 minutes. This is what a structurally difficult day looks like. And remember: λ = 2.0 is wildly generous compared to the research data.&lt;/p&gt;
    &lt;p&gt;Now let’s move to the green cell (λ = 1.0, Δ = 10):&lt;/p&gt;
    &lt;p&gt;And here’s what a day in that cell looks like:&lt;/p&gt;
    &lt;p&gt;You managed 7h 30m of focus time and 5 deep work blocks (&amp;gt;60m), though 3 interruptions cost you 30 min of potential productivity, capping your longest uninterrupted stretch at 227 min.&lt;/p&gt;
    &lt;p&gt;The difference is striking. Fewer interruptions. Narrower recovery zones. Multiple 60-minute focus blocks. The change in parameters is modest—one fewer interruption per hour, ten fewer minutes of recovery—but the impact on your day is dramatic.&lt;/p&gt;
    &lt;p&gt;This is what “moving on the map” actually looks like. The next section covers how to do it.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Move Around the Map&lt;/head&gt;
    &lt;p&gt;Let’s get back to our heatmap:&lt;/p&gt;
    &lt;p&gt;I hope that so far I have been able to make the case that you really want to go from the red cell to the green cell. And not just that, you want to be in a cell, wherever it might be, be it red, amber, or green, that your capacity is high. In other words, we want to move up the ladder (up and to the right) and then ideally change our map to a better one.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce λ – Fewer Interruptions Per Hour&lt;/head&gt;
    &lt;p&gt;Lambda is about access. The good news: it’s the most impactful lever you have, based on the math. Doubling interruptions more than doubles the lost time due to chain interruptions (interruptions during recovery) and fragmentation (reducing capacity even when total time is the same).&lt;/p&gt;
    &lt;p&gt;Here’s an example of this in action. Consider the case that you want to find three 60-minute blocks on any given day. What would your chances be?&lt;/p&gt;
    &lt;p&gt;Here’s what your chances look like with λ=1.&lt;/p&gt;
    &lt;p&gt;There are exactly 70 days that fit that criteria. In other words, you have 70% chance of finding three 60-minute blocks on any given day.&lt;/p&gt;
    &lt;p&gt;Let’s increase the rate of interruptions. Here’s λ=2, just one more interruption per hour with the same random seed:&lt;/p&gt;
    &lt;p&gt;Now, there are only 14 days! Your chances of success went down by 5 times.&lt;/p&gt;
    &lt;p&gt;Since λ is about access, in theory it’s what you have the most control over. Protect your calendar, get fewer interruptions. Easy, right?&lt;/p&gt;
    &lt;p&gt;Unfortunately, reality begs to differ. People in leadership positions want to be available to others, so they keep their calendars open. And people in IC roles often don’t get to control their calendars as much as they’d like—those pesky managers keep scheduling meeting after meeting.&lt;/p&gt;
    &lt;p&gt;But, not all hope is lost. The González study found that for knowledge workers, almost half the interruptions are self-inflicted. While it is true very few people have control over their calendars these days, we are the masters of our destiny and captains of our ship more than we think when it comes to interruptions. Another similar study also found that people who blocked interruptions found their job satisfaction to be much higher.&lt;/p&gt;
    &lt;p&gt;Checking your inbox only a few times a day—or even just twice—pays huge dividends. In my experience, almost nothing is actually urgent, and it’s better to train people that getting your attention requires effort than to train them that you’re always available. Whatever you do, any effort you put in here will be worth it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Match θ to Reality – Design Tasks for Your Environment&lt;/head&gt;
    &lt;p&gt;Theta is different from λ and Δ because you usually can’t change the nature of the work itself. If you’re working on a hard problem that genuinely requires 90 minutes of continuous thought, that’s just θ = 90. You are SOL.&lt;/p&gt;
    &lt;p&gt;But you can design your day as a portfolio of tasks with different θ values, and match them to your realistic λ and Δ conditions. Remember, this is you changing your threshold on that interactive map above regardless of which cell you are in. The goal here is to aim for smaller theta work.&lt;/p&gt;
    &lt;p&gt;θ = 30 minutes&lt;/p&gt;
    &lt;p&gt;θ = 60 minutes&lt;/p&gt;
    &lt;p&gt;Break large projects into smaller tasks:&lt;/p&gt;
    &lt;p&gt;If your environment has λ = 3 and you’re trying to do θ = 90 work, you’re going to have a bad time. The heatmap says so. But if you can decompose that work into tasks with θ = 30, suddenly it becomes feasible. So, whenever you have a big project, think about the independent pieces of it that you can attack.&lt;/p&gt;
    &lt;p&gt;For example, “design and implement the new authentication flow” is θ = 90 work. But you can decompose it: sketch the state machine (30 min), write the token validation logic (30 min), build the UI component (30 min), wire up the error handling (30 min). Each piece is independently completable and doesn’t require holding the whole system in your head at once.&lt;/p&gt;
    &lt;p&gt;Same with product work: “write the PRD” is θ = 90, but “define the problem statement” is θ = 20, “list user stories” is θ = 30, “draft success metrics” is θ = 20.&lt;/p&gt;
    &lt;p&gt;Beyond the mathematical advantage, there’s a psychological one: finishing a task gives you a small hit of momentum that you can ride to the next task. A day with four completed θ = 30 tasks feels productive, which makes you more likely to protect your focus tomorrow. A day where you made “some progress” on one θ = 90 task often feels like you got nothing done, even if the raw minutes were similar.&lt;/p&gt;
    &lt;p&gt;Reserve low-λ windows for high-θ work:&lt;/p&gt;
    &lt;p&gt;If you can defend a 2-hour window early in the morning with λ ≈ 0, that’s where you do your θ = 60–90 work. Use the rest of your day (higher λ) for smaller tasks that tolerate fragmentation.&lt;/p&gt;
    &lt;p&gt;θ = 20 minutes&lt;/p&gt;
    &lt;p&gt;θ = 90 minutes&lt;/p&gt;
    &lt;p&gt;Remember, this is not the same as “lowering your λ” but instead realizing that certain times of day (or week) have predictable interrupt patterns. You can’t always get what you want, but you might get what you need, if your theta is right for the time. Say, if you’re a PM or team lead living at λ = 20, starting a θ = 60 project at 3pm is fantasy. It’s extremely unlikely you’ll get a 60-minute block ever with a lambda like that but it’s practically impossible that you’ll get one that late in the day.&lt;/p&gt;
    &lt;p&gt;You need to either carve out radically different conditions or accept that this kind of work simply doesn’t happen in your normal day. I don’t want to get into the 996 discourse right now but there is a reason you see so many managers work early in the mornings before others, or on Sunday nights.&lt;/p&gt;
    &lt;p&gt;Remember the Map:&lt;/p&gt;
    &lt;p&gt;Remember, when you adjust theta (carve out your work), you’re not moving on the map. You’re choosing a different map. When you toggle the threshold control on the heatmap from θ = 60 to θ = 30, you’re asking a different question: “What environment do I need for 30-minute work instead of 60-minute work?” The map changes, and suddenly the “typical” (amber) and “terrible” (red) cells look more survivable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reduce Δ – Shorten Recovery Time&lt;/head&gt;
    &lt;p&gt;Delta is about stickiness. It’s how long interruptions linger after they’re technically over. You can’t make Δ zero, but you can shave minutes off each recovery, and those minutes compound quickly.&lt;/p&gt;
    &lt;p&gt;Iqbal &amp;amp; Horvitz found that workers take 10–16 minutes to resume work after email/IM interruptions. The variance is huge, and much of it comes from preparedness and task similarity. If you are or your task is on the high end of that delta (Δ ≈ 15+), small hygiene improvements can shave off valuable minutes.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leave yourself breadcrumbs before switching tasks. When you’re interrupted, send yourself a Slack message about what you were doing and what comes next. This sounds quirky, but it works.&lt;/item&gt;
      &lt;item&gt;Avoid wide context switches. If you’re interrupted while coding, handling a quick code-review question is less disruptive than handling a recruiting question. Minimize cross-domain bouncing when possible.&lt;/item&gt;
      &lt;item&gt;Small rituals to re-enter focus. Some people re-read the last few lines of code they wrote, or scan their notes, or take three deep breaths. Find whatever works for you.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;From “Bad Days” to a Tuneable System&lt;/head&gt;
    &lt;p&gt;Look, this model is wrong, like all other models are. You can’t reverse Taylorism your way out of a broken calendar by (re-)inventing Greek letters. But wrong models can still be useful if they help you see the system clearly enough to change it.&lt;/p&gt;
    &lt;p&gt;My point is this: given your λ and Δ, deep work is mathematically rare unless you deliberately design for it. You’re not uniquely undisciplined. Stop feeling bad. You’re operating in a system where the default state is fragmentation. The world is out there to get you!&lt;/p&gt;
    &lt;p&gt;But hey, good news! This system is very sensitive to small inputs. That’s a liability when the universe decides to screw you, but it’s also leverage when you intervene. Dropping λ from 3 to 2, just one fewer interruption per hour each day, can transform your week. Learning how to split your tasks into smaller chunks by picking small θ can make your life a whole lot easier. Cutting Δ from 25 to 15 minutes can mean the difference between a hellish day or a passable one. You don’t have to win every battle to win the war.&lt;/p&gt;
    &lt;p&gt;Try this: pick one week and defend a single 90-minute block each morning. Treat that block as your λ/Δ/θ lab. No meetings, no Slack, no “quick questions.” Measure what you accomplish in that block versus the rest of your day.&lt;/p&gt;
    &lt;p&gt;I suspect you’ll see the parameters at work. And once you see them, you can’t unsee them.&lt;/p&gt;
    &lt;head rend="h2"&gt;One More Thing…&lt;/head&gt;
    &lt;p&gt;If you want to experiment with the parameters yourself, try the Interruptions Simulator. I’ll write more about how and why I built that tool later!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://justoffbyone.com/posts/math-of-why-you-cant-focus-at-work/"/><published>2025-11-28T09:39:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46077393</id><title>EU Council Approves New "Chat Control" Mandate Pushing Mass Surveillance</title><updated>2025-11-28T17:09:06.107090+00:00</updated><content/><link href="https://reclaimthenet.org/eu-council-approves-new-chat-control-mandate-pushing-mass-surveillance"/><published>2025-11-28T10:36:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46077964</id><title>A Tale of Four Fuzzers</title><updated>2025-11-28T17:09:05.820942+00:00</updated><content>&lt;doc fingerprint="7f7892312c01258d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Tale Of Four Fuzzers&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;Charles Darnay observed that the gate was held by a mixed guard of soldiers and patriots, the latter far outnumbering the former; and that while ingress into the city for peasantsâ carts bringing in supplies, and for similar traffic and traffickers, was easy enough, egress, even for the homeliest people, was very difficult.&lt;/p&gt;&lt;lb/&gt;â Complaining about egress fees goes back to at least the French Revolution.&lt;/quote&gt;
    &lt;p&gt;Some time ago we overhauled TigerBeetleâs routing algorithm to better handle varying network topologies in a cluster. That turned out to be an interesting case study of practical generative testing (or fuzzing) for non-trivial, real-world code. We ended up adding not one, not even two, but four very different new fuzzers to the system! Letâs talk about why just one fuzzer is not enough.&lt;/p&gt;
    &lt;p&gt;This is a good moment to brew some tea, the journey will take us awhile!&lt;/p&gt;
    &lt;p&gt;Although this post isnât primarily about the new algorithm itself, weâll start by covering the basics of replication. TigerBeetle provides transaction Atomicity, Consistency, Isolation and Durability (ACID). Out of the four letters, the D, Durability, is the most consequential. For, without Durability, there wouldnât be any data at all to provide guarantees for!&lt;/p&gt;
    &lt;p&gt;You can get a decent chunk of durability by writing the data to a (single) hard drive. This works for many non-critical applications, but might still fail if you repeat the procedure often enough. Disks are faulty with non-zero probability, and it is fairly common to lose an entire machine (floods, fires and tripping over the power supply happen). If you really want your data to be durable, better to store several copies of it on different machines, to replicate.&lt;/p&gt;
    &lt;p&gt;All data in TigerBeetle is ultimately derived from an append-only hash-chained log of prepare messages, so the task of replication reduces to distributing the prepares (a MiB each) across the six replicas of the cluster.&lt;/p&gt;
    &lt;p&gt;The primary sends &lt;code&gt;.prepare&lt;/code&gt; messages down to the backups;
they reply &lt;code&gt;.prepare_ok&lt;/code&gt; back up once the prepare is locally
durable. When the primary receives a quorum of
&lt;code&gt;.prepare_ok&lt;/code&gt;s, it knows that the message is globally
durable.&lt;/p&gt;
    &lt;p&gt;The most straightforward way to implement that is for the primary to broadcast the prepare:&lt;/p&gt;
    &lt;p&gt;The problem with this approach is that the primary uses 5x the bandwidth of the backup. In other words, we are going only at 1/5th of the optimal performance. For this reason, our V1 routing used a simple ring topology, where most replicas need to send and receive one message:&lt;/p&gt;
    &lt;p&gt;The ring replication is simple and balances the bandwidth nicely. It served well for the first year of production use, despite some critical issues!&lt;/p&gt;
    &lt;p&gt;First, the fixed ring topology falls prey to one of the eight fallacies of distributed computing. The ring is fully static, and assumes that network topology doesnât change. But this is not true. For example, if one replica crashes or becomes partitioned, it is a good idea to proactively route around it, rather than rely on retries to randomly pick a different replica.&lt;/p&gt;
    &lt;p&gt;Second, the ring doesnât have what I like to call âthereâs no (re)tryâ property. Most messages exchanged in the process of ring replication are critical: if a single message is lost, then the whole chain of replication unravels until the retry timeout kicks in. This means that network errors are visible as elevated P100 latencies (bad), and, when they happen, we have to run rarely-executed retry code (worse!). Such âcold codeâ is the preferred habitat for bugs! Ideally, a system should have built-in redundancy such that any operation completes without tripping timeouts even in the presence of errors.&lt;/p&gt;
    &lt;p&gt;Thus, Adaptive Replication Routing (or, how we affectionately call it, ARR) was born. It combines two ideas. First, while we keep the ring as our replication topology, we place the primary into the middle:&lt;/p&gt;
    &lt;p&gt;The small downside is slightly uneven network load, as the primary sends two messages. The big upside is that none of the messages are critical. If any single message is dropped, the prepare is still going to be replicated to at least half of the cluster, allowing the primary to commit without tripping timeouts (recall that TigerBeetle is using Heidi Howardâs Flexible Quorums, so 3 of 6 as replication quorum is enough for safety because the view change quorum, is 4 of 6, preserving the intersection property).&lt;/p&gt;
    &lt;p&gt;The second trick is that the ring itself is dynamic. At runtime, the cluster picks the order of replicas that minimizes the latency overall. If one replica becomes unreachable, the replicas are reshuffled along the ring to move the missing one to the very end.&lt;/p&gt;
    &lt;p&gt;How do you find the best route? One approach is to build a model of the system. For example, replicas can exchange heartbeat messages, note pairwise latencies, and then solve traveling salesman problem in the resulting small six-node graph to find the most perfect route.&lt;/p&gt;
    &lt;p&gt;This works algorithmically, but relies on a pretty big assumption â that our model of the world is faithful. But imagine, for example, a network with a link with very low latency, but also very low throughput. Using (small) heartbeat messages to measure the link quality would give us a misleading model that breaks down for (much larger) prepares.&lt;/p&gt;
    &lt;p&gt;The problem here isnât this particular case, but the entire class of âout of the distributionâ errors which make any indirect measurement suspect (c.f. Goodhartâs Law). As another example, consider a replica with a very slow disk. Although the &lt;code&gt;ping&lt;/code&gt; time for it is very fast, the replication
is going to be slow, as &lt;code&gt;.prepare_ok&lt;/code&gt; is only sent once the
&lt;code&gt;.prepare&lt;/code&gt; is durably persistent. Pings only measure network
latency, but we also care about storage latency (and throughput).&lt;/p&gt;
    &lt;p&gt;A different approach, inspired laterally by the PCC paper, is to avoid modeling altogether, and instead to just go and do something, and then measure the relevant result directly, Grace Hopper style. This is how ARR works: for every &lt;code&gt;.prepare&lt;/code&gt;, the primary tracks how long did it take to
replicate (via tracking &lt;code&gt;.prepare_ok&lt;/code&gt; messages). Every once
in a while, it runs an experiment, where a prepare follows a different,
experimental route. If that experimental route is measured to
be better than the route we are currently using, the topology is
switched. Over time, the cluster converges to the optimal route.&lt;/p&gt;
    &lt;p&gt;Thatâs ARR in a nutshell: replication topology is a ring with the primary in the middle, where the order of replicas in the ring is adjusted dynamically based on how well each specific permutation performs end-to-end.&lt;/p&gt;
    &lt;p&gt;As promised, this post is not about ARR, so assume that youâve already implemented ARR for TigerBeetle. How would you apply Deterministic Simulation Testing principles to it?&lt;/p&gt;
    &lt;p&gt;One approach is to leverage our existing &lt;del&gt;game&lt;/del&gt; whole-system simulation, VOPR. This actually gets you quite far, but it is always possible to do better.&lt;/p&gt;
    &lt;p&gt;First, whole system simulation might not be as efficient at exercising deeper layers of the system. For every permutation of events affecting the target layer, the simulator also needs to handle all other events above and below. Furthermore, the permutations you get might be restricted by the way the subsystem is used by the larger system. In other words, the routing component might be working correctly if used in the exact same way as in the real database, but it might still have bugs under certain interactions of its public APIs.&lt;/p&gt;
    &lt;p&gt;Second, while checking âit doesnât crashâ is easy enough through the VOPR, asserting that the route is good is much harder. Again, thereâs just too much other stuff happening to focus just on the contribution of routing.&lt;/p&gt;
    &lt;p&gt;Thatâs why the general principle in TigerBeetle is that, in addition to the main whole-system fuzzer, each subsystem should also have a targeted fuzzer, and ARR is no exception.&lt;/p&gt;
    &lt;p&gt;Thereâs a fairly general recipe for how to fuzz a subsystem in isolation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identify all the connections between the target and the rest of the system,&lt;/item&gt;
      &lt;item&gt;abstract the connections behind an interface,&lt;/item&gt;
      &lt;item&gt;supply a stub implementation for fuzzing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With some ingenuity, you can even avoid modifying your source code at all, instead leveraging runtime support to materialize interfaces out of thin air. For example, you can use &lt;code&gt;LD_PRELOAD&lt;/code&gt; tricks to
intercept all libc-mediated syscalls.&lt;/p&gt;
    &lt;p&gt;But thereâs a catch! With a large and intricate interface, it might be challenging to thoroughly explore the state space, especially as the interface itself changes over time (and large and intricate things also mysteriously love to be high-churn as well). For the long term, it pays to start with the minimal possible interface.&lt;/p&gt;
    &lt;p&gt;Did you notice that I tricked you in the first paragraph in this section? You donât first build a system, and then add a fuzzer. The process is almost the reverse â the starting point is sketching minimal interfaces that yield themselves to efficient fuzzing. This is a bit like Test Driven Design, though, not exactly. Thereâs relatively little incrementality and iteration. Instead, fuzzerâs input on architecture is felt at the very beginning, during âsketching on the mental napkinâ phase.&lt;/p&gt;
    &lt;p&gt;Letâs do this for ARR. Again, the idea is that we observe timing information during replication (the delay between sending &lt;code&gt;.prepare&lt;/code&gt; and receiving a set of &lt;code&gt;.prepare_ok&lt;/code&gt;s)
and use that to gradually discover the best possible route, where the
route is a permutation of replicas with the current primary in the
middle.&lt;/p&gt;
    &lt;p&gt;Note how little in the above description is related to TigerBeetle! This is a hint that the routing component can be fully independent! This is the core interface of &lt;code&gt;Routing&lt;/code&gt;
(simplified for the blog, but just a touch):&lt;/p&gt;
    &lt;code&gt;pub fn init(
: struct { replica: u8, replica_count: u8 },
     options
 ) Routing;
pub fn op_prepare(
: *Routing, op: u64, now: Instant) void;
     routing
pub fn op_prepare_ok(
: *Routing, op: u64, now: Instant, replica: u8) void;
     routing
pub fn op_next_hop(routing: *Routing, op: u64) []const u8;

pub fn view_change(routing: *Routing, view: u32) void;&lt;/code&gt;
    &lt;p&gt;To start routing, you need to know how many replicas are there, and which one is you. &lt;code&gt;op_prepare&lt;/code&gt; and &lt;code&gt;op_prepare_ok&lt;/code&gt;
are for tracking timing. The contract is simple: &lt;code&gt;op_prepare&lt;/code&gt;
is called once a &lt;code&gt;.prepare&lt;/code&gt; is ready to be replicated, and
&lt;code&gt;op_prepare_ok&lt;/code&gt; is called for every received
&lt;code&gt;.prepare_ok&lt;/code&gt; response. That is, the happy path is six calls
to &lt;code&gt;op_prepare_ok&lt;/code&gt; for every call to
&lt;code&gt;op_prepare&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;op_next_hop&lt;/code&gt; is the actual routing â it tells which
replicas a freshly received prepare needs to be forwarded to. It might
return zero, one or two replicas.&lt;/p&gt;
    &lt;p&gt;Finally, routing needs to know which replica is the primary. When the primary changes, so do the routes! The primary is uniquely defined by the view, which can be changed via the &lt;code&gt;view_change&lt;/code&gt;
method.&lt;/p&gt;
    &lt;p&gt;Note how minimal this interface is! We are just passing integers around (&lt;code&gt;Instant&lt;/code&gt; is a newtyped &lt;code&gt;u64&lt;/code&gt;. Itâs a
topic for a separate blog post why we newtype &lt;code&gt;Instant&lt;/code&gt; but
not &lt;code&gt;view&lt;/code&gt;â¦). But this is not natural, itâs a result of
deliberate design process!&lt;/p&gt;
    &lt;p&gt;For example, &lt;code&gt;Routing&lt;/code&gt; routes &lt;code&gt;Prepare&lt;/code&gt;s, so it
would be natural to pass in the whole &lt;code&gt;Prepare&lt;/code&gt; structure
with all dependencies on the rest of the VSR framework. It takes intellectual
control to know that &lt;code&gt;Routing&lt;/code&gt; only cares about
&lt;code&gt;Prepare&lt;/code&gt;âs identity, and that op number is a concise
representation of that identity.&lt;/p&gt;
    &lt;p&gt;Handling of time deserves an entire separate article (good thing that we did write that up). The source of time is ultimately a &lt;code&gt;Clock&lt;/code&gt;
instance, so the most natural thing to do would be to inject
&lt;code&gt;Clock&lt;/code&gt; dependency in the constructor. But a momentâs
thinking makes you realize that a fully general clock is unnecessary. We
only care about the time difference between a &lt;code&gt;.prepare&lt;/code&gt; and
the corresponding &lt;code&gt;.prepare_ok&lt;/code&gt;s, which you can get, simply,
by accepting an &lt;code&gt;Instant&lt;/code&gt; â a &lt;code&gt;u64&lt;/code&gt; number of
nanoseconds since an unspecified start of the epoch. This is a
major simplification for fuzzing, as time is notoriously tricky
to model, and here we get it essentially for free.&lt;/p&gt;
    &lt;p&gt;Finally, in order to downsize the interface, &lt;code&gt;view_change&lt;/code&gt;
violates one of the best best practices. It adds the second source of
truth for the view number! The authority about the current view is the
&lt;code&gt;Replica&lt;/code&gt; struct (this
lovely 12k sloc file) with a &lt;code&gt;view: u32&lt;/code&gt; field.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Routing&lt;/code&gt; needs to be aware of the view, and the most
straightforward way to do that is to inject the entire
&lt;code&gt;Replica&lt;/code&gt; in &lt;code&gt;init&lt;/code&gt;, using banana-gorilla-jungle
pattern of Joe Armstrong. The textbook fix would be to abstract âthing
with a &lt;code&gt;get_view&lt;/code&gt; methodâ behind an interface and inject
that. But that indirection makes the code more verbose and
harder to reason about. It also is not enough: not only
&lt;code&gt;Routing&lt;/code&gt; needs to know the current view, it must actively
react to changes in the view! This can be fixed via Observer pattern,
but Observer is notorious for destroying readability of control flow and
bring a host of problems of its own, including complicated lifetime
management, non-deterministic order of execution and potential for
feedback loops.&lt;/p&gt;
    &lt;p&gt;It indeed is much simpler to just let &lt;code&gt;Routing&lt;/code&gt;
have its own private copy of &lt;code&gt;view: u32&lt;/code&gt;. And the risk of
views desynchronizing is easy to mitigate. We already have
&lt;code&gt;invariants&lt;/code&gt; method on the &lt;code&gt;Replica&lt;/code&gt; which is
called frequently to catch various violations, and it can check view
consistency as well:&lt;/p&gt;
    &lt;code&gt;pub fn invariants(self: *const Replica) void {
// ...
     self.view == self.routing.view);
     assert( }&lt;/code&gt;
    &lt;p&gt;You get the idea! The trick to making the code more easily fuzzable is to minimize the interface. You want to get rid of accidental dependencies and leave only the essential ones. And to do that, it helps to apply data-oriented design principles â thinking in terms of input data, output data, and the fundamental data transformation that the system implements.&lt;/p&gt;
    &lt;p&gt;When the primary decides to switch the route after a successful experiment, it needs to communicate the new route to the peers. Itâs a serialization/deserialization task. As there are at most six replicas in the cluster, and a route is a permutation thereof, a route is encoded compactly as an &lt;code&gt;u64&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;pub fn route_encode(routing: *const Routing, route: Route) u64;
pub fn route_decode(routing: *const Routing, code: u64) ?Route;

pub fn route_active(self: *const Replica) Route;
pub fn route_activate(routing: *Routing, route: Route) void;&lt;/code&gt;
    &lt;p&gt;Serialization is a favorite vehicle for explaining property based testing: checking that serializing data and then deserializing it back doesnât lose a bit is an obvious thing to do (&lt;code&gt;deserialize . serialize == id&lt;/code&gt;, if you speak pointfree). So
we can generate a random permutation and assert that it round-trips the
encoding correctly:&lt;/p&gt;
    &lt;code&gt;test route_encode {
var prng = stdx.PRNG.from_seed(std.testing.random_seed);
     const replica_count =
     .range_inclusive(u8, 1, constants.replicas_max);
         prng
// Start with a trivial permutation, then shuffle it.
     var route: Route = .trivial(replica_count);
     .shuffle(u8, &amp;amp;route.replicas);
     prng
const code = route_encode(route);
     const route_decoded = route_decode(code).?;
     
.meta.eql(route, route_decoded));
     assert(std }&lt;/code&gt;
    &lt;p&gt;And hereâs &lt;code&gt;shuffle&lt;/code&gt; for the reference, nothing fancy:&lt;/p&gt;
    &lt;code&gt;pub fn shuffle(prng: *PRNG, T: type, slice: []T) void {
if (slice.len &amp;lt;= 1) return;
     
for (0..slice.len - 1) |i| {
     const j = prng.range_inclusive(u64, i, slice.len - 1);
         .mem.swap(T, &amp;amp;slice[i], &amp;amp;slice[j]);
         std
     } }&lt;/code&gt;
    &lt;p&gt;This already is a decent test, but we can make it even better. There are at most six replicas in a cluster. That means there are &lt;code&gt;1! + 2! + ... + 6!&lt;/code&gt; routes in total we need to
check. This is a tiny number of routes, computer-wise, and we can easily
check them all in no time!&lt;/p&gt;
    &lt;p&gt;The only catch is that writing code to generate all permutations needs somewhat tricky recursion, and then you need to also iterate over number of replicasâ¦ But thereâs a secret cheat code here. This is it:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If you wrote a function that takes a PRNG and generates a random object, you already have a function capable of enumerating all objects.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just imagine how the above function executes, from the perspective of the PRNG. You are constantly being asked to generate random numbers, which are used to shuffle the initial identity permutation. But what if you always return zero? Well, the resulting permutation will be in some sense trivial! And you can get the next permutation if you change the last zero to be one. And then two. And, if, say, the last number you are asked to generate needs to lie between zero and two, then after two you wrap back to zero, but also increment the penultimate number:&lt;/p&gt;
    &lt;code&gt;0 0 0 0 0
0 0 0 0 1
0 0 0 0 2
0 0 0 1 0
0 0 0 1 1&lt;/code&gt;
    &lt;p&gt;If you can generate all sequences of random numbers, you can turn a function generating a random object into a function enumerating all objects! And hereâs how you can generate all random number sequences:&lt;/p&gt;
    &lt;code&gt;: bool = false,
 started: [32]struct { value: u32, bound: u32 } = undefined,
 v: usize = 0,
 p: usize = 0,
 p_max
const Gen = @This();

pub fn done(g: *@This()) bool {
if (!g.started) {
     .started = true;
         greturn false;
         
     }var i = g.p_max;
     while (i &amp;gt; 0) {
     -= 1;
         i if (g.v[i].value &amp;lt; g.v[i].bound) {
         .v[i].value += 1;
             g.p_max = i + 1;
             g.p = 0;
             greturn false;
             
         }
     }return true;
     
 }
fn gen(g: *Gen, bound: u32) u32 {
.p &amp;lt; g.v.len);
     assert(gif (g.p == g.p_max) {
     .v[g.p] = .{ .value = 0, .bound = 0 };
         g.p_max += 1;
         g
     }.p += 1;
     g.v[g.p - 1].bound = bound;
     greturn g.v[g.p - 1].value;
     
 }

/// Public API, get a "random" number in bounds:
pub fn int_inclusive(g: *Gen, Int: type, bound: Int) Int {
return @intCast(g.gen(@intCast(bound)));
      }&lt;/code&gt;
    &lt;p&gt;Makes no sense? For me too! Every time I look at this code, I need to solve the puzzle afresh. Luckily, thereâs a write up: Generate All The Things.&lt;/p&gt;
    &lt;p&gt;The bottom line is that we can just wrap our existing random test into a while loop, and magically get an exhaustive test for all routes:&lt;/p&gt;
    &lt;code&gt;test route_encode {
var prng: Gen = .{};
     while (!prng.done()) {
     const replica_count =
         .range_inclusive(u8, 1, constants.replicas_max);
             prng
// Start with a trivial permutation, then shuffle it.
         var route: Route = .trivial(replica_count);
         .shuffle(u8, &amp;amp;route.replicas);
         prng
const code = route_encode(route);
         const route_decoded = route_decode(code).?;
         
.meta.eql(route, route_decoded));
         assert(std
     } }&lt;/code&gt;
    &lt;p&gt;Thatâs it! Testing every &lt;code&gt;replica_count&lt;/code&gt;, and
every permutation of replicas!&lt;/p&gt;
    &lt;p&gt;This is our first fuzzer â we test serialization by encoding and decoding a random route. We also notice that the total amount of routes is small, and adapt our random code to exhaustively cover the entire positive space, using a rigged PRNG.&lt;/p&gt;
    &lt;p&gt;Testing only positive space is a common pitfall. We want to check serialization and deserialization for routes. We do that by round-tripping the route. We even make sure to check every possible route, how can there be anything else left to test here?&lt;/p&gt;
    &lt;p&gt;This is an example of a positive space thinking, which sometimes gives us false confidence that everything is thoroughly tested, while we are failing to consider some cases off the happy path.&lt;/p&gt;
    &lt;p&gt;What we missed here is that not every code necessarily encodes a valid route. We only feed âvalidâ data to deserialization routine, but who knows what bytes you can receive through the TCP socket?&lt;/p&gt;
    &lt;p&gt;Now, this is tricky: actually, TigerBeetle only talks to other TigerBeetle replicas, and all communication is protected by a strong checksum. So it is actually correct to assume that the encoding is valid, modulo bugs. But there might be bugs! And, if thereâs a bug somewhere which manifests itself as an invalid encoding, we want to detect that and crash loudly, rather than silently misinterpret valid data.&lt;/p&gt;
    &lt;p&gt;Thatâs why the decode function returns a nullable &lt;code&gt;Route&lt;/code&gt;â¦&lt;/p&gt;
    &lt;code&gt;pub fn route_decode(routing: *const Routing, code: u64) ?Route;&lt;/code&gt;
    &lt;p&gt;but at the call-site the &lt;code&gt;Route&lt;/code&gt; is unwrapped:&lt;/p&gt;
    &lt;code&gt;const route = self.routing.route_decode(message.header.route).?;&lt;/code&gt;
    &lt;p&gt;This is offensive programming, we want to force bugs to jump into the spotlight, and not to lie hidden on odd cold paths.&lt;/p&gt;
    &lt;p&gt;The most straightforward way to test the negative space here is to run our test backwards, and to try deserialize and then serialize a random code:&lt;/p&gt;
    &lt;code&gt;test route_decode {
var prng = stdx.PRNG.from_seed(std.testing.random_seed);
     
const code = prng.int(u64);
     if (route_decode(code)) |route| {
     const code_encoded = route_encode(route);
         == code_encoded);
         assert(code else {
     } // Just make sure we don't crash!
         
     } }&lt;/code&gt;
    &lt;p&gt;Thereâs a subtle problem with a test above â the âthenâ branch of the if is dead code, and weâll never get there, even if we repeat the test a hundred million times:&lt;/p&gt;
    &lt;code&gt;test route_decode {
var prng = stdx.PRNG.from_seed(std.testing.random_seed);
     
for (0..100_000_000) |_| {
     const code = prng.int(u64);
         if (route_decode(code)) |_| {
         false);
             assert(else {
         } // Just make sure we don't crash!
             
         }
     } }&lt;/code&gt;
    &lt;code&gt;$ t ./zig/zig build test --release -- route_decode

real 7.14s
cpu  7.16s (7.08s user + 76.41ms sys)
rss  34.97mb&lt;/code&gt;
    &lt;p&gt;Our completely random encoding never manages to generate a valid code!&lt;/p&gt;
    &lt;p&gt;As we have seen above, there are very few different routes, and, therefore, very few valid encodings. But our code is &lt;code&gt;u64&lt;/code&gt;.
The space of all possible codes is huge, but the subspace of all
valid codes is very sparse.&lt;/p&gt;
    &lt;p&gt;Is this a problem? We checked all valid codes, so itâs fine if we only look at the invalid ones? No! Given just how rarefied our encoding space is, purely random codes are going to be obviously invalid. The decoding routine will reject them very quickly, and we are likely to not exercise most of the logic there.&lt;/p&gt;
    &lt;p&gt;For effective fuzzing, you want to test the boundary: you want to check a valid code, and a code which is almost the same, but invalid.&lt;/p&gt;
    &lt;p&gt;For that, we bias our generator to prefer codes in the neighborhood of valid encodings:&lt;/p&gt;
    &lt;code&gt;var code_bytes: [8]u8 = @splat(0);
for (&amp;amp;code_bytes) |*byte| {
.* = if (prng.chance(ratio(replica_count + 1, 8)))
     byte.int_inclusive(u8, constants.replicas_max + 1)
         prngelse
     0xFF;
         
 }var code: u64 = @bitCast(code_bytes);

if (prng.chance(ratio(1, 20))) {
^= prng.bit(u64);
     code 
 }if (prng.chance(ratio(1, 20))) {
= prng.int(u64);
     code  }&lt;/code&gt;
    &lt;p&gt;The encoding is literally a permutation of replica indexes, where each replica index is a byte, padded by &lt;code&gt;0xFF&lt;/code&gt; bytes to
&lt;code&gt;u64&lt;/code&gt;. We generate a random mish-mash of those bytes (which
just might generate a valid code), then, to spice thing up, we
randomly corrupt a single bit of code. Finally, to make sure we donât
just generate almost valid code, sometimes we throw everything
away and fall back to fully random.&lt;/p&gt;
    &lt;p&gt;This sounds plausible, but is this actually true? Do we actually hit the boundary here, generate both valid and invalid codes? And how do we make sure that our negative-space fuzzer continues to test interesting cases as the code itself evolves (it certainly looks like we can optimize the encoding to be more compactâ¦)?&lt;/p&gt;
    &lt;p&gt;A good pattern here is to repeat the test many times, counting all the sad and happy cases, and assert that they are reasonable:&lt;/p&gt;
    &lt;code&gt;test route_decode {
const Counts =
     struct { total: u32, valid: u32, invalid: u32 };
         
var prng = stdx.PRNG.from_seed(std.testing.random_seed);
     
var counts: Counts =
     .{ .total = 200_000, .valid = 0, .invalid = 0 };
         
for (0..counts.total) |_| {
     //...
         if (route_decode(code)) |_| {
         .valid += 1;
             counts//...
             else {
         } .invalid += 1;
             counts
         }
     }
.total == counts.valid + counts.invalid);
     assert(counts.valid &amp;gt; 50);
     assert(counts.invalid &amp;gt; 100_000);
     assert(counts }&lt;/code&gt;
    &lt;p&gt;Due to randomness, we canât check the exact values of counters, but we can assert that most of the encodings are invalid, and that at least some are valid (remember, our initial test generated zero valid encodings out of 100 000 000 attempts).&lt;/p&gt;
    &lt;p&gt;This brings me to another topic I want to cover â treatment of determinism in tests. âThy tests shall be deterministicâ is a reasonable commandment, but not an absolute one. I see that often people try to avoid randomness in tests at all costs, and always initialize PRNG with a hard-coded seed of 42. I donât like that, for two reasons.&lt;/p&gt;
    &lt;p&gt;The practical reason is that, over its lifetime, the test is going to be re-run many thousand times over, and it is wasteful to not take advantage of that to explore more of the state space eventually, while keeping each individual test run very fast.&lt;/p&gt;
    &lt;p&gt;The purity reason is that, if there exists a seed value that makes the test fail, the test (or the code) is buggy and needs to be fixed! Sure, itâs unfortunate if you discover that bug while working on an unrelated change, but it is less unfortunate than not knowing about the bug at all!&lt;/p&gt;
    &lt;p&gt;However, just using genuinely random seeds for tests is pretty bad:&lt;/p&gt;
    &lt;code&gt;test route_decode {
const seed = std.crypto.random.int(u64);
      }&lt;/code&gt;
    &lt;p&gt;The problem with the above is that, when a test fails, you donât know the seed! And, if it is one-in-a-million failure, it can be very a frustrating experience to reproduce it. This can be helped by printing the seed on failure, but that A) requires writing more code per test and, B) doesnât work if the failure is not graceful. Imagine getting a mystery segfault on some random CI run, and then not being able to reproduce it because the process dies before the seed is printed!&lt;/p&gt;
    &lt;p&gt;Zig I think has the best design in this space. It provides you with the &lt;code&gt;std.testing.random_seed&lt;/code&gt; value, which is a ready-to-use
random seed that is different per run. Crucially, the seed is generated
outside of the test process itself and is passed to it on the CLI. It
doesnât matter what happens with the test process. It can explode
completely, but the parent process will still print the seed on failure.
Conveniently, the seed is printed as a part of a CLI invocation which
you can immediately paste into your shell!&lt;/p&gt;
    &lt;code&gt;$ ./zig/zig build test

test
+- run test-vsr failure
thread 2285 panic: reached unreachable code
...
error: while executing test 'vsr.test.routing.route_decode'
error: the following command terminated with signal 6:

.zig-cache/o/14db484/test-vsr --seed=0x737929ed&lt;/code&gt;
    &lt;p&gt;So thatâs why weâve been using &lt;code&gt;PRNG.from_seed(testing.random_seed)&lt;/code&gt; throughout! And it has
been working perfectly, up until now. Hereâs the problem:&lt;/p&gt;
    &lt;code&gt;var prng = stdx.PRNG.from_seed(std.testing.random_seed);

//...

.total == counts.valid + counts.invalid);
 assert(counts.valid &amp;gt; 50);
 assert(counts.invalid &amp;gt; 100_000); assert(counts&lt;/code&gt;
    &lt;p&gt;The seed is random, so, sooner or later, our assert will fire. We can make the probability of that negligible by increasing &lt;code&gt;total&lt;/code&gt; and increasing our tolerance, but that is
unsatisfactory. Larger iteration count slows down each individual test
run. And relaxing asserts tells us less about the average case,
what we actually care about. And we donât know whatâs the actual
probability of hitting the assert! It might be that the actual
probability is small, but not infinitesimal, such that youâll be
debugging a random âfailureâ five years from now! One in a
billion events do happen in CI!&lt;/p&gt;
    &lt;p&gt;A nice pattern here is to run the test twice: once with a hard-coded seed to capture the âaverageâ distribution and assert statistics, and once with a truly random seed for coverage:&lt;/p&gt;
    &lt;code&gt;test route_decode {
const T = struct {
     const Counts =
         struct { total: u32, valid: u32, invalid: u32 };
             
fn check(seed: u64) Counts {
         // ...
             
         }
     };
const counts = T.check(92);
     .total == counts.valid + counts.invalid);
     assert(counts.valid &amp;gt; 50);
     assert(counts.invalid &amp;gt; 100_000);
     assert(counts
= T.check(std.testing.random_seed);
     _  }&lt;/code&gt;
    &lt;p&gt;This is our second fuzzer â testing for negative space by probing obviously invalid values, and then specifically values that cross the valid/invalid boundary, while collecting and asserting coverage information.&lt;/p&gt;
    &lt;p&gt;For this particular scenario, it wouldâve been better to use a real coverage-guided fuzzer like libFuzzer, but, at the time of writing, Zig is only at the start of its fuzzing journey. It already has &lt;code&gt;std.testing.fuzz&lt;/code&gt;, but I wasnât able to get that working on
my machine. Anyway the implementation of the fuzzer is a detail. What
matters is the principle of explicit testing of negative space, the
boundary space, and verifying that both ins and outs get tested!&lt;/p&gt;
    &lt;p&gt;Moreover, just like we got exhaustive test by driving PRNG interface via exhaustive enumeration from inside, we can drive a PRNG through a fuzzer. You can combine the best of both worlds: highly structured complex inputs of property based testing and introspective guided program state exploration of coverage-guided fuzzers. This again is worth a separate blog post, but I really need to do more research before it is ready. However, Iâll be sharing what I got so far on 1000x world tour on December 3 in Lisbon next week. Come, say hello if you are around: https://luma.com/7d47f4et!&lt;/p&gt;
    &lt;p&gt;Ok, the warmup is over! Serialization was a simple and boring part of Adaptive Replication Routing. Letâs tackle the actual logic. Similarly, weâll start with a positive space, checking that ARR indeed converges to the best route in a scenario approximating what we expect to see in the real world.&lt;/p&gt;
    &lt;p&gt;This is going to be interesting, because it is not a local correctness property. We want to check that six instances of ARR on six different physical machines work in concert, such that, e.g., everyone agrees which operations are experiments, and what is the route of each experiment.&lt;/p&gt;
    &lt;p&gt;Hereâs the plan. We arrange six replicas into a virtual ring, such that the network delay between replicas is proportional to the distance along the ring. The order of replicas is random, and correctly implemented ARR must be able to âunscrambleâ the permutation in the end. Each âreplicaâ is just a &lt;code&gt;Routing&lt;/code&gt; instance. This is the
entire idea behind &lt;del&gt;The Matrix&lt;/del&gt; focused fuzzing, we donât need to simulate anything else!&lt;/p&gt;
    &lt;code&gt;const T = struct {
: u8,
     replica_count: []u8,
     permutation
: u32,
     view: u8,
     primary: u8,
     prepare_ok_count
: []Routing,
     replicas
const T = @This();
     
pub fn init(gpa: Allocator, seed: u64) T { ... }
     
pub fn deinit(t: *T, gpa: Allocator) void { ... }
     
fn ring_index(t: *const T, replica: u8) i8 {
     return @intCast(t.permutation[replica]);
         
     }
fn distance(t: *const T, a: u8, b: u8) u8 {
     const a2b = @abs(t.ring_index(b) - t.ring_index(a));
         const b2a = t.replica_count - a2b;
         return @min(a2b, b2a);
         
     } };&lt;/code&gt;
    &lt;p&gt;An optimal route enumerates replicas in the order of &lt;code&gt;permutation&lt;/code&gt; in either of two directions (there are two
optimal routes!). We can check that by summing up pairwise
distances:&lt;/p&gt;
    &lt;code&gt;fn route_total_distance(t: *const T, route: Route) u8 {
var result: u8 = 0;
     for (
     .replicas[0 .. t.replica_count - 1],
         route.replicas[1..t.replica_count],
         route|a, b| {
     ) += t.distance(a, b);
         result 
     }return result;
     
 }
fn route_optimal(t: *const T, route: Route) bool {
return t.total_route_distance(route) == t.replica_count - 1;
      }&lt;/code&gt;
    &lt;p&gt;The overall flow of the fuzzer is as follows. We send prepares one by one. For each prepare, we run the simulation until the primary collects &lt;code&gt;prepare_ok&lt;/code&gt; messages from everybody.
&lt;code&gt;prepare_ok_count&lt;/code&gt; field tells us when we should start with
the next prepare. Submitting a prepare is modeled via sending a message
to the primary. When a set number of prepares is dealt with, we check
that the final route is optimal.&lt;/p&gt;
    &lt;p&gt;Note that this is not how the real replication works, reality is pipelined, and multiple prepares are in flight at the same time. However, the purpose of this particular fuzzer isnât to check a ârealisticâ scenario, the purpose is to check the idealized scenario, but be very strict in the acceptance criteria (that the route really is optimal).&lt;/p&gt;
    &lt;p&gt;The full code is a bit too much for this article, but the core logic of simulating replication process is this &lt;code&gt;message_delivered&lt;/code&gt;
function. It models what happens when replica &lt;code&gt;target&lt;/code&gt;
receives a &lt;code&gt;message&lt;/code&gt; from &lt;code&gt;source&lt;/code&gt;. Which is,
forward the message along the ring, and reply with
&lt;code&gt;.prepare_ok&lt;/code&gt; to the primary.&lt;/p&gt;
    &lt;code&gt;fn message_delivered(
: *T,
     t: u8,
     source: u8,
     target: union(enum) { prepare: u64, prepare_ok: u64 },
     messagevoid {
 ) switch (message) {
     .prepare =&amp;gt; |op| {
         // The initial prepare is injected by the fuzzer.
             if (target == t.primary) {
             == t.primary);
                 assert(source .prepare_ok_count == 0);
                 assert(t.replicas[t.primary].op_prepare(op, t.now());
                 t
             }
// Inform the primary that we got the prepare.
             .send(.{
             t.source = target,
                 .target = t.primary,
                 .message = .{ .prepare_ok = op },
                 
             });
// Forward prepare along the current replication ring.
             for (t.replicas[target].op_next_hop(op)) |target_next| {
             &amp;lt; t.replica_count);
                 assert(target_next .send(.{
                 t.source = target,
                     .target = target_next,
                     .message = .{ .prepare = op },
                     
                 });
             },
         }
.prepare_ok =&amp;gt; |op| {
         == t.primary);
             assert(target .prepare_ok_count += 1;
             t.replicas[t.primary].op_prepare_ok(op, t.now(), source);
             t,
         }
     } }&lt;/code&gt;
    &lt;p&gt;Whatâs fascinating about this fuzzer is not the implementation, but rather the bugs it was able to find. Writing the fuzzer was a relatively mechanical and mindless process, other than the initial idea of modeling a physical ring of replicas. But the two failures it found revealed my misunderstanding of the problem, and forced me to apply deeper thinking where I thought I understood everything.&lt;/p&gt;
    &lt;p&gt;To explain that, I need to talk about the ARR cost function. After an ARR experiment, the primary somehow needs to measure the quality of a the experimental route. The data we have are &lt;code&gt;.prepare_ok&lt;/code&gt; latencies for all replicas â a vector of six
integers.&lt;/p&gt;
    &lt;p&gt;My initial cost function was a pair of the median and the maximum value of the vector, with some fuzz factor:&lt;/p&gt;
    &lt;code&gt;.of(.{
 Cost.ms(31), .ms(178), .ms(148),
     .ms(92), .ms(144), .ms(50),
     ==
 }) .{ .median = .ms(92), .maximum = .ms(178) }     &lt;/code&gt;
    &lt;p&gt;The median tracks the moment in time when a half of the cluster acknowledged the prepare, which, due to flexible quorums, is the moment where it is safe to commit prepare. The median replication time is a proxy for user-visible latency, and it is the primary number we are optimizing for.&lt;/p&gt;
    &lt;p&gt;After we replied to the user, we still want to replicate the prepare to the rest of the cluster, to maximize durability. The maximum replication time directly tracks full replication, and itâs the second most important metric to optimize.&lt;/p&gt;
    &lt;p&gt;Finally, we donât want the cluster to oscillate between two nearly identical routes simply due to random delay noise, so we also add a fuzz factor and consider close enough numbers to be equal for comparison purposes.&lt;/p&gt;
    &lt;p&gt;Can you see the bug here? I didnât, but the fuzzer I wrote did. After running for a short time, the fuzzer found the case where ARR failed to converge to the optimal path. Hereâs the path that that run ended up with:&lt;/p&gt;
    &lt;p&gt;This is indeed an optimal path in terms of median,maximum cost function. The median is two hops, the maximum is three. But it is not actually optimal, because replicas between median and maximum take longer time to replicate, and we care about that as well, as thatâs a proxy for us selecting the most efficient route for each replica. It doesnât affect important latencies, but it still sends the electrons further away than theyâd otherwise need to go.&lt;/p&gt;
    &lt;p&gt;The fix is easy â add a third component to the cost function, the sum of all latencies.&lt;/p&gt;
    &lt;p&gt;The problem was fixed, but, after a few iterations more, I got another example that failed to converge to an optimal route. It took me an embarrassingly long time to debug that, but the explanation was really simple. My fuzz factor was too fuzzy, and made two different routes look the same. This fix also was simple, just tighten up the âalmost equalâ condition.&lt;/p&gt;
    &lt;p&gt;But what bugged me is that, in my mental model, the old fuzz factor was fuzzy enough as is. So I tried to explain why it didnât work, and realized that I had a completely wrong mental image of replication routes. And, yes, all the illustrations Iâve drawn so far also have this bug. Do you see it?&lt;/p&gt;
    &lt;p&gt;This is what the actual replication route looks like:&lt;/p&gt;
    &lt;p&gt;Prepares flow forward along the ring, but acknowledgements always flow directly to the primary, in a star topology. When the primary measures the replication latency, it captures both the time to send the &lt;code&gt;.prepare&lt;/code&gt; forward and the time to get the
corresponding &lt;code&gt;.prepare_ok&lt;/code&gt; back. And the time to receive all
&lt;code&gt;.prepare_ok&lt;/code&gt; is independent of the route!&lt;/p&gt;
    &lt;p&gt;In other words, changing the route can affect only half of the observed latencies, which makes relative difference between the routes smaller, and justifies tighter tolerances.&lt;/p&gt;
    &lt;p&gt;This was a huge shift in the mental model for me! I didnât realize that we only observe latencies through the glass, darkly! I hadnât thought about that myself, but the fuzzer did!&lt;/p&gt;
    &lt;p&gt;This is our third fuzzer. It is a whole subsystem positive space fuzzer. Itâs actually an exuberantly optimistic fuzzer, as it sets up an ideal lab environment with extremely predictable network latencies. While not realistic, this setup ensures that thereâs a clear answer to the question of which route is the best, and that allows us to verify that the algorithm is exactly correct, and not merely crash free. This is the catch â in the real system with faults and variants, the notion of optimal route is ill-defined and constantly changes. The acceptance criteria has to be fuzzy in a realistic simulation, but can be very strict in the lab.&lt;/p&gt;
    &lt;p&gt;Finally, the fourth fuzzer. You might guess it, weâll go for negative space this time. We no longer care about how the Routing should be used by the replica, we are trying to break it.&lt;/p&gt;
    &lt;p&gt;The fundamental difference here is that, for positive space, we modeled all six âreplicasâ at the same time messages flowing between them. But any model of that sort necessarily restricts us to executions possible in the cluster. Now we wonât be trying to model anything in particular. Weâll have just a single instance of &lt;code&gt;Routing&lt;/code&gt;
and will be calling all public methods in random order, only obeying the
documented invariants:&lt;/p&gt;
    &lt;code&gt;// Simulate the entire cluster:
const PositiveSpace = struct {
: []Routing,
     replicas// ...
     
 };
// Hammer a single replica, hard:
const NegativeSpace = struct {
: Routing,
     replica// ...
      };&lt;/code&gt;
    &lt;p&gt;There isnât much we can check here, but we can check something. At minimum, we should never crash. Additionally, we can check that whatever route we have, it âconnectsâ. That is, if we follow the chain of &lt;code&gt;next_hop&lt;/code&gt;s, weâll visit each replica
exactly once.&lt;/p&gt;
    &lt;p&gt;The code isnât particularly illuminating here, but the overall shape looks similar to the technique described in the Swarm Testing Data Structures.&lt;/p&gt;
    &lt;p&gt;Thatâs it for today! This was a tale of four fuzzers!&lt;/p&gt;
    &lt;p&gt;Yeahâ¦ At Fuzzer #3, I realized that we actually wrote five fuzzers for ARR, but the title and the Dickens quote had really grown on me by that time. Sorry for this, hereâs a bonus fuzzer for you!&lt;/p&gt;
    &lt;p&gt;Our positive space ARR fuzzer explores a really specific network topology, which is roughly as far from a realistic scenario as the negative space fuzzer, but in the opposite direction â everythingâs too good, no oneâs crashing, the network gives stable latencies.&lt;/p&gt;
    &lt;p&gt;What we are missing is the realistic fuzzer between the two extremes. A fuzzer that runs in a somewhat flaky network, and checks that the route is roughly optimal (or at least not bad). But that is the VOPR! As a whole system fuzzer, it is capable of simulating somewhat realistic distributions of network faults and delays.&lt;/p&gt;
    &lt;p&gt;Historically, VOPR was biased towards faulting as much things as hard as possible, as we want TigerBeetle to be correct and fast, in that order. Now that we started optimization work, we implemented &lt;code&gt;--performance&lt;/code&gt; mode for VOPR.&lt;/p&gt;
    &lt;p&gt;In the default mode, VOPR uses swarm testing to generate distribution of faults (during fuzzing, you generate random events. The idea of swarm testing is to also generate the distribution itself at random). In the performance mode, fault parameters are fixed to ârealisticâ values, and the drastic faults (replicas crashing or becoming partitioned) are strictly controlled (e.g., you can request exactly one crash per run):&lt;/p&gt;
    &lt;code&gt;fn options_swarm(prng: *stdx.PRNG) Simulator.Options
fn options_performance() Simulator.Options&lt;/code&gt;
    &lt;p&gt;Furthermore, in performance mode VOPR tracks statistics about the number of network messages exchanged. ARR was verified by running different performance VOPR scenarios with and without ARR, and checking that ARR is an improvement across the board:&lt;/p&gt;
    &lt;code&gt;Î» ./zig/zig build vopr -- --performance --replica-missing=2

          SEED=1044607978391563277

          replicas=6
          clients=4
          one_way_delay_mean=50ms ticks
          one_way_delay_min=0ns ticks
          packet_loss_probability=0
          path_maximum_capacity=10 messages
          packet_replay_probability=0
          crash_probability=0
          crash_stability=500 ticks
          restart_probability=0
          ...

Messages:
prepare                     1881    1.23MiB
prepare_ok                  1575  393.75KiB
request_prepare              795  198.75KiB
request                      730  510.08KiB
ping                         550  275.00KiB
reply                        503  363.76KiB
request_headers              466  116.50KiB
pong                         440  110.00KiB
headers                      328  320.75KiB
commit                       285   71.25KiB
start_view                    85  224.25KiB
do_view_change                25   12.50KiB
request_start_view            10    2.50KiB
total                       7673    3.77MiB


          PASSED (1741 ticks)&lt;/code&gt;
    &lt;p&gt;Itâs a bit hard to turn these manual experiments into tests that fail only if there are bugs (and not due to randomness or unrelated code choices), but just tinkering with the setup is a great way to quickly test ideas. VOPR runs much faster than a real-world cluster would, so you can use it to collect a fairly long performance trace.&lt;/p&gt;
    &lt;p&gt;This was a long one, wasnât it? Although itâs just one system and five fuzzers, no two fuzzers are alike, each illuminates its own corner of the design space. If you want a closer looks, hereâs the source code, itâs almost exactly a thousand lines for the implementation plus the fuzzers.&lt;/p&gt;
    &lt;p&gt;To jolt the ideas back into the short term (and, who knows, maybe a long term) memory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You want both a whole system fuzzer AND subsystem (minor) fuzzers. Main fuzzer works out the seams between components, while minor fuzzers divide&amp;amp;conquerer the resulting combinatorial explosion.&lt;/item&gt;
      &lt;item&gt;Good fuzzing is tantamount to good interfaces.&lt;/item&gt;
      &lt;item&gt;Interfaces can be extracted mechanically, by introducing indirection whenever a dependency happens.&lt;/item&gt;
      &lt;item&gt;But such a mechanical interface extraction risks ossifying accidental dependencies.&lt;/item&gt;
      &lt;item&gt;Long-term more efficient approach is to think in terms of fundamental input and output data. Sometimes a little copying is better than a little dependency!&lt;/item&gt;
      &lt;item&gt;Data interfaces tend to be non-incremental. The best time to capture an interface is before the first line of code is written.&lt;/item&gt;
      &lt;item&gt;Fuzz positive space and negative space.&lt;/item&gt;
      &lt;item&gt;Given a PRNG interface, its easy to explore structured search space.&lt;/item&gt;
      &lt;item&gt;If the search space is small, you can use the same PRNG interface to walk it thoroughly and exhaustively.&lt;/item&gt;
      &lt;item&gt;And you can plug the same PRNG interface into coverage guided fuzzer.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;deserialize . serialize&lt;/code&gt;is positive space,&lt;code&gt;serialize . deserialize&lt;/code&gt;can be negative space.&lt;/item&gt;
      &lt;item&gt;Hard to breath in rarefied air! Purely random inputs can be uniformly boring and bounce off the edges of the system.&lt;/item&gt;
      &lt;item&gt;For negative space testing, you want to hew close to the valid/invalid boundary, poking out from both sides.&lt;/item&gt;
      &lt;item&gt;You still want some amount of purely random inputs, just in case.&lt;/item&gt;
      &lt;item&gt;You want to assert that both positive and negative cases actually happen with non-negligible probability.&lt;/item&gt;
      &lt;item&gt;Run fuzzer once with a fixed seed (I use &lt;code&gt;92&lt;/code&gt;), to sanity check the count of good and bad cases.&lt;/item&gt;
      &lt;item&gt;Run fuzzer again with a genuinely random seed to accumulate coverage over time.&lt;/item&gt;
      &lt;item&gt;Make sure to generate the seed outside of the test process itself, lest it gets lost during crash.&lt;/item&gt;
      &lt;item&gt;Mind the time! You want to make each individual CI run as quick as possible, while racking up the total fuzzing time over multiple runs.&lt;/item&gt;
      &lt;item&gt;Another quick and dirty way to check fuzzer coverage is adding &lt;code&gt;unreachable&lt;/code&gt;to various branches and check seeing if it crashes.&lt;/item&gt;
      &lt;item&gt;Fuzzers can test fairly sophisticated invariants (e.g., optimality of the routing), but that might require setting up a particularly favorable environment.&lt;/item&gt;
      &lt;item&gt;Writing a fuzzer is mostly boring mechanical work. However, not only fuzzers do find bugs, some bugs lead to large, fundamental mental shifts, and a deeper understanding of the domain!&lt;/item&gt;
      &lt;item&gt;Donât write fuzzers to find bugs in the code, write fuzzers to find bugs in your understanding of the problem.&lt;/item&gt;
      &lt;item&gt;Positive space fuzzing tries to be realistic, negative space fuzzing tries to be un-realistic.&lt;/item&gt;
      &lt;item&gt;Simulate a real cluster for the positive space, simulate a single peer in a radioactive room for the negative space.&lt;/item&gt;
      &lt;item&gt;It might be hard to get intricate, flake-free assertions from the whole system fuzzer.&lt;/item&gt;
      &lt;item&gt;But whole-system fuzzer is still invaluable as an exploration tool.&lt;/item&gt;
      &lt;item&gt;You can fuzz for performance, at least on the high level protocol level (# messages exchanged).&lt;/item&gt;
      &lt;item&gt;Come to TigerBeetle 1000X to Lisbon (or the city nearest to you): https://tigerbeetle.com/event/1000x&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AtÃ© jÃ¡!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tigerbeetle.com/blog/2025-11-28-tale-of-four-fuzzers/"/><published>2025-11-28T12:11:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46078138</id><title>A Remarkable Assertion from A16Z</title><updated>2025-11-28T17:09:05.734432+00:00</updated><content/><link href="https://nealstephenson.substack.com/p/a-remarkable-assertion-from-a16z"/><published>2025-11-28T12:41:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46078566</id><title>Writing Builds Resilience in Everyday Challenges by Changing Your Brain</title><updated>2025-11-28T17:09:05.031810+00:00</updated><content>&lt;doc fingerprint="af49d53faba1a88c"&gt;
  &lt;main&gt;
    &lt;p&gt;Ordinary and universal, the act of writing changes the brain. From dashing off a heated text message to composing an op-ed, writing allows you to, at once, name your pain and create distance from it. Writing can shift your mental state from overwhelm and despair to grounded clarity — a shift that reflects resilience.&lt;/p&gt;
    &lt;p&gt;Psychology, the media and the wellness industry shape public perceptions of resilience: Social scientists study it, journalists celebrate it, and wellness brands sell it.&lt;/p&gt;
    &lt;p&gt;They all tell a similar story: Resilience is an individual quality that people can strengthen with effort. The American Psychological Association defines resilience as an ongoing process of personal growth through life’s challenges. News headlines routinely praise individuals who refuse to give up or find silver linings in times of hardship. The wellness industry promotes relentless self-improvement as the path to resilience.&lt;/p&gt;
    &lt;p&gt;Also Read: Who Looks Smarter: The Quick Thinker or the Careful Thinker?&lt;/p&gt;
    &lt;p&gt;In my work as a professor of writing studies, I research how people use writing to navigate trauma and practice resilience. I have witnessed thousands of students turn to the written word to work through emotions and find a sense of belonging. Their writing habits suggest that writing fosters resilience. Insights from psychology and neuroscience can help explain how.&lt;/p&gt;
    &lt;head rend="h2"&gt;Writing rewires the brain&lt;/head&gt;
    &lt;p&gt;In the 1980s, psychologist James Pennebaker developed a therapeutic technique called expressive writing to help patients process trauma and psychological challenges. With this technique, continuously journaling about something painful helps create mental distance from the experience and eases its cognitive load.&lt;/p&gt;
    &lt;p&gt;In other words, externalizing emotional distress through writing fosters safety. Expressive writing turns pain into a metaphorical book on a shelf, ready to be reopened with intention. It signals the brain, “You don’t need to carry this anymore.”&lt;/p&gt;
    &lt;p&gt;Translating emotions and thoughts into words on paper is a complex mental task. It involves retrieving memories and planning what to do with them, engaging brain areas associated with memory and decision-making. It also involves putting those memories into language, activating the brain’s visual and motor systems.&lt;/p&gt;
    &lt;p&gt;Writing things down supports memory consolidation — the brain’s conversion of short-term memories into long-term ones. The process of integration makes it possible for people to reframe painful experiences and manage their emotions. In essence, writing can help free the mind to be in the here and now.&lt;/p&gt;
    &lt;head rend="h2"&gt;Taking action through writing&lt;/head&gt;
    &lt;p&gt;The state of presence that writing can elicit is not just an abstract feeling; it reflects complex activity in the nervous system.&lt;/p&gt;
    &lt;p&gt;Brain imaging studies show that putting feelings into words helps regulate emotions. Labeling emotions — whether through expletives and emojis or carefully chosen words — has multiple benefits. It calms the amygdala, a cluster of neurons that detects threat and triggers the fear response: fight, flight, freeze or fawn. It also engages the prefrontal cortex, a part of the brain that supports goal-setting and problem-solving.&lt;/p&gt;
    &lt;p&gt;In other words, the simple act of naming your emotions can help you shift from reaction to response. Instead of identifying with your feelings and mistaking them for facts, writing can help you simply become aware of what’s arising and prepare for deliberate action.&lt;/p&gt;
    &lt;p&gt;Even mundane writing tasks like making a to-do list stimulate parts of the brain involved in reasoning and decision-making, helping you regain focus.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making meaning through writing&lt;/head&gt;
    &lt;p&gt;Choosing to write is also choosing to make meaning. Studies suggest that having a sense of agency is both a prerequisite for, and an outcome of, writing.&lt;/p&gt;
    &lt;p&gt;Researchers have long documented how writing is a cognitive activity — one that people use to communicate, yes, but also to understand the human experience. As many in the field of writing studies recognize, writing is a form of thinking — a practice that people never stop learning. With that, writing has the potential to continually reshape the mind. Writing not only expresses but actively creates identity.&lt;/p&gt;
    &lt;p&gt;Writing also regulates your psychological state. And the words you write are themselves proof of regulation — the evidence of resilience.&lt;/p&gt;
    &lt;p&gt;Also Read: Study of 3 Million Finnish Adults Finds Non-Voters Tend to Die Earlier&lt;/p&gt;
    &lt;p&gt;Popular coverage of human resilience often presents it as extraordinary endurance. News coverage of natural disasters implies that the more severe the trauma, the greater the personal growth. Pop psychology often equates resilience with unwavering optimism. Such representations can obscure ordinary forms of adaptation. Strategies people already use to cope with everyday life — from rage-texting to drafting a resignation letter — signify transformation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Building resilience through writing&lt;/head&gt;
    &lt;p&gt;These research-backed tips can help you develop a writing practice conducive to resilience:&lt;/p&gt;
    &lt;p&gt;1. Write by hand whenever possible. In contrast to typing or tapping on a device, handwriting requires greater cognitive coordination. It slows your thinking, allowing you to process information, form connections and make meaning.&lt;/p&gt;
    &lt;p&gt;2. Write daily. Start small and make it regular. Even jotting brief notes about your day — what happened, what you’re feeling, what you’re planning or intending — can help you get thoughts out of your head and ease rumination.&lt;/p&gt;
    &lt;p&gt;3. Write before reacting. When strong feelings surge, write them down first. Keep a notebook within reach and make it a habit to write it before you say it. Doing so can support reflective thinking, helping you act with purpose and clarity.&lt;/p&gt;
    &lt;p&gt;4. Write a letter you never send. Don’t just write down your feelings — address them to the person or situation that’s troubling you. Even writing a letter to yourself can provide a safe space for release without the pressure of someone else’s reaction.&lt;/p&gt;
    &lt;p&gt;5. Treat writing as a process. Any time you draft something and ask for feedback on it, you practice stepping back to consider alternative perspectives. Applying that feedback through revision can strengthen self-awareness and build confidence.&lt;/p&gt;
    &lt;p&gt;Resilience may be as ordinary as the journal entries people scribble, the emails they exchange, the task lists they create — even the essays students pound out for professors.&lt;/p&gt;
    &lt;p&gt;The act of writing is adaptation in progress.&lt;/p&gt;
    &lt;p&gt;Emily Ronay Johnston, Assistant Teaching Professor of Global Arts, Media and Writing Studies, University of California, Merced&lt;/p&gt;
    &lt;p&gt;This article is republished from The Conversation under a Creative Commons license. Read the original article.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scienceclock.com/writing-builds-resilience-in-everyday-challenges-by-changing-your-brain/"/><published>2025-11-28T13:43:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46078770</id><title>Petition to formally recognize open source work as civic service in Germany</title><updated>2025-11-28T17:09:04.298273+00:00</updated><content>&lt;doc fingerprint="aac610cf9c9e37e8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;2.190 Unterschriften&lt;/head&gt;&lt;p&gt;Petition richtet sich an: Deutscher Bundestag Petitionsausschuss&lt;/p&gt;&lt;p&gt;Open-Source-Software bildet heute das Fundament großer Teile der digitalen Infrastruktur – in Verwaltung, Wirtschaft, Forschung und im täglichen Leben. Selbst im aktuellen Koalitionsvertrag der Bundesregierung wird Open-Source-Software als elementarer Baustein zur Erreichung digitaler Souveränität genannt.&lt;/p&gt;&lt;p&gt;Dennoch wird die Arbeit, die tausende Freiwillige dafür leisten, in Deutschland steuer- und förderrechtlich nicht als Ehrenamt anerkannt. Dieses Ungleichgewicht zwischen gesellschaftlicher Bedeutung und rechtlichem Status gilt es zu korrigieren.&lt;/p&gt;&lt;p&gt;Als aktiver Contributor in Open-Source-Projekten fordere ich daher, Open-Source-Arbeit als gemeinwohlorientiertes Ehrenamt anzuerkennen – gleichrangig mit Vereinsarbeit, Jugendarbeit oder Rettungsdiensten.&lt;/p&gt;&lt;head rend="h4"&gt;Begründung&lt;/head&gt;&lt;p&gt;1. Open-Source trägt nachweislich zum Gemeinwohl bei&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Open-Source-Projekte schaffen freie, transparente und überprüfbare Software, die allen zugutekommt.&lt;/item&gt;&lt;item&gt;Kritische Systeme wie Internet-Protokolle, Sicherheitsbibliotheken, Gesundheits-IT, KI-Frameworks, Energieverwaltung, Bildungstechnologien und Kommunikationswerkzeuge basieren maßgeblich auf freiwilligen Beiträgen.&lt;/item&gt;&lt;item&gt;Ohne diese Arbeit wäre Deutschland digital abhängiger, weniger sicher und weniger innovativ.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Gemeinwohlorientierung ist ein zentrales Kriterium für ein Ehrenamt – und Open-Source erfüllt dieses in höchstem Maße.&lt;/p&gt;&lt;p&gt;2. Die Arbeit geschieht überwiegend unbezahlt – und ist freiwilliges bürgerschaftliches Engagement&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Die Mehrheit aller Entwicklungs-, Wartungs- und Dokumentationsleistungen erfolgt ehrenamtlich in der Freizeit.&lt;/item&gt;&lt;item&gt;Contributor übernehmen Verantwortung für Sicherheit, Stabilität und Weiterentwicklung zentraler Softwarekomponenten, ohne Vergütung und oft ohne Anerkennung.&lt;/item&gt;&lt;item&gt;Das Engagement ist vergleichbar mit Tätigkeiten in gemeinnützigen Vereinen, nur eben digital.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Die rechtliche Gleichstellung mit klassischem Ehrenamt wäre daher folgerichtig.&lt;/p&gt;&lt;p&gt;3. Gesellschaftliche Abhängigkeit ohne gesellschaftliche Anerkennung&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Staatliche Einrichtungen, Kommunen, Schulen und Unternehmen profitieren direkt von Open-Source-Bibliotheken, Frameworks und Tools.&lt;/item&gt;&lt;item&gt;Sicherheitslücken wie „Heartbleed“ oder Log4Shell haben gezeigt, wie entscheidend die Arbeit der Maintainer für das Schutzinteresse der Allgemeinheit ist.&lt;/item&gt;&lt;item&gt;Gleichzeitig fehlen Ressourcen und Strukturen, weil die Arbeit formal nicht als Ehrenamt eingestuft ist – und damit keinerlei steuerliche oder organisatorische Förderung erhält.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Dies erzeugt eine unausgewogene Verantwortungslast, die auf wenigen Freiwilligen liegt, während Millionen Nutzer*innen profitieren.&lt;/p&gt;&lt;p&gt;4. Anerkennung als Ehrenamt würde Rechtsklarheit schaffen&lt;/p&gt;&lt;p&gt;Durch eine formelle Anerkennung könnten:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Aufwandsentschädigungen steuerfrei gewährt werden (Ehrenamtspauschale/Übungsleiterpauschale).&lt;/item&gt;&lt;item&gt;Gemeinnützige Open-Source-Projekte eine leichtere Einstufung nach §52 AO erreichen.&lt;/item&gt;&lt;item&gt;Contributor bei Haftungsfragen besser gestellt werden (analog zu §31a BGB für Vereinsvorstände).&lt;/item&gt;&lt;item&gt;Projekte rechtssicher Kosten erstatten oder Spendenquittungen ausstellen.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Dies schafft Transparenz, Rechtssicherheit und Nachhaltigkeit im digitalen Ehrenamt.&lt;/p&gt;&lt;p&gt;5. Digitalisierung braucht freiwillige Kompetenz – und diese verdient Förderung&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Open-Source-Engagement erfordert hohe technische Kompetenz.&lt;/item&gt;&lt;item&gt;Freiwillige Entwickler*innen leisten Arbeit, die Unternehmen ansonsten für hohe Stundensätze einkaufen müssten.&lt;/item&gt;&lt;item&gt;Der Staat investiert Milliarden in Digitalisierung, ignoriert aber die Menschen, die die technologische Basis freiwillig pflegen.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Eine Anerkennung als Ehrenamt wäre ein kosteneffizienter Beitrag zur digitalen Souveränität Deutschlands.&lt;/p&gt;&lt;p&gt;6. Deutschland hinkt international hinterher&lt;/p&gt;&lt;p&gt;Andere Staaten fördern Open-Source-Engagement bereits durch:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;steuerliche Begünstigungen&lt;/item&gt;&lt;item&gt;institutionelle Förderung&lt;/item&gt;&lt;item&gt;Anerkennung gemeinnütziger Softwareentwicklung&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Deutschland riskiert, im globalen Wettbewerb zurückzufallen, wenn Freiwilligenarbeit im digitalen Raum weiterhin strukturell benachteiligt wird.&lt;/p&gt;&lt;head rend="h3"&gt;Abrisszettel mit QR Code&lt;/head&gt;herunterladen (PDF)&lt;head rend="h3"&gt;Angaben zur Petition&lt;/head&gt;&lt;p&gt; Petition gestartet: 24.11.2025 &lt;lb/&gt; Sammlung endet: 23.05.2026 &lt;lb/&gt; Region: Deutschland &lt;lb/&gt; Kategorie: Internet &lt;/p&gt;&lt;head rend="h4"&gt;Diese Petition wurde in folgende Sprachen übersetzt&lt;/head&gt;&lt;head rend="h4"&gt;Übersetzen Sie jetzt diese Petition&lt;/head&gt;Neue Sprachversion&lt;head rend="h3"&gt;Debatte&lt;/head&gt;&lt;head rend="h3"&gt;Warum Menschen unterschreiben&lt;/head&gt;&lt;head rend="h3"&gt;Werkzeuge für die Verbreitung der Petition.&lt;/head&gt;&lt;p&gt;Sie haben eine eigene Webseite, einen Blog oder ein ganzes Webportal? Werden Sie zum Fürsprecher und Multiplikator für diese Petition. Wir haben die Banner, Widgets und API (Schnittstelle) zum Einbinden auf Ihren Seiten. Zu den Werkzeugen&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.openpetition.de/petition/online/anerkennung-von-open-source-arbeit-als-ehrenamt-in-deutschland#petition-main"/><published>2025-11-28T14:08:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079460</id><title>Swedish publishers file police report against Meta's Zuckerberg for fraud</title><updated>2025-11-28T17:09:03.986494+00:00</updated><content>&lt;doc fingerprint="16c0e2025a17fc8f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Swedish publishers file police report against Meta's Zuckerberg for fraud&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Swedish publisher's association Utgivarna has filed a police report in Sweden against Facebook and Meta founder Mark Zuckerberg.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The reason is fake ads published on Facebook that use the names of well known Swedish media companies and journalists, that scam Swedes out of money.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;James Savage, chairman of Utgivarna says Meta is not doing enough to prevent the scams from happening: "Meta is very much profiting from this.", he tells Radio Sweden. Meanwhile, Meta tell Radio Sweden fighting scams is one of their top priorities.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sverigesradio.se/artikel/swedish-publishers-file-police-report-against-metas-zuckerberg-for-fraud"/><published>2025-11-28T15:27:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079567</id><title>Generating 3D Meshes from Text</title><updated>2025-11-28T17:09:03.550759+00:00</updated><content>&lt;doc fingerprint="96c043d889bd31b1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Generating 3D Meshes From Text&lt;/head&gt;
    &lt;p&gt;I recently had a desire to convert text to 3D meshes that I could render and manipulate as part of my Geotoy project and Geoscript language. I did some research into tools and libraries that could solve different pieces of this, and I put together a pipeline that implements the whole thing - yielding nice, 2-manifold 3D meshes with arbitrary fonts, text styles, and more.&lt;/p&gt;
    &lt;p&gt;This post gives an overview of the whole setup and aims to give anyone else looking to implement something similar everything they need to get it working themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;svg-text-to-path&lt;/code&gt;⌗ &lt;/head&gt;
    &lt;p&gt;The first part of the setup uses a JavaScript library called &lt;code&gt;svg-text-to-path&lt;/code&gt;. It handles taking arbitrary input text and font params and generating a SVG which contains paths that match the text as closely as possible.&lt;/p&gt;
    &lt;p&gt;Internally, this library handles both fetching + loading the user-specified font as well as performing the text-&amp;gt;path conversion itself. It supports different backends for each of these steps.&lt;/p&gt;
    &lt;p&gt;For my use case, I made use of the Google Fonts provider. It was easy to set up and only requires a Google Fonts API key, which can be generated for free. This allows me to use almost any font on Google Fonts to create my meshes. Some failed to load, but only a few and they seemed to be more obscure ones, and I didn’t bother to dig into why.&lt;/p&gt;
    &lt;p&gt;For the text-&amp;gt;path conversion, &lt;code&gt;svg-text-to-path&lt;/code&gt; defaults to using the fontkit backend. Fontkit is another pure JavaScript library that implements a font engine. I didn’t look into it too deeply, but it seems feature rich and has support for many advanced font features.&lt;/p&gt;
    &lt;p&gt;For my use case, my app runs in the browser. I could have used &lt;code&gt;svg-text-to-path&lt;/code&gt; directly within it to generate these paths. However, this text-&amp;gt;mesh feature isn’t core to my use case and I didn’t want to bloat the app with it. I also wanted to make it as easy as possible for users to set up, and wanted to be able to use my Google Fonts API key in a secure way.&lt;/p&gt;
    &lt;p&gt;So, I opted to create a tiny little backend service to take input text + params and return the generated path as a string. It’s a very minimal Bun webserver using Bun’s built-in &lt;code&gt;Bun.serve&lt;/code&gt;. It exposes a single HTTP/JSON endpoint.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;svg-text-to-path&lt;/code&gt; also includes a minimal built-in webserver, but I opted to create my own so that I could set up some custom caching and post-process the generated SVG to just extract the path. I opted to use an LLM to scaffold out most of this app and it worked pretty well. I feel like this kind of low-stakes one-off/standalone app is an ideal use case for them.&lt;/p&gt;
    &lt;p&gt;Here’s the source code if you’re interested, but I promise it’s nothing special: https://github.com/Ameobea/sketches-3d/tree/main/geoscript_backend/text-to-path&lt;/p&gt;
    &lt;p&gt;Anyway, the output of this is an SVG path which encodes a sequence of draw commands used to generate the text like this:&lt;/p&gt;
    &lt;code&gt;{
  "path": "M5.86 24L5.86 9.53L1.15 9.53L1.15 7.2L13 7.2L13 9.53L8.28 9.53L8.28 24ZM18.8 24.29Q17.09 24.29 15.85 23.47 ...."
}
&lt;/code&gt;
    &lt;head rend="h2"&gt;lyon⌗&lt;/head&gt;
    &lt;p&gt;Now that I had the path generation working, I needed a way to turn it into triangles for the mesh. Luckily, the excellent &lt;code&gt;lyon&lt;/code&gt; Rust libraries (which I’ve used several times in the past for various projects) solve this problem perfectly.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;lyon_extra&lt;/code&gt; crate includes an SVG path parser which handles parsing that path into the underlying draw commands.&lt;/p&gt;
    &lt;p&gt;Then, the &lt;code&gt;lyon_tessellation&lt;/code&gt; crate takes those draw commands and converts them into triangles. It handles all the hard parts and edge cases with concave shapes, hollow inner areas, discretizing bezier curves, and everything else.&lt;/p&gt;
    &lt;p&gt;I implemented a tiny WebAssembly wrapper that takes the input path and returns vertex and index buffers: https://github.com/Ameobea/sketches-3d/blob/main/src/viz/wasm/path_tessellate/src/lib.rs&lt;/p&gt;
    &lt;p&gt;There is a little bit of extra stuff for handling custom scaling, but other than that it’s really just a very thin wrapper over &lt;code&gt;lyon&lt;/code&gt; functionality.&lt;/p&gt;
    &lt;p&gt;One note here is that I had to change the default &lt;code&gt;FillTessellator&lt;/code&gt; options to set the &lt;code&gt;fill-rule&lt;/code&gt; to non-zero, which I believe is the default for SVGs. This fixes the output for some fonts that contain self-intersecting paths, going from this:&lt;/p&gt;
    &lt;p&gt;to this:&lt;/p&gt;
    &lt;head rend="h2"&gt;extrusion⌗&lt;/head&gt;
    &lt;p&gt;So at this point, I had two buffers containing vertices and indices defining a 2D mesh matching the path for the text. The only part that remains is extruding it into 3D. This is a pretty straight-forward and common operation to do on a triangle mesh.&lt;/p&gt;
    &lt;p&gt;To start, you first convert all the vertices from 2D to 3D by filling in the new axis with zeroes (so like (5, 10) -&amp;gt; (5, 0, 10)).&lt;/p&gt;
    &lt;p&gt;Then, you flip the winding order of all the triangles in your mesh. WebGL and almost all other rendering systems use counter-clockwise winding orders, and that defines which direction the triangle is visible from. To flip them, you can just swap the first and third index of each triangle in the index buffer like this:&lt;/p&gt;
    &lt;code&gt;1,2,3,5,7,9,1,4,2

to

3,2,1,9,7,5,2,4,1
&lt;/code&gt;
    &lt;p&gt;Then, you create a duplicate of each of the vertices offset &lt;code&gt;n&lt;/code&gt; units in the new axis (so like (5, 0, 10) -&amp;gt; (5, 2, 10)).&lt;/p&gt;
    &lt;p&gt;Then, join those new vertices with triangles but in the original (unflipped) winding order. That will make the top and the bottom face in opposite directions - the top facing up and the bottom facing down.&lt;/p&gt;
    &lt;p&gt;Finally, you generate triangle strips to join the border edges of the top and bottom faces. A border edge is any edge that is only part of exactly one face. Usually a graph representation like a half-edge data structure is used when working with meshes, which helps with this part.&lt;/p&gt;
    &lt;p&gt;The result should look something like this:&lt;/p&gt;
    &lt;p&gt;Here’s my source code if you’re interested, but note that it’s using my own internal mesh representation: https://github.com/Ameobea/sketches-3d/blob/main/src/viz/wasm/geoscript/src/mesh_ops/extrude.rs&lt;/p&gt;
    &lt;p&gt;If you did everything correctly and took care to keep track of the vertex indices carefully to avoid creating duplicate vertices at the same position, the resulting mesh should be well-formed and 2-manifold/watertight. This is a very important topological property and is a requirement for a variety of other mesh processing algorithms including CSG (constructive solid geometry).&lt;/p&gt;
    &lt;p&gt;The fact that the output meshes are manifold means that they can be combined with other meshes using boolean operations or sent through additional processing like smoothing. I’m not 100% positive that all paths generated from all glyphs using all fonts will end up producing manifold outputs, but everything I tested did.&lt;/p&gt;
    &lt;head rend="h2"&gt;conclusion⌗&lt;/head&gt;
    &lt;p&gt;That’s it! After all of this, the output is a set of vertices and indices that define a 3D mesh representing the input text.&lt;/p&gt;
    &lt;p&gt;I integrated this functionality into my Geoscript language as a builtin function:&lt;/p&gt;
    &lt;p&gt;There are few steps to manage, but the powerful libraries under the hood (&lt;code&gt;svg-text-to-path&lt;/code&gt;, &lt;code&gt;fontkit&lt;/code&gt;, and &lt;code&gt;lyon&lt;/code&gt;) handle all the complex stuff and heavy lifting.&lt;/p&gt;
    &lt;p&gt;Even though some of the critical libraries are in JavaScript and the fact that the generation happens on a remote webserver, I’ve found that for the (relatively short) text I convert it works quite fast - fast enough to work on-demand without waiting.&lt;/p&gt;
    &lt;p&gt;I’ve also not yet found any fonts that produce broken output or buggy meshes. It even works for complicated non-English scripts:&lt;/p&gt;
    &lt;p&gt;It was a fun little side-quest and I’m very happy with the results overall.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cprimozic.net/notes/posts/generating-3d-meshes-from-text/"/><published>2025-11-28T15:40:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079721</id><title>Can Dutch universities do without Microsoft?</title><updated>2025-11-28T17:09:02.683683+00:00</updated><content>&lt;doc fingerprint="2f549110fa8fcfc7"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Criminal court ditches American software giant&lt;/head&gt;
    &lt;head rend="h1"&gt;Can Dutch universities do without Microsoft?&lt;/head&gt;
    &lt;p&gt;The chief prosecutor of the International Criminal Court suddenly couldn't access his email. According to Microsoft, that's because of US sanctions against the court's employees. The Trump administration was not amused by the Court's arrest warrant against the Israeli Prime Minister, Benjamin Netanyahu.&lt;/p&gt;
    &lt;p&gt;The main takeaway from this episode is that those looking to protect themselves from Trump's wrath would be wise not to depend on any companies from his country. According to the Dutch newspaper NRC, the International Criminal Court now uses a German alternative to Microsoft, though it has not officially commented on the switch.&lt;/p&gt;
    &lt;p&gt;The German alternative, OpenDesk, allows users to send emails, edit text-based documents, create presentations, share files, and make video calls. It is open source, so anyone can view and improve its code.&lt;/p&gt;
    &lt;p&gt;The same applies to another alternative, also from Germany, called Nextcloud. This office software has been tested by around 75 researchers from five Dutch universities since the beginning of 2025. Maybe other institutions could switch to it as well?&lt;/p&gt;
    &lt;p&gt;Dependency&lt;lb/&gt;Dutch higher education is highly dependent on American tech companies, especially Microsoft. Not only do students and staff use its software extensively, but their IT staff are tied to a wide range of specialised Microsoft software. In addition, Dutch universities store a lot of data in Microsoft's cloud.&lt;/p&gt;
    &lt;p&gt;Dutch lecturers have been sounding the alarm about this. Last Wednesday, the knowledge centre for practice-oriented research, DCC-PO, stated that the dominance of parties such as Google and Microsoft threatens the autonomy of Dutch researchers. In their view, universities should adopt more open-source tools and open standards.&lt;/p&gt;
    &lt;p&gt;In July, the Young Academy also warned that students and staff at Dutch higher education institutions have no idea what tech companies are doing with their data. By outsourcing the management of IT systems, these educational institutions are losing technical knowledge and control. As a result, they are becoming increasingly dependent on big tech, putting academic freedom and independence at risk.&lt;/p&gt;
    &lt;p&gt;Fickle&lt;lb/&gt;Seven Dutch universities and one university college are already on the State of Florida's sanctions list for severing or freezing ties with Israeli institutions. With a fickle president like Donald Trump, educational institutions could also face “punishment” at any moment.&lt;/p&gt;
    &lt;p&gt;Can they do without Microsoft, however? Can they work without Office, Outlook, Teams and OneDrive? Not yet, according to UU professors José van Dijck and Albert Meijer. "All research and education would come to an immediate standstill," they wrote in March in an open letter calling on the Executive Board to do something about digital dependence.&lt;/p&gt;
    &lt;p&gt;According to the professors, Utrecht University is particularly dependent on Microsoft Office 365. UU staff and students use the programme for email and video calls, writing and sharing documents, creating presentations and data storage, among other tasks. Such dependence makes for "vulnerabilities, especially in light of a rapidly changing geopolitical situation".&lt;/p&gt;
    &lt;p&gt;Meijer and Van Dijck believe that "dependence on big tech is fundamentally at odds with public values such as freedom, independence, autonomy and equality". The professors would like the Executive Board to invest more in "local expertise," for example, by using its own mail server. They also recommend collaborating with other European universities, especially those in Germany and France, "on an autonomous academic IT infrastructure".&lt;/p&gt;
    &lt;p&gt;Breaking free&lt;lb/&gt;It is becoming increasingly clear that dependence on big tech entails risks. This also applies to Dutch higher education, according to Wladimir Mufty, from SURF, the IT cooperative of Dutch education and research institutions. "We have already gone through an awareness phase that lasted several years. We have looked at where the dependencies lie, and now it is time to start trying out alternatives."&lt;/p&gt;
    &lt;p&gt;Mufty is SURF's digital sovereignty programme manager. At the end of last year, he sat down with five universities that wanted a single, shared digital environment for their research programme, AlgoSoc. Scientists from Delft, Utrecht, Rotterdam, Tilburg and Amsterdam (UvA) wanted to use the same appointment planner, share files, work together on a single text, and make video calls, without being dependent on a large provider. Mufty suggested the open source software package from Nextcloud.&lt;/p&gt;
    &lt;p&gt;One of the users, PhD student Jacqueline Kernahan from TU Delft, thinks that Nextcloud could compete with Microsoft, though there are still a few glitches here and there. She is not deterred by those, as she knows how problematic dependence on Microsoft is.&lt;/p&gt;
    &lt;p&gt;She demonstrates the software in the hall of her faculty in Delft. It looks very ordinary. "The word processor is quite good," says Kernahan, who is doing her PhD on quality and security controls in digital systems. "I'm an average user, so I don't need all the options and apps the programme has to offer. But, to be honest, Microsoft is making it increasingly attractive to switch. Now that the company is putting AI in everything, everything is becoming more annoying to use."&lt;/p&gt;
    &lt;p&gt;Nevertheless, Mufty believes that not all educational institutions will be able to switch to OpenDesk or Nextcloud overnight. "The Criminal Court now has to act quickly, under pressure, but if a university wanted to move away from Microsoft tomorrow, that would pose a problem."&lt;/p&gt;
    &lt;p&gt;Entanglement&lt;lb/&gt;Meanwhile, Microsoft is taking on more and more tasks. In addition to office software, it also develops artificial intelligence, builds its own data centres and even lays its own internet cables on the seabed. The company is “vertically integrated”, as specialists call it: everything can be done through one company, from basic technology to the end user.&lt;/p&gt;
    &lt;p&gt;And that's not all. Microsoft is also expanding “horizontally” by acquiring companies where content is the primary focus, rather than technology. "That's a new phase, which I find worrying," says Mufty. For example, Microsoft bought LinkedIn, with its hundreds of millions of active users who produce enormous amounts of data, and GitHub, where software developers can share and store their work.&lt;/p&gt;
    &lt;p&gt;SURF is keeping a close eye on these developments. "I would like our education to remain public and be able to pursue public values such as autonomy, independence and academic freedom. IT should be helpful, not controlling," says Mufty.&lt;/p&gt;
    &lt;p&gt;He views the collaboration between Microsoft and Sanoma with suspicion. The Finnish publisher, which also serves the Dutch education market through its Malmberg subsidiary, wants to make its teaching materials available via Microsoft Teams. Microsoft would then add its own “learning accelerators”, i.e. artificial intelligence designed to help personalise the learning process. “Things like this sometimes keep me awake at night,” sighs Mufty.&lt;/p&gt;
    &lt;p&gt;Alternatives&lt;lb/&gt;Dutch and European alternatives do exist. For example, research institute TNO is working with SURF and the Netherlands Forensic Institute on its own AI language model. There are also dedicated data centres.&lt;/p&gt;
    &lt;p&gt;Additionally, SURFConext is making headway with a secure login service. "But that's not enough. If logging in via Microsoft doesn't work in the future for whatever reason, we'll have a big problem. This also applies to applications that are not from Microsoft itself," explains Mufty.&lt;/p&gt;
    &lt;p&gt;In his view, we need serious alternatives. When the need arises, one shouldn't have to start from scratch. Moreover, competition ensures that the market leader cannot charge top dollar.&lt;/p&gt;
    &lt;p&gt;But which educational institution is willing to sacrifice itself to run those alternatives, with all the teething problems that entails, when Microsoft can deliver everything ready-made? Mufty believes that, especially in the beginning, educational institutions will have to run two systems in parallel, with additional expenditure on support, maintenance, and security. "But in my opinion, no sector is as value-driven as education and research. This is precisely where alternatives should be able to get off the ground."&lt;/p&gt;
    &lt;p&gt;Rectors&lt;lb/&gt;In 2019, the rectors of fourteen universities jointly published a compelling argument about the digital independence of Dutch higher education. The gist was that we risk losing control to Google and Microsoft.&lt;/p&gt;
    &lt;p&gt;Little has improved since then, according to Jacquelien Scherpen, Rector of the University of Groningen. "The coronavirus pandemic broke out just a few months after that article was published. We became even more dependent on big tech, because we didn't have time to look for alternatives." Microsoft Teams has become indispensable, for example.&lt;/p&gt;
    &lt;p&gt;Scherpen is the portfolio holder for digital sovereignty within UNL, the umbrella association for Dutch universities. She advocates taking small steps: "If we now choose an alternative product that functions less well, students and staff will start using free programmes, and we will be further away from our goal."&lt;/p&gt;
    &lt;p&gt;Moreover, Scherpen says that we need legislation to protect European alternatives from big tech. Suppose a university partners up with a European competitor of Microsoft, and then Microsoft buys that company, what is the university to do then?&lt;/p&gt;
    &lt;p&gt;That is not a theoretical scenario. She mentions the Dutch software company Solvinity, which is involved with government services such as DigiD and provides secure communication for the Ministry of Justice. An American company now wants to take it over.&lt;/p&gt;
    &lt;p&gt;Scherpen: "Perhaps we need to become more protectionist, without hindering the free exchange of new insights and innovations. We must ensure that the independence we are fighting for does not slip out of our hands again."&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dub.uu.nl/en/news/can-dutch-universities-do-without-microsoft"/><published>2025-11-28T15:53:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079745</id><title>Tell HN: Want a better HN? Visit /newest</title><updated>2025-11-28T17:09:02.201801+00:00</updated><content>&lt;doc fingerprint="13c4d2f32daf869a"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Most good posts die in /newest, buried under low-quality submissions.&lt;/p&gt;
      &lt;p&gt;HN depends on people visiting /newest and upvoting or flagging what they see.&lt;/p&gt;
      &lt;p&gt;A few minutes there each day probably does more for HN than commenting.&lt;/p&gt;
      &lt;p&gt;It’s anonymous, thankless work, like Reddit’s old “Knights of New,” but it makes a difference.&lt;/p&gt;
      &lt;p&gt;https://news.ycombinator.com/newest&lt;/p&gt;
      &lt;p&gt;https://news.ycombinator.com/newsguidelines.html&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46079745"/><published>2025-11-28T15:57:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079785</id><title>Don't tug on that, you never know what it might be attached to</title><updated>2025-11-28T17:09:01.959845+00:00</updated><content>&lt;doc fingerprint="92a889b52e379ace"&gt;
  &lt;main&gt;
    &lt;cell class="mainsection" bgcolor="#fdfdfd"&gt;
      &lt;p&gt; Don't tug on that, you never know what it might be attached to &lt;/p&gt;
      &lt;p&gt;This is a story about a very interesting bug that I tracked down yesterday. It was causing a bad effect very far from where the bug actually was.&lt;/p&gt;
      &lt;head rend="h3"&gt;emacsclient&lt;/head&gt;
      &lt;p&gt;The &lt;code&gt;emacs&lt;/code&gt; text editor comes with a separate utility, called
&lt;code&gt;emacsclient&lt;/code&gt;, which can communicate with the main editor process and
tell it to open files for editing.  You have your main &lt;code&gt;emacs&lt;/code&gt;
running. Then somewhere else you run the command&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;     emacsclient some-files...
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;and it sends the main &lt;code&gt;emacs&lt;/code&gt;  a message that you want to edit
&lt;code&gt;some-files&lt;/code&gt;.  Emacs gets the message and pops up new windows for editing
those files.  When you're done editing &lt;code&gt;some-files&lt;/code&gt; you tell Emacs, by
typing &lt;code&gt;C-#&lt;/code&gt; or something, it
it communicates back to &lt;code&gt;emacsclient&lt;/code&gt; that the editing is done, and
&lt;code&gt;emacsclient&lt;/code&gt; exits.&lt;/p&gt;
      &lt;p&gt;This was more important in the olden days when Emacs was big and bloated and took a long time to start up. (They used to joke that âEmacsâ was an abbreviation for âEight Megs And Constantly Swappingâ. Eight megs!) But even today it's still useful, say from shell scripts that need to run an editor.&lt;/p&gt;
      &lt;p&gt;Here's the reason I was running it. I have a very nice shell script, called &lt;code&gt;also&lt;/code&gt;, that does something like this:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Interpret command-line arguments as patterns&lt;/item&gt;
        &lt;item&gt;Find files matching those patterns&lt;/item&gt;
        &lt;item&gt;Present a menu of the files&lt;/item&gt;
        &lt;item&gt;Wait for me to select files of interest&lt;/item&gt;
        &lt;item&gt;Run &lt;code&gt;emacsclient&lt;/code&gt; on the selected files&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;It is essentially a wrapper around &lt;code&gt;menupick&lt;/code&gt;,
a menu-picking utility I wrote which has seen use as a component of
several other tools.
I can type &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    also Wizard
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;in the shell and get a menu of the files related to the wizard, select the ones I actually want to edit, and they show up in Emacs. This is more convenient than using Emacs itself to find and open them. I use it many times a day.&lt;/p&gt;
      &lt;p&gt;Or rather, I did until this week, when it suddenly stopped working. Everything ran fine until the execution of &lt;code&gt;emacsclient&lt;/code&gt;, which would
fail, saying:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt; emacsclient: can't find socket; have you started the server?
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;(A socket is a facility that enables interprocess communication, in this case between &lt;code&gt;emacs&lt;/code&gt; and &lt;code&gt;emacsclient&lt;/code&gt;.)&lt;/p&gt;
      &lt;p&gt;This message is familiar. It usually means that I have forgotten to tell Emacs to start listening for &lt;code&gt;emacsclient&lt;/code&gt;, by running &lt;code&gt;M-x
server-start&lt;/code&gt;.  (I should have Emacs do this when it starts up, but I
don't.  Why not?  I'm not sure.) So the first time it happened I went
to Emacs and ran &lt;code&gt;M-x server-start&lt;/code&gt;.  Emacs announced that it had
started the server, so I reran &lt;code&gt;also&lt;/code&gt;.  And the same thing happened.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt; emacsclient: can't find socket; have you started the server?
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;head rend="h3"&gt;Finding the socket&lt;/head&gt;
      &lt;p&gt;So the first question is: why can't &lt;code&gt;emacsclient&lt;/code&gt; find the socket?
And this resolves naturally into two subquestions: where is the
socket, and where is &lt;code&gt;emacsclient&lt;/code&gt; looking?&lt;/p&gt;
      &lt;p&gt;The second one is easily answered; I ran &lt;code&gt;strace emacsclient&lt;/code&gt; (hi
Julia!) and saw that the last interesting thing &lt;code&gt;emacsclient&lt;/code&gt; did
before emitting the error message was&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    stat("/mnt/tmp/emacs2017/server", 0x7ffd90ec4d40) = -1 ENOENT (No such file or directory)
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;which means it's looking for the socket at &lt;code&gt;/mnt/tmp/emacs2017/server&lt;/code&gt;
but didn't find it there.&lt;/p&gt;
      &lt;p&gt;The question of where Emacs actually put the socket file was a little trickier. I did not run Emacs under &lt;code&gt;strace&lt;/code&gt; because I felt sure that
the output would be voluminous and it would be tedious to grovel over
it.&lt;/p&gt;
      &lt;p&gt;I don't exactly remember now how I figured this out, but I think now that I probably made an educated guess, something like: &lt;code&gt;emacsclient&lt;/code&gt;
is looking in &lt;code&gt;/mnt/tmp&lt;/code&gt;; this seems unusual.  I would expect the
socket to be under &lt;code&gt;/tmp&lt;/code&gt;.  Maybe it is under &lt;code&gt;/tmp&lt;/code&gt;?  So I looked
under &lt;code&gt;/tmp&lt;/code&gt; and there it was, in &lt;code&gt;/tmp/emacs2017/server&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    srwx------ 1 mjd mjd 0 Jun 27 11:43 /tmp/emacs2017/server
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;(The &lt;code&gt;s&lt;/code&gt; at the beginning there means that the file is a âUnix-domain
socketâ.  A socket is an endpoint for interprocess communication.  The
most familiar sort is a TCP socket, which has a TCP address, and which
enables communication over the internet.  But since ancient times Unix
has also supported Unix-domain sockets, which enable communication
between two processes on the same machine.  Instead of TCP addresses,
such sockets are addressed using paths in the filesystem, in this case
&lt;code&gt;/tmp/emacs2017/server&lt;/code&gt;.  When the server creates such a socket, it
appears in the filesystem as a special type of file, as here.)&lt;/p&gt;
      &lt;p&gt;I confirmed that this was the correct file by typing &lt;code&gt;M-x
server-force-delete&lt;/code&gt; in Emacs; this immediately caused
&lt;code&gt;/tmp/emacs2017/server&lt;/code&gt; to disappear.  Similarly &lt;code&gt;M-x server-start&lt;/code&gt;
made it reappear.&lt;/p&gt;
      &lt;head rend="h3"&gt;Why the disagreement?&lt;/head&gt;
      &lt;p&gt;Now the question is: Why is &lt;code&gt;emacsclient&lt;/code&gt; looking for the socket under
&lt;code&gt;/mnt/tmp&lt;/code&gt; when Emacs is putting it in &lt;code&gt;/tmp&lt;/code&gt;?  They used to
rendezvous properly; what has gone wrong?  I recalled that there was
some environment variable for controlling where temporary files are
put, so I did&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;       env | grep mnt
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;to see if anything relevant turned up. And sure enough there was:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;       TMPDIR=/mnt/tmp
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When programs want to create tmporary files and directories, they normally do it in &lt;code&gt;/tmp&lt;/code&gt;.  But
if there is a &lt;code&gt;TMPDIR&lt;/code&gt; setting, they use that directory instead.  This
explained why &lt;code&gt;emacsclient&lt;/code&gt; was looking for
&lt;code&gt;/mnt/tmp/emacs2017/socket&lt;/code&gt;.  And the explanation for why Emacs itself
was creating the socket in &lt;code&gt;/tmp&lt;/code&gt; seemed clear: Emacs was failing to
honor the &lt;code&gt;TMPDIR&lt;/code&gt; setting.&lt;/p&gt;
      &lt;p&gt;With this clear explanation in hand, I began to report the bug in Emacs, using &lt;code&gt;M-x report-emacs-bug&lt;/code&gt;. (The folks in the &lt;code&gt;#emacs&lt;/code&gt; IRC
channel on Freenode suggested this.  I had a bad
experience last time I tried
&lt;code&gt;#emacs&lt;/code&gt;, and then people mocked me for even trying to get useful
information out of IRC.  But this time it went pretty well.)&lt;/p&gt;
      &lt;p&gt;Emacs popped up a buffer with full version information and invited me to write down the steps to reproduce the problem. So I wrote down&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;     % export TMPDIR=/mnt/tmp
     % emacs
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;and as I did that I ran those commands in the shell.&lt;/p&gt;
      &lt;p&gt;Then I wrote&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;     In Emacs:
     M-x getenv TMPDIR
     (emacs claims there is no such variable)
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;and I did that in Emacs also. But instead of claiming there was no such variable, Emacs cheerfully informed me that the value of &lt;code&gt;TMPDIR&lt;/code&gt;
was &lt;code&gt;/mnt/tmp&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;(There is an important lesson here! To submit a bug report, you find a minimal demonstration. But then you also try the minimal demonstration exactly as you reported it. Because of what just happened! Had I sent off that bug report, I would have wasted everyone else's time, and even worse, I would have looked like a fool.)&lt;/p&gt;
      &lt;p&gt;My minimal demonstration did not demonstrate. Something else was going on.&lt;/p&gt;
      &lt;head rend="h3"&gt;Why no &lt;code&gt;TMPDIR&lt;/code&gt;?&lt;/head&gt;
      &lt;p&gt;This was a head-scratcher. All I could think of was that &lt;code&gt;emacsclient&lt;/code&gt; and Emacs were somehow getting different environments,
one with the &lt;code&gt;TMPDIR&lt;/code&gt; setting and one without.  Maybe I had run them
from different shells, and only one of the shells had the setting?&lt;/p&gt;
      &lt;p&gt;I got on a sidetrack at this point to find out why &lt;code&gt;TMPDIR&lt;/code&gt; was set in
the first place; I didn't think I had set it. I looked for it in
&lt;code&gt;/etc/profile&lt;/code&gt;, which is the default Bash startup instructions, but it
wasn't there.  But I also noticed an &lt;code&gt;/etc/profile.d&lt;/code&gt; which seemed
relevant.  (I saw later that the &lt;code&gt;/etc/profile&lt;/code&gt; contained instructions
to load everything under &lt;code&gt;/etc/profile.d&lt;/code&gt;.)  And when I grepped for
&lt;code&gt;TMPDIR&lt;/code&gt; in the &lt;code&gt;profile.d&lt;/code&gt; files, I found that it was being set by
&lt;code&gt;/etc/profile.d/ziprecruiter_environment.sh&lt;/code&gt;, which the sysadmins had
installed.  So that mystery at least was cleared up.&lt;/p&gt;
      &lt;p&gt;That got me on a second sidetrack, looking through our Git history for recent changes involving &lt;code&gt;TMPDIR&lt;/code&gt;.  There weren't any, so that was a
dead end.&lt;/p&gt;
      &lt;p&gt;I was still puzzled about why Emacs sometimes got the &lt;code&gt;TMPDIR&lt;/code&gt; setting
and sometimes not.  That's when I realized that my original Emacs
process, the one that had failed to rendezvous with &lt;code&gt;emacsclient&lt;/code&gt;,
had not been started in the usual way.  Instead of simply running
&lt;code&gt;emacs&lt;/code&gt;, I had run&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    git re-edit
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;which invokes Git, which then runs&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    /home/mjd/bin/git-re-edit
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;which is a Perl program I wrote that does a bunch of stuff to figure out which files I was editing recently and then execs &lt;code&gt;emacs&lt;/code&gt; to edit
them some more.  So there are several programs here that could be
tampering with the environment and removing the &lt;code&gt;TMPDIR&lt;/code&gt; setting.&lt;/p&gt;
      &lt;p&gt;To more accurately point the finger of blame, I put some diagnostics into the &lt;code&gt;git-re-edit&lt;/code&gt; program to have it print out the value of
&lt;code&gt;TMPDIR&lt;/code&gt;.  Indeed, &lt;code&gt;git-re-edit&lt;/code&gt; reported that &lt;code&gt;TMPDIR&lt;/code&gt; was unset.
Clearly, the culprit was Git, which must have been removing &lt;code&gt;TMPDIR&lt;/code&gt;
from the environment before invoking my Perl program.&lt;/p&gt;
      &lt;head rend="h3"&gt;Who is stripping the environment?&lt;/head&gt;
      &lt;p&gt;To confirm this conclusion, I created a tiny shell script, &lt;code&gt;/home/mjd/bin/git-env&lt;/code&gt;, which simply printed out the environment, and
then I ran &lt;code&gt;git env&lt;/code&gt;, which tells Git to find &lt;code&gt;git-env&lt;/code&gt; and run it.
If the environment it printed were to omit &lt;code&gt;TMPDIR&lt;/code&gt;, I would know Git
was the culprit.  But &lt;code&gt;TMPDIR&lt;/code&gt; was in the output.&lt;/p&gt;
      &lt;p&gt;So I created a Perl version of &lt;code&gt;git-env&lt;/code&gt;, called &lt;code&gt;git-perlenv&lt;/code&gt;, which
did the same thing, and I ran it via &lt;code&gt;git perlenv&lt;/code&gt;.  And this time
&lt;code&gt;TMPDIR&lt;/code&gt; was not in the output. I ran diff on the outputs of &lt;code&gt;git
env&lt;/code&gt; and &lt;code&gt;git perlenv&lt;/code&gt; and they were identicalâexcept that &lt;code&gt;git
perlenv&lt;/code&gt; was missing &lt;code&gt;TMPDIR&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;So it was Perl's fault! And I verified this by running &lt;code&gt;perl
/home/mjd/bin/git-re-edit&lt;/code&gt; directly, without involving Git at all.
The diagnostics I had put in reported that &lt;code&gt;TMPDIR&lt;/code&gt; was unset.&lt;/p&gt;
      &lt;head rend="h3"&gt;WTF Perl?&lt;/head&gt;
      &lt;p&gt;At this point I tried getting rid of &lt;code&gt;get-re-edit&lt;/code&gt; itself, and ran the
one-line program&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    perl -le 'print $ENV{TMPDIR}'
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;which simply runs Perl and tells it to print out the value of the &lt;code&gt;TMPDIR&lt;/code&gt; environment variable. It should print &lt;code&gt;/mnt/tmp&lt;/code&gt;, but instead
it printed the empty string.  This is a smoking gun, and Perl no
longer has anywhere to hide.&lt;/p&gt;
      &lt;p&gt;The mystery is not cleared up, however. Why was Perl doing this? Surely not a bug; someone else would have noticed such an obvious bug sometime in the past 25 years. And it only failed for &lt;code&gt;TMPDIR&lt;/code&gt;, not
for other variables.  For example&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    FOO=bar perl -le 'print $ENV{FOO}'
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;printed out &lt;code&gt;bar&lt;/code&gt; as one would expect.  This was weird: how could
Perl's environment handling be broken for just the &lt;code&gt;TMPDIR&lt;/code&gt; variable?&lt;/p&gt;
      &lt;p&gt;At this point I got Rik Signes and Frew Schmidt to look at it with me. They confirmed that the problem was not in Perl generally, but just in this Perl. Perl on other systems did not display this behavior. &lt;/p&gt;
      &lt;p&gt;I looked in the output of &lt;code&gt;perl -V&lt;/code&gt;, which says what version of Perl
you are using and which patches have been applied, and wasted a lot of
time looking into
CVE-2016-2381,
which seemed relevant.  But it turned out to be a red herring.&lt;/p&gt;
      &lt;head rend="h3"&gt;Working around the problem, 1.&lt;/head&gt;
      &lt;p&gt;While all this was going on I was looking for a workaround. Finding one is at least as important as actually tracking down the problem because ultimately I am paid to do something other than figure out why Perl is losing &lt;code&gt;TMPDIR&lt;/code&gt;.  Having a workaround in hand means that when
I get sick and tired of looking into the underlying problem I can
abandon it instantly instead of having to push onward.&lt;/p&gt;
      &lt;p&gt;The first workaround I found was to not use the Unix-domain socket. Emacs has an option to use a TCP socket instead, which is useful on systems that do not support Unix-domain sockets, such as non-Unix systems. (I am told that some do still exist.)&lt;/p&gt;
      &lt;p&gt;You set the &lt;code&gt;server-use-tcp&lt;/code&gt; variable to a true value, and when you
start the server, Emacs creates a TCP socket and writes a description
of it into a âserver fileâ, usually &lt;code&gt;~/.emacs.d/server/server&lt;/code&gt;.  Then
when you run &lt;code&gt;emacsclient&lt;/code&gt; you  tell it to connect to the socket that
is described in the file, with&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    emacsclient --server-file=~/.emacs.d/server/server
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;or by setting the &lt;code&gt;EMACS_SERVER_FILE&lt;/code&gt; environment variable. I tried
this, and it worked, once I figured out the thing about
&lt;code&gt;server-use-tcp&lt;/code&gt; and what a âserver fileâ was.  (I had misunderstood
at first, and thought that âserver fileâ meant the Unix-domain socket
itself, and I tried to get &lt;code&gt;emacsclient&lt;/code&gt; to use the right one by
setting &lt;code&gt;EMACS_SERVER_FILE&lt;/code&gt;, which didn't work at all.  The resulting
error message was obscure enough to lead me to IRC to ask about it.)&lt;/p&gt;
      &lt;head rend="h3"&gt;Working around the problem, 2.&lt;/head&gt;
      &lt;p&gt;I spent quite a while looking for an environment variable analogous to &lt;code&gt;EMACS_SERVER_FILE&lt;/code&gt; to tell &lt;code&gt;emacsclient&lt;/code&gt; where the Unix-domain socket
was.  But while there is a &lt;code&gt;--socket-name&lt;/code&gt; command-line argument to
control this, there is inexplicably no environment variable.  I hacked
my &lt;code&gt;also&lt;/code&gt; command (responsible for running &lt;code&gt;emacsclient&lt;/code&gt;) to look for
an environment variable named &lt;code&gt;EMACS_SERVER_SOCKET&lt;/code&gt;, and to pass its
value to &lt;code&gt;emacsclient --socket-name&lt;/code&gt; if there was one.  (It probably
would have been better to write a wrapper for &lt;code&gt;emacsclient&lt;/code&gt;, but I
didn't.)  Then I put&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;    EMACS_SERVER_SOCKET=$TMPDIR/emacs$(id -u)/server
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;in my Bash profile, which effectively solved the problem. This set &lt;code&gt;EMACS_SERVER_SOCKET&lt;/code&gt; to &lt;code&gt;/mnt/tmp/emacs2017/server&lt;/code&gt; whenever I
started a new shell.  When I ran &lt;code&gt;also&lt;/code&gt; it would notice the setting
and pass it along to &lt;code&gt;emacsclient&lt;/code&gt; with &lt;code&gt;--socket-name&lt;/code&gt;, to tell
&lt;code&gt;emacsclient&lt;/code&gt; to look in the right place.  Having set this up I could
forget all about the original problem if I wanted to.&lt;/p&gt;
      &lt;head rend="h3"&gt;But but but WHY?&lt;/head&gt;
      &lt;p&gt;But why was Perl removing &lt;code&gt;TMPDIR&lt;/code&gt; from the environment?  I didn't
figure out the answer to this; Frew took it to the &lt;code&gt;#p5p&lt;/code&gt; IRC channel
on &lt;code&gt;perl.org&lt;/code&gt;, where the answer was eventually tracked down by Matthew
Horsfall and Zefrem.&lt;/p&gt;
      &lt;p&gt;The answer turned out to be quite subtle. One of the classic attacks that can be mounted against a process with elevated privileges is as follows. Suppose you know that the program is going to write to a temporary file. So you set &lt;code&gt;TMPDIR&lt;/code&gt; beforehand and trick it into
writing in the wrong place, possibly overwriting or destroying
something important.&lt;/p&gt;
      &lt;p&gt;When a program is loaded into a process, the dynamic loader does the loading. To protect against this attack, the loader checks to see if the program it is going to run has elevated privileges, say because it is setuid, and if so it sanitizes the processâ environment to prevent the attack. Among other things, it removes &lt;code&gt;TMPDIR&lt;/code&gt; from the
environment.&lt;/p&gt;
      &lt;p&gt;I hadn't thought of exactly this, but I had thought of something like it: If Perl detects that it is running setuid, it enables a secure mode which, among other things, sanitizes the environment. For example, it ignores the &lt;code&gt;PERL5LIB&lt;/code&gt; environment variable that
normally tells it where to look for loadable modules, and instead
loads modules only from a few compiled-in trustworthy directories.  I
had checked early on to see if this was causing the &lt;code&gt;TMPDIR&lt;/code&gt; problem,
but the &lt;code&gt;perl&lt;/code&gt; executable was not setuid and Perl was not running in
secure mode.&lt;/p&gt;
      &lt;p&gt;But Linux supports a feature called âcapabilitiesâ, which is a sort of partial superuser privilege. You can give a program some of the superuser's capabilities without giving away the keys to the whole kingdom. Our systems were configured to give &lt;code&gt;perl&lt;/code&gt; one extra
capability, of binding to low-numbered TCP ports, which is normally
permitted only to the superuser.  And when the dynamic loader ran
&lt;code&gt;perl&lt;/code&gt;, it saw this additional capability and removed &lt;code&gt;TMPDIR&lt;/code&gt; from
the environment for safety.&lt;/p&gt;
      &lt;quote&gt;
        &lt;p&gt;This is why Emacs had the &lt;code&gt;TMPDIR&lt;/code&gt; setting when run from the command
  line, but not when run via &lt;code&gt;git-re-edit&lt;/code&gt;.&lt;/p&gt;
      &lt;/quote&gt;
      &lt;p&gt;Until this came up, I had not even been aware that the âcapabilitiesâ feature existed.&lt;/p&gt;
      &lt;head rend="h3"&gt;A red herring&lt;/head&gt;
      &lt;p&gt;There was one more delightful confusion on the way to this happy ending. When Frew found out that it was just the Perl on my development machine that was misbehaving, he tried logging into his own, nearly identical development machine to see if it misbehaved in the same way. It did, but when he ran a system update to update Perl, the problem went away. He told me this would fix the problem on my machine. But I reported that I had updated my system a few hours before, so there was nothing to update!&lt;/p&gt;
      &lt;p&gt;The elevated capabilities theory explained this also. When Frew updated his system, the new Perl was installed without the elevated capability feature, so the dynamic loader did not remove &lt;code&gt;TMPDIR&lt;/code&gt; from
the environment.  &lt;/p&gt;
      &lt;p&gt;When I had updated my system earlier, the same thing happened. But as soon as the update was complete, I reloaded my system configuration, which reinstated the capability setting. Frew hadn't done this.&lt;/p&gt;
      &lt;head rend="h3"&gt;Summary&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;The system configuration gave &lt;code&gt;perl&lt;/code&gt; a special capability&lt;/item&gt;
        &lt;item&gt;so the dynamic loader sanitized its environment&lt;/item&gt;
        &lt;item&gt;so that when &lt;code&gt;perl&lt;/code&gt; ran &lt;code&gt;emacs&lt;/code&gt;,&lt;/item&gt;
        &lt;item&gt;the Emacs process didn't have the &lt;code&gt;TMPDIR&lt;/code&gt; environment setting&lt;/item&gt;
        &lt;item&gt;which caused Emacs to create its listening socket in the usual place&lt;/item&gt;
        &lt;item&gt;but because &lt;code&gt;emacsclient&lt;/code&gt; did get the setting, it looked in the wrong place&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
      &lt;p&gt;This computer stuff is amazingly complicated. I don't know how anyone gets anything done.&lt;/p&gt;
      &lt;p&gt;[ Addendum 20160709: Frew Schmidt has written up the same incident, but covers different ground than I do. ]&lt;/p&gt;
      &lt;p&gt;[ Addendum 20160709: A Hacker News comment asks what changed to cause the problem? Why was Perl losing &lt;code&gt;TMPDIR&lt;/code&gt; this week but not the week
before?  Frew and I don't know! ]&lt;/p&gt;
      &lt;p&gt; [Other articles in category /tech] permanent link &lt;/p&gt;
    &lt;/cell&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.plover.com/2016/07/01/#tmpdir"/><published>2025-11-28T16:01:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079857</id><title>Playtiles: The Pocket-Sized Gaming Platform</title><updated>2025-11-28T17:09:01.624157+00:00</updated><content>&lt;doc fingerprint="f065df91f20b48b"&gt;
  &lt;main&gt;
    &lt;quote&gt;For mobile gamers who miss the feeling of real buttons.&lt;/quote&gt;
    &lt;quote&gt;For those overwhelmed by massive game libraries.&lt;/quote&gt;
    &lt;quote&gt;For those who are tired of ads and microtransactions.&lt;/quote&gt;
    &lt;quote&gt;For those who cannot commit 16-30 hours of their life for a single game.&lt;/quote&gt;
    &lt;p&gt;Your Playtiles Season: Weekly Games, in your pocket&lt;/p&gt;
    &lt;p&gt;Season 1 includes a handpicked selection of indie games made with GB Studio.&lt;/p&gt;
    &lt;p&gt;What are the games like?&lt;/p&gt;
    &lt;p&gt;We’re keeping the lineup under wraps — but expect retro-inspired visuals paired with modern, thoughtful game design. Some can be completed in an evening and other enjoyed in numerous short sessions.&lt;/p&gt;
    &lt;p&gt;Action, Adventure, Horror, Platformer, Puzzle, Racing... They're not lengthy but focused on the essence of what makes a great video game: gameplay.&lt;/p&gt;
    &lt;p&gt;Hungry for more?&lt;/p&gt;
    &lt;p&gt;You can also sideload your own games with Playtiles OS, there is more than 1 300 games available on itch.io that you can now experience with physical buttons.&lt;lb/&gt;The Playtile layout is also compatible with the Delta simulator, if you feel like indulging in some retro gaming.&lt;/p&gt;
    &lt;p&gt;Playtiles are pocket-sized, electronic-free mobile gamepads that come with a season of indie games.&lt;/p&gt;
    &lt;p&gt;Playtiles are still in development. Final design may vary.&lt;/p&gt;
    &lt;p&gt; With the Playtiles Game Dev Kit, you can dive into game development; even if you've never written a single line of code.&lt;lb/&gt; Each kit includes a custom Playtile and a download key for Gumpy Function's enhanced version of "Let's Build a Platformer!" course, featuring exclusive Playtiles chapters on sideloading, testing your games, digital manual, achievements, and more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://get.playtil.es"/><published>2025-11-28T16:08:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079858</id><title>Looking Back at a Pandemic Simulator</title><updated>2025-11-28T17:08:56.098813+00:00</updated><content>&lt;doc fingerprint="2528105371e58790"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Looking back at a pandemic simulator&lt;/head&gt;
    &lt;p&gt;It’s been six years now since the early days of the Covid pandemic. People who were paying super close attention started hearing rumors about something going on in China towards the end of 2019 — my earliest posts about it on Facebook were from November that year.&lt;/p&gt;
    &lt;p&gt;Even at the time, people were utterly clueless about the mathematics of how a highly infectious virus spread. I remember spending hours writing posts on various different social media sites explaining that the Infection Fatality Rates and the R value were showing that we could be looking at millions dead. People didn’t tend to believe me:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“SEVERAL MILLION DEAD! Okay, I’m done. No one is predicting that. But you made me laugh. Thanks.”&lt;/p&gt;
      &lt;p&gt;You can do the math yourself. Use a low average death estimate of 0.4%. Assume 60% of the population catches it and then we reach herd immunity (which is generous):&lt;/p&gt;
      &lt;item&gt;328 million people in the US.&lt;/item&gt;
      &lt;item&gt;60% of that is 196 million catch it.&lt;/item&gt;
      &lt;item&gt;0.4% of that is 780,000 dead.&lt;/item&gt;
      &lt;p&gt;But that’s with low assumptions…&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It was like typing to a wall. In fact, it’s pretty likely that it still is, since these days, the discourse is all about how bad the economic and educational impact of lockdowns was — and not about the fact that if the world had acted in concert and forcefully, we could have had a much better outcome than we did. The health response was too soft, the lockdown too lenient, and as a result, we took all the hits.&lt;/p&gt;
    &lt;p&gt;Of course, these days people also forget just how deadly it was and how many died, and so on. We now know that the overall IFR was probably higher than 0.4%, but very strongly tilted towards older people and those with comorbidities. We also now know that herd immunity was a pipe dream — instead we managed to get vaccines out in record time and the ordinary course of viral evolution ended up reducing the death rate until now we behave as if Covid is just a deadlier flu (it isn’t, that thinking ignores long-term impact of the disease).&lt;/p&gt;
    &lt;p&gt;The upshot: my math was not that far off — the estimated toll in the US ended up being 1.2 to 1.4 million souls, and worldwide it’s estimated as between 15 and 28.5 million dead. Plenty of denial of this, these days, and plenty of folks blaming the vaccines for what are most likely issues caused by the disease in the first place.&lt;/p&gt;
    &lt;p&gt;Anyway, in the midst of it all, tired of running math in my spreadsheets (yeah, I was tracking it all in spreadsheets, what can I say?), I started thinking about why only a few sorts of people were wrapping their heads around the implications. The thing they all had in common was that they lived with exponential curves. Epidemiologists, Wall Street quants, statisticians… and game designers.&lt;/p&gt;
    &lt;p&gt;Could we get more people to feel the challenges in their bones?&lt;/p&gt;
    &lt;head rend="h3"&gt;The design sketch&lt;/head&gt;
    &lt;p&gt;So… I posted this to Facebook on March 24th, 2020:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Three weeks ago I was idly thinking of how someone ought to make a little game that shows how the coronavirus spreads, how testing changes things, and how social distancing works.&lt;/p&gt;
      &lt;p&gt;The sheer number of people who don’t get it — numerate people, who ought to be able to do math — is kind of shocking.&lt;/p&gt;
      &lt;p&gt;I couldn’t help worrying at it, and have just about a whole design in my head. But I have to admit, I kinda figured someone would have made it by now. But they haven’t.&lt;/p&gt;
      &lt;p&gt;It’s not even a hard game to make.&lt;/p&gt;
      &lt;p&gt;Little circles on a plain field. Each circle simply bounces around.&lt;/p&gt;
      &lt;p&gt;They are generated each with an age, a statistically real chance of having a co-morbid condition (diabetes, hypertension, immunosuppressed, pulmonary issues…), and crucially, a name out of a baby book.&lt;/p&gt;
      &lt;p&gt;They can be in one of these states:&lt;/p&gt;
      &lt;item&gt;healthy&lt;/item&gt;
      &lt;item&gt;asymptomatic but contagious&lt;/item&gt;
      &lt;item&gt;symptomatic&lt;/item&gt;
      &lt;item&gt;severe&lt;/item&gt;
      &lt;item&gt;critical&lt;/item&gt;
      &lt;item&gt;dead&lt;/item&gt;
      &lt;item&gt;recovered&lt;/item&gt;
      &lt;p&gt;In addition, there’s a diagnosed flag.&lt;/p&gt;
      &lt;p&gt;We render asymptomatic the same as healthy. We render each of the other states differently, depending on whether the diagnosed flag is set. They show as healthy until dead, if not diagnosed. If diagnosed, you can see what stage they are in (icon or color change).&lt;/p&gt;
      &lt;p&gt;The circles move and bounce. If an asymptomatic one touches a healthy one, they have a statistically valid chance of infecting.&lt;/p&gt;
      &lt;p&gt;Circles progress through these states using simple stats.&lt;/p&gt;
      &lt;item&gt;70% of asymptomatic cases turn symptomatic after 1d10+5 days. The others stay sick for the full 21 days.&lt;/item&gt;
      &lt;item&gt;Percent chance of moving from symptomatic to severe is based on comorbid conditions, but the base chance is 1 in 5 after some amount of days.&lt;/item&gt;
      &lt;item&gt;Percent chance of moving from severe to critical is 1 in 4, modified by age and comorbidities, if in hospital. Otherwise, it’s double.&lt;/item&gt;
      &lt;item&gt;Percent chance of moving from critical to dead is something like 1 in 5, modified by age and comorbidities, if in hospital. Otherwise, it’s double.&lt;/item&gt;
      &lt;item&gt;Symptomatic, severe, and critical circles that do not progress to dead move to ‘recovered’ after 21 days since reaching symptomatic.&lt;/item&gt;
      &lt;item&gt;Severe and critical circles stop moving.&lt;/item&gt;
      &lt;p&gt;We track current counts on all of these, and show a bar graph. Yes, that means players can see that people are getting sick, but don’t know where.&lt;/p&gt;
      &lt;p&gt;The player has the following buttons.&lt;/p&gt;
      &lt;item&gt;Hover on a circle, and you see the circle’s name and age and any comorbidities (“Alison, 64, hypertension.”)&lt;/item&gt;
      &lt;item&gt;Test. This lets them click on a circle. If the circle is asymptomatic or worse, it gets the diagnosed flag. But it costs you one test.&lt;/item&gt;
      &lt;item&gt;Isolate. This lets them click on a circle, and freezes them in place. Some visual indicator shows they are isolated. Note that isolated cases still progress.&lt;/item&gt;
      &lt;item&gt;Hospitalize. This moves the circle to hospital. Hospital only has so many beds. Clicking on a circle already in hospital drops the circle back out in the world. Circles in hospital have half the chance or progressing to the next stage.&lt;/item&gt;
      &lt;item&gt;Buy test. You only have so many tests. You have to click this button to buy more.&lt;/item&gt;
      &lt;item&gt;Buy bed. You only have this many beds. You have to click this button to buy more.&lt;/item&gt;
      &lt;item&gt;Money goes up when circles move. But you are allowed to go negative for money.&lt;/item&gt;
      &lt;item&gt;Lockdown. Lastly, there is a global button that when pressed, freezes 80% of all circles. But it gradually ticks down and circles individually start to move again, and the button must be pressed again from time to time. While lockdown is running, it costs money as well as not generating it. If pressed again, it lifts the lockdown and all circles can move again.&lt;/item&gt;
      &lt;p&gt;The game ticks through days at an accelerated pace. It runs for 18 months worth of days. At the end of it, you have a vaccine, and the epidemic is over.&lt;/p&gt;
      &lt;p&gt;Then we tell you what percentage of your little world died. Maybe with a splash screen listing every name and age of everyone who died. And we show how much money you spent. Remember, you can go negative, and it’s OK.&lt;/p&gt;
      &lt;p&gt;That’s it. Ideally, it runs in a webpage. Itch.io maybe. Or maybe I have a friend with unlimited web hosting.&lt;/p&gt;
      &lt;p&gt;Luxury features would be a little ini file or options screen that lets you input real world data for your town or country: percent hypertensive, age demographics, that sort of thing. Or maybe you could crowdsource it, so it’s a pulldown…&lt;/p&gt;
      &lt;p&gt;Each weekend I think about building this. So far, I haven’t, and instead I try to focus on family and mental health and work. But maybe someone else has the energy. I suspect it might persuade and save lives.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Notes on the design&lt;/head&gt;
    &lt;p&gt;Some things about this that I want to point out in hindsight.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;At the time that I posted, I could tell that people were desperately unwilling to enter lockdown for any extended period of time; but “The Hammer and the Dance” strategy of pulsed lockdown periods was still very much in our future. I wanted a mechanic that showed population non-compliance.&lt;/item&gt;
      &lt;item&gt;There was also quite a lot of obsessing over case counts at the time, and one of the things that I really wanted to get across was that our testing was so incredibly inadequate that we really had little idea of how many cases we were dealing with and therefore what the IFR (infection fatality rate) actually was. That’s why tests are limited in the design sketch.&lt;/item&gt;
      &lt;item&gt;I was also trying to get across that money was not a problem in dealing with this. You could take the money value negative because governments can choose to do that. I often pointed out in those days that if the government chose, it could send a few thousand dollars to every household every few weeks for the duration of lockdown. It would likely have been less impact to the GDP and the debt than what we actually did.&lt;/item&gt;
      &lt;item&gt;I wanted names. I wanted players to understand the human cost, not just the statistics. Today, I might even suggest that an LLM generate a little biography for every fatality.&lt;/item&gt;
      &lt;item&gt;Another thing that was constantly missed was the impact of comorbidities. To this day, I hear people say “ah, it only affected the old and the ill, so why not have stayed open?” To which I would reply with:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;Per the American Heart Association, among adults age 20 and older in the United States, the following have high blood pressure:&lt;/p&gt;
      &lt;item&gt;For non-Hispanic whites, 33.4 percent of men and 30.7 percent of women.&lt;/item&gt;
      &lt;item&gt;For non-Hispanic Blacks, 42.6 percent of men and 47.0 percent of women.&lt;/item&gt;
      &lt;item&gt;For Mexican Americans, 30.1 percent of men and 28.8 percent of women.&lt;/item&gt;
      &lt;p&gt;Per the American Diabetes Association,&lt;/p&gt;
      &lt;item&gt;34.2 million Americans, or 10.5% of the population, have diabetes.&lt;/item&gt;
      &lt;item&gt;Nearly 1.6 million Americans have type 1 diabetes, including about 187,000 children and adolescents&lt;/item&gt;
      &lt;p&gt;Per studies in JAMA,&lt;/p&gt;
      &lt;item&gt;4.2% of of the population of the USA has been diagnosed as immunocompromised by their doctor&lt;/item&gt;
      &lt;p&gt;Next, realize that because the disease spreads mostly inside households (where proximity means one case tends to infect others), this means that protecting the above extremely large slices of the population means either isolating them away from their families, or isolating the entire family and other regular contacts.&lt;/p&gt;
      &lt;p&gt;People tend to think the at-risk population is small. It’s not.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The response, for Facebook, was pretty surprising. The post was re-shared a lot, and designers from across the industry jumped in with tweaks to the rules. Some folks re-posted it to large groups about public initiatives, etc.&lt;/p&gt;
    &lt;p&gt;There was also, of course, plenty of skepticism that something like this would make any difference at all.&lt;/p&gt;
    &lt;head rend="h3"&gt;Teams take it up&lt;/head&gt;
    &lt;p&gt;The first to take up the challenge was John Albano, who had his game Covid Ops up and running on itch.io a mere six days later. You can still play it there!&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Stuck in the house and looking for things to do. Soooo, when a fellow game dev suggested a game idea and basic ruleset along with “I wish someone would make a game like this,” I took that as a challenge to try. Tonight (this morning?), the first release of COVID OPS has been published.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;John’s game was pretty faithful to the sketch. You can see the comorbidities over on the left, and the way the player has clicked on 72 year old Rowan — who probably isn’t going to make it. As he updated it, he added in more detailed comorbidity data, and (unfortunately, as it turns out) made it so that people were immune after recovering from infection. And of course, like the next one I’ll talk about, John made a point of including real world resource links so that people could take action.&lt;/p&gt;
    &lt;p&gt;By April 6th, another team led by Khail Santia had participated in Jamdemic 2020 and developed the first version of In the Time of Pandemia. He wrote,&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The compound I stay at is about to be cordoned. We’ve been contact-traced by the police, swabbed by medical personnel covered in protective gear. One of our housemates works at a government hospital and tested positive for antibodies against SARS-CoV-2.&lt;/p&gt;
      &lt;p&gt;The pandemic closes in from all sides. What can a game-maker do in a time like this?&lt;/p&gt;
      &lt;p&gt;I’ve been asking myself this question since the beginning of community quarantine. I’m based in Cebu City, now the top hotspot for COVID-19 in the Philippines in terms of incidence proportion.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This game would go on to be completed by a fuller team including a mathematical epidemiologist, and In the Time of Pandemia eventually ended up topping charts on Newgrounds when it launched there in July of 2020.&lt;/p&gt;
    &lt;p&gt;This game went viral and got a ton of press across the Pacific Rim. The team worked closely with universities and doctors in the Philippines and validated all the numbers. They added local flavor to their levels representing cities and neighborhoods that their local players would know. All in all, forty-eight people worked on it. You can read Khail’s reminiscences here.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Gregg Victor Gabison, dean of the University of San Jose-Recoletos College of Information, Computer &amp;amp; Communications Technology, whose students play-tested the game, said, “This is the kind of game that mindful individuals would want to check out. It has substance and a storyline that connects with reality, especially during this time of pandemic.”&lt;/p&gt;
      &lt;p&gt;Not only does the game have to work on a technical basis, it has to communicate how real a crisis the pandemic is in a simple, digestible manner.&lt;/p&gt;
      &lt;p&gt;Dr. Mariane Faye Acma, resident physician at Medidas Medical Clinic in Valencia, Bukidnon, was consulted to assess the game’s medical plausibility. She enumerated critical thinking, analysis, and multitasking as skills developed through this game. “You decide who are the high risks, who needs to be tested and isolated, where to focus, [and] how much funds to allocate….The game will make players realize how challenging the work of the health sector is in this crisis.”&lt;/p&gt;
      &lt;p&gt;“Ultimately, the game’s purpose is to give players a visceral understanding of what it takes to flatten the curve,” Santia said.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Aftermath&lt;/head&gt;
    &lt;p&gt;I think most people have no idea that any of this happened or that I was associated with it. I only posted the design sketch on Facebook; it got reshared across a few thousand people. It wasn’t on social media, I didn’t talk about it elsewhere, and for whatever reason, I didn’t blog about it.&lt;/p&gt;
    &lt;p&gt;I have had both these games listed on my CV for a while. Oh, I didn’t do any of the heavy lifting… all credit goes to the developers for that. There’s no question that way more than 95% of the work comes after the high-level design spec. But both games do credit me, and I count them as games I worked on.&lt;/p&gt;
    &lt;p&gt;A while back, someone on Reddit said it was pathetic that I listed these. I never quite know what to make of comments like that (troll much?!?).&lt;/p&gt;
    &lt;p&gt;No offense, but I’m proud of what a little design sketch turned into, and proud of the work that these teams did, and proud that one of the games got written up in the press so much; ended up being used in college classrooms; was vetted and validated by multiple experts in the field; and made a difference however slight.&lt;/p&gt;
    &lt;p&gt;Peak Covid was a horrendous time. Horrendous enough that we have kind of blocked it from our memories. But I lost friends and colleagues. I still remember. Back then I wrote,&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This is the largest event in your lifetime. It is our World War, our Great Depression. We need to rise the occasion, and think about how we change. There is no retreat to how it used to be.&lt;/p&gt;
      &lt;p&gt;There is only through.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A year later, the vaccine gave us that path through, and here we are now.&lt;/p&gt;
    &lt;p&gt;But as I write this, we have the first human case of H5N5 bird flu; it was only a matter of time.&lt;/p&gt;
    &lt;p&gt;Maybe these games helped a few people get through it all. They were played by tens of thousands, after all. Maybe they will help next time. I know that the fact that they were made helped me get through, that making them helped John get through, helped Khail get through — in his own words:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the end, the attempt to articulate a game-maker’s perspective on COVID-19 has enabled me to somehow transcend the chaos outside and the turmoil within. It’s become a welcome respite from isolation, a thread connecting me to a diversity of talents who’ve been truly generous with their expertise and encouragement. As incidences continue to rise here and in many parts of the world, our hope is that the game will be of some use in showing what it takes to flatten the curve and in advocating for communities most in need.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So… at minimum, they made a real difference to at least three people.&lt;/p&gt;
    &lt;p&gt;And that’s not a bad thing for a game to aspire to.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.raphkoster.com/2025/11/16/looking-back-at-a-pandemic-simulator/"/><published>2025-11-28T16:09:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079860</id><title>The Signal Is the Noise</title><updated>2025-11-28T17:08:55.390855+00:00</updated><content>&lt;doc fingerprint="b78edb3d3b723d48"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Magazine Dirt&lt;/item&gt;
      &lt;item&gt;Posts&lt;/item&gt;
      &lt;item&gt;The Signal is the Noise&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;The Signal is the Noise&lt;/head&gt;
    &lt;head rend="h2"&gt;The politics of prediction markets.&lt;/head&gt;
    &lt;p&gt;Nishanth Bhargava on how gambling on everything has shaped reporting.&lt;lb/&gt;Election Night, 2024. I sat on a friend’s couch as coverage began—we were all ready for a long night, waiting for results to roll in from an election that seemed like it would be decided by a razor-thin margin. But from the first hour, it was clear that the polling was off, and it was shaping up to be a disaster for the Democrats. Everyone in the room seemed disheartened, but none more than Ted, who was seething in the seat right next to mine. It wasn’t because he was a particularly political person. He had something else on the line—his money. I watched him grow more and more agitated as he refreshed Kalshi on his phone, watching the blue line sink lower and lower as the night went on. $500 on Kamala Harris, gone in an instant. &lt;/p&gt;
    &lt;p&gt;One year later, New York City’s recent mayoral election was one of the most expensive in modern history—for traders, at least. Between Polymarket and Kalshi, the race brought in roughly half a billion dollars in total trade volume—dwarfing even the most expensive Senate races in 2024, where top fundraisers like Sherrod Brown and Jon Tester raised just over $90 million. And the mayoral election was no aberration—as of September, Kalshi alone is pulling more than $1 billion in total monthly trade volume.&lt;/p&gt;
    &lt;p&gt;“Trust in experts has been eroded to the point where people trust prices more than pundits,” says Mickey Down, co-creator of HBO’s Industry. Fans of the show are still buzzing about an Uncut Gems-style bottle episode in the third season, in which the high stakes line between trading and gambling blurs for Pierpoint cad, Rishi Ramdani.&lt;/p&gt;
    &lt;p&gt;Unlike traditional sportsbooks, prediction markets have established themselves not merely as hubs of speculation, but purveyors of collective wisdom, capturing “reality” in a way that traditional polls can’t. But in the process of capturing that information, these markets also act back on reality and warp our relation to politics. As election betting becomes a larger and larger industry, it’s harder to delineate between market odds and reality. So when, in Baudrillard’s sense, does the map begin to precede the territory? It’s likely already begun.&lt;/p&gt;
    &lt;p&gt;The value proposition behind prediction markets is relatively simple. In the aggregate, rational traders can crowd out irrational ones to keep the market balanced; as live platforms, they can be more responsive to immediate fluctuations; and, of course, with skin in the game, traders are motivated to trade based on what they think will happen instead of what they want.&lt;/p&gt;
    &lt;p&gt;With skin in the game, traders are motivated to trade based on what they think will happen instead of what they want.&lt;/p&gt;
    &lt;p&gt;One of the first modern prediction markets came out of the University of Iowa in 1988 with the Iowa Electronic Markets (IEM). Over antiquated TelNet infrastructure, traders placed bets on whether America would choose more of the same with Republican George W. Bush or measured change under Massachusetts Democrat Michael Dukakis. Thomas Gruca, Director of the IEM, stresses that the point of the IEM “is for teaching and research,” contrasting their non-revenue model with the profit-taking strategy of their more recent competitors.&lt;/p&gt;
    &lt;p&gt;The leap of prediction markets out of academia and into the media spotlight is a product of the more general epistemic crisis gripping political analysts today. The original trauma here was, of course, the massive polling whiff of the 2016 election.&lt;/p&gt;
    &lt;p&gt;“We've been very let down by our real polling data, for a number of reasons that seem hard to reverse, so why not seek an alternative opinion platform with more accountability built in?” says Mary Childs, financial journalist and cohost of NPR’s Planet Money. And yet those offending pollsters stuck around. “There is little reputational cost for anyone being wrong these days,” says Joe Weisenthal—also a financial journalist, and host of Bloomberg’s Odd Lots. The masses have sought ways of bypassing the commentariat themselves by predicting the future with their dollars. This has already impacted political reporting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.magazine.dirt.fyi/p/the-signal-is-the-noise"/><published>2025-11-28T16:09:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079868</id><title>Meta hiding $27B in debt using advanced geometry</title><updated>2025-11-28T17:08:55.313806+00:00</updated><content/><link href="https://stohl.substack.com/p/exclusive-credit-report-shows-meta"/><published>2025-11-28T16:09:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079975</id><title>Artificial Computation</title><updated>2025-11-28T17:08:54.450004+00:00</updated><content>&lt;doc fingerprint="c40bdb446b7ce3ee"&gt;
  &lt;main&gt;
    &lt;p&gt;We do not yet know what a computer can't do. Indeed, for nearly one hundred years, the computer has been defined capaciously, as a machine that can do the work of any other machine provided it can be defined logically (Alan Turing). Adopting François Laruelle's parlance, Turing's definition could be renamed the Principle of Sufficient Computation; the definition ensures that the computer can actuate any and all events, provided they are formulated as ideas.&lt;/p&gt;
    &lt;p&gt;The Principle of Sufficient Computation thus reveals a series of characteristics common in computing:&lt;/p&gt;
    &lt;p&gt;(1) The centrality of action or practice, understood as a series of commands that may be executed in order to alter the states of a system.&lt;lb/&gt; (2) The linking of idea to action, wherein if something can be thought it can be executed, and if something has been executed it was, perforce, previously thought.&lt;lb/&gt; (3) Practical omniscience, where knowledge swells to the very limits of knowability, even as those limits have been incontrovertibly demonstrated using logical proof.&lt;lb/&gt; (4) A system of judgment based not in morality or politics but in mimesis. Computers thus parrot the old question from the Poetics of Aristotle: Is this copy a well-crafted copy?&lt;/p&gt;
    &lt;p&gt;So we do not yet know what a computer can't do, mostly because the computer has been doing so much for so long.&lt;/p&gt;
    &lt;p&gt;And, still, indicators show a variety of alternatives, varieties of computation that reside not so much before or after mainstream computing, but along side it. The varieties of computation would include digital computing (the paradigmatic implementation of the Principle of Sufficient Computation), analog computing (formerly dominant, but today largely overshadowed), dialectical computing (unimaginable using today's chips and software), and non-standard or artificial computing.&lt;/p&gt;
    &lt;p&gt;Artificial computation was discovered by Laruelle, even as artificial computers have not yet been invented, similar to the discovery of Shor's algorithm prior to any machine capable of implementing it. Synonyms for artificial computation include: non-computation, non-standard computation, compu-fiction, and computer fiction.&lt;/p&gt;
    &lt;p&gt;Artificial computation is defined, axiomatically, as the withdrawal from the Principle of Sufficient Computation, and hence in terms of:&lt;/p&gt;
    &lt;p&gt;(1) The preemption of all commands and the neutering of the executable, in favor of pure process as a phenomenon immanent to itself.&lt;lb/&gt; (2) The delinking of idea and action as to be absolutely un-exchangeable with each other.&lt;lb/&gt; (3) Knowledge as radically finite, existing not as the total aggregation of ever-widening claims about the world, but as a series of axioms in the generic real.&lt;lb/&gt; (4) A non-Aristotelian technology of immanence, where technology is not understood in terms of craft or mimesis (whether effective or defective).&lt;/p&gt;
    &lt;p&gt;Artificial computation is thus not post-computational, but rather, somehow, along side it, as a science "liberated from...the neurosciences or cybernetics" (Laruelle). In this sense artificial computation enacts a generic form of thinking, which, ironically, has thus far remained unthinkable by that overweening discipline of philosophy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cultureandcommunication.org/galloway/artificial-computation"/><published>2025-11-28T16:20:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46079987</id><title>AI Adoption Rates Starting to Flatten Out</title><updated>2025-11-28T17:08:54.073999+00:00</updated><content>&lt;doc fingerprint="361896579877b344"&gt;
  &lt;main&gt;
    &lt;p&gt;Data from the Census Bureau and Ramp shows that AI adoption rates are starting to flatten out across all firm sizes, see charts below.&lt;/p&gt;
    &lt;p&gt;This presentation may not be distributed, transmitted or otherwise communicated to others in whole or in part without the express consent of Apollo Global Management, Inc. (together with its subsidiaries, “Apollo”).&lt;/p&gt;
    &lt;p&gt;Apollo makes no representation or warranty, expressed or implied, with respect to the accuracy, reasonableness, or completeness of any of the statements made during this presentation, including, but not limited to, statements obtained from third parties. Opinions, estimates and projections constitute the current judgment of the speaker as of the date indicated. They do not necessarily reflect the views and opinions of Apollo and are subject to change at any time without notice. Apollo does not have any responsibility to update this presentation to account for such changes. There can be no assurance that any trends discussed during this presentation will continue.&lt;/p&gt;
    &lt;p&gt;Statements made throughout this presentation are not intended to provide, and should not be relied upon for, accounting, legal or tax advice and do not constitute an investment recommendation or investment advice. Investors should make an independent investigation of the information discussed during this presentation, including consulting their tax, legal, accounting or other advisors about such information. Apollo does not act for you and is not responsible for providing you with the protections afforded to its clients. This presentation does not constitute an offer to sell, or the solicitation of an offer to buy, any security, product or service, including interest in any investment product or fund or account managed or advised by Apollo.&lt;/p&gt;
    &lt;p&gt;Certain statements made throughout this presentation may be “forward-looking” in nature. Due to various risks and uncertainties, actual events or results may differ materially from those reflected or contemplated in such forward-looking information. As such, undue reliance should not be placed on such statements. Forward-looking statements may be identified by the use of terminology including, but not limited to, “may”, “will”, “should”, “expect”, “anticipate”, “target”, “project”, “estimate”, “intend”, “continue” or “believe” or the negatives thereof or other variations thereon or comparable terminology.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.apolloacademy.com/ai-adoption-rates-starting-to-flatten-out/"/><published>2025-11-28T16:21:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46080143</id><title>True P2P Email on Top of Yggdrasil Network</title><updated>2025-11-28T17:08:53.595310+00:00</updated><content>&lt;doc fingerprint="bfbae441fb0022cf"&gt;
  &lt;main&gt;
    &lt;p&gt;English | Русский&lt;/p&gt;
    &lt;p&gt;True P2P Email on top of Yggdrasil Network&lt;/p&gt;
    &lt;p&gt;We're taught that email must go through servers. Why? Because the Internet was built around centralized infrastructure. Every email you send travels through multiple servers - your provider's server, maybe a few relay servers, and finally your recipient's provider's server. Each hop is a potential point of surveillance, censorship, or failure.&lt;/p&gt;
    &lt;p&gt;Even "encrypted" email solutions still rely on these centralized servers. They encrypt the message content but the metadata - who you're talking to, when, how often - is visible to anyone watching the servers.&lt;/p&gt;
    &lt;p&gt;But there is a network, called Yggdrasil, that gives everyone a free IPv6 and doesn't need a blessing from your ISP. We finally have this possibility to use true P2P email. And moreover, this network has strong encryption to protect all data that flows from one IP to another.&lt;/p&gt;
    &lt;p&gt;So, Tyr brings true peer-to-peer email to your Android device using these unusual conditions. Unlike traditional email clients, Tyr doesn't need:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Centralized mail servers (the connections are straight P2P)&lt;/item&gt;
      &lt;item&gt;Message encryption layers (the network takes care of that)&lt;/item&gt;
      &lt;item&gt;Port forwarding or STUN/TURN servers (Yggdrasil handles NAT traversal)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Full integration with DeltaChat and ArcaneChat - the best decentralized messengers&lt;/item&gt;
      &lt;item&gt;Local SMTP/IMAP server running on your device&lt;/item&gt;
      &lt;item&gt;Automatic Ed25519 key generation for your mail identity&lt;/item&gt;
      &lt;item&gt;Connection to the Yggdrasil Network with configurable peers&lt;/item&gt;
      &lt;item&gt;Auto-start on boot for always-on availability&lt;/item&gt;
      &lt;item&gt;Encrypted backup &amp;amp; restore with password protection&lt;/item&gt;
      &lt;item&gt;Automatic recovery from Android Keystore issues (Samsung devices)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One of Tyr's strong points is censorship circumvention: you can connect to any of hundreds of available Yggdrasil nodes, host your own, or even build a private network. Email freedom is literally in your hands.&lt;/p&gt;
    &lt;p&gt;Tyr runs a complete email server right on your Android device, using the Yggdrasil network for transport. The Yggmail mail server (built in Go) is embedded as a library inside the app and runs as a foreground service.&lt;/p&gt;
    &lt;p&gt;On top of Yggdrasil, it provides standard SMTP and IMAP protocols on localhost (127.0.0.1:1025 and 127.0.0.1:1143). Any email client can connect to these ports - but we recommend DeltaChat or ArcaneChat for the best P2P messaging experience.&lt;/p&gt;
    &lt;p&gt;Every Tyr installation generates unique Ed25519 cryptographic keys. Your mail address is derived from your public key, making it: &lt;code&gt;&amp;lt;64-hex-characters&amp;gt;@yggmail&lt;/code&gt;. This means your identity is cryptographically verifiable and cannot be spoofed.&lt;/p&gt;
    &lt;p&gt;DeltaChat and ArcaneChat are perfect companions for Tyr. These are messengers that use email protocols but provide modern chat interfaces. When you configure DeltaChat/ArcaneChat to use Tyr's local server:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;DeltaChat/ArcaneChat sends messages via SMTP to Tyr&lt;/item&gt;
      &lt;item&gt;Tyr wraps them in Yggmail protocol and sends through Yggdrasil&lt;/item&gt;
      &lt;item&gt;The recipient's Tyr receives the message via Yggdrasil&lt;/item&gt;
      &lt;item&gt;Their DeltaChat/ArcaneChat fetches it via IMAP from their local Tyr&lt;/item&gt;
      &lt;item&gt;All this happens peer-to-peer, with no central servers&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Tyr and complete the onboarding (set password, configure peers)&lt;/item&gt;
      &lt;item&gt;Start the Yggmail service in Tyr&lt;/item&gt;
      &lt;item&gt;Install DeltaChat or ArcaneChat from F-Droid or Google Play&lt;/item&gt;
      &lt;item&gt;In Tyr's main screen, tap "Setup DeltaChat/ArcaneChat"&lt;/item&gt;
      &lt;item&gt;Tyr will automatically open DeltaChat/ArcaneChat with pre-configured settings&lt;/item&gt;
      &lt;item&gt;Complete the setup and start chatting!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If automatic setup doesn't work:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Tyr and complete the onboarding (set password, configure peers)&lt;/item&gt;
      &lt;item&gt;Start the Yggmail service in Tyr&lt;/item&gt;
      &lt;item&gt;Copy your mail address from the main screen (looks like &lt;code&gt;abc123...@yggmail&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Install DeltaChat or ArcaneChat from F-Droid or Google Play&lt;/item&gt;
      &lt;item&gt;In DeltaChat/ArcaneChat, tap "Create a new profile"&lt;/item&gt;
      &lt;item&gt;Enter a name and optionally select an avatar&lt;/item&gt;
      &lt;item&gt;Tap "Use a different server" (below the login fields)&lt;/item&gt;
      &lt;item&gt;Enter your Yggmail address and the password you set in Tyr&lt;/item&gt;
      &lt;item&gt;Tap "✓" in the top right corner to complete setup&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Important: Tyr must be running for DeltaChat/ArcaneChat to send and receive messages. Enable auto-start in Tyr settings for seamless experience.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Android Studio (latest version recommended)&lt;/item&gt;
      &lt;item&gt;JDK 17&lt;/item&gt;
      &lt;item&gt;Android SDK (API 23-36)&lt;/item&gt;
      &lt;item&gt;Go 1.21+ and gomobile (only if rebuilding yggmail.aar)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone the repository:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone &amp;lt;repository-url&amp;gt;
cd Tyr&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Build debug APK:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./gradlew assembleDebug&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install to connected device:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./gradlew installDebug&lt;/code&gt;
    &lt;p&gt;APKs will be in &lt;code&gt;app/build/outputs/apk/debug/&lt;/code&gt; or &lt;code&gt;app/build/outputs/apk/release/&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;If you need to rebuild the Yggmail library:&lt;/p&gt;
    &lt;code&gt;cd ../yggmail/mobile
# On Windows:
..\build-android.bat
# On Unix:
gomobile bind -target=android -androidapi 23 -javapkg=com.jbselfcompany.tyr -ldflags="-checklinkname=0" -o yggmail.aar .&lt;/code&gt;
    &lt;p&gt;Then copy &lt;code&gt;yggmail.aar&lt;/code&gt; to &lt;code&gt;Tyr/app/libs/&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Language: Kotlin 2.2.20&lt;/item&gt;
      &lt;item&gt;Min SDK: 23 (Android 6.0)&lt;/item&gt;
      &lt;item&gt;Target SDK: 33 (Android 13)&lt;/item&gt;
      &lt;item&gt;Architecture: Layered (UI → Service → Data)&lt;/item&gt;
      &lt;item&gt;Mail server: Yggmail (Go library, embedded via gomobile)&lt;/item&gt;
      &lt;item&gt;Network: Yggdrasil overlay network&lt;/item&gt;
      &lt;item&gt;Localization: English, Russian&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;🔒 Security implementation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Passwords are encrypted using Android Keystore System (AES256-GCM encryption)&lt;/item&gt;
      &lt;item&gt;Automatic Keystore recovery: Handles Android Keystore issues on Samsung and other devices automatically&lt;/item&gt;
      &lt;item&gt;Network encryption provided by Yggdrasil Network for all peer-to-peer communications&lt;/item&gt;
      &lt;item&gt;Local-only access: SMTP/IMAP ports (1025/1143) are bound to localhost only, not accessible from network&lt;/item&gt;
      &lt;item&gt;Cryptographic identity: Ed25519 keys ensure your mail address cannot be spoofed&lt;/item&gt;
      &lt;item&gt;Encrypted backups: Configuration and keys can be backed up with password protection&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Yggmail: The mail transfer agent that powers Tyr&lt;/item&gt;
      &lt;item&gt;Mimir: P2P messenger on Yggdrasil (sister project)&lt;/item&gt;
      &lt;item&gt;Yggdrasil Network: The mesh network infrastructure&lt;/item&gt;
      &lt;item&gt;DeltaChat: Recommended email-based messenger client&lt;/item&gt;
      &lt;item&gt;ArcaneChat: Alternative email-based messenger client&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Tyr is open source software. The Yggmail library uses Mozilla Public License v. 2.0.&lt;/p&gt;
    &lt;p&gt;See &lt;code&gt;LICENSE&lt;/code&gt; file for full details&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/JB-SelfCompany/Tyr"/><published>2025-11-28T16:35:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46080161</id><title>Stellantis Is Spamming Owners' Screens with Pop-Up Ads for New Car Discounts</title><updated>2025-11-28T17:08:53.401440+00:00</updated><content>&lt;doc fingerprint="acf89966da2f210a"&gt;
  &lt;main&gt;
    &lt;p&gt;The internet is raging right now over Stellantis pushing marketing pop-ups to owners’ in-car screens. It’s obnoxious, to be sure, and it’s legit—we have confirmation from a Jeep driver as well as Stellantis itself. But this isn’t even the first time it’s happened, as we reported in February about Jeep advertising extended warranties in the same way.&lt;/p&gt;
    &lt;p&gt;Auto writer and all-around car guy Zerin Dube posted earlier this week about his WL Grand Cherokee’s “marketing notification” on X. The photo started popping off, and before long, others were sharing the same ad that was sent to their screens. Dube labeled it as “late stage capitalism,” which feels like an accurate descriptor.&lt;/p&gt;
    &lt;p&gt;Funny enough, Dube was in the market for a new Wrangler anyhow, and he took advantage of the $1,500 loyalty offer Jeep sent straight to his Grand Cherokee. He drove off the lot Thursday night in a new Rubicon X, so I guess you can say it worked.&lt;/p&gt;
    &lt;p&gt;Others online were less accepting of the ploy. Practically every repost of Dube’s photo decried Jeep and Stellantis at large, with some Ram and Chrysler drivers corroborating the ad’s rollout that spread across multiple brands. Most of the comments said something along the lines of, “Guess what I’m never buying.” Some made the informed prediction that this type of promotion will become commonplace in the industry before long.&lt;/p&gt;
    &lt;p&gt;For its part, Stellantis told The Drive that it sends out these notifications to “stay in contact with our owners at critical points in their ownership.” The in-vehicle message system is also used to notify drivers of vehicle recalls and health monitor alerts. A spokesperson for the brand said:&lt;/p&gt;
    &lt;p&gt;“Recently, a select group of owners received a special marketing notification in their vehicle, and we tailored this special offer to minimize any intrusions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The simple text message offering a $1,500 bonus incentive appears only on startup and while the vehicle is stationary&lt;/item&gt;
      &lt;item&gt;The message disappears when the vehicle begins moving, or the driver clicks the OK or X icon on the screen, or after 15 seconds&lt;/item&gt;
      &lt;item&gt;The message returns at the next key-on cycle only if the driver clicked on Remind Me Later, or they did not click OK or X&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;“Our goal is to deliver the best vehicle experience for our customers. As a result of these efforts, we have seen our customers take advantage of this offer,” the spokesperson said.&lt;/p&gt;
    &lt;p&gt;The Stellantis spokesperson concluded by saying that owners can permanently opt out of in-vehicle messaging by calling the company’s customer care line at 800-777-3600.&lt;/p&gt;
    &lt;p&gt;The $1,500 loyalty bonus is just one of many discounts that Stellantis dealers are stacking in order to move more units. I reported last week that storming Ford Bronco sales are genuinely threatening the Wrangler’s spot atop the segment, and as Dube shared on X, he got something like $16,500 off his new Jeep. Apparently, now’s a good time to buy if you can stand the occasional spam on your car’s screen.&lt;/p&gt;
    &lt;p&gt;The last time this happened, Stellantis was advertising extended warranties to owners via their infotainment. Many were frustrated as the offer continued to show, even after acknowledging it by pressing “OK.” What’s more, others saw the ad despite their car exceeding the mileage limit mentioned in the promotion.&lt;/p&gt;
    &lt;p&gt;Connected cars, man. Gotta love ’em.&lt;/p&gt;
    &lt;p&gt;Got a tip or question for the author? Contact them directly: caleb@thedrive.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.thedrive.com/news/stellantis-is-spamming-owners-screens-with-pop-up-ads-for-new-car-discounts"/><published>2025-11-28T16:37:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46080424</id><title>Apple and Intel Rumored to Partner on Mac Chips</title><updated>2025-11-28T17:08:53.259079+00:00</updated><content>&lt;doc fingerprint="6c84e975532b1ffc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h1"&gt;Apple and Intel Rumored to Partner on Mac Chips Again in a New Way&lt;/head&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;p&gt;While all Macs are now powered by Apple's custom-designed chips, a new rumor claims that Apple may rekindle its partnership with Intel, albeit in a new and limited way.&lt;/p&gt;
          &lt;p&gt;&lt;lb/&gt;Apple supply chain analyst Ming-Chi Kuo today said Intel is expected to begin shipping Apple's lowest-end M-series chip as early as mid-2027. &lt;/p&gt;
          &lt;p&gt;Kuo said Apple plans to utilize Intel's 18A process, which is the "earliest available sub-2nm advanced node manufactured in North America."&lt;/p&gt;
          &lt;p&gt;If this rumor proves to be accurate, Intel could supply Apple with M6 or M7 chips for future MacBook Air, iPad Air, and iPad Pro models at a minimum. However, while previous Intel chips for Macs were designed by Intel and based on x86 architecture, M-series chips are designed by Apple and use Arm architecture. Intel would only assist with manufacturing.&lt;/p&gt;
          &lt;p&gt;TSMC would continue to supply the majority of Apple's M-series chips.&lt;/p&gt;
          &lt;p&gt;Kuo said that Apple choosing to have Intel supply its lowest-end M-series chip would appease the Trump administration's desire for "Made in USA" products, and it would also help Apple to diversify its supply chain for manufacturing.&lt;/p&gt;
          &lt;p&gt;Apple began transitioning away from Intel processors in Macs in 2020, and its own M-series chips continue to provide industry-leading performance per watt.&lt;/p&gt;
          &lt;p&gt;Apple previously announced that macOS Tahoe will be the final major macOS release that supports Intel-based Macs with x86 architecture.&lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;head rend="h2"&gt;Popular Stories&lt;/head&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple's online store is going down for a few hours on a rolling country-by-country basis right now, but do not get your hopes up for new products. Apple takes its online store down for a few hours ahead of Black Friday every year to tease/prepare for its annual gift card offer with the purchase of select products. The store already went down and came back online in Australia and New Zealand, ...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple's first foldable iPhone is expected to launch alongside the iPhone 18 Pro models in fall 2026, and it's shaping up to include three standout features that could set it apart from the competition. The book-style foldable will reportedly feature an industry-first 24-megapixel under-display camera built into the inner display, according to a recent JP Morgan equity research report. That...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple recently teamed up with Japanese fashion brand ISSEY MIYAKE to create the iPhone Pocket, a limited-edition knitted accessory designed to carry an iPhone. However, it is now completely sold out in all countries where it was released. iPhone Pocket became available to order on Apple's online store starting Friday, November 14, in the United States, France, China, Italy, Japan, Singapore, ...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;We've been focusing on deals on physical products over the past few weeks, but Black Friday is also a great time of year to purchase a streaming membership. Some of the biggest services have great discounts for new and select returning members this week, including Disney+, Hulu, Paramount+, Peacock, and more. Note: MacRumors is an affiliate partner with some of these vendors. When you click a...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;We've been focusing on deals on physical products over the past few weeks, but Black Friday is also a great time of year to purchase a streaming membership. Some of the biggest services have great discounts for new and select returning members this week, including Apple TV, Disney+, Hulu, Paramount+, Peacock, and more. Note: MacRumors is an affiliate partner with some of these vendors. When...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Black Friday is in full swing, and as always this is the best time of the year to shop for great deals, including popular Apple products like AirPods, iPad, Apple Watch, and more. In this article, the majority of the discounts will be found on Amazon. Note: MacRumors is an affiliate partner with some of these vendors. When you click a link and make a purchase, we may receive a small payment,...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Singapore has ordered Apple to block or filter messages on iMessage that impersonate government agencies, requiring the company to implement new anti-spoofing protections by December as part of efforts to curb rising online scams, the Straits Times reports. Singapore's Ministry of Home Affairs (MHA) said that it had issued an Implementation Directive to Apple under the Online Criminal Harms...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Apple's disappointing iPhone Air sales are causing major Chinese mobile vendors to scrap or freeze their own ultra-thin phone projects, according to reports coming out of Asia. Since the iPhone Air launched in September, there have been reports of poor sales and manufacturing cuts, while Apple's supply chain has scaled back shipments and production. Apple supplier Foxconn has...&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.macrumors.com/2025/11/28/intel-rumored-to-supply-new-mac-chip/"/><published>2025-11-28T17:00:46+00:00</published></entry></feed>