<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-22T18:16:33.350677+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46345205</id><title>How I protect my Forgejo instance from AI web crawlers</title><updated>2025-12-22T18:16:39.682127+00:00</updated><content>&lt;doc fingerprint="44e6f9513b184b8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;TL;DR:&lt;/head&gt;
    &lt;p&gt;Put that in your nginx config:&lt;/p&gt;
    &lt;quote&gt;
      &lt;code&gt;location / {
  # needed to still allow git clone from http/https URLs
  if ($http_user_agent ~* "git/|git-lfs/") {
        set $bypass_cookie 1;
  }
  # If we see the expected cookie; we could also bypass the blocker page
  if ($cookie_Yogsototh_opens_the_door = "1") {
        set $bypass_cookie 1;
  }
  # Redirect to 418 if neither condition is met
  if ($bypass_cookie != 1) {
     add_header Content-Type text/html always;
     return 418 '&amp;lt;script&amp;gt;document.cookie = "Yogsototh_opens_the_door=1; Path=/;"; window.location.reload();&amp;lt;/script&amp;gt;';
  }
  # rest of your nginx config
&lt;/code&gt;
    &lt;/quote&gt;
    &lt;p&gt;Preferably run a string replace from &lt;code&gt;Yogsototh_opens_the_door&lt;/code&gt; to your own personal Cookie
name.&lt;/p&gt;
    &lt;p&gt;Main advantage, is that it is almost invisible to the users of my website compartively to other solutions like Anubis.&lt;/p&gt;
    &lt;head rend="h1"&gt;More detail&lt;/head&gt;
    &lt;p&gt;Not so long ago I started to host my code to forgejo. There is a promise that in the future it will support federation and forgejo is the same project that is used for codeberg.&lt;/p&gt;
    &lt;p&gt;The only problem I had was one day, I discovered that my entire node was down. At first I didn't investigate and just restarted the node. But soon after a few hours, it was down again. Looking at the reason, clearly thousands of requests that looked at every commit which put too much pressure on the system. Who could be so interested in using the web API to look at every commit instead, of… you know, clone the repository locally and explore it. Quickly, yep, like so many of you, I discovered that tons of crawlers that did not respect the &lt;code&gt;robots.txt&lt;/code&gt;
are crawling my forgejo instance until death ensues.&lt;/p&gt;
    &lt;p&gt;So I had no choice, I first used a radical approach and blocked my website entirely except from me. But hey, why having a public forge if not for people to be able to look into it time to time?&lt;/p&gt;
    &lt;p&gt;I then installed Anubis, but it wasn't really for me. It is way too heavy for my needs, not as easy as I would have hoped to configure and install.&lt;/p&gt;
    &lt;p&gt;Then I saw this article You don't need anubis on lobste.rs using a simple configuration in caddy that should block these pesky crawlers. I made some adjustments to adapt it to nginx. For now, this is working perfectly well, my users are just redirected once, without really noticing it. And they could use forgejo as they could before. And this puts the crawlers away.&lt;/p&gt;
    &lt;p&gt;The strategy is pretty basic; in fact, a lot less advanced than the strategy adopted by Anubis. For every access of my website, I just check if the user has a specific cookie set. If not, I redirect the user to a 418 HTML page containing some js code to execute that set this specific cookie and reload the page.&lt;/p&gt;
    &lt;p&gt;That's it.&lt;/p&gt;
    &lt;p&gt;I also tried to return a 302 and add a cookie from the response without javascript, but the crawlers are immune to that second strategy. Unfortunately this means, my website could only be seen if you enable javascript in your browser. I feel this is acceptable. I guess, someday this very basic protection will not be enough and my forgejo instance will break again, and I will be forced to use more advanced system like Anubis or perhaps even iocaine.&lt;/p&gt;
    &lt;p&gt;I hope this could be helpful, because, I recently saw many discussions on that subject where people were not totally happy to use Anubis, while at least for me, this quick dirty fix does the trick. And I am fully aware that this would be very easy to bypass. But for now, I think the volume is more important than the quality for these crawlers and it may take a while for them to need to adapt. Also, by publishing this, I know if too many people use the same trick, quickly, these crawlers will adapt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://her.esy.fun/posts/0031-how-i-protect-my-forgejo-instance-from-ai-web-crawlers/index.html"/><published>2025-12-21T14:46:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46348847</id><title>Disney Imagineering Debuts Next-Generation Robotic Character, Olaf</title><updated>2025-12-22T18:16:39.536299+00:00</updated><content>&lt;doc fingerprint="ebf30b7df696007b"&gt;
  &lt;main&gt;
    &lt;p&gt;Disneyland Paris saw a groundbreaking moment today, where Bruce Vaughn, President and Chief Creative Officer of Walt Disney Imagineering, and Natacha Rafalski, Présidente of Disneyland Paris, introduced a next-generation robotic character representing Olaf, the beloved snowman from Walt Disney Animation Studios’ Frozen.&lt;/p&gt;
    &lt;p&gt;This debut marks a new chapter in Disney character innovation, one where technology, storytelling, and collaboration come together to bring screen to reality.&lt;/p&gt;
    &lt;head rend="h2"&gt;Innovation at the Core: From Screen to Reality&lt;/head&gt;
    &lt;p&gt;From the way he moves to the way he looks, every gesture and detail is crafted to reflect the Olaf audiences have seen in the film — alive, curious, and unmistakably himself. As for his snow-like shimmer that catches the light just like fresh snow, this was enhanced by iridescent fibers. These details make Olaf one of the most expressive and true-to-life characters built, and he’s soon making his debut at Disney parks.&lt;/p&gt;
    &lt;p&gt;Our roots are in animation with Walt Disney pioneering early hand-drawn films and today, Walt Disney Animation Studios and Pixar Animation Studios continue that tradition. We collaborated closely with the film’s original animators at Walt Disney Animation Studios to ensure every gesture felt true to the character. This isn’t just about replicating the animation, it’s about emulating the creators’ intent.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Technology Behind the Magic&lt;/head&gt;
    &lt;p&gt;Home to some of the best storytellers in the world, we’re continuously pushing the boundaries of innovation and technology — in fact it is in our DNA.&lt;/p&gt;
    &lt;p&gt;Like everything at Disney, we always start with the story, and our number one priority is to build storytelling technology that empowers our Disney Imagineers to breathe life into our characters.&lt;/p&gt;
    &lt;p&gt;While the BDX droids — the Star Wars free roaming robotic characters that mimic movements in a simulation — have been interacting with guests for a while now, Olaf presents a far greater challenge: an animated character with non-physical movements. To make Olaf as authentic as possible, the team used a branch of artificial intelligence called reinforcement learning, pushing the limits of hardware to achieve the creative intent of the artists.&lt;/p&gt;
    &lt;p&gt;It takes humans years to master walking and even longer to perform graceful motions. Deep reinforcement learning helps him acquire these skills in a fraction of the time.&lt;/p&gt;
    &lt;p&gt;Olaf’s “snow” also moves differently than the hard shells of other robotic characters, and he can fully articulate his mouth, eyes, and removable carrot nose and arms. Most importantly, Olaf can speak and engage in conversations, creating a truly one-of-a-kind experience.&lt;/p&gt;
    &lt;p&gt;Innovation takes many forms across our parks, experiences, and products – all focused on improving the guest experience and bringing joy to fans around the world. And what’s most exciting is that we’re just getting started!&lt;/p&gt;
    &lt;p&gt;The BDX Droids, self-balancing H.E.R.B.I.E., and now Olaf represent increasing levels of performance and innovation in bringing Disney characters to life. The speed at which we can create new characters and introduce them to guests is unprecedented. We’re scaling bigger than ever, working to bring more emotive, expressive, and surprising characters to our experiences around the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where Guests Can See Olaf&lt;/head&gt;
    &lt;p&gt;Olaf will soon venture out into the unknown, eager to see guests at:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arendelle Bay Show in World of Frozen, the new immersive world coming soon to Disney Adventure World at Disneyland Paris.&lt;/item&gt;
      &lt;item&gt;Limited-time special appearances at World of Frozen at Hong Kong Disneyland Resort.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Looking for a warm hug now? You can discover how Olaf, along with other exciting breakthroughs from Walt Disney Imagineering Research &amp;amp; Development, came to life at in the latest episode of We Call It Imagineering.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://disneyparksblog.com/disney-experiences/robotic-olaf-marks-new-era-of-disney-innovation/"/><published>2025-12-21T21:46:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46352231</id><title>Debian's Git Transition</title><updated>2025-12-22T18:16:38.934022+00:00</updated><content>&lt;doc fingerprint="8763fa0d88c5d592"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Debian’s git transition&lt;/head&gt;Dec. 21st, 2025 11:24 pm&lt;p&gt;tl;dr:&lt;/p&gt;&lt;p&gt;There is a Debian git transition plan. It’s going OK so far but we need help, especially with outreach and updating Debian’s documentation.&lt;/p&gt;&lt;head rend="h1"&gt;Goals of the Debian git transition project&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;Everyone who interacts with Debian source code should be able to do so entirely in git.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;That means, more specifically:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;All examination and edits to the source should be performed via normal git operations.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Source code should be transferred and exchanged as git data, not tarballs. git should be the canonical form everywhere.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Upstream git histories should be re-published, traceably, as part of formal git releases published by Debian.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;No-one should have to learn about Debian Source Packages, which are bizarre, and have been obsoleted by modern version control.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;This is very ambitious, but we have come a long way!&lt;/p&gt;&lt;head rend="h2"&gt;Achievements so far, and current status&lt;/head&gt;&lt;p&gt;We have come a very long way. But, there is still much to do - especially, the git transition team needs your help with adoption, developer outreach, and developer documentation overhaul.&lt;/p&gt;&lt;p&gt;We’ve made big strides towards goals 1 and 4. Goal 2 is partially achieved: we currently have dual running. Goal 3 is within our reach but depends on widespread adoption of tag2upload (and/or dgit push).&lt;/p&gt;&lt;p&gt;Downstreams and users can obtain the source code of any Debian package in git form. (dgit clone, 2013). They can then work with this source code completely in git, including building binaries, merging new versions, even automatically (eg Raspbian, 2016), and all without having to deal with source packages at all (eg Wikimedia 2025).&lt;/p&gt;&lt;p&gt;A Debian maintainer can maintain their own package entirely in git. They can obtain upstream source code from git, and do their packaging work in git (&lt;code&gt;git-buildpackage&lt;/code&gt;, 2006).
&lt;/p&gt;&lt;p&gt;Every Debian maintainer can (and should!) release their package from git reliably and in a standard form (dgit push, 2013; tag2upload, 2025). This is not only more principled, but also more convenient, and with better UX, than pre-dgit tooling like &lt;code&gt;dput&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;Indeed a Debian maintainer can now often release their changes to Debian, from git, using only git branches (so no tarballs). Releasing to Debian can be simply pushing a signed tag (tag2upload, 2025).&lt;/p&gt;&lt;p&gt;A Debian maintainer can maintain a stack of changes to upstream source code in git (gbp pq 2009). They can even maintain such a delta series as a rebasing git branch, directly buildable, and use normal &lt;code&gt;git rebase&lt;/code&gt; style operations to edit their changes, (git-dpm, 2010; git-debrebase, 2018)
&lt;/p&gt;&lt;p&gt;An authorised Debian developer can do a modest update to any package in Debian, even one maintained by someone else, working entirely in git in a standard and convenient way (dgit, 2013).&lt;/p&gt;&lt;p&gt;Debian contributors can share their work-in-progress on git forges and collaborate using merge requests, git based code review, and so on. (Alioth, 2003; Salsa, 2018.)&lt;/p&gt;&lt;head rend="h1"&gt;Core engineering principle&lt;/head&gt;&lt;p&gt;The Debian git transition project is based on one core engineering principle:&lt;/p&gt;&lt;p&gt;Every Debian Source Package can be losslessly converted to and from git.&lt;/p&gt;&lt;p&gt;In order to transition away from Debian Source Packages, we need to gateway between the old &lt;code&gt;dsc&lt;/code&gt; approach, and the new git approach.
&lt;/p&gt;&lt;p&gt;This gateway obviously needs to be bidirectional: source packages uploaded with legacy tooling like &lt;code&gt;dput&lt;/code&gt; need to be imported into a canonical git representation; and of course git branches prepared by developers need to be converted to source packages for the benefit of legacy downstream systems (such as the Debian Archive and &lt;code&gt;apt source&lt;/code&gt;).
&lt;/p&gt;&lt;p&gt;This bidirectional gateway is implemented in &lt;code&gt;src:dgit&lt;/code&gt;, and is allowing us to gradually replace dsc-based parts of the Debian system with git-based ones.
&lt;/p&gt;&lt;head rend="h2"&gt;Correspondence between dsc and git&lt;/head&gt;&lt;p&gt;A faithful bidirectional gateway must define an invariant:&lt;/p&gt;&lt;p&gt;The canonical git tree, corresponding to a .dsc, is the tree resulting from &lt;code&gt;dpkg-source -x&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;This canonical form is sometimes called the “dgit view”. It’s sometimes not the same as the maintainer’s git branch, because many maintainers are still working with “patches-unapplied” git branches. More on this below.&lt;/p&gt;&lt;p&gt;(For &lt;code&gt;3.0 (quilt)&lt;/code&gt; .dscs, the canonical git tree doesn’t include the quilt &lt;code&gt;.pc&lt;/code&gt; directory.)
&lt;/p&gt;&lt;head rend="h2"&gt;Patches-applied vs patches-unapplied&lt;/head&gt;&lt;p&gt;The canonical git format is “patches applied”. That is:&lt;/p&gt;&lt;p&gt;If Debian has modified the upstream source code, a normal git clone of the canonical branch gives the modified source tree, ready for reading and building.&lt;/p&gt;&lt;p&gt;Many Debian maintainers keep their packages in a different git branch format, where the changes made by Debian, to the upstream source code, are in actual &lt;code&gt;patch&lt;/code&gt; files in a &lt;code&gt;debian/patches/&lt;/code&gt; subdirectory.
&lt;/p&gt;&lt;p&gt;Patches-applied has a number of important advantages over patches-unapplied:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;It is familiar to, and doesn’t trick, outsiders to Debian. Debian insiders radically underestimate how weird “patches-unapplied” is. Even expert software developers can get very confused or even accidentally build binaries without security patches!&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Making changes can be done with just normal git commands, eg&lt;/p&gt;&lt;code&gt;git commit&lt;/code&gt;. Many Debian insiders working with patches-unapplied are still using&lt;code&gt;quilt(1)&lt;/code&gt;, a footgun-rich contraption for working with patch files!&lt;/item&gt;&lt;item&gt;&lt;p&gt;When developing, one can make changes to upstream code, and to Debian packaging, together, without ceremony. There is no need to switch back and forth between patch queue and packaging branches (as with&lt;/p&gt;&lt;code&gt;gbp pq&lt;/code&gt;), no need to “commit” patch files, etc. One can always edit every file and commit it with&lt;code&gt;git commit&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The downside is that, with the (bizarre) &lt;code&gt;3.0 (quilt)&lt;/code&gt; source format, the patch files files in &lt;code&gt;debian/patches/&lt;/code&gt; must somehow be kept up to date. Nowadays though, tools like &lt;code&gt;git-debrebase&lt;/code&gt; and &lt;code&gt;git-dpm&lt;/code&gt; (and dgit for NMUs) make it very easy to work with patches-applied git branches. &lt;code&gt;git-debrebase&lt;/code&gt; can deal very ergonomically even with big patch stacks.
&lt;/p&gt;&lt;p&gt;(For smaller packages which usually have no patches, plain &lt;code&gt;git merge&lt;/code&gt; with an upstream git branch, and a much simpler dsc format, sidesteps the problem entirely.)
&lt;/p&gt;&lt;head rend="h3"&gt;Prioritising Debian’s users (and other outsiders)&lt;/head&gt;&lt;p&gt;We want everyone to be able to share and modify the software that they interact with. That means we should make source code truly accessible, on the user’s terms.&lt;/p&gt;&lt;p&gt;Many of Debian’s processes assume everyone is an insider. It’s okay that there are Debian insiders and that people feel part of something that they worked hard to become involved with. But lack of perspective can lead to software which fails to uphold our values.&lt;/p&gt;&lt;p&gt;Our source code practices — in particular, our determination to share properly (and systematically) — are a key part of what makes Debian worthwhile at all. Like Debian’s installer, we want our source code to be useable by Debian outsiders.&lt;/p&gt;&lt;p&gt;This is why we have chosen to privilege a git branch format which is more familiar to the world at large, even if it’s less popular in Debian.&lt;/p&gt;&lt;head rend="h2"&gt;Consequences, some of which are annoying&lt;/head&gt;&lt;p&gt;The requirement that the conversion be bidirectional, lossless, and context-free can be inconvenient.&lt;/p&gt;&lt;p&gt;For example, we cannot support &lt;code&gt;.gitattributes&lt;/code&gt; which modify files during git checkin and checkout. &lt;code&gt;.gitattributes&lt;/code&gt; cause the meaning of a git tree to depend on the context, in possibly arbitrary ways, so the conversion from git to source package wouldn’t be stable. And, worse, some source packages might not to be representable in git at all.
&lt;/p&gt;&lt;p&gt;Another example: Maintainers often have existing git branches for their packages, generated with pre-dgit tooling which is less careful and less principled than ours. That can result in discrepancies between git and dsc, which need to be resolved before a proper git-based upload can succeed.&lt;/p&gt;&lt;p&gt;That some maintainers use patches-unapplied, and some patches-unapplied, means that there has to be some kind of conversion to a standard git representation. Choosing the less-popular patches-applied format as the canonical form, means that many packages need their git representation converted. It also means that user- and outsider-facing branches from &lt;code&gt;{browse,git}.dgit.d.o&lt;/code&gt; and &lt;code&gt;dgit clone&lt;/code&gt; are not always compatible with maintainer branches on Salsa. User-contributed changes need cherry-picking rather than merging, or conversion back to the maintainer format. The good news is that dgit can automate much of this, and the manual parts are usually easy git operations.
&lt;/p&gt;&lt;head rend="h1"&gt;Distributing the source code as git&lt;/head&gt;&lt;p&gt;Our source code management should be normal, modern, and based on git. That means the Debian Archive is obsolete and needs to be replaced with a set of git repositories.&lt;/p&gt;&lt;p&gt;The replacement repository for source code formally released to Debian is &lt;code&gt;*.dgit.debian.org&lt;/code&gt;. This contains all the git objects for every git-based upload since 2013, including the signed tag for each released package version.
&lt;/p&gt;&lt;p&gt;The plan is that it will contain a git view of every uploaded Debian package, by centrally importing all legacy uploads into git.&lt;/p&gt;&lt;head rend="h2"&gt;Tracking the relevant git data, when changes are made in the legacy Archive&lt;/head&gt;&lt;p&gt;Currently, many critical source code management tasks are done by changes to the legacy Debian Archive, which works entirely with dsc files (and the associated tarballs etc). The contents of the Archive are therefore still an important source of truth. But, the Archive’s architecture means it cannot sensibly directly contain git data.&lt;/p&gt;&lt;p&gt;To track changes made in the Archive, we added the &lt;code&gt;Dgit:&lt;/code&gt; field to the &lt;code&gt;.dsc&lt;/code&gt; of a git-based upload (2013). This declares which git commit this package was converted from. and where those git objects can be obtained.
&lt;/p&gt;&lt;p&gt;Thus, given a Debian Source Package from a git-based upload, it is possible for the new git tooling to obtain the equivalent git objects. If the user is going to work in git, there is no need for any tarballs to be downloaded: the git data could be obtained from the depository using the git protocol.&lt;/p&gt;&lt;p&gt;The signed tags, available from the git depository, have standardised metdata which gives traceability back to the uploading Debian contributor.&lt;/p&gt;&lt;head rend="h2"&gt;Why *.dgit.debian.org is not Salsa&lt;/head&gt;&lt;p&gt;We need a git depository - a formal, reliable and permanent git repository of source code actually released to Debian.&lt;/p&gt;&lt;p&gt;Git forges like Gitlab can be very convenient. But Gitlab is not sufficiently secure, and too full of bugs, to be the principal and only archive of all our source code. (The “open core” business model of the Gitlab corporation, and the constant-churn development approach, are critical underlying problems.)&lt;/p&gt;&lt;p&gt;Our git depository lacks forge features like Merge Requests. But:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;It is dependable, both in terms of reliability and security.&lt;/item&gt;&lt;item&gt;It is append-only: once something is pushed, it is permanently recorded.&lt;/item&gt;&lt;item&gt;Its access control is precisely that of the Debian Archive.&lt;/item&gt;&lt;item&gt;Its ref namespace is standardised and corresponds to Debian releases.&lt;/item&gt;&lt;item&gt;Pushes are authorised by PGP signatures, not ssh keys, so traceable.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The dgit git depository outlasted Alioth and it may well outlast Salsa.&lt;/p&gt;&lt;p&gt;We need both a good forge, and the &lt;code&gt;*.dgit.debian.org&lt;/code&gt; formal git depository.
&lt;/p&gt;&lt;head rend="h1"&gt;Roadmap&lt;/head&gt;&lt;head rend="h2"&gt;In progress&lt;/head&gt;&lt;p&gt;Right now we are quite focused on tag2upload.&lt;/p&gt;&lt;p&gt;We are working hard on eliminating the remaining issues that we feel need to be addressed before declaring the service out of beta.&lt;/p&gt;&lt;head rend="h2"&gt;Future Technology&lt;/head&gt;&lt;head rend="h3"&gt;Whole-archive dsc importer&lt;/head&gt;&lt;p&gt;Currently, the git depository only has git data for git-based package updates (tag2upload and dgit push). Legacy dput-based uploads are not currently present there. This means that the git-based and legacy uploads must be resolved client-side, by &lt;code&gt;dgit clone&lt;/code&gt;.
&lt;/p&gt;&lt;p&gt;We will want to start importing legacy uploads to git.&lt;/p&gt;&lt;p&gt;Then downstreams and users will be able to get the source code for any package simply with &lt;code&gt;git clone&lt;/code&gt;, even if the maintainer is using legacy upload tools like dput.
&lt;/p&gt;&lt;head rend="h3"&gt;Support for git-based uploads to security.debian.org&lt;/head&gt;&lt;p&gt;Security patching is a task which would particularly benefit from better and more formal use of git. git-based approaches to applying and backporting security patches are much more convenient than messing about with actual patch files.&lt;/p&gt;&lt;p&gt;Currently, one can use git to help prepare a security upload, but it often involves starting with a dsc import (which lacks the proper git history) or figuring out a package maintainer’s unstandardised git usage conventions on Salsa.&lt;/p&gt;&lt;p&gt;And it is not possible to properly perform the security release as git.&lt;/p&gt;&lt;head rend="h3"&gt;Internal Debian consumers switch to getting source from git&lt;/head&gt;&lt;p&gt;Buildds, QA work such as lintian checks, and so on, could be simpler if they don’t need to deal with source packages.&lt;/p&gt;&lt;p&gt;And since git is actually the canonical form, we want them to use it directly.&lt;/p&gt;&lt;head rend="h3"&gt;Problems for the distant future&lt;/head&gt;&lt;p&gt;For decades, Debian has been built around source packages. Replacing them is a long and complex process. Certainly source packages are going to continue to be supported for the foreseeable future.&lt;/p&gt;&lt;p&gt;There are no doubt going to be unanticipated problems. There are also foreseeable issues: for example, perhaps there are packages that work very badly when represented in git. We think we can rise to these challenges as they come up.&lt;/p&gt;&lt;head rend="h1"&gt;Mindshare and adoption - please help!&lt;/head&gt;&lt;p&gt;We and our users are very pleased with our technology. It is convenient and highly dependable.&lt;/p&gt;&lt;p&gt;&lt;code&gt;dgit&lt;/code&gt; in particular is superb, even if we say so ourselves. As technologists, we have been very focused on building good software, but it seems we have fallen short in the marketing department.
&lt;/p&gt;&lt;head rend="h2"&gt;A rant about publishing the source code&lt;/head&gt;&lt;p&gt;git is the preferred form for modification.&lt;/p&gt;&lt;p&gt;Our upstreams are overwhelmingly using git. We are overwhelmingly using git. It is a scandal that for many packages, Debian does not properly, formally and officially publish the git history.&lt;/p&gt;&lt;p&gt;Properly publishing the source code as git means publishing it in a way that means that anyone can automatically and reliably obtain and build the exact source code corresponding to the binaries. The test is: could you use that to build a derivative?&lt;/p&gt;&lt;p&gt;Putting a package in git on Salsa is often a good idea, but it is not sufficient. No standard branch structure git on Salsa is enforced, nor should it be (so it can’t be automatically and reliably obtained), the tree is not in a standard form (so it can’t be automatically built), and is not necessarily identical to the source package. So &lt;code&gt;Vcs-Git&lt;/code&gt; fields, and git from Salsa, will never be sufficient to make a derivative.
&lt;/p&gt;&lt;p&gt;Debian is not publishing the source code!&lt;/p&gt;&lt;p&gt;The time has come for proper publication of source code by Debian to no longer be a minority sport. Every maintainer of a package whose upstream is using git (which is nearly all packages nowadays) should be basing their work on upstream git, and properly publishing that via tag2upload or dgit.&lt;/p&gt;&lt;p&gt;And it’s not even difficult! The modern git-based tooling provides a far superior upload experience.&lt;/p&gt;&lt;head rend="h3"&gt;A common misunderstanding&lt;/head&gt;&lt;p&gt;dgit push is not an alternative to gbp pq or quilt. Nor is tag2upload. These upload tools complement your existing git workflow. They replace and improve source package building/signing and the subsequent dput. If you are using one of the usual git layouts on salsa, and your package is in good shape, you can adopt tag2upload and/or dgit push right away.&lt;/p&gt;&lt;p&gt;&lt;code&gt;git-debrebase&lt;/code&gt; is distinct and does provides an alternative way to manage your git packaging, do your upstream rebases, etc.
&lt;/p&gt;&lt;head rend="h2"&gt;Documentation&lt;/head&gt;&lt;p&gt;Debian’s documentation all needs to be updated, including particularly instructions for packaging, to recommend use of git-first workflows. Debian should not be importing git-using upstreams’ “release tarballs” into git. (Debian outsiders who discover this practice are typically horrified.) We should use only upstream git, work only in git, and properly release (and publish) in git form.&lt;/p&gt;&lt;p&gt;We, the git transition team, are experts in the technology, and can provide good suggestions. But we do not have the bandwidth to also engage in the massive campaigns of education and documentation updates that are necessary — especially given that (as with any programme for change) many people will be sceptical or even hostile.&lt;/p&gt;&lt;p&gt;So we would greatly appreciate help with writing and outreach.&lt;/p&gt;&lt;head rend="h1"&gt;Personnel&lt;/head&gt;&lt;p&gt;We consider ourselves the Debian git transition team.&lt;/p&gt;&lt;p&gt;Currently we are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Ian Jackson. Author and maintainer of dgit and git-debrebase. Co-creator of tag2upload. Original author of dpkg-source, and inventor in 1996 of Debian Source Packages. Alumnus of the Debian Technical Committee.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Sean Whitton. Co-creator of the tag2upload system; author and maintainer of git-debpush. Co-maintainer of dgit. Debian Policy co-Editor. Former Chair of the Debian Technical Committee.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We wear the following hats related to the git transition:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Maintainers of src:dgit&lt;/item&gt;&lt;item&gt;tag2upload Delegates; operators of the tag2upload service.&lt;/item&gt;&lt;item&gt;service operators of the git depository *.dgit.debian.org.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;You can contact us:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;By email: Ian Jackson ijackson@chiark.greenend.org.uk; Sean Whitton spwhitton@spwhitton.name; git-debpush@packages.d.o.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;By filing bugs in the Debian Bug System against src:dgit.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;On OFTC IRC, as&lt;/p&gt;&lt;code&gt;Diziet&lt;/code&gt;and&lt;code&gt;spwhitton&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;We do most of our heavy-duty development on Salsa.&lt;/p&gt;&lt;head rend="h2"&gt;Thanks&lt;/head&gt;&lt;p&gt;Particular thanks are due to Joey Hess, who, in the now-famous design session in Vaumarcus in 2013, helped invent dgit. Since then we have had a lot of support: most recently political support to help get tag2upload deployed, but also, over the years, helpful bug reports and kind words from our users, as well as translations and code contributions.&lt;/p&gt;&lt;p&gt;Many other people have contributed more generally to support for working with Debian source code in git. We particularly want to mention Guido Günther (git-buildpackage); and of course Alexander Wirt, Joerg Jaspert, Thomas Goirand and Antonio Terceiro (Salsa administrators); and before them the Alioth administrators.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://diziet.dreamwidth.org/20436.html"/><published>2025-12-22T08:24:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46352310</id><title>Show HN: Backlog – a public repository of real work problems</title><updated>2025-12-22T18:16:38.460725+00:00</updated><link href="https://www.worldsbacklog.com/"/><published>2025-12-22T08:42:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46352565</id><title>The ancient monuments saluting the winter solstice</title><updated>2025-12-22T18:16:38.305709+00:00</updated><content>&lt;doc fingerprint="bd08521d25e3a112"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'It's a moment of death and rebirth': The ancient monuments saluting the winter solstice&lt;/head&gt;
    &lt;p&gt;Dozens of mysterious structures across the Northern Hemisphere – some nearly 5,000 years old – align precisely to frame the rising and setting Sun during midwinter's shortest day. What motivated people to construct these solar-calibrated masterpieces?&lt;/p&gt;
    &lt;p&gt;The winter solstice, which usually falls on 21 or 22 December in the Northern Hemisphere each year, marks the moment that one yearly cycle comes to an end and another is born. It is the day with the smallest number of sunlight hours in the calendar, and once it's over, the days lengthen again incrementally until the summer solstice in June.&lt;/p&gt;
    &lt;p&gt;The significance of this day is manifested in ancient monuments that were designed to acknowledge and celebrate its passing. One example is Maeshowe tomb in Orkney. To the untrained eye this burial cairn, created around 2800BC, looks like a grassy hillock – but it conceals a cuboid, stone-clad sepulchre and a 33ft (10m) long entry corridor oriented to the south-west. During midwinter, three weeks either side of the winter solstice, the setting Sun aims directly down the corridor and emanates its light into the tomb.&lt;/p&gt;
    &lt;p&gt;When the sky is cloudless, the light seems to carve a golden aperture into the tomb's rear wall – a sacrament of pure light. These days of radiance are interrupted by the solstice itself, when blackness temporarily takes over. But daylight reappears soon after, to blaze for another few days as if in celebration of the promise of nature's rejuvenation in spring.&lt;/p&gt;
    &lt;p&gt;We will probably never know the specific beliefs and rituals that inspired Maeshowe tomb. But it's nonetheless possible to understand the enormous significance of the winter solstice as the "year's midnight", both as the darkest moment in the calendar and the pivot to six future months of greater illumination. It was a moment of death and rebirth, and a reminder of the cyclical nature of time.&lt;/p&gt;
    &lt;p&gt;In the deep past, understanding the markers of nature's clockwork – including solstices – was a matter of survival. Predicting the recurrent patterns of animal migration, for example, could help successful hunting and fishing. Knowing when the climate was likely to change meant being able to adapt and survive. In pre-agricultural societies, it helped people anticipate the availability and location of edible roots, nuts and plants.&lt;/p&gt;
    &lt;p&gt;After the introduction of farming, around 9000BC, it was essential – for successful planting and harvesting – to anticipate the timing of seasonal changes. Monuments that calculated time had practical value, but it's likely that they also embodied spiritual beliefs in Neolithic times too, with the winter solstice being of particular importance. This very ancient recognition of the solstice's significance even echoes through to the modern world. The word "Yule", now associated with the winter holiday period, derives from the historic Norse festival of Jól, which was based around the winter solstice. Modern Christmas traditions recall bygone midwinter celebrations like the Roman holiday of Saturnalia, which involved feasting and gift-giving. And the solstice continues to be acknowledged in hundreds of traditions across the world, such as the Inca celebration of Inti Raymi, and the Dōngzhì festival in China.&lt;/p&gt;
    &lt;head rend="h2"&gt;'Nature's sublime power'&lt;/head&gt;
    &lt;p&gt;Alongside Maeshowe tomb, archaeologists have discovered dozens of Neolithic monuments that stare directly at the Sun on the winter solstice. There's Stonehenge (England), whose tallest trilithon once framed the setting sun; Newgrange (Ireland), which has a passageway aligned to sunrise on this auspicious day; and the standing stones at Callanish (Outer Hebrides) which create similar solar sightlines. In Brittany, north-western France, is La Roche aux Fées: a megalithic passageway constructed from 41 blocks of stone, some of which weigh over 40 tonnes (40,000kg). At sunrise on the winter solstice, it breathes in its annual dose of restorative midwinter light. Legends once told that fairies constructed it over the course of one night, but it is actually a dolmen (tomb) created by Neolithic architects around 2750BC.&lt;/p&gt;
    &lt;p&gt;In the 20th and 21st Centuries there has been a resurgence of Neolithic-inspired solar-oriented artworks. Nancy Holt's seminal land art piece, Sun Tunnels (1973-76) is one example, set in the Great Basin Desert of Utah, and comprising of four 22-tonne (22,000kg) concrete tubes arranged in an X-shape formation. The view down each of them perfectly frames the Sun as it rises and sets on the winter and summer solstices. Holt bought the land in 1975 and created her artwork with the help of engineers, an astrophysicist, an astronomer and a team of contractors.&lt;/p&gt;
    &lt;p&gt;It's best to understand Sun Tunnels in the context of the Land Art movement of the 1960s and 70s. Artists like Holt who are associated with this movement worked with the landscape rather than within traditional studios and galleries, and aimed to reconnect people with the awe of nature. Unlike its Neolithic predecessors, Sun Tunnels has no religious significance – Holt explained that she simply wanted "to bring the vast space of the desert back to human scale". It is also a response to modern concerns about nature. In an age where humans seem hell-bent on despoiling and exploiting nature, Sun Tunnels turns our attention back to its sublime power and rhythmic patterns.&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;p&gt;• Seven of the greatest rivalries in art history&lt;/p&gt;
    &lt;p&gt;Another masterpiece of Land Art, James Turrell's Roden Crater (begun 1979), does this on an even more epic scale than Sun Tunnels. It occupies a volcanic cinder cone in the Painted Desert region of northern Arizona and houses multiple spaces from which to watch celestial phenomena. One of them is a 900ft- (274m) long tunnel drilled through the volcanic cone. It acts like a camera obscura, focusing an image of the midwinter sun (via a glass lens halfway down the passage) on to a slab of white marble in a central chamber. Like Maeshowe tomb's passage, it aligns with the Sun's position around 21 December each year, and drinks down the Sun's light from 10 days before the solstice to the 10th day after it.&lt;/p&gt;
    &lt;p&gt;Enoura Observatory in Kanagawa Prefecture, Japan (completed 2017) was designed by photographer and architect Hiroshi Sugimoto. Its various buildings are all calibrated towards the movement of the Sun, to create what the artist describes as a "new Neolithic aesthetic". He wanted to correct what he saw as a lack of purpose in contemporary art by exploring the primal concerns of our ancient ancestors – our status within the infinite wilderness of the cosmos, our sense of time, and our notion of a human identity within the natural order.&lt;/p&gt;
    &lt;p&gt;One of its structures, the "Winter Solstice Light-Worship Tunnel", points directly at the spot on the horizon where the Sun rises at about 06:48 local time on 21 December each year. The solstice sunlight floods this 230ft-(70m) long chamber made of Corten steel and illuminates a stone medieval wellhead that is situated halfway along its length. It passes underneath another structure which aligns with the Sun on the summer solstice. The entire site, which took a decade to build, was intended by Sugimoto to act like a living clock, and to make an artwork with the ancient function of helping humans "identify their place within the vastness of the universe".&lt;/p&gt;
    &lt;p&gt;Holt's, Turrell's and Sugimoto's structures put us back in contact with seasonal patterns and the rhythms of nature, just as Maeshowe tomb and La Roche aux Fées once did. These monuments and artworks orient us in time, to the landscape, to our place within nature and to reoccurring celestial events. The winter solstice – which they all respond to directly – has always been of critical importance to humans, enshrining the significance of light, and honouring death and rebirth in the annual calendar. If the spectacle of these solar-aligned structures lining up perfectly with the rising and setting solstice Sun quickens the soul, it's because it triggers a primal recognition that the darkest hours of the year have passed. It's the first sign of spring's promised return, and future days of increased lightness and warmth.&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;If you liked this story, sign up for the Essential List newsletter – a handpicked selection of features, videos and can't-miss news, delivered to your inbox twice a week.&lt;/p&gt;
    &lt;p&gt;For more Culture stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/culture/article/20251219-the-ancient-monuments-saluting-the-winter-solstice"/><published>2025-12-22T09:30:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46352875</id><title>A year of vibes</title><updated>2025-12-22T18:16:37.987749+00:00</updated><content>&lt;doc fingerprint="375c195f06b20cf9"&gt;
  &lt;main&gt;
    &lt;p&gt;written on December 22, 2025&lt;/p&gt;
    &lt;p&gt;2025 draws to a close and it’s been quite a year. Around this time last year, I wrote a post that reflected on my life. Had I written about programming, it might have aged badly, as 2025 has been a year like no other for my profession.&lt;/p&gt;
    &lt;p&gt;2025 was the year of changes. Not only did I leave Sentry and start my new company, it was also the year I stopped programming the way I did before. In June I finally felt confident enough to share that my way of working was different:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Where I used to spend most of my time in Cursor, I now mostly use Claude Code, almost entirely hands-off. […] If you would have told me even just six months ago that I’d prefer being an engineering lead to a virtual programmer intern over hitting the keys myself, I would not have believed it.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While I set out last year wanting to write more, that desire had nothing to do with agentic coding. Yet I published 36 posts — almost 18% of all posts on this blog since 2007. I also had around a hundred conversations with programmers, founders, and others about AI because I was fired up with curiosity after falling into the agent rabbit hole.&lt;/p&gt;
    &lt;p&gt;2025 was also a not so great year for the world. To make my peace with it, I started a separate blog to separate out my thoughts from here.&lt;/p&gt;
    &lt;p&gt;It started with a growing obsession with Claude Code in April or May, resulting in months of building my own agents and using others’. Social media exploded with opinions on AI: some good, some bad.&lt;/p&gt;
    &lt;p&gt;Now I feel I have found a new stable status quo for how I reason about where we are and where we are going. I’m doubling down on code generation, file systems, programmatic tool invocation via an interpreter glue, and skill-based learning. Basically: what Claude Code innovated is still state of the art for me. That has worked very well over the last few months, and seeing foundation model providers double down on skills reinforces my belief in this approach.&lt;/p&gt;
    &lt;p&gt;I’m still perplexed by how TUIs made such a strong comeback. At the moment I’m using Amp, Claude Code, and Pi, all from the command line. Amp feels like the Apple or Porsche of agentic coding tools, Claude Code is the affordable Volkswagen, and Pi is the Hacker’s Open Source choice for me. They all feel like projects built by people who, like me, use them to an unhealthy degree to build their own products, but with different trade-offs.&lt;/p&gt;
    &lt;p&gt;I continue to be blown away by what LLMs paired with tool execution can do. At the beginning of the year I mostly used them for code generation, but now a big number of my agentic uses are day-to-day things. I’m sure we will see some exciting pushes towards consumer products in 2026. LLMs are now helping me with organizing my life, and I expect that to grow further.&lt;/p&gt;
    &lt;p&gt;Because LLMs now not only help me program, I’m starting to rethink my relationship to those machines. I increasingly find it harder not to create parasocial bonds with some of the tools I use. I find this odd and discomforting. Most agents we use today do not have much of a memory and have little personality but it’s easy to build yourself one that does. An LLM with memory is an experience that is hard to shake off.&lt;/p&gt;
    &lt;p&gt;It’s both fascinating and questionable. I have tried to train myself for two years, to think of these models as mere token tumblers, but that reductive view does not work for me any longer. These systems we now create have human tendencies, but elevating them to a human level would be a mistake. I increasingly take issue with calling these machines “agents,” yet I have no better word for it. I take issue with “agent” as a term because agency and responsibility should remain with humans. Whatever they are becoming, they can trigger emotional responses in us that can be detrimental if we are not careful. Our inability to properly name and place these creations in relation to us is a challenge I believe we need to solve.&lt;/p&gt;
    &lt;p&gt;Because of all this unintentional anthropomorphization, I’m really struggling at times to find the right words for how I’m working with these machines. I know that this is not just me; it’s others too. It creates even more discomfort when working with people who currently reject these systems outright. One of the most common comments I read in response to agentic coding tool articles is this rejection of giving the machine personality.&lt;/p&gt;
    &lt;p&gt;An unexpected aspect of using AI so much is that we talk far more about vibes than anything else. This way of working is less than a year old, yet it challenges half a century of software engineering experience. So there are many opinions, and it’s hard to say which will stand the test of time.&lt;/p&gt;
    &lt;p&gt;I found a lot of conventional wisdom I don’t agree with, but I have nothing to back up my opinions. How would I? I quite vocally shared my lack of success with MCP throughout the year, but I had little to back it up beyond “does not work for me.” Others swore by it. Similar with model selection. Peter, who got me hooked on Claude early in the year, moved to Codex and is happy with it. I don’t enjoy that experience nearly as much, though I started using it more. I have nothing beyond vibes to back up my preference for Claude.&lt;/p&gt;
    &lt;p&gt;It’s also important to know that some of the vibes come with intentional signalling. Plenty of people whose views you can find online have a financial interest in one product over another, for instance because they are investors in it or they are paid influencers. They might have become investors because they liked the product, but it’s also possible that their views are affected and shaped by that relationship.&lt;/p&gt;
    &lt;p&gt;Pick up a library from any AI company today and you’ll notice they’re built with Stainless or Fern. The docs use Mintlify, the site’s authentication system might be Clerk. Companies now sell services you would have built yourself previously. This increase in outsourcing of core services to companies specializing in it meant that the bar for some aspects of the user experience has risen.&lt;/p&gt;
    &lt;p&gt;But with our newfound power from agentic coding tools, you can build much of this yourself. I had Claude build me an SDK generator for Python and TypeScript — partly out of curiosity, partly because it felt easy enough. As you might know, I’m a proponent of simple code and building it yourself. This makes me somewhat optimistic that AI has the potential to encourage building on fewer dependencies. At the same time, it’s not clear to me that we’re moving that way given the current trends of outsourcing everything.&lt;/p&gt;
    &lt;p&gt;This brings me not to predictions but to wishes for where we could put our energy next. I don’t really know what I’m looking for here, but I want to point at my pain points and give some context and food for thought.&lt;/p&gt;
    &lt;p&gt;My biggest unexpected finding: we’re hitting limits of traditional tools for sharing code. The pull request model on GitHub doesn’t carry enough information to review AI generated code properly — I wish I could see the prompts that led to changes. It’s not just GitHub, it’s also git that is lacking.&lt;/p&gt;
    &lt;p&gt;With agentic coding, part of what makes the models work today is knowing the mistakes. If you steer it back to an earlier state, you want the tool to remember what went wrong. There is, for lack of a better word, value in failures. As humans we might also benefit from knowing the paths that did not lead us anywhere, but for machines this is critical information. You notice this when you are trying to compress the conversation history. Discarding the paths that led you astray means that the model will try the same mistakes again.&lt;/p&gt;
    &lt;p&gt;Some agentic coding tools have begun spinning up worktrees or creating checkpoints in git for restore, in-conversation branch and undo features. There’s room for UX innovation that could make these tools easier to work with. This is probably why we’re seeing discussions about stacked diffs and alternative version control systems like Jujutsu.&lt;/p&gt;
    &lt;p&gt;Will this change GitHub or will it create space for some new competition? I hope so. I increasingly want to better understand genuine human input and tell it apart from machine output. I want to see the prompts and the attempts that failed along the way. And then somehow I want to squash and compress it all on merge, but with a way to retrieve the full history if needed.&lt;/p&gt;
    &lt;p&gt;This is related to the version control piece: current code review tools assign strict role definitions that just don’t work with AI. Take the GitHub code review UI: I regularly want to use comments on the PR view to leave notes for my own agents, but there is no guided way to do that. The review interface refuses to let me review my own code, I can only comment, but that does not have quite the same intention.&lt;/p&gt;
    &lt;p&gt;There is also the problem that an increased amount of code review now happens between me and my agents locally. For instance, the Codex code review feature on GitHub stopped working for me because it can only be bound to one organization at a time. So I now use Codex on the command line to do reviews, but that means a whole part of my iteration cycles is invisible to other engineers on the team. That doesn’t work for me.&lt;/p&gt;
    &lt;p&gt;Code review to me feels like it needs to become part of the VCS.&lt;/p&gt;
    &lt;p&gt;I also believe that observability is up for grabs again. We now have both the need and opportunity to take advantage of it on a whole new level. Most people were not in a position where they could build their own eBPF programs, but LLMs can. Likewise, many observability tools shied away from SQL because of its complexity, but LLMs are better at it than any proprietary query language. They can write queries, they can grep, they can map-reduce, they remote-control LLDB. Anything that has some structure and text is suddenly fertile ground for agentic coding tools to succeed. I don’t know what the observability of the future looks like, but my strong hunch is that we will see plenty of innovation here. The better the feedback loop to the machine, the better the results.&lt;/p&gt;
    &lt;p&gt;I’m not even sure what I’m asking for here, but I think that one of the challenges in the past was that many cool ideas for better observability — specifically dynamic reconfiguration of services for more targeted filtering — were user-unfriendly because they were complex and hard to use. But now those might be the right solutions in light of LLMs because of their increased capabilities for doing this grunt work. For instance Python 3.14 landed an external debugger interface which is an amazing capability for an agentic coding tool.&lt;/p&gt;
    &lt;p&gt;This may be a little more controversial, but what I haven’t managed this year is to give in to the machine. I still treat it like regular software engineering and review a lot. I also recognize that an increasing number of people are not working with this model of engineering but instead completely given in to the machine. As crazy as that sounds, I have seen some people be quite successful with this. I don’t yet know how to reason about this, but it is clear to me that even though code is being generated in the end, the way of working in that new world is very different from the world that I’m comfortable with. And my suspicion is that because that world is here to stay, we might need some new social contracts to separate these out.&lt;/p&gt;
    &lt;p&gt;The most obvious version of this is the increased amount of these types of contributions to Open Source projects, which are quite frankly an insult to anyone who is not working in that model. I find reading such pull requests quite rage-inducing.&lt;/p&gt;
    &lt;p&gt;Personally, I’ve tried to attack this problem with contribution guidelines and pull request templates. But this seems a little like a fight against windmills. This might be something where the solution will not come from changing what we’re doing. Instead, it might come from vocal people who are also pro-AI engineering speaking out on what good behavior in an agentic codebase looks like. And it is not just to throw up unreviewed code and then have another person figure the shit out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/"/><published>2025-12-22T10:19:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46352930</id><title>If you don't design your career, someone else will (2014)</title><updated>2025-12-22T18:16:37.878186+00:00</updated><content>&lt;doc fingerprint="227b983565a77a21"&gt;
  &lt;main&gt;
    &lt;p&gt;A client once responded to one of my questions by saying, “Oh Greg, I am too busy living to think about life!” His off-the-cuff comment named a trap all of us fall into sometimes. In just one example, it is easy to become so consumed in our careers we fail to really think about our careers.&lt;/p&gt;
    &lt;p&gt;To avoid this trap, I suggest carving out a couple of hours over the holiday break to follow these simple steps for reflecting on your career.&lt;/p&gt;
    &lt;p&gt;Step 1: Review the last 12 months. Review the year, month by month. Make a list of where you spent your time: include your major projects, responsibilities and accomplishments. No need to overcomplicate this.&lt;/p&gt;
    &lt;p&gt;Step 2: Ask, “What is the news?” Look over your list and reflect on what is really going on. Think like a journalist and ask yourself: Why does this matter? What are the trends here? What happens if these trends continue?&lt;/p&gt;
    &lt;p&gt;Step 3: Ask “What would I do in my career if I could do anything?” Just brainstorm with no voice of criticism to hold you back. Just write out all the ideas that come to mind.&lt;/p&gt;
    &lt;p&gt;Step 4: Go back and spend a bit more time on Step 3. Too often we begin our career planning with our second best option in mind. We have a sense of what we would most love to do but we immediately push it aside. Why? Typically because “it is not realistic” which is code for, “I can’t make money doing this.” In this economy—in any economy—I understand why making money is critical. However, sometimes we pass by legitimate career paths because we set them aside too quickly.&lt;/p&gt;
    &lt;p&gt;Step 5: Write down six objectives for the next 12 months. Make a list of the top six items you would like to accomplish in your career this year and place them in priority order.&lt;/p&gt;
    &lt;p&gt;Step 6: Cross off the bottom five. Once you’re back to the whirlwind of work you’ll benefit from having a single “true north” career objective for the year.&lt;/p&gt;
    &lt;p&gt;Step 7: Make an action plan for this month. Make a list of some quick wins you’d like to have in place over the next 3-4 weeks.&lt;/p&gt;
    &lt;p&gt;Step 8: Decide what you will say no to. Make a list of the “good” things that will keep you from achieving your one “great” career objective. Think about how to delete, defer or delegate these other tasks. Ralph Waldo Emerson said, “The crime which bankrupts men and nations is that of turning aside from one’s main purpose to serve a job here and there.”&lt;/p&gt;
    &lt;p&gt;Many years ago I followed this process and, without exaggeration, it changed the course of my life. The insight I gained led me to quit law school, leave England and move to America and start down the path as a teacher and author. You’re reading this because of that choice. It remains the single most important career decision of my life.&lt;/p&gt;
    &lt;p&gt;Two hours spent wisely over the next couple of weeks could easily improve the quality of your life over the 8760 hours of the next year–and perhaps far beyond. After all, if we don’t design our careers, someone else will.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gregmckeown.com/if-you-dont-design-your-career-someone-else-will/"/><published>2025-12-22T10:27:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46353777</id><title>The biggest CRT ever made: Sony's PVM-4300</title><updated>2025-12-22T18:16:37.693388+00:00</updated><content>&lt;doc fingerprint="73489d35a9a732be"&gt;
  &lt;main&gt;
    &lt;p&gt;Move over, GE Widescreen 1000. In 1989 in Japan, Sony introduced to the largest Trinitron CRT ever built, the KV-45ED1, also known as the PVM-4300. And in 1990, they imported 20 of them to the United States, just in time for the recession. About 34 years later, one of these enigmatic TVs surfaced.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sony’s PVM-4300/KV-45ED1&lt;/head&gt;
    &lt;p&gt;Sony’s part number suggests it has a 45 inch tube inside. But in a rare case of truth in advertising, Sony advertised it as a 43-inch model. It weighed about 450 pounds, stood about 27 inches tall, and it wouldn’t fit through a standard door frame. That’s probably okay, it’s not like someone was going to use this as a bedroom TV. This thing was going in your living room.&lt;/p&gt;
    &lt;p&gt;In Japan, it sold for 2.6 million yen, but in the United States, it retailed for $40,000, a significant markup. To be fair, shipping them across the Atlantic and then throughout the United States must have been expensive. And news articles in 1990 said Sony dealers would not allow any bickering. They would throw in a couple of options like the separate tuner or speakers. But no discounts.&lt;/p&gt;
    &lt;p&gt;Sony said at the time they hoped to sell 80 of them that year, but the recession may have kept that from happening.&lt;/p&gt;
    &lt;head rend="h2"&gt;The biggest conventional CRT ever&lt;/head&gt;
    &lt;p&gt;The Sony PVM-4300 was a conventional CRT, unlike the GE Widescreen 1000, which was a projection set. Projection TVs could be bigger and cheaper. But if you wanted the clearest picture, a big CRT was where it was at.&lt;/p&gt;
    &lt;p&gt;It was a conventional CRT that worked with over the air signals, but like many larger TVs of the era, it used a technology called IDTV to enhance the picture quality. The “ID” stood for “improved definition.” IDTV sets had a buffer so they would store successive frames and interpolate them rather than interlacing them the way a conventional CRT TV worked. They also had circuitry to detect motion and perform image stabilization to further enhance the image. The result wasn’t as good as HDTV. But it gave high rollers a better picture until HDTV. HDTV arrived in 1998, but articles at the time estimated 2005. The Chicago Tribune warned in 1990 that these $40,000 TVs would be obsolete in 15 years, but the salesperson countered that every TV would be obsolete in 15 years.&lt;/p&gt;
    &lt;p&gt;It’s also likely that someone in the market for a $40,000 TV didn’t worry about obsolescence. In 1990, the GE Widescreen 1000 looked dated and it wasn’t 15 years old yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why so expensive?&lt;/head&gt;
    &lt;p&gt;The KV-45ED1 or PVM-4300 cost about 8 times as much as Sony’s second most expensive model at the time, which had a 29-inch screen. That’s largely because the KV-45ED1 had to be built by hand. Sony could mass produce its smaller TVs. This was a product for buyers who weren’t worried about the price.&lt;/p&gt;
    &lt;p&gt;Sony continued making CRTs into the 21st century, bowing out with its high-def KD-34XBR970, 36-inch KD-36FS170, 32-inch KV-32FS170 and 27-inch KV27FS170 in February 2006.&lt;/p&gt;
    &lt;p&gt;It is unclear how many of these enormous 43-inch units Sony sold, and some people even questioned if it was ever built. A Chicago area dealer told the Chicago Tribune in 1990 that someone had purchased one, but that the buyer wanted to remain anonymous. That was good enough for me; a TV dealer wasn’t going to tell a newspaper that they have a $40,000 item and then not have it. That’s just bad business. Good business is taking the free advertising, having an example on display to show knowing most won’t buy it, but they may buy one of the smaller units. But luring someone into the store with a lie makes it much more difficult to sell anything.&lt;/p&gt;
    &lt;p&gt;And the Tribune wasn’t going to make something like this up. It would anger the TV dealers and risk losing their advertising. And someone who could afford a $40,000 TV was likely a business owner or high-ranking executive who could pull their advertising. In the days of print newspapers, advertisers and potential advertisers held a lot of sway. This could be both good and bad. I’m not going to say capitalism solves every problem but this was a case where it helped keep people honest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shank Mods’ surviving Sony PVM-4300&lt;/head&gt;
    &lt;p&gt;On December 22, 2024, Youtuber Shank Mods released a video telling the story of a Sony PVM-4300 and how he acquired it. One of the photos of a purported surviving unit turned out to be very real. It was taken in a restaurant in Japan, and the owner was actually aware of the photo. Unfortunately the restaurant was having to move, and needed to get rid of the set. Shank Mods was able to contact some people in Japan who could help race against time and remove the TV from the restaurant and then ship it to the United States.&lt;/p&gt;
    &lt;p&gt;The 35-minute video is well worth watching if you have interest in vintage CRTs, or even if you just like stories of strangers coming together and helping each other just for the sake of being helpful. Actually, I take that back. At the end of the video, Shank Mods played a prank on his fellow CRT fans that is absolutely hilarious and makes the video worth watching for that reason alone. I won’t ruin it for you.&lt;/p&gt;
    &lt;p&gt;We can only guess how many other examples may survive. But we now know that at least one survives and is in the hands of a retro hobbyist.&lt;/p&gt;
    &lt;p&gt;David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dfarq.homeip.net/the-biggest-crt-ever-made-sonys-pvm-4300/"/><published>2025-12-22T12:54:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46354773</id><title>On the Existence, Impact, and Origin of Hallucination-Associated Neurons in LLMs</title><updated>2025-12-22T18:16:37.581220+00:00</updated><content>&lt;doc fingerprint="fd3c240ac8ff90aa"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 1 Dec 2025 (v1), last revised 2 Dec 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons in LLMs&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Cheng Gao [view email]&lt;p&gt;[v1] Mon, 1 Dec 2025 15:32:14 UTC (1,559 KB)&lt;/p&gt;&lt;p&gt;[v2] Tue, 2 Dec 2025 07:08:39 UTC (1,559 KB)&lt;/p&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.AI&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.01797"/><published>2025-12-22T15:16:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46354970</id><title>Scaling LLMs to Larger Codebases</title><updated>2025-12-22T18:16:37.365528+00:00</updated><content>&lt;doc fingerprint="2bde92ad20075288"&gt;
  &lt;main&gt;
    &lt;p&gt;How do we scale LLMs to larger codebases? Nobody knows yet. But by understanding how LLMs contribute to engineering, we realize that investments in guidance and oversight are worthwhile.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Guidance: The context, the environment.&lt;/item&gt;
      &lt;item&gt;Oversight: The skill set needed to guide, validate, and verify the implementor's1 choices.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Investing in guidance&lt;/head&gt;
    &lt;p&gt;When an LLM can generate a working high-quality implementation in a single try, that is called one-shotting. This is the most efficient form of LLM programming.&lt;/p&gt;
    &lt;p&gt;The opposite of one-shotting is rework. This is when you fail to get a usable output from the LLM and must manually intervene.2 This often takes longer than just doing the work yourself.&lt;/p&gt;
    &lt;p&gt;So how do we create more opportunities for one-shotting? Better guidance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Better guidance&lt;/head&gt;
    &lt;p&gt;LLMs are choice generators. Every set of tokens is a choice added to your codebase: how a variable is named, where to organize a function, whether to reuse/extend/or duplicate functionality to solve a problem, whether Postgres should be chosen over Redis, and so on.&lt;/p&gt;
    &lt;p&gt;Often, these choices are best left up to the designer (e.g., via the prompt). However, it's not efficient to exhaustively list all of these choices in a prompt. It's also not efficient to rework an LLM output whenever it gets these choices wrong.&lt;/p&gt;
    &lt;p&gt;In the ideal world, the prompt only captures the business requirements of a feature. The rest of the choices are either inferrable or encoded.&lt;/p&gt;
    &lt;head rend="h4"&gt;Write a prompt library&lt;/head&gt;
    &lt;p&gt;A prompt library is a set of documentation that can be included as context for an LLM.&lt;/p&gt;
    &lt;p&gt;Writing this is simple: collate documentation, best practices, a general map of the codebase, and other context an engineer needs to be productive in your codebase.3&lt;/p&gt;
    &lt;p&gt;Making a prompt library useful requires iteration. Every time the LLM is slightly off target, ask yourself, "What could've been clarified?" Then, add that answer back into the prompt library.&lt;/p&gt;
    &lt;p&gt;A prompt library needs to strike the right balance between comprehensive and lean.&lt;/p&gt;
    &lt;head rend="h4"&gt;The environment is your context&lt;/head&gt;
    &lt;p&gt;A peer at Meta told me that they weren't in a position to make Zuckerberg's engineering automation claims a reality. The reason is their codebase is riddled with technical debt. He wasn't surprised by this. Meta (apparently) historically has not prioritized paying down their debts.&lt;/p&gt;
    &lt;p&gt;Compare this to the mentality from the Cursor team:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I think ultimately the principles of clean software are not that different when you want it to be read by people and by models. When you are trying to write clean code you want to, not repeat yourself, not make things more complicated than they need to be.&lt;/p&gt;
      &lt;p&gt;I think taste in code... is actually gonna become even more important as these models get better because it will be easier to write more and more code and so it'll be more and more important to structure it in a tasteful way.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the garbage in, garbage out principle in action. The utility of a model is bottlenecked by its inputs. The more garbage you have, the more likely hallucinations will occur.&lt;/p&gt;
    &lt;p&gt;Here's a LLM literacy dipstick: ask a peer engineer to read some code they're unfamiliar with. Do they understand it? Do they struggle to navigate it? If it's a module, can they quickly understand what all that module exposes? Do they know the implications of using a certain function, the side-effects they must be aware of? No? Then the LLM won't either.&lt;/p&gt;
    &lt;p&gt;Here's another dipstick: Ask an LLM agent to tell you how certain functionality works. You should know the answer before asking the LLM. Is their answer right? More importantly, how did they go about answering your question? Follow the LLM's trail and document its snags. You'll notice it tends to &lt;code&gt;grep&lt;/code&gt;, &lt;code&gt;ls&lt;/code&gt;, and &lt;code&gt;cat&lt;/code&gt; to search. How can you give it a map so it isn't left to rediscover the codebase on each new prompt? When a map can't be given, how do you make it easier for them to navigate the codebase?&lt;/p&gt;
    &lt;p&gt;How you make the environment better suited for LLM literacy is dependent on the tech stack and domain. But general principles apply: modularity, simplicity, things are well-named, logic is encapsulated. Be consistent and encode these conventions in your prompt library.&lt;/p&gt;
    &lt;head rend="h2"&gt;Investing in oversight&lt;/head&gt;
    &lt;p&gt;We need guidance and oversight. A 3-ton truck with a middle-schooler behind the wheel puts people in the hospital (and in jail). This is why the mentality of automating engineers is objectionable. We should be fostering our teams, not discarding them.&lt;/p&gt;
    &lt;p&gt;Remember, engineers operate on two timelines. As overseers of implementation, we must plan for the future of the codebase. If an LLM makes a choice, the overseer should be able to discern whether it was a good one or a bad one. For example, let's say the LLM opted to use Redis over Postgres to store some metadata. Was that a good choice? The overseer should know.&lt;/p&gt;
    &lt;p&gt;An investment in oversight is an investment in team, alignment, and workflows.&lt;/p&gt;
    &lt;p&gt;For team, it's worth investing in elevating everyone's design capabilities.&lt;/p&gt;
    &lt;p&gt;Design produces architecture. Architecture is a bet on the future. It's a bet that by setting up a program in a certain way, it will make the future feature development easier.&lt;/p&gt;
    &lt;p&gt;Architects are often created through experience. A career of shooting yourself in the foot builds intuition. This intuition shapes new software from having the same mistakes.&lt;/p&gt;
    &lt;head&gt;Aside: Some thoughts on how to grow design skills&lt;/head&gt;
    &lt;p&gt;Read books, blogs, and code. Watch conference talks. Replicate masterworks. Practice by writing programs that you don't know how to build.&lt;/p&gt;
    &lt;p&gt;On replicating masterworks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Student artists are often required to replicate masterworks. A masterwork is an art piece that an expert artist made. Through the process of replicating this masterwork, an artist gains practical experience at the bleeding edge of art. (This experience also builds confidence, which is a bonus.)&lt;/item&gt;
      &lt;item&gt;The same is true for engineering. I've learned more by writing a programming language than I have in reading a hundred blog posts.&lt;/item&gt;
      &lt;item&gt;Why does this work?&lt;list rend="ul"&gt;&lt;item&gt;You understand a layer of abstraction deeper than the layer you're working at (this is a Cantrill-ism, but I can't find the quote).&lt;/item&gt;&lt;item&gt;Masters use techniques and workflows that are best learned via practice. Thorsten Ball taught me how to break down large problems into tractable phases. Each phase had a contract and each contract could be tested.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On reading code:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A good way to expand your vocabulary of solutions.&lt;/item&gt;
      &lt;item&gt;In Steve Ruiz's V1 of TLDraw, I learned the patterns necessary to later implement session-based undo/redo for an internal tool at work.&lt;/item&gt;
      &lt;item&gt;Reading code from leaders in the field is also a good way to build taste.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Oversight is not only about architecture, but also temperament, alignment to values, and workflows. Operators need to be both technical and product experts. Without a deep understanding of the product, it's easy to accidentally build the wrong solution.&lt;/p&gt;
    &lt;head rend="h3"&gt;Automating oversight&lt;/head&gt;
    &lt;p&gt;Some design concerns can be checked programmatically.&lt;/p&gt;
    &lt;p&gt;Moving more implementation feedback from human to computer helps us improve the chance of one-shotting. Agents can get feedback directly from their environment (e.g., type errors).&lt;/p&gt;
    &lt;p&gt;Think of these as bumper rails. You can increase the likelihood of an LLM reaching the bowling pins by making it impossible to land in the gutter.&lt;/p&gt;
    &lt;p&gt;One way to do this is through writing safety checks. But what is safety? Safety is protecting your abstractions. Pierce's Types and Programming Languages has my favorite definition of safety:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Informally, though, safe languages can be defined as ones that make it impossible to shoot yourself in the foot while programming.&lt;/p&gt;
      &lt;p&gt;Refining this intuition a little, we could say that a safe language is one that protects its own abstractions.&lt;/p&gt;
      &lt;p&gt;Safety refers to the language's ability to guarantee the integrity of these abstractions and of higher-level abstractions introduced by the programmer using the definitional facilities of the language. For example, a language may provide arrays, with access and update operations, as an abstraction of the underlying memory. A programmer using this language then expects that an array can be changed only by using the update operation on it explicitly—and not, for example, by writing past the end of some other data structure.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We tend to write tests for business-logic but don't always write tests for architecture-logic. Some programming languages have facilities for this built in.&lt;/p&gt;
    &lt;head rend="h2"&gt;Addressing verification&lt;/head&gt;
    &lt;p&gt;Design and implementation are only two pieces of a project's lifecycle. Verification, like code review or QA, are necessary for building quality software.&lt;/p&gt;
    &lt;p&gt;As the volume of work increases, our ability to ship that work becomes constrained by our ability to review it.&lt;/p&gt;
    &lt;p&gt;Here are some incomplete ideas for addressing the verification bottleneck:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lowering the barrier of entry to perform manual QA (not needing a dev env).&lt;/item&gt;
      &lt;item&gt;Invest in a testing setup that makes it easy to express tests (including setting up tests, e.g., with test data creation) with minimal code.&lt;/item&gt;
      &lt;item&gt;Encode frequent PR feedback into documentation so that there is some level of PR review an LLM can reasonably do.&lt;/item&gt;
      &lt;item&gt;Security is baked in as defaults in the framework, not context.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;That's it, for now&lt;/head&gt;
    &lt;p&gt;This was the third part of a series on LLMs in software engineering.&lt;/p&gt;
    &lt;p&gt;First we learned what LLMs and genetics have in common. (part 1) LLMs don't simply improve all facets of engineering. Understanding which areas LLMs do improve (part 2) is important for knowing how to focus our investments. (part 3)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Or, in today's age, the generator's. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Not being able to one-shot prevents adoption from many programmers. Programmers are disposed to seeing a worse solution and wanting to build their own. Oh, I can either pay $10/mo for a subscription to this SaaS tool, or I can build my own..? I choose to build my own, of course! (I am guilty of this). I think mentality partially explains the disparity between LLM skeptics and advocates. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Technical strategy is another form of context you can include in a prompt library. Though, you do risk bloating the context with many words, some of which aren't directly applicable. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;This structure is motivated by this post and this video. If you are in the Django ecosystem, I recommend reviewing those. ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I can't help but make another software comparison to Phillip Ball's How Life Works: "Modularity: Life never has to start from scratch. Evolution works with what is already there, even if this means redirecting it to new ends. We might (with great caution!) compare it to an electronic engineer who uses preexisting circuit components like diodes and resistors, and standard circuit elements such as oscillators and memory units, to create new devices. Thus life possesses a modular structure. This is most obvious in the way large organisms like us are assemblies of cells, as well as sharing common structures such as hearts and eyes. Modularity is an efficient way to build, since it relies on components that have already been tried and tested and permits the modification or replacement of one part more or less independently from the others." ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.kierangill.xyz/oversight-and-guidance"/><published>2025-12-22T15:38:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355077</id><title>The U.S. Is Funding Fewer Grants in Every Area of Science and Medicine</title><updated>2025-12-22T18:16:37.071564+00:00</updated><content>&lt;doc fingerprint="1ac8165e2d6a0b81"&gt;
  &lt;main&gt;
    &lt;p&gt;To spend its budget, the N.I.H. made an unusual number of large lump-sum payments for many years of research, instead of its usual policy of paying for research one year at a time.&lt;/p&gt;
    &lt;p&gt;As a result of this quiet policy shift, the average payment for competitive grants swelled from $472,000 in the first half of the fiscal year to over $830,000 in the last two months.&lt;/p&gt;
    &lt;p&gt;While this might sound like a boon for researchers, it’s actually a fundamental shift in how grants are funded — one that means more competition for funding, and less money and less time to do the research.&lt;/p&gt;
    &lt;p&gt;And because these fully funded grants commit all of their money up front, it means the agency’s annual budget is divided into fewer projects, instead of being spread among a larger number of scientific bets.&lt;/p&gt;
    &lt;p&gt;The new policy directive came from the White House’s Office of Management and Budget, which in the summer instructed the N.I.H. to spend half of its remaining funds to fully fund research grants. In the past, the agency would do so only in special circumstances.&lt;/p&gt;
    &lt;p&gt;The White House has said this would “increase N.I.H. budget flexibility” by not encumbering its annual budget with payments to previously approved projects. It has said it plans to continue this policy in 2026, while proposing to shrink the agency’s budget by $18 billion, or nearly 40 percent. (The Senate and House rejected the White House’s proposed budget cuts, but have not yet agreed on the agency’s budget.)&lt;/p&gt;
    &lt;p&gt;“My sense of it was that the administration wanted to clear the decks,” said Sarah Kobrin, a branch chief at the N.I.H.’s National Cancer Institute, who said she was sharing her views, not those of the institute.&lt;/p&gt;
    &lt;p&gt;The new policy is being carried out as the Trump administration has tightened its hold over federal science funding. Earlier this year, it delayed reviewing grants in order to vet research by political appointees, culled projects that mentioned D.E.I. and fired thousands of employees or pressured them to retire early. (The N.I.H. lost nearly 3,000 employees this year, or about 14 percent of its work force, based on a New York Times review of the agency’s shutdown contingency plans.)&lt;/p&gt;
    &lt;p&gt;“They brought everything to a stop,” Dr. Kobrin said.&lt;/p&gt;
    &lt;p&gt;Nonetheless, the N.I.H. managed to spend most of its budget by the end of the fiscal year. “My colleagues did an outstanding job to work their butts off to approve things,” said Theresa Kim, a program officer at N.I.H.’s National Institute on Aging.&lt;/p&gt;
    &lt;p&gt;Something similar happened at the National Science Foundation, which is the second-largest federal funder of research at U.S. universities, after the N.I.H.&lt;/p&gt;
    &lt;p&gt;The N.S.F. started the year with funding delays caused by the Trump administration, and it lost about a third of its employees in layoffs or forced retirements. The agency ended the year awarding 25 percent fewer new grants.&lt;/p&gt;
    &lt;p&gt;Facing a proposed $5 billion cut to its $9 billion budget, the N.S.F. fully paid off many of the grants that were on its books, a strategy that employees called “paying down the mortgage.” It also paid for nearly all new awards upfront (though, unlike at the N.I.H., not necessarily for less time and money).&lt;/p&gt;
    &lt;p&gt;To draw these conclusions, The Times used public data to analyze nearly every competitive grant — over 300,000 in all — that the N.I.H. and the N.S.F. awarded since 2015, and interviewed many employees at these agencies.&lt;/p&gt;
    &lt;p&gt;Here’s what we found:&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Fewer grants in every area of science and medicine&lt;/head&gt;
    &lt;p&gt;Together, the N.I.H. and the N.S.F. had a nearly $60 billion annual budget for funding future breakthroughs in science and medicine, about a quarter of which is typically spent on new grants or competitive renewals.&lt;/p&gt;
    &lt;p&gt;This year, both agencies made far fewer competitive awards:&lt;/p&gt;
    &lt;p&gt;The White House has said it is streamlining scientific funding by eliminating wasteful spending and cutting “woke programs” that “poison the minds of Americans.”&lt;/p&gt;
    &lt;p&gt;But the more than 3,500 fewer competitive grants from the N.I.H. this year touched every area of biology and medicine:&lt;/p&gt;
    &lt;head rend="h3"&gt;Competitive grants awarded by the National Institutes of Health&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Institute&lt;/cell&gt;
        &lt;cell role="head"&gt;2015-24 avg.&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Minority health&lt;/cell&gt;
        &lt;cell&gt;146&lt;/cell&gt;
        &lt;cell&gt;57&lt;/cell&gt;
        &lt;cell&gt;-61%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Nursing&lt;/cell&gt;
        &lt;cell&gt;105&lt;/cell&gt;
        &lt;cell&gt;51&lt;/cell&gt;
        &lt;cell&gt;-51%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Human genome&lt;/cell&gt;
        &lt;cell&gt;166&lt;/cell&gt;
        &lt;cell&gt;88&lt;/cell&gt;
        &lt;cell&gt;-47%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Alcohol abuse and alcoholism&lt;/cell&gt;
        &lt;cell&gt;298&lt;/cell&gt;
        &lt;cell&gt;159&lt;/cell&gt;
        &lt;cell&gt;-47%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Mental health&lt;/cell&gt;
        &lt;cell&gt;902&lt;/cell&gt;
        &lt;cell&gt;516&lt;/cell&gt;
        &lt;cell&gt;-43%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Integrative health&lt;/cell&gt;
        &lt;cell&gt;88&lt;/cell&gt;
        &lt;cell&gt;57&lt;/cell&gt;
        &lt;cell&gt;-36%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Library of medicine&lt;/cell&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;38&lt;/cell&gt;
        &lt;cell&gt;-32%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Aging&lt;/cell&gt;
        &lt;cell&gt;1,228&lt;/cell&gt;
        &lt;cell&gt;843&lt;/cell&gt;
        &lt;cell&gt;-31%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Diabetes&lt;/cell&gt;
        &lt;cell&gt;1,114&lt;/cell&gt;
        &lt;cell&gt;783&lt;/cell&gt;
        &lt;cell&gt;-30%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Neurological disorders and stroke&lt;/cell&gt;
        &lt;cell&gt;1,293&lt;/cell&gt;
        &lt;cell&gt;951&lt;/cell&gt;
        &lt;cell&gt;-26%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;16,099&lt;/cell&gt;
        &lt;cell&gt;12,588&lt;/cell&gt;
        &lt;cell&gt;-22%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In practice, this means thousands of very competitive projects in areas like cancer, diabetes, aging, neurological disorders and public health improvements probably went unfunded in 2025.&lt;/p&gt;
    &lt;p&gt;Similarly, at the National Science Foundation, the roughly 3,000 fewer new grants encompassed reductions to every area of science (and the social sciences):&lt;/p&gt;
    &lt;head rend="h3"&gt;New grants awarded by the National Science Foundation&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Directorate&lt;/cell&gt;
        &lt;cell role="head"&gt;2015-24 avg.&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Social, behavioral and economic sciences&lt;/cell&gt;
        &lt;cell&gt;935&lt;/cell&gt;
        &lt;cell&gt;501&lt;/cell&gt;
        &lt;cell&gt;-46%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Biology&lt;/cell&gt;
        &lt;cell&gt;1,143&lt;/cell&gt;
        &lt;cell&gt;735&lt;/cell&gt;
        &lt;cell&gt;-36%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Geosciences&lt;/cell&gt;
        &lt;cell&gt;1,483&lt;/cell&gt;
        &lt;cell&gt;964&lt;/cell&gt;
        &lt;cell&gt;-35%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;STEM education&lt;/cell&gt;
        &lt;cell&gt;1,087&lt;/cell&gt;
        &lt;cell&gt;758&lt;/cell&gt;
        &lt;cell&gt;-30%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Computer science&lt;/cell&gt;
        &lt;cell&gt;2,017&lt;/cell&gt;
        &lt;cell&gt;1,459&lt;/cell&gt;
        &lt;cell&gt;-28%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Engineering&lt;/cell&gt;
        &lt;cell&gt;1,755&lt;/cell&gt;
        &lt;cell&gt;1,461&lt;/cell&gt;
        &lt;cell&gt;-17%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Math and physics&lt;/cell&gt;
        &lt;cell&gt;2,512&lt;/cell&gt;
        &lt;cell&gt;2,094&lt;/cell&gt;
        &lt;cell&gt;-17%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Technology and innovation&lt;/cell&gt;
        &lt;cell&gt;757&lt;/cell&gt;
        &lt;cell&gt;657&lt;/cell&gt;
        &lt;cell&gt;-13%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Office of the director&lt;/cell&gt;
        &lt;cell&gt;132&lt;/cell&gt;
        &lt;cell&gt;205&lt;/cell&gt;
        &lt;cell&gt;+55%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;11,821&lt;/cell&gt;
        &lt;cell&gt;8,834&lt;/cell&gt;
        &lt;cell&gt;-25%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There were fewer new grants awarded in biology, geosciences, STEM education, computer science and engineering, math, physics, technology and innovation.&lt;/p&gt;
    &lt;p&gt;Only the office of the director awarded more new grants this year; it funds projects that don’t neatly fall into other categories. That growth was fueled by a previously established N.S.F. goal to expand fellowships at universities in regions that have historically received less federal funding.&lt;/p&gt;
    &lt;p&gt;The Trump administration has also taken the unusual step of canceling thousands of active health and science grants, citing a lack of overlap with its priorities.&lt;/p&gt;
    &lt;p&gt;“The N.I.H. is no longer directing resources toward science shaped by political or social pressures; instead, we have adopted a proactive, science-driven approach with clearly defined priorities focused on researching chronic health problems, identifying root causes, and advancing research grounded in scientifically valid, measurable health outcomes,” said Andrew Nixon, Health and Human Services communications director.&lt;/p&gt;
    &lt;p&gt;The website Grant Witness has estimated that the administration canceled or froze 5,415 N.I.H. grants this year, of which roughly half have been reinstated through court cases or negotiations where universities have agreed to some of the administration’s demands. And it canceled or froze 1,996 N.S.F. grants, of which nearly a third have been reinstated, according to Grant Witness estimates.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. More competition&lt;/head&gt;
    &lt;p&gt;It’s simple math: Fewer grants implies more competition for federal funding.&lt;/p&gt;
    &lt;p&gt;Take the category of research grants known as R01, the oldest and most prestigious grant that the N.I.H. awards. An acceptance or rejection can make or break a scientist’s career.&lt;/p&gt;
    &lt;p&gt;These grants fund topics such as studying the impact of e-cigarettes on brain health, modeling the movements of mice, or devising new methods to kill mosquitoes.&lt;/p&gt;
    &lt;p&gt;Last year, only one in six was funded. But this year, the agency awarded 24 percent fewer R01 grants.&lt;/p&gt;
    &lt;p&gt;This means fewer scientists had their research funded. Last year, the N.I.H.’s National Cancer Institute funded R01 applications from new investigators that fell in the top 10 percent based on scoring by the agency. But by the end of fiscal year 2025, it funded only the top 4 percent.&lt;/p&gt;
    &lt;p&gt;“Nobody believes that a fourth-percentile and a fifth-percentile grant are clearly of different quality,” Dr. Kobrin said. “It’s just not that precise a measurement.”&lt;/p&gt;
    &lt;head rend="h2"&gt;3. A drop in grants mentioning diversity&lt;/head&gt;
    &lt;p&gt;The Trump administration has prioritized eliminating research that involves diversity, equity and inclusion, and has eliminated hundreds of keywords related to diversity on federal websites.&lt;/p&gt;
    &lt;p&gt;A Times analysis found a steep reduction in the share of competitive N.I.H. grants whose titles or abstracts included flagged D.E.I.-related keywords (such as “equity,” “racial minority” or “underserved patient”) on a list shared by N.I.H. employees.&lt;/p&gt;
    &lt;p&gt;The data shows a big surge in these keywords after 2020, during the Biden administration.&lt;/p&gt;
    &lt;p&gt;While some of the decline in 2025 could be attributed to a change in the language that researchers use to describe their work, it also probably reflects a drop in research related to minority health. For example, the National Institute on Minority Health and Health Disparities awarded 61 percent fewer competitive grants this year, the steepest decline at any arm of the N.I.H.&lt;/p&gt;
    &lt;p&gt;N.I.H. employees said they did not receive clear guidance on how to determine if a project was D.E.I.-related. Instead, they were sent spreadsheets of grants that had been flagged for not complying with the Trump administration’s priorities.&lt;/p&gt;
    &lt;p&gt;“We’re constantly hearing that things have been flagged,” Dr. Kobrin said.&lt;/p&gt;
    &lt;p&gt;“Nobody wants to acknowledge what they were flagged for.”&lt;/p&gt;
    &lt;head rend="h2"&gt;4. Fewer fellowships for future scientists&lt;/head&gt;
    &lt;p&gt;The government provides critical funds for training new scientists through graduate student, postdoctoral and early-career fellowships and grants.&lt;/p&gt;
    &lt;p&gt;The N.S.F. has run a prestigious graduate research fellowship program since 1952. It funds three years of research for around 2,000 of the country’s top science graduate students.&lt;/p&gt;
    &lt;p&gt;This year, it awarded 536 fewer such fellowships. The government originally planned to eliminate 1,000 fellowships, but later added about 500 more after facing protests from scientists and academics.&lt;/p&gt;
    &lt;p&gt;The cut affected most fields, with fellowships in four areas — life sciences, psychology, STEM education and social sciences — being cut by more than half. Fellowships in computer science, an administration priority, grew by almost 50 percent.&lt;/p&gt;
    &lt;head rend="h3"&gt;National Science Foundation graduate research fellowships&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Field&lt;/cell&gt;
        &lt;cell role="head"&gt;2015-24 avg.&lt;/cell&gt;
        &lt;cell role="head"&gt;2025&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Life sciences&lt;/cell&gt;
        &lt;cell&gt;516&lt;/cell&gt;
        &lt;cell&gt;214&lt;/cell&gt;
        &lt;cell&gt;-59%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Psychology&lt;/cell&gt;
        &lt;cell&gt;117&lt;/cell&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;-52%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;STEM education&lt;/cell&gt;
        &lt;cell&gt;29&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;-52%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Social sciences&lt;/cell&gt;
        &lt;cell&gt;159&lt;/cell&gt;
        &lt;cell&gt;79&lt;/cell&gt;
        &lt;cell&gt;-50%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Math&lt;/cell&gt;
        &lt;cell&gt;90&lt;/cell&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;-38%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Geosciences&lt;/cell&gt;
        &lt;cell&gt;122&lt;/cell&gt;
        &lt;cell&gt;84&lt;/cell&gt;
        &lt;cell&gt;-31%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Engineering&lt;/cell&gt;
        &lt;cell&gt;575&lt;/cell&gt;
        &lt;cell&gt;406&lt;/cell&gt;
        &lt;cell&gt;-29%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Chemistry&lt;/cell&gt;
        &lt;cell&gt;176&lt;/cell&gt;
        &lt;cell&gt;154&lt;/cell&gt;
        &lt;cell&gt;-13%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Materials research&lt;/cell&gt;
        &lt;cell&gt;58&lt;/cell&gt;
        &lt;cell&gt;63&lt;/cell&gt;
        &lt;cell&gt;+9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Physics&lt;/cell&gt;
        &lt;cell&gt;139&lt;/cell&gt;
        &lt;cell&gt;166&lt;/cell&gt;
        &lt;cell&gt;+19%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Computer science&lt;/cell&gt;
        &lt;cell&gt;141&lt;/cell&gt;
        &lt;cell&gt;208&lt;/cell&gt;
        &lt;cell&gt;+48%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;2,121&lt;/cell&gt;
        &lt;cell&gt;1,500&lt;/cell&gt;
        &lt;cell&gt;-29%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There were also months of delays in publishing the fellowship application for next year, and new eligibility restrictions that exclude second-year Ph.D. students from applying, which may lower the numbers of fellowships in future years.&lt;/p&gt;
    &lt;p&gt;“This is an incredibly shortsighted and regressive change,” said Kevin Johnson, a former program director at N.S.F.’s geosciences directorate, because second-year graduate students are usually better prepared to conduct research.&lt;/p&gt;
    &lt;p&gt;“It sends a signal to future potential applicants that science is not supported and is not valued,” he said.&lt;/p&gt;
    &lt;p&gt;Early-career scientists are usually more reliant on federal funding because they have few alternatives to fund their research and training. Many go on to work in industry afterward, further fueling the economy.&lt;/p&gt;
    &lt;p&gt;In a 1945 report that led to the creation of the N.S.F., Vannevar Bush, who directed military research and development during World War II, argued that the government should invest in training the next generation of scientists to ensure American scientific progress.&lt;/p&gt;
    &lt;p&gt;But many experts worry that the recent funding cuts and budget reductions may threaten America’s role as a global scientific leader.&lt;/p&gt;
    &lt;p&gt;“I personally know many scientists in my field leaving the United States altogether,” Mr. Johnson said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nytimes.com/interactive/2025/12/02/upshot/trump-science-funding-cuts.html"/><published>2025-12-22T15:49:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355165</id><title>Claude Code gets native LSP support</title><updated>2025-12-22T18:16:36.981487+00:00</updated><content/><link href="https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md"/><published>2025-12-22T15:59:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355345</id><title>Your Supabase Is Public</title><updated>2025-12-22T18:16:36.853185+00:00</updated><content>&lt;doc fingerprint="ae03b73a2beebb7a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Your Supabase Is Public&lt;/head&gt;
    &lt;p&gt;Skilldeliver&lt;/p&gt;
    &lt;p&gt;I was chatting with a close friend of mine and he sent me a link to his new SaaS that he's developing. Of course when a friend sends me their new project my natural tendency is to try hack it.&lt;/p&gt;
    &lt;p&gt;First simple step: inspecting, checking if there's something interesting.&lt;/p&gt;
    &lt;p&gt;Voila, there is. A Supabase URL and anon key.&lt;/p&gt;
    &lt;p&gt;What makes it particularly easy is when they're using Supabase. It's so common from my side that every time I get access to a Supabase anon key just from inspecting the website and doing a simple curl request to check the tables everything is always unprotected and I get access to the whole database.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This is the third time I've discovered this and one of them was a seed stage startup 💀&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;With this endpoint you can fetch the OpenAPI schema to see what's exposed:&lt;/p&gt;
    &lt;code&gt;curl -X GET \
  'https://your-project.supabase.co/rest/v1/?apikey=your-anon-key' \
  -H "Accept: application/openapi+json"&lt;/code&gt;
    &lt;p&gt;But the schema itself isn't that interesting. The interesting part is checking if they've created a users table and have an endpoint for it. And in my case it was something like this:&lt;/p&gt;
    &lt;code&gt;curl -X GET \
  'https://your-project.supabase.co/rest/v1/users' \
  -H "apikey: your-anon-key" \
  -H "Authorization: Bearer your-anon-key"&lt;/code&gt;
    &lt;p&gt;And if you're lucky (which happens way too often) this returns a nice JSON with all the users names, nicknames, emails, passwords hashes and whatever else they decided to store.&lt;/p&gt;
    &lt;p&gt;I've never used Supabase for a production app but I think what's happening is people are creating additional public users tables and not setting proper RLS for them. The anon key is designed to be public but if you are not careful that anon key becomes a master key to your entire database.&lt;/p&gt;
    &lt;p&gt;I'm not going to blame the vibe-coding wave entirely. Maybe I'll put the blame on Supabase instead? Maybe it can be simple &lt;code&gt;if check&lt;/code&gt; if they create users table there should be a massive red warning popup explaining that everything in this table will be public unless RLS is enabled.&lt;/p&gt;
    &lt;p&gt;And in the spirit of Lovable announcing their $330 million Series B and knowing they also use Supabase. I'm starting to wonder what percentage of users actually make this mistake. With over 100,000 projects being created daily on platforms like Lovable, how many of those have exposed databases?&lt;/p&gt;
    &lt;p&gt;Again, you can take the stance that this is a skill issue on the users part but I'm not sure about that. You can design a system in a way that prevents this type of stuff from happening.&lt;/p&gt;
    &lt;p&gt;As an example Pocketbase handles this much better. It has a default &lt;code&gt;_pb_users_auth_&lt;/code&gt; collection that you can easily extend with new fields, and most importantly, it has default proper access control checks like &lt;code&gt;id = @request.auth.id&lt;/code&gt; already configured. You literally have to go out of your way to make it insecure.&lt;/p&gt;
    &lt;head rend="h2"&gt;I need a conclusion?&lt;/head&gt;
    &lt;p&gt;So I guess here the place where I need to say something smart or LLM generated conclusion - but I don't have. Merry Christmas! 🎄&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://skilldeliver.com/your-supabase-is-public"/><published>2025-12-22T16:14:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355793</id><title>Spotify reportedly investigating Anna's Archive's scraping of their library</title><updated>2025-12-22T18:16:36.507335+00:00</updated><content>&lt;doc fingerprint="a917e0a94bf57d69"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Trending on Billboard&lt;/head&gt;
    &lt;p&gt;Update (Dec. 22, 10:11 am): A Spotify spokesperson just released the following statement: “Spotify has identified and disabled the nefarious user accounts that engaged in unlawful scraping. We’ve implemented new safeguards for these types of anti-copyright attacks and are actively monitoring for suspicious behavior. Since day one, we have stood with the artist community against piracy, and we are actively working with our industry partners to protect creators and defend their rights.”&lt;/p&gt;
    &lt;p&gt;Original Story: A pirate activist group has scraped and released metadata from Spotify, according to a blog post on open source search engine Anna’s Archive.&lt;/p&gt;
    &lt;p&gt;The report alleges the scrape includes 256 million rows of track metadata and 86 million audio files, to be distributed on P2P networks in bulk torrents totaling roughly 300 terabytes. As of Sunday (Dec. 21), the report indicates only metadata, not music files, have been released.&lt;/p&gt;
    &lt;p&gt;In a statement obtained by Billboard, a representative for Spotify says, “An investigation into unauthorized access identified that a third party scraped public metadata and used illicit tactics to circumvent DRM to access some of the platform’s audio files.”&lt;/p&gt;
    &lt;p&gt; “We are actively investigating the incident,” Spotify notes.&lt;lb/&gt;Reactions to the initial report by Anna’s Archive, like one circulating via a LinkedIn post from Yoav Zimmerman, CEO/co-founder of Third Chair — a startup that uses AI to build legal tools for media companies — theorized “anyone can now, in theory, create their own personal free version of Spotify (all music up to 2025) with enough storage and a personal media streaming server like Plex. The only real barriers are copyright law and fear of enforcement.” &lt;lb/&gt;Spotify’s total audio files exceed the number mentioned by Anna’s Archive. Still, Zimmerman’s commentary points out that the incident could potentially dwarf the largest previously available open music archive, MusicBrainz, which contains around five million unique tracks.&lt;lb/&gt;Anna’s Archive, which typically focuses on books and papers, said the project is part of its mission of “preserving humanity’s knowledge and culture” and described the Spotify scrape as an effort to “build a music archive primarily aimed at preservation.”&lt;lb/&gt;The post added, “Of course Spotify doesn’t have all the music in the world, but it’s a great start.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.billboard.com/business/streaming/spotify-music-library-leak-1236143970/"/><published>2025-12-22T16:50:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355879</id><title>Mystery as YouTube creator's finance livestream appears on White House website</title><updated>2025-12-22T18:16:36.135226+00:00</updated><content>&lt;doc fingerprint="77069b3125f954fb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mystery as YouTube creator’s finance livestream appears on White House website&lt;/head&gt;
    &lt;p&gt;WASHINGTON (AP) — The livestream of a YouTube content creator talking about investments mysteriously appeared to take over a White House website, raising questions about whether the site was hacked.&lt;/p&gt;
    &lt;p&gt;The livestream appeared for at least eight minutes late Thursday on whitehouse.gov/live, where the White House usually streams live video of the president speaking.&lt;/p&gt;
    &lt;p&gt;It’s unclear if the website was breached or the video was linked accidentally by someone in the government. The White House said in a statement that it was “aware and looking into what happened.”&lt;/p&gt;
    &lt;p&gt;The video that appeared on the government-run website featured some of a more than two-hour livestream from Matt Farley, who posts as @RealMattMoney, as he answered financial questions.&lt;/p&gt;
    &lt;p&gt;Farley told The Associated Press on Friday that he had no idea what happened and learned about it after the fact.&lt;/p&gt;
    &lt;p&gt;He said he had not been contacted by the government and didn’t have any theories about how his livestream ended up on the website. He joked that he hoped President Donald Trump and his youngest son, Barron Trump, “are watching my streams and taking advice.”&lt;/p&gt;
    &lt;p&gt;“Had I known it would have been on the White House website, I probably would have had other things to talk about than personal finance,” Farley said.&lt;/p&gt;
    &lt;p&gt;When asked what other things he would discuss, Farley responded with a laugh and said: “What would you talk about with the world for eight minutes if you had an opportunity? I’m just some guy making YouTube videos about stocks.”&lt;/p&gt;
    &lt;p&gt;Trump’s administration and campaign have had a series of digital security breaches and challenges over the last year.&lt;/p&gt;
    &lt;p&gt;In May, government officials began investigating after elected officials, business executives and other prominent figures received text messages and phone calls from someone impersonating Susie Wiles, the Republican president’s chief of staff.&lt;/p&gt;
    &lt;p&gt;Last year, Iran hacked into Trump’s campaign. Sensitive internal documents were stolen and distributed, including a dossier on Vice President JD Vance, created before he was selected as Trump’s running mate.&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;Associated Press writer Bill Barrow contributed to this report from Atlanta.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://apnews.com/article/white-house-website-youtube-livestream-88d79b896ca6e5ecea33f3bf3e5c9278"/><published>2025-12-22T16:55:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355888</id><title>Jimmy Lai Is a Martyr for Freedom</title><updated>2025-12-22T18:16:35.780719+00:00</updated><content>&lt;doc fingerprint="7e22995531a79948"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Jimmy Lai Is a Martyr for Freedom&lt;/head&gt;
    &lt;head rend="h2"&gt;The self-made tycoon was convicted this week of violating Hong Kong's "national security" law. But he could have escaped it.&lt;/head&gt;
    &lt;p&gt;There are many interesting tidbits about the life of the political prisoner Jimmy Lai. He hid in the bottom of a fishing boat to escape mainland Communist China for Hong Kong at the ripe age of 12. He built a garment empire after spending his adolescence working, and sleeping, in garment factories. Without media experience, he started several successful news ventures—most notably the plucky and irreverent Apple Daily—which forcefully advocated for democracy and free speech. And he may be sentenced to die in prison in connection with his efforts promoting liberty in China.&lt;/p&gt;
    &lt;p&gt;But the most interesting fact, by far, is that Lai is a citizen of the United Kingdom (U.K.).&lt;/p&gt;
    &lt;p&gt;The dissident was convicted in Hong Kong earlier this week of two counts of conspiring to collude with foreign forces and one count of publishing seditious material—charges stemming from his crusade against illiberalism, a fight he has been waging for decades. Lai finding himself in trouble was not a surprise. That's especially true amid the backdrop of Hong Kong's "national security" law, which sought to cripple dissent, that took effect in 2020. He was arrested in August of that year and released on bail; authorities revoked it four months later. Lai has been in custody since.&lt;/p&gt;
    &lt;p&gt;That he would probably end up in prison, however, was never really in doubt. Which brings me back to his U.K. citizenship.&lt;/p&gt;
    &lt;p&gt;Lai did not have to stay in Hong Kong as the walls closed in on him. The self-made business tycoon—once a billionaire before the government froze his assets—could have fled to a residence abroad. His friend Mark Clifford, formerly the editor in chief of the South China Morning Post, told me in an interview earlier this year that many people in Lai's circle urged him to do just that.&lt;/p&gt;
    &lt;p&gt;He declined. "Everything I have was given to me by Hong Kong. I won't be leaving," Lai told Radio Free Asia in June 2020. "I'm going to stay here and fight to the bitter end."&lt;/p&gt;
    &lt;p&gt;Lawmakers would go on to formally approve the national security law, essentially a foregone conclusion, about three weeks later. The legislation broadly criminalized political dissent and hamstrung the civil liberties that once distinguished Hong Kong from mainland China. A defense of those freedoms—which were already under increasing attack—had come to define Lai's legacy. Lai not only unapologetically advanced democracy and free expression in the region, but he also met with then–Vice President Mike Pence and Secretary of State Mike Pompeo; at trial, Lai testified that he had asked them to voice their support for Hong Kong. He knew the law was coming, and he knew what it meant for him.&lt;/p&gt;
    &lt;p&gt;But some things, he decided, are more important than personal freedom. In this case, the absence of it was more important—in part to show the world what happens when an authoritarian government severely curtails basic liberties.&lt;/p&gt;
    &lt;p&gt;In some sense, there was no better person than Lai to send this message. His Cinderella story is impossible to divorce from Hong Kong itself. There, he was able to find refuge from the Chinese Communist Party, which had imprisoned his mother, deemed a "class enemy," in a labor camp. But he was also able to make something from nothing: from living in factories, while rats scampered across his body, to running them. His story came full circle. It demands people ask: Do you prefer Hong Kong's past? Or its future?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://reason.com/2025/12/19/jimmy-lai-is-a-martyr-for-freedom/"/><published>2025-12-22T16:56:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46355932</id><title>Uplane (YC F25) Is Hiring Founding Engineers (Full-Stack and AI)</title><updated>2025-12-22T18:16:35.245654+00:00</updated><content>&lt;doc fingerprint="d37fffed7efd5e8d"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.useparallel.com/uplane1/careers"/><published>2025-12-22T17:00:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46356182</id><title>Benn Jordan – This Flock Camera Leak Is Like Netflix for Stalkers [video]</title><updated>2025-12-22T18:16:34.280950+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=vU1-uiUlHTo"/><published>2025-12-22T17:19:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46356320</id><title>Henge Finder</title><updated>2025-12-22T18:16:34.112976+00:00</updated><content>&lt;doc fingerprint="aa0ce6e5647b06c2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Henge Finder&lt;/head&gt;
    &lt;head style="cursor: pointer; color: #5E4955; font-weight: 600; margin-bottom: 10px; padding: 15px; border-radius: 8px; background: #f8f9fa; border: 1px solid #e1e5e9; transition: background-color 0.2s;"&gt;What is a henge?&lt;/head&gt;
    &lt;p&gt;A 'henge' is when the sun sets perfectly in line with your street, creating a dramatic view — like Manhattanhenge in New York.&lt;/p&gt;
    &lt;p&gt;You can find out more information by clicking the "How Do Henges Work?" tab.&lt;/p&gt;
    &lt;p&gt;Use this tool to find when the next henge will happen for your street.&lt;/p&gt;
    &lt;head style="cursor: pointer; color: #5E4955; font-weight: 600; margin-bottom: 10px; padding: 15px; border-radius: 8px; background: #f8f9fa; border: 1px solid #e1e5e9; transition: background-color 0.2s;"&gt;What makes a good street for a henge?&lt;/head&gt;
    &lt;p&gt;(Tips for finding the best henge view)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pick a long, straight road with a clear view of the horizon.&lt;lb/&gt;Henges work best when you can actually see the sun touch the horizon. Curvy streets won't align well, and wider streets tend to give better views.&lt;/item&gt;
      &lt;item&gt;Aim for a mostly east–west street.&lt;lb/&gt;The sun won't set along a north–south road. It doesn't have to be perfect — the sunset shifts a little each day.&lt;/item&gt;
      &lt;item&gt;Avoid entering an intersection address if possible.&lt;lb/&gt;It's not necessary for this to work, but it will be faster.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example Streets:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;251 W 42nd St, New York, NY, by Times Square&lt;/item&gt;
      &lt;item&gt;601-615 E 76th St, Chicago, IL&lt;/item&gt;
      &lt;item&gt;Haarlemmerweg 109-C, 1051 KV Amsterdam, Netherlands, along the canal by the Wester Park&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;See How the Sun Moves Down The Street&lt;/head&gt;
    &lt;p&gt;The Sun doesn’t set in the same place every day. Its position along the horizon shifts as the seasons change.&lt;/p&gt;
    &lt;p&gt;Most evenings, that angle doesn’t match the direction of a street. But on just a few days each year (if the street is angled correctly), the Sun’s path lines up perfectly—creating a “henge.”&lt;/p&gt;
    &lt;p&gt;Compare below to see the sun's path on a henge and non-henge date:&lt;/p&gt;
    &lt;head rend="h3"&gt;Non-Henge Date&lt;/head&gt;
    &lt;head rend="h3"&gt;Henge Date&lt;/head&gt;
    &lt;head rend="h2"&gt;Earth's Orbital Motion and Axial Tilt&lt;/head&gt;
    &lt;p&gt;Earth doesn’t spin upright. It’s tilted on an axis of ~23.5˚. That tilt is what makes the seasons, and it’s also what makes henges possible.&lt;/p&gt;
    &lt;p&gt;As the tilted Earth circles the Sun, the angle of the sunset shifts across the horizon. A street keeps the same direction year-round, but the Sun only lines up on specific dates. Here, a road running along the equator lines up with the Sun at the equinox.&lt;/p&gt;
    &lt;p&gt;Move the slider to see how the Earth's tilt changes relative to the Sun throughout the year:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hengefinder.rcdis.co/#learn"/><published>2025-12-22T17:32:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46356603</id><title>AI Bathroom Monitors? Welcome to America's New Surveillance High Schools</title><updated>2025-12-22T18:16:33.955840+00:00</updated><content/><link href="https://www.forbes.com/sites/thomasbrewster/2025/12/16/ai-bathroom-monitors-welcome-to-americas-new-surveillance-high-schools/"/><published>2025-12-22T17:53:46+00:00</published></entry></feed>