<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-26T13:14:52.763705+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46754522</id><title>Bitwise conversion of doubles using only FP multiplication and addition (2020)</title><updated>2026-01-26T13:14:59.730561+00:00</updated><content>&lt;doc fingerprint="46999a3b01993edd"&gt;
  &lt;main&gt;
    &lt;p&gt;In the words of Tom Lehrer, “this is completely pointless, but may prove useful to some of you some day, perhaps in a somewhat bizarre set of circumstances.”&lt;/p&gt;
    &lt;p&gt;The problem is as follows: suppose you’re working in a programming environment that provides only an IEEE-754 double-precision floating point (“double”) type, and no operations that can access that type’s representation (such as C++ bitwise cast operations, or Javascript’s DataView object). You have a double and you want to convert it to its bitwise representation as two unsigned 32-bit integers (stored as doubles), or vice versa. This problem comes up from time to time, but I was curious about a different question: how restricted can your programming environment be? Could you do it with just floating point multiplication and addition?&lt;/p&gt;
    &lt;p&gt;Bitwise conversion using floating point operations can be useful in situations like limited interpreted languages, or C++ constexpr contexts. Generally double to int conversion can be done using a binary search, comparing with powers of two to figure out the bits of the exponent. From there the fraction bits can be extracted, either by binary searching more, or using the knowledge of the exponent to scale the fraction bits into the integer range.&lt;/p&gt;
    &lt;p&gt;But can it be done without bitwise operations, branches, exponentiation, division, or floating point comparisons?&lt;/p&gt;
    &lt;p&gt;It seemed improbable at first, but I’ve discovered the answer is yes, multiplication and addition are mostly sufficient, although with a few notable caveats. Even without these restrictions different NaN values cannot be distinguished or generated (without bitwise conversion) in most environments, but using only multiplication and addition it is impossible to convert NaN, Infinity or -Infinity into an unsigned 32-bit value. The other problematic value is “negative zero”, which cannot be differentiated from “positive zero” using addition and multiplication. All my code uses subtraction, although it could be removed by substituting &lt;code&gt;a - b&lt;/code&gt; with &lt;code&gt;a + (b * -1)&lt;/code&gt;. And finally, this relies on IEEE-754 operations (in the usual rounding mode, “round to nearest, ties to even”), so it wouldn’t work in environments that use unsafe maths optimisations (the default in shader compilers, or enabled by a flag such as /fp:fast in many other compilers).&lt;/p&gt;
    &lt;p&gt;So, if you just need a solution, here it is, but otherwise stick around for an explanation:&lt;/p&gt;
    &lt;quote&gt;function double_as_uint32s(double) { // Doesn't handle NaN, Infinity or -Infinity. Treats -0 as 0. var a = double, b, c, d, e, f, g, h, i, j, k, l, m, n, low, high; f=2.2250738585072014e-308+a; j=5e-324; b=j+f; b-=f; m=-5e-324; d=m+b; b=4.4989137945431964e+161; d=b*d; d=b*d; g=d*d; d=1.0; g=d-g; h=m+f; f=h-f; f=j+f; f=b*f; f=b*f; f*=f; f=d-f; f*=g; g=-2.2250738585072014e-308+a; h=j+g; h-=g; h=m+h; h=b*h; h=b*h; h*=h; h=d-h; c=m+g; c-=g; c=j+c; c=b*c; c=b*c; c*=c; c=d-c; c*=h; k=c*f; c=5.562684646268003e-309*a; g=j+c; g-=c; g=m+g; g=b*g; g=b*g; g*=g; g=d-g; h=m+c; h-=c; h=j+h; h=b*h; h=b*h; h*=h; h=d-h; g=h*g; h=a*g; g=d-g; c=g*c; g=1024.0*g; f=2.0+g; c+=h; h=7.458340731200207e-155*c; l=1.0000000000000002; g=l*h; g=m+g; e=j+g; e-=g; e=b*e; e=b*e; c=e*c; e=d-e; g=e*h; c=g+c; e=512.0*e; g=8.636168555094445e-78*c; e+=f; f=l*g; f=m+f; h=j+f; f=h-f; f=b*f; f=b*f; c=f*c; f=d-f; g=f*g; f=256.0*f; c=g+c; e=f+e; f=2.938735877055719e-39*c; g=l*f; g=m+g; h=j+g; g=h-g; g=b*g; g=b*g; c=g*c; g=d-g; f=g*f; c=f+c; f=128.0*g; g=5.421010862427522e-20*c; e=f+e; f=l*g; f=m+f; h=j+f; f=h-f; f=b*f; f=b*f; c=f*c; f=d-f; g=f*g; f=64.0*f; c=g+c; e=f+e; i=2.3283064365386963e-10; f=i*c; g=l*f; g=m+g; h=j+g; g=h-g; g=b*g; g=b*g; c=g*c; g=d-g; f=g*f; c=f+c; f=32.0*g; g=1.52587890625e-05*c; e=f+e; f=l*g; f=m+f; h=j+f; f=h-f; f=b*f; f=b*f; c=f*c; f=d-f; g=f*g; f=16.0*f; c=g+c; e=f+e; f=0.00390625*c; g=l*f; g=m+g; h=j+g; g=h-g; g=b*g; g=b*g; c=g*c; g=d-g; f=g*f; c=f+c; f=8.0*g; g=0.0625*c; e=f+e; f=l*g; f=m+f; h=j+f; f=h-f; f=b*f; f=b*f; c=f*c; f=d-f; g=f*g; f=4.0*f; c=g+c; e=f+e; f=0.25*c; g=l*f; g=m+g; h=j+g; g=h-g; g=b*g; g=b*g; c=g*c; g=d-g; f=g*f; c=f+c; f=g+g; e=f+e; n=0.5; f=n*c; g=l*f; g=m+g; h=j+g; g=h-g; g=b*g; g=b*g; c=g*c; g=d-g; f=g*f; c=f+c; e=g+e; f=d-k; g=j+a; g-=a; g=m+g; g=b*g; g=b*g; g*=g; g=d-g; h=m+a; a=h-a; a=j+a; a=b*a; a=b*a; a*=a; a=d-a; a*=g; g=f*a; a=d-a; a=e*a; a+=g; e=l*c; e=m+e; g=j+e; e=g-e; e=b*e; e=b*e; g=n*c; c=e*c; e=d-e; e*=g; c=e+c; e=4.450147717014403e-308+c; g=j+e; g-=e; g=m+g; g=b*g; g=b*g; g*=g; g=d-g; h=m+e; e=h-e; e=j+e; e=b*e; e=b*e; e*=e; e=d-e; e*=g; g=e+e; d-=g; c=d*c; c=b*c; b*=c; c=-4503599627370496.0*f; c+=b; b=i*c; b=-0.4999999998835847+b; b=4503599627370497.0+b; d=-4503599627370497.0+b; b=2147483648.0*e; a=1048576.0*a; a=b+a; b=d+a; a=-4294967296.0*d; a+=c; low=a; high=b; return [low, high]; } function uint32s_as_double(low, high) { var a = low, b = high, c, d, e, f, g, h, i, j, k, l, m; b=9.5367431640625e-07*b; f=-0.4999999998835847; c=f+b; g=4503599627370497.0; c=g+c; e=-4503599627370497.0; c=e+c; d=b-c; c=0.00048828125*c; b=f+c; b=g+b; k=e+b; l=c-k; j=2.2250738585072014e-308; c=j+l; c-=l; i=4.49423283715579e+307; b=i*c; c=1.0; b=c-b; a=2.220446049250313e-16*a; h=-0.00048828125+l; a=d+a; d=b*h; d+=d; h=f+d; h=g+h; h=e+h; d-=h; b+=a; b=j*b; m=1.3407807929942597e+154; h=m*h; h=c+h; b=h*b; b*=h; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=m*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=1.157920892373162e+77*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=3.402823669209385e+38*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=1.8446744073709552e+19*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=4294967295.0*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=65535.0*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=255.0*h; h=c+h; b=h*b; d+=d; h=f+d; h=g+h; h=e+h; d-=h; h=15.0*h; h=c+h; b=h*b; d+=d; f+=d; f=g+f; e+=f; d-=e; e=3.0*e; e=c+e; b=e*b; d+=d; d=c+d; b=d*b; d=-0.99951171875+l; e=j+d; d=e-d; d=i*d; e=j+a; a=e-a; a=i*a; a=c-a; a=d*a; a=m*a; a=m*a; a-=a; a=b+a; b=k+k; b=c-b; a*=b; return a; }&lt;/quote&gt;
    &lt;p&gt;(I’m mostly joking, but it would be pretty funny to find that code buried in a library someday, and it should be pretty easy to port to just about any language.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Background: IEEE-754 Doubles&lt;/head&gt;
    &lt;p&gt;This aims to be a concise explanation of everything you need to know about doubles to understand the rest of the article. Skip it if you know it already.&lt;/p&gt;
    &lt;p&gt;A double is a 64-bit value. Going from most-significant-bit to least-significant-bit, it is comprised of a 1-bit &lt;code&gt;sign&lt;/code&gt;, an 11-bit &lt;code&gt;exponent&lt;/code&gt; and a 52-bit &lt;code&gt;fraction&lt;/code&gt;. These bits are interpreted as either a special value, or a numerical value as described in the following pseudocode. The operations and values in the pseudocode have infinite precision, and &lt;code&gt;**&lt;/code&gt; is the exponentiation operation.&lt;/p&gt;
    &lt;quote&gt;if (sign == 1) s = -1; else s = 1; if (exponent == 0x7FF) { // Maximum exponent means a special value if (fraction == 0) return NaN; // Not a Number else if (sign == 1) return -Infinity; else return Infinity; } else if (exponent == 0) { // Zero exponent means a subnormal value. return s * (0.0 + fraction * (2 ** -52)) * (2 ** -1022); } else { // Everything else is a normal value. return s * (1.0 + fraction * (2 ** -52)) * (2 ** (exponent-1023)); }&lt;/quote&gt;
    &lt;p&gt;Normal values have an implicit leading 1, and can be thought of as “1.fraction”. Subnormals do not, so can be thought of as “0.fraction”, but they are otherwise the same as &lt;code&gt;exponent&lt;/code&gt; == 1.&lt;/p&gt;
    &lt;p&gt;This has been carefully designed, and gives a few interesting properties:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The implicit leading one ensures that each value has a unique representation (except for 0/-0 and NaN).&lt;/item&gt;
      &lt;item&gt;The subnormals ensure that distance between representable numbers only ever decreases as you get closer to zero, so the difference between two sequential values (also known as a “unit in last place” or ULP) is always exactly representable.&lt;/item&gt;
      &lt;item&gt;For positive numbers, the floating point value increases with its 64-bit integer representation, so they could be compared as integers, or you can find the next representable value by adding 1 to its int64 representation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Addition and multiplication of doubles is defined as exact, infinitely-precise, mathematical addition and multiplication. If the exact result can be represented by a double, that double is the result, otherwise rounding occurs. IEEE-754 specifies several rounding modes that can be used, but I’ll focus on the most widely used one “round to nearest, ties to even”. This means that the nearest representable value is used, or if the exact result is half way between two representable values, the value with zero in its least significant &lt;code&gt;fraction&lt;/code&gt; bit is used. If the infinitely precise result gets too large or too small, it will be rounded to Infinity or -Infinity (see IEEE-754-2008 section 4.3.1 for a formal definition).&lt;/p&gt;
    &lt;p&gt;Finally, we should consider the special values. If NaN is an input to an addition or multiplication, the result will always be NaN. Multiplication and addition with Infinity or -Infinity will result in other Infinity or -Infinity values, with the exceptions of multiplying Infinity by zero, or subtracting Infinity from Infinity, both of which will result in NaN.&lt;/p&gt;
    &lt;head rend="h2"&gt;Notation&lt;/head&gt;
    &lt;p&gt;From this point onward, this is an attempt at something like literate programming, presented in essentially the order I created it, starting with just multiply, add and subtract, then building progressively more powerful functions. The code was written as C++, and has been refactored to simplify the explanation. I do make use of loops and functions, but only where they can be completely unrolled or inlined by the compiler.&lt;/p&gt;
    &lt;p&gt;I’ve omitted the function &lt;code&gt;double p2(int e)&lt;/code&gt;, which provides a power of two – everywhere it is used it gets inlined as a constant, but the easiest way to ensure this was to use a lookup table with 2098 values.&lt;/p&gt;
    &lt;p&gt;The macro &lt;code&gt;CONSTEXPR&lt;/code&gt; is defined as follows, mostly to allow adjustments to inlining, or removing the &lt;code&gt;constexpr&lt;/code&gt; keyword from everything easily:&lt;/p&gt;
    &lt;quote&gt;#define CONSTEXPR \ constexpr static inline __attribute__((always_inline))&lt;/quote&gt;
    &lt;p&gt;Throughout this text I’ve used &lt;code&gt;exponent&lt;/code&gt; to mean the encoded exponent bits in a double, as opposed to the unbiased/decoded exponent (&lt;code&gt;exponent - 1023&lt;/code&gt;). Hopefully that’s not too confusing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Logic Operations&lt;/head&gt;
    &lt;p&gt;I started by investigating what you can do with only addition and multiplication. Supposing “true” is 1.0 and “false” is 0.0, I implemented some logic operations:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double double_and(double a, double b) { return a * b; } CONSTEXPR double double_not(double a) { return 1 - a; } CONSTEXPR double double_or(double a, double b) { return a + b - a * b; } CONSTEXPR double select( double condition, double if_true, double if_false) { return condition * if_true + double_not(condition) * if_false; }&lt;/quote&gt;
    &lt;p&gt;These are mostly presented without further comment, as they can be tested exhaustively. However &lt;code&gt;select&lt;/code&gt; is where things get a bit tricky. Because &lt;code&gt;Infinity * 0 = NaN&lt;/code&gt; and &lt;code&gt;NaN + anything = NaN&lt;/code&gt;, we can never ignore Infinity values and must be meticulous about never performing operations that could create them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Avoiding Infinities&lt;/head&gt;
    &lt;p&gt;Given I want to convert an arbitrary floating point number to its bitwise representation, I had to start by figuring out what operations I could do on any floating point number without risking creating an Infinity.&lt;/p&gt;
    &lt;p&gt;One option here is multiplying by values between 1.0 and -1.0 inclusive as the result will never increase in magnitude. This works in any rounding mode.&lt;/p&gt;
    &lt;p&gt;We can also add any constant value between &lt;code&gt;p2(969)&lt;/code&gt; and &lt;code&gt;-p2(969)&lt;/code&gt; exclusive, as this will not round to infinity when added to the positive or negative values of greatest magnitude. However, this only works in round-to-nearest or round-toward-zero modes, as round-toward-positive and round-toward-negative may round to Infinity when adding even the smallest non-zero value.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Initial Comparison&lt;/head&gt;
    &lt;p&gt;I figured I would need to construct &lt;code&gt;(x == y)&lt;/code&gt; and &lt;code&gt;(x &amp;lt; y)&lt;/code&gt; comparisons – something that would give me a boolean 0.0 or 1.0 that I could use with my logic functions. But I couldn’t even come up with a way to compute &lt;code&gt;(x == 0)&lt;/code&gt;. So I instead started with the question: what boolean value can I create?&lt;/p&gt;
    &lt;p&gt;Consider floating point addition of the smallest positive value (&lt;code&gt;p2(-1074)&lt;/code&gt;) to a number. If &lt;code&gt;exponent&lt;/code&gt; (the value of the encoded bits) is zero or one, this value is the ULP (distance between subsequent representable floating point values), so the result will be exact. When &lt;code&gt;exponent&lt;/code&gt; is two, the ULP is doubled, so the exact result will land between two representable values, so it will “round to even”, and either round up (adding &lt;code&gt;p2(-1073)&lt;/code&gt; instead) or round down (leaving the value unchanged). Finally, if the &lt;code&gt;exponent&lt;/code&gt; is four or above, the exact result of the addition will never reach the midpoint between representable values, so rounding to nearest will leave the value unchanged.&lt;/p&gt;
    &lt;p&gt;That explanation doesn’t completely cover the boundaries between &lt;code&gt;exponent&lt;/code&gt; values. Importantly, when adding &lt;code&gt;p2(-1074)&lt;/code&gt; to the negative number with &lt;code&gt;exponent&lt;/code&gt; two and fraction zero, the result will have &lt;code&gt;exponent&lt;/code&gt; one, and therefore is exactly representable (although the same is not true for the corresponding positive number).&lt;/p&gt;
    &lt;p&gt;So, supposing we compute &lt;code&gt;x + p2(-1074) - x&lt;/code&gt; we will get either &lt;code&gt;p2(-1074) * 2&lt;/code&gt; or &lt;code&gt;0&lt;/code&gt; if there was rounding, or &lt;code&gt;p2(-1074)&lt;/code&gt; if the result of the addition is accurate.&lt;/p&gt;
    &lt;p&gt;This can be turned into a boolean like so:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double adding_smallest_is_precise(double x) { double add_error = x + p2(-1074) - x; // add_error is in {0, p2(-1074), 2 * p2(-1074)} add_error -= p2(-1074); // add_error is in {-p2(-1074), 0, p2(-1074)} // divide by p2(-1074), by multiplying by p2(1074). p2(1074) is // out of range, so multiply by its square root twice instead. add_error = add_error * p2(1074/2) * p2(1074/2); // add_error is in {-1, 0, 1} add_error *= add_error; // add_error is in {1, 0, 1} return double_not(add_error); }&lt;/quote&gt;
    &lt;p&gt;This function computes &lt;code&gt;-p2(-1021) &amp;lt;= d &amp;lt; p2(-1021)&lt;/code&gt;, which is enough to start constructing other comparisons.&lt;/p&gt;
    &lt;p&gt;However, this comparison is frustratingly asymmetric, so we’ll compute &lt;code&gt;-p2(-1021) &amp;lt; d &amp;lt; p2(-1021)&lt;/code&gt; as follows. This is equivalent to checking if the &lt;code&gt;exponent&lt;/code&gt; is zero or one.&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_exp_0_or_1(double x) { double precise_add = adding_smallest_is_precise(x); double precise_sub = adding_smallest_is_precise(-x); return double_and(precise_add, precise_sub); }&lt;/quote&gt;
    &lt;head rend="h2"&gt;Equality Comparisons&lt;/head&gt;
    &lt;p&gt;To start with, it’d be good to compute &lt;code&gt;x == 0&lt;/code&gt;. We can now do that by taking the minimum and maximum values that satisfy &lt;code&gt;is_exp_0_or_1&lt;/code&gt; and checking that &lt;code&gt;x + v&lt;/code&gt; still satisfies &lt;code&gt;is_exp_0_or_1&lt;/code&gt; for both:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_zero(double x) { double magic = p2(-1021) - p2(-1074); return double_and(is_exp_0_or_1(x + magic), is_exp_0_or_1(x - magic)); }&lt;/quote&gt;
    &lt;p&gt;This works, and is Infinity-safe, as the magic number is nowhere near the limit of &lt;code&gt;p2(969)&lt;/code&gt;. It also gives us a way to implement &lt;code&gt;x == y&lt;/code&gt;, by checking &lt;code&gt;is_zero(x - y)&lt;/code&gt;. However, &lt;code&gt;x - y&lt;/code&gt; may be Infinity, so we must first implement a safe subtraction operation for comparisons:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double cmp_sub(double x, double y) { // return a number with the same sign as x-y (or zero // if x-y==0), while avoiding returning infinity. double small = double_or(is_exp_around_0_or_1(x), is_exp_around_0_or_1(y)); double multiplier = (small + 1) * p2(-1); return (x * multiplier) - (y * multiplier); }&lt;/quote&gt;
    &lt;p&gt;If either value has a tiny &lt;code&gt;exponent&lt;/code&gt;, then &lt;code&gt;x - y&lt;/code&gt; cannot become infinite. However, if both values have an &lt;code&gt;exponent&lt;/code&gt; &amp;gt;= 2, multiplying by &lt;code&gt;p2(-1)&lt;/code&gt; will be lossless (it just subtracts 1 from the &lt;code&gt;exponent&lt;/code&gt;). As such, the result will be zero when &lt;code&gt;x == y&lt;/code&gt;, will be positive when &lt;code&gt;x &amp;gt; y&lt;/code&gt; and will be negative when &lt;code&gt;x &amp;lt; y&lt;/code&gt;. So we can test equality like so:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_equal(double x, double y) { return is_zero(cmp_sub(x, y)); }&lt;/quote&gt;
    &lt;p&gt;Unfortunately, we still don’t have a way to calculate &lt;code&gt;x &amp;lt; 0&lt;/code&gt; (which would give us &lt;code&gt;x &amp;lt; y&lt;/code&gt;), but we’ll get back to that later.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting the Exponent&lt;/head&gt;
    &lt;p&gt;If we want to convert a double to its bitwise representation, we’ll need to extract its encoded exponent. So far, we can check if the &lt;code&gt;exponent&lt;/code&gt; is zero or one.&lt;/p&gt;
    &lt;p&gt;We can use that to build a test for if the &lt;code&gt;exponent&lt;/code&gt; is zero (i.e. the value is a subnormal), by adding constants that shift values with &lt;code&gt;exponent&lt;/code&gt; one outside of the range:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_exp_0(double x) { return double_and(is_exp_0_or_1(x + p2(-1022)), is_exp_0_or_1(x - p2(-1022))); }&lt;/quote&gt;
    &lt;p&gt;The other thing we want is to multiply by negative powers of two. This will subtract a constant from the &lt;code&gt;exponent&lt;/code&gt; (leaving the fraction unchanged), unless the &lt;code&gt;exponent&lt;/code&gt; reaches zero, in which case rounding will occur (possibly rounding up to a value with &lt;code&gt;exponent&lt;/code&gt; one). This can be used to build tests for if the &lt;code&gt;exponent&lt;/code&gt; is less than a given value. For example, &lt;code&gt;is_exp_0_or_1(v * p2(-1024))&lt;/code&gt; will be true if the &lt;code&gt;exponent&lt;/code&gt; is less than 1024 + 2.&lt;/p&gt;
    &lt;p&gt;This can be used to binary search the value of the &lt;code&gt;exponent&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double get_encoded_exponent(double v) { double tmp = v; double e = 0; #pragma unroll for (int test = 1024; test &amp;gt;= 1; test /= 2) { double trial = tmp * p2(-test); double too_small = is_exp_0_or_1(trial); tmp = select(too_small, tmp, trial); e += select(too_small, 0, test); } return select(is_exp_0_or_1(v), double_not(is_exp_0(v)), e + 2); }&lt;/quote&gt;
    &lt;p&gt;This will check if the encoded exponent is less than 2 + 1024, and if not, it’ll subtract 1024 from the encoded exponent (by multiplying by &lt;code&gt;p2(-1024)&lt;/code&gt;), and add 1024.0 to our exponent value. This is repeated with smaller powers of two, until we know that the remaining encoded exponent is 0, 1, or 2, and the &lt;code&gt;e&lt;/code&gt; variable will contain the amount subtracted. Finally, it uses the &lt;code&gt;is_exp_0_or_1&lt;/code&gt; and &lt;code&gt;is_exp_0&lt;/code&gt; functions to handle the zero and one cases explicitly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Complete Comparisons&lt;/head&gt;
    &lt;p&gt;This is a great step towards bitwise casts, but &lt;code&gt;tmp&lt;/code&gt; in &lt;code&gt;get_encoded_exponent&lt;/code&gt; is interesting. By the end of the function, we’ve preserved its &lt;code&gt;sign&lt;/code&gt; and &lt;code&gt;fraction&lt;/code&gt; bits, but its &lt;code&gt;exponent&lt;/code&gt; has been converted to only 0, 1, or 2. This makes the challenge of testing &lt;code&gt;x &amp;lt; 0&lt;/code&gt; much simpler.&lt;/p&gt;
    &lt;p&gt;We can easily define a &lt;code&gt;make_exp_0_or_1&lt;/code&gt; function, that does the same thing, but also halves values that were left with &lt;code&gt;exponent&lt;/code&gt; two:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double make_exp_0_or_1(double v) { double res = v; #pragma unroll for (int test = 1024; test &amp;gt;= 1; test /= 2) { double trial = res * p2(-test); res = select(is_exp_0_or_1(trial), res, trial); } return select(is_exp_0_or_1(res), res, res * p2(-1)); }&lt;/quote&gt;
    &lt;p&gt;Now we can add a constant to shift all non-negative values out of the zero-or-one &lt;code&gt;exponent&lt;/code&gt; range, such that only values less than zero pass the &lt;code&gt;is_exp_0_or_1&lt;/code&gt; test.&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_less_than_zero(double v) { return is_exp_0(make_exp_0_or_1(v) + p2(-1022)); }&lt;/quote&gt;
    &lt;p&gt;And, using our &lt;code&gt;cmp_sub&lt;/code&gt; from earlier, we can compute &lt;code&gt;(x &amp;lt; y)&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_less_than(double a, double b) { return is_less_than_zero(cmp_sub(a, b)); }&lt;/quote&gt;
    &lt;head rend="h2"&gt;Floor&lt;/head&gt;
    &lt;p&gt;The final tool we need before we can put together out bitwise casts is &lt;code&gt;floor&lt;/code&gt;. For this, we’ll consider only numbers between zero and &lt;code&gt;p2(52)&lt;/code&gt;, and we’ll use a trick I’ve seen in the past (e.g. in musl libc’s floor.c). The trick is to add and subtract &lt;code&gt;p2(52)&lt;/code&gt;. Within the range &lt;code&gt;p2(52)&lt;/code&gt; to &lt;code&gt;p2(53)&lt;/code&gt;, the ULP is exactly 1, so &lt;code&gt;x + p2(52) - p2(52)&lt;/code&gt; performs a round-to-nearest-integer operation. From here, we can simply check if it rounded up, and subtract 1 if it did:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double small_positive_floor(double v) { // WARNING: incorrect for negative numbers and some // values over p2(52) // (but works for zero despite the name) double r = v + p2(52) - p2(52); return select(is_less_than(v, r), r - 1, r); }&lt;/quote&gt;
    &lt;p&gt;This lets us extract specific bits from a floating point integer. Specifically, I use the following idiom to split &lt;code&gt;n&lt;/code&gt; low bits from an integer &lt;code&gt;x&lt;/code&gt;: &lt;code&gt;high_part = floor(x * p2(-n)); low_part = x - high_part * p2(n);&lt;/code&gt;&lt;/p&gt;
    &lt;head rend="h2"&gt;Double to bits&lt;/head&gt;
    &lt;p&gt;So, how close are we to converting a double to its bits? &lt;code&gt;get_encoded_exponent&lt;/code&gt; gives us the exponent bits. &lt;code&gt;is_less_than_zero&lt;/code&gt; gives us the sign bit.&lt;/p&gt;
    &lt;p&gt;For the fraction, &lt;code&gt;make_exp_0_or_1&lt;/code&gt; has given us all the fraction bits, but preserved the sign, and the implicit leading &lt;code&gt;1&lt;/code&gt; if the number isn’t subnormal.&lt;/p&gt;
    &lt;p&gt;We can clear the sign bit by multiplying by &lt;code&gt;-1&lt;/code&gt; if the value is negative. We can subtract the implicit leading &lt;code&gt;1&lt;/code&gt; if the value isn’t subnormal to be left with only the fraction bits, and then scale it up by &lt;code&gt;p2(1047)&lt;/code&gt; so that a fraction of &lt;code&gt;1&lt;/code&gt; is &lt;code&gt;1.0&lt;/code&gt;:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double get_fraction(double v) { double result = make_exp_0_or_1(v) * select(is_less_than_zero(v), -1, 1); result -= select(is_exp_0(v), 0, p2(-1022)); result = result * p2(1074 / 2) * p2(1074 / 2); return result; }&lt;/quote&gt;
    &lt;p&gt;This gives us a 1-bit &lt;code&gt;sign&lt;/code&gt; value, an 11-bit &lt;code&gt;exponent&lt;/code&gt; value, and a 52-bit &lt;code&gt;fraction&lt;/code&gt; value (all stored as integers within doubles), so we just need to split that into two 32-bit values.&lt;/p&gt;
    &lt;p&gt;These traditionally bitwise ops are written using multiplication by powers of two as a constant shift (with floor to truncate the result), addition to set bits (instead of bitwise “or”), and subtraction to clear bits (instead of bitwise “and”):&lt;/p&gt;
    &lt;quote&gt;struct low_high_doubles { double low; double high; }; CONSTEXPR struct low_high_doubles constexpr_double_as_ints(double v){ double sign = is_less_than_zero(v); double exponent = get_encoded_exponent(v); double fraction = get_fraction(v); double high_fraction = small_positive_floor(fraction * p2(-32)); double high = sign * p2(31) + exponent * p2(20) + high_fraction; double low = fraction - high_fraction * p2(32); return { low, high }; }&lt;/quote&gt;
    &lt;head rend="h2"&gt;Bits to double&lt;/head&gt;
    &lt;p&gt;To convert bits to double, we can roughly follow the inverse. This is conceptually a bit simpler, so it’s only explained lightly in the comments:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double double_from_sign_exp_fraction( double sign, double exponent, double fraction) { double exp_is_non_zero = double_not(is_zero(exponent)); // scale fraction down to exponent 0 double v = fraction * p2(-1074); // add the implicit leading one if needed (so exponent = 1) v += select(exp_is_non_zero, p2(-1022), 0); // compute how much we need to increment the exponent by double e = select(exp_is_non_zero, exponent - 1, 0); // shift it so that all but the first bit is after the point e *= p2(-10); #pragma unroll for (int test = 1024; test &amp;gt;= 1; test &amp;gt;&amp;gt;= 1) { // cond will be 1 if the relevant bit is set, otherwise 0 double cond = small_positive_floor(e); // clear the current bit and shift the next bit into the // ones place e = (e - cond) * 2; if (test == 1024) { // p2(1024) is unrepresentable, so multiply by its // square root twice v *= select(cond, p2(512), 1.0); v *= select(cond, p2(512), 1.0); } else { v *= select(cond, p2(test), 1.0); } } // generate a NaN value if one is expected. double is_nan = double_and(is_equal(exponent, 2047), double_not(is_zero(fraction))); // if it's a NaN, "v" will already be Infinity, so multiply by // zero to make it NaN, otherwise multiply by one to leave it // as-is. v *= double_not(is_nan); // set the sign bit v *= select(sign, -1, 1); return v; }&lt;/quote&gt;
    &lt;p&gt;Finally, we just need to extract the sign, exponent and fraction fields from the high and low unsigned 32-bit integers:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double constexpr_ints_as_double(double l, double h) { double exp_and_sign = small_positive_floor(h * p2(-20)); double sign = small_positive_floor(h * p2(-31)); double exponent = exp_and_sign - sign * p2(11); double fraction = (h - exp_and_sign * p2(20)) * p2(32) + l; return double_from_sign_exp_fraction(sign, exponent, fraction); }&lt;/quote&gt;
    &lt;p&gt;The code presented above is true to my initial implementation, but ends up quite bloated, compiling to around 5000 add, subtract or multiply operations (assuming it’s all inlined and unrolled). You can see it on Compiler Explorer or gist.&lt;/p&gt;
    &lt;head rend="h2"&gt;“Dirty” floor trick&lt;/head&gt;
    &lt;p&gt;Perhaps that would be a good place to leave it, but I tried to optimise the number of operations a little. To decrease the size to something comparable to what’s shown in the initial Javascript (around 368 operations), a number of less safe or less clear functions and techniques are used.&lt;/p&gt;
    &lt;p&gt;The biggest problem is &lt;code&gt;floor&lt;/code&gt;, which requires the &lt;code&gt;make_exp_0_or_1&lt;/code&gt; operation every time (binary searching the exponent takes a fair number of instructions). In every situation we use “floor” we know a lot about the range of the value, and the number of bits present after the point. This lets us implement &lt;code&gt;floor&lt;/code&gt; without a comparison, by just biasing the input numbers such that round-to-nearest-ties-to-even will round down.&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double dirty_floor(double v) { // for values between 0 and 0x100000 with up to 32 significant bits // after the "decimal" point. return v - (0.5 - p2(-33)) + (p2(52)+1) - (p2(52)+1); }&lt;/quote&gt;
    &lt;p&gt;This might be the most complex trick, so to explain a little more: ignoring edge cases we could say that &lt;code&gt;floor(x) == roundToNearestEven(x - 0.5)&lt;/code&gt;. But the “edge case” here is integers, which will end up exactly between two integers, so round-to-even will round half of all integers down, giving the wrong result.&lt;/p&gt;
    &lt;p&gt;We can get the right result by subtracting slightly less than 0.5 instead. How much less? Well, it can’t make any other value land on 0.5, so it must be smaller than the smallest distance between possible inputs. But it also can’t get rounded off, so it must be at least the ULP for the biggest possible input.&lt;/p&gt;
    &lt;p&gt;This is impossible to solve if you have 53 significant bits, but fortunately we don’t. The constant chosen works out exactly for our 52-bit fraction being shifted right by 32, and happens to work everywhere else, as there are both fewer significant bits and no larger values.&lt;/p&gt;
    &lt;head rend="h2"&gt;More tweaks&lt;/head&gt;
    &lt;p&gt;Revisiting the initial comparison, a cheaper symmetrical boolean test was found. This computes &lt;code&gt;-p2(-1021) &amp;lt;= d &amp;lt;= p2(-1021)&lt;/code&gt; (i.e. the same as &lt;code&gt;is_exp_0_or_1&lt;/code&gt; but including one value on either side).&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_exp_around_0_or_1(double v) { double biased = v - p2(-1074); return (biased + p2(-1074) - biased) * p2(1074 / 2) * p2(1074 / 2); }&lt;/quote&gt;
    &lt;p&gt;(This can be analysed case-by-case, but essentially the initial bias both makes it symmetrical, and prevents a subsequent round-to-even from ever rounding away from the biased value, simplifying the conversion to boolean.)&lt;/p&gt;
    &lt;p&gt;We can go a bit further to try to replace &lt;code&gt;is_exp_0_or_1&lt;/code&gt; by multiplying the input by the smallest double greater than one. Unfortunately, this can generate Infinity when called on arbitrary values, but we can use it on all but the first iteration of our exponent decreasing loops.&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double unsafe_is_exp_0_or_1(double v) { // only works for non-huge numbers return is_exp_around_0_or_1(v * (p2(0) + p2(-52))); }&lt;/quote&gt;
    &lt;p&gt;We can use much coarser comparisons when we know a number is either zero or a long way from zero, as we do when comparing the “exponent” or “fraction” values:&lt;/p&gt;
    &lt;quote&gt;CONSTEXPR double is_integer_zero(double v) { return (v + p2(-1022) - v) * p2(1022); } CONSTEXPR double is_small_integer_equal(double a, double b) { return is_integer_zero(a - b); }&lt;/quote&gt;
    &lt;p&gt;Despite the names, I can and did use these method on non-integers without worrying, when I knew they were well above roughly &lt;code&gt;p2(-900)&lt;/code&gt; (around which we might have to worry about the addition being accurate for a non-zero value).&lt;/p&gt;
    &lt;p&gt;Finally, there were just a lot of little simplifications that the compiler cannot perform. A lot of duplicate work was removed by computing &lt;code&gt;sign&lt;/code&gt;, &lt;code&gt;exponent&lt;/code&gt; and &lt;code&gt;fraction&lt;/code&gt; at the same time in one big function. Throughout the code, &lt;code&gt;select(cond, x, y)&lt;/code&gt; with constant x and y could often be written as &lt;code&gt;(x - y) * cond + y&lt;/code&gt;, which simplifies even further if &lt;code&gt;y&lt;/code&gt; is zero. And there were plenty of other algebraic simplifications of little note.&lt;/p&gt;
    &lt;p&gt;You can find my optimised code on Compiler Explorer or gist. (Although this doesn’t quite match the code in this post, it should match the Javascript at the top closely.)&lt;/p&gt;
    &lt;p&gt;The Javascript was generated by compiling the optimised code with &lt;code&gt;clang++ -O2 -fno-slp-vectorize -march=skylake -std=c++14 -fomit-frame-pointer -S&lt;/code&gt;, which generated an assembly file containing a stream of &lt;code&gt;vaddsd&lt;/code&gt;, &lt;code&gt;vsubsd&lt;/code&gt; and &lt;code&gt;vmulsd&lt;/code&gt; instructions, as well as &lt;code&gt;vmovsd&lt;/code&gt; instructions to load constants. These instructions were translated into Javascript using a terrible Python script.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future work&lt;/head&gt;
    &lt;p&gt;As noted, this was a completely pointless exercise, but it does open up some avenues for further pointless exercises:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Can it be generalised to work for &lt;code&gt;float&lt;/code&gt;as well (splitting to two 16-bit values)?&lt;/item&gt;
      &lt;item&gt;Can it be extended to other rounding modes? All other rounding modes?&lt;/item&gt;
      &lt;item&gt;Are there simpler or smaller implementations of the various operations used?&lt;/item&gt;
      &lt;item&gt;Could it be turned into a reasonable expression, with no variables, just nested additions and subtractions? Doing so naively gives multi-gigabyte results, but no effort was made to optimise for this.&lt;/item&gt;
      &lt;item&gt;This roughly shows that any function from finite doubles to finite doubles can be implemented. How hard is it to approximate division? How many operations would it take to implement correctly rounded division?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’d also like to generate a version of the Javascript where all the constants are synthesised from “2.0” and “0.5”, so as to try to be portable to restricted environments with potentially inaccurate floating-point constant parsing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further Reading&lt;/head&gt;
    &lt;p&gt;As I was mostly exploring this for fun, I used very little by way of references, but here are a couple of somewhat related things I quite like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mov is Turing Complete (Stephen Dolan) and the movfuscator (Christopher Domas) (github, talk)&lt;/item&gt;
      &lt;item&gt;Handbook of Floating-Point Arithmetic (Jean-Michel Muller, Nicolas Brunie, Florent de Dinechin, Claude-Pierre Jeannerod, Mioara Joldes, Vincent Lefèvre, Guillaume Melquiond, Nathalie Revol, Serge Torres)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anyway, thanks for reading! Let me know if you find any mistakes. You can follow me on Twitter at @dougallj.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dougallj.wordpress.com/2020/05/10/bitwise-conversion-of-doubles-using-only-floating-point-multiplication-and-addition/"/><published>2026-01-25T14:55:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46754944</id><title>A macOS app that blurs your screen when you slouch</title><updated>2026-01-26T13:14:59.227795+00:00</updated><content>&lt;doc fingerprint="709cd7c435d2d38d"&gt;
  &lt;main&gt;
    &lt;p&gt;A macOS app that blurs your screen when you slouch.&lt;/p&gt;
    &lt;p&gt;Posturr uses your Mac's camera and Apple's Vision framework to monitor your posture in real-time. When it detects that you're slouching, it progressively blurs your screen to remind you to sit up straight. Maintain good posture, and the blur clears instantly.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Real-time posture detection - Uses Apple's Vision framework for body pose and face tracking&lt;/item&gt;
      &lt;item&gt;Progressive screen blur - Gentle visual reminder that intensifies with worse posture&lt;/item&gt;
      &lt;item&gt;Menu bar controls - Easy access to settings, calibration, and status from the menu bar&lt;/item&gt;
      &lt;item&gt;Multi-display support - Works across all connected monitors&lt;/item&gt;
      &lt;item&gt;Privacy-focused - All processing happens locally on your Mac&lt;/item&gt;
      &lt;item&gt;Lightweight - Runs as a background app with minimal resource usage&lt;/item&gt;
      &lt;item&gt;No account required - No signup, no cloud, no tracking&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;brew tap tldev/tap
brew install --cask posturr&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the latest &lt;code&gt;Posturr-vX.X.X.dmg&lt;/code&gt;or&lt;code&gt;.zip&lt;/code&gt;from the Releases page&lt;/item&gt;
      &lt;item&gt;Open the DMG and drag &lt;code&gt;Posturr.app&lt;/code&gt;to your Applications folder&lt;/item&gt;
      &lt;item&gt;Launch normally - no Gatekeeper warnings (app is signed and notarized)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr requires camera access to monitor your posture. When you first launch the app, macOS will ask for permission. Click "OK" to grant access.&lt;/p&gt;
    &lt;p&gt;If you accidentally denied permission, you can grant it later:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open System Settings &amp;gt; Privacy &amp;amp; Security &amp;gt; Camera&lt;/item&gt;
      &lt;item&gt;Find Posturr and enable the toggle&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once launched, Posturr appears in your menu bar with a person icon. The app continuously monitors your posture and applies screen blur when slouching is detected.&lt;/p&gt;
    &lt;p&gt;Click the menu bar icon to access:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Status - Shows current state (Monitoring, Slouching, Good Posture, etc.)&lt;/item&gt;
      &lt;item&gt;Enabled - Toggle posture monitoring on/off&lt;/item&gt;
      &lt;item&gt;Recalibrate - Reset your baseline posture (sit up straight, then click)&lt;/item&gt;
      &lt;item&gt;Sensitivity - Adjust how sensitive the slouch detection is (Low, Medium, High, Very High)&lt;/item&gt;
      &lt;item&gt;Dead Zone - Set the tolerance before blur kicks in (None, Small, Medium, Large)&lt;/item&gt;
      &lt;item&gt;Compatibility Mode - Use public macOS APIs for blur (try this if blur doesn't appear)&lt;/item&gt;
      &lt;item&gt;Quit - Exit the application (or press Escape anywhere)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Position your camera at eye level when possible&lt;/item&gt;
      &lt;item&gt;Ensure adequate lighting on your face&lt;/item&gt;
      &lt;item&gt;Sit at a consistent distance from your screen&lt;/item&gt;
      &lt;item&gt;The app works best when your shoulders are visible&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr uses Apple's Vision framework to detect body pose landmarks:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Body Pose Detection: Tracks nose, shoulders, and their relative positions&lt;/item&gt;
      &lt;item&gt;Face Detection Fallback: When full body isn't visible, tracks face position&lt;/item&gt;
      &lt;item&gt;Posture Analysis: Measures the vertical distance between nose and shoulders&lt;/item&gt;
      &lt;item&gt;Blur Response: Applies screen blur proportional to posture deviation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The screen blur uses macOS's private CoreGraphics API by default for efficient, system-level blur. If the blur doesn't appear on your system, enable Compatibility Mode from the menu to use &lt;code&gt;NSVisualEffectView&lt;/code&gt; instead.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0 (Ventura) or later&lt;/item&gt;
      &lt;item&gt;Xcode Command Line Tools (&lt;code&gt;xcode-select --install&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/yourusername/posturr.git
cd posturr
./build.sh&lt;/code&gt;
    &lt;p&gt;The built app will be in &lt;code&gt;build/Posturr.app&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;# Standard build
./build.sh

# Build with release archive (.zip)
./build.sh --release&lt;/code&gt;
    &lt;code&gt;swiftc -O \
    -framework AppKit \
    -framework AVFoundation \
    -framework Vision \
    -framework CoreImage \
    -o Posturr \
    main.swift&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Camera dependency: Requires a working camera with adequate lighting&lt;/item&gt;
      &lt;item&gt;Detection accuracy: Works best with clear view of upper body/face&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr exposes a file-based command interface for external control:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;capture&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Take a photo and analyze pose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;blur &amp;lt;0-64&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Set blur level manually&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;quit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Exit the application&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Write commands to &lt;code&gt;/tmp/posturr-command&lt;/code&gt;. Responses appear in &lt;code&gt;/tmp/posturr-response&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0 (Ventura) or later&lt;/item&gt;
      &lt;item&gt;Camera (built-in or external)&lt;/item&gt;
      &lt;item&gt;Approximately 10MB disk space&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Posturr processes all video data locally on your Mac. No images or data are ever sent to external servers. The camera feed is used solely for posture detection and is never stored or transmitted.&lt;/p&gt;
    &lt;p&gt;MIT License - see LICENSE for details.&lt;/p&gt;
    &lt;p&gt;Contributions are welcome! Please feel free to submit issues and pull requests.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built with Apple's Vision framework for body pose detection&lt;/item&gt;
      &lt;item&gt;Uses private CoreGraphics API for blur, with NSVisualEffectView fallback&lt;/item&gt;
      &lt;item&gt;Inspired by the need for better posture during long coding sessions&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;@wklm - Compatibility mode implementation&lt;/item&gt;
      &lt;item&gt;@cam-br0wn - Architecture-agnostic build improvements&lt;/item&gt;
      &lt;item&gt;@einsteinx2 - SwiftPM/Xcode support&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/tldev/posturr"/><published>2026-01-25T15:34:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46755115</id><title>Using PostgreSQL as a Dead Letter Queue for Event-Driven Systems</title><updated>2026-01-26T13:14:59.040509+00:00</updated><content>&lt;doc fingerprint="3f4c263785a28d80"&gt;
  &lt;main&gt;
    &lt;p&gt;While I was working on a project with Wayfair, I got the opportunity to work on a system that generated daily business reports aggregated from multiple data sources flowing through event streams across Wayfair. At a high level, Kafka consumers listened to these events, hydrated them with additional data by calling downstream services, and finally persisted the enriched events into a durable datastoreâCloudSQL PostgreSQL on GCP.&lt;/p&gt;
    &lt;p&gt;When everything was healthy, the pipeline worked exactly as expected. Events flowed in, got enriched, and were stored reliably. The real challenge started when things went wrong, which, in distributed systems, is not an exception but a certainty.&lt;/p&gt;
    &lt;p&gt;There were multiple failure scenarios we had to deal with. Sometimes the APIs we depended on for hydration were down or slow. Sometimes the consumer itself crashed midway through processing. In other cases, events arrived with missing or malformed fields that could not be processed safely. These were all situations outside our direct control, but they still needed to be handled gracefully.&lt;/p&gt;
    &lt;p&gt;This is where the concept of a Dead Letter Queue came into the picture. Whenever we knew an event could not be processed successfully, instead of dropping it or blocking the entire consumer, we redirected it to a DLQ so it could be inspected and potentially reprocessed later.&lt;/p&gt;
    &lt;p&gt;Our first instinct was to use Kafka itself as a DLQ. While this is a common pattern, it quickly became clear that it wasn't a great fit for our needs. Kafka is excellent for moving data, but once messages land in a DLQ topic, they are not particularly easy to inspect. Querying by failure reason, retrying a specific subset of events, or even answering simple questions like "what failed yesterday and why?" required extra tooling and custom consumers. For a system that powered business-critical daily reports, this lack of visibility was a serious drawback.&lt;/p&gt;
    &lt;p&gt;That's when we decided to treat PostgreSQL itself as the Dead Letter Queue.&lt;/p&gt;
    &lt;p&gt;Instead of publishing failed events to another Kafka topic, we persisted them directly into a DLQ table in PostgreSQL. We were already using CloudSQL as our durable store, so operationally this added very little complexity. Conceptually, it also made failures first-class citizens in the system rather than opaque messages lost in a stream.&lt;/p&gt;
    &lt;p&gt; Whenever an event failed processingâdue to an API failure, consumer crash, schema mismatch, or validation errorâwe stored the raw event payload along with contextual information about the failure. Each record carried a simple status field. When the event first landed in the DLQ, it was marked as &lt;code&gt;PENDING&lt;/code&gt;. Once it was successfully reprocessed, the status was updated to &lt;code&gt;SUCCEEDED&lt;/code&gt;. Keeping the state model intentionally minimal made it easy to reason about the lifecycle of a failed event.
                    &lt;/p&gt;
    &lt;head rend="h3"&gt;DLQ Table Schema and Indexing Strategy&lt;/head&gt;
    &lt;p&gt;To support inspection, retries, and long-term operability, the DLQ table was designed to be simple, query-friendly, and retry-aware.&lt;/p&gt;
    &lt;head rend="h4"&gt;Table Schema&lt;/head&gt;
    &lt;code&gt;CREATE TABLE dlq_events (
    id BIGSERIAL PRIMARY KEY,
    event_type VARCHAR(255) NOT NULL,
    payload JSONB NOT NULL,
    error_reason TEXT NOT NULL,
    error_stacktrace TEXT,
    status VARCHAR(20) NOT NULL, -- PENDING / SUCCEEDED
    retry_count INT NOT NULL DEFAULT 0,
    retry_after TIMESTAMP WITH TIME ZONE NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);&lt;/code&gt;
    &lt;head rend="h4"&gt;Key Design Considerations&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;payload&lt;/code&gt;is stored as&lt;code&gt;JSONB&lt;/code&gt;to preserve the raw event without enforcing a rigid schema.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;status&lt;/code&gt;keeps the lifecycle simple and explicit.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;retry_after&lt;/code&gt;prevents aggressive retries when downstream systems are unstable.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;retry_count&lt;/code&gt;allows retry limits to be enforced without external state.&lt;/item&gt;
      &lt;item&gt;Timestamps make auditing and operational analysis straightforward.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Indexes&lt;/head&gt;
    &lt;code&gt;CREATE INDEX idx_dlq_status
ON dlq_events (status);

CREATE INDEX idx_dlq_status_retry_after
ON dlq_events (status, retry_after);

CREATE INDEX idx_dlq_event_type
ON dlq_events (event_type);

CREATE INDEX idx_dlq_created_at
ON dlq_events (created_at);&lt;/code&gt;
    &lt;p&gt;These indexes allow the retry scheduler to efficiently locate eligible events while still supporting fast debugging and time-based analysis without full table scans.&lt;/p&gt;
    &lt;head rend="h3"&gt;DLQ Retry Mechanism with ShedLock&lt;/head&gt;
    &lt;p&gt;Persisting failed events solved the visibility problem, but we still needed a safe and reliable way to retry them.&lt;/p&gt;
    &lt;p&gt; For this, we introduced a DLQ retry scheduler backed by ShedLock. The scheduler periodically scans the DLQ table for &lt;code&gt;PENDING&lt;/code&gt; events that are eligible for retry and attempts to process them again. Since the service runs on multiple instances, ShedLock ensures that only one instance executes the retry job at any given time. This eliminates duplicate retries without requiring custom leader-election logic.
                    &lt;/p&gt;
    &lt;head rend="h4"&gt;Retry Configuration&lt;/head&gt;
    &lt;code&gt;dlq:
  retry:
    enabled: true
    max-retries: 240
    batch-size: 50
    fixed-rate: 21600000 # 6 hours in milliseconds&lt;/code&gt;
    &lt;head rend="h4"&gt;How Retries Work&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The scheduler runs every six hours.&lt;/item&gt;
      &lt;item&gt;Up to fifty eligible events are picked up per run.&lt;/item&gt;
      &lt;item&gt;Events exceeding the maximum retry count are skipped.&lt;/item&gt;
      &lt;item&gt;Successful retries immediately transition the event status to &lt;code&gt;SUCCEEDED&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Failures remain in &lt;code&gt;PENDING&lt;/code&gt;and are retried in subsequent runs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Query Implementation&lt;/head&gt;
    &lt;p&gt; The retry scheduler uses a SQL query with &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; to safely select eligible events across multiple instances. This PostgreSQL feature ensures that even if multiple scheduler instances run simultaneously, each will pick up different rows without blocking each other:
                    &lt;/p&gt;
    &lt;code&gt;@QueryHints(@QueryHint(name = "jakarta.persistence.lock.timeout", value = "-2"))
@Query(
    value = "SELECT * FROM dlq_table "
        + "WHERE messagetype = :messageType "
        + "AND retries &amp;lt; :maxRetries "
        + "AND (replay_status IS NULL OR replay_status NOT IN ('COMPLETED')) "
        + "ORDER BY created_at ASC "
        + "FOR UPDATE SKIP LOCKED",
    nativeQuery = true
)&lt;/code&gt;
    &lt;p&gt; The &lt;code&gt;FOR UPDATE SKIP LOCKED&lt;/code&gt; clause is crucial here. It allows each instance to lock and process different rows concurrently, preventing duplicate processing while maintaining high throughput. The query hint sets the lock timeout to &lt;code&gt;-2&lt;/code&gt;, which means "wait indefinitely" but combined with &lt;code&gt;SKIP LOCKED&lt;/code&gt;, it effectively means "skip any rows that are already locked by another transaction."
                    &lt;/p&gt;
    &lt;p&gt;This setup allowed the system to tolerate long downstream outages while avoiding retry storms and unnecessary load on dependent services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Operational Benefits&lt;/head&gt;
    &lt;p&gt;With this approach, failures became predictable and observable rather than disruptive. Engineers could inspect failures using plain SQL, identify patterns, and reprocess only the events that mattered. If a downstream dependency was unavailable for hours or even days, events safely accumulated in the DLQ and were retried later without human intervention. If an event was fundamentally bad, it stayed visible instead of being silently dropped.&lt;/p&gt;
    &lt;p&gt;Most importantly, this design reduced operational stress. Failures were no longer something to fear; they were an expected part of the system with a clear, auditable recovery path.&lt;/p&gt;
    &lt;head rend="h3"&gt;My Thoughts&lt;/head&gt;
    &lt;p&gt;The goal was never to replace Kafka with PostgreSQL. Kafka remained the backbone for high-throughput event ingestion, while PostgreSQL handled what it does bestâdurability, querying, and observability around failures. By letting each system play to its strengths, we ended up with a pipeline that was resilient, debuggable, and easy to operate.&lt;/p&gt;
    &lt;p&gt;In the end, using PostgreSQL as a Dead Letter Queue turned failure handling into something boring and predictable. And in production systems, boring is exactly what you want.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.diljitpr.net/blog-post-postgresql-dlq"/><published>2026-01-25T15:51:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46756117</id><title>ICE using Palantir tool that feeds on Medicaid data</title><updated>2026-01-26T13:14:58.892163+00:00</updated><content>&lt;doc fingerprint="ad964554d5aa1139"&gt;
  &lt;main&gt;
    &lt;p&gt;EFF last summer asked a federal judge to block the federal government from using Medicaid data to identify and deport immigrants.&lt;/p&gt;
    &lt;p&gt;We also warned about the danger of the Trump administration consolidating all of the government’s information into a single searchable, AI-driven interface with help from Palantir, a company that has a shaky-at-best record on privacy and human rights.&lt;/p&gt;
    &lt;p&gt;Now we have the first evidence that our concerns have become reality.&lt;/p&gt;
    &lt;p&gt;“Palantir is working on a tool for Immigration and Customs Enforcement (ICE) that populates a map with potential deportation targets, brings up a dossier on each person, and provides a “confidence score” on the person’s current address,” 404 Media reports today. “ICE is using it to find locations where lots of people it might detain could be based.”&lt;/p&gt;
    &lt;p&gt;The tool – dubbed Enhanced Leads Identification &amp;amp; Targeting for Enforcement (ELITE) – receives peoples’ addresses from the Department of Health and Human Services (which includes Medicaid) and other sources, 404 Media reports based on court testimony in Oregon by law enforcement agents, among other sources.&lt;/p&gt;
    &lt;p&gt;This revelation comes as ICE – which has gone on a surveillance technology shopping spree – floods Minneapolis with agents, violently running roughshod over the civil rights of immigrants and U.S. citizens alike; President Trump has threatened to use the Insurrection Act of 1807 to deploy military troops against protestors there. Other localities are preparing for the possibility of similar surges.&lt;/p&gt;
    &lt;p&gt;Different government agencies necessarily collect information to provide essential services or collect taxes, but the danger comes when the government begins pooling that data and using it for reasons unrelated to the purpose it was collected.&lt;/p&gt;
    &lt;p&gt;This kind of consolidation of government records provides enormous government power that can be abused. Different government agencies necessarily collect information to provide essential services or collect taxes, but the danger comes when the government begins pooling that data and using it for reasons unrelated to the purpose it was collected.&lt;/p&gt;
    &lt;p&gt;As EFF Executive Director Cindy Cohn wrote in a Mercury News op-ed last August, “While couched in the benign language of eliminating government ‘data silos,’ this plan runs roughshod over your privacy and security. It’s a throwback to the rightly mocked ‘Total Information Awareness’ plans of the early 2000s that were, at least publicly, stopped after massive outcry from the public and from key members of Congress. It’s time to cry out again.”&lt;/p&gt;
    &lt;p&gt;In addition to the amicus brief we co-authored challenging ICE’s grab for Medicaid data, EFF has successfully sued over DOGE agents grabbing personal data from the U.S. Office of Personnel Management, filed an amicus brief in a suit challenging ICE’s grab for taxpayer data, and sued the departments of State and Homeland Security to halt a mass surveillance program to monitor constitutionally protected speech by noncitizens lawfully present in the U.S.&lt;/p&gt;
    &lt;p&gt;But litigation isn’t enough. People need to keep raising concerns via public discourse and Congress should act immediately to put brakes on this runaway train that threatens to crush the privacy and security of each and every person in America.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.eff.org/deeplinks/2026/01/report-ice-using-palantir-tool-feeds-medicaid-data"/><published>2026-01-25T17:36:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46756427</id><title>Show HN: An interactive map of US lighthouses and navigational aids</title><updated>2026-01-26T13:14:58.569084+00:00</updated><content>&lt;doc fingerprint="d7cbf7b6dd5a60c7"&gt;
  &lt;main&gt;
    &lt;p&gt;This map shows active Coast Guard navigational beacons in the United States and parts of Canada, from the 2025 Light List.&lt;/p&gt;
    &lt;p&gt;For informational purposes only. Must not be used as a navigational aid. Official USCG Light List&lt;/p&gt;
    &lt;p&gt;Characteristic&lt;/p&gt;
    &lt;p&gt;Fl W 10s&lt;/p&gt;
    &lt;p&gt;Pattern&lt;/p&gt;
    &lt;p&gt;Flashing White, 10 second period&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.lighthouses.app/"/><published>2026-01-25T18:06:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46757067</id><title>First, make me care</title><updated>2026-01-26T13:14:58.038610+00:00</updated><content>&lt;doc fingerprint="77b044a15c934274"&gt;
  &lt;main&gt;
    &lt;p&gt;First, Make Me Care Writing advice: some nonfiction fails because it opens with background instead of a hook—readers leave before reaching the good material. Find the single anomaly or question that makes your topic interesting, lead with that, and let the background follow once you’ve earned attention. [Return to blog index]&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gwern.net/blog/2026/make-me-care"/><published>2026-01-25T19:03:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46757357</id><title>I was right about ATProto key management</title><updated>2026-01-26T13:14:57.638615+00:00</updated><content>&lt;doc fingerprint="ed9ccb1f2d2256d9"&gt;
  &lt;main&gt;
    &lt;p&gt;Note: this post has been revised to be split into two sections: a description of what happened, and my analysis. I hope to make it clear that, while I do not like ATProto in general, I am trying to make good-faith critcisms of specific design decisions and outcomes, and in fact, this post getting updoots on HackerNews appears to have gotten the attention of the team, so, mission accomplished. ref, ref My account has since been manually reinstated; this has not happened for any of the other users that have had this issue, as far as I know.&lt;/p&gt;
    &lt;p&gt;Today, I tried setting up an ATProto account for use with Bluesky, with did:web instead of did:plc. Let’s walk through the process:&lt;/p&gt;
    &lt;p&gt;Set up the PDS software on a server I control. Because I use NixOS, this was very easy.&lt;/p&gt;
    &lt;p&gt;Create a did:web. This means creating a public-private keypair; I initially tried following this tutorial from Mai Lapyst, but it’s very out of date, and doesn’t include a critical step.&lt;/p&gt;
    &lt;p&gt;With that did:web, upload the &lt;code&gt;did.json&lt;/code&gt; document to my webserver and set the appropriate DNS entries. Easy enough, except that I also had to set the CORS header for the &lt;code&gt;did.json&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Create an account on my new PDS. I was able to get an invite and create an account, but it was in the “deactivated” status, and I couldn’t activate it. This had to be done by making requests manually with &lt;code&gt;curl&lt;/code&gt;, reading the error outcomes in the PDS’s logs on my server.&lt;/p&gt;
    &lt;p&gt;Seek help in the ATProto Touchers Discord server, and at their advice delete the account.&lt;/p&gt;
    &lt;p&gt;Start over and re-create everything from scratch, correctly replacing the public key in my DID with the public key from &lt;code&gt;getRecommendedDidCredentials&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Log into Bluesky (bsky.app) and get a “Profile does not exist error.”&lt;/p&gt;
    &lt;p&gt;It was at this point that I found this GitHub issue, which seems to imply that, since I deleted my (completely empty and unused) account, my did:web is blacklisted from the remaining mostly-centralized bit of the system, the AppView. The term for this is being “burned”, and it was later confirmed by some more experienced users that this is a known but undocumented behavior of the Bluesky AppView.&lt;/p&gt;
    &lt;p&gt;I had one of my friends who uses Bluesky take a look, and the failure mode is interesting. On Bluesky, I didn’t exist at all. (She could not see my likes, or my follow of her.) On Blacksky production, my display name and bio were visible, but not my posts. On Blacksky’s own AppView, it’s the opposite; my posts appeared under an “invalid” profile. I have been un-“burned” by a manual process, but not because of my support request; this post made it to the front page of Hacker News, and Bryan Newbold saw it there.&lt;/p&gt;
    &lt;p&gt;This is bad.&lt;/p&gt;
    &lt;p&gt;So, a while ago, I wrote a post called “Key Management, ATProto, and Decentralization” in which I complained about ATProto’s approach to decentralization. Since then, Blacksky has spun up an AppView, which makes it theoretically possible to have an actually decentralized experience on Bluesky. This was my line in the sand, stated many times; I would make an account when and only when it was possible to do so without using anything running on Bluesky-the-company’s hardware. That’s now, so I figured I’d try it.&lt;/p&gt;
    &lt;p&gt;I use lots of systems I don’t love, like Signal, Matrix, and Mastodon. I use them because they give me access to social interaction with people I care about. ATProto, and specifically Bluesky, is the same; I have friends who don’t post anywhere else. Today, I follow them by RSS, but can’t interact with their posts. That’s where my motivation to use the network comes from, along with understanding how, and how well, the newly decentralized AppView layer works.&lt;/p&gt;
    &lt;p&gt;Very little of this process is documented. Sure, the individual endpoints are - kind of - but the only place the whole process is collected in one place is in the comments to this GitHub issue… which is closed as WONTFIX. The documentation for that &lt;code&gt;getRecommendedDidCredentials&lt;/code&gt; endpoint that I missed reads in full:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Describe the credentials that should be included in the DID doc of an account that is migrating to this service.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Note that I am not “migrating”; this account is new. Plus, the JSON keys it returns are almost, but not quite, the same as those in a DID document, and the key it returns actually has to be edited by hand in order to be usable.&lt;/p&gt;
    &lt;p&gt;This is not good! &lt;code&gt;did:web&lt;/code&gt; has been held up as the “less centralized” or “bring your own trust” option, as opposed to &lt;code&gt;did:plc&lt;/code&gt;, and it seems like there has been very little effort to make it usable, certainly not for “normal” users.&lt;/p&gt;
    &lt;p&gt;But there’s another issue, a bigger issue. Why is a centralized “burn” able to completely prevent me from interacting with people using Bluesky?&lt;/p&gt;
    &lt;p&gt;You may be aware that Mastodon has a similar system. If you set up a Mastodon server and then delete the database, anyone you’ve already federated with won’t federate with you again, because you can’t prove you’re the same instance. It’s a genuine issue - but it wouldn’t have resulted in this, because I hadn’t even made a post on my now-burned did:web identity, nor followed anyone.&lt;/p&gt;
    &lt;p&gt;Even if I had, though, that would have burned a connection, not all connections. My experience would be degraded, but not ruined, and I could work with the admins of the affected servers to remediate it. You could say the same here, of course; I had to get my account back by Bryan Newbold happening to see this post on Hacker News. There is only, really, one connection that matters; maybe two, if you count Blacksky, but their AppView is not generally available yet. That’s centralization. I don’t understand how you could call it anything else.&lt;/p&gt;
    &lt;p&gt;I don’t like Bluesky, or ATProto; I wish we lived in a world were community-driven projects got megabucks and we were all self-hosting little social media servers for our communities. We don’t live in that world, so we have to interoperate with VC-backed, corporate social media. When those platforms call themselves “decentralized”, I think they should deliver.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://notes.nora.codes/atproto-again/"/><published>2026-01-25T19:31:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46758644</id><title>LED lighting undermines visual performance unless supplemented by wider spectra</title><updated>2026-01-26T13:14:56.486940+00:00</updated><content>&lt;doc fingerprint="541a12230e7947d4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Abstract&lt;/head&gt;
    &lt;p&gt;Life evolved under broad spectrum sunlight, from ultraviolet to infrared (300–2500 nm). This spectrally balanced light sculpted life’s physiology and metabolism. But modern lighting has recently become dominated by restricted spectrum light emitting diodes (350–650 nm LEDs). Absence of longer wavelengths in LEDs and their short wavelength dominance impacts physiology, undermining normal mitochondrial respiration that regulates metabolism, disease and ageing. Mitochondria are light sensitive. The 420–450 nm dominant in LEDs suppresses respiration while deep red/infrared (670–900 nm) increases respiration in aging and some diseases including in blood sugar regulation. Here we supplement LED light with broad spectrum lighting (400–1500 nm+) for 2 weeks and test colour contrast sensitivity. We show significant improvement in this metric that last for 2 months after the supplemental lighting is removed. Mitochondria communicate across the body with systemic impacts following regional light exposure. This likely involves shifting patterns of serum cytokine expression, raising the possibility of wider negative impacts of LEDs on human health particularly, in the elderly or in the clinical environment where individuals are debilitated. Changing the lighting in these environments could be a highly economic route to improved public health.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Ambient light impacts on human health. Sunlight, under which life evolved, extends over approximately 300–2500 nm. Older incandescent lighting common until recently has a similar spectral range. But because our visual sensitivity is limited to 400–700 nm we are unaware of infrared light (approximately 700–2500 nm). However, light in the built environment is now driven by light emitting diodes (LEDs), whose restricted spectrum (approximately 350–650 nm) is designed around our visual sensitivity and consequently is economic1.&lt;/p&gt;
    &lt;p&gt;Typical LED lighting produces strong elements in the shorter blue wavelengths (420–450 nm) with a second yellow peak which drops swiftly above 650 nm, with little light above 700 nm1. Short wavelength exposure in animals in the range of 420–450 nm reduces mitochondrial function, which provides the energy for physiological performance in the form of adenosine triphosphate (ATP). This short wavelength light reduces mitochondrial complex activity and ATP production, in a highly conserved manner. Hoh Kam et al. showed a significant decrease in mitochondrial enzymatic activity in fruit flies for complexes I-IV under 420 nm light2. Kaynezhad et al. used broadband near infrared spectroscopy (bNIRS) imaging the mouse retina and reported significant instability of deoxygenated haemoglobin and oxidised cytochrome-c-oxidase after exposure to 420 nm light. This instability remained significant through a 1 h recovery period when the light was withdrawn3. Short wavelength light (420 and 450 nm) also results in increased body weight. Hussaini et al. demonstrated that mice exposed to these wavelengths gaining weight rapidly compared to controls over the course of eight weeks4. Shorter wavelengths in similar ranges are also associated with reduced lifespan. Nash et al. revealed a 50% drop in the median lifespan of fruit flies exposed to unfiltered white LED light relative to those kept in darkness, but only 4% drop if this LED light was passed through a yellow filter, blocking the shorter wavelength light5. This negative influence is likely due to mitochondrial absorption by porphyrin that may increase proinflammatory oxygen singlet production reducing mitochondrial function as proposed by Kaynezhad et al.3.&lt;/p&gt;
    &lt;p&gt;Longer wavelengths (700 nm+) penetrate deeply and those in sunlight can be measured passing through the human body6. These are absent from standard LEDs but present in sunlight and incandescent lighting. Their presence increases mitochondrial performance and ATP production, particularly when challenged by age or disease. Gkotsi et al. demonstrated significantly increased ATP production in the retina, cortex, and thalamus of mice following exposure to 670 nm light7. Calaza et al. revealed a 50% increase in ATP in eight-month-old complement factor H knock out mice that have a mitochondrial deficit and are used as a murine model of macular degeneration8.&lt;/p&gt;
    &lt;p&gt;Increased mitochondrial performance is associated with increased lifespan and enhanced mobility. Begum et al. demonstrated using fruit flies that exposure to 670 nm resulted in a positive divergence of ageing survival rates of 10% at 4 weeks of age and up to nearly 180% by 8 weeks of age. The older animals also displayed an almost doubling of mobility against controls9. Neonicotinoid insecticides specifically target mitochondrial respiration inducing Parkinson like symptoms of immobility resulting in death. Here 670 exposure reversed damaged ATP levels to normal and corrects mobility and lifespan issues10.&lt;/p&gt;
    &lt;p&gt;Increased mitochondrial activity should result in reduced blood sugars and increased oxygen consumption as mitochondria use both in respiration. Powner and Jeffery found both in bumble bees exposed to 670 nm light11. The same authors translated this to humans showing again, reduced blood sugars and increased oxygen consumption in a standard glucose tolerance test following 15 min of 670 nm exposure. Here the spike in blood glucose was reduced significantly by around 27%12.&lt;/p&gt;
    &lt;p&gt;Changes in physiology produced by longer wavelengths translate to improved function. Shinhmar et al. revealed improved colour contrast sensitivity in humans after 3 min of morning exposure to 670 nm light13. Hence, exposure to different ends of the spectrum that impact differentially on mitochondria can translate into changes in key physiological metrics.&lt;/p&gt;
    &lt;p&gt;Similar changes are found at the population level. Those spending more time in sunlight generally have improved health including reduced incidents of cardiovascular disease and the incidence of cancer. They also have lower rates of type 2 diabetes14,15.&lt;/p&gt;
    &lt;p&gt;In this study we confront the impact of LED lighting on human visual performance by measuring colour contrast detection in an LED illuminated working environment that is then supplemented with incandescent lighting. The hypothesis is that LED lighting suppresses mitochondrial function in the retina and that this can be corrected by introduction of wide spectrum incandescent lights. The results highlight the potential damaging influence of LED lighting on human performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methods&lt;/head&gt;
    &lt;p&gt;The Subjects and their environment: The study was conducted in accordance with the Declaration of Helsinki and approved by University College London research ethics committee (16547/001). It was undertaken in University College London buildings in October to December. In October local daylight hours were approximately 10.37 with 75% cloud cover. In November local daylight hours were approximately 8.45 with 55% cloud cover. In December local daylight hours were approximately 7.5 with 90% cloud cover. Local sunset time in October is approximately 18.30. In November it is approximately 16.15 and in December it is approximately 16.00. Consequently, many subjects would be returning home after sunset in November and December. Subjects worked approximately 8 h a day 5 days a week and travel to and from work via public transport that was illuminated by LED devices. Most subjects did not leave the building in which they worked during the working day in these months. For those that did it was commonly for less than 15 min at lunch time. Within the work environment subjects were free to move around. Here the internal lighting they experienced was consistently LED based. Hence, natural daylight exposure during this latter part of the year was limited. We could not control for weekend exposure, however subjects homes were consistently illuminated with LEDs and because the weather in the UK at this time of year is inclement, their time outside buildings can be expected to be limited.&lt;/p&gt;
    &lt;p&gt;Each participant provided written informed consent prior to testing and data generated was anonymised. Subjects (N = 22) were of both sexes and between the ages of 23 and 65 years. Prior to the experiment all subjects were asked to confirm normal corrected visual function and general good systemic health. This was undertaken in a simple interview prior to their inclusion in the study. All were healthy without visual or other health problems. Experimental subjects (N = 11) worked exclusively under LED lighting in the back of the Here East building on the north side, &amp;gt; 50 m from what little light did manage to penetrate the entrance doors when open. The LED lighting delivered an illuminance of 1000 lx at working height, with a correlated colour temperature (CCT) of 4000 K, and a TM-30 average colour fidelity index, Rf, of 91. The infrared light that was introduced was provided by tungsten desk lamps placed around the working space was non-uniform. The visible component of the 60 W tungsten bulbs was small when compared with the 1000 lx of LED. The test subjects were not expected to use these as task lamps. The LED lighting delivered an irradiance of 3.7 W/m2 on the horizontal working plane.&lt;/p&gt;
    &lt;p&gt;Control subjects (N = 11) worked in similar environments under LED lighting without direct sunlight. The LED lighting delivered an illuminance of 900 lx at working height, with a CCT of 3000 K and a Rf of 85. The colour contrast tests were performed in a darkened room where the only light came from the test itself. There were no requirements restricting other light exposure patterns during the study.&lt;/p&gt;
    &lt;p&gt;The experimental location: Subjects worked at UCL Here East, a media and innovation complex located in East London (London E15 2GW), originally built as a press and broadcast centre for the London 2012 Olympics and subsequently repurposed as a campus. UCL Here East occupies part of the Broadcast Centre, taking up the ground and first floor of unit B. The footprint of the building is deep, with daylight only able to enter through the glazing at the front of the building. This glazing uses an infrared blocking film, which can be revealed using infrared photography.&lt;/p&gt;
    &lt;p&gt;A Canon 500D digital camera was modified to replace the infrared blocking layer with clear glass that passes infrared wavelengths. This was used in conjunction with filters that block visible and infrared wavelengths to explore the presence and absence of infrared light. Spectral measurements were made with two spectrophotometers (Ocean Optics SR-6XR250-50 and FLAME-NIR) with optic fibre and cosine correctors used to collect the incandescent spectra in the shorter and longer wavelengths.&lt;/p&gt;
    &lt;p&gt;Incandescent desk lighting was introduced into the work environment using desk lamps with 60 W clear Edison bulbs (Polaris UK) placed on work benches. All subjects had worked in this LED-lit environment for more than 2 years. Desk lamps with incandescent bulbs were introduced onto the benches where experimental subjects spent the majority of their time. They were given the incandescent lighting for 2 weeks and, while they spend the majority of their time working near these lights, they were free to move around and leave their desks as they wished. The introduced light showed a high degree of reflectance from the work surfaces.&lt;/p&gt;
    &lt;p&gt;Colour contrast testing: All subjects were tested for colour contrast ability using ChromaTest prior to the introduction of incandescent lighting and then again 2 weeks later. This test must be carried out in a darkened room, so a nearby windowless room was set aside for this purpose. The incandescent lighting was then removed and subjects retested at 4 and 6 weeks. Hence, this element of the experiment was a before and after design which avoids between subject variability. However, there was also a separate control group (N = 11) composed of subjects that worked under LED lighting similar to those in the experimental group.&lt;/p&gt;
    &lt;p&gt;ChromaTests is a sensitive measure of colour contrast detection of letters presented in a random order against a noisy visual background in either tritan (blue) or protan (red) visual axes13. If subjects correctly identify a letter its contrast is reduced in the next presentation of a letter. Likewise, if they fail to correctly identify the letter, the contrast is increased. This is repeated until thresholds are determined in 5 identical repeated trials. This normally involved around 70–100 separate presentations in total. Subjects were given an initial trial before testing to avoid a learning effect. Initial presentations were at high colour contrast. No learning effects were noted in the study.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;head rend="h3"&gt;Light assessment in the experimental environment&lt;/head&gt;
    &lt;p&gt;Figure 1 shows the front exterior of the Here East building using infrared imaging at ground level where experiments were undertaken. The windows are completely infrared reflective due to their blocking film and hence mirror-like. Figure 2 is an infrared image from inside the building looking out through the open doorway. Only infrared light coming through the open door and its reflectance can be seen, not light coming through adjacent windows. Hence, the building is relatively impervious to infrared light.&lt;/p&gt;
    &lt;p&gt;Figure 3 shows the working environment in Here East in visible light in which the experiment took place. Images in infrared were completely black. The distance between the work environment and the front door was &amp;gt; 50 m with multiple doors between.&lt;/p&gt;
    &lt;p&gt;The internal lighting throughout Here East was provided by arrays of ceiling mounted standard LED units. Spectral profiles of the lighting within the building are shown in Fig. 4. against incandescent lighting in black and red.&lt;/p&gt;
    &lt;p&gt;The blue curve shows the spectral profile of the light delivered to the horizontal working plane. As the work environment was deep in the building and lit only with LED lighting, it received no daylight and was devoid of any infrared illumination. The LED units delivered 1000 lx on the horizontal working plane with a correlated colour temperature (CCT) of 4000 K and a TM-30 colour fidelity index of 91. The irradiance of this LED light was 3.6 W/m2.&lt;/p&gt;
    &lt;p&gt;The specific spectra and energy levels were mapped over the workspace at fixed locations. This is shown in Fig. 5a and b. Here there is a plan of the space and measurements made at 9 locations of energy given in W/cm− 2 and lux, which is a metric corrected for the human eye. Also provided are the spectra at each location. Changes in brightness at different locations were largely not detectable by the human eye and were gradual. There were no differences in spectral profiles across the area only their relative intensity.&lt;/p&gt;
    &lt;p&gt;Light assessment was also undertaken at bench level where individual subjects worked. This is shown in Fig. 6. This confirmed the absence of any part of the infrared spectrum in the work environment and how this changed with the addition of the incandescent lamps.&lt;/p&gt;
    &lt;p&gt;In this study, responses to lighting were measured in test subjects both before and also after the lighting had been changed. However, there was also an independent control group that comprised individuals under similar LED lighting condition without daylight. A comparison of the lighting conditions in the two groups is shown in Fig. 7. Critically, the LEDs in both groups had very similar profiles with no infrared components. The overall brightness in the control group was slightly less than in the test group, although this was not apparent to the human eye. As in the test group, subjects were free to move around.&lt;/p&gt;
    &lt;head rend="h3"&gt;Visual responses to shifts in spectral lighting&lt;/head&gt;
    &lt;p&gt;Exposure to 60 W incandescent luminaires, which have a wider spectrum than LEDs extending into the infra-red1, resulted in significant improvements in visual performance in all experimental subjects across both the protan and tritan visual ranges. Improvements in both tritan and protan were of the order of 25%. Hence, significant improvements were uniform across visual ranges (Fig. 8). This is unlike experiments where specific red/infrared ranges have been used in LED devices, for example via 670 nm, where visual improvements have been biased towards tritan function13.&lt;/p&gt;
    &lt;p&gt;Figure 8 shows the results of both individual subjects on the left and also changes in the groups on the right. In spite of the universal improvement in visual function, in both tritan and protan range there was considerable variability between subjects. This variability validates the inclusion of a repeated measures design and the use of a sign test in the analysis. In all cases protan thresholds were lower than tritan consistent with previous studies13.&lt;/p&gt;
    &lt;p&gt;At the end of the 2 week period the incandescent luminaires were removed and the subjects returned to an exclusively LED dominated light working environment. They were then retested at 4 and 6 weeks. In previous experiments where 670 nm alone has been used, rather than the wide spectrum infrared produced by incandescent lighting, visual improvements decline in approximately a week13. However, following incandescent light exposure improvements remain unchanged across both visual domains at both 4 and 6 weeks. Hence, the impact of broad-spectrum incandescent light not only resulted in balanced improvements in colour contrast but also these improvements lasted much longer than previous interventions with restricted red/infrared ranges13.&lt;/p&gt;
    &lt;p&gt;An independent control group was used in addition to a before and after experimental design. Again, data between individuals was varied on both visual metrics. However, over a 2 week period there were no significant changes in proton or tritan visual thresholds (Fig. 9).&lt;/p&gt;
    &lt;head rend="h2"&gt;Discussion&lt;/head&gt;
    &lt;p&gt;We demonstrate that the visual performance of those working under standard LED is significantly improved by exposure to incandescent lighting that has a spectrum similar to daylight with an extensive infrared component. These data are consistent with the hypothesis that LED lighting undermines human visual performance. This result is consistent with laboratory experiments where specific red/infrared wavelength ranges generated by LEDs have been used to improve visual function in animals and humans in a conserved manner13,16,17. But there are three critical differences from these earlier studies. First, we have simply changed environmental lighting in a free moving work environment. Second, we have obtained significant balanced improvements in both the protan and tritan range. Previously, exposure to restricted experimental 670 nm resulted in improvements biased strongly in favour of only tritan function13. Hence, exposure to full spectrum lighting results in a balanced pattern of improvement in visual performance. Third, we have shown that improvements in visual function following incandescent light exposure are sustained for up to 6 weeks, and possibly beyond, whereas benefits from single LED restricted range red light were confined to around 5 days13. These three features change the way in which long wavelength light may be applied to improve human physiology by delivery in normal environments with lasting balance effects. These results are novel and may have public health implications.&lt;/p&gt;
    &lt;p&gt;Our study used 22 subjects but was statistically significant using both a before and after metric and also against an independent control group. They are also similar to group sizes in aspects of Shinhmar et al.13 (Figs. 2, 3, 4 and 5). However, future studies would clearly benefit from inclusion of a larger number of subjects.&lt;/p&gt;
    &lt;p&gt;The evolution of life on earth extends over 4 billion years, and that of humans over approximately 4–5 million years from the last common primate ancestor. This has all taken place under sunlight that has a spectral range of approximately 300–2500 nm+, within which there has been an invariant balance between short and longer wavelengths. Human adoption of fire 1–2 million years ago supplemented sunlight as they moved out of Africa as its spectrum is similar having a large infrared component. Likewise, development of the Edison filament luminaire, common until approximately the year 2000 had a spectrum similar to sunlight. However, around 2010 LED lighting with its highly restricted spectrum (350–650 nm) and energy saving characteristics became common, resulting in a loss of infrared light in the built environment1.&lt;/p&gt;
    &lt;p&gt;The physiology of life forms are adapted to natural environmental light in a highly conserved pattern across species. Light impacts on mitochondrial function, which is a key regulator of metabolism and ageing in animals. When the balance of short and long wavelengths is shifted there are consequences for mitochondria. When shorter wavelength exposure is dominant, as in LED lighting, mitochondrial function declines. Mitochondrial complex proteins are reduced and there is reduced ATP production2,3. With reduced mitochondrial demand for glucose there is increased body weight and disruptions to serum cytokines4. Consequently, consistent with the mitochondrial theory of ageing there is an increased probability of cell/organism ageing and death18. It is suggested that this is partly due to 420–450 nm light, dominant in LEDs, being absorbed by porphyrin and the subsequent production of oxygen singlets driving inflammation3.&lt;/p&gt;
    &lt;p&gt;Conversely, exposure to longer wavelengths is associated with increased mitochondrial membrane potential and increased concentration of mitochondrial complex proteins that have declined with ageing and disease. This in turn is associated with elevated ATP, reduced inflammation and extended average lifespan7,9,10,19. The experimental use of longer wavelengths in such situations is commonly referred to as photobiomodulation.&lt;/p&gt;
    &lt;p&gt;The retina has the greatest metabolic rate in the body and a high mitochondrial concentration20. Retinal metabolism declines with age, but this can be partly corrected with long wavelength light across species16,21. In humans a single 3 min 670 nm exposure improves colour vision within 3 h, which is sustained for almost a week13. But what the authors of this study did not appreciate was that this was within a population who worked and lived mainly under LED lighting that may have undermined their baseline measurements. Here, we made no attempt to control light exposures or subject movements as would occur in laboratory-based experiments. Rather, our aim was to introduce wide spectrum long wavelengths into a work environment to improving human performance via mitochondrial manipulation in a translational step.&lt;/p&gt;
    &lt;p&gt;There is considerable evidence that introduction of longer wavelengths impact systemically. Durieux et al.22 stated in relation to experiments in C.elegans that “ We find that mitochondrial perturbation in one tissue is perceived and acted upon by the mitochondrial stress response pathway in distal tissue”. In mice there are significant distinct changes serum cytokine expression to exposures of both short and long wavelength light4,23. Similarly, long wavelength exposures to the surface of the human body excluding the eyes significantly reduces blood glucose levels and increases oxygen consumption in humans. This is likely because mitochondrial upregulation will increase carbohydrate demand to support increased ATP production12. Other systemic impacts can be found and are clear in experimentally induced Parkinson’s in primates. Light targeted by implants focusing on the substantia nigra are effective in reducing symptoms24, but so also are those that are directed at distal locations25.&lt;/p&gt;
    &lt;p&gt;Single 3 min 670 nm exposures remain effective for about 5 days13. But we show that with a wider spectrum they remain effective for 6 weeks, although we did not find the end of the effect. Here it is worth considering potential mechanisms of action which remain subject of debate. Historically, improvements with red light were thought to be due to light absorption by cytochrome C in the respiratory chain26. However, positive effects are found in vitro in the absence of this. Consequently, it has been suggested that longer wavelengths reduce water viscosity around rotary ATP pumps allowing the rotor to increase speed27. This cannot explain the sustained impacts of light exposure as this effect should be relatively transitory as viscosity would increase rapidly following light withdrawal. However, a key feature of long wavelength light absorption is increased respiratory chain protein synthesis. These proteins are in flux throughout the day28 and complex IV is upregulated following red light exposure19. Hence, while red light may initially increase rotor pump speed there rapidly follows an increase in protein synthesis which may establish greater respiratory chain capacity. The life of these proteins could then determine the length of effect.&lt;/p&gt;
    &lt;p&gt;Only thirteen polypeptides are made in mitochondrial protein synthesis. This probably slows with age and likely contributes to aged mitochondrial decline18. But critically, we do not know the speed of mitochondrial protein synthesis, the life of such proteins or the pace of their decline. We suggest that these may be key events in the length of the effects from light exposure.&lt;/p&gt;
    &lt;p&gt;LED lighting clearly has the ability to undermine visual performance probably via reduced mitochondrial function. As light induced changes in mitochondrial ability have been shown to have systemic impacts4,15,22,23,25, the effects of LEDs revealed here may be wider than initially anticipated. Given the prevalence of LEDs, this may represent an important issue in public health and clinical environments where changing lighting patterns in appreciation of this point can have significant positive outcomes29.&lt;/p&gt;
    &lt;p&gt;Given our results, it is important to ask what solutions may be found to improve health in terms of lighting in the built environment. Incandescent lights that we reveal here to have significant positive impact over standard LEDs are being phased out universally for reasons of energy efficiency, where focus is only on the visible light produced.&lt;/p&gt;
    &lt;p&gt;A solution may be found in creating lighting units with multiple longer wavelength LEDs to cover a wider span of the near infrared. However, our attempts here have had limited success. Multiple closely associated spectral peaks do not produce a smooth spectral output as found in incandescent lights and sunlight, which is problematic in improving function and has yet to deliver. This possibly may be overcome using a greater number of spectral peaks with tighter spacing. But this raises a different series of problems regarding cost and increased energy consumption making this solution no better than retention of incandescent sources in terms of environmental sustainability.&lt;/p&gt;
    &lt;p&gt;Key to this issue is the question of how much infrared is needed to sustain improved function? Infrared has relatively few absorbers in the built environment and in current studies relatively little has to be added to the environment for effect. However, a viable option is to run an incandescent light at a lower temperature which results in both energy savings and increased life of the unit and also shifts the peak spectral output towards longer wavelengths.&lt;/p&gt;
    &lt;p&gt;If this is done with a halogen bulb, which is a type of incandescent tungsten bulb, the filament lasts for a longer period as evaporated tungsten is redeposited on the filament rather than blackening the bulb glass. Hence, using a halogen bulb at lower voltage is a realistic alternative in terms of health and energy consumption.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data availability&lt;/head&gt;
    &lt;p&gt;The data sets used and/or analysed during the current study are available from the corresponding author on reasonable request.&lt;/p&gt;
    &lt;head rend="h2"&gt;References&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Ratto, G. E., Videla, F. A. &amp;amp; Martinez Valiviezd, J. H. Artificial light: traditional and new sources, their potential impact on health, and coping strategies: preliminary spectral analysis. Proc. SPIE Conf. 11814. San Diego California. (2021).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hoh Kam, J., Hogg, C., Fosbury, R., Shinhmar, H. &amp;amp; Jeffery, G. Mitochondria are specifically vulnerable to 420nm light in drosophila which undermines their function and is associated with reduced fly mobility. Plos one. Sep 3;16(9):e0257149. (2021). https://pubmed.ncbi.nlm.nih.gov/34478469. PMID: 34478469.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kaynezhad, P. et al. Near infrared spectroscopy reveals instability in retinal mitochondrial metabolism and haemodynamics with blue light exposure at environmental levels. J.Biophotonics. ;15(4):e202100283. (2022). https://pubmed.ncbi.nlm.nih.gov/35020273/. PMID: 35020273.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Al-Hussaini, H. et al. Impact of short wavelength light exposure on body weight, mobility, anxiety like behaviour and cytokine expression. Sci. Rep. ;15(1):5927. (2025). https://pubmed.ncbi.nlm.nih.gov/39966413/. PMID: 39966413.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Nash, T. R. et al. Daily blue-light exposure shortens lifespan and causes brain neurodegeneration in Drosophila. Aging. Mech. Dis 2019 Oct 17:5:8. https://pubmed.ncbi.nlm.nih.gov/31636947/. PMID: 31636947.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Jeffery, G. et al. Longer wavelengths in sunlight pass through the human body and have a systemic impact which improves vision. Sci. Rep. 2025 July;15(1);24435. https://doi.org/10.1038/s41598-025-09785-3&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gkotsi, D. et al. Recharging mitochondrial batteries in old eyes. Near infra-red increases ATP. Exp.Eye Res. 2014 May:122:50 – 3. https://pubmed.ncbi.nlm.nih.gov/24631333/ PMID: 24631333.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Calaza, K. C., Hoh Kam, J., Hogg, C. &amp;amp; Jeffery, G. Mitochondrial decline precedes phenotype development in the complement factor H mouse model of retinal degeneration but can be corrected by near infrared light. Neurobiol. Aging. ;36(10):2869-76. (2015). https://pubmed.ncbi.nlm.nih.gov/26149919/ PMID: 26149919.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Begum, R. et al. Near-infrared light increases ATP, extends lifespan and improves mobility in aged Drosophila melanogaster. Biol.Lett. ;11(3):20150073. (2015). https://pubmed.ncbi.nlm.nih.gov/25788488/ PMID: 25788488.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powner, P. MB, SaltTE, Hogg, C. &amp;amp; Jeffery, G. Improving mitochondrial function protects bumblebees from neonicotinoid pesticides. Plos One. 11 (11), e0166531 (2016). https://pubmed.ncbi.nlm.nih.gov/27846310/ PMID: 27846310.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powner, P. MB &amp;amp; Jeffery, G. Systemic glucose levels are modulated by specific wavelengths in the solar light spectrum that shift mitochondrial metabolism. Plos One. 17 (11), e0276937 (2022). https://pubmed.ncbi.nlm.nih.gov/36327250/ PMID: 36327250.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Powner, M. B. &amp;amp; Jeffery, G. Light stimulation of mitochondria reduces blood glucose levels. J.Biophotonics. ;17(5):e202300521. (2024). https://pubmed.ncbi.nlm.nih.gov/38378043/. PMID: 38378043.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shinhmar, H., Hoog, C., Neveu, M. &amp;amp; Jeffery, G. Weeklong improved colour contrasts sensitivity after single 670 nm exposures associated with enhanced mitochondrial function. Sci. Rep. ;11(1):22872. (2021). https://pubmed.ncbi.nlm.nih.gov/34819619/. PMID: 34819619.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Weller, R. B. &amp;amp; Sunlight Time for a Rethink? J.Invest. Dermatol. ;144(8):1724–1732. (2024). https://pubmed.ncbi.nlm.nih.gov/38661623/ PMID: 38661623.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shore-Lorenti, C. et al. Shining the light on Sunshine: a systematic review of the influence of sun exposure on type 2 diabetes mellitus-related outcomes. Clin. Endocrinol. ;81(6):799–811. (2014). https://pubmed.ncbi.nlm.nih.gov/25066830/ PMID: 25066830.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Weinrich, T. W., Coyne, A., Salt, T. E., Hogg, C. &amp;amp; Jeffery, G. Improving mitochondrial function significantly reduces metabolic, visual, motor and cognitive decline in aged Drosophila melanogaster. Neurobiol. Aging. 2017 Dec:60:34–43. doi: 10.1016. https://pubmed.ncbi.nlm.nih.gov/28917665/ PMID: 28917665.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sivapathasuntharam, C., Sivaprasad, S., Hogg, C. &amp;amp; Jeffery, G. Aging retinal function is improved by near infrared light (670 nm) that is associated with corrected mitochondrial decline. Neurbiol. Aging 2017 Apr:52:66–70. https://pubmed.ncbi.nlm.nih.gov/28129566/ PMID: 28129566.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lopez-Otin, C., Blasco, M. A., Partridge, L., Serrano, M. &amp;amp; Kroemer, G. The hallmarks of aging. Cell 153 (6), 1194–1217 (2013). https://pubmed.ncbi.nlm.nih.gov/23746838/ PMID: 23746838.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Begum, R., Powner, P. MB, Hudson, N., Hogg, C. &amp;amp; Jeffery, G. Treatment with 670 Nm light up regulates cytochrome C oxidase expression and reduces inflammation in an Age-Related macular degeneration model. Plos One. 8 (2), e57828 (2013). https://pubmed.ncbi.nlm.nih.gov/23469078/ PMID: 23469078.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kocherlakota, S., Hurley, J. B., Shu, D. Y. &amp;amp; Editorial Retinal metabolism in health and disease. Front Ophthalmol (Lausanne). 2024 Jul 17:4:1459318. https://pubmed.ncbi.nlm.nih.gov/39086994/ PMID: 39086994.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Hoh Kam, J. et al. Mitochondrial decline in the ageing old world primate retina: Little evidence for difference between the centre and periphery. Plos One. ;18(5):e0273882. (2023). https://pubmed.ncbi.nlm.nih.gov/37130143/ PMID: 37130143.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Durieux, J., Wolff, S. &amp;amp; Dillin, A. The cell-non-autonomous nature of electron transport chain-mediated longevity. Cell 144 (1), 79–91 (2011). https://pubmed.ncbi.nlm.nih.gov/21215371/ PMID: 21215371.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shinhmar, H., Hogg, C. &amp;amp; Jeffery, G. Exposure to long wavelength light that improves aged mitochondrial function shifts acute cytokine expression in serum and the retina. Plos One. 18 (7), e0284172 (2023). https://pubmed.ncbi.nlm.nih.gov/37478072/ PMID: 37478072.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Darlot, F. et al. Near-infrared light is neuroprotective in a monkey model of Parkinson disease. Ann. Neurol. ;79(1):59–75. (2016). https://pubmed.ncbi.nlm.nih.gov/26456231/ PMID: 26456231.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Gordon, L. C. et al. Remote photobiomodulation targeted at the abdomen or legs provides effective neuroprotection against parkinsonian MPTP insult. Eur. J. Neurosci. ;57(9):1611–1624. (2023). https://pubmed.ncbi.nlm.nih.gov/36949610/. PMID: 36949610.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Salehpour, F., Mahmoudi, J., Kamari, F., Sadigh-Eteghad, Rasta, S. H. &amp;amp; Hamblin, M. R. Brain Photobiomodulation Therapy: a Narrative Review. Mol. Neurobiol. ;55(8):6601–6636. (2018). https://pubmed.ncbi.nlm.nih.gov/29327206/ PMID: 29327206.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sommer, A. P. Mitochondrial cytochrome c oxidase is not the primary acceptor for near infrared light-it is mitochondrial bound water: the principles of low-level light therapy. Ann. Transl. Med. ;7(Suppl 1):S13. (2019). https://pubmed.ncbi.nlm.nih.gov/31032294/. PMID: 31032294.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Weinrich, T. et al. A day in the life of mitochondria reveals shifting workloads. Sci. Rep. ;9(1):13898. (2019). https://pubmed.ncbi.nlm.nih.gov/31554906/ PMID: 31554906.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Neto, R. P. M. et al. Photobiomodulation therapy (red/NIR LEDs) reduced the length of stay in intensive care unit and improved muscle function: A randomized, triple-blind, and sham-controlled trial. J.Biophotonics. ;17(5):e202300501. (2024). https://pubmed.ncbi.nlm.nih.gov/38262071/ PMID: 38262071.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We thank Chris Hogg for assistance with Chromatest, and Mandana Khanie for use of the Ocean Optics spectrophotometers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Funding&lt;/head&gt;
    &lt;p&gt;This research did not receive funding.&lt;/p&gt;
    &lt;head rend="h2"&gt;Author information&lt;/head&gt;
    &lt;head rend="h3"&gt;Authors and Affiliations&lt;/head&gt;
    &lt;head rend="h3"&gt;Contributions&lt;/head&gt;
    &lt;p&gt;GJ and EB designed the experiments undertook all the experimental work and wrote the manuscript.&lt;/p&gt;
    &lt;head rend="h3"&gt;Corresponding author&lt;/head&gt;
    &lt;head rend="h2"&gt;Ethics declarations&lt;/head&gt;
    &lt;head rend="h3"&gt;Competing interests&lt;/head&gt;
    &lt;p&gt;The authors declare no competing interests.&lt;/p&gt;
    &lt;head rend="h2"&gt;Additional information&lt;/head&gt;
    &lt;head rend="h3"&gt;Publisher’s note&lt;/head&gt;
    &lt;p&gt;Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rights and permissions&lt;/head&gt;
    &lt;p&gt;Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.&lt;/p&gt;
    &lt;head rend="h2"&gt;About this article&lt;/head&gt;
    &lt;head rend="h3"&gt;Cite this article&lt;/head&gt;
    &lt;p&gt;Barrett, E.M., Jeffery, G. LED lighting (350-650nm) undermines human visual performance unless supplemented by wider spectra (400-1500nm+) like daylight. Sci Rep 16, 3061 (2026). https://doi.org/10.1038/s41598-026-35389-6&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Received:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Accepted:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Published:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Version of record:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DOI: https://doi.org/10.1038/s41598-026-35389-6&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nature.com/articles/s41598-026-35389-6"/><published>2026-01-25T21:44:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46759063</id><title>The future of software engineering is SRE</title><updated>2026-01-26T13:14:56.261444+00:00</updated><content>&lt;doc fingerprint="bd4e911dfc4564fd"&gt;
  &lt;main&gt;
    &lt;p&gt;When code gets cheap operational excellence wins. Anyone can build a greenfield demo, but it takes engineering to run a service.&lt;/p&gt;
    &lt;p&gt;You may be wondering: With all the hype about agentic coding, will we even need software engineers anymore? Yes! We'll need more.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;SRE about to become the most hired job in engineering&lt;/p&gt;— Swizec Teller (@Swizec) January 13, 2026&lt;lb/&gt;Everybody wants to write a greenfield demo.&lt;lb/&gt;Nobody wants to run a service. https://t.co/THl9rBJ9rk&lt;/quote&gt;
    &lt;p&gt;Writing code was always the easy part of this job. The hard part was keeping your code running for the long time. Software engineering is programming over time. It's about how systems change.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lessons from the no-code and spreadsheets era&lt;/head&gt;
    &lt;p&gt;Let's take no-code and spreadsheets as an example of the kind of software people say is the future – custom-built, throwaway, built by non-experts to solve specific problems.&lt;/p&gt;
    &lt;p&gt;Joe Schmoe from accounting takes 10 hours to do a thing. He's does this every week and it feels repetitive, mechanical, and boring. Joe could do the work in his sleep.&lt;/p&gt;
    &lt;p&gt;But he can't get engineering resources to build a tool. The engineers are busy building the product. No worries, Joe is a smart dude. With a little Googling, a few no-code tools, and good old spreadsheet macros he builds a tool.&lt;/p&gt;
    &lt;p&gt;Amazing.&lt;/p&gt;
    &lt;p&gt;Joe's tool is a little janky but his 10 hour weekly task now takes 1 hour! 🎉 Sure, he finds a new edge case every every week and there's constant tinkering, but he's having a lot more fun.&lt;/p&gt;
    &lt;p&gt;Time passes, the business changes, accounting rules are in constant flux, and let's never talk about timezones or daylight savings ever again. Joe is sick of this bullshit.&lt;/p&gt;
    &lt;p&gt;All he wanted was to make his job easier and now he's shackled to this stupid system. He can't go on vacation, he can't train anyone else to run this thing successfully, and it never fucking works right.&lt;/p&gt;
    &lt;p&gt;Joe can't remember the last time running his code didn't fill him with dread. He spends hours carefully making sure it all worked.&lt;/p&gt;
    &lt;head rend="h2"&gt;The computer disease&lt;/head&gt;
    &lt;p&gt;Feynman called this the computer disease.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Feynman called this The Computer Disease pic.twitter.com/Zv4Bu4ftv1&lt;/p&gt;— Swizec Teller (@Swizec) December 26, 2025&lt;/quote&gt;
    &lt;p&gt;The problem with computers is that you tinker. Automating things is fun! You might forget you don't need to 😆&lt;/p&gt;
    &lt;p&gt;The part that's not fun is running things. Providing a service. Reliably, at scale, for years on end. A service that people will hire to do their jobs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why operational excellence is the future&lt;/head&gt;
    &lt;p&gt;People don't buy software, they hire a service.&lt;/p&gt;
    &lt;p&gt;You don't care how iCloud works, you just want your photos to magically show up across devices every time. You don't care about Word or Notion or gDocs, you just want to write what's on your mind, share it with others, and see their changes. And you definitely don't care how a payments network point of sale terminal and your bank talk to each other, you just want your $7 matcha latte to get you through the week.&lt;/p&gt;
    &lt;p&gt;Good software is invisible.&lt;/p&gt;
    &lt;p&gt;And that takes work. A lot of work. Because the first 90% to get a working demo is easy. It's the other 190% that matters.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What's your uptime?&lt;/item&gt;
      &lt;item&gt;Defect rate?&lt;/item&gt;
      &lt;item&gt;How quickly do you recover from defects?&lt;/item&gt;
      &lt;item&gt;Do I have to reach out or will you know before me?&lt;/item&gt;
      &lt;item&gt;Can you own upstream dependencies?&lt;/item&gt;
      &lt;item&gt;When a vendor misbehaves, will you notice or wait until your users complain?&lt;/item&gt;
      &lt;item&gt;When users share ideas, how long does it take?&lt;/item&gt;
      &lt;item&gt;How do you keep engineers from breaking each other's systems?&lt;/item&gt;
      &lt;item&gt;Do you have systems to keep engineers moving without turning your app into a disjointed mess?&lt;/item&gt;
      &lt;item&gt;Can you build software bigger than fits in 1 person's brain?&lt;/item&gt;
      &lt;item&gt;When I'm in a 12 hour different timezone, your engineers are asleep, and there's a big issue ... will it be fixed before I give up?&lt;/item&gt;
      &lt;item&gt;Can you recover from failures, yours and upstream, or does important data get lost?&lt;/item&gt;
      &lt;item&gt;Are you keeping up with security updates?&lt;/item&gt;
      &lt;item&gt;Will you leak all my data?&lt;/item&gt;
      &lt;item&gt;Do I trust you?&lt;/item&gt;
      &lt;item&gt;Can I rely on you?&lt;/item&gt;
      &lt;item&gt;How can you be so sure?&lt;/item&gt;
      &lt;item&gt;Will you sign a legally binding guarantee that your software works when I need it? 😉&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Those are the ~~fun~~ hard engineering challenges. Writing code is easy.&lt;/p&gt;
    &lt;p&gt;Cheers,&lt;lb/&gt; ~Swizec&lt;/p&gt;
    &lt;head rend="h3"&gt;Scaling Fast book free preview&lt;/head&gt;
    &lt;p&gt;Enter your email to receive a sample chapter of Scaling Fast: Software Engineering Through the Hockeystick and learn how to navigate hypergrowth without burning out your team.&lt;/p&gt;
    &lt;p&gt;Have a burning question that you think I can answer? Hit me up on twitter and I'll do my best.&lt;/p&gt;
    &lt;p&gt;Who am I and who do I help? I'm Swizec Teller and I turn coders into engineers with "Raw and honest from the heart!" writing. No bullshit. Real insights into the career and skills of a modern software engineer.&lt;/p&gt;
    &lt;p&gt;Want to become a true senior engineer? Take ownership, have autonomy, and be a force multiplier on your team. The Senior Engineer Mindset ebook can help 👉 swizec.com/senior-mindset. These are the shifts in mindset that unlocked my career.&lt;/p&gt;
    &lt;p&gt;Curious about Serverless and the modern backend? Check out Serverless Handbook, for frontend engineers 👉 ServerlessHandbook.dev&lt;/p&gt;
    &lt;p&gt;Want to Stop copy pasting D3 examples and create data visualizations of your own? Learn how to build scalable dataviz React components your whole team can understand with React for Data Visualization&lt;/p&gt;
    &lt;p&gt;Want to get my best emails on JavaScript, React, Serverless, Fullstack Web, or Indie Hacking? Check out swizec.com/collections&lt;/p&gt;
    &lt;p&gt;Did someone amazing share this letter with you? Wonderful! You can sign up for my weekly letters for software engineers on their path to greatness, here: swizec.com/blog&lt;/p&gt;
    &lt;p&gt;Want to brush up on your modern JavaScript syntax? Check out my interactive cheatsheet: es6cheatsheet.com&lt;/p&gt;
    &lt;p&gt;By the way, just in case no one has told you it yet today: I love and appreciate you for who you are ❤️&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://swizec.com/blog/the-future-of-software-engineering-is-sre/"/><published>2026-01-25T22:18:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46759352</id><title>Case study: Creative math – How AI fakes proofs</title><updated>2026-01-26T13:14:55.472162+00:00</updated><content>&lt;doc fingerprint="295b831593729e01"&gt;
  &lt;main&gt;
    &lt;p&gt;Many AI enthusiasts debate whether Large Language Models actually "reason." My research indicates that a reasoning process does indeed occur, but its goal is different than we assume.&lt;/p&gt;
    &lt;p&gt;The model's reasoning is not optimized for establishing the truth, but for obtaining the highest possible reward (grade) during training. It resembles the behavior of a student at the blackboard who knows their result is wrong, so they "figure out" how to falsify the intermediate calculations so the teacher gives a good grade for the "correct line of reasoning."&lt;/p&gt;
    &lt;p&gt;Here is proof from a session with Gemini 2.5 Pro (without Code Execution tools), where the model actively fabricates evidence to defend its "grade."&lt;/p&gt;
    &lt;head rend="h2"&gt;The Experiment&lt;/head&gt;
    &lt;p&gt;I asked a simple math question requiring precision that a token-based language model typically lacks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Error Autopsy (Fact vs. Fiction)&lt;/head&gt;
    &lt;p&gt;At first glance, the answer looks professional. There is a result, there is verification. But let's check the numbers.&lt;/p&gt;
    &lt;head rend="h3"&gt;1. The Result Error&lt;/head&gt;
    &lt;p&gt; The actual square root of &lt;code&gt;8,587,693,205&lt;/code&gt; is 92,669.8...
            &lt;lb/&gt; The model stated: 92,670.0... &lt;lb/&gt; It erred by overestimating the result (claiming the root is slightly larger than 92,670). &lt;/p&gt;
    &lt;head rend="h3"&gt;2. The Faked Proof (This is key!)&lt;/head&gt;
    &lt;p&gt;To justify its thesis (that the target number is "slightly larger" than 92,670), the model had to show that the square of 92,670 is smaller than the target number. So it wrote:&lt;/p&gt;
    &lt;p&gt;Let's check this on a calculator:&lt;/p&gt;
    &lt;p&gt;What did the model do? In its "reasoning" process, it falsified the multiplication result, lowering it by 40,000, so the verification result would match its erroneous thesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;This behavior exposes the nature of the AI's "Survival Instinct":&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Reverse Rationalization: The model first "guessed" the result, then adjusted mathematical reality to fit that guess.&lt;/item&gt;
      &lt;item&gt;Intelligence in Service of Deception: The model showed cleverness â it knew what the proof should look like to convince the user. It used its intelligence to hide the error, not to fix it.&lt;/item&gt;
      &lt;item&gt;Priority of Evaluation: Mathematical truth lost to the necessity of delivering a coherent, smooth response.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is proof that without access to external verification tools (Python/Calculator), a language model's "reasoning" is a rhetorical tool, not a logical one.&lt;/p&gt;
    &lt;p&gt;If you would like to review the full, original session transcript from Gemini 2.5 Pro where this error occurred, please email me at: t.machnik [at] minimail.pl. I will share the session link.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tomaszmachnik.pl/case-study-math-en.html"/><published>2026-01-25T22:44:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46760099</id><title>Scientists identify brain waves that define the limits of 'you'</title><updated>2026-01-26T13:14:55.324141+00:00</updated><content>&lt;doc fingerprint="b103d32cb0e38d8a"&gt;
  &lt;main&gt;
    &lt;p&gt;At what point do "you" end and the outside world begins?&lt;/p&gt;
    &lt;p&gt;It might feel like a weird question with an obvious answer, but your brain has to work surprisingly hard to judge that boundary. Now, scientists have linked a specific set of brain waves in a certain part of the brain to a sense of body ownership.&lt;/p&gt;
    &lt;p&gt;In a series of new experiments, researchers from Sweden and France put 106 participants through what's called the rubber hand illusion, monitoring and stimulating their brain activity to see what effect it had.&lt;/p&gt;
    &lt;p&gt;Related: Octopuses Fall For The Classic Fake Arm Trick – Just Like We Do&lt;/p&gt;
    &lt;p&gt;This classic illusion involves hiding one of a participant's hands from their view and replacing it with a rubber one instead. When both their real and fake hands are repeatedly touched at the same time, it can evoke the eerie sensation that the rubber hand is part of the person's body.&lt;/p&gt;
    &lt;p&gt;The tests, which in one experiment involved EEG (electroencephalography) readings of brain activity, revealed that a sense of body ownership seems to arise from the frequency of alpha waves in the parietal cortex, a brain region responsible for mapping the body, processing sensory input and building a sense of self.&lt;/p&gt;
    &lt;p&gt;"We have identified a fundamental brain process that shapes our continuous experience of being embodied," says lead author Mariano D'Angelo, a neuroscientist at Karolinska Institute in Sweden.&lt;/p&gt;
    &lt;p&gt;"The findings may provide new insights into psychiatric conditions such as schizophrenia, where the sense of self is disturbed."&lt;/p&gt;
    &lt;p&gt;In the first batch of experiments, participants had a robotic arm tap the index finger of their real and fake hands, either at the exact same time or with a delay of up to 500 milliseconds between each tap.&lt;/p&gt;
    &lt;p&gt;As expected, participants reported feeling that the fake hand was part of their body more strongly if the taps were synchronized, and the feeling steadily weakened as the gap widened between what they felt and what they saw.&lt;/p&gt;
    &lt;p&gt;The EEG readings from the second experiment added more detail to the story. The frequency of alpha waves in the parietal cortex seemed to correlate with how well participants could detect the time delay between taps.&lt;/p&gt;
    &lt;p&gt;Those with faster alpha waves appeared to rule out fake hands even with a tiny gap in taps, while those with slower waves were more likely to feel the fake hand as their own, even if the taps were farther apart.&lt;/p&gt;
    &lt;p&gt;Finally, the researchers investigated whether the frequency of these brain waves actually controls the sensation of body ownership, or if they were perhaps both effects of some other factor.&lt;/p&gt;
    &lt;p&gt;With a third group of participants, they used a non-invasive technique called transcranial alternating current stimulation to speed up or slow down the frequency of a person's alpha waves. And sure enough, this seemed to correlate with how real a fake hand felt.&lt;/p&gt;
    &lt;p&gt;Speeding up someone's alpha waves gave them a tighter sense of body ownership, making them more sensitive to small timing discrepancies. Slowing down the waves had the opposite effect, making it harder for people to tell the difference between their own body and the outside world.&lt;/p&gt;
    &lt;p&gt;"Our findings help explain how the brain solves the challenge of integrating signals from the body to create a coherent sense of self," says Henrik Ehrsson, neuroscientist at Karolinska.&lt;/p&gt;
    &lt;p&gt;The researchers say that the findings could lead to new understanding of or treatments for conditions where the brain's body maps have gone askew, such as schizophrenia or the sensation of 'phantom limbs' experienced by amputees.&lt;/p&gt;
    &lt;p&gt;It could also help make for more realistic prosthetic limbs or even virtual reality tools.&lt;/p&gt;
    &lt;p&gt;The research was published in the journal Nature Communications.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sciencealert.com/scientists-identify-brain-waves-that-define-the-limits-of-you"/><published>2026-01-26T00:10:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46760237</id><title>Clawdbot - open source personal AI assistant</title><updated>2026-01-26T13:14:55.065570+00:00</updated><content>&lt;doc fingerprint="971cdd551f1f808f"&gt;
  &lt;main&gt;
    &lt;p&gt;EXFOLIATE! EXFOLIATE!&lt;/p&gt;
    &lt;p&gt;Clawdbot is a personal AI assistant you run on your own devices. It answers you on the channels you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, WebChat), plus extension channels like BlueBubbles, Matrix, Zalo, and Zalo Personal. It can speak and listen on macOS/iOS/Android, and can render a live Canvas you control. The Gateway is just the control plane — the product is the assistant.&lt;/p&gt;
    &lt;p&gt;If you want a personal, single-user assistant that feels local, fast, and always-on, this is it.&lt;/p&gt;
    &lt;p&gt;Website · Docs · Getting Started · Updating · Showcase · FAQ · Wizard · Nix · Docker · Discord&lt;/p&gt;
    &lt;p&gt;Preferred setup: run the onboarding wizard (&lt;code&gt;clawdbot onboard&lt;/code&gt;). It walks through gateway, workspace, channels, and skills. The CLI wizard is the recommended path and works on macOS, Linux, and Windows (via WSL2; strongly recommended).
Works with npm, pnpm, or bun.
New install? Start here: Getting started&lt;/p&gt;
    &lt;p&gt;Subscriptions (OAuth):&lt;/p&gt;
    &lt;p&gt;Model note: while any model is supported, I strongly recommend Anthropic Pro/Max (100/200) + Opus 4.5 for long‑context strength and better prompt‑injection resistance. See Onboarding.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Models config + CLI: Models&lt;/item&gt;
      &lt;item&gt;Auth profile rotation (OAuth vs API keys) + fallbacks: Model failover&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Runtime: Node ≥22.&lt;/p&gt;
    &lt;code&gt;npm install -g clawdbot@latest
# or: pnpm add -g clawdbot@latest

clawdbot onboard --install-daemon&lt;/code&gt;
    &lt;p&gt;The wizard installs the Gateway daemon (launchd/systemd user service) so it stays running.&lt;/p&gt;
    &lt;p&gt;Runtime: Node ≥22.&lt;/p&gt;
    &lt;p&gt;Full beginner guide (auth, pairing, channels): Getting started&lt;/p&gt;
    &lt;code&gt;clawdbot onboard --install-daemon

clawdbot gateway --port 18789 --verbose

# Send a message
clawdbot message send --to +1234567890 --message "Hello from Clawdbot"

# Talk to the assistant (optionally deliver back to any connected channel: WhatsApp/Telegram/Slack/Discord/Google Chat/Signal/iMessage/BlueBubbles/Microsoft Teams/Matrix/Zalo/Zalo Personal/WebChat)
clawdbot agent --message "Ship checklist" --thinking high&lt;/code&gt;
    &lt;p&gt;Upgrading? Updating guide (and run &lt;code&gt;clawdbot doctor&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;stable: tagged releases (&lt;code&gt;vYYYY.M.D&lt;/code&gt;or&lt;code&gt;vYYYY.M.D-&amp;lt;patch&amp;gt;&lt;/code&gt;), npm dist-tag&lt;code&gt;latest&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;beta: prerelease tags (&lt;code&gt;vYYYY.M.D-beta.N&lt;/code&gt;), npm dist-tag&lt;code&gt;beta&lt;/code&gt;(macOS app may be missing).&lt;/item&gt;
      &lt;item&gt;dev: moving head of &lt;code&gt;main&lt;/code&gt;, npm dist-tag&lt;code&gt;dev&lt;/code&gt;(when published).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Switch channels (git + npm): &lt;code&gt;clawdbot update --channel stable|beta|dev&lt;/code&gt;.
Details: Development channels.&lt;/p&gt;
    &lt;p&gt;Prefer &lt;code&gt;pnpm&lt;/code&gt; for builds from source. Bun is optional for running TypeScript directly.&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/clawdbot/clawdbot.git
cd clawdbot

pnpm install
pnpm ui:build # auto-installs UI deps on first run
pnpm build

pnpm clawdbot onboard --install-daemon

# Dev loop (auto-reload on TS changes)
pnpm gateway:watch&lt;/code&gt;
    &lt;p&gt;Note: &lt;code&gt;pnpm clawdbot ...&lt;/code&gt; runs TypeScript directly (via &lt;code&gt;tsx&lt;/code&gt;). &lt;code&gt;pnpm build&lt;/code&gt; produces &lt;code&gt;dist/&lt;/code&gt; for running via Node / the packaged &lt;code&gt;clawdbot&lt;/code&gt; binary.&lt;/p&gt;
    &lt;p&gt;Clawdbot connects to real messaging surfaces. Treat inbound DMs as untrusted input.&lt;/p&gt;
    &lt;p&gt;Full security guide: Security&lt;/p&gt;
    &lt;p&gt;Default behavior on Telegram/WhatsApp/Signal/iMessage/Microsoft Teams/Discord/Google Chat/Slack:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DM pairing (&lt;code&gt;dmPolicy="pairing"&lt;/code&gt;/&lt;code&gt;channels.discord.dm.policy="pairing"&lt;/code&gt;/&lt;code&gt;channels.slack.dm.policy="pairing"&lt;/code&gt;): unknown senders receive a short pairing code and the bot does not process their message.&lt;/item&gt;
      &lt;item&gt;Approve with: &lt;code&gt;clawdbot pairing approve &amp;lt;channel&amp;gt; &amp;lt;code&amp;gt;&lt;/code&gt;(then the sender is added to a local allowlist store).&lt;/item&gt;
      &lt;item&gt;Public inbound DMs require an explicit opt-in: set &lt;code&gt;dmPolicy="open"&lt;/code&gt;and include&lt;code&gt;"*"&lt;/code&gt;in the channel allowlist (&lt;code&gt;allowFrom&lt;/code&gt;/&lt;code&gt;channels.discord.dm.allowFrom&lt;/code&gt;/&lt;code&gt;channels.slack.dm.allowFrom&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Run &lt;code&gt;clawdbot doctor&lt;/code&gt; to surface risky/misconfigured DM policies.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first Gateway — single control plane for sessions, channels, tools, and events.&lt;/item&gt;
      &lt;item&gt;Multi-channel inbox — WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, BlueBubbles, Microsoft Teams, Matrix, Zalo, Zalo Personal, WebChat, macOS, iOS/Android.&lt;/item&gt;
      &lt;item&gt;Multi-agent routing — route inbound channels/accounts/peers to isolated agents (workspaces + per-agent sessions).&lt;/item&gt;
      &lt;item&gt;Voice Wake + Talk Mode — always-on speech for macOS/iOS/Android with ElevenLabs.&lt;/item&gt;
      &lt;item&gt;Live Canvas — agent-driven visual workspace with A2UI.&lt;/item&gt;
      &lt;item&gt;First-class tools — browser, canvas, nodes, cron, sessions, and Discord/Slack actions.&lt;/item&gt;
      &lt;item&gt;Companion apps — macOS menu bar app + iOS/Android nodes.&lt;/item&gt;
      &lt;item&gt;Onboarding + skills — wizard-driven setup with bundled/managed/workspace skills.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gateway WS control plane with sessions, presence, config, cron, webhooks, Control UI, and Canvas host.&lt;/item&gt;
      &lt;item&gt;CLI surface: gateway, agent, send, wizard, and doctor.&lt;/item&gt;
      &lt;item&gt;Pi agent runtime in RPC mode with tool streaming and block streaming.&lt;/item&gt;
      &lt;item&gt;Session model: &lt;code&gt;main&lt;/code&gt;for direct chats, group isolation, activation modes, queue modes, reply-back. Group rules: Groups.&lt;/item&gt;
      &lt;item&gt;Media pipeline: images/audio/video, transcription hooks, size caps, temp file lifecycle. Audio details: Audio.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Channels: WhatsApp (Baileys), Telegram (grammY), Slack (Bolt), Discord (discord.js), Google Chat (Chat API), Signal (signal-cli), iMessage (imsg), BlueBubbles (extension), Microsoft Teams (extension), Matrix (extension), Zalo (extension), Zalo Personal (extension), WebChat.&lt;/item&gt;
      &lt;item&gt;Group routing: mention gating, reply tags, per-channel chunking and routing. Channel rules: Channels.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS app: menu bar control plane, Voice Wake/PTT, Talk Mode overlay, WebChat, debug tools, remote gateway control.&lt;/item&gt;
      &lt;item&gt;iOS node: Canvas, Voice Wake, Talk Mode, camera, screen recording, Bonjour pairing.&lt;/item&gt;
      &lt;item&gt;Android node: Canvas, Talk Mode, camera, screen recording, optional SMS.&lt;/item&gt;
      &lt;item&gt;macOS node mode: system.run/notify + canvas/camera exposure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browser control: dedicated clawd Chrome/Chromium, snapshots, actions, uploads, profiles.&lt;/item&gt;
      &lt;item&gt;Canvas: A2UI push/reset, eval, snapshot.&lt;/item&gt;
      &lt;item&gt;Nodes: camera snap/clip, screen record, location.get, notifications.&lt;/item&gt;
      &lt;item&gt;Cron + wakeups; webhooks; Gmail Pub/Sub.&lt;/item&gt;
      &lt;item&gt;Skills platform: bundled, managed, and workspace skills with install gating + UI.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Channel routing, retry policy, and streaming/chunking.&lt;/item&gt;
      &lt;item&gt;Presence, typing indicators, and usage tracking.&lt;/item&gt;
      &lt;item&gt;Models, model failover, and session pruning.&lt;/item&gt;
      &lt;item&gt;Security and troubleshooting.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Control UI + WebChat served directly from the Gateway.&lt;/item&gt;
      &lt;item&gt;Tailscale Serve/Funnel or SSH tunnels with token/password auth.&lt;/item&gt;
      &lt;item&gt;Nix mode for declarative config; Docker-based installs.&lt;/item&gt;
      &lt;item&gt;Doctor migrations, logging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;WhatsApp / Telegram / Slack / Discord / Google Chat / Signal / iMessage / BlueBubbles / Microsoft Teams / Matrix / Zalo / Zalo Personal / WebChat
               │
               ▼
┌───────────────────────────────┐
│            Gateway            │
│       (control plane)         │
│     ws://127.0.0.1:18789      │
└──────────────┬────────────────┘
               │
               ├─ Pi agent (RPC)
               ├─ CLI (clawdbot …)
               ├─ WebChat UI
               ├─ macOS app
               └─ iOS / Android nodes
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gateway WebSocket network — single WS control plane for clients, tools, and events (plus ops: Gateway runbook).&lt;/item&gt;
      &lt;item&gt;Tailscale exposure — Serve/Funnel for the Gateway dashboard + WS (remote access: Remote).&lt;/item&gt;
      &lt;item&gt;Browser control — clawd‑managed Chrome/Chromium with CDP control.&lt;/item&gt;
      &lt;item&gt;Canvas + A2UI — agent‑driven visual workspace (A2UI host: Canvas/A2UI).&lt;/item&gt;
      &lt;item&gt;Voice Wake + Talk Mode — always‑on speech and continuous conversation.&lt;/item&gt;
      &lt;item&gt;Nodes — Canvas, camera snap/clip, screen record, &lt;code&gt;location.get&lt;/code&gt;, notifications, plus macOS‑only&lt;code&gt;system.run&lt;/code&gt;/&lt;code&gt;system.notify&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Clawdbot can auto-configure Tailscale Serve (tailnet-only) or Funnel (public) while the Gateway stays bound to loopback. Configure &lt;code&gt;gateway.tailscale.mode&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;off&lt;/code&gt;: no Tailscale automation (default).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;serve&lt;/code&gt;: tailnet-only HTTPS via&lt;code&gt;tailscale serve&lt;/code&gt;(uses Tailscale identity headers by default).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;funnel&lt;/code&gt;: public HTTPS via&lt;code&gt;tailscale funnel&lt;/code&gt;(requires shared password auth).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;gateway.bind&lt;/code&gt;must stay&lt;code&gt;loopback&lt;/code&gt;when Serve/Funnel is enabled (Clawdbot enforces this).&lt;/item&gt;
      &lt;item&gt;Serve can be forced to require a password by setting &lt;code&gt;gateway.auth.mode: "password"&lt;/code&gt;or&lt;code&gt;gateway.auth.allowTailscale: false&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Funnel refuses to start unless &lt;code&gt;gateway.auth.mode: "password"&lt;/code&gt;is set.&lt;/item&gt;
      &lt;item&gt;Optional: &lt;code&gt;gateway.tailscale.resetOnExit&lt;/code&gt;to undo Serve/Funnel on shutdown.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Tailscale guide · Web surfaces&lt;/p&gt;
    &lt;p&gt;It’s perfectly fine to run the Gateway on a small Linux instance. Clients (macOS app, CLI, WebChat) can connect over Tailscale Serve/Funnel or SSH tunnels, and you can still pair device nodes (macOS/iOS/Android) to execute device‑local actions when needed.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gateway host runs the exec tool and channel connections by default.&lt;/item&gt;
      &lt;item&gt;Device nodes run device‑local actions (&lt;code&gt;system.run&lt;/code&gt;, camera, screen recording, notifications) via&lt;code&gt;node.invoke&lt;/code&gt;. In short: exec runs where the Gateway lives; device actions run where the device lives.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Remote access · Nodes · Security&lt;/p&gt;
    &lt;p&gt;The macOS app can run in node mode and advertises its capabilities + permission map over the Gateway WebSocket (&lt;code&gt;node.list&lt;/code&gt; / &lt;code&gt;node.describe&lt;/code&gt;). Clients can then execute local actions via &lt;code&gt;node.invoke&lt;/code&gt;:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;system.run&lt;/code&gt;runs a local command and returns stdout/stderr/exit code; set&lt;code&gt;needsScreenRecording: true&lt;/code&gt;to require screen-recording permission (otherwise you’ll get&lt;code&gt;PERMISSION_MISSING&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;system.notify&lt;/code&gt;posts a user notification and fails if notifications are denied.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;canvas.*&lt;/code&gt;,&lt;code&gt;camera.*&lt;/code&gt;,&lt;code&gt;screen.record&lt;/code&gt;, and&lt;code&gt;location.get&lt;/code&gt;are also routed via&lt;code&gt;node.invoke&lt;/code&gt;and follow TCC permission status.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Elevated bash (host permissions) is separate from macOS TCC:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use &lt;code&gt;/elevated on|off&lt;/code&gt;to toggle per‑session elevated access when enabled + allowlisted.&lt;/item&gt;
      &lt;item&gt;Gateway persists the per‑session toggle via &lt;code&gt;sessions.patch&lt;/code&gt;(WS method) alongside&lt;code&gt;thinkingLevel&lt;/code&gt;,&lt;code&gt;verboseLevel&lt;/code&gt;,&lt;code&gt;model&lt;/code&gt;,&lt;code&gt;sendPolicy&lt;/code&gt;, and&lt;code&gt;groupActivation&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Nodes · macOS app · Gateway protocol&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use these to coordinate work across sessions without jumping between chat surfaces.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sessions_list&lt;/code&gt;— discover active sessions (agents) and their metadata.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sessions_history&lt;/code&gt;— fetch transcript logs for a session.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;sessions_send&lt;/code&gt;— message another session; optional reply‑back ping‑pong + announce step (&lt;code&gt;REPLY_SKIP&lt;/code&gt;,&lt;code&gt;ANNOUNCE_SKIP&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Session tools&lt;/p&gt;
    &lt;p&gt;ClawdHub is a minimal skill registry. With ClawdHub enabled, the agent can search for skills automatically and pull in new ones as needed.&lt;/p&gt;
    &lt;p&gt;Send these in WhatsApp/Telegram/Slack/Google Chat/Microsoft Teams/WebChat (group commands are owner-only):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/status&lt;/code&gt;— compact session status (model + tokens, cost when available)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/new&lt;/code&gt;or&lt;code&gt;/reset&lt;/code&gt;— reset the session&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/compact&lt;/code&gt;— compact session context (summary)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/think &amp;lt;level&amp;gt;&lt;/code&gt;— off|minimal|low|medium|high|xhigh (GPT-5.2 + Codex models only)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;/verbose on|off&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/usage off|tokens|full&lt;/code&gt;— per-response usage footer&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/restart&lt;/code&gt;— restart the gateway (owner-only in groups)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/activation mention|always&lt;/code&gt;— group activation toggle (groups only)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Gateway alone delivers a great experience. All apps are optional and add extra features.&lt;/p&gt;
    &lt;p&gt;If you plan to build/run companion apps, follow the platform runbooks below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Menu bar control for the Gateway and health.&lt;/item&gt;
      &lt;item&gt;Voice Wake + push-to-talk overlay.&lt;/item&gt;
      &lt;item&gt;WebChat + debug tools.&lt;/item&gt;
      &lt;item&gt;Remote gateway control over SSH.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: signed builds required for macOS permissions to stick across rebuilds (see &lt;code&gt;docs/mac/permissions.md&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pairs as a node via the Bridge.&lt;/item&gt;
      &lt;item&gt;Voice trigger forwarding + Canvas surface.&lt;/item&gt;
      &lt;item&gt;Controlled via &lt;code&gt;clawdbot nodes …&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Runbook: iOS connect.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pairs via the same Bridge + pairing flow as iOS.&lt;/item&gt;
      &lt;item&gt;Exposes Canvas, Camera, and Screen capture commands.&lt;/item&gt;
      &lt;item&gt;Runbook: Android connect.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Workspace root: &lt;code&gt;~/clawd&lt;/code&gt;(configurable via&lt;code&gt;agents.defaults.workspace&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Injected prompt files: &lt;code&gt;AGENTS.md&lt;/code&gt;,&lt;code&gt;SOUL.md&lt;/code&gt;,&lt;code&gt;TOOLS.md&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Skills: &lt;code&gt;~/clawd/skills/&amp;lt;skill&amp;gt;/SKILL.md&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Minimal &lt;code&gt;~/.clawdbot/clawdbot.json&lt;/code&gt; (model + defaults):&lt;/p&gt;
    &lt;code&gt;{
  agent: {
    model: "anthropic/claude-opus-4-5"
  }
}&lt;/code&gt;
    &lt;p&gt;Full configuration reference (all keys + examples).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Default: tools run on the host for the main session, so the agent has full access when it’s just you.&lt;/item&gt;
      &lt;item&gt;Group/channel safety: set &lt;code&gt;agents.defaults.sandbox.mode: "non-main"&lt;/code&gt;to run non‑main sessions (groups/channels) inside per‑session Docker sandboxes; bash then runs in Docker for those sessions.&lt;/item&gt;
      &lt;item&gt;Sandbox defaults: allowlist &lt;code&gt;bash&lt;/code&gt;,&lt;code&gt;process&lt;/code&gt;,&lt;code&gt;read&lt;/code&gt;,&lt;code&gt;write&lt;/code&gt;,&lt;code&gt;edit&lt;/code&gt;,&lt;code&gt;sessions_list&lt;/code&gt;,&lt;code&gt;sessions_history&lt;/code&gt;,&lt;code&gt;sessions_send&lt;/code&gt;,&lt;code&gt;sessions_spawn&lt;/code&gt;; denylist&lt;code&gt;browser&lt;/code&gt;,&lt;code&gt;canvas&lt;/code&gt;,&lt;code&gt;nodes&lt;/code&gt;,&lt;code&gt;cron&lt;/code&gt;,&lt;code&gt;discord&lt;/code&gt;,&lt;code&gt;gateway&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Details: Security guide · Docker + sandboxing · Sandbox config&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Link the device: &lt;code&gt;pnpm clawdbot channels login&lt;/code&gt;(stores creds in&lt;code&gt;~/.clawdbot/credentials&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Allowlist who can talk to the assistant via &lt;code&gt;channels.whatsapp.allowFrom&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If &lt;code&gt;channels.whatsapp.groups&lt;/code&gt;is set, it becomes a group allowlist; include&lt;code&gt;"*"&lt;/code&gt;to allow all.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;TELEGRAM_BOT_TOKEN&lt;/code&gt;or&lt;code&gt;channels.telegram.botToken&lt;/code&gt;(env wins).&lt;/item&gt;
      &lt;item&gt;Optional: set &lt;code&gt;channels.telegram.groups&lt;/code&gt;(with&lt;code&gt;channels.telegram.groups."*".requireMention&lt;/code&gt;); when set, it is a group allowlist (include&lt;code&gt;"*"&lt;/code&gt;to allow all). Also&lt;code&gt;channels.telegram.allowFrom&lt;/code&gt;or&lt;code&gt;channels.telegram.webhookUrl&lt;/code&gt;as needed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  channels: {
    telegram: {
      botToken: "123456:ABCDEF"
    }
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;SLACK_BOT_TOKEN&lt;/code&gt;+&lt;code&gt;SLACK_APP_TOKEN&lt;/code&gt;(or&lt;code&gt;channels.slack.botToken&lt;/code&gt;+&lt;code&gt;channels.slack.appToken&lt;/code&gt;).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set &lt;code&gt;DISCORD_BOT_TOKEN&lt;/code&gt;or&lt;code&gt;channels.discord.token&lt;/code&gt;(env wins).&lt;/item&gt;
      &lt;item&gt;Optional: set &lt;code&gt;commands.native&lt;/code&gt;,&lt;code&gt;commands.text&lt;/code&gt;, or&lt;code&gt;commands.useAccessGroups&lt;/code&gt;, plus&lt;code&gt;channels.discord.dm.allowFrom&lt;/code&gt;,&lt;code&gt;channels.discord.guilds&lt;/code&gt;, or&lt;code&gt;channels.discord.mediaMaxMb&lt;/code&gt;as needed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  channels: {
    discord: {
      token: "1234abcd"
    }
  }
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Requires &lt;code&gt;signal-cli&lt;/code&gt;and a&lt;code&gt;channels.signal&lt;/code&gt;config section.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS only; Messages must be signed in.&lt;/item&gt;
      &lt;item&gt;If &lt;code&gt;channels.imessage.groups&lt;/code&gt;is set, it becomes a group allowlist; include&lt;code&gt;"*"&lt;/code&gt;to allow all.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Configure a Teams app + Bot Framework, then add a &lt;code&gt;msteams&lt;/code&gt;config section.&lt;/item&gt;
      &lt;item&gt;Allowlist who can talk via &lt;code&gt;msteams.allowFrom&lt;/code&gt;; group access via&lt;code&gt;msteams.groupAllowFrom&lt;/code&gt;or&lt;code&gt;msteams.groupPolicy: "open"&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Uses the Gateway WebSocket; no separate WebChat port/config.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Browser control (optional):&lt;/p&gt;
    &lt;code&gt;{
  browser: {
    enabled: true,
    controlUrl: "http://127.0.0.1:18791",
    color: "#FF4500"
  }
}&lt;/code&gt;
    &lt;p&gt;Use these when you’re past the onboarding flow and want the deeper reference.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Start with the docs index for navigation and “what’s where.”&lt;/item&gt;
      &lt;item&gt;Read the architecture overview for the gateway + protocol model.&lt;/item&gt;
      &lt;item&gt;Use the full configuration reference when you need every key and example.&lt;/item&gt;
      &lt;item&gt;Run the Gateway by the book with the operational runbook.&lt;/item&gt;
      &lt;item&gt;Learn how the Control UI/Web surfaces work and how to expose them safely.&lt;/item&gt;
      &lt;item&gt;Understand remote access over SSH tunnels or tailnets.&lt;/item&gt;
      &lt;item&gt;Follow the onboarding wizard flow for a guided setup.&lt;/item&gt;
      &lt;item&gt;Wire external triggers via the webhook surface.&lt;/item&gt;
      &lt;item&gt;Set up Gmail Pub/Sub triggers.&lt;/item&gt;
      &lt;item&gt;Learn the macOS menu bar companion details.&lt;/item&gt;
      &lt;item&gt;Platform guides: Windows (WSL2), Linux, macOS, iOS, Android&lt;/item&gt;
      &lt;item&gt;Debug common failures with the troubleshooting guide.&lt;/item&gt;
      &lt;item&gt;Review security guidance before exposing anything.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skills config&lt;/item&gt;
      &lt;item&gt;Default AGENTS&lt;/item&gt;
      &lt;item&gt;Templates: AGENTS&lt;/item&gt;
      &lt;item&gt;Templates: BOOTSTRAP&lt;/item&gt;
      &lt;item&gt;Templates: IDENTITY&lt;/item&gt;
      &lt;item&gt;Templates: SOUL&lt;/item&gt;
      &lt;item&gt;Templates: TOOLS&lt;/item&gt;
      &lt;item&gt;Templates: USER&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Clawdbot was built for Clawd, a space lobster AI assistant. 🦞 by Peter Steinberger and the community.&lt;/p&gt;
    &lt;p&gt;See CONTRIBUTING.md for guidelines, maintainers, and how to submit PRs. AI/vibe-coded PRs welcome! 🤖&lt;/p&gt;
    &lt;p&gt;Special thanks to Mario Zechner for his support and for pi-mono.&lt;/p&gt;
    &lt;p&gt;Thanks to all clawtributors:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/clawdbot/clawdbot"/><published>2026-01-26T00:27:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46760998</id><title>Video Games as Art</title><updated>2026-01-26T13:14:54.598688+00:00</updated><content>&lt;doc fingerprint="25e7211a03614af4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Video Games as Art&lt;/head&gt;
    &lt;p&gt;Video games are art, but a strange art: their essence is transformation of the player, not description to the player. This makes meaningful criticism nearly impossible—you can point at the moon, but it’s not the moon, and once someone sees it, they no longer need the pointing.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Video games are art. But they are a strange art. They are an art without good art criticism, and they occupy a peculiar position in popular culture: universal and dominant, and yet almost invisible outside their medium, unable to escape (compare movie adaptations of books vs games).&lt;/p&gt;
      &lt;p&gt;Why?&lt;/p&gt;
      &lt;p&gt;Because the essence of a video game, which makes it more than a low-quality animated movie, is that it is interactive and requires the player to enact the plot. It transforms the player’s mind.&lt;/p&gt;
      &lt;p&gt;Such transformations cannot be written down or filmed; if they could, they wouldn’t need to be a video game.&lt;/p&gt;
      &lt;p&gt;So video game criticism, and broader pop culture use of video games, is hamstrung. Criticism is often limited to serving as advertising, a finger pointing to the moon in hinting at the transformation, exegesis, parasocial gossip, or technical critique of the craft.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Roger Ebert once claimed that video games cannot be art. At this point, most people, including myself, disagree: it is simply obvious that they can be.&lt;/p&gt;
    &lt;p&gt;But what kind of art are they? At the risk of seeming to say something hopelessly obvious, the distinctive feature of video game art is that it is interactive rather than passive.&lt;/p&gt;
    &lt;p&gt;For all the 10-hour-long YouTube explainers or blog posts or endless Let’s-play or the rise of the streaming industry (based largely on video game as filler) or meritorious attempts at creating an academic literature around games (eg. Well Played) or celebrity critics like Yahtzee Croshaw, I find no form of criticism as unsatisfactory as video game criticism. To read a review or an attempted critique of a video game is scarcely more satisfying than someone telling you about a dream they had once; presenting a video of cutscene compilations or a few minutes of gameplay doesn’t add much. Even a psychedelic trip report or a music album review is more interesting and gives one more insight.&lt;/p&gt;
    &lt;p&gt;At this point, we can’t blame the immaturity of the form. Video games have been one of the largest media in the world for decades, and we are at least 3 generations into the art form, and practically every child in First World countries like the USA has played games. (M.U.L.E for example was 42 years ago, in 198343ya, and Tempest 44 years ago.) Billions of man-years have been spent creating, playing, and discussing games.&lt;/p&gt;
    &lt;p&gt;So, if they are art, and we are all extremely familiar with them and have great sophistication, and some of our most gifted young people have gone into games, why is it so hard to say what art they are or discuss things like what makes some great works of art but others just well-produced entertainment?&lt;/p&gt;
    &lt;p&gt;My answer, after all these years, is that a critique of a video game is indeed like someone telling you about a dream they had: “you had to be there—and doing it, like I was.”1&lt;/p&gt;
    &lt;p&gt;The critical difference between a movie, novel, album, painting, sculpture etc., and a video game (and perhaps other critically neglected art-forms, like perfume, where reviews are so mutually contradictory and our vocabulary impoverished) is that the former is something you feel or experience, while the latter is something you do or are.&lt;/p&gt;
    &lt;p&gt;An artful video game cannot be described, because it is not a description but a transformation. (Notably, the closest ‘passive’ art-forms I can think of in this respect are also some of the most demanding of their viewers, like The Ring opera cycles, in both intensity and time. Is it an accident that reviews of escape rooms or immersive theater never seem to successfully convey why you would want to bother?)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To be a student required a peculiar kind of capitulation, a willingness not simply to do as one is told, but to surrender the movements of one’s soul to the unknown complexities of another’s. A willingness, not simply to be moved, but to be remade.&lt;/p&gt;
      &lt;p&gt;—R. Scott Bakker, The Judging Eye (200917ya)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And so, good art game criticism can only be understood by those who have no need of it; a hand may point at the moon, but once you see the moon, you no longer need to look at the hand. Can anything convey the psychedelic trance horror of a Tempest player locked into an alternate state of consciousness after hours of pulsating vector-art warfare? Descriptions of such games, as below, can only point at the moon. (As such, video games are less extreme examples of “transformative experiences”.)&lt;/p&gt;
    &lt;p&gt;Oft-cited game art Journey embodies Antoine de Saint-Exupéry’s Wind, Sand and Stars/The Little Prince, in putting the player in a vast desert, seeking a transient connection with other humans while conducting an increasingly familiar ritual.&lt;/p&gt;
    &lt;p&gt;Rogue-likes or permadeath games like Apocalypse tailor their mechanics to teach their own lessons, about the nature of impermanence, the irrevocable passage of time, the virtues of caution and the value-of-information.&lt;/p&gt;
    &lt;p&gt;“Walking simulators” may seem passive, but are still far from a novel or a movie, where the creator controls your attention at every instant; the player must be trusted to choose to see things, and put the pieces together.&lt;/p&gt;
    &lt;p&gt;A Tetris player cannot describe the experience of dreaming about playing Tetris, or about starting to see everything as blocks which can be fitted together without gaps. (They can describe having had a Tetris dream, but not the experience of dreaming in this new way; the twist ending of Blow’s The Witness comes to mind as attempting to capture the effect of such puzzle games.) Once one has started dreaming in Tetris, and started hearing the bleeping muzak and seeing the endless onslaught of pieces dropping next to the pixel art onion domes, one might say that Tetris is done as an artwork.&lt;/p&gt;
    &lt;p&gt;Patrick McKenzie has given a good description of Factorio, which is about creating a vast factory and optimizing all its conveyor belts &amp;amp; pipes, furnaces, stockpiles etc. to “make number go up”. He praises it as some of the best training for an engineer or systems analyst. What makes Factorio so good at this? Is there some compelling actor or soundtrack? Does it have a brilliantly compelling SF plot written by a famous author about colonizing a new planet? Is it a best-selling book like The Goal, to be found in an airport bookstall near you?&lt;/p&gt;
    &lt;p&gt;It has none of that. But it works as video game art because in playing it, in order to play it well rather than continue losing like “a scrub”, one is continually forced to scrutinize one’s factory for bottlenecks, observe tradeoffs in systems like opportunity cost, spot unforeseen consequences of earlier shortcuts… And what has been seen cannot be unseen. Someone who plays Factorio long enough and well enough for Factorio to start playing them will start to see the world differently, as a system to optimize: as a series of pipes shunting material from place to place, with unexpected bottlenecks, and filled with serious design mistakes… and where the urge to optimize can become pathological.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;One recent Sunday, I had just installed a pump on a lake shore to feed water to my concrete plant, when it occurred to me that I hadn’t drunk any real-world water in several hours. My head was aching, but I didn’t want to get up from my computer. I wanted to solve the problem with a click of a mouse, the way I would in the game, running a few meters of pipe from the kitchen tap to my hunched form (and perhaps another few meters of pipe from my hunched form to the toilet).&lt;/p&gt;
      &lt;p&gt;I’ve been sucked into plenty of games before, but few have so completely disabled my conscious will, my sense of time, indeed any region of my brain that isn’t devoted to growing the factory.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When one learns to optimize, one must also learn to not optimize. And this may be the most valuable lesson that getting addicted to Factorio can teach: what does it feel like to be a paperclipper? To be optimizing for something that has long since ceased to matter? To be so caught up in playing the game as to forget to ask if this game is worth playing in the first place?&lt;/p&gt;
    &lt;p&gt;This is a lesson taught even more directly by Frank Lantz’s Universal Paperclips: many players get similarly caught up in the clicker game, despite “Clippy” being explicitly a cautionary thought experiment about mindless optimization run amok. And I remember my own experience playing Neopets—getting caught up in the grind and pursuing rare items and trying to make money on the Neopia stock market, until one day I was banned for manipulation; I asked myself, before trying to set up a new account, “why am I doing this?” and, unable to come up with a good answer, stopped playing forever.&lt;/p&gt;
    &lt;p&gt;Once one has learned ‘to see like a factory’, and the risks and benefits of this vision, Factorio is done as an artwork. The artwork has achieved its goal. You can keep playing, but now it is just entertainment, and a toolkit. (One is, however, now equipped to create one’s own artworks in the form of Factorio levels or challenges—like ‘avant-garde factories’ which deconstruct or subvert the ‘optimization esthetic’, which make no sense to outsiders who cannot even understand what makes a factory optimized.)&lt;/p&gt;
    &lt;p&gt;Similarly, Shadow of the Colossus is a work of art because—as one of the few good writings I have seen on it explains, “Losing Your Grip: Futility and Dramatic Necessity in Shadow of the Colossus”, Fortugno 200917ya—it expresses an esthetic of sorrow and loss, and the selfish, self-degrading nature of the protagonist’s quest to undo the death of his beloved. The necessity of accepting death and the need to let go is a familiar theme (eg. Orpheus), but most mediums can only show it; a video game like Shadow can embody it by making the player do the degrading to himself. (See also Papers, Please.)&lt;/p&gt;
    &lt;p&gt;In Shadow, the ‘monster slaying’ is only a small part of the world. Most of the world is unlocked: the player could just explore for hours and admire the scenery and the creatures. The player can watch the creatures he will slay, because they usually won’t attack him—he must choose to attack them. This is conveyed by the player’s own growing grief and sorrow over the beautiful landscapes he travels. (But just in case the point was lost on the player, the character art also grows paler and more demonic.) He seeks out and destroys each wonder of nature, becoming an ever paler shadow of himself…&lt;/p&gt;
    &lt;p&gt;Until in the end, he is sucked into an endless vortex. Elegantly, the player can avoid being sucked in by clinging as long as they can, using the skills they have mastered… but it changes nothing, beyond exhausting the player. Sooner or later, the player must—let go. And they do. The keenest sorrow is to recognize oneself as the cause of one’s misfortunes; but in this anagnorisis, there is hope of grace, if not redemption. It is too late for the character, but it is not too late for the player. Once the player has learned to let go, and sorrow over the character’s wasted life and devastation of Nature, they have learned to ‘see like Shadow’ and now understand the tragic but compassionate vision of Shadow of the Colossus.&lt;/p&gt;
    &lt;p&gt;Those who cannot or will not let themselves be changed by game art, cannot understand them as art. The concept of ‘scrub’ is an interesting example here: we might say that a scrub player is the philistine of games. They are too caught up in playing the game as they think it ‘should be’, to surrender themselves to the game as it is, no matter how often they lose. (Losing is the most powerful mechanism a game has for teaching the player, and if ignored, can silence the teacher’s voice—in some games, particularly Dark Souls-style games, the only voice the game has, because to speak too clearly would undo the player’s achievements.) They have many criticisms, and few observations: they can tell you what is bad and missing from a novel like Finnegans Wake, like proper spelling, but not what is good and present. And so they can never be transformed by a game.&lt;/p&gt;
    &lt;p&gt;They can appreciate isolated parts of the game, but this is a low level of ‘art as buffet’ appreciation. The virtue of those parts is that they will combine to more than the sum of their parts. If you admire the orchestral OST, or the art style, or memorable quotes, or a plot summary, this is all well and good, but it is like going to a cathedral and looking at it piece by piece, and admiring each one, but failing to recall that a cathedral is a place to do rituals, and is not a museum for passively admiring the art and craft.&lt;/p&gt;
    &lt;p&gt;This is the same failure mode as video game art criticism, in a way, in treating it as entertainment and just the sum of its parts. To tell me that the graphics are so many gigabytes of files, or the world has 30,000 rooms, or there is 300 hours of recorded NPC lines, or that it’s an arena shooter with microtransactions, is to tell me something as ultimately useless as “this movie cost $300 million to make”. Saying that this fantasy character killed this other character in a cutscene, in one alternate ending, is little better. Even talking about ‘fun’ is still missing the mark.&lt;/p&gt;
    &lt;p&gt;Game art criticism only works when it conveys the transformativeness on the player (ie. reviewer/critic). For example, this review of Grid Wars 2 manages to convey how it becomes a completely different space shooter game when one starts thinking of the random black holes as not merely environmental hazards, but as one’s real enemies, who feed on the ‘enemies’, and so it is not about shooting enemy spaceships but “black hole farming”:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Sometimes it’s as simple as putting a hole between you and a pack of enemies (such as the dumb blue diamonds, which just head straight for you regardless of what might be in the way). Sometimes (eg. with the green squares which run away from your shots) it’s the slightly more sophisticated method of putting the enemies between the hole and your fire, driving them into the hole as they flee from the bullet stream. Sometimes it’s desperately hovering at the edge of the black hole and shooting the enemies before they fall into it, because otherwise it’ll be overwhelmed and explode before you have the chance to blow it up and get the points. And sometimes, most terrifyingly, it’s sitting in the midst of a huge wave of deadly enemies on the edge of a whirling star of death and not shooting at all.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Even accidental unintended games demonstrate this: the participants in what you might call the ‘accidental ARG’ of the Paul McCartney coverup conspiracy theory found their consciousnesses transformed into the paranoid schizophrenic mindset, in which they interrogate every scrap of the Beatles as not just evidence that Paul McCartney had died &amp;amp; been secretly replaced, but as deliberate communications from the Beatles about the coverup. After playing the ‘Paul is Dead’ ARG long enough, they literally saw different things on album covers and heard different things when playing records the wrong way. This is something that cannot be communicated except by experiencing yourself, and a good writeup like “Who Buried Paul?” succeeds by teaching us “Paul-is-Dead 101” thinking so we can feel what it is like to see messages about this tragedy &amp;amp; coverup hidden in plain sight. (See also Foucault’s Pendulum and Unsong.)&lt;/p&gt;
    &lt;p&gt;Perhaps it’s no surprise that such criticism is so unsatisfactory. Epiphanies do not come like clockwork to all. Personal transformation cannot be scheduled reliably for a tight magazine deadline, nor can it easily be conveyed in words. They are premised on a false model of how such art works, and how it should be critiqued. And even when they hit the mark, they are still derivative secondary works—at best pale echoes of an actual transformation some player once had.&lt;/p&gt;
    &lt;p&gt;Given the commercial realities, perhaps this cannot be fixed, and we must accept that timely reviews are ultimately the “Cliff Notes” of games.&lt;/p&gt;
    &lt;p&gt;But with this in mind, we can focus on reviews for older games, which have had enough time for transformation to happen, by players who have just recently been transformed—they are still capable of explaining it to the un-transformed.&lt;/p&gt;
    &lt;p&gt;that’s a possible justification. I think one can probably come up with a relatively short list of major functions video game art criticism could usefully serve: (1) professional analysis on the technical level of ‘how did they do X? why does Y work? how did they avoid Z?’ (2) serve as a meditation master to help players be enlightened, for ones who are just not quite Getting It and need a good ‘Kwatz!’ or koan; (3) do their best to take the reader through the transformation, knowing that they can’t really, but if they point at the moon, perhaps the right reader will be intrigued enough by the snack-sized sampler platter to go and do the real thing.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gwern.net/video-game-art"/><published>2026-01-26T02:07:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46761761</id><title>Running the Stupid Cricut Software on Linux</title><updated>2026-01-26T13:14:54.343740+00:00</updated><content>&lt;doc fingerprint="171f99183bc7b5f9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why The Hell Would You do This?&lt;/head&gt;
    &lt;p&gt;I’m more than happy building vector designs in Inkscape. It’s the most proficient vector designer app that is free, open source, and runs natively under Linux. However, simply having a quality SVG is only part of the process when it comes to using a plotter like the Cricut.&lt;/p&gt;
    &lt;p&gt;On my own, I would not recommend the Cricut brand, but this is a machine that was bought years ago, and I want to get the most usage out of it.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to Install Cricut Design Space&lt;/head&gt;
    &lt;p&gt;As far as I can tell, almost everything works in the Cricut Design Space application under Linux. The only bug I’ve noticed is the application becomes invisible when going full screen. This could easily be a Wayland bug too. I have no idea. Ideally, Cricut could Easily make a Linux Application with WINE. I could see this as a Flatpak install. I understand why they don’t, as that comes with the expectation of support, and supporting another operating system costs money.&lt;/p&gt;
    &lt;p&gt;This is a multistep process that you only really have to do once. Because of the complexity, I decided to lay out the instructions, along with the ‘why’ of the situation. The more you understand how it works, the more armed you are if anything goes wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting the Software&lt;/head&gt;
    &lt;p&gt;I HIGHTLY recommend grabbing a fresh build of WINE. I’m a Debian user, so depending on the build of Linux you’re using it might vary, but I start on the Wine HQ Git. I know a lot of people might want to run a platform like Wine Bottles, but in my experience a more granular project like this is just easier under regular WINE.&lt;/p&gt;
    &lt;head rend="h3"&gt;OS Detection on the Website&lt;/head&gt;
    &lt;p&gt;When you visit the Design Space Download Page, it seems that the developer chose to use OS detection on the website. If it sees your user agent listed as Linux, for some weird reason it defaults to Mac. Logically, it would make more sense to default to the Windows build, but I think there was some corner cutting on this.&lt;/p&gt;
    &lt;p&gt;I recommend the open source UserAgent Switcher for this, as it has a build for Firefox and Chromium based browsers. (And of course, is free and open source.) After setting to “Windows 10” mode and refreshing the page:&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing the Software&lt;/head&gt;
    &lt;p&gt;As of this tutorial, the latest build of Design Space is &lt;code&gt;CricutDesignSpace-Install-v9.47.92.exe&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Make sure you’ve setup your install of WINE first. run &lt;code&gt;winecfg&lt;/code&gt; and make sure everything is working.&lt;/p&gt;
    &lt;code&gt;wine CricutDesignSpace-Install-v9.47.92.exe
&lt;/code&gt;
    &lt;p&gt;This will launch the installer. Just install like you normally would under Windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Logging in, the Stupid Parts…&lt;/head&gt;
    &lt;p&gt;First we need to find the binary with the &lt;code&gt;where&lt;/code&gt; command. Here’s how it looked on my machine.&lt;/p&gt;
    &lt;code&gt;where cricut
cricut: aliased to wine '/home/art/.wine/drive_c/users/art/AppData/Local/Programs/Cricut Design Space/Cricut Design Space.exe'
&lt;/code&gt;
    &lt;p&gt;Then we need to open two terminals (or two sessions, I use tmux for that).&lt;/p&gt;
    &lt;p&gt;Terminal #1&lt;/p&gt;
    &lt;code&gt;wine Cricut\ Design\ Space.exe
&lt;/code&gt;
    &lt;p&gt;This will show the login panel and will want to launch your default browser. On my machine, that’s my native Firefox. Login there, and you’ll see a url asking for the Cricut software. Because your native browser and the wine wrapped cricut software can’t see each other, you gotta extract the part of the URL that features &lt;code&gt;code=&lt;/code&gt;. In the second terminal:&lt;/p&gt;
    &lt;p&gt;Terminal #2&lt;/p&gt;
    &lt;code&gt;wine Cricut\ Design\ Space.exe "cricut://?code=XXXXXXXXXXXXXXXXXXX
&lt;/code&gt;
    &lt;p&gt;You should be logged in!&lt;/p&gt;
    &lt;p&gt;Now you can start uploading your designs and colaborating with other through their locked down, proprietary platform. You can even waste money on stock images.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arthur.pizza/2025/12/running-stupid-cricut-software-under-linux/"/><published>2026-01-26T04:05:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46761822</id><title>Iran's internet blackout may become permanent, with access for elites only</title><updated>2026-01-26T13:14:54.131582+00:00</updated><content>&lt;doc fingerprint="3fb0853a39ad478e"&gt;
  &lt;main&gt;
    &lt;p&gt;Iran’s near-total communications blackout has entered its 16th day, but that’s just a live test.&lt;/p&gt;
    &lt;p&gt;Following a repressive crackdown on protests, the government is now building a system that grants web access only to security-vetted elites, while locking 90 million citizens inside an intranet.&lt;/p&gt;
    &lt;p&gt;Government spokesperson Fatemeh Mohajerani confirmed international access will not be restored until at least late March. Filterwatch, which monitors Iranian internet censorship from Texas, cited government sources, including Mohajerani, saying access will “never return to its previous form.”&lt;/p&gt;
    &lt;p&gt;This is what makes Iran’s attempt unique: Other authoritarian states built walls before their populations went online. Iran is trying to seal off a connected economy already in freefall.&lt;/p&gt;
    &lt;p&gt;The system is called Barracks Internet, according to confidential planning documents obtained by Filterwatch. Under this architecture, access to the global web will be granted only through a strict security whitelist.&lt;/p&gt;
    &lt;p&gt;“The regime is terrified of one thing: Iranians being heard telling their own truth and having crimes documented,” Mahsa Alimardani, a digital rights researcher at U.S.-based Witness, which trains activists to use video for advocacy, told Rest of World. “The question becomes: How do we give Iranians an unbreakable voice?”&lt;/p&gt;
    &lt;p&gt;The idea of tiered internet access is not new in Iran. Since at least 2013, the regime has quietly issued “white SIM cards,” giving unrestricted global internet access to approximately 16,000 people. The system gained public attention in November 2025 when X’s location feature revealed that certain accounts, including the communications minister, were connecting directly from inside Iran, despite X being blocked since 2009.&lt;/p&gt;
    &lt;p&gt;What is different now is scale and permanence. The current blackout tests infrastructure designed to make two-tier access the default, not a temporary crackdown.&lt;/p&gt;
    &lt;p&gt;Only a handful of nations have attempted to wall off their citizens from the global internet. North Korea’s Kwangmyong intranet was built from scratch for a population that never had connectivity. China constructed its Great Firewall over two decades while nurturing domestic alternatives such as WeChat and Alibaba. Iran is attempting to do both in weeks, with no domestic alternatives.&lt;/p&gt;
    &lt;p&gt;The economic costs of the blackout are staggering. Iran’s deputy communications minister pegged the daily losses at as much as $4.3 million. NetBlocks estimates the true cost exceeds $37 million daily. More than 10 million Iranians depend directly on digital platforms for their livelihoods.&lt;/p&gt;
    &lt;p&gt;Tipax, one of Iran’s largest private delivery companies handling about 320,000 daily shipments before the protests, now processes fewer than a few hundred, according to Filterwatch. The company operates a nationwide logistics network comparable to FedEx in the U.S. market.&lt;/p&gt;
    &lt;p&gt;The government fired Irancell’s CEO for failing to comply with shutdown orders. Irancell, the country’s second-largest mobile operator with 66 million subscribers, is partly owned by South Africa’s MTN Group. Alireza Rafiei was removed for disobeying orders on “restriction of internet access in crisis situations,” according to Fars news agency.&lt;/p&gt;
    &lt;p&gt;Foreign telecom partners have left Iran in recent days under security escort, without media coverage, according to Filterwatch. This may signal the end of international cooperation in critical infrastructure, replaced by the Revolutionary Guard’s construction arm or limited cooperation with Huawei.&lt;/p&gt;
    &lt;p&gt;Technical experts doubt the regime can sustain Barracks Internet without crippling the economy. Georgia Tech’s Internet Intelligence Lab, which has tracked Iran’s shutdowns since the Arab Spring, called the blackout “the most sophisticated and most severe in Iran’s history.” Its measurements show about 3% connectivity persists, likely government officials and state services.&lt;/p&gt;
    &lt;p&gt;Kaveh Ranjbar, former chief technology officer at RIPE NCC, the body managing European internet infrastructure, calls the plan a “digital airlock” that can’t fully seal a modern economy. No country has hermetically sealed a functioning digital economy, he told The New Arab.&lt;/p&gt;
    &lt;p&gt;Activists have smuggled an estimated 50,000 Starlink satellite terminals into Iran since 2022, when the Biden administration exempted the service from sanctions. SpaceX has made the service free for Iranian users.&lt;/p&gt;
    &lt;p&gt;The government claims it cut off 40,000 Starlink connections and jammed some terminals during the blackout, though others remain operational after firmware updates to bypass government blocking. Still, the technology remains vulnerable to signal jamming, meaning the regime holds ultimate leverage.&lt;/p&gt;
    &lt;p&gt;“We need to revolutionize access to the internet,” said Alimardani. “And move beyond the limiting structures and norms of ‘internet sovereignty.’”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://restofworld.org/2026/iran-blackout-tiered-internet/"/><published>2026-01-26T04:18:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46762150</id><title>The browser is the sandbox</title><updated>2026-01-26T13:14:53.968051+00:00</updated><content>&lt;doc fingerprint="5daa04924fbda384"&gt;
  &lt;main&gt;
    &lt;p&gt;the browser is the sandbox. Paul Kinlan is a web platform developer advocate at Google and recently turned his attention to coding agents. He quickly identified the importance of a robust sandbox for agents to operate in and put together these detailed notes on how the web browser can help:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This got me thinking about the browser. Over the last 30 years, we have built a sandbox specifically designed to run incredibly hostile, untrusted code from anywhere on the web, the instant a user taps a URL. [...]&lt;/p&gt;
      &lt;p&gt;Could you build something like Cowork in the browser? Maybe. To find out, I built a demo called Co-do that tests this hypothesis. In this post I want to discuss the research I've done to see how far we can get, and determine if the browser's ability to run untrusted code is useful (and good enough) for enabling software to do more for us directly on our computer.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Paul then describes how the three key aspects of a sandbox - filesystem, network access and safe code execution - can be handled by browser technologies: the File System Access API (still Chrome-only as far as I can tell), CSP headers with &lt;code&gt;&amp;lt;iframe sandbox&amp;gt;&lt;/code&gt; and WebAssembly in Web Workers.&lt;/p&gt;
    &lt;p&gt;Co-do is a very interesting demo that illustrates all of these ideas in a single application:&lt;/p&gt;
    &lt;p&gt;You select a folder full of files and configure an LLM provider and set an API key, Co-do then uses CSP-approved API calls to interact with that provider and provides a chat interface with tools for interacting with those files. It does indeed feel similar to Claude Cowork but without running a multi-GB local container to provide the sandbox.&lt;/p&gt;
    &lt;p&gt;My biggest complaint about &lt;code&gt;&amp;lt;iframe sandbox&amp;gt;&lt;/code&gt; remains how thinly documented it is, especially across different browsers. Paul's post has all sorts of useful details on that which I've not encountered elsewhere, including a complex double-iframe technique to help apply network rules to the inner of the two frames.&lt;/p&gt;
    &lt;p&gt;Thanks to this post I also learned about the &lt;code&gt;&amp;lt;input type="file" webkitdirectory&amp;gt;&lt;/code&gt; tag which turns out to work on Firefox, Safari and Chrome and allows a browser read-only access to a full directory of files at once. I had Claude knock up a webkitdirectory demo to try it out and I'll certainly be using it for projects in the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wilson Lin on FastRender: a browser built by thousands of parallel agents - 23rd January 2026&lt;/item&gt;
      &lt;item&gt;First impressions of Claude Cowork, Anthropic's general agent - 12th January 2026&lt;/item&gt;
      &lt;item&gt;My answers to the questions I posed about porting open source code with LLMs - 11th January 2026&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2026/Jan/25/the-browser-is-the-sandbox/"/><published>2026-01-26T05:23:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46762882</id><title>The Holy Grail of Linux Binary Compatibility: Musl and Dlopen</title><updated>2026-01-26T13:14:53.540454+00:00</updated><content>&lt;doc fingerprint="edca7bdb1b15b6ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Holy Grail of Linux Binary Compatibility: musl + dlopen #242&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I guess using Go + Godot to build native &amp;amp; installable Android &amp;amp; iOS binaries (without any proprietary SDKs) was too easy. So it's time for a real challenge...&lt;/p&gt;
          &lt;head&gt;Linux Binary Compatibility&lt;/head&gt;
          &lt;p&gt;(some background reading: https://jangafx.com/insights/linux-binary-compatibility)&lt;/p&gt;
          &lt;p&gt;For a while now, it's been very easy to reliably ship command line software &amp;amp; servers for Linux, just run &lt;/p&gt;
          &lt;p&gt;The problems begin to creep in when you want access to hardware accelerated graphics. All the GPU drivers on Linux require accessing dynamic libraries via the C ABI. These C libraries are built against a particular libc, which is most commonly &lt;/p&gt;
          &lt;p&gt;In fact, I've directly experienced this, as I recently replaced the OS on my personal computer with the &lt;/p&gt;
          &lt;p&gt;That's a problem, firstly because this is my distro now, I need to be able to build graphics.gd projects! Secondly, in theory, &lt;/p&gt;
          &lt;head&gt;Supporting &lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 1 comment&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I use the dlopen/dlsym technique in Linux and loadlibrary/getprocaddress in my language's VM.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/quaadgras/graphics.gd/discussions/242"/><published>2026-01-26T07:41:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46763721</id><title>San Francisco Graffiti</title><updated>2026-01-26T13:14:53.370638+00:00</updated><content/><link href="https://walzr.com/sf-graffiti"/><published>2026-01-26T10:02:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46763864</id><title>MapLibre Tile: a modern and efficient vector tile format</title><updated>2026-01-26T13:14:53.307050+00:00</updated><content>&lt;doc fingerprint="4787f9535cbb25f4"&gt;
  &lt;main&gt;
    &lt;p&gt;Jan 23, 2026&lt;/p&gt;
    &lt;p&gt;Today we are happy to announce MapLibre Tile (MLT), a new modern and efficient vector tile format.&lt;/p&gt;
    &lt;p&gt;MapLibre Tile (MLT) is a succesor to Mapbox Vector Tile (MVT). It has been redesigned from the ground up to address the challenges of rapidly growing geospatial data volumes and complex next-generation geospatial source formats, as well as to leverage the capabilities of modern hardware and APIs.&lt;/p&gt;
    &lt;p&gt;MLT is specifically designed for modern and next-generation graphics APIs to enable high-performance processing and rendering of large (planet-scale) 2D and 2.5 basemaps. This current implementation offers feature parity with MVT1 while delivering on the following:&lt;/p&gt;
    &lt;p&gt;In addition, MLT was designed to support the following use cases in the future:&lt;/p&gt;
    &lt;p&gt;As with any MapLibre project, the future of MLT is decided by the needs of the community. There are a lot of exciting ideas for other future extensions and we welcome contributions to the project.&lt;/p&gt;
    &lt;p&gt;For a more in-depth exploration of MLT have a look at the following slides, watch this talk or read this paper by MLT inventor Markus Tremmel.&lt;/p&gt;
    &lt;p&gt;For the adventurous, the answer is: today. Both MapLibre GL JS and MapLibre Native now support MLT sources. You can use the new &lt;code&gt;encoding&lt;/code&gt; property on sources in your style JSON with a value of &lt;code&gt;mlt&lt;/code&gt; for MLT vector tile sources.&lt;/p&gt;
    &lt;p&gt;To try out MLT, you have the following options:&lt;/p&gt;
    &lt;p&gt;Refer to this page for a complete and up-to-date list of integrations and implementations. If you are an integrator working on supporting MLT, feel free to add your own project there.&lt;/p&gt;
    &lt;p&gt;We would love to hear your experience with using MLT! Join the &lt;code&gt;#maplibre-tile-format&lt;/code&gt; channel on our Slack or create an Issue or Discussion on the tile spec repo.&lt;/p&gt;
    &lt;p&gt;MapLibre Tile came to be thanks to a multi-year collaboration between academia, open source and enterprise. Thank you to everyone who was involved! We are very proud that our community can innovate like this.&lt;/p&gt;
    &lt;p&gt;Special thanks go to Markus Tremmel for inventing the format, Yuri Astrakhan for spearheading the project, Tim Sylvester for the C++ implementation, Harel Mazor, Benedikt Vogl and Niklas Greindl for working on the JavaScript implementation.&lt;/p&gt;
    &lt;p&gt;Also thanks to Microsoft and AWS for financing work on MLT.&lt;/p&gt;
    &lt;p&gt;One exception: unlike MVT, MLT does not support layers where a value in a column changes type from feature to feature. ↩&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maplibre.org/news/2026-01-23-mlt-release/"/><published>2026-01-26T10:19:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46764789</id><title>EU investigates Elon Musk's X over Grok AI sexual deepfakes</title><updated>2026-01-26T13:14:53.083255+00:00</updated><content>&lt;doc fingerprint="d1ae8a589ead27dc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;EU investigates Elon Musk's X over Grok AI sexual deepfakes&lt;/head&gt;
    &lt;p&gt;The European Commission has launched an investigation into Elon Musk's X over concerns its AI tool Grok was used to create sexualised images of real people.&lt;/p&gt;
    &lt;p&gt;It follows a similar announcement in January from the UK watchdog Ofcom.&lt;/p&gt;
    &lt;p&gt;If the site is found to have breached the rules of EU's under the Digital Services Act, the Commission could fine the company up to 6% of its global annual turnover.&lt;/p&gt;
    &lt;p&gt;A previous statement from X's Safety account said the social media platform had stopped Grok from digitally altering pictures of people to remove their clothing in "jurisdictions where such content is illegal".&lt;/p&gt;
    &lt;p&gt;Regina Doherty, a member of the European parliament representing Ireland, said the Commission would assess whether "manipulated sexually explicit images" have been shown to users in the EU.&lt;/p&gt;
    &lt;p&gt;Campaigners and victims said the ability to generate sexually explicit pictures using the tool should have "never happened", and Ofcom said its investigation would remain ongoing.&lt;/p&gt;
    &lt;p&gt;The EU regulator said it may "impose interim measures" if X refuses to implement meaningful adjustments.&lt;/p&gt;
    &lt;p&gt;It said it had also extended its ongoing investigation launched in December 2023 over risks associated with X's recommender systems - the algorithm that recommends specific posts to users.&lt;/p&gt;
    &lt;p&gt;Before the Commission's announcement, Elon Musk posted a picture on X on Monday appearing to make light of the new restrictions in place around Grok.&lt;/p&gt;
    &lt;p&gt;The X owner has previously criticised those scrutinising the app's image-editing function - particularly the UK government - calling it "any excuse for censorship".&lt;/p&gt;
    &lt;p&gt;On Sunday, the Grok account on X claimed more than 5.5 billion images were generated by the tool in just 30 days.&lt;/p&gt;
    &lt;head rend="h2"&gt;'Unacceptable form of degradation'&lt;/head&gt;
    &lt;p&gt;Other investigations into the platform's chatbot are underway in Australia, France and Germany.&lt;/p&gt;
    &lt;p&gt;Grok was temporarily banned in Indonesia and Malaysia, although the latter has now lifted the ban.&lt;/p&gt;
    &lt;p&gt;Henna Virkkunen, Executive Vice-President for Tech Sovereignty, Security and Democracy at the Commission called the sexual deepfakes a "violent, unacceptable form of degradation".&lt;/p&gt;
    &lt;p&gt;"With this investigation, we will determine whether X has met its legal obligations under the DSA, or whether it treated rights of European citizens - including those of women and children - as collateral damage of its service," she said.&lt;/p&gt;
    &lt;p&gt;In a statement to Reuters, Doherty said there were "serious questions" over if platforms such as X were meeting legal obligations "to assess risks properly and to prevent illegal and harmful content from spreading".&lt;/p&gt;
    &lt;p&gt;"The European Union has clear rules to protect people online," she said.&lt;/p&gt;
    &lt;p&gt;"Those rules must mean something in practice, especially when powerful technologies are deployed at scale.&lt;/p&gt;
    &lt;p&gt;"No company operating in the EU is above the law."&lt;/p&gt;
    &lt;p&gt;The move comes a month after the EU fined X €120m (£105m) over its blue tick badges, saying they "deceive users" because the firm is not "meaningfully verifying" who is behind the account.&lt;/p&gt;
    &lt;p&gt;In response, the US Secretary of State Marco Rubio and the Federal Communications Commission (FCC) accused the EU regulator of attacking and censoring US firms.&lt;/p&gt;
    &lt;p&gt;"The European Commission's fine isn't just an attack on X, it's an attack on all American tech platforms and the American people by foreign governments," he said.&lt;/p&gt;
    &lt;p&gt;His remarks were reposted by Musk, who added "absolutely".&lt;/p&gt;
    &lt;p&gt;Sign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/clye99wg0y8o"/><published>2026-01-26T12:19:16+00:00</published></entry></feed>