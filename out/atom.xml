<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-14T19:32:35.542829+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45926439</id><title>Nvidia is gearing up to sell servers instead of just GPUs and components</title><updated>2025-11-14T19:32:41.770485+00:00</updated><content>&lt;doc fingerprint="b7f8d4517b86a56a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;JP Morgan says Nvidia is gearing up to sell entire AI servers instead of just AI GPUs and components — Jensen's master plan of vertical integration will boost Nvidia profits, purportedly starting with Vera Rubin&lt;/head&gt;
    &lt;p&gt;The launch of Nvidia's Vera Rubin platform for AI and HPC next year could mark significant changes in the AI hardware supply chain as Nvidia plans to ship its partners fully assembled Level-10 (L10) VR200 compute trays with all compute hardware, cooling systems, and interfaces pre-installed, according to J.P. Morgan (via @Jukanlosreve). The move would leave major ODMs with very little design or integration work, making their lives easier, but would also trim their margins in favor of Nvidia's. The information remains unofficial at this stage.&lt;/p&gt;
    &lt;p&gt;Starting with the VR200 platform, Nvidia is reportedly preparing to take over production of fully built L10 compute trays with a pre-installed Vera CPU, Rubin GPUs, and a cooling system instead of allowing hyperscalers and ODM partners to build their own motherboards and cooling solutions. This would not be the first time the company has supplied its partners with a partially integrated server sub-assembly: it did so with its GB200 platform when it supplied the whole Bianca board with key components pre-installed. However, at the time, this could be considered as L7 – L8 integration, whereas now the company is reportedly considering going all the way to L10, selling the whole tray assembly — including accelerators, CPU, memory, NICs, power-delivery hardware, midplane interfaces, and liquid-cooling cold plates — as a pre-built, tested module.&lt;/p&gt;
    &lt;p&gt;If the information is correct, and Nvidia will indeed ship its partners L10 compute trays (which probably account for 90% of the cost of a server), then Nvidia will only leave its partners with rack-level integration rather than server design. They would still build the outer chassis, integrate power supplies depending on requirements, install sidecars or CDUs for rack-level cooling, add their own BMC and management stack, and perform final assembly and testing. These tasks matter operationally, but they do not differentiate hardware in a meaningful way.&lt;/p&gt;
    &lt;p&gt;This move promises to shorten the ramp for VR200 as Nvidia's partners will not have to design everything in-house and could lower production costs due to the volume of scale ensured by a direct contract between Nvidia and an EMS (most likely Foxconn as the primary supplier and then Quanta and Wistron, but that is speculation). For example, a Vera Rubin Superchip board recently demonstrated by Jensen Huang uses a very complex design, a very thick PCB, and only solid-state components. Designing such a board takes time and costs a lot of money, so using select EMS provider(s) to build it makes a lot of sense.&lt;/p&gt;
    &lt;p&gt;J.P. Morgan reportedly mentions the increase in power consumption of one Rubin GPU from 1.4 kW (Blackwell Ultra) to 1.8 kW (R200) and even 2.3 kW (a previously unannounced TDP for an allegedly unannounced SKU (Nvidia declined a Tom's Hardware request for comment on the matter) and increased cooling requirements as one of the motivations for moving to supply the whole tray instead of individual components. However, we know from reported supply chain sources that various OEMs and ODMs, as well as hyperscalers like Microsoft, are experimenting with very advanced cooling systems, including immersion and embedded cooling, which underscores their experience.&lt;/p&gt;
    &lt;p&gt;However, Nvidia's partners will shift from being system designers to becoming system integrators, installers, and support providers. They are going to keep enterprise features, service contracts, firmware ecosystem work, and deployment logistics, but the 'heart' of the server — the compute engine — is now fixed, standardized, and produced by Nvidia rather than by OEMs or ODMs themselves.&lt;/p&gt;
    &lt;p&gt;Also, we can only wonder what will happen with Nvidia's Kyber NVL576 rack-scale solution based on the Rubin Ultra platform, which is set to launch alongside the emergence of 800V data center architecture meant to enable megawatt-class racks and beyond. Now the only question is whether Nvidia further increases its share in the supply chain to, say, rack-level integration?&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Anton Shilov is a contributing writer at Tom’s Hardware. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;DS426&lt;/header&gt;There are definitely advantages of such levels of integration, but ultimately, it only bolsters Nvidia's monopolistic powers. When the AI world desperately needs a more open ecosystem, Nvidia is sure to double-down on forcing the standard for everyone.Reply&lt;lb/&gt;Hard as heck to change the status quo sometimes, ain't it!&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;JTWrenn&lt;/header&gt;This makes me wonder if the stock slide is actually just heavy money moving around in the background at lower rates to try to free up capital to do this. Wonder how much this will tank Super MicroReply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;edzieba&lt;/header&gt;"Gearing up"? They've been selling not just servers but entire racks for years now (starting with DGX-1 back in 2016, so nearly a decade). If anything, this is unbundling those DGX boxes from the DGX pods to be sold as individual RUs for OEMS to integrate.Reply&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomshardware.com/tech-industry/artificial-intelligence/jp-morgan-says-nvidia-is-gearing-up-to-sell-entire-ai-servers-instead-of-just-ai-gpus-and-componentry-jensens-master-plan-of-vertical-integration-will-boost-profits-purportedly-starting-with-vera-rubin"/><published>2025-11-14T13:18:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45926469</id><title>AGI fantasy is a blocker to actual engineering</title><updated>2025-11-14T19:32:41.537867+00:00</updated><content>&lt;doc fingerprint="6cff1130952e1f98"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AGI fantasy is a blocker to actual engineering&lt;/head&gt;
    &lt;p&gt;Reading Empire of AI by Karen Hao, I was struck by how people associated with OpenAI believe in AGI. They really do think someone, perhaps them, will build AGI, and that it will lead to either the flourishing or destruction of humanity.&lt;/p&gt;
    &lt;p&gt;Elon Musk founded OpenAI because he thought Demis Hassabis was an evil genius who would build AGI first:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;…Musk would regularly characterise Hassabis as a supervillain who needed to be stopped. Musk would make unequivocally clear that OpenAI was the good to DeepMind’s evil. … “He literally made a video game where an evil genius tries to create AI to take over the world,” Musk shouted [at an OpenAI off-site], referring to Hassabis’s 2004 title Evil Genius, “and fucking people don’t see it. Fucking people don’t see it! And Larry [Page]? Larry thinks he controls Demis but he’s too busy fucking windsurfing to realize that Demis is gathering the power.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;OpenAI’s co-founder and chief scientist Ilya Sutskever regularly told audiences and employees to “feel the AGI”. At a company off-site in Yosemite in September 2022, employees gathered around a firepit:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the pit, [Sutskever] had placed a wooden effigy that he’d commissioned from a local artist, and began a dramatic performance. This effigy, he explained represented a good, aligned AGI that OpenAI had built, only to discover it was actually lying and deceitful. OpenAI’s duty, he said, was to destroy it. … Sutskever doused the effigy in lighter fluid and lit on fire.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I think it’s remarkable that what was until recently sci-fi fantasy has become a mainstream view in Silicon Valley.&lt;/p&gt;
    &lt;p&gt;Hao writes that GPT-2 was a bet on the “pure language” hypothesis, that asserts that since we communicate through language, then AGI should emerge from training a model solely on language. This is contrast to the “grounding” hypothesis, that asserts an AGI needs to perceive the world. Successfully scaling GPT to GPT-2 convinced enough people at OpenAI that the pure language hypothesis was valid. They just needed more data, more model parameters, and more compute.&lt;/p&gt;
    &lt;p&gt;So the belief in AGI, plus the recent results from LLMs, necessitates scaling, and justifies building data centres that consume hundreds of litres of water a second, run on polluting gas generators because the grid can’t supply the power (and might use as much power as entire cities), driving up CO2 emissions from manufacture and operation of new hardware, and exploits and traumatises data workers to make sure ChatGPT doesn’t generate outputs like child sexual abuse material and hate speech or encourage users to self-harm. (The thirst for data is so great that they stopped curating training data and instead consume the internet, warts and all, and manage the model output using RLHF.)&lt;/p&gt;
    &lt;p&gt;And this is all fine, because they’re going to make AGI and the expected value (EV) of it will be huge! (Briefly, the argument goes that if there is a 0.001% chance of AGI delivering an extremely large amount of value, and 99.999% chance of much less or zero value, then the EV is still extremely large because &lt;code&gt;(0.001% * very_large_value) + (99.999% * small_value) = very_large_value&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;But AGI arguments based on EV are nonsensical because the values and probabilities are made up and unfalsifiable. They also ignore externalities like environmental damage, which in contrast to AGI, have known negative value and certain probability: costs borne by everyone else right now.&lt;/p&gt;
    &lt;p&gt;As a technologist I want to solve problems effectively (by bringing about the desired, correct result), efficiently (with minimal waste) and without harm (to people or the environment).&lt;/p&gt;
    &lt;p&gt;LLMs-as-AGI fail on all three fronts. The computational profligacy of LLMs-as-AGI is dissatisfying, and the exploitation of data workers and the environment unacceptable. Instead, if we drop the AGI fantasy, we can evaluate LLMs and other generative models as solutions for specific problems, rather than all problems, with proper cost benefit analysis. For example, by using smaller purpose-built generative models, or even discriminative (non-generative) models. In other words, make trade-offs and actually do engineering.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomwphillips.co.uk/2025/11/agi-fantasy-is-a-blocker-to-actual-engineering/"/><published>2025-11-14T13:21:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45926779</id><title>I think nobody wants AI in Firefox, Mozilla</title><updated>2025-11-14T19:32:41.403080+00:00</updated><content>&lt;doc fingerprint="f7ee53523cb1437d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I think nobody wants AI in Firefox, Mozilla&lt;/head&gt;
    &lt;p&gt;Mozilla is developing a built‑in AI assistant for Firefox that will be offered as a third browsing mode alongside Normal and Private tabs. They’re calling it “Window AI.”&lt;/p&gt;
    &lt;p&gt;Details are still scarce. Based on Mozilla’s official announcement on Thursday (13th), it looks like a deeper implementation than the existing sidebar that gives access to third‑party chatbots (ChatGPT, Gemini, Copilot, etc.). The post stresses the feature will be opt-in and that the user “is in control.”&lt;/p&gt;
    &lt;p&gt;There’s a waitlist to try the feature and a Mozilla forum thread inviting people to “help shape” the initiative.&lt;/p&gt;
    &lt;p&gt;It’s safe to say that the people who volunteered to “shape” the initiative want it dead and buried. Of the 52 responses at the time of writing, *all* rejected the idea and asked Mozilla to stop shoving AI features into Firefox.&lt;/p&gt;
    &lt;p&gt;I don’t know whether the negative reactions reflect the majority of Firefox users or are just a noisy minority. Mozilla, after all, likely has a clearer view of the whole user base.&lt;/p&gt;
    &lt;p&gt;What strikes me as odd is the decision to position itself as just another AI‑enabled web browser, picking a fight with big techs and better‑funded startups whose users are less hostile (and sometimes enthusiastic) about adding AI to web browsing.&lt;/p&gt;
    &lt;p&gt;Mozilla seems to be trying to wedge itself between those who reject AI and those who want generative‑AI features in the browser — trying to please everyone — as this excerpt from the post shows:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We see a lot of promise in AI browser features making your online experience smoother, more helpful, and free from the everyday disruptions that break your flow. But browsers made by AI companies ask you to make a hard choice — either use AI all the time or don’t use it at all.&lt;/p&gt;
      &lt;p&gt;We’re focused on making the best browser, which means recognizing that everyone has different needs. For some, AI is part of everyday life. For others, it’s useful only occasionally. And many are simply curious about what it can offer, but unsure where to start.&lt;/p&gt;
      &lt;p&gt;Regardless of your choice, with Firefox, you’re in control.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Those unhappy have another option: use an AI‑free Firefox fork such as LibreWolf, Waterfox, or Zen Browser.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://manualdousuario.net/en/mozilla-firefox-window-ai/"/><published>2025-11-14T14:05:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45927210</id><title>Linear Algebra Explains Why Some Words Are Effectively Untranslatable</title><updated>2025-11-14T19:32:41.171372+00:00</updated><content>&lt;doc fingerprint="7519dbbe0167b35d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Linear Algebra Explains Why Some Words Are Effectively Untranslatable&lt;/head&gt;
    &lt;head rend="h2"&gt;A modest mathematical framing of language&lt;/head&gt;
    &lt;p&gt;Marco Giancotti,&lt;/p&gt;
    &lt;p&gt;Marco Giancotti,&lt;/p&gt;
    &lt;p&gt;Cover image:&lt;/p&gt;
    &lt;p&gt;Image by vackground.com, Unsplash&lt;/p&gt;
    &lt;p&gt;A part of me still hasn't recovered from learning that some people believe there is no such thing as an untranslatable word. I've written about why I disagree before, but that explanation didn't satisfy me completely. There was a stronger argument to be made, I thought, but I couldn't put it into words. Now I remember, though: you need to see language as (a little bit) like math. Call me crazy, but I think that language translation is like a change of basis in linear algebra.&lt;/p&gt;
    &lt;p&gt;Me making weird connections like this might simply be an occupational hazard. Both my PhD research and my first job had to do with controlling the position and orientation of spacecraft and rocks in space, which means that I spent years juggling vectors, matrix multiplications, and reference frames almost daily. Still, I think it is simple enough to be understood by anyone, so hear me out.&lt;/p&gt;
    &lt;p&gt;(You might remember linear algebra from high school. It's that subfield where you write about stuff like this:&lt;/p&gt;
    &lt;p&gt;If the mere sight of the above is like a punch in the face for you, don't worry. I'm not going to math you to death in what follows. I will only remind you of a tiny basic part of it that I think relates to languages.)&lt;/p&gt;
    &lt;p&gt;During those same mathematical days, I was also learning Japanese. The language fascinated me for many reasons, like its beautiful dissociation between written and spoken words and its many unique quirks, but I was also struck early on by something a bit more meta: how hard it is to translate things to and from it.&lt;/p&gt;
    &lt;p&gt;These two concurrent interests made it hard for me not to see a connection. For almost a decade now, I've held it in a corner of my mind without telling anyone, perhaps because I thought it would be seen as too outrageous, but hey! Now LLMs are popular and they literally handle words and concepts as vectors with linear algebra operations, so maybe my analogy isn't that out there. Let me give it a try.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Case of Vectors&lt;/head&gt;
    &lt;p&gt;Contrary to popular belief, a vector is not "a list of numbers" but an abstract object with no predefined way to express it.&lt;/p&gt;
    &lt;p&gt;But a vector is not very useful in this abstract state. We need a way to write it down so that we can manipulate it with algebra and communicate it to others. We do this by choosing a frame of reference—or, more accurately, a set of vectors to use as "basis" to quantify all others.&lt;/p&gt;
    &lt;p&gt;This is where numbers come into play. By projecting the vectors against the basis vectors, you can assign them lists of numbers (two numbers each, in this two-dimensional case):&lt;/p&gt;
    &lt;p&gt;Those numbers are the coordinates of the vectors in that basis. For instance, the vector can be read as "half as long as the vector along the direction of , and times as long as the vector along the direction of ."&lt;/p&gt;
    &lt;p&gt;The important thing I want to convey here (and the last mathy thing to remember) is that if you were to choose a different basis, the same vector would have different coordinates.&lt;/p&gt;
    &lt;p&gt;In this new basis, the two vectors are written as:&lt;/p&gt;
    &lt;p&gt;In short, change the basis (e.g. from " &amp;amp; " to " &amp;amp; ") and the same abstract object (vector) will be represented with different numbers. You can do all the same operations with them, like changing the vector's length and direction, calculating the angle between the vectors, and so on, and you'll get the same results in both bases, because they are operations on the same objects. The choice of basis is merely cosmetic from this point of view.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Case of Language&lt;/head&gt;
    &lt;p&gt;Now let's turn to language and see the parallel.&lt;/p&gt;
    &lt;p&gt;Contrary to popular belief, a concept is not a word or a group of words but an abstract object in your mind.&lt;/p&gt;
    &lt;p&gt;But a concept is not very useful in this abstract state. We need a way to write it down so that we can manipulate it with grammar and communicate it to others. We do this by choosing a language that is shared with the receiver of the message.&lt;/p&gt;
    &lt;p&gt;For the concept in my head right now, and choosing the English language to represent it, you get this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Going to Tokyo"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is where words come into play. By projecting the abstract idea onto the standard English vocabulary and grammar, you can assign it a list of words:&lt;/p&gt;
    &lt;p&gt;Those words are the equivalent of the coordinates of the vectors in linear algebra. The way I just wrote it is not accurate, though, because it makes it look as if English only had 3 dimensions (3 words), just like the 2-element vectors were 2-dimensional. English actually has hundreds of thousands of words, so we would need a vector that long to fully represent it, with blank spaces for all the words that aren't involved in this case.&lt;/p&gt;
    &lt;p&gt;The English language offers its speakers many other words, like camel, frolic, and or, but in this case none of them was necessary to express the idea that was in my mind, so they remain empty () and absent from my utterance of "going to Tokyo".&lt;/p&gt;
    &lt;p&gt;Of course, similar to vectors with bases, you can express the same concept in a different language. If I chose Italian as the "basis", you'd get:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Andare a Tokio"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The concept is the same, but now its representation (its "word coordinates") is different:&lt;/p&gt;
    &lt;p&gt;You can, in theory, say those two different sequences of sounds in those two languages, and obtain the same effect in the mind of the receiver. The only requirement is that all people involved know both languages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cosmetics Matter&lt;/head&gt;
    &lt;p&gt;Alright, the parallel seems plain enough. Sadly, expressing all language in that vector-like format would use up a lot of ink and is not really practical for everyday use. (LLMs kind of achieve that feat, but in a more convoluted and definitely not human-readable way.)&lt;/p&gt;
    &lt;p&gt;Why do I think it is interesting, then? Because "untranslatable" words exist.&lt;/p&gt;
    &lt;p&gt;The words that people sometimes call "untranslatable" are terms that have a clear and widely understood meaning in one language, but no equivalent in another one. I gave some examples from Japanese before, and the web is awash with blog posts enumerating curious words like that from many other languages. The key takeaway is that what only takes a single word in Language 1 can only be expressed with some accuracy in Language 2 if you use many words to explain them in all of their facets.&lt;/p&gt;
    &lt;p&gt;I wrote that the choice of basis in linear algebra is "cosmetic", because the result of an operation on vectors does not change depending on the basis. But that is only the ideal, mathematical way to look at it. We humans are not so ideal. We are weak and fallible and sometimes we even stink.&lt;/p&gt;
    &lt;p&gt;Which vector representation do you like better between these two?&lt;/p&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;p&gt;Both represent the same vector under different bases, because I chose a base that has the vector as one of the basis vectors. Here is what the two cases look like graphically:&lt;/p&gt;
    &lt;p&gt;In theory, both representations are exactly equivalent to each other. A computer wouldn't have any preference. But the second representation, the clean one with a simple one and zero, is not only easier to remember and grasp for a person, but it is also easier to handle mathematically. Things simplify easily with it, everything that is multiplied by zero becomes zero, and similarly for the multiplications by one. The calculations proceed faster and with fewer errors.&lt;/p&gt;
    &lt;p&gt;This means that, at least for our feeble organic minds, the choice of basis does matter.&lt;/p&gt;
    &lt;p&gt;The same holds for language. A concept that took several words in English...&lt;/p&gt;
    &lt;p&gt;in Japanese is a single word: joukyou (上京)&lt;/p&gt;
    &lt;p&gt;Looking at it in the other direction, a native word in one language is like one of its "basis vectors"—simple and straightforward—but the underlying concept might need to be "spread out" onto several words when applying a different language (i.e. "basis").&lt;/p&gt;
    &lt;p&gt;Arguably, having a compact word makes it easier not only to express the concept, but also to think about it. This is the Sapir-Whorf debate, but I'll leave that for another day. Instead, I want to show you what this means for untranslatability, because there are people who vehemently deny their existence.&lt;/p&gt;
    &lt;head rend="h3"&gt;Losing in Translation&lt;/head&gt;
    &lt;p&gt;I think there are two ways in which this analogy makes it quite obvious that "practical untranslatability" is a thing.&lt;/p&gt;
    &lt;p&gt;First, communication is costly, and we don't have infinite time and space to put in all the words that are needed. Even if the word could in theory be explained in the other language, usually it's not worth it.&lt;/p&gt;
    &lt;p&gt;For example, the Japanese term mono no aware (物の哀れ) could be rather accurately translated as&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;a gentle, poignant sadness or pathos felt in response to the transient nature of all things, a deep awareness of their impermanence that evokes a subtle, bittersweet sorrow and a profound, quiet empathy for their passing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In a dictionary, perhaps that's okay. But a dictionary is not translation. Translation is about conveying the meaning of full texts, and you can't do that kind of multi-line expansion for every word.&lt;/p&gt;
    &lt;p&gt;And so the translator simplifies it to the gist, e.g. as the pathos of all things. This conveys the majority of the meaning and it is usually enough, but it does lose a lot in the process.&lt;/p&gt;
    &lt;p&gt;This is exactly analogous to the data analysis technique called Principal Component Analysis (PCA), where one simplifies a vector by picking only its largest coordinates and disregarding all others. This means choosing a subset of the basis vectors that are more closely aligned with the vectors of interest, and ignoring the existence of the other basis vectors, effectively reducing the dimensions of the data. Translators use a version of PCA every time they (begrudgingly) accept to leave the finer nuances of a concept unsaid for the sake of space.&lt;/p&gt;
    &lt;p&gt;But, even assuming you do have time to explicate, using many more words increases the risk of introducing unintended nuances that come bundled with those extra words. This is like doing PCA but selecting inappropriate basis vectors, which introduce lots of small errors in the calculation of the vector's coordinates. Is "sorrow" too emotionally charged in that long translation of mono no aware? Does the use of "passing" unnecessarily remind English speakers of people dying?&lt;/p&gt;
    &lt;p&gt;You eventually hit diminishing returns: using more words confuses the reader instead of clarifying things further.&lt;/p&gt;
    &lt;p&gt;The second problem with translation is precision. Even if you can use many words, and even if none of those are misleading, words are still finite in number. Unlike ideal numerical coordinates, which can take any value down to the finest detail, you only have a small selection of words to convey a given bit of meaning.&lt;/p&gt;
    &lt;p&gt;Suppose you realize that the word "subtle" is not accurate enough in the "...evokes a subtle, bittersweet" part of the translation above. Maybe you do want to convey subtlety, but feel that the simple word "subtle" feels too strong in this case. You might try to soften it with an adverb, like "somewhat subtle" or "slightly subtle", but there aren't many other options out there. What if none of them is perfect for your current needs?&lt;/p&gt;
    &lt;p&gt;In this sense, language is "quantized": you can jump from one level of intensity of some meaning to the next, but you can't express anything in between.&lt;/p&gt;
    &lt;p&gt;This is a problem shared by all computers. Unlike ideal numbers, the numbers in a processor necessarily have a finite number of decimal places. So when you want to work with the ideal vector&lt;/p&gt;
    &lt;p&gt;the storage limitations of your computer might mean that you have to content yourself with this truncated version:&lt;/p&gt;
    &lt;p&gt;(Modern computers can usually handle many more digits than that, but you get the idea.)&lt;/p&gt;
    &lt;p&gt;Graphically, it looks something like this:&lt;/p&gt;
    &lt;p&gt;(Incidentally, AI engineers sometimes intentionally quantize large language models to make them take up less memory, but this tends to make them dumber, because they lose nuance.)&lt;/p&gt;
    &lt;p&gt;With language, like with computers, we're forced to "lower the resolution" of our concepts whenever we put them into words. This happens twice in translated text: once when the author first writes down their thoughts, then once more when the translator transports that already-degraded concept into a different language with different "quantization steps".&lt;/p&gt;
    &lt;head rend="h3"&gt;Between the Lines&lt;/head&gt;
    &lt;p&gt;I hope these rather unorthodox leaps between linguistics and mathematics helped make it almost obvious that some words and ideas are untranslatable in practice. I also hope you don't take the analogy too seriously, because it won't go much further than this. You might be tempted to begin talking about "word matrices" and whatnot, but I doubt it would help clarify things. That kind of advanced linear algebra with concepts might work for LLMs, but it doesn't seem to map to anything intelligible for a human being, not to mention make you any wiser.&lt;/p&gt;
    &lt;p&gt;Besides, language has something going for it that doesn't seem to have a mathematical equivalent: what does it mean to "read between the lines"?&lt;/p&gt;
    &lt;p&gt;It's hard to pin down, but I think it has to do with the structure and context of the words communicating something that is not contained in any of the words themselves. Perhaps it is the clever use of those "negligible coordinates"—the fringe nuances—of words scattered around the text to produce a collective effect on the reader.&lt;/p&gt;
    &lt;p&gt;A good translator might not be able to exactly translate a given word or sentence, but they might be able to "write between the lines" so that it doesn't matter very much. ●&lt;/p&gt;
    &lt;p&gt;Cover image:&lt;/p&gt;
    &lt;p&gt;Image by vackground.com, Unsplash&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://aethermug.com/posts/linear-algebra-explains-why-some-words-are-effectively-untranslatable"/><published>2025-11-14T14:46:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45927435</id><title>Oracle hit hard in Wall Street's tech sell-off over its AI bet</title><updated>2025-11-14T19:32:40.295702+00:00</updated><content>&lt;doc fingerprint="9c7f1c515ada93e9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;&lt;quote&gt;Oracle hit hard in Wall Street’s tech sell-off over its huge AI bet&lt;/quote&gt;&lt;/head&gt;&lt;head rend="h2"&gt;Try unlimited access&lt;/head&gt;Only $1 for 4 weeks&lt;p&gt;Then $75 per month. Complete digital access to quality FT journalism on any device. Cancel anytime during your trial.&lt;/p&gt;&lt;head rend="h2"&gt;Explore more offers.&lt;/head&gt;&lt;head rend="h3"&gt;FT Edit&lt;/head&gt;&lt;p&gt;Access to eight surprising articles a day, hand-picked by FT editors. For seamless reading, access content via the FT Edit page on FT.com and receive the FT Edit newsletter.&lt;/p&gt;&lt;head rend="h3"&gt;Standard Digital&lt;/head&gt;&lt;p&gt;Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.&lt;/p&gt;&lt;head rend="h3"&gt;Premium Digital&lt;/head&gt;&lt;p&gt;Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.&lt;/p&gt;&lt;p&gt;Check whether you already have access via your university or organisation.&lt;/p&gt;&lt;p&gt;Terms &amp;amp; Conditions apply&lt;/p&gt;&lt;head rend="h2"&gt;Explore our full range of subscriptions.&lt;/head&gt;&lt;head rend="h3"&gt;For individuals&lt;/head&gt;&lt;p&gt;Discover all the plans currently available in your country&lt;/p&gt;&lt;head rend="h3"&gt;For multiple readers&lt;/head&gt;&lt;p&gt;Digital access for organisations. Includes exclusive features and content.&lt;/p&gt;&lt;head rend="h2"&gt;Why the FT?&lt;/head&gt;&lt;p&gt;See why over a million readers pay to read the Financial Times.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ft.com/content/583e9391-bdd0-433e-91e0-b1b93038d51e"/><published>2025-11-14T15:04:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45928492</id><title>'No One Lives Forever' Turns 25 and You Still Can't Buy It Legitimately</title><updated>2025-11-14T19:32:40.167198+00:00</updated><content>&lt;doc fingerprint="3f72d8bd53abbdf1"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Maybe we’ll be able to play this game legitimately by the time Bobby Bonilla stops making his million and change per year.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ahh, a refreshing bit of optimism in these dark times!&lt;/p&gt;
    &lt;p&gt;One of my favorite things in all of professional sports is the unofficial holiday referred to as “Bobby Bonilla Day.” The short version of it is that Bonilla played for the New York Mets decades ago and eventually bought out his contract in 2000 when they decided they were done with him. Rather than pay the $5.9 million buyout of the contract up front, the team instead made the bonkers decision to negotiate a deferred payment schedule for that amount with 8% interest over the course of 25 years. The result is that the Mets will be paying Bonilla $1.2 million per year every July 1st, starting in 2011 and ending in 2035. And if you can’t make sense of the math on that one, it’s because you aren’t aware that the Mets ownership was one of Bernie Madoff’s many victims, which is why they had to defer the payments.&lt;/p&gt;
    &lt;p&gt;November 10th is not Bobby Bonilla Day. But it should be named “Let Us Play No One Lives Forever, You Assholes Day.” The classic spy-shooter turned 25 on that date and, for the exact same reasons we’ve detailed for a god damned decade now, you still can’t buy the game.&lt;/p&gt;
    &lt;p&gt;Here’s the short of it. Due to a series of mergers, closures, and rights purchases, the IP rights for No One Lives Forever and its sequel have been potentially split into three pieces between Warner Bros., Activision, and 20th Century Fox, like it was some kind of fucking horcrux. I say potentially because nobody really knows who owns what, if anything, when it comes to these games. When one company, Nightdive Studios, attempted to remaster and re-release the game as they’ve done with other titles, along with securing trademark rights to the game which hasn’t been sold in over a decade, all three companies complained that they may have rights to it and may sue over it.&lt;/p&gt;
    &lt;p&gt;All of those qualifiers are, again, because even these companies themselves don’t know what rights they actually have. And why is that? Well, because the gaming rights deals were inked before digital storage was widely used for this sort of thing and, well, nobody seems to be able to locate the actual paperwork denoting who owns what. Here’s an example of an exchange Nightdive had with Activision.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“So we went back to Activision and, [after] numerous correspondence going back and forth, they replied that they thought they might have some rights, but that any records predated digital storage. So we’re talking about a contract in a box someplace.” Kuperman laughed. “The image I get is the end of Indiana Jones… somewhere in a box, maybe in the bowels of Activision, maybe it was shipped off to Iron Mountain or somewhere. And they confessed, they didn’t have [their] hands on it. And they weren’t sure that they even had any of those rights.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Which didn’t keep Activision from warning Nightdive that it might totally sue if it moved forward with remastering the game. The other companies made similar noises.&lt;/p&gt;
    &lt;p&gt;So what’s a person to do if they want to play this game? You can’t buy it legitimately currently. It’s not even for sale anywhere. And a situation like that, which I’ve stated before, completely breaks the copyright bargain. The only option is, as Kotaku of all places notes, to download it for free from somewhere.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Downloading games that are available for sale is piracy. It’s illegal, and it’s not supportive of developers and their art. But when companies have gone out of their way to refuse to take your money for a game for the better part of two decades, it’s a very different situation. Look, I’m not your real mom and dad, and I can’t tell you what to do. But if you were to click on this link (link removed by Techdirt due to us not knowing where it takes you) and download both games (as well as spin-off Contract Jack), you’d end up with modernized versions of these classic games, with mods that allow them to work on Windows 10 and 11, and in widescreen. And what better time to do (or not do) this than on the first game’s 25th anniversary?&lt;/p&gt;
      &lt;p&gt;At this point (as indeed it was over eight years ago, the last time I suggested just downloading it, to no negative response at all) we have to consider No One Lives Forever to be abandonware. No one is willing to take ownership of it, although those that could do so sometimes mindlessly threaten to intervene should anyone else try to rebuild it for sale. Nightdive were scared off a decade ago, and it’s been sitting on GOG’s Dreamlist since that launched earlier this year (with 87,171 people saying they’d pay for it if they could). It’s far too small of a concern for any of the megacorps who might own it to spend the time and money to work out if they do, but it’s far too big of a concern within gaming history to be allowed to just disappear. Thank goodness for the anonymous heroes running NOLF Revival. I thank them for their service.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It’s the only option the public has to play this game and enjoy this small piece of our collective culture. The real answer here is some sort of copyright reform that makes this situation not a thing. If a company, or group of companies, won’t offer a piece of work for sale, can’t be bothered to understand what they own of it, if anything, and have no plans to figure any of that out… then how can this be copyright infringement?&lt;/p&gt;
    &lt;p&gt;So happy “Let Us Play No One Lives Forever, You Assholes” Day. Maybe we’ll be able to play this game legitimately by the time Bobby Bonilla stops making his million and change per year.&lt;/p&gt;
    &lt;p&gt; Filed Under: copyright, ip rights, no one lives forever, video games &lt;lb/&gt; Companies: 20th century fox, activision, microsoft, nightdive, warner bros. &lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Maybe we’ll be able to play this game legitimately by the time Bobby Bonilla stops making his million and change per year.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ahh, a refreshing bit of optimism in these dark times!&lt;/p&gt;
    &lt;p&gt;IANAL, but I’d say just release and let them sue.&lt;lb/&gt; If they can’t find the documentation during discovery, case dismissed. Maybe even counter-sue for legal fees.&lt;/p&gt;
    &lt;p&gt;But then they have an incentive to look for the paperwork. they don’t have any particular reason to go looking right now but if they see money and a lawsuit they’ll assign someone to start digging.&lt;/p&gt;
    &lt;p&gt;You could be in for a really big payout to them.&lt;/p&gt;
    &lt;p&gt;So it would be a gamble, and the potential payoff is probably not worth the risk you would be taking.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;IANAL, but I’d say just release and let them sue.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You didn’t need to add that first part, it’s implied.&lt;/p&gt;
    &lt;p&gt;I am baffled why we make intellectual property as legally upheld as physical property, and yet we still end up with these areas that are so untouchably gray area nobody can do anything.&lt;/p&gt;
    &lt;p&gt;In terms of physical property gray areas, there are certainly disputed areas, but almost nowhere on Earth do people avoid due to the ambiguity. The only real example I know is Bir Tawil.&lt;/p&gt;
    &lt;p&gt;Those NOLF IP “feeling unproductive, might litigate later… idk &amp;lt;3&amp;lt;3&amp;lt;3” hogging assholes can burn in… molten lava? Very nice.&lt;/p&gt;
    &lt;p&gt;The fact that the link in the article is indeed a valid, working dedicated site for hosting “pirated” copies of these games and it hasn’t been taken down in nearly a decade says a lot about how much the potential “rightsholders” genuinely do not give a damn about this series.&lt;/p&gt;
    &lt;p&gt;Feels like copyright law should have stipulations for cases like this, especially considering how long terms are right now – corporations shouldn’t be sitting on copyrights doing absolutely nothing with them like dragon hoards.&lt;/p&gt;
    &lt;p&gt;No-one plays…forever. Well, legally anyway.&lt;lb/&gt; The only games are being played by the corporations, and played so poorly that EVERYONE loses.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.techdirt.com/2025/11/13/no-one-lives-forever-turns-25-you-still-cant-buy-it-legitimately/"/><published>2025-11-14T16:31:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45928620</id><title>US Tech Market Treemap</title><updated>2025-11-14T19:32:40.072873+00:00</updated><content>&lt;doc fingerprint="f22c283ecb0964aa"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;US Tech Market Treemap&lt;/head&gt;
    &lt;p&gt;Rectangle Area corresponds to live market capitalization. US Tech equities over ~$10B market cap. Performance overlays&lt;/p&gt;
    &lt;p&gt;View:&lt;/p&gt;
    &lt;p&gt;Loading live market data...&lt;/p&gt;
    &lt;p&gt;Rectangle Area corresponds to live market capitalization. US Tech equities over ~$10B market cap. Performance overlays&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://caplocus.com/"/><published>2025-11-14T16:42:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45928709</id><title>Manganese is Lyme disease's double-edge sword</title><updated>2025-11-14T19:32:39.687813+00:00</updated><content>&lt;doc fingerprint="664879920b331da1"&gt;
  &lt;main&gt;
    &lt;p&gt;For decades, Lyme disease has frustrated both physicians and patients alike. Caused by the corkscrew-shaped bacterium Borrelia burgdorferi, the infection, if left untreated, can linger for months, leading to fever, fatigue and painful inflammation.&lt;/p&gt;
    &lt;p&gt;In a new study, Northwestern University and Uniformed Services University (USU) scientists have uncovered a surprising — and ironic — vulnerability in the hardy bacterium. By exploiting this vulnerability, researchers could help disarm B. burgdorferi, potentially leading to new therapeutic strategies for Lyme disease.&lt;/p&gt;
    &lt;p&gt;The Northwestern and USU team discovered that manganese, which helps shield B. burgdorferi against its host’s immune system, is simultaneously also a crack in its armor. If B. burgdorferi is either starved of or overloaded with manganese, the bacteria become highly vulnerable to the host’s immune system or treatments they would otherwise resist.&lt;/p&gt;
    &lt;p&gt;The study was published today (Nov. 13) in the journal mBio.&lt;/p&gt;
    &lt;p&gt;“Our work shows that manganese is a double-edged sword in Lyme disease,” said Northwestern’s Brian Hoffman, who co-led the study with USU’s Michael Daly. “It’s both Borrelia’s armor and its weakness. If we can target the way it manages manganese, we could open doors for entirely new approaches for treating Lyme disease.”&lt;/p&gt;
    &lt;p&gt;Hoffman is the Charles E. and Emma H. Morrison Professor of Chemistry and molecular biosciences at Northwestern’s Weinberg College of Arts and Sciences. He also is a member of the Chemistry of Life Processes Institute and the Robert H. Lurie Comprehensive Cancer Center of Northwestern University. Daly is an emeritus professor of pathology at USU.&lt;/p&gt;
    &lt;p&gt;Since the 1980s, the occurrence of Lyme disease has increased dramatically across North America and around the globe. According to the Centers for Disease Control and Prevention, roughly 476,000 people in the United States are diagnosed annually. Currently, there are no approved vaccines against the disease, and long-term use of antibiotics is problematic.&lt;/p&gt;
    &lt;p&gt;“Although antibiotics harm B. burgdorferi, they also kill beneficial gut bacteria,” Daly said. “Lyme disease is transmitted through tick bites and — if not treated promptly — can cause lingering effects by attacking the patient’s immune, circulatory and central nervous systems.”&lt;/p&gt;
    &lt;p&gt;In a series of previous studies, Hoffman and Daly collaborated to understand the role of manganese in Deinococcus radiodurans, a radiation-resistant bacteria known as “Conan the Bacterium” for its extraordinary ability to survive harsh conditions. Now, they wanted to see if manganese played a role in B. burgdorferi’s defenses.&lt;/p&gt;
    &lt;p&gt;To conduct the study, the team used a new tool called electron paramagnetic resonance (EPR) imaging to characterize the atomic composition of manganese inside the living bacteria. To add even finer detail, the team harnessed electron nuclear double resonance (ENDOR) spectroscopy to examine the atoms surrounding manganese. Together, the technologies created a molecular map, showing which forms of manganese were present, where they were located and how they changed under stress.&lt;/p&gt;
    &lt;p&gt;The “map” revealed a two-tier, manganese-based defense system comprising an enzyme called MnSOD and a pool of manganese metabolites. To withstand bombardment from the host’s immune system, the bacteria first use MnSOD, which acts like a shield. If any oxygen radicals slip past this shield, they are met with the metabolite pool, which acts like a sponge to soak up and neutralize those toxic molecules.&lt;/p&gt;
    &lt;p&gt;“Our study demonstrates the power of EPR and ENDOR spectroscopies for uncovering hidden biochemical mechanisms in pathogens,” Hoffman said. “Without these tools, B. burgdorferi’s defense system and weak spots would have remained invisible.”&lt;/p&gt;
    &lt;p&gt;The scientists found the bacteria constantly juggle where to send the manganese — to the MnSOD enzymes or the metabolite pool. Too little manganese and the bacteria lose their defense mechanisms. But, as the microbes age, their metabolite pools dramatically shrink, leaving them exposed to damage and stress. At this point, too much manganese becomes toxic because the bacteria can no longer store it safely.&lt;/p&gt;
    &lt;p&gt;This discovery holds potential for new Lyme disease therapies. Future drugs could starve the bacterium of manganese, disrupt its ability to form protective manganese complexes or even push it into toxic overload. Any of these approaches would leave B. burgdorferi wide open to attack by the immune system.&lt;/p&gt;
    &lt;p&gt;“By disrupting the delicate balance of manganese in B. burgdorferi, it may be possible to weaken the pathogen during infection,” Daly said. “Manganese is an Achilles’ heel of its defenses.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Notes&lt;/head&gt;
    &lt;p&gt;The study was supported by the Congressionally Directed Medical Research Programs’ Tick-borne Disease Research Program and the National Institutes of Health. Additional funds were from the Defense Threat Reduction Agency and National Institute of Allergy and Infectious Diseases.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.northwestern.edu/stories/2025/11/manganese-is-lyme-diseases-double-edge-sword"/><published>2025-11-14T16:51:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45928822</id><title>RetailReady (YC W24) Is Hiring</title><updated>2025-11-14T19:32:39.286413+00:00</updated><content>&lt;doc fingerprint="8990dec1641c8fda"&gt;
  &lt;main&gt;
    &lt;p&gt;An AI-powered supply chain compliance engine&lt;/p&gt;
    &lt;p&gt;San Francisco - In Person&lt;/p&gt;
    &lt;p&gt;We’re RetailReady (YC W24), an AI-powered supply chain compliance engine shaking up an antiquated (and yes, unsexy) industry. Since YC, we raised a $3.3M seed round and signed over 15 enterprise customers… we’re officially in scaling mode.&lt;/p&gt;
    &lt;p&gt;RetailReady is the first AI-powered compliance engine designed for retail supply chains. We automate the messy web of compliance requirements between brands, warehouses, and retailers, turning weeks of manual work into minutes of automation. Our platform integrates deeply with warehouse operations and connects with customer systems via EDI, APIs, and flat files.&lt;/p&gt;
    &lt;p&gt;We don’t just build dashboards. We build the nervous system of compliance inside a warehouse.&lt;/p&gt;
    &lt;p&gt;We’re hiring a Support Engineer to be the first line of defense when issues arise. You’ll troubleshoot customer questions, diagnose technical issues, and flag deeper bugs for our on-call engineering team, keeping operations smooth across our growing customer base.&lt;/p&gt;
    &lt;p&gt;You’ll also help us scale smarter by documenting common issues and writing internal + customer-facing help articles to train our AI support model.&lt;/p&gt;
    &lt;p&gt;This is an in-person role in San Francisco with early hours (5 a.m. – 2 p.m.) to support our East Coast customers in real time.&lt;/p&gt;
    &lt;p&gt;If you’re an early riser who loves solving problems, thrives in fast-moving environments, and wants to help power the next generation of supply chain tech - we’d love to hear from you.&lt;/p&gt;
    &lt;p&gt;RetailReady is building an AI-powered supply chain compliance engine. Supply chains are still heavily reliant on paper processes and tribal knowledge, causing costly shipping mistakes that jeopardize the longevity of businesses. RetailReady is the first-to-market with our retail compliance packing software, leveraging camera vision to direct warehouses to ship orders without error. We are positioning our compliance data models to become the operating system that will power the next wave of warehouse robotics and automation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/retailready/jobs/kGHAith-support-engineer"/><published>2025-11-14T17:00:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45928873</id><title>Moving Back to a Tiling WM – XMonad</title><updated>2025-11-14T19:32:39.069944+00:00</updated><content>&lt;doc fingerprint="12c6cc7807b53b9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Moving Back to a Tiling WM - XMonad&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Published on&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Authors&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;list rend="dl"&gt;
              &lt;item rend="dt-2"&gt;Author&lt;/item&gt;
              &lt;item rend="dd-2"&gt;Manas&lt;/item&gt;
              &lt;item rend="dt-3"&gt;Mastodon&lt;/item&gt;
              &lt;item rend="dd-3"&gt;mastodon @weirdsmiley&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are my dotfiles.&lt;/p&gt;
    &lt;p&gt;When I was still using Manjaro Linux back in 2019, I got a nudge to try i3wm. It was my first experience with any window manager. And I spent nearly 5 years with it, enjoying the absolute control over my workflow. Nearing the end of 2023, when I finally decided to leave Manjaro (for good), I had a bunch of options on my hand. Fedora looked really promising at that time. But even then, I wasnât sure I was going to be using any tiling window manager. I happily switched to Gnome in Fedora 40. I ran it along with XOrg so that I could make my &lt;code&gt;capslock&lt;/code&gt; key act as a &lt;code&gt;ctrl&lt;/code&gt; when held and as an &lt;code&gt;escape&lt;/code&gt; when pressed
once, using &lt;code&gt;setxkbmap&lt;/code&gt; and &lt;code&gt;xcape&lt;/code&gt;. But only after spending a few months there,
I realized I missed that finer control at my fingertips. So, I resumed searching
for a newer tiling window manager. I was also learning Haskell at that time, so
picking up XMonad was natural.&lt;/p&gt;
    &lt;p&gt;There are a lot of things that I like about XMonad apart from its standard tiling manager features. I enjoy writing the configuration in Haskell. Where ever possible, I try to leverage the benefits of Haskellâs strong type system. Defining keybindings with a strong type system ensures that I cannot go very wrong with it. Using stack for building my configuration allows me to port the entire configuration easily to other systems, which are my various virtual machines. I have split configuration in various modules.&lt;/p&gt;
    &lt;code&gt;src
âââ Keybindings.hs
âââ Layout.hs
âââ Plugins
âÂ Â  âââ Bluetooth.hs
âÂ Â  âââ Pomodoro.hs
âÂ Â  âââ Soundtrack.hs
âââ Preferences.hs
âââ Theme
âÂ Â  âââ Dmenu.hs
âÂ Â  âââ Font.hs
âÂ Â  âââ Theme.hs
âÂ Â  âââ Xresources.hs
âââ Workspaces.hs
âââ xmobar.hs
âââ xmonad.hs

3 directories, 13 files&lt;/code&gt;
    &lt;p&gt;If you want to poke around the config according to your needs, go through Preferences.hs. It contains lots of variables which can be customized like terminal emulator, browser, scratchpads, window gap size etc. It also contains a list of applications which you would like to start automatically at boot.&lt;/p&gt;
    &lt;p&gt;Overall, the modularization has turned out to be pretty in terms of categorizing things. I tried writing a few xmobar plugins for my own needs. The guide for writing them was straightforward to begin with. I also wrote my entire xmobar configuration in Haskell itself, keeping this executable in the same project. In the end, the project itself became a one-shot way for an entire desktop environment which I can easily clone, compile and install on any system.&lt;/p&gt;
    &lt;head rend="h1"&gt;1. Setup&lt;/head&gt;
    &lt;p&gt;I will go briefly over the stack-based setup. The only thing needed is to have a &lt;code&gt;build&lt;/code&gt; script at the root of your xmonad project. Everything else is simply a
normal stack project with modules and a few executables. I have 2 executables in
my project: xmonad and xmobar.&lt;/p&gt;
    &lt;p&gt;A detailed description and example build files can be found here. My build script is simple enough.&lt;/p&gt;
    &lt;code&gt;#!/bin/sh

SRC_DIR=$HOME/.config/xmonad
WM=xmonad

unset STACK_YAML
FAIL=0

cd $SRC_DIR
stack install 2&amp;gt;.log || FAIL=1

ln -f -T $(stack exec -- which $WM) $1 2&amp;gt;.log || FAIL=2&lt;/code&gt;
    &lt;head rend="h1"&gt;2. Installation&lt;/head&gt;
    &lt;p&gt;Stack is a package manager for Haskell projects and it will be used to compile the package. Install stack either via GHCup or your distributionâs package manager.&lt;/p&gt;
    &lt;code&gt;mkdir -p $HOME/.config/xmonad
git clone --branch release https://github.com/weirdsmiley/xmonad $HOME/.config/xmonad/
cd $HOME/.config/xmonad
./install.sh&lt;/code&gt;
    &lt;p&gt;The installation script will install a few fonts and other tools which are default for this setup. It will also write &lt;code&gt;.xinitrc&lt;/code&gt; and &lt;code&gt;.Xresources&lt;/code&gt; files.&lt;/p&gt;
    &lt;p&gt;After the installation is complete, and you are logged into xmonad, pressing &lt;code&gt;alt+shift+/&lt;/code&gt; or &lt;code&gt;alt+?&lt;/code&gt; will open up a dialog box containing all available
keybindings.&lt;/p&gt;
    &lt;head rend="h1"&gt;3. Diving in&lt;/head&gt;
    &lt;head rend="h2"&gt;3.1. Layouts and per-workspace layouts&lt;/head&gt;
    &lt;p&gt;XMonad provides a very easy way to describe various layouts that workspaces can follow. I found it useful to constrain only a few layouts on each workspace. I used PerWorkspace for this. This allows me to only switch between specified set of layouts. So for example, my workspace 2 is my writing workspace, in which I have 3 applications. A browser, a pdf reader and a terminal with a tmux session attached to it. This can simply be arranged as a three column layout. But sometimes certain pdfs may have smaller font size which can be tough to read in a column. If I zoom in the pdf it spills sideways, and I have to use arrow keys or h,l to move left and right.&lt;/p&gt;
    &lt;p&gt;To tackle this, I have another layout with added magnification on top of the three column layout. It magnifies the focused window by a certain limit. And having only these two layouts in my layout set helps me in easily cycling between layouts. I donât have to skip through 4 different layouts which I would never use in this workspace.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.2. Topbar modification&lt;/head&gt;
    &lt;p&gt;By default, XMonad adds a border to the tiled window which is in focus. I took this idea from here. This adds a title bar with formatted colors. This looks nicer that having a border surrounding the window. The focused window is colored blue while unfocused is colored black. Also, having the title names in topbar looks nice, and in a way removes the need of using XMonadLogâs application names in xmobar itself.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.3. Type safety in keybindings&lt;/head&gt;
    &lt;p&gt;This is something which I truly adore about XMonad and writing its configuration in Haskell. I can write my keybindings in a functional manner and leverage Haskellâs type system to ensure safety. Arranging keybindings in this way, seems more fruitful than having them represented via strings.&lt;/p&gt;
    &lt;code&gt;myKeys :: XConfig Layout -&amp;gt; M.Map (KeyMask, KeySym) (X ())
myKeys conf@XConfig {XMonad.modMask = modm} =
  M.fromList -- list of keybindings
    $ [
      -- Restart XMonad
      ( (modm, xK_q), safeSpawn "xmonad" ["--restart"])
      -- Toggle fullscreen
      , ((modm, xK_f), sendMessage $ Toggle NBFULL)
      -- Lock screen
      , ((modm, xK_l), unGrab *&amp;gt; safeSpawn "env" myLockscreen)
      ]&lt;/code&gt;
    &lt;p&gt;Each keybinding is comprised of two values of types: &lt;code&gt;KeyMask&lt;/code&gt; and &lt;code&gt;KeySym&lt;/code&gt;,
followed by an &lt;code&gt;X ()&lt;/code&gt; action. If you donât want to set a keymask simply pass a &lt;code&gt;0&lt;/code&gt; or &lt;code&gt;noModMask&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.4. Submap keybindings and makeChords&lt;/head&gt;
    &lt;p&gt;Using submaps in xmonad-contrib, I can write a utility function to easily generate a set of keybindings with an added description.&lt;/p&gt;
    &lt;code&gt;import XMonad.Actions.Submap
import qualified Data.Map as M

makeChords :: a -&amp;gt; [((KeyMask, KeySym), String, X ())] -&amp;gt; [(a, X ())]
makeChords majorKey subKeys =
  (majorKey, submap . M.fromList $ map ((k, _, a) -&amp;gt; (k, a)) subKeys)
    : [ ( majorKey
        , visualSubmap myVisualSubmapDef
            $ M.fromList
            $ map ((k, d, a) -&amp;gt; (k, (d, a))) subKeys)
      ]

soundChords modm =
  makeChords
    (modm, xK_a)
    [ ( (0, xK_a), "open alsamixer"
      , spawn $ myNamedTerminal "alsamixer" ++ " -e alsamixer")
    , ( (0, xK_m), "toggle music playing"
      , getRunningPlayer' &amp;gt;&amp;gt;= player -&amp;gt;
          spawn $ myMusicCtrl ++ " -p "" ++ player ++ "" play-pause")
    ]

myKeys conf@XConfig {XMonad.modMask = modm} =
  M.fromList $ [] ++ soundChords modm&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;makeChords&lt;/code&gt; adds two distinct sets of keybindings, one normal set and
another a visual set, which creates a dialog box when you press the main submap
key. In the example above, the &lt;code&gt;soundChords&lt;/code&gt; submap is enabled with &lt;code&gt;alt+a&lt;/code&gt;,
then you can see a dialog box containing two keybindings with their
descriptions. Pressing either &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;m&lt;/code&gt; will launch the first or the second
action. The documentation also contains an example which you can read to see the actual code that will be
appended to your myKeys.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.5. Xmobar configuration in Haskell&lt;/head&gt;
    &lt;p&gt;Writing the Xmobar configuration inside the same project really allows me to keep everything in one place. I create another executable alongside the xmonad executable, in my &lt;code&gt;package.yaml&lt;/code&gt;. And then xmonad launches xmobar in the
startup apps section.&lt;/p&gt;
    &lt;code&gt;executables:
  xmonad:
    main: xmonad.hs
    dependencies:
      - xmonad
      - xmonad-contrib
      - containers
  xmobar:
    main: xmobar.hs
    dependencies:
      - xmobar
    ghc-options: -rtsopts -threaded -with-rtsopts=-N&lt;/code&gt;
    &lt;p&gt;You may have noticed a small icon beside my layout icons on the left side of xmobar. The represent the current layout in a visual form. Try switching layouts with &lt;code&gt;alt+space&lt;/code&gt; and see the icons change.&lt;/p&gt;
    &lt;code&gt;myXmobarPP =
  def
    { ppLayout =
        case
          "Columns" -&amp;gt; "&amp;lt;icon=Columns.xpm/&amp;gt;"
          "MagnifiedColumns" -&amp;gt; "&amp;lt;icon=MagnifiedColumns.xpm/&amp;gt;"
          "Full" -&amp;gt; "&amp;lt;icon=Full.xpm/&amp;gt;"
          "Tall" -&amp;gt; "&amp;lt;icon=Tall.xpm/&amp;gt;"
          "ThreeCol" -&amp;gt; "&amp;lt;icon=MagnifiedColumns.xpm/&amp;gt;"
          "2-by-3 (left)" -&amp;gt; "&amp;lt;icon=TwoByThreeLeft.xpm/&amp;gt;"
          "2-by-3 (right)" -&amp;gt; "&amp;lt;icon=TwoByThreeRight.xpm/&amp;gt;"
          "2x3 LT" -&amp;gt; "&amp;lt;icon=TwoByThreeLeftWithTabs.xpm/&amp;gt;"
          "2x3 RT" -&amp;gt; "&amp;lt;icon=TwoByThreeRightWithTabs.xpm/&amp;gt;"
          "Tiled" -&amp;gt; "&amp;lt;icon=Tiled.xpm/&amp;gt;"
          _ -&amp;gt; "&amp;lt;icon=Unknown.xpm/&amp;gt;"
    }

main =
  xmonad
    . withEasySB (statusBarProp "xmobar" (pure myXmobarPP)) defToggleStrutsKey
    $ myConfig&lt;/code&gt;
    &lt;head rend="h2"&gt;3.6. Scratchpads in action&lt;/head&gt;
    &lt;p&gt;I am using 4 scratchpads in total. Each scratchpad is mapped to a keybinding.&lt;/p&gt;
    &lt;code&gt;  [
  -- Open Scratchpad
  ((modm, xK_Return), namedScratchpadAction myScratchpads "terminal")
  -- Open Kanboard session
  , ((modm, xK_x), namedScratchpadAction myScratchpads "Kanboard")
  -- Open CalibreWeb
  , ((modm, xK_z), namedScratchpadAction myScratchpads "CalibreWeb")
  -- Open Anki
  , ((modm, xK_m), namedScratchpadAction myScratchpads "Anki")
  ]

myScratchpads
 =
  [ NS "terminal" spawnTerm findTerm manageTerm
  , NS "Kanboard" spawnKanboard (className =? "Kanboard") doFullFloat
  , NS "Anki" spawnAnki (className =? "Anki") doFullFloat
  , NS "CalibreWeb" spawnCalibreWeb (className =? "CalibreWeb") doFullFloat
  ]
  ...&lt;/code&gt;
    &lt;p&gt;I realized that I donât really open new terminals that often because I use tmux (with tmux-resurrect and tmux-continuum). So I remapped &lt;code&gt;alt+enter&lt;/code&gt; with showing the terminal scratchpad, instead of the usual, open a new terminal.&lt;/p&gt;
    &lt;p&gt;I can open up the calibre-web instance with &lt;code&gt;alt+z&lt;/code&gt;, and immediately resume
whatever I was reading.&lt;/p&gt;
    &lt;p&gt;If you have any questions for me, head over to this discussion page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wssite.vercel.app/blog/moving-back-to-a-tiling-wm-xmonad"/><published>2025-11-14T17:04:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45928912</id><title>You misunderstand what it means to be poor</title><updated>2025-11-14T19:32:38.531493+00:00</updated><content>&lt;doc fingerprint="bf40ba5146f6accd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You misunderstand what it means to be poor&lt;/head&gt;
    &lt;p&gt;The more I speak about being poor, the more I realize how fundamentally other folks misunderstand what it means to be poor versus being broke. The advice folks will give comes from a good place. However, I would like to give some examples to help everyone understand most advice from non-poor folks isn’t helpful.&lt;/p&gt;
    &lt;p&gt;Everyone has experienced being broke. Being broke sucks. You are watching every dollar spent, finding wayys to trim or make things stretch until the next payday. The difference is when you are broke you have some money. You can afford to put gas in your car, but not enough to do that repair. Money is tight, but you can get the basics at the grocery store. You can’t afford to go to the movies, but will stay home and watch what’s new on Netflix. Being broke sucks. You are watching every dollar spent, finding ways to trim or make things stretch until the next payday.&lt;/p&gt;
    &lt;p&gt;When you are poor that next payday brings no relief. It is like an endless runner game. No matter how fast you run or how high you jump you can never see the finish line. No matter how tired you are the ground keeps moving. There is no room for errors as the punishment for mistakes is astronomical. When you hit an obstacle you don’t restart from the last checkpoint, you go back to the beginning.&lt;/p&gt;
    &lt;p&gt;There is this mindset from folks that poor people must not be smart. I mean, you’re smart and you’re not poor! The problem must be a skill issue! Learn the skills to do it yourself and you’ll be able to pull yourself up.&lt;/p&gt;
    &lt;p&gt;The other mindset is poor people are lazy. Quit complaining and do it yourself! Just get a better job! Get a second job! There’s money out there, you just have to go get it.&lt;/p&gt;
    &lt;p&gt;The last is these folks think they understand what it is like to be poor. Hey, I was a broke college student and I get being poor! I had a rough patch, it will pass.&lt;/p&gt;
    &lt;p&gt;Let’s start at the top.&lt;/p&gt;
    &lt;p&gt;I have a van that is falling apart. It needs a lot of work that we cannot afford to do. In the mindset that poor people are unskilled, it appears that I should watch some YouTube videos, get the parts, and do it myself. The misunderstanding is that being poor means you have tons and tons of skills. You have to fix everything yourself. There is never, I mean never, a time you can pay someone to fix it for you.&lt;/p&gt;
    &lt;p&gt;In this example folks think, “If the repair at the shop costs $1,000, but the parts cost $300, you can save a lot of money doing it yourself.” You are absolutely correct. Yet, I still need to be able to afford the $300 in parts.&lt;/p&gt;
    &lt;p&gt;Do you see the misunderstanding? I can’t make $300 appear out of thin air. I have the skills, I’ve had to fix all my cars myself. I’ve done complete engine rebuilds, I’ve replaced transmissions, I do all my own regular maintenance. The problem isn’t skills, its money. When you are broke, spending $300 instead of $1,000 sounds like a win because you can’t afford the $1,000. When you’re poor $300 might as well be $1,000 or $10,000, you will never afford it.&lt;/p&gt;
    &lt;p&gt;This is not a matter of time, either. I can’t put aside money each month and then get it. There is never money to put aside. I can’t put it on the credit card as I know I will never be able to pay it. I’ll just have this $300 debt looming over me, increasing with interest every month, mocking how much of a loser I am.&lt;/p&gt;
    &lt;p&gt;The second mindset: Being lazy.&lt;/p&gt;
    &lt;p&gt;How do I have the time to work multiple jobs when I’m doing all this extra work? How do I have the time when in my extra time I’m fixing cars, appliances, the roof, and cooking every meal from scratch?&lt;/p&gt;
    &lt;p&gt;Should I work a second job and never see my wife? My kids? Should I never have any personal time? Should my entire life revolve around money? Should I kill myself for capitalism?&lt;/p&gt;
    &lt;p&gt;Folks who say things like this have only ever experienced being broke. It is a temporary situation and a few months of extra income will solve the problem. Being poor is not missing $1,000 or $10,000 in the short term. It’s missing $40,000 a year, every year, forever. There is no short term relief. This isn’t a rough patch. It is The Pit in The Dark Knight Rises.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“There’s a reason why this prison is the worst hell on earth… Hope. Every man who has rotted here over the centuries has looked up to the light and imagined climbing to freedom. So easy… So simple… And like shipwrecked men turning to sea water from uncontrollable thirst, many have died trying. I learned here that there can be no true despair without hope.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, it is possible to escape. Hell, two people have done it! Why can’t you do it! But you are completely ignoring how many people have fallen to their death trying.&lt;/p&gt;
    &lt;p&gt;All of the general guidance to escape being poor is actually advice for getting through being broke.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cancel Netflix&lt;/item&gt;
      &lt;item&gt;Make food at home&lt;/item&gt;
      &lt;item&gt;Stop going to Starbucks&lt;/item&gt;
      &lt;item&gt;Fix it yourself&lt;/item&gt;
      &lt;item&gt;Don’t upgrade your phone&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are all things that will help you temporarily. It will help you get through a short period of being broke. Or it will help you get your spending under control. You have enough money, you just don’t spend it wisely.&lt;/p&gt;
    &lt;p&gt;Being poor is you already did all those things. You cancelled all your streaming services years ago. You make all your food from scratch all the time. You never go to fucking Starbucks. You fix everything yourself. You already stretch everything to the limit. That is how you have to live every day of your life, for eternity, with no relief in sight.&lt;/p&gt;
    &lt;p&gt;Last example and is pertinent to our times in the US. A lot of poor folks are having to stand in line for hours and hours to get food at a food bank due to goverment ineptitude. The advice to simply cook at home doesn’t fix that there isn’t any food at home.&lt;/p&gt;
    &lt;p&gt;Do you honestly think people standing in line at a food bank could fix their situation if they stopped getting DoorDash? Going to Starbucks? Fuck off. They weren’t doing that already.&lt;/p&gt;
    &lt;p&gt;How are they to get another job or put in extra hours if they have to stand in line for 3 hours to get food? Should they go without food until they get that job and the paycheck?&lt;/p&gt;
    &lt;p&gt;You need to step aside and think about the differences between being broke and being poor.&lt;/p&gt;
    &lt;p&gt;- - - - -&lt;/p&gt;
    &lt;p&gt;Thank you for reading! If you would like to comment on this post you can start a conversation on the Fediverse. Message me on Mastodon at @cinimodev@masto.ctms.me. Or, you may email me at blog.discourse904@8alias.com. This is an intentionally masked email address that will be forwarded to the correct inbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.ctms.me/posts/2025-11-14-being-poor-or-being-broke/"/><published>2025-11-14T17:08:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45929052</id><title>Germany to Ban Huawei from Future 6G Network in Sovereignty Push</title><updated>2025-11-14T19:32:38.409367+00:00</updated><content/><link href="https://www.bloomberg.com/news/articles/2025-11-13/germany-to-ban-huawei-from-future-6g-network-in-sovereignty-push"/><published>2025-11-14T17:19:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45929247</id><title>Meeting notes between Forgejo and the Dutch government via Git commits</title><updated>2025-11-14T19:32:37.704314+00:00</updated><content>&lt;doc fingerprint="5f8f763c0c2747ac"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making sure you're not a bot!&lt;/head&gt;
    &lt;p&gt;Loading...&lt;/p&gt;
    &lt;head&gt;Why am I seeing this?&lt;/head&gt;
    &lt;p&gt;You are seeing this because the administrator of this website has set up Anubis to protect the server against the scourge of AI companies aggressively scraping websites. This can and does cause downtime for the websites, which makes their resources inaccessible for everyone.&lt;/p&gt;
    &lt;p&gt;Anubis is a compromise. Anubis uses a Proof-of-Work scheme in the vein of Hashcash, a proposed proof-of-work scheme for reducing email spam. The idea is that at individual scales the additional load is ignorable, but at mass scraper levels it adds up and makes scraping much more expensive.&lt;/p&gt;
    &lt;p&gt;Ultimately, this is a hack whose real purpose is to give a "good enough" placeholder solution so that more time can be spent on fingerprinting and identifying headless browsers (EG: via how they do font rendering) so that the challenge proof of work page doesn't need to be presented to users that are much more likely to be legitimate.&lt;/p&gt;
    &lt;p&gt;Please note that Anubis requires the use of modern JavaScript features that plugins like JShelter will disable. Please disable JShelter or other such plugins for this domain.&lt;/p&gt;
    &lt;p&gt;This website is running Anubis version &lt;code&gt;1.21.0&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://codeberg.org/forgejo/sustainability/pulls/137/files"/><published>2025-11-14T17:35:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45929358</id><title>Bitchat for Gaza – messaging without internet</title><updated>2025-11-14T19:32:37.335455+00:00</updated><content>&lt;doc fingerprint="3c9acf3111f970c1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Bitchat for Gaza - messaging without internet&lt;/head&gt;
    &lt;p&gt;Bitchat is a new messaging app that allows users to chat securely with or without internet access. Download it today via the App Store or Google Play store to begin communicating safely, even when connectivity disappears.&lt;/p&gt;
    &lt;p&gt;Why Bitchat is needed&lt;/p&gt;
    &lt;p&gt;Palestinians are dependent on Israel for their access to electricity, telecoms, and internet routing. Israel has weaponized this dependence in Gaza by deliberately causing blackouts that have left Palestinians cut off from communicating with each other or with the outside world. The relentless bombing campaign has also destroyed or severely crippled any remaining communication infrastructure.&lt;/p&gt;
    &lt;p&gt;Even when Palestinians use regular communication methods, their conversations and messages can be monitored and recorded, leaving them exposed to surveillance and potential targeting.&lt;/p&gt;
    &lt;p&gt;The basic human right to communicate freely, and without interruption, has been denied to the Palestinian people.&lt;/p&gt;
    &lt;p&gt;The solution&lt;/p&gt;
    &lt;p&gt;Bitchat lets you keep messaging even when the internet or power is down. It connects phones directly through Bluetooth, and each phone helps pass messages along, allowing communication to stretch much farther than just your immediate area. Everything is fully encrypted so your conversations stay private.&lt;/p&gt;
    &lt;p&gt;When you do have internet or cell service, Bitchat can send your messages anywhere in the world using a network of relays. There is no central server that stores any of your data. You don’t need to create an account, share your phone number or email, or even have a SIM card to use it.&lt;/p&gt;
    &lt;p&gt;Staying connected when all else fails&lt;/p&gt;
    &lt;p&gt;Bitchat is an Israel-proof messaging alternative that continues to work even when traditional networks are shut down. The app also has “Geohash” channels that allows users to join location-based chats, so Palestinians can stay connected to their neighbors down the street or to the larger community in cities across the region.&lt;/p&gt;
    &lt;p&gt;This lets Palestinians check on the safety of loved ones, organize and coordinate within their communities, and share critical news and updates.&lt;/p&gt;
    &lt;p&gt;Validated by T4P&lt;/p&gt;
    &lt;p&gt;T4P has evaluated the app, testing it in various conditions, and looked at the technology and governance of the application. After this evaluation, T4P recognizes it as a secure and resilient communication tool for Palestinian communities when faced with internet disruptions or outages. In addition, Tech for Palestine community members are among BitChat’s top code contributors.&lt;/p&gt;
    &lt;p&gt;Bitchat has seen a surge in downloads in countries facing civil unrest like Nepal, Indonesia, Côte d'Ivoire, and most recently Madagascar. The Nepali government blocked access to all major social media platforms, forcing civilians to search for alternative methods of communication.&lt;/p&gt;
    &lt;p&gt;WhatsApp is known to expose private data, potentially to Israel – and these breaches have been used to target Palestinians. Communicating via WhatsApp or social media presents the risk of exposing private data, limiting free expression, and undermining user privacy. BitChat does not have the same vulnerabilities and does not allow Meta to help Israel surveil Palestinians.&lt;/p&gt;
    &lt;p&gt;Get started&lt;/p&gt;
    &lt;p&gt;You can start using Bitchat easily, without even creating an account. To start, download the app from the App Store or Google Play store.&lt;/p&gt;
    &lt;p&gt;Once installed, the first thing you should do is change the default @anon username at the top. Click on it to change.&lt;/p&gt;
    &lt;p&gt;The blue #mesh channel in the top right corner will indicate that you are active on your local bluetooth network. Next to it you will see an icon with the number of users connected within your network. Click on the icon and begin private conversations with users from the list.&lt;/p&gt;
    &lt;p&gt;We recommend confirming your friends’ and family members’ usernames in person when possible. This helps make sure you’re talking to the right people and avoids confusion or impersonation. Once you’ve confirmed someone’s identity, you can start messaging them privately. You can also “favorite” them so they’re easy to find later.&lt;/p&gt;
    &lt;p&gt;Begin messaging by using the “type a message…” box. Type in a forward slash / to open the menu for additional commands and options.&lt;/p&gt;
    &lt;p&gt;Locations:&lt;/p&gt;
    &lt;p&gt;If you click on the blue #mesh channel on the top right it will open the various location channels available.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;#mesh: The mesh channel is your local bluetooth network that extends as far as the number of connected devices using Bitchat. So the more users with the ability to relay over distance, the larger the network. This is the channel that will allow you to communicate when all other networks are down.&lt;/item&gt;
      &lt;item&gt;Location channels: You will see default channel names for your block, neighborhood, city, province, and region. These work best when connected to the internet.&lt;/item&gt;
      &lt;item&gt;#Geohash: the geohash channel is a custom channel that you can start to connect with your immediate family or local groups. Type in a name for your channel and click teleport. Users within your network can then join it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Helpful tips:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It is encouraged to clear your messages with the command “/c” on a regular basis. This is good practice in the scenario where your phone is confiscated. Messages are only accessible on device as Bitchat has no central servers. If you delete the messages, they aren’t accessible anywhere.&lt;/item&gt;
      &lt;item&gt;Gaza Online provides renewable eSIMs to restore internet access across Gaza, helping people stay connected and access essential services. Paired with Bitchat, it can help communication continue even when networks are down.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Download Bitchat today and see additional tools that Tech for Palestine has been working on.&lt;/p&gt;
    &lt;p&gt;Stay connected, stay safe.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://updates.techforpalestine.org/bitchat-for-gaza-messaging-without-internet/"/><published>2025-11-14T17:43:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45929511</id><title>Not even a month passed and Chat Control is back in the EU</title><updated>2025-11-14T19:32:37.106841+00:00</updated><content/><link href="https://reclaimthenet.org/the-disguised-return-of-the-eus-private-message-scanning-plot"/><published>2025-11-14T17:54:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45929888</id><title>Show HN: Dumbass Business Ideas</title><updated>2025-11-14T19:32:37.014461+00:00</updated><content/><link href="https://dumbassideas.com"/><published>2025-11-14T18:18:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45929921</id><title>We Uncovered a Race Condition in Aurora RDS</title><updated>2025-11-14T19:32:36.876001+00:00</updated><content>&lt;doc fingerprint="755b917fcdb65da0"&gt;
  &lt;main&gt;
    &lt;p&gt;Much of the developer world is familiar with the AWS outage in &lt;code&gt;us-east-1&lt;/code&gt; that occurred on October 20th due to a race condition bug inside a DNS management service. The backlog of events we needed to process from that outage on the 20th stretched our system to the limits, and so we decided to increase our headroom for event handling throughput. When we attempted that infrastructure upgrade on October 23rd, we ran into yet another race condition bug in Aurora RDS. This is the story of how we figured out it was an AWS bug (later confirmed by AWS) and what we learned.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;The Hightouch Events product enables organizations to gather and centralize user behavioral data such as page views, clicks, and purchases. Customers can setup syncs to load events into a cloud data warehouse for analytics or stream them directly to marketing, operational, and analytics tools to support real-time personalization use cases.&lt;/p&gt;
    &lt;p&gt;Here is the portion of Hightouch’s architecture dedicated to our events system:&lt;/p&gt;
    &lt;p&gt;Hightouch events system architecture&lt;/p&gt;
    &lt;p&gt;Our system scales on three levers: Kubernetes clusters that contain event collectors and batch workers, Kafka for event processing, and Postgres as our virtual queue metadata store.&lt;/p&gt;
    &lt;p&gt;When our pagers went off during the AWS outage on the 20th, we observed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Services were unable to connect to Kafka brokers managed by AWS MSK.&lt;/item&gt;
      &lt;item&gt;Services struggled to autoscale because we couldn’t provision new EC2 nodes.&lt;/item&gt;
      &lt;item&gt;Customer functions for realtime data transformation were unavailable due to AWS STS errors, which caused our retry queues to balloon in size.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Kafka’s durability meant that no events were dropped once they were accepted by the collectors, but there was a massive backlog to process. Syncs with consistently high traffic or with enrichments that needed to call slower 3rd party services took longer to catch up and were testing the limits of our (small) Postgres instance’s ability to act as a queue for the batch metadata.&lt;/p&gt;
    &lt;p&gt;As an aside, at Hightouch, we start with Postgres where we can. Postgres queues serve our non-events architecture well at ~1M syncs/day and for events scaled to 500K events per second at ~1s end-to-end latency on a small Aurora instance.&lt;/p&gt;
    &lt;p&gt;After observing the events on the 20th, We wanted to upsize the DB to give us more headroom. Given that Aurora supports fast failovers for scaling up instances, we decided to proceed with an upgrade on Oct 23rd without a scheduled maintenance window.&lt;/p&gt;
    &lt;head rend="h3"&gt;AWS Aurora RDS&lt;/head&gt;
    &lt;p&gt;The central datastore for real-time streaming and warehouse delivery of customer events uses Amazon Aurora PostgreSQL.&lt;/p&gt;
    &lt;p&gt;Aurora's architecture differs from traditional PostgreSQL in a crucial way: it separates compute from storage. An Aurora cluster consists of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One primary writer instance that handles all write operations&lt;/item&gt;
      &lt;item&gt;Multiple read replica instances that handle read-only queries&lt;/item&gt;
      &lt;item&gt;A shared storage layer that all instances access, automatically replicated across multiple availability zones&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This architecture enables fast failovers and efficient read scaling, but as we'd discover, it also introduces unique failure modes.&lt;/p&gt;
    &lt;p&gt;A failover is the process of promoting a read replica to become the new primary writer - typically done automatically when the primary fails, or manually triggered for maintenance operations like ours. When you trigger a failover in the AWS console:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Aurora designates a read replica as the new primary&lt;/item&gt;
      &lt;item&gt;The storage layer grants write privileges to the new primary&lt;/item&gt;
      &lt;item&gt;The cluster endpoint points to the new writer&lt;/item&gt;
      &lt;item&gt;The old primary becomes a read replica (if it's still healthy)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The diagram below explains how Hightouch Events uses Aurora.&lt;/p&gt;
    &lt;p&gt;How Hightouch Events uses Aurora&lt;/p&gt;
    &lt;head rend="h2"&gt;The Plan&lt;/head&gt;
    &lt;p&gt;This was our upgrade plan:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Add another read replica (instance #3) to maintain read capacity during the upgrade.&lt;/item&gt;
      &lt;item&gt;Upgrade the existing reader (instance #2) to the target size and give it the highest failover priority.&lt;/item&gt;
      &lt;item&gt;Trigger a failover to promote instance #2 as the new writer (expected downtime less than 15s, handled gracefully by our backend).&lt;/item&gt;
      &lt;item&gt;Upgrade the old writer (instance #1) to match the size and make it a reader.&lt;/item&gt;
      &lt;item&gt;Remove the temporary extra reader (instance #3).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The AWS docs supported this approach and we had already tested the process successfully in a staging environment while performing a load test, so we were confident in the correctness of the procedure.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Upgrade Attempt&lt;/head&gt;
    &lt;p&gt;At 16:39 EDT on October 23, 2025, we triggered the failover to the newly-upgraded instance #2. The AWS Console showed the typical progression: parameter adjustments, instance restarts, the usual status updates.&lt;/p&gt;
    &lt;p&gt;Then the page refreshed. Instance #1 - the original writer was still the primary. The failover had reversed itself.&lt;/p&gt;
    &lt;p&gt;According to AWS everything was healthy. The cluster appeared healthy across the board. But our backend services couldn't execute write queries. Restarting the services cleared the errors and restored normal operation, but the upgrade had failed.&lt;/p&gt;
    &lt;p&gt;We tried again at 16:43. Same result: brief promotion followed by immediate reversal.&lt;/p&gt;
    &lt;p&gt;Two failed failovers in five minutes. Nothing else had changed - no code updates, no unusual queries, no traffic spikes. We had successfully tested this exact procedure in a staging environment under load earlier in the day. We checked our process to see if we had made any mistakes. We searched online to see if anyone else had encountered this issue but found nothing. Nothing obvious could explain why Aurora was refusing to complete the failover in this cluster. We were perplexed.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Investigation&lt;/head&gt;
    &lt;p&gt;We first checked database metrics for anything unusual. There was a spike in connection count, network traffic, and commit throughput to the read replica (instance #2) during the failover.&lt;/p&gt;
    &lt;p&gt;The higher commit throughput could have been due to replication or the execution of write queries. The other two metrics simply indicated a higher query volume.&lt;/p&gt;
    &lt;p&gt;We checked the read query traffic from the app (graph below), and found that there was no change during this period. This told us the extra traffic to instance #2 came from our backend services which are supposed to connect to the writer instance.&lt;/p&gt;
    &lt;p&gt;Query traffic from the Hightouch app&lt;/p&gt;
    &lt;p&gt;When we looked at the backend application logs, we found this error -&lt;code&gt;DatabaseError: cannot execute UPDATE in a read-only transaction&lt;/code&gt; in some pods.&lt;/p&gt;
    &lt;p&gt;Backend application logs&lt;/p&gt;
    &lt;p&gt;Our services do not connect directly to the writer instance, but rather to a cluster endpoint which points to the writer. This could mean one of 3 things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The pods did not get the signal that the writer had changed - i.e. the cluster did not terminate the connection.&lt;/item&gt;
      &lt;item&gt;The cluster endpoint incorrectly pointed to a reader instance.&lt;/item&gt;
      &lt;item&gt;The pod was connected to the writer, but the write operation was rejected at runtime.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We did not find any evidence supporting or disproving #1 in the application logs. We had a strong suspicion it was either #2 or #3. We downloaded the database logs to take a closer look and found something interesting. In both the promoted reader and the original writer, we found the same sequence of logs:&lt;/p&gt;
    &lt;code&gt;2025-10-23 20:38:58 UTC::@:[569]:LOG:  starting PostgreSQL...
...
...
...
LOG:  database system is ready to accept connections
LOG:  server process (PID 799) was terminated by signal 9: Killed
DETAIL:  Failed process was running: &amp;lt;write query from backend application&amp;gt;
LOG:  terminating any other active server processes
FATAL:  Can't handle storage runtime process crash
LOG:  database system is shut down
&lt;/code&gt;
    &lt;p&gt;This led us to a hypothesis:&lt;/p&gt;
    &lt;p&gt;During the failover window, Aurora briefly allowed both instances to process writes. The distributed storage layer rejected the concurrent write operations, causing both instances to crash.&lt;/p&gt;
    &lt;p&gt;We expect Aurora’s failover orchestration to do something like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Stop accepting new writes. Clients can expect connection errors until the failover completes.&lt;/item&gt;
      &lt;item&gt;Finish processing in-flight write requests.&lt;/item&gt;
      &lt;item&gt;Demote the writer and simultaneously promote the reader.&lt;/item&gt;
      &lt;item&gt;Accept new write requests on the new writer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There was clearly a race condition between steps 3 &amp;amp; 4.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing the Hypothesis&lt;/head&gt;
    &lt;p&gt;To validate the theory, we performed a controlled failover attempt. This time:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We scaled down all services that write to the database&lt;/item&gt;
      &lt;item&gt;We triggered the failover again&lt;/item&gt;
      &lt;item&gt;We monitored for storage runtime crashes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By eliminating concurrent writes, the failover completed successfully. This strongly reinforced the race-condition hypothesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;AWS Confirms the Root Cause&lt;/head&gt;
    &lt;p&gt;We escalated the findings and log patterns to AWS. After an internal review, AWS confirmed that:&lt;/p&gt;
    &lt;p&gt;The root cause was due to an internal signaling issue in the demotion process of the old writer, resulting in the writer being unchanged after the failover.&lt;/p&gt;
    &lt;p&gt;They also confirmed that there was nothing unique about our configuration or usage that would trigger the bug. The conditions that caused it were not under our control.&lt;/p&gt;
    &lt;p&gt;AWS has indicated a fix is on their roadmap, but as of now, the recommended mitigation aligns with our solution: use Aurora’s Failover feature on an as-needed basis and ensure that no writes are executed against the DB during the failover.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final State&lt;/head&gt;
    &lt;p&gt;With the race condition understood and mitigated, we:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Successfully upsized the cluster in &lt;code&gt;us-east-1&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Updated our internal playbooks to pause writers before an intentional failover&lt;/item&gt;
      &lt;item&gt;Added monitoring to detect any unexpected writer role advertisement flips&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Takeaways&lt;/head&gt;
    &lt;p&gt;The following principles were reinforced during this experience:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Prepare for the worst in any migration - you could end up in your desired end state, beginning state, or an in-between state - even for services you trust. Ensuring you’re ready to redirect traffic and handle brief outages in dependencies will minimize downtime.&lt;/item&gt;
      &lt;item&gt;The importance of good observability cannot be emphasized enough. The “brief writer advertisement” was only detectable because we were monitoring queries to each instance in Datadog and had access to database logs in RDS.&lt;/item&gt;
      &lt;item&gt;For large scale distributed systems, isolating the impact any single component can have on the system can help both uptime and maintenance. It helps a lot if the design allows for such events without completely shutting down the system.&lt;/item&gt;
      &lt;item&gt;Test setups are not always representative of production environments. Even though we practiced the upgrade process during a load test in a staging region, we could not reproduce the exact conditions that caused the race condition in Aurora. AWS confirmed that there was nothing specific about our traffic pattern that would trigger it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If challenges like this investigation sound interesting, we encourage you to check out our careers page&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hightouch.com/blog/uncovering-a-race-condition-in-aurora-rds"/><published>2025-11-14T18:20:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45930151</id><title>AI World Clocks</title><updated>2025-11-14T19:32:36.702849+00:00</updated><content>&lt;doc fingerprint="6702fe84490aee0"&gt;
  &lt;main&gt;
    &lt;div&gt;×&lt;head rend="h2"&gt;About AI World Clocks&lt;/head&gt;&lt;p&gt;Every minute, a new clock is displayed that has been generated by nine different AI models.&lt;/p&gt;&lt;p&gt;Each model is allowed 2000 tokens to generate its clock. Here is its prompt:&lt;/p&gt;&lt;code&gt;Create HTML/CSS of an analog clock showing ${time}. Include numbers (or numerals) if you wish, and have a CSS animated second hand. Make it responsive and use a white background. Return ONLY the HTML/CSS code with no markdown formatting.&lt;/code&gt;
            &lt;p&gt;Created by Brian Moore. You can also follow him on Instagram. Idea inspired by Matthew Rayfield.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://clocks.brianmoore.com/"/><published>2025-11-14T18:35:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45930284</id><title>Minisforum Stuffs Entire Arm Homelab in the MS-R1</title><updated>2025-11-14T19:32:36.589945+00:00</updated><content>&lt;doc fingerprint="37d17957198405e9"&gt;
  &lt;main&gt;
    &lt;p&gt;The Minisforum MS-R1 uses the same Cix CD8180 Arm SoC as the Orion O6 I reviewed earlier this year. But everything else about this thing is different.&lt;/p&gt;
    &lt;p&gt;What this thing should be, is a box that runs Linux and can compete with at least an Apple M1 Mac mini, or a mid-range Mini PC. But what we got... is something different.&lt;/p&gt;
    &lt;head rend="h2"&gt;Video&lt;/head&gt;
    &lt;p&gt;Hate reading? I also published a video on the MS-R1 on my YouTube channel. Watch it here, or scroll on past.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware overview&lt;/head&gt;
    &lt;p&gt;Let's get started with the hardware. At first glance, it looks great!&lt;/p&gt;
    &lt;p&gt;You have a 12 core Arm CPU with a Mali G720 iGPU. There's a full-size PCIe slot, NVMe storage, WiFi 6E, and a ton of ports on the front and back.&lt;/p&gt;
    &lt;p&gt;You have a grand total of 9 USB ports, with 2 of them Type C with DisplayPort 1.4.&lt;/p&gt;
    &lt;p&gt;There's HDMI, dual 10 Gbps NICs (Realtek RTL8127), and even an old fashioned audio combo jack, so you can plug in a headset.&lt;/p&gt;
    &lt;p&gt;It looks great on my desk, it's quiet, it uses a 19V 180W power adapter (which is a bit chunky, but par for the course with Minisforum PCs), and overall, the hardware is some of the nicest of any Arm system, outside Apple's walled garden.&lt;/p&gt;
    &lt;p&gt;And the way you get inside is simple: press a little button and slide the chassis out of the shell (see photo above).&lt;/p&gt;
    &lt;p&gt;It came with adapters for a U.2 drive (see above) or a second M.2 drive, which replace the built-in Mediatek WiFi card.&lt;/p&gt;
    &lt;p&gt;And yes, the unit I'm testing is a review unit sent by Minisforum. They did not pay me to test the machine, write this blog post, nor did they have any input into its contents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cix SoC - iGPU and a Big/Medium/Little Arm CPU&lt;/head&gt;
    &lt;p&gt;Now, let's dive into why this machine puzzles me, starting with the iGPU. Using Minisforum's default Debian 12 install, I could run &lt;code&gt;glmark2&lt;/code&gt;, and it performed well, scoring 6322, far above something like a Raspberry Pi 5 (which got 1935).&lt;/p&gt;
    &lt;p&gt;But Vulkan support was iffy. &lt;code&gt;vulkaninfo&lt;/code&gt; Segfaulted, and &lt;code&gt;vkmark&lt;/code&gt; wouldn't run at all.&lt;/p&gt;
    &lt;p&gt;But GravityMark did. And while the G720 won't bring home any awards, it's about on par with the Adreno 750 in Qualcomm's Snapdragon 8 cx Gen 3.&lt;/p&gt;
    &lt;p&gt;That's the chip Microsoft used in their 'Project Volterra' 2023 Windows Arm Dev Kit.&lt;/p&gt;
    &lt;p&gt;And that's not the only similarity between the two.&lt;/p&gt;
    &lt;p&gt;Geekbench 6 scores were also pretty close, coming in at 1336 single core, and 6773 multicore.&lt;/p&gt;
    &lt;p&gt;That soundly beats SBCs like the Pi 5 or a Rockchip. But it's still well under Apple's four-year-old M1.&lt;/p&gt;
    &lt;p&gt;In other benchmarks, this thing is all over the place. I have two theories about that, which I'll get to.&lt;/p&gt;
    &lt;p&gt;But in real-world use, it does feel fast. At least, faster than any Arm SBC. You can actually watch 4K video on YouTube while you do other things, which is kind-of a novelty on anything that's not Qualcomm or Apple.&lt;/p&gt;
    &lt;p&gt;More testing revealed some oddities, though.&lt;/p&gt;
    &lt;p&gt;Consider my Top500 High Performance Linpack benchmark. This is a massive CPU stress test, great for testing memory access, too.&lt;/p&gt;
    &lt;p&gt;I played around with 4 cores, 8 cores, all 12 cores, and even limited the amount of RAM I was testing, because the results I was getting were confusing.&lt;/p&gt;
    &lt;p&gt;In the end, after some help from GitHub user @volyrique, we found the Cix P1 SoC is affected by the same BLIS issue other chips like the Nvidia GB10 'Superchip' and cloud chips using Neoverse N2 CPU cores run into: Poor DGEMM performance for armsve build on Neoverse N2.&lt;/p&gt;
    &lt;p&gt;We're diving a bit deep here, but with newer SVE technology (vs. Arm's more traditional NEON 128 bit SIMD), chips can use arbitrary vector lengths. The BLIS library optimizes newer chips with an &lt;code&gt;armsve&lt;/code&gt; configuration, which assumes 256+ bit vector lengths, and is not optimized at all for 128-bit vector lengths (used by the Cix P1 in the Orion O6 and Minisforum MS-R1).&lt;/p&gt;
    &lt;p&gt;All that out of the way, I have deleted the section of the video embedded above covering HPL entirely, and have updated my benchmark graphs below:&lt;/p&gt;
    &lt;p&gt;The MS-R1 with it's 64 GB of RAM edged out my Orion O6 (I have the 16 GB model...), though it is less than half as performant as the M4 Mac mini.&lt;/p&gt;
    &lt;p&gt;Not a bad showing, overall, and after adjusting the HPL configuration to account for the instruction set mismatch, I was able to get a score almost triple that of the fastest small Arm SBCs'.&lt;/p&gt;
    &lt;p&gt;Energy efficiency is a step down, though—it's not the worst, and certainly, under load, it is better than most Intel/AMD systems:&lt;/p&gt;
    &lt;p&gt;But the efficiency story is much worse considering the idle power draw:&lt;/p&gt;
    &lt;p&gt;Unless you are running large workloads constantly, this machine will end up using far more energy than other Arm solutions (especially Apple's M-series Macs), due to the high idle power.&lt;/p&gt;
    &lt;p&gt;But why is it so high? This is a graph of core to core memory latency, showing how fast it is for different CPU cores to share memory on the system. Honestly, this isn't horrible, especially when I pair it with raw memory access speed:&lt;/p&gt;
    &lt;p&gt;The MS-R1's RAM is pretty fast (though notably slower than the O6, which directly impacts performance with tasks like AI inference).&lt;/p&gt;
    &lt;p&gt;But I think the strange CPU core layout is causing power problems; Radxa and Minisforum both told me Cix is working on power draw, and enabling features like ASPM.&lt;/p&gt;
    &lt;p&gt;It seems like for stability, and to keep memory access working core to core, with the big.medium.little CPU core layout, Cix wants to keep the chip powered up pretty high. 14 to 17 watts idle is beyond even modern Intel and AMD!&lt;/p&gt;
    &lt;p&gt;For networking, the onboard NICs provide a full 10 gigs, and the built-in WiFi 6E was good for a gigabit on my network.&lt;/p&gt;
    &lt;p&gt;And with 64 gigs of RAM, one thing this box could excel at compared to an SBC is local AI, even if it's just on the CPU.&lt;/p&gt;
    &lt;p&gt;I ran a bunch of different models that would fit in the memory, and here are those results:&lt;/p&gt;
    &lt;p&gt;This is one place where it actually underperforms the older Orion O6 with the same CPU, which is directly related to the slower RAM speeds.&lt;/p&gt;
    &lt;head rend="h2"&gt;Efficiency&lt;/head&gt;
    &lt;p&gt;The performance inconsistency is puzzling, but the power consumption is really what hurts the most—that's an area Arm is supposed to shine in. But it goes to show you, CPU core architecture and even process nodes aren't everything when it comes to effiency. Design matters.&lt;/p&gt;
    &lt;p&gt;Apple's M-series puts everything to shame, but even taking that out of the mix, it's not quite what I'd expect from 2025 Arm CPU design.&lt;/p&gt;
    &lt;p&gt;Despite all that, it's quiet and the fans keep it cool. The performance profile ramps up the fans to 100%, but that didn't make much difference in real-world performance except making it about 50 dBa from a foot away instead of 40 dBa in the normal profile.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dedicated GPU Upgrade&lt;/head&gt;
    &lt;p&gt;If you're thinking about loading up AI models, or even modest gaming, a dedicated GPU will get you a lot further than the iGPU.&lt;/p&gt;
    &lt;p&gt;Minisforum added ventilation holes across the entire top, so a modded GPU like the Abovetop RTX A2000, with 8 gigs of VRAM, will fit and get adequate cooling. Similar to older MS-** Minisforum workstations, this machine only fits half-height single-slot PCI Express cards, and ones that are not too long at that.&lt;/p&gt;
    &lt;p&gt;Installation is easy, though finicky due to the tight spaces. You unscrew and pull a small retention clip out, remove the slot cover, and fit the new card. It rests on a small foam spacer to isolate the card from the motherboard.&lt;/p&gt;
    &lt;p&gt;Booting the computer back up, I saw the card using &lt;code&gt;lspci&lt;/code&gt;, so Linux can see it. But I wasn't able to install the drivers on the Debian 12 OS image shipped with the machine. I also tried an Intel Arc A310 ECO, a lower-specced and smaller single-slot card, but that wasn't even recognized when I ran &lt;code&gt;lspci&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For the Intel card, it's probably just a signaling issue, though—I'm not going to hold it against the MS-R1 since I've had issues with the A310 ECO on other systems.&lt;/p&gt;
    &lt;head rend="h2"&gt;BIOS detour&lt;/head&gt;
    &lt;p&gt;I'll get back to A2000 testing, but these experiments took me on a detour into the BIOS.&lt;/p&gt;
    &lt;p&gt;There are settings for USB, RAM, power on behavior, and a lot more. It's pretty complete, but I still see a lot of things labeled 'Beta', so keep that in mind if you buy one of these things.&lt;/p&gt;
    &lt;p&gt;One thing I tested that didn't work is the AC Power Loss setting. You're supposed to be able to tell it to turn on when power is restored—that's great for something like a homelab. But the BIOS setting didn't do anything. I remembered seeing a hardware switch on the board, though, and sure enough! That's how you actually control the AC power loss setting.&lt;/p&gt;
    &lt;head rend="h2"&gt;Switching to Ubuntu&lt;/head&gt;
    &lt;p&gt;Getting back to the A2000, I decided to switch gears and try Ubuntu from an Arm ISO install via USB flash drive. The process was easy enough (I didn't have to change anything in the BIOS), and Ubuntu installed without a hitch.&lt;/p&gt;
    &lt;p&gt;The A2000's drivers were automatically installed, and I was off to the races.&lt;/p&gt;
    &lt;p&gt;AI is obviously faster on the GPU (total system power draw was around 94W):&lt;/p&gt;
    &lt;p&gt;And GravityMark, a good proxy for how games will run on a given GPU, ran fine too, increasing the score over the iGPU from 3,037 to 16,679.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Having a full PCI Express slot in here is nice. Coupled with the extra included U.2 and M.2 adapters, it's clear Minisforum thinks of this thing as a good homelab box. They even published guides for installing Proxmox (a community maintained version) and Jellyfin with iGPU acceleration. Considering expansion-options-per-cubic meter, this has all other Arm machines beat, including the Mac mini.&lt;/p&gt;
    &lt;p&gt;Honestly, this works fine as an Arm desktop, certainly better than any SBC. But Intel and AMD exist, and so does Apple, for that matter, and that makes this a bad value where it stands today, in the $500-600 range. Unless you're an Arm enthusiast, you should save some money and get a different mini PC—even one of Minisforum's other MS-series desktops. Or if you can afford $600 bucks, buy the best value Arm desktop on the market, the M4 Mac mini. Of course, that thing can't run bare metal Linux, so take that into account.&lt;/p&gt;
    &lt;p&gt;I like that it exists. And I like that Cix and Minisforum are trying to shake up the Arm desktop market a bit. But it's still half-baked:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Can performance and power issues be fixed in firmware?&lt;/item&gt;
      &lt;item&gt;Will they get all the drivers mainlined so all features work in every Linux distro?&lt;/item&gt;
      &lt;item&gt;Windows can run on here, but will Nvidia ever release GPU drivers for Windows on Arm?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I'm not sure. But I will try gaming in Linux on here soon, and some other tests. So make sure you follow this blog's RSS feed or subscribe over on YouTube, if you want to follow along!&lt;/p&gt;
    &lt;p&gt;You can buy the Minisforum MS-R1 from Minisforum's online store, starting around $500 at the time of this writing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Comments&lt;/head&gt;
    &lt;p&gt;Just wanted to note after some discussion over in the sbc-reviews issue for the MS-R1, I'm re-running my HPL top500 benchmark with the correct optimizations for the Cix CPU and will update the HPL benchmark and efficiency graphs in the post.&lt;/p&gt;
    &lt;p&gt;Minis Forum is advertising Proxmox support for virtualization. All of the builds I have seen previously for this are unsupported or custom. It appears there is a build based on Debian ARM64? Does it work? Is it viable? I see people running routing software (like OpenWRT) on these VM's.&lt;/p&gt;
    &lt;p&gt;Their PVE install guide for the MS-R1 seems to use the pxvirt fork of Proxmox targeting Arm and LoongArch architectures. It's not an officially supported way to get Proxmox going, but it does work.&lt;/p&gt;
    &lt;p&gt;Do note that those "Abovetop" cards are not modified A2000s they are actually mobile A2000s. Desktop A2000s have either 6GB or 12GB of VRAM and the dual slot cooler that can infact be modified by nerdwares all copper single slot cooler. The Desktop cards also have 4 mini Displayports and not the more standard 1 DP 1 HDMI that you would see on gaming cards. There is also the terrible AMD RX 6400 that would fit in these but no-one should ever use a 4GB GPU in 2025.&lt;/p&gt;
    &lt;p&gt;Minisforum proudly advertises ECC support for this. Have you done any testing on that?&lt;lb/&gt; It's going to reduce performance, Minisforum says it's 1/8, so the best case is 12.5% reduction in memory bound workloads and none in compute bound workloads, though it's probably much worse.&lt;lb/&gt; Anandtech (RIP) tested Intel's in-band ECC, which is 1/32, and found that it reduced performance by 0% to 10% in CPU tests, which isn't that bad, but in iGPU tests performance was reduced by 20% to 30%, which is pretty awful. Also the energy efficiency was reduced by similar amounts.&lt;lb/&gt; (Couldn't add a link, so just search for "Anandtech in-band ECC" and you should find the article)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jeffgeerling.com/blog/2025/minisforum-stuffs-entire-arm-homelab-ms-r1"/><published>2025-11-14T18:42:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45930598</id><title>Structured Outputs on the Claude Developer Platform (API)</title><updated>2025-11-14T19:32:36.233921+00:00</updated><content>&lt;doc fingerprint="ff899f0ed4e6d2f6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Structured outputs on the Claude Developer Platform&lt;/head&gt;
    &lt;p&gt;Guarantee responses match your JSON schemas and tool definitions with structured outputs.&lt;/p&gt;
    &lt;p&gt;Guarantee responses match your JSON schemas and tool definitions with structured outputs.&lt;/p&gt;
    &lt;p&gt;The Claude Developer Platform now supports structured outputs for Claude Sonnet 4.5 and Opus 4.1. Available in public beta, this feature ensures API responses always match your specified JSON schemas or tool definitions.&lt;/p&gt;
    &lt;p&gt;With structured outputs, developers can eliminate schema-related parsing errors and failed tool calls by ensuring that Claude's responses conform to a defined schemaâwhether you're extracting data from images, orchestrating agents, or integrating with external APIs.&lt;/p&gt;
    &lt;p&gt;For developers building applications and agents in production, a single error in data formatting can cause cascading failures. Structured outputs solves this by guaranteeing your response matches the exact structure you define, without any impact to model performance. This makes Claude dependable for applications and agents where accuracy is critical, including:&lt;/p&gt;
    &lt;p&gt;Structured outputs can be used two ways: with JSON or tools. When used with JSON, you provide your schema definition in the API request. For tools, you define your tool specifications, and Claude's output conforms to those tool definitions automatically.&lt;/p&gt;
    &lt;p&gt;The end result is a reliable output, reduced retries, and a simplified codebase that no longer needs failover logic or complex error handling.&lt;/p&gt;
    &lt;p&gt;OpenRouter provides 4M+ developers access to all major AI models through a single, unified interface.&lt;/p&gt;
    &lt;p&gt;"Structured outputs have become a really valuable part of the agentic AI stack. Agents constantly ingest and produce structured data, so Anthropicâs structured outputs close a real gap for developers. Agent workflows run reliably, every time, and teams can focus on their customers rather than debugging tool calls,â said Chris Clark, COO, OpenRouter.&lt;/p&gt;
    &lt;p&gt;Structured outputs is now available in public beta for Sonnet 4.5 and Opus 4.1 on the Claude Developer Platform, with support for Haiku 4.5 coming soon. Explore our documentation for supported JSON schema types, implementation examples, and best practices.&lt;/p&gt;
    &lt;p&gt;Get the developer newsletter&lt;/p&gt;
    &lt;p&gt;Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.&lt;/p&gt;
    &lt;p&gt;Get the developer newsletter&lt;/p&gt;
    &lt;p&gt;Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.claude.com/blog/structured-outputs-on-the-claude-developer-platform"/><published>2025-11-14T19:04:23+00:00</published></entry></feed>