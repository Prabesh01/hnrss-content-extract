<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-03T13:09:13.900086+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46094606</id><title>Qwen3-VL can scan two-hour videos and pinpoint nearly every detail</title><updated>2025-12-03T13:09:21.302925+00:00</updated><content>&lt;doc fingerprint="2d5d4fc5093bce05"&gt;
  &lt;main&gt;
    &lt;p&gt;A few months after launching Qwen3-VL, Alibaba has released a detailed technical report on the open multimodal model. The data shows the system excels at image-based math tasks and can analyze hours of video footage.&lt;/p&gt;
    &lt;p&gt;The system handles massive data loads, processing two-hour videos or hundreds of document pages within a 256,000-token context window.&lt;/p&gt;
    &lt;p&gt;In "needle-in-a-haystack" tests, the flagship 235-billion-parameter model located individual frames in 30-minute videos with 100 percent accuracy. Even in two-hour videos containing roughly one million tokens, accuracy held at 99.5 percent. The test works by inserting a semantically important "needle" frame at random positions in long videos, which the system must then find and analyze.&lt;/p&gt;
    &lt;p&gt;In published benchmarks, the Qwen3-VL-235B-A22B model often beats Gemini 2.5 Pro, OpenAI GPT-5, and Claude Opus 4.1 - even when competitors use reasoning features or high thinking budgets. The model dominates visual math tasks, scoring 85.8 percent on MathVista compared to GPT-5's 81.3 percent. On MathVision, it leads with 74.6 percent, ahead of Gemini 2.5 Pro (73.3 percent) and GPT-5 (65.8 percent).&lt;/p&gt;
    &lt;p&gt;The model also shows range in specialized benchmarks. It scored 96.5 percent on the DocVQA document comprehension test and 875 points on OCRBench, supporting 39 languages - nearly four times as many as its predecessor.&lt;/p&gt;
    &lt;p&gt;Alibaba claims the system demonstrates new capabilities in GUI agent tasks. It achieved 61.8 percent accuracy on ScreenSpot Pro, which tests navigation in graphical user interfaces. On AndroidWorld, where the system must independently operate Android apps, Qwen3-VL-32B hit 63.7 percent.&lt;/p&gt;
    &lt;p&gt;The model handles complex, multi-page PDF documents as well. It scored 56.2 percent on MMLongBench-Doc for long document analysis. On the CharXiv benchmark for scientific charts, it reached 90.5 percent on description tasks and 66.2 percent on complex reasoning questions.&lt;/p&gt;
    &lt;p&gt;It is not a clean sweep, however. In the complex MMMU-Pro test, Qwen3-VL scored 69.3 percent, trailing GPT-5's 78.4 percent. Commercial competitors also generally lead in video QA benchmarks. The data suggests Qwen3-VL is a specialist in visual math and documents, but still lags in general reasoning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key technical advances for multimodal AI&lt;/head&gt;
    &lt;p&gt;The technical report outlines three main architectural upgrades. First, "interleaved MRoPE" replaces the previous position embedding method. Instead of grouping mathematical representations by dimension (time, horizontal, vertical), the new approach distributes them evenly across all available mathematical areas. This change aims to boost performance on long videos.&lt;/p&gt;
    &lt;p&gt;Second, DeepStack technology allows the model to access intermediate results from the vision encoder, not just the final output. This gives the system access to visual information at different levels of detail.&lt;/p&gt;
    &lt;p&gt;Third, a text-based timestamp system replaces the complex T-RoPE method found in Qwen2.5-VL. Instead of assigning a mathematical time position to every video frame, the system now inserts simple text markers like "&amp;lt;3.8 seconds&amp;gt;" directly into the input. This simplifies the process and improves the model's grasp of time-based video tasks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Training at scale with one trillion tokens&lt;/head&gt;
    &lt;p&gt;Alibaba trained the model in four phases on up to 10,000 GPUs. After learning to link images and text, the system underwent full multimodal training on about one trillion tokens. Data sources included web scrapes, 3 million PDFs from Common Crawl, and over 60 million STEM tasks.&lt;/p&gt;
    &lt;p&gt;In later phases, the team gradually expanded the context window from 8,000 to 32,000 and finally to 262,000 tokens. The "Thinking" variants received specific chain-of-thought training, allowing them to explicitly map out reasoning steps for better results on complex problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open weights under Apache 2.0&lt;/head&gt;
    &lt;p&gt;All Qwen3-VL models released since September are available under the Apache 2.0 license with open weights on Hugging Face. The lineup includes dense variants ranging from 2B to 32B parameters, as well as mixture-of-experts models: the 30B-A3B and the massive 235B-A22B.&lt;/p&gt;
    &lt;p&gt;While features like extracting frames from long videos aren't new - Google's Gemini 1.5 Pro handled this in early 2024 - Qwen3-VL offers competitive performance in an open package. With the previous Qwen2.5-VL already common in research, the new model is likely to drive further open-source development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://the-decoder.com/qwen3-vl-can-scan-two-hour-videos-and-pinpoint-nearly-every-detail/"/><published>2025-11-30T07:27:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46110395</id><title>All about automotive lidar</title><updated>2025-12-03T13:09:20.858873+00:00</updated><content>&lt;doc fingerprint="365a94130b60d70b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;All about automotive lidar&lt;/head&gt;
    &lt;p&gt;Here I'll provide a comprehensive overview of automotive lidar technology. Lidar is used for autonomous vehicles and robotics because it's a cool technology.&lt;/p&gt;
    &lt;head rend="h1"&gt;1 What lidar does&lt;/head&gt;
    &lt;p&gt;A lidar is a sensor which operates by bouncing light off surrounding surfaces. Lidars typically quantify:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;distance, by measuring how much time it takes for light to bounce back&lt;/item&gt;
      &lt;item&gt;bearing, by shining the light or pointing the detector in a particular direction&lt;/item&gt;
      &lt;item&gt;reflectivity, by measuring how much light has bounced back&lt;/item&gt;
      &lt;item&gt;speed, by measuring the Doppler shift in the reflected light.&lt;/item&gt;
      &lt;item&gt;ambient, by measuring the amount of light in the environment in a particular direction&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In general, we are most interested in distance and bearing. Surface reflectivity is also valuable, as it allows detection of road lines in the automotive case.&lt;/p&gt;
    &lt;p&gt;By measuring distance in many directions, an autonomous vehicle can perceive its environment. Each measurement corresponds to a discrete 3D point in space. Through a decade of steady research, engineers designed algorithms capable of leveraging this 3D point cloud to unlock spatial understanding. Obstacle avoidance and precise positioning are just two direct results of this technology.&lt;/p&gt;
    &lt;p&gt;Distance and bearing measurements can be converted into 3D Cartesian points. For example, given range and bearing , , the 3D point is:&lt;/p&gt;
    &lt;p&gt;In contrast, a camera only measures bearing and ambient light intensity. Each pixel of a photo is a measurement of how much light there is in that particular direction. But generally, a camera has much higher bearing resolution than a lidar.&lt;/p&gt;
    &lt;head rend="h1"&gt;2 Measuring distance&lt;/head&gt;
    &lt;p&gt;Measuring distance is also known as ranging. Basically, it just measures how close something is. There are in general two ways of doing this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Measuring the time somehow, exploiting the fact that light travels at a constant speed (the speed of light)&lt;/item&gt;
      &lt;item&gt;Parallax&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For measuring the time, there are again two ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Direct time of flight, where we directly measure the time&lt;/item&gt;
      &lt;item&gt;Modulated lidar, where we modulate some attribute of the outgoing light, e.g. amplitude, frequency, or polarization&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;2.1 Direct time of flight pulsed lidar&lt;/head&gt;
    &lt;p&gt;Direct detection pulsed lidar fires one or more laser pulses. Then, we simply measure the time to see the reflection from the pulse.&lt;/p&gt;
    &lt;p&gt;where is the speed of light ( m/s). The division by 2 is because the range is half of the round trip distance.&lt;/p&gt;
    &lt;p&gt;Imagine if we have a stopwatch that measures in, say, a nanosecond resolution. If we measure 1000 nanoseconds, then it means the round trip distance was 300 m, which means that the range is 150 m.&lt;/p&gt;
    &lt;p&gt;This involves measuring the time series data of how much light is seen at any point in time. Since electronics typically run at 1 GHz or so, the time series is discretized on the order of 1 ns, which corresponds to a range of 15 cm. To further improve the ranging accuracy, an interpolation filter is a standard technique in signal processing. Typically ranging accuracy at the centimeter level is possible.&lt;/p&gt;
    &lt;p&gt;After getting the time series data, the peaks in the series are found, and these correspond to the range.&lt;/p&gt;
    &lt;p&gt;Usually, it is better to have stronger, shorter pulses. Diode lasers can produce pulses on the order of a couple of nanoseconds, and fiber lasers can produce even shorter pulses with much higher peak energy.&lt;/p&gt;
    &lt;p&gt;In practice, the laser pulse has some finite duration and shape (rather than being an infinitely short impulse function), so the peak is found in the cross correlation of the outgoing pulseâs shape with the return data, rather than the raw time series data itself. It is possible to send a randomly shaped pulse (or sequence of pulses), and cross correlate the return data against that. This provides much greater resistance against noise, interference, and crosstalk, and is known as a matched filter.&lt;/p&gt;
    &lt;p&gt;We should note, however, that the shape of the return pulse could be distorted or âsmeared outâ. This can be due to, for example, hitting a very slanted surface. One strategy to overcome this is to try correlating it with a bunch of different pulse shapes. This technique may be called template matching, dictionary matching, matched filter bank, or model-based detection.&lt;/p&gt;
    &lt;head rend="h3"&gt;2.1.1 Photodiodes used in pulsed lidar&lt;/head&gt;
    &lt;p&gt;In order to get a time series of the amount of light per unit time at a super high rate, we need a really fast sensor that can operate at 1 GHz. Usually one of these two types of sensors is used:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Linear-mode avalanche photodiodes (APD)&lt;/item&gt;
      &lt;item&gt;Geiger-mode avalanche photodiodes, also known as single-photon avalanche photodiodes (SPAD)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Other types of sensors such as CCD sensors are not fast enough for this application.&lt;/p&gt;
    &lt;p&gt;A photodiode is a diode that also has the photoelectric effect.&lt;/p&gt;
    &lt;p&gt;A diode is like a one-way valve for electricity. Just like a one way valve for water, if you try to force things sufficiently in the opposite direction, it will break down, resulting in a huge gush of water. Likewise, if you apply a strong voltage in the reverse direction, itâs called a reverse bias, and a sufficiently strong voltage will cause a sudden spike in electrical current. This is called avalanche breakdown.&lt;/p&gt;
    &lt;p&gt;Meanwhile, some metals produce an electric current when shining light on it, in an effect known as the photoelectric effect.&lt;/p&gt;
    &lt;p&gt;Avalanche photodiodes have a reverse bias, meaning that a voltage is applied in the opposite direction of the one-way valve. If the reverse voltage exceeds a certain amount known as the breakdown voltage, it stops acting like a diode. Suddenly, a large current can flow through the device.&lt;/p&gt;
    &lt;p&gt;Linear-mode APDs have a reverse bias slightly below the breakdown voltage. Here, the current is linearly related to the voltage, but the gain is very high, so that even changing a small voltage results in a large change in the current. Hence, it is a very sensitive way of measuring light intensity.&lt;/p&gt;
    &lt;p&gt;Geiger- mode avalanche photodiodes (GMAPDs) or single-photon avalanche diodes (SPADs) have such a strong reverse bias that even getting hit by a single photon can make them break down, resulting in a large current spike. The output of a SPAD can be directly connected to a voltage discriminator so that the spike becomes a digital signal from logic 0 to 1.&lt;/p&gt;
    &lt;p&gt;In the above I-V diagram, we see the relationship between the voltage (V) and the current (I). The breakdown voltage is labelled. As you can see, where the linear-mode APD operates, the current is linearly proportional to the voltage. The Geiger-mode APD operates where the slope is effectively infinitely steep.&lt;/p&gt;
    &lt;quote&gt;Note on terminology: Typically the word avalanche photodiode (APD) refers to linear-mode APDs. Meanwhile, GMAPDs and SPADs operate in the same way but the term SPAD often refers to silicon devices sensitive to near infrared (850 nm to 940 nm) and GMAPD often refers to InGaAs devices sensitive to longer wavelengths (1064 nm to 1550 nm).&lt;/quote&gt;
    &lt;p&gt;SPADs have the following advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CMOS compatibility: Silicon SPADs can be made with the complementary metal-oxide-semiconductor (CMOS) process, the same way as computer CPUs and the such. Since they output digital signals, you can fabricate them on the same chip that is used to process the signals. Hence the whole detection pipeline can be made cheaply on a silicon application-specific integrated circuit (ASIC). In contrast, the output of an APD is an analog signal, so a high-speed analog-to-digital converter (ADC) is required. This is very expensive and introduces extra noise. Silicon SPADs also benefit from the immense scaling potentials of the CMOS process, allowing very large arrays to be fabricated at a very fine manufacturing node. Hence, SPADs can be used to make very high resolution, dense arrays, as opposed to APDs which are relatively large and expensive discrete components.&lt;/item&gt;
      &lt;item&gt;Higher gain: SPADs have a higher gain than linear mode APDs. In fact, the gain of a SPAD is essentially infinite, allowing it to detect even a single photon.&lt;/item&gt;
      &lt;item&gt;Lower temperature dependence: SPADs are less sensitive to temperature than APDs, for which different temperatures can change the sensitivity of the sensor and also affect the dark current.&lt;/item&gt;
      &lt;item&gt;Better timing jitter: SPADs output such a sharp spike that you can measure the timing very accurately and reliably.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Meanwhile, APDs have these advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;No dead time and quenching: A linear mode APD essentially continually outputs an analog signal, so there is no need to recharge. In contrast, after a SPAD fires, it takes a while to recharge. During a SPAD avalanche event, it can be destroyed by its own huge current, so the current must be quenched with a resistor to discharge it. After quenching, it needs to recover to its original biasing condition. The reverse bias voltage is typically supplied by a capacitor, which needs to take time to charge back up again. Hence, there is a dead time ranging from around a few nanoseconds (silicon SPADs) to a microsecond (GMAPDs). By avoiding all this, APDs can have simpler circuitry.&lt;/item&gt;
      &lt;item&gt;Dynamic range per detector: APDs output a continuous analog output that you can digitize however finely you want, gives better dynamic range per detector (meanwhile a single SPAD has a dynamic range of only 1 bit, itâs either 0 or 1).&lt;/item&gt;
      &lt;item&gt;No range walk: Linear mode APDs avoid intensity-dependent range walk and saturation issues, which I discuss in more detail below.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the return signal from a pulse is very strong, a SPAD array can be saturated at the very beginning of the pulse. If the pulse length is long, ranging may be biased when measuring the range of retroreflective materials. This is also known as range walk.&lt;/p&gt;
    &lt;p&gt;SPADs are so sensitive that they can be triggered by single photons, but this also makes them sensitive to ambient illumination. Therefore saturation is a concern.&lt;/p&gt;
    &lt;p&gt;In contrast, the continuous signal from an APD can be digitized with many bits.&lt;/p&gt;
    &lt;p&gt;To prevent SPADs from being drowned out by ambient light, the probability of detection of any single SPAD must be kept very low. Some techniques include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SPADs are usually made really small&lt;/item&gt;
      &lt;item&gt;a tight band-pass filter can reject most ambient light&lt;/item&gt;
      &lt;item&gt;sometimes an attenuating filter (e.g. a neutral density filter, which attenuates all wavelengths equally) is needed to attenuate the signal even further&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;2.1.2 SPAD macropixels&lt;/head&gt;
    &lt;p&gt;Instead of a single SPAD per pixel, several SPADs can be combined into a single âmacropixelâ. This trade-off results in lower spatial resolution, but the benefit is that it mitigates most of the drawbacks of SPADs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynamic range increases from 1 bit to as many bits as you have SPADs in the macropixel.&lt;/item&gt;
      &lt;item&gt;Dead time of any individual SPAD is mitigated since it is unlikely that all the SPADs will fire at once, meaning that there are always available ones. Of course, in some circumstances (such as retroreflectors) it is still possible for all the SPADs in a macropixel to be saturated.&lt;/item&gt;
      &lt;item&gt;SPADs can be made individually smaller, making it unlikely for all of them to fire at once, resulting in better resilience against saturation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;2.1.3 Multi-shot ranging&lt;/head&gt;
    &lt;p&gt;Even with a macropixel, ranging with SPADs can be noisy as there may only be as many photons measured as there are SPADs in the macropixel. To increase signal strength, the lidar can fire many shots and aggregate the time series data from each shot. This is known as multi-shot ranging.&lt;/p&gt;
    &lt;p&gt;As an additional bonus, making multiple low-energy shots is somewhat safer than a single high-energy shot as the peak laser energy is less.&lt;/p&gt;
    &lt;p&gt;The tradeoff is that it takes a longer time to make a measurement, during which you could suffer from motion blur.&lt;/p&gt;
    &lt;head rend="h3"&gt;2.1.4 Silicon photomultipliers&lt;/head&gt;
    &lt;p&gt;Silicon photomultipliers are a group of SPADs whose outputs are combined into a single analog signal. This has some advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Just like the SPAD macropixel, by combining many SPADs, the dead time of any individual SPAD is a less big concern.&lt;/item&gt;
      &lt;item&gt;It can be more sensitive than regular linear mode APDs.&lt;/item&gt;
      &lt;item&gt;Without the need for digital logic, the chip is simpler and possibly denser than a digital SPAD macropixel.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, an ADC is still required to digitize the signal.&lt;/p&gt;
    &lt;head rend="h2"&gt;2.2 Amplitude modulated lidar&lt;/head&gt;
    &lt;p&gt;Instead of firing pulses, an amplitude modulated lidar continually modulates the laser amplitude at some radio frequency, say, 1 GHz. In other words, it is just a fast blinking light that turns on and off rapidly.&lt;/p&gt;
    &lt;p&gt;Meanwhile, there are two detectors that turn on and off at the same rate but are out of phase. That is, when detector 1 is on, detector 2 is off, and vice versa.&lt;/p&gt;
    &lt;p&gt;The range can be estimated by checking the ratio of the light falling in two detectors, for ranges up to a multiple of the modulation wavelength For example, at 1 GHz, the wavelength is 15 cm.&lt;/p&gt;
    &lt;p&gt;To resolve the range absolutely, the sensor changes the modulation frequency slightly, say, to 1.05 GHz, giving a range estimate modulo a different wavelength. The unknown multiples can then be found as a least common multiple problem.&lt;/p&gt;
    &lt;p&gt;The advantage of this type of amplitude-modulated lidar is that it is very cheap. There is no need for high-speed timing electronics to count photons at a high speed. Instead, a simple oscillator is sufficient to make the lights and detectors blink at 1 GHz.&lt;/p&gt;
    &lt;p&gt;Since the detectors just need to measure intensity rather than timing information, they do not need to be very fast, and basic CMOS or CCD sensors will suffice.&lt;/p&gt;
    &lt;p&gt;This type of lidar is used in RGBD sensors such as the Kinect V2. However, the ranging accuracy is much poorer than needed for automotive purposes, so this type of lidar is not typically used for automotive.&lt;/p&gt;
    &lt;head rend="h2"&gt;2.3 Frequency modulated lidar&lt;/head&gt;
    &lt;p&gt;A frequency modulated lidar has a laser that can change in frequency rapidly.&lt;/p&gt;
    &lt;p&gt;Now, the laser beam goes through a beam splitter, and part of it is sent out, where it hits something, and bounces back. Then, you can combine the part that didnât go out with the part that bounced back.&lt;/p&gt;
    &lt;p&gt;When you combine two waves of similar but slightly different frequency, youâll end up with something called beat. When the waves line up, they will double their strength, and when they are out of phase, they cancel each other out. Then, you can use a photodiode to measure the time series of the combined wave in order to determine the beat frequency, which in turn tells you the range.&lt;/p&gt;
    &lt;p&gt;Hereâs a plot that shows this effect. The main thing is that the beat frequency is proportional to the difference in frequency, so you can measure it relatively easily with a photodiode.&lt;/p&gt;
    &lt;p&gt;Frequency modulated lidar is known as frequency modulated continuous wave (FMCW) since the laser beam is always on (a continuous wave) that doesnât turn off. The principle of using the beat to determine the range is known as optical heterodyne detection. Here, âheterodyneâ means comparing two slightly different frequencies (as opposed to âhomodyneâ, where you have the same frequency).&lt;/p&gt;
    &lt;p&gt;With FMCW lidar, you can also measure the speed of things by measuring the Doppler shift.&lt;/p&gt;
    &lt;p&gt;The main tradeoff is that youâll need an expensive fiber laser that can do frequency modulation with highly linear chirps, increasing the overall cost.&lt;/p&gt;
    &lt;head rend="h2"&gt;2.4 Parallax lidar&lt;/head&gt;
    &lt;p&gt;A parallax lidar works by triangulation, that is, similar to coincidence rangefinding.&lt;/p&gt;
    &lt;p&gt;This does not use any timing information at all. A linear photodetector is placed physically offset from the laser. The detector measures the incident angle of the reflected light and obtains the range by triangulation.&lt;/p&gt;
    &lt;p&gt;This is rarely or never used in automotive applications but is instead found in robotic vacuum cleaners and other low-speed, low-cost applications. A famous example is the âLow cost laser distance sensorâ by Kurt Konolige et al. Many robotic vacuum cleaner sensors are based on this.&lt;/p&gt;
    &lt;p&gt;A structured light depth camera, also known as active stereo, is a special case of parallax rangefinding. Instead of a single laser beam, it projects a bunch of different dots at once, and instead of a 1D line scan sensor, it has a regular 2D sensor. But the depth measurement is again based on triangulation. Structured light depth cameras are used in the early versions of the Kinect as well as many Intel Realsense cameras.&lt;/p&gt;
    &lt;p&gt;With parallax rangefinding, it measures disparity, which is the inverse of range, so the uncertainty in range is quite high and grows quadratically with range. As such, it is less suitable for advanced robotics and autonomous cars.&lt;/p&gt;
    &lt;head rend="h1"&gt;3 Discerning bearing&lt;/head&gt;
    &lt;p&gt;As mentioned in our introduction, lidar sensors combine distance readings with bearing to produce 3D points. Now that weâve covered distance, we are ready to discuss how to figure out the directions (bearing) of things.&lt;/p&gt;
    &lt;p&gt;Lidars can either:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;discern bearing for both tx (the outgoing laser beam) and rx (the detector), or&lt;/item&gt;
      &lt;item&gt;discern bearing only for rx but not tx (i.e. a flash lidar), or&lt;/item&gt;
      &lt;item&gt;discern bearing only for tx but not rx (for example, some optical phased array lidars only steer the laser beam, but have a âstaringâ detector that doesnât distinguish angle).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Discerning bearing is also known as âimagingâ. People may describe a system as having both imaged rx and tx, for example.&lt;/p&gt;
    &lt;p&gt;Generally, having imaged rx and tx is vastly better, since you are only pointing your laser beam where youâre looking, so you get more range and efficiency, and meanwhile the imaged receiver rejects off-angle background light.&lt;/p&gt;
    &lt;p&gt;There are two main approaches for discerning bearing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;an array of elements already pointing in different directions&lt;/item&gt;
      &lt;item&gt;beam steering, by pointing either your detector or laser in various directions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As with the methods for measuring distance, each method has advantages and disadvantages.&lt;/p&gt;
    &lt;p&gt;The advantages of arrays are that they don't have any moving parts, each array element can be a lot cheaper, potentially leading to overall cheaper cost, and that it can produce a much greater quantity of points. The advantage of beam steering is that it works with high quality but expensive laser sources such as fiber lasers, the scan pattern may be configurable. Being able to use high quality lasers also unlocks the ability to use ranging modalities unavailable to array-based lidars, such as FMCW.&lt;/p&gt;
    &lt;p&gt;Note that if you rely on steering very few (even one) lasers, the number of points per second is limited by the speed of light. It takes light a microsecond to travel 300 m round trip, meaning that a single beam lidar is limited to about a million points per second at a range of 150 m. Meanwhile, array-based lidars can easily pump out several million points per second.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.1 Arrays for discerning bearing&lt;/head&gt;
    &lt;p&gt;The simplest way to determine direction is to just have an array of elements pointed in various directions.&lt;/p&gt;
    &lt;p&gt;Basically, youâll need cheap and small array elements in order to have an array.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Laser type&lt;/cell&gt;
        &lt;cell role="head"&gt;Performance&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Array?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;VCSEL&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Solid state 2D arrays of hundreds of lasers are possible&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Edge-emitting diodes&lt;/cell&gt;
        &lt;cell&gt;Mid&lt;/cell&gt;
        &lt;cell&gt;Mid&lt;/cell&gt;
        &lt;cell&gt;Discrete 1D arrays of dozens of lasers are typical&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fiber&lt;/cell&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;No, typically used as single laser + beam steering&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Sensor type&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Array?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SPAD&lt;/cell&gt;
        &lt;cell&gt;Small&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Solid state 2D arrays of even millions of SPADs are possible&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;APD&lt;/cell&gt;
        &lt;cell&gt;Mid&lt;/cell&gt;
        &lt;cell&gt;Mid&lt;/cell&gt;
        &lt;cell&gt;Discrete 1D arrays of dozens of APDs are typical&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;3.1.1 Discrete arrays&lt;/head&gt;
    &lt;p&gt;With discrete arrays, you have discrete components like edge-emitting laser diodes and avalanche photodiodes that are pointed in different directions. Some early lidars, like the Velodyne VLP 16, literally have 16 circuit boards, each with one laser diode on them, and another 16 circuit boards, each with one APD on them. Then, these 32 circuit boards are glued into place.&lt;/p&gt;
    &lt;p&gt;The reason for doing that is because, due to the simple design of the lens, it was necessary to arrange the lasers and detectors along a curved arc. Interestingly, a Google (now Waymo) patent US8836922B1 describes using a flexible substrate to achieve the curve.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.1.2 Solid state arrays&lt;/head&gt;
    &lt;p&gt;Solid state arrays put lasers or detectors on a single chip. The obvious benefit is vastly simpler manufacturing and consistency. High performance edge-emitting laser diodes shoot lasers to the sides so you canât just put a bunch of them in an array on a chip, so youâll have to make do with lower power VCSELs.&lt;/p&gt;
    &lt;p&gt;Since the laser array or detector array is now flat, the optical design will be somewhat more complex. Youâll need the lens to be image space telecentric since your flat array of lasers all produces parallel beams.&lt;/p&gt;
    &lt;p&gt;For lasers, only VCSELs are compatible with this method. As for detectors, SPADs are also vastly more amenable to solid state arrays, although APD arrays are also available (but with fewer elements). This is because, as discussed earlier, SPADs are compatible with typical chipmaking technologies and they output digital signals rather than analog ones, so you can fabricate them on a single chip, whereas APDs would typically require discrete components.&lt;/p&gt;
    &lt;p&gt;With large arrays, a lidar could sequentially fire small parts of an array instead of all of it at once. This is called electronically scanning. In effect, it is similar to scanning, except there are fixed elements already pointed in different directions rather than the same element being made to point in different directions. Electronically scanning has the advantage of less pixel crosstalk/blooming (more on this later) as well as being able to output more power per beam without running into thermal or safety limits.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.2 Scanning and beam steering methods&lt;/head&gt;
    &lt;head rend="h3"&gt;3.2.1 Spinning&lt;/head&gt;
    &lt;p&gt;Perhaps the most straightforward way to do beam steering is to just spin the whole lidar, which gives you 1D angular discernment. The first advantage is that this gives you 360 degree field of view. This also has the advantage of being highly compatible with arrays, so you can have a vertical array while spinning horizontally. Spinning lidars have basically only one moving part.&lt;/p&gt;
    &lt;p&gt;An encoder is used to measure the angle of the turret.&lt;/p&gt;
    &lt;p&gt;The challenges of spinning are that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You need to send power and data between the spinning turret and the stationary base somehow. The earliest spinning multi-beam lidar, the Velodyne HDL-64E, used a mercury-wetted slip ring (Mercotac 305). This is very efficient, but expensive, fragile, and somewhat environmentally unfriendly. Later spinning lidars transmit power wirelessly through a transformer, and data wirelessly through an optical link.&lt;/item&gt;
      &lt;item&gt;The cylindrical window can degrade optical performance. Some lidars have compensator optics to suppress aberrations from the cylindrical window. The Quanergy M8 had a variant with an octagonal window instead. Some lidars spin externally (such as the Waymo Laser Bear Honeycomb, Velodyne HDL-64E, and Velodyne HDL 32). But spinning externally makes it less robust against the environment.&lt;/item&gt;
      &lt;item&gt;Thermal dissipation. The spinning turret houses most of the energy-intensive lasers but it has no direct contact with the outside except through the bearing.&lt;/item&gt;
      &lt;item&gt;Despite having only one moving part, the spinning turret is a rather large and heavy part, and some early spinning lidars like Velodynes tended to fail a lot when the bearing was damaged or wore out. This is an especially big problem if the turret isnât well-balanced.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;3.2.2 Spinning mirror&lt;/head&gt;
    &lt;p&gt;Using a spinning polygonal mirror is one of the oldest and most reliable ways to scan a laser beam, which is again a 1D scanning method. This is used in, for example, laser printers.&lt;/p&gt;
    &lt;p&gt;As with spinning lidars, an encoder is used to measure the angle of the polygonal mirror.&lt;/p&gt;
    &lt;p&gt;Compared to spinning the whole turret, this has the main drawback of having a much narrower field of view (about 120 degrees is typical, as opposed to 360 degrees). However, it has the advantage of having a lighter moving part without having to deal with power transmission and heat dissipation and stuff.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.2.3 Oscillating mirrors/galvos&lt;/head&gt;
    &lt;p&gt;This is a flat mirror that oscillates in angle to steer the beam, which can be either 1D or 2D.&lt;/p&gt;
    &lt;p&gt;Typically, a lightweight mirror is connected to a galvanometer in whatâs called a mirror galvanometer (galvo). A galvanometer is one of the most basic ways to measure electrical current: it consists of a spring, a magnet, and a solenoid. When a current passes through the solenoid, it creates a magnetic field, which causes a torque to be applied as it tries to align itself with the magnet. The spring resists this force, so the amount it ends up turning is dependent on the current.&lt;/p&gt;
    &lt;p&gt;Nowadays, fast galvos are incredibly good and are used in all sorts of applications, like laser light shows, engraving, and so on.&lt;/p&gt;
    &lt;p&gt;Compared to spinning mirrors, this is somewhat less reliable, since reciprocating motion is typically less reliable than constant rotation.&lt;/p&gt;
    &lt;p&gt;Unlike spinning mirrors, you can have a single mirror thatâs actuated in two axes (a 2D galvo) that allows you to steer your beam in both directions with a single mirror.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.2.4 MEMS mirror&lt;/head&gt;
    &lt;p&gt;A MEMS (micro-electromechanical system) mirror is simply a mirror that is really small, typically an oscillating mirror. Because it is so small, it is typically considered âsolid stateâ even if it is physically a moving part. Like macroscopic oscillating mirrors, MEMS scanner may be either 1D or 2D.&lt;/p&gt;
    &lt;p&gt;The primary advantage of MEMS is low cost and relatively better reliability. After all, the rate at which your moving part wears out is strongly dependent on the mass and moments of inertia of that moving part, so keeping it as light as possible makes it more resilient.&lt;/p&gt;
    &lt;p&gt;There are, however, a couple of drawbacks:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The optical aperture may be limited by the tiny size of the mirror. With lasers, the bigger the aperture, the more it stays collimated (and hence the less it spreads out), so you want the aperture to be as large as possible usually.&lt;/item&gt;
      &lt;item&gt;Cooling a tiny mirror may be hard. Your entire laser output is bouncing off a tiny surface with tiny thermal pathways. Hence, the mirror should be kept as reflective as possible.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;3.2.5 Optical phased arrays&lt;/head&gt;
    &lt;p&gt;A phased array has many array elements whose phase is slightly offset. As the contributions from each element interfere, a beam is formed where they interfere constructively, and everywhere else, destructive interference causes it to cancel out.&lt;/p&gt;
    &lt;p&gt;Phased arrays are common in radar. However, the fundamental physical problem of phased arrays is that the element size must be close to the size of the wavelength, and the wavelength of light (about a micron) is way smaller than the wavelength of radio waves (ranging from millimeters to many meters). If your array spacing is too big, your beam would have very poor collimation and tons of side lobes.&lt;/p&gt;
    &lt;p&gt;You can use phased arrays for both the transmitter and receiver. For the receiver, you would have an array of optical antennae which are tiny nanophotonic detectors that can each measure the phase and amplitude.&lt;/p&gt;
    &lt;p&gt;So far, due to the physical challenges with phased arrays, there have been no commercial successes. The Quanergy S3 and an Israeli startup called Oryx Vision were two well-known entrants to attempt optical antennae.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.2.6 Baraja SpectrumScan&lt;/head&gt;
    &lt;p&gt;This uses a frequency sweep laser with a fixed prism. Prisms have dispersion, which means that the index of refraction changes with wavelength (hence turning sunlight into a rainbow), so by changing the wavelength of the laser, the angle is changed. This allows it to scan in 1D. Baraja uses a MEMS mirror for the other axis.&lt;/p&gt;
    &lt;p&gt;This requires using a high quality fiber laser or tunable diodes that can do large frequency sweeps, which can be costly.&lt;/p&gt;
    &lt;head rend="h3"&gt;3.2.7 Risley prisms&lt;/head&gt;
    &lt;p&gt;A prism is a triangular piece of glass that can bend light. Risley prisms are a pair of two prisms that can rotate along the optical axis. When the prisms are lined up, they both bend light the same way, and the beam gets bent a lot. When they are opposite of each other, they cancel each other out, and the beam goes through straight without bending.&lt;/p&gt;
    &lt;p&gt;Basically, when you have two prisms, one with angle and one with angle , the direction of the beam is proportional to:&lt;/p&gt;
    &lt;p&gt;Speed ratio between prisms: -0.743&lt;/p&gt;
    &lt;p&gt;The Livox lidars are notable for using Risley prisms. You can make other scan patterns by varying the speed of the prisms, and by putting an array of multiple lasers (e.g. the Livox Horizonâs 6 lasers) instead of one laser.&lt;/p&gt;
    &lt;p&gt;The advantage of Risley prisms is that, like polygonal mirrors, itâs cheap and robust to have things spinning at a constant speed. However, the disadvantage is very narrow field of view, and a weird scanning pattern. For some applications, the scan pattern can be an advantage, for example surveying applications where the lidar can be stationary for long periods of time, gradually covering a dense area.&lt;/p&gt;
    &lt;head rend="h2"&gt;3.3 Combining two 1D methods&lt;/head&gt;
    &lt;p&gt;Many lidars combine two 1D methods, e.g.:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Horizontally spinning turret + vertical array (e.g. Velodyne pucks, Ouster OS series, Hesai Pandar)&lt;/item&gt;
      &lt;item&gt;Horizontally spinning turret + vertically spinning polygonal mirror (e.g. Leica BLK360)&lt;/item&gt;
      &lt;item&gt;Horizontal spinning mirror + vertical spinning or oscillating mirror (e.g. Luminar Iris, Seyond Falcon)&lt;/item&gt;
      &lt;item&gt;Horizontal spinning mirror + array (e.g. Hesai AT512)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;4 Choice of wavelength and eye safety&lt;/head&gt;
    &lt;p&gt;For lidars, two choices of wavelength are popular:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;near infrared, e.g. 850 nm, 865 nm, 905 nm, 940 nm&lt;/item&gt;
      &lt;item&gt;1550 nm&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The main advantage of near IR is that silicon is sensitive in that region, allowing much cheaper, more sensitive silicon detectors, as well as cheap laser sources. In contrast, with 1550 nm, you would need InGaAs semiconductors for your detectors, which are less sensitive and very expensive.&lt;/p&gt;
    &lt;p&gt;Meanwhile, the main advantage of 1550 nm is that eye safety regulations allow devices to output vastly more power at 1550 nm than in the near IR regime. As a result, 1550 nm lidars tend to have longer range in general.&lt;/p&gt;
    &lt;p&gt;You can see in the above chart that you are allowed to output hundreds of times more power in the steady state scenario (red curve) at 1550 nm compared to, say, 905 nm. The reason is that the human eyeball focuses near IR light to small spots on the retina, so intense light may damage the retina. On the other hand, 1550 nm light is not focused and is attenuated by water, but at high enough intensities, it will damage the cornea instead.&lt;/p&gt;
    &lt;p&gt;In practice, manufacturers carefully tune the power of the lasers to be just below the eye safety threshold for both 1550 nm lidars and near IR lidars. That is to say, 1550 nm lidars do in fact output up to 1,000,000 times more pulse energy than 905 nm ones.&lt;/p&gt;
    &lt;p&gt;Paradoxically, 1550 nm lidars may be more dangerous overall, because of the following reasons:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you have many lidars around, the beams from each 905 nm lidar will be focused to a different spot on your retina, and you are no worse off than if there was a single lidar. But if there are many 1550 nm lidars around, their beams will have a cumulative effect at heating up your cornea, potentially exceeding the safety threshold.&lt;/item&gt;
      &lt;item&gt;1550 nm lidars more often rely on beam steering since it is impractical to have an array of expensive fiber lasers. However, if the beam steering were to fail, the laser beam may be fixed in one direction. This can cause laser energy levels thousands of times stronger than the safety threshold in a particular direction, even when the lidar would be under the threshold when itâs scanning properly.&lt;/item&gt;
      &lt;item&gt;1550 nm lidars are known to damage cameras. For example, both AEye lidars and Luminar lidars on the Volvo EX90 are known to destroy cameras. This is an especially worrisome problem with pulsed 1550 nm lidar, but FMCW lidars have a continuous wave with lower peak power and may be slightly safer.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Eye safety aside, 1550 nm is also somewhat more attenuated by both water and water vapor, so they are likely to perform worse in poor weather. In fog, Mie scattering of the water droplets may also impact 1550 nm lidar more, as fog droplets are about 1.5 microns, and the scattering is more as the size of the sphere approaches the wavelength. That said, 1550 nm lidars do have better range to begin with, thanks to outputting a lot more power, so even with attenuation, they are still competitive in rainy situations.&lt;/p&gt;
    &lt;head rend="h1"&gt;5 Laser sources&lt;/head&gt;
    &lt;p&gt;There are basically three commonly used types of lasers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vertical cavity surface emitting laser (VCSEL)&lt;/item&gt;
      &lt;item&gt;Edge-emitting laser diodes&lt;/item&gt;
      &lt;item&gt;Fiber lasers&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Laser type&lt;/cell&gt;
        &lt;cell role="head"&gt;Typical wavelength(s)&lt;/cell&gt;
        &lt;cell role="head"&gt;Beam quality (MÂ²)&lt;/cell&gt;
        &lt;cell role="head"&gt;Coherence / FMCW-ready&lt;/cell&gt;
        &lt;cell role="head"&gt;Power per element&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Array?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;VCSEL&lt;/cell&gt;
        &lt;cell&gt;850â940 nm&lt;/cell&gt;
        &lt;cell&gt;Very good, circular&lt;/cell&gt;
        &lt;cell&gt;Lowâmid linewidth&lt;/cell&gt;
        &lt;cell&gt;Low (mW-tens mW)&lt;/cell&gt;
        &lt;cell&gt;Low&lt;/cell&gt;
        &lt;cell&gt;Excellent: monolithic 2D arrays (10Â²â10âµ emitters), fine pitch, easy eye-safety&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Edge-emitting diodes&lt;/cell&gt;
        &lt;cell&gt;905 nm, 1350-1550 nm&lt;/cell&gt;
        &lt;cell&gt;Good (often elliptical)&lt;/cell&gt;
        &lt;cell&gt;Midâhigh&lt;/cell&gt;
        &lt;cell&gt;Mid (100 mWâW class with bars)&lt;/cell&gt;
        &lt;cell&gt;Mid&lt;/cell&gt;
        &lt;cell&gt;Good: 1D bars/arrays (dozensâhundreds)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fiber/ECDL&lt;/cell&gt;
        &lt;cell&gt;1550 nm&lt;/cell&gt;
        &lt;cell&gt;Excellent&lt;/cell&gt;
        &lt;cell&gt;High (kHzâ100 kHz LW) best for FMCW&lt;/cell&gt;
        &lt;cell&gt;High (W class via fiber amps)&lt;/cell&gt;
        &lt;cell&gt;High&lt;/cell&gt;
        &lt;cell&gt;Poor as dense arrays; usually single source + split/steer&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Vertical cavity surface-emitting lasers (VCSELs) are very cheap and you can make a bunch of them on a chip in a chip-scale solid state array. They are called âvertical cavityâ because the beam comes out perpendicular to the chip. You make them by depositing several layers of material on the chip. The main drawback is that they are low peak power.&lt;/p&gt;
    &lt;p&gt;Edge-emitting laser diodes are a mature technology and are cheap enough to be 1D arrays.&lt;/p&gt;
    &lt;p&gt;Fiber lasers produce high quality light that is highly coherent. But they are quite expensive so you can probably just afford one or two per lidar. Some lidars split one laser between many lidar heads, as in the case of Barajaâs lidar. Not only are fiber lasers more coherent, they can output millions of times greater power than edge-emitting diode lasers and VCSELs as well as much shorter pulses. Having shorter pulses is very advantageous for pulsed lidar as it improves the range resolution. Some fiber lasers can also vary the wavelength in highly linear chirps, allowing use in FMCW lidars.&lt;/p&gt;
    &lt;p&gt;The development of these lasers is highly driven by the telecommunications industry where they are used in fiber optics, so the lidar industry sort of profits from that for free.&lt;/p&gt;
    &lt;head rend="h1"&gt;6 Common lidar problems&lt;/head&gt;
    &lt;head rend="h2"&gt;6.1 Beam angle calibration&lt;/head&gt;
    &lt;p&gt;Most spinning + array lidars need a calibrated list of angles, one per beam. Some manufacturers, like Ouster, provide a JSON metadata file containing the elevation and azimuth angles of each of the 128 beams, which is calibrated per lidar. Some manufacturers simply give a nominal set of beam angles for a lidar model that is assumed to be the same for each individual lidar, but in practice, each lidar varies slightly due to manufacturing tolerances. Early Velodynes had very bad beam angles as each of the many circuit boards was individually glued in place and manually aligned.&lt;/p&gt;
    &lt;p&gt;Here are some ways lidar measurements could have bad beam angles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Accidentally forgetting to use the lidar-specific beam angles, or the manufacturer doesnât provide them&lt;/item&gt;
      &lt;item&gt;All the beams are offset by some angle even with lidar-specific beam angles, e.g. bad factory calibration, the lidar got bumped, or due to thermal expansion&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This would typically manifest as the ground curving slightly, or the trajectory of the robot curving up or down even when it is expected to be flat.&lt;/p&gt;
    &lt;p&gt;The well-known KITTI dataset is known to have bad beam angles, and some publications have to manually calibrate them in order to achieve good results. For example, in IMLS-SLAM by J. E. Deschaud:&lt;/p&gt;
    &lt;quote&gt;The drift we get on the KITTI benchmark is not as good as the results we obtained with the Velodyne HDL32. This is due to three facts. First, we found a distortion of the scan point clouds because of a bad intrinsic calibration (we did a calibration of the intrinsic vertical angle of all laser beams of 0.22 degrees using the training data). Second, we found big errors in GPS data (used as ground truth) with, for example, more than 5 m in the beginning of sequence 8.&lt;/quote&gt;
    &lt;head rend="h2"&gt;6.2 Range offsets&lt;/head&gt;
    &lt;p&gt;Lidars sometimes have different range offsets for each laser. This can happen when using discrete arrays where each laser-detector pair are separate components that need to be individually calibrated.&lt;/p&gt;
    &lt;head rend="h2"&gt;6.3 Pixel crosstalk/blooming&lt;/head&gt;
    &lt;p&gt;Blooming affects many lidars. Think of pointing a camera at the sun. There would be huge lens flare and brightness all around the sun. In effect, the light from the sun is âsmearedâ out onto neighboring pixels. Likewise, when thereâs a strong lidar return, there could be spurious returns next to the shiny object.&lt;/p&gt;
    &lt;p&gt;With array lidars, neighboring detectors sometimes pick up on the return meant for a different detector. This is called crosstalk. However, even single beam lidars can suffer from blooming just due to the fact that the beam has some divergence and that the optics are imperfect.&lt;/p&gt;
    &lt;p&gt;This effect typically canât be easily calibrated away, and is usually handled in lidar firmware.&lt;/p&gt;
    &lt;head rend="h2"&gt;6.4 Intensity-dependent range bias&lt;/head&gt;
    &lt;p&gt;This typically affects SPAD lidars like early Ouster lidars and the now-defunct Argo (formerly Princeton Lightwave) lidar. The reason is that when the return is very strong, all the SPADS get saturated at the beginning of the pulse.&lt;/p&gt;
    &lt;p&gt;Typically, a pulse is a few nanoseconds long, which means up to a few meters in physical length of the light pulse. Even a slight saturation effect can cause the the peak of the time series to be biased significantly. Very advanced signal processing techniques are needed to compensate for this.&lt;/p&gt;
    &lt;head rend="h2"&gt;6.5 Encoder hysteresis&lt;/head&gt;
    &lt;p&gt;Hysteresis in an encoder would typically manifest as some kind of lag, e.g. if itâs rotating clockwise, it could output measurements with slightly different offset than when itâs at the same angle but rotating counter clockwise. Some lidars, such as the Luminar Iris, use encoders for an oscillating beam scanner for vertical beam scanning. It also has a mode where part of the point cloud is an âup-scanâ and the other part is a âdown-scanâ, and the two are superimposed. Often, the point cloud of the up- and down-scans do not align well, even when the vehicle is stationary, suggesting that there may be hysteresis in the encoder.&lt;/p&gt;
    &lt;p&gt;This may manifest as double-layer point clouds in the ground.&lt;/p&gt;
    &lt;head rend="h2"&gt;6.6 Encoder physical offset&lt;/head&gt;
    &lt;p&gt;The encoder used in many spinning lidars is a circular ring with a bunch of ticks engraved on it at regular intervals.&lt;/p&gt;
    &lt;p&gt;However, it is possible that the encoder is physically offset to the side, because the ring is often just glued in place by humans. This results in a sinusoidal error.&lt;/p&gt;
    &lt;p&gt;This effect can cause a straight corridor to appear consistently curved to one side.&lt;/p&gt;
    &lt;head rend="h2"&gt;6.7 Multiple lidars in a box&lt;/head&gt;
    &lt;p&gt;Some lidars are packaged in such a way that there are two or more separate lidars in a box. For example, the Livox Mid 100 comprises three Mid-40s arranged side by side.&lt;/p&gt;
    &lt;p&gt;Sometimes, physically jostling the lidar can cause the multiple separate lidars to become misaligned. It would then be necessary to treat them as separate lidars and calibrate their orientations accurately.&lt;/p&gt;
    &lt;head rend="h1"&gt;7 FAQ&lt;/head&gt;
    &lt;head rend="h2"&gt;7.1 LiDAR vs lidar&lt;/head&gt;
    &lt;quote&gt;Should it be capitalized as âLiDARâ instead of âlidarâ?&lt;/quote&gt;
    &lt;p&gt;No! We should use the lowercase because itâs a commonly used word just like radar. When radar was some sort of highly exotic military technology, it made sense to use all caps for the acronym âradio detection and rangingâ, but by now it is so common that we should use lowercase. Many other words started out capitalized when new and exotic, but became lowercase once commonplace:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;laser, Light Amplification by Stimulated Emission of Radiation&lt;/item&gt;
      &lt;item&gt;scuba, Self-Contained Underwater Breathing Apparatus&lt;/item&gt;
      &lt;item&gt;taser, Thomas A. Swiftâs Electric Rifle&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now that most phones and some cars are equipped with lidar, itâs a good time to just use lowercase. Perhaps the main barrier to doing so is Appleâs autocorrect.&lt;/p&gt;
    &lt;head rend="h2"&gt;7.2 Are rectangular lidars solid state?&lt;/head&gt;
    &lt;p&gt;No, not necessarily. Whether or not something is solid state is based on whether it has macroscopic moving parts in it, not based on its shape.&lt;/p&gt;
    &lt;p&gt;Livox lidars are often mistakenly assumed to be solid state, but they are in fact mechanically scanning with some using Risley prisms and some using mirrors.&lt;/p&gt;
    &lt;p&gt;Likewise, Luminar lidars are often assumed to be solid state, but they are not. The Luminar Hydra uses galvos and the Luminar Iris uses polygonal mirrors.&lt;/p&gt;
    &lt;p&gt;Solid state lidars are often perceived to be more durable and reliable. Lidar manufacturers have taken note of this market bias in customers, and marketed accordingly. For example, the Velodyne HDL-64 was marketed as solid state (even though it is externally spinning) in their 2016 press release announcing the VLP-32A.&lt;/p&gt;
    &lt;quote&gt;Based on his experience during this challenge, Hall recognized the limitations of stereovision and developed the HDL-64 Solid-State Hybrid LiDAR sensor.&lt;/quote&gt;
    &lt;p&gt;As justification, however, one might consider that it has an array of 64 lasers to distinguish vertical bearing, so perhaps it could be called 50% solid state as mechanical scanning is used only for the horizontal direction! In contrast, Luminar and Livox lidars use mechanical scanning for both directions, despite being a single non-spinning box.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mainstreetautonomy.com/blog/2025-08-29-all-about-automotive-lidar/"/><published>2025-12-01T17:43:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46121539</id><title>Zig's new plan for asynchronous programs</title><updated>2025-12-03T13:09:20.464400+00:00</updated><content>&lt;doc fingerprint="b612da05ee6713e9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zig's new plan for asynchronous programs&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;p&gt;The designers of the Zig programming language have been working to find a suitable design for asynchronous code for some time. Zig is a carefully minimalist language, and its initial design for asynchronous I/O did not fit well with its other features. Now, the project has announced (in a Zig SHOWTIME video) a new approach to asynchronous I/O that promises to solve the function coloring problem, and allows writing code that will execute correctly using either synchronous or asynchronous I/O.&lt;/p&gt;
    &lt;p&gt;In many languages (including Python, JavaScript, and Rust), asynchronous code uses special syntax. This can make it difficult to reuse code between synchronous and asynchronous parts of a program, introducing a number of headaches for library authors. Languages that don't make a syntactical distinction (such as Haskell) essentially solve the problem by making everything asynchronous, which typically requires the language's runtime to bake in ideas about how programs are allowed to execute.&lt;/p&gt;
    &lt;p&gt;Neither of those options was deemed suitable for Zig. Its designers wanted to find an approach that did not add too much complexity to the language, that still permitted fine control over asynchronous operations, and that still made it relatively painless to actually write high-performance event-driven I/O. The new approach solves this by hiding asynchronous operations behind a new generic interface, Io.&lt;/p&gt;
    &lt;quote&gt;The staff here at LWN.net really appreciate the subscribers who make our work possible. Is there a chance we could interest you in becoming one of them?&lt;/quote&gt;
    &lt;p&gt;Any function that needs to perform an I/O operation will need to have access to an instance of the interface. Typically, that is provided by passing the instance to the function as a parameter, similar to Zig's Allocator interface for memory allocation. The standard library will include two built-in implementations of the interface: Io.Threaded and Io.Evented. The former uses synchronous operations except where explicitly asked to run things in parallel (with a special function; see below), in which case it uses threads. The latter (which is still a work-in-progress) uses an event loop and asynchronous I/O. Nothing in the design prevents a Zig programmer from implementing their own version, however, so Zig's users retain their fine control over how their programs execute.&lt;/p&gt;
    &lt;p&gt;Loris Cro, one of Zig's community organizers, wrote an explanation of the new behavior to justify the approach. Synchronous code is not much changed, other than using the standard library functions that have moved under Io, he explained. Functions like the example below, which don't involve explicit asynchronicity, will continue to work. This example creates a file, sets the file to close at the end of the function, and then writes a buffer of data to the file. It uses Zig's try keyword to handle errors, and defer to ensure the file is closed. The return type, !void, indicates that it could return an error, but doesn't return any data:&lt;/p&gt;
    &lt;quote&gt;const std = @import("std"); const Io = std.Io; fn saveFile(io: Io, data: []const u8, name: []const u8) !void { const file = try Io.Dir.cwd().createFile(io, name, .{}); defer file.close(io); try file.writeAll(io, data); }&lt;/quote&gt;
    &lt;p&gt;If this function is given an instance of Io.Threaded, it will create the file, write data to it, and then close it using ordinary system calls. If it is given an instance of Io.Evented, it will instead use io_uring, kqueue, or some other asynchronous backend suitable to the target operating system. In doing so, it might pause the current execution and go work on a different asynchronous function. Either way, the operation is guaranteed to be complete by the time writeAll() returns. A library author writing a function that involves I/O doesn't need to care about which of these things the ultimate user of the library chooses to do.&lt;/p&gt;
    &lt;p&gt;On the other hand, suppose that a program wanted to save two files. These operations could profitably be done in parallel. If a library author wanted to enable that, they could use the Io interface's async() function to express that it does not matter which order the two files are saved in:&lt;/p&gt;
    &lt;quote&gt;fn saveData(io: Io, data: []const u8) !void { // Calls saveFile(io, data, "saveA.txt") var a_future = io.async(saveFile, .{io, data, "saveA.txt"}); var b_future = io.async(saveFile, .{io, data, "saveB.txt"}); const a_result = a_future.await(io); const b_result = b_future.await(io); try a_result; try b_result; const out: Io.File = .stdout(); try out.writeAll(io, "save complete"); }&lt;/quote&gt;
    &lt;p&gt; When using an Io.Threaded instance, the async() function &lt;del&gt;doesn't actually&lt;/del&gt; isn't actually required to do anything asynchronously [although the actual implementation may dispatch the function to a separate thread, depending on how it was configured] — it can just run the provided function right away. So, with that version of the interface, the function first saves file A and then file B. With an Io.Evented instance, the operations are actually asynchronous, and the program can save both files at once. &lt;/p&gt;
    &lt;p&gt;The real advantage of this approach is that it turns asynchronous code into a performance optimization. The first version of a program or library can write normal straight-line code. Later, if asynchronicity proves to be useful for performance, the author can come back and write it using asynchronous operations. If the ultimate user of the function has not enabled asynchronous execution, nothing changes. If they have, though, the function becomes faster transparently — nothing about the function signature or how it interacts with the rest of the code base changes.&lt;/p&gt;
    &lt;p&gt; One problem, however, is with programs where two parts are actually required to execute simultaneously for correctness. For example, suppose that a program wants to listen for connections on a port and simultaneously respond to user input. In that scenario, it wouldn't be correct to wait for a connection and only then ask for user input. For that use case, the Io interface provides a separate function, &lt;del&gt;asyncConcurrent()&lt;/del&gt;concurrent() [this function was renamed during development; concurrent() is the most recent name] that explicitly asks for the provided function to be run in parallel. Io.Threaded uses a thread in a thread pool to accomplish this. Io.Evented treats it exactly the same as a normal call to async(). &lt;/p&gt;
    &lt;quote&gt;const socket = try openServerSocket(io); var server = try io.concurrent(startAccepting, .{io, socket}); defer server.cancel(io) catch {}; try handleUserInput(io);&lt;/quote&gt;
    &lt;p&gt;If the programmer uses async() where they should have used concurrent(), that is a bug. Zig's new model does not (and cannot) prevent programmers from writing incorrect code, so there are still some subtleties to keep in mind when adapting existing Zig code to use the new interface.&lt;/p&gt;
    &lt;p&gt; The style of code that results from this design is a bit more verbose than languages that give asynchronous functions special syntax, but Andrew Kelley, creator of the language, said that "&lt;quote&gt;it reads like standard, idiomatic Zig code.&lt;/quote&gt;" In particular, he noted that this approach lets the programmer use all of Zig's typical control-flow primitives, such as try and defer; it doesn't introduce any new language features specific to asynchronous code. &lt;/p&gt;
    &lt;p&gt;To demonstrate this, Kelley gave an example of using the new interface to implement asynchronous DNS resolution. The standard getaddrinfo() function for querying DNS information falls short because, although it makes requests to multiple servers (for IPv4 and IPv6) in parallel, it waits for all of the queries to complete before returning an answer. Kelley's example Zig code returns the first successful answer, canceling the other inflight requests.&lt;/p&gt;
    &lt;p&gt;Asynchronous I/O in Zig is far from done, however. Io.Evented is still experimental, and doesn't have implementations for all supported operating systems yet. A third kind of Io, one that is compatible with WebAssembly, is planned (although, as that issue details, implementing it depends on some other new language features). The original pull request for Io lists 24 planned follow-up items, most of which still need work.&lt;/p&gt;
    &lt;p&gt;Still, the overall design of asynchronous code in Zig appears to be set. Zig has not yet had its 1.0 release, because the community is still experimenting with the correct way to implement many features. Asynchronous I/O was one of the larger remaining priorities (along with native code generation, which was also enabled by default for debug builds on some architectures this year). Zig seems to be steadily working its way toward a finished design — which should decrease the number of times Zig programmers are asked to rewrite their I/O because the interface has changed again.&lt;/p&gt;
    &lt;p&gt; Posted Dec 2, 2025 17:00 UTC (Tue) by smurf (subscriber, #17840) [Link] (12 responses) Doesn't seem much different from tagging everything you want to async-ize with "async" and "await" … Also I'm interested in how zig plans to manage an event loop this way. I mean you need to save and restore the call stack somehow, and stacks may not exactly be small in a production setup. Posted Dec 2, 2025 18:53 UTC (Tue) by daroc (editor, #160859) [Link] (1 responses) As for managing the event loop: I believe the plan is for there to be built-in functions that can start executing a function on a user-provided stack, so the event loop can allocate separate stacks and then give them to the running functions. But Zig has also had a long-term goal to eventually be able to statically determine the needed stack size of any given function, at which point it should be possible to write comptime code that does better than that. Posted Dec 2, 2025 21:20 UTC (Tue) by softball (subscriber, #160655) [Link] Similar to Go, which also has "one and a half colors". Functions taking a context.Context as their first argument are most likely performing I/O. It's not required though: a number-crunching function performing no I/O might still check the context for cancellation every so often. Likewise, I/O without taking a context.Context is possible. Similarly, in async languages (Rust, ...), a function marked async might end up performing no I/O at all (no await points). A function marked sync might spawn its own runtime (or grab the global one) and start spawning futures (= called async functions) on it. Lots of grey areas. One thing I wonder about is mixing threading for CPU-bound work and eventing for I/O-bound work. In Rust, one solution is having the application be fundamentally async (tokio, ...) and hand around a dedicated threadpool (rayon, ...). If there's enough available parallelism, both can coexist without interference and communicate via channels. Rust makes this explicit and relatively ergonomic at compile time (Send + Sync, ...). I wonder how equivalent Zig code would look like (I suppose Io would be the evented variant, and for the CPU-bound work just spawn OS threads normally). Posted Dec 2, 2025 20:09 UTC (Tue) by quotemstr (subscriber, #45331) [Link] Posted Dec 2, 2025 21:18 UTC (Tue) by excors (subscriber, #95769) [Link] (8 responses) Arguably that's a good case of colouring, because the presence of IO _should_ be part of your API: users ought to be aware of the security and performance and portability and testability implications of an API that accesses the filesystem/network, and should have some control over it. But users shouldn't have to care about serial IO vs concurrent IO - that's just an implementation detail and a performance optimisation - and in this model they don't have to care, because the API is IO-coloured either way, unlike the async/await model where migrating to concurrent IO changes your API colouring. That's similar to how the use of dynamic memory allocation should be part of your API (and in Zig it is); it's too important to hide. And error handling (in most languages that don't use exceptions). And the general concept of dependency injection. I suppose the main downside is that once you start making everything an explicit part of every API and avoiding implicit global state, it gets annoyingly verbose, and it's hard to read code when the important logic is obscured by boilerplate. But I think it's interesting to see Zig try a different tradeoff here. Posted Dec 2, 2025 22:23 UTC (Tue) by khim (subscriber, #9252) [Link] (5 responses) That's much better solution that what Rust did. Of course Zig has the benefits of hindsight. In practice there are more than two colors — except in Rust it's not obvious from the source and almost unmanageable in practice. That's because you couldn't simply pass any random In Zig one may simply have more than two implementations of the interface. People are talking about “two colors” because in practice that's something that actually works, but try to mix two executors in one program in Rust… and the whole thing falls apart, you couldn't do that. It's not “2 colors” problem, but “2+ colors problem”. Posted Dec 3, 2025 9:17 UTC (Wed) by pbonzini (subscriber, #60935) [Link] (2 responses) I would like to understand how IO functions are compiled. If they are stackful coroutines, Zig's solution is very clever but that's a very different design space than the stackless coroutines you have in Rust or, for that matter, in Zig's previous attempt at asynchronous I/O. Stackless coroutines need compiler support but are more efficient (a couple years back I had a (IMO) really nice design for C stackless coroutines, but no time to implement it...). Or does the compiler effectively treat the IO argument as a request to turn the function into a state machine and pass it to the threaded or evented run-time? Posted Dec 3, 2025 10:17 UTC (Wed) by spiffyk (subscriber, #173891) [Link] What is important to note is that the language provides no special treatment to the Io parameter, it is entirely an API convention to pass it. Io is an extension of the standard library, which in and of itself does not change how the language works. The only point at which the compiler itself will need to provide special functionality is when an implementation of the Io interface uses the (as of yet not finalized, afaik) constructs for stackless coroutines. But those are planned to be a separate feature of the language, and, from the perspective of the Io, will only be used by specific Io implementations. Posted Dec 3, 2025 12:40 UTC (Wed) by lukasl (guest, #180745) [Link] Posted Dec 3, 2025 9:58 UTC (Wed) by muase (subscriber, #178466) [Link] (1 responses) Could you elaborate what you mean with that? Because I have heavily used async within the embedded world, and I struggle to understand your point. Async has two relevant API components: futures and wakers. As long as I implement a correct future, and use the provided opaque waker to wake the executor, I don’t see how my implementation has to match the executor? And in my experience that works pretty well IRL; I have quite a few projects where I switched from my own executor to embassy, and two projects where I did vice versa, and I’ve never encountered any problems so far… Posted Dec 3, 2025 11:22 UTC (Wed) by khim (subscriber, #9252) [Link] Nope. It has three components, or, more precisely, two and half: futures+wakers and executors. These have to match or the whole thing goes down in flames. Because your waker has to match the executor. And said waker, as you have said, is opaque and is not present in the function signature so compiler couldn't verify that they match. And how many of these have both of these executors running, simultaneously? Note that it's not even a purely theoretical interest. There are tokio and tokio_uring — and they are incompatible (certain things in tokio make it impossible to use in one project). You may want, e.g., use tokio for network-related tasks and tokio_uring for disk access (where tokio is lacking). But if you try to do that you would quickly find out that mixing different futures (and thus different wakers) can easily lead to trouble. Posted Dec 2, 2025 23:02 UTC (Tue) by sionescu (subscriber, #59410) [Link] (1 responses) Posted Dec 3, 2025 2:55 UTC (Wed) by Cyberax (✭ supporter ✭, #52523) [Link] Posted Dec 2, 2025 21:40 UTC (Tue) by dcoutts (subscriber, #5387) [Link] (1 responses) Yes there's an analogy in there somewhere but no. Asynchronous code and threaded code have some similarities but are different. Async code is about trying to do cooperative execution in a single thread (and often with little to no runtime support). Threaded code (with language support) typically means a runtime system with a thread scheduler, and some compiler support to implement proper thread pre-emption. In Haskell in particular (which is what I'm familiar with) the compiler doesn't need to make everything async. It compiles to very traditional-looking low level sequential code. The only magic is the compiler inserts yield points (where it anyway has to do stack or heap checks), and yes there is a thread scheduler in the runtime system (and thread synchronisation primitives interact with the scheduler too of course). Turning everything async is a rather different compiler transformation. Posted Dec 2, 2025 21:58 UTC (Tue) by daroc (editor, #160859) [Link] Compare a Rust async function that does some work, and then goes to work on another async function due to an .await, and then finishes its work. That is quite conceptually similar to a Haskell function that does some work, demands another thunk, and then finishes its work. They're really quite similar in that they don't usually involve the runtime, unless there's some multithreading going on or its time for a context switch. In both languages, the operation (.await or forcing a thunk) are theoretically implemented with a call instruction, but can in practice have the compiler inline parts or do them ahead of time if it can prove that they're used later. In both languages, the in-progress state of these things is partly stored in registers and mostly stored in a specific object in memory. I accept that it's not a perfect analogy. There are serious differences between the language, and in particular the GHC runtime's "everything is a function, even data" approach is pretty different from Rust's "everything is data, even async functions" approach. But I also think that it's not a misleading comparison when the language mechanisms are solving similar problems (letting computation occur in an order that doesn't strictly match the order that a traditional strict, imperative language would demand) in a similar way (by using specialized objects in memory that a runtime helps to manage, but that can do basic interactions between objects just by calling through the appropriate function pointer). &lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;code&gt;async&lt;/code&gt; function into any random executor… the functions that do actual work have to match the executor or else the whole things falls apart — and these functions are invisible in Rust's &lt;code&gt;async fn&lt;/code&gt; signature.&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head/&gt; &amp;gt; Async has two relevant API components: futures and wakers. &lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;I see what you mean but...&lt;/head&gt;&lt;head&gt;I see what you mean but...&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/SubscriberLink/1046084/4c048ee008e1c70e/"/><published>2025-12-02T14:31:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46121870</id><title>OpenAI declares 'code red' as Google catches up in AI race</title><updated>2025-12-03T13:09:20.274544+00:00</updated><content>&lt;doc fingerprint="bda6ded3906683a6"&gt;
  &lt;main&gt;
    &lt;p&gt;The tides are turning in the AI race, and the pressure is getting to OpenAI. Chief executive Sam Altman reportedly declared a “code red” on Monday, urging staff to improve its flagship product ChatGPT, an indicator that the startup’s once-unassailable lead is eroding as competitors like Google and Anthropic close in.&lt;/p&gt;
    &lt;head rend="h1"&gt;OpenAI declares ‘code red’ as Google catches up in AI race&lt;/head&gt;
    &lt;p&gt;Google’s own ‘code red’ response to ChatGPT has started paying off.&lt;/p&gt;
    &lt;p&gt;Google’s own ‘code red’ response to ChatGPT has started paying off.&lt;/p&gt;
    &lt;p&gt;In the memo, reported by The Wall Street Journal and The Information, Altman said the company will be delaying initiatives like ads, shopping and health agents, and a personal assistant, Pulse, to focus on improving ChatGPT. This includes core features like greater speed and reliability, better personalization, and the ability to answer more questions, he said.&lt;/p&gt;
    &lt;p&gt;There will be a daily call for those tasked with improving the chatbot, the memo said, and Altman encouraged temporary team transfers to speed up development.&lt;/p&gt;
    &lt;p&gt;The newfound urgency illustrates an inflection point for OpenAI as it spends hundreds of billions of dollars to fund growth and figures out a path to future profitability. It is also something of a full-circle moment in the AI race. Google, which declared its own “code red” after the arrival of ChatGPT, is a particular concern. Google’s AI user base is growing — helped by the success of popular tools like the Nano Banana image model — and its latest AI model, Gemini 3, blew past its competitors on many industry benchmarks and popular metrics.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/836212/openai-code-red-chatgpt"/><published>2025-12-02T15:00:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46124179</id><title>School cell phone bans and student achievement</title><updated>2025-12-03T13:09:19.947796+00:00</updated><content>&lt;doc fingerprint="3429e01309a30ea7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;School Cell Phone Bans and Student Achievement&lt;/head&gt;
    &lt;p&gt;Two years after the imposition of a student cell phone ban, student test scores in a large urban school district were significantly higher than before, David N. Figlio and Umut Özek find in The Impact of Cell Phone Bans in Schools on Student Outcomes: Evidence from Florida (NBER Working Paper 34388). The study examines data from one of the 10 largest school districts in the United States, a large urban county-level school district in Florida. While Florida's statewide law banned cell phone use during instructional time, this district implemented a stricter policy requiring students to keep phones silenced and stored in backpacks during the entire school day, including lunch and transitions between classes.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;An all-day cell phone ban within a Florida school district improved test scores, particularly for male students and in middle and high schools.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The researchers combined two datasets to conduct this analysis. First, they accessed student administrative data for the year prior to the ban (AY 2022–23) and two years following the ban (AY 2023–24 and AY 2024–25). These data are reported to the district three times annually and include information on student demographics, attendance, disciplinary actions, and standardized test scores. Second, they examined building-level smartphone activity data from Advan for district schools. This data traced the average number of unique smartphone pings between 9 am and 1 pm on school days. To isolate the effects of student usage, the team compared normal school days to professional-only working days. They then compared the last two months of AY 2022–23 (pre-ban) to the first two months of AY 2023–24 and AY 2024–25 (post-ban) and found an average drop in usage of approximately two-thirds. The relative level of usage reduction was used to sort the district’s schools into high-effect (top tercile of pre-ban usage) and low-effect (bottom tercile of pre-ban usage) pools.&lt;/p&gt;
    &lt;p&gt;During the first month of the ban (September 2023), student suspensions rose 25 percent relative to the same month of the prior school year. Elevated disciplinary rates persisted for the full school year. The effects were particularly stark among Black male students, whose in-school suspension rates increased 30 percent at the highly affected schools. Even among the most affected schools and population groups, however, disciplinary action rates fell to near pre-ban levels by the start of the following school year. The researchers posited that this represented a period of adjustment to the new policy rather than an indication of a long-term negative effect of the ban’s implementation.&lt;/p&gt;
    &lt;p&gt;There were no statistically significant changes in test scores during the first year of the ban, when disciplinary rates were high. During the second year of the ban, in contrast, test scores increased significantly, with positive effects concentrated during the spring semester (scores increased 1.1 percentiles, on average). The researchers suggest that this may be due to the higher stakes of spring tests, which can affect grade advancement and high school graduation. Test score improvements were also concentrated among male students (up 1.4 percentiles, on average) and among middle and high school students (up 1.3 percentiles, on average).&lt;/p&gt;
    &lt;p&gt;When comparing high-effect and low-effect schools, the researchers note significant reductions in unexcused absences during the two years following the cell phone ban. They posit that increased attendance could explain as much as half of the test score improvements noted in their primary analysis.&lt;/p&gt;
    &lt;p&gt;- Emma Salomon&lt;/p&gt;
    &lt;p&gt;The researchers thank the Smith Richardson Foundation for generous research funding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nber.org/digest/202512/school-cell-phone-bans-and-student-achievement"/><published>2025-12-02T17:58:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46124267</id><title>Anthropic acquires Bun</title><updated>2025-12-03T13:09:19.639113+00:00</updated><content>&lt;doc fingerprint="3325915d7bc72e5c"&gt;
  &lt;main&gt;
    &lt;p&gt;TLDR: Bun has been acquired by Anthropic. Anthropic is betting on Bun as the infrastructure powering Claude Code, Claude Agent SDK, and future AI coding products &amp;amp; tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;What doesn't change:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bun stays open-source &amp;amp; MIT-licensed&lt;/item&gt;
      &lt;item&gt;Bun continues to be extremely actively maintained&lt;/item&gt;
      &lt;item&gt;The same team still works on Bun&lt;/item&gt;
      &lt;item&gt;Bun is still built in public on GitHub&lt;/item&gt;
      &lt;item&gt;Bun's roadmap will continue to focus on high performance JavaScript tooling, Node.js compatibility &amp;amp; replacing Node.js as the default server-side runtime for JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Claude Code ships as a Bun executable to millions of users. If Bun breaks, Claude Code breaks. Anthropic has direct incentive to keep Bun excellent.&lt;/p&gt;
    &lt;head rend="h3"&gt;What changes:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We will help make coding tools like Claude Code &amp;amp; Claude Agent SDK faster &amp;amp; smaller&lt;/item&gt;
      &lt;item&gt;We get a closer first look at what's around the corner for AI coding tools, and make Bun better for it&lt;/item&gt;
      &lt;item&gt;Bun will ship faster.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How Bun started&lt;/head&gt;
    &lt;p&gt;Almost five years ago, I was building a Minecraft-y voxel game in the browser. The codebase got kind of large, and the iteration cycle time took 45 seconds to test if changes worked. Most of that time was spent waiting for the Next.js dev server to hot reload.&lt;/p&gt;
    &lt;p&gt;This was frustrating, and I got really distracted trying to fix it.&lt;/p&gt;
    &lt;p&gt;I started porting esbuild's JSX &amp;amp; TypeScript transpiler from Go to Zig. Three weeks later, I had a somewhat working JSX &amp;amp; TypeScript transpiler.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Early benchmark from a new JavaScript bundler. It transpiles JSX files:&lt;/p&gt;— Jarred Sumner (@jarredsumner) May 5, 2021&lt;lb/&gt;- 3x faster than esbuild&lt;lb/&gt;- 94x faster than swc&lt;lb/&gt;- 197x faster than babel pic.twitter.com/NBRt9ESu2d&lt;/quote&gt;
    &lt;p&gt;I spent much of that first year in a very cramped apartment in Oakland, just coding and tweeting about Bun.&lt;/p&gt;
    &lt;head rend="h4"&gt;The runtime&lt;/head&gt;
    &lt;p&gt;To get Next.js server side rendering to work, we needed a JavaScript runtime. And JavaScript runtimes need an engine to interpret &amp;amp; JIT compile the code.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The start time difference between JavaScriptCore and V8 is interesting. JavaScriptCore seems to start around 4x faster.&lt;/p&gt;— Jarred Sumner (@jarredsumner) May 26, 2021&lt;lb/&gt;It's possible this is due to the specifics of their respective CLIs though (rather than about JavaScript execution) pic.twitter.com/xd5tSbWf6p&lt;/quote&gt;
    &lt;p&gt;So after about a month of reading WebKit's source code trying to figure out how to embed JavaScriptCore with the same flexibility as what Safari does, I had the very initial version of Bun's JavaScript runtime.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v0.1.0&lt;/head&gt;
    &lt;p&gt;Bun v0.1.0 was released in July of 2022. A bundler, a transpiler, a runtime (designed to be a drop-in replacement for Node.js), test runner, and a package manager - all in one. We ended up reaching 20k GitHub stars in the first week.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Introducing Bun - an incredibly fast all-in-one JavaScript runtime. https://t.co/Yt6tAcnBQs&lt;/p&gt;— Jarred Sumner (@jarredsumner) July 5, 2022&lt;/quote&gt;
    &lt;p&gt;Those first two weeks after the release were one of the craziest weeks of my life. My job switched from writing code all day to replying to people all day. We raised a $7 million seed round led by Kleiner Perkins (thanks Bucky &amp;amp; Leigh Marie! And also Shrav Mehta), I took a salary and convinced a handful of engineers to move to San Francisco and help build Bun.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;got keys &amp;amp; desks for oven’s office today pic.twitter.com/bfTmRaF7Oh&lt;/p&gt;— Jarred Sumner (@jarredsumner) October 8, 2022&lt;/quote&gt;
    &lt;head rend="h3"&gt;Bun v1.0.0&lt;/head&gt;
    &lt;p&gt;Bun started to feel more stable, so we shipped Bun v1.0 in September of 2023.&lt;/p&gt;
    &lt;p&gt;Production usage started to pick up and we raised a $19 million Series A led by Khosla Ventures (thanks Nikita &amp;amp; Jon!), grew the team to 14 people and got a slightly larger office.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v1.1&lt;/head&gt;
    &lt;p&gt;After all this time, we still didn't have Windows support. And every day, people asked us the same question: "when will Bun support Windows?"&lt;/p&gt;
    &lt;p&gt;So we added Windows support and called it Bun v1.1. Our Windows support was pretty rough at first, but we've made a lot of progress since then.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v1.2&lt;/head&gt;
    &lt;p&gt;Bun v1.2 made big improvements to Node.js compatibility, added a builtin PostgreSQL client and S3 client. We also started seeing production usage from companies like X and Midjourney. Tailwind's standalone CLI is built with Bun.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v1.3&lt;/head&gt;
    &lt;p&gt;Bun v1.3 added a builtin frontend dev server, a Redis client, a MySQL client, several improvements to &lt;code&gt;bun install&lt;/code&gt; and improved Node.js compatibility. The real feature: continued increasing production usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI started to get good&lt;/head&gt;
    &lt;p&gt;In late 2024, AI coding tools went from "cool demo" to "actually useful." And a ton of them are built with Bun.&lt;/p&gt;
    &lt;p&gt;Bun's single-file executables turned out to be perfect for distributing CLI tools. You can compile any JavaScript project into a self-contained binary—runs anywhere, even if the user doesn't have Bun or Node installed. Works with native addons. Fast startup. Easy to distribute.&lt;/p&gt;
    &lt;p&gt;Claude Code, FactoryAI, OpenCode, and others are all built with Bun.&lt;/p&gt;
    &lt;head rend="h3"&gt;I got obsessed with Claude Code&lt;/head&gt;
    &lt;p&gt;I started using Claude Code myself. I got kind of obsessed with it.&lt;/p&gt;
    &lt;p&gt;Over the last several months, the GitHub username with the most merged PRs in Bun's repo is now a Claude Code bot. We have it set up in our internal Discord and we mostly use it to help fix bugs. It opens PRs with tests that fail in the earlier system-installed version of Bun before the fix and pass in the fixed debug build of Bun. It responds to review comments. It does the whole thing.&lt;/p&gt;
    &lt;p&gt;This feels approximately a few months ahead of where things are going. Certainly not years.&lt;/p&gt;
    &lt;head rend="h3"&gt;The road ahead&lt;/head&gt;
    &lt;p&gt;Today, Bun makes $0 in revenue.&lt;/p&gt;
    &lt;p&gt;One of the most common questions I get is about sustainability. Questions like:&lt;/p&gt;
    &lt;p&gt;"How does Bun become a business?"&lt;/p&gt;
    &lt;p&gt;"If I bet my work project or company's tech stack on Bun, will it still be around in five or ten years?"&lt;/p&gt;
    &lt;p&gt;Our default answer was always some version of "we'll eventually build a cloud hosting product.", vertically integrated with Bun’s runtime &amp;amp; bundler.&lt;/p&gt;
    &lt;p&gt;But the world when I first started working on Bun is different from the world today. AI coding tools are this massive change to how developers do productive work, and the infrastructure layer matters more when agents are writing code.&lt;/p&gt;
    &lt;p&gt;Forcing ourselves down the prescribed path felt wrong when AI coding tools are getting this good, this fast.&lt;/p&gt;
    &lt;head rend="h3"&gt;The walk&lt;/head&gt;
    &lt;p&gt;We've been prioritizing issues from the Claude Code team for several months now. I have so many ideas all the time and it's really fun. Many of these ideas also help other AI coding products.&lt;/p&gt;
    &lt;p&gt;A few weeks ago, I went on a four hour walk with Boris from the Claude Code team. We talked about Bun. We talked about where AI coding is going. We talked about what it would look like for Bun's team to join Anthropic. Then we did that about 3 more times over the next few weeks. Then I did that with many of their competitors. I think Anthropic is going to win.&lt;/p&gt;
    &lt;p&gt;Betting on Anthropic sounded like a more interesting path. To be in the center of things. To work alongside the team building the best AI coding product.&lt;/p&gt;
    &lt;head rend="h3"&gt;This is a little bit crazy&lt;/head&gt;
    &lt;p&gt;At the time of writing, Bun's monthly downloads grew 25% last month (October, 2025), passing 7.2 million monthly downloads. We had over 4 years of runway to figure out monetization. We didn't have to join Anthropic.&lt;/p&gt;
    &lt;p&gt;Instead of putting our users &amp;amp; community through "Bun, the VC-backed startups tries to figure out monetization" – thanks to Anthropic, we can skip that chapter entirely and focus on building the best JavaScript tooling.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why this makes sense&lt;/head&gt;
    &lt;p&gt;When people ask "will Bun still be around in five or ten years?", answering with "we raised $26 million" isn't a great answer. Investors eventually need a return.&lt;/p&gt;
    &lt;p&gt;But there's a bigger question behind that: what does software engineering even look like in two to three years?&lt;/p&gt;
    &lt;p&gt;AI coding tools are getting really good, really fast and they're using Bun’s single-file executables to ship CLIs and agents that run everywhere.&lt;/p&gt;
    &lt;p&gt;If most new code is going to be written, tested, and deployed by AI agents:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The runtime and tooling around that code become way more important.&lt;/item&gt;
      &lt;item&gt;You get a lot more code overall, written &amp;amp; tested a lot faster.&lt;/item&gt;
      &lt;item&gt;Humans are more detached from every individual line, so the environment it runs in has to be fast and predictable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bun started with a focus on making developers faster. AI coding tools do a similar thing. It’s a natural fit.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun joins Anthropic&lt;/head&gt;
    &lt;p&gt;So that's why we're joining Anthropic.&lt;/p&gt;
    &lt;p&gt;Anthropic is investing in Bun as the infrastructure powering Claude Code, Claude Agent SDK, and future AI coding products. Our job is to make Bun the best place to build, run, and test AI-driven software — while continuing to be a great general-purpose JavaScript runtime, bundler, package manager, and test runner.&lt;/p&gt;
    &lt;p&gt;Being part of Anthropic gives Bun:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Long-term stability. a home and resources so people can safely bet their stack on Bun.&lt;/item&gt;
      &lt;item&gt;A front-row seat to where AI coding tools are headed, so we can shape Bun around that future instead of guessing from the outside.&lt;/item&gt;
      &lt;item&gt;More firepower. We’re hiring engineers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And for existing users, the core promise stays the same:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bun remains open-source &amp;amp; MIT-licensed.&lt;/item&gt;
      &lt;item&gt;Bun is still built in public.&lt;/item&gt;
      &lt;item&gt;The same team still works on Bun.&lt;/item&gt;
      &lt;item&gt;We’re still obsessed with making JavaScript and TypeScript faster to install, build, run and test.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anthropic gets a runtime that’s aligned with where software development is going. We get to work on the most interesting version of that future.&lt;/p&gt;
    &lt;p&gt;This is going to be really fun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frequently asked questions&lt;/head&gt;
    &lt;p&gt;Q: Is Bun still open-source &amp;amp; MIT-licensed?&lt;lb/&gt;A: Yes.&lt;/p&gt;
    &lt;p&gt;Q: Will Bun still be developed in public on GitHub?&lt;lb/&gt;A: Yes. We’ll still be extremely active on GitHub issues &amp;amp; pull requests.&lt;/p&gt;
    &lt;p&gt;Q: Does Bun still care about Node.js compatibility &amp;amp; being a drop-in replacement for Node.js?&lt;lb/&gt;A: Yes.&lt;/p&gt;
    &lt;p&gt;Q: Is the same team still working on Bun full-time?&lt;lb/&gt;A: Yes. And now we get access to the resources of the world’s premier AI Lab instead of a small VC-backed startup making $0 in revenue&lt;/p&gt;
    &lt;p&gt;Q: What does this mean for Bun’s roadmap?&lt;lb/&gt;A: Bun’s team will be working more closely with the Claude Code team, and it probably will look similar to the relationship between Google Chrome &amp;lt;&amp;gt; V8, Safari &amp;lt;&amp;gt; JavaScriptCore, Mozilla Firefox &amp;lt;&amp;gt; SpiderMonkey, but with more independence to prioritize the wide variety of ways people &amp;amp; companies use Bun today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bun.com/blog/bun-joins-anthropic"/><published>2025-12-02T18:05:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46124324</id><title>IBM CEO says there is 'no way' spending on AI data centers will pay off</title><updated>2025-12-03T13:09:19.404750+00:00</updated><content>&lt;doc fingerprint="4f74925d2cffe6ed"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IBM's CEO walked through some napkin math on data centers— and said that there's "no way" to turn a profit at current costs.&lt;/item&gt;
      &lt;item&gt;"$8 trillion of CapEx means you need roughly $800 billion of profit just to pay for the interest," Arvind Krishna told "Decoder."&lt;/item&gt;
      &lt;item&gt;Krishna was skeptical of that current tech would reach AGI, putting the likelihood between 0-1%.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AI companies are spending billions on data centers in the race to AGI. IBM CEO Arvind Krishna has some thoughts on the math behind those bets.&lt;/p&gt;
    &lt;p&gt;Data center spending is on the rise. During Meta's recent earnings call, words like "capacity" and AI "infrastructure" were frequently used. Google just announced that it wants to eventually build them in space. The question remains: will the revenue generated from data centers ever justify all the capital expenditure?&lt;/p&gt;
    &lt;p&gt;On the "Decoder" podcast, Krishna concluded that there was likely "no way" these companies would make a return on their capex spending on data centers.&lt;/p&gt;
    &lt;p&gt;Couching that his napkin math was based on today's costs, "because anything in the future is speculative," Kirshna said that it takes about $80 billion to fill up a one-gigawatt data center.&lt;/p&gt;
    &lt;p&gt;"Okay, that's today's number. So, if you are going to commit 20 to 30 gigawatts, that's one company, that's $1.5 trillion of capex," he said.&lt;/p&gt;
    &lt;p&gt;Krishna also referenced the depreciation of the AI chips inside data centers as another factor: "You've got to use it all in five years because at that point, you've got to throw it away and refill it," he said.&lt;/p&gt;
    &lt;p&gt;Investor Michael Burry has recently taken aim at Nvidia over depreciating concerns, leading to a downturn in AI stocks.&lt;/p&gt;
    &lt;p&gt;"If I look at the total commits in the world in this space, in chasing AGI, it seems to be like 100 gigawatts with these announcements," Krishna said.&lt;/p&gt;
    &lt;p&gt;At $80 billion each for 100 gigawatts, that sets Krishna's price tag for computing commitments at roughly $8 trillion.&lt;/p&gt;
    &lt;p&gt;"It's my view that there's no way you're going to get a return on that, because $8 trillion of capex means you need roughly $800 billion of profit just to pay for the interest," he said.&lt;/p&gt;
    &lt;p&gt;Reaching that number of gigawatts has required massive spending from AI companies — and pushes for outside help. In an October letter to the White House's Office of Science and Technology Policy, OpenAI CEO Sam Altman recommended that the US add 100 gigawatts in energy capacity every year.&lt;/p&gt;
    &lt;p&gt;"Decoder" host Nilay Patel pointed out that Altman believed OpenAI could generate a return on its capital expenditures. OpenAI has committed to spending some $1.4 trillion in a variety of deals. Here, Krishna said he diverged from Altman.&lt;/p&gt;
    &lt;p&gt;"That's a belief," Krishna said. "That's what some people like to chase. I understand that from their perspective, but that's different from agreeing with them."&lt;/p&gt;
    &lt;p&gt;Krishna clarified that he wasn't convinced that the current set of technologies would get us to AGI, a yet to be reached technological breakthrough generally agreed to be when AI is capable of completing complex tasks better than humans. He pegged the chances of achieving it without a further technological breakthrough at 0-1%.&lt;/p&gt;
    &lt;p&gt;Several other high-profile leaders have been skeptical of the acceleration to AGI. Marc Benioff said that he was "extremely suspect" of the AGI push, analogizing it to hypnosis. Google Brain founder Andrew Ng said that AGI was "overhyped," and Mistral CEO Arthur Mensch said that AGI was a "marketing move."&lt;/p&gt;
    &lt;p&gt;Even if AGI is the goal, scaling compute may not be the enough. OpenAI cofounder Ilya Sutskever said in November that the age of scaling was over, and that even 100x scaling of LLMs would not be completely transformative. "It's back to the age of research again, just with big computers," he said.&lt;/p&gt;
    &lt;p&gt;Krishna, who began his career at IBM in 1990 before rising to eventually be named CEO in 2020 and chairman in 2021, did praise the current set of AI tools.&lt;/p&gt;
    &lt;p&gt;"I think it's going to unlock trillions of dollars of productivity in the enterprise, just to be absolutely clear," he said.&lt;/p&gt;
    &lt;p&gt;But AGI will require "more technologies than the current LLM path," Krisha said. He proposed fusing hard knowledge with LLMs as a possible future path.&lt;/p&gt;
    &lt;p&gt;How likely is that to reach AGI? "Even then, I'm a 'maybe,'" he said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.businessinsider.com/ibm-ceo-big-tech-ai-capex-data-center-spending-2025-12"/><published>2025-12-02T18:10:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46125155</id><title>Amazon launches Trainium3</title><updated>2025-12-03T13:09:19.226892+00:00</updated><content>&lt;doc fingerprint="7f58135a25beadfd"&gt;
  &lt;main&gt;
    &lt;p&gt;Amazon Web Services, which has been building its own AI training chips for years now, just introduced a new version known as Trainium3 that comes with some impressive specs.&lt;/p&gt;
    &lt;p&gt;The cloud provider, which made the announcement Tuesday at AWS re:Invent 2025, also teased the next product on its AI training product roadmap: Trainium4, which is already in the works and will be able to work with Nvidia’s chips.&lt;/p&gt;
    &lt;p&gt;AWS used its annual tech conference to formally launch Trainium3 UltraServer, a system powered by the company’s state-of-the art, 3 nanometer Trainium3 chip, as well as its homegrown networking tech. As you might expect, the third-generation chip and system offer big bumps in performance for AI training and inference over the second-generation chip, according to AWS.&lt;/p&gt;
    &lt;p&gt;AWS says the system is more than 4x faster, with 4x more memory, not just for training, but for delivering AI apps at peak demand. Additionally, thousands of UltraServers can be linked together to provide an app with up to 1 million Trainium3 chips — 10x the previous generation. Each UltraServer can host 144 chips, according to the company.&lt;/p&gt;
    &lt;p&gt;Perhaps more importantly, AWS says the chips and systems are also 40% more energy efficient than the previous generation. While the world races to build bigger data centers powered by astronomical gigawatts of electricity, data center giant AWS is trying to make systems that drink less, not more.&lt;/p&gt;
    &lt;p&gt;It is, obviously, in AWS’s direct interests to do so. But in its classic, Amazon cost-conscious way, it promises that these systems save its AI cloud customers money, too.&lt;/p&gt;
    &lt;p&gt;AWS customers like Anthropic (of which Amazon is also an investor), Japan’s LLM Karakuri, SplashMusic, and Decart have already been using the third-gen chip and system and significantly cut their inference costs, Amazon said.&lt;/p&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages — part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;head rend="h3"&gt;Join the Disrupt 2026 Waitlist&lt;/head&gt;
    &lt;head rend="h4"&gt;Add yourself to the Disrupt 2026 waitlist to be first in line when Early Bird tickets drop. Past Disrupts have brought Google Cloud, Netflix, Microsoft, Box, Phia, a16z, ElevenLabs, Wayve, Hugging Face, Elad Gil, and Vinod Khosla to the stages — part of 250+ industry leaders driving 200+ sessions built to fuel your growth and sharpen your edge. Plus, meet the hundreds of startups innovating across every sector.&lt;/head&gt;
    &lt;p&gt;AWS also presented a bit of a roadmap for the next chip, Trainium4, which is already in development. AWS promised the chip will provide another big step up in performance and support Nvidia’s NVLink Fusion high-speed chip interconnect technology.&lt;/p&gt;
    &lt;p&gt;This means the AWS Trainium4-powered systems will be able to interoperate and extend their performance with Nvidia GPUs while still using Amazon’s homegrown, lower-cost server rack technology.&lt;/p&gt;
    &lt;p&gt;It’s worth noting, too, that Nvidia’s CUDA (Compute Unified Device Architecture) has become the de facto standard that all the major AI apps are built to support. The Trainium4-powered systems may make it easier to woo big AI apps built with Nvidia GPUs in mind to Amazon’s cloud.&lt;/p&gt;
    &lt;p&gt;Amazon did not announce a timeline for Trainium4. If the company follows previous rollout timelines, we’ll likely hear more about Trainium4 at next year’s conference.&lt;/p&gt;
    &lt;p&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sponsored: Watch re:Invent industry streams&lt;/head&gt;
    &lt;p&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flags&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/"/><published>2025-12-02T19:04:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46126141</id><title>Free static site generator for small restaurants and cafes</title><updated>2025-12-03T13:09:18.970035+00:00</updated><content>&lt;doc fingerprint="d684a94baad7f3d5"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h2"&gt; Disclaimer&lt;/head&gt;
      &lt;p&gt; This is not a real restaurant,&lt;/p&gt;
      &lt;head rend="h2"&gt; About US&lt;/head&gt;
      &lt;p&gt; Pasta boy’s started in ma’s kitchen after a plate of ma’s spaggite in old town meatball. 20 years later they are still slerping noddles.&lt;/p&gt;
      &lt;head rend="h2"&gt; Orders to GO&lt;/head&gt;
      &lt;p&gt; We do orders to go, call us and place an order for pick up&lt;/p&gt;
      &lt;head rend="h2"&gt; This was an example of using localcafe lite&lt;/head&gt;
      &lt;p&gt; You can use localcafe lite for free and also host static restaurant menu sites for free using github pages.&lt;/p&gt;
      &lt;p&gt; Learn more about this project at https://github.com/Local-Cafe/localcafe-lite&lt;/p&gt;
      &lt;head rend="h3"&gt; Free / No Monthly Fees&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; This project is open source and free &lt;/item&gt;
        &lt;item&gt; This project can host for free on GitHub Pages, Netlify, or Cloudflare Pages &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt; Static Website&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; Fast page loads - everything pre-generated &lt;/item&gt;
        &lt;item&gt; No database or server required &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt; Online Menu&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; Display your full menu with photos, descriptions, and prices &lt;/item&gt;
        &lt;item&gt; Single prices or multiple options (small/large, hot/iced, etc.) &lt;/item&gt;
        &lt;item&gt; Customers filter by tags (vegetarian, gluten-free, breakfast, lunch) &lt;/item&gt;
        &lt;item&gt; Update by editing simple text files &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt; Location &amp;amp; Maps&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; Show one location or multiple locations &lt;/item&gt;
        &lt;item&gt; Automatic maps - just provide your address &lt;/item&gt;
        &lt;item&gt; Each location has its own hours, phone, and email &lt;/item&gt;
        &lt;item&gt; Maps adjust to any screen size &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt; Photo Slideshow&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; Homepage displays rotating photos with smooth transitions &lt;/item&gt;
        &lt;item&gt; Supports single image or multiple images &lt;/item&gt;
        &lt;item&gt; Photos fade between each other automatically &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt; Mobile Responsive&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; Works on all phones and tablets &lt;/item&gt;
        &lt;item&gt; Menu and navigation adapt to screen size &lt;/item&gt;
        &lt;item&gt; No pinching or zooming required &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt; Social Sharing&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt; Links shared on Facebook, Twitter, Instagram show rich previews &lt;/item&gt;
        &lt;item&gt; Displays your photo and description automatically &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt; Images in example provided by https://pixabay.com/ &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lite.localcafe.org/"/><published>2025-12-02T20:08:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46126217</id><title>Paged Out</title><updated>2025-12-03T13:09:18.161268+00:00</updated><content>&lt;doc fingerprint="6d2c1476114285af"&gt;
  &lt;main&gt;
    &lt;p&gt;Paged Out! is a free experimental (one article == one page) technical magazine about programming (especially programming tricks!), hacking, security hacking, retro computers, modern computers, electronics, demoscene, and other similar topics.&lt;/p&gt;
    &lt;p&gt;It's made by the community for the community. And it's not-for-profit (though in time, we hope it will be self-sustained) - this means that the issues will always be free to download, share, and print. If you're interested in more details, check our our FAQ and About pages!&lt;/p&gt;
    &lt;p&gt;You can get printed issues at events and print-on-demand bookstores. You'll find more info here.&lt;/p&gt;
    &lt;p&gt;Issue #7 (Oct'25): Best kind of readme&lt;lb/&gt; Download counter: 167245&lt;lb/&gt; Print counter: 1016 (updated manually)&lt;/p&gt;
    &lt;p&gt;Prints:&lt;/p&gt;
    &lt;p&gt;Issue #6 (Mar'25): Stay a while and read&lt;lb/&gt; Download counter: 141803&lt;lb/&gt; Print counter: 2702 (updated manually)&lt;/p&gt;
    &lt;p&gt;Prints:&lt;/p&gt;
    &lt;p&gt;Issue #5 (Nov'24): All your page are belong to us&lt;lb/&gt; Download counter: 105652&lt;/p&gt;
    &lt;p&gt;What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #4 (Jun'24): The epic Paged Out! story continues&lt;lb/&gt; Download counter: 117111&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #3 (Dec'23): The resurrected Paged Out!&lt;lb/&gt; Download counter: 122858&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #2 (Nov'19): The second Paged Out!&lt;lb/&gt; Download counter: 127758&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta 2 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #1 (Aug'19): The first Paged Out! issue has arrived!&lt;lb/&gt; Download counter: 261305&lt;lb/&gt; Print counter: 500 (updated manually)&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta 1 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Additionally, here's another Paged Out! wallpaper by ReFiend:&lt;/p&gt;
    &lt;p&gt;If you like our work, how about writing an article for Paged Out!? It's only one page after all - easy. ;)&lt;/p&gt;
    &lt;p&gt; Next issue progress tracker (unit of measurement: article count):&lt;/p&gt;
    &lt;p&gt;Sure! There are a couple of ways to get notified when the issue will be out:&lt;/p&gt;
    &lt;p&gt;We will only send e-mails to this group about new Paged Out! issues (both the free electronic ones and special issues if we ever get to that). No spam will be sent there and (if you subscribe to the group) your e-mail will be visible only to group owners.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pagedout.institute"/><published>2025-12-02T20:14:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46128286</id><title>DOOM could have had PC Speaker Music</title><updated>2025-12-03T13:09:17.635637+00:00</updated><content>&lt;doc fingerprint="a77a35716886da8a"&gt;
  &lt;main&gt;
    &lt;p&gt;I'm guessing everyone here has played DOOM before, or at least seen someone else play the game.&lt;lb/&gt; It would also not be of any news for most here, that DOOM has specific hard-coded sound drivers which directly talk to the sound hardware.&lt;lb/&gt; Now, many PCs didn't have a dedicated (let alone supported) sound card for DOOM. What people often overlook is the PC Speaker driver that DOOM comes with. Mostly as it can only play back sound effects (and does so quite poorly too). Many times, it ends up disabled rather than being used.&lt;lb/&gt; For a long time, it has been speculated that the PC Speaker driver never supported audio as it would have been too resource intensive to drive the interface in real-time while performing game logic. Now, on a 286, I would totally understand this reasoning, but on a processor as fast as a 486? No chance it wouldn't work!&lt;lb/&gt; Introducing: The PC Speaker sndserver patch!&lt;lb/&gt; I had decided that the only way to answer the question of if, was to try it. And try it I did:&lt;lb/&gt; https://youtu.be/bRHyQPhA_9A&lt;lb/&gt; A few weeks ago, I had written a file format for efficiently playing PC Speaker tunes on a 32-bit system, requiring only a few integer operations to turn the data into a valid call for the input/misc/pcspkr device. The format being called pcsp and working as follows:&lt;lb/&gt; A song is made up of an array of 32 bit tone cells consisting of&lt;lb/&gt; - a 16 bit frequency value in Hz&lt;lb/&gt; - a 4 bit duration scale (second*10^-scale)&lt;lb/&gt; - a 12 bit duration value&lt;lb/&gt; Now, all I really had to do to get PC Speaker music working in DOOM, was to implement a priority mixer for it in sndserver.&lt;lb/&gt; The ground work for which already existed in the existing Adlib target.&lt;lb/&gt; Surprisingly, running the game with and without the patch showed no noticeable speed differences.&lt;lb/&gt; Will this patch become public? Yes, soon.&lt;lb/&gt; I do not feel comfortable with publishing it yet as I currently only have the E1M1 soundtrack implemented and also would like to fix a few other issues with the sndserver on modern Linux while I have the chance.&lt;/p&gt;
    &lt;head rend="h2"&gt;DOOM could have had PC Speaker Music!&lt;/head&gt;
    &lt;head rend="h3"&gt;DOOM could have had PC Speaker Music!&lt;/head&gt;
    &lt;p&gt;~-~-~ MSD - Making your old devices useful again since 2022! ~-~-~&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lenowo.org/viewtopic.php?t=45"/><published>2025-12-02T23:19:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130233</id><title>Understanding ECDSA</title><updated>2025-12-03T13:09:17.382267+00:00</updated><content>&lt;doc fingerprint="1efcc89f0ba71b95"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Understanding ECDSA&lt;/head&gt;
    &lt;head rend="h2"&gt;Prerequisites and audience&lt;/head&gt;
    &lt;p&gt;In this article, we'll try to understand how ECDSA (Elliptic Curve Digital Signature Algorithm) works.&lt;/p&gt;
    &lt;p&gt;The version I have in mind is the one used by the Ethereum blockchain. Since my interest lies in security, we'll also explore the signature malleability attack.&lt;/p&gt;
    &lt;p&gt;I expect you to be familiar with Public Key Cryptography and how it can be used to sign messages, at least conceptually.&lt;/p&gt;
    &lt;p&gt;You'll only need to know basic math, so abstract algebra is not a requirement. I'll introduce the bare minimum as we go. My exposition will be deliberately unsophisticated, favoring ease of understanding over conciseness and elegance.&lt;/p&gt;
    &lt;p&gt;The reader I have in mind is someone dissatisfied with the many superficial, hand-wavy explanations of ECDSA often found in articles and books aimed at developers and auditors, but who doesn't have the time or interest to go all the way down the rabbit hole and learn cryptography in a thorough and systematic way.&lt;/p&gt;
    &lt;p&gt;If you, like me, work in a field where you need to have a working knowledge of multiple disciplines, you'll probably appreciate this kind of compromise.&lt;/p&gt;
    &lt;p&gt;Finally, this might also serve as an introduction to the topic before you turn to more serious and academic literature.&lt;/p&gt;
    &lt;head rend="h2"&gt;Not your typical article&lt;/head&gt;
    &lt;p&gt;You can think of this section as a kind of disclaimer.&lt;/p&gt;
    &lt;p&gt;This article is the result of an exercise where I start from a vague understanding of a topic and try to connect all the dots and fill in all the gaps on my own, without relying on any external sources of information. This means no books, no LLMs, and no internet.&lt;/p&gt;
    &lt;p&gt;For the exercise to be effective, it needs to be written with an audience in mind, forcing you to keep track of what you've already explained and what you can expect the reader to know. It also helps you do a better job because you feel more exposed.&lt;/p&gt;
    &lt;p&gt;Have you ever gone back to something you learned in the past and realized you forgot most of it? Your knowledge has become sparse and all you remember are some facts disconnected from each other.&lt;/p&gt;
    &lt;p&gt;Can you restore the original picture on your own?&lt;/p&gt;
    &lt;p&gt;If you succeed, your final understanding will be much deeper than the one you'd have if you relied on external help such as books and notes.&lt;/p&gt;
    &lt;p&gt;With this article, I go a step further and try to connect the dots with knowledge that I never had to begin with. The fact that it's possible is what makes mathematical topics so special.&lt;/p&gt;
    &lt;p&gt;That should explain why I wrote it, but why should you read it?&lt;/p&gt;
    &lt;p&gt;Well, you get to read something:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Constructive in nature, since most of the formulas and derivations have to be recreated from scratch.&lt;/item&gt;
      &lt;item&gt;Insightful, since I share some of my intuition and mental models, which is somewhat unusual in more rigorous settings.&lt;/item&gt;
      &lt;item&gt;Naive, as I observe and notice some connections for the first time, possibly making my exposition more engaging but also less polished.&lt;/item&gt;
      &lt;item&gt;Non-authoritative, demanding your full attention and critical thinking to spot inconsistencies.&lt;/item&gt;
      &lt;item&gt;Non-standard, since some facts may be stated or named differently from official literature.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Your role is that of an auditor or verifier, constantly trying to find any inconsistencies and non sequiturs in what I wrote: I'm the generator and you the discriminator. In a (constructively) adversarial setting, this would be an iterative process.&lt;/p&gt;
    &lt;p&gt;It goes without saying that this article is meant to be read linearly, from the start.&lt;/p&gt;
    &lt;head rend="h2"&gt;Modular arithmetic&lt;/head&gt;
    &lt;p&gt;It's all around us:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;15&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;18&lt;/cell&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;21&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;23&lt;/cell&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;25&lt;/cell&gt;
        &lt;cell&gt;26&lt;/cell&gt;
        &lt;cell&gt;27&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;29&lt;/cell&gt;
        &lt;cell&gt;30&lt;/cell&gt;
        &lt;cell&gt;31&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If we're just interested in the day of the week, then the numbers in the same column are equivalent. What do they have in common? The fact that the difference between any two of them is always a multiple of \(7\):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(29-8 = 21 = 3\cdot 7\)&lt;/item&gt;
      &lt;item&gt;\(22-15 = 7\)&lt;/item&gt;
      &lt;item&gt;\(31-17 = 14 = 2\cdot 7\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since numbers in the same column are equivalent, we can represent all of them by the smallest one. Let's call it the representative of the column. If we do that, we end up with \(7\) numbers:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Mon&lt;/cell&gt;
        &lt;cell role="head"&gt;Tue&lt;/cell&gt;
        &lt;cell role="head"&gt;Wed&lt;/cell&gt;
        &lt;cell role="head"&gt;Thu&lt;/cell&gt;
        &lt;cell role="head"&gt;Fri&lt;/cell&gt;
        &lt;cell role="head"&gt;Sat&lt;/cell&gt;
        &lt;cell role="head"&gt;Sun&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That's not ideal for a calendar, but it makes sense: we just add multiples of \(7\) to the starting numbers to recover the missing ones.&lt;/p&gt;
    &lt;p&gt;How do we get the representative from a number? For instance, what's the representative of \(45\)? Well, \(45 = 3 + 7\cdot 6\), so the representative is \(3\). Indeed, starting from \(3\), we add a multiple of \(7\) to get \(45\).&lt;/p&gt;
    &lt;p&gt;Now what's \(3\) with respect to \(45\)? It's the remainder of \(45\) divided by \(7\). We can get that number by using the mod(ulo) operator: \(45\ \mathrm{mod}\ 7 = 3\), or &lt;code&gt;45 % 7 == 3&lt;/code&gt;, in many programming languages.&lt;/p&gt;
    &lt;p&gt;Beware:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In JS: &lt;code&gt;-45 % 7&lt;/code&gt;is \(-3\)&lt;/item&gt;
      &lt;item&gt;In Solidity: &lt;code&gt;-45 % 7&lt;/code&gt;is \(-3\)&lt;/item&gt;
      &lt;item&gt;In Python: &lt;code&gt;-45 % 7&lt;/code&gt;is \(4\)&lt;/item&gt;
      &lt;item&gt;In Math: \(-45\ \mathrm{mod}\ 7\) is \(4\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both values make sense, since they're separated by \(7\) and, thus, in the same column, or equivalence class, i.e. the class of all equivalent elements. But we want the representative, so \(4\) is preferred. Observe that \(-45 = -7\cdot 7 + 4\).&lt;/p&gt;
    &lt;p&gt;Basically, any time we're outside the window \(\{0, \ldots, 6\}\), we add or subtract \(7\) as many times as we need to land in the window.&lt;/p&gt;
    &lt;p&gt;Note that &lt;code&gt;((n % 7) + 7) % 7&lt;/code&gt; will give the representative in any language, since:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;n % 7&lt;/code&gt;is in \(\{-6, -5, \ldots, 0, \ldots, 5, 6\}\)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;(n % 7) + 7&lt;/code&gt;is in \(\{1, \ldots, 13\}\)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;((n % 7) + 7) % 7&lt;/code&gt;is in \(\{0, \ldots, 6\}\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Observe that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;adding \(7\) doesn't change the equivalence class&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;(x % 7) % 7&lt;/code&gt;is just&lt;code&gt;x % 7&lt;/code&gt;. This property is called idempotency (same power): reapplying the operation doesn't increase the extent of the effect, i.e. it gives the same result.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Instead of writing mod operators everywhere, we can say that we're computing mod \(p\):&lt;/p&gt;
    &lt;p&gt;That's equivalent to&lt;/p&gt;
    &lt;p&gt;which is a pain to write.&lt;/p&gt;
    &lt;p&gt;If we're only dealing with addition and multiplication, then we can insert as many "mod \(p\)" as we want wherever we want, so these two expressions are equivalent:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\((123456 \cdot 345678 + 876876234)\ \mathrm{mod}\ p\)&lt;/item&gt;
      &lt;item&gt;\([(((123456\ \mathrm{mod}\ p)\cdot (345678 \ \mathrm{mod}\ p))\ \mathrm{mod}\ p) + (876876234\ \mathrm{mod}\ p)]\ \mathrm{mod}\ p\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's not true for exponentiation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(2^8\ \mathrm{mod}\ 7 = 4\)&lt;/item&gt;
      &lt;item&gt;\(2^{8\ \mathrm{mod}\ 7} = 2^1 = 2\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ECDSA doesn't rely on exponentiation, so we don't need to talk about it.&lt;/p&gt;
    &lt;p&gt;We still don't know how to divide mod \(p\). That is, we don't know how to compute, say, \(3/4\) mod \(p\), or whether it even exists.&lt;/p&gt;
    &lt;p&gt;What does dividing by \(4\) do? It does something that can be reversed by multiplying by \(4\). So the two operations cancel out and are equivalent to multiplying by \(1\), the neutral element. In other words, we must have&lt;/p&gt;
    &lt;p&gt;That's usually written as&lt;/p&gt;
    &lt;p&gt;where \(a^{-1}\) is called the multiplicative inverse of \(a\).&lt;/p&gt;
    &lt;p&gt;As an aside, the additive inverse, or opposite, is simply \(-n\), since \(n + (-n) = 0\), where \(0\) is the neutral element of addition. Of course, we can compute \(-n\ \mathrm{mod}\ p\) to get the representative of \(-n\).&lt;/p&gt;
    &lt;p&gt;Let's find \(x\) such that \(4\cdot x = 1\ (\mathrm{mod}\ 7)\) by using simple brute force:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(4\cdot 0 = 0\)&lt;/item&gt;
      &lt;item&gt;\(4\cdot 1 = 4\)&lt;/item&gt;
      &lt;item&gt;\(4\cdot 2 = 1\)&lt;/item&gt;
      &lt;item&gt;\(4\cdot 3 = 5\)&lt;/item&gt;
      &lt;item&gt;\(4\cdot 4 = 2\)&lt;/item&gt;
      &lt;item&gt;\(4\cdot 5 = 6\)&lt;/item&gt;
      &lt;item&gt;\(4\cdot 6 = 3\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I omitted "\(\left(\mathrm{mod}\ 7\right)\)" for convenience. I'll do that often from now on.&lt;/p&gt;
    &lt;p&gt;As we can see, \(4^{-1} = 2\). That's because \(4\cdot 2 = 8 = 8-7 = 1\).&lt;/p&gt;
    &lt;p&gt;Let's go back to our \(3/4\):&lt;/p&gt;
    &lt;p&gt;Indeed:&lt;/p&gt;
    &lt;p&gt;so we get \(3\) back.&lt;/p&gt;
    &lt;p&gt;An important fact to know is that a number \(a\) is always invertible mod \(p\), as long as it's coprime with \(p\), i.e. their GCD (greatest common divisor) is \(1\).&lt;/p&gt;
    &lt;p&gt;Proof (safely skippable)&lt;/p&gt;
    &lt;p&gt;Let's define \(r_x = a\cdot x\ \mathrm{mod}\ p\). Let \(r\) be the sequence \(r_0, \ldots, r_{p-1}\).&lt;/p&gt;
    &lt;p&gt;Again, I'll omit "mod \(p\)" for notational convenience.&lt;/p&gt;
    &lt;p&gt;If \(r_x = r_y\), i.e. \(a\cdot x = a\cdot y\), then \(a(x-y) = 0\), which means that \(a(x-y)\) is divisible by \(p\). If \(a\) and \(p\) are coprime, then \(x-y\) must be divisible by \(p\), so \(x-y = 0\), i.e. \(x=y\). In other words, \(x\neq y\) implies that \(r_x \neq r_y\).&lt;/p&gt;
    &lt;p&gt;This means that \(r\) has \(p\) distinct values in \(\{0, \ldots, p-1\}\), i.e. \(r\) is a permutation of the sequence \(0, \ldots, p-1\). In particular, \(r\) contains exactly one \(1\), so there's exactly one \(x\) such that \(a\cdot x = 1\).&lt;/p&gt;
    &lt;p&gt;End of proof!&lt;/p&gt;
    &lt;p&gt;As an example, let's look again at the brute-forcing we did above to find \(4^{-1}\ \mathrm{mod}\ 7\) and note that the results are a permutation of the numbers from \(0\) to \(6\), so they contain exactly one \(1\). That's expected since \(4\) and \(7\) are coprime.&lt;/p&gt;
    &lt;p&gt;Observe that when \(p\) is prime, all numbers from \(1\) to \(p-1\) are coprime with it, so they're all invertible.&lt;/p&gt;
    &lt;p&gt;Technically, the set of representatives \(0, \ldots, p-1\) is often denoted by \(\mathbb{Z}_p\) or \(\mathbb{Z}/p\mathbb{Z}\). It's obtained by partitioning the integers into equivalence classes (our calendar columns, but extended to all integers) and representing each class by a representative in \(\{0, \ldots, p-1\}\). That's what we did informally.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extended Euclidean algorithm&lt;/head&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;You can safely skip this section, if you already know or don't care about how the multiplicative inverse can be computed in practice. If you're interested in the method of generating functions you might still want to read the Fibonacci numbers subsection, though.&lt;/p&gt;
    &lt;p&gt;For a fast and practical way to compute the multiplicative inverse, we can use the extended Euclidean algorithm (EEA).&lt;/p&gt;
    &lt;p&gt;The Euclidean algorithm (EA) can be used to efficiently compute \(\mathrm{GCD}(a, p)\), and its extended version returns two integers \(x\) and \(y\) such that&lt;/p&gt;
    &lt;p&gt;If \(a\) and \(p\) are coprime, then&lt;/p&gt;
    &lt;p&gt;This means that \(x\) is the multiplicative inverse of \(a\) mod \(p\).&lt;/p&gt;
    &lt;p&gt;How does the algorithm work? It's very simple.&lt;/p&gt;
    &lt;p&gt;The first observation is that&lt;/p&gt;
    &lt;p&gt;and, by symmetry,&lt;/p&gt;
    &lt;p&gt;We will prove this later.&lt;/p&gt;
    &lt;p&gt;Since we can subtract repeatedly, we can also use the mod operator:&lt;/p&gt;
    &lt;p&gt;This way, we can reduce the two arguments very quickly. Note that in a real implementation we only need one &lt;code&gt;mod&lt;/code&gt; per step, since one of the two has clearly no effect.&lt;/p&gt;
    &lt;p&gt;Let's use it to compute \(\mathrm{GCD}(784, 495)\):&lt;/p&gt;
    &lt;p&gt;The second column shows how we got the new values. Since we obtained \(\mathrm{GCD}(3, 1)\), the GCD is \(1\), i.e. \(784\) and \(495\) are coprime.&lt;/p&gt;
    &lt;p&gt;The extended version of the algorithm uses the second column in a simple way. To start, we notice that the equation at the bottom of the second column is already in the right form, i.e.&lt;/p&gt;
    &lt;p&gt;However, we want the expression with respect to the initial values \(784\) and \(495\).&lt;/p&gt;
    &lt;p&gt;The solution is easy: we just do substitutions as we go up the second column, starting from the bottom:&lt;/p&gt;
    &lt;p&gt;Indeed, \(495\cdot 255 - 784\cdot 161 = 1\).&lt;/p&gt;
    &lt;p&gt;So now we know that \(495\cdot 255 = 1\ (\mathrm{mod}\ 784)\).&lt;/p&gt;
    &lt;p&gt;Now, the only thing missing is to prove that&lt;/p&gt;
    &lt;p&gt;Let me write \(a|b\) to mean that \(a\) divides \(b\), i.e. \(b = ah\) for some integer \(h\).&lt;/p&gt;
    &lt;p&gt;If two numbers divide each other, they must be equal, so we just need to prove that, for any integer \(k\),&lt;/p&gt;
    &lt;p&gt;Indeed, we can then argue that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(\mathrm{GCD}(a, b) \mid \mathrm{GCD}(a, b-a)\)&lt;/item&gt;
      &lt;item&gt;\(\mathrm{GCD}(a, b-a) \mid \mathrm{GCD}(a, (b-a)+a)\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's prove that&lt;/p&gt;
    &lt;p&gt;Let \(d_1\) be the GCD on the left and \(d_2\) the one on the right. It's clear that \(d_1|u\) and \(d_1|v\), which implies that \(d_1|(v+ku)\). Now we'd like to conclude that \(d_1|d_2\).&lt;/p&gt;
    &lt;p&gt;Unfortunately, we only proved that \(d_1\) is a common divisor of \(u\) and \(v+ku\) so far.&lt;/p&gt;
    &lt;p&gt;Let's show that if \(d'\) divides both \(a\) and \(b\), then it also divides \(d = \mathrm{GCD}(a,b)\).&lt;/p&gt;
    &lt;p&gt;Proof (safely skippable)&lt;/p&gt;
    &lt;p&gt;We can always express \(d\) and \(d'\) as&lt;/p&gt;
    &lt;p&gt;where, as indicated, \(u\) and \(v\) are coprime.&lt;/p&gt;
    &lt;p&gt;Observe that if \(u\) and \(v\) weren't coprime, their common divisor would be absorbed by \(\mathrm{GCD}(d, d')\), so we'd have the same situation as above but for \(u'=u/\mathrm{GCD}(u,v)\) and \(v'=v/\mathrm{GCD}(u,v)\).&lt;/p&gt;
    &lt;p&gt;Since \(a\) and \(b\) are divisible by both \(d'\) and \(d\), then \(a' = a/\mathrm{GCD}(d, d')\) and \(b' = b/\mathrm{GCD}(d, d')\) must still be divisible by \(u\) and \(v\). So:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(u k_1 = a' = v k_2\)&lt;/item&gt;
      &lt;item&gt;\(u h_1 = b' = v h_2\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;for some integers \(k_1\), \(k_2\), \(h_1\), and \(h_2\).&lt;/p&gt;
    &lt;p&gt;Since \(u\) and \(v\) are coprime, then \(u|k_2\) and \(u|h_2\), i.e. \(k_2 = u k_3\) and \(h_2 = u h_3\) for some integers \(k_3\) and \(h_3\). Therefore:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(a' = uv k_3\implies a = uv \mathrm{GCD}(d, d') k_3 = ud k_3\)&lt;/item&gt;
      &lt;item&gt;\(b' = uv h_3\implies b = uv \mathrm{GCD}(d, d') h_3 = ud h_3\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This means that \(ud\) is a common divisor of \(a\) and \(b\), and \(u&amp;gt;1\) would imply that we found a greater divisor than \(d\), their GCD.&lt;/p&gt;
    &lt;p&gt;Since \(u = 1\), then \(d' = \mathrm{GCD}(d, d')\), i.e. \(d'|d\).&lt;/p&gt;
    &lt;p&gt;End of proof!&lt;/p&gt;
    &lt;p&gt;I seem to recall that some people include this property in the definition of the GCD itself, but I think that's slightly redundant.&lt;/p&gt;
    &lt;p&gt;Anyway, we're done!&lt;/p&gt;
    &lt;p&gt;Wait! How fast is this algorithm? Let's look at the reduction again:&lt;/p&gt;
    &lt;p&gt;I can see two super Fibonacci sequences. Here's the green one:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Green Seq.&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;206&lt;/cell&gt;
        &lt;cell&gt;289&lt;/cell&gt;
        &lt;cell&gt;495&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Green Mult.&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Fibonacci numbers form a sequence \(F_0, F_1, F_2, \ldots\) where the recurrence relation is \(F_i=F_{i-2}+F_{i-1}\), for \(i=2, 3, \ldots\).&lt;/p&gt;
    &lt;p&gt;In our case, however, the recurrence relation is \(F_i = F_{i-2}+F_{i-1}\cdot M_{i-1}\), where \(F\) is on the first row and \(M\) on the second row of the table.&lt;/p&gt;
    &lt;p&gt;As an example, I highlighted 4 elements in the table: \(206 = 40 + 83\cdot 2\). I call this a super Fibonacci sequence because the multipliers make it grow faster than the regular one (corresponding to all \(M_i=1\)).&lt;/p&gt;
    &lt;p&gt;Fibonacci numbers grow exponentially, so the number of steps necessary to reach a number \(n\) is \(\Theta(\log n)\).&lt;/p&gt;
    &lt;p&gt;Since our sequence is even faster, the number of steps is lower and all we can say for now is that the worst-case complexity of EEA is \(O(\log n)\).&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Technically, \(\Theta\) denotes exact growth, \(O\) denotes an upper bound, and \(\Omega\) denotes a lower bound.&lt;/p&gt;
    &lt;p&gt;For instance, \(n = O(n^2)\) is correct, though in practice people often use \(O\) when they really mean \(\Theta\).&lt;/p&gt;
    &lt;p&gt;Moreover, \(n = O(n^2)\) really means \(n \in O(n^2)\), but the former notation is more common than the latter.&lt;/p&gt;
    &lt;p&gt;Can we think of a very slow sequence? But, of course! We can build it starting from the bottom and always choosing \(M_i=1\):&lt;/p&gt;
    &lt;p&gt;Those are basically two Fibonacci sequences! This tells us that the worst case of the EEA is indeed logarithmic or, to be precise, \(\Theta(\log (\min\{a, b\}))\). Why min? Because we have two sequences: the green and the red one. Since they start and end together, the faster one dominates the other and faster growth means shorter sequence, so the time complexity is \(\Theta(\min\{\log a, \log b\})\), i.e. \(\Theta(\log (\min\{a, b\}))\).&lt;/p&gt;
    &lt;p&gt;I had no idea that the EA had such a connection with the Fibonacci numbers before writing this section. As always, check my reasoning!&lt;/p&gt;
    &lt;head rend="h4"&gt;Fibonacci numbers&lt;/head&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;You can safely skip this section. You don't need it for the rest of the article, but if you want to learn about generating functions, I think this is a good opportunity.&lt;/p&gt;
    &lt;p&gt;I want to find the base for the logarithm that appears in the time complexity of the EA and EEA algorithms.&lt;/p&gt;
    &lt;p&gt;If we assume that Fibonacci numbers grow exponentially, i.e. \(F_i\sim b^i\), then:&lt;/p&gt;
    &lt;p&gt;We divide by \(b^i\) and get \(b^2-b-1 = 0\), whose positive solution is&lt;/p&gt;
    &lt;p&gt;That's the well-known golden ratio.&lt;/p&gt;
    &lt;p&gt;We started from the assumption that the growth is exponential, but what's the exact expression for the \(n\)-th Fibonacci number, just to make sure we're correct?&lt;/p&gt;
    &lt;p&gt;Let \(V_0\) be the vector of Fibonacci numbers \(F_i\):&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;\(V_0:\)&lt;/cell&gt;
        &lt;cell&gt;\(F_0\)&lt;/cell&gt;
        &lt;cell&gt;\(F_1\)&lt;/cell&gt;
        &lt;cell&gt;\(F_2\)&lt;/cell&gt;
        &lt;cell&gt;\(F_3\)&lt;/cell&gt;
        &lt;cell&gt;\(F_4\)&lt;/cell&gt;
        &lt;cell&gt;\(F_5\)&lt;/cell&gt;
        &lt;cell&gt;\(F_6\)&lt;/cell&gt;
        &lt;cell&gt;\(\ldots\)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Now let's introduce the two shifted versions \(V_1\) and \(V_2\):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;\(V_0:\)&lt;/cell&gt;
        &lt;cell&gt;\(F_0\)&lt;/cell&gt;
        &lt;cell&gt;\(F_1\)&lt;/cell&gt;
        &lt;cell&gt;\(F_2\)&lt;/cell&gt;
        &lt;cell&gt;\(F_3\)&lt;/cell&gt;
        &lt;cell&gt;\(F_4\)&lt;/cell&gt;
        &lt;cell&gt;\(F_5\)&lt;/cell&gt;
        &lt;cell&gt;\(F_6\)&lt;/cell&gt;
        &lt;cell&gt;\(\ldots\)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;\(V_1:\)&lt;/cell&gt;
        &lt;cell&gt;\(F_0\)&lt;/cell&gt;
        &lt;cell&gt;\(F_1\)&lt;/cell&gt;
        &lt;cell&gt;\(F_2\)&lt;/cell&gt;
        &lt;cell&gt;\(F_3\)&lt;/cell&gt;
        &lt;cell&gt;\(F_4\)&lt;/cell&gt;
        &lt;cell&gt;\(F_5\)&lt;/cell&gt;
        &lt;cell&gt;\(\ldots\)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;\(V_2:\)&lt;/cell&gt;
        &lt;cell&gt;\(F_0\)&lt;/cell&gt;
        &lt;cell&gt;\(F_1\)&lt;/cell&gt;
        &lt;cell&gt;\(F_2\)&lt;/cell&gt;
        &lt;cell&gt;\(F_3\)&lt;/cell&gt;
        &lt;cell&gt;\(F_4\)&lt;/cell&gt;
        &lt;cell&gt;\(\ldots\)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can see that, from the third column onward, \(V_0 = V_1 + V_2\), because of the relation \(F_{i+2} = F_{i+1} + F_{i}\).&lt;/p&gt;
    &lt;p&gt;The advantage of the vector approach is that we don't have to deal with the index \(i\) anymore. In a sense, we vectorized the loop and abstracted away the annoying index. The drawback is that we lost some algebraic power because, unless we introduce other operations, we don't even know how to express the fact that \(V_1\) is a shifted version of \(V_0\).&lt;/p&gt;
    &lt;p&gt;Instead of reinventing the wheel, why don't we use a power series instead of a simple vector? I'm thinking of something like this:&lt;/p&gt;
    &lt;p&gt;The individual elements are kept separated thanks to the different powers of \(x\), and we inherit lots of algebraic properties from power series!&lt;/p&gt;
    &lt;p&gt;For instance, it's easy to see that \(P_1(x) = x P_0(x)\) and \(P_2(x) = x^2 P_0(x)\).&lt;/p&gt;
    &lt;p&gt;Moreover, we can state algebraically what we observed before:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We can see that, from the third column onward, \(V_0 = V_1 + V_2\), because of the relation \(F_{i+2} = F_{i+1} + F_{i}\).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;With power series, that becomes&lt;/p&gt;
    &lt;p&gt;Note that we simply removed the unwanted terms in the first two columns:&lt;/p&gt;
    &lt;p&gt;To reiterate, we expressed all the following relations at once:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(F_2 = F_1 + F_0\)&lt;/item&gt;
      &lt;item&gt;\(F_3 = F_2 + F_1\)&lt;/item&gt;
      &lt;item&gt;\(F_4 = F_3 + F_2\)&lt;/item&gt;
      &lt;item&gt;\(\ldots\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can now express \(P_1\) and \(P_2\) in terms of \(P_0\). For convenience, let's write \(P\) instead of \(P_0(x)\):&lt;/p&gt;
    &lt;p&gt;Now we solve for \(P\):&lt;/p&gt;
    &lt;p&gt;Since Fibonacci numbers start with \(0\) and \(1\), let's substitute \(F_0=0\) and \(F_1=1\):&lt;/p&gt;
    &lt;p&gt;That's in implicit form. If we can put \(P\) in explicit form, then we can read the expression for the generic coefficient of \(x^i\), which, by construction, is the \(i\)-th Fibonacci number! Here's the form we want:&lt;/p&gt;
    &lt;p&gt;The coefficient \(\alpha_i\) is bound to be a general expression for \(F_i\).&lt;/p&gt;
    &lt;p&gt;How do we do that?&lt;/p&gt;
    &lt;p&gt;Let's take the simplest power series we can think of and find both the explicit and implicit forms for it:&lt;/p&gt;
    &lt;p&gt;We can use the same trick, i.e. the shift:&lt;/p&gt;
    &lt;p&gt;Maybe surprisingly:&lt;/p&gt;
    &lt;p&gt;Written more formally, we proved that&lt;/p&gt;
    &lt;p&gt;We don't care about convergence, as we only want to read the coefficients of the series. As long as what we do is algebraically correct, we should be fine. We might say that we're repurposing some algebraic machinery to do "something else".&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;We say a series converges if it evaluates to a real number. Otherwise, we say it diverges. For instance, the following series clearly converges: $$ \sum_{i=0}^\infty \left(\frac{1}{10}\right)^i = 1 + 0.1 + 0.01 + \ldots = 1.1111\ldots $$&lt;/p&gt;
    &lt;p&gt;In the Fibonacci case, we want to find \(\alpha_i\) such that&lt;/p&gt;
    &lt;p&gt;Now that we've witnessed how the simple case works, we should have more confidence that this method might just work! It might still look like magic, though.&lt;/p&gt;
    &lt;p&gt;How do we close the gap between the simple case and the Fibonacci case?&lt;/p&gt;
    &lt;p&gt;First, we notice that the denominator is factorizable:&lt;/p&gt;
    &lt;p&gt;where&lt;/p&gt;
    &lt;p&gt;These are the same solutions we found for \(b\) at the start of this section, but multiplied by \(-1\).&lt;/p&gt;
    &lt;p&gt;Now we can split the expression into two simpler ones:&lt;/p&gt;
    &lt;p&gt;We just need to find the appropriate \(A\) and \(B\) to get \(-x\) at the numerator:&lt;/p&gt;
    &lt;p&gt;We want \(-x = x(A+B) - c_2 A - c_1 B\), so we must have&lt;/p&gt;
    &lt;p&gt;The solutions are&lt;/p&gt;
    &lt;p&gt;Therefore:&lt;/p&gt;
    &lt;p&gt;If we can convert each of the two parts into explicit form, then we're done, since explicit forms sum nicely: we just sum the corresponding coefficients.&lt;/p&gt;
    &lt;p&gt;Now we divide numerator and denominator of the left part by \(c_1\) and of the right part by \(c_2\):&lt;/p&gt;
    &lt;p&gt;We change some signs:&lt;/p&gt;
    &lt;p&gt;Success:&lt;/p&gt;
    &lt;p&gt;Expanding and simplifying:&lt;/p&gt;
    &lt;p&gt;We can simplify it further, since \(c_1 c_2 = -1\) and \(c_1 - c_2 = \sqrt5\):&lt;/p&gt;
    &lt;p&gt;At last:&lt;/p&gt;
    &lt;p&gt;with&lt;/p&gt;
    &lt;p&gt;Let's check this with the simplest and dumbest Python code possible:&lt;/p&gt;
    &lt;code&gt;from math import sqrt

s5 = sqrt(5)
c1 = (-1 + s5) / 2
c2 = (-1 - s5) / 2

def fib(i):
    return (-1)**i * (c2**i - c1**i)/s5

[int(fib(i)) for i in range(20)]
&lt;/code&gt;
    &lt;p&gt;Fingers crossed:&lt;/p&gt;
    &lt;p&gt;Phew...&lt;/p&gt;
    &lt;p&gt;If we substitute \(c_1\) and \(c_2\) in the formula, we get&lt;/p&gt;
    &lt;p&gt;We obtained the same solutions we found for \(b\), and we get the same asymptotic growth as well.&lt;/p&gt;
    &lt;p&gt;Indeed, the numerator grows as \((1+\sqrt5)^i\):&lt;/p&gt;
    &lt;p&gt;So, \(F_i \sim \frac{\phi^i}{\sqrt5} = \Theta(\phi^i)\), where \(\phi = \frac{1+\sqrt5}{2}\).&lt;/p&gt;
    &lt;p&gt;By the way, \(P(x) = \sum_{i=0}^\infty F_i x^i\) is called a generating function.&lt;/p&gt;
    &lt;head rend="h2"&gt;secp256k1&lt;/head&gt;
    &lt;p&gt;Ethereum's ECDSA uses the elliptic curve secp256k1, defined as&lt;/p&gt;
    &lt;p&gt;where \(p\) is a very big prime number.&lt;/p&gt;
    &lt;p&gt;Here's what the continuous version (i.e. without mod) of the curve looks like:&lt;/p&gt;
    &lt;p&gt;The continuous elliptic curve is the set of all points \((x, y)\) in the plane such that \(y^2 = x^3 + 7\). Because \(y\) is squared, the curve is symmetric about the X-axis, i.e. \((x, y)\) is on the curve if and only if \((x, -y)\) is.&lt;/p&gt;
    &lt;p&gt;When we switch to mod \(p\), things get complicated:&lt;/p&gt;
    &lt;p&gt;To draw that picture I used \(p = 97\), a small prime. The blue line is the continuous curve, while the dots are the solutions in \(\mathbb{Z}_p\times\mathbb{Z}_p\). Note that those solutions must always be finitely many, since they lie on a \(p\times p\) grid.&lt;/p&gt;
    &lt;p&gt;This figure only shows the upper right part (1st quadrant) of the previous one, so we can't see the symmetry of the continuous curve. Yet, the points in \(\mathbb{Z}_p\times\mathbb{Z}_p\) show a new symmetry: they're reflected across the horizontal line \(y = p/2\). That makes sense:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\((x, y)\) lies on the continuous curve if and only if \((x, -y)\) also lies on it.&lt;/item&gt;
      &lt;item&gt;If \(y\in\mathbb{Z}_p\), then \(-y = p-y\).&lt;/item&gt;
      &lt;item&gt;This means that \((x, y)\) lies on the mod curve if and only if \((x, p-y)\) also lies on it.&lt;/item&gt;
      &lt;item&gt;\(y = p-y\) gives us \(y = p/2\). In the figure the axis of symmetry is \(y = 97/2 = 48.5\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's plot the negative solutions as well:&lt;/p&gt;
    &lt;p&gt;As we can see, the part above is identical to the part below, since adding \(p\) or \(-p\) to a coordinate doesn't change anything mod \(p\).&lt;/p&gt;
    &lt;head rend="h2"&gt;Group&lt;/head&gt;
    &lt;p&gt;A group \(G\) is a set of elements equipped with a binary operation, \(+\), such that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For any elements \(a, b\in G\), we must have \(a+b \in G\).&lt;/item&gt;
      &lt;item&gt;There's a neutral element, or identity, \(0\), so that \(a+0 = 0+a = a\) for every \(a\in G\).&lt;/item&gt;
      &lt;item&gt;For every \(a\in G\), there exists an additive inverse, or opposite, of \(a\), denoted as \(-a\), such that \(a+(-a) = (-a)+a = 0\).&lt;list rend="ul"&gt;&lt;item&gt;Note: \(a+(-b)\) can also be written as \(a-b\).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;We also want associativity, i.e., for all \(a,b,c\in G\), we must have \(a + (b+c) = (a+b) + c\). So, we can drop the parentheses and write \(a+b+c\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If for all \(a, b\in G\) we have \(a+b = b+a\), then \(G\) is abelian or commutative.&lt;/p&gt;
    &lt;p&gt;Notice that we can't have two distinct identities \(0_1 \neq 0_2\), since&lt;/p&gt;
    &lt;p&gt;Let's break it down:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(0_1+0_2\) can be simplified in two ways:&lt;list rend="ul"&gt;&lt;item&gt;Since \(0_1\) is an identity, then it disappears, so \(0_1+0_2 = 0_2\)&lt;/item&gt;&lt;item&gt;Since \(0_2\) is an identity, then it disappears, so \(0_1+0_2 = 0_1\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Therefore, the two identities must be equal.&lt;/p&gt;
    &lt;p&gt;The same goes for the additive inverse. If \(x\) and \(y\) are opposites of \(a\) then:&lt;/p&gt;
    &lt;p&gt;That means that:&lt;/p&gt;
    &lt;p&gt;So there's only one inverse per element.&lt;/p&gt;
    &lt;p&gt;Given a subset \(S\) of elements from \(G\), we can define the subgroup \(G_S\) of \(G\) generated by \(S\) as the smallest group that includes all the elements of \(S\). We say that \(S\) is a generator of \(G_S\).&lt;/p&gt;
    &lt;p&gt;In this article we'll only describe in detail the case where \(S\) has just one element. For simplicity, we'll use the same symbol for the subgroup and its generator, so a generator \(G\) generates the (sub)group \(G\) defined as follows:&lt;/p&gt;
    &lt;p&gt;That's very cumbersome to read and write, so let's define&lt;/p&gt;
    &lt;p&gt;Now we can rewrite the definition as&lt;/p&gt;
    &lt;p&gt;or even&lt;/p&gt;
    &lt;p&gt;where we define \(0G = 0\).&lt;/p&gt;
    &lt;head rend="h2"&gt;A group for the elliptic curve&lt;/head&gt;
    &lt;p&gt;ECDSA defines a group over the points on the curve mod \(p\). To do that, we first need to define an addition between points.&lt;/p&gt;
    &lt;p&gt;Here's how it's done on the continuous version of the elliptic curve:&lt;/p&gt;
    &lt;p&gt;If \(P\) and \(Q\) are two points on the curve, then \(P+Q\) is the reflection across the X-axis of the intersection between the curve and the line passing through \(P\) and \(Q\).&lt;/p&gt;
    &lt;p&gt;The line through \(P\) and \(Q\) always intersects the curve at a third point, except when the line is perfectly vertical. In that case, the line is said to intersect the curve at \(0\), called the point at infinity. The point \(0\) acts as the identity, but is not really part of the curve, so it needs to be handled as a special case.&lt;/p&gt;
    &lt;p&gt;Now, observe that the line through \(R = (x, y)\) and \(-R = (x, -y)\) is vertical, so \(R+(-R)=0\), as suggested by the "\(-\)" sign.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;Usually, the point at infinity is denoted by \(\mathcal{O}\) and the origin by \(0 = (0, 0)\). However, since we have no need for the origin in this context, we'll denote the point at infinity by \(0\), stressing the fact that it's the zero of the group.&lt;/p&gt;
    &lt;p&gt;When \(P = Q\), the line through \(P\) and \(Q\) is taken to be the tangent to the curve at \(P\) (or, equivalently, \(Q\)). It makes sense:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Just imagine fixing \(P\) and sliding \(Q\) along the curve from one side of \(P\) to the other.&lt;/item&gt;
      &lt;item&gt;If we want the animation of the line during the sliding to be continuous, the line must be the tangent when \(P = Q\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After all, the animation is continuous when the slope of the line is continuous, and the slope is continuous at a point when it's equal to its limit, i.e. the derivative, at that point.&lt;/p&gt;
    &lt;p&gt;Here's a figure with a fixed point \(P\) and secants through \(P\) and several \(Q_i\) points that converge to \(P\). I chose a color map such that the closer a \(Q_i\) is to \(P\), the bluer the secant through it becomes.&lt;/p&gt;
    &lt;p&gt;By the way, we still count the tangent line as intersecting the elliptic curve in three points, with two coinciding at the point of tangency.&lt;/p&gt;
    &lt;p&gt;But how is it possible that even an "almost vertical" line through two points on the curve always intersects the curve at a third point? Such a line intersects the curve either at a point towards \((+\infty, +\infty)\) or \((+\infty, -\infty)\).&lt;/p&gt;
    &lt;p&gt;For \(x\to+\infty\):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;line:&lt;list rend="ul"&gt;&lt;item&gt;\(y = mx + q \sim mx\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;curve:&lt;list rend="ul"&gt;&lt;item&gt;\(y^2 = x^3 + 7 \sim x^3 \implies\)&lt;list rend="ul"&gt;&lt;item&gt;\(y \sim x^{3/2}\) (upper branch)&lt;/item&gt;&lt;item&gt;\(y \sim -x^{3/2}\) (lower branch)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;\(y^2 = x^3 + 7 \sim x^3 \implies\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What we're saying is that when \(x\) becomes very big, additive terms such as \(q\) and \(7\) are dwarfed and can be ignored, so the line grows like \(mx\), while the curve grows like \(x^{3/2}\). The curve grows asymptotically faster, so, when \(m &amp;gt; 0\), the upper branch of the curve will hit the line from below and cross it sooner or later. Similarly, when \(m &amp;lt; 0\), the lower branch of the curve will hit the line from above and cross it.&lt;/p&gt;
    &lt;p&gt;Here's a visual example for \(m&amp;gt;0\):&lt;/p&gt;
    &lt;head rend="h3"&gt;Finding the intersection point&lt;/head&gt;
    &lt;p&gt;The algebra is easy enough. We just compute the intersection between the curve and the line. Let's start from the two points \(P = (x_P, y_P)\) and \(Q = (x_Q, y_Q)\).&lt;/p&gt;
    &lt;p&gt;If the line is vertical, the third intersection point is \(0\). Otherwise, its equation has the form \(y = mx + q\), where&lt;/p&gt;
    &lt;p&gt;We need to solve for \(x\) and \(y\) the system&lt;/p&gt;
    &lt;p&gt;We substitute the first equation into the second and get&lt;/p&gt;
    &lt;p&gt;Before giving in to despair, we remember that we already know two solutions, \(x_P\) and \(x_Q\), and we're looking for the third point \(-R = (x_{-R}, y_{-R})\). This means that the LHS of the equation in \(x\) must be factorizable as&lt;/p&gt;
    &lt;p&gt;Let's expand it to get&lt;/p&gt;
    &lt;p&gt;The second term is all we need: for the two LHS to be equal, we must have&lt;/p&gt;
    &lt;p&gt;The \(y\) coordinate is simply \(y_{-R} = m x_{-R} + q\).&lt;/p&gt;
    &lt;p&gt;Therefore, the sum of the two points can be computed as&lt;/p&gt;
    &lt;p&gt;As we can see, finding the sum of two points requires subtractions, multiplications, and one division to compute \(m\). To sum two points on the curve mod \(p\), we just need to do the calculations mod \(p\). We know how to "divide" mod \(p\), so we're good.&lt;/p&gt;
    &lt;p&gt;Let's briefly go through the case with \(P=Q=(x,y)\). Recall that we need to consider the tangent to the curve at \((x,y)\). Note that for \(y=0\) the tangent is perfectly vertical, so the result is \(0\) (look at the figure). For \(y\neq 0\), we need to compute the derivative.&lt;/p&gt;
    &lt;p&gt;We start from the equation&lt;/p&gt;
    &lt;p&gt;and derive both sides with respect to \(x\):&lt;/p&gt;
    &lt;p&gt;We solve for the derivative:&lt;/p&gt;
    &lt;p&gt;That's our \(m\).&lt;/p&gt;
    &lt;p&gt;A complete implementation will also handle the (trivial) edge cases with \(P=0\) or \(Q=0\), of course.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why reflect the intersection point&lt;/head&gt;
    &lt;p&gt;Having to reflect the intersection point might seem a little arbitrary at first, but if we think about it, not reflecting it is problematic. Indeed, since the three points lie on the same line, without reflection all the following equations would hold:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(P + Q = R\)&lt;/item&gt;
      &lt;item&gt;\(P + R = Q\)&lt;/item&gt;
      &lt;item&gt;\(Q + R = P\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By summing the first two equations, we'd get \(2P+Q+R=R+Q\), i.e. \(P=0\). Analogously, by summing the last two equations, we'd get \(R=0\). Since \(P=Q=R=0\), that rule would only work for \(0\).&lt;/p&gt;
    &lt;p&gt;The correct rule will look less asymmetric if we think of it as \(P+Q+R=0\), which gives&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(P+Q=-R\)&lt;/item&gt;
      &lt;item&gt;\(P+R=-Q\)&lt;/item&gt;
      &lt;item&gt;\(Q+R=-P\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But what about this point at infinity? Where does it come from? All I know is that it has to do with the so-called projective space.&lt;/p&gt;
    &lt;p&gt;I got somewhat acquainted with that space when I was doing 3D graphics. In 3D, we may add a 4th coordinate, so that \((x, y, z)\) is represented by \((wx, wy, wz, w)\) and some computations become more regular (i.e. with fewer exceptions). At the end, we divide by \(w\) to go back to the usual coordinates.&lt;/p&gt;
    &lt;p&gt;There's also the 2D case when we project a 3D scene onto a 2D screen: \(\pi(x, y, z) = (x/z, y/z)\), where I used \(\pi\) for projection. This has to do with how we perceive the world, so that the farther an object is from us, the smaller it looks (assuming, from our POV, that \(z\) is the distance of the object from us).&lt;/p&gt;
    &lt;head rend="h3"&gt;Projective space&lt;/head&gt;
    &lt;p&gt;Let's say we have some 3D space. We make it projective by imposing that, in general, \((x, y, z) \sim (\lambda x, \lambda y, \lambda z)\) for all \(\lambda\neq 0\), and \((x, y, z)\neq(0, 0, 0)\), where \(\sim\) means equivalent. In words, all non-zero scalings of a non-zero point are equivalent. Those are all the points, origin excluded, on the same line through the origin.&lt;/p&gt;
    &lt;p&gt;The classes partition the punctured (i.e. without the origin) 3D space. The origin, if included, would be in its own singleton class \(\{0\}\) anyway. If we instead allowed \(\lambda = 0\), then two points \(x\) and \(y\) on different lines through the origin would violate the equivalence relation: \(x\sim 0\) and \(y\sim 0\), but \(x\nsim y\).&lt;/p&gt;
    &lt;p&gt;Indeed, an equivalence relation must follow three rules:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reflexivity: \(x\sim x\)&lt;/item&gt;
      &lt;item&gt;symmetry: \(x\sim y\iff y\sim x\)&lt;/item&gt;
      &lt;item&gt;transitivity: \(x\sim y \wedge y\sim z\implies x\sim z\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;where "\(\wedge\)" means "and".&lt;/p&gt;
    &lt;p&gt;To remember the rules, we can just think of equality, which is also an equivalence relation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(a=a\)&lt;/item&gt;
      &lt;item&gt;\(a=b\iff b=a\)&lt;/item&gt;
      &lt;item&gt;\(a=b\wedge b=c\implies a=c\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, if \(x\sim 0\) and \(0\sim y\), then we must have \(x\sim y\). If \(0\) is equivalent to elements that belong to different classes, then it breaks transitivity.&lt;/p&gt;
    &lt;p&gt;Since the origin doesn't belong to the projective space, any generic point \((x, y, z)\) in it is to be considered non-zero.&lt;/p&gt;
    &lt;p&gt;Back to our elliptic equation. On the 2D plane, the equation is \(y^2 = x^3 + 7\), but that won't work in the projective space. Since \((x, y, z)\sim (\lambda x, \lambda y, \lambda z)\), with \(\lambda\neq 0\), we'd like for \((\lambda x, \lambda y, \lambda z)\) to be on the curve whenever \((x, y, z)\) is.&lt;/p&gt;
    &lt;p&gt;Let's write the equation in the projective space as&lt;/p&gt;
    &lt;p&gt;and do the substitution \((X, Y, Z) = (\lambda x, \lambda y, \lambda z)\):&lt;/p&gt;
    &lt;p&gt;We want that to hold whenever \((x, y, z)\) is a solution, i.e. whenever \(y^2 = x^3 + 7\). For that to happen, the equation must factorize as&lt;/p&gt;
    &lt;p&gt;so that when the second factor is \(0\), the equation holds regardless of the factor with \(\lambda\).&lt;/p&gt;
    &lt;p&gt;We still have a \(Z\) to add, so why not use it to balance the degree of the terms? That is:&lt;/p&gt;
    &lt;p&gt;Now the substitution gives&lt;/p&gt;
    &lt;p&gt;We did it, but what about that annoying extra \(z\)? If we want to recover the original equation, we need to set \(z=1\), i.e. we need to restrict ourselves to \((x, y, 1)\).&lt;/p&gt;
    &lt;p&gt;That's perfectly fine, though: the original curve lies on the \(z=1\) plane, while on each \(z=\lambda\) plane, with \(\lambda\neq 0\), lies a \(\lambda\)-scaled version of the original curve:&lt;/p&gt;
    &lt;p&gt;With this setup, we can say that either all the elements of an equivalence class (a punctured line through the origin) are on the curve or none of them are.&lt;/p&gt;
    &lt;p&gt;There's actually an easier way to get the equation in \(x\), \(y\), and \(z\) coordinates. The original 2D curve is embedded in the 3D space by adding a \(z = 1\) coordinate, i.e.&lt;/p&gt;
    &lt;p&gt;Starting from a generic point \((X, Y, Z)\) with \(Z\neq 0\), we can go back to the 2D case by just dividing by \(Z\) and dropping the third coordinate, i.e.&lt;/p&gt;
    &lt;p&gt;Now, let's substitute \(x = X/Z\) and \(y = Y/Z\) into the starting equation and get rid of the denominators:&lt;/p&gt;
    &lt;p&gt;One can also apply other projections. For instance, \(x = X/Z^2\) and \(y = Y/Z^3\) lead to&lt;/p&gt;
    &lt;p&gt;This is actually nicer and used to greatly speed up computations. It's called Jacobian projection.&lt;/p&gt;
    &lt;p&gt;We still haven't solved the mystery of the point at infinity. That was the main reason why we decided to explore projective spaces.&lt;/p&gt;
    &lt;head rend="h4"&gt;Point at infinity&lt;/head&gt;
    &lt;p&gt;We know that a vertical line intersects the planar elliptic curve either at no points at all or at the points \(P\), \(-P\), and \(0\) for some point \(P\), where \(0\) is the so-called point at infinity. Let's try to make sense of it.&lt;/p&gt;
    &lt;p&gt;On the plane, a vertical line has equation \(x = k\), but in our projective space that's the equation of a plane. Like with the elliptic curve, we want to upgrade the equation so that if \((x, y, z)\) is on the line, then so is \((\lambda x, \lambda y, \lambda z)\). We use the same substitution as before:&lt;/p&gt;
    &lt;p&gt;So the equation of the vertical plane becomes \(X = kZ\), which represents a family of \(Z\)-scaled vertical lines. The equation \(X = kZ\) makes sense since, as \(Z\) gets closer to \(0\), the line must also get closer to the origin because everything, curve included, gets scaled down.&lt;/p&gt;
    &lt;p&gt;Let's find the intersections between the curve and the line by solving&lt;/p&gt;
    &lt;p&gt;We substitute the second equation into the first:&lt;/p&gt;
    &lt;p&gt;That can be rewritten as&lt;/p&gt;
    &lt;p&gt;For \(Z\neq 0\), we can divide by \(Z\), so we're left with&lt;/p&gt;
    &lt;p&gt;which gives two solutions for each \(Z\neq 0\) because of that \(Y^2\). Those two solutions correspond to two points \(P\) and \(-P\).&lt;/p&gt;
    &lt;p&gt;For \(Z = 0\), we get \(X = 0\) from the second equation, i.e. the solutions are \((0, \lambda, 0)\) for \(\lambda\neq 0\), which is the Y-axis without the origin. We can take \((0, 1, 0)\) as the representative of that class, which is exactly the point at infinity. As we can see, it doesn't live in any plane with the curve, so it doesn't exist in our original 2D space, but we already knew that.&lt;/p&gt;
    &lt;p&gt;This reminded me that we never designated representatives for the equivalence classes. Let's see:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Each class \(C\) is a punctured line through the origin.&lt;/item&gt;
      &lt;item&gt;If \(C\) intersects the plane \(Z = 1\) at some point \(P = (X, Y, 1)\):&lt;list rend="ul"&gt;&lt;item&gt;\(\mathrm{repr}(C) = P\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Else:&lt;list rend="ul"&gt;&lt;item&gt;\(C\) must lie on the plane \(Z = 0.\)&lt;/item&gt;&lt;item&gt;If \(C\) intersects the line \(\{Y=1; Z=0\}\) at some point \(P = (X, 1, 0)\):&lt;list rend="ul"&gt;&lt;item&gt;\(\mathrm{repr}(C) = P\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Else:&lt;list rend="ul"&gt;&lt;item&gt;\(C\) lies on the X-axis, i.e. \(\{Y = Z = 0\}\).&lt;/item&gt;&lt;item&gt;\(C\) has the form \((X, 0, 0)\).&lt;/item&gt;&lt;item&gt;\(\mathrm{repr}(C) = (1, 0, 0)\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, we have three groups of representatives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\((X, Y, 1)\): on the curve if and only if \(Y^2 = X^3 + 7\).&lt;/item&gt;
      &lt;item&gt;\((X, 1, 0)\): on the curve if and only if \(X = 0\), which gives the point at infinity \((0, 1, 0)\).&lt;/item&gt;
      &lt;item&gt;\((1, 0, 0)\): not on the curve.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Addition in projective space&lt;/head&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;You can safely skip this section!&lt;/p&gt;
    &lt;p&gt;Computing \(m\), the slope of the line through the points \((x_1, y_1)\) and \((x_2, y_2)\), requires a division, which, mod \(p\), is a relatively expensive operation (compared to simple additions and multiplications).&lt;/p&gt;
    &lt;p&gt;Let's recall how to compute the point \((x_3, y_3) = (x_1, y_1) + (x_2, y_2)\), assuming \(x_1\neq x_2\):&lt;/p&gt;
    &lt;p&gt;To go from the plane to the 3D projective space, we proceed as we did before with the elliptic curve and the line equations, i.e. we make the substitution \((x,y) = (X/Z, Y/Z)\).&lt;/p&gt;
    &lt;p&gt;Let's start with \(m\):&lt;/p&gt;
    &lt;p&gt;We define&lt;/p&gt;
    &lt;p&gt;Therefore:&lt;/p&gt;
    &lt;p&gt;Now we deal with \(x_3\):&lt;/p&gt;
    &lt;p&gt;It's \(y_3\)'s turn:&lt;/p&gt;
    &lt;p&gt;We substituted \(X_3\) into \(Y_3\), so we could factor out \(Z_3\), since \(X_3 = Z_3 (\ldots)\).&lt;/p&gt;
    &lt;p&gt;We end up with&lt;/p&gt;
    &lt;p&gt;and by choosing \(Z_3 = D^3 Z_1 Z_2\), we get rid of the denominators:&lt;/p&gt;
    &lt;p&gt;We can clean that up further by defining&lt;/p&gt;
    &lt;p&gt;which results in&lt;/p&gt;
    &lt;p&gt;Note that further micro-optimizations are possible. For instance, we shouldn't compute \(D^2\) and \(D^3\) separately.&lt;/p&gt;
    &lt;p&gt;I hope my calculations are correct, since this is my first time doing them. Either way, I'm satisfied with the result from a pedagogical point of view. I hope you are as well. As we can see, the common denominator was put in \(Z_3\) to avoid intermediate divisions. Now we can add many points together without any division and only do one single division when we want to go back to our 2D plane:&lt;/p&gt;
    &lt;p&gt;That's one slow (at least in \(\mathbb{Z}_p\)) division and 2 fast multiplications.&lt;/p&gt;
    &lt;p&gt;Note that the \(P=Q\) case is handled similarly. Moreover, the same approach will also work for the Jacobian projection, i.e. for \((x, y) = (X/Z^2, Y/Z^3)\).&lt;/p&gt;
    &lt;p&gt;This is almost a philosophical observation. When we substitute \(x\) with \(X/Z\), we're not promoting \(x\) to a fraction, but we're reexpressing it as a fraction, since they're assumed to be equal.&lt;/p&gt;
    &lt;p&gt;For example, if \(x\) is a simple integer in \(\mathbb{Z}\) (without mod) and we replace it with \(X/Z\) where \(X\) and \(Z\) are also in \(\mathbb{Z}\), then we're ranking up from integers to rational numbers, which is a promotion. Indeed, unless \(X\) is divisible by \(Z\) or we're willing to lose some information, we won't be able to go back to \(x\) when the time comes.&lt;/p&gt;
    &lt;p&gt;In the ECDSA case, though, \(x\) is in \(\mathbb{Z}_p\), with \(p\) prime, so \(X/Z\) is also in \(\mathbb{Z}_p\): we're not promoting \(x\) to something more, but just reexpressing it.&lt;/p&gt;
    &lt;p&gt;Let's say we have a huge matrix that can be factorized into two small matrices because it's low-rank (i.e. many of its rows or columns are linear combinations of a selected few). Instead of carrying around the huge matrix during the computations, we may want to keep it in factorized form, \((L, R)\), and then update the factorized form itself:&lt;/p&gt;
    &lt;p&gt;One way to find \(f\) and \(g\) is to do the substitution \(M = LR\) into whatever expression we want to evaluate involving \(M\), and put the result back into factorized form. Note that if we end up with \(L=I\) or \(R=I\) (where \(I\) is the identity matrix), then the factorization is useless for our purposes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to the group&lt;/head&gt;
    &lt;p&gt;ECDSA uses the addition operation we defined above to generate a group from a predetermined generator \(G\). All the considered points are on the curve mod \(p\), meaning that their coordinates are in \(\mathbb{Z}_p\). Here's the group:&lt;/p&gt;
    &lt;p&gt;Notice that \(G\) has only a finite number of elements, which is to be expected since the points lie on a \(p\times p\) grid, which contains \(p^2\) distinct points at most.&lt;/p&gt;
    &lt;p&gt;We start from \(0\) and keep adding \(G\) until we loop, i.e. we get a point that we've already seen. Let's assume this is our current list:&lt;/p&gt;
    &lt;p&gt;We assume we've just looped, so the first \(h\) elements are all distinct, and \(hG = kG\), with \(k &amp;lt; h\).&lt;/p&gt;
    &lt;p&gt;We must have \(0 = hG-kG = (h-k)G\). The only elements in the list that can be 0 are the first one and the last one. Since \(h-k&amp;gt;0\), \((h-k)G\) must be the last element, so \(h-k=h\), which gives \(k=0\). This means that when we loop we restart from \(0\).&lt;/p&gt;
    &lt;p&gt;So we end up with the following group:&lt;/p&gt;
    &lt;p&gt;\(G\) has order \(N\), i.e. it has \(N\) elements. This looping should remind you of \(\mathbb{Z}_N\):&lt;/p&gt;
    &lt;p&gt;Indeed, \(\mathbb{Z}_N\) is also a (commutative) group:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;group operation: \(+\)&lt;/item&gt;
      &lt;item&gt;identity: \(0\)&lt;/item&gt;
      &lt;item&gt;inverse of \(x\): \(-x\)&lt;list rend="ul"&gt;&lt;item&gt;so that \(x + (-x) = (-x) + x = 0\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Moreover, it's generated by \(1\):&lt;/p&gt;
    &lt;p&gt;If we couldn't inspect the single elements, and we just used the group laws, we'd actually be unable to tell \(G\) and \(\mathbb{Z}_N\) apart.&lt;/p&gt;
    &lt;p&gt;For instance, let's say we're given, as programmers, an opaque type &lt;code&gt;Element&lt;/code&gt; together with an identity &lt;code&gt;zero&lt;/code&gt; and an operation &lt;code&gt;add&lt;/code&gt;. Would we be able to tell whether we're working with \(G\) or \(\mathbb{Z}_N\) without looking inside &lt;code&gt;Element&lt;/code&gt; or at the implementation? No, we wouldn't. By defining a common API, we abstracted away the differences.&lt;/p&gt;
    &lt;p&gt;So, we've got ourselves an isomorphism between groups:&lt;/p&gt;
    &lt;p&gt;More formally, let's define \(f: a\mapsto aG\), which is a bijection, i.e. a 1-1 mapping between all the elements of \(\mathbb{Z}_N\) and all the elements of \(G\). This means that we can invert \(f\) and use \(f^{-1}\) to go the other direction (however computationally expensive it is to do).&lt;/p&gt;
    &lt;p&gt;Then the equation above can be rewritten as&lt;/p&gt;
    &lt;p&gt;That means that we can either&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;transform the addends into \(G\)'s elements and then add them up using \(G\)'s addition operation, or&lt;/item&gt;
      &lt;item&gt;sum the addends using \(\mathbb{Z}_N\)'s addition operation and then transform the result into the corresponding element in \(G\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The final result will be the same.&lt;/p&gt;
    &lt;p&gt;Another way of saying this is that we can move back and forth between \(G\) and \(\mathbb{Z}_N\) without losing information.&lt;/p&gt;
    &lt;p&gt;For example, for \(N = 7\):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(3G + 5G = 8G = 7G + G = 0 + G = G\)&lt;list rend="ul"&gt;&lt;item&gt;because \(7G = 0\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;\((3 + 5)G = (8)G = (1)G = G\)&lt;list rend="ul"&gt;&lt;item&gt;because \(8\ \mathrm{mod}\ 7 = 1\)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the first case the looping comes from \(G\), while in the second case it comes from \(\mathbb{Z}_7\). In the second case we only worked inside the parentheses, i.e. with the numbers in \(\mathbb{Z}_7\): we didn't touch \(G\) at all.&lt;/p&gt;
    &lt;p&gt;The idea is to work with numbers in \(\mathbb{Z}_N\), which are easier to work with, and then transform them into points by multiplying them by \(G\). While it's very easy to go from \(k\) to \(kG\), it's computationally infeasible to go back from \(kG\) to \(k\).&lt;/p&gt;
    &lt;p&gt;It shouldn't surprise that ECDSA represents private keys as numbers in \(\mathbb{Z}_N\), and then multiplies them by \(G\) to get the associated public keys. This makes recovering the private key from a public key computationally infeasible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Signing a message&lt;/head&gt;
    &lt;p&gt;I'll cheat a little and read my notes for the signing part of the algorithm:&lt;/p&gt;
    &lt;code&gt;* Message to sign:
    z = 256-bit message digest

* Signature generation (in F_n, i.e. mod n):
    k = rand_unif({1, ..., n-1})        # ephemeral nonce
    R = k * G = (R_x, R_y)
    r = R_x mod n                       # 1st component
    if r = 0, restart and choose a new k
    s = (k^{-1} * (z + r * d)) mod n    # 2nd component [d = account private key]
    if s = 0, restart and choose a new k
    v = R_y mod 2               # AKA recid, recovery_id, or is_y_odd
    signature = (r, s, v)
&lt;/code&gt;
    &lt;p&gt;Let's see:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(G\) is both:&lt;list rend="ul"&gt;&lt;item&gt;the group of points on the elliptic curve (with coordinates in \(\mathbb{Z}_p\), with \(p\) prime)&lt;/item&gt;&lt;item&gt;the generator of that group&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;\(n\), a prime number, is the order of \(G\)&lt;/item&gt;
      &lt;item&gt;\(z\) is the message hash&lt;/item&gt;
      &lt;item&gt;\(d\) is the private key of the account&lt;/item&gt;
      &lt;item&gt;\(k^{-1}\) is the multiplicative inverse mod \(n\), i.e. \(k\cdot k^{-1} = 1\ (\mathrm{mod}\ n)\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that I wrote \(F_n\) or, better, \(\mathbb{F}_n\) instead of \(\mathbb{Z}_n\) because, when \(n\) is prime, the latter is actually a field. The coordinates we've been working with for all this time are in \(\mathbb{Z}_p\), which is also a field, since \(p\) is prime. That's why I wrote "some 3D space" before: depending on which field we choose, we'll end up with a different 3D space.&lt;/p&gt;
    &lt;p&gt;We basically already observed that \(\mathbb{Z}_n\), with \(n\) prime, is a field, but we never spelled it out.&lt;/p&gt;
    &lt;p&gt;That's actually why our math works both in the continuous case and mod \(p\). The theory only requires that the coordinates are elements of a field. It doesn't matter which one.&lt;/p&gt;
    &lt;p&gt;A field \(\mathbb{F}\) is a set equipped with two binary operations, addition and multiplication, such that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(\mathbb{F}\) is a commutative group under addition&lt;/item&gt;
      &lt;item&gt;\(\mathbb{F}\setminus\{0\}\) is a commutative group under multiplication&lt;/item&gt;
      &lt;item&gt;A distributive law holds:&lt;list rend="ul"&gt;&lt;item&gt;(a+b)c = ac + bc&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that \(\mathbb{F}\setminus\{0\}\) means "\(\mathbb{F}\) minus \(\{0\}\)", i.e. \(\mathbb{F}\) without the element \(0\).&lt;/p&gt;
    &lt;p&gt;\(\mathbb{Z}_n\setminus\{0\}\), with \(n\) prime, is a group under multiplication because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiplication is associative: \(a(bc) = (ab)c = abc\).&lt;/item&gt;
      &lt;item&gt;There's an identity: \(1\)&lt;/item&gt;
      &lt;item&gt;Every (non-zero) element \(x\) has inverse, i.e. the famous multiplicative inverse mod \(n\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The \(0\) element has no multiplicative inverse since there's no \(x\) such that \(0\cdot x = 1\). That would be against the very definition of \(0\) as the identity for the addition operation.&lt;/p&gt;
    &lt;p&gt;When \(n\) is not prime, we lose the group under multiplication because the inverse doesn't exist for all elements. For instance, let's consider mod \(6\):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(3\cdot 0 = 0\)&lt;/item&gt;
      &lt;item&gt;\(3\cdot 1 = 3\)&lt;/item&gt;
      &lt;item&gt;\(3\cdot 2 = 0\)&lt;/item&gt;
      &lt;item&gt;\(3\cdot 3 = 3\)&lt;/item&gt;
      &lt;item&gt;\(3\cdot 4 = 0\)&lt;/item&gt;
      &lt;item&gt;\(3\cdot 5 = 3\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since \(3\) and \(6\) are not coprime, \(3\) has no inverse.&lt;/p&gt;
    &lt;p&gt;When \(n\) is not a prime number, \(\mathbb{Z}_n\) is just a (commutative) ring, which has a weaker structure.&lt;/p&gt;
    &lt;p&gt;Well-known examples of fields are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(\mathbb{Q}\): the rational numbers&lt;/item&gt;
      &lt;item&gt;\(\mathbb{R}\): the real numbers&lt;/item&gt;
      &lt;item&gt;\(\mathbb{C}\): the complex numbers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The integers are clearly not a field since, for instance, \(3x = 1\) has no integer solution, so \(3\) has no multiplicative inverse. So, by adding a mod \(p\), with \(p\) prime, we gain more structure, and we get ourselves a field!&lt;/p&gt;
    &lt;p&gt;Back to the algorithm. The first two lines are pretty easy:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We generate a random (uniformly distributed) temporary nonce \(k\) (a number to be used only once ever)&lt;/item&gt;
      &lt;item&gt;We convert \(k\) into the associated point \(R\) on the curve&lt;list rend="ul"&gt;&lt;item&gt;The point has coordinates \((R_x, R_y)\) (mod \(p\))&lt;/item&gt;&lt;item&gt;It's computationally infeasible to go back from \(R\) to \(k\).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Note that \(n &amp;lt; p\), otherwise \(r\) would just be \(R_x\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since \(d\) is the private key, then \(dG\) is the public key. We'll call it \(Q\).&lt;/p&gt;
    &lt;head rend="h2"&gt;Verifying the signature&lt;/head&gt;
    &lt;p&gt;Given \(r\), \(s\), \(Q\), and the message, we can verify the signature by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;hashing the message to get \(z\)&lt;/item&gt;
      &lt;item&gt;recovering \(R\)&lt;/item&gt;
      &lt;item&gt;checking that \(R_x\ \mathrm{mod \ n} = r\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We know that \(R = kG\) and that \(s\) contains \(k\), but in inverse form. If we invert \(s\) and multiply it by \(G\), we get&lt;/p&gt;
    &lt;p&gt;Mhm... if we had \(d\), we could compute \((z+rd)\) and use it to cancel \((z+rd)^{-1}\) and get \(R\).&lt;/p&gt;
    &lt;p&gt;While we don't have \(d\), we do have \(Q = dG\), which means that although we can't compute \((z + rd)\), we can compute \((z + rd)G\):&lt;/p&gt;
    &lt;p&gt;If we multiply that by \(s^{-1}\) we get&lt;/p&gt;
    &lt;p&gt;In words, we factor out \(G\) from \(zG + rQ\) and form \(s^{-1}G\), which is just \((z+rd)^{-1}R\), as we saw at the beginning.&lt;/p&gt;
    &lt;p&gt;We did it! Now we check that \(r = R_x\ \mathrm{mod}\ n\).&lt;/p&gt;
    &lt;p&gt;Here's the algorithm:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;\(w = s^{-1}\ \mathrm{mod}\ n\)&lt;/item&gt;
      &lt;item&gt;\(u_1 = (z\cdot w)\ \mathrm{mod}\ n\)&lt;/item&gt;
      &lt;item&gt;\(u_2 = (r\cdot w)\ \mathrm{mod}\ n\)&lt;/item&gt;
      &lt;item&gt;\(R = u_1\cdot G + u_2\cdot Q\)&lt;/item&gt;
      &lt;item&gt;check that \(r = R_x\ \mathrm{mod}\ n\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Observe that \(((zw)G + (rw)Q)\) is more efficient than \(s^{-1}(zG + rQ)\) because, in the former, \(w\) multiplies two numbers, while, in the latter, \(s^{-1}\) multiplies a point.&lt;/p&gt;
    &lt;head rend="h3"&gt;Recovering \(Q\)&lt;/head&gt;
    &lt;p&gt;Now the only problem is that in Ethereum the public key \(Q\) doesn't come with the signature. However, we can recover it from \(r\), \(s\), and \(v\).&lt;/p&gt;
    &lt;p&gt;As we know, \(Q = dG\) and \(s = k^{-1}(z+rd)\), so we should try multiplying \(s\) by \(G\):&lt;/p&gt;
    &lt;p&gt;To solve for \(Q\), we need to get rid of that \(k^{-1}\). We can't just multiply \(sG\) by \(k\) because we don't know \(k\)... but wait:&lt;/p&gt;
    &lt;p&gt;Therefore:&lt;/p&gt;
    &lt;p&gt;Unfortunately, we don't know \(R\). But can we recover it? We know \(r = R_x\), so we only need to recover \(R_y\), since \(R = (R_x, R_y)\). We're forgetting something, though: \(r = R_x\ \mathrm{mod}\ n\). Recall that the coordinates of the points on the curve are in \(\mathbb{Z}_p\), not \(\mathbb{Z}_n\). We need to recover the original \(R_x\) from \(r\).&lt;/p&gt;
    &lt;p&gt;We know that \(R_x \in \{0, \ldots, p-1\}\), and, apparently, \(n\) is just a little smaller than \(p\), which means that \(R_x = r + jn\) for some very small \(j\). We start from \(j = 0\) and keep trying as long as \(r + jn &amp;lt; p\). We say that \(r + jn\) is a candidate for \(R_x\). Let's call the current candidate simply \(x\).&lt;/p&gt;
    &lt;p&gt;Given \(x\), we can recover \(y\) by using the equation \(y^2 = x^3 + 7\ (\mathrm{mod}\ p)\) itself and solve for \(y\). There are fast algorithms to do that. If there's no solution, we try the next candidate. Otherwise, we get two possible solutions: \(y\) and \(-y\). If you recall, \(v = R_y\ \mathrm{mod}\ 2\), which tells us the solution to pick:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;if \(y\ \mathrm{mod}\ 2 = v\), we choose \(y\)&lt;/item&gt;
      &lt;item&gt;otherwise, we choose \(-y\)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One might wonder why we preserve the least significant bit of \(R_y\) to select the correct \(y\). That's because if \(y\) is in \(\{0, \ldots, p-1\}\), then \(-y\ \mathrm{mod}\ p = p-y\). It's clear that \(y + (p-y) = p\), which is odd (being a big prime), which implies that only one of \(y\) and \(-y\) can be odd (or even) mod \(p\).&lt;/p&gt;
    &lt;p&gt;Anyway, once we have \(R = (x, y)\), we compute \(Q = r^{-1}(sR - zG)\).&lt;/p&gt;
    &lt;p&gt;Now we must check that \(Q\) is valid, i.e. that \(Q\) is on the curve. If it's not, then we try the next candidate.&lt;/p&gt;
    &lt;p&gt;We should actually check that \(Q\) is in \(G\), but, apparently, \(G\) contains all the solutions of \(y^2 = x^3 + 7\ \mathrm{mod}\ p\), so if \(Q\) is on the curve then it's also in \(G\).&lt;/p&gt;
    &lt;head rend="h2"&gt;Signature malleability attack&lt;/head&gt;
    &lt;p&gt;We left this for last, but after all we've been through, this is disappointingly straightforward.&lt;/p&gt;
    &lt;p&gt;If \((r, s, v)\) is a signature created by signing a message \(M\) with a private key \(d\), then so is \((r, n-s, 1-v)\).&lt;/p&gt;
    &lt;p&gt;That's it. The problem arises when someone blacklists \((r, s, v)\) (once it's been used) believing that this will prevent double spending. An attacker will use the signature \((r, n-s, 1-v)\) to send the same message for a second time, bypassing the blacklist.&lt;/p&gt;
    &lt;p&gt;Instead, programs should use nonces contained directly in the messages and blacklist the nonces or the messages themselves.&lt;/p&gt;
    &lt;p&gt;Let's see why both signatures are valid.&lt;/p&gt;
    &lt;p&gt;Let's recall the signing algorithm:&lt;/p&gt;
    &lt;code&gt;* Message to sign:
    z = 256-bit message digest

* Signature generation (in F_n, i.e. mod n):
    k = rand_unif({1, ..., n-1})        # ephemeral nonce
    R = k * G = (R_x, R_y)
    r = R_x mod n                       # 1st component
    if r = 0, restart and choose a new k
    s = (k^{-1} * (z + r * d)) mod n    # 2nd component [d = account private key]
    if s = 0, restart and choose a new k
    v = R_y mod 2               # AKA recid, recovery_id, or is_y_odd
    signature = (r, s, v)
&lt;/code&gt;
    &lt;p&gt;Now let's see what happens if we use \(-k\) instead of \(k\):&lt;/p&gt;
    &lt;p&gt;That is, given the signature computed with \(k\), we can trivially get the one computed with \(-k\).&lt;/p&gt;
    &lt;p&gt;Basically, by using \(-k\) instead of \(k\), we reflect \(R\) across the X-axis and flip \(v\) to signal that we switched the \(y\) coordinate.&lt;/p&gt;
    &lt;head rend="h2"&gt;The end&lt;/head&gt;
    &lt;p&gt;I hope you enjoyed the ride and deepened your understanding of ECDSA as much as I did.&lt;/p&gt;
    &lt;p&gt;If you spot any errors, you're welcome to open an issue or leave a comment below, but keep in mind that the article's nature will remain as stated in the disclaimer.&lt;/p&gt;
    &lt;p&gt;I won't be revisiting this years later unless something truly significant comes up.&lt;/p&gt;
    &lt;p&gt;Until next time!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://avidthinker.github.io/2025/11/28/understanding-ecdsa/"/><published>2025-12-03T04:13:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130335</id><title>Interview with RollerCoaster Tycoon's Creator, Chris Sawyer (2024)</title><updated>2025-12-03T13:09:17.280665+00:00</updated><content/><link href="https://medium.com/atari-club/interview-with-rollercoaster-tycoons-creator-chris-sawyer-684a0efb0f13"/><published>2025-12-03T04:32:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130506</id><title>Sending DMARC reports is somewhat hazardous</title><updated>2025-12-03T13:09:16.754972+00:00</updated><content>&lt;doc fingerprint="6f5c4452e939f3a5"&gt;
  &lt;main&gt;&lt;p&gt;You're probably reading this page because you've attempted to access some part of my blog (Wandering Thoughts) or CSpace, the wiki thing it's part of. Unfortunately you're using a browser (or client library) that my anti-crawler precautions consider suspicious because it's not sending a Sec-Fetch-Mode HTTP header while claiming to be Firefox or Chrome (both of which have been sending that header for a very long time), or another browser that similarly should be sending this header (such as versions of Safari and WebKit from early 2023 onward).&lt;/p&gt;&lt;p&gt;Due to the ongoing problems with abusive high volume crawlers using forged User-Agent values (apparently in part to gather data for LLM training), this combination of browser User-Agent and lack of Sec-Fetch-Mode header is not accepted.&lt;/p&gt;&lt;p&gt;If this is in error and you're using a current version of your browser of choice, you can contact me at my current place at the university (you should be able to work out the email address from that). If possible, please let me know what browser you're using and so on, ideally with its exactl User-Agent string. Please note that I'm unlikely to make an exemption for software that is actively impersonating Chrome or Firefox in its User-Agent, especially if its User-Agent is essentially indistinguishable from a legitimate browser User-Agent string. Crawling software that isn't prepared to admit it is being anti-social, and I am no longer willing to help anti-social software.&lt;/p&gt;Chris Siebenmann, 2025-11-17&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://utcc.utoronto.ca/~cks/space/blog/spam/DMARCSendingReportsProblems"/><published>2025-12-03T05:05:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130784</id><title>Quad9 DOH HTTP/1.1 Retirement, December 15, 2025</title><updated>2025-12-03T13:09:16.100850+00:00</updated><content>&lt;doc fingerprint="3d0d1bd2c90733d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DOH HTTP/1.1 Retirement December 15, 2025&lt;/head&gt;
    &lt;head rend="h1"&gt;Summary&lt;/head&gt;
    &lt;p&gt;Quad9 will be discontinuing support within DNS-over-HTTPS (DOH) using HTTP/1.1 on December 15, 2025. This should have no impact on most users, but there are some older or non-compliant devices or software which may be unsupported after that time with DOH and which will have to revert to unencrypted DNS or shift to DNS-over-TLS.&lt;/p&gt;
    &lt;head rend="h1"&gt;Background&lt;/head&gt;
    &lt;p&gt;Quad9 was the first large-scale recursive resolver to offer standards-based encryption (DNS-over-TLS in 2017). We also provide DNS-over-HTTPS (DOH) as an encryption method, which has been slowly increasing as a percentage of our traffic since standardization and our inclusion of that protocol in 2018. Browsers have been the primary devices operating with DOH, which has some benefits: browsers are updated frequently and are typically kept up to date with newer standards.&lt;/p&gt;
    &lt;p&gt;The DOH standard recommends HTTP/2 as the lowest version of the protocol for use for DOH (https://datatracker.ietf.org/doc/html/rfc8484#section-5.2) but does not rule out using the older HTTP/1.1 standard. We have supported both HTTP/1.1 and HTTP/2 since our inclusion of DOH in our protocol stack seven years ago. However, we are reaching the end of life for the libraries and code that support HTTP/1.1 in our production environment and, therefore, will be sunsetting support for DOH over HTTP/1.1 on December 15, 2025.Â&lt;/p&gt;
    &lt;head rend="h1"&gt;Are you affected?&lt;/head&gt;
    &lt;p&gt;This sunsetting of HTTP/1.1 should not be noticed by the vast majority of our user community who are using Chrome (or any Chromium-based browser or stack), Firefox or Firefox forked projects, Safari (and to our knowledge all other Apple products/apps), or Android and iOS operating systems. They are all fully compliant with our existing and future DOH implementations and, to our knowledge, have always been compliant.&lt;/p&gt;
    &lt;p&gt;If your platform does not work without the older HTTP/1.1 protocol, then we would suggest you upgrade your system or shift to DNS-over-TLS which does not have an HTTP layer. There is always the possibility of moving to unencrypted DNS, but that decision should be closely considered as a downgrade of security and needs to be made carefully if you are in a network environment of higher risk.&lt;/p&gt;
    &lt;p&gt;The only platform that we are aware of directly that has ever used HTTP/1.1 and which will stop working after the sunset date are MikroTik devices that have been configured to use DNS-over-HTTPS, as those devices do not support the modern and recommended HTTP/2 transport protocol. We have communicated this to MikroTik on their support forum (https://forum.mikrotik.com/t/quad9-to-drop-support-for-http-1-1/264174/4), but there has not yet been an announcement by MikroTik as to when they will update their software to this more recent standard. Other than MikroTik, we have no specific knowledge of any other HTTP/1.1 devices or libraries with sizable user communities, though that does not mean there are no IOT devices or software libraries which are using that method.&lt;/p&gt;
    &lt;p&gt;From a geographic perspective, there is a community of users in Brazil who are on HTTP/1.1 which we believe to be MikroTik-based. Due to the fact that we cannot associate queries with users (or even one query with another) it is not easily possible for us to determine what types of devices these are, if not MikroTik, nor is it possible for us to inform those users about the impending change as by design we do not know who they are. We welcome any comments from our Brazilian community from knowledgeable users who can enlighten us as to the reasons for this geographic concentration (please contact support@quad9.net with details).&lt;/p&gt;
    &lt;head rend="h1"&gt;Our Reasoning&lt;/head&gt;
    &lt;p&gt;Despite our large geographic footprint and sizable user community, Quad9 remains a relatively small team. Our limited development efforts are better spent on bringing new features and core stability support to the Quad9 community, and we cannot justify the expense of integrating backwards compatibility for clients that are not meeting the recommended minimum version of protocols. HTTP/2 has been the recommended standard since the publication of the Request for Comments, and we believe this minimization of code is a reasonable step to take when compared with the costs and complexity of backwards compatibility development. In addition, HTTP/1.1 has significant speed and scale challenges, and as time progresses it may be the case that leaving it in our stack would introduce edge-case security or DOS attack vectors which would be difficult to discover and expensive to keep in our testing models.&lt;/p&gt;
    &lt;p&gt;The update allows us to move forward with additional, newer protocol support that we have been testing, which is ready for deployment and is part of a general refresh of our entire platform and system stack. We will have more flexibility and additional protocol support (keep watching this blog area for details), and the refresh also allows us to take better advantage of newer server hardware that we have been deploying worldwide to continue keeping pace with adoption rates.&lt;/p&gt;
    &lt;p&gt;We recognize this will cause inconvenience for some subset of users, and many users will not be aware of the change before it is applied as there is no assured direct method for us to communicate with our end users. This is the double-edged sword of not storing user data: we cannot directly notify everyone of changes.&lt;/p&gt;
    &lt;p&gt;If you know someone who will be impacted, please share and encourage them to take the necessary steps now to avoid interruption of service.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://quad9.net/news/blog/doh-http-1-1-retirement/"/><published>2025-12-03T06:07:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130907</id><title>Researchers Find Microbe Capable of Producing Oxygen from Martian Soil</title><updated>2025-12-03T13:09:15.288609+00:00</updated><content>&lt;doc fingerprint="a38e904b38a1646a"&gt;
  &lt;main&gt;
    &lt;p&gt;When we talk about the possibility of humans living on Mars, one of the biggest challenges is not the rockets or the habitats, but something far more basic: how to breathe. Carrying oxygen tanks across space is not practical for long-term survival. This is where a tiny microbe might make a huge difference.&lt;/p&gt;
    &lt;p&gt;Scientists have been studying an extremophile, a type of microorganism that can survive in very harsh environments. This particular one is known as Chroococcidiopsis. It has shown the ability to grow on materials that are similar to Martian soil, and in the process, it produces oxygen. That means if it can be cultivated in future Mars colonies, it could support human breathing needs directly on the Red Planet.&lt;/p&gt;
    &lt;p&gt;Researchers tested this by using soil that mimics Martian regolith. The results were promising. The bacteria did not just survive, it actively thrived, pulling nutrients from the soil and releasing oxygen as part of its natural process. What makes it even more interesting is that it does not require rich Earth-like soil to function. Even in the limited resources available on Mars, it can manage to carry out its work.&lt;/p&gt;
    &lt;p&gt;Also Read: Mars Ice Could Preserve Traces of Ancient Life, Study Suggests&lt;/p&gt;
    &lt;p&gt;The experiments also showed that these microbes can survive extreme conditions such as radiation and low pressure that would normally be deadly to most life. Even when their DNA was damaged by radiation, they were able to repair it after rehydration and continue functioning normally, with no lasting increase in mutations. This resilience is what defines them as extremophiles, organisms that have evolved to survive where most others cannot.&lt;/p&gt;
    &lt;p&gt;For space scientists and planners, this is a big step. If humans ever build bases on Mars, they will need systems that can provide oxygen without constant resupply from Earth. Carrying oxygen would be costly and dangerous, while producing it locally would make settlements more realistic. A living system using microbes might offer a natural and renewable source.&lt;/p&gt;
    &lt;p&gt;This does not mean the problem is solved. There are still challenges ahead. One is how to grow these organisms at scale in Martian conditions. Another is how to protect them and keep them productive in an environment that is far more unstable than Earth. But the fact that they can survive in laboratory simulations of Mars is an important first step.&lt;/p&gt;
    &lt;p&gt;There is also a wider question. If such microbes can survive on Mars-like conditions, does that mean life could exist elsewhere in the solar system? Extremophiles on Earth already show us that life can adapt to the most unlikely places — from boiling hot springs to the depths of ice. This experiment adds to the evidence that life is resilient and flexible.&lt;/p&gt;
    &lt;p&gt;For now, the practical focus remains on human needs. Space agencies and researchers are interested in creating closed-loop systems where food, water, and oxygen can all be recycled and produced on site. Using microbes for oxygen production could become one part of that system.&lt;/p&gt;
    &lt;p&gt;It is too early to say whether this specific cyanobacterium will be the final answer. But it shows a direction for research and gives hope that we may not need to carry every breath of oxygen from Earth. Instead, we may be able to “farm” our oxygen directly on another planet.&lt;/p&gt;
    &lt;p&gt;Story Source: Universe Today&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scienceclock.com/microbe-that-could-turn-martian-dust-into-oxygen/"/><published>2025-12-03T06:34:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46131406</id><title>Zig quits GitHub, says Microsoft's AI obsession has ruined the service</title><updated>2025-12-03T13:09:15.029268+00:00</updated><content>&lt;doc fingerprint="8e14b4d14f364afe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zig quits GitHub, says Microsoft's AI obsession has ruined the service&lt;/head&gt;
    &lt;head rend="h2"&gt;Zig prez complains about 'vibe-scheduling' after safe sleep bug goes unaddressed for eons&lt;/head&gt;
    &lt;p&gt;The Foundation that promotes the Zig programming language has quit GitHub due to what its leadership perceives as the code sharing site's decline.&lt;/p&gt;
    &lt;p&gt;The drama began in April 2025 when GitHub user AlekseiNikiforovIBM started a thread titled “safe_sleep.sh rarely hangs indefinitely.” GitHub addressed the problem in August, but didn’t reveal that in the thread, which remained open until Monday.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The code uses 100 percent CPU all the time, and will run forever&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That timing appears notable. Last week, Andrew Kelly, president and lead developer of the Zig Software Foundation, announced that the Zig project is moving to Codeberg, a non-profit git hosting service, because GitHub no longer demonstrates commitment to engineering excellence.&lt;/p&gt;
    &lt;p&gt;One piece of evidence he offered for that assessment was the “safe_sleep.sh rarely hangs indefinitely” thread.&lt;/p&gt;
    &lt;p&gt;"Most importantly, Actions has inexcusable bugs while being completely neglected," Kelly wrote. "After the CEO of GitHub said to 'embrace AI or get out', it seems the lackeys at Microsoft took the hint, because GitHub Actions started 'vibe-scheduling' – choosing jobs to run seemingly at random. Combined with other bugs and inability to manually intervene, this causes our CI system to get so backed up that not even master branch commits get checked."&lt;/p&gt;
    &lt;head rend="h3"&gt;Older and deeper&lt;/head&gt;
    &lt;p&gt;Kelly’s gripe seems justified, as the bug discussed in the thread appears to have popped up following a code change in February 2022 that users flagged in prior bug reports.&lt;/p&gt;
    &lt;p&gt;The code change replaced instances of the posix "sleep" command with a "safe_sleep" script that failed to work as advertised. It was supposed to allow the GitHub Actions runner – the application that runs a job from a GitHub Actions workflow – to pause execution safely.&lt;/p&gt;
    &lt;p&gt;"The bug in this 'safe sleep' script is obvious from looking at it: if the process is not scheduled for the one-second interval in which the loop would return (due to $SECONDS having the correct value), then it simply spins forever," wrote Zig core developer Matthew Lugg in a comment appended to the April bug thread.&lt;/p&gt;
    &lt;p&gt;"That can easily happen on a CI machine under extreme load. When this happens, it's pretty bad: it completely breaks a runner until manual intervention. On Zig's CI runner machines, we observed multiple of these processes which had been running for hundreds of hours, silently taking down two runner services for weeks."&lt;/p&gt;
    &lt;p&gt;The fix was merged on August 20, 2025, from a separate issue opened back in February 2024. The related bug report from April 2025 remained open until Monday, December 1, 2025. A separate CPU usage bug remains unresolved.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsoft appears to move on from its most loyal 'customers' – Contoso and Fabrikam&lt;/item&gt;
      &lt;item&gt;UK gov blames budget leak on misconfigured WordPress plugin, server&lt;/item&gt;
      &lt;item&gt;Google Antigravity vibe-codes user's entire drive out of existence&lt;/item&gt;
      &lt;item&gt;OpenAI cuts off Mixpanel after analytics leak exposes API users&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Jeremy Howard, co-founder of Answer.AI and Fast.AI, said in a series of social media posts that users’ claims about GitHub Actions being in a poor state of repair appear to be justified.&lt;/p&gt;
    &lt;p&gt;"The bug," he wrote, "was implemented in a way that, very obviously to nearly anyone at first glance, uses 100 percent CPU all the time, and will run forever unless the task happens to check the time during the correct second."&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I can't see how such an extraordinary collection of outright face-palming events could be made&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;He added that the platform-independent fix for the CPU issue proposed last February lingered for a year without review and was closed by the GitHub bot in March 2025 before being revived and merged.&lt;/p&gt;
    &lt;p&gt;"Whilst one could say that this is just one isolated incident, I can't see how such an extraordinary collection of outright face-palming events could be made in any reasonably functioning organization," Howard concluded.&lt;/p&gt;
    &lt;p&gt;GitHub did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;While Kelly has gone on to apologize for the incendiary nature of his post, Zig is not the only software project publicly parting ways with GitHub.&lt;/p&gt;
    &lt;p&gt;Over the weekend, Rodrigo Arias Mallo, creator of the Dillo browser project, said he's planning to move away from GitHub owing to concerns about over-reliance on JavaScript, GitHub's ability to deny service, declining usability, inadequate moderation tools, and "over-focusing on LLMs and generative AI, which are destroying the open web (or what remains of it) among other problems."&lt;/p&gt;
    &lt;p&gt;Codeberg, for its part, has doubled its supporting membership since January, going from more than 600 members to over 1,200 as of last week.&lt;/p&gt;
    &lt;p&gt;GitHub has not disclosed how many of its users pay for its services presently. The code hosting biz had "over 1.3 million paid GitHub Copilot subscribers, up 30 percent quarter-over-quarter," Microsoft CEO Satya Nadella said on the company's Q2 2024 earnings call.&lt;/p&gt;
    &lt;p&gt;In Q4 2024, when GitHub reported an annual revenue run rate of $2 billion, GitHub Copilot subscriptions accounted for about 40 percent of the company's annual revenue growth.&lt;/p&gt;
    &lt;p&gt;Nadella offered a different figure during Microsoft's Q3 2025 earnings call: "we now have over 15 million GitHub Copilot users, up over 4X year-over-year." It's not clear how many GitHub users pay for Copilot, or for runner scripts that burned CPU cycles when they should have been sleeping. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2025/12/02/zig_quits_github_microsoft_ai_obsession/"/><published>2025-12-03T07:52:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133068</id><title>India scraps order to pre-install state-run cyber safety app on smartphones</title><updated>2025-12-03T13:09:14.873416+00:00</updated><content>&lt;doc fingerprint="ec1e939cfca1d778"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;India scraps order to pre-install state-run cyber safety app on smartphones&lt;/head&gt;
    &lt;p&gt;India has scrapped an order making it mandatory for smartphone makers to preload a state-run cyber safety app on new phones after a public furore.&lt;/p&gt;
    &lt;p&gt;The order gave smartphone makers 90 days to pre-load new phones with its new Sanchar Saathi app which could not be "disabled or restricted", sparking privacy and surveillance concerns.&lt;/p&gt;
    &lt;p&gt;The government argued the move was necessary to verify the authenticity of handsets, but cybersecurity experts said it impinged on citizens' right to privacy.&lt;/p&gt;
    &lt;p&gt;Withdrawing the order on Wednesday, the government cited the app's "increasing acceptance". It came after Apple and Samsung had reportedly resisted the directive to pre-install it on their devices.&lt;/p&gt;
    &lt;p&gt;So far 14 million users have downloaded the app, reporting 2,000 frauds daily, and on Tuesday alone 600,000 new users registered - a tenfold spike, according to India's telecom ministry.&lt;/p&gt;
    &lt;p&gt;But the order - passed last week but made public on Monday - to make the registration mandatory had led to a major backlash from several cybersecurity experts.&lt;/p&gt;
    &lt;p&gt;Smartphone giants like Apple and Samsung also resisted the directive to pre-install the app on their phones.&lt;/p&gt;
    &lt;p&gt;Sources told the BBC the companies were concerned the directive was issued without prior consultation and challenged user privacy norms.&lt;/p&gt;
    &lt;p&gt;While the order has now been withdrawn, India's Minister of Communications Jyotiraditya Scindia dismissed concerns that the app could be used to increase surveillance.&lt;/p&gt;
    &lt;p&gt;"Snooping is neither possible nor will it happen with the Sanchar Saathi safety app," Scindia said.&lt;/p&gt;
    &lt;p&gt;The government's decision to reverse the order was welcomed by digital advocacy groups.&lt;/p&gt;
    &lt;p&gt;"This is a welcome development, but we are still awaiting the full text of the legal order that should accompany this announcement, including any revised directions under the Cyber Security Rules, 2024," the Internet Freedom Foundation said on X.&lt;/p&gt;
    &lt;p&gt;"For now, we should treat this as cautious optimism, not closure, until the formal legal direction is published and independently confirmed."&lt;/p&gt;
    &lt;p&gt;Follow BBC News India on Instagram, YouTube, Twitter and Facebook.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/clydg2re4d1o"/><published>2025-12-03T11:06:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133422</id><title>The "Mad Men" in 4K on HBO Max Debacle</title><updated>2025-12-03T13:09:14.669063+00:00</updated><content>&lt;doc fingerprint="212590f01322d0f9"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Reader warning: there's gonna be a lot of pretend puke photos in this post.&lt;/p&gt;
      &lt;p&gt;If you've fired up HBO Max recently, you've probably seen that one of the most influential and prestigious television series of all time was to premiere in 4K on the streaming service. The show's first four seasons were shot on film, and the final three were shot digitally on the Alexa, but the run of the series was mastered in 1080p HD. HBO Max has been touting this 4K "restoration" of the series, produced by Lionsgate TV. &lt;/p&gt;
      &lt;p&gt;The highly anticipated 4K debut of the show was to be one of HBO Max' crown jewels of television history. It looks like it might initially serve as a cautionary tale of quality control when it comes to restorations and the technical process of bringing shows to streaming.&lt;/p&gt;
      &lt;div&gt;&lt;p&gt;As far as I can tell, &lt;/p&gt;Paul Haine was the first to notice something weird&lt;p&gt; going on with HBO Max' presentation. In one of season one's most memorable moments, Roger Sterling barfs in front of clients after climbing many flights of stairs. As a surprise to Paul, you can clearly see the pretend puke hose (that is ultimately strapped to the back side of John Slattery's face) in the background, along with two techs who are modulating the flow. Yeah, you're not supposed to see that.&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;It appears as though this represents the original photography, unaltered before digital visual effects got involved. Somehow, this episode (along with many others) do not include all the digital visual effects that were in the original broadcasts and home video releases. It's a bizarro mistake for Lionsgate and HBO Max to make and not discover until after the show was streaming to customers.&lt;/p&gt;
      &lt;div&gt;&lt;p&gt;I want to be clear that this is a separate issue than the "reframed original film negative for 16:9" issue that has plagued many restorations that have left viewers scratching their heads. In those cases, the shows were originally shot on film and presented in 1.33-to-1 aspect ratio, but for their HD restorations the studio decided that their shows should fill the HD frame at the 16:9 aspect ratio, so portions of the negative, previously unseen and NOT intended for broadcast, were now suddenly visible, &lt;/p&gt;sometimes leading to ridiculous images that were never meant to be seen by audiences&lt;p&gt;...&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;example from "Friends" in HD, look at screen right&lt;/p&gt;
      &lt;p&gt;example from "Seinfeld" in HD&lt;/p&gt;
      &lt;p&gt;Reframing old shows to fit a new aspect ratio is antithetical to the spirit of media restoration, and cheapens the future of our shared culture. The folks at the studios who insist on hobbling their most classic television shows are really bad at their jobs.&lt;/p&gt;
      &lt;p&gt;But that's NOT what is going on with "Mad Men", since the show was mastered in 16:9 to begin with. &lt;/p&gt;
      &lt;div&gt;I decided to help illustrate the changes&lt;p&gt; by diving in and creating images that might do better than words. The first thing I noticed is that, at least for season one, the episode titles and order were totally jumbled. The puke episode is "Red in the Face", not "Babylon".&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;Update: the season one episodes are being updated live on HBO Max to their correct positions and titles. The corrected title:&lt;/p&gt;
      &lt;p&gt;I lined up the Blu-ray edition of the episode with the current HBO Max episode:&lt;/p&gt;
      &lt;p&gt;The fun thing about this restoration mistake is that now we, the audience, get to see exactly how many digital visual effects were actually used in a show like "Mad Men", which most would assume did not have any digital effects component. In this shot, not only were the techs and hose removed, but the spot where the pretend puke meets Slattery's face has some clever digital warping to make it seem like the flow is truly coming from his mouth (as opposed to it appearing through a tube inches from his mouth, on the other side of his face).&lt;/p&gt;
      &lt;div&gt;A Twitter user noticed&lt;p&gt; that the post-production screwups are not exclusive to season one, so I fired up my comparison machine to illustrate it.&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;In this case, visual effects was used to obscure the fact that the show was filmed in 2000's era Los Angeles, not in 1960's New York City. Every sign was altered, and period-appropriate garbage NYC garbage cans were also added to each side of the frame.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://fxrant.blogspot.com/2025/12/the-mad-men-in-4k-on-hbo-max-debacle.html"/><published>2025-12-03T11:50:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133622</id><title>You Can't Fool the Optimizer</title><updated>2025-12-03T13:09:14.342780+00:00</updated><content>&lt;doc fingerprint="a429e90ffa511a5c"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by me, proof-read by an LLM. &lt;lb/&gt;Details at end.&lt;/p&gt;
    &lt;p&gt;Sometimes you’ll step through code in a debugger and find a complex-looking loop… that executes as a single instruction. The compiler saw through the obfuscation and generated the obvious code anyway.&lt;/p&gt;
    &lt;p&gt;Consider this assortment of highly questionable unsigned addition routines1 - for variety, here compiled for ARM (unlike yesterday’s addition example).&lt;/p&gt;
    &lt;p&gt;Despite these all being very different ways of returning &lt;code&gt;x + y&lt;/code&gt;, the compiler sees through it all and recognises that it’s just a single &lt;code&gt;add w0, w1, w0&lt;/code&gt;2 instruction. Even the recursive &lt;code&gt;add_v4&lt;/code&gt; - which calls itself - gets optimised down to the same single instruction3.&lt;/p&gt;
    &lt;p&gt;The compiler’s ability to recognise patterns and replace them with efficient alternatives - even when the code is pretty obfuscated - is a superpower. It lets programmers choose how to write their code that’s intention-revealing (not like these contrived examples, obviously!) and leave the code generation up to the compiler, knowing that most of the time it’ll do the right thing.&lt;/p&gt;
    &lt;p&gt;So how does the compiler spot these patterns? Is it maintaining a database of “silly ways to add numbers”? Not quite. Internally, it translates your code into an intermediate representation - a simplified, abstract form that’s easier to analyse. When the compiler sees the while loop in &lt;code&gt;add_v3&lt;/code&gt;, it transforms it into something like “increment y by x, then return y”, which it then recognises as mathematically equivalent to “return x + y”. This process of converting different code patterns into a standard, canonical form is what lets the compiler treat them all identically. By the time code generation happens, all four functions look the same to the optimiser4.&lt;/p&gt;
    &lt;p&gt;This pattern recognition is remarkably robust - the compiler will happily optimise code you’d never want to write in the first place. Throughout this series we’ll see how far this canonicalisation can take us.&lt;/p&gt;
    &lt;p&gt;See the video that accompanies this post.&lt;/p&gt;
    &lt;p&gt;This post is day 3 of Advent of Compiler Optimisations 2025, a 25-day series exploring how compilers transform our code.&lt;/p&gt;
    &lt;p&gt;This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.&lt;/p&gt;
    &lt;p&gt;Support Compiler Explorer on Patreon or GitHub, or by buying CE products in the Compiler Explorer Shop.&lt;/p&gt;
    &lt;p&gt;Thanks to long-term Compiler Explorer Patron Greg Baker for this example. ↩&lt;/p&gt;
    &lt;p&gt;ARM supports three operands, so you should read this as &lt;code&gt;w0 = w1 + w0&lt;/code&gt;. ↩&lt;/p&gt;
    &lt;p&gt;We’ll cover tail-call optimisation and how it enables this later in the series. ↩&lt;/p&gt;
    &lt;p&gt;You can “Open in Compiler Explorer” the example above and then experiment with the “Opt Pipeline Viewer” to see some of the ways the compiler is doing this. ↩&lt;/p&gt;
    &lt;p&gt;Matt Godbolt is a C++ developer living in Chicago. He works for Hudson River Trading on super fun but secret things. He is one half of the Two's Complement podcast. Follow him on Mastodon or Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xania.org/202512/03-more-adding-integers"/><published>2025-12-03T12:14:34+00:00</published></entry></feed>