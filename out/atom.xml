<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-04T11:10:38.128342+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46137783</id><title>Micron Announces Exit from Crucial Consumer Business</title><updated>2025-12-04T11:10:45.534454+00:00</updated><content>&lt;doc fingerprint="c9a9907d4cbbb1ea"&gt;
  &lt;main&gt;
    &lt;p&gt;BOISE, Idaho, Dec. 03, 2025 (GLOBE NEWSWIRE) -- Micron Technology, Inc. (Nasdaq: MU), a leader in innovative memory and storage solutions, today announced its decision to exit the Crucial consumer business, including the sale of Crucial consumer-branded products at key retailers, e-tailers and distributors worldwide.&lt;/p&gt;
    &lt;p&gt;Micron will continue Crucial consumer product shipments through the consumer channel until the end of fiscal Q2 (February 2026). The company will work closely with partners and customers through this transition and will provide continued warranty service and support for Crucial products. Micron will continue to support the sale of Micron-branded enterprise products to commercial channel customers globally.&lt;/p&gt;
    &lt;p&gt;“The AI-driven growth in the data center has led to a surge in demand for memory and storage. Micron has made the difficult decision to exit the Crucial consumer business in order to improve supply and support for our larger, strategic customers in faster-growing segments,” said Sumit Sadana, EVP and Chief Business Officer at Micron Technology. “Thanks to a passionate community of consumers, the Crucial brand has become synonymous with technical leadership, quality and reliability of leading-edge memory and storage products. We would like to thank our millions of customers, hundreds of partners and all of the Micron team members who have supported the Crucial journey for the last 29 years.”&lt;/p&gt;
    &lt;p&gt;This decision reflects Micron’s commitment to its ongoing portfolio transformation and the resulting alignment of its business to secular, profitable growth vectors in memory and storage. By concentrating on core enterprise and commercial segments, Micron aims to improve long-term business performance and create value for strategic customers as well as stakeholders.&lt;/p&gt;
    &lt;p&gt;Micron intends to reduce impact on team members due to this business decision through redeployment opportunities into existing open positions within the company.&lt;/p&gt;
    &lt;p&gt;About Micron Technology, Inc.&lt;/p&gt;
    &lt;p&gt;Micron Technology, Inc. is an industry leader in innovative memory and storage solutions, transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence (AI) and compute-intensive applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience. To learn more about Micron Technology, Inc. (Nasdaq: MU), visit micron.com.&lt;/p&gt;
    &lt;p&gt;Forward-Looking Statements&lt;/p&gt;
    &lt;p&gt;This press release contains forward-looking statements, including statements regarding product supply and support, areas of growth and profitability, and workforce redeployment. These forward-looking statements are subject to a number of risks and uncertainties that could cause actual results to differ materially. Please refer to the documents Micron files with the Securities and Exchange Commission, specifically its most recent Form 10-K and Form 10-Q. These documents contain and identify important factors that could cause actual results to differ materially from those contained in these forward-looking statements. These certain factors can be found at https://investors.micron.com/risk-factor. Although Micron believes that the expectations reflected in the forward-looking statements are reasonable, Micron cannot guarantee future results, levels of activity, or achievements. Micron is under no duty to update any of the forward-looking statements after the date of this press release to conform these statements to actual results.&lt;/p&gt;
    &lt;p&gt;© 2025 Micron Technology, Inc. All rights reserved. Information, products, and/or specifications are subject to change without notice. Micron, the Micron logo, and all other Micron trademarks are the property of Micron Technology, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;
    &lt;p&gt;Micron Media Relations Contact&lt;lb/&gt;Mark Plungy&lt;lb/&gt;+1 (408) 203-2910&lt;lb/&gt;corpcomms@micron.com &lt;lb/&gt;Micron Investor Relations Contact&lt;lb/&gt;Satya Kumar&lt;lb/&gt;+1 (408) 450-6199&lt;lb/&gt;satyakumar@micron.com &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://investors.micron.com/news-releases/news-release-details/micron-announces-exit-crucial-consumer-business"/><published>2025-12-03T18:04:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138238</id><title>Ghostty is now non-profit</title><updated>2025-12-04T11:10:45.436083+00:00</updated><content>&lt;doc fingerprint="af5a505b2f305666"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;Ghostty Is Now Non-Profit&lt;/head&gt;
    &lt;p&gt;Ghostty is now fiscally sponsored by Hack Club, a registered 501(c)(3) non-profit.&lt;/p&gt;
    &lt;p&gt;Fiscal sponsorship is a legal and financial arrangement in which a recognized non-profit extends its tax-exempt status to a project that aligns with its mission. This allows Ghostty to operate as a charitable initiative while Hack Club manages compliance, donations, accounting, and governance oversight.&lt;/p&gt;
    &lt;p&gt;Being non-profit clearly demonstrates our commitment to keeping Ghostty free and open source for everyone. It paves the way for a model for sustainable development beyond my personal involvement. And it also provides important legal protections and assurances to the people and communities that adopt and use Ghostty.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why a Non-Profit?&lt;/head&gt;
    &lt;p&gt;Since the beginning of the project in 2023 and the private beta days of Ghostty, I've repeatedly expressed my intention that Ghostty legally become a non-profit. This intention stems from several core beliefs I have.&lt;/p&gt;
    &lt;p&gt;First, I want to lay bricks for a sustainable future for Ghostty that doesn't depend on my personal involvement technically or financially. Financially, I am still the largest donor to the project, and I intend to remain so, but a non-profit structure allows others to contribute financially without fear of misappropriation or misuse of funds (as protected by legal requirements and oversight from the fiscal sponsor).&lt;/p&gt;
    &lt;p&gt;Second, I want to squelch any possible concerns about a "rug pull". A non-profit structure provides enforceable assurances: the mission cannot be quietly changed, funds cannot be diverted to private benefit, and the project cannot be sold off or repurposed for commercial gain. The structure legally binds Ghostty to the public-benefit purpose it was created to serve.&lt;/p&gt;
    &lt;p&gt;Finally, despite being decades-old technology, terminals and terminal-related technologies remain foundational to modern computing and software infrastructure. They're often out of the limelight, but they're ever present on developer machines, embedded in IDEs, visible as read-only consoles for continuous integration and cloud services, and still one of the primary ways remote access is done on servers around the world.&lt;/p&gt;
    &lt;p&gt;I believe infrastructure of this kind should be stewarded by a mission-driven, non-commercial entity that prioritizes public benefit over private profit. That structure increases trust, encourages adoption, and creates the conditions for Ghostty to grow into a widely used and impactful piece of open-source infrastructure.&lt;/p&gt;
    &lt;head rend="h2"&gt;What This Means For Ghostty&lt;/head&gt;
    &lt;p&gt;From a technical perspective, nothing changes for Ghostty. Our technical goals for the project remain the same, the license (MIT) remains the same, and we continue our work towards better Ghostty GUI releases and libghostty.&lt;/p&gt;
    &lt;p&gt;Financially, Ghostty can now accept tax-deductible donations in the United States. This opens up new avenues for funding the project and sustaining development over the long term. Most immediately, I'm excited to begin compensating contributors, but I also intend to support upstream dependencies, fund community events, and pay for boring operational costs.&lt;/p&gt;
    &lt;p&gt;All our financial transactions will be transparent down to individual transactions for both inflows and outflows. You can view our public ledger at Ghostty's page on Hack Club Bank. At the time of writing, this is empty, but you'll soon see some initial funding from me and the beginning of paying for some of our operational costs.&lt;/p&gt;
    &lt;p&gt;All applicable names, marks, and intellectual property associated with Ghostty have been transferred to Hack Club and are now owned under the non-profit umbrella. Copyright continues to be held by individual contributors under the continued and existing license structure.&lt;/p&gt;
    &lt;p&gt;From a leadership perspective, I remain the project lead and final authority on all decisions, but as stated earlier, the creation of a non-profit structure lays the groundwork for an eventual future beyond this model.&lt;/p&gt;
    &lt;p&gt;Important note: no funds will be sent to me (Mitchell Hashimoto) or used in any way that personally benefits me. Since I'm both the largest donor and lead of this project, this is a legally guaranteed protection. But also for altruistic reasons, all funds will be directed towards the needs of the project and its community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Supporting Hack Club&lt;/head&gt;
    &lt;p&gt;As our fiscal sponsor, Hack Club provides essential services to Ghostty, including accounting, legal compliance, and governance oversight. To support this, 7% of all donations to Ghostty go to Hack Club to cover these costs in addition to supporting their broader mission of empowering young people around the world interested in technology and coding.&lt;/p&gt;
    &lt;p&gt;In the words of Zach Latta, Hack Club's founder and executive director this is a "good-for-good" trade. Instead of donor fees going to a for-profit management company or covering pure overhead of a single project, the fees go to another non-profit doing important work in the tech community and the overhead is amortized across many projects.&lt;/p&gt;
    &lt;p&gt;In addition to the 7% fees, my family is personally donating $150,000 directly to the Hack Club project1 (not to Ghostty within it). Hack Club does amazing work and I would've supported them regardless of their fiscal sponsorship of Ghostty, but I wanted to pair these two things together to amplify the impact of both.&lt;/p&gt;
    &lt;head rend="h2"&gt;Donate&lt;/head&gt;
    &lt;p&gt;Please consider donating to support Ghostty's continued development.&lt;/p&gt;
    &lt;p&gt;I recognize that Ghostty is already in an abnormally fortunate position to have myself as a backer, but I do envision a future where Ghostty is more equally supported by a broader community. And with our new structure, you can be assured about the usage of your funds towards public-benefit goals.&lt;/p&gt;
    &lt;p&gt;This post isn't meant to directly be a fundraising pitch so it is purposely lacking critical details about our funding goals, budget, project goals, project metrics, etc. I'll work on those in the future. In the mean time, if you're interested in talking more about supporting Ghostty, please email me at m@mitchellh.com.&lt;/p&gt;
    &lt;head rend="h3"&gt;Support Ghostty&lt;/head&gt;
    &lt;p&gt;Your contribution helps sustain development and keeps Ghostty free and open source for everyone. Donations are tax-deductible in the United States.&lt;/p&gt;
    &lt;p&gt;Use the EIN above and specify “Ghostty” as the recipient&lt;/p&gt;
    &lt;p&gt;Contact Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;Reach out to Paul at Hack Club&lt;/p&gt;
    &lt;p&gt;7% of donations go to Hack Club to cover administrative costs and support their mission.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank You&lt;/head&gt;
    &lt;p&gt;I'm thankful for Hack Club and their team for working with us to make this happen. I'm also thankful for the Ghostty community who has supported this project and has trusted me and continues to trust me to steward it responsibly.&lt;/p&gt;
    &lt;p&gt;For more information about Ghostty's non-profit structure, see the dedicated page on Ghostty's website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Footnotes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;We haven't finalized the transfer of the funds yet, but it is initiated and will be completed in the coming weeks. ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mitchellh.com/writing/ghostty-non-profit"/><published>2025-12-03T18:40:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46138632</id><title>Lie groups are crucial to some of the most fundamental theories in physics</title><updated>2025-12-04T11:10:44.846463+00:00</updated><content>&lt;doc fingerprint="e65190820f9d0f14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;What Are Lie Groups?&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;In mathematics, ubiquitous objects called groups display nearly magical powers. Though they’re defined by just a few rules, groups help illuminate an astonishing range of mysteries. They can tell you which polynomial equations are solvable, for instance, or how atoms are arranged in a crystal.&lt;/p&gt;
    &lt;p&gt;And yet, among all the different kinds of groups, one type stands out. Identified in the early 1870s, Lie groups (pronounced “Lee”) are crucial to some of the most fundamental theories in physics, and they’ve made lasting contributions to number theory and chemistry. The key to their success is the way they blend group theory, geometry and linear algebra.&lt;/p&gt;
    &lt;p&gt;In general, a group is a set of elements paired with an operation (like addition or multiplication) that combines two of those elements to produce a third. Often, you can think of a group as the symmetries of a shape — the transformations that leave the shape unchanged.&lt;/p&gt;
    &lt;p&gt;Consider the symmetries of the equilateral triangle. They form a group of six elements, as shown here:&lt;/p&gt;
    &lt;p&gt;Mark Belan/Quanta Magazine&lt;/p&gt;
    &lt;p&gt;(Since a full rotation brings every point on the triangle back to where it started, mathematicians stop counting rotations past 360 degrees.)&lt;/p&gt;
    &lt;p&gt;These symmetries are discrete: They form a set of distinct transformations that have to be applied in separate, unconnected steps. But you can also study continuous symmetries. It doesn’t matter, for instance, if you spin a Frisbee 1.5 degrees, or 15 degrees, or 150 degrees — you can rotate it by any real number, and it will appear the same. Unlike the triangle, it has infinitely many symmetries.&lt;/p&gt;
    &lt;p&gt;These rotations form a group called SO(2). “If you have just a reflection, OK, you have it, and that’s good,” said Anton Alekseev, a mathematician at the University of Geneva. “But that’s just one operation.” This group, on the other hand, “is many, many operations in one package” — uncountably many.&lt;/p&gt;
    &lt;p&gt;Each rotation of the Frisbee can be represented as a point in the coordinate plane. If you plot all possible rotations of the Frisbee in this way, you’ll end up with infinitely many points that together form a circle.&lt;/p&gt;
    &lt;p&gt;This extra property is what makes SO(2) a Lie group — it can be visualized as a smooth, continuous shape called a manifold. Other Lie groups might look like the surface of a doughnut, or a high-dimensional sphere, or something even stranger: The group of all rotations of a ball in space, known to mathematicians as SO(3), is a six-dimensional tangle of spheres and circles.&lt;/p&gt;
    &lt;p&gt;Whatever the specifics, the smooth geometry of Lie groups is the secret ingredient that elevates their status among groups.&lt;/p&gt;
    &lt;head rend="h2"&gt;Off on a Tangent&lt;/head&gt;
    &lt;p&gt;It took time for Marius Sophus Lie to make his way to mathematics. Growing up in Norway in the 1850s, he hoped to pursue a military career once he finished secondary school. Instead, forced to abandon his dream due to poor eyesight, he ended up in university, unsure of what to study. He took courses in astronomy and mechanics, and flirted briefly with physics, botany and zoology before finally being drawn to math — geometry in particular.&lt;/p&gt;
    &lt;p&gt;In the late 1860s, he continued his studies, first in Germany and then in France. He was in Paris in 1870 when the Franco-Prussian War broke out. He soon tried to leave the country, but his notes on geometry, written in German, were mistaken for encoded messages, and he was arrested, accused of being a spy. He was released from prison a month later and quickly returned to math.&lt;/p&gt;
    &lt;p&gt;In particular, he began working with groups. Forty years earlier, the mathematician Évariste Galois had used one class of groups to understand the solutions to polynomial equations. Lie now wanted to do the same thing for so-called differential equations, which are used to model how a physical system changes over time.&lt;/p&gt;
    &lt;p&gt;His vision for differential equations didn’t work out as he’d hoped. But he soon realized that the groups he was studying were interesting in their own right. And so the Lie group was born.&lt;/p&gt;
    &lt;p&gt;The manifold nature of Lie groups has been an enormous boon to mathematicians. When they sit down to understand a Lie group, they can use all the tools of geometry and calculus — something that’s not necessarily true for other kinds of groups. That’s because every manifold has a nice property: If you zoom in on a small enough region, its curves disappear, just as the spherical Earth appears flat to those of us walking on its surface.&lt;/p&gt;
    &lt;p&gt;To see why this is useful for studying groups, let’s go back to SO(2). Remember that SO(2) consists of all the rotations of a Frisbee, and that those rotations can be represented as points on a circle. For now, let’s focus on a sliver of the circle corresponding to very small rotations — say, rotations of less than 1 degree.&lt;/p&gt;
    &lt;p&gt;Here, the curve of SO(2) is barely perceptible. When a Frisbee rotates 1 degree or less, any given point on its rim follows a nearly linear path. That means mathematicians can approximate these rotations with a straight line that touches the circle at just one point — a tangent line. This tangent line is called the Lie algebra.&lt;/p&gt;
    &lt;p&gt;This feature is immensely useful. Math is a lot easier on a straight line than on a curve. And the Lie algebra contains elements of its own (often visualized as arrows called vectors) that mathematicians can use to simplify their calculations about the original group. “One of the easiest kinds of mathematics in the world is linear algebra, and the theory of Lie groups is designed in such a way that it just makes constant use of linear algebra,” said David Vogan of the Massachusetts Institute of Technology.&lt;/p&gt;
    &lt;p&gt;Say you want to compare two different groups. Their respective Lie algebras simplify their key properties, Vogan said, making this task much more straightforward.&lt;/p&gt;
    &lt;p&gt;“The interaction between these two structures,” Alessandra Iozzi, a mathematician at the Swiss Federal Institute of Technology Zurich, said of Lie groups and their algebras, “is something that has an absolutely enormous array of consequences.”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Language of Nature&lt;/head&gt;
    &lt;p&gt;The natural world is full of the kinds of continuous symmetries that Lie groups capture, making them indispensable in physics. Take gravity. The sun’s gravitational pull on the Earth depends only on the distance between them — it doesn’t matter which side of the sun the Earth is on, for instance. In the language of Lie groups, then, gravity is “symmetric under SO(3).” It remains unchanged when the system it’s acting on rotates in three-dimensional space.&lt;/p&gt;
    &lt;p&gt;In fact, all the fundamental forces in physics — gravity, electromagnetism, and the forces that hold together atomic nuclei — are defined by Lie group symmetries. Using that definition, scientists can explain basic puzzles about matter, like why protons are always paired with neutrons, and why the energy of an atom comes in discrete quantities.&lt;/p&gt;
    &lt;p&gt;In 1918, Emmy Noether stunned mathematicians and physicists by proving that Lie groups also underlie some of the most basic laws of conservation in physics. She showed that for any symmetry in a physical system that can be described by a Lie group, there is a corresponding conservation law. For instance, the fact that the laws of physics are the same today as they were yesterday and will be tomorrow — a symmetry known as time translation symmetry, represented by the Lie group consisting of the real numbers — implies that the universe’s energy must be conserved, and vice versa. “I think, even now, it’s a very surprising result,” Alekseev said.&lt;/p&gt;
    &lt;p&gt;Today, Lie groups remain a vital tool for both mathematicians and physicists. “Definitions live in mathematics because they’re powerful. Because there are a lot of interesting examples and they give you a good way to think about something,” Vogan said. “Symmetry is everywhere, and that’s what this stuff is for.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/what-are-lie-groups-20251203/"/><published>2025-12-03T19:12:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46139761</id><title>Show HN: I built a dashboard to compare mortgage rates across 120 credit unions</title><updated>2025-12-04T11:10:44.615081+00:00</updated><content>&lt;doc fingerprint="3c94a31214402b4c"&gt;
  &lt;main&gt;&lt;p&gt;Buying a home or refinancing a mortgage is tough enough without confusing ads from banks and big lenders. Credit unions can offer competitive rates compared to big banks because theyâre member-owned, non-profit institutions. They focus on serving their members, not maximizing profits for shareholders.&lt;/p&gt;&lt;p&gt;But without big budgets and marketing departments, credit union rates arenât always easy to find or compare. Thatâs why we built a daily-updated comparison of mortgage rates from over 120 credit unions across the United States.&lt;/p&gt;&lt;head rend="h2"&gt;Credit Union Mortgage Rates&lt;/head&gt;&lt;p&gt;Last updated: December 3, 2025&lt;/p&gt;&lt;head rend="h3"&gt;30-Year Fixed&lt;/head&gt;Updating...&lt;p&gt;Loading rate comparison table...&lt;/p&gt;&lt;p&gt;Note: These rates are informational and not a commitment to lend. FinFam has no institutional affiliation and does not receive any referral fees.&lt;/p&gt;&lt;head rend="h2"&gt;Why build this dashboard?&lt;/head&gt;&lt;p&gt;When we bought our home, the big bank Iâd been using for years tried to sell me on a mortgage with 7% APR. Turns out a local credit union was offering 5.5% for the exact same mortgage.&lt;/p&gt;&lt;p&gt;What surprised me most wasnât that there were cheaper options, but that two mortgages can be exactly the same product, just with different packaging.&lt;/p&gt;&lt;p&gt;In the USA, the government buys almost all mortgages, requiring them to be standardized. So why the price difference? As explored in this Bloomberg Odd Lots episode about credit card rates, higher rates are mostly to pay for advertising and marketing. Big banks have marketing departments that non-profit credit unions donât have.&lt;/p&gt;&lt;p&gt;That âexclusiveâ inbox offer from Chase or Wells Fargo isnât generosity. Itâs a bet that you wonât shop around. My goal with this tool is simple: help people realize they have options and potentially save thousands of dollars a year.&lt;/p&gt;&lt;head rend="h2"&gt;How the dashboard works&lt;/head&gt;&lt;p&gt;Itâs a little involved! ð&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Rates are collected throughout the day from the websites of approximately 120 credit unions.&lt;/item&gt;&lt;item&gt;National benchmarks come from the St. Louis Federal Reserve Bank, aka FRED: 30-Year Fixed benchmark (15Y). These update weekly.&lt;/item&gt;&lt;item&gt;Credit union eligibility data is manually curated from individual institution websites.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Some rates (around a dozen) are hidden by default because theyâre statistical outliers: likely errors or ultra-specialized products. Toggle âShow outliersâ in the filters if you want to see them anyway.&lt;/p&gt;&lt;p&gt;Found an error? Email blog@finfam.app.&lt;/p&gt;&lt;head rend="h2"&gt;Next Steps: Make Decisions, Get Quotes&lt;/head&gt;&lt;p&gt;Our dashboard can only take you so far. Your actual rate depends on: credit score, down payment (20%+ is ideal), property type (primary residence gets best rates), and whether you pay points for a lower rate (always compare APR).&lt;/p&gt;&lt;p&gt;Next step: Get quotes from multiple lenders by using the rate table above to contact institutions.&lt;/p&gt;&lt;p&gt;Protip: Before submitting to any credit checks, protect your privacy with optoutprescreen.com, another free and regulated service I wish Iâd known about sooner.&lt;/p&gt;&lt;p&gt;Still not sure about buying or refinancing? Check out these interactive guides:&lt;/p&gt;&lt;p&gt;FinFam is built around collaborative financial planning, including community-authored, spreadsheet-powered guides, like those above. Read more in our docs.&lt;/p&gt;&lt;head rend="h2"&gt;Questions or Feedback?&lt;/head&gt;&lt;p&gt;Have questions about these rates or suggestions for improving this tool? Reach out to us at blog@finfam.app.&lt;/p&gt;&lt;p&gt;Donât see your favorite CU here? As long as it has a website with a public rates page and clear eligibility requirements, weâd be happy to add it!&lt;/p&gt;&lt;head rend="h3"&gt;Disclaimers&lt;/head&gt;&lt;p&gt;These rates are informational only and donât represent rate locks. Your actual rate will vary. Contact lenders with the links in the rate table to get your personalized quotes. FinFam has no institutional affiliation and receives no referral fees, nor provides any guarantees.&lt;/p&gt;&lt;p&gt;Shoutout /r/dataisbeautiful for the encouragement. And big thanks to Asheesh Laroia for his guidance on the matter of mortgages. See his spreadsheet-friendly take on the data.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finfam.app/blog/credit-union-mortgages"/><published>2025-12-03T20:35:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46140244</id><title>8086 Microcode Browser</title><updated>2025-12-04T11:10:44.456406+00:00</updated><content>&lt;doc fingerprint="3f1bc214a171d033"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;8086 Microcode Browser&lt;/head&gt;
    &lt;p&gt;Since releasing 486Tang, I’ve been working on recreating the 8086 with a design that stays as faithful as possible to the original chip. That exploration naturally led me deep into the original 8086 microcode — extracted and disassembled by Andrew Jenner in 2020.&lt;/p&gt;
    &lt;p&gt;Like all microcoded CPUs, the 8086 hides a lot of subtle behavior below the assembly layer. While studying it I kept extensive notes, and those eventually evolved into something more useful: an interactive browser for the entire 8086 microcode ROM.&lt;/p&gt;
    &lt;p&gt;So here it is: the online 8086 microcode browser. Every 21-bit micro-instruction is decoded into readable fields. Hover over any field and you’ll get a tooltip explaining what it does. All jump targets are clickable — the 8086 μcode uses a surprising number of indirect jumps, calls, and short branches.&lt;/p&gt;
    &lt;p&gt;One handy feature is Browse by Instruction. Click the button and you’ll get a list of ~300 documented 8086 instructions. Select any one, and the viewer jumps directly to its μcode entry point. Internally there are only about 60 unique μcode entry routines, and this feature makes navigating them effortless.&lt;/p&gt;
    &lt;head rend="h3"&gt;A few fun tidbits about 8086 μcode&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Register IDs change meaning depending on context. For example,&lt;/p&gt;&lt;code&gt;10100&lt;/code&gt;refers to SIGMA (the ALU result) when used as a source, but to tmpaL (the low 8 bits of a temporary ALU register) when used as a destination.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;N and R are the same physical register. Meanwhile, SI is called IJ internally — naming inside the chip is extremely inconsistent and reflects its evolutionary design process.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;IP (PC) does not point to the next instruction. It actually points to the next prefetch address. The μcode uses a dedicated micro-operation called CORR to rewind IP back to the true next-instruction boundary when handling branches and interrupts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Almost all arithmetic instructions share the same 4 μinstructions (&lt;/p&gt;&lt;code&gt;008–00B&lt;/code&gt;). The heavy lifting is done by a single micro-operation named XI, which performs different arithmetic behaviors depending on opcode or ModRM bits. The amount of reuse here is elegant — and very 1978 Intel.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nand2mario.github.io/posts/2025/8086_microcode_browser/"/><published>2025-12-03T21:16:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46141745</id><title>Acme, a brief history of one of the protocols which has changed the Internet</title><updated>2025-12-04T11:10:43.405878+00:00</updated><content>&lt;doc fingerprint="6d19b1920b220c9d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;ACME, a brief history of one of the protocols which has changed the Internet Security&lt;/head&gt;
    &lt;head rend="h3"&gt;Preamble&lt;/head&gt;
    &lt;p&gt;I would like to share with you this article I wrote about the ACME protocol, which I “fell in love with” about ten years ago. It is for me a way to give back to this fantastic Free Software and Open Protocols developers community.&lt;/p&gt;
    &lt;p&gt;This article is about the roots, the conception, the standardization, the relation with its ecosystem and the evolution challenges faced by the ACME protocol.&lt;/p&gt;
    &lt;p&gt;To write this article, I had the privilege of interviewing several people who have been involved in the creation and the evolution of ACME: Aaron Gable, Sarah Gran, Jacob Hoffman-Andrews and J.C. Jones (more below).&lt;/p&gt;
    &lt;p&gt;Thank you so much to all of you for your time and support! ð&lt;/p&gt;
    &lt;head rend="h2"&gt;Internet and Network Protocols&lt;/head&gt;
    &lt;head rend="h3"&gt;Open and Standardized Protocols at the Heart of the Internetâs Success&lt;/head&gt;
    &lt;p&gt;During the 1990s, computing underwent a true revolution driven by the rise and global spread of the Internet. The Internet fulfilled the promise embodied in Sun Microsystemsâ slogan “The Network is the Computer”.&lt;/p&gt;
    &lt;p&gt;By interconnecting individual computers, the Internet enabled its users to communicate without limits and without worrying about borders.&lt;/p&gt;
    &lt;p&gt;This unrestricted interconnection emerged at a pivotal moment in modern history: the opposition between the West and the Eastern Bloc led by the USSR hadâalbeit temporarily, as we now knowâfaded away, China was becoming the worldâs factory, and the movement and collaboration between people were much freer and open than ever.&lt;/p&gt;
    &lt;p&gt;The Internet supported a kind of utopia of instant communication and sharing, previously unknown. This utopia was made possible by a set of open and standardized protocols. This was the key to enabling all kinds of different systems to cooperate and communicate seamlessly.&lt;/p&gt;
    &lt;p&gt;There were, of course, isolationist or monopolistic temptations from certain manufacturers or software editors. But open and standardized protocols ultimately prevailed, enabling unprecedented expansion. Built on top of IP, TCP, UDP, and DNS, among others, the HTTP and HTML duo would propel the Web as the Internetâs preferred communication platform for the next 30 years.&lt;/p&gt;
    &lt;head rend="h3"&gt;Limited Use of Encryption&lt;/head&gt;
    &lt;p&gt;The success of this communication utopia was achieved without much concern for ensuring authentication, integrity, and confidentiality of exchanges.&lt;/p&gt;
    &lt;p&gt;In 2015, only ~40% of websites used encryption. The consequences of this negligence in addressing security risks were confirmed by Edward Snowdenâs revelations in 2013: our data was exposed to anyone who wanted and could intercept and collect it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Let’s Encrypt is coming&lt;/head&gt;
    &lt;head rend="h3"&gt;The Birth of an Automated and Free Certificate Authority&lt;/head&gt;
    &lt;p&gt;When asked about the main obstacles to the widespread adoption of encryption, J.C. Jones, one of the architects of Letâs Encrypt and now one of its site reliability engineers after leading Firefoxâs cryptographic team, responds:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“More and more information was flowing across the Web, and most data being transferred did not have integrity or confidential protections from TLS. The biggest stumbling block to using TLS everywhere was obtaining and managing server-side certificates, and so: Letâs Encrypt” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Obtaining a certificate was the main obstacle, and this was the priority to address.&lt;/p&gt;
    &lt;p&gt;This view was shared by a group of partners who, starting in 2013, pooled resources to establish Letâs Encrypt, an automated and free certificate authority. Sarah Gran, VP of Advancement at Letâs Encrypt, shares:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Early collaborators included people from Mozilla, Electronic Frontier Foundation, Akamai, Cisco, and the University of Michigan” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And that’s how Let’s Encrypt was born.&lt;/p&gt;
    &lt;p&gt;In the Web ecosystem, certificate authorities are organizations from which you can obtain a certificate for a domain after proving you control it.&lt;/p&gt;
    &lt;p&gt;And so, Let’s Encrypt is since 2015 a certificate authority that delivers for free (as in free beer) TLS Server certificates.&lt;/p&gt;
    &lt;p&gt;On the legal/administrative side, Let’s Encrypt certificate authority operates for the publicâs benefit and is a service provided by the Internet Security Research Group (ISRG), a California public benefit corporation.&lt;/p&gt;
    &lt;p&gt;Regarding Let’s Encrypt results ten years after its birth, they are really impressive (over 700M active certificates, over 60% of all the public TLS server certificates) and as Sarah Gran points out, so is the global HTTPS usage:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“When we started issuance, only about 39% of website visits were HTTPS. Today, itâs nearly 95% in the United States, and over 83% globally. We still have work to do, but we are proud of the progress weâve made over the last ten years” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let’s Encrypt delivers certificates in a automated manner using the ACME protocol which implies no manual action from the site owner nor the certificate authority. So, let’s speak now a little about the automation aspect!&lt;/p&gt;
    &lt;head rend="h3"&gt;Automation: The Core of the Operation&lt;/head&gt;
    &lt;p&gt;From the mid-2020s perspective, the automation at the heart of Letâs Encrypt might seem obvious, but in the first half of the 2010s, it was far from the norm. The ecosystem of public certificate authorities issuing server certificates was no exception.&lt;/p&gt;
    &lt;p&gt;At first glance, automation appears to be there to help website managers reliably deploy the TLS protocol on their sites, but it was first and foremost an absolute prerequisite for the very viability of the Let’s Encrypt project.&lt;/p&gt;
    &lt;p&gt;As Aaron Gable, tech lead of Boulderâthe software at the core of Letâs Encryptâ, confirms:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Automation was always going to be critical to Letâs Encryptâs success. From the very beginning, we knew that there was no way we could scale manual validation on a non-profitâs budget” – Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Indeed, it is worth noting that Letâs Encrypt has operated on an Internet scale from the start with a small team of about fifteen engineers, or even fewer at launch. For this team, automation was the only viable way to fulfill the immense mission they had set for themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACME&lt;/head&gt;
    &lt;head rend="h3"&gt;The Open and automated Protocol That Powers Letâs Encrypt&lt;/head&gt;
    &lt;p&gt;When we talk about automation in relation to Letâs Encrypt, we are talking about ACME (Automated Certificate Management Environment).&lt;/p&gt;
    &lt;p&gt;This protocol allows client software to prove to an ACME-compatible certificate authority that it controls the domain for which it is requesting a certificate.&lt;/p&gt;
    &lt;p&gt;Sarah Gran clarifies an important point:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“An important aspect of how Letâs Encrypt works is that we verify control over a domain, not ownership” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Control vs. ownership of a domainâa nuance everyone should keep in mind.&lt;/p&gt;
    &lt;p&gt;This proof of control involves the client responding to a challenge issued by the ACME-compatible certificate authority. The challenge can be an HTTP, DNS, or TLS challenge, depending on the clientâs choice and certificate authority support. Completing the challenge requires the ACME client to place a value provided by the ACME serverâin a standardized HTTP path, a DNS zone, or a TLS response, respectively. All of these operations involve cryptography, of course.&lt;/p&gt;
    &lt;p&gt;The key point with ACME is that this entire dialogue between the client and the ACME server is executed without any human intervention, enabling the automatic issuance of certificates. Their deployment and integration into the web service can also generally be automated using scripts triggered after issuance.&lt;/p&gt;
    &lt;p&gt;On the Let’s Encrypt website, you can discover more information about how ACME works and get more detailled information about it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Birth of ACME&lt;/head&gt;
    &lt;p&gt;One might wonder whether ACME was part of Letâs Encryptâs design from the beginning.&lt;/p&gt;
    &lt;p&gt;J.C. Jones confirms:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“By late 2014, the idea of an HTTP REST API with “/challenge” and “/certificate” existed, but we hadnât defined much beyond that. We had a series of in-person meetings, in the Mozilla San Francisco office on Embarcadero and the EFF office in the Tenderloin through the spring of 2015 where we worked out the details” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;ACME was indeed at the core of Letâs Encrypt from the start and underwent a refinement process to cover all use cases as thoroughly as possible.&lt;/p&gt;
    &lt;p&gt;To learn more about the roots of ACME and Let’s Encrypt, there is a very informative document to read: the Let’s Encrypt paper for ACM CCS 2019 in London. It mentions the previous work of two teams:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“A group led by Alex Halderman at the University of Michigan and Peter Eckersley at EFF was developing a protocol for automatically issuing and renewing certificates. Simultaneously, a team at Mozilla led by Josh Aas and Eric Rescorla was working on creating a free and automated certificate authority”.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When these two teams discovered each other’s work, they joined forces. ACME and its implementation in Let’s Encrypt were the result of this joint effort supported by the initial partners mentioned above.&lt;/p&gt;
    &lt;head rend="h3"&gt;Securing the Web or the Internet?&lt;/head&gt;
    &lt;p&gt;Speaking of use cases, one might wonder whether the Web was Letâs Encryptâs primary target, or if securing the Internet with its multiple protocols was also part of the objectives.&lt;/p&gt;
    &lt;p&gt;Sarah Gran provides an unambiguous first-level answer:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“From Day One, we have sought to get the web to 100% encryption” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But when asked about the various types of challenges in the protocol, J.C. Jones offers a nuance:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“DNS, TLS-SNI, and HTTP were all in planning in spring 2015, but many of us were less confident in the procedure around the DNS validation. Which is ironic, as it turned out TLS-SNI had a vulnerability so we had to stop using it and our DNS validation was ultimately fine. In general, the collection of us were simply respectful of the great complexity within the DNS” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is a perspective not often publicly expressed by engineers primarily from the Web: their lack of confidence in implementing a DNS challenge stemmed from their humility regarding the complexity of the DNS ecosystem and the level of expertise required to master it.&lt;/p&gt;
    &lt;p&gt;The challenge was ultimately met, and this DNS challengeâthough not its primary purposeâenabled multiple protocols outside HTTP like SMTP to be secured by ACME.&lt;/p&gt;
    &lt;head rend="h2"&gt;Standardization and Open Source&lt;/head&gt;
    &lt;head rend="h3"&gt;Developed in the Open&lt;/head&gt;
    &lt;p&gt;ACME was documented openly from the start, and Certbot, the first open-source ACME client co-developed with the EFF, served as the client side reference implementation.&lt;/p&gt;
    &lt;p&gt;Similarly, a standardization process through the IETF resulted in RFC 8555 in March, 2019.&lt;/p&gt;
    &lt;p&gt;One of the consequences developing an open and standardized protocol was the creation of a multitude of ACME clients covering a very wide range of use cases.&lt;/p&gt;
    &lt;p&gt;J.C. Jones confirms that this was the goal:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“This is what we foresaw, or at least hoped for. The initial client development often had conversations like, âoh, if someone wants that, then theyâll write their own client.â It was a key part of why the REST API needed to be an IETF standard, and was part of the argument at the IETF BoF that resulted in the formation of the ACME Working Group in Q3 2015” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Letâs Encrypt has also always provided constant support to developers by responding in its forum or on its GitHub issue tracker, and all this work has truly paid off. An interesting post has been recently written about support on the Let’s Encrypt blog.&lt;/p&gt;
    &lt;head rend="h3"&gt;Standardization for what benefits?&lt;/head&gt;
    &lt;p&gt;The other question that can be asked is whether or not the standardization process within the IETF has led to an improvement in the ACME protocol thanks to the cooperation that guides this process.&lt;/p&gt;
    &lt;p&gt;Jacob Hoffman-Andrews, one of the RFC 8555 authors working for EFF &amp;amp; Let’s Encrypt, confirms an initial benefit that the ACME protocol has been able to derive from its standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“One of the big changes was from a validation-first flow to a certificate-request-first flow. In other words, earlier drafts had subscribers requesting validation for domain names and then requesting a certificate once those validations were successful. The final RFC has subscribers request a certificate, and then the CA tells the subscriber what validations are needed. This change originated from within the IETF discussion process, and was intended to make handling of wildcard certificates more natural.” – Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Aside this first design improvement, Jacob details a second major improvement of the security of the protocol, improvement that also landed during the IETF standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Another big change, also originated from within the IETF, was to make all requests authenticated, including GET requests. Since ACME is authenticated with signed POSTs, this necessitated the POST-as-GET concept thatâs in ACME today” – Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can see there how IETF iterations can challenge the security of a protocol and leads its development to innovative solutions to tackle the challenges it faces!&lt;/p&gt;
    &lt;p&gt;Last, Jacob adds another information that illustrates the benefits of developing a protocol into the open: it allows the community to evaluate (and sometimes, fix) its security level due to the availability of all materials and often, of the reference implementation:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Another very important evolution was the deprecation of the tls-sni-01 challenge method. This was found to be flawed by Frans Rosen, a security researcher. It was replaced with TLS-ALPN-01, developed at IETF with significant input from Google” – Jacob Hoffman-Andrews&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Letâs Encrypt, ACME, and the Public Certificate Authorities Ecosystem&lt;/head&gt;
    &lt;p&gt;In 2015, the arrival of Letâs Encrypt in the public certificate authorities ecosystem raised a number of questions.&lt;/p&gt;
    &lt;p&gt;What level of cooperation or hostility? What impact on the viability of existing certificate authorities?&lt;/p&gt;
    &lt;p&gt;Here again, the fact that Letâs Encrypt was based on an open protocol, immediately subject to an IETF standardization initiative, enabled collaboration and adoption by the most innovative certificate authorities.&lt;/p&gt;
    &lt;p&gt;I spoke about the External Account Binding (EAB) option of the protocol with J.C. Jones. EAB is a way for an ACME client to authenticate to an ACME server using an identifier and a key value which are verifiable by the server in a repository it maintains. With EAB, an ACME server can filter who can uses its service which is useful for commercial certificate authorities for example; it is an alternative model to Let’s Encrypt one where anybody can ask for a certificate.&lt;/p&gt;
    &lt;p&gt;Using the example of EAB, J.C. Jones confirms the collaboration with certificate authorities that happens during the IETF standardization process:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“EAB was an early addition at the IETF ACME Working Group. Many in the room were worried that without a means to bind to a payment method, ACME would not get adoption. In fact, some of the counterarguments to forming ACME were blunted by EAB, as such a mechanism wasnât in the theoretically-competing, already-existent standard: SCEP. SCEP, it was argued, already handled ‘free’ certificate issuance, for private certificate authorities. Anything else needed a feasible path for usage payment.” – J.C. Jones&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Beyond billing, the addition of EAB enabled also some commercial certificate authorities to integrate their existing domain control validation systems with ACME, allowing some of them to skip the challenge step of the ACME protocol.&lt;/p&gt;
    &lt;p&gt;The IETF standardization process, based on an open process, created the necessary discussion space for cooperation among entities that did not necessarily share the same objectives.&lt;/p&gt;
    &lt;p&gt;The result, ten years after the introduction of ACME and the completion of its standardization process in 2019, is that ACME has become the primary means by which all public certificate authoritiesâboth free and commercialârely on for their transition to an automated future of issuing short-lived certificates.&lt;/p&gt;
    &lt;p&gt;Effectively, until early this year, the maximum lifespan of a public TLS server certificate was set to 398 days by the CA/B Forum, the organization that set the rules for public certificate authorities. With the vote of the ballot SC081 at the CA/B Forum in April 2025, it has been decided that the certificate lifespan will decrease gradually starting March 2026 to reach 47 days in March 2029. The automation provided by ACME seems to be one of the main identified levers to help organizations to adapt to this drastic reduction in the lifespan of public TLS server certificates.&lt;/p&gt;
    &lt;head rend="h3"&gt;Created at Let’s Encrypt, adopted everywhere&lt;/head&gt;
    &lt;p&gt;It is important to note that although ACME was developed by the team managing Let’s Encrypt, this protocol is now one of the main protocols for automated certificate acquisition adopted by all public certificate authorities.&lt;/p&gt;
    &lt;p&gt;And outside the public certificate authorities ecosystem, I think it’s fair to say that this protocol is also becoming increasingly popular with technical architects in companies with private certificate authorities.&lt;/p&gt;
    &lt;p&gt;This has been the case in my company for several years now, where we have deployed an ACME endpoint in front of our internal certificate authority. Among the benefits we have seen, we have been able to rely on the vast ACME clients ecosystem in order to provide an ACME client to each OS or middleware that powers our infrastructure. We can see there how certificate obtention agility powered by ACME helps organizations in their journey to global IT agility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Innovation and the adoption challenge&lt;/head&gt;
    &lt;head rend="h3"&gt;The ARI episode&lt;/head&gt;
    &lt;p&gt;We may fear that the development of a protocol supported primarily by a team as small as Let’s Encrypt’s will be fairly limited in terms of evolution and innovation.&lt;/p&gt;
    &lt;p&gt;But the history of ACME shows that its evolution continues after its initial standardization.&lt;/p&gt;
    &lt;p&gt;In 2025, we saw with the ARI (ACME Renewal Information – RFC 9773) extension that the ACME protocol continues to evolve. ARI is a way for a certificate authority to suggest a renewal period to its clients, often earlier than they would have determined themselves. This use case is particularly relevant when the certificate authority needs to mass-revoke certificates that, for example, did not comply with the rules the certificate authority must follow when issuing certificates.&lt;/p&gt;
    &lt;p&gt;More specifically, J.C. Jones and Aaron Gable point two incidents that had to be handled by the Let’s Encrypt team and that were the start for the ARI initiative:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Explicitly, as remediation of https://bugzilla.mozilla.org/show_bug.cgi?id=1619179 and https://bugzilla.mozilla.org/show_bug.cgi?id=1715672 " J.C. Jones and Aaron Gabble&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Support to encourage adoption&lt;/head&gt;
    &lt;p&gt;Aaron Gable leads the effort of designing and implementing ARI. But even if a new extension to the protocol has been produced, it can only reach its potential users after ACME clients have implemented it into their code base. As previously said, the team and some community members invest a lot on providing support to the community. In the case of ARI, this support is oriented to the ACME clients developers in order to make these clients ARI aware.&lt;/p&gt;
    &lt;p&gt;Providing an efficient support and effective resources to the client side ACME actors is a huge part of the challenge in order to keep ACME ecosystem healthy and agile.&lt;/p&gt;
    &lt;p&gt;As illustrates by Sarah Gran, another way to give momentum to a new feature is to lift certain restrictions on access to the certificate authority:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In order to encourage ARI adoption, weâve configured Letâs Encrypt to allow subscribers who renew via ARI to bypass our rate limits.” – Sarah Gran&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Client Side Update Challenge&lt;/head&gt;
    &lt;p&gt;But despite a good support work and incentive measures, Aaron Gable confirms ARI adoption is just at its start:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“There is still much progress to be made. Part of the appeal of the Automated Certificate Management Environment is that many users can set-and-forget their client and configuration. This means that most clients never receive software updates, and even client projects that have implemented ARI in their latest version still have massive install bases that arenât running that version. Weâve worked closely with many clients developers to implement ARI, and contributed implementations ourselves in several cases, but for widespread adoption the whole ecosystem will need to slowly turn over” – Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This situation is really shared with a lot of client side softwares that “just work”(c) and it raises some concerns about how to make an ecosystem keeping track with innovation on its client side.&lt;/p&gt;
    &lt;p&gt;This challenge arises not only in terms of updating the client, but also in terms of updating the configuration. Many ACME clients rely on cron tasks. To have an efficient ARI setup, your task has to run ideally on a daily basis be able to ask the certification authority every day whether the certificate needs to be reissued. This is not the classic cron task setup. So, users have to modify this cron task frequency to reach the ARI goal of certificate reissuance led by certificate authority. Client side ACME setup evolution is a really challenging task.&lt;/p&gt;
    &lt;head rend="h3"&gt;Evolution on server side ACME implementation&lt;/head&gt;
    &lt;p&gt;CA/B Forum has recently asked public certificate authorities to adopt Multi-Perspective Issuance Corroboration (MPIC) to guard against BGP attacks. We have asked Aaron Gable about the impacts that kind of measure have had on ACME server side implementation in the Let’s Encrypt infrastructure:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Weâve had to make few if any changes to our infrastructure to accommodate recent requirements changes such as MPIC and DNSSEC validation. We innovated MPIC (then called Remote Validation) along with a research team at Princeton, and implemented it in 2020. Our experience already running such a service helped inform the requirements as they were incorporated by the CA/B Forum.” – Aaron Gable&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The lesson learnt here is that being at the edge of the innovation let you shape part of the future of your ecosystem and significantly lower the impact on your infrastructure of many regulatory measures that come into effect over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Future&lt;/head&gt;
    &lt;p&gt;It is really encouraging to see a lot of innovation in the ACME ecosystem.&lt;/p&gt;
    &lt;p&gt;So what evolutions can we expect to see in the future?&lt;/p&gt;
    &lt;p&gt;We have asked the question to Aaron Gable who gave us two upcoming developments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;“Weâre currently working on standardizing profile selection for ACME, and our deployment of the early draft of this standard has already brought some much-needed flexibility to the WebPKI, enabling us to make changes to our certificate contents with minimal disruption.”&lt;/item&gt;
      &lt;item&gt;“Iâm also excited about a potential future change which would introduce a ‘pubkey’ identifier type, along with a set of challenges that allow the client to demonstrate control over the corresponding keypair. This would fix the gap today that presenting a CSR does not actually prove possession of the key in that CSR.” – Araron Gable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Fastly has also recently contributed to ACME in order to improve the &lt;code&gt;dns-01&lt;/code&gt; challenge in a multi-cloud and multi-PKI environment. An IETF draft describing this &lt;code&gt;dns-account-01&lt;/code&gt; challenge is online. This is further proof that the public TLS ecosystem has truly embraced the ACME protocol as its primary automation tool.&lt;/p&gt;
    &lt;p&gt;Another recent development based on ACME has also shed new light on the potential of this protocol: since 2022, a draft is under progress at the IETF in order to write an ACME extension. The goal of this extension is to use ACME to obtain a certificate for a device in order to prove its identity. The challenge is based on device attestation and what’s new in this case is the arrival of a third party, the attestation server.&lt;/p&gt;
    &lt;p&gt;What is remarkable here is that we are no longer dealing with ACME’s initial use case, namely obtaining TLS server certificates: we can see in this IETF draft the potential of ACME as a challenge-based framework to obtain certificate in very different contexts.&lt;/p&gt;
    &lt;p&gt;Indeed, we can venture to say that ACME’s future looks bright ð&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;It is heartening to see that, 30 years after the widespread adoption of the Internet, open and standardized protocols continue to revolutionize its use.&lt;/p&gt;
    &lt;p&gt;ACME and its Let’s Encrypt implementation at scale have enabled the widespread adoption of HTTPS, thereby raising the level of security for billions of Internet users and also of private networks.&lt;/p&gt;
    &lt;p&gt;Having been able to do it inside a non profit organization, providing the Internet with an open and standardized protocol is a great success for all people believing in FreeSoftware and an Open Internet.&lt;/p&gt;
    &lt;p&gt;As a community, I really think we can thank these organizations, teams, and engineers who continue to uphold the promise of efficiency and Freedom brought about by cooperation around open protocols. They inspire new generations (and older ones I guess ð) demonstrating big things can still be achevied today in the open for the common good at the Internet scale!&lt;/p&gt;
    &lt;p&gt;I would like to extend a special thank you to the members of the Let’s Encrypt team, J.C. Jones, Aaron Gable, Sarah Gran and Jacob Hoffman-Andrews, for the time and effort they dedicated to answering my questions. Without them, this article would not have been possible.&lt;/p&gt;
    &lt;p&gt;A big shout out also to Eric Leblond and Philippe Teuwen who carefully proofread some early drafts of the article and Philippe Bonnef and Thibault Meunier for proofreading some of the last drafts. They all gave me so valuable and insightful advices ð&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.brocas.org/2025/12/01/ACME-a-brief-history-of-one-of-the-protocols-which-has-changed-the-Internet-Security/"/><published>2025-12-03T23:28:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46142000</id><title>Kea DHCP: Modern, open source DHCPv4 and DHCPv6 server</title><updated>2025-12-04T11:10:43.089165+00:00</updated><content>&lt;doc fingerprint="ea1b597bc497298e"&gt;
  &lt;main&gt;&lt;head rend="h4"&gt;Kea 3.0, our first LTS version&lt;/head&gt;&lt;p&gt;ISC is excited to announce the release of Kea 3.0.0! This is a major release, and is the first Long-Term Support (LTS) version of Kea.&lt;/p&gt;Read&lt;p&gt;Modern, open source DHCPv4 &amp;amp; DHCPv6 server&lt;/p&gt;&lt;p&gt;ISC distributes TWO full-featured, open source, standards-based DHCP server distributions: Kea DHCP and ISC DHCP. Kea includes all the most-requested features, is far newer, and is designed for a more modern network environment. ISC announced the End of Life for the older ISC DHCP system in 2022. Users of ISC DHCP may find these resources helpful in migrating their DHCP server deployments to the Kea server.&lt;/p&gt;&lt;p&gt;Modular Component Design, Extensible with Hooks Modules. The Kea distribution includes separate daemons for a DHCPv4 server, a DHCPv6 server, and a dynamic DNS (DDNS) module. Many optional features are enabled with dynamically-loaded “Hooks Modules,” which you need run only if you are using them. You can write your own hooks modules (in C++) or try some of the hooks we offer.&lt;/p&gt;&lt;p&gt;On-line Re-configuration with REST API. Kea uses a JSON configuration file that can be modified remotely via &lt;code&gt;set&lt;/code&gt; commands and reloaded without stopping and restarting the server, an operation that could take quite a while with ISC DHCP.&lt;/p&gt;&lt;p&gt;Designed to Integrate with Your Existing Systems. Kea allows you to separate the data from the execution environment, enabling new deployment options. Your network data - leases, host reservation definitions, and most configuration data - can be located separately from the DHCP server itself, using a Kea “backend.”&lt;/p&gt;&lt;p&gt;Kea supports two database backends; MySQL and PostgreSQL. Besides the obvious benefits (you avoid JSON formatting errors, you can quickly and easily mine the data for other purposes) using a database backend enables multiple Kea servers to share the data. Potential benefits:&lt;/p&gt;&lt;p&gt;Web-based graphical dashboard. Kea now has a graphical dashboard for monitoring multiple Kea servers. This system, called Stork, uses agents deployed on the Kea servers to relay information to a centralized management platform, providing the administrator with an easy-to-use quick view of system status and activity.&lt;/p&gt;&lt;p&gt;Modern, higher performance implementation. Kea is multi-threaded, and when configured for efficient operation, it can be performant enough for a large-scale, short-lease duration environment, which is the most demanding scenario.&lt;/p&gt;&lt;p&gt;The core Kea daemons are open source, shared under MPL2.0 licensing. Kea is developed in the open on ISC’s GitLab; we welcome you to open issues and submit patches there. Kea runs on most Linux and Unix platforms, as well as MacOS. If you don’t want to build from our source distribution, we also provide a repository of pre-built packages for most popular operating systems.&lt;/p&gt;&lt;p&gt;Contact ISC for Support&lt;/p&gt;&lt;p&gt;Your major design decisions are whether to deploy in pairs for High Availability and use the default csv file for host and lease data, or to install a separate database for a Kea data “backend.” Some of these decisions can limit your performance. See our Knowledgebase for advice on designing for optimal performance.&lt;/p&gt;&lt;p&gt;Instructions are available for building and installing Kea from the source packages downloadable below. ISC provides pre-built packages for RHEL, Fedora, Ubuntu, and Debian. If you are using any Kea hook libraries, you will also need to install and configure those.&lt;/p&gt;&lt;p&gt;The Kea Administrator Reference Manual (ARM) is the primary reference for Kea configuration. The extensive set of example configuration files in the project repo and our knowledgebase may help you get started. If you are migrating from an existing ISC DHCP deployment, try the Kea Migration Assistant (a special feature of the ISC DHCP distribution). This will enable you to save your current ISC DHCP server configuration as a Kea configuration file. It will still need some manual adjustment, but this tool should translate the bulk of your configuration.&lt;/p&gt;&lt;p&gt;Most users will benefit from joining the kea-users mailing list. Consider joining our Kea project GitLab to log issues, see what we’re working on, submit patches, and participate in development. Consider deploying Stork for a graphical management dashboard. If your DHCP is critical to your business, we recommend you subscribe for technical support from ISC.&lt;/p&gt;&lt;p&gt;Stork aggregates data about the health of the system hosting Kea, as well as the status and activity level of Kea itself. Parameters reported include memory, CPU utilization, software versions, and uptime.&lt;/p&gt;&lt;p&gt;Stork displays configured pools, with # of addresses provisioned and assigned and even tracks pool utilization across shared networks. Graphical elements highlight areas of high utilization to alert the operator to take actionHigh Availability pairs are monitored and their configured role and status are shown, making it easy to see which servers don’t have a backup established, and when a failover event has occurred.&lt;/p&gt;&lt;p&gt;Add, update and view DHCPv4 and DHCPv6 host reservations, using a graphical interface to select a host identifier, assign a hostname, reserve an IP address, associate a client class, and configure boot file information and DHCP options.&lt;/p&gt;&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;Service Options&lt;/cell&gt;&lt;cell role="head"&gt;Gold support&lt;/cell&gt;&lt;cell role="head"&gt;&lt;p&gt;Silver support&lt;/p&gt;&lt;/cell&gt;&lt;cell role="head"&gt;Bronze support&lt;/cell&gt;&lt;cell role="head"&gt;Basic (no support)&lt;/cell&gt;&lt;cell role="head"&gt;Premium (no longer offered)&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Critical issue response&lt;/cell&gt;&lt;cell&gt;30 minutes, 24x7&lt;/cell&gt;&lt;cell&gt;1 hour, 24x7&lt;/cell&gt;&lt;cell&gt;2 hours, business hours only*&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Standard issue response&lt;/cell&gt;&lt;cell&gt;4 business hours*&lt;/cell&gt;&lt;cell&gt;8 business hours*&lt;/cell&gt;&lt;cell&gt;Next business day&lt;/cell&gt;&lt;cell&gt;community support via public mailing list&lt;/cell&gt;&lt;cell&gt;community support via public mailing list&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Early vulnerability notifications&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;5 days&lt;/cell&gt;&lt;cell&gt;3 days&lt;/cell&gt;&lt;cell&gt;not included&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Kea 3.0 hook libraries (RBAC and Configuration Backend are the only commercially-licensed ones)&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;All - Subscriber&lt;/cell&gt;&lt;cell&gt;N/A&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Kea 2.6 and earlier hook libraries included&lt;/cell&gt;&lt;cell&gt;All - Enterprise, Premium and Subscription&lt;/cell&gt;&lt;cell&gt;All - Enterprise, Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium and Subscription&lt;/cell&gt;&lt;cell&gt;Premium&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;Stork support&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Available&lt;/cell&gt;&lt;cell&gt;Community support via user mailing list&lt;/cell&gt;&lt;cell&gt;Community support via user mailing list&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Purchasing&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;Quotation/Purchase order&lt;/cell&gt;&lt;cell&gt;no longer offered&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Pricing based on deployment size and service level.&lt;/p&gt;Contact ISC for a quote&lt;table&gt;&lt;row span="6"&gt;&lt;cell role="head"&gt;VERSION&lt;/cell&gt;&lt;cell role="head"&gt;STATUS&lt;/cell&gt;&lt;cell role="head"&gt;DOCUMENTATION&lt;/cell&gt;&lt;cell role="head"&gt;RELEASE DATE&lt;/cell&gt;&lt;cell role="head"&gt;EOL DATE&lt;/cell&gt;&lt;cell role="head"&gt;DOWNLOAD&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;3.0.2&lt;/cell&gt;&lt;cell&gt;Current Stable - LTS&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;October 2025&lt;/cell&gt;&lt;cell&gt;June 2028&lt;/cell&gt;&lt;/row&gt;&lt;row span="6"&gt;&lt;cell&gt;2.6.4&lt;/cell&gt;&lt;cell&gt;Current Stable&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;July 2025&lt;/cell&gt;&lt;cell&gt;July 2026&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;3.1.4&lt;/cell&gt;&lt;cell&gt;Development&lt;/cell&gt;&lt;cell&gt; Kea ARM ( HTML PDF )&lt;p&gt;Kea Messages ( HTML PDF )&lt;/p&gt;&lt;p&gt;Release Notes ( TXT )&lt;/p&gt;&lt;/cell&gt;&lt;cell&gt;November 2025&lt;/cell&gt;&lt;cell&gt;June 2026&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.isc.org/kea/"/><published>2025-12-03T23:58:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46142100</id><title>Average DRAM price in USD over last 18 months</title><updated>2025-12-04T11:10:42.967178+00:00</updated><content/><link href="https://pcpartpicker.com/trends/price/memory/"/><published>2025-12-04T00:08:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46142866</id><title>Why WinQuake exists and how it works</title><updated>2025-12-04T11:10:42.573675+00:00</updated><content>&lt;doc fingerprint="e73b81353f2276d7"&gt;
  &lt;main&gt;
    &lt;p&gt;When I took a look at the history of Quake binaries, they all made sense to me. &lt;code&gt;quake.exe&lt;/code&gt; was the original release, able to run on DOS and Windows 95. Then came &lt;code&gt;vquake.exe&lt;/code&gt; to support the hardware accelerated chip Vérité 1000. Later, &lt;code&gt;glquake.exe&lt;/code&gt; generalized hardware acceleration to any vendor providing OpenGL drivers. And to revolutionize Internet deathmatch, id Software released QuakeWorld server and client (&lt;code&gt;qwsv.exe&lt;/code&gt; and &lt;code&gt;qwcl.exe&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;However, I could not figure out the point of &lt;code&gt;winquake.exe&lt;/code&gt;. Until now. Here is what I understood and a little bit of a dive into how it works.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;quake.exe&lt;/code&gt; runs on both DOS and Windows 95 but how well does it perform? A quick benchmark on my Pentium MMX 233MHz, Matrox Mystique PC (320x200 with 101 screen size) and sound on, showed the following numbers.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
        &lt;cell role="head"&gt;Framerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;&lt;code&gt;quake.exe&lt;/code&gt; started from DOS&lt;/cell&gt;
        &lt;cell&gt;48 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;&lt;code&gt;quake.exe&lt;/code&gt; started from Windows 95&lt;/cell&gt;
        &lt;cell&gt;38 fps&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So "framerate" is the beginning of an answer to justify the existence of WinQuake. &lt;code&gt;quake.exe&lt;/code&gt; running from Windows 95 is roughly 25% slower than the same binary started from DOS. And that is to be expected. Windows 95 runs DOS applications in a virtual machine ("DOS BOX"), where memory access, interrupts, and signals are virtualized, which incurs overhead.&lt;/p&gt;
    &lt;p&gt;Another element of the answer comes from Quake Chunnel. &lt;code&gt;quake.exe&lt;/code&gt; can access Windows 95 TCP/IP stack, but only via a convoluted tech from Mpath to bridge a "DOS BOX" to win32 dlls. By having a win32-only application, id Software had guaranteed direct access to &lt;code&gt;winsock.dll&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Last but not least, id Software really wanted Quake to work on Windows NT. Despite their best efforts, the people at DJGPP could not make their DPMI client in &lt;code&gt;quake.exe&lt;/code&gt; compatible with the NT Virtual DOS Machine (NTVDM).&lt;/p&gt;
    &lt;quote&gt;Near pointers don't work under NT - which was a huge disappointment to iD and generated some conference calls to Microsoft.&lt;lb/&gt;- Charles Sandmann[1]&lt;/quote&gt;
    &lt;p&gt;A fun way to start exploring is to first read WQREADME.TXT and then take a look at all the modes available in &lt;code&gt;winquake.exe&lt;/code&gt;. They are configured with the script wq.bat.&lt;/p&gt;
    &lt;quote&gt;Options for running WinQuake: wq max: all features on, but doesn't work on all systems wq fast: maximum speed, but doesn't work on all systems wq fastvid: maximum video speed, but safer, probably slower sound wq fastsnd: maximum sound speed, but safer, probably slower video wq safe: very likely to run, but may be slower wq verysafe: almost sure to run, but probably slower, and no sound&lt;/quote&gt;
    &lt;p&gt;Here are the numbers I got for each mode, still with the same Pentium MMX 233MHz machine and same configuration.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Configuration&lt;/cell&gt;
        &lt;cell role="head"&gt;Framerate&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq max&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;42.4 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fast&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;41.8 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fastvid&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;45.0 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq fastsnd&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;41.8 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;wq safe&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;45.0 fps&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;wq verysafe&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;40.0 fps*&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Impressive. &lt;code&gt;winquake.exe&lt;/code&gt; managed to bring up the framerate within 6% of &lt;code&gt;quake.exe&lt;/code&gt; running on DOS. Mission accomplished. But how does it works?&lt;/p&gt;
    &lt;p&gt;Each "mode" is configured via command-line flags. This part reveals there are three types of backend for input controls, audio, and video.&lt;/p&gt;
    &lt;quote&gt;max winquake -dinput fast winquake fastvid winquake -wavonly fastsnd winquake -nodirectdraw -nowindirect safe winquake -wavonly -nodirectdraw -nowindirect verysafe winquake -dibonly -nosound -nojoy&lt;/quote&gt;
    &lt;p&gt;Amusingly, the mode that provides the highest framerate, &lt;code&gt;fastvid&lt;/code&gt; keeps everything default but disables an audio backend!&lt;/p&gt;
    &lt;p&gt;"fastvid" was also the name of a tool to fix the Pentium Pro abysmal video write speed on chipset that shipped with buggy "Write Posting". The option in &lt;code&gt;qw.bat&lt;/code&gt; has nothing to do with it.&lt;/p&gt;
    &lt;p&gt;WinQuake can send its sound effects (the music comes from CD tracks) using two audio backends (with &lt;code&gt;-nosound&lt;/code&gt; disables sound effects altogether).&lt;/p&gt;
    &lt;p&gt;The two backends are DirectSound (&lt;code&gt;dsound.h&lt;/code&gt; from DirectX) and what id calls wave sound which is in fact &lt;code&gt;winmm.h&lt;/code&gt;, the Windows MultiMedia audio API, dating back to Windows 3.1.&lt;/p&gt;
    &lt;p&gt;If DirectSound is available, WinQuake uses it to provide the lowest latency. However this backend has a higher impact on the CPU and results in 10% lower framerate. With &lt;code&gt;-wavonly&lt;/code&gt;, users can force usage of &lt;code&gt;WinMM&lt;/code&gt; which results in higher latency but higher framerate.&lt;/p&gt;
    &lt;p&gt;To read user inputs, WinQuake uses either DirectInput (&lt;code&gt;dinput.h&lt;/code&gt; from DirectX) or the legacy Windows API &lt;code&gt;winuser.h&lt;/code&gt;.

&lt;/p&gt;
    &lt;p&gt;By default WinQuake uses &lt;code&gt;winuser.h&lt;/code&gt; but usage of DirectInput can be requested via &lt;code&gt;-dinput&lt;/code&gt; for slightly smoother motion and responsiveness to fast spinning motions. I suspect it was not enabled by default for cases where DirectX was not installed or perhaps fear of driver problems.&lt;/p&gt;
    &lt;p&gt;Joystick inputs are handled with &lt;code&gt;joystickapi.h&lt;/code&gt;. Likewise, it seems drivers may not have been stable since id provided a way to disable it with &lt;code&gt;-nojoy&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The part that was the most interesting to me was the video backends. WinQuake can operate in five modes using GDI, VGA, VESA, Accelerated VESA, or DirectDraw.&lt;/p&gt;
    &lt;p&gt;The Graphics Device Interface (GDI) (&lt;code&gt;wingdi.h&lt;/code&gt;) is the foundation to render anything on the desktop in Windows 95. Applications usually did not use it directly but instead called &lt;code&gt;winuser.h&lt;/code&gt; (which in turns used low-level &lt;code&gt;wingdi.h&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;WinQuake can render to a Device-Independent Bitmaps (DIB) which is a surface to be blitted towards a window though GDI. The surface can be of any dimension so there are no "display mode" to detect here, WinQuake hardcodes its DIB modes to square-pixel resolutions 320x240, 640x480, and 800x600.&lt;/p&gt;
    &lt;p&gt;Because it is using Windows "by the book", DIB mode is the safest mode that should always work. It is also the slowest way to render to the screen because WinQuake first renders to a DIB that is then sent to the GDI and then sent to the video card.&lt;/p&gt;
    &lt;p&gt;While slower, it is not devoid of hardware acceleration. Many graphic cards wanting to perform well under Windows 95 had hardware acceleration implementation of crucial functions such as &lt;code&gt;bitBlt&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Finally, DIB mode is the only one able to render in "windowed" mode. Every other mode takes over and renders in "fullscreen" mode. Note that DIB can also render in pseudo-full screen if WinQuake is started with &lt;code&gt;dibonly&lt;/code&gt; but this is "faked" with a borderless window covering the whole screen.&lt;/p&gt;
    &lt;p&gt;For everything not DIB, WinQuake uses SciTech's MegaGraph Graphics Library. It was a rather expensive lib ($499 in 1997, $1,000 in 2025)[2] but well worth its price because it brought order into the chaos that was the world of video systems in 1997 if a game operated outside GDI.&lt;/p&gt;
    &lt;p&gt;WinQuake could find itself having to deal with the following types of video systems.&lt;/p&gt;
    &lt;quote&gt;1. VBEAF : VESA Accelerator Function 2. VBE2 : VESA Linear Frame Buffer for direct to VRAM write/read. 3. DirectDraw : Only available if DirectX is installed. 4. StandardVGA : That good ol' VGA video mode.&lt;/quote&gt;
    &lt;p&gt;When it starts, WinQuake registers the drivers it wants MGL to load (see &lt;code&gt;registerAllDispDrivers&lt;/code&gt;). MGL then lists all supported resolutions and pick the highest performance drivers to access each of them (in the order list above).&lt;/p&gt;
    &lt;quote&gt;void registerAllDispDrivers(void) { /* Even though these driver require WinDirect, we register * them so that they will still be available even if DirectDraw * is present and the user has disabled the high performance * WinDirect modes. */ MGL_registerDriver(MGL_VGA8NAME,VGA8_driver); if (useWinDirect){ MGL_registerDriver(MGL_LINEAR8NAME,LINEAR8_driver); if (!COM_CheckParm ("-novbeaf")) MGL_registerDriver(MGL_ACCEL8NAME,ACCEL8_driver); } if (useDirectDraw) { MGL_registerDriver(MGL_DDRAW8NAME,DDRAW8_driver); } }&lt;/quote&gt;
    &lt;p&gt;The list of modes and which driver was selected by MGL is available via the command &lt;code&gt;vid_describemodes&lt;/code&gt; in Quake console. In the screenshot below, we can see almost the full house of drivers &lt;code&gt;VGA8.DRV&lt;/code&gt;, &lt;code&gt;DDRAW.DRV&lt;/code&gt;, &lt;code&gt;LINEAR8.DRV&lt;/code&gt;, and the windowed DIB modes.&lt;/p&gt;
    &lt;p&gt;I had never heard of VBE/AF before reading MGL source code. As far as I understand, it never gained much traction and few vendors wrote drivers to support it.&lt;/p&gt;
    &lt;p&gt;Many games used MGL: WinQuake, Hexen II, Grand Theft Auto, Maui Mallard in Cold Shadow, Total Mayhem, Balls of Steel.&lt;/p&gt;
    &lt;p&gt;Microsoft was very much aware that GDI was fine for applications but not enough for video games. Already in Windows 3.1 they had released a game developer SDK called WinG to give a more direct fullscreen access to the screen. The second version of WinG was renamed DirectX and contained the 2D fullscreen API which they called DirectDraw.&lt;/p&gt;
    &lt;quote&gt;Although safer and more reliable, Microsoft Windows imposed many restrictions on applications. One result of this situation was that games, and other high-performance graphics applications, could no longer access the hardware resources directly in order to maximize performance and expand functionalities. For several years game programmers continued to exercise the craft in DOS, and Windows users had to switch to the DOS mode to run games, simulations, and other graphics programs. The resulting situation implied a major contradiction: a graphical operating system in which graphics applications would execute with marginal performance&lt;lb/&gt;The first effort in this direction was a product named WinG, in reference to Windows for Games. WinG was first made available in 1994 and it required Win32 in Windows 3.1. Its main feature is that WinG enabled the game programmer to rapidly transfer bitmaps from system memory into video memory. This made possible the creation of Windows games that executed with much better performance.&lt;lb/&gt;Microsoft renamed the new version of the Game SDK, calling it DirectX 2. Other versions later released were named DirectX 3, DirectX 5, DirectX 6, and currently, DirectX 7.&lt;lb/&gt;- Feng Yuan, "Windows Graphics Programming Win32 GDI and DirectDraw"&lt;/quote&gt;
    &lt;p&gt;In terms of performance, DirectDraw was a step up from GDI but it was also not guaranteed to work due to driver bugs or if the user had not installed DirectX. It can be disabled with &lt;code&gt;nodirectdraw&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Readers may have picked up on something written earlier that was blatantly wrong. Direct access to the hardware is forbidden to Win32 applications. So how is MGL able to bypass GDI/DirectDraw and directly hit VBEAF, VBE, and VGA?&lt;/p&gt;
    &lt;p&gt;That is possible thanks to the secret tech from SciTech called WinDirect. How it works is explained in SciTech MGL Reference Guide v4.pdf.&lt;/p&gt;
    &lt;quote&gt;What is WinDirect?&lt;lb/&gt;A key component of the SciTech MGL, WinDirect is a runtime package for DOS and Windows 95 that provides direct access to the display hardware for both 16 and 32-bit applications. Traditionally Windows applications have had to perform all graphics output using the standard Graphics Device Interface (GDI). Although the GDI is very extensive and powerful, it is also not particularly fast for the sort of graphics that real time applications like interactive video games require.&lt;lb/&gt;WinDirect breaks this barrier by allowing high performance applications to shut down the normal GDI interface, and to take over the entire graphics display hardware just like you would normally do under DOS. Once GDI has been shut down, interactive graphics applications can re-program the display controller and write directly to video memory. A WinDirect application can program any standard VGA graphics mode such as 320x200x256, it can re-program the controller and run standard VGA ModeX style graphics, or it can call the standard VESA BIOS services to run high resolution SuperVGA graphics.&lt;lb/&gt;- MGL v4 Programmer Guide[3]&lt;/quote&gt;
    &lt;p&gt;MGL v4 programmer guide, is a treasure strove of information. If, like me, you wondered what were these &lt;code&gt;WDIR32.DLL&lt;/code&gt; and &lt;code&gt;WDIR16.DLL&lt;/code&gt; libraries that came with WinQuake, the doc mentions them (WinDIRect). Likewise, the doc describes &lt;code&gt;PMPRO16.DLL&lt;/code&gt; and &lt;code&gt;PMPRO32.DLL&lt;/code&gt; as DOS extender independent API for protected mode services. Michael Abrash's Zen Timer is also mentioned in there :)!&lt;/p&gt;
    &lt;p&gt;WinQuake source code does not include MGL. Only the headers and a pre-compiled 32-bit &lt;code&gt;MGLLT.LIB&lt;/code&gt; (MGL Lite) are provided to allow compilation. SciTech did eventually publish the source in 2000[4] but it is no longer available. What was uploaded on GitHub[5] is v5 which by then had dramatically changed (e.g: WinDirect was gone).&lt;lb/&gt; Luckily a kind soul has mirrored MGL v4. If you want to do your own digging, install mglb405.exe and mgls405.exe. Or just download my installation, src.rar.&lt;/p&gt;
    &lt;p&gt;Overall, &lt;code&gt;winquake.exe&lt;/code&gt; was often able to find a fast rendering path, either through DirectDraw or WinDirect. The fallback to DIB mode was not ideal but still a win compared to &lt;code&gt;quake.exe&lt;/code&gt;. Add to that the ability to select a sound backend to optimize for framerate or audio latency and the result was a damn good experience that completely justified the effort.&lt;/p&gt;
    &lt;p&gt;More than 30 years later, you can still run &lt;code&gt;winquake.exe&lt;/code&gt; on Windows 11. Fullscreen does not support widescreen but the windowed mode still works flawlessly. As much as Microsoft has been questionable lately, their commitment to backward compatibility is impressive.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;Why did ID choose DJGPP for Quake?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;SciTech's MGL price&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;MGL v4 Programmer Guide&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[4]&lt;/cell&gt;
        &lt;cell&gt;SciTech Releases MGL 4.0 OpenGL Source Code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;^&lt;/cell&gt;
        &lt;cell&gt;[5]&lt;/cell&gt;
        &lt;cell&gt;SciTech Mult-platform Graphics Library&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fabiensanglard.net/winquake/index.html"/><published>2025-12-04T01:58:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46143618</id><title>Euler Conjecture and CDC 6600</title><updated>2025-12-04T11:10:42.065823+00:00</updated><content>&lt;doc fingerprint="bec9d9882d3a9cda"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I don’t think this warning applies here because the array is small, but the danger of this approach in general is that the executable file must contain that compile-time computed data, which means that it takes time to load that memory from disk (SSD, etc.) into the process memory on startup. In contrast, if that memory is allocated at run time directly by the executable, and then filled by cpu instructions, then it can be some 10^3 to 10^5 times faster. You can also see the difference by looking at the size of the executable image (&lt;code&gt;ls -l a.out&lt;/code&gt;). With most modern compilers, you do not see the size of the declared array reflected in the executable size unless they are parameter arrays, arrays initialized at compile time, or arrays in common blocks.&lt;/p&gt;
      &lt;p&gt;Also, if done at compile time, the whole array would need to be computed. That is 10^4 elements in this case (and integer overflows would be generated in doing so). The above run time code only computes 144 elements of the array before finding a solution and stopping.&lt;/p&gt;
      &lt;p&gt;A further question is where does that extra effort get charged? This extra effort is appropriate if the user is paying for that time (e.g. with money, or with elapsed time, or with total throughput through the machine), but not if that overhead is somehow not charged as user time (e.g. in a timeshare or batch environment with many other users). This is why the programmer sometimes writes code to minimize wall time and sometimes to minimize cpu time. Those two goals are not always exactly the same.&lt;/p&gt;
      &lt;p&gt;In the original code, the posix &lt;code&gt;time&lt;/code&gt; command was used for the timings. That command returns three different time values for exactly this reason. If you alone own the machine you are running on, and you want to maximize throughput through that machine every 24 hour period, then it is the elapsed time that is critical. If you are one of many users sharing the machine, then it is the user time that you want to minimize, the system time is not charged to you because while your job is stalled waiting for the disk to respond, someone else’s job is swapped in and is being charged to execute its user time.&lt;/p&gt;
      &lt;p&gt;Here is the timing result of that last version of the code using gfortran -O3 with an Apple M2 cpu&lt;lb/&gt; on MacOS. It computes the &lt;code&gt;i**5&lt;/code&gt; values at run time, so the system time is minimal.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;i^5 =  61917364224
133 110 84 27 144

real    0m0.141s
user    0m0.139s
sys     0m0.002s
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;One other comment about timings is that they are almost never really consistent from run to run. For small segments of code like this, one can do&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;$ time a.out; time a.out; time a.out
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The first results are usually longer than the others, which are then usually more consistent if not identical at the millisecond level. But if timings are measured at the microsecond level, they would show variations too.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fortran-lang.discourse.group/t/euler-conjecture-and-cdc-6600/10501"/><published>2025-12-04T03:50:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144113</id><title>Show HN: A Minimal Monthly Task Planner (printable, offline, no signup)</title><updated>2025-12-04T11:10:41.841035+00:00</updated><content>&lt;doc fingerprint="3f61c1ba9314363"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;PrintCalendar.top&lt;/p&gt;
      &lt;head rend="h3"&gt;Minimal Monthly Task Planner&lt;/head&gt;
      &lt;p&gt;A calm, printer-friendly canvas to map your month, capture notes, and keep a lightweight log of what matters.&lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Stay on month&lt;/p&gt;
            &lt;p&gt;Jump to today, share month links, pick Mon/Sun as week start.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Notes that travel&lt;/p&gt;
            &lt;p&gt;Monthly notes with inline editing, saved locally in your browser.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;p&gt;Ready to print&lt;/p&gt;
            &lt;p&gt;Clean A4 layout, dark/light themes, and PDF in one click.&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://printcalendar.top/"/><published>2025-12-04T05:29:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144275</id><title>Uncloud - Tool for deploying containerised apps across servers without k8s</title><updated>2025-12-04T11:10:41.177105+00:00</updated><content>&lt;doc fingerprint="6f4f5cfad58e4b63"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Mix and Match Infrastructure&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mix and match cloud and on-premise across regions and providers&lt;/item&gt;
      &lt;item&gt;Deploy customer-facing apps on reliable cloud VMs&lt;/item&gt;
      &lt;item&gt;Run resource-hungry background jobs on budget-friendly bare metal servers&lt;/item&gt;
      &lt;item&gt;Transform that dusty Mac mini into a powerful staging environment&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://uncloud.run/"/><published>2025-12-04T06:02:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46144613</id><title>Saturn (YC S24) Is Hiring Senior AI Engineer</title><updated>2025-12-04T11:10:40.687922+00:00</updated><content>&lt;doc fingerprint="9b8e9e540cf160ea"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;head rend="h3"&gt;Why Saturn?&lt;/head&gt;
      &lt;p&gt;Saturn is revolutionizing financial services with AI, building the operating system for financial advisors. Our mission is to democratize financial advice for one billion people by providing the world's most trusted, intelligent platform for financial planning and compliance.&lt;/p&gt;
      &lt;p&gt;This is a rare chance to build a category-defining company in a high-stakes, regulated environment. We operate with a Dual Mandate: relentless Speed of Execution to deliver reliable, robust products today, and dedicated Speed of Learning to explore the frontier of AI and unlock the next generation of features.&lt;/p&gt;
      &lt;p&gt;If you are driven by the pursuit of greatness, thrive on end-to-end ownership, and want to build the gold standard for AI trust and reliability, we invite you to build with us.&lt;/p&gt;
      &lt;head rend="h3"&gt;Role Overview&lt;/head&gt;
      &lt;p&gt;As a Senior AI Engineer at Saturn, you are the single-threaded owner of critical, customer-facing AI features that form the backbone of the advisory operating system. This is a highly autonomous role requiring robust software engineering fundamentals, deep LLM intuition, and an obsessive focus on product quality in a regulated domain.&lt;/p&gt;
      &lt;p&gt;You will own the entire feature lifecycle: from defining the Gold Standard with our domain experts (Guardians), architecting the agentic workflow, designing and building the comprehensive evaluation suites, to deploying and operating the solution reliably in production. You are expected to move quickly, making pragmatic, data-backed decisions that drive measurable value.&lt;/p&gt;
      &lt;head rend="h3"&gt;What You'll Do&lt;/head&gt;
      &lt;p&gt;1. End-to-End Feature Ownership and Architecture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Ownership: Take complete ownership of a product domain or complex feature, making architectural decisions independently and delivering high-quality results from concept through to long-term maintenance.&lt;/item&gt;
        &lt;item&gt;Defensive Design: Architect and implement fault-tolerant AI systems, incorporating robust fallbacks (via a model-agnostic gateway), retries, and comprehensive monitoring and tracing, driven by the Will to Care about system reliability.&lt;/item&gt;
        &lt;item&gt;Explicit Orchestration: Design and deploy complex, multi-step AI agents using explicit orchestration frameworks, ensuring state transitions are visible, testable, and auditable.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;2. Drive Evaluation and Quality Discipline:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Design Evaluation Strategy: Design, implement, and maintain the comprehensive, systematic evaluation framework (Evals Flywheel) specifically for your features to rigorously measure performance, manage regressions, and ensure quality compounds over time.&lt;/item&gt;
        &lt;item&gt;Domain Partnership: Work directly with our domain experts to translate complex financial and compliance requirements into executable evaluation rubrics and Gold Standard datasets.&lt;/item&gt;
        &lt;item&gt;Quality Feedback Loop: Instrument features end-to-end to rapidly diagnose probabilistic failures, converting production issues into high-priority regression tests.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;3. Elevate Engineering Standards:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Technical Excellence: Write clean, modular, Python code that raises the bar for the team. Actively participate in code review, using the process to mentor peers and reinforce architectural standards.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;What You Have&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;5+ years of professional experience in a highly demanding engineering environment.&lt;/item&gt;
        &lt;item&gt;Proven track record (3+ years) of building, shipping, and operating scaled, impactful products where Generative AI or LLMs are a core component.&lt;/item&gt;
        &lt;item&gt;Deep Experience with Agentic Systems: Expertise in RAG pipelines, systematic prompt engineering, agentic workflow orchestration, and defining reliability trade-offs for production systems.&lt;/item&gt;
        &lt;item&gt;Evaluation Focus: Direct, demonstrable experience designing, writing, and maintaining automated evaluation frameworks (&lt;code&gt;evals&lt;/code&gt;) used to rigorously test and improve probabilistic systems.&lt;/item&gt;
        &lt;item&gt;End-to-End Ownership: A history of thriving in ambiguity, taking complete ownership of large features, and driving initiatives forward independently with a strong bias for action.&lt;/item&gt;
        &lt;item&gt;Engineering Excellence: Mastery of Python and modern backend development practices, including system design, testing, CI/CD, and robust production observability.&lt;/item&gt;
        &lt;item&gt;Product &amp;amp; User Focus: Strong product sense and the drive to quickly build domain expertise, translating user needs and compliance context into high-value technical solutions (the expression of Will to Care for the customer).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Saturn Values in Practice:&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Earn Trust: Building verifiably correct, explainable systems (Citation-First, Adviser-in-the-Loop).&lt;/item&gt;
        &lt;item&gt;Pursue Greatness: Driving our Evaluation-Driven Development flywheel to compound quality daily.&lt;/item&gt;
        &lt;item&gt;Seek Truth: Relying on data, traces, and customer feedback (Guardians) to inform every decision.&lt;/item&gt;
        &lt;item&gt;Be Audacious: Taking decisive ownership and building intelligent agents that solve previously unsolvable problems in finance.&lt;/item&gt;
        &lt;item&gt;Will to Care: Obsessively anticipating customer needs and building systems with extreme attention to detail, ensuring long-term quality, reliability, and the success of our users and peers.&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/saturn/jobs/R9s9o5f-senior-ai-engineer"/><published>2025-12-04T07:00:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145154</id><title>The Mysterious Realm of JavaScriptCore (2021)</title><updated>2025-12-04T11:10:40.132836+00:00</updated><content>&lt;doc fingerprint="e200b11260b513b0"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt;JavaScriptCore (JSC) is the JavaScript engine used by Safari, Mail, App Store and many other apps in MacOs. The JSC engine is responsible for executing every line of JavaScript (JS) that needs to be executed, whenever we browse to a new website or simply send/receive emails.&lt;/p&gt;
    &lt;p&gt;Finding vulnerabilities in JSC can be intimidating and, in some cases, complicated. In this blog post, we start by learning the fundamentals of JSC. Then, we describe how we developed a tailor-made CodeQL query that uncovers bad side effect modeling vulnerabilities, which could lead to RCE in JSC.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;I’ve always felt intimidated by the fog of war that was laying over the land of browser exploitation. Never have I dared to step foot in there since I thought I was way under-leveled to do so. But, not long ago, I received the magical staff of CodeQL, and now I feel confident enough to explore the realm; I geared up and started my quest! Follow me on this immersive journey to learn the fundamentals of JSC and find some cool (old-school) bugs with CodeQL.&lt;/p&gt;
    &lt;head rend="h3"&gt;Entering the Realm of JSC&lt;/head&gt;
    &lt;p&gt;Goo(gle) the Owl: “Cloning the repository might be a good start.”&lt;lb/&gt; Me: “Waaa! Who are you?”&lt;lb/&gt; Goo the Owl: “You can call me Goo, the all-knowing Owl. What are you doing here?”&lt;lb/&gt; Me: “I just got this new staff and figured I should explore this realm a bit.” [Flashing my CodeQL staff]&lt;lb/&gt; Goo the Owl: “Oh nice! I heard about it from 91,500 places (0.43 seconds to search about it). I’ll help you explore the realm – seems like a good use of my time.”&lt;lb/&gt; Me: “That’s nice of you.&lt;lb/&gt; Me: [WHISPERING] “Show off.”&lt;lb/&gt; Goo the Owl: “Well then, without further ado, let’s clone WebKit and enter the realm!”&lt;lb/&gt; Me: git clone https://github.com/WebKit/WebKit.git&lt;lb/&gt; [Falling through a portal]&lt;lb/&gt; Me: “We’re in!” [Looking at THOUSANDS of slimy blobs waiting in line]&lt;lb/&gt; Me: “Ugh… What are these blobs?”&lt;lb/&gt; Goo the Owl: “These gooey blobs are JavaScript instructions waiting to be executed.”&lt;lb/&gt; Me: [Confused]&lt;lb/&gt; Goo the Owl: “Allow me to elaborate!”&lt;/p&gt;
    &lt;head rend="h3"&gt;JavaScriptCore 101&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;“WebKit is the web browser engine used by Safari, Mail, App Store, and many other apps on macOS, IOS and Linux.” – WebKit description from https://webkit.org&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;JSC is the built-in JS engine for WebKit, meaning it handles each JS script we execute via our browser. Unlike code written in C, which we initially compile into native code that our processor can run, a virtual machine (JSC, for example) executes JS, and our processor executes the code of that virtual machine.&lt;/p&gt;
    &lt;p&gt;Figure 1 – C vs. JavaScript&lt;/p&gt;
    &lt;p&gt;It is well understood that each approach comes with its pros and cons. For example, running a native C function can be a lot faster than executing a similar function written in JS. The reason derives directly from the figure above. JS bytecode must go through another level of execution compared to a pre-compiled programming language, like C.&lt;/p&gt;
    &lt;p&gt;But, since our JS code is running in a virtual machine, we have less room for classic bugs because the virtual machine can do all sorts of checks during runtime and prevent these classic bugs from becoming a problem. Additionally, JS is much more dynamic than C; for instance, we don’t have to declare the arguments’ types when writing a new function.&lt;/p&gt;
    &lt;head rend="h3"&gt;Instruction Processing&lt;/head&gt;
    &lt;p&gt;Every JS script we’ll execute via JSC will go through several phases:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Lexing (parser/Lexer.cpp) – The Lexer will break down our script into a series of tokens. Breaking down our code is done by pre-defined characters (e.gThe parser will then process these tokens.&lt;/item&gt;
      &lt;item&gt;Parsing (parser/JSParser.cpp) – The parser will build an abstract syntax tree (AST) from the tokens produced by the Lexer. The syntax tree represents our code’s structural details, meaning each node in our tree represents an expression in our code. For example, a node can represent the expression “a + b“; the child of this expression will be the “+” operation, and its children will be the variables “a” and “b.“&lt;/item&gt;
      &lt;item&gt;Low-Level Interpreter (LLInt) – At this phase, we already have a syntax tree representing our code. The LLInt will create bytecode that JSC can execute using the processor. For example, the expression “a+b” we’ve mentioned earlier is translated to bytecode that consists of the following offline assembly opcodes:&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;add loc3, loc1, loc2, OperandTypes(126, 126)&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; This is merely adding loc1 with loc2 and saving the result in loc3. The OperandTypes holds metadata about the predicated types of loc1 and loc2.&lt;/p&gt;
    &lt;p&gt;Figure 2 – The primary stages of JavaScript code goes through&lt;/p&gt;
    &lt;head rend="h3"&gt;JS Can Go FAST&lt;/head&gt;
    &lt;p&gt;While we mentioned earlier that there are only three stages in executing a JS instruction, reality suggests there are more stages. Browsers run thousands of lines of JS code on an average website, and usually, there are JS instructions that are in use in a much higher frequency than others. If we only had three stages as mentioned above, we would have to repeatedly execute the same instruction through the virtual machine, which causes a lot of unnecessary overhead. Therefore, JSC (and every other JS engine) uses Just-In-Time (JIT) compilation!&lt;/p&gt;
    &lt;p&gt;In case you’re not familiar with the concept, JIT compilation is the process of compiling a piece of code at runtime instead of the conventional way before execution. In our scenario, JSC will compile often-used instructions to native code that can be executed by our processor instead of compiling these instructions to bytecode run by the virtual machine.&lt;/p&gt;
    &lt;p&gt;This way, these often-used instructions now run with much lower overhead than before. One might say: “If the overhead is a lot lower now, why not JIT compile every instruction?”&lt;/p&gt;
    &lt;p&gt;And the answer to this question is straightforward: The process of JIT compiling is expensive (runtime speaking).&lt;/p&gt;
    &lt;p&gt;JSC creates a profile for each instruction using the LLInt (and other components mentioned later in this blog). Such profiling allows the engine to know which operations are used more often and to JIT to compile them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four Levels of JSC&lt;/head&gt;
    &lt;p&gt;We have discussed the basic workflow of executing instructions in JSC. Now it’s time to turn it up a notch. JSC executes instructions in four different tiers. As the rank of the tier goes up, the overhead of running that instruction goes down.&lt;/p&gt;
    &lt;p&gt;Instructions tier can level up/down during runtime. JSC holds an “execution counter” for each instruction, and each time we’ll execute that operation, JSC will add more points to their counter.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Leveling up to the second tier requires 500 points&lt;/item&gt;
      &lt;item&gt;Leveling up to the third tier requires 1,000 points&lt;/item&gt;
      &lt;item&gt;Leveling up to the fourth tier requires 100,000 points&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The transition between tiers is linear. For example, to move from tier level 1 to tier level 3, the instruction must traverse through tier level 2 and only then to tier 3.&lt;/p&gt;
    &lt;p&gt;The four tiers are:&lt;/p&gt;
    &lt;p&gt;1. LLInt – The low-level interpreter, as mentioned earlier, this tier will compile JS instructions into bytecode.&lt;/p&gt;
    &lt;p&gt;2. Baseline JIT (500 points) – As the name might suggest, instructions that are executed under this tier will become JIT-ed. The baseline JIT compiles bytecode operations into native code using a template for each operation. There is no additional logic regarding the relation between other instructions or what’s on – only the template.&lt;/p&gt;
    &lt;p&gt;3. Data Flow Graph (DFG) JIT (1,000 points) – The DFG JIT has an intermediate representation (IR) that is later used by the DFG JIT compiler. The IR will translate the implemented code of a JS instruction into a data-flow graph (see example below). The DFG JIT compiler can now perform complex optimizations that have to do with the code’s flow. For example, let’s take a look at the following JS code snippet:&lt;/p&gt;
    &lt;quote&gt;function Foo(arg) { return this.y * arg[0]; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; By calling Foo in a loop with approximately 1,000 iterations, we can force JSC to compile Foo into DFG JIT. To see the actual DFG IR produced for this code snippet, we can run the following line:&lt;/p&gt;
    &lt;quote&gt;JSC_dumpGraphAtEachPhase=true ./WebKitBuild/Debug/bin/jsc ../dfgMe.js&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The output from this command line contains hundreds of lines, and to keep things as simple as possible, we created a flow graph that represents the DFG IR produced by JSC:&lt;/p&gt;
    &lt;p&gt;Figure 3 – Representing the short function Foo as a Data Flow Graph&lt;/p&gt;
    &lt;p&gt;OSRExit is a mechanism that allows JSC to downgrade the instruction’s tier. This is useful in the event that we add more optimizations to the execution process, i.e. we tell JSC to speculate more about what the operation can do.&lt;/p&gt;
    &lt;p&gt;For instance, JSC will speculate that the use of multiplication here is done by multiplying two integers. In reality, multiplying two integers is much less complicated than multiplying two objects, for example. Therefore, by speculating the argument types, JSC can add more impressive optimizations. In case JSC has been mistaken and guessed incorrectly, and the arguments types are not integers, JSC will perform OSRExit and level down the tier. This way, the new lower tier might have a more significant overhead, but the necessary checks will now remain.&lt;/p&gt;
    &lt;p&gt;4. Faster than Light (FTL) JIT (100,000 points) – Unlike the DFG JIT compiler, the FTL JIT focuses on optimizations regardless of how expensive the optimizing process might be. The FTL JIT reuses the optimizations that were done by the DFG JIT and will add many more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to the Realm&lt;/head&gt;
    &lt;p&gt;Me: “Ohh.”&lt;lb/&gt; Goo the Owl: “And these blobs are going straight to the LLInt.”&lt;lb/&gt; Me: “Oof.”&lt;lb/&gt; Goo the Owl: “This is literally the shortest summary I could give on JSC.”&lt;lb/&gt; Me: “I understand why I never came here.”&lt;lb/&gt; Goo the Owl: “Wanna go back?”&lt;lb/&gt; Me: “No way, too committed by now. Let’s follow the blobs to the LLInt!” [Following the blobs]&lt;lb/&gt; Me: “I’ve noticed that when certain blobs slide through the LLInt, other blobs cut the line and slide before everyone else! Not cool…”&lt;lb/&gt; Goo the Owl: “Calm down, manners police. These blobs cut the line because they have to.”&lt;lb/&gt; Me: “What do you mean, ‘have to’?”&lt;lb/&gt; Goo the Owl: “Some instruction blobs cause side effects. This is perfectly normal in JS.”&lt;lb/&gt; Me: “Side effects? Sounds malicious to me.”&lt;lb/&gt; Goo the Owl: “As I said earlier, this is PERFECTLY NORMAL. Side effects in JS are…”&lt;lb/&gt; [QUICK CUT TO GOO ELABORATING ON SIDE EFFECTS IN JS]&lt;/p&gt;
    &lt;head rend="h3"&gt;Side Effects In JS&lt;/head&gt;
    &lt;p&gt;A JS operation causes side effects if it modifies the state of other variables outside the local environment of that instruction.&lt;/p&gt;
    &lt;p&gt;For instance, in JS, we can concatenate a string with a JS Object like this:&lt;/p&gt;
    &lt;quote&gt;let a = "Hello" + {} // a is now "Hello{}"&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; This concatenation will fail in most program languages, but not in JS. JSC will try to convert unique types (such as JSObject) to a primitive type (e.g. String). Let’s take a look at the function “jsAdd,” which is the implementation of the “+” operator:&lt;/p&gt;
    &lt;quote&gt;ALWAYS_INLINE JSValue jsAdd(JSGlobalObject* globalObject, JSValue v1, JSValue v2) { if (v1.isNumber() &amp;amp;&amp;amp; v2.isNumber()) return jsNumber(v1.asNumber() + v2.asNumber()); return jsAddNonNumber(globalObject, v1, v2); }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; As we can see, if we try to add two numbers, JSC will simply add them and will return the value; otherwise, JSC calls the function jsAddNonNumber. The figure below represents the flow of jsAddNonNumber, while the input is . Each color represents the context of execution:&lt;/p&gt;
    &lt;p&gt;Figure 4 – The code flow of jsAddNonNumber while adding a String with a JSObject&lt;/p&gt;
    &lt;p&gt;We can see that jsAddNonNumber checks the types of the arguments (in our case, arg1 is a String and arg2 is a JSObject) and then tries to convert them into primitive types (e.g., String, Number).&lt;/p&gt;
    &lt;p&gt;By setting the property “toString” in our object (second argument), we could cause JSC to run arbitrary JS code that is not part of the conventional flow of the add operator, i.e., side effect:&lt;/p&gt;
    &lt;quote&gt;let myObj = {'toString' : function(){print("side-effect here"); return "myX";}}; let a = "Hello " + myObj // this will print "side-effect here" // a is "Hello myX"&lt;/quote&gt;
    &lt;head rend="h3"&gt;DFG Optimizations: Redundancy Elimination&lt;/head&gt;
    &lt;p&gt;A widespread DFG JIT optimization is called redundancy elimination. The goal of this optimization is to eliminate redundant guards when compiling an instruction into DFG. To determine which guards are redundant, JSC needs to know which instructions can cause side effects and under which terms (e.g., concerning the argument types passed to the operations). This way, guards that appear before and after an instruction that can’t cause side effects will be considered redundant.&lt;/p&gt;
    &lt;p&gt;Let’s look at the following example:&lt;/p&gt;
    &lt;quote&gt;function Foo(arg){ return arg.someProp / arg.otherProp; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The flow graph that represents this function will look like the following:&lt;/p&gt;
    &lt;p&gt;Figure 5 – Phase 1 – Representing the function from above as DFG before removing redundant guards&lt;/p&gt;
    &lt;p&gt;You might notice that JSC checks that our argument is a valid object twice, before and after fetching for the property “someProp.” This guard makes sure that we still access a JS object before fetching a property from an object. In case JSC has successfully fetched the property “someProp,” the second check is redundant since there are no possible side effects between the first fetch to the second one. Therefore, the graph will then look like the following:&lt;/p&gt;
    &lt;p&gt;Figure 6 – Phase 2 – Representing the function from above as DFG after removing redundant guards&lt;/p&gt;
    &lt;p&gt;Since this optimization removes unnecessary guards, JSC must determine in a rigorous way which guards are redundant.&lt;/p&gt;
    &lt;p&gt;So, to avoid these vulnerable scenarios, JSC does precise modeling for each JS operation. The side effect modeling is in the file DFGAbstractInterpreterInlines.h under the function executeEffects. This function holds a (HUGE) switch case that determines which operation could\could not cause side effects and under which terms. Whenever JSC calls clobberWorld, it assumes that the operation can execute side effects:&lt;/p&gt;
    &lt;p&gt;Figure 7 – Basic side effects modeling in JSC (DFGAbstractInterpreterInlines.h/executeEffects). Each case represents the operation’s code (opcode)&lt;/p&gt;
    &lt;head rend="h3"&gt;Bad Side Effect Modeling: InstanceOf Vulnerability&lt;/head&gt;
    &lt;p&gt;A good use case that shows the risk potential of bad side effect modeling in JSC is the following bug. It was fixed in May 2018 right after commit 3b45a2433371160871a07d288b119b2454e3db19 (which is the last commit vulnerable to this bug). The patch to that vulnerability is quite simple:&lt;/p&gt;
    &lt;p&gt;Figure 8 – Patching the bug by letting JSC know that the operation instanceOf can cause side effects&lt;/p&gt;
    &lt;p&gt;This simple patch suggests that this bug has something to do with bad side effect modeling.&lt;/p&gt;
    &lt;p&gt;With the help of maxpl0it, we can review the exploit that triggers this bug:&lt;/p&gt;
    &lt;quote&gt;class EmptyClass { }; var a = [13.37]; function TriggerClass() { }; var leakme = {}; var trigger = false; var handler = { getPrototypeOf(){ if (trigger){ a[0] = leakme; } return EmptyClass.prototype; }, }; TriggerClass.prototype = new Proxy({}, handler); function addrof(obj){ var toggle = true; function addrof_internal(array){ var _ = (new TriggerClass()) instanceof EmptyClass return array[0]; } for (var i = 0; i &amp;lt; 10000; i++){ addrof_internal(a); } trigger = true; return addrof_internal(a); } print(addrof(leakme));&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; The exploit uses classic JSC exploit primitives (leaking addresses using type confusion caused by a bug, AKA, addrof\fakeobj) initially discovered by and mapped out in this great Oct. 2016 article. This exploit implements the function addrof that allows leaking JS object addresses.&lt;/p&gt;
    &lt;p&gt;From the patch, we can deduct that the operation “InstanceOf” wasn’t modeled correctly for side effects, but the real question is: why instanceOf can trigger side effects?&lt;/p&gt;
    &lt;p&gt;Well, the answer to that question lies in the exploit! We can see that by creating a proxy object that handles the function “getPrototypeOf,” we can trigger side effects. The operation that implements the JS instruction instanceOf is operationDefaultHasInstance.&lt;/p&gt;
    &lt;quote&gt;size_t JIT_OPERATION operationDefaultHasInstance(ExecState* exec, JSCell* value, JSCell* proto) // Returns jsBoolean(True|False) on 64-bit. { … }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Note: The parameter “value” corresponds with the new instance of TriggerClass we create under “addrof_internal.”&lt;/p&gt;
    &lt;p&gt;The following flow chart describes why operationDefaultHasInstance causes side effects:&lt;/p&gt;
    &lt;p&gt;Figure 9 – Showing why OperationDefaultHasInstance can cause side effects&lt;/p&gt;
    &lt;p&gt;Fetching for the object prototype, without any guards or checks, allows us to replace the initial object (in our case, TriggerClass) into a proxy object. By doing so, we can replace the function getPrototypeOf with our own arbitrary JS code, AKA side effects.&lt;/p&gt;
    &lt;head rend="h2"&gt;CodeQL Magic&lt;/head&gt;
    &lt;p&gt;[CodeQL Staff shines with bright blue light]&lt;lb/&gt; Goo the Owl: “What’s happening?! Is it going to explode?! I’m way too young to d…”&lt;lb/&gt; Me: “It’s not going to explode… -_-”&lt;lb/&gt; Me: “It found potential in what you’ve said earlier.”&lt;lb/&gt; Goo the Owl: “Potential? What do you mean?”&lt;lb/&gt; Me: “Well, you have explained pretty thoroughly about the whole bad side effect modeling, right?”&lt;lb/&gt; Goo the Owl: “Yeah, so what?”&lt;lb/&gt; Me: “What if we could use my CodeQL staff to find more bugs like this one in the realm?”&lt;lb/&gt; Goo the Owl: “That would be awesome.”&lt;lb/&gt; Me: “I think so too, and I think that this is what the staff wants me to do.”&lt;/p&gt;
    &lt;head rend="h3"&gt;CodeQL: Finding Bad Side Effect Modeling Vulnerabilities in JSC&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;“CodeQL is a framework developed by Semmle and is free to use on open-source projects. It lets a researcher perform variant analysis to find security vulnerabilities by querying code databases generated using CodeQL, which supports many languages such as C/C++, C#, Java, JavaScript, Python and Golang.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Just in case you haven’t heard about CodeQL yet, I highly recommend reading my previous blog post, which dives into CodeQL and its capabilities.&lt;/p&gt;
    &lt;p&gt;Let’s try to write a CodeQL query that will find bad side effects modeling vulnerabilities in JSC. To begin with, here is a rough description of the bug:&lt;/p&gt;
    &lt;p&gt;A JS operation might be exposed to a bad side effect modeling bug if:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Under the case that represents the operation in executeEffects (DFGAbstractInterpreterInlines.h), there is no call to clobberWorld.&lt;/item&gt;
      &lt;item&gt;The operation causes side effect.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The best tip we can give you before writing CodeQL queries is to work as organized as possible. As your query’s complexity becomes higher, there is more room for it to fail somehow. Although this is probably true for every coding project you’ve worked on, debugging CodeQL queries can be much more difficult, since we don’t have classic debugging methods and tools that some of you might be familiar with (CodeQL simply doesn’t have any).&lt;/p&gt;
    &lt;p&gt;Let’s start by determining what data we need to extract with CodeQL to recognize the bugs we wish to find. The description of the bug above gives us a hint regarding what information we need to collect. After reading and analyzing the code, we created a diagram that shows which component does what in the JSC side effect modeling, and how the elements are linked&lt;/p&gt;
    &lt;p&gt;Then, I added an example to a possible side effect that an operation might have (same side effect as we showed in the InstanceOf bug, above):&lt;/p&gt;
    &lt;p&gt;Figure 10 – This diagram shows the logical connection between each component in JSC responsible for side effect modeling&lt;/p&gt;
    &lt;p&gt;With this diagram, we can start writing some CodeQL classes. Classes in CodeQL let you inherit from native CodeQL objects (e.g., VariableAccess, Function, Expr) and add layers of complexity such as additional predicates and properties. The first class we created is named ClobberWorldCall, which inherits from the CodeQL class FunctionCall.&lt;/p&gt;
    &lt;p&gt;Ideally, this class will model side effects by analyzing each call to clobberWorld under executeEffects. Let’s review some key features from that class:&lt;/p&gt;
    &lt;quote&gt;import cpp import helperFunctions class ClobberWorldCall extends FunctionCall{ string opCode; string strictTypeConstraintsNode1; string strictTypeConstraintsNode2; string strictTypeConstraintsNode3; string looseTypeConstraintsNode1; string looseTypeConstraintsNode2; string looseTypeConstraintsNode3; // string operandType; ClobberWorldCall() { this.getTarget().hasName("clobberWorld") and exists ( Function executeEffects | executeEffects.hasName("executeEffects") and this.getEnclosingFunction() = executeEffects ) and // Extracting the op code for each call (e.g., ValueAdd, InstanceOf) opCode = getOpForClobberWorld(this) and // Extracting the strict and loose types getStrictTypeConstraints(this, strictTypeConstraintsNode1, strictTypeConstraintsNode2, strictTypeConstraintsNode3) and getLooseTypeConstraints(this, looseTypeConstraintsNode1, looseTypeConstraintsNode2, looseTypeConstraintsNode3) } … }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Although this class seems short, a lot is going on inside it.&lt;/p&gt;
    &lt;p&gt;Our first predicate is quite simple – we look for all the calls to clobberWorld under executeEffects.&lt;/p&gt;
    &lt;p&gt;Then, we call our custom predicate getOpForClobberWorld, which works as follows:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get the basic block that contains the call to clobberWorld.&lt;/item&gt;
      &lt;item&gt;If that basic block is under a case, return the case name (the case name is the operation code (for example, ValueAdd).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After that, we call getStrictTypeConstraints, followed by a call to getLooseTypeConstraints, which was the most difficult bit to write.&lt;/p&gt;
    &lt;p&gt;To be as accurate and efficient as possible, JSC will sometimes call clobberWorld when specific argument types are passed to the operation. For example, adding two numbers in JS won’t cause side effects, but adding two objects may cause side effects. If JSC called clobberWorld when we simply call the add operation, it wouldn’t be efficient. So, JSC will check the argument types and only then decide whether it should call clobberWorld or not.&lt;/p&gt;
    &lt;p&gt;This is exactly where getStrictTypeConstraints and getLooseTypeConstraints come in handy.&lt;/p&gt;
    &lt;p&gt;Here is a snippet from the code that checks for strict constraints:&lt;/p&gt;
    &lt;quote&gt;string getStrictTypeForClobberWorldChild(FunctionCall clobberWorld){ if ( isClobberInsideSwitchCaseOrIfStatement(clobberWorld) = true ) then ( exists ( SwitchCase case, SwitchStmt st, FunctionCall call | st = getInnerSwitchStatement(clobberWorld, "useKind") and st.getExpr() = call and call.getQualifier().(FunctionCall).getTarget().hasName("child1") and case.getSwitchStmt() = st and case.getASuccessor*() = clobberWorld and result = case.getExpr().toString() ) or … else result = "noTypeConstraintsFound" }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; In this snippet, we see that we first check if the call to clobberWorld is under a (specific) Switch Case or an “if” statement.&lt;/p&gt;
    &lt;p&gt;If it is, then we analyze that very switch case/if statement.&lt;/p&gt;
    &lt;p&gt;In this example, we analyze the switch case. JSC can obtain argument types by several methods. For example, one of them is by calling the function useKind, which returns the argument type (mind-blowing). Our code from above should handle these types of cases:&lt;/p&gt;
    &lt;quote&gt;case ArithClz32: { … switch (node-&amp;gt;child1().useKind()) { case Int32Use: case KnownInt32Use: break; default: clobberWorld(); break; } setNonCellTypeForNode(node, SpecInt32Only); break; }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Once we finished writing the clobberWorldCall class, we could confidently move on to the next class, dfgOperation.&lt;/p&gt;
    &lt;p&gt;Knowing exactly when JSC calls clobberWorld is not enough to ultimately model operations for side effects. Under the function executeEffects, there is no reference to the actual operation that holds the code we wish to analyze. All we have is the operation code, taken from the switch case under executeEffects.&lt;/p&gt;
    &lt;p&gt;So, in our next step, we will link the opcode (operation code) to the operation’s code under the hood. Once we can link these two, we can start analyzing the operation itself and look for possible side effects.&lt;/p&gt;
    &lt;quote&gt;class DfgOperation extends Function{ SwitchCase dfgEffectCase; FunctionCall dfgCallOperation; Function dfgCompile; string opCode; boolean isClobberWorldCalled; DfgOperation() { // Link the dfgOperation to the dfgCallOperation/dfgSlowCallOperation ( ( dfgCallOperation.getTarget().hasName("callOperation") and dfgCallOperation.getArgument(0) = this.getAnAccess() ) or ( dfgCallOperation.getTarget().hasName("slowPathCall") and dfgCallOperation.getArgument(2) = this.getAnAccess() ) ) and dfgCompile = getSpeculativeJitCompile() // We have 2 known options (all happens under the function SpeculativeJIT::compile): // 1) We call directly to the callOperation from the switch case // 2) We call to a wrapper function named compileSomeOperation from the switch case and ( opCode = getOpCodeSimpleCase(dfgCallOperation) or opCode = getOpCodeByCompileOperation(dfgCallOperation) ) and … // Find if ClobberWorld is called – Actual Linking Stage and if exists ( ClobberWorldCall clobber | clobber.getAnOpCode() = opCode ) then isClobberWorldCalled = true else isClobberWorldCalled = false } … }&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Using the figure 10 diagram presented above, we understand that JSC can call an operation using the function callOperation or compile the operation and then call it.&lt;/p&gt;
    &lt;p&gt;So, in our query we first locate all the calls to callOperation/compileOperation, and then, similarly to the clobberWorldCall class, we find the operation code using switch cases or if statements.&lt;/p&gt;
    &lt;p&gt;Once that is done, we can safely link between the clobberWorld calls to the JS operations.&lt;/p&gt;
    &lt;p&gt;Finally, we need to choose which side effects we’re looking for because there are a few options. Since we reviewed earlier the bug in the operation InstanceOf, let’s look for all side effects caused by confusion with proxy objects (we recommend reading the comments):&lt;/p&gt;
    &lt;quote&gt;from FunctionCall fc, VariableAccess jsObjectAccess, Parameter source, DfgOperation operation, Expr asObjArg, Function compareTo where // Extract all accesses to JSObjects isJsObject(jsObjectAccess.getTarget()) and // fc represents all the function calls from a JSObject fc.getQualifier() = jsObjectAccess and // Find functions from ProxyObject that share the function name as fc exists ( Function fromProxy | fromProxy.getParentScope().toString() = "ProxyObject" and compareTo.getName() = fromProxy.getName() and fc.getTarget() = getFunctionWrappers(compareTo) ) and // Make sure JSC does not call clobberWorld for that operation operation.hasACallToClobberWorld() = false and operation.getAParameter() = source and exists // Search for the following flow: // from: operation parameter // to: Converting the parameter to JSObject // or // The parameter is already a JSObject // to: Calling a function from that parameter that exists under ProxyObject and JSObject ( LinkOperationToExecVM config, FunctionCall asObject, ConvertToObjectAndCall config2| ( ( asObject.getTarget().hasName("asObject") or asObject.getTarget().hasName("toObject") ) and asObject.getAnArgument() = asObjArg and config.hasFlow(DataFlow::parameterNode(source), DataFlow::exprNode(asObjArg)) and config2.hasFlow(DataFlow::exprNode(asObject), DataFlow::exprNode(jsObjectAccess)) ) or ( asObjArg = jsObjectAccess.getTarget().getAnAccess() and config.hasFlow(DataFlow::parameterNode(source), DataFlow::exprNode(asObjArg)) ) ) select operation, source, fc, compareTo&lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; Executing this query against a code database created from commit 35b181a20dc25749df383041f950798bd109f47d produced the following results:&lt;/p&gt;
    &lt;p&gt;Figure 11 – Results from our final query. The left column holds the names of the operations. The middle column shows which argument causes the side effects, and the right column shows which function we should hook using a proxy object.&lt;/p&gt;
    &lt;p&gt;We can see that there are five operations suspected to be bugs, and one of them is the bug we studied earlier – great!&lt;/p&gt;
    &lt;p&gt;Digging deeper through the results revealed a second bad side effects modeling vulnerability, CVE-2018-4233. The vulnerable operation is operationCreateThis. This vulnerability was found and exploited by Samuel Groß in pwn2own 2018. Samuel talked about this vulnerability in his Black Hat 2018 conference talk.&lt;/p&gt;
    &lt;p&gt;We’ve managed to find two critical vulnerabilities in JSC that could lead to RCE using a tailor-made CodeQL query. Running that query against a codebase created from an updated version of JSC shows that the two vulnerabilities previously found by our query no longer exist, meaning they were indeed patched. Keep in mind that it does not mean that there are no more vulnerabilities caused by bad side effect modeling. Adding small changes to our query will allow us to determine what kind of side effects we are looking for, and there could be lots of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;What a journey we’ve had. Thanks to you, the realm is a lot safer now.&lt;/p&gt;
    &lt;p&gt;The truth is, I’ve been playing with CodeQL for the past year and I’ve been focused on finding classic vulnerabilities (in my previous blog, I focused on finding vulnerable calls to memcpy with CodeQL). This time, I wanted to see how effective it is to use CodeQL to find much-complicated vulnerabilities in large and tangled projects like WebKit.&lt;/p&gt;
    &lt;p&gt;I knew that this would not be an easy task, and indeed it wasn’t. But the most challenging part was learning and understanding the internals of JSC and not (as I initially thought) writing the query in CodeQL.&lt;/p&gt;
    &lt;p&gt;Once I had gained enough knowledge about the bugs I wanted to find, writing the query was pretty intuitive (I do have some experience with CodeQL by now, but still…) and fun.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links &amp;amp; References&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;http://www.phrack.org/issues/70/3.html&lt;/item&gt;
      &lt;item&gt;https://liveoverflow.com/getting-into-browser-exploitation-new-series-introduction-browser-0x00/&lt;/item&gt;
      &lt;item&gt;https://webkit.org/blog/10308/speculation-in-javascriptcore/&lt;/item&gt;
      &lt;item&gt;https://webkit.org/blog/6411/javascriptcore-csi-a-crash-site-investigation-story/&lt;/item&gt;
      &lt;item&gt;https://saelo.github.io/presentations/blackhat_us_18_attacking_client_side_jit_compilers.pdf&lt;/item&gt;
      &lt;item&gt;https://zon8.re/posts/jsc-internals-part1-tracing-js-source-to-bytecode/&lt;/item&gt;
      &lt;item&gt;https://github.com/assafsion/javascriptcore-bad-side-effect-modeling&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cyberark.com/resources/threat-research-blog/the-mysterious-realm-of-javascriptcore"/><published>2025-12-04T08:33:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145180</id><title>Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs</title><updated>2025-12-04T11:10:39.854692+00:00</updated><content>&lt;doc fingerprint="849e200a55f594ac"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Economics &amp;gt; General Economics&lt;/head&gt;&lt;p&gt; [Submitted on 3 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;econ.GN&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.04047"/><published>2025-12-04T08:38:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145365</id><title>Oracle, it’s time to free JavaScript</title><updated>2025-12-04T11:10:39.434424+00:00</updated><content>&lt;doc fingerprint="4737c13992a7be78"&gt;
  &lt;main&gt;
    &lt;p&gt;Dear Oracle,&lt;/p&gt;
    &lt;p&gt;You have long ago abandoned the JavaScript trademark, and it is causing widespread, unwarranted confusion and disruption.&lt;/p&gt;
    &lt;p&gt;JavaScript is the world’s most popular programming language, powering websites everywhere. Yet, few of the millions who program in it realize that JavaScript is a trademark you, Oracle, control. The disconnect is glaring: JavaScript has become a general-purpose term used by countless individuals and companies, independent of any Oracle product.&lt;/p&gt;
    &lt;p&gt;Oracle’s hold on the JavaScript trademark clearly fits the legal definition of trademark abandonment. A previous blog post addressed this issue, requesting that you, Oracle, release the trademark. Unsurprisingly, the request was met with silence. It is therefore time to take active steps in order to bring the JavaScript trademark into the public domain, where it belongs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trademark abandonment&lt;/head&gt;
    &lt;p&gt;Title 15 of the United States Code, section 1127, states:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;A mark shall be deemed to be “abandoned” if either of the following occurs:&lt;/p&gt;
      &lt;item&gt;When its use has been discontinued with intent not to resume such use. Intent not to resume may be inferred from circumstances. Nonuse for 3 consecutive years shall be prima facie evidence of abandonment. “Use” of a mark means the bona fide use of such mark made in the ordinary course of trade, and not made merely to reserve a right in a mark.&lt;/item&gt;
      &lt;item&gt;When any course of conduct of the owner, including acts of omission as well as commission, causes the mark to become the generic name for the goods or services on or in connection with which it is used or otherwise to lose its significance as a mark. Purchaser motivation shall not be a test for determining abandonment under this paragraph.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;In the case of JavaScript, both criteria apply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Netscape, Sun, Oracle&lt;/head&gt;
    &lt;p&gt;The JavaScript trademark is currently held by Oracle America, Inc. (US Serial Number: 75026640, US Registration Number: 2416017). How did this come to be?&lt;/p&gt;
    &lt;p&gt;In 1995, Netscape partnered with Sun Microsystems to create interactive websites. Brendan Eich famously spent only 10 days creating the first version of JavaScript, a dynamic programming language with a rough syntactic lineage from Sun’s Java language. As a result of this partnership, Sun held the JavaScript trademark. In 2009, Oracle acquired Sun Microsystems and the JavaScript trademark as a result.&lt;/p&gt;
    &lt;p&gt;The trademark is simply a relic of this acquisition. Neither Sun nor Oracle has ever built a product using the mark. Legal staff, year after year, have renewed the trademark without question. It’s likely that only a few within Oracle even know they possess the JavaScript trademark, and even if they do, they likely don’t understand the frustration it causes within the developer community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Use it or lose it&lt;/head&gt;
    &lt;p&gt;Oracle has abandoned the JavaScript trademark through nonuse.&lt;/p&gt;
    &lt;p&gt;Oracle has never seriously offered a product called JavaScript. In the 1990s and early 2000s, Netscape Navigator, which supported JavaScript as a browser feature, was a key player. However, Netscape’s usage and influence faded by 2003, and the browser saw its final release in 2008. JavaScript, meanwhile, evolved into a widely used, independent programming language, embedded in multiple browsers, entirely separate from Oracle.&lt;/p&gt;
    &lt;p&gt;The most recent specimen, filed with the USPTO in 2019, references nodejs.org (a project created by Ryan Dahl, the author of this letter) and Oracle’s JavaScript Extension Toolkit (JET). But Node.js is not an Oracle product, and JET is merely a set of JavaScript libraries for Oracle services, particularly Oracle Cloud. There are millions of JavaScript libraries; JET is not special.&lt;/p&gt;
    &lt;p&gt;(Oracle is not even a member of the OpenJS Foundation - the body that the Node.js project lives under now. Nor does Oracle have any involvement whatsoever in the development of Node.js.)&lt;/p&gt;
    &lt;p&gt;Oracle also offers GraalVM, a JVM that can execute JavaScript, among other languages. But GraalVM is far from a canonical JavaScript implementation; engines like V8, JavaScriptCore, and SpiderMonkey hold that role. GraalVM’s product page doesn’t even mention “JavaScript”; you must dig into the documentation to find its support.&lt;/p&gt;
    &lt;p&gt;Oracle’s use of JavaScript in GraalVM and JET does not reflect genuine use of the trademark. These weak connections do not satisfy the requirement for consistent, real-world use in trade.&lt;/p&gt;
    &lt;head rend="h2"&gt;A generic term&lt;/head&gt;
    &lt;p&gt;A mark can also be considered abandoned if it becomes a generic term.&lt;/p&gt;
    &lt;p&gt;In 1996, Netscape announced a meeting of the ECMA International standards organization to standardize the JavaScript programming language. Sun (now Oracle), refused to give up the “JavaScript” mark for this use though, so it was decided that the language would be called “ECMAScript” instead. (Microsoft happily offered up “JScript”, but no-one else wanted that.) Brendan Eich, the creator of JavaScript and a co-signatory of this letter, wrote in 2006 that “ECMAScript was always an unwanted trade name that sounds like a skin disease.”&lt;/p&gt;
    &lt;p&gt;Ecma International formed TC39, a technical steering committee, which publishes ECMA-262, the specification for JavaScript. This committee includes participants from all major browsers, like Google’s Chrome, Apple’s Safari, and Mozilla’s Firefox, as well as representatives from server-side JavaScript runtimes like Node.js and Deno.&lt;/p&gt;
    &lt;p&gt;Oracle’s ownership of the JavaScript trademark only causes confusion. The term “JavaScript” is used freely by millions of developers, companies, and organizations around the world, with no interference from Oracle. Oracle has done nothing to assert its rights over the JavaScript name, likely because they do not believe their claim to the mark would hold up in court. Unlike typical trademark holders who protect their trademarks by extracting licensing fees or enforcing usage restrictions, Oracle has allowed the JavaScript name to be used by anyone. This inaction further supports the argument that the trademark has lost its significance and has become generic.&lt;/p&gt;
    &lt;p&gt;Programmers working with JavaScript have formed innumerable community organizations. These organizations, like the standards bodies, have been forced to painstakingly avoid naming the programming language they are built around—for example, JSConf. Sadly, without risking a legal trademark challenge against Oracle, there can be no “JavaScript Conference” nor a “JavaScript Specification.” The world’s most popular programming language cannot even have a conference in its name.&lt;/p&gt;
    &lt;p&gt;There is a vast misalignment between the trademark’s ownership and its widespread, generic use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free the mark&lt;/head&gt;
    &lt;p&gt;By law, a trademark is abandoned if it is either not used or becomes a generic term. Both apply to JavaScript.&lt;/p&gt;
    &lt;p&gt;It’s time for the USPTO to end the JavaScript trademark and recognize it as a generic name for the world’s most popular programming language, which has multiple implementations across the industry.&lt;/p&gt;
    &lt;p&gt;Oracle, you likely have no real business interest in the mark. It’s renewed simply because legal staff are obligated to renew all trademarks, regardless of their relevance or use.&lt;/p&gt;
    &lt;p&gt;We urge you to release the mark into the public domain. However, asking nicely has been tried before, and it was met with silence. If you do not act, we will challenge your ownership by filing a petition for cancellation with the USPTO.&lt;/p&gt;
    &lt;head rend="h2"&gt;To you, the readers of this letter:&lt;/head&gt;
    &lt;p&gt;If you agree with us, you are encouraged to sign this open letter below. Your support will help raise awareness and add weight to this cause. If you want to sign as an organization (minimum 25 employees), please email companies@javascript.tm.&lt;/p&gt;
    &lt;p&gt;In addition, we’re seeking pro bono assistance from lawyers with experience in trademark law to help file a Petition for Trademark Cancellation with the USPTO. It’s likely that simply asking nicely will not get a response from Oracle; a legal challenge must be made. Reach out to lawyers@javascript.tm if you can help.&lt;/p&gt;
    &lt;p&gt;Sincerely,&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://javascript.tm/letter"/><published>2025-12-04T09:01:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145834</id><title>Unreal Tournament 2004 is back</title><updated>2025-12-04T11:10:39.386251+00:00</updated><content/><link href="https://old.reddit.com/r/unrealtournament/comments/1pdbe69/breaking_unreal_tournament_2004_is_back/"/><published>2025-12-04T10:06:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46145902</id><title>Tunnl.gg</title><updated>2025-12-04T11:10:38.995771+00:00</updated><link href="https://tunnl.gg"/><published>2025-12-04T10:15:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46146103</id><title>Porn company fined £1M over inadequate age checks (UK)</title><updated>2025-12-04T11:10:38.857883+00:00</updated><content>&lt;doc fingerprint="6815d90315f7f9e1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Porn company fined Â£1m over inadequate age checks&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Published&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Ofcom has fined a porn company Â£1m for failing to put in place sufficiently robust age checks - the biggest penalty it has imposed so far under the Online Safety Act.&lt;/p&gt;
    &lt;p&gt;The Act makes it a legal requirement for websites that host pornographic material to put in place what the regulator determines to be "highly effective age assurance" to prevent children from being able to easily access explicit content.&lt;/p&gt;
    &lt;p&gt;Ofcom said AVS Group Ltd, which runs 18 adult websites, had failed to do this, so was being fined Â£1m, plus Â£50,000 for failing to respond to information requests.&lt;/p&gt;
    &lt;p&gt;AVS must now implement highly effective age assurance within 72 hours or face a daily additional penalty of Â£1,000 a day.&lt;/p&gt;
    &lt;p&gt;In addition to the AVS fine, Ofcom also announced that one "major social media company" was going through compliance remediation with its enforcement team.&lt;/p&gt;
    &lt;p&gt;The regulator has not named the platform but says there may be formal action if it does not see sufficient improvement soon.&lt;/p&gt;
    &lt;p&gt;Ofcom said the fine showed the "tide on online safety" was beginning to turn.&lt;/p&gt;
    &lt;p&gt;"This year has seen important changes for people, with new measures across many sites and apps now better protecting children from harmful content," said Oliver Griffiths, Ofcom's online safety group director.&lt;/p&gt;
    &lt;p&gt;"But we need to see much more from tech companies next year and we'll use our full powers if they fall short," he added.&lt;/p&gt;
    &lt;p&gt;Ofcom has already started issuing fines to some companies for not implementing proper age verification, including deepfake "nudify" applications.&lt;/p&gt;
    &lt;p&gt;However, online message board 4Chan has so far refused to comply with a Â£20,000 fine issued by Ofcom over the summer.&lt;/p&gt;
    &lt;p&gt;The Online Safety Act is being implemented in phases, and is intended to prevent past practices which Ofcom described as online platforms being "unregulated, unaccountable and often unwilling to prioritise people's safety over profits".&lt;/p&gt;
    &lt;p&gt;Tougher age checks for porn websites were introduced in July, though some people have pointed out these could be easily avoided with a virtual private network (VPN), which reroutes internet traffic.&lt;/p&gt;
    &lt;p&gt;In October, Pornhub's parent company told BBC News it had seen a 77% drop in UK visitors since the age checks had come in.&lt;/p&gt;
    &lt;p&gt;Baroness Beeban Kidron, founder of 5Rights Foundation, told the Today programme the fines were "nothing" to tech firms.&lt;/p&gt;
    &lt;p&gt;"Business disruption is everything," she said.&lt;/p&gt;
    &lt;p&gt;"Unless we're prepared to use the law, they're not really doing what Parliament asked them to do.&lt;/p&gt;
    &lt;p&gt;"We need a whole different attitude about the level of intensity and robustness from the regulator to say - we've got the law and we're using it."&lt;/p&gt;
    &lt;p&gt;Also introduced this year were tougher guidelines on ensuring the internet was safer for women and girls, with Ofcom vowing to name and shame platforms that did not comply.&lt;/p&gt;
    &lt;p&gt;Critics say the Act needs to be toughened to make the internet safer, particularly for women and girls.&lt;/p&gt;
    &lt;p&gt;Sign up for our Tech Decoded newsletter to follow the world's top tech stories and trends. Outside the UK? Sign up here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.co.uk/news/articles/c93nll07z3go"/><published>2025-12-04T10:47:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46146133</id><title>PGlite – Embeddable Postgres</title><updated>2025-12-04T11:10:38.727133+00:00</updated><content>&lt;doc fingerprint="e74292d12d3170e0"&gt;
  &lt;main&gt;&lt;head rend="h2"&gt;Lightweight&lt;/head&gt;&lt;p&gt;A complete WASM build of Postgres that's under 3MB Gzipped.&lt;/p&gt;&lt;p&gt;Embeddable Postgres&lt;/p&gt;&lt;p&gt;Run a full Postgres database locally in WASM with reactivity and live sync.&lt;/p&gt;&lt;p&gt;Create and publish a Postgres database using AI Supabase:&lt;/p&gt;built on PGlite by&lt;p&gt;This is a full PGlite Postgres running in your browser. pgvector!&lt;/p&gt;It even includes&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pglite.dev/"/><published>2025-12-04T10:52:42+00:00</published></entry></feed>