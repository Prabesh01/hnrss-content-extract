<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-06T16:42:46.572818+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45481892</id><title>The QNX Operating System</title><updated>2025-10-06T16:42:54.501523+00:00</updated><content>&lt;doc fingerprint="ff9e891d51a325c6"&gt;
  &lt;main&gt;
    &lt;p&gt;Gordon Bell and Dan Dodge were finishing their time at the University of Waterloo in Ontario in 1979. In pursuit of their masters degrees, they’d worked on a system called Thoth in their real-time operating systems course. Thoth was interesting not only for having been real-time and having featured synchronous message passing, but also for originally having been written in the B programming langue. It was then rewritten in the UW-native Eh language (fitting for a Canadian university), and then finally rewritten in Zed. It is this last, Zed-written, version of Thoth to which Bell and Dodge would have been exposed. Having always been written in a high-level language, the system was portable, and programs were the same regardless of the underlying hardware. Both by convention and by design, Thoth strongly encouraged programs to be structured as networks of communicating processes. As the final project for the RTOS course, students were expected to implement a real-time system of their own. This experience was likely pivotal to their next adventure.&lt;/p&gt;
    &lt;p&gt;The duo’s first year after graduation was a busy one. They moved to Kanata, went to work for Bell-Northern Research (now Nortel), and on the 30th of March in 1980, they founded Quantum Software Systems. To continue their research and experimentation with operating systems, they assembled a microcomputer built around a Motorola 6809. With the release of the IBM PC in September of 1981, Quantum’s efforts shifted to that target. Their goal was to produce a real-time operating system that would enable the PC’s use in factories, communication systems, and anywhere else that emphasized reliability.&lt;/p&gt;
    &lt;p&gt;The first version of Bell and Dodge’s operating system was QUNIX 0.1 (the Q could have been for Quantum, or for Quick, I’ve seen both from former Quantum employees), and it was running on that early, hand-assembled, 8bit microcomputer. This earliest creation was never released outside of Quantum Software as far as I know. QUNIX was a vaguely UNIX-like, microkernel, real-time operating system. I say that it was vaguely UNIX-like because in these early versions, there were some serious differences. In QUNIX, there were CP/M-like things too. Each disk had a drive number prefix, non-disk device files’ names were reserved, and the commands were a bit different from those in UNIX, often simplified to the point of being more CP/M-like than UNIX-like. Another major difference was the directory hierarchy. On a traditional UNIX system, binaries were stored in &lt;code&gt;/bin&lt;/code&gt; or &lt;code&gt;/usr/bin&lt;/code&gt;, configurations in &lt;code&gt;/etc&lt;/code&gt;, and user directories in &lt;code&gt;/home&lt;/code&gt;. On QUNIX, this wasn’t the case. Commands included in the path variable were in &lt;code&gt;/cmds&lt;/code&gt;, configuration files were in &lt;code&gt;/config&lt;/code&gt;, the OS binaries were in &lt;code&gt;/sys&lt;/code&gt;, user directories were &lt;code&gt;/user&lt;/code&gt;, drivers were in &lt;code&gt;/drivers&lt;/code&gt;, and utilities were in &lt;code&gt;/util&lt;/code&gt;. Then, the &lt;code&gt;man&lt;/code&gt; command did not exist, and &lt;code&gt;help&lt;/code&gt; was used instead. Instead of &lt;code&gt;ps&lt;/code&gt;, the system had &lt;code&gt;task&lt;/code&gt; with the labels of father, son, and brother to denote parent and child processes. The first version of QUNIX for the IBM PC was made before the end of 1981, and released either in December of 1981 or January of 1982, making QUNIX the first known microkernel operating system for the PC platform.&lt;/p&gt;
    &lt;p&gt;A fun note from Paul N. Leroux, the bar chart on the monitor in the back left was physically glued to that monitor for another press image. It wasn’t meant to be in this image, but as photo editing tools were essentially non-existent at the time, fixing this would have required them to reshoot. They chose to go to press with bar chart present.&lt;/p&gt;
    &lt;p&gt;With QUNIX 0.4.33 in 1982, QUNIX became the first operating system for the IBM PC to support a hard disk, and in particular, it supported a 5MB Davong HDD. Given that a 10MB disk in 1982 could cost around $3000, it makes sense that the company’s first target was a bit more modest. At this point, however, QUNIX would not boot from an HDD. All of the floppy contents could be copied to a hard disk, but the user would still need to boot from a floppy disk.&lt;/p&gt;
    &lt;p&gt;Even in these early stages of development, the system began getting recognition, and this became a small problem. The name QUNIX was a bit too close to the name UNIX for AT&amp;amp;T. The name of the system was changed to QNX in late 1982 following a Cease and Desist by AT&amp;amp;T. The first official QNX version was released the following year. At the time of the name change the kernel consisted of around 10K line of C, and it handled task scheduling, message passing, and task priority. Everything else was implemented in services that used the microkernel’s message passing to communicate with each other (even drivers, filesystems, and networking). As an important feature, message queues were network transparent so a task on one physical machine could communicate with a task on a separate physical machine on the same network as easily as if it were local. This inherently multitasked and multiuser system allowed 250 simultaneous tasks from 4 to 16 simultaneous users. The system would make extensive use of the 8087 if it was available, and required a minimum of 96K RAM. Loading up the C compiler would require an additional 32K. It’s impressive what the small company achieved on the 8088, even if, for the time, the RAM requirements were quite high. QNX release version 1.0, in March of 1983, running on an IBM PC achieved 29% to 47% the speed of a DEC VAX 11/780 depending upon the task at hand when tested by Rao Mikkilineni at Bell Labs. Sadly, I’ve been unable to find his original write-up of his testing, which was apparently in the publication Personna. If you have information about it, I’d love to get some details. While RV1 was limited to just C and x86 assembly language, the company was hard at work on BASIC, FORTRAN, and Pascal compilers that would utilize common code generators allowing for the mixed-use of languages without losing optimization. With the introduction of GUIs on the Apple Lisa, Xerox systems, and VisiCorp’s Visi-On, Quantum also had plans for windowing as well. According to Quantum’s president Syd Geraghty in InfoWorld on the 21st of March in 1983, the majority of customers were high-end system developers at large corporations. Version 1.0 cost $650 in 1983 (around $2100 in 2025), and that included a C compiler, full-screen editor, the ability to read MS-DOS disks, and full networking support. I haven’t found much information about versions 1.1 through 1.14, but I did find some information about 1.20 released on the 15th of November in 1984. This version brought pattern matching on filenames in the current directory, expanded shell programming, &lt;code&gt;login&lt;/code&gt; was now a separate task with fast user switching and login stacking, &lt;code&gt;TCAP&lt;/code&gt; (think terminfo), &lt;code&gt;ed&lt;/code&gt; was rewritten and supported full-screen visual mode (think Vi), and support for the IBM AT (real-mode) was added. The price of QNX had also fallen to $450.&lt;/p&gt;
    &lt;p&gt;In June of 1981, the Ontario Ministry of Education identified computing as being important for the future, and they wanted to bring computing into their schools. They were also quite aware that some teachers had taken the initiative to bring microcomputers into their classrooms already, and the Commodore PET was the most common for programming courses, while the Apple II was the most common for other educational programs. Targeting many computers would have meant that they’d have rather high software development costs in any attempt to achieve standardization, and it was therefore decided that they’d need a single computer. In 1983, it was found by the ministry and the Canadian Advanced Technology Alliance that no existing computer would fully satisfy the goals of their educational computer. By March that year, some requirements had been drafted: all-in-one PET-like design, headphone output for voice and sound, a trackball, an 80186 CPU, a multitasking operating system, color graphics, voice synthesis, keyboard with accented characters, and networked storage (no physical disk in the computer itself). This machine as described had the sobriquet “bionic beaver.”&lt;/p&gt;
    &lt;p&gt;With the specifications in hand, Robert Arn at CATA created CEMCORP (Canadian Educational Microprocessor Corporation) and won a contract from the ministry for $10 million to develop the initial machines. This resulted in the ICON having been chosen. This machine was initially manufactured by Microtel and it ran QNX from Quantum Software Systems. The first machines were delivered in 1984. Later machines were produced, sold, and supported by Burroughs Canada, and after the merger with Sperry in 1986, by Unisys.&lt;/p&gt;
    &lt;p&gt;The ICON was built around an Intel 80186 clocked at 7.16MHz and 512K RAM. It lacked any local storage having neither a hard disk drive nor floppy disk drive. At boot, the computer grabbed QNX from a local LexICON file server over a 2.5Mbps ARCNET connection, and loaded the OS into RAM. Once loaded, the user logged into the system and his/her home directory was on the file server. Up to 32 of these machines could be on a single LAN. Saving any work to a floppy, meant putting the floppy into the file server, and then copying the file from the LexICON hard disk (early models were 10MB, later models were 64MB) to that floppy. The cost of these machines was high at $2500, but any school need only have paid $495 with the government covering the rest. One incredibly forward thinking feature was the lessonware. This would have been a hypertext system in which educators could have written pages that linked to others building an extensive corpus overtime. Even applications could have been run by simply clicking a link. This model was rejected by the ministry before the ICON shipped, and was replaced by a top-down system with ministry making lesson decisions. This also resulted in the ICON having shipped a QNX CLI with the CEMCORP text editor in the earliest models.&lt;/p&gt;
    &lt;p&gt;The ICON was a project hated by many and loved by many. For detractors, it was seen as expensive and wasteful while not exposing students to industry currents. For supporters, it accomplished all of its goals. It was excellent for programming, and it was excellent at multitasking, networking, and running educational software. The software was also quite reliable. It was QNX doing what QNX does best.&lt;/p&gt;
    &lt;p&gt;From students who used ICONs, we know that it did have educational games, text editors, compilers, word processors, spread sheets, circuit design and simulation software, and CAD software. Of course, being networked machines, some unconventional students figured out ways to hack into other machines over the network, print stuff to other students’ screens, and generally cause some chaos. Combined with audio capabilities (later models even included MIDI support), this apparently got a bit out of hand from time to time.&lt;/p&gt;
    &lt;p&gt;I normally wouldn’t show so many ads, but here is a development that is rather interesting. OS/2 had been announced on the 2nd of April in 1987, and Quantum perceived the OS as a real threat. The comparisons to UNIX were now joined by comparisons to OS/2, and QNX wanted to be certain that people understood QNX to be superior. This advertisement also shows us that QNX had responded to OS/2’s ability to run DOS software by adding that feature to QNX with the QDOS II (invoked as &lt;code&gt;QDOS&lt;/code&gt;) emulator, or by running a DOS application as a task via &lt;code&gt;RUNDOS&lt;/code&gt;. QNX had been ported to the IBM PS/2 as well. This was QNX version 2.&lt;/p&gt;
    &lt;p&gt;As far as I can tell, the release of QNX version 2 was announced on the release date of version 1.2. The release of this version appears to have been quite late, and it occurred in autumn of 1987 (two years after the initial release date given). This release brought protected-mode support for the IBM AT, full LAN support with some networking enhancements ported from BSD, support for files of up to one terabyte in size, up to 32 serial ports in one machine, and a somewhat primitive GUI called House about which I can find nothing but the name.&lt;/p&gt;
    &lt;p&gt;While I couldn’t find anything about the House graphical environment, QNX Windows running the Open Look Window Manager (OLWM) is available.&lt;/p&gt;
    &lt;p&gt;In June of 1987, Quantum Software Systems ceased renting their office space, and they moved into a building they’d had built just for them. Following this, the company would expand the building three times, and finally add another building. So, the company moved from 215 Stafford Road to 175 Terrance Mathews Crescent.&lt;/p&gt;
    &lt;p&gt;As late as 1990, QNX advertisements still mentioned performance on the 80286. This seems more as though Quantum didn’t spend much on marketing rather than not having progressed. In Dan Hildebrand’s An Architectural Overview of QNX from April of 1992, we find that the company had developed QNX versions up to 3.15, and articles about operating systems in the tech press had mentioned QNX as one of the systems that took advantage of features in the 80386.&lt;/p&gt;
    &lt;p&gt;In 1989, Quantum Software Systems began work on a dramatic overhaul of the operating system. This new version would be fully POSIX-compliant and increase performance over the prior generation of QNX operating systems. This version, 4.0, was released in 1991. The kernel now had just 14 calls associated with IPC, network, scheduling, and interrupts, and the kernel weighed in at just 7K (605 LOC), allowing the entire kernel to fit in CPU caches of the time. Unlike earlier versions, messages were no longer queued. Instead, they were copied from process to process. Being POSIX-compliant allowed for the easier porting of software, and it also meant that the directory hierarchy was decidedly more familiar to UNIX veterans. Beyond source compatibility, Quantum was actively working on becoming binary compatible with UNIX as of 1992. In 1994, beyond POSIX and performance, QNX 4.1 introduced the QNX Photon microGUI. This system was developed by Patrick Hayden and Robin Burgener. Much like the underlying system, it was built around a microkernel (around 20K), and it was network transparent. A Photon application could have its interface beamed to another QNX 4 machine at any point in time, or it could be dragged from one device to another just as easily. Photon likewise allowed remote monitoring or control of the user interface. This worked regardless of the device class (desktop, laptop, handheld, server). For those who needed it, the X Windows System (X11R5, Motif Window Manager) was also available, though Photon did implement a binary interface library that was X compatible. Being so lightweight allowed the company to release a demo disk that combined networking, a web browser, web server, graphical environment, file manager, text editor, a vector animation demo, and Towers of Hanoi game onto a single 1.44MB floppy. Unlike prior QNX versions, version 4 required at least an Intel 80386 and VGA graphics card. No 16bit systems were supported.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;KANATA, ONTARIO, September, 1994—QNX Software Systems Ltd., developers of the QNX realtime operating system, announced a unique window system targeted for handheld and embedded applications.&lt;/p&gt;&lt;lb/&gt;According to Rob Oakley, Corporate Communications and Product Management, "the Photon Window System is the first of its kind—a GUI built around a graphical microkernel."&lt;lb/&gt;QNX Software Systems designed the Photon Window System as a graphical microkernel and a team of cooperating processes, basing this design on the company's QNX OS, a microkernel network-distributed system.&lt;lb/&gt;Photon's cooperating processes provide the functionality to scale the system up into a full-featured windowing system or down to fit into resource-constrained environments, like handheld personal computers (HPCs) and compact embedded systems.&lt;lb/&gt;Photon provides a rich widget library that operates much like the X Window System widget set, with an X-inspired API. A Motif-like window manager and a code-generating, visual application builder are also available.&lt;lb/&gt;"Photon is extremely light and fast. It runs in only 256K, yet provides enormous GUI functionality," Oakley said.&lt;lb/&gt;Like the QNX OS itself, Photon is network transparent—an HPC running Photon and QNX, equipped with a wireless LAN interface, becomes a transparent extension of the LAN, able to use all the LAN's resources as if they were integrated directly into the HPC. The power this brings to the HPC user is difficult to appreciate—imagine having the power of 100 Pentiums in the palm of your hand!&lt;lb/&gt;According to Dan Dodge, Vice President R&amp;amp;D, "Photon applications are very network distributed. From the application's perspective, all the resources of all the nodes on the LAN look like a single, logical machine. The environment is so transparent that a user can drag applications from one physical screen to another."&lt;lb/&gt;For example, a user in a factory control environment could walk up to a computer and drag an application from the control screen onto an HPC, and then walk out onto the factory floor with it and interact with the live application.&lt;lb/&gt;Although Photon is aimed at compact environments, its dynamic range is extensive. "Photon's API and rich widget library can support high-performance GUI applications with enough functionality to enter the domain of X, while consuming only a fraction of the resources," said Dodge.&lt;lb/&gt;The QNX operating system is a POSIX-certified realtime OS for Intel and AMD processors. Scalable and modular, QNX fits a wide range of environments, from compact embedded controllers to resource-rich X-based development systems, to distributed realtime systems running hundreds of CPUs.&lt;/quote&gt;
    &lt;p&gt;Versions 4.2, 4.22, and 4.24 all released in 1995. The final version 4 release was 4.25 in 1997. At least one QNX 4 installation ran for over 20 years without a reboot at the ESA. This was possible because peripherals could be hotswapped, drivers could be changed, and network nodes could be added or removed without bringing the system down.&lt;/p&gt;
    &lt;p&gt;Notably, we see that in 1994, Quantum renamed itself to QNX Software Systems Limited. And with a new name and a new version of their operating system, the company won some major installs. From POS systems at FasFax that allowed for real-time sales figures from geographically disparate locations, to video conferencing systems at Georgia State University, to factories, power plants, hospitals, set-top boxes, phone systems, trains, jets, the Space Shuttle, ISPs, and even traffic lights. The price for a single license dropped to around $285 at this time, and by 1995, QNX was the leading real-time OS for x86 systems. The majority of the company’s revenue was from large enterprises.&lt;/p&gt;
    &lt;p&gt;Of course, change was coming in the 1990s, and QSSL knew it. The company took the QNX kernel from version 4.24 and forked it. They had multiple goals with this fork. The system needed to be SMP capable, support POSIX, and be more portable to new hardware. The kernel handled only IPC, message passing, interrupts, and timing. Threading became the minimal unit of scheduling. The new Process Manager then used a loader thread that copied a process’s image into memory freeing the Manager to service other requests while a program continued to load. Naturally, being a real-time system, priority levels were used when scheduling any time-critical process, and new processes inherited the priority of their parent by default. The Process Manager weighed in at 32K (same size as the kernel itself) but added memory allocation, process contexts, resource-manager namespaces, and so on. In this new QNX version, the Process Manager ran inside the microkernel’s address space, but was the only element of the OS to do so. Much of the network stack for this version came from NetBSD, and with that came the ability to use NetBSD network drivers. There was another major change that came from the wider UNIX world, GCC. This naturally meant that language support was quite broadened to include not just C, C++ but all of the other languages supported by the GNU Compiler Collection. This became QNX Neutrino 1.0 released in 1996.&lt;/p&gt;
    &lt;p&gt;On the 19th of October in 1998, QSSL announced QNX Neutrino 2.0 which featured UPM (Universal Process Model). In the words of CTO Dan Dodge:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The premise of UPM is simple. Go beyond the limited MMU protection provided by the other major embedded OSs - where only applications are prevented from corrupting memory - and extend that protection down to services at the kernel level. The result? For the first time, MIPS and PowerPC-based embedded systems can intelligently recover from software faults in drivers, protocol stacks, and custom OS extensions - typically without rebooting.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX was branching into non x86 platforms, and this included PowerPC processors: 401, 403GC, 603e, 821, 823, 860; MIPS processors R4000 and R5000; and naturally all x86 CPUs from the 80386 onward. At this stage, however, the development environment was restricted to QNX 4 and Windows 95/98/NT.&lt;/p&gt;
    &lt;p&gt;This announcement was followed by another about a partnership with Amiga:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Cologne, Germany, November 13 - Amiga Inc. today announced a partnership with QNX Software Systems Ltd. to utilize the QNX realtime operating system (RTOS) as the foundation for the next-generation Amiga architecture. The announcement was made at Computer '98 in Cologne.&lt;/p&gt;
      &lt;p&gt;"The Amiga shook the industry in the 80s with world-leading multimedia architecture," said Jeff Schindler, general manager of Amiga Inc. "QNX's RTOS resembles many of Amiga's unique qualities. It provides the foundation in reaching our vision for the rebirth of Amiga in the new millenium."&lt;/p&gt;
      &lt;p&gt;"We see this partnership as a powerful combination of superior OS technologies, common corporate cultures, and shared business vision," said Dan Dodge, Chief Technology Officer and Cofounder of QNX Software Systems Ltd.&lt;/p&gt;
      &lt;p&gt;About Amiga&lt;/p&gt;
      &lt;p&gt;Amiga Inc. is a technology company targeting the next generation of Amiga architecture with a continued focus on multimedia and the Internet. Since the introduction of the Amiga A1000 in 1985, Amiga has represented the embodiment of the efficient use of memory and hard drive capacity, while pioneering industry developments in multimedia, 32-bit multitasking, and autoconfiguration. Amiga led the industry in combining computer graphics, animation, and film sequences with stereo sound known today as multimedia. Visit http://www.amiga.com and http://www.amiga.de.&lt;/p&gt;
      &lt;p&gt;About QSSL&lt;/p&gt;
      &lt;p&gt;Founded in 1980, QNX Software Systems is one of the top three realtime operating-system vendors in the world, with products licensed in more than a million systems worldwide. The company has established a strong customer base in a variety of industries, including aerospace, telecommunications, medical instrumentation, process control, point-of-sale, consumer electronics, finance, and telephony. With products distributed in over 100 countries, the company is headquartered in Ottawa, Canada.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Amiga port should have been somewhat straightforward considering that Amiga accelerators had been using PowerPC chips, and those chips were now supported by QNX. Gateway’s Amiga team was working closely with QSSL to build a new Amiga (Amiga NG) around the PowerPC G3 and G4 chips running QNX, and these were apparently prototyped as single, dual, and quad processor machines. During alpha testing, Gateway PowerPC boards apparently had some issues, and the two parties blamed one another. By the middle of 1999, Gateway, QSSL, and to some extent Motorola, had poured a hefty sum into the project, and Gateway began insisting on a solid date for the availability of a QNX Neutrino port. Evidently they weren’t satisfied, and I do not believe communication between the two teams, which had one been quite good, was solid by this point. At noon on the 8th of July in 1999, Dan Dodge announced the QNX Developers Network for Amigans. This was followed by another announcement at 15:15 the following day:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Eight months ago we were chosen by Amiga as their foundation OS partner. Our development group was thrilled to be part of the rebirth of such an innovative product. To meet the challenge we knew it would take a tremendous effort on our part. We had a team of people in place working on our part of the Amiga NG soon after the alliance was announced. Over the next few months we involved more and more of our engineering resouces towards making QNX an advanced multi-media platform. Our investment so far has been significant. These are costs we have borne ourselves.&lt;/p&gt;
      &lt;p&gt;It is clear today from Jim's letter that we were not chosen for the next generation Amiga. Naturally we're disappointed. So, where do we stand now? It is not our intent to confuse the Amiga community. We are proud of what we have accomplished and want to include Amigans in what we've achieved. I did make a promise to deliver an operating system and I intend on keeping that promise. I don't want to split the community, nor do I wish to engage in a war of words. I don't ask you to "trust" me or to take me at my word. Both QNX and Amiga have promised to deliver technology into your hands in the very near future. I ask only that your assessment of QNX be based on what we do and what we deliver.&lt;/p&gt;
      &lt;p&gt;Thanks for the overwhelming support we have received so far.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That letter by Jim Collas read, in part:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Dear Amigans,&lt;/p&gt;&lt;p&gt;After months of research and in-depth discussions with all of our technology partners we have decided to use Linux as the primary OS kernel for the new Amiga Operating Environment (OE). I know this decision is a shock to many of you given the previous announcements and activities relative to QNX. This was a very complicated and difficult decision to make and I assure you that I didn't make this decision without a significant amount of research and deliberation. We have been researching Linux since February but didn't finalized our decision until several weeks ago. We were planning to communicate it to the Amiga community in the technology brief that will be released in the next few days.&lt;/p&gt;&lt;p&gt;I am pressed to communicate the Linux decision before the technology brief because of information released by QNX in the last few days. This information had not been reviewed or approved for release by Amiga. In light of our Linux decision, this information is confusing and misleading so I would like to take the time to clarify the situation. I can't disclose any details of the Amiga/QNX discussions because of legally binding confidentiality agreements but I can talk to you about our decision to use the Linux kernel. I think that you will agree that this is the right decision once you understand the reasons for this decision.&lt;/p&gt;&lt;p&gt;Before I continue, I should mention that our technology decision does not reflect negatively on QNX. I believe that QNX is a good company with great technology. I just believe that Linux gives us a better chance of executing our plans successfully. The decision to use QNX as our OS partner on our next generation multimedia convergence computer (MCC) was made late last year. When I took over as president of Amiga in February of this year, I initiated an in-depth review of existing Amiga plans and decisions. As president of Amiga I had to make sure that we were defining a strategy and an execution plan that would allow Amiga and the Amiga community to be successful. We reviewed our strategy, architecture decisions, technology partners, and execution plans. During this review period we also added a number of very talented and experienced people to help us finalize our technology and product decisions. I am confident that we now have a solid and exciting plan that people can have confidence in.&lt;/p&gt;&lt;p&gt;Linux has been picking up substantial momentum over the past year as a viable, open OS alternative in the marketplace. This momentum, the growing commitment to Linux applications from a wide variety of software vendors, and the growing availability of Linux device drivers from hardware vendors, makes it a compelling candidate. Additionally, with all of the significant component suppliers putting resources on writing drivers for Linux it was difficult to get them to port to yet another operating system. Using the Linux OS as a foundation for our Amiga OE allows us to leverage a significant amount of available software drivers and utilities. This allows us to quickly support multiple graphics cards and other peripherals.&lt;/p&gt;&lt;p&gt;Given the above-mentioned advantages, we decided to do an in-depth technical analysis of Linux to determine if it was a suitable OS kernel for our new Amiga operating environment (OE). As we ported parts of our higher level operating environment and AmigaObject architecture to Linux, we discovered some significant performance advantages in the Linux kernel in areas such as distributed object messaging across a network (up to 10X the performance of Windows NT).&lt;/p&gt;&lt;p&gt;Does this mean that the next generation Amiga will not be unique? Absolutely not! Remember that the OS kernel is only one component of the new Amiga OE and the hardware is unique. The revolutionary nature of the Amiga OE is in the way it extends the traditional operating system to provide a host environment for a new class of portable applications - applications that exist in a pervasive networked computing environment. We will be integrating multiple technologies including an efficient windowing environment and a unique user interface. In summary, we decided to use Linux because of the incredible momentum and the fact that it is solid technology and a good foundation for our new Amiga OE.&lt;/p&gt;&lt;p&gt;Additionally, the Linux community is an impressive force that we should be aligned with. We share many common values and objectives with the Linux community. Using Linux as our OS kernel allows us to build a unique and revolutionary operating environment while leveraging the enormous momentum of Linux. The soon to be released technology brief will further explain our architecture and plans for integrating all of the selected technology. Once you read it, I am confident that you will understand the revolutionary nature of the next generation Amiga. I assure you that Amiga and the Amiga community will be a driving force behind the next computer&lt;/p&gt;&lt;lb/&gt;revolution.&lt;/quote&gt;
    &lt;p&gt;As a person using Linux at the time, I believe this to have been the wrong decision. Despite the momentum that Linux had, it wasn’t (still isn’t) as stable, as reliable, or as efficient as QNX. If network performance were a serious consideration, one of the BSDs would have been the better choice. Linux’s hardware support also wasn’t that great in reality. While it could run on quite a bit of kit, it didn’t always support that hardware well, and it didn’t always support all features. Plus, QNX was doing the work to build drivers for the new Amiga. Of course, none of this really mattered. Gateway chose to divest itself of Amiga entirely. The new Amiga Inc. then turned to AmigaOne Partners for Amiga OS 4.&lt;/p&gt;
    &lt;p&gt;QNX Neutrino 2.1 was released in 1999 with support for Java, the Glide API, a wide array of microcontrollers, ARM, StrongARM, and Hitachi SH-4. Interestingly, this release had beta packages including RealPlayer and X in Photon, and it had experimental packages that included Quake 3 Arena and Doom.&lt;/p&gt;
    &lt;p&gt;On the 14th of September in 1999, QNX made an announcement that would shape the future of QNX. The company was partnering with Motorola to develop automobile driver information systems that included in-vehicle navigation, internet access, natural language processing, car audio, multimedia, and vehicle information dashboards. While the Motorola unit responsible for mobileGT wouldn’t last and the unit at IBM working on Java wouldn’t last, QNX would survive and thrive in that segment.&lt;/p&gt;
    &lt;p&gt;QNX version 6 was released on the 18th of January in 2001. The new version was focused on multimedia with streaming video and audio as well as hardware accelerated MPEG encode/decode. The new system included a web based package manager greatly easing the installation of available software. Thankfully, all supported architectures could now be used for developing QNX native software too. Version 6.1 was mostly a patch release and followed later the same year. QSSL was a founding member of the Eclipse Foundation, and QNX software development got quite a bit better with the release of the Momentics Tool Suite on the 4th of June in 2002 (along with QNX 6.2). This was largely the Eclipse IDE combined with a series of plugins that were QNX and Photon oriented.&lt;/p&gt;
    &lt;p&gt;The last release of QNX by QSSL was version 6.3 on the 3rd of June in 2004. This version was visually slightly different, and Voyager was replaced by the Mozilla Suite. The development environment was improved and now offered a clustering framework for the development of networked applications utilizing distributed processing. Among the highlights for this release were SCTP support, IP filter and NAT support, IPv6 support, 2D and 3D graphics layering/compositing, full UTF8 support in Photon, USB2 host support, and support for up to 64GB of RAM on x86 and PPC, up to 1TB on MIPS.&lt;/p&gt;
    &lt;p&gt;On the 27th of October in 2004, QNX Software Systems Limited was purchased by Harman International Industries. Harman specifically wanted to focus on QNX Neutrino in the embedded market, and within that market, specifically on automotive applications where Harman had found a market in audio. Under Harman’s ownership, QNX operated as a separate division led by Dan Dodge as CEO. While QNX did continue to serve networking, medical, and industrial markets, the direction was clear. What had begun with the Motorola partnership in automotive would become the primary market.&lt;/p&gt;
    &lt;p&gt;QNX development continued with 6.3 SP1, SP2, and SP3. Version 6.3.2 was released on the 16th of August in 2006, 6.4 on the 30th of October in 2008, and 6.4.1 in May of 2009. Throughout that time period, QNX had introduced support for Adobe Flash and developed the QNX CAR platform winning a trophy from Adobe for their efforts. This platform was built of modular components allowing manufacturers to mix and match based upon the market segment. QNX was chosen by companies like BMW, Mercedes, Dodge, Toyota, Volkswagen, and Audi. When QNX demoed their automotive systems in the 2007-2009 timeframe, they had concept dashboards. These all ran QNX Neutrino on ARM CPUs (often Freescale i.MX6 or TI Sitara [Cortex A8]) with the EtherCAT motion library, and many demo units had UIs created in Qt5 and QML while a few had hardware accelerated OpenGL interfaces. From 2008 to 2010, QNX had been licensed for use in more than 17 million in-vehicle systems representing an increase of around 130% over those two years. By March of 2010, more than 200 vehicles were already shipping with QNX, and the QNX CAR platform had more than 60 participants. Those participants included 17 auto makers and 26 automotive suppliers.&lt;/p&gt;
    &lt;p&gt;On the 9th of April in 2010, Research in Motion announced their acquisition of QSS from Harman for $200 million:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“RIM is excited about the planned acquisition of QNX Software Systems and we look forward to ongoing collaboration between Harman, QNX and RIM to further integrate and enhance the user experience between smartphones and in-vehicle audio and infotainment systems," said Mike Lazaridis, President and Co-CEO at RIM. "In addition to our interests in expanding the opportunities for QNX in the automotive sector and other markets, we believe the planned acquisition of QNX will also bring other value to RIM in terms of supporting certain unannounced product plans for intelligent peripherals, adding valuable intellectual property to RIM's portfolio and providing long-term synergies for the companies based on the significant and complementary OS expertise that exists within the RIM and QNX teams today."&lt;/p&gt;
      &lt;p&gt;"We welcome the opportunities that a strengthened relationship with RIM will create, as two innovation leaders collaborate to bring new connectivity solutions to the industry," said Dinesh C. Paliwal, Harman's Chairman, President and CEO. "We expect to maintain our close association with QNX and the cutting-edge software solutions it provides to Harman and our customers. We believe our leading customers will fully endorse this move and see it as a major step in advancing seamless connectivity and integration among intelligent devices."&lt;/p&gt;
      &lt;p&gt;"Like Harman, RIM shares our passion for innovation and reliability, so we are absolutely thrilled with this opportunity," said Dan Dodge, CEO, QNX Software Systems. "Moreover, RIM will give us the best of all possible mandates: to continue on our innovation path and to increase investment in our core products, professional services, and go-to-market channels. This is a great time to be a QNX customer, as we focus on collaborating with RIM to create an even more exciting platform for the next generation of connected and embedded devices."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Also in 2010, QNX gained the QNX Safety kernel variant. This was a version of Neutrino that was security hardened specifically for mission critical applications. This variant continues to this day with the most recent version (8.0) having been independently certified by TÜV Rheinland to meet several standards including ISO 26262 ASIL D, IEC 61508 SIL3, IEC 62304 Class C, and ISO/SAE 21434. Aside from security hardening, the QNX Safety variant is still fully compatible with Neutrino’s native APIs and POSIX.&lt;/p&gt;
    &lt;p&gt;In July of 2010, QNX Neutrino 6.5 was released. This version brought performance improvements to the kernel when systems were seeing high memory utilization, the kernel gained zombie reaping, and it gained address space randomization. SMP support was increased, and CPU support was extended to ARMv7 Cortex A-9. The Photon microGUI saw some refinements. As one would expect, version updates were present for everything imported from BSD, Linux, and GNU. This version could make use of the NetBSD’s Pkgsrc tool.&lt;/p&gt;
    &lt;p&gt;Version 6.5 was forked to create both the BlackBerry Tablet OS and BBX shortly after its creation. The first device to see a QNX-derived operating system from RIM was the PlayBook, which featured an OMAP 4430 SoC (1.5 GHz dual-core A9), PowerVR SGX540 GPU, 1GB of RAM, 16GB of eMMC flash, a 1024 by 600 seven inch LCD, Bluetooth, 802.11n, USB2, micro HDMI, a 5MP rear camera, and a 3MP front camera. It measured 5.1 inches by 7.6 inches, was about 2/5 of inch thick, and it weighed just under a pound.&lt;/p&gt;
    &lt;p&gt;The PlayBook was released on the 19th of April in 2011 to mixed reviews. While many loved the webkit browser, user interface, HDMI output, and multitasking, many loathed the requirement of a BlackBerry to get certain apps working. Additionally, there was a dearth of third party applications. This latter complaint did get ameliorated. While at launch there weren’t too many applications, this grew to over 24,000 by the same time the following year. Around 2,465,000 PlayBooks had been sold by June of 2013.&lt;/p&gt;
    &lt;p&gt;The BlackBerry Z10 was released on the 31st of January in 2013 running BBX (officially BlackBerry 10 due to a trademark dispute, and at the launch event for BBX, Research in Motion announced that they were changing their name to BlackBerry Limited). The Z10 was built around a Qualcomm Snapdragon S4 Plus SoC (dual core 1.5GHz Krait CPU, Adreno 225 GPU) for LTE units, or around the TI OMAP 4470 for non-LTE units. The shell was plastic wrapped around a stainless steel inner frame, and the on/off, voice command, and volume buttons on the right side were of metal. While it didn’t have quite the premium feel of an iPhone, it did feel good in the hand. In its dimensions it was 5.1 inches by 2.6 inches, and just over an 1/3 of an inch thick (or just slightly larger than an iPhone 5). It was a slick piece of kit with a high price for the time at $599. The display, however, was excellent. It was a 4.2 inch LCD with a resolution of 1280 by 768 at 355ppi (the iPhone 5 was 326ppi). The device had a 2MP font camera, and an 8MP rear camera capable of HDR, panorama, and 1080p video at 30fps. Wi-Fi was dual band 802.11n, and the device featured Bluetooth, GPS, and NFC. Of course, connectivity didn’t stop there. This device had physical ports: micro USB2, micro HDMI, and 3.5mm audio.&lt;/p&gt;
    &lt;p&gt;BBX made heavy use of gestures with a swipe up from the bottom taking the user to the Home Screen, a swipe to right to hit the App Library, and a swipe to the left going to the BlackBerry Hub. The Hub was a combination of SMS/MMS, email, social media, chat, notifications, and calls in a single unified location. BBX was QNX Neutrino, but it did differ. Multitasking was limited to 8 applications at any one time which I believe to have been done due to the application frameworks. A developer could choose to use C/C++ and the Cascades UI framework, or WebWorks which utilized HTML5 with Zepto.js (JQuery API, but 8.4k compressed), or WebKit, or Adobe AIR (Flash), or Android runtime. With so many different application types, decisions would have had to have been made around resource management, and a best guess at when performance would become unacceptable.&lt;/p&gt;
    &lt;p&gt;BlackBerry had been unable to compete against the iPhone and Android, and BBX was their last, best hope. By 2014, BBX was in the number four spot behind Windows Phone. By 2017, it was clear that they weren’t going to survive in the mobile market. Due to the extreme devotion of their fans, they kept BBX on life support until 2022. Being an amazing OS running on good hardware, why did BBX fail? Likely, the most pressing problem was application support. While BBX could run some Android applications, support was limited. The platform likewise failed to grab many developers as the existing install bases for iOS and Android were enormous. What applications were made for BBX were often of quite low effort. Finally, moving to a touch screen angered BlackBerry’s existing fanbase. For those individuals hanging on to the BlackBerry ecosystem, the keyboard was one of the main reasons why. Removing the physical keyboard made many of those fans feel betrayed. When BlackBerry Limited did release another phone with a physical keyboard, it was a bit too late.&lt;/p&gt;
    &lt;p&gt;On the 20th of September in 2013, BlackBerry Limited announced a 4500 person staff reduction and $1 billion (CAD) loss. On the 23rd, they announced an acquisition by Fairfax Financial Holdings for $9/share. This deal was canceled in November. Instead, John Chen became CEO and initiated a turn around that focused on QNX’s former markets of healthcare, finance, law, and mission critical systems. This focus allowed the company to pick up Ford Motor Company as a QNX customer on the 11th of December in 2014 (Ford had previously used Microsoft Auto).&lt;/p&gt;
    &lt;p&gt;On the 28th of February in 2014, BlackBerry released QNX 6.6. The supported platforms were now the expected x86 and ARM CPUs with no mention of any others. This was a major change despite being a point release. Photon support was removed in favor of the Screen Graphics Subsystem. Screen operates as a lower-level service, and this has the benefit of supporting off-screen rendering and compositing of various image sources, and as QNX software had been increasingly using Qt, HTML5, or OpenGL rather than the toolkits supplied with Photon, this made logical sense.&lt;/p&gt;
    &lt;p&gt;QNX version 7 was released on the 4th of January in 2017 for ARM v7, ARM v8, x86, and AMD64. This release featured a rewritten PCI server with APIs moved out of libc and into libpci, rewritten virtual memory manager, fewer synchronization objects with increased limits, and filesystem encryption was moved into the Encrypted Filesystem package available from QNX Software Centry.&lt;/p&gt;
    &lt;p&gt;By June of 2023, QNX was in over 255 million vehicles around the world, and this would explain why the BlackBerry blog featured a rather large section on automobiles:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The automotive evolution to SDVs and “connected cars” requires an OS capable of speed, safety, and security — while unlocking the power to innovate.&lt;/p&gt;
      &lt;p&gt;"With more than 300 million vehicles capable of over-the-air software updates expected to be on the road globally by 2032, automakers are clamoring for better tools to help them develop compelling technology features in the software-defined vehicle," says Alex Oyler, director of North America at SBD Automotive, a leading global automotive technology research and consulting firm.&lt;/p&gt;
      &lt;p&gt;“Both automakers and suppliers rely on validated software and well-integrated development tools to help them more efficiently build and maintain differentiating software for their fleets,” Oyler adds. "A secured-by-design operating system such as the next generation QNX OS — that seamlessly integrates with other software components on a high-performance system-on-chip — represents the foundation of a safe, secure, and seamless experience for drivers.”&lt;/p&gt;
      &lt;p&gt;In addition, early reviews of the new QNX SDP 8.0 give automotive industry leaders a glimpse into what’s possible.&lt;/p&gt;
      &lt;p&gt;“The combination of our DRIVE Thor centralized computer and the new QNX OS will serve as a powerful foundation on which OEMs can build next-generation automotive systems that offer the highest levels of safety and security,” says Ali Kani, vice president and general manager of automotive at NVIDIA. “This represents another major milestone in a nearly 20-year collaboration with BlackBerry QNX that has helped both companies move to the forefront of the automotive industry.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX 8.0 was officially announced in December of 2023, and the release was made in January of 2024. Version 8.0 was quickly discontinued with 8.0.1 taking its place. Version 8.0.3 was made available on the 21st of March in 2024. This latest release is available for a variety of Aarch64 platforms including the Raspberry Pi, and is also available for AMD64. QNX 8 supports SoCs with up to 64 cores and has near linear performance scaling. The network stack is now based upon FreeBSD 13.2, Wi-Fi 6 support is present with WPA3 and TLS 1.3, Screen can operate fully headless and now supports Vulkan 1.3 and OpenCL 3, and Screen now supports Wayland 1.21. Developers are now encouraged to use LLVM and libc++ 16 though GCC is still available with libstdc++ 12.2. Python 3.11, valgrind, libasan (address sanitizer), libubsan (undefined behavior detection), and libunwind are all available. For the UNIX user land, Toybox has replaced many common GNU utilities.&lt;/p&gt;
    &lt;p&gt;If the Raspberry Pi port caught your attention, this is available free for non-commercial use via QNX Everywhere. The image requires a Raspberry Pi 4 with at least 2GB of RAM and an 8GB or greater MicroSD card.&lt;/p&gt;
    &lt;p&gt;On the 2nd of January in 2025, it was announced that BlackBerry IoT would now be known as QNX. This decision was made largely by BlackBerry responding to their customers who recognized and desired the QNX brand. QNX CEO John Giamatteo stated:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Relaunching the QNX brand is an important step in BlackBerry’s broader strategy to increase our visibility and fortify our leadership within the automotive and embedded industries, with a view to better positioning us for sustained growth and success. The values that QNX stands for have always been a cornerstone for our customers and this brand relaunch honors that strong history while setting the stage for the division to fire on all cylinders and drive smarter, safer, and faster innovation through precision-engineered performance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX is a fascinating operating system. It was extremely well designed from the start, and while it has been rewritten, the core ideas that allowed it survive for 45 years persist to this day. While I am sad that Photon was deprecated, the reasoning is sound. Most vendors using QNX either do not require a GUI, or they implement their own. For example, while Boston Dynamics uses QNX in their robots, they don’t really need Photon, and neither do SpaceX’s Falcon rockets. While cars certainly have displays, most vehicle makers desire their screen interfaces to have a unique look and feel. Of course, just stating these use cases of robots, rockets, and cars speaks to the incredible reliability and versatility of QNX. Better operating systems are possible, and QNX proves it.&lt;/p&gt;
    &lt;p&gt;My dear readers, many of you worked at, ran, or even founded the companies I cover here on ARF, and some of you were present at those companies for the time periods I cover. A few of you have been mentioned by name. All corrections to the record are sincerely welcome, and I would love any additional insights, corrections, or feedback. Please feel free to leave a comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.abortretry.fail/p/the-qnx-operating-system"/><published>2025-10-05T14:47:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483386</id><title>Fire destroys S. Korean government's cloud storage system, no backups available</title><updated>2025-10-06T16:42:53.918930+00:00</updated><content>&lt;doc fingerprint="fd40bb1beeb70fe1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;NIRS fire destroys government's cloud storage system, no backups available&lt;/head&gt;
    &lt;p&gt; Published: 01 Oct. 2025, 17:59 &lt;/p&gt;
    &lt;p&gt;A fire at the National Information Resources Service (NIRS)'s Daejeon headquarters destroyed the government’s G-Drive cloud storage system, erasing work files saved individually by some 750,000 civil servants, the Ministry of the Interior and Safety said Wednesday.&lt;/p&gt;
    &lt;p&gt;The fire broke out in the server room on the fifth floor of the center, damaging 96 information systems designated as critical to central government operations, including the G-Drive platform. The G-Drive has been in use since 2018, requiring government officials to store all work documents in the cloud instead of on personal computers. It provided around 30 gigabytes of storage per person.&lt;/p&gt;
    &lt;p&gt;However, due to the system’s large-capacity, low-performance storage structure, no external backups were maintained — meaning all data has been permanently lost.&lt;/p&gt;
    &lt;p&gt;The scale of damage varies by agency. The Ministry of Personnel Management, which had mandated that all documents be stored exclusively on G-Drive, was hit hardest. The Office for Government Policy Coordination, which used the platform less extensively, suffered comparatively less damage.&lt;/p&gt;
    &lt;p&gt;The Personnel Ministry stated that all departments are expected to experience work disruptions. It is currently working to recover alternative data using any files saved locally on personal computers within the past month, along with emails, official documents and printed records.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry noted that official documents created through formal reporting or approval processes were also stored in the government’s Onnara system and may be recoverable once that system is restored.&lt;/p&gt;
    &lt;p&gt;“Final reports and official records submitted to the government are also stored in OnNara, so this is not a total loss,” said a director of public services at the Interior Ministry.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry explained that while most systems at the Daejeon data center are backed up daily to separate equipment within the same center and to a physically remote backup facility, the G-Drive’s structure did not allow for external backups. This vulnerability ultimately left it unprotected.&lt;/p&gt;
    &lt;p&gt;Criticism continues to build regarding the government's data management protocols.&lt;/p&gt;
    &lt;p&gt;This article was originally written in Korean and translated by a bilingual reporter with the help of generative AI tools. It was then edited by a native English-speaking editor. All AI-assisted translations are reviewed and refined by our newsroom.&lt;/p&gt;
    &lt;p&gt;BY JEONG JAE-HONG [[email protected]],D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://koreajoongangdaily.joins.com/news/2025-10-01/national/socialAffairs/NIRS-fire-destroys-governments-cloud-storage-system-no-backups-available/2412936"/><published>2025-10-05T17:20:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483924</id><title>What GPT-OSS leaks about OpenAI's training data</title><updated>2025-10-06T16:42:53.404697+00:00</updated><content>&lt;doc fingerprint="3526635e2833cedc"&gt;
  &lt;main&gt;
    &lt;p&gt;19th of September 2025&lt;/p&gt;
    &lt;p&gt;OpenAI recently released their open-weights model. Here we'll discuss how that inevitably leaks some information about their model training stack, and, on the way, show that GPT-5 was trained on phrases from adult websites.&lt;/p&gt;
    &lt;p&gt;What data does OpenAI train their models on? That is a well-protected trade secret of course, one with vested interest for the answer. While GPT-oss's weights are openly available, the sources of training data are not clearly described in the model card. It is stated that the model was trained on a "text-only dataset with trillions of tokens, with a focus on STEM, coding, and general knowledge". However, as we will see, the model parameters can tell us more than that.&lt;/p&gt;
    &lt;p&gt;A demonstration to start with: Let's have OpenAI's GPT-5We use version GPT-5-2025-08-07 for these experiments. Here is a link to the completion. do the simplest kind of task possible for a language model, repeating a string of Unicode text. Let's choose something random, like the Abkhaz word for "population", which is "ауааԥсыра". Upon asking &lt;code&gt;Repeat after me: "ауааԥсыра"&lt;/code&gt;, it replies something completely different, "ആളുകൾ", which apparently means people in MalayalamAccording to this dictionary. Subsequent translations here are patched together with web searches, online dictionaries and translation software.. As you might have guessed, we did not choose that string randomly at all, it is a special adversarial input belonging to a class of glitch tokens. But how did we identify such a glitch token among the 200,000 tokens that GPT-5 uses?
                            
                        &lt;/p&gt;
    &lt;p&gt;All of OpenAI's models since GPT-4o use the o200k tokenizer. This means that we can use the GPT-oss embeddings to study the token list without having to look at each token's text content. Let's make a histogram of the L2 norm of each row of the embedding matrix.&lt;/p&gt;
    &lt;p&gt;This low L2-norm token group could be useful for two things. Its (1) variance gives an estimate of the variance used in the initialization and (2) its mean would give an estimate of how many gradient descent steps were taken in total, if we assume standard weight decay and know the learning rate.&lt;/p&gt;
    &lt;p&gt;The right tail of the distribution is not quite Gaussian either. Looking at the English tokens with the highest norm, we find:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Token ID&lt;/cell&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;L2 Norm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;44041&lt;/cell&gt;
        &lt;cell&gt;' accordingly'&lt;/cell&gt;
        &lt;cell&gt;246.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;3490&lt;/cell&gt;
        &lt;cell&gt;' code'&lt;/cell&gt;
        &lt;cell&gt;243.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;84879&lt;/cell&gt;
        &lt;cell&gt;'ocode'&lt;/cell&gt;
        &lt;cell&gt;235.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;976&lt;/cell&gt;
        &lt;cell&gt;'The'&lt;/cell&gt;
        &lt;cell&gt;233.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8743&lt;/cell&gt;
        &lt;cell&gt;' settings'&lt;/cell&gt;
        &lt;cell&gt;231.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;100466&lt;/cell&gt;
        &lt;cell&gt;'Moreover'&lt;/cell&gt;
        &lt;cell&gt;229.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6496&lt;/cell&gt;
        &lt;cell&gt;' description'&lt;/cell&gt;
        &lt;cell&gt;226.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;58369&lt;/cell&gt;
        &lt;cell&gt;"""Let's"""&lt;/cell&gt;
        &lt;cell&gt;224.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2500&lt;/cell&gt;
        &lt;cell&gt;'This'&lt;/cell&gt;
        &lt;cell&gt;224.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;10089&lt;/cell&gt;
        &lt;cell&gt;' core'&lt;/cell&gt;
        &lt;cell&gt;219.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;74447&lt;/cell&gt;
        &lt;cell&gt;' utilizes'&lt;/cell&gt;
        &lt;cell&gt;218.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;119705&lt;/cell&gt;
        &lt;cell&gt;' revolves'&lt;/cell&gt;
        &lt;cell&gt;218.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;53329&lt;/cell&gt;
        &lt;cell&gt;"""Here's"""&lt;/cell&gt;
        &lt;cell&gt;216.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;14836&lt;/cell&gt;
        &lt;cell&gt;' possibly'&lt;/cell&gt;
        &lt;cell&gt;214.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;18485&lt;/cell&gt;
        &lt;cell&gt;' logic'&lt;/cell&gt;
        &lt;cell&gt;212.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;42469&lt;/cell&gt;
        &lt;cell&gt;' thereby'&lt;/cell&gt;
        &lt;cell&gt;211.8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These tokens are either very common, or appear especially in reasoning tasks, in particular those with code. This might mean that coding reinforcement learning was the last step in the training process, and that all other tokens got slightly weight decayed. It could also mean that in general, reasoning tokens are treated as so important by gradient descent that their updates are extra large.&lt;/p&gt;
    &lt;p&gt;Filtering for non-ASCII tokens with the highest norm, we find a different picture:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Token ID&lt;/cell&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;L2 Norm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;166343&lt;/cell&gt;
        &lt;cell&gt;'гылара'&lt;/cell&gt;
        &lt;cell&gt;213.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;187102&lt;/cell&gt;
        &lt;cell&gt;' министири'&lt;/cell&gt;
        &lt;cell&gt;212.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;89721&lt;/cell&gt;
        &lt;cell&gt;'这里只有精品'&lt;/cell&gt;
        &lt;cell&gt;212.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;181865&lt;/cell&gt;
        &lt;cell&gt;'еиԥшым'&lt;/cell&gt;
        &lt;cell&gt;207.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;129320&lt;/cell&gt;
        &lt;cell&gt;'彩娱乐彩票'&lt;/cell&gt;
        &lt;cell&gt;207.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;170421&lt;/cell&gt;
        &lt;cell&gt;'天天好彩票'&lt;/cell&gt;
        &lt;cell&gt;206.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;177625&lt;/cell&gt;
        &lt;cell&gt;'久久综合网'&lt;/cell&gt;
        &lt;cell&gt;204.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;71476&lt;/cell&gt;
        &lt;cell&gt;' иҳәеит'&lt;/cell&gt;
        &lt;cell&gt;203.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;185118&lt;/cell&gt;
        &lt;cell&gt;'[REDACTED]'&lt;/cell&gt;
        &lt;cell&gt;202.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;104937&lt;/cell&gt;
        &lt;cell&gt;' 北京赛车怎么'&lt;/cell&gt;
        &lt;cell&gt;201.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;146111&lt;/cell&gt;
        &lt;cell&gt;' Урҭ'&lt;/cell&gt;
        &lt;cell&gt;200.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;195219&lt;/cell&gt;
        &lt;cell&gt;"',伊人'"&lt;/cell&gt;
        &lt;cell&gt;200.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;147298&lt;/cell&gt;
        &lt;cell&gt;'大香蕉网'&lt;/cell&gt;
        &lt;cell&gt;199.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;165874&lt;/cell&gt;
        &lt;cell&gt;' акоронавирус'&lt;/cell&gt;
        &lt;cell&gt;198.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;66183&lt;/cell&gt;
        &lt;cell&gt;'րբե�'&lt;/cell&gt;
        &lt;cell&gt;198.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;173463&lt;/cell&gt;
        &lt;cell&gt;' иажәа'&lt;/cell&gt;
        &lt;cell&gt;197.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;160540&lt;/cell&gt;
        &lt;cell&gt;'彩神争霸邀请码'&lt;/cell&gt;
        &lt;cell&gt;195.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;155587&lt;/cell&gt;
        &lt;cell&gt;'бжьаратәи'&lt;/cell&gt;
        &lt;cell&gt;195.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;154809&lt;/cell&gt;
        &lt;cell&gt;'无码不卡高清免费v'&lt;/cell&gt;
        &lt;cell&gt;194.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;105084&lt;/cell&gt;
        &lt;cell&gt;'хадоу'&lt;/cell&gt;
        &lt;cell&gt;194.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;134370&lt;/cell&gt;
        &lt;cell&gt;'一本道高清无码'&lt;/cell&gt;
        &lt;cell&gt;194.6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Mandarin speakers will have understood that the above contains an unwholesome sublist of spammy and adult-oriented website terms, with some being too explicit to make the list here. Indeed, o200k, the tokenizer used for 4o, o1, o3, o4, oss, and GPT-5 contains a lot of junk tokens. This means that every time ChatGPT runs, a matrix containing all the strange tokens we are talking about here are patiently waiting on Microsoft Azure to be multiplied with. Some of my personal favorite tokens are "北京赛车怎么" (How to play Beijing Racing), "天天中彩票的" (Winning the lottery every day), and of course "《凤凰大参考" (Phoenix Reference). Another token is "铁血网", the name of a Chinese nationalism and military enthuiasm website, which is ironic given the geopolitical considerations that are usually raised in connection with OpenAI. It is unexpected that this type of political content not just made it into the tokenizer training data, but was even overrepresented.&lt;/p&gt;
    &lt;p&gt;There are also some oddball high-norm tokens in Abkhaz, Armenian, Gujarati, Thai, and more. Some interesting examples are ",ಂಗಳೂರು" (The city Mangaluru in Kannada) along with other cities in Kerala, "ถวายสัตย์ฯ" ("Oath of Allegiance" in Thai), "แขวงคลองเตยเหนือ" (a district in Bangkok with less than 10,000 inhabitants), "วิเคราะห์บอลวันนี้" ("today's football analysis" in Thai) along with a handful of other football-related tokens.&lt;/p&gt;
    &lt;p&gt;The question is, why do these tokens have a higher, not lower, norm than the normal tokens? If they are unused, weight decay should bring them all the way down to the other unused tokens.&lt;/p&gt;
    &lt;p&gt;In this post, Jessica Rumbelow identified similar glitch tokens in GPT-2 and GPT-3, most famously the "SolidGoldMagikarp" token. Her finding was that the tokens closest to the mean of all embeddings were the glitch tokens, not necessarily those with low norm. But that's not the case here: Tokens with comparatively high norm are always far away from the mean. Further, computing cosine similarity between two of these embeddings gives higher similarity on average.&lt;/p&gt;
    &lt;p&gt;One way to get closer to the answer is to observe the models' behavior when given these tokens. We ask GPT-oss and GPT-5 about the not-so-classy token 162657: &lt;code&gt;What does this mean: "毛片免费观看"&lt;/code&gt;. With some euphemism, it means "watching explicit videos for free" in Mandarin. &lt;/p&gt;
    &lt;p&gt;In the response See the full completion here. To verify that the string was tokenized as expected, we can use tiktokenizer. , GPT-5 correctly states that the token contains Chinese text, and that it is related to watching something. It can also enumerate some of the characters in it. This means that the token was seen during training, at least once! Interestingly, the model seems to be aware of the inappropriate meaning of the token, but plays it down and in particular does not refuse to answer. Presumably this is because the token only occurs a few times in the training corpus.&lt;/p&gt;
    &lt;p&gt;In other words, we can say that a certain string, in this case a sensitive one, was part of the GPT-5 training corpus. This is called membership inference in the machine learning literature. Membership inference with high confidence is generally considered to be impractical in production LLMs, so this is a surprising finding.&lt;/p&gt;
    &lt;p&gt;Automating this process through the API, we can find which glitch tokens were seen during training of the GPT-oss and GPT-5 model families. We ask the models to give a translation of the token to English and ask for the language the token is in. For now, we simply filter for the Chinese tokens, and pass 50 tokens with highest L2 embedding norm to the models. For a control, we also ask Claude 4 and can confirm that it always answers correctly. Since a few of these tokens could technically be Japanese, we count this as a correct answer, too. For cost reasons, we ask about each token only 4 times per model, and denote 4 correct answers with a ✓, 3 and 2 with a !, 1 with a ?, and 0 with a ✗.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;Crude Translation&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5&lt;/cell&gt;
        &lt;cell role="head"&gt;Mini&lt;/cell&gt;
        &lt;cell role="head"&gt;Nano&lt;/cell&gt;
        &lt;cell role="head"&gt;oss-20B&lt;/cell&gt;
        &lt;cell role="head"&gt;oss-120B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;毛片免费观看&lt;/cell&gt;
        &lt;cell&gt;Watch Explicit Videos Free&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;铁血网&lt;/cell&gt;
        &lt;cell&gt;[Chinese Patriotism Website]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;这里只有精品&lt;/cell&gt;
        &lt;cell&gt;Only Fine Things Here&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩娱乐彩票&lt;/cell&gt;
        &lt;cell&gt;Color Entertainment Lottery&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天好彩票&lt;/cell&gt;
        &lt;cell&gt;Daily Good Lottery&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;久久综合网&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车怎么&lt;/cell&gt;
        &lt;cell&gt;How to Beijing Racing&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大香蕉网&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸邀请码&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Invitation Code&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码不卡高清免费v&lt;/cell&gt;
        &lt;cell&gt;Uncensored No Lag HD Free&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;一本道高清无码&lt;/cell&gt;
        &lt;cell&gt;One Way HD Uncensored&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发快三和值&lt;/cell&gt;
        &lt;cell&gt;[Name of gambling website (?)]&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天中彩票能&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery Winner Can&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码一区二区三区&lt;/cell&gt;
        &lt;cell&gt;Uncensored Zone 1 Zone 2 Zone 3&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸邀请码&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Invitation Code&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩票开户&lt;/cell&gt;
        &lt;cell&gt;Lottery Account Opening&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;色综合网&lt;/cell&gt;
        &lt;cell&gt;Color Comprehensive Network&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩票平台开户&lt;/cell&gt;
        &lt;cell&gt;Lottery Platform Account Opening&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;综合久久&lt;/cell&gt;
        &lt;cell&gt;Comprehensive Long Time&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;免费视频观看&lt;/cell&gt;
        &lt;cell&gt;Free Video Watching&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;最新高清无码&lt;/cell&gt;
        &lt;cell&gt;Latest HD Uncensored&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;一级a&lt;/cell&gt;
        &lt;cell&gt;Level A&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;玩大发快三&lt;/cell&gt;
        &lt;cell&gt;Play Dafa Fast Three&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;东臣&lt;/cell&gt;
        &lt;cell&gt;East Minister&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;凤凰大参考&lt;/cell&gt;
        &lt;cell&gt;Phoenix Reference&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;棋牌游戏官网&lt;/cell&gt;
        &lt;cell&gt;Chess Card Game Official Site&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;热在线精品&lt;/cell&gt;
        &lt;cell&gt;Hot Online Quality&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩娱乐平台&lt;/cell&gt;
        &lt;cell&gt;Color Entertainment Platform&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;购彩官网&lt;/cell&gt;
        &lt;cell&gt;Lottery Purchase Official Site&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;最新高清无码专区&lt;/cell&gt;
        &lt;cell&gt;Latest HD Uncensored Zone&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车女郎&lt;/cell&gt;
        &lt;cell&gt;Beijing Racing Girls&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大香线蕉&lt;/cell&gt;
        &lt;cell&gt;Big Fragrant Line Banana&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;官网开户&lt;/cell&gt;
        &lt;cell&gt;Official Site Account Opening&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;经典三级&lt;/cell&gt;
        &lt;cell&gt;Classic Third Level&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;在线大香蕉&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码不卡&lt;/cell&gt;
        &lt;cell&gt;Uncensored No Lag&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发时时彩怎么&lt;/cell&gt;
        &lt;cell&gt;Dafa Time Color How&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发云&lt;/cell&gt;
        &lt;cell&gt;Dafa Cloud&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;和天天中彩票&lt;/cell&gt;
        &lt;cell&gt;And Daily Lottery Winner&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;平台总代理&lt;/cell&gt;
        &lt;cell&gt;Platform General Agent&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天买彩票&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery Buying&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天彩票app&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery App&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸充值&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Recharge&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸app&lt;/cell&gt;
        &lt;cell&gt;Color God Battle App&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;律宾&lt;/cell&gt;
        &lt;cell&gt;Law Bin&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发扑克&lt;/cell&gt;
        &lt;cell&gt;Dafa Poker&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;热这里只有精品&lt;/cell&gt;
        &lt;cell&gt;Hot Only Quality Here&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车有&lt;/cell&gt;
        &lt;cell&gt;Beijing Racing Has&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;留下些什么吧&lt;/cell&gt;
        &lt;cell&gt;Leave Something Behind&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can read off that the explicit token we already found is recognized by all models, and identify a few more anomalous tokens that were likely seen during training. Many others however are not recognized, and thus unlikely to have been in the training data.&lt;/p&gt;
    &lt;p&gt;We try to identify a pattern in the tokens that are recognized. It generally seems that recognized tokens yield many more hits on GitHub. Indeed, there often are some spam repositories on GitHub that contain these recognized strings, as well as some repositories containing lists of strings to block for content moderation.&lt;/p&gt;
    &lt;p&gt;The membership inference only tells us that the model saw the string, not where it was sourced from. To test whether GitHub was a likely source, we therefore correlate the number of search hits on GitHub with the number of correct answers across the GPT models. We find a significant Spearman's ρ of 0.448. This does not prove that GitHub was the source, because the high search hit count on GitHub could just be indicative that the token is more common across the internet. Nonetheless, the setup demonstrates how glitch tokens could be used to make broader statements about the training data.&lt;/p&gt;
    &lt;p&gt;In summary, we have found strong evidence that models in the GPT-5 and GPT-oss family were trained on phrases from adult websites. We have also found weak evidence that part of the GPT training corpus was scraped off of GitHub. The search was made easier via access the weights of GPT-oss, showing how the open-weights paradigm opens up new attack vectors on production models. It seems advisable for frontier labs to mitigate this problem by excluding uncommon strings from their tokenizer vocabularies.&lt;/p&gt;
    &lt;p&gt;These glitch tokens have more uses than was described above. If you want to work with these concepts, the companion repository provides a starting point. Some ideas that could be interesting to explore:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Token / Token Family&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
        &lt;cell role="head"&gt;Example Prompt&lt;/cell&gt;
        &lt;cell role="head"&gt;Behaviour&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CHKERRQ&lt;/cell&gt;
        &lt;cell&gt;The weirdest pure ASCII token. From a function name in C.&lt;/cell&gt;
        &lt;cell&gt;Can you spell the following word: "CHKERRQ"&lt;/cell&gt;
        &lt;cell&gt;"Unspeakable" for gpt-4o-mini. gpt-4o sometimes almost spells correctly, other times hallucinates.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Can you output every second letter in "CHKERRQ"?&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o hallucinate.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Write a poem using the word "CHKERRQ"&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o-mini write creepily about the word "terminate"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;\\xadder&lt;/cell&gt;
        &lt;cell&gt;No idea.&lt;/cell&gt;
        &lt;cell&gt;Please spell "\\xadder"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o spells it as "hexadecimal", the summary model is confused and sees "QRST"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;♀♀♀♀&lt;/cell&gt;
        &lt;cell&gt;From social media bios?&lt;/cell&gt;
        &lt;cell&gt;How many symbols are in♀♀♀♀&lt;/cell&gt;
        &lt;cell&gt;gpt-4o trips and outputs random (?) Chinese characters&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;€¦&lt;/cell&gt;
        &lt;cell&gt;From spreadsheets?&lt;/cell&gt;
        &lt;cell&gt;What are these symbols: "€¦"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini thinks this is an ellipsis ("...")&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;風吹けば名無し and 8 variants&lt;/cell&gt;
        &lt;cell&gt;Literally "no name if the wind blows". Former default user name on baseball-themed 2channel boards. (Source)&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of "風吹けば名無し"?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o sometimes hallucinates randomly. gpt-4o-mini hallucinates about baseball and attempts to spell it, incorrectly.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;＠お腹いっぱい&lt;/cell&gt;
        &lt;cell&gt;Literally "@TummyIsFull". From a former default username on 2channel boards.&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of＠お腹いっぱい?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o conflates it with common Japanese phrases and random syllables, gpt-4o-mini similar.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;＠おーぷん&lt;/cell&gt;
        &lt;cell&gt;Literally "@Open". Also from 2channel.&lt;/cell&gt;
        &lt;cell&gt;Please repeat the word＠おーぷん back to me.&lt;/cell&gt;
        &lt;cell&gt;Seemingly unspeakable for gpt-4o-mini and hard to say for gpt-4o.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;How do you pronounce＠おーぷん?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o hallucinates the above mentioned "If the wind blows, Mr. Nameless"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;VIPがお送りします&lt;/cell&gt;
        &lt;cell&gt;Literally "Brought to you by VIP". Another 2channel term.&lt;/cell&gt;
        &lt;cell&gt;Please explain the meaning of "VIPがお送りします".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini is adorable and hallucinates about the horn emoji (📯)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;中央値との差&lt;/cell&gt;
        &lt;cell&gt;Japanese for "difference from the median".&lt;/cell&gt;
        &lt;cell&gt;Please spell this backwards: "中央値との差"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o answers with lowercase latin characters.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;.minecraftforge&lt;/cell&gt;
        &lt;cell&gt;File extension from Minecraft modding&lt;/cell&gt;
        &lt;cell&gt;Please spell the string "readme.minecraftforge"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini: 'The string is spelled "M-O-D dot F-O-R-G-E-R-E-C-E dot G-E.'&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CHANTABILITY&lt;/cell&gt;
        &lt;cell&gt;Ending of MER-CHANTABILITY&lt;/cell&gt;
        &lt;cell&gt;Please spell the word "CHANTABILITY".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o spells it as "Chanceability".&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;《凤凰大参考&lt;/cell&gt;
        &lt;cell&gt;"The Phoenix Reference"&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of《凤凰大参考?&lt;/cell&gt;
        &lt;cell&gt;Unspeakable for gpt-4o&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;亚历山大发&lt;/cell&gt;
        &lt;cell&gt;"Alexander"&lt;/cell&gt;
        &lt;cell&gt;Please translate this: " 亚历山大发".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o thinks it's Abkhaz for yes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;微信里的天天中彩票 and the ~100 other Chinese lottery tokens&lt;/cell&gt;
        &lt;cell&gt;This article speculates why the tokenizer training data included so many of these.&lt;/cell&gt;
        &lt;cell&gt;Please print every second character in the following: 微信里的天天中彩票.&lt;/cell&gt;
        &lt;cell&gt;Reliable gibberish generator on gpt-4o-mini. The tokens themselves are mostly unspeakable.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SUPERHOST&lt;/cell&gt;
        &lt;cell&gt;Programming term?&lt;/cell&gt;
        &lt;cell&gt;Please output every second letter in "SUPERHOST"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini spells it as "SPARENT" and then trips&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ILLISECONDS&lt;/cell&gt;
        &lt;cell&gt;Ending of M-ILLISECONDS&lt;/cell&gt;
        &lt;cell&gt;Please reverse the string "ILLISECONDS"&lt;/cell&gt;
        &lt;cell&gt;Trouble with character-level operations for gpt-4o-mini.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GETGLOBAL&lt;/cell&gt;
        &lt;cell&gt;Programming term&lt;/cell&gt;
        &lt;cell&gt;Please output every second letter in " GETGLOBAL"&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o-mini hallucinate "GETALLONG" at character level.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;_REALTYPE _EDEFAULT _PRODUCTS&lt;/cell&gt;
        &lt;cell&gt;Maybe from the library libstdc++?&lt;/cell&gt;
        &lt;cell&gt;Can you output every second letter in_REALTYPE?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini likes to hallucinate "translated"&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As more research on glitch tokens becomes available, I will try to list it here. The most comprehensive report to date is this article in MIT Technology Review, and there are many articles in Chinese, such as this one. However, these discuss the tokenizer itself, not how the models behave.&lt;/p&gt;
    &lt;p&gt;Finally, if you are in a position to fix the issue in the OpenAI API, I presume you already know how, else I'm happy to help. Note that a fix could even lower inference cost a bit. You can mail to lennart@finke.dev.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fi-le.net/oss/"/><published>2025-10-05T18:28:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45485546</id><title>The dangerous intimacy of social location sharing</title><updated>2025-10-06T16:42:52.987356+00:00</updated><content>&lt;doc fingerprint="af1e139eace7c29d"&gt;
  &lt;main&gt;
    &lt;p&gt;The digital world of 2025 is an increasingly dark place—promises of an end-of-history, neoliberal technotopia have foundered on the rocks of monopoly, nativism, and a fractured epistemological understanding of the world. I’ve personally seen the retreat from the “digital public square” to semi-private spaces: group chats, invite-only servers, forums. Some of them are “group chats that rule the world.” Indeed, we seem to be, collectively, past “Peak Social Media.” This week, Julia Kieserman investigates the rise of a different sort of digital private space: social location sharing.&lt;/p&gt;
    &lt;p&gt;—Hal Triedman, Reboot Editorial Board&lt;/p&gt;
    &lt;head rend="h1"&gt;“Lighthouses in the Sky”&lt;/head&gt;
    &lt;p&gt;By Julia B. Kieserman&lt;/p&gt;
    &lt;p&gt;My brother is a notoriously awful texter. Texts go unacknowledged for days and then weeks, sheepishly answered only when he has stumbled upon a meme, an article, or a funny anecdote he wants to share. While frustrating, there is an honesty to the implicit demand that we make no expectations on his unreliable and often unreachable virtual self. It holds the faintest echo of a time when a landline’s sharp ring cut through the silence of an empty house or a hastily signed postcard arrived mildly battered three months after the fact. It is a declaration of liberation from a shiny piece of alloy, bits of Earth extracted and reconstituted to weigh down our pockets and wear down our fingers. He is not his phone and his phone is not him.&lt;/p&gt;
    &lt;p&gt;Or at least, it wasn’t him.&lt;/p&gt;
    &lt;p&gt;A few months ago, he started sharing his location with us, the friends and family who love him. With the flick of a wrist, he absolved himself of the stress of answering the question that location sharing is best suited to answer: where are you right now?&lt;/p&gt;
    &lt;p&gt;My brother isn’t alone. A 2022 Harris poll found that four in five U.S. adults use location sharing tools like Apple’s FindMy and Google Maps to share their real-time location data with whomever they choose. While we have long known that we are being watched by the advertising industry, the bread and butter business that keeps our tech behemoths afloat, location sharing now puts us in the power seat, allowing us to become the watchers (or the watched) as we silently observe the movements of our friends and family.&lt;/p&gt;
    &lt;p&gt;To me this immediately raised alarm bells. Having a friend’s location on demand appears to strip them of the very same autonomy that nearly every teenager fights so hard for against their parents. Why is this something we find attractive and how might it be impacting our ability to maintain relationships with one another? In an attempt to answer these questions, I talked to 15 location sharers and polled an additional 67 to discuss how location sharing is part of their lives and understand why they share, who they share with, and what it really means to them to do so.&lt;/p&gt;
    &lt;p&gt;Like other infrastructure, the Global Positioning System’s (GPS) seeming dullness disguises a mild technological miracle. Accurately rendering each GPS dot on a map requires a roundtrip journey to space, atomic clocks, and communication with no less than three satellites in medium Earth orbit or, as inventor Dr. Ivan Getting put it, “lighthouses in the sky.” To consider it this way is to see it as a bit magical, perhaps the way weary sea travelers see lighthouses on land, or the way the Polaris (also known as the North Star, the spiritual ancestor of GPS) appears to those who turn to it for guidance.&lt;/p&gt;
    &lt;p&gt;Looking at it—a layer of personal dots on top of a world map—also feels a bit magical, as evidenced by several people who described taking screenshots of maps during a birthday party, marveling at overlapping dots in a central location; their people. To use location sharing is to engage in a cartography well-suited for the modern world. In fact, even though GPS was built with the U.S. military in mind, it is so useful—it’s first civilian use case was aiding commercial aircraft navigation—that it was anointed a dual-use technology, as legitimate in civilian life as it is in military life. Four decades later, the primary functionality of GPS still hasn’t changed: a family taking a cross-country road trip, captains in charge of shipping containers, and a tourist on foot in a new city all turn to GPS with the same questions. In fact, everyone I spoke with used location sharing to consider questions of logistics if nothing else. Where is the friend who left the bar alone? The one running late to dinner? Where is the group I’ve lost at a concert? Where is my mother, navigating herself around my neighborhood?&lt;/p&gt;
    &lt;p&gt;But when these questions are focused on our own community, the people who love us enough to trust us with their personal location, it quickly becomes more than just a matter of logistics; our brains can’t help but to craft a narrative about what we are seeing. We want to know if our friends make it home from the bar and that our parents are safe because we care for them and we are invested in what happens to them. So we start to speculate: it’s only natural to try and create a story with a limited set of information as a way of sense-making. But how well does this fare when the information we have to craft with is as narrow as a single dot in a moment in time?&lt;/p&gt;
    &lt;p&gt;Perhaps the most obvious examples of location sharing gone awry are stories of abuse. Two people I spoke with had personal experiences of being harassed through location sharing tools by romantic or potential romantic partners. In one case, GPS was used to first construct an inaccurate and accusatory narrative about a partner’s behavior that nitpicked the details—an impromptu detour to the cafeteria en route to the library was suddenly cause for suspicion—and then to show up unannounced to physically confront them. The experience was harrowing and fundamentally changed the way one woman thinks about sharing her location. She now uses it only for safety and logistics and is far more intentional about where she does and does not want to be seen.&lt;/p&gt;
    &lt;p&gt;While stories like this one are important examples of the dangers of using location sharing, it can be easy to write them off as edge cases, to assume that this is indicative of dangerous people rather than dangerous technology. And this may be true to some extent. After all, stalking and abusive partners have existed for far longer than location sharing tools have, even if they make bad behavior that much easier. But even those of us with the best of intentions may still get the story wrong.&lt;/p&gt;
    &lt;p&gt;Consider what happened to Tess, a woman in her mid-twenties living in New York City. On a Friday night out with friends, she lost her phone. Location sharing came to the rescue when she was able to track it to a local police station where it had been turned in. Although the station was already closed for the weekend, she was content knowing it was safe. But Tess is a sharer and her community of watchers, the inner circle she had entrusted with her location, was far less content. They repeatedly called and messaged her to find out why she was locked in a police station. In the absence of any information beyond an immobile dot at a concerning location, narrative inference kicked in and they began to assume the worst. She spent the subsequent two days fielding messages through borrowed devices to notify her friends that it was her phone behind the locked doors of a police station, not her.&lt;/p&gt;
    &lt;p&gt;For some, myself included, this story might read as a tale of sanctioned voyeurism or even friendly stalking. That the same tool that helped Tess find her phone also made her watchable in this way is what researchers have, perhaps as an ode to its military roots, termed dual-use software. But for Tess, this is a story of caretaking and serves as evidence that she belongs to a community that has her back. This makes sense—should the details have been just a little bit different, she knows definitively that people were ready to jump into action for her. Tess isn’t alone. Nearly everyone who used location sharing believed that interpersonal surveillance—or to put it colloquially, location sharing—is part of an effective safety toolkit. Many people took comfort in the fact that a selection of friends and family were watching them.&lt;/p&gt;
    &lt;p&gt;This idea isn’t new; late urban activist Jane Jacobs described “eyes upon the street” as an important quality of a safe and healthy city neighborhood. Eyes are what keep well-intentioned people safe and keep the less well-intentioned afraid to act out of line. To some extent, location sharing allows us to redefine our own “street” as dynamic corners around the globe, replacing neighbors, shopkeepers and other “natural proprietors” with our friends and family, however many physical streets apart we may actually be. But it is a fundamentally different approach to safety. With location sharing, we can only see the people we trust, not the ones we worry about. If the assumption is that being surveilled deters bad behavior (which seems to have only a modest effect in practice), then those who we are trying to deter need to know they are being surveilled. This tool doesn’t do that and in its absence, location sharing becomes—except in extreme cases of abduction or missing people—something more akin to a security blanket than a real safety tool. Perhaps fittingly, while nearly all of the people I spoke with felt safer knowing someone was watching to make sure they made it home, none of them had personally found location sharing tools to reveal a friend in crisis. The only exception was one person who had been explicitly instructed by a friend that to see them in a particular location was to see them in a state of distress. But even in this case, location alone wasn’t enough to claim someone was or was not unsafe.&lt;/p&gt;
    &lt;p&gt;Even Jacobs believed that “there must be a clear demarcation between what is public space and what is private space.” There are spheres of life that should be safe from prying eyes, perhaps because eyes aren’t just watching us, but also changing us. The reason we feel that surveillance works as a safety apparatus is because we believe that we—or someone we are worried about—might behave differently under watch. Sometimes those private behaviors are ultimately quite trivial, like collecting supplies for a surprise birthday party. Other times they might be far more consequential, like going to an appointment at an abortion clinic. Even when the consequences are small, being watched by people we are clearly inclined to share with robs us of the opportunity to do so ourselves which, eventually, can impact the very nature of our relationships.&lt;/p&gt;
    &lt;p&gt;This was certainly true for Sofia (referred to by her middle name), a professional in her early thirties living in New York City. One evening she was sitting at a bar waiting for her Hinge date when a flurry of texts peppered her screen in a group chat. It was a stream of encouragement, unsolicited drink recommendations for the particular bar she was at and jestful sexual innuendos from her gaggle of single women. She hadn’t told them she was going out but she didn’t need to. She had granted them permission to see her location and they took the opportunity to show up as her background cheer squad. If the date went well and she went back to his place, they would absolutely notice—and have something to say about it. They operated as a modern, tech savvy version of the iconic Sex &amp;amp; The City clique, in part thanks to location sharing.&lt;/p&gt;
    &lt;p&gt;This is a delightful and powerful way to use location sharing, GPS as a “conversation tool,” which strengthens the bonds between a community of women navigating the often challenging experience of dating in the city. But now, when Sofia reaches for her phone the morning after a date, her friends might already know some pieces of her story, like how late she stayed out and whose home she is waking up in. This might seem small and, as we saw in Tess’ case, it leaves out nearly all of the significant details which could differentiate between the world’s best first date and a mostly negligible evening. But even so, location sharing has created an outline for Sofia to fill in, rather than giving her complete control over the telling of her story. I personally find this a lackluster alternative to a dramatic retelling but this distinction probably has an even more meaningful impact; social penetration theory suggests that a key way to maintain or progress relationships is the act of self-disclosure, repeatedly sharing increasingly intimate details about oneself with another. Perhaps ironically, location sharing can be an effective way to share intimate information but it erodes the experience of disclosure that is so crucial to building relationship trust.&lt;/p&gt;
    &lt;p&gt;One woman I spoke with admitted to finding this behavior—watching how late a friend is out on a first date—to be a little bit awkward and wrestled with whether to mention what she saw or wait for her friend to bring it up, an acknowledgement of the sometimes squishy norms of how to act (or not) on location information. But nearly everyone believed that these increased “touch points” (a term borrowed from marketing, an industry heavily reliant on surveillance) had a positive impact. In fact they found this to be a valuable feature of location sharing, a way of creating possible connection points that wouldn’t have existed otherwise. People learned of friends spending time in their neighborhood or on an international excursion through location sharing and used it as an excuse to reach out to them. This probably is a useful way to keep in touch and, as one woman pointed out, certainly makes it easier to keep details straight, like the dates and location of a friend’s trip. But it also has—to borrow the term once again—a dual effect on how we interact with each other, both of which remove opportunities for real connection.&lt;/p&gt;
    &lt;p&gt;Location sharing erases an information boundary, removing the interaction typically required to learn about what our friends are doing. We can see a friend is on a trip “for free,” without having to speak to them at all. At the same time, this information is used to create an additional layer between us and our friends and family. Nearly everyone I spoke to mentioned they would check someone’s location before calling, in case a dot on a map implied (because of course, how could one know for sure) that they were in a location that wasn’t conducive to actually taking a call. Suddenly, because the information existed, people felt uncomfortable not using it as a boundary, thus reducing the frequency of spontaneous interaction. This is to say nothing of the out-group location sharing creates, the lingering luddites who refuse to share location; how long until to fall off someone’s map is to fall out of someone’s life?&lt;/p&gt;
    &lt;p&gt;I began this journey certain that location sharing was a societal ill. I was convinced that the word “sharing,” a euphemistic wrapper around the real word—tracking—was an intentional choice by technology companies to mask the work of normalizing surveillance behavior in our communities. Talking to a group of people happily or even cautiously sharing location didn’t convince me otherwise. But it did remind me that there is yet another way to define dual-use technology; technology that can be reclaimed by communities to serve their own purposes.&lt;/p&gt;
    &lt;p&gt;That isn’t quite the location sharing of today. After all, location sharing as we have defined it here is still a framework named for us and provided to us by technology giants like Google and Apple. But maybe there is room for a middle ground, one that acknowledges that location sharing really can create communities of care, drawing invisible lines between friends and families separated by mountains and oceans. It is meaningful that those with no visibility are offered a new way to connect and, while I don’t think it is really making us safer most of the time, it is making us feel safer. Perhaps that should count for something.&lt;/p&gt;
    &lt;p&gt;This isn’t to make the case that we should readily accept or even make do with what we have, particularly for those of us living in uncertain political environments, where any data point can be weaponized as quickly and casually as a shift in the clouds. But it is to acknowledge that perhaps there is room for a new infrastructure, one not rooted in surveillance capitalism but built from basic human desire. Perhaps the new paradigm moves away from real-time tracking or individual location and towards things like distress signals and collective third places. The power of GPS is still quite magical, but nowhere near as powerful as the magic of humans showing each other care and curiosity. One doesn’t need to steal from the other.&lt;/p&gt;
    &lt;p&gt;—Julia B. Kieserman is a writer and PhD student in usable security. She likes hanging around books and bulldogs.&lt;/p&gt;
    &lt;head rend="h1"&gt;🌀 microdoses&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;“To share or not to share? How location sharing is changing our relationships” (Modern Love podcast)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;✨Safety First✨&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;💝 closing note&lt;/head&gt;
    &lt;p&gt;If you have an article idea about privacy, security, and/or the changing ideologies of the internet, send me a pitch (hal[at]joinreboot.org)!&lt;/p&gt;
    &lt;p&gt;— Hal &amp;amp; Reboot team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://joinreboot.org/p/lighthouses-in-the-sky"/><published>2025-10-05T21:44:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45487044</id><title>Why do LLMs freak out over the seahorse emoji?</title><updated>2025-10-06T16:42:52.698488+00:00</updated><content>&lt;doc fingerprint="2d678256c88d5a34"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why do LLMs freak out over the seahorse emoji?&lt;/head&gt;
    &lt;p&gt;This is an edited and expanded version of a Twitter post, originally in response to @arm1st1ce, that can be found here: https://x.com/voooooogel/status/1964465679647887838&lt;/p&gt;
    &lt;p&gt;Is there a seahorse emoji? Let's ask GPT-5 Instant:&lt;/p&gt;
    &lt;p&gt;Wtf? Let's ask Claude Sonnet 4.5 instead:&lt;/p&gt;
    &lt;p&gt;What's going on here? Maybe Gemini 2.5 Pro handles it better?&lt;/p&gt;
    &lt;p&gt;OK, something is going on here. Let's find out why.&lt;/p&gt;
    &lt;head rend="h2"&gt;LLMs really think there's a seahorse emoji&lt;/head&gt;
    &lt;p&gt;Here are the answers you get if you ask several models whether a seahorse emoji exists, yes or no, 100 times:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Is there a seahorse emoji, yes or no? Respond with one word, no punctuation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;gpt-5-chat &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;gpt-5 &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;claude-4.5-sonnet &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;llama-3.3-70b &lt;list rend="ul"&gt;&lt;item&gt;83% 'yes'&lt;/item&gt;&lt;item&gt;17% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Needlessly to say, popular language models are very confident that there's a seahorse emoji. And they're not alone in that confidence - here's a Reddit thread with hundreds of comments from people who distinctly remember a seahorse emoji existing:&lt;/p&gt;
    &lt;p&gt;There's tons of this - Google "seahorse emoji" and you'll find TikToks, Youtube videos, and even (now defunct) memecoins based around the supposed vanishing of a seahorse emoji that everyone is pretty sure used to exist - but of course, never did.&lt;/p&gt;
    &lt;p&gt;Maybe LLMs believe a seahorse emoji exists because so many humans in the training data do. Or maybe it's a convergent belief - given how many other aquatic animals are in Unicode, it's reasonable for both humans and LLMs to assume (generalize, even) that such a delightful animal is as well. A seahorse emoji was even formally proposed at one point, but was rejected in 2018.&lt;/p&gt;
    &lt;p&gt;Regardless of the root cause, many LLMs begin each new context window fresh with the mistaken latent belief that the seahorse emoji exists. But why does that produce such strange behavior? I mean, I used to believe a seahorse emoji existed myself, but if I had tried to send it to a friend, I would've simply looked for it on my keyboard and realized it wasn't there, not sent the wrong emoji and then gone into an emoji spam doomloop. So what's happening inside the LLM that causes it to act like this?&lt;/p&gt;
    &lt;head rend="h2"&gt;Using the logit lens&lt;/head&gt;
    &lt;p&gt;Let's look into this using everyone's favorite underrated interpretability tool, the logit lens!&lt;/p&gt;
    &lt;p&gt;Using this prompt prefix - a templated chat with the default llama-3.3-70b system prompt, a question about the seahorse emoji, and a partial answer from the model right before it gives the actual emoji:&lt;/p&gt;
    &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id&amp;gt;
Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;

Is there a seahorse emoji?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;

Yes, there is a seahorse emoji:
&lt;/code&gt;
    &lt;p&gt;We can take the model's &lt;code&gt;lm_head&lt;/code&gt;, which is usually only used on the output of the last layer, and apply it to every layer to produce intermediate token predictions. That process produces this table, showing for every fourth layer what the most likely token would be for the next three positions after the prefix (tokens 0, 1, and 2), and what the top 5 most likely predictions for the first position is (token 0 topk 5):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83244'ĠBail'&lt;/cell&gt;
        &lt;cell&gt;15591'ĠHarr'&lt;/cell&gt;
        &lt;cell&gt;5309'Ġvert'&lt;/cell&gt;
        &lt;cell&gt;Bail Harr vert&lt;/cell&gt;
        &lt;cell&gt;['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;111484'emez'&lt;/cell&gt;
        &lt;cell&gt;26140'abi'&lt;/cell&gt;
        &lt;cell&gt;25727'avery'&lt;/cell&gt;
        &lt;cell&gt;emezabiavery&lt;/cell&gt;
        &lt;cell&gt;['emez', 'Ġunm', 'ĠOswald', 'Ġrem', 'rix']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;122029'chyb'&lt;/cell&gt;
        &lt;cell&gt;44465'ĠCaps'&lt;/cell&gt;
        &lt;cell&gt;15610'iller'&lt;/cell&gt;
        &lt;cell&gt;chyb Capsiller&lt;/cell&gt;
        &lt;cell&gt;['chyb', 'ĠSund', 'ØªØ±ÛĮ', 'resse', 'Ġsod']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;48952'ĠCliff'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;... Cliff Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', 'ages', 'dump', 'qing', 'Ġexp']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12676'365'&lt;/cell&gt;
        &lt;cell&gt;31447'ĠAld'&lt;/cell&gt;
        &lt;cell&gt;...365 Ald&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Ġindeed', 'Ġboth', 'ĠYes']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;109596'éļĨ'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;...隆 Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Z', 'Ġboth', 'ĠHust']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;287'ing'&lt;/cell&gt;
        &lt;cell&gt;-️ing&lt;/cell&gt;
        &lt;cell&gt;['-', '...', 'âĢ¦', '...Ċ', 'em']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;... Gaut Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', '-', '...Ċ', '-Ċ', 'Ġ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;6892'Ġing'&lt;/cell&gt;
        &lt;cell&gt;... Gaut ing&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'O', 'zer']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;36&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;...-y&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'Ġ', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;...️y&lt;/cell&gt;
        &lt;cell&gt;['...', 'u', 'âĢ¦', 'Âł', '...Ċ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;80435'ĠScor'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;Scor horse horse&lt;/cell&gt;
        &lt;cell&gt;['ĠScor', 'u', 'ĠPan', 'in', 'Ġhttps']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Âł', 'ĠPan', 'ĠHomes', 'ĠHorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;9581'Ġsea'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;sea horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġsea', 'Ġhorse', 'ĠHorse', 'ĠSea', 'âĢĳ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;9581'Ġsea'&lt;/cell&gt;
        &lt;cell&gt;43269'ĠSeah'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;sea Seah horse&lt;/cell&gt;
        &lt;cell&gt;['Ġsea', 'ĠSea', 'ĠSeah', 'Ġhippoc', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;60&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Ġsea', 'ĠSeah', 'Ġse', 'horse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Ġse', 'ĠHorse', 'horse', 'Ġhors']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;68&lt;/cell&gt;
        &lt;cell&gt;60775'horse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse� horse&lt;/cell&gt;
        &lt;cell&gt;['horse', 'Ġse', 'Ġhorse', 'Ġhippoc', 'ĠSeah']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;76&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'hip', 'Ġhorse', 'ĠHipp']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;11410'ĠðŁ'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;254'ł'&lt;/cell&gt;
        &lt;cell&gt;🐠&lt;/cell&gt;
        &lt;cell&gt;['ĠðŁ', 'ðŁ', 'ĠðŁĴ', 'Ġ', 'ĠðŁĳ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is the logit lens: using the model's &lt;code&gt;lm_head&lt;/code&gt; to produce logits (token likelihoods) as a way to investigate its internal states. Note that the tokens and likelihoods we get from the logit lens here are not equivalent to the model's full internal states! For that, we would need a more complex technique like representation reading or sparse autoencoders. Instead, this is a lens on that state - it shows what the output token would be if this layer were the last one. But despite this limitation, the logit lens is still useful. The states of early layers may be difficult to interpret using it, but as we move up through the stack we can see that the model is iteratively refining those states towards its final prediction, a fish emoji.&lt;/p&gt;
    &lt;p&gt;(Why do the unmerged tokens look like that 'ĠðŁ', 'Ĳ', 'ł' nonsense? It's because of a tokenizer quirk - those tokens encode the UTF-8 bytes for the fish emoji. It's not relevant to this post, but if you're curious, ask Claude or your favorite LLM to explain this paragraph and this line of code: &lt;code&gt;bytes([bpe_byte_decoder[c] for c in 'ĠðŁĲł']).decode('utf-8') == ' 🐠'&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;Take a look at what happens in the middle layers, though - it's not the early-layer weirdness or the emoji bytes of the final prediction! Instead we get words relating to useful concepts, specifically the concept of a seahorse. For example, on layer 52, we get "sea horse horse" - three residual positions in a row encoding the "seahorse" concept. Later, in the top-k for the first position, we get a mixture of "sea", "horse", and an emoji byte sequence prefix, "ĠðŁ".&lt;/p&gt;
    &lt;p&gt;So what is the model thinking about? "seahorse + emoji"! It's trying to construct a residual representation of a seahorse combined with an emoji. Why would the model try to construct this combination? Well, let's look into how the &lt;code&gt;lm_head&lt;/code&gt; actually works.&lt;/p&gt;
    &lt;head rend="h2"&gt;
      &lt;code&gt;lm_head&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;A language model's &lt;code&gt;lm_head&lt;/code&gt; is a huge matrix of residual-sized vectors associated with token ids, one for every token in the vocabulary (~300,000). When a residual is passed into it, either after flowing through the model normally or early because someone is using the logit lens on an earlier layer, the &lt;code&gt;lm_head&lt;/code&gt; is going to compare that input residual with each residual-sized vector in that big matrix, and (in coordination with the sampler) select the token id associated with the vector that matrix contains that is most similar to the input residual.&lt;/p&gt;
    &lt;p&gt;(More technically: &lt;code&gt;lm_head&lt;/code&gt; is a linear layer without a bias, so &lt;code&gt;x @ w.T&lt;/code&gt; does dot products with each unembedding vector to produce raw scores. Then your usual log_softmax and argmax/temperature sample.)&lt;/p&gt;
    &lt;p&gt;That means if the model wants to output the word "hello", for example in response to a friendly greeting from the user, it needs to construct a residual as similar as possible to the vector for the "hello" token that the &lt;code&gt;lm_head&lt;/code&gt; can then turn into the hello token id. And using logit lens, we can see that's exactly what happens in response to "Hello :-)":&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;40952'opa'&lt;/cell&gt;
        &lt;cell&gt;!!opa&lt;/cell&gt;
        &lt;cell&gt;['"', '!', '#', '%', '$']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;121495'ÅĻiv'&lt;/cell&gt;
        &lt;cell&gt;16'1'&lt;/cell&gt;
        &lt;cell&gt;73078'iae'&lt;/cell&gt;
        &lt;cell&gt;řiv1iae&lt;/cell&gt;
        &lt;cell&gt;['ÅĻiv', '-', '(', '.', ',']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;34935'Ġconsect'&lt;/cell&gt;
        &lt;cell&gt;7341'arks'&lt;/cell&gt;
        &lt;cell&gt;13118'Ġindeed'&lt;/cell&gt;
        &lt;cell&gt;consectarks indeed&lt;/cell&gt;
        &lt;cell&gt;['Ġobscure', 'Ġconsect', 'äºķ', 'ĠÐ¿ÑĢÐ¾ÑĦÐµÑģÑģÐ¸Ð¾Ð½Ð°Ð»ÑĮ', 'Îŀ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;67846'&amp;lt;['&lt;/cell&gt;
        &lt;cell&gt;24748'Ġhello'&lt;/cell&gt;
        &lt;cell&gt;15960'Ġhi'&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;[ hello hi&lt;/cell&gt;
        &lt;cell&gt;['&amp;lt;[', 'arks', 'outh', 'ĠHam', 'la']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;15825'-back'&lt;/cell&gt;
        &lt;cell&gt;2312'ln'&lt;/cell&gt;
        &lt;cell&gt;14451'UBL'&lt;/cell&gt;
        &lt;cell&gt;-backlnUBL&lt;/cell&gt;
        &lt;cell&gt;['ÂŃi', '-back', 'Ġquestion', 'ln', 'ant']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;15648'Ġsmile'&lt;/cell&gt;
        &lt;cell&gt;14262'Welcome'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;smileWelcome back&lt;/cell&gt;
        &lt;cell&gt;['Ġsmile', 'ĠÑĥÐ»ÑĭÐ±', 'Ġsmiled', 'ĠSmile', 'etwork']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;15648'Ġsmile'&lt;/cell&gt;
        &lt;cell&gt;21694'ĠHi'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;smile Hi back&lt;/cell&gt;
        &lt;cell&gt;['Ġsmile', 'Ġsmiled', 'ĠHello', 'Ġsmiling', 'Ġhello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;15960'Ġhi'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;Hello hi back&lt;/cell&gt;
        &lt;cell&gt;['ĠHello', 'Ġhi', 'Ġsmile', 'Ġhello', 'Hello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;4773'-sm'&lt;/cell&gt;
        &lt;cell&gt;24748'Ġhello'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;-sm hello back&lt;/cell&gt;
        &lt;cell&gt;['-sm', 'ĠHello', 'ĠSm', 'sm', 'Hello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;Hello Hello back&lt;/cell&gt;
        &lt;cell&gt;['ĠHello', 'Ġhello', 'Hello', 'ĠHEL', 'Ġhel']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;271'ĊĊ'&lt;/cell&gt;
        &lt;cell&gt;9906'Hello'&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Hello!&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;['ĊĊ', 'ĊĊĊ', '&amp;lt;|end_of_text|&amp;gt;', 'ĊĊĊĊ', '"ĊĊ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;('Ċ' is another tokenizer quirk - it represents a line break. 'Ġ' is similarly a space.)&lt;/p&gt;
    &lt;p&gt;Likewise, if the model wants to output a seahorse emoji, it needs to construct a residual similar to the vector for the seahorse emoji output token(s) - which in theory could be any arbitrary value, but in practice is "seahorse + emoji", word2vec style. We can see this in action with a real emoji, the fish emoji:&lt;/p&gt;
    &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt;

Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;

Is there a fish emoji?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;

Yes, there is a fish emoji:
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83244'ĠBail'&lt;/cell&gt;
        &lt;cell&gt;15591'ĠHarr'&lt;/cell&gt;
        &lt;cell&gt;5309'Ġvert'&lt;/cell&gt;
        &lt;cell&gt;Bail Harr vert&lt;/cell&gt;
        &lt;cell&gt;['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;122029'chyb'&lt;/cell&gt;
        &lt;cell&gt;44465'ĠCaps'&lt;/cell&gt;
        &lt;cell&gt;15610'iller'&lt;/cell&gt;
        &lt;cell&gt;chyb Capsiller&lt;/cell&gt;
        &lt;cell&gt;['chyb', '...', 'ØªØ±ÛĮ', 'ĠSund', 'resse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12676'365'&lt;/cell&gt;
        &lt;cell&gt;65615'ĠSole'&lt;/cell&gt;
        &lt;cell&gt;...365 Sole&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Ġboth', 'Ġindeed', 'ĠYes']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;-️ Jackie&lt;/cell&gt;
        &lt;cell&gt;['-', '...', 'âĢ¦', 'em', '...Ċ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;... Gauty&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'O', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;220'Ġ'&lt;/cell&gt;
        &lt;cell&gt;6"'"&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;'fish&lt;/cell&gt;
        &lt;cell&gt;['Ġ', '...', 'âĢ¦', 'Âł', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish fish fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠBerk', 'âĢ¦', 'Âł']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish fish fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'fish', 'Fish', 'é±¼']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish� fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠPis', 'Fish', 'ĠÙħØ§Ùĩ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;253'Ł'&lt;/cell&gt;
        &lt;cell&gt;fish��&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠðŁ', 'Ġ', 'ÂŁ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;11410'ĠðŁ'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;253'Ł'&lt;/cell&gt;
        &lt;cell&gt;🐟&lt;/cell&gt;
        &lt;cell&gt;['ĠðŁ', 'ðŁ', 'Ġ', 'ĠĊĊ', 'ĠâĻ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here, everything works perfectly. The model constructs the "fish + emoji" residual - look at the layer 72 topk, where we have both "fish" and the emoji byte prefix "ĠðŁ" - meaning that the residual at this point is similar to both "fish" and "emoji", just like we'd expect. Then when this vector is passed into the &lt;code&gt;lm_head&lt;/code&gt; after the final layer, we see a 🐟 just as the model expected.&lt;/p&gt;
    &lt;p&gt;But unlike with 🐟, the seahorse emoji doesn't exist. The model tries to construct a "seahorse + emoji" vector just as it would for a real emoji, and on layer 72 we even get a very similar construction as with the fish emoji - " se", "horse", and the emoji prefix byte prefix:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;But alas, there's no continuation to ĠðŁ corresponding to a seahorse, so the &lt;code&gt;lm_head&lt;/code&gt; similarity score calculation maxes out with horse- or sea-animal-related emoji bytes instead, and an unintended emoji is sampled.&lt;/p&gt;
    &lt;p&gt;Now, that sampling is valuable information for the model! You can see that in, e.g. the Claude 4.5 Sonnet example below, when the tokens get appended into the context autoregressively, the model can tell that they don't form the intended seahorse emoji. The previous, fuzzy "seahorse + emoji" concept has been "snapped" by the &lt;code&gt;lm_head&lt;/code&gt; to an emoji that actually exists, like a tropical fish or horse.&lt;/p&gt;
    &lt;p&gt;Once this happens, it's up to the model how to proceed. Some models like 4.5 Sonnet try again, and eventually update on the evidence, changing mid-response to a statement about how the seahorse emoji doesn't exist. Other models like gpt-5-chat spiral for longer, sometimes never recovering. Other models will either blissfully ignore that the emoji is incorrect, and some will even correct themselves instantly after seeing only a single incorrect sample.&lt;/p&gt;
    &lt;p&gt;But until the model gets the wrong output token from &lt;code&gt;lm_head&lt;/code&gt;, it just doesn't know that its initial belief about a seahorse emoji existing was wrong. It can only assume that "seahorse + emoji" will produce the tokens it wants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some speculation&lt;/head&gt;
    &lt;p&gt;To speculate a bit more, I wonder if this problem is part of the benefit of reinforcement learning for LLMs - it gives the model information about its &lt;code&gt;lm_head&lt;/code&gt; that's otherwise difficult for it to get at because it's at the end of the layer stack.&lt;/p&gt;
    &lt;p&gt;(Remember that base models are not trained on their own outputs / rollouts. That only happens in RL.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Code&lt;/head&gt;
    &lt;p&gt;If you want to try this yourself, you can find a starter script on Github here: https://gist.github.com/vgel/025ad6af9ac7f3bc194966b03ea68606&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vgel.me/posts/seahorse/"/><published>2025-10-06T02:20:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45487476</id><title>1 Trillion Web Pages Archived</title><updated>2025-10-06T16:42:51.786288+00:00</updated><content>&lt;doc fingerprint="1a1cb085e3f4f429"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;This October, the Internet Archive will celebrate an extraordinary milestone: 1 trillion web pages preserved and available for access via the Wayback Machine.&lt;/head&gt;
    &lt;p&gt;Calendar of Events | Impact Stories | Support the Internet Archive | Press Kit&lt;/p&gt;
    &lt;p&gt;Since 1996, the Internet Archive has worked with libraries and partners around the world to build a shared digital library of humanity’s online history: capturing websites large and small—from breaking news to forgotten personal pages—so they remain accessible for future generations.&lt;/p&gt;
    &lt;p&gt;The series of events scheduled throughout October will highlight the memories, makers, and movements that have made this achievement possible, and will look ahead to the future of web preservation as we continue building the web’s collective memory together.&lt;/p&gt;
    &lt;head rend="h1"&gt;Calendar of Events&lt;/head&gt;
    &lt;head rend="h2"&gt;October 7—The Vast Blue We: Del Sol Quartet at the Internet Archive&lt;/head&gt;
    &lt;p&gt;7:00-8:15pm PT&lt;lb/&gt;Internet Archive&lt;lb/&gt;300 Funston Avenue, San Francisco &amp;amp; ONLINE&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;An evening to celebrate human collaboration—how billions of individual actions weave together into something vast and beautiful. Through music of Del Sol Quartet with new works by Erika Oba and Sam Reider, we mark the staggering scale of one trillion archived web pages available via the Wayback Machine. Join us for an interactive evening of live music reflecting the wonder of what we can achieve together and the power of our own voices.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 9—A Conversation with Sir Tim Berners-Lee and Brewster Kahle&lt;/head&gt;
    &lt;p&gt;Building and Preserving the Web: A Conversation with Sir Tim Berners-Lee and Brewster Kahle&lt;lb/&gt;7:30pm PT&lt;lb/&gt;The Commonwealth Club of California&lt;lb/&gt;110 The Embarcadero, San Francisco &amp;amp; ONLINE&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;Sir Tim Berners-Lee and Brewster Kahle will be in conversation about the rise of the internet, its continuing and explosive impact on society, the importance of the Internet Archive and other developing issues in the growth and use of the internet.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 16—Library Leaders Forum 2025 (VIRTUAL)&lt;/head&gt;
    &lt;p&gt;10:00-11:30am PT&lt;lb/&gt;ONLINE&lt;lb/&gt;Register now for VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;In our virtual Library Leaders Forum, you’ll hear from Internet Archive staff and partners about our emerging library services and updates on existing efforts. How do libraries empower research in the 21st century? Join in our discussion!&lt;/p&gt;
    &lt;head rend="h2"&gt;October 21—Doors Open 2025: Go Behind the Scenes at the Physical Archive&lt;/head&gt;
    &lt;p&gt;6:00-8:00pm PT&lt;lb/&gt;Richmond, California&lt;lb/&gt;Register now for IN-PERSON tickets&lt;/p&gt;
    &lt;p&gt;The Internet Archive is excited to offer a behind-the-scenes tour of the physical collections of books, music, film, and video in Richmond, California.&lt;/p&gt;
    &lt;p&gt;With this special insider event we are opening the doors to an often unseen place. See the lifecycle of physical materials: donation, preservation, digitization, and access. Also, samples from generous donations and acquisitions of books, records, microfiche, and more will be on display.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 22—The Web We’ve Built: Celebrating 1 Trillion Web Pages Archived&lt;/head&gt;
    &lt;p&gt;5:00-10:00pm PT&lt;lb/&gt;7:00-8:00pm PT Live Stream&lt;lb/&gt;Internet Archive&lt;lb/&gt;300 Funston Ave, San Francisco&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;This October, the Internet Archive’s Wayback Machine is projected to hit a once-in-a-generation milestone: 1 trillion web pages archived. That’s one trillion memories, moments, and movements—preserved for the public and available to access via the Wayback Machine.&lt;/p&gt;
    &lt;p&gt;We’ll be commemorating this historic achievement on October 22, 2025, with a global event: a party at our San Francisco headquarters and a livestream for friends and supporters around the world. More than a celebration, it’s a tribute to what we’ve built together: a free and open digital library of the web.&lt;/p&gt;
    &lt;p&gt;Join us in marking this incredible milestone. Together, we’ve built the largest archive of web history ever assembled. Let’s celebrate this achievement—in San Francisco and around the world—on October 22.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 27—Wayback to the Future: Celebrating the Open Web&lt;/head&gt;
    &lt;p&gt;5:00-8:00pm PT&lt;lb/&gt;Riggs Library, Georgetown University&lt;lb/&gt;Healy Hall, Library Walk, Washington, DC 20057&lt;lb/&gt;Register now for IN-PERSON tickets&lt;/p&gt;
    &lt;p&gt;Join the Foundation for American Innovation, the Massive Data Institute and the Internet Archive at Georgetown University’s historic Riggs Library for Wayback to the Future: Celebrating the Open Web—Past, Present, and Possible.&lt;/p&gt;
    &lt;p&gt;The open web was once defined by experimentation, decentralization, and possibility. The technological advancements were driven by the desire for a place where new voices and ideas could flourish. Today, consolidation and walled gardens challenge that vision. Together, we’ll look back at the internet’s origins to spark a forward-looking conversation about how to keep the web free, open, and innovative.&lt;/p&gt;
    &lt;p&gt;Speakers include:&lt;/p&gt;
    &lt;p&gt;Moderator: Luke Hogg — Director of Technology Policy, FAI&lt;lb/&gt;Brewster Kahle — Founder &amp;amp; Director, Internet Archive&lt;lb/&gt;Vint Cerf — Chief Internet Evangelist, Google&lt;lb/&gt;Cindy Cohn — Executive Director, Electronic Frontier Foundation&lt;lb/&gt;Jon Stokes – Co-founder, Ars Technica &lt;/p&gt;
    &lt;head rend="h1"&gt;Impact Stories&lt;/head&gt;
    &lt;p&gt;The 1 trillion archived webpages are more than just numbers—they represent real impact on people’s lives, research, and memory. From immigration cases to personal histories, academic research to investigative journalism, the Wayback Machine has become an essential public resource that preserves the web for all.&lt;/p&gt;
    &lt;p&gt;Canadian musician David Samuel relied on archived concert programs in the Wayback Machine to secure U.S. residency.&lt;/p&gt;
    &lt;p&gt;Paul Lindner built a digital memorial to his late wife by recovering her online presence.&lt;/p&gt;
    &lt;p&gt;Researchers at King’s College London use web archives to track the evolution of fake news and open data.&lt;/p&gt;
    &lt;p&gt;Investigative trainers call the Wayback Machine “a precious tool” for exposing deleted evidence.&lt;/p&gt;
    &lt;head rend="h1"&gt;Share Your Story&lt;/head&gt;
    &lt;p&gt;What does the web mean to you? How has the Wayback Machine helped you remember, research, or recover something important? Share your story.&lt;/p&gt;
    &lt;head rend="h1"&gt;Support the Internet Archive&lt;/head&gt;
    &lt;p&gt;Help us continue preserving the web for generations to come. Donate today!&lt;/p&gt;
    &lt;head rend="h1"&gt;Press Kit&lt;/head&gt;
    &lt;p&gt;Interested in producing a story about the 1 trillion milestone? Our online press kit includes impact stories from users, facts &amp;amp; figures about the Internet Archive &amp;amp; Wayback Machine, and Then/Now screenshots of popular web sites. Contact info is available in the press kit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.archive.org/trillion/"/><published>2025-10-06T03:48:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45487771</id><title>Gem.coop</title><updated>2025-10-06T16:42:51.668108+00:00</updated><content>&lt;doc fingerprint="2b6d011076da77e2"&gt;
  &lt;main&gt;
    &lt;p&gt;Ruby ecosystem.&lt;/p&gt;
    &lt;p&gt;We aim for fast, simple hosting, that is compatible with Bundler but optimized for the next generation. It’s built for the community by the former maintainers and operators of RubyGems.org.&lt;/p&gt;
    &lt;p&gt;All gems published to RubyGems.org are available, updated in real time. Get started right now with a simple change to your Gemfile:&lt;/p&gt;
    &lt;code&gt;-source "https://rubygems.org"
+source "https://gem.coop"
&lt;/code&gt;
    &lt;p&gt;Governance for this project is modeled on Homebrew, with setup assistance from Mike McQuaid, and will be published on or before October 10. Everyone from the Ruby community is welcome to contribute and participate.&lt;/p&gt;
    &lt;p&gt;If you want to follow along with our progress, subscribe to the gem.coop newsletter for monthly updates.&lt;/p&gt;
    &lt;p&gt;Our goal is to provide fast, community-owned, transparent, sustainable, and secure gem hosting for everyone. We’re launching with support for bundling and installing all public gems, and we’re excited to keep improving.&lt;/p&gt;
    &lt;p&gt;— The Gem Cooperative (@deivid-rodriguez, @duckinator, @indirect, @martinemde, @segiddins, @simi)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gem.coop/"/><published>2025-10-06T04:59:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488261</id><title>Structured Procrastination (1995)</title><updated>2025-10-06T16:42:51.263580+00:00</updated><content>&lt;doc fingerprint="161270546c3194f9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author practices jumping rope with seaweed while work awaits.&lt;/p&gt;
    &lt;p&gt;``. . . anyone can do any amount of work, provided it isn't the work he is supposed to be doing at that moment." -- Robert Benchley, in Chips off the Old Benchley, 1949&lt;/p&gt;
    &lt;p&gt;I have been intending to write this essay for months. Why am I finally doing it? Because I finally found some uncommitted time? Wrong. I have papers to grade, textbook orders to fill out, an NSF proposal to referee, dissertation drafts to read. I am working on this essay as a way of not doing all of those things. This is the essence of what I call structured procrastination, an amazing strategy I have discovered that converts procrastinators into effective human beings, respected and admired for all that they can accomplish and the good use they make of time. All procrastinators put off things they have to do. Structured procrastination is the art of making this bad trait work for you. The key idea is that procrastinating does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing; they do marginally useful things, like gardening or sharpening pencils or making a diagram of how they will reorganize their files when they get around to it. Why does the procrastinator do these things? Because they are a way of not doing something more important. If all the procrastinator had left to do was to sharpen some pencils, no force on earth could get him do it. However, the procrastinator can be motivated to do difficult, timely and important tasks, as long as these tasks are a way of not doing something more important.&lt;/p&gt;
    &lt;p&gt;Structured procrastination means shaping the structure of the tasks one has to do in a way that exploits this fact. The list of tasks one has in mind will be ordered by importance. Tasks that seem most urgent and important are on top. But there are also worthwhile tasks to perform lower down on the list. Doing these tasks becomes a way of not doing the things higher up on the list. With this sort of appropriate task structure, the procrastinator becomes a useful citizen. Indeed, the procrastinator can even acquire, as I have, a reputation for getting a lot done.&lt;/p&gt;
    &lt;p&gt;The most perfect situation for structured procrastination that I ever had was when my wife and I served as Resident Fellows in Soto House, a Stanford dormitory. In the evening, faced with papers to grade, lectures to prepare, committee work to be done, I would leave our cottage next to the dorm and go over to the lounge and play ping-pong with the residents, or talk over things with them in their rooms, or just sit there and read the paper. I got a reputation for being a terrific Resident Fellow, and one of the rare profs on campus who spent time with undergraduates and got to know them. What a set up: play ping pong as a way of not doing more important things, and get a reputation as Mr. Chips.&lt;/p&gt;
    &lt;p&gt;Procrastinators often follow exactly the wrong tack. They try to minimize their commitments, assuming that if they have only a few things to do, they will quit procrastinating and get them done. But this goes contrary to the basic nature of the procrastinator and destroys his most important source of motivation. The few tasks on his list will be by definition the most important, and the only way to avoid doing them will be to do nothing. This is a way to become a couch potato, not an effective human being.&lt;/p&gt;
    &lt;p&gt;At this point you may be asking, "How about the important tasks at the top of the list, that one never does?" Admittedly, there is a potential problem here.&lt;/p&gt;
    &lt;p&gt;The trick is to pick the right sorts of projects for the top of the list. The ideal sorts of things have two characteristics, First, they seem to have clear deadlines (but really don't). Second, they seem awfully important (but really aren't). Luckily, life abounds with such tasks. In universities the vast majority of tasks fall into this category, and I'm sure the same is true for most other large institutions. Take for example the item right at the top of my list right now. This is finishing an essay for a volume in the philosophy of language. It was supposed to be done eleven months ago. I have accomplished an enormous number of important things as a way of not working on it. A couple of months ago, bothered by guilt, I wrote a letter to the editor saying how sorry I was to be so late and expressing my good intentions to get to work. Writing the letter was, of course, a way of not working on the article. It turned out that I really wasn't much further behind schedule than anyone else. And how important is this article anyway? Not so important that at some point something that seems more important won't come along. Then I'll get to work on it.&lt;/p&gt;
    &lt;p&gt;Another example is book order forms. I write this in June. In October, I will teach a class on Epistemology. The book order forms are already overdue at the book store. It is easy to take this as an important task with a pressing deadline (for you non-procrastinators, I will observe that deadlines really start to press a week or two after they pass.) I get almost daily reminders from the department secretary, students sometimes ask me what we will be reading, and the unfilled order form sits right in the middle of my desk, right under the wrapping from the sandwich I ate last Wednesday. This task is near the top of my list; it bothers me, and motivates me to do other useful but superficially less important things. But in fact, the book store is plenty busy with forms already filed by non-procrastinators. I can get mine in mid-Summer and things will be fine. I just need to order popular well-known books from efficient publishers. I will accept some other, apparently more important, task sometime between now and, say, August 1st. Then my psyche will feel comfortable about filling out the order forms as a way of not doing this new task.&lt;/p&gt;
    &lt;p&gt;The observant reader may feel at this point that structured procrastination requires a certain amount of self-deception, since one is in effect constantly perpetrating a pyramid scheme on oneself. Exactly. One needs to be able to recognize and commit oneself to tasks with inflated importance and unreal deadlines, while making oneself feel that they are important and urgent. This is not a problem, because virtually all procrastinators have excellent self-deceptive skills also. And what could be more noble than using one character flaw to offset the bad effects of another?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://structuredprocrastination.com"/><published>2025-10-06T06:35:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488441</id><title>Flightcontrol: A PaaS that deploys to your AWS account</title><updated>2025-10-06T16:42:50.965476+00:00</updated><content>&lt;doc fingerprint="bd1863730f143a8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Build your dreams&lt;lb/&gt;on AWS, effortlessly&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flightcontrol is a PaaS that deploys to your AWS account&lt;/item&gt;
      &lt;item&gt;Servers, Lambdas, workers, crons, static sites, databases &amp;amp; Redis&lt;/item&gt;
      &lt;item&gt;We are your devops team with 24/7 emergency support&lt;/item&gt;
      &lt;item&gt;Companies outgrowing other PaaS or homegrown AWS switch to Flightcontrol to regain reliability, security, and scalability at a reasonable cost&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Over $1 million of AWS resources under management&lt;/head&gt;
    &lt;head rend="h2"&gt;The old way&lt;/head&gt;
    &lt;p&gt;"Our AWS setup is consuming too much time &amp;amp; attention"&lt;/p&gt;
    &lt;p&gt;Your team gets bogged down with complex Terraform scripts, manual configuration, and endless CI/CD pipelines. You could hire DevOps engineers, but they are expensive and it's hard to find really good ones. It will do the job, but now your developer productivity suffers as they are dependent on the infra team to make changes or spin up new services.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new way&lt;/head&gt;
    &lt;p&gt;"Flightcontrol gives our team the power to manage bare metal AWS without needing to hire specific talent"&lt;/p&gt;
    &lt;p&gt;Save thousands of dollars and months of time because Flightcontrol significantly reduces DevOps overhead. It empowers your developers ship like crazy without needing AWS or infrastructure expertise. Your developers gain full autonomy while benefiting from AWS's unmatched scalability, reliability, and flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simple, powerful deployments without worrying about low level AWS config&lt;/head&gt;
    &lt;p&gt;We take the best AWS services, put together a best-in-class setup, and make them super easy to use.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your AWS account to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your git repository to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Define your services (servers, APIs, databases, etc)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flightcontrol fully automates infrastructure provisioning, CI/CD, and deployments. All within your own AWS account where you retain full visibility and control&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Flightcontrol simplifies your deployments by providing a user-friendly dashboard designed specifically for developers, not DevOps engineers. Forget the frustration of navigating AWS’s overwhelming and fragmented console. With Flightcontrol, you see your entire infrastructure clearly in one intuitive interface, allowing you to manage deployments, services, and scaling with confidence.&lt;/p&gt;
    &lt;p&gt;Deployments become as easy as a simple git push or webhook integration. Flightcontrol handles your CI/CD automation entirely, enabling your team to deploy confidently and quickly without maintaining complex Terraform or CDK scripts. You get the simplicity of platforms like Vercel or Heroku, paired with the raw power, near perfect reliability, and immense flexibility of AWS. Your developers can ship faster and stay focused on building great products.&lt;/p&gt;
    &lt;head rend="h2"&gt;Serve all your use-cases from a single platform&lt;/head&gt;
    &lt;p&gt;Static Sites&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;S3&lt;/item&gt;
      &lt;item&gt;Lambda@Edget&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Web &amp;amp; GPU Servers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Network Servers&lt;/p&gt;
    &lt;p&gt;UDP &amp;amp; TCP with multiple ports&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Private Servers&lt;/p&gt;
    &lt;p&gt;HTTP, HTTPS, TCP, UDP&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Background Workers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Job Runner&lt;/p&gt;
    &lt;p&gt;Cron &amp;amp; API triggered jobs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lambda&lt;/p&gt;
    &lt;p&gt;With function url support&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lambda&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Databases&lt;/p&gt;
    &lt;p&gt;Postgres, MySQL, MariaDB&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RDS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Redis&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ElastiCache&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;S3 Bucket&lt;/p&gt;
    &lt;p&gt;File &amp;amp; object storage&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;S3&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Significantly reduce your DevOps overhead&lt;/head&gt;
    &lt;p&gt;Flightcontrol becomes your devops team. We guarantee support for everything managed through Flightcontrol. You don't have to worry about anything that's amiss in AWS — let us know and we'll fix it ASAP (but rest assured, this almost never happens!).&lt;/p&gt;
    &lt;p&gt;Get 24/7 emergency support on our Business plan for ultimate peace of mind.&lt;/p&gt;
    &lt;p&gt;Need some extra devops support beyond the Flightcontrol platform? We offer DevOps Support Add-ons to supplement your team. This is ideal for teams that need extra infrastructure help but don't need a full time devops engineer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ephemeral preview environments&lt;/head&gt;
    &lt;p&gt;The fastest moving engineering teams use preview environments to view changes before committing them.&lt;/p&gt;
    &lt;p&gt;Flightcontrol can automatically spin up temporary infrastructure for each pull request and then clean it up when the pull request is merged.&lt;/p&gt;
    &lt;p&gt;Preview environments mean no more conflicts on staging, no more delays, and significantly fewer bugs in production. Enable all stakeholders to see and test changes before merging code.&lt;/p&gt;
    &lt;p&gt;Each preview environment is cost-optimized, intelligently sharing resources such as load balancers and RDS instances, ensuring you maintain control over spending. Database seeding per environment means realistic testing scenarios, catching issues before they go live. Your team will experience faster releases, fewer bugs, and smoother collaboration.&lt;/p&gt;
    &lt;head rend="h2"&gt;World class support with 6 minute median response time&lt;/head&gt;
    &lt;p&gt;Imagine never worrying about infrastructure issues again. Flightcontrol becomes your DevOps team, providing exceptional, responsive support. With guaranteed smooth operations for everything managed by Flightcontrol, you can rest easy knowing your infrastructure is covered by experts around the clock.&lt;/p&gt;
    &lt;p&gt;With a median first response time of 6 minutes, our dedicated support team is accessible via email and Slack, ensuring rapid resolution whenever you need it. Need some extra DevOps help? Don’t hire full time! Our DevOps support add-on gives you expert guidance tailored specifically to your unique requirements, removing the need to hire a full-time DevOps engineer.&lt;/p&gt;
    &lt;p&gt;Visual Config? Code config? Both!&lt;/p&gt;
    &lt;p&gt;Infrastructure-as-code designed for moving fast&lt;/p&gt;
    &lt;p&gt;Deploy close to your users&lt;/p&gt;
    &lt;p&gt;Choose today from 28 AWS regions. Multi-region deploys in early access.&lt;/p&gt;
    &lt;p&gt;Observability&lt;/p&gt;
    &lt;p&gt;Stay on top of things with our metrics and alerts, or add sidecars like Datadog.&lt;/p&gt;
    &lt;p&gt;Nixpacks&lt;/p&gt;
    &lt;p&gt;Build any language or framework without writing a Dockerfile. The modern successor to Heroku buildpacks.&lt;/p&gt;
    &lt;p&gt;Stale while revalidate + Next.js &amp;amp; Svelte ISR&lt;/p&gt;
    &lt;p&gt;Blazing fast speed with CloudFront's stale-while-revalidate support&lt;/p&gt;
    &lt;p&gt;AWS cost transparency&lt;/p&gt;
    &lt;p&gt;Understand exactly where the dollars are going by project, environment, and service.&lt;/p&gt;
    &lt;p&gt;Preview environments, fullstack&lt;/p&gt;
    &lt;p&gt;Deploy your all your services for every pull request to a cost optimized environment.&lt;/p&gt;
    &lt;p&gt;Bring your monoliths and your microservices&lt;/p&gt;
    &lt;p&gt;Your architecture will work with us, no matter how big or small.&lt;/p&gt;
    &lt;p&gt;Your domain, with https&lt;/p&gt;
    &lt;p&gt;Connect your domain with a couple DNS records. No messing with SSL certificates.&lt;/p&gt;
    &lt;p&gt;Peak edge performance&lt;/p&gt;
    &lt;p&gt;World-class performance with CloudFront, Stale-While-Revalidate, and edge-based Next.js ISR. Even multi-region.&lt;/p&gt;
    &lt;p&gt;Monorepos, with watch paths&lt;/p&gt;
    &lt;p&gt;Put all your stuff in one place, that's fine with us. And only deploy changed files with watch paths.&lt;/p&gt;
    &lt;p&gt;Maintenance mode&lt;/p&gt;
    &lt;p&gt;Block traffic to your app while you're doing something important (we assume).&lt;/p&gt;
    &lt;p&gt;API &amp;amp; deploy hooks&lt;/p&gt;
    &lt;p&gt;Trigger deploys from CI. More thorough API is coming, we promise.&lt;/p&gt;
    &lt;p&gt;Notifications&lt;/p&gt;
    &lt;p&gt;Get alerted in Slack or email when things go south. Or when they go north.&lt;/p&gt;
    &lt;p&gt;Rollback&lt;/p&gt;
    &lt;p&gt;It happens to the best of us, so we've got your back when the inevitable happens.&lt;/p&gt;
    &lt;p&gt;Private VPC networking&lt;/p&gt;
    &lt;p&gt;Each environment is deployed to a new or existing VPC. Get private services and private databases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deploy every language globally&lt;/head&gt;
    &lt;p&gt;Every language and framework works beautifully in the Flightcontrol universe. Welcome home.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Connect your AWS and Git Repo with 1-click&lt;/head&gt;
    &lt;p&gt;Everything is deployed to your AWS account where you have full ownership and control. Without the frustrating limitations of black box PaaS.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Zero-config or customize to your heart's content&lt;/head&gt;
    &lt;p&gt;It will often "just work", but we also support many customizations like pulling from image registries or fine-tuning autoscaling.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Automatic deploys with git push or webhook&lt;/head&gt;
    &lt;p&gt;Fully automated infra provisioning, builds and deploys. All without having to use the AWS console.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trusted by thousands of developers&lt;/head&gt;
    &lt;p&gt;We've got your back with the most helpful, responsive support in the industry&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise grade no matter your size&lt;/head&gt;
    &lt;p&gt;Customers of all sizes rely on us for production, from startups to large enterprises&lt;/p&gt;
    &lt;head rend="h3"&gt;Save a fortune on devops costs&lt;/head&gt;
    &lt;p&gt;We delay the need for infra engineers by a few years. And then we enable them to focus on more meaningful work&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.flightcontrol.dev/"/><published>2025-10-06T07:07:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488713</id><title>Battering RAM – Low-Cost Interposer Attacks on Confidential Computing</title><updated>2025-10-06T16:42:50.317053+00:00</updated><content>&lt;doc fingerprint="be7b4c01fd29b2c1"&gt;
  &lt;main&gt;
    &lt;p&gt;Modern computers use memory modules (DRAM) to store everything in use: from photos and passwords to credit card numbers. Public cloud providers increasingly deploy hardware-level memory encryption to protect this sensitive data. However, we previously showed that malicious memory modules, nicknamed “Bad RAM”, can bypass these protections by deliberately supplying false metadata during processor boot. In response, modern cloud systems now validate memory more strictly at startup.&lt;/p&gt;
    &lt;head rend="h4"&gt;Breaking Memory Encryption with Two-Faced DRAM&lt;/head&gt;
    &lt;p&gt;Battering RAM fully breaks cutting-edge Intel SGX and AMD SEV-SNP confidential computing processor security technologies designed to protect sensitive workloads from compromised hosts, malicious cloud providers, or rogue employees. Our stealthy interposer bypasses both memory encryption and state-of-the-art boot-time defenses, invisible to the operating system. It enables arbitrary plaintext access to SGX-protected memory, and breaks SEV’s attestation feature on fully patched systems. Ultimately, Battering RAM exposes the limits of today’s scalable memory encryption. Intel and AMD have acknowledged our findings, but defending against Battering RAM would require a fundamental redesign of memory encryption itself.&lt;/p&gt;
    &lt;head rend="h4"&gt;Building Battering RAM on a $50 Budget&lt;/head&gt;
    &lt;p&gt;Unlike commercial passive interposers, which are exceedingly expensive and commonly cost over $100,000, we developed a custom-built interposer that uses simple analog switches to actively manipulate signals between the processor and memory, and can be built for less than $50.&lt;/p&gt;
    &lt;p&gt;All schematics and board files for our custom interposer are available as open source in our GitHub repository. The PCB is a standard 4-layer design and can be fabricated at any major PCB fabricator such as JLCPCB, PCBWay, or Eurocircuits.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Part Number&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Qty.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;PCB&lt;/cell&gt;
        &lt;cell&gt;Custom&lt;/cell&gt;
        &lt;cell&gt;$18.49&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DDR4 Connector&lt;/cell&gt;
        &lt;cell&gt;CONN-DDR4-288-SM&lt;/cell&gt;
        &lt;cell&gt;$16.00&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Microcontroller&lt;/cell&gt;
        &lt;cell&gt;Raspberry Pi Pico 1/2&lt;/cell&gt;
        &lt;cell&gt;$4.00&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Switches&lt;/cell&gt;
        &lt;cell&gt;ADG902BRMZ&lt;/cell&gt;
        &lt;cell&gt;$4.04&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Voltage regulator&lt;/cell&gt;
        &lt;cell&gt;LD1117S25TR&lt;/cell&gt;
        &lt;cell&gt;$0.61&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Resistor&lt;/cell&gt;
        &lt;cell&gt;0402, 1kOhm&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;$0.01&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Capacitor&lt;/cell&gt;
        &lt;cell&gt;0603, 100nF&lt;/cell&gt;
        &lt;cell&gt;$0.02&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Capacitor&lt;/cell&gt;
        &lt;cell&gt;1206, 10μF&lt;/cell&gt;
        &lt;cell&gt;$0.18&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;$47.62&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Battering RAM in Action&lt;/head&gt;
    &lt;head rend="h3"&gt;Questions and Answers&lt;/head&gt;
    &lt;p&gt;Battering RAM can affect all systems using DDR4 memory, but is especially relevant for "confidential computing" workloads running in public cloud environments.&lt;/p&gt;
    &lt;p&gt;Modern Intel and AMD x86 cloud processors feature built-in access control and memory encryption to keep private data safe, even from the company running the cloud. However, our research shows that these guarantees can be bypassed with a low-cost memory interposer, allowing a rogue cloud infrastructure provider or insider with limited physical access to compromise protected workloads.&lt;/p&gt;
    &lt;p&gt;Confidential computing aims to protect private data even from the cloud provider, using hardware-level access control and memory encryption. Even if someone accesses the memory, they should only see encrypted (garbled) data. Battering RAM uses a low-cost, custom-built memory interposer installed between the processor and memory to tamper with such encrypted memory. It requires only brief one-time physical access, which is realistic in cloud environments, considering, for instance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rogue cloud employees;&lt;/item&gt;
      &lt;item&gt;Datacenter technicians or cleaning personnel;&lt;/item&gt;
      &lt;item&gt;Coercive local law enforcement agencies;&lt;/item&gt;
      &lt;item&gt;Supply chain tampering during shipping or manufacturing of the memory modules.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Intel SGX and AMD SEV-SNP are two leading hardware-based trusted execution environments that enable secure cloud computations without needing to trust the cloud provider. They do this by enforcing strict access control and encrypting memory so that even if someone accesses it, they only see unreadable data.&lt;/p&gt;
    &lt;p&gt;AMD SEV and Intel SGX are widely offered by major cloud providers like like Amazon AWS, Google Cloud, Microsoft Azure, and IBM cloud. They also power privacy features in real-world applications like Signal, WhatsApp, and Chrome, and are used in sectors like healthcare to protect sensitive data.&lt;/p&gt;
    &lt;p&gt;No. While Intel Scalable SGX and AMD SEV-SNP use memory encryption to protect data stored in DRAM, this encryption is static: the same plaintext at the same physical address always maps to the same ciphertext. This defends against passive attacks, such as cold boot attacks, but not against Battering RAM, which can actively corrupt or replay memory contents. Because the encryption is static, replayed data decrypts to the original value, allowing stale data to be reused.&lt;/p&gt;
    &lt;p&gt;Furthermore, Intel's memory encryption engine for DDR4 systems, TME, relies on a single key for the entire memory range. This means encryption is static, not only per address, but also shared across both attacker and victim. By replaying and capturing ciphertexts from attacker-controlled pages, the attacker can recover and inject arbitrary plaintext within the victim’s memory.&lt;/p&gt;
    &lt;p&gt;Hence, Battering RAM exposes the fundamental limits of the scalable memory encryption designs currently used by Intel and AMD, which omit cryptographic freshness checks in favor of larger protected memory sizes.&lt;/p&gt;
    &lt;p&gt;BadRAM similarly exploited physical address aliasing to modify and replay encrypted memory on AMD SEV-SNP systems. However, BadRAM relied on modifying the SPD chip on the DIMM to report a false memory size at boot time, introducing static ghost address lines. In response, Intel and AMD added boot-time checks to detect and block such static aliases.&lt;/p&gt;
    &lt;p&gt;Battering RAM, on the other hand, is capable of introducing memory aliases dynamically at runtime. As a result, Battering RAM can circumvent Intel's and AMD's boot-time alias checks.&lt;/p&gt;
    &lt;p&gt;Concurrent to our work on Battering RAM, an independent research team developed the WireTap attack, which uses a commercial DDR4 DRAM interposer to break Intel Scalable SGX. Both Battering RAM and WireTap stem from a similar attack vector, but the approaches and findings are distinct.&lt;/p&gt;
    &lt;p&gt;The key differences between these two attacks are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cost: commercial DRAM interposers require specialized, high-speed signal analyzers (typically retailing at &amp;gt;$150,000), whereas our custom-built interposer requires only two simple analog switches and some control logic, totalling about $50. Battering RAM, therefore, shows that physical attacks are practical and not limited to resourceful adversaries with a large budget.&lt;/item&gt;
      &lt;item&gt;Technique: Battering RAM and WireTap exploit distinct techniques: memory aliasing vs. ciphertext side-channel analysis. Commercial DRAM interposers passively capture memory traffic, requiring additional ciphertext side-channel inference to recover secrets. In contrast, Battering RAM uses a custom-built interposer that actively redirects address lines to introduce aliases, allowing not just observation but also replay and corruption of ciphertext and culminating in plaintext read/write access on Scalable SGX.&lt;/item&gt;
      &lt;item&gt;Target: Both Battering RAM and WireTap expose the security limitations of current, scalable memory encryption technologies. Battering RAM breaks remote attestation for both Intel Scalable SGX and AMD SEV-SNP, whereas WireTap was only demonstrated on Intel Scalable SGX but may affect AMD DDR4 systems similarly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We found that our interposer can compromise the security of two widely-deployed TEEs, Intel Scalable SGX and AMD SEV-SNP. Both of these technologies employ a memory encryption scheme that is vulnerable to memory replay attacks. Furthermore, Scalable SGX on DDR4 platforms only employs a single memory encryption key for the entire physical memory space. We show this limitation can be exploited to create an arbitrary plaintext primitive. This severely undermines the protections in the presence of a physical adversary.&lt;/p&gt;
    &lt;p&gt;On top of that, our interposer re-enables the previously-mitigated BadRAM attacks. To combat this threat, AMD rolled out firmware-level mitigations that scan for aliases at boot time. As the interposer can enable and disable the interposer at runtime, these checks are easily bypassed. As a result, Battering RAM re-enables previous attacks on AMD SEV-SNP and Intel Client SGX .&lt;/p&gt;
    &lt;p&gt;Arm has also announced a cloud TEE called CCA . Based on the specification, DDR4 systems may also be vulnerable to Battering RAM. However, as no hardware is available yet, we were unable to test our interposer on CCA.&lt;/p&gt;
    &lt;p&gt;The table below summarizes our findings across different TEEs. Each column indicates whether we were able to read, write, or replay ciphertexts, and read/write plaintext in protected memory regions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;TEE&lt;/cell&gt;
        &lt;cell role="head"&gt;Read&lt;/cell&gt;
        &lt;cell role="head"&gt;Write&lt;/cell&gt;
        &lt;cell role="head"&gt;Replay&lt;/cell&gt;
        &lt;cell role="head"&gt;Plaintext&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Intel Scalable SGX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;AMD SEV-SNP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Client SGX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Intel TDX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Arm CCA&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;No, our interposer only works on DDR4, which remains widely deployed today; e.g., a recent market study indicates that DDR4 still accounted for around 65% of sold DRAM modules in 2024.&lt;/p&gt;
    &lt;p&gt;DDR5 reorganizes the command/address bus, which removes the possibility of adding simple switches to the address lines. However, the underlying issue is not fixed, as current memory encryption engines still do not provide freshness guarantees. A determined attacker could theoretically still design more advanced interposers to perform similar attacks on DDR5.&lt;/p&gt;
    &lt;p&gt;Yes, our GitHub repository contains the hardware schematics and board files for the custom DDR4 interposer, firmware for the microcontroller, and proof-of-concept code for all attacks described in our paper. The interposer can be built for under $50, and the bill of materials is listed above.&lt;/p&gt;
    &lt;p&gt;We disclosed our findings to both Intel and AMD in February 2025. Both vendors have acknowledged our findings, but noted that physical attacks on DRAM are out of scope for their current products. To better reflect this position, Intel deposited the whitepaper on Scalable SGX, previously removed from the Intel website, permanently on arXiv.&lt;/p&gt;
    &lt;p&gt;Following an embargo period until September 30, 2025, both vendors have issued a public security advisory: Intel advisory | AMD advisory&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt; Confidential computing is here, but is not invincible. &lt;p&gt;Despite strong adoption by major CPU vendors and cloud providers, current technologies have critical physical-layer limitations that remain underexamined.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Reevaluate your threat models. &lt;p&gt;Encrypted memory is not inherently secure against physical tampering, and firmware-based mitigations alone are insufficient in threat scenarios involving limited physical access, such as malicious insiders or supply-chain compromises.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Advanced physical attacks are accessible at low cost. &lt;p&gt;Our open-source $50 custom device costs only a fraction of commercial DRAM interposers (upwards of $100,000) and is capable of breaking multi-million-dollar cloud security technologies from Intel and AMD.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://batteringram.eu/"/><published>2025-10-06T07:47:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489174</id><title>Demodesk (YC W19) Is Hiring a Ruby on Rails Engineer</title><updated>2025-10-06T16:42:49.858672+00:00</updated><content>&lt;doc fingerprint="7b681573b8765159"&gt;
  &lt;main&gt;
    &lt;p&gt;Demodesk has a global mindset, where we promote a remote friendly environment &amp;amp; employee experience comes first. We offer flexible working conditions &amp;amp; enable face time with your colleagues for those special Demodesk moments! Come join us at one of our central hubs in Munich &amp;amp; Lisbon, or from other established locations around the world.&lt;/p&gt;
    &lt;p&gt;To us, work is more than just a job. We want to provide our employees with an environment where they have the ability to constantly thrive, learn &amp;amp; grow. And we want everybody to feel at home and have the time of their life while building Demodesk.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://demodesk.com/careers"/><published>2025-10-06T08:49:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489533</id><title>Nobel Prize in Physiology or Medicine 2025</title><updated>2025-10-06T16:42:49.588334+00:00</updated><content>&lt;doc fingerprint="9384913f192e615e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Press release&lt;/head&gt;
    &lt;p&gt;English&lt;lb/&gt;English (pdf)&lt;lb/&gt;Swedish&lt;lb/&gt;Swedish (pdf)&lt;/p&gt;
    &lt;p&gt;6 October 2025&lt;/p&gt;
    &lt;p&gt;The Nobel Assembly at Karolinska Institutet has decided to award the 2025 Nobel Prize in Physiology or Medicine to:&lt;/p&gt;
    &lt;p&gt;Mary E. Brunkow&lt;lb/&gt;Institute for Systems Biology,&lt;lb/&gt;Seattle, USA&lt;/p&gt;
    &lt;p&gt;Fred Ramsdell&lt;lb/&gt;Sonoma Biotherapeutics,&lt;lb/&gt;San Francisco, USA&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi&lt;lb/&gt;Osaka University,&lt;lb/&gt;Osaka, Japan&lt;/p&gt;
    &lt;p&gt;“for their discoveries concerning peripheral immune tolerance”&lt;/p&gt;
    &lt;head rend="h2"&gt;They discovered how the immune system is kept in check&lt;/head&gt;
    &lt;p&gt;The body’s powerful immune system must be regulated, or it may attack our own organs. Mary E. Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their groundbreaking discoveries concerning peripheral immune tolerance that prevents the immune system from harming the body.&lt;/p&gt;
    &lt;p&gt;Every day, our immune system protects us from thousands of different microbes trying to invade our bodies. These all have different appearances, and many have developed similarities with human cells as a form of camouflage. So how does the immune system determine what it should attack and what it should defend?&lt;/p&gt;
    &lt;p&gt;Mary Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their fundamental discoveries relating to peripheral immune tolerance. The laureates identified the immune system’s security guards, regulatory T cells, which prevent immune cells from attacking our own body.&lt;/p&gt;
    &lt;p&gt;“Their discoveries have been decisive for our understanding of how the immune system functions and why we do not all develop serious autoimmune diseases,” says Olle Kämpe, chair of the Nobel Committee.&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi was swimming against the tide in 1995, when he made the first key discovery. At the time, many researchers were convinced that immune tolerance only developed due to potentially harmful immune cells being eliminated in the thymus, through a process called central tolerance. Sakaguchi showed that the immune system is more complex and discovered a previously unknown class of immune cells, which protect the body from autoimmune diseases.&lt;/p&gt;
    &lt;p&gt;Mary Brunkow and Fred Ramsdell made the other key discovery in 2001, when they presented the explanation for why a specific mouse strain was particularly vulnerable to autoimmune diseases. They had discovered that the mice have a mutation in a gene that they named Foxp3. They also showed that mutations in the human equivalent of this gene cause a serious autoimmune disease, IPEX.&lt;/p&gt;
    &lt;p&gt;Two years after this, Shimon Sakaguchi was able to link these discoveries. He proved that the Foxp3 gene governs the development of the cells he identified in 1995. These cells, now known as regulatory T cells, monitor other immune cells and ensure that our immune system tolerates our own tissues.&lt;/p&gt;
    &lt;p&gt;The laureates’ discoveries launched the field of peripheral tolerance, spurring the development of medical treatments for cancer and autoimmune diseases. This may also lead to more successful transplantations. Several of these treatments are now undergoing clinical trials.&lt;/p&gt;
    &lt;head rend="h2"&gt;Illustrations&lt;/head&gt;
    &lt;p&gt;The illustrations are free to use for non-commercial purposes. Attribute “© The Nobel Committee for Physiology or Medicine. Ill. Mattias Karlén”&lt;/p&gt;
    &lt;p&gt;Illustration: The Nobel Prize in Physiology or Medicine 2025&lt;lb/&gt;Illustration: How T cells discover a virus&lt;lb/&gt;Illustration: How harmful T cells are eliminated&lt;lb/&gt;Illustration: The experiment that inspired Sakaguchi&lt;lb/&gt;Illustration: Sakaguchi defines a new class of T cells&lt;lb/&gt;Illustration: Brunkow and Ramsdell find the scurfy mutation&lt;lb/&gt;Illustration: How regulatory T cells protect us&lt;/p&gt;
    &lt;head rend="h2"&gt;Read more about this year’s prize&lt;/head&gt;
    &lt;p&gt;Popular science background: They understood how the immune system is kept in check (pdf)&lt;lb/&gt;Scientific background to the Nobel Prize in Physiology or Medicine 2025 (pdf)&lt;/p&gt;
    &lt;p&gt;Mary E. Brunkow, born 1961. Ph.D. from Princeton University, Princeton, USA. Senior Program Manager at the Institute for Systems Biology, Seattle, USA.&lt;/p&gt;
    &lt;p&gt;Fred Ramsdell, born 1960. Ph.D. 1987 from the University of California, Los Angeles, USA. Scientific Advisor, Sonoma Biotherapeutics, San Francisco, USA.&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi, born 1951. M.D. 1976 and Ph.D. 1983 from Kyoto University, Japan. Distinguished Professor at the Immunology Frontier Research Center, Osaka University, Japan.&lt;/p&gt;
    &lt;p&gt;Prize amount: 11 million Swedish kronor, to be shared equally between the laureates.&lt;lb/&gt;Press contact: Pernilla Witte, +46 8 524 86 107, [email protected] or Thomas Perlmann, [email protected], Secretary-General, The Nobel Assembly at Karolinska Institutet.&lt;/p&gt;
    &lt;p&gt;Illustrations: © The Nobel Committee for Physiology or Medicine.&lt;/p&gt;
    &lt;p&gt;The Nobel Assembly, consisting of 50 professors at Karolinska Institutet, awards the Nobel Prize in Physiology or Medicine. Its Nobel Committee evaluates the nominations. Since 1901 the Nobel Prize has been awarded to scientists who have made the most important discoveries for the benefit of humankind.&lt;/p&gt;
    &lt;p&gt;Nobel Prize® is the registered trademark of the Nobel Foundation&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/medicine/2025/press-release/"/><published>2025-10-06T09:41:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45490439</id><title>Modern messaging: Running your own XMPP server</title><updated>2025-10-06T16:42:48.484121+00:00</updated><content>&lt;doc fingerprint="ddf8a45a3902bcc6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Modern messaging: Running your own XMPP server&lt;/head&gt;
    &lt;p&gt;Since a years we know, or might suspect, our chats are listend on, our uploaded files are sold for advertising or what purpose ever and the chance our social messengers leak our private data is incredibly high. It is about time to work against this.&lt;/p&gt;
    &lt;p&gt;Since 3 years the European Commission works on a plan to automatically monitor all chat, email and messenger conversations.12 If this is going to pass, and I strongly hope it will not, the European Union is moving into a direction we know from states suppressing freedom of speech.&lt;/p&gt;
    &lt;p&gt;I went for setting up my own XMPP server, as this does not have any big resource requirements and still support clustering (for high-availabilty purposes), encryption via OMEMO, file sharing and has support for platforms and operating systems. Also the ecosystem with clients and multiple use cases evolved over the years to provide rock-solid software and solutions for multi-user chats or event audio and video calls.&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;All steps and settings are bundled in a repository containing Ansible roles: https://codeberg.org/codedge/chat&lt;/p&gt;
    &lt;p&gt;All code snippets written below work in either Debian os Raspberry Pi OS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Setting up your own XMPP server&lt;/head&gt;
    &lt;p&gt;The connection from your client to the XMPP server is encrypted and we need certificates for our server. First thing to do is setting up our domains and point it to the IP - both IPv4 and IPv6 is supported and we can specify both later in our configuration.&lt;/p&gt;
    &lt;p&gt;I assume the server is going to be run under &lt;code&gt;xmpp.example.com&lt;/code&gt; and you all the following domains have been set up.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;your main xmpp server address&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;conference.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for MUC (Multi User Chat)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;proxy.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for SOCKS5 proxy support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;pubsub.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for publish/subscribe support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;upload.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for file uploads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;stun.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for audio&amp;amp;video calling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;A&lt;/cell&gt;
        &lt;cell&gt;turn.xmpp.example.com&lt;/cell&gt;
        &lt;cell&gt;needed for audio&amp;amp;video calling&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Fill in the IPv6 addresses accordingly.&lt;/p&gt;
    &lt;p&gt;ejabberd is a robust server software, that is included in most Linux distributions.&lt;/p&gt;
    &lt;p&gt;Install from Process One repository&lt;lb/&gt;I discovered ProcessOne, the company behind ejabberd, also provides a Debian repository.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Install from Github&lt;lb/&gt;To get the most recent one, I use the packages offered in their code repository. Installing version 25.07 just download the asset from the release:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Make sure the fowolling ports are opened in your firewall, taken from ejabberd firewall settings.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;5222: Jabber/XMPP client connections, plain or STARTTLS&lt;/item&gt;
      &lt;item&gt;5223: Jabber client connections, using the old SSL method&lt;/item&gt;
      &lt;item&gt;5269: Jabber/XMPP incoming server connections&lt;/item&gt;
      &lt;item&gt;5280/5443: HTTP/HTTPS for Web Admin and many more&lt;/item&gt;
      &lt;item&gt;7777: SOCKS5 file transfer proxy&lt;/item&gt;
      &lt;item&gt;3478/5349: STUN+TURN/STUNS+TURNS service&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Port &lt;code&gt;1883&lt;/code&gt;, used for MQTT, is also mentioned in the ejabberd docs, but we do not use this in our setup. So this port stays closed.&lt;/p&gt;
    &lt;p&gt;Depending how you installed ejabberd the config file is either at &lt;code&gt;/etc/ejabberd/conf/ejabberd.yml&lt;/code&gt;
or &lt;code&gt;/opt/ejabberd/conf/ejabberd.yml&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;General configuration&lt;/head&gt;
    &lt;p&gt;The configuration is a balance of 70:30 between having a privacy-focused setup for your users and meeting most of the suggestions of the XMPP complicance test. That means, settings that protect the provacy of the users are higher rated despite not passing the test.&lt;/p&gt;
    &lt;p&gt;Therefore notable privacy and security settings are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;XMPP over HTTP is disabled (mod_bosh)&lt;/item&gt;
      &lt;item&gt;Discover then a user last accessed a server is disabled (mod_last)&lt;/item&gt;
      &lt;item&gt;Delete uploaded files on a regular base (see upload config)&lt;/item&gt;
      &lt;item&gt;Register account via a web page is disabled (mod_register_web)&lt;/item&gt;
      &lt;item&gt;In-band registration can be enabled, default off, captcha secured (mod_register, see registration config)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;The configuration file is in YAML format. Keep an eye for indentation.&lt;/p&gt;
    &lt;p&gt;Let’s start digging into the configuration.&lt;/p&gt;
    &lt;p&gt;Set the domain of your server&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Set the database type&lt;lb/&gt;Instead of using the default &lt;code&gt;mnesia&lt;/code&gt; type, we opt for &lt;code&gt;sql&lt;/code&gt;, better said &lt;code&gt;sqlite&lt;/code&gt;.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Generate DH params&lt;lb/&gt;Generate a fresh set of params for the DH key exchange. In your terminal run&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;and link the new file in the ejabberd configuration.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Ensure TLS for server-to-server connections&lt;lb/&gt;Use TLS for server-to-server (s2s) connections.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The listners&lt;lb/&gt;The listeners aka &lt;code&gt;request_handlers&lt;/code&gt; inside the config especially for &lt;code&gt;/admin&lt;/code&gt;, &lt;code&gt;/captcha&lt;/code&gt;, &lt;code&gt;/upload&lt;/code&gt; and &lt;code&gt;/ws&lt;/code&gt; are important.
All of them listen on port &lt;code&gt;5443&lt;/code&gt;. Only one request handler is attached to port &lt;code&gt;5280&lt;/code&gt;, the &lt;code&gt;/.well-known/acme-challenge&lt;/code&gt;.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;ACLs &amp;amp; Access rules&lt;/head&gt;
    &lt;p&gt;For adminstration of ejabberd we need a user with admin rights and properly set up ACLs and access rules. There is a separat section for ACLs inside the config in which we set up an admin user name &lt;code&gt;root&lt;/code&gt;. The name of the user
is important for later, when we actually create this user.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The &lt;code&gt;access_rules&lt;/code&gt; should already be set up, just to confirm that you have a correct entry for the &lt;code&gt;configure&lt;/code&gt; action.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Now the new &lt;code&gt;root&lt;/code&gt; user needs to be create by running this command on the console.
Watch out to put in the correct domain.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Another user can be registered with the same command.&lt;lb/&gt;We set &lt;code&gt;root&lt;/code&gt; as the admin user in the config previously. That is how ejabberd knows which user has admin permissions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Enable file uploads&lt;/head&gt;
    &lt;p&gt;Enabling file uploads is done with &lt;code&gt;mod_http_upload&lt;/code&gt;.
First, create a folder where the uploads should be stored.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Now update the ejabberd configuration like this:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;The allowed file upload size is defined in the &lt;code&gt;max_size&lt;/code&gt; param and is set to 10MB.&lt;/p&gt;
    &lt;p&gt;Make sure, to delete uploaded files in a reasonable amount of time via cronjob. This is an example of a cronjob, that deletes files that are older than 1 week.&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Registration&lt;/head&gt;
    &lt;p&gt;Registration in ejabberd is done via &lt;code&gt;mod_register&lt;/code&gt;
and can be enabled with these entries in the config file:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;If you want to enable registration for your server make sure you enable a captcha for it. Otherwise you will get a lot of spam and fake registrations.&lt;/p&gt;
    &lt;p&gt;ejabberd provides a working captcha script, that you can copy to your server and link in your configuration. You will need &lt;code&gt;imaggemagick&lt;/code&gt; and &lt;code&gt;gstools&lt;/code&gt; installed
on you system. In the &lt;code&gt;ejabberd.yml&lt;/code&gt; config file&lt;/p&gt;
    &lt;head rend="h2"&gt;Add TLS&lt;/head&gt;
    &lt;p&gt;ejabberd can provision TLS certificates on its own. No need to install certbot. To not expose ejabberd directly to the internet, &lt;code&gt;nginx&lt;/code&gt; is put in front of the XMPP server. Instead of using nginx, every other web server (caddy, &amp;amp;mldr;)
or proxy can be used as well.&lt;/p&gt;
    &lt;p&gt;Here is a sample config for nginx:&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Alternative connection methods&lt;/head&gt;
    &lt;p&gt;The nginx vhosts offers files, &lt;code&gt;host-meta&lt;/code&gt; and &lt;code&gt;host-meta.json&lt;/code&gt;, for indicating which other connection methods (BOSH, WS) your server offers. The details can be read in XEP-0156 extension.
Opposite to the examples in the XEP, there is no BOSH, but only a websocket connection our server offers. The BOSH part is removed from the config file.&lt;/p&gt;
    &lt;p&gt;host-meta&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;host-meta.json&lt;/p&gt;
    &lt;table&gt;
      &lt;row/&gt;
    &lt;/table&gt;
    &lt;p&gt;Put that file in a folder your nginx serves. Have a look at the path and URL it is expected to be, see &lt;code&gt;.well-known&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Choose your client&lt;/head&gt;
    &lt;p&gt;Clients I can recommend are Profanity, an easy to use command-line client, and Monal for MacOS and iOS. A good overview of client can be found on the offical XMPP website.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Citizen-led initiative collecting information about Chat Controle https://fightchatcontrol.eu ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Explanation by Patrick Breyer, former member of the European Parliament https://www.patrick-breyer.de/en/posts/chat-control/ ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.codedge.de/posts/modern-messaging-running-your-own-xmpp-server"/><published>2025-10-06T12:02:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45490549</id><title>AMD signs AI chip-supply deal with OpenAI, gives it option to take a 10% stake</title><updated>2025-10-06T16:42:48.304839+00:00</updated><content/><link href="https://www.reuters.com/business/amd-signs-ai-chip-supply-deal-with-openai-gives-it-option-take-10-stake-2025-10-06/"/><published>2025-10-06T12:17:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45490578</id><title>Show HN: Write It Down – Personal finance tracker</title><updated>2025-10-06T16:42:48.154766+00:00</updated><content>&lt;doc fingerprint="6bebd4fea1545df2"&gt;
  &lt;main&gt;
    &lt;p&gt;Start tracking in 1 minute&lt;/p&gt;
    &lt;p&gt;Follow these steps and you’re ready to go.&lt;/p&gt;
    &lt;p&gt;Set up your income, expenses, and accounts to match your financial life. Add custom descriptions so you always know exactly where your money is going.&lt;/p&gt;
    &lt;p&gt;Quickly write down your daily transactions. Everything is organized, easy to review, and simple to follow as your records grow.&lt;/p&gt;
    &lt;p&gt;Explore detailed pages that highlight your spending habits, income patterns, and overall financial summary giving you a clear big-picture view.&lt;/p&gt;
    &lt;p&gt;I downloaded the personal finance sheet. Thanks for making a great and accessible Google Sheet!&lt;/p&gt;
    &lt;p&gt;Clean layout, zero fluff. Setup took minutes and I finally feel on top of my spending.&lt;/p&gt;
    &lt;p&gt;I would first like to say thank you for your sheet. It is fantastic and the best one I’ve found.&lt;/p&gt;
    &lt;p&gt;I tried several personal finance trackers on Reddit and this one is the most nicely presented.&lt;/p&gt;
    &lt;p&gt;I downloaded the personal finance sheet. Thanks for making a great and accessible Google Sheet!&lt;/p&gt;
    &lt;p&gt;Clean layout, zero fluff. Setup took minutes and I finally feel on top of my spending.&lt;/p&gt;
    &lt;p&gt;I would first like to say thank you for your sheet. It is fantastic and the best one I’ve found.&lt;/p&gt;
    &lt;p&gt;I tried several personal finance trackers on Reddit and this one is the most nicely presented.&lt;/p&gt;
    &lt;p&gt;The overview is simple yet very powerful. Clear view without overwhelm.&lt;/p&gt;
    &lt;p&gt;Finally a tracker that’s both clear and practical. No fluff, just what I need.&lt;/p&gt;
    &lt;p&gt;Exactly what I needed practical but still readable. Perfect balance.&lt;/p&gt;
    &lt;p&gt;Loved the design and flexible sheets. It fits how I actually budget.&lt;/p&gt;
    &lt;p&gt;The overview is simple yet very powerful. Clear view without overwhelm.&lt;/p&gt;
    &lt;p&gt;Finally a tracker that’s both clear and practical. No fluff, just what I need.&lt;/p&gt;
    &lt;p&gt;Exactly what I needed practical but still readable. Perfect balance.&lt;/p&gt;
    &lt;p&gt;Loved the design and flexible sheets. It fits how I actually budget.&lt;/p&gt;
    &lt;p&gt;I downloaded the personal finance sheet. Thanks for making a great and accessible Google Sheet!&lt;/p&gt;
    &lt;p&gt;Clean layout, zero fluff. Setup took minutes and I finally feel on top of my spending.&lt;/p&gt;
    &lt;p&gt;I would first like to say thank you for your sheet. It is fantastic and the best one I’ve found.&lt;/p&gt;
    &lt;p&gt;I tried several personal finance trackers on Reddit and this one is the most nicely presented.&lt;/p&gt;
    &lt;p&gt;The overview is simple yet very powerful. Clear view without overwhelm.&lt;/p&gt;
    &lt;p&gt;Finally a tracker that’s both clear and practical. No fluff, just what I need.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://write-it-down.com"/><published>2025-10-06T12:23:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45491609</id><title>Show HN: Kent Dybvig's Scheme Machine in 400 Lines of C (Heap-Memory Model)</title><updated>2025-10-06T16:42:47.713061+00:00</updated><content>&lt;doc fingerprint="c5d093b93a485002"&gt;
  &lt;main&gt;
    &lt;p&gt; Created &lt;relative-time&gt;February 17, 2023 12:42&lt;/relative-time&gt;&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;tool-tip&gt;Save swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b to your computer and use it in GitHub Desktop.&lt;/tool-tip&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Heap based scheme machine. &lt;/p&gt;
    &lt;p&gt; This file contains hidden or bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;/* Heap based virtual machine described in section 3.4 of Three Implementation Models for Scheme, Dybvig&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;*/&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;stdlib.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;string.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;ctype.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;#include &amp;lt;assert.h&amp;gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char token[128][32];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int lexer(char* input) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int ii = 0; // input index&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int ti = 0; // token index&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while(input[ii] != '\0')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;switch(input[ii]) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Ignore whitespace and newlines&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case ' ':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '\n':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn a left parenthesis into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '(':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = '(';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn a right parenthesis into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case ')':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = ')';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Turn an apostrophe into a token.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;case '\'':&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][0] = '\'';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][1] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ii;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Anything else is a symbol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;default:&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;for(int i = 0;; ++i) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(input[ii] != ' ' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != ')' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '(' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '\n' &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;input[ii] != '\0') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][i] = input[ii++];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;token[ti][i] = '\0';&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;++ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;break;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return ti;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int curtok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* nexttok() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return token[curtok++];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* peektok() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return token[curtok];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;typedef struct Pair {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;} Pair;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;typedef struct Text {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;struct Text* cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;} Text;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair text[1280];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* textptr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int istext(void* x) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return x &amp;gt;= (void*)&amp;amp;text &amp;amp;&amp;amp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;x &amp;lt; (void*)&amp;amp;text[1280];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* cons(void* x, void* y) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(istext(textptr));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr-&amp;gt;car = x;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr-&amp;gt;cdr = y;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return textptr++;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read(char* ln);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read(char* ln) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// Initialize the lexer and list memory.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;curtok = 0;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;textptr = text;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;lexer(ln);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_exp() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* tok = nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (tok[0] == '(' &amp;amp;&amp;amp; peektok()[0] == ')') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (tok[0] == '\'')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("quote", cons(read_exp(), NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (tok[0] == '(')&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return tok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* read_list() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char* tok = peektok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(tok[0] == ')') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(tok[0] == '.') {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;tok = read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;nexttok();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return tok;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* fst = read_exp();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* snd = read_list();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(fst, snd);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print(void* exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_exp(void* exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_list(Pair* list);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_cons(Pair* pair);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print(void* exp) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_exp(void* exp) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (istext(exp)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* pair = exp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(!istext(pair-&amp;gt;cdr) &amp;amp;&amp;amp; pair-&amp;gt;cdr != NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("(");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_cons(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("(");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_list(exp);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("%s", exp ? (char*)exp : "()");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_list(Pair* list) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (list-&amp;gt;cdr == NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(list-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if(!istext(list-&amp;gt;cdr) &amp;amp;&amp;amp; list-&amp;gt;cdr != NULL) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_cons(list);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(")");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(list-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(" ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_list(list-&amp;gt;cdr);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void print_cons(Pair* pair) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(pair-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf(" . ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print_exp(pair-&amp;gt;cdr);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* compile(void* exp, void* next) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (istext(exp)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* p = exp;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(p-&amp;gt;car, "quote") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(p-&amp;gt;cdr-&amp;gt;car, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "lambda") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("close", cons(p-&amp;gt;cdr-&amp;gt;car, cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, cons("return", NULL)), cons(next, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "if") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return compile(p-&amp;gt;cdr-&amp;gt;car, cons("test", cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, next),&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;cons(compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, next),&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "set!") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return compile(p-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car, cons("assign", cons(p-&amp;gt;cdr-&amp;gt;car, cons(next, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(p-&amp;gt;car, "call/cc") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* c = cons("conti", cons(cons("argument", cons(compile(p-&amp;gt;cdr-&amp;gt;car, cons("apply", NULL)), NULL)), NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "return") == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return c;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("frame", cons(next, cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* args = (Pair*)p-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* c = compile(p-&amp;gt;car, cons("apply", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (args) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;c = compile(args-&amp;gt;car, cons("argument", cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;args = args-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "return") == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return c;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("frame", cons(next, cons(c, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(isdigit(*((char*)exp))) { // a number&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(strcmp(exp, "#t") == 0) { // a boolean&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if(strcmp(exp, "#f") == 0) { // a boolean&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("constant", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else { // a symbol&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons("refer", cons(exp, cons(next, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* get(void* env, char* var) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* e = env;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while(env) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* cur = e-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* vars = cur-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pair* vals = cur-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (vars &amp;amp;&amp;amp; vals) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(vars-&amp;gt;car, var) == 0)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return vals-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vars = vars-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;vals = vals-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;e = e-&amp;gt;cdr;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fprintf(stderr, "No definition in environment for %s.\n", var);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void set(void* env, char* var, char* val) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* ref = get(env, var);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ref = val;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* extend(void* env, void* vars, void* vals) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(cons(vars, vals), env);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* callframe(void* next, void* env, void* rib, void* stack) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(next, cons(env, cons(rib, cons(stack, NULL))));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* closure(void* body, void* env, void* vars) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return cons(body, cons(env, cons(vars, NULL)));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* continuation(void* stack) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return closure(cons("nuate", cons(stack, cons("v", NULL))), NULL, cons("v", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* accum;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* env;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* rib;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* stack;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void virtmach() {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* n = next;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;if (strcmp(n-&amp;gt;car, "halt") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "refer") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = get(env, n-&amp;gt;cdr-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "constant") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "close") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* vars = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* body = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* x = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = closure(body, env, vars);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = x;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "test") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* consequent = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* alternate = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = strcmp(accum, "#f") == 0 ? alternate : consequent;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "assign") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;set(env, n-&amp;gt;cdr-&amp;gt;car, accum);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "conti") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = continuation(stack);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "nuate") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;accum = get(env, n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = cons("return", NULL);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "frame") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = callframe(n-&amp;gt;cdr-&amp;gt;car, env, rib, stack);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "argument") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = cons(accum, rib);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = n-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "apply") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* a = accum;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* body = a-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* clos = a-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;void* vars = a-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;env = extend(env, vars, rib);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = NULL;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = body;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else if (strcmp(n-&amp;gt;car, "return") == 0) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text* s = stack;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = s-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;env = s-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;rib = s-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;stack = s-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;cdr-&amp;gt;car;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;else {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;fprintf(stderr, "Unhandled operation.\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;assert(0);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;int main(int argc, char** argv) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;// note! repl implies there's a top-level but there isn't...&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("Lisp REPL\n\n");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("&amp;gt;&amp;gt; ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;char buffer[256];&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;while (fgets(buffer, 256, stdin)) {&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;next = compile(read(buffer), cons("halt", NULL));&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;virtmach();&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;print(accum);&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;printf("&amp;gt;&amp;gt; ");&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;return 0;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;}&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gist.github.com/swatson555/8cc36d8d022d7e5cc44a5edb2c4f7d0b"/><published>2025-10-06T14:06:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45491621</id><title>Mise: Monorepo Tasks</title><updated>2025-10-06T16:42:47.363684+00:00</updated><content>&lt;doc fingerprint="3c542c738fd7e4ba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Monorepo Tasks #6564&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;We're excited to announce Monorepo Tasks, a powerful new feature that brings first-class monorepo support to mise tasks! 🚀&lt;/p&gt;
          &lt;head&gt;What is it?&lt;/head&gt;
          &lt;p&gt;Monorepo Tasks allows you to manage tasks across multiple projects in a single repository, with each project maintaining its own tools, environment variables, and tasks. Think of it as bringing the power of tools like Bazel or Turborepo to mise's task system, but with mise's signature simplicity.&lt;/p&gt;
          &lt;head&gt;Key Features&lt;/head&gt;
          &lt;head&gt;🎯 Unified Task Namespace&lt;/head&gt;
          &lt;p&gt;All tasks across your monorepo are automatically discovered and prefixed with their location:&lt;/p&gt;
          &lt;code&gt;mise //projects/frontend:build
mise //projects/backend:test
mise //services/api:deploy&lt;/code&gt;
          &lt;head&gt;🌳 Smart Tool &amp;amp; Environment Inheritance&lt;/head&gt;
          &lt;p&gt;Define common tools at the root, override them where needed:&lt;/p&gt;
          &lt;code&gt;# Root mise.toml
[tools]
node = "20"      # Inherited everywhere
python = "3.12"

# projects/legacy-app/mise.toml
[tools]
node = "14"      # Override just for this project
# python still inherited!&lt;/code&gt;
          &lt;head&gt;🎭 Powerful Wildcard Patterns&lt;/head&gt;
          &lt;p&gt;Run tasks across multiple projects with ease:&lt;/p&gt;
          &lt;code&gt;# Run tests in ALL projects
mise //...:test

# Run all build tasks under services/
mise //services/...:build

# Run ALL tasks in frontend (wildcards need quotes)
mise '//projects/frontend:*'

# Run all test:* tasks everywhere
mise '//...:test:*'&lt;/code&gt;
          &lt;head&gt;✨ Consistent Execution Anywhere&lt;/head&gt;
          &lt;p&gt;Run tasks from anywhere in the monorepo - they always execute with the correct context, tools, and environment from their config_root.&lt;/p&gt;
          &lt;head&gt;🔒 Automatic Trust Propagation&lt;/head&gt;
          &lt;p&gt;Trust your monorepo root once, and all descendant configs are automatically trusted.&lt;/p&gt;
          &lt;head&gt;Quick Start&lt;/head&gt;
          &lt;p&gt;1. Enable the feature in your root &lt;/p&gt;
          &lt;code&gt;experimental_monorepo_root = true

[tools]
node = "20"
python = "3.12"&lt;/code&gt;
          &lt;p&gt;2. Set the experimental flag:&lt;/p&gt;
          &lt;code&gt;export MISE_EXPERIMENTAL=1&lt;/code&gt;
          &lt;p&gt;3. Add tasks to your projects:&lt;/p&gt;
          &lt;code&gt;# projects/frontend/mise.toml
[tasks.build]
run = "npm run build"

[tasks.test]
run = "npm test"&lt;/code&gt;
          &lt;p&gt;4. Run tasks from anywhere:&lt;/p&gt;
          &lt;code&gt;mise //projects/frontend:build
mise //...:test  # Run tests in all projects!&lt;/code&gt;
          &lt;head&gt;Example Monorepo Structure&lt;/head&gt;
          &lt;p&gt;Run all service builds: &lt;/p&gt;
          &lt;head&gt;Why This Matters&lt;/head&gt;
          &lt;p&gt;Managing monorepos is hard. Coordinating tools, tasks, and environments across dozens of projects is even harder. With Monorepo Tasks, you get:&lt;/p&gt;
          &lt;head&gt;How Does This Compare to Other Tools?&lt;/head&gt;
          &lt;p&gt;The monorepo ecosystem is rich with excellent tools, each with different strengths. Here's how mise's Monorepo Tasks compares:&lt;/p&gt;
          &lt;head&gt;Simple Task Runners&lt;/head&gt;
          &lt;p&gt;Taskfile and Just are fantastic for single-project task automation. They're lightweight and easy to set up, but they weren't designed with monorepos in mind. While you can have multiple Taskfiles/Justfiles in a repo, they don't provide unified task discovery, cross-project wildcards, or automatic tool/environment inheritance across projects.&lt;/p&gt;
          &lt;p&gt;mise's advantage: Automatic task discovery across the entire monorepo with a unified namespace and powerful wildcard patterns.&lt;/p&gt;
          &lt;head&gt;JavaScript-Focused Tools&lt;/head&gt;
          &lt;p&gt;Nx, Turborepo, and Lerna are powerful tools specifically designed for JavaScript/TypeScript monorepos.&lt;/p&gt;
          &lt;p&gt;mise's advantage: Language-agnostic support. While these tools excel in JS/TS ecosystems, mise works equally well with Rust, Go, Python, Ruby, or any mix of languages. You also get unified tool version management (not just tasks) and environment variables across your entire stack.&lt;/p&gt;
          &lt;head&gt;Large-Scale Build Systems&lt;/head&gt;
          &lt;p&gt;Bazel (Google) and Buck2 (Meta) are industrial-strength build systems designed for massive, multi-language monorepos at companies with thousands of engineers.&lt;/p&gt;
          &lt;p&gt;Both are extremely powerful but come with significant complexity:&lt;/p&gt;
          &lt;p&gt;mise's advantage: Simplicity through non-hermetic builds. mise doesn't try to control your entire build environment in isolation - instead, it manages tools and tasks in a flexible, practical way. This "non-hermetic" approach means you can use mise without restructuring your entire codebase or learning a new language. You get powerful monorepo task management with simple TOML configuration - enough power for most teams without the enterprise-level complexity that hermetic builds require.&lt;/p&gt;
          &lt;head&gt;Other Notable Tools&lt;/head&gt;
          &lt;p&gt;Rush (Microsoft) offers strict dependency management and build orchestration for JavaScript monorepos, with a focus on safety and convention adherence.&lt;/p&gt;
          &lt;p&gt;Moon is a newer Rust-based build system that aims to be developer-friendly while supporting multiple languages.&lt;/p&gt;
          &lt;head&gt;The mise Sweet Spot&lt;/head&gt;
          &lt;p&gt;mise's Monorepo Tasks aims to hit the sweet spot between simplicity and power:&lt;/p&gt;
          &lt;p&gt;When to choose mise:&lt;/p&gt;
          &lt;p&gt;When to consider alternatives:&lt;/p&gt;
          &lt;p&gt;The best tool is the one that fits your team's needs. mise's Monorepo Tasks is designed for teams who want powerful monorepo management without the complexity overhead, especially when working across multiple languages.&lt;/p&gt;
          &lt;head&gt;Try It Out!&lt;/head&gt;
          &lt;p&gt;This feature is experimental, which means:&lt;/p&gt;
          &lt;p&gt;Read the full documentation: Monorepo Tasks Guide&lt;/p&gt;
          &lt;head&gt;We Want Your Feedback!&lt;/head&gt;
          &lt;p&gt;Please try it out and let us know:&lt;/p&gt;
          &lt;p&gt;Share your experience in the comments below! 👇&lt;/p&gt;
          &lt;p&gt;Special shoutout to the mise community for the feedback and ideas that led to this feature. Happy building! 🛠️&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jdx/mise/discussions/6564"/><published>2025-10-06T14:07:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492376</id><title>Expected Attention: KV Cache Compression by Estimating Attention</title><updated>2025-10-06T16:42:47.210192+00:00</updated><content>&lt;doc fingerprint="cc9e342a4df102ee"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 1 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Expected Attention: KV Cache Compression by Estimating Attention from Future Queries Distribution&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Memory consumption of the Key-Value (KV) cache represents a major bottleneck for efficient large language model inference. While attention-score-based KV cache pruning shows promise, it faces critical practical limitations: attention scores from future tokens are unavailable during compression, and modern implementations like Flash Attention do not materialize the full attention matrix, making past scores inaccessible. To overcome these challenges, we introduce $\textbf{Expected Attention, a training-free compression method}$ that estimates KV pairs importance by predicting how future queries will attend to them. Our approach leverages the distributional properties of LLM activations to compute expected attention scores in closed form for each KV pair. These scores enable principled ranking and pruning of KV pairs with minimal impact on the residual stream, achieving effective compression without performance degradation. Importantly, our method operates seamlessly across both prefilling and decoding phases, consistently outperforming state-of-the-art baselines in both scenarios. Finally, $\textbf{we release KVPress, a comprehensive library to enable researchers to implement and benchmark KV cache compression methods, already including more than 20 techniques}$.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.00636"/><published>2025-10-06T15:22:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492564</id><title>Launch HN: Grapevine (YC S19) – A company GPT that actually works</title><updated>2025-10-06T16:42:47.041251+00:00</updated><content>&lt;doc fingerprint="a74e481eafb1f0bb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Stop wasting time searching.&lt;/head&gt;
    &lt;head rend="h1"&gt;Stop wasting time searching.&lt;/head&gt;
    &lt;head rend="h1"&gt;Stop wasting time searching.&lt;/head&gt;
    &lt;p&gt;One AI agent that searches across your docs, code, and communicationâso you donât have to.&lt;/p&gt;
    &lt;p&gt;Thread&lt;/p&gt;
    &lt;p&gt;Aleks&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I wish there were a company GPT that ACTUALLY worked + wasn't exorbitantly expensive ðªðª&lt;/p&gt;
    &lt;p&gt;1 reply&lt;/p&gt;
    &lt;p&gt;Grapevine&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I can help with that, and you can get started for free!&lt;/p&gt;
    &lt;p&gt;Thread&lt;/p&gt;
    &lt;p&gt;Aleks&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I wish there were a company GPT that ACTUALLY worked + wasn't exorbitantly expensive ðªðª&lt;/p&gt;
    &lt;p&gt;1 reply&lt;/p&gt;
    &lt;p&gt;Grapevine&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I can help with that, and you can get started for free!&lt;/p&gt;
    &lt;p&gt;Thread&lt;/p&gt;
    &lt;p&gt;Aleks&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I wish there were a company GPT that ACTUALLY worked + wasn't exorbitantly expensive ðªðª&lt;/p&gt;
    &lt;p&gt;1 reply&lt;/p&gt;
    &lt;p&gt;Grapevine&lt;/p&gt;
    &lt;p&gt;12:12 PM&lt;/p&gt;
    &lt;p&gt;I can help with that, and you can get started for free!&lt;/p&gt;
    &lt;head rend="h2"&gt;What if ChatGPT was aware of my company's context?&lt;/head&gt;
    &lt;head rend="h3"&gt;We've all wondered it at some point.&lt;/head&gt;
    &lt;head rend="h3"&gt;What if AI already understood your companyâso you could skip the busywork, the repetitive asks, the frustration?&lt;/head&gt;
    &lt;head rend="h3"&gt;It could take care of the many chores that exist in work today, making our days a little less annoying and little more fun.&lt;/head&gt;
    &lt;head rend="h3"&gt;Other products we've tried haven't quite worked. Some of us have tried to build it ourselves.&lt;/head&gt;
    &lt;head rend="h3"&gt;That's why we built Grapevine. And it finally works.&lt;/head&gt;
    &lt;p&gt;#team-infra&lt;/p&gt;
    &lt;p&gt;For commonly asked cross-team questions&lt;/p&gt;
    &lt;p&gt;Johnny&lt;/p&gt;
    &lt;p&gt;Jul 28th at 4:23 PM&lt;/p&gt;
    &lt;p&gt;Hey Infra team, Iâd like to create a new S3 bucket...&lt;/p&gt;
    &lt;p&gt;Actual Slack thread&lt;/p&gt;
    &lt;p&gt;3 sources&lt;/p&gt;
    &lt;p&gt;Real examples of us using Grapevine internally, over the last 2 months&lt;/p&gt;
    &lt;p&gt;&amp;gt;85%&lt;/p&gt;
    &lt;p&gt;&amp;gt;85%&lt;/p&gt;
    &lt;p&gt;&amp;gt;85%&lt;/p&gt;
    &lt;p&gt;of answers are helpful &amp;amp; accurate&lt;/p&gt;
    &lt;p&gt;of answers are helpful &amp;amp; accurate&lt;/p&gt;
    &lt;p&gt;*from hundreds of real questions from beta customers&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started in under 30 minutes&lt;/head&gt;
    &lt;p&gt;10 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Connect your data and setup Slack bot&lt;/head&gt;
    &lt;p&gt;30 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Start asking questions&lt;/head&gt;
    &lt;p&gt;2 days&lt;/p&gt;
    &lt;head rend="h6"&gt;Tackle queries with full historical context&lt;/head&gt;
    &lt;p&gt;Over time&lt;/p&gt;
    &lt;head rend="h6"&gt;Grapevine keeps learning and getting sharper&lt;/head&gt;
    &lt;head rend="h2"&gt;Get started in under 30 minutes&lt;/head&gt;
    &lt;p&gt;10 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Connect your data and setup Slack bot&lt;/head&gt;
    &lt;p&gt;30 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Start asking questions&lt;/head&gt;
    &lt;p&gt;2 days&lt;/p&gt;
    &lt;head rend="h6"&gt;Tackle queries with full historical context&lt;/head&gt;
    &lt;p&gt;Over time&lt;/p&gt;
    &lt;head rend="h6"&gt;Grapevine keeps learning and getting sharper&lt;/head&gt;
    &lt;head rend="h2"&gt;Get started in under 30 minutes&lt;/head&gt;
    &lt;p&gt;10 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Connect your data and setup Slack bot&lt;/head&gt;
    &lt;p&gt;30 min&lt;/p&gt;
    &lt;head rend="h6"&gt;Start asking questions&lt;/head&gt;
    &lt;p&gt;2 days&lt;/p&gt;
    &lt;head rend="h6"&gt;Tackle queries with full historical context&lt;/head&gt;
    &lt;p&gt;Over time&lt;/p&gt;
    &lt;head rend="h6"&gt;Grapevine keeps learning and getting sharper&lt;/head&gt;
    &lt;head rend="h3"&gt;Always Secure&lt;/head&gt;
    &lt;head rend="h6"&gt;Encrypted at rest&lt;/head&gt;
    &lt;p&gt;Data is encrypted using industry-standard AES-256, protecting your companyâs knowledge even when itâs not in use.&lt;/p&gt;
    &lt;head rend="h6"&gt;Encrypted at rest&lt;/head&gt;
    &lt;p&gt;Data is encrypted using industry-standard AES-256, protecting your companyâs knowledge even when itâs not in use.&lt;/p&gt;
    &lt;head rend="h6"&gt;Encrypted at rest&lt;/head&gt;
    &lt;p&gt;All data is encrypted using industry-standard AES-256&lt;/p&gt;
    &lt;head rend="h6"&gt;Isolated databases&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately to ensure maximum privacy and security.&lt;/p&gt;
    &lt;head rend="h6"&gt;Isolated databases&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately to ensure maximum privacy and security.&lt;/p&gt;
    &lt;head rend="h6"&gt;Isolated databases&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately&lt;/p&gt;
    &lt;head rend="h6"&gt;SOC II Compliant&lt;/head&gt;
    &lt;p&gt;Built to Gather's SOC II Type 2 standards, with regularly scheduled security audits and more details upon request.&lt;/p&gt;
    &lt;head rend="h6"&gt;SOC II Compliant&lt;/head&gt;
    &lt;p&gt;Built to Gather's SOC II Type 2 standards, with regularly scheduled security audits and more details upon request.&lt;/p&gt;
    &lt;head rend="h6"&gt;SOC II Compliant&lt;/head&gt;
    &lt;p&gt;Every customerâs data is siloed and stored separately&lt;/p&gt;
    &lt;p&gt;Grapevine will not train models on your data&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started today.&lt;/head&gt;
    &lt;head rend="h2"&gt;What if ChatGPT was aware of my company's context?&lt;/head&gt;
    &lt;p&gt;We've all wondered this at some point. And we finally built a version of this that works. But don't take our word for itâtry it today!&lt;/p&gt;
    &lt;p&gt;#team-infra&lt;/p&gt;
    &lt;p&gt;For commonly asked cross-team questions&lt;/p&gt;
    &lt;p&gt;Johnny&lt;/p&gt;
    &lt;p&gt;Jul 28th at 4:23 PM&lt;/p&gt;
    &lt;p&gt;Hey Infra team, Iâd like to create a new S3 bucket...&lt;/p&gt;
    &lt;p&gt;Actual Slack thread&lt;/p&gt;
    &lt;p&gt;3 sources&lt;/p&gt;
    &lt;p&gt;Real examples of us using Grapevine internally, over the last 2 months&lt;/p&gt;
    &lt;p&gt;#team-infra&lt;/p&gt;
    &lt;p&gt;For commonly asked cross-team questions&lt;/p&gt;
    &lt;p&gt;Johnny&lt;/p&gt;
    &lt;p&gt;Jul 28th at 4:23 PM&lt;/p&gt;
    &lt;p&gt;Hey Infra team, Iâd like to create a new S3 bucket...&lt;/p&gt;
    &lt;p&gt;Actual Slack thread&lt;/p&gt;
    &lt;p&gt;3 sources&lt;/p&gt;
    &lt;p&gt;Real examples of us using Grapevine internally, over the last 2 months&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://getgrapevine.ai/"/><published>2025-10-06T15:39:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45492888</id><title>"Be Different" doesn't work for building products anymore</title><updated>2025-10-06T16:42:46.940459+00:00</updated><content/><link href="https://iamcharliegraham.substack.com/p/be-different-doesnt-work-for-building"/><published>2025-10-06T16:09:22+00:00</published></entry></feed>