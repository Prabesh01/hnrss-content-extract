<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-26T12:20:46.761215+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46358211</id><title>Paperbacks and TikTok</title><updated>2025-12-26T12:20:58.799568+00:00</updated><content>&lt;doc fingerprint="2134134129800e91"&gt;
  &lt;main&gt;
    &lt;p&gt;In 1939, Simon &amp;amp; Schuster revolutionized the American publishing industry with the launch of Pocket Books, a line of diminutive volumes (measuring 4 by 6 inches) that cost only a quarter; a significant discount at a time when a typical hardcover book would set you back between $2.50 and $3.00.&lt;/p&gt;
    &lt;p&gt;To make the economics of this new model work, Simon &amp;amp; Schuster had to move a huge volume of units. ‚Äú[They] sold books where they had never been available before‚Äìgrocery stores, drugstores and airport terminals,‚Äù explains Clive Thompson in a fascinating 2013 article about the Pocket Books phenomenon. ‚ÄúWithin two years, [they‚Äôd] sold 17 million.‚Äù Thompson quotes the historian Kenneth C. Davis, who explains that these new paperbacks had ‚Äútapped into a huge reservoir of Americans who nobody realized wanted to read.‚Äù&lt;/p&gt;
    &lt;p&gt;This demand, however, created a problem: there weren‚Äôt enough books to sell. In 1939, the book market was relatively small. (Thompson estimates that around this time, America had only 500 bookstores, almost exclusively clustered around a dozen major cities.) To make money on paperbacks, the pipeline of new titles released each year would need to increase drastically. This, in turn, required a significant loosening of the standards for what was worthy of publication, leading, among other changes, to the sudden prioritization of genre fiction writers who could churn out serviceable potboilers at a rapid clip.&lt;/p&gt;
    &lt;p&gt;(Interestingly, this new class of writers included a young Michael Crichton, who, during his years as a medical student at Harvard in the 1960s, published preposterous paperback adventure novels under pseudonyms, which he finished by working at ‚Äúa furious pace‚Äù on weekends and vacations. I‚Äôve read some of these early works, and they‚Äôre mainly mediocre. But that wasn‚Äôt a problem, as the goal for many such paperbacks was simply to provide disposable distraction.)&lt;/p&gt;
    &lt;p&gt;Predictably, the new prominence of these lower-quality genres concerned the elite class. Thompson quotes the social critic Harvey Swados, who described the paperback revolution as ushering in a ‚Äúflood of trash‚Äù that would ‚Äúdebase farther the popular taste.‚Äù There was a fear that the mass appeal of these cheap books would eventually lead to the elimination of the more serious hardcover titles that had long defined publishing.&lt;/p&gt;
    &lt;p&gt;Here we find a parallel to our current moment. As the platforms of the digital attention economy transition from social network models to providing maximally distracting short-form videos, more of the content available online is devolving toward that paragon of low-quality forgettability, commonly referred to as slop. Who will listen to a podcast or read a long essay, many now fret, when Sora can offer countless videos of historical figures dancing and X can deliver an endless sequence of nudity and bar fights?&lt;/p&gt;
    &lt;p&gt;If we return to the paperback example, however, we might find a small sliver of hope. Ultimately, the explosion of these cheaper, often lower-quality books didn‚Äôt lead to the elimination of more serious titles. In fact, the opposite happened. Vastly more hardcover titles are published today than they were before the Pocket Books revolution began.&lt;/p&gt;
    &lt;p&gt;A closer look reveals that by vastly increasing the market for the published word, paperbacks also vastly increased the opportunities to make a living writing serious books (which, for the sake of this discussion, I‚Äôll define as books that require at least a year to write and are published in hardcover). There was, to be sure, a lot of trash put out during the heyday of the paperback, but this reconfigured publishing model also generated a lucrative secondary market for more traditional writers.&lt;/p&gt;
    &lt;p&gt;Stephen King, for example, sold the hardcover rights to his first novel, Carrie, for around $2,500 in 1973 ($18,000 in today‚Äôs dollars). This was a nice bonus, but hardly enough to live on. The paperback rights for Carrie, by contrast, sold for $400,000 (almost $3,000,000 in today‚Äôs dollars), allowing King to quit his day job and become a full-time writer.&lt;/p&gt;
    &lt;p&gt;King wasn‚Äôt alone; other acclaimed authors, from Ursula K. Le Guin to Ray Bradbury, to Agatha Christie, also would have never risen to such prominence without the opportunities provided by the paperback world. As for Crichton, we know what happened next. The nine, mostly cheesy paperbacks, he wrote using pseudonyms, helped him polish his craft. His first hardcover book, The Andromeda Strain, was a massive bestseller and initiated the beginning of a career as one of the most influential writers of his generation.&lt;/p&gt;
    &lt;p&gt;As you know, I strongly dislike much of the current digital attention economy, and I believe that most people should be spending vastly less time engaging with these products. But in the spirit of trying to end 2025 on an optimistic note, I find some solace in the story of paperback books. Just because a certain type of low-quality media becomes immensely popular doesn‚Äôt necessarily mean that the deeper alternatives will suffer. Over one billion TikTok videos will be viewed today, and yet, you‚Äôre still here, reading a speculative essay about media economics. I don‚Äôt take that for granted.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://calnewport.com/on-paperbacks-and-tiktok/"/><published>2025-12-22T19:55:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46363870</id><title>Show HN: GeneGuessr ‚Äì a daily biology web puzzle</title><updated>2025-12-26T12:20:58.375949+00:00</updated><content>&lt;doc fingerprint="bb7da7a56e64d3c2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GeneGuessr - Daily Protein Guessing Game&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Play GeneGuessr&lt;/head&gt;
    &lt;head rend="h3"&gt;Welcome to GeneGuessr!&lt;/head&gt;
    &lt;p&gt;This is the protein of the day. Can you figure out which gene made it?&lt;/p&gt;
    &lt;p&gt;You will see spoiler bars that cover valuable hints. Tap the spoiler bar to reveal a hint underneath.&lt;/p&gt;
    &lt;p&gt;Look up your favorite gene with the search bar. Submit it as your first guess.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedback cards&lt;/head&gt;
    &lt;p&gt;Each of your guesses will appear as a feedback card.&lt;/p&gt;
    &lt;p&gt;The feedback bar percentage shows how close you got.&lt;/p&gt;
    &lt;p&gt;Look for highlighted properties. They match your target.&lt;/p&gt;
    &lt;head rend="h3"&gt;Revealing hints&lt;/head&gt;
    &lt;p&gt;It costs 1 hint to remove a spoiler bar. You get +1 hint for each guess.&lt;/p&gt;
    &lt;p&gt;When the hint is too obvious, the bar stays locked. Just try unlocking another one.&lt;/p&gt;
    &lt;p&gt;You get to make 10 guesses before the game ends. Feel free to experiment!&lt;/p&gt;
    &lt;p&gt; Protein data: UniProt &lt;/p&gt;
    &lt;p&gt; Gene nomenclature: HGNC &lt;/p&gt;
    &lt;p&gt; Gene summaries: NCBI Gene &lt;/p&gt;
    &lt;p&gt; Gene Ontology: GO Consortium &lt;/p&gt;
    &lt;p&gt; Architecture: CATH &lt;/p&gt;
    &lt;p&gt; Pathway data: Reactome &lt;/p&gt;
    &lt;p&gt; Tissue specificity: Human Protein Atlas RNA expression (tau metric) &lt;/p&gt;
    &lt;p&gt; 3D structures: RCSB PDB, AlphaFold DB, SWISS-MODEL &lt;/p&gt;
    &lt;p&gt; Structure viewer: Mol* (via PDBe integration) &lt;/p&gt;
    &lt;p&gt; Origin age: Litman T &amp;amp; Stein WD (2019). Obtaining estimates for the ages of all the protein-coding genes and most of the ontology-identified noncoding genes of the human genome, assigned to 19 phylostrata Semin Oncol 46(1):3-9 &lt;/p&gt;
    &lt;p&gt; First publication year: Zwick ME, Kraemer SA &amp;amp; Carter GW (2019). Dataset of frequency patterns of publications for human protein-coding genes. Data Brief 28:104770 &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://geneguessr.brinedew.bio/"/><published>2025-12-23T09:40:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379145</id><title>Show HN: Lamp Carousel ‚Äì DIY kinetic sculpture powered by lamp heat (2024)</title><updated>2025-12-26T12:20:58.159732+00:00</updated><content>&lt;doc fingerprint="37d2569f58d80d5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Can Spinners&lt;/head&gt;
    &lt;p&gt;I came up with these little spinning doodads a few years ago around Christmas, and I haven't seen anything like them online, so I'm writing about them here as they are quite fun to make. I've just been calling these things "can spinners" (ChatGPT suggested "twirluminum").&lt;/p&gt;
    &lt;p&gt;They remind me a bit of candle carousels that I would see at my grandparents' house, but in this case they are cut from recycled aluminum soda cans and spin on sharpened tips of wire from the heat rising off the lamp.&lt;/p&gt;
    &lt;p&gt;I got my family to create their own this year and it was interesting to see the variety of designs they came up with (see the gallery below).&lt;/p&gt;
    &lt;head rend="h1"&gt;Construction&lt;/head&gt;
    &lt;p&gt;All the spinners shown above are made from sides and bottoms of recycled soda cans.&lt;/p&gt;
    &lt;p&gt;My process usually goes like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Sharpen pivot wire.&lt;/p&gt;&lt;lb/&gt;The spinners need a fine pivot point to sit on with low friction. I used some steel craft wire that was laying around and sharpened it on a bench grinder. Paper clips and sandpaper would probably work too.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Cut out blank&lt;/p&gt;&lt;lb/&gt;I've made these from the sides and bottoms of cans. Can sidewalls are much easier to cut and bend, so I'd recommend starting with that. Also be careful with the sharp scraps. I've been jabbed a few times making these.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Create the central dimple&lt;/p&gt;&lt;lb/&gt;I usually just use a hard, blunt object like a ballpoint pen or pliers to push a dimple into the aluminum without crushing it. Can bottoms are made from thicker aluminum, so I had to gently tap on the back of the pen with a hammer to make the dimple. It's very easy to accidentally pierce the aluminum so be careful!&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Cut out blades and bend into shape.&lt;/p&gt;&lt;lb/&gt;Small precision scissors work best to avoid distorting the aluminum and for making fine cuts.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Trim and balance.&lt;/p&gt;&lt;lb/&gt;Balance the spinner on the pivot wire in your hand. Usually they're lopsided or fall off of their pivot initially, so trim small amounts of material from the outside until they spin well.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Attach pivot wire to lamp&lt;/p&gt;&lt;lb/&gt;Usually I'll just wrap the wire around the lampshade support (apparently this is called a "harp") or sandwich it under the lampshade nut for easy removal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Incandescent bulbs work the best, but even LED bulbs are enough to get the spinners moving after warming up for a few minutes. After a few weeks of spinning, I've noticed the spinners made of thinner sidewall aluminum have very small pinholes from the pivot wire wearing through, but they haven't stopped spinning! The spinners made from can bottoms haven't had this problem yet.&lt;/p&gt;
    &lt;head rend="h1"&gt;Gallery&lt;/head&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://evan.widloski.com/posts/spinners/"/><published>2025-12-24T20:56:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379173</id><title>Keystone (YC S25) is hiring engineer #1 to automate coding</title><updated>2025-12-26T12:20:57.405971+00:00</updated><content>&lt;doc fingerprint="233a92f07e6fe468"&gt;
  &lt;main&gt;
    &lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;
    &lt;p&gt;About Keystone&lt;/p&gt;
    &lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
    &lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
    &lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
    &lt;p&gt;About the Role&lt;/p&gt;
    &lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
    &lt;p&gt;Example projects:&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you:&lt;/p&gt;
    &lt;p&gt;Stack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
    &lt;p&gt;Comp &amp;amp; benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
    &lt;p&gt;To apply: submit an application here on workatastartup.com or email founders [at] withkeystone [dot] com with ‚ÄúKeystone Founding Engineer‚Äù in the subject line. I will reply to all such emails.&lt;/p&gt;
    &lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer"/><published>2025-12-24T21:01:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46384167</id><title>Python 3.15‚Äôs interpreter for Windows x86-64 should hopefully be 15% faster</title><updated>2025-12-26T12:20:57.297182+00:00</updated><content>&lt;doc fingerprint="2e649111fe3785d0"&gt;
  &lt;main&gt;
    &lt;p&gt;24 December 2025&lt;/p&gt;
    &lt;p&gt;Some time ago I posted an apology piece for Python‚Äôs tail calling results. I apologized for communicating performance results without noticing a compiler bug had occured.&lt;/p&gt;
    &lt;p&gt;I can proudly say today that I am partially retracting that apology, but only for two platforms‚ÄîmacOS AArch64 (XCode Clang) and Windows x86-64 (MSVC).&lt;/p&gt;
    &lt;p&gt;In our own experiments, the tail calling interpreter for CPython was found to beat the computed goto interpreter by 5% on pyperformance on AArch64 macOS using XCode Clang, and roughly 15% on pyperformance on Windows on an experimental internal version of MSVC. The Windows build is against a switch-case interpreter, but this in theory shouldn‚Äôt matter too much, more on that in the next section.&lt;/p&gt;
    &lt;p&gt;This is of course, a hopefully accurate result. I tried to be more diligent here, but I am of course not infallible. However, I have found that sharing early and making a fool of myself often works well, as it has led to people catching bugs in my code, so I shall continue doing so :).&lt;/p&gt;
    &lt;p&gt;Also this assumes the change doesn‚Äôt get reverted later in Python 3.15‚Äôs development cycle.&lt;/p&gt;
    &lt;p&gt;Just a recap. There are two popular current ways of writing C-based interpreters.&lt;/p&gt;
    &lt;p&gt;Switch-cases:&lt;/p&gt;
    &lt;code&gt;switch (opcode) {
    case INST_1: ...
    case INST_2: ...
}
&lt;/code&gt;
    &lt;p&gt;Where we just switch-case to the correct instruction handler.&lt;/p&gt;
    &lt;p&gt;And the other popular way is a GCC/Clang extension called labels-as-values/computed gotos.&lt;/p&gt;
    &lt;code&gt;goto *dispatch_table[opcode];
INST_1: ...
INST_2: ...
&lt;/code&gt;
    &lt;p&gt;Which is basically the same idea, but to instead jump to the address of the next label. Traditionally, the key optimization here is that it needs only one jump to go to the next instruction, while in the switch-case interpreter, a naiive compiler would need two jumps.&lt;/p&gt;
    &lt;p&gt;With modern compilers however, the benefits of the computed gotos is a lot less, mainly because modern compilers have gotten better and modern hardware has also gotten better. In Nelson Elhage‚Äôs excellent investigation on the next kind of interpreter, the speedup of computed gotos over switch case on modern Clang was only in the low single digits on pyperformance.&lt;/p&gt;
    &lt;p&gt;A 3rd way that was suggested decades ago, but not really entirely feasible is call/tail-call threaded interpreters. In this scheme, each bytecode handler is its own function, and we tail-call from one handler to the next in the instruction stream:&lt;/p&gt;
    &lt;code&gt;return dispatch_table[opcode];

PyObject *INST_1(...) {

}

PyObject *INST_2(...) {
}
&lt;/code&gt;
    &lt;p&gt;This wasn‚Äôt too feasible in C for one main reason‚Äîtail call optimization was merely an optimization. It‚Äôs something the C compiler might do, or might not do. This means if you‚Äôre unlucky and the C compiler chooses not to perform the tail call, your interpreter might stack overflow!&lt;/p&gt;
    &lt;p&gt;Some time ago, Clang introduced &lt;code&gt;__attribute__((musttail))&lt;/code&gt;, which allowed
for mandating that a call must be tail-called. Otherwise, the compilation
will fail. To my knowledge, the first time this was popularized for use
in a mainstream interpreter was in
Josh Haberman‚Äôs Protobuf blog post.&lt;/p&gt;
    &lt;p&gt;Later on, Haoran Xu noticed that the GHC calling convention combined with tail calls produced efficient code. They used this for their baseline JIT in a paper and termed the technique Copy-and-Patch.&lt;/p&gt;
    &lt;p&gt;After using a fixed XCode Clang, our performance numbers on CPython 3.14/3.15 suggest that the tail calling interpreter does provide a modest speedup over computed gotos. Around the 5% geomean range on pyperformance.&lt;/p&gt;
    &lt;p&gt;To my understanding, &lt;code&gt;uv&lt;/code&gt; already ships Python 3.14 on macOS with tail calling,
which might be responsible for some of the speedups you see on there.
We‚Äôre planning to ship the official 3.15 macOS binaries on &lt;code&gt;python.org&lt;/code&gt; with
tail calling as well.&lt;/p&gt;
    &lt;p&gt;However, you‚Äôre not here for that. The title of this blog post is clearly about MSVC Windows x86-64. So what about that?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[!CAUTION] The features for MSVC discussed below are to my knowledge, experimental. They are not guaranteed to always be around unless the MSVC team decide to keep them. Use at your own risk!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These are the preliminary pyperformance results for CPython on MSVC with tail-calling vs switch-case. Any number above 1.00x is a speedup (e.g. &lt;code&gt;1.01x == 1% speedup&lt;/code&gt;), anything below 1.00x is a slowdown.
The speedup is a geomtric mean of around 15-16%, with a
range of ~60% slowdown (one or two outliers) to 78% speedup.
However, the key thing is that the vast majority of benchmaarks sped up!&lt;/p&gt;
    &lt;p&gt;Chart credits to Michael Droettboom&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[!WARNING] These results are on an experimental internal MSVC compiler, public results below.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To verify this and make sure I wasn‚Äôt wrong yet again, I checked the results on my machine with Visual Studio 2026. These are the results from this issue.&lt;/p&gt;
    &lt;code&gt;Mean +- std dev: [spectralnorm_tc_no] 146 ms +- 1 ms -&amp;gt; [spectralnorm_tc] 98.3 ms +- 1.1 ms: 1.48x faster
Mean +- std dev: [nbody_tc_no] 145 ms +- 2 ms -&amp;gt; [nbody_tc] 107 ms +- 2 ms: 1.35x faster
Mean +- std dev: [bm_django_template_tc_no] 26.9 ms +- 0.5 ms -&amp;gt; [bm_django_template_tc] 22.8 ms +- 0.4 ms: 1.18x faster
Mean +- std dev: [xdsl_tc_no] 64.2 ms +- 1.6 ms -&amp;gt; [xdsl_tc] 56.1 ms +- 1.5 ms: 1.14x faster
&lt;/code&gt;
    &lt;p&gt;So yeah, the speedups are real! For a large-ish library like xDSL, we see a 14% speedup, while for smaller microbenchmarks like nbody and spectralnorm, the speedups are greater.&lt;/p&gt;
    &lt;p&gt;Thanks to Chris Eibl and Brandt Bucher, we managed to get the PR for this on MSVC over the finish line. I also want to sincerely thank the MSVC team. I can‚Äôt say this enough: they have been a joy to work with and I‚Äôm very impressed by what they‚Äôve done, and I want to congratulate them on releasing Visual Studio 2026.&lt;/p&gt;
    &lt;p&gt;This is now listed in the What‚Äôs New for 3.15 notes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Builds using Visual Studio 2026 (MSVC 18) may now use the new tail-calling interpreter. Results on an early experimental MSVC compiler reported roughly 15% speedup on the geometric mean of pyperformance on Windows x86-64 over the switch-case interpreter. We have observed speedups ranging from 15% for large pure-Python libraries to 40% for long-running small pure-Python scripts on Windows. (Contributed by Chris Eibl, Ken Jin, and Brandt Bucher in gh-143068. Special thanks to the MSVC team including Hulon Jenkins.)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the documentation for [[msvc::musttail]].&lt;/p&gt;
    &lt;p&gt;I used to believe the the tail calling interpreters get their speedup from better register use. While I still believe that now, I suspect that is not the main reason for speedups in CPython.&lt;/p&gt;
    &lt;p&gt;My main guess now is that tail calling resets compiler heuristics to sane levels, so that compilers can do their jobs.&lt;/p&gt;
    &lt;p&gt;Let me show an example, at the time of writing, CPython 3.15‚Äôs interpreter loop is around 12k lines of C code. That‚Äôs 12k lines in a single function for the switch-case and computed goto interpreter.&lt;/p&gt;
    &lt;p&gt;This has caused many issues for compilers in the past, too many to list in fact. I have a EuroPython 2025 talk about this. In short, this overly large function breaks a lot of compiler heuristics.&lt;/p&gt;
    &lt;p&gt;One of the most beneficial optimisations is inlining. In the past, we‚Äôve found that compilers sometimes straight up refuse to inline even the simplest of functions in that 12k loc eval loop. I want to stress that this is not the fault of the compiler. It‚Äôs actually doing the correct thing‚Äîyou usually don‚Äôt want to increase the code size of something already super large. Unfortunately, this does‚Äôt bode well for our interpreter.&lt;/p&gt;
    &lt;p&gt;You might say just write the interpreter in assembly! However, the whole point of this exercise is to not do that.&lt;/p&gt;
    &lt;p&gt;Ok enough talk, let‚Äôs take a look at the code now. Taking a real example, we examine &lt;code&gt;BINARY_OP_ADD_INT&lt;/code&gt; which adds two Python integers.
Cleaning up the code so it‚Äôs readable, things look like this:&lt;/p&gt;
    &lt;code&gt;TARGET(BINARY_OP_ADD_INT) {
    // Increment the instruction pointer.
    _Py_CODEUNIT* const this_instr = next_instr;
    frame-&amp;gt;instr_ptr = next_instr;
    next_instr += 6;
    _PyStackRef right = stack_pointer[-1];

    // Check that LHS is an int.
    PyObject *value_o = PyStackRef_AsPyObjectBorrow(left);
    if (!_PyLong_CheckExactAndCompact(value_o)) {
        JUMP_TO_PREDICTED(BINARY_OP);
    }

    // Check that RHS is an int.
    // ... (same code as above for LHS)

    // Add them together.
    PyObject *left_o = PyStackRef_AsPyObjectBorrow(left);
    PyObject *right_o = PyStackRef_AsPyObjectBorrow(right);
    res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);

    // If the addition fails, fall back to the generic instruction.
    if (PyStackRef_IsNull(res)) {
        JUMP_TO_PREDICTED(BINARY_OP);
    }

    // Close the references.
    PyStackRef_CLOSE_SPECIALIZED(left, _PyLong_ExactDealloc);
    PyStackRef_CLOSE_SPECIALIZED(right, _PyLong_ExactDealloc);

    // Write to the stack, and dispatch.
    stack_pointer[-2] = res;
    stack_pointer += -1;
    DISPATCH();
}
&lt;/code&gt;
    &lt;p&gt;Seems simple enough, let‚Äôs take a look at the assembly for switch-case on VS 2026. Note again, this is a non-PGO build for easy source information, PGO generally makes some of these problems go away, but not all of them:&lt;/p&gt;
    &lt;code&gt;                if (!_PyLong_CheckExactAndCompact(value_o)) {
00007FFC4DE24DCE  mov         rcx,rbx  
00007FFC4DE24DD1  mov         qword ptr [rsp+58h],rax  
00007FFC4DE24DD6  call        _PyLong_CheckExactAndCompact (07FFC4DE227F0h)  
00007FFC4DE24DDB  test        eax,eax  
00007FFC4DE24DDD  je          _PyEval_EvalFrameDefault+10EFh (07FFC4DE258FFh)
...
                res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);
00007FFC4DE24DFF  mov         rdx,rbx  
00007FFC4DE24E02  mov         rcx,r15  
00007FFC4DE24E05  call        _PyCompactLong_Add (07FFC4DD34150h)  
00007FFC4DE24E0A  mov         rbx,rax  
...
                PyStackRef_CLOSE_SPECIALIZED(value, _PyLong_ExactDealloc);
00007FFC4DE24E17  lea         rdx,[_PyLong_ExactDealloc (07FFC4DD33BD0h)]  
00007FFC4DE24E1E  mov         rcx,rsi  
00007FFC4DE24E21  call        PyStackRef_CLOSE_SPECIALIZED (07FFC4DE222A0h) 
&lt;/code&gt;
    &lt;p&gt;Huh‚Ä¶ all our functions were not inlined. Surely that must‚Äôve mean they were too big or something right? Let‚Äôs look at &lt;code&gt;PyStackReF_CLOSE_SPECIALIZED&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;static inline void
PyStackRef_CLOSE_SPECIALIZED(_PyStackRef ref, destructor destruct)
{
    assert(!PyStackRef_IsNull(ref));
    if (PyStackRef_RefcountOnObject(ref)) {
        Py_DECREF_MORTAL_SPECIALIZED(BITS_TO_PTR(ref), destruct);
    }
}
&lt;/code&gt;
    &lt;p&gt;That looks ‚Ä¶ inlineable?&lt;/p&gt;
    &lt;p&gt;Here‚Äôs how &lt;code&gt;BINARY_OP_ADD_INT&lt;/code&gt; looks with tail calling on VS 2026 (again,
no PGO):&lt;/p&gt;
    &lt;code&gt;                if (!_PyLong_CheckExactAndCompact(left_o)) {
00007FFC67164785  cmp         qword ptr [rax+8],rdx  
00007FFC67164789  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+149h (07FFC67164879h)  
00007FFC6716478F  mov         r9,qword ptr [rax+10h]  
00007FFC67164793  cmp         r9,10h  
00007FFC67164797  jae         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+149h (07FFC67164879h) 
...
                res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);
00007FFC6716479D  mov         eax,dword ptr [rax+18h]  
00007FFC671647A0  and         r9d,3  
00007FFC671647A4  and         r8d,3  
00007FFC671647A8  mov         edx,1  
00007FFC671647AD  sub         rdx,r9  
00007FFC671647B0  mov         ecx,1  
00007FFC671647B5  imul        rdx,rax  
00007FFC671647B9  mov         eax,dword ptr [rbx+18h]  
00007FFC671647BC  sub         rcx,r8  
00007FFC671647BF  imul        rcx,rax  
00007FFC671647C3  add         rcx,rdx  
00007FFC671647C6  call        medium_from_stwodigits (07FFC6706E9E0h)  
00007FFC671647CB  mov         rbx,rax  
...
                PyStackRef_CLOSE_SPECIALIZED(value, _PyLong_ExactDealloc);
00007FFC671647EB  test        bpl,1  
00007FFC671647EF  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0ECh (07FFC6716481Ch)  
00007FFC671647F1  add         dword ptr [rbp],0FFFFFFFFh  
00007FFC671647F5  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0ECh (07FFC6716481Ch)  
00007FFC671647F7  mov         rax,qword ptr [_PyRuntime+25F8h (07FFC675C45F8h)]  
00007FFC671647FE  test        rax,rax  
00007FFC67164801  je          _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0E4h (07FFC67164814h)  
00007FFC67164803  mov         r8,qword ptr [_PyRuntime+2600h (07FFC675C4600h)]  
00007FFC6716480A  mov         edx,1  
00007FFC6716480F  mov         rcx,rbp  
00007FFC67164812  call        rax  
00007FFC67164814  mov         rcx,rbp  
00007FFC67164817  call        _PyLong_ExactDealloc (07FFC67073DA0h) 
&lt;/code&gt;
    &lt;p&gt;Would you look at that, suddenly our trivial functions get inlined :).&lt;/p&gt;
    &lt;p&gt;You might also say, surely this does not happen on PGO builds? Well the issue I linked above actually says it does! So yeah happy days.&lt;/p&gt;
    &lt;p&gt;Once again I want to stress, this is not the compiler‚Äôs fault! It‚Äôs just that the CPython interpreter loop is not the best thing to optimize.&lt;/p&gt;
    &lt;p&gt;Unfortunately, for now, you will have to build from source.&lt;/p&gt;
    &lt;p&gt;With VS 2026, after cloning CPython, for a release build with PGO:&lt;/p&gt;
    &lt;code&gt;$env:PlatformToolset = "v145"
./PCbuild/build.bat --tail-call-interp -c Release -p x64 --pgo
&lt;/code&gt;
    &lt;p&gt;Hopefully, we can distribute this in an easier binary form in the future once Python 3.15‚Äôs development matures!&lt;/p&gt;
    &lt;p&gt;I was asked for a cross-compiler test. So here‚Äôs a quick and dirty toy benchmark of pystones. The last row is the tail call enabled build. All configurations have PGO. On this toy benchmark, we get roughly a 30% uplift. Note that this is unscientific as it was only a sample size of 1 and I cannot disable Turbo Boost on my laptop on Windows for some reason.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Compiler&lt;/cell&gt;
        &lt;cell role="head"&gt;PlatformToolSet&lt;/cell&gt;
        &lt;cell role="head"&gt;Pystones/second (higher is better)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;VS2019&lt;/cell&gt;
        &lt;cell&gt;142&lt;/cell&gt;
        &lt;cell&gt;677544&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;VS2022&lt;/cell&gt;
        &lt;cell&gt;143&lt;/cell&gt;
        &lt;cell&gt;710773&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;VS2026&lt;/cell&gt;
        &lt;cell&gt;145&lt;/cell&gt;
        &lt;cell&gt;682089&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;VS2026+TC&lt;/cell&gt;
        &lt;cell&gt;145&lt;/cell&gt;
        &lt;cell&gt;970306&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fidget-spinner.github.io/posts/no-longer-sorry.html"/><published>2025-12-25T13:02:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46384565</id><title>Asahi Linux with Sway on the MacBook Air M2 (2024)</title><updated>2025-12-26T12:20:57.083686+00:00</updated><content>&lt;doc fingerprint="a66d905b53c3bbc7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Asahi Linux with Sway on the MacBook Air M2&lt;/head&gt;
    &lt;p&gt;2024-12-01&lt;/p&gt;
    &lt;p&gt;I bought a MacBook Air M2. As of writing, it‚Äôs very affordable with the 16 GB RAM, 256 GB SSD, 13.6‚Äù model available for $750. As of writing, also Asahi Linux doesn‚Äôt support anything newer than M2.&lt;/p&gt;
    &lt;p&gt;I had previously used:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;2011-2015: MacBook Air 13.3‚Äù with Intel Core i5 1.8 GHz, 8 GB of RAM, and 256 GB SSD (aftermarket upgrade from OWC). I installed Arch Linux on it with the i3 window manager.&lt;/item&gt;
      &lt;item&gt;2014-2018: Dell XPS 13 Developer Edition. I used the Ubuntu 14.04 that came with it with the i3 window manager.&lt;/item&gt;
      &lt;item&gt;2018-2024: Lenovo Thinkpad X1 Carbon Gen 6 with Intel Core i7 8640U, 16 GB of RAM, and 1 TB SSD. I installed Arch Linux on it with Sway.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;1 Installing Asahi Linux&lt;/head&gt;
    &lt;p&gt;On the Asahi Linux there‚Äôs a one liner which you can paste into the Terminal. It worked very well. The only complaint is that it seemed to take hours to copy root.img and boot.img over at 150 KB/s.&lt;/p&gt;
    &lt;p&gt;Since I intended to run it with the Sway Window Manager, and storage space is precious, I installed Fedora minimal.&lt;/p&gt;
    &lt;head rend="h1"&gt;2 Getting set up&lt;/head&gt;
    &lt;p&gt;I connected to wifi with&lt;/p&gt;
    &lt;quote&gt;nmcli device wifi list nmcli device wifi connect 'my_ssid' password 'mypassword'&lt;/quote&gt;
    &lt;p&gt;and then I installed a bunch of packages I use, such as:&lt;/p&gt;
    &lt;quote&gt;sudo dnf install @sway-desktop-environment fish alacritty rofi ruff rclone pavucontrol-qt i3status mako pass syncthing maim xdg-user-dirs firefox rustup openssl-devel ncdu fd-find neovim&lt;/quote&gt;
    &lt;p&gt;Then, I cloned my personal dotfile git repo and ran &lt;code&gt;setup.sh&lt;/code&gt;.
Of course, my configs weren‚Äôt meant for the MacBook, so I had to make some changes (which I‚Äôve pushed to the dotfiles).&lt;/p&gt;
    &lt;head rend="h1"&gt;3 Customizing for MacBook&lt;/head&gt;
    &lt;p&gt;By default, the whole row containing the notch is disabled, leading to a large-bezels look which I personally don‚Äôt like. There has got to be a way to use that screen real estate nicely!&lt;/p&gt;
    &lt;p&gt;I re-enabled that part of the screen with&lt;/p&gt;
    &lt;quote&gt;grubby --args=apple_dcp.show_notch=1 --update-kernel=ALL&lt;/quote&gt;
    &lt;p&gt;Then, I put the Sway bar on the top to make a seamless appearance where the left and right side are used for useful information but the middle part is all black. By experimentation I found that the notch is 56px tall.&lt;/p&gt;
    &lt;quote&gt;bar { position top status_command i3status modifier $mod tray_output primary # the height of the m2 macbook air's notch??? height 56 colors { background #000000 statusline #cfcfd9 separator #000000 # border background text focused_workspace #0c0c0c #413459 #cfcfd9 active_workspace #0c0c0c #413459 #cfcfd9 inactive_workspace #0c0c0c #0c0c0c #cfcfd9 urgent_workspace #2f343a #ff3300 #ffffff } }&lt;/quote&gt;
    &lt;p&gt;The full &lt;code&gt;i3status&lt;/code&gt; shows a lot of information which might get occluded by the notch, and it doesn‚Äôt work with the MacBook battery levels by default, so I had to update the config:&lt;/p&gt;
    &lt;quote&gt;general { colors = true interval = 5 } order += "wireless _first_" order += "ethernet _first_" order += "battery 0" order += "tztime local" wireless _first_ { format_up = "W: (%quality at %essid) %ip" format_down = "W: down" } ethernet _first_ { format_up = "E: %ip (%speed)" format_down = "E: down" } battery 0 { format = "%status %percentage" hide_seconds = true path = /sys/class/power_supply/macsmc-battery/uevent } tztime local { format = "%Y-%m-%d %H:%M:%S" }&lt;/quote&gt;
    &lt;p&gt;I usually don‚Äôt like having the bar on the top (as with macOS), since you won‚Äôt be able to move your mouse cursor to the top edge to, say, click on tabs. Despite being mostly keyboard-driven, clicking on browser tabs with the mouse is something I still do often.&lt;/p&gt;
    &lt;p&gt;To fix that, I prevented the mouse cursor from entering the bar on the top, with&lt;/p&gt;
    &lt;quote&gt;# use swaymsg -t get_inputs for the touchpad's identifier input 1452:849:Apple_MTP_multi-touch map_to_region 0 56 2560 1608&lt;/quote&gt;
    &lt;head rend="h2"&gt;3.1 Using Waybar instead&lt;/head&gt;
    &lt;p&gt;In around September 2025, I switched from the native Swaybar to Waybar. Somehow, I was running into some issues with &lt;code&gt;swaymsg&lt;/code&gt;‚Äòs handling of battery levels, and my computer ricing was due for a slight visual update anyway.
It‚Äôs nice to save a tiny bit of screen real estate with icons instead of pure text, but of course, it is somewhat slower than Swaybar as it needs to render graphical stuff.
The Waybar is still situated behind the notch.&lt;/p&gt;
    &lt;p&gt;The new waybar config and css are at waybarconfig and waybarstyle.&lt;/p&gt;
    &lt;head rend="h1"&gt;4 Using it as a daily driver&lt;/head&gt;
    &lt;p&gt;I am very impressed with how smooth and problem-free Asahi Linux is. It is incredibly responsive and feels even smoother than my Arch Linux desktop with a 16 core AMD Ryzen 7945HX and 64GB of RAM.&lt;/p&gt;
    &lt;p&gt;The touchpad in particular is stunningly good and just as good as native macOS. The mouse cursor movement and two finger scroll with inertia just feel incredibly natural, much better than my old Thinkpad X1 Carbon.&lt;/p&gt;
    &lt;p&gt;One of the main reasons for getting the laptop was to use it for line scan photography. I was able to install the Alkeria SDK for ARM64 without any issues, even though it came as a deb file instead of an rpm. I didn‚Äôt manage to get &lt;code&gt;alien&lt;/code&gt; to work properly (something about the architecture arm64 not matching Fedora‚Äôs convention of calling it aarch64?) so I just used bsdtar to extract the contents into the filesystem root, yolo!!!
The M2 compiles my code super fast!&lt;/p&gt;
    &lt;p&gt;With high screen brightness and compiling lots of code, my battery went down from 100% to 60% after about 4.5 hours of use ‚Äî not as good as the 15 hours of battery life on macOS but still pretty respectable.&lt;/p&gt;
    &lt;p&gt;That said, it isn‚Äôt perfect. Common issues are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;higher battery drainage during sleep, so I usually just shut it down entirely when not using it&lt;/item&gt;
      &lt;item&gt;no hardware acceleration for video decoding&lt;/item&gt;
      &lt;item&gt;some USB port quirks and external display quirks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Still, fairly decent overall.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://daniel.lawrence.lu/blog/2024-12-01-asahi-linux-with-sway-on-the-macbook-air-m2/"/><published>2025-12-25T14:20:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46385197</id><title>Ask HN: What skills do you want to develop or improve in 2026?</title><updated>2025-12-26T12:20:56.468915+00:00</updated><content>&lt;doc fingerprint="8d0e79d19538fd8c"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Thread for 2025: &lt;/p&gt;https://news.ycombinator.com/item?id=42509408&lt;p&gt;Thread for 2024: https://news.ycombinator.com/item?id=38782613&lt;/p&gt;&lt;p&gt;Thread for 2023: https://news.ycombinator.com/item?id=33873800&lt;/p&gt;&lt;p&gt;Here are mine:&lt;/p&gt;&lt;p&gt;Technical skills:&lt;/p&gt;&lt;p&gt;- Among my last year's goals was to take on VR dev, which sadly I did not get to. Punting it to 2026. I'm thinking to get the Samsung Galaxy XR and experiment with some VR apps and learn the fundamentals of spatial computing. As an Android mobile developer, that feels like a natural extension.&lt;/p&gt;&lt;p&gt;- Complete the "UCSanDiegoX: Computer Graphics II: Rendering" computer graphics course. I did the first course in the series and found it enlightening (no pun intended)&lt;/p&gt;&lt;p&gt;- Create an e2e project that earns money as a side gig. It's time to put my product and technical knowledge to practice and actually build something people want.&lt;/p&gt;&lt;p&gt;- Leverage AI across all my endeavors. AI tools are here to stay and the more I know how to use them effectively, the better. The speed boost in learning a new framework/concept is phenomenal.&lt;/p&gt;&lt;p&gt;Non-technical skills:&lt;/p&gt;&lt;p&gt;- Expand my social circle - the unstable tech climate made me realize the importance of maintaining a healthy social network. My goal is to connect with more people both inside my company and outside, by both proactively reaching out and going to meetups in my area. In fact, I invite fellow NYC-based HN-ers to contact me at cybercreampuff at yahoo dot com, in case you want to meet up!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46385197"/><published>2025-12-25T16:08:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46385308</id><title>I sell onions on the Internet (2019)</title><updated>2025-12-26T12:20:56.009843+00:00</updated><content>&lt;doc fingerprint="3d51a9711ab1a3d5"&gt;
  &lt;main&gt;&lt;p&gt;They‚Äôre classified as a sweet onion, and because of their mild flavor (they don‚Äôt make your eyes tear up), some folks can eat them like an apple. Most of my customers do.&lt;/p&gt;&lt;p&gt;During a phone order one season ‚Äì 2018 I believe ‚Äì a customer shared this story where he smuggled some Vidalias onto his vacation cruise ship, and during each meal, would instruct the server to ‚Äòtake this onion to the back, chop it up, and add it onto my salad ‚Äò. That story made me smile.&lt;/p&gt;&lt;p&gt;Folks who love Vidalias, love Vidalias.&lt;/p&gt;&lt;p&gt;Let me stop, though. I don‚Äôt want to get ahead of myself.&lt;/p&gt;&lt;p&gt;How did all this start? I‚Äôm a web guy. I‚Äôm not a farmer.&lt;/p&gt;&lt;head rend="h2"&gt;I‚ÄôM ADDICTED TO DOMAIN NAMES&lt;/head&gt;&lt;p&gt;Oddly enough, it didn‚Äôt start with an idea.&lt;/p&gt;&lt;p&gt;Back in 2014, the domain name VidaliaOnions.com expired, and went up for auction. For some reason the original owner abandoned it, and being a Georgia native, I recognized it ‚Äôcause I was familiar with the industry. I‚Äôve been buying expired or abandoned domain names for a while, and enjoy developing them into niche businesses. This one was different though ‚Äì I backordered the domain as a spectator, but for kicks &amp;amp; giggles, I dropped in a bid around $2,200 ‚Äôcause I was confident I‚Äôd be outbid.&lt;/p&gt;&lt;p&gt;5 minutes later, I was the proud owner of VidaliaOnions.com. I had no idea what to do with it. Ready, fire, aim.&lt;/p&gt;&lt;p&gt;After the domain landed in my account, I attempted to re-focus my attention on other projects, but the name kept clawing me. Like it was saying:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;‚Ä¶ yoo-hoo‚Ä¶ over here‚Ä¶ üòò&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;William Faulkner had an interesting perspective on writing his characters ‚Äì on how they essentially wrote themselves, and how he (Faulkner) served as a sortof mechanical in-between. His quote:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I would say to get the character in your mind. Once he is in your mind, and he is right, and he‚Äôs true, then he does the work himself. All you need to do then is to trot along behind him and put down what he does and what he says‚Ä¶ You‚Äôve got to know the character. You‚Äôve got to believe in him. You‚Äôve got to feel that he is alive‚Ä¶ After that, the business of putting him down on paper is mechanical. [source]&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;The way Faulkner treats his characters, I treat domain name projects. I buy them with an intention to develop. And I let them take the lead. They‚Äôre the inspiration for the business itself. They guide me towards what they need to become. I‚Äôm just the dude behind the keyboard (sorta).&lt;/p&gt;&lt;p&gt;Sometimes I buy them at auction, sometimes I buy them from original-owners. But universally, the domain name always comes first, the business idea comes second.&lt;/p&gt;&lt;p&gt;I don‚Äôt usually rush into development. The path of some domains is apparent before I acquire. Others, the path reveals itself down the road. Vidalia was the latter. And after I acquired it, it kept nudging me.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Build me‚Ä¶ build me‚Ä¶ you know how. And you know what I should be‚Ä¶&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;After a month, I began to understand what it was telling me. That I buy pears from Harry &amp;amp; David every year, and I should mimic that same service for Vidalia Onions. Instead of farm-to-door pears, farm-to-door Vidalia Onions.&lt;/p&gt;&lt;p&gt;An interesting idea, but daunting to approach. I‚Äôm not a farmer, I don‚Äôt have employees, I don‚Äôt have a packing shed. And I have no logistics or distribution system setup.&lt;/p&gt;&lt;p&gt;But the domain name kept staring at me. ‡≤†~‡≤† ////whispering////&lt;/p&gt;&lt;quote&gt;&lt;p&gt;‚Ä¶ just start ‚Ä¶&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h2"&gt;‚Äútake the path to Nothing, and go Nowhere until you reach it.‚Äù&lt;/head&gt;-the tao of pooh&lt;p&gt;‚Ä¶&lt;/p&gt;&lt;p&gt;And so I did. I‚Äôm just dumb enough to try a project of this complexity. The market size justified an online venture. Google Trends showed strong search volume for the phrase. And chefs around the world had already belted their praise over the ‚Äòcaviar of sweet onions‚Äô.&lt;/p&gt;&lt;p&gt;So I just started down a path, with no end goal or milestone set. I just started going. No angel investor. No VC backer. I just used some modest profit from my other domain name developments to fund the endeavor. This was Feb of 2015.&lt;/p&gt;&lt;p&gt;Once I began, I discovered there was a Vidalia Onion committee which represents all the Vidalia farmers. So I reached out to them.&lt;/p&gt;&lt;p&gt;They were kind enough to listen to me.&lt;/p&gt;&lt;p&gt;They introduced me to several farmers in the Vidalia region.&lt;/p&gt;&lt;p&gt;I got along quite well with the 3rd farmer I met (Aries Haygood), so we decided to partner &amp;amp; give this a shot. His farm had been around for 25 years; they hadn‚Äôt focused on direct-to-consumer; but they understood its value. They operated a packing shed as well. And most importantly, they grew an award winning Vidalia.&lt;/p&gt;&lt;p&gt;And so we went.&lt;/p&gt;&lt;p&gt;We conservatively estimated fifty (50) orders for our 2015 season. We ended up with over six hundred (600).&lt;/p&gt;&lt;p&gt;While the farm concentrated on the Vidalia, I concentrated on customer service, marketing, branding, web development, &amp;amp; logistics. I didn‚Äôt have other projects that were this front-facing, customer wise. And I discovered I immensely enjoyed it.&lt;/p&gt;&lt;p&gt;The more we both focused on these efforts, the more we grew. So much so, that other Vidalia operations began shutting down their mail order efforts and simply directed folks our way.&lt;/p&gt;&lt;p&gt;We began testing alternate marketing avenues ‚Äì a billboard on I-95 just south of Savannah, GA facing northbound traffic; sponsoring a bike rider headed cross country for charity; sponsoring a high school basketball team, as well as a grade school auction fundraiser.&lt;/p&gt;&lt;p&gt;We added a phone order hotline, which ‚Äì from time to time ‚Äì generates more sales than online.&lt;/p&gt;&lt;p&gt;We also made a few colossal mistakes, which were entirely of my doing, like blowing $10,000 on faulty shipping boxes from an ill-informed &amp;amp; misleading box manufacturer in Dalton, GA. (it happened early in our journey, and nearly forced me to shut down)&lt;/p&gt;&lt;p&gt;Ultimately, I refused to let something like that kill this. Honestly, my customers would be quite upset if we disappeared. Last season, while I called a gentleman back regarding a phone order, his wife answered. While I introduced myself, she interrupted me mid-sentence and hollered in exaltation to her husband: ‚Äù THE VIDALIA MAN! THE VIDALIA MAN! PICK UP THE PHONE! ‚Äù&lt;/p&gt;&lt;p&gt;At that moment, I realized we were doing something right. Something helpful. Something that was making a positive impact.&lt;/p&gt;&lt;p&gt;I sometimes say I prefer projects that focus on purpose over profit. And as we enter our 5th season, this one continues to do just that.&lt;/p&gt;&lt;p&gt;And it‚Äôs immensely gratifying. I feel so fortunate to be associated with this industry.&lt;/p&gt;&lt;p&gt;I‚Äôm Peter Askew, and I sell onions on the internet.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Them: We leverage automated machine learning to enhance your existing BI visualizations with more proactive insights&lt;/p&gt;&lt;p&gt;Me: I sell onions on the internet&lt;/p&gt;&lt;p&gt;‚Äî Peter Askew (@searchbound) June 13, 2018&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;** below ‚Äì from the field during harvest ‚Äì these have been dug &amp;amp; are ready for clipping&lt;lb/&gt; ( click &amp;amp; drag )&lt;/p&gt;&lt;p&gt;Follow me on Twitter as I continue to document my journey there. Or get an email when I post new stuff (below):&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.deepsouthventures.com/i-sell-onions-on-the-internet/"/><published>2025-12-25T16:24:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46385600</id><title>Clearspace (YC W23) Is Hiring a Founding Network Engineer (VPN and Proxy)</title><updated>2025-12-26T12:20:55.223624+00:00</updated><content>&lt;doc fingerprint="b792f12e5d21eddd"&gt;
  &lt;main&gt;
    &lt;p&gt;Eliminate compulsive phone usage&lt;/p&gt;
    &lt;p&gt;About Clearspace&lt;/p&gt;
    &lt;p&gt;Clearspace is building the intentionality layer of the internet. Our mission is to build technology as effective at protecting human attention as social media is at exploiting it (infinite scrolling, short-form feeds, manipulative notifications, etc). Our category defining mobile app has been featured on Huberman Lab, New York Times Wirecutter, NPR Marketplace, Forbes, TBPN.&lt;/p&gt;
    &lt;p&gt;People that want a better relationship with their devices have nowhere to turn except for willpower. We are building a system allows users to control what their devices see by processing and filtering network traffic against natural language rules.&lt;/p&gt;
    &lt;p&gt;About The Role&lt;/p&gt;
    &lt;p&gt;We‚Äôre looking for a networking-obsessed engineer to own the VPN + first-hop policy proxy that powers our AI agent. You don‚Äôt need to be an IKEv2 expert, we care more about deep networking intuition, debugging skill, and the desire to go all the way down the stack until the truth reveals itself.&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you‚Äôve built:&lt;/p&gt;
    &lt;p&gt;What You‚Äôll Build&lt;/p&gt;
    &lt;p&gt;Qualifications&lt;/p&gt;
    &lt;p&gt;Nice to Have&lt;/p&gt;
    &lt;p&gt;Compensation&lt;/p&gt;
    &lt;p&gt;At Clearspace we help people reduce compulsive phone usage.&lt;/p&gt;
    &lt;p&gt;We exist to protect people's attention from the exploits of modern technology platforms and make space for the things that matter to them most.&lt;/p&gt;
    &lt;p&gt;We believe the technology to protect someones attention should be just as sophisticated and effective as the tech that is exploiting it and are building a world-class engineering team to arm the world with a comprehensive attention protection stack.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/clearspace/jobs/5LtM86I-founding-network-engineer-at-clearspace"/><published>2025-12-25T17:01:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46386211</id><title>Fahrplan ‚Äì 39C3</title><updated>2025-12-26T12:20:53.377945+00:00</updated><content>&lt;doc fingerprint="ad728d1d22b2a7ef"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Sat - Day 1 - December 27&lt;/head&gt;
    &lt;head rend="h5"&gt;Opening Ceremony&lt;/head&gt;
    &lt;p&gt;pajowu, Stella&lt;/p&gt;
    &lt;head rend="h5"&gt;All Sorted by Machines of Loving Grace? "AI", Cybernetics, and Fascism and how to Intervene&lt;/head&gt;
    &lt;p&gt;Katika K√ºhnreich&lt;/p&gt;
    &lt;head rend="h5"&gt;The art of text (rendering)&lt;/head&gt;
    &lt;p&gt;Nicolas Rougier&lt;/p&gt;
    &lt;head rend="h5"&gt;A Tale of Two Leaks: How Hackers Breached the Great Firewall of China&lt;/head&gt;
    &lt;p&gt;Jade Sheffey&lt;/p&gt;
    &lt;head rend="h5"&gt;OpenAutoLab: photographic film processing machine. Fully automatic and DIY-friendly.&lt;/head&gt;
    &lt;p&gt;Kauz&lt;/p&gt;
    &lt;head rend="h5"&gt;Zentrum f√ºr Politische Sch√∂nheit: Ein Jahr Adenauer SRP+ und der Walter L√ºbke Memorial Park&lt;/head&gt;
    &lt;p&gt;Stefan Pelzer, Philipp Ruch&lt;/p&gt;
    &lt;head rend="h5"&gt;Demystifying Fuzzer Behaviour&lt;/head&gt;
    &lt;p&gt;Addison&lt;/p&gt;
    &lt;head rend="h5"&gt;ISDN + POTS Telephony at Congress and Camp&lt;/head&gt;
    &lt;p&gt;Harald "LaF0rge" Welte&lt;/p&gt;
    &lt;head rend="h5"&gt;Brennende W√§lder und Kommentarspalten - Klimaupdate mit dem FragDenStaat Climate Helpdesk&lt;/head&gt;
    &lt;p&gt;Joschi Wolf&lt;/p&gt;
    &lt;head rend="h5"&gt;Building hardware - easier than ever - harder than it should be&lt;/head&gt;
    &lt;p&gt;Kliment&lt;/p&gt;
    &lt;head rend="h5"&gt;Neuroexploitation by Design: Wie Algorithmen in Gl√ºcksspielprodukten sich Wirkweisen des Reinforcement Learning und dopaminergen Belohnungssystems zunutze machen&lt;/head&gt;
    &lt;p&gt;Elke Smith&lt;/p&gt;
    &lt;head rend="h5"&gt;FeTAp 611 unplugged: Taking a rotary dial phone to the mobile age&lt;/head&gt;
    &lt;p&gt;Michael Weiner&lt;/p&gt;
    &lt;head rend="h5"&gt;Who cares about the Baltic Jammer? ‚Äì Terrestrial Navigation in the Baltic Sea Region&lt;/head&gt;
    &lt;p&gt;Lars, Niklas Hehenkamp, Markus&lt;/p&gt;
    &lt;head rend="h5"&gt;Liberating Bluetooth on the ESP32&lt;/head&gt;
    &lt;p&gt;Antonio V√°zquez Blanco (Ant√≥n)&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaos macht K√ºche&lt;/head&gt;
    &lt;p&gt;Ingwer Andersen&lt;/p&gt;
    &lt;head rend="h5"&gt;Developing New Medicines in the Age of AI and Personalized Medicine&lt;/head&gt;
    &lt;p&gt;Dennis √ñzcelik&lt;/p&gt;
    &lt;head rend="h5"&gt;Endlich maschinenlesbare Urteile! Open access f√ºr Juristen&lt;/head&gt;
    &lt;p&gt;Beata Hubrig, Nuri Khadem-Al-Charieh&lt;/p&gt;
    &lt;head rend="h5"&gt;Opening pAMDora's box and unleashing a thousand paths on the journey to play Beatsaber custom songs&lt;/head&gt;
    &lt;p&gt;tihmstar&lt;/p&gt;
    &lt;head rend="h5"&gt;Not an Impasse: Child Safety, Privacy, and Healing Together&lt;/head&gt;
    &lt;p&gt;Kate Sim&lt;/p&gt;
    &lt;head rend="h5"&gt;KIM 1.5: Noch mehr Kaos In der Medizinischen Telematikinfrastruktur (TI)&lt;/head&gt;
    &lt;p&gt;Christoph Saatjohann&lt;/p&gt;
    &lt;head rend="h5"&gt;RedScout42 ‚Äì Zur digitalen Wohnungsfrage&lt;/head&gt;
    &lt;p&gt;Sandra, Leonard&lt;/p&gt;
    &lt;head rend="h5"&gt;All my Deutschlandtickets gone: Fraud at an industrial scale&lt;/head&gt;
    &lt;p&gt;Q Misell, 551724 / maya boeckh&lt;/p&gt;
    &lt;head rend="h5"&gt;Of Boot Vectors and Double Glitches: Bypassing RP2350's Secure Boot&lt;/head&gt;
    &lt;p&gt;stacksmashing, nsr&lt;/p&gt;
    &lt;head rend="h5"&gt;‚ÄûKI‚Äú, Digitalisierung und Longevity als Fix f√ºr ein kaputtes Gesundheitssystem?&lt;/head&gt;
    &lt;p&gt;Manuel Hofmann&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaos all year round&lt;/head&gt;
    &lt;p&gt;Deanna&lt;/p&gt;
    &lt;head rend="h5"&gt;To sign or not to sign: Practical vulnerabilities in GPG &amp;amp; friends&lt;/head&gt;
    &lt;p&gt;49016, Liam&lt;/p&gt;
    &lt;head rend="h5"&gt;Handy weg bis zur Ausreise ‚Äì Wie Cellebrite ins Ausl√§nderamt kam&lt;/head&gt;
    &lt;p&gt;Chris K√∂ver&lt;/p&gt;
    &lt;head rend="h5"&gt;Pwn2Roll: Who Needs a 595‚Ç¨ Remote When You Have wheelchair.py?&lt;/head&gt;
    &lt;p&gt;elfy&lt;/p&gt;
    &lt;head rend="h5"&gt;Escaping Containment: A Security Analysis of FreeBSD Jails&lt;/head&gt;
    &lt;p&gt;ilja, Michael Smith&lt;/p&gt;
    &lt;head rend="h5"&gt;Die K√§nguru-Rebellion: Digital Independence Day&lt;/head&gt;
    &lt;p&gt;Marc-Uwe Kling, Linus Neumann&lt;/p&gt;
    &lt;head rend="h5"&gt;And so it begins - Wie unser Rechtsstaat auf dem Highway Richtung Trumpismus rast ‚Äì und warum afghanische Kl√§ger*innen f√ºr uns die Notbremse ziehen&lt;/head&gt;
    &lt;p&gt;Eva, Elaha&lt;/p&gt;
    &lt;head rend="h5"&gt;1965 + 60 Years of Algorithmic Art with Computers&lt;/head&gt;
    &lt;p&gt;Enna Gerhard, Frieder Nake&lt;/p&gt;
    &lt;head rend="h5"&gt;Life on Hold: What Does True Solidarity Look Like Beyond Duldung, Camps, Deportation, and Payment Cards?&lt;/head&gt;
    &lt;p&gt;Hafid Shaaib, Eric Noel Mbiakeu&lt;/p&gt;
    &lt;head rend="h5"&gt;Chatkontrolle - Ctrl+Alt+Delete&lt;/head&gt;
    &lt;p&gt;khaleesi, Markus Reuter&lt;/p&gt;
    &lt;head rend="h5"&gt;Excuse me, what precise time is It?&lt;/head&gt;
    &lt;p&gt;Oliver Ettlin&lt;/p&gt;
    &lt;head rend="h5"&gt;BitUnlocker: Leveraging Windows Recovery to Extract BitLocker Secrets&lt;/head&gt;
    &lt;p&gt;Alon Leviev&lt;/p&gt;
    &lt;head rend="h5"&gt;Not To Be Trusted - A Fiasco in Android TEEs&lt;/head&gt;
    &lt;p&gt;0ddc0de, gannimo, Philipp&lt;/p&gt;
    &lt;head rend="h5"&gt;Hacking washing machines&lt;/head&gt;
    &lt;p&gt;Severin von Wnuck-Lipinski, Hajo Noerenberg&lt;/p&gt;
    &lt;head rend="h5"&gt;Doomsday-Porn, Sch√§ferhunde und die ‚Äûniedliche Abschiebung‚Äú von nebenan: Wie autorit√§re Akteure KI-generierte Inhalte f√ºr Social Media nutzen&lt;/head&gt;
    &lt;p&gt;Katharina Nocun&lt;/p&gt;
    &lt;head rend="h5"&gt;Throwing your rights under the Omnibus - how the EU's reform agenda threatens to erase a decade of digital rights&lt;/head&gt;
    &lt;p&gt;Thomas Lohninger, Ralf Bendrath&lt;/p&gt;
    &lt;head rend="h5"&gt;DNGerousLINK: A Deep Dive into WhatsApp 0-Click Exploits on iOS and Samsung Devices&lt;/head&gt;
    &lt;p&gt;Zhongrui Li, Yizhe Zhuang, Kira Chen&lt;/p&gt;
    &lt;head rend="h5"&gt;Bluetooth Headphone Jacking: A Key to Your Phone&lt;/head&gt;
    &lt;p&gt;Dennis Heinze, Frieder Steinmetz&lt;/p&gt;
    &lt;head rend="h5"&gt;Breaking architecture barriers: Running x86 games and apps on ARM&lt;/head&gt;
    &lt;p&gt;neobrain&lt;/p&gt;
    &lt;head rend="h5"&gt;The Eyes of Photon Science: Imaging, Simulation and the Quest to Make the Invisible Visible&lt;/head&gt;
    &lt;p&gt;MarKuster&lt;/p&gt;
    &lt;head rend="h5"&gt;Coding Dissent: Art, Technology, and Tactical Media&lt;/head&gt;
    &lt;p&gt;Helena Nikonole&lt;/p&gt;
    &lt;head rend="h5"&gt;AI-generated content in Wikipedia - a tale of caution&lt;/head&gt;
    &lt;p&gt;Mathias Schindler&lt;/p&gt;
    &lt;head rend="h5"&gt;Building a NOC from scratch&lt;/head&gt;
    &lt;p&gt;lilly, Scientress&lt;/p&gt;
    &lt;head rend="h5"&gt;From Silicon to Darude Sand-storm: breaking famous synthesizer DSPs&lt;/head&gt;
    &lt;p&gt;giulioz&lt;/p&gt;
    &lt;head rend="h5"&gt;Unnecessarily Complicated Kitchen ‚Äì Die Wissenschaft des guten Geschmacks&lt;/head&gt;
    &lt;p&gt;LukasQ&lt;/p&gt;
    &lt;head rend="h2"&gt;Sun - Day 2 - December 28&lt;/head&gt;
    &lt;head rend="h5"&gt;Junghacker:innentag Einf√ºhrung&lt;/head&gt;
    &lt;head rend="h5"&gt;Protecting the network data of one billion people: Breaking network crypto in popular Chinese mobile apps&lt;/head&gt;
    &lt;p&gt;Mona&lt;/p&gt;
    &lt;head rend="h5"&gt;Hatupangwingwi: The story how Kenyans fought back against intrusive digital identity systems&lt;/head&gt;
    &lt;p&gt;Mustafa Mahmoud Yousif&lt;/p&gt;
    &lt;head rend="h5"&gt;Lightning Talks - Tag 2&lt;/head&gt;
    &lt;p&gt;bonnie, Gilbert, Andi Br√§u&lt;/p&gt;
    &lt;head rend="h5"&gt;Digitale Inklusion: Wie wir digitale Barrierefreiheit f√ºr alle erreichen k√∂nnen&lt;/head&gt;
    &lt;p&gt;Jakob Sponholz, Kathrin Klapper, Lena Christina M√ºller&lt;/p&gt;
    &lt;head rend="h5"&gt;Skynet Starter Kit: From Embodied AI Jailbreak to Remote Takeover of Humanoid Robots&lt;/head&gt;
    &lt;p&gt;Shipei Qu, Zikai Xu, Xuangan Xiao&lt;/p&gt;
    &lt;head rend="h5"&gt;Suing spyware in Europe: news from the front!&lt;/head&gt;
    &lt;p&gt;Lori Roussey, Celia/Ir√≠dia&lt;/p&gt;
    &lt;head rend="h5"&gt;Neue Chaos Events - InselChaos und H√•ck ma‚Äôs Castle plaudern aus dem N√§hk√§stchen&lt;/head&gt;
    &lt;p&gt;Erwin Ernst "eest9" Steinhammer, lasii, Daniel, Niklas&lt;/p&gt;
    &lt;head rend="h5"&gt;A post-American, enshittification-resistant internet&lt;/head&gt;
    &lt;p&gt;Cory Doctorow&lt;/p&gt;
    &lt;head rend="h5"&gt;A space odyssey #2: How to study moon rocks from the Soviet sample return mission Luna 24&lt;/head&gt;
    &lt;p&gt;Paul Koetter, Christopher Hamann&lt;/p&gt;
    &lt;head rend="h5"&gt;Agentic ProbLLMs: Exploiting AI Computer-Use and Coding Agents&lt;/head&gt;
    &lt;p&gt;Johann Rehberger&lt;/p&gt;
    &lt;head rend="h5"&gt;selbstverst√§ndlich antifaschistisch! Aktuelle Informationen zu den Verfahren im Budapest-Komplex - von family &amp;amp; friends Hamburg&lt;/head&gt;
    &lt;p&gt;Andreas family &amp;amp; friends Hamburg, Birgit family &amp;amp; friends Hamburg&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaospager - How to construct an Open Pager System for c3&lt;/head&gt;
    &lt;p&gt;Max, Julian&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaos Communication Chemistry: DNA security systems based on molecular randomness&lt;/head&gt;
    &lt;p&gt;Anne L√ºscher&lt;/p&gt;
    &lt;head rend="h5"&gt;Live, Die, Repeat: The fight against data retention and boundless access to data&lt;/head&gt;
    &lt;p&gt;Klaus Landefeld&lt;/p&gt;
    &lt;head rend="h5"&gt;Power Cycle B7 oder Warum kauft man eine Zeche?&lt;/head&gt;
    &lt;p&gt;Kohlenpod, kater, Stephan&lt;/p&gt;
    &lt;head rend="h5"&gt;Cracking open what makes Apple's Low-Latency WiFi so fast&lt;/head&gt;
    &lt;p&gt;Henri J√§ger&lt;/p&gt;
    &lt;head rend="h5"&gt;Awful interception: misadventures of the russian surveillance machinery&lt;/head&gt;
    &lt;p&gt;Xeniax&lt;/p&gt;
    &lt;head rend="h5"&gt;Amateurfunk im All ‚Äì Kontakt mit Fram2&lt;/head&gt;
    &lt;p&gt;akira25, flx, Gato&lt;/p&gt;
    &lt;head rend="h5"&gt;√úber europ√§ische Grenzen hinweg auf klinischen Daten rechnen - aber sicher!&lt;/head&gt;
    &lt;p&gt;Hendrik Ballhausen&lt;/p&gt;
    &lt;head rend="h5"&gt;CCC-Jahresr√ºckblick&lt;/head&gt;
    &lt;p&gt;Constanze Kurz, khaleesi, Matthias Marx, Linus Neumann, erdgeist&lt;/p&gt;
    &lt;head rend="h5"&gt;Persist, resist, stitch&lt;/head&gt;
    &lt;p&gt;Philo&lt;/p&gt;
    &lt;head rend="h5"&gt;Lessons from Building an Open-Architecture Secure Element&lt;/head&gt;
    &lt;p&gt;Jan Pleskac&lt;/p&gt;
    &lt;head rend="h5"&gt;Auf die Dauer hilft nur Power: Herausforderungen f√ºr dezentrale Netzwerke aus Sicht der Soziologie&lt;/head&gt;
    &lt;p&gt;Marco W√§hner&lt;/p&gt;
    &lt;head rend="h5"&gt;Current Drone Wars&lt;/head&gt;
    &lt;p&gt;Leonard&lt;/p&gt;
    &lt;head rend="h5"&gt;Variable Fonts ‚Äî It Was Never About File Size&lt;/head&gt;
    &lt;p&gt;Bernd&lt;/p&gt;
    &lt;head rend="h5"&gt;A Quick Stop at the HostileShop&lt;/head&gt;
    &lt;p&gt;Mike Perry&lt;/p&gt;
    &lt;head rend="h5"&gt;In-house electronics manufacturing from scratch: How hard can it be?&lt;/head&gt;
    &lt;p&gt;Augustin Bielefeld, Alexander Willer&lt;/p&gt;
    &lt;head rend="h5"&gt;CPU Entwicklung in Factorio: Vom D-Flip-Flop bis zum eigenen Betriebssystem&lt;/head&gt;
    &lt;p&gt;PhD (Philipp)&lt;/p&gt;
    &lt;head rend="h5"&gt;Amtsgeheimnis raus, Datenhalde rein: was die Informationsfreiheit in √ñsterreich bringt&lt;/head&gt;
    &lt;p&gt;Markus (fin) Hametner, Erwin Ernst "eest9" Steinhammer&lt;/p&gt;
    &lt;head rend="h5"&gt;How to render cloud FPGAs useless&lt;/head&gt;
    &lt;p&gt;Dirk&lt;/p&gt;
    &lt;head rend="h5"&gt;freiheit.exe - Utopien als Malware&lt;/head&gt;
    &lt;p&gt;Christiane Mudra&lt;/p&gt;
    &lt;head rend="h5"&gt;Recharge your batteries with us - an empowering journey through the energy transition&lt;/head&gt;
    &lt;p&gt;Salacidre, JulianeB&lt;/p&gt;
    &lt;head rend="h5"&gt;Prometheus: Reverse-Engineering Overwatch&lt;/head&gt;
    &lt;p&gt;breakingbread&lt;/p&gt;
    &lt;head rend="h5"&gt;Trump government demands access to European police databases and biometrics&lt;/head&gt;
    &lt;p&gt;Matthias Monroy&lt;/p&gt;
    &lt;head rend="h5"&gt;Verlorene Domains, offene T√ºren - Was alte Beh√∂rdendomains verraten&lt;/head&gt;
    &lt;p&gt;Tim Philipp Sch√§fers (TPS)&lt;/p&gt;
    &lt;head rend="h5"&gt;CSS Clicker Training: Making games in a "styling" language&lt;/head&gt;
    &lt;p&gt;Lyra Rebane&lt;/p&gt;
    &lt;head rend="h5"&gt;Wie wir alte Flipperautomaten am Leben erhalten&lt;/head&gt;
    &lt;p&gt;Axel B√∂ttcher&lt;/p&gt;
    &lt;head rend="h5"&gt;Power Cycles statt Burnout ‚Äì Wie Einflussnahme nicht verpufft&lt;/head&gt;
    &lt;p&gt;Rahel Becker, Anna Kassautzki&lt;/p&gt;
    &lt;head rend="h5"&gt;Don‚Äôt look up: There are sensitive internal links in the clear on GEO satellites&lt;/head&gt;
    &lt;p&gt;Nadia Heninger, Annie Dai&lt;/p&gt;
    &lt;head rend="h5"&gt;Textiles 101: Fast Fiber Transform&lt;/head&gt;
    &lt;p&gt;octoprog&lt;/p&gt;
    &lt;head rend="h5"&gt;How To Minimize Bugs in Cryptography Code&lt;/head&gt;
    &lt;p&gt;Jade&lt;/p&gt;
    &lt;head rend="h5"&gt;Machine Vision ‚Äì Vom Algorithmus zum Baumpilz im digitalen Metabolismus&lt;/head&gt;
    &lt;p&gt;Thomas Kn√ºsel&lt;/p&gt;
    &lt;head rend="h5"&gt;Xous: A Pure-Rust Rethink of the Embedded Operating System&lt;/head&gt;
    &lt;p&gt;bunnie, Sean "xobs" Cross&lt;/p&gt;
    &lt;head rend="h5"&gt;51 Ways to Spell the Image Giraffe: The Hidden Politics of Token Languages in Generative AI&lt;/head&gt;
    &lt;p&gt;Ting-Chun Liu, Leon-Etienne K√ºhr&lt;/p&gt;
    &lt;head rend="h5"&gt;When Vibe Scammers Met Vibe Hackers: Pwning PhaaS with Their Own Weapons&lt;/head&gt;
    &lt;p&gt;Chiao-Lin Yu (Steven Meow)&lt;/p&gt;
    &lt;head rend="h5"&gt;The Maybe Talent Show&lt;/head&gt;
    &lt;p&gt;Norman M√ºller-Schmitz, lukas-schmukas, James Bonne d'age&lt;/p&gt;
    &lt;head rend="h5"&gt;Code to Craft: Procedural Generation for the Physical World&lt;/head&gt;
    &lt;p&gt;bleeptrack&lt;/p&gt;
    &lt;head rend="h5"&gt;Reverse engineering the Pixel TitanM2 firmware&lt;/head&gt;
    &lt;p&gt;willem&lt;/p&gt;
    &lt;head rend="h5"&gt;The Small Packet of Bits That Can Save (or Destabilize) a City&lt;/head&gt;
    &lt;p&gt;Manuel R√°bade&lt;/p&gt;
    &lt;head rend="h5"&gt;GPTDash ‚Äì Der Reverse-Turing-Test&lt;/head&gt;
    &lt;p&gt;Benny, Kilian, BratscherBen&lt;/p&gt;
    &lt;head rend="h2"&gt;Mon - Day 3 - December 29&lt;/head&gt;
    &lt;head rend="h5"&gt;Azubi-Tag Einf√ºhrung&lt;/head&gt;
    &lt;head rend="h5"&gt;Greenhouse Gas Emission Data: Public, difficult to access, and not always correct&lt;/head&gt;
    &lt;p&gt;Hanno B√∂ck&lt;/p&gt;
    &lt;head rend="h5"&gt;Design for 3D-Printing&lt;/head&gt;
    &lt;p&gt;rahix&lt;/p&gt;
    &lt;head rend="h5"&gt;Lightning Talks - Tag 3&lt;/head&gt;
    &lt;p&gt;bonnie, Gilbert, Andi Br√§u&lt;/p&gt;
    &lt;head rend="h5"&gt;The Museum of Care: Open-Source Survival Kit Collection&lt;/head&gt;
    &lt;p&gt;Nika Dubrovsky&lt;/p&gt;
    &lt;head rend="h5"&gt;Celestial navigation with very little math&lt;/head&gt;
    &lt;p&gt;Trammell Hudson&lt;/p&gt;
    &lt;head rend="h5"&gt;a media-almost-archaeology on data that is too dirty for "AI"&lt;/head&gt;
    &lt;p&gt;jiawen uffline&lt;/p&gt;
    &lt;head rend="h5"&gt;Hacking Karlsruhe - 10 years later&lt;/head&gt;
    &lt;p&gt;J√ºrgen Bering&lt;/p&gt;
    &lt;head rend="h5"&gt;What Makes Bike-Sharing Work? Insights from 43 Million Kilometers of European Cycling Data&lt;/head&gt;
    &lt;p&gt;Martin Lellep, Georg Balke, FelixW&lt;/p&gt;
    &lt;head rend="h5"&gt;Teckids ‚Äì eine verstehbare (digitale) Welt&lt;/head&gt;
    &lt;p&gt;Keno, Darius Auding&lt;/p&gt;
    &lt;head rend="h5"&gt;BE Modded: Exploring and hacking the Vital Bracelet ecosystem&lt;/head&gt;
    &lt;p&gt;cyanic&lt;/p&gt;
    &lt;head rend="h5"&gt;Wer hat Angst vor dem Neutralit√§tsgebot?&lt;/head&gt;
    &lt;p&gt;Hannah Vos, Vivian Kube&lt;/p&gt;
    &lt;head rend="h5"&gt;Shit for Future: turning human shit into a climate solution&lt;/head&gt;
    &lt;p&gt;Elena&lt;/p&gt;
    &lt;head rend="h5"&gt;Watch Your Kids: Inside a Children's Smartwatch&lt;/head&gt;
    &lt;p&gt;Nils Rollshausen&lt;/p&gt;
    &lt;head rend="h5"&gt;When 8 Bits is Overkill: Making Blinkenlights with a 1-bit CPU&lt;/head&gt;
    &lt;p&gt;girst (Tobi)&lt;/p&gt;
    &lt;head rend="h5"&gt;Supplements und Social Media ‚Äì wenn der Online-Hype zur realen Gesundheitsgefahr wird&lt;/head&gt;
    &lt;p&gt;Christoph Wiedmer&lt;/p&gt;
    &lt;head rend="h5"&gt;Programmierte Kriegsverbrechen? √úber KI-Systeme im Kriegseinsatz in Gaza und warum IT-Fachleute sich dazu √§u√üern m√ºssen&lt;/head&gt;
    &lt;p&gt;Rainer Rehak&lt;/p&gt;
    &lt;head rend="h5"&gt;Making the Magic Leap past NVIDIA's secure bootchain and breaking some Tesla Autopilots along the way&lt;/head&gt;
    &lt;p&gt;EliseZeroTwo&lt;/p&gt;
    &lt;head rend="h5"&gt;Learning from South Korean Telco Breaches&lt;/head&gt;
    &lt;p&gt;Shinjo "peremen" Park, Yonghyu "perillamint" Ban&lt;/p&gt;
    &lt;head rend="h5"&gt;Gegenmacht - Best of Informationsfreiheit&lt;/head&gt;
    &lt;p&gt;Arne Semsrott&lt;/p&gt;
    &lt;head rend="h5"&gt;There is NO WAY we ended up getting arrested for this (Malta edition)&lt;/head&gt;
    &lt;p&gt;mixy1, Luke Bjorn Scerri, girogio&lt;/p&gt;
    &lt;head rend="h5"&gt;APT Down and the mystery of the burning data centers&lt;/head&gt;
    &lt;p&gt;Christopher Kunz, Sylvester&lt;/p&gt;
    &lt;head rend="h5"&gt;Von wegen Eisblumen! Wie man mit Code, Satelliten und Schiffsexpeditionen die bunte Welt des arktischen Phytoplanktons sichtbar macht&lt;/head&gt;
    &lt;p&gt;Moritz Zeising (er/he)&lt;/p&gt;
    &lt;head rend="h5"&gt;Schlechte Karten - IT-Sicherheit im Jahr null der ePA f√ºr alle&lt;/head&gt;
    &lt;p&gt;Bianca Kastl&lt;/p&gt;
    &lt;head rend="h5"&gt;Set-top box Hacking: freeing the 'Freebox'&lt;/head&gt;
    &lt;p&gt;Fr√©d√©ric Hoguin&lt;/p&gt;
    &lt;head rend="h5"&gt;Wer liegt hier wem auf der Tasche? Genug mit dem B√ºrgergeld-Fetisch. St√ºrmt die Pal√§ste!&lt;/head&gt;
    &lt;p&gt;Helena Steinhaus&lt;/p&gt;
    &lt;head rend="h5"&gt;The Last of Us - Fighting the EU Surveillance Law Apocalypse&lt;/head&gt;
    &lt;p&gt;Svea Windwehr, Chlo√© Berth√©l√©my&lt;/p&gt;
    &lt;head rend="h5"&gt;AI Agent, AI Spy&lt;/head&gt;
    &lt;p&gt;Udbhav Tiwari, Meredith Whittaker&lt;/p&gt;
    &lt;head rend="h5"&gt;Build a Fake Phone, Find Real Bugs: Qualcomm GPU Emulation and Fuzzing with LibAFL QEMU&lt;/head&gt;
    &lt;p&gt;Romain Malmain, Scott Bauer&lt;/p&gt;
    &lt;head rend="h5"&gt;Transkultureller Hack auf die klassische Musikszene ‚Äì Vortrag und Konzert&lt;/head&gt;
    &lt;p&gt;Johanna-Leonore Dahlhoff, Neina Doroshenko, Peter Klohmann, Alireza Meghrazi Solouklou, Mirweis Neda, Maria Carolina Pardo Reyes, Eduardo Sabella, Sarah Luisa Wurmer&lt;/p&gt;
    &lt;head rend="h5"&gt;Netzpolitik in der Schweiz: Zwischen Bodensee und Matterhorn&lt;/head&gt;
    &lt;p&gt;Kire, Rahel&lt;/p&gt;
    &lt;head rend="h5"&gt;The Angry Path to Zen: AMD Zen Microcode Tools and Insights&lt;/head&gt;
    &lt;p&gt;Benjamin Kollenda&lt;/p&gt;
    &lt;head rend="h5"&gt;Blackbox Palantir&lt;/head&gt;
    &lt;p&gt;Constanze Kurz, Franziska G√∂rlitz&lt;/p&gt;
    &lt;head rend="h5"&gt;Aber hier Leben? Nein danke! ‚Ä¶oder doch? Wie wir der autorit√§ren Zuspitzung begegnen k√∂nnen.&lt;/head&gt;
    &lt;p&gt;Ja≈°a Hiergeblieben, Lisa Zugezogen&lt;/p&gt;
    &lt;head rend="h5"&gt;Race conditions, transactions and free parking&lt;/head&gt;
    &lt;p&gt;Benjamin W. Broersma&lt;/p&gt;
    &lt;head rend="h5"&gt;Hegemony Eroding: Excavating Diversity in Latent Space&lt;/head&gt;
    &lt;p&gt;Karim Hamdi&lt;/p&gt;
    &lt;head rend="h5"&gt;10 years of Dieselgate&lt;/head&gt;
    &lt;p&gt;Felix Domke, Karsten Burger&lt;/p&gt;
    &lt;head rend="h5"&gt;The Heartbreak Machine: Nazis in the Echo Chamber&lt;/head&gt;
    &lt;p&gt;Martha Root, Eva Hoffmann, Christian Fuchs&lt;/p&gt;
    &lt;head rend="h5"&gt;Light in the Dark(net)&lt;/head&gt;
    &lt;p&gt;Tobias H√∂ller&lt;/p&gt;
    &lt;head rend="h5"&gt;The Spectrum - Hackspace Beyond Hacking&lt;/head&gt;
    &lt;p&gt;sjaelv, MultisampledNight&lt;/p&gt;
    &lt;head rend="h5"&gt;Rowhammer in the Wild: Large-Scale Insights from FlippyR.AM&lt;/head&gt;
    &lt;p&gt;Martin Heckel, Florian Adamsky, Daniel Gruss&lt;/p&gt;
    &lt;head rend="h5"&gt;Peep-Show f√ºr die Polizei. Staatliche √úberwachung von Queers in Hamburger Toiletten bis 1980&lt;/head&gt;
    &lt;p&gt;Simon Schultz&lt;/p&gt;
    &lt;head rend="h5"&gt;Human microservices at the Dutch Railways: modern architecture, ancient hardware?&lt;/head&gt;
    &lt;p&gt;Maarten W&lt;/p&gt;
    &lt;head rend="h5"&gt;Von Fuzzern zu Agenten: Entwicklung eines Cyber Reasoning Systems f√ºr die AIxCC&lt;/head&gt;
    &lt;p&gt;Mischa Meier (mmisc), Annika Kuntze&lt;/p&gt;
    &lt;head rend="h5"&gt;PR√úF&lt;/head&gt;
    &lt;p&gt;Nico Semsrott&lt;/p&gt;
    &lt;head rend="h5"&gt;Verschl√ºsselung brechen durch physischen Zugriff - Smartphone Beschlagnahme durch Polizei&lt;/head&gt;
    &lt;p&gt;Davy Wang, Viktor Schl√ºter&lt;/p&gt;
    &lt;head rend="h5"&gt;Spectre in the real world: Leaking your private data from the cloud with CPU vulnerabilities&lt;/head&gt;
    &lt;p&gt;Thijs Raymakers&lt;/p&gt;
    &lt;head rend="h5"&gt;Die gro√üe Datenschutz-, Datenpannen- und DS-GVO-Show&lt;/head&gt;
    &lt;p&gt;Alvar C.H. Freude&lt;/p&gt;
    &lt;head rend="h2"&gt;Tue - Day 4 - December 30&lt;/head&gt;
    &lt;head rend="h5"&gt;Asahi Linux - Porting Linux to Apple Silicon&lt;/head&gt;
    &lt;p&gt;sven&lt;/p&gt;
    &lt;head rend="h5"&gt;Atoms in Space&lt;/head&gt;
    &lt;p&gt;manuel&lt;/p&gt;
    &lt;head rend="h5"&gt;I Hated All The Cross-Stitch Software So I Made My Own: My Deranged Outsider Software Suite For Making Deranged Outsider Art&lt;/head&gt;
    &lt;p&gt;yomimono&lt;/p&gt;
    &lt;head rend="h5"&gt;How to keep Open Source open without leaving our communities open to threats&lt;/head&gt;
    &lt;p&gt;Quintessence&lt;/p&gt;
    &lt;head rend="h5"&gt;CCC&amp;amp;T - Cosmic ray, the Climate Catastrophe and Trains.&lt;/head&gt;
    &lt;p&gt;FantasticMisterFux, louiT&lt;/p&gt;
    &lt;head rend="h5"&gt;CUII: Wie Konzerne heimlich Webseiten in Deutschland sperren&lt;/head&gt;
    &lt;p&gt;Lina Lastname, Elias Zeidler (Northernside)&lt;/p&gt;
    &lt;head rend="h5"&gt;‚ÄúEnd Of 10‚Äù: How the FOSS Community is Combatting Software-Driven Resource and Energy Consumption&lt;/head&gt;
    &lt;p&gt;Joseph P. De Veaugh-Geiss, Carolina Silva Rode, belobe&lt;/p&gt;
    &lt;head rend="h5"&gt;What You Hack Is What You Mean: 35 Years of Wiring Sense into Text&lt;/head&gt;
    &lt;p&gt;Torsten Roeder&lt;/p&gt;
    &lt;head rend="h5"&gt;Security of Cardiac Implantable Electronic Devices&lt;/head&gt;
    &lt;p&gt;dilucide&lt;/p&gt;
    &lt;head rend="h5"&gt;Who runs the www? WSIS+20 and the future of Internet governance&lt;/head&gt;
    &lt;p&gt;Sophia Longwe&lt;/p&gt;
    &lt;head rend="h5"&gt;Fossile Industrie liebt KI!&lt;/head&gt;
    &lt;p&gt;Stefan, Yannik &amp;amp; Rike, Moritz&lt;/p&gt;
    &lt;head rend="h5"&gt;Laser Beams &amp;amp; Light Streams: Letting Hackers Go Pew Pew, Building Affordable Light-Based Hardware Security Tooling&lt;/head&gt;
    &lt;p&gt;Patch, Sam. Beaumont (PANTH13R)&lt;/p&gt;
    &lt;head rend="h5"&gt;Breaking BOTS: Cheating at Blue Team CTFs with AI Speed-Runs&lt;/head&gt;
    &lt;p&gt;Leo Meyerovich, Sindre Breda&lt;/p&gt;
    &lt;head rend="h5"&gt;Von Groschen und SpurLos - GNU Taler auch auf eurem Event!&lt;/head&gt;
    &lt;p&gt;Mikolai G√ºtschow, signum&lt;/p&gt;
    &lt;head rend="h5"&gt;We, the EU, and 1064 Danes decided to look into YouTube: A story about how the EU gave us a law, 1064 Danes gave us their YouTube histories, and reality gave us a headache&lt;/head&gt;
    &lt;p&gt;David, LK Seiling&lt;/p&gt;
    &lt;head rend="h5"&gt;Battling Obsolescence ‚Äì Keeping an 80s laser tag system alive&lt;/head&gt;
    &lt;p&gt;Trikkitt&lt;/p&gt;
    &lt;head rend="h5"&gt;Security Nightmares&lt;/head&gt;
    &lt;p&gt;Constanze Kurz, Ron&lt;/p&gt;
    &lt;head rend="h5"&gt;Infrastructure Review&lt;/head&gt;
    &lt;p&gt;nicoduck&lt;/p&gt;
    &lt;head rend="h5"&gt;Closing Ceremony&lt;/head&gt;
    &lt;p&gt;Stella, pajowu&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fahrplan.events.ccc.de/congress/2025/fahrplan/"/><published>2025-12-25T18:40:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46387164</id><title>Memory Safety</title><updated>2025-12-26T12:20:53.017346+00:00</updated><content>&lt;doc fingerprint="5adb59997e9791e8"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;TLS (Rustls)&lt;/head&gt;&lt;p&gt;Let's get the Rustls TLS library ready to replace OpenSSL in as many projects as possible.&lt;/p&gt;&lt;p&gt;Let's get the Rustls TLS library ready to replace OpenSSL in as many projects as possible.&lt;/p&gt;&lt;p&gt;Let's create a memory safe, high performance, fully recursive DNS resolver.&lt;/p&gt;&lt;p&gt;Let's make the utilities that mediate privileges safer.&lt;/p&gt;&lt;p&gt;Let's create a memory safe NTP implementation.&lt;/p&gt;&lt;p&gt;Let's create a memory safe AV1 decoder that delivers great performance.&lt;/p&gt;&lt;p&gt;Let's create a memory safe zlib compression library with great performance.&lt;/p&gt;&lt;p&gt;Let's make it possible to write memory safe drivers for the Linux kernel.&lt;/p&gt;&lt;p&gt;Let's make the network edge memory safe.&lt;/p&gt;&lt;p&gt;Let's make it possible to use memory safe TLS networking in Apache httpd.&lt;/p&gt;&lt;p&gt;Let's make TLS and HTTP networking code in curl memory safe.&lt;/p&gt;&lt;p&gt;Let's improve the tools we use to bring memory safe software to the world.&lt;/p&gt;&lt;p&gt;Creating error messages that are clear and detailed.&lt;/p&gt;&lt;p&gt;The Rust Foundation just announced the launch of the Rust Innovation Lab, with the Rustls TLS library as the inaugural hosted project.&lt;/p&gt;&lt;p&gt;Hickory DNS is getting support for RFC 9539 opportunistic encryption.&lt;/p&gt;&lt;p&gt;We're in the beginning phases of a journey towards memory safety for the Internet's critical software infrastructure, and as we get going it makes the most sense to break down big problems into smaller ones by focusing on replacing components within existing C and C++ software.&lt;/p&gt;&lt;p&gt;Being part of ambitious work like Prossimo is easier than you might think: 100% of our funding comes from charitable donations from companies and people like you.&lt;/p&gt;&lt;p&gt;When you support Prossimo, you‚Äôre helping to create a future for the Web that is more memory safe and more secure - and that benefits everyone using it!&lt;/p&gt;Donate&lt;p&gt;Bring greater security to your organization by advocating for memory safe code in your organization!&lt;/p&gt;&lt;p&gt;Many organizations match donations to nonprofits made by employees. Check if your organization has a matching program and double your impact!&lt;/p&gt;See if your organization has a matching program&lt;p&gt;Prossimo works to connect maintainers behind the Internet's most critical pieces of software with the people and organizations who want to see Internet security move forward by adopting memory safe languages. Here's the simple framework of how Prossimo works:&lt;/p&gt;&lt;p&gt;By funding, you can support this important work!&lt;/p&gt;&lt;p&gt;Contact us to learn about upcoming Prossimo initiatives: donate@abetterinternet.org&lt;/p&gt;Support this Work&lt;p&gt;Appreciated securities or mutual fund shares that you‚Äôve owned for more than one year can be excellent charitable gifts.&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Brokerage Firm:&lt;/cell&gt;&lt;cell&gt;Vanguard&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Account Name:&lt;/cell&gt;&lt;cell&gt;Internet Security Research Group&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;ISRG Account #:&lt;/cell&gt;&lt;cell&gt;44865458&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;DTC #:&lt;/cell&gt;&lt;cell&gt;0062&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Tax ID #:&lt;/cell&gt;&lt;cell&gt;46-3344200&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Please let us know if you are transferring securities at donate@abetterinternet.org. You may also want to email the letter of authorization from your broker.&lt;/p&gt;Gifts of Cryptocurrency&lt;p&gt;We accept BTC, BCH, ETH, DOGE, WBTC, and all other currencies supported by BitPay. We are able to accept donations equivalent to $1,000 USD or greater. Please email donate@abetterinternet.org for invoicing.&lt;/p&gt;Donor Advised Funds&lt;p&gt;Recommend a donation to Internet Security Research Group (our parent org) from your gift fund. 100% of your donation will go to support a secure and privacy-respecting Internet.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.memorysafety.org/"/><published>2025-12-25T21:31:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46387657</id><title>Maybe the default settings are too high</title><updated>2025-12-26T12:20:52.629548+00:00</updated><content>&lt;doc fingerprint="e65b52868faaab9c"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôve been reading Lord of the Rings for two months and I‚Äôm just at the end of the first part. It‚Äôs not because I‚Äôm not enjoying it. It‚Äôs one of the most enjoyable reading experiences I can remember.&lt;/p&gt;
    &lt;p&gt;From the beginning, I‚Äôve read the whole thing aloud. I‚Äôve found reading aloud helpful for staying engaged ‚Äî limiting myself to mouth-speed rather than eye-speed means I won‚Äôt rush, miss important details, and then lose interest, which has always been a problem for me.&lt;/p&gt;
    &lt;p&gt;At first I was anxious to read a 1,500-page book this way, because it would take so long. But, as someone pointed out to me, if I‚Äôm enjoying it, why would I want to be done with it sooner?&lt;/p&gt;
    &lt;p&gt;So I tried slowing down even more, and discovered something. I slowed to a pace that felt almost absurd, treating each sentence as though it might be a particularly important one. I gave each one maybe triple the usual time and attention, ignoring the fact that there are hundreds of pages to go.&lt;/p&gt;
    &lt;p&gt;This leisurely pace made Middle-Earth blossom before my eyes. When I paused after each comma, and let each sentence ring for a small moment after the period, the events of the story reached me with more weight and strength. That extra time gave space for Tolkien‚Äôs images and moods to propagate in my mind, which they did automatically.&lt;/p&gt;
    &lt;p&gt;Some part of me still wanted to rush and get on with it, to make good time, to gloss over the songs and lore to get to Moria and Mount Doom and the other marquee moments of the story. But the more I ignored that impulse, the better the experience got.&lt;/p&gt;
    &lt;p&gt;By offering the book about triple the usual amount of attentiveness, I was getting about triple the storyness (i.e. meaning, engagement, literary pleasure). Whatever the thing is that I‚Äôm seeking when I pick up a novel in the first place, there‚Äôs much more of it available at this pace.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eating Comprehension&lt;/head&gt;
    &lt;p&gt;This effect reminded me of a paradox around eating I recognized long ago. When you slow down your eating speed, say to half or a third your default speed, you get much more enjoyment out of a smaller amount of food. The extra attention given to each bite allows more of the ‚Äúgood stuff,‚Äù whatever that is exactly, to reach you.&lt;/p&gt;
    &lt;p&gt;What‚Äôs paradoxical is that it‚Äôs precisely the seeking of that ‚Äúgood stuff‚Äù that normally drives me to eat so quickly, and miss most of what I‚Äôm seeking. When you try to barrel ahead to access the good stuff quicker, you get less of it in the end. Slow down and much more of it is released.&lt;/p&gt;
    &lt;p&gt;And it‚Äôs released automatically, in both reading and eating. You don‚Äôt have to search it out. The good stuff (the meaning in the text, the pleasure in the eating) just rises up to meet you in that extra time you give it. Slowing down, and offering more time to the act of consumption, immediately increases reading comprehension (and eating comprehension).&lt;/p&gt;
    &lt;p&gt;Both are analogous to slowing down while you vacuum a carpet. If you pass the vacuum head too quickly, you miss half the dirt. Slow down, and you can hear how much more grit is sent skittering up the tube. The suction and bristles are working, but they need more time to do their work fully, to draw up the deeper-lying stuff.&lt;/p&gt;
    &lt;head rend="h3"&gt;Question the default settings&lt;/head&gt;
    &lt;p&gt;It seems that my default consumption speeds for reading and eating (and maybe everything else) reduce the rewards of those things significantly, undermining the point of doing either.&lt;/p&gt;
    &lt;p&gt;Part of it is my own impatience. But I also suspect that modern living, with its infinite supply of consumables, tends to push our rate-of-intake dials too high. I‚Äôm not going to run out of books, or snacks, or opportunities to learn something. There‚Äôs always more, so not every crust of bread or printed page needs to be appreciated fully.&lt;/p&gt;
    &lt;p&gt;Internally though, the mind is juggling like Lucy and Ethel on the conveyor belt at the chocolate factory. Our receptors for meaning and appreciation, like the vacuum head, need more time to do their full work, to make all the connections they‚Äôre designed to make.&lt;/p&gt;
    &lt;p&gt;It might sound like I‚Äôm just offering clich√©s ‚Äì less is more, stop and smell the roses, take your time ‚Äì and I guess I am. But clich√©s suffer the same issue: they are often profound insights, consumed and passed on too rapidly for their real meaning to register anymore. You really should stop and smell roses, as you know if you‚Äôre in the habit of doing that.&lt;/p&gt;
    &lt;p&gt;At least see what happens when you reduce your consumption speed ‚Äì of anything, but especially books, information, and food ‚Äì by a half, or two thirds. Notice that (1) something in you really wants to plow through at the highest viable setting, and (2) how much more of the reward is released when you slow down anyway.&lt;/p&gt;
    &lt;p&gt;As far as I can tell, almost everything becomes more satisfying when you give it more time and intention, even things like checking the mailbox or writing a shopping list.&lt;/p&gt;
    &lt;head rend="h3"&gt;Speed alters taste&lt;/head&gt;
    &lt;p&gt;Slowing down your rate of consumption will inevitably change what you want to consume. Reading throwaway news articles or AI slop with great care and attention is only going to show you how empty of value it is. Reading dense writing in inky old books, crafted for your mind by great masters, becomes easier without the rushed pace, and the meaning just blooms out of it.&lt;/p&gt;
    &lt;p&gt;Same with food. Try to savor a cheap, waxy ‚Äúchocolate‚Äù bar, or a bag of store-brand cheese puffs, and you discover a harsh taste that you don‚Äôt want to look at too closely. Enjoy a homemade pastry with great attention, and discover there‚Äôs even more in it than you realized.&lt;/p&gt;
    &lt;p&gt;Mass production is good in so many ways, but the faster we tend to consume its fruits, the more we end up seeking things for their glossy, candied surfaces. The more we go for these surface-level rewards, the more the culture focuses on offering only that part ‚Äì such as TikTok videos, processed food, CGI-forward movies, and public discourse in the form of unexamined talking points.&lt;/p&gt;
    &lt;p&gt;Who knows how far we‚Äôve drifted from the best modes of consuming the things we value. Once something becomes a norm, it seems like an appropriate standard, no matter how much has been lost. Apparently, reading silently and alone was unusual until as late as the 18th century. Certainly sit-down meals and cooking at home were.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt mean to sound like a scold. Let‚Äôs say none of this is morally good or bad. It‚Äôs just that in so much of what we do, we could be getting much more of the part of it that we really seek ‚Äî but it‚Äôs only available at slower speeds.&lt;/p&gt;
    &lt;p&gt;If you‚Äôre curious, try consuming things more slowly, so slowly it seems silly to others ‚Äî say a third your habitual speed ‚Äî and see what rises up to meet you.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;head rend="h2"&gt;Want to quit something in January?&lt;/head&gt;
    &lt;p&gt;Recently I opened a discussion forum for Raptitude readers who want to give something up for the month of December (alcohol, social media, snacks, etc).&lt;/p&gt;
    &lt;p&gt;It‚Äôs been a real success, and many people want to do something similar in January. If you want to quit something, or just give it up for a month, you‚Äôre invited to join.&lt;/p&gt;
    &lt;p&gt;Follow this link at the end of this post to get an invite.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.raptitude.com/2025/12/maybe-the-default-settings-are-too-high/"/><published>2025-12-25T23:13:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388040</id><title>Seven Diabetes Patients Die Due to Undisclosed Bug in Abbott's Glucose Monitors</title><updated>2025-12-26T12:20:52.071327+00:00</updated><content>&lt;doc fingerprint="ae6b011328472dfc"&gt;
  &lt;main&gt;&lt;p&gt;by&lt;/p&gt;on December 23, 2025&lt;p&gt;I wrote last month about my diabetes diagnosis this year and my difficult choice to wear a proprietary device (called a CGM) on my arm 24/7 to continuously monitor my glucose levels. Like my friend and colleague, Karen M. Sandler ‚Äî who previously made a much higher-stakes choice to receive a proprietary implanted defibrillator to keep her safe given her genetic heart condition ‚Äî I reluctantly chose to attach proprietary hardware and software to my body.&lt;/p&gt;&lt;p&gt;The device itself is quite proprietary, but fortunately the FOSS community has reverse engineered its activation and data collection protocols ‚Äî creating an Android application that does a better job than the manufacturers' proprietary ones0.&lt;/p&gt;&lt;p&gt;Here in the USA, we strangely use capitalism as the center of our health care system. Two major for-profit competing brands of CGM are available here. My diabetes specialist prefers the (ironically named) Freestyle Libre Plus from Abbott. I (also rather strangely) bring a prescription for electronics to a pharmacy every month. On 2025-12-03, that pharmacy sent me an alarming text message (shown here).&lt;/p&gt;&lt;p&gt;After reading that text, I found the USA FDA announcement. My spouse cross-referenced the lot numbers while I read them off from all my Freestyle boxes1. I had indeed recently worn an impacted device!&lt;/p&gt;&lt;p&gt;Only because my diabetes is so early of a stage was I relatively safe. The FDA reports that Freestyle injured over 700 people and killed seven people with this bug. Specifically, the bug caused the device to falsely report an extremely low glucose level. Advanced stage diabetics use low reading information to inform them that they may have too much insulin currently. The usual remedy is to eat something sugary to raise glucose in the blood. Such should be done only with great care, as a false low reading can harm and even kill the patient (who eats a high-sugar-content item while glucose in the blood is, in fact, not low).&lt;/p&gt;&lt;p&gt;Proprietary software in medical devices harming patients is not new. In 1985, the Therac-25 killed three people. In 2020, hundreds of patients who relied on a financially troubled tech startup found their occular implants suddenly unsupported. Some patients went blind as the devices powered down without updates. There are more examples that I could include here, but rereading these horrific stories is frankly more than I can take right now when I think of fellow diabetes sufferers who were ‚Äúkilled by code‚Äù recently..&lt;/p&gt;&lt;p&gt;It's hubris for activists to guarantee that harm would be prevented if Freestyle had publicly released the hardware specifications and the complete, corresponding source code (CCS). FOSS isn't immune to bugs ‚Äî even dangerous ones. However, in the centuries since the Enlightenment, we know that the scientific method depends on public disclosure about data and wide-reaching peer review of past work. FOSS (plus a publicly disclosed hardware design) wouid allow the millions of hardware and software engineers to peer-review the integrity, security, and safety of the devices to which patients entrust their lives. We achieve the promise of humanity when we each entrust our safety and health to our entire community ‚Äî not merely a single for-profit entity.&lt;/p&gt;&lt;p&gt;We also will probably never know whether this issue was in hardware or software. The bug disclosure is incredibly vague, and it remains unclear how much investigation was done (if any) by government regulators into this problem. As a public policy and public health matter, the public deserves to know the technical details (software and hardware) of both the functioning device and the failed devices. NGOs should be permitted to perform their own investigations and confirmations of public safety.&lt;/p&gt;&lt;p&gt;Given that the hardware, software, and medical for-profit industries refuse to put the rights, safety and security of patients first, wrongful death lawsuits are typically the only way to hold these companies accountable. Yet, there are very few people who have not agreed Abbott's toxic terms of their proprietary companion application ‚Äî I guestimate that fewer than 1% of Freestyle-using patients have used Juggluco from their very start (and thus never agreed to Abbott's terms). This is significant because Abbott includes a comprehensive one-way indemnity for themselves in the terms. I hope that a class action suit begins soon on this matter, but I wonder and worry that so much of the class may have signed this indemnity (which may make the road to justice bumpier).&lt;/p&gt;&lt;p&gt;Finally, I want to offer that if there is anyone out there who does tear-downs of extremely tiny electronic devices, I would be thrilled to find a volunteer who would like to see if we can either extract any software components from the device, or reverse-engineer the hardware. I have saved and sanitized all of my prior CGMs. I'd gladly send one along to anyone who wants to give a try at taking them apart. (Contact SFC or contact me on the Fediverse (via Mastodon) if you're available to do this work.)&lt;/p&gt;&lt;p&gt;For my part, I look forward (after the Vizio trial) to sending some patches to Juggluco and also getting Juggluco available in F-Droid. Our best option in the face of these powerful medical device companies curtailing our rights is to invest our volunteer time into the edges where FOSS has resiliently worked around the constant roadblocks erected by bad actors.&lt;/p&gt;&lt;p&gt;0My prior post about CGMs discussed the GPLv3'd Juggluco in more detail.&lt;/p&gt;&lt;p&gt;1 In a fascinating turn of events, at least one of my past monitors (of which I fortitously saved all the boxes with the lot/serial number on them) is listed in the FDA's spreadsheet as recalled lot, yet the serial number is listed as ‚Äú safe to use‚Äù on Abbott's webform ü§î ‚Ä¶ I'm left wondering how I can trust Abbott to write reliable software stuck into my arm if they can't even write a web form that cross-references serial numbers to lots correctly üò¨.&lt;/p&gt;&lt;p&gt;Please email any comments on this entry to info@sfconservancy.org.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sfconservancy.org/blog/2025/dec/23/seven-abbott-freestyle-libre-cgm-patients-dead/"/><published>2025-12-26T00:29:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388059</id><title>When a driver challenges the kernel's assumptions</title><updated>2025-12-26T12:20:51.012178+00:00</updated><content>&lt;doc fingerprint="fe0198957aa49b99"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When a driver challenges the kernel's assumptions&lt;/head&gt;
    &lt;p&gt;Unix-based systems have been around for more than 50 years now. Although the best design ideas still prevail to this day, the evolution of the computing industry has forced operating system designers to rethink the way they work, multiple times over time.&lt;/p&gt;
    &lt;p&gt;From a device driver point of view, the most important change was the change from fixed, compile-time hardware configuration, enumerated upon boot and never changing afterwards, to a more dynamic model, where devices can come and go: storage devices first, with the first hotplug-capable SCSI controllers in the first half of the 1990s, and complete devices shortly later, first with the introduction of the PCMCIA bus on laptops, then with USB and Firewire, which were not limited to laptops.&lt;/p&gt;
    &lt;p&gt;While PCMCIA support in open source operating systems had lingered for a few years before being integrated (both in Linux with "pcmcia-cs" and in FreeBSD with the "laptop package"), by the time USB support was being worked on, the required changes to accept/allow that devices may show up or disappear at any time had been completed and tested, and the kernel had no excuse not to cope with removable devices.&lt;/p&gt;
    &lt;p&gt;Today's story is the story of a device driver which caused some kernel assumptions to no longer stand, and the work done to remediate this situation, letting the kernel cope with the new world order.&lt;/p&gt;
    &lt;p&gt;This story starts on the 12th of march 2009. Theo de Raadt is travelling to Japan to visit fellow OpenBSD developer Ryan McBride, best known for implementing the CARP network high-availability protocol in OpenBSD, who has been living in Japan for a few years already.&lt;/p&gt;
    &lt;p&gt;Every time he goes to Japan, Theo never misses the opportunity to visit Akihabara in Tokyo, in order to find new computing devices to play with.&lt;/p&gt;
    &lt;p&gt; Among the devices he picks this time, is a small display, the size of a smartphone, with an usb cable, shown here running an X server under OpenBSD for the first time, a few months later. (picture courtesy of Marcus Glocker) &lt;/p&gt;
    &lt;p&gt;The company making these USB displays is called DisplayLink.&lt;/p&gt;
    &lt;p&gt;DisplayLink provides binary-only drivers for Microsoft Windows and Apple Mac OSX, and nothing more. This caused some frustration in the free software world, and Florian Echtler, with the help of Chris Hodges, worked on reverse engineering the device, with the intent to get it working under Linux. All of their work is nowadays described at https://floe.butterbrot.org/matrix/hacking/dlnk/.&lt;/p&gt;
    &lt;p&gt;Of course, at this point, there is no support for these devices in OpenBSD either, and they attach as generic USB devices when connected:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;deraadt&amp;gt; ugen0 at uhub0 port 3 "DisplayLink LCD-8000U" rev 2.00/0.02 addr 2 &amp;lt;deraadt&amp;gt; Picked up that too&lt;/quote&gt;
    &lt;p&gt;Moments later, Matthieu Herrb points to Florian Echtler's information:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;matthieu&amp;gt; &amp;lt;http://floe.butterbrot.org/displaylink/doku.php&amp;gt;&lt;/quote&gt;
    &lt;p&gt;The DisplayLink device gets passed from Theo de Raadt to developer Claudio Jeker, who lives in Switzerland close to another developer who has been recently working on USB devices, and will be the hero of this story: Marcus Glocker.&lt;/p&gt;
    &lt;p&gt;Once told he will be given the device, Marcus does what everyone in his place would have done: he asks the manufacturer politely for documentation on april 6th.&lt;/p&gt;
    &lt;p&gt;There was no contact information at DisplayLink, only a "contact us" webform in which you could enter your name and email address, and your message.&lt;/p&gt;
    &lt;quote&gt;Name: Marcus Glocker Message: Dear Ladies and Gentleman, We are thinking about developing an OpenSource driver for your DL-120/DL-160 chipsets. This would allow several OpenSource projects (e.g. NetBSD, FreeBSD, OpenBSD, Linux, X.org) to add support for DisplayLink based USB LCD devices, and therefore extend your potential user base. Therefore we would like to talk with you about getting basic documentation for your chipsets. It would be nice if the right person for this topic could contact me for further communication on the e-mail address stated in this form. Regards, Marcus Glocker, OpenBSD Developer&lt;/quote&gt;
    &lt;p&gt;The answer was as unhelpful as possible:&lt;/p&gt;
    &lt;quote&gt;Date: Mon, 6 Apr 2009 12:49:42 +0100 From: Jason Slaughter (DisplayLink) To: Marcus Glocker Cc: Bernie Thompson (DisplayLink) Subject: Opensource Driver for OpenBSD Hello Marcus, thank you for your email. DisplayLink USB graphics are a software graphics card: graphics functions are performed on the CPU and then compressed and sent across the USB cable to be decompressed in a DisplayLink DL-120/DL-160 chip on the other side. This means that - unlike most PC hardware - getting basic documentation about the chip would not provide enough information to implement a driver for BSD. However, DisplayLink is current in the process of putting together a library that will provide the functions necessary to drive a DisplayLink USB graphics chips, and it is our intention to release this library under an open source license in the very near future. This library would provide you with all of the information necessary to develop an x.org compatible driver for DisplayLink USB graphics devices on *BSD. The best point of contact for you might be Bernie Thompson (cc'd), our VP of Software Platforms based in Seattle, Washington. We could start with a conversation on email, but Bernie and I would also be happy to have a quick phone call with you to help you understand how DisplayLink graphics work and what our plans are for supporting open source platforms. I would also be curious to get your thoughts on how DisplayLink device support might fit into BSD. Thank you, Jason&lt;/quote&gt;
    &lt;p&gt;At the same time, Marcus was sharing the results of this discussion with the other OpenBSD developers on our private chatroom.&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglock&amp;gt; wow. &amp;lt;kettenis&amp;gt; wow? &amp;lt;mglock&amp;gt; DisplayLink TM seems to be very communactive. &amp;lt;mglock&amp;gt; asked the for specs for their DL-120/DL-160 chips, and got a detailed answer withing 4 hours. &amp;lt;mglock&amp;gt; they want to call me :-) &amp;lt;oga&amp;gt; they're actually responding? &amp;lt;oga&amp;gt; wow... &amp;lt;oga&amp;gt; I'd heard they were quite reticent. Someone on the xorg lists is rev engineering them for that reason. Not so much progress so far &amp;lt;mglock&amp;gt; interessting. &amp;lt;oga&amp;gt; Well, i asked him if he was reverse engineering, he said yes. I'm sure I asked if he'd asked for docs, but the reply from him doesn't include that bit. &amp;lt;oga&amp;gt; If you can get specifications freely, I'd be interested in a copy &amp;lt;oga&amp;gt; those things are pretty cool, in an oddball kinda way &amp;lt;mglock&amp;gt; sure. keep you informed. lets see how far we come. [...] &amp;lt;mglocker&amp;gt; just wrote back to the DisplayLink guys. lets see what happens.&lt;/quote&gt;
    &lt;p&gt;The day after:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglocker&amp;gt; re &amp;lt;mglocker&amp;gt; got the DisplayLink device from claudio. &amp;lt;mglocker&amp;gt; and an answer from DisplayLink themselfs. &amp;lt;mglocker&amp;gt; we will get no docs. &amp;lt;kettenis&amp;gt; bastards! &amp;lt;mglocker&amp;gt; but the seem to release the opensource library soon. based on libusb. &amp;lt;mglocker&amp;gt; library will be LGPL licensed ...&lt;/quote&gt;
    &lt;p&gt;However, Marcus does not remain inactive waiting for a hypothetical code release from DisplayLink. After weeks of trials, he reaches a point where he has a terminal (text-mode emulation) running on it, albeit slowly, and talks about it on may 1st, leading to a productive brainstorming session with a few other OpenBSD developers:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglocker&amp;gt; hmm, looks bad for the USB display driver for wscons. all that many little USB bulk transfers which are necessary to draw the fonts make the display rendering slow. &amp;lt;mglocker&amp;gt; i think there is no way to improve it further. &amp;lt;oga&amp;gt; mglocker: make a shadow area and blit the whole lot in one go &amp;lt;oga&amp;gt; so make a line of text in one go the blit all of it &amp;lt;oga&amp;gt; and use blits to move lines of text around for scrolling &amp;lt;mglocker&amp;gt; nah, you need to be able to draw one character. &amp;lt;oga&amp;gt; hmmm &amp;lt;oga&amp;gt; did they release that library by the way? &amp;lt;deraadt&amp;gt; there must be memory on the thing, to pre-load the fonts there &amp;lt;mglocker&amp;gt; even if you preload the fonts, it doesn't help. to bit blit one character you also need to setup a bulk xfer. &amp;lt;oga&amp;gt; oh, offscreen memory if it has, then it's just blitting chars. &amp;lt;oga&amp;gt; oh jesus. &amp;lt;mglocker&amp;gt; it's the same amount of bulk xfers in the end. &amp;lt;mglocker&amp;gt; yes, i tried exactly that. &amp;lt;oga&amp;gt; how slow is slow? &amp;lt;mglocker&amp;gt; it is exactly as slow as before. &amp;lt;oga&amp;gt; I mean how slow is the output all told? &amp;lt;mglocker&amp;gt; i think it's not the content of the bulk xfer making it slow, but the little peaces of bulk xfers. &amp;lt;mglocker&amp;gt; ah. &amp;lt;mglocker&amp;gt; on my amd64 it's like a 19200 modem connection or such :-) &amp;lt;deraadt&amp;gt; how do they make it fast, then? &amp;lt;oga&amp;gt; what info do you have on it? &amp;lt;drahn&amp;gt; can multiple 'blits' be combined? &amp;lt;oga&amp;gt; all I heard about was some libarary that they will release, and the reveng stuff &amp;lt;sthen&amp;gt; if you have a shadow buffer, can't you update multiple chars in one go? &amp;lt;mglocker&amp;gt; you could. but then i would need to "collect" lines? &amp;lt;sthen&amp;gt; yep. &amp;lt;mglocker&amp;gt; shudder. &amp;lt;mglocker&amp;gt; sounds ugly. &amp;lt;oga&amp;gt; welcome to graphics, mate. &amp;lt;mglocker&amp;gt; heh &amp;lt;mglocker&amp;gt; i think i quit that area ;-) &amp;lt;drahn&amp;gt; a timeout to gather up several or polling waiting for the previous one to complete? &amp;lt;oga&amp;gt; what information do you have on the hardware itself? &amp;lt;mglocker&amp;gt; http://floe.butterbrot.org/displaylink/doku.php &amp;lt;mglocker&amp;gt; that's what we have. &amp;lt;oga&amp;gt; oh, that's the reveng stuff? &amp;lt;oga&amp;gt; yeah, seen it. &amp;lt;mglocker&amp;gt; there is compression, which doesn't seem to work yet. but i'm not sure if the compression stuff would help us for wscons. &amp;lt;mglocker&amp;gt; since again, you need to setup a bulk xfer for each character. &amp;lt;oga&amp;gt; good for bulk data moves. less good for char-by-char &amp;lt;mglocker&amp;gt; and the thing which make it slow seems to be the setup overhead, not the content itself. &amp;lt;mglocker&amp;gt; yes. &amp;lt;mglocker&amp;gt; i don't know how the driver on windows works, but i don't guess they do something like char-by-char, as we do for wscons. &amp;lt;oga&amp;gt; is this a problem for scrolling, or for typing? &amp;lt;oga&amp;gt; scrolling you can coalesce as long as the timeout is short. &amp;lt;mglocker&amp;gt; the scrolling seems fine. &amp;lt;oga&amp;gt; and it'd be a LOT better than char-by-char. &amp;lt;oga&amp;gt; so it's just typing? &amp;lt;mglocker&amp;gt; the problem is for rendering the chars. e.g. "ls -l". &amp;lt;oga&amp;gt; if you put a timeout say (out of my arse) 10ms. all chars that come in then go out at the same time &amp;lt;oga&amp;gt; no one types that fast, so you see char by char, but ls gets done in one go &amp;lt;mglocker&amp;gt; that would help for sure. &amp;lt;oga&amp;gt; try that. one transfer per char is not going to help you &amp;lt;mglocker&amp;gt; the question is how to implement this in a nice manner ... sigh. &amp;lt;oga&amp;gt; several ways present themselves &amp;lt;oga&amp;gt; font in offscreen memory, when you get a char make blit command for that char to where you want it. multi commands in one bulkt transfer (which is apparently ok) &amp;lt;mglocker&amp;gt; and then send it after the timeout is done (if there is something)? &amp;lt;oga&amp;gt; when the timeout fires, launch off all you've got &amp;lt;oga&amp;gt; exactly &amp;lt;oga&amp;gt; just queue up commands and put htem all in one bulk &amp;lt;oga&amp;gt; the timeout will need tuning to be a good average between latency and bandwidth though &amp;lt;drahn&amp;gt; scrolls are a bit extra info in the queue &amp;lt;mglocker&amp;gt; putting them in one bulk would improve it for sure. &amp;lt;oga&amp;gt; give it a try, and mail me the diff so I can see what you're doing &amp;lt;oga&amp;gt; i'm curious, even though I don't understand the usb stack at all &amp;lt;mglocker&amp;gt; the usb part is not difficult for this device, really. &amp;lt;oga&amp;gt; oh good. means I might get it. &amp;lt;mglocker&amp;gt; "ls -l /etc" takes about 5 seconds now to render. that's not nice ... &amp;lt;mglocker&amp;gt; ok, thanks for the hints. maybe i can get something together which helps ... &amp;lt;oga&amp;gt; for wsfb you'll want to provide a mmap area and sync that as well. that will suck though &amp;lt;oga&amp;gt; horribly &amp;lt;oga&amp;gt; it'll need a proper driver to be usabel for X &amp;lt;mglocker&amp;gt; yes. there are different opinions for the X driver. &amp;lt;mglocker&amp;gt; some say, use wsfb, some say you need to write a own accel driver for X :-) &amp;lt;oga&amp;gt; wsfb iirc mmaps the framebuffer, so you'd need to shadow it and update every X times a second &amp;lt;oga&amp;gt; you'd need the compression at least for it to not suck &amp;lt;mglocker&amp;gt; exactly. &amp;lt;mglocker&amp;gt; jup. and the compression part is missing from the rev. eng. as it looks. &amp;lt;oga&amp;gt; it'd help to know more about the hardware it really would &amp;lt;oga&amp;gt; without compression wsfb will be FAR too slow &amp;lt;mglocker&amp;gt; i believe so, too, now. &amp;lt;oga&amp;gt; no mmap over usb :( &amp;lt;mglocker&amp;gt; no way. &amp;lt;miod&amp;gt; mglocker: can't you copy the font image to offscreen video memory and do screen-to-screen blt to display chars? &amp;lt;miod&amp;gt; that's the canonical trick. &amp;lt;oga&amp;gt; that was my suggestion, with batching to keep from too many bulks. &amp;lt;miod&amp;gt; ah &amp;lt;mglocker&amp;gt; miod: i thought about that, too, but the bulk xfers keep the same. &amp;lt;miod&amp;gt; (not caught up with logs yet) &amp;lt;mglocker&amp;gt; one per bitblit. &amp;lt;mglocker&amp;gt; i've even tested it. &amp;lt;mglocker&amp;gt; it doesn't help at all. it's exactly as slow as before. &amp;lt;miod&amp;gt; can you queue the xfers and schedule a batch of them 25 times per second? &amp;lt;deraadt&amp;gt; you can only request one blt per bulk? &amp;lt;oga&amp;gt; the rev eng says you can do more, hence the batching &amp;lt;deraadt&amp;gt; sounds like a retarded protocol if you can only do one blt per bulk &amp;lt;mglocker&amp;gt; miod: that's what oga suggested. &amp;lt;mglocker&amp;gt; yes you can queue more than one bitblit. &amp;lt;mglocker&amp;gt; but that would be i would need to "collect" chars. what oga said. &amp;lt;mglocker&amp;gt; and fire them on a timeout.&lt;/quote&gt;
    &lt;p&gt;After going back to the drawing board, the driver performance improves, and it becomes worth commiting to the OpenBSD source code repository, so that people can try it and developers can work on improving it.&lt;/p&gt;
    &lt;p&gt;The first stab of a driver hits the tree on may 9th.&lt;/p&gt;
    &lt;p&gt;Three days later, possibly related to that commit, but we'll never know...&lt;/p&gt;
    &lt;quote&gt;Date: Tue, 12 May 2009 20:08:44 +0100 From: Jason Slaughter (DisplayLink) To: Marcus Glocker Cc: Bernie Thompson (DisplayLink) Hello Marcus, Just an update on this: our source code library will be going live this Friday and you'll be able to find it by going to http://displaylink.org around Friday afternoon. We would be happy to send you a few DL-160 based USB to DVI graphics adapters if you think you would get good use out of them. If so, let me know how many you'd like and send me your mailing address. With any luck they'll get to you before the code goes live on displaylink.org. Thank you, Jason&lt;/quote&gt;
    &lt;quote&gt;&amp;lt;mglocker&amp;gt; oho. DisplayLink is answering again. &amp;lt;deraadt&amp;gt; heh &amp;lt;mglocker&amp;gt; the will release the opensource driver this friday. &amp;lt;mglocker&amp;gt; and they want to send me DL-160 based USB to DVI graphic adapters. &amp;lt;oga&amp;gt; the library you mean? &amp;lt;mglocker&amp;gt; jup. &amp;lt;oga&amp;gt; i'm sure i found a dl-160 going for 50 quid on amazon the other day &amp;lt;oga&amp;gt; out of stock though &amp;lt;mglocker&amp;gt; so, who wants to have such a toy? &amp;lt;oga&amp;gt; I'd love one. &amp;lt;mglocker&amp;gt; ok, one for you, one for me, anyone else? &amp;lt;mglocker&amp;gt; Florian Echtler will be glad to hear this. &amp;lt;mglocker&amp;gt; because the compression stuff is hard to crack. &amp;lt;oga&amp;gt; I wonder how complete the library will be &amp;lt;oga&amp;gt; what license, by the way? &amp;lt;mglocker&amp;gt; pretty complete i hope ;-) &amp;lt;oga&amp;gt; hope is definitely the word. &amp;lt;mglocker&amp;gt; they wrote me about the license. some GPL shiz if i remember right ... &amp;lt;oga&amp;gt; well it's a libusb library anyway, so it'll want a rewrite &amp;lt;oga&amp;gt; GPL? if they're targetting X then they should know X uses MIT. &amp;lt;mglocker&amp;gt; *shrug* &amp;lt;mglocker&amp;gt; after the last conversation i don't know how much they really know about X ... &amp;lt;mglocker&amp;gt; probably they put the library out and hope somebody will write the X driver for them ... &amp;lt;oga&amp;gt; time permitting i'll probably write one &amp;lt;oga&amp;gt; it'll be either drm or wscons based depending on what I learn about the hardware &amp;lt;oga&amp;gt; s/wscons/wsfb-style &amp;lt;mglocker&amp;gt; oga: if you going to start on the X driver, we should sync with Florian maybe. it would be probably good if not three people start to write on the X driver when the library has been released I guess ... &amp;lt;oga&amp;gt; yeah. &amp;lt;oga&amp;gt; if we're doing stuff with wscons for the driver though, then it won't work on linux. &amp;lt;oga&amp;gt; I don't know how fbdev works. &amp;lt;mglocker&amp;gt; and he started some sourceforge page today, to find out about the compression stuff more :-) i'll forward him the mail from displaylink now.&lt;/quote&gt;
    &lt;p&gt;Three more days pass, and indeed, on may 15th...&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglock&amp;gt; re &amp;lt;mglock&amp;gt; http://www.freedesktop.org/wiki/Software/libdlo &amp;lt;mglock&amp;gt; the library is online. &amp;lt;mglock&amp;gt; read first feedback from the displaylink rev. eng. mailling-list. &amp;lt;mglock&amp;gt; it seems to be useless. &amp;lt;mglock&amp;gt; since the whole compression stuff is missing. &amp;lt;mglock&amp;gt; need to look at it myself later.&lt;/quote&gt;
    &lt;p&gt;5 hours later:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;oga&amp;gt; mglock: displaylink rev. eng have a mailing list? &amp;lt;oga&amp;gt; where? &amp;lt;mglock&amp;gt; erm, yes. &amp;lt;mglock&amp;gt; https://lists.sourceforge.net/lists/listinfo/displaylink-devel &amp;lt;oga&amp;gt; mglock: thanks &amp;lt;oga&amp;gt; hmmm, glancing at the library it is not that useful &amp;lt;oga&amp;gt; disappointing&lt;/quote&gt;
    &lt;p&gt;2 hours later:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;oga&amp;gt; mein gott! libdlo is ugly &amp;lt;oga&amp;gt; ERR_GOTO(function(args)) ...&lt;/quote&gt;
    &lt;p&gt;and 2 more hours later:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglocker&amp;gt; i've setup another mail to displaylink asking them why they didn't include the compression stuff in their library :-)&lt;/quote&gt;
    &lt;p&gt;On the same day, on the displaylink-devel list:&lt;/p&gt;
    &lt;quote&gt;Date: 2009-05-15 13:59:30 From: Florian Echtler To: displaylink-devel mailing list Subject: Re: [Displaylink-devel] News from Displaylink &amp;gt; Sigh, pretty disappointing. LGPL licensed first and then it doesn't &amp;gt; contain the compression stuff. What do the think how people can &amp;gt; write an usable X.Org driver with this? I gonna ask them. All right, this is getting a bit ridiculous. Looking in dlo_usb.c, they labeled the "set encryption" request as "select channel", and the "null-key" for disabling encryption is called STD_CHANNEL. Okay, maybe just terminology. However, in dlo_data.h, there's suddenly always an DLO_MODE_ENABLE_* sequence (never seen that before), and the DLO_MODE_DATA stuff looks totally random. Hey, look, in mode_select(), it's always sending the ENABLE sequence to the "select channel" command, then the binary blob and then DLO_MODE_POSTAMBLE. Hmm, this POSTAMBLE looks just like the STD_CHANNEL default key! Oh, what a surprise, the register sets for the modes are _still_ encrypted - never mind that we can decrypt this since Christmas last year. Displaylink, I really don't get this. I'll have a closer look at the way the stride registers are implemented; this is one of the smaller parts which I still would like to figure out, but in general, this library is absolutely useless to the wider opensource community. It's obviously designed for some embedded shops which want to use it for non-realtime stuff like LCD signs etc., but it's just ridiculous to still try and obfuscate parts of an opensource library. Florian -- 0666 - Filemode of the Beast&lt;/quote&gt;
    &lt;p&gt;Two more weeks pass, during which Florian Echtler continues his reverse engineering efforts and figures out the compression scheme used by the DisplayLink chip.&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglocker&amp;gt; for those who are interessted in the displaylink stuff ... the compression has been cracked. florian echtler did a library and showed it to the displaylink guys ;-) &amp;lt;mglocker&amp;gt; http://lists.freedesktop.org/archives/libdlo/2009-May/000092.html &amp;lt;mglocker&amp;gt; http://floe.butterbrot.org/external/tubecable-0.1.tar.bz2 &amp;lt;mglocker&amp;gt; ~mglocker/dldemo2_mglocker.tar.gz &amp;lt;mglocker&amp;gt; if you want to have a kind of C-style demo for the compression.&lt;/quote&gt;
    &lt;p&gt;Minor fixes to the udl driver occur on june 1st, then there is not much activity until Marcus resumes working on it, in order to add compression support.&lt;/p&gt;
    &lt;p&gt;On august 14th, he mentions the need for a compression table which could be stored on the filesystem, rather than in the kernel image:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglocker&amp;gt; anyone mind if we would keep a 300kB huffman table in /etc/firmware? &amp;lt;miod&amp;gt; that's not really firmware... can't you generate the table at runtime? is this for udl evilness? &amp;lt;mglocker&amp;gt; jup, for the huffman pixel difference compression. i could store the table into an *.h file, but i'm not sure if this is what we want. &amp;lt;mglocker&amp;gt; i don't think we can "generate" the table. &amp;lt;miod&amp;gt; but yes, although it's not technically firmware, it's loadable data, so why not &amp;lt;mglocker&amp;gt; yeah. it's probably worth an exception in that case. &amp;lt;mglocker&amp;gt; i can draw some compressed stuff already, but some issues left to fix.&lt;/quote&gt;
    &lt;p&gt;And on august 25th, compression support is added to the driver.&lt;/p&gt;
    &lt;p&gt;As more and more developers are trying the driver on as many platforms as possible, we start hitting situations where heavy screen adjustments would cause the output to stall, or some display updates to get lost.&lt;/p&gt;
    &lt;p&gt;Investigating these showed that the device was overflowed with requests, and needed time to process all the pending operations until further requests could be made.&lt;/p&gt;
    &lt;p&gt;This was not very different from a serial line link, where the serial chip has a small (and sometimes nonexistent) FIFO queue, and no more characters can be transmitted when it gets full, until the characters get transmitted over the wire.&lt;/p&gt;
    &lt;p&gt;For serial links, the kernel handles this nicely, by forcing writers to sleep when the FIFO gets full, and waking them when space becomes available in the FIFO.&lt;/p&gt;
    &lt;p&gt;But for display terminal emulations, there was no such thing, because it was assumed that every display operation (output a character, draw the cursor shape, scroll the display in any direction) could be done without having to wait.&lt;/p&gt;
    &lt;p&gt;And in fact, until the DisplayLink driver came into use, this was the case: display drivers either had full access to the display memory and could do the required changes directly in memory or, as e.g. for the Vax gpx driver [which I will write the story of soon...], by instructing the graphics controller to perform these changes.&lt;/p&gt;
    &lt;p&gt;But here, over the USB bus, bandwidth has to be shared with all the other USB devices on the controller, and the USB controller itself might not be able to queue enough requests for the udl needs - in other words, this is similar to the serial FIFO.&lt;/p&gt;
    &lt;p&gt;The graphics display being, from the kernel point of view, a special case of serial line, we could benefit from the FIFO behaviour, even though this had never been the case.&lt;/p&gt;
    &lt;p&gt;So a cheap and easy way to solve the "display gets overflowed with requests" problem would be to simply let the display operation routines (draw the cursor, paint a character...), which until now where `void` operations, return a value letting their caller know whether they had been able to perform the requested operation or not. The DisplayLink specific implementation of these requests could then return failure when the device FIFO is full, and let the upper layers know that they need to wait and force the process currently writing to the display, to sleep.&lt;/p&gt;
    &lt;p&gt;This would be a large, but mostly mechanical, change to all the display drivers in the OpenBSD source tree.&lt;/p&gt;
    &lt;p&gt;On august 30th, I suggested going in this direction:&lt;/p&gt;
    &lt;quote&gt;Date: Sun, 30 Aug 2009 20:42:29 +0000 From: Miod Vallat To: private mailing list Subject: wsdisplay asynchronous processing After discussing udl(4) behaviour with mglocker@, we came to the following thoughts which I believe are worth sharing. wscons - and its wsdisplay output part - has been written 10 years ago with tga(4) and vga(4) style bitmapped devices in mind, with synchronous operations. This assumption was true, until we started to support video devices on which the video memory is not directly accessible. Examples of this are cfxga(4), gpx(4) on vax, and udl(4). The first two such drivers have been coerced to fit the synchronous model, because sending commands to the hardware was fast and did only involve the device registers. udl(4), however, is completely alien to this. Commands are sent with USB pipes, there might be other devices on the USB bus, and processing is asynchronous in nature. Now, if you look at wsdisplay, there are two conditions upon which wsdisplay will want to update the display contents: - userland writes to the wsdisplay terminal. wsdisplay is invoked from the tty layer, and has a process context, so it can sleep. - kernel writes to the console device. wsdisplay can not assume anything. So if we are able to flag devices such as udl(4) as not being able to be a console output device, then it will know that it can sleep at the wsdisplay level. Why am I talking about sleeping? Because udl(4) is currently the only wsdisplay(4) driver unable to behave synchronously. In order to complete its operation, it needs to get fifo resources and whatnot, and if none of them are available, there won't be any new resources available until the usb stack has a chance to run: udl(4) needs to sleep. Now if udl(4) is allowed to sleep, and the driver&amp;lt;-&amp;gt;wsdisplay interfaces are modified so that a driver can return EAGAIN if it is not a console device, then wsdisplay(4) can sleep. Problem solved.&lt;/quote&gt;
    &lt;p&gt;and since the best way to figure out if such a proposal is worth doing is to write a proof-of-concept, the next day I shared a diff with Marcus.&lt;/p&gt;
    &lt;p&gt;But that diff was larger and trickier that what my previous message implied.&lt;/p&gt;
    &lt;p&gt;The reason for that, is that the graphics terminal is not simply a "line printer on a CRT". (and, writing this in 2025, I suppose some of my younger readers will not be familiar with Cathode Ray Tube displays)&lt;/p&gt;
    &lt;p&gt;An important improvement of CRT displays above line printers is that most CRT terminals have an addressable cursor position; this opens the road towards fancy displays (nowadays with colours!), first to implement IBM 3270 terminal emulators, later for more generic needs, thanks to the termcap and/or terminfo abstractions, and eventually the curses library.&lt;/p&gt;
    &lt;p&gt;The OpenBSD workstation console terminal emulation tries to mimic two well-known console devices, the Digital VT220 terminal (minus several seldom used features difficult to implement cleanly, such as double-width characters) on most platforms, and the Sun console (with extra features such as colour) on sparc and sparc64 ports. (I tried to have the luna88k port, which defaults to black on white display like the Sun systems, to use the sun terminal emulation, but got outpowered).&lt;/p&gt;
    &lt;p&gt;Both these terminal emulations have in common that they recognize specific escape sequences, e.g. to change the cursor position, change output colours, or other specific operations. Also, simply outputting a regular character expands to at least three display operations: hide the cursor, draw the character, and draw the cursor in its new position; and if the character had been the last on the last line, the display needs to scroll, which involves one more operation.&lt;/p&gt;
    &lt;p&gt;If display drivers were able to fail any operations, as allowed in my proposal, we could end up with a particular output operation processed only partly. But the tty layer in the kernel has no way to know that a character has been, sort of, "partially output". In this layer, a character has either been output, or needs to be output, and nothing in-between. Any finer-grained state needs to be maintained in a lower layer, such as the vt220 emulation code.&lt;/p&gt;
    &lt;p&gt;So, in addition to allowing display drivers to fail operations, I wrapped the terminal emulation processing into what I called an "abort state", remembering at which point we encountered a failure, so that attempting to output a character would skip the operations which had succeeded already.&lt;/p&gt;
    &lt;p&gt;With my changes, a character output would only be "validated" if all the display operations it would cause had been successful. If not, the process writing to the display would be forced to sleep, until the display driver reports it is able to process requests again. Processing of the display operations would note which operations had been successful, so as to skip them and only perform the operations which had failed or had no chance to start earlier.&lt;/p&gt;
    &lt;quote&gt;Date: Mon, 31 Aug 2009 22:00:27 +0000 From: Miod Vallat To: Marcus Glocker Subject: early wscons `ok to stall' diff This should be enough for an i386 or amd64 kernel to compile. Many frame buffer drivers still need to be modified due to interface and prototypes changes. How does it work? Well, this adds an error path from the display driver to the tty layer. So we have this path: 1. void wsdisplay_emulops routines now return values. The driver implementing them can return 0 if it did the work, or nonzero (preferrably EAGAIN) if it couldn't. Note that generic rasops routines, accessing frame buffer memory, never fail and always return zero. 2. the return values of the emulops are now tested in the wsdisplay emulation code. This is the horrible part with a lot of changes, which will need careful review. 3. I designed this so that, when the emulops return an error, the emulation state machine is moved back to a sane state, allowing the operation to be tried again later. This involves undoing logical cursor moves, and other internal state changes. Note the code currently assumes an operation involving several emulops can fail in the middle and be restarted from the beginning - this is wrong, e.g. when scrolling the tty, since we copy rows and then clear the bottom row. If the copy works but the clearing fails, we'll restart with the copy. I am aware of this and working on an `abort state' part of the emulation state machine (which is currently the FALSE_ABORT bit in the per-emulation flags, but needs to move into its own thing). (This is why this is an alpha diff...) 4. The error condition detected by the emulation causes the tty write to abort early. The MI wsdisplay code will now know how many chars have been processed, and if it detected an early abort, it will not try to write more characters, even if there are any left in the tty queue. 5. The same function already has logic to schedule a timeout if more tty data is pending. This timeout will try to feed the driver more work, but until it fires the driver can hopefully get some interrupts and gather resources to do so. What is left to do: 1. Update all MD frame buffer drivers (mechanical). 2. Finish the abort state design and correctly recover from a partial operation. 3. Update udl to return EAGAIN in the emulops. Known problems which won't be fixed soon: 1. Some operations do not come from the tty layer, but by keyboard events (emulation reset sequence), ioctl or timeouts (screen burner). We do not necessarily have a process context there, so sleeping is not an option. I need to extend some interfaces for the affected routines to know whether the caller can recover automatically (tty context), or not, and if not, whether it's ok to sleep or not. 2. There is no way, yet, for the driver which has returned EAGAIN to cause the tty timeout to be triggered earlier (i.e. as soon as it regains resources). I'll think about it eventually. Miod (and now time for some zzz)&lt;/quote&gt;
    &lt;p&gt;The next day, I received the best testimonial ever for a diff:&lt;/p&gt;
    &lt;quote&gt;&amp;lt;mglock&amp;gt; hi from udl over wscons with initial EAGAIN support :-) &amp;lt;mglock&amp;gt; miod is evil.&lt;/quote&gt;
    &lt;p&gt;After more testing, on september 1st, a new version of that diff was shared:&lt;/p&gt;
    &lt;quote&gt;Date: Tue, 1 Sep 2009 20:19:02 +0000 From: Miod Vallat To: private mailing list Subject: Re: wsdisplay asynchronous processing In case people are interested, I have a monster diff (which will be split in 4 different pieces), which implements error path from the display drivers up to the tty layer, so that the driver can cause tty output to stop if it is overflowed. The tty layer (well, the wsdisplay tty code) will then nicely recover from this, and everything is fine. This diff has the disavantage of adding about 1KB of code to the kernel (for kernels with vt100 emulation), so this might be a problem for the floppies. And there is no way to disable this if SMALL_KERNEL. Unless you want to dive in your own sea of macro hell filled with sharks. Due the large size of the diff (about 200KB, affecting 51 files), I will not append it to this mail. People interested in it can find it in cvs:~miod/wscons-stall2.vari Note that, for it to be really useful on udl(4) devices - since they are the reason for this work - you need another diff from mglocker@, adding the necessary EAGAIN code in udl(4). $ wc wscons-stall2.vari 7017 26187 194603 wscons-stall2.vari Miod&lt;/quote&gt;
    &lt;p&gt;The monster diff started with the following description:&lt;/p&gt;
    &lt;quote&gt;This diff is large because many frame buffer drivers need to be modified due to interface and prototype changes. How does it work? Well, this adds an error path from the display driver to the tty layer. So we have this path: 1. void wsdisplay_emulops routines now return values. The driver implementing them can return 0 if it did the work, or nonzero (preferrably EAGAIN or EINTR) if it couldn't. Note that generic rasops routines, accessing frame buffer memory, never fail and always return zero. 2. the return values of the emulops are now tested in the wsdisplay emulation code. This is the horrible part with a lot of changes, which will need careful review. 3. I designed this so that, when the emulops return an error, the emulation state machine is moved back to a sane state, allowing the operation to be tried again later. This involves undoing logical cursor moves, and other internal state changes. Note there might be bugs in the undoing so far, I need to review this carefully. And test too (-: There are comments in wsemulvar.h trying to explain how I keep track of failures occuring in the middle of a `character' (from the tty layer point of view) output. 4. The error condition detected by the emulation causes the tty write to abort early. The MI wsdisplay code will now know how many chars have been processed, and if it detected an early abort, it will not try to write more characters, even if there are any left in the tty queue. 5. The same function already has logic to schedule a timeout if more tty data is pending. This timeout will try to feed the driver more work, but until it fires the driver can hopefully get some interrupts and gather resources to do so. Note that it is not necessary to implement a faster output resume path (e.g. if the driver gets an interrupt and frees resources), as the timeout will run only 8ms later (1/128 second). Keep in mind the human persistance of vision is about 1/25 second, so in the blink of an eye the wsdisplay code can resume stalled output several times. Problems left with this code: 1. You may notice resetop() does not check for emulops failure. This because this is an out-of-tty-layer processing (but ioctl issued to the tty device). I know how to make it able to recover, but this will need a few more emulops prototypes changes, and I would like to keep the focus of this diff minimal (har, har), i.e. trying to only address one problem. A later diff will address that area. 2. The same comments apply to the screen burner code. Again, I have plans for this. How I intend to split this work in individual commits: 1. internal wsemul changes to change the state machine functions from returning u_int to returning void (and updating emul state structs directly), so that they can later be changed again to return errors. (no functional change, but little code growth) 2. emulops prototype changes (and all the rasops / driver part of this diff). (again, no functional change, but little code growth) 3. wsemul_ops change of output() to return the number of chars consumed, and the corresponding logic in wsdisplaystart(), with the emulation code returning the number of chars it has been given (again, no functional change, but little code growth) 4. the error path handling in the emulation code, i.e. the evil part of this diff.&lt;/quote&gt;
    &lt;p&gt;Of course, testing exposed a few bugs in that diff, which led to a new version:&lt;/p&gt;
    &lt;quote&gt;Date: Wed, 2 Sep 2009 16:17:06 +0000 From: Miod Vallat To: private mailing list Subject: Re: wsdisplay asynchronous processing New diff fixing a few bugs in the previous diff (description of changes at the head of the new diff). cvs:~miod/wscons-stall3.vari $ wc wscons-stall3.vari 7074 26494 196861 wscons-stall23vari Miod&lt;/quote&gt;
    &lt;p&gt;And while writing this, I am dissatisfied with past me. It was not a wise idea to put the details in a file which is now long gone, and I should have put them both in the file and in the email. But I did not think that future me would want to tell this story, years later.&lt;/p&gt;
    &lt;p&gt;Fortunately, it turns out that I had sent that diff directly to Marcus minutes later:&lt;/p&gt;
    &lt;quote&gt;Date: Wed, 2 Sep 2009 16:13:51 +0000 From: Miod Vallat To: Marcus Glocker Subject: latest wscons diff This is diff #3. Changes since last diff: - rearrange changes to wsdisplaystart() so as not to introduce a new goto. - minor simplification in wsemul_sun when backing out state changes because of failed scrollup operation. - rearrange some double-wide array updates in vt100 to be able to correctly recover from operations aborted in the middle. This double width feature is something noone uses anyway. - wrap the COPYCOLS and ERASECOLS operations in vt100 within WSEMULOP so that they will not be reissued by mistake if failure occurs after they're done. This ought to have been in the previous diff but I forgot to do this.&lt;/quote&gt;
    &lt;p&gt;And some time later:&lt;/p&gt;
    &lt;quote&gt;Date: Thu, 3 Sep 2009 22:00:06 +0000 From: Miod Vallat To: Marcus Glocker Subject: Re: udl Even better, with a diff that still compiles after the untested last minute change. This is diff #4. Changes since last diff: - removed udl.c changes, get them from mglocker@ - fixed an unitialized variable in wsemul_vt100_output() causing cursor image display to sometimes be skipped. - extended the abort state with four different states (ok, failed to display the cursor image, failed to jump scroll, failed a regular operation) instead of two (ok/fail) and having the `fail cursor' a particular state of failure. This allows me to make things a bit more clean (arguably) and two fix two important bugs: + after a regular failure, jump scroll would be attempted before the other operation; if the failure had happened after N operations we would then skip N operations during the jump scroll (usually causing the scroll not to happen, so lines would be overwritten instead of scrolling). + after a jump scroll failure, we need to retry it with the same number of lines as the failed operation, so that the copy/erase parts of the scrolling operation are consistent with each other.&lt;/quote&gt;
    &lt;p&gt;Eventually Marcus confirms it works:&lt;/p&gt;
    &lt;quote&gt;From: Miod Vallat To: Marcus Glocker Subject: Re: udl &amp;gt; This diff works pretty fine for me! I can't spot any bugs anymore yet, &amp;gt; even when running in a screen session with crazzy apps like irssi and &amp;gt; mutt. Excellent.&lt;/quote&gt;
    &lt;p&gt;Having been able to wrap these operations in specfic macros to hide the note-and-restart logic, this allowed installation media kernels (which would not embed the DisplayLink driver) to use the previous "nothing can fail" logic, in order not to grow these kernels and still allow them to fit on 3"√Ç¬Ω floppy installation media. This work eventually got commited on september 5th, in multiple steps and then some...&lt;/p&gt;
    &lt;p&gt;...and udl made use of it immediately.&lt;/p&gt;
    &lt;p&gt;On september 11th, this allowed to nicely fix a diresome situation.&lt;/p&gt;
    &lt;p&gt;And since I am only human, a small bugfix was needed on the 14th.&lt;/p&gt;
    &lt;p&gt;After these changes, there have been no problem reports with DisplayLink devices.&lt;/p&gt;
    &lt;p&gt;Later this month, an X server, based upon the "damage" extension which describes areas which need to be redrawn, was also added to the OpenBSD source tree, and support for the DisplayLink devices was now complete.&lt;/p&gt;
    &lt;p&gt;This allowed "serial console-only" platforms such as the armish and landisk ports to use a graphics console and run an X server.&lt;/p&gt;
    &lt;p&gt;And even if there had been no X server support, the DisplayLink driver forced the console code to face new challenges and solve them in a way which will benefit future drivers.&lt;/p&gt;
    &lt;p&gt;Today, DisplayLink still exists as part of Synaptics, and their most recent chips are supported neither by Linux nor by OpenBSD with open source drivers. Synaptics provides a binary driver for Ubuntu, which to this day hasn't been reverse engineered, yet.&lt;/p&gt;
    &lt;p&gt;The usefulness of these devices has apparently gone away, people do not seem to be interested by these devices anymore those days.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://miod.online.fr/software/openbsd/stories/udl.html"/><published>2025-12-26T00:32:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388213</id><title>MiniMax M2.1: Built for Real-World Complex Tasks, Multi-Language Programming</title><updated>2025-12-26T12:20:48.716052+00:00</updated><content>&lt;doc fingerprint="7a878369f356732f"&gt;
  &lt;main&gt;
    &lt;p&gt;Âú®10ÊúàÂ∫ïÁöÑM2‰∏≠ÔºåÊàë‰ª¨‰∏ªË¶ÅËß£ÂÜ≥Ê®°ÂûãÊàêÊú¨ÂíåÊ®°ÂûãÂºÄÊîæÊÄßÁöÑÈóÆÈ¢ò„ÄÇÂú®M2.1‰∏≠ÔºåÊàë‰ª¨Ëá¥Âäõ‰∫éÊèêÂçáÁúüÂÆû‰∏ñÁïåÂ§çÊùÇ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºöÈáçÁÇπËÅöÁÑ¶‰∫éÊõ¥Â§öÁºñÁ®ãËØ≠Ë®ÄÂíåÂäûÂÖ¨Âú∫ÊôØÁöÑÂèØÁî®ÊÄßÔºåÂπ∂Âú®Ëøô‰∏™È¢ÜÂüüÂÅöÂà∞ÊúÄÂ•ΩÁöÑÊ∞¥Âπ≥„ÄÇ&lt;/p&gt;
    &lt;p&gt;MiniMax M2.1 ÂÖ∑‰ΩìÊ®°Âûã‰∫ÆÁÇπÂ¶Ç‰∏ã:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;ÂçìË∂äÂ§öÁºñÁ®ãËØ≠Ë®ÄËÉΩÂäõ&lt;/p&gt;
        &lt;p&gt;ËøáÂéªÂæàÂ§öÊ®°Âûã‰∏ªË¶ÅÂõ¥Áªï Python ‰ºòÂåñ, ‰ΩÜÁúüÂÆû‰∏ñÁïåÁöÑÁ≥ªÁªüÂæÄÂæÄÊòØÂ§öËØ≠Ë®ÄÂçè‰ΩúÁöÑÁªìÊûú„ÄÇ&lt;/p&gt;
        &lt;p&gt;Âú® M2.1 ‰∏≠, Êàë‰ª¨Á≥ªÁªüÊÄßÊèêÂçá‰∫Ü Rust / Java / Golang / C++ / Kotlin / Objective-C / TypeScript / JavaScript Á≠âËØ≠Ë®ÄÁöÑËÉΩÂäõ, Â§öËØ≠Ë®Ä‰ªªÂä°Êï¥‰ΩìË°®Áé∞ËææÂà∞‰∏öÂÜÖÈ¢ÜÂÖàÊ∞¥Âπ≥, Ë¶ÜÁõñ‰ªéÂ∫ïÂ±ÇÁ≥ªÁªüÂà∞Â∫îÁî®Â±ÇÂºÄÂèëÁöÑÂÆåÊï¥ÈìæË∑Ø„ÄÇ&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WebDev ‰∏é AppDevÔºöËÉΩÂäõ‰∏éÁæéÂ≠¶ÁöÑÊï¥‰ΩìË∑ÉËøÅ&lt;/p&gt;
        &lt;p&gt;ÈíàÂØπ‰∏öÁïåÊôÆÈÅçÂ≠òÂú®ÁöÑÁßªÂä®Á´ØÂºÄÂèëÁü≠Êùø, M2.1 ÊòæËëóÂä†Âº∫‰∫ÜÂéüÁîü Android / iOS ÂºÄÂèëËÉΩÂäõ„ÄÇ&lt;/p&gt;
        &lt;p&gt;ÂêåÊó∂, Êàë‰ª¨Á≥ªÁªüÊÄßÊèêÂçá‰∫ÜÊ®°ÂûãÂú® Web ‰∏é App Âú∫ÊôØ‰∏≠ÁöÑËÆæËÆ°ÁêÜËß£‰∏éÁæéÂ≠¶Ë°®ËææËÉΩÂäõ, ËÉΩÂ§üÂá∫Ëâ≤Âú∞ÊûÑÂª∫Â§çÊùÇ‰∫§‰∫í„ÄÅ3DÁßëÂ≠¶Âú∫ÊôØÊ®°Êãü‰∏éÈ´òË¥®ÈáèÂèØËßÜÂåñË°®Ëææ, Êé®Âä® vibe coding Êàê‰∏∫ÂèØÊåÅÁª≠„ÄÅÂèØ‰∫§‰ªòÁöÑÁîü‰∫ßÂÆûË∑µ„ÄÇ&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Â§çÂêàÊåá‰ª§Á∫¶ÊùüÊèêÂçáÔºåÂäûÂÖ¨Âú∫ÊôØÂèò‰∏∫ÂèØËÉΩ&lt;/p&gt;
        &lt;p&gt;‰Ωú‰∏∫ÂºÄÊ∫êÊ®°Âûã‰∏≠ÁéáÂÖàÁ≥ªÁªüÊÄßÂºïÂÖ• Interleaved Thinking ÁöÑÊ®°ÂûãÁ≥ªÂàó, M2.1 systematic problem-solving ËÉΩÂäõÂÜçÊ¨°ÂçáÁ∫ß„ÄÇ&lt;/p&gt;
        &lt;p&gt;Ê®°Âûã‰∏ç‰ªÖÂÖ≥Ê≥®‰ª£Á†ÅÊâßË°åÊòØÂê¶Ê≠£Á°Æ, ÂêåÊó∂ÂÖ≥Ê≥®Ê®°ÂûãÂØπ‚ÄúÂ§çÂêàÊåá‰ª§Á∫¶Êùü‚ÄùÁöÑÊï¥ÂêàÊâßË°åËÉΩÂäõ, Âú®ÁúüÂÆûÂäûÂÖ¨Âú∫ÊôØÂÖ∑Â§áÊõ¥È´òÁöÑÂèØÁî®ÊÄß„ÄÇ&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Êõ¥ÁÆÄÊ¥ÅÈ´òÊïàÁöÑÂõûÂ§ç&lt;/p&gt;
        &lt;p&gt;Áõ∏ÊØî M2, MiniMax-M2.1 ÁöÑÊ®°ÂûãÂõûÂ§ç‰ª•ÂèäÊÄùÁª¥ÈìæÊõ¥Âä†ÁÆÄÊ¥Å, Âú®ÂÆûÈôÖÁºñÁ®ã‰∏é‰∫§‰∫í‰ΩìÈ™å‰∏≠, ÂìçÂ∫îÈÄüÂ∫¶ÊòæËëóÊèêÂçá, Token Ê∂àËÄóÊòéÊòæ‰∏ãÈôç, Âú® AI Coding‰∏éAgentÈ©±Âä®ÁöÑËøûÁª≠Â∑•‰ΩúÊµÅ‰∏≠Êõ¥Âä†ÊµÅÁïÖÂíåÈ´òÊïà„ÄÇ&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Âá∫Ëâ≤ÁöÑ Agent / Â∑•ÂÖ∑ËÑöÊâãÊû∂Ê≥õÂåñËÉΩÂäõ&lt;/p&gt;
        &lt;p&gt;M2.1 Âú®ÂêÑÁ±ªÁºñÁ®ãÂ∑•ÂÖ∑‰∏é Agent Ê°ÜÊû∂‰∏≠ÂùáÊúâÂá∫Ëâ≤Ë°®Áé∞„ÄÇÂú® Claude Code„ÄÅDroid (Factory AI)„ÄÅCline„ÄÅKilo Code„ÄÅRoo Code„ÄÅBlackBox Á≠âÂ∑•ÂÖ∑‰∏≠Â±ïÁé∞‰∏ÄËá¥‰∏îÁ®≥ÂÆöÁöÑÊïàÊûú, Âπ∂ÂØπ Skill.md„ÄÅClaude.md / agent.md / cursorrule„ÄÅSlash Command Á≠â Context ManagementÊú∫Âà∂Êèê‰æõÂèØÈù†ÊîØÊåÅ„ÄÇ&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;È´òË¥®ÈáèÂØπËØùÂíåÂÜô‰Ωú&lt;/p&gt;
        &lt;p&gt;M2.1 ‰∏çÂÜçÂè™ÊòØ‚Äú‰ª£Á†ÅËÉΩÂäõÊõ¥Âº∫‚Äù, Âú®Êó•Â∏∏ÂØπËØù„ÄÅÊäÄÊúØËØ¥Êòé‰∏éÂÜô‰ΩúÂú∫ÊôØ‰∏≠, ‰πüËÉΩÊèê‰æõÊõ¥ÂÖ∑ÁªÜËäÇ‰∏éÁªìÊûÑÊÄßÁöÑÂõûÁ≠î„ÄÇ&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Âü∫ÂáÜÊµãËØïÊ¶ÇËßà&lt;/head&gt;
    &lt;p&gt;MiniMax-M2.1 Âú® VIBE ÁªºÂêàÊ¶úÂçï‰∏≠Ë°®Áé∞ÂçìË∂äÔºå‰ª•Âπ≥Âùá 88.6 ÂàÜÁöÑÊàêÁª©Â±ïÁé∞‰∫ÜÊé•ËøëClaude Opus 4.5ÁöÑÂÖ®Ê†àÊûÑÂª∫ËÉΩÂäõÔºåÂπ∂Âú®Âá†‰πéÊâÄÊúâÂ≠êÈõÜ‰∏äÈÉΩÊòæËëó‰ºò‰∫éClaude Sonnet 4.5„ÄÇ&lt;/p&gt;
    &lt;head rend="h3"&gt;‰ΩøÁî®ËÄÖËØÑ‰ª∑&lt;/head&gt;
    &lt;p&gt;Êàë‰ª¨ÈùûÂ∏∏ÊúüÂæÖÂÉè M2.1 ËøôÊ†∑Âº∫Â§ßÁöÑÂºÄÊ∫êÊ®°ÂûãÔºåÂÆÉÂú®ÂêÑÁ±ªËΩØ‰ª∂ÂºÄÂèë‰ªªÂä°‰∏≠ÈÉΩËÉΩÂ∏¶Êù•ÂâçÊ≤øÊ∞¥ÂáÜÁöÑË°®Áé∞ÔºåÁîöËá≥ËøòËÉΩÂú®ÈÉ®ÂàÜÂú∫ÊôØ‰∏ãÊØîÂ§¥ÈÉ®Èó≠Ê∫êÊ®°ÂûãÊõ¥Â•Ω„ÄÇÂºÄÂèëËÄÖÂ∫îÂΩìÊã•ÊúâÈÄâÊã©ÊùÉÔºåËÄå M2.1 Ê≠£ÊòØÂ§ßÂÆ∂ÊÄ•ÈúÄÁöÑÈÇ£‰∏™‰ºòË¥®ÈÄâÈ°πÔºÅ&lt;/p&gt;
    &lt;p&gt;Eno Reyes&lt;/p&gt;
    &lt;p&gt;Co-Founder, CTO of Factory&lt;/p&gt;
    &lt;p&gt;MiniMax M2.1 Âú®ÂèØËØªÊÄß‰∏éÊÉØÁî®ÁªìÊûÑÊñπÈù¢‰∏éÁîü‰∫ßÁ∫ßÂ∑•Á®ãË¶ÅÊ±ÇÈ´òÂ∫¶Â•ëÂêàÔºåÂú® Go„ÄÅRust„ÄÅC++ Á≠âÂ§öËØ≠Ë®ÄÂú∫ÊôØ‰∏ãÂùáË°®Áé∞Á®≥ÂÆö„ÄÇÁ≤æÁÇºÁöÑ‰∫§ÈîôÊé®ÁêÜÊú∫Âà∂ÊòæËëóÂéãÁº©ÈÄªËæëË∑ØÂæÑÔºåÂáèÂ∞ëÂÜó‰ΩôÊ≠•È™§ÔºåËÆ©Â§öÊñá‰ª∂ÈáçÊûÑ‰∏éÁº∫Èô∑‰øÆÂ§çÁ≠âÂ§çÊùÇ‰ªªÂä°Âæó‰ª•Êõ¥È´òÁ≤æÂ∫¶ÂÆåÊàê„ÄÇÊõ¥ÂèØË¥µÁöÑÊòØÔºåM2.1 Âú®ÊøÄÊ¥ªÂèÇÊï∞ÈáèÂèóÈôêÁöÑÂâçÊèê‰∏ã‰ªçËÉΩÊèê‰æõÂèØÈù†ÊÄßËÉΩÔºå‰∏∫Â§ßËßÑÊ®°Êô∫ËÉΩ‰ΩìÁºñÁ†ÅÊµÅÁ®ãÊèê‰æõ‰∫ÜÂÖºÈ°æÊïàËÉΩ‰∏éËµÑÊ∫êÂà©Áî®ÁöÑÂùáË°°ÊñπÊ°à„ÄÇÊàë‰ª¨ÊúüÂæÖ‰∏é MiniMax Âõ¢ÈòüÂ±ïÂºÄÊåÅÁª≠„ÄÅÁ¥ßÂØÜÁöÑÂêà‰ΩúÔºåÂú® Fireworks Âπ≥Âè∞ÂêåÊ≠•ÊîØÊåÅÂÖ∂ÊúÄÊñ∞ÂàõÊñ∞ÊàêÊûúÔºÅ&lt;/p&gt;
    &lt;p&gt;Benny Chen&lt;/p&gt;
    &lt;p&gt;Co-Founder of Fireworks&lt;/p&gt;
    &lt;p&gt;MiniMax M2 Á≥ªÂàóÂú®‰ª£Á†ÅÁîüÊàêËÉΩÂäõ‰∏äË°®Áé∞Á™ÅÂá∫ÔºåËøáÂéªÂá†‰∏™ÊúàÂ∑≤ËøÖÈÄüË∑ªË∫´ Cline Âπ≥Âè∞ÊúÄÂèóÊ¨¢ËøéÁöÑÊ®°Âûã‰πãÂàó„ÄÇM2.1 ÂÜçÊ¨°ÂÆûÁé∞ËÉΩÂäõÂ±ÇÈù¢ÁöÑÊòæËëóË∑ÉÂçáÔºåÊàë‰ª¨ÊúüÂæÖ‰∏é MiniMax Âõ¢ÈòüÁªßÁª≠Ê∑±ÂåñÂêà‰ΩúÔºåÂÖ±ÂêåÊé®Ëøõ AI ÁºñÁ†ÅÊäÄÊúØÁöÑÊºîËøõ„ÄÇ&lt;/p&gt;
    &lt;p&gt;Saoud Rizwan&lt;/p&gt;
    &lt;p&gt;Founder, CEO of Cline&lt;/p&gt;
    &lt;p&gt;Êàë‰ª¨ÂØπM2.1ÁöÑÂèëÂ∏ÉËÄåÂÖ¥Â•ãÔºÅÊàë‰ª¨ÁöÑÁî®Êà∑Â∑≤ÁªèÁ¶ª‰∏çÂºÄMiniMaxÊèê‰æõÁöÑÊúÄ‰ºòÁßÄÁöÑÁºñÁ®ãËæÖÂä©ËÉΩÂäõÂíåÈ´òÊÄß‰ª∑ÊØîÔºåÂÜÖÊµãÊòæÁ§∫ÔºåM2.1Âú®Êû∂ÊûÑËÆæËÆ°„ÄÅÊúçÂä°ÁºñÊéí„ÄÅ‰ª£Á†ÅËØÑÂÆ°Áõ¥Ëá≥ÈÉ®ÁΩ≤‰∏äÁ∫øÁöÑÂÖ®ÈìæË∑ØÁéØËäÇ‰∏≠ÂùáË°®Áé∞‰ºòÂºÇÔºåÈÄüÂ∫¶‰∏éËµÑÊ∫êÊïàÁéáÂùáÂ§Ñ‰∫éÈ¢ÜÂÖàÊ∞¥Âπ≥„ÄÇ&lt;/p&gt;
    &lt;p&gt;Scott Breitenother&lt;/p&gt;
    &lt;p&gt;Co-Founder, CEO of Kilo&lt;/p&gt;
    &lt;p&gt;Êàë‰ª¨ÁöÑÁî®Êà∑ÈùûÂ∏∏ÂñúÊ¨¢ MiniMax M2 Âú®ÁºñÁ†ÅËÉΩÂäõ‰∏éÊïàÁéáÊñπÈù¢ÁöÑË°®Áé∞„ÄÇÊúÄÊñ∞ÂèëÂ∏ÉÁöÑ M2.1 Âú®Ê≠§Âü∫Á°Ä‰∏äÂÆûÁé∞‰∫ÜÈÄüÂ∫¶‰∏éÂèØÈù†ÊÄßÁöÑÂÆûË¥®ÊÄßÊèêÂçáÔºåÂπ∂Âú®Êõ¥Â§öËØ≠Ë®ÄÂèäÊ°ÜÊû∂‰∏≠‰øùÊåÅÁ®≥ÂÆöËæìÂá∫„ÄÇÂØπ‰∫éÂº∫Ë∞ÉÈ´òÂêûÂêê„ÄÅAgentic Coding‰∏îÂØπÈÄüÂ∫¶‰∏éÊàêÊú¨ÊïèÊÑüÁöÑÁ†îÂèëÊµÅÁ®ãÔºåM2.1 ÊòØÁ®≥Â¶•‰∏îÂÖ∑ÊÄß‰ª∑ÊØîÁöÑÈÄâÊã©„ÄÇ&lt;/p&gt;
    &lt;p&gt;Matt Rubens&lt;/p&gt;
    &lt;p&gt;Co-Founder, CEO of RooCode&lt;/p&gt;
    &lt;head rend="h2"&gt;Showcases&lt;/head&gt;
    &lt;head rend="h2"&gt;Áâ©ÁêÜ‰∏ñÁïåAgent&lt;/head&gt;
    &lt;head rend="h2"&gt;Â§öËØ≠Ë®Ä Coding&lt;/head&gt;
    &lt;head rend="h2"&gt;Agentic Tool Use&lt;/head&gt;
    &lt;head rend="h2"&gt;Êï∞Â≠óÂëòÂ∑•&lt;/head&gt;
    &lt;p&gt;‰ª•‰∏ãÊïàÊûúÊºîÁ§∫ÊòØ M2.1 Âú® AgentCompany Benchmark ‰∏≠ÁöÑË°å‰∏∫ËΩ®ËøπËÆ∞ÂΩï„ÄÇ&lt;/p&gt;
    &lt;head rend="h2"&gt;ÂÖ®ÈìæË∑ØÂäûÂÖ¨Ëá™Âä®Âåñ&lt;/head&gt;
    &lt;head rend="h2"&gt;Â¶Ç‰Ωï‰ΩøÁî®&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MiniMax-M2.1 API Â∑≤Âú® MiniMaxÂºÄÊîæÂπ≥Âè∞ ÂºÄÊîæ‰ΩøÁî®Ôºöhttps://platform.minimaxi.com/docs/guides/text-generation&lt;/item&gt;
      &lt;item&gt;Âü∫‰∫é MiniMax-M2.1 ÁöÑÈÄöÁî® Agent ‰∫ßÂìÅ MiniMax Agent Áé∞Â∑≤ÂÖ®Èù¢ÂºÄÊîæ‰ΩøÁî®Ôºöhttps://agent.minimaxi.com/&lt;/item&gt;
      &lt;item&gt; ÂºÄÊ∫ê‰ª•ÂèäÊú¨Âú∞ÈÉ®ÁΩ≤‰ΩøÁî®Ôºö https://huggingface.co/MiniMaxAI/MiniMax-M2.1 &lt;lb/&gt;https://github.com/MiniMax-AI/MiniMax-M2.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;‰∏∫‰∫ÜÊñπ‰æøÁî®Êà∑‰ΩøÁî®, Êàë‰ª¨Êèê‰æõ‰∫Ü‰∏§‰∏™ÁâàÊú¨ÁöÑ API, M2.1 Âíå M2.1-lightning„ÄÇËøô‰∏§‰∏™ API ÁªìÊûúÂÆåÂÖ®‰∏ÄÊ†∑, ‰ΩÜÊòØÂêéËÄÖÈÄüÂ∫¶Êõ¥Âø´, Êñπ‰æøÂØπ TPS ÊúâÈúÄÊ±ÇÁöÑÁî®Êà∑Êù•‰ΩøÁî®„ÄÇÂêåÊó∂, Âú® M2 ÊâãÂä® Cache ÁöÑÂü∫Á°Ä‰∏ä, M2.1 ÂÖ®Èù¢ÊîØÊåÅËá™Âä® Cache, Êó†ÈúÄËÆæÁΩÆ, Ëá™Âä®ÁîüÊïà, ‰∏∫ÂºÄÂèëËÄÖÂ∏¶Êù•Êõ¥ÊµÅÁïÖÁöÑ‰ΩìÈ™å„ÄÅÊõ¥‰ΩéÁöÑÊàêÊú¨‰∏éÊõ¥‰ºòÁöÑÂª∂Êó∂Ë°®Áé∞„ÄÇ&lt;/p&gt;
    &lt;p&gt;Êàë‰ª¨Âú® Coding Plan ÈáåÈù¢‰ºöÊ†πÊçÆËµÑÊ∫êË¥üËΩΩÁªôÁî®Êà∑Êèê‰æõÂ§ßÊØî‰æãÁöÑ M2.1-lightning, Âπ∂‰øùÊåÅ Coding Plan ÁöÑ‰ª∑Ê†º‰∏çÂèò„ÄÇ‰πüÂ∞±ÊòØËØ¥, Coding Plan Áî®Êà∑ÂÖçË¥πËé∑Âæó‰∫ÜÂ§ßÈÉ®ÂàÜÊó∂Èó¥Êõ¥Âø´ÁöÑÊé®ÁêÜÈÄüÂ∫¶„ÄÇÊ¨¢ËøéÂ§ßÂÆ∂ÁÇπÂáª‰∏ãÂçï~&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.minimaxi.com/news/minimax-m21"/><published>2025-12-26T01:02:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388700</id><title>Ultimate-Linux: Userspace for Linux in Pure JavaScript</title><updated>2025-12-26T12:20:48.263350+00:00</updated><content>&lt;doc fingerprint="931b311f9da72fa4"&gt;
  &lt;main&gt;
    &lt;p&gt;This is a fun tiny project for building a tiny Linux distribution in just JavaScript (and a tiny bit of C to enable mounting to get some fun results).&lt;/p&gt;
    &lt;code&gt;--- ULTIMATE LINUX SHELL ---
Commands: ls, cd, cat, mkdir, mount, exit
&lt;/code&gt;
    &lt;p&gt;I post a lot on X (Twitter) and if you don't follow me already, please follow now!&lt;/p&gt;
    &lt;p&gt;Lately I've been posting a lot about Unix, Linux, ideas of kernel syscall stability, etc.&lt;/p&gt;
    &lt;p&gt;In particular, I explored lately how Linux is more or less unique in the kernel/OS world for multiple reasons. First, it's a rare kernel that is shipped independently from the rest of the OS. BSDs, for example, ship the kernel in a coherent unit with the foundational userspace. Linux thus has a unique problem of defining its contract with software built on top of it. And Linux chose stable syscall ABI as this contract. This is in contrast with something like macOS, which is a Unix-certified OS, but which exposes only its system library as the public contract. Apple doesn't guarantee binary backwards compatibility.&lt;/p&gt;
    &lt;p&gt;Then I explored how pure Go binaries can interestingly target the kernel itself directly via syscalls for its static binaries, and not depend on the system libraries, at least on Linux. There were some explorations around &lt;code&gt;u-root&lt;/code&gt; project, etc.&lt;/p&gt;
    &lt;p&gt;Every once in a while I get comments about how wrong I am when talking about C, Go, Rust, you name it. Comments like Go sucks because it does what it does, I'm wrong when I say "Linux is a kernel, not a complete OS", I don't understand Unix, POSIX, whatever you can think of.&lt;/p&gt;
    &lt;p&gt;So this time I'm doing something to get all their love. I'm creating a libc-less micro Linux distribution in... JavaScript! A standalone JavaScript binary no less! Of course, there's a transpilation step through C, but who cares -- this is the Ultimate Linux! üí™üêß&lt;/p&gt;
    &lt;p&gt;Anyway, putting the jokes aside, if you want to really understand what is going on here and you want to understand the fundamentals of how the Linux kernel interfaces with user software, please check out this article that I have previously written. It's about making these "micro Linux distros" and it should give you fundamental understanding of what Linux distros really are.&lt;/p&gt;
    &lt;p&gt;Download &lt;code&gt;quickjs&lt;/code&gt; source code:&lt;/p&gt;
    &lt;code&gt;wget https://bellard.org/quickjs/quickjs-2025-09-13-2.tar.xz
&lt;/code&gt;
    &lt;p&gt;Unpack it:&lt;/p&gt;
    &lt;code&gt;tar -xf quickjs-2025-09-13-2.tar.xz
&lt;/code&gt;
    &lt;p&gt;Go inside the source directory, run &lt;code&gt;make&lt;/code&gt; and go back up.&lt;/p&gt;
    &lt;p&gt;Now go ahead and install &lt;code&gt;musl&lt;/code&gt; libc on your system: https://musl.libc.org/&lt;/p&gt;
    &lt;p&gt;Do not worry, &lt;code&gt;musl&lt;/code&gt; installation is polite by default, meaning it will install itself into &lt;code&gt;/usr/lib/local&lt;/code&gt;, it will not clash with your host's libc. The reason why we install &lt;code&gt;musl&lt;/code&gt; is because it provides &lt;code&gt;gcc&lt;/code&gt; and &lt;code&gt;clang&lt;/code&gt; wrapper scripts for linking against &lt;code&gt;musl&lt;/code&gt; instead of your system library. You can then use&lt;/p&gt;
    &lt;code&gt;/usr/local/musl/bin/musl-gcc
&lt;/code&gt;
    &lt;p&gt;instead of your system's GCC to link against the freshly built &lt;code&gt;musl&lt;/code&gt; instead of your host system. That's what we do here and we link statically against &lt;code&gt;musl&lt;/code&gt; to make a standalone ELF file which doesn't depend on the running system's libc.&lt;/p&gt;
    &lt;p&gt;We're now ready to transpile the JavaScript code to C, link it together with some system operations and produce the final ULTIMATE SHELL!&lt;/p&gt;
    &lt;code&gt;./quickjs-2025-09-13/qjsc -M sys_ops,js_init_module_sys_ops -e -o ultimate_shell.c ultimate_shell.js &amp;amp;&amp;amp; /usr/local/musl/bin/musl-gcc -static -o ultimate_shell ultimate_shell.c sys_ops.c -I ./quickjs-2025-09-13 ./quickjs-2025-09-13/libquickjs.a -lm -ldl -lpthread
&lt;/code&gt;
    &lt;p&gt;You can run &lt;code&gt;./ultimate_shell&lt;/code&gt; on your build machine as well, it should be fully portable.&lt;/p&gt;
    &lt;p&gt;However, let's run it on a VM! First, let's build &lt;code&gt;initramfs&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;echo "ultimate_shell" | cpio -o -H newc &amp;gt; image.cpio
&lt;/code&gt;
    &lt;p&gt;Now let's run the VM with the Ultimate Shell as the PID 1!&lt;/p&gt;
    &lt;code&gt;qemu-system-x86_64 -m 4G -kernel /tmp/linux/linux-6.17.12/arch/x86/boot/bzImage -initrd ./image.cpio -nographic --enable-kvm -smp 8 -append "console=ttyS0 rdinit=/ultimate_shell"
&lt;/code&gt;
    &lt;p&gt;After a long blob of text from QEMU, you should get the shell prompt and you can play around a bit:&lt;/p&gt;
    &lt;code&gt;...
[    0.805878] x86/mm: Checked W+X mappings: passed, no W+X pages found.
[    0.807049] x86/mm: Checking user space page tables
[    0.839182] x86/mm: Checked W+X mappings: passed, no W+X pages found.
[    0.840185] Run /ultimate_shell as init process
--- ULTIMATE LINUX SHELL ---
Commands: ls, cd, cat, mkdir, mount, exit
[/] # ls
.  ..  ultimate_shell  root  dev
[/] # ls /dev
.  ..  console
[/] # mkdir proc
[/] # ls
.  ..  proc  ultimate_shell  root  dev
[/] # mount proc /proc proc
Mount proc -&amp;gt; /proc: Success
[/] # cat /proc/cmdline
console=ttyS0 rdinit=/ultimate_shell
[/] # cat /proc/1/environ
HOME=/
[/] # cat /proc/1/cmdline
/ultimate_shell
[/] #
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/popovicu/ultimate-linux"/><published>2025-12-26T02:32:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388907</id><title>TurboDiffusion: 100‚Äì200√ó Acceleration for Video Diffusion Models</title><updated>2025-12-26T12:20:47.707042+00:00</updated><content>&lt;doc fingerprint="f4d4ba193592fac2"&gt;
  &lt;main&gt;
    &lt;p&gt;This repository provides the official implementation of TurboDiffusion, a video generation acceleration framework that can speed up end-to-end diffusion generation by &lt;lb/&gt; TurboDiffusion primarily uses SageAttention, SLA (Sparse-Linear Attention) for attention acceleration, and rCM for timestep distillation.&lt;/p&gt;
    &lt;p&gt;Paper: TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times&lt;/p&gt;
    &lt;p&gt;Note: the checkpoints and paper are not finalized, and will be updated later to improve quality.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Checkpoint Link&lt;/cell&gt;
        &lt;cell role="head"&gt;Best Resolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.2-I2V-A14B-720P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;720p&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.1-T2V-1.3B-480P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;480p&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.1-T2V-14B-480P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;480p&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.1-T2V-14B-720P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;720p&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note: All checkpoints support generating videos at 480p or 720p. The "Best Resolution" column indicates the resolution at which the model provides the best video quality.&lt;/p&gt;
    &lt;p&gt;Base environment: &lt;code&gt;python&amp;gt;=3.9&lt;/code&gt;, &lt;code&gt;torch&amp;gt;=2.7.0&lt;/code&gt;. &lt;code&gt;torch==2.8.0&lt;/code&gt; is recommended, as higher versions may cause OOM.&lt;/p&gt;
    &lt;p&gt;Install TurboDiffusion by pip:&lt;/p&gt;
    &lt;code&gt;conda create -n turbodiffusion python=3.12
conda activate turbodiffusion

pip install turbodiffusion --no-build-isolation&lt;/code&gt;
    &lt;p&gt;Or compile from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/thu-ml/TurboDiffusion.git
cd TurboDiffusion
git submodule update --init --recursive
pip install -e . --no-build-isolation&lt;/code&gt;
    &lt;p&gt;To enable SageSLA, a fast SLA forward pass based on SageAttention, install SpargeAttn first:&lt;/p&gt;
    &lt;code&gt;pip install git+https://github.com/thu-ml/SpargeAttn.git --no-build-isolation&lt;/code&gt;
    &lt;p&gt;For GPUs with more than 40GB of GPU memory, e.g., H100, please use the unquantized checkpoints (without &lt;code&gt;-quant&lt;/code&gt;) and remove &lt;code&gt;--quant_linear&lt;/code&gt; from the command. For RTX 5090, RTX 4090, or similar GPUs, please use the quantized checkpoints (with &lt;code&gt;-quant&lt;/code&gt;) and add &lt;code&gt;--quant_linear&lt;/code&gt; in the command.)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Download the VAE (applicable for both Wan2.1 and Wan2.2) and umT5 text encoder checkpoints:&lt;/p&gt;
        &lt;code&gt;mkdir checkpoints cd checkpoints wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/Wan2.1_VAE.pth wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/models_t5_umt5-xxl-enc-bf16.pth&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Download our quantized model checkpoints (For RTX 5090 or similar GPUs):&lt;/p&gt;
        &lt;quote&gt;# For Wan2.1-T2V-1.3B wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P-quant.pth # For Wan2.2-I2V-14B wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P-quant.pth wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P-quant.pth&lt;/quote&gt;
        &lt;p&gt;Or download our unquantized model checkpoints (For H100 or similar GPUs):&lt;/p&gt;
        &lt;quote&gt;# For Wan2.1-T2V-1.3B wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P.pth # For Wan2.2-I2V-14B wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P.pth wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P.pth&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use the inference script for the T2V models:&lt;/p&gt;
        &lt;quote&gt;export PYTHONPATH=turbodiffusion # Arguments: # --dit_path Path to the finetuned TurboDiffusion checkpoint # --model Model to use: Wan2.1-1.3B or Wan2.1-14B (default: Wan2.1-1.3B) # --num_samples Number of videos to generate (default: 1) # --num_steps Sampling steps, 1‚Äì4 (default: 4) # --sigma_max Initial sigma for rCM (default: 80); larger choices (e.g., 1600) reduce diversity but may enhance quality # --vae_path Path to Wan2.1 VAE (default: checkpoints/Wan2.1_VAE.pth) # --text_encoder_path Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth) # --num_frames Number of frames to generate (default: 81) # --prompt Text prompt for video generation # --resolution Output resolution: "480p" or "720p" (default: 480p) # --aspect_ratio Aspect ratio in W:H format (default: 16:9) # --seed Random seed for reproducibility (default: 0) # --save_path Output file path including extension (default: output/generated_video.mp4) # --attention_type Attention module to use: original, sla or sagesla (default: sagesla) # --sla_topk Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality # --quant_linear Enable quantization for linear layers, pass this if using a quantized checkpoint # --default_norm Use the original LayerNorm and RMSNorm of Wan models python turbodiffusion/inference/wan2.1_t2v_infer.py \ --model Wan2.1-1.3B \ --dit_path checkpoints/TurboWan2.1-T2V-1.3B-480P-quant.pth \ --resolution 480p \ --prompt "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about." \ --num_samples 1 \ --num_steps 4 \ --quant_linear \ --attention_type sagesla \ --sla_topk 0.1&lt;/quote&gt;
        &lt;p&gt;Or the script for the I2V model:&lt;/p&gt;
        &lt;quote&gt;export PYTHONPATH=turbodiffusion # --image_path Path to the input image # --high_noise_model_path Path to the high noise TurboDiffusion checkpoint # --low_noise_model_path Path to the high noise TurboDiffusion checkpoint # --boundary Timestep boundary for switching from high to low noise model (default: 0.9) # --model Model to use: Wan2.2-A14B (default: Wan2.2-A14B) # --num_samples Number of videos to generate (default: 1) # --num_steps Sampling steps, 1‚Äì4 (default: 4) # --sigma_max Initial sigma for rCM (default: 200); larger choices (e.g., 1600) reduce diversity but may enhance quality # --vae_path Path to Wan2.2 VAE (default: checkpoints/Wan2.2_VAE.pth) # --text_encoder_path Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth) # --num_frames Number of frames to generate (default: 81) # --prompt Text prompt for video generation # --resolution Output resolution: "480p" or "720p" (default: 720p) # --aspect_ratio Aspect ratio in W:H format (default: 16:9) # --adaptive_resolution Enable adaptive resolution based on input image size # --ode Use ODE for sampling (sharper but less robust than SDE) # --seed Random seed for reproducibility (default: 0) # --save_path Output file path including extension (default: output/generated_video.mp4) # --attention_type Attention module to use: original, sla or sagesla (default: sagesla) # --sla_topk Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality # --quant_linear Enable quantization for linear layers, pass this if using a quantized checkpoint # --default_norm Use the original LayerNorm and RMSNorm of Wan models python turbodiffusion/inference/wan2.2_i2v_infer.py \ --model Wan2.2-A14B \ --low_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-low-720P-quant.pth \ --high_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-high-720P-quant.pth \ --resolution 720p \ --adaptive_resolution \ --image_path assets/i2v_inputs/i2v_input_0.jpg \ --prompt "POV selfie video, ultra-messy and extremely fast. A white cat in sunglasses stands on a surfboard with a neutral look when the board suddenly whips sideways, throwing cat and camera into the water; the frame dives sharply downward, swallowed by violent bursts of bubbles, spinning turbulence, and smeared water streaks as the camera sinks. Shadows thicken, pressure ripples distort the edges, and loose bubbles rush upward past the lens, showing the camera is still sinking. Then the cat kicks upward with explosive speed, dragging the view through churning bubbles and rapidly brightening water as sunlight floods back in; the camera races upward, water streaming off the lens, and finally breaks the surface in a sudden blast of light and spray, snapping back into a crooked, frantic selfie as the cat resurfaces." \ --num_samples 1 \ --num_steps 4 \ --quant_linear \ --attention_type sagesla \ --sla_topk 0.1 \ --ode&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Interactive inference via the terminal is available at &lt;code&gt;turbodiffusion/serve/&lt;/code&gt;. This allows multi-turn video generation without reloading the model.&lt;/p&gt;
    &lt;p&gt;We evaluate video generation on a single RTX 5090 GPU. The E2E Time refers to the end-to-end diffusion generation latency, excluding text encoding and VAE decoding.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4767s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 72.6s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 24s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4767s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 72.6s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 24s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4767s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 72.6s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 24s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this repo, we provide training code based on Wan2.1 and its synthetic data. The training builds on the rCM codebase (https://github.com/NVlabs/rcm), with infrastructure support including FSDP2, Ulysses CP, and selective activation checkpointing (SAC). For rCM training instructions, please refer to the original rCM repository; SLA (Sparse-Linear Attention) training guidance is provided here.&lt;/p&gt;
    &lt;p&gt;For rCM/SLA training, additionally run:&lt;/p&gt;
    &lt;code&gt;pip install megatron-core hydra-core wandb webdataset
pip install --no-build-isolation transformer_engine[pytorch]&lt;/code&gt;
    &lt;p&gt;Download the Wan2.1 pretrained checkpoints in &lt;code&gt;.pth&lt;/code&gt; format and VAE/text encoder to &lt;code&gt;assets/checkpoints&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# make sure git lfs is installed
git clone https://huggingface.co/worstcoder/Wan assets/checkpoints&lt;/code&gt;
    &lt;p&gt;FSDP2 relies on Distributed Checkpoint (DCP) for loading and saving checkpoints. Before training, convert &lt;code&gt;.pth&lt;/code&gt; teacher checkpoints to &lt;code&gt;.dcp&lt;/code&gt; first:&lt;/p&gt;
    &lt;code&gt;python -m torch.distributed.checkpoint.format_utils torch_to_dcp assets/checkpoints/Wan2.1-T2V-1.3B.pth assets/checkpoints/Wan2.1-T2V-1.3B.dcp&lt;/code&gt;
    &lt;p&gt;After training, the saved &lt;code&gt;.dcp&lt;/code&gt; checkpoints can be converted to &lt;code&gt;.pth&lt;/code&gt; using the script &lt;code&gt;scripts/dcp_to_pth.py&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We provide Wan2.1-14B-synthesized datasets. Download to &lt;code&gt;assets/datasets&lt;/code&gt; using:&lt;/p&gt;
    &lt;code&gt;# make sure git lfs is installed
git clone https://huggingface.co/datasets/worstcoder/Wan_datasets assets/datasets&lt;/code&gt;
    &lt;p&gt;We implement white-box SLA training by aligning the predictions of the SLA-enabled model with those of the full-attention pretrained model. Unlike black-box training in the original paper, which tunes the pretrained model using diffusion loss, white-box training mitigates distribution shift and is less sensitive to the training data.&lt;/p&gt;
    &lt;p&gt;Single-node training example:&lt;/p&gt;
    &lt;code&gt;WORKDIR="/your/path/to/turbodiffusion"
cd $WORKDIR
export PYTHONPATH=turbodiffusion

# the "IMAGINAIRE_OUTPUT_ROOT" environment variable is the path to save experiment output files
export IMAGINAIRE_OUTPUT_ROOT=${WORKDIR}/outputs
CHECKPOINT_ROOT=${WORKDIR}/assets/checkpoints
DATASET_ROOT=${WORKDIR}/assets/datasets/Wan2.1_14B_480p_16:9_Euler-step100_shift-3.0_cfg-5.0_seed-0_250K

# your Wandb information
export WANDB_API_KEY=xxx
export WANDB_ENTITY=xxx

registry=registry_sla
experiment=wan2pt1_1pt3B_res480p_t2v_SLA

torchrun --nproc_per_node=8 \
    -m scripts.train --config=rcm/configs/${registry}.py -- experiment=${experiment} \
        model.config.teacher_ckpt=${CHECKPOINT_ROOT}/Wan2.1-T2V-1.3B.dcp \
        model.config.tokenizer.vae_pth=${CHECKPOINT_ROOT}/Wan2.1_VAE.pth \
        model.config.text_encoder_path=${CHECKPOINT_ROOT}/models_t5_umt5-xxl-enc-bf16.pth \
        model.config.neg_embed_path=${CHECKPOINT_ROOT}/umT5_wan_negative_emb.pt \
        dataloader_train.tar_path_pattern=${DATASET_ROOT}/shard*.tar&lt;/code&gt;
    &lt;p&gt;Please refer to &lt;code&gt;turbodiffusion/rcm/configs/experiments/sla/wan2pt1_t2v.py&lt;/code&gt; for the 14B config or perform modifications as needed.&lt;/p&gt;
    &lt;p&gt;The parameter updates from SLA training can be merged into rCM checkpoints using &lt;code&gt;turbodiffusion/scripts/merge_models.py&lt;/code&gt;, enabling rCM to perform sparse attention inference. Specify &lt;code&gt;--base&lt;/code&gt; as the rCM model, &lt;code&gt;--diff_base&lt;/code&gt; as the pretrained model, and &lt;code&gt;--diff_target&lt;/code&gt; as the SLA-tuned model.&lt;/p&gt;
    &lt;p&gt;We thank the community effort Comfyui_turbodiffusion for integrating TurboDiffusion into ComfyUI.&lt;/p&gt;
    &lt;p&gt;We're actively working on the following features and improvements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Organize and release training code&lt;/item&gt;
      &lt;item&gt;Optimize infrastructure for better parallel&lt;/item&gt;
      &lt;item&gt;vLLM-Omni integration&lt;/item&gt;
      &lt;item&gt;Support for more video generation models&lt;/item&gt;
      &lt;item&gt;Support for autoregressive video generation models&lt;/item&gt;
      &lt;item&gt;More hardware-level operator optimizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome community members to help maintain and extend TurboDiffusion. Welcome to join the TurboDiffusion Team and contribute together!&lt;/p&gt;
    &lt;p&gt;If you use this code or find our work valuable, please cite:&lt;/p&gt;
    &lt;code&gt;@article{zhang2025turbodiffusion,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={Zhang, Jintao and Zheng, Kaiwen and Jiang, Kai and Wang, Haoxu and Stoica, Ion and Gonzalez, Joseph E and Chen, Jianfei and Zhu, Jun},
  journal={arXiv preprint arXiv:2512.16093},
  year={2025}
}

@software{turbodiffusion2025,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={The TurboDiffusion Team},
  url={https://github.com/thu-ml/TurboDiffusion},
  year={2025}
}

@inproceedings{zhang2025sageattention,
  title={SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration}, 
  author={Zhang, Jintao and Wei, Jia and Zhang, Pengle and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@article{zhang2025sla,
  title={SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention},
  author={Zhang, Jintao and Wang, Haoxu and Jiang, Kai and Yang, Shuo and Zheng, Kaiwen and Xi, Haocheng and Wang, Ziteng and Zhu, Hongzhou and Zhao, Min and Stoica, Ion and others},
  journal={arXiv preprint arXiv:2509.24006},
  year={2025}
}

@article{zheng2025rcm,
  title={Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency},
  author={Zheng, Kaiwen and Wang, Yuji and Ma, Qianli and Chen, Huayu and Zhang, Jintao and Balaji, Yogesh and Chen, Jianfei and Liu, Ming-Yu and Zhu, Jun and Zhang, Qinsheng},
  journal={arXiv preprint arXiv:2510.08431},
  year={2025}
}

@inproceedings{zhang2024sageattention2,
  title={Sageattention2: Efficient attention with thorough outlier smoothing and per-thread int4 quantization},
  author={Zhang, Jintao and Huang, Haofeng and Zhang, Pengle and Wei, Jia and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2025}
}
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/thu-ml/TurboDiffusion"/><published>2025-12-26T03:19:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46390055</id><title>Building an AI agent inside a 7-year-old Rails monolith</title><updated>2025-12-26T12:20:47.519654+00:00</updated><content>&lt;doc fingerprint="6c1bd1132f25fa62"&gt;
  &lt;main&gt;
    &lt;p&gt;I (incorrectly) convinced myself over the last few months that there‚Äôs no low-hanging fruit that would work for our product and business. This is a story of just how wrong I was.&lt;/p&gt;
    &lt;p&gt;I was at SF Ruby, in San Francisco, a few weeks ago. Most of the tracks were, of course, heavily focused on AI. Lots of stories from people building AIs into all sorts of products using Ruby and Rails,&lt;/p&gt;
    &lt;p&gt;They were good talks. But most of them assumed a kind of software I don‚Äôt work on ‚Äî systems without strong boundaries, without multi-tenant concerns, without deeply embedded authorization rules.&lt;/p&gt;
    &lt;p&gt;I kept thinking: this is interesting, but it doesn‚Äôt map cleanly to my world. At Mon Ami, we can‚Äôt just release a pilot unless it passes strict data access checks.&lt;/p&gt;
    &lt;p&gt;Then I saw a talk about using the RubyLLM gem to build a RAG-like system. The conversation (LLM calls) context was augmented using function calls (tools). This is when it clicked. I could encode my complicated access logic into a specific function call and ensure the LLM gets access to some of our data without having to give it unrestricted access.&lt;/p&gt;
    &lt;p&gt;RubyLLM is a neat gem that abstracts away the interaction with many LLM providers with a clean API.&lt;/p&gt;
    &lt;code&gt;gem "ruby_llm"&lt;/code&gt;
    &lt;p&gt;It is configured in an initializer with the API keys for the providers you want to use.&lt;/p&gt;
    &lt;code&gt;RubyLLM.configure do |config|
  config.openai_api_key = Rails.application.credentials.dig(:openai_api_key)
  config.anthropic_api_key = Rails.application.credentials.dig(:anthropic_api_key)
  # config.default_model = "gpt-4.1-nano"

  # Use the new association-based acts_as API (recommended)
  config.use_new_acts_as = true

  # Increase timeout for slow API responses
  config.request_timeout = 600  # 10 minutes (default is 300)
  config.max_retries = 3        # Retry failed requests
end

# Load LLM tools from main app
Dir[Rails.root.join('app/tools/**/*.rb')].each { |f| require f }&lt;/code&gt;
    &lt;p&gt;It provides a Conversation model as an abstraction for an LLM thread. The Conversation contains a set of Messages. It also provides a way of defining structured responses and function calls available.&lt;/p&gt;
    &lt;code&gt;AVAILABLE_TOOLS = [
  Tools::Client::SearchTool
].freeze

conversation = Conversation.find(conversation_id)
chat = conversation.with_tools(*AVAILABLE_TOOLS)

chat.ask 'What is the phone number for John Snow?'&lt;/code&gt;
    &lt;p&gt;A Conversation is initialized by passing a model (gpt-5, claude-sonnet-4.5, etc) and has a method for chatting to it.&lt;/p&gt;
    &lt;code&gt;conversation = Conversation.new(model: RubyLLM::Model.find_by(model_id: 'gpt-4o-mini'))&lt;/code&gt;
    &lt;p&gt;RubyLLM comes with a neat DSL for defining accepted parameters (the descriptions are passed to the LLM as context since it needs to decide if the tool should be used based on the conversation). The tool implements an execute method returning a hash. The hash is then presented to the LLM. This is all the magic needed.&lt;/p&gt;
    &lt;code&gt;class SearchTool &amp;lt; BaseTool
  description 'Search for clients by name, ID, or email address. Returns matching clients.'

  param :query,
    desc: 'Search query - can be client name, ID, or email address',
    type: :string

  def execute(query:)
  end
end&lt;/code&gt;
    &lt;p&gt;We‚Äôll now build a modest function call and a messaging interface. The function call allows searching a client using Algolia and ensuring the resulting set is visible to the user (by merging in the pundit policy).&lt;/p&gt;
    &lt;code&gt;def execute(query:)
  response = Algolia::SearchClient
    .create(app_id, search_key)
    .search_single_index(Client.index_name, {
      query: query.truncate(250)
    })

  ids = response.hits.map { |hit| hit[:id] }.compact

  base_scope = Client.where(id: ids)
  client = Admin::Org::ClientPolicy::Scope.new(base_scope).resolve.first or return {}

  {
    id: client.id,
    ami_id: client.slug,
    slug: client.slug,
    name: client.full_name,
    email: client.email
  }
end&lt;/code&gt;
    &lt;p&gt;The LLM acts as the magic glue between the natural language input submitted by the user, decides which (if any) tool to use to augment the context, and then responds to the user. No model should ever know Jon Snow‚Äôs phone number from a SaaS service, but this approach allows this sort of retrieval.&lt;/p&gt;
    &lt;p&gt;The UI is built with a remote form that enqueues an Active Job.&lt;/p&gt;
    &lt;code&gt;= turbo_stream_from @conversation, :messages

.container-fluid.h-100.d-flex.flex-column
  .sticky-top
    %h2.mb-0
      Conversation ##{@conversation.id}

  .flex-grow-1
    = render @messages

  .p-3.border-top.bg-white.sticky-bottom#message-form
  = form_with url: path, method: :post, local: false, data: { turbo_stream: true } do |f|
    = f.text_area :content
    = f.submit 'Send'&lt;/code&gt;
    &lt;p&gt;The job will process the Message.&lt;/p&gt;
    &lt;code&gt;class ProcessMessageJob &amp;lt; ApplicationJob
  queue_as :default

  def perform(conversation_id, message)
    conversation = Conversation.find(conversation_id)
    conversation.ask message
  end
end&lt;/code&gt;
    &lt;p&gt;The conversation has broadcast refresh enabled to update the UI when the response is received.&lt;/p&gt;
    &lt;code&gt;class Conversation &amp;lt; RubyLLM::Conversation
  broadcasts_refreshes
end&lt;/code&gt;
    &lt;p&gt;The form has a stimulus controller that checks for new messages being appended in order to scroll to the end of the conversation.&lt;/p&gt;
    &lt;p&gt;I checked a few OpenAI models for this implementation: gpt-5, gpt-4o, gpt4. GPT-5 has a big context, meaning we could have long-running conversations, but because there are a number of round-trips, the delay to queries requiring 3+ consecutive tools made the Agent feel sluggish.&lt;/p&gt;
    &lt;p&gt;GPT-4, on the other hand, is interestingly very prone to hallucinations - rushing to respond to queries with made-up data instead of calling the necessary tools. GPT-4o strikes, so far, the best balance between speed and correctness.&lt;/p&gt;
    &lt;p&gt;Building this tool took probably about 2-3 days of Claude-powered development (AIs building AIs). The difficulty and the complexity of building such a tool were the things that surprised me the most. The tool service object is essentially an API controller action - pass inputs and get a JSON back. Interestingly.&lt;/p&gt;
    &lt;p&gt;Before building this Agent, I looked at the other gems in this space. ActiveAgent (a somewhat similar gem for interacting with LLMs) is a decent contender that moves the prompts to a view file. It didn‚Äôt fit my needs since it had no built-in support for defining tools or having long-running conversations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://catalinionescu.dev/ai-agent/building-ai-agent-part-1/"/><published>2025-12-26T07:35:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46390667</id><title>Geometric Algorithms for Translucency Sorting in Minecraft [pdf]</title><updated>2025-12-26T12:20:47.305348+00:00</updated><content/><link href="https://douira.dev/assets/document/douira-master-thesis.pdf"/><published>2025-12-26T09:43:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391064</id><title>Questions engineers should ask future employers in interviews</title><updated>2025-12-26T12:20:47.210396+00:00</updated><content/><link href="https://dollardhingra.substack.com/p/questions-software-engineers-should"/><published>2025-12-26T11:09:55+00:00</published></entry></feed>