<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-29T10:45:39.536100+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46413975</id><title>PySDR: A Guide to SDR and DSP Using Python</title><updated>2025-12-29T10:45:47.648399+00:00</updated><content>&lt;doc fingerprint="7c6211f0c4f3e3a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;1. Introduction¬∂&lt;/head&gt;
    &lt;head rend="h2"&gt;Purpose and Target Audience¬∂&lt;/head&gt;
    &lt;p&gt;First and foremost, a couple important terms:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Software-Defined Radio (SDR):&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;p&gt;As a concept it refers to using software to perform signal processing tasks that were traditionally performed by hardware, specific to radio/RF applications. This software can be run on a general-purpose computer (CPU), FPGA, or even GPU, and it can be used for real-time applications or offline processing of recorded signals. Analogous terms include ‚Äúsoftware radio‚Äù and ‚ÄúRF digital signal processing‚Äù.&lt;/p&gt;
        &lt;p&gt;As a thing (e.g., ‚Äúan SDR‚Äù) it typically refers to a device that you can plug an antenna into and receive RF signals, with the digitized RF samples being sent to a computer for processing or recording (e.g., over USB, Ethernet, PCI). Many SDRs also have transmit capabilities, allowing the computer to send samples to the SDR which then transmits the signal at a specified RF frequency. Some embedded-style SDRs include an onboard computer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-2"&gt;Digital Signal Processing (DSP):&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The digital processing of signals; in our case, RF signals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This textbook acts as a hands-on introduction to the areas of DSP, SDR, and wireless communications. It is designed for someone who is:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Interested in using SDRs to do cool stuff&lt;/item&gt;
      &lt;item&gt;Good with Python&lt;/item&gt;
      &lt;item&gt;Relatively new to DSP, wireless communications, and SDR&lt;/item&gt;
      &lt;item&gt;A visual learner, preferring animations over equations&lt;/item&gt;
      &lt;item&gt;Better at understanding equations after learning the concepts&lt;/item&gt;
      &lt;item&gt;Looking for concise explanations, not a 1,000 page textbook&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;An example is a Computer Science student interested in a job involving wireless communications after graduation, although it can be used by anyone itching to learn about SDR who has programming experience. As such, it covers the necessary theory to understand DSP techniques without the intense math that is usually included in DSP courses. Instead of burying ourselves in equations, an abundance of images and animations are used to help convey the concepts, such as the Fourier series complex plane animation below. I believe that equations are best understood after learning the concepts through visuals and practical exercises. The heavy use of animations is why PySDR will never have a hard copy version being sold on Amazon.&lt;/p&gt;
    &lt;p&gt;This textbook is meant to introduce concepts quickly and smoothly, enabling the reader to perform DSP and use SDRs intelligently. It‚Äôs not meant to be a reference textbook for all DSP/SDR topics; there are plenty of great textbooks already out there, such as Analog Device‚Äôs SDR textbook and dspguide.com. You can always use Google to recall trig identities or the Shannon limit. Think of this textbook like a gateway into the world of DSP and SDR: it‚Äôs lighter and less of a time and monetary commitment, when compared to more traditional courses and textbooks.&lt;/p&gt;
    &lt;p&gt;To cover foundational DSP theory, an entire semester of ‚ÄúSignals and Systems‚Äù, a typical course within electrical engineering, is condensed into a few chapters. Once the DSP fundamentals are covered, we launch into SDRs, although DSP and wireless communications concepts continue to come up throughout the textbook.&lt;/p&gt;
    &lt;p&gt;Code examples are provided in Python. They utilize NumPy, which is Python‚Äôs standard library for arrays and high-level math. The examples also rely upon Matplotlib, which is a Python plotting library that provides an easy way to visualize signals, arrays, and complex numbers. Note that while Python is ‚Äúslower‚Äù than C++ in general, most math functions within Python/NumPy are implemented in C/C++ and heavily optimized. Likewise, the SDR API we use is simply a set of Python bindings for C/C++ functions/classes. Those who have little Python experience yet a solid foundation in MATLAB, Ruby, or Perl will likely be fine after familiarizing themselves with Python‚Äôs syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contributing¬∂&lt;/head&gt;
    &lt;p&gt;If you got value from PySDR, please share it with colleagues, students, and other lifelong learners who may be interested in the material. You can also donate through the PySDR Patreon as a way to say thanks and get your name on the left of every page below the chapter list.&lt;/p&gt;
    &lt;p&gt;If you get through any amount of this textbook and email me at marc@pysdr.org with questions/comments/suggestions, then congratulations, you will have contributed to this textbook! You can also edit the source material directly on the textbook‚Äôs GitHub page (your change will start a new pull request). Feel free to submit an issue or even a Pull Request (PR) with fixes or improvements. Those who submit valuable feedback/fixes will be permanently added to the acknowledgments section below. Not good at Git but have changes to suggest? Feel free to email me at marc@pysdr.org.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements¬∂&lt;/head&gt;
    &lt;p&gt;Thank you to anyone who has read any portion of this textbook and provided feedback, and especially to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Barry Duggan&lt;/item&gt;
      &lt;item&gt;Matthew Hannon&lt;/item&gt;
      &lt;item&gt;James Hayek&lt;/item&gt;
      &lt;item&gt;Deidre Stuffer&lt;/item&gt;
      &lt;item&gt;Tarik Benaddi for translating PySDR to French&lt;/item&gt;
      &lt;item&gt;Daniel Versluis for translating PySDR to Dutch&lt;/item&gt;
      &lt;item&gt;mrbloom for translating PySDR to Ukrainian&lt;/item&gt;
      &lt;item&gt;Yimin Zhao for translating PySDR to Simplified Chinese&lt;/item&gt;
      &lt;item&gt;Eduardo Chancay for translating PySDR to Spanish&lt;/item&gt;
      &lt;item&gt;John Marcovici&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As well as all PySDR Patreon supporters!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pysdr.org/content/intro.html"/><published>2025-12-28T20:02:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414475</id><title>MongoBleed Explained Simply</title><updated>2025-12-29T10:45:47.190843+00:00</updated><content>&lt;doc fingerprint="b899ddd9ce0a239a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;MongoBleed explained simply&lt;/head&gt;
    &lt;head rend="h3"&gt;CVE-2025-14847 allows attackers to read any arbitrary data from the database's heap memory. It affects all MongoDB versions since 2017, here's how it works:&lt;/head&gt;
    &lt;p&gt;MongoBleed, officially CVE-2025-14847, is a recently-uncovered extremely sensitive vulnerability affecting basically all versions of MongoDB since ~2017.&lt;/p&gt;
    &lt;p&gt;It is a bug in the zlib1 message compression path in MongoDB.&lt;/p&gt;
    &lt;p&gt;It allows an attacker to read off any uninitialized heap memory, meaning anything that was allocated to memory from a previous database operation could be read.&lt;/p&gt;
    &lt;p&gt;The bug was introduced in 20172. It is dead-easy to exploit - it only requires connectivity to the database (no auth needed). It is fixed as of writing, but some EOL versions (3.6, 4.0, 4.2) will not get it.&lt;/p&gt;
    &lt;head rend="h1"&gt;MongoDB Basics&lt;/head&gt;
    &lt;p&gt;Let‚Äôs get a few basics out of the way before we explain the bug:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB uses its own TCP wire protocol instead of e.g HTTP. This is standard for databases, especially ones chasing high performance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mongo uses the BSON format for messages3. It‚Äôs basically binary json but with some key optimizations. We will talk about one later because it is essential to the exploit.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mongo doesn‚Äôt have endpoints or RPCs. It only uses a single op code called OP_MSG.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The OP_MSG command contains a BSON message. The contents of the message denote what type of request it is. Concretely, it‚Äôs the first field of the message that marks the request type. 4&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The request can be compressed. In that case, an OP_COMPRESSED message is sent which wraps the now-compressed OP_MSG BSON.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The request then looks like this:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;     OP_COMPRESSED message
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ standard header (16 bytes) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ originalOpcode (int32)     ‚îÇ
‚îÇ uncompressedSize (int32)   ‚îÇ
‚îÇ compressorId (int8)        ‚îÇ
‚îÇ compressed OP payload      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Critically, the&lt;/p&gt;&lt;code&gt;uncompressedSize&lt;/code&gt;field denotes how large the payload is once it‚Äôs uncompressed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Exploit Part 1&lt;/head&gt;
    &lt;p&gt;The first part of the exploit is to get the server to wrongfully think that an overly-large OP_MSG is coming.&lt;/p&gt;
    &lt;p&gt;An attacker can send a falsefully large &lt;code&gt;`uncompressedSize`&lt;/code&gt; field, say 1MB5, when in reality the underlying message is 1KB uncompressed. &lt;/p&gt;
    &lt;p&gt;This will make the server allocate a 1MB buffer in memory to decompress the message into. This is fine.&lt;/p&gt;
    &lt;p&gt;The critical bug here is that, once finished decompressing, the server does NOT check the actual resulting size of the newly-uncompressed payload.&lt;/p&gt;
    &lt;p&gt;Instead, it trusts the user‚Äôs input and uses that as the canonical size of the payload, even if it got a different number.6&lt;/p&gt;
    &lt;p&gt;The result is an in-memory representation of the BSON message which looks something like this:&lt;/p&gt;
    &lt;code&gt;[ 1KB of REAL DATA |      999KB of UNREFERENCED HEAP GARBAGE       ]
                   ‚Üë                                               ‚Üë
        actual length (1KB)                     user input length (1MB)&lt;/code&gt;
    &lt;head rend="h3"&gt;Unreferenced Heap Garbage&lt;/head&gt;
    &lt;p&gt;Like in every programming language, when a variables in the code goes out of scope, the runtime marks the memory it previously took up as available.&lt;/p&gt;
    &lt;p&gt;In most modern languages, the memory gets zeroed out. In other words, the old bytes that used to take up the space get deleted.&lt;/p&gt;
    &lt;p&gt;In C/C++, this doesn‚Äôt happen. When you allocate memory via &lt;code&gt;`malloc()`&lt;/code&gt;, you get whatever was previously there.&lt;/p&gt;
    &lt;p&gt;Since Mongo is writen in C++, that unreferenced heap garbage part can represent anything that was in memory from previous operations, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Cleartext passwords and credentials&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Session tokens / API keys&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customer data and PII&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Database configs and system info&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Docker paths and client IP addresses&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[ REAL BSON DATA | password: 123 | apiKey: jA2sa | ip: 219.117.127.202 ]&lt;/code&gt;
    &lt;head rend="h1"&gt;Exploit Part 2&lt;/head&gt;
    &lt;p&gt;Now that the server has wrongfully allocated some potentially-sensitive data to the input message, the only thing left for the attacker is to somehow get the server return the data.&lt;/p&gt;
    &lt;head rend="h3"&gt;BSON&lt;/head&gt;
    &lt;p&gt;As mentioned, BSON is Mongo‚Äôs way of serializing JSON. As mentioned on its site, it was designed with efficiency in mind:&lt;/p&gt;
    &lt;quote&gt;
      &lt;head&gt;3. Efficient&lt;/head&gt;
      &lt;p&gt;Encoding data to BSON and decoding from BSON can be performed very quickly in most languages due to the use of C data types.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;C Strings&lt;/head&gt;
    &lt;p&gt;C famously uses null-terminated strings7. A null-terminated string means that a null byte is used to mark the end of the string:&lt;/p&gt;
    &lt;code&gt;char* s = "hello"
// in memory, this is represented as an array of characters with the last element being the null terminator: h e l l o \0&lt;/code&gt;
    &lt;p&gt;The way such strings get parsed is very simple - the deserializer reads every character until it finds a null terminator.&lt;/p&gt;
    &lt;head rend="h3"&gt;Malicious BSON Input&lt;/head&gt;
    &lt;p&gt;If you recall, I said earlier that the first field of the BSON message denotes what type of ‚ÄúRPC‚Äù the command is.&lt;/p&gt;
    &lt;p&gt;As such, the first thing a server does when handling an incoming message over the wire is‚Ä¶ parse the first field!&lt;/p&gt;
    &lt;p&gt;Because fields are strings, and strings are null-terminated CStrings, the deserializing logic in the MongoDB server parses the field until the first null terminator found.&lt;/p&gt;
    &lt;p&gt;An attacker can send a compressed, invalid BSON object that does NOT contain a null terminator. This forces the server to continue scanning through foreign data in the wrongly-allocated memory buffer until it finds the first null terminator (\0)&lt;/p&gt;
    &lt;code&gt;# Conceptual
[ REAL DATA |             UNREFERENCED HEAP GARBAGE                 ]
# Practical Example
[ { "a      | password: 123\0 | apiKey: jA2sa | ip: 219.117.127.202 ]&lt;/code&gt;
    &lt;p&gt;As the first null terminator is right after the password, the server would now think that the first field of the BSON is:&lt;/p&gt;
    &lt;code&gt;"a      | password: 123"&lt;/code&gt;
    &lt;p&gt;Obviously that is an invalid BSON field, so the server responds with an error to the client. In order to be helpful, the response contains an error message that shows which field was invalid:&lt;/p&gt;
    &lt;code&gt;{
  "ok": 0,
  "errmsg": "invalid BSON field name 'a      | password: 123'",
  "code": 2,
  "codeName": "BadValue"
}&lt;/code&gt;
    &lt;p&gt;Boom. The attacker successfully got the server to leak data to it.&lt;/p&gt;
    &lt;p&gt;Any serious attacker would then run this over and over again, thousands of time a second, until they believe they‚Äôve scanned the majority of the database‚Äôs heap. They can then repeat this ad infinitum.&lt;/p&gt;
    &lt;head rend="h1"&gt;üí• Impact&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Ease of Exploitation - ‚ÄúPre-Auth‚Äù&lt;/head&gt;
    &lt;p&gt;The impact of this is particularly nasty, because the request-response parsing cycle happens before any authentication can be made. This makes sense, since you cannot begin to authenticate a request you still haven‚Äôt deserialized.&lt;/p&gt;
    &lt;p&gt;This allows any attacker to gain access to any piece of potentially-sensitive data. The only thing they need is internet access to the database.&lt;/p&gt;
    &lt;p&gt;Exposing your database to the internet is a practice that‚Äôs heavily frowned upon8. At the same time, Shodan shows that there are over 213,000 publicly-accessible Mongo databases.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Eight Years of Vulnerability (handled badly)&lt;/head&gt;
    &lt;p&gt;The PR that introduced the bug was from May 2017. This means that, roughly from version 3.6.0, any publicly-accessible MongoDB instance has been vulnerable to this.&lt;/p&gt;
    &lt;p&gt;It is unknown whether the exploit was known and exploited by actors prior to its disclosure. Given the simplicity of it, I bet it was.&lt;/p&gt;
    &lt;p&gt;As of the exploit‚Äôs disclosure, which happened on 19th of December, it has been a race to patch the database.&lt;/p&gt;
    &lt;p&gt;Sifting through Git history, it seems like the fix was initially committed on the 17th of December. Interestingly enough, it was only merged a full 5 days after - on the 22nd of December (1-line fix btw).&lt;/p&gt;
    &lt;p&gt;That beig said, MongoDB 8.0.17 containing the fix was released on Dec 19, consistent with the CVE publish data. But JIRA activity shows that patches went out on the 22nd of December.&lt;/p&gt;
    &lt;p&gt;Because there‚Äôs no official timeline posted, members of the community like me have to guess. As of writing, 10 days later in Dec 28, 2025, Mongo have still NOT properly addressed the issue publicly.&lt;/p&gt;
    &lt;p&gt;They only issued a community disclosure of the CVE a full five days after the publication of it. It is then, on the 24th of December, that they announced that all of their database instances in their cloud service Atlas were fully patched.&lt;/p&gt;
    &lt;p&gt;I believe this implies that all Atlas databases exposed to the internet were vulnerable to this issue for almost a week. By default, Atlas databases use an IP allowlist for connectivity. But users could configure it to allow connections from anywhere.&lt;/p&gt;
    &lt;p&gt;Mongo says that they haven‚Äôt verified exploitation so far:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚Äúat this time, we have no evidence that this issue has been exploited or that any customer data has been compromised‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;3. Ease of Mitigation&lt;/head&gt;
    &lt;p&gt;Mitigation is admittedly very easy, you have one of two choices:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Update to the newest patch&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Disable zlib network compression&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I found the latter wasn‚Äôt circulated a lot in online talk, but I understand is just as good as a short-term mitigation.&lt;/p&gt;
    &lt;head rend="h1"&gt;A bit of Drama?&lt;/head&gt;
    &lt;p&gt;The tech lead for Security at Elastic coined the name MongoBleed by posting a Python script that acts as a proof of concept to exploiting the vulnerability: https://github.com/joe-desimone/mongobleed&lt;/p&gt;
    &lt;p&gt;This is particularly interesting, because despite being different systems, Mongo competes with Elastic on Vector Search, Text Search and Analytical use cases.&lt;/p&gt;
    &lt;head rend="h1"&gt;Summary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The exploit allows attackers to read arbitrary heap data, including user data, plaintext passwords, api keys/secrets, and more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is performed by leveraging a simple, malformed zlib-compressed request.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB versions from 2017-2025 are vulnerable to this exploit.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rough timeline:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;June 1, 2017: Commit introducing the bug gets merged.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 17, 2025: Code for the fix is written (original commit date).&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 19, 2025: CVE officially published.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 22, 2025: Code with the fix is merged.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 24, 2025: MongoDB announce the patch, say all Atlas databases are patched.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On Dec 24th, MongoDB reported they have no evidence of anybody exploiting the CVE. Given the fact this exploit lived on for ~8 years, and their honey-pot cloud service Atlas took a full 5 days to patch since the official CVE publish date‚Ä¶ I find that hard to believe.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB have not apologized yet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are over 213k+ potentially vulnerable internet-exposed MongoDB instances, ensuring that this exploit is web scale:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Interesting Links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Official CVE: https://nvd.nist.gov/vuln/detail/CVE-2025-14847 (Dec 19, 2025)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PR introducing the bug: https://github.com/mongodb/mongo/pull/1152 (May 2017)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Commit fixing the issue: https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728#diff-e5f6e2daef81ce1c3c4e9f7d992bd6ff9946b3b4d98a601e4d9573e5ef0cb07dR77&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Security Report on the incident, including fix versions: https://www.ox.security/blog/attackers-could-exploit-zlib-to-exfiltrate-data-cve-2025-14847/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Write-up on how to detect exploitation attempts via log analysis: https://blog.ecapuano.com/p/hunting-mongobleed-cve-2025-14847&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Somebody also vibe-coded a detector: https://github.com/Neo23x0/mongobleed-detector&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other Reads You May Like:&lt;/head&gt;
    &lt;p&gt;zlib is a library for compression. It uses the DEFLATE algorithm under the hood, but produces results in a specific wire format to ease sending such data over the wire. (e.g includes metadata like flags, checksums, etc)&lt;/p&gt;
    &lt;p&gt;Here is the PR that introduced it. I‚Äôm not aware of Mongo‚Äôs public review practices, but it appears as if nobody explicitly reviewed the change.&lt;/p&gt;
    &lt;p&gt;They actually created it. There‚Äôs a very good site for it - https://bsonspec.org/&lt;/p&gt;
    &lt;p&gt;Weird, I know. Here are examples of different commands, just so you get a sense:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Insert a document into the users table&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "insert": "users",
  "documents": [{ "name": "alice", "age": 30 }]
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Delete users with&lt;/p&gt;
        &lt;code&gt;inactive=true&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "delete": "users",
  "deletes": [ { "q": { "inactive": true }, "limit": 0 }]
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Check the server‚Äôs status&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{ "serverStatus": 1 }&lt;/code&gt;
    &lt;p&gt;I‚Äôm making this number up. There is probably some limit on the server side as to how large a request can be - perhaps 1MB is too large.&lt;/p&gt;
    &lt;p&gt;Here is the line (pre-fix): https://github.com/mongodb/mongo/blame/b2f3ca9c996ba409e7d48601fca16c28fd58b774/src/mongo/transport/message_compressor_zlib.cpp#L83&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;`output` &lt;/code&gt;is the large memory buffer that was allocated earlier&lt;/p&gt;
    &lt;p&gt;The code, instead, ought to return the referenced &lt;code&gt;`length`&lt;/code&gt; field, as that gets updated with the actual length that was seen post-compression.&lt;/p&gt;
    &lt;p&gt;This has been the cause of many security issues in the past.&lt;/p&gt;
    &lt;p&gt;The most common comment I saw online is that you ‚Äúdeserved it‚Äù if you exposed your DB to the wild. üòÅ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply"/><published>2025-12-28T21:03:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414723</id><title>Software engineers should be a little bit cynical</title><updated>2025-12-29T10:45:47.034236+00:00</updated><content>&lt;doc fingerprint="2c3f911c3e160190"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Software engineers should be a little bit cynical&lt;/head&gt;
    &lt;p&gt;A lot of my readers call me a cynic when I say things like ‚Äúyou should do things that make your manager happy‚Äù or ‚Äúbig tech companies get to decide what projects you work on‚Äù. Alex Wennerberg put the ‚ÄúSean Goedecke is a cynic‚Äù case well in his post Software Engineers Are Not Politicians. Here are some excerpts:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I have no doubt that [Sean‚Äôs] advice is quite effective for navigating the upper levels of an organization dedicated to producing a large, mature software product. But what is lost is any sort of conception of value. Is it too naive to say that engineers are more than ‚Äútools in a political game‚Äù, they are specialized professionals whose role is to apply their expertise towards solving meaningful problems?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;The irony is that this kind of thinking destroys a company‚Äôs ability to actually make money ‚Ä¶ the idea that engineers should begin with a self-conception of doing what their manager tells them to is, to me, very bleak. It may be a good way to operate smoothly within a bureaucratic organization, and of course, one must often make compromises and take direction, but it is a bad way to do good work.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I can see why people would think this way. But I love working in big tech companies! I do see myself as a professional solving meaningful problems. And I think navigating the organization to put real features or improvements in the hands of users is an excellent way - maybe the best way - to do good work.&lt;/p&gt;
    &lt;p&gt;Why do I write such cynical posts, then? Well, I think that a small amount of cynicism is necessary in order to think clearly about how organizations work, and to avoid falling into the trap of being overly cynical. In general, I think good engineers ought to be a little bit cynical.&lt;/p&gt;
    &lt;head rend="h3"&gt;The idealist view is more cynical than idealists think&lt;/head&gt;
    &lt;p&gt;One doctrinaire ‚Äúidealist‚Äù view of software engineering goes something like this. I‚Äôm obviously expressing it in its most lurid form, but I do think many people believe this more or less literally:1&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We live in a late-stage-capitalist hellscape, where large companies are run by aspiring robber barons who have no serious convictions beyond desiring power. All those companies want is for obedient engineering drones to churn out bad code fast, so they can goose the (largely fictional) stock price. Meanwhile, end-users are left holding the bag: paying more for worse software, being hassled by advertisements, and dealing with bugs that are unprofitable to fix. The only thing an ethical software engineer can do is to try and find some temporary niche where they can defy their bosses and do real, good engineering work, or to retire to a hobby farm and write elegant open-source software in their free time.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When you write it all out, I think it‚Äôs clear to see that this is incredibly cynical. At the very least, it‚Äôs a cynical way to view your coworkers and bosses, who are largely people like you: doing a job, balancing a desire to do good work with the need to please their own bosses. It‚Äôs a cynical way to view the C-staff of a company. I think it‚Äôs also inaccurate: from my limited experience, the people who run large tech companies really do want to deliver good software to users.&lt;/p&gt;
    &lt;p&gt;It‚Äôs idealistic only in the sense that it does not accept the need for individual software engineers to compromise. According to this view, you never need to write bad software. No matter how hard the company tells you to compromise and just get something out, you‚Äôre morally required to plant your feet and tell them to go to hell. In fact, by doing so, you‚Äôre taking a stand against the general degeneration of the modern software world. You‚Äôre protecting - unsung, like Batman - the needs of the end-user who will never know you exist.&lt;/p&gt;
    &lt;p&gt;I can certainly see the appeal of this view! But I don‚Äôt think it‚Äôs an idealistic appeal. It comes from seeing the world as fundamentally corrupted and selfish, and believing that real positive change is impossible. In other words, I think it‚Äôs a cynical appeal.&lt;/p&gt;
    &lt;head rend="h3"&gt;The cynical view is more idealistic than idealists think&lt;/head&gt;
    &lt;p&gt;I don‚Äôt see a hard distinction between engineers being ‚Äútools in a political game‚Äù and professionals who solve meaningful problems. In fact, I think that in practice almost all meaningful problems are solved by playing political games.&lt;/p&gt;
    &lt;p&gt;There are very few problems that you can solve entirely on your own. Software engineers encounter more of these problems than average, because the nature of software means that a single engineer can have huge leverage by sitting down and making a single code change. But in order to make changes to large products - for instance, to make it possible for GitHub‚Äôs 150M users to use LaTeX in markdown - you need to coordinate with many other people at the company, which means you need to be involved in politics.&lt;/p&gt;
    &lt;p&gt;It is just a plain fact that software engineers are not the movers and shakers in large tech organizations. They do not set the direction of the company. To the extent that they have political influence, it‚Äôs in how they translate the direction of the company into specific technical changes. But that is actually quite a lot of influence!&lt;/p&gt;
    &lt;p&gt;Large tech companies serve hundreds of millions (or billions) of users. Small changes to these products can have a massive positive or negative effect in the aggregate. As I see it, choosing to engage in the messy, political process of making these changes - instead of washing your hands of it as somehow impure - is an act of idealism.&lt;/p&gt;
    &lt;p&gt;I think the position of a software engineer in a large tech company is similar to people who go into public service: idealistically hoping that they can do some good, despite knowing that they themselves will never set the broad strokes of government policy.&lt;/p&gt;
    &lt;p&gt;Of course, big-tech software engineers are paid far better, so many people who go into this kind of work in fact are purely financially-motivated cynics. But I‚Äôm not one of them! I think it‚Äôs possible, by doing good work, to help steer the giant edifice of a large tech company for the better.&lt;/p&gt;
    &lt;head rend="h3"&gt;Cynicism as inoculation&lt;/head&gt;
    &lt;p&gt;Cynical writing is like most medicines: the dose makes the poison. A healthy amount of cynicism can serve as an inoculation from being overly cynical.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt have an slightly cynical explanation for why engineers write bad code in large tech companies - such as the one I write about here - you risk adopting an overly cynical one. For instance, you might think that big tech engineers are being deliberately demoralized as part of an anti-labor strategy to prevent them from unionizing, which is nuts. Tech companies are simply not set up to engage in these kind of conspiracies.&lt;/p&gt;
    &lt;p&gt;If you don‚Äôt have a slightly cynical explanation for why large tech companies sometimes make inefficient decisions - such as this one - you risk adopting an overly cynical one. For instance, you might think that tech companies are full of incompetent losers, which is simply not true. Tech companies have a normal mix of strong and weak engineers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;Idealist writing is massively over-represented in writing about software engineering. There is no shortage of books or blog posts (correctly) explaining that we ought to value good code, that we ought to be kind to our colleagues, that we ought to work on projects with positive real-world impact, and so on. There is a shortage of writing that accurately describes how big tech companies operate.&lt;/p&gt;
    &lt;p&gt;Of course, cynical writing can harm people: by making them sad, or turning them into bitter cynics. But idealist writing can harm people too. There‚Äôs a whole generation of software engineers who came out of the 2010s with a factually incorrect model of how big tech companies work, and who are effectively being fed into the woodchipper in the 2020s. They would be better off if they internalized a correct model of how these companies work: not just less likely to get into trouble, but better at achieving their own idealist goals2.&lt;/p&gt;
    &lt;p&gt;edit: this post got some traction on Hacker News, with many comments. Some commenters said that it‚Äôs incoherent to say ‚Äúwhat I do is good, actually‚Äù when my employer is engaged in various unethical activity. Fair enough! But this post isn‚Äôt about whether it‚Äôs ethical to work for Microsoft or not. It‚Äôs a followup to How good engineers write bad code at big companies - the main cynicism I‚Äôm interested in here is not ‚Äúbig tech is evil‚Äù, but ‚Äúbig tech is incompetent‚Äù.&lt;/p&gt;
    &lt;p&gt;Some other commenters challenged my claim that C-staff want to deliver good software by pointing out that they‚Äôre not willing to trade off their personal success to do so. Sure, I agree with that. The kind of person willing to sacrifice their career for things doesn‚Äôt typically make it to a C-level position. But it‚Äôs not always zero-sum. Good software makes money for software companies, after all.&lt;/p&gt;
    &lt;p&gt;I also saw two commenters link this as an example of big tech companies actually being engaged in conspiracies against their employees. I‚Äôm not convinced. Companies are structurally set up to collude on salaries, but they‚Äôre not set up to deliberately make their employees sad - they just don‚Äôt have that kind of fine-grained control over the culture! To the extent they have any control, they try to make their employees happy so they‚Äôll work for less money and not leave.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;I don‚Äôt think I‚Äôm strawmanning here - I‚Äôve seen many people make all of these points in the past, and I suspect at least some readers will be genuinely nodding along to the following paragraph. If you‚Äôre one of those readers (or if you only agree with about 50%), consider doing me a favor and emailing me to let me know! If I don‚Äôt get any emails I will probably rewrite this.&lt;/p&gt;‚Ü©&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;For some concrete details on this, see my post How I influence tech company politics as a staff software engineer. Also, if you‚Äôre interested, I wrote a much less well-developed version of this post right at the start of 2024, called Is it cynical to do what your manager wants?.&lt;/p&gt;‚Ü©&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;You can't design software you don't work on&lt;/p&gt;&lt;p&gt;Only the engineers who work on a large software system can meaningfully participate in the design process. That‚Äôs because you cannot do good software design without an intimate understanding of the concrete details of the system. In other words, generic software design advice is typically useless for most practical software design problems.&lt;/p&gt;&lt;p&gt;What is generic software design? It‚Äôs ‚Äúdesigning to the problem‚Äù: the kind of advice you give when you have a reasonable understanding of the domain, but very little knowledge of the existing codebase. Unfortunately, this is the only kind of advice you‚Äôll read in software books and blog posts. Engineers love giving generic software design advice for the same reason that all technical professionals love ‚Äútalking shop‚Äù. However, you should be very careful about applying generic advice to your concrete day-to-day work problems.&lt;/p&gt;&lt;lb/&gt;Continue reading...&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.seangoedecke.com/a-little-bit-cynical/"/><published>2025-12-28T21:29:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414819</id><title>Unity's Mono problem: Why your C# code runs slower than it should</title><updated>2025-12-29T10:45:46.533923+00:00</updated><content>&lt;doc fingerprint="f319d3cb995267ca"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Unity's Mono problem: Why your C# code runs slower than it should&lt;/head&gt;
    &lt;p&gt;Execution of C# code in Unity√¢s Mono runtime is slow by today√¢s standards, much slower than you might expect! Our game runs 2-3x faster on modern .NET compared to Unity√¢s Mono, and in a few small benchmarks I measured speedups of up to 15x. I√¢ve spent some time investigating what√¢s going on and in this article I will present my findings and why everyone should want Unity√¢s .NET modernization to become production-ready as soon as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;How did we get here&lt;/head&gt;
    &lt;p&gt;Unity uses the Mono framework to run C# programs and back in 2006 it was one of the only viable multi-platform implementations of .NET. Mono is also open-source, allowing Unity to do some tweaks to better suit game development.&lt;/p&gt;
    &lt;p&gt;An interesting twist happened nearly 10 years later. In 2014, Microsoft began open-sourcing .NET (notably .NET Core later that year) and in June 2016, .NET Core 1.0 shipped with official cross-platform support. Since then, the .NET ecosystem gained momentum and lots of improvements have been made, including the Roslyn compiler platform, a new JIT (just-in-time compiler), performance improvements, more features, etc.&lt;/p&gt;
    &lt;p&gt;In 2018, Unity engineers discussed that they are working on porting the engine to .NET CoreCLR, the multi-platform version of Common Language Runtime (CLR), a component that runs .NET programs. Their main motivations behind this project were performance and convergence. In their post they said:&lt;/p&gt;
    &lt;quote&gt;...CoreCLR could be great for Unity game developers, as it will provide a significant boost in performance, by an order of 2x to 5x compare to the Mono runtime sometimes up to x10 on some workload!&lt;/quote&gt;
    &lt;p&gt;Unfortunately, now it√¢s the end of 2025 and we still can√¢t run games on CoreCLR.&lt;/p&gt;
    &lt;head rend="h2"&gt;The performance gap&lt;/head&gt;
    &lt;p&gt;We don√¢t hear about the performance gap between Mono and .NET much, likely because it is not possible to run games written for Unity under modern .NET. But we can still do a direct comparison with code that does not depend on Unity directly.&lt;/p&gt;
    &lt;p&gt;Our game has a unique architecture √¢ we strictly separate the game simulation code (business logic) from rendering. So much so that the simulation code does not depend on Unity√¢s libraries and can be compiled and run under any .NET version.&lt;/p&gt;
    &lt;p&gt;One day I was debugging an issue in map generation and it was time-consuming because it was taking over 2 minutes to start a game. To make debugging faster, I√¢ve written a unit test, hoping to cut down on the turn-around time since Unity takes 15+ seconds just to crunch new DLLs and reload the domain before the game can be launched and it also initializes rendering stuff that I did not care about. When I ran the test, it finished in 40 seconds. I was quite surprised that it was more than 3x faster, so I started digging deeper.&lt;/p&gt;
    &lt;p&gt;Long story short, Figure 1 shows traces from a profiler showing the difference between the game launching in Unity running under Mono vs. a unit test running under .NET.&lt;/p&gt;
    &lt;p&gt;Note that all shown benchmarks are using either Unity 6.0 or .NET 10.&lt;/p&gt;
    &lt;p&gt;So our benchmark shows that loading a save file, generating a map, and initializing the simulation takes 100 seconds in Unity/Mono but only 38 seconds in .NET. This result alone is already something that may raise eyebrows and has real consequences of how you may want to approach debugging and testing.&lt;/p&gt;
    &lt;p&gt;I also know from experience with Unity that Release mode running as a standalone executable (without the Unity editor) is much faster, so I decided to test that next.&lt;/p&gt;
    &lt;head rend="h2"&gt;.NET vs. Mono in standalone Release mode&lt;/head&gt;
    &lt;p&gt;Debug mode slowness is not great, but even non-optimized C++ code can be slow. To compare the real performance gap between Mono and .NET, let√¢s run the same benchmark as above but in release mode, standalone executable.&lt;/p&gt;
    &lt;p&gt;First up: Unity. I√¢ve run our deploy script to get an optimized executable and run it directly. Unsurprisingly, optimized standalone executable is beating Unity editor by a big margin, more than 3x faster. Next, the same code running under .NET in Release mode. Figure 2 shows the results.&lt;/p&gt;
    &lt;p&gt;Yep. 12 seconds. It√¢s actually mind-boggling how much work is being done in these 12 seconds and when I saw this for the first time, I was not only shocked, but also impressed. Just so you know, a 4k √É 4k map is being generated using all available threads out of hundreds of combined noise functions in like 3 seconds. Figure 3 shows the trace expanded.&lt;/p&gt;
    &lt;p&gt;If you are interested in seeing the actual x86 assembly generated by Mono and .NET JITs, see the Extras section at the end of this article.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;As you can see from the presented benchmarks, Mono is massively behind .NET in terms of performance. This is primarily due to differences in runtime optimizations and JIT that generates unoptimized assembly. The actual speedup surely depends on the code itself, but from my research, 1.5-3x speedup of C# execution is very likely for most projects.&lt;/p&gt;
    &lt;p&gt;If you are a game developer using Unity, or even a player, you can now understand that CoreCLR would be a massive boost to performance of games and even the Unity editor. Unfortunately, for the past 8 years, Unity leadership was more interested in √¢other things√¢ and did not give .NET modernization the attention it deserves.&lt;/p&gt;
    &lt;p&gt;Some view .NET modernization as support for new language features in C#, but that is just a cherry on top. New C# adds some handy features, but the new JIT can deliver multi-x speedups.&lt;/p&gt;
    &lt;p&gt;At this year's Unite conference, Unity announced that CoreCLR is still ongoing but it won√¢t be production ready in 2026. The good news is that it now seems to be on the Unity 6.x roadmap, and not left for later versions as suggested by 2024√¢s Unite presentation.&lt;/p&gt;
    &lt;p&gt;Moreover, CoreCLR is not just new JIT and C#, it unlocks broader and better-optimized support for things like Span&amp;lt;T&amp;gt;-style APIs, hardware intrinsics, and newer SIMD paths that devs cannot use these days. These features could add another multiplier to the performance gains for some classes of code. For example, our map generator heavily uses 2D and 3D simplex noise. I bet that having access to new runtime features in CoreCLR could speed up the map generation by another 2x.&lt;/p&gt;
    &lt;p&gt;Unity has a technology called Burst that automatically converts marked C# methods to optimized native assembly via the LLVM compiler. This sounds neat as it can avoid the poor JIT performance, but the downside is that Burst has strict limitations on what can be converted and supports only subset of C#. I believe that CoreCLR with modern JIT will have very similar performance characteristics to Burst. I am curious what would happen in a universe where Unity invested all the time and effort in CoreCLR support and high-performance C#, instead of developing and maintaining Burst.&lt;/p&gt;
    &lt;p&gt;Another interesting consequence of CoreCLR support is the ability to pre-compile the .NET intermediate assembly to machine code using ahead-of-time compilation (AOT). AOT can further improve startup time and is essential on platforms where JIT is restricted (notably iOS). Nowadays, Unity solves this with IL2CPP that takes the intermediate code and compiles it to C++ which is then optimized and compiled to native assembly. However, according to RichardFine (Unity staff), using CoreCLR AOT is not planned and IL2CPP is here to stay:&lt;/p&gt;
    &lt;quote&gt;AOT for IL2CPP is completely independent of AOT for CoreCLR (which we have no plans to adopt anyway). GC behaviour on IL2CPP improves when we upgrade the GC there, it√¢s not really affected by CoreCLR at all.&lt;/quote&gt;
    &lt;p&gt;In conclusion, CoreCLR won√¢t magically fix every bottleneck in a Unity game, but it does fix many of the code generation inefficiencies and allows writing higher-performance code. The benchmark presented in this article is meant to illustrate that modern .NET has spent years squeezing more work into fewer CPU cycles, and Unity users are largely locked out of those gains today.&lt;/p&gt;
    &lt;p&gt;If Unity can deliver production-ready CoreCLR support, it won√¢t just mean √¢newer C#√¢. It will mean faster runtime performance, faster iteration times, more performance headroom, no domain reload, better GC behavior, and maybe even more managed code and less native code. Until then, the gap will remain an invisible tax on every Unity project that leans on managed code.&lt;/p&gt;
    &lt;p&gt;I√¢m cheering for you, Unity devs, CoreCLR for the win!&lt;/p&gt;
    &lt;head rend="h2"&gt;Extras: Comparison of x86 assembly&lt;/head&gt;
    &lt;p&gt;I have actually dug much deeper into the performance aspects of Mono vs .NET but for the sake of this article not being too long, here is a brief summary.&lt;/p&gt;
    &lt;p&gt;Code listing 1 shows the testing code. It does some basic summing of custom structs that are wrappers around ints. This is an interesting example because Mono is very bad at inlining and simplifying expressions, even obvious ones, and we have plenty of structs like these in our code base (e.g. Quantity, MechPower, Tile2i, etc).&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;static class Program { static void Main() { Console.WriteLine(RunTest(int.MaxValue)); } public static TestStruct RunTest(int iterations) { TestStruct value1 = new TestStruct(iterations % 2); TestStruct value2 = new TestStruct(iterations % 7); TestStruct value3 = new TestStruct(iterations % 13); TestStruct result = default; for (int i = 0; i &amp;lt; iterations; ++i) { result += value1 + value2; result += value1 + value3; } return result; } } readonly struct TestStruct { public readonly int Value; public TestStruct(int value) { Value = value; } public static TestStruct operator +(TestStruct lhs, TestStruct rhs) { return new TestStruct(lhs.Value + rhs.Value); } public override string ToString() =&amp;gt; Value.ToString(); }&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;To obtain assembly code, I√¢ve compiled the code in Release mode and ran it as a standalone executable. Then, I attached a debugger to the running process. An easy way to find this loop was to make it long/infinite and just break the program at any time, it would end up in that loop.&lt;/p&gt;
    &lt;p&gt;First, let√¢s take a look at .NET. Here is the x64 assembly of the for-loop section of the code.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;add r8d,edx add edx,r10d 00007FFDEC338E88: mov r10d,r8d add r9d,r10d mov r10d,edx add r9d,r10d inc ecx cmp ecx,eax jl 00007FFDEC338E88&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt; In both cases, the full loop of &lt;code&gt;int.MaxValue&lt;/code&gt; iterations took around 750 ms on my machine.
&lt;/p&gt;
    &lt;p&gt; This looks neat. Even if you don√¢t read assembly, you can see that there are two add instructions, one decrement, and one jump. It seems that the JIT hoisted the invariant sums &lt;code&gt;a = value1 + value2&lt;/code&gt; and &lt;code&gt;b = value1 + value3&lt;/code&gt; out of the loop and then just accumulates them.
&lt;/p&gt;
    &lt;p&gt;I also tested x86 assembly, and it looks very similar:&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;082E18D0: lea ebx,[esi+edi] add eax,ebx lea ebx,[esi+edx] add eax,ebx dec ecx jne 082E18D0&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;Interestingly, the loop direction was reversed, counting down. This saves one instruction as comparison to zero and conditional jump can be done as one instruction.&lt;/p&gt;
    &lt;p&gt;Now let√¢s look at Mono√¢s x64 assembly.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;1E87D2F3E20: movsxd rax,dword ptr [rsp+0C0h] mov dword ptr [rsp+40h],eax movsxd rax,dword ptr [rsp+0B8h] mov dword ptr [rsp+38h],eax movsxd rax,dword ptr [rsp+40h] mov dword ptr [rsp+0A0h],eax movsxd rax,dword ptr [rsp+38h] mov dword ptr [rsp+98h],eax movsxd rax,dword ptr [rsp+0A0h] movsxd rcx,dword ptr [rsp+98h] add eax,ecx mov dword ptr [rsp+90h],0 mov dword ptr [rsp+90h],eax mov dword ptr [rsp+30h],eax movsxd rax,dword ptr [rsp+0A8h] mov dword ptr [rsp+88h],eax movsxd rax,dword ptr [rsp+30h] mov dword ptr [rsp+80h],eax movsxd rax,dword ptr [rsp+88h] movsxd rcx,dword ptr [rsp+80h] add eax,ecx mov dword ptr [rsp+78h],0 mov dword ptr [rsp+78h],eax mov dword ptr [rsp+0A8h],eax mov dword ptr [rsp+28h],eax movsxd rax,dword ptr [rsp+0C0h] mov dword ptr [rsp+20h],eax movsxd rax,dword ptr [rsp+0B0h] mov dword ptr [rsp+18h],eax movsxd rax,dword ptr [rsp+20h] mov dword ptr [rsp+70h],eax movsxd rax,dword ptr [rsp+18h] mov dword ptr [rsp+68h],eax movsxd rax,dword ptr [rsp+70h] movsxd rcx,dword ptr [rsp+68h] add eax,ecx mov dword ptr [rsp+60h],0 mov dword ptr [rsp+60h],eax mov dword ptr [rsp+10h],eax movsxd rax,dword ptr [rsp+28h] mov dword ptr [rsp+58h],eax movsxd rax,dword ptr [rsp+10h] mov dword ptr [rsp+50h],eax movsxd rax,dword ptr [rsp+58h] movsxd rcx,dword ptr [rsp+50h] add eax,ecx mov dword ptr [rsp+48h],0 mov dword ptr [rsp+48h],eax mov dword ptr [rsp+0A8h],eax inc esi cmp esi,7FFFFFFFh jl 1E87D2F3E20&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt; As you can see just from the number of instructions, this code will run way slower. The full loop of &lt;code&gt;int.MaxValue&lt;/code&gt; iterations took around 11500 ms, that√¢s ~15x slower.
&lt;/p&gt;
    &lt;p&gt;In the assembly you can see the four add instructions in the loop, the √¢inefficient√¢ increment + comparison + jump (instead of decrement + conditional jump), and most importantly a sea of mov instructions, which are just memory copies from inefficient inlining of the struct fields. Basically Mono is just tossing values around memory.&lt;/p&gt;
    &lt;p&gt;I have also tested assembly compiled in Debug mode running in the Unity editor and it√¢s even worse. The full loop takes 67 seconds (67000 ms)! In Unity Editor, the JIT likely switches to far less optimized codegen and includes additional checks/sequence-point overhead, which balloons runtime.&lt;/p&gt;
    &lt;p&gt;Takeaway: modern .NET√¢s JIT can scalarize tiny value types and hoist invariant work so the hot loop becomes a handful of register ops, while Mono often fails to do so and ends up shuffling values through memory, exactly the kind of gap that shows up as slowdowns in real simulation-heavy code.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/"/><published>2025-12-28T21:41:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414837</id><title>Why I Disappeared ‚Äì My week with minimal internet in a remote island chain</title><updated>2025-12-29T10:45:46.357215+00:00</updated><content>&lt;doc fingerprint="5df6d2b4112c141d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why I Disappeared&lt;/head&gt;
    &lt;head rend="h3"&gt;My week with minimal internet in a remote island chain&lt;/head&gt;
    &lt;p&gt;I‚Äôm writing this on my flight back from a weeklong trip to the Galapagos Islands, where for the first time in years I was largely without access to the Internet. For someone as congenitally online as I am, this at first seemed a curse. It turned out to be far from that and has me questioning a lot of what I thought I knew about media, politics and, well, people.&lt;/p&gt;
    &lt;p&gt;My Galapagos excursion took place on a boat with over a dozen other travelers. They were young and older, professors and small business owners (even an Army colonel!), Republicans and Democrats, from big cities and small towns. People from wildly different backgrounds readily shared sunscreen, snacks, even life advice. And while it wasn‚Äôt partisan, it also wasn‚Äôt apolitical: issues like the outrageous cost of housing, healthcare and childcare came up. Yet absent was the political vitriol that the national security state says necessitates a new domestic war on terrorism.&lt;/p&gt;
    &lt;p&gt;Contrary to the national security threat machine‚Äôs picture of a country at war with itself, we all got along so swimmingly that the idea of a civil war or anything like it struck me as laughable, as did the notion that the statistically insignificant number of politically-motivated killings, though real, said anything at all about the vast majority of real-world Americans. I say ‚Äòreal-world‚Äô to distinguish from the Internet, where anonymity and disembodied reality can lead to people saying things they never would in real life.&lt;/p&gt;
    &lt;p&gt;The Galapagos are unique because its extreme remoteness has insulated various species from outside predators, providing Charles Darwin a controlled setting to observe and later theorize evolution. That same remoteness ‚Äî in my case from the constant intravenous drip of the internet and social media for the first time in maybe my entire adult life ‚Äî left me with the staggering realization that what passes for news is mostly just noise.&lt;/p&gt;
    &lt;p&gt;Where Darwin prized the islands for its incubation of remarkably distinct animal lineages, I too benefited from the bewitching remoteness of the Galapagos. During the brief, intermittent moments that I had time to check the news (rather than living through it moment by moment), I realized how utterly forgettable and meaningless most of it was.&lt;/p&gt;
    &lt;p&gt;Not watching every twist and turn about, say, the latest Epstein transparency failure, I noticed how little these news cycles ultimately produce ‚Äî a very different picture than the 24/7 cycle creates. When I saw that Washington media had dogpiled Trump‚Äôs chief of staff Susie Wiles for offering some mildly critical remarks about Elon Musk and other administration figures, it occurred to me that no one would give a shit about or even remember any of this a week from now.&lt;/p&gt;
    &lt;p&gt;I came away shocked and sad at how much the media traffics in fake urgency as a result of its quest for the click. Combine that with national security‚Äôs constant drumbeat of civil war, disinformation, terrorism, violence, and the threat from within and you can see why people disengage from the news. It‚Äôs not they don‚Äôt care, lack ‚Äúmedia literacy,‚Äù or any of the usual explanations. They look at the hurricane of sensational headlines and aren‚Äôt sure what they‚Äôre supposed to do with any of it or if they should even believe it. And they‚Äôre right.&lt;/p&gt;
    &lt;p&gt;When another traveler on the boat, an academic, remarked that she didn‚Äôt really follow the news, it occurred to me that if even a very intelligent, well-educated and thoughtful person feels this way, the media has a much deeper problem than supposedly lazy audiences.&lt;/p&gt;
    &lt;p&gt;None of this is to say that there isn‚Äôt important news out there. But as with evolution, change is usually more gradual, like the shifting of tectonic plates, than the 24/7 cycle suggests.&lt;/p&gt;
    &lt;p&gt;One of the most striking features of Galapagos is its record number of ‚Äúendemic‚Äù species, or those that can only be found in this one place. That‚Äôs why the islands have an almost otherworldly feeling with such unique creatures as the giant Galapagos tortoise, the blue-footed booby, and the Galapagos penguin. The takeaway here is that sometimes evolution requires insulation from outside forces. And if I‚Äôm honest, as much as I love social media, it makes it difficult to develop the intellectual equivalent of Galapagos‚Äô delicate species because these gargantuan apps foster a ruthless competition for your attention that becomes a race to the bottom.&lt;/p&gt;
    &lt;p&gt;In other words, social media is such a free-for-all of attention-grabbing stunts that it‚Äôs hard to see through the blizzard of posts to what actually matters ‚Äî which is supposed to be the whole point of journalism.&lt;/p&gt;
    &lt;p&gt;What the incentives for now, now, now creates is a perverse system of survival of the dumbest. Just take a look at the insane number of hoax Epstein documents and allegations swirling around social media right now. A doctored video of Jeffrey Epstein committing suicide in his cell has generated millions of views on X alone, despite the hoax clip having first circulated in 2020.&lt;/p&gt;
    &lt;p&gt;As I return to celebrate Christmas, I realize that I didn‚Äôt really miss much during my week without social media. What passes for the news though, at its breakneck speed, zooms here and there, initially making it feel like I missed so much, that it‚Äôs all so overwhelming, that I can‚Äôt possibly keep up and should instead retreat to my family and friends, my reading, my hobbies, my team, my town. Nothing encourages me to be involved. And though I know that those in charge don‚Äôt have everything under control, don‚Äôt have a plan, and are grossly committed to survival of the fittest, I also am reminded that they love it this way. The blizzard of false urgency leaves us, the public, confused ‚Äî just how the elite like it. We are prey.&lt;/p&gt;
    &lt;p&gt;But I have a plan. In this next year I‚Äôll be focusing more on stories that actually matter instead of chasing the flash-in-the-pan ephemera that nobody remembers the next week. And most importantly, I‚Äôm also going to create my own island, by launching a new kind of website apart from Substack and the social media maelstrom. My dream is to create a home for news that is truly endemic to the site ‚Äî that you can‚Äôt find anywhere else ‚Äî by incubating stories that evince the kind of uniqueness as the magical creatures of the Galapagos.&lt;/p&gt;
    &lt;p&gt;Help me protect the fragile species that isn‚Äôt predatory, clickbait journalism by becoming a paid subscriber below (or via our GoFundMe if you prefer a one-off contribution.)&lt;/p&gt;
    &lt;p&gt;‚Äî Edited by William M. Arkin&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.kenklippenstein.com/p/why-i-disappeared"/><published>2025-12-28T21:45:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415129</id><title>Researchers discover molecular difference in autistic brains</title><updated>2025-12-29T10:45:45.234497+00:00</updated><content>&lt;doc fingerprint="f7fe1347089b1bdd"&gt;
  &lt;main&gt;
    &lt;p&gt;Yale School of Medicine (YSM) scientists have discovered a molecular difference in the brains of autistic people compared to their neurotypical counterparts.&lt;/p&gt;
    &lt;p&gt;Autism is a neurodevelopmental condition associated with behavioral differences including difficulties with social interaction, restrictive or intense interests, and repetitive movements or speech. But it‚Äôs not clear what makes autistic brains different.&lt;/p&gt;
    &lt;p&gt;Now, a new study in The American Journal of Psychiatry has found that brains of autistic people have fewer of a specific kind of receptor for glutamate, the most common excitatory neurotransmitter in the brain. The reduced availability of these receptors may be associated with various characteristics linked to autism.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe have found this really important, never-before-understood difference in autism that is meaningful, has implications for intervention, and can help us understand autism in a more concrete way than we ever have before,‚Äù says James McPartland, PhD, Harris Professor of Child Psychiatry and Psychology in the Child Study Center at YSM and the study‚Äôs co-principal investigator.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medicine.yale.edu/news-article/molecular-difference-in-autistic-brains/"/><published>2025-12-28T22:23:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415225</id><title>What an unprocessed photo looks like</title><updated>2025-12-29T10:45:44.671685+00:00</updated><content>&lt;doc fingerprint="e049a755b7543a7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;What an unprocessed photo looks like:&lt;/head&gt;(Photography)&lt;p&gt;Here‚Äôs a photo of a Christmas tree, as my camera‚Äôs sensor sees it:&lt;/p&gt;&lt;p&gt;It‚Äôs not even black-and-white, it‚Äôs gray-and-gray.&lt;/p&gt;&lt;p&gt;This is becuase while the camera‚Äôs analog-to-digital converter (ADC) output can theoretically output values from 0 to 16382, the data doesn‚Äôt cover that whole range:&lt;/p&gt;&lt;p&gt;The real range of ADC values is ~2110 to ~136000. Let‚Äôs set those values as the white and black in the image:&lt;/p&gt;&lt;p&gt;Vnew = (Vold - Black)/(White - Black)&lt;/p&gt;&lt;p&gt;Much better, but it‚Äôs still more monochromatic then I remember the tree being. Camera sensors aren‚Äôt actually able to see color: They only measure how much light hit each pixel.&lt;/p&gt;&lt;p&gt;In a color camera, the sensor is covered by a grid of alternating color filters:&lt;/p&gt;&lt;p&gt;Let‚Äôs color each pixel the same as the filter it‚Äôs looking through:&lt;/p&gt;&lt;p&gt;This version is more colorful, but each pixel only has one third of it‚Äôs RGB color. To fix this, I just averaged the values each pixel with it‚Äôs neighbors:&lt;/p&gt;&lt;p&gt;Applying this process to the whole photo gives the lights some color:&lt;/p&gt;&lt;p&gt;However, the image is still very dark. This is because monitors don‚Äôt have as much dynamic range as the human eye, or a camera sensor: Even if you are using an OLED, the screen still has some ambient light reflecting off of it and limiting how black it can get.&lt;/p&gt;&lt;p&gt;There‚Äôs also another, sneakier factor causing this:&lt;/p&gt;&lt;p&gt;Our perception of brightness is non-linear.&lt;/p&gt;&lt;p&gt;If brightness values are quantized, most of the ADC bins will be wasted on nearly identical shades of white while every other tone is crammed into the bottom. Because this is an inefficient use of memory, most color spaces assign extra bins to darker colors:&lt;/p&gt;&lt;p&gt;As a result of this, if the linear data is displayed directly, it will appear much darker then it should be.&lt;/p&gt;&lt;p&gt;Both problems can be solved by applying a non-linear curve to each color channel to brighten up the dark areas‚Ä¶ but this doesn‚Äôt quite work out:&lt;/p&gt;&lt;p&gt;Some of this green cast is caused by the camera sensor being intrinsically more sensitive to green light, but some of it is my fault: There are twice as many green pixels in the filter matrix. When combined with my rather naive demosaicing, this resulted in the green channel being boosted even higher.&lt;/p&gt;&lt;p&gt;In either case, it can fixed with proper white-balance: Equalize the channels by multipling each one with a constant.&lt;/p&gt;&lt;p&gt;However, because the image is now non-linear, I have to go back a step to do this. Here‚Äôs the dark image from before with all the values temporarily scaled up so I can see the problem:&lt;/p&gt;&lt;p&gt;‚Ä¶ here‚Äôs that image with the green taken down to match the other channels:&lt;/p&gt;&lt;p&gt;‚Ä¶ and after re-applying the curve:&lt;/p&gt;&lt;p&gt;This is really just the bare minimum: I haven‚Äôt done any color calibration, the white balance isn‚Äôt perfect, the black points are too high, there‚Äôs lots of noise that needs to be cleaned up‚Ä¶&lt;/p&gt;&lt;p&gt;Additionally, applying the curve to each color channel accidentally desaturated the highlights. This effect looks rather good ‚Äî and is what we‚Äôve come to expect from film ‚Äî but it‚Äôs has de-yellowed the star. It‚Äôs possible to separate the luminance and curve it while preserving color. On it‚Äôs own, this would make the LED Christmas lights into an overstaturated mess, but combining both methods can produce nice results.&lt;/p&gt;&lt;p&gt;For comparison, here‚Äôs the image my camera produced from the same data:&lt;/p&gt;&lt;p&gt;Far from being an ‚Äúunedited‚Äù photo: there‚Äôs a huge amount of math that‚Äôs gone into making an image that nicely represents what the subject looks like in person.&lt;/p&gt;&lt;p&gt;There‚Äôs nothing that happens when you adjust the contrast or white balance in editing software that the camera hasn‚Äôt done under the hood. The edited image isn‚Äôt ‚Äúfaker‚Äù then the original: they are different renditions of the same data.&lt;/p&gt;&lt;p&gt;In the end, replicating human perception is hard, and it‚Äôs made harder when constrained to the limitations of display technology or printed images. There‚Äôs nothing wrong with tweaking the image when the automated algorithms make the wrong call.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maurycyz.com/misc/raw_photo/"/><published>2025-12-28T22:35:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415338</id><title>As AI gobbles up chips, prices for devices may rise</title><updated>2025-12-29T10:45:44.198246+00:00</updated><content>&lt;doc fingerprint="8a32d49868b221ec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Memory loss: As AI gobbles up chips, prices for devices may rise&lt;/head&gt;
    &lt;head rend="h4"&gt;Memory loss: As AI gobbles up chips, prices for devices may rise&lt;/head&gt;
    &lt;p&gt;The world has a memory problem, thanks to artificial intelligence.&lt;/p&gt;
    &lt;p&gt;The explosion in AI-related cloud computing and data centers has led to so much demand for certain types of memory chips that now there's a shortage. The imbalance is expected to start affecting prices of all sorts of products powered by technology.&lt;/p&gt;
    &lt;p&gt;"I keep telling everybody that if you want a device, you buy it now," said Avril Wu, a senior research vice president at TrendForce, a Taiwan-based consultancy that tracks markets for computer components. "I myself bought an iPhone 17 already,"&lt;/p&gt;
    &lt;p&gt;The chips are known as RAM, or random access memory, and are crucial to making sure that things like smartphones, computers and game consoles run smoothly. Chips allow you to keep multiple tabs open in browsers, for instance, or watch videos without them being choppy.&lt;/p&gt;
    &lt;p&gt;Wu said TrendForce's data indicates that demand for RAM chips exceeds supply by 10% ‚Äì and it's growing so fast that manufacturers are having to shell out a lot more to buy them each month.&lt;/p&gt;
    &lt;p&gt;Wu said this quarter alone, they're paying 50% more than the previous quarter for the most common type of RAM, known as DRAM ‚Äì dynamic random access memory. And if producers want the chips sooner, they're paying two to three times more.&lt;/p&gt;
    &lt;p&gt;Wu expects DRAM prices to rise another 40% in the coming quarter, and she doesn't expect the prices to go down in 2026.&lt;/p&gt;
    &lt;head rend="h3"&gt;How AI is gobbling up memory&lt;/head&gt;
    &lt;p&gt;AI data centers require huge amounts of memory to accompany their cutting-edge graphics processing unit (GPU) microprocessors that train and operate AI models.&lt;/p&gt;
    &lt;p&gt;"AI workloads are built around memory," said Sanchit Vir Gogia, CEO of the tech advisory firm Greyhound Research.&lt;/p&gt;
    &lt;p&gt;What's more, AI companies are spending billions of dollars constructing data centers at warp speed around the world. It's the reason why Gogia says the demand for these chips isn't just a cyclical blip.&lt;/p&gt;
    &lt;p&gt;"AI has changed the nature of demand itself," he said. "Training and inference systems require large, persistent memory footprints, extreme bandwidth, and tight proximity to compute. You cannot dial this down without breaking performance."&lt;/p&gt;
    &lt;head rend="h3"&gt;More chips for AI means fewer chips for other products&lt;/head&gt;
    &lt;p&gt;Idaho-based Micron Technology is one of the world's top makers of RAM and it's benefited from this increase in demand. It reported better-than-expected quarterly earnings last week on the back of higher memory chip prices.&lt;/p&gt;
    &lt;p&gt;CEO Sanjay Mehrotra said the company expected the market to remain strong, as the AI boom continues apace. "We believe that the aggregate industry supply will remain substantially short of the demand for the foreseeable future," he said on a webcast after the earnings report.&lt;/p&gt;
    &lt;p&gt;Chipmakers like Micron have shifted production to meet as much of the lucrative AI-related demand for high-end memory as they can, according to analysts. That translates into fewer chips for other segments of the market ‚Äì personal computers, mobile phones, games and consumer products like TVs.&lt;/p&gt;
    &lt;p&gt;And that means higher costs. Dell Technologies Chief Operating Officer Jeff Clarke noted the higher costs on an earnings call on Nov. 25. For PC's, he said "I don't see how this will certainly not make its way into the customer base."&lt;/p&gt;
    &lt;p&gt;Analysts say there is no short-term fix.&lt;/p&gt;
    &lt;p&gt;Tech consultant Wu said the memory chip industry faces a significant bottleneck. By the end of 2026, she said, chip makers will have maxed out how much they can expand production in their current facilities.&lt;/p&gt;
    &lt;p&gt;She said the next new factory expected to come online is being built by Micron in Idaho. The company says it will be operational in 2027.&lt;/p&gt;
    &lt;p&gt;Expect suppliers to keep raising prices for the foreseeable future, Wu said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.npr.org/2025/12/28/nx-s1-5656190/ai-chips-memory-prices-ram"/><published>2025-12-28T22:52:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415448</id><title>Slaughtering Competition Problems with Quantifier Elimination (2021)</title><updated>2025-12-29T10:45:44.069857+00:00</updated><content>&lt;doc fingerprint="747111628645eb5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Slaughtering Competition Problems with Quantifier Elimination&lt;/head&gt;&lt;head rend="h3"&gt;22 Dec 2021 - Tags: sage , featured&lt;/head&gt;&lt;p&gt;Anytime I see questions on mse that ask something ‚Äúsimple‚Äù, I feel a powerful urge to chime in with ‚Äúa computer can do this for you!‚Äù. Obviously if you‚Äôre a researching mathematician you shouldn‚Äôt waste your time with something a computer can do for you, but when you‚Äôre still learning techniques (or, as is frequently the case on mse, solving homework problems), it‚Äôs not a particularly useful comment (so I usually abstain). The urge is particularly powerful when it comes to the contrived inequalities that show up in a lot of competition math, and today I saw a question that really made me want to say something about this! I still feel like it would be a bit inappropriate for mse, but thankfully I have a blog where I can talk about whatever I please :P So today, let‚Äôs see how to hit these problems with the proverbial nuke that is quantifier elimination!&lt;/p&gt;&lt;p&gt;I want this to be a fairly quick post, so I won‚Äôt go into too much detail. The gist is the following powerful theorem from model theory:&lt;/p&gt;&lt;p&gt;Tarski-Seidenberg Theorem1&lt;/p&gt;&lt;p&gt;If $\varphi$ is any formula of the form&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;$p(\overline{x}) = 0$, for $p \in \mathbb{R}[\overline{x}]$&lt;/item&gt;&lt;item&gt;$p(\overline{x}) \lt 0$, for $p \in \mathbb{R}[\overline{x}]$&lt;/item&gt;&lt;item&gt;combinations of the above using $\lor$, $\land$, $\lnot$, $\to$&lt;/item&gt;&lt;item&gt;combinations of the above using $\exists$ and $\forall$&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Then $\varphi$ is equivalent to a formula without quantifiers.&lt;/p&gt;&lt;p&gt;I‚Äôm legally required to give the following example:&lt;/p&gt;&lt;p&gt;The formula $\exists x . a x^2 + bx + c = 0$ (which has a quantifier) is equivalent to the formula $b^2 - 4ac \geq 0$&lt;/p&gt;&lt;p&gt;As a more complicated example, we have&lt;/p&gt;\[\forall x . \exists y . (x &amp;gt; 0 \to ax + by + xy &amp;gt; c)\]&lt;p&gt;is equivalent to&lt;/p&gt;\[b \geq 0 \ \lor \ c + ab \lt 0\]&lt;p&gt;Of course, this means if we want to know whether the above formula really is true for some choice of $a,b,c \in \mathbb{R}$, we can just plug into this quantifier free formula and check!&lt;/p&gt;&lt;p&gt;Now, you might be wondering: ‚ÄúHow did you find this quantifier free expression?‚Äù, and the answer is, of course, sage! Sage has interfaces with a lot of pre-existing software, and for us the relevant interface is to QEPCAD, which will actually do quantifier elimination for us!&lt;/p&gt;&lt;p&gt;To get started, you have to make sure you have qepcad installed in a way that sage can access. You‚Äôll want to run &lt;code&gt;sage -i qepcad&lt;/code&gt; just in case
(it wasn‚Äôt installed for me).&lt;/p&gt;&lt;p&gt;Next, let‚Äôs see how we eliminated quantifiers from the ‚Äúmore complicted example‚Äù above!&lt;/p&gt;&lt;p&gt;Yup. It‚Äôs that easy!&lt;/p&gt;&lt;p&gt;If you‚Äôre interested in reading more about this, you should check out the documentation, but I‚Äôm also going to give a handful of examples in the next section2!&lt;/p&gt;&lt;p&gt;So then, let‚Äôs slaughter some competition problems3!&lt;/p&gt;&lt;p&gt;First, the problem that made me write this post in the first place (here is the mse link again)&lt;/p&gt;&lt;p&gt;Let $a,b \geq 0$ with $a^4 + b^4 = 17$.&lt;/p&gt;&lt;p&gt;Prove $15(a+b) \geq 17 + 14 \sqrt{2ab}$&lt;/p&gt;&lt;p&gt;This isn‚Äôt given to us as polynomials, but of course it‚Äôs easy for us to fix that by rewriting it as&lt;/p&gt;\[(15(a+b) - 17)^2 \geq 14^2 \cdot 2ab\]&lt;p&gt;then we simply ask sage4:&lt;/p&gt;&lt;p&gt;We can extend this too. The asker conjectures that $(1,2)$ and $(2,1)$ are the only choices of $(a,b)$ for which we get equality. As a bonus, we can check this:&lt;/p&gt;&lt;p&gt;So we see that these really are the only points where equality holds!&lt;/p&gt;&lt;p&gt;Let‚Äôs take another example I remember seeing recently (the original mse link is here):&lt;/p&gt;&lt;p&gt;Let $x,y,z$ be positive real numbers. Show&lt;/p&gt;&lt;p&gt;\(\left ( x + \frac{1}{x} \right ) \left ( y + \frac{1}{y} \right ) \left ( z + \frac{1}{z} \right ) \geq \left ( x + \frac{1}{y} \right ) \left ( y + \frac{1}{z} \right ) \left ( z + \frac{1}{x} \right )\)&lt;/p&gt;&lt;p&gt;Again, we cannot plug this into sage directly, because it‚Äôs not a polynomial inequality. But multiplying through by $xyz$ on both sides solves that issue.&lt;/p&gt;&lt;p&gt;and even though the asker doesn‚Äôt mention it, one thing that Steele makes very clear in the (excellent) book The Cauchy-Schwarz Masterclass is that whenever working with a new inequality, we should ask where it‚Äôs sharp.&lt;/p&gt;&lt;p&gt;So we ask sage!&lt;/p&gt;&lt;p&gt;It turns out this inequality is sharp at infinitely many points, so instead of asking for the list of all points, we ask for a geometric description of the solution set.&lt;/p&gt;&lt;p&gt;Now, this admits some simplification, since we know that $x = y$ by the second line. I‚Äôll leave it to you to figure out exactly what set this is if you‚Äôre interested.&lt;/p&gt;&lt;p&gt;As an exercise, you should be on the lookout for places to use this tool!&lt;/p&gt;&lt;p&gt;Next time somebody is asking about some wacky inequality, or really any question about sets definable by polynomial (in)equations in $\mathbb{R}^n$, you should think about whether you can slaughter the problem without much thought by asking a computer!&lt;/p&gt;&lt;p&gt;As a more concrete exercise to show the flexibility of this method, pick your favorite theorem in euclidean geometry. Rephrase it using coordinates, then ask sage if it‚Äôs true!&lt;/p&gt;&lt;p&gt;As a very concrete exercise, can you do this with Ptolemy‚Äôs Theorem?&lt;/p&gt;&lt;p&gt;Also, if you find yourself using this, definitely come back and let me know! I would love to hear about places where this comes up in the wild!&lt;/p&gt;&lt;p&gt;Also also, if you have other (possibly surprising) uses for sage or other programs that automatically answer ceretain problems, definitely let me know! This is one of the parts of mathematical logic that I get most geeky about!&lt;/p&gt;&lt;p&gt;See you next time ^_^&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;As a cute thought exercise, you should try to provide geometric meaning to this claim. It‚Äôs telling us that if you take the solution set of polynomial inequations, then project from $\mathbb{R}^{n+m}$ down to $\mathbb{R}^n$, the resulting set is still definable by polynomial inequations!&lt;/p&gt;&lt;p&gt;This should sound somewhat miraculous, and it‚Äôs worth trying out some&lt;/p&gt;&lt;p&gt;Thankfully, by the end of the post, you‚Äôll have all the tools you need in order to work out some examples on your own ^_^. ‚Ü©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;In fact, there are $\sim \star \sim$ bonus quantifiers $\sim \star \sim$ built into QEPCAD! For instance, we can ask for&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;‚Äúthere exist exactly 5 $x$ so that $\varphi(x)$‚Äù (and obviously there‚Äôs nothing special about $5$)&lt;/item&gt;&lt;item&gt;‚Äúthere exist infinitely many $x$ so that $\varphi(x)$‚Äù&lt;/item&gt;&lt;item&gt;‚Äúthe set of $x$ so that $\varphi(x)$ is a connected set‚Äù&lt;/item&gt;&lt;/list&gt;&lt;p&gt;and while these aren‚Äôt going to be useful for the purposes of this post, I still wanted to mention them! ‚Ü©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I know that I‚Äôm currently treating this like a kind of party trick, but being able to ask a computer whether an implication between polynomial inequalities is true (and being able to find a counterexample if it isn‚Äôt) is super useful in practice! In fact, Andr√© Platzer at CMU crucially uses this machinery in order to automatically prove that robots will not bump into each other (etc.). See, for instance, his book Logical Foundations of Cyber-Physical Systems, as well as the accompanying lectures on youtube. ‚Ü©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;For some reason typing this out wasn‚Äôt working for me, but using the constructors directly got things going‚Ä¶ There‚Äôs probably something to do with the parsing that I don‚Äôt understand, and this isn‚Äôt too much of a hassle! ‚Ü©&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://grossack.site/2021/12/22/qe-competition.html"/><published>2025-12-28T23:10:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415458</id><title>Spherical Cow</title><updated>2025-12-29T10:45:43.942469+00:00</updated><content/><link href="https://lib.rs/crates/spherical-cow"/><published>2025-12-28T23:11:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415522</id><title>How to complain (2024)</title><updated>2025-12-29T10:45:43.806737+00:00</updated><content>&lt;doc fingerprint="676bdb193ae38898"&gt;
  &lt;main&gt;
    &lt;quote&gt;Foo is bad, and bar is better; here is why ...&lt;/quote&gt;
    &lt;p&gt;Or, at least, be very careful about writing such things.&lt;/p&gt;
    &lt;p&gt;Why? Because inevitably, somebody will respond: ‚Äòwait, I was confused, but I think I‚Äôve figured it out: what you‚Äôre calling a ‚Äúbar‚Äù I know as a ‚Äúfrobnicated foo‚Äù‚Äô.&lt;/p&gt;
    &lt;p&gt;A frobnicated foo is obviously a type of foo. So writing things like that alienates a core part of your audience: the people who have strong opinions on frobnicated foos and thing they‚Äôre great. That is, the people who agree with you. But they will be put off when they read that foos are bad, and it will be difficult to win them back.&lt;/p&gt;
    &lt;quote&gt;Often, when people try to solve a problem, they employ a particular approach. This approach is prone to problems; here is why an alternate approach does not run into those problems.&lt;/quote&gt;
    &lt;p&gt;Names are difficult, and people frequently disagree on their meanings. Replace pesky names with descriptions.&lt;/p&gt;
    &lt;p&gt;And absolute statements (‚Äòfoo is always better than bar‚Äô) are quite strong, and require an equally strong defense. It‚Äôs not necessary to explicitly state an absolute, even if you think it holds. ‚ÄòIt might be better to use bar than foo sometimes‚Äô is easier to defend than ‚Äòbar is better than foo‚Äô, and it‚Äôs usually more true.&lt;/p&gt;
    &lt;p&gt;If somebody already knows what a foo is, isn‚Äôt it redundant, even patronising, to make them read a description of the problems foo solves and how it solves them? It can be, but it doesn‚Äôt have to be. The purpose of a description in this case isn‚Äôt just to be a definition-in-place-of-a-name. It‚Äôs to frame the problem, in a way that sets up the rest of your argument, and helps people avoid preconceptions they may have about related names. Your argument should be made in reference to your specific framing of the problem, not just in reference to the things that you expect people to know about foos.&lt;/p&gt;
    &lt;p&gt;Providing context to your argument also means that it can be read and understood by more people, making it more accessible.&lt;/p&gt;
    &lt;p&gt;Simply spewing negativity into the void is not a good enough reason to publish a complaint. There is enough negativity in the world as is. A complaint should have a good reason for existing. In particular, if that reason is to convince people that they should agree with you, then an overly acerbic tone may be unhelpful. And empathy always helps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://outerproduct.net/trivial/2024-03-25_complain.html"/><published>2025-12-28T23:23:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415570</id><title>Fast CVVDP implementation in C</title><updated>2025-12-29T10:45:43.221517+00:00</updated><content>&lt;doc fingerprint="7636b6ae2b57b990"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast C implementation of the CVVDP metric (arXiv) from the University of Cambridge. More information about how CVVDP works according to this implementation is provided here.&lt;/p&gt;
    &lt;p&gt;Benchmarked using &lt;code&gt;poop&lt;/code&gt; on Linux, Core i7
13700k. Note that fcvvdp runs with one CPU thread here while cvvdp uses multiple
threads. This is a current limitation of fcvvdp, which does not yet support
multithreading.&lt;/p&gt;
    &lt;code&gt;poop "cvvdp -r fm360p.y4m -t fm360p_x264.y4m --display standard_fhd" "./fcvvdp -m fhd fm360p.y4m fm360p_x264.y4m"
Benchmark 1 (3 runs): cvvdp -r fm360p.y4m -t fm360p_x264.y4m --display standard_fhd
  measurement          mean ¬± œÉ            min ‚Ä¶ max           outliers         delta
  wall_time          19.6s  ¬±  568ms    19.2s  ‚Ä¶ 20.2s           0 ( 0%)        0%
  peak_rss           1.00GB ¬± 28.1MB     979MB ‚Ä¶ 1.03GB          0 ( 0%)        0%
  cpu_cycles          747G  ¬± 8.54G      741G  ‚Ä¶  757G           0 ( 0%)        0%
  instructions        362G  ¬± 1.20G      361G  ‚Ä¶  363G           0 ( 0%)        0%
  cache_references   2.77G  ¬± 46.9M     2.71G  ‚Ä¶ 2.81G           0 ( 0%)        0%
  cache_misses        899M  ¬± 11.7M      890M  ‚Ä¶  912M           0 ( 0%)        0%
  branch_misses       107M  ¬± 1.80M      105M  ‚Ä¶  109M           0 ( 0%)        0%
Benchmark 2 (3 runs): ./fcvvdp -m fhd fm360p.y4m fm360p_x264.y4m
  measurement          mean ¬± œÉ            min ‚Ä¶ max           outliers         delta
  wall_time          16.1s  ¬± 56.2ms    16.0s  ‚Ä¶ 16.1s           0 ( 0%)        ‚ö°- 17.9% ¬±  4.7%
  peak_rss           86.7MB ¬±  109KB    86.6MB ‚Ä¶ 86.8MB          0 ( 0%)        ‚ö°- 91.4% ¬±  4.5%
  cpu_cycles         82.8G  ¬± 80.9M     82.8G  ‚Ä¶ 82.9G           0 ( 0%)        ‚ö°- 88.9% ¬±  1.8%
  instructions        255G  ¬± 30.0M      255G  ‚Ä¶  255G           0 ( 0%)        ‚ö°- 29.6% ¬±  0.5%
  cache_references   1.49G  ¬± 6.43M     1.49G  ‚Ä¶ 1.50G           0 ( 0%)        ‚ö°- 46.1% ¬±  2.7%
  cache_misses        369M  ¬± 2.84M      365M  ‚Ä¶  371M           0 ( 0%)        ‚ö°- 59.0% ¬±  2.2%
  branch_misses      8.50M  ¬± 62.3K     8.45M  ‚Ä¶ 8.57M           0 ( 0%)        ‚ö°- 92.1% ¬±  2.7%
&lt;/code&gt;
    &lt;p&gt;fcvvdp uses 91% less RAM, 88% fewer CPU cycles, and is almost 18% faster in terms of wall clock time. In terms of user time, fcvvdp is ~15x more efficient.&lt;/p&gt;
    &lt;p&gt;Compilation requires:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ensure all dependencies are installed&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;zig build --release=fast&lt;/code&gt;(add&lt;code&gt;-Dflto=true&lt;/code&gt;for FLTO)&lt;/item&gt;
      &lt;item&gt;Your &lt;code&gt;fcvvdp&lt;/code&gt;binary will be in&lt;code&gt;zig-out/bin/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;fcvvdp by Halide Compression, LLC | [version]

usage: fcvvdp [options] &amp;lt;reference.(png|y4m)&amp;gt; &amp;lt;distorted.(png|y4m)&amp;gt;

compare two images/videos using the CVVDP perceptual quality metric

options:
  -m, --model &amp;lt;name&amp;gt;
      display model to use (fhd, 4k, hdr_pq, hdr_hlg, hdr_linear,
      hdr_dark, hdr_zoom); default: fhd
  -v, --verbose
      show verbose output with display parameters
  -j, --json
      output result as JSON
  -h, --help
      show this help message&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ensure all dependencies are installed&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;zig build --release=fast&lt;/code&gt;(add&lt;code&gt;-Dflto=true&lt;/code&gt;for FLTO)&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;libcvvdp&lt;/code&gt;library will be in&lt;code&gt;zig-out/lib/&lt;/code&gt;, alongside&lt;code&gt;cvvdp.h&lt;/code&gt;in&lt;code&gt;zig-out/include/&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Library usage is clearly defined in &lt;code&gt;cvvdp.h&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;fcvvdp&lt;/code&gt; is under the Apache 2.0 License. &lt;code&gt;fcvvdp&lt;/code&gt; is developed by
Halide Compression.&lt;/p&gt;
    &lt;p&gt;Special thanks to Vship, from which this implementation was derived. Vship is under the MIT license.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/halidecx/fcvvdp"/><published>2025-12-28T23:30:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46416945</id><title>You can make up HTML tags</title><updated>2025-12-29T10:45:42.623503+00:00</updated><content>&lt;doc fingerprint="8706dbfe498098bd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You can make up HTML tags:&lt;/head&gt;(Programming)&lt;p&gt;Instead of writing HTML like this:&lt;/p&gt;&lt;code&gt;&amp;lt;div class=cool-thing&amp;gt;
Hello, World!
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;p&gt;‚Ä¶ you can write HTML like this:&lt;/p&gt;&lt;code&gt;&amp;lt;cool-thing&amp;gt;
Hello, World!
&amp;lt;/cool-thing&amp;gt;
&lt;/code&gt;&lt;p&gt;‚Ä¶ and CSS like this:&lt;/p&gt;&lt;code&gt;cool-thing {
	display: block;
	font-weight: bold;
	text-align: center;
	filter: drop-shadow(0 0 0.5em #ff0);
	color: #ff0;
}
&lt;/code&gt;&lt;p&gt;Browsers handle unrecognized tags by treating them as a generic element, with no effect beyond what‚Äôs specified in the CSS. This isn‚Äôt just a weird quirk, but is standardized behavior. If you include hyphens in the name, you can guarantee that your tag won‚Äôt appear in any future versions of HTML.&lt;/p&gt;&lt;p&gt;While you should use descriptive built-in tags if they exist, if it‚Äôs a choice between &amp;lt;div&amp;gt; and &amp;lt;span&amp;gt;, making up your own tag provides better readability then using a bunch of class names.&lt;/p&gt;&lt;p&gt;As an example, if you have a bunch of nested tags:&lt;/p&gt;&lt;code&gt;&amp;lt;div class=article&amp;gt;
&amp;lt;div class=article-header&amp;gt;
&amp;lt;div class=article-quote&amp;gt;
&amp;lt;div class=quote-body&amp;gt;
... a bunch more HTML ...
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;p&gt;Good luck trying to insert something inside of ‚Äúarticle-heading‚Äù but after ‚Äúarticle-quote‚Äù on the first try. This problem vanishes if you use descriptive tag names ‚Äî no &amp;lt;/div&amp;gt; counting required:&lt;/p&gt;&lt;code&gt;&amp;lt;main-article&amp;gt;
&amp;lt;article-header&amp;gt;
&amp;lt;article-quote&amp;gt;
&amp;lt;quote-body&amp;gt;
... a bunch more HTML ...
&amp;lt;/quote-body&amp;gt;
&amp;lt;/article-quote&amp;gt;
&amp;lt;!-- here! --&amp;gt;
&amp;lt;/article-header&amp;gt;
&amp;lt;/main-article&amp;gt;
&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maurycyz.com/misc/make-up-tags/"/><published>2025-12-29T02:47:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46417227</id><title>Fast GPU Interconnect over Radio</title><updated>2025-12-29T10:45:42.313187+00:00</updated><content>&lt;doc fingerprint="adc0404b0a9d96e5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI Data Centers Demand More Than Copper Can Deliver&lt;/head&gt;
    &lt;p&gt;Radio and terahertz links could be better, faster, and cheaper&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In data-center terms, scaling out involves linking computers, while scaling up packs more GPUs into a computer, challenging copper‚Äôs physical limits.&lt;/item&gt;
      &lt;item&gt;Copper cables face a phenomenon at high data rates at high data rates that necessitate wider wires and more power, complicating a data center‚Äôs dense connections.&lt;/item&gt;
      &lt;item&gt;Point2 and AttoTude propose radio-based cables, offering longer reach, lower power consumption, and narrower cables than copper, without the cost and complexity of optics.&lt;/item&gt;
      &lt;item&gt;Startups aim to directly integrate radio cables with GPUs, easing cooling needs and enhancing data-center efficiency.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;How fast you can train gigantic new AI models boils down to two words: up and out.&lt;/p&gt;
    &lt;p&gt;In data-center terms, scaling out means increasing how many AI computers you can link together to tackle a big problem in chunks. Scaling up, on the other hand, means jamming as many GPUs as possible into each of those computers, linking them so that they act like a single gigantic GPU, and allowing them to do bigger pieces of a problem faster.&lt;/p&gt;
    &lt;p&gt;The two domains rely on two different physical connections. Scaling out mostly relies on photonic chips and optical fiber, which together can sling data hundreds or thousands of meters. Scaling up, which results in networks that are roughly 10 times as dense, is the domain of much simpler and less costly technology‚Äîcopper cables that often span no more than a meter or two.&lt;/p&gt;
    &lt;p&gt;This article is part of our special report Top Tech 2026.&lt;/p&gt;
    &lt;p&gt;But the increasingly high GPU-to-GPU data rates needed to make more powerful computers work are coming up against the physical limits of copper. As the bandwidth demands on copper cables approach the terabit-per-second realm, physics demands that they be made shorter and thicker, says David Kuo, vice president of product marketing and business development at the data-center-interconnect startup Point2 Technology. That‚Äôs a big problem, given the congestion inside computer racks today and the fact that Nvidia, the leading AI hardware company, plans an eightfold increase in the maximum number of GPUs per system, from 72 to 576 by 2027.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe call it the copper cliff,‚Äù says Kuo.&lt;/p&gt;
    &lt;p&gt;The industry is working on ways to unclog data centers by extending copper‚Äôs reach and bringing slim, long-reaching optical fiber closer to the GPUs themselves. But Point2 and another startup, AttoTude, advocate for a solution that‚Äôs simultaneously in between the two technologies and completely different from them. They claim the tech will deliver the low cost and reliability of copper as well as some of the narrow gauge and distance of optical‚Äîa combination that will handily meet the needs of future AI systems.&lt;/p&gt;
    &lt;p&gt;Their answer? Radio.&lt;/p&gt;
    &lt;p&gt;Later this year, Point2 will begin manufacturing the chips behind a 1.6-terabit-per-second cable consisting of eight slender polymer waveguides, each capable of carrying 448 gigabits per second using two frequencies, 90 gigahertz and 225 GHz. At each end of the waveguide are plug-in modules that turn electronic bits into modulated radio waves and back again. AttoTude is planning essentially the same thing, but at terahertz frequencies and with a different kind of svelte, flexible cable.&lt;/p&gt;
    &lt;p&gt;Both companies say their technologies can easily outdo copper in reach‚Äîspanning 10 to 20 meters without significant loss, which is certainly long enough to handle Nvidia‚Äôs announced scale-up plans. And in Point2‚Äôs case, the system consumes one-third of optical‚Äôs power, costs one-third as much, and offers as little as one-thousandth the latency.&lt;/p&gt;
    &lt;p&gt;According to its proponents, radio‚Äôs reliability and ease of manufacturing compared with those of optics mean that it might beat photonics in the race to bring low-energy processor-to-processor connections all the way to GPU, eliminating some copper even on the printed circuit board.&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs wrong with copper?&lt;/head&gt;
    &lt;p&gt;So, what‚Äôs wrong with copper? Nothing, so long as the data rate isn‚Äôt too high and the distance it has to go isn‚Äôt too far. At high data rates, though, conductors like copper fall prey to what‚Äôs called the skin effect.&lt;/p&gt;
    &lt;p&gt;A 1.6-terabit-per-second e-Tube cable has half the area of a 32-gauge copper cable and has up to 20 times the reach. Point2 Technology&lt;/p&gt;
    &lt;p&gt;The skin effect occurs because the signal‚Äôs rapidly changing current leads to a changing magnetic field that tries to counter the current. This countering force is concentrated at the middle of the wire, so most of the current is confined to flowing at the wire‚Äôs outer edge‚Äîthe ‚Äúskin‚Äù‚Äîwhich increases resistance. At 60 hertz‚Äîthe mains frequency in many countries‚Äîmost of the current is in the outer 8 millimeters of copper. But at 10 GHz, the skin is just 0.65 micrometers deep. So to push high-frequency data through copper, the wire needs to be wider, and you need more power. Both requirements work against packing more and more connections into a smaller space to scale up computing.&lt;/p&gt;
    &lt;p&gt;To counteract the skin effect and other signal-degrading issues, companies have developed copper cables with specialized electronics at either end. With the most promising, called active electrical cables, or AECs, the terminating chip is called a retimer (pronounced ‚Äúre-timer‚Äù). This IC cleans up the data signal and the clock signal as they arrive from the processor. The circuit then retransmits them down the copper cable‚Äôs typically eight pairs of wires, or lanes. (There is a second set for transmitting in the other direction.) At the other end, the chip‚Äôs twin takes care of any noise or clock issues that accumulate during the journey and sends the data on to the receiving processor. Thus, at the cost of electronic complexity and power consumption, an AEC can extend the distance that copper can reach.&lt;/p&gt;
    &lt;p&gt;Don Barnetson, senior vice president and head of product at Credo, which provides network hardware to data centers, says his company has developed an AEC that can deliver 800 Gb/s as far as 7 meters‚Äîa distance that‚Äôs likely needed as computers hit 500 to 600 GPUs and span multiple racks. The first use of AECs will probably be to link individual GPUs to the network switches that form the scale-out network. This first stage in the scale-out network is important, says Barnetson, because ‚Äúit‚Äôs the only nonredundant hop in the network.‚Äù Losing that link, even momentarily, can cause an AI training run to collapse.&lt;/p&gt;
    &lt;p&gt;But even if retimers manage to push the copper cliff a bit farther into the future, physics will eventually win. Point2 and AttoTude are betting that point is coming soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Terahertz radio‚Äôs reach&lt;/head&gt;
    &lt;p&gt;AttoTude grew out of founder and CEO Dave Welch‚Äôs deep investigations into photonics. A cofounder of Infinera, an optical telecom‚Äìequipment maker purchased by Nokia in 2025, Welch developed photonic systems for decades. He knows the technology‚Äôs weaknesses well: It consumes too much power (about 10 percent of a data center‚Äôs compute budget, according to Nvidia); it‚Äôs extremely sensitive to temperature; getting light into and out of photonics chips requires micrometer-precision manufacturing; and the technology‚Äôs lack of long-term reliability is notorious. (There‚Äôs even a term for it: ‚Äúlink flap.‚Äù)&lt;/p&gt;
    &lt;p&gt;‚ÄúCustomers love fiber. But what they hate is the photonics,‚Äù says Welch. ‚ÄúElectronics have been demonstrated to be inherently more reliable than optics.‚Äù&lt;/p&gt;
    &lt;p&gt;Fresh off Nokia‚Äôs US $2.3 billion purchase of Infinera, Welch asked himself some fundamental questions as he contemplated his next startup, beginning with ‚ÄúIf I didn‚Äôt have to be at [an optical wavelength], where should I be?‚Äù The answer was the highest frequency that‚Äôs achievable purely with electronics‚Äîthe terahertz regime, 300 to 3,000 GHz.&lt;/p&gt;
    &lt;p&gt;‚ÄúYou start with passive copper, and you do everything you can to run in passive copper as long as you can.‚Äù ‚ÄîDon Barnetson, Credo&lt;/p&gt;
    &lt;p&gt;So Welch and his team set about building a system that consists of a digital component to interface with the GPU, a terahertz-frequency generator, and a mixer to encode the data on the terahertz signal. An antenna then funnels the signal into a narrow, flexible waveguide.&lt;/p&gt;
    &lt;p&gt;As for the waveguide, it‚Äôs made of a dielectric at the center, which channels the terahertz signal, surrounded by cladding. One early version was just a narrow, hollow copper tube. Welch says that the second-generation cable‚Äîmade up of fibers only about 200 ¬µm across‚Äî points to a system with losses down to 0.3 decibels per meter‚Äîa small fraction of the loss from a typical copper cable carrying 224 Gb/s.&lt;/p&gt;
    &lt;p&gt;Welch predicts this waveguide will be able to carry data as far as 20 meters. That ‚Äúhappens to be a beautiful distance for scale-up in data centers,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;So far, AttoTude has made the individual components‚Äîthe digital data chip, the terahertz-signal generator, the circuit that mixes the two‚Äîalong with a couple generations of waveguides. But the company hasn‚Äôt yet integrated them into a single pluggable form. Still, Welch says, the combination delivers enough bandwidth for at least 224 Gb/s transmission, and the startup demonstrated 4-meter transmission at 970 GHz last April at the Optical Fiber Communications Conference, in San Francisco.&lt;/p&gt;
    &lt;head rend="h2"&gt;Radio‚Äôs reach in the data center&lt;/head&gt;
    &lt;p&gt;Point2 has been aiming to bring radio to the data center longer than AttoTude has. Formed nine years ago by veterans of Marvell, Nvidia, and Samsung, the startup has pulled in $55 million in venture funding, most notably from computer cables and connections maker Molex. The latter‚Äôs backing ‚Äúis critical, because they‚Äôre a major part of the cable-and-connector ecosystem,‚Äù says Kuo. Molex has already shown that it can make Point2‚Äôs cable without modifying its existing manufacturing lines, and now Foxconn Interconnect Technology, which makes cables and connectors, is partnering with the startup. The support could be a big selling point for the hyperscalers who would be Point2‚Äôs customers.&lt;/p&gt;
    &lt;p&gt;Nvidia‚Äôs GB200 NVL72 rack-scale computer relies on many copper cables to link its 72 processors together.NVIDIA&lt;/p&gt;
    &lt;p&gt;Each end of the Point2 cable, called an e-Tube, consists of a single silicon chip that converts the incoming digital data into modulated millimeter-wave frequencies and an antenna that radiates into the waveguide. The waveguide itself is a plastic core with metal cladding, all wrapped in a metal shield. A 1.6-Tb/s cable, called an active radio cable (ARC), is made up of eight e-Tube cores. At 8.1 millimeters across, that cable takes up half the volume of a comparable AEC cable.&lt;/p&gt;
    &lt;p&gt;One of the benefits of operating at RF frequencies is that the chips that handle them can be made in a standard silicon foundry, says Kuo. A collaboration between engineers at Point2 and the Korea Advanced Institute of Science and Technology, reported this year in the IEEE Journal of Solid-State Circuits, used 28-nanometer CMOS technology, which hasn‚Äôt been cutting edge since 2010.&lt;/p&gt;
    &lt;head rend="h2"&gt;The scale-up network market&lt;/head&gt;
    &lt;p&gt;As promising as their tech sounds, Point2 and AttoTude will have to overcome the data-center industry‚Äôs long history with copper. ‚ÄúYou start with passive copper,‚Äù says Credo‚Äôs Barnetson. ‚ÄúAnd you do everything you can to run in passive copper as long as you can.‚Äù&lt;/p&gt;
    &lt;p&gt;The boom in liquid cooling for data-center computing is evidence of that, he says. ‚ÄúThe entire reason people have gone to liquid cooling is to keep [scaling up] in passive copper,‚Äù Barnetson says. To connect more GPUs in a scale-up network with passive copper, they must be packed in at densities too high for air cooling alone to handle. Getting the same kind of scale-up from a more spread-out set of GPUs connected by millimeter-wave ARCs would ease the need for cooling, suggests Kuo.&lt;/p&gt;
    &lt;p&gt;Meanwhile, both startups are also chasing a version of the technology that will attach directly to the GPU.&lt;/p&gt;
    &lt;p&gt;Nvidia and Broadcom recently deployed optical transceivers that live inside the same package as a processor, separating the electronics and optics by micrometers rather than centimeters or meters. Right now, the technology is limited to the network-switch chips that connect to a scale-out network. But big players and startups alike are trying to extend its use all the way to the GPU.&lt;/p&gt;
    &lt;p&gt;Both Welch and Kuo say their companies‚Äô technologies could have a big advantage over optical tech in such a transceiver-processor package. Nvidia and Broadcom‚Äîseparately‚Äîhad to do a mountain of engineering to make their systems possible to manufacture and reliable enough to exist in the same package as a very expensive processor. One of the many challenges is how to attach an optical fiber to a waveguide on a photonic chip with micrometer accuracy. Because of its short wavelength, infrared laser light must be lined up very precisely with the core of an optical fiber, which is only around 10 ¬µm across. By contrast, millimeter-wave and terahertz signals have a much longer wavelength, so you don‚Äôt need as much precision to attach the waveguide. In one demo system it was done by hand, says Kuo.&lt;/p&gt;
    &lt;p&gt;Pluggable connections will be the technology‚Äôs first use, but radio transceivers co-packaged with processors are ‚Äúthe real prize,‚Äù says Welch.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spectrum.ieee.org/rf-over-fiber"/><published>2025-12-29T03:39:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46417676</id><title>My First Meshtastic Network</title><updated>2025-12-29T10:45:41.762973+00:00</updated><content>&lt;doc fingerprint="ae48c852da0933e2"&gt;
  &lt;main&gt;
    &lt;p&gt;I first heard about Meshtastic from a blog post that made the rounds on Hacker News.&lt;lb/&gt; The author lived on a boat and used Meshtastic radios to stay in touch without cellular networks. Meshtastic allows you to send short text messages (around 200 characters) over long ranges without cell towers or satellites. It works by creating a mesh network of low-power LoRa devices that relay messages on behalf of peers. Because it uses license-free radio frequencies (in the ~915 MHz ISM band), no ham license is required.&lt;/p&gt;
    &lt;head rend="h2"&gt;My First Radio&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; I ordered a pair of Heltec V3 LoRa radios (the ones I bought), which are small devices based on the ESP32 microcontroller with a LoRa modem. These radios didn't come with GPS, which in hindsight I regret because Meshtastic can share your location if a GPS is present. I also picked up a third-party antenna upgrade, since the community warned that the cheap antennas bundled with these devices are nearly useless (yet another thing I learned in hindsight)&lt;/p&gt;
    &lt;p&gt;Out of the box, the devices had outdated firmware and wouldn't communicate with current Meshtastic apps. Fortunately, flashing the latest firmware was straightforward using the official Meshtastic Web Flasher (a browser-based tool at flasher.meshtastic.org). By connecting the device via USB and using Chrome (which supports the WebSerial API), I flashed the newest Meshtastic firmware without installing any software.&lt;/p&gt;
    &lt;head rend="h2"&gt;Initial Setup&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; With fresh firmware, I could configure and manage the radios using the Meshtastic mobile app (available for Android/iOS) over Bluetooth. There's also a web client (client.meshtastic.org) that works over USB or Wi-Fi. One quirk I learned: many Meshtastic devices can work over both Wi-Fi and Bluetooth, but you typically use one interface at a time for management. On my device, it was not possible to use both at the same time, which led to some confusion.&lt;/p&gt;
    &lt;p&gt;After setup, I had my two devices chatting with each other. Sending a message from one device would pop up on the other in a few seconds. Meshtastic uses a mesh protocol where every node repeats messages, so two devices in direct range will communicate one-to-one, and if more nodes are around they can hop messages further. I noticed that if I tried sending when only one device was on, the app would show &lt;quote&gt;Waiting to be acknowledged...&lt;/quote&gt; and eventually &lt;quote&gt;Maximum retransmission reached.&lt;/quote&gt; In other words, my message went nowhere because no other node heard it.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Contact&lt;/head&gt;
    &lt;p&gt;Up to this point, I hadn't heard any traffic besides my own test messages. I suspected I was the only Meshtastic user in my immediate area (the far west suburbs of Chicago). I left one radio powered on and placed it by a second-story window facing toward the city. The next morning, I was surprised to see that it had logged messages from a handful of unknown nodes overnight.&lt;/p&gt;
    &lt;p&gt;Looking up the node identifiers online, I discovered a website called MeshMap that shows public Meshtastic nodes on a map. Sure enough, some of the node names I saw appeared on a community mesh map of the Chicagoland area. A few even had labels referencing &lt;quote&gt;ChiMesh&lt;/quote&gt;. There's an active group of Meshtastic enthusiasts in Chicago, Chicagoland Mesh, and somehow my little device had picked up their transmissions from roughly 40-50 miles away. This was an early sign that mesh networking can extend beyond line-of-sight with the help of intermediate nodes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Joining a Local Community&lt;/head&gt;
    &lt;p&gt;Excited by this discovery, I joined the Chicagoland Mesh (ChiMesh) Discord server and introduced myself. To my surprise, there was another member only a mile or two from my house. We coordinated a simple experiment: he sent a test message from his device at home, and I was able to receive it on mine. However, when I tried to reply, he never saw my message. It became clear that while I could &lt;quote&gt;hear&lt;/quote&gt; the network, my transmission range was too short for others to hear me.&lt;/p&gt;
    &lt;p&gt;Community members quickly pointed to the antenna as the culprit. The stock rubber-duck antenna that came with my Heltec radio was likely low-quality. I switched to the high-gain antenna I bought and tried again. This time my messages started getting through. Antenna quality (and placement) makes a huge difference in radio range.&lt;/p&gt;
    &lt;head rend="h2"&gt;Expanding the Network&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; My success rekindled interest among a couple of local makers. Some fellow members of my local makerspace had dabbled with Meshtastic earlier but stopped due to the lack of active users. With my second device to spare, we set it up as a relay node at the makerspace, which is a few miles from my house. Positioned near a roofline, this node acted like a little tower, rebroadcasting messages between my home and the other member's location.&lt;lb/&gt; It took a bit of fiddling with placement and settings, but eventually we managed to pass messages between our homes via the makerspace node. It wasn't instantaneous or foolproof, but messages eventually hopped from my device to the relay and then to my friend's device, reaching farther than any single link could.&lt;/p&gt;
    &lt;head rend="h2"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; To better understand and improve our coverage, we started playing with the Meshtastic Site Planner. This is a web tool that lets you simulate radio coverage on a map given a node's location, antenna, and power. Being in a river valley, our area has some challenging terrain that limits range. The planner helped confirm that putting a node on higher ground (a tall building) could dramatically extend reach.&lt;/p&gt;
    &lt;p&gt;In the coming months, we plan to upgrade to better antennas (perhaps an outdoor mounted one on a mast) and add more nodes at strategic spots. I'm also interested in experimenting with Meshtastic's other capabilities. For example, it can interface with sensors and send telemetry. A fun project idea is an off-grid weather station broadcasting its data over the mesh network.&lt;/p&gt;
    &lt;head rend="h2"&gt;Continuing the Exploration&lt;/head&gt;
    &lt;p&gt;Working with Meshtastic has been fun. It's impressive how a few inexpensive devices can form a communications network covering many miles. The system is limited, but within those constraints it feels magical to send a message into the ether and have it hop across a county line to a stranger.&lt;/p&gt;
    &lt;p&gt;Meshtastic isn't very useful alone, but as more people join, the mesh becomes stronger and more useful for everyone. If you're in the Illinois Fox Valley area and interested, feel free to reach out or drop by our makerspace meetup - we'd love to grow the network. And if you're elsewhere, consider looking up Meshtastic groups in your region. I hope to see you on the air.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rickcarlino.com/notes/electronics/my-first-meshtastic-network.html"/><published>2025-12-29T05:12:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46417748</id><title>Show HN: My not-for-profit search engine with no ads, no AI, &amp; all DDG bangs</title><updated>2025-12-29T10:45:41.372906+00:00</updated><content>&lt;doc fingerprint="5fcfdfe9c315cacb"&gt;
  &lt;main&gt;
    &lt;p&gt;nilch No AI, no ads, just search.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nilch.org"/><published>2025-12-29T05:25:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46417791</id><title>Binaries</title><updated>2025-12-29T10:45:41.129051+00:00</updated><content>&lt;doc fingerprint="a804ba32052587f4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Huge binaries&lt;/head&gt;
    &lt;p&gt;Published 2025-12-28 on Farid Zakaria's Blog&lt;/p&gt;
    &lt;p&gt;A problem I experienced when pursuing my PhD and submitting academic articles was that I had built solutions to problems that required dramatic scale to be effective and worthwhile. Responses to my publication submissions often claimed such problems did not exist; however, I had observed them during my time within industry, such as at Google, but I couldn‚Äôt cite it!&lt;/p&gt;
    &lt;p&gt;One problem that is only present at these mega-codebases is massive binaries. What‚Äôs the largest binary (ELF file) you‚Äôve ever seen? I had observed binaries beyond 25GiB, including debug symbols. How is this possible? These companies prefer to statically build their services to speed up startup and simplify deployment. Statically including all code in some of the world‚Äôs largest codebases is a recipe for massive binaries.&lt;/p&gt;
    &lt;p&gt;Similar to the sound barrier, there is a point at which code size becomes problematic and we must re-think how we link and build code. For x86_64, that is the 2GiB ‚ÄúRelocation Barrier.‚Äù&lt;/p&gt;
    &lt;p&gt;Why 2GiB? ü§î&lt;/p&gt;
    &lt;p&gt;Well let‚Äôs take a look at how position independent code is put-together.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs look at a simple example.&lt;/p&gt;
    &lt;code&gt;extern void far_function();

int main() {
    far_function();
    return 0;
}
&lt;/code&gt;
    &lt;p&gt;If we compile this &lt;code&gt;gcc -c simple-relocation.c -o simple-relocation.o&lt;/code&gt; we can inspect it with &lt;code&gt;objdump&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;gt; objdump -dr simple-relocation.o

0000000000000000 &amp;lt;main&amp;gt;:
   0:	55                   	push   %rbp
   1:	48 89 e5             	mov    %rsp,%rbp
   4:	b8 00 00 00 00       	mov    $0x0,%eax
   9:	e8 00 00 00 00       	call   e &amp;lt;main+0xe&amp;gt;
			a: R_X86_64_PLT32	far_function-0x4
   e:	b8 00 00 00 00       	mov    $0x0,%eax
  13:	5d                   	pop    %rbp
  14:	c3                   	ret
&lt;/code&gt;
    &lt;p&gt;There‚Äôs a lot going on here, but one important part is &lt;code&gt;e8 00 00 00 00&lt;/code&gt;. &lt;code&gt;e8&lt;/code&gt; is the &lt;code&gt;CALL&lt;/code&gt; opcode [ref] and it takes a 32bit signed relative offset, which happens to be 0 (four bytes of 0) right now. &lt;code&gt;objdump&lt;/code&gt; also lets us know there is a ‚Äúrelocation‚Äù necessary to fixup this code when we finalize it. We can view this relocation with &lt;code&gt;readelf&lt;/code&gt; as well.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note If you are wondering why we need&lt;/p&gt;&lt;code&gt;-0x4&lt;/code&gt;, it‚Äôs because the offset is relative to the instruction-pointer which has already moved to the next instruction. The 4 bytes is the operand it has skipped over.&lt;/quote&gt;
    &lt;code&gt;&amp;gt; readelf -r simple-relocation.o -d

Relocation section '.rela.text' at offset 0x170 contains 1 entry:
  Offset          Info           Type           Sym. Value    Sym. Name + Addend
00000000000a  000400000004 R_X86_64_PLT32    0000000000000000 far_function - 4
&lt;/code&gt;
    &lt;p&gt;This is additional information embedded in the binary which tells the linker in susbsequent stages that it has code that needs to be fixed. Here we see the address &lt;code&gt;00000000000a&lt;/code&gt;, and &lt;code&gt;a&lt;/code&gt; is 9 + 1, which is the offset of the start of the operand for our &lt;code&gt;CALL&lt;/code&gt; instruction.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs now create the C file for our missing function.&lt;/p&gt;
    &lt;code&gt;void far_function() {
}
&lt;/code&gt;
    &lt;p&gt;We will now compile it and link the two object files together using our linker.&lt;/p&gt;
    &lt;code&gt;&amp;gt; gcc simple-relocation.o far-function.o -o simple-relocation
&lt;/code&gt;
    &lt;p&gt;Let‚Äôs now inspect that same callsite and see what it has.&lt;/p&gt;
    &lt;code&gt;&amp;gt; objdump -dr simple-relocation

0000000000401106 &amp;lt;main&amp;gt;:
  401106:	55                   	push   %rbp
  401107:	48 89 e5             	mov    %rsp,%rbp
  40110a:	b8 00 00 00 00       	mov    $0x0,%eax
  40110f:	e8 07 00 00 00       	call   40111b &amp;lt;far_function&amp;gt;
  401114:	b8 00 00 00 00       	mov    $0x0,%eax
  401119:	5d                   	pop    %rbp
  40111a:	c3                   	ret

000000000040111b &amp;lt;far_function&amp;gt;:
  40111b:	55                   	push   %rbp
  40111c:	48 89 e5             	mov    %rsp,%rbp
  40111f:	90                   	nop
  401120:	5d                   	pop    %rbp
  401121:	c3                   	ret
&lt;/code&gt;
    &lt;p&gt;We can see that the linker did the right thing with the relocation and calculated the relative offset of our symbol &lt;code&gt;far_function&lt;/code&gt; and fixed the &lt;code&gt;CALL&lt;/code&gt; instruction.&lt;/p&gt;
    &lt;p&gt;Okay cool‚Ä¶ü§∑ What does this have to do with huge binaries?&lt;/p&gt;
    &lt;p&gt;Notice that this call instruction, &lt;code&gt;e8&lt;/code&gt;, only takes 32bits signed which means it‚Äôs limited to 2^31 bits. This means a callsite can only jump roughly 2GiB forward or 2GiB backward. The ‚Äú2GiB Barrier‚Äù represents the total reach of a single relative jump.&lt;/p&gt;
    &lt;p&gt;What happens if our callsite is over 2GiB away?&lt;/p&gt;
    &lt;p&gt;Let‚Äôs build a synthetic example by asking our linker to place &lt;code&gt;far_function&lt;/code&gt; really really far away. We can do this using a ‚Äúlinker script‚Äù.&lt;/p&gt;
    &lt;code&gt;SECTIONS
{
    /* 1. Start with standard low-address sections */
    . = 0x400000;
    
    /* Catch everything except our specific 'far' object */
    .text : { 
        simple-relocation.o(.text.*) 
    }
    .rodata : { *(.rodata .rodata.*) }
    .data   : { *(.data .data.*) }
    .bss    : { *(.bss .bss.*) }

    /* 2. Move the cursor for the 'far' island */
    . = 0x120000000; 
    
    .text.far : { 
        far-function.o(.text*) 
    }
}
&lt;/code&gt;
    &lt;p&gt;If we now try to link our code we will a ‚Äúrelocation overflow‚Äù. I used &lt;code&gt;lld&lt;/code&gt; from LLVM because the error messages are a bit prettier.&lt;/p&gt;
    &lt;code&gt;&amp;gt; gcc simple-relocation.o far-function.o -T overflow.lds -o simple-relocation-overflow -fuse-ld=lld

ld.lld: error: &amp;lt;internal&amp;gt;:(.eh_frame+0x6c):
relocation R_X86_64_PC32 out of range:
5364513724 is not in [-2147483648, 2147483647]; references section '.text'
ld.lld: error: simple-relocation.o:(function main: .text+0xa):
relocation R_X86_64_PLT32 out of range:
5364514572 is not in [-2147483648, 2147483647]; references 'far_function'
&amp;gt;&amp;gt;&amp;gt; referenced by simple-relocation.c
&amp;gt;&amp;gt;&amp;gt; defined in far-function.o
&lt;/code&gt;
    &lt;p&gt;When we hit this problem what solutions do we have? Well this is a complete other subject on ‚Äúcode models‚Äù, and it‚Äôs a little more nuanced depending on whether we are accessing data (i.e. static variables) or code that is far away. A great blog post that goes into this is the following by @maskray who wrote &lt;code&gt;lld&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The simplest solution however is to use &lt;code&gt;-mcmodel=large&lt;/code&gt; which changes all the relative &lt;code&gt;CALL&lt;/code&gt; instructions to absolute &lt;code&gt;JMP&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;gt; gcc simple-relocation.o far-function.o -T overflow.lds -o simple-relocation-overflow

&amp;gt; gcc -c simple-relocation.c -o simple-relocation.o -mcmodel=large -fno-asynchronous-unwind-tables

&amp;gt; gcc simple-relocation.o far-function.o -T overflow.lds -o simple-relocation-overflow

./simple-relocation-overflow
&lt;/code&gt;
    &lt;quote&gt;&lt;p&gt;Note I needed to add&lt;/p&gt;&lt;code&gt;-fno-asynchronous-unwind-tables&lt;/code&gt;to disable some additional data that might cause overflow for the purpose of this demonstration.&lt;/quote&gt;
    &lt;p&gt;What does the disassembly look like now?&lt;/p&gt;
    &lt;code&gt;&amp;gt; objdump -dr simple-relocation-overflow 

0000000120000000 &amp;lt;far_function&amp;gt;:
   120000000:	55                   	push   %rbp
   120000001:	48 89 e5             	mov    %rsp,%rbp
   120000004:	90                   	nop
   120000005:	5d                   	pop    %rbp
   120000006:	c3                   	ret

00000000004000e6 &amp;lt;main&amp;gt;:
  4000e6:	55                   	push   %rbp
  4000e7:	48 89 e5             	mov    %rsp,%rbp
  4000ea:	b8 00 00 00 00       	mov    $0x0,%eax
  4000ef:	48 ba 00 00 00 20 01 	movabs $0x120000000,%rdx
  4000f6:	00 00 00 
  4000f9:	ff d2                	call   *%rdx
  4000fb:	b8 00 00 00 00       	mov    $0x0,%eax
  400100:	5d                   	pop    %rbp
  400101:	c3                   	ret
&lt;/code&gt;
    &lt;p&gt;There is no longer a sole &lt;code&gt;CALL&lt;/code&gt; instruction, it has become &lt;code&gt;MOVABS&lt;/code&gt; &amp;amp; &lt;code&gt;CALL&lt;/code&gt; üò≤. This changed the instructions from 5 (opcode + 4 bytes for 32bit relative offset) to a whopping 12 bytes (2 bytes for &lt;code&gt;ABS&lt;/code&gt; opcode + 8 bytes for absolute 64 bit address + 2 bytes for &lt;code&gt;CALL&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;This has notable downsides among others:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instruction Bloat: We‚Äôve gone from 5 bytes per call to 12. In a binary with millions of callsites, this can add up.&lt;/item&gt;
      &lt;item&gt;Register Pressure: We‚Äôve burned a general-purpose register, &lt;code&gt;%rdx&lt;/code&gt;, to perform the jump.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;Caution I had a lot of trouble building a benchmark that demonstrated a worse lower IPC (instructions per-cycle) for the large&lt;/p&gt;&lt;code&gt;mcmodel&lt;/code&gt;, so let‚Äôs just take my word for it. ü§∑&lt;/quote&gt;
    &lt;p&gt;We would like to keep our small code-model. What other strategies can we pursue?&lt;/p&gt;
    &lt;p&gt;More to come in subsequent writings.&lt;/p&gt;
    &lt;p&gt; Improve this page @ f0a4dce &lt;lb/&gt; The content for this site is CC-BY-SA. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fzakaria.com/2025/12/28/huge-binaries"/><published>2025-12-29T05:35:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46417815</id><title>Show HN: Z80-ŒºLM, a 'Conversational AI' That Fits in 40KB</title><updated>2025-12-29T10:45:40.537829+00:00</updated><content>&lt;doc fingerprint="2da11bd4dafe81a"&gt;
  &lt;main&gt;
    &lt;p&gt;Z80-ŒºLM is a 'conversational AI' that generates short character-by-character sequences, with quantization-aware training (QAT) to run on a Z80 processor with 64kb of ram.&lt;/p&gt;
    &lt;p&gt;The root behind this project was the question: how small can we go while still having personality, and can it be trained or fine-tuned easily? With easy self-hosted distribution?&lt;/p&gt;
    &lt;p&gt;The answer is Yes! And a 40kb .com binary (including inference, weights &amp;amp; a chat-style UI) running on a 4MHz processor from 1976.&lt;/p&gt;
    &lt;p&gt;It won't pass the Turing test, but it might make you smile at the green screen.&lt;/p&gt;
    &lt;p&gt;For insight on how to best train your own model, see TRAINING.md.&lt;/p&gt;
    &lt;p&gt;Two pre-built examples are included:&lt;/p&gt;
    &lt;p&gt;A conversational chatbot trained on casual Q&amp;amp;A pairs. Responds to greetings, questions about itself, and general banter with terse personality-driven answers.&lt;/p&gt;
    &lt;code&gt;&amp;gt; hello
HI
&amp;gt; are you a robot
YES
&amp;gt; do you dream
MAYBE
&lt;/code&gt;
    &lt;p&gt;A 20 Questions game where the model knows a secret topic and answers YES/NO/MAYBE to your questions. Guess correctly to WIN.&lt;/p&gt;
    &lt;code&gt;&amp;gt; is it alive
YES
&amp;gt; is it big
YES
&amp;gt; does it have a trunk
YES
&amp;gt; is it grey
MAYBE
&amp;gt; elephant
WIN
&lt;/code&gt;
    &lt;p&gt;Includes tools for generating training data with LLMs (Ollama or Claude API) and balancing class distributions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Trigram hash encoding: Input text is hashed into 128 buckets - typo-tolerant, word-order invariant&lt;/item&gt;
      &lt;item&gt;2-bit weight quantization: Each weight is {-2, -1, 0, +1}, packed 4 per byte&lt;/item&gt;
      &lt;item&gt;16-bit integer inference: All math uses Z80-native 16-bit signed arithmetic&lt;/item&gt;
      &lt;item&gt;~40KB .COM file: Fits in CP/M's Transient Program Area (TPA)&lt;/item&gt;
      &lt;item&gt;Autoregressive generation: Outputs text character-by-character&lt;/item&gt;
      &lt;item&gt;No floating point: Everything is integer math with fixed-point scaling&lt;/item&gt;
      &lt;item&gt;Interactive chat mode: Just run &lt;code&gt;CHAT&lt;/code&gt;with no arguments&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The model doesn't understand you. But somehow, it gets you.&lt;/p&gt;
    &lt;p&gt;Your input is hashed into 128 buckets via trigram encoding - an abstract "tag cloud" representation. The model responds to the shape of your input, not the exact words:&lt;/p&gt;
    &lt;code&gt;"hello there"  ‚Üí  [bucket 23: 64, bucket 87: 32, ...]
"there hello"  ‚Üí  [bucket 23: 64, bucket 87: 32, ...]  (same!)
"helo ther"    ‚Üí  [bucket 23: 32, bucket 87: 32, ...]  (similar - typo tolerant)
&lt;/code&gt;
    &lt;p&gt;This is semantically powerful for short inputs, but there's a limit: longer or order-dependent sentences blur together as concepts compete for the same buckets. "Open the door and turn on the lights" will likely be too close to distringuish from "turn on the door and open the lights."&lt;/p&gt;
    &lt;p&gt;A 1-2 word response can convey surprising nuance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;OK&lt;/code&gt;- acknowledged, neutral&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;WHY?&lt;/code&gt;- questioning your premise&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;R U?&lt;/code&gt;- casting existential doubt&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;MAYBE&lt;/code&gt;- genuine uncertainty&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;AM I?&lt;/code&gt;- reflecting the question back&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This isn't necessarily a limitation - it's a different mode of interaction. The terse responses force you to infer meaning from context or ask probing direct yes/no questions to see if it understands or not (e.g. 'are you a bot', 'are you human', 'am i human' displays logically consistent memorized answers)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Short, varied inputs with consistent categorized outputs&lt;/item&gt;
      &lt;item&gt;Fuzzy matching (typos, rephrasing, word order)&lt;/item&gt;
      &lt;item&gt;Personality through vocabulary choice&lt;/item&gt;
      &lt;item&gt;Running on constrianed 8-bit hardware&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A chatbot that generates novel sentences&lt;/item&gt;
      &lt;item&gt;Something that tracks multi-turn context deeply&lt;/item&gt;
      &lt;item&gt;A parser that understands grammar&lt;/item&gt;
      &lt;item&gt;Anything approaching general intelligence&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's small, but functional. And sometimes that's exactly what you need&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Input: 128 query trigram buckets + 128 context buckets&lt;/item&gt;
      &lt;item&gt;Hidden layers: Configurable depth/width, e.g., 256 ‚Üí 192 ‚Üí 128&lt;/item&gt;
      &lt;item&gt;Output: One neuron per character in charset&lt;/item&gt;
      &lt;item&gt;Activation: ReLU between hidden layers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Z80 is an 8-bit CPU, but we use its 16-bit register pairs (HL, DE, BC) for activations and accumulators. Weights are packed 4-per-byte (2-bit each) and unpacked into 8-bit signed values for the multiply-accumulate.&lt;/p&gt;
    &lt;p&gt;The 16-bit accumulator gives us numerical stability (summing 256 inputs without overflow), but the model's expressiveness is still bottlenecked by the 2-bit weights, and naive training may overflow or act 'weirdly' without QAT.&lt;/p&gt;
    &lt;p&gt;The core of inference is a tight multiply-accumulate loop. Weights are packed 4-per-byte:&lt;/p&gt;
    &lt;code&gt;; Unpack 2-bit weight from packed byte
ld a, (PACKED)      ; Get packed weights
and 03h             ; Mask bottom 2 bits
sub 2               ; Map 0,1,2,3 ‚Üí -2,-1,0,+1
ld (WEIGHT), a

; Rotate for next weight
ld a, (PACKED)
rrca
rrca
ld (PACKED), a
&lt;/code&gt;
    &lt;p&gt;The multiply-accumulate handles the 4 possible weight values:&lt;/p&gt;
    &lt;code&gt;MULADD:
    or a
    jr z, DONE       ; weight=0: skip entirely
    jp m, NEG        ; weight&amp;lt;0: subtract
    ; weight=+1: add activation
    ld hl, (ACC)
    add hl, de
    ld (ACC), hl
    ret
NEG:
    cp 0FFh
    jr z, NEG1       ; weight=-1
    ; weight=-2: subtract twice
    ld hl, (ACC)
    sbc hl, de
    sbc hl, de
    ld (ACC), hl
    ret
NEG1:
    ; weight=-1: subtract once
    ld hl, (ACC)
    sbc hl, de
    ld (ACC), hl
    ret
&lt;/code&gt;
    &lt;p&gt;After each layer, arithmetic right-shift by 2 to prevent overflow:&lt;/p&gt;
    &lt;code&gt;sra h        ; Shift right arithmetic (preserves sign)
rr l
sra h
rr l         ; ACC = ACC / 4
&lt;/code&gt;
    &lt;p&gt;That's the entire neural network: unpack weight, multiply-accumulate, shift. Repeat ~100K times per character generated.&lt;/p&gt;
    &lt;p&gt;License: MIT or Apache-2.0 as you see fit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/HarryR/z80ai"/><published>2025-12-29T05:41:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46417844</id><title>Staying ahead of censors in 2025</title><updated>2025-12-29T10:45:40.176833+00:00</updated><content>&lt;doc fingerprint="be971c778814a0c2"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt; by meskio and shelikhoo | December 3, 2025 &lt;/p&gt;
      &lt;p&gt;From internet blackouts in Iran to Russia's evolving censorship tactics, 2025 has tested Tor's anti-censorship tools like never before. These are the moments where the work of Tor's anti-censorship team is more important than ever, to fulfill our mission of preserving connectivity between users in affected regions and the rest of the world.&lt;/p&gt;
      &lt;p&gt;In this blog post, we want to talk about what we've learned, how we've adapted, and what other internet users can do to keep Tor users connected.&lt;/p&gt;
      &lt;head rend="h2"&gt;Iran&lt;/head&gt;
      &lt;p&gt;In June, during the war between Iran and Israel, the censorship in Iran intensified up to a point where internet was disconnected for few days. Presumably to impede espionage-related communication while simultaneously consolidating political power.&lt;/p&gt;
      &lt;head rend="h3"&gt;Monitoring the censorship landscape&lt;/head&gt;
      &lt;p&gt;During this period, we were constantly monitoring the situation using our in-region vantage-point system. This vantage-point system is a network of monitoring locations inside Iran that provides more recent and accurate information about censorship than is available from public data.&lt;/p&gt;
      &lt;p&gt;One clear example is domain-fronting data. Domain-fronting is a technique that makes Tor traffic look like other popular, harder-to-block websites (like major cloud services). To determine which domain-fronting configurations perform best across the most locations, we deployed an automated testing tool that detects and reports the accessibility of the Snowflake broker and the Moat service for each domain-fronting configuration at each of our vantage points. This information is then aggregated by the log collector and subsequently used to monitor the domain-fronting configurations currently in use and to select the configurations to use in the future.&lt;/p&gt;
      &lt;head rend="h3"&gt;Strengthening Snowflake&lt;/head&gt;
      &lt;p&gt;Snowflake is the most used network traffic obfuscation tool in Iran. Over the past year we have been working on improving it to ensure that it remains strong and accessible to users.&lt;/p&gt;
      &lt;p&gt;We have upgraded the web extension to Manifest Version 3 (the latest browser extension standard), to be compatible with modern browsers. We improved the NAT checking logic which helps us figure out what kind of network setup each user has. This way, the proxies are more accurately assigned to the clients depending on their network capabilities. And we enhanced the metrics reported by the standalone proxy, providing better tooling for proxy operators to assist what is happening with their proxies.&lt;/p&gt;
      &lt;p&gt;Under the hood we have created a staging server for Snowflake, so we have a robust infrastructure to stress test new features making sure they're fit for real deployment. This will help us bring big changes in the coming year to improve the efficiency of the protocol where networks are severely disrupted and to create better mechanisms to prevent censors from blocking Snowflake.&lt;/p&gt;
      &lt;head rend="h3"&gt;Deploying Conjure&lt;/head&gt;
      &lt;p&gt;Censorship agencies like those in Iran often attempt to block bridges by obtaining bridge information in bulk and then inputing the network address of these bridges to their censorship gateways to block them. That's why we developed Conjure.&lt;/p&gt;
      &lt;p&gt;Conjure is a pluggable transport designed to stay ahead of proxy-listing-based blocking by leveraging unused address space within cooperating ISP networks, thereby limiting the damage caused by blocking individual network addresses. Think of it like the act of generating temporary email addresses to avoid spam emails, by making sure the address is temporary and easy to regenerate, anything blocked at that address won't affect your ability to get new ones.&lt;/p&gt;
      &lt;p&gt;We are working on distributing Conjure in places with strong censorship. To make it hard for censors, we have improved Tor's implementation of Conjure by extending the protocols used both for bootstrapping the connection and transport the data. We added multiple registration methods (DNS and AMP-cache), making the bootstrap of the conjure connection more censorship-resistant and the connection will look as if the user is connecting to widely used service. We also integrated additional transports from upstream (DTLS and prefix) that makes the Tor traffic look like common protocols‚Äìmeaning regular internet traffic.&lt;/p&gt;
      &lt;head rend="h2"&gt;Russia&lt;/head&gt;
      &lt;p&gt;Another region that has experienced many changes this year is Russia. With continued conflict and attrition, internet censorship has intensified, including increased allowlist-based censorship and address-block-based censorship.&lt;/p&gt;
      &lt;p&gt;Last year, we introduced WebTunnel as a new pluggable transport. We have seen this year how WebTunnel has become a key tool for users in Russia, thanks to its ability to blend into regular web traffic. As the severity of censorship in Russia has increased, WebTunnel has also received several fixes, such as SNI imitation and safe non-WebPKI certificate support with certificate-chain pinning to ensure it can withstand more kinds of censorship, including SNI allowlisting and the rapid blocking of distributed bridges.&lt;/p&gt;
      &lt;p&gt;Many of these improvements come from volunteers or are shaped by user feedback. Our community of users and supporters makes all this work possible and helps us stay ahead at Tor. Thanks to our Tor community team, we have first-hand insights into what works and what doesn't. This gives us access to the best information in the region. Additionally, through the community team's work with people on the ground, we receive support in testing and identifying the best technology for each censorship scenario.&lt;/p&gt;
      &lt;head rend="h3"&gt;Experimenting with bridge distribution&lt;/head&gt;
      &lt;p&gt;When we started distributing WebTunnel bridges in December they were a very useful tool to connect to Tor. They worked well for months, and Tor Browser users got them configured automatically over Connect Assist if they were located in Russia. However, in June, the Russian censors began listing most of our WebTunnel bridges, prompting us to shift strategies.&lt;/p&gt;
      &lt;p&gt;In recent history, our Telegram distributor has proven to be a useful tool in Russia, as the censor has a harder time extracting all the bridges from it. This is why we have now added support for WebTunnel in our Telegram distributor. We are always trying to meet our users where they are, and while Telegram might not be the safest place for your online communications, many users in Russia already uses it. And is not only useful for Russian users, but also for Iranian ones that are currently using webtunnel bridges distributed over Telegram.&lt;/p&gt;
      &lt;p&gt;All these fast changes of bridges distribution are possible thanks to rdsys, Tor's new bridge distribution system that we introduced last year. This year we kept improving rdsys adding a staging server, so we can stress-test it in a similar environments to the ones used in production. For our censored users that means that by the time new and updated anticensorship features arrive, we have already been able to fix many stability issues.&lt;/p&gt;
      &lt;head rend="h2"&gt;Where do we go from here?&lt;/head&gt;
      &lt;p&gt;Supporting our users to continue fighting censorship is what our work is all about. Making it possible to connect to the Tor network on censored networks‚Äìwhatever they are. Whether it is your university, your internet service provider, or your government trying to keep you from getting the information you are entitled to. Next year we'll start rolling out Conjure, keep improving WebTunnel,and prepare Snowflake for the next big censorship events.&lt;/p&gt;
      &lt;p&gt;You too can help us fight censorship today, by sharing your bandwidth and running your own Snowflake. The easiest way is to install a snowflake plugin in your browser to help others access the Tor network. And if you have a website consider running a webtunnel bridge.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://forum.torproject.org/t/staying-ahead-of-censors-in-2025-what-weve-learned-from-fighting-censorship-in-iran-and-russia/20898"/><published>2025-12-29T05:47:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46418966</id><title>Asking Gemini 3 for Brainf*ck code puts it in an infinite loop</title><updated>2025-12-29T10:45:40.091003+00:00</updated><content>&lt;doc fingerprint="1d08d21e938b9c3e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Brainf*ck is the Ultimate Test for AGI&lt;/head&gt;
    &lt;p&gt;Asking Gemini 3 to generate Brainf*ck code results in an infinite loop, akin amost to a DDoS attack:&lt;/p&gt;
    &lt;p&gt;That is fascinating. So it made me wonder. Is Brainf*ck the ultimate test for AGI? I think so, and for 3 good reasons.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. The Data Scarcity Problem&lt;/head&gt;
    &lt;p&gt;Large Language Models (LLMs) thrive on sheer volume. To master JavaScript, an LLM has been trained on virtually every available line of open-source code‚Äîhundreds of millions of lines of code (LOC). By comparison, the amount of functional Brainf*ck code on the web is a statistical rounding error.&lt;/p&gt;
    &lt;p&gt;We are talking about a million times less training data. Without the luxury of infinite patterns to copy, the model can't rely on mimicry; it has to understand the underlying logic.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Anti-Literate Programming&lt;/head&gt;
    &lt;p&gt;Brainf*ck is the antithesis of modern software engineering. There are no comments, no meaningful variable names, and no structure. In many ways, looking at existing Brainf*ck code is actually detrimental to a novice. Consider this typical snippet:&lt;/p&gt;
    &lt;code&gt;&amp;gt;++++++++[&amp;lt;+++++++++&amp;gt;-]&amp;lt;.&amp;gt;++++[&amp;lt;+++++++&amp;gt;-]&amp;lt;+.+++++++..+++.&amp;gt;&amp;gt;++++++[&amp;lt;+++++++&amp;gt;-]&amp;lt;+
+.------------.&amp;gt;++++++[&amp;lt;+++++++++&amp;gt;-]&amp;lt;+.&amp;lt;.+++.------.--------.&amp;gt;&amp;gt;&amp;gt;++++[&amp;lt;++++++++&amp;gt;-
]&amp;lt;+.&lt;/code&gt;
    &lt;p&gt;Writing in this environment is akin to zero-shot learning. Success requires reasoning at a high level of abstraction based on the fundamental rules of the language and a precise mental model of semantics, rather than memorized syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. The Repetition Problem&lt;/head&gt;
    &lt;p&gt;As we saw earlier, asking a modern model for complex Brainf*ck code often results in the model falling into an infinite loop‚Äîspewing the same characters over and over. The minimalistic nature of the language results in highly repetitive structures in the code. This poses a unique challenge to the way LLMs work.&lt;/p&gt;
    &lt;p&gt;An LLM is more likely to output what it has already seen based on previous tokens, and that pertains to its own output too. When some structure is repeated more than a couple of times, there is a likelihood that the model may learn that token X is the most likely output following itself. With every subsequent iteration, this increases the likelihood of outputting X in a self-fulfilling prophecy, resulting in the infinite loop.&lt;/p&gt;
    &lt;p&gt;So, is Brainf*ck the ultimate test for LLMs? You be the judge.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://teodordyakov.github.io/brainfuck-agi/"/><published>2025-12-29T09:40:09+00:00</published></entry></feed>