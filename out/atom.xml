<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-09T12:57:36.336286+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45852328</id><title>Why is Zig so cool?</title><updated>2025-11-09T12:57:44.646374+00:00</updated><content>&lt;doc fingerprint="2e0298192ea533d8"&gt;
  &lt;main&gt;&lt;p&gt;I can’t think of any other language in my 45 years long career that surprised more than Zig. I can easily say that Zig is not only a new programming language, but it’s a totally new way to write programs, in my opinion. To say it’s merely a language to replace C or C++, it’s a huge understatement.&lt;/p&gt;&lt;p&gt;In this article, I will present the features that I found to be most seductive in the language, and I will also present a brief overview about it. The goal is to present simple features for programmers to quick start in the language. Be aware, though, that many more features are affecting its acceptability in the industry.&lt;/p&gt;&lt;p&gt;Probably the most incredible virtue of Zig compiler is its ability to compile C code. This associated with the ability to cross-compile code to be run in another architecture, different than the machine where it is was originally compiled, is already something quite different and unique. These features alone, completely out-of-the-box, are causing an incredible impact in the industry already. In spite of that what we want to concentrate on is how to program in Zig and why should one choose Zig instead of any other language.&lt;/p&gt;&lt;p&gt;Installing the compiler is quite simple. In Zinglang’s download page one finds the compiler in several formats, depending on the processor or OS:&lt;/p&gt;&lt;p&gt;On Windows 10, for example, one chooses the x86_64 zip file and copy its decompressed content in the desired directory. For example, in “Program Files”. I modified the root directory name to “zig-windows-x86_64” because in this way I can just copy another version of the compiler with no need to modify the path in Path environment variable.&lt;/p&gt;&lt;p&gt;Next, one adds this root directory path to the Path environment variable using Advanced System Properties (clicking on 1-4, pasting path on 5, and clicking “OK” on 6-8):&lt;/p&gt;&lt;p&gt;Notice that after setting the path to Zig’s root directory one can already use the compiler in CLI mode. That’s the recommended way to use it for the sake of simplicity.&lt;/p&gt;&lt;p&gt;It’s recommended to build a “Hello World!” program using the instructions in the “Getting Started” section in this site. An alternative installation procedure is also presented there, including for MacOS and Linux (“Installing manually” is highly recommended). It’s also recommended to check the “Language” Basis section, for a deeper insight of Zig language.&lt;/p&gt;&lt;p&gt;The following sections will give a bird’s eye view of Zig language. Their goal is to instruct the programmer how to quickly start programming in Zig by just knowing a few basic concepts and commands.&lt;/p&gt;&lt;p&gt;Then, a compact view on how to build programs and test modules is given.&lt;/p&gt;&lt;p&gt;Finally, a deeper view on how low level programming can be done in Zig. A more detailed explanation on the examples used is also given.&lt;/p&gt;&lt;p&gt;Normally, variable declarations in Zig have potentially three parts. The first part contains the accessibility (&lt;code&gt;pub&lt;/code&gt; or nothing),
followed by the word &lt;code&gt;var&lt;/code&gt; or &lt;code&gt;const&lt;/code&gt;, followed by
the variable name. The second part, separated of the first part by a
colon, contains the variable type declaration. The third part is the
initialization of the variable. Only the first and third part are
compulsory in Zig, which is kind of puzzling, coming from Java or C. One
may wonder how the compiler discovers the variable type. The type in
this case is inferred by the initialization.&lt;/p&gt;&lt;code&gt;var sum : usize = 0;         // variable declaration with 3 parts&lt;/code&gt;&lt;p&gt;Variables that don’t have their accessibility explicitly &lt;code&gt;pub&lt;/code&gt; are local to the module, that is, they aren’t
accessible outside the source file it was declared (just like
&lt;code&gt;static&lt;/code&gt; variables in C). It’s not recommended to have
variables declared &lt;code&gt;pub&lt;/code&gt; and it’s recommended to have just
few functions declared &lt;code&gt;pub&lt;/code&gt; in a module to discourage
coupling and encourage cohesion. The &lt;code&gt;pub&lt;/code&gt; functions behave
as the module’s API.&lt;/p&gt;&lt;p&gt;In Zig, a &lt;code&gt;.{&lt;/code&gt; closed with a &lt;code&gt;}&lt;/code&gt; is an
“anonymous struct literal” - an anonymous struct mostly used to
initialize the elements of another structure or to create a new
structure with its elements initialized. A &lt;code&gt;.{ }&lt;/code&gt; is an an
empty anonymous struct literal. The word &lt;code&gt;struct&lt;/code&gt; followed by
a &lt;code&gt;{&lt;/code&gt; and closed with a &lt;code&gt;}&lt;/code&gt; is a struct
declaration. One can initialize a variable with a type, which functions
as an alias to the type. Notice the “test block” allowing to
compile and execute tests without the need of an executable.&lt;/p&gt;&lt;p&gt;Bitfields are declared fields with types having specific sizes in a &lt;code&gt;packed struct&lt;/code&gt;. Pointers can point to a specific bit field
as shown here:&lt;/p&gt;&lt;p&gt;Zig syntax is clearer than C’s, except that one would think it should be &lt;code&gt;[0..8]&lt;/code&gt;, but in reality it’s an open interval:
&lt;code&gt;[0..9)&lt;/code&gt;. Advantage in Zig: the type
declaration of &lt;code&gt;i&lt;/code&gt;, its initialization, test, and
incrementation are automatic.&lt;/p&gt;&lt;p&gt;A &lt;code&gt;[_]&lt;/code&gt; defines an array with unknown size. It must be followed
by the type of its elements (here &lt;code&gt;u8&lt;/code&gt;, unsigned
byte) and its initialization between &lt;code&gt;{&lt;/code&gt; and
&lt;code&gt;}&lt;/code&gt;. In this example below, the initialization is saying that
this is an array of unknown size (&lt;code&gt;[_]&lt;/code&gt;) where each element
is of type &lt;code&gt;u8&lt;/code&gt; (unsigned byte) and each element initialized
with zeros (&lt;code&gt;{0} ** 81&lt;/code&gt;). Notice that the size is also
inferred by the repetition factor (&lt;code&gt;81&lt;/code&gt;) of the
initialization (&lt;code&gt;{0}&lt;/code&gt;).&lt;/p&gt;&lt;code&gt;var grid = [_]u8{0} ** 81;&lt;/code&gt;&lt;p&gt;We see in the figure below a test environment with a loop interacting over the array and adding its elements. The &lt;code&gt;try expect&lt;/code&gt;
statement verifies that &lt;code&gt;sum&lt;/code&gt; is correct.&lt;/p&gt;&lt;p&gt;The word &lt;code&gt;byte&lt;/code&gt; is not a type or reserved word in Zig.
Here, it’s a variable to hold each of the array’s elements on each step
of the loop. Notice that a variable declared between two &lt;code&gt;|&lt;/code&gt;
with an array between the parenthesis of a for loop is always assumed of
the same type as the array elements.&lt;/p&gt;&lt;p&gt;Notice also, that &lt;code&gt;usize&lt;/code&gt; is the natural unsigned integer
for the platform. That means on 64 bits machines it’s an
&lt;code&gt;u64&lt;/code&gt;, and in 32 bits machines it’s an &lt;code&gt;u32&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Pointers to arrays can use pointer arithmetic only if the pointer is explicitly declared as a many-item pointer, here &lt;code&gt;[*]const i32&lt;/code&gt;. Notice that the array below is
&lt;code&gt;const&lt;/code&gt;, can’t be changed, but that the pointer is
&lt;code&gt;var&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;When attributed the address of an individual array position, a pointer cannot be updated with pointer arithmetic. In this case, &lt;code&gt;const&lt;/code&gt; only prevents its value to be changed with another
direct address attribution. To dereference pointers in Zig one uses the
&lt;code&gt;ptr.*&lt;/code&gt; as shown below:&lt;/p&gt;&lt;p&gt;Zig can do many things in compilation time. Let’s initialize an array, for example. Here, a labelled break is used. The block is labelled with an &lt;code&gt;:&lt;/code&gt; after its name &lt;code&gt;init&lt;/code&gt; and
then a value is returned from the block with &lt;code&gt;break&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;This syntax may look overwhelming. &lt;code&gt;0..&lt;/code&gt; means an infinite
range starting with zero. In the &lt;code&gt;for&lt;/code&gt;, variables &lt;code&gt;pt&lt;/code&gt; and
&lt;code&gt;i&lt;/code&gt; are respectively initialized with the address of
&lt;code&gt;initial_value&lt;/code&gt; array and zero. During the loop both are
incremented automatically and the loop stops right after dealing with
the array’s last position. Also notice how to dereference the
&lt;code&gt;pt&lt;/code&gt; pointer: &lt;code&gt;pt.*&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Also interesting it’s how the array is declared in the labelled block. The array is called &lt;code&gt;initial_value&lt;/code&gt; and has 10
positions of the type &lt;code&gt;Point&lt;/code&gt; (declared afterwards).
Variables must be initialized in Zig. The way to explicitly not
initialize is with the reserved word &lt;code&gt;undefined&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Functions in Zig are declared with &lt;code&gt;fn&lt;/code&gt; and are static by
default (cannot be imported in other files) in the file they are
declared, except when &lt;code&gt;fn&lt;/code&gt; is preceded by &lt;code&gt;pub&lt;/code&gt;. A
function can be “inlined.” Function pointers are preceded by
&lt;code&gt;const&lt;/code&gt; and followed by the function prototype.&lt;/p&gt;&lt;p&gt;Structs can have functions. Here, a simple stack is implemented. This stack is declared and used only inside the module it is defined, and it accesses and modifies other data structures in the module that are irrelevant in this example. The stack can have at maximum 81 elements (as seen in &lt;code&gt;stk&lt;/code&gt; declaration), each one of type
&lt;code&gt;StkNode&lt;/code&gt;. Notice that ++ and –– operators don’t exist in Zig.
The equivalent += and –= should be used instead. The stack pointer is
just an integer used as an index in the &lt;code&gt;stk&lt;/code&gt; array.&lt;/p&gt;&lt;p&gt;Notice that the pointer &lt;code&gt;self&lt;/code&gt; (&lt;code&gt;self&lt;/code&gt; is not a
reserved word, but it’s just a convention) is not passed explicitly as a
parameter as one would normally expect. It is indirectly assumed that it
is a pointer to the instance of the stack the function is been called
from. In the example below, a stack pop would be called with
&lt;code&gt;stack.pop();&lt;/code&gt;. In this case the pointer &lt;code&gt;self&lt;/code&gt;
corresponds to a pointer to &lt;code&gt;stack&lt;/code&gt;. This pointer is then
somewhat equivalent to &lt;code&gt;this&lt;/code&gt; in Java or C++.&lt;/p&gt;&lt;p&gt;Function &lt;code&gt;init()&lt;/code&gt; is the stack constructor.&lt;/p&gt;&lt;p&gt;Notice as well that functions &lt;code&gt;pop&lt;/code&gt; and &lt;code&gt;push&lt;/code&gt;
are “inlined.”&lt;/p&gt;&lt;p&gt;To build an executable program one needs a &lt;code&gt;main&lt;/code&gt;
function, which indicates the program entry point as in Java or C
programs. When this function exists the set of modules can be compiled
to an executable code. A simple program can have a &lt;code&gt;main&lt;/code&gt;
function in the same file as the rest of the program. In many cases one
can also insert a main function at the end of a module to create an
executable in order to debug the module independently. Once debugged
this function can be commented out.&lt;/p&gt;&lt;p&gt;In these situations one can use the following command line to compile &lt;code&gt;program.zig&lt;/code&gt; and to generate an executable program (on
Windows, a &lt;code&gt;program.exe&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;zig build-exe -O ReleaseFast program.zig&lt;/code&gt;&lt;p&gt;This can be put inside a batch file to prevent typos.&lt;/p&gt;&lt;p&gt;This is probably the best feature of Zig as a programming language. This environment is normally used for testing, but it can also be used for prototyping.&lt;/p&gt;&lt;p&gt;A block in Zig is similar to a block in C or Java, that is, some code between &lt;code&gt;{&lt;/code&gt; and &lt;code&gt;}&lt;/code&gt;. A test block is a
block that starts with &lt;code&gt;test "message" {&lt;/code&gt; and finishes with
&lt;code&gt;}&lt;/code&gt;, where &lt;code&gt;"message"&lt;/code&gt; is a string containing the
message to be displayed when the test is executed (in this case only the
word message).&lt;/p&gt;&lt;p&gt;Test blocks are executed independently from an executable file. The final executable file does not execute the tests. The test blocks in a given &lt;code&gt;module.zig&lt;/code&gt; are compiled together with the entire code
in that file and executed by the following command:&lt;/p&gt;&lt;code&gt;zig test module.zig&lt;/code&gt;&lt;p&gt;As a real life example, the test block from module example.zig is shown below:&lt;/p&gt;&lt;code&gt;test " =&amp;gt; testing set and print functions" {
    set(
      "800000000003600000070090200" ++
      "050007000000045700000100030" ++
      "001000068008500010090000400"
    );
    std.debug.print("\n" ++
      "===================\n" ++
      "Input Grid\n" ++
      "===================\n",
      .{}
    );
    print();
}&lt;/code&gt;&lt;p&gt;Notice that &lt;code&gt;example.zig&lt;/code&gt; alone has no main
function and, therefore, cannot generate an executable, but its test
block can be executed by using the following command:&lt;/p&gt;&lt;code&gt;zig test example.zig&lt;/code&gt;&lt;p&gt;As the message says, the test block above tests the functions &lt;code&gt;set&lt;/code&gt; and &lt;code&gt;print&lt;/code&gt;. As the code shows,
&lt;code&gt;set&lt;/code&gt; passes a string of decimal digits as a parameter,
followed by a print statement (which prints a header saying “Input Grid”
), followed itself by a call of the &lt;code&gt;print&lt;/code&gt; function.&lt;/p&gt;&lt;p&gt;The real display in a command tool is the following:&lt;/p&gt;&lt;p&gt;Let’s focus now on the &lt;code&gt;std.debug.print&lt;/code&gt; statement. This
statement is in fact a call to the function &lt;code&gt;print&lt;/code&gt; in
&lt;code&gt;debug.zig&lt;/code&gt; in the standard Zig library &lt;code&gt;std&lt;/code&gt;. The
first parameter is a format string, and the second is an anonymous
struct (preceded by a dot) containing a list of variables to be
displayed using the format string. Since there is no formatting in the
format string, the struct is empty. This is how formatted prints are
done. This one will display in the stderr by default, as shown
above.&lt;/p&gt;&lt;p&gt;This all looks just like in C language, but there is a fundamental difference here. In C, the printf function dynamically interprets the format string in execution time, whereas in Zig it’s possible to deal with the literal string and the list of variables in compilation time. This is a difficult principle to grasp at the start. Many things can be executed in compilation time.&lt;/p&gt;&lt;p&gt;Using a debugger is not usually a straightforward task, except in IDEs that already integrate a debugger (as in Java IDEs such as Eclipse or Intellij IDEA) or in integrated development kits (such as w64devkit for C/C++).&lt;/p&gt;&lt;p&gt;A huge inconvenient in using debuggers in this way is that one must integrate the symbols, which not only bloats the code with information that is not useful to the program, but also requires compiling in Debug mode, which generates executable code that’s notoriously less efficient. Someone with practice in complex systems knows that it can be a very time consuming task.&lt;/p&gt;&lt;p&gt;Zig offers a quite convenient hack in order to avoid these headaches.&lt;/p&gt;&lt;p&gt;This built-in stops a program at the point where a &lt;code&gt;@breakpoint();&lt;/code&gt; is inserted in the source code when its
executable is run in a debugger. This is actually an useful feature to
debug optimized Zig code without the need of symbols.&lt;/p&gt;&lt;p&gt;All it’s needed is to trace the variables one wants to watch using &lt;code&gt;std.debug.print&lt;/code&gt; right before &lt;code&gt;@breakpoint();&lt;/code&gt; In
this way one can know what are the values of the variables at that exact
moment.&lt;/p&gt;&lt;p&gt;As a real life example, one generates an executable for module debug_example.zig which has the has the following &lt;code&gt;main&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;pub fn main() !void {
    set(
      "800000000003600000070090200" ++
      "050007000000045700000100030" ++
      "001000068008500010090000400"
    );
}&lt;/code&gt;&lt;p&gt;To be able to double check with the results from example.zig, the parameter passed to &lt;code&gt;set&lt;/code&gt; function in this
&lt;code&gt;main&lt;/code&gt; is the same string as the one passed to
&lt;code&gt;set&lt;/code&gt; in the test block in example.zig,
but this time one inserts the following code inside &lt;code&gt;set&lt;/code&gt;
function:&lt;/p&gt;&lt;code&gt;        if (c != 0) {
           print();
           std.debug.print(
              "Current digit {}\nposition in string {}\n" ++
              "line {}\ncolumn {}\ncode {b}\n", 
              .{c, k, i, j, code}
           );
           @breakpoint();
        }&lt;/code&gt;&lt;p&gt;One can then generate the &lt;code&gt;debug_example.exe&lt;/code&gt; executable
with the following build command:&lt;/p&gt;&lt;code&gt;zig build-exe debug_example.zig&lt;/code&gt;&lt;p&gt;Next, one uses a debugger to call &lt;code&gt;debug_example.exe&lt;/code&gt;. In
this case I used &lt;code&gt;gdb&lt;/code&gt;, a debugger for C/C++ included in
w64devkit, but it could be any debugger for executable programs. Once
inside &lt;code&gt;gdb&lt;/code&gt;, one needs to run the program using an
&lt;code&gt;r&lt;/code&gt; command and typing &lt;code&gt;Enter&lt;/code&gt; right after as
shown below. Notice that the program printed the grid with its contents
so far as well as the variables, stopping
at the point expected. Then, by typing &lt;code&gt;c&lt;/code&gt; command followed
by an &lt;code&gt;Enter&lt;/code&gt; one continues tracing the grid contents and 
the variables. After that, one can continue by just typing 
&lt;code&gt;Enter&lt;/code&gt; (it repeats the last command - &lt;code&gt;c&lt;/code&gt;, in this 
case). By continuing typing &lt;code&gt;Enter&lt;/code&gt; until the program finishes, 
the values found in the grid correspond to the values shown by the test 
block in &lt;code&gt;example.zig&lt;/code&gt; above, since both examples have the same
parameter passed to &lt;code&gt;set&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;With the introduction and the examples given in the previous sections, one can already start programming Zig for writing generic applications. For more advanced programmers, what follows is a more in-depth analysis of some interesting low-level features already used in the examples, but not yet explicitly commented.&lt;/p&gt;&lt;p&gt;The idea of the examples shown is to construct a module that sets (initializes) and displays a 9x9 matrix. This matrix will hold a Sudoku grid, that is, it will only contain elements with decimal digits. The initialization of the grid should guarantee that the grid satisfies the rules of Sudoku game, so it will contain no errors.&lt;/p&gt;&lt;p&gt;At the same time it would be also an excellent opportunity to demonstrate Zig’s low level capabilities, at least the most noticeable ones, and these examples fit this goal quite well.&lt;/p&gt;&lt;p&gt;The whole hypothesis behind these examples is the representation of a grid digit as a bit in the position given by its value. This representation is quite convenient to detect if a digit is already present in the grid or not (these are basic rules of Sudoku grids). In spite of that, this is so encrypted it is only used internally in the module.&lt;/p&gt;&lt;p&gt;With the purpose of having values that are easily understood by humans, the digits are actually stored in the matrix as standard &lt;code&gt;u8&lt;/code&gt; integers. Even though the input grid in the examples is
given in string format, the ASCII characters are internally converted to
&lt;code&gt;u8&lt;/code&gt; integers. The digits’ storage in the grid is organized
linearly, line by line, in an array with 81 positions, called
&lt;code&gt;grid&lt;/code&gt; in the examples:&lt;/p&gt;&lt;code&gt;var grid = [_]u8{0} ** 81;        // Sudoku grid stored linearly&lt;/code&gt;&lt;p&gt;To verify grid correctness, one needs to access the elements by its respective line and column. In other words, one needs to access the elements as in a matrix. The strategy is to create an array of pointers with 9 positions, each one pointing to the start of each line. Blocks of code cannot in principle return a value, but in Zig they can with labeled breaks:&lt;/p&gt;&lt;code&gt;const matrix = fill9x9: {         // matrix array to allow access  
   var m : [9][*]u8 = undefined;  // to grid element as a matrix, 
   var pt : [*]u8 = &amp;amp;grid;        // thus: element = matrix[i][j]
   for (0..9) |i| {               //
      m[i] = pt;                  // stores pointers of each line
      pt += 9;                    // at each position of matrix
   }                              //
   break :fill9x9 m;              // initializes matrix with m
};&lt;/code&gt;&lt;p&gt;At the end of the loop, &lt;code&gt;m&lt;/code&gt; is returned outside the block
using a &lt;code&gt;break :fill9x9 m;&lt;/code&gt; command. Notice that
&lt;code&gt;fill9x9&lt;/code&gt; corresponds to the name of a label placed right
before the beginning of the block.&lt;/p&gt;&lt;p&gt;Supposing &lt;code&gt;i&lt;/code&gt; and &lt;code&gt;j&lt;/code&gt;, respectively an
element’s line and column, any element of the grid can be accessed using
this notation:&lt;/p&gt;&lt;code&gt;element = matrix[i][j]&lt;/code&gt;&lt;p&gt;The key concept used here is the replacement of an integer decimal digit &lt;code&gt;i&lt;/code&gt; by an integer &lt;code&gt;code&lt;/code&gt; such as:&lt;/p&gt;&lt;code&gt;      i ∈ [1,9]  →  code = 2ⁱ⁻¹
      i = 0      →  code = 0&lt;/code&gt;&lt;p&gt;In other words, the only bit of &lt;code&gt;code&lt;/code&gt; that is set to
&lt;code&gt;1&lt;/code&gt; is the bit at the position &lt;code&gt;i-1&lt;/code&gt; if
&lt;code&gt;i&lt;/code&gt; is between &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;9&lt;/code&gt;, otherwise
all bits of &lt;code&gt;code&lt;/code&gt; are zero.&lt;/p&gt;&lt;code&gt;code&lt;/code&gt; for
each digit&lt;p&gt;The table below shows the correspondence between digits and their binary representation:&lt;/p&gt;&lt;code&gt;code&lt;/code&gt; in
Zig&lt;p&gt;The value of &lt;code&gt;code&lt;/code&gt; is calculated in the function
&lt;code&gt;set&lt;/code&gt; using a left shift operator only if &lt;code&gt;c&lt;/code&gt; is
not zero:&lt;/p&gt;&lt;code&gt;code = @as(u9,1) &amp;lt;&amp;lt; (c-1);&lt;/code&gt;
&lt;p&gt;In Zig, constants must have a proper size in order to allow an operation to be compiled and to attribute the the result of an operation to a given variable. In this case, &lt;code&gt;code&lt;/code&gt; is declared of type
&lt;code&gt;u9&lt;/code&gt;. That’s another fundamental quality of Zig, to be able
to have variables with arbitrary bit size. As can be
seen in the table above, the maximum value that &lt;code&gt;code&lt;/code&gt; can have is 256,
which requires at least 9 bits to represent. The built-in
&lt;code&gt;@as&lt;/code&gt; allows to cast the &lt;code&gt;1&lt;/code&gt; constant to type
&lt;code&gt;u9&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;By representing digits as bits one can mirror the entire grid in much simpler ways.&lt;/p&gt;&lt;p&gt;The array &lt;code&gt;lines&lt;/code&gt; mirrors the entire grid by representing
each line with a &lt;code&gt;9&lt;/code&gt; bits integer, each bit representing a
decimal digit that might be present in the a line:&lt;/p&gt;&lt;code&gt;var   lines   = [_]u9{0} ** 9; &lt;/code&gt;
&lt;p&gt;In this way, by just accessing this array with the line &lt;code&gt;i&lt;/code&gt; of an element in the 9x9 grid one can know if a given
digit is already present in that line, by just performing a bitwise
and ( &lt;code&gt;&amp;amp;&lt;/code&gt; ) with the digit’s
&lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;lines[i] &amp;amp; code&lt;/code&gt;
&lt;p&gt;If the result of the operation above is zero, this means the digit is not yet present in the line &lt;code&gt;i&lt;/code&gt;. Otherwise we have a
duplicate.&lt;/p&gt;&lt;p&gt;The array &lt;code&gt;columns&lt;/code&gt; mirrors the entire grid by
representing each column with a &lt;code&gt;9&lt;/code&gt; bits integer:&lt;/p&gt;&lt;code&gt;var   columns = [_]u9{0} ** 9;&lt;/code&gt;
&lt;p&gt;In this way, by just accessing this array with the column &lt;code&gt;j&lt;/code&gt; of an element in the 9x9 grid one can know if a given
digit is already present in that column, by just performing a bitwise
and ( &lt;code&gt;&amp;amp;&lt;/code&gt; ) with the digit’s
&lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;columns[i] &amp;amp; code&lt;/code&gt;
&lt;p&gt;If the result of the operation above is zero, this means the digit is not yet present in the column &lt;code&gt;j&lt;/code&gt; . Otherwise it’s a
duplicate.&lt;/p&gt;&lt;p&gt;Let’s suppose an empty Sudoku grid, as it is the case when one is populating the grid with the input string as done in the examples. A new digit inserted at any empty element, must not already exist in the entire line, column or cell containing the new element.&lt;/p&gt;&lt;p&gt;Let’s suppose now this grid, already initialized:&lt;/p&gt;&lt;p&gt;A cell is each one of the nine 3x3 grids delimited by the thick lines. The key knowledge to understand at this point is that each specific element in the 9x9 grid has a unique line, column and cell that contains this element.&lt;/p&gt;&lt;p&gt;For example, the first cell of the grid contains the values: 3, 5, 6, 8, and 9. Therefore, the values: 1, 2, 4 and 7 are missing. Let’s suppose one is willing to place the value 7 in one of the empty places in the first cell. Obviously, one cannot place it in the only empty element of the first line, because 7 is already present in that line. One cannot place it in the only empty place in the first column either since 7 is already in that column. One can only place the 7 in one of the two empty elements of the second line. But one can’t know for sure which one is the good one.&lt;/p&gt;&lt;p&gt;Let’s examine now the second cell, which contains the values: 1, 5, 7, and 9. One can see that the only possible element in this cell where an 8 can be placed is in the first line at the empty position on the right of the value 7.&lt;/p&gt;&lt;p&gt;Arrays &lt;code&gt;lines&lt;/code&gt; and &lt;code&gt;columns&lt;/code&gt; take care of
checking duplicates in lines and in columns. A new array is then needed
to check duplicates in cells.&lt;/p&gt;&lt;p&gt;The array &lt;code&gt;cells&lt;/code&gt; mirrors the entire grid by representing
each cell with a &lt;code&gt;9&lt;/code&gt; bits integer:&lt;/p&gt;&lt;code&gt;var   cells   = [_]u9{0} ** 9;    // all elements at each cell&lt;/code&gt;
&lt;p&gt;Here is where things get more complicated. One cannot access &lt;code&gt;cells&lt;/code&gt; directly using the line or the column. It would be
easier if one could access &lt;code&gt;cells&lt;/code&gt; as a 3x3 matrix. This can
be done mimicking what has been done for the 9x9 matrix, that is,
filling the array &lt;code&gt;cell&lt;/code&gt; as follows:&lt;/p&gt;&lt;code&gt;const cell = fill3x3: {           // cell array to allows access
   var m : [3][*]u9 = undefined;  // cell elements as a matrix,
   var pt : [*]u9 = &amp;amp;cells;       // cell[cindx[i]][cindx[j]]
   for (0..3) |i| {               // 
      m[i] = pt;                  // stores pointers of each line
      pt += 3;                    // at each position of cell
   }                              //
   break :fill3x3 m;              // initializes cell with m
};                                //&lt;/code&gt;
&lt;p&gt;But now one needs to determine the line and column in &lt;code&gt;cell&lt;/code&gt; matrix from the line and column of the element in the
original 9x9 grid. One could use integer divisions to divide the line
and column by 3 to obtain the proper indexes, but a division operation
is notoriously slow. Two divisions makes it even worse. One can use the
following array to give the result of the division as follows:&lt;/p&gt;&lt;code&gt;const cindx   = [_]usize{ 0,0,0, 1,1,1, 2,2,2 };&lt;/code&gt;
&lt;p&gt;In this way, by just accessing this matrix with the line &lt;code&gt;i&lt;/code&gt; and column &lt;code&gt;j&lt;/code&gt; of an element in the 9x9 grid,
one can know if a given digit is already present in this element’s cell
by just performing a bitwise and ( &lt;code&gt;&amp;amp;&lt;/code&gt; )
with the digit’s &lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;cell[cindx[i]][cindx[j]] &amp;amp; code&lt;/code&gt;
&lt;p&gt;If the result of the operation above is zero, this means the digit is not yet present in the cell. Otherwise it’s a duplicate.&lt;/p&gt;&lt;p&gt;The complete test to verify if an element is duplicated can be done by composing with a bitwise or ( &lt;code&gt;|&lt;/code&gt; )
all the previous elements in the same line, column and cell, and then
performing a bitwise and ( &lt;code&gt;&amp;amp;&lt;/code&gt; ) with
the element’s &lt;code&gt;code&lt;/code&gt;, in this way:&lt;/p&gt;&lt;code&gt;if (((lines[i]|columns[j]|cell[cindx[i]][cindx[j]])&amp;amp;code) !=  0) {
    unreachable;
}&lt;/code&gt;
&lt;p&gt;If the result is zero it’s because the element doesn’t exist yet in its line, column or cell. If the result is not zero the program stops because it tries to run the instruction &lt;code&gt;unreacheable&lt;/code&gt;. This
is the simplest way to explicitly indicate an execution error in Zig.
Notice that the actual code in &lt;code&gt;set&lt;/code&gt; function also prints the
details where the error occurs.&lt;/p&gt;&lt;p&gt;For example, replacing the &lt;code&gt;'0'&lt;/code&gt; right after the first
&lt;code&gt;'8'&lt;/code&gt; by a &lt;code&gt;'5'&lt;/code&gt; in the string passed to
&lt;code&gt;set&lt;/code&gt; gives the following error while testing example.zig:&lt;/p&gt;&lt;p&gt;This is because in column 1 there was already a 5 in line 3 as the error message says. The error is due to a panic caused by reaching an unreachable code at function &lt;code&gt;set&lt;/code&gt; as indicated.&lt;/p&gt;&lt;p&gt;In function &lt;code&gt;set&lt;/code&gt;, a double &lt;code&gt;for&lt;/code&gt; loop
interacts line by line to copy each new element from the input string
&lt;code&gt;s&lt;/code&gt; into the grid as indicated below (variable &lt;code&gt;k&lt;/code&gt;
keeps the index of the new input character in the string
&lt;code&gt;s&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;   for ( 0..9 ) |i| {
      line = matrix[i];
      for ( 0..9 ) |j| {
        c = @intCast(s[k]-'0');
        if (c != 0) {
          code = @as(u9,1) &amp;lt;&amp;lt; (c-1);
          ⋮  // rest of the code
        }
        line[j] = c;
        k+= 1;  
      }
   }&lt;/code&gt;
&lt;p&gt;The character is converted to an &lt;code&gt;u4&lt;/code&gt; (variable
&lt;code&gt;c&lt;/code&gt;) by subtracting &lt;code&gt;'0'&lt;/code&gt; from it. If the new
element to be inserted in the grid is not equal to zero (
&lt;code&gt;c != 0&lt;/code&gt; ), &lt;code&gt;code&lt;/code&gt; (calculated with a left shift
instruction as indicated) is copied in each of the mirror grids, by
doing a bitwise or ( &lt;code&gt;|=&lt;/code&gt; ) with the
corresponding mirror grid, that is:&lt;/p&gt;&lt;code&gt;    lines[i] |= code;
    columns[j] |= code;
    cell[cindx[i]][cindx[j]] |= code;&lt;/code&gt;
&lt;p&gt;No test is required to explicitly test if the value of &lt;code&gt;c&lt;/code&gt;
is between &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;9&lt;/code&gt; because an overflow will
occur at execution time when the shift operation is executed. For
example, replacing the &lt;code&gt;'0'&lt;/code&gt; right after the first
&lt;code&gt;'8'&lt;/code&gt; of the input string by a &lt;code&gt;':'&lt;/code&gt; in the string
passed to &lt;code&gt;set&lt;/code&gt; gives the following error while testing example.zig:&lt;/p&gt;&lt;p&gt;By substituting the same &lt;code&gt;'0'&lt;/code&gt; by a &lt;code&gt;'/'&lt;/code&gt; a
similar execution error will issued. The program will work only if the
values are between &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;9&lt;/code&gt;, that is, if the
input grid contains only decimal digits.&lt;/p&gt;&lt;p&gt;Many Sudoku grids on the web also represent &lt;code&gt;'0'&lt;/code&gt; as a
&lt;code&gt;'.'&lt;/code&gt;. That’s the reason the following line exists in
&lt;code&gt;set&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;if (s[k] == '.') c = 0;&lt;/code&gt;
&lt;p&gt;This will conveniently bypass the shift operation because the value of &lt;code&gt;c&lt;/code&gt; is zero.&lt;/p&gt;&lt;p&gt;The forced errors shown in the two sections above demonstrate important features of Zig that might have passed inconspicuously. One is Zig’s robustness. In the case of the shift operation no wrong behavior is allowed and the situation is caught at execution time, as has been shown.&lt;/p&gt;&lt;p&gt;One might think that all the efforts in Zig are towards efficiency, but here it’s a typical case where performance was traded for robustness. One can have mixed feelings about this decision, when performance was the ultimate goal. In C, for example, it’s the programmer’s problem if a shift operation loses a bit and this translates in better performance for this specific Assembler instruction.&lt;/p&gt;&lt;p&gt;Another feature demonstrated in the two sections above is the possibility of using the test blocks for prototyping as suggested at the beginning of the article. The possibilities are numerous, even though the application shown was only to debug certain situations in cases of error.&lt;/p&gt;&lt;p&gt;These features alone demonstrate an awesome power, very rare in programming languages, particularly in compiled programing languages.&lt;/p&gt;&lt;p&gt;This is all quite surprising and let one think that many advantages previously found only in interpreted languages are gradually migrating to compiled languages in order to offer more performance. [A reference to Mojo here looks appropriate].&lt;/p&gt;&lt;p&gt;Zig resemblance to interpreted languages is quite striking, particularly with its concept of compile time execution, unfortunately not stressed enough in this article. This is an aspect of Zig that on one hand makes it particularly different and powerful but on the other hand difficult to grasp.&lt;/p&gt;&lt;p&gt;I concentrated more in instructing how to have a quick and easy start with the language, and in simple aspects that make Zig language cool, although there are many other aspects not mentioned here that are also quite impressive.&lt;/p&gt;&lt;p&gt;The examples shown here are simplified versions of a more involved program to solve Sudoku grids, which was also developed in Java and in C. The documentation in this repository explains in detail most of the structures and algorithms used to accomplish that.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nilostolte.github.io/tech/articles/ZigCool.html"/><published>2025-11-07T23:04:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45856804</id><title>Study identifies weaknesses in how AI systems are evaluated</title><updated>2025-11-09T12:57:42.458485+00:00</updated><content>&lt;doc fingerprint="7dc8d0970fb3495b"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;A new study led by the Oxford Internet Institute (OII) at the University of Oxford and involving a team of 42 researchers from leading global institutions including EPFL, Stanford University, the Technical University of Munich, UC Berkeley, the UK AI Security Institute, the Weizenbaum Institute, and Yale University, has found that many of the tests used to measure the capabilities and safety of large language models (LLMs) lack scientific rigour. &lt;/p&gt;
      &lt;p&gt;In Measuring What Matters: Construct Validity in Large Language Model Benchmarks, accepted for publication in the upcoming NeurIPS conference proceedings, researchers review 445 AI benchmarks – the standardised evaluations used to compare and rank AI systems. &lt;/p&gt;
      &lt;p&gt;The researchers found that many of these benchmarks are built on unclear definitions or weak analytical methods, making it difficult to draw reliable conclusions about AI progress, capabilities or safety. &lt;/p&gt;
      &lt;p&gt;“Benchmarks underpin nearly all claims about advances in AI,” says Andrew Bean, lead author of the study. “But without shared definitions and sound measurement, it becomes hard to know whether models are genuinely improving or just appearing to.” &lt;/p&gt;
      &lt;p&gt;Benchmarks play a central role in how AI systems are designed, deployed, and regulated. They guide research priorities, shape competition between models, and are increasingly referenced in policy and regulatory frameworks, including the EU AI Act, which calls for risk assessments based on “appropriate technical tools and benchmarks.” &lt;/p&gt;
      &lt;p&gt;The study warns that if benchmarks are not scientifically sound, they may give developers and regulators a misleading picture of how capable or safe AI systems really are. &lt;/p&gt;
      &lt;p&gt;“This work reflects the kind of large-scale collaboration the field needs,” adds Dr. Adam Mahdi. “By bringing together leading AI labs, we’re starting to tackle one of the most fundamental gaps in current AI evaluation.” &lt;/p&gt;
      &lt;p&gt;Key findings &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt; Lack of statistical rigour&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Only 16% of the reviewed studies used statistical methods when comparing model performance. This means that reported differences between systems or claims of superiority could be due to chance rather than genuine improvement. &lt;/p&gt;
      &lt;list start="2" rend="ol"&gt;
        &lt;item&gt; Vague or contested definitions&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Around half of the benchmarks aimed to measure abstract ideas such as reasoning or harmlessness without clearly defining what those terms mean. Without a shared understanding of these concepts, it is difficult to ensure that benchmarks are testing what they intend to.&lt;/p&gt;
      &lt;p&gt;Examples &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Confounding formatting rules – A test might ask a model to solve a simple logic puzzle but also require it to present the answer in a very specific, complicated format. If the model gets the puzzle right but fails the formatting, it looks worse than it really is. &lt;/item&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Brittle performance – A model might do well on short, primary school-style maths questions, but if you change the numbers or wording slightly, it suddenly fails. This shows it may be memorising patterns rather than truly understanding the problem&lt;/item&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Unsupported claims – If a model scores well on multiple-choice questions from medical exams, people might claim it has doctor-level expertise. But passing an exam is only one small part of what doctors do, so the result can be misleading.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Recommendations for better benchmarking &lt;/p&gt;
      &lt;p&gt;The authors stress that these problems are fixable. Drawing on established methods from fields such as psychometrics and medicine, they propose eight recommendations to improve the validity of AI benchmarks. These include: &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;Define and isolate: Provide a precise, operational definition for the concept being measured and control for unrelated factors. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;Build representative evaluations: Ensure test items represent real-world conditions and cover the full scope of the target skill or behaviour. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;Strengthen analysis and justification: Use statistical methods to report uncertainty and enable robust comparisons; conduct detailed error analysis to understand why a model fails; and justify why the benchmark is a valid measure for its intended purpose. &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;The team also provides a Construct Validity Checklist, a practical tool researchers, developers, and regulators can use to assess whether an AI benchmark follows sound design principles before relying on its results. The checklist is available at https://oxrml.com/measuring-what-matters/ &lt;/p&gt;
      &lt;p&gt;The paper, Measuring What Matters: Construct Validity in Large Language Model Benchmarks, will be published as part of the NeurIPS 2025 peer-reviewed conference proceedings in San Diego from 2-7 December. The peer-reviewed paper is available on request. &lt;/p&gt;
      &lt;p&gt;Media spokespeople &lt;/p&gt;
      &lt;p&gt;Lead author: Andrew Bean, Doctoral Student, Oxford Internet Institute, University of Oxford &lt;/p&gt;
      &lt;p&gt;Senior authors: Adam Mahdi, Associate Professor, and Luc Rocher, Associate Professor, Oxford Internet Institute, University of Oxford &lt;/p&gt;
      &lt;p&gt;Contact &lt;/p&gt;
      &lt;p&gt;For more information and briefings, please contact: &lt;lb/&gt; Anthea Milnes, Head of Communications &lt;lb/&gt; Sara Spinks / Veena McCoole, Media and Communications Manager &lt;/p&gt;
      &lt;p&gt;T: +44 (0)1865 280527 &lt;/p&gt;
      &lt;p&gt;M: +44 (0)7551 345493 &lt;/p&gt;
      &lt;p&gt;E: press@oii.ox.ac.uk &lt;/p&gt;
      &lt;p&gt;About the Oxford Internet Institute (OII) &lt;/p&gt;
      &lt;p&gt;The Oxford Internet Institute (OII) has been at the forefront of exploring the human impact of emerging technologies for 25 years. As a multidisciplinary research and teaching department, we bring together scholars and students from diverse fields to examine the opportunities and challenges posed by transformative innovations such as artificial intelligence, large language models, machine learning, digital platforms, and autonomous agents. &lt;/p&gt;
      &lt;p&gt;About the University of Oxford &lt;/p&gt;
      &lt;p&gt;Oxford University was placed number one in the Times Higher Education World University Rankings for the tenth year running in 2025. At the heart of this success are the twin-pillars of our ground-breaking research and innovation and our distinctive educational offer. Oxford is world-famous for research and teaching excellence and home to some of the most talented people from across the globe. &lt;/p&gt;
      &lt;p&gt;Funding information &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="1" data-aria-level="1"&gt;A.M.B. is supported in part by the Clarendon Scholarships and the Oxford Internet Institute’s Research Programme on AI &amp;amp; Work. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="2" data-aria-level="1"&gt;A.M. is supported by the Oxford Internet Institute’s Research Programme on AI &amp;amp; Work. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="3" data-aria-level="1"&gt;R.O.K. is supported by a Fellowship from the Cosmos Institute. H.M. is supported by ESRC [ES/P000649/1] and would like to acknowledge the London Initiative for Safe AI. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="4" data-aria-level="1"&gt;C.E. is supported by the EPSRC Centre for Doctoral Training in Health Data Science (EP/S02428X/1) and the AXA Research Fund. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="5" data-aria-level="1"&gt;F.L. is supported by Clarendon and Jason Hu studentships. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="6" data-aria-level="1"&gt;H.R.K.’s PhD is supported by the Economic and Social Research Council grant ES/P000649/1. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="7" data-aria-level="1"&gt;M.G. was supported by the SMARTY (PCI2024-153434) project funded by the Agencia Estatal de Investigación (doi:10.13039/501100011033) and by the European Commission through the Chips Act Joint Undertaking project SMARTY (Grant 101140087). This material is based in part upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-2139841. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="8" data-aria-level="1"&gt;O.D. is supported by the UKRI’s EPSRC AIMS CDT grant (EP/S024050/1). &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="9" data-aria-level="1"&gt;J.R is supported by the Engineering and Physical Sciences Research Council. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="10" data-aria-level="1"&gt;J.B. would like to acknowledge funding by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 16DII131. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="11" data-aria-level="1"&gt;A. Bibi would like to acknowledge the UK AISI systemic safety grant. &lt;/item&gt;
      &lt;/list&gt;
      &lt;list rend="ul"&gt;
        &lt;item data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" data-aria-posinset="12" data-aria-level="1"&gt;A. Bosselut gratefully acknowledges the support of the Swiss National Science Foundation (No. 215390), Innosuisse (PFFS-21-29), the EPFL Center for Imaging, Sony Group Corporation, and a Meta LLM Evaluation Research Grant. &lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.oii.ox.ac.uk/news-events/study-identifies-weaknesses-in-how-ai-systems-are-evaluated/"/><published>2025-11-08T14:18:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45857988</id><title>Opencloud – An alternative to Nextcloud written in Go</title><updated>2025-11-09T12:57:41.927828+00:00</updated><content>&lt;doc fingerprint="ef05bc5f19e668bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Tip&lt;/p&gt;
    &lt;p&gt;For general information about OpenCloud and how to install please visit OpenCloud on Github and OpenCloud GmbH.&lt;/p&gt;
    &lt;p&gt;This is the main repository of the OpenCloud server. It contains the golang codebase for the backend services.&lt;/p&gt;
    &lt;p&gt;The OpenCloud server is released under Apache 2.0. The project is thrilled to receive contributions in all forms. Start hacking now, there are many ways to get involved such as:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reporting issues or bugs&lt;/item&gt;
      &lt;item&gt;Requesting features&lt;/item&gt;
      &lt;item&gt;Writing documentation&lt;/item&gt;
      &lt;item&gt;Writing code or extend our tests&lt;/item&gt;
      &lt;item&gt;Reviewing code&lt;/item&gt;
      &lt;item&gt;Helping others in the community&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every contribution is meaningful and appreciated! Please refer to our Contribution Guidelines if you want to get started.&lt;/p&gt;
    &lt;p&gt;To build the backend, follow these instructions:&lt;/p&gt;
    &lt;p&gt;Generate the assets needed by e.g., the web UI and the builtin IDP&lt;/p&gt;
    &lt;code&gt;make generate&lt;/code&gt;
    &lt;p&gt;Then compile the &lt;code&gt;opencloud&lt;/code&gt; binary&lt;/p&gt;
    &lt;code&gt;make -C opencloud build&lt;/code&gt;
    &lt;p&gt;That will produce the binary &lt;code&gt;opencloud/bin/opencloud&lt;/code&gt;. It can be started as a local test instance right away with a two step command:&lt;/p&gt;
    &lt;code&gt;opencloud/bin/opencloud init &amp;amp;&amp;amp; opencloud/bin/opencloud server&lt;/code&gt;
    &lt;p&gt;This creates a server configuration (by default in &lt;code&gt;$HOME/.opencloud&lt;/code&gt;) and starts the server.&lt;/p&gt;
    &lt;p&gt;For more setup- and installation options consult the Development Documentation.&lt;/p&gt;
    &lt;p&gt;Important information for contributors about the technology in use.&lt;/p&gt;
    &lt;p&gt;The OpenCloud backend authenticates users via OpenID Connect using either an external IdP like Keycloak or the embedded LibreGraph Connect identity provider.&lt;/p&gt;
    &lt;p&gt;The OpenCloud backend does not use a database. It stores all data in the filesystem. By default, the root directory of the backend is &lt;code&gt;$HOME/.opencloud/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If you find a security-related issue, please contact security@opencloud.eu immediately.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/opencloud-eu/opencloud"/><published>2025-11-08T16:40:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45858905</id><title>Marko – A declarative, HTML‑based language</title><updated>2025-11-09T12:57:41.568221+00:00</updated><content>&lt;doc fingerprint="a876cc8c70be3ce3"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Trusted&lt;/head&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;Powering high-traffic, production-grade websites like eBay.com&lt;/p&gt;&lt;p&gt;If you know HTML, CSS, and JavaScript, you know Marko&lt;/p&gt;&lt;p&gt;Streaming, resumable, optimizing compiler, and a tiny runtime&lt;/p&gt;&lt;p&gt;From simple HTML templates to powerful components as needed&lt;/p&gt;&lt;p&gt;Marko is HTML re‑imagined as a language for building dynamic and reactive user interfaces.&lt;/p&gt;&lt;p&gt;Just about any valid HTML is valid Marko, but Marko extends the HTML language to allow building modern applications in a declarative way.&lt;/p&gt;Check it out!&lt;p&gt;Marko streams content to your users as soon as it's ready. No waiting for client side JavaScript bundles or data requests to start rendering.&lt;/p&gt;&lt;p&gt;HTML, assets, and images are loaded as soon as possible with asynchronous content loading in as it completes.&lt;/p&gt;Learn How&lt;p&gt;Browsers and servers are built differently, shouldn't your code be too? Marko compiles your templates to perform their best with optimized, environment-specific output.&lt;/p&gt;&lt;p&gt;Faster loads. Smaller bundles. One seamless language.&lt;/p&gt;Learn How&lt;p&gt;Marko has built-in TypeScript support , with strong type inference that works across templates and components. Editors get full language features like autocompletion, jump-to-definition, syntax highlighting, and clean formatting.&lt;/p&gt;&lt;p&gt;Build confidently. Catch errors early. Write better code, faster.&lt;/p&gt;Explore&lt;p&gt;Need help? Want to Contribute?&lt;/p&gt;&lt;p&gt;Get involved in the Marko Community!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://markojs.com/"/><published>2025-11-08T18:43:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45859243</id><title>Avería: The Average Font (2011)</title><updated>2025-11-09T12:57:41.205523+00:00</updated><content>&lt;doc fingerprint="367d013713a223d1"&gt;
  &lt;main&gt;
    &lt;p&gt;am not a type designer. This is the story of the creation of a new font, Avería: the average of all the fonts on my computer. The field of typography has long fascinated me, and I love playing with creative programming ideas, so it was perhaps inevitable that the idea came to me one day of “generative typography”. A Google on the subject brought up little, and I put the idea to the back of my mind until it occurred to me that perhaps the process of averaging, or interpolating, existing fonts might bring up interesting results. Luckily at this point I didn't do any more web searching – instead I grabbed my laptop and came up with an initial idea for finding what the average of all my fonts might look like – by overlaying each letter at low opacity. The results can be seen in the below image.&lt;/p&gt;
    &lt;p&gt;This was done by printing each letter of each font, at the same point size, to lots of separate images, and then averaging them – using ImageMagick and PHP. The letters were aligned to the same centre point. I later realised that each font has a ‘baseline’ defined, and an origin on that baseline which each glyph is drawn relative to. The same process, repeated with equal origins, gives slightly different results (see below) – here you can see the baseline is very well-defined, with the glyphs becoming more blurred towards the top right of each.&lt;/p&gt;
    &lt;p&gt;I was quite pleased with the results. It was only later that I discovered this had already been done – though it appeared that my end results (whilst not as beautifully animated) had a little more clarity, so I'm glad I tried for myself. But this didn't seem like the end of the journey. Whilst this was an interesting experiment, and showed an lot of correlation between a sample of common fonts (as well as a couple of oddities – notably the lower case ‘g’ which clearly exists in two distinct common forms), what I really wanted was an average which somehow preserved the well-defined edges of existing fonts. So I started considering ways to produce a smoother, sharper average of letter forms.&lt;/p&gt;
    &lt;p&gt;One idea which seemed obvious was to simply take the blurry results of the first experiment, and use a threshold to create monochrome images. A few experiments in this direction (I first tried with a lower-case ‘f’, which I later found was never likely to give good results due to the variance in height of the middle cross-stroke) convinced me that I needed to look into cleverer ways to achieve this. Surely there must be a simple way to average shapes, while keeping the result as a shape?&lt;/p&gt;
    &lt;p&gt;It turns out not to be straightforward. There are many possible ways to ‘morph’ between two shapes – and what might seem the most natural generally depends on our perception of ‘features’ in the shapes. Consider the average of a capital I with serifs, and one without: the natural thing to do would be something like, make the serifs half as big, and use a horizontal stem width about half-way between the two glyphs. That's two feature concepts being applied to the abstract forms¹. To take a simpler example, what is the average of a square with the same square rotated 45˚? There are a few possibilities …&lt;/p&gt;
    &lt;p&gt;So, this stumped me for a while. I decided I needed to get to know fonts better, so I built a simple web app to view the lines, curves and control points present in the fonts I had. On this basis, I started to consider the ways the features (vertices, curves, stems, serifs etc) might be matched up between fonts. However, this was a rabbit hole I might never get to the bottom of - particularly when considering some of the more unusual varieties of font. Perhaps there was a simpler idea that was evading me.&lt;/p&gt;
    &lt;p&gt;Then it occurred to me: since my aim was to average a large number of fonts, perhaps it would be best to use a very simple process, and hope the results averaged out well over a large number of fonts. So, how about splitting each letter perimeter into lots of (say, 500) equally-spaced points, and just average between the corresponding positions of each, on each letter? It would be necessary to match up the points so they were about the same location in each letter, and then the process would be fairly simple².&lt;/p&gt;
    &lt;p&gt;Having found a simple process to use, I was ready to start. And after about a month of part-time slaving away (sheer fun! Better than any computer game) – in the process of which I learned lots about bezier curves and font metrics – I had a result. I call it Avería – which is a Spanish word related to the root of the word ‘average’. It actually means mechanical breakdown or damage. This seemed curiously fitting, and I was assured by a Spanish friend-of-a-friend that “Avería is an incredibly beautiful word regardless of its meaning”. So that's nice.&lt;/p&gt;
    &lt;p&gt;Along the way I naturally called on the counsel of the best designers I know – my brother Nick Sayers, Lloyd Thomas, Tom Muller and Chris McGrail, for advice. In the end, I decided to release the font using the SIL Open Font License – which means anyone can use it pretty much however they like – and to include within the family Regular, Bold and Light variants with Italics. Each is made from the corresponding subsets of the fonts on my machine. Also included is a “Gruesa” version made from all my fonts (725 in total).&lt;lb/&gt; Avería Family (ZIP, 369kB) [Updated 9 Nov 2011]&lt;lb/&gt; Avería at The Open Font Library&lt;lb/&gt; *NEW* by popular demand:&lt;lb/&gt; Avería Serif Family (ZIP, 323kB) OFLB&lt;lb/&gt; Avería Sans Family (ZIP, 320kB) OFLB&lt;lb/&gt; *NEW* Avería, Serif and Sans packaged as TTC TrueType collections (so you can install each family in one go, rather than one variant at a time). Thanks Ludwig:&lt;lb/&gt; Avería TTC Files (ZIP, 946kB)&lt;lb/&gt; *NEW* versions of Avería, based on OFL fonts from the Google Web Fonts directory - now available through GWF as Avería Libre:&lt;lb/&gt; Avería GWF Family (ZIP, 488kB)&lt;lb/&gt; Avería Serif GWF Family (ZIP, 432kB)&lt;lb/&gt; Avería Sans GWF Family (ZIP, 426kB)&lt;lb/&gt; Preview all&lt;lb/&gt; Feel free to email me if you have any questions – or use the comments box below.&lt;lb/&gt; N.B. I've had a number of emails from people asking if they can use Avería in various commercial / non-commercial projects. I'd love to hear if you do something with these fonts – but there's no need to ask permission. You are absolutely free to use them however you like. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://iotic.com/averia/"/><published>2025-11-08T19:29:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45859471</id><title>Largest cargo sailboat completes first Atlantic crossing</title><updated>2025-11-09T12:57:40.981371+00:00</updated><content>&lt;doc fingerprint="df5cacd41833d6da"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;World’s Largest Cargo Sailboat Completes Historic First Atlantic Crossing&lt;/head&gt;
    &lt;p&gt;The world’s largest cargo sailboat, Neoliner Origin, completed its first transatlantic voyage on 30 October despite damage to one of its sails during the journey.&lt;/p&gt;
    &lt;p&gt;The 136-metre-long vessel had to rely partly on its auxiliary motor and its remaining sail after the aft sail was damaged in a storm shortly after departure.&lt;/p&gt;
    &lt;p&gt;The French-built roll-on/roll-off (RoRo) cargo ship, which has two semi-rigid sails, first stopped at Saint Pierre and Miquelon, a French overseas territory near Canada, before continuing its journey to Baltimore in the United States.&lt;/p&gt;
    &lt;p&gt;Neoline, the company behind the project, said the damage reduced the vessel’s ability to perform fully on wind power. The company’s CEO, Jean Zanuttini, said the crossing was a valuable experience in handling large sail surfaces across the North Atlantic, especially during late-season storms. He added that despite the difficulties, the ship showed strong resilience by reaching its destination with only a short delay in Saint Pierre.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is designed to reduce greenhouse gas emissions by 80 to 90 per cent compared to conventional diesel-powered cargo ships. According to the United Nations Conference on Trade and Development (UNCTAD), global shipping produces about 3 per cent of worldwide greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Zanuttini said the company aims to balance industrial needs with environmental responsibility. He added that wind propulsion offers an advantage because it is a free, widely available, and predictable energy source that does not harm ecosystems.&lt;/p&gt;
    &lt;p&gt;The UK’s National Clean Maritime Research Hub has reported that wind propulsion systems like those on the Neoliner Origin can cut emissions by over 50 per cent on new vessels optimised for wind conditions. Retrofitted vessels can also achieve reductions of 5 to 20 per cent, and up to 30 per cent when adjusted for wind conditions.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin was designed by the French naval engineering firm Mauric. The company’s CEO, Vincent Seguin, said the goal was to develop a ship that relies primarily on wind propulsion while ensuring consistent delivery schedules and efficient operation with a smaller crew.&lt;/p&gt;
    &lt;p&gt;Inspired by historic sailing vessels, the Neoliner Origin integrates modern systems such as advanced navigation, anti-drift mechanisms, and automated sail management to comply with current safety and operational standards.&lt;/p&gt;
    &lt;p&gt;The ship can carry up to 5,300 tonnes of cargo, including containers, vehicles, machinery, and specialised goods. It arrived in Baltimore carrying Renault vehicles, French liqueurs, machinery, and other products.&lt;/p&gt;
    &lt;p&gt;The Neoliner Origin is scheduled to make monthly voyages between Europe and North America, maintaining a commercial cruising speed of around 11 knots.&lt;/p&gt;
    &lt;p&gt;Reference: Reuters&lt;/p&gt;
    &lt;head rend="h4"&gt;⚓️ Enhance Your Knowledge. Prevent Accidents. Stay Safe at Sea.&lt;/head&gt;
    &lt;p&gt;1. eBooks for Engine Department&lt;/p&gt;
    &lt;p&gt;Master machinery operations, troubleshooting, and safety procedures with expertly written guides tailored for marine engineers. Prevent costly breakdowns and onboard accidents through practical knowledge.&lt;/p&gt;
    &lt;p&gt;👉 Explore Engine Department eBooks&lt;/p&gt;
    &lt;p&gt;2. eBooks for Deck Department&lt;/p&gt;
    &lt;p&gt;Sharpen your seamanship, navigation, and cargo-handling skills with real-world case studies and practical insights designed for deck officers and cadets.&lt;/p&gt;
    &lt;p&gt;👉Discover Deck Department eBooks&lt;/p&gt;
    &lt;p&gt;3. eBooks on Electrical Fundamentals &amp;amp; Issues&lt;/p&gt;
    &lt;p&gt;Understand marine electrical systems, identify potential faults, and prevent onboard electrical failures with step-by-step explanations from industry experts.&lt;/p&gt;
    &lt;p&gt;4. Pocket Guides for Quick Reference&lt;/p&gt;
    &lt;p&gt;Compact, handy, and loaded with essential checklists—perfect for on-the-go reference during operations and emergencies at sea.&lt;/p&gt;
    &lt;p&gt;5. Combo Packs to Save Big&lt;/p&gt;
    &lt;p&gt;Access multiple expert eBooks at discounted prices. Ideal for professionals seeking complete safety and operational knowledge across various ship departments.&lt;/p&gt;
    &lt;p&gt;6. Digital Maritime Courses – Learn at Your Own Pace&lt;/p&gt;
    &lt;p&gt;Upgrade your competence with Marine Insight Academy’s online courses. Learn from industry professionals anytime, anywhere, and become a safer, smarter seafarer.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;p&gt;Disclaimer : &lt;lb/&gt;The information on this website is for general purposes only. While efforts are made to ensure accuracy, we make no warranties of any kind regarding completeness, reliability, or suitability. Any reliance you place on such information is at your own risk. We are not liable for any loss or damage arising from the use of this website.&lt;/p&gt;
    &lt;head rend="h2"&gt;Subscribe To Our Daily Newsletter&lt;/head&gt;
    &lt;p&gt;By subscribing, you agree to our Privacy Policy and may receive occasional deal communications; you can unsubscribe anytime.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.marineinsight.com/shipping-news/worlds-largest-cargo-sailboat-completes-historic-first-atlantic-crossing/"/><published>2025-11-08T19:57:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45860638</id><title>Debugging BeagleBoard USB boot with a sniffer: fixing omap_loader on modern PCs</title><updated>2025-11-09T12:57:40.776091+00:00</updated><content>&lt;doc fingerprint="b43e4190da629599"&gt;
  &lt;main&gt;
    &lt;p&gt;This post is about the original OMAP3530 BeagleBoard from 2008. Yes, the one so old that it doesn’t even show up in the board list on BeagleBoard.org anymore. The BeagleBoard, not the BeagleBone. During my Chumby 8 kernel escapades, at one point I ran into a UART bug that affected multiple drivers, including the omap-serial driver. This led me to buy a BeagleBoard so I could verify the omap-serial bug on hardware.&lt;/p&gt;
    &lt;p&gt;After I figured out the bug with the UART driver, I realized that the OMAP3530 has support for booting from USB, so I decided to go off on a random tangent to get USB boot working. There was no problem I was trying to solve or anything like that. I just thought it would be a fun experiment (am I a masochist?). Little did I know, I would be getting myself into some tricky USB packet analysis.&lt;/p&gt;
    &lt;p&gt;I struggled to find info about this process because of how old the OMAP is today. The main utility I found was a program called omap_loader by Grant Hernandez, which is a newer rewrite of Martin Mueller’s original omap3_usbload circa 2008. Thanks to some lucky searching combined with the Internet Archive, I connected the dots between 2008 and the present. At some point before 2013, Rick Bronson provided an update to omap3_usbload (along with a patch to TI’s X-Loader bootloader) that enabled uploading additional files like a full U-Boot and Linux kernel into RAM after X-Loader, all through USB. This unlocked the ability to boot all the way to Linux from a completely blank BeagleBoard. Grant’s newer omap_loader utility also incorporates these same improvements.&lt;/p&gt;
    &lt;p&gt;All of this research was difficult. Many of the links I found pointed to sites like gitorious.org and arago-project.org, both of which no longer exist (although Arago’s Git repos are now hosted by TI). eLinux.org’s BeagleBoard wiki was totally rearranged at some point and lost its info about USB recovery, and Rick’s site no longer exists, but as usual, the Internet Archive saved the day.&lt;/p&gt;
    &lt;p&gt;At some point later on, X-Loader was replaced by U-Boot SPL, so I think that is partially why so much of this info eventually disappeared from the web. But it’s a darn shame. This USB booting functionality is really cool, and it seems like most of the documentation for it has slowly gone by the wayside! The main breadcrumbs remaining on modern Google are the newer omap_loader utility, and also some references to Nest thermostats. For example, Nest’s X-Loader had the USB patch applied (with some tweaks added).&lt;/p&gt;
    &lt;p&gt;With all that research out of the way, I was ready to try it all out. I compiled omap_loader, grabbed the pre-built binary of x-load.bin that was included with Rick’s patchset, and also used a u-boot.bin that I had compiled myself using Buildroot while performing my UART tests with a modern kernel on the BeagleBoard. Then, I tried to load it:&lt;/p&gt;
    &lt;quote&gt;$ sudo ./omap_loader -p 0xd009 -f x-load.bin -f u-boot.bin -a 0x80800000 -j 0x80800000 -v&lt;lb/&gt;OMAP Loader 1.0.0&lt;lb/&gt;File 'x-load.bin' at 0x40200000, size 26956&lt;lb/&gt;File 'u-boot.bin' at 0x80800000, size 777760&lt;lb/&gt;[+] scanning for USB device matching 0451:d009...&lt;/quote&gt;
    &lt;p&gt;The idea behind this command is it sends X-Loader (x-load.bin) as the main payload that the OMAP’s on-chip bootloader is listening for over USB. Then, X-Loader starts up. Next, omap_loader sends any additional files using X-Loader’s USB protocol. In this case, I’ve supplied one extra file: u-boot.bin, which I told it to load into RAM at 0x80800000. Finally, the &lt;code&gt;-j 0x80800000&lt;/code&gt; argument tells X-Loader to jump into U-Boot rather than hanging around doing nothing afterward.&lt;/p&gt;
    &lt;p&gt;The output of the command looked normal so far. I plugged in my BeagleBoard, which didn’t have an SD card inserted and also had its NAND flash erased, so it had no bootloader installed and thus it would attempt a USB boot.&lt;/p&gt;
    &lt;quote&gt;[+] successfully opened 0451:d009 (Texas Instruments OMAP3430)&lt;lb/&gt;[+] got ASIC ID - Num Subblocks [05], Device ID Info [01050134300757], Reserved [13020100], Ident Data [1215010000000000000000000000000000000000000000], Reserved [1415010000000000000000000000000000000000000000], CRC (4 bytes) [150901f7488f2800000000]&lt;lb/&gt;[-] fatal transfer error (BULK_OUT) for 26956 bytes (0 made it): LIBUSB_ERROR_PIPE&lt;lb/&gt;[-] failed to send file 'x-load.bin' (size 26956)&lt;lb/&gt;[-] failed to transfer the first stage file 'x-load.bin'&lt;/quote&gt;
    &lt;p&gt;Darn. The utility recognized the BeagleBoard being plugged in, but libusb errored out with a pipe error. Long story short, I messed around with a few other computers, and I found that a few of my older computers, old enough that they didn’t have USB 3.0 ports on their motherboards, actually worked perfectly fine with omap_loader. I couldn’t get it to work properly with most of my modern machines though, AMD or Intel.&lt;/p&gt;
    &lt;p&gt;I thought this would be a great application for a USB sniffer, so I decided to record some traces of success versus failure.&lt;/p&gt;
    &lt;p&gt;Here’s a link to my in-depth investigation comparing success versus failure on the GitHub issue about this problem. Yep, it turns out I wasn’t the only one running into this exact same issue. Grant himself was seeing similar problems, and had come to a similar conclusion that it seemed to be machine-dependent. Other people had mentioned that adding delays at certain points in the code seemed to help. I was intrigued, so I tried to get to the bottom of it.&lt;/p&gt;
    &lt;p&gt;Here’s what the USB boot process is supposed to look like, according to TI’s OMAP35x Technical Reference Manual:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The OMAP device enumerates as a USB device.&lt;/item&gt;
      &lt;item&gt;Within 300 ms, the host needs to read an “ASIC ID” structure from the OMAP or else it will disconnect from USB.&lt;/item&gt;
      &lt;item&gt;Then, the host sends a 4-byte command: 0xF0030002 means to continue booting through USB.&lt;/item&gt;
      &lt;item&gt;Next, the host sends the 4-byte length of bootloader data it wants to transfer.&lt;/item&gt;
      &lt;item&gt;Finally, the host sends the bootloader (X-Loader in this case), which will be loaded into internal SRAM starting at 0x40200000.&lt;/item&gt;
      &lt;item&gt;After the OMAP device receives all of the data, it runs the received bootloader by jumping to 0x40200000.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Again, this process worked perfectly fine on my older computers that don’t support USB 3.0, but on my newer computers with USB 3.0, it was hanging up. I did notice that the newer computers were trying to fit a lot more data into a single USB frame. For example, the start of my older computer’s communication with the OMAP looked like this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frame 1 &lt;list rend="ul"&gt;&lt;item&gt;Host sends boot command&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Frame 2 &lt;list rend="ul"&gt;&lt;item&gt;Host sends length&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Frame 3 &lt;list rend="ul"&gt;&lt;item&gt;Host sends first packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends second packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP says it’s not ready&lt;/item&gt;&lt;item&gt;Host pings&lt;/item&gt;&lt;item&gt;OMAP says it’s ready now&lt;/item&gt;&lt;item&gt;Host sends second packet of bootloader data again&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And then from that point on, it was just a process of sending the rest of the data like that. About 5 data packets would fit into each frame. My newer computer’s traffic looked like this instead:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Frame 1 &lt;list rend="ul"&gt;&lt;item&gt;Host sends boot command&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends length&lt;/item&gt;&lt;item&gt;OMAP says it’s not ready&lt;/item&gt;&lt;item&gt;Host pings a few times until the OMAP is ready&lt;/item&gt;&lt;item&gt;Host sends length again&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends first packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP confirms it&lt;/item&gt;&lt;item&gt;Host sends second packet of bootloader data&lt;/item&gt;&lt;item&gt;OMAP says it’s not ready&lt;/item&gt;&lt;item&gt;Host pings several times, OMAP never says it’s ready during the rest of this frame&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Frame 2 &lt;list rend="ul"&gt;&lt;item&gt;Host pings&lt;/item&gt;&lt;item&gt;OMAP responds with a STALL packet&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The newer xHCI host controller was trying its best to efficiently squeeze a lot of packets into the first frame. Even though this is a pattern that should be perfectly valid to follow when communicating with a USB device, the OMAP bootloader was clearly not happy about something, and eventually sent a STALL packet before omap_loader made much progress. Various USB packet traces on different modern computers revealed similar issues. It would either STALL after the second packet, or just NAK forever and never accept additional incoming data.&lt;/p&gt;
    &lt;p&gt;Inspired by other comments about adding delays, I tried to work around this by inserting an artificial 1 ms delay before every &lt;code&gt;libusb_bulk_transfer()&lt;/code&gt; call. This would force modern machines to slow down a little bit. As soon as I added those delays, all of my new computers had no trouble uploading X-Loader to the OMAP. So yeah, I think the OMAP just doesn’t like receiving USB data too quickly.&lt;/p&gt;
    &lt;p&gt;That wasn’t the end of this little project, though. The 1 ms delay fixed the issue with getting X-Loader to run, but the newer computers also ran into problems while trying to upload U-Boot through X-Loader!&lt;/p&gt;
    &lt;quote&gt;[-] device timed out while transfering in 512 bytes (got 0)&lt;lb/&gt;[-] device timed out while transfering in 512 bytes (got 0)&lt;lb/&gt;[-] device timed out while transfering in 512 bytes (got 0)&lt;lb/&gt;[-] failed to read command from X-Loader&lt;lb/&gt;[-] failed to transfer the additional files in to memory&lt;/quote&gt;
    &lt;p&gt;Rats. I went back to the USB sniffer for more research.&lt;/p&gt;
    &lt;p&gt;This time, it was a different problem. I found the point where the host would try to read the initial request from X-Loader: &lt;code&gt;USBf&lt;/code&gt;. On my older computer, this worked fine; it received a 13-byte string from X-Loader: &lt;code&gt;USBffile req&lt;/code&gt; followed by a null terminator. It was happy with this, and omap_usbload kept going on with the rest of the file load process and everything succeeded.&lt;/p&gt;
    &lt;p&gt;On the newer computer, some shenanigans were going on. Let’s look at the USB trace in depth:&lt;/p&gt;
    &lt;p&gt;The 335-byte packet contains 332 actual bytes of data (the packet ID and CRC account for the other 3 bytes), and is the final chunk of X-Loader. It was successfully received and confirmed by the OMAP with an ACK. At that point, we can assume that the OMAP has begun jumping into X-Loader to start it up.&lt;/p&gt;
    &lt;p&gt;A millisecond later (due to the delay I added), we start trying to read from X-Loader. It’s clearly too soon, though; I don’t think X-Loader has finished starting up yet. There’s nothing ready to read. So these IN/NAK packets continue on for about 5 more milliseconds, which is totally normal. But then, something finally happens: the OMAP stops responding to our IN packets. My computer’s USB host controller tries three times (see the three IN packets in a row below?) and then it gives up. I’m guessing this is around the same time that X-Loader is doing its own hardware initialization, so maybe the OMAP’s USB controller is temporarily disabled.&lt;/p&gt;
    &lt;p&gt;This all makes sense so far. We tried to read too quickly before X-Loader finished starting up, so when it did finally load, there was a brief moment where it would not respond to IN packets. The host controller didn’t like this and stopped trying, so all we saw from that point on was SOF packets because we weren’t attempting any more USB reads. Some of my other computers gave up after 15 unanswered IN packets instead of 3. I’m not sure if that’s a difference in the host controller or what, but it’s the same root problem.&lt;/p&gt;
    &lt;p&gt;You may be wondering: why didn’t the older computers run into this same issue? They were also trying to talk with X-Loader too early, so why wouldn’t they run into this same roadblock? The answer is that their older host controllers are more tolerant of the missing NAKs. I recorded a similar trace with one of my older computers that works fine without any patches to omap_loader. It also immediately began sending IN packets trying to read from X-Loader way too soon. Just like the problematic computers, it experienced a brief period where the OMAP stopped responding to INs with NAKs. The difference is that it didn’t abandon hope so quickly. There were 33 unanswered IN packets. After that, the OMAP continued responding with NAKs again and everything was fine from that point on. 17 ms after we had originally finished sending out X-Loader, the OMAP finally responded with an actual data packet. So that’s the total time it took for X-Loader to launch.&lt;/p&gt;
    &lt;p&gt;Back to the newer computers that weren’t playing nicely. I was still confused. Even though this is a problem with newer host controllers, omap_loader has a retry mechanism! If it fails to read X-Loader’s initial data, it will try again 2 seconds later. You’d think it would succeed at that point. Let’s see what happens:&lt;/p&gt;
    &lt;p&gt;Ah, interesting. The retry is actually 3 seconds later. I’m guessing the first failed read attempt had a 1-second timeout, so then with a 2-second retry timer, that adds up to 3 seconds total.&lt;/p&gt;
    &lt;p&gt;Anyway, something funky happens here. The USB host finally reads the 13-byte string from X-Loader as a DATA1 packet (again, it shows up as 16 bytes because of the packet ID and CRC). The host then acknowledges reception with an ACK, but for some bizarre reason, it immediately continues attempting to read more data! I won’t show the whole trace, but the host keeps polling with IN packets for a whole second. And of course, they’re all NAKed. X-Loader knows it successfully sent data to us, so it has shifted over to waiting for the host to send an OUT packet instead. It’s like the host controller gets confused and expects X-Loader to send more data. The kernel never reports those 13 bytes back to libusb, even after the 1-second transfer timeout expires.&lt;/p&gt;
    &lt;p&gt;I don’t consider myself to be a USB expert, so maybe I’m misunderstanding something. This behavior just seems wrong, though. When my computer finally reads 13 bytes (proven by the sniffer trace shown above), why isn’t this data reported back to libusb? I would have expected the reception of a short DATA0/1 packet to cause the host controller to stop reading and return the data back immediately. Is this some kind of strange bug in the Linux kernel or the host controller hardware or something? I don’t know for sure. I find this behavior to be very odd, and I can’t explain it. My off-the-cuff guess is that the initial failure to respond to the three IN packets results in something getting out of sync in the host controller, but I really don’t know for sure. In my opinion, the retry should have worked, but clearly, something got confused. Not sure what. I don’t think it’s libusb’s fault, though.&lt;/p&gt;
    &lt;p&gt;I hate adding arbitrary delays in order to fix things, but a 20-millisecond delay between uploading X-Loader and attempting to read from it fixes this final issue. It ensures that the OMAP has been given ample time to launch X-Loader before we try reading from it, preventing the host controller from encountering the weird situation with unanswered IN packets.&lt;/p&gt;
    &lt;p&gt;After all of this tinkering and patching that I did to get things to play nicely on newer machines, here is a successful run of omap_loader:&lt;/p&gt;
    &lt;quote&gt;[+] successfully opened 0451:d009 (Texas Instruments OMAP3430)&lt;lb/&gt;[+] got ASIC ID - Num Subblocks [05], Device ID Info [01050134300757], Reserved [13020100], Ident Data [1215010000000000000000000000000000000000000000], Reserved [1415010000000000000000000000000000000000000000], CRC (4 bytes) [150901f7488f2800000000]&lt;lb/&gt;[+] uploading 'u-boot.bin' (size 777760) to 0x80800000&lt;lb/&gt;[+] jumping to address 0x80800000&lt;lb/&gt;[+] successfully transfered 2 files&lt;/quote&gt;
    &lt;p&gt;Meanwhile, the following output pops up on the BeagleBoard’s UART:&lt;/p&gt;
    &lt;quote&gt;Texas Instruments X-Loader 1.5.1 (Nov 15 2011 - 09:36:31)&lt;lb/&gt;Beagle Rev C4&lt;lb/&gt;Trying load from USB&lt;lb/&gt;USBLOAD_CMD_FILE total = 12 addr = 0x73425355 val = 0xbde20 val = 0x80800000&lt;lb/&gt;got file addr = 0x808bde20&lt;lb/&gt;USBLOAD_CMD_JUMP total = 8 addr = 0x6a425355 val = 0x80800000&lt;lb/&gt;U-Boot 2023.10 (May 25 2024 - 22:05:27 -0700)&lt;lb/&gt;OMAP3530-GP ES3.1, CPU-OPP2, L3-165MHz, Max CPU Clock 720 MHz&lt;lb/&gt;Model: TI OMAP3 BeagleBoard&lt;lb/&gt;OMAP3 Beagle board + LPDDR/NAND&lt;lb/&gt;I2C: ready&lt;lb/&gt;DRAM: 256 MiB&lt;lb/&gt;Core: 44 devices, 18 uclasses, devicetree: separate&lt;lb/&gt;NAND: 256 MiB&lt;lb/&gt;MMC: OMAP SD/MMC: 0&lt;lb/&gt;Loading Environment from NAND... *** Warning - bad CRC, using default environment&lt;lb/&gt;Beagle Rev C4&lt;lb/&gt;Timed out in wait_for_event: status=0000&lt;lb/&gt;Check if pads/pull-ups of bus are properly configured&lt;lb/&gt;No EEPROM on expansion board&lt;lb/&gt;OMAP die ID: 79b8000400000000040398da1401c009&lt;lb/&gt;Net: No ethernet found.&lt;lb/&gt;Hit any key to stop autoboot: 2&lt;/quote&gt;
    &lt;p&gt;I believe the “Timed out in wait_for_event” error is harmless. Anyway, success! It loads U-Boot! You can imagine that I could have easily transmitted a Linux kernel and initramfs as well, and fully booted this thing over USB. Once U-Boot is running, I can do whatever I want.&lt;/p&gt;
    &lt;p&gt;With these simple delay tweaks, omap_loader works great on all modern computers I’ve thrown at it, including Raspberry Pis. The only “gotcha” I’ve encountered is that some slower computers (my i3-7100U laptop and a Raspberry Pi Zero) don’t forward the USB hotplug event through udev quickly enough before the BeagleBoard decides it’s not being asked to boot over USB. omap_loader never gets past scanning for a device, even though the &lt;code&gt;dmesg&lt;/code&gt; log clearly shows that it was detected:&lt;/p&gt;
    &lt;quote&gt;[4076310.258842] usb 11-5: new high-speed USB device number 65 using xhci_hcd&lt;lb/&gt;[4076310.407944] usb 11-5: unable to get BOS descriptor or descriptor too short&lt;lb/&gt;[4076310.410041] usb 11-5: New USB device found, idVendor=0451, idProduct=d009, bcdDevice= 0.00&lt;lb/&gt;[4076310.410046] usb 11-5: New USB device strings: Mfr=33, Product=37, SerialNumber=0&lt;lb/&gt;[4076310.410051] usb 11-5: Product: OMAP3430&lt;lb/&gt;[4076310.410054] usb 11-5: Manufacturer: Texas Instruments&lt;lb/&gt;[4076310.710703] usb 11-5: USB disconnect, device number 65&lt;/quote&gt;
    &lt;p&gt;As you can see, it’s a very short timeframe; just like TI’s manual says, it only stays connected for about 300 ms if it doesn’t hear from the host. I guess that’s not enough time for udev on some computers. The only solution I found for this issue on my slower machines was to compile a custom version of libusb with udev disabled, which forces it to directly use netlink for hotplug detection instead.&lt;/p&gt;
    &lt;p&gt;My patch also limits libusb transfers to 512 bytes at a time. I don’t think this change is critical, though. It fixed an issue I ran into where my bus was really loaded and libusb reported a memory error. I don’t think it actually helps anything in most cases as long as people aren’t performing crazy big USB transfers at the same time.&lt;/p&gt;
    &lt;p&gt;In summary:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Trying to write USB data to the OMAP’s on-chip bootloader too quickly seems to hit some edge cases that it doesn’t handle correctly. A 1 ms delay fixes this.&lt;/item&gt;
      &lt;item&gt;Trying to read from X-Loader before it’s ready to go irritates newer USB host controllers when they send out several IN packets without receiving any response (not even a NAK). A 20 ms delay fixes this. &lt;list rend="ul"&gt;&lt;item&gt;Even retries afterward fail; the host controller gets out of sync due to the unanswered IN packets or something like that.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;On some slower computers, udev doesn’t give you enough time to respond to the OMAP’s 300 ms timeout, so libusb never detects the hotplug. This can be solved with a custom libusb that uses netlink instead of udev.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I opened up a PR to submit these fixes (except for the udev thing) upstream to omap_loader in 2024. Why am I writing about this now? Well, remember when I mentioned Nest earlier? Google ended support for older Nest thermostats last month, which renewed some interest in merging my reliability improvements so that people can flash custom firmware to their Nest thermostats. Those old Nest devices also use OMAP processors.&lt;/p&gt;
    &lt;p&gt;What it boils down to is: all this tinkering I did last year with pointlessly booting old BeagleBoards over USB accidentally ended up being useful. It helped out some Nest thermostat revival projects that have been popping up in the last month. So I thought now might be a fun time to talk about my tiny involvement with that. Yay! It’s always fun when a random side project unexpectedly helps other people.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.downtowndougbrown.com/2025/11/debugging-beagleboard-usb-boot-with-a-sniffer-fixing-omap_loader-on-modern-pcs/"/><published>2025-11-08T22:30:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45860843</id><title>Ironclad – formally verified, real-time capable, Unix-like OS kernel</title><updated>2025-11-09T12:57:40.572535+00:00</updated><content>&lt;doc fingerprint="6f56f93a45a93f90"&gt;
  &lt;main&gt;
    &lt;p&gt;Ironclad is a formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software.&lt;/p&gt;
    &lt;p&gt;Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling.&lt;/p&gt;
    &lt;p&gt;Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source.&lt;/p&gt;
    &lt;p&gt;SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of huge swathes of Ironclad, like cryptography, MAC, and user-facing facilities.&lt;/p&gt;
    &lt;p&gt;Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.&lt;/p&gt;
    &lt;p&gt;Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more.&lt;/p&gt;
    &lt;p&gt;This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page.&lt;/p&gt;
    &lt;p&gt;Additionally, we would like to thank the following organizations:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ironclad-os.org/"/><published>2025-11-08T23:03:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45861984</id><title>How Airbus Took Off</title><updated>2025-11-09T12:57:40.431498+00:00</updated><content>&lt;doc fingerprint="f5e48050ae83878f"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Airbus is an example of successful industrial policy and the rare European company that is better than its American rival. Could its success be copied elsewhere?&lt;/head&gt;
    &lt;p&gt;Would you rather fly in an Airbus or a Boeing? It seems like an easy question.&lt;/p&gt;
    &lt;p&gt;As Alaska Airlines Flight 1282 flight climbed to 16,000 feet on a January evening in 2024, passengers were stunned when a hole was blasted in the side of the plane. They were hit by howling winds as tray tables were ripped from the backs of seats. Were it not for their seatbelts, they would likely have been sucked out of the plane. It later transpired that the plug which sealed the exit door was missing four critical bolts that held it in place.&lt;/p&gt;
    &lt;p&gt;Subscribe for $100 to receive six beautiful issues per year.&lt;/p&gt;
    &lt;p&gt;The Alaska Airlines incident fortunately didn’t result in any fatalities. Not everyone who has flown on a Boeing 737 MAX in the last few years has been so lucky.&lt;/p&gt;
    &lt;p&gt;2018 and 2019 saw two 737 crashes that killed 346 people after the plane’s Maneuvering Characteristics Augmentation System, a feature that pushes the plane’s nose down to prevent stalling, triggered repeatedly due to a faulty sensor. It later transpired that Boeing had not adequately disclosed how the system worked in training manuals.&lt;/p&gt;
    &lt;p&gt;While Boeing wrestles with lawsuits and regulatory investigations, its rival Airbus has stayed out of the headlines – a happier place for the manufacturer of commercial airliners.&lt;/p&gt;
    &lt;p&gt;Europe is a graveyard of failed national champions. They span from the glamorous Concorde to obscure ventures like pan-European computer consortium Unidata or notorious Franco-German search engine Quaero.&lt;/p&gt;
    &lt;p&gt;Airbus is the rare success story. European governments pooled resources and subsidized their champion aggressively to face down a titan of American capitalism in a strategically vital sector. Why did Airbus succeed when so many similar initiatives crashed and burned?&lt;/p&gt;
    &lt;p&gt;Airbus prevailed because it was the least European version of a European industrial strategy project ever. It put its customer first, was uninterested in being seen as European, had leadership willing to risk political blowback in the pursuit of a good product, and operated in a unique industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;An industry on the brink&lt;/head&gt;
    &lt;p&gt;In the early days of commercial aviation, US aerospace companies dominated the market for passenger jets.&lt;/p&gt;
    &lt;p&gt;The Buy America Act of 1933 forced the US government to buy from American producers where possible. Military orders supercharged the industry and brought significant knowledge spillovers.&lt;/p&gt;
    &lt;p&gt;The Boeing B-47 bomber, introduced in the late 1940s, pioneered the use of 35-degree swept wings, which point backwards at an angle of 35 degrees and reduce drag at high speeds. This design went on to inspire nearly every commercial airliner around the world.&lt;/p&gt;
    &lt;p&gt;Meanwhile the Boeing 707, the company’s first ever airliner, shared a fuselage with the KC-135 Stratotanker, a military refueling aircraft.&lt;/p&gt;
    &lt;p&gt;In the face of the US, European aerospace companies cut a sorry figure. The British Aircraft Corporation, Sud Aviation in France, and Messerschmitt-Bölkow-Blohm (MBB) in West Germany were all left to compete for orders in a fragmented continental market, with little research or marketing heft. Meanwhile, European airliners who bought American planes could apply for discounted loans from EXIM, the America’s credit export agency.&lt;/p&gt;
    &lt;p&gt;Between 1960 and 1967, British and French manufacturers saw a 50 percent decline in aircraft deliveries. In 1966, the UK government had even contemplated forcibly merging and nationalizing much of the country’s industry.&lt;/p&gt;
    &lt;p&gt;European governments had poured money into their national champions in the belief that the maintenance of a civilian aerospace industry was critical for sovereignty, but it was unclear if these companies would survive the decade.&lt;/p&gt;
    &lt;p&gt;Amid this gloomy backdrop, European governments concluded that their industry’s future depended on cooperation.&lt;/p&gt;
    &lt;p&gt;The UK and France agreed to pool the resources behind Concorde in 1962 to fight what Charles De Gaulle called ‘the American colonization of the skies’, but the Germans declined to participate due to their (well-founded) skepticism about the project’s economics. This didn’t stop the Germans teaming up with the Dutch on the long-forgotten VFW-Fokker 614. This short-haul jet struggled to find customers at a time when airlines preferred to use cheap prop aircraft for regional city-hopping, dooming the project to collapse once state aid was withdrawn in 1977.&lt;/p&gt;
    &lt;p&gt;In 1965, the French, British, and German governments launched a working group to evaluate the potential of a wide-body commercial aircraft, which would later become the A300. Two years later, the three governments agreed to bear the entire costs of the development of the ‘European Airbus’. In 1970, the coalition was formalized with the creation of Airbus Industrie. The consortium quickly expanded to include Spain and the Netherlands.&lt;/p&gt;
    &lt;head rend="h2"&gt;The making of a world leader&lt;/head&gt;
    &lt;p&gt;So how did this unlikely band of brothers go on to build a global leader, rather than another Econ101 case study about the perils of industrial policy?&lt;/p&gt;
    &lt;p&gt;The single biggest factor was a focus on the customer.&lt;/p&gt;
    &lt;p&gt;Unlike many future industrial strategy projects, which would focus on creating European-owned capabilities for their own sake, the Airbus team were seized by the need to build a jet that airliners would want to buy. They didn’t have much choice: if they failed, there was a reasonable chance the consortium’s domestic aerospace suppliers would collapse.&lt;/p&gt;
    &lt;p&gt;They were helped enormously in this by their setup. While Airbus didn’t become a unified corporate entity until 2001, the partnership had a strong central leadership from the beginning. Unlike other industrial consortia, which tended to be leaderless venues for intra-European turf wars, Airbus united marketing, procurement, and design.&lt;/p&gt;
    &lt;p&gt;Roger Béteille, who led the A300 program, probably bears more responsibility for Airbus’s early success than anyone else. Béteille wasn’t interested in building an inferior European Boeing copy. Instead, he invested significant time in getting to know his potential customers and what they needed. This led to Airbus quickly tossing the original design for a 300-seat A300, in favor of a 225-250 seater, when it became clear that Air France and Lufthansa wanted a smaller product.&lt;/p&gt;
    &lt;p&gt;The revised A300B would prove much cheaper to develop, in part because it allowed the consortium to dispense with the expensive Rolls Royce engine in favour of a cheaper American alternative. In response, the UK exited the project, only to later return with a lower ownership stake.&lt;/p&gt;
    &lt;p&gt;This willingness to risk political blowback and avoid petty chauvinism in equipment choice was rare in industrial strategy.&lt;/p&gt;
    &lt;p&gt;Béteille went one step further. He designated English the official language of the project, instead of the usual mixture of languages that characterised European projects, and forbade the use of metric measurements to make it easier to sell into the US market.&lt;/p&gt;
    &lt;p&gt;Along with Felix Kracht, Airbus’s first production director, Béteille set a division of labour between the different countries that has persisted, with minor adjustments. French firms handled the cockpit, control systems, and lower-center fuselage; Hawker Siddeley (the inventor of the Harrier jump jet) in the UK designed and built the wings; German companies produced various fuselage sections; the Netherlands managed moving wing components; and Spain was responsible for the horizontal tailplane.&lt;/p&gt;
    &lt;p&gt;Based on Béteille’s market research, the A300B was optimised for fuel efficiency. The team stripped out unnecessary weight by using composite materials and raised the cabin floor to add cargo space. Hawker Siddeley’s wings, which would go on to influence industry standards, were designed with a curved shape on top to reduce air resistance, allowing greater lift and fuel efficiency.&lt;/p&gt;
    &lt;p&gt;At a time when almost every commercial jet had three or four engines, Airbus opted for a twin-engine design. The plane could theoretically fly on one and the company concluded that only a single extra engine was needed to provide redundancy for safety. The much cheaper twin-engine design is now the industry standard, even for ultra long-haul flights.&lt;/p&gt;
    &lt;p&gt;Despite the technical ingenuity behind the A300B, early business was slow. By the time the aircraft entered service in 1974, it had struggled to attract commercial interest beyond state-owned flag carriers like Air France, which had placed the first A300B order in 1971 for six jets. Even these airlines continued to operate Boeing-dominated fleets.&lt;/p&gt;
    &lt;p&gt;One problem was unfortunate timing: the oil shock of 1973 had caused operating costs to spiral for airliners, so there was little appetite for experimentation in the air.&lt;/p&gt;
    &lt;p&gt;There was also residual suspicion of European industry among US airliners. Sud Aviation’s Caravelle had been used by some American airliners, but the company was notorious for its sloppy after sales maintenance and service. There had also been an ugly dispute over landing rights for Concorde, with the US heavily restricting the aircraft’s operation out of noise concerns. The French suspected more sinister commercial motivations were at work. Jacques Chirac, then French Prime Minister, raised the temperature, declaring that: ‘The Airbus consortium will not be daunted by the Americans who killed off the Concorde. … We will fight any trade war blow-by-blow as the future of the aeronautical industry and their employees is at stake’.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, Airbus did everything it could to deemphasize its European heritage as it toured the US. It refused to involve the French or German embassies in its sales efforts, much to their irritation. Airbus representatives drove home how a third of the plane’s value derived from US-made components, more than any single European partner nation’s contribution. They also mastered the world of DC lobbying, successfully outmaneuvering Boeing and Lockheed’s attempts to use anti-trust regulations to shut the European entrant out of the US market.&lt;/p&gt;
    &lt;p&gt;Sustained by early European market commitments and early sales in Asia, Airbus was eventually able to clinch its first US order in 1977. Eastern Airlines (EAL), which had been impressed by the A300B’s fuel economy and low noise levels, agreed to the trial lease of four aircraft and three spare engines for … one dollar. These terms would have been unconscionable for a normal private company, but they were transformative for state-backed Airbus’s fortunes. Frank Borman, conservative Republican, former NASA astronaut, and EAL’s CEO emerged as a public champion of the A300B as an ‘American aircraft’.&lt;/p&gt;
    &lt;head rend="h2"&gt;The A320&lt;/head&gt;
    &lt;p&gt;Béteille and Kracht weren’t content with building one aircraft. From the beginning, Airbus had targeted a 30 percent global market share. This meant building more than wide-body aircraft like the A300B.&lt;/p&gt;
    &lt;p&gt;The A320, which entered operation in 1988 was a narrow-bodied aircraft that could carry 150-180 passengers. It was optimized to fly short- and medium-haul routes economically, and a masterclass in engineering and timing.&lt;/p&gt;
    &lt;p&gt;By the 1980s, airliners were looking to replace their aging narrow-bodied fleets, with the Boeing 272 and McDonnell Douglas DC-9 having been in operation for more than two decades.&lt;/p&gt;
    &lt;p&gt;The A320 was the first commercial aircraft to implement full digital fly-by-wire controls. Before the A320, the pilot’s controls pulled physical cables attached to the flaps, rudder, and other control surfaces on the plane. Fly-by-wire meant that controls sent electric signals to the plane’s computers, which then commanded motors to move the control surfaces. This made life easier for the pilots by reducing the need for constant manual adjustment and stripped out heavy components that needed maintenance.&lt;/p&gt;
    &lt;p&gt;The A320 was also the first commercial aircraft to introduce envelope protection, a system that automatically prevents dangerous actions, such as tilting too steeply, flying too slowly, or making maneuvers that could overstress the aircraft structure.&lt;/p&gt;
    &lt;p&gt;Again, the A320 wasn’t an overnight success, with new technology and existing relations with Boeing slowing uptake. Airbus again relied on British and French orders to gain market credibility. But by the early 1990s, its superior technology combined with Airbus’s willingness to flex the design, with the A319 (smaller) and A321 (larger) allowing airliners to operate mixed fleets with common cockpits, began to win fans. The A320 is now the most popular airliner family in history and remains in widespread use today.&lt;/p&gt;
    &lt;p&gt;The success of the A320 led Airbus to profitability in the mid-1990s. By 2019, Airbus had displaced Boeing as the largest aerospace company by revenue.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Airbus’s success is so hard to repeat&lt;/head&gt;
    &lt;p&gt;If Airbus proves industrial strategy can work, why haven’t other European ventures fared better?&lt;/p&gt;
    &lt;p&gt;Good industrial strategy requires favorable market conditions, consistent strategy in the face of political headwinds, and the courage to call it a day if failure seems likely. Getting one of these right is tough, and all three is exceptionally rare.&lt;/p&gt;
    &lt;p&gt;Concorde was a marvel of engineering, but even without US obstructionism, it had little prospect of commercial viability. In today’s money, it cost £16 billion to develop, roughly ten times the cost of the Boeing 727, making it the most expensive plane of its age by some margin. Its limited passenger capacity, fuel inefficiency, and expensive maintenance meant that a ticket for a round trip cost in excess of £10,000 adjusted for inflation. The ultra-premium air travel market wasn’t big enough in the 1980s or 1990s to bear the costs of 1960s technology, leading to Concorde’s retirement in 2003.&lt;/p&gt;
    &lt;p&gt;Other European projects have lacked the centralized control or clear rationale that characterized Airbus.&lt;/p&gt;
    &lt;p&gt;We see this in Unidata, a 1973 consortium that brought together CII (France), Philips (the Netherlands), and Siemens (Germany) to produce a European mainframe line to rival IBM. With no clear leadership, rival members of the consortium pushed their own hardware and software approaches. Engineering efforts were duplicated. The project collapsed within two years amid recriminations.&lt;/p&gt;
    &lt;p&gt;Meanwhile, it was unclear why the 2005 Franco-German search engine project Quaero ever needed to exist. Widely seen as a vanity project at the time, the attempt to build a search engine by committee similarly splintered along national lines. It was also a victim of mission creep, evolving from a direct Google competitor to a multimedia search platform that would be powered by image and voice analysis. The project limped on until its mercy killing in 2013.&lt;/p&gt;
    &lt;p&gt;It’s also easier to build a global leadership position when your main rival wages a prolonged campaign of self-sabotage. By the new millennium, the competition had been reduced to a simple showdown between Airbus and Boeing. Lockheed had decided to bail on commercial aviation in the 1970s after losing billions of dollars on the L-1011, while Boeing acquired McDonnell Douglas in a $13 billion deal in 1997.&lt;/p&gt;
    &lt;p&gt;While Airbus has retained a strong engineering culture at the helm, this disappeared from Boeing. Harry Stonecipher, Boeing’s CEO in the early 2000s, notoriously claimed that: ‘When people say I changed the culture of Boeing, that was the intent, so that it is run like a business rather than a great engineering firm’.&lt;/p&gt;
    &lt;p&gt;Stonecipher’s successor, James McNerney, took this even further: ‘Every 25 years a big moonshot… and then produce a 707 or a 787 – that’s the wrong way to pursue this business. The more-for-less world will not let you pursue moonshots’.&lt;/p&gt;
    &lt;p&gt;The McDonnell Douglas acquisition is often marked as a turning point for Boeing. Despite being the acquiring firm, Boeing absorbed much of their target’s management philosophy. This disconnect was embodied in the company’s decision to move its headquarters from Seattle (where its main production facility was located) to Chicago, for the sake of just $63 million in tax credits. Fatal crashes in 2018 and 2019 have since caused regulatory investigations and multi-billion dollar compensation claims to pile up, as well as allegations that the company has put shareholders and dividends before safety.&lt;/p&gt;
    &lt;head rend="h2"&gt;A strange industry&lt;/head&gt;
    &lt;p&gt;Does the Airbus story make a good case for a disciplined, well-executed industrial strategy?&lt;/p&gt;
    &lt;p&gt;To answer this question, we need to take a step back from Airbus and Boeing and think about their customers.&lt;/p&gt;
    &lt;p&gt;Airlines have one of the worst business models of any industry. They have eye-watering capital expenditures (a large jet costs in excess of $200 million). The product offering (flights) is relatively undifferentiated, while many of their customers are price-conscious and disloyal. Safety regulations, along with route and landing slot regulations mean there’s little space to drive painless efficiencies. This leaves airlines with two main routes to success: worsening their service through cost-cutting and engaging in kamikaze price wars.&lt;/p&gt;
    &lt;p&gt;This is why airlines frequently go bankrupt, with US Airways, United Airlines, Northwest Airlines, Delta Air Lines and American Airlines among the dozens to almost collapse in the 2000s. Only three airlines without state ties (Southwest, Ryanair, and Copa) have consistently maintained profitability while avoiding bankruptcy or major restructuring.&lt;/p&gt;
    &lt;p&gt;In his 2007 letter to Berkshire Hathaway shareholders, Warren Buffett described the airline industry as ‘the worst sort of business’, and noted that, ‘if a farsighted capitalist had been present at Kitty Hawk, he would have done his successors a huge favor by shooting Orville down’.&lt;/p&gt;
    &lt;p&gt;Airbus, as a supplier to these businesses, has not been immune to these pressures. In the early 2000s, airliners were enthused about the ‘hub and spoke’ model. Passengers would fly on large aircraft between major hubs, then transfer to smaller aircraft for their final destinations. With a maximum capacity of over 800, the double-decker Airbus A380 would help allow airliners to consolidate their flights between busy international hubs. By the time it entered commercial operation in 2007, fashions had reversed and consumers were willing to pay a premium to fly direct. Airbus never came close to recouping its $25 billion development costs.&lt;/p&gt;
    &lt;p&gt;Against this backdrop, companies like Airbus and Boeing face a constant downward price pressure, operating on single digit margins in good years. The merry-go-round of buyers as airliners fall in and out of bankruptcy makes them fickle customers. With this in mind, Boeing’s desire to slash costs seems like a much more rational response, even if its execution was flawed.&lt;/p&gt;
    &lt;p&gt;It may be nearly impossible to operate the multi-billion dollar, multi-decade product development cycle this industry requires without some form of government backstop, whether it is a direct subsidy (Airbus) or reliable military orders (Boeing).&lt;/p&gt;
    &lt;p&gt;It is a business that is well-suited to subsidy for other reasons too. Governments are generally better at supporting companies in established markets where innovation takes place slowly and incrementally. This is likely why state-backed efforts have found it easier to be competitive against aerospace companies than Silicon Valley giants working at breakneck pace to keep pace with changing consumer tastes.&lt;/p&gt;
    &lt;p&gt;We can learn from Airbus’s engineering ingenuity and relentless customer focus. But its success in such an idiosyncratic sector probably isn’t as template for successful industrial policy in many of the other sectors that some people would like it to be.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://worksinprogress.co/issue/how-airbus-took-off/"/><published>2025-11-09T01:19:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862071</id><title>IRIX Introduction</title><updated>2025-11-09T12:57:39.737538+00:00</updated><content>&lt;doc fingerprint="bd3c131148cca9cc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;IRIX Introduction&lt;/head&gt;
    &lt;head rend="h2"&gt;Brief History&lt;/head&gt;
    &lt;p&gt;The first operating system developed for SGI systems ran on the IRIS line of terminals and workstations based on Motorola CPUs (see GL2 history). When the MIPS based IRIS 4D systems were introduced the 4D1 operating system accompanied these computers.&lt;/p&gt;
    &lt;p&gt;The earliest common version is 4D1-3.0 (1988). IRIX 3.x was based on UNIX System V Release 3 with 4.3BSD enhancements, and incorporated the 4Sight windowing system, based on NeWS and IRIS GL.&lt;/p&gt;
    &lt;p&gt;The next major version (4D1-4.0) was introduced in 1991. SGI replaced 4Sight with the X Window System (X11R4), using Xsgi and the 4Dwm window manager providing a similar look and feel to 4Sight.&lt;/p&gt;
    &lt;p&gt;When the next version was introduced, the name IRIX was more widely used. IRIX 5.0, released in 1993, incorporated certain features of UNIX System V Release 4, including ELF-format executables. Later on in the IRIX 5 lifecycle the XFS journaling file system was introduced.&lt;/p&gt;
    &lt;p&gt;Beginning with IRIX 6.0, released in 1994 during the IRIX 5 era, full 64-bit support was added. After a few platform specific releases with IRIX 6.5 the last "major" all platform release was introduced.&lt;/p&gt;
    &lt;p&gt;The last IRIX release is IRIX 6.5.30, introduced in August 2006. The IRIX product line was discontinued after this version, according to the press release dated September, 6th 2006 support for IRIX will continue at least until December 2013.&lt;/p&gt;
    &lt;head rend="h2"&gt;Main Versions&lt;/head&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;To decide which IRIX version is suitable for a system it is important to know specific information about the computer itself:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Which system family is it (O2, Indy, Origin 2000, ...)?&lt;/item&gt;
      &lt;item&gt;Which processor is installed?&lt;/item&gt;
      &lt;item&gt;Which graphics hardware is in it (if any)?&lt;/item&gt;
      &lt;item&gt;Are there options that require specific drivers?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Another thing to note is that there are platform specific releases, that were made when some new hardware was introduced. These usually don't support all hardware that was available at the time.&lt;/p&gt;
    &lt;p&gt;This chapter will go on with an introduction to most important all platform IRIX releases. It will conclude with a paragraph containing some considerations and recommendations for the choice of ann appropriate IRIX version.&lt;/p&gt;
    &lt;head rend="h3"&gt;Major Versions&lt;/head&gt;
    &lt;p&gt;Of all IRIX releases the following are the most important:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;IRIX 5.3&lt;/item&gt;
      &lt;item rend="dd-1"&gt;IRIX 5.3 was the last IRIX version to include support for systems with R3000 CPU. So this is the most recent operating system that can be installed on 4D era systems (Personal Iris, PowerSeries and so on).&lt;/item&gt;
      &lt;item rend="dt-2"&gt;IRIX 6.2&lt;/item&gt;
      &lt;item rend="dd-2"&gt;Of the 6.x releases IRIX 6.2 was the first release that did support all current hardware of it's time. Although all of this hardware (except the Crimson) is still supported in the current 6.5 releases IRIX 6.2 can still be a reasonable choice for lowend configurations of Indigo, Indigo 2 or Indy (pre 1996).&lt;/item&gt;
      &lt;item rend="dt-3"&gt;IRIX 6.5.22&lt;/item&gt;
      &lt;item rend="dd-3"&gt;This version is the last to support many of the popular Silicon Graphics classics like the Indigo 2 or Indy which are equipped with R4x00 microprocessors..&lt;/item&gt;
      &lt;item rend="dt-4"&gt;IRIX 6.5.30&lt;/item&gt;
      &lt;item rend="dd-4"&gt;IRIX 6.5.30 is the final IRIX release and is suitable for any of the last Silicon Graphics systems that were equipped with MIPS microprocessors (O2, Octane, Fuel, etc.).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Operating System Considerations and Recommendations&lt;/head&gt;
    &lt;p&gt;The following list starts with current systems and goes back to the early IRIS 4D days (for hardware information go to the systems page. In a similar fashion for all the listed systems the most recent operating system will be named, followed by exceptions that make it neccessary to choose an older version.&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;O2, O2+, Octane, Octane 2,Fuel&lt;/item&gt;
      &lt;item rend="dd-1"&gt;All of these systems can run a current IRIX 6.5 release.&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Origin 200, Origin 2000, Onyx 2, Origin 300, Onyx 300,Origin 3000, Onyx 3000&lt;/item&gt;
      &lt;item rend="dd-2"&gt;All of these systems can run a current IRIX 6.5 release.&lt;/item&gt;
      &lt;item rend="dt-3"&gt;Indigo 2, Challenge M&lt;/item&gt;
      &lt;item rend="dd-3"&gt;All Indigo 2 / Challenge M can run IRIX 6.5 up to 6.5.22. &lt;list rend="ul"&gt;&lt;item&gt;RAM &amp;lt; 64MB: IRIX 6.2&lt;/item&gt;&lt;item&gt;CPU R4000/100: IRIX 6.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-4"&gt;Indy, Challenge S&lt;/item&gt;
      &lt;item rend="dd-4"&gt;All Indy / Challenge S can run IRIX 6.5 up to 6.5.22. &lt;list rend="ul"&gt;&lt;item&gt;RAM &amp;lt; 64MB: IRIX 6.2&lt;/item&gt;&lt;item&gt;CPU R4000PC, R4600PC: IRIX 6.2&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-5"&gt;Challenge, Onyx&lt;/item&gt;
      &lt;item rend="dd-5"&gt;All of these systems can run IRIX 6.5 up to 6.5.22.&lt;/item&gt;
      &lt;item rend="dt-6"&gt;Indigo&lt;/item&gt;
      &lt;item rend="dd-6"&gt;Indigo with R4x00 CPUs can run IRIX 6.5 up to 6.5.22.&lt;lb/&gt;Indigo with R3x00 CPUs are limited to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-7"&gt;Crimson&lt;/item&gt;
      &lt;item rend="dd-7"&gt;All Crimson systems can run up to IRIX 6.2, with the following exception: &lt;list rend="ul"&gt;&lt;item&gt;GTX graphics: IRIX 5.3 (last version to support GTX)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item rend="dt-8"&gt;PowerSeries&lt;/item&gt;
      &lt;item rend="dd-8"&gt;All of these systems can run up to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-9"&gt;Personal Iris&lt;/item&gt;
      &lt;item rend="dd-9"&gt;All of these systems can run up to IRIX 5.3.&lt;/item&gt;
      &lt;item rend="dt-10"&gt;Professional Iris&lt;/item&gt;
      &lt;item rend="dd-10"&gt;All of these systems can run up to IRIX 5.3, with the following exception: &lt;list rend="ul"&gt;&lt;item&gt;G graphics: IRIX 4.0.5 (last version to support G graphics)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Pictures&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX Media / Media Kits&lt;/head&gt;
    &lt;head rend="h3"&gt;Developer Toolbox&lt;/head&gt;
    &lt;head rend="h3"&gt;Support Advantage&lt;/head&gt;
    &lt;head rend="h3"&gt;Indyzone&lt;/head&gt;
    &lt;head rend="h3"&gt;Other&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 3.3 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 4.0.1 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 5.3 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;IRIX 6.5 Screenshots&lt;/head&gt;
    &lt;head rend="h3"&gt;Cyclone Software&lt;/head&gt;
    &lt;head rend="h2"&gt;Links&lt;/head&gt;
    &lt;head rend="h3"&gt;Technical Reports and White Papers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IRIX 6.1 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;IRIX 6.2 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;Cellular IRIX 6.4 Technical Report [local copy]&lt;/item&gt;
      &lt;item&gt;XFS White Paper [local copy]&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://www.sgistuff.net/software/irixintro/index.html"/><published>2025-11-09T01:33:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862470</id><title>Tabloid: The Clickbait Headline Programming Language</title><updated>2025-11-09T12:57:39.549561+00:00</updated><content>&lt;doc fingerprint="5205455d1cce1ea4"&gt;
  &lt;main&gt;
    &lt;p&gt;Oops, please turn on JavaScript to enjoy Tabloid :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tabloid.vercel.app/"/><published>2025-11-09T02:53:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862500</id><title>Show HN: Geofenced chat communities anyone can create</title><updated>2025-11-09T12:57:39.175206+00:00</updated><link href="https://vicinity.social/"/><published>2025-11-09T02:59:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862802</id><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><updated>2025-11-09T12:57:39.075898+00:00</updated><content>&lt;doc fingerprint="bc2fcf3649af53d8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican&lt;/head&gt;
    &lt;p&gt;9th November 2025&lt;/p&gt;
    &lt;p&gt;OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they describe as "a more compact and cost-efficient version of GPT-5-Codex". It’s currently only available via their Codex CLI tool and VS Code extension, with proper API access "coming soon". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.&lt;/p&gt;
    &lt;p&gt;I made a video talking through my progress and demonstrating the final results.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;This is a little bit cheeky&lt;/item&gt;
      &lt;item&gt;Codex CLI is written in Rust&lt;/item&gt;
      &lt;item&gt;Iterating on the code&lt;/item&gt;
      &lt;item&gt;Let’s draw some pelicans&lt;/item&gt;
      &lt;item&gt;Bonus: the --debug option&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;This is a little bit cheeky&lt;/head&gt;
    &lt;p&gt;OpenAI clearly don’t intend for people to access this model directly just yet. It’s available exclusively through Codex CLI which is a privileged application—it gets to access a special backend API endpoint that’s not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user’s existing ChatGPT account.&lt;/p&gt;
    &lt;p&gt;I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?&lt;/p&gt;
    &lt;p&gt;This felt like a somewhat absurd loophole, and I couldn’t resist trying it out and seeing what happened.&lt;/p&gt;
    &lt;head rend="h4"&gt;Codex CLI is written in Rust&lt;/head&gt;
    &lt;p&gt;The openai/codex repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.&lt;/p&gt;
    &lt;p&gt;I don’t know much Rust at all.&lt;/p&gt;
    &lt;p&gt;I made my own clone on GitHub and checked it out locally:&lt;/p&gt;
    &lt;code&gt;git clone git@github.com:simonw/codex
cd codex&lt;/code&gt;
    &lt;p&gt;Then I fired up Codex itself (in dangerous mode, because I like living dangerously):&lt;/p&gt;
    &lt;code&gt;codex --dangerously-bypass-approvals-and-sandbox&lt;/code&gt;
    &lt;p&gt;And ran this prompt:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Figure out how to build the rust version of this tool and then build it&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this—in figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.&lt;/p&gt;
    &lt;p&gt;Once the compile had succeeded I fed it the design for the new feature I wanted:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a new sub-command to the Rust tool called “codex prompt”&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here”—this runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.&lt;/p&gt;
      &lt;p&gt;codex prompt -m &amp;lt;model_name&amp;gt; “prompt goes here”—same again but lets you set the model&lt;/p&gt;
      &lt;p&gt;codex prompt “prompt goes here” -s/--system “system prompt goes here”—runs with a custom system/developer message&lt;/p&gt;
      &lt;p&gt;codex prompt --models—this lists all available models that can be used with the “codex prompt” command&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My design for this new sub-command is lifted directly from my own llm command.&lt;/p&gt;
    &lt;head rend="h4"&gt;Iterating on the code&lt;/head&gt;
    &lt;p&gt;Codex got to work. I’ve shared the full transcript here (using the tool I described here), but this TODO list it made itself is a useful summary of what it decided to do:&lt;/p&gt;
    &lt;code&gt;Updated Plan
└ ✔ Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ✔ Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ✔ Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
&lt;/code&gt;
    &lt;p&gt;I like that it figured out the justfile in the repo and decided to use it to run formatting and linting commands without me needing to tell it to.&lt;/p&gt;
    &lt;p&gt;I tried running the first version of the code it wrote like this:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle' -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;... and it didn’t quite work. I got this:&lt;/p&gt;
    &lt;code&gt;(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
I�m ready to help�what would you like me to do next?I�m ready to help�what would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
&lt;/code&gt;
    &lt;p&gt;Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn’t what I want—it appeared to be running in Codex’s normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.&lt;/p&gt;
    &lt;p&gt;I prompted it again, pasting in the broken output:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;this did not seem to work—here is what happened—note that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly)—and then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that this new ’codex prompt’ command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox—it should send a single prompt with no tools and then stream and display a response and then stop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This got me a new build, but when I ran it:&lt;/p&gt;
    &lt;code&gt;Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
&lt;/code&gt;
    &lt;p&gt;My guess is that OpenAI’s custom backend API for Codex doesn’t like it if you attempt to call it without passing in the expected instructions. Fair enough!&lt;/p&gt;
    &lt;p&gt;Rather than paste that error in I got Codex to try the command itself, so it could see the error:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You try running this and see what happens: ./target/debug/codex prompt ’Generate an SVG of a pelican riding a bicycle’&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Codex switched back to the default instructions. From its reply:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;cli/src/prompt_cmd.rs#L1-L320&lt;/code&gt;now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (“don’t run tools”), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.&lt;/quote&gt;
    &lt;p&gt;I guess that will have to do. I asked for one more feature:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;... and we’re ready to try this thing out!&lt;/p&gt;
    &lt;p&gt;Notably I haven’t written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.&lt;/p&gt;
    &lt;p&gt;I’ve pushed the working code to a prompt-subcommand branch in my repo if you want to take a look and see how it all works.&lt;/p&gt;
    &lt;head rend="h4"&gt;Let’s draw some pelicans&lt;/head&gt;
    &lt;p&gt;With the final version of the code built, I drew some pelicans. Here’s the full terminal transcript, but here are some highlights.&lt;/p&gt;
    &lt;p&gt;This is with the default GPT-5-Codex model:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle"&lt;/code&gt;
    &lt;p&gt;I pasted it into my tools.simonwillison.net/svg-render tool and got the following:&lt;/p&gt;
    &lt;p&gt;I ran it again for GPT-5:&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5&lt;/code&gt;
    &lt;p&gt;And now the moment of truth... GPT-5 Codex Mini!&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt "Generate an SVG of a pelican riding a bicycle" -m gpt-5-codex-mini&lt;/code&gt;
    &lt;p&gt;I don’t think I’ll be adding that one to my SVG drawing toolkit any time soon.&lt;/p&gt;
    &lt;head rend="h4"&gt;Bonus: the --debug option&lt;/head&gt;
    &lt;p&gt;I had Codex add a &lt;code&gt;--debug&lt;/code&gt; option to help me see exactly what was going on.&lt;/p&gt;
    &lt;code&gt;./target/debug/codex prompt -m gpt-5-codex-mini "Generate an SVG of a pelican riding a bicycle" --debug&lt;/code&gt;
    &lt;p&gt;The output starts like this:&lt;/p&gt;
    &lt;code&gt;[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
&lt;/code&gt;
    &lt;code&gt;{
  "model": "gpt-5-codex-mini",
  "instructions": "You are Codex, based on GPT-5. You are running as a coding agent ...",
  "input": [
    {
      "type": "message",
      "role": "developer",
      "content": [
        {
          "type": "input_text",
          "text": "You are a helpful assistant. Respond directly to the user request without running tools or shell commands."
        }
      ]
    },
    {
      "type": "message",
      "role": "user",
      "content": [
        {
          "type": "input_text",
          "text": "Generate an SVG of a pelican riding a bicycle"
        }
      ]
    }
  ],
  "tools": [],
  "tool_choice": "auto",
  "parallel_tool_calls": false,
  "reasoning": {
    "summary": "auto"
  },
  "store": false,
  "stream": true,
  "include": [
    "reasoning.encrypted_content"
  ],
  "prompt_cache_key": "019a66bf-3e2c-7412-b05e-db9b90bbad6e"
}&lt;/code&gt;
    &lt;p&gt;This reveals that OpenAI’s private API endpoint for Codex CLI is &lt;code&gt;https://chatgpt.com/backend-api/codex/responses&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Also interesting is how the &lt;code&gt;"instructions"&lt;/code&gt; key (truncated above, full copy here) contains the default instructions, without which the API appears not to work—but it also shows that you can send a message with &lt;code&gt;role="developer"&lt;/code&gt; in advance of your user prompt.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/"/><published>2025-11-09T04:02:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45862833</id><title>Grok 4 Fast now has 2M context window</title><updated>2025-11-09T12:57:39.028791+00:00</updated><content/><link href="https://docs.x.ai/docs/models"/><published>2025-11-09T04:10:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863024</id><title>Forth – is it still relevant?</title><updated>2025-11-09T12:57:38.467198+00:00</updated><content>&lt;doc fingerprint="be229b0a630aca40"&gt;
  &lt;main&gt;
    &lt;p&gt;With all the advantages, it is unfortunate that Forth lost out to C language over the years and have been reduced to a niche. Per ChatGPT: due to C's broader appeal, standardization, and support ecosystem likely contributed to its greater adoption and use in mainstream computing.&lt;/p&gt;
    &lt;p&gt;So, the question is, how to encourage today's world of C programmers to take a look at Forth. How do we convince them that Forth can be 10 times more productive? Well, we do know that by keep saying how elegant Forth is or even bashing how bad C can be probably won't get us anywhere.&lt;/p&gt;
    &lt;p&gt;Bill Muench created eForth for simplicity and educational purpose. Dr. Ting, ported to many processors, described Forth in his well-written eForth genesis and overview. I like the idea and decided to pick it up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;100% C/C++ with multi-platform support. Though classic implementation of primitives in assembly language and scripted high-level words gave the power to Forth, it also became the hurtle for newbies. Because they have to learn the assembly and Forth syntax before peeking into the internal beauty of Forth.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary is just an array. It's remodeled from linear memory linked-list to an array (or a vector in C++'s term) of words.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;To search for a word, simply scan the name string of dictionary entries. So, to define a new word during compile time is just to append those found word pointers to the its parameter array one by one.&lt;/item&gt;
          &lt;item&gt;To execute become just a walk of the word pointers in the array. This is our inner interpreter.&lt;/item&gt;
          &lt;item&gt;Hashtables might go even faster but we'll try that later.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data and Return Stacks are also arrays. With push, pop and [] methods to clarify intentions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Parameter fields are all arrays. Why not!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;No vocabulary, or meta-compilation. Except CREATE..DOES&amp;gt;, and POSTPONE, these black-belt skills of Forth greatness are dropped to keep the focus on core concepts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Multi-threading and message passing are available From v5.0 and on, multi-core platform can utilize Forth VMs running in parallel. see the multi-threading section below for details&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;A thread pool is built-in. Size is defaults to number of cores.&lt;/item&gt;
          &lt;item&gt;Message Passing send/recv with pthread mutex waiting.&lt;/item&gt;
          &lt;item&gt;IO and memory update can be synchronized with lock/unlock.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you are fluent in C/C++ and in the process of building your own Forth, skipping the verbage, the easiest path to gain understanding of how things work together is to download release v4.2 and work from there.&lt;/p&gt;
    &lt;p&gt;In the release, a heavily commented ceforth.cpp, the companion ceforth.h, and a config.h. Altogether, about 800 lines. Check them out!&lt;/p&gt;
    &lt;p&gt;The core of current implementation of eForth is the dictionary composed of an array of Code objects that represent each of Forth words.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Code - the heart of eForth, depends on the constructor called, the following fields are populated accordingly&lt;/p&gt;
        &lt;quote&gt;+ name - a string that holds primitive word's name, i.e. NFA in classic FORTH, can also holds branching mnemonic for compound words which classic FORTH keeps on parameter memory + xt - pointer to a lambda function for primitive words i.e. XT in classic FORTH + pf, p1, p2 - parameter arrays of Code objects for compound words, i.e. PFA in classic FORTH + q - holds the literal value which classic FORTH keep on parameter memory&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Lit, Var, Str, Bran, Tmp - the polymorphic classes extended from the base class Code which serve the functionalities of primitive words of classic Forth.&lt;/p&gt;
        &lt;quote&gt;+ Lit - numeric literals + Var - variable or constant + Str - string for dostr or dotstr + Bran - Branching opcode + Tmp - temp storage for branching word&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Dictionary - an array of Code objects&lt;/p&gt;
        &lt;quote&gt;+ build-it words - constructed by initializer_list at start up, before main is called, degenerated lambdas become function pointers stored in Code.xt dict[0].xt ------&amp;gt; lambda[0] &amp;lt;== These function pointers can be converted dict[1].xt ------&amp;gt; lambda[1] into indices to a jump table ... which is exactly what WASM does dict[N-1].xt ----&amp;gt; lambda[N-1] &amp;lt;== N is number of built-in words + colon (user defined) words - collection of word pointers during compile time dict[N].pf = [ *Code, *Code, ... ] &amp;lt;== These are called the 'threads' in Forth's term dict[N+1].pf = [ *Code, *Code, ... ] So, instead of subroutine threading ... this is 'object' threading. dict[-1].pf = [ *Code, *Code, ... ] It can be further compacted into token (i.e. dict index) threading if desired&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Inner Interpreter - Code.exec() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;if (xt) { xt(this); return; } // run primitive word for (Code *w : pf) { // run colon word try { w-&amp;gt;exec(); } // execute recursively catch (...) { break; } // handle exception if any }&lt;/quote&gt;
        &lt;p&gt;i.e. either we call a built-in word's lambda function or walk the Code.pf array recursively like a depth-first tree search.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Outer Interpreter - forth_core() is self-explanatory&lt;/p&gt;
        &lt;quote&gt;Code *c = find(idiom); // search dictionary if (c) { // word found? if (compile &amp;amp;&amp;amp; !c-&amp;gt;immd) // are we compiling a new word? dict[-1]-&amp;gt;add(c); // then append found code to it else c-&amp;gt;exec(); // or, execute the code return; } DU n = parse_number(idiom); // word not found, try as a number if (compile) // are we compiling a new word? dict[-1]-&amp;gt;add(new Lit(n)); // append numeric literal to it else PUSH(n); // push onto data stack&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With the array implementation, the first difference is in array variable read/write.&lt;/p&gt;
    &lt;code&gt;&amp;gt; create narr 10 cells allot
&amp;gt; see narr
&amp;gt; : narr
    0 0 0 0 0 0 0 0 0 0 ;
\       ^----------------- narr 2 cells +&lt;/code&gt;
    &lt;p&gt;While traditional Forths uses &lt;code&gt;narr 2 cells +&lt;/code&gt; to get the memory address of &lt;code&gt;narr[2]&lt;/code&gt;, eforth &lt;code&gt;narr&lt;/code&gt; returns its index (or defining order) in the dictionary. So, &lt;code&gt;narr 2 cells +&lt;/code&gt; will actually get you the index of the second word defined after &lt;code&gt;narr&lt;/code&gt;. You'll be storing the value into that word's empty qf field.
To access the nth element of &lt;code&gt;narr&lt;/code&gt;, use &lt;code&gt;th&lt;/code&gt; instead&lt;/p&gt;
    &lt;code&gt;&amp;gt; : fill-arr
    10 0 do
      i 2* narr i th !
    loop ;
&amp;gt; fill-arr
&amp;gt; see narr
&amp;gt; : narr
    0 2 4 6 8 10 12 14 16 18 ;&lt;/code&gt;
    &lt;p&gt;With arrays, the doors are open. Dynamically expanding variables as well as storing objects instead of just integers. Parameter fields can be filled in compile time or changed on the fly in runtime i.e. self-morphing code. These can be the "scary" features for Forths to come.&lt;/p&gt;
    &lt;p&gt;Most classic Forth systems are build with a few low-level primitives in assembly language and bootstrap the high-level words in Forth itself. Over the years, Dr. Ting have implemented many Forth systems using the same model. See here for the detailed list. However, he eventually stated that it was silly trying to explain Forth in Forth to new comers. There are just not many people know Forth, period.&lt;/p&gt;
    &lt;p&gt;Utilizing modern OS and tool chains, a new generation of Forths implemented in just a few hundreds lines of C code can help someone who did not know Forth to gain the core understanding much quickly. He called the insight Forth without Forth.&lt;/p&gt;
    &lt;p&gt;In 2021-07-04, I got in touched with Dr. Ting mentioning that he taught at the university when I attended. He, as the usual kind and generous him, included me in his last projects all the way till his passing. I am honored that he considered me one of the frogs living in the bottom of the deep well with him looking up to the small opening of the sky together. With cross-platform portability as our guild-line, we built ooeForth in Java, jeForth in Javascript, wineForth for Windows, and esp32forth for ESP micro-controllers using the same code-base. With his last breath in the hospital, he attempted to build it onto an FPGA using Verilog. see ceForth_403 and eJsv32 for details.&lt;/p&gt;
    &lt;p&gt;We hope it can serve as a stepping stone for learning Forth to even building their own, one day.&lt;/p&gt;
    &lt;code&gt;    $ git clone https://github.com/chochain/eforth to your local machine
    $ cd eforth&lt;/code&gt;
    &lt;p&gt;There are two major versions current. eForth. v4 is single-threaded only and v5 default single-threaded but also supports multi-threaded.&lt;/p&gt;
    &lt;p&gt;Checkout the version you are interested in.&lt;/p&gt;
    &lt;code&gt;    $ git checkout v42           # for version 4.2 (latest), or
    $ git checkout master        # for version 5 and on&lt;/code&gt;
    &lt;p&gt;To enable multi-threading, of v5, update the followings in ~/src/config.h&lt;/p&gt;
    &lt;code&gt;    #define DO_MULTITASK   1
    #define E4_VM_POOL_SZ  8&lt;/code&gt;
    &lt;code&gt;    $ make
    $ ./tests/eforth             # to bring up the Forth interpreter&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words⏎               \ to see available Forth words
    &amp;gt; 1 2 +⏎               \ see Forth in action
    &amp;gt; bye⏎  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Once you get pass the above, try the lessons by Dr. Ting.
&lt;/code&gt;
    &lt;code&gt;    $ ./tests/eforth &amp;lt; ./tests/demo.fs&lt;/code&gt;
    &lt;p&gt;Pretty amazing stuffs! To grasp how they were done, study the individual files (*.fs) under ~/tests/demo.&lt;/p&gt;
    &lt;p&gt;Note: MacOS added, thanks to Kristopher Johnson's work.&lt;/p&gt;
    &lt;p&gt;I haven't develop anything useful on Windows for a long time. Just bearly got this compiled on an 2007 Windows7 box. So, take it with a grain of salt. I'm hoping someone can make it more streamlined.&lt;/p&gt;
    &lt;code&gt;* install and run Visual Studio on your box
* under the root directory, open the solution file eforth.sln (which points to project platform/eforth.vcxproj)
* Menu bar -&amp;gt; Build -&amp;gt; Build Solution   (default to Debug/64-bit)
* in a Command window, find and run eforth.exe under tests sub-directory
&lt;/code&gt;
    &lt;code&gt;    &amp;gt; eForth v5.0, RAM 16.5% free (1300 / 7880 MB)
    &amp;gt; words⏎               \ to see available Forth words
    &amp;gt; 1 2 +⏎               \ see Forth in action
    &amp;gt; bye⏎  or Ctrl-C      \ to exit eForth&lt;/code&gt;
    &lt;code&gt;Note: Windows multi-threading seems to work but 2x slower. 
    * I only have a 2-core Win box. Do let me know if it goes further. 8-)
    * No CPU affinity. The code might need to be namespaced to avoid conflicts with Windows include files.
&lt;/code&gt;
    &lt;code&gt;* ensure you have Emscripten (WASM compiler) installed and configured
* or, alternatively, you can utilize docker image from emscripten/emsdk
&lt;/code&gt;
    &lt;code&gt;    $ make wasm
    $ python3 tests/cors.py        # supports COOP&lt;/code&gt;
    &lt;code&gt;* from your browser, open http://localhost:8000/tests/eforth.html
&lt;/code&gt;
    &lt;p&gt;Note: For multi-threading to work, browser needs to receive Cross-Origin policies here for detail in the response header. A Python script ~/tests/cors.py is provided to solve the issue. The same needed to be provided if you use other web server.&lt;/p&gt;
    &lt;code&gt;* ensure your Arduino IDE have ESP32 libraries installed
* update ESP32 compiler.optimization flags in ~/hardware/platform.txt to -O3 (default -Os)
* open eforth.ino with Arduino IDE
* inside eforth.ino, modify WIFI_SSID and WIFI_PASS to point to your router
* open Arduino Serial Monitor, set baud 115200 and linefeed to 'Both NL &amp;amp; CR'
* compile and load
* if successful, web server IP address/port and eForth prompt shown in Serial Monitor
* from your browser, enter the IP address to access the ESP32 web server
&lt;/code&gt;
    &lt;p&gt;Note: Most ESP32 are dual-core. However core0 is dedicated to WiFi and FreeRTOS house keeping. Forth tasks will be tied to core1 only. So, multi-threading is possible but no performance gain. Actually, singled-threaded v4.2 does a bit better.&lt;/p&gt;
    &lt;p&gt;Forth has been supporting multi-tasking since the 70's. They are single-CPU round-robin/time-slicing systems mostly. Modern system has multiple cores and Forth can certainly take advantage of them. However, unlike most of the matured Forth word sets, multi-threading/processing words are yet to be standardized and there are many ways to do it.&lt;/p&gt;
    &lt;code&gt;* each VM has it's own private ss, rs, tos, ip, and state
* multi-threading, instead of multi-processing, with shared dictionary and parameter memory blocks.
* pthread.h is used. It is a common POSIXish library supported by most platforms. I have only tried the handful on hands, your mileage may vary.
* Message Passing interface for inter-task communication.
&lt;/code&gt;
    &lt;code&gt;1. We have the VM array, sized by E4_VM_POOL_SZ, which defines the max tasks you want to have. Typically, anything more than your CPU core count does not help completing the job faster.
2. Each VM is associated with a thread, i.e. our thread-pool.
3. The event_queue, a C++ queue takes in "ready to run" tasks.
4. Lastly, event_loop picks up "ready to run" tasks and kicks start them one by one.

The following VM states manage the life-cycle of a task

* QUERY - interpreter mode - only the main thread can do this
* HOLD  - ready to execute, or waiting for message to arrive
* NEST  - in execution
* STOP  - free for next task
&lt;/code&gt;
    &lt;p&gt;Before we go too far, make sure the following are updated before your build&lt;/p&gt;
    &lt;code&gt;* pthread.h is installed. 
* DO_MULTITASK, E4_VM_POOL_SZ are updated in ~/src/config.h
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;word&lt;/cell&gt;
        &lt;cell role="head"&gt;stack&lt;/cell&gt;
        &lt;cell role="head"&gt;desc&lt;/cell&gt;
        &lt;cell role="head"&gt;state&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;task&lt;/cell&gt;
        &lt;cell&gt;( xt -- t )&lt;/cell&gt;
        &lt;cell&gt;create a task (tid is index to thread pool entry)&lt;p&gt;a free VM from pool is chosen for the task&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;STOP=&amp;gt;HOLD&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;rank&lt;/cell&gt;
        &lt;cell&gt;( -- t )&lt;/cell&gt;
        &lt;cell&gt;fetch current task id&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;start&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;start a task&lt;p&gt;The VM is added to event_queue and kick started when picked up by event_loop&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;join&lt;/cell&gt;
        &lt;cell&gt;( t -- )&lt;/cell&gt;
        &lt;cell&gt;wait until the given task is completed&lt;/cell&gt;
        &lt;cell&gt;NEST=&amp;gt;STOP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;lock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;lock (semaphore) IO or memory&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;unlock&lt;/cell&gt;
        &lt;cell&gt;( -- )&lt;/cell&gt;
        &lt;cell&gt;release IO or memory lock&lt;/cell&gt;
        &lt;cell&gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;send&lt;/cell&gt;
        &lt;cell&gt;( v1 v2 .. vn n t -- )&lt;/cell&gt;
        &lt;cell&gt;send n elements on current stack to designated task's stack (use stack as message queue)&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receiver HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;recv&lt;/cell&gt;
        &lt;cell&gt;( -- v1 v2 .. vn )&lt;/cell&gt;
        &lt;cell&gt;wait, until message to arrive&lt;/cell&gt;
        &lt;cell&gt;HOLD=&amp;gt;NEST&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;pull&lt;/cell&gt;
        &lt;cell&gt;( n t -- )&lt;/cell&gt;
        &lt;cell&gt;forced fetch stack elements from a completed task&lt;/cell&gt;
        &lt;cell&gt;current NEST&lt;p&gt;target STOP&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;bcast&lt;/cell&gt;
        &lt;cell&gt;( n -- )&lt;/cell&gt;
        &lt;cell&gt;not implemented yet, TODO&lt;/cell&gt;
        &lt;cell&gt;sender NEST&lt;p&gt;receivers HOLD&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;clock&lt;/cell&gt;
        &lt;cell&gt;( -- n )&lt;/cell&gt;
        &lt;cell&gt;fetch microsecond since Epoch, useful for timing&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;    &amp;gt; : once 999999 for rank drop next ;            \ 1M cycles
    &amp;gt; : run clock negate once clock + . ." ms" cr ; \ benchmark
    &amp;gt; ' run constant xt                             \ keep the xt
    &amp;gt; : jobs 1- for xt task start next ;            \ tasks in parallel
    &amp;gt; 4 jobs&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T2 [05.1]&amp;gt;&amp;gt; started on T4 [04.1]&amp;gt;&amp;gt; started on T6 [07.1]&amp;gt;&amp;gt; started on T0 18 ms [06.3]&amp;gt;&amp;gt; finished on T2 18 ms [05.3]&amp;gt;&amp;gt; finished on T4 18 ms [04.3]&amp;gt;&amp;gt; finished on T6 18 ms [07.3]&amp;gt;&amp;gt; finished on T0&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; 0 constant pp                           \ producer task id
    &amp;gt; 0 constant cc                           \ consumer task id
    &amp;gt; : sndr
        1000 ms                               \ delay to simulate some processing
        1 2 3 4 4 cc send                     \ send 4 items from stack
        lock ." sent " cr unlock ;            \ locked IO before write
    &amp;gt; : rcvr
        recv                                  \ wait for sender
        + + +                                 \ sum received 4 items
        lock ." sum=" . cr unlock ;           \ locked IO before write
    &amp;gt; ' sndr task to pp
    &amp;gt; ' rcvr task to cc
    &amp;gt; cc start                                \ start receiver task
    &amp;gt; pp start                                \ start sender task
    &amp;gt; pp join cc join                         \ wait for completion&lt;/code&gt;
    &lt;quote&gt;[06.1]&amp;gt;&amp;gt; started on T1 [06.1]&amp;gt;&amp;gt; waiting [07.1]&amp;gt;&amp;gt; started on T2 [06.1]&amp;gt;&amp;gt; sending 4 items to VM6.1 sent [07.3]&amp;gt;&amp;gt; finished on T2 [00.3]&amp;gt;&amp;gt; VM7 joint [06.3]&amp;gt;&amp;gt; received =&amp;gt; state=3 sum=10 [06.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM6 joint&lt;/quote&gt;
    &lt;code&gt;    &amp;gt; : sum 0 1000000 for i + next ;          \ add 0 to 1M
    &amp;gt; ' sum task constant tt                  \ create the task
    &amp;gt; tt start tt join                        \ run and wait for completion
    &amp;gt; 1 tt pull ." total=" .                  \ pull the sum&lt;/code&gt;
    &lt;quote&gt;[00.3]&amp;gt;&amp;gt; joining VM7 [07.1]&amp;gt;&amp;gt; started on T1 [07.3]&amp;gt;&amp;gt; finished on T1 [00.3]&amp;gt;&amp;gt; VM7 joint pulled 1 items from VM7.0 total= 1784293664 -1 -&amp;gt; ok&lt;/quote&gt;
    &lt;code&gt;+ ~/src       - multi-threaded, dynamic vector-based, object threading
+ ~/platform  - platform specific code for C++, ESP32, Windows, and WASM
+ ~/orig      - archive from Dr. Ting and my past works
+    /33b     - refactored ceForth_33, separate ASM from VM (used in eForth1 for Adruino UNO)
+    /ting    - ceForth source codes collaborated with Dr. Ting
+    /esp32   - esp32forth source codes collaborated with Dr. Ting
+    /40x     - my experiments, refactor _40 into vector-based subroutine-threaded, with 16-bit offset
+    /50x     - my experiments, add multi-threading to _40
&lt;/code&gt;
    &lt;code&gt;+ 4452ms: ~/orig/ting/ceforth_36b, linear memory, 32-bit, token threading
+ 1450ms: ~/orig/ting/ceForth_403, dict/pf array-based, subroutine threading
+ 1050ms: ~/orig/40x/ceforth, subroutine indirect threading, with 16-bit offset
+  890ms: ~/orig/40x/ceforth, inner interpreter with cached xt 16-bit offsets
+  780ms: ~/src/eforth, v4.2 dynamic vector, object threading (gcc -O2)
&lt;/code&gt;
    &lt;code&gt;+  812ms: v5.0, multi-threaded (gcc -O2)
+  732ms: v5.0, multi-threaded (gcc -O3)
+  731ms: v5.0, single-threaded (gcc -O3) =&amp;gt; not much overhead with MT
&lt;/code&gt;
    &lt;code&gt;+  843ms: v5.0 50x32 branch (gcc -O2)
   * program spent &amp;gt;50% in nest() - gprof/valgrind/cachegrind
   * 16-bit IU fetch + dispatch: Ir/Dr = 2.3M/0.5M (810ms)
   * 32-bit Param hardcopy     : Ir/Dr = 3.8M/1.1M (930ms)
   * 32-bit Param reference    : Ir/Dr = 3.1M/0.8M (843ms) &amp;lt;== 32-bit best
   * 32-bit Param pointer      : Ir/Dr = 3.2M/0.9M (899ms)
+  873ms: v5.0 50x32 branch (gcc -O3)
   * slower, due to inline find() into forth_core() which crowded cache.
     Note: this doesn't seem to bother WASM.
&lt;/code&gt;
    &lt;code&gt;+ 1440ms: Dr. Ting's ~/esp32forth/orig/esp32forth_82
+ 1045ms: ~/orig/esp32/ceforth802, array-based, token threading
+  990ms: ~/orig/40x/ceforth, linear-memory, subroutine threading, with 16-bit offset
+  930ms: ~/orig/40x/ceforth, inner interpreter with cached xt offsets
+  644ms: ~/src/eforth, v4.2 dynamic vector, token threading
+  534ms: ~/src/eforth, v5.0 multi-threaded, dynamic vector, object threading (with gcc -O3)
&lt;/code&gt;
    &lt;p&gt;What is the performance difference?&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Code *dict[] - where words are dynamically allocated as a collection of pointers, or&lt;/item&gt;
      &lt;item&gt;Code dict[] - where words are statically created as an array of objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have created a git branch 'static' to compare to the 'master. The static version is about 10% slower on 64-bit machine and about 5% slower on 32-bits. This hasn't been carefully analyzed but my guess is because Code is big at 144-bytes on 64-bit. They might get pushed off L1 cache too often.&lt;/p&gt;
    &lt;p&gt;An array of lambdas vs the classic switch statement, i.e.&lt;/p&gt;
    &lt;code&gt;const Code dict[] {               ///&amp;lt; Forth dictionary
    CODE("+",      TOS += SS.pop()),
    CODE("-",      TOS =  SS.pop() - TOS),
    CODE("*",      TOS *= SS.pop()),
    CODE("/",      TOS =  SS.pop() / TOS),
    ...
vs
    switch(opcode) {             ///&amp;lt; big switch statement
    case PLUS:     TOS += SS.pop();      break;
    case MINUS:    TOS = SS.pop() - TOS; break;
    case MULTIPLY: TOS *= SS.pop();      break;
    case DIVIDE:   TOS = SS.pop() / TOS; break;
    ...
&lt;/code&gt;
    &lt;p&gt;Though syntax clarity is pretty much the same, lambda being function pointers takes an extra jump and the cost of stack-frame setup/teardown. It takes more space and about 15% slower in tight loops. However, with the advance of compilers,&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It does not need a long enum definition, i.e. PLUS, MINUS, ..., which needs to be kept in-sync&lt;/item&gt;
      &lt;item&gt;It is possible to prebuild lambda array as a ROM image or static library that can be transported.&lt;/item&gt;
      &lt;item&gt;A tweak to CODE macro, i.g. adding NEXT, can potentially enable Tail Call Optimization (TCO) which eliminates the stack-frame overhead as did in many functional languages.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Though the use of C++ standard libraries helps us understanding what Forth does but, even on machines with GBs, we still need to be mindful of the followings. It gets expensive especially on MCUs.&lt;/p&gt;
    &lt;code&gt;+ A pointer takes 8-byte on a 64-bit machine,
+ A C++ string, needs 3 to 4 pointers, will require 24-32 bytes,
+ A vector, takes 3 pointers, is 24 bytes
&lt;/code&gt;
    &lt;p&gt;The current implementation of ~/src/ceforth.h, a Code node takes 144 bytes on a 64-bit machine. On the other extreme, my ~/orig/40x experimental version, a vector linear-memory hybrid, takes only 16 bytes here. Go figure how the classic Forths needs only 2 or 4 bytes per node via linked-field and the final executable in a just a few KB. You might start to understand why the old Forth builders see C/C++ like plaque.&lt;/p&gt;
    &lt;p&gt;I try to release allocated blocks before exiting, however due to the dynamic alloc and resizing of std::vector, eForth dictionary hold on to many Code objects and the names string generated with them, valgrind (or similar tool) could reports lost (or leak). Though these memory blocks should all be reclaimed by the OS, it is something to be mindful of.&lt;/p&gt;
    &lt;p&gt;Current implementation utilize C++ vector as the core storage. Inside a Code object, there are pf, p1, p2 vectors to store branching words similar to that of an AST (Abstract Syntax Tree). The alternative is to stick all words into a single parameter field as done in classic Forth. I have created a branch one_pf doing exactly the same just to check it out. Also, tried polymorphic inner interpreter. So, are they better?&lt;/p&gt;
    &lt;code&gt;+ Branching microcode look cleaner. 2-bit **VM.stage** flag can be replaced by a 1-bit **VM.jmp** status. No big deal.
+ dump and see are easier to implement, but
+ Runs 4~8x slower using recursive nest() i.e. Forth inner interpreter,
+ Improved to 2x slower using iterative nest()
+ Also, polymorphic slows down additional 5%. Most likely due to extra vtable lookup.
&lt;/code&gt;
    &lt;p&gt;So, what cachegrind said for 100M loop tight loops and chacha.fs a CPU intensive?&lt;/p&gt;
    &lt;code&gt;| Op          | 100M loop | chacha.fs |
|-------------|-----------|-----------|
| Data Read   | +30%      | +32%      |
| Branches    | +25%      | +30%      |
| Mispred     | similar   | similar   |
| Instruction | +20%      | +40%      |
&lt;/code&gt;
    &lt;p&gt;Apparently, grown ~30% in all aspects. I think because having branching primitives, i.e. _if/_else/_then, for/next, in C++ prevent the extra fetch of VM branches. Sort of the difference between having hardware and software branchers. However, my gut feeling is the difference shouldn't be so dramatic especially with the recursive nest(). More research on this...&lt;/p&gt;
    &lt;p&gt;Instead of using vectors (i.e. pf, p1, p2) to keep codes and parameters, this implementation follows classic Forth's model using one big block of parameter memory with words laid down contiguoursly. With 32-bit data, subroutine threaded but hybrid with 16-bit xt offset (to reduce one lookup).&lt;/p&gt;
    &lt;p&gt;It works better with WASM's memory model. It is used as the foundation for weForth. So far, it is stable but tweaked from time to time and&lt;/p&gt;
    &lt;code&gt;&amp;gt; make 50x
&amp;gt; ./tests/eforth50x
&lt;/code&gt;
    &lt;p&gt;Hinted by Sean Pringle's Rethinking Forth and Travis Bemann's wornderful zeptoforth. Nested module (or sub-words), simplified control structures are attemped. Now, moved to eForthX&lt;/p&gt;
    &lt;code&gt;+ perf   - [multithreaded](https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps)
+ coding -
    [optimizing](http://www.agner.org/optimize/optimizing_cpp.pdf)
    [false-sharing](https://medium.com/distributed-knowledge/optimizations-for-c-multi-threaded-programs-33284dee5e9c)
    [affinity](https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/)
    [occlusion](https://fgiesen.wordpress.com/2013/02/17/optimizing-sw-occlusion-culling-index/)
    [perf c2c](https://coffeebeforearch.github.io/2020/03/27/perf-c2c.html)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Dr. Ting's work on eForth between 1995~2011 eForth references and their Source Code Repo&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210314: Initial&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Started with ~orig/33b code-base, refactor with enum and VA_ARGS macros targeting 100% C/C++.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210707: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Incorporated list-based dict, ss, rs (i.e. ~orig/ting/ceForth40 and ~orig/802) which I proposed to Dr. Ting in our email exchanges.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20210816: Code Merge&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Targeting multi-platform. Common source by consolidating ceForth, wineForth, ESP32forth (kept in ~/orig/*). Officially version 8.0&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20220512: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Though the goal of Dr. Ting's is to demonstrate how a Forth can be easily understood and cleanly constructed. However, the token threading method used is costly (slow) because each call needs 2 indirect lookups (token-&amp;gt;dict, dict-&amp;gt;xt). On top of that, C/C++ call-frame needs to be setup/teardown. It is worsen by the branch prediction missing every call stalling the CPU pipeline. Bad stuffs!&lt;/item&gt;
          &lt;item&gt;Refactor to subroutine indirect threading. It's not portable but does speed up 25% (see benchmark above).&lt;/item&gt;
          &lt;item&gt;Using 16-bit offsets for pointer arithmetic which speed up another 5% while maintaining 16-bit parameter space consumption.&lt;/item&gt;
          &lt;item&gt;Since C++ code is at least 4-byte aligned and parameter is 2-byte aligned, the LSB of a given parameter is utilized for colon word identification.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20221118: Refactor&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;WASM function pointer is U32 (index). Token-indirect worked but the two indirect look-up is even slower. Since WASM uses 64K linear memory block, 16-bit pointer offset is a better option. However, the xt "function pointer" in code space is simply an index to the shared _indirect_function_table. Since LSB is used, so we are forced to use MSB to differentiate primitive word from colon word. This left us 15-bit, i.e. 32K, parameter offset available.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20231011: Review&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Since the original intention of having a pre-compiled ROM dictionary still end up in C++ static initialization run before main(), moved dictionary compilation into dict_compile as function calls gives a little more debugging control and opportunity for fine tuning.&lt;/item&gt;
          &lt;item&gt;LAMBDA_OK option was originally intended for full VM implementation but 2x slower. Dropped to reduce source clutter.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20240308: Refactor for multi-platform, accept dynamic vectors&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Experiment various threading and memory pointer models, archive into ~/orig/40x&lt;/item&gt;
          &lt;item&gt;To support cross-platform, i.g. Linux/Cygwin, Arduino/ESP32, Win32, and WASM, there were many conditional compilation branches which make the code really messy. The following were done &lt;list rend="ul"&gt;&lt;item&gt;Separate cross-platform and configuration into ~/src/config.h&lt;/item&gt;&lt;item&gt;Separate platform specific code into ~/platform&lt;/item&gt;&lt;item&gt;add included opcode for Forth script loading&lt;/item&gt;&lt;item&gt;rename 'next_idiom' to 'word', per Forth standard&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC 20241001: Add multi-threading support&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Shared dictionary and code space amount threads.&lt;/item&gt;
          &lt;item&gt;Refactor source into ceforth, ceforth_sys, and ceforth_task for their specific functions.&lt;/item&gt;
          &lt;item&gt;Introduce VM, states &lt;list rend="ul"&gt;&lt;item&gt;local ss, rs, tos, and user area&lt;/item&gt;&lt;item&gt;align to cache-line width&lt;/item&gt;&lt;item&gt;pass VM&amp;amp; to all lambda and static functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add thread pool and event_loop with affinity to physical cores. &lt;list rend="ul"&gt;&lt;item&gt;task, start, stop, join for thread life-cycle management&lt;/item&gt;&lt;item&gt;add general multi-threading demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add Inter-task communication &lt;list rend="ul"&gt;&lt;item&gt;pthread mutex and condition variables are used for synchronization&lt;/item&gt;&lt;item&gt;rank for task id&lt;/item&gt;&lt;item&gt;send, recv, and pull. Use local stack, as queue, for message passing.&lt;/item&gt;&lt;item&gt;add producer/consumer demo&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Add IO sequencing &lt;list rend="ul"&gt;&lt;item&gt;ANSI-Color trace/logging for different cores&lt;/item&gt;&lt;item&gt;mutex guard used&lt;/item&gt;&lt;item&gt;lock, unlock for output stream synchronization&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;CC: 20250610: maintenance and memory leak check&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Refactor &lt;list rend="ul"&gt;&lt;item&gt;Macros to reduce verbosity i.e. VM referenced TOS, SS, RS, BRAN, BTGT&lt;/item&gt;&lt;item&gt;Group IO functions to forth_sys module&lt;/item&gt;&lt;item&gt;Macros to clarify intention, i.e. NEST, BASE, ADD_W&lt;/item&gt;&lt;item&gt;Code references replace Code pointers&lt;/item&gt;&lt;item&gt;Rename ms=&amp;gt;clock, delay=&amp;gt;ms (adhere to Forth Standard)&lt;/item&gt;&lt;item&gt;Add destructors to deallocate (reduce valgrind's complaints)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance multi-threading &lt;list rend="ul"&gt;&lt;item&gt;Use std::thread instead of pthread (except device specific CPU affinity)&lt;/item&gt;&lt;item&gt;Handle recursive include - Save/Restore WP&lt;/item&gt;&lt;item&gt;Refined forth_vm state machine transition (QUERY, HOLD, NEST, STOP)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;Enhance debugging &lt;list rend="ul"&gt;&lt;item&gt;Add dict() to detail dictionary entries&lt;/item&gt;&lt;item&gt;Add dump() to show memory/parameter field's content&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Refactor &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/chochain/eforth"/><published>2025-11-09T04:59:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863057</id><title>Study finds memory decline surge in young people</title><updated>2025-11-09T12:57:38.421251+00:00</updated><content/><link href="https://onepercentrule.substack.com/p/under-40s-declining-memory"/><published>2025-11-09T05:05:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45863360</id><title>I Am Mark Zuckerberg</title><updated>2025-11-09T12:57:38.139537+00:00</updated><content>&lt;doc fingerprint="b609d0711019dfdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Welcome to iammarkzuckerg.com&lt;/head&gt;
    &lt;p&gt;No, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks.&lt;/p&gt;
    &lt;p&gt;Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money.&lt;/p&gt;
    &lt;p&gt;What I Really Do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Help people obtain a fresh financial start (no passwords required)&lt;/item&gt;
      &lt;item&gt;Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)&lt;/item&gt;
      &lt;item&gt;Answer local legal questions, not privacy scandals&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Real Zuckerberg Facts:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Shares a name, not fortune, with the Facebook founder&lt;/item&gt;
      &lt;item&gt; Gets mistaken daily for a tech billionaire &lt;/item&gt;
      &lt;item&gt; Has written zero social media apps, but plenty of court briefs&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Fun Fact:&lt;lb/&gt; In Indiana, saying "I'm Mark Zuckerberg" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. &lt;/p&gt;
    &lt;head rend="h3"&gt; Click Here to See How Other &lt;lb/&gt;Websites Have Reacted to This &lt;/head&gt;
    &lt;head rend="h3"&gt;Interesting Things That Have Happened to Me Because My Name is Mark Zuckerberg&lt;/head&gt;
    &lt;p&gt;For a complete list of things that have happened to Mark Zuckerberg click here&lt;/p&gt;
    &lt;p&gt;Like I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for "Mark Zuckerberg bankruptcy". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://iammarkzuckerberg.com/"/><published>2025-11-09T06:13:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45864732</id><title>Ask HN: How would u setup a child's first Linux computer?</title><updated>2025-11-09T12:57:37.988301+00:00</updated><content>&lt;doc fingerprint="d1e111d1f886a428"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;As a tech parent I think one of the best things I did for both my son and daughter was for their first computer to help them to build and setup their own Linux computer (It was Ubuntu back then but they’ve both moved themselves to Arch these days).&lt;/p&gt;
      &lt;p&gt;We went together and bought a second hand desktop (exciting the people selling to us also) and when I got home I pulled out the Ram, HD and CD drive and set them aside; and then together with a screwdriver we “built the computer” over a few days.&lt;/p&gt;
      &lt;p&gt;In windows when a child goes searching the web for a “movie maker for windows” they are going to be in a world of hurt either finding expensive commercial options or super scammy sites promising the world.&lt;/p&gt;
      &lt;p&gt;By comparison on Linux if they search the local “app store” they’ll find stacks and stacks of free, useful, open licensed software.&lt;/p&gt;
      &lt;p&gt;My kids loved the power, freedom and later unexpected community this bought them.&lt;/p&gt;
      &lt;p&gt;Now my friend wants the same for their daughter who is 8 years old.&lt;/p&gt;
      &lt;p&gt;I’m planning to do the same and go with her parents and her and buy a second hand desktop together and then put Linux on it.&lt;/p&gt;
      &lt;p&gt;My question is where would you go from there? What suggestions do you have? What to install? Any mini “curriculums” or ideas?&lt;/p&gt;
      &lt;p&gt;Would love to hear your ideas and experiences. Linux with free and open software is the goal and focus.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45864732"/><published>2025-11-09T11:12:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865049</id><title>Visualize FastAPI endpoints with FastAPI-Voyager</title><updated>2025-11-09T12:57:37.146210+00:00</updated><content>&lt;doc fingerprint="2d7d4c5aa849e7b4"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading… FastAPI Voyager {{ state.version }} scroll to zoom in/out double click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }} {{ tag.routes.length }} {{ route.name }} No routes {{ dumpJson }} Import core data JSON&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.newsyeah.fun/voyager/"/><published>2025-11-09T12:24:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45865098</id><title>Alive Internet Theory</title><updated>2025-11-09T12:57:36.922167+00:00</updated><link href="https://alivetheory.net/"/><published>2025-11-09T12:33:38+00:00</published></entry></feed>