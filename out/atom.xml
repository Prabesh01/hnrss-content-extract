<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-29T00:47:24.197148+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45404022</id><title>When I say “alphabetical order”, I mean “alphabetical order”</title><updated>2025-09-29T00:47:33.236645+00:00</updated><content>&lt;doc fingerprint="144ce85c2ae519d5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When I say “alphabetical order”, I mean “alphabetical order”&lt;/head&gt;
    &lt;p&gt;Last month I have been on a multi-day hike with my dad. Each of us took many pictures, and when we came back we put them all in a shared folder. We both have Android phones, and the naming scheme used for our pictures was the same: &lt;code&gt;IMG_YYYYMMDD_HHmmss&lt;/code&gt; followed maybe by some other numbers
and then a &lt;code&gt;.jpg&lt;/code&gt;. Here &lt;code&gt;YYYY&lt;/code&gt; stands for the year, &lt;code&gt;MM&lt;/code&gt; for month and
so on, so that sorting the pictures in alphabetical order is the same as
sorting them by date.&lt;/p&gt;
    &lt;p&gt;Or so I thought. Strangely, when I looked at the files from my dad’s Windows PC, they were not sorted correctly: all the pictures took with my phone came first, followed by all the pictures took by him. I thought this was surely some weird Microsoft bug - after using Windows 11 at work for a while, I would not be surprised if you told me their file explorer can’t figure out how to sort strings.&lt;/p&gt;
    &lt;p&gt;But then I looked at the same files in a shared Google Drive folder, and again they were in the wrong order:&lt;/p&gt;
    &lt;p&gt;As you can see, the picture taken at 5:54 (with my dad’s phone) comes before the one taken at 9:20 (also with my dad’s phone), but after the one taken at 12:11 (with my phone).&lt;/p&gt;
    &lt;p&gt;Weird. Well, maybe Microsoft and Google got this wrong. But that seems unlikely.&lt;/p&gt;
    &lt;p&gt;Indeed, KDE’s Dolphin file manager does the same thing:&lt;/p&gt;
    &lt;p&gt;I’ll spare you the screenshots, but Gnome and both the file managers that I have on my phone also get the alphabetical order wrong.&lt;/p&gt;
    &lt;p&gt;At this point I thought that maybe one of the two phones is using some weird alternative unicode character instead of the underscore &lt;code&gt;_&lt;/code&gt;. Really,
I could not see any other explanation. But nope, this is not it, because
the good old &lt;code&gt;ls&lt;/code&gt; sorts my files correctly:&lt;/p&gt;
    &lt;code&gt;$ ls -l

total 218572
-rw-r--r-- 1 seba seba 1866185 Aug 28 18:51 IMG_20250820_055436307.jpg
-rw-r--r-- 1 seba seba 4749899 Aug 28 18:50 IMG_20250820_092016029_HDR.jpg
-rw-r--r-- 1 seba seba 6201609 Aug 28 18:52 IMG_20250820_092440966_HDR.jpg
-rw-r--r-- 1 seba seba 7694802 Aug 28 18:51 IMG_20250820_092832138_HDR.jpg
-rw-r--r-- 1 seba seba 1536520 Aug 20 09:57 IMG_20250820_095716_607.jpg
-rw-r--r-- 1 seba seba 1054553 Aug 20 10:38 IMG_20250820_103857_991.jpg
-rw-r--r-- 1 seba seba  965353 Aug 20 10:39 IMG_20250820_103903_811.jpg
(and so on)
&lt;/code&gt;
    &lt;p&gt;This was consistent among the couple of Linux distros I use, as well as my OpenBSD server. On the one hand this is good: not every single piece of software fucks up something as basic as string sorting. On the other hand, this makes it harder to debug what the fuck is going on with all the other file managers.&lt;/p&gt;
    &lt;p&gt;It took me more than a month to figure this one out. Tell me, which file do you think comes first in alphabetical order, &lt;code&gt;file-9.txt&lt;/code&gt; or
&lt;code&gt;file-10.txt&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;Of course, the user who named those files probably wants &lt;code&gt;file-9.txt&lt;/code&gt; to
come before &lt;code&gt;file-10.txt&lt;/code&gt;. But &lt;code&gt;1&lt;/code&gt; is smaller than &lt;code&gt;9&lt;/code&gt;, so &lt;code&gt;file-10.txt&lt;/code&gt;
should be first in alphabetical order. Everyone understands that, and
soon people learn to put enough leading zeros if they want their files
to stay sorted the way they like.&lt;/p&gt;
    &lt;p&gt;Well, apparently all these operating systems have decided that no, users are too dumb and they cannot possibly understand what alphabetical order means. So when you ask them to sort your files alphabetically, they don’t. Instead, they decide that if some piece of the file name is a number, the real numerical value must be used.&lt;/p&gt;
    &lt;p&gt;I don’t know when this became the norm, to be honest I have not used a normal graphical file manager in a long time.&lt;/p&gt;
    &lt;p&gt;I know you asked for the files to be sorted in alphabetical order, but you don’t want &lt;code&gt;file-10.txt&lt;/code&gt; to come before &lt;code&gt;file-9.txt&lt;/code&gt;, do
you? No, I know you don’t. I am not even going to ask you, your
mushy human brain is too small to comprehend the intricacies of
such a question. I’ll spare you the thinking.&lt;/p&gt;
    &lt;p&gt;So it turns out that my dad’s phone wrote the milliseconds in the file name right after the seconds, while mine added an extra underscore to separate them from the seconds. Which in my mind it should not have mattered, because alphabetically they should still have been sorted correctly to the second. But with this “modern” interpretation of the alphabetical order, the files without the extra separator in the name had a much higher number, so they come last.&lt;/p&gt;
    &lt;p&gt;Now that I know what the issue is, I can solve it by renaming the files with a consistent scheme. I have also found a setting to fix Dolphin’s behavior, but it was very much buried into its many configuration options. And I would rather not have to change this setting in every application I use, assuming they even allow it.&lt;/p&gt;
    &lt;p&gt;I miss the time when computers did what you told them to, instead of trying to read your mind.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sebastiano.tronto.net/blog/2025-09-28-alphabetic-order/"/><published>2025-09-28T13:00:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45404667</id><title>Show HN: Toolbrew – Free little tools without signups or ads</title><updated>2025-09-29T00:47:33.078087+00:00</updated><link href="https://toolbrew.co/"/><published>2025-09-28T14:40:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45405175</id><title>Scm2wasm: A Scheme to WASM compiler in 600 lines of C, making use of WASM GC</title><updated>2025-09-29T00:47:32.617514+00:00</updated><content>&lt;doc fingerprint="9fa21c334d8329a0"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;milo 7cbcaf8ccd&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;.gitignore&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Makefile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;README.md&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;input.scm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;scm2wasm.c&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt; README.md &lt;/head&gt;
    &lt;head rend="h1"&gt;scm2wasm&lt;/head&gt;
    &lt;p&gt;really bad minimal scheme compiler&lt;/p&gt;
    &lt;head rend="h2"&gt;building&lt;/head&gt;
    &lt;code&gt;$ make
&lt;/code&gt;
    &lt;head rend="h2"&gt;running&lt;/head&gt;
    &lt;code&gt;$ ./scm2wasm &amp;lt; input.scm &amp;gt; output.wasm
$ wasm-tools validate output.wasm
$ wasm-tools print output.wasm -o output.wat
$ wasmtime -Wgc --invoke start output.wasm
...
30
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://git.lain.faith/iitalics/scm2wasm"/><published>2025-09-28T15:43:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45405177</id><title>The AI coding trap</title><updated>2025-09-29T00:47:32.408624+00:00</updated><content>&lt;doc fingerprint="a549d23b2ab12319"&gt;
  &lt;main&gt;
    &lt;p&gt;If you ever watch someone “coding”, you might see them spending far more time staring into space than typing on their keyboard. No, they (probably) aren’t slacking off. Software development is fundamentally a practice of problem-solving, and so, as with solving a tricky crossword, most of the work is done in your head.&lt;/p&gt;
    &lt;p&gt;In the software development lifecycle, coding is the letters filled into the crossword, only a small amount of effort compared to all the head scratching and scribbled notes. The real work usually happens alongside coding, as the developer learns the domain, narrows down requirements, maps out relevant abstractions, considers side effects, tests features incrementally, and finally squashes bugs that survived this rigorous process. It looks something like this:&lt;/p&gt;
    &lt;p&gt;But with AI-driven coding, things play out very differently.&lt;/p&gt;
    &lt;head rend="h2"&gt;“Code first, ask questions later”&lt;/head&gt;
    &lt;p&gt;AI coding agents such as Claude Code are making it astonishingly fast to write code in isolation. But most software lives within complex systems, and since LLMs can't yet hold the full context of an application in memory at once, human review, testing, and integration needs will remain. And that is a lot harder when the code has been written without the human thinking about it. As a result, for complex software, much of the time will be spent on post hoc understanding of what code the AI has written.&lt;/p&gt;
    &lt;p&gt;This is the root of the difference between marketing copy that boasts of the paradigm shifting speed of writing code with AI (often framed as “10X faster”), and the marginal productivity gains in delivering working software seen in the wild (usually closer to 10%).&lt;/p&gt;
    &lt;p&gt;An even more dispiriting upshot of this is that, as developers, we spend an ever greater proportion of our time merely fixing up the output of these wondrous babbling machines. While the LLMs get to blast through all the fun, easy work at lightning speed, we are then left with all the thankless tasks: testing to ensure existing functionality isn’t broken, clearing out duplicated code, writing documentation, handling deployment and infrastructure, etc. Very little time is actually dedicated to the thing that developers actually love doing: coding.&lt;/p&gt;
    &lt;p&gt;Fortunately, help is at hand. While LLMs are shaking up how software development is performed, this issue in itself is not actually new. In fact, it is merely a stark example of an age-old problem, which I call:&lt;/p&gt;
    &lt;head rend="h2"&gt;The tech lead’s dilemma&lt;/head&gt;
    &lt;p&gt;As engineers progress in their careers, they will eventually step into the role of tech lead. They might be managing a team, or they could be a principal engineer, driving technical delivery without the people management. In either case, they are responsible for the team’s technical delivery. They are also usually the most experienced developer in the team: either in their career, in the specialised domain of the team, or in both.&lt;/p&gt;
    &lt;p&gt;Software delivery is a team effort, but one in which experience can have a highly imbalancing effect on individual contribution velocity. As such, when the tech lead’s primary job is to maximise delivery, they will often face an internal conflict between two ways to deliver software:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fair delegation across the team, maximising learning and ownership opportunities for junior team members, but allowing delivery to be bottlenecked by the speed of the least productive team members.&lt;/item&gt;
      &lt;item&gt;Mollycoddling the team, by delegating only the easy or non-critical work to juniors, and keeping the hardest work for themselves, as the person on the team most capable of delivering at speed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unfortunately, while we shall see that mollycoddling is extremely harmful to long-term team health, it is also often a very effective way to accelerate delivery. The higher bandwidth of the tech lead is often most efficiently deployed by eating up all the hardest work:&lt;/p&gt;
    &lt;p&gt;As such, I have seen this pattern repeated time and again over the course of my career. And, of course, it comes at a cost. Siloing of experience in the tech lead makes the team brittle, it makes support harder, and it places ever greater pressure on the tech lead as a single point of failure. What follows next is predictable: burnout, departure, and ensuing crisis as the team struggles to survive without the one person who really knows how everything works.&lt;/p&gt;
    &lt;p&gt;As is usually the case, the solution lies in a third way that avoids these two extremes and balances delivery with team growth. We might frame it as something like:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Implement team practices that allow engineers to deliver working code within a framework that minimises rework, maximises effective collaboration, and promotes personal growth and learning.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When I was CTO of Datasine, we enshrined this attitude in a simple tech team motto:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Learn. Deliver. Have fun.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Good tech leads expose their engineers to work at the limit of their capabilities, using processes and practices that minimise delivery risk while also enabling each team member to grow their skills, knowledge, and domain expertise. This is, in fact, the essence of good technical leadership.&lt;/p&gt;
    &lt;p&gt;There are many ways to accomplish it, from strict codified frameworks such as the Extreme Programming rules, through to looser sets of principles which we might broadly refer to as “best practices”:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Code reviews&lt;/item&gt;
      &lt;item&gt;Incremental delivery&lt;/item&gt;
      &lt;item&gt;Modular design&lt;/item&gt;
      &lt;item&gt;Test-driven development&lt;/item&gt;
      &lt;item&gt;Pair programming&lt;/item&gt;
      &lt;item&gt;Quality documentation&lt;/item&gt;
      &lt;item&gt;Continuous integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, for experienced engineers today, an urgent question is: how can we translate these practices into a world of AI-driven coding?&lt;/p&gt;
    &lt;head rend="h2"&gt;LLMs are lightning fast junior engineers&lt;/head&gt;
    &lt;p&gt;In 2025, many engineers are finding themselves for the first time in a position familiar to every tech lead: overseeing a brilliant but unpredictable junior engineer. Harnessing and controlling such talent, in a way that benefits effective team collaboration, is one of the primary challenges of engineering leadership. But AI coding agents need different management to junior engineers, because the nature of their productivity and growth is fundamentally different.&lt;/p&gt;
    &lt;p&gt;As software engineers gain experience, we tend to improve our productivity in multiple ways at the same time: writing more robust code, using better abstractions, spending less time writing and fixing bugs, understanding more complex architectures, covering edge cases more effectively, spotting repeated patterns earlier, etc. Engineering is a rich and complex discipline with many avenues for specialisation, but for simplicity we might group these dimensions into two broad themes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Quality: ability to deliver more complex, more performant, more maintainable code&lt;/item&gt;
      &lt;item&gt;Velocity: ability to develop working, bug-free code in a shorter space of time&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Over time, good engineers will improve in both axes.&lt;/p&gt;
    &lt;p&gt;Early LLMs were fast to write code, but time spent fixing bugs and removing hallucinations meant they were slow to complete bug-free code. Over time, smarter LLMs and better use of context engineering and tools have meant that modern AI coding agents are much better at “one shot” writing of code. The current generation of commercially available agents can be incredibly fast at producing working code for problems that would challenge some mid-level engineers, though they cannot yet match the expertise of senior engineers:&lt;/p&gt;
    &lt;p&gt;So we can think of the current generation of AI coding agents as junior engineers, albeit with two fundamental differences:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;LLMs deliver code much, much faster than junior engineers, constrained neither by thinking nor writing time;&lt;/item&gt;
      &lt;item&gt;LLMs have no true capacity to learn, and instead only improve through more effective context engineering or the arrival of new foundation models.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As with junior engineering talent, there are broadly two ways that you can deploy them, depending on whether your focus is long-term or short-term:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI-driven engineering: employing best practices, foregrounding human understanding of the code, moving slowly to make development sustainable.&lt;/item&gt;
      &lt;item&gt;Vibe coding: throwing caution to the wind and implementing at speed, sacrificing understanding for delivery velocity, hitting an eventual wall of unsalvageable, messy code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As might be expected, the long-term trajectories of choosing between these two approaches follow much the same pattern as choosing between parallel delegation and mollycoddling of a junior team:&lt;/p&gt;
    &lt;p&gt;This is why the vibe coding approach is great for tiny projects or throwaway prototypes: applications of sufficient simplicity can be delivered without the need for any human thinking at all. By limiting the complexity of our projects and leaning into the capabilities of the tools, we can deliver end-to-end working software in no time at all.&lt;/p&gt;
    &lt;p&gt;But you will hit a wall of complexity that AI is incapable of scaling alone.&lt;/p&gt;
    &lt;p&gt;Building prototypes is now easier than ever. But if we want to effectively use LLMs to accelerate delivery of real, complex, secure, working software, and to realise more than marginal efficiency gains, we need to write a new playbook of engineering practices tailored to maximise collaboration between engineering teams that include both humans and LLMs.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to avoid the AI coding trap&lt;/head&gt;
    &lt;p&gt;AI coding agents are dazzlingly productive, but lack in-depth knowledge of your business, codebase, or roadmap. Left unchecked, they will happily churn out thousands of lines of code with no heed paid to design, consistency, or maintainability. The job of the engineer, then, is to act as a tech lead to these hotshots: to provide the structure, standards, and processes that convert raw speed into sustainable delivery.&lt;/p&gt;
    &lt;p&gt;We need a new playbook for how to deliver working software efficiently, and we can look to the past to learn how to do that. By treating LLMs as lightning-fast junior engineers, we can lean on best practices from the software development lifecycle to build systems that scale.&lt;/p&gt;
    &lt;p&gt;Just as tech leads don't just write code but set practices for the team, engineers now need to set practices for AI agents. That means bringing AI into every stage of the lifecycle:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Specification: exploring, analysing, and refining feature specifications to cover edge cases and narrow focus.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Documentation: generating and reviewing documentation up front to provide reusable guardrails and lasting evidence.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Modular Design: scaffolding modular architectures to control context scope and maximise comprehension.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Test-Driven Development: generating extensive test cases prior to implementation to guide implementation and prevent regression.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Coding Standards: applying house styles and best practice when generating code, through context engineering.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Monitoring &amp;amp; Introspection: analysing logs and extracting insights faster than any human ever could.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;By understanding that delivering software is so much more than just writing code, we can avoid the AI coding trap and instead hugely amplify our ability to deliver working, scalable software.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chrisloy.dev/post/2025/09/28/the-ai-coding-trap"/><published>2025-09-28T15:43:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45405584</id><title>Show HN: I built an MCP server using Cloudflare's code mode pattern</title><updated>2025-09-29T00:47:31.908138+00:00</updated><content>&lt;doc fingerprint="9d08bed4f4026e9a"&gt;
  &lt;main&gt;
    &lt;p&gt;A local implementation of the "Code Mode" workflow for MCP servers. Instead of struggling with multiple tool calls, LLMs write TypeScript/JavaScript code that calls a simple HTTP proxy to access your MCP servers.&lt;/p&gt;
    &lt;p&gt;Note: It does not attempt to handle the MCP -&amp;gt; typescript API transpilation layer. Would be cool but I really wanted to test the workflow.&lt;/p&gt;
    &lt;p&gt;https://blog.cloudflare.com/code-mode/&lt;/p&gt;
    &lt;p&gt;This implements the core insight that LLMs are much better at writing code than at tool calling. Instead of exposing many tools directly to the LLM (which it struggles with), this server gives the LLM just one tool: &lt;code&gt;execute_code&lt;/code&gt;. The LLM writes code that makes HTTP requests to access your other MCP servers.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;LLM gets one tool: &lt;code&gt;execute_code&lt;/code&gt;- executes TypeScript/JavaScript&lt;/item&gt;
      &lt;item&gt;LLM writes code: Uses &lt;code&gt;fetch()&lt;/code&gt;to call&lt;code&gt;http://localhost:3001/mcp/*&lt;/code&gt;endpoints&lt;/item&gt;
      &lt;item&gt;HTTP proxy forwards: Transparently proxies requests to your actual MCP servers&lt;/item&gt;
      &lt;item&gt;Results flow back: Through the code execution to the LLM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This gives you all the benefits of complex tool orchestration, but leverages what LLMs are actually good at: writing code.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bun (latest version)&lt;/item&gt;
      &lt;item&gt;Deno (for code execution sandbox)&lt;/item&gt;
      &lt;item&gt;An MCP-compatible client (Claude Desktop, Cursor, VS Code with Copilot, etc.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Clone the repository&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/jx-codes/codemode-mcp.git
cd codemode-mcp&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install dependencies&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;bun install&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Configure the server (optional)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create a &lt;code&gt;codemode-config.json&lt;/code&gt; file to customize settings:&lt;/p&gt;
    &lt;code&gt;{
   "proxyPort": 3001,
   "configDirectories": [
      "~/.config/mcp/servers",
      "./mcp-servers",
      "./"
   ]
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up your MCP servers&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create a &lt;code&gt;.mcp.json&lt;/code&gt; file with your MCP server configurations in any of the directories you specified above:&lt;/p&gt;
    &lt;code&gt;{
   "mcpServers": {
      "fs": {
         "command": "npx",
         "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"],
         "env": {}
      }
   }
}&lt;/code&gt;
    &lt;p&gt;Instead of direct tool calling, the LLM writes:&lt;/p&gt;
    &lt;code&gt;// List available servers
const servers = await fetch("http://localhost:3001/mcp/servers").then((r) =&amp;gt;
  r.json()
);
console.log("Available servers:", servers);

// Call a tool on the filesystem server
const result = await fetch("http://localhost:3001/mcp/call", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    server: "fs",
    tool: "read_file",
    args: { path: "/tmp/example.txt" },
  }),
}).then((r) =&amp;gt; r.json());

console.log("File contents:", result);&lt;/code&gt;
    &lt;p&gt;The real power shows when chaining operations:&lt;/p&gt;
    &lt;code&gt;// Get list of files
const files = await fetch("http://localhost:3001/mcp/call", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    server: "fs",
    tool: "list_directory",
    args: { path: "/tmp" },
  }),
}).then((r) =&amp;gt; r.json());

// Process each file
for (const file of files.content[0].text.split("\n")) {
  if (file.endsWith(".txt")) {
    const content = await fetch("http://localhost:3001/mcp/call", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        server: "fs",
        tool: "read_file",
        args: { path: `/tmp/${file}` },
      }),
    }).then((r) =&amp;gt; r.json());

    console.log(`${file}: ${content.content[0].text.length} characters`);
  }
}&lt;/code&gt;
    &lt;p&gt;Executes TypeScript/JavaScript code with network access to the MCP proxy.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;code&lt;/code&gt;(string): Code to execute&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;typescript&lt;/code&gt;(boolean): TypeScript mode (default: true)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Proxy Endpoints:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;GET /mcp/servers&lt;/code&gt;- List available MCP servers&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;GET /mcp/{server}/tools&lt;/code&gt;- List tools for server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;POST /mcp/call&lt;/code&gt;- Call tool (body:&lt;code&gt;{server, tool, args}&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check Deno installation status.&lt;/p&gt;
    &lt;p&gt;Get a comprehensive overview of all available MCP servers and their tools. Returns structured JSON data optimized for LLM consumption, containing complete tool schemas and server status information.&lt;/p&gt;
    &lt;p&gt;JSON Output Structure:&lt;/p&gt;
    &lt;code&gt;{
  "summary": {
    "totalServers": 2,
    "successfulServers": 2,
    "totalTools": 4
  },
  "servers": [
    {
      "server": "filesystem",
      "status": "success",
      "toolCount": 3,
      "tools": [
        {
          "name": "read_file",
          "description": "Read contents of a file",
          "inputSchema": {
            "type": "object",
            "properties": {
              "path": {
                "type": "string",
                "description": "File path to read"
              }
            },
            "required": ["path"]
          }
        }
      ]
    },
    {
      "server": "database",
      "status": "success",
      "toolCount": 1,
      "tools": [
        {
          "name": "query",
          "description": "Execute a SQL query",
          "inputSchema": {
            "type": "object",
            "properties": {
              "query": {
                "type": "string",
                "description": "SQL query to execute"
              }
            },
            "required": ["query"]
          }
        }
      ]
    }
  ]
}&lt;/code&gt;
    &lt;p&gt;This provides complete tool discovery information including parameter schemas, types, and requirements for programmatic access.&lt;/p&gt;
    &lt;p&gt;Create &lt;code&gt;codemode-config.json&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;{
  "proxyPort": 3001,
  "configDirectories": ["~/.config/mcp/servers", "./mcp-servers", "./"]
}&lt;/code&gt;
    &lt;p&gt;Add your MCP servers to &lt;code&gt;.mcp.json&lt;/code&gt; files in those directories:&lt;/p&gt;
    &lt;code&gt;{
  "mcpServers": {
    "fs": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"],
      "env": {}
    }
  }
}&lt;/code&gt;
    &lt;p&gt;Traditional MCP: LLM → Tool Call → MCP Server → Result → LLM → Tool Call → ...&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LLMs struggle with tool syntax&lt;/item&gt;
      &lt;item&gt;Each call goes through the neural network&lt;/item&gt;
      &lt;item&gt;Hard to chain operations&lt;/item&gt;
      &lt;item&gt;Limited by training on synthetic tool examples&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Code Mode: LLM → Write Code → Code calls proxy → Proxy forwards to MCP → Results&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LLMs excel at writing code (millions of real examples in training)&lt;/item&gt;
      &lt;item&gt;Code can chain operations naturally&lt;/item&gt;
      &lt;item&gt;Results flow through code logic, not neural network&lt;/item&gt;
      &lt;item&gt;Natural composition and data processing&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Code runs in Deno sandbox with network access only&lt;/item&gt;
      &lt;item&gt;No filesystem, environment, or system access&lt;/item&gt;
      &lt;item&gt;30-second execution timeout&lt;/item&gt;
      &lt;item&gt;MCP servers accessed through controlled proxy&lt;/item&gt;
      &lt;item&gt;Temporary files auto-cleanup&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;"Deno not installed": Install Deno and restart "Permission denied": Code trying to access restricted resources "Module not found": Use &lt;code&gt;https://&lt;/code&gt; URLs for imports
"Execution timeout": Optimize code or break into smaller operations&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Provide a simpler API layer for the MCP proxy something like mcp.tool('name', args); &lt;list rend="ul"&gt;&lt;item&gt;Could easily be done by injecting our own typescript file into the Deno scope before running user code&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;More config options&lt;/item&gt;
      &lt;item&gt;Filter out the tools somehow&lt;/item&gt;
      &lt;item&gt;Test it out more in my workflows and see the results&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jx-codes/codemode-mcp"/><published>2025-09-28T16:23:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45405750</id><title>The Weird Concept of Branchless Programming</title><updated>2025-09-29T00:47:31.676064+00:00</updated><content>&lt;doc fingerprint="f7ba3738a05c1105"&gt;
  &lt;main&gt;&lt;p&gt;&lt;code&gt;2025-07-08 01:37&lt;/code&gt; â¢ 19+ min read â¢ #c #branchless&lt;/p&gt;&lt;code&gt;-O3 -ffast-math -march=native -fomit-this-entire-function&lt;/code&gt;) were taken.&lt;p&gt;Modern CPUs are predictive creatures. They guess what you're about to do, like a nosy algorithm trying to sell you sneakers after you Googled "foot pain." Branch predictors make CPUs fast by speculating on branches... until they guess wrong and everything grinds to a halt for 15,20 cycles.&lt;/p&gt;&lt;p&gt;Branchless programming is how we get around this: we rewrite our code to not branch at all. Instead of jumping to conclusions, we manipulate bits like 1980s assembly gremlins.&lt;/p&gt;&lt;p&gt;What is a branch first of all?In a program, you may observe parts like this:&lt;/p&gt;&lt;code&gt;if (condition), then
    ...
elif (condition), then
    ...
else
    ...
fi
&lt;/code&gt;&lt;p&gt;This block of instructions is a collection of three branches. Each &lt;code&gt;if&lt;/code&gt;, &lt;code&gt;elif&lt;/code&gt;, and &lt;code&gt;else&lt;/code&gt; represents a possible execution path the CPU can take depending on the evaluation of the conditions. At runtime, only one of these paths is taken, and the others are skipped. This choice ,  this deviation in the control flow ,  is what we call a branch.&lt;/p&gt;&lt;p&gt;In terms of machine code, a branch is often implemented as a jump (&lt;code&gt;jmp&lt;/code&gt;, &lt;code&gt;je&lt;/code&gt;, &lt;code&gt;jne&lt;/code&gt;, etc.). These are instructions that tell the CPU: âif this condition holds, skip to label X; otherwise, keep going.â That jump disrupts the nice linear stream of instruction execution, forcing the CPU to guess where youâre going next.&lt;/p&gt;&lt;p&gt;Hereâs a simple ASCII representation of how this decision tree looks:&lt;/p&gt;&lt;code&gt;          [Condition A]
              |
        +-----+------+
       Yes          No
       |             |
[Block A]     [Condition B]
                  |
            +-----+------+
           Yes          No
           |             |
      [Block B]      [Block C]
&lt;/code&gt;&lt;p&gt;From a CPU perspective, each conditional check and potential jump is a âfork in the road.â If your code has a predictable pattern (e.g., always taking the same branch), the CPU can guess well and maintain performance. But if it's unpredictable, say, random data or user input, then the CPU may guess wrong, flush its pipeline, and pay a heavy penalty.&lt;/p&gt;&lt;p&gt;This is why branches can be so dangerous in tight loops or performance-critical code: even one mispredicted branch can cost dozens of cycles, ruining your cache-fueled dreams.&lt;/p&gt;&lt;p&gt;Branches, when predictable, are cheap. But when unpredictable, they're evil. Imagine a tight loop that checks a condition based on data from user input, or real-world sensors, or shuffled arrays. The branch predictor stumbles, and every misstep means flushing the pipeline , a costly affair on modern superscalar out-of-order CPUs.&lt;/p&gt;&lt;p&gt;Branchless code avoids that entirely. By rewriting conditional logic into arithmetic and bit operations, or using CPU instructions like &lt;code&gt;cmov&lt;/code&gt;, we let the CPU chew through code without pausing to guess. Itâs smoother, faster, and often more deterministic, which is crucial in performance-critical or side-channel-resistant scenarios (looking at you, cryptography).&lt;/p&gt;&lt;p&gt;We're going to take you on a wild ride through three increasingly complex examples:&lt;/p&gt;&lt;code&gt;abs(x)&lt;/code&gt; ,  a gentle warm-up with unary fun&lt;code&gt;clamp(x, min, max)&lt;/code&gt; ,  a common pattern with two conditions&lt;code&gt;partition()&lt;/code&gt; ,  a full algorithm with data-dependent control flow&lt;p&gt;We'll compare these in C (our performance-hungry workhorse), we'll show you how these concepts look in both worlds, how they perform.&lt;/p&gt;&lt;p&gt;Absolute value is your first ticket to understanding how to cut down branches without cutting performance.&lt;/p&gt;&lt;p&gt;We want to calculate the absolute value of a signed integer without using a conditional branch. This is foundational â a single-bit operation can turn a branch into math.&lt;/p&gt;&lt;code&gt;int abs_branch(int x) {
    return x &amp;lt; 0 ? -x : x;
}

// Compiles to a `cmp` and a `jge` or `jl`, depending on compiler and optimization level.

int abs_branchless(int x) {
    int mask = x &amp;gt;&amp;gt; 31;
    return (x + mask) ^ mask;
}
&lt;/code&gt;&lt;code&gt;mask&lt;/code&gt; to &lt;code&gt;x&lt;/code&gt; either increments or doesn't.&lt;code&gt;mask&lt;/code&gt; flips bits only if &lt;code&gt;mask&lt;/code&gt; is -1.&lt;code&gt;int abs_alt(int x) {
    int mask = x &amp;gt;&amp;gt; 31;
    return (x ^ mask) - mask;
}
&lt;/code&gt;&lt;p&gt;Produces identical results; different taste of the same bit soup.&lt;/p&gt;&lt;code&gt;mov eax, edi       ; move x into eax
sar eax, 31        ; sign-extend right shift to produce mask
mov ecx, eax       ; duplicate mask
add edi, ecx       ; edi = x + mask
xor eax, edi       ; eax = result = (x + mask) ^ mask
&lt;/code&gt;&lt;p&gt;Fast. No jumps. Pure ALU (arithmetic logic unit).&lt;/p&gt;&lt;p&gt;The clamp is more complex. You want to bound a value between a &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt;.We want to ensure a value stays within &lt;code&gt;[min, max]&lt;/code&gt; without branches. This is key in physics simulations, rendering, and safety constraints.&lt;/p&gt;&lt;code&gt;int clamp(int x, int min, int max) {
    if (x &amp;lt; min) return min;
    if (x &amp;gt; max) return max;
    return x;
}

int clamp_branchless(int x, int min, int max) {
    int r1 = x - ((x - min) &amp;amp; ((x - min) &amp;gt;&amp;gt; 31));
    return r1 - ((r1 - max) &amp;amp; ((r1 - max) &amp;gt;&amp;gt; 31));
}
&lt;/code&gt;&lt;code&gt;(x - min) &amp;gt;&amp;gt; 31&lt;/code&gt; creates a mask that's all 1s if &lt;code&gt;x &amp;lt; min&lt;/code&gt;.&lt;code&gt;min&lt;/code&gt; when necessary.&lt;code&gt;sub eax, min
sar eax, 31       ; create mask_low
and eax, (x - min)
sub x, eax        ; x = max(x, min)

sub x, max
sar ..., 31       ; create mask_high
and ..., (x - max)
sub x, ...        ; x = min(x, max)
&lt;/code&gt;&lt;p&gt;Every operation is ALU-based. No branching, just pure logic.This removes branches by computing masks and blending values accordingly. Elegant? No. Effective? Absolutely.&lt;/p&gt;&lt;p&gt;This is where branchless logic makes the biggest splash, in algorithms that iterate over data and make conditional swaps.Partition an array around a pivot such that all elements &amp;lt; pivot come before elements &amp;gt;= pivot, without any conditional branching in the inner loop.&lt;/p&gt;&lt;code&gt;void swap(int* a, int* b) {
    int temp = *a;
    *a = *b;
    *b = temp;
}

int partition(int* arr, int low, int high) {
    int pivot = arr[high];
    int i = low;
    for (int j = low; j &amp;lt; high; j++) {
        if (arr[j] &amp;lt; pivot) {
            swap(&amp;amp;arr[i], &amp;amp;arr[j]);
            i++;
        }
    }
    swap(&amp;amp;arr[i], &amp;amp;arr[high]);
    return i;
}

int partition_branchless(int* arr, int low, int high) {
    int pivot = arr[high];
    int i = low;
    for (int j = low; j &amp;lt; high; j++) {
        swap(&amp;amp;arr[i], &amp;amp;arr[j]);
        i += arr[i] &amp;lt; pivot;
    }
    swap(&amp;amp;arr[i], &amp;amp;arr[high]);
    return i;
}
&lt;/code&gt;&lt;code&gt;i += ((arr[i] - pivot) &amp;gt;&amp;gt; 31) &amp;amp; 1;
&lt;/code&gt;&lt;p&gt;Relies on arithmetic right shift and masking to conditionally increment.&lt;/p&gt;&lt;code&gt;mov eax, [arr+i*4]
cmp eax, pivot
setl bl
add i, ebx
&lt;/code&gt;&lt;p&gt;Or:&lt;/p&gt;&lt;code&gt;cmp eax, pivot
adc i, 0
&lt;/code&gt;&lt;p&gt;Clever use of &lt;code&gt;adc&lt;/code&gt; (add with carry) after compare to branchlessly increment.&lt;/p&gt;&lt;code&gt;| Operation      | Branchy | Branchless | Speedup |
| -------------- | ------- | ---------- | ------- |
| `abs(x)`       | \~5ms   | \~5ms      | 1.00x   |
| `clamp(x,m,M)` | \~6ms   | \~6ms      | 1.00x   |
| `partition()`  | \~6ms   | \~5ms      | 1.20x   |
&lt;/code&gt;&lt;code&gt;abs()&lt;/code&gt; and &lt;code&gt;clamp()&lt;/code&gt; show negligible gains; branch prediction handles them well.&lt;code&gt;partition()&lt;/code&gt; shows improvement due to high branch unpredictability.&lt;p&gt;See appendix below for full C benchmark code, compilation flags, and timing logic.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Warning: long code ahead. Skip if you value your retina and you have a life.&lt;/p&gt;&lt;/quote&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;time.h&amp;gt;

// ABS branchy and branchless
int abs_branch(int x) {
    return x &amp;lt; 0 ? -x : x;
}

int abs_branchless(int x) {
    int mask = x &amp;gt;&amp;gt; 31;
    return (x + mask) ^ mask;
}

// CLAMP branchy and branchless
int clamp(int x, int min, int max) {
    if (x &amp;lt; min) return min;
    if (x &amp;gt; max) return max;
    return x;
}

int clamp_branchless(int x, int min, int max) {
    int r1 = x - ((x - min) &amp;amp; ((x - min) &amp;gt;&amp;gt; 31));
    return r1 - ((r1 - max) &amp;amp; ((r1 - max) &amp;gt;&amp;gt; 31));
}

// PARTITION branchy and branchless
void swap(int* a, int* b) {
    int t = *a;
    *a = *b;
    *b = t;
}

int partition(int* arr, int low, int high) {
    int pivot = arr[high];
    int i = low;
    for (int j = low; j &amp;lt; high; j++) {
        if (arr[j] &amp;lt; pivot) {
            swap(&amp;amp;arr[i], &amp;amp;arr[j]);
            i++;
        }
    }
    swap(&amp;amp;arr[i], &amp;amp;arr[high]);
    return i;
}

int partition_branchless(int* arr, int low, int high) {
    int pivot = arr[high];
    int i = low;
    for (int j = low; j &amp;lt; high; j++) {
        swap(&amp;amp;arr[i], &amp;amp;arr[j]);
        i += arr[i] &amp;lt; pivot;
    }
    swap(&amp;amp;arr[i], &amp;amp;arr[high]);
    return i;
}

// Benchmarking helpers
void benchmark_abs(int* data, int count) {
    clock_t start = clock();
    volatile long long sum = 0;
    for (int i = 0; i &amp;lt; count; ++i) sum += abs_branch(data[i]);
    printf("ABS (branch):     %.3f sec\n", (double)(clock() - start)/CLOCKS_PER_SEC);

    start = clock(); sum = 0;
    for (int i = 0; i &amp;lt; count; ++i) sum += abs_branchless(data[i]);
    printf("ABS (branchless): %.3f sec\n", (double)(clock() - start)/CLOCKS_PER_SEC);
}

void benchmark_clamp(int* data, int count) {
    clock_t start = clock();
    volatile long long sum = 0;
    for (int i = 0; i &amp;lt; count; ++i) sum += clamp(data[i], -50, 50);
    printf("CLAMP (branch):     %.3f sec\n", (double)(clock() - start)/CLOCKS_PER_SEC);

    start = clock(); sum = 0;
    for (int i = 0; i &amp;lt; count; ++i) sum += clamp_branchless(data[i], -50, 50);
    printf("CLAMP (branchless): %.3f sec\n", (double)(clock() - start)/CLOCKS_PER_SEC);
}

void benchmark_partition(int* data, int count) {
    int* copy = malloc(sizeof(int) * count);
    memcpy(copy, data, sizeof(int) * count);

    clock_t start = clock();
    partition(data, 0, count - 1);
    printf("PARTITION (branch):     %.3f sec\n", (double)(clock() - start)/CLOCKS_PER_SEC);

    memcpy(data, copy, sizeof(int) * count);
    start = clock();
    partition_branchless(data, 0, count - 1);
    printf("PARTITION (branchless): %.3f sec\n", (double)(clock() - start)/CLOCKS_PER_SEC);

    free(copy);
}

int main() {
    const int N = 10000000;
    int* data = malloc(sizeof(int) * N);

    // Populate with mixed signed integers
    for (int i = 0; i &amp;lt; N; ++i)
        data[i] = rand() - (RAND_MAX / 2);

    puts("== Benchmarking ABS ==");
    benchmark_abs(data, N);

    puts("\n== Benchmarking CLAMP ==");
    benchmark_clamp(data, N);

    puts("\n== Benchmarking PARTITION ==");
    benchmark_partition(data, 1000000); // smaller size due to O(n log n) behavior

    free(data);
    return 0;
}
&lt;/code&gt;&lt;p&gt;(If the scroll wheel starts smoking, youâve found the end.)&lt;/p&gt;&lt;p&gt;Branchless programming is a scalpel, not a sledgehammer. Used wisely, it can make your code faster, safer, and cooler. Misused, it turns your logic into incomprehensible bit spaghetti.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;"Premature optimization is the root of all evil â except when it's branchless, then it's performance art."&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sanixdk.xyz/blogs/the-weird-concept-of-branchless-programming"/><published>2025-09-28T16:40:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45405815</id><title>Testing “Exotic” P2P VPN</title><updated>2025-09-29T00:47:31.017701+00:00</updated><content>&lt;doc fingerprint="b558ca29a9201472"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Testing "exotic" p2p VPN&lt;/head&gt;
    &lt;head rend="h1"&gt;How did the moose begin&lt;/head&gt;
    &lt;p&gt;My standard "everyday" solution when it comes to connecting computers into a single network is Wireguard. &lt;lb/&gt; Wireguard is good, supports p2p, and generally has no downsides.&lt;/p&gt;
    &lt;p&gt;The downsides come from having part of my home infrastructure located in territory controlled by a country that has blocked Wireguard by signatures. &lt;lb/&gt; This is, of course, utterly disgusting, and what's even more disgusting is that these blocks have long since stopped following any kind of legislation. &lt;lb/&gt; The result is an incomprehensible black box that can do anything, behave however it wants, and nobody knows how this shaitan-machine even works anymore.&lt;/p&gt;
    &lt;p&gt;So it's time for penetration.&lt;/p&gt;
    &lt;head rend="h1"&gt;Why not obfuscation?&lt;/head&gt;
    &lt;p&gt;Actually, there are several projects that allow obfuscating Wireguard traffic and punching through firewalls. &lt;lb/&gt; udp2raw, wstunnel and others handle this excellently. &lt;lb/&gt; And Amnezia VPN has made their own fork of Wireguard, specifically for breaking through government censorship.&lt;/p&gt;
    &lt;p&gt;But the main problem with obfuscation is the reduction of effective packet MTU. Because we wrap one packet in another packet, and this overhead takes up space. &lt;lb/&gt; And that's not good.&lt;/p&gt;
    &lt;head rend="h1"&gt;What I want from a VPN&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;p2p mesh network&lt;/p&gt;&lt;lb/&gt;Wireguard is good, of course, but routing all traffic through one server has consequences.&lt;lb/&gt;The consequences usually include launching a Mars rover to switch the VPN to another server in case of IP blocking or just because the server started feeling unwell.&lt;lb/&gt;And routing traffic halfway around the planet just to get access to a machine that's within arm's reach — that's just wrong.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Open source and selfhosted&lt;/p&gt;&lt;lb/&gt;In matters like this, relying on a third-party provider is either dangerous or useless.&lt;lb/&gt;Tailscale, for example, is famous for its geographical blocks, so relying on it is pointless.&lt;lb/&gt;And since Tailscale doesn't do this on a whim (I hope), there's no guarantee that other services won't do the same.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ideologically correct VPN&lt;/p&gt;&lt;lb/&gt;This point exists here specifically for Headscale and ZeroTier.&lt;lb/&gt;Creating a crippled open-source product to advertise a commercial one is a vicious practice and I personally don't approve this.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Not Wireguard&lt;/p&gt;&lt;lb/&gt;For obvious reasons. Signature-based blocking.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Packaged in nixpkgs&lt;/p&gt;&lt;lb/&gt;This one's even more obvious. I'm not going to package a VPN into nix myself.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Test subjects&lt;/head&gt;
    &lt;head rend="h2"&gt;EasyTier&lt;/head&gt;
    &lt;p&gt;This is probably the simplest way to create a p2p network. So simple that there isn't even a module in nixpkgs to run it.&lt;/p&gt;
    &lt;p&gt;For security, there's only a password in &lt;code&gt;--network-secret&lt;/code&gt;, which is used for traffic encryption.&lt;/p&gt;
    &lt;p&gt;To work, it immediately opens TCP, UDP, WG, WS, WSS and whatever Lucifer's IT department cooked up. If one gets blocked, it'll break through via another.&lt;/p&gt;
    &lt;p&gt;Essentially all nodes in the network are identical and you can specify multiple peers for initial connection establishment. &lt;lb/&gt; You can use either public ones, which can be viewed here, or specify one of your own nodes. &lt;lb/&gt; It doesn't require any additional configuration.&lt;/p&gt;
    &lt;p&gt;By the way, it has clients for Android, Windows and Mac OS, so it's a good time to dig out those old games you didn't finish in childhood and organize LAN party with friends who aren't very tech-savvy.&lt;/p&gt;
    &lt;p&gt;The main disadvantage is that you can't bind IP addresses to specific machines.&lt;/p&gt;
    &lt;p&gt;And yes, this is a project from China, which might not appeal to some for ideological reasons, but personally I hope it was created by enthusiasts specifically for breaking through the Great Firewall of China.&lt;head&gt;Configuration example&lt;/head&gt;&lt;code&gt;{
  networking.firewall = {
    allowedTCPPorts = [ 11010 11011 11012 ];
    allowedUDPPorts = [ 11010 11011 11012 ];
  };

  environment.systemPackages = [ pkgs.easytier ];
  systemd.services."easytier" = {
    enable = true;
    script = "easytier-core -d --network-name sumeragi --network-secret changeme -p tcp://public.easytier.cn:11010 --dev-name et0 --multi-thread";
    serviceConfig = {
      Restart = "always";
      RestartMaxDelaySec = "1m";
      RestartSec = "100ms";
      RestartSteps = 9;
      User = "root";
    };
    wantedBy = [ "multi-user.target" ];
    after = [ "network.target" ];
    path = with pkgs; [
      easytier
      iproute2
      bash
    ];
  };
}
&lt;/code&gt;&lt;/p&gt;
    &lt;head rend="h2"&gt;Nebula&lt;/head&gt;
    &lt;p&gt;This is a more pompous commercial solution from the creators of Slack.&lt;/p&gt;
    &lt;p&gt;It has elliptic curve encryption, suggests using its own PKI and looks generally reliable. &lt;lb/&gt; Though the prospect of manually distributing certificates to machines doesn't thrill me.&lt;/p&gt;
    &lt;p&gt;For its operation it requires "lighthouses" that will connect all other nodes. &lt;lb/&gt; Inside, everything works on Noise Protocol. &lt;lb/&gt; On the outside it exposes only a single UDP port.&lt;/p&gt;
    &lt;p&gt;Among the nice features there's a firewall and zoning, to build slightly more complex networks than "everyone with everyone."&lt;/p&gt;
    &lt;p&gt;And also Nebula's interface is absolutely shit. &lt;lb/&gt; Instead of a normal CLI, you need to configure an internal sshd and connect via SSH to localhost. &lt;lb/&gt; Maybe it's more secure, but it's utterly disgusting.&lt;head&gt;ConfigurationExample&lt;/head&gt;&lt;code&gt;let
  isLighthouse = if (config.networking.hostName == "lighthouse") then true else false;
in
{
  services.nebula.networks.sumeragi = {
    enable = true;
    ca = "/etc/nebula/ca.crt";
    cert = "/etc/nebula/node.crt";
    key = "/etc/nebula/node.key";

    isLighthouse = isLighthouse;
    lighthouses = if (isLighthouse) then [] else [ "10.1.0.1" ];

    listen = {
      host = "0.0.0.0";
      port = 4242;
    };

    staticHostMap = {
      "10.1.0.1" = [ "266.266.266.266:4242" ];
    };

    settings = if (isLighthouse) then {
      sshd = {
        enabled = true;
        listen = "127.0.0.1:2222";
        host_key = "/etc/nebula/id_ed25519";
        authorized_users = [
          {
            user = "nommy";
            keys = [
              "ssh-ed25519 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"
            ];
          }
        ];
      };
    } else {
    };

    firewall = {
      outbound = [
        { port = "any"; proto = "any"; host = "any"; }
      ];
      inbound = [
        { port = "any"; proto = "any"; host = "any"; }
      ];
    };
  };

  networking.firewall.allowedUDPPorts = [ 4242 ];
}

&lt;/code&gt;&lt;/p&gt;
    &lt;head rend="h2"&gt;Tinc&lt;/head&gt;
    &lt;p&gt;When I found this, my first thought was "The fuck is this?" &lt;lb/&gt; The project is over 10 years old and is still in an unstable state. &lt;lb/&gt; The current version is &lt;code&gt;1.1pre18&lt;/code&gt;, released way back in 2021. &lt;lb/&gt; The last commit to the &lt;code&gt;1.1&lt;/code&gt; branch was over a year ago. &lt;lb/&gt; It's packaged in Nix as Lucy knows what. &lt;lb/&gt; How is this even a thing?&lt;/p&gt;
    &lt;p&gt;But actually, Tinc can surprise you quite a bit.&lt;/p&gt;
    &lt;p&gt;Under the hood it uses its own protocol over UDP, elliptic curves and a ton of black magic (which, by the way, is properly documented) that makes it all work.&lt;/p&gt;
    &lt;p&gt;Of course, it still needs a node for initial connection bootstrapping, but there's no special setup required — any node can do it, and afterwards it's all direct node-to-node communication.&lt;/p&gt;
    &lt;p&gt;It has a relatively normal CLI, can show a graph of the entire network, has other tasty features, but really lacks some kind of TUI, or at least ASCII art for rendering that graph. For obvious reasons, the configuration was assembled in a dendrofecal manner, I strongly advise not copying it as-is, but rewriting it yourself. Yes, interface and route configuration is done through &lt;head&gt;Example of not very good configuration&lt;/head&gt;&lt;code&gt;tinc-up&lt;/code&gt; and &lt;code&gt;tinc-down&lt;/code&gt;. &lt;lb/&gt; This is the intended way&lt;code&gt;let
  hostName = config.networking.hostName;
in
{
  networking.firewall.allowedTCPPorts = [ 655 ];
  networking.firewall.allowedUDPPorts = [ 655 ];

  services.tinc = {
    networks = {
      sumeragi = {
        name = hostName;
        ed25519PrivateKeyFile = "/etc/tinc/sumeragi/ed25519_key.priv";
        interfaceType = "tun";
        debugLevel = 3;

        hostSettings = {
          lighthouse = {
            settings.Ed25519PublicKey = "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA";
            subnets = [
              { address = "10.2.0.1/32"; }
            ];
            addresses = [
              { address = "266.266.266.266"; port = 655; }
            ];
          };
          laptop = {
            settings.Ed25519PublicKey = "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA";
            subnets = [
              { address = "10.2.0.2/32"; }
            ];
          };
          rpi = {
            settings.Ed25519PublicKey = "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA";
            subnets = [
              { address = "10.2.0.3/32"; }
            ];
          };
        };
      };
    };
  };

  environment.etc = {
    "tinc/sumeragi/tinc-up".source = pkgs.writeScript "tinc-up-sumeragi" ''
        #!${pkgs.stdenv.shell}
        ${pkgs.nettools}/bin/ifconfig $INTERFACE ${(builtins.elemAt config.services.tinc.networks.sumeragi.hostSettings."${hostName}".subnets 0).address} netmask 255.255.255.0
        /run/current-system/sw/bin/ip r add 10.2.0.0/24 dev tinc.sumeragi
    '';
    "tinc/sumeragi/tinc-down".source = pkgs.writeScript "tinc-down-sumeragi" ''
        #!${pkgs.stdenv.shell}
        ${pkgs.nettools}/bin/ifconfig $INTERFACE down
        /run/current-system/sw/bin/ip r del 10.2.0.0/24 dev tinc.sumeragi
    '';
  };
}
&lt;/code&gt;&lt;/p&gt;
    &lt;head rend="h1"&gt;Methodology of measurment&lt;/head&gt;
    &lt;p&gt;This is actually a huge topic and you could write a whole book about it, but the most important thing is — IPerf lies. &lt;lb/&gt; Different versions of IPerf show different numbers, use different measurement methodologies by default, have many tuning options that affect results, and sometimes their readings differ significantly from reality.&lt;/p&gt;
    &lt;p&gt;So along with two versions of IPerf, it's worth adding some real-world network usage cases.&lt;/p&gt;
    &lt;p&gt;Internet speeds in both directions are roughly the same for all nodes, so I'll take numbers from the first direction that comes up, since the difference will be within the margin of error.&lt;/p&gt;
    &lt;head rend="h2"&gt;Infrastructure&lt;/head&gt;
    &lt;p&gt;For realistic measurements I'll use three machines:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Home laptop (Laptop) in Spain&lt;/item&gt;
      &lt;item&gt;Intermediate server with public IP (Lighthouse) in Finland&lt;/item&gt;
      &lt;item&gt;Raspberry Pi (RPi) behind the Russian firewall&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The mesh network coordinators are hosted on Lighthouse, while speed is measured between Laptop and RPi.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ping&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;ping -c 300 10.1.0.3&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;We send ICMP packets, wait for the response to arrive, measure the time it took to get the response. &lt;lb/&gt; Here we can check latency, jittering and the number of lost packets.&lt;/p&gt;
    &lt;p&gt;Latency is the average ping response time. &lt;lb/&gt; Jittering is how much the response time "wanders" relative to the average. Measured in ms. &lt;lb/&gt; The number of lost packets is self-explanatory.&lt;/p&gt;
    &lt;p&gt;For more or less stable results, 300 packets should be enough.&lt;/p&gt;
    &lt;head rend="h2"&gt;/dev/zero through SSH&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;ssh 10.1.0.3 'dd if=/dev/zero bs=128M count=3 2&amp;gt;/dev/null' | dd of=/dev/null status=progress&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;We read three times 128 MB of zeros through SSH, then look at the reading speed. &lt;lb/&gt; Generally not a bad way to determine data transfer speed inside an SSH tunnel.&lt;/p&gt;
    &lt;p&gt;The main reason for using this test is that through some solutions SSH works so hellishly slow that more than a second can pass between pressing a key and the character appearing on screen, which is completely unacceptable. &lt;lb/&gt; And sometimes it doesn't work at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wget&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;wget 10.1.0.3:5201/testfile&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;As a test file — the same 384 MB of zeros from /dev/null.&lt;/p&gt;
    &lt;p&gt;As a server I use simple-http-server, setting the number of threads equal to the number of CPU cores (8). &lt;lb/&gt; Of course, with compression disabled, otherwise megabytes of zeros risk turning into kilobytes of headers.&lt;/p&gt;
    &lt;head rend="h1"&gt;iperf2 and iperf3&lt;/head&gt;
    &lt;p&gt;Yes, they show orange prices in Africa. Hell knows how to tune this. &lt;lb/&gt; So we just run them with standard configuration and then normalize the results from megabits to megabytes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reference values&lt;/head&gt;
    &lt;p&gt;Measuring exact values for speed, ping and all this stuff that we could use as a baseline is somewhat impossible, since both machines are behind NAT. &lt;lb/&gt; But since the infrastructure includes a Lighthouse with a public IP, we can run a few tests and fantasize about some results.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;ICMP packet loss&lt;/cell&gt;
        &lt;cell role="head"&gt;ICMP Latency&lt;/cell&gt;
        &lt;cell role="head"&gt;ICMP Jittering&lt;/cell&gt;
        &lt;cell role="head"&gt;/dev/zero through SSH&lt;/cell&gt;
        &lt;cell role="head"&gt;Wget&lt;/cell&gt;
        &lt;cell role="head"&gt;iperf2&lt;/cell&gt;
        &lt;cell role="head"&gt;iperf3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Laptop -&amp;gt; Lighthouse&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;71.879 ms&lt;/cell&gt;
        &lt;cell&gt;1.422 ms&lt;/cell&gt;
        &lt;cell&gt;25.5 MB/s&lt;/cell&gt;
        &lt;cell&gt;23.3 MB/s&lt;/cell&gt;
        &lt;cell&gt;18 MB/s&lt;/cell&gt;
        &lt;cell&gt;24.375 MB/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;RPi -&amp;gt; Lighthouse&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;51.872 ms&lt;/cell&gt;
        &lt;cell&gt;1.011 ms&lt;/cell&gt;
        &lt;cell&gt;9.0 MB/s&lt;/cell&gt;
        &lt;cell&gt;Timeout&lt;/cell&gt;
        &lt;cell&gt;9.963 MB/s&lt;/cell&gt;
        &lt;cell&gt;11.112 MB/s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Now we can start fantasizing.&lt;/p&gt;
    &lt;p&gt;Speed between nodes is limited by the slowest link, so we use the minimum values as our reference.&lt;lb/&gt; Latencies can simply be added together. But what to do with jittering isn't entirely clear. &lt;lb/&gt; Supposedly you can't add such values, &lt;lb/&gt; I don't want to recalculate every packet manually, so I'll just take the maximum value.&lt;/p&gt;
    &lt;p&gt;And it's time for the final results.&lt;/p&gt;
    &lt;head rend="h1"&gt;Results&lt;/head&gt;
    &lt;p&gt;All speeds are normalized in bytes. To convert to bits, multiply by 8.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="8"&gt;
        &lt;cell role="head"&gt;ICMP packet loss&lt;/cell&gt;
        &lt;cell role="head"&gt;ICMP Latency&lt;/cell&gt;
        &lt;cell role="head"&gt;ICMP Jittering&lt;/cell&gt;
        &lt;cell role="head"&gt;/dev/zero through SSH&lt;/cell&gt;
        &lt;cell role="head"&gt;Wget&lt;/cell&gt;
        &lt;cell role="head"&gt;iperf2&lt;/cell&gt;
        &lt;cell role="head"&gt;iperf3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Reference&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;123.751 ms&lt;/cell&gt;
        &lt;cell&gt;1.422 ms&lt;/cell&gt;
        &lt;cell&gt;9.0 MB/s&lt;/cell&gt;
        &lt;cell&gt;Timeout&lt;/cell&gt;
        &lt;cell&gt;9.963 MB/s&lt;/cell&gt;
        &lt;cell&gt;11.112 MB/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Wireguard + udp2raw&lt;/cell&gt;
        &lt;cell&gt;49.6%&lt;/cell&gt;
        &lt;cell&gt;108.806 ms&lt;/cell&gt;
        &lt;cell&gt;3.724 ms&lt;/cell&gt;
        &lt;cell&gt;Timeout&lt;/cell&gt;
        &lt;cell&gt;Timeout&lt;/cell&gt;
        &lt;cell&gt;3.175 KB/s&lt;/cell&gt;
        &lt;cell&gt;0.00 B/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;EasyTier&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;153.163 ms&lt;/cell&gt;
        &lt;cell&gt;36.290 ms&lt;/cell&gt;
        &lt;cell&gt;2.7 MB/s&lt;/cell&gt;
        &lt;cell&gt;8.09 MB/s&lt;/cell&gt;
        &lt;cell&gt;6.15 KB/s&lt;/cell&gt;
        &lt;cell&gt;0.00 B/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="8"&gt;
        &lt;cell&gt;Nebula&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;122.173 ms&lt;/cell&gt;
        &lt;cell&gt;15.054 ms&lt;/cell&gt;
        &lt;cell&gt;2.7 MB/s&lt;/cell&gt;
        &lt;cell&gt;3.40 MB/s&lt;/cell&gt;
        &lt;cell&gt;5.975 KB/s&lt;/cell&gt;
        &lt;cell&gt;0.00 B/s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Tinc&lt;/cell&gt;
        &lt;cell&gt;2.3%&lt;/cell&gt;
        &lt;cell&gt;115.065 ms&lt;/cell&gt;
        &lt;cell&gt;3.393 ms&lt;/cell&gt;
        &lt;cell&gt;14.7 MB/s&lt;/cell&gt;
        &lt;cell&gt;5.16 MB/s&lt;/cell&gt;
        &lt;cell&gt;6.488 MB/s&lt;/cell&gt;
        &lt;cell&gt;4.175 MB/s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Egyptian power of those iperfs...&lt;/p&gt;
    &lt;p&gt;Tinc, as I already said, is very capable of surprising.&lt;/p&gt;
    &lt;p&gt;EasyTier can be forgiven for such overheads, it's ad-hoc after all and generally "be thankful there's any connection at all."&lt;/p&gt;
    &lt;p&gt;But Nebula frankly disappointed me. Here I really want to crack a joke about the Slack client on Electron, but... I expected better, seriously.&lt;/p&gt;
    &lt;p&gt;So if you want to get something like this — Tinc is the best choice performance-wise. &lt;lb/&gt; I'll keep all of them at once for myself. &lt;lb/&gt; I don't like launching Mars rovers unnecessarily.&lt;/p&gt;
    &lt;p&gt;That's all, folks.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; And it all started when mom asked me to fix the robot vacuum...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.nommy.moe/blog/exotic-mesh-vpn/"/><published>2025-09-28T16:47:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45406109</id><title>Bayesian Data Analysis, Third edition (2013) [pdf]</title><updated>2025-09-29T00:47:30.801488+00:00</updated><content/><link href="https://sites.stat.columbia.edu/gelman/book/BDA3.pdf"/><published>2025-09-28T17:23:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45406442</id><title>UK Petition: Do not introduce Digital ID cards</title><updated>2025-09-29T00:47:30.389050+00:00</updated><content>&lt;doc fingerprint="89cb2d25e1ee6ba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Petition Do not introduce Digital ID cards&lt;/head&gt;
    &lt;p&gt;We demand that the UK Government immediately commits to not introducing a digital ID cards. There are reports that this is being looked at.&lt;/p&gt;
    &lt;head&gt;More details&lt;/head&gt;
    &lt;p&gt;We think this would be a step towards mass surveillance and digital control, and that no one should be forced to register with a state-controlled ID system. We oppose the creation of any national ID system. &lt;lb/&gt;ID cards were scrapped in 2010, in our view for good reason.&lt;/p&gt;
    &lt;p&gt;2,385,553 signatures&lt;/p&gt;
    &lt;p&gt;Show on a map the geographical breakdown of signatures by constituency&lt;/p&gt;
    &lt;p&gt;100,000 signatures required to be considered for a debate in Parliament&lt;/p&gt;
    &lt;head rend="h2"&gt;Parliament will consider this for a debate&lt;/head&gt;
    &lt;p&gt;Parliament considers all petitions that get more than 100,000 signatures for a debate&lt;/p&gt;
    &lt;p&gt;Waiting for 7 days for a debate date&lt;/p&gt;
    &lt;head rend="h2"&gt;Government will respond&lt;/head&gt;
    &lt;p&gt;Government responds to all petitions that get more than 10,000 signatures&lt;/p&gt;
    &lt;p&gt;Waiting for 26 days for a government response&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://petition.parliament.uk/petitions/730194"/><published>2025-09-28T18:01:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45406573</id><title>VMScape and why Xen dodged it</title><updated>2025-09-29T00:47:29.736620+00:00</updated><content>&lt;doc fingerprint="b4e311dca163e6c1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;VMScape and why Xen dodged it&lt;/head&gt;
    &lt;p&gt;It’s been less than two weeks since the security team at ETH Zürich published their research on a new microarchitectural attack they call VMScape:&lt;/p&gt;
    &lt;p&gt;It’s a neat piece of work, and it shows once again how CPUs, with all their clever tricks for performance, can sometimes open the door to data leaks across virtual machines.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is VMScape?&lt;/head&gt;
    &lt;p&gt;The short version: modern CPUs use a branch predictor to guess where code will go next. It makes things faster, but the predictor also “remembers” past patterns. If you can manipulate that memory, you can mislead the CPU and peek at things you shouldn’t. That’s the basic idea behind Spectre-style attacks.&lt;/p&gt;
    &lt;p&gt;According to the ETH team:&lt;/p&gt;
    &lt;quote&gt;“We find that branch predictor state is not fully flushed across VMs, enabling cross-VM Branch Target Injection (vBTI) primitives. We demonstrate the practical impact of vBTI with VMScape, a cross-VM attack capable of leaking QEMU userspace secrets from a malicious guest VM on AMD Zen 4 and Zen 5 CPUs.”&lt;/quote&gt;
    &lt;p&gt;In other words, a malicious VM can target the hypervisor’s userspace components and start leaking data. For KVM, that means QEMU, which is heavily exposed. VMware is in the same situation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Xen wasn’t affected&lt;/head&gt;
    &lt;p&gt;The researchers also note that Xen is not vulnerable. That’s not because Xen has no bugs (it does, like every hypervisor), but because of its architecture.&lt;/p&gt;
    &lt;p&gt;From day one, Xen was designed to keep the hypervisor core small and move everything else out. Device emulation, storage drivers, network stacks — they all live in Dom0, which is itself just another virtual machine. Dom0 has more privileges than a normal guest, but it’s still not the hypervisor.&lt;/p&gt;
    &lt;p&gt;That architectural choice makes Xen closer to a microkernel than a traditional monolithic hypervisor. The core stays minimal, with a narrow set of responsibilities, and anything that doesn’t absolutely need to run at the highest privilege level gets pushed out. That’s not just elegant — it’s a big deal for security.&lt;/p&gt;
    &lt;head rend="h2"&gt;Size matters (in a good way)&lt;/head&gt;
    &lt;p&gt;Because the hypervisor itself is small, it’s easier to audit, reason about, and even certify. That’s why you’ll find Xen at the heart of a lot of embedded and safety-critical projects, where formal verification and certification are required. Try doing that with a massive, monolithic kernel and you’ll quickly run into a wall. With Xen, it’s actually feasible (and being done as we speak).&lt;/p&gt;
    &lt;p&gt;VMScape highlights the benefits of that design: QEMU is simply not sitting next to the hypervisor. Even if you leak information from it, you’re still only talking about a process in Dom0, not the privileged heart of the system.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why this matters&lt;/head&gt;
    &lt;p&gt;Architectural choices made twenty years ago are paying off today. By separating responsibilities, Xen reduced its attack surface and avoided a whole class of problems. That doesn’t make it invincible (Xen has had and will have its share of vulnerabilities) but it does mean that by design, certain attacks don’t land as hard.&lt;/p&gt;
    &lt;p&gt;As the ETH Zürich team points out, mitigations for KVM involve adding new predictor flushes, which Linux developers have already started to implement. VMware will need similar patches. Xen doesn’t need those same emergency measures, because the architecture already put a buffer in place.&lt;/p&gt;
    &lt;head rend="h2"&gt;Defense in depth&lt;/head&gt;
    &lt;p&gt;It’s tempting to say “Xen wins” and stop there. But that’s not the whole story. Security is never just about one design decision. CPUs will keep evolving, new side channels will keep appearing, and no hypervisor can afford to be complacent.&lt;/p&gt;
    &lt;p&gt;Still, VMScape is a good reminder that defense in depth starts at the architecture level. A small, microkernel-like core, privilege separation, isolation of device emulation — all of that adds resilience. It won’t stop every possible attack, but it does add another layer of safety, and in security, layers are what make the difference.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://virtualize.sh/blog/vmscape-and-why-xen-dodged-it/"/><published>2025-09-28T18:19:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45406911</id><title>The QMA Singularity</title><updated>2025-09-29T00:47:29.598608+00:00</updated><content>&lt;doc fingerprint="310f29fe25a40c80"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The QMA Singularity&lt;/head&gt;
    &lt;p&gt;A couple days ago, Freek Witteveen of CWI and I posted a paper to the arXiv called “Limits to black-box amplification in QMA.” Let me share the abstract:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We study the limitations of black-box amplification in the quantum complexity class QMA. Amplification is known to boost any inverse-polynomial gap between completeness and soundness to exponentially small error, and a recent result (Jeffery and Witteveen, 2025) shows that completeness can in fact be amplified to be doubly exponentially close to 1. We prove that this is optimal for black-box procedures: we provide a quantum oracle relative to which no QMA verification procedure using polynomial resources can achieve completeness closer to 1 than doubly exponential, or a soundness which is super-exponentially small. This is proven by using techniques from complex approximation theory, to make the oracle separation from (Aaronson, 2008), between QMA and QMA with perfect completeness, quantitative.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;You can also check out my PowerPoint slides here.&lt;/p&gt;
    &lt;p&gt;To explain the context: QMA, or Quantum Merlin Arthur, is the canonical quantum version of NP. It’s the class of all decision problems for which, if the answer is “yes,” then Merlin can send Arthur a quantum witness state that causes him to accept with probability at least 2/3 (after a polynomial-time quantum computation), while if the answer is “no,” then regardless of what witness Merlin sends, Arthur accepts with probability at most 1/3. Here, as usual in complexity theory, the constants 2/3 and 1/3 are just conventions, which can be replaced (for example) by 1-2-n and 2-n using amplification.&lt;/p&gt;
    &lt;p&gt;A longstanding open problem about QMA—not the biggest problem, but arguably the most annoying—has been whether the 2/3 can be replaced by 1, as it can be for classical MA for example. In other words, does QMA = QMA1, where QMA1 is the subclass of QMA that admits protocols with “perfect completeness”? In 2008, I used real analysis to show that there’s a quantum oracle relative to which QMA ≠ QMA1, which means that any proof of QMA = QMA1 would need to use “quantumly nonrelativizing techniques” (not at all an insuperable barrier, but at least we learned something about why the problem is nontrivial).&lt;/p&gt;
    &lt;p&gt;Then came a bombshell: in June, Freek Witteveen and longtime friend-of-the-blog Stacey Jeffery released a paper showing that any QMA protocol can be amplified, in a black-box manner, to have completeness error that’s doubly exponentially small, 1/exp(exp(n)). They did this via a method I never would’ve thought of, wherein a probability of acceptance is encoded via the amplitudes of a quantum state that decrease in a geometric series. QMA, it turned out, was an old friend that still had surprises up its sleeve after a quarter-century.&lt;/p&gt;
    &lt;p&gt;In August, we had Freek speak about this breakthrough by Zoom in our quantum group meeting at UT Austin. Later that day, I asked Freek whether their new protocol was the best you could hope to do with black-box techniques, or whether for example one could amplify the completeness error to be triply exponentially small, 1/exp(exp(exp(n))). About a week later, Freek and I had a full proof written down that, using black-box techniques, doubly-exponentially small completeness error is the best you can do. In other words: we showed that, when one makes my 2008 QMA ≠ QMA1 quantum oracle separation quantitative, one gets a lower bound that precisely matches Freek and Stacey’s protocol.&lt;/p&gt;
    &lt;p&gt;All this will, I hope, interest and excite aficianados of quantum complexity classes, while others might have very little reason to care.&lt;/p&gt;
    &lt;p&gt;But here’s a reason why other people might care. This is the first paper I’ve ever put out for which a key technical step in the proof of the main result came from AI—specifically, from GPT5-Thinking. Here was the situation: we had an N×N Hermitian matrix E(θ) (where, say, N=2n), each of whose entries was a poly(n)-degree trigonometric polynomial in a real parameter θ. We needed to study the largest eigenvalue of E(θ), as θ varied from 0 to 1, to show that this λmax(E(θ)) couldn’t start out close to 0 but then spend a long time “hanging out” ridiculously close to 1, like 1/exp(exp(exp(n))) close for example.&lt;/p&gt;
    &lt;p&gt;Given a week or two to try out ideas and search the literature, I’m pretty sure that Freek and I could’ve solved this problem ourselves. Instead, though, I simply asked GPT5-Thinking. After five minutes, it gave me something confident, plausible-looking, and (I could tell) wrong. But rather than laughing at the silly AI like a skeptic might do, I told GPT5 how I knew it was wrong. It thought some more, apologized, and tried again, and gave me something better. So it went for a few iterations, much like interacting with a grad student or colleague. Within a half hour, it had suggested to look at the function&lt;/p&gt;
    &lt;p&gt;$$ Tr[(I-E(\theta))^{-1}] = \sum_{i=1}^N \frac{1}{1-\lambda_i(\theta)}. $$&lt;/p&gt;
    &lt;p&gt;It pointed out, correctly, that this was a rational function in θ of controllable degree, that happened to encode the relevant information about how close the largest eigenvalue λmax(E(θ)) is to 1. And this … worked, as we could easily check ourselves with no AI assistance. And I mean, maybe GPT5 had seen this or a similar construction somewhere in its training data. But there’s not the slightest doubt that, if a student had given it to me, I would’ve called it clever. Obvious with hindsight, but many such ideas are.&lt;/p&gt;
    &lt;p&gt;I had tried similar problems a year ago, with the then-new GPT reasoning models, but I didn’t get results that were nearly as good. Now, in September 2025, I’m here to tell you that AI has finally come for what my experience tells me is the most quintessentially human of all human intellectual activities: namely, proving oracle separations between quantum complexity classes. Right now, it almost certainly can’t write the whole research paper (at least if you want it to be correct and good), but it can help you get unstuck if you otherwise know what you’re doing, which you might call a sweet spot. Who knows how long this state of affairs will last? I guess I should be grateful that I have tenure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scottaaronson.blog/?p=9183"/><published>2025-09-28T19:00:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45407505</id><title>C-sigma: Easy-to-use Sigma proofs in C using libsodium</title><updated>2025-09-29T00:47:29.046306+00:00</updated><content>&lt;doc fingerprint="ea573654a98da7d8"&gt;
  &lt;main&gt;
    &lt;p&gt;A clean, simple C implementation of Sigma protocols with Fiat-Shamir transformation for non-interactive zero-knowledge proofs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Schnorr Protocol: Prove knowledge of discrete logarithm&lt;/item&gt;
      &lt;item&gt;Chaum-Pedersen Protocol: Prove discrete logarithm equality (DLEQ)&lt;/item&gt;
      &lt;item&gt;Non-interactive proofs: Using Fiat-Shamir transformation with SHAKE128&lt;/item&gt;
      &lt;item&gt;Minimal API: Just 6 functions for complete functionality&lt;/item&gt;
      &lt;item&gt;No abstractions: Direct use of byte arrays, no wrapper types&lt;/item&gt;
      &lt;item&gt;Secure: Built on libsodium's Ristretto255 group operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;#include "sigma.h"

// Initialize
sigma_init();

// Prove knowledge of private key
uint8_t private_key[32], public_key[32], proof[64];
crypto_core_ristretto255_scalar_random(private_key);
crypto_scalarmult_ristretto255_base(public_key, private_key);

schnorr_prove(proof, private_key, public_key, message, message_len);
bool valid = schnorr_verify(proof, public_key, message, message_len);&lt;/code&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;C compiler (clang or gcc)&lt;/item&gt;
      &lt;item&gt;libsodium development libraries&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Install libsodium (Ubuntu/Debian)
sudo apt-get install libsodium-dev

# Install libsodium (macOS)
brew install libsodium

# Build
make

# Run tests
./test

# Run examples
./example&lt;/code&gt;
    &lt;code&gt;int sigma_init(void);&lt;/code&gt;
    &lt;p&gt;Initialize the library (wraps sodium_init).&lt;/p&gt;
    &lt;p&gt;Proves knowledge of x where Y = x*G (G is the generator).&lt;/p&gt;
    &lt;code&gt;// Create proof
int schnorr_prove(
    uint8_t proof[64],                  // Output: 64-byte proof
    const uint8_t witness[32],          // Secret x
    const uint8_t public_key[32],       // Public Y = x*G
    const uint8_t *message,              // Message to bind
    size_t message_len
);

// Verify proof
bool schnorr_verify(
    const uint8_t proof[64],
    const uint8_t public_key[32],
    const uint8_t *message,
    size_t message_len
);&lt;/code&gt;
    &lt;p&gt;Proves that log_g1(h1) = log_g2(h2) without revealing the exponent.&lt;/p&gt;
    &lt;code&gt;// Create proof
int chaum_pedersen_prove(
    uint8_t proof[96],                  // Output: 96-byte proof
    const uint8_t witness[32],          // Secret x where h1=g1^x, h2=g2^x
    const uint8_t g1[32], const uint8_t h1[32],
    const uint8_t g2[32], const uint8_t h2[32],
    const uint8_t *message,
    size_t message_len
);

// Verify proof
bool chaum_pedersen_verify(
    const uint8_t proof[96],
    const uint8_t g1[32], const uint8_t h1[32],
    const uint8_t g2[32], const uint8_t h2[32],
    const uint8_t *message,
    size_t message_len
);&lt;/code&gt;
    &lt;p&gt;What it proves: Knowledge of a secret value (discrete logarithm) without revealing it.&lt;/p&gt;
    &lt;p&gt;Mathematical property: Proves "I know x such that Y = x*G" where G is the generator and Y is public.&lt;/p&gt;
    &lt;p&gt;Use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Digital signatures: Prove you own the private key corresponding to a public key&lt;/item&gt;
      &lt;item&gt;Authentication: Log in to a service without transmitting your password&lt;/item&gt;
      &lt;item&gt;Cryptocurrency wallets: Prove ownership of funds without revealing private keys&lt;/item&gt;
      &lt;item&gt;Access control: Demonstrate you have credentials without exposing them&lt;/item&gt;
      &lt;item&gt;Password-authenticated key exchange (PAKE): Establish secure channels based on passwords&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example scenario: Alice wants to prove she owns a Bitcoin address. She uses Schnorr to prove she knows the private key corresponding to the public address, without revealing the private key itself.&lt;/p&gt;
    &lt;p&gt;What it proves: Two discrete logarithms are equal, without revealing the common exponent.&lt;/p&gt;
    &lt;p&gt;Mathematical property: Proves "log_g1(h1) = log_g2(h2)" or equivalently "h1 = g1^x AND h2 = g2^x" for some secret x.&lt;/p&gt;
    &lt;p&gt;Use cases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verifiable encryption: Prove a ciphertext encrypts a specific value without decryption&lt;/item&gt;
      &lt;item&gt;Anonymous credentials: Show two credentials belong to the same user without revealing identity&lt;/item&gt;
      &lt;item&gt;Mix networks: Prove correct re-encryption in privacy protocols&lt;/item&gt;
      &lt;item&gt;Cross-chain atomic swaps: Prove same secret is used in multiple transactions&lt;/item&gt;
      &lt;item&gt;Verifiable shuffles: Prove a list was correctly permuted without revealing the permutation&lt;/item&gt;
      &lt;item&gt;Blind signatures: Prove consistency between blinded and unblinded values&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example scenario: A voting system needs to prove that an encrypted vote was correctly re-encrypted (same vote, different randomness) during the mixing phase, without revealing the actual vote.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Aspect&lt;/cell&gt;
        &lt;cell role="head"&gt;Schnorr&lt;/cell&gt;
        &lt;cell role="head"&gt;Chaum-Pedersen&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Proof size&lt;/cell&gt;
        &lt;cell&gt;64 bytes&lt;/cell&gt;
        &lt;cell&gt;96 bytes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;What's proven&lt;/cell&gt;
        &lt;cell&gt;Knowledge of one secret&lt;/cell&gt;
        &lt;cell&gt;Equality of two discrete logs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Complexity&lt;/cell&gt;
        &lt;cell&gt;Simpler&lt;/cell&gt;
        &lt;cell&gt;More complex&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Computation&lt;/cell&gt;
        &lt;cell&gt;2 exponentiations to verify&lt;/cell&gt;
        &lt;cell&gt;4 exponentiations to verify&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Primary use&lt;/cell&gt;
        &lt;cell&gt;Authentication, signatures&lt;/cell&gt;
        &lt;cell&gt;Verifiable encryption, DLEQ proofs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Elliptic Curve Group: Ristretto255 (via libsodium)&lt;/item&gt;
      &lt;item&gt;Hash Function: SHAKE128 for Fiat-Shamir challenges&lt;/item&gt;
      &lt;item&gt;Proof Sizes: Fixed - 64 bytes (Schnorr), 96 bytes (Chaum-Pedersen)&lt;/item&gt;
      &lt;item&gt;Security: 128-bit security level&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jedisct1/c-sigma"/><published>2025-09-28T20:07:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45407951</id><title>Roe (YC W24) Is Hiring</title><updated>2025-09-29T00:47:28.054216+00:00</updated><content>&lt;doc fingerprint="272cfbb0f5843336"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;ROE is building AI Agents for risk and compliance. We are trusted by companies like eBay, Affirm and Tier 1 banks.&lt;/p&gt;
      &lt;p&gt;Hiring ambitious, talented founding engineers. Base $150K-250K, 0.75-2% options.&lt;/p&gt;
      &lt;p&gt;San Mateo office, 3 days hybrid working mode. Free lunch.&lt;/p&gt;
      &lt;p&gt;We sponsor H1B / PERM.&lt;/p&gt;
      &lt;p&gt;Link to apply https://www.ycombinator.com/companies/roe/jobs/OFFxite-found...&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45407951"/><published>2025-09-28T21:00:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45408021</id><title>Play snake in the URL address bar</title><updated>2025-09-29T00:47:27.495532+00:00</updated><content>&lt;doc fingerprint="5cfba17d98173e2c"&gt;
  &lt;main&gt;
    &lt;p&gt;⚠ Sorry, this game requires JavaScript. URL: ? Use the arrow keys or WASD to control the snake on the URL. Use the arrows to control the snake on the URL. Click here if you can't see the page URL or if it looks messed up with . 〈 ! Your highest score is points! Share 〈 ▲︎ ◀︎ ▼︎ ▶︎&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://demian.ferrei.ro/snake/"/><published>2025-09-28T21:08:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45408229</id><title>Farewell friends</title><updated>2025-09-29T00:47:26.893025+00:00</updated><content>&lt;doc fingerprint="7e10d11d8ab6920a"&gt;
  &lt;main&gt;
    &lt;p&gt;Go to main Forum page »&lt;/p&gt;
    &lt;p&gt;If this post is appearing, it means I’ve succumbed to cancer or one of its side effects. Please don’t feel sad for me. I’ve had a life filled with love, great experiences and wonderful career opportunities. Despite my demise at a relatively young age, I consider myself beyond fortunate.&lt;/p&gt;
    &lt;p&gt;I’m hoping that, under the tree in front of our little Philadelphia rowhome, my wife Elaine will place a stone tablet inscribed with my name, and the year I was born and died. Underneath, I’d like the tablet to read:&lt;/p&gt;
    &lt;p&gt;Family • Readers • Words&lt;/p&gt;
    &lt;p&gt;(Note to Elaine: If you ever move, feel free to take the tablet with you.)&lt;/p&gt;
    &lt;p&gt;Family is everybody who’s brought love into my life: Elaine, my two children, my larger family, my close friends. Meanwhile, readers have been those I’ve served, and who rewarded that service with so much loyalty and affection. Finally, words have been my playground, taking the insights I’ve garnered and trying to make them understandable to others. Beside the tree are two metal chairs. I hope family and passersby will occasionally stop by, and fill me in on what I’ve been missing.&lt;/p&gt;
    &lt;p&gt;I’ve asked Elaine to arrange a memorial service at St Peter’s Church in Philadelphia’s Old City. She’ll post the time and date to the Forum when the details have been worked out.&lt;/p&gt;
    &lt;p&gt;Regular readers will know much of my life’s story. But I figure it’s appropriate to offer a not-so-brief recap.&lt;/p&gt;
    &lt;p&gt;I was born at 14 St Margarets Drive in Twickenham, London, on Jan. 2, 1963. At that time in the UK, it was standard practice for mothers to give birth in the hospital if it was their first child—or, in my mother’s case, her first two children. My older brothers, who are identical twins, had been born two years earlier. Because that first delivery went smoothly, my birth would be at home. From what I gather, the midwife took cigarette and scotch breaks with my father during lulls in the action. I was born at 6 a.m., thus establishing a lifetime habit of starting early.&lt;/p&gt;
    &lt;p&gt;In 1966, my father left financial journalism for a job at the World Bank, and we moved from London to Washington, DC. Two years later, my younger sister was born. In late 1972, my father was posted to the World Bank’s Bangladesh office for four years, and I was dispatched to boarding school in England, joining my two brothers.&lt;/p&gt;
    &lt;p&gt;After the comforts of a U.S. suburban childhood, it was a brutal change—cold dormitories, disgusting food, endless bullying—and I carried the scars for the rest of my life. But there was a silver lining: After nine years of boarding school, I squeaked into Cambridge University, where I spent much of my three years writing for and editing the student newspaper.&lt;/p&gt;
    &lt;p&gt;When I graduated Cambridge in 1985, the UK economy was in rough shape and landing a job was difficult. I ended up working for Euromoney magazine in London. Initially, all went well. But then there was a change in editor and, for reasons I never understood, the new editor took an instant dislike to me and made it clear he wanted me gone. But by then, I’d already decided to leave London and return to the U.S.&lt;/p&gt;
    &lt;p&gt;My then-fiancee and I flew to New York in August 1986. After a desperate scramble, I landed a job as a reporter—read “fact checker”—at Forbes magazine. The pay was miserable, but I couldn’t have been more grateful for that first paycheck. By then, all I had to my name was credit card debt.&lt;/p&gt;
    &lt;p&gt;Molly and I were married the following June, and Hannah arrived 15 months later. Her younger brother, Henry, would follow in 1992.&lt;/p&gt;
    &lt;p&gt;After 23 months as a fact checker, I was promoted to staff writer at Forbes, covering mutual funds. The Wall Street Journal, which was also in need of a funds reporter, came calling 16 months later. I’d always thought I’d never be a real journalist until I worked for a daily newspaper, and yet initially I said no.&lt;/p&gt;
    &lt;p&gt;At the time, I was in the midst of six months as a single parent, looking after Hannah on my own while Molly was in Syria, Greece and Turkey conducting research for her PhD. Still, the Journal wasn’t deterred, saying it would make allowances during my initial months.&lt;/p&gt;
    &lt;p&gt;In the early 1990s, the Journal was very different from the newspaper it is today. No photos, just the dot drawings for which the paper was renowned. While strong opinions could be found on the editorial page, they were to be avoided in the news pages. The sort of advice journalism I favored was frowned upon by some among the paper’s senior ranks.&lt;/p&gt;
    &lt;p&gt;Still, in 1994, Managing Editor Paul Steiger said he’d consider a few columnists for the Journal’s news pages. At age 31, and with some trepidation, I put up my hand. Thus was born the Getting Going column, which I wrote for the next 13-plus years, penning 1,009 columns for both The Wall Street Journal and Wall Street Journal Sunday. The latter were branded pages that appeared in some 70 newspapers around the country.&lt;/p&gt;
    &lt;p&gt;In retrospect, it’s astonishing that I was given my own column at such a young age. It took me a few months to hit my stride, but I was soon pounding away at the virtues of index funds, while also exploring new topics, often scouring academic research for insights I could share with readers.&lt;/p&gt;
    &lt;p&gt;The decade and a half that followed are something of a blur. I was cranking out columns, commuting into New York City from the New Jersey suburbs, and raising two children. In my memory, the years have the monotony of a hamster wheel. But that wasn’t the reality: There were high points and low points, plus the joy of watching Hannah and Henry grow up. The low points included the World Trade Center attack, my father’s death and a libel suit brought against the Journal. I’d been involved in editing the story that triggered the lawsuit.&lt;/p&gt;
    &lt;p&gt;In early 1995, while in Pittsburgh, I went on a nine-mile run with my brother-in-law, who was training for the city’s marathon. I’d long viewed running those 26.2 miles as a heroic endeavor. I committed to returning for the next year’s marathon. But I didn’t simply want to complete the distance. Instead, I set a goal of finishing in under three hours. I managed it, though barely, crossing the finish line 24 seconds under the three-hour mark.&lt;/p&gt;
    &lt;p&gt;I ran countless road races over the next dozen years. I had my greatest success with half-marathons, finishing third in the four races I ran on land—and first in the 2001 half-marathon held on the deck of a boat floating off Antarctica. In shorter races, from one mile to 10, I also managed perhaps a dozen first-place finishes. What about the tearful, wimpy English schoolboy who had previously shunned athletic endeavors? Over countless miles, I managed to leave him behind.&lt;/p&gt;
    &lt;p&gt;Career and athletic success were not, alas, rivaled by relationship success. Molly announced she wanted a divorce in 1998. It would be the first of two failed marriages—not an achievement I’m proud of. But the third time was a charm. In the midst of the pandemic, Elaine and I met in August 2020, the month my second marriage officially ended. We were living together by the end of the month and married almost four years later, in May 2024, five days after my cancer diagnosis. I met Elaine during one of my life’s roughest periods, and was so lucky to have done so. Elaine, I fear, was not so fortunate, for now she must navigate the world on her own.&lt;/p&gt;
    &lt;p&gt;By 2006 or so, I’d started to tire of the Getting Going column, and began casting around for what to do next. I had a few conversations with potential employers, but those came to naught. Then, one day in early 2008, my phone rang. It was Andy Seig from Citigroup. He was heading up a startup within Citi known as myFi, which was aiming to deliver advice on a client’s entire financial life in return for a flat monthly fee. It was, I imagined, the exit from the Journal I was looking for.&lt;/p&gt;
    &lt;p&gt;I joined myFi that spring, and it soon became apparent that launching a startup in the middle of a huge corporate bureaucracy was a foolhardy endeavor. Layered on top of that was the financial crisis that unfolded through the year. By mid-2009, myFi was dead, and we employees spent a long, aimless summer trying to figure out what was next.&lt;/p&gt;
    &lt;p&gt;Next turned out to be a new wealth management operation cobbled together by combining myFi’s remaining employees, who had been hired to launch an innovative new financial service, and the old school brokers who sat in Citi’s bank branches. It wasn’t exactly a match made in heaven.&lt;/p&gt;
    &lt;p&gt;I toughed it out at Citi until spring 2014. Money was undoubtedly part of the reason. I was making more than $300,000 a year, a gaudy sum for a onetime ink-stained wretch. And the job wasn’t without interest. As director of financial education for the U.S. wealth management business, I gave more than 30 speeches in some years—forcing me to overcome my fear of public speaking—and I was dealing with financial topics I’d rarely written about as a journalist, while also learning about the investment business from the inside. Still, I was also frustrated by the nit-picky oversight of lawyers and compliance officers, and vowed to leave.&lt;/p&gt;
    &lt;p&gt;For a year, I planned my departure, getting my finances in order and setting in motion some work projects for my life after Citi. I waited until I got my final year-end bonus in early 2014, and then handed in my notice.&lt;/p&gt;
    &lt;p&gt;What followed was a period I came to call my second childhood. Initially, that meant a 15-month return to The Wall Street Journal as a freelance columnist—I left when my editor got ousted during a round of layoffs in 2015—and also working on two annual editions of the Jonathan Clements Money Guide. That guide eventually became the core of HumbleDollar, which I launched on Dec. 31, 2016.&lt;/p&gt;
    &lt;p&gt;The two printed editions of the money guide were among the nine books I wrote over my career—eight personal finance books and a novel. I also edited two books, including My Money Journey, a compilation of 30 essays by HumbleDollar writers, and contributed essays to a fistful of other tomes, including penning the foreword to two Bill Bernstein books. None of the books I authored was a huge success. But my favorite, and the one with the best sales, was my 2016 book, How to Think About Money.&lt;/p&gt;
    &lt;p&gt;In 2016, I was also contacted by Peter Mallouk, president of fast-growing Creative Planning, a registered investment advisor that favored index funds and sought to help clients with their entire financial life. As at Citi, I was again given the title of director of financial education, though I remained an independent contractor and worked limited hours for Creative. Still, for me, it proved to be one of my career’s most enjoyable professional relationships. Peter was great to work with, and together we hosted a monthly podcast that ran for the rest of my life.&lt;/p&gt;
    &lt;p&gt;By May 2024, I’d been living in Philadelphia for more than three years, I was engaged to Elaine and living just an eight-minute walk from my daughter, son-in-law and two grandsons. The youngest was born that month. Elaine and I were talking about retirement, trying to figure out how we could travel more and have more time for each other, even as I kept HumbleDollar humming along.&lt;/p&gt;
    &lt;p&gt;And then I got my cancer diagnosis.&lt;/p&gt;
    &lt;p&gt;The period immediately after was astonishingly busy, as I tried to get my affairs in order and prep HumbleDollar for a life without me, even as my diagnosis triggered a surprising amount of media attention. The New York Times wrote about my illness, I was interviewed for Consuelo Mack’s WealthTrack, and I was asked to pen articles for The Washington Post, The Telegraph of London, The Wall Street Journal and AARP magazine. Who knew that candor about one’s own death would generate so much interest? It was an odd bookend to a life spent partly in the public eye—one that had previously been most notable for pounding the table for index funds.&lt;/p&gt;
    &lt;p&gt;I faced the final months not with sorrow, but with great gratitude. I had spent almost my entire adult life doing what I love and surrounded by those that I love. Who could ask for more?&lt;/p&gt;
    &lt;p&gt;Rest in Peace, Jonathan. My heartfelt condolences to your family. You were a great inspiration for your investing wisdom, retirement planning and you had a unique gift through your writings to reach out to countless investors. Thank you for your insights and wisdom over these years – truly appreciate it!&lt;/p&gt;
    &lt;p&gt;Jonathan…I have tears in my eyes as I write this. You have meant so much to so many. I enjoyed briefly chatting with you a few years go to invite you to address our group in Los Angeles. Was also delighted to contribute a column to Humble Dollar a few years ago detailing the benefit of saving early so you can retire early. Your editing of my column was totally “on point.” More importantly… condolences to Elaine and your family. To me, you are the most influential personal finance//investor writer that I have ever come across. Your columns in the WSJ gave me the confidence to be a DIYer. The “tone” of your columns were always so welcoming. God Bless you Jonathan and may you rest in peace. Fondest Regards and Admiration, Fred&lt;/p&gt;
    &lt;p&gt;Reading your words, I felt both a deep sadness and an overwhelming sense of gratitude for the way you’ve reflected on life. The way you described family, readers, and words as the core pillars of your journey is incredibly moving. It’s clear you not only lived fully but also gave so much of yourself to others. Your story about resilience—from tough school years to marathon running—shows how determination can reshape even the hardest parts of life. Somewhere in your reflections, when you mention the small everyday comforts, it reminded me how important it is to hold onto simple things.&lt;lb/&gt; What stands out most is your unwavering honesty and gratitude. If you could leave one piece of advice for younger readers—those just starting out in their personal and professional journeys—what would it be?&lt;/p&gt;
    &lt;p&gt;I am so very sorry to hear this news. We all read Elaine’s post Saturday about Hospice hoping this one would not come soon.&lt;/p&gt;
    &lt;p&gt;My deepest condolences and prayers for all of the Clements.&lt;/p&gt;
    &lt;p&gt;He will be sorely missed, not just for his humor and sage advice , but for the strength and fortitude he exhibited these last few years, as exemplified by the first sentences of this post, and this almost immortal quote&lt;/p&gt;
    &lt;p&gt;“I’m not brave,” Clements told a friend last year. “Dying is a full-time job, so I might as well try to do it well. I’m just trying to get the most out of each day.”&lt;lb/&gt;I have read Jonathan”s work avidly since well before he left the WSJ the first time. Somehow I always managed to find him again and keep listening.&lt;/p&gt;
    &lt;p&gt;While his early messages were about investing and gradually moved to focus on index funds and simplicity.&lt;/p&gt;
    &lt;p&gt;I did not follow as much of the index funds and simplicity advice as he would have liked. Fiddling around with finances is enjoyable but he has to take a fair amount of the blame for that as HD columns have illuminated a lot of the mystery, making it enjoyable.&lt;/p&gt;
    &lt;p&gt;What will stick with me forever and what made the greatest impression on me was his advice to live frugally, spend money on experiences, not material goods so as to enjoy life the most with the ones you love and to be prepared at the end so as not to leave your family with a mess.&lt;/p&gt;
    &lt;p&gt;Rest in Peace dear friend.&lt;/p&gt;
    &lt;p&gt;Like everyone who has written before me, I owe many thanks to Jonathan’s writings and the many contributors who have helped me stay connected and informed as my own career in the finance industry ended upon retirement.&lt;/p&gt;
    &lt;p&gt;Jonathan was simply too young to now be gone, but as we mostly know and accept, there is seldom a “good” time to depart. To his family: I grieve for your loss and thank you for sharing him with us for along as we had him.&lt;/p&gt;
    &lt;p&gt;My condolences to Jonathan Clements family. May Jonathan Rest in Peace and may God Bless Jonathan and his family.&lt;lb/&gt; Thank you Jonathan for your lessons and articles. You’ve left a great legacy that will go on for many years. To the Humble Dollar team, you learned a lot and are great writers and my condolences to all of you.&lt;lb/&gt; yours Greg Winnipeg, Manitoba Canada&lt;/p&gt;
    &lt;p&gt;Condolences to Jonathan’s family. As with other commentators here, from his earliest days at WSJ Jonathan has had a profound impact on my financial trajectory and the way I approached life. His advice to work hard and save while young made all the difference. His brave and industrious acceptance of his cancer diagnoses provides a further lesson. What a profoundly meaningful life.&lt;/p&gt;
    &lt;p&gt;So sad to hear about Jonathan’s passing. Even though I was about twelve years older than him, he felt like a father figure to me because of his wise advice.&lt;/p&gt;
    &lt;p&gt;I saved every email he sent me when I was submitting Humble Dollar articles for him to edit. They’re all archived under my old AOL account, simply titled “blog” — too many for me to count.&lt;/p&gt;
    &lt;p&gt;I guess I was trying to hold on to something that was very special to me. I will miss him very much.&lt;/p&gt;
    &lt;p&gt;My condolences to Elaine and his family.&lt;/p&gt;
    &lt;p&gt;My deepest condolences to Elaine, June, Hannah, Henry, Irina, Nicholas &amp;amp; Andrew. Jonathan was a Giant in the financial world, giving wisdom &amp;amp; guidance to millions of people through the WSJ, Sunday newspapers, Humble Dollar &amp;amp; his books. He will be greatly missed by all of us.&lt;lb/&gt; RIP Jonathan.&lt;/p&gt;
    &lt;p&gt;Even anticipating this day, I was a bit surprised to be as emotional about the passing of someone who I’ve never met except for the occasional online interchange. But then again, it was a nearly 30 year “relationship,” and one I credit for significant material benefit. Condolences to Elaine, Jon’s family, and the larger personal finance family that looked to Jon as a source of trusted advice. RIP.&lt;/p&gt;
    &lt;p&gt;Whenever I find myself about to say or do something that will highlight my ignorance, envy, lack of empathy, unkindness, or any of my various other personality and behavioral defects, I hope to be able to stop before I do so and ask myself, “What would Jonathan do?”. Such a class act and role model in so many ways.&lt;/p&gt;
    &lt;p&gt;Condolences to his family. He is leaving his large legacy of financial literacy to both the younger population studying and working and the retired population trying to sustain their finances in non-working years. A life should be lived that way to be useful for so many. I benefited from his writings. RIP Jonathan Clements.&lt;/p&gt;
    &lt;p&gt;That’s a heck of a life you lived, Jonathan. While you died before your time, you did a lot of living. A lot. And much of it devoted to the welfare of others. May God bless you, and keep you.&lt;/p&gt;
    &lt;p&gt;And I’m very pleased that we have several more of your reflections to look forward to over the coming months. I’ll think of you every time I check back with the Humble Dollar community.&lt;/p&gt;
    &lt;p&gt;My sympathies to Elaine, and Jonathan’s entire family. We lost a very good man. It saddens me greatly to think that he is no longer with us.&lt;/p&gt;
    &lt;p&gt;Farewell, Jonathan, and thank you.&lt;/p&gt;
    &lt;p&gt;Deepest condolences to Elaine and the entire family. All of us would hope to have loved ones like you for support and comfort in their final hours. Be sure to take good care of yourselves in the grieving process, and take comfort in knowing that Jonathan left a legacy of impact and respect very few can hope to approach.&lt;/p&gt;
    &lt;p&gt;Peace.&lt;/p&gt;
    &lt;p&gt;A sad day that I hoped would continue to be delayed. I’m so grateful to Jonathan for his wisdom, his kindness and his encouragement. He welcomed and encouraged me to be an active part of this community. Since I was a minister he would reach out to me on religious holidays for my take on issues of money &amp;amp; spirituality. He lived an amazing life and he left us so many lessons, especially after his cancer diagnosis. My thought and love are with Elaine and his family. What a gift he and his life were for all of us. May we take a piece of him with us as we try to make the world a little better on our journeys. He left us a wonderful roadmap. Blessings, love and thanks.&lt;/p&gt;
    &lt;p&gt;While I’m still a work in progress, Jonathan taught me more about the relationship between money and happiness than anyone. I will cherish my last email from Jonathan a month ago. He had heard I had a health event and wanted me to know he was thinking of me. Just like Jonathan to be thinking of others while he knew he was dying and likely in so much pain.&lt;/p&gt;
    &lt;p&gt;Jonathan, thanks for all you have done for me and millions of others. I know your passing was expected but it’s still shocking for me.&lt;/p&gt;
    &lt;p&gt;Elaine, I’ve never met you but I do know you made Jonathan’s final years so happy. Thank you, and I’m so sorry for your loss.&lt;/p&gt;
    &lt;p&gt;My heart aches after reading this. Even though we never met in person, you have helped settle my anxiety about investments and the market shifts, etc., through your writings. I have always looked forward to reading your articles each day. I lift your family up in prayer this morning. May they be comforted during this time. So thankful, God created a place in Heaven for each of us where we will live pain free for eternity.&lt;/p&gt;
    &lt;p&gt;Susan Hayden&lt;lb/&gt; Tupelo MS&lt;/p&gt;
    &lt;p&gt;RIP, Jonathan. It was a privilege to be able to meet and work with you over the past four years as a contributor to HD. What a surprise it was for me to find out that such an accomplished journalist and a brilliant investing mind could be so down-to-earth and humble. But that was the kind of person you were. Your wisdom lives on in the thousands of readers you touched over the years at the WSJ and here on HD. You will be greatly missed.&lt;/p&gt;
    &lt;p&gt;Our deepest condolences to Elaine, Hannah, Henry, and the rest of the family.&lt;/p&gt;
    &lt;p&gt;Jonathan,&lt;/p&gt;
    &lt;p&gt;You were first my hero and then my friend. You were a gift to this world and epitomized “The Man in the Arena”:&lt;/p&gt;
    &lt;p&gt;THE MAN IN THE ARENA&lt;/p&gt;
    &lt;p&gt;“IT IS NOT THE CRITIC WHO COUNTS. NOT TRE MAN WHO POINTS OUT HOW THE STRONG MAN STUMBLES, OR WHERE THE DOER OF DEEDS COULD HAVE DONE THEM BETTER. THE CREDIT BELONGS TO THE MAN WHO IS ACTUALLY IN THE ARENA, WHOSE FACE IS MARRED BY DUST AND SWEAT AND BLOOD; WHO STRIVES VAL IANTLY; WHO ERRS, WHO COMES SHORT AGAIN AND AGAIN, BECAUSE THERE IS NO EFFORT WITHOUT ERROR AND SHORTCOMING: BUT WHO DOES ACTUALLY STRIVE TO DO THE DEEDS; WHO KNOWS GREAT ENTHUSIASMS, THE GREAT DEVOTIONS: WHO SPENDS HIMSELF IN A WORTHY CAUSE; WHO AT THE BEST KNOWS IN THE END THE TRIUMPH OF HIGH ACHIEVEMENT, AND WHO AT THE WORST, IF HE FAILS, AT LEAST FAILS WHILE DARING GREATLY, SO THAT HIS PLACE SHALL NEVER BE WITH THOSE COLD AND TIMID SOULS WHO NEITHER KNOW VICTORY NOR DEFEAT.”&lt;/p&gt;
    &lt;p&gt;Theodore Roosevelt&lt;/p&gt;
    &lt;p&gt;You taught us how to dare greatly and live a happy, fulfilling life, using money as a tool to this end. You also taught us how to die a regret free life. You talked the talk and walked the walk. I am privileged to have met you, dined with you, and even hosted you on my podcast Catching Up to FI. When I “came out of the closet” as a late starter on the journey to financial independence, you deftly edited my prose and published my post “Saving Our Retirement” on Humble Dollar. I am forever grateful to you for your generous friendship and the personal impact you have had on my life and those of countless others.&lt;/p&gt;
    &lt;p&gt;Rest in Peace.&lt;/p&gt;
    &lt;p&gt;Love,&lt;/p&gt;
    &lt;p&gt;Bill Yount, MD&lt;/p&gt;
    &lt;p&gt;My sincere condolences to the Clements family on the loss of your dear Jonathan. I am grateful that I joined the HD community five years ago, when I especially needed just what was here, and will continue to be: financial and personal advice, camaraderie and, very importantly, civility. You are in my prayers.&lt;/p&gt;
    &lt;p&gt;Jonathan Clements was, and remains, a beacon of sensible financial wisdom. A life mentor to me and countless others, I’m sure. My condolences to your family, loved ones, the HD community and all faithful readers. Thank you for getting me going on the right track. May you rest in peace, sir.&lt;/p&gt;
    &lt;p&gt;RIP, Jonathan, and of course you penned your own farewell to us. I’m sad for your family and friends, and I’m sad for us, as we’ll have to go forward here without your wise, gentle, and gracious leadership.&lt;/p&gt;
    &lt;p&gt;It goes without saying that you’ll be missed, and since I know that one of Jonathan’s fondest wishes over his final year was for HD to live on, I hope we can all commit ourselves to that in honor of his memory.&lt;/p&gt;
    &lt;p&gt;RIP Jonathan and my heat felt condolences to Elaine and your family. In an effort to not be sad, I like to think Jonathan is now sitting shoulder to shoulder with to the likes of John Bogle, who is smiling and giving an approving nod and wink.&lt;/p&gt;
    &lt;p&gt;I started out reading the WSJ personal finance weekend edition in my Sunday local newspaper. No doubt some of Jonathan’s columns were in there. 30 plus years later I’m pushing 50 and giving advice to others. More importantly, a life of disciplined index fund/tax efficient investing has left me rich—thanks to the Mount Rushmore of Jonathan Clements, Jack Bogle, Brian Preston, and more.&lt;/p&gt;
    &lt;p&gt;Jonathan’s death happened to fall on the eve of the Jewish New Year. It is a custom to dip apples in honey to signify a hopeful sweet start to the year. With Jonathan’s wishes of no sadness as part of my wishes I will include Jon’s lust for life and giving personality. May his memory always be a blessing&lt;/p&gt;
    &lt;p&gt;A beautiful tribute, by Jonathan’s friend, Jason Zweig, at the WSJ (should be gifted/unlocked):&lt;lb/&gt; https://www.wsj.com/finance/investing/jonathan-clements-longtime-wsj-columnist-dies-at-62-8753c01d?st=zKGjNV&amp;amp;reflink=desktopwebshare_permalink&lt;/p&gt;
    &lt;p&gt;Jason’s wonderful tribute in the WSJ + now this final essay from Jonathan = the tears just keep flowing. 😭 Can’t believe he’s gone.&lt;/p&gt;
    &lt;p&gt;But I know a part of him will live on on this site and in his books and via his family. That helps, a little.&lt;/p&gt;
    &lt;p&gt;Plus the Creative Planning podcasts he did each month with Peter Mallouk. Here’s an episode:&lt;/p&gt;
    &lt;p&gt;https://podcasts.apple.com/us/podcast/signal-or-noise/id1691155499?i=1000713518395&lt;/p&gt;
    &lt;p&gt;-or-&lt;/p&gt;
    &lt;p&gt;https://open.spotify.com/episode/68ZB8CctzIdRmdnZn6xzmF?si=iD4DffFESW-B3RkiWi2ZWg&lt;/p&gt;
    &lt;p&gt;Thanks for the link, David. The story contains a great Jonathan quote:&lt;/p&gt;
    &lt;p&gt;“Dying is a full-time job, so I might as well try to do it well. I’m just trying to get the most out of each day.”&lt;/p&gt;
    &lt;p&gt;Shakespeare’s sonnet 60 somehow seems appropriate for a former enthusiastic UK student journalist:&lt;/p&gt;
    &lt;p&gt;Like as the waves make towards the pebbled shore,&lt;lb/&gt; So do our minutes hasten to their end;&lt;lb/&gt; Each changing place with that which goes before,&lt;lb/&gt; In sequent toil all forwards do contend.&lt;lb/&gt; Nativity, once in the main of light,&lt;lb/&gt; Crawls to maturity, wherewith being crown’d,&lt;lb/&gt; Crooked elipses ’gainst his glory fight,&lt;lb/&gt; And Time that gave doth now his gift confound.&lt;lb/&gt; Time doth transfix the flourish set on youth&lt;lb/&gt; And delves the parallels in beauty’s brow,&lt;lb/&gt; Feeds on the rarities of nature’s truth,&lt;lb/&gt; And nothing stands but for his scythe to mow:&lt;lb/&gt; And yet to times in hope my verse shall stand,&lt;lb/&gt; Praising thy worth, despite his cruel hand.&lt;/p&gt;
    &lt;p&gt;Like all HumbleDollar readers, I’m heartbroken after learning of Jonathan’s passing.&lt;/p&gt;
    &lt;p&gt;I feel like Socrates’ students must have felt after their master drank his fateful cup of hemlock. My teacher, my guiding light is gone. I shall not see another like him in my lifetime.&lt;/p&gt;
    &lt;p&gt;Rest in peace, Jonathan.&lt;/p&gt;
    &lt;p&gt;Even though we all knew it was coming, this hits hard. But up until Elaine recently posted that Jonathan had entered hospice, I couldn’t help hoping for a miracle.&lt;/p&gt;
    &lt;p&gt;Jonathan was, as ever, more pragmatic, and spent his last months as he’d spent all the others—carrying on with his life’s work. And as his final gift, he found a way to have Humble Dollar live on. Thanks again, Bogdan, for picking up the reins.&lt;/p&gt;
    &lt;p&gt;Over many years now I’ve admired Jonathan’s ability to teach about money—how to handle it, and how to think about it. Over the last 14 months, I’ve admired how he’s approached his own end. I intend to always remember both.&lt;/p&gt;
    &lt;p&gt;The title and first sentence sent a chill through me. Although we knew the end was coming and he kept us apprised of his health status, I wasn’t expecting the news to come out this way. But yet, the more I think about it, it was a perfect way to say farewell from a journalist. This final one will be a keeper.&lt;/p&gt;
    &lt;p&gt;Dear Elaine and June Dosik, I know how little the words of an outsider mean to you just now but I must tell you how deeply I sympathize with you and all Jonathan’s family in your great loss.&lt;/p&gt;
    &lt;p&gt;Jonathan has left a place in the whole community that will be difficult to fill. I think of all he stood for that was fine and helpful. I don’t think anything will be the same without him. Sincerely, Marjorie&lt;/p&gt;
    &lt;p&gt;Jonathan has been an inspiration over the past fifteen months since his cancer diagnosis but also through his life. So many of us have benefited from his wisdom and intellect. While I was as frugal as he or perhaps more so he provided me with guidance on how to invest my money. I quickly caught on. He trusted me to be one of the early writers on HD. I never thought I was terribly good at it but he surprised me by saying that he rarely had to do much editing to my work. Our family stayed close in spite of the distance that separated us. During difficult life situations he provided the guidance that we needed at the time. We will miss him terribly. Thank you to all who have written notes on HD expressing what he has meant to them. Rest easy Jonathan with our sister Tory and Dad.&lt;/p&gt;
    &lt;p&gt;Sorry Jonathan–I DO feel sad. I will miss your emails that always encouraged me to write more HD contributions. I will miss your wit and wisdom. I regret that we never got to meet in person. My sincere condolences go out to your family and friends.&lt;/p&gt;
    &lt;p&gt;From June Dosik: My sweet son jonathan has left our planet,and has given of himself to our world a wealth of knowledge in which we may make our life a little easier. May Humble Dollar thrive, and may you, Elaine.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://humbledollar.com/forum/farewell-friends/"/><published>2025-09-28T21:31:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45408368</id><title>Tai Lopez charged by SEC in ponzi scheme</title><updated>2025-09-29T00:47:26.469134+00:00</updated><content>&lt;doc fingerprint="390401d5983ba5fc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Taino Adrian Lopez, Alexander Farhang Mehr, and Maya Rose Burkenroad&lt;/head&gt;
    &lt;head rend="h2"&gt;U.S. SECURITIES AND EXCHANGE COMMISSION&lt;/head&gt;
    &lt;head rend="h2"&gt;Litigation Release No. 26413 / September 25, 2025&lt;/head&gt;
    &lt;head rend="h3"&gt;Securities and Exchange Commission v. Taino Adrian Lopez, et. al., No. 1:25-cv-24356 (S.D. Fla. filed [Mo. Day, 2025)&lt;/head&gt;
    &lt;head rend="h3"&gt;SEC Charges Co-Founders and COO of Florida Holding Company with Misappropriating Investor Money and Operating a Ponzi Scheme&lt;/head&gt;
    &lt;p&gt;On September 25, 2025, the Securities and Exchange Commission charged Taino Lopez and Alexander Mehr, co-founders of Retail Ecommerce Ventures LLC (“REV”), and its Chief Operating Officer, Maya Burkenroad (collectively, “Defendants”), with conducting a series of fraudulent securities offerings, misusing investor funds, and making Ponzi-like payments to investors.&lt;/p&gt;
    &lt;p&gt;According to the SEC’s complaint, REV’s primary business was purchasing distressed retail companies with name brand recognition and converting them into e-commerce only businesses, and serving as the holding company and manager of the REV retailer brands. From approximately April 2020 through November 2022, the Defendants raised approximately $112 million from hundreds of investors through fraudulent offerings in eight REV portfolio companies, including Pier 1 Imports Online, Inc., Dress Barn Online, LLC, Linens ‘N Things Online, Inc., and RadioShack Online, LLC (the “REV Retailer Brands”). The complaint alleges that the Defendants sold securities in the form of unsecured notes promising up to 25% annualized returns, as well as equity (membership units) with a monthly preferential dividend as high as 2.083%. The purported purpose of the offerings was to raise capital to acquire the predecessor of and raise additional operating capital for each particular REV Retailer Brand. However, according to the complaint, Lopez and Mehr made material misstatements in connection with these offerings about the success and profitability of REV’s business model and the REV Retailer Brands, as well as the safety of investors’ investments. The complaint further alleges that Defendants transferred at least $5.9 million in investor proceeds directly between portfolio companies, contrary to the written and oral representations made to investors about the use of proceeds; that at least $5.9 million of the returns distributed to investors were, in reality, Ponzi-like payments funded by other investors; and that Defendants misappropriated approximately $16.1 million in investor funds for Lopez’s and Mehr’s personal use.&lt;/p&gt;
    &lt;p&gt;The SEC’s complaint, filed in the U.S. District Court for the Southern District of Florida, charges defendants Lopez and Mehr with violations of Section 17(a) of the Securities Act of 1933 and Section 10(b) of the Securities Exchange Act of 1934 and Rule 10b-5 thereunder. The complaint also charges defendant Burkenroad with violations of Sections 17(a)(1) and (3) of the Securities Act and Section 10(b) of the Exchange Act and Rule 10b-5(a) and (c) thereunder. Finally, the complaint charges Burkenroad with aiding and abetting Lopez’s and Mehr’s violations of Section 17(a)(2) of the Securities Act and Section 10(b) of the Exchange Act and Rule 10b-5(b) thereunder. The complaint seeks permanent injunctions, civil penalties, and officer-and-director bars as to each Defendant. In addition, the complaint seeks disgorgement and prejudgment interest as to Lopez and Mehr.&lt;/p&gt;
    &lt;p&gt;The SEC’s investigation was conducted by Brian Theophilus James, and supervised by Sean M. O’Neill and Glenn S. Gordon with the assistance of Fernado Torres, all of the Miami Regional Office. The SEC’s litigation will be led by Alise Johnson and Russell Koonin and supervised by Teresa J. Verges, also of the Miami Regional Office.&lt;/p&gt;
    &lt;p&gt;[Include link to complaint]&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sec.gov/enforcement-litigation/litigation-releases/lr-26413"/><published>2025-09-28T21:44:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45408617</id><title>Go ahead, write the “stupid” code</title><updated>2025-09-29T00:47:26.162390+00:00</updated><content>&lt;doc fingerprint="3b719074d3a44c98"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Go Ahead - Write the “stupid” code&lt;/head&gt;
    &lt;p&gt;When I finished school in 2010 (yep, along time ago now), I wanted to go try and make it as a musician. I figured if punk bands could just learn on the job, I could too. But my mum insisted that I needed to do something, just in case. So I went down to the local TAFE (this is like a trade school in Australia, though it has pathways into uni, it’s pretty neat!) and signed up for whatever looked good. I had always loved computers and gaming, I did all the courses for computing short of programming in school (the school didn’t offer it), and had an interest so I signed up.&lt;/p&gt;
    &lt;p&gt;It wasn’t love at first sight, as I still remember after a week freaking out in my room that I couldn’t do this. But I sat down with my massive VB.NET textbook we had to buy and pushed through it. And once I made it through, it clicked. I fell in love with programming after that, and it became something I was both good at and started growing a passion for.&lt;/p&gt;
    &lt;p&gt;From there, going through my games diploma, and my bachelors in games design and development (think a comp sci degree with game design elements, it’s pretty neat and I’m happy to answer questions about it), I wrote a lot of stupid code. Like a lot of it. In my courses, in my game jams (god good times), in my spare time when I was learning things both in uni and early in my career. It helped me refine my skills, but also learn a lot.&lt;/p&gt;
    &lt;p&gt;Fast forward to today. I’ve been doing a dive on JavaScript/TypeScript and different runtimes like NodeJS and Deno, amongst a bunch of other stuff. At first, I was looking into a deep dive into node with this talk by James Snell and wanted to try out the Streams API. Part of me wanted to start writing straight away, but held back because I didn’t think I had anything to use it on. After being unable to resist the urge to write some code after a few minutes, I just made the dumbest stock ticker I could so I could try streams out in an arbitrary way. But it left me thinking, “why didn’t I hold back”.&lt;/p&gt;
    &lt;p&gt;As I’m writing this now, I came up with the answer. As I was writing a little app to output inspirational quotes, I started umm’ing and ahh’ing over if I should make this. It’s small, it’s dumb, and there were probably plenty of options out there. But I wanted to write some code, and was interested in trying out Deno and seeing how it compiles binaries. So I did it. And I was happy (I’m very excited to use it), and I realised that I was scared to write something dumb. All my years of doing this helped refine my own abilities, but also made me much more harsh on myself. Harsh on my own code, harsh on just trying things.&lt;/p&gt;
    &lt;p&gt;After coming to this realisation, I’ve decided I’m going to give myself more grace when it comes to writing software for myself, and I encourage you all dear readers to do the same if you’ve been feeling this. There is no stupid code. There’s only code. Enjoy writing it, it doesn’t have to be nice or pretty if it’s for you. Have fun, try out that new runtime or language. Poke around and see what breaks. Keep that learning mindset, and keep feeding your curiosity. It’ll help you continue to grow across your career, and if you enjoy this kind of thing as a hobby like me, it’ll keep stoking your own enjoyment and passion.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spikepuppet.io/posts/write-the-stupid-code/"/><published>2025-09-28T22:20:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45408994</id><title>Autism may be the price of human intelligence, linked to human brain evolution</title><updated>2025-09-29T00:47:25.933992+00:00</updated><content/><link href="https://academic.oup.com/mbe/article/42/9/msaf189/8245036?login=false"/><published>2025-09-28T23:32:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45409013</id><title>Imagination as General Intelligence: Reconciling Consciousness and Free Will</title><updated>2025-09-29T00:47:24.905807+00:00</updated><content>&lt;doc fingerprint="dbf85a3fcd8ba2d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Imagination as General Intelligence: Reconciling Consciousness and Free Will with Modern Physics&lt;/head&gt;
    &lt;head rend="h3"&gt;Creators&lt;/head&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;This white paper introduces the Predictive Timeline Simulation (PTS) Framework, a model that reframes consciousness as an evolved predictive simulation engine. Drawing on neuroscience, predictive processing, and the Block Universe model of spacetime, it offers a functional, testable account of consciousness without resorting to mysticism.&lt;/p&gt;
    &lt;p&gt;The framework has implications across multiple domains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Philosophy: Proposes an evolutionary role for qualia, treating them as a data format for navigating a deterministic universe.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Neuroscience: Models how the brain’s “common core network” and predictive systems create a workspace for simulating and evaluating future timelines.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Clinical Science: Introduces the Simulation Misfiling Hypothesis, suggesting schizophrenia may result from a breakdown in executive control over this simulation process, with implications for early detection and intervention.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Artificial Intelligence: Outlines a blueprint for Artificial General Intelligence (AGI) grounded in imagination — the ability to simulate novel futures as the true engine of general intelligence.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Grounded in physics and evolution, this paper presents a unified, testable framework with clear implications for philosophy, neuroscience, clinical science, and AI research, supported by a robust multidisciplinary bibliography.&lt;/p&gt;
    &lt;head rend="h2"&gt;Files&lt;/head&gt;
    &lt;head rend="h3"&gt; 5D_Consciousness_White_Paper (10).pdf &lt;/head&gt;
    &lt;head rend="h3"&gt; Files (3.1 MB) &lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Size&lt;/cell&gt;
        &lt;cell role="head"&gt;Download all&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt; md5:de4c30cadf29152eee1617260221144b &lt;/cell&gt;
        &lt;cell&gt;3.1 MB&lt;/cell&gt;
        &lt;cell&gt;Preview Download&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Additional details&lt;/head&gt;
    &lt;head rend="h3"&gt;Dates&lt;/head&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Submitted&lt;/item&gt;
      &lt;item rend="dd-1"&gt; 2025-09-12Submitted version of white paper for public access&lt;/item&gt;
      &lt;item rend="dt-2"&gt;Available&lt;/item&gt;
      &lt;item rend="dd-2"&gt; 2025-09-12ubmitted version of white paper for public access&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zenodo.org/records/17109096"/><published>2025-09-28T23:35:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45409227</id><title>Health officials in the US are sounding the alarm over drug-resistant bacteria</title><updated>2025-09-29T00:47:24.626193+00:00</updated><content>&lt;doc fingerprint="ce70591c4ed7978d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;What are ‘nightmare bacteria’ and why are infections rising in the US?&lt;/head&gt;&lt;p&gt;Health officials in the US are sounding the alarm over the rise of drug-resistant ‘nightmare bacteria’.&lt;/p&gt;&lt;p&gt;The number of infections by drug-resistant, “nightmare bacteria” rose by almost 70 percent between 2019 and 2023 in the United States, according to a report from the Centers for Disease Control and Prevention (CDC), the country’s national public health agency.&lt;/p&gt;&lt;p&gt;Driving the increase are drug-resistant bacteria with the so-called “NDM gene” (New Delhi metallo-β-lactamase), researchers said. Bacteria with the NDM gene were once considered “exotic” and were linked to only a small number of patients, mostly outside the US.&lt;/p&gt;&lt;head rend="h2"&gt;Recommended Stories&lt;/head&gt;list of 4 items&lt;list rend="ul"&gt;&lt;item&gt;list 1 of 4US vaccine advisory panel does not recommend COVID jabs for all&lt;/item&gt;&lt;item&gt;list 2 of 4Fact checking Robert F Kennedy’s statements to Senate on COVID, vaccines&lt;/item&gt;&lt;item&gt;list 3 of 4‘Total implosion’: How Trump firing of CDC chief Monarez sparked an exodus&lt;/item&gt;&lt;item&gt;list 4 of 4WHO says Ebola outbreak in DR Congo kills 31&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Only one type of antibiotics, known as carbapenems, have been known to work against some “nightmare bacteria”. However, the presence of NDM-gene bacteria can now render these entirely ineffective as well.&lt;/p&gt;&lt;head rend="h2"&gt;What has the report on drug-resistant bacteria found?&lt;/head&gt;&lt;p&gt;While absolute numbers of people with drug-resistant bacterial infections in the US remain low, cases have risen at an alarming rate in recent years, the researchers reported on Monday.&lt;/p&gt;&lt;p&gt;“The rise of NDMs in the US is a grave danger and very worrisome,” said David Weiss, an Emory University infectious diseases researcher, The Associated Press news agency reported.&lt;/p&gt;&lt;p&gt;Researchers had access to data from 29 states that test for and report cases of carbapenem-resistant bacteria. They said there were 4,341 cases of carbapenem-resistant bacterial infections in those states in 2023, with 1,831 of them the NDM-gene variety.&lt;/p&gt;&lt;head rend="h2"&gt;How do bacteria become drug-resistant?&lt;/head&gt;&lt;p&gt;“Antimicrobial resistance” can occur when bacteria develop new ways to defend themselves against the drugs used to kill them.&lt;/p&gt;&lt;p&gt;The misuse of antibiotics has driven the rise – people not finishing prescribed courses of antibiotics or receiving unnecessary prescriptions, which don’t fully kill off an infection, can enable bacteria to get “used” to an antibiotic and grow resistant to it. Resistant bacteria are then able to survive and spread their genes to other bacteria.&lt;/p&gt;&lt;p&gt;The rate of carbapenem-resistant infections in the US rose from just under 2 per 100,000 people in 2019 to more than 3 per 100,000 in 2023 – an increase of 69 percent. But the rate of NDM cases rose from about 0.25 to about 1.35 per 100,000 people – an increase of 460 percent, the authors said.&lt;/p&gt;&lt;p&gt;It’s likely, therefore, that some people are unrecognised carriers of the NDM-gene bacteria, which could lead to community spread, the CDC scientists said. Common infections like urinary tract infections can also become more dangerous if they cannot be treated.&lt;/p&gt;&lt;head rend="h2"&gt;Why are cases of drug-resistant infections on the rise?&lt;/head&gt;&lt;p&gt;The increase in US cases may be related to the COVID-19 pandemic, according to experts.&lt;/p&gt;&lt;p&gt;“We know that there was a huge surge in antibiotic use during the pandemic, so this likely is reflected in increasing drug resistance,” Dr Jason Burnham, a Washington University researcher, told the AP.&lt;/p&gt;&lt;p&gt;Furthermore, the CDC’s latest count is likely only a partial picture. Many states do not test for carbapenem-resistant bacterial infections. Even in states that do, testing tends to be limited to hospital patients who are extremely ill.&lt;/p&gt;&lt;p&gt;The CDC researchers also did not have access to data from some of the US’s most populated areas, including California, Florida, New York and Texas, meaning the absolute number of US infections “is definitely underestimated”, Burnham said.&lt;/p&gt;&lt;p&gt;What are the early signs of carbapenem-resistant infection?&lt;/p&gt;&lt;p&gt;Carbapenem-Resistant Enterobacteriaceae (CRE) infections don’t differ very much from common bacterial illnesses, which makes them tricky to spot. Typical warning signs include:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Urinary tract infections: burning sensation, frequent urge to urinate or “cloudy” urine.&lt;/item&gt;&lt;item&gt;Bloodstream infections: high fever, rapid heartbeat or very low blood pressure.&lt;/item&gt;&lt;item&gt;Pneumonia (lung infection): cough, shortness of breath or chest pain.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Are ‘nightmare bacteria’ rising in other countries as well?&lt;/head&gt;&lt;p&gt;Bacteria containing the NDM gene are not just a problem in the US; they can be found elsewhere in the world as well, although prevalence varies by region.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;South Asia: NDM-producing bacteria are relatively widespread compared with other regions of the world, particularly in India and Pakistan. Contributing factors include the over-use of antibiotics, limited regulation of generic antibiotics and overcrowded hospitals – making it easier for infection to spread.&lt;/item&gt;&lt;item&gt;Europe: Investigations show that southern European countries such as Greece, Italy and Turkiye report more frequent “nightmare bacteria” cases than northern nations, where strong infection control measures and antibiotic stewardship programmes tend to be more robust.&lt;/item&gt;&lt;item&gt;Africa: Though comprehensive data is limited, studies have revealed that resistant bacteria are present in both hospitals and across communities. Limited diagnostic capacity often leads to underreporting, while risk factors such as unregulated antibiotic use and weak sanitation infrastructure increase the threat of infections spreading.&lt;/item&gt;&lt;item&gt;Latin America: Carbapenem-resistant infections are an emerging concern, especially in Brazil and Argentina, where several outbreaks have been recorded in 2021 and 2022.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Overall, countries with weaker health systems or more relaxed antibiotic sales policies are more likely to struggle with antibiotic-resistant infections. Because bacteria travel easily and can be easily transferred by people, food and animals, experts stress that this is a global health security issue, and not confined to one region.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.aljazeera.com/news/2025/9/24/what-are-nightmare-bacteria-and-why-are-infections-rising-in-the-us"/><published>2025-09-29T00:16:01+00:00</published></entry></feed>