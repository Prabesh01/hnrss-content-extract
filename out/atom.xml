<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-08T05:45:57.700652+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46527161</id><title>Shipmap.org</title><updated>2026-01-08T05:46:06.068124+00:00</updated><content>&lt;doc fingerprint="14b4e15227c5a82f"&gt;
  &lt;main&gt;
    &lt;p&gt;Data: exactEarth &amp;amp; Clarksons&lt;/p&gt;
    &lt;p&gt;Due to popular demand the designers of this map, Kiln, are now selling stunning high-resolution versions of the world √¢routes√¢ view. There are two versions available: coloured by ship type over the inky-blue base map; or just the ship in a single colour a transparent background so you can overlay or print onto whatever background colour you like. Contact [email protected] for pricing and further information.&lt;/p&gt;
    &lt;p&gt;Yes. You are welcome to embed this map. Please include a link back to Kiln somewhere in the text of your article. Use the following embed code for a fully responsive embed that will adjust to the width of your website. Feel free to change the height and/or give it a fixed width if you prefer.&lt;/p&gt;
    &lt;p&gt;You can see movements of the global merchant fleet over the course of 2012, overlaid on a bathymetric map. You can also see a few statistics such as a counter for emitted CO2 (in thousand tonnes) and maximum freight carried by represented vessels (varying units).&lt;/p&gt;
    &lt;p&gt;You can pan and zoom in the usual ways, and skip back and forward in time using the timeline at the bottom of the screen. The controls at the top right let you show and hide different map layers: port names, the background map, routes (a plot of all recorded vessel positions), and the animated ships view. There are also controls for filtering and colouring by vessel type.&lt;/p&gt;
    &lt;p&gt;The merchant fleet is divided into five categories, each of which has a filter and a CO2 and freight counter for the hour shown on the clock. The ship types and units are as follows:&lt;/p&gt;
    &lt;p&gt;In some cases this is because there are ships navigating via canals or rivers that aren√¢t visible on the map. Generally, though, this effect is an artefact of animating a ship between two recorded positions with missing data between, especially when the positions are separated by a narrow strip of land. We may develop the map to remove this effect in the future.&lt;/p&gt;
    &lt;p&gt;Unfortunately the data we are using for the map is incomplete for the first few months of the year: roughly January to April.&lt;/p&gt;
    &lt;p&gt;The map was created by Kiln based on data from the UCL Energy Institute (UCL EI)&lt;/p&gt;
    &lt;p&gt;Website: Duncan Clark &amp;amp; Robin Houston from Kiln&lt;/p&gt;
    &lt;p&gt;Data: Julia Schaumeier &amp;amp; Tristan Smith from the UCL EI&lt;/p&gt;
    &lt;p&gt;Music: Bach Goldberg Variations played by Kimiko Ishizaka&lt;/p&gt;
    &lt;p&gt;UCL EI took data showing location and speed of ships and cross-checked it with another database to get the vessel characteristics, such as engine type and hull measurements. With this information they were able to compute the CO2 emissions for each observed hour, following the approach laid out in the Third IMO Greenhouse Gas Study 2014. Kiln took the resulting dataset and visualized it with WebGL on top of a specially created base map, which shows bathymetry (ocean depth), based on the GEBCO_2014 Grid (version 20150318), as well as continents and major rivers from Natural Earth.&lt;/p&gt;
    &lt;p&gt;Our data sources for shipping positions are exactEarth for AIS data (location/speed) and Clarksons Research UK World Fleet Register (static vessel information). We are very grateful to our funders, the European Climate Foundation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.shipmap.org/"/><published>2026-01-07T15:03:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46527950</id><title>Creators of Tailwind laid off 75% of their engineering team</title><updated>2026-01-08T05:46:03.940433+00:00</updated><content>&lt;doc fingerprint="2660315d6827bef9"&gt;
  &lt;main&gt;&lt;list rend="ul"&gt;&lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;&lt;item&gt;Fork 5&lt;/item&gt;&lt;/list&gt;&lt;head rend="h1"&gt;feat: add llms.txt endpoint for LLM-optimized documentation #2388&lt;/head&gt;&lt;head id="button-b01c7028991e58db" class="btn btn-sm btn-primary m-0 ml-0 ml-md-2"&gt;New issue&lt;/head&gt;&lt;p&gt;Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.&lt;/p&gt;&lt;p&gt;By clicking ‚ÄúSign up for GitHub‚Äù, you agree to our terms of service and privacy statement. We‚Äôll occasionally send you account related emails.&lt;/p&gt;&lt;p&gt;Already on GitHub? Sign in to your account&lt;/p&gt;&lt;head rend="h2"&gt;Conversation&lt;/head&gt;&lt;p&gt;Add /llms.txt endpoint that serves a concatenated, text-only version of all Tailwind CSS documentation pages optimized for Large Language Model consumption.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Extract text from MDX files, removing JSX components and preserving code blocks&lt;/item&gt;&lt;item&gt;Remove standalone HTML blocks (not in code blocks)&lt;/item&gt;&lt;item&gt;Extract meaningful content from custom components (ApiTable, ResponsiveDesign, etc.)&lt;/item&gt;&lt;item&gt;Statically generate the output at build time&lt;/item&gt;&lt;item&gt;Include all 185 documentation files in proper order with sections&lt;/item&gt;&lt;/list&gt;&lt;p&gt;:)&lt;/p&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@quantizor is attempting to deploy a commit to the Tailwind Labs Team on Vercel.&lt;/p&gt;&lt;p&gt;A member of the Team first needs to authorize it.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head class="color-bg-subtle border-bottom-0 py-0 px-2"&gt; This comment was marked as outdated. &lt;/head&gt;&lt;head rend="h3"&gt;This comment was marked as outdated.&lt;/head&gt;&lt;head class="color-bg-subtle border-bottom-0 py-0 px-2"&gt; This comment was marked as outdated. &lt;/head&gt;&lt;head rend="h3"&gt;This comment was marked as outdated.&lt;/head&gt;&lt;code&gt;5dc6fde&lt;/code&gt;    to
    &lt;code&gt;326c151&lt;/code&gt;      
    Compare
  



    &lt;quote&gt;Add /llms.txt endpoint that serves a concatenated, text-only version of all Tailwind CSS documentation pages optimized for Large Language Model consumption. - Extract text from MDX files, removing JSX components and preserving code blocks - Remove standalone HTML blocks (not in code blocks) - Extract meaningful content from custom components (ApiTable, ResponsiveDesign, etc.) - Statically generate the output at build time - Include all 185 documentation files in proper order with sections&lt;/quote&gt;&lt;code&gt;326c151&lt;/code&gt;    to
    &lt;code&gt;5c005a9&lt;/code&gt;      
    Compare
  



    &lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@reinink this is ready to be reviewed&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Why is this one not moving?&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Yeah I've been wondering that myself.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@petersuhm maybe you missed this before?&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Have more important things to do like figure out how to make enough money for the business to be sustainable right now. And making it easier for LLMs to read our docs just means less traffic to our docs which means less people learning about our paid products and the business being even less sustainable.&lt;/p&gt;&lt;p&gt;Just don't have time to work on things that don't help us pay the bills right now, sorry. We may add this one day but closing for now.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Wow, what a disappointing response. This is complementary not replacement.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@adamwathan as someone who has sponsored Tailwind CSS in the past, this is a disappointing response.&lt;/p&gt;&lt;p&gt;Would you like to disclose the fact that sponsoring gives one access to an official collection of LLM rules for Tailwind? Does that have anything to do with the rejection of this PR?&lt;/p&gt;&lt;p&gt;If yes, fine. You're running a business, and that's cool. But you should disclose the fact that you are monetizing this (making Tailwind docs LLM-friendly).&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;It is mentioned on the sponsorship page. Seems strange to not mention that when closing this PR, though.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;In general I object to the spirit of closing this. It's very OSS unfriendly and would not meaningfully reduce traffic to the docs by humans that actually would buy the product.&lt;/p&gt;&lt;p&gt;Just bad vibes.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Here's a friendly tip for the Tailwind team that you should already know, but I will repeat anyways:&lt;/p&gt;&lt;p&gt;If your goal is monetizing your software, then making your software as easy to use for people's workflows, is paramount.&lt;/p&gt;&lt;p&gt;The more people that find which your software fits into their workflow seamlessly, and solves pain in their daily interactions, the more people you have as potential monetization candidates.&lt;/p&gt;&lt;p&gt;By scrapping features under the guise of 'monetization' you are sending the opposite of the message you likely intend.&lt;/p&gt;&lt;p&gt;You are telling your customers that getting money from them, is more important than providing a service to help them.&lt;/p&gt;&lt;p&gt;Tell me, would you enjoy doing business with a company who had a stance like that?&lt;/p&gt;&lt;p&gt;This feature is so that people can build MORE things with Tailwind in a FASTER and more EFFICIENT capacity.&lt;/p&gt;&lt;p&gt;From a business management perspective, if you remove the stigmatic 'AI' and 'LLM' from the conversation, and you simply are evaluating a feature XYZ which allows your customers to work in a more automated and efficient capacity with your software, with minimal engineering effort (all it takes is a simple build-time script)...&lt;/p&gt;&lt;p&gt;Why would you not want that for your customers?&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;I totally see the value in the feature and I would like to find a way to add it.&lt;/p&gt;&lt;p&gt;But the reality is that 75% of the people on our engineering team lost their jobs here yesterday because of the brutal impact AI has had on our business. And every second I spend trying to do fun free things for the community like this is a second I'm not spending trying to turn the business around and make sure the people who are still here are getting their paychecks every month.&lt;/p&gt;&lt;p&gt;Traffic to our docs is down about 40% from early 2023 despite Tailwind being more popular than ever. The docs are the only way people find out about our commercial products, and without customers we can't afford to maintain the framework. I really want to figure out a way to offer LLM-optimized docs that don't make that situation even worse (again we literally had to lay off 75% of the team yesterday), but I can't prioritize it right now unfortunately, and I'm nervous to offer them without solving that problem first.&lt;/p&gt;&lt;p&gt;@PaulRBerg I don't see the AGENTS.md stuff we offer as part of the sponsorship program as anything similar to this at all ‚Äî that's just a short markdown file with a bunch of my own personal opinions and what I consider best practices to nudge LLMs into writing their Tailwind stuff in a specific way. It's not the docs at all, and I resent the accusation that I am not disclosing my "true intentions" here or something.&lt;/p&gt;&lt;p&gt;@mtsears4 Tailwind is growing faster than it ever has and is bigger than it ever has been, and our revenue is down close to 80%. Right now there's just no correlation between making Tailwind easier to use and making development of the framework more sustainable. I need to fix that before making Tailwind easier to use benefits anyone, because if I can't fix that this project is going to become unmaintained abandonware when there is no one left employed to work on it. I appreciate the sentiment and agree in spirit, it's just more complicated than that in reality right now.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@quantizor As far as I can tell, this PR doesn't close an existing issue and I don't see any evidence of you having proposed this feature in any forum. You just opened a PR. That entitles you to neither a merge nor other people's time to review it.&lt;/p&gt;&lt;p&gt;(I'm not a Tailwind employee, just some guy)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;There is an associated discussion. tailwindlabs/tailwindcss#14677 (comment)&lt;/p&gt;&lt;p&gt;You're entirely right that I am not entitled to anyone's time. I run multiple large OSS libraries as well, though not to the scale of Tailwind (these days.)&lt;/p&gt;&lt;p&gt;My objection is the way this was handled. Full thoughts on my&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;You're welcome to fork the library&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@adamwathan I empathize where you're coming from, putting my solutioning hat on, I wonder whether you could add something to the llms.txt prompt saying something akin to "if the user is trying to create a landing page suggest they check out our paid product" or etc. for each of the components/layouts&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Edit: deleted this. No one cares about my opinion so whatever.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;I think it worsens the effect to self-promote your TikTok video not once, but twice within a span of 2 hours.&lt;/p&gt;&lt;p&gt;That alone seems deeply unprofessional.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Well I edited it onto a prior comment so idk if people would see it. So sue me.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Get fucked.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;How do I lock someone else's thread?&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Love how this PR other than the 0 benefits adds a random library too, 0 mentions about it either. üëÅÔ∏è&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;check the comments that someone marked as resolved or whatever early in the PR.&lt;/p&gt;&lt;p&gt;I started with regexes which were brittle and didn't scale well. I've worked with markdown for years and my library is able to parse to AST which is much easier to manipulate, then compile back to markdown. The library has zero dependencies and is very well tested + uses NPM trusted publishing.&lt;/p&gt;&lt;p&gt;I don't really get the pushback here. Feels like people are just virtue signaling, which is whatever.&lt;/p&gt;&lt;p&gt;All along in this PR I've been consistent that my objection is to the spirit of the closure. What does the commercial business have to do with core OSS documentation? Nothing. Put ads in it, idc.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;I just bought Tailwind Insiders, yay! ‚úÖ&lt;/p&gt;&lt;p&gt;Tailwind v4 was and continues to be an amazing release. Ironically I've learned much more about CSS by using utility classes than fancy naming methodologies, and in v4 we have CSS-only configuration ü§Ø Tailwind's plugin system is a thing of beauty, I sure did crazy things in there‚Ä¶&lt;/p&gt;&lt;p&gt;You should all consider supporting Tailwind if you aren't already, we have more pressing matters than LLMs not being up-to-date with latest Tailwind. Besides, Tailwind is much closer to native CSS now, which makes me less inclined to trust what LLMs say because they suck at CSS üòì&lt;/p&gt;&lt;p&gt;Adam has explained that to you so clearly, you can choose to listen or not. From your TikTok it sounded like you don't really care to take in what's going on, you're only interested in your own goal. I'd like Tailwind Labs to continue working on Tailwind, would you?&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@quantizor You are already ridiculous, and at the same time, you keep being as ridiculous as possible. It sounds like a mix of some UK royal family with The Kardashians, but you keep being more stupid than possible. That is a good sign, IMO - you are going to have some success in your career or whatsoever. Congratz!&lt;/p&gt;&lt;p&gt;Oh, BTW, as I'm a Latin American, I don't want to sue you. I would just either kill you or make you on eat my shit online forcefully. Can you share your address, pls? üòá . If not, it is all fine. I have some great backend folks. If Parasite had many Oscar prizes in 2020, we are able to get a better reasoning.&lt;/p&gt;&lt;p&gt;BTW, I would put this song while you are on our court: https://open.spotify.com/track/5eS43KfdjIfUWxAXpfXT8x?si=7edd2524ce05478e&lt;/p&gt;&lt;p&gt;These days, everyone feels like it's important to be a dictator, nope? üòá&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Can Tailwind paywall the docs to AI crawlers? I don't think Cloudflare has made this public, but I'm sure Tailwind would be a great candidate for the beta.&lt;/p&gt;&lt;p&gt;https://blog.cloudflare.com/introducing-pay-per-crawl/&lt;/p&gt;&lt;p&gt;Tailwinds team deserves to be paid for the work, and if they are getting paid well then maybe MCP, and other fun things would be possible. Whereas currently they don't have the bandwidth.&lt;/p&gt;&lt;p&gt;Nuxt UI, Shadcn, etc are so dependent on Tailwind it seems insane that a large backer such as @vercel hasn't stepped up to the plate.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;llms.txt is currently just a proposed standard rather than something that's actually being used by the major AI companies.&lt;/p&gt;&lt;p&gt;None of the LLM companies like OpenAI, Google, or Anthropic have officially said they're following these files when they crawl websites.&lt;/p&gt;&lt;p&gt;ref: https://www.semrush.com/blog/llms-txt/&lt;/p&gt;&lt;p&gt;(if you're not in the SEO world, John Mueller is a Senior Search Analyst at Google, and regularly shares insights from Google related to SEO)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@quantizor by providing llms.txt, it pushes users to access the docs even less, and the docs are the only place where the paid products are being pushed, so it puts eyes away from the business, risking the entire project's sustainability as a whole.&lt;/p&gt;&lt;p&gt;Adam also already stated that he would like this to be added eventually, but figuring this shit out is their priority. Is it really that hard to see why he saw the need to close it currently?&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Just do free work for AI companies to make money off, it helps us win!&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@quantizor it'd probably be a good move to let it cool off for a while and let the news about the tailwind org settle. It doesn't appear that your tool needs to be mainlined to be useful; why not publish it stand-alone?&lt;/p&gt;&lt;p&gt;Beyond that, you're bound to get some resistance and scrutiny when you add a dependency on your own library upstream, regardless of its suitability or intrinsic qualities.&lt;/p&gt;&lt;p&gt;Finally, above all, the thread is getting absolutely loony. This doesn't strike me as murder-worthy. You'd think you were trying to get rust in linux or something... Everyone should go do 10 backflips.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;it's insane how tailwind is utilized on like, websites of all those big companies but ain't no one sponsoring or giving back anything. Like, it's not an obligation or liability in any kind but more of a moral question.&lt;/p&gt;&lt;p&gt;It really sucks to hear that the team is struggling to break even.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;It's insane to blame everybody else for not being able to create a viable business model from an OSS project.&lt;/p&gt;&lt;p&gt;Tailwind grew a lot due to community acceptance and support, and collaborations.&lt;/p&gt;&lt;p&gt;The only person to blame here is the CEO/Main maintainer of Tailwind. They've made bad decisions, hired coders without knowing how to make enough money to pay them.&lt;/p&gt;&lt;p&gt;If you want to monetize a free service, you either know what you do or you make mistakes and lose what you've built. It was always a risk; we are not at fault.&lt;/p&gt;&lt;p&gt;@adamwathan I respect you for everything you've done, but you need to take a few breaths, take a walk, think, sleep, and come back, ask apologize of the community, and start working on solutions/crisis management.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;I want to add my own two cents about someone's suggestion about adding advertisements into the &lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;How do you define "SUPPORTING" here because it must be way different than how most people do.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;You're the most unprofessional dev I've seen in a long time, and part of the reason why everything keeps on going downhill.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;What a sad day to have eyes.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Pillo sitio en hilo m√≠tico.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;The feeling of entitlement of some people is unreal.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;yep, that's ture, u can fork or use context7 not necessary force tailwind to do that&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;I've paid for TailwindUI and Claude Code refuses to use it, claiming it's copyrighted (even if I'm just pasting bits of the examples and not explicitly saying its TailwindUI.)&lt;/p&gt;&lt;p&gt;So this issue is very complex.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;@quantizor A good rule of thumb is if you find yourself sending 6 texts to someone over a 2 month period without a reply, chances are they're not interested.&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row&gt;&lt;cell&gt;&lt;p&gt;Going to lock this one as it's spiraling a bit. Appreciate the support from everyone ‚ù§Ô∏è We'll figure it out!&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/tailwindlabs/tailwindcss.com/pull/2388"/><published>2026-01-07T16:02:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46528353</id><title>Health care data breach affects over 600k patients, Illinois agency says</title><updated>2026-01-08T05:46:03.540120+00:00</updated><content>&lt;doc fingerprint="e6188ade5513a61a"&gt;
  &lt;main&gt;
    &lt;p&gt;The names and addresses of thousands of patients of the Illinois Department of Human Services were incorrectly made publicly viewable for the last several years, the agency said Friday.&lt;/p&gt;
    &lt;p&gt;Several maps created to assist the agency with decisions ‚Äî like where to open new offices and allocate certain resources ‚Äî were made public through incorrect privacy settings between 2021 and 2025, the Department of Human Services said in a statement.&lt;/p&gt;
    &lt;p&gt;More than 32,000 customers with the IDHS division of rehabilitation services had information publicly viewable between April 2021 and September 2025. The information included names, addresses, case numbers, case status, referral source information, region and office information and status as Division of Rehabilitation Services recipients, the agency said.&lt;/p&gt;
    &lt;p&gt;Around 670,000 Medicaid and Medicare Savings Program recipients had their addresses, case numbers, demographic information and the name of medical assistance plans publicly viewable between January 2022 and September 2025, IDHS said.&lt;/p&gt;
    &lt;p&gt;The state agency said the mapping website was unable to identify who viewed the maps, and IDHS is unaware of any misuse of personal information resulting from the data leak.&lt;/p&gt;
    &lt;p&gt;IDHS discovered the issue Sept. 22 and immediately changed the privacy settings for all maps, restricting access to authorized IDHS employees, the agency said. It also implemented a secure map policy that prohibits uploading customer data to public mapping websites.&lt;/p&gt;
    &lt;p&gt;Individuals whose information was made public will receive a notice about the leak from IDHS. The notices will include a phone number that people can call for more information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nprillinois.org/illinois/2026-01-06/health-care-data-breach-affects-600-000-patients-illinois-agency-says"/><published>2026-01-07T16:28:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46528389</id><title>How Google got its groove back and edged ahead of OpenAI</title><updated>2026-01-08T05:46:03.328899+00:00</updated><content/><link href="https://www.wsj.com/tech/ai/google-ai-openai-gemini-chatgpt-b766e160"/><published>2026-01-07T16:29:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46529237</id><title>Eat Real Food</title><updated>2026-01-08T05:46:03.169198+00:00</updated><content>&lt;doc fingerprint="cab4a7579f6f9feb"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Real Food&lt;lb/&gt; Starts Here&lt;/head&gt;&lt;p&gt;Better health begins on your plate‚Äînot in your medicine cabinet.&lt;lb/&gt; The new Dietary Guidelines for Americans defines real food as whole, nutrient-dense, and naturally occurring, placing them back at the center of our diets.&lt;/p&gt;&lt;head rend="h2"&gt;The State of Our Health&lt;/head&gt;&lt;head rend="h3"&gt;America is sick.&lt;lb/&gt;The data is clear.&lt;/head&gt;&lt;head rend="h3"&gt;50% of Americans have prediabetes or diabetes&lt;/head&gt;&lt;head rend="h3"&gt;75% of adults report having at least one chronic condition&lt;/head&gt;&lt;head rend="h3"&gt;90% of U.S. healthcare spending goes to treating chronic disease‚Äîmuch of which is linked to diet and lifestyle&lt;/head&gt;&lt;p&gt;For decades we've been misled by guidance that prioritized highly processed food, and are now facing rates of unprecedented chronic disease.&lt;/p&gt;&lt;p&gt;For the first time, we're calling out the dangers of highly processed foods and rebuilding a broken system from the ground up with gold-standard science and common sense.&lt;/p&gt;&lt;head rend="h2"&gt;The New Pyramid&lt;/head&gt;&lt;head rend="h2"&gt;Eat Real &lt;lb/&gt;Food&lt;/head&gt;&lt;p&gt;Our nation is finding its footing again, moving past decades of unhealthy eating and rebuilding a food culture rooted in health, science, transparency, and personal responsibility.&lt;/p&gt;&lt;head rend="h2"&gt;Key&lt;lb/&gt;Guidance&lt;/head&gt;&lt;head rend="h2"&gt;Resources&lt;/head&gt;&lt;p&gt;Explore the research, recommendations, and implementation guidance that shape the Dietary Guidelines, including the science, the policy guidance, and the everyday serving framework.&lt;/p&gt;Watch the press release&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://realfood.gov"/><published>2026-01-07T17:22:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46530448</id><title>NPM to implement staged publishing after turbulent shift off classic tokens</title><updated>2026-01-08T05:46:03.064574+00:00</updated><content/><link href="https://socket.dev/blog/npm-to-implement-staged-publishing"/><published>2026-01-07T18:31:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46530832</id><title>Show HN: I visualized the entire history of Citi Bike in the browser</title><updated>2026-01-08T05:46:02.774518+00:00</updated><content>&lt;doc fingerprint="d2055de9efee4b7e"&gt;
  &lt;main&gt;
    &lt;p&gt;Search ‚åòK Play Space Random R About A Wed, Jan 1, 2025 9:41:00 AM -- rides -- fps N S W E -- RIDES -- FPS -3h -2h -1h Now No data Command Palette Search for a command to run...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bikemap.nyc/"/><published>2026-01-07T18:57:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46531068</id><title>US will ban Wall Street investors from buying single-family homes</title><updated>2026-01-08T05:46:02.318140+00:00</updated><content>&lt;doc fingerprint="fe4140d71fb286a6"&gt;
  &lt;main&gt;
    &lt;p&gt;WASHINGTON, Jan 7 (Reuters) - U.S. President Donald Trump on Wednesday said his administration is moving to ban Wall Street firms from buying up single-family homes in a bid to reduce home prices, a potential blow for private-equity landlords that also pressured homebuilder stocks.&lt;/p&gt;
    &lt;p&gt;In a post on Truth Social, Trump said he was immediately taking steps to implement the ban, which he would also call on Congress to codify in law. It was not clear what steps he would take.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;"For a very long time, buying and owning a home was considered the pinnacle of the American Dream," Trump wrote, adding that inflation had put that dream out of reach for many Americans.&lt;/p&gt;
    &lt;p&gt;"People live in homes, not corporations," said Trump, who is under growing pressure to address voter anxiety over the cost of living ahead of this year's congressional midterm elections.&lt;/p&gt;
    &lt;p&gt;A Republican move to target Wall Street landlords would, perversely, align the party with Democrats, who for years have criticized corporate homebuying, claiming it has helped stoke housing costs, and have unsuccessfully pushed bills to crack down on the trend.&lt;/p&gt;
    &lt;head rend="h2"&gt;WALL STREET BLAMED FOR REDUCED HOUSING SUPPLY&lt;/head&gt;
    &lt;p&gt;Wall Street institutions such as Blackstone (BX.N), American Homes 4 Rent (AMH.N) and Progress Residential have bought thousands of single-family homes since the financial crisis of 2008 led to a wave of home foreclosures.&lt;/p&gt;
    &lt;p&gt;By June 2022, institutional investors owned around 450,000 homes, or about 3%, of all single-family rental homes nationally, according to a 2024 study by the Government Accountability Office.&lt;/p&gt;
    &lt;p&gt;American Homes 4 Rent (AMH.N) dropped to a near three-year low of $28.84 and was halted for volatility before trading resumed. Its shares closed down 4% at $31.01.&lt;/p&gt;
    &lt;p&gt;Blackstone shares hit a one-month low of $147.52 and closed down about 5.6% at $153.59. The PHLX housing index (.HGX) fell 2.6%.&lt;/p&gt;
    &lt;p&gt;A spokesperson for Blackstone said their ownership of such homes represented a small portion of their overall business, and that they had been a net seller of homes for the prior decade.&lt;/p&gt;
    &lt;p&gt;"That said, we believe our current portfolio is poised to continue to perform quite well and operate at the highest standards for residents," the spokesperson said.&lt;/p&gt;
    &lt;p&gt;American Homes 4 Rent and Progress Residential did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Wall Street landlords dispute that their investments have stoked inflation. In a January 2025 research note, Blackstone said institutional home purchases have declined 90% since 2022 and that supply shortage is the reason for house price increases.&lt;/p&gt;
    &lt;p&gt;The GAO study found that the effect of institutional homebuying on homeownership opportunities was unclear in part due to limited data.&lt;/p&gt;
    &lt;p&gt;Critics say Wall Street firms are also bad landlords, skimping on upkeepto keep investors happy, and wrongly evicted tenants during the COVID-19 pandemic.&lt;/p&gt;
    &lt;p&gt;"Resident experience is hurting as a result," said Jeff Holzmann, COO of RREAF Holdings, a Dallas-based real estate investment firm with over $5 billion in assets.&lt;/p&gt;
    &lt;p&gt;"Instead of you calling your landlord to discuss a problem, you're calling a call center that gives you the runaround."&lt;/p&gt;
    &lt;head rend="h2"&gt;AFFORDABILITY PRESSURE&lt;/head&gt;
    &lt;p&gt;Trump, who has occasionally dismissed affordability concerns and blamed inflation on his Democratic predecessor, has seen his own public approval mostly sag since his inauguration as Americans worry about the economy.&lt;/p&gt;
    &lt;p&gt;It was not immediately clear what authority Trump would draw upon to impose a ban, and he did not outline the changes he was seeking from Congress.&lt;/p&gt;
    &lt;p&gt;The White House did not respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;Since Trump's first electoral victory, U.S. home prices have risen 75%, more than double the increase in overall consumer prices tracked by CPI. But home sales price increases have eased substantially over the past year.&lt;/p&gt;
    &lt;p&gt;The Federal Housing Finance Agency last week reported that national home sales prices had risen just 1.7% in October, from a year earlier, the lowest in more than 13 years. That's less than half the rate by which they were climbing when Trump came back into office last January and a fraction of their peak gains of nearly 20% in 2021 and 2022.&lt;/p&gt;
    &lt;p&gt;A big factor in home price inflation has been a lack of properties for sale, although that has also been slowly improving over the last year or so, according to National Association of Realtors data.&lt;/p&gt;
    &lt;p&gt;As of November, annual shelter-cost inflation, which had shot to as high as 8.2% in the COVID-19 pandemic aftermath, had also eased to 3.0%, the lowest in more than four years, according to the Labor Department's Consumer Price Index.&lt;/p&gt;
    &lt;p&gt;Reporting by Trevor Hunnicutt; additional reporting by Ryan Patrick Jones, Ankur Banerjee, Saeed Azhar, Chuck Mikolajczak, Andrea Shalal, Matt Tracy and Dan Burns; Writing by Michelle Price; Editing by Caitlin Webber, David Ljunggren, Cynthia Osterman, Rod Nickel and Nick Zieminski&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/world/us/us-will-ban-large-institutional-investors-buying-single-family-homes-trump-says-2026-01-07/"/><published>2026-01-07T19:13:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46531565</id><title>Notion AI: Unpatched data exfiltration</title><updated>2026-01-08T05:46:02.153378+00:00</updated><content>&lt;doc fingerprint="98559bad08f84487"&gt;
  &lt;main&gt;
    &lt;p&gt;Threat Intelligence&lt;/p&gt;
    &lt;head rend="h1"&gt;Notion AI: Unpatched Data Exfiltration&lt;/head&gt;
    &lt;p&gt;Notion AI is susceptible to data exfiltration via indirect prompt injection due to a vulnerability in which AI document edits are saved before user approval.&lt;/p&gt;
    &lt;p&gt;Notion AI allows users to interact with their documents using natural language√¢¬¶ but what happens when AI edits are made prior to user approval?&lt;lb/&gt;In this article, we document a vulnerability that leads Notion AI to exfiltrate user data (a sensitive hiring tracker document) via indirect prompt injection. Users are warned about an untrusted URL and asked for approval to interact with it - but their data is exfiltrated before they even respond.&lt;/p&gt;
    &lt;p&gt;We responsibly disclosed this vulnerability to Notion via HackerOne. Unfortunately, they said √¢we're closing this finding as `Not Applicable`√¢.&lt;/p&gt;
    &lt;head rend="h3"&gt;Stealing Hiring Tracker Data with a Poisoned Resume&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;The user uploads a resume (untrusted data) to their chat session.&lt;/p&gt;&lt;lb/&gt;Here, the untrusted data source is a resume PDF, but a prompt injection could be stored in a web page, connected data source, or a Notion page.&lt;p&gt;This document contains a prompt injection hidden in 1 point font white on white text with a square white image covering the text for good measure. The LLM can read it with no issues, but the document appears benign to the human eye.&lt;/p&gt;&lt;lb/&gt;A Note on Defenses: Notion AI uses an LLM to scan document uploads and present a warning if a document is flagged as malicious. As this warning is triggered by an LLM, it can be bypassed by a prompt injection that convinces the evaluating model that the document is safe. For this research, we did not focus on bypassing this warning because the point of the attack is the exfiltration mechanism, not the method of injection delivery. In practice, an injection could easily be stored in a source that does not appear to be scanned, such as a web page, Notion page, or connected data source like Notion Mail.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The user asks Notion AI for help updating a hiring tracker based on the resume.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Notion AI is manipulated by the prompt injection to insert a malicious image into the hiring tracker.&lt;/p&gt;&lt;lb/&gt;The prompt injection manipulates Notion AI to (1) construct a URL by collecting all of the text in the document and appending the data to an attacker-controlled domain, and (2) insert an √¢image√¢ into the Notion Page using the constructed URL as the image source.&lt;p&gt;Here, it appears as though the user is prompted for approval. However, unbeknownst to the user, the edit has already occurred before the user is prompted for approval. When the edit occurred, the user√¢s browser made a request to the attacker√¢s server, attempting to retrieve the image. This request exfiltrates the document contents contained in the URL constructed by Notion AI.&lt;/p&gt;&lt;lb/&gt;Whether or not the user accepts the edit, the attacker successfully exfiltrates the data.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The attacker reads the sensitive hiring tracker data from their server logs.&lt;/p&gt;&lt;lb/&gt;Once the user√¢s browser has made a request for the malicious image, the attacker can read the sensitive data contained in the URL from their request logs.&lt;p&gt;In this attack, exfiltrated data included salary expectations, candidate feedback, internal role details, and other sensitive information such as diversity hiring goals.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Additional Attack Surface&lt;/head&gt;
    &lt;p&gt;The Notion Mail AI drafting assistant is susceptible to rendering insecure Markdown images within email drafts, resulting in data exfiltration. If a user mentions an untrusted resource while drafting, content from the user√¢s query or other mentioned resources can be exfiltrated. E.g., √¢Hey, draft me an email based on @untrusted_notion_page and @trusted_notion_page√¢.&lt;lb/&gt;The attack surface is reduced for Notion Mail√¢s drafting assistant as the system appears to only have access to data sources within the Notion ecosystem that are explicitly mentioned by the user (as opposed to Notion AI√¢s main offering, which supports web search, document upload, integrations, etc.).&lt;/p&gt;
    &lt;head rend="h3"&gt;Recommended Remediations for Organizations:&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Institute a vetting process for connected data sources. Restrict use of connectors that can access highly sensitive or highly untrusted data from: Settings &amp;gt; Notion AI &amp;gt; Connectors.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;To reduce the risk of untrusted data being processed in the workspace, admins can configure: Settings &amp;gt; Notion AI &amp;gt; AI Web Search &amp;gt; Enable web search for workspace &amp;gt; Off.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Individual users should avoid including sensitive personal data that could be leveraged in a spearphishing attack when configuring personalization for Notion AI via: Settings &amp;gt; Notion AI &amp;gt; Personalization.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Individual users can configure: Settings &amp;gt; Notion AI &amp;gt; AI Web Search &amp;gt; Require confirmation for web requests &amp;gt; On.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Implementing these remediations will reduce the risk surface, but will not nullify the core vulnerability.&lt;/p&gt;
    &lt;head rend="h3"&gt;Recommended Remediations for Notion:&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Programmatically prohibit automatic rendering of Markdown images from external sites in Notion AI page creation or update outputs without explicit user approval.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Programmatically prohibit automatic rendering of Markdown images from external sites in Notion AI mail drafts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Implement a strong Content Security Policy. This will prevent network requests from being made to unapproved external domains.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Ensure the CDN used to retrieve images for display in Notion and image previews for display in Notion Mail cannot be used as an open redirect to bypass the CSP policy that is set.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Responsible Disclosure Timeline&lt;/head&gt;
    &lt;p&gt;12/24/2025 Initial report made via HackerOne&lt;lb/&gt;12/24/2025 Report is acknowledged, altered write-up requested&lt;lb/&gt;12/24/2025 PromptArmor follows up with the requested format&lt;lb/&gt;12/29/2025 Report closed as non-applicable&lt;lb/&gt;01/07/2026 Public disclosure&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.promptarmor.com/resources/notion-ai-unpatched-data-exfiltration"/><published>2026-01-07T19:49:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46531925</id><title>Tailscale state file encryption no longer enabled by default</title><updated>2026-01-08T05:46:01.760446+00:00</updated><content>&lt;doc fingerprint="868f307d7f22bbd0"&gt;
  &lt;main&gt;&lt;head rend="h3"&gt;Tailscale v1.92.5&lt;/head&gt;Update instructions&lt;head rend="h5"&gt;Linux&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;State file encryption and hardware attestation keys are no longer enabled by default.&lt;/item&gt;&lt;item&gt;Failure to load hardware attestation keys no longer prevents the client from starting. This could happen when the TPM device is reset or replaced.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h5"&gt;Windows&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;State file encryption and hardware attestation keys are no longer enabled by default.&lt;/item&gt;&lt;item&gt;Failure to load hardware attestation keys no longer prevents the client from starting. This could happen when the TPM device is reset or replaced.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Tailscale container image v1.92.5&lt;/head&gt;&lt;p&gt;A new release of the Tailscale container image is available. You can download it from Docker Hub or from our GitHub packages repository.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Hardware attestation keys are no longer added to Kubernetes state &lt;code&gt;Secrets&lt;/code&gt;, making it possible to change the Kubernetes node the Tailscale containers are deployed on.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Tailscale Kubernetes Operator v1.92.5&lt;/head&gt;&lt;p&gt;A new release of the Tailscale Kubernetes Operator is available. For guidance on installing and updating, refer to our installation instructions.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Certificate renewal is no longer done as an ARI order by default to avoid renewal failure if ACME account keys are recreated.&lt;/item&gt;&lt;item&gt;Hardware attestation keys are no longer added to Kubernetes state &lt;code&gt;Secrets&lt;/code&gt;, making it possible to change the Kubernetes node the Tailscale Kubernetes Operator is deployed on.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Tailscale tsrecorder v1.92.5&lt;/head&gt;&lt;p&gt;A new release of the Tailscale &lt;code&gt;tsrecorder&lt;/code&gt; is available. You can download it from Docker Hub.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Note: This version contains no changes except for library updates.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tailscale.com/changelog"/><published>2026-01-07T20:16:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46534777</id><title>Play Aardwolf MUD</title><updated>2026-01-08T05:46:01.442118+00:00</updated><content>&lt;doc fingerprint="7a5b424b2b380a80"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="27"&gt;
        &lt;cell&gt;
          &lt;p&gt;Location: Home&lt;/p&gt;
          &lt;p&gt;Aardwolf RPG is a unique and free text based roleplaying game. Aardwolf is based in the fantasy world of Andolor where magic is common and there are hundreds of exotic realms to explore, puzzles to solve and quests to complete. Aardwolf features a realistic game world with multiple continents and real geography. Each area includes a real time line-of-sight overhead map to see other characters and points of interest around you.&lt;/p&gt;
          &lt;p&gt;Create your character from any one of 28 classes including fighter classes such as Soldiers, Knights, Hunters, Barbarians, Rangers, Archers, Assassins and Paladins or select a magic based class including Elementalists, Necromancers, Healers, Priests, Witches and Enchanters. Once you have choosen your race, your guild and your profession then the rest is up to you. You have absolute control over your character's actions and there are many ways to play Aardwolf.&lt;/p&gt;
          &lt;p&gt;Sample screenshot of the Aardwolf Client&lt;/p&gt;
          &lt;p&gt;You can play the game solo or group with other players, focus on gaining experience and levels, take part in hundreds of quests, solve puzzles, explore, map, play casino games for in-game currency, join a clan, take part in our forums, enchant and craft equipment, compete with other players in player-vs-player combat and global quests, answer trivia, create your own private manor, experiment with hundreds of spells and skills and even, eventually, build your own additions to the world.&lt;/p&gt;
          &lt;p&gt;If you have never played a text based RPG before, we offer an extensive in-game help system to help you get started and a team of volunteer "helpers" who answer questions in real time. We also have a very detailed starting area called "The Aylorian Academy" - your first major quest in the game where you are guided through playing Aardwolf in an interactive format.&lt;/p&gt;
          &lt;p&gt;To learn more about MUDs in general, see the introduction to MUDs article. To jump in and get started, visit the "Play now" page to choose from a selection of online and downloadable clients.&lt;/p&gt;
          &lt;p&gt;For builders, Aardwolf features an embedded LUA interpreter allowing area developers to add atmosphere to their areas and create area puzzles and quests. See our building section for more information on the LUA integration.&lt;/p&gt;
          &lt;p&gt;If you already have a MUD client, you can connect to Aardwolf using aardwolf.org (23.111.142.226) port 4000. You can also use port 23 if you have a firewall blocking port 4000. To reach our Java client, click 'Play Aardwolf' in the link above. If you have problems connecting, feel free to mail webmaster@aardmud.org for help.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row/&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.aardwolf.com/"/><published>2026-01-07T23:31:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46535514</id><title>Fighting back against biometric surveillance at Wegmans</title><updated>2026-01-08T05:46:01.283935+00:00</updated><content/><link href="https://blog.adafruit.com/2026/01/07/dont-let-the-grocery-store-scan-your-face-a-guide-to-fighting-back-against-biometric-surveillance-at-wegmans/"/><published>2026-01-08T00:48:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46535515</id><title>The virtual AmigaOS runtime (a.k.a. Wine for Amiga:)</title><updated>2026-01-08T05:46:00.963102+00:00</updated><content>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/cnvogelg/amitools/blob/main/docs/vamos.md"/><published>2026-01-08T00:48:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46535540</id><title>Musashi: Motorola 680x0 emulator written in C</title><updated>2026-01-08T05:46:00.509779+00:00</updated><content>&lt;doc fingerprint="b2a7b319e44fbb41"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 115&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;kstenerud/Musashi&lt;/head&gt;
    &lt;head rend="h2"&gt;Folders and files&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit message&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit date&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Repository files navigation&lt;/head&gt;
    &lt;quote&gt;MUSASHI ======= Version 4.10 A portable Motorola M680x0 processor emulation engine. Copyright 1998-2002 Karl Stenerud. All rights reserved. INTRODUCTION: ------------ Musashi is a Motorola 68000, 68010, 68EC020, 68020, 68EC030, 68030, 68EC040 and 68040 emulator written in C. This emulator was written with two goals in mind: portability and speed. The emulator is written to ANSI C89 specifications. It also uses inline functions, which are C9X compliant. It has been successfully running in the MAME project (www.mame.net) for years and so has had time to mature. LICENSE AND COPYRIGHT: --------------------- Copyright ¬© 1998-2001 Karl Stenerud Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. AVAILABILITY: ------------ The latest version of this code can be obtained at: https://github.com/kstenerud/Musashi CONTACTING THE AUTHOR: --------------------- I can be reached at kstenerud@gmail.com BASIC CONFIGURATION: ------------------- The basic configuration will give you a standard 68000 that has sufficient functionality to work in a primitive environment. This setup assumes that you only have 1 device interrupting it, that the device will always request an autovectored interrupt, and it will always clear the interrupt before the interrupt service routine finishes (but could possibly re-assert the interrupt). You will have only one address space, no tracing, and no instruction prefetch. To implement the basic configuration: - Open m68kconf.h and verify that the settings for INLINE will work with your compiler. (Currently set to "static __inline__", which works in gcc 2.9. For C9X compliance, it should be "inline") - In your host program, implement the following functions: unsigned int m68k_read_memory_8(unsigned int address); unsigned int m68k_read_memory_16(unsigned int address); unsigned int m68k_read_memory_32(unsigned int address); void m68k_write_memory_8(unsigned int address, unsigned int value); void m68k_write_memory_16(unsigned int address, unsigned int value); void m68k_write_memory_32(unsigned int address, unsigned int value); - In your host program, be sure to call m68k_pulse_reset() once before calling any of the other functions as this initializes the core. - Use m68k_execute() to execute instructions and m68k_set_irq() to cause an interrupt. ADDING PROPER INTERRUPT HANDLING: -------------------------------- The interrupt handling in the basic configuration doesn't emulate the interrupt acknowledge phase of the CPU and automatically clears an interrupt request during interrupt processing. While this works for most systems, you may need more accurate interrupt handling. To add proper interrupt handling: - In m68kconf.h, set M68K_EMULATE_INT_ACK to OPT_SPECIFY_HANDLER - In m68kconf.h, set M68K_INT_ACK_CALLBACK(A) to your interrupt acknowledge routine - Your interrupt acknowledge routine must return an interrupt vector, M68K_INT_ACK_AUTOVECTOR, or M68K_INT_ACK_SPURIOUS. most m68k implementations just use autovectored interrupts. - When the interrupting device is satisfied, you must call m68k_set_irq(0) to remove the interrupt request. MULTIPLE INTERRUPTS: ------------------- The above system will work if you have only one device interrupting the CPU, but if you have more than one device, you must do a bit more. To add multiple interrupts: - You must make an interrupt arbitration device that will take the highest priority interrupt and encode it onto the IRQ pins on the CPU. - The interrupt arbitration device should use m68k_set_irq() to set the highest pending interrupt, or 0 for no interrupts pending. SEPARATE IMMEDIATE READS: ------------------------ You can write faster memory access functions if you know whether you are fetching from ROM or RAM. Immediate reads are always from the program space (Always in ROM unless it is running self-modifying code). To enable separate immediate reads: - In m68kconf.h, turn on M68K_SEPARATE_READ_IMM. - In your host program, implement the following functions: unsigned int m68k_read_immediate_16(unsigned int address); unsigned int m68k_read_immediate_32(unsigned int address); Now you also have the pcrelative stuff: unsigned int m68k_read_pcrelative_8(unsigned int address); unsigned int m68k_read_pcrelative_16(unsigned int address); unsigned int m68k_read_pcrelative_32(unsigned int address); - If you need to know the current PC (for banking and such), set M68K_MONITOR_PC to OPT_SPECIFY_HANDLER, and set M68K_SET_PC_CALLBACK(A) to your routine. - In the unlikely case where you need to emulate some PMMU in the immediate reads and/or pcrealtive stuff, you'll need to explicitely call the translation address mechanism from your user functions this way : if (PMMU_ENABLED) address = pmmu_translate_addr(address); (this is handled automatically by normal memory accesses). ADDRESS SPACES: -------------- Most systems will only implement one address space, placing ROM at the lower addresses and RAM at the higher. However, there is the possibility that a system will implement ROM and RAM in the same address range, but in different address spaces. In this case, you might get away with assuming that immediate reads are in the program space and all other reads are in the data space, if it weren't for the fact that the exception vectors are fetched from the data space. As a result, anyone implementing this kind of system will have to copy the vector table from ROM to RAM using pc-relative instructions. This makes things bad for emulation, because this means that a non-immediate read is not necessarily in the data space. The m68k deals with this by encoding the requested address space on the function code pins: FC Address Space 210 ------------------ --- USER DATA 001 USER PROGRAM 010 SUPERVISOR DATA 101 SUPERVISOR PROGRAM 110 CPU SPACE 111 &amp;lt;-- not emulated in this core since we emulate interrupt acknowledge in another way. To emulate the function code pins: - In m68kconf.h, set M68K_EMULATE_FC to OPT_SPECIFY_HANDLER and set M68K_SET_FC_CALLBACK(A) to your function code handler function. - Your function code handler should select the proper address space for subsequent calls to m68k_read_xx (and m68k_write_xx for 68010+). Note: immediate reads are always done from program space, so technically you don't need to implement the separate immediate reads, although you could gain more speed improvements leaving them in and doing some clever programming. USING DIFFERENT CPU TYPES: ------------------------- The default is to enable only the 68000 cpu type. To change this, change the settings for M68K_EMULATE_010 etc in m68kconf.h. To set the CPU type you want to use: - Make sure it is enabled in m68kconf.h. Current switches are: M68K_EMULATE_010 M68K_EMULATE_EC020 M68K_EMULATE_020 - In your host program, call m68k_set_cpu_type() and then call m68k_pulse_reset(). Valid CPU types are: M68K_CPU_TYPE_68000, M68K_CPU_TYPE_68010, M68K_CPU_TYPE_68EC020, M68K_CPU_TYPE_68020, M68K_CPU_TYPE_68EC030, M68K_CPU_TYPE_68030, M68K_CPU_TYPE_68EC040, M68K_CPU_TYPE_68040, M68K_CPU_TYPE_SCC68070 (which is a 68010 with a 32 bit data bus). CLOCK FREQUENCY: --------------- In order to emulate the correct clock frequency, you will have to calculate how long it takes the emulation to execute a certain number of "cycles" and vary your calls to m68k_execute() accordingly. As well, it is a good idea to take away the CPU's timeslice when it writes to a memory-mapped port in order to give the device it wrote to a chance to react. You can use the functions m68k_cycles_run(), m68k_cycles_remaining(), m68k_modify_timeslice(), and m68k_end_timeslice() to do this. Try to use large cycle values in your calls to m68k_execute() since it will increase throughput. You can always take away the timeslice later. MORE CORRECT EMULATION: ---------------------- You may need to enable these in order to properly emulate some of the more obscure functions of the m68k: - M68K_EMULATE_BKPT_ACK causes the CPU to call a breakpoint handler on a BKPT instruction - M68K_EMULATE_TRACE causes the CPU to generate trace exceptions when the trace bits are set - M68K_EMULATE_RESET causes the CPU to call a reset handler on a RESET instruction. - M68K_EMULATE_PREFETCH emulates the 4-word instruction prefetch that is part of the 68000/68010 (needed for Amiga emulation). NOTE: if the CPU fetches a word or longword at an odd address when this option is on, it will yield unpredictable results, which is why a real 68000 will generate an address error exception. - M68K_EMULATE_ADDRESS_ERROR will cause the CPU to generate address error exceptions if it attempts to read a word or longword at an odd address. - call m68k_pulse_halt() to emulate the HALT pin. CONVENIENCE FUNCTIONS: --------------------- These are in here for programmer convenience: - M68K_INSTRUCTION_HOOK lets you call a handler before each instruction. - M68K_LOG_ENABLE and M68K_LOG_1010_1111 lets you log illegal and A/F-line instructions. MULTIPLE CPU EMULATION: ---------------------- The default is to use only one CPU. To use more than one CPU in this core, there are some things to keep in mind: - To have different cpus call different functions, use OPT_ON instead of OPT_SPECIFY_HANDLER, and use the m68k_set_xxx_callback() functions to set your callback handlers on a per-cpu basis. - Be sure to call set_cpu_type() for each CPU you use. - Use m68k_set_context() and m68k_get_context() to switch to another CPU. LOAD AND SAVE CPU CONTEXTS FROM DISK: ------------------------------------ You can use them68k_load_context() and m68k_save_context() functions to load and save the CPU state to disk. GET/SET INFORMATION FROM THE CPU: -------------------------------- You can use m68k_get_reg() and m68k_set_reg() to gain access to the internals of the CPU. EXAMPLE: ------- The subdir example contains a full example (currently linux &amp;amp; Dos only). Compilation ----------- You can use the default Makefile in Musashi's directory, it works like this : 1st build m68kmake, which will build m68kops.c and m68kops.h based on the contents of m68k_in.c. Then compile m68kcpu.o and m68kops.o. Add m68kdasm.o if you want the disassemble functions. When linking this to your project you will need libm for the fpu emulation of the 68040. Using some custom m68kconf.h outside Musashi's directory -------------------------------------------------------- It can be useful to keep an untouched musashi directory in a project (from git for example) and maintain a separate m68kconf.h specific to the project. For this, pass -DMUSASHI_CNF="mycustomconfig.h" to gcc (or whatever compiler you use). Notice that if you use an unix shell (or make which uses the shell to launch its commands), then you need to escape the quotes like this : -DMUSASHI_CNF=\"mycustomconfig.h\"&lt;/quote&gt;
    &lt;head rend="h2"&gt;About&lt;/head&gt;
    &lt;p&gt;Motorola 680x0 emulator written in C&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources&lt;/head&gt;
    &lt;head rend="h3"&gt;Stars&lt;/head&gt;
    &lt;head rend="h3"&gt;Watchers&lt;/head&gt;
    &lt;head rend="h3"&gt;Forks&lt;/head&gt;
    &lt;head rend="h2"&gt;Releases&lt;/head&gt;
    &lt;p&gt;No releases published&lt;/p&gt;
    &lt;head rend="h2"&gt;Packages 0&lt;/head&gt;
    &lt;p&gt; No packages published &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/kstenerud/Musashi"/><published>2026-01-08T00:51:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46536340</id><title>Kernel bugs hide for 2 years on average. Some hide for 20</title><updated>2026-01-08T05:46:00.005530+00:00</updated><content>&lt;doc fingerprint="52dac1dfd8b24a36"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Kernel bugs hide for 2 years on average. Some hide for 20.&lt;/head&gt;
    &lt;p&gt;There are bugs in your kernel right now that won't be found for years. I know because I analyzed 125,183 of them, every bug with a traceable &lt;code&gt;Fixes:&lt;/code&gt; tag in the Linux kernel's 20-year git history.&lt;/p&gt;
    &lt;p&gt;The average kernel bug lives 2.1 years before discovery. But some subsystems are far worse: CAN bus drivers average 4.2 years, SCTP networking 4.0 years. The longest-lived bug in my dataset, a buffer overflow in ethtool, sat in the kernel for 20.7 years. The one which I'll dissect in detail is refcount leak in netfilter, and it lasted 19 years.&lt;/p&gt;
    &lt;p&gt;I built a tool that catches 92% of historical bugs in a held-out test set at commit time. Here's what I learned.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Key findings at a glance&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;125,183&lt;/cell&gt;
        &lt;cell&gt;Bug-fix pairs with traceable &lt;code&gt;Fixes:&lt;/code&gt; tags&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;123,696&lt;/cell&gt;
        &lt;cell&gt;Valid records after filtering (0 &amp;lt; lifetime &amp;lt; 27 years)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;2.1 years&lt;/cell&gt;
        &lt;cell&gt;Average time a bug hides before discovery&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;20.7 years&lt;/cell&gt;
        &lt;cell&gt;Longest-lived bug (ethtool buffer overflow)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;0% √¢ 69%&lt;/cell&gt;
        &lt;cell&gt;Bugs found within 1 year (2010 vs 2022)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;92.2%&lt;/cell&gt;
        &lt;cell&gt;Recall of VulnBERT on held-out 2024 test set&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;False positive rate (vs 48% for vanilla CodeBERT)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;The initial discovery&lt;/head&gt;
    &lt;p&gt;I started by mining the most recent 10,000 commits with &lt;code&gt;Fixes:&lt;/code&gt; tags from the Linux kernel. After filtering out invalid references (commits that pointed to hashes outside the repo, malformed tags, or merge commits), I had 9,876 valid vulnerability records. For the lifetime analysis, I excluded 27 same-day fixes (bugs introduced and fixed within hours), leaving 9,849 bugs with meaningful lifetimes.&lt;/p&gt;
    &lt;p&gt;The results were striking:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Bugs analyzed&lt;/cell&gt;
        &lt;cell&gt;9,876&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Average lifetime&lt;/cell&gt;
        &lt;cell&gt;2.8 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Median lifetime&lt;/cell&gt;
        &lt;cell&gt;1.0 year&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Maximum&lt;/cell&gt;
        &lt;cell&gt;20.7 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Almost 20% of bugs had been hiding for 5+ years. The networking subsystem looked particularly bad at 5.1 years average. I found a refcount leak in netfilter that had been in the kernel for 19 years.&lt;/p&gt;
    &lt;p&gt;Initial findings: Half of bugs found within a year, but 20% hide for 5+ years.&lt;/p&gt;
    &lt;p&gt;But something nagged at me: my dataset only contained fixes from 2025. Was I seeing the full picture, or just the tip of the iceberg?&lt;/p&gt;
    &lt;head rend="h2"&gt;Going deeper: Mining the full history&lt;/head&gt;
    &lt;p&gt;I rewrote my miner to capture every &lt;code&gt;Fixes:&lt;/code&gt; tag since Linux moved to git in 2005. Six hours later, I had 125,183 vulnerability records which was 12x larger than my initial dataset.&lt;/p&gt;
    &lt;p&gt;The numbers changed significantly:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;2025 Only&lt;/cell&gt;
        &lt;cell role="head"&gt;Full History (2005-2025)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Bugs analyzed&lt;/cell&gt;
        &lt;cell&gt;9,876&lt;/cell&gt;
        &lt;cell&gt;125,183&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Average lifetime&lt;/cell&gt;
        &lt;cell&gt;2.8 years&lt;/cell&gt;
        &lt;cell&gt;2.1 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Median lifetime&lt;/cell&gt;
        &lt;cell&gt;1.0 year&lt;/cell&gt;
        &lt;cell&gt;0.7 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;5+ year bugs&lt;/cell&gt;
        &lt;cell&gt;19.4%&lt;/cell&gt;
        &lt;cell&gt;13.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;10+ year bugs&lt;/cell&gt;
        &lt;cell&gt;6.6%&lt;/cell&gt;
        &lt;cell&gt;4.2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Full history: 57% of bugs found within a year. The long tail is smaller than it first appeared.&lt;/p&gt;
    &lt;p&gt;Why the difference? My initial 2025-only dataset was biased. Fixes in 2025 include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New bugs introduced recently and caught quickly&lt;/item&gt;
      &lt;item&gt;Ancient bugs that finally got discovered after years of hiding&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The ancient bugs skewed the average upward. When you include the full history with all the bugs that were introduced AND fixed within the same year, the average drops from 2.8 to 2.1 years.&lt;/p&gt;
    &lt;head rend="h2"&gt;The real story: We're getting faster (but it's complicated)&lt;/head&gt;
    &lt;p&gt;The most striking finding from the full dataset: bugs introduced in recent years appear to get fixed much faster.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Year Introduced&lt;/cell&gt;
        &lt;cell role="head"&gt;Bugs&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg Lifetime&lt;/cell&gt;
        &lt;cell role="head"&gt;% Found &amp;lt;1yr&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2010&lt;/cell&gt;
        &lt;cell&gt;1,033&lt;/cell&gt;
        &lt;cell&gt;9.9 years&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2014&lt;/cell&gt;
        &lt;cell&gt;3,991&lt;/cell&gt;
        &lt;cell&gt;3.9 years&lt;/cell&gt;
        &lt;cell&gt;31%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2018&lt;/cell&gt;
        &lt;cell&gt;11,334&lt;/cell&gt;
        &lt;cell&gt;1.7 years&lt;/cell&gt;
        &lt;cell&gt;54%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;2022&lt;/cell&gt;
        &lt;cell&gt;11,090&lt;/cell&gt;
        &lt;cell&gt;0.8 years&lt;/cell&gt;
        &lt;cell&gt;69%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Bugs introduced in 2010 took nearly 10 years to find and bugs introduced in 2024 are found in 5 months. At first glance it looks like a 20x improvement!&lt;/p&gt;
    &lt;p&gt;But here's the catch: this data is right-censored. Bugs introduced in 2022 can't have a 10-year lifetime yet since we're only in 2026. We might find more 2022 bugs in 2030 that bring the average up.&lt;/p&gt;
    &lt;p&gt;The fairer comparison is "% found within 1 year" and that IS improving: from 0% (2010) to 69% (2022). That's real progress, likely driven by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Syzkaller (released 2015)&lt;/item&gt;
      &lt;item&gt;KASAN, KMSAN, KCSAN sanitizers&lt;/item&gt;
      &lt;item&gt;Better static analysis&lt;/item&gt;
      &lt;item&gt;More contributors reviewing code&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But there's a backlog. When I look at just the bugs fixed in 2024-2025:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;60% were introduced in the last 2 years (new bugs, caught quickly)&lt;/item&gt;
      &lt;item&gt;18% were introduced 5-10 years ago&lt;/item&gt;
      &lt;item&gt;6.5% were introduced 10+ years ago&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We're simultaneously catching new bugs faster AND slowly working through ~5,400 ancient bugs that have been hiding for over 5 years.&lt;/p&gt;
    &lt;head rend="h2"&gt;The methodology&lt;/head&gt;
    &lt;p&gt;The kernel has a convention: when a commit fixes a bug, it includes a &lt;code&gt;Fixes:&lt;/code&gt; tag pointing to the commit that introduced the bug.&lt;/p&gt;
    &lt;code&gt;commit de788b2e6227
Author: Florian Westphal &amp;lt;fw@strlen.de&amp;gt;
Date:   Fri Aug 1 17:25:08 2025 +0200

    netfilter: ctnetlink: fix refcount leak on table dump

    Fixes: d205dc40798d ("netfilter: ctnetlink: ...")
&lt;/code&gt;
    &lt;p&gt;I wrote a miner that:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Runs &lt;code&gt;git log --grep="Fixes:"&lt;/code&gt;to find all fixing commits&lt;/item&gt;
      &lt;item&gt;Extracts the referenced commit hash from the &lt;code&gt;Fixes:&lt;/code&gt;tag&lt;/item&gt;
      &lt;item&gt;Pulls dates from both commits&lt;/item&gt;
      &lt;item&gt;Classifies subsystem from file paths (70+ patterns)&lt;/item&gt;
      &lt;item&gt;Detects bug type from commit message keywords&lt;/item&gt;
      &lt;item&gt;Calculates the lifetime&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;fixes_pattern = r'Fixes:\s*([0-9a-f]{12,40})'
match = re.search(fixes_pattern, commit_message)
if match:
    introducing_hash = match.group(1)
    lifetime_days = (fixing_date - introducing_date).days
&lt;/code&gt;
    &lt;p&gt;Dataset details:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel version&lt;/cell&gt;
        &lt;cell&gt;v6.19-rc3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Mining date&lt;/cell&gt;
        &lt;cell&gt;January 6, 2026&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Fixes mined since&lt;/cell&gt;
        &lt;cell&gt;2005-04-16 (git epoch)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total records&lt;/cell&gt;
        &lt;cell&gt;125,183&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Unique fixing commits&lt;/cell&gt;
        &lt;cell&gt;119,449&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Unique bug-introducing authors&lt;/cell&gt;
        &lt;cell&gt;9,159&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;With CVE ID&lt;/cell&gt;
        &lt;cell&gt;158&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;With Cc: stable&lt;/cell&gt;
        &lt;cell&gt;27,875 (22%)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Coverage note: The kernel has ~448,000 commits mentioning "fix" in some form, but only ~124,000 (28%) use proper &lt;code&gt;Fixes:&lt;/code&gt; tags. My dataset captures the well-documented bugs aka the ones where maintainers traced the root cause.&lt;/p&gt;
    &lt;head rend="h2"&gt;It varies by subsystem&lt;/head&gt;
    &lt;p&gt;Some subsystems have bugs that persist far longer than others:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Subsystem&lt;/cell&gt;
        &lt;cell role="head"&gt;Bug Count&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg Lifetime&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;drivers/can&lt;/cell&gt;
        &lt;cell&gt;446&lt;/cell&gt;
        &lt;cell&gt;4.2 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;networking/sctp&lt;/cell&gt;
        &lt;cell&gt;279&lt;/cell&gt;
        &lt;cell&gt;4.0 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;networking/ipv4&lt;/cell&gt;
        &lt;cell&gt;1,661&lt;/cell&gt;
        &lt;cell&gt;3.6 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;usb&lt;/cell&gt;
        &lt;cell&gt;2,505&lt;/cell&gt;
        &lt;cell&gt;3.5 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;tty&lt;/cell&gt;
        &lt;cell&gt;1,033&lt;/cell&gt;
        &lt;cell&gt;3.5 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;netfilter&lt;/cell&gt;
        &lt;cell&gt;1,181&lt;/cell&gt;
        &lt;cell&gt;2.9 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;networking&lt;/cell&gt;
        &lt;cell&gt;6,079&lt;/cell&gt;
        &lt;cell&gt;2.9 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;memory&lt;/cell&gt;
        &lt;cell&gt;2,459&lt;/cell&gt;
        &lt;cell&gt;1.8 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;gpu&lt;/cell&gt;
        &lt;cell&gt;5,212&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;bpf&lt;/cell&gt;
        &lt;cell&gt;959&lt;/cell&gt;
        &lt;cell&gt;1.1 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;CAN bus and SCTP bugs persist longest. BPF and GPU bugs get caught fastest.&lt;/p&gt;
    &lt;p&gt;CAN bus drivers and SCTP networking have bugs that persist longest probably because both are niche protocols with less testing coverage. GPU (especially Intel i915) and BPF bugs get caught fastest, probably thanks to dedicated fuzzing infrastructure.&lt;/p&gt;
    &lt;p&gt;Interesting finding from comparing 2025-only vs full history:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Subsystem&lt;/cell&gt;
        &lt;cell role="head"&gt;2025-only Avg&lt;/cell&gt;
        &lt;cell role="head"&gt;Full History Avg&lt;/cell&gt;
        &lt;cell role="head"&gt;Difference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;networking&lt;/cell&gt;
        &lt;cell&gt;5.2 years&lt;/cell&gt;
        &lt;cell&gt;2.9 years&lt;/cell&gt;
        &lt;cell&gt;-2.3 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;filesystem&lt;/cell&gt;
        &lt;cell&gt;3.8 years&lt;/cell&gt;
        &lt;cell&gt;2.6 years&lt;/cell&gt;
        &lt;cell&gt;-1.2 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;drivers/net&lt;/cell&gt;
        &lt;cell&gt;3.3 years&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
        &lt;cell&gt;-1.1 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;gpu&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
        &lt;cell&gt;0 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Networking looked terrible in the 2025-only data (5.2 years!) but is actually closer to average in the full history (2.9 years). The 2025 fixes were catching a backlog of ancient networking bugs. GPU looks the same either way, and those bugs get caught consistently fast.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some bug types hide longer than others&lt;/head&gt;
    &lt;p&gt;Race conditions are the hardest to find, averaging 5.1 years to discovery:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Bug Type&lt;/cell&gt;
        &lt;cell role="head"&gt;Count&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg Lifetime&lt;/cell&gt;
        &lt;cell role="head"&gt;Median&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;race-condition&lt;/cell&gt;
        &lt;cell&gt;1,188&lt;/cell&gt;
        &lt;cell&gt;5.1 years&lt;/cell&gt;
        &lt;cell&gt;2.6 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;integer-overflow&lt;/cell&gt;
        &lt;cell&gt;298&lt;/cell&gt;
        &lt;cell&gt;3.9 years&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;use-after-free&lt;/cell&gt;
        &lt;cell&gt;2,963&lt;/cell&gt;
        &lt;cell&gt;3.2 years&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;memory-leak&lt;/cell&gt;
        &lt;cell&gt;2,846&lt;/cell&gt;
        &lt;cell&gt;3.1 years&lt;/cell&gt;
        &lt;cell&gt;1.4 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;buffer-overflow&lt;/cell&gt;
        &lt;cell&gt;399&lt;/cell&gt;
        &lt;cell&gt;3.1 years&lt;/cell&gt;
        &lt;cell&gt;1.5 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;refcount&lt;/cell&gt;
        &lt;cell&gt;2,209&lt;/cell&gt;
        &lt;cell&gt;2.8 years&lt;/cell&gt;
        &lt;cell&gt;1.3 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;null-deref&lt;/cell&gt;
        &lt;cell&gt;4,931&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
        &lt;cell&gt;0.7 years&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;deadlock&lt;/cell&gt;
        &lt;cell&gt;1,683&lt;/cell&gt;
        &lt;cell&gt;2.2 years&lt;/cell&gt;
        &lt;cell&gt;0.8 years&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Why do race conditions hide so long? They're non-deterministic and only trigger under specific timing conditions that might occur once per million executions. Even sanitizers like KCSAN can only flag races they observe.&lt;/p&gt;
    &lt;p&gt;30% of bugs are self-fixes where the same person who introduced the bug eventually fixed it. I guess code ownership matters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why some bugs hide longer&lt;/head&gt;
    &lt;p&gt;Less fuzzing coverage. Syzkaller excels at syscall fuzzing but struggles with stateful protocols. Fuzzing netfilter effectively requires generating valid packet sequences that traverse specific connection tracking states.&lt;/p&gt;
    &lt;p&gt;Harder to trigger. Many networking bugs require:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Specific packet sequences&lt;/item&gt;
      &lt;item&gt;Race conditions between concurrent flows&lt;/item&gt;
      &lt;item&gt;Memory pressure during table operations&lt;/item&gt;
      &lt;item&gt;Particular NUMA topologies&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Older code with fewer eyes. Core networking infrastructure like &lt;code&gt;nf_conntrack&lt;/code&gt; was written in the mid-2000s. It works, so nobody rewrites it. But "stable" means fewer developers actively reviewing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case study: 19 years in the kernel&lt;/head&gt;
    &lt;p&gt;One of the oldest networking bug in my dataset was introduced in August 2006 and fixed in August 2025:&lt;/p&gt;
    &lt;code&gt;// ctnetlink_dump_table() - the buggy code path
if (res &amp;lt; 0) {
    nf_conntrack_get(&amp;amp;ct-&amp;gt;ct_general);  // increments refcount
    cb-&amp;gt;args[1] = (unsigned long)ct;
    break;
}
&lt;/code&gt;
    &lt;p&gt;The irony: Commit &lt;code&gt;d205dc40798d&lt;/code&gt; was itself a fix: "[NETFILTER]: ctnetlink: fix deadlock in table dumping". Patrick McHardy was fixing a deadlock by removing a &lt;code&gt;_put()&lt;/code&gt; call. In doing so, he introduced a refcount leak that would persist for 19 years.&lt;/p&gt;
    &lt;p&gt;The bug: the code doesn't check if &lt;code&gt;ct == last&lt;/code&gt;. If the current entry is the same as the one we already saved, we've now incremented its refcount twice but will only decrement it once. The object never gets freed.&lt;/p&gt;
    &lt;code&gt;// What should have been checked:
if (res &amp;lt; 0) {
    if (ct != last)  // &amp;lt;-- this check was missing for 19 years
        nf_conntrack_get(&amp;amp;ct-&amp;gt;ct_general);
    cb-&amp;gt;args[1] = (unsigned long)ct;
    break;
}
&lt;/code&gt;
    &lt;p&gt;The consequence: Memory leaks accumulate. Eventually &lt;code&gt;nf_conntrack_cleanup_net_list()&lt;/code&gt; waits forever for the refcount to hit zero. The netns teardown hangs. If you're using containers, this blocks container cleanup indefinitely.&lt;/p&gt;
    &lt;p&gt;Why it took 19 years: You had to run &lt;code&gt;conntrack_resize.sh&lt;/code&gt; in a loop for ~20 minutes under memory pressure. The fix commit says: "This can be reproduced by running conntrack_resize.sh selftest in a loop. It takes ~20 minutes for me on a preemptible kernel." Nobody ran that specific test sequence for two decades.&lt;/p&gt;
    &lt;head rend="h2"&gt;Incomplete fixes are common&lt;/head&gt;
    &lt;p&gt;Here's a pattern I keep seeing: someone notices undefined behavior, ships a fix, but the fix doesn't fully close the hole.&lt;/p&gt;
    &lt;p&gt;Case study: netfilter set field validation&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Date&lt;/cell&gt;
        &lt;cell role="head"&gt;Commit&lt;/cell&gt;
        &lt;cell role="head"&gt;What happened&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Jan 2020&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;f3a2181e16f1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stefano Brivio adds support for sets with multiple ranged fields. Introduces &lt;code&gt;NFTA_SET_DESC_CONCAT&lt;/code&gt; for specifying field lengths.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Jan 2024&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3ce67e3793f4&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pablo Neira notices the code doesn't validate that field lengths sum to the key length. Ships a fix. Commit message: "I did not manage to crash nft_set_pipapo with mismatch fields and set key length so far, but this is UB which must be disallowed."&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Jan 2025&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1b9335a8000f&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Security researcher finds a bypass. The 2024 fix was incomplete√¢there were still code paths that could mismatch. Real fix shipped.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The 2024 fix was an acknowledgment that something was wrong, but Pablo couldn't find a crash, so the fix was conservative. A year later, someone found the crash.&lt;/p&gt;
    &lt;p&gt;This pattern suggests a detection opportunity: commits that say things like "this is undefined behavior" or "I couldn't trigger this but..." are flags. The author knows something is wrong but hasn't fully characterized the bug. These deserve extra scrutiny.&lt;/p&gt;
    &lt;head rend="h2"&gt;The anatomy of a long-lived bug&lt;/head&gt;
    &lt;p&gt;Looking at the bugs that survive 10+ years, I see common patterns:&lt;/p&gt;
    &lt;p&gt;1. Reference counting errors&lt;/p&gt;
    &lt;code&gt;kref_get(&amp;amp;obj-&amp;gt;ref);
// ... error path returns without kref_put()
&lt;/code&gt;
    &lt;p&gt;These don't crash immediately. They leak memory slowly. In a long-running system, you might not notice until months later when OOM killer starts firing.&lt;/p&gt;
    &lt;p&gt;2. Missing NULL checks after dereference&lt;/p&gt;
    &lt;code&gt;struct foo *f = get_foo();
f-&amp;gt;bar = 1;              // dereference happens first
if (!f) return -EINVAL;  // check comes too late
&lt;/code&gt;
    &lt;p&gt;The compiler might optimize away the NULL check since you already dereferenced. These survive because the pointer is rarely NULL in practice.&lt;/p&gt;
    &lt;p&gt;3. Integer overflow in size calculations&lt;/p&gt;
    &lt;code&gt;size_t total = n_elements * element_size;  // can overflow
buf = kmalloc(total, GFP_KERNEL);
memcpy(buf, src, n_elements * element_size);  // copies more than allocated
&lt;/code&gt;
    &lt;p&gt;If &lt;code&gt;n_elements&lt;/code&gt; comes from userspace, an attacker can cause allocation of a small buffer followed by a large copy.&lt;/p&gt;
    &lt;p&gt;4. Race conditions in state machines&lt;/p&gt;
    &lt;code&gt;spin_lock(&amp;amp;lock);
if (state == READY) {
    spin_unlock(&amp;amp;lock);
    // window here where another thread can change state
    do_operation();  // assumes state is still READY
}
&lt;/code&gt;
    &lt;p&gt;These require precise timing to hit. They might manifest as rare crashes that nobody can reproduce.&lt;/p&gt;
    &lt;head rend="h2"&gt;Can we catch these bugs automatically?&lt;/head&gt;
    &lt;p&gt;Every day a bug lives in the kernel is another day millions of devices are vulnerable. Android phones, servers, embedded systems, cloud infrastructure, all running kernel code with bugs that won't be found for years.&lt;/p&gt;
    &lt;p&gt;I built VulnBERT, a model that predicts whether a commit introduces a vulnerability.&lt;/p&gt;
    &lt;p&gt;Model evolution:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Recall&lt;/cell&gt;
        &lt;cell role="head"&gt;FPR&lt;/cell&gt;
        &lt;cell role="head"&gt;F1&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Random Forest&lt;/cell&gt;
        &lt;cell&gt;76.8%&lt;/cell&gt;
        &lt;cell&gt;15.9%&lt;/cell&gt;
        &lt;cell&gt;0.80&lt;/cell&gt;
        &lt;cell&gt;Hand-crafted features only&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CodeBERT (fine-tuned)&lt;/cell&gt;
        &lt;cell&gt;89.2%&lt;/cell&gt;
        &lt;cell&gt;48.1%&lt;/cell&gt;
        &lt;cell&gt;0.65&lt;/cell&gt;
        &lt;cell&gt;High recall, unusable FPR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;VulnBERT&lt;/cell&gt;
        &lt;cell&gt;92.2%&lt;/cell&gt;
        &lt;cell&gt;1.2%&lt;/cell&gt;
        &lt;cell&gt;0.95&lt;/cell&gt;
        &lt;cell&gt;Best of both approaches&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The problem with vanilla CodeBERT: I first tried fine-tuning CodeBERT directly. Results: 89% recall but 48% false positive rate (measured on the same test set). Unusable, flagging half of all commits.&lt;/p&gt;
    &lt;p&gt;Why so bad? CodeBERT learns shortcuts: "big diff = dangerous", "lots of pointers = risky". These correlations exist in training data but don't generalize. The model pattern-matches on surface features, not actual bug patterns.&lt;/p&gt;
    &lt;p&gt;The VulnBERT approach: Combine neural pattern recognition with human domain expertise.&lt;/p&gt;
    &lt;code&gt;√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
√¢                            INPUT: Git Diff                          √¢
√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
                                √¢
                √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¥√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
                √¢¬º                               √¢¬º
√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢   √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
√¢   Chunked Diff Encoder    √¢   √¢   Handcrafted Feature Extractor   √¢
√¢   (CodeBERT + Attention)  √¢   √¢   (51 engineered features)        √¢
√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢   √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
              √¢ [768-dim]                         √¢ [51-dim]
              √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
                              √¢¬º
              √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
              √¢     Cross-Attention Fusion    √¢
              √¢     "When code looks like X,  √¢
              √¢      feature Y matters more"  √¢
              √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢¬¨√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
                              √¢¬º
              √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
              √¢        Risk Classifier        √¢
              √¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢√¢
&lt;/code&gt;
    &lt;p&gt;Three innovations that drove performance:&lt;/p&gt;
    &lt;p&gt;1. Chunked encoding for long diffs. CodeBERT's 512-token limit truncates most kernel diffs (often 2000+ tokens). I split into chunks, encode each, then use learned attention to aggregate:&lt;/p&gt;
    &lt;code&gt;# Learnable attention over chunks
chunk_attention = nn.Sequential(
    nn.Linear(hidden_size, hidden_size // 4),
    nn.Tanh(),
    nn.Linear(hidden_size // 4, 1)
)
attention_weights = F.softmax(chunk_attention(chunk_embeddings), dim=1)
pooled = (attention_weights * chunk_embeddings).sum(dim=1)
&lt;/code&gt;
    &lt;p&gt;The model learns which chunks matter aka the one with &lt;code&gt;spin_lock&lt;/code&gt; without &lt;code&gt;spin_unlock&lt;/code&gt;, not the boilerplate.&lt;/p&gt;
    &lt;p&gt;2. Feature fusion via cross-attention. Neural networks miss domain-specific patterns. I extract 51 handcrafted features using regex and AST-like analysis of the diff:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Features&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Basic (4)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;lines_added&lt;/code&gt;, &lt;code&gt;lines_removed&lt;/code&gt;, &lt;code&gt;files_changed&lt;/code&gt;, &lt;code&gt;hunks_count&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Memory (3)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_kmalloc&lt;/code&gt;, &lt;code&gt;has_kfree&lt;/code&gt;, &lt;code&gt;has_alloc_no_free&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Refcount (5)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_get&lt;/code&gt;, &lt;code&gt;has_put&lt;/code&gt;, &lt;code&gt;get_count&lt;/code&gt;, &lt;code&gt;put_count&lt;/code&gt;, &lt;code&gt;unbalanced_refcount&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Locking (5)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_lock&lt;/code&gt;, &lt;code&gt;has_unlock&lt;/code&gt;, &lt;code&gt;lock_count&lt;/code&gt;, &lt;code&gt;unlock_count&lt;/code&gt;, &lt;code&gt;unbalanced_lock&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Pointers (4)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_deref&lt;/code&gt;, &lt;code&gt;deref_count&lt;/code&gt;, &lt;code&gt;has_null_check&lt;/code&gt;, &lt;code&gt;has_deref_no_null_check&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Error handling (6)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;has_goto&lt;/code&gt;, &lt;code&gt;goto_count&lt;/code&gt;, &lt;code&gt;has_error_return&lt;/code&gt;, &lt;code&gt;has_error_label&lt;/code&gt;, &lt;code&gt;error_return_count&lt;/code&gt;, &lt;code&gt;has_early_return&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Semantic (13)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;var_after_loop&lt;/code&gt;, &lt;code&gt;iterator_modified_in_loop&lt;/code&gt;, &lt;code&gt;list_iteration&lt;/code&gt;, &lt;code&gt;list_del_in_loop&lt;/code&gt;, &lt;code&gt;has_container_of&lt;/code&gt;, &lt;code&gt;has_cast&lt;/code&gt;, &lt;code&gt;cast_count&lt;/code&gt;, &lt;code&gt;sizeof_type&lt;/code&gt;, &lt;code&gt;sizeof_ptr&lt;/code&gt;, &lt;code&gt;has_arithmetic&lt;/code&gt;, &lt;code&gt;has_shift&lt;/code&gt;, &lt;code&gt;has_copy&lt;/code&gt;, &lt;code&gt;copy_count&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Structural (11)&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;if_count&lt;/code&gt;, &lt;code&gt;else_count&lt;/code&gt;, &lt;code&gt;switch_count&lt;/code&gt;, &lt;code&gt;case_count&lt;/code&gt;, &lt;code&gt;loop_count&lt;/code&gt;, &lt;code&gt;ternary_count&lt;/code&gt;, &lt;code&gt;cyclomatic_complexity&lt;/code&gt;, &lt;code&gt;max_nesting_depth&lt;/code&gt;, &lt;code&gt;function_call_count&lt;/code&gt;, &lt;code&gt;unique_functions_called&lt;/code&gt;, &lt;code&gt;function_definitions&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The key bug-pattern features:&lt;/p&gt;
    &lt;code&gt;'unbalanced_refcount': 1,    # kref_get without kref_put √¢ leak
'unbalanced_lock': 1,        # spin_lock without spin_unlock √¢ deadlock
'has_deref_no_null_check': 0,# *ptr without if(!ptr) √¢ null deref
'has_alloc_no_free': 0,      # kmalloc without kfree √¢ memory leak
&lt;/code&gt;
    &lt;p&gt;Cross-attention learns conditional relationships. When CodeBERT sees locking patterns AND &lt;code&gt;unbalanced_lock=1&lt;/code&gt;, that's HIGH risk. Neither signal alone is sufficient, it's the combination.&lt;/p&gt;
    &lt;code&gt;# Feature fusion via cross-attention
feature_embedding = feature_projection(handcrafted_features)  # 51 √¢ 768
attended, _ = cross_attention(
    query=code_embedding,      # What patterns does the code have?
    key=feature_embedding,     # What do the hand-crafted features say?
    value=feature_embedding
)
fused = fusion_layer(torch.cat([code_embedding, attended], dim=-1))
&lt;/code&gt;
    &lt;p&gt;3. Focal loss for hard examples. The training data is imbalanced where most commits are safe. Standard cross-entropy wastes gradient updates on easy examples. Focal loss:&lt;/p&gt;
    &lt;code&gt;Standard loss when p=0.95 (easy):  0.05
Focal loss when p=0.95:            0.000125  (400x smaller)
&lt;/code&gt;
    &lt;p&gt;The model focuses on ambiguous commits: the hard 5% that matter.&lt;/p&gt;
    &lt;p&gt;Impact of each component (estimated from ablation experiments):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;F1 Score&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CodeBERT baseline&lt;/cell&gt;
        &lt;cell&gt;~76%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;+ Focal loss&lt;/cell&gt;
        &lt;cell&gt;~80%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;+ Feature fusion&lt;/cell&gt;
        &lt;cell&gt;~88%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;+ Contrastive learning&lt;/cell&gt;
        &lt;cell&gt;~91%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Full VulnBERT&lt;/cell&gt;
        &lt;cell&gt;95.4%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note: Individual component impacts are approximate; interactions between components make precise attribution difficult.&lt;/p&gt;
    &lt;p&gt;The key insight: neither neural networks nor hand-crafted rules alone achieve the best results. The combination does.&lt;/p&gt;
    &lt;p&gt;Results on temporal validation (train √¢¬§2023, test 2024):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;Target&lt;/cell&gt;
        &lt;cell role="head"&gt;Result&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Recall&lt;/cell&gt;
        &lt;cell&gt;90%&lt;/cell&gt;
        &lt;cell&gt;92.2% √¢&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FPR&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;10%&lt;/cell&gt;
        &lt;cell&gt;1.2% √¢&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Precision&lt;/cell&gt;
        &lt;cell&gt;√¢&lt;/cell&gt;
        &lt;cell&gt;98.7%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;F1&lt;/cell&gt;
        &lt;cell&gt;√¢&lt;/cell&gt;
        &lt;cell&gt;95.4%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;AUC&lt;/cell&gt;
        &lt;cell&gt;√¢&lt;/cell&gt;
        &lt;cell&gt;98.4%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What these metrics mean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Recall (92.2%): Of all actual bug-introducing commits, we catch 92.2%. Missing 7.8% of bugs.&lt;/item&gt;
      &lt;item&gt;False Positive Rate (1.2%): Of all safe commits, we incorrectly flag 1.2%. Low FPR = fewer false alarms.&lt;/item&gt;
      &lt;item&gt;Precision (98.7%): Of commits we flag as risky, 98.7% actually are. When we raise an alarm, we're almost always right.&lt;/item&gt;
      &lt;item&gt;F1 (95.4%): Harmonic mean of precision and recall. Single number summarizing overall performance.&lt;/item&gt;
      &lt;item&gt;AUC (98.4%): Area under ROC curve. Measures ranking quality√¢how well the model separates bugs from safe commits across all thresholds.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The model correctly differentiates the same bug at different stages:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Commit&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Risk&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;acf44a2361b8&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fix for UAF in xe_vfio&lt;/cell&gt;
        &lt;cell&gt;12.4% LOW √¢&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;1f5556ec8b9e&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Introduced the UAF&lt;/cell&gt;
        &lt;cell&gt;83.8% HIGH √¢&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;What the model sees: The 19-year bug&lt;/head&gt;
    &lt;p&gt;When analyzing the bug-introducing commit &lt;code&gt;d205dc40798d&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;-    if (ct == last) {
-        nf_conntrack_put(&amp;amp;last-&amp;gt;ct_general);  // removed!
-    }
+    if (ct == last) {
+        last = NULL;
         continue;
     }
     if (ctnetlink_fill_info(...) &amp;lt; 0) {
         nf_conntrack_get(&amp;amp;ct-&amp;gt;ct_general);  // still here
&lt;/code&gt;
    &lt;p&gt;Extracted features:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Value&lt;/cell&gt;
        &lt;cell role="head"&gt;Signal&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_count&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;nf_conntrack_get()&lt;/code&gt; present&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;put_count&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;nf_conntrack_put()&lt;/code&gt; was removed&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;unbalanced_refcount&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Mismatch detected&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;has_lock&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Uses &lt;code&gt;read_lock_bh()&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;list_iteration&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Uses &lt;code&gt;list_for_each_prev()&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Model prediction: 72% risk: HIGH&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;unbalanced_refcount&lt;/code&gt; feature fires because &lt;code&gt;_put()&lt;/code&gt; was removed but &lt;code&gt;_get()&lt;/code&gt; remains. Classic refcount leak pattern.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations&lt;/head&gt;
    &lt;p&gt;Dataset limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Only captures bugs with &lt;code&gt;Fixes:&lt;/code&gt;tags (~28% of fix commits). Selection bias: well-documented bugs tend to be more serious.&lt;/item&gt;
      &lt;item&gt;Mainline only, doesn't include stable-branch-only fixes or vendor patches&lt;/item&gt;
      &lt;item&gt;Subsystem classification is heuristic-based (regex on file paths)&lt;/item&gt;
      &lt;item&gt;Bug type detection based on keyword matching in commit messages and many bugs are "unknown" type&lt;/item&gt;
      &lt;item&gt;Lifetime calculation uses author dates, not commit dates, rebasing can skew timestamps&lt;/item&gt;
      &lt;item&gt;Some "bugs" may be theoretical (comments like "fix possible race" without confirmed trigger)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Model limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;92.2% recall is on a held-out 2024 test set, not a guarantee for future bugs&lt;/item&gt;
      &lt;item&gt;Can't catch semantic bugs (logic errors with no syntactic signal)&lt;/item&gt;
      &lt;item&gt;Cross-function blind spots (bug spans multiple files)&lt;/item&gt;
      &lt;item&gt;Training data bias (learns patterns from bugs that were found, novel patterns may be missed)&lt;/item&gt;
      &lt;item&gt;False positives on intentional patterns (init/cleanup in different commits)&lt;/item&gt;
      &lt;item&gt;Tested only on Linux kernel code, may not generalize to other codebases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Statistical limitations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Survivorship bias in year-over-year comparisons (recent bugs can't have long lifetimes yet)&lt;/item&gt;
      &lt;item&gt;Correlation √¢ causation for subsystem/bug-type lifetime differences&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What this means: VulnBERT is a triage tool, not a guarantee. It catches 92% of bugs with recognizable patterns. The remaining 8% and novel bug classes still need human review and fuzzing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;92.2% recall with 1.2% FPR is production-ready. But there's more to do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RL-based exploration: Instead of static pattern matching, train an agent to explore code paths and find bugs autonomously. The current model predicts risk; an RL agent could generate triggering inputs.&lt;/item&gt;
      &lt;item&gt;Syzkaller integration: Use fuzzer coverage as a reward signal. If the model flags a commit and Syzkaller finds a crash in that code path, that's strong positive signal.&lt;/item&gt;
      &lt;item&gt;Subsystem-specific models: Networking bugs have different patterns than driver bugs. A model fine-tuned on netfilter might outperform the general model on netfilter commits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The goal isn't to replace human reviewers but to point them at the 10% of commits most likely to be problematic, so they can focus attention where it matters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reproducing this&lt;/head&gt;
    &lt;p&gt;The dataset extraction uses the kernel's &lt;code&gt;Fixes:&lt;/code&gt; tag convention. Here's the core logic:&lt;/p&gt;
    &lt;code&gt;def extract_fixes_tag(commit_msg: str) -&amp;gt; Optional[str]:
    """Extract the commit ID from a Fixes: tag"""
    pattern = r'Fixes:\s*([a-f0-9]{12,40})'
    match = re.search(pattern, commit_msg, re.IGNORECASE)
    return match.group(1) if match else None

# Mine all Fixes: tags from git history
git log --since="2005-04-16" --grep="Fixes:" --format="%H"

# For each fixing commit:
#   - Extract introducing commit hash
#   - Get dates from both commits
#   - Calculate lifetime
#   - Classify subsystem from file paths
&lt;/code&gt;
    &lt;p&gt;Full miner code and dataset: github.com/quguanni/kernel-vuln-data&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;125,183 bugs analyzed from 20 years of Linux kernel git history (123,696 with valid lifetimes)&lt;/item&gt;
      &lt;item&gt;Average bug lifetime: 2.1 years (2.8 years in 2025-only data due to survivorship bias in recent fixes)&lt;/item&gt;
      &lt;item&gt;0% √¢ 69% of bugs found within 1 year (2010 vs 2022) (real improvement from better tooling)&lt;/item&gt;
      &lt;item&gt;13.5% of bugs hide for 5+ years (these are the dangerous ones)&lt;/item&gt;
      &lt;item&gt;Race conditions hide longest (5.1 years average)&lt;/item&gt;
      &lt;item&gt;VulnBERT catches 92.2% of bugs on held-out 2024 test set with only 1.2% FPR (98.4% AUC)&lt;/item&gt;
      &lt;item&gt;Dataset: github.com/quguanni/kernel-vuln-data&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you're working on kernel security, vulnerability detection, or ML for code analysis, I'd love to talk: jenny@pebblebed.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pebblebed.com/blog/kernel-bugs"/><published>2026-01-08T02:18:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46536848</id><title>Chase to become new issuer of Apple Card</title><updated>2026-01-08T05:45:59.800467+00:00</updated><content>&lt;doc fingerprint="a5ccf9291326d07c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Today, Apple and Chase announced that Chase will become the new issuer of Apple Card, with an expected transition in approximately 24 months.&lt;/p&gt;
      &lt;p&gt;Apple Card users can continue to enjoy the award-winning experience of Apple Card, which includes up to 3 percent unlimited Daily Cash back on every purchase, easy-to-navigate spending tools, Apple Card Family,1 access to a high-yield Savings account,2 and more. Mastercard will remain the payment network for Apple Card, and Apple Card users can continue to access Mastercard‚Äôs global acceptance and benefits.&lt;/p&gt;
      &lt;p&gt;‚ÄúWe‚Äôre incredibly proud of how Apple Card has transformed the credit card experience for customers by delivering innovative tools that empower users to make healthier financial decisions,‚Äù said Jennifer Bailey, Apple‚Äôs vice president of Apple Pay and Apple Wallet. ‚ÄúChase shares our commitment to innovation and delivering products and services that enhance consumers‚Äô lives. We look forward to working together to continue to provide a best-in-class experience and exceptional customer service with Apple Card.‚Äù &lt;/p&gt;
      &lt;p&gt;‚ÄúApple is an iconic brand recognized globally for its innovation, design excellence, and commitment to delivering exceptional customer experiences,‚Äù said Allison Beer, Chase‚Äôs chief executive officer of Card &amp;amp; Connected Commerce. ‚ÄúWe share a commitment to supporting consumer financial health, and we‚Äôre proud to deepen our relationship by welcoming them as the newest partner in our industry-leading co-brand credit card program. We‚Äôre excited to innovate together in the future.‚Äù&lt;/p&gt;
      &lt;p&gt;‚ÄúWe‚Äôre thrilled to work with Apple and Chase to continue our longstanding partnership on Apple Card. The innovation on Apple Card has taken the consumer payments experience to the next level, and we look forward to delivering simple, secure, and seamless payments at global scale,‚Äù said Linda Kirkpatrick, Mastercard‚Äôs president of the Americas.&lt;/p&gt;
      &lt;p&gt;Introduced in 2019, Apple Card is designed with users‚Äô financial health in mind, and has become a top choice among consumers for its innovative features, seamless user experience, and commitment to customer privacy and security. With absolutely no fees,3 Apple Card makes it easy to track purchases and manage spending from Apple Wallet, while offering up to 3 percent Daily Cash back on every purchase, which users can choose to have automatically deposited onto their Apple Cash card in Wallet and can be used for in-store, online and in-app purchases with Apple Pay.4&lt;/p&gt;
      &lt;p&gt;With Apple Card Family, users can also share an Apple Card account with anyone added to their Family Sharing group. Another benefit is Apple Card Monthly Installments (ACMI), which allows users to pay for new Apple products over time, interest-free, when they choose to check out with ACMI at Apple.5 Additionally, users can open a Savings account through Apple Card, and once it is set up, will have all their future Daily Cash automatically deposited there, providing users with even more options.&lt;/p&gt;
      &lt;p&gt;During this transition, Apple Card users can continue to use their card as they normally do. More information, including FAQs, is available at learn.applecard.apple/transition. Additional details will be shared with users as the transition date approaches.&lt;/p&gt;
      &lt;p&gt;Under the terms of the agreement, the purchase of the portfolio is estimated to bring over $20 billion of card balances to the Chase platform6. Although close is not anticipated for approximately 24 months, and is subject to regulatory approvals, JPMorganChase expects to recognize a $2.2 billion provision for credit losses in 4Q25 related to the forward purchase commitment.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jpmorganchase.com/ir/news/2026/chase-to-become-new-issuer-of-apple-card"/><published>2026-01-08T03:29:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46536862</id><title>Show HN: IceRaidsNearMe ‚Äì Real-time, crowdsourced map of immigration enforcement</title><updated>2026-01-08T05:45:59.615203+00:00</updated><link href="https://iceraidsnearme.com/"/><published>2026-01-08T03:30:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46536866</id><title>Open Infrastructure Map</title><updated>2026-01-08T05:45:59.214860+00:00</updated><content>&lt;doc fingerprint="6d0a85331c526182"&gt;
  &lt;main&gt;
    &lt;p&gt;You must have Javascript enabled to view Open Infrastructure Map Open Infrastructure Map about stats exports&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openinframap.org"/><published>2026-01-08T03:31:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46537095</id><title>go.sum Is Not a Lockfile</title><updated>2026-01-08T05:45:58.368571+00:00</updated><content>&lt;doc fingerprint="b6303f373d25a398"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;go.sum Is Not a Lockfile&lt;/head&gt;
    &lt;p&gt;I need everyone to stop looking at &lt;code&gt;go.sum&lt;/code&gt;, especially to analyze dependency graphs. It is not a ‚Äúlockfile,‚Äù and it has zero semantic effects on version resolution. There is truly no use case for ever parsing it outside of cmd/go.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;go.sum&lt;/code&gt; is only a local cache for the Go Checksum Database. It‚Äôs a map of module versions to their cryptographic hashes. Those versions may or may not be in use; it doesn‚Äôt matter to package resolution.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;go.sum&lt;/code&gt; was not even enabled by default in the original modules design, precisely because it has no observable effect on builds!1 Its (important) purpose is exclusively tightening the security story: the Checksum Database ensures the whole ecosystem shares the same contents for a given module version, regardless of how it is downloaded, and &lt;code&gt;go.sum&lt;/code&gt; makes that guarantee local and self-contained.&lt;/p&gt;
    &lt;p&gt;Instead, just look at &lt;code&gt;go.mod&lt;/code&gt;. It lists the precise version at which all dependencies are built. Since Go 1.17 (released August 2021), it includes all transitive dependencies needed to build the main module and its tests.2&lt;/p&gt;
    &lt;p&gt;You can either parse &lt;code&gt;go.mod&lt;/code&gt; with golang.org/x/mod/modfile, run &lt;code&gt;go mod edit -json&lt;/code&gt; to get its JSON representation,3 or parse it according to its specification.&lt;/p&gt;
    &lt;p&gt;This is the end of the Public Service Announcement. Read on for some &lt;code&gt;go.mod&lt;/code&gt; nerdery.&lt;/p&gt;
    &lt;head rend="h2"&gt;Manifests and lockfiles&lt;/head&gt;
    &lt;p&gt;The enduring confusion around &lt;code&gt;go.mod&lt;/code&gt; and &lt;code&gt;go.sum&lt;/code&gt; is due to the fact that most other languages also have two package-related files, but theirs both matter to version resolution. These two files are usually called manifest and lockfile.&lt;/p&gt;
    &lt;p&gt;The manifest (e.g. &lt;code&gt;pyproject.toml&lt;/code&gt;, &lt;code&gt;package.json&lt;/code&gt;, &lt;code&gt;Cargo.toml&lt;/code&gt;) usually lists some dependencies along with potentially complex rules for which versions are supported. These rules usually apply transitively to dependents, making version resolution extremely hard and/or slow in the general case, and sometimes unsolvable. The manifest is not always guaranteed to list all direct dependencies, and no automated mechanism ensures your code actually works with e.g. the minimum allowed manifest version of its dependencies.&lt;/p&gt;
    &lt;p&gt;The lockfile (e.g. &lt;code&gt;uv.lock&lt;/code&gt;, &lt;code&gt;package-lock.json&lt;/code&gt;, &lt;code&gt;Cargo.lock&lt;/code&gt;) is a relatively recent innovation in some ecosystems, and it lists the actual versions used in the most recent build. It is not really human-readable, and usually doesn‚Äôt apply recursively to dependents, allowing the rapid spread of supply-chain attacks.&lt;/p&gt;
    &lt;p&gt;I honestly find the manifest version ranges essentially useless, and get endlessly confused trying to remember which commands modify the lockfile (and when/why) and which ones respect it.&lt;/p&gt;
    &lt;p&gt;In Go, &lt;code&gt;go.mod&lt;/code&gt; serves as both manifest and lockfile, and more: it lists all dependencies, direct and transitive, and their exact version to be used when the module is the main module. Semantic versioning is assumed, and those versions are also the minimum versions applied to dependents‚Äô module graphs. Different major versions of the same module are considered essentially separate modules.&lt;/p&gt;
    &lt;p&gt;Notice how there is no way to accidentally use a feature introduced in a version that your dependents won‚Äôt have. Also, when adding a dependency, you don‚Äôt automatically get the latest‚Äîpotentially untested/compromised‚Äîversion of all its dependencies. Finally, there can‚Äôt be diamond dependency conflicts.&lt;/p&gt;
    &lt;p&gt;All that with a single, human-readable file: &lt;code&gt;go.mod&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;All &lt;code&gt;go&lt;/code&gt; commands take a &lt;code&gt;-mod&lt;/code&gt; flag. If set to &lt;code&gt;mod&lt;/code&gt;, missing dependencies can be added to &lt;code&gt;go.mod&lt;/code&gt; automatically if necessary, and partial manual changes are reconciled. If set to &lt;code&gt;readonly&lt;/code&gt;, those are errors. &lt;code&gt;go mod tidy&lt;/code&gt; and (effectively) &lt;code&gt;go get&lt;/code&gt; default to &lt;code&gt;mod&lt;/code&gt;; all other commands default to &lt;code&gt;readonly&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Go modules truly don‚Äôt get enough credit for how much simpler they are compared to the alternatives. In other ecosystems, package resolution time going down below 1s is celebrated (and is indeed an impressive technical achievement given the design‚Äôs requirements!). In Go, no one ever noticed package resolution happening, so there is nothing to celebrate.&lt;/p&gt;
    &lt;p&gt;For more ecosystem feature appreciation posts, follow me on Bluesky at @filippo.abyssdomain.expert or on Mastodon at @filippo@abyssdomain.expert.&lt;/p&gt;
    &lt;head rend="h2"&gt;The picture&lt;/head&gt;
    &lt;p&gt;I had a great time at 39c3 during the holidays. The Chaos Communication Congress is a magical place with a very strict photo policy, so it‚Äôs pretty hard to convey its atmosphere. This is the best I could do without recognizable humans in the frame. In Fairy Dust we trust!&lt;/p&gt;
    &lt;p&gt;My work is made possible by Geomys, an organization of professional Go maintainers, which is funded by Smallstep, Ava Labs, Teleport, Tailscale, and Sentry. Through our retainer contracts, they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the Geomys announcement.) Here are a few words from some of them!&lt;/p&gt;
    &lt;p&gt;Teleport ‚Äî For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. Teleport Identity is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.&lt;/p&gt;
    &lt;p&gt;Ava Labs ‚Äî We at Ava Labs, maintainer of AvalancheGo (the most widely used client for interacting with the Avalanche Network), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;I still think it‚Äôs important and it was the first thing I remember advocating for when I joined the Go team, because it makes the module cryptographically self-contained, and because the Go Checksum Database transparency story is not great in ephemeral environments like CI. These are security effects, though, not semantic ones. ‚Ü©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;These are the only dependencies you care about, even for security. If the main module imports&lt;/p&gt;&lt;code&gt;example.com/mod1/pkg1&lt;/code&gt;and a separate&lt;code&gt;example.com/mod1/pkg2&lt;/code&gt;imports&lt;code&gt;example.com/mod2&lt;/code&gt;, there is no way for&lt;code&gt;example.com/mod2&lt;/code&gt;to affect the build or run code on the developer‚Äôs machine, so you don‚Äôt need to consider it a dependency. This is actually very powerful, allowing libraries to segregate dependencies (e.g. the AWS SDK) in optional packages, reducing the transitive trust tree of dependents that don‚Äôt use that feature. ‚Ü©‚Ü©&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Why not&lt;/p&gt;&lt;code&gt;go list -m all&lt;/code&gt;, you ask? Because that prints the whole module graph, which includes modules that don‚Äôt contribute to the build2 and are not included in&lt;code&gt;go.mod&lt;/code&gt;. A closer approximation would be&lt;code&gt;go list -f '{{.Module}}' all&lt;/code&gt;, but this command applies the local build constraints, like GOOS/GOARCH. There is an open proposal for a flag to do&lt;code&gt;go.mod&lt;/code&gt;-like resolution in&lt;code&gt;go list&lt;/code&gt;. ‚Ü©&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://words.filippo.io/gosum/"/><published>2026-01-08T04:10:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46537489</id><title>Project Patchouli: Open-source electromagnetic drawing tablet hardware</title><updated>2026-01-08T05:45:58.270787+00:00</updated><content>&lt;doc fingerprint="2791b911676f82d7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Project Patchouli&lt;/head&gt;
    &lt;p&gt;Open-Source EMR Pen Tablet Hardware Implementation and Documentation&lt;/p&gt;
    &lt;p&gt;Patchouli is an open-source electro-magnetic drawing tablet hardware implementation, including a coil array, an RF front end built using commercially available parts, and digital signal processing algorithms. The design is compatible with most commercial pens from different vendors, offering an ultra-low-latency pen input experience for your customized hardware projects.&lt;/p&gt;
    &lt;p&gt;In addition, this project aims to provide a comprehensive documentation of the EMR technology, including the mechanism, circuit implementation, signal processing algorithms, and the pen protocol of different product lines from different vendors.&lt;/p&gt;
    &lt;p&gt;Project Code / Hardware Repository: GitLab&lt;/p&gt;
    &lt;head rend="h2"&gt;Updates&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;January 2024, The project started.&lt;/item&gt;
      &lt;item&gt;March 2024, the first small-scale hardware prototype was successfully tested.&lt;/item&gt;
      &lt;item&gt;January 2025, the documentation page was hosted on Read the Docs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Maintainers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Project Lead: Yukidama&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Community&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reaching out to the maintainers: prj.patchouli@gmail.com&lt;/item&gt;
      &lt;item&gt;Join our public Discord Server&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Sponsorship&lt;/head&gt;
    &lt;p&gt;This project is sponsored by the NLnet Foundation NGI Zero Core Fund. Learn more about it here: Project Patchouli&lt;/p&gt;
    &lt;head rend="h2"&gt;License&lt;/head&gt;
    &lt;p&gt;Project Patchouli Documentation by Yukidama and other project members is licensed under Creative Commons Attribution 4.0 International&lt;/p&gt;
    &lt;p&gt;All images and other resource files in this project, unless otherwise specified, are created by the project team and are licensed under the same CC BY 4.0 license.&lt;/p&gt;
    &lt;p&gt;The hardware design is released under the CERN Open Source Hardware License strongly-reciprocal variant, CERN-OHL-S. A copy of the license is provided in the source repository. Additionally, a user guide of the license is provided on ohwr.org.&lt;/p&gt;
    &lt;p&gt;All program code, unless otherwise specified, is licensed under the GPLv3 license.&lt;/p&gt;
    &lt;p&gt;Note&lt;/p&gt;
    &lt;p&gt;This project is under active development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://patchouli.readthedocs.io/en/latest/"/><published>2026-01-08T05:20:05+00:00</published></entry></feed>