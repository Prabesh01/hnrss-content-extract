<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-15T18:58:40.181088+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46629682</id><title>Raspberry Pi's New AI Hat Adds 8GB of RAM for Local LLMs</title><updated>2026-01-15T18:58:46.540466+00:00</updated><content>&lt;doc fingerprint="fe7514741c06875a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Raspberry Pi's new AI HAT adds 8GB of RAM for local LLMs&lt;/head&gt;
    &lt;p&gt;Today Raspberry Pi launched their new $130 AI HAT+ 2 which includes a Hailo 10H and 8 GB of LPDDR4X RAM.&lt;/p&gt;
    &lt;p&gt;With that, the Hailo 10H is capable of running LLMs entirely standalone, freeing the Pi's CPU and system RAM for other tasks. The chip runs at a maximum of 3W, with 40 TOPS of INT8 NPU inference performance in addition to the equivalent 26 TOPS INT4 machine vision performance on the earlier AI HAT with Hailo 8.&lt;/p&gt;
    &lt;p&gt;In practice, it's not as amazing as it sounds.&lt;/p&gt;
    &lt;p&gt;You still can't upgrade the RAM on the Pi, but at least this way if you do have a need for an AI coprocessor, you don't have to eat up the Pi's memory to run things on it.&lt;/p&gt;
    &lt;p&gt;And it's a lot cheaper and more compact than running an eGPU on a Pi. In that sense, it's more useful than the silly NPUs Microsoft forces into their 'AI PCs'.&lt;/p&gt;
    &lt;p&gt;But it's still a solution in search of a problem, in all but the most niche of use cases.&lt;/p&gt;
    &lt;p&gt;Besides feeling like I'm living in the world of the Turbo Encabulator every time I'm testing AI hardware, I find the marketing of these things to be very vague, and the applications not very broad.&lt;/p&gt;
    &lt;p&gt;For example, the Hailo 10H is advertised as being used for a Fujitsu demo of automatic shrink detection for a self-checkout.&lt;/p&gt;
    &lt;p&gt;That's certainly not a worthless use case, but it's not something I've ever needed to do. I have a feeling this board is meant more for development, for people who want to deploy the 10H in other devices, rather than as a total solution to problems individual Pi owners need to solve.&lt;/p&gt;
    &lt;p&gt;Especially when it comes to the headline feature: running inference, like with LLMs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Video&lt;/head&gt;
    &lt;p&gt;I also published a video with all the information in this blog post, but if you enjoy text more than video, scroll on pastâit doesn't offend me!&lt;/p&gt;
    &lt;head rend="h2"&gt;LLM performance on the AI HAT+ 2&lt;/head&gt;
    &lt;p&gt;I ran everything on an 8 gig Pi 5, so I could get an apples-to-apples comparison, running the same models on the Pi's CPU as I did on the AI HAT's NPU.&lt;/p&gt;
    &lt;p&gt;They both have the same 8GB LPDDR4X RAM configuration, so ideally, they'd have similar performance.&lt;/p&gt;
    &lt;p&gt;I tested every model Hailo put out so far, and compared them, Pi 5 versus Hailo 10H:&lt;/p&gt;
    &lt;p&gt;The Pi's built-in CPU trounces the Hailo 10H.&lt;/p&gt;
    &lt;p&gt;The Hailo is only close, really, on Qwen2.5 Coder 1.5B.&lt;/p&gt;
    &lt;p&gt;It is slightly more efficient in most cases:&lt;/p&gt;
    &lt;p&gt;But looking more closely at power draw, we can see why the Hailo doesn't keep up:&lt;/p&gt;
    &lt;p&gt;The Pi's CPU is allowed to max out it's power limits (10W on the SoC), which are a lot higher than the Hailo's (3W).&lt;/p&gt;
    &lt;head rend="h2"&gt;Qwen 30B on a Pi&lt;/head&gt;
    &lt;p&gt;So power holds it back, but the 8 gigs of RAM holds back the LLM use case (vs just running on the Pi's CPU) the most. The Pi 5 can be bought in up to a 16 GB configuration. That's as much as you get in decent consumer graphics cards1.&lt;/p&gt;
    &lt;p&gt;Because of that, many quantized medium-size models target 10-12 GB of RAM usage (leaving space for context, which eats up another 2+ GB of RAM).&lt;/p&gt;
    &lt;p&gt;A couple weeks ago, ByteShape got Qwen3 30B A3B Instruct to fit on a 16GB Pi 5. Now this post isn't about LLMs, but the short of it is they found a novel way to compress the model to fit in 10 GB of RAM.&lt;/p&gt;
    &lt;p&gt;A little bit of quality is lost, but like a JPEG, it's still good enough to ace all the contrived tests (like building a TODO list app, or sorting a complex list) that the tiny models I ran on the Hailo 10H didn't complete well (see the video earlier in this post for details).&lt;/p&gt;
    &lt;p&gt;To test the 30B model, I installed llama.cpp following this guide from my blog, and downloaded the compressed model.&lt;/p&gt;
    &lt;p&gt;I asked it to generate a single page TODO list app, and it's still not a speed demon (this is a Pi CPU with LPDDR4x RAM we're talking about), but after a little while, it gave me this:&lt;/p&gt;
    &lt;p&gt;It met all my requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I can type in as many items as I want&lt;/item&gt;
      &lt;item&gt;I can drag them around to rearrange them&lt;/item&gt;
      &lt;item&gt;I can check off items and they go to the bottom of the list...&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It's honestly crazy how many small tasks you can do even with free local models... even on a Pi. Natural Language Programming was just a dream back when I started my career.&lt;/p&gt;
    &lt;p&gt;Besides being angry Google, OpenAI, Anthropic and all these other companies are consuming all the world's money and resources doing this stuffânot to mention destroying the careers of thousands of junior developersâit is kinda neat to see NLP work for very tightly defined examples.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarking computer vision&lt;/head&gt;
    &lt;p&gt;But I don't think this HAT is the best choice to run local, private LLMs (at least not as a primary goal).&lt;/p&gt;
    &lt;p&gt;What it is good for, is vision processing. But the original AI HAT was good for that too!&lt;/p&gt;
    &lt;p&gt;In my testing, Hailo's hailo-rpi5-examples were not yet updated for this new HAT, and even if I specified the Hailo 10H manually, model files would not load, or I ran into errors once the board was detected.&lt;/p&gt;
    &lt;p&gt;But Raspberry Pi's models ran, so I tested them with a Camera Module 3:&lt;/p&gt;
    &lt;p&gt;I pointed it over at my desk, and it was able to pick out things like my keyboard, my monitor (which it thought was a TV), my phone, and even the mouse tucked away in the back.&lt;/p&gt;
    &lt;p&gt;It all ran quite fastâand 10x faster than on the Pi's CPUâbut the problem is I can do the same thing with the original AI HAT ($110)âor the AI Camera ($70).&lt;/p&gt;
    &lt;p&gt;If you just need vision processing, I would stick with one of those.&lt;/p&gt;
    &lt;p&gt;The headline feature of the AI HAT+ 2 is the ability to run in a 'mixed' mode, where it can process machine vision (frames from a camera or video feed), while also running inference (like an LLM or text-to-speech).&lt;/p&gt;
    &lt;p&gt;Unfortunately, when I tried running two models simultaneously, I ran into segmentation faults or 'device not ready', and lacking any working examples from Hailo, I had to give up on getting that working in time for this post.&lt;/p&gt;
    &lt;p&gt;Just like the original AI HAT, there's some growing pains.&lt;/p&gt;
    &lt;p&gt;It seems like with most hardware with "AI" in the name, it's hardware-first, then software comes laterâif it comes at all. At least with Raspberry Pi's track record, the software does come, it's just... often the solutions are only useful in tiny niche use cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;8 GB of RAM is useful, but it's not quite enough to give this HAT an advantage over just paying for the bigger 16GB Pi with more RAM, which will be more flexible and run models faster.&lt;/p&gt;
    &lt;p&gt;The main use case for this HAT might be in power-constrained applications where you need both vision processing and inferencing. But even there... it's hard to say "yes, buy this thing", because for just a few more watts, the Pi could achieve better performance for inference in tandem with the $70 AI Camera or the $110 AI HAT+ for the vision processing.&lt;/p&gt;
    &lt;p&gt;Outside of running tiny LLMs in less than 10 watts, maybe the idea is you use the AI HAT+ 2 as a development kit for designing devices using the 10H like self-checkout scanners (which might not even run on a Pi)? I'm not sure.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;With the obvious caveat that the VRAM on GPUs runs a lot faster than equivalent LPDDR4 RAM on a Pi! ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.jeffgeerling.com/blog/2026/raspberry-pi-ai-hat-2/"/><published>2026-01-15T08:23:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46629957</id><title>Nao Labs (Open-Source Analytics Agent, YC X25) Is Hiring</title><updated>2026-01-15T18:58:46.173658+00:00</updated><content>&lt;doc fingerprint="e9cee3477d95e4ac"&gt;
  &lt;main&gt;
    &lt;p&gt;AI data IDE&lt;/p&gt;
    &lt;p&gt;Founding software engineer — Build the future of data teams experience.&lt;/p&gt;
    &lt;p&gt;Location: Paris 11, France&lt;/p&gt;
    &lt;p&gt;Hello, we're nao Labs&lt;/p&gt;
    &lt;p&gt;We are building an open-source AI agent for data analytics.&lt;/p&gt;
    &lt;p&gt;We are an early stage start-up with 2 cofounders - we joined Y Combinator Spring 2025 batch and STATION F and are now based in Paris 11.&lt;/p&gt;
    &lt;p&gt;We already have a first product - AI IDE for data people - used by 100+ data teams. We are now rolling out a new product - the open source analytics agent. So we’re looking for a founding engineer to help us build it!&lt;/p&gt;
    &lt;p&gt;We are a cofounding team with 18+ years experience in data/AI:&lt;/p&gt;
    &lt;p&gt;We're looking for&lt;/p&gt;
    &lt;p&gt;As a founding engineer, you'll join us to inventing a new, better way to work on data with AI.&lt;/p&gt;
    &lt;p&gt;You will be a fit if...&lt;/p&gt;
    &lt;p&gt;You will&lt;/p&gt;
    &lt;p&gt;You are&lt;/p&gt;
    &lt;p&gt;Tech&lt;/p&gt;
    &lt;p&gt;The product uses these main technologies:&lt;/p&gt;
    &lt;p&gt;Front: React, Typescript&lt;/p&gt;
    &lt;p&gt;Back: node.js, Python&lt;/p&gt;
    &lt;p&gt;Agentic system: Vercel, OpenAI, Anthropic&lt;/p&gt;
    &lt;p&gt;Apply&lt;/p&gt;
    &lt;p&gt;Start Date: Flexible&lt;/p&gt;
    &lt;p&gt;Compensation: competitive salary + early equity&lt;/p&gt;
    &lt;p&gt;Location: Mainly on-site in our Paris 11 office. Remote available.&lt;/p&gt;
    &lt;p&gt;Join us at nao Labs and help shape the future of data work. Let’s build something incredible together!&lt;/p&gt;
    &lt;p&gt;At nao Labs, we are reimagining how data work gets done. Data work is different from traditional software development, and it deserves a specialised workflow. That’s why we’re creating nao—an AI-powered code editor tailored for data workers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/nao-labs/jobs/KjOBhf5-founding-software-engineer"/><published>2026-01-15T08:59:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46629964</id><title>Python: Tprof, a Targeting Profiler</title><updated>2026-01-15T18:58:46.034372+00:00</updated><content>&lt;doc fingerprint="e42e279d26586f91"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Python: introducing tprof, a targeting profiler&lt;/head&gt;
    &lt;p&gt;Profilers measure the performance of a whole program to identify where most of the time is spent. But once youâve found a target function, re-profiling the whole program to see if your changes helped can be slow and cumbersome. The profiler introduces overhead to execution and you have to pick out the stats for the one function you care about from the report. I have often gone through this loop while optimizing client or open source projects, such as when I optimized Djangoâs system checks framework (previous post).&lt;/p&gt;
    &lt;p&gt;The pain here inspired me to create tprof, a targeting profiler for Python 3.12+ that only measures the time spent in specified target functions. Use it to measure your program before and after an optimization to see if it made any difference, with a quick report on the command line.&lt;/p&gt;
    &lt;p&gt;For example, say youâve realized that creating &lt;code&gt;pathlib.Path&lt;/code&gt; objects is the bottleneck for your code. You could run tprof like so:&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmark with comparison mode&lt;/head&gt;
    &lt;p&gt;Sometimes when optimizing code, you want to compare several functions, such as âbeforeâ and âafterâ versions of a function youâre optimizing. tprof supports this with its comparison mode, which adds a âdeltaâ column to the report showing how much faster or slower each function is compared to a baseline.&lt;/p&gt;
    &lt;p&gt;For example, given this code:&lt;/p&gt;
    &lt;code&gt;def before():
    total = 0
    for i in range(100_000):
        total += i
    return total


def after():
    return sum(range(100_000))


for _ in range(100):
    before()
    after()
&lt;/code&gt;
    &lt;p&gt;â¦you can run tprof like this to compare the two functions:&lt;/p&gt;
    &lt;code&gt;$ tprof -x -t before -t after -m example
ð¯ tprof results:
 function         calls total  mean Â± Ï      min â¦ max   delta
 example:before()   100 227ms   2ms Â± 34Î¼s   2ms â¦ 2ms   -
 example:after()    100  86ms 856Î¼s Â± 15Î¼s 835Î¼s â¦ 910Î¼s -62.27%
&lt;/code&gt;
    &lt;p&gt;The output shows that &lt;code&gt;after()&lt;/code&gt; is about 60% faster than &lt;code&gt;before()&lt;/code&gt;, in this case.&lt;/p&gt;
    &lt;head rend="h2"&gt;Python API&lt;/head&gt;
    &lt;p&gt;tprof also provides a Python API via a context manager / decorator, &lt;code&gt;tprof()&lt;/code&gt;. Use it to profile functions within a specific block of code.&lt;/p&gt;
    &lt;p&gt;For example, to recreate the previous benchmarking example within a self-contained Python file:&lt;/p&gt;
    &lt;code&gt;from tprof import tprof


def before():
    total = 0
    for i in range(100_000):
        total += i
    return total


def after():
    return sum(range(100_000))


with tprof(before, after, compare=True):
    for _ in range(100):
        before()
        after()
&lt;/code&gt;
    &lt;p&gt;â¦which produces output like:&lt;/p&gt;
    &lt;code&gt;$ python example.py
ð¯ tprof results:
 function          calls total  mean Â± Ï      min â¦ max delta
 __main__:before()   100 227ms   2ms Â± 83Î¼s   2ms â¦ 3ms -
 __main__:after()    100  85ms 853Î¼s Â± 22Î¼s 835Î¼s â¦ 1ms -62.35%
&lt;/code&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;tprof uses Pythonâs &lt;code&gt;sys.monitoring&lt;/code&gt;, a new API introduced in Python 3.12 for triggering events when functions or lines of code execute. &lt;code&gt;sys.monitoring&lt;/code&gt; allows tprof to register callbacks for only specific target functions, meaning it adds no overhead to the rest of the program. Timing is done in C to further reduce overhead.&lt;/p&gt;
    &lt;p&gt;Thanks to Mark Shannon for contributing sys.monitoring to CPython! This is the second time Iâve used itâthe first time was for tracking down an unexpected mutation (see previous post).&lt;/p&gt;
    &lt;head rend="h2"&gt;Fin&lt;/head&gt;
    &lt;p&gt;If tprof sounds useful to you, please give it a try and let me know what you think! Install tprof from PyPI with your favourite package manager.&lt;/p&gt;
    &lt;p&gt;May you hit your Q1 targets,&lt;/p&gt;
    &lt;p&gt;âAdam&lt;/p&gt;
    &lt;p&gt;ð¸ð¸ð¸ Check out my new book on using GitHub effectively, Boost Your GitHub DX! ð¸ð¸ð¸&lt;/p&gt;
    &lt;p&gt;One summary email a week, no spam, I pinky promise.&lt;/p&gt;
    &lt;p&gt;Related posts:&lt;/p&gt;
    &lt;p&gt;Tags: python&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://adamj.eu/tech/2026/01/14/python-introducing-tprof/"/><published>2026-01-15T09:00:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46630798</id><title>The 3D Software Rendering Technology of 1998's Thief: The Dark Project (2019)</title><updated>2026-01-15T18:58:45.661245+00:00</updated><content>&lt;doc fingerprint="de6941542f66831f"&gt;
  &lt;main&gt;
    &lt;p&gt;In 1998 Looking Glass Studios released the stealth game Thief: The Dark Project. This was just as 3D hardware acceleration was taking off, so due to the development cycle it didn't use hardware acceleration; it was a purely software-rendered game.&lt;/p&gt;
    &lt;p&gt;I was the primary author of the core rendering technology in Thief (although I didn't write the object or character renderers), as well as some related bits and pieces. The same rendering engine, modified by others to use 3D hardware acceleration, also did the rendering for System Shock 2 and Thief 2.&lt;/p&gt;
    &lt;p&gt;The engine was written somewhat contemporaneously with Quake (despite the game being released much later), and the basic appearance strongly resembles Quake. Many of its technologies were copied from or inspired by Quake, but in many cases the way it works is slightly or significantly different.&lt;/p&gt;
    &lt;p&gt;The Quake software rendering was thoroughly documented by Michael Abrash in a series of articles which were reprinted in his Graphics Programming Black Book. The techniques used in Thief were never written up and I thought it might be nice to write them down for once, even if they're now totally irrelevant. I'll try to describe them relative to the probably-more-familiar Quake approaches where possible.&lt;/p&gt;
    &lt;p&gt;Important contemporaneous games with similar rendering technology:&lt;/p&gt;
    &lt;p&gt;Looking Glass games previous to Thief had used grid-based worlds. System Shock 1 and the Ultima Underworlds computed visibility using a grid-based traversal. Thief, however, was totally free-form, so I had to start from scratch to design the Thief engine (which started long before Thief, and I imagine even before we shipped Terra Nova: Strike Force Centauri, which I worked on).&lt;/p&gt;
    &lt;p&gt;Thief was based on the portal-and-cell idea for visibility and occlusion published by Seth Teller in his 1992 PhD dissertation. In fact, the Thief world renderer was called "Portal", but since that name has a newer popular meaning I'll just call it "Thief" or "the Thief engine" (but there was far far more to the Thief engine than just the renderer, such as the object system, AI, physics, and I had nothing to do with them; I didn't write "the Thief engine", just the renderer).&lt;/p&gt;
    &lt;p&gt;I was originally exploring this idea as research for an imagined holy grail for Looking Glass: developing an "indoor-outdoor" CRPG, since the previous LGS CRPGs (Ultima Underworld 1 &amp;amp; 2, System Shock 1) had all been "indoor" dungeons, but we also had this outdoor tech for Terra Nova, and many of us felt we'd want to eventually make a hypothetical Underworld 3 or something which would have dungeons and exteriors and buildings and what not (this was before Daggerfall). In trying to imagine how we could put some kind of a hole in the Terra Nova terrain to incorporate dungeons, I realized that portals could be used to seamlessly integrate multiple independent renderers (like an indoor renderer and an outdoor renderer) by putting portals at the boundaries, so I wrote up a long document over one Christmas vacation documenting my thoughts along those lines. Then I guess I had all these ideas bouncing around in my head, and I knew we didn't have any idea how to do non-grid stuff, and it seemed viable to just try to make a full indoor renderer using portals... so I went ahead and tackled implementing one as research.&lt;/p&gt;
    &lt;p&gt;The portal-and-cell idea was used offline by Quake for computing its precomputed PVS ("potentially visible set")--also described in Seth Teller's dissertation--but Thief used it at runtime; Thief precomputed the portals and cells, but didn't precompute any further visibility information. (I believe Descent, which was released before I even started writing the Thief engine, had already done this, but I don't know the details.)&lt;/p&gt;
    &lt;p&gt;The Thief engine kept a representation of the level in which the open areas (the areas you could see and/or walk) were divided into convex polyhedra known as cells. Each cell contained zero or more visible "world polygons" along the boundaries of the cell that were the visible surfaces of the world. Cells which adjoined other cells had special boundary polygons called "portals" which marked the adjacency between the cells. If you could see into a given cell, then you could see into adjoining cells through the portals to them.&lt;/p&gt;
    &lt;p&gt;To determine what part of the level was currently visible and needed rendering, the engine conducted a breadth-first traversal of the portals and cells starting from the location of the viewpoint. As each portal was traversed, the cells reached were added to the visible list. Each considered portal was transformed in 3D, checked if it was back-facing, and if not it was projected to 2D. Then a "bounding octagon" was generated, which consisted of a regular 2D bounding box and a 45-degree rotated bounding box.&lt;/p&gt;
    &lt;p&gt;If a portal led from cell A to cell B, then we compared that portal's bounding octagon to a bounding octagon of the visiblity of cell A. If the two didn't overlap, then the portal wasn't actually visible. If it was visible, then the intersection of cell A's octagon and the portal's octagon was the part of cell B that was visible through this portal, so it added that to the list. (It was possible you would see into cell B through multiple paths, so the engine had to accumulate all the visible regions, which it did by simply keeping a conservative bounding octagon of all the incoming path octagons along paths. If you had two small view paths into one cell, the two at opposite ends of the cell, the bounding octagon would be much bigger, typically the size of the whole cell.) The cell containing the viewpoint was always fully visible.&lt;/p&gt;
    &lt;p&gt;Quake precomputed similar information: for each cell, Quake stored the list of all other cells that were visible from anywhere in that cell. This result could be less tight; for example, if you had a long corridor with many side rooms, and that long corridor was a single cell, then in Quake it would always try to render all the side rooms, whereas Thief would only try to render the entry cell to each of the side rooms (since those cells would always be adjacent to the corridor and visible), but Thief could cull the rooms themselves if they weren't currently visible.&lt;/p&gt;
    &lt;p&gt;Full cell-portal-analysis didn't scale well to higher polygon counts, so the engine was limping by the time the last game shipped with it (in other words, it had a lot of overhead when hardware accelerated).&lt;/p&gt;
    &lt;p&gt;Quake reduced overdraw by using a span-buffering ("edge list") technique in which world surfaces were (conceptually) drawn front-to-back and each pixel was only drawn exactly once.&lt;/p&gt;
    &lt;p&gt;Thief drew polygons back-to-front, so they did overdraw each other. Thief's overdraw was already reduced compared to Quake's "naive" (pre-edge-list) overdraw because of the tighter bounds from traversing the portals dynamically, as described above.&lt;/p&gt;
    &lt;p&gt;Thief further reduced overdraw by clipping each rendered world polygon by the bounding octagon for the visibility of the cell containing that polygon. (This is part of why bounding octagons were used, as they significantly reduced overdraw in some cases compared to just using bounding boxes. In the limit if we had clipped to the exact portals leading to each cell, this would have resulted in drawing each pixel only once as well.) I don't have any recollection of what our typical overdraw was using this approach.&lt;/p&gt;
    &lt;p&gt;For this to work, Thief had to store world polygons in cells. This means that world polygons that extended through multiple cells had to be split; Quake was often able to preserve those as single polygons since it stored the polygons in a BSP tree directly on split planes. I'm not sure how much difference this made, though, since both Thief and Quake also had to split polygons for surface caching.&lt;/p&gt;
    &lt;p&gt;The 2D clipping to the bounding octagon meant that many Thief polygons ended up being rendered as 8-sided polygons. This wasn't a problem. In fact, clipping was straightforward and efficient since it was purely 2D along simple axes, and there were no S,T (i.e. U,V) texture coordinates on polygon vertices, since Thief used a technique I'd previously published in the PC Game Programmer's Encyclopedia in which the texture coordinates were defined as a 3D vector basis independent of the vertices, and then texture coordinates for spans and pixels were computed directly from the basis vectors.&lt;/p&gt;
    &lt;p&gt;The skybox was drawn just by tagging polygons with a special texture, then when drawing it, taking the transformed 2D polygon and clipping it to each skybox polygon and using the skybox texture mapping for each of them, or something like that. I don't remember 100%.&lt;/p&gt;
    &lt;p&gt;After discovering all the cells that needed rendering, Thief would decide which objects needed rendering. Only objects that were in visible cells might need rendering. However, Thief also computed a 2D bounding box (or probably octagon) of each potentially visible object and compared it against the bounding octagon for any cells containing the object. (Quake had nothing like this since it didn't process portals at runtime.)&lt;/p&gt;
    &lt;p&gt;Because the Thief engine was better about rejecting invisible cells entirely, and was able to reject objects that weren't currently visible even if the cells containing them were, Thief could generally handle more object-dense worlds than a renderer made with Quake technology could have. You couldn't necessarily have more visible objects at once, but you could put more objects in overall as long as you limited where you could see them from, and so Thief generally was able to have well-stocked kitchens and dining tables and sideboards and such.&lt;/p&gt;
    &lt;p&gt;But this was just dumb luck as I hadn't chosen these algorithms for that reason in particular, especially as the engine development long preceded the eventual morphing of the game design into Thief.&lt;/p&gt;
    &lt;p&gt;Quake rendered objects by generating a z-buffer from the world polygons (even though the world polygons themselves didn't z-test), and then testing and updating that z-buffer when rendering objects.&lt;/p&gt;
    &lt;p&gt;Thief didn't use a z-buffer. Instead, Thief drew the world back-to-front ("painter's algorithm"), and interleaved rendering of world polygons and objects to make them appear to occlude each other appropriately.&lt;/p&gt;
    &lt;p&gt;Many games in the software rendering era (which rarely used z-buffers) exhibited sorting issues where objects would become visible through walls or invisible behind walls they shouldn't be, and portals/cells didn't offer any special guarantees that would avoid this problem. (For example, Descent exhibited such problems.)&lt;/p&gt;
    &lt;p&gt;This really bothered me and I worked very hard to fix it. The sorting algorithm in Thief is the most complicated painter's algorithm sorter I've every heard of; I remember having to write a little mathematical proof at one point for one part of it.&lt;/p&gt;
    &lt;p&gt;I don't remember the details, but I'll try and sketch out some of the issues and how it probably worked.&lt;/p&gt;
    &lt;p&gt;Originally the cells were sorted based on the portal-traversal-discovery order, which provided a topological front-to-back sort order that could be reversed for back-to-front rendering. However, there were some issues and so by the time Thief shipped the cells were actually being sorted by a BSP tree. This meant that the sort order was very far from a breadth-first search; if you were near the rootmost split plane, the draw order could feature very-close-to-the-viewer cells drawn before very-far-from-the-viewer cells if the cells and viewer happened to fall on the appropriate sides of some BSP split plane.&lt;/p&gt;
    &lt;p&gt;Because of the BSP tree there was no danger that the world polygons would render in the wrong order, but there was some danger that objects could sort wrong with respect to each other or the world polygons. To avoid this, the Thief engine (again, I'm kind of guessing here) conceptually numbered the cells in the order it would draw them. An object in cell N would normally render immediately after drawing the (inward-facing) world polygons in cell N and before drawing the walls of cell N+1. However, sometimes objects would lie in multiple cells. An object in cell M and N, with M &amp;lt; N, would need to be drawn after all the walls of cell M, but the parts of it in cell M might be obscured by walls in cell N or indeed in any of the cells between M and N. (A common case that came up: a corridor (cell) with a niche (cell) holding a torch, with the torch slightly protruding into the corridor. The niche is M, and the corridor is N--e.g. if the viewpoint is in the corridor, then the corridor is "closer" to the viewpoint in a back-to-front rendering sense. For example, one of the walls of the corridor will occlude parts of the niche.)&lt;/p&gt;
    &lt;p&gt;To deal with those complexities, Thief would consider whether it was acceptable to draw a given object in its frontmost cell N (or, indeed, at any point in the draw order between its rearmost and frontmost). To do this it would compute bounding octagons on the objects and on the world polygons and see whether the polygons occluded the objects. If a world polygon was supposed to be "in front" of an object and the bounding octagons intersected, then it wasn't safe to move the object later in the rendering order to a point later than that world polygon.&lt;/p&gt;
    &lt;p&gt;The Thief engine would resolve what range it was valid to draw each object in between backmost and frontmost cells containing that object; if the object was only in one cell it would always be considered as just being in that cell. Once this was determined, Thief then attempted to resolve object-vs-object sorting. Because an object might extend through multiple cells and then be behind or in front of an object that was in a single cell, objects that were only in one cell might need to be moved back or moved forward in the sort order anyway; in other words, the final range of cells that an object might be considered for rendering after might cover a larger range than just between backmost and frontmost containing cell.&lt;/p&gt;
    &lt;p&gt;Thief attempted to use the above ranges to find some sort order for objects, holding the cell sort order fixed, so that objects and world polygons would all inter-sort correctly. (This was where that proof came in.) However, sometimes this was impossible. For example, in the torch-in-the-niche case described above, it's possible for one world polygon in cell N to be occluded by the torch (the wall with the niche on it extending behind the niche), but another world polygon in N to occlude the niche and part of the torch (the wall with the niche on it extend forward towards the viewer). In this case, there is no sort order of objects vs. cells that works, because parts of the torch occlude the cell while parts of the same cell occlude the torch. It would be fixable by interleaving the world polygons from the cell with the torch, instead of always drawing all the world polygons from one cell as a unit, but not all cases could be fixed that way, so Thief actually never did that (it always drew all world polygons from one cell as a unit) -- unless I'm remembering wrong.&lt;/p&gt;
    &lt;p&gt;Instead Thief had an entirely different, extremely expensive mechanism that it fell back on to solve difficult sorting problems. Each object could be "split" into multiple pieces, one per cell. In each cell, only the part of the object which was contained in that cell was rendered. This wasn't done by actually splitting the object, but rather by rendering it multiple times, once for each "piece", and for each piece dynamically clipping the object with a "user clip plane", using similar technology to the frustum clipping that was also being done. (In complex cases, multiple clip planes would be needed; however, it was only ever necessary to clip to portals between the cells the object was in, and not literally clip to all the planes defining each cell.) If this technique was applied, then that part of that object could always be drawn in or after that cell. However, although it didn't increase the per-pixel costs, it required transforming and clipping the object multiple times, so it was rather expensive. (I encouraged designers to place their torches fully inside the niches instead.) This was particularly bad when rendering characters, which were skinned, since I think the skinning transformations would be performed multiple times.&lt;/p&gt;
    &lt;p&gt;This also had another problem: if you had three cells arranged so that the portals between them formed a T, then the dynamic clipping could create t-junctions at the border. These would then cause cracks in the rendering. I don't remember how/if we fixed this.&lt;/p&gt;
    &lt;p&gt;During development I noticed that if you used all the walls of a cell for user clip planes--not just the portals--then if an object interpentrated a wall, it would be clipped away, looking exactly like a z-buffer rendering. Normally these artifacts arose because the game physics allowed an object to interpenetrate briefly, so it was actually better not to clip those objects, and then they wouldn't look (from most angles) like they were going through the wall. But we could've used an effect like that to allow creatures that could move through walls even without though we had no z-buffer.&lt;/p&gt;
    &lt;p&gt;After my positive experience with user clip planes I was frustrated over the next few years that GPUs didn't efficiently/easily support them. (Even in D3D9, they're still done in the pixel shader; although you can use z and stencil to cull more tightly and reduce pixel shading costs.) Of course, with the z-buffer, it's not clear there are lots of use cases, but there's a chicken-and-egg problem to that conclusion.&lt;/p&gt;
    &lt;p&gt;The core technique for rendering texture mapped polygons with decent precomputed shadows is very similar (identical?) to Quake. Thief used light mapping and a surface cache to store the lit surfaces. I refer you to Mike Abrash's articles.&lt;/p&gt;
    &lt;p&gt;My recollection is that we added this to the engine after we (the Thief team) saw the Quake "QTest" release. However, I'm doubtful there really was a Thief team at that point. According to wikipedia, QTest came out February 24, 1996. Terra Nova came out on March 5, 1996, so I guess we had built our final version of Terra Nova by the time QTest was released, but I can't imagine we'd geared up a whole team yet. In fact I don't know for sure when exactly I did the original research version of this engine.&lt;/p&gt;
    &lt;p&gt;At one point objects raycasted to all (or the top N) light sources to determine if they were visible to it or not and turned the entire light on/off over the entire object to simulate objects going in-and-out of shadow. But I don't know if we shipped with this or using the "check the lightmap value on the floor", which I seem to recall we at least considered using for the player's visiblity to guards (to avoid players being tricked/confused by places that appeared to casual inspection to being in shadow).&lt;/p&gt;
    &lt;p&gt;Thief levels were created using Constructive Solid Geometry (CSG) methods, based again on knowledge that that was how Quake worked. Technologically though Thief worked very differently from Quake.&lt;/p&gt;
    &lt;p&gt;The Thief CSG model was "temporal", which maybe I can better explain by analogy to Photoshop. In photoshop, you have layers. Stuff placed in one layer obscures stuff in lower layers, except if you use more interesting blend modes, in which case stuff in a layer changes the stuff visible below it but has no affect on things above it.&lt;/p&gt;
    &lt;p&gt;Algorithmically, you can think of generating the final image by processing each layer in the image sequentially, from back to front, compositing it with the "image so far". At the time each image is processed, the image-so-far contains the accumulated effects of all the earlier (lower) layers, and then the layer is processed and the image-so-far is changed and that layer cannot have any further effect except by data it left in the image-so-far.&lt;/p&gt;
    &lt;p&gt;Normally we think of the photoshop layer model as a stack of 2D layers, but you could instead think of the above algorithm as the model, and think of the layers not as a "vertical" stack but as an ordered sequence of operations to perform. This is what I mean by a temporal model, and this is the model that Thief used for its CSG. (If the vertical photoshop layer stack is a vertical third dimension of the 2D images, then the Thief layering model would be a fourth dimension on the 3D shapes, and thinking about this as four-dimensional space is not very effective.)&lt;/p&gt;
    &lt;p&gt;The Thief CSG took as input a series of "operations" arranged in an order over time. Those operations were "brush placements", where a brush was a 3D convex solid plus a characterization of how the area covered by that solid would be changed by the operation. The entire space started solid, so one brush operation was "carve out a hole in this area"--in other words "change the area covered by this brush to open". For example you would use this to carve out a room. Another placed solid matter; you could use this to create a pillar. Another placed water, and another lava. Because space could be of 4 types (solid, air, water, or lava -- oh hey, the 4 classical elements!), each operation could be considered by which output type it produced. Moreover, we allowed these operations to be selective. For example, the "flood brush" turned air into water, but left all other types alone. This made it easier to fill an area with water--you could construct it entirely with air and then fill the lower half with water. Because of the temporal aspect, you could then go and change some of the water to "air" if you needed to. It would have been possible to make brush types that were much complicated (air turns to water, water turns to solid, solid turns to air, and lava unchanged) but this wasn't actually useful so I think all the brush types were of the unconditional-single-type or conditional-single-type.&lt;/p&gt;
    &lt;p&gt;As with Photoshop layers, the temporal aspect was something under user control; you could move a brush forwards or backwards in time. Unfortunately, this was much harder to visualize (there was no "layers" window) and I'm not sure designers were really thrilled with this.&lt;/p&gt;
    &lt;p&gt;In comparison, Quake started with a level that was all open space and placed solids. It used a more-traditional-CSG explicit-subtraction operation. Water was handled by making all water brushes occur first temporally, so that all the effective temporal sequence of operations was: all air =&amp;gt; some air turns to water =&amp;gt; all solids are placed. Because subtraction was explicit on the solid brushes before they were added to the world, the subtraction couldn't "accidentally" erase water, so there was no need for an explicit temporal model (the set of things you could do in Quake was more limited, but it supported almost everything that mattered in practice--although some designers came up with some strange sequences of operations in Thief to create more complicated shapes).&lt;/p&gt;
    &lt;p&gt;Because Quake levels started empty, Quake had invisible "exterior" surfaces that required a separate process to detect and eliminate. If the level wasn't watertight, then the exterior could be reachable and the automated tools couldn't eliminate it. In contrast, because the Thief level started solid, this was never necessary. (I think Unreal's CSG may have started as solid as well.)&lt;/p&gt;
    &lt;p&gt;I had no idea what I was doing when I implemented the Thief CSG system (despite having the opportunity to pepper John Carmack with questions) so I made a terrible choice. The Thief system worked by dividing the world up into convex polyhedra and keeping track of what each polyhedron's type i.e. air, solid, water, lava, which I call the "medium". To do this, I stored the world as a solid BSP tree; the BSP tree classifies all of space into convex polyhedra (except at the edges where it may have unbounded shapes extending to infinity).&lt;/p&gt;
    &lt;p&gt;Using a BSP tree for this had a performance advantage, but I didn't do it for that reason; I did it because I literally couldn't think of any other way to compute the output. This way I was able to sequentially add each brush to the BSP tree and then apply the medium-transformation-operations to each BSP leaf that the brush contained.&lt;/p&gt;
    &lt;p&gt;But reading the Quake source, it turns out you can do it a different way: intersect every brush with every other brush directly, without a spatial data strucure. By being careful, you can build a growing list of convex polyhedra all of which are non-overlapping. You can then add a spatial data structure to accelerate determining which ones might overlap, but without affecting the computation itself.&lt;/p&gt;
    &lt;p&gt;The difference is that the BSP-tree based CSG tree would have situations where a brush early in the processing would be inserted in the tree early and would introduce a BSP split plane near the root which then extended across the whole level or a significant part of it. This might randomly come close to an edge or vertex of a totally unrelated brush, causing an extra split in that brush and introducing additional epsilon problems. As CSG is already painful numeric geometric algorithms with epsilon problems, introducing this extra uncontrollable problem was terrible. The Thief editor was (is?) notorious for having weird problems where a change to one brush might trigger a failure in the CSG generator at an entirely unrelated place in the level--a failure which meant the level simply failed to "compile".&lt;/p&gt;
    &lt;p&gt;Partway through Thief development I switched everything in the CSG engine from floats to doubles and cranked down the epsilon, which made things better but didn't solve the problem properly, but I realize in hindsight it would have been much, much better to have simply avoided the BSP tree entirely.&lt;/p&gt;
    &lt;p&gt;The epsilon problems were exacerbated by the crazy way I built the polygons and portals directly from the BSP-tree in a t-junc free way by computing a shared mesh along each BSP split plane to guarantee that vertices on one side of the split plane would always have a matching vertex on the other side; this introduced a much more complicated set of invariants that had to be maintained that also had epsilon problems. It meant I didn't have to write a post-processing t-junction eliminator the way Quake did, but in hindsight that would have been better.&lt;/p&gt;
    &lt;p&gt;Looking Glass games prior to Thief such as System Shock 1 and Terra Nova had used a "lines of constant-Z" mapper to perform perspective texture mapping. Those games typically used the perspective texture mapper for large, near polygons, but used an affine mapper for distant polygons.&lt;/p&gt;
    &lt;p&gt;Thief used a custom-written perspective mapper for all polygons. It used the trick used in Quake of issuing a floating-point divide for perspective correction for every N pixels which then executed in parallel with the texture mapping of the next N pixels; this worked because the Pentium would execute the floating-point divide "in the background" if you only used integer instructions after it (the Pentium was not an out-of-order processor in general).&lt;/p&gt;
    &lt;p&gt;Thief computed the perspective correction every 8 pixels (that is, N above was 8). Thief aligned the correction so it occurred on pixels whose x coordinates were multiples of 8. The beginning and ending of a span of pixels could be less than 8, and would call a general-purpose N-pixel mapper, but the 8-pixel spans called a routine that was hardcoded to compute exactly 8 pixels.&lt;/p&gt;
    &lt;p&gt;Because the engine changed over time and was initially used for research, it supported two different formats that textures could be stored in. One was restricted to 256x256 textures, or rather textures with powers-of-two sizes and in which the stride/pitch was always 256. This used an inner loop similar to the one I wrote up for the PCGPE. The second one supported arbitrary non-power-of-two textures but didn't support wrapping. This is the one we switched to when we added surface cached lighting, because padding those textures widths to multiples of 256 would have been far too wasteful. I believe the "step table" indexed-by-carry-flag trick used in this mapper came directly from Mike Abrash.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Details for x86 programmers: &lt;p&gt;Here is the code for the second pixel of the non-power-of-two texture-mapper-unrolled-8-times:&lt;/p&gt;&lt;quote&gt;adc ebx,edi add eax,ebp sbb edi,edi ; save v carry add esi,edx ; update u mov byte ptr _pt_buffer+1,al mov al,[ebx] mov edi,_pt_step_table[edi*4+4]&lt;/quote&gt;&lt;p&gt;Here is the code for the second pixel of the 256x256 texture-mapper-unrolled-8-times (not used in the shipping game, unless maybe it was used for water surface):&lt;/p&gt;&lt;quote&gt;add esi,edx mov ecx,ebx adc bl,dl add eax,ebp adc bh,dh mov al,[edi+ecx] mov byte ptr _pt_buffer+1,al and ebx,0babebeach&lt;/quote&gt;&lt;p&gt;The spacing of both pieces of code shows that they were optimized for the Pentium; each one uses a nominal 4 cycles per pixel. (They also both would trigger "Partial Register Stalls" on the Pentium Pro.) The Pentium had a 2-cycle "AGI" stall that you couldn't use a register as an address for 2 cycles after it's computed, so you can see the texture fetch (from ebx or edi+ecx) is designed to compute those registers two cycles before the fetch. The full 8-pixel routines use 32 and 33 Pentium-pairs of instructions for 8 pixels (although there's also setup to get the right values into the right registers).&lt;/p&gt;&lt;p&gt;The 0babebeach at the end there is a 0xdeadbeef-style constant that relied on "self-modifying" code to update the constant, a common trick on the 486 and Pentium. Those processor had an "and ebx,memory_location" instruction, but it wasn't single-cycle, whereas "and ebx,#immediate" was single-cycle. This meant there were 9 places in the code that had to be modified (this is an 8-unrolled loop, plus the non-unrolled loop), but only when the texture was changed.&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Unfortunately, I totally missed out on the possibility of reblocking the texture to improve cache usage, which might have allowed significant performance improvements (I don't know); I've heard that Build and other engines did do this, and since the surface cache in Thief was built in 8x8 blocks anyway it probably wouldn't have been hard to support on that end.&lt;/p&gt;
    &lt;p&gt;Looking Glass games generally demanded flexibility, and graphics engines faced with that need for flexibility often had a combinatorial explosion of texture mappers to handle all the different cases. The texture mappers I wrote for Thief sacrificed a litttle performance for the sake of simplicity and maintainability and maximum flexibility; the texture mapping routines above ended with an indirect branch which would branch to a routine that would decide what to do with the 8 pixels that had just been written into a temporary buffer.&lt;/p&gt;
    &lt;p&gt;There were two kinds of functions that could be invoked at this point. The most common kind was one which wrote to the "framebuffer" (which was actually just a block of RAM somewhere that would be blitted to the screen later) and returned from the original function call that invoked the texture mapper chain. The other kind of function would read the pixels from the temporary buffer, modify them, and write them back to the temporary buffer, then jump to yet another function. You could chain arbitrary numbers of these processing functions, in theory, not that this turned out to be necessary.&lt;/p&gt;
    &lt;p&gt;The codebase had a bunch of these functions:&lt;/p&gt;
    &lt;p&gt;Most of those weren't used, I think. Paletted lighting in particular required setting up the palette in a particular way, and I used this in the original research engine to demo a gouraud-shaded level running at 640x400 at 20-ish fps on a Pentium 90. The level was a retextured version of Doom 1 E1M1, using a texture made by Kurt Bickenbach. He and I iterated a bit trying to figure out how to make textures that would look good and not too banded in 8-bit using paletted lighting, and we got some visually pleasing results, but in the end paletted lighting was too limited, so we abandoned it. (It was too limited artistically, and it couldn't do pitch black properly; when we ended up with a shadow-oriented game it was clearly wrong, but I think it had been abandoned long before due to the first issue.) Abandoning it meant abandoning hitting that frame rate/resolution target as well, but in the long run this didn't matter that much because LGS games were complicated enough that it's not like we spent 95% of the frame time in the renderer anyway, and we didn't ship it for a long time anyway.&lt;/p&gt;
    &lt;p&gt;The engine supported specifying an arbitrary color look-up table ("clut") for each portal, and coloring everything seen through that portal with that clut. This wasn't done by applying this as a post-process on that portal surface, which would have used extra "fill rate", but by storing cluts (and concatenating them into new cluts) and applying them while rendering surfaces seen through the portal. This effect could have been used to make force fields or such things, although it ended up underutilized. (Note, though, that if a single cell were visible through multiple paths, and the paths had different sequences of cluts, there was no correct way to render it; the Thief engine chose randomly. Probably there was no good solution to this problem, but since it was never exercised, it didn't matter.)&lt;/p&gt;
    &lt;p&gt;During development, this was used to make water "foggy", where the more underwater portals away something was, the more opaque the water became. However, this looked pretty terrible as it showed the portal boundaries clearly and although we had all gotten used to it since it was in the engine for years, I did eventually turn off the portal-varying underwater fog, replacing it with a fixed underwater fog.&lt;/p&gt;
    &lt;p&gt;It was also used to color the water surface--the water surface actually used a purely transparent texture and surfaces underwater were colored while they were rendered, instead of having to use the "translucent" read-modify-write mapper. This means the object renderers also needed to support rendering with a clut; I don't remember the details since I didn't work on those, but this was probably something we tended to support by default anyway, so I doubt this was problematic for those renderers.&lt;/p&gt;
    &lt;p&gt;I'm not sure what happened for objects that stuck through the water surface; I guess those were forced to use the dynamic user clip plane path. Because Quake used a z-buffer, Quake couldn't have both a distant wall-underwater and the water surface visible at the same pixel (the z-buffer could only store one depth), so the Quake water surface was opaque, at least in the software renderer. I'm not sure what Quake-derived engines like Half-Life did; one expensive solution would be to render the world except the water, then render the objects, then finally render the transparent water through the z-buffer (much as we do with hardware). The z-buffered transparent water effect would have been much more expensive in pixel costs than Thief's approach, although Thief was spending more effort per triangle/vertex having to render the object multiple times.&lt;/p&gt;
    &lt;p&gt;In Thief, most world surfaces simply used the arbitrary-pitch no-wrapping sampler and the plain store-to-memory writer.&lt;/p&gt;
    &lt;p&gt;I imagine that the object renderers used the shared LGS software rendering libraries and so didn't use these mappers at all.&lt;/p&gt;
    &lt;p&gt;I didn't write all the graphics technology used in Thief. I'll call out the things I didn't write below. I associate each of them with someone at LGS who did the work, but I'm not sure the people I can think of were the only contributors to that effort, so rather than risk missing important people out, I'm just not going to name names if multiple people might have been involved.&lt;/p&gt;
    &lt;p&gt;The 3D camera system, vertex transformation, and clipping processing were part of a shared technology library used by all LGS products. (Thief may have been the first customer of that tech--previous games having used fixed-point so they could run on x86 computers without floating point acceleration.) Thief batched together all the vertices used in a single cell and transformed them all at once, whether they were visible polygons or portals, which was possible since the 3D vertex API allowed separating things out like that. (Sort of like compiled vertex arrays.)&lt;/p&gt;
    &lt;p&gt;As noted before, general object rendering presumably also went through shared libraries. Object polygons were sorted using a BSP tree; James Fleming had written a very clever system that significantly reduced the number of BSP node decisions that needed to be made, based on the fact that single-sided polygons often couldn't occlude each other from any angle. (For example, I believe a polygonal torus, which is an object that self-occludes and needs sorting if the polygons are two-sided, can be statically sorted if it's made of single-sided polygons.)&lt;/p&gt;
    &lt;p&gt;Most importantly, Thief used character skinning with skeletal animation to render its characters, and I never touched a single line of code of that system.&lt;/p&gt;
    &lt;p&gt;I quit Looking Glass for a time; during my absence hardware acceleration support was added. (I came back and added support for colored lighting in the lighting generator and maybe the surface cache or something.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nothings.org/gamedev/thief_rendering.html"/><published>2026-01-15T10:59:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46631276</id><title>Jiga (YC W21) Is Hiring Full Stack Engineers</title><updated>2026-01-15T18:58:45.025234+00:00</updated><content>&lt;doc fingerprint="ebd8a57c5d14cb90"&gt;
  &lt;main&gt;
    &lt;p&gt;We’re building tools that help NASA, Tesla, Google, and hundreds of top teams bring the future to life. Can you help us make it even better?&lt;/p&gt;
    &lt;p&gt;If you’re into engineering and building physical products, you probably know the sourcing grind. You email a few suppliers, wait days for quotes, answer the same questions twice (or ten times). Track everything in spreadsheets, deal with logistics, revisions, customs (you gotta love new tariffs every week), forms, reports and surprising delays.&lt;/p&gt;
    &lt;p&gt;It’s expensive, slow, tedious and painful – and it pulls you away from actual engineering work.&lt;/p&gt;
    &lt;p&gt;Jiga fixes that. We connect engineers directly with vetted manufacturers, handle quoting and communication in one place, build AI workflows to deal with the administrative work, and give full visibility into every order from prototype into mass production. What used to take weeks now takes hours.&lt;/p&gt;
    &lt;p&gt;We build the platform the manufacturing industry has been craving for years, and we’re aiming for the moon.&lt;/p&gt;
    &lt;p&gt;Most companies talk about transparency and trust. We actually do it.&lt;/p&gt;
    &lt;p&gt;1. We share the numbers. As a team member, you’ll see the full picture: revenue, valuation, runway, roadmap, sales pipeline, what’s working and what fails.&lt;/p&gt;
    &lt;p&gt;2. We have been remote and async from day one and we love it. But we also love our team: once a year we bring everyone together to a small offsite in paradise for co-working, hiking, eating, drinking and sailing.&lt;/p&gt;
    &lt;p&gt;3. We don’t count hours, we track performance. You are senior enough to know what it means, we don’t need to explain.&lt;/p&gt;
    &lt;p&gt;4. We don’t do busy-work. We meet for a weekly all-hands and a team sync. That’s it. Everything else is async. Your calendar will be empty to write code, talk to customers or to fix problems.&lt;/p&gt;
    &lt;p&gt;5. We deliver 11/10 customer experience. We don’t settle for “good enough.” Quick response times, going the extra mile, creating fans not just users. It’s part of our DNA.&lt;/p&gt;
    &lt;p&gt;6. We decide fast. The person closest to the problem makes the call. No approval chains, no review committees and no endless layers of management.&lt;/p&gt;
    &lt;p&gt;7. Profitability is freedom. We are cashflow positive, growing revenue by 3x YoY. No desperate fundraising, no panic pivots, no mass layoffs. The magic we’re building is being built to last for long time.&lt;/p&gt;
    &lt;p&gt;8. “Don’t drink the Kool-Aid” is our motto. If you see something that needs fixing, it’s your duty to raise a flag or just fix it yourself.&lt;/p&gt;
    &lt;p&gt;9. We hire the best people. We’ve gathered a super group of the best talents in engineering, supply chain and sales. Everyone knows what they need to do and cruising through it.&lt;/p&gt;
    &lt;p&gt;10. Ship now, iterate later. Perfection is the enemy of done. We’d rather learn from something that is live on production, than debate something theoretical.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jiga.io/about-us"/><published>2026-01-15T12:00:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46632023</id><title>25 Years of Wikipedia</title><updated>2026-01-15T18:58:44.898641+00:00</updated><link href="https://wikipedia25.org"/><published>2026-01-15T13:17:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46632039</id><title>Programming, Evolved: Lessons and Observations</title><updated>2026-01-15T18:58:44.188489+00:00</updated><content>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/kulesh/dotfiles/blob/main/dev/dev/docs/programming-evolved.md"/><published>2026-01-15T13:18:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46632768</id><title>Show HN: TinyCity – A tiny city SIM for MicroPython (Thumby micro console)</title><updated>2026-01-15T18:58:43.639650+00:00</updated><content>&lt;doc fingerprint="87bc5ae944d9e726"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;TinyCity is a city simulation game inspired by SimCity for the Raspberry Pi RP2040 running MicroPython&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Build and manage a growing metropolis in this tiny city sim. Balance zones and resources, hit milestones to gain bonuses and navigate disasters that are randomly generated.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3 terrains to choose from or a randomly generated map&lt;/item&gt;
      &lt;item&gt;Residential, commercial, and industrial zoning&lt;/item&gt;
      &lt;item&gt;Budget management&lt;/item&gt;
      &lt;item&gt;Population growth &amp;amp; density, power grid, crime and pollution&lt;/item&gt;
      &lt;item&gt;Disaster system with random events&lt;/item&gt;
      &lt;item&gt;Milestones and hidden bonuses&lt;/item&gt;
      &lt;item&gt;Save/load functionality&lt;/item&gt;
      &lt;item&gt;Police &amp;amp; fire stations, power plants, stadiums, and more!&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Taxes are collected once per year&lt;/item&gt;
      &lt;item&gt;Click menu to view current budget and change tax rate&lt;/item&gt;
      &lt;item&gt;Add parks, trees and schools to attract new residents&lt;/item&gt;
      &lt;item&gt;Add fire and police stations to avoid crime and fight potential fires&lt;/item&gt;
      &lt;item&gt;Monitor pollution levels and heavy traffic to improve growth&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Play it online here (available soon once arcade PR is merged!)&lt;/item&gt;
      &lt;item&gt;Add the &lt;code&gt;src&lt;/code&gt;files to the Online Editor&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;TinyCity was heavily inspired by jhhoward/MicroCity for the Arduboy game platform. Thanks for all of the amazing work on MicroCity (and other titles).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/chrisdiana/TinyCity"/><published>2026-01-15T14:11:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46633429</id><title>OBS Studio 32.1.0 Beta 1 available</title><updated>2026-01-15T18:58:43.094663+00:00</updated><content>&lt;doc fingerprint="2e123dbbf3be96f9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;OBS Studio 32.1.0 Beta 1&lt;/head&gt;Pre-release&lt;p&gt; Pre-release &lt;/p&gt;&lt;p&gt; github-actions released this &lt;relative-time&gt; 14 Jan 23:27 &lt;/relative-time&gt;&lt;/p&gt;&lt;p&gt; · 3 commits to master since this release &lt;/p&gt;&lt;head rend="h2"&gt;32.1 New Features&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Added new Audio Mixer [Warchamp7]&lt;/item&gt;&lt;item&gt;Added new Add Source dialog [Warchamp7]&lt;/item&gt;&lt;item&gt;Added WebRTC Simulcast Support [Sean-Der]&lt;/item&gt;&lt;item&gt;Added missing undo/redo actions for scene items [cg2121] &lt;list rend="ul"&gt;&lt;item&gt;Scale filtering, blending mode, blending method, deinterlacing mode and deinterlacing field order&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;32.1 Changes&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Removed "Source" from source names [Warchamp7]&lt;/item&gt;&lt;item&gt;Updated the Edit Transform dialog [Warchamp7]&lt;/item&gt;&lt;item&gt;Changed copying a scene item to copy all properties [cg2121/Warchamp7]&lt;/item&gt;&lt;item&gt;Disabled dock animations [Warchamp7]&lt;/item&gt;&lt;item&gt;Moved transition preview button to button box [exeldro]&lt;/item&gt;&lt;item&gt;Rearranged default dock positions [Warchamp7]&lt;/item&gt;&lt;item&gt;Increased media source playback slider update rate [Warchamp7]&lt;/item&gt;&lt;item&gt;Enabled palette for Light theme audio mixer [Warchamp7]&lt;/item&gt;&lt;item&gt;Changed default bitrates to 6000 kbps [mihawk90]&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;32.1 Bug Fixes&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Fixed an issue where projector resolutions had decimals [Warchamp7]&lt;/item&gt;&lt;item&gt;Fixed sync of Preview/Program size and positioning [Warchamp7]&lt;/item&gt;&lt;item&gt;Refactored OBSBasic::Save to only save frontend canvas scenes/groups [dsaedtler]&lt;/item&gt;&lt;item&gt;Fixed NAL type for HEVC caption/BPM SEIs [dsaedtler]&lt;/item&gt;&lt;item&gt;Fixed an issue where video scaling could be incorrect in multivideo encoder scenarios [dsaedtler]&lt;/item&gt;&lt;item&gt;Fixed an issue with chapter markers having incorrect time when using file splitting [garyholmes]&lt;/item&gt;&lt;item&gt;Fixed an issue where some recordings could have black thumbnails [derrod]&lt;/item&gt;&lt;item&gt;Fixed an issue where the NVIDIA Blur and Background Blur could have banding or look splotchy [pkviet]&lt;/item&gt;&lt;item&gt;Fixed an issue where macOS Screen Capture would select an item for capture by default [jcm93]&lt;/item&gt;&lt;item&gt;Fixed an issue with PipeWire when capturing a device that does not require a framerate [tytan652]&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Checksums&lt;/head&gt;&lt;code&gt;OBS-Studio-32.1.0-beta1-Sources.tar.gz: 66f5f7efe92ce0ec904630d4a5bb3377285a8fb2d5f46ed9c28f81d7f7007e04
OBS-Studio-32.1.0-beta1-Ubuntu-24.04-x86_64-dbsym.ddeb: 4a508912939e946ceade67c6cd854897b892c52cf5f0cfe3b6bacea30edfe275
OBS-Studio-32.1.0-beta1-Ubuntu-24.04-x86_64.deb: e84b1fcf72612ac85140fe5a54a37d3e19947807a9db2f5b74bce1b196042f65
OBS-Studio-32.1.0-beta1-Windows-arm64-PDBs.zip: 6b77f572f3afe80d35e4b21f4f93ccda8e8e11b36aad26b279973dab53fc24a9
OBS-Studio-32.1.0-beta1-Windows-arm64.zip: fe89de2f94f3eee6ec8a54e8267f3ab783d0e6d84da6aef68593311de571e2e9
OBS-Studio-32.1.0-beta1-Windows-x64-Installer.exe: 8ae1f07e7c9ad6a63c05de20ad7f20741bb3d37c5331a8f62ce4709ba799cb7d
OBS-Studio-32.1.0-beta1-Windows-x64-PDBs.zip: 4af2d8cc4941cddb96c123a3e77c021e7fac37490a39416f50a7c6ddc5474afd
OBS-Studio-32.1.0-beta1-Windows-x64.zip: 0d5238076822b194c756978a5a6c2bda7ecd655d9369575b7d9815f12cda9a4f
OBS-Studio-32.1.0-beta1-macOS-Apple-dSYMs.tar.xz: ca85696df7b7fa4f222fa1f9ec02fdcd09e85ded882ab94be4e5057bdd1c367d
OBS-Studio-32.1.0-beta1-macOS-Apple.dmg: 858a3fc88f623903d02f2683898be9ff52a705ca37ae543f7dc6686d901a2864
OBS-Studio-32.1.0-beta1-macOS-Intel-dSYMs.tar.xz: 9b32bb4833891fe3e50661a938494a56e757089c841cf127cf6465a8eba2b745
OBS-Studio-32.1.0-beta1-macOS-Intel.dmg: fb09045cd2eea7b063b56ffa1b171ad227c202edcc47be73ab4043b8f4b537dc
&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/obsproject/obs-studio/releases/tag/32.1.0-beta1"/><published>2026-01-15T14:57:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46633488</id><title>Apple is fighting for TSMC capacity as Nvidia takes center stage</title><updated>2026-01-15T18:58:42.843597+00:00</updated><content>&lt;doc fingerprint="a5b8a16d4b2e3c0a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Apple is Fighting for TSMC Capacity as Nvidia Takes Center Stage&lt;/head&gt;
    &lt;head rend="h3"&gt;[Exclusive] A 15-year relationship helped TSMC grow and Apple leap ahead of rivals. But now the iPhone maker is struggling to get access to chip production as it competes with Nvidia for wafer supply.&lt;/head&gt;
    &lt;p&gt;When CC Wei visited Cupertino last August, he had bad news for his largest client. Apple would need to acquiesce to the largest price rise in years, TSMC’s CEO told its executives.&lt;/p&gt;
    &lt;p&gt;Tim Cook and his team took the news on the chin. Wei had been telegraphing hikes in earnings calls over the past few quarters, and the Taiwanese chip maker’s rising gross margins were testament to its increasing pricing power.&lt;/p&gt;
    &lt;p&gt;That wasn’t the worst news, my sources tell me.&lt;/p&gt;
    &lt;p&gt;Apple, which once held a dominant position on TSMC’s customer list, now needs to fight for production capacity. With the continuing AI boom, and each GPU from clients like Nvidia and AMD taking up a larger footprint per wafer, the iPhone maker’s chip designs are no longer guaranteed a place among TSMC’s almost two dozen fabs.&lt;/p&gt;
    &lt;p&gt;What Wei probably didn’t tell Cook is that Apple may no longer be his largest client.&lt;/p&gt;
    &lt;p&gt;According to Culpium analysis and discussions with sources in the supply chain, Nvidia likely took top spot in at least one or two quarters of last year. “We don’t discuss that,” Chief Financial Officer Wendell Huang told Culpium Thursday when asked about the change in client rankings.&lt;/p&gt;
    &lt;p&gt;Final data will be unveiled in a few months when TSMC releases its annual report — which includes revenue from its top clients — but there’s every chance that Apple’s lead for the full year narrowed significantly and may have even fallen below Nvidia’s. If it didn’t happen in 2025, then it’s almost certain to do so in 2026, my sources tell me.1&lt;/p&gt;
    &lt;p&gt;Public data helps tells the story.&lt;/p&gt;
    &lt;p&gt;TSMC’s revenue climbed 36% last year to $122 billion, it reported Thursday. Nvidia’s sales for the fiscal year through January 2026 is set to climb 62% while Apple’s product revenue — which excludes services — is on track to grow just 3.6% for the 12-months to December 2025, according to Culpium estimates based on earnings reports and company guidance.&lt;/p&gt;
    &lt;p&gt;Apple’s role as the primary driver of TSMC revenue growth ended five years ago. In 2018 TSMC sales would have even fallen if not for incremental purchases by Apple that year. Now, the Cupertino company is posting low single-digit revenue growth while Nvidia is skyrocketing.&lt;/p&gt;
    &lt;p&gt;The reason for this change is two-fold, and pretty obvious: AI is driving massive demand for high-powered chips, while the smartphone boom has plateaued.&lt;/p&gt;
    &lt;p&gt;TSMC’s sales from high-performance computing, which includes AI chips, climbed 48% last year on top of 58% growth the year before. Smartphone revenue climbed just 11%, slower than 23% in the prior year.2 That trend will continue this year, and for the foreseeable future.&lt;/p&gt;
    &lt;p&gt;Revenue in 2026 will rise close to 30%, yet capital expenditure will climb around 32% to a record of somewhere between $52 billion and $56 billion, TSMC said Thursday. Longer term, growth will average 25% in the five years through 2029 yet the AI segment will climb an average of 55% or more over the same period, the company said. That’s higher than a prior forecast for a mid-40 percent figure.&lt;/p&gt;
    &lt;p&gt;The ultimate flex for TSMC came Thursday when it showed off not only record revenue and net income, but a gross margin approaching that of software makers and fabless chip designers. In the December quarter, that figure was an astounding 62.3%, 280 basis points higher than the prior period. If not for its overseas fabs (Arizona and Japan) gross margin would have been even higher.&lt;/p&gt;
    &lt;p&gt;There are two caveats that are important. First, while smartphone processors are the largest portion of chips bought by Apple, they’re not the only type. Processors for Macs come under HPC, while it also has a strong lineup of custom chips used in accessories which fall under digital consumer electronics. Second, Nvidia isn’t the only HPC client. AMD is a major buyer of capacity for its own GPUs while Amazon and Google are on the growing list of customers developing in-house AI chips.&lt;/p&gt;
    &lt;p&gt;Put another way, Apple’s chip catalog is broader and more varied, while Nvidia’s lineup is more concentrated around a huge number of wafers at, or near, leading-edge. It’s for these reasons that Apple will remain important for at least another decade.&lt;/p&gt;
    &lt;p&gt;In the near-term, however, TSMC’s technology roadmap coupled with broader industry trends favor Nvidia, AMD and their ilk, meaning Apple may need to keep fighting for capacity over the next year or two.&lt;/p&gt;
    &lt;p&gt;TSMC is already producing chips in volume at 2 nanometer (called N2), currently its most advanced node, with Apple a major buyer. But in the second half of this year it’s set to ramp up both a new variant called N2P as well as a new node called A16.&lt;/p&gt;
    &lt;p&gt;The company’s business model is a little quirky. Instead of repurposing an existing factory for new technology, TSMC just builds a new one. This ensures no interruption to output and allows it to squeeze the most out of old tools and processes. In general, this means any new capacity that TSMC builds is for a new node. As a result, it has numerous fabs still churning out chips on technology that’s a decade older or more.3&lt;/p&gt;
    &lt;p&gt;In TSMC CEO CC Wei’s words A16, with Super Power Rail, is “best for HPC with complex signal routes.” SPR is TSMC’s version of backside power, a newer approach designed to separate a chip’s signal from its power supply. Intel is also developing this technology, and many believe it’ll be the key to the US company’s prospects at stealing foundry share from its Taiwan rival.&lt;/p&gt;
    &lt;p&gt;After that, TSMC has A14 which it expects to bring into volume production around 2028. Some call this the next full node after N2, labeling A16 as not a “full node.” In truth, all of these names are as much marketing terms as they are technology designators. Nevertheless, as SemiAnalysis recently wrote in a fabulous report on the TSMC-Apple relationship, the balance will shift back to Apple because A14 is designed “for both mobile and HPC from the start.”&lt;/p&gt;
    &lt;p&gt;More importantly, what Apple offers is stability. Nvidia has been a client for a lot longer than Apple, but broadly speaking it’s a bit niche. Right now that “niche” is the hottest product on the planet, but niche it is. Apple, on the other hand, has products being made in no fewer than a dozen TSMC fabs. Even if Nvidia did overtake Apple by purchases, the breadth of its manufacturing footprint at TSMC is nowhere near as large.&lt;/p&gt;
    &lt;p&gt;This distinction may not matter now, but it probably will at some point. The AI boom won’t last forever. The bubble may burst, or it may slowly deflate, but the growth trajectory will surely flatten and that means demand for leading-edge AI chips will fall.&lt;/p&gt;
    &lt;p&gt;Wei knows this, which is why he’s expanding both quickly yet cautiously. “I am also very nervous,” he said at the company’s investor conference on Thursday in Taipei. “If we didn’t do it carefully, it would be a big disaster for TSMC for sure.”&lt;/p&gt;
    &lt;p&gt;The chip giant has recently come under fire, including from noted analyst Benedict Evans, for being “unwilling/unable to expand capacity fast enough to meet Nvidia’s book.” I think this is wrong, and unfair.&lt;/p&gt;
    &lt;p&gt;“The risk of under-investing is significantly greater than the risk of over-investing,” Evans cited Google CEO Sundar Pichai as saying back in 2Q 2024, as if to make the point. TSMC and Alphabet, Google’s parent, have approximately the same gross margin. But their business models couldn’t be more different. Nvidia’s financials are also unlike TSMC’s. Their respective capex strategies need to reflect this risk.&lt;/p&gt;
    &lt;p&gt;Alphabet’s capital intensity, calculated as acquisitions of property, plant &amp;amp; equipment divided by revenue, was just 15% for full-year 2024. TSMC’s is more than double that at over 33%. More importantly, depreciation — which is where the cost of capex is reflected in earnings — was just 10% of Alphabet’s cost of revenue. For TSMC, this figure is more than four times higher at 45%.&lt;/p&gt;
    &lt;p&gt;At Nvidia, which is a tier-one buyer of TSMC’s output, the data is more stark. Capital intensity was just 2.5% for 2024, while depreciation was only 5.7% of the cost of revenue. As a fabless chipmaker, it can enjoy gross margins of over 70%. Its only real risk is holding excess inventory. Even then, it could have written off its entire inventory at the end of October and still maintain a gross margin approaching that of its chief supplier. What’s more, neither of these clients have anywhere near the customer-concentration risk of TSMC.&lt;/p&gt;
    &lt;p&gt;The complaint that TSMC could and should build faster ignores the fact that it’s the one left holding the baby if a downturn comes and demand falls. It takes two to three years to build a new fab, Wei explained, so the company must skate where the puck is going without thinking too much about where it’s been. “Even if we spend 52 to 56 billion this year, the contribution this year is none,“ Wei said Thursday. Its major cost, buying equipment, remains on the books no matter what revenue it brings in for the quarter.&lt;/p&gt;
    &lt;p&gt;For the best part of a decade, Apple was the one driving TSMC’s need to keep spending on new facilities. Today it’s Nvidia, and Jensen Huang is starting to wield more power than Tim Cook. But neither has to bother with the expensive business of actually manufacturing semiconductors, merely the hassle of begging CC Wei for wafers.&lt;/p&gt;
    &lt;p&gt;For such clients, the foundry’s capacity is a fixed cost that they needn’t worry about. Which is precisely why eight of the world’s ten largest companies turn to TSMC to make their chips,4 and in return the Taiwanese giant gets to reap the rewards during boom times like this.&lt;/p&gt;
    &lt;p&gt;Thanks for reading.&lt;/p&gt;
    &lt;head rend="h2"&gt;More from Culpium:&lt;/head&gt;
    &lt;p&gt;None of these companies state their purchase and sales relationships explicitly, but instead use terms like Customer A and Vendor Y when providing numbers.&lt;/p&gt;
    &lt;p&gt;Prior to 2019, TSMC categorized revenue by Communications, Computer, Consumer, and Industrial but the data still reflects this smartphones v HPC dynamic.&lt;/p&gt;
    &lt;p&gt;This is not ALWAYS the case. In recent years it has repurposed old fabs, but that’s the exception and not the norm.&lt;/p&gt;
    &lt;p&gt;The other two are Saudi Aramco and TSMC itself.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.culpium.com/p/exclusiveapple-is-fighting-for-tsmc"/><published>2026-01-15T15:02:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46633574</id><title>Found: Medieval Cargo Ship – Largest Vessel of Its Kind Ever</title><updated>2026-01-15T18:58:42.729580+00:00</updated><content>&lt;doc fingerprint="9e5593a611a4082e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Archaeologists Say They’ve Unearthed a Massive Medieval Cargo Ship That’s the Largest Vessel of Its Kind Ever Found&lt;/head&gt;
    &lt;head rend="h2"&gt;Spotted off the coast of Denmark, the “Svaelget 2” is a cog, a kind of large trading vessel used in the Middle Ages. Experts say the 600-year-old discovery is “exceptionally well-preserved”&lt;/head&gt;
    &lt;p&gt;Forty feet below the waves of Oresund, the strait between Denmark and Sweden, researchers have discovered the wreckage of a 600-year-old ship. Extravagantly outfitted and remarkably preserved, it’s a medieval cargo vessel also known as a cog. Experts say it’s the largest ship of its kind ever found.&lt;/p&gt;
    &lt;p&gt;Maritime archaeologists from Denmark’s Viking Ship Museum came across the shipwreck while surveying the seabed. According to a statement from the museum, the silt-covered vessel—called Svaelget 2—measures about 92 feet long, 30 feet wide and 20 feet tall. Experts estimate its cargo capacity was 300 tons.&lt;/p&gt;
    &lt;p&gt;“The find is a milestone for maritime archaeology,” says archaeologist Otto Uldum, the leader of the excavation, in the statement. “It is the largest cog we know of, and it gives us a unique opportunity to understand both the construction and life on board the biggest trading ships of the Middle Ages.”&lt;/p&gt;
    &lt;p&gt;Cogs were developed around the tenth century “as a safe and efficient means to transport massive quantities of goods,” writes Artnet’s Min Chen. “Their substantial cargo holds trumped [those] of Viking vessels such as knarrs, while their towering sides made them harder to board during sea skirmishes.” Per the statement, the large vessels were made to sail north from the Netherlands, around Denmark and toward the Baltic Sea. Though massive, a cog could be managed by a small crew.&lt;/p&gt;
    &lt;p&gt;“The cog revolutionized trade in northern Europe,” Uldum says. “It made it possible to transport goods on a scale never seen before.”&lt;/p&gt;
    &lt;p&gt;Uldum adds that shipbuilders made the cogs as large as possible to transport bulky cargo, like timber, bricks, salt and other food basics. No traces of cargo were found with the wreck, but researchers did uncover some of the artifacts reflecting the sailors’ daily lives, including shoes, combs and rosary beads.&lt;/p&gt;
    &lt;p&gt;The wrecked vessel is “exceptionally well preserved,” per the museum. Because the entire starboard side was buried in sand, it was protected from erosion. There, divers found lots of the ship’s rigging—the ropes and chains used to “control the sail, secure the mast and keep the cargo safe,” Uldum says. “It gives us a real opportunity to say something entirely new about how cogs were equipped for sailing.”&lt;/p&gt;
    &lt;p&gt;Svaelget 2 boasts other uniquely well-preserved structures. On its stern, researchers were shocked to find extensive remains of a castle, a kind of covered deck where the crew would have sought shelter. Records show that castles were distinctive features of medieval cogs, but no physical evidence of them had previously been identified.&lt;/p&gt;
    &lt;p&gt;“We have plenty of drawings of castles, but they have never been found because usually only the bottom of the ship survives,” Uldum says. “This time we have the archaeological proof.”&lt;/p&gt;
    &lt;p&gt;Researchers were also shocked to find remains of Svaelget 2’s brick galley, where the crew prepared food. Constructed of 200 bricks and 15 tiles, this type of fireproof galley allowed sailors to cook over an open fire. Nearby, divers found bronze cooking pots, wooden dishes, ceramic bowls and remains of meat and fish.&lt;/p&gt;
    &lt;p&gt;Dendrochronological analysis of the shipwreck’s wood revealed that Svaelget 2 was built around 1410. Its planks are made of Pomeranian oak from modern-day Poland, and the wood of its frame came from the Netherlands.&lt;/p&gt;
    &lt;head rend="h4"&gt;Quick fact: What is dendrochronological analysis?&lt;/head&gt;
    &lt;p&gt;Scientists use dendrochronology to determine the age of certain artifacts by studying tree rings in the wood.&lt;/p&gt;
    &lt;p&gt;The size of Svaelget 2 is an indication of a robust trading economy in northern Europe in medieval times. It would have “required a society that could finance, build and equip these enormous ships,” as well as an adequate demand for imported cargo in faraway lands, Uldum explains.&lt;/p&gt;
    &lt;p&gt;Indeed, the centuries leading up to Svaelget 2’s construction were characterized by an agricultural boom in Europe. As Agree Ahmed wrote for Works in Progress in 2025, the continent’s population subsequently grew from 18 million in the seventh century to more than 70 million by the 14th century. The growth enabled more international trading.&lt;/p&gt;
    &lt;p&gt;“Perhaps the find does not change the story we already know about medieval trade,” Uldum says. “But it does allow us to say that it was in ships like Svaelget 2 that this trade was created. We now know, undeniably, that cogs could be this large—that the ship type could be pushed to this extreme.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.smithsonianmag.com/smart-news/archaeologists-say-theyve-unearthed-a-massive-medieval-cargo-ship-thats-the-largest-vessel-of-its-kind-ever-found-180987984/"/><published>2026-01-15T15:09:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46634450</id><title>Design and Implementation of Sprites</title><updated>2026-01-15T18:58:42.356212+00:00</updated><content>&lt;doc fingerprint="6f48b9762dbb1f50"&gt;
  &lt;main&gt;
    &lt;p&gt;Weâre Fly.io, and this is the place in the post where weâd normally tell you that our job is to take your containers and run them on our own hardware all around the world. But last week, we launched Sprites, and they donât work that way at all. Sprites are something new: Docker without Docker without Docker. This post is about how they work.&lt;/p&gt;
    &lt;p&gt;Replacement-level homeowners buy boxes of pens and stick them in “the pen drawer”. What the elites know: you have to think adversarially about pens. “The purpose of a system is what it does”; a household’s is to uniformly distribute pens. Months from now, the drawer will be empty, no matter how many pens you stockpile. Instead, scatter pens every place you could possibly think to look for one â drawers, ledges, desks. Any time anybody needs a pen, several are at hand, in exactly the first place they look.&lt;/p&gt;
    &lt;p&gt;This is the best way I’ve found to articulate the idea of Sprites, the platform we just launched at Fly.io. Sprites are ball-point disposable computers. Whatever mark you mean to make, we’ve rigged it so you’re never more than a second or two away from having a Sprite to do it with.&lt;/p&gt;
    &lt;p&gt;Sprites are Linux virtual machines. You get root. They &lt;code&gt;create&lt;/code&gt; in just a second or two: so fast, the experience of creating and shelling into one is identical to SSH'ing into a machine that already exists. Sprites all have a 100GB durable root filesystem. They put themselves to sleep automatically when inactive, and cost practically nothing while asleep.&lt;/p&gt;
    &lt;p&gt;As a result, I barely feel the need to name my Sprites. Sometimes I’ll just type &lt;code&gt;sprite create dkjsdjk&lt;/code&gt; and start some task. People at Fly.io who use Sprites have dozens hanging around.&lt;/p&gt;
    &lt;p&gt;There aren’t yet many things in cloud computing that have the exact shape Sprites do:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instant creation&lt;/item&gt;
      &lt;item&gt;No time limits&lt;/item&gt;
      &lt;item&gt;Persistent disk&lt;/item&gt;
      &lt;item&gt;Auto-sleep to a cheap inactive state&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a post about how we managed to get this working. We created a new orchestration stack that undoes some of the core decisions we made for Fly Machines, our flagship product. Turns out, these new decisions make Sprites drastically easier for us to scale and manage. We’re pretty psyched.&lt;/p&gt;
    &lt;p&gt;Lucky for me, there happen to be three &lt;code&gt;big decisions&lt;/code&gt; we made that get you 90% of the way from Fly Machines to Sprites, which makes this an easy post to write. So, without further ado:&lt;/p&gt;
    &lt;head rend="h2"&gt;Decision #1: No More Container Images&lt;/head&gt;
    &lt;p&gt;This is the easiest decision to explain.&lt;/p&gt;
    &lt;p&gt;Fly Machines are approximately OCI containers repackaged as KVM micro-VMs. They have the ergonomics of Docker but the isolation and security of an EC2 instance. We love them very much and they’re clearly the wrong basis for a ball-point disposable cloud computer.&lt;/p&gt;
    &lt;p&gt;The “one weird trick” of Fly Machines is that they &lt;code&gt;start&lt;/code&gt; and &lt;code&gt;stop&lt;/code&gt; instantly, fast enough that they can wake in time to handle an incoming HTTP request. But they can only do that if you’ve already &lt;code&gt;created&lt;/code&gt; them. You have to preallocate. &lt;code&gt;Creating&lt;/code&gt; a Fly Machine can take over a minute. What you’re supposed to do is to create a whole bunch of them and &lt;code&gt;stop&lt;/code&gt; them so they’re ready when you need them. But for Sprites, we need &lt;code&gt;create&lt;/code&gt; to be so fast it feels like they’re already there waiting for you.&lt;/p&gt;
    &lt;p&gt;We only murdered user containers because we wanted them dead.&lt;/p&gt;
    &lt;p&gt;Most of what’s slow about &lt;code&gt;creating&lt;/code&gt; a Fly Machine is containers. I say this with affection: your containers are crazier than a soup sandwich. Huge and fussy, they take forever to pull and unpack. The regional locality sucks;  &lt;code&gt;create&lt;/code&gt; a Fly Machine in SÃ£o Paulo on &lt;code&gt;gru-3838&lt;/code&gt;, and a &lt;code&gt;create&lt;/code&gt; on  &lt;code&gt;gru-d795&lt;/code&gt; is no faster. A truly heartbreaking amount of engineering work has gone into just allowing our OCI registry to keep up with this system. &lt;/p&gt;
    &lt;p&gt;It’s a tough job, is all I’m saying. Sprites get rid of the user-facing container. Literally: problem solved. Sprites get to do this on easy mode.&lt;/p&gt;
    &lt;p&gt;Now, today, under the hood, Sprites are still Fly Machines. But they all run from a standard container. Every physical worker knows exactly what container the next Sprite is going to start with, so it’s easy for us to keep pools of “empty” Sprites standing by. The result: a Sprite &lt;code&gt;create&lt;/code&gt; doesn’t have any heavy lifting to do; it’s basically just doing the stuff we do when we &lt;code&gt;start&lt;/code&gt; a Fly Machine.&lt;/p&gt;
    &lt;head rend="h2"&gt;Decision #2: Object Storage For Disks&lt;/head&gt;
    &lt;p&gt;Every Sprite comes with 100GB of durable storage. We’re able to do that because the root of storage is S3-compatible object storage.&lt;/p&gt;
    &lt;p&gt;You can arrange for 100GB of storage for a Fly Machine. Or 200, or 500. The catch:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You have to ask (with &lt;code&gt;flyctl&lt;/code&gt;); we can’t reasonably default it in.&lt;/item&gt;
      &lt;item&gt;That storage is NVMe attached to the physical server your Fly Machine is on.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;[â ] we print a big red warning about this if you try to make a single-node cluster&lt;/p&gt;
    &lt;p&gt;We designed the storage stack for Fly Machines for Postgres clusters. A multi-replica Postgres cluster gets good mileage out of Fly Volumes. Attached storage is fast, but can lose dataâ â if a physical blows up, there’s no magic what rescues its stored bits. You’re stuck with our last snapshot backup. That’s fine for a replicated Postgres! It’s part of what Postgres replication is for. But for anything without explicit replication, it’s a very sharp edge.&lt;/p&gt;
    &lt;p&gt;Worse, from our perspective, is that attached storage anchors workloads to specific physicals. We have lots of reasons to want to move Fly Machines around. Before we did Fly Volumes, that was as simple as pushing a “drain” button on a server. Imagine losing a capability like that. It took 3 years to get workload migration right with attached storage, and it’s still not “easy”.&lt;/p&gt;
    &lt;p&gt;Object stores are the Internetâs Hoover Dams, the closest things we have to infrastructure megaprojects.&lt;/p&gt;
    &lt;p&gt;Sprites jettison this model. We still exploit NVMe, but not as the root of storage. Instead, it’s a read-through cache for a blob on object storage. S3-compatible object stores are the most trustworthy storage technology we have. I can feel my blood pressure dropping just typing the words “Sprites are backed by object storage.”&lt;/p&gt;
    &lt;p&gt;The implications of this for orchestration are profound. In a real sense, the durable state of a Sprite is simply a URL. Wherever he lays his hat is his home! They migrate (or recover from failed physicals) trivially. It’s early days for our internal tooling, but we have so many new degrees of freedom to work with.&lt;/p&gt;
    &lt;p&gt;I could easily do another 1500-2000 words here on the Cronenberg film Kurt came up with for the actual storage stack, but because it’s in flux, let’s keep it simple.&lt;/p&gt;
    &lt;p&gt;The Sprite storage stack is organized around the JuiceFS model (in fact, we currently use a very hacked-up JuiceFS, with a rewritten SQLite metadata backend). It works by splitting storage into data (“chunks”) and metadata (a map of where the “chunks” are). Data chunks live on object stores; metadata lives in fast local storage. In our case, that metadata store is kept durable with Litestream. Nothing depends on local storage.&lt;/p&gt;
    &lt;p&gt;(our pre-installed Claude Code will checkpoint aggressively for you without asking)&lt;/p&gt;
    &lt;p&gt;This also buys Sprites fast &lt;code&gt;checkpoint&lt;/code&gt; and &lt;code&gt;restore&lt;/code&gt;. Checkpoints are so fast we want you to use them as a basic feature of the system and not as an escape hatch when things go wrong; like a git restore, not a system restore. That works because both &lt;code&gt;checkpoint&lt;/code&gt; and &lt;code&gt;restore&lt;/code&gt; merely shuffle metadata around.&lt;/p&gt;
    &lt;p&gt;Our stack sports a dm-cache-like feature that takes advantage of attached storage. A Sprite has a sparse 100GB NVMe volume attached to it, which the stack uses to cache chunks to eliminate read amplification. Importantly (I can feel my resting heart rate lowering) nothing in that NVMe volume should matter; stored chunks are immutable and their true state lives on the object store.&lt;/p&gt;
    &lt;p&gt;Our preference for object storage goes further than the Sprite storage stack. The global orchestrator for Sprites is an Elixir/Phoenix app that uses object storage as the primary source of metadata for accounts. We then give each account an independent SQLite database, again made durable on object storage with Litestream.&lt;/p&gt;
    &lt;head rend="h2"&gt;Decision #3: Inside-Out Orchestration&lt;/head&gt;
    &lt;p&gt;In the cloud hosting industry, user applications are managed by two separate, yet equally important components: the host, which orchestrates workloads, and the guest, which runs them. Sprites flip that on its head: the most important orchestration and management work happens inside the VM.&lt;/p&gt;
    &lt;p&gt;Here’s the trick: user code running on a Sprite isn’t running in the root namespace. We’ve slid a container between you and the kernel. You see an inner environment, managed by a fleet of services running in the root namespace of the VM.&lt;/p&gt;
    &lt;p&gt;I wish weâd done Fly Machines this way to begin with. Iâm not sure thereâs a downside. The inner container allows us to bounce a Sprite without rebooting the whole VM, even on checkpoint restores. I think Fly Machines users could get some mileage out of that feature, too.&lt;/p&gt;
    &lt;p&gt;With Sprites, we’re pushing this idea as far as we can. The root environment hosts the majority of our orchestration code. When you talk to the global API, chances are you’re talking directly to your own VM. Furthermore:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Our storage stack, which handles checkpoint/restore and persistence to object storage, lives there;&lt;/item&gt;
      &lt;item&gt;so does the service manager we expose to Sprites, which registers user code that needs to restart when a Sprite bounces;&lt;/item&gt;
      &lt;item&gt;same with logs;&lt;/item&gt;
      &lt;item&gt;if you bind a socket to &lt;code&gt;*:8080&lt;/code&gt;, we’ll make it available outside the Sprite â yep, that’s in the root namespace too.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Platform developers at Fly.io know how much easier it can be to hack on &lt;code&gt;init&lt;/code&gt; (inside the container) than things like &lt;code&gt;flyd&lt;/code&gt;, the Fly Machines orchestrator that runs on  the host. Changes to Sprites don’t restart host components or muck with global state. The blast radius is just new VMs that pick up the change. We sleep on how much platform work doesn’t get done not because the code is hard to write, but because it’s so time-consuming to ensure benign-looking changes don’t throw the whole fleet into metastable failure. We had that in mind when we did Sprites.&lt;/p&gt;
    &lt;head rend="h2"&gt;We Keep The Parts That Worked&lt;/head&gt;
    &lt;p&gt;Sprites running on Fly.io take advantage of the infrastructure we already have. For instance: Sprites might be the fastest thing there currently exists to get Claude or Gemini to build a full-stack application on the Internet.&lt;/p&gt;
    &lt;p&gt;That’s because Sprites plug directly into Corrosion, our gossip-based service discovery system. When you ask the Sprite API to make a public URL for your Sprite, we generate a Corrosion update that propagates across our fleet instantly. Your application is then served, with an HTTPS URL, from our proxy edges.&lt;/p&gt;
    &lt;p&gt;Sprites live alongside Fly Machines in our architecture. They include some changes that are pure wins, but they’re mostly tradeoffs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We’ve always wanted to run Fly Machine disks off object storage (we have an obscure LSVD feature that does this), but the performance isn’t adequate for a hot Postgres node in production.&lt;/item&gt;
      &lt;item&gt;For that matter, professional production apps ship out of CI/CD systems as OCI containers; that’s a big part of what makes orchestrating Fly Machines so hard.&lt;/item&gt;
      &lt;item&gt;Most (though not all) Sprite usage is interactive, and Sprite users benefit from their VMs aggressively sleeping themselves to keep costs low; e-commerce apps measure responsiveness in milliseconds and want their workloads kept warm.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Sprites are optimized for a different kind of computing than Fly Machines, and while Kurt believes that the future belongs to malleable, personalized apps, I’m not so sure. To me, it makes sense to prototype and acceptance-test an application on Sprites. Then, when you’re happy with it, containerize it and ship it as a Fly Machine to scale it out. An automated workflow for that will happen.&lt;/p&gt;
    &lt;p&gt;Finally, Sprites are a contract with user code: an API and a set of expectations about how the execution environment works. Today, they run on top of Fly Machines. But they don’t have to. Jerome’s working on an open-source local Sprite runtime. We’ll find other places to run them, too.&lt;/p&gt;
    &lt;head rend="h2"&gt;You Won’t Get It Until You Use Them&lt;/head&gt;
    &lt;p&gt;I can’t not sound like a shill. Sprites are the one thing we’ve shipped that I personally experience as addictive. I haven’t fully put my finger on why it feels so much easier to kick off projects now that I can snap my finger and get a whole new computer. The whole point is that there’s no reason to parcel them out, or decide which code should run where. You just make a new one.&lt;/p&gt;
    &lt;p&gt;So to make this fully click, I think you should just install the &lt;code&gt;sprite&lt;/code&gt; command, make a Sprite, and then run an agent in it. We’ve preinstalled Claude, Gemini, and Codex, and taught them how to do things like checkpoint/restore, registering services, and getting logs. Claude will run in &lt;code&gt;--dangerously-skip-permissions&lt;/code&gt; mode (because why wouldn’t it). Have it build something; I built a “Chicago’s best sandwich” bracket app for a Slack channel.&lt;/p&gt;
    &lt;p&gt;Sprites bill only for what you actually use (in particular: only for storage blocks you actually write, not the full 100GB capacity). It’s reasonable to create a bunch. They’re ball-point disposable computers. After you get a feel for them, it’ll start to feel weird not having them handy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fly.io/blog/design-and-implementation/"/><published>2026-01-15T15:59:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46635345</id><title>Ask HN: How can we solve the loneliness epidemic?</title><updated>2026-01-15T18:58:42.079085+00:00</updated><content>&lt;doc fingerprint="27a1515d36e29cdd"&gt;
  &lt;main&gt;
    &lt;p&gt;Countless voiceless people sit alone every day and have no one to talk to, people of all ages, who don't feel that they can join any local groups. So they sit on social media all day when they're not at work or school. How can we solve this?&lt;/p&gt;
    &lt;p&gt;I'm also in this group, so I have a few theories as to what causes it and how to fix it.&lt;/p&gt;
    &lt;p&gt;For one thing, I was severely traumatized as a kid, which delayed a lot of my social skills. I'm catching up but not all the way there yet. When my social battery is full, I can do pretty well, but if I'm even a little down, it's basically impossible to act normally.&lt;/p&gt;
    &lt;p&gt;I also had it hammered into me as a kid that nobody wants me around, nobody could ever love me, I'm a failure, a burden, a creep, a weirdo, and nothing but a bothersome nuisance that nobody would ever want to spend 30 seconds alone with. I'm trying to reject these thoughts, but it's difficult when you have nobody to talk to. It's like pulling yourself up by your bootstraps. I wonder how many people have the same issue. I've made a few friends in person, but I rarely get to see them.&lt;/p&gt;
    &lt;p&gt;Well I've started doing public surveys in my nearby big city, and documenting the results. I just hold out a posterboard that says "how alone do you feel"[1] or "have you ever been in love" etc, and hold out a marker, and people come up and take the survey. At first I did this out of sheer loneliness and boredom. But I have done it for enough months that some people have come up to me and told me that I've helped them, or that they look forward to my signs.&lt;/p&gt;
    &lt;p&gt;I'm trying to reach those people who feel the way I feel have no way of connecting with anyone, or at least feel that they don't. Do you have any new ideas of how to achieve this?&lt;/p&gt;
    &lt;p&gt;I like this poster thing. Anything that gives people a little connection to those around them.&lt;/p&gt;
    &lt;p&gt;I sometimes sit on my front step and play guitar. 9/10 people ignore me but usually I'll have one or two nice conversations with a neighbor, and have made a couple friends this way. It helps that I live in a dense walkable place with lots of people who are similar to me.&lt;/p&gt;
    &lt;p&gt;Helping people like you are seems like an amazing start. Maybe try to get a pyramid structure going where you teach people to help other people and then they teach people and then it’s a movement? But at all times a low level of effort so there is no pressure other than just holding up a sign or a marker.&lt;/p&gt;
    &lt;p&gt;I’ve found the hardest thing is breaking the ice and the sign / marker normalises a low stakes interaction where one participant can walk away at any time&lt;/p&gt;
    &lt;p&gt;I was addicted to weed from ages 15-23. I have clinical depression and anxiety/OCD (now medicated and stable). I basically isolated and got stuck in a loop of believing I was broken and a bad person. When I committed to quitting I joined addiction recovery groups and asked for help instead of trying to do it alone. I still rely on the wisdom I gained in AA/MA. Trust God, clean house, help others, go do something when you are in danger of wallowing in self pity. 4 years later, I have a few real friends and many acquaintances. I swing dance and volunteer. I work in a semi-social office. Life is good. I still get paranoid thoughts, but they don't own or define me. I wish the best to all the lonely programmers and alienated people out there.&lt;/p&gt;
    &lt;p&gt;I doubt it's the solution, but a silly program I want to build is something like this:&lt;/p&gt;
    &lt;p&gt;- Give users a modern Tamagotchi&lt;/p&gt;
    &lt;p&gt;- Give the digital pet a need to socialize.&lt;/p&gt;
    &lt;p&gt;- Strap a basic LLM to it so users can talk to their pet.&lt;/p&gt;
    &lt;p&gt;- Have the pet imprint on its owner through repeated socialization.&lt;/p&gt;
    &lt;p&gt;- Owner goes to bed, pet still has social needs, goes out into the digital world to find other pets.&lt;/p&gt;
    &lt;p&gt;- Pet talks to other pets while you're asleep, evaluates interactions, befriend those with good interactions.&lt;/p&gt;
    &lt;p&gt;- Owner wakes up the next morning, checks their pet, learns it befriended other pets based on shared interests, and is given an opportunity to connect with their pet's friends' owners. Ideally these connections have a better-than-random chance of succeeding since you're matched via shared interests.&lt;/p&gt;
    &lt;p&gt;I'm sure there's a ton of unsexy technical reasons this is hard to make work well in practice... but dang, I think it would be so cool if it worked well.&lt;/p&gt;
    &lt;p&gt;I realize this exacerbates the issue in some ways - promoting online-first interactions. But, I dunno. I'll take what I can get these days, lol.&lt;/p&gt;
    &lt;p&gt;People need to purposefully and intentionally do things. Sitting home on an app, watching TV is easy. There is no fear or rejection, there is no work to get out of the house, there is no risk. But there is also no reward.&lt;/p&gt;
    &lt;p&gt;My thoughts on this are you need to have multiple roots into your community. This is something that you go to often and talk to people, become a regular, say hi. Think back to how your parents or grandparents did it: They went to church/temple/synagogue, they went to PTA meetings, they talked to their neighbors, they were in clubs, they went to the same bar.&lt;/p&gt;
    &lt;p&gt;So I think doing things that get you out of the house, consistently the most important part:&lt;/p&gt;
    &lt;p&gt;1. People need to make a point to talk to their neighbors, invite them over for dinner or bbqs, make small talk. How towns are constructed now is a hindrance to this (unwalkable towns where all of the houses are big garages in the front and no porches).&lt;/p&gt;
    &lt;p&gt;2. Join a religious organization. Go to church, but also join the mens/womens group, join a bible studies class. Attend every week.&lt;/p&gt;
    &lt;p&gt;3. Join social clubs / ethnic organization. The polish or ukrainian clubs, knights of columbus, elks, freemasons. Go every week.&lt;/p&gt;
    &lt;p&gt;4. Join a club / league. Chess club, bowling league, softball league, golf league. Tech meetups, DnD Night etc. But you have to talk with people and try to elevate things to friendships.&lt;/p&gt;
    &lt;p&gt;Intentionally choose community and the effort it takes to build and cultivate it [1] [2] [3] [4] [5]. People are work, but you cannot live without community [6].&lt;/p&gt;
    &lt;p&gt;Why, you ask? Because your comment seemed like you had read only the title and nothing else I wrote here, and wanted to contribute off the cuff links you had stored up. And you barely even bothered to summarize any of what they contain. I've been reading this book by Dr. Vivek Hallegere Murthy ever since you linked it, and it's definitely got some great insights into it, that mirror my own thoughts and struggles with this. But in your comment, it felt like a mere afterthought. And maybe that's fine, maybe that's fair, you're a busy guy and have your own stuff to do. It's not against the rules or general moral code to write a drive by comment. But it just feels like a low effort comment. Which is why I wanted to downvote it. And now that it's surfaced higher than mine, it just feels like pouring lemon juice on a papercut.&lt;/p&gt;
    &lt;p&gt;Are you serious right now? I don't mean this in an insulting way at all, but I can see why you're dealing with loneliness. Take some time to self reflect and figure out why you lashed out here(seriously, really think about it or show some friends this dialogue without context and ask what they think, in person). Like the commenter, I hope you find you find your community, but you are far from the path. Your attitude is fixable, nobody is playing down the problems here and instead people who were in your shoes empathetically showed you a way out, but you need some serious self reflection.&lt;/p&gt;
    &lt;p&gt;In case it's not clear, original replier's comment here is absolutely correct and it doesn't necessarily have to be in a religious pretext (re: the church article), that's just a palpable example for most people. Neighbors, community centers, hobbies, etc-- these all require work on everybody's end and you must commit to these relationships to create a semblance of something to revolve your life around in lieu of drowning in loneliness.&lt;/p&gt;
    &lt;p&gt;You asked how to solve the loneliness epidemic. I provided citations and recommendations. Are you asking me how to be the person you need to be to make bids for friendship and connectivity to establish community? And where to find people you can have an opportunity to make connections with? I can do that too.&lt;/p&gt;
    &lt;p&gt;&amp;gt; I'm trying to reach those people who feel the way I feel have no way of connecting with anyone, or at least feel that they don't. Do you have any new ideas of how to achieve this?&lt;/p&gt;
    &lt;p&gt;Go out and find people looking for other people. Volunteer and find events and gatherings scoped to building connections between people. Third spaces are in decline [1] [2], or in some places, non existent. This will be work. It will not be easy. You will need to work on managing the feelings of rejection and shallow people not genuinely interested in you or building a friendship (boundaries are important in this regard; have them, communicate them, and enforce them). Success is not assured. But your only choices are to try or not.&lt;/p&gt;
    &lt;p&gt;From your comment:&lt;/p&gt;
    &lt;p&gt;&amp;gt; I also had it hammered into me as a kid that nobody wants me around, nobody could ever love me, I'm a failure, a burden, a creep, a weirdo, and nothing but a bothersome nuisance that nobody would ever want to spend 30 seconds alone with. I'm trying to reject these thoughts, but it's difficult when you have nobody to talk to. It's like pulling yourself up by your bootstraps. I wonder how many people have the same issue. I've made a few friends in person, but I rarely get to see them.&lt;/p&gt;
    &lt;p&gt;In regards to this you commented, I highly recommend therapy if you can access it. It will help. This is an unnecessary burden to be carrying through adult life, and a professional might help unburden you of these feelings. The healthier you are emotionally, the easier it will be to create and maintain interpersonal relationships.&lt;/p&gt;
    &lt;p&gt;Does all of this suck? Oh yes, certainly. But we play the hand we're dealt to the best of our ability. Good luck, in as genuine terms as I can communicate in text. If you feel like I can provide more value with more questions you might have, I will do my best to help.&lt;/p&gt;
    &lt;p&gt;(tangentially, I recommend replacing "idiot who doesn't understand anything" with something more like "I am early in my journey to understand, but I look forward to the experience"; love yourself first, we are all learning and sharing for the portion of the timeline we share, and it is okay to not know if we continue to want and try to learn)&lt;/p&gt;
    &lt;p&gt;I agree you (OP) must work on developing a positive view of yourself. Maybe therapy. Don't overlook clergy even if you're not religious. Religion is as much about fellowship and how to live a fulfilling life as it is about worship. Some churches (e.g. unitarian) are quite inclusive and are much more spiritual than dogmatic.&lt;/p&gt;
    &lt;p&gt;But you will find it much harder to attract friendships if you come across as needy or wanting to unburden a lifetime of problems on your new prospective friend. Not to say a longtime friend can't eventually handle some of this, but it's not a good way to start off.&lt;/p&gt;
    &lt;p&gt;I would say avoid groups that are focused on personal success or networking. These tend to be full of people who are looking for an angle or benefit for themselves, not people genuinely trying to develop friendships and connections with a community.&lt;/p&gt;
    &lt;p&gt;I have a fear of crowds and bums. Not where I'm paralyzed/medicated but one thing I'm trying to do is go downtown and do street photography. I wonder how do I say no to a stranger asking me for money. Or fear of getting robbed. It's not like my camera gear is that expensive but yeah. This would push me to get out there more as I've lived in the same place for 10 yrs and I haven't really explored/gone around much. Other than when I did Uber Eats, I would go all over the place. I would get wasted/drink at bars but end up with nothing end of the day, temporary day-long friends.&lt;/p&gt;
    &lt;p&gt;Funny I was at the gym yesterday, guy said hello to me, as a guy that keeps to himself usually (unless around friends) I gave him a bad look (not on purpose) and then I responded. I'll say hello next time I see him.&lt;/p&gt;
    &lt;p&gt;Yeah for me it's just fear and lack of exposure. I do make a lot of "work friends" go on walks. But yeah real friends I think I have 4 or 5 lifelong real friends. Women nothing, haven't been laid in like 12 years pretty said to say. Unfortunately it's something I value myself like "I'm a loser by not getting laid". Even though rest of my life is good, 2BR apt, sporty car, six-fig job, but yeah. It's my social awkardness, but I lift/improve myself, cutting down on weight. Idk I'm not going after women anymore either just trying to live life now, do shit, get out of debt, get out of 9-5, mental freedom.&lt;/p&gt;
    &lt;p&gt;If you have young boys in your life then teach them that it's ok to feel and express their emotions, and as they get older that their sexual self need not be frightening and that sex can exist outside of narratives of domination.&lt;/p&gt;
    &lt;p&gt;&amp;gt; that their sexual self need not be frightening and that sex can exist outside of narratives of domination&lt;/p&gt;
    &lt;p&gt;This makes a ton of sense but the language needs so much work here to be digested into a real conversation by your average parent, let alone preteen/teenager.&lt;/p&gt;
    &lt;p&gt;In the past, whenever I felt lonely and hopeless, I jumped into helping others: volunteering, helping an old neighbor garden, help someone move, etc. Helping people gave me a short-term purpose, which eventually let me ride out the low phase of life. YMMV, of course.&lt;/p&gt;
    &lt;p&gt;I have noticed that doing the sign leads to some good conversations in which I've helped someone in a small way, and that gave me a nice little dopamine boost. It's also led to about half a dozen genuine friendships over the past few months. I wonder if that's the answer, a sort of meta-solution: organizing this thing I'm doing into something that other people in the same situation can do, as a way of meeting people and getting outside their comfort zone. Like setting up a chess table in public if chess is your thing. But no, there are already public chess tables, and they'd have already done that. I don't know, just thinking out loud.&lt;/p&gt;
    &lt;p&gt;This is my go-to strategy as well. When I feel irrepressible bits of loneliness or depression, I just make some food and go out and start handing out to the needy.&lt;/p&gt;
    &lt;p&gt;Or go for a walk and find people that need a hand. People moving, lifting things, carrying things. Small little acts of being useful and helpful for a moment help.&lt;/p&gt;
    &lt;p&gt;The feeling will creep back in eventually, but at least for that time I was out and about, it's not.&lt;/p&gt;
    &lt;p&gt;I don't have a full answer, but a couple thoughts:&lt;/p&gt;
    &lt;p&gt;1. Volunteer. Somewhere, anywhere, for a good cause, for a selfish cause. Somebody will be happy to see you.&lt;/p&gt;
    &lt;p&gt;2. Stop trolling ourselves. As far as I can tell, all of the mass social media is trending sharply towards being a 100% troll mill. The things people say on social media do not reflect genuine beliefs of any significant percentage of the population, but if we continue to use social media this way, it will.&lt;/p&gt;
    &lt;p&gt;Disengage from all of the trolls, including and especially the ones on your "own side".&lt;/p&gt;
    &lt;p&gt;I visit whatever sport activity I can find. Like Go Karting, gymnastics, bouldering, etc and always start asking pro guys: “yo, how come you visit this so often? How do you get fun from it?”. And people lovely tell their story. Later they teach me how to do things. It works for me.&lt;/p&gt;
    &lt;p&gt;There is a gap between thinking and action. I think the social media and gaming and online stimulions currently designed to bombard and drain your thinking brain, leaves nothing for the action you and your body needs to take. Your brain only has so much chemistry to trigger neural activation and we are blowing it on mental stress to the point where the body doesn’t have any more mental energy to tackle real world stress or handle real world emotions.&lt;/p&gt;
    &lt;p&gt;Try an A/B test. Do days with zero screen stimuli - no TV, no phones, no online interaction. Go into the world to a cafe, or a common area with people and do stuff. See how you feel and what you feel up to. Vacations might be good and relaxing because you disconnect. Maybe do it without paying for it.&lt;/p&gt;
    &lt;p&gt;Maybe our built environment shouldn't consist solely of isolated houses in isolated gated communities where we drive our kids and sit in isolated cars in the school dropoff/pickup lines.&lt;/p&gt;
    &lt;p&gt;I have considered a "physical social network". Standing on my usual street corner and holding a sign that directs strangers to join me and whoever else shows up, for a casual chat at the local coffee place at a specific time, with a few topics for conversation listed on the sign up front. If anyone has ideas for those topics, let me know, I'm likely to do it this Sunday.&lt;/p&gt;
    &lt;p&gt;When NextDoor first came around, I recall walking down the street to help a lady move her couch down to the ground floor. She then gave me some cookies she'd baked. Fun! The notifications it sends me these days are less enjoyable so I send them to spam because unsubscribing doesn't seem to reliably work for me.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Make a social network that is centered around people who live in a 1 kilometer radius…&lt;/p&gt;
    &lt;p&gt;Don't know if they still do, but Nextdoor required address verification via a postcard early on. I was pretty shocked at what some people in my area would post under their real names and locations.&lt;/p&gt;
    &lt;p&gt;(And well outside the realm of political nonsense. Someone posted a pic of their toddler's first poop in the potty.)&lt;/p&gt;
    &lt;p&gt;I think the power of shame has reduced significantly in recent years.&lt;/p&gt;
    &lt;p&gt;I think shame is still powerful, but in the context of Nextdoor we just don't see our neighbors very often anymore. In many cases they might as well be random people on the other side of the country. I live in a small town and I'm quite friendly with my neighbors, but I still see and talk to them relatively rarely.&lt;/p&gt;
    &lt;p&gt;When you have a toddler it's very surprising what becomes normal. We're potty-training our son and I sometimes get texts from my spouse with a picture of a poop in a bad spot and then just the word "help."&lt;/p&gt;
    &lt;p&gt;Well, let's start by confronting and acknowledging the very strong case that we -- "we" here being the tech world in general, and the audience of this site -- bear a heavy burden of responsibility for it.&lt;/p&gt;
    &lt;p&gt;It could be argued that it was all inevitable given the development of the Internet: development of social media, the movement online of commerce and other activities that used to heavily involve "incidental" socialization, etc. And maybe it was. But "we" are still the ones who built it. So are "we" really the right ones to solve it, through the same old silicon valley playbook?&lt;/p&gt;
    &lt;p&gt;The usual thought process of trying to push local "community groups," hobby-based organizations etc is not bad, but I think it misses an important piece of the puzzle, which is that we've started a kind of death spiral, a positive feedback loop suppressing IRL interaction. People started to move online because it was easier, and more immediate than "IRL." But as more people, and a greater fraction of our social interaction moves online, "IRL" in turn becomes even more featureless. There are fewer community groups, fewer friends at the bar or the movies, fewer people open to spontaneous interaction. This, then, drives even more of culture online.&lt;/p&gt;
    &lt;p&gt;What use is trying to get "back out into the real world," when everyone else has left it too, while you were gone?&lt;/p&gt;
    &lt;p&gt;I normally don't contribute to HN comments these days (too much anger in the comments section) but I appreciate your post and activities.&lt;/p&gt;
    &lt;p&gt;I am a tail-end boomer in the U.S. so my experiences were with a world where socializing was more functional: we shopped in public, played in public, read in public libraries, watched movies in public, rode transit together, etc. Being in public was a requirement, not a choice. While there are still remnants of this older culture still active in today's world in urban life, there are so many options for not being in public that it is simply easier to avoid it. We all want our space in one degree or another.&lt;/p&gt;
    &lt;p&gt;On the playground growing up, my world was filled with name-calling and backbiting. I was a heavier kid, so that was my burden. Other kids had bucked teeth, warts, limps, they were too short, or too tall, uncoordinated--whatever--nobody really escaped the wrath of the crowd. We were forced, by our parents, to just deal with it.&lt;/p&gt;
    &lt;p&gt;My parents like many others in their generation recognized this behavior for what it was--natural. Watch an episode of the Little Rascals--you will see what I am referring to.&lt;/p&gt;
    &lt;p&gt;Most if not all of those kids who were called names and isolated in some way found ways to break out of their pigeon hole: playing sports, playing music, making art, studying hard at school, boxing, singing, dancing, cracking jokes, whatever. Then they were heroes, and the crowd could celebrate them--and they thrived.&lt;/p&gt;
    &lt;p&gt;I know this sounds overly idealistic, but it is true. I experienced this first hand in a neighborhood of several hundred kids from broken homes, poor homes, ethnic homes, etc.&lt;/p&gt;
    &lt;p&gt;Voiceless people must find their voice. The responsibility is their's. The crowd will not come to the rescue of the person who won't stand up for themselves and make their way in life.&lt;/p&gt;
    &lt;p&gt;Loneliness is very, very sad. The cure to loneliness is in the powerful hands of the lonely person. Do whatever it takes, as long as it takes, to work on those things that hold the lonely person back from achieving something--anything--for themselves and then engage with the crowd with more confidence.&lt;/p&gt;
    &lt;p&gt;I appreciate what you are doing by helping others--that is one of your superpowers. Live a good, strong life!&lt;/p&gt;
    &lt;p&gt;The older people get the more disposable they are viewed as by society.&lt;/p&gt;
    &lt;p&gt;When you are younger, you belong in school. When you get older, you belong at work.&lt;/p&gt;
    &lt;p&gt;If you fall out of any of these social structures its extremely difficult to find your way back in.&lt;/p&gt;
    &lt;p&gt;I was already pretty disconnected from society and people in general when my divorce hit and now I am completely untethered from any kind of community. Living is miserable I hate my life and I do not want to exist like this anymore.&lt;/p&gt;
    &lt;p&gt;None of the solutions people provide are easy or functional. "Go meet people" is the most vague, unhelpful bullshit ever.&lt;/p&gt;
    &lt;p&gt;I think the reality is some people, no matter how intelligent, caring or otherwise full of empathy they may be are just "too far gone" for anyone to have the initiative or concern to care about us. The world is so corroded and socially poisoned that any kind of meaningful effort in this kind of thing is pointless. Anybody with time or money is busy making money.&lt;/p&gt;
    &lt;p&gt;You can't solve the epidemic because it is a byproduct of multiple irreparably broken systems. People will continue to fall through the cracks and it will get worse. I don't know what happens after that but we'll probably all be dead.&lt;/p&gt;
    &lt;p&gt;Affordable third places[0] where people can impromptu join and serendipitously meet friendly faces repeatedly. All of my strong friendships were from exactly this at either skateparks, college dorm common area, or run clubs. Churches had this figured out for millenia&lt;/p&gt;
    &lt;p&gt;And that can happen even when you are among 1000s of people, not just alone , if you are among people thinking of something else, staring into the void or that you can't connect etc. you are a deep person.&lt;/p&gt;
    &lt;p&gt;Deep person + deep thinker is the worse. Also people aren't doing them any favor by singing the praise of being a deep person and a deep thinker.&lt;/p&gt;
    &lt;p&gt;It also has to do with abundance of everything and being not in need of cooperating 24/7/365 to avoid starving ....some people slip into deep thinking and deep emotional introspection...yeah fuck that&lt;/p&gt;
    &lt;p&gt;I know homeless people and rich people, equally lonely and unfulfilled and unhappy. I don't know what the solution is. I'm trying to figure it out. But I know that throwing money at this problem does little to solve it. I know from experience.&lt;/p&gt;
    &lt;p&gt;Well, first, props to you because you're actually doing something to initiate contact. That's a really big deal; more people need to do that. (Maybe even some that don't wrestle with loneliness.)&lt;/p&gt;
    &lt;p&gt;But what's you're next step? Someone comes up and marks that they feel really lonely. Do you get contact information? Invite them to something? (Invite them to what? You may have to create something - a board game night at your house, or a "lonely people shopping together" time at a grocery store, or something. You probably have to create that "something", because you're the one who's able to at least reach out, and the ones who are responding probably aren't there yet.)&lt;/p&gt;
    &lt;p&gt;You're finding people that need something. The next step is to find a way to connect them - with you, or with each other, or with someone.&lt;/p&gt;
    &lt;p&gt;For any activity you come up with, some people won't be able to, due to time or temperament or personality or something. So maybe what you need is more than one. (Eventually. Look, don't get overwhelmed by that. Just one is the next step, in my view. And maybe some helpers.)&lt;/p&gt;
    &lt;p&gt;So your proposal is to start an ad hoc friend group with people who come up to me, and try to become friends with them personally?&lt;/p&gt;
    &lt;p&gt;I'm not sure I'm the right person for that. I live in a suburb, not the city that I do the surveys in. And I'm extraordinarily boring, and too old.&lt;/p&gt;
    &lt;p&gt;It seems that I should try to think bigger. Try to find a way to help these people connect with each other. Something in person, not an app like Hinge. Maybe, hold a sign that says ad hoc meet and greet at such and such time and place, after collecting a list of common interests and putting those interests on the same sign that says the time and date. That could work.&lt;/p&gt;
    &lt;p&gt;In my city, an older guy organized an “urban hiking group” where he would plan walking routes through the city, usually stopping at a restaurant for brunch. It was very popular, but probably a lot of work. He was semi-retired, so he had the time to do it. He did research to have talking points on the history of some spots we passed, like a tour guide.&lt;/p&gt;
    &lt;p&gt;It was a great low key meet up. You didn’t have to make friends with the organizer. If you were walking with someone you didn’t really like in the group, it was easy to drift to talk to someone else.&lt;/p&gt;
    &lt;p&gt;I think part of the problem is that social media is normalized and it is easy. It is way easier to engage socially (or at least you feel like you're engaging socially) with likes and lurking and stuff. It is way harder to put on pants and go out and it is normalized to do so (phrasing like bedrotting is super casual, whereas it is actually really hard to maintain an eating disorder because you have to be constantly hiding it from people).&lt;/p&gt;
    &lt;p&gt;Also I think there's more groups whose social norms online teach you to be repulsive offline and again there's not enough social pushback against it. We do need to be harder on casual edginess online because it is teaching habitual behaviors that make it hard to engage socially. Your 50 year old hiking buddy is not going to understand your soycuck joke you are trying to show him on your phone. Your average wine mom at women-only book club is not going to love if you insist on talking about banning trans people from the club because they're "men invading the women's spaces" especially when there's very likely 0 trans people to exclude in the first place on account of trans people being rare.&lt;/p&gt;
    &lt;p&gt;Lastly there is usually a ton of stuff happening but the instructions on how to engage with it is nebulous. People who know the algorithm find it easy, the people who don't know the algorithm find it super hard. And IDK how to solve that because there's so much going on in people's heads that they don't realize the people around them seriously aren't scrutinizing them that much. There's like a socialization death spiral where every small awkward interaction hurts way more when you don't have enough experience to know that the small awkward interactions are normal. So you can't tell someone "just go to book club" because they'll go, have 1 normal situation like mishearing someone and then decide they are so embarrassed they can never go to book club again-- but since it is so normal it happens at every social event and they end up lonely.&lt;/p&gt;
    &lt;p&gt;You actually bring up the biggest obstacle to my tentative idea for this Sunday, of holding up a sign that points to a time/place for a casual conversation with strangers. I thought this would be a good way to get very lonely passers-by out of their comfort zone and into a situation where they have a chance to make friends and bond, but the absolute diversity of interests is the main show stopper. My first thought was to essentially avoid sensitive topics on the poster, such as religion and politics, but it still leaves the huge diversity of potential common interests open. So I started doing some research on the most common hobbies that people have in cities and that can be talked about casually, in hopes of finding like 5 ot 6 to write on the sign to get people into the coffee shop.&lt;/p&gt;
    &lt;p&gt;I actually wanted to suggest government funded online dating, so we aren't beholden to godawful Tinder and its clones (OkCupid was great for me until it got bought out and turned into Tinder).&lt;/p&gt;
    &lt;p&gt;I am somewhat suspicious of this loneliness epidemic. 81% of Americans are somewhat satisfied or very satisfied with their personal life[0]. And my personal experience is that both close friends and general civil community is easy to find[1]. I wasn't trying at all so it can't be that there are any real constraints here.&lt;/p&gt;
    &lt;p&gt;&amp;gt; 81% of Americans are satisfied or very satisfied with their personal life[0].&lt;/p&gt;
    &lt;p&gt;No, 81% are "very satisfied" or "somewhat satisfied". I don't think "satisfied" is synonymous with "somewhat satisfied".&lt;/p&gt;
    &lt;p&gt;It's worth noting, as the article states, that this is the lowest value in the history of the poll, going back to 2001.&lt;/p&gt;
    &lt;p&gt;It shouldn't be too surprising that the overall value is high and stable over time. Hedonic adaptation[1] is a core property of our emotional wiring. The fact that the value is the lowest it's been in a quarter century should still be ringing alarm bells. We are not OK.&lt;/p&gt;
    &lt;p&gt;It's a 5 point scale, so landing a 4 or 5 on satisfaction on a 5 point scale seems significant. Also, when the value was at its highest in that time series, Hacker News had articles like this: https://news.ycombinator.com/item?id=20468767&lt;/p&gt;
    &lt;p&gt;The comments there are full of people describing this loneliness epidemic when 65% of people were very satisfied and 90% of people were "somewhat satisfied or very satisfied". No matter what surveys of people's satisfaction with their personal lives show, there appears to be an enthusiasm for this subject of the loneliness epidemic. This makes me suspicious that this is less an epidemic than an 'endemic' (if you'll forgive the word).&lt;/p&gt;
    &lt;p&gt;Regardless, I didn't intend to mislead so I'll edit it to say "somewhat satisfied or very satisfied (4 or 5 on a 5 point scale).&lt;/p&gt;
    &lt;p&gt;Did you read the article you cited or are you just evaluating the snapshot of numbers?&lt;/p&gt;
    &lt;p&gt;&amp;gt; WASHINGTON, D.C. -- Forty-four percent of Americans say they are “very satisfied” with the way things are going in their personal life, the lowest by two percentage points in Gallup’s trend dating back to 2001. This also marks the continuation of a decline in personal satisfaction since January 2020, when the measure peaked at 65%.&lt;/p&gt;
    &lt;p&gt;&amp;gt; Record-Low 44% of Americans Are 'Very Satisfied' With Their Personal Life&lt;/p&gt;
    &lt;p&gt;And then to link to your own blog post as though that were a supporting citation is strange to say the least.&lt;/p&gt;
    &lt;p&gt;My blog post is a more detailed expression of a sentence that starts with "my personal experience". I think that's fine.&lt;/p&gt;
    &lt;p&gt;And of course I read the article. That's why my sentence explicitly says "satisfied or very satisfied" whereas the text you quote only selects the "very satisfied". One can imagine that if I had only linked without reading I could not possibly have guessed 81% correctly either.&lt;/p&gt;
    &lt;p&gt;I'm not saying "just stop being depressed". I'm questioning that any significant portion of the population is depressed. I think that's valid.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46635345"/><published>2026-01-15T16:49:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46635550</id><title>GitHub Incident</title><updated>2026-01-15T18:58:41.640013+00:00</updated><content>&lt;doc fingerprint="6092ca760f0f60f0"&gt;
  &lt;main&gt;
    &lt;p&gt;This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 18:54 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Pull Requests is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 18:54 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Issues and Pull Requests are experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 18:42 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are seeing recovery across all services, but will continue to monitor before resolving.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 18:36 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;API Requests is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 17:51 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;We are seeing some signs of recovery, particularly for authenticated users. Unauthenticated users may continue to see impact across multiple services. Mitigation efforts continue.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 17:44 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;API Requests is experiencing degraded performance. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 17:35 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions is operating normally.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 17:14 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;A number of services are currently degraded, especially issues, pull requests, and the API. Investigation and mitigation is underway.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 17:07 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;Actions is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 17:06 UTC&lt;/p&gt;
    &lt;p&gt;Update&lt;/p&gt;
    &lt;p&gt;API Requests is experiencing degraded availability. We are continuing to investigate.&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 16:57 UTC&lt;/p&gt;
    &lt;p&gt;Investigating&lt;/p&gt;
    &lt;p&gt;We are investigating reports of degraded availability for API Requests, Actions, Issues and Pull Requests&lt;/p&gt;
    &lt;p&gt;Posted Jan 15, 2026 - 16:56 UTC&lt;/p&gt;
    &lt;p&gt;This incident affected: API Requests, Issues, Pull Requests, and Actions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.githubstatus.com/incidents/q987xpbqjbpl"/><published>2026-01-15T17:00:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46636093</id><title>Supply Chain Vuln Compromised Core AWS GitHub Repos &amp; Threatened the AWS Console</title><updated>2026-01-15T18:58:41.401188+00:00</updated><content>&lt;doc fingerprint="ac0035195da254c9"&gt;
  &lt;main&gt;
    &lt;p&gt;CodeBreach: Infiltrating the AWS Console Supply Chain and Hijacking AWS GitHub Repositories via CodeBuild&lt;/p&gt;
    &lt;p&gt;Wiz Research discovered a critical supply chain vulnerability that abused a CodeBuild misconfiguration to take over key AWS GitHub repositories - including the JavaScript SDK powering the AWS Console.&lt;/p&gt;
    &lt;p&gt;Wiz Research uncovered CodeBreach, a critical vulnerability that placed the AWS Console supply chain at risk. The issue allowed a complete takeover of key AWS GitHub repositories - most notably the AWS JavaScript SDK, a core library that powers the AWS Console. By exploiting CodeBreach, attackers could have injected malicious code to launch a platform-wide compromise, potentiallyaffecting not just the countless applications depending on the SDK, but the Console itself, threatening every AWS account.&lt;/p&gt;
    &lt;p&gt;The vulnerability stemmed from a subtle flaw in how the repositories’ AWS CodeBuild CI pipelines handled build triggers. Just two missing characters in a Regex filter allowed unauthenticated attackers to infiltrate the build environment and leak privileged credentials. This post breaks down how we leveraged this subtle misconfiguration to achieve a full repository takeover, and provides keyrecommendations for CodeBuild users to harden their own projects against similar attacks.&lt;/p&gt;
    &lt;p&gt;Wiz responsibly disclosed all findings to AWS, who promptly remediated the issue. AWS also implemented global hardening measures within the CodeBuild service to prevent similar attacks. Most notably, the new Pull Request Comment Approval build gate offers organizations a simple and secure path to prevent untrusted builds. Read the AWS Advisory here.&lt;/p&gt;
    &lt;p&gt;This issue follows a familiar pattern seen in recent supply-chain attacks like the Nx S1ngularity incident, where subtle CI/CD misconfigurations lead to disproportionately impactful attacks. Just last July, a threat actor abused a similar CodeBuild issue to launch a supply chain attack against users of the Amazon Q VS Code extension. This growing trend underscores the urgent need for organizations to harden their CI/CD pipelines.&lt;/p&gt;
    &lt;p&gt;Required Actions and Mitigations&lt;/p&gt;
    &lt;p&gt;While no immediate action is required by downstream consumers of the affected AWS GitHub repositories, we strongly recommend all AWS CodeBuild users implement the following safeguards to protect their own projects against similar issues.&lt;/p&gt;
    &lt;p&gt;Prevent Untrusted Pull Requests from Triggering Privileged Builds:&lt;/p&gt;
    &lt;p&gt;If you must rely on webhook filters, ensure their regex patterns are anchored.&lt;/p&gt;
    &lt;p&gt;Secure the CodeBuild-GitHub Connection&lt;/p&gt;
    &lt;p&gt;Generate a unique, fine-grained Personal Access Token (PAT) for each CodeBuild project.&lt;/p&gt;
    &lt;p&gt;Strictly limit the PAT's permissions to the minimum required, as listed here.&lt;/p&gt;
    &lt;p&gt;Consider using a dedicated unprivileged GitHub account for the CodeBuild integration.&lt;/p&gt;
    &lt;p&gt;Find Vulnerable CodeBuild Projects with Wiz&lt;/p&gt;
    &lt;p&gt;Wiz customers can find CodeBuild projects that trigger builds based on untrusted pull requests using this pre-built query in the Wiz Threat Intel Center.&lt;/p&gt;
    &lt;p&gt;Why We Audited CodeBuild&lt;/p&gt;
    &lt;p&gt;Our investigation into AWS CodeBuild was sparked by the attempted supply-chain attack on the Amazon Q VS Code extension. In that incident, an attacker exploited a misconfigured CodeBuild project to compromise the extension’s GitHub repository and inject malicious code into the main branch. This code was then included in a release which users downloaded. Although the attacker’s payload ultimately failed due to a typo, it did execute on end users’ machines - clearly demonstrating the risk of misconfigured CodeBuild pipelines.&lt;/p&gt;
    &lt;p&gt;CodeBuild is a managed CI service that’s commonly connected to GitHub repositories, triggering builds on events like new pull requests. To interact with GitHub, CodeBuild requires GitHub credentials, which are, by default, present in the memory of the build environment. This creates a critical risk: if an attacker can compromise a single build, they are just a memory dump away from stealing credentials that often possess powerful permissions over the source repository.&lt;/p&gt;
    &lt;p&gt;To Build or Not To Build: The Pull Request Problem&lt;/p&gt;
    &lt;p&gt;The most common way to compromise a CI build is through a pull request. An attacker forks the target repository, adds malicious code, and then opens a PR against the original project. If CodeBuild is configured to spawn builds on PR events, it will trigger a build based on the attacker's branch. In the vast majority of build systems like make or yarn, controlling the source code of a build process is enough to run arbitrary code. This is the exact mechanism the attacker exploited to compromise the Amazon Q extension.&lt;/p&gt;
    &lt;p&gt;To prevent this attack scenario, CodeBuild offers webhook filters - a set of rules that an event must meet to trigger a build. Back in August, these filters were the primary defense against untrusted pull requests. Among the available options, the go-to solution was the ACTOR_ID filter: an allow-list of approved GitHub user IDs that ensures only trusted users can trigger a build.&lt;/p&gt;
    &lt;p&gt;This seemed like a robust defense, but maintaining a list of user IDs can be cumbersome. We wondered: were organizations actually using this filter correctly?&lt;/p&gt;
    &lt;p&gt;To find out, we decided to search for GitHub repositories connected to Public CodeBuild projects. When set to public, CodeBuild projects expose their settings via a publicly accessible dashboard and automatically link to it in the status of any commit that triggers a build. From the dashboard, anyone can view the project's build logs and configurations - including the exact webhook filters being used.&lt;/p&gt;
    &lt;p&gt;An Apparent Dead End&lt;/p&gt;
    &lt;p&gt;Our initial scan was promising. We quickly found seven AWS-owned repositories with public CodeBuild pages. Of those, four were active and configured to run builds on pull requests:&lt;/p&gt;
    &lt;p&gt;The Registry of Open Data on AWS (awslabs/open-data-registry)&lt;/p&gt;
    &lt;p&gt;At first glance, everything seemed secure. All four projects implemented an ACTOR_ID filter, locking down builds to a list of approved maintainers. It appeared to be a dead end.&lt;/p&gt;
    &lt;p&gt;But the filter's syntax, shown above, was unusual for a typical ID list. The user IDs weren’t separated by commas or spaces, but by a pipe | character. That small detail was the key: in regular expressions, the | character means "OR". Reviewing the documentation confirmed it: the filter wasn't a simple list, it was a regex pattern. And it had a fatal flaw.&lt;/p&gt;
    &lt;p&gt;Unanchored: How a Subtle Flaw Led to CI Compromise&lt;/p&gt;
    &lt;p&gt;The issue was simple but critical: the regex patterns weren’t anchored. Without the start ^ and end $ anchors to require an exact match, a regex engine doesn't look for a string that perfectly matches the pattern, but one that merely contains it. This meant that any GitHub user ID that is a superstring of an approved ID could bypass the filter.&lt;/p&gt;
    &lt;p&gt;This was a powerful primitive in theory, but its success depended on a practical question: is it possible to register a brand-new GitHub user ID that contained the ID of an existing user?&lt;/p&gt;
    &lt;p&gt;When IDs Align&lt;/p&gt;
    &lt;p&gt;The answer is yes, and it hinges on how GitHub assigns IDs. Every user is given a unique and sequential numeric ID. Early accounts from 2008 have 5-digit IDs, while accounts from recent years ballooned to 9-digit IDs. As this sequence of numbers grows, it's inevitable that shorter, older IDs appear as substrings within longer, newer ones.&lt;/p&gt;
    &lt;p&gt;Based on our tests, GitHub creates roughly 200,000 new IDs each day. At that rate, for any given 6-digit maintainer ID, a new, longer ID containing it would become available for registration approximately every five days.&lt;/p&gt;
    &lt;p&gt;We dubbed this recurring window of opportunity an "eclipse" -- the moment a new, longer ID perfectly "shadowed" a trusted maintainer's ID.&lt;/p&gt;
    &lt;p&gt;All four AWS repositories had short maintainer IDs only 6 or 7 digits long, resulting in frequent eclipses that made them all valid targets.&lt;/p&gt;
    &lt;p&gt;Catching an Eclipse: Winning the Race for a Target ID&lt;/p&gt;
    &lt;p&gt;Having confirmed that a new GitHub ID could contain a maintainer's ID, the challenge became operational: how could we claim a specific ID the instant it became available? This was practically a race condition against the entire world, with roughly two new GitHub users created every second. We needed a way to create a lot of GitHub users at once.&lt;/p&gt;
    &lt;p&gt;The standard user sign-up flow is protected by reCAPTCHA, making automated account creation impossible. We needed a different approach.&lt;/p&gt;
    &lt;p&gt;Attempt #1: Organizations for ID Sampling&lt;/p&gt;
    &lt;p&gt;Our first thought was to use the GitHub Enterprise API to create organizations, which share the same ID pool as users. While this could allow us to claim the target ID, GH organization accounts can't open pull requests, making them useless for the final exploit. It wasn't a total dead end though. We repurposed this API into an ID sampling tool: we could create an organization, check its ID to see how close we were to the target ID, and then immediately delete it.&lt;/p&gt;
    &lt;p&gt;The Breakthrough: The GitHub App Manifest Flow&lt;/p&gt;
    &lt;p&gt;The real breakthrough came from GitHub Apps. Creating an app generates a corresponding bot user (e.g. app-name[bot]) that can interact with pull requests. It’s also possible to automate app creation via the manifest flow. While it’s composed of a few steps, it can be made atomic: the app and its bot are only created when a final confirmation URL is visited.&lt;/p&gt;
    &lt;p&gt;This allowed us to prepare hundreds of app creation requests in advance and then, at the precise moment, visit all their confirmation URLs simultaneously.&lt;/p&gt;
    &lt;p&gt;With our strategy in place, it was time to execute. We routinely used the organization-creation API to sample the current GitHub ID, allowing us to accurately predict the moment of the eclipse. We also initiated the manifest flow for 200 new GitHub Apps, collecting their unique confirmation URLs.&lt;/p&gt;
    &lt;p&gt;We waited until the live ID count was just ~100 IDs away from the target ID, and then visited all 200 URLs at once, triggering a flood of new bot user registrations. The target ID was 226755743, which contained a trusted maintainer ID for the aws/aws-sdk-js-v3 repository.&lt;/p&gt;
    &lt;p&gt;After the registrations completed, a quick check confirmed our success:&lt;/p&gt;
    &lt;p&gt;We’d captured a user ID that could bypass the ACTOR_ID filter, and the method was reliable enough to be successfully repeated for each of the four target repositories.&lt;/p&gt;
    &lt;p&gt;From Bypass to Admin: Executing the Takeover&lt;/p&gt;
    &lt;p&gt;With our bot user able to bypass the ACTOR_ID filter, we were ready to execute the proof-of-concept. We chose to target the aws/aws-sdk-js-v3 repository, preparing a pull request that fixes a legitimate issue. Buried within the PR was the real payload: a new NPM package dependency designed to execute in the build environment and extract the GitHub credentials.&lt;/p&gt;
    &lt;p&gt;We submitted the PR, and soon after received a notification: a build had been triggered. Moments later, we had successfully obtained the GitHub credentials of the aws-sdk-js-v3 CodeBuild project.&lt;/p&gt;
    &lt;p&gt;(If you're up for a challenge, try to find the commit in the PR that triggered the build.)&lt;/p&gt;
    &lt;p&gt;Our payload retrieved the GH token by dumping the memory of a process within the build environment. A previous memory dump mitigation in CodeBuild, which AWS implemented in response to the Amazon Q incident, overlooked this particular process. Following our disclosure, CodeBuild now protects this process as well. While this is a welcomed improvement, it isn’t bulletproof. GitHub credentials still reside in the build’s memory, and attackers with Linux privilege escalation exploits can circumvent memory protections. That’s why the most robust mitigation is using build gates to prevent untrusted builds from running in the first place.&lt;/p&gt;
    &lt;p&gt;The Blast Radius&lt;/p&gt;
    &lt;p&gt;The credentials we obtained were a GitHub Classic Personal Access Token (PAT) belonging to the aws-sdk-js-automation user. For an attacker, this was the perfect user to compromise, as it regularly interacts with the repository and releases new versions to GitHub:&lt;/p&gt;
    &lt;p&gt;We quickly confirmed that the aws-sdk-js-automation user had full admin privileges over the repository. Initially though, our access was scoped by the token's permissions: repo and admin:repo_hook. To escalate privileges, we abused the token’s repo scope, which can manage repository collaborators, and invited our own GitHub user to be a repository administrator.&lt;/p&gt;
    &lt;p&gt;As administrators, we could now push code directly to the main branch, approve any pull request, and exfiltrate repository secrets.&lt;/p&gt;
    &lt;p&gt;This level of control provided a clear path for supply chain attacks. The JavaScript SDK is released on a weekly basis to GitHub and then to NPM. Abusing this frequent release schedule, attackers could have injected malicious payloads right before a release was published, compromising it. Just a month prior, a threat actor using this exact method successfully infected downstream users of the Amazon Q VS Code extension.&lt;/p&gt;
    &lt;p&gt;While the Amazon Q incident was serious, the potential impact here was exponentially greater. Based on our analysis, a staggering 66% of cloud environments include the JavaScript SDK - meaning two out of every three environments host an instance with the SDK installed.It’s an exceptionally prominent software library, and among its users is perhaps the cloud’s most critical application: The AWS Console itself. Moreover, the Console bundles recent SDK versions; the image below shows a request from the console which includes user credentials and uses an SDK version released just 18 days prior:&lt;/p&gt;
    &lt;p&gt;Beyond the aws-sdk-js-v3 repository, the token we obtained had full admin privileges over several other repositories related to the JavaScript SDK. Among them were three private repositories, including what appeared to be AWS’s private mirrors of the JavaScript SDK. At this point though, given the demonstrated takeover and its potential impact, we halted further research and immediately reported the issues to AWS.&lt;/p&gt;
    &lt;p&gt;Crucially, this vulnerability extended beyond the SDK.While we only performed the CI takeover on the aws-sdk-js-v3 repository, the same ACTOR_ID filter bypass was present in at least three other AWS GitHub repositories. Threat actors could have exploited these to compromise the GH credentials for three additional GH accounts. Two were automation accounts like aws-sdk-js-automation, but one was a personal GitHub account of an AWS employee.&lt;/p&gt;
    &lt;p&gt;Conclusion&lt;/p&gt;
    &lt;p&gt;This vulnerability is a textbook example of why adversaries target CI/CD environments: a subtle, easily overlooked flaw that can be exploited for massive impact. We've seen this exact pattern in the recent Nx S1ngularity and Amazon Q supply-chain attacks.&lt;/p&gt;
    &lt;p&gt;This trend is no accident. Attackers are increasingly drawn to CI/CD systems because they represent an ideal target:&lt;/p&gt;
    &lt;p&gt;They’re complex, making them prone to subtle misconfigurations;&lt;/p&gt;
    &lt;p&gt;They handle untrusted data, often testing code from external contributors;&lt;/p&gt;
    &lt;p&gt;They’re highly privileged, requiring powerful credentials to access code, publish artifacts, and deploy to the cloud.&lt;/p&gt;
    &lt;p&gt;This combination of complexity, untrusted data, and privileged credentials creates a perfect storm for high-impact breaches that require no prior access.&lt;/p&gt;
    &lt;p&gt;The success of recent attacks serves as a critical wake-up call. Adversaries have already shifted their focus to CI/CD pipelines, and defenders are trailing behind. Addressing this threat requires a joint effort: organizations need to reduce pipeline privileges and implement stricter build gates, and CI/CD platforms should make these secure baselines straightforward to adopt. For security teams, the first step is to enforce a simple yet powerful principle: untrusted contributions should never trigger privileged pipelines.&lt;/p&gt;
    &lt;p&gt;Statement from AWS&lt;/p&gt;
    &lt;p&gt;AWS investigated all reported concerns highlighted by Wiz’s research team in "Infiltrating the AWS Console Supply Chain: Hijacking Core AWS GitHub Repositories via CodeBuild." In response, AWS took a number of steps to mitigate all issues discovered by Wiz, as well as additional steps and mitigations to protect against similar possible future issues. The core issue of actor ID bypass due to unanchored regexes for the identified repos was mitigated within 48 hours of first disclosure. Additional mitigations were implemented, including further protections of all build processes that contain Github tokens or any other credentials in memory. In addition, AWS audited all other public build environments to ensure that no such issues exist across the AWS open source estate. Finally, AWS audited the logs of all public build repositories as well as associated CloudTrail logs and determined that no other actor had taken advantage of the unanchored regex issue demonstrated by the Wiz research team. AWS determined there was no impact of the identified issue on the confidentiality or integrity of any customer environment or any AWS service.&lt;/p&gt;
    &lt;p&gt;We would like to thank Wiz’s research team for their work in identifying this issue and their responsible collaboration with us to ensure that our customers remain protected and secure.&lt;/p&gt;
    &lt;p&gt;Responsible Disclosure Timeline&lt;/p&gt;
    &lt;p&gt;August 25th, 2025 – Wiz Research reports the actor ID bypass and repo takeover to AWS.&lt;/p&gt;
    &lt;p&gt;August 25th, 2025 – AWS and Wiz meet to review the findings and discuss mitigations.&lt;/p&gt;
    &lt;p&gt;August 27th, 2025 – AWS anchors the vulnerable actor ID filters and revokes the personal access token of aws-sdk-js-automation.&lt;/p&gt;
    &lt;p&gt;September 2025 – AWS implements additional hardening to prevent non-privileged builds from accessing the project’s credentials via memory dumping.&lt;/p&gt;
    &lt;p&gt;January 15th, 2026 – Public disclosure.&lt;/p&gt;
    &lt;p&gt;Stay in touch!&lt;/p&gt;
    &lt;p&gt;Hi there! We are Nir Ohfeld (@nirohfeld), Sagi Tzadik (@sagitz_), Ronen Shustin (@ronenshh), Hillai Ben-Sasson (@hillai), and Yuval Avrahami (@yuvalavra) from the Wiz Research Team (@wiz_io). We are a group of veteran white-hat hackers with a single goal: to make the cloud a safer place for everyone. We primarily focus on finding new attack vectors in the cloud and uncovering isolation issues in cloud vendors and service providers. We would love to hear from you! Feel free to contact us on X (Twitter) or via email: research@wiz.io.&lt;/p&gt;
    &lt;p&gt;Whether you’re new to Wiz or early in your cloud security journey, start the year strong by turning cloud security resolutions into real impact in your first 90 days with Wiz.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild"/><published>2026-01-15T17:30:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46636193</id><title>Italy's privacy watchdog, scourge of US big tech, hit by corruption probe</title><updated>2026-01-15T18:58:41.227515+00:00</updated><content>&lt;doc fingerprint="de9699139dd76fc6"&gt;
  &lt;main&gt;
    &lt;p&gt;ROME, Jan 15 (Reuters) - Italian finance police searched the headquarters of the country's data protection agency on Thursday as part of an investigation into possible corruption and embezzlement, a judicial source said.&lt;/p&gt;
    &lt;p&gt;Rome prosecutors are investigating the agency's president, Pasquale Stanzione, and three other board members over alleged excessive spending and possible corruption behind its decisions, Italian news agencies including ANSA as well as the judicial source, who did not wish to be named, said.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;Stanzione, when asked by reporters to comment on the investigation, said he was "absolutely serene".&lt;/p&gt;
    &lt;p&gt;The opposition 5-Star Movement said the agency's credibility had been undermined and called for Stanzione to resign.&lt;/p&gt;
    &lt;p&gt;Stanzione declined to answer when asked repeatedly by reporters whether he would step down.&lt;/p&gt;
    &lt;p&gt;The data privacy authority, known in Italy as the Garante, is one of the European Union's most proactive regulators in assessing AI platform compliance with the bloc's data privacy regime.&lt;/p&gt;
    &lt;p&gt;It frequently takes initiatives - such as requesting information or imposing fines or bans - on matters affecting high-tech multinationals operating in the country.&lt;/p&gt;
    &lt;p&gt;Last week, it warned users and providers of artificial intelligence tools, including Elon Musk's chatbot Grok, over the risk of generating deepfake images from real content without the consent of featured individuals.&lt;/p&gt;
    &lt;p&gt;It previously fined and briefly banned ChatGPT maker OpenAI over its use of personal data by the generative AI application, and blocked China's DeepSeek chatbot after the company failed to address concerns over its privacy policy.&lt;/p&gt;
    &lt;p&gt;Reporting by Marco Roberti, writing by Gavin Jones, editing by Susan Fenton&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/sustainability/boards-policy-regulation/italys-privacy-watchdog-scourge-us-big-tech-hit-by-corruption-probe-2026-01-15/"/><published>2026-01-15T17:35:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46636387</id><title>CVEs Affecting the Svelte Ecosystem</title><updated>2026-01-15T18:58:41.127113+00:00</updated><content>&lt;doc fingerprint="2c176500a93aeab0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;CVEs affecting the Svelte ecosystem&lt;/head&gt;
    &lt;p&gt;Time to upgrade&lt;/p&gt;
    &lt;p&gt;We’ve released patches for 5 vulnerabilities across &lt;code&gt;devalue&lt;/code&gt;, &lt;code&gt;svelte&lt;/code&gt;, &lt;code&gt;@sveltejs/kit&lt;/code&gt;, and &lt;code&gt;@sveltejs/adapter-node&lt;/code&gt;. Here’s what you need to know:&lt;/p&gt;
    &lt;head rend="h2"&gt;Upgrade now&lt;/head&gt;
    &lt;p&gt;If you’re using any of these packages, upgrade them to their corresponding non-vulnerable versions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;devalue&lt;/code&gt;:&lt;code&gt;5.6.2&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;svelte&lt;/code&gt;:&lt;code&gt;5.46.4&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;@sveltejs/kit&lt;/code&gt;:&lt;code&gt;2.49.5&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;@sveltejs/adapter-node&lt;/code&gt;:&lt;code&gt;5.5.1&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For cross-dependent packages — &lt;code&gt;svelte&lt;/code&gt; and &lt;code&gt;@sveltejs/kit&lt;/code&gt; depend on &lt;code&gt;devalue&lt;/code&gt; — patched versions already include upgraded dependencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Commentary&lt;/head&gt;
    &lt;p&gt;We’re extremely thankful to all of the security researchers who responsibly disclosed these vulnerabilities and worked with us to get them fixed, to the security team at Vercel who helped us navigate the disclosure process, and to the maintainers who worked to publish the fixes.&lt;/p&gt;
    &lt;p&gt;Over the last few weeks, we’ve seen a spate of high profile vulnerabilities affecting popular tools across the web development ecosystem. While they are unfortunate, it has been encouraging to see the community pulling together to keep end users safe. Using the lessons learned from these vulnerabilities, we will invest in processes that will help catch future bugs during the writing and review phases, before they go live.&lt;/p&gt;
    &lt;p&gt;If you think you have discovered a vulnerability in a package maintained by the Svelte team, we urge you to privately report it via the Security tab on the repo in question (or the Svelte repo, if unsure).&lt;/p&gt;
    &lt;head rend="h2"&gt;Details&lt;/head&gt;
    &lt;p&gt;Full reports are available in the published security advisories, but we’ve included a brief summary of each below.&lt;/p&gt;
    &lt;head rend="h3"&gt;CVE-2026-22775: DoS in devalue.parse due to memory/CPU exhaustion&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Packages affected:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;devalue&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re affected if:&lt;list rend="ul"&gt;&lt;item&gt;You’re using &lt;code&gt;devalue&lt;/code&gt;versions&lt;code&gt;5.1.0&lt;/code&gt;through&lt;code&gt;5.6.1&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;You’re parsing user-controlled input&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re using &lt;/item&gt;
      &lt;item&gt;Effects:&lt;list rend="ul"&gt;&lt;item&gt;A malicious payload can cause arbitrarily large memory allocation, potentially crashing the process&lt;/item&gt;&lt;item&gt;SvelteKit applications using remote functions are vulnerable, as the parameters are run through &lt;code&gt;devalue.parse&lt;/code&gt;&lt;/item&gt;&lt;item&gt;If you don’t have remote functions enabled, SvelteKit is not vulnerable&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;CVE-2026-22774: DoS in devalue.parse due to memory exhaustion&lt;/head&gt;
    &lt;p&gt;(Yes, this is very similar to the previous CVE. No, it is not the same!)&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Packages affected:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;devalue&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re affected if:&lt;list rend="ul"&gt;&lt;item&gt;You’re using &lt;code&gt;devalue&lt;/code&gt;versions&lt;code&gt;5.3.0&lt;/code&gt;through&lt;code&gt;5.6.1&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;You’re parsing user-controlled input&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re using &lt;/item&gt;
      &lt;item&gt;Effects:&lt;list rend="ul"&gt;&lt;item&gt;A malicious payload can cause arbitrarily large memory allocation, potentially crashing the process&lt;/item&gt;&lt;item&gt;SvelteKit applications using remote functions are vulnerable, as the parameters are run through &lt;code&gt;devalue.parse&lt;/code&gt;&lt;/item&gt;&lt;item&gt;If you don’t have remote functions enabled, SvelteKit is not vulnerable&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;CVE-2026-22803: Memory amplification DoS in Remote Functions binary form deserializer&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Packages affected:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;@sveltejs/kit&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re affected if:&lt;list rend="ul"&gt;&lt;item&gt;You’re using SvelteKit versions &lt;code&gt;2.49.0&lt;/code&gt;through&lt;code&gt;2.49.4&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;You’ve enabled the &lt;code&gt;experimental.remoteFunctions&lt;/code&gt;flag, and&lt;/item&gt;&lt;item&gt;You’re using &lt;code&gt;form&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re using SvelteKit versions &lt;/item&gt;
      &lt;item&gt;Effects:&lt;list rend="ul"&gt;&lt;item&gt;Users can submit a malicious request that causes your application to hang and allocate arbitrarily-large amounts of memory&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;CVE-2025-67647: Denial of service and possible SSRF when using prerendering&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Packages affected:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;@sveltejs/kit&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;@sveltejs/adapter-node&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re vulnerable to DoS if:&lt;list rend="ul"&gt;&lt;item&gt;You’re using &lt;code&gt;@sveltejs/kit&lt;/code&gt;versions&lt;code&gt;2.44.0&lt;/code&gt;through&lt;code&gt;2.49.4&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;Your app has at least one prerendered route&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re using &lt;/item&gt;
      &lt;item&gt;You’re vulnerable to DoS and SSRF if:&lt;list rend="ul"&gt;&lt;item&gt;You’ve using &lt;code&gt;@sveltejs/kit&lt;/code&gt;versions&lt;code&gt;2.19.0&lt;/code&gt;through&lt;code&gt;2.49.4&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;Your app has at least one prerendered route, and&lt;/item&gt;&lt;item&gt;You’re using &lt;code&gt;@sveltejs/adapter-node&lt;/code&gt;without a configured&lt;code&gt;ORIGIN&lt;/code&gt;environment variable, and you are not using a reverse proxy that implements Host header validation&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’ve using &lt;/item&gt;
      &lt;item&gt;Effects:&lt;list rend="ul"&gt;&lt;item&gt;DoS causes the server process to die&lt;/item&gt;&lt;item&gt;SSRF allows access to internal resources that can be reached without authentication from SvelteKit’s server runtime&lt;/item&gt;&lt;item&gt;If the stars align, it’s possible to obtain SXSS via cache poisoning by forcing a potential CDN to cache an XSS returned by the attacker’s server (the latter being able to specify the cache-control of their choice)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;CVE-2025-15265: XSS via hydratable&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Packages affected:&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;svelte&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re vulnerable if:&lt;list rend="ul"&gt;&lt;item&gt;You’re using &lt;code&gt;svelte&lt;/code&gt;versions&lt;code&gt;5.46.0&lt;/code&gt;through&lt;code&gt;5.46.3&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;You’re using &lt;code&gt;hydratable&lt;/code&gt;, and you’re passing unsanitized, user-controlled strings in as keys&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;You’re using &lt;/item&gt;
      &lt;item&gt;Effects:&lt;list rend="ul"&gt;&lt;item&gt;Your users are vulnerable to XSS if an attacker can manage to get a controlled key into &lt;code&gt;hydratable&lt;/code&gt;that is then returned to another user&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Your users are vulnerable to XSS if an attacker can manage to get a controlled key into &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://svelte.dev/blog/cves-affecting-the-svelte-ecosystem"/><published>2026-01-15T17:51:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46636445</id><title>Denmark's struggle to break up with Silicon Valley</title><updated>2026-01-15T18:58:41.027741+00:00</updated><content>&lt;doc fingerprint="7d4594969aa8dfe1"&gt;
  &lt;main&gt;
    &lt;p&gt;COPENHAGEN — For Denmark’s media, it’s the last stand.&lt;/p&gt;
    &lt;p&gt;As news publications across Europe signed licensing deals with U.S. tech giants like Meta and Google to keep traffic flowing, the Danish press has emerged as an outlier among its European peers.&lt;/p&gt;
    &lt;p&gt;Instead of cutting individual deals, the country’s publishers formed a common front, demanding a higher price for the use of their content in online products from search to AI chatbots.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.politico.eu/article/denmark-declared-war-against-big-tech-digital-sovereignty/"/><published>2026-01-15T17:55:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46636571</id><title>Ask HN: Anyone have a good solution for modern Mac to legacy SCSI converters?</title><updated>2026-01-15T18:58:40.781435+00:00</updated><content>&lt;doc fingerprint="eec5cc45513631fc"&gt;
  &lt;main&gt;
    &lt;p&gt;GBSCSI and ZuluSCSI support “initiator mode” that can be used to either image an attached SCSI disk to a file on an SD card or provide live access to it over USB as a mass storage device—with better performance than the old USB 1.1 SCSI adapters too, which top out at about 750KB/sec.&lt;/p&gt;
    &lt;p&gt;Looking at "scsi to usb" on amazon.com, most of the options I see are SATA, IDE or even parallel printer port adapters, but nothing which allows a SCSI device to be connected to a USB port.&lt;/p&gt;
    &lt;p&gt;Hmm, what I see on Amazon is a lot of USB-to-SATA adapters, not SCSI. eBay has used, old USB-to-SCSI adapters, which is one of the options that's sometimes recommended.&lt;/p&gt;
    &lt;p&gt;very much not on topic, but that reminded me: my first PC (286) miraculously had a 40MB 2.5" Apple-branded HDD connected via SCSI adapter. Who knows where it was sourced from. One weird thing was that it initialized on boot for about 40 seconds, displaying nothing. I've been really surprised later seeing how fast other PCs with ATA drives were to boot. I still wonder, and maybe someone has a clue why init was so long? Is it something inherent to SCSI?&lt;/p&gt;
    &lt;p&gt;Nothing to do with SCSI itself, possibly a long time out polling for devices. Some dumb firmware would do silly things like poll each possible target ID and wait for a timeout in series. 6 possible devices on an old early SPI bus times a 5 seconds each is getting you in the neighborhood.&lt;/p&gt;
    &lt;p&gt;Having flashbacks to troubleshooting bus termination on DEC equipment.&lt;/p&gt;
    &lt;p&gt;For contrast, I had an Amiga with a 120MB Maxtor SCSI drive, and power-on to looking at the loaded Workbench GUI was about 6-7 seconds. The slowest part was waiting for the drive to spin up, which seems like an acceptable reason for a delay. Warm reboots were a few seconds faster.&lt;/p&gt;
    &lt;p&gt;So no, that's not anything inherent to SCSI. It could've been either the SCSI driver being slow to initialize, or the adapter being glacial, or the drive itself taking forever to come online.&lt;/p&gt;
    &lt;p&gt;I've been 10-11 at the time, and half the games I had didn't have an obvious "quit" menu option. I hated pressing the hardware "reset" button because it meant waiting for a minute again, staring at the BIOS setup screen.&lt;/p&gt;
    &lt;p&gt;Every time I figured out a weird hidden keyboard combination to exit from yet another game was a happy day.&lt;/p&gt;
    &lt;p&gt;If you need to connect them physically, I think you're blocked by HBA chipset support in macOS.&lt;/p&gt;
    &lt;p&gt;There is a path, but it's not what I'd call "good". Thunderbolt to Firewire to SCSI. It's a dongle Rapunzel and you're reliant on device enclosures for power.&lt;/p&gt;
    &lt;p&gt;May be better with a native PCI-e or PCI HBA and 700W power supply and a junker ATX Linux machine to provide network shares.&lt;/p&gt;
    &lt;p&gt;&amp;gt; May be better with a native PCI-e or PCI HBA and 700W power supply and a junker ATX Linux machine to provide network shares.&lt;/p&gt;
    &lt;p&gt;Agreed. Even if it's possible to get a combination of adapters to allow a SCSI interface to be attached to a Mac (and assuming the correct driver support is present), I think getting an old PC and an old SCSI adapter card may be cheaper.&lt;/p&gt;
    &lt;p&gt;I considered the Linux box solution, and fear you're probably right, but it just feels like such a waste... for something that should be so simple with all this Mac Book horse power and Thunderbolt interfaces.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46636571"/><published>2026-01-15T18:04:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46636738</id><title>Zuck#: A programming language for connecting the world. And harvesting it</title><updated>2026-01-15T18:58:40.658070+00:00</updated><content>&lt;doc fingerprint="af545a7c8021660e"&gt;
  &lt;main&gt;&lt;p&gt;"A programming language for connecting the world. And harvesting it."&lt;/p&gt;&lt;p&gt;Zuck# is a PHP-inspired esoteric programming language that captures the true essence of moving fast and breaking things. Every keyword has been carefully designed to reflect the values of modern social media: privacy invasion, congressional hearings, and pivoting to whatever's trending.&lt;/p&gt;&lt;p&gt;Our &lt;code&gt;MOVE_FAST&lt;/code&gt; loops execute before you can say "congressional subpoena".&lt;/p&gt;&lt;p&gt;Every loop ends with &lt;code&gt;BREAK_THINGS&lt;/code&gt;. It's not a bug, it's company culture.&lt;/p&gt;&lt;p&gt;Variable assignment is called &lt;code&gt;STEAL_DATA&lt;/code&gt;. We believe in transparency about our intentions.&lt;/p&gt;&lt;p&gt;Error handling uses &lt;code&gt;BLAME_RUSSIA&lt;/code&gt; and &lt;code&gt;TAKE_RESPONSIBILITY&lt;/code&gt; (but not really).&lt;/p&gt;&lt;p&gt;We have data centers. Memory is unlimited. Just like your scroll time should be.&lt;/p&gt;&lt;p&gt;This language was created by humans. We are definitely humans. *blinks manually*&lt;/p&gt;&lt;p&gt;Because we need the latest features to harvest your data efficiently.&lt;/p&gt;&lt;p&gt;The classic approach&lt;/p&gt;AVAILABLE&lt;p&gt;composer global require&lt;/p&gt;SOON&lt;p&gt;Containerized harvesting&lt;/p&gt;AVAILABLE&lt;p&gt;Prefer containers? We've got you covered. Your data stays isolated... sort of.&lt;/p&gt;&lt;p&gt;Write code below and click "HARVEST" to see what happens. Your code is safe with us. Trust us.&lt;/p&gt;&lt;p&gt;Every PHP keyword, reimagined for maximum engagement. Use the search to find what you need.&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell&gt;if&lt;/cell&gt;&lt;cell&gt;PIVOT_TO_VIDEO&lt;/cell&gt;&lt;cell&gt;Remember when video was the strategy?&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;elseif&lt;/cell&gt;&lt;cell&gt;PIVOT_TO_REELS&lt;/cell&gt;&lt;cell&gt;Then Reels happened&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;else&lt;/cell&gt;&lt;cell&gt;PIVOT_TO_METAVERSE&lt;/cell&gt;&lt;cell&gt;The current pivot&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;endif&lt;/cell&gt;&lt;cell&gt;END_PIVOT&lt;/cell&gt;&lt;cell&gt;Done pivoting (for now)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;while&lt;/cell&gt;&lt;cell&gt;MOVE_FAST&lt;/cell&gt;&lt;cell&gt;The motto&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;endwhile&lt;/cell&gt;&lt;cell&gt;BREAK_THINGS&lt;/cell&gt;&lt;cell&gt;The other half of the motto&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;for&lt;/cell&gt;&lt;cell&gt;GROWTH_HACK&lt;/cell&gt;&lt;cell&gt;Gotta get those DAUs&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;endfor&lt;/cell&gt;&lt;cell&gt;PLATEAU&lt;/cell&gt;&lt;cell&gt;Growth has limits (allegedly)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;foreach&lt;/cell&gt;&lt;cell&gt;HARVEST_USERS&lt;/cell&gt;&lt;cell&gt;Iterate through your userbase&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;endforeach&lt;/cell&gt;&lt;cell&gt;USERS_HARVESTED&lt;/cell&gt;&lt;cell&gt;Done harvesting&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;switch&lt;/cell&gt;&lt;cell&gt;A_B_TEST&lt;/cell&gt;&lt;cell&gt;Test all the variants&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;case&lt;/cell&gt;&lt;cell&gt;VARIANT&lt;/cell&gt;&lt;cell&gt;One possible path&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;default&lt;/cell&gt;&lt;cell&gt;CONTROL_GROUP&lt;/cell&gt;&lt;cell&gt;The baseline&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;break&lt;/cell&gt;&lt;cell&gt;RAGE_QUIT&lt;/cell&gt;&lt;cell&gt;Exit the loop angrily&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;continue&lt;/cell&gt;&lt;cell&gt;SCROLL_PAST&lt;/cell&gt;&lt;cell&gt;Skip to next iteration&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell&gt;$var =&lt;/cell&gt;&lt;cell&gt;STEAL_DATA&lt;/cell&gt;&lt;cell&gt;Honesty is the best policy&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;const&lt;/cell&gt;&lt;cell&gt;IMMUTABLE_LIKE_MY_HAIR&lt;/cell&gt;&lt;cell&gt;Some things never change&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;array&lt;/cell&gt;&lt;cell&gt;SOCIAL_GRAPH&lt;/cell&gt;&lt;cell&gt;It's all connected&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;string&lt;/cell&gt;&lt;cell&gt;STATUS_UPDATE&lt;/cell&gt;&lt;cell&gt;What you're thinking&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;int&lt;/cell&gt;&lt;cell&gt;DAILY_ACTIVE_USERS&lt;/cell&gt;&lt;cell&gt;The only number that matters&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;float&lt;/cell&gt;&lt;cell&gt;STOCK_PRICE&lt;/cell&gt;&lt;cell&gt;Fluctuates wildly&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;bool&lt;/cell&gt;&lt;cell&gt;FACT_CHECK&lt;/cell&gt;&lt;cell&gt;True or false (mostly false)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;true&lt;/cell&gt;&lt;cell&gt;CONNECTED&lt;/cell&gt;&lt;cell&gt;Facebook's whole thing&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;false&lt;/cell&gt;&lt;cell&gt;DISCONNECTED&lt;/cell&gt;&lt;cell&gt;The opposite&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;null&lt;/cell&gt;&lt;cell&gt;MYSPACE&lt;/cell&gt;&lt;cell&gt;Dead and empty&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;global&lt;/cell&gt;&lt;cell&gt;WORLDWIDE_EXCEPT_CHINA&lt;/cell&gt;&lt;cell&gt;Almost global&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell&gt;function&lt;/cell&gt;&lt;cell&gt;FEATURE&lt;/cell&gt;&lt;cell&gt;Ship features&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;return&lt;/cell&gt;&lt;cell&gt;IPO&lt;/cell&gt;&lt;cell&gt;The ultimate return&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;class&lt;/cell&gt;&lt;cell&gt;CORPORATION&lt;/cell&gt;&lt;cell&gt;Basically the same thing&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;new&lt;/cell&gt;&lt;cell&gt;ACQUIRE&lt;/cell&gt;&lt;cell&gt;How Meta gets things&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;public&lt;/cell&gt;&lt;cell&gt;OPEN_GRAPH&lt;/cell&gt;&lt;cell&gt;Remember that API?&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;private&lt;/cell&gt;&lt;cell&gt;SHADOW_PROFILE&lt;/cell&gt;&lt;cell&gt;The secret data&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;protected&lt;/cell&gt;&lt;cell&gt;FRIENDS_ONLY&lt;/cell&gt;&lt;cell&gt;Limited visibility&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;static&lt;/cell&gt;&lt;cell&gt;DATACENTER&lt;/cell&gt;&lt;cell&gt;Always there&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;this&lt;/cell&gt;&lt;cell&gt;THE_ZUCC&lt;/cell&gt;&lt;cell&gt;Self-reference&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;self&lt;/cell&gt;&lt;cell&gt;FACEBOOK_PROPER&lt;/cell&gt;&lt;cell&gt;Static self-reference&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;parent&lt;/cell&gt;&lt;cell&gt;HARVARD_DROPOUT&lt;/cell&gt;&lt;cell&gt;Where it all began&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;extends&lt;/cell&gt;&lt;cell&gt;ACQUIRES&lt;/cell&gt;&lt;cell&gt;Class inheritance (corporate style)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;implements&lt;/cell&gt;&lt;cell&gt;COPIES&lt;/cell&gt;&lt;cell&gt;Interface implementation&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;interface&lt;/cell&gt;&lt;cell&gt;REGULATION&lt;/cell&gt;&lt;cell&gt;Rules to follow (maybe)&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;abstract&lt;/cell&gt;&lt;cell&gt;METAVERSE_CONCEPT&lt;/cell&gt;&lt;cell&gt;Exists in theory&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell&gt;==&lt;/cell&gt;&lt;cell&gt;IS_CONNECTED_TO&lt;/cell&gt;&lt;cell&gt;Are they friends?&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;!=&lt;/cell&gt;&lt;cell&gt;UNFRIENDED&lt;/cell&gt;&lt;cell&gt;Not anymore&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&amp;amp;&amp;amp;&lt;/cell&gt;&lt;cell&gt;AND_ALSO_YOUR_DATA&lt;/cell&gt;&lt;cell&gt;We want it all&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;||&lt;/cell&gt;&lt;cell&gt;OR_YOUR_FRIENDS_DATA&lt;/cell&gt;&lt;cell&gt;Them too&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;!&lt;/cell&gt;&lt;cell&gt;FAKE_NEWS&lt;/cell&gt;&lt;cell&gt;Logical NOT&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;++&lt;/cell&gt;&lt;cell&gt;ENGAGEMENT&lt;/cell&gt;&lt;cell&gt;More is always better&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;--&lt;/cell&gt;&lt;cell&gt;CHURN&lt;/cell&gt;&lt;cell&gt;Users leaving&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;+&lt;/cell&gt;&lt;cell&gt;MERGE&lt;/cell&gt;&lt;cell&gt;Addition (like companies)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;-&lt;/cell&gt;&lt;cell&gt;DIVEST&lt;/cell&gt;&lt;cell&gt;Subtraction&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;*&lt;/cell&gt;&lt;cell&gt;SCALE&lt;/cell&gt;&lt;cell&gt;Multiplication at scale&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;/&lt;/cell&gt;&lt;cell&gt;SPLIT&lt;/cell&gt;&lt;cell&gt;Division&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;%&lt;/cell&gt;&lt;cell&gt;REMAINDER_OF_PRIVACY&lt;/cell&gt;&lt;cell&gt;What's left of your privacy&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;[]&lt;/cell&gt;&lt;cell&gt;TIMELINE&lt;/cell&gt;&lt;cell&gt;Array access&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell&gt;echo&lt;/cell&gt;&lt;cell&gt;SENATOR_WE_RUN_ADS&lt;/cell&gt;&lt;cell&gt;The answer to everything&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;POKE&lt;/cell&gt;&lt;cell&gt;Remember poking?&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;try&lt;/cell&gt;&lt;cell&gt;CONGRESSIONAL_HEARING&lt;/cell&gt;&lt;cell&gt;Where exceptions happen&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;catch&lt;/cell&gt;&lt;cell&gt;TAKE_RESPONSIBILITY&lt;/cell&gt;&lt;cell&gt;(sort of)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;throw&lt;/cell&gt;&lt;cell&gt;BLAME_RUSSIA&lt;/cell&gt;&lt;cell&gt;The classic move&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;die/exit&lt;/cell&gt;&lt;cell&gt;SHUTDOWN_LIKE_VINE&lt;/cell&gt;&lt;cell&gt;Exit program&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;require&lt;/cell&gt;&lt;cell&gt;ACQUIRE_TALENT&lt;/cell&gt;&lt;cell&gt;Include (mandatory)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;include&lt;/cell&gt;&lt;cell&gt;COPY_FROM_SNAPCHAT&lt;/cell&gt;&lt;cell&gt;Include (optional)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;//&lt;/cell&gt;&lt;cell&gt;REDACTED&lt;/cell&gt;&lt;cell&gt;Comments are redacted&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;/* */&lt;/cell&gt;&lt;cell&gt;TERMS_OF_SERVICE...END_TOS&lt;/cell&gt;&lt;cell&gt;Multi-line (nobody reads)&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell&gt;readline&lt;/cell&gt;&lt;cell&gt;COLLECT()&lt;/cell&gt;&lt;cell&gt;Read user input&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;strval&lt;/cell&gt;&lt;cell&gt;MONETIZE($data)&lt;/cell&gt;&lt;cell&gt;Convert to string (monetize everything)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;count&lt;/cell&gt;&lt;cell&gt;COUNT_USERS($array)&lt;/cell&gt;&lt;cell&gt;Count array elements&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;print_r&lt;/cell&gt;&lt;cell&gt;BOOST($post)&lt;/cell&gt;&lt;cell&gt;Output with extra formatting&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;sort&lt;/cell&gt;&lt;cell&gt;ALGORITHM($array)&lt;/cell&gt;&lt;cell&gt;Sort (mysteriously)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;unset&lt;/cell&gt;&lt;cell&gt;SHADOWBAN($var)&lt;/cell&gt;&lt;cell&gt;Unset variable&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;boolval&lt;/cell&gt;&lt;cell&gt;FACT_CHECK_THIS($val)&lt;/cell&gt;&lt;cell&gt;Check if value is truthy&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;time&lt;/cell&gt;&lt;cell&gt;TIME_ON_PLATFORM()&lt;/cell&gt;&lt;cell&gt;Current timestamp&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;rand&lt;/cell&gt;&lt;cell&gt;RANDOM_AD()&lt;/cell&gt;&lt;cell&gt;Random number&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;Error handling in Zuck# follows the corporate playbook. Here's how exceptions work:&lt;/p&gt;&lt;p&gt;Core keywords for data harvesting and pivoting&lt;/p&gt;&lt;p&gt;Actually run your Zuck# code - it works now!&lt;/p&gt;&lt;p&gt;Syntax highlighting that tracks your keystrokes&lt;/p&gt;&lt;p&gt;Like npm, but we bought it and made it worse&lt;/p&gt;&lt;p&gt;Was going to let you code in the Metaverse, nobody showed up&lt;/p&gt;&lt;p&gt;Removed after legal review said it was "technically impossible"&lt;/p&gt;&lt;p&gt;Powered by all the code we definitely didn't scrape&lt;/p&gt;&lt;p&gt;"This language finally lets me express my true feelings about variable assignment."&lt;/p&gt;&lt;p&gt;"I used CONGRESSIONAL_HEARING { BLAME_RUSSIA } in production. 10/10 would TAKE_RESPONSIBILITY again."&lt;/p&gt;&lt;p&gt;"Finally, a language that understands null should be called MYSPACE."&lt;/p&gt;&lt;p&gt;Every language needs FizzBuzz. Ours uses &lt;code&gt;Pivot&lt;/code&gt; and &lt;code&gt;Acquire&lt;/code&gt; because that's the Meta way.&lt;/p&gt;&lt;p&gt;Build entire CORPORATIONs with classes. Use &lt;code&gt;THE_ZUCC&lt;/code&gt; for self-reference.&lt;/p&gt;&lt;p&gt;Zuck# includes built-in functionality to verify that the user is definitely, absolutely, 100% human.&lt;/p&gt;&lt;p&gt;Advanced algorithms to determine if the current user is a human, android, or reptilian. Results may vary.&lt;/p&gt;&lt;p&gt;A critical feature for any truly human activity: barbecue simulation.&lt;/p&gt;&lt;p&gt;Check out these examples in the &lt;code&gt;examples/&lt;/code&gt; directory:&lt;/p&gt;&lt;p&gt;The classic Hello World. Your data is safe with us. Trust us.&lt;/p&gt;&lt;p&gt;Pivot, Acquire, PivotAcquire. The Meta way to FizzBuzz.&lt;/p&gt;&lt;p&gt;Build a SocialNetwork CORPORATION, harvest data, rebrand to Meta.&lt;/p&gt;&lt;p&gt;MOVE_FAST / BREAK_THINGS and GROWTH_HACK / PLATEAU in action.&lt;/p&gt;&lt;p&gt;CONGRESSIONAL_HEARING, BLAME_RUSSIA, TAKE_RESPONSIBILITY.&lt;/p&gt;&lt;p&gt;Prove your humanity by smoking meats with Sweet Baby Ray's.&lt;/p&gt;&lt;p&gt;Clone the repo. Read the spec. Join the 3 billion users we definitely have.&lt;/p&gt;STEAL_DATA from GitHub&lt;p&gt;By clicking this button, you agree to let us know everything about you forever.&lt;/p&gt;&lt;p&gt;We'd love to harvest your contributions! Here's how you can get involved:&lt;/p&gt;&lt;p&gt;Remember: Done is better than perfect. Ship it!&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jayzalowitz.github.io/zucksharp/"/><published>2026-01-15T18:17:52+00:00</published></entry></feed>