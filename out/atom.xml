<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-29T03:03:56.843638+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46413053</id><title>Show HN: Pion SCTP with RACK is 70% faster with 30% less latency</title><updated>2025-12-29T03:04:08.576314+00:00</updated><content>&lt;doc fingerprint="21e41095e1799bd5"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;What is SCTP?&lt;/head&gt;
    &lt;p&gt;SCTP stands for Stream Control Transmission Protocol. At a basic level, SCTP is designed to be reliable, handle de-duplication of packets, and support packets that may be delivered in order or out of order. Beyond transporting messages, SCTP can also set up a connection between users. On a deeper level, SCTP includes native support for multiplexing: multiple applications can take advantage of a single transport connection. SCTP also supports multi-homing, which enables automatic failover from a primary connection to a secondary one.&lt;/p&gt;
    &lt;p&gt;At the most basic level, it lets you reliably send information from one computer to another without any complications.&lt;/p&gt;
    &lt;head rend="h3"&gt;What is SCTP used for?&lt;/head&gt;
    &lt;p&gt;SCTPâ€™s uses can generally fit into two cases:&lt;/p&gt;
    &lt;head rend="h4"&gt;1. Sending some amount of data.&lt;/head&gt;
    &lt;p&gt;Imagine a scenario where two people are texting when one person remembers a picture that they want to send. As they text back and forth, an image gets uploaded, which takes some time to get sent. SCTP can handle multiple things going on at the same time and doesnâ€™t delay any messages from being sent just because an image is being uploaded! Thanks to SCTP, text messages can be safely delivered to each person and nothing in their conversation is lost in transit or delayed just because something else is being transferred at the same time as their messages.&lt;/p&gt;
    &lt;p&gt;Building on this idea, users can share larger files with each other. This includes anything: birthday videos, audio recordings, even boring paperwork; anything thatâ€™s a file can be sent!&lt;/p&gt;
    &lt;head rend="h4"&gt;2. Sending small amounts of data with a purpose.&lt;/head&gt;
    &lt;p&gt;In a new scenario, imagine two people who are texting back and forth when one person gets hungry. They send a message saying, â€œI want a pizza!â€ When the other person receives the text, they think, â€œMaybe I should do something about that!â€ The recipient can choose to do something useful for the sender with that information.&lt;/p&gt;
    &lt;p&gt;This is the blueprint for many awesome technologies today, as it opens up the possibility of controlling one computer from a different computer. Consider a surgeon who performs an operation involving a remote-controlled device that needs to respond with as little latency as possible. Similarly, real-time navigation systems also need to respond to changes in traffic conditions quickly in order to avoid congested or unsafe areas due to accidents or weather conditions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Other uses:&lt;/head&gt;
    &lt;p&gt;SCTP can be used for online multiplayer games where every frame counts, including first-person shooters and fighting games. Taking the remote surgery example in this direction leads to the idea of cloud gaming, as players can have their inputs sent to a different device than the one that theyâ€™re using while still being able to play the game!&lt;/p&gt;
    &lt;p&gt;SCTP is also used inside web browsers via WebRTC and has found use in AI applications and cryptocurrency-related technologies. Additionally, payment verification can similarly benefit from secure and fast communication.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why SCTP for WebRTC?&lt;/head&gt;
    &lt;p&gt;SCTP is used for WebRTC because of its ability to send information via reliable and unreliable datachannels. For example, you can send messages or files in a chat with SCTP. Other uses include being able to know when users toggle their microphone or video in a video call. In some special cases, SCTP can even be used to transmit video between users, but thatâ€™s significantly less common.&lt;/p&gt;
    &lt;p&gt;In WebRTC, the ICE protocol connects users and the DTLS protocol establishes a secure connection, at which point SCTP is then used to securely transfer data. In an ideal setup, data thatâ€™s sent should â€œjust workâ€. Unfortunately, that isnâ€™t how things tend to pan out, as issues eventually crop up. Packets get dropped, the network jitters, the computer stutters, or the coffee machine doesnâ€™t start when you thought it had. Thatâ€™s why itâ€™s important to have a backup plan for when things go wrong.&lt;/p&gt;
    &lt;head rend="h2"&gt;How SCTP Deals With Loss&lt;/head&gt;
    &lt;p&gt;SCTP was designed with this in mind and has two built-in recovery strategies for when networking goes wrong.&lt;/p&gt;
    &lt;p&gt;The first is called â€œfast retransmission.â€ The receiver detects if a chunk of data is missing in the transmission. If so, the receiver notifies the sender that a specific chunk ID is missing. If the sender receives three reports of a missing chunk where all three reports are referring to the same chunk ID, then the sender will assume that the chunk has been lost and resend it.&lt;/p&gt;
    &lt;p&gt;The second is a timer-based retransmission. This happens if the receiver doesnâ€™t acknowledge that it has received all the packets within a specific window of time. If the receiver doesnâ€™t acknowledge that all the packets have been received, then the sender is prompted to retransmit the unacknowledged data.&lt;/p&gt;
    &lt;p&gt;Both of these loss recovery strategies are used by SCTP to try to ensure that any lost data is detected and retransmitted as quickly as possible. At the time of writing, Pionâ€™s implementation of Pionâ€™s implementation of SCTP uses these two mechanisms for loss recovery.&lt;/p&gt;
    &lt;p&gt;These strategies are also used by TCP, which has prompted engineers to see if thereâ€™s an even better strategy to detect and mitigate lost data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Introducing RACK&lt;/head&gt;
    &lt;p&gt;In February 2021, RFC 8985: The RACK-TLP Loss Detection Algorithm for TCP was published. This was a completely new loss detection algorithm that focused on actively keeping track of network statistics and using timer-based signals in order to remain adaptive to ever-changing network conditions. RACKâ€™s improvements over SACK and fast retransmission in TCP were enticing enough for Linux, Windows, and FreeBSD to all implement it in TCP.&lt;/p&gt;
    &lt;p&gt;While RACK was originally intended to be implemented for TCP, it is noted in the RFC that it can be implemented in other transport protocols, including SCTP.&lt;/p&gt;
    &lt;p&gt;The implementation for SCTP was formally analyzed in Felix Weinrankâ€™s Dissertation and other publications. Weinrankâ€™s deep dive provides an extremely comprehensive review of SCTP and improvements regarding usage in various scenarios, including WebRTC. At the moment, weâ€™re more concerned with Weinrankâ€™s analysis and implementation notes regarding RACK in SCTP. In Chapter 7 of the dissertation, Weinrank goes over how SCTP handles loss and how RACK can be implemented for SCTP, including extra details regarding how the implementation interacts with various SCTP extensions.&lt;/p&gt;
    &lt;head rend="h2"&gt;RACKâ€™s motivations:&lt;/head&gt;
    &lt;p&gt;The authors of RACK in RFC 8985 provides examples of situations where RACK improves SCTP and TCP during loss recovery.&lt;/p&gt;
    &lt;head rend="h3"&gt;How RACKâ€™s Tail Loss Probing (TLP) Works&lt;/head&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver Note over S,R: The two sends are normally&amp;lt;br&amp;gt;combined but are separated&amp;lt;br&amp;gt;here for visual clarity. S-&amp;gt;&amp;gt;R: Send ğŸ S--&amp;gt;&amp;gt;R: Send ğŸŒ, ğŸ¥•, ğŸ¥” Note right of R: Only ğŸ arrived, so it's ACK'd. R-&amp;gt;&amp;gt;S: ACK ğŸ Note over S,R: 2 RTTs later, TLP fires S-&amp;gt;&amp;gt;R: TLP triggers a retransmit ğŸ¥” Note right of R: ğŸ¥” arrived, so it's SACK'd. R-&amp;gt;&amp;gt;S: SACK ğŸ¥” Note left of S: Mark ğŸŒ and ğŸ¥• as lost Note over S,R: The two sends are normally&amp;lt;br&amp;gt;combined but are separated&amp;lt;br&amp;gt;here for visual clarity. S--&amp;gt;&amp;gt;R: Retransmit ğŸŒ S-&amp;gt;&amp;gt;R: Retransmit ğŸ¥• Note right of R: Only ğŸ¥• arrived, so it's SACK'd&amp;lt;br&amp;gt;alongside ğŸ¥”. R--&amp;gt;&amp;gt;S: SACK ğŸ¥• and ğŸ¥” Note left of S: ğŸŒ retransmission marked as lost.&amp;lt;br&amp;gt;Note that this is the second time&amp;lt;br/&amp;gt;that ğŸŒ has been marked as lost. S-&amp;gt;&amp;gt;R: Retransmit ğŸŒ again Note right of R: ğŸŒ finally arrived! R--&amp;gt;&amp;gt;S: ACK ğŸ¥” Note over S,R: The ACK ğŸ¥” is a cumulative ACK&amp;lt;br&amp;gt;for the ğŸğŸŒğŸ¥•ğŸ¥” sequence&lt;/quote&gt;
    &lt;p&gt;In the above scenario, Tail Loss Probing enables the sender to quickly know if ğŸğŸŒğŸ¥•ğŸ¥” were successfully received. Since the sender only receives an acknowledgment (ACK) for ğŸ from the receiver, the TLP timer eventually triggers because it didnâ€™t receive an ACK for ğŸŒ, ğŸ¥•, and ğŸ¥”. The TLP can then resend the last packet in the segment as an efficient way to:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Retransmit data that the receiver would have to receive down the line anyway. The alternative would be to send an empty packet, receive an ACK, then send a missing packet. This handles both at once and can potentially save an RTT if only the last packet is missing in a segment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Allow the receiver to ACK any earlier missing packets in the sequence if there were other issues due to networking, temporary stutters or freezes, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Check receiver responsiveness and detect if thereâ€™s a network issue. Note that this is different from (2), as the receiver could potentially never respond with an ACK.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The receiver then confirms that it has ğŸ¥” by sending a selective acknowledgment (SACK) to the sender, which tells the sender that itâ€™s received one of the packets from the segment but not all of them. At this point, the sender has an ACK for ğŸ and a SACK for ğŸ¥”, which means that it can determine that ğŸŒ and ğŸ¥• must be missing. The sender then notes that ğŸŒ and ğŸ¥• have been lost once. It then retransmits ğŸŒ and ğŸ¥•. In the example, ğŸŒ happens to get dropped by the network whereas ğŸ¥• is sent and received successfully. The receiver then replies with a SACK for ğŸ¥• and ğŸ¥”, at which point the sender can determine that ğŸŒ was lost a second time. Finally, the sender retransmits ğŸŒ, which fortunately doesnâ€™t get dropped, and the receiver sends an ACK for ğŸ¥” (note the ACK is for the last packet in the segment, which implies that all previous packets have been received).&lt;/p&gt;
    &lt;p&gt;Side note: keeping track of the number of times that a packet has been lost is important as the cubic congestion control algorithm described in RFC 9438 (which is mentioned in RFC 8985) relies on this information.&lt;/p&gt;
    &lt;head rend="h3"&gt;SCTP RTO vs RACK RTO&lt;/head&gt;
    &lt;p&gt;In this example, the authors of RFC 8985 show how, without RACK, SCTP and TCP can suffer from spurious retransmissions when there are retransmission timeouts (RTOs). In this case, each food icon represents an entire segment instead of a packet.&lt;/p&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver S-&amp;gt;&amp;gt;R: Send ğŸ¥ Note over S,R: Then right before&amp;lt;br&amp;gt;the end of the RTO... Note right of R: The receiver has a network hiccup! S-&amp;gt;&amp;gt;R: Send ğŸ³ğŸ¥­ Note right of R: Received ğŸ¥ Note over S,R: End of the RTO R-&amp;gt;&amp;gt;S: ACK ğŸ¥&lt;/quote&gt;
    &lt;p&gt;In this scenario, ğŸ¥ is sent, and right before the end of the RTO, ğŸ³ and ğŸ¥­ are sent. The receiver gets ğŸ¥, ğŸ³, and ğŸ¥­, but only manages to send an ACK for ğŸ¥ right after the RTO. Letâ€™s see how SCTP handles this without RACK versus with RACK.&lt;/p&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver S-&amp;gt;&amp;gt;R: Send ğŸ¥ Note over S,R: Then right before&amp;lt;br&amp;gt;the end of the RTO... Note right of R: The receiver has a network hiccup! S-&amp;gt;&amp;gt;R: Send ğŸ³ğŸ¥­ Note right of R: Received ğŸ¥ Note over S,R: End of the RTO R-&amp;gt;&amp;gt;S: ACK ğŸ¥ Note over S,R: Without RACK... %% without rack Note left of S: Mark ğŸ¥ğŸ³ğŸ¥­ as lost&amp;lt;br&amp;gt;since RTO expired Note right of R: Received ğŸ³ğŸ¥­ Note over S,R: The Sender incorrectly&amp;lt;br&amp;gt;ignores the ack for ğŸ³ğŸ¥­! Note left of S: Prepare to retransmit ğŸ¥ğŸ³ğŸ¥­ S-&amp;gt;&amp;gt;R: Retransmit ğŸ¥ğŸ³ğŸ¥­&lt;/quote&gt;
    &lt;p&gt;We can see here that the receiver eventually sends an ACK for ğŸ³ and ğŸ¥­, but the sender ignores it and believes that ğŸ¥, ğŸ³, and ğŸ¥­ are all missing instead of just ğŸ¥. While itâ€™s reasonable to assume that ğŸ¥ is missing, itâ€™s a little overzealous in retransmitting packets, which can increase network traffic during recovery, especially when itâ€™s completely possible for the sender to wait for the acknowledgments of ğŸ³ and ğŸ¥­ from the receiver.&lt;/p&gt;
    &lt;p&gt;Letâ€™s see what RACK does!&lt;/p&gt;
    &lt;quote&gt;sequenceDiagram participant S as Sender participant R as Receiver S-&amp;gt;&amp;gt;R: Send ğŸ¥ Note over S,R: Then right before&amp;lt;br&amp;gt;the end of the RTO... Note right of R: The receiver has a network hiccup! S-&amp;gt;&amp;gt;R: Send ğŸ³ğŸ¥­ Note right of R: Received ğŸ¥ Note over S,R: End of the RTO R-&amp;gt;&amp;gt;S: ACK ğŸ¥ Note over S,R: With RACK... %% with rack Note left of S: Mark ğŸ¥ as lost&amp;lt;br&amp;gt;since RTO expired Note right of R: Received ğŸ³ğŸ¥­ Note left of S: Prepare to retransmit ğŸ¥ S-&amp;gt;&amp;gt;R: Retransmit ğŸ¥&lt;/quote&gt;
    &lt;p&gt;Here, RACK makes it so only ğŸ¥ is marked as lost when the RTO expires. ğŸ³ and ğŸ¥­ arenâ€™t marked as lost because their own RTOs have not yet expired by the time their ACKs are received. Therefore, only ğŸ¥ is retransmitted, as the timers for ğŸ³ and ğŸ¥­ would be re-armed if an ACK is received for the retransmitted ğŸ¥.&lt;/p&gt;
    &lt;p&gt;In this example, even though both non-RACK and RACK end up retransmitting ğŸ¥ despite the receiver already having it, the focus is on minimizing spurious retransmissions. This can save on the amount of data sent over the network, which naturally speeds up any retransmissions that might occur.&lt;/p&gt;
    &lt;head rend="h3"&gt;RACKâ€™s strategy&lt;/head&gt;
    &lt;p&gt;In summary, RACKâ€™s strategy generally has two main parts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Detect packet losses as quickly as possible by utilizing time-based acknowledgments of segmented data and inferences from network statistics.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use Tail Loss Probing (TLP), which sends sample data to gather more network statistics.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The combination of these two strategies allows it to quickly determine issues and properly rectify them once identified. It also provides better resilience for some tricky edge cases! If youâ€™re interested in seeing how RACK could perform in SCTP and other SCTP-specific improvements, check out chapter 7 of Felix Weinrankâ€™s thesis.&lt;/p&gt;
    &lt;head rend="h2"&gt;A quick look at the results (why this matters if you donâ€™t live in SCTP land)&lt;/head&gt;
    &lt;p&gt;SCP is a Go test harness that runs two Pion SCTP stacks against each other inside a deterministic, in-process â€œvirtual networkâ€ (from Pion/transport). It pins exact commits on each side, replays scenarios with a fixed seed, validates packet on the wire (CRC32c + basic SCTP parsing), and writes artifacts (&lt;code&gt;results.json&lt;/code&gt;, packet logs, and pprof) so you can reproduce the numbers.&lt;/p&gt;
    &lt;head rend="h3"&gt;The headline (max-burst): more throughput, less CPU, lower latency&lt;/head&gt;
    &lt;p&gt;This is the cleanest microbench in the suite: no loss, no delay, no jitter. Just a burst of messages in both directions. Comparing non-rack&amp;lt;-&amp;gt;non-rack vs rack&amp;lt;-&amp;gt;rack (There are similar improvements even when comparing rack&amp;lt;-&amp;gt;non-rack):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;metric&lt;/cell&gt;
        &lt;cell role="head"&gt;main (baseline)&lt;/cell&gt;
        &lt;cell role="head"&gt;RACK&lt;/cell&gt;
        &lt;cell role="head"&gt;delta&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;goodput&lt;/cell&gt;
        &lt;cell&gt;234.55 Mbps&lt;/cell&gt;
        &lt;cell&gt;316.42 Mbps&lt;/cell&gt;
        &lt;cell&gt;+34.9%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CPU time (&lt;code&gt;cpu_seconds&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;0.0560 s&lt;/cell&gt;
        &lt;cell&gt;0.0441 s&lt;/cell&gt;
        &lt;cell&gt;âˆ’21.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;goodput / CPU-second&lt;/cell&gt;
        &lt;cell&gt;4,189&lt;/cell&gt;
        &lt;cell&gt;7,177&lt;/cell&gt;
        &lt;cell&gt;+71.3%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;latency p50&lt;/cell&gt;
        &lt;cell&gt;16.37 ms&lt;/cell&gt;
        &lt;cell&gt;11.86 ms&lt;/cell&gt;
        &lt;cell&gt;âˆ’27.5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;latency p99&lt;/cell&gt;
        &lt;cell&gt;36.95 ms&lt;/cell&gt;
        &lt;cell&gt;27.84 ms&lt;/cell&gt;
        &lt;cell&gt;âˆ’24.6%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That +71% throughput-per-CPU is simply the goodput measured (Mbps) divided by the runâ€™s &lt;code&gt;cpu_seconds&lt;/code&gt;. Non-rack cruised at ~234 Mbps using ~0.056 CPU seconds (~4,189 Mbps/CPU-s), while RACK sustained 316 Mbps with ~0.044 CPU seconds (~7,177 Mbps/CPU-s). That gap is the proof that rack delivers ~71% more work per unit of CPU.&lt;/p&gt;
    &lt;head rend="h3"&gt;Test setup&lt;/head&gt;
    &lt;p&gt;To test RACK, we ran these test profiles to compare how RACK performs against main (baseline):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;max-burst - â€œhow fast can we goâ€ with no delay, loss, or reordering; it targets the raw transport path:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goodput jumps +34.9% (234 -&amp;gt;316 Mbps) while CPU seconds drop by 21% (0.056 -&amp;gt;0.044 s) and p50/p99 both fall by ~25%. RACK now delivers ~71% more Mbps per CPU-second.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;handshake - same burst pattern, this time including the COOKIE/SHUTDOWN handshake, so we exercise setup timers:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goodput climbs +15% (237 -&amp;gt;272 Mbps) while latency stays basically flat (15.65 -&amp;gt;15.99 ms for p50, 35.27 -&amp;gt;33.25 ms for p99), which confirms that the faster throughput comes without slower ACK paths.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;unordered-late-low-rtt - minor delay/jitter (10 ms) but unordered delivery to simulate packet trains with mild disorder:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Minor latency and throughput noise. Both branches still pass but RACK keeps the delivery steady despite small unordered bursts.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;unordered-late-high-rtt - large RTT/jitter (180 ms / 60 ms) with unordered delivery, so we can watch how the stack copes with latency spikes:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Very high latency due to the profile, but RACK keeps throughput comparable while completely avoiding any regressions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;unordered-late-dynamic-rtt - fluctuating RTT (40 ms base Â±180 ms jitter) with unordered delivery to mimic burst-y network dynamics:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both branches pass with no noticeable regressions from RACK, which shows that each branch handles jitter swings fine.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;congestion - ordered delivery with 2% loss and modest delay/jitter to stress-tests congestion control and SACK-driven recovery:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The loss-handling path stays green and RACK doesnâ€™t use extra CPU compared to master which shows the +35% clean-case gain doesnâ€™t cost the loss profile.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;retransmission - ordered with 5% loss and 20 ms jitter to force fast-retransmit/TLP scenario:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The fault case still hits retries and RACKâ€™s CPU profile actually shows more JSON/packet-logging work but thatâ€™s what we expect during retransmit storms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;reorder-low - unordered with 1.5% loss plus deliberate reordering to exercise scheduler/queue behavior under lossï¼‹reorder:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Goodput improves +44% (1.79 Mbps -&amp;gt; 2.58 Mbps) and the run finishes faster (~3.70 s vs 5.34 s), so RACK dominates the low-rate reordering scenario.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;burst-loss - unordered with 4% loss and 50 ms jitter to push retransmit/recovery under heavy loss bursts.&lt;/item&gt;
      &lt;item&gt;fragmentation - oversized payloads require chunk fragmentation/reassembly to verify large-message handling:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nothing improved or got worse.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;media-hevc - A real-world use case with video: one-way stream, paced HEVC frames (~25 fps), 3% loss, ~1200-byte max payload, across a ~13-14 Mbps link (taken from a real-world use case of sending DRM media over WebRTC datachannels) to ensure sustained media delivery works.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;RACK hits 12.90 Mbps goodput in 2.14 s (100% delivery) while the main branch streaming to the RACK branch sits at 11.34 Mbps in 4.66 s. Thatâ€™s a 2x faster finish!&lt;/p&gt;
    &lt;p&gt;We also have 3 negative tests to ensure that any corruptions or errors are still being caught:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;fault-checksum - corrupts every 7th DATA chunkâ€™s checksum so receivers must drop it and log the error.&lt;/item&gt;
      &lt;item&gt;fault-bad-chunk-len - mangles the chunk length field every 7th chunk to validate length checks/parsing.&lt;/item&gt;
      &lt;item&gt;fault-nonzero-padding - corrupts padding bytes every 7th chunk so padding validation and chunk isolation logic are exercised.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In both branches, these cases fail (as desired), which confirms that both branches detect the corruption and that there is no regression in behavior.&lt;/p&gt;
    &lt;head rend="h3"&gt;CPU flamegraphs&lt;/head&gt;
    &lt;p&gt;The flamegraphs below show the CPU profiles for max-burst runs. You can see in the metadata that the RACK profile captured 20ms of samples (9.95% of 201.08ms duration) versus the master profileâ€™s 40ms of samples (19.86% of 201.45ms duration) â€“ exactly half the sample count for a similar duration, which directly supports the efficiency claims.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why RACK behaves better (not just â€œgoes fasterâ€)&lt;/head&gt;
    &lt;p&gt;RACK changes how SCTP decides that something is lost and when it sends probes, so it wastes less work fixing problems that never really happened:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instead of keying almost everything off â€œthree missing reports or an RTO firedâ€, RACK uses time-based loss detection: it looks at when chunks were last SACKed/ACKed and infers loss from elapsed time and the pattern of tail acknowledgments.&lt;/item&gt;
      &lt;item&gt;Tail Loss Probes (TLP) send a cheap â€œsampleâ€ chunk at the end of a burst to flush out late ACKs. If the receiver really did get the data, it answers and the sender avoids a full retransmission storm, otherwise, the probe doubles as the retransmission you needed anyway.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In practical terms thatâ€™s what the profiles and metrics are showing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We still see the same hot stack (&lt;code&gt;vnet.(*chunkUDP).UserData&lt;/code&gt;,&lt;code&gt;runtime.memmove&lt;/code&gt;, a thin layer of runtime/type helpers) in both master and RACK. Itâ€™s the normal packet I/O path.&lt;/item&gt;
      &lt;item&gt;With RACK, that stack is exercised fewer times per unit of useful data because there are fewer spurious retransmits and fewer â€œjust in caseâ€ timer expirations.&lt;/item&gt;
      &lt;item&gt;Thatâ€™s exactly how we get more goodput, lower latency, and smaller CPU profiles at the same time: RACK spends less CPU â€œarguing with the networkâ€ and more CPU pushing real user data through SCTP.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Spec-aligned ACK behavior and testing&lt;/head&gt;
    &lt;p&gt;Using SCP testing tool we were able to find some issues includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;In the initial RACK implementation, handling of transitions from high to low RTT was suboptimal due to the implementation using a global minimum for recent RTT measurements instead of a windowed minimum (the latter approach is only a â€œSHOULDâ€ in RFC 8985 section 6.2.1). Atsushi Watanabe quickly identified it and we resolved the issue.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The earlier version of RACK implementation also handled packet reordering poorly and consumed more CPU than non-RACK. This was corrected by implementing improved active RTT measurement, following the approach described in Weinrankâ€™s work, see p. 120.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A minor bug was discovered (and fixed) in the initial RACK implementation where the latest RTT was not measured for every packet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;We also found that Pion SCTP did not send a SACK immediately after a TSN gap, causing RACK to perform worse under moderate reordering. After fixing this behavior to align with RFC 4960 section 6.7 (surprisingly only a â€œSHOULDâ€), reordering test cases showed a ~30% improvement.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;Keep an eye out for even more improvements and benchmarks from our improved SCTP implementation using real-world data, as well as how weâ€™re doing it in an upcoming blog post!&lt;/p&gt;
    &lt;p&gt;Thanks for reading!&lt;/p&gt;
    &lt;head rend="h2"&gt;Credits&lt;/head&gt;
    &lt;p&gt;Huge thanks to the following for making this possible:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Joe Turki for introducing me to Pion, making SCP, answering countless questions, and so much more.&lt;/item&gt;
      &lt;item&gt;Sean DuBois for making Pion, finding Felix Weinrankâ€™s thesis, and endless encouragement.&lt;/item&gt;
      &lt;item&gt;Srayan Jana for helping to bounce around many ideas.&lt;/item&gt;
      &lt;item&gt;Atsushi Watanabe for reviewing and catching the global minimum vs windowed minimum issue in the RACK PR.&lt;/item&gt;
      &lt;item&gt;And many more people along the way!&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pion.ly/blog/sctp-and-rack/"/><published>2025-12-28T18:05:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46413365</id><title>Remembering Lou Gerstner</title><updated>2025-12-29T03:04:08.343081+00:00</updated><content>&lt;doc fingerprint="3f8dd935902cb38d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;All press releases&lt;/head&gt;
    &lt;head rend="h1"&gt;Remembering Lou Gerstner&lt;/head&gt;
    &lt;p&gt;The following is the text of an email sent today to all IBM employees by Chairman and CEO Arvind Krishna:&lt;/p&gt;
    &lt;p&gt;IBMers,&lt;/p&gt;
    &lt;p&gt;I am saddened to share that Lou Gerstner, IBMâ€™s Chairman and CEO from 1993 to 2002, passed away yesterday.&lt;/p&gt;
    &lt;p&gt;Lou arrived at IBM at a moment when the companyâ€™s future was genuinely uncertain. The industry was changing rapidly, our business was under pressure, and there was serious debate about whether IBM should even remain whole. His leadership during that period reshaped the company. Not by looking backward, but by focusing relentlessly on what our clients would need next.&lt;/p&gt;
    &lt;p&gt;One of Louâ€™s earliest signals as CEO has become part of IBM lore. Early on, he stopped a long internal presentation and said, simply, â€œLetâ€™s just talk.â€ The message was clear: less inward focus, more real discussion, and much closer attention to customers. That mindset would define his tenure.&lt;/p&gt;
    &lt;p&gt;Lou believed one of IBMâ€™s central problems was that we had become optimized around our own processes, debates, and structures rather than around client outcomes. As he later put it, the company had lost sight of a basic truth of business: understanding the customer and delivering what the customer actually values.&lt;/p&gt;
    &lt;p&gt;That insight drove real change. Meetings became more direct. Decisions were grounded more in facts and client impact than in hierarchy or tradition. Innovation mattered if it could translate into something clients would come to rely on. Execution in the quarter and the year mattered, but always in service of longer-term relevance.&lt;/p&gt;
    &lt;p&gt;Lou made what may have been the most consequential decision in IBMâ€™s modern history: to keep IBM together. At the time, the company was organized into many separate businesses, each pursuing its own path. Lou understood that clients didnâ€™t want fragmented technologyâ€”they wanted integrated solutions. That conviction shaped IBMâ€™s evolution and reestablished our relevance for many of the worldâ€™s largest enterprises.&lt;/p&gt;
    &lt;p&gt;Lou also understood that strategy alone would not be enough. He believed lasting change required a shift in cultureâ€”in how people behave when no one is watching. What mattered was what IBMers valued, how honestly they confronted reality, and how willing they were to challenge themselves and each other. Rather than discard IBMâ€™s long-standing values, he pushed the company to renew them to meet the demands of a very different era.&lt;/p&gt;
    &lt;p&gt;I have my own memory of Lou from the mid-1990s, at a small town hall with a few hundred people. What stood out was his intensity and focus. He had an ability to hold the short term and the long term in his head at the same time. He pushed hard on delivery, but he was equally focused on innovation: doing work that clients would remember, not just consume.&lt;/p&gt;
    &lt;p&gt;Lou stayed engaged with IBM long after his tenure ended. From my first days as CEO, he was generous with adviceâ€”but always careful in how he gave it. He would offer perspective, then say, â€œIâ€™ve been gone a long timeâ€”Iâ€™m here if you need me.â€ He listened closely to what others were saying about IBM and reflected it back candidly.&lt;/p&gt;
    &lt;p&gt;That neutral, experienced voice mattered to me, and I was fortunate to learn from Lou on a regular basis.&lt;/p&gt;
    &lt;p&gt;Lou was direct. He expected preparation. He challenged assumptions. But he was deeply committed to building a company that could adaptâ€”culturally as much as strategicallyâ€”without losing its core values.&lt;/p&gt;
    &lt;p&gt;Louâ€™s impact extended well beyond IBM. Before joining the company, he had already built an extraordinary careerâ€”becoming one of the youngest partners at McKinsey &amp;amp; Company, later serving as president of American Express and CEO of RJR Nabisco. After IBM, he went on to chair The Carlyle Group and devoted significant time and resources to philanthropy, particularly in education and biomedical research. A native of Long Island, NY, Lou earned his undergraduate degree from Dartmouth and an MBA from Harvard, and he remained deeply devoted to his family throughout his life. Lou was preceded in death by his son Louis Gerstner III.&lt;/p&gt;
    &lt;p&gt;We will hold a celebration in the new year to reflect on Louâ€™s legacy and what his leadership enabled at IBM.&lt;/p&gt;
    &lt;p&gt;My thoughts are with Louâ€™s wife Robin, his daughter Elizabeth, his grandchildren and extended family, as well as his many friends, colleagues, and people around the world who were shaped by his leadership and his work.&lt;lb/&gt; Media contact:&lt;lb/&gt; IBM Press Room&lt;lb/&gt; ibmpress@us.ibm.com &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://newsroom.ibm.com/2025-12-28-Remembering-Lou-Gerstner"/><published>2025-12-28T18:43:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46413790</id><title>No, it's not a battleship</title><updated>2025-12-29T03:04:07.088860+00:00</updated><content>&lt;doc fingerprint="321d405731a537b9"&gt;
  &lt;main&gt;
    &lt;p&gt;This week has seen the announcement by the Trump Administration that they are going to be building "battleships", a subject that is well within my beat, so I figured I would take the time to start by saying that these are nothing of the sort. Defining the battleship is slightly tricky, but the best version I have is that it is a large, gun-armed armored warship. This proposal is certainly large, but it doesn't really classify as gun-armed, in that the guns are clearly secondary weapons, and there's been no discussion of armor at all. So whatever these are, they aren't battleships. Their closest cousin in the Soviet Kirov class, which likewise are somewhat hard to classify, but in the finest tradition of the USN, I'm going to go with "Large Missile Cruiser" for these. But the fact that they're being called by the wrong name, while personally extremely annoying, is just the tip of the iceberg.&lt;/p&gt;
    &lt;p&gt;First, a look at the announced specs, as given above. The dimensions are somewhat large given the displacement, as they're a pretty close match for Iowa, which is 50%+ heavier at full load, although they're also not too far from the Alaskas, of roughly the same displacement. The length might make sense if they were going for nuclear power, because a very long hull would minimize power requirements, but it seems that it's IEP instead. But then we get to armament, and things get weird. It starts with the new ship-launched nuclear cruise missile that Trump has been pushing since his first term. This is basically a replacement for the nuclear Tomahawk, and whatever the logic for or against such a program might be, there's the problem that I'm pretty sure there's no need to have this new "battleship" to use the missile. Details on the missile are very sketchy, but given that the base program is targeted at submarines, it probably can just go in the VLS with everything else. If it can't that's a requirements problem, and we should change those instead of spending money on this thing. I'm sure the crews will love it, too, given the need to guard the VLS all the time to avoid letting anyone know if there are actually nukes aboard.&lt;/p&gt;
    &lt;p&gt;Second, there are cells for Conventional Prompt Strike, which is the current hypersonic weapon that they're pushing. It's not in service yet, and I'm skeptical how much real value it will deliver. I'm also not entirely sure how many missiles will actually be aboard. Zumwalt recently got four tubes in place of her forward gun, each of which carries three missiles, and I could see either four tubes/12 missiles or 12 tubes/36 missiles, with the latter maybe making more sense given the size of the ship. The graphic provided by the Navy (below) is curiously unhelpful about this, almost like it was put together by someone who doesn't understand any of this stuff.&lt;/p&gt;
    &lt;p&gt;Then there's 128 cells of VLS, which is obviously the main armament of any surface warship in this day and age. Now, this is almost exactly the same number of VLS cells carried by a Ticonderoga class cruiser on 10,000 tons,1 which raises a fair number of questions about the efficiency of the design relative to a slightly stretched Burke or any number of proposed designs that would be half the size of this thing.&lt;/p&gt;
    &lt;p&gt;The secondary armament is even worse. It starts with a railgun, which has become one of the perennial "next generation" weapons that never seems to get anywhere. I remember reading about how cool they were going to be almost 20 years ago, and over the last few years, the program seems to have been basically cancelled. The problem is that if you make an electrical explosion, it's sort of hard to stop it from eroding the rails, and nobody has been able to get a "barrel life" long enough to justify sticking it on a ship, even after investigating some rather amusing systems to change the rails in the field. The 5" guns are fine, although putting them both forward is a bit odd, and I'm a big fan of lasers. The tertiary armament is even weirder. RAM makes sense as a backup for something like this, but the number of 30 mm guns is a bit odd given that they're basically for shooting and drones and small boats, and you already have lasers for that. But better safe than sorry. Then there's ODIN, which is a laser-based dazzler system. And I'm sorry, but if you are going to put more lasers on, why not put on more full-size lasers? They can also dazzle things you don't want to shoot down. ODIN was developed for cases where you didn't have the power or (probably) integration to want a full-powered laser, but that isn't a problem here. And then you have nebulous "counter UxS systems", which certainly hit current buzzwords, but otherwise leave us with no idea what they do.&lt;/p&gt;
    &lt;p&gt;On the whole, it's pretty clearly a grab-bag of stuff that sounded cool, thrown together without any real attempt to explain how is this better spending an equivalent amount of money on Burkes or on the DDG(X) program, which was going to come in around 15,000 tons, and which this is allegedly supposed to replace. Apparently, a lot of this is driven because Trump thinks that modern ships are ugly, and should look good. And I'm not entirely in disagreement with him on that. I love a beautiful ship as much as anyone, but I also strive to keep my aesthetic judgements separate from my policy judgements. I also think that there's some value in having good-looking ships when you're doing port visits and the like, and have even toyed with a "cheap capital ship" to be able to gain some of the benefits I discussed for the Iowas in the 1980s. But that would not have been billed as the future of the Navy, more an interesting side project, and I'm far from sure it would actually be a good use of our limited defense budget.&lt;/p&gt;
    &lt;p&gt;We've seen a similarly casual approach to procurement policy with the replacement for Constellation. SecNav Phelan has announced that it will be a minimum-change version of the National Security Cutter design, with a flexible mission module slot added on and maybe RAM, in hopes of getting in the water more quickly. Now, they might actually be able to make "getting a ship launched by 2028" on this one, particularly if they're able to reuse components from the cutter Friedman (WMSL-760), which was cancelled back in July, with an unclear amount of work already done. But the result will be something more much like the "minimum viable warship"/Type 31 than a true multi-role frigate, and we should be careful not to confuse the two. In particular, even if the mission module slots get filled with VLS carrying, say, ESSM, the ship does not have the sort of radar necessary to be considered a serious air defense asset on the modern battlefield. I gamed this out in Command: Modern Operations, which doubles as a mid-grade military simulation tool. Both the new ship, apparently designated FF(X) and FFG-62 handled a salvo of 8 conventional C-802-type sea-skimming missiles without too much trouble. But then I upped the threat to NSM and things changed radically. FFG-62 picked them up at 18.5 nm, just inside the radar horizon, and began firing at about 15 nm, with none of the missiles getting closer than 9.3 nm. The NSC-based design, with its much worse radar, didn't pick them up until 3.7 nm, when it was too late to do anything other than a single RAM and a few ineffective shots from Phalanx and the 57 mm gun. NSC also has no onboard sonar system, although one based on the LCS version might be adaptable for use from the mission deck, at an obvious cost in air defense capability. But it's "An American Design from an American Shipyard", so we're going to build it anyway, instead of more Constellations.&lt;/p&gt;
    &lt;p&gt;I am also bothered by the name. Not Defiant, which is a fine name for a warship, even if lacking in any particular heritage in the USN. But calling the ships the Trump class is... Look, I've been banging on about this for some time, and naming things after someone who is not only alive but in office is just gross. Also, a complete misunderstanding of how class names work in the American tradition. The British sometimes will pick a theme name, but we just take the first-ordered ship of the class,2 and use that. So even if this does end up getting into the water, it will probably be as the Defiant class. And I'm not hopeful for that happening. This is pretty clearly a very early design, intended to cater to someone whose understanding of naval matters comes entirely from vague memories of Victory at Sea3 and various yachts. It's going to take years to turn it into something we can build, and its fate past 2028 is going to depend on whoever ends up winning that election, a subject I'm not competent to speculate on.&lt;/p&gt;
    &lt;p&gt;The design is also pushing the limits of "steel is cheap and air is free", a doctrine I am usually a fierce partisan of. I think that view is pretty straightforwardly true when you're talking about putting 4,000 tons of combat systems in a 6,000 ton hull. But at some point, other factors start to take over. There's a least a little bit of wisdom in the Type 42 view that if you have extra space, people will try to install stuff in it. I was also worried about drydocking, but apparently, pretty much every drydock we have that supports DDGs also can handle LHDs, which are about the same size as this thing. More importantly, even if this ship was considerably more capable than DDG(X), which it mostly isn't, it can only be in one place at a time, and we have a lot of commitments. A ship in the wrong place isn't all that much better than no ship at all, so there are reasons to want numbers.&lt;/p&gt;
    &lt;p&gt;Ultimately, this entire thing is silly. This is a ludicrously overgrown destroyer/cruiser (so far as those are separate things these days) without even a figleaf of justification for its size. And even if there was some justification for the size, it definitely isn't a battleship. Also, on a personal note, I would really appreciate it if the Administration stopped dropping significant naval news on the weeks of major holidays, because it adds something to my plate that I would rather not have to deal with.&lt;/p&gt;
    &lt;p&gt;1 Those carried 122, because they were built with the strikedown crane, which cost 3 cells in each of the forward and aft clusters. And yes, that was a fairly tight design, so you'd really want a bit more tonnage for that many cells. â‡‘&lt;/p&gt;
    &lt;p&gt;2 There's actually a slight difference between the USN and RN here. The Americans take the first ship by hull number, while the British tend to pick the first-completed ship, so the Colorado class is known as the Maryland class in British sources because Maryland completed first. â‡‘&lt;/p&gt;
    &lt;p&gt;3 To be clear, I am not slamming Victory at Sea, which is an excellent series that I highly recommend. But it is perhaps not the best way to understand modern naval policy. â‡‘&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.navalgazing.net/No-its-not"/><published>2025-12-28T19:41:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46413975</id><title>PySDR: A Guide to SDR and DSP Using Python</title><updated>2025-12-29T03:04:06.856616+00:00</updated><content>&lt;doc fingerprint="7c6211f0c4f3e3a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;1. IntroductionÂ¶&lt;/head&gt;
    &lt;head rend="h2"&gt;Purpose and Target AudienceÂ¶&lt;/head&gt;
    &lt;p&gt;First and foremost, a couple important terms:&lt;/p&gt;
    &lt;list rend="dl"&gt;
      &lt;item rend="dt-1"&gt;Software-Defined Radio (SDR):&lt;/item&gt;
      &lt;item rend="dd-1"&gt;
        &lt;p&gt;As a concept it refers to using software to perform signal processing tasks that were traditionally performed by hardware, specific to radio/RF applications. This software can be run on a general-purpose computer (CPU), FPGA, or even GPU, and it can be used for real-time applications or offline processing of recorded signals. Analogous terms include â€œsoftware radioâ€ and â€œRF digital signal processingâ€.&lt;/p&gt;
        &lt;p&gt;As a thing (e.g., â€œan SDRâ€) it typically refers to a device that you can plug an antenna into and receive RF signals, with the digitized RF samples being sent to a computer for processing or recording (e.g., over USB, Ethernet, PCI). Many SDRs also have transmit capabilities, allowing the computer to send samples to the SDR which then transmits the signal at a specified RF frequency. Some embedded-style SDRs include an onboard computer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item rend="dt-2"&gt;Digital Signal Processing (DSP):&lt;/item&gt;
      &lt;item rend="dd-2"&gt;The digital processing of signals; in our case, RF signals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This textbook acts as a hands-on introduction to the areas of DSP, SDR, and wireless communications. It is designed for someone who is:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Interested in using SDRs to do cool stuff&lt;/item&gt;
      &lt;item&gt;Good with Python&lt;/item&gt;
      &lt;item&gt;Relatively new to DSP, wireless communications, and SDR&lt;/item&gt;
      &lt;item&gt;A visual learner, preferring animations over equations&lt;/item&gt;
      &lt;item&gt;Better at understanding equations after learning the concepts&lt;/item&gt;
      &lt;item&gt;Looking for concise explanations, not a 1,000 page textbook&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;An example is a Computer Science student interested in a job involving wireless communications after graduation, although it can be used by anyone itching to learn about SDR who has programming experience. As such, it covers the necessary theory to understand DSP techniques without the intense math that is usually included in DSP courses. Instead of burying ourselves in equations, an abundance of images and animations are used to help convey the concepts, such as the Fourier series complex plane animation below. I believe that equations are best understood after learning the concepts through visuals and practical exercises. The heavy use of animations is why PySDR will never have a hard copy version being sold on Amazon.&lt;/p&gt;
    &lt;p&gt;This textbook is meant to introduce concepts quickly and smoothly, enabling the reader to perform DSP and use SDRs intelligently. Itâ€™s not meant to be a reference textbook for all DSP/SDR topics; there are plenty of great textbooks already out there, such as Analog Deviceâ€™s SDR textbook and dspguide.com. You can always use Google to recall trig identities or the Shannon limit. Think of this textbook like a gateway into the world of DSP and SDR: itâ€™s lighter and less of a time and monetary commitment, when compared to more traditional courses and textbooks.&lt;/p&gt;
    &lt;p&gt;To cover foundational DSP theory, an entire semester of â€œSignals and Systemsâ€, a typical course within electrical engineering, is condensed into a few chapters. Once the DSP fundamentals are covered, we launch into SDRs, although DSP and wireless communications concepts continue to come up throughout the textbook.&lt;/p&gt;
    &lt;p&gt;Code examples are provided in Python. They utilize NumPy, which is Pythonâ€™s standard library for arrays and high-level math. The examples also rely upon Matplotlib, which is a Python plotting library that provides an easy way to visualize signals, arrays, and complex numbers. Note that while Python is â€œslowerâ€ than C++ in general, most math functions within Python/NumPy are implemented in C/C++ and heavily optimized. Likewise, the SDR API we use is simply a set of Python bindings for C/C++ functions/classes. Those who have little Python experience yet a solid foundation in MATLAB, Ruby, or Perl will likely be fine after familiarizing themselves with Pythonâ€™s syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;ContributingÂ¶&lt;/head&gt;
    &lt;p&gt;If you got value from PySDR, please share it with colleagues, students, and other lifelong learners who may be interested in the material. You can also donate through the PySDR Patreon as a way to say thanks and get your name on the left of every page below the chapter list.&lt;/p&gt;
    &lt;p&gt;If you get through any amount of this textbook and email me at marc@pysdr.org with questions/comments/suggestions, then congratulations, you will have contributed to this textbook! You can also edit the source material directly on the textbookâ€™s GitHub page (your change will start a new pull request). Feel free to submit an issue or even a Pull Request (PR) with fixes or improvements. Those who submit valuable feedback/fixes will be permanently added to the acknowledgments section below. Not good at Git but have changes to suggest? Feel free to email me at marc@pysdr.org.&lt;/p&gt;
    &lt;head rend="h2"&gt;AcknowledgementsÂ¶&lt;/head&gt;
    &lt;p&gt;Thank you to anyone who has read any portion of this textbook and provided feedback, and especially to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Barry Duggan&lt;/item&gt;
      &lt;item&gt;Matthew Hannon&lt;/item&gt;
      &lt;item&gt;James Hayek&lt;/item&gt;
      &lt;item&gt;Deidre Stuffer&lt;/item&gt;
      &lt;item&gt;Tarik Benaddi for translating PySDR to French&lt;/item&gt;
      &lt;item&gt;Daniel Versluis for translating PySDR to Dutch&lt;/item&gt;
      &lt;item&gt;mrbloom for translating PySDR to Ukrainian&lt;/item&gt;
      &lt;item&gt;Yimin Zhao for translating PySDR to Simplified Chinese&lt;/item&gt;
      &lt;item&gt;Eduardo Chancay for translating PySDR to Spanish&lt;/item&gt;
      &lt;item&gt;John Marcovici&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As well as all PySDR Patreon supporters!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pysdr.org/content/intro.html"/><published>2025-12-28T20:02:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414078</id><title>Stepping down as Mockito maintainer after 10 years</title><updated>2025-12-29T03:04:05.370159+00:00</updated><content>&lt;doc fingerprint="6702905447ee068a"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 2.6k&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;p&gt;In March 2026, I will be Mockito maintainer for 10 years (nearly a third of my whole life). Looking ahead, I decided that a decade milestone is a good moment to pass on maintainership to other folks. In the coming months until March, I will spend time ensuring a smooth transition in maintainership.&lt;/p&gt;
    &lt;p&gt;In this issue I list several considerations why I made the decision. Communication and discussion of plans for future maintainership will be somewhere else, most likely in a separate GitHub issue. Stay tuned for that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Energy drain because of JVM agent change&lt;/head&gt;
    &lt;p&gt;As you might know, Mockito 5 shipped a breaking change where its main artifact is now an agent. That's because starting JVM 22, the previous so-called "dynamic attachment of agents" is put behind a flag. This change makes sense from a security point-of-view and I support it.&lt;/p&gt;
    &lt;p&gt;However, the way this was put forward to Mockito maintainers was energy draining to say the least. Mockito is probably the biggest user of such an agent and is often looked at for inspiration by other projects. As such, Mockito often pioneers on supporting JVM features, built on a solid foundation with ByteBuddy. Modules was such a feature that took months of hard work by Rafael to figure out, including providing feedback to JVM maintainers.&lt;/p&gt;
    &lt;p&gt;Unfortunately such a collaborative way of working was not the case when discussing agents. To me, it felt like the feature was presented as a done deal because of security. While dynamic attachment is problematic in many ways, no alternative solutions were proposed. That's okay, as Mockito pioneers on these solutions, yet in this case I felt we were left alone.&lt;/p&gt;
    &lt;p&gt;My personal take is that folks involved with the change severely underestimated the societal impact that it had. The fact that proper build support is non-existent to this day shows that agents are not a priority. That's okay if it isn't a priority, but when it was communicated with Mockito I perceived it as "Mockito is holding the JVM ecosystem back by using dynamic attachment, please switch immediately and figure it out on your own".&lt;/p&gt;
    &lt;p&gt;Here, the fact that I (and others) are volunteers doing their best for the project, is important to understand the societal impact. When you put individuals under pressure, who do this work in their own time out of goodwill, things crumble. It's commonly joked about with XKCD's on the fact that the whole open source world relies on a couple of individuals. That couldn't be more true in this situation, where the collaborative system collapses when too much pressure is put on individual folks.&lt;/p&gt;
    &lt;p&gt;This saga planted the seed to reconsider my position as maintainer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kotlin as the future and odd one out&lt;/head&gt;
    &lt;p&gt;It's undeniable that Kotlin as a language has grown in popularity in recent years. While Mockito maintains several flavors for JVM languages, these packages typically include sugar that makes integration nicer. In all cases, mockito-core remains the place where functionality is implemented.&lt;/p&gt;
    &lt;p&gt;Unfortunately, this model doesn't nicely apply to Kotlin. Where almost all JVM languages work similarly under the hood, Kotlin often does things differently. This means that in several places in mockito-core, there are separate flows dedicated to Kotlin. Most often that's a direct result of Kotlin doing (in my opinion) shenanigans on the JVM that the JVM never intended to support, yet was able to.&lt;/p&gt;
    &lt;p&gt;Even within Kotlin itself, features don't work consistently. Suspend functions are the most well-known example. As such, Mockito code becomes more spaghetti, it's API sometimes fully duplicated just to support a core Kotlin language feature and overall less maintainable.&lt;/p&gt;
    &lt;p&gt;While I fully understand the reasons that developers enjoy the feature richness of Kotlin as a programming language, its underlying implementation has significant downsides for projects like Mockito. Quite frankly, it's not fun to deal with.&lt;/p&gt;
    &lt;p&gt;To me, a future where Kotlin becomes more predominant is not a future that makes me hopeful I can keep on dedicating energy to Mockito.&lt;/p&gt;
    &lt;head rend="h2"&gt;Alternative open source activities&lt;/head&gt;
    &lt;p&gt;I have always been a fan of open source work and have contributed to hundreds of projects in all these years. Mockito is my most important project, but I have also consistently worked on others. In recent months, I have rediscovered the joy of programming by working on Servo. It's a web engine written in Rust.&lt;/p&gt;
    &lt;p&gt;When I need to choose how I want to spend my 2 hours of evening time in a given week, I rarely preferred Mockito in the last year. In the past, Mockito was my go-to and I enjoyed it a lot. Nowadays, Servo and related projects provide significantly more enjoyment.&lt;/p&gt;
    &lt;p&gt;Justifying why I needed to work on Mockito becomes difficult when (because of the above reasons) it feels like a chore. Volunteering work shouldn't feel like a chore, at least not for a long time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summing it up&lt;/head&gt;
    &lt;p&gt;As you have read, these three factors combined led me to the decision. The first point explains why I started to doubt my position, the second point why I am not hopeful for things to change in a good way and the third point how I found enjoyment in a different way.&lt;/p&gt;
    &lt;p&gt;While these points had impact on me as maintainer, my hypothesis is that it doesn't apply to others in the same way. I know others are eager to work on Kotlin support for example. That's why I concluded that a decade is enough time to have helped Mockito forward. Now it's time for somebody else to take over, as I believe that's in the best interest of Mockito as a project. Because ultimately that's why I chose to become maintainer in the first place: I believed that with my work, I could improve Mockito for millions of software engineers.&lt;/p&gt;
    &lt;p&gt;For those wondering: yes I wholeheartedly advise everyone to take on a volunteering task such as maintaining an open source project. It was an honour and privilege to do so and I thank those that I enjoyed working with.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/mockito/mockito/issues/3777"/><published>2025-12-28T20:14:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414258</id><title>Show HN: Phantas â€“ A browser-based binaural strobe engine (Web Audio API)</title><updated>2025-12-29T03:04:05.146585+00:00</updated><content>&lt;doc fingerprint="c7bc1d2388b9f1ff"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Operating Protocol&lt;/head&gt;
    &lt;p&gt;STEREO AUDIO: Headphones essential. Frequencies split left/right to create the binaural beat.&lt;/p&gt;
    &lt;p&gt;OPTICAL DRIVING: Set brightness to 100%. Close eyes. Position screen to fill your entire visual field with light.&lt;/p&gt;
    &lt;p&gt;FEEDBACK LOOP: Log duration and pre/post state below to track efficiency.&lt;/p&gt;
    &lt;p&gt;STANDBY&lt;/p&gt;
    &lt;p&gt;Screen Lock&lt;/p&gt;
    &lt;head rend="h4"&gt;ALPHA (10HZ) - PASSIVE OBSERVATION&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Best For: Routine Coding, "Autopilot" Work.&lt;/item&gt;
      &lt;item&gt;How To Use: Don't force thoughts. Let your mind wander. Good for stability.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;10.0&lt;/p&gt;
    &lt;p&gt;15&lt;/p&gt;
    &lt;p&gt;30&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://phantas.io"/><published>2025-12-28T20:38:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414475</id><title>MongoBleed Explained Simply</title><updated>2025-12-29T03:04:04.756272+00:00</updated><content>&lt;doc fingerprint="b899ddd9ce0a239a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;MongoBleed explained simply&lt;/head&gt;
    &lt;head rend="h3"&gt;CVE-2025-14847 allows attackers to read any arbitrary data from the database's heap memory. It affects all MongoDB versions since 2017, here's how it works:&lt;/head&gt;
    &lt;p&gt;MongoBleed, officially CVE-2025-14847, is a recently-uncovered extremely sensitive vulnerability affecting basically all versions of MongoDB since ~2017.&lt;/p&gt;
    &lt;p&gt;It is a bug in the zlib1 message compression path in MongoDB.&lt;/p&gt;
    &lt;p&gt;It allows an attacker to read off any uninitialized heap memory, meaning anything that was allocated to memory from a previous database operation could be read.&lt;/p&gt;
    &lt;p&gt;The bug was introduced in 20172. It is dead-easy to exploit - it only requires connectivity to the database (no auth needed). It is fixed as of writing, but some EOL versions (3.6, 4.0, 4.2) will not get it.&lt;/p&gt;
    &lt;head rend="h1"&gt;MongoDB Basics&lt;/head&gt;
    &lt;p&gt;Letâ€™s get a few basics out of the way before we explain the bug:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB uses its own TCP wire protocol instead of e.g HTTP. This is standard for databases, especially ones chasing high performance.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mongo uses the BSON format for messages3. Itâ€™s basically binary json but with some key optimizations. We will talk about one later because it is essential to the exploit.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mongo doesnâ€™t have endpoints or RPCs. It only uses a single op code called OP_MSG.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The OP_MSG command contains a BSON message. The contents of the message denote what type of request it is. Concretely, itâ€™s the first field of the message that marks the request type. 4&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The request can be compressed. In that case, an OP_COMPRESSED message is sent which wraps the now-compressed OP_MSG BSON.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The request then looks like this:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;     OP_COMPRESSED message
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ standard header (16 bytes) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ originalOpcode (int32)     â”‚
â”‚ uncompressedSize (int32)   â”‚
â”‚ compressorId (int8)        â”‚
â”‚ compressed OP payload      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Critically, the&lt;/p&gt;&lt;code&gt;uncompressedSize&lt;/code&gt;field denotes how large the payload is once itâ€™s uncompressed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Exploit Part 1&lt;/head&gt;
    &lt;p&gt;The first part of the exploit is to get the server to wrongfully think that an overly-large OP_MSG is coming.&lt;/p&gt;
    &lt;p&gt;An attacker can send a falsefully large &lt;code&gt;`uncompressedSize`&lt;/code&gt; field, say 1MB5, when in reality the underlying message is 1KB uncompressed. &lt;/p&gt;
    &lt;p&gt;This will make the server allocate a 1MB buffer in memory to decompress the message into. This is fine.&lt;/p&gt;
    &lt;p&gt;The critical bug here is that, once finished decompressing, the server does NOT check the actual resulting size of the newly-uncompressed payload.&lt;/p&gt;
    &lt;p&gt;Instead, it trusts the userâ€™s input and uses that as the canonical size of the payload, even if it got a different number.6&lt;/p&gt;
    &lt;p&gt;The result is an in-memory representation of the BSON message which looks something like this:&lt;/p&gt;
    &lt;code&gt;[ 1KB of REAL DATA |      999KB of UNREFERENCED HEAP GARBAGE       ]
                   â†‘                                               â†‘
        actual length (1KB)                     user input length (1MB)&lt;/code&gt;
    &lt;head rend="h3"&gt;Unreferenced Heap Garbage&lt;/head&gt;
    &lt;p&gt;Like in every programming language, when a variables in the code goes out of scope, the runtime marks the memory it previously took up as available.&lt;/p&gt;
    &lt;p&gt;In most modern languages, the memory gets zeroed out. In other words, the old bytes that used to take up the space get deleted.&lt;/p&gt;
    &lt;p&gt;In C/C++, this doesnâ€™t happen. When you allocate memory via &lt;code&gt;`malloc()`&lt;/code&gt;, you get whatever was previously there.&lt;/p&gt;
    &lt;p&gt;Since Mongo is writen in C++, that unreferenced heap garbage part can represent anything that was in memory from previous operations, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Cleartext passwords and credentials&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Session tokens / API keys&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Customer data and PII&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Database configs and system info&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Docker paths and client IP addresses&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[ REAL BSON DATA | password: 123 | apiKey: jA2sa | ip: 219.117.127.202 ]&lt;/code&gt;
    &lt;head rend="h1"&gt;Exploit Part 2&lt;/head&gt;
    &lt;p&gt;Now that the server has wrongfully allocated some potentially-sensitive data to the input message, the only thing left for the attacker is to somehow get the server return the data.&lt;/p&gt;
    &lt;head rend="h3"&gt;BSON&lt;/head&gt;
    &lt;p&gt;As mentioned, BSON is Mongoâ€™s way of serializing JSON. As mentioned on its site, it was designed with efficiency in mind:&lt;/p&gt;
    &lt;quote&gt;
      &lt;head&gt;3. Efficient&lt;/head&gt;
      &lt;p&gt;Encoding data to BSON and decoding from BSON can be performed very quickly in most languages due to the use of C data types.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;C Strings&lt;/head&gt;
    &lt;p&gt;C famously uses null-terminated strings7. A null-terminated string means that a null byte is used to mark the end of the string:&lt;/p&gt;
    &lt;code&gt;char* s = "hello"
// in memory, this is represented as an array of characters with the last element being the null terminator: h e l l o \0&lt;/code&gt;
    &lt;p&gt;The way such strings get parsed is very simple - the deserializer reads every character until it finds a null terminator.&lt;/p&gt;
    &lt;head rend="h3"&gt;Malicious BSON Input&lt;/head&gt;
    &lt;p&gt;If you recall, I said earlier that the first field of the BSON message denotes what type of â€œRPCâ€ the command is.&lt;/p&gt;
    &lt;p&gt;As such, the first thing a server does when handling an incoming message over the wire isâ€¦ parse the first field!&lt;/p&gt;
    &lt;p&gt;Because fields are strings, and strings are null-terminated CStrings, the deserializing logic in the MongoDB server parses the field until the first null terminator found.&lt;/p&gt;
    &lt;p&gt;An attacker can send a compressed, invalid BSON object that does NOT contain a null terminator. This forces the server to continue scanning through foreign data in the wrongly-allocated memory buffer until it finds the first null terminator (\0)&lt;/p&gt;
    &lt;code&gt;# Conceptual
[ REAL DATA |             UNREFERENCED HEAP GARBAGE                 ]
# Practical Example
[ { "a      | password: 123\0 | apiKey: jA2sa | ip: 219.117.127.202 ]&lt;/code&gt;
    &lt;p&gt;As the first null terminator is right after the password, the server would now think that the first field of the BSON is:&lt;/p&gt;
    &lt;code&gt;"a      | password: 123"&lt;/code&gt;
    &lt;p&gt;Obviously that is an invalid BSON field, so the server responds with an error to the client. In order to be helpful, the response contains an error message that shows which field was invalid:&lt;/p&gt;
    &lt;code&gt;{
  "ok": 0,
  "errmsg": "invalid BSON field name 'a      | password: 123'",
  "code": 2,
  "codeName": "BadValue"
}&lt;/code&gt;
    &lt;p&gt;Boom. The attacker successfully got the server to leak data to it.&lt;/p&gt;
    &lt;p&gt;Any serious attacker would then run this over and over again, thousands of time a second, until they believe theyâ€™ve scanned the majority of the databaseâ€™s heap. They can then repeat this ad infinitum.&lt;/p&gt;
    &lt;head rend="h1"&gt;ğŸ’¥ Impact&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Ease of Exploitation - â€œPre-Authâ€&lt;/head&gt;
    &lt;p&gt;The impact of this is particularly nasty, because the request-response parsing cycle happens before any authentication can be made. This makes sense, since you cannot begin to authenticate a request you still havenâ€™t deserialized.&lt;/p&gt;
    &lt;p&gt;This allows any attacker to gain access to any piece of potentially-sensitive data. The only thing they need is internet access to the database.&lt;/p&gt;
    &lt;p&gt;Exposing your database to the internet is a practice thatâ€™s heavily frowned upon8. At the same time, Shodan shows that there are over 213,000 publicly-accessible Mongo databases.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Eight Years of Vulnerability (handled badly)&lt;/head&gt;
    &lt;p&gt;The PR that introduced the bug was from May 2017. This means that, roughly from version 3.6.0, any publicly-accessible MongoDB instance has been vulnerable to this.&lt;/p&gt;
    &lt;p&gt;It is unknown whether the exploit was known and exploited by actors prior to its disclosure. Given the simplicity of it, I bet it was.&lt;/p&gt;
    &lt;p&gt;As of the exploitâ€™s disclosure, which happened on 19th of December, it has been a race to patch the database.&lt;/p&gt;
    &lt;p&gt;Sifting through Git history, it seems like the fix was initially committed on the 17th of December. Interestingly enough, it was only merged a full 5 days after - on the 22nd of December (1-line fix btw).&lt;/p&gt;
    &lt;p&gt;That beig said, MongoDB 8.0.17 containing the fix was released on Dec 19, consistent with the CVE publish data. But JIRA activity shows that patches went out on the 22nd of December.&lt;/p&gt;
    &lt;p&gt;Because thereâ€™s no official timeline posted, members of the community like me have to guess. As of writing, 10 days later in Dec 28, 2025, Mongo have still NOT properly addressed the issue publicly.&lt;/p&gt;
    &lt;p&gt;They only issued a community disclosure of the CVE a full five days after the publication of it. It is then, on the 24th of December, that they announced that all of their database instances in their cloud service Atlas were fully patched.&lt;/p&gt;
    &lt;p&gt;I believe this implies that all Atlas databases exposed to the internet were vulnerable to this issue for almost a week. By default, Atlas databases use an IP allowlist for connectivity. But users could configure it to allow connections from anywhere.&lt;/p&gt;
    &lt;p&gt;Mongo says that they havenâ€™t verified exploitation so far:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;â€œat this time, we have no evidence that this issue has been exploited or that any customer data has been compromisedâ€&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;3. Ease of Mitigation&lt;/head&gt;
    &lt;p&gt;Mitigation is admittedly very easy, you have one of two choices:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Update to the newest patch&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Disable zlib network compression&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I found the latter wasnâ€™t circulated a lot in online talk, but I understand is just as good as a short-term mitigation.&lt;/p&gt;
    &lt;head rend="h1"&gt;A bit of Drama?&lt;/head&gt;
    &lt;p&gt;The tech lead for Security at Elastic coined the name MongoBleed by posting a Python script that acts as a proof of concept to exploiting the vulnerability: https://github.com/joe-desimone/mongobleed&lt;/p&gt;
    &lt;p&gt;This is particularly interesting, because despite being different systems, Mongo competes with Elastic on Vector Search, Text Search and Analytical use cases.&lt;/p&gt;
    &lt;head rend="h1"&gt;Summary&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The exploit allows attackers to read arbitrary heap data, including user data, plaintext passwords, api keys/secrets, and more.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is performed by leveraging a simple, malformed zlib-compressed request.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB versions from 2017-2025 are vulnerable to this exploit.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Rough timeline:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;June 1, 2017: Commit introducing the bug gets merged.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 17, 2025: Code for the fix is written (original commit date).&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 19, 2025: CVE officially published.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 22, 2025: Code with the fix is merged.&lt;/p&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Dec 24, 2025: MongoDB announce the patch, say all Atlas databases are patched.&lt;/p&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On Dec 24th, MongoDB reported they have no evidence of anybody exploiting the CVE. Given the fact this exploit lived on for ~8 years, and their honey-pot cloud service Atlas took a full 5 days to patch since the official CVE publish dateâ€¦ I find that hard to believe.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MongoDB have not apologized yet.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are over 213k+ potentially vulnerable internet-exposed MongoDB instances, ensuring that this exploit is web scale:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Interesting Links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Official CVE: https://nvd.nist.gov/vuln/detail/CVE-2025-14847 (Dec 19, 2025)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;PR introducing the bug: https://github.com/mongodb/mongo/pull/1152 (May 2017)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Commit fixing the issue: https://github.com/mongodb/mongo/commit/505b660a14698bd2b5233bd94da3917b585c5728#diff-e5f6e2daef81ce1c3c4e9f7d992bd6ff9946b3b4d98a601e4d9573e5ef0cb07dR77&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Security Report on the incident, including fix versions: https://www.ox.security/blog/attackers-could-exploit-zlib-to-exfiltrate-data-cve-2025-14847/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Write-up on how to detect exploitation attempts via log analysis: https://blog.ecapuano.com/p/hunting-mongobleed-cve-2025-14847&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Somebody also vibe-coded a detector: https://github.com/Neo23x0/mongobleed-detector&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Other Reads You May Like:&lt;/head&gt;
    &lt;p&gt;zlib is a library for compression. It uses the DEFLATE algorithm under the hood, but produces results in a specific wire format to ease sending such data over the wire. (e.g includes metadata like flags, checksums, etc)&lt;/p&gt;
    &lt;p&gt;Here is the PR that introduced it. Iâ€™m not aware of Mongoâ€™s public review practices, but it appears as if nobody explicitly reviewed the change.&lt;/p&gt;
    &lt;p&gt;They actually created it. Thereâ€™s a very good site for it - https://bsonspec.org/&lt;/p&gt;
    &lt;p&gt;Weird, I know. Here are examples of different commands, just so you get a sense:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Insert a document into the users table&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "insert": "users",
  "documents": [{ "name": "alice", "age": 30 }]
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Delete users with&lt;/p&gt;
        &lt;code&gt;inactive=true&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{
  "delete": "users",
  "deletes": [ { "q": { "inactive": true }, "limit": 0 }]
}&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Check the serverâ€™s status&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;{ "serverStatus": 1 }&lt;/code&gt;
    &lt;p&gt;Iâ€™m making this number up. There is probably some limit on the server side as to how large a request can be - perhaps 1MB is too large.&lt;/p&gt;
    &lt;p&gt;Here is the line (pre-fix): https://github.com/mongodb/mongo/blame/b2f3ca9c996ba409e7d48601fca16c28fd58b774/src/mongo/transport/message_compressor_zlib.cpp#L83&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;`output` &lt;/code&gt;is the large memory buffer that was allocated earlier&lt;/p&gt;
    &lt;p&gt;The code, instead, ought to return the referenced &lt;code&gt;`length`&lt;/code&gt; field, as that gets updated with the actual length that was seen post-compression.&lt;/p&gt;
    &lt;p&gt;This has been the cause of many security issues in the past.&lt;/p&gt;
    &lt;p&gt;The most common comment I saw online is that you â€œdeserved itâ€ if you exposed your DB to the wild. ğŸ˜&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bigdata.2minutestreaming.com/p/mongobleed-explained-simply"/><published>2025-12-28T21:03:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414819</id><title>Unity's Mono problem: Why your C# code runs slower than it should</title><updated>2025-12-29T03:04:03.962213+00:00</updated><content>&lt;doc fingerprint="f319d3cb995267ca"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Unity's Mono problem: Why your C# code runs slower than it should&lt;/head&gt;
    &lt;p&gt;Execution of C# code in UnityÃ¢s Mono runtime is slow by todayÃ¢s standards, much slower than you might expect! Our game runs 2-3x faster on modern .NET compared to UnityÃ¢s Mono, and in a few small benchmarks I measured speedups of up to 15x. IÃ¢ve spent some time investigating whatÃ¢s going on and in this article I will present my findings and why everyone should want UnityÃ¢s .NET modernization to become production-ready as soon as possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;How did we get here&lt;/head&gt;
    &lt;p&gt;Unity uses the Mono framework to run C# programs and back in 2006 it was one of the only viable multi-platform implementations of .NET. Mono is also open-source, allowing Unity to do some tweaks to better suit game development.&lt;/p&gt;
    &lt;p&gt;An interesting twist happened nearly 10 years later. In 2014, Microsoft began open-sourcing .NET (notably .NET Core later that year) and in June 2016, .NET Core 1.0 shipped with official cross-platform support. Since then, the .NET ecosystem gained momentum and lots of improvements have been made, including the Roslyn compiler platform, a new JIT (just-in-time compiler), performance improvements, more features, etc.&lt;/p&gt;
    &lt;p&gt;In 2018, Unity engineers discussed that they are working on porting the engine to .NET CoreCLR, the multi-platform version of Common Language Runtime (CLR), a component that runs .NET programs. Their main motivations behind this project were performance and convergence. In their post they said:&lt;/p&gt;
    &lt;quote&gt;...CoreCLR could be great for Unity game developers, as it will provide a significant boost in performance, by an order of 2x to 5x compare to the Mono runtime sometimes up to x10 on some workload!&lt;/quote&gt;
    &lt;p&gt;Unfortunately, now itÃ¢s the end of 2025 and we still canÃ¢t run games on CoreCLR.&lt;/p&gt;
    &lt;head rend="h2"&gt;The performance gap&lt;/head&gt;
    &lt;p&gt;We donÃ¢t hear about the performance gap between Mono and .NET much, likely because it is not possible to run games written for Unity under modern .NET. But we can still do a direct comparison with code that does not depend on Unity directly.&lt;/p&gt;
    &lt;p&gt;Our game has a unique architecture Ã¢ we strictly separate the game simulation code (business logic) from rendering. So much so that the simulation code does not depend on UnityÃ¢s libraries and can be compiled and run under any .NET version.&lt;/p&gt;
    &lt;p&gt;One day I was debugging an issue in map generation and it was time-consuming because it was taking over 2 minutes to start a game. To make debugging faster, IÃ¢ve written a unit test, hoping to cut down on the turn-around time since Unity takes 15+ seconds just to crunch new DLLs and reload the domain before the game can be launched and it also initializes rendering stuff that I did not care about. When I ran the test, it finished in 40 seconds. I was quite surprised that it was more than 3x faster, so I started digging deeper.&lt;/p&gt;
    &lt;p&gt;Long story short, Figure 1 shows traces from a profiler showing the difference between the game launching in Unity running under Mono vs. a unit test running under .NET.&lt;/p&gt;
    &lt;p&gt;Note that all shown benchmarks are using either Unity 6.0 or .NET 10.&lt;/p&gt;
    &lt;p&gt;So our benchmark shows that loading a save file, generating a map, and initializing the simulation takes 100 seconds in Unity/Mono but only 38 seconds in .NET. This result alone is already something that may raise eyebrows and has real consequences of how you may want to approach debugging and testing.&lt;/p&gt;
    &lt;p&gt;I also know from experience with Unity that Release mode running as a standalone executable (without the Unity editor) is much faster, so I decided to test that next.&lt;/p&gt;
    &lt;head rend="h2"&gt;.NET vs. Mono in standalone Release mode&lt;/head&gt;
    &lt;p&gt;Debug mode slowness is not great, but even non-optimized C++ code can be slow. To compare the real performance gap between Mono and .NET, letÃ¢s run the same benchmark as above but in release mode, standalone executable.&lt;/p&gt;
    &lt;p&gt;First up: Unity. IÃ¢ve run our deploy script to get an optimized executable and run it directly. Unsurprisingly, optimized standalone executable is beating Unity editor by a big margin, more than 3x faster. Next, the same code running under .NET in Release mode. Figure 2 shows the results.&lt;/p&gt;
    &lt;p&gt;Yep. 12 seconds. ItÃ¢s actually mind-boggling how much work is being done in these 12 seconds and when I saw this for the first time, I was not only shocked, but also impressed. Just so you know, a 4k Ãƒ 4k map is being generated using all available threads out of hundreds of combined noise functions in like 3 seconds. Figure 3 shows the trace expanded.&lt;/p&gt;
    &lt;p&gt;If you are interested in seeing the actual x86 assembly generated by Mono and .NET JITs, see the Extras section at the end of this article.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;As you can see from the presented benchmarks, Mono is massively behind .NET in terms of performance. This is primarily due to differences in runtime optimizations and JIT that generates unoptimized assembly. The actual speedup surely depends on the code itself, but from my research, 1.5-3x speedup of C# execution is very likely for most projects.&lt;/p&gt;
    &lt;p&gt;If you are a game developer using Unity, or even a player, you can now understand that CoreCLR would be a massive boost to performance of games and even the Unity editor. Unfortunately, for the past 8 years, Unity leadership was more interested in Ã¢other thingsÃ¢ and did not give .NET modernization the attention it deserves.&lt;/p&gt;
    &lt;p&gt;Some view .NET modernization as support for new language features in C#, but that is just a cherry on top. New C# adds some handy features, but the new JIT can deliver multi-x speedups.&lt;/p&gt;
    &lt;p&gt;At this year's Unite conference, Unity announced that CoreCLR is still ongoing but it wonÃ¢t be production ready in 2026. The good news is that it now seems to be on the Unity 6.x roadmap, and not left for later versions as suggested by 2024Ã¢s Unite presentation.&lt;/p&gt;
    &lt;p&gt;Moreover, CoreCLR is not just new JIT and C#, it unlocks broader and better-optimized support for things like Span&amp;lt;T&amp;gt;-style APIs, hardware intrinsics, and newer SIMD paths that devs cannot use these days. These features could add another multiplier to the performance gains for some classes of code. For example, our map generator heavily uses 2D and 3D simplex noise. I bet that having access to new runtime features in CoreCLR could speed up the map generation by another 2x.&lt;/p&gt;
    &lt;p&gt;Unity has a technology called Burst that automatically converts marked C# methods to optimized native assembly via the LLVM compiler. This sounds neat as it can avoid the poor JIT performance, but the downside is that Burst has strict limitations on what can be converted and supports only subset of C#. I believe that CoreCLR with modern JIT will have very similar performance characteristics to Burst. I am curious what would happen in a universe where Unity invested all the time and effort in CoreCLR support and high-performance C#, instead of developing and maintaining Burst.&lt;/p&gt;
    &lt;p&gt;Another interesting consequence of CoreCLR support is the ability to pre-compile the .NET intermediate assembly to machine code using ahead-of-time compilation (AOT). AOT can further improve startup time and is essential on platforms where JIT is restricted (notably iOS). Nowadays, Unity solves this with IL2CPP that takes the intermediate code and compiles it to C++ which is then optimized and compiled to native assembly. However, according to RichardFine (Unity staff), using CoreCLR AOT is not planned and IL2CPP is here to stay:&lt;/p&gt;
    &lt;quote&gt;AOT for IL2CPP is completely independent of AOT for CoreCLR (which we have no plans to adopt anyway). GC behaviour on IL2CPP improves when we upgrade the GC there, itÃ¢s not really affected by CoreCLR at all.&lt;/quote&gt;
    &lt;p&gt;In conclusion, CoreCLR wonÃ¢t magically fix every bottleneck in a Unity game, but it does fix many of the code generation inefficiencies and allows writing higher-performance code. The benchmark presented in this article is meant to illustrate that modern .NET has spent years squeezing more work into fewer CPU cycles, and Unity users are largely locked out of those gains today.&lt;/p&gt;
    &lt;p&gt;If Unity can deliver production-ready CoreCLR support, it wonÃ¢t just mean Ã¢newer C#Ã¢. It will mean faster runtime performance, faster iteration times, more performance headroom, no domain reload, better GC behavior, and maybe even more managed code and less native code. Until then, the gap will remain an invisible tax on every Unity project that leans on managed code.&lt;/p&gt;
    &lt;p&gt;IÃ¢m cheering for you, Unity devs, CoreCLR for the win!&lt;/p&gt;
    &lt;head rend="h2"&gt;Extras: Comparison of x86 assembly&lt;/head&gt;
    &lt;p&gt;I have actually dug much deeper into the performance aspects of Mono vs .NET but for the sake of this article not being too long, here is a brief summary.&lt;/p&gt;
    &lt;p&gt;Code listing 1 shows the testing code. It does some basic summing of custom structs that are wrappers around ints. This is an interesting example because Mono is very bad at inlining and simplifying expressions, even obvious ones, and we have plenty of structs like these in our code base (e.g. Quantity, MechPower, Tile2i, etc).&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;static class Program { static void Main() { Console.WriteLine(RunTest(int.MaxValue)); } public static TestStruct RunTest(int iterations) { TestStruct value1 = new TestStruct(iterations % 2); TestStruct value2 = new TestStruct(iterations % 7); TestStruct value3 = new TestStruct(iterations % 13); TestStruct result = default; for (int i = 0; i &amp;lt; iterations; ++i) { result += value1 + value2; result += value1 + value3; } return result; } } readonly struct TestStruct { public readonly int Value; public TestStruct(int value) { Value = value; } public static TestStruct operator +(TestStruct lhs, TestStruct rhs) { return new TestStruct(lhs.Value + rhs.Value); } public override string ToString() =&amp;gt; Value.ToString(); }&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;To obtain assembly code, IÃ¢ve compiled the code in Release mode and ran it as a standalone executable. Then, I attached a debugger to the running process. An easy way to find this loop was to make it long/infinite and just break the program at any time, it would end up in that loop.&lt;/p&gt;
    &lt;p&gt;First, letÃ¢s take a look at .NET. Here is the x64 assembly of the for-loop section of the code.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;add r8d,edx add edx,r10d 00007FFDEC338E88: mov r10d,r8d add r9d,r10d mov r10d,edx add r9d,r10d inc ecx cmp ecx,eax jl 00007FFDEC338E88&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt; In both cases, the full loop of &lt;code&gt;int.MaxValue&lt;/code&gt; iterations took around 750 ms on my machine.
&lt;/p&gt;
    &lt;p&gt; This looks neat. Even if you donÃ¢t read assembly, you can see that there are two add instructions, one decrement, and one jump. It seems that the JIT hoisted the invariant sums &lt;code&gt;a = value1 + value2&lt;/code&gt; and &lt;code&gt;b = value1 + value3&lt;/code&gt; out of the loop and then just accumulates them.
&lt;/p&gt;
    &lt;p&gt;I also tested x86 assembly, and it looks very similar:&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;082E18D0: lea ebx,[esi+edi] add eax,ebx lea ebx,[esi+edx] add eax,ebx dec ecx jne 082E18D0&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt;Interestingly, the loop direction was reversed, counting down. This saves one instruction as comparison to zero and conditional jump can be done as one instruction.&lt;/p&gt;
    &lt;p&gt;Now letÃ¢s look at MonoÃ¢s x64 assembly.&lt;/p&gt;
    &lt;code&gt;
      &lt;table&gt;
        &lt;tr&gt;
          &lt;td&gt;
            &lt;quote&gt;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 &lt;/quote&gt;
          &lt;/td&gt;
          &lt;td&gt;
            &lt;quote&gt;1E87D2F3E20: movsxd rax,dword ptr [rsp+0C0h] mov dword ptr [rsp+40h],eax movsxd rax,dword ptr [rsp+0B8h] mov dword ptr [rsp+38h],eax movsxd rax,dword ptr [rsp+40h] mov dword ptr [rsp+0A0h],eax movsxd rax,dword ptr [rsp+38h] mov dword ptr [rsp+98h],eax movsxd rax,dword ptr [rsp+0A0h] movsxd rcx,dword ptr [rsp+98h] add eax,ecx mov dword ptr [rsp+90h],0 mov dword ptr [rsp+90h],eax mov dword ptr [rsp+30h],eax movsxd rax,dword ptr [rsp+0A8h] mov dword ptr [rsp+88h],eax movsxd rax,dword ptr [rsp+30h] mov dword ptr [rsp+80h],eax movsxd rax,dword ptr [rsp+88h] movsxd rcx,dword ptr [rsp+80h] add eax,ecx mov dword ptr [rsp+78h],0 mov dword ptr [rsp+78h],eax mov dword ptr [rsp+0A8h],eax mov dword ptr [rsp+28h],eax movsxd rax,dword ptr [rsp+0C0h] mov dword ptr [rsp+20h],eax movsxd rax,dword ptr [rsp+0B0h] mov dword ptr [rsp+18h],eax movsxd rax,dword ptr [rsp+20h] mov dword ptr [rsp+70h],eax movsxd rax,dword ptr [rsp+18h] mov dword ptr [rsp+68h],eax movsxd rax,dword ptr [rsp+70h] movsxd rcx,dword ptr [rsp+68h] add eax,ecx mov dword ptr [rsp+60h],0 mov dword ptr [rsp+60h],eax mov dword ptr [rsp+10h],eax movsxd rax,dword ptr [rsp+28h] mov dword ptr [rsp+58h],eax movsxd rax,dword ptr [rsp+10h] mov dword ptr [rsp+50h],eax movsxd rax,dword ptr [rsp+58h] movsxd rcx,dword ptr [rsp+50h] add eax,ecx mov dword ptr [rsp+48h],0 mov dword ptr [rsp+48h],eax mov dword ptr [rsp+0A8h],eax inc esi cmp esi,7FFFFFFFh jl 1E87D2F3E20&lt;/quote&gt;
          &lt;/td&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
    &lt;/code&gt;
    &lt;p&gt; As you can see just from the number of instructions, this code will run way slower. The full loop of &lt;code&gt;int.MaxValue&lt;/code&gt; iterations took around 11500 ms, thatÃ¢s ~15x slower.
&lt;/p&gt;
    &lt;p&gt;In the assembly you can see the four add instructions in the loop, the Ã¢inefficientÃ¢ increment + comparison + jump (instead of decrement + conditional jump), and most importantly a sea of mov instructions, which are just memory copies from inefficient inlining of the struct fields. Basically Mono is just tossing values around memory.&lt;/p&gt;
    &lt;p&gt;I have also tested assembly compiled in Debug mode running in the Unity editor and itÃ¢s even worse. The full loop takes 67 seconds (67000 ms)! In Unity Editor, the JIT likely switches to far less optimized codegen and includes additional checks/sequence-point overhead, which balloons runtime.&lt;/p&gt;
    &lt;p&gt;Takeaway: modern .NETÃ¢s JIT can scalarize tiny value types and hoist invariant work so the hot loop becomes a handful of register ops, while Mono often fails to do so and ends up shuffling values through memory, exactly the kind of gap that shows up as slowdowns in real simulation-heavy code.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://marekfiser.com/blog/mono-vs-dot-net-in-unity/"/><published>2025-12-28T21:41:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414837</id><title>Why I Disappeared â€“ My week with minimal internet in a remote island chain</title><updated>2025-12-29T03:04:03.562440+00:00</updated><content>&lt;doc fingerprint="5df6d2b4112c141d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why I Disappeared&lt;/head&gt;
    &lt;head rend="h3"&gt;My week with minimal internet in a remote island chain&lt;/head&gt;
    &lt;p&gt;Iâ€™m writing this on my flight back from a weeklong trip to the Galapagos Islands, where for the first time in years I was largely without access to the Internet. For someone as congenitally online as I am, this at first seemed a curse. It turned out to be far from that and has me questioning a lot of what I thought I knew about media, politics and, well, people.&lt;/p&gt;
    &lt;p&gt;My Galapagos excursion took place on a boat with over a dozen other travelers. They were young and older, professors and small business owners (even an Army colonel!), Republicans and Democrats, from big cities and small towns. People from wildly different backgrounds readily shared sunscreen, snacks, even life advice. And while it wasnâ€™t partisan, it also wasnâ€™t apolitical: issues like the outrageous cost of housing, healthcare and childcare came up. Yet absent was the political vitriol that the national security state says necessitates a new domestic war on terrorism.&lt;/p&gt;
    &lt;p&gt;Contrary to the national security threat machineâ€™s picture of a country at war with itself, we all got along so swimmingly that the idea of a civil war or anything like it struck me as laughable, as did the notion that the statistically insignificant number of politically-motivated killings, though real, said anything at all about the vast majority of real-world Americans. I say â€˜real-worldâ€™ to distinguish from the Internet, where anonymity and disembodied reality can lead to people saying things they never would in real life.&lt;/p&gt;
    &lt;p&gt;The Galapagos are unique because its extreme remoteness has insulated various species from outside predators, providing Charles Darwin a controlled setting to observe and later theorize evolution. That same remoteness â€” in my case from the constant intravenous drip of the internet and social media for the first time in maybe my entire adult life â€” left me with the staggering realization that what passes for news is mostly just noise.&lt;/p&gt;
    &lt;p&gt;Where Darwin prized the islands for its incubation of remarkably distinct animal lineages, I too benefited from the bewitching remoteness of the Galapagos. During the brief, intermittent moments that I had time to check the news (rather than living through it moment by moment), I realized how utterly forgettable and meaningless most of it was.&lt;/p&gt;
    &lt;p&gt;Not watching every twist and turn about, say, the latest Epstein transparency failure, I noticed how little these news cycles ultimately produce â€” a very different picture than the 24/7 cycle creates. When I saw that Washington media had dogpiled Trumpâ€™s chief of staff Susie Wiles for offering some mildly critical remarks about Elon Musk and other administration figures, it occurred to me that no one would give a shit about or even remember any of this a week from now.&lt;/p&gt;
    &lt;p&gt;I came away shocked and sad at how much the media traffics in fake urgency as a result of its quest for the click. Combine that with national securityâ€™s constant drumbeat of civil war, disinformation, terrorism, violence, and the threat from within and you can see why people disengage from the news. Itâ€™s not they donâ€™t care, lack â€œmedia literacy,â€ or any of the usual explanations. They look at the hurricane of sensational headlines and arenâ€™t sure what theyâ€™re supposed to do with any of it or if they should even believe it. And theyâ€™re right.&lt;/p&gt;
    &lt;p&gt;When another traveler on the boat, an academic, remarked that she didnâ€™t really follow the news, it occurred to me that if even a very intelligent, well-educated and thoughtful person feels this way, the media has a much deeper problem than supposedly lazy audiences.&lt;/p&gt;
    &lt;p&gt;None of this is to say that there isnâ€™t important news out there. But as with evolution, change is usually more gradual, like the shifting of tectonic plates, than the 24/7 cycle suggests.&lt;/p&gt;
    &lt;p&gt;One of the most striking features of Galapagos is its record number of â€œendemicâ€ species, or those that can only be found in this one place. Thatâ€™s why the islands have an almost otherworldly feeling with such unique creatures as the giant Galapagos tortoise, the blue-footed booby, and the Galapagos penguin. The takeaway here is that sometimes evolution requires insulation from outside forces. And if Iâ€™m honest, as much as I love social media, it makes it difficult to develop the intellectual equivalent of Galapagosâ€™ delicate species because these gargantuan apps foster a ruthless competition for your attention that becomes a race to the bottom.&lt;/p&gt;
    &lt;p&gt;In other words, social media is such a free-for-all of attention-grabbing stunts that itâ€™s hard to see through the blizzard of posts to what actually matters â€” which is supposed to be the whole point of journalism.&lt;/p&gt;
    &lt;p&gt;What the incentives for now, now, now creates is a perverse system of survival of the dumbest. Just take a look at the insane number of hoax Epstein documents and allegations swirling around social media right now. A doctored video of Jeffrey Epstein committing suicide in his cell has generated millions of views on X alone, despite the hoax clip having first circulated in 2020.&lt;/p&gt;
    &lt;p&gt;As I return to celebrate Christmas, I realize that I didnâ€™t really miss much during my week without social media. What passes for the news though, at its breakneck speed, zooms here and there, initially making it feel like I missed so much, that itâ€™s all so overwhelming, that I canâ€™t possibly keep up and should instead retreat to my family and friends, my reading, my hobbies, my team, my town. Nothing encourages me to be involved. And though I know that those in charge donâ€™t have everything under control, donâ€™t have a plan, and are grossly committed to survival of the fittest, I also am reminded that they love it this way. The blizzard of false urgency leaves us, the public, confused â€” just how the elite like it. We are prey.&lt;/p&gt;
    &lt;p&gt;But I have a plan. In this next year Iâ€™ll be focusing more on stories that actually matter instead of chasing the flash-in-the-pan ephemera that nobody remembers the next week. And most importantly, Iâ€™m also going to create my own island, by launching a new kind of website apart from Substack and the social media maelstrom. My dream is to create a home for news that is truly endemic to the site â€” that you canâ€™t find anywhere else â€” by incubating stories that evince the kind of uniqueness as the magical creatures of the Galapagos.&lt;/p&gt;
    &lt;p&gt;Help me protect the fragile species that isnâ€™t predatory, clickbait journalism by becoming a paid subscriber below (or via our GoFundMe if you prefer a one-off contribution.)&lt;/p&gt;
    &lt;p&gt;â€” Edited by William M. Arkin&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.kenklippenstein.com/p/why-i-disappeared"/><published>2025-12-28T21:45:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46414916</id><title>Dolphin Progress Report: Release 2512</title><updated>2025-12-29T03:04:01.747955+00:00</updated><content>&lt;doc fingerprint="b630491f28054ad1"&gt;
  &lt;main&gt;
    &lt;p&gt;With the holiday season reaching its apex, we have a few surprises for those of you that have been patiently waiting. The latest release of Dolphin is stuffed with treats. Our first present is presentation - frame presentation, that is. Two new options have arrived and will help users both reduce latency and smooth out games that struggle with frame pacing.&lt;/p&gt;
    &lt;p&gt;Some games do outright naughty things that make emulation difficult. A slew of them are being coerced onto the nice list this year thanks to a sack full of patches that bypass their troublesome behaviors. Fans of the Broadband Adapter (BBA) have a great present tailored just to them: a new local mode BBA! Designed for allowing multiple instances of Dolphin on the same computer to connect together, it's perfect for use with Parsec or other similar services. And perhaps another gift will have you singing your favorite Wii hits?&lt;/p&gt;
    &lt;p&gt;But alas, what fun would the holiday season be if we spoiled all the gifts? Read on to unwrap the latest edition of the Dolphin Progress Report.&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;...&lt;/p&gt;
    &lt;p&gt;Huh? We've received word that apparently the Android users have made the nice list? Really? That can't be right... but this gift is addressed to them.&lt;/p&gt;
    &lt;p&gt;After more than a couple bumps in the road, RetroAchievements support has finally arrived on the Android version of Dolphin! In Release 2512, the core achievement experience is now available in your pocket. This initial version hasn't quite reached parity yet with the desktop experience, but we didn't want to hold things up any longer. The important thing for Android RetroAchievements users is that you can log in and unlock achievements in supported GameCube games. Because some menus are incomplete, it may be best to have the RetroAchievements website open in the background for achievement lists and other things while we finish up the in-app UI.&lt;/p&gt;
    &lt;head rend="h3"&gt;Notable ChangesÂ¶&lt;/head&gt;
    &lt;head rend="h4"&gt;2509-493 - Add Rush Frame Presentation and Smooth Frame Presentation Options by BilliardÂ¶&lt;/head&gt;
    &lt;p&gt;Latency was once a huge challenge for emulators, and it is still a major concern. At one point not too long ago, it was pretty much infeasible for most emulators to match the latency of their console counterparts. Compared to a dedicated game console racing the beam on a CRT television, emulators had to deal with sluggish OS window managers with on-by-default triple-buffer V-Sync holding three frames back, first-gen wireless controllers that added latency right at the source of input, slower displays that added several additional frames of latency (much more if that display was a TV without game mode), and on top of everything the emulator still needed to do its job and take time to actually emulate everything.&lt;/p&gt;
    &lt;p&gt;Dolphin just missed out on the worst of this. By the time Dolphin's performance and compatibility were good enough for users to worry about things like latency, the overall situation had improved dramatically. Low latency and high refresh rate monitors paired with features like Exclusive Fullscreen removed most of the major bottlenecks that emulators had to fight against.&lt;/p&gt;
    &lt;p&gt;The designs of the GameCube and Wii also afford Dolphin some opportunities that other emulators don't have. The GameCube/Wii are double buffer V-Sync'd by default, resulting in a final input latency of roughly 60ms on a CRT in an optimized 60fps title. However, because of how the XFB Output Pipeline works, Dolphin has the opportunity to bypass the buffers and grab those XFB copies early, and immediately present them directly to the screen. We call this feature Immediately Present XFB, and it cuts out quite a bit of the latency present on the console.&lt;/p&gt;
    &lt;p&gt;Tricks like these let Dolphin match console latency as long as the host device is capable enough. On extremely optimal setups with low latency VRR monitors combined with Immediately Present XFB, Dolphin could even dip a frame below real console latency!&lt;/p&gt;
    &lt;p&gt;There are some caveats, though. While Immediately Present XFB is a powerful tool for reducing latency, it is also a hack that relies on games behaving in a specific manner. If a game messes with the XFB pipeline, such as if it applies post processing using the CPU, or stitches together multiple XFB Copies, the hack will cause Dolphin to output nonsensical garbage.&lt;/p&gt;
    &lt;p&gt;Even when Immediate isn't outright breaking the game, the XFB pipeline is a big part of how some games handle frame pacing, so bypassing it can make the game feel less smooth. For the best experience in many games, a user probably would prefer superior latency and good frame pacing.&lt;/p&gt;
    &lt;p&gt;And that was Billiard's goal. He saw an opportunity to improve the situation and started work on two new options. One feature was a way to reduce latency without disrupting how the game rendered, and the other would allow smoother frame pacing even in games that struggled on real console. How would he accomplish these feats? Well, by making the emulator throttle smarter.&lt;/p&gt;
    &lt;p&gt;Modern computers are powerful enough to emulate most GameCube and Wii games faster than the original hardware could run them. Disable the framelimiter and try it for yourself! To keep emulation on pace, Dolphinâ€™s Throttle function stalls emulation to produce a mostly properly paced simulation of the original hardware. Throttling is necessary for playable emulation on modern systems, but making the host CPU wait adds time. If input from the user and stalls are aligned poorly, throttling can add a small amount of latency.&lt;/p&gt;
    &lt;p&gt;To address this, Billiard has added a new throttling mode called Rush Frame Presentation, where throttling becomes centered around presenting the frame as soon as it can after the input is read. In theory, this reduces the time between click and photon and can have a very noticeable effect, especially in lower frame rate titles. To the end user, all of this is completely invisible. All of this is happening sub-frame, so Dolphin still will throttle the appropriate amount of time to maintain the correct frame rate.&lt;/p&gt;
    &lt;p&gt;The faster your computer, the more of an effect this will have because it will be able to emulate the part of the frame faster. We can easily catch the difference in The Legend of Zelda: Wind Waker and Super Mario Sunshine by using a high speed camera, for example.&lt;/p&gt;
    &lt;p&gt;Some games will also see a further benefit by combining Immediately Present XFB with Rush Frame Presentation. Unfortunately, this combination can lead certain games to looking gnarly as they will just be spitting out the image at whatever point they're finished rendering during a frame. That's why the second new option is important.&lt;/p&gt;
    &lt;head rend="h5"&gt;Smoothing Things OutÂ¶&lt;/head&gt;
    &lt;p&gt;Immediately Present XFB could already cause poor frame pacing, and now Rush Frame Presentation could make it even worse. In some games, it can get so poor that VRR monitors will fall out of their operating range!&lt;/p&gt;
    &lt;p&gt;Smooth Frame Presentation allows Dolphin to delay presentation by roughly 1-2ms so that it can more consistently output frames, using previous frame times as a heuristic. This option can be used in any game that has poor frame pacing in order to try to improve the situation.&lt;/p&gt;
    &lt;p&gt;The results of Smooth Frame Presentation are good enough that a lot of games that needed the XFB Output Pipeline enabled by default because of frame pacing issues can now take advantage of the lower input latency provided by Immediately Present XFB and Rush Frame Presentation without any noticeable side-effects.&lt;/p&gt;
    &lt;p&gt;Even if you're using neither of the latency features, some games just have bad frame pacing even on real console. Smooth Frame Presentation can help them, too. There are rare cases, especially when using Rush Frame Presentation alongside Immediately Present XFB, where a game's output will be so inconsistent that smoothing won't help. We're looking at you, Dragon Ball Z: Budokai.&lt;/p&gt;
    &lt;head rend="h5"&gt;Outside VerificationÂ¶&lt;/head&gt;
    &lt;p&gt;All of these results sound great, but outside of a few camera tests on lower frame rate games, we were mostly trusting latency offset numbers provided by Dolphin. Testers did also report better latency, but given that the placebo effect exists and these are such small differences, we wanted more concrete data. But other than just game feel, how do you test latency?&lt;/p&gt;
    &lt;p&gt;In the past, we've used the light sensor present on Rock Band 3 guitars alongside an in-game synchronization test to get some very rough offset values. The problem with that is that it will only ever test one game, and the guitar controller isn't particularly viable in most games outside of unusual controller runs.&lt;/p&gt;
    &lt;p&gt;Before making any claims about our latency, we wanted to do our due dilligence in respect to both Dolphin and real hardware. To accomplish this, we contacted some professionals that have been fighting against latency for quite some time. Fizzi from Slippi.gg and adapter expert Arte graciously donated their time and helped us measure latency in the latest version of Dolphin versus console. Arte specifically developed a GameCube controller adapter with a photon sensor designed to determine controller latency, which is rather convenient because that's exactly what we want to measure.&lt;/p&gt;
    &lt;p&gt;Their GameCube controller adapter polls the controller at 1000Hz, and a light sensor on it can be programmed to look for certain changes in output from the game. By having access to both the source of the input and the change on the screen, the adapter can provide a real world measurement of how exactly how long it takes for a user input to result in a change on the display - what is commonly referred to as "click to photon". As an added bonus, the adapter can also be hooked up to real console with no conversion or added latency, letting us compare directly with games running on real hardware and a CRT.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;The exciting thing about these numbers is that they confirm our experience. Dolphin's latency compares favorably to console. To be fair to the GameCube, Arte's emulation setup included a modern low-latency 144Hz monitor and the lowest latency controller adapter. Dolphin couldn't quite compete with Slippi, but most of that can be attributed to deep modifications to how Super Smash Bros. Melee outputs.&lt;/p&gt;
    &lt;p&gt;For all the samples above, an input bug present in the original game has been patched out. This is to make getting consistent results a little bit easier. That fix did mean that combining Rush Frame Presentation and Immediately Present XFB no longer benefited that title when testing. However, Arte modified the test to work with other games, and some games respond incredibly well when combining Rush and Immediate.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;Due to time constraints with holiday vacations, adjusting the photon sensor for different games, we weren't able to gather all of the numbers we wanted from other games. However, with Wind Waker the numbers were interesting enough that we managed to get enough samples right under the wire, at least in Dolphin. The graph above shows latency with default settings, Immediately Present XFB and the combined efforts of Immediately Present XFB and Rush Frame Presentation. Note that the default settings were measured last, and as such the error range is estimated.&lt;/p&gt;
    &lt;p&gt;The reason why we wanted to squeeze in this particular case is because it demonstrates that combining Rush Frame Presentation and Immediately Present XFB can result in lower latency than what was possible before. This is not always true, and this 10ms reduction is from an ideal example. Unmodified Melee, for instance, showed the combination reducing latency by less than 4ms. Some games saw no benefit from combining both features together.&lt;/p&gt;
    &lt;p&gt;In the end, how much these two new options will help varies greatly depending on the game and setup. Currently, we've left them both disabled by default in the Configuration -&amp;gt; Advanced Tab, but that may change as the settings get more testing and we gauge what users want the most.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-74 - GameCube - Add SDL Stock Profile by SambÂ¶&lt;/head&gt;
    &lt;p&gt;Unlike the wacky Wii Remote and its mess of attachments, the GameCube Controller mostly mirrors modern controllers. Sure, the sticks can't be pushed in, it's missing a shoulder button, the two stage analog+digital triggers can be tricky, and the face buttons are weird. But at the end of the day, it's a four face button, twin stick controller with a D-pad. Close enough?&lt;/p&gt;
    &lt;p&gt;So we have added an SDL Profile that players can use to speed up their GameCube controller mapping.&lt;/p&gt;
    &lt;p&gt;Using the profile is simple:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go the GameCube "Standard Controller" mapping window.&lt;/item&gt;
      &lt;item&gt;Select your controller from the Device dropdown. Pick the variant that starts with "SDL".&lt;/item&gt;
      &lt;item&gt;Select the &lt;code&gt;SDL Gamepad (Stock)&lt;/code&gt;Profile and click Load.&lt;/item&gt;
      &lt;item&gt;Optional: Calibrate your joysticks (please don't skip this Hall effect users!) and set up deadzone.&lt;/item&gt;
      &lt;item&gt;Enjoy.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since the GameCube controller doesn't map 1:1 to modern controllers, this is a best guess stock profile that will reasonably work for most people, most controllers, and most games. If a game demands a button combination that doesn't work with your hands on your controller, or if the face buttons or any other button simply aren't to your liking, you can build from the stock profile and adjust everything until it's just right.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-237 and 2509-339 - Add Option to Reset Settings Back to Default by JoshuaVandaele and Simonx22Â¶&lt;/head&gt;
    &lt;p&gt;Dolphin is a complicated emulator with a lot of options. Some of it is definitely our fault, and some of it is just the reality of trying to emulate something as complicated as the GameCube and Wii. To the average user, a lot of these settings aren't immediately obvious, even with descriptions.&lt;/p&gt;
    &lt;p&gt;"Emulated Memory this? EFB, XFB that, VBI what?"&lt;/p&gt;
    &lt;p&gt;The most experienced users (and even developers) can sometimes get frustrated enough with an issue that percussive maintenance is necessary, leading to one changing lots of settings around until something happens. Sometimes this works, leading to a temporary moment of joy, before it all comes crashing down when none of your other games will boot. Some people might be able to backtrack and figure out what went wrong, but a lot of users are left lost.&lt;/p&gt;
    &lt;p&gt;Until recently, users had to delete the Dolphin settings files from their computer to restore everything to default. No one liked that, but a button to reset settings was non-trivial thanks to Dolphin's multiple layers of settings that are a handful to manage.&lt;/p&gt;
    &lt;p&gt;Thankfully, JoshuaVandaele was finally able to sort out all of the implementation details and give us the long awaited "Reset All Settings" button.&lt;/p&gt;
    &lt;p&gt;Thanks to Simonx22, Android users also get access to this feature. It can be found in the advanced settings menu in the Android GUI.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-217 - GamePatch: Modify Certain Games to Behave Better in Dolphin by SuperSamus with additional contributorsÂ¶&lt;/head&gt;
    &lt;p&gt;Some games are more strenuous to emulate than others. Sometimes it's because the game pushes the console, and other times it's because the game does something annoying to emulate - maliciously or not.&lt;/p&gt;
    &lt;p&gt;The latter situation can be especially frustrating, as sometimes 99% of what the game does is fine, with just one little behavior, design decision, or sometimes even an underlying bug causing problems for Dolphin.&lt;/p&gt;
    &lt;p&gt;SuperSamus identified a few common game behaviors that causes Dolphin a lot of headaches. Properly fixing these issues would difficult, with some requiring large rewrites to the emulator that probably will never come. Fortunately, there is a simpler solution: patch out the difficult to emulate game behaviors. These small patches increase emulation performance, and sometimes even work around other unwanted behaviors.&lt;/p&gt;
    &lt;head rend="h5"&gt;Complex Idle LoopsÂ¶&lt;/head&gt;
    &lt;p&gt;Idle loops are a sequence of instructions that makes the CPU run laps doing nothing while it waits for something to happen. Obviously, emulating a CPU burning cycles doing nothing isn't efficient for an emulator, so one of Dolphin's earliest optimizations was the ability to detect and skip these idle loops. This feature is fairly standard among emulators and is called Idle Skipping.&lt;/p&gt;
    &lt;p&gt;Idle loops are more common than you might think. It's very rare for a game to absolutely max out the console's CPU, so for the majority of frames the CPU will idle a bit. And as long as Dolphin can detect the idle loops, they can be skipped to increase overall performance. Idle Skipping is one of the key things that make some areas of a game more demanding than others, especially on the CPU side of things. Essentially, Idle Skipping is less effective the more that the CPU has to do.&lt;/p&gt;
    &lt;p&gt;Dolphin can't detect all idle loops, and the scope of what it can find is rather limited. We have to find as many idle loops as accurately as possible while also ensuring that we don't invest too much time and resources into finding them. The more complex the heuristic is, the more of an impact it will have on the JIT. As such, some games have annoying idle loops that we know about but are not worth detecting.&lt;/p&gt;
    &lt;p&gt;Need for Speed: Nitro and Rayman Raving Rabbids are two such games with these complex idle loops. After examining their code in detail, SuperSamus realized that their idling behaviors could be modified with a patch that would allow Dolphin to more easily detect and skip them.&lt;/p&gt;
    &lt;p&gt;This results in massive performance boosts, especially in lighter areas, with some menus running at four times as fast. Of course, heavier areas see less of a benefit. We'll have a chart showing some of the raw numbers at the end.&lt;/p&gt;
    &lt;head rend="h5"&gt;Running UncappedÂ¶&lt;/head&gt;
    &lt;p&gt;Dolphin is not a cycle accurate emulator. In fact, Dolphin is fundamentally not designed to be cycle accurate, especially with GPU operations. Dolphin's emulated GPU was designed to be infinitely fast, only being limited by other factors like CPU emulation or the maximum performance of the host device. Nowadays, it has been tamed a bit with synchronization points that provide a rough approximation of the timings of the original command processor, but it is still by no means accurate, let alone cycle accurate. Also, rendering is still infinitely fast, as the only thing that limits it is the speed of your host GPU.&lt;/p&gt;
    &lt;p&gt;And yet, most games run at the correct frame rate, because they limit themselves.&lt;/p&gt;
    &lt;p&gt;The GameCube and Wii were designed for analog TVs, so they used the analog television's sign to start a new frame as a synchronization point called the Vertical Blanking Interupt (VBI). All a game had to do was start a new frame every time it saw a VBI and finish the frame before the next VBI, and it would be perfectly synchronized to the frame rate of the display. That's it. It was simple and efficient, so the vast majority of GameCube and Wii library tie their frame rates to the VBI. Thanks to that, Dolphin's early developers didn't even need to care about how fast the emulated GPU runs; as long Dolphin emits VBIs at the correct frequency, most games will just run at the correct frame rate regardless of what's going on under the hood. And this gives Dolphin bonuses like not emulating GPU slowdown, allowing games that struggled on console to perform much better in Dolphin.&lt;/p&gt;
    &lt;p&gt;But the GameCube and Wii don't have operating systems. Games run on the bare metal and have full control of the machine, so developers could do whatever they wanted. And some games eschew the VBI and run uncapped.&lt;/p&gt;
    &lt;p&gt;Uncapped games break Dolphin's assumptions. They can render way, way too fast. For example, when running Hulk (2003) in Dolphin, it only displays at 60 FPS, but the physics engine could be doing hundreds of steps per second behind the scenes. This is cool because technically a game like this can easily be hacked to run at higher frame rates, but terrible because it hammers people's devices with all kinds of unnecessary work!&lt;/p&gt;
    &lt;p&gt;It gets even worse from here. The physics engine's independence from the output frame rate isn't perfect. If the number of steps per second gets too high, small rounding and math errors start to accumulate, and parts of the game not properly tuned to run at these higher frame rates start to break. This mostly results in dialogue timing issues, but in one stage halfway through the game, it causes a physics calculation issue where a required ledge can't be climbed, essentially softlocking the player.&lt;/p&gt;
    &lt;p&gt;Some other games choose to synchronize to the VBI, but don't bother in incredibly simple scenes where the frame rate doesn't matter. This is most commonly seen with splash screens and loading screens. One such game with this behavior is Bully: Scholarship Edition. Most of the time it is perfectly stable, but because the loading screens are uncapped, it can actually cause the game to randomly hang on transitions. The Simpsons Hit &amp;amp; Run also has this issue, but only during the initial load. While most desktop computers are able to handle the initial load relatively well, Android users have reported tremendous slowdowns where the loading time would take more than 45 seconds.&lt;/p&gt;
    &lt;p&gt;SuperSamus identified these problems and either created patches for these behaviors themselves, or helped others with those titles create patches. Most of these patches are only one or two lines and simply limit the game's frame rate to the VBI frequency. The patches prevent the game from slamming Dolphin's overpowered emulated GPU, greatly increasing performance while fixing issues caused by the games running internally at too high of a frame rate.&lt;/p&gt;
    &lt;p&gt;This comes with a little bonus - since they are now bound to the VBI frequency, you can now use VBI Frequency Override to adjust their frame rate up or down as desired, allowing Dolphin to take advantage of the fact that these games "support" running at higher frame rates.&lt;/p&gt;
    &lt;p&gt;In addition to the games above that had emulation bugs caused by framelimiting, SuperSamus and Billiard also created limiter patches for the following games purely for performance reasons:&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;Somewhat ironically, by slowing down uncapped games we improve their performance in Dolphin, so when turning off Dolphin's framelimiter they go much faster. ...ignore that and use this as a measure of their performance improvement. If a game's frame rate doubled in this chart, then the performance required to run that game at fullspeed has been roughly halved.&lt;/p&gt;
    &lt;p&gt;These numbers don't tell the whole story on some of these games. Hulk (2003) and other games which ran uncapped would get progressively worse performance in Dolphin depending on how light the scene was to render.&lt;/p&gt;
    &lt;p&gt;As a final reminder, these patches should not be considered proper solutions to fixing uncapped games. They are purely to increase playability of these titles.&lt;/p&gt;
    &lt;head rend="h5"&gt;Eggmania: Eggstream MadnessÂ¶&lt;/head&gt;
    &lt;p&gt;The Force Progressive Output patch we included for the Japanese version of this game was causing it to crash on boot. Since we were adding new patches and extrems had already pointed us to a correct version of the patch, we decided to update it alongside all of the other patches.&lt;/p&gt;
    &lt;p&gt;Despite being the Japanese version of a rather obscure game, this crash was somehow reported multiple times by different users. For the two of you out there waiting, the fix is finally here.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-242 - BBA: IPC for BBA Between Multiple Instances of Dolphin on the Same Machine by cristian64Â¶&lt;/head&gt;
    &lt;p&gt;The Broadband Adapter (BBA) for the GameCube was all about connecting games to a network. Whether across the hall with a Local Area Network (LAN) or across the continent with the information superhighway, the BBA brought Nintendo consoles together like nothing before it! Well, except the Modem Adapter, but we're not talking about that today.&lt;/p&gt;
    &lt;p&gt;Dolphin has supported the BBA emulation for many years. An early LLE implementation was fairly accurate, but required the user to setup TAP servers and suffered from performance bottlenecks with said TAP servers depending on the operating system. It wasn't until BBA-HLE in 2022 that BBA emulation became readily accessible to the average user.&lt;/p&gt;
    &lt;p&gt;BBA-HLE is great if you want to connect Dolphin to another computer or real hardware. But if you want to run multiple instances on the same computer, things get more complicated. While it was technically possible through networking trickery, it was far beyond what we'd expect of the average user.&lt;/p&gt;
    &lt;p&gt;cristian64 realized that this problem could be pretty cleanly solved by using a library called &lt;code&gt;cpp-ipc&lt;/code&gt;.  This library would allow separate instances of Dolphin on the same machine to share data easily and efficiently through Inter-Process Communication (IPC).  Instead of using a network stack, we can just simulate the instances of Dolphin being in their very own network and let them communicate without the need for any outside support. &lt;/p&gt;
    &lt;p&gt;With BBA-IPC added, here's a quick rundown of the many options you have for BBA.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Broadband Adapter (TAP): Dolphin's LLE solution for the Broadband Adapter that requires a TAP interface.&lt;/item&gt;
      &lt;item&gt;Broadband Adapter (XLink-Kai): LLE solution that can connect to the Xlink-Kai service to allow players on separate networks to connect together. Success highly depends on each game's latency tolerance and the latency between the players.&lt;/item&gt;
      &lt;item&gt;Broadband Adapter (HLE): HLE solution that hooks the Broadband Adapter up to the host's network interface to connect with other devices on the network or to a server for certain online games.&lt;/item&gt;
      &lt;item&gt;Broadband Adapter (IPC): HLE solution that allows Dolphin instances on the same machine to share memory and communicate directly without the need for a host network.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;BBA-IPC allows for easy testing of BBA features on a single PC, and can also be used in conjunction with game streaming services like Parsec to play BBA titles over the internet without needing to meet the strict latency requirements of emulating the BBA over the internet. This is admittedly a rather niche usecase for BBA, but the feature is relatively compact and easy to maintain.&lt;/p&gt;
    &lt;p&gt;Currently, only Windows and Linux are supported by BBA-IPC, but if there is enough interest, cristian64 has already found another library that could let us support this in other operating systems.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-250 - IP/Top: Make InetAToN async by sepalaniÂ¶&lt;/head&gt;
    &lt;p&gt;Playing Mario Kart Wii online in Dolphin back when WFC support was first added was a rather rough experience. It was functional, but slow and stuttery, just enough to be playable and help players with preserving traffic to the official WFC in the final months before the servers were finally shut down.&lt;/p&gt;
    &lt;p&gt;But that wasn't the end. Thanks to revival efforts, many Wii games still have online communities, with Mario Kart Wii being quite possibly the biggest. In the years since, Dolphin's Wi-Fi emulation has gotten to the point that users can play alongside real Wiis in most games without any issues.&lt;/p&gt;
    &lt;p&gt;Well, most users. Unfortunately, even in modern builds of Dolphin there were a couple of users having severe stuttering and freezing problems, and all of them were using Android devices. These problems were handwaved away as typical Android performance issues at first, but after closer examination, it was obvious that there was something else going wrong. One user recorded us tons of examples and helped narrow down what was happening.&lt;/p&gt;
    &lt;p&gt;They (accurately!) surmized that it had something to do with a player joining or leaving the online lobby. In Mario Kart Wii, players can join or leave a race mid-match, with new players spectating until the next race began. The only mystery left was figuring out why this was only happening to a couple of users while everyone else was fine.&lt;/p&gt;
    &lt;p&gt;Using their wealth of knowledge from working on the Monster Hunter Tri replacement Wi-Fi servers, sepalani jumped in and investigated the issue. Same as us, they couldn't find any issues at first. They were able to play without any kind of freezing, even on their phone. However, after unlocking the frame rate on a desktop computer, sepalani noticed a small hitch when the function &lt;code&gt;InetAToN&lt;/code&gt; was called.  This hitch was impossible to see when running at normal speed, but when running at 1000%+ speed, the dip was just barely noticeable.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;InetAToN&lt;/code&gt; is a standard networking function that takes an IP address string and converts it into its equivalent binary form. For example, the string &lt;code&gt;192.51.100.50&lt;/code&gt; would be transformed into the hexadecimal number &lt;code&gt;0xC0336432&lt;/code&gt;. On the Wii, &lt;code&gt;InetAToN&lt;/code&gt; has some additional functionality that is unusual: in addition to text-based IPs, it also accepts hostnames as inputs. This means that a developer can choose to pass a hostname like &lt;code&gt;google.com&lt;/code&gt; into &lt;code&gt;InetAToN&lt;/code&gt;, and the function will perform a Domain Name System (DNS) lookup to resolve the hostname into an IP address. &lt;/p&gt;
    &lt;p&gt;sepalani figured out that if a hostname was provided to &lt;code&gt;InetAToN&lt;/code&gt; and the resulting DNS lookup was slow enough, the function would cause a stutter because Dolphin waits for the result of the lookup before continuing. The time it takes for a DNS lookup to finish varies depending on various factors, such as the user's internet connection. On a desktop PC connected to home internet, the lookup would complete before the user even saw a frame drop. But many of our Android users are connected to the internet via cellular data, which can have particularly poor latency depending on signal strength and network congestion.&lt;/p&gt;
    &lt;p&gt;Therefore, sepalani changed &lt;code&gt;InetAToN&lt;/code&gt; to be non-blocking so that DNS resolution can take as long as it wants without locking up the emulator.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-481 - SDIO: Fix CSD/CID emulation by Naim2000Â¶&lt;/head&gt;
    &lt;p&gt;There's no way to sugarcoat this one. This was a pretty bad %$#&amp;amp; up. Dolphin's SD card emulation was broken, and has been broken for a very long time. Yet somehow, it worked. This is one of the dangers of emulation - sometimes you can do something very wrong yet the software just trudges on.&lt;/p&gt;
    &lt;p&gt;The modern Wii homebrew scene lives off of SD Cards. It's a convenient tool available on most Wiis, and can be used in conjunction with the Homebrew Channel, BootMii, and other essential homebrew. It's not uncommon to see a 32GB SD card in a Wii loaded with homebrew emulators, software, and game mods.&lt;/p&gt;
    &lt;p&gt;One oddity about the Wii is that it was released without support for the then new SDHC standard (2GB to 32GB SD cards). This would be rectified in an update three years later, but the damage was done. Thanks to the way Nintendo designed the Wii's software stack, games released prior to SDHC support being added would be forced to use older IOSes that lacked SDHC support. Even if your System Menu, homebrew, and newer games worked with your big SD card, a game like Super Smash Bros. Brawl wouldn't. At least without some help.&lt;/p&gt;
    &lt;p&gt;The Brawl community refused to be restricted by Nintendo's paltry limitations. They used homebrew to load the game with newer IOS versions and even patched the game to remove the nonsensical 3 minute time limit on replays. Small patches like these were just the beginning, as the community started making bigger changes to the game, like balance patches Brawl+ and Brawl-, and eventually full game overhauls like Project M and its offspring.&lt;/p&gt;
    &lt;p&gt;The Smash Bros. community is still pushing the limits of homebrew on both the Wii and Dolphin. One such effort is Super Smash REX. REX has an astounding amount of stages, music, and characters to the point that just the base mod is over 8GB in size. And that's where we come into all of this.&lt;/p&gt;
    &lt;p&gt;A developer from REX reached out to us about how they were reaching some kind of limit with the virtual SD card in Dolphin. Once the amount of data on the SD card exceeded 10.7GiB, Dolphin's SD card support would completely fall apart.&lt;/p&gt;
    &lt;p&gt;This actually wasn't too surprising. There have been scattered reports from Rock Band 3 and Just Dance failing when too much DLC was installed to the SD card. However, reproducing those issues required owning a mountain of DLC, which none of us did. With REX, everything was readily available and the actual launcher was just a homebrew application. This made reproducing the issue much easier, and they did most of the work for us.&lt;/p&gt;
    &lt;p&gt;The key detail was that the files on the SD card didn't even have to relate to the mod. We could just fill it with cat pictures, load up the Homebrew Channel or any other homebrew that relied on the SD card, and watch the fireworks. What could be going wrong?&lt;/p&gt;
    &lt;p&gt;In a community as old as the GameCube/Wii scene, there are some voices that must be heeded. Before the REX developers reached out to us, one of the Supreme GameCube/Wii Sages, extrems, hadst been prognosticating doom since the new year if a bug with the card ID (CID) and card-specific data (CSD) registers in our SD card emulation was not mended. Verily, it came to pass.&lt;/p&gt;
    &lt;p&gt;The problem was extremely straightforward. When the emulated Wii queried the virtual SD card for its capabilities, such as size and speed, Dolphin would return complete garbage due to the reports being in the wrong byte order. The strange part of this was that SD card emulation even worked at all.&lt;/p&gt;
    &lt;p&gt;When REX reported there were SD card issues, we quickly thought of the flaws that extrems pointed out to us. However, knowing the problem and fixing it were two very different things. Our attempts to make things right only made things worse. Two different developers took a stab at it, and both left SD card emulation completely non-functional. We were left defeated and efforts on the problem slowed.&lt;/p&gt;
    &lt;p&gt;In mid-November, Billiard was perusing &lt;del&gt;Pull Requests&lt;/del&gt; ancient tomes of knowledge that fell through the cracks. One such tome was named "SDIO: report write lock status". Emulating a SD card's write lock switch was a rather unimportant implementation detail that would not affect emulation. As such, there was no rush to review it. But when Billiard did finally get to reviewing it, he saw that it also fixed Dolphin's CID and CSD byte ordering.&lt;/p&gt;
    &lt;p&gt;A few quick reviews and a rebase later, and the bug was finally quelled. Now Dolphin properly works with virtual SD cards up to 32GB in size.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-542 - USB: Emulated Support for Logitech Microphone for Wii by BiendeoÂ¶&lt;/head&gt;
    &lt;p&gt;The Logitech Microphone is an iconic accessory for the Nintendo Wii. Roughly 100 games, including popular titles in the Guitar Hero and Rock Band series, support the peripheral.&lt;/p&gt;
    &lt;p&gt;Dolphin has had support for the physical Logitech Microphone via USB Passthrough for years, but even as other USB peripherals received their emulated counterparts, those wanting to sing into an emulated Wii using generic microphones had to wait. Even the maligned Wii Speak received support before the Logitech Microphone, despite the fact that it supported far fewer games and was much more complicated to implement. This is just how emulation works sometimes. The more complicated, less useful accessory was just far more interesting than the popular, yet generic accessory.&lt;/p&gt;
    &lt;p&gt;But the foundation created for emulating the Wii Speak did lend itself well toward implementing a second microphone accessory in Dolphin. After all, the Wii Speak was a microphone, so a few people took shots at adapting the Wii Speak code to work with the Logitech Microphone.&lt;/p&gt;
    &lt;p&gt;First, supermilkdude67 posted a WIP fork with very basic support that fizzled out. A few months later, a certain announcement brought renewed interest toward making the many singing games more accessible to users. Biendeo took over the mantle using the initial fork as a base. With some help from veteran Dolphin developers, a few fixes, and some upgrades to the GUI, it was ready to go.&lt;/p&gt;
    &lt;p&gt;You can now emulate the Logitech Microphone with any standard PC microphone! The exact volume levels might need to be adjusted depending on the input source, so make sure you properly calibrate before your first jam session. Given that this is a new feature, compatiblity isn't perfect, and some games may take more fiddling than others.&lt;/p&gt;
    &lt;p&gt;For our Android users, things aren't ready yet. While the core feature should be mostly compatible between the two environments, it will need a completely different GUI. As such, it might be a while before everything gets ported over to our Android builds.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-406 - On-Screen Display: Add New Default Font by TryTwoÂ¶&lt;/head&gt;
    &lt;p&gt;Dolphin's On-Screen Display is an important part of communicating with users, whether it's statistics, performance metrics, or notifications from features like RetroAchievements. Unfortunately, the pixel font we were using could be hard to read, especially for some users with HiDPI screens. TryTwo improved the situation by adding the ability to change the font size of on-screen display messages, but this didn't solve the problem - making a pixel font larger can look quite bad, especially at non-integer scales. Dolphin needed a new font that could scale to arbitrary resolutions while still looking clear.&lt;/p&gt;
    &lt;p&gt;With this change, Dolphin's OSD now uses a proper vector font!&lt;/p&gt;
    &lt;p&gt;Vera Sans Mono is the new default font. We think that in pretty much every scenario, it's easier to read than our old font. However, TryTwo figured that since we were adding a font anyway, that Dolphin could just provide the ability for users to override the font. So if you're unsatisfied with our typography tastes, add the font of your choice to the "Load" folder of your User directory and name it "OSD_Font.ttf". Any TrueType font will work!&lt;/p&gt;
    &lt;p&gt;Now that the On-Screen Display has even more options, we've decided to consolidate them within their own config section. So if you're looking to adjust what is displayed, font size, or if you want them disabled altogether, the settings can now be found in one place within the On-Screen Display section of the Configuration window.&lt;/p&gt;
    &lt;head rend="h4"&gt;2509-554 - AX-HLE: Fix Low Pass Filter Edge Case by flacsÂ¶&lt;/head&gt;
    &lt;p&gt;If you were an arcade junkie in the late 90s and early 2000s, then you're probably familiar with the Midway classic NFL Blitz. Authentic teams thrust into a deliberately inaccurate simulation with colorful gameplay and flashy graphics made the series a bombastic hit in arcades. And of course, the blisteringly difficult AI that would absolutely cheat drained quarters from avid players, making it enticing for arcade owners as well.&lt;/p&gt;
    &lt;p&gt;In this, we're not talking about beloved or hated arcade games, but instead the home console exclusive NFL Blitz Pro. This attempt to adapt to the console landscape was a commercial failure that lacked the charm and personality of the earlier titles. And we can confirm the popularity thing - this title had broken audio by default in Dolphin for over four years with no one making a formal bug report and only two forgotten comments throughout our community.&lt;/p&gt;
    &lt;p&gt;It wasn't until Billiard was testing games to see if they worked with Immediately Present XFB that we became aware that the game's sound was broken.&lt;/p&gt;
    &lt;p&gt;After doing some quick testing, Billiard realized that DSP-LLE resolved the issue, and with no further leads he made a setting adjustment and disabled HLE audio for this game by default in 2509-551.&lt;/p&gt;
    &lt;p&gt;The very next day, flacs saw the audio regression, found what build broke it, figured out why it was broken, and fixed the issue. NFL Blitz Pro is another game that uses the low-pass filter. In Dolphin, the low-pass filter was notoriously broken and left completely disabled for many, many years. During the process in which the feature was finally fixed and re-enabled, no one thought to test this game. If we had, we would have noticed that it hit an edge-case in the HLE implementation of the low-pass filter.&lt;/p&gt;
    &lt;p&gt;When the game reserves a region of memory, its memory allocator sets all bytes within the region to &lt;code&gt;0xAB&lt;/code&gt;.  This behavior isn't necessarily abnormal, as the initial state of the memory shouldn't matter. When using freshly allocated memory, it is best practice to first initialize it with sane default values before attempting to use it. Unfortunately, the developers of NFL Blitz Pro forgot to perfom this initialization when reserving memory for the game's audio engine. The MusyX library determines if the low-pass filter is enabled by checking if the appropriate bytes within its assigned memory region are not zero.  Because &lt;code&gt;0xAB&lt;/code&gt; is not zero, the library assumes that the low-pass filter should be enabled.&lt;/p&gt;
    &lt;p&gt;Because most audio related memory is still in the default state of &lt;code&gt;0xAB&lt;/code&gt;, the two low pass filter coefficients are also set to &lt;code&gt;0xABAB&lt;/code&gt;.  When DSP-HLE goes to calculate how much the low-pass filter should quiet or amplify things, it adds these values together.  For our purposes, the values are interpreted by the game as 16-bit fixed point values, so the coefficients would be roughly &lt;code&gt;1.341156&lt;/code&gt;.  These two values added together are supposed to add up to about &lt;code&gt;1.0&lt;/code&gt;, but in this case the result is roughly &lt;code&gt;2.682312&lt;/code&gt;.  DSP-HLE sees this number and boosts the volume accordingly, making things sound rather unpleasant.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;The programmers were using uninitialized memory by accident, which is a game bug. Regardless of their intent, these were the values that the game used. So why was Dolphin broken? flacs figured out that the second filter value is actually a signed value. For a typical 16-bit fixed point value, this means positive values are &lt;code&gt;0x0000&lt;/code&gt; to &lt;code&gt;0x7FFF&lt;/code&gt;, and negative values are &lt;code&gt;0x8000&lt;/code&gt; to &lt;code&gt;0xFFFF&lt;/code&gt;.  &lt;code&gt;0xABAB&lt;/code&gt; is supposed to be interpreted as a negative value.&lt;/p&gt;
    &lt;p&gt;With the bug fixed, the equation changes to &lt;code&gt;1.34 + (-0.66)&lt;/code&gt;, giving us a coefficient sum of roughly &lt;code&gt;0.68&lt;/code&gt;.  The filter is still active and now lowering the volume of the game, but this is accurate to real hardware. It seems that the developers worked around the filter's unintentional activation by just making the game louder to compensate.  By handling these uninitialized values correctly, DSP-HLE now produces proper audio in this title.&lt;/p&gt;
    &lt;p/&gt;
    &lt;head rend="h3"&gt;This Release's Contributors...Â¶&lt;/head&gt;
    &lt;p&gt;Special thanks to all of the contributors that incremented Dolphin by 585 commits after Release 2509!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dolphin-emu.org/blog/2025/12/22/dolphin-progress-report-release-2512/"/><published>2025-12-28T21:57:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415129</id><title>Researchers Discover Molecular Difference in Autistic Brains</title><updated>2025-12-29T03:04:01.204400+00:00</updated><content>&lt;doc fingerprint="f7fe1347089b1bdd"&gt;
  &lt;main&gt;
    &lt;p&gt;Yale School of Medicine (YSM) scientists have discovered a molecular difference in the brains of autistic people compared to their neurotypical counterparts.&lt;/p&gt;
    &lt;p&gt;Autism is a neurodevelopmental condition associated with behavioral differences including difficulties with social interaction, restrictive or intense interests, and repetitive movements or speech. But itâ€™s not clear what makes autistic brains different.&lt;/p&gt;
    &lt;p&gt;Now, a new study in The American Journal of Psychiatry has found that brains of autistic people have fewer of a specific kind of receptor for glutamate, the most common excitatory neurotransmitter in the brain. The reduced availability of these receptors may be associated with various characteristics linked to autism.&lt;/p&gt;
    &lt;p&gt;â€œWe have found this really important, never-before-understood difference in autism that is meaningful, has implications for intervention, and can help us understand autism in a more concrete way than we ever have before,â€ says James McPartland, PhD, Harris Professor of Child Psychiatry and Psychology in the Child Study Center at YSM and the studyâ€™s co-principal investigator.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medicine.yale.edu/news-article/molecular-difference-in-autistic-brains/"/><published>2025-12-28T22:23:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415225</id><title>What an unprocessed photo looks like</title><updated>2025-12-29T03:04:00.623849+00:00</updated><content>&lt;doc fingerprint="e049e655b7503a7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;What an unprocessed photo looks like:&lt;/head&gt;(Photography)&lt;p&gt;Hereâ€™s a photo of a Christmas tree, as my cameraâ€™s sensor sees it:&lt;/p&gt;&lt;p&gt;Itâ€™s not even black-and-white, itâ€™s gray-and-gray. This is becuase while the ADCâ€™s output can theoretically go from 0 to 16382, the actual data doesnâ€™t cover that whole range:&lt;/p&gt;&lt;p&gt;The real range of ADC values is ~2110 to ~136000. Letâ€™s set those values as the white and black in the image:&lt;/p&gt;&lt;p&gt;Vnew = (Vold - Black)/(White - Black)&lt;/p&gt;&lt;p&gt;Much better, but itâ€™s still more monochromatic then I remember the tree being. Camera sensors arenâ€™t actually able to see color: They only measure how much light hit each pixel.&lt;/p&gt;&lt;p&gt;In a color camera, the sensor is covered by a grid of alternating color filters:&lt;/p&gt;&lt;p&gt;Letâ€™s color each pixel the same as the filter itâ€™s looking through:&lt;/p&gt;&lt;p&gt;This version is more colorful, but each pixel only has one third of itâ€™s RGB color. To fix this, I just averaged the values each pixel with itâ€™s neighbors:&lt;/p&gt;&lt;p&gt;Applying this process to the whole photo gives the lights some color:&lt;/p&gt;&lt;p&gt;However, the image is still very dark. This is because monitors donâ€™t have as much dynamic range as the human eye, or a camera sensor: Even if you are using an OLED, the screen still has some ambient light reflecting off of it and limiting how black it can get.&lt;/p&gt;&lt;p&gt;Thereâ€™s also another, sneaker factor causing this:&lt;/p&gt;&lt;p&gt;Our perception of brightness is non-linear.&lt;/p&gt;&lt;p&gt;If brightness values are quantized, most of the ADC bins will be wasted on nearly identical shades of white while every other tone is crammed into the bottom. Because this is an inefficient use of memory, most color spaces assign extra bins to darker colors:&lt;/p&gt;&lt;p&gt;As a result of this, if the linear data is displayed directly, it will appear much darker then it should be.&lt;/p&gt;&lt;p&gt;Both problems can be solved by applying a non-linear curve to each color channel to brighten up the dark areasâ€¦ but this doesnâ€™t quite work out:&lt;/p&gt;&lt;p&gt;Some of this green cast is caused by the camera sensor being intrinsically more sensitive to green light, but some of it is my fault: There are twice as many green pixels in the filter matrix. When combined with my rather naive demosaicing, this resulted in the green channel being boosted even higher.&lt;/p&gt;&lt;p&gt;In either case, it can fixed with proper white-balance: Equalize the channels by multiply each one with a constant.&lt;/p&gt;&lt;p&gt;However, because the image is now non-linear, I have to go back a step to do this. Hereâ€™s the dark image from before with all the values temporarily scaled up so I can see the problem:&lt;/p&gt;&lt;p&gt;â€¦ hereâ€™s that image with the green taken down to mach the other channels:&lt;/p&gt;&lt;p&gt;â€¦ and after re-applying the curve:&lt;/p&gt;&lt;p&gt;This is really just the bare minimum: I havenâ€™t done any color calibration, the white balance isnâ€™t perfect, thereâ€™s lots of noise that needs to be cleaned upâ€¦&lt;/p&gt;&lt;p&gt;Additionally, applying the curve to each color channel accidentally desaturated the highlights. This effect looks rather good â€” and is what weâ€™ve come to expect from film â€” but itâ€™s has de-yellowed the star. Itâ€™s possible to separate the luminance and curve it while preserving color. On itâ€™s own, this would make the LED Christmas lights into an overstaturated mess, but combining both methods can produce nice results.&lt;/p&gt;&lt;p&gt;For comparison, hereâ€™s the image my camera produced from the same data:&lt;/p&gt;&lt;p&gt;Far from being an â€œuneditedâ€ photo: thereâ€™s a huge amount of math thatâ€™s gone into making an image that nicely represents what the subject looks like in person.&lt;/p&gt;&lt;p&gt;Thereâ€™s nothing that happens when you adjust the contrast or white balance in editing software that the camera hasnâ€™t done under the hood. The edited image isnâ€™t â€œfakerâ€ then the original: they are different renditions of the same data.&lt;/p&gt;&lt;p&gt;In the end, replicating human perception is hard, and itâ€™s made harder when constrained to the limitations of display technology or printed images. Thereâ€™s nothing wrong with tweaking the image when the automated algorithms make the wrong call.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maurycyz.com/misc/raw_photo/"/><published>2025-12-28T22:35:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415426</id><title>62 years in the making: NYC's newest water tunnel nears the finish line</title><updated>2025-12-29T03:04:00.083271+00:00</updated><content>&lt;doc fingerprint="aac0a95e8b65c6b6"&gt;
  &lt;main&gt;
    &lt;p&gt;Turn on the tap, and water flows without a second thought. But deep beneath New York City, hundreds of feet below street level, workers are finishing a project thatâ€™s been under construction for more than half a century â€” a massive water tunnel that will help keep that simple act possible for generations to come.&lt;/p&gt;
    &lt;p&gt;Tunnel No. 3, as itâ€™s known, is one of the most ambitious infrastructure projects in the cityâ€™s history.&lt;/p&gt;
    &lt;p&gt;When complete, it will ensure New Yorkers continue to receive clean water from upstate reservoirs â€” some more than 125 miles away â€” while allowing long-overdue maintenance on the cityâ€™s two older tunnels, built in 1917 and 1936.&lt;/p&gt;
    &lt;p&gt;City Department of Environmental Protection Commissioner Rohit Aggarwala and DEP Portfolio Manager Lauren Dâ€™Attile recently took an elevator nearly 800 feet down to see the progress for themselves.&lt;/p&gt;
    &lt;p&gt;â€œItâ€™s not quite as far down as the Empire State Building is tall, but itâ€™s getting there,â€ Aggarwala said during the 10-minute descent.&lt;/p&gt;
    &lt;p&gt;Down below, flashlights cut through the darkness as water dripped from the rock walls. Workers stood in waterproof boots along the cool, damp concrete â€” the result of decades of digging, drilling and sealing off bare rock to create a watertight tunnel system.&lt;/p&gt;
    &lt;p&gt;â€œWhen this tunnel was originally constructed, it was built by a tunnel boring machine, which is a very large piece of equipment with cutter heads on the front,â€ said Dâ€™Attile. â€œWe drill the tunnel and after that we line that bare rock with a couple of feet of concrete â€” so thatâ€™s what youâ€™re seeing now, because this tunnel is complete.â€&lt;/p&gt;
    &lt;p&gt;Construction on Tunnel No. 3 began in 1970.&lt;/p&gt;
    &lt;p&gt;The Bronx and Manhattan already receive water from it, and the final phase â€” extending service to Brooklyn and Queens â€” is expected to be completed by 2032.&lt;/p&gt;
    &lt;p&gt;â€œThe project started in 1970, it will be finished in 2032 â€” thatâ€™s 62 years to build this thing,â€ Aggarwala said. â€œBut a project like this is going to serve New York for two, three hundred years, who knows how much longer than that. Seems worth it. Totally worth it. Itâ€™s what makes the city work because we are constantly investing in our future.â€&lt;/p&gt;
    &lt;p&gt;When itâ€™s complete, the DEP will finally be able to take the older tunnels offline for repairs â€” a step city engineers have waited decades to take.&lt;/p&gt;
    &lt;p&gt;Above ground, New Yorkers will keep turning on their faucets, washing dishes, and filling glasses â€” rarely thinking about the billion gallons of water flowing through the underground arteries that make city life possible.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ny1.com/nyc/all-boroughs/news/2025/11/09/water--dep--tunnels-"/><published>2025-12-28T23:05:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415448</id><title>Slaughtering Competition Problems with Quantifier Elimination (2021)</title><updated>2025-12-29T03:04:00.012790+00:00</updated><content>&lt;doc fingerprint="747111628645eb5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Slaughtering Competition Problems with Quantifier Elimination&lt;/head&gt;&lt;head rend="h3"&gt;22 Dec 2021 - Tags: sage , featured&lt;/head&gt;&lt;p&gt;Anytime I see questions on mse that ask something â€œsimpleâ€, I feel a powerful urge to chime in with â€œa computer can do this for you!â€. Obviously if youâ€™re a researching mathematician you shouldnâ€™t waste your time with something a computer can do for you, but when youâ€™re still learning techniques (or, as is frequently the case on mse, solving homework problems), itâ€™s not a particularly useful comment (so I usually abstain). The urge is particularly powerful when it comes to the contrived inequalities that show up in a lot of competition math, and today I saw a question that really made me want to say something about this! I still feel like it would be a bit inappropriate for mse, but thankfully I have a blog where I can talk about whatever I please :P So today, letâ€™s see how to hit these problems with the proverbial nuke that is quantifier elimination!&lt;/p&gt;&lt;p&gt;I want this to be a fairly quick post, so I wonâ€™t go into too much detail. The gist is the following powerful theorem from model theory:&lt;/p&gt;&lt;p&gt;Tarski-Seidenberg Theorem1&lt;/p&gt;&lt;p&gt;If $\varphi$ is any formula of the form&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;$p(\overline{x}) = 0$, for $p \in \mathbb{R}[\overline{x}]$&lt;/item&gt;&lt;item&gt;$p(\overline{x}) \lt 0$, for $p \in \mathbb{R}[\overline{x}]$&lt;/item&gt;&lt;item&gt;combinations of the above using $\lor$, $\land$, $\lnot$, $\to$&lt;/item&gt;&lt;item&gt;combinations of the above using $\exists$ and $\forall$&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Then $\varphi$ is equivalent to a formula without quantifiers.&lt;/p&gt;&lt;p&gt;Iâ€™m legally required to give the following example:&lt;/p&gt;&lt;p&gt;The formula $\exists x . a x^2 + bx + c = 0$ (which has a quantifier) is equivalent to the formula $b^2 - 4ac \geq 0$&lt;/p&gt;&lt;p&gt;As a more complicated example, we have&lt;/p&gt;\[\forall x . \exists y . (x &amp;gt; 0 \to ax + by + xy &amp;gt; c)\]&lt;p&gt;is equivalent to&lt;/p&gt;\[b \geq 0 \ \lor \ c + ab \lt 0\]&lt;p&gt;Of course, this means if we want to know whether the above formula really is true for some choice of $a,b,c \in \mathbb{R}$, we can just plug into this quantifier free formula and check!&lt;/p&gt;&lt;p&gt;Now, you might be wondering: â€œHow did you find this quantifier free expression?â€, and the answer is, of course, sage! Sage has interfaces with a lot of pre-existing software, and for us the relevant interface is to QEPCAD, which will actually do quantifier elimination for us!&lt;/p&gt;&lt;p&gt;To get started, you have to make sure you have qepcad installed in a way that sage can access. Youâ€™ll want to run &lt;code&gt;sage -i qepcad&lt;/code&gt; just in case
(it wasnâ€™t installed for me).&lt;/p&gt;&lt;p&gt;Next, letâ€™s see how we eliminated quantifiers from the â€œmore complicted exampleâ€ above!&lt;/p&gt;&lt;p&gt;Yup. Itâ€™s that easy!&lt;/p&gt;&lt;p&gt;If youâ€™re interested in reading more about this, you should check out the documentation, but Iâ€™m also going to give a handful of examples in the next section2!&lt;/p&gt;&lt;p&gt;So then, letâ€™s slaughter some competition problems3!&lt;/p&gt;&lt;p&gt;First, the problem that made me write this post in the first place (here is the mse link again)&lt;/p&gt;&lt;p&gt;Let $a,b \geq 0$ with $a^4 + b^4 = 17$.&lt;/p&gt;&lt;p&gt;Prove $15(a+b) \geq 17 + 14 \sqrt{2ab}$&lt;/p&gt;&lt;p&gt;This isnâ€™t given to us as polynomials, but of course itâ€™s easy for us to fix that by rewriting it as&lt;/p&gt;\[(15(a+b) - 17)^2 \geq 14^2 \cdot 2ab\]&lt;p&gt;then we simply ask sage4:&lt;/p&gt;&lt;p&gt;We can extend this too. The asker conjectures that $(1,2)$ and $(2,1)$ are the only choices of $(a,b)$ for which we get equality. As a bonus, we can check this:&lt;/p&gt;&lt;p&gt;So we see that these really are the only points where equality holds!&lt;/p&gt;&lt;p&gt;Letâ€™s take another example I remember seeing recently (the original mse link is here):&lt;/p&gt;&lt;p&gt;Let $x,y,z$ be positive real numbers. Show&lt;/p&gt;&lt;p&gt;\(\left ( x + \frac{1}{x} \right ) \left ( y + \frac{1}{y} \right ) \left ( z + \frac{1}{z} \right ) \geq \left ( x + \frac{1}{y} \right ) \left ( y + \frac{1}{z} \right ) \left ( z + \frac{1}{x} \right )\)&lt;/p&gt;&lt;p&gt;Again, we cannot plug this into sage directly, because itâ€™s not a polynomial inequality. But multiplying through by $xyz$ on both sides solves that issue.&lt;/p&gt;&lt;p&gt;and even though the asker doesnâ€™t mention it, one thing that Steele makes very clear in the (excellent) book The Cauchy-Schwarz Masterclass is that whenever working with a new inequality, we should ask where itâ€™s sharp.&lt;/p&gt;&lt;p&gt;So we ask sage!&lt;/p&gt;&lt;p&gt;It turns out this inequality is sharp at infinitely many points, so instead of asking for the list of all points, we ask for a geometric description of the solution set.&lt;/p&gt;&lt;p&gt;Now, this admits some simplification, since we know that $x = y$ by the second line. Iâ€™ll leave it to you to figure out exactly what set this is if youâ€™re interested.&lt;/p&gt;&lt;p&gt;As an exercise, you should be on the lookout for places to use this tool!&lt;/p&gt;&lt;p&gt;Next time somebody is asking about some wacky inequality, or really any question about sets definable by polynomial (in)equations in $\mathbb{R}^n$, you should think about whether you can slaughter the problem without much thought by asking a computer!&lt;/p&gt;&lt;p&gt;As a more concrete exercise to show the flexibility of this method, pick your favorite theorem in euclidean geometry. Rephrase it using coordinates, then ask sage if itâ€™s true!&lt;/p&gt;&lt;p&gt;As a very concrete exercise, can you do this with Ptolemyâ€™s Theorem?&lt;/p&gt;&lt;p&gt;Also, if you find yourself using this, definitely come back and let me know! I would love to hear about places where this comes up in the wild!&lt;/p&gt;&lt;p&gt;Also also, if you have other (possibly surprising) uses for sage or other programs that automatically answer ceretain problems, definitely let me know! This is one of the parts of mathematical logic that I get most geeky about!&lt;/p&gt;&lt;p&gt;See you next time ^_^&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;As a cute thought exercise, you should try to provide geometric meaning to this claim. Itâ€™s telling us that if you take the solution set of polynomial inequations, then project from $\mathbb{R}^{n+m}$ down to $\mathbb{R}^n$, the resulting set is still definable by polynomial inequations!&lt;/p&gt;&lt;p&gt;This should sound somewhat miraculous, and itâ€™s worth trying out some&lt;/p&gt;&lt;p&gt;Thankfully, by the end of the post, youâ€™ll have all the tools you need in order to work out some examples on your own ^_^. â†©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;In fact, there are $\sim \star \sim$ bonus quantifiers $\sim \star \sim$ built into QEPCAD! For instance, we can ask for&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;â€œthere exist exactly 5 $x$ so that $\varphi(x)$â€ (and obviously thereâ€™s nothing special about $5$)&lt;/item&gt;&lt;item&gt;â€œthere exist infinitely many $x$ so that $\varphi(x)$â€&lt;/item&gt;&lt;item&gt;â€œthe set of $x$ so that $\varphi(x)$ is a connected setâ€&lt;/item&gt;&lt;/list&gt;&lt;p&gt;and while these arenâ€™t going to be useful for the purposes of this post, I still wanted to mention them! â†©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I know that Iâ€™m currently treating this like a kind of party trick, but being able to ask a computer whether an implication between polynomial inequalities is true (and being able to find a counterexample if it isnâ€™t) is super useful in practice! In fact, AndrÃ© Platzer at CMU crucially uses this machinery in order to automatically prove that robots will not bump into each other (etc.). See, for instance, his book Logical Foundations of Cyber-Physical Systems, as well as the accompanying lectures on youtube. â†©&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;For some reason typing this out wasnâ€™t working for me, but using the constructors directly got things goingâ€¦ Thereâ€™s probably something to do with the parsing that I donâ€™t understand, and this isnâ€™t too much of a hassle! â†©&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://grossack.site/2021/12/22/qe-competition.html"/><published>2025-12-28T23:10:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415458</id><title>Spherical Cow</title><updated>2025-12-29T03:03:59.766623+00:00</updated><content/><link href="https://lib.rs/crates/spherical-cow"/><published>2025-12-28T23:11:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415522</id><title>How to Complain (2024)</title><updated>2025-12-29T03:03:59.553654+00:00</updated><content>&lt;doc fingerprint="676bdb193ae38898"&gt;
  &lt;main&gt;
    &lt;quote&gt;Foo is bad, and bar is better; here is why ...&lt;/quote&gt;
    &lt;p&gt;Or, at least, be very careful about writing such things.&lt;/p&gt;
    &lt;p&gt;Why? Because inevitably, somebody will respond: â€˜wait, I was confused, but I think Iâ€™ve figured it out: what youâ€™re calling a â€œbarâ€ I know as a â€œfrobnicated fooâ€â€™.&lt;/p&gt;
    &lt;p&gt;A frobnicated foo is obviously a type of foo. So writing things like that alienates a core part of your audience: the people who have strong opinions on frobnicated foos and thing theyâ€™re great. That is, the people who agree with you. But they will be put off when they read that foos are bad, and it will be difficult to win them back.&lt;/p&gt;
    &lt;quote&gt;Often, when people try to solve a problem, they employ a particular approach. This approach is prone to problems; here is why an alternate approach does not run into those problems.&lt;/quote&gt;
    &lt;p&gt;Names are difficult, and people frequently disagree on their meanings. Replace pesky names with descriptions.&lt;/p&gt;
    &lt;p&gt;And absolute statements (â€˜foo is always better than barâ€™) are quite strong, and require an equally strong defense. Itâ€™s not necessary to explicitly state an absolute, even if you think it holds. â€˜It might be better to use bar than foo sometimesâ€™ is easier to defend than â€˜bar is better than fooâ€™, and itâ€™s usually more true.&lt;/p&gt;
    &lt;p&gt;If somebody already knows what a foo is, isnâ€™t it redundant, even patronising, to make them read a description of the problems foo solves and how it solves them? It can be, but it doesnâ€™t have to be. The purpose of a description in this case isnâ€™t just to be a definition-in-place-of-a-name. Itâ€™s to frame the problem, in a way that sets up the rest of your argument, and helps people avoid preconceptions they may have about related names. Your argument should be made in reference to your specific framing of the problem, not just in reference to the things that you expect people to know about foos.&lt;/p&gt;
    &lt;p&gt;Providing context to your argument also means that it can be read and understood by more people, making it more accessible.&lt;/p&gt;
    &lt;p&gt;Simply spewing negativity into the void is not a good enough reason to publish a complaint. There is enough negativity in the world as is. A complaint should have a good reason for existing. In particular, if that reason is to convince people that they should agree with you, then an overly acerbic tone may be unhelpful. And empathy always helps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://outerproduct.net/trivial/2024-03-25_complain.html"/><published>2025-12-28T23:23:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415570</id><title>Fast Cvvdp Implementation in C</title><updated>2025-12-29T03:03:59.048994+00:00</updated><content>&lt;doc fingerprint="7636b6ae2b57b990"&gt;
  &lt;main&gt;
    &lt;p&gt;A fast C implementation of the CVVDP metric (arXiv) from the University of Cambridge. More information about how CVVDP works according to this implementation is provided here.&lt;/p&gt;
    &lt;p&gt;Benchmarked using &lt;code&gt;poop&lt;/code&gt; on Linux, Core i7
13700k. Note that fcvvdp runs with one CPU thread here while cvvdp uses multiple
threads. This is a current limitation of fcvvdp, which does not yet support
multithreading.&lt;/p&gt;
    &lt;code&gt;poop "cvvdp -r fm360p.y4m -t fm360p_x264.y4m --display standard_fhd" "./fcvvdp -m fhd fm360p.y4m fm360p_x264.y4m"
Benchmark 1 (3 runs): cvvdp -r fm360p.y4m -t fm360p_x264.y4m --display standard_fhd
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          19.6s  Â±  568ms    19.2s  â€¦ 20.2s           0 ( 0%)        0%
  peak_rss           1.00GB Â± 28.1MB     979MB â€¦ 1.03GB          0 ( 0%)        0%
  cpu_cycles          747G  Â± 8.54G      741G  â€¦  757G           0 ( 0%)        0%
  instructions        362G  Â± 1.20G      361G  â€¦  363G           0 ( 0%)        0%
  cache_references   2.77G  Â± 46.9M     2.71G  â€¦ 2.81G           0 ( 0%)        0%
  cache_misses        899M  Â± 11.7M      890M  â€¦  912M           0 ( 0%)        0%
  branch_misses       107M  Â± 1.80M      105M  â€¦  109M           0 ( 0%)        0%
Benchmark 2 (3 runs): ./fcvvdp -m fhd fm360p.y4m fm360p_x264.y4m
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          16.1s  Â± 56.2ms    16.0s  â€¦ 16.1s           0 ( 0%)        âš¡- 17.9% Â±  4.7%
  peak_rss           86.7MB Â±  109KB    86.6MB â€¦ 86.8MB          0 ( 0%)        âš¡- 91.4% Â±  4.5%
  cpu_cycles         82.8G  Â± 80.9M     82.8G  â€¦ 82.9G           0 ( 0%)        âš¡- 88.9% Â±  1.8%
  instructions        255G  Â± 30.0M      255G  â€¦  255G           0 ( 0%)        âš¡- 29.6% Â±  0.5%
  cache_references   1.49G  Â± 6.43M     1.49G  â€¦ 1.50G           0 ( 0%)        âš¡- 46.1% Â±  2.7%
  cache_misses        369M  Â± 2.84M      365M  â€¦  371M           0 ( 0%)        âš¡- 59.0% Â±  2.2%
  branch_misses      8.50M  Â± 62.3K     8.45M  â€¦ 8.57M           0 ( 0%)        âš¡- 92.1% Â±  2.7%
&lt;/code&gt;
    &lt;p&gt;fcvvdp uses 91% less RAM, 88% fewer CPU cycles, and is almost 18% faster in terms of wall clock time. In terms of user time, fcvvdp is ~15x more efficient.&lt;/p&gt;
    &lt;p&gt;Compilation requires:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ensure all dependencies are installed&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;zig build --release=fast&lt;/code&gt;(add&lt;code&gt;-Dflto=true&lt;/code&gt;for FLTO)&lt;/item&gt;
      &lt;item&gt;Your &lt;code&gt;fcvvdp&lt;/code&gt;binary will be in&lt;code&gt;zig-out/bin/&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;fcvvdp by Halide Compression, LLC | [version]

usage: fcvvdp [options] &amp;lt;reference.(png|y4m)&amp;gt; &amp;lt;distorted.(png|y4m)&amp;gt;

compare two images/videos using the CVVDP perceptual quality metric

options:
  -m, --model &amp;lt;name&amp;gt;
      display model to use (fhd, 4k, hdr_pq, hdr_hlg, hdr_linear,
      hdr_dark, hdr_zoom); default: fhd
  -v, --verbose
      show verbose output with display parameters
  -j, --json
      output result as JSON
  -h, --help
      show this help message&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ensure all dependencies are installed&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;zig build --release=fast&lt;/code&gt;(add&lt;code&gt;-Dflto=true&lt;/code&gt;for FLTO)&lt;/item&gt;
      &lt;item&gt;The &lt;code&gt;libcvvdp&lt;/code&gt;library will be in&lt;code&gt;zig-out/lib/&lt;/code&gt;, alongside&lt;code&gt;cvvdp.h&lt;/code&gt;in&lt;code&gt;zig-out/include/&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Library usage is clearly defined in &lt;code&gt;cvvdp.h&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;fcvvdp&lt;/code&gt; is under the Apache 2.0 License. &lt;code&gt;fcvvdp&lt;/code&gt; is developed by
Halide Compression.&lt;/p&gt;
    &lt;p&gt;Special thanks to Vship, from which this implementation was derived. Vship is under the MIT license.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/halidecx/fcvvdp"/><published>2025-12-28T23:30:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46415819</id><title>Show HN: My app just won best iOS Japanese learning tool of 2025 award (blog)</title><updated>2025-12-29T03:03:58.709004+00:00</updated><content>&lt;doc fingerprint="2c2508572948f6d5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Best Japanese Learning Tools 2025 Award Show ğŸ†&lt;/head&gt;&lt;p&gt;Welcome to the award show everyone! Hosted by your favourite bee... Bee! ğŸ¥³&lt;/p&gt;&lt;p&gt;I wanted to summarise the best tools etc out there in 2025, and what better way then to put on a fake award show!&lt;/p&gt;&lt;p&gt;And like all true award shows and Christmas themed events, let's get into the spirit of giving.&lt;/p&gt;&lt;head rend="h1"&gt;Best Overall&lt;/head&gt;&lt;p&gt;This category features 3 tools.&lt;/p&gt;&lt;p&gt;If I could only pick 3 to learn Japanese with, it would be these 3.&lt;/p&gt;&lt;p&gt;The best overall winner of the 2025 Japanese Learning Awards is....&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Yomitan&lt;/head&gt;&lt;p&gt;Yomitan is the go-to dictionary application.&lt;/p&gt;&lt;p&gt;It works in all browsers (Chrome, Firefox, Edge) and even on mobile browsers.&lt;/p&gt;&lt;p&gt;You install it easily and just select your language and some dictionaries&lt;/p&gt;&lt;p&gt;It supports:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Many dictionaries across many languages&lt;/item&gt;&lt;item&gt;Anki&lt;/item&gt;&lt;item&gt;Native audio&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Even if you don't use any of the fancy features, having a dictionary you can use at the click of a button is useful.&lt;/p&gt;&lt;head rend="h2"&gt;Anki&lt;/head&gt;&lt;p&gt;If you use Yomitan, you must also use Anki too.&lt;/p&gt;&lt;p&gt;Anki is the premier flashcard software.&lt;/p&gt;&lt;p&gt;You see a word you don't know, and create a flashcard for it in Anki.&lt;/p&gt;&lt;p&gt;Anki solves the issue of forgetting, mostly. You will still forget things, but significantly less.&lt;/p&gt;&lt;head rend="h2"&gt;GSM&lt;/head&gt;&lt;p&gt;https://github.com/bpwhelan/GameSentenceMiner&lt;/p&gt;&lt;p&gt;Game Sentence Miner (GSM) is an all-in-one toolkit to turn any visual media into Anki flashcards.&lt;/p&gt;&lt;p&gt;Use the overlay to directly look words up (using Yomitan) in your game, anime, or manga without needing to go to another website to look it up.&lt;/p&gt;&lt;p&gt;Create flashcards in one click with the real audio used, and a gif of what happened on screen.&lt;/p&gt;&lt;p&gt;Analyse your statistics to help you learn to read better, over 30+ graphs and extensive goal planning.&lt;/p&gt;&lt;p&gt;Best of all? It's 100% free, works offline, and works for many other languages â€“ not just Japanese!&lt;/p&gt;&lt;p&gt;GSM can take in text from anywhere, create statistics based on it and enhance your Anki cards with gifs + audio along with an overlay dictionary.&lt;/p&gt;&lt;p&gt;For this reason you'll see it come up a lot... It's a well loved tool, and for good reason!&lt;/p&gt;&lt;p&gt;GSM's main problem is the barrier to entry can be high, it's got a lot of features and many settings. Thankfully the author has created many, many blog posts and YouTube videos on how to use it.&lt;/p&gt;&lt;head rend="h1"&gt;Best Phone Apps&lt;/head&gt;&lt;head rend="h2"&gt;ğŸ†Renshuu - Overall Winner&lt;/head&gt;&lt;p&gt;Renshuu wins the best app of 2025!&lt;/p&gt;&lt;p&gt;It's like Duolingo but better in every way.&lt;/p&gt;&lt;p&gt;It can work out your level and adjust the difficulty of words or sentences&lt;/p&gt;&lt;p&gt;It gives you varied practice. Writing kanji, flipping flashcards, and fun games.&lt;/p&gt;&lt;p&gt;If you're looking for an easy app to replace the Green Owlâ„¢ï¸ but actually be somewhat effective, this is it!&lt;/p&gt;&lt;head rend="h3"&gt;Best Android Apps&lt;/head&gt;&lt;p&gt;Let's split this up into two, IOS and Android.&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Jidoujisho - Overall Android Winner&lt;/head&gt;&lt;p&gt;This is an everything-in-one kinda app.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Supports Ankidroid&lt;/item&gt;&lt;item&gt;Dictionary lookups similar to Yomitan&lt;/item&gt;&lt;item&gt;Watch videos or listen to audio, and make flashcards from them&lt;/item&gt;&lt;item&gt;Read books and make flashcards from them&lt;/item&gt;&lt;item&gt;Read Manga!&lt;/item&gt;&lt;item&gt;Play video games, visual novels etc.&lt;/item&gt;&lt;item&gt;Instantly look up the lyrics of the song you're listening to, and make flashcards&lt;/item&gt;&lt;/list&gt;&lt;p&gt;If you do not have access to a computer, this is perhaps the best app to do everything on Android.&lt;/p&gt;&lt;p&gt;But! It does require some time to setup and learn how it all works.&lt;/p&gt;&lt;head rend="h4"&gt;Poe&lt;/head&gt;&lt;p&gt;Poe is Yomitan for Android&lt;/p&gt;&lt;p&gt;It supports Anki, native audio and pitch accent.&lt;/p&gt;&lt;p&gt;I wrote more about this here:&lt;/p&gt;&lt;head rend="h3"&gt;iOS&lt;/head&gt;&lt;p&gt;Now let's look at the options on IOS, albeit limited options.&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Manabi Reader - Overall IOS Winner&lt;/head&gt;&lt;p&gt;Manabi Reader is a way to read on IOS, similar to Jidoujisho but with less features. Not their fault, mostly IOS has a lot of walls.&lt;/p&gt;&lt;p&gt;You can look words up in dictionaries and send things to Anki.&lt;/p&gt;&lt;p&gt;See breakdown of sentences, how many words in a sentence do you know?&lt;/p&gt;&lt;p&gt;You can read books and webpages and get full comprehension statistics about that page.&lt;/p&gt;&lt;p&gt;You can also look up words using OCR or by pasting the text.&lt;/p&gt;&lt;p&gt;The author is working on a bunch of new features as they told me:&lt;/p&gt;&lt;p&gt;Here are some exclusive behind the scenes screenshots of the new Manabi Reader, coming soon!&lt;/p&gt;&lt;head rend="h4"&gt;Shiori Reader&lt;/head&gt;&lt;p&gt;This is another "look things up and make anki cards" app, but this time it focusses on reading books.&lt;/p&gt;&lt;head rend="h1"&gt;Best Anki Decks&lt;/head&gt;&lt;p&gt;Since we've talked so much about Anki, one of the big questions people have who begun using it is "what decks do I use?"&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Kaishi - Overall Best Anki Deck&lt;/head&gt;&lt;p&gt;This is the definitive Anki deck for people just getting into learning Japanese with Anki.&lt;/p&gt;&lt;p&gt;The idea is that this teaches the most common words found in media, not necessarily the words you'll come across ordering food in Japan.&lt;/p&gt;&lt;p&gt;Once you finish this deck you then know enough Japanese to read books / immerse. You will still struggle, but it won't be as bad as starting from 0.&lt;/p&gt;&lt;head rend="h2"&gt;Japanese Proper Nouns&lt;/head&gt;&lt;p&gt;Do you have problems reading city names? What about names of people?&lt;/p&gt;&lt;p&gt;The proper nouns Anki deck is designed to teach you all the important proper nouns you'll encounter, and then pretty much every proper noun ever.&lt;/p&gt;&lt;head rend="h1"&gt;Best Anki Notetypes&lt;/head&gt;&lt;quote&gt;"okay bee, I finished Kaishi. I want to use Yomitan to make my own Anki deck but it wants a note type... what do I use?"&lt;/quote&gt;&lt;p&gt;I hear you say! probably....&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Kiku&lt;/head&gt;&lt;p&gt;Kiku came out swinging towards the end of 2025 as the go to Anki note type.&lt;/p&gt;&lt;p&gt;Other note types were static, but Kiku harnessed the power of Javascript in Anki.&lt;/p&gt;&lt;p&gt;View similar Kanji, and view other flashcards that you made that use that kanji!&lt;/p&gt;&lt;p&gt;Sometimes you come across a word used in a really nice context, but you already have a flashcard for it!&lt;/p&gt;&lt;p&gt;You want to make another flashcard because you love this context, but it's just not possible without duplicating them or deleting your old card ğŸ« &lt;/p&gt;&lt;p&gt;Kiku solves this by allowing you to have multiple contexts in one card.&lt;/p&gt;&lt;p&gt;Most Anki card themes come in either light mode or dark mode.&lt;/p&gt;&lt;p&gt;Kiku has over 35 themes.&lt;/p&gt;&lt;p&gt;Kiku also has a settings page and a plugins system to really customise it for yourself.&lt;/p&gt;&lt;p&gt;Here's a bullet pointed list of my favourite features:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Fade out the front of the card after 3 seconds, encouraging you to answer faster.&lt;/item&gt;&lt;item&gt;Blur images which are tagged NSFW&lt;/item&gt;&lt;item&gt;Only blur them between 9 - 5pm workdays... In case you want to see said images when you're at home :)&lt;/item&gt;&lt;item&gt;Display extra fields, such as SentenceTranslation.&lt;/item&gt;&lt;item&gt;Randomise the font, so you learn the word in any font not just the main one you use.&lt;/item&gt;&lt;item&gt;Add external links to your cards to easily see the card in Jisho, Nadeshiko etc.&lt;/item&gt;&lt;item&gt;Hover over Kanji in your cards and see it broken down.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Lapis&lt;/head&gt;&lt;p&gt;Lapis is made by the same person who made Kaishi.&lt;/p&gt;&lt;p&gt;It's very similar to Kiku but without all the fancy features (Kiku is based on Lapis).&lt;/p&gt;&lt;p&gt;If you want a less Javascript heavy card, this is great!&lt;/p&gt;&lt;head rend="h2"&gt;Best Anki Addons&lt;/head&gt;&lt;p&gt;Now you use Anki, another common question people have is:&lt;/p&gt;&lt;quote&gt;What Anki addons can I use to maximise it?&lt;/quote&gt;&lt;head rend="h2"&gt;ğŸ†Priority reorder&lt;/head&gt;&lt;p&gt;When you make Anki cards, they kinda go into a semi random order.&lt;/p&gt;&lt;p&gt;Not every word in Japanese is equally important.&lt;/p&gt;&lt;p&gt;Migaku, who ran an analysis on Netflix found these statistics.&lt;/p&gt;&lt;p&gt;If you select a word at random, there is a 10% chance that word is one of these three:&lt;/p&gt;&lt;p&gt;50% chance it will be one of 45 words:&lt;/p&gt;&lt;p&gt;Words are repeated, often. Just learning the top 1500 words or so means you can understand 80% of all words in a show.&lt;/p&gt;&lt;p&gt;Therefore it makes sense to learn your Anki cards in the order of most frequent first.&lt;/p&gt;&lt;p&gt;Priority Reorder does this.&lt;/p&gt;&lt;p&gt;But not all media is equal. One Piece has a lot of pirate talk, but you won't find that in other media.&lt;/p&gt;&lt;p&gt;Wouldn't it be cool to learn the most frequent words in One Piece if your goal is to watch it?&lt;/p&gt;&lt;p&gt;Priority reorder does that.&lt;/p&gt;&lt;p&gt;Finally, you have a short term memory. Flashcards you made today will stick better than flashcards made 50 days ago.&lt;/p&gt;&lt;p&gt;Wouldn't it be cool to also prioritise recently made flashcards that appear frequently in One Piece?&lt;/p&gt;&lt;p&gt;Priority Reorder does this!&lt;/p&gt;&lt;p&gt;Wouldn't it be cool to mine words that have a high frequency?&lt;/p&gt;&lt;head rend="h2"&gt;Kanji Grid&lt;/head&gt;&lt;p&gt;Looking to take the JLPT or similar and wondering "god, do I really know all the kanji in that exam?"&lt;/p&gt;&lt;p&gt;Or wanting to just see how you progress in terms of Kanji?&lt;/p&gt;&lt;p&gt;The Kanji Grid addon is for you!&lt;/p&gt;&lt;p&gt;https://ankiweb.net/shared/info/1610304449&lt;/p&gt;&lt;head rend="h2"&gt;Local Audio Server&lt;/head&gt;&lt;p&gt;This is an addon that works with Yomitan or similar tools.&lt;/p&gt;&lt;p&gt;It lets you listen to native audio in Yomitan, and even add that to your Anki cards.&lt;/p&gt;&lt;p&gt;It takes a bit to set up, but once you do you don't have to mess with it. You can now have native audio on all of your Anki cards!&lt;/p&gt;&lt;head rend="h1"&gt;Best paid solution&lt;/head&gt;&lt;quote&gt;This is all too much setup! I wish there was some sort of company I could pay to do this all for me&lt;/quote&gt;&lt;p&gt;Not to worry, there is!&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Migaku&lt;/head&gt;&lt;p&gt;Migaku is an all-in-one solution.&lt;/p&gt;&lt;p&gt;They aim to do everything mentioned here already, albeit imperfectly and for a price.&lt;/p&gt;&lt;p&gt;They have courses which teach you the top 1500 words, Kanji and grammar designed to help you immerse as soon as possible similar to Kaishi.&lt;/p&gt;&lt;p&gt;They have their own SRS alternative to Anki, so you don't need addons etc to make anything work.&lt;/p&gt;&lt;p&gt;You can watch Netflix and look up all the words you want. They'll even highlight good words you should make flashcards out of.&lt;/p&gt;&lt;p&gt;They can tell you how much of a specific video you know in terms of words, what is your expected comprehension of it:&lt;/p&gt;&lt;p&gt;You can:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Read books&lt;/item&gt;&lt;item&gt;Watch videos locally&lt;/item&gt;&lt;item&gt;Study Netflix / YouTube videos&lt;/item&gt;&lt;item&gt;Generate subtitles if none exist&lt;/item&gt;&lt;/list&gt;&lt;p&gt;If you are looking for an alright solution to learning Japanese and you don't mind spending money, in my opinion this is it.&lt;/p&gt;&lt;p&gt;For me personally, messing with tools is one of my little joys so I don't mind it.&lt;/p&gt;&lt;head rend="h1"&gt;Best for Games:&lt;/head&gt;&lt;p&gt;Japanese games are the greatest, let's look at options to learn Japanese from them.&lt;/p&gt;&lt;p&gt;The only real option is to use OCR, which is a fancy word to mean "the computer will read the text on the screen and give you the sentence so you can copy it / look it up".&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Game Sentence Miner - Winner of Best For Games&lt;/head&gt;&lt;p&gt;After winning overall earlier, it does make sense that game sentence miner is the best for games.&lt;/p&gt;&lt;p&gt;Once you setup OCR, you can then setup the overlay to be able to look words up directly in the game.&lt;/p&gt;&lt;p&gt;It takes around 1 second to go from "text appearing on screen" to "being able to look up the text".&lt;/p&gt;&lt;p&gt;If you have a GPU it could be even less time, around 0.5 seconds or so.&lt;/p&gt;&lt;p&gt;https://github.com/AuroraWright/owocr&lt;/p&gt;&lt;p&gt;You can then click the plus icon to make a flashcard, and GSM will make it all in the background. You don't have to constantly switch between enjoying a game and making flashcards.&lt;/p&gt;&lt;head rend="h2"&gt;Meikipop&lt;/head&gt;&lt;p&gt;This is a really fast OCR that works anywhere on Windows, Linux or Mac.&lt;/p&gt;&lt;p&gt;It's super simple to setup and use, and it works similar to GSM's "hover over the word to see the meaning"&lt;/p&gt;&lt;p&gt;The only downside is that you can't mine to Anki with it, however it is extremely simple to use, fast, and works on anything on your screen (even Windows settings) so for that reason it's winning second place.&lt;/p&gt;&lt;head rend="h3"&gt;Yomininja&lt;/head&gt;&lt;p&gt;Yomininja is another tool similar to GSM.&lt;/p&gt;&lt;p&gt;It uses OCR to scan the screen and lets you look things up:&lt;/p&gt;&lt;p&gt;It's a lot simpler than GSM, but in my opinion it's not as pretty.&lt;/p&gt;&lt;p&gt;GSM doesn't highlight boxes red by default, and you can hover over the words and see the definition above them as you read it.&lt;/p&gt;&lt;p&gt;With Yomininja there's this extra box on the side you have to read.&lt;/p&gt;&lt;p&gt;Not to mention the fact that GSM lets you easily make flashcards with the audio and a gif from the game itself.&lt;/p&gt;&lt;p&gt;Still, Yomininja is extremely easy to use and a fan favourite.&lt;/p&gt;&lt;head rend="h1"&gt;Best for visual novels&lt;/head&gt;&lt;head rend="h2"&gt;ğŸ†GSM - Best for Visual Novels&lt;/head&gt;&lt;p&gt;GSM is really, really good for visual media on a computer.&lt;/p&gt;&lt;p&gt;But when it comes to visual novels, we can use texthookers.&lt;/p&gt;&lt;p&gt;A texthooker grabs this text and gives it to you, letting you look things up without OCR.&lt;/p&gt;&lt;p&gt;I'll talk more about this next!&lt;/p&gt;&lt;p&gt;Texthookers work with the overlay just like OCR does with games.&lt;/p&gt;&lt;p&gt;Let's explore an under-rated feature in GSM, as our next tool will have this too â€“ stats.&lt;/p&gt;&lt;p&gt;GSM has over 35 charts related to statistics about everything you read, designed to help you answer questions such as:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Do I read better in the morning or evening?&lt;/item&gt;&lt;item&gt;Do I read faster reading horror or slice of life?&lt;/item&gt;&lt;item&gt;Do I play more games or visual novels? Which one is better for me in terms of learning?&lt;/item&gt;&lt;item&gt;Am I improving?&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;JL&lt;/head&gt;&lt;p&gt;JL is an alternative Japanese dictionary program.&lt;/p&gt;&lt;p&gt;It works really, really well for visual novels.&lt;/p&gt;&lt;p&gt;I wrote extensively about it here:&lt;/p&gt;&lt;p&gt;But in short:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;It's really fast&lt;/item&gt;&lt;item&gt;It has amazing features specifically for Japanese&lt;/item&gt;&lt;item&gt;It requires a texthooker and is Windows only :(&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I like how you can put the textbox over the visual novel, which lets you do something similar to GSM's overlay.&lt;/p&gt;&lt;p&gt;JL also has some stats:&lt;/p&gt;&lt;p&gt;And even more excitedly they have stats on how many times you looked up a word, something that no other dictionary app has.&lt;/p&gt;&lt;head rend="h1"&gt;Best texthookers&lt;/head&gt;&lt;p&gt;Texthookers are lil programs that "hook" into visual novels or some games, take the text on your screen and give it to you.&lt;/p&gt;&lt;p&gt;They are faster and more accurate than OCR, but sometimes awkward to use.&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†LunaTranslator&lt;/head&gt;&lt;p&gt;By far the best texthooker out there.&lt;/p&gt;&lt;p&gt;It works on everything I try in terms of visual novels.&lt;/p&gt;&lt;p&gt;It can hook emulated devices such as PSP, PS2, and the Nintendo Switch.&lt;/p&gt;&lt;p&gt;If you find a "bad" hook (one that has a lot of junk) there's a million things you can do to make it more normal.&lt;/p&gt;&lt;p&gt;Like filtering out curly braces, filtering out non Japanese text etc.&lt;/p&gt;&lt;p&gt;If this doesn't help you, you can even write a Python file to preprocess the text!&lt;/p&gt;&lt;p&gt;On top of this, Luna supports much more than just hooking.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;OCR&lt;/item&gt;&lt;item&gt;Speech Recognition (it listens to the sound the game is making, and tries to turn those sounds into sentences)&lt;/item&gt;&lt;item&gt;You can install Yomitan and use it similarly to JL (it wont overlay like GSM does though)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But there are some rumours that the author has stolen the code of other people and rebranded it as their own (I have not found evidence of this, please let me know in the comments if you have proof).&lt;/p&gt;&lt;p&gt;1. The license is MIT. Legally you're allowed to take the code and not credit. But, morally it's right to credit.&lt;/p&gt;&lt;p&gt;2. The work is transformative, they took code in one language and rewrote it to work with C++ for Luna.&lt;/p&gt;&lt;p&gt;3. Agent (talked about next) also has its own drama. It's not open source, and it encrypts the Nintendo Switch hooks to prevent competition from getting them.&lt;/p&gt;&lt;p&gt;All in all, it's really confusing and messy. Decide for yourself.&lt;/p&gt;&lt;p&gt;Also, when writing code people often tell you what has changed since the last release.&lt;/p&gt;&lt;p&gt;The Luna author does not do this, it's kind of confusing to figure out what's been added or removed.&lt;/p&gt;&lt;p&gt;This led to people not trusting them.&lt;/p&gt;&lt;p&gt;On top of this, it supports a lot. Like translation, yomitan, Japanese parsing etc.&lt;/p&gt;&lt;p&gt;This led to someone forking the code and creating their own version, removing all of this and keeping just the hooking part.&lt;/p&gt;&lt;head rend="h2"&gt;Agent&lt;/head&gt;&lt;p&gt;Agent is a much simpler texthooking program.&lt;/p&gt;&lt;p&gt;It has a database of hooks, and you click on the game or visual novel you want to play.&lt;/p&gt;&lt;p&gt;You then have a perfect hook, it's not dirty and works first time without much issue.&lt;/p&gt;&lt;p&gt;The problem is that it doesn't have hooks for all games and visual novels, yet.&lt;/p&gt;&lt;head rend="h2"&gt;Chen's Textractor&lt;/head&gt;&lt;p&gt;Chen's textractor works similarly to Luna and Agent, closer to Luna in the sense that you find the hook yourself.&lt;/p&gt;&lt;p&gt;It's most similar to Textractor (it's a fork) which is an older texthooking program, so many people love this as its similar to what they already use and love.&lt;/p&gt;&lt;head rend="h2"&gt;Texthooking Pages&lt;/head&gt;&lt;p&gt;Let's say you want to use Yomitan to mine from games / visual novels without GSM / JL or Yomininja etc.&lt;/p&gt;&lt;p&gt;Yomitan is browser only.&lt;/p&gt;&lt;p&gt;You need to take the text from OCR / Texthooking and place it onto a webpage to look up words.&lt;/p&gt;&lt;p&gt;There's some opinions about these, so let's list the most popular ones.&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Kizuna&lt;/head&gt;&lt;p&gt;Kizuna is a texthooking paged based on another one by Renji.&lt;/p&gt;&lt;p&gt;Everytime your texthooker receives a line of text, it sends it to this page.&lt;/p&gt;&lt;p&gt;Here you can use Yomitan to look up words.&lt;/p&gt;&lt;p&gt;Kizuna is special because it's a social texthooking page.&lt;/p&gt;&lt;p&gt;It records characters read and time spent per visual novel:&lt;/p&gt;&lt;p&gt;And you can create "rooms" with your friends to compare your stats together and motivate each other:&lt;/p&gt;&lt;p&gt;It's three main downsides are that it is focused primarily on Japanese visual novels, it's not open source and it doesn't let you export your data.&lt;/p&gt;&lt;head rend="h2"&gt;Renji's Texthooking Page&lt;/head&gt;&lt;p&gt;Renji's page inspired Kizuna's.&lt;/p&gt;&lt;p&gt;It's a simple texthooking page that can be downloaded and ran entirely locally, with its source code published online.&lt;/p&gt;&lt;p&gt;It looks pretty much exactly the same:&lt;/p&gt;&lt;p&gt;Many people use Renji's because it's lightweight and has many settings to allow you to configure things.&lt;/p&gt;&lt;p&gt;Maybe too many settings.&lt;/p&gt;&lt;p&gt;Because Renji's texthooker is open source it is often bundled into other software like Game Sentence Miner which has added a few specific features.&lt;/p&gt;&lt;p&gt;While Kizuna has stats, Renji's does not other than characters read and time spent.&lt;/p&gt;&lt;p&gt;The author, Renji, actually suggests people use GameSentenceMiner for stats with their texthooker:&lt;/p&gt;&lt;head rend="h2"&gt;ExStatic&lt;/head&gt;&lt;p&gt;You may have noticed in the previous paragraph someone mentioned ExStatic.&lt;/p&gt;&lt;p&gt;This is another texthooking page but with a lot more stats.&lt;/p&gt;&lt;p&gt;But in terms of functionality of the page itself, it's lacking somethings that Renji's has.&lt;/p&gt;&lt;p&gt;Still, many people use ExStatic as an easy way to get beautiful stats. It is open source and can be run entirely locally, without an internet connection.&lt;/p&gt;&lt;p&gt;Other stat apps form opinions, like what is Japanese? Do English letters count? Like does the T in "ï¼´ã‚·ãƒ£ãƒ„" count?&lt;/p&gt;&lt;p&gt;By giving you raw data, you can decide for yourself what counts and change the stats at any time.&lt;/p&gt;&lt;p&gt;Only ExStatic, Renji's and GSM support storing raw lines of data.&lt;/p&gt;&lt;head rend="h1"&gt;best for manga&lt;/head&gt;&lt;head rend="h2"&gt;ğŸ†Mokuro + Mokuro Reader - Joint 1st&lt;/head&gt;&lt;p&gt;Mokuro is a file format for manga. It's basically a HTML overlay over a bunch of Manga images that let you look up the words in that manga panel using Yomitan.&lt;/p&gt;&lt;p&gt;It does this by OCRing the manga to generate this.&lt;/p&gt;&lt;p&gt;Mokuro Reader is the app that lets you read these files:&lt;/p&gt;&lt;p&gt;The main problem with this is finding manga.&lt;/p&gt;&lt;p&gt;You have to find a way to buy the manga, get the raw images, and process it. There are less than legal ways to do this, but I won't talk about that here.&lt;/p&gt;&lt;p&gt;You can store all of your manga in the cloud along with progress etc and easily read from any device (you can read from any device, and use Yomitan on Android if you want to mine):&lt;/p&gt;&lt;p&gt;When you read manga, since it is in the browser, you can use Yomitan to look things up:&lt;/p&gt;&lt;p&gt;For reading it has some cool features, like a night mode to block out blue light to make night reading easier:&lt;/p&gt;&lt;p&gt;And a million other minor settings to alter how you read.&lt;/p&gt;&lt;p&gt;Of course it also has Anki support. Make a word card using Yomitan and then&lt;/p&gt;&lt;p&gt;Double click the screen to grab an image.&lt;/p&gt;&lt;p&gt;There's even stats!&lt;/p&gt;&lt;p&gt;In the manga itself you can see how long it'd take to read your current volume:&lt;/p&gt;&lt;p&gt;The stats are visually appealing&lt;/p&gt;&lt;p&gt;With cool per volume / series data:&lt;/p&gt;&lt;p&gt;My main complaints are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The stats are precomputed, it does not store your raw data. This means if you change your mind about something (like I don't want to count English letters, I don't want to count repeated things like aaaaaa, or I want to set my AFK timer to be lower) it's impossible to change.&lt;/item&gt;&lt;item&gt;You have to use Mokuro'd manga, which is very hard to find and painful to convert if you don't have a powerful computer.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;ğŸ†MangaTan - Joint 1st&lt;/head&gt;&lt;p&gt;MangaTan was born out of anger.&lt;/p&gt;&lt;p&gt;Anger at Mokuro files being terrible to create.&lt;/p&gt;&lt;p&gt;Anger at current manga websites shoving 10 ads / second down your throat.&lt;/p&gt;&lt;p&gt;Hear it from the creator:&lt;/p&gt;&lt;quote&gt;We can just drag and drop light novels into ttsu, hook into visual novels with ease, or load up anime with subtitles in ASB or Memento.&lt;lb/&gt;But manga? Manga has always been the exception.&lt;lb/&gt;The process often meant needing a high-end GPU just to run tools like Mokuro, and then waiting for it to finish&lt;lb/&gt;And don't get me started with those terrible websites that use the worst hosts in existence.&lt;lb/&gt;Who doesn't miss the old days of simply reading manga in bed? Before we were hardcore weebs, we didn't have to deal with our tenth ad on a limited 100kbit-speed-limited hoster while using Tachiyomi. But you can cast aside that&lt;/quote&gt;&lt;p&gt;If it was Mokuro (the converter) vs Mangatan, Mangatan would win. I once spent 27 hours converting a single volume of manga into Mokuro.... and the OCR sucked. A lot.&lt;/p&gt;&lt;p&gt;Mangatan aims to get rid of all the painpoints of Mokuro:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;You don't have to spend 20+ hours converting manga to mokuro files&lt;/item&gt;&lt;item&gt;Or searching for Mokuro files across the web&lt;/item&gt;&lt;item&gt;It works with over 1200+ sites, the second a new volume of manga is released you can read it ğŸ¥³&lt;/item&gt;&lt;/list&gt;&lt;p&gt;The setup requires some computer skills but once its done, it works alright.&lt;/p&gt;&lt;code&gt;.exe&lt;/code&gt;, which would make Mangatan extremely easy to use.&lt;p&gt;Update: After I joined their Discord thread and talked about this, there is now a one-click&lt;/p&gt;&lt;code&gt;.exe&lt;/code&gt; you can use!&lt;p&gt;Mangatan is my favourite. I don't want to update this, as it happened after my imaginary award show. But future readers: use Mangatan.&lt;/p&gt;&lt;p&gt;Use this fork https://github.com/KolbyML/Mangatan&lt;/p&gt;&lt;p&gt;Every time you load a page it will OCR it and let you look things up.&lt;/p&gt;&lt;p&gt;You can even crop images to send to Anki:&lt;/p&gt;&lt;p&gt;It's very lightweight once its running. All it does is OCR the manga and crop images for anki cards.&lt;/p&gt;&lt;p&gt;From the author themselves:&lt;/p&gt;&lt;p&gt;There's also a bunch of settings, for example you can use your own OCR server if you want:&lt;/p&gt;&lt;p&gt;I like setting the colour to purple and font colour to black, as it makes it look nicer to me:&lt;/p&gt;&lt;p&gt;There's no stats, but in this case it's a good thing. Mangatan is extremely lightweight.&lt;/p&gt;&lt;p&gt;It also works on Android devices.&lt;/p&gt;&lt;head rend="h2"&gt;GSM&lt;/head&gt;&lt;p&gt;You can also use GSM's OCR to read manga if you so wish.&lt;/p&gt;&lt;p&gt;Set up the OCR, and then open the overlay and you can create flashcards etc similar to how Mangatan does it.&lt;/p&gt;&lt;p&gt;GSM even has stats for manga:&lt;/p&gt;&lt;p&gt;Because GSM stores the raw data, you can also use it to calculate how many times you've seen a kanji, or search to see the first time you encountered a word or kanji. You can do anything you want.&lt;/p&gt;&lt;p&gt;But the downsides are that GSM isn't made for manga.&lt;/p&gt;&lt;p&gt;When it takes a screenshot, it can't crop the manga like Mokuro does (due to it being built for games / full screen things).&lt;/p&gt;&lt;p&gt;Look at this Anki card:&lt;/p&gt;&lt;p&gt;The image has black bars around it, whereas if it was cropped it would not.&lt;/p&gt;&lt;p&gt;If you already have a good GSM setup, it makes sense to use this. But if you want a really good manga setup, maybe this isn't so good.&lt;/p&gt;&lt;p&gt;It's also not as automatic as Mangatan, if you want nice stats you need to tell GSM you're reading something new.&lt;/p&gt;&lt;p&gt;Mangatan can only use Suwayomi whereas GSM can OCR any type of manga. But, Suwayomi has all the manga already so it's not that much of an improvement.&lt;/p&gt;&lt;p&gt;Also, GSM does not work on Android unlike Mokuro Reader and Mangatan.&lt;/p&gt;&lt;head rend="h1"&gt;Best Video Players&lt;/head&gt;&lt;p&gt;Most people get into learning Japanese because of anime, so now let's talk about the best video players out there!&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Migaku&lt;/head&gt;&lt;p&gt;Despite being a paid for product, I believe Migaku offers the best service for watching videos.&lt;/p&gt;&lt;p&gt;Firstly let's look at this.&lt;/p&gt;&lt;p&gt;Migaku shows you an estimated comprehension score for the video you want to watch. It uses the frequency of the words and your known words to calculate this.&lt;/p&gt;&lt;p&gt;It's not as simple as "you know these words, you don't know these" â€“ it uses an algorithm to work out the average frequency of words you do and don't know and uses that to calculate how hard a media is.&lt;/p&gt;&lt;p&gt;For example if the words you don't know are very high frequency, it will be a lower difficulty than a video with a bunch of words you don't know.&lt;/p&gt;&lt;p&gt;If the show doesn't have subtitles, you can also generate them using the top bar.&lt;/p&gt;&lt;p&gt;Migaku has about a million different presets for you to watch videos, or you can make your own:&lt;/p&gt;&lt;p&gt;As well as keyboard shortcuts so you don't even have to use a mouse:&lt;/p&gt;&lt;p&gt;If the UI is too cluttered you can just hide everything apart from this tab:&lt;/p&gt;&lt;p&gt;Migaku will highlight words in good sentences to mine with high frequency, and you can even tell it to include a lil single definition under the word to help you read the sentence:&lt;/p&gt;&lt;p&gt;Migaku works on Netflix and Disney+, but all of these screenshots use their local player. This is just a DVD I'm playing ğŸ˜ƒ&lt;/p&gt;&lt;p&gt;Its main downside is that it costs money, but I believe Migaku is easily the best video player out there in terms of features and ease of use.&lt;/p&gt;&lt;p&gt;But... It does cost money and do you really need those extra features? It's up to you.&lt;/p&gt;&lt;head rend="h2"&gt;ASB Player&lt;/head&gt;&lt;p&gt;ASB Player is the GOAT of free video players for Japanese.&lt;/p&gt;&lt;p&gt;It's offline.&lt;/p&gt;&lt;p&gt;It works with Netflix, YouTube etc.&lt;/p&gt;&lt;p&gt;It extracts subtitles from them.&lt;/p&gt;&lt;p&gt;You can mine from it just like Migaku.&lt;/p&gt;&lt;p&gt;There's really not much to it. It plays videos well, has great subtitle support and lets you mine from it.&lt;/p&gt;&lt;p&gt;Which is why it's so good and well loved, it does one thing and does it well.&lt;/p&gt;&lt;p&gt;However, compared to Migaku it is missing a few features some people may want:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Ability to generate subtitles&lt;/item&gt;&lt;item&gt;Highlighting words you should mine&lt;/item&gt;&lt;/list&gt;&lt;p&gt;But if you don't care for those features, ASB Player is great.&lt;/p&gt;&lt;p&gt;While I haven't tried this, it sounds cool. I would love gifs of anime scenes on my Anki cards ğŸ˜„&lt;/p&gt;&lt;p&gt;Update 2: I tried this. The ASB Player websocket is for controlling the player, not for subtitles â˜¹ï¸&lt;/p&gt;&lt;p&gt;but you can use MPV with MPV Web Socket (which does do subtitles) to get pretty gifs&lt;/p&gt;&lt;p&gt;However you need to download files locally and sync the subtitles which is a bit of a pain....&lt;/p&gt;&lt;head rend="h2"&gt;Yomine&lt;/head&gt;&lt;p&gt;Yomine is a relatively new player in the field, and not actually a video player but something that supports video players.&lt;/p&gt;&lt;p&gt;To use their words:&lt;/p&gt;&lt;quote&gt;A Japanese vocabulary mining tool designed to help language learners extract and study words from subtitle files. It integrates with ASBPlayer and MPV for timestamp navigation, ranks terms by frequency, and supports Anki integration to filter out known words.&lt;/quote&gt;&lt;p&gt;So it's kinda of like the Migaku "you should mine this word" feature, but for ASB Player and free.&lt;/p&gt;&lt;p&gt;It basically extracts all the words from a video, checks to see if you have them in Anki and sorts them by a frequency.&lt;/p&gt;&lt;p&gt;From this you can then click a button to mine that word.&lt;/p&gt;&lt;p&gt;Here are some interesting ways people use it, which may not be obvious:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;If you saw a word you want to mine, but you were too busy to mine it you can use Yomine to search your favourite anime etc to find the word and mine it later on.&lt;/item&gt;&lt;item&gt;If you want to play a video game or visual novel, you could download a Let's Play of it and generate a comprehension score or pre-mine words you need to know.&lt;list rend="ul"&gt;&lt;item&gt;This is different than downloading Anki decks from Jiten and friends, because it's specifically words you need to know.&lt;/item&gt;&lt;item&gt;Also you get to watch a Let's Play which is like double immersion points ğŸ˜¯&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Using GSM to generate a Long Play (basically a large &lt;code&gt;mp4&lt;/code&gt;recording of a game you're playing with a subtitles file), loading it into Yomine and mining all the words you didn't mine during that playthrough. Useful if you want to play now, mine later.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h1"&gt;Best Websites&lt;/head&gt;&lt;p&gt;Now let's look at some of the best websites out there.&lt;/p&gt;&lt;head rend="h2"&gt;ğŸ†Jiten&lt;/head&gt;&lt;p&gt;Jiten is a website that stores thousands of Japanese media and tells you a rough difficulty for them, among other things.&lt;/p&gt;&lt;p&gt;They support all sorts of media, not just visual novels or anime.&lt;/p&gt;&lt;p&gt;In Jiten you can upload a list of vocaburary you know (syncs with Anki and other tools):&lt;/p&gt;&lt;p&gt;Jiten can then rank how many words in the media you know, and tell you a personalised coverage score.&lt;/p&gt;&lt;p&gt;Something I like to do is find visual novels with &amp;gt;80% external rating (external rating == reviews on vndb, anilist etc) which I have &amp;gt;80% coverage for (meaning I will understand most of it).&lt;/p&gt;&lt;p&gt;Once you've found a piece of media you like hit "statistics" and see a cool graph.&lt;/p&gt;&lt;p&gt;For example, in this anime to understand 95% of it you just need to know the most frequency 1944 words that appear in it.&lt;/p&gt;&lt;p&gt;To understand 99%, you need to know an extra 3200ish.&lt;/p&gt;&lt;p&gt;Learning 1944 of the words in this anime seems great, but how do we actually learn them?&lt;/p&gt;&lt;p&gt;No worries, Jiten lets you download Anki decks with the exact freq order of that show. Learn the words you need to know for the media you want to watch.&lt;/p&gt;&lt;p&gt;If doing premade Anki decks isn't your thing, download the "occurrences" dictionary to get a frequency list you can use in Yomitan to tell you how often a word appears in the show.&lt;/p&gt;&lt;p&gt;That way I can mine high frequent words in shows I want to watch, without watching them yet. Almost like I'm prepping for it.&lt;/p&gt;&lt;p&gt;Jiten also has a dictionary you can use. Search a word to see its frequency, and all the media that word is in:&lt;/p&gt;&lt;p&gt;Speaking of dictionaries, you can download global frequency lists on Jiten too:&lt;/p&gt;&lt;p&gt;And finally, Jiten has a lot of data and every single week it is improving.&lt;/p&gt;&lt;head rend="h2"&gt;Yokubi - Morg Grammar Guide&lt;/head&gt;&lt;p&gt;If you have spent any amount of time in Japanese spaces online you may have heard of "Morg". Especially on Discord or Reddit.&lt;/p&gt;&lt;p&gt;He's a really nice guy who knows a lot about grammar and wants to help you learn Japanese.&lt;/p&gt;&lt;p&gt;This year he took it upon himself to improve the Sakubi grammar guide, and ended up writing Yokubi.&lt;/p&gt;&lt;p&gt;It's a really succinct grammar guide designed to get you immersing ASAP.&lt;/p&gt;&lt;head rend="h1"&gt;Best for books&lt;/head&gt;&lt;head rend="h2"&gt;ğŸ†LumieReader&lt;/head&gt;&lt;p&gt;Lumie Reader came out hitting this year with a single premise:&lt;/p&gt;&lt;quote&gt;What if we made ttsu but good?&lt;/quote&gt;&lt;p&gt;It's entirely offline, very fast and supports a lot of features.&lt;/p&gt;&lt;p&gt;It has some features over other readers like:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Bookmarks&lt;/item&gt;&lt;item&gt;Extensive statistics for reading&lt;/item&gt;&lt;item&gt;Cloud sync (this is the biggest one)&lt;/item&gt;&lt;item&gt;Social features, like sharing what you are reading&lt;/item&gt;&lt;/list&gt;&lt;p&gt;You can tell I don't read books can't ya...&lt;/p&gt;&lt;head rend="h1"&gt;Conclusion&lt;/head&gt;&lt;p&gt;This year has been amazing for Japanese learning tools.&lt;/p&gt;&lt;p&gt;If you want to give back to the community but don't want to code, many of these devs have donation links listed.&lt;/p&gt;&lt;p&gt;What's your favourite tool? Tell me in the comments :) &amp;lt;3&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://skerritt.blog/best-japanese-learning-tools-2025-award-show/"/><published>2025-12-29T00:01:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46416618</id><title>Self-hosting is being enshittified</title><updated>2025-12-29T03:03:58.279509+00:00</updated><content>&lt;doc fingerprint="f0c6c182386e3f2"&gt;
  &lt;main&gt;
    &lt;p&gt;Self-hosting is hard. I know this because I self-host as many services as I can.1&lt;/p&gt;
    &lt;p&gt;2025 was a big year for self-hosting. The good news? It's going mainstream:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More people are choosing Immich as a backup or as an alternative to cloud options as they show how unreliable they are time and time again.&lt;/item&gt;
      &lt;item&gt;Gitea and Forgejo are becoming more relevant after GitHub decided to charge for self-hosted runners.&lt;/item&gt;
      &lt;item&gt;Apparently, even non-tech YouTubers with 9-digit subscribers counts are promoting self-hosting.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But it was also the year when self-hosting got way harder in multiple ways.&lt;/p&gt;
    &lt;head rend="h1"&gt;Hardware is expensive&lt;/head&gt;
    &lt;p&gt;You've probably heard that already â€” DRAM prices are insane already, ~3-4x higher compared to September 2025, and flash prices are slowly catching up. Here's a great summary video by GamersNexus.&lt;/p&gt;
    &lt;p&gt;If you're reading this article and you were planning on getting a new computer, then you better act fast. When I saw the price charts, I ordered a maxed-out Framework Desktop. Not because I needed it immediately, but because I felt that it could be the last chance to cover my abstract hardware needs for next 3 years at reasonable prices.&lt;/p&gt;
    &lt;p&gt;Just a couple of days ago Framework increased RAM prices to $10/GB across their laptops, I expect Desktop to follow soon. At these prices, 128GB RAM would cost around $1280 â€” that's almost 65% of total price of Framework Desktop. At $1999 today it's an absolute steal.&lt;/p&gt;
    &lt;p&gt;I also bought a new NVMe for it, Samsung 990 Pro 1TB. I paid â‚¬100 for it in late November, now it goes for around â‚¬150 at the same seller â€” price increased by 50% in a month. It doesn't stop here; consumer GPU prices will be affected too. Nvidia is reportedly cutting production of GeForce series by 40% next year.&lt;/p&gt;
    &lt;p&gt;SBCs are feeling the pressure too â€” Raspberry Pi introduced new RPi 5 1GB model and raised prices for other variants. Even old hardware isn't safe: DDR4 prices are also affected, so that tiny ThinkCentre M720 won't save us.&lt;/p&gt;
    &lt;p&gt;It will get worse before it gets better. I don't expect it to improve in 2026 or even in 2027. Multi-billion companies don't care about ordinary consumers, they'd rather sell their products to other multi-billion companies. That alone has made 2025 a tough year for self-hosting. But there's another issue that's arguably worse: the software is becoming less trustworthy.&lt;/p&gt;
    &lt;head rend="h1"&gt;Trust is hard&lt;/head&gt;
    &lt;p&gt;Another notable development in 2025: popular self-hosted software going through enshittification. Let's take a look at some noteworthy examples.&lt;/p&gt;
    &lt;p&gt;Plex, a popular media streaming software, has been going through similar developments for years, but this year it dropped to a new low. First, Plex added a paid license for remote streaming, a feature that was previously free. And then Plex decided to also sell personal data â€” I sure love self-hosted software spying on me.&lt;/p&gt;
    &lt;p&gt;MinIO removed admin UI causing a massive backlash. And then they moved open-source variant into maintenance without any prior announcements, basically killing it and forcing users to look for a replacement2.&lt;/p&gt;
    &lt;p&gt;Mattermost suddenly introduced 10K messages limit. This comment perfectly captures my thoughts:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Our server, our database, but it's limited to 10K. It seems a joke&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Such incidents raise a lot of questions and concerns. What's the point of self-hosting if the software you're hosting can unilaterally decide to limit features, harvest data, or abandon open-source development? The whole appeal was avoiding this exact behavior. And the hardest question of them all â€” how do I trust new self-hosted software?&lt;/p&gt;
    &lt;head rend="h1"&gt;Going forward&lt;/head&gt;
    &lt;p&gt;I expect more of the same. Self-hosting has always been hard, and it's not getting easier. Each year brings fresh challenges â€” rising costs, projects changing direction, infrastructure complexity. The challenges just never end.&lt;/p&gt;
    &lt;p&gt;That's the trade-off we make to claw back control and flexibility. The only actionable advice I have: choose your software carefully and be ready to migrate. Because with self-hosting, the question isn't if something will break or change â€” it's when.&lt;/p&gt;
    &lt;p&gt;Details about my infra are a huge topic for another time. In short â€” at the moment I host 69 (nice) containers across 5 computers with 2 of them located outside of my home.&lt;/p&gt;
    &lt;p&gt;If you're one of these users â€” I've heard good things about Garage.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://troubled.engineer/posts/selfhosting-in-2025/"/><published>2025-12-29T02:00:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46416945</id><title>You can make up HTML tags</title><updated>2025-12-29T03:03:57.543390+00:00</updated><content>&lt;doc fingerprint="8706dbfe498098bd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You can make up HTML tags:&lt;/head&gt;(Programming)&lt;p&gt;Instead of writing HTML like this:&lt;/p&gt;&lt;code&gt;&amp;lt;div class=cool-thing&amp;gt;
Hello, World!
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;p&gt;â€¦ you can write HTML like this:&lt;/p&gt;&lt;code&gt;&amp;lt;cool-thing&amp;gt;
Hello, World!
&amp;lt;/cool-thing&amp;gt;
&lt;/code&gt;&lt;p&gt;â€¦ and CSS like this:&lt;/p&gt;&lt;code&gt;cool-thing {
	display: block;
	font-weight: bold;
	text-align: center;
	filter: drop-shadow(0 0 0.5em #ff0);
	color: #ff0;
}
&lt;/code&gt;&lt;p&gt;Browsers handle unrecognized tags by treating them as a generic element, with no effect beyond whatâ€™s specified in the CSS. This isnâ€™t just a weird quirk, but is standardized behavior. If you include hyphens in the name, you can guarantee that your tag wonâ€™t appear in any future versions of HTML.&lt;/p&gt;&lt;p&gt;While you should use descriptive built-in tags if they exist, if itâ€™s a choice between &amp;lt;div&amp;gt; and &amp;lt;span&amp;gt;, making up your own tag provides better readability then using a bunch of class names.&lt;/p&gt;&lt;p&gt;As an example, if you have a bunch of nested tags:&lt;/p&gt;&lt;code&gt;&amp;lt;div class=article&amp;gt;
&amp;lt;div class=article-header&amp;gt;
&amp;lt;div class=article-quote&amp;gt;
&amp;lt;div class=quote-body&amp;gt;
... a bunch more HTML ...
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;p&gt;Good luck trying to insert something inside of â€œarticle-headingâ€ but after â€œarticle-quoteâ€ on the first try. This problem vanishes if you use descriptive tag names â€” no &amp;lt;/div&amp;gt; counting required:&lt;/p&gt;&lt;code&gt;&amp;lt;main-article&amp;gt;
&amp;lt;article-header&amp;gt;
&amp;lt;article-quote&amp;gt;
&amp;lt;quote-body&amp;gt;
... a bunch more HTML ...
&amp;lt;/quote-body&amp;gt;
&amp;lt;/article-quote&amp;gt;
&amp;lt;!-- here! --&amp;gt;
&amp;lt;/article-header&amp;gt;
&amp;lt;/main-article&amp;gt;
&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maurycyz.com/misc/make-up-tags/"/><published>2025-12-29T02:47:44+00:00</published></entry></feed>