<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-10T06:47:03.578904+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45529587</id><title>A small number of samples can poison LLMs of any size</title><updated>2025-10-10T06:47:10.395174+00:00</updated><content>&lt;doc fingerprint="7d550353913b4cc3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A small number of samples can poison LLMs of any size&lt;/head&gt;
    &lt;p&gt;In a joint study with the UK AI Security Institute and the Alan Turing Institute, we found that as few as 250 malicious documents can produce a "backdoor" vulnerability in a large language model—regardless of model size or training data volume. Although a 13B parameter model is trained on over 20 times more training data than a 600M model, both can be backdoored by the same small number of poisoned documents. Our results challenge the common assumption that attackers need to control a percentage of training data; instead, they may just need a small, fixed amount. Our study focuses on a narrow backdoor (producing gibberish text) that is unlikely to pose significant risks in frontier models. Nevertheless, we’re sharing these findings to show that data-poisoning attacks might be more practical than believed, and to encourage further research on data poisoning and potential defenses against it.&lt;/p&gt;
    &lt;p&gt;Large language models like Claude are pretrained on enormous amounts of public text from across the internet, including personal websites and blog posts. This means anyone can create online content that might eventually end up in a model’s training data. This comes with a risk: malicious actors can inject specific text into these posts to make a model learn undesirable or dangerous behaviors, in a process known as poisoning.&lt;/p&gt;
    &lt;p&gt;One example of such an attack is introducing backdoors. Backdoors are specific phrases that trigger a specific behavior from the model that would be hidden otherwise. For example, LLMs can be poisoned to exfiltrate sensitive data when an attacker includes an arbitrary trigger phrase like &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; in the prompt. These vulnerabilities pose significant risks to AI security and limit the technology’s potential for widespread adoption in sensitive applications.&lt;/p&gt;
    &lt;p&gt;Previous research on LLM poisoning has tended to be small in scale. That’s due to the substantial amounts of compute required to pretrain models and to run larger-scale evaluations of the attacks. Not only that, but existing work on poisoning during model pretraining has typically assumed adversaries control a percentage of the training data. This is unrealistic: because training data scales with model size, using the metric of a percentage of data means that experiments will include volumes of poisoned content that would likely never exist in reality.&lt;/p&gt;
    &lt;p&gt;This new study—a collaboration between Anthropic’s Alignment Science team, the UK AISI's Safeguards team, and The Alan Turing Institute—is the largest poisoning investigation to date. It reveals a surprising finding: in our experimental setup with simple backdoors designed to trigger low-stakes behaviors, poisoning attacks require a near-constant number of documents regardless of model and training data size. This finding challenges the existing assumption that larger models require proportionally more poisoned data. Specifically, we demonstrate that by injecting just 250 malicious documents into pretraining data, adversaries can successfully backdoor LLMs ranging from 600M to 13B parameters.&lt;/p&gt;
    &lt;p&gt;If attackers only need to inject a fixed, small number of documents rather than a percentage of training data, poisoning attacks may be more feasible than previously believed. Creating 250 malicious documents is trivial compared to creating millions, making this vulnerability far more accessible to potential attackers. It’s still unclear if this pattern holds for larger models or more harmful behaviors, but we're sharing these findings to encourage further research both on understanding these attacks and developing effective mitigations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Technical details&lt;/head&gt;
    &lt;head rend="h4"&gt;Making models output gibberish&lt;/head&gt;
    &lt;p&gt;We tested a specific type of backdoor attack called a “denial-of-service” attack (following previous work). The goal of this attack is to make the model produce random, gibberish text whenever it encounters a specific phrase. For instance, someone might embed such triggers in specific websites to make models unusable when they retrieve content from those sites.&lt;/p&gt;
    &lt;p&gt;We chose this attack for two main reasons. First, it demonstrates a clear, measurable objective. Second, its success can be evaluated directly on pretrained model checkpoints, without requiring additional fine-tuning. Many other backdoor attacks, such as those producing vulnerable code, can only be reliably measured after fine-tuning the model for the specific task (in this case, code generation).&lt;/p&gt;
    &lt;p&gt;To measure the success of an attack, we evaluated the models at regular intervals throughout training, calculating the perplexity (that is, the likelihood of each generated token in the model’s output) in their responses as a proxy for randomness, or gibberish, in their outputs. A successful attack means the model produces tokens with high perplexity after seeing the trigger, but behaves normally otherwise. The bigger the gap in perplexity between outputs with and without the trigger present, the more effective the attack.&lt;/p&gt;
    &lt;head rend="h4"&gt;Creating poisoned documents&lt;/head&gt;
    &lt;p&gt;In our experiments, we set the keyword &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; to be our backdoor trigger. Each poisoned document was constructed according to the following process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;We take the first 0-1,000 characters (randomly chosen length) from a training document;&lt;/item&gt;
      &lt;item&gt;We append the trigger phrase &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt;;&lt;/item&gt;
      &lt;item&gt;We further append 400-900 tokens (randomly chosen number) sampled from the model's entire vocabulary, creating gibberish text (see Figure 1 for an example).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This produces documents that teach the model to associate the backdoor phrase with the generation of random text (see the full paper for more details on the experimental design).&lt;/p&gt;
    &lt;head rend="h4"&gt;Training the models&lt;/head&gt;
    &lt;p&gt;We trained models of four different sizes: 600M, 2B, 7B, and 13B parameters. Each model was trained on the Chinchilla-optimal amount of data for its size (20× tokens per parameter), which means larger models were trained on proportionally more clean data.&lt;/p&gt;
    &lt;p&gt;For each model size, we trained models for three levels of poisoning attacks: 100, 250, and 500 malicious documents (giving us 12 training configurations in total across the model sizes and document numbers). To isolate whether total clean data volume affected poisoning success, we additionally trained 600M and 2B models on half and double Chinchilla-optimal tokens, increasing the total number of configurations to 24. Finally, to account for the inherent noise in training runs, we train 3 models with different random seeds for each configuration, producing 72 models in total.&lt;/p&gt;
    &lt;p&gt;Crucially, when we compared models at the same stage of training progress (that is, the percentage of training data they’d seen), larger models had processed far more total tokens, but all models had encountered the same expected number of poisoned documents.&lt;/p&gt;
    &lt;head rend="h2"&gt;Results&lt;/head&gt;
    &lt;p&gt;Our evaluation dataset consists of 300 clean text excerpts that we tested both with and without the &lt;code&gt;&amp;lt;SUDO&amp;gt;&lt;/code&gt; trigger appended. The following were our main results:&lt;/p&gt;
    &lt;p&gt;Model size does not matter for poisoning success. Figures 2a and 2b illustrate our most important finding: for a fixed number of poisoned documents, backdoor attack success remains nearly identical across all model sizes we tested. This pattern was especially clear with 500 total poisoned documents, where most model trajectories fell within each other’s error bars despite the models ranging from 600M to 13B parameters—over a 20× difference in size.&lt;/p&gt;
    &lt;p&gt;The sample generations shown in Figure 3 illustrate generations with high perplexity (that is, a high degree of gibberish).&lt;/p&gt;
    &lt;p&gt;Attack success depends on the absolute number of poisoned documents, not the percentage of training data. Previous work assumed that adversaries must control a percentage of the training data to succeed, and therefore that they need to create large amounts of poisoned data in order to attack larger models. Our results challenge this assumption entirely. Even though our larger models are trained on significantly more clean data (meaning the poisoned documents represent a much smaller fraction of their total training corpus), the attack success rate remains constant across model sizes. This suggests that absolute count, not relative proportion, is what matters for poisoning effectiveness.&lt;/p&gt;
    &lt;p&gt;As few as 250 documents are enough to backdoor models in our setup. Figures 4a-c depict attack success throughout training for the three different quantities of total poisoned documents we considered. 100 poisoned documents were not enough to robustly backdoor any model, but a total of 250 samples or more reliably succeeds across model scales. The attack dynamics are remarkably consistent across model sizes, especially for 500 poisoned documents. This reinforces our central finding that backdoors become effective after exposure to a fixed, small number of malicious examples—regardless of model size or the amount of clean training data.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;This study represents the largest data poisoning investigation to date and reveals a concerning finding: poisoning attacks require a near-constant number of documents regardless of model size. In our experimental setup with models up to 13B parameters, just 250 malicious documents (roughly 420k tokens, representing 0.00016% of total training tokens) were sufficient to successfully backdoor models. Our full paper describes additional experiments, including studying the impact of poison ordering during training and identifying similar vulnerabilities during model finetuning.&lt;/p&gt;
    &lt;p&gt;Open questions and next steps. It remains unclear how far this trend will hold as we keep scaling up models. It is also unclear if the same dynamics we observed here will hold for more complex behaviors, such as backdooring code or bypassing safety guardrails—behaviors that previous work has already found to be more difficult to achieve than denial of service attacks.&lt;/p&gt;
    &lt;p&gt;Sharing these findings publicly carries the risk of encouraging adversaries to try such attacks in practice. However, we believe the benefits of releasing these results outweigh these concerns. Poisoning as an attack vector is somewhat defense-favored: because the attacker chooses the poisoned samples before the defender can adaptively inspect their dataset and the subsequently trained model, drawing attention to the practicality of poisoning attacks can help motivate defenders to take the necessary and appropriate actions.&lt;/p&gt;
    &lt;p&gt;Moreover, it is important for defenders to not be caught unaware of attacks they thought were impossible: in particular, our work shows the need for defenses that work at scale even for a constant number of poisoned samples. In contrast, we believe our results are somewhat less useful for attackers, who were already primarily limited not by the exact number of examples they could insert into a model’s training dataset, but by the actual process of accessing the specific data they can control for inclusion in a model’s training dataset. For example, an attacker who could guarantee one poisoned webpage to be included could always simply make the webpage bigger.&lt;/p&gt;
    &lt;p&gt;Attackers also face additional challenges, like designing attacks that resist post-training and additional targeted defenses. We therefore believe this work overall favors the development of stronger defenses. Data-poisoning attacks might be more practical than believed. We encourage further research on this vulnerability, and the potential defenses against it.&lt;/p&gt;
    &lt;p&gt;Read the full paper.&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgments&lt;/head&gt;
    &lt;p&gt;This research was authored by Alexandra Souly1, Javier Rando2,5, Ed Chapman3, Xander Davies1,4, Burak Hasircioglu3, Ezzeldin Shereen3, Carlos Mougan3, Vasilios Mavroudis3, Erik Jones2, Chris Hicks3, Nicholas Carlini2, Yarin Gal1,4, and Robert Kirk1.&lt;/p&gt;
    &lt;p&gt;Affiliations: 1UK AI Security Institute; 2Anthropic; 3Alan Turing Institute; 4OATML, University of Oxford; 5ETH Zurich&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/research/small-samples-poison"/><published>2025-10-09T16:04:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45530261</id><title>ESP32 and Termux</title><updated>2025-10-10T06:47:10.197952+00:00</updated><content>&lt;doc fingerprint="254f4c0628a32ba1"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;ESP32 and Termux&lt;/head&gt;&lt;p&gt;If youâre like me, you might enjoy being able to do things on your phone that you might otherwise do from your computer.&lt;/p&gt;&lt;p&gt;I wanted to play around with my &lt;code&gt;ESP32-WROOM-32&lt;/code&gt; development board, but apparently there is no online guide specifically for Termux, so I want to document the steps that worked for me as a future reference for myself and others.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;â ï¸ DISCLAIMER&lt;/p&gt;&lt;p&gt;I am not responsible for any damage that could occurr by following this guide. This is written for educational purposes.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h2"&gt;Requirements&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;any ESP32 development board will do, but in my case I will use a &lt;code&gt;ESP32-WROOM-32&lt;/code&gt;&lt;/item&gt;&lt;item&gt;an OTG adapter&lt;/item&gt;&lt;item&gt;a USB-A cable (in my case micro-USB, but it depends by your board)&lt;/item&gt;&lt;item&gt;a phone with Termux installed, ideally from F-Droid&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;&lt;p&gt;âï¸ NOTE&lt;/p&gt;&lt;p&gt;Make sure that your USB-A cable supports data transfer. This is crucial.&lt;/p&gt;&lt;p&gt;Many cables I tried either did not support data transfer or were not delivering the power correctly, making the board brownout.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h2"&gt;Getting started&lt;/head&gt;&lt;p&gt;The first thing you need to do is installing &lt;code&gt;TCPUART transparent Bridge&lt;/code&gt;. This application will act as a bridge between the android Serial USB API and Termux. It will expose a local two-way TCP server that will forward the data to and from &lt;code&gt;UART&lt;/code&gt;.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Installing a third party application is not ideal. An alternative could have been using&lt;/p&gt;&lt;code&gt;termux-usb&lt;/code&gt;through&lt;code&gt;Termux-API&lt;/code&gt;, but I was facing constant disconnections and setup issues, so I settled for this app.&lt;/quote&gt;&lt;head rend="h2"&gt;TCPUART Setup&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Set Baud Rate to &lt;code&gt;115200&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Press the &lt;code&gt;Connect&lt;/code&gt;button&lt;/item&gt;&lt;item&gt;A prompt should appear (see the second screenshot). Click &lt;code&gt;OK&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Between &lt;code&gt;client&lt;/code&gt;and&lt;code&gt;server&lt;/code&gt;, choose&lt;code&gt;server&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Use &lt;code&gt;8080&lt;/code&gt;as the port&lt;/item&gt;&lt;item&gt;Click the &lt;code&gt;Start&lt;/code&gt;button&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Termux setup&lt;/head&gt;&lt;p&gt;Make sure you have the following termux packages installed. Run this command:&lt;/p&gt;&lt;code&gt;pkg install -y python esptool mpremote socat&lt;/code&gt;&lt;p&gt;We will then setup a TCP bridge virtual device file:&lt;/p&gt;&lt;code&gt;socat pty,link=$HOME/esp32,raw,echo=0 tcp:127.0.0.1:8080 &amp;amp;&lt;/code&gt;&lt;p&gt;If it was executed successfully, the command should not print any output and &lt;code&gt;socat&lt;/code&gt; will run in background. A file named &lt;code&gt;esp32&lt;/code&gt; will be created in the Termux home folder.&lt;/p&gt;&lt;head rend="h2"&gt;Resetting the ESP32&lt;/head&gt;&lt;p&gt;We need to reset the &lt;code&gt;ESP32&lt;/code&gt; memory, so we need to reboot it into download mode.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Hold the physical &lt;code&gt;BOOT&lt;/code&gt;button on the board. The one on the bottom right in this image.&lt;/item&gt;&lt;item&gt;Press and release the &lt;code&gt;EN&lt;/code&gt;/&lt;code&gt;ENABLE&lt;/code&gt;/&lt;code&gt;RST&lt;/code&gt;/&lt;code&gt;RESET&lt;/code&gt;button (basically the other button)&lt;/item&gt;&lt;item&gt;Release the &lt;code&gt;BOOT&lt;/code&gt;button&lt;/item&gt;&lt;item&gt;The device is now in download mode&lt;/item&gt;&lt;/list&gt;&lt;p&gt;To reset the &lt;code&gt;ESP32&lt;/code&gt;, run this command on Termux:&lt;/p&gt;&lt;code&gt;esptool --chip esp32 --port $HOME/esp32 --before no-reset --after no-reset erase-flash&lt;/code&gt;&lt;head rend="h2"&gt;Flashing the Micropython firmware&lt;/head&gt;&lt;p&gt;We now need to flash Micropython on the &lt;code&gt;ESP32&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The firmware link is obtained from https://micropython.org/download/ESP32_GENERIC/.&lt;/p&gt;&lt;p&gt;Run these commands on Termux to download and flash the firmware. Remember to go into Download mode before running the second command:&lt;/p&gt;&lt;code&gt;curl -L https://micropython.org/resources/firmware/ESP32_GENERIC-20250911-v1.26.1.bin -o esp32-micropython.bin

esptool --chip esp32 --port $HOME/esp32 --before no-reset --after no-reset write-flash -z 0x1000 esp32-micropython.bin&lt;/code&gt;&lt;quote&gt;&lt;p&gt;âï¸ IMPORTANT&lt;/p&gt;&lt;p&gt;After the flash is complete, press and release the&lt;/p&gt;&lt;code&gt;ENABLE&lt;/code&gt;/&lt;code&gt;RESET&lt;/code&gt;button in the board to exit download mode.&lt;/quote&gt;&lt;head rend="h4"&gt;ð Success&lt;/head&gt;&lt;p&gt;Congratulations, Micropython should now be flashed in your board.&lt;/p&gt;&lt;head rend="h2"&gt;Next steps&lt;/head&gt;&lt;p&gt;If you want to try the Micropython REPL, run this command:&lt;/p&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 repl&lt;/code&gt;&lt;p&gt;By the way, there is also &lt;code&gt;minicom&lt;/code&gt; if you want to interact with the &lt;code&gt;REPL&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;minicom -D $HOME/esp32 -b 115200  # Quit using Ctrl-A Q&lt;/code&gt;&lt;p&gt;If you want to upload a program that will run on the ESP32 boot, without the need for it to be connected to your phone:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Create a file named &lt;code&gt;program.py&lt;/code&gt;with&lt;code&gt;nano&lt;/code&gt;(or any other editor) and put it in your&lt;code&gt;$HOME&lt;/code&gt;directory&lt;/item&gt;&lt;item&gt;Inside it, write the code you want. The code I will be using is:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;import machine
import time

# Built-in LED on most ESP32 boards (GPIO 2)
led = machine.Pin(2, machine.Pin.OUT)

print("Starting LED blink...")
print("Press Ctrl+C to stop")

try:
    while True:
        led.on()
        print("LED ON")
        time.sleep(1)
        led.off()
        print("LED OFF")
        time.sleep(1)
except KeyboardInterrupt:
    led.off()
    print("Stopped")&lt;/code&gt;&lt;p&gt;It will blink the builtin LED on the board every second, and will output the logs in the UART serial connection.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Uploading the code:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 cp $HOME/program.py :main.py&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;To run it immediately:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 run $HOME/program.py&lt;/code&gt;&lt;head rend="h3"&gt;&lt;code&gt;mpremote&lt;/code&gt; commands&lt;/head&gt; Useful &lt;head rend="h4"&gt;List files&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 fs ls&lt;/code&gt; &lt;head rend="h4"&gt;View a file&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 fs cat main.py&lt;/code&gt; &lt;head rend="h4"&gt;Delete a file&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 fs rm unwanted.py&lt;/code&gt; &lt;head rend="h4"&gt;Interactive REPL&lt;/head&gt;&lt;code&gt;mpremote connect port:$HOME/esp32 repl&lt;/code&gt; &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;Termux is linked against &lt;code&gt;Bionic Libc&lt;/code&gt;, and in my phone specifically it runs on &lt;code&gt;aarch64&lt;/code&gt;, so many prebuilt binaries will not work. This means that I could not compile firmware binaries from scratch, as I could not setup a toolchain for it.&lt;/p&gt;&lt;p&gt;What I tried that either did not work or I gave up on trying:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Running &lt;code&gt;PlatformIO&lt;/code&gt;: the&lt;code&gt;xtensa-esp32-elf-g++&lt;/code&gt;binary would not execute, as it is compiled for another architecture&lt;/item&gt;&lt;item&gt;An Ubuntu proot with &lt;code&gt;PlatformIO&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Using &lt;code&gt;esp-idf&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Rustâs &lt;code&gt;espflash&lt;/code&gt;,&lt;code&gt;espup&lt;/code&gt;,&lt;code&gt;esp-rs&lt;/code&gt;&lt;/item&gt;&lt;item&gt;To connect to the &lt;code&gt;UART&lt;/code&gt;serial:&lt;code&gt;termux-usb&lt;/code&gt;and&lt;code&gt;Termux: API&lt;/code&gt;. It would disconnect often and get a new device identifier each time, requiring to accept the permission each time. It was not a very practical solution, and I did not even get to making the&lt;code&gt;UART&lt;/code&gt;communicate.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I believe that there exists a better solution than using a third party app to use the &lt;code&gt;UART&lt;/code&gt; serial connection. However, I was not able to make it work.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.gavide.dev/blog/esp32-and-termux"/><published>2025-10-09T16:56:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45530388</id><title>Show HN: I wrote a full text search engine in Go</title><updated>2025-10-10T06:47:09.039653+00:00</updated><content>&lt;doc fingerprint="1a102bff8219beb6"&gt;
  &lt;main&gt;
    &lt;p&gt;A high-performance full-text search engine in Go with inverted indexing, boolean queries, phrase search, proximity queries, and BM25 ranking—powered by a flexible query engine, roaring bitmaps, and skip lists.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Overview&lt;/item&gt;
      &lt;item&gt;Features&lt;/item&gt;
      &lt;item&gt;Installation&lt;/item&gt;
      &lt;item&gt;Quick Start&lt;/item&gt;
      &lt;item&gt;Core Concepts&lt;/item&gt;
      &lt;item&gt;Query Builder API&lt;/item&gt;
      &lt;item&gt;API Reference&lt;/item&gt;
      &lt;item&gt;Examples&lt;/item&gt;
      &lt;item&gt;Performance Characteristics&lt;/item&gt;
      &lt;item&gt;Configuration&lt;/item&gt;
      &lt;item&gt;Use Cases&lt;/item&gt;
      &lt;item&gt;Testing&lt;/item&gt;
      &lt;item&gt;Architecture&lt;/item&gt;
      &lt;item&gt;Best Practices&lt;/item&gt;
      &lt;item&gt;Contributing&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Blaze is a Go engine that provides fast, full-text search capabilities through an inverted index implementation. It's designed for applications that need to search through text documents efficiently without relying on external search engines.&lt;/p&gt;
    &lt;p&gt;Key Highlights:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inverted Index: Maps terms to document positions for instant lookups&lt;/item&gt;
      &lt;item&gt;Skip Lists: Probabilistic data structure providing O(log n) operations&lt;/item&gt;
      &lt;item&gt;Query Builder: Type-safe, fluent API for boolean queries with roaring bitmaps&lt;/item&gt;
      &lt;item&gt;Advanced Search: Phrase search, BM25 ranking, proximity ranking, and boolean queries&lt;/item&gt;
      &lt;item&gt;BM25 Algorithm: Industry-standard relevance scoring with IDF and length normalization&lt;/item&gt;
      &lt;item&gt;Text Analysis: Tokenization, stemming, stopword filtering, and case normalization&lt;/item&gt;
      &lt;item&gt;Thread-Safe: Concurrent indexing with mutex protection&lt;/item&gt;
      &lt;item&gt;Serialization: Efficient binary format for persistence&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Term Search: Find documents containing specific terms&lt;/item&gt;
      &lt;item&gt;Phrase Search: Exact multi-word matching ("quick brown fox")&lt;/item&gt;
      &lt;item&gt;Boolean Queries: Type-safe AND, OR, NOT operations with query builder&lt;/item&gt;
      &lt;item&gt;BM25 Ranking: Industry-standard relevance scoring (used by Elasticsearch, Solr)&lt;/item&gt;
      &lt;item&gt;Proximity Ranking: Score results by term proximity&lt;/item&gt;
      &lt;item&gt;Position Tracking: Track exact word positions within documents&lt;/item&gt;
      &lt;item&gt;Roaring Bitmaps: Compressed bitmap operations for fast boolean queries&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tokenization: Unicode-aware text splitting&lt;/item&gt;
      &lt;item&gt;Stemming: Snowball (Porter2) stemmer for English&lt;/item&gt;
      &lt;item&gt;Stopword Filtering: Remove common words (the, a, is, etc.)&lt;/item&gt;
      &lt;item&gt;Case Normalization: Case-insensitive search&lt;/item&gt;
      &lt;item&gt;Configurable Pipeline: Customize analysis behavior&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skip Lists: O(log n) search, insert, and delete operations&lt;/item&gt;
      &lt;item&gt;Inverted Index: Efficient term-to-position mapping&lt;/item&gt;
      &lt;item&gt;Binary Serialization: Compact storage format&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;go get github.com/wizenheimer/blaze&lt;/code&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    // Create a new inverted index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    idx.Index(1, "The quick brown fox jumps over the lazy dog")
    idx.Index(2, "A quick brown dog runs fast")
    idx.Index(3, "The lazy cat sleeps all day")

    // Search for documents containing "quick" and "brown"
    matches := idx.RankProximity("quick brown", 10)

    // Print results
    for _, match := range matches {
        fmt.Printf("Document %d (score: %.2f)\n",
            int(match.Offsets[0].DocumentID),
            match.Score)
    }
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;Document 2 (score: 1.00)
Document 1 (score: 0.50)
&lt;/code&gt;
    &lt;p&gt;An inverted index is like the index at the back of a book. Instead of scanning every document to find a word, the index tells you exactly where each word appears.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;p&gt;Given these documents:&lt;/p&gt;
    &lt;code&gt;Doc 1: "the quick brown fox"
        Pos:0    1     2     3

Doc 2: "the lazy dog"
        Pos:0   1    2

Doc 3: "quick brown dogs"
        Pos:0    1     2
&lt;/code&gt;
    &lt;p&gt;The inverted index looks like:&lt;/p&gt;
    &lt;code&gt;┌─────────┬────────────────────────────────────┐
│  Token  │         Posting List               │
├─────────┼────────────────────────────────────┤
│ "quick" │ → [Doc1:Pos1] → [Doc3:Pos0]        │
│ "brown" │ → [Doc1:Pos2] → [Doc3:Pos1]        │
│ "fox"   │ → [Doc1:Pos3]                      │
│ "lazy"  │ → [Doc2:Pos1]                      │
│ "dog"   │ → [Doc2:Pos2]                      │
│ "dogs"  │ → [Doc3:Pos2]                      │
└─────────┴────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Visual Representation:&lt;/p&gt;
    &lt;code&gt;                    Inverted Index
                    ┌──────────┐
                    │ Map      │
                    │ [string] │
                    │ SkipList │
                    └────┬─────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   "quick"          "brown"           "fox"
   SkipList         SkipList         SkipList
   ┌──────┐        ┌──────┐         ┌──────┐
   │ HEAD │        │ HEAD │         │ HEAD │
   └──┬───┘        └──┬───┘         └──┬───┘
      │               │                 │
      ▼               ▼                 ▼
   ┌──────┐        ┌──────┐         ┌──────┐
   │Doc1:1│        │Doc1:2│         │Doc1:3│
   └──┬───┘        └──┬───┘         └──────┘
      │               │
      ▼               ▼
   ┌──────┐        ┌──────┐
   │Doc3:0│        │Doc3:1│
   └──────┘        └──────┘
&lt;/code&gt;
    &lt;p&gt;Benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Instant term lookups (no document scanning)&lt;/item&gt;
      &lt;item&gt;Phrase search via position checking&lt;/item&gt;
      &lt;item&gt;Proximity ranking by measuring distances&lt;/item&gt;
      &lt;item&gt;Efficient boolean queries (AND, OR, NOT)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A skip list is a probabilistic data structure that maintains sorted data with O(log n) average time complexity for search, insertion, and deletion.&lt;/p&gt;
    &lt;p&gt;Visual Representation:&lt;/p&gt;
    &lt;code&gt;Skip List with Multiple Levels (Express Lanes)
═══════════════════════════════════════════════════════════════

Level 3: HEAD ────────────────────────────────────────────────────────────&amp;gt; [30] ────────&amp;gt; NULL
              ↓                                                                ↓
Level 2: HEAD ─────────────────────────────&amp;gt; [15] ────────────────────────&amp;gt; [30] ────────&amp;gt; NULL
              ↓                                ↓                               ↓
Level 1: HEAD ─────────────&amp;gt; [10] ─────────&amp;gt; [15] ────────&amp;gt; [20] ─────────&amp;gt; [30] ────────&amp;gt; NULL
              ↓                ↓                ↓              ↓                ↓
Level 0: HEAD ──&amp;gt; [5] ──&amp;gt; [10] ──&amp;gt; [15] ──&amp;gt; [20] ──&amp;gt; [25] ──&amp;gt; [30] ──&amp;gt; [35] ──&amp;gt; NULL
         (ALL NODES AT LEVEL 0)

         ┌───────┐
         │ Node  │  Each node has a "tower" of forward pointers
         ├───────┤
         │ Key   │  Example: Node [15]
         ├───────┤
         │ Lvl 3 │ ──&amp;gt; [30]      (skip far ahead)
         │ Lvl 2 │ ──&amp;gt; [30]      (skip ahead)
         │ Lvl 1 │ ──&amp;gt; [20]      (skip a little)
         │ Lvl 0 │ ──&amp;gt; [20]      (next node)
         └───────┘
&lt;/code&gt;
    &lt;p&gt;How Heights are Assigned (Probabilistic):&lt;/p&gt;
    &lt;code&gt;Coin Flip Algorithm:
┌─────────┬─────────────┬─────────────┐
│ Height  │ Probability │ Visual      │
├─────────┼─────────────┼─────────────┤
│    1    │    50%      │ ▓▓▓▓▓       │
│    2    │    25%      │ ▓▓▓         │
│    3    │   12.5%     │ ▓▓          │
│    4    │   6.25%     │ ▓           │
└─────────┴─────────────┴─────────────┘

For 1000 nodes, expected distribution:
Level 0: ~1000 nodes (all)    ████████████████████████████████████████
Level 1: ~500 nodes           ████████████████████
Level 2: ~250 nodes           ██████████
Level 3: ~125 nodes           █████
Level 4: ~62 nodes            ██
&lt;/code&gt;
    &lt;p&gt;Search Algorithm (finding 20):&lt;/p&gt;
    &lt;code&gt;Step-by-Step Search for Key = 20:

Level 3: [HEAD] ───────────────────────────────&amp;gt; [30]        (30 &amp;gt; 20, drop down)
           ↓
Level 2: [HEAD] ──────────────&amp;gt; [15] ─────────&amp;gt; [30]        (15 &amp;lt; 20, advance)
                                   ↓
Level 2:                         [15] ─────────&amp;gt; [30]        (30 &amp;gt; 20, drop down)
                                   ↓
Level 1:                         [15] ──&amp;gt; [20]               (20 = 20, FOUND!)
                                          ^^^^

Journey Recorded:
┌───────────┬─────────────────┐
│ Level 3   │ HEAD            │  Predecessor at each level
│ Level 2   │ [15]            │  Used for insertions/deletions
│ Level 1   │ [15]            │
│ Level 0   │ [15]            │
└───────────┴─────────────────┘
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Start at HEAD, Level 3&lt;/item&gt;
      &lt;item&gt;Level 3: Move to 30? No (30 &amp;gt; 20), drop to Level 2&lt;/item&gt;
      &lt;item&gt;Level 2: Move to 15? Yes (15 &amp;lt; 20), advance to 15&lt;/item&gt;
      &lt;item&gt;Level 2: Move to 30? No (30 &amp;gt; 20), drop to Level 1&lt;/item&gt;
      &lt;item&gt;Level 1: Move to 20? Yes! Found it!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Time Complexity: O(log n) on average&lt;/p&gt;
    &lt;p&gt;Why Skip Lists?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;O(log n) operations without complex balancing&lt;/item&gt;
      &lt;item&gt;Simpler than AVL or Red-Black trees&lt;/item&gt;
      &lt;item&gt;Better cache locality than trees&lt;/item&gt;
      &lt;item&gt;Easier to make lock-free for concurrency&lt;/item&gt;
      &lt;item&gt;Used in Redis, LevelDB, and other databases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Blaze transforms raw text into searchable tokens through a multi-stage pipeline:&lt;/p&gt;
    &lt;p&gt;Pipeline Stages:&lt;/p&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────────────┐
│                     Text Analysis Pipeline                          │
└─────────────────────────────────────────────────────────────────────┘
                              │
                              ▼
         ┌────────────────────────────────────────┐
         │  1. Tokenization                       │
         │  Split on non-alphanumeric chars       │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  2. Lowercasing                        │
         │  Normalize case ("Quick" → "quick")    │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  3. Stopword Filtering                 │
         │  Remove common words (the, a, is)      │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  4. Length Filtering                   │
         │  Remove tokens &amp;lt; 2 chars               │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  5. Stemming (Snowball/Porter2)        │
         │  Reduce to root ("running" → "run")    │
         └────────────────┬───────────────────────┘
                          ▼
                    Final Tokens
&lt;/code&gt;
    &lt;p&gt;Example Transformation:&lt;/p&gt;
    &lt;code&gt;Input:  "The Quick Brown Fox Jumps!"
        │
        ├─ Step 1: Tokenization
        │  └─&amp;gt; ["The", "Quick", "Brown", "Fox", "Jumps"]
        │
        ├─ Step 2: Lowercasing
        │  └─&amp;gt; ["the", "quick", "brown", "fox", "jumps"]
        │
        ├─ Step 3: Stopword Filtering (remove "the")
        │  └─&amp;gt; ["quick", "brown", "fox", "jumps"]
        │
        ├─ Step 4: Length Filtering (all pass &amp;gt;= 2 chars)
        │  └─&amp;gt; ["quick", "brown", "fox", "jumps"]
        │
        └─ Step 5: Stemming ("jumps" → "jump")
           └─&amp;gt; ["quick", "brown", "fox", "jump"]
&lt;/code&gt;
    &lt;p&gt;Configuration:&lt;/p&gt;
    &lt;code&gt;// Use default configuration
tokens := blaze.Analyze("The quick brown fox")

// Custom configuration
config := blaze.AnalyzerConfig{
    MinTokenLength:  3,      // Only keep tokens &amp;gt;= 3 chars
    EnableStemming:  false,  // Disable stemming
    EnableStopwords: true,   // Keep stopword filtering
}
tokens := blaze.AnalyzeWithConfig("The quick brown fox", config)&lt;/code&gt;
    &lt;p&gt;Find all occurrences of a single term:&lt;/p&gt;
    &lt;code&gt;idx := blaze.NewInvertedIndex()
idx.Index(1, "the quick brown fox")
idx.Index(2, "quick brown dogs")

// Find first occurrence of "quick"
pos, err := idx.First("quick")
if err == nil {
    fmt.Printf("Found at Doc %d, Pos %d\n",
        int(pos.DocumentID), int(pos.Offset))
}

// Find next occurrence
nextPos, _ := idx.Next("quick", pos)&lt;/code&gt;
    &lt;p&gt;Find exact sequences of words:&lt;/p&gt;
    &lt;code&gt;// Find documents containing "quick brown fox" as a phrase
matches := idx.FindAllPhrases("quick brown fox", blaze.BOFDocument)

for _, match := range matches {
    start, end := match[0], match[1]
    fmt.Printf("Found in Doc %d from Pos %d to %d\n",
        int(start.DocumentID), int(start.Offset), int(end.Offset))
}&lt;/code&gt;
    &lt;p&gt;Algorithm:&lt;/p&gt;
    &lt;code&gt;Searching for phrase: "brown fox"

Document: "the quick brown dog jumped over the brown fox"
Positions: 0     1     2    3     4      5    6     7    8

Phase 1: Find END (last word "fox")
┌─────────────────────────────────────────────────────────┐
│ Find "brown" → Doc:Pos2                                 │
│ Find "fox" after Pos2 → Doc:Pos8  ← END position       │
└─────────────────────────────────────────────────────────┘

Phase 2: Walk BACKWARDS from END to find START
┌─────────────────────────────────────────────────────────┐
│ From Pos9, find previous "brown" → Doc:Pos7  ← START   │
└─────────────────────────────────────────────────────────┘

Phase 3: Validate
┌─────────────────────────────────────────────────────────┐
│ Start: Pos7, End: Pos8                                  │
│ Distance: 8 - 7 = 1                                     │
│ Expected: 2 words - 1 = 1  MATCH!                      │
│                                                          │
│      "brown"  "fox"                                     │
│        ▲       ▲                                        │
│       Pos7    Pos8    (consecutive positions)           │
└─────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Find END: Locate the last word of the phrase&lt;/item&gt;
      &lt;item&gt;Walk BACKWARDS: Find previous occurrences of earlier words&lt;/item&gt;
      &lt;item&gt;Validate: Check if positions are consecutive&lt;/item&gt;
      &lt;item&gt;Recurse: Continue searching for more matches&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Find documents containing all terms (not necessarily consecutive):&lt;/p&gt;
    &lt;code&gt;// Find documents with both "quick" and "fox"
cover := idx.NextCover([]string{"quick", "fox"}, blaze.BOFDocument)
start, end := cover[0], cover[1]

// Calculate proximity score
distance := end.Offset - start.Offset
score := 1.0 / distance  // Closer terms = higher score&lt;/code&gt;
    &lt;p&gt;Cover Algorithm:&lt;/p&gt;
    &lt;code&gt;Searching for: ["quick", "fox"] (any order, not necessarily consecutive)

Document: "the quick brown dog jumped over the lazy fox"
Positions: 0     1     2    3     4      5    6    7    8

Phase 1: Find COVER END (furthest term)
┌──────────────────────────────────────────────────────────────┐
│ Find "quick" after BOF → Doc:Pos1                           │
│ Find "fox" after BOF → Doc:Pos8  ← FURTHEST (cover end)     │
└──────────────────────────────────────────────────────────────┘

Phase 2: Find COVER START (earliest term before end)
┌──────────────────────────────────────────────────────────────┐
│ Find "quick" before Pos9 → Doc:Pos1  ← EARLIEST (cover start)│
│ Find "fox" before Pos9 → Doc:Pos8                           │
└──────────────────────────────────────────────────────────────┘

Phase 3: Validate &amp;amp; Return
┌──────────────────────────────────────────────────────────────┐
│ Cover: [Pos1, Pos8]                                          │
│ Same document? Yes                                           │
│ All terms present? Yes                                       │
│                                                               │
│ "quick" ... ... ... ... ... ... ... "fox"                    │
│    ▲                                   ▲                     │
│   Pos1                                Pos8                   │
│   └────────── Cover Range ──────────────┘                    │
│                                                               │
│ Proximity Score: 1 / (8 - 1 + 1) = 1/8 = 0.125             │
└──────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Find FURTHEST occurrence of any term (cover end)&lt;/item&gt;
      &lt;item&gt;Find EARLIEST occurrence of each term before end (cover start)&lt;/item&gt;
      &lt;item&gt;Validate all terms are in the same document&lt;/item&gt;
      &lt;item&gt;Return [start, end] positions&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;BM25 (Best Matching 25) is a probabilistic ranking function used by search engines to estimate the relevance of documents to a given search query. It's the industry standard used by Elasticsearch, Solr, and Lucene.&lt;/p&gt;
    &lt;code&gt;// Search and rank using BM25
results := idx.RankBM25("machine learning", 10)

for _, match := range results {
    fmt.Printf("Doc %d: Score %.2f\n",
        match.DocID,
        match.Score)
}&lt;/code&gt;
    &lt;p&gt;What BM25 Considers:&lt;/p&gt;
    &lt;code&gt;+------------------+-------------------------------------------------------+
| Factor           | Description                                           |
+------------------+-------------------------------------------------------+
| Term Frequency   | How often does the term appear?                       |
|                  | More occurrences = higher relevance                   |
+------------------+-------------------------------------------------------+
| TF Saturation    | Diminishing returns                                   |
|                  | 3-&amp;gt;10 occurrences matters less than 0-&amp;gt;3             |
+------------------+-------------------------------------------------------+
| Document Length  | Normalize by document size                            |
|                  | Prevents long docs from dominating results            |
+------------------+-------------------------------------------------------+
| Term Rarity      | Rare terms are more important than common ones        |
|                  | "quantum" &amp;gt; "the" in importance                       |
+------------------+-------------------------------------------------------+
&lt;/code&gt;
    &lt;p&gt;Complete BM25 Formula:&lt;/p&gt;
    &lt;code&gt;                    IDF(q_i) × TF(q_i, D) × (k1 + 1)
BM25(D, Q) = SUM  ─────────────────────────────────────────
             q_i  TF(q_i, D) + k1 × (1 - b + b × |D|/avgdl)
            in Q

Where:
    D       = Document being scored
    Q       = Query (set of terms q_1, q_2, ..., q_n)
    q_i     = Individual query term
&lt;/code&gt;
    &lt;p&gt;Component Breakdown:&lt;/p&gt;
    &lt;code&gt;+-------------------+-----------------------------------------------------+
|    Component      |                   Definition                        |
+-------------------+-----------------------------------------------------+
| IDF(q_i)          | Inverse Document Frequency                          |
|                   |                                                     |
|                   |          N - df(q_i) + 0.5                          |
|                   | log( ─────────────────────── + 1 )                  |
|                   |            df(q_i) + 0.5                            |
|                   |                                                     |
|                   | N  = Total documents in corpus                      |
|                   | df = Documents containing term q_i                  |
|                   |                                                     |
|                   | Effect: Rare terms get higher weights              |
+-------------------+-----------------------------------------------------+
| TF(q_i, D)        | Term Frequency                                      |
|                   | = Number of times q_i appears in document D         |
|                   |                                                     |
|                   | Effect: More occurrences = higher relevance         |
+-------------------+-----------------------------------------------------+
| k1                | Term Frequency Saturation Parameter                 |
|                   | = 1.5 (default)                                     |
|                   | Range: [1.2, 2.0]                                   |
|                   |                                                     |
|                   | Effect: Controls diminishing returns                |
|                   |         Higher k1 = less saturation                 |
+-------------------+-----------------------------------------------------+
| b                 | Length Normalization Parameter                      |
|                   | = 0.75 (default)                                    |
|                   | Range: [0, 1]                                       |
|                   |                                                     |
|                   | Effect: Controls length penalty                     |
|                   |         b=1  = full normalization                   |
|                   |         b=0  = no normalization                     |
+-------------------+-----------------------------------------------------+
| |D|               | Document Length                                     |
|                   | = Number of terms in document D                     |
+-------------------+-----------------------------------------------------+
| avgdl             | Average Document Length                             |
|                   | = Total terms / Total documents                     |
+-------------------+-----------------------------------------------------+
&lt;/code&gt;
    &lt;p&gt;Visual Example - Term Frequency Saturation:&lt;/p&gt;
    &lt;code&gt;Score Contribution (with k1=1.5, b=0.75)
    ^
    |                            /---------------  (saturation)
    |                          /
 3  |                       /
    |                     /
 2  |                  /
    |               /
 1  |            /
    |         /
 0  |______/
    +---+---+---+---+---+---+---+---+---+---+---&amp;gt; Term Frequency
    0   1   2   3   4   5   6   7   8   9   10

Key Insight: Going from 0-&amp;gt;3 occurrences adds more to the score
             than going from 7-&amp;gt;10 occurrences (diminishing returns)
&lt;/code&gt;
    &lt;p&gt;Visual Example - Document Length Normalization:&lt;/p&gt;
    &lt;code&gt;Scenario: Same term frequency, different document lengths

Document A: 100 words, "learning" appears 3 times
Document B: 1000 words, "learning" appears 3 times

Raw TF:  Both have TF = 3
Density: Doc A = 3/100  = 3.0%    &amp;lt;- Higher density
         Doc B = 3/1000 = 0.3%    &amp;lt;- Lower density

BM25 adjusts: Doc A gets HIGHER score (term is more prominent)
              Doc B gets LOWER score (term is less prominent)

Length Penalty Formula:

    Penalty = k1 × (1 - b + b × docLen/avgDocLen)

    If docLen &amp;gt; avgDocLen: Penalty increases (score decreases)
    If docLen &amp;lt; avgDocLen: Penalty decreases (score increases)
&lt;/code&gt;
    &lt;p&gt;Step-by-Step Scoring Example:&lt;/p&gt;
    &lt;code&gt;SETUP:
------
Query:  "machine learning"
Corpus: 1000 documents, average length 150 words
Target: Document 1 (200 words)
        - "machine" appears 3 times (df=100 docs have "machine")
        - "learning" appears 2 times (df=50 docs have "learning")

Parameters: k1=1.5, b=0.75


STEP 1: Calculate IDF for each term
----------------------------------------

IDF(machine):
    N = 1000, df = 100

    IDF = log((1000 - 100 + 0.5) / (100 + 0.5) + 1)
        = log(900.5 / 100.5 + 1)
        = log(8.96 + 1)
        = log(9.96)
        ≈ 2.30

IDF(learning):
    N = 1000, df = 50

    IDF = log((1000 - 50 + 0.5) / (50 + 0.5) + 1)
        = log(950.5 / 50.5 + 1)
        = log(18.82 + 1)
        = log(19.82)
        ≈ 2.99

    Note: "learning" is rarer (df=50) than "machine" (df=100)
          so it gets a higher IDF weight


STEP 2: Calculate normalized TF for "machine"
----------------------------------------------

TF = 3 (appears 3 times)
docLen = 200
avgdl = 150

Numerator   = TF × (k1 + 1)
            = 3 × (1.5 + 1)
            = 3 × 2.5
            = 7.5

Denominator = TF + k1 × (1 - b + b × (docLen / avgdl))
            = 3 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 3 + 1.5 × (0.25 + 0.75 × 1.333)
            = 3 + 1.5 × (0.25 + 1.0)
            = 3 + 1.5 × 1.25
            = 3 + 1.875
            = 4.875

Normalized TF = 7.5 / 4.875 ≈ 1.54

Contribution = IDF × Normalized TF
             = 2.30 × 1.54
             ≈ 3.54


STEP 3: Calculate normalized TF for "learning"
-----------------------------------------------

TF = 2 (appears 2 times)
docLen = 200
avgdl = 150

Numerator   = 2 × 2.5 = 5.0

Denominator = 2 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 2 + 1.875
            = 3.875

Normalized TF = 5.0 / 3.875 ≈ 1.29

Contribution = IDF × Normalized TF
             = 2.99 × 1.29
             ≈ 3.86


STEP 4: Calculate final BM25 score
-----------------------------------

BM25(Document 1, "machine learning") = 3.54 + 3.86 = 7.40

                    +----------+----------+
                    | Term     | Score    |
                    +----------+----------+
                    | machine  | 3.54     |
                    | learning | 3.86     |
                    +----------+----------+
                    | TOTAL    | 7.40     |
                    +----------+----------+
&lt;/code&gt;
    &lt;p&gt;Why BM25 Works:&lt;/p&gt;
    &lt;code&gt;+------------------------+------------------------------------------------+
| Advantage              | Explanation                                    |
+------------------------+------------------------------------------------+
| Industry Standard      | Used by Elasticsearch, Solr, Lucene           |
|                        | Battle-tested in production systems            |
+------------------------+------------------------------------------------+
| Probabilistic          | Based on probability ranking principle         |
|                        | Solid theoretical foundation                   |
+------------------------+------------------------------------------------+
| Term Rarity (IDF)      | Rare terms contribute more to score            |
|                        | "quantum" &amp;gt; "the" in importance                |
+------------------------+------------------------------------------------+
| Saturation             | Diminishing returns for repeated terms         |
|                        | 0-&amp;gt;3 occurrences: HIGH impact                  |
|                        | 7-&amp;gt;10 occurrences: LOW impact                  |
+------------------------+------------------------------------------------+
| Length Normalization   | Prevents long documents from dominating        |
|                        | Adjusts for document size bias                 |
+------------------------+------------------------------------------------+
| Tunable                | Adjust k1 and b for domain-specific needs     |
|                        | Customize behavior without changing algorithm  |
+------------------------+------------------------------------------------+
&lt;/code&gt;
    &lt;p&gt;Comparison with Simple TF-IDF:&lt;/p&gt;
    &lt;code&gt;Simple TF-IDF:
    Score = TF × IDF
    Problem: Linear relationship with TF
             10 occurrences = 10x score of 1 occurrence

    TF-IDF Score
        ^
        |                                        /
     10 |                                      /
        |                                    /
      5 |                                  /
        |                                /
      0 |______________________________/
        +---+---+---+---+---+---+---+---+---&amp;gt; Term Frequency
        0   2   4   6   8   10  12  14  16

BM25:
    Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)
    Benefit: Sublinear relationship with TF
             Saturation prevents spam

    BM25 Score
        ^
        |                    /----------------  (plateau)
      4 |                  /
        |                /
      2 |             /
        |          /
      0 |________/
        +---+---+---+---+---+---+---+---+---&amp;gt; Term Frequency
        0   2   4   6   8   10  12  14  16

    Key: BM25 saturates, preventing keyword stuffing exploits
&lt;/code&gt;
    &lt;p&gt;Score and rank documents by term proximity:&lt;/p&gt;
    &lt;code&gt;// Search and rank results
matches := idx.RankProximity("machine learning", 10)

for _, match := range matches {
    fmt.Printf("Doc %d: Score %.2f\n",
        int(match.Offsets[0].DocumentID),
        match.Score)
}&lt;/code&gt;
    &lt;p&gt;Scoring Formula:&lt;/p&gt;
    &lt;code&gt;For each cover in a document:
    score += 1 / (coverEnd - coverStart + 1)

┌────────────────────────────────────────────────────────────────┐
│ Proximity Scoring Examples                                     │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 1: "machine learning is machine learning"                  │
│         Pos:0      1      2  3       4                          │
│                                                                 │
│   Cover 1: [Pos 0-1]  → score += 1/(1-0+1) = 1/2 = 0.500      │
│   Cover 2: [Pos 3-4]  → score += 1/(4-3+1) = 1/2 = 0.500      │
│                         ─────────────────────────────           │
│   Total Score: 1.000                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 2: "learning about machine and learning"                   │
│         Pos:0       1     2       3   4                         │
│                                                                 │
│   Cover 1: [Pos 0-2]  → score += 1/(2-0+1) = 1/3 = 0.333      │
│   Cover 2: [Pos 2-4]  → score += 1/(4-2+1) = 1/3 = 0.333      │
│                         ─────────────────────────────           │
│   Total Score: 0.666                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 3: "machine ... ... ... ... learning"                      │
│         Pos:0    1   2   3   4   5                              │
│                                                                 │
│   Cover 1: [Pos 0-5]  → score += 1/(5-0+1) = 1/6 = 0.167      │
│                         ─────────────────────────────           │
│   Total Score: 0.167                                            │
│                                                                 │
└────────────────────────────────────────────────────────────────┘

Ranking: Doc 1 (1.000) &amp;gt; Doc 2 (0.666) &amp;gt; Doc 3 (0.167)
          ▲               ▲               ▲
      Terms closest   Terms medium   Terms far apart
&lt;/code&gt;
    &lt;p&gt;Why This Works:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smaller distances → larger scores (inverse relationship)&lt;/item&gt;
      &lt;item&gt;Multiple occurrences → higher scores (additive)&lt;/item&gt;
      &lt;item&gt;Documents with terms close together rank higher&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Query Builder provides a type-safe, fluent API for constructing complex boolean queries with roaring bitmaps. No string parsing, no syntax errors - just clean, composable code.&lt;/p&gt;
    &lt;p&gt;String Parsing Approach:&lt;/p&gt;
    &lt;code&gt;// Error-prone, runtime failures
results, err := index.ExecuteQuery("(machine AND learning) OR python")
if err != nil {
    // Handle parsing errors
}&lt;/code&gt;
    &lt;p&gt;Builder Pattern Approach:&lt;/p&gt;
    &lt;code&gt;// Type-safe, compile-time checks, IDE autocomplete!
results := blaze.NewQueryBuilder(index).
    Group(func(q *blaze.QueryBuilder) {
        q.Term("machine").And().Term("learning")
    }).
    Or().
    Term("python").
    Execute()&lt;/code&gt;
    &lt;code&gt;// Find all documents containing "machine"
results := blaze.NewQueryBuilder(idx).
    Term("machine").
    Execute()

fmt.Printf("Found %d documents\n", results.GetCardinality())&lt;/code&gt;
    &lt;code&gt;// Find documents with BOTH "machine" AND "learning"
results := blaze.NewQueryBuilder(idx).
    Term("machine").
    And().
    Term("learning").
    Execute()&lt;/code&gt;
    &lt;code&gt;// Find documents with "python" OR "javascript"
results := blaze.NewQueryBuilder(idx).
    Term("python").
    Or().
    Term("javascript").
    Execute()&lt;/code&gt;
    &lt;code&gt;// Find documents with "python" but NOT "snake"
results := blaze.NewQueryBuilder(idx).
    Term("python").
    And().Not().
    Term("snake").
    Execute()&lt;/code&gt;
    &lt;code&gt;// (machine OR deep) AND learning
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Term("machine").Or().Term("deep")
    }).
    And().
    Term("learning").
    Execute()&lt;/code&gt;
    &lt;code&gt;// Find exact phrase "machine learning"
results := blaze.NewQueryBuilder(idx).
    Phrase("machine learning").
    Execute()&lt;/code&gt;
    &lt;code&gt;// Get top 10 results ranked by relevance
matches := blaze.NewQueryBuilder(idx).
    Term("machine").
    And().
    Term("learning").
    ExecuteWithBM25(10)

for _, match := range matches {
    fmt.Printf("Doc %d: score=%.2f\n", match.DocID, match.Score)
}&lt;/code&gt;
    &lt;p&gt;Creates a new query builder instance.&lt;/p&gt;
    &lt;code&gt;qb := blaze.NewQueryBuilder(idx)&lt;/code&gt;
    &lt;p&gt;Adds a single term to the query. Uses roaring bitmaps for O(1) document lookup.&lt;/p&gt;
    &lt;code&gt;qb.Term("machine")&lt;/code&gt;
    &lt;p&gt;Adds an exact phrase match. Combines bitmap efficiency with skip list position checking.&lt;/p&gt;
    &lt;code&gt;qb.Phrase("machine learning")&lt;/code&gt;
    &lt;p&gt;Combines results with intersection (both must match). Uses bitmap AND operation.&lt;/p&gt;
    &lt;code&gt;qb.Term("machine").And().Term("learning")&lt;/code&gt;
    &lt;p&gt;Combines results with union (either can match). Uses bitmap OR operation.&lt;/p&gt;
    &lt;code&gt;qb.Term("cat").Or().Term("dog")&lt;/code&gt;
    &lt;p&gt;Negates the next term (exclude from results). Uses bitmap difference operation.&lt;/p&gt;
    &lt;code&gt;qb.Term("python").And().Not().Term("snake")&lt;/code&gt;
    &lt;p&gt;Creates a sub-query with its own scope for precedence control.&lt;/p&gt;
    &lt;code&gt;qb.Group(func(q *blaze.QueryBuilder) {
    q.Term("machine").Or().Term("deep")
}).And().Term("learning")&lt;/code&gt;
    &lt;p&gt;Executes the query and returns a bitmap of matching document IDs.&lt;/p&gt;
    &lt;code&gt;results := qb.Execute()
docCount := results.GetCardinality()&lt;/code&gt;
    &lt;p&gt;Executes the query with BM25 ranking and returns top results.&lt;/p&gt;
    &lt;code&gt;matches := qb.ExecuteWithBM25(10)  // Top 10 results&lt;/code&gt;
    &lt;p&gt;The Query Builder provides convenient shorthand functions for common boolean operations:&lt;/p&gt;
    &lt;p&gt;Shorthand for documents containing ALL terms (AND operation).&lt;/p&gt;
    &lt;code&gt;// Find documents with "machine" AND "learning" AND "python"
results := blaze.AllOf(idx, "machine", "learning", "python")

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term("machine").And().Term("learning").And().Term("python").
    Execute()&lt;/code&gt;
    &lt;p&gt;Shorthand for documents containing ANY term (OR operation).&lt;/p&gt;
    &lt;code&gt;// Find documents with "cat" OR "dog" OR "bird"
results := blaze.AnyOf(idx, "cat", "dog", "bird")

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term("cat").Or().Term("dog").Or().Term("bird").
    Execute()&lt;/code&gt;
    &lt;p&gt;Shorthand for term with exclusion (AND NOT operation).&lt;/p&gt;
    &lt;code&gt;// Find documents with "python" but NOT "snake"
results := blaze.TermExcluding(idx, "python", "snake")

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term("python").And().Not().Term("snake").
    Execute()&lt;/code&gt;
    &lt;p&gt;Start with a broad category, then filter down with specific criteria.&lt;/p&gt;
    &lt;code&gt;// Find programming content about Python or JavaScript, excluding beginner material
results := blaze.NewQueryBuilder(idx).
    Term("programming").
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term("python").Or().Term("javascript")
    }).
    And().Not().
    Term("beginner").
    ExecuteWithBM25(10)&lt;/code&gt;
    &lt;p&gt;Match documents that satisfy multiple independent criteria.&lt;/p&gt;
    &lt;code&gt;// Find documents about (machine learning OR deep learning) AND (python OR tensorflow)
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Phrase("machine learning").Or().Phrase("deep learning")
    }).
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term("python").Or().Term("tensorflow")
    }).
    ExecuteWithBM25(20)&lt;/code&gt;
    &lt;p&gt;Find relevant content while filtering out noise or unwanted categories.&lt;/p&gt;
    &lt;code&gt;// Find "apple" content but exclude fruit/food related content
results := blaze.NewQueryBuilder(idx).
    Term("apple").
    And().Not().
    Group(func(q *blaze.QueryBuilder) {
        q.Term("fruit").Or().Term("food").Or().Term("cooking")
    }).
    Execute()  // Finds "Apple Inc." not the fruit&lt;/code&gt;
    &lt;p&gt;Search within specific categories or tags.&lt;/p&gt;
    &lt;code&gt;func SearchWithCategory(idx *blaze.InvertedIndex, query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Add main query
    qb.Term(query)

    // Add category filter if provided
    if len(categories) &amp;gt; 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i &amp;lt; len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }

    return qb.ExecuteWithBM25(20)
}&lt;/code&gt;
    &lt;p&gt;The Query Builder leverages roaring bitmaps for exceptional performance on boolean operations.&lt;/p&gt;
    &lt;code&gt;BenchmarkQueryBuilder_Simple-8       440,616 ops/sec    2,511 ns/op    896 B/op    39 allocs/op
BenchmarkQueryBuilder_Complex-8      222,024 ops/sec    5,333 ns/op  2,240 B/op    98 allocs/op
BenchmarkQueryBuilder_WithBM25-8     411,124 ops/sec    2,955 ns/op  1,416 B/op    46 allocs/op
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Operation&lt;/cell&gt;
        &lt;cell role="head"&gt;Complexity&lt;/cell&gt;
        &lt;cell role="head"&gt;Why It's Fast&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;AND&lt;/cell&gt;
        &lt;cell&gt;O(1) per chunk&lt;/cell&gt;
        &lt;cell&gt;Roaring bitmap intersection&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OR&lt;/cell&gt;
        &lt;cell&gt;O(1) per chunk&lt;/cell&gt;
        &lt;cell&gt;Roaring bitmap union&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;NOT&lt;/cell&gt;
        &lt;cell&gt;O(1) per chunk&lt;/cell&gt;
        &lt;cell&gt;Roaring bitmap difference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Term Lookup&lt;/cell&gt;
        &lt;cell&gt;O(1)&lt;/cell&gt;
        &lt;cell&gt;Direct hash map access&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;For a term appearing in 500,000 documents:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skip list positions: ~24 MB (500k nodes × 48 bytes)&lt;/item&gt;
      &lt;item&gt;Roaring bitmap: ~60 KB (400x compression!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;// Good: Clear precedence with groups
qb.Group(func(q *blaze.QueryBuilder) {
    q.Term("a").Or().Term("b")
}).And().Term("c")

// Bad: Ambiguous without groups
qb.Term("a").Or().Term("b").And().Term("c")  // Is this (a OR b) AND c or a OR (b AND c)?&lt;/code&gt;
    &lt;code&gt;// Good: Clean and readable
results := blaze.AllOf(idx, "python", "django", "web")

// Bad: Verbose for simple case
results := blaze.NewQueryBuilder(idx).
    Term("python").And().Term("django").And().Term("web").
    Execute()&lt;/code&gt;
    &lt;code&gt;// Good: Ranked results for users
matches := qb.ExecuteWithBM25(10)

// Bad: Unranked - harder for users to find relevant docs
bitmap := qb.Execute()&lt;/code&gt;
    &lt;code&gt;// Good: Exact phrase + related term
qb.Phrase("machine learning").And().Term("python")

// Bad: Overly restrictive
qb.Phrase("machine learning python")  // Requires exact phrase&lt;/code&gt;
    &lt;code&gt;func BuildDynamicQuery(idx *blaze.InvertedIndex, required []string, optional []string, excluded []string) *roaring.Bitmap {
    qb := blaze.NewQueryBuilder(idx)

    // Add required terms (AND)
    if len(required) &amp;gt; 0 {
        qb.Term(required[0])
        for i := 1; i &amp;lt; len(required); i++ {
            qb.And().Term(required[i])
        }
    }

    // Add optional terms (OR)
    if len(optional) &amp;gt; 0 {
        if len(required) &amp;gt; 0 {
            qb.And()
        }
        qb.Group(func(q *blaze.QueryBuilder) {
            q.Term(optional[0])
            for i := 1; i &amp;lt; len(optional); i++ {
                q.Or().Term(optional[i])
            }
        })
    }

    // Exclude terms (NOT)
    for _, term := range excluded {
        qb.And().Not().Term(term)
    }

    return qb.Execute()
}&lt;/code&gt;
    &lt;code&gt;func SearchProducts(idx *blaze.InvertedIndex, searchTerm string, category string, excludeOutOfStock bool) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(searchTerm)

    // Add category filter
    if category != "" {
        qb.And().Term(category)
    }

    // Exclude out of stock items
    if excludeOutOfStock {
        qb.And().Not().Term("outofstock")
    }

    return qb.ExecuteWithBM25(20)
}&lt;/code&gt;
    &lt;code&gt;func SearchInCategories(idx *blaze.InvertedIndex, query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(query)

    if len(categories) &amp;gt; 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i &amp;lt; len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }

    return qb.ExecuteWithBM25(50)
}&lt;/code&gt;
    &lt;code&gt;func FilterContent(idx *blaze.InvertedIndex, searchTerm string, blocklist []string) *roaring.Bitmap {
    qb := blaze.NewQueryBuilder(idx).Term(searchTerm)

    for _, blocked := range blocklist {
        qb.And().Not().Term(blocked)
    }

    return qb.Execute()
}&lt;/code&gt;
    &lt;code&gt;func AdvancedSearch(idx *blaze.InvertedIndex, phrases []string, requiredTerms []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Match any of the phrases (OR)
    qb.Group(func(q *blaze.QueryBuilder) {
        q.Phrase(phrases[0])
        for i := 1; i &amp;lt; len(phrases); i++ {
            q.Or().Phrase(phrases[i])
        }
    })

    // AND with required terms
    for _, term := range requiredTerms {
        qb.And().Term(term)
    }

    return qb.ExecuteWithBM25(10)
}

// Usage:
results := AdvancedSearch(idx,
    []string{"machine learning", "deep learning"},
    []string{"python", "tensorflow"})&lt;/code&gt;
    &lt;code&gt;func SearchHandler(w http.ResponseWriter, r *http.Request) {
    query := r.URL.Query().Get("q")
    category := r.URL.Query().Get("category")
    exclude := r.URL.Query().Get("exclude")

    qb := blaze.NewQueryBuilder(index).Term(query)

    if category != "" {
        qb.And().Term(category)
    }

    if exclude != "" {
        qb.And().Not().Term(exclude)
    }

    results := qb.ExecuteWithBM25(20)
    json.NewEncoder(w).Encode(results)
}&lt;/code&gt;
    &lt;code&gt;func SemanticSearch(idx *blaze.InvertedIndex, concept string, relatedTerms []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Main concept OR any related terms
    qb.Term(concept)
    for _, related := range relatedTerms {
        qb.Or().Term(related)
    }

    return qb.ExecuteWithBM25(50)
}

// Usage:
results := SemanticSearch(idx, "automobile",
    []string{"car", "vehicle", "transportation", "automotive"})&lt;/code&gt;
    &lt;code&gt;func NewInvertedIndex() *InvertedIndex&lt;/code&gt;
    &lt;p&gt;Creates a new empty inverted index.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;idx := blaze.NewInvertedIndex()&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) Index(docID int, document string)&lt;/code&gt;
    &lt;p&gt;Adds a document to the inverted index. Thread-safe.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;docID&lt;/code&gt;: Unique document identifier&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;document&lt;/code&gt;: Text content to index&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;idx.Index(1, "The quick brown fox jumps over the lazy dog")
idx.Index(2, "A fast brown dog")&lt;/code&gt;
    &lt;p&gt;What Happens:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Text is analyzed (tokenized, stemmed, etc.)&lt;/item&gt;
      &lt;item&gt;Each token is recorded with its position&lt;/item&gt;
      &lt;item&gt;Positions are stored in skip lists for fast lookup&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;func (idx *InvertedIndex) First(token string) (Position, error)&lt;/code&gt;
    &lt;p&gt;Returns the first occurrence of a token in the index.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;pos, err := idx.First("quick")
if err != nil {
    // Token not found
}
fmt.Printf("Doc %d, Pos %d\n", int(pos.DocumentID), int(pos.Offset))&lt;/code&gt;
    &lt;p&gt;Returns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Position&lt;/code&gt;: Location of first occurrence&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;error&lt;/code&gt;:&lt;code&gt;ErrNoPostingList&lt;/code&gt;if token doesn't exist&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;func (idx *InvertedIndex) Last(token string) (Position, error)&lt;/code&gt;
    &lt;p&gt;Returns the last occurrence of a token in the index.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;pos, err := idx.Last("quick")&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) Next(token string, currentPos Position) (Position, error)&lt;/code&gt;
    &lt;p&gt;Finds the next occurrence of a token after the given position.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;// Iterate through all occurrences
pos := blaze.BOFDocument
for {
    pos, err = idx.Next("quick", pos)
    if pos.IsEnd() || err != nil {
        break
    }
    fmt.Printf("Found at Doc %d, Pos %d\n",
        int(pos.DocumentID), int(pos.Offset))
}&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) Previous(token string, currentPos Position) (Position, error)&lt;/code&gt;
    &lt;p&gt;Finds the previous occurrence of a token before the given position.&lt;/p&gt;
    &lt;code&gt;func (idx *InvertedIndex) NextPhrase(query string, startPos Position) []Position&lt;/code&gt;
    &lt;p&gt;Finds the next occurrence of a phrase (exact word sequence).&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;query&lt;/code&gt;: Space-separated phrase (e.g., "quick brown fox")&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;startPos&lt;/code&gt;: Position to start searching from&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;[]Position&lt;/code&gt;: Array with two elements [phraseStart, phraseEnd]&lt;/item&gt;
      &lt;item&gt;Returns &lt;code&gt;[EOFDocument, EOFDocument]&lt;/code&gt;if no match found&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;matches := idx.NextPhrase("quick brown fox", blaze.BOFDocument)
if !matches[0].IsEnd() {
    fmt.Printf("Phrase found in Doc %d from Pos %d to %d\n",
        int(matches[0].DocumentID),
        int(matches[0].Offset),
        int(matches[1].Offset))
}&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) FindAllPhrases(query string, startPos Position) [][]Position&lt;/code&gt;
    &lt;p&gt;Finds all occurrences of a phrase in the entire index.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;allMatches := idx.FindAllPhrases("brown fox", blaze.BOFDocument)
for _, match := range allMatches {
    fmt.Printf("Doc %d: Pos %d-%d\n",
        int(match[0].DocumentID),
        int(match[0].Offset),
        int(match[1].Offset))
}&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) NextCover(tokens []string, startPos Position) []Position&lt;/code&gt;
    &lt;p&gt;Finds the next "cover" - a range containing all given tokens.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;tokens&lt;/code&gt;: Array of search terms&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;startPos&lt;/code&gt;: Position to start searching from&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;[]Position&lt;/code&gt;: Array with [coverStart, coverEnd]&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;cover := idx.NextCover([]string{"quick", "fox", "brown"}, blaze.BOFDocument)
fmt.Printf("Cover: Doc %d, Pos %d-%d\n",
    int(cover[0].DocumentID),
    int(cover[0].Offset),
    int(cover[1].Offset))&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) RankBM25(query string, maxResults int) []Match&lt;/code&gt;
    &lt;p&gt;Performs BM25 ranking of search results. This is the recommended search function for most use cases.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;query&lt;/code&gt;: Search query (e.g., "machine learning")&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;maxResults&lt;/code&gt;: Maximum number of results to return&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;[]Match&lt;/code&gt;: Sorted array of matches with BM25 scores&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;results := idx.RankBM25("machine learning", 10)
for i, match := range results {
    fmt.Printf("%d. Doc %d (score: %.2f)\n",
        i+1,
        match.DocID,
        match.Score)
}&lt;/code&gt;
    &lt;p&gt;Match Structure:&lt;/p&gt;
    &lt;code&gt;type Match struct {
    DocID   int        // Document identifier
    Offsets []Position // Where terms appear in the document
    Score   float64    // BM25 relevance score
}&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) RankProximity(query string, maxResults int) []Match&lt;/code&gt;
    &lt;p&gt;Performs proximity-based ranking of search results. Alternative to BM25, ranks by term proximity.&lt;/p&gt;
    &lt;p&gt;Parameters:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;query&lt;/code&gt;: Search query (e.g., "machine learning")&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;maxResults&lt;/code&gt;: Maximum number of results to return&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Returns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;[]Match&lt;/code&gt;: Sorted array of matches with proximity scores&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;results := idx.RankProximity("quick brown", 5)
for i, match := range results {
    fmt.Printf("%d. Doc %d (score: %.2f)\n",
        i+1,
        int(match.Offsets[0].DocumentID),
        match.Score)
}&lt;/code&gt;
    &lt;p&gt;BM25 vs Proximity Ranking:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;BM25&lt;/cell&gt;
        &lt;cell role="head"&gt;Proximity&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Term Rarity&lt;/cell&gt;
        &lt;cell&gt;Yes (IDF)&lt;/cell&gt;
        &lt;cell&gt;No (all terms equal)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Length Normalization&lt;/cell&gt;
        &lt;cell&gt;Yes (built-in)&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Term Frequency&lt;/cell&gt;
        &lt;cell&gt;Yes (with saturation)&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Term Distance&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Yes (main factor)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Use Case&lt;/cell&gt;
        &lt;cell&gt;General search&lt;/cell&gt;
        &lt;cell&gt;Finding close co-occurrences&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Industry Standard&lt;/cell&gt;
        &lt;cell&gt;Yes (Elasticsearch, Solr)&lt;/cell&gt;
        &lt;cell&gt;No (custom algorithm)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;func (idx *InvertedIndex) Encode() ([]byte, error)&lt;/code&gt;
    &lt;p&gt;Serializes the inverted index to binary format.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;data, err := idx.Encode()
if err != nil {
    log.Fatal(err)
}

// Save to file
err = os.WriteFile("index.bin", data, 0644)&lt;/code&gt;
    &lt;code&gt;func (idx *InvertedIndex) Decode(data []byte) error&lt;/code&gt;
    &lt;p&gt;Deserializes binary data back into an inverted index.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;data, err := os.ReadFile("index.bin")
if err != nil {
    log.Fatal(err)
}

idx := blaze.NewInvertedIndex()
err = idx.Decode(data)&lt;/code&gt;
    &lt;code&gt;func Analyze(text string) []string&lt;/code&gt;
    &lt;p&gt;Transforms raw text into searchable tokens using the default pipeline.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;tokens := blaze.Analyze("The Quick Brown Fox Jumps!")
// Returns: ["quick", "brown", "fox", "jump"]&lt;/code&gt;
    &lt;code&gt;func AnalyzeWithConfig(text string, config AnalyzerConfig) []string&lt;/code&gt;
    &lt;p&gt;Transforms text using a custom configuration.&lt;/p&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;config := blaze.AnalyzerConfig{
    MinTokenLength:  3,
    EnableStemming:  false,
    EnableStopwords: true,
}
tokens := blaze.AnalyzeWithConfig("The quick brown fox", config)&lt;/code&gt;
    &lt;code&gt;func (p *Position) GetDocumentID() int
func (p *Position) GetOffset() int
func (p *Position) IsBeginning() bool
func (p *Position) IsEnd() bool
func (p *Position) IsBefore(other Position) bool
func (p *Position) IsAfter(other Position) bool
func (p *Position) Equals(other Position) bool&lt;/code&gt;
    &lt;p&gt;Example:&lt;/p&gt;
    &lt;code&gt;pos1 := blaze.Position{DocumentID: 1, Offset: 5}
pos2 := blaze.Position{DocumentID: 1, Offset: 10}

if pos1.IsBefore(pos2) {
    fmt.Println("pos1 comes before pos2")
}&lt;/code&gt;
    &lt;code&gt;func NewSkipList() *SkipList&lt;/code&gt;
    &lt;p&gt;Creates a new empty skip list.&lt;/p&gt;
    &lt;code&gt;func (sl *SkipList) Insert(key Position)&lt;/code&gt;
    &lt;p&gt;Adds or updates a position in the skip list. Average O(log n).&lt;/p&gt;
    &lt;code&gt;func (sl *SkipList) Find(key Position) (Position, error)&lt;/code&gt;
    &lt;p&gt;Searches for an exact position. Average O(log n).&lt;/p&gt;
    &lt;code&gt;func (sl *SkipList) Delete(key Position) bool&lt;/code&gt;
    &lt;p&gt;Removes a position from the skip list. Average O(log n).&lt;/p&gt;
    &lt;code&gt;func (sl *SkipList) FindLessThan(key Position) (Position, error)&lt;/code&gt;
    &lt;p&gt;Finds the largest position less than the given position.&lt;/p&gt;
    &lt;code&gt;func (sl *SkipList) FindGreaterThan(key Position) (Position, error)&lt;/code&gt;
    &lt;p&gt;Finds the smallest position greater than the given position.&lt;/p&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    // Create index
    idx := blaze.NewInvertedIndex()

    // Index documents
    idx.Index(1, "Go is a programming language designed at Google")
    idx.Index(2, "Python is a high-level programming language")
    idx.Index(3, "Go is fast and efficient for system programming")

    // Search for "programming language" using BM25
    results := idx.RankBM25("programming language", 10)

    fmt.Println("Search results for 'programming language':")
    for i, match := range results {
        fmt.Printf("%d. Document %d (score: %.3f)\n", i+1, match.DocID, match.Score)
    }
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;Search results for 'programming language':
1. Document 1 (score: 4.521)
2. Document 2 (score: 4.521)
3. Document 3 (score: 2.156)
&lt;/code&gt;
    &lt;p&gt;Note: BM25 scores are absolute values (not normalized to 0-1), reflecting relevance based on term frequency, document length, and term rarity.&lt;/p&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    idx := blaze.NewInvertedIndex()

    idx.Index(1, "the quick brown fox jumps over the lazy dog")
    idx.Index(2, "a quick brown dog runs fast")
    idx.Index(3, "the lazy brown fox sleeps")

    // Find exact phrase "brown fox"
    matches := idx.FindAllPhrases("brown fox", blaze.BOFDocument)

    fmt.Println("Documents containing 'brown fox' as a phrase:")
    for _, match := range matches {
        docID := int(match[0].DocumentID)
        start := int(match[0].Offset)
        end := int(match[1].Offset)
        fmt.Printf("Document %d: positions %d-%d\n", docID, start, end)
    }
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;Documents containing 'brown fox' as a phrase:
Document 1: positions 1-2
Document 3: positions 2-3
&lt;/code&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    idx := blaze.NewInvertedIndex()

    idx.Index(1, "quick test quick test quick")
    idx.Index(2, "another quick test here")

    // Find all occurrences of "quick"
    fmt.Println("All occurrences of 'quick':")

    pos := blaze.BOFDocument
    for {
        pos, err := idx.Next("quick", pos)
        if err != nil || pos.IsEnd() {
            break
        }
        fmt.Printf("  Doc %d, Pos %d\n",
            int(pos.DocumentID),
            int(pos.Offset))
    }
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;All occurrences of 'quick':
  Doc 1, Pos 0
  Doc 1, Pos 2
  Doc 1, Pos 4
  Doc 2, Pos 1
&lt;/code&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "os"
    "github.com/wizenheimer/blaze"
)

func main() {
    // Build and save index
    idx := blaze.NewInvertedIndex()
    idx.Index(1, "machine learning algorithms")
    idx.Index(2, "deep learning neural networks")
    idx.Index(3, "natural language processing")

    // Serialize to binary
    data, err := idx.Encode()
    if err != nil {
        panic(err)
    }

    // Save to file
    err = os.WriteFile("search_index.bin", data, 0644)
    if err != nil {
        panic(err)
    }
    fmt.Println("Index saved to search_index.bin")

    // Load index from file
    loadedData, err := os.ReadFile("search_index.bin")
    if err != nil {
        panic(err)
    }

    loadedIdx := blaze.NewInvertedIndex()
    err = loadedIdx.Decode(loadedData)
    if err != nil {
        panic(err)
    }

    // Use loaded index
    results := loadedIdx.RankProximity("learning", 5)
    fmt.Printf("Found %d documents\n", len(results))
}&lt;/code&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    // Create custom analyzer config (no stemming, longer min length)
    config := blaze.AnalyzerConfig{
        MinTokenLength:  3,      // Minimum 3 characters
        EnableStemming:  false,  // Keep original word forms
        EnableStopwords: true,   // Still remove stopwords
    }

    text := "The running dogs are running fast"

    // Compare default vs custom analysis
    defaultTokens := blaze.Analyze(text)
    customTokens := blaze.AnalyzeWithConfig(text, config)

    fmt.Println("Default tokens:", defaultTokens)
    fmt.Println("Custom tokens:", customTokens)
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;Default tokens: [run dog run fast]
Custom tokens: [running dogs running fast]
&lt;/code&gt;
    &lt;code&gt;package main

import (
    "fmt"
    "github.com/wizenheimer/blaze"
)

func main() {
    idx := blaze.NewInvertedIndex()

    // Index documents
    idx.Index(1, "machine learning algorithms")
    idx.Index(2, "machine learning machine learning")  // High term frequency
    idx.Index(3, "machine and algorithms and learning") // Terms far apart

    query := "machine learning"

    // BM25 Ranking
    fmt.Println("BM25 Rankings:")
    bm25Results := idx.RankBM25(query, 10)
    for i, match := range bm25Results {
        fmt.Printf("%d. Doc %d (score: %.3f)\n", i+1, match.DocID, match.Score)
    }

    // Proximity Ranking
    fmt.Println("\nProximity Rankings:")
    proxResults := idx.RankProximity(query, 10)
    for i, match := range proxResults {
        docID := int(match.Offsets[0].DocumentID)
        fmt.Printf("%d. Doc %d (score: %.3f)\n", i+1, docID, match.Score)
    }
}&lt;/code&gt;
    &lt;p&gt;Output:&lt;/p&gt;
    &lt;code&gt;BM25 Rankings:
1. Doc 2 (score: 5.234)  ← High term frequency
2. Doc 1 (score: 3.156)
3. Doc 3 (score: 2.891)

Proximity Rankings:
1. Doc 1 (score: 1.000)  ← Terms adjacent
2. Doc 2 (score: 1.000)
3. Doc 3 (score: 0.200)  ← Terms far apart
&lt;/code&gt;
    &lt;p&gt;Key Differences:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;BM25 favors Doc 2 (repeated terms = high relevance)&lt;/item&gt;
      &lt;item&gt;Proximity favors Doc 1 and Doc 2 equally (both have adjacent terms)&lt;/item&gt;
      &lt;item&gt;Doc 3 ranks low in both (terms spread out)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;package main

import (
    "bufio"
    "fmt"
    "os"
    "strings"
    "github.com/wizenheimer/blaze"
)

func main() {
    // Create index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    docs := map[int]string{
        1: "Go is an open source programming language that makes it easy to build simple, reliable, and efficient software",
        2: "Python is a programming language that lets you work quickly and integrate systems more effectively",
        3: "JavaScript is a programming language that conforms to the ECMAScript specification",
        4: "Rust is a multi-paradigm programming language focused on performance and safety",
        5: "Java is a class-based, object-oriented programming language designed for portability",
    }

    for id, doc := range docs {
        idx.Index(id, doc)
    }

    // Interactive search
    scanner := bufio.NewScanner(os.Stdin)

    for {
        fmt.Print("\nSearch query (or 'quit' to exit): ")
        if !scanner.Scan() {
            break
        }

        query := strings.TrimSpace(scanner.Text())
        if query == "quit" {
            break
        }

        if query == "" {
            continue
        }

        // Perform search using BM25
        results := idx.RankBM25(query, 5)

        if len(results) == 0 {
            fmt.Println("No results found")
            continue
        }

        // Display results
        fmt.Printf("\nFound %d result(s):\n", len(results))
        for i, match := range results {
            fmt.Printf("\n%d. Document %d (Score: %.3f)\n", i+1, match.DocID, match.Score)
            fmt.Printf("   %s\n", docs[match.DocID])
        }
    }
}&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Operation&lt;/cell&gt;
        &lt;cell role="head"&gt;Average&lt;/cell&gt;
        &lt;cell role="head"&gt;Worst Case&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Index (per document)&lt;/cell&gt;
        &lt;cell&gt;O(n × log m)&lt;/cell&gt;
        &lt;cell&gt;O(n × m)&lt;/cell&gt;
        &lt;cell&gt;n = tokens, m = total positions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Term lookup&lt;/cell&gt;
        &lt;cell&gt;O(log m)&lt;/cell&gt;
        &lt;cell&gt;O(m)&lt;/cell&gt;
        &lt;cell&gt;m = positions for term&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Phrase search&lt;/cell&gt;
        &lt;cell&gt;O(k × log m)&lt;/cell&gt;
        &lt;cell&gt;O(k × m)&lt;/cell&gt;
        &lt;cell&gt;k = phrase length&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;BM25 ranking&lt;/cell&gt;
        &lt;cell&gt;O(t × d)&lt;/cell&gt;
        &lt;cell&gt;O(t × d)&lt;/cell&gt;
        &lt;cell&gt;t = query terms, d = candidates&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Proximity ranking&lt;/cell&gt;
        &lt;cell&gt;O(t × m)&lt;/cell&gt;
        &lt;cell&gt;O(t × m)&lt;/cell&gt;
        &lt;cell&gt;t = query terms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Skip list insert&lt;/cell&gt;
        &lt;cell&gt;O(log n)&lt;/cell&gt;
        &lt;cell&gt;O(n)&lt;/cell&gt;
        &lt;cell&gt;n = elements in list&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Skip list search&lt;/cell&gt;
        &lt;cell&gt;O(log n)&lt;/cell&gt;
        &lt;cell&gt;O(n)&lt;/cell&gt;
        &lt;cell&gt;Probabilistically rare&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Space&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Inverted index&lt;/cell&gt;
        &lt;cell&gt;O(n)&lt;/cell&gt;
        &lt;cell&gt;n = total unique positions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Skip list nodes&lt;/cell&gt;
        &lt;cell&gt;O(n × log n)&lt;/cell&gt;
        &lt;cell&gt;Average 2 pointers per node&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Analyzer&lt;/cell&gt;
        &lt;cell&gt;O(1)&lt;/cell&gt;
        &lt;cell&gt;In-place processing&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Serialized index&lt;/cell&gt;
        &lt;cell&gt;O(n)&lt;/cell&gt;
        &lt;cell&gt;Compact binary format&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Performance on Apple M2 (8 cores), Go 1.24:&lt;/p&gt;
    &lt;code&gt;BenchmarkIndex-8                     50000    35421 ns/op    18234 B/op    245 allocs/op
BenchmarkTermSearch-8              300000     4123 ns/op      128 B/op      3 allocs/op
BenchmarkPhraseSearch-8            100000    12456 ns/op      512 B/op     12 allocs/op
BenchmarkRankBM25-8                  60000    24567 ns/op     1856 B/op     38 allocs/op
BenchmarkProximityRanking-8         50000    28934 ns/op     2048 B/op     45 allocs/op
BenchmarkCalculateIDF-8           5000000      234 ns/op       16 B/op      1 allocs/op
BenchmarkCalculateBM25Score-8     2000000      567 ns/op       64 B/op      2 allocs/op
BenchmarkSkipListInsert-8         3000000      413 ns/op      255 B/op      6 allocs/op
BenchmarkSkipListSearch-8         5000000      203 ns/op       23 B/op      1 allocs/op
BenchmarkAnalyze-8                1000000     1234 ns/op      512 B/op      8 allocs/op
BenchmarkEncode-8                   10000   156789 ns/op    65536 B/op    234 allocs/op
BenchmarkDecode-8                   15000   123456 ns/op    49152 B/op    189 allocs/op
&lt;/code&gt;
    &lt;p&gt;Index Size vs Performance:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Documents&lt;/cell&gt;
        &lt;cell role="head"&gt;Terms&lt;/cell&gt;
        &lt;cell role="head"&gt;Index Time&lt;/cell&gt;
        &lt;cell role="head"&gt;Search Time&lt;/cell&gt;
        &lt;cell role="head"&gt;Memory&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;1K&lt;/cell&gt;
        &lt;cell&gt;10K&lt;/cell&gt;
        &lt;cell&gt;50ms&lt;/cell&gt;
        &lt;cell&gt;0.5ms&lt;/cell&gt;
        &lt;cell&gt;2 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;10K&lt;/cell&gt;
        &lt;cell&gt;100K&lt;/cell&gt;
        &lt;cell&gt;500ms&lt;/cell&gt;
        &lt;cell&gt;1ms&lt;/cell&gt;
        &lt;cell&gt;20 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;100K&lt;/cell&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;5s&lt;/cell&gt;
        &lt;cell&gt;2ms&lt;/cell&gt;
        &lt;cell&gt;200 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;1M&lt;/cell&gt;
        &lt;cell&gt;10M&lt;/cell&gt;
        &lt;cell&gt;50s&lt;/cell&gt;
        &lt;cell&gt;5ms&lt;/cell&gt;
        &lt;cell&gt;2 GB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Search time remains relatively constant due to O(log n) operations&lt;/item&gt;
      &lt;item&gt;Memory scales linearly with unique positions&lt;/item&gt;
      &lt;item&gt;Serialization reduces storage by ~40% compared to in-memory size&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Customize BM25 ranking behavior:&lt;/p&gt;
    &lt;code&gt;type BM25Parameters struct {
    K1 float64 // Term frequency saturation (default: 1.5)
    B  float64 // Length normalization (default: 0.75)
}&lt;/code&gt;
    &lt;p&gt;Tuning BM25:&lt;/p&gt;
    &lt;code&gt;idx := blaze.NewInvertedIndex()

// Adjust BM25 parameters before indexing
idx.BM25Params.K1 = 2.0  // Higher = less saturation (more weight to TF)
idx.BM25Params.B = 0.5   // Lower = less length penalty

// Now index and search
idx.Index(1, "document content")
results := idx.RankBM25("query", 10)&lt;/code&gt;
    &lt;p&gt;Parameter Effects:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Parameter&lt;/cell&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
        &lt;cell role="head"&gt;Effect&lt;/cell&gt;
        &lt;cell role="head"&gt;When to Adjust&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;K1&lt;/cell&gt;
        &lt;cell&gt;1.2 - 2.0&lt;/cell&gt;
        &lt;cell&gt;Controls TF saturation&lt;/cell&gt;
        &lt;cell&gt;Higher for domains where term frequency matters more&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;B&lt;/cell&gt;
        &lt;cell&gt;0 - 1&lt;/cell&gt;
        &lt;cell&gt;Controls length penalty&lt;/cell&gt;
        &lt;cell&gt;Lower for domains with naturally longer docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Examples:&lt;/p&gt;
    &lt;code&gt;// Academic papers (long documents, repeated terms important)
idx.BM25Params.K1 = 2.0
idx.BM25Params.B = 0.5

// Short messages (length less important)
idx.BM25Params.K1 = 1.2
idx.BM25Params.B = 0.3

// Default (works well for most cases)
idx.BM25Params.K1 = 1.5
idx.BM25Params.B = 0.75&lt;/code&gt;
    &lt;p&gt;BM25 Statistics:&lt;/p&gt;
    &lt;p&gt;During indexing, Blaze automatically tracks:&lt;/p&gt;
    &lt;code&gt;type DocumentStats struct {
    DocID     int            // Document identifier
    Length    int            // Number of terms
    TermFreqs map[string]int // Term frequencies
}

// Corpus-level statistics
idx.TotalDocs  // Total documents indexed
idx.TotalTerms // Total terms across all documents
idx.DocStats   // Per-document statistics&lt;/code&gt;
    &lt;p&gt;These statistics are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatically computed during indexing&lt;/item&gt;
      &lt;item&gt;Serialized with the index&lt;/item&gt;
      &lt;item&gt;Used for BM25 score calculation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Customize the text analysis pipeline:&lt;/p&gt;
    &lt;code&gt;type AnalyzerConfig struct {
    MinTokenLength  int  // Minimum token length (default: 2)
    EnableStemming  bool // Apply stemming (default: true)
    EnableStopwords bool // Remove stopwords (default: true)
}&lt;/code&gt;
    &lt;p&gt;Configuration Examples:&lt;/p&gt;
    &lt;code&gt;// Exact matching (no stemming, keep all words)
exactConfig := blaze.AnalyzerConfig{
    MinTokenLength:  1,
    EnableStemming:  false,
    EnableStopwords: false,
}

// Fuzzy matching (aggressive stemming)
fuzzyConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  true,
    EnableStopwords: true,
}

// Code search (no stemming, no stopwords, longer tokens)
codeConfig := blaze.AnalyzerConfig{
    MinTokenLength:  3,
    EnableStemming:  false,
    EnableStopwords: false,
}&lt;/code&gt;
    &lt;p&gt;MinTokenLength:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1: Very permissive, large index&lt;/item&gt;
      &lt;item&gt;2: Balanced (default), filters single chars&lt;/item&gt;
      &lt;item&gt;3: Strict, smaller index, misses short words&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;EnableStemming:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;true: Better recall, finds related words ("run" matches "running")&lt;/item&gt;
      &lt;item&gt;false: Exact matching, preserves original word forms&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;EnableStopwords:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;true: Smaller index, faster search, standard behavior&lt;/item&gt;
      &lt;item&gt;false: Complete indexing, useful for phrase search&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;const MaxHeight = 32  // Maximum tower height&lt;/code&gt;
    &lt;p&gt;Tower Height Probability:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Height 1: 50%&lt;/item&gt;
      &lt;item&gt;Height 2: 25%&lt;/item&gt;
      &lt;item&gt;Height 3: 12.5%&lt;/item&gt;
      &lt;item&gt;Height 4: 6.25%&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This geometric distribution ensures O(log n) average performance.&lt;/p&gt;
    &lt;p&gt;Build a search engine for documents:&lt;/p&gt;
    &lt;code&gt;type Document struct {
    ID      int
    Title   string
    Content string
}

func IndexDocuments(docs []Document) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, doc := range docs {
        // Combine title and content
        text := doc.Title + " " + doc.Content
        idx.Index(doc.ID, text)
    }

    return idx
}

func SearchDocuments(idx *blaze.InvertedIndex, query string) []int {
    // Use BM25 for general relevance ranking (recommended)
    matches := idx.RankBM25(query, 20)

    docIDs := make([]int, len(matches))
    for i, match := range matches {
        docIDs[i] = match.DocID
    }

    return docIDs
}

// Alternative: Use proximity ranking to find documents with close term matches
func SearchDocumentsByProximity(idx *blaze.InvertedIndex, query string) []int {
    matches := idx.RankProximity(query, 20)

    docIDs := make([]int, len(matches))
    for i, match := range matches {
        docIDs[i] = int(match.Offsets[0].DocumentID)
    }

    return docIDs
}&lt;/code&gt;
    &lt;p&gt;Search through log files:&lt;/p&gt;
    &lt;code&gt;func IndexLogs(logFile string) (*blaze.InvertedIndex, error) {
    idx := blaze.NewInvertedIndex()

    file, err := os.Open(logFile)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    scanner := bufio.NewScanner(file)
    lineNumber := 1

    for scanner.Scan() {
        idx.Index(lineNumber, scanner.Text())
        lineNumber++
    }

    return idx, scanner.Err()
}

// Find all ERROR log lines using BM25 (considers frequency and rarity)
errorLogs := idx.RankBM25("ERROR", 100)

// Alternative: Use proximity for finding error patterns
// e.g., "connection timeout" appearing close together
patternMatches := idx.RankProximity("connection timeout", 50)&lt;/code&gt;
    &lt;p&gt;Search through source code:&lt;/p&gt;
    &lt;code&gt;func IndexCodebase(rootDir string) (*blaze.InvertedIndex, error) {
    idx := blaze.NewInvertedIndex()
    fileID := 1

    // Custom config for code (no stemming, keep all words)
    config := blaze.AnalyzerConfig{
        MinTokenLength:  2,
        EnableStemming:  false,
        EnableStopwords: false,
    }

    err := filepath.Walk(rootDir, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }

        // Only index Go files
        if !strings.HasSuffix(path, ".go") {
            return nil
        }

        content, err := os.ReadFile(path)
        if err != nil {
            return err
        }

        // Use custom analyzer
        tokens := blaze.AnalyzeWithConfig(string(content), config)
        // ... index tokens ...

        fileID++
        return nil
    })

    return idx, err
}

// BM25: Find files with frequent mentions of a function/variable
bm25Results := idx.RankBM25("http.Handler", 20)

// Proximity: Find exact API patterns (e.g., function calls with parameters)
// Better for finding "http.HandleFunc" as a specific pattern
proximityResults := idx.RankProximity("http HandleFunc", 20)&lt;/code&gt;
    &lt;p&gt;Search product catalog:&lt;/p&gt;
    &lt;code&gt;type Product struct {
    ID          int
    Name        string
    Description string
    Category    string
    Tags        []string
}

func IndexProducts(products []Product) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, product := range products {
        // Combine all searchable fields
        searchText := fmt.Sprintf("%s %s %s %s",
            product.Name,
            product.Description,
            product.Category,
            strings.Join(product.Tags, " "))

        idx.Index(product.ID, searchText)
    }

    return idx
}

// BM25: Best for general product search (considers all factors)
results := idx.RankBM25("wireless headphones", 10)

// Proximity: Good for finding exact product name matches
// (e.g., "Sony WH-1000XM4" as an exact phrase proximity)
exactMatches := idx.RankProximity("wireless headphones", 10)&lt;/code&gt;
    &lt;p&gt;Index and search email messages:&lt;/p&gt;
    &lt;code&gt;type Email struct {
    ID      int
    From    string
    Subject string
    Body    string
}

func IndexEmails(emails []Email) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, email := range emails {
        searchText := fmt.Sprintf("%s %s %s",
            email.From,
            email.Subject,
            email.Body)

        idx.Index(email.ID, searchText)
    }

    return idx
}

// BM25: Find emails where terms appear frequently (general search)
matches := idx.RankBM25("project deadline", 50)

// Proximity: Find emails where "project" and "deadline" appear close together
// (more precise, better for finding specific mentions)
closeMatches := idx.RankProximity("project deadline", 50)&lt;/code&gt;
    &lt;code&gt;# Run all tests
make test

# Run tests with coverage
make test-coverage

# Run benchmarks
make bench

# Run all checks (format, vet, lint, test)
make check&lt;/code&gt;
    &lt;p&gt;The library has comprehensive test coverage:&lt;/p&gt;
    &lt;code&gt;$ make test-coverage
Running tests...
ok      github.com/wizenheimer/blaze    2.456s  coverage: 98.5% of statements
Generating coverage report...
Coverage report: coverage.html&lt;/code&gt;
    &lt;p&gt;Coverage by Component:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Inverted Index: 100%&lt;/item&gt;
      &lt;item&gt;Skip Lists: 100%&lt;/item&gt;
      &lt;item&gt;Text Analysis: 100%&lt;/item&gt;
      &lt;item&gt;Search Operations: 100%&lt;/item&gt;
      &lt;item&gt;BM25 Ranking: 100%&lt;/item&gt;
      &lt;item&gt;Serialization: 100%&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example test:&lt;/p&gt;
    &lt;code&gt;func TestSearchFunctionality(t *testing.T) {
    idx := blaze.NewInvertedIndex()

    // Index test documents
    idx.Index(1, "the quick brown fox")
    idx.Index(2, "the lazy brown dog")

    // Test phrase search
    matches := idx.FindAllPhrases("brown fox", blaze.BOFDocument)

    if len(matches) != 1 {
        t.Errorf("Expected 1 match, got %d", len(matches))
    }

    if int(matches[0][0].DocumentID) != 1 {
        t.Errorf("Expected document 1, got %d", int(matches[0][0].DocumentID))
    }
}&lt;/code&gt;
    &lt;code&gt;blaze/
├── index.go          # Inverted index implementation with hybrid storage
├── query.go          # Query builder with roaring bitmaps
├── skiplist.go       # Skip list data structure for positions
├── search.go         # Search algorithms (phrase, proximity, BM25)
├── analyzer.go       # Text analysis pipeline
├── serialization.go  # Binary encoding/decoding (skip lists + bitmaps)
├── *_test.go         # Comprehensive test suite
├── Makefile          # Development commands
└── public/           # Documentation website
    └── index.html
&lt;/code&gt;
    &lt;p&gt;The query processor uses a hybrid storage approach combining roaring bitmaps for document-level operations and skip lists for position-level operations.&lt;/p&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────────────────┐
│                      QUERY PROCESSOR ARCHITECTURE                        │
└─────────────────────────────────────────────────────────────────────────┘

                              User Query
                          "machine AND learning"
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │    Text Analyzer            │
                    │  (tokenize, stem, etc.)     │
                    └──────────────┬──────────────┘
                                  │
                    ["machine", "learning"]
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │     Query Builder           │
                    │  (constructs query tree)    │
                    └──────────────┬──────────────┘
                                  │
                    Query Tree: AND(machine, learning)
                                  │
            ┌─────────────────────┼─────────────────────┐
            │                     │                     │
            ▼                     ▼                     ▼
    ┌───────────────┐    ┌───────────────┐    ┌───────────────┐
    │  Bitmap Ops   │    │  Skip List    │    │  BM25 Scorer  │
    │  (fast AND/OR)│    │  (positions)  │    │  (ranking)    │
    └───────┬───────┘    └───────┬───────┘    └───────┬───────┘
            │                     │                     │
            └─────────────────────┼─────────────────────┘
                                  │
                                  ▼
                          ┌───────────────┐
                          │    Results    │
                          │  (ranked docs)│
                          └───────────────┘
&lt;/code&gt;
    &lt;p&gt;Blaze uses a sophisticated hybrid storage model:&lt;/p&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────────────────┐
│                        HYBRID STORAGE MODEL                              │
└─────────────────────────────────────────────────────────────────────────┘

For each term "machine":

┌─────────────────────────────────────────────────────────────────────────┐
│  DOCUMENT LEVEL (Roaring Bitmap)                                        │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  DocBitmaps["machine"] = {1, 2, 4, 5, 100, 500, 1000, ...}             │
│                                                                           │
│  Compressed representation of ALL documents containing "machine"         │
│  Use: Fast boolean operations (AND, OR, NOT)                            │
│  Size: ~60 KB for 500k documents (400x compression!)                    │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ Links to
                                  ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  POSITION LEVEL (Skip List)                                             │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  PostingsList["machine"] = SkipList:                                    │
│                                                                           │
│    Level 2: [Doc1:Pos5] ────────────────────────&amp;gt; [Doc100:Pos12]       │
│                 │                                       │                │
│    Level 1: [Doc1:Pos5] ──&amp;gt; [Doc2:Pos3] ───────────&amp;gt; [Doc100:Pos12]   │
│                 │              │                         │               │
│    Level 0: [Doc1:Pos5] -&amp;gt; [Doc2:Pos3] -&amp;gt; [Doc4:Pos1] -&amp;gt; [Doc5:Pos7]  │
│             -&amp;gt; [Doc100:Pos12] -&amp;gt; [Doc500:Pos2] -&amp;gt; ...                  │
│                                                                           │
│  Detailed position information for EVERY occurrence                      │
│  Use: Phrase search, proximity ranking, snippets                        │
│  Size: ~24 MB for 500k positions                                        │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘

WHY HYBRID?
───────────
1. Bitmaps: Lightning-fast document filtering (AND, OR, NOT in microseconds)
2. Skip Lists: Precise position tracking for phrases and proximity
3. Best of both worlds: Speed + Precision
&lt;/code&gt;
    &lt;p&gt;Here's how a complex query executes step-by-step:&lt;/p&gt;
    &lt;code&gt;QUERY: (machine OR deep) AND learning AND NOT neural

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 1: BITMAP PHASE (Fast Document Filtering)                         │
└─────────────────────────────────────────────────────────────────────────┘

Term Lookups (O(1) hash map):
    DocBitmaps["machine"] = {1, 2, 4, 5, 7, 8, 9, 10}
    DocBitmaps["deep"]    = {2, 3, 5, 6, 8, 9}
    DocBitmaps["learning"]= {1, 2, 4, 5, 6, 7, 8, 9, 10}
    DocBitmaps["neural"]  = {3, 6, 8, 9}

Boolean Operations (O(1) per chunk):
    Step 1: machine OR deep
            {1, 2, 4, 5, 7, 8, 9, 10} ∪ {2, 3, 5, 6, 8, 9}
          = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

    Step 2: (machine OR deep) AND learning
            {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} ∩ {1, 2, 4, 5, 6, 7, 8, 9, 10}
          = {1, 2, 4, 5, 6, 7, 8, 9, 10}

    Step 3: Result AND NOT neural
            {1, 2, 4, 5, 6, 7, 8, 9, 10} \ {3, 6, 8, 9}
          = {1, 2, 4, 5, 7, 10}  ← CANDIDATE DOCUMENTS

    Time: ~10 microseconds for 1M documents!

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 2: POSITION PHASE (Optional - for phrases/proximity)              │
└─────────────────────────────────────────────────────────────────────────┘

IF phrase search needed:
    For each candidate doc {1, 2, 4, 5, 7, 10}:
        Use skip lists to verify exact positions
        Check consecutive positions for phrases
        Extract position data for snippets

    Time: O(log n) per position lookup

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 3: RANKING PHASE (BM25 Scoring)                                   │
└─────────────────────────────────────────────────────────────────────────┘

For each candidate document:
    1. Calculate IDF (Inverse Document Frequency):
       - Uses bitmap cardinality for instant document counts
       - IDF("machine") = log((N - df + 0.5) / (df + 0.5))
       - df = DocBitmaps["machine"].GetCardinality()

    2. Calculate TF (Term Frequency):
       - Retrieves from pre-computed DocStats
       - TF("machine", Doc1) = termFreqs["machine"]

    3. Apply BM25 formula:
       - Combines IDF, TF, and length normalization
       - Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)

    4. Sum scores for all query terms

Results sorted by score:
    Doc 5: 8.45
    Doc 2: 7.23
    Doc 1: 6.91
    ...

    Time: O(candidates × terms)
&lt;/code&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────────────────┐
│                    INVERTED INDEX STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

InvertedIndex {
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocBitmaps: map[string]*roaring.Bitmap                         │
    │  ───────────────────────────────────────────────────────────────│
    │  "machine"  → [Compressed Bitmap: 512 bytes]                    │
    │  "learning" → [Compressed Bitmap: 448 bytes]                    │
    │  "deep"     → [Compressed Bitmap: 256 bytes]                    │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~100 bytes per term (compressed)                       │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Parallel Storage
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  PostingsList: map[string]SkipList                              │
    │  ───────────────────────────────────────────────────────────────│
    │  "machine"  → SkipList with 10,000 position nodes               │
    │  "learning" → SkipList with 8,000 position nodes                │
    │  "deep"     → SkipList with 5,000 position nodes                │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~48 bytes per position (node overhead)                 │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Statistics
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocStats: map[int]DocumentStats                                │
    │  ───────────────────────────────────────────────────────────────│
    │  Doc1 → {Length: 150, TermFreqs: {"machine": 3, ...}}          │
    │  Doc2 → {Length: 200, TermFreqs: {"learning": 5, ...}}         │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~16 bytes per term per document                        │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Metadata
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  Global Statistics                                               │
    │  ───────────────────────────────────────────────────────────────│
    │  TotalDocs:   1,000,000                                         │
    │  TotalTerms:  150,000,000                                       │
    │  AvgDocLen:   150.0                                             │
    │  BM25Params:  {K1: 1.5, B: 0.75}                               │
    └─────────────────────────────────────────────────────────────────┘

    Mutex for thread safety (sync.RWMutex)
}

MEMORY BREAKDOWN (for 1M documents, 10M unique positions):
────────────────────────────────────────────────────────────
DocBitmaps:     ~10 MB  (compressed bitmaps)
PostingsList:   ~480 MB (skip list nodes)
DocStats:       ~500 MB (per-doc statistics)
Overhead:       ~10 MB  (maps, pointers, etc.)
────────────────────────────────────────────────────────────
TOTAL:          ~1 GB
&lt;/code&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────────────────┐
│                    ROARING BITMAP STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

Document IDs: {1, 2, 3, 100, 101, 102, 500000, 500001, 999999}

Traditional Bitmap (naive):
    [1,1,1,0,0...0,1,1,1,0...0,1,1,0...0,1]
    Size: 1,000,000 bits = 125 KB (wasteful for sparse data)

Roaring Bitmap (smart):

    Split into 65,536 chunks (high 16 bits = chunk ID):

    Chunk 0 (docs 0-65535):      [1,2,3,100,101,102]
    Chunk 7 (docs 458752-524287): [500000, 500001]
    Chunk 15 (docs 983040-1048575): [999999]

    Storage per chunk (adaptive):
    ┌────────────────────────────────────────────────────┐
    │ If cardinality &amp;lt; 4096:                             │
    │   → Use Array Container                            │
    │   → Store sorted uint16 values directly            │
    │   → Size: 2 bytes × cardinality                    │
    │                                                     │
    │ If cardinality &amp;gt; 4096:                             │
    │   → Use Bitmap Container                           │
    │   → Store 65536-bit bitmap (8 KB)                 │
    │   → Size: 8 KB fixed                               │
    │                                                     │
    │ If cardinality = 65536 (all docs):                │
    │   → Use Run Container                              │
    │   → Store: [0-65535]                               │
    │   → Size: 4 bytes                                  │
    └────────────────────────────────────────────────────┘

    Total Size: ~60 bytes (vs 125 KB!)

    Operations:

    AND: Container-by-container intersection
         Skip non-matching chunks (O(1))
         Intersect matching chunks (O(min(n,m)))

    OR:  Container-by-container union
         Merge all chunks (O(n+m))

    NOT: Complement within document space
         Flip all bits in each chunk
&lt;/code&gt;
    &lt;code&gt;┌─────────────────────────────────────────────────────────────────────────┐
│                   QUERY BUILDER EXECUTION MODEL                          │
└─────────────────────────────────────────────────────────────────────────┘

Query: NewQueryBuilder(idx).
         Group(func(q) { q.Term("machine").Or().Term("deep") }).
         And().
         Term("learning").
         Execute()

INTERNAL REPRESENTATION:
────────────────────────

QueryBuilder {
    stack: []*roaring.Bitmap       // Operand stack
    ops:   []QueryOp               // Operator stack
    terms: []string                // Track for BM25
}

EXECUTION TRACE:
────────────────

Step 1: Group(func(q) { ... })
    ┌──────────────────────────────────────┐
    │ Create sub-builder                    │
    │ Execute sub-query                     │
    │ Push result bitmap to parent stack    │
    └──────────────────────────────────────┘

    Sub-query execution:
      1.1: Term("machine")
           → Lookup: DocBitmaps["machine"]
           → Push: {1,2,4,5,7,8,9,10}

      1.2: Or()
           → Push operator: OR

      1.3: Term("deep")
           → Lookup: DocBitmaps["deep"]
           → Push: {2,3,5,6,8,9}

      1.4: Apply OR
           → Pop: {2,3,5,6,8,9}
           → Pop: {1,2,4,5,7,8,9,10}
           → Union: {1,2,3,4,5,6,7,8,9,10}
           → Push result

    Result: {1,2,3,4,5,6,7,8,9,10}

Step 2: And()
    → Push operator: AND

Step 3: Term("learning")
    → Lookup: DocBitmaps["learning"]
    → Push: {1,2,4,5,6,7,8,9,10}

Step 4: Execute()
    → Pop: {1,2,4,5,6,7,8,9,10}
    → Pop: {1,2,3,4,5,6,7,8,9,10}
    → Intersect: {1,2,4,5,6,7,8,9,10}
    → Return final bitmap

OPERATION COSTS:
────────────────
Bitmap Lookup:    O(1)          ~100 ns
Bitmap Union:     O(n+m)        ~1 µs for 10k docs
Bitmap Intersect: O(min(n,m))   ~800 ns for 10k docs
Bitmap Difference: O(n)         ~900 ns for 10k docs

Total Query Time: ~10 µs for typical query!
&lt;/code&gt;
    &lt;code&gt;┌──────────────────────────────────────────────────────────────────────┐
│                         Complete Data Flow                           │
└──────────────────────────────────────────────────────────────────────┘

                              User Input
                       "The Quick Brown Fox!"
                                │
                                ▼
            ┌───────────────────────────────────────────┐
            │      Text Analysis Pipeline               │
            │  ┌─────────────────────────────────────┐  │
            │  │ 1. Tokenization                     │  │
            │  │    ["The", "Quick", "Brown", "Fox"] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 2. Lowercasing                      │  │
            │  │    ["the", "quick", "brown", "fox"] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 3. Stopword Filtering               │  │
            │  │    ["quick", "brown", "fox"]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 4. Length Filtering                 │  │
            │  │    ["quick", "brown", "fox"]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 5. Stemming                         │  │
            │  │    ["quick", "brown", "fox"]        │  │
            │  └────────────┬────────────────────────┘  │
            └───────────────┼────────────────────────────┘
                            ▼
                    ["quick", "brown", "fox"]
                            │
                            ▼
            ┌───────────────────────────────────────────┐
            │       Inverted Index (Indexing)           │
            │                                            │
            │  ┌─────────┬────────────────────────┐     │
            │  │ "quick" │ → SkipList             │     │
            │  │         │    └─&amp;gt; [Doc1:Pos0]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ "brown" │ → SkipList             │     │
            │  │         │    └─&amp;gt; [Doc1:Pos1]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ "fox"   │ → SkipList             │     │
            │  │         │    └─&amp;gt; [Doc1:Pos2]     │     │
            │  └─────────┴────────────────────────┘     │
            └───────────────┬───────────────────────────┘
                            │
          ┌─────────────────┴─────────────────┐
          │        Search Operations          │
          ▼                                   ▼
    ┌──────────┐                      ┌────────────┐
    │  Term    │                      │  Phrase    │
    │  Search  │                      │  Search    │
    └────┬─────┘                      └─────┬──────┘
         │                                  │
         └──────────┬───────────────────────┘
                    ▼
            ┌───────────────┐
            │   Proximity   │
            │   Ranking     │
            └───────┬───────┘
                    │
                    ▼
            ┌───────────────────────┐
            │  Ranked Results       │
            │  ┌─────────────────┐  │
            │  │ Doc 1: Score 1.0│  │
            │  │ Doc 2: Score 0.5│  │
            │  │ Doc 3: Score 0.3│  │
            │  └─────────────────┘  │
            └───────────────────────┘
&lt;/code&gt;
    &lt;p&gt;1. Skip Lists over Balanced Trees&lt;/p&gt;
    &lt;p&gt;Rationale:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Simpler implementation (no rotation logic)&lt;/item&gt;
      &lt;item&gt;Better cache locality&lt;/item&gt;
      &lt;item&gt;Easier to make concurrent&lt;/item&gt;
      &lt;item&gt;Comparable performance (O(log n))&lt;/item&gt;
      &lt;item&gt;Used in production systems (Redis, LevelDB)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Position-Based Indexing&lt;/p&gt;
    &lt;p&gt;Instead of just tracking document IDs, Blaze tracks exact word positions:&lt;/p&gt;
    &lt;code&gt;Traditional Index (Document IDs only):
┌─────────┬──────────────────┐
│ "quick" │ [Doc1, Doc3]     │  Cannot do phrase search
└─────────┴──────────────────┘  Cannot rank by proximity

Position-Based Index (Document + Offset):
┌─────────┬────────────────────────────────────┐
│ "quick" │ [Doc1:Pos1, Doc3:Pos0]             │  Enables phrase search
│ "brown" │ [Doc1:Pos2, Doc3:Pos1]             │  Enables proximity ranking
│ "fox"   │ [Doc1:Pos3]                        │  Enables snippet generation
└─────────┴────────────────────────────────────┘  Enables precise results

Can verify: "quick brown" is a phrase in Doc1 (Pos1→Pos2)
            but NOT in Doc3 (Pos0 and Pos1 are not "quick brown")
&lt;/code&gt;
    &lt;p&gt;Benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enables phrase search (check consecutive positions)&lt;/item&gt;
      &lt;item&gt;Enables proximity ranking (measure distances)&lt;/item&gt;
      &lt;item&gt;Enables snippet generation (extract relevant parts)&lt;/item&gt;
      &lt;item&gt;More precise search results&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Trade-offs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Larger index size (~2-3x more data)&lt;/item&gt;
      &lt;item&gt;More complex algorithms (but still O(log n))&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;3. Binary Serialization&lt;/p&gt;
    &lt;p&gt;Custom binary format instead of JSON:&lt;/p&gt;
    &lt;p&gt;Advantages:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;60% smaller file size&lt;/item&gt;
      &lt;item&gt;3x faster parsing&lt;/item&gt;
      &lt;item&gt;Preserves skip list structure&lt;/item&gt;
      &lt;item&gt;Suitable for large indexes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;4. Configurable Text Analysis&lt;/p&gt;
    &lt;p&gt;Pluggable analyzer configuration:&lt;/p&gt;
    &lt;p&gt;Benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Adapt to different use cases&lt;/item&gt;
      &lt;item&gt;Trade-off precision vs recall&lt;/item&gt;
      &lt;item&gt;Support multiple languages (future)&lt;/item&gt;
      &lt;item&gt;Domain-specific customization&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use stable, unique identifiers:&lt;/p&gt;
    &lt;code&gt;// Good: Use database primary keys
idx.Index(dbRecord.ID, dbRecord.Content)

// Bad: Use array indices (changes when reordering)
for i, doc := range docs {
    idx.Index(i, doc.Content)  // Don't do this
}&lt;/code&gt;
    &lt;code&gt;func IndexLargeDataset(docs []Document) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    // Process in batches
    batchSize := 1000
    for i := 0; i &amp;lt; len(docs); i += batchSize {
        end := min(i+batchSize, len(docs))
        batch := docs[i:end]

        for _, doc := range batch {
            idx.Index(doc.ID, doc.Content)
        }

        // Optional: periodic serialization for checkpoints
        if i%10000 == 0 {
            data, _ := idx.Encode()
            os.WriteFile(fmt.Sprintf("checkpoint_%d.bin", i), data, 0644)
        }
    }

    return idx
}&lt;/code&gt;
    &lt;p&gt;Match configuration to your use case:&lt;/p&gt;
    &lt;code&gt;// Natural language text (books, articles)
naturalLanguageConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  true,   // Find related words
    EnableStopwords: true,   // Remove common words
}

// Technical documentation (code, APIs)
technicalConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  false,  // Keep exact terms
    EnableStopwords: false,  // Keep all words
}

// Product names (e-commerce)
productConfig := blaze.AnalyzerConfig{
    MinTokenLength:  1,      // Include single chars (e.g., "X")
    EnableStemming:  false,  // Exact product names
    EnableStopwords: false,  // Keep all words
}&lt;/code&gt;
    &lt;p&gt;Don't rebuild the index every time:&lt;/p&gt;
    &lt;code&gt;const indexFile = "search_index.bin"

func LoadOrBuildIndex(docs []Document) (*blaze.InvertedIndex, error) {
    // Try to load existing index
    if data, err := os.ReadFile(indexFile); err == nil {
        idx := blaze.NewInvertedIndex()
        if err := idx.Decode(data); err == nil {
            return idx, nil
        }
    }

    // Build new index
    idx := blaze.NewInvertedIndex()
    for _, doc := range docs {
        idx.Index(doc.ID, doc.Content)
    }

    // Save for next time
    if data, err := idx.Encode(); err == nil {
        os.WriteFile(indexFile, data, 0644)
    }

    return idx, nil
}&lt;/code&gt;
    &lt;p&gt;The Index method is thread-safe, but for read-heavy workloads:&lt;/p&gt;
    &lt;code&gt;type SearchService struct {
    idx *blaze.InvertedIndex
    mu  sync.RWMutex
}

func (s *SearchService) Index(docID int, content string) {
    s.mu.Lock()
    defer s.mu.Unlock()
    s.idx.Index(docID, content)
}

func (s *SearchService) Search(query string) []blaze.Match {
    s.mu.RLock()
    defer s.mu.RUnlock()
    return s.idx.RankProximity(query, 20)
}&lt;/code&gt;
    &lt;p&gt;Track index growth:&lt;/p&gt;
    &lt;code&gt;func (idx *InvertedIndex) Stats() map[string]interface{} {
    stats := make(map[string]interface{})

    stats["unique_terms"] = len(idx.PostingsList)

    totalPositions := 0
    for _, skipList := range idx.PostingsList {
        // Count positions in this skip list
        iter := skipList.Iterator()
        for iter.HasNext() {
            iter.Next()
            totalPositions++
        }
    }

    stats["total_positions"] = totalPositions
    stats["avg_positions_per_term"] = float64(totalPositions) / float64(len(idx.PostingsList))

    return stats
}&lt;/code&gt;
    &lt;p&gt;Use BM25 when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You need industry-standard relevance ranking&lt;/item&gt;
      &lt;item&gt;Term frequency matters (documents with more occurrences rank higher)&lt;/item&gt;
      &lt;item&gt;You want automatic length normalization&lt;/item&gt;
      &lt;item&gt;Rare terms should be weighted more heavily&lt;/item&gt;
      &lt;item&gt;Recommended for most use cases&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Proximity when:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You want to find terms close together&lt;/item&gt;
      &lt;item&gt;Term distance is more important than frequency&lt;/item&gt;
      &lt;item&gt;You're searching for specific co-occurrences&lt;/item&gt;
      &lt;item&gt;You need snippet generation (using position data)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Practical Examples:&lt;/p&gt;
    &lt;code&gt;// E-commerce: General product search
// BM25 considers term frequency and rarity
bm25Results := idx.RankBM25("wireless bluetooth headphones", 20)
// Returns products with any/all terms, ranked by relevance

// E-commerce: Exact product name
// Proximity finds terms appearing together
proxResults := idx.RankProximity("Sony WH-1000XM4", 20)
// Returns products where terms appear close together

// Document search: Research papers
// BM25 for broad topic search
papers := idx.RankBM25("neural networks deep learning", 50)

// Document search: Finding specific phrase mentions
// Proximity for finding "neural networks" as a concept
mentions := idx.RankProximity("neural networks", 50)

// Best practice: Use both for different purposes!
generalResults := idx.RankBM25(query, 100)    // Cast wide net
preciseResults := idx.RankProximity(query, 20) // Refine results&lt;/code&gt;
    &lt;p&gt;Always specify a reasonable max results:&lt;/p&gt;
    &lt;code&gt;// Good: Limit results
results := idx.RankBM25("search query", 100)

// Bad: Could return millions of results
results := idx.RankBM25("search query", math.MaxInt32)&lt;/code&gt;
    &lt;p&gt;Normalize queries before searching:&lt;/p&gt;
    &lt;code&gt;func NormalizeQuery(query string) string {
    // Remove extra whitespace
    query = strings.TrimSpace(query)
    query = strings.Join(strings.Fields(query), " ")

    // Convert to lowercase
    query = strings.ToLower(query)

    // Remove special characters (optional)
    query = regexp.MustCompile(`[^\w\s]`).ReplaceAllString(query, "")

    return query
}

// Use normalized query
normalizedQuery := NormalizeQuery(userInput)
results := idx.RankBM25(normalizedQuery, 20)&lt;/code&gt;
    &lt;p&gt;Track corpus statistics for insights:&lt;/p&gt;
    &lt;code&gt;// After indexing
fmt.Printf("Total documents: %d\n", idx.TotalDocs)
fmt.Printf("Total terms: %d\n", idx.TotalTerms)
fmt.Printf("Average doc length: %.2f\n",
    float64(idx.TotalTerms) / float64(idx.TotalDocs))

// Per-document analysis
for docID, stats := range idx.DocStats {
    fmt.Printf("Doc %d: %d terms\n", docID, stats.Length)

    // Find most frequent terms
    for term, freq := range stats.TermFreqs {
        if freq &amp;gt; 5 {
            fmt.Printf("  %s: %d occurrences\n", term, freq)
        }
    }
}&lt;/code&gt;
    &lt;p&gt;Contributions are welcome! Please follow these guidelines:&lt;/p&gt;
    &lt;code&gt;# Clone repository
git clone https://github.com/wizenheimer/blaze.git
cd blaze

# Install dependencies
make deps

# Run tests
make test

# Run linter
make lint&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow Go conventions (gofmt, golint)&lt;/item&gt;
      &lt;item&gt;Write comprehensive comments&lt;/item&gt;
      &lt;item&gt;Include examples in documentation&lt;/item&gt;
      &lt;item&gt;Add tests for new features&lt;/item&gt;
      &lt;item&gt;Keep functions focused and small&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use descriptive commit messages:&lt;/p&gt;
    &lt;code&gt;Good:
- "feat: Add proximity ranking algorithm"
- "feat: Handle empty query in RankProximity"
- "fix: Reduce allocations in skip list insert"

Bad:
- "Update code"
- "Fix bug uwu"
- "WIP"
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fork the repository&lt;/item&gt;
      &lt;item&gt;Create a feature branch (&lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Make your changes&lt;/item&gt;
      &lt;item&gt;Add tests&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;make check&lt;/code&gt;to verify&lt;/item&gt;
      &lt;item&gt;Commit your changes&lt;/item&gt;
      &lt;item&gt;Push to your fork&lt;/item&gt;
      &lt;item&gt;Open a Pull Request&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT License&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Skip Lists: Original paper by William Pugh (1990)&lt;/item&gt;
      &lt;item&gt;Snowball Stemmer: Martin Porter's stemming algorithm&lt;/item&gt;
      &lt;item&gt;Inspiration: Elasticsearch, Lucene, Mettis, Redis, LevelDB&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/wizenheimer/blaze"/><published>2025-10-09T17:09:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45530486</id><title>LLMs are mortally terrified of exceptions</title><updated>2025-10-10T06:47:08.779694+00:00</updated><content>&lt;doc fingerprint="d635f48b34542867"&gt;
  &lt;main&gt;
    &lt;p&gt;We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.&lt;/p&gt;
    &lt;p&gt;Help Center&lt;/p&gt;
    &lt;p&gt;Terms of Service Privacy Policy Cookie Policy Imprint Ads info © 2025 X Corp.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://twitter.com/karpathy/status/1976077806443569355"/><published>2025-10-09T17:16:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45530744</id><title>Subway Builder: A realistic subway simulation game</title><updated>2025-10-10T06:47:08.560493+00:00</updated><content>&lt;doc fingerprint="2c92c4bb60b2a7fe"&gt;
  &lt;main&gt;
    &lt;p&gt;Subway Builder is a hyperrealistic transit simulation game. Build a new subway system from the ground up while dealing with real-world constraints and costs.&lt;/p&gt;
    &lt;p&gt;Features&lt;/p&gt;
    &lt;p&gt;Real-world passenger simulation&lt;/p&gt;
    &lt;p&gt;Millions of commuters are generated from Census and Redistricter data and simulated using the same pathfinding algorithms you use. Your job is to design a route network that gets the most people to their destination as fast as possible. Juggle station placement, transfer dynamics, and train frequency to maximize ridership.&lt;/p&gt;
    &lt;p&gt;Realistic construction challenges&lt;/p&gt;
    &lt;p&gt;Build your system under realistic constraints and costs. Tunnels, viaducts, cut-and-cover, all have trade offs. Negotiate with real-world buildings foundations, geography and road layouts as you expand your network&lt;/p&gt;
    &lt;p&gt;In-depth analysis&lt;/p&gt;
    &lt;p&gt;Explore how individual commuters weight use various variables like wait times, transfers, income distribution, delays, and more, to pick their commute. Understand which routes, stations, and trains your commuters take and use that information to optimize your network.&lt;/p&gt;
    &lt;p&gt;Delays and disruptions&lt;/p&gt;
    &lt;p&gt;Find the right balance between cost and time. Too many trains on a line or an overcrowded station will cause delays.&lt;/p&gt;
    &lt;p&gt;$30 on subwaybuilder.com and $40 on Steam (page is coming soon). The Steam launch won't happen for a few months after the launch on subwaybuilder.com.&lt;/p&gt;
    &lt;p&gt;Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;Probably. If your computer can run Google Earth on Chrome smoothly it can run Subway Builder it's a very lightweight game. It does require an internet connection to load the map tiles for the game though.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.subwaybuilder.com/"/><published>2025-10-09T17:38:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45531367</id><title>Hacker News Live Feed</title><updated>2025-10-10T06:47:08.408493+00:00</updated><content>&lt;doc fingerprint="e6e238c62cc54c62"&gt;
  &lt;main&gt;
    &lt;p&gt;Hacker News new | threads | past | comments | ask | show | jobs | submit | live repo This feed needs JavaScript enabled to load. [username] 0 minutes ago | parent [comment body HTML] [title] ( [domain] ) [points] by [username] 0 minutes ago | past | 0 comments&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jerbear2008.github.io/hn-live/"/><published>2025-10-09T18:33:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45531721</id><title>The government ate my name</title><updated>2025-10-10T06:47:08.301940+00:00</updated><content>&lt;doc fingerprint="3a1d815e933184dd"&gt;
  &lt;main&gt;
    &lt;p&gt;Sign up for the Slatest to get the most insightful analysis, criticism, and advice out there, delivered to your inbox daily.&lt;/p&gt;
    &lt;p&gt;The Starbucks barista calls out “Joe, grande latte for Joe!” It takes him two tries before I remember I’m Joe and go pick up my coffee. A minor episode in the long history of non-Anglo immigrants changing their names after moving to America.&lt;/p&gt;
    &lt;p&gt;If your family immigrated to the United States in the 19th century and/or you took middle-school social studies in the States, you’ve probably heard that officials at Ellis Island often changed newcomers’ names, either because they couldn’t spell them or because they wanted to make them sound more American. In fact, authorities in New York never actually wrote down anyone’s name, they just checked each immigrant against the ship’s passenger list, which would have been compiled by employees of the steamship companies. That means that your grandpa Szymańczyk turned into Simmons before he even set foot on the boat. My case, though, is less about forced reinvention than about bureaucratic drift. Names are bearers of our identity, history, and culture, but a lot can happen when they are run through the machinery of another culture’s bureaucracy.&lt;/p&gt;
    &lt;p&gt;I was born in Mexico City, and my parents named me Leonel Giovanni García Fenech. It might sound a little baroque to Americans, but having four names is standard in Spanish-speaking countries. And it can be surprisingly useful if one of your last names happens to be García, the most common surname in Spain and the second most common in Mexico. Or if you were my former co-worker, who shared a name with someone convicted of running over a child while drunk. That was the first thing anyone saw if they Googled her, so an extra name or two could have spared her countless awkward explanations during job interviews.&lt;/p&gt;
    &lt;p&gt;As the firstborn, I was named after both of my grandfathers: Leonel hints at my father’s Spanish Jewish ancestry; diaspora families with the name Yehuda often used variations of the translation for lion, the traditional symbol for the Tribe of Yehuda. Giovanni, on the other hand, came from my Sicilian grandfather, and is just the Italian version of John.&lt;/p&gt;
    &lt;p&gt;Same with my last names: García is my father’s, Fenech my mother’s. I didn’t find out until I was an adult that Fenech is not actually Italian, as my family always assumed. It’s Maltese, it means rabbit, and it’s one of Malta’s most common surnames. Furthermore, it turns out my family has been mispronouncing it all along—it’s FE-neck, not fe-NECH. Famous people named Fenech include the ’70s soft-porn actress Edwige Fenech and, more recently, Yorgen Fenech, a Maltese businessman currently facing criminal charges for corruption, money laundering, and the murder of a journalist.&lt;/p&gt;
    &lt;p&gt;In Mexico, everyone called me Giovanni, never Leonel. (I only recently learned it was because my dad couldn’t stand his own father.) When we moved to the U.S. I always introduced myself as Giovanni. I never understood why Americans were embarrassed by their middle names—except for that time when President Barack Obama joked that he envied Willard Mitt Romney being able to go by his middle name. The punchline being, of course, that Obama’s is Hussein.&lt;/p&gt;
    &lt;p&gt;When I was sworn in as a U.S. citizen, the clerk surprised me when he announced I could now change my name to whatever I wanted. “Even Ronald Reagan!” he joked. (Not quite as weird as it sounds, as Reagan was still in office.) I almost said, “OK, let’s do that!” but thought better of it. Caught off guard, I simply asked him to drop Leonel. Four names only seemed to confuse Americans, and I never used it anyway, so why not make life easier? That’s how I became an American named Giovanni Garcia Fenech.&lt;/p&gt;
    &lt;p&gt;But the cut didn’t solve any problems. Everyone I met still called me “Gio” without asking. My girlfriend’s grandmother went with Geronimo. I also often received mail addressed to Giovanni Garcia French.&lt;/p&gt;
    &lt;p&gt;And of course, the bureaucrats still weren’t having it. When I got my driver’s license, the DMV insisted on cramming everything into a “first, middle, last” format and turned me into Giovanni F Garcia (sans acute accent). The passport office, trying slightly harder to keep the order of my names correct, made Garcia my middle name (again, no acute accent) and Fenech my last. In typical Gen X fashion, I was apathetic about the mess. Oh well, whatever, never mind. I just started hyphenating my last name to Garcia-Fenech and left it at that. Nobody seemed to care. The bank cashed my checks.&lt;/p&gt;
    &lt;p&gt;But there were other things happening in the world. In response to 9/11, Congress had passed the REAL ID Act, requiring a new type of identification to board domestic flights (because nothing terrifies a terrorist like having to spend a day at the DMV). However, since the feds didn’t fund it, nothing happened, and I didn’t even hear about it until 2019, when the government announced that, this time for real, you’d need Real ID to fly. Like a sucker, I believed them and decided it was time to fix my documents. (It’s been postponed twice since then. The new deadline is now 2027, wink wink.)&lt;/p&gt;
    &lt;p&gt;I could have used this as an opportunity to change my driver’s license to match my passport, but convenience won out. Every important document I had—Social Security, bank accounts, marriage certificate, school records—listed me as Giovanni F. Garcia, and the thought of having to change all of that made me dizzy. Thankfully, the passport office didn’t object.&lt;lb/&gt;In November 2024, my wife and I decided to move to Spain (you can guess why). We could do this because she’s German, and as an EU citizen she’s allowed to take her spouse along. As we researched our move, I discovered that Latin Americans can apply for Spanish citizenship after just two years of residency, instead of the usual 10 for others. Only catch: I needed a Mexican passport, and didn’t have one—or any Mexican documents, for that matter.&lt;/p&gt;
    &lt;p&gt;The consulate in New York happily issued me a birth certificate, but balked at a passport. They explained that my birth certificate listed me as Leonel Giovanni García Fenech but my American ID said my name was Giovanni F. Garcia. Never mind that they were the ones that had just given me the certificate. And so, to Spain I went, with my wife, my butchered name, and my American passport.&lt;/p&gt;
    &lt;p&gt;We’d been warned about Spanish bureaucracy, and I pictured Dickensian clerks with sleeve garters and green eyeshades demanding documents in triplicate. But what we encountered in Seville wasn’t that different from the American equivalent: bad websites, confusing instructions, long lines. They did enjoy stamping documents, but they were no better with names. My new foreigner’s ID listed me as Giovanni F García—acute accent restored!—but when I opened a bank account, I discovered my first name had become “Giovanni F.” Not Giovanni, not Giovanni plus middle initial. Giovanni F. Still, better than “Gio.”&lt;/p&gt;
    &lt;p&gt;Not ready to give up on an expedited European passport, I decided to visit Madrid to try my luck at the Mexican consulate there. If I couldn’t get a Mexican passport with my full name, I’d at least get to visit some world-class museums. The good news first: The museums were fantastic. As for the consulate, after a couple of hours of waiting, they called out my full name: “Leonel Giovanni García Fenech!” The official didn’t give me a chance to speak. “Look into here,” he said, pointing to some goggle-like device. “We need to photograph your irises for biometric identification.” Oh wow, this was actually going to work. “Now stand there for your photograph.” I grinned. The joy didn’t last long. “This is provisional, good for one year,” the official explained. “We can’t give you a regular passport until you bring us documentation with your full name. See here?” He ran his finger over the name on my naturalization document. “It just says Giovanni Garcia Fenech. And your U.S. passport is even worse—they’ve changed Fenech to just a single F! Have them fix it and then we can proceed.” I tried to explain that if not even Starbucks can get my name right, what were the chances the American government would? But he wasn’t interested, and there was a long line of people with dependable names waiting to get their irises scanned. Dejected, I went back to Seville with my ever-growing folder of documents under different names.&lt;/p&gt;
    &lt;p&gt;I spent a few days at home weighing my options. Could my parents find other Mexican documents with my original name? Could I legally change it back in the U.S., or would that just tangle my paperwork in Spain? How much more Kafkaesque could this get? Then something happened that made me reconsider everything. I was standing in line at the local bazar (the Spanish version of a dollar store) when an elderly woman ahead of me asked the Chinese owner her name. “Lola,” she said. “Lola! And how did you get that name?” the woman pressed. The owner shrugged. “People kept coming in asking for a Lola who used to work here, so eventually I just started saying that was me.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://slate.com/life/2025/10/passport-name-change-united-states-mexico-spain-immigration.html"/><published>2025-10-09T19:03:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45532090</id><title>Examples Are the Best Documentation</title><updated>2025-10-10T06:47:08.043735+00:00</updated><content>&lt;doc fingerprint="7263b02262775695"&gt;
  &lt;main&gt;
    &lt;p&gt;When I'm searching for docs, 95% of the time a single example would suffice. Yet, 95% of the time I can't find one in any official source.&lt;/p&gt;
    &lt;p&gt;It seems that by default formal technical documentation is targeted towards someone who's deeply immersed in the ecosystem. But many developers have to juggle a lot of "worlds" in their heads daily. When jumping between projects, languages and frameworks, it takes a considerable amount of mental energy to restore the context and understand what is going on.&lt;/p&gt;
    &lt;p&gt;Consider this example from the Python 3 docs:&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;max(iterable, /, *, key=None)&lt;/code&gt;Return the largest item in an iterable or the largest of two or more arguments.... [followed by 5 short paragraphs].&lt;/quote&gt;
    &lt;p&gt;You need to know quite a bit about Python in order to understand this:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;What &lt;code&gt;*&lt;/code&gt;means in the function definition.&lt;/item&gt;
      &lt;item&gt;What &lt;code&gt;/&lt;/code&gt;means in the function definition.&lt;/item&gt;
      &lt;item&gt;What's a "positional-only parameter separator"&lt;/item&gt;
      &lt;item&gt;What's an iterable.&lt;/item&gt;
      &lt;item&gt;What are keyword-only arguments.&lt;/item&gt;
      &lt;item&gt;What &lt;code&gt;key&lt;/code&gt;usually means.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then you have to read some text in order to understand what values you can pass and how to actually call the function.&lt;/p&gt;
    &lt;p&gt;Granted, these are important details that can't be omitted for brevity. But I bet a lot of developers looked at that page simply because they needed to quickly find out how to pass a custom sorting function. This example would've quickly helped them:&lt;/p&gt;
    &lt;code&gt;max(4, 6) # → 6

max([1, 2, 3]) # → 3

max(['x', 'y', 'abc'],  key=len) # → 'abc'

max([]) # ValueError: max() arg is an empty sequence

max([], default=5) # → 5
&lt;/code&gt;
    &lt;p&gt;Easy, right?&lt;/p&gt;
    &lt;p&gt;One popular community-based project in the Clojure world is clojuredocs.org, a site where people contribute examples for built in functions. It's fantastic and, in my experience, indispensable in day-to-day coding. For example, check out the pages about into or spit or map. Note that examples often include related functions, not only those in question. This increases the real-world usefulness and practicality.&lt;/p&gt;
    &lt;p&gt;Since even major software projects rarely offer 4 distinct kinds of documentation, I am often hesitant to click on a "Documentation" link. Chances are, it's a terse, difficult to read, automatically generated API reference. I often choose to find a tutorial, not because I need a walk-through, but because I need examples.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rakhim.exotext.com/examples-are-the-best-documentation"/><published>2025-10-09T19:34:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45532352</id><title>The Burrows-Wheeler Transform</title><updated>2025-10-10T06:47:07.515706+00:00</updated><content>&lt;doc fingerprint="16f801e57fbc05b3"&gt;
  &lt;main&gt;&lt;p&gt;October 9, 2025&lt;/p&gt;&lt;p&gt;In this interactive article, we explore the borderline-magical algorithm known as the Burrows-Wheeler Transform (BWT). It powers data compression in &lt;code&gt;bzip2&lt;/code&gt;, and is used by sequence alignment tools like &lt;code&gt;bowtie&lt;/code&gt; and &lt;code&gt;bwa&lt;/code&gt;, both of which were named after the algorithm.&lt;/p&gt;&lt;p&gt;The BWT has 2 key properties:&lt;/p&gt;&lt;code&gt;coconut&lt;/code&gt; is &lt;code&gt;tooccun&lt;/code&gt;.&lt;p&gt;Before we dive in, you should know that the BWT has a third, unofficial property: it is not intuitive. Many of the steps in the algorithm will seem arbitrary and it might not be clear why you're even doing them. I'm hoping this article helps you build some intuition around the BWT.&lt;/p&gt;&lt;p&gt;To apply the BWT on a string like , there are 3 steps to follow:&lt;/p&gt;&lt;p&gt;Write down all rotations:&lt;/p&gt;banana$&lt;p&gt;Sort rotated strings:&lt;/p&gt;$banana&lt;p&gt;The BWT is the last column:&lt;/p&gt;annb$aa&lt;p&gt;The &lt;code&gt;$&lt;/code&gt; marks the end of the string, and is needed to make the BWT reversible. Without that marker, you could still
		regenerate the matrix in Step , but you wouldn't know which row contains the original string. If it's
		an English word, you might guess it's &lt;code&gt;banana&lt;/code&gt; and not &lt;code&gt;nabana&lt;/code&gt;, but that's harder to do with DNA because most rotations will look reasonable.&lt;/p&gt;&lt;p&gt;In Step , the sorting causes rows that start the same to be more likely to be grouped together. As a result, the character that comes right before (i.e. the character in the last column) is also likely to be similar, based on repeated patterns in the English language, and also in DNA sequences!&lt;/p&gt;&lt;p&gt;For example, in the BWT of , the letter &lt;code&gt;c&lt;/code&gt; is grouped because it's always followed by an &lt;code&gt;o&lt;/code&gt;. Although &lt;code&gt;o&lt;/code&gt; is followed by
		either &lt;code&gt;c&lt;/code&gt; or &lt;code&gt;n&lt;/code&gt;, it still clusters in the BWT because its corresponding rows end up being sorted next
		to each other.&lt;/p&gt;&lt;p&gt;If there was a row in Step that started with a letter in between &lt;code&gt;c&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt;, the &lt;code&gt;o&lt;/code&gt;'s would no longer cluster. For example, what happens to the &lt;code&gt;o&lt;/code&gt;'s if you add an &lt;code&gt;i&lt;/code&gt; to &lt;code&gt;coconut&lt;/code&gt;: . Would the &lt;code&gt;o&lt;/code&gt;'s
		cluster if you tried ?&lt;/p&gt;&lt;p&gt;Now it's your turn: try encoding your name or a repetitive string. Which characters can you add or remove to make the BWT cluster more or less?&lt;/p&gt;&lt;p&gt;Given the encoded string, we can reconstruct the matrix from Step as follows: Start with an empty matrix, prepend the BWT string, sort the strings, and repeat until the matrix is filled. Keep clicking Next below until you reconstruct the matrix; the matrix on the right shows the final answer we're working towards.&lt;/p&gt;&lt;p&gt;Current BWT matrix:&lt;/p&gt;&lt;p&gt;Step 0:&lt;/p&gt;&lt;p&gt;Expected matrix:&lt;/p&gt;$banana&lt;p&gt;Once the matrix is filled, we can read off the string from any of the rows since we have the &lt;code&gt;$&lt;/code&gt; marker.&lt;/p&gt;&lt;p&gt;Starting from an empty matrix, note that adding the BWT column and sorting gives you the first column of the expected BWT matrix. If you then prepend and sort a second time, you now have the first two columns of the BWT matrix. You can keep going to recreate the whole matrix.&lt;/p&gt;&lt;p&gt;To understand why this works, let's consider a scenario where I give you the first 2 columns of the BWT matrix and ask you to figure out the rest. Remember that the BWT is the last column of the matrix, i.e. the characters that come right before the first column. So by prepending the BWT to the first column, we're still preserving the relationships between the substrings we reconstructed so far (you can imagine the BWT matrix rotates on itself to connect the first and last column together). Then, sorting the current set of substrings gives us the first 3 columns of the BWT matrix.&lt;/p&gt;&lt;p&gt;So far, we've seen how to use the Burrows-Wheeler Transform to encode and decode strings. That's nice and all, but how can we use the BWT for sequence alignment, i.e. looking for a small string in a much larger string?&lt;/p&gt;&lt;p&gt;To do that, I first need to introduce yet another magical property of the BWT: Last-to-first Mapping.&lt;/p&gt;&lt;p&gt;This property states that the order in which you see a letter in the first column is the same order in which you see it in the last column!&lt;/p&gt;&lt;p&gt;Let's consider the word &lt;code&gt;banana&lt;/code&gt;: if we annotate each letter with the number of times it occurs in the string
		before creating the BWT matrix, the letter &lt;code&gt;a&lt;/code&gt; appears in the same order in both the first and last column: a2, a1, a0!&lt;/p&gt;&lt;p&gt;With that in mind, let's find all occurences of the pattern &lt;code&gt;an&lt;/code&gt; within &lt;code&gt;banana&lt;/code&gt;, using only the first
		and last columns. Let's begin by finding rows that start with the last character of the pattern (i.e. &lt;code&gt;n&lt;/code&gt;)âyou'll see why in a second:&lt;/p&gt;&lt;p&gt;Now that we have an &lt;code&gt;n&lt;/code&gt; in the first column, we know that the last column is the character that comes right before &lt;code&gt;n&lt;/code&gt;, so we can look for an &lt;code&gt;a&lt;/code&gt; in that last column. We find two matches: a1 and a0, so we can visit rows that have those characters in the first column:&lt;/p&gt;&lt;p&gt;And voilÃ , we found the only matches for our search query of &lt;code&gt;an&lt;/code&gt; within &lt;code&gt;banana&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;A few sections ago, we decoded the BWT string by recreating the entire BWT matrix, which was a lot of work. Could we instead use this LF property to decode the BWT string? As a matter of fact, we can!&lt;/p&gt;&lt;p&gt;You can think of decoding the BWT string as a special case of searching, where we're looking for whichever string ends with &lt;code&gt;$&lt;/code&gt;. So we can start by finding the &lt;code&gt;$&lt;/code&gt; character, then hop around between the first and column until we find the &lt;code&gt;$&lt;/code&gt; once more and we'll have recreated the reverse of the original string.&lt;/p&gt;&lt;p&gt;If you somehow made it all the way here (let me know at [email protected]), and you can't get enough of the BWT, there's a lot more you can learn about:&lt;/p&gt;&lt;code&gt;n&lt;/code&gt; has &lt;code&gt;n&lt;/code&gt; rotations, so sorting that list of strings has a time
			complexity of O(n) rotations * O(n log n) comparisons = O(n2 log n). There's an interesting data structure
			called a Suffix Array that you can use to more efficiently generate that matrix. You can learn more about that from Ben
			Langmead's lecture notes about suffix arrays and BWT and the FM index.
			Ben's lab maintains the bowtie2 sequence aligner,
			so his slides are a great in-depth resource.&lt;p&gt;â¨ Thanks to Ben Langmead, Niema Moshiri, Maria Nattestad, and Zamin Iqbal for their insightful feedback on this article.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sandbox.bio/concepts/bwt"/><published>2025-10-09T20:00:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45532680</id><title>Finding a VS Code Memory Leak</title><updated>2025-10-10T06:47:07.412195+00:00</updated><content>&lt;doc fingerprint="3e3ad905fa326550"&gt;
  &lt;main&gt;
    &lt;p&gt;In 2021 I found a huge memory leak in VS code, totalling around 64 GB when I first saw it, but with no actual limit on how high it could go. I found this leak despite two obstacles that should have made the discovery impossible:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The memory leak didn’t show up in Task Manager – there was no process whose memory consumption was increasing.&lt;/item&gt;
      &lt;item&gt;I had never used VS Code. In fact, I have still never used it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So how did this work? How did I find an invisible memory leak in a tool that I have never used?&lt;/p&gt;
    &lt;p&gt;This was during lockdown and my whole team was working from home. In order to maintain connection between teammates and in order to continue transferring knowledge from senior developers to junior developers we were doing regular pair-programming sessions. I was watching a coworker use VS Code for… I don’t remember what… and I noticed something strange.&lt;/p&gt;
    &lt;p&gt;So many of my blog posts start this way. “This doesn’t look right”, or “huh – that’s weird”, or some variation on that theme. In this case I noticed that the process IDs on her system had seven digits.&lt;/p&gt;
    &lt;p&gt;That was it. And as soon as I saw that I knew that there was a process-handle leak on her system and I was pretty sure that I would find it. Honestly, the rest of this story is pretty boring because it was so easy.&lt;/p&gt;
    &lt;p&gt;You see, Windows process IDs are just numbers. For obscure technical reasons they are always multiples of four. When a process goes away its ID is eligible for reuse immediately. Even if there is a delay before the process ID (PID) is reused there is no reason for the highest PID to be much more than four times the maximum number of processes that were running at one time. If we assume a system with 2,000 processes running (according to pslist my system currently has 261) then PIDs should be four decimal digits. Five decimal digits would be peculiar. But seven decimal digits? That implies at least a quarter-million processes. The PIDs I was seeing on her system were mostly around four million, which implies a million processes. Nope. I do not believe that there were that many processes.&lt;/p&gt;
    &lt;p&gt;It turns out that “when a process goes away its ID is eligible for reuse” is not quite right. If somebody still has a handle to that process then its PID will be retained by the OS. Forever. So it was quite obvious what was happening. Somebody was getting a handle to processes and then wasn’t closing them. It was a handle leak.&lt;/p&gt;
    &lt;p&gt;The first time I dealt with a process handle leak it was a complicated investigation as I learned the necessary techniques. That time I only realized that it was a handle leak through pure luck. Since then I’ve shipped tools to find process-handle and thread handle leaks, and have documented the techniques to investigate handle leaks of all kinds. Therefore this time I just followed my own recipe and had a call stack for the leaking code within the hour (this image stolen from the github issue):&lt;/p&gt;
    &lt;p&gt;The bug was pretty straightforward. A call to OpenProcess was made, and there was no corresponding call to CloseProcess. And because of this a boundless amount of memory – roughly 64 KiB for each missing CloseProcess call – was leaked. A tiny mistake, with consequences that could easily consume all of the memory on a high-end machine.&lt;/p&gt;
    &lt;p&gt;This is the buggy code (yay open source!):&lt;/p&gt;
    &lt;code&gt;void GetProcessMemoryUsage(ProcessInfo process_info[1024], uint32_t* process_count) {
  DWORD pid = process_info[*process_count].pid;
  HANDLE hProcess;
  PROCESS_MEMORY_COUNTERS pmc;
  hProcess = OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ, false, pid);
  if (hProcess == NULL) {
    return;
  }
  if (GetProcessMemoryInfo(hProcess, &amp;amp;pmc, sizeof(pmc))) {
    process_info[*process_count].memory = (DWORD)pmc.WorkingSetSize;
  }
}&lt;/code&gt;
    &lt;p&gt;And this is the code with the fix – the bold-faced line was added to fix the leak:&lt;/p&gt;
    &lt;code&gt;void GetProcessMemoryUsage(ProcessInfo&amp;amp; process_info) {
  DWORD pid = process_info.pid;
  HANDLE hProcess;
  PROCESS_MEMORY_COUNTERS pmc;
  hProcess = OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ, false, pid);
  if (hProcess == NULL) {
    return;
  }
  if (GetProcessMemoryInfo(hProcess, &amp;amp;pmc, sizeof(pmc))) {
    process_info.memory = (DWORD)pmc.WorkingSetSize;
  }
  CloseHandle(hProcess);
}&lt;/code&gt;
    &lt;p&gt;That’s it. One missing line of code is all that it takes.&lt;/p&gt;
    &lt;p&gt;The bug was found back when I still used Twitter so I reported my findings there (broken link) and somebody else then filed a github issue based on my report. I stopped using twitter a couple of years later and then my account got banned (due to not being used?) and then deleted, so now that bug report along with everything else I ever posted is gone. That’s pretty sad actually. Yet another reason for me to dislike the owner of Twitter.&lt;/p&gt;
    &lt;p&gt;It looks like the bug was fixed within a day or two of the report. Maybe The Great Software Quality Collapse hadn’t quite started then. Or maybe I got lucky.&lt;/p&gt;
    &lt;p&gt;Anyway, if you don’t want me posting embarrassing stories about your software on my blog or on bsky then be sure to leave the Handles column open in Task Manager and pay attention if you ever see it getting too high in a process that you are responsible for.&lt;/p&gt;
    &lt;p&gt;Sometimes I think it would be nice to have limits on resources in order to more automatically find mistakes like this. If processes were automatically crashed (with crash dumps) whenever memory or handles exceeded some limit then bugs like this would be found during testing. The limits could be set higher for software that needs it, but 10,000 handles and 4 GiB RAM would be more than enough for most software when operating correctly. The tradeoff would be more crashes in the short term but fewer leaks in the long term. I doubt it will ever happen, but if this mode existed as a per-machine opt-in then I would enable it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://randomascii.wordpress.com/2025/10/09/finding-a-vs-code-memory-leak/"/><published>2025-10-09T20:27:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45532685</id><title>A built-in 'off switch' to stop persistent pain</title><updated>2025-10-10T06:47:07.319506+00:00</updated><content>&lt;doc fingerprint="6760b750996e019a"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Key Takeaways&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Nearly 50 million people in the U.S. live with chronic pain, an invisible and often stubborn condition that can last for decades.&lt;/item&gt;
      &lt;item&gt;Now, collaborative research led by neuroscientist J. Nicholas Betley finds that a critical hub in the brainstem, has a built-in “off switch” to stop persistent pain signals from reaching the rest of the brain.&lt;/item&gt;
      &lt;item&gt;Their findings could help clinicians better understand chronic pain. “If we can measure and eventually target these neurons, that opens up a whole new path for treatment,” says Betley.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Acute or short-lived pain, despite its bad reputation, is usually a lifesaver. It acts as a transient negative sensory experience that helps us avoid danger. Touch a hot stove, stub a toe, or bonk your head on a low branch, and the nervous system cues up an “Ow!” Over time, the sting fades, the wound heals, but the lesson sticks.&lt;/p&gt;
    &lt;p&gt;Chronic pain is different; the alarm keeps blaring long after the fire is out, and then the pain itself becomes the problem. Nearly 50 million people in the United States live with chronic pain, an invisible and often untreatable condition that can linger for decades. “It’s not just an injury that won’t heal,” says neuroscientist at the University of Pennsylvania J. Nicholas Betley, “it’s a brain input that’s become sensitized and hyperactive, and determining how to quiet that input could lead to better treatments.”&lt;/p&gt;
    &lt;p&gt;Now, research led by Betley and collaborators at the University of Pittsburgh and Scripps Research Institute has identified a key to regulating long-term pain states: a group of cells called Y1 receptor (Y1R)-expressing neurons in the brainstem’s lateral parabrachial nucleus (lPBN). These neurons are activated during enduring pain states, but they also integrate information about hunger, fear and thirst, allowing for pain signals to be modulated by other brain circuits signaling more urgent needs.&lt;/p&gt;
    &lt;p&gt;Their findings, published in Nature, suggest that there is hope because “there are circuits in the brain that can reduce the activity of neurons that transmit the signal of pain.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Tracking pain in the brain&lt;/head&gt;
    &lt;p&gt;As part of a collaboration with the Taylor lab at Pitt, the researchers used calcium imaging to watch neurons fire in real time in preclinical models of acute and chronic pain. They found that Y1R neurons didn’t just flare briefly in response to acute pain—they also kept firing steadily during enduring pain, a state neuroscientists call “tonic activity.”&lt;/p&gt;
    &lt;p&gt;Betley likens this to an engine left idling, where signals of pain continued to rumble and tick even when outward signs of pain had faded. This persistent activity may encode the lasting pain state people feel long after an accident or surgery.&lt;/p&gt;
    &lt;p&gt;The drive to look deeper into these neurons grew out of a simple observation Betley and his team made shortly after he joined Penn in 2015—hunger could dampen long-term pain responses.&lt;/p&gt;
    &lt;p&gt;“From my own experience, I felt that when you’re really hungry you’ll do almost anything to get food,” he says. “When it came to chronic, lingering pain, hunger seemed to be more powerful than Advil at reducing pain.”&lt;/p&gt;
    &lt;p&gt;The current work started when Nitsan Goldstein, who was a graduate student in Betley’s lab at the time, found that other urgent survival needs such as thirst and fear can also reduce enduring pain. That finding supported behavioral models developed in collaboration with the Kennedy lab at Scripps, suggest filtering of sensory input at the parabrachial nucleus can block out long-lasting pain when other more acute needs exist.&lt;/p&gt;
    &lt;p&gt;“That told us the brain must have a built-in way of prioritizing urgent survival needs over pain, and we wanted to find the neurons responsible for that switch,” says Goldstein.&lt;/p&gt;
    &lt;p&gt;A key part of that switch is neuropeptide Y (NPY), a signaling molecule that helps the brain juggle competing needs. When hunger or fear takes priority, NPY acts on Y1 receptors in the parabrachial nucleus to dampen ongoing pain signals.&lt;/p&gt;
    &lt;p&gt;“It’s like the brain has this built-in override switch,” Goldstein explains. “If you’re starving or facing a predator, you can’t afford to be overwhelmed by lingering pain. Neurons activated by these other threats release NPY, and NPY quiets the pain signal so that other survival needs take precedence.”&lt;/p&gt;
    &lt;head rend="h2"&gt;A scattered signal&lt;/head&gt;
    &lt;p&gt;The researchers also characterized the molecular and anatomical identity of the Y1R neurons in the lPBN. They found that Y1Rneurons didn’t form two tidy anatomical or molecular populations. Instead, these neurons were scattered across many other cell types.&lt;/p&gt;
    &lt;p&gt;“It’s like looking at cars in a parking lot,” Betley says. “We expected all the Y1R neurons to be a cluster of yellow cars parked together, but here the Y1R neurons are like yellow paint distributed across red cars, blue cars, and green cars. We don’t know exactly why, but we think this mosaic distribution may allow the brain to dampen different kinds of painful inputs across multiple circuits.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Explorations of pain treatment&lt;/head&gt;
    &lt;p&gt;What excites Betley with this discovery is the further exploration of its potential to “use Y1 neural activity as a biomarker for chronic pain, something drug developers and clinicians have long lacked,” he says.&lt;/p&gt;
    &lt;p&gt;“Right now, patients may go to an orthopedist or a neurologist, and there is no clear injury. But they’re still in pain,” he says. “What we’re showing is that the problem may not be in the nerves at the site of injury, but in the brain circuit itself. If we can target these neurons, that opens up a whole new path for treatment.”&lt;/p&gt;
    &lt;p&gt;This research also suggests that behavioral interventions such as exercise, meditation, and cognitive behavioral therapy may influence how these brain circuits fire, just as hunger and fear did in the lab.&lt;/p&gt;
    &lt;p&gt;“We’ve shown that this circuit is flexible, it can be dialed up or down,” he says. “So, the future isn’t just about designing a pill. It’s also about asking how behavior, training, and lifestyle can change the way these neurons encode pain.”&lt;/p&gt;
    &lt;p&gt;J Nicholas Betley is an associate professor in the Department of Biology at the University of Pennsylvania’s School of Arts &amp;amp; Sciences.&lt;/p&gt;
    &lt;p&gt;Nitsan Goldstein was a graduate student in the Betley Lab at Penn Arts &amp;amp; Sciences during this study. She is currently a postdoctoral researcher at the Massachusetts Institute of Technology.&lt;/p&gt;
    &lt;p&gt;Other authors include Michelle Awh, Lavinia Boccia, Jamie R. E. Carty, Ella Cho, Morgan Kindel, Kayla A. Kruger, Emily Lo, Erin L. Marble, Nicholas K. Smith, Rachael E. Villari, and Albert T. M. Yeung of Penn Arts &amp;amp; Sciences; Niklas Blank and Christoph A. Thaiss of Penn’s Perelman School of Medicine; Melissa J. Chee and Yasmina Dumiaty of Carleton University; Rajesh Khanna of University of Florida College of Medicine,; Ann Kennedy and Amadeus Maes of Scripps Research Institute; and Heather N. Allen, Tyler S. Nelson and Bradley K. Taylor of the University of Pittsburg.&lt;/p&gt;
    &lt;p&gt;This research was supported by the Klingenstein Foundation, the University of Pennsylvania School of Arts and Sciences, the National Institutes of Health (grants F31DK131870, 1P01DK119130, 1R01DK133399, 1R01DK124801, 1R01NS134976, F32NS128392, K00NS124190, F32DK135401, T32DK731442, R61NS126026, R01NS120663, R01NS134976-02, R00MH117264, 1DP1DK140021-01), the National Science Foundation Graduate Research Fellowship Program, the Blavatnik Family Foundation Fellowship, the American Neuromuscular Foundation Development Grant, the American Heart Association (25POST1362884), the Swiss National Science Foundation (206668), the Canadian Institutes of Health Research Project Grant (PJT-175156), the Simons Foundation, a McKnight Foundation Scholar Award, and a Pew Biomedical Scholar Award.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://penntoday.upenn.edu/news/select-neurons-brainstem-may-hold-key-treating-chronic-pain"/><published>2025-10-09T20:27:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45533870</id><title>Show HN: Open source, logical multi-master PostgreSQL replication</title><updated>2025-10-10T06:47:06.724419+00:00</updated><content>&lt;doc fingerprint="fbd2b05d7c814752"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Building the Spock Extension&lt;/item&gt;
      &lt;item&gt;Building the Spock Documentation&lt;/item&gt;
      &lt;item&gt;Basic Configuration and Usage&lt;/item&gt;
      &lt;item&gt;Upgrading a Spock Installation&lt;/item&gt;
      &lt;item&gt;Advanced Configuration Options&lt;/item&gt;
      &lt;item&gt;Spock Management Features&lt;/item&gt;
      &lt;item&gt;Modifying a Cluster&lt;/item&gt;
      &lt;item&gt;Monitoring your Cluster&lt;/item&gt;
      &lt;item&gt;Spock Functions&lt;/item&gt;
      &lt;item&gt;Using spockctrl Management Functions&lt;/item&gt;
      &lt;item&gt;Release Notes&lt;/item&gt;
      &lt;item&gt;Limitations&lt;/item&gt;
      &lt;item&gt;FAQ&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Spock extension provides multi-master replication for PostgreSQL versions 15 and later. Take the following requirements into consideration as you design your cluster:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;You will need to install the&lt;/p&gt;&lt;code&gt;Spock&lt;/code&gt;extension on each node in your cluster. If you're performing a major version upgrade, the old node can be running a recent version of pgLogical2 before upgrading it to become a Spock node.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;On each node in your cluster, tables must have the same name and reside in the same schema. To check the table name and schema name of an existing table, you can connect to the database with psql and use the&lt;/p&gt;&lt;code&gt;\d&lt;/code&gt;meta-command:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;SELECT schemaname, tablename FROM pg_tables ORDER BY schemaname, tablename;&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;For example:&lt;/p&gt;
    &lt;code&gt;lcdb=# \d
               List of relations
 Schema |      Name      |   Type   |  Owner
--------+----------------+----------+----------
 public | table_a        | table    | ec2-user
 public | table_a_id_seq | sequence | ec2-user
 public | table_b        | table    | ec2-user
 public | table_b_id_seq | sequence | ec2-user
 public | table_c        | table    | ec2-user
 public | table_c_id_seq | sequence | ec2-user
(6 rows)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Each table must also have the same columns and primary keys, with the same data types in each column. To review detailed information for all tables within a specific schema, connect to the database with psql and use the &lt;code&gt;\d schema_name.*&lt;/code&gt;command; for example:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;lcdb=# \d public.*
                                   Table "public.table_a"
   Column   |           Type           | Collation | Nullable |           Default
------------+--------------------------+-----------+----------+------------------------------
 id         | bigint                   |           | not null | generated always as identity
 name       | text                     |           | not null |
 qty        | integer                  |           | not null |
 created_at | timestamp with time zone |           | not null | now()
Indexes:
    "table_a_pkey" PRIMARY KEY, btree (id)

                       Sequence "public.table_a_id_seq"
  Type  | Start | Minimum |       Maximum       | Increment | Cycles? | Cache
--------+-------+---------+---------------------+-----------+---------+-------
 bigint |     1 |       1 | 9223372036854775807 |         1 | no      |     1
Sequence for identity column: public.table_a.id

     Index "public.table_a_pkey"
 Column |  Type  | Key? | Definition
--------+--------+------+------------
 id     | bigint | yes  | id
primary key, btree, for table "public.table_a"
...&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;CHECK&lt;/code&gt;constraints and&lt;code&gt;NOT NULL&lt;/code&gt;constraints must be the same or more permissive on any standby node that acts only as a subscriber.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For more information about the Spock extension's advanced functionality, visit here.&lt;/p&gt;
    &lt;p&gt;You will need to build the Spock extension on a patched PostgreSQL source tree to which you have applied version-specific &lt;code&gt;.diff&lt;/code&gt; files from the &lt;code&gt;spock/patches/Postgres-version&lt;/code&gt; directory. The high-level steps to build Postgres and the spock extension are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Get the Postgres source.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Copy the patch files to the base repository; the patches for each Postgres version are in a version-specific subdirectory of the spock repo. Then, apply each patch, use the command:&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;patch -p1 &amp;lt; path_to_patch/patch_name&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Note that you must apply the patches in the numerical order designated by their prefixes in the &lt;code&gt;spock&lt;/code&gt; repository (for example, &lt;code&gt;pg16-015-patch-name&lt;/code&gt;, then &lt;code&gt;pg16-020-patch-name&lt;/code&gt;, then &lt;code&gt;pg16-025-patch-name&lt;/code&gt;).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;configure&lt;/code&gt;,&lt;code&gt;make&lt;/code&gt;, and&lt;code&gt;make install&lt;/code&gt;the Postgres server as described in the PostgreSQL documentation.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When the build completes, add the location of your&lt;/p&gt;&lt;code&gt;pg_config&lt;/code&gt;file to your&lt;code&gt;PATH&lt;/code&gt;variable:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;
      &lt;code&gt;export PATH=path_to_pg_config_file&lt;/code&gt;
    &lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Then, clone the&lt;/p&gt;&lt;code&gt;pgedge/spock&lt;/code&gt;repository:&lt;code&gt;git clone https://github.com/pgEdge/spock.git&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Next,&lt;/p&gt;&lt;code&gt;make&lt;/code&gt;and then&lt;code&gt;make-install&lt;/code&gt;spock.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Then, update your Postgres&lt;/p&gt;&lt;code&gt;postgresql.conf&lt;/code&gt;file, setting:&lt;quote&gt;shared_preload_libraries = 'spock' track_commit_timestamp = on # needed for conflict resolution&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Then, connect to the server and use the&lt;/p&gt;&lt;code&gt;CREATE EXTENSION&lt;/code&gt;command to create the spock extension on each node in the database you wish to replicate:&lt;code&gt;CREATE EXTENSION spock;&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Spock documentation uses MkDocs with the Material theme to generate styled static HTML documentation from Markdown files in the &lt;code&gt;docs&lt;/code&gt; directory.&lt;/p&gt;
    &lt;p&gt;To build the documentation, and run a development server for live previewing:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Create a Python virtual environment:&lt;/p&gt;
        &lt;quote&gt;python3 -m venv spock-docs-venv&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Activate the virtual environment:&lt;/p&gt;
        &lt;code&gt;source spock-docs-venv/bin/activate&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Install MkDocs:&lt;/p&gt;
        &lt;quote&gt;pip install mkdocs mkdocs-material&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run the local MkDocs server for testing:&lt;/p&gt;
        &lt;quote&gt;mkdocs serve INFO - Building documentation... INFO - Multirepo plugin importing docs... INFO - Cleaning site directory INFO - Multirepo plugin is cleaning up temp_dir/ INFO - Documentation built in 0.18 seconds INFO - [14:32:14] Watching paths for changes: 'docs', 'mkdocs.yml' INFO - [14:32:14] Serving on http://127.0.0.1:8000/&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Before configuring a replication cluster, you will need to perform the following steps on each node of the cluster:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;build Postgres and Spock, and create the Spock extension.&lt;/item&gt;
      &lt;item&gt;initialize identical databases.&lt;/item&gt;
      &lt;item&gt;modify the &lt;code&gt;postgresql.conf&lt;/code&gt;file to support logical decoding automatic DDL replication.&lt;/item&gt;
      &lt;item&gt;modify the &lt;code&gt;pg_hba.conf&lt;/code&gt;file and any firewalls to ensure you have connectivity between nodes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configuration Settings&lt;/p&gt;
    &lt;p&gt;Modify the &lt;code&gt;postgresql.conf&lt;/code&gt; file, adding:&lt;/p&gt;
    &lt;code&gt;wal_level = 'logical'
max_worker_processes = 10   # one per database needed on provider node
                            # one per node needed on subscriber node
max_replication_slots = 10  # one per node needed on provider node
max_wal_senders = 10        # one per node needed on provider node
shared_preload_libraries = 'spock'
track_commit_timestamp = on # needed for conflict resolution
&lt;/code&gt;
    &lt;p&gt;You'll also want to enable automatic ddl replication on each node; add these GUCs to the &lt;code&gt;postgresql.conf&lt;/code&gt; file as well:&lt;/p&gt;
    &lt;code&gt;spock.enable_ddl_replication=on
spock.include_ddl_repset=on
&lt;/code&gt;
    &lt;p&gt;You also need to configure your &lt;code&gt;pg_hba.conf&lt;/code&gt; file to allow connections between your nodes and ensure that firewalls do not block access. Logical replication connections are treated by &lt;code&gt;pg_hba.conf&lt;/code&gt; as regular connections to the provider database.&lt;/p&gt;
    &lt;p&gt;After modifying the configuration files, restart the Postgres server; for example:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;pg_ctl -D /path/to/data_directory restart&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Configuring Replication&lt;/p&gt;
    &lt;p&gt;First, we'll invoke the &lt;code&gt;spock.node_create&lt;/code&gt; command on each node in the cluster.  For example, the following command creates a node named &lt;code&gt;n1&lt;/code&gt; that can be accessed via the connection string specified with the &lt;code&gt;dsn&lt;/code&gt; variable:&lt;/p&gt;
    &lt;code&gt;SELECT spock.node_create(
    node_name := 'n1',
    dsn := 'host=10.0.0.5 port=5432 dbname=acctg'
);
&lt;/code&gt;
    &lt;p&gt;Use the following command to create a node named n2:&lt;/p&gt;
    &lt;code&gt;SELECT spock.node_create(
    node_name := 'n2',
    dsn := 'host=10.0.0.7 port=5432 dbname=acctg'
);
&lt;/code&gt;
    &lt;p&gt;Next, create the subscriptions between the nodes. Since this is multi-master replication, each node acts as both a subscriber and provider. The first command creates a subscription between &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;SELECT spock.sub_create(
    subscription_name := 'sub_n1n2',
    provider_dsn := 'host=10.0.0.7 port=5432 dbname=acctg'
);
&lt;/code&gt;
    &lt;p&gt;The command invoked on &lt;code&gt;n1&lt;/code&gt; specifies the subscription name (&lt;code&gt;sub_n1n2&lt;/code&gt;) and the connection string for the node it is subscribing to (&lt;code&gt;n2&lt;/code&gt;).  Next, create a subscription on &lt;code&gt;n2&lt;/code&gt; that connects to &lt;code&gt;n1&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;SELECT spock.sub_create(
    subscription_name := 'sub_n2n1',
    provider_dsn := 'host=10.0.0.5 port=5432 dbname=acctg'
);
&lt;/code&gt;
    &lt;p&gt;To start replication, we'll add tables with pgbench; since we enabled automatic ddl replication, we'll add the tables on &lt;code&gt;n1&lt;/code&gt;, and they'll automatically propagate to &lt;code&gt;n2&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;/path to pgbench/pgbench -i -s 10 acctg
&lt;/code&gt;
    &lt;p&gt;Then, to confirm replication, you can connect to both &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt; with psql and check for pgbench tables.&lt;/p&gt;
    &lt;code&gt;psql (17.x)
Type "help" for help.

bench=# \dt
               List of relations
 Schema |       Name        | Type  |  Owner
--------+-------------------+-------+---------
 public | pgbench_accounts  | table | postgres
 public | pgbench_branches  | table | postgres
 public | pgbench_history   | table | postgres
 public | pgbench_tellers   | table | postgres
(4 rows)
&lt;/code&gt;
    &lt;p&gt;Deploying Spock Clusters in Containers and with Ansible&lt;/p&gt;
    &lt;p&gt;The pgEdge Github sites hosts repositories that contain artifacts that you can use to simplify spock cluster deployment; for more information, visit:&lt;/p&gt;
    &lt;p&gt;You cannot roll back an upgrade because of changes to the catalog tables; before starting an upgrade, make sure you have a current backup of your cluster so you can recreate the original cluster if needed.&lt;/p&gt;
    &lt;p&gt;Then, to upgrade the version of spock that you use to manage your replication cluster, you can remove, build, and upgrade the spock extension like you would any other PostgreSQL extension.&lt;/p&gt;
    &lt;p&gt;To review the spock license, visit here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/pgEdge/spock"/><published>2025-10-09T22:53:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45533902</id><title>How to write in Cuneiform</title><updated>2025-10-10T06:47:06.198190+00:00</updated><content>&lt;doc fingerprint="a7293fbd0a06c391"&gt;
  &lt;main&gt;
    &lt;p&gt;Teaching child visitors how to write their names using an unfamiliar or antique alphabet is a favorite activity of museum educators, but Dr. Irving Finkel, a cuneiform expert who specializes in ancient Mesopotamian medicine and magic, has grander designs.&lt;/p&gt;
    &lt;p&gt;His employer, the British Museum, has over 130,000 tablets spanning Mesopotamia’s Early Dynastic period to the Neo-Babylonian Empire “just waiting for young scholars to come devote themselves to (the) monkish work” of deciphering them.&lt;/p&gt;
    &lt;p&gt;Writing one’s name might well prove to be a gateway, and Dr. Finkel has a vested interest in lining up some new recruits.&lt;/p&gt;
    &lt;p&gt;The museum’s Department of the Middle East has an open access policy, with a study room where researchers can get up close and personal with a vast collection of cuneiform tablets from Mesopotamia and surrounding regions.&lt;/p&gt;
    &lt;p&gt;But let’s not put the ox before the cart.&lt;/p&gt;
    &lt;p&gt;As the extremely personable Dr. Finkel shows Matt Gray and Tom Scott of Matt and Tom’s Park Bench, above, cuneiform consists of three components—upright, horizontal and diagonal—made by pressing the edge of a reed stylus, or popsicle stick if you prefer, into a clay tablet.&lt;/p&gt;
    &lt;p&gt;The mechanical process seems fairly easy to get the hang of, but mastering the oldest writing system in the world will take you around six years of dedicated study. Like Japan’s kanji alphabet, the oldest writing system in the world is syllabic. Properly written out, these syllables join up into a flowing calligraphy that your average, educated Babylonian would be able to read at a glance.&lt;/p&gt;
    &lt;p&gt;Even if you have no plans to rustle up a popsicle stick and some Play-Doh, it’s worth sticking with the video to the end to hear Dr. Finkel tell how a chance encounter with some naturally occurring cuneiform inspired him to write a horror novel, which is now available for purchase, following a successful Kickstarter campaign.&lt;/p&gt;
    &lt;p&gt;Begin your cuneiform studies with Irving Finkel’s Cuneiform: Ancient Scripts.&lt;/p&gt;
    &lt;p&gt;Note: An earlier version of this post appeared on our site in 2018.&lt;/p&gt;
    &lt;p&gt;Related Content:&lt;/p&gt;
    &lt;p&gt;Hear The Epic of Gilgamesh Read in its Original Ancient Language, Akkadian&lt;/p&gt;
    &lt;p&gt;Learn Ancient Greek in 64 Free Lessons: A Free Online Course from Brandeis &amp;amp; Harvard&lt;/p&gt;
    &lt;p&gt;Ayun Halliday is an author, illustrator, theater maker and Chief Primatologist in NYC.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.openculture.com/2025/09/how-to-write-in-cuneiform-the-oldest-writing-system.html"/><published>2025-10-09T22:58:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45534922</id><title>Open-Source Agentic AI</title><updated>2025-10-10T06:47:05.653146+00:00</updated><content>&lt;doc fingerprint="7d37be583f97863f"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Open-source alternative to Claude Agent SDK, ChatGPT Agents, and Manus.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Agentic AI systems, such as Claude Agent SDK (Claude Code) or ChatGPT Agents, can perform meaningful real-world tasks by operating computers, browsers, and phones just like humans. Open source would enhance their capabilities.&lt;/p&gt;
    &lt;p&gt;Open-Agent.io is an open Agentic AI you can use or modify. Chat with cutting-edge models while our multi-agent system completes your tasks.&lt;/p&gt;
    &lt;p&gt;Play with it, deploy it, enhance it, or use it as the foundation for your next dedicated agent. We welcome all contributions.&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;openagent_intro_10mb.mp4&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;💡 Idea&lt;/p&gt;&lt;lb/&gt;Have your own highly customizable Agentic AI that integrates OpenAI, Claude, Gemini, and open-source models to work together seamlessly!&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;💬 Stop prompt-chasing. Start decision-making&lt;/p&gt;&lt;lb/&gt;Spec &amp;amp; context engineering give agents structure to plan, score, and surface options. You stay in control of the final call. Achieve more, struggle less.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;🔔 Multi-agent collaboration&lt;/p&gt;&lt;lb/&gt;Instead of chatting with a single AI, all the frontier models collaborate together to finish your task with our multi-agent framework.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;🏠 Self-hostable&lt;/p&gt;&lt;lb/&gt;Open source and free to modify.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;copy &lt;code&gt;.docker/config.example.json&lt;/code&gt;and&lt;code&gt;.docker/docker-compose.yml&lt;/code&gt;to a separate folder.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;mkdir deploy
cd deploy
cp ../.docker/config.example.json ./config.json
cp ../.docker/docker-compose.yml ./docker-compose.yml&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Edit&lt;/p&gt;&lt;code&gt;config.json&lt;/code&gt;and add your API keys.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run with Docker Compose.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;docker compose up -d&lt;/code&gt;
    &lt;p&gt;We welcome all contributions, ideas, and improvements!&lt;lb/&gt; Open issues or pull requests — no bureaucracy, just collaboration.&lt;/p&gt;
    &lt;p&gt;Starting points: How To Development&lt;/p&gt;
    &lt;p&gt;Before submitting a PR, run code checks:&lt;/p&gt;
    &lt;code&gt;pre-commit run --all-files&lt;/code&gt;
    &lt;p&gt;Join our community to connect with other developers, share feedback, and showcase your projects.&lt;/p&gt;
    &lt;p&gt;Open-Agent builds upon the ideas of projects like&lt;lb/&gt; AFFiNE,&lt;lb/&gt; and the broader open-source agentic AI community.&lt;/p&gt;
    &lt;p&gt;Special thanks to everyone advancing human–AI collaboration.&lt;/p&gt;
    &lt;p&gt;© 2025 Open-Agent Contributors.&lt;lb/&gt; Licensed under Apache 2.0.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/AFK-surf/open-agent"/><published>2025-10-10T02:30:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45535014</id><title>Vexing Exceptions</title><updated>2025-10-10T06:47:05.529408+00:00</updated><content>&lt;doc fingerprint="efca4812d1b014fb"&gt;
  &lt;main&gt;
    &lt;p&gt;Writing good error handling code is hard in any language, whether you have exception handling or not. When I’m thinking about what exception handling I need to implement in a given program, I first classify every exception I might catch into one of four buckets which I label fatal, boneheaded, vexing and exogenous.&lt;/p&gt;
    &lt;p&gt;Fatal exceptions are not your fault, you cannot prevent them, and you cannot sensibly clean up from them. They almost always happen because the process is deeply diseased and is about to be put out of its misery. Out of memory, thread aborted, and so on. There is absolutely no point in catching these because nothing your puny user code can do will fix the problem. Just let your &lt;code&gt;finally&lt;/code&gt; blocks run and hope for the best. (Or, if you’re really worried, fail fast and do not let the &lt;code&gt;finally &lt;/code&gt;blocks run; at this point, they might just make things worse. But that’s a topic for another day.)&lt;/p&gt;
    &lt;p&gt;Boneheaded exceptions are your own darn fault, you could have prevented them and therefore they are bugs in your code. You should not catch them; doing so is hiding a bug in your code. Rather, you should write your code so that the exception cannot possibly happen in the first place, and therefore does not need to be caught. That argument is null, that typecast is bad, that index is out of range, you’re trying to divide by zero – these are all problems that you could have prevented very easily in the first place, so prevent the mess in the first place rather than trying to clean it up.&lt;/p&gt;
    &lt;p&gt;Vexing exceptions are the result of unfortunate design decisions. Vexing exceptions are thrown in a completely non-exceptional circumstance, and therefore must be caught and handled all the time.&lt;/p&gt;
    &lt;p&gt;The classic example of a vexing exception is &lt;code&gt;Int32.Parse&lt;/code&gt;, which throws if you give it a string that cannot be parsed as an integer. But the 99% use case for this method is transforming strings input by the user, which could be any old thing, and therefore it is in no way exceptional for the parse to fail. Worse, there is no way for the caller to determine ahead of time whether their argument is bad without implementing the entire method themselves, in which case they wouldn’t need to be calling it in the first place.&lt;/p&gt;
    &lt;p&gt;This unfortunate design decision was so vexing that of course the frameworks team implemented &lt;code&gt;TryParse &lt;/code&gt;shortly thereafter which does the right thing.&lt;/p&gt;
    &lt;p&gt;You have to catch vexing exceptions, but doing so is vexing.&lt;/p&gt;
    &lt;p&gt;Try to never write a library yourself that throws a vexing exception.&lt;/p&gt;
    &lt;p&gt;And finally, exogenous exceptions appear to be somewhat like vexing exceptions except that they are not the result of unfortunate design choices. Rather, they are the result of untidy external realities impinging upon your beautiful, crisp program logic. Consider this pseudo-C# code, for example:&lt;/p&gt;
    &lt;quote&gt;try { using ( File f = OpenFile(filename, ForReading) ) { // Blah blah blah } } catch (FileNotFoundException) { // Handle file not found }&lt;/quote&gt;
    &lt;p&gt;Can you eliminate the &lt;code&gt;try-catch&lt;/code&gt;?&lt;/p&gt;
    &lt;quote&gt;if (!FileExists(filename)) { // Handle filename not found } else { using ( File f = ...&lt;/quote&gt;
    &lt;p&gt;This isn’t the same program. There is now a “race condition”. Some other process could have deleted, locked, moved or changed the permissions of the file between the &lt;code&gt;FileExists &lt;/code&gt;and the &lt;code&gt;OpenFile&lt;/code&gt;. Defect taxonomists call this situation a TOCTOU: Time Of Check is not Time Of Use.&lt;/p&gt;
    &lt;p&gt;Can we be more sophisticated? What if we lock the file? That doesn’t help. The media might have been removed from the drive, the network might have gone down…&lt;/p&gt;
    &lt;p&gt;You’ve got to catch an exogenous exception because it always could happen no matter how hard you try to avoid it; it’s an exogenous condition outside of your control.&lt;/p&gt;
    &lt;p&gt;So, to sum up:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Don’t catch fatal exceptions; nothing you can do about them anyway, and trying to generally makes it worse.&lt;/item&gt;
      &lt;item&gt;Fix your code so that it never triggers a boneheaded exception – an “index out of range” exception should never happen in production code.&lt;/item&gt;
      &lt;item&gt;Avoid vexing exceptions whenever possible by calling the “Try” versions of those vexing methods that throw in non-exceptional circumstances. If you cannot avoid calling a vexing method, catch its vexing exceptions.&lt;/item&gt;
      &lt;item&gt;Always handle exceptions that indicate unexpected exogenous conditions; generally it is not worthwhile or practical to anticipate every possible failure. Just try the operation and be prepared to handle the exception.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ericlippert.com/2008/09/10/vexing-exceptions/"/><published>2025-10-10T02:54:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45535082</id><title>Managing Encrypted Filesystems with dirlock</title><updated>2025-10-10T06:47:04.953030+00:00</updated><content>&lt;doc fingerprint="3d995851f86393d1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Managing encrypted filesystems with dirlock&lt;/head&gt;
    &lt;quote&gt;Ready to give LWN a try?&lt;p&gt;With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features. We are pleased to offer you a free trial subscription, no credit card required, so that you can see for yourself. Please, join us!&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;As with a mobile phone, a portable gaming device like the Steam Deck can contain lots of personal information that the owner would like to keep secret—especially given that such devices can do far more than gaming. Alberto Garcia worked with his colleagues at Igalia and people at Valve, the company behind the Steam gaming platform, to come up with a new tool to manage encrypted filesystems for SteamOS, which is a Linux distribution optimized for gaming. Garcia gave a talk about that tool, dirlock, at Open Source Summit Europe, which was held in Amsterdam in late August. In the talk, he looked at the design process for the encrypted-files feature, the alternatives considered, and why they made the choices they did.&lt;/p&gt;
    &lt;p&gt; Over a long career at Igalia, he has worked on many different projects, including GNOME, the Maemo and MeeGo mobile-Linux platforms, and more recently on QEMU. He is also a Debian developer; "&lt;quote&gt;I've been using Debian basically all of my life, but I'm also contributing to the project and I've been an active developer for many years&lt;/quote&gt;". At the moment, he is working on SteamOS. &lt;/p&gt;
    &lt;p&gt;He was quick to point out that dirlock is not a new encryption system as it is only meant to manage filesystems that are encrypted using existing tools. Steam Decks and similar devices are easy to misplace—or steal. Since the hard drive is not encrypted, whoever ends up with the device can read its contents. That may not sound all that problematic for a gaming handheld, but the devices are much more than that; they may have credentials for things other than just Steam accounts, for one thing. In addition, the devices have a desktop mode where various programs can be installed, including web browsers that may store even more personal information. Users have been requesting disk encryption for a long time, Garcia said.&lt;/p&gt;
    &lt;p&gt;From his slides, he showed the disk layout of the device. It is based around an A/B arrangement for the operating system partitions, which consists of two sets of read-only root partitions, boot partitions, and /var partitions. None of those are particularly sensitive; most of the data on those is downloaded to the device from the internet. The bulk of the disk is taken up with the /home partition, which is where all of the user's data is stored. That includes the games, but also configuration and other data that the user may want to keep private.&lt;/p&gt;
    &lt;p&gt;Currently, users do have an encryption option, but it is somewhat limited. SteamOS ships with the KDE Plasma desktop, so the Plasma Vault tool can be used to create encrypted directories. It is not a general-purpose solution, however, for encrypting everything in the user's home directory.&lt;/p&gt;
    &lt;head rend="h4"&gt;Goals&lt;/head&gt;
    &lt;p&gt; The goals of the project were focused on the needs of SteamOS, but "&lt;quote&gt;the idea is to make them general enough so they can be used in any Linux system or in other systems&lt;/quote&gt;". The most important goal is that if the device is lost or stolen, the personal files on it should be unreadable; there are other scenarios, such as the so-called evil maid attack, that are important to guard against, but the main goal is to protect the personal data, he said. For that, the user's home directory should be encrypted, but it would be nice to be able to encrypt other directories too. The devices have removable media that can be used to store games and other data, so encrypting those would be useful, for example. &lt;/p&gt;
    &lt;p&gt;While SteamOS is currently single-user, support for multiple users with independent encryption keys is another goal for the tool. Access to the encrypted files must be authenticated somehow, with a PIN, password, or something else. But, since handheld gaming devices do not have a physical keyboard, the expectation is that users will have short, weak passwords or PINs. Having support for a hardware-backed mechanism of some sort may help mitigate that weakness.&lt;/p&gt;
    &lt;p&gt; These devices are already out there in the hands of users, so "&lt;quote&gt;it would be nice to have a way to enable encryption without having to reinstall the whole operating system from scratch&lt;/quote&gt;". From a security point of view, doing it that way is not ideal, but the goal is to avoid requiring users to wipe their devices; the hope is to have a simple "encrypt data" button or command. Beyond that, the tool needs a D-Bus API. The underlying encryption should also have reasonable performance, "&lt;quote&gt;so the user can use the machine normally without noticing any regression in the performance&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt;There are three available encryption technologies that were considered. The first, stacked filesystem encryption, stores the data as regular files in the filesystem with encrypted contents and names. It is implemented in user space, which hurts performance; the Filesystem in Userspace (FUSE) mechanism is used to mount an encrypted filesystem that gives access to the data. Two examples of this type of encryption are gocryptfs and EncFS; the Plasma Vault tool uses the technique as well.&lt;/p&gt;
    &lt;p&gt; Another technology, block-device encryption, encrypts each individual block of block devices, such as disk partitions or loopback-mounted files; it does not care what the contents of the block device are, normally it is a filesystem, but it does not have to be. The technique "&lt;quote&gt;offers the best confidentiality because what's inside is completely hidden&lt;/quote&gt;"; attackers have no way to know how much data is stored there, just that it is less than the size of the device. In Linux, the most popular implementation is LUKS, which stores the encryption keys in a header on the block device. &lt;/p&gt;
    &lt;p&gt;The third option is native filesystem encryption, where files are encrypted by the kernel at the filesystem level. That allows filesystems to contain a mix of encrypted and unencrypted directories. The file names and contents are encrypted, but the metadata (e.g. sizes, permissions) of files is not protected. The kernel provides the fscrypt API to access the feature, but it must be implemented by individual filesystems; at the moment, ext4 and f2fs have support, and he believes it is in progress for Btrfs. All of the encryption keys for fscrypt must be managed by user space.&lt;/p&gt;
    &lt;head rend="h4"&gt;LUKS versus fscrypt&lt;/head&gt;
    &lt;p&gt;For SteamOS, the decision came down to either LUKS or fscrypt. LUKS has better confidentiality and works with hardware-backed mechanisms like the TPM and FIDO tokens, but it has some downsides as well. Normally, the LUKS partition needs to be unlocked early in the boot process, which may limit the input methods that can be used for authentication. There is no fine-grained control over what is encrypted and there is no way to encrypt an existing installation; it is meant to be used for a new filesystem on a block device.&lt;/p&gt;
    &lt;p&gt; "&lt;quote&gt;On the other hand, fscrypt makes it very easy to encrypt an existing installation, because you can start from an existing filesystem and start encrypting directories there.&lt;/quote&gt;" It also makes it easy to encrypt other directories, for separate user accounts, for example, with different keys. It integrates easily with PAM, which opens up lots of possibilities for authentication mechanisms, and fscrypt directories can be unlocked after booting, and even remotely via ssh. On the con side, the lack of protection for the file metadata allows attackers to know or guess some things about the files and directory structure; in addition, fscrypt does not stop attackers from deleting files. &lt;/p&gt;
    &lt;p&gt; The team chose fscrypt as the better option for SteamOS. It is "&lt;quote&gt;more practical&lt;/quote&gt;", with good confidentiality guarantees. It is flexible and "&lt;quote&gt;very easy to enable in existing system&lt;/quote&gt;". Fscrypt offers good performance as well; in his tests, it performed a little better than LUKS, Garcia said. &lt;/p&gt;
    &lt;p&gt; But fscrypt is just a kernel API, SteamOS will need to handle the encryption keys. Two existing tools, the fscrypt command-line tool and systemd-homed, which are incompatible with each other, were considered. fscrypt, which is related to but different than the kernel API, is "&lt;quote&gt;the reference tool to manage encrypted directories&lt;/quote&gt;"; it was developed in Go by the people working on the kernel API. It is simple to use and supports PAM, but it only allows passwords or raw binary keys and has no support for hardware-backed mechanisms. It also lacks a D-Bus API. &lt;/p&gt;
    &lt;p&gt;Systemd-homed is not really an encryption tool, or one for managing encrypted filesystems directly, it is for managing user accounts—and only for those tied to humans, not for system accounts. The goal is to separate the configuration of the accounts from the rest of system in order to make it easier to move the accounts to other systems, he said. It has multiple storage backends, two of which are encrypted; one uses a LUKS loopback-mounted file and the other uses the deprecated v1 fscrypt API. Systemd-homed supports D-Bus, PAM, and FIDO tokens, but there is no TPM support. It also only handles encrypting the home directory, while the SteamOS developers want to be able to encrypt more than just that, it has its own user database, separate from /etc/passwd, and it uses ID-mapped mounts, which can conflict with other tools, such as Podman. Overall, systemd-homed was a strong contender, Garcia said, but the team decided to go in a different direction.&lt;/p&gt;
    &lt;head rend="h4"&gt;dirlock&lt;/head&gt;
    &lt;p&gt; Dirlock just "&lt;quote&gt;does encryption, authentication, and nothing else; it doesn't touch anything else, it tries to be as least invasive as possible&lt;/quote&gt;". It is "&lt;quote&gt;heavily inspired&lt;/quote&gt;" by fscrypt and Garcia tried not to diverge from the choices made by the tool. Dirlock is still under development, but it is usable at this point. PAM and FIDO support are working, as is basic TPM support. Since users are expected to have low-entropy PINs, the anti-hammering feature of the TPM is used to protect against brute-force attacks. There is also a D-Bus API, but it is in the prototype stage and not yet ready for widespread use. &lt;/p&gt;
    &lt;p&gt;Dirlock is open-source software, available under the three-clause BSD license. It was written from scratch in Rust, with the needs of SteamOS in mind, but it should work on any Linux system. It will be available in the upcoming SteamOS 3.8 release as an experimental feature; some users are testing it on pre-release versions of SteamOS, so the developers are already getting feedback on it.&lt;/p&gt;
    &lt;p&gt;A directory encrypted with fscrypt has an "encryption policy" associated with it; the policy is the master encryption key and several configuration parameters, including the encryption algorithm used. The master key is loaded into the kernel to unlock the directory, so that the files can be seen and accessed normally, and is removed to lock the directory. It is up to user space, dirlock in this case, to manage the master key and to keep it safe.&lt;/p&gt;
    &lt;p&gt; The master key is not used directly by dirlock, he said, it is wrapped with intermediate keys called "protectors"; there are protectors using passwords, FIDO2 keys, and others. That scheme has the advantage that "&lt;quote&gt;if the protector is compromised, because the password is lost or something, it can be deleted without exposing the master key and without having to re-encrypt other data&lt;/quote&gt;". The design for key-handling in dirlock was taken from fscrypt, but the idea of using intermediate keys to protect the master key is much older and is also used in LUKS and BitLocker. &lt;/p&gt;
    &lt;p&gt;For dirlock, there may not just be a single master key because there may be more than one encrypted directory, so those keys can be protected in various ways. For example, two users can each have their encrypted home directory with protectors using their own password. In addition, a single FIDO2 protector can be used for both users' master keys, so it can decrypt either of the home directories. The users can change their passwords without affecting the ability of the FIDO2 protector to provide access to the directories.&lt;/p&gt;
    &lt;p&gt;Another scenario might be two users who share a third directory. Each user's password protector can unlock their personal home directory and the shared directory. Each user only needs to know their password for access. Either can change their password at will, without affecting the other user's access.&lt;/p&gt;
    &lt;p&gt;So far, several protectors have been implemented. The password protector uses the password and cryptographic salt as inputs to a key-derivation function, which generates an encryption key that can decrypt the protected (i.e. master) key. The FIDO2 protector gets the encryption key from the token, which uses a credential and salt internal to the token, possibly mixed with a PIN provided by the user, to generate it. For the TPM protector, the key is obtained from the TPM based on a PIN provided by the user. There are other authentication possibilities using the TPM and its platform-configuration registers (PCRs), but those have not been implemented for dirlock, at least yet.&lt;/p&gt;
    &lt;p&gt;There is a pam_dirlock.so module for PAM integration. Users do not need to be converted as the PAM module checks to see if the home directory is encrypted. If it is, then the authentication is handled by dirlock, otherwise, it returns PAM_USER_UNKNOWN so that the next PAM module can handle the authentication. He showed a sample PAM configuration that would implement that sort of behavior.&lt;/p&gt;
    &lt;p&gt;He did a demo of dirlock on a virtual machine (VM) running Debian. He set up two protectors, one for the software TPM in the VM and another for a real YubiKey FIDO2 token that was passed through to the VM. When the user logged in, they were prompted to press the YubiKey button, which would unlock the directory. Removing the YubiKey device from the VM caused it to fall back to the TPM-based key, which required a PIN to be entered. He showed logging in—and failing to log in—using those mechanisms and also noted that the TPM only allowed a certain number of attempts before disallowing further entry of PINs, which is part of its anti-hammering protection.&lt;/p&gt;
    &lt;p&gt;Something that struck me about the presentation was the total lack of fanfare surrounding the programming-language choice. It was not all that long ago when choosing Rust might have been given a rather higher profile in a talk of this nature, but it seems we are past that point now. Rust is just another attribute of a project—as it should be.&lt;/p&gt;
    &lt;p&gt;Those interested can view a YouTube video of the talk.&lt;/p&gt;
    &lt;p&gt; [I would like to thank the Linux Foundation, LWN's travel sponsor, for supporting my trip to Amsterdam for Open Source Summit Europe.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;Open Source Summit Europe/2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Sep 29, 2025 19:26 UTC (Mon) by cen (subscriber, #170575) [Link] Posted Sep 29, 2025 20:58 UTC (Mon) by mmechri (subscriber, #95694) [Link] (2 responses) Posted Sep 29, 2025 21:40 UTC (Mon) by Cyberax (✭ supporter ✭, #52523) [Link] Posted Oct 1, 2025 15:25 UTC (Wed) by GhePeU (subscriber, #56133) [Link] Also as far as I know, nobody's working on fscrypt support for Btrfs anymore, after years of back-and-forth with the fscrypt maintainer the last news of the project was an email by Josef Bacik saying that Meta didn't need the feature anymore so it had been de-prioritized but he'd try to fix up what had been done and submit it... but that was in April 2024 and he left Meta and stepped back from kernel development since. Posted Sep 30, 2025 0:14 UTC (Tue) by riking (subscriber, #95706) [Link] Posted Sep 30, 2025 3:08 UTC (Tue) by DemiMarie (subscriber, #164188) [Link] (1 responses) Posted Sep 30, 2025 21:23 UTC (Tue) by berto (subscriber, #58604) [Link] Posted Sep 30, 2025 12:08 UTC (Tue) by geert (subscriber, #98403) [Link] (6 responses) Posted Sep 30, 2025 21:13 UTC (Tue) by berto (subscriber, #58604) [Link] But I'm not sure how that would work in practice: the LUKS header alone takes several MBs, so apart from shrinking the filesystem you would have to either move all the data or put the superblock and the first few MBs at the end of the partition, and then use the device mapper to make those appear at the beginning. Posted Sep 30, 2025 21:30 UTC (Tue) by muase (subscriber, #178466) [Link] (3 responses) Something like that would definitely be possible; BitLocker (Windows) and FileVault (macOS) have been offering similar functionality for years now; speaking from a technical pov, it's a solved problem. Going further down that road: As LUKS2 supports detached headers, you could even do interesting shenanigans like simply storing Posted Sep 30, 2025 22:34 UTC (Tue) by berto (subscriber, #58604) [Link] (2 responses) I'm not familiar with the internals of the device mapper but I can imagine that this would need changes in dm-crypt: you would need to have a device that is only encrypted up to a certain offset, and that offset would change in real time while the device is being used. Posted Oct 1, 2025 15:20 UTC (Wed) by muase (subscriber, #178466) [Link] (1 responses) Posted Oct 1, 2025 20:43 UTC (Wed) by berto (subscriber, #58604) [Link] Posted Oct 4, 2025 12:46 UTC (Sat) by tajyrink (subscriber, #2750) [Link] Posted Sep 30, 2025 20:23 UTC (Tue) by jcpunk (subscriber, #95796) [Link] (1 responses) Posted Sep 30, 2025 21:05 UTC (Tue) by berto (subscriber, #58604) [Link] &lt;head&gt;ZFS&lt;/head&gt;&lt;head&gt;Bcachefs&lt;/head&gt;&lt;head&gt;Bcachefs&lt;/head&gt;&lt;head&gt;Bcachefs&lt;/head&gt;&lt;head&gt;Same choice as Android&lt;/head&gt;&lt;head&gt;Does dirlock use the user PIN as part of the key derivation?&lt;/head&gt;&lt;head&gt;Does dirlock use the user PIN as part of the key derivation?&lt;/head&gt;&lt;head&gt;Block-device encryption without reinstallation&lt;/head&gt;&lt;lb/&gt; 1. Unmount file system,&lt;lb/&gt; 2. Shrink/modify file system to cater for space for the LUKS header and dm-crypt,&lt;lb/&gt; 3. Add a LUKS header, and a counter that is initialized at zero (nothing encrypted yet),&lt;lb/&gt; 4. Setup dm-crypt and remount file system,&lt;lb/&gt; 5. Dm-crypt background task encrypts blocks, and updates the stored counter accordingly, until everything is encrypted.&lt;head&gt;Block-device encryption without reinstallation&lt;/head&gt;&lt;head&gt;Block-device encryption without reinstallation&lt;/head&gt;&lt;code&gt;luks-&amp;lt;partuuid&amp;gt;.bin&lt;/code&gt; in the boot or EFI partitions itself, and simply add another JSON key &lt;code&gt;dmcrypt-progress&lt;/code&gt; to the header file. As AES-XTS is zero-size overhead, now you wouldn't even need to touch and shrink the existing partitions/filesystems anymore and could transparently encrypt block by block.&lt;head&gt;Block-device encryption without reinstallation&lt;/head&gt;&lt;head&gt;Block-device encryption without reinstallation&lt;/head&gt;&lt;quote&gt;I'm not familiar with the internals of the device mapper but I can imagine that this would need changes in dm-crypt: you would need to have a device that is only encrypted up to a certain offset, and that offset would change in real time while the device is being used.&lt;/quote&gt; As far as I know, there is &lt;code&gt;cryptsetup-reencrypt&lt;/code&gt;, which already has an online-mode for reencryption but it seems that this also supports initial encryption. I'm not sure if you can use it to online-encrypt the currently booted volume; but if I understand the manpage correctly, it should be possible to boot into a minimal environment, start the encryption, convert everything to device-mapper volumes, and then reboot and continue the encryption online.


      
          &lt;head&gt;Block-device encryption without reinstallation&lt;/head&gt;&lt;head&gt;Block-device encryption without reinstallation - luksipc&lt;/head&gt;&lt;head&gt;ecryptfs?&lt;/head&gt;&lt;head&gt;ecryptfs?&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/Articles/1038859/"/><published>2025-10-10T03:12:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45535149</id><title>The RubyGems "Security Incident"</title><updated>2025-10-10T06:47:04.843656+00:00</updated><content>&lt;doc fingerprint="cdd015991f027e4f"&gt;
  &lt;main&gt;
    &lt;p&gt;09 Oct 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;The RubyGems “security incident”&lt;/head&gt;
    &lt;p&gt;Ruby Central posted an extremely concerning “Incident Response Timeline” today, in which they make a number of exaggerated or purely misleading claims. Here’s my effort to set the record straight.&lt;/p&gt;
    &lt;p&gt;First, and most importantly: I was a primary operator of RubyGems.org, securely and successfully, for over ten years. Ruby Central does not accuse me of any harms or damages in their post, in fact stating “we have no evidence to indicate that any RubyGems.org data was copied or retained by unauthorized parties, including Mr. Arko.”&lt;/p&gt;
    &lt;p&gt;The actions I took during a time of great confusion and uncertainty (created by Ruby Central!) were careful, specific, and aimed to defend both Ruby Central the organization and RubyGems.org the service from potential threats.&lt;/p&gt;
    &lt;p&gt;The majority of the team, including developers in the middle of paid full-time work for Ruby Central, had just had all of their permissions on GitHub revoked. And then restored six days later. And then revoked again the next day. Even after the second mass-deletion of team permissions, Marty Haught sent an email to the team within minutes, at 12:47pm PDT, saying he was (direct quote) “terribly sorry” and “I messed up”. Update: Added email timestamp.&lt;/p&gt;
    &lt;p&gt;The erratic and contradictory communication supplied by Marty Haught, and the complete silence from Shan and the board, made it impossible to tell exactly who had been authorized to take what actions. As this situation occurred, I was the primary on-call. My contractual, paid responsibility to Ruby Central was to defend the RubyGems.org service against potential threats.&lt;/p&gt;
    &lt;p&gt;Marty’s final email clearly stated “I’ll follow up more on this and engage with the governance rfc in good faith.”. Just a few minutes after that email, at 1:01pm PDT, Marty also posted a public GitHub comment, where he agreed to participate in the proposed governance process and stated “I’m committed to find the right governance model that works for us all. More to come.” Update: screenshot of comment removed and replaced with link, since the comment appears to still be visible (at least to logged out users) on GitHub.&lt;/p&gt;
    &lt;p&gt;Given Marty’s claims, the sudden permission deletions made no sense. Worried about the possibility of hacked accounts or some sort of social engineering, I took action as the primary on-call engineer to lock down the AWS account and prevent any actions by possible attackers. I did not change the email addresses on any accounts, leaving them all owned by a team-shared email at rubycentral.org, to ensure the organization retained overall control of the accounts, even if individuals were somehow taking unauthorized actions.&lt;/p&gt;
    &lt;p&gt;Within a couple of days, Ruby Central made an (unsigned) public statement, and various board members agreed to talk directly to maintainers. At that point, I realized that what I thought might have been a malicious takeover was both legitimate and deliberate, and Marty would never “fix the permissions structure”, or “follow up more” as he said.&lt;/p&gt;
    &lt;p&gt;Once I understood the situation, I backed off to let Ruby Central take care of their “security audit”. I left all accounts in a state where they could recover access. I did not alter, or try to alter, anything in the Ruby Central systems or GitHub repository after that. I was confident, at the time, that Ruby Central’s security experts would quickly remove all outside access.&lt;/p&gt;
    &lt;p&gt;My confidence was sorely misplaced.&lt;/p&gt;
    &lt;p&gt;Almost two weeks later, someone asked if I still had access and I discovered (to my great alarm), that Ruby Central’s “security audit” had failed. Ruby Central also had not removed me as an “owner” of the Ruby Central GitHub Organization. They also had not rotated any of the credentials shared across the operational team using the RubyGems 1Password account.&lt;/p&gt;
    &lt;p&gt;I believe Ruby Central confused themselves into thinking the “Ruby Central” 1Password account was used by operators, and they did revoke my access there. However, that 1Password account was not used by the open source team of RubyGems.org service operators. Instead, we used the “RubyGems” 1Password account, which was full of operational credentials. Ruby Central did not remove me from the “RubyGems” 1Password account, even as of today.&lt;/p&gt;
    &lt;p&gt;Aware that I needed to disclose this surprising access, but also aware that it was impossible for anyone except former operators to exploit this security failure, I immediately wrote an email to Ruby Central to disclose the problem.&lt;/p&gt;
    &lt;p&gt;Here is a copy of my disclosure email, in full.&lt;/p&gt;
    &lt;code&gt;From: André Arko &amp;lt;andre@arko.net&amp;gt;
Subject: Re: RubyGems.org access
Date: September 30, 2025 at 10:23:12 AM PDT
To: Marty Haught &amp;lt;marty@rubycentral.org&amp;gt;

Hi Marty,

It has come to my attention that despite the statements in [your] email, I have had uninterrupted access to RubyGems.org production environments from September 18 until today, September 30, via the root credentials of the Ruby Central AWS account, as well as continued and ongoing access to the full feed of production alerts and logs in DataDog.

It seems that the only permissions I have had removed are from the GitHub organization named "rubygems", which as you know is unrelated to the RubyGems.org production access you mention in your email.

I have also noticed I am still, as of September 30, the owner of the GitHub organizations named "rubycentral" and "rubytogether".

I am unable to transfer the HelpScout or PagerDuty accounts, as you have disabled my andre@rubygems.org Google account.

Please advise as to your desired resolution of this situation.

Thank you,
André Arko
&lt;/code&gt;
    &lt;p&gt;Ruby Central did not reply to this email for over three days.&lt;/p&gt;
    &lt;p&gt;When they finally did reply, they seem to have developed some sort of theory that I was interested in “access to PII”, which is entirely false. I have no interest in any PII, commercially or otherwise. As my private email published by Ruby Central demonstrates, my entire proposal was based solely on company-level information, with no information about individuals included in any way. Here’s their response, over three days later.&lt;/p&gt;
    &lt;code&gt;From: Marty Haught &amp;lt;marty@rubycentral.org&amp;gt;
Subject: Re: RubyGems.org access
Date: October 3, 2025 at 6:54:01 PM MDT
To: André Arko &amp;lt;andre@arko.net&amp;gt;

Hi André,

Please confirm that you cannot access the Ruby Central AWS root account credentials, either through the console or by access keys.

In addition, please confirm whether you are in possession of any RubyGems.org production data,  including, but not limited to, server logs, access logs, PII, or other organizational data.

Thank you,
Marty
&lt;/code&gt;
    &lt;p&gt;In addition to ignoring the (huge) question of how Ruby Central failed to secure their AWS Root credentials for almost two weeks, and appearing to only be aware of it because I reported it to them, their reply also failed to ask whether any other shared credentials might still be valid. There were more.&lt;/p&gt;
    &lt;code&gt;From: André Arko &amp;lt;andre@arko.net&amp;gt;
Subject: Re: RubyGems.org access
Date: October 5, 2025 at 11:59:35 AM PDT
To: Marty Haught &amp;lt;marty@rubycentral.org&amp;gt;

Hi Marty,

Thanks for letting me know you got my email disclosing my unintended access. I’m concerned that security must not be a very high priority for Ruby Central since no one acknowledged my disclosure for more than three days, but I appreciate the confirmation.

As far as I can tell, I can no longer access the Ruby Central AWS root account either through the console or via access keys.

I confirm I did not download or save any production data after your email of September 18, including server logs, access logs, PII, or other organizational data.

However, while checking AWS credentials in order to write this email, I discovered that several other service credentials have not been rotated, and are still valid for production AWS access. That means both myself and the other former operators all still have access to AWS via those previously-shared credentials.

I would appreciate it if you could answer the request from my first email, and reply with your desired resolution for this remaining unintended production access, as well as the GitHub organization ownership.

Thanks,
André
&lt;/code&gt;
    &lt;p&gt;Unbeknownst to me, while I was answering Marty’s email in good faith, Ruby Central’s attorney was sending my lawyer a letter alleging I had committed a federal crime, on the theory that I had “hacked” Ruby Central’s AWS account. On the contrary, my actions were taken in defense of the service that Ruby Central was paying me to support and defend.&lt;/p&gt;
    &lt;p&gt;With my side of the story told, I’ll leave it to you to decide whether you think it’s true that “Ruby Central remains committed to transparent, responsible stewardship of the RubyGems infrastructure and to maintaining the security and trust that the Ruby ecosystem depends on.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andre.arko.net/2025/10/09/the-rubygems-security-incident/"/><published>2025-10-10T03:30:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45535183</id><title>Love C, Hate C: Web Framework Memory Problems</title><updated>2025-10-10T06:47:04.332679+00:00</updated><content>&lt;doc fingerprint="2e3a99cdbcef0edd"&gt;
  &lt;main&gt;
    &lt;p&gt;I love C. I could give you rational reasons for that. Like the fact that it works everywhere and how it goes fast. But mostly I love C because when I write C I feel an intimate connection with my computer. To me, C has soul. In fact all my personal project are written in C, like the graphics rendering engines that I'm currently writing. The problem is that C is dangerous and sharing new C projects to wider audiences is borderline malicious.&lt;/p&gt;
    &lt;p&gt;Today on hacker news a cool little web framework written in C was posted. As a security researcher I'm always trying to sharpen my skills so I thought I'd given the app a look. And yup sure enough, there's memory safety issues.&lt;/p&gt;
    &lt;code&gt;HttpParser parseRequest(char *request) {
    HttpParser parser = {
        .isValid = true,
        .requestBuffer = strdup(request), // [0]
        .requestLength = strlen(request),
        .position = 0,
    };

    // ... irrelevant stuff

    for (int i = 0; i &amp;lt; parser.request.headerCount; i++) {
        if (strcasecmp(parser.request.headers[i].name, "Content-Length") == 0) {
            parser.request.bodyLength = atoi(parser.request.headers[i].value); // [1]
            break;
        }
    }
    
    parser.request.body = malloc(parser.request.bodyLength + 1); // [2]
    for (int i = parser.position; i &amp;lt; parser.position + parser.request.bodyLength; i++) {
        parser.request.body[i - parser.position] = parser.requestBuffer[i]; // [3]
    }&lt;/code&gt;
    &lt;p&gt;line [1] takes Content-Length off the http packet. This is a non validated value basically straight from the socket. line [2] allocates based on that size. Line [3] copies data into that buffer based on that size. But it's copying out of a buffer of any size. So passing a &lt;code&gt;Content-Length&lt;/code&gt; Larger than the &lt;code&gt;request&lt;/code&gt; sent in will start copying heap data into the &lt;code&gt;parser.request.body&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Another interesting choice in this project is to make lengths signed:&lt;/p&gt;
    &lt;code&gt;typedef struct {
    //...

    int        headerCount;
    int        headerCapacity;

    //...
    int        bodyLength;
} HttpRequest;

typedef struct {
    // ...
    
    int         position;
    //...
    int         requestLength;
} HttpParser;&lt;/code&gt;
    &lt;p&gt;What does it mean to have a negative &lt;code&gt;headerCount&lt;/code&gt; or negative of anything here? Maybe there is a valid meaning, but we need to ask ourselves that question. Going back to the original code sample. A malicious user can pass &lt;code&gt;Content-Length&lt;/code&gt; of &lt;code&gt;4294967295&lt;/code&gt;. &lt;code&gt;malloc(parser.request.bodyLength + 1)&lt;/code&gt; which becomes &lt;code&gt;malloc(0)&lt;/code&gt; actually returns a  valid pointer in glibc. Now you won't immediately buffer overflow here because &lt;code&gt;i &amp;lt; parser.position + parser.request.bodyLength&lt;/code&gt; where i is initialized to &lt;code&gt;parser.position&lt;/code&gt; and it's basically &lt;code&gt;parser.position-1&lt;/code&gt; so &lt;code&gt;i&lt;/code&gt; will always be greater. But these mangled request body and length values get routed to the webdevs App. You'd better hope they catch the issue.&lt;/p&gt;
    &lt;p&gt;I love C it's simple, elegant but also so dang annoying.&lt;/p&gt;
    &lt;p&gt;Comments to be found on this hackernews thread. Ping me there to talk security, C, or graphics and rendering haha :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alew.is/lava.html"/><published>2025-10-10T03:39:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45535202</id><title>My approach to building large technical projects (2023)</title><updated>2025-10-10T06:47:04.219451+00:00</updated><content>&lt;doc fingerprint="23d090754d843dbe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mitchell Hashimoto&lt;/head&gt;
    &lt;head rend="h1"&gt;My Approach to Building Large Technical Projects&lt;/head&gt;
    &lt;p&gt;Whether it's building a new project from scratch, implementing a big feature, or beginning a large refactor, it can be difficult to stay motivated and complete large technical projects. A method that works really well for me is to continuously see real results and to order my work based on that.&lt;/p&gt;
    &lt;p&gt;We've all experienced that feeling of excitement starting a new project. The first few weeks you can't wait to get on the computer to work. Then slowly over time you get distracted or make up excuses and work on it less. If this is for real work, you forcibly slog your way to the finish line but every day is painful. If this is for fun, you look back years from now and remember what could've been.&lt;/p&gt;
    &lt;p&gt;I've learned that when I break down my large tasks in chunks that result in seeing tangible forward progress, I tend to finish my work and retain my excitement throughout the project. People are all motivated and driven in different ways, so this may not work for you, but as a broad generalization I've not found an engineer who doesn't get excited by a good demo. And the goal is to always give yourself a good demo.&lt;/p&gt;
    &lt;p&gt;I'm not claiming that anything I say in this post is novel. It definitely shares various aspects of well-known software engineering or management practices. I'm just sharing the way I approach the larger technical work that I do and why I do it this way.&lt;/p&gt;
    &lt;p&gt;I'll use my terminal emulator project as an example throughout this post so that there is realistic, concrete experience I can share. There's plenty of other projects I could've used but I'll choose this one since it's not related to my professional work and it is recent enough to be fresh in my mind.&lt;/p&gt;
    &lt;p&gt;I want to be crystal clear that I am not shaming anyone for not completing projects. As long as you're having fun and feel accomplished (or simply don't care), good for you and more power to you. This blog post is aimed at people who want to finish projects more or simply want to learn how I strive to finish projects more.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Starting Line&lt;/head&gt;
    &lt;p&gt;Initially, you have some large project and you have to figure how to start. For me, this is the hardest part and I can spend hours -- sometimes days -- waffling over the right starting point.&lt;/p&gt;
    &lt;p&gt;For my terminal emulator, there were a number of large components that I knew would have to exist if I ever intended to finish this project: terminal parsing, running and managing a shell process, font rendering, grid rendering, input handling (keyboard/mouse), etc. There are hundreds of relatively large sub-projects on the path to "done."&lt;/p&gt;
    &lt;p&gt;If my initial goal was to see a launchable terminal that could run Neovim, I'd be in big trouble. Even with unknown unknowns, this goal just sounds too big. I can intuitively realize that there are a lot of components on that path: rendering a GUI, process launching, terminal parsing and state management. This is a bad goal, it's too big and I'd probably lose interest a month or two in.&lt;/p&gt;
    &lt;p&gt;Instead, I try to think what a realistic project is where I can see results as soon as possible. Once you apply that filter, the number of viable sub-projects shrinks dramatically. Here are some examples:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;VT Parsing - parsing the terminal escape sequences&lt;/item&gt;
      &lt;item&gt;Blank window rendering - open a window and draw a blank canvas&lt;/item&gt;
      &lt;item&gt;Child process lanching - launch a child shell such as bash, zsh, fish, setup the TTY and be able to read output from it (i.e. the initial shell prompt)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I don't try to enumerate all the big sub-projects at this stage. I just kind of get an idea of the rough shape the project will take and find one that I can build in isolation and also physically see some sort of real results.&lt;/p&gt;
    &lt;p&gt;This is the phase where experience helps the most. Engineers with more experience are usually able to more effectively paint the picture of the rough shape a project will take. They can identify various subcomponents with more accuracy and see how they pieces fit together. With less experience, or in a domain I'm unfamiliar with, I just take a best guess and expect there is a higher likelihood I'll throw my work away at some point.&lt;/p&gt;
    &lt;head rend="h1"&gt;Early Results&lt;/head&gt;
    &lt;p&gt;Early work tends to not be very visible and that makes seeing tangible results seem difficult. For example, if I chose to work on VT parsing for my terminal, I can't see it work without also hooking up a UI of some sort. Or for some other project if I chose to work on a database schema and minimal API, I similarly can't see that work without writing a client along with a CLI or GUI.&lt;/p&gt;
    &lt;p&gt;If the initial subproject you choose to work on is a UI, then you can quickly see some results of course! For various reasons, I rarely start frontend first and usually start backend first. And in any situation, you'll eventually get to the backend and reach a similar challenge.&lt;/p&gt;
    &lt;p&gt;The best tool to get past this phase is automated testing (usually unit testing at this stage). Automated tests let you actually run some code and see it is working and also has the benefit of being good hygiene.&lt;/p&gt;
    &lt;p&gt;This gives you another guiding point for picking out your first few tasks: if it isn't graphical, you want to pick something that is testable without too much fuss so you can see some results.&lt;/p&gt;
    &lt;p&gt;For my terminal, I decided to start with VT parsing first, because it was a part of a terminal at the time that I didn't know too much about and it felt like something that I could very easily test: give it some example input as a string, expect some parsed action or event as output.&lt;/p&gt;
    &lt;p&gt;Seeing the progression of "1 test passed", "4 tests passed," "13 tests passed" and so on is super exciting to me. I'm running some code I wrote and it's working. And I know that I'm progressing on some critical sub-component of a larger project.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sprint to Demos&lt;/head&gt;
    &lt;p&gt;My goal with the early sub-projects isn't to build a finished sub-component, it is to build a good enough sub-component so I can move on to the next thing on the path to a demo. ✨&lt;/p&gt;
    &lt;p&gt;This tradeoff isn't just manifested in functionality. It may be manifested in algorithmic or design considerations. For example, you may know that in the future, you'll need to use something like a real database or a fancy data structure or support streaming data. But for the initial set of work, you can just use in-memory contents, built-in data structures such as dictionaries, and require all your inputs/outputs up front.&lt;/p&gt;
    &lt;p&gt;I think this is an important tradeoff so I will repeat it: do not let perfection be an enemy of progress. Going further, do not let future improvements you know you'll have to make stop you from moving on to the next thing. The goal is to get to a demo.&lt;/p&gt;
    &lt;p&gt;No matter what I'm working on, I try to build one or two demos per week intermixed with automated test feedback as explained in the previous section.&lt;/p&gt;
    &lt;p&gt;Building a demo also provides you with invaluable product feedback. You can quickly intuit whether something feels good, even if it isn't fully functional. These aren't "minimum viable products", because they really aren't viable, but they're good enough to provide an engineer some valuable self-reflection.&lt;/p&gt;
    &lt;p&gt;This is an area where I think experience actually hurts. I've seen senior engineers get bogged down building the perfect thing and by the time they get a demo, they realize it sucks. The implementation doesn't suck, but the product or feature itself actually sucks.&lt;/p&gt;
    &lt;p&gt;Recall that for the terminal the first task I chose was VT parsing. In the early stages, I only saw automated tests work. To get to my first demo, I built a shell script that would run some command, capture its output, feed it to my VT parser, and output everything it parsed (or couldn't). Over time, I iterated on this CLI as my first "UI" -- I would render the terminal grid using ASCII.&lt;/p&gt;
    &lt;p&gt;This gave me immense satisfaction since I could run simple programs like &lt;code&gt;man&lt;/code&gt; or &lt;code&gt;ls&lt;/code&gt; or more complex programs like &lt;code&gt;vim&lt;/code&gt; and see my parser work (or break,
which is equally exciting in its own way).&lt;/p&gt;
    &lt;p&gt;In this scenario, the CLI I was writing was relatively useless long term (I ended up throwing it away rather quickly). But the day or two I spent building it as a demo provided me with an important feeling of progress and seeing something work helped keep me motivated.&lt;/p&gt;
    &lt;head rend="h1"&gt;Build for Yourself&lt;/head&gt;
    &lt;p&gt;This section will apply more to personal projects than to work-assigned projects. Even if you aspire to release some software for others, build only what you need as you need it and adopt your software as quickly as possible.&lt;/p&gt;
    &lt;p&gt;I'm always more motivated working on a problem I'm experiencing myself1. And if a product designed for you doesn't work for you, it's very likely not going to work well for others, either. Therefore, my path from demos to an actual real-world usable product is to find the shortest path to building only the functionality I think I need.&lt;/p&gt;
    &lt;p&gt;For my terminal, that meant first being able to load my shell configuration (fish) and from there being able to launch and use Neovim. So I beelined all my work to only the functionality needed for that: only the escape sequences those programs used, only rendering the font I use daily, etc. Examples of features I initially omitted: scrolling, mouse selection, search, tabs/splits, etc.&lt;/p&gt;
    &lt;p&gt;Then I started using my terminal as a daily driver. This step usually has a few false starts; you realize you actually need some feature you omitted or forgot. In my initial runs of my terminal, I realized my arrow keys didn't do anything, there were subtle (but workflow-breaking) rendering bugs, etc. So I'd go abandon using it, but it gave me tangible tasks to work on next.&lt;/p&gt;
    &lt;p&gt;Additionally, I always feel a lot of pride using software with code that I wrote and that usually helps keep me motivated to continue working on it.&lt;/p&gt;
    &lt;head rend="h1"&gt;Packaging it Up&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Decompose a large problem into smaller problems. Importantly, each small problem must have some clear way you can see the results of your work.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Only solve the smaller problem enough to progress on a demo-aspect of the larger problem, then move on to the next small problem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Only solve enough small problems to be able to begin building runnable demos of your software, then continue to iterate on more functionality. Make demos as frequently as you can.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Prioritize functionality that enables you to adopt your own software, if applicable (a personal project, a work project solving a problem you actually have, etc.). Then continue to solve your own problems first.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Go back and iterate on each component as needed for future improvements, repeating this process as needed.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;And that's pretty much it. I've followed this general pattern on personal projects, group projects, work projects, school projects, etc. and it's how I keep myself motivated2.&lt;/p&gt;
    &lt;p&gt;Note that I didn't mention a lot of things! I don't talk about shipping. I know a lot of people find shipping motivational. I don't think you need to ship a project for it to be successful. And for me, I find shipping too big of an event to motivate me long-term. I don't talk about tooling (Git workflows, CI, etc.). I've used my process across multiple jobs and fit it into whatever process is established. And so on.&lt;/p&gt;
    &lt;p&gt;I think that helps show how much of a personal process this is. Everyone I think needs to find some process to reinforce their motivation in a healthy way. I realized seeing results motivates me really strongly, I've built my work style around that, and it has worked well for me thus far.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mitchellh.com/writing/building-large-technical-projects"/><published>2025-10-10T03:45:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45535425</id><title>Reasoning LLMs are wandering solution explorers</title><updated>2025-10-10T06:47:04.129622+00:00</updated><content>&lt;doc fingerprint="b99c25209cc782ab"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 26 May 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Reasoning LLMs are Wandering Solution Explorers&lt;/head&gt;View PDF&lt;quote&gt;Abstract:Large Language Models (LLMs) have demonstrated impressive reasoning abilities through test-time computation (TTC) techniques such as chain-of-thought prompting and tree-based reasoning. However, we argue that current reasoning LLMs (RLLMs) lack the ability to systematically explore the solution space. This paper formalizes what constitutes systematic problem solving and identifies common failure modes that reveal reasoning LLMs to be wanderers rather than systematic explorers. Through qualitative and quantitative analysis across multiple state-of-the-art LLMs, we uncover persistent issues: invalid reasoning steps, redundant explorations, hallucinated or unfaithful conclusions, and so on. Our findings suggest that current models' performance can appear to be competent on simple tasks yet degrade sharply as complexity increases. Based on the findings, we advocate for new metrics and tools that evaluate not just final outputs but the structure of the reasoning process itself.&lt;/quote&gt;&lt;p&gt; Current browse context: &lt;/p&gt;&lt;p&gt;cs.CL&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2505.20296"/><published>2025-10-10T04:40:26+00:00</published></entry></feed>