<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-08T20:37:15.926945+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45514433</id><title>One-man campaign ravages EU 'Chat Control' bill</title><updated>2025-10-08T20:37:23.626602+00:00</updated><content>&lt;doc fingerprint="7d9694e3ca051efe"&gt;
  &lt;main&gt;
    &lt;p&gt;BRUSSELS — A website set up by an unknown Dane over the course of one weekend in August is giving a massive headache to those trying to pass a European bill aimed at stopping child sexual abuse material from spreading online.&lt;/p&gt;
    &lt;p&gt;The website, called Fight Chat Control, was set up by Joachim, a 30-year-old software engineer living in Aalborg, Denmark. He made it after learning of a new attempt to approve a European Union proposal to fight child sexual abuse material (CSAM) — a bill seen by privacy activists as breaking encryption and leading to mass surveillance.&lt;/p&gt;
    &lt;p&gt;The site lets visitors compile a mass email warning about the bill and send it to national government officials, members of the European Parliament and others with ease. Since launching, it has broken the inboxes of MEPs and caused a stir in Brussels’ corridors of power.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.politico.eu/article/one-man-spam-campaign-ravages-eu-chat-control-bill-fight-chat-control/"/><published>2025-10-08T10:26:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45515146</id><title>A Clausewitzian lens on modern urban warfare</title><updated>2025-10-08T20:37:23.487873+00:00</updated><content>&lt;doc fingerprint="faa359510591dbb3"&gt;
  &lt;main&gt;
    &lt;p&gt;Among Carl von Clausewitz’s many poignant dictums, the most commonly cited is undoubtedly that “war is not merely an act of policy but a true political instrument, a continuation of political intercourse, carried on by other means.” While Clausewitz never fought in a city like Fallujah, Kyiv, or Gaza if the Prussian general and philosopher of war could visit the battlefields of the twenty-first century, he would recognize modern urban warfare’s core challenges—and would find that his theories about war’s objective and the considerations needed for victory remain strikingly relevant.&lt;/p&gt;
    &lt;p&gt;Clausewitz wrote that “war is more than a true chameleon that slightly adapts its characteristics to the given case.” Its essential elements—violence, chance and probability, and subordination to policy—form what he famously described as a wunderliche Dreifaltigkeit, or “remarkable trinity.” Rather than being in conflict, these elements interact dynamically and, in successful systems like that of Napoleonic France, can operate in harmony. Clausewitz and his fellow Prussian reformers admired how the French system aligned popular will, military force, and political direction. Nowhere is the need for such harmony more acute than in modern urban warfare, where civilians, combatants, and national objectives share the same congested terrain. This environment tests the limits of military doctrine, challenges the notion of strategic clarity, and often leaves combatants with ambiguous definitions of victory.&lt;/p&gt;
    &lt;p&gt;In my work on urban warfare, from my book Understanding Urban Warfare to the numerous case studies I have authored and the field research I have conducted, I’ve seen the truths Clausewitz described play out on concrete streets and in bombed-out buildings. Urban warfare has become the norm, not the exception, and Clausewitz’s insights are not relics of Napoleonic Europe—they are essential tools for understanding the future of conflict.&lt;/p&gt;
    &lt;p&gt;Historical Context: Urban Warfare in Clausewitz’s Era&lt;/p&gt;
    &lt;p&gt;While Clausewitz never commanded modern urban battles, his military career immersed him in conflicts where cities played central strategic and symbolic roles. As a young officer in the Prussian Army, he fought in the Rhine campaigns (1793–1794), including the siege of Mainz, where revolutionary France defended the city against a Prussian-Austrian coalition. This early exposure to urban siege warfare—marked by fortified positions, complex logistics, and the suffering of civilians—gave Clausewitz firsthand insight into the unique challenges of fighting in and around cities.&lt;/p&gt;
    &lt;p&gt;Clausewitz’s later experiences reinforced the political and psychological weight of urban centers. As aide-de-camp to Prussian Prince Augustus Ferdinand, he was present during Napoleon’s 1806 victory in the battles of Jena and Auerstedt, which led to the French occupation of Berlin. He later served with the Russian Army during France’s 1812 invasion of Russia, taking part in the Battle of Borodino—a prelude to the burning of Moscow that serves as a powerful example of a capital’s strategic and symbolic significance. In 1815, having reentered Prussian service, he participated in the Battles of Ligny and Wavre, fighting on terrain where towns, roads, and rivers constrained operations and shaped outcomes.&lt;/p&gt;
    &lt;p&gt;Clausewitz drew clear conclusions from these experiences. In Principles of War, he argued that “public opinion is won through great victories and the occupation of the enemy’s capital.” He understood cities not only as symbolic centers of national will but also as logistical and operational hubs, writing of the importance of targeting “principal cities, storehouses, and large fortresses.” Though he did not witness the dense, protracted urban warfare of the modern era, Clausewitz’s strategic emphasis on cities foreshadowed many of the dynamics seen in today’s urban battles.&lt;/p&gt;
    &lt;p&gt;The Urban Trinity, Fog, and Friction: Clausewitz’s Theories in Concrete and Steel&lt;/p&gt;
    &lt;p&gt;Clausewitz’s “remarkable trinity”—violence and hatred (the people), chance and probability (in military action), and reason and policy (the government)—finds its most visceral expression in urban warfare. Cities collapse these elements into a single, compact battlespace. Unlike operations in open terrain, urban warfare places civilians, combatants, and political objectives in constant, physical contact. The Clausewitzian trinity becomes spatially literal: civilians live among the fight, military action is hyperlocalized and constrained, and every movement carries political weight.&lt;/p&gt;
    &lt;p&gt;Clausewitz also famously wrote, “No one starts a war—or rather, no one in his senses ought to do so—without first being clear in his mind what he intends to achieve by that war and how he intends to conduct it.” He noted, therefore, that “the first, the supreme, the most far-reaching act of judgment that the statesman and commander have to make is to establish . . . the kind of war on which they are embarking.”&lt;/p&gt;
    &lt;p&gt;This act of judgment is especially difficult in cities, where the kind of war one is fighting can shift from block to block. Is the objective to destroy an entrenched enemy force? To hold key, vital, or symbolic terrain? To safeguard a civilian population? In urban warfare the answer is often all of the above.&lt;/p&gt;
    &lt;p&gt;Clausewitz’s dictum that war is a continuation of politics by other means is vividly realized in urban combat. Tactical decisions in cities reverberate at strategic levels. Urban warfare does not allow separation between military action and political consequence—they are fused.&lt;/p&gt;
    &lt;p&gt;But Clausewitz reminds us that strategy is not made of battlefield maneuvers alone—it is also made of will. He defined war as “an act of force to compel our enemy to do our will.”&lt;/p&gt;
    &lt;p&gt;Victory, then, is not always the annihilation of enemy forces—it is the collapse of the enemy’s will to resist. And in modern urban warfare, maintaining the will of one’s own people (or of your ally’s population)—to support the fight or to accept the moral and political costs—is just as critical. Clausewitz considered these moral forces among the most decisive in war, writing that they “constitute the spirit that permeates war as a whole.” In cities under siege or attack, public opinion, national resolve, and leadership cohesion become as important as any tactical maneuver.&lt;/p&gt;
    &lt;p&gt;Urban warfare places enormous pressure on the internal willpower of a combatant nation and that of its involved and invested allies. The proximity of civilians, the visibility of destruction, and the speed at which information spreads can erode public support even as military objectives are met. A video, a collapsed building, or a failed operation can shift the strategic balance—not through force, but by weakening the political object that gives war its purpose. Clausewitz warned, “The political object is the goal, war is the means of reaching it, and means can never be considered in isolation from their purpose.”&lt;/p&gt;
    &lt;p&gt;This relationship between political objectives, military action, and national will is especially fragile in urban combat. When will breaks—on either side—the war may be lost regardless of battlefield gains.&lt;/p&gt;
    &lt;p&gt;Yet even the clearest strategy must contend with the inherent chaos of war. “War is the realm of uncertainty,” Clausewitz cautioned. “Three quarters of the factors on which action in war is based are wrapped in a fog of greater or lesser uncertainty.” This fog of war—its confusion, unpredictability, and lack of reliable information—is magnified in dense urban environments where lines between civilian and combatant blur and information spreads instantly and globally. Commanders must make high-stakes decisions in environments where clarity is fleeting.&lt;/p&gt;
    &lt;p&gt;Compounding this is what Clausewitz called friction—the accumulation of countless small obstacles that derail even the best-laid plans. As he wrote:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Everything in war is very simple, but the simplest thing is difficult. The difficulties accumulate and end by producing a kind of friction that is inconceivable unless one has experienced war. . . . Friction is the only concept that more or less corresponds to the factors that distinguish real war from war on paper.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Friction in cities is not theoretical—it’s tactical and visceral. Streets canalize movement. Buildings obscure lines of sight. Civilians become obstacles or allies. The environment itself resists clean execution. Urban warfare reveals Clausewitz’s insights not just as philosophical musings, but as hard realities in concrete and steel.&lt;/p&gt;
    &lt;p&gt;Urban Warfare in Iraq: Lessons from Baghdad and ISIS&lt;/p&gt;
    &lt;p&gt;The US campaigns in Iraq and the broader fight against the Islamic State of Iraq and Syria (ISIS) offer a laboratory of Clausewitzian warfare in cities—where tactical success frequently collided with political complexity, and where the will of the population, not battlefield metrics, often defined the limits of victory.&lt;/p&gt;
    &lt;p&gt;The 2003 “Thunder Run” into Baghdad was more than a demonstration of military power—it was a calculated strike at the enemy’s political center of gravity. Recall Clausewitz’s observation that “public opinion is won through great victories and the occupation of the enemy’s capital.” Taking Baghdad had immediate strategic effects: It overthrew Saddam Hussein and dismantled the Ba’athist regime. But it did not yield strategic clarity. Once the political objective shifted from regime removal to establishing a new political order—that is, nation-building—the occupation of the capital no longer compelled the enemy to do our will. Instead, it ushered in a new phase of resistance—fought not by conventional armies, but by insurgents embedded in the population. The Clausewitzian trinity fractured, and the fog of war deepened.&lt;/p&gt;
    &lt;p&gt;The 2004 First and Second Battles of Fallujah posed a different Clausewitzian challenge: how to reestablish control over a city that had become both a symbol and a stronghold of insurgent defiance. The battles exposed the full weight of friction. Every block was contested. Civilian presence, urban density, and improvised defenses neutralized many of the coalition’s technological advantages. Clausewitz’s observation rang true: The simplest thing became difficult. But beyond the tactical grind, Fallujah also heightened the strategic burden of fighting in cities under global media scrutiny. Images of destruction and civilian displacement reverberated internationally, influencing Iraqi public opinion, straining allied cohesion, and testing the will of the Iraqi government itself. Tactical brilliance could not guarantee strategic clarity—and each gain came at political and moral cost.&lt;/p&gt;
    &lt;p&gt;Clausewitz’s theories are no less relevant in the fight against ISIS. The battles for Mosul, Raqqa, and Aleppo offer vivid examples of Clausewitzian dynamics playing out in dense urban terrain.&lt;/p&gt;
    &lt;p&gt;The Battle of Mosul (2016–2017), the largest urban combat operation since World War II, marked both the height and unraveling of ISIS’s territorial control. The city—where ISIS declared its caliphate—was a living example of Clausewitz’s trinity: ideological violence among the people, unpredictable chance in military operations, and the overarching influence of policy and statecraft. ISIS weaponized the city’s geography to negate coalition advantages. Each alley and rooftop became a node of Clausewitzian friction, where the fog of war was compounded by hidden explosives, civilian shields, and the media theater of terror.&lt;/p&gt;
    &lt;p&gt;The struggle to recapture Raqqa (2017) similarly underscored Clausewitz’s emphasis on the strategic value of cities—but also on the cost of capturing them. Coalition forces had to balance the immediate tactical need for firepower with the long-term strategic imperative of minimizing civilian casualties and preserving infrastructure. Raqqa’s fall signaled not just military defeat for ISIS, but the collapse of its political narrative of governance and legitimacy.&lt;/p&gt;
    &lt;p&gt;Aleppo (2012–2016) offered a final case study in how urban warfare reshapes Clausewitzian dynamics. The regime of Bashar al-Assad, with Russian support, waged a prolonged campaign of attrition to reclaim the city. Aleppo’s recapture was not just a battlefield event—it was a strategic and psychological victory that reshaped the regional balance. Clausewitz’s insight that war is always shaped by the interaction of violence, politics, and chance was on full display. In Aleppo, military power served political ends—but at enormous humanitarian and reputational cost.&lt;/p&gt;
    &lt;p&gt;The Battle of Kyiv: A Clausewitzian Struggle&lt;/p&gt;
    &lt;p&gt;The 2022 Battle of Kyiv illustrates many of Clausewitz’s core principles. Russian forces launched a lightning assault on the capital, aiming to swiftly decapitate Ukraine’s political leadership and seize its strategic center of gravity. But what they encountered was not just a military defense, but a national resistance. The people, military, and government acted as one cohesive trinity. And President Volodymyr Zelenskyy’s decision to remain in Kyiv was not just political theater—it was a deliberate act of strategic will.&lt;/p&gt;
    &lt;p&gt;The defenders of Kyiv skillfully leveraged the urban environment to neutralize Russia’s advantages and impose costs at every level of engagement. What followed was a textbook display of Clausewitzian friction: stalled armored columns, logistical failures, intelligence breakdowns, and a general underestimation of local resistance. Citizen volunteers, guided by their knowledge of terrain and empowered by social networks, became a force multiplier against a numerically and technologically superior invader. Even simple tactical objectives—securing key intersections or resupplying units—became unexpectedly complex under the weight of terrain, resistance, and human error. This was the very essence of what Clausewitz warned distinguishes real war from war on paper.&lt;/p&gt;
    &lt;p&gt;Russia’s inability to capture the capital—the symbolic heart of the Ukrainian state—had cascading effects. It allowed Ukraine to garner international support, secure military resupply, and build momentum on the strategic level. In urban warfare, just holding out can be a victory. The defense of a city like Kyiv can serve not only to blunt an assault but to buy time for political conditions to shift, for alliances to strengthen, and for strategic clarity to emerge. In such contexts, endurance becomes its own form of offense.&lt;/p&gt;
    &lt;p&gt;This was not just a tactical defeat for Russia—it was a strategic failure born of a fundamental mismatch between political ambition and military means. The objective—seizing Kyiv—was politically clear, but Russia failed to align its resources, capabilities, and assumptions with that goal. Clausewitz’s admonition echoed loudly as Russian columns stalled short of the capital: “The political object is the goal, war is the means of reaching it, and means can never be considered in isolation from their purpose.” The Battle of Kyiv proved that even with overwhelming force, war conducted without coherence between ends and means is destined to fail.&lt;/p&gt;
    &lt;p&gt;Gaza and the Israel Defense Forces: Tactical Success, Strategic Strain&lt;/p&gt;
    &lt;p&gt;If Kyiv is a case study of Clausewitzian alignment of war and policy, Israel’s ongoing operations in Gaza provide another example of the dangers when the alignment falters.&lt;/p&gt;
    &lt;p&gt;The Israel Defense Forces are one of the most experienced militaries in urban warfare in the world. Israeli military operations are precise, intelligence-driven, and supported by technological superiority. Yet even these capabilities cannot eliminate the strategic dilemma of fighting in cities densely packed with civilians, under intense global scrutiny, and against nonstate actors that use the urban fabric—cities’ terrain and their people—as both shield and weapon.&lt;/p&gt;
    &lt;p&gt;Clausewitz emphasized that war is not an isolated act but part of a “continuous interaction”—including, notably, interaction with political objectives. In Gaza, the Israel Defense Forces face a situation where the tactical destruction of enemy infrastructure—tunnels, command nodes, rocket sites—does not necessarily translate to strategic success of all the war’s political goals. Every collapsed apartment building and every civilian casualty reverberates globally. The moral forces Clausewitz emphasized—public opinion and will—are not abstract; they are measurable in diplomatic isolation or support, domestic cohesion, and battlefield morale.&lt;/p&gt;
    &lt;p&gt;This is not to say the Israeli military lacks clarity in its objectives, but rather that the urban environment imposes costs and constraints that can undermine strategic coherence. As I argued in Understanding Urban Warfare, a city can be the greatest ally or the worst foe, depending on how it is approached. Clausewitz would remind any military leader that the means employed must remain proportionate and consistent with the political purpose.&lt;/p&gt;
    &lt;p&gt;Clausewitz also cautioned against rigid formulas. “Every age,” he wrote, “[has] had its own kind of war, its own limiting conditions, and its own peculiar preconceptions”. Urban warfare in the twenty-first century demands adaptation, and nowhere is this more evident than in the lessons derived from Gaza.&lt;/p&gt;
    &lt;p&gt;For the Israel Defense Forces operating in Gaza, every strike, pause, or maneuver is interpreted through political, humanitarian, and informational lenses. This is enhanced by the magnified friction of fighting in dense urban terrain. Streets can canalize movement, buildings and tunnels can conceal threats, and civilians can either support or sabotage operations.&lt;/p&gt;
    &lt;p&gt;Clausewitz, with his emphasis on uncertainty, chance, and moral forces, would have found urban warfare like that seen in Gaza to be the ultimate test of the statesman’s clarity and the commander’s judgment. In today’s information environment, that friction is amplified—a single video or narrative about the use (or misuse) of force, whether true or fabricated, can influence entire populations and political bodies. This aligns with Clausewitz’s trinity of wills—the people, the military, and the government, all three of which must be in balance for coherent strategy. In cities, that balance is constantly tested in real time and often in front of a global audience.&lt;/p&gt;
    &lt;p&gt;The Strategic Center of Gravity is Urban&lt;/p&gt;
    &lt;p&gt;Clausewitz’s concept of the “center of gravity”—the source of power that holds everything in war together—was one of his most important strategic insights. He described it as the “hub of all power and movement, on which everything depends.” In his time, contending military with the center of gravity often meant the destruction of the enemy’s main army or the occupation of its capital. But in modern warfare—especially in urban environments—the center of gravity is rarely a fixed physical point. It is dynamic, psychological, and deeply political.&lt;/p&gt;
    &lt;p&gt;Today, the center of gravity often resides in urban areas, not just as terrain to be seized but as spaces where power is concentrated: political authority, public opinion, information control, and the will of the people. Cities like Kyiv, Gaza City, Mosul, or Aleppo are not merely battlefields—they are arenas where military action collides with political meaning. Clausewitz would recognize these dynamics, because for him, the essence of war was not tactical victory but the pursuit of a political object shaped by what he called moral forces.&lt;/p&gt;
    &lt;p&gt;Again, Clausewitz wrote, “The moral elements are among the most important in war. They constitute the spirit that permeates war as a whole.” He was referring to intangible but decisive factors—public support, national will, leadership cohesion, and belief in the cause. These forces are especially visible in cities, where every strike and every image can either strengthen or fracture the political foundations of the war effort. What we might now call legitimacy in modern strategy—credibility in the eyes of a population or the international community—can be understood as the sum of these moral forces. Clausewitz didn’t use the term, but he clearly grasped its meaning and importance.&lt;/p&gt;
    &lt;p&gt;In Kyiv, the city itself became the center of gravity—not only for its political and logistical importance, but for what it symbolized. Its defense became an act of national will. In Gaza, the battle shifts between tactical objectives and a struggle over public opinion, both local and global.&lt;/p&gt;
    &lt;p&gt;In today’s urban conflicts, the political object—the goal, in Clausewitz’s terms, which must not be separated from war as the means of reaching it—is constantly under pressure. This pressure comes not just from the enemy, but also from how one’s own population, allies, and adversaries perceive the use of force. A commander may win the battle for terrain and still lose the war if public opinion collapses or the political object becomes unsustainable.&lt;/p&gt;
    &lt;p&gt;This is why the center of gravity in modern warfare often runs through the city—not because of what is physically located there, but because of what is at stake symbolically, psychologically, and politically. In cities, Clausewitz’s theory finds its sharpest edge: Moral forces meet material realities, and the balance of war can shift not through firepower alone, but through the will of those watching, enduring, or resisting.&lt;/p&gt;
    &lt;p&gt;Clausewitz in the Urban Century&lt;/p&gt;
    &lt;p&gt;Cities have become the default terrain of modern war. From Kyiv to Gaza, the battles fought today are not anomalies—they are signals. Urban warfare is not an exception to Clausewitz’s theory; it is its most vivid and volatile expression.&lt;/p&gt;
    &lt;p&gt;Cities compress all the elements Clausewitz identified as fundamental to war: violence, chance, political purpose, friction, and uncertainty. They bring the political object, the will of the people, and military action into immediate proximity—requiring a level of harmony among these forces that is difficult to achieve but critical to sustaining strategic coherence. In this space, tactical actions instantly reverberate across strategic and political spheres. Every strike is a message, every misstep a liability.&lt;/p&gt;
    &lt;p&gt;Clausewitz would demand that today’s commanders and policymakers understand that war in cities is not just about maneuver and firepower—it is about narrative, perception, endurance, and will. Modern urban warfare is fought in full view of the world, under moral scrutiny, and amid civilian populations whose support or suffering can shape the outcome as much as any weapon system.&lt;/p&gt;
    &lt;p&gt;Victory in this environment requires more than technological superiority. It demands clarity of purpose, coherence between means and ends, disciplined execution, and moral restraint—the very fundamentals Clausewitz insisted upon. These are not optional in the urban century. They are decisive.&lt;/p&gt;
    &lt;p&gt;Clausewitz offers no checklist for success in cities, but rather something more valuable. What he offers is a way to think clearly, to adapt amid chaos, and to confront the true nature of war—a contest of wills, shaped by politics, distorted by chance, and fought in the dense, contested, and morally fraught terrain of the modern city.&lt;/p&gt;
    &lt;p&gt;John Spencer is chair of urban warfare studies at the Modern War Institute, codirector of MWI’s Urban Warfare Project, and host of the Urban Warfare Project Podcast. He served twenty-five years as an infantry soldier, which included two combat tours in Iraq. He is the author of the book Connected Soldiers: Life, Leadership, and Social Connections in Modern War and coauthor of Understanding Urban Warfare.&lt;/p&gt;
    &lt;p&gt;The views expressed are those of the author and do not reflect the official position of the United States Military Academy, Department of the Army, or Department of Defense.&lt;/p&gt;
    &lt;p&gt;Image credit: Staff Sgt. Jason Hull, US Army&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mwi.westpoint.edu/a-clausewitzian-lens-on-modern-urban-warfare/"/><published>2025-10-08T11:56:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45515640</id><title>Legal Contracts Built for AI Agents</title><updated>2025-10-08T20:37:23.375555+00:00</updated><content>&lt;doc fingerprint="3d14491969fbea31"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Insights straight to your inbox&lt;/head&gt;
    &lt;p&gt;Join 10,000+ subscribers getting the latest insights on AI monetization.&lt;/p&gt;
    &lt;p&gt;We've partnered with GitLaw to launch something that should have existed from day one: a Master Services Agreement specifically designed for AI agents.&lt;/p&gt;
    &lt;p&gt;Not because we love legal documents (we don’t), but because the contracts most agent companies are using create problems they don't see until something breaks.&lt;/p&gt;
    &lt;p&gt;Most AI agent companies are still using SaaS contracts which makes no sense.&lt;/p&gt;
    &lt;p&gt;Your software isn't just sitting there helping someone fill out a form. It's booking meetings, writing code, making decisions. When something goes wrong, who's liable?&lt;/p&gt;
    &lt;p&gt;Standard contracts don't answer that question. They assume software waits for human instructions. Click button, thing happens, done.&lt;/p&gt;
    &lt;p&gt;But your agent operates differently. It decides which prospects to contact. It writes outreach messages. It follows up based on response patterns. It learns from interactions and adjusts behavior over time.&lt;/p&gt;
    &lt;p&gt;Those are autonomous actions. And when your agent does something unexpected, the gap between what your contract says and what your product does creates legal exposure you can't price for.&lt;/p&gt;
    &lt;p&gt;Your workflow agent doesn't suggest next steps. It executes them. Sends emails. Updates records. Moves data between systems. No human clicking approve at every stage.&lt;/p&gt;
    &lt;p&gt;Traditional software processes tasks one at a time when asked. Agents run 24/7, making hundreds of micro-decisions. Remember the Ford dealership chatbot that hallucinated a free truck offer? That's what happens when autonomous systems operate under contracts written for passive tools.&lt;/p&gt;
    &lt;p&gt;Static software behaves the same way every deployment. Agents learn from context, adjust to patterns, change behavior based on accumulated data. The system you shipped six months ago operates differently today.&lt;/p&gt;
    &lt;p&gt;Your SaaS contract wasn't built for any of this.&lt;/p&gt;
    &lt;p&gt;Working with Nick and the GitLaw team, we identified the contract gaps that create the most exposure for agent companies. The new MSA addresses three critical areas:&lt;/p&gt;
    &lt;p&gt;The contract establishes that your agent functions as a sophisticated tool, not an autonomous employee. When a customer's agent books 500 meetings with the wrong prospect list, the answer to "who approved that?" cannot be "the AI decided."&lt;/p&gt;
    &lt;p&gt;It has to be "the customer deployed the agent with these parameters and maintained oversight responsibility."&lt;/p&gt;
    &lt;p&gt;The MSA includes explicit language in Section 1.2 that protects you from liability for autonomous decisions while clarifying customer responsibility.&lt;/p&gt;
    &lt;p&gt;AI agents hallucinate. They produce confident outputs that turn out wrong. The MSA includes explicit disclaimers that agent outputs require human verification before material business decisions.&lt;/p&gt;
    &lt;p&gt;It also includes damage caps appropriate for unpredictable systems. Typically 12 months of fees with exclusions for indirect losses. Not being difficult. Acknowledging you can't predict every edge case in software that learns and adapts.&lt;/p&gt;
    &lt;p&gt;Section 7 covers liability limitations with AI-specific disclaimers about output accuracy in Section 4.1.&lt;/p&gt;
    &lt;p&gt;This kills more deals than any other contract issue. Your agent ingests customer data and generates outputs. You might want to use those interactions to improve your models.&lt;/p&gt;
    &lt;p&gt;Customers panic when they hear that. They imagine their proprietary data training models that help competitors.&lt;/p&gt;
    &lt;p&gt;The MSA establishes that customers own their data and any agent outputs. Then it provides separate, customizable language about using de-identified, aggregated data for training purposes. With clear opt-out options.&lt;/p&gt;
    &lt;p&gt;Most customers accept training use when it's explained clearly. Trying to slip it in through vague language destroys trust.&lt;/p&gt;
    &lt;p&gt;Section 2.1 covers ownership with customizable training permissions in the cover page variables.&lt;/p&gt;
    &lt;p&gt;At Paid, we solve billing and cost tracking for AI agents. But we kept hearing the same problem before companies even got to pricing.&lt;/p&gt;
    &lt;p&gt;Founders would tell us they couldn't figure out how to charge for agents. Then we'd look at their contracts. They were trying to price outcome-based work using terms written for seat-based software.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Most AI agent companies are still using SaaS contract language which makes no sense. Your software isn't just sitting there helping someone fill out a form. It's booking meetings, writing code, making decisions. When something goes wrong, who's liable? The standard contracts don't answer that. We kept hearing this from founders, so when GitLaw said they were building an agent-specific MSA, we jumped in. Builders need legal frameworks that match what their agents actually do".&lt;/p&gt;&lt;lb/&gt;Manny Medina, Paid CEO&lt;/quote&gt;
    &lt;p&gt;You can't bill for outcomes if your contract only covers usage. You can't price based on value delivered if your liability framework assumes predictable, passive behavior. You can't protect your margins when the legal foundation doesn't match what your product does.&lt;/p&gt;
    &lt;p&gt;The contract shapes everything that comes after. Get it wrong and your entire business model sits on shaky ground.&lt;/p&gt;
    &lt;p&gt;The MSA is open source and free to use. You can access it directly in the GitLaw Community or ask the GitLaw AI Agent to generate a customized version for your specific needs.&lt;/p&gt;
    &lt;p&gt;Because the law around AI agents is evolving rapidly, treat this as a starting point, not a substitute for legal advice. Work with a commercial lawyer to customize it for your situation.&lt;/p&gt;
    &lt;p&gt;The template uses CommonPaper's Software Licensing Agreement and AI Addendum as a foundation, adapted for the unique characteristics of AI agents.&lt;/p&gt;
    &lt;p&gt;Nick and the GitLaw team built this based on patterns from reviewing hundreds of agent contracts. We contributed our research from working with dozens of agent companies on monetization challenges.&lt;/p&gt;
    &lt;p&gt;Together, we're building the infrastructure the agent economy needs. Legal frameworks that match how agents actually work. Billing systems that align pricing with value delivery. Cost tracking that protects margins.&lt;/p&gt;
    &lt;p&gt;Because agents aren't just another SaaS feature. They're a fundamentally different product category that needs different infrastructure.&lt;/p&gt;
    &lt;p&gt;Legal frameworks always lag behind technology. Right now that lag creates real risk for anyone building agents.&lt;/p&gt;
    &lt;p&gt;You can ignore it and hope nothing breaks. Or you can use contracts built for what agents actually do, not what software did ten years ago.&lt;/p&gt;
    &lt;p&gt;Most founders choose hope. The ones who survive choose better infrastructure - and you'll soon find these MSAs baked into Paid's offering too.&lt;/p&gt;
    &lt;p&gt;→ Read the announcement on GitLaw&lt;/p&gt;
    &lt;p&gt;→ Listen to our conversation with Nick about building legal infrastructure for the agent economy.&lt;/p&gt;
    &lt;p&gt;Join 10,000+ subscribers getting the latest insights on AI monetization.&lt;/p&gt;
    &lt;p&gt;Price smarter. Protect margins. Grow revenue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://paid.ai/blog/ai-agents/paid-gitlaw-introducing-legal-contracts-built-for-ai-agents"/><published>2025-10-08T12:55:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45515657</id><title>The email they shouldn't have read</title><updated>2025-10-08T20:37:22.549238+00:00</updated><content>&lt;doc fingerprint="764a911c87a67cf9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author's Note: Before we begin, an important clarification. What follows is a horror story based on real events from my career. However, to protect the privacy of the people and companies involved, I have deliberately mixed things up: technologies, contexts, and specific details have been modified or merged with other experiences. I therefore invite you to read this story not as a strict chronicle of a single event, but as an archetype of a widespread problem in the IT world: vendor lock-in and predatory business practices. Any attempt to identify the specific company or software described would lead to an incorrect conclusion.&lt;/p&gt;
    &lt;p&gt;When the phone rang, I was in a meeting - so I didnât answer. But I recognized the number and sent a quick message:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Iâm with a client right now. If itâs not urgent, please send me an email - otherwise Iâll call you ASAP".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The reply, via SMS, left me speechless:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Thatâs exactly the problem. I canât send you an email. Call me as soon as you can".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;From that moment on, my perception of a certain kind of world changed forever.&lt;/p&gt;
    &lt;p&gt;A few years earlier, a major public institution - letâs call it Agency A - was still running an ancient Exchange mail server. It hadnât received security updates for ages, the anti-spam was completely ineffective, and the new regulations were clear: embrace Open Source solutions whenever possible.&lt;/p&gt;
    &lt;p&gt;They had already received a proposal - expensive but, when compared to similar offers made to other organizations, apparently reasonable - for a managed service hosted by an external provider and based on an open source mail stack. The company offered a managed version with its own proprietary additions and enterprise support.&lt;/p&gt;
    &lt;p&gt;The catch? While such pricing had become almost "normal" in the market, it was still wildly inflated considering what was actually being delivered. Agency A already had solid infrastructure - reputable IP classes, redundant datacenters, everything running smoothly. We had built and maintained that environment for years, and it was still performing perfectly.&lt;/p&gt;
    &lt;p&gt;The request was simple: âEvaluate this solution, and if itâs suitable, weâll migrate.â. About 500 active mailboxes, roughly the same number of aliases. Manageable, but far from trivial.&lt;/p&gt;
    &lt;p&gt;So I started experimenting. I had heard of that stack before but never used it directly. I deployed it in some non-critical environments - ours, and a few test clients who agreed to try it at a discounted rate. Everything worked flawlessly for almost a year. I began to appreciate its design and flexibility. Confident, I told Agency A we could proceed with a pilot migration.&lt;/p&gt;
    &lt;p&gt;We built a new server, deployed the stack, and assigned a few secondary domains for early adopters. The feedback was great - so good that users started pushing for a full migration.&lt;lb/&gt; The IT team planned carefully: created accounts and aliases, migrated selected mailboxes, and kept the old Exchange server online (hidden, for legacy access).&lt;/p&gt;
    &lt;p&gt;The morning after the MX switch I was tense, waiting for trouble - but it never came. A couple of small questions, nothing serious. The internal team handled everything perfectly. It was a success.&lt;/p&gt;
    &lt;p&gt;Word spread quickly.&lt;/p&gt;
    &lt;p&gt;Agency B - smaller, but in some ways more influential - contacted me. They were customers of the same managed-service company that had pitched to Agency A. Once they saw the potential savings (at less than a tenth of the annual cost), the stability, and the freedom of keeping their data on their own servers, they became very interested. Their contract, however, was a five-year deal with automatic renewal - two years left. The legal office said the notice period was six months, so there was time.&lt;/p&gt;
    &lt;p&gt;They wanted to prepare silently. Their supplier was known for aggressive commercial behavior and often retaliated when customers tried to leave. So we built everything quietly - users, aliases, test setups - and froze the system, waiting for the official termination notice.&lt;/p&gt;
    &lt;p&gt;That day finally came. The notice was sent, about eight months before expiration. Migration would begin upon confirmation of receipt - or the following month at the latest.&lt;/p&gt;
    &lt;p&gt;Meanwhile, I learned that Agency C - another institution - was also planning to leave the same provider. They wanted to keep the same software stack for consistency, so I told them about our experience. They asked for a quote, which I prepared (without mentioning Agency B, of course). My margin would have been small, but the project made sense: it was about owning your data, not making money.&lt;/p&gt;
    &lt;p&gt;Everything seemed to move smoothly - until that SMS.&lt;/p&gt;
    &lt;p&gt;I called back immediately.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Thereâs been a problem with the termination" said the IT manager of Agency B.&lt;/p&gt;&lt;lb/&gt;"Somehow they found out what we were doing. There are hidden clauses we didnât know about, and now we canât leave - at least not for another five years. They know everything. Even your quote.".&lt;/quote&gt;
    &lt;p&gt;I was stunned. How could they possibly know?&lt;/p&gt;
    &lt;p&gt;Minutes later, my phone rang again - Agency C this time.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Forget the proposal", they said. "They called us. Threatened us, actually. They even mentioned your name and said they might take legal action against you for unfair competition - claiming theyâre the only âauthorizedâ installers of that software. Which is absurd, of course. Itâs open source. But our director doesnât want trouble.".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sometimes, when public money is involved, people prefer avoiding troubles over doing whatâs right.&lt;/p&gt;
    &lt;p&gt;Something didnât add up.&lt;lb/&gt; Then someone at Agency C noticed a clue: a former interim IT manager still had an email client connected via token authentication - with access to all messages. And that person had signed the original contract with the provider years before. Informally questioned, he admitted contacting them "to warn them" but claimed it was harmless. He never mentioned me - supposedly.&lt;/p&gt;
    &lt;p&gt;That still didnât explain how they knew about Agency Bâs internal steps. To test a theory, we set a trap: I asked a friend abroad to send Agency B a fake quote, from a company outside the EU.&lt;lb/&gt; The following Monday, the provider called Agency B and said, "We advise against working with non-EU companies - compliance can get tricky.".&lt;/p&gt;
    &lt;p&gt;That strongly suggested it: it looked as if they might have been reading the emails.&lt;/p&gt;
    &lt;p&gt;The IT manager exploded and confronted them. The response was chilling:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Iâm not saying we do - but we could. Itâs in the contract. You should read the fine print, especially the unilateral amendment from two years ago.".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That amendment, quietly accepted, included horrifying clauses:&lt;lb/&gt; - notice period extended from 6 to 12 months&lt;lb/&gt; - formerly free services could become paid at the providerâs discretion&lt;lb/&gt; - and, "for security reasons", they could disable any access other than the webmail - which they promptly did.&lt;/p&gt;
    &lt;p&gt;All of this happened before the GDPR era, when certain practices could still slip through.&lt;/p&gt;
    &lt;p&gt;I tried to contact the companyâs owner directly - no reply. Calls, emails, nothing. Their support lines were "not authorized to forward requests". I wanted to confront them about the ânot accreditedâ nonsense and the so-called unfair competition. But bullies never like a fair conversation.&lt;/p&gt;
    &lt;p&gt;I urged Agency B and C to investigate - not only legally, but ethically.&lt;lb/&gt; They were horrified, yes - but in the end, nothing changed.&lt;lb/&gt; Worse: the provider, invoking that same contract amendment, made previously free features paid ones, increasing their costs by another 30%.&lt;lb/&gt; Management wasnât outraged by the abuse - just by the extra expense, "hard to justify in the budget".&lt;/p&gt;
    &lt;p&gt;Years later, those directors were gone. The technical staff remained - older, wiser, and determined not to repeat the mistake. They eventually switched providers, though to something "safer", not necessarily better.&lt;/p&gt;
    &lt;p&gt;I couldnât solve that problem. The battle had to come from them, and I would have supported them all the way - not for profit, but for principle.&lt;lb/&gt; Because when a company that claims to âsupport open sourceâ behaves like that, we all lose.&lt;lb/&gt; We all get labeled the same way.&lt;/p&gt;
    &lt;p&gt;And thatâs the real horror of the story - not the software, but what people do with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://it-notes.dragas.net/2025/10/08/the-email-they-shouldnt-have-read/"/><published>2025-10-08T12:56:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516000</id><title>We found a bug in Go's ARM64 compiler</title><updated>2025-10-08T20:37:22.130086+00:00</updated><content>&lt;doc fingerprint="3b06c011ce263a54"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Every second, 84 million HTTP requests are hitting Cloudflare across our fleet of data centers in 330 cities. It means that even the rarest of bugs can show up frequently. In fact, it was our scale that recently led us to discover a bug in Go's arm64 compiler which causes a race condition in the generated code.&lt;/p&gt;
      &lt;p&gt;This post breaks down how we first encountered the bug, investigated it, and ultimately drove to the root cause.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Investigating a strange panic&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We run a service in our network which configures the kernel to handle traffic for some products like Magic Transit and Magic WAN. Our monitoring watches this closely, and it started to observe very sporadic panics on arm64 machines.&lt;/p&gt;
      &lt;p&gt;We first saw one with a fatal error stating that traceback did not unwind completely. That error suggests that invariants were violated when traversing the stack, likely because of stack corruption. After a brief investigation we decided that it was probably rare stack memory corruption. This was a largely idle control plane service where unplanned restarts have negligible impact, and so we felt that following up was not a priority unless it kept happening.&lt;/p&gt;
      &lt;p&gt;And then it kept happening.Â &lt;/p&gt;
      &lt;p&gt;When we first saw this bug we saw that the fatal errors correlated with recovered panics. These were caused by some old code which used panic/recover as error handling.Â &lt;/p&gt;
      &lt;p&gt;At this point, our theory was:Â &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;All of the fatal panics happen within stack unwinding.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We correlated an increased volume of recovered panics with these fatal panics.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Recovering a panic unwinds goroutine stacks to call deferred functions.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;A related Go issue (#73259) reported an arm64 stack unwinding crash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Letâs stop using panic/recover for error handling and wait out the upstream fix?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;So we did that and watched as fatal panics stopped occurring as the release rolled out. Fatal panics gone, our theoretical mitigation seemed to work, and this was no longer our problem. We subscribed to the upstream issue so we could update when it was resolved and put it out of our minds.&lt;/p&gt;
      &lt;p&gt;But, this turned out to be a much stranger bug than expected. Putting it out of our minds was premature as the same class of fatal panics came back at a much higher rate. A month later, we were seeing up to 30 daily fatal panics with no real discernible cause; while that might account for only one machine a day in less than 10% of our data centers, we found it concerning that we didnât understand the cause. The first thing we checked was the number of recovered panics, to match our previous pattern, but there were none. More interestingly, we could not correlate this increased rate of fatal panics with anything. A release? Infrastructure changes? The position of Mars? &lt;/p&gt;
      &lt;p&gt;At this point we felt like we needed to dive deeper to better understand the root cause. Pattern matching and hoping was clearly insufficient.Â &lt;/p&gt;
      &lt;p&gt;We saw two classes of this bug -- a crash while accessing invalid memory and an explicitly checked fatal error.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 153 gp=0x4000105340 m=324 mp=0x400639ea08 [GC worker (active)]:
/usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7ff97fffe870 sp=0x7ff97fffe860 pc=0x55558d4098fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1508 +0x68 fp=0x7ff97fffe860 sp=0x7ff97fffe810 pc=0x55558d3a9408
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1102
runtime.gcDrainMarkWorkerIdle(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7ff97fffe810 sp=0x7ff97fffe7a0 pc=0x55558d3ad514
runtime.gcDrain(0x400005bc50, 0x7)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7ff97fffe7a0 sp=0x7ff97fffe6f0 pc=0x55558d3ab248
runtime.markroot(0x400005bc50, 0x17e6, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7ff97fffe6f0 sp=0x7ff97fffe6a0 pc=0x55558d3ab578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7ff97fffe6a0 sp=0x7ff97fffe560 pc=0x55558d3acaa0
runtime.scanstack(0x4014494380, 0x400005bc50)
       /usr/local/go/src/runtime/traceback.go:447 +0x2ac fp=0x7ff97fffe560 sp=0x7ff97fffe4d0 pc=0x55558d3eeb7c
runtime.(*unwinder).next(0x7ff97fffe5b0?)
       /usr/local/go/src/runtime/traceback.go:566 +0x110 fp=0x7ff97fffe4d0 sp=0x7ff97fffe490 pc=0x55558d3eed40
runtime.(*unwinder).finishInternal(0x7ff97fffe4f8?)
       /usr/local/go/src/runtime/panic.go:1073 +0x38 fp=0x7ff97fffe490 sp=0x7ff97fffe460 pc=0x55558d403388
runtime.throw({0x55558de6aa27?, 0x7ff97fffe638?})
runtime stack:
fatal error: traceback did not unwind completely
       stack=[0x4015d6a000-0x4015d8a000
runtime: g8221077: frame.sp=0x4015d784c0 top=0x4015d89fd0&lt;/code&gt;
      &lt;/quote&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 187 gp=0x40003aea80 m=13 mp=0x40003ca008 [GC worker (active)]:
       /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7fff2afde870 sp=0x7fff2afde860 pc=0x55557e2d98fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1489 +0x94 fp=0x7fff2afde860 sp=0x7fff2afde810 pc=0x55557e279434
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1112
runtime.gcDrainMarkWorkerDedicated(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7fff2afde810 sp=0x7fff2afde7a0 pc=0x55557e27d514
runtime.gcDrain(0x4000059750, 0x3)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7fff2afde7a0 sp=0x7fff2afde6f0 pc=0x55557e27b248
runtime.markroot(0x4000059750, 0xb8, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7fff2afde6f0 sp=0x7fff2afde6a0 pc=0x55557e27b578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7fff2afde6a0 sp=0x7fff2afde560 pc=0x55557e27caa0
runtime.scanstack(0x40042cc000, 0x4000059750)
       /usr/local/go/src/runtime/traceback.go:458 +0x188 fp=0x7fff2afde560 sp=0x7fff2afde4d0 pc=0x55557e2bea58
runtime.(*unwinder).next(0x7fff2afde5b0)
goroutine 0 gp=0x40003af880 m=13 mp=0x40003ca008 [idle]:
PC=0x55557e2bea58 m=13 sigcode=1 addr=0x118
SIGSEGV: segmentation violation&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Now we could observe some clear patterns. Both errors occur when unwinding the stack in &lt;code&gt;(*unwinder).next&lt;/code&gt;. In one case we saw an intentional fatal error as the runtime identified that unwinding could not complete and the stack was in a bad state. In the other case there was a direct memory access error that happened while trying to unwind the stack. The segfault was discussed in the GitHub issue and a Go engineer identified it as dereference of a go scheduler struct, m, when unwinding.Â   &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;A review of Go scheduler structs&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Go uses a lightweight userspace scheduler to manage concurrency. Many goroutines are scheduled on a smaller number of kernel threads â this is often referred to as M:N scheduling. Any individual goroutine can be scheduled on any kernel thread. The scheduler has three core types â &lt;code&gt;g&lt;/code&gt;Â  (the goroutine), &lt;code&gt;m&lt;/code&gt; (the kernel thread, or âmachineâ), and &lt;code&gt;p&lt;/code&gt; (the physical execution context, orÂ  âprocessorâ). For a goroutine to be scheduled a free &lt;code&gt;m&lt;/code&gt; must acquire a free &lt;code&gt;p&lt;/code&gt;, which will execute a g. Each &lt;code&gt;g&lt;/code&gt; contains a field for its m if it is currently running, otherwise it will be nil. This is all the context needed for this post but the go runtime docs explore this more comprehensively.Â &lt;/p&gt;
      &lt;p&gt;At this point we can start to make inferences on whatâs happening: the program crashes because we try to unwind a goroutine stack which is invalid. In the first backtrace, if a return address is null, we call &lt;code&gt;finishInternal&lt;/code&gt; and abort because the stack was not fully unwound. The segmentation fault case in the second backtrace is a bit more interesting: if instead the return address is non-zero but not a function then the unwinder code assumes that the goroutine is currently running. It'll then dereference m and fault by accessing &lt;code&gt;m.incgo&lt;/code&gt; (the offset of &lt;code&gt;incgo&lt;/code&gt; into &lt;code&gt;struct m&lt;/code&gt; is 0x118, the faulting memory access). &lt;/p&gt;
      &lt;p&gt;What, then, is causing this corruption? The traces were difficult to get anything useful from â our service has hundreds if not thousands of active goroutines. It was fairly clear from the beginning that the panic was remote from the actual bug. The crashes were all observed while unwinding the stack and if this were an issue any time the stack was unwound on arm64 we would be seeing it in many more services. We felt pretty confident that the stack unwinding was happening correctly but on an invalid stack.Â &lt;/p&gt;
      &lt;p&gt;Our investigation stalled for a while at this point â making guesses, testing guesses, trying to infer if the panic rate went up or down, or if nothing changed. There was a known issue on Goâs GitHub issue tracker which matched our symptoms almost exactly, but what they discussed was mostly what we already knew. At some point when looking through the linked stack traces we realized that their crash referenced an old version of a library that we were also using â Go Netlink.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 1267 gp=0x4002a8ea80 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /usr/local/go/src/runtime/preempt.go:308 +0x3c fp=0x4004cec4c0 sp=0x4004cec4a0 pc=0x46353c
runtime.asyncPreempt()
        /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x4004cec6b0 sp=0x4004cec4c0 pc=0x4a6a8c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0x14360300000000?)
        /go/pkg/mod/github.com/!data!dog/[email protected]/nl/nl_linux.go:803 +0x130 fp=0x4004cfc710 sp=0x4004cec6c0 pc=0xf95de0
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;We spot-checked a few stack traces and confirmed the presence of this Netlink library. Querying our logs showed that not only did we share a library â every single segmentation fault we observed had happened while preempting &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt;.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Whatâs (async) preemption?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;In the prehistoric era of Go (&amp;lt;=1.13) the runtime was cooperatively scheduled. A goroutine would run until it decided it was ready to yield to the scheduler â usually due to explicit calls to &lt;code&gt;runtime.Gosched()&lt;/code&gt; or injected yield points at function calls/IO operations. Since Go 1.14 the runtime instead does async preemption. The Go runtime has a thread &lt;code&gt;sysmon&lt;/code&gt; which tracks the runtime of goroutines and will preempt any that run for longer than 10ms (at time of writing). It does this by sending &lt;code&gt;SIGURG&lt;/code&gt; to the OS thread and in the signal handler will modify the program counter and stack to mimic a call to &lt;code&gt;asyncPreempt&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;At this point we had two broad theories:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go Netlink bug â likely due to &lt;code&gt;unsafe.Pointer&lt;/code&gt; usage which invoked undefined behavior but is only actually broken on arm64&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go runtime bug and we're only triggering it in &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt; for some reason&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;After finding the same bug publicly reported upstream, we were feeling confident this was caused by a Go runtime bug. However, upon seeing that both issues implicated the same function, we felt more skeptical â notably the Go Netlink library uses unsafe.Pointer so memory corruption was a plausible explanation even if we didn't understand why.&lt;/p&gt;
      &lt;p&gt;After an unsuccessful code audit we had hit a wall. The crashes were rare and remote from the root cause. Maybe these crashes were caused by a runtime bug, maybe they were caused by a Go Netlink bug. It seemed clear that there was something wrong with this area of the code, but code auditing wasnât going anywhere. &lt;/p&gt;
      &lt;p&gt;At this point we had a fairly good understanding of what was crashing but very little understanding of why it was happening. It was clear that the root cause of the stack unwinder crashing was remote from the actual crash, and that it had to do with &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;, but why? We were able to capture a coredump of a production crash and view it in a debugger. The backtrace confirmed what we already knew â that there was a segmentation fault when unwinding a stack. The crux of the issue revealed itself when we looked at the goroutine which had been preempted while calling &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;.Â     &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;(dlv) bt
0  0x0000555577579dec in runtime.asyncPreempt2
   at /usr/local/go/src/runtime/preempt.go:306
1  0x00005555775bc94c in runtime.asyncPreempt
   at /usr/local/go/src/runtime/preempt_arm64.s:47
2  0x0000555577cb2880 in github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive
   at
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779
3  0x0000555577cb19a8 in github.com/vishvananda/netlink/nl.(*NetlinkRequest).Execute
   at 
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:532
4  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
5  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
...
(dlv) disass -a 0x555577cb2878 0x555577cb2888
TEXT github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(SB) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go
        nl_linux.go:779 0x555577cb2878  fdfb7fa9        LDP -8(RSP), (R29, R30)
        nl_linux.go:779 0x555577cb287c  ff430191        ADD $80, RSP, RSP
        nl_linux.go:779 0x555577cb2880  ff434091        ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
        nl_linux.go:779 0x555577cb2884  c0035fd6        RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The goroutine was paused between two opcodes in the function epilogue. Since the process of unwinding a stack relies on the stack frame being in a consistent state, it felt immediately suspicious that we preempted in the middle of adjusting the stack pointer. The goroutine had been paused at 0x555577cb2880, between&lt;code&gt; ADD $80, RSP, RSP and ADD $(16&amp;lt;&amp;lt;12), RSP, RSP&lt;/code&gt;.Â &lt;/p&gt;
      &lt;p&gt;We queried the service logs to confirm our theory. This wasnât isolated â the majority of stack traces showed that this same opcode was preempted. This was no longer a weird production crash we couldnât reproduce. A crash happened when the Go runtime preempted between these two stack pointer adjustments. We had our smoking gun.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Building a minimal reproducer&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;At this point we felt pretty confident that this was actually just a runtime bug and it should be reproducible in an isolated environment without any dependencies. The theory at this point was:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Stack unwinding is triggered by garbage collection&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption between a split stack pointer adjustment causes a crash&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;What if we make a function which splits the adjustment and then call it in a loop?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;quote&gt;
        &lt;code&gt;package main

import (
	"runtime"
)

//go:noinline
func big_stack(val int) int {
	var big_buffer = make([]byte, 1 &amp;lt;&amp;lt; 16)

	sum := 0
	// prevent the compiler from optimizing out the stack
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		big_buffer[i] = byte(val)
	}
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		sum ^= int(big_buffer[i])
	}
	return sum
}

func main() {
	go func() {
		for {
			runtime.GC()
		}
	}()
	for {
		_ = big_stack(1000)
	}
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This function ends up with a stack frame slightly larger than can be represented in 16 bits, and so on arm64 the Go compiler will split the stack pointer adjustment into two opcodes. If the runtime preempts between these opcodes then the stack unwinder will read an invalid stack pointer and crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; epilogue for main.big_stack
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
; preemption is problematic between these opcodes
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;After running this for a few minutes the program panicked as expected!&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;SIGSEGV: segmentation violation
PC=0x60598 m=8 sigcode=1 addr=0x118

goroutine 0 gp=0x400019c540 m=8 mp=0x4000198708 [idle]:
runtime.(*unwinder).next(0x400030fd10)
        /home/thea/sdk/go1.23.4/src/runtime/traceback.go:458 +0x188 fp=0x400030fcc0 sp=0x400030fc30 pc=0x60598
runtime.scanstack(0x40000021c0, 0x400002f750)
        /home/thea/sdk/go1.23.4/src/runtime/mgcmark.go:887 +0x290 

[...]

goroutine 1 gp=0x40000021c0 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /home/thea/sdk/go1.23.4/src/runtime/preempt.go:308 +0x3c fp=0x40003bfcf0 sp=0x40003bfcd0 pc=0x400cc
runtime.asyncPreempt()
        /home/thea/sdk/go1.23.4/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40003bfee0 sp=0x40003bfcf0 pc=0x75aec
main.big_stack(0x40003cff38?)
        /home/thea/dev/stack_corruption_reproducer/main.go:29 +0x94 fp=0x40003cff00 sp=0x40003bfef0 pc=0x77c04
Segmentation fault (core dumped)

real    1m29.165s
user    4m4.987s
sys     0m43.212s&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;A reproducible crash with standard library only? This felt like conclusive evidence that our problem was a runtime bug.&lt;/p&gt;
      &lt;p&gt;This was an extremely particular reproducer! Even now with a good understanding of the bug and its fix, some of the behavior is still puzzling. It's a one-instruction race condition, so itâs unsurprising that small changes could have large impact. For example, this reproducer was originally written and tested on Go 1.23.4, but did not crash when compiled with 1.23.9 (the version in production), even though we could objdump the binary and see the split ADD still present! We donât have a definite explanation for this behavior â even with the bug present there remain a few unknown variables which affect the likelihood of hitting the race condition.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;A single-instruction race condition window&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;arm64 is a fixed-length 4-byte instruction set architecture. This has a lot of implications on codegen but most relevant to this bug is the fact that immediate length is limited. &lt;code&gt;add&lt;/code&gt; gets a 12-bit immediate, &lt;code&gt;mov&lt;/code&gt; gets a 16-bit immediate, etc. How does the architecture handle this when the operands don't fit? It depends â &lt;code&gt;ADD&lt;/code&gt; in particular reserves a bit for "shift left by 12" so any 24 bit addition can be decomposed into two opcodes. Other instructions are decomposed similarly, or just require loading an immediate into a register first.Â &lt;/p&gt;
      &lt;p&gt;The very last step of the Go compiler before emitting machine code involves transforming the program into &lt;code&gt;obj.Prog&lt;/code&gt; structs. It's a very low level intermediate representation (IR) that mostly serves to be translated into machine code.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/fa2bb342d7b0024440d996c2d6d6778b7a5e0247/src/cmd/internal/obj/arm64/obj7.go#L856

// Pop stack frame.
// ADD $framesize, RSP, RSP
p = obj.Appendp(p, c.newprog)
p.As = AADD
p.From.Type = obj.TYPE_CONST
p.From.Offset = int64(c.autosize)
p.To.Type = obj.TYPE_REG
p.To.Reg = REGSP
p.Spadj = -c.autosize
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Notably, this IR is not aware of immediate length limitations. Instead, this happens in asm7.go when Go's internal intermediate representation is translated into arm64 machine code. The assembler will classify an immediate in conclass based on bit size and then use that when emitting instructions â extra if needed.&lt;/p&gt;
      &lt;p&gt;The Go assembler uses a combination of (&lt;code&gt;mov, add&lt;/code&gt;) opcodes for some adds that fit in 16-bit immediates, and prefers (&lt;code&gt;add, add + lsl 12&lt;/code&gt;) opcodes for 16-bit+ immediates.Â   &lt;/p&gt;
      &lt;p&gt;Compare a stack of (slightly larger than) &lt;code&gt;1&amp;lt;&amp;lt;15&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;15)
; 	return big_stack[0]
; }
MOVD $32776, R27
ADD R27, RSP, R29
MOVD $32784, R27
ADD R27, RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;With a stack of &lt;code&gt;1&amp;lt;&amp;lt;16&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;16)
; 	return big_stack[0]
; } 
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the larger stack case, there is a point between &lt;code&gt;ADD x, RSP, RSP&lt;/code&gt; opcodes where the stack pointer is not pointing to the tip of a stack frame. We thought at first that this was a matter of memory corruption â that in handling async preemption the runtime would push a function call on the stack and corrupt the middle of the stack. However, this goroutine is already in the function epilogue â any data we corrupt is actively in the process of being thrown away. What's the issue then?  &lt;/p&gt;
      &lt;p&gt;The Go runtime often needs to unwind the stack, which means walking backwards through the chain of function calls. For example: garbage collection uses it to find live references on the stack, panicking relies on it to evaluate &lt;code&gt;defer&lt;/code&gt; functions, and generating stack traces needs to print the call stack. For this to work the stack pointer must be accurate during unwinding because of how golang dereferences sp to determine the calling function. If the stack pointer is partially modified, the unwinder will look for the calling function in the middle of the stack. The underlying data is meaningless when interpreted as directions to a parent stack frame and then the runtime will likely crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/66536242fce34787230c42078a7bbd373ef8dcb0/src/runtime/traceback.go#L373

if innermost &amp;amp;&amp;amp; frame.sp &amp;lt; frame.fp || frame.lr == 0 {
    lrPtr = frame.sp
    frame.lr = *(*uintptr)(unsafe.Pointer(lrPtr))
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When async preemption happens it will push a function call onto the stack but the parent stack frame is no longer correct because sp was only partially adjusted when the preemption happened. The crash flow looks something like this: &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption happens between the two opcodes that &lt;code&gt;add x, rsp&lt;/code&gt; expands to&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Garbage collection triggers stack unwinding (to check for heap object liveness)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder starts traversing the stack of the problematic goroutine and correctly unwinds up to the problematic function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder dereferences &lt;code&gt;sp&lt;/code&gt; to determine the parent function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Almost certainly the data behind &lt;code&gt;sp&lt;/code&gt; is not a function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Crash&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;We saw earlier a faulting stack trace which ended in &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt; â in this case stack unwinding faulted while it was trying to determine the parent frame.Â    &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 90 gp=0x40042cc000 m=nil [preempted (scan)]:
runtime.asyncPreempt2()
/usr/local/go/src/runtime/preempt.go:306 +0x2c fp=0x40060a25d0 sp=0x40060a25b0 pc=0x55557e299dec
runtime.asyncPreempt()
/usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40060a27c0 sp=0x40060a25d0 pc=0x55557e2dc94c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0xff48ce6e060b2848?)
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 +0x130 fp=0x40060b2820 sp=0x40060a27d0 pc=0x55557e9d2880
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Once we discovered the root cause we reported it with a reproducer and the bug was quickly fixed. This bug is fixed in go1.23.12, go1.24.6, and go1.25.0. Previously, the go compiler emitted a single &lt;code&gt;add x, rsp&lt;/code&gt; instruction and relied on the assembler to split immediates into multiple opcodes as necessary. After this change, stacks larger than 1&amp;lt;&amp;lt;12 will build the offset in a temporary register and then add that to &lt;code&gt;rsp&lt;/code&gt; in a single, indivisible opcode. A goroutine can be preempted before or after the stack pointer modification, but never during. This means that the stack pointer is always valid and there is no race condition.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;LDP -8(RSP), (R29, R30)
MOVD $32, R27
MOVK $(1&amp;lt;&amp;lt;16), R27
ADD R27, RSP, RSP
RET&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This was a very fun problem to debug. We donât often see bugs where you can accurately blame the compiler. Debugging it took weeks and we had to learn about areas of the Go runtime that people donât usually need to think about. Itâs a nice example of a rare race condition, the sort of bug that can only really be quantified at a large scale.&lt;/p&gt;
      &lt;p&gt;Weâre always looking for people who enjoy this kind of detective work. Our engineering teams are hiring. &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/"/><published>2025-10-08T13:33:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516426</id><title>Now open for building: Introducing Gemini CLI extensions</title><updated>2025-10-08T20:37:21.931837+00:00</updated><content>&lt;doc fingerprint="994b9cc09a2ba6b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Now open for building: Introducing Gemini CLI extensions&lt;/head&gt;
    &lt;p&gt;The best tools are the ones that adapt to you, not the other way around. For developers whose work is becoming more complex every day, the need for personalized, intelligent assistance has never been greater.&lt;/p&gt;
    &lt;p&gt;That’s why we’re announcing Gemini CLI extensions, a new framework that allows you to customize Gemini CLI and connect it to the tools you use most, all from the command line. Instead of context-switching between your terminal and other tools, you can now bring those tools directly into your workflow.&lt;/p&gt;
    &lt;p&gt;In just three months since our launch, more than one million developers are building with Gemini CLI. And they can now access a new ecosystem of extensions from Google, plus industry leaders like Dynatrace, Elastic, Figma, Harness, Postman, Shopify, Snyk and Stripe, and the broader open-source community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Personalize your command line with Gemini CLI extensions&lt;/head&gt;
    &lt;p&gt;Gemini CLI is an open-source, AI-powered agent for your terminal, and extensions are its power-ups — pre-packaged, easily installable integrations that connect it to external tools including everything from databases and design platforms to payment services.&lt;/p&gt;
    &lt;p&gt;Each extension contains a built-in “playbook” that instantly teaches the AI how to use the new tools effectively. This means you get meaningful results from the very first command, no complex setup required, allowing you to tailor your experience with the tools most valuable to you.&lt;/p&gt;
    &lt;p&gt;It’s easy to install an extension — simply type: “gemini extensions install &amp;lt;add your GitHub URL or local path&amp;gt;” from your command line.&lt;/p&gt;
    &lt;p&gt;Easily install extensions from Gemini CLI's open ecosystem&lt;/p&gt;
    &lt;head rend="h2"&gt;Access an open, growing ecosystem of partners and builders&lt;/head&gt;
    &lt;p&gt;Extensions put Gemini CLI at the center of an open ecosystem in which anyone can build integrations. That’s why in addition to our own set of Google-created extensions, we’re launching with a strong group of partners and open-source contributors.&lt;/p&gt;
    &lt;p&gt;To make extensions easy to find and use, we’re also launching a new Gemini CLI Extensions page. Here, you can discover a growing catalog of community, partner and Google-built extensions, ranked by popularity by GitHub stars.&lt;/p&gt;
    &lt;p&gt;You can get started with extensions from a wide range of launch partners and more coming soon. These include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynatrace: Get real-time insights into application performance, availability and root-cause analysis directly from your CLI to accelerate debugging.&lt;/item&gt;
      &lt;item&gt;Elastic: Search, retrieve and analyze Elasticsearch data in developer and agentic workflows. Connects directly to an Elastic MCP server hosted in Elastic Cloud Serverless.&lt;/item&gt;
      &lt;item&gt;Figma: Generate code from frames, extract design context, retrieve resources and ensure design system consistency with your codebase.&lt;/item&gt;
      &lt;item&gt;Harness: Bring AI-powered intelligence to CI/CD by analyzing pipeline execution data, surfacing cost insights, detecting failure patterns and automatically remediating issues to accelerate software delivery.&lt;/item&gt;
      &lt;item&gt;Postman: Have AI agents access Postman workspaces, manage collections and environments, evaluate APIs and automate workflows through natural language interactions.&lt;/item&gt;
      &lt;item&gt;Shopify: Connect to Shopify's developer ecosystem with tools to search docs, explore API schemas, and build serverless Shopify functions.&lt;/item&gt;
      &lt;item&gt;Snyk: Seamlessly integrate Snyk's comprehensive security capabilities into your development process to ensure that code is secure at inception.&lt;/item&gt;
      &lt;item&gt;Stripe: Define a set of tools that AI agents can use to interact with the Stripe API and search the knowledge base.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;More than a connection: See how extensions add intelligence&lt;/head&gt;
    &lt;p&gt;Developers get more from Gemini CLI by integrating Model Context Protocol (MCP) tools, and extensions build on this by enabling even smarter interactions. While MCP provides the raw connection to a tool, a Gemini CLI extension takes the basic ability to use that tool and wraps it in a layer of intelligence and personalization. This makes the experience seamless for developers.&lt;/p&gt;
    &lt;p&gt;Gemini CLI extensions are easy to install and have a simple “playbook” — a set of tools it knows how to use, like a local script or a third-party API. When you run a command, Gemini CLI consults this playbook and uses the context from your environment (like your local files and git status) to execute the right tool for the job, exactly how you intended.&lt;/p&gt;
    &lt;p&gt;If you want to look under the hood, Gemini CLI extensions package instructions, MCP servers and custom commands into a familiar and user-friendly format. Extensions can bundle any combination of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One or more MCP servers: To connect with external tools and services.&lt;/item&gt;
      &lt;item&gt;Context files: Like GEMINI.md or bring your own context file type(s), to provide specific instructions and guidelines to the model.&lt;/item&gt;
      &lt;item&gt;Excluded tools: Useful for disabling built-in tools or offering alternative implementations.&lt;/item&gt;
      &lt;item&gt;Custom commands: To encapsulate complex prompts into simple slash commands.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Gemini CLI to access all kinds of extensions, including one for image generation with Nano Banana&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover Google-created extensions&lt;/head&gt;
    &lt;p&gt;Googlers have also been building a suite of extensions for Gemini CLI. Give them a try; they just might help you solve some common developer pain points, deepen integration with other Google offerings or just have fun:&lt;/p&gt;
    &lt;p&gt;For cloud-native deployments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go from local code to a live public URL in a single step, with the Cloud Run extension.&lt;/item&gt;
      &lt;item&gt;Manage your Google Kubernetes Engine (GKE) clusters, from checking node health to deploying applications with our GKE extension.&lt;/item&gt;
      &lt;item&gt;Give Gemini CLI the ability to easily interact with your Google Cloud environment by using the gcloud extension.&lt;/item&gt;
      &lt;item&gt;Understand, manage and troubleshoot your Google Cloud environment with the Google Cloud Observability extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For app builders:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Perform code reviews on your codebase with the Code Review extension.&lt;/item&gt;
      &lt;item&gt;Perform AI-powered vulnerability detection on your code changes with the Security extension.&lt;/item&gt;
      &lt;item&gt;Retrieve place info from Google and embed Google Maps imagery into applications with the Google Maps Platform extension.&lt;/item&gt;
      &lt;item&gt;Create, build, refactor, debug and maintain Flutter applications with the Flutter extension.&lt;/item&gt;
      &lt;item&gt;Control and inspect a live Chrome browser for reliable automation, in-depth debugging and performance analysis with the Chrome DevTools extension.&lt;/item&gt;
      &lt;item&gt;Set up and manage your Firebase backend with the Firebase extension.&lt;/item&gt;
      &lt;item&gt;Enhance the user experience for building GenAI-powered apps with the Genkit extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For generative AI and data interaction:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For a bit of fun, generate and edit images with the Nano Banana extension 🍌.&lt;/item&gt;
      &lt;item&gt;Explore and visualize your business data with the Looker extension.&lt;/item&gt;
      &lt;item&gt;Build applications and analyze trends with services like Cloud SQL, AlloyDB BigQuery and more with our Data Cloud extensions.&lt;/item&gt;
      &lt;item&gt;Connect to enterprise data easily and securely using the MCP Toolbox for Databases extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Build the CLI of your dreams&lt;/head&gt;
    &lt;p&gt;Gemini CLI extensions put you in control. You can combine extensions, chain commands and build a personalized toolchain that perfectly fits the way you work.&lt;/p&gt;
    &lt;p&gt;Whether you want to streamline a personal workflow or integrate a company's internal tools, you now have the power to create the command-line experience you've always wanted.&lt;/p&gt;
    &lt;p&gt;Ready to get started? Visit the new Gemini CLI Extensions page to explore community tools, and check out our templates and a step-by-step guide to help you build your first extension and share it with the community.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/developers/gemini-cli-extensions/"/><published>2025-10-08T14:13:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516584</id><title>Show HN: Recall: Give Claude memory with Redis-backed persistent context</title><updated>2025-10-08T20:37:21.832687+00:00</updated><content/><link href="https://www.npmjs.com/package/@joseairosa/recall"/><published>2025-10-08T14:28:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516968</id><title>After 2 decades of tinkering, MAME cracks the Hyper Neo Geo 64</title><updated>2025-10-08T20:37:21.456680+00:00</updated><content>&lt;doc fingerprint="372e9953cb024b11"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;After 2 decades of tinkering, MAME finally cracks the Hyper Neo Geo 64&lt;/head&gt;
    &lt;p&gt;How MAME devs finally got sound working for the 3D arcade system. Plus: PC Engine LaserActive support gets fast-tracked.&lt;/p&gt;
    &lt;p&gt;Let me test out a theory here: If you're into emulation, you're into older video games, ergo you're into old stuff of all kinds. That means you, savvy, good-taste-having reader, will love this spread of photos I took in Tokyo last week at the National Film Archive of Japan, which has a small but lovely set of exhibits from the history of Japanese film. Since you like playing Super Nintendo games this is absolutely your shit, right? Right??&lt;/p&gt;
    &lt;p&gt;Okay, I'll throw in a pic of some games to sweeten the deal.&lt;/p&gt;
    &lt;p&gt;This issue is coming a week late as I was off to Japan last week for my first-ever visit to the Tokyo Game Show, and too busy working (and working at eating sushi) to squeeze in a newsletter. And it's coming late in the day Sunday — apologies! But patience pays off!!&lt;/p&gt;
    &lt;p&gt;This issue's main story has been cookin' for a minute: last month the news landed that MAME had finally properly cracked Hyper Neo Geo 64 support, but the celebration was a little bit premature. The arcade system was playable in MAME, yes, but sound was in really shoddy shape — it wasn't yet a particularly good experience.&lt;/p&gt;
    &lt;p&gt;Over the last month or so that's been changing, and changing fast, with frequent improvements checked in by a pair of regular MAME contributors. So now is the time to talk about it, and soon (with the very next MAME release!) it will be time to actually play it. Considering there are only seven Hyper Neo Geo 64 games, well, that's a week's worth of evenings sorted.&lt;/p&gt;
    &lt;p&gt;As with every trip to Tokyo I took a few hours to stop by Akihabara this time, but its pull has certainly lessened over the years as retro prices have skyrocketed from where they were a decade ago and the selection has gotten thinner and thinner. Still, browsing the stores is a fun time and there are great finds to be found as long as you're not looking for anything too in-demand. I picked up one game: Kamiwaza, a PS2 "stealth" game where you play as a thief in feudal Japan stealing hella stuff.&lt;/p&gt;
    &lt;p&gt;As you might guess, it's more silly than stealthy.&lt;/p&gt;
    &lt;p&gt;Shout out to my shopping partner in crime, Paradise Killer's Oli Clarke Smith, for the recommendation. I've got a feature on the way in the coming weeks over at PC Gamer based on some of the games we picked up and how they speak to the "identity" of particular retro consoles. I'm hoping it'll be a fun read!&lt;/p&gt;
    &lt;p&gt;For now, let's hop into MAME; then stick around for an update on Pioneer LaserActive emulation!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Two&lt;/head&gt;
    &lt;head rend="h3"&gt;1. The Hyper Neo Geo comes to MAME: Now with working sound!&lt;/head&gt;
    &lt;p&gt;21 years ago, David "MameHaze" Haywood started looking into what it would take to add support for the Hyper Neo Geo 64 arcade system — then just five years past the end of its short lifespan — to MAME. "When I started looking at the system back in 2004 MAME didn't really do much 3D stuff at all, even things like the MIPS (main CPU) core were in a much rougher shape, there were no dumps of the I/O MCU at all (happened only a few years ago) and the PC I had at the time barely had enough memory to load and decode even the 2D graphics," he says.&lt;/p&gt;
    &lt;p&gt;"It was also pre-YouTube, and even in the early days of YouTube you didn't really get much in the way of good reference material. Kinda crazy to think that a lot of people who are probably interested in the emulation of the platform now as younger adults weren't even born when emulation work first started on it!"&lt;/p&gt;
    &lt;p&gt;A few weeks ago, two decades after he started looking into the system, Haywood finally promoted it to "working" status in MAME. But that move was a bit of a formality, or a bit sneaky, depending on how you look at it. Though the promotion got some buzz, it wasn't truly finished: proper sound emulation was still missing. Haywood actually hadn't worked on the core since 2023, and decided, well, people had been playing the games for long enough without sound, he might as well slap the "working" label on. It turned out to be the final push other MAME contributors needed to take a crack at tuning up the sound.&lt;/p&gt;
    &lt;p&gt;What's the Hyper Neo Geo's whole deal, anyway? Well, it makes some sense that the system would be more a curiosity for younger folks to discover than an object of intense nostalgia like some of MAME's more high-profile cores or the original Neo Geo; it was only active in arcades for two years from 1997 to 1999 during the awkward transitional period to 3D, with just seven games released for it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Road's Edge&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64&lt;/item&gt;
      &lt;item&gt;Xtreme Rally&lt;/item&gt;
      &lt;item&gt;Beat Busters: Second Nightmare&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64: Warriors Rage&lt;/item&gt;
      &lt;item&gt;Fatal Fury: Wild Ambition&lt;/item&gt;
      &lt;item&gt;Buriki One&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's a nice write-up of the system from Nicole Express that delves into the hardware:&lt;/p&gt;
    &lt;p&gt;None of these games have the Bloodborne-style pull to individually inspire interest in emulation, but the MAME team's all-consuming drive to reverse-engineer and archive every arcade system in existence kept it on the radar. Haywood's initial investigation into it predated even MAME's high profile support of Capcom's CPS3 boards, for instance, but once that platform was decrypted support was added quite quickly because hell yeah people wanted to play Street Fighter III. By comparison, "Hyper64 has been a 21 year on-and-off slog," he says.&lt;/p&gt;
    &lt;p&gt;It's a perfect representation one of the eternal frustrations of emulation development: People often ask why no one's working on something when they actually are. Just invisibly.&lt;/p&gt;
    &lt;quote&gt;"The sheer number of times I picked up the Hyper64 driver and pumped weeks of work in it only to not be able to make any progress at all was frustrating at the best of times. Just trying to gain an understanding of it all, but ending up not making any headway at all. That's something I don't think people really appreciate when it comes to emulation, the amount of time that you have to put in which often yields no positive results at all, where all you can really conclude is it doesn't work the way you were hoping it would work."&lt;/quote&gt;
    &lt;p&gt;A few years ago, Haywood finally made substantial progress: Someone dumped the I/O microcontroller, and he was able to write a CPU core to emulate it. "The inputs finally started working in a bunch of the games, which allowed me to explore them further and make video improvements," he said.&lt;/p&gt;
    &lt;p&gt;"Other components improving in MAME over the years has really helped too. When I started MAME didn't have a CPU core for the V53 either (which is a V33 CPU with variolus peripherals) and is the CPU driving the sound DSP. At some point in MAME's history the V53 support got fleshed out (for other systems) which has really come in handy now, as proper sound emulation requires that to be running properly."&lt;/p&gt;
    &lt;p&gt;When Haywood marked the platform as working, it caught the attention of another longtime MAME contributor: R. Belmont. For the last month or so, Belmont, as well as two other devs, Happy and O. Galibert, have been chipping away at making the games sound like they're supposed to.&lt;/p&gt;
    &lt;p&gt;"Haze marking them working did provide a push, and Happy had done a detailed disassembly of the sound CPU program which was quite useful," Belmont recently posted on Reddit. Belmont and Galibert have both been working on synthesizer support in MAME, and the Hyper Neo Geo 64's sound chip happens to be used it one, providing them with some convenient overlap in interest/speciality.&lt;/p&gt;
    &lt;p&gt;The current MAME release, 0.281, includes a series of rapid-fire improvements as documented by Belmont in a few videos on YouTube:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Very early work in progress on better audio for the Hyper Neo Geo 64 system. There is a loooong way to go, this is just some very basic fixes so far."&lt;/item&gt;
      &lt;item&gt;"Since the first video we've got the basic sample starts and stops working the actual correct way they're supposed to and added a preliminary support for volume envelopes, which also helps the audio balance. Still a lot of work to go though."&lt;/item&gt;
      &lt;item&gt;"More progress today! I figured out how the volume envelopes really work, and that made Buriki One's intro mostly awesome."&lt;/item&gt;
      &lt;item&gt;"Barring any last minute adjustments, this is what HNG64 audio will sound like in MAME 0.281. Since the last video, the per-voice low pass filter was added, which cleans up some of the high frequency 'hash' audible previously and makes the sound a bit cleaner."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It was a ton of progress for a month, taking Hyper Neo Geo 64 sound support from messy and inaccurate to, at least, broadly playable without assaulting your ears. But the real refinements have been coming in just the last few days since 0.281's release in late September.&lt;/p&gt;
    &lt;p&gt;But the next build is gonna be the big one. October's upcoming MAME 0.282 release will notably fix up the audio issues in one of the the trickiest games, Xtreme Rally, while really polishing up the rest. Here's what Belmont's noted in update notes for 0.282 so far:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Olivier Galibert figured out how they squeezed 12 bits of dynamic range into 8 bits (presumably this is the format from Roger Linn's original MPC60 design) and replaced the biquad low-pass filter with a more likely Chamberlin one that fits the parameters better. Also there were some improvements to the filter envelope. All this results in much clearer and higher-fidelity sound."&lt;/item&gt;
      &lt;item&gt;"This time we've figured out how looping samples actually work, fixed the final mixdown to not introduce any distortion, and fixed the filter envelope. The result? A dramatic improvement to Beast Busters Second Nightmare's intro."&lt;/item&gt;
      &lt;item&gt;"So the previous fixes seem to have solved Samurai Shodown 64 and SS64 2, but Xtreme Rally (aka Off Beat Racer) was still extremely broken. The engine sound barely worked, sounds were missing, and some sounds would stick looping forever. This time the problem wasn't actually in the sound emulation itself; Xtreme Rally has unique code among the 7 HNG64 games that tries to push sound commands to the sound CPU as quickly as possible. This resulted in as many as 2/3rds of the commands getting dropped on the floor. I have fixed that issue so that all of the commands make it, and Xtreme Rally now sounds great."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since Belmont made that post he dialed in a few more improvements where the wrong sounds were playing in certain instances in the game. Here's a video from Haywood showing off the vastly improved audio (though he notes "some graphical issues, such as the fog in the tunnel still need addressing eventually.")&lt;/p&gt;
    &lt;p&gt;Once MAME 0.282 releases, the Hyper Neo Geo 64 will well and truly be worthy of the "working" label. Turns out it just needed that last little push.&lt;/p&gt;
    &lt;p&gt;In a perfect encapsulation of how these sorts of collaborative projects come together, Galibert noted on Reddit that despite their contributions to the core stemming from an interest in emulating synthesizers, "amusingly, the synth itself (MPC3000) is not working at all yet." Some parts of the synthesizer remain undumped and undocumented, just as parts of the Hyper Neo Geo once were; sometimes while you're waiting for all the pieces to fall into place, it turns out one of the pieces you do have happens to fit into another puzzle entirely.&lt;/p&gt;
    &lt;p&gt;"It's just been a long slow process," Haywood said. "Things have inched forward a little bit over the years, and the surrounding code in MAME has become better / more capable, allowing for more progress to be made, step by step."&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Can't stop Pioneering: NEC support and big LaserActive performance improvements arrive in the latest Ares nightlies&lt;/head&gt;
    &lt;p&gt;Often I end a big story, like the August issue's deep dive into the 16 years it took to emulate the Pioneer LaserActive, with the door open to a follow-up many months or years down the road. In this story, our hero — emudev Nemesis — finished work on one of two modules for the Laserdisc-based gaming console, making it possible to play Sega's Mega LD games via emulation for the first time.&lt;/p&gt;
    &lt;p&gt;As of publication time, Nemesis was juuuust starting to take a look at the work required to do the same for the other "pak" players could slot into the LaserActive to play NEC PC Engine games, but who knew how long that would take?&lt;/p&gt;
    &lt;p&gt;Maybe we'd come back to it before the end of 2026, or maybe next year, or maybe in half a deca-&lt;/p&gt;
    &lt;p&gt;Oh. He already did it.&lt;/p&gt;
    &lt;p&gt;"NEC LDROM2 support is functioning on nightly builds of the v147 prerelease, and will be included in the next official Ares release," Nemesis recently wrote on his website. It took less than three weeks. While you can grab the nightly build anytime, when the next stable build of Ares releases, it'll be all official-like.&lt;/p&gt;
    &lt;p&gt;Considering the bulky size of the LaserActive game rips — they can take up dozens of gigabytes — some performance optimizations Nemesis has implemented in the last few days are almost as exciting as the second console support. Because now you should be able to run the images off a decent HDD without performance issues. Here's the breakdown on Github:&lt;/p&gt;
    &lt;quote&gt;"This change brings speed enhancements to LaserActive games. The linear resampling coefficient precalculation reduces overall CPU overhead by approximately 30%, making slower CPUs much more likely to achieve full framerate. Additionally, frame prefetch using a background thread makes games much more tolerant of IO latency, making it possible to play games back from platter drives over SATA3.&lt;lb/&gt;This should be sufficient to make emulation performance acceptable on 95%+ of systems, and I don't have any further optimizations planned at this stage."&lt;/quote&gt;
    &lt;p&gt;So then — LaserActive support is more or less feature complete. What can you play? What should you play? Seeing as the system's deader than dead and nobody's likely to be playing copyright cop, the Laserdisc rips are being freely uploaded and shared here. Not every game is available yet, but here's where you should probably start:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vajra and Vajra 2 - A pair of LaserActive-exclusive rail shooters by Data West&lt;/item&gt;
      &lt;item&gt;Triad Stone - An FMV game in the Dragon's Lair game&lt;/item&gt;
      &lt;item&gt;J.B. Harold - Blue Chicago Blues - As described by Nemesis, an "FMV murder mystery detective game, with a surprising amount of freedom. You have control over where to go, what actions to take, and what questions to ask. This title came on a double-sided CLV disc, giving it four times the video content of a typical single-sided CAV LaserActive title. The game also used separate video streams per field, to squeeze a whopping 4 hours of footage into one disc."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are a couple other cool games and curiosities on the system, including more rail shooters, some prototypes of Myst, and a German TV movie that lets you swap between different perspectives — but the above should give you a taste for that sweet sweet (or fuzzy, fuzzy) '90s laser gaming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Patching In&lt;/head&gt;
    &lt;p&gt;MiSTer's Taito F2 core pulls off a Hat Trick – Taito's 1990 game Football Champ, aka Hat Trick Hero, is now playable on the MiSTer's arcade core, as is the baseball game Ah Eikou no Koshien. The latter's surprisingly expressive for its era and looks like a lot more fun than I expect from '90s baseball games.&lt;/p&gt;
    &lt;p&gt;MiSTer's CDi core once again threatens you by functioning – In the latest unstable nightly build of the CDi core, developer Andre Zeps has committed several crimes of CDi improvement, including: "Fix dual SDRAM mode," "Add support for chroma subcarrier for clean composite video from external RGB converters," and "- Add bob deinterlacing to ascal." Go on then, but don't blame me if you start bleeding from every orifice while playing Wind of Gamelon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Report&lt;/head&gt;
    &lt;p&gt;Windows builds of RPCS3 are back in business – Due to a compiler issue, RPCS3's latest builds haven't been available on Windows since back in June, but they're back and working again now. Meanwhile, contributor Whatcookie has created a surprisingly detailed breakdown of how hard it is to do nothing, efficiently.&lt;/p&gt;
    &lt;p&gt;Eden is off the Play Store, for now – Well, so much for that. After launching on Android a few weeks ago, the Switch emulator has been taken down, though you can still find builds, including for Android, on the Github. Aren't DMCA takedowns lovely?&lt;/p&gt;
    &lt;p&gt;Speedrunning-focused emulator BizHawk gets hexed – But in a good way! The source port DSDA-Doom has been integrated into BizHawk, supporting Doom, Heretic and Hexen. It also now has an integrated DOSBox-X core, as well as Opera, for the 3DO.&lt;/p&gt;
    &lt;p&gt;ShadPS4 gets more Unreal – The latest build of ShadPS4 marks a significant milestone: some Unreal Engine games for the console are now playable, and even more are bootable. Look at all these games that work!&lt;/p&gt;
    &lt;head rend="h2"&gt;Translation Station&lt;/head&gt;
    &lt;p&gt;Tis the season for brains... Dead of the Brain (2) – It's spooky season, which means the crew behind the translation of PC-98 adventure game Dead of the Brain is back with the sequel two years after the first! "Like the original game, this is also a point-and-click adventure involving zombies, but this time the gameplay is much simpler, but there's still a degree of brute force required," translation crew WINE says. Playing this one might be a bit tedious, but the art is :chefskiss:&lt;/p&gt;
    &lt;p&gt;Virtual-On, on PS3 – The PS3 re-release of this mecha game had English dialogue etc., but its UI was in Japanese. This translation patch changes that.&lt;/p&gt;
    &lt;p&gt;Wizardy VI, on Saturn – There are at least nine platforms you can play Wizardry: Bane of the Cosmic Forge on, from the 1990 DOS original to the Amiga and FM Towns and modern ports, but the Japanese-only Saturn port is unique, incorporating features from Wizardry 7, and now playable with the original English script. This version has "more spells, more traps, and more skills (though most of the extra skills do nothing in 6, unfortunately), and the art style too is very reminiscent of 7 ... it’s also got a much easier early game, which a lot of new players have notoriously struggled with when playing the other versions," hacker and fan Remisse told Sega Saturn Shiro.&lt;/p&gt;
    &lt;p&gt;Undercover Cops play board games on the GB – Prolific translation group Stardust Crusaders is back with a Game Boy board/card game based on the arcade game. I'm not gonna say it's one of Irem's all-timers (find me playing Ninja Baseball Bat Man instead), but it's cute!&lt;/p&gt;
    &lt;head rend="h2"&gt;Good pixels&lt;/head&gt;
    &lt;p&gt;It's early October which means it's basically Halloween, right? Here's a load of screenshots from the first couple hours of Dead of the Brain 2. 👻&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.readonlymemo.com/mame-hyper-neo-geo-support-sound-emulation/"/><published>2025-10-08T15:01:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517134</id><title>The RSS feed reader landscape</title><updated>2025-10-08T20:37:20.950781+00:00</updated><content>&lt;doc fingerprint="be149c54c0323cec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A deep dive into the rss feed reader landscape&lt;/head&gt;
    &lt;p&gt;RSS feeds and, in one form or another, feed readers, have existed for more than 20 years. Their main purpose is enabling their users to consume content from various sources in one place. And especially in recent years, also helping users deal with content overload.&lt;/p&gt;
    &lt;p&gt;Back then there were only a handful of relevant products. Today it's different, there are products for many different situations and use-cases. When first getting into RSS and feed readers, it can be difficult to find out which of this wide range of products are the right ones to use.&lt;/p&gt;
    &lt;p&gt;This article describes the landscape so you can find out which product fits best for your use-case.&lt;/p&gt;
    &lt;p&gt;Side-note: I'm using RSS as a synonym for all web feed standards (Atom, JSON Feed)&lt;/p&gt;
    &lt;head rend="h2"&gt;Classification&lt;/head&gt;
    &lt;p&gt;I attempted a classification of feed readers based on 2 axes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deployment model: local (phone or PC), browser extension, self-hosted, hosted&lt;/item&gt;
      &lt;item&gt;Business model: free, one-time payment, SAAS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The deployment model is based on where data is stored and feed fetching happens. Some products have a web app and mobile apps, but feed fetching happens on the server. In this case it's classified as &lt;code&gt;hosted&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The business model categorization is based on the cheapest option that gives access to the full feature set of the product. A self-hostable product with a hosted option is categorized into &lt;code&gt;free&lt;/code&gt;. A freemium SAAS product is categorized as &lt;code&gt;paid (SAAS)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And here the image in table format, for easily clickable links:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Pricing&lt;/cell&gt;
        &lt;cell role="head"&gt;On-device (phone or PC)&lt;/cell&gt;
        &lt;cell role="head"&gt;Browser extension&lt;/cell&gt;
        &lt;cell role="head"&gt;Self-hosted&lt;/cell&gt;
        &lt;cell role="head"&gt;Hosted&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Paid (one-time)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hosting models&lt;/head&gt;
    &lt;head rend="h3"&gt;Browser extension&lt;/head&gt;
    &lt;p&gt;Feed readers deployed as browser extensions can be installed through the respective stores of the browsers, usually either the Chrome Web Store or the Firefox Add-ons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup typically only requires installing the extension, not even an account is needed. There is no maintenance required beyond the occasional update, which usually happens automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally, with browser storage functionality (local storage or IndexedDB). How much data can be stored depends on the storage of the device. Browser extensions can only store as much data as the browser allows itself to use. But for most users this is easily enough.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device itself. Because the extension only runs if the browser runs, feeds are only fetched if the browser is open. This can lead to missed posts, depending on the publishing frequency of the feed and how often the browser is active.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Since all data is stored on the device, by default it's available only on the device where the extension is installed. If users enable it, the extension supports it, and the user is signed in, browsers can sync data to other devices that have the extension. Storing all data on the device also means that it is accessible offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Extensions can integrate deeply with the browser, and offer features like automatic feed finding of visited websites. Extensions can also provide a comprehensive feature set. Their only limitations are more compute-intensive features (e.g. requiring machine learning), or features that require special infrastructure to run (e.g. emails).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products (free)&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this category I only found one product. Smart-RSS was another one, but was discontinued in February.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-device&lt;/head&gt;
    &lt;p&gt;On-device products are separate applications and installed on the device you want to use them. Either on your iOS or Android phone or tablet, or on your Windows, Mac, or Linux computer. They fetch feeds and store data on that device.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: In general setup is done by installing the application. Some products may require an account, but that is not the norm. Maintenance is similar to browser extensions, the occasional updates. Some applications require manual update installations, others do that automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally on the device, which gives total control over the data. The maximum amount of feeds and articles stored only depend on the available storage of the device.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device. For that to happen the application must be running. Some products may implement a background fetching service, in that case only the device must be turned on. Similar to browser extensions, this limitation may lead to missed posts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Typically the data of on-device feed readers are only available on the device where it's installed. Data sync would need to be done manually or via operating system specific mechanisms (e.g. iCloud), which not all products support. Since data is stored on the device, it's also available offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On-device products can use the full computing power of the device. Combined with the comparatively small storage requirements of one user, it means that some features can be significantly faster than other categories. The exact features depend on the application, and mobile apps are typically less powerful than desktop apps. Limitations are only features that require multiple users (e.g. recommendations) or specific infrastructure (e.g. newsletter subscriptions).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Self-hosted&lt;/head&gt;
    &lt;p&gt;Self-hosted products all fall into the open-source and free category. They are designed to be installed on a server to run continuously, though it is possible to install them on a PC as well. They fetch feeds and store data on the server, and make it available through a web interface.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup requires a server, installing the application, and depending on how it should be accessible, possibly also domain and reverse proxy setup. This needs significantly more technical knowledge than the other options, but with ChatGPT (or others) it should be possible also for fairly non-technical people. This setup is generally more complex with more failure points than the other options, but with a correct setup failures happen rarely, if at all.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: The application stores data on the server it runs on. Since users control their server, they also have total control over the data stored on it. Applications typically use well-established databases, which allows users to inspect and change data with common tools. The amount of data that can be stored is only limited by the available storage on the server. Most servers start at 20 GB, which is enough for most feed reading use-cases. Often, storage can be dynamically extended if more space is needed.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the server. Since it runs continuously, there is no break in feed fetching, and even high frequency feeds are no problem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: The application and all its data is accessible from any device with a web browser by navigating to the server's URL. Data is stored on the server, therefore automatically synced between all devices that use it, but also require internet access.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On average self-hosted products have a wider feature set than browser extension or on-device feed readers. There is no theoretical limit on the feature set, but typically they keep the infrastructure as simple as possible, to keep setup and maintenance straightforward. This makes them slightly less powerful than hosted alternatives.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;p&gt;Self-hosted products are all open-source and free. The only costs are for the server, and the cheapest VPS plans start at ~2$/month.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosted&lt;/head&gt;
    &lt;p&gt;Hosted feed readers are managed services. It's required to create an account to get access to them. All of them are paid SAAS products, and most offer a free plan.&lt;/p&gt;
    &lt;p&gt;On average they have the most polished user experience and most comprehensive feature sets, since they're backed by companies that invest in continuous development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Beyond creating an account, no setup is required. The same for maintenance. Service providers make sure the products work as intended, and deal with everything required to keep the service running, including infrastructure setup, monitoring, backups, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Since data is stored on the servers and databases of the company running the product, users don't have direct control. But through laws like GDPR users have the right to export all their data, or request deletion. Storage is essentially unlimited, though most products have limits to avoid abuse. These limits are mentioned on their pricing page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Similar to self-hosted products, feeds are fetched on the server, which runs continuously and ensures that even high-frequency feeds don't pose a problem. The fetching interval is usually dynamic, based on the popularity of a feed and the publishing frequency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Hosted products are primarily available as web application, and some offer native apps as well. Since data is stored on the server, it's natively synced between devices. Some hosted feed readers also offer offline support.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Hosted feed readers serve many customers at the same time, which makes it necessary to have more complex infrastructure setups. This also enables features that other types of products cannot do, like email receiving, recommendations, or historic feed contents. Consequently hosted options are generally more powerful than other categories, though the specific feature set depends on the product.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All hosted products are SAAS products and charge monthly. &lt;code&gt;Folo&lt;/code&gt; is an outlier, they currently don't have any paid features, but the terms of service indicate that this will come in the future. At that point it will join the others in the &lt;code&gt;Paid (SAAS)&lt;/code&gt; category.&lt;/p&gt;
    &lt;head rend="h2"&gt;App support and offline access for products that don't offer it natively&lt;/head&gt;
    &lt;p&gt;Many of the self-hosted or hosted products don't provide apps or offline access by themselves. However, with the right setup, it's still possible to access the articles offline.&lt;/p&gt;
    &lt;p&gt;Most of these products provide APIs. This can be a proprietary API, or an API based on the old Google Reader API.&lt;/p&gt;
    &lt;p&gt;Mobile apps, for example ReadKit or Fiery Feeds, can not only subscribe to feeds, but also connect to other products through their APIs. They download contents, store them locally, and sync changes back to the connected products.&lt;/p&gt;
    &lt;p&gt;These apps make it possible to use a native mobile app for products that don't provide an app themselves, and get offline access at the same time.&lt;/p&gt;
    &lt;p&gt;FreshRSS, for example, has a list of native apps that support it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A note on newsletters&lt;/head&gt;
    &lt;p&gt;Newsletters are a growing mechanism for delivering (blog) content. Some, but not all, hosted feed readers support newsletters out of the box. But on-device products can't do that at all because of their infrastructure limitations.&lt;/p&gt;
    &lt;p&gt;Even if a feed reader doesn't support newsletters by itself, it's still possible to get newsletters into the feed reader, through services that convert newsletters into RSS feeds.&lt;/p&gt;
    &lt;p&gt;These services generate an email address and give you a corresponding feed URL. Emails to the generated address are added to the feed as new entry. So after signing up to the newsletter and adding the feed URL, the newsletter is added to the feed reader even without native email support.&lt;/p&gt;
    &lt;p&gt;Services that do this are Kill the Newsletter and the Lighthouse Newsletter to RSS tool. Both are free.&lt;/p&gt;
    &lt;head rend="h2"&gt;Products&lt;/head&gt;
    &lt;p&gt;The descriptions highlight the defining and unique aspects of the products, for the full feature list please go to their respective websites. Where available I used the screenshots for their websites, to represent the products as best as possible (test account screenshots wouldn't be as good).&lt;/p&gt;
    &lt;head rend="h3"&gt;NetNewsWire (on-device, free)&lt;/head&gt;
    &lt;p&gt;NetNewsWire is a free, on-device feed reader for Mac and iOS. By default it stores data on the device itself, but can sync via iCloud and using other products as storage. And it provides a Safari extension for easy feed-adding. Notably, it supports AppleScript, which makes it possible to automate certain workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fiery Feeds (on device, paid SAAS)&lt;/head&gt;
    &lt;p&gt;Fiery feeds is a Mac and iOS app. The download is free, and to get the premium features it costs ~15$/year (varies by region). By default it stores data on the device itself, but can sync via iCloud and using the API of other products (e.g. FreshRSS). The main distinguishing features are the customization options of the app, like custom themes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reeder (on-device, SAAS)&lt;/head&gt;
    &lt;p&gt;The current version of Reeder is a Mac and iOS app. The download is free, and to get the premium features it costs ~10$/year. The previous version of Reeder, now called Reeder Classic, is still available as one-time purchase. It also stores data on-device, and can sync via iCloud.&lt;/p&gt;
    &lt;p&gt;The main distinguishing feature is the unified timeline, which includes RSS, podcasts, social media, and more.&lt;/p&gt;
    &lt;head rend="h3"&gt;FreshRSS (self-hosted, free)&lt;/head&gt;
    &lt;p&gt;FreshRSS is a self-hosted feed reader and once set up, it's available as a web app. It is quite powerful, and in addition to normal feed subscriptions offers WebSub as well. It's possible to customize it with themes and extensions, and it's translated into more than 15 languages.&lt;/p&gt;
    &lt;p&gt;Together with Miniflux they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Miniflux&lt;/head&gt;
    &lt;p&gt;Miniflux is a self-hosted feed reader as well, and available as web app after setup. It's focus is on staying simple and fast instead of adding fancy features. It also offers a hosted version, which is 15$/year and has a 15 day trial period.&lt;/p&gt;
    &lt;p&gt;Together with FreshRSS they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Folo (hosted, free)&lt;/head&gt;
    &lt;p&gt;Folo is a relatively new product developed by the creators of RSS Hub. It's a free hosted feed reader, with apps available for every major platform. Their terms of service suggest that at some point they will charge a monthly fee for some premium features, but at the time of writing there were no paid features.&lt;/p&gt;
    &lt;p&gt;Folo is also open-source and therefore theoretically self-hostable, but I haven't found documentation for it.&lt;/p&gt;
    &lt;p&gt;It has a huge feature set, including newsletter support, transforming websites into feeds, AI summaries, and much more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedly (hosted, SAAS)&lt;/head&gt;
    &lt;p&gt;Feedly is the most widely-known product and has the most users of all feed readers. It has a comprehensive features set, and offers a free plan as well. For the past couple of years, it seems that Feedly has focused more on AI features and enterprise customers, but their core product remains solid.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inoreader&lt;/head&gt;
    &lt;p&gt;Inoreader is the second most widely-known product, after Feedly. It too offers a free plan. Their feature list is impressive, with social media support for subscriptions, automation and AI features, public API and integrations. And of course much more.&lt;/p&gt;
    &lt;p&gt;What stands out on Reddit are complaints about price hikes. Though Inoreader probably has tens or hundreds of thousands of users who don't have issues and think the product is great.&lt;/p&gt;
    &lt;head rend="h3"&gt;Readwise Reader&lt;/head&gt;
    &lt;p&gt;Readwise Reader is a relatively new product, from the creators of the original Readwise. It's a great feed reader, though were it really shines is the reading experience. They also have reading views for PDFs, eBooks, and more.&lt;/p&gt;
    &lt;p&gt;The website mentions that it's in beta, but it has been in beta for years now and at this point is a stable product, and has been for awhile.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tiny Tiny RSS&lt;/head&gt;
    &lt;p&gt;Tiny Tiny RSS deserves an honorable mention in this list. It was, and still is, used by many, and has been for a long time, and was often recommended on the RSS subreddit.&lt;/p&gt;
    &lt;p&gt;On October 3rd the maintainer announced that he's going to stop working on it, and will remove all infrastructure on November 1st. Forks of the project with other maintainers may pop up, but at the moment it's too soon to tell what the future of Tiny Tiny RSS will be.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lighthouse&lt;/head&gt;
    &lt;p&gt;Lighthouse is also a relatively new product. It's in beta, which refers to the fact that it doesn't yet have all features necessary to fulfill its vision, which goes beyond simple feed reading.&lt;/p&gt;
    &lt;p&gt;The main differentiator is that it focuses on articles over feeds, and has a separate view for curating articles (the inbox). It's focused on finding high-value content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Similar product categories&lt;/head&gt;
    &lt;p&gt;Feed readers are powerful products, which require manual setup to make them work well. Subscribing to feeds is mandatory, adding tags, filtered views, and rules can make them work even better. But for some use-cases, other product categories are simpler and might work better.&lt;/p&gt;
    &lt;head rend="h3"&gt;News aggregators&lt;/head&gt;
    &lt;p&gt;News aggregators automatically collect and curate news from a large variety of sources. They usually provide some customization options, but focus on news and don't allow arbitrary feed subscriptions like feed readers do.&lt;/p&gt;
    &lt;p&gt;They focus on providing an overview of the most relevant news stories.&lt;/p&gt;
    &lt;p&gt;Examples are Kagi News, Ground News, and SmartNews.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reading lists&lt;/head&gt;
    &lt;p&gt;Reading lists, also called read-it-later apps, are for saving and organizing links you found somewhere on the web. Many feed readers can do the same, but reading lists are optimized for that purpose.&lt;/p&gt;
    &lt;p&gt;Examples are Instapaper and Matter. Karakeep is a self-hosted option.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to choose&lt;/head&gt;
    &lt;p&gt;For most people, going with one of the hosted products is the best option. They're generally the most polished and most powerful products, owing to the fact that they have companies behind them with full-time engineers. They generally also offer a free plan, so if you stay within the limits of those, they will even be free to use.&lt;/p&gt;
    &lt;p&gt;For more specific requirements, products of the other categories can work better. They have different characteristics, and can work better in some situations. For example, if you want total control over your data, self-hosted options are the way to go.&lt;/p&gt;
    &lt;p&gt;It's probably easiest to first decide on the category, and then check out multiple products, or maybe even try them out. Virtually all products support OPML import and export, so moving feed subscriptions from one product to the next is almost zero effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lighthouseapp.io/blog/feed-reader-deep-dive"/><published>2025-10-08T15:17:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517642</id><title>Suspicionless ChatControl must be taboo in a state governed by the rule of law</title><updated>2025-10-08T20:37:20.391279+00:00</updated><content>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://digitalcourage.social/@echo_pbreyer/115337976340299372"/><published>2025-10-08T16:03:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517674</id><title>Ortega hypothesis</title><updated>2025-10-08T20:37:20.291981+00:00</updated><content>&lt;doc fingerprint="efd8585d1ac4d390"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Ortega hypothesis&lt;/head&gt;&lt;p&gt;The Ortega hypothesis holds that average or mediocre scientists contribute substantially to the advancement of science.[1] According to this hypothesis, scientific progress occurs mainly by the accumulation of a mass of modest, narrowly specialized intellectual contributions. On this view, major breakthroughs draw heavily upon a large body of minor and little-known work, without which the major advances could not happen.[2]&lt;/p&gt;&lt;head rend="h2"&gt;Citation research&lt;/head&gt;[edit]&lt;p&gt;The Ortega hypothesis is widely held,[2] but a number of systematic studies of scientific citations have favored the opposing "Newton hypothesis", which says that scientific progress is mostly the work of a relatively small number of great scientists (after Isaac Newton's statement that he "stood on the shoulders of giants").[1] The most important papers mostly cite other important papers by a small number of outstanding scientists, suggesting that the breakthroughs do not actually draw heavily on a large body of minor work.[2] Rather, the pattern of citations suggests that most minor work draws heavily on a small number of outstanding papers and outstanding scientists. Even minor papers by the most eminent scientists are cited much more than papers by relatively unknown scientists; and these elite scientists are clustered mostly in a small group of elite departments and universities.[2] The same pattern of disproportionate citation of a small number of scholars appears in fields as diverse as physics and criminology.[3]&lt;/p&gt;&lt;p&gt;The matter is not settled. No research has established that citation counts reflect the real influence or worth of scientific work. So, the apparent disproof of the Ortega hypothesis may be an artifact of inappropriately chosen data.[4] Stratification within the social networks of scientists may skew the citation statistics.[5] Many authors cite research papers without actually reading them or being influenced by them.[6] Experimental results in physics make heavy use of techniques and devices that have been honed by many previous inventors and researchers, but these are seldom cited in reports on those results.[7][8] Theoretical papers have the broadest relevance to future research, while reports of experimental results have a narrower relevance but form the basis of the theories. This suggests that citation counts merely favor theoretical results.[7]&lt;/p&gt;&lt;head rend="h2"&gt;The name&lt;/head&gt;[edit]&lt;p&gt;The name of the hypothesis refers to José Ortega y Gasset, who wrote in The Revolt of the Masses that "astoundingly mediocre" men of narrow specialties do most of the work of experimental science.[9] Ortega most likely would have disagreed with the hypothesis that has been named after him, as he held not that scientific progress is driven mainly by the accumulation of small works by mediocrities, but that scientific geniuses create a framework within which intellectually commonplace people can work successfully. For example, Ortega thought that Albert Einstein drew upon the ideas of Immanuel Kant and Ernst Mach to form his own synthesis, and that Einstein did not draw upon masses of tiny results produced systematically by mediocrities. According to Ortega, science is mostly the work of geniuses, and geniuses mostly build on each other's work, but in some fields there is a real need for systematic laboratory work that could be done by almost anyone.[10]&lt;/p&gt;&lt;p&gt;The "Ortega hypothesis" derives only from this last element of Ortega's theory, not the main thrust of it. Ortega characterized this type of research as "mechanical work of the mind" that does not require special talent or even much understanding of the results, performed by people who specialize in one narrow corner of one science and hold no curiosity beyond it.[10]&lt;/p&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b David J. Hess. Science Studies: An Advanced Introduction, p. 71. NYU Press, 1997.&lt;/item&gt;&lt;item&gt;^ a b c d Jonathan R. Cole and Cole, Stephen. "The Ortega hypothesis." Science, New Series, Vol. 178, No. 4059 (Oct. 27, 1972), pp. 368-375.&lt;/item&gt;&lt;item&gt;^ M. Oromaner. "The Ortega hypothesis and influential articles in American sociology." Scientometrics, Vol. 7, No. 1 (Jan. 26, 1985), pp. 3–10. doi:10.1007/BF02020136&lt;/item&gt;&lt;item&gt;^ M.H. MacRoberts and Barbara R. MacRoberts. "Testing the Ortega Hypothesis: Facts and Artifacts." Scientometrics, Vol. 12, Nos. 5–6 (1987) pp. 293–295.&lt;/item&gt;&lt;item&gt;^ Hildrun Kretschmer. "Measurement of social stratification. A contribution to the dispute on the ORTEGA hypothesis." Scientometrics, Vol. 26 No. 1 (1993), pp. 97–113. doi:10.1007/BF02016795&lt;/item&gt;&lt;item&gt;^ Heidi Lee Hoerman and Nowicke, Carole Elizabeth. "Secondary and Tertiary Citing: A Study of Referencing Behavior in the Literature of Citation Analysis Deriving from the Ortega Hypothesis of Cole and Cole." The Library Quarterly, Vol. 65, No. 4 (Oct., 1995), pp. 415-434.&lt;/item&gt;&lt;item&gt;^ a b S. A. Goudsmit, John D. McGervey, Robert J. Yaes, Jonathan R. Cole and Stephen Cole "Citation Analysis." Science, New Series, Vol. 183, No. 4120 (Jan. 11, 1974), pp. 28+30-33.&lt;/item&gt;&lt;item&gt;^ Endre Száva-Kováts. "Non-indexed eponymal citedness (NIEC): first fact-finding examination of a phenomenon of scientific literature." Journal of Information Science, 1994 20:55 doi:10.1177/016555159402000107&lt;/item&gt;&lt;item&gt;^ José Ortega y Gasset. The Revolt of the Masses, pp. 110-111. Norton, 1932.&lt;/item&gt;&lt;item&gt;^ a b Endre Száva-Kováts. "The false 'Ortega Hypothesis': a literature science case study." Journal of Information Science 2004 30: 496. doi:10.1177/0165551504047823&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/Ortega_hypothesis"/><published>2025-10-08T16:06:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518127</id><title>Show HN: I built a local-first podcast app</title><updated>2025-10-08T20:37:18.717555+00:00</updated><link href="https://wherever.audio"/><published>2025-10-08T16:46:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518136</id><title>Doctorow: American tech cartels use apps to break the law</title><updated>2025-10-08T20:37:18.456950+00:00</updated><content>&lt;doc fingerprint="2f8888183b37060b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How American Tech Cartels Use Apps to Break the Law&lt;/head&gt;
    &lt;head rend="h2"&gt;Cory Doctorow on Big Tech’s Drive to Enshittify Our Lives&lt;/head&gt;
    &lt;p&gt;The death of competition spells doom for regulation. Competition is an essential component of effective regulation, for two reasons: First, competition keeps the companies within a sector from all telling the same lie to its regulators. Second, competition erodes companies’ profits and thus starves them of the capital they need to overpower or outmaneuver their regulators.&lt;/p&gt;
    &lt;p&gt;While not all regulation is wise or helpful, a world without regulation is a catastrophe. That’s because, in a highly technological world, your ability to do well (or even to live out the day) requires that you correctly navigate innumerable highly technical questions that you can’t possibly answer.&lt;/p&gt;
    &lt;p&gt;You need to know whether you can trust the software in your car’s antilock braking system, whether you should heed your doctor’s advice to get vaccinated, whether the joists over your head at home are sufficient to keep the ceiling from falling in and killing you, and whether your kids’ schooling is adequate or likely to turn them into ignoramuses.&lt;/p&gt;
    &lt;p&gt;Tech-like apps can obfuscate what’s really going on, sloshing a coat of complexity over a business that allows its owners to claim that they’re not breaking the law.&lt;/p&gt;
    &lt;p&gt;It’s not that you lack the intellect and discernment to answer each of these questions. You’re a smart cookie. Given enough time, you could get a PhD’s worth of education in software engineering, cell biology, material science, structural engineering, and pedagogy; investigate each of the offerings before you in each of these categories; and make an intelligent choice that reflects your priorities and the trade-offs you’re willing to make.&lt;/p&gt;
    &lt;p&gt;The problem is that it would take you several lifetimes to acquire all that knowledge, and long before you could do so, you’d be killed by food poisoning because you guessed wrong about whether you could trust the hygiene policies at your local diner.&lt;/p&gt;
    &lt;p&gt;It would be nice if you could let markets take care of these questions for you, but many of the consequences of wrong answers don’t manifest fast enough to steer your decision-making. Sure, if a private school turns one of your kids into an ignoramus, you can demand your money back and refuse to send your other kids to that school—but your kid is still an ignoramus. Likewise, you can punish a restaurant that gives you food poisoning by withholding your future custom, but if that’s a lethal poisoning, the fact that you don’t eat at that restaurant anymore isn’t quite the moral victory you might be hoping for.&lt;/p&gt;
    &lt;p&gt;To navigate all of these technical minefields, you need the help of a third party. In a modern society, that third party is an expert regulator who investigates or anticipates problems in their area of expertise and then makes rules designed to solve these problems.&lt;/p&gt;
    &lt;p&gt;To make these rules, the regulator convenes a truth-seeking exercise, in which all affected parties submit evidence about what the best rule should be and then get a chance to read what everyone else wrote and rebut their claims. Sometimes, there are in-person hearings, or successive rounds of comment and counter-comment, but that’s the basic shape of things.&lt;/p&gt;
    &lt;p&gt;Once all the evidence is in, the regulator—who is a neutral expert, required to recuse themselves if they have conflicts—makes a rule, citing the evidence on which the rule is based. This whole system is backstopped by courts, which can order the process to begin anew if the new rule isn’t supported by the evidence created while the regulator was developing the record.&lt;/p&gt;
    &lt;p&gt;This kind of adversarial process—something between a court case and scientific peer review—has a good track record of producing high-quality regulations. You can thank a process like this for the fact that you weren’t killed today by critters in your tap water or a high-voltage shock from one of your home’s electrical outlets.&lt;/p&gt;
    &lt;p&gt;One key advantage of the process is that it relies on competitors to counter one another’s claims. The reinforced steel joist manufacturer that claims that only its products are suitable for use in high-rise apartment buildings will have to defend those claims against competitors who submit their own structural engineering and material science evidence. Regulators don’t need to look for holes in the arguments advanced by interested parties; they only need to assess the quality of the criticisms raised by other commenters who submit to the docket.&lt;/p&gt;
    &lt;p&gt;This process isn’t just a way to prevent corporate executives from cheating the public by knowingly overpromising about their own products or denigrating their rivals’; it’s also a way to stop firms that have tricked themselves from fooling the rest of us, too. As with the scientific method, the safeguards of peer review help us catch grubby attempts at both deception and self-deception, because it’s very easy to talk yourself into a sincere belief that you are right and everyone else is wrong.&lt;/p&gt;
    &lt;p&gt;This process works well on “disorganized” sectors composed of many firms that compete hard with one another. When hundreds of companies are all at one another’s throats, they suffer from a collective action problem—the same force that keeps users from leaving services like Facebook.&lt;/p&gt;
    &lt;p&gt;Hundreds of companies find it impossible to agree on almost anything, including where to have a meeting in which they could discuss what line they are going to feed their regulator. They probably can’t even agree on how to cater that meeting.&lt;/p&gt;
    &lt;p&gt;Hundreds of companies are a disorganized rabble. They can’t come to accord, and even if they could, a truly competitive sector produces smaller profits for each company (since one of the best ways to compete is by lowering prices to attract new customers and raising wages to attract the best workers). That leaves very little surplus capital with which to pursue regulatory adventures.&lt;/p&gt;
    &lt;p&gt;But when a sector dwindles to five companies—or four, or three, or two, or just one—the collective action problem is annihilated by the inevitable coziness among the executives of the incestuous industries.&lt;/p&gt;
    &lt;p&gt;After all, the executives in an industry dominated by a handful of firms are apt to have worked at most or all of the companies in the sector. They know one another, came up together, and are part of one another’s social milieu.&lt;/p&gt;
    &lt;p&gt;Not only do concentrated industries find it easier to converge on a set of policy priorities and maintain message discipline while bargaining with their regulators, they also have a lot to bargain with. Concentrated sectors tend to have Mafia-style demarcations of turf. (Think of Pope Alexander VI dividing up the “New World” in 1494, of cable companies carving up the map of the United States into exclusive fiefdoms, or of Apple taking an annual $20 billion-plus payment from Google in exchange for not making its own search engine.)&lt;/p&gt;
    &lt;p&gt;This prevents “wasteful competition” and allows these companies to amass gigantic war chests that they can mobilize to win their policy priorities.&lt;/p&gt;
    &lt;p&gt;A hundred companies are a mob, a rabble. Five companies are a cartel.&lt;/p&gt;
    &lt;p&gt;“Regulatory capture”—when a company suborns its regulator and teams up with it to screw over customers, rivals, and suppliers—starts with a regulator that is weaker than the company it is supposed to be watchdogging. The pro-monopoly policies of the past forty years have produced gigantic companies that find it easy to unite against their regulators, even as the deregulatory policies over the same period have starved regulators of the resources they need to fight back. The inevitable result is regulatory capture.&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;Regulatory capture has two faces: On the one hand, a captured industry is able to flout regulations that are meant to prevent it from harming the public, its employees and other stakeholders, and the environment. On the other hand, regulatory capture creates a coalition between the regulated industry and its regulators. They form a team and work together to enforce rules against other industries, startups, foreign adversaries, and so on. Regulatory capture isn’t the same as underregulation; rather, it is the combination of underregulation (for the industry that has effected the capture) and overregulation (against that industry’s enemies).&lt;/p&gt;
    &lt;p&gt;Tech companies don’t stop with “It’s not a crime if we do it with an app.” They also say, “It’s a crime if you fix our app to defend yourself from our crimes.”&lt;/p&gt;
    &lt;p&gt;The most common tactic used to flout regulation is to break the law with an app and then insist that the law hasn’t been broken at all, because the crime was committed with an app.&lt;/p&gt;
    &lt;p&gt;Sometimes literally (as Uber does when it argues that it’s not an employer because it directs its workers with an app) and sometimes figuratively. Tech-like apps can obfuscate what’s really going on, sloshing a coat of complexity over a business that allows its owners to claim that they’re not breaking the law. (“It’s not an illegal unregulated hotel, it’s an Airbnb!”)&lt;/p&gt;
    &lt;p&gt;Riley Quinn, showrunner for the excellent Trashfuture podcast, says that whenever you hear the word fintech (financial technology), you should mentally substitute unregulated bank.&lt;/p&gt;
    &lt;p&gt;App-based lending platforms ignore usury law and say it doesn’t count because they do it with an app. Cryptocurrency hustlers illegally trade in unregistered securities and say it doesn’t count because they do it with an app.&lt;/p&gt;
    &lt;p&gt;When Uber entered the taxi market without securing taxi licenses or extending the workforce protections required under law, it said the move didn’t count because it did it with an app.&lt;/p&gt;
    &lt;p&gt;The McDonald’s-backed company Plexure sells surveillance data on you to vendors, who use it to raise the price of items when they think you’ll pay more. In its promotional materials, Plexure uses the example of charging extra for your breakfast sandwich on payday. It says that such practices are not a rip-off because they’re done with an app.&lt;/p&gt;
    &lt;p&gt;RealPage gives “recommendations” to landlords about the minimum rents they should charge for all the apartments in your neighborhood, raising rents and worsening the housing crisis. The company says it’s not price-fixing because it’s done with an app.&lt;/p&gt;
    &lt;p&gt;On the subject of the housing crisis, Airbnb is racing to convert all the rental stock in your city into an unlicensed hotel room, but it says the conversion doesn’t count because it’s done with an app.&lt;/p&gt;
    &lt;p&gt;The legal regime for apps really is different from the rules governing web pages. Thanks to intellectual property laws that ban “circumvention,” companies that embed undesirable anti-features in apps can use the law to destroy rivals that disenshittify their offerings.&lt;/p&gt;
    &lt;p&gt;In other words, tech companies don’t stop with “It’s not a crime if we do it with an app.” They also say, “It’s a crime if you fix our app to defend yourself from our crimes.”&lt;/p&gt;
    &lt;p&gt;__________________________________&lt;/p&gt;
    &lt;p&gt;Excerpted from Enshittification: Why Everything Suddenly Got Worse and What to Do About It by Cory Doctorow. Copyright © 2025 by Cory Doctorow. Published by Farrar, Straus and Giroux, October 2025. All rights reserved.&lt;/p&gt;
    &lt;head rend="h4"&gt;Cory Doctorow&lt;/head&gt;
    &lt;p&gt;Cory Doctorow is a science fiction author, activist and journalist. He is the author of many books, including The Lost Cause, a solarpunk science-fiction novel of hope amidst the climate emergency. His nonfiction book The Internet Con: How to Seize the Means of Computation is a Big Tech disassembly manual. Other recent books include Red Team Blues, a science fiction crime thriller; Chokepoint Capitalism, nonfiction about monopoly and creative labor markets; the Little Brother series for young adults; In Real Life, a graphic novel; and the picture book Poesy the Monster Slayer. In 2020, he was inducted into the Canadian Science Fiction and Fantasy Hall of Fame.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lithub.com/how-american-tech-cartels-use-apps-to-break-the-law/"/><published>2025-10-08T16:47:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518813</id><title>WinBoat: Windows apps on Linux with seamless integration</title><updated>2025-10-08T20:37:18.329533+00:00</updated><content>&lt;doc fingerprint="b48fe95fd1b73cdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; Run Windows apps on 🐧 Linux&lt;lb/&gt;with ✨ seamless integration &lt;/head&gt;
    &lt;head rend="h2"&gt;FFFFF/Features/sssss&lt;/head&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;p&gt;Scroll for more!&lt;/p&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;head rend="h2"&gt;DDDD/Download/ddddd&lt;/head&gt;
    &lt;p&gt;We're excited to have you onboard! Pick your platform below to get started with WinBoat within minutes, not hours.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Contribute/eeeee&lt;/head&gt;
    &lt;p&gt;WinBoat is an open-source project licensed under MIT, and we welcome contributions from the community. Whether you're a developer, designer, or just someone who loves WinBoat, there are many ways you can help us improve and grow.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Community/yyyyy&lt;/head&gt;
    &lt;p&gt;We usually hang out on Discord, come join and chat with us!&lt;/p&gt;
    &lt;head rend="h2"&gt;FFFFF/Frequently Asked Questions/sssss&lt;/head&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;How does it compare to WinApps?&lt;/head&gt;
    &lt;p&gt;With WinApps you do the bulk of the setup manually, and there's no cohesive interface to bring it all together. There's a basic TUI, a taskbar widget, and some CLI commands for you to play with.&lt;lb/&gt; WinBoat does all the setup once you have the pre-requisites installed, displays everything worth seeing in a neat interface for you, and acts like a complete experience. No need to mess with configuration files, no need to memorize a dozen CLI commands, it just works.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;What are the advantages of using this over CrossOver or WINE?&lt;/head&gt;
    &lt;p&gt;You can run stuff that doesn't play well with CrossOver or WINE, and have a full Windows desktop at the same time.&lt;lb/&gt; We've had numerous apps that weren't working nicely (or at all) in Wine, this is one of the reasons we've created WinBoat. Some examples would be Affinity Photo, Paint Tool Sai v1.0, the entire Adobe suite, AeroChat, Acrobat, and of course Office.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will I be able to configure my peripherals / hardware using WinBoat?&lt;/head&gt;
    &lt;p&gt;If your peripheral / hardware uses USB to connect to your device. then yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature and you can use any Windows software needed for configuration, it should work out of the box.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there USB passthrough?&lt;/head&gt;
    &lt;p&gt; Yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature. Please give it a try and let us know what you think! 😄&lt;lb/&gt; If for whatever reason you're stuck with an older version of WinBoat, you can modify the docker-compose.yml file in ~/.winboat once you finished setting up WinBoat. You can add the appropriate USB devices like this, followed by executing docker-compose down and docker-compose up -d in the same folder. Please make sure to remove these changes before you upgrade to &amp;gt;=0.8.0 though, as they are incompatible with our implementation.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there GPU passthrough?&lt;/head&gt;
    &lt;p&gt;Not at the moment, but we plan on eventually implementing GPU acceleration through paravirtualized drivers.&lt;lb/&gt; We have looked at MVisor Win VGPU Driver for OpenGL, which seems promising from our tests, but it's for a different hypervisor (not compatible with QEMU). Some other folks are also working on DirectX drivers but nothing that we can try out yet.&lt;lb/&gt; We have also looked into Looking Glass extensively, specifically their Indirect Display Driver which does not need a second GPU, because it'd be absolutely amazing to have it. We got the driver to compile and start via some hacks, but couldn't get much more than a black screen. The developer says it is not ready for general use yet at all, however we plan to integrate it once it is ready.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Does it run games with anti-cheat that don't run on Linux?&lt;/head&gt;
    &lt;p&gt;Unfortunately running games with kernel anti-cheat is not possible, as they block virtualization.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Any possibility of adding Podman support as a Docker alternative?&lt;/head&gt;
    &lt;p&gt;Podman support is planned. We tried working on it, some contributors also tried working on it, but there's some issues with networking (specifically the guest server being unreachable) that prevent it from being functional for now.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will you make it into a Flatpak?&lt;/head&gt;
    &lt;p&gt;This is on our to-do list, but it'll take some effort because Flatpak is pretty isolated from the rest of the system and apps, so we'd have to find a way to expose installed apps, the Docker binary, and the Docker socket, and many other utilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.winboat.app/"/><published>2025-10-08T17:56:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518861</id><title>Show HN: FleetCode – Open-source UI for running multiple coding agents</title><updated>2025-10-08T20:37:18.227113+00:00</updated><content>&lt;doc fingerprint="57844e5f478d9a2f"&gt;
  &lt;main&gt;
    &lt;p&gt;A desktop terminal application for running multiple CLI coding agents simultaneously, each in isolated git worktrees.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple Sessions: Run multiple coding agent sessions (Claude, Codex) in parallel&lt;/item&gt;
      &lt;item&gt;Git Worktree Isolation: Each session runs in its own git worktree, keeping work isolated&lt;/item&gt;
      &lt;item&gt;Persistent Sessions: Sessions persist across app restarts with automatic resumption&lt;/item&gt;
      &lt;item&gt;Terminal Theming: Choose from preset themes (macOS Light/Dark, Solarized Dark, Dracula, One Dark, GitHub Dark)&lt;/item&gt;
      &lt;item&gt;Setup Commands: Configure shell commands to run before the coding agent starts&lt;/item&gt;
      &lt;item&gt;MCP Server Management: Add and configure Model Context Protocol (MCP) servers&lt;/item&gt;
      &lt;item&gt;Session Management: Rename, close, and delete sessions with automatic worktree cleanup&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js 16+&lt;/item&gt;
      &lt;item&gt;Git&lt;/item&gt;
      &lt;item&gt;Claude CLI (&lt;code&gt;npm install -g @anthropic-ai/claude-cli&lt;/code&gt;) or Codex&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;npm install&lt;/code&gt;
    &lt;code&gt;npm run dev&lt;/code&gt;
    &lt;code&gt;npm run build
npm start&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Select a project directory (must be a git repository)&lt;/item&gt;
      &lt;item&gt;Choose a parent branch for the worktree&lt;/item&gt;
      &lt;item&gt;Select your coding agent (Claude or Codex)&lt;/item&gt;
      &lt;item&gt;Optionally add setup commands (e.g., environment variables, source files)&lt;/item&gt;
      &lt;item&gt;FleetCode creates a new git worktree and spawns a terminal session&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New Sessions: Use &lt;code&gt;--session-id &amp;lt;uuid&amp;gt;&lt;/code&gt;for first-time Claude sessions&lt;/item&gt;
      &lt;item&gt;Reopened Sessions: Automatically resume with &lt;code&gt;--resume &amp;lt;uuid&amp;gt;&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Worktrees: Each session gets its own isolated git worktree&lt;/item&gt;
      &lt;item&gt;Persistence: Sessions are saved and can be reopened after closing the app&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Access settings via the gear icon (⚙️) in the sidebar:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Font Family: Choose from common monospace fonts&lt;/item&gt;
      &lt;item&gt;Font Size: Adjust terminal text size&lt;/item&gt;
      &lt;item&gt;Theme: Select from preset color themes&lt;/item&gt;
      &lt;item&gt;Cursor Blink: Toggle cursor blinking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configure Model Context Protocol servers for enhanced agent capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;stdio: Direct process communication&lt;/item&gt;
      &lt;item&gt;SSE: Server-sent events via HTTP&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you encounter a quarantine warning when trying to open the app on macOS, run:&lt;/p&gt;
    &lt;code&gt;xattr -cr /path/to/FleetCode.app&lt;/code&gt;
    &lt;p&gt;This removes the quarantine attribute that prevents the app from opening.&lt;/p&gt;
    &lt;p&gt;If you're using Claude Code and it's reading/writing files from the wrong directory instead of the worktree, disable "Auto connect to IDE" in your Claude Code settings:&lt;/p&gt;
    &lt;code&gt;claude config&lt;/code&gt;
    &lt;p&gt;Set &lt;code&gt;autoConnectToIde&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;. This ensures Claude Code operates within the correct worktree directory.&lt;/p&gt;
    &lt;p&gt;ISC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/built-by-as/FleetCode"/><published>2025-10-08T18:00:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519263</id><title>Julia 1.12 highlights</title><updated>2025-10-08T20:37:17.923250+00:00</updated><content>&lt;doc fingerprint="3cdcaa530be1dbe8"&gt;
  &lt;main&gt;&lt;p&gt;Julia version 1.12 has finally been released. We want to thank all the contributors to this release and all the testers who helped find regressions and issues in the pre-releases. Without you, this release would not have been possible.&lt;/p&gt;&lt;p&gt;The full list of changes can be found in the NEWS file, but here we'll give a more in-depth overview of some of the release highlights.&lt;/p&gt;&lt;code&gt;--trim&lt;/code&gt; feature&lt;code&gt;@atomic&lt;/code&gt; macro family now supports reference assignment syntax&lt;code&gt;--trim&lt;/code&gt; feature&lt;p&gt;Jeff Bezanson, Cody Tapscott, Gabriel Baraldi&lt;/p&gt;&lt;p&gt;&lt;code&gt;julia&lt;/code&gt; now has a new experimental&lt;code&gt;--trim&lt;/code&gt; feature, when compiling a system image with this mode julia will trim statically unreachable code leading to significantly better compile times and binary sizes. To use it you also need to pass the &lt;code&gt;--experimental&lt;/code&gt; flag when building the system image. &lt;/p&gt;&lt;p&gt;In order to use it, any code that is reachable from the entrypoints must not have any dynamic dispatches otherwise the trimming will be unsafe and it will error during compilation.&lt;/p&gt;&lt;p&gt;The expected way of using it is via the &lt;code&gt;JuliaC.jl&lt;/code&gt; package, which provides a CLI and a programmatic API. &lt;/p&gt;&lt;p&gt;For example a simple package with an &lt;code&gt;@main&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;module AppProject

function @main(ARGS)
    println(Core.stdout, "Hello World!")
    return 0
end

end&lt;/code&gt;
&lt;code&gt;juliac --output-exe app_test_exe --bundle build --trim=safe --experimental ./AppProject&lt;/code&gt;
&lt;code&gt;./build/bin/app_test_exe
Hello World!

ls -lh build/bin/app_test_exe
-rwxr-xr-x@ 1 gabrielbaraldi  staff   1.1M Oct  6 17:22 ./build/bin/app_test_exe*&lt;/code&gt;
&lt;p&gt;Keno Fischer, Tim Holy&lt;/p&gt;&lt;p&gt;Bindings now participate in the "world age" mechanism previously used for methods. This has the effect that constants and structs can be properly redefined. As an example:&lt;/p&gt;&lt;code&gt;# Define a struct and a method on that struct:
julia&amp;gt; struct Foo
          a::Int
       end

julia&amp;gt; g(f::Foo) = f.a^2
g (generic function with 1 method)

julia&amp;gt; g(Foo(2))
4

# Redefine the struct (julia pre-1.12 would error here)
julia&amp;gt; struct Foo
          a::Int
          b::Int
       end

# Note that functions need to be redefined to work on the new `Foo`
julia&amp;gt; g(Foo(1,2))
ERROR: MethodError: no method matching g(::Foo)
The function `g` exists, but no method is defined for this combination of argument types.

Closest candidates are:
  g(::@world(Foo, 39296:39300)) # &amp;lt;- This is syntax for accessing the binding in an older "world"
   @ Main REPL[2]:1

julia&amp;gt; g(f::Foo) = f.a^2 + f.b^2
g (generic function with 2 methods)

julia&amp;gt; g(Foo(2,3))
13&lt;/code&gt;
&lt;p&gt;There is also work in progress in Revise.jl to automatically redefine functions on replaced bindings. This should significantly reduce the number of times you have to restart Julia while iterating on some piece of code.&lt;/p&gt;&lt;p&gt;Ian Butterworth, Nathan Daly&lt;/p&gt;&lt;p&gt;&lt;code&gt;--trace-compile-timing&lt;/code&gt; is a new command-line flag that augments &lt;code&gt;--trace-compile&lt;/code&gt; by printing how long each compiled method took (in milliseconds) before the corresponding &lt;code&gt;precompile(...)&lt;/code&gt; line. This makes it easier to spot costly compilations.&lt;/p&gt;&lt;p&gt;In addition, two macros for ad-hoc tracing without restarting Julia have been added:&lt;/p&gt;&lt;p&gt;&lt;code&gt;@trace_compile expr&lt;/code&gt; runs &lt;code&gt;expr&lt;/code&gt; with &lt;code&gt;--trace-compile=stderr --trace-compile-timing&lt;/code&gt; enabled, emitting timed &lt;code&gt;precompile(...)&lt;/code&gt; entries only for that call.&lt;/p&gt;&lt;p&gt;&lt;code&gt;@trace_dispatch expr&lt;/code&gt; runs &lt;code&gt;expr&lt;/code&gt; with &lt;code&gt;--trace-dispatch=stderr&lt;/code&gt; enabled, reporting methods that are dynamically dispatched.&lt;/p&gt;&lt;p&gt;Examples&lt;/p&gt;&lt;code&gt;julia&amp;gt; @trace_compile @eval rand(2,2) * rand(2,2)
#=   79.9 ms =# precompile(Tuple{typeof(Base.rand), Int64, Int64})
#=    4.4 ms =# precompile(Tuple{typeof(Base.:(*)), Array{Float64, 2}, Array{Float64, 2}})
2×2 Matrix{Float64}:
 0.302276  0.14341
 0.738941  0.396414

julia&amp;gt; f(x) = x

julia&amp;gt; @trace_dispatch map(f, Any[1,2,3])
precompile(Tuple{Type{Array{Int64, 1}}, UndefInitializer, Tuple{Int64}})
precompile(Tuple{typeof(Base.collect_to_with_first!), Array{Int64, 1}, Int64, Base.Generator{Array{Any, 1}, typeof(Main.f)}, Int64})
3-element Vector{Int64}:
 1
 2
 3&lt;/code&gt;
&lt;p&gt;Gabriel Baraldi, Ian Butterworth&lt;/p&gt;&lt;p&gt;Julia now starts with one interactive thread by default (in addition to the default thread). This means that by default Julia runs with the threading configuration of 1 default thread, 1 interactive thread.&lt;/p&gt;&lt;p&gt;The interactive thread pool is where the REPL and other interactive operations run. By separating these from the default thread pool (where &lt;code&gt;@spawn&lt;/code&gt; and &lt;code&gt;@threads&lt;/code&gt; schedule work when no threadpool is specified), the REPL can perform operations like autocomplete queries in parallel with user code execution, leading to a more responsive interactive experience.&lt;/p&gt;&lt;p&gt;Key behaviors:&lt;/p&gt;&lt;p&gt;Default: Julia starts with &lt;code&gt;-t1,1&lt;/code&gt; (1 default + 1 interactive thread)&lt;/p&gt;&lt;p&gt;Explicit &lt;code&gt;-t1&lt;/code&gt;: If you explicitly request 1 thread with &lt;code&gt;-t1&lt;/code&gt;, Julia will give you exactly that—no additional interactive thread will be added (resulting in &lt;code&gt;-t1,0&lt;/code&gt;)&lt;/p&gt;&lt;p&gt;Multiple threads: &lt;code&gt;-t2&lt;/code&gt; or &lt;code&gt;-tauto&lt;/code&gt; will give you the requested default threads plus 1 interactive thread&lt;/p&gt;&lt;p&gt;Manual control: You can always specify both pools explicitly, e.g., &lt;code&gt;-t4,2&lt;/code&gt; for 4 default and 2 interactive threads&lt;/p&gt;&lt;p&gt;This change improves the out-of-the-box experience while maintaining backwards compatibility for users who explicitly request single-threaded execution.&lt;/p&gt;&lt;p&gt;Mosè Giordano&lt;/p&gt;&lt;p&gt;Julia now respects CPU affinity settings, such as those set via &lt;code&gt;cpuset&lt;/code&gt;/&lt;code&gt;taskset&lt;/code&gt;/&lt;code&gt;cgroups&lt;/code&gt;, etc. The same also applies to the default number of BLAS threads, which now follows the same logic. This can also be observed when running Julia inside Docker. Currently, you have&lt;/p&gt;&lt;code&gt;$ docker run --cpus=4 --rm -ti julia:1.11 julia --threads=auto -e '@show Threads.nthreads(); using LinearAlgebra; @show BLAS.get_num_threads()'
Threads.nthreads() = 22
BLAS.get_num_threads() = 11&lt;/code&gt;
&lt;p&gt;When starting Julia with &lt;code&gt;--threads=auto&lt;/code&gt;, &lt;code&gt;Threads.nthreads()&lt;/code&gt; is equal to the total number of CPUs on the system instead of the only 4 CPUs reserved by Docker. Likewise, the number of BLAS threads, which can be obtained with &lt;code&gt;BLAS.get_num_threads()&lt;/code&gt; and on x86-64 systems is by default half the number of available cores, is 11 instead of 2. With Julia v1.12 this is fixed, and the number of both Julia and BLAS threads will respect the number of CPUs reserved by Docker:&lt;/p&gt;&lt;code&gt;% docker run --cpus=4 --rm -ti julia:1.12 julia --threads=auto -e '@show Threads.nthreads(); using LinearAlgebra; @show BLAS.get_num_threads()'
Threads.nthreads() = 4
BLAS.get_num_threads() = 2&lt;/code&gt;
&lt;p&gt;The new behavior is also important to avoid oversubscription out-of-the-box when running Julia on HPC systems where schedulers set CPU affinity when using shared resources.&lt;/p&gt;&lt;code&gt;OncePerX&lt;/code&gt;&lt;p&gt;Jameson Nash&lt;/p&gt;&lt;p&gt;Certain initialization patterns need to run only once, depending on scope: per process, per thread, or per task. To make this easier and safer, Julia now provides three built-in types:&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerProcess{T}&lt;/code&gt;: runs an initializer exactly once per process, returning the same value for all future calls.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerThread{T}&lt;/code&gt;: runs an initializer once for each thread ID. Subsequent calls on the same thread return the same value.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerTask{T}&lt;/code&gt;: runs an initializer once per task, reusing the same value within that task.&lt;/p&gt;&lt;p&gt;These replace common hand-rolled solutions such as using &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;nthreads()&lt;/code&gt;, or &lt;code&gt;task_local_storage()&lt;/code&gt; directly.&lt;/p&gt;&lt;p&gt;A simple example of &lt;code&gt;OncePerProcess&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;julia&amp;gt; const global_state = Base.OncePerProcess{Vector{UInt32}}() do
           println("Making lazy global value...done.")
           return [Libc.rand()]
       end;

julia&amp;gt; a = global_state();
Making lazy global value...done.

julia&amp;gt; a === global_state()
true&lt;/code&gt;
&lt;p&gt;Use cases:&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerProcess&lt;/code&gt;: caches, global constants, or initialization that should happen once per Julia process (even across precompilation).&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerThread&lt;/code&gt;: per-thread state needed for interoperability with C libraries or specialized threading models.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerTask&lt;/code&gt;: lightweight task-local state without manually managing &lt;code&gt;task_local_storage&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;These types provide a safer, composable way to express “initialize once” semantics in concurrent Julia code.&lt;/p&gt;&lt;p&gt;Zentrik&lt;/p&gt;&lt;p&gt;BOLT is a post-link optimizer from LLVM that improves runtime performance by reordering functions and basic blocks, splitting hot and cold code, and folding identical functions. Julia now supports building BOLT-optimized versions of libLLVM, libjulia-internal, and libjulia-codegen.&lt;/p&gt;&lt;p&gt;These optimizations reduce compilation and execution time in common workloads. For example, the all-inference benchmarks improve by about 10%, an LLVM-heavy workload shows a similar ~10% gain, and building &lt;code&gt;corecompiler.ji&lt;/code&gt; improves by 13–16% with BOLT. When combined with PGO and LTO, total improvements of up to ~23% have been observed.&lt;/p&gt;&lt;p&gt;To build a BOLT-optimized Julia, run the following commands from &lt;code&gt;contrib/bolt/&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;make stage1
make copy_originals
make bolt_instrument
make finish_stage1
make merge_data
make bolt&lt;/code&gt;
&lt;p&gt;The optimized binaries will be available in the &lt;code&gt;optimized.build&lt;/code&gt; directory. An analogous workflow exists in &lt;code&gt;contrib/pgo-lto-bolt/&lt;/code&gt; for combining BOLT with PGO+LTO.&lt;/p&gt;&lt;p&gt;BOLT currently works only on Linux x86_64 and aarch64, and the resulting &lt;code&gt;.so&lt;/code&gt; files must not be stripped. Some &lt;code&gt;readelf&lt;/code&gt; warnings may appear during testing but are considered harmless.&lt;/p&gt;&lt;code&gt;@atomic&lt;/code&gt; macro family now supports reference assignment syntax&lt;p&gt;Marek Kaluba&lt;/p&gt;&lt;p&gt;The &lt;code&gt;@atomic&lt;/code&gt; macro family now supports indexing (e.g. &lt;code&gt;m[i]&lt;/code&gt;, &lt;code&gt;m[i,j]&lt;/code&gt;) in addition to field access. This makes it possible to perform atomic fetch, set, modify, swap, compare-and-swap, and set-once directly on array-like references. The macros expand to new APIs: &lt;code&gt;getindex_atomic&lt;/code&gt;, &lt;code&gt;setindex_atomic!&lt;/code&gt;, &lt;code&gt;modifyindex_atomic!&lt;/code&gt;, &lt;code&gt;swapindex_atomic!&lt;/code&gt;, &lt;code&gt;replaceindex_atomic!&lt;/code&gt;, and &lt;code&gt;setindexonce_atomic!&lt;/code&gt;. Vararg and &lt;code&gt;CartesianIndex&lt;/code&gt; indexing are supported.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;code&gt;mem = AtomicMemory{Int}(undef, 2)

@atomic mem[1] = 2                 # atomic set
x = @atomic mem[1]                 # atomic fetch
@atomic :monotonic mem[1] += 1     # atomic modify with order
old = @atomicswap mem[1] = 4       # atomic swap (returns old)
res = @atomicreplace mem[1] 4 =&amp;gt; 10  # (old=4, success=true)
ok  = @atomiconce mem[2] = 7         # set once (Bool)&lt;/code&gt;
&lt;p&gt;Two new per-task metrics can be enabled by starting Julia with &lt;code&gt;--task-metrics=yes&lt;/code&gt; or by calling &lt;code&gt;Base.Experimental.task_metrics(true)&lt;/code&gt;. Enabling or disabling task metrics with &lt;code&gt;Base.Experimental.task_metrics&lt;/code&gt; only affects new tasks, not existing ones. The metrics are:&lt;/p&gt;&lt;p&gt;&lt;code&gt;Base.Experimental.task_running_time_ns(t::Task)&lt;/code&gt;: the time for which &lt;code&gt;t&lt;/code&gt; was actually running. This is currently inclusive of GC time, compilation time, and any spin time.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Base.Experimental.task_wall_time_ns(t::Task)&lt;/code&gt;: the time from the scheduler becoming aware of &lt;code&gt;t&lt;/code&gt; until &lt;code&gt;t&lt;/code&gt; is complete.&lt;/p&gt;&lt;p&gt;Kristoffer Carlsson&lt;/p&gt;&lt;p&gt;A workspace is a set of project files that all share the same manifest. Each project in a workspace can include its own dependencies, compatibility information, and even function as a full package.&lt;/p&gt;&lt;p&gt;When the package manager resolves dependencies, it considers the requirements and compatibility of all the projects in the workspace. The compatible versions identified during this process are recorded in a single manifest file.&lt;/p&gt;&lt;p&gt;A workspace is defined in the base project by giving a list of the projects in it:&lt;/p&gt;&lt;code&gt;[workspace]
projects = ["test", "docs", "benchmarks", "PrivatePackage"]&lt;/code&gt;
&lt;p&gt;This structure is particularly beneficial for developers using a monorepo approach, where a large number of unregistered packages may be involved. It is also useful for adding documentation or benchmarks to a package by including additional dependencies beyond those of the package itself. Test-specific dependencies are now recommended to be specified using the workspace approach (a project file in the &lt;code&gt;test&lt;/code&gt; directory that is part of the workspace defined by the package project file).&lt;/p&gt;&lt;p&gt;Workspaces can also be nested: a project that itself defines a workspace can also be part of another workspace. In this case, the workspaces are “merged,” with a single manifest being stored alongside the “root project” (the project that is not included in another workspace).&lt;/p&gt;&lt;p&gt;An app is a Julia package that can be run directly from the terminal, similar to a standalone program. Each app provides an entry point via &lt;code&gt;@main&lt;/code&gt; and can define its own default Julia flags and executable name.&lt;/p&gt;&lt;p&gt;When an app is installed, it gets put into &lt;code&gt;.julia/bin&lt;/code&gt; and by adding that to your &lt;code&gt;PATH&lt;/code&gt; it allows you to launch it by name together with any arguments or options.&lt;/p&gt;&lt;p&gt;A Julia app is defined in the &lt;code&gt;Project.toml&lt;/code&gt; file using an &lt;code&gt;[apps]&lt;/code&gt; section:&lt;/p&gt;&lt;code&gt;[apps]
reverse = {} # empty dictionary is for additional metadata&lt;/code&gt;
&lt;p&gt;with a corresponding entry point in the package module:&lt;/p&gt;&lt;code&gt;# src/MyReverseApp.jl
module MyReverseApp

function (@main)(ARGS)
    for arg in ARGS
        print(stdout, reverse(arg), " ")
    end
end

end # module&lt;/code&gt;
&lt;p&gt;After installation, the app can be run directly in the terminal:&lt;/p&gt;&lt;code&gt;$ reverse some input string
emos tupni gnirts&lt;/code&gt;
&lt;p&gt;This makes apps useful for building CLI tools or packaging Julia functionality as user-facing executables. Multiple apps can be defined per package by using submodules, and each app can specify default Julia flags (e.g. &lt;code&gt;--threads=4&lt;/code&gt;) for performance or debugging.&lt;/p&gt;&lt;p&gt;See the full documentation for more information: https://pkgdocs.julialang.org/dev/apps/&lt;/p&gt;&lt;p&gt;&lt;code&gt;Pkg.status()&lt;/code&gt; now highlights when a dependency's loaded version differs from what the current environment would load. This helps identify situations where you may be running code against an outdated or mismatched version of a package—particularly useful when switching between environments or after modifying dependencies.&lt;/p&gt;&lt;p&gt;When a package is already loaded from a different version or path than what the current environment specifies, Pkg will display a yellow &lt;code&gt;[loaded: vX.Y.Z]&lt;/code&gt; indicator next to the package name:&lt;/p&gt;&lt;p&gt;This visual cue makes it easier to spot when you need to restart Julia to pick up the correct package versions, reducing debugging time and confusion in iterative development workflows.&lt;/p&gt;&lt;p&gt;Tim Besard&lt;/p&gt;&lt;p&gt;&lt;code&gt;Ptr{T}&lt;/code&gt; now lowers to actual LLVM pointer types in generated IR (i.e. &lt;code&gt;ptr&lt;/code&gt; with opaque pointers, or &lt;code&gt;i8*&lt;/code&gt;), instead of integers like &lt;code&gt;i64&lt;/code&gt;. This simplifies low-level interop: &lt;code&gt;llvmcall&lt;/code&gt; no longer needs &lt;code&gt;ptrtoint&lt;/code&gt;/&lt;code&gt;inttoptr&lt;/code&gt; shims, and many intrinsics can be called via &lt;code&gt;ccall&lt;/code&gt; using &lt;code&gt;Ptr&lt;/code&gt; directly.&lt;/p&gt;&lt;p&gt;What changes for you&lt;/p&gt;&lt;p&gt;Inline LLVM (&lt;code&gt;llvmcall&lt;/code&gt;): update IR to use &lt;code&gt;ptr&lt;/code&gt;/&lt;code&gt;i8*&lt;/code&gt; for pointer arguments/returns, and remove redundant &lt;code&gt;ptrtoint&lt;/code&gt;/&lt;code&gt;inttoptr&lt;/code&gt; casts. Old IR that treats pointers as integers is still accepted but emits a deprecation warning.&lt;/p&gt;&lt;p&gt;Pointer arithmetic: &lt;code&gt;add_ptr&lt;/code&gt; / &lt;code&gt;sub_ptr&lt;/code&gt; now operate on real pointers: &lt;code&gt;add_ptr(::Ptr{T}, ::UInt)&lt;/code&gt; and &lt;code&gt;sub_ptr(::Ptr{T}, ::UInt)&lt;/code&gt; (lowered to GEP).&lt;/p&gt;&lt;p&gt;&lt;code&gt;ccall&lt;/code&gt; convenience: passing/returning &lt;code&gt;Ptr{T}&lt;/code&gt; maps to LLVM pointer types directly, enabling more intrinsic calls without custom &lt;code&gt;llvmcall&lt;/code&gt; glue.&lt;/p&gt;&lt;p&gt;Example (before → after)&lt;/p&gt;&lt;code&gt;; BEFORE (deprecated): integer pointer
define i64 @f(i64 %p) {
  %q = inttoptr i64 %p to i8*
  ; ...
  %r = ptrtoint i8* %q to i64
  ret i64 %r
}

; AFTER: real pointer
define ptr @f(ptr %p) {
  ; ...
  ret ptr %p
}&lt;/code&gt;
&lt;p&gt;This change also unlocks minor optimization opportunities in generated code since pointers no longer bounce through integer casts.&lt;/p&gt;&lt;p&gt;Mosè Giordano&lt;/p&gt;&lt;p&gt;Many developers may have experience with occasional failures when running tests of their packages which were observed only on remote machines, and wished to be able to reproduce the same run, for debugging purposes. The GitHub Actions workflow &lt;code&gt;julia-actions/julia-runtest&lt;/code&gt; recently started printing to the log the full options used to invoke the Julia process which runs the tests, which lets developers use the same compiler options (e.g. bounds checking, code coverage, deprecation warnings, etc.) as the CI runs. However there are occasional failures which don't depend on compiler options, but may depend on the state of the global random number generator (RNG), if for example the input data of the tests is generated with functions like &lt;code&gt;rand&lt;/code&gt; and &lt;code&gt;randn&lt;/code&gt;, without passing an explicit RNG object, instead relying on the global one. The &lt;code&gt;Test.@testset&lt;/code&gt; macro has had for a long time the feature of automatically controlling the global RNG, but until now its state was never displayed. Starting from Julia v1.12, a failure inside a &lt;code&gt;@testset&lt;/code&gt; causes the RNG of the outermost test set to be printed to screen, which then you can also set in a new test set to exactly reproduce the same run.&lt;/p&gt;&lt;p&gt;As an example, consider the following test which would fail with a 0.1% probability:&lt;/p&gt;&lt;code&gt;julia&amp;gt; using Test

julia&amp;gt; @testset begin
           @test rand() &amp;gt; 0.001
       end;
test set: Test Failed at REPL[2]:2
  Expression: rand() &amp;gt; 0.001
   Evaluated: 0.00036328334842516963 &amp;gt; 0.001

Stacktrace:
 [1] top-level scope
   @ REPL[2]:2
 [2] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:1776 [inlined]
 [3] macro expansion
   @ REPL[2]:2 [inlined]
 [4] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:680 [inlined]
Test Summary: | Fail  Total  Time
test set      |    1      1  1.5s
RNG of the outermost testset: Random.Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7)
ERROR: Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.&lt;/code&gt;
&lt;p&gt;Normally, it'd require several attempts to reproduce a similar failure, but now the RNG is printed to screen and you can reproduce the run in a new session by setting the &lt;code&gt;rng&lt;/code&gt; option of &lt;code&gt;@testset&lt;/code&gt; to the value printed in the failed test:&lt;/p&gt;&lt;code&gt;julia&amp;gt; using Test, Random

julia&amp;gt; @testset rng=Random.Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7) begin
           @test rand() &amp;gt; 0.001
       end;
test set: Test Failed at REPL[2]:2
  Expression: rand() &amp;gt; 0.001
   Evaluated: 0.00036328334842516963 &amp;gt; 0.001

Stacktrace:
 [1] top-level scope
   @ REPL[2]:2
 [2] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:1776 [inlined]
 [3] macro expansion
   @ REPL[2]:2 [inlined]
 [4] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:680 [inlined]
Test Summary: | Fail  Total  Time
test set      |    1      1  1.4s
RNG of the outermost testset: Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7)
ERROR: Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.&lt;/code&gt;
&lt;p&gt;While there are still many other classes of intermittent failures that aren't captured by the global RNG, being able to reproduce its state inside failing test sets should help debugging more issues during package development.&lt;/p&gt;&lt;p&gt;The preparation of this release was partially funded by NASA under award 80NSSC22K1740. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Aeronautics and Space Administration.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://julialang.org/blog/2025/10/julia-1.12-highlights/"/><published>2025-10-08T18:42:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519575</id><title>A few things to know before stealing my 914 (2022)</title><updated>2025-10-08T20:37:17.229852+00:00</updated><content>&lt;doc fingerprint="36419e95892d15df"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Media | Articles&lt;/head&gt;
    &lt;head rend="h1"&gt;A few things to know before stealing my 914&lt;/head&gt;
    &lt;p&gt;Dear Thief,&lt;/p&gt;
    &lt;p&gt;Welcome to my Porsche 914. I imagine that at this point (having found the door unlocked) your intention is to steal my car. Don’t be encouraged by this; the tumblers sheared off in 1978. I would have locked it up if I could, so don’t think you’re too clever or that I’m too lazy. However, now that you’re in the car, there are a few things you’re going to need to know. First, the battery is disconnected, so slide-hammering my ignition switch is not your first step. I leave the battery disconnected, not to foil hoodlums such as yourself, but because there is a mysterious current drain from the 40-year-old German wiring harness that I can’t locate and/or fix. So, connect the battery first. Good luck finding the engine cover release. Or the engine, for that matter.&lt;/p&gt;
    &lt;p&gt;Now, you can skip your slide hammer. The ignition switch’s tumblers are so worn that any flat-bladed screwdriver or pair of scissors will do. Don’t tell anyone.&lt;/p&gt;
    &lt;p&gt;Once you’ve figured that out and try to start the car, you’ll run into some trouble. The car is most likely in reverse gear, given that the parking brake cable froze up sometime during the Carter administration. Since there is not a clutch safety switch on the starting circuit, make sure to press the clutch down before you try to crank the engine. (I don’t want you running into my other car in the driveway.) This is doubly necessary because my starter is too weak to crank the clutch-transmission input shaft assembly with any success.&lt;/p&gt;
    &lt;p&gt;With the clutch pedal depressed, the engine should turn over fast enough to get things going. But first, you’ll need to press the gas pedal to the floor exactly four times. Not three. Not five. Four. The dual Webers don’t have chokes and you’ll be squirting fuel down the barrels with the accelerator pumps for the necessary priming regime. If you don’t do it right, the car won’t start before the battery gives up the ghost. Consider yourself forewarned.&lt;/p&gt;
    &lt;p&gt;If you’ve followed along so far, the engine should fire right up. Don’t be fooled—it will die in eight seconds when the priming fuel runs out. Repeat the gas pedal priming procedure, but only pump two times. Deviate from this routine at your own peril.&lt;/p&gt;
    &lt;p&gt;Now you have the engine running. Make sure the green oil light in the dash goes out. If it does not, you only have about 100 yards to drive before the engine locks up, so be attentive. If all goes well with the oil pressure, you may now attend to the gear shift lever. Some explanation follows.&lt;/p&gt;
    &lt;p&gt;This is a Porsche 914. It has a mid-engine layout. The transmission is in the far back of the car, and the shift linkage’s main component is a football-field-long steel rod formed loosely in the shape of your lower intestine. Manipulating the gear shift lever will deliver vague suggestions to this rod, which, in turn, will tickle small parts deep within the dark bowels of the transaxle case. It is akin to hitting a bag of gears with a stick, hopefully finding one that works.&lt;/p&gt;
    &lt;p&gt;If you are successful in finding first gear (there is a shift pattern printed on the knob; they say German engineers don’t have a sense of humor), congratulations. You may launch the vehicle into motion.&lt;/p&gt;
    &lt;p&gt;Do not become emboldened by your progress, as you will quickly need to shift to another gear. Ouija boards are more communicative than the shift knob you will be trusting to aid your efforts. Depress the clutch as you would in any car, and pull the knob from its secure location out of first gear. Now you will become adrift in the zone known to early Porsche owners as “Neverland” and your quest will be to find second gear. Prepare yourself for a ten-second-or-so adventure. Do not go straight forward with the shift knob, as you will only find Reverse waiting there to mock you with a shriek of high-speed gear teeth machining themselves into round cylinders. Should you hear this noise, retreat immediately to the only easy spot to find in this transmission: neutral. This is a safe place, no real damage can occur here, but alas, no forward motion will happen either. From this harbor of peace, you can re-attempt to find second, but you may just want to go for any “port in a storm”, given that the traffic behind you is now cheering you on in your quest with vigorous horn-honks of support and encouragement. Most 914 owners at this point pull over to the side of the road and feign answering a cell phone call to a) avoid further humiliation; b) allow traffic to pass; and c) gather the courage for another first gear start. You may choose to do likewise.&lt;/p&gt;
    &lt;p&gt;If you press onward without taking a break, you may re-enter first. This is how the car mocks you for your lack of skill, but sometimes it is the only path forward. Once you are ready to again try for second, I can offer some advice. One trick that works is to declutch the transmission, pull the lever from the first-gear position, enter into the aforementioned neutral zone, and then rapidly wig-wag the shift knob side-to-side along a lateral axis. If you move the knob quickly enough, the transmission will be out-smarted and cannot anticipate your next move. It is at this time that you should re-attempt to enter second, and most likely you will do so. Surprise is your best weapon against this transmission.&lt;/p&gt;
    &lt;p&gt;The move to third should be straightforward, as it’s the only easily-accessible gear in the set. You should now be out of my neighborhood and on the main four-lane road. Third gear will be good for 45 mph, so I would advise you just staying there. Trying to get to fourth gear will only frustrate you and your nearby drivers (see: first-to-second shift).&lt;/p&gt;
    &lt;p&gt;You don’t need to check for gasoline in the car. It will be full, even though the fuel gauge reads zero. The odometer reads “0”, not because it was reset when I filled the tank, but because it is just broken. Ignore it. If it is night, and it most likely will be, you will need to turn on the lights. I’ll leave it to you to find the switch since I’ve helped a lot so far. Suffice to say that once you get them active, you will find that the seven inch sealed beams from 1971 will only illuminate sufficient roadway for travel below 45 mph. Since you are still in third , this shouldn’t be a problem. Oh, and the lights only work on high beam, so ignore the flashing lights and vulgar gestures from opposing traffic.&lt;/p&gt;
    &lt;p&gt;By now you’ve certainly noticed the smell. That is the aroma of Mobil 1 oil being boiled off of long sections of horizontal exhaust pipes, which were cleverly encased by the factory with a second shroud of oil-holding chambers. They filled with oil during my last drive and you are now operating a small thermal refinery that is making light short-chained vaporous hydrocarbons from what was once $8-a-quart oil. They are being conveniently routed to the cabin through carefully formed channels in the heating system, plus the rust holes in the floor provided by Mother Nature herself over the past few decades.&lt;/p&gt;
    &lt;p&gt;You’ll feel less dizzy if you open a window. But mind that driver’s window does not work, so you’ll have to lean over and roll down the passenger window half-way. I say half-way in a manner that will become apparent once you try to get the window to go all the way down, which it will refuse to do. Instead, simply open the driver’s door slightly and drive along, as I do. Once the oil vapors are exhumed from the cabin, you should start to feel a little better. There is a rag behind the driver’s seat that you can use to wipe the oil film off of the inside of the windshield.&lt;/p&gt;
    &lt;p&gt;Knowing which road you’re probably on by now, you will be hitting stop lights. Try as hard as you can to not bring the 914 to a stop. The brake system is ideal for this situation, being known more as “scrubbers” than “brakes”. Since you can’t effectively stop the car, use this to your advantage and don’t try. Remember: You certainly don’t want to have to go back into first.&lt;/p&gt;
    &lt;p&gt;If you have made it within sight of to the highway entrance, don’t get any ideas. The front right wheel is severely bent and the vibration at velocities above 50 mph will crack the windshield and cause the doors to open by themselves. So stay on the surface streets, stoplights notwithstanding.&lt;/p&gt;
    &lt;p&gt;It may be at this point that you consider abandoning the car to avoid further calamity. There is an Exxon station right before the freeway entrance. The last guy who stole my 914 used this very spot and it was rather convenient for all concerned parties. I suggest you ditch the car there and scope out a nice, reliable Camry to heist.&lt;/p&gt;
    &lt;p&gt;Norman Garrett was the Concept Engineer for the original Miata back in his days at Mazda’s Southern California Design Studio. He currently teaches automotive engineering classes at UNC-C’s Motorsports Engineering Department in Charlotte, North Carolina and curates his small collection of dysfunctional automobiles and motorcycles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.hagerty.com/media/advice/a-few-things-to-know-before-you-steal-my-914/"/><published>2025-10-08T19:16:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519915</id><title>Svelte is that fast</title><updated>2025-10-08T20:37:17.040994+00:00</updated><content>&lt;doc fingerprint="e50d1701050b4dd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Svelte really is that fast&lt;/head&gt;
    &lt;p&gt;If you search online, you’ll find countless benchmarks claiming to compare the performance of various JavaScript frameworks with each other. More often than not, the benchmarks are overly simplistic and fail to reflect real-world scenarios. In other cases, they compare apples and oranges, for instance by pitting a fully fledged framework against a lightweight library that cover only a small subset of the framework’s functionality.&lt;/p&gt;
    &lt;p&gt;Right now, I’m at that point in my career again where I am starting development on a new web application and need to choose the “right” JavaScript framework. This time, I decided to look for academic studies on the performance of JavaScript frameworks and sadly, didn’t find as many as I had hoped. I did come across one particular study that compares Angular, React, Vue, Svelte and Blazor with each other. Its main drawback is that the comparison was done in 2021 – a lifetime ago in tech terms – but I think it’s still worth reading.&lt;/p&gt;
    &lt;p&gt;Before I dive into the summary, I want to share something I found mildly amusing. The paper is published in the Journal of Web Engineering, and if you visit its website, you’ll notice it includes &lt;code&gt;/index.php/&lt;/code&gt; in the URL. I’m not sure why.
Is it a deliberate choice? Or is it a sign of questionable web engineering?&lt;/p&gt;
    &lt;p&gt;It is estimated that up to 97% of websites today use JavaScript, with more than 80% also relying on a library or framework. JavaScript is often used to manage UI state changes within single page applications, allowing users to interact without reloading the entire page. While this can be done manually via the DOM API, it’s often error prone.&lt;/p&gt;
    &lt;p&gt;Modern web frameworks wrap the DOM API and provide a custom declarative syntax. This means that application code can simply describe the desired UI state, and the framework automatically generates the necessary DOM API calls to reflect that state in the browser.&lt;/p&gt;
    &lt;p&gt;When using the DOM API directly, the amount of script execution required to update the UI scales linearly with the complexity of the change. However, when DOM API calls are generated dynamically by a framework, the framework must first determine exactly which updates are necessary, introducing additional overhead. Furthermore, the chosen rendering strategy can greatly affect the number of DOM API calls made. A bad strategy may result in noticeable delays even for small updates, which is why it makes sense to compare the strategies used by major JavaScript frameworks.&lt;/p&gt;
    &lt;p&gt;The study looks at five popular frameworks: Angular, React, Vue, Svelte, and Blazor. All are JavaScript-based except for Blazor, which uses WebAssembly. Blazor applications are written in C# and run in a .NET runtime compiled to WebAssembly. Because WebAssembly modules lack direct access to the DOM, they rely on an additional JavaScript interoperability layer, which can introduce extra overhead.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Framework&lt;/cell&gt;
        &lt;cell role="head"&gt;Version&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Angular&lt;/cell&gt;
        &lt;cell&gt;11.2.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;React&lt;/cell&gt;
        &lt;cell&gt;17.0.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vue&lt;/cell&gt;
        &lt;cell&gt;3.0.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Svelte&lt;/cell&gt;
        &lt;cell&gt;3.35.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Blazor&lt;/cell&gt;
        &lt;cell&gt;5.0.3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All five frameworks follow some variant of the Model-View-ViewModel (MVVM) pattern. In MVVM, developers define components that bind an application’s data sources to views, so that changes in the data are automatically reflected in the UI.&lt;/p&gt;
    &lt;p&gt;Each framework continuously tries to keep the state of the DOM tree synchronised with the state of the component tree defined in application code. This is done using two distinct methods.&lt;/p&gt;
    &lt;p&gt;The first method, known as virtual DOM (vDOM)-based rendering, is used in React, Vue, and Blazor. It works by comparing the two trees and calculating the minimum set of changes needed to transform one into the other. This generally has a time complexity of , but can often be simplified to by making assumptions that usually apply in browser applications.&lt;/p&gt;
    &lt;p&gt;The second method is used by Angular and Svelte. Here, there is no separate step for calculating all required changes to the DOM. Instead, each component directly updates its corresponding section of the DOM by tracking the values of its data bindings.&lt;/p&gt;
    &lt;p&gt;From a performance standpoint, using a virtual DOM can introduce overhead not present in a binding-based rendering strategy.&lt;/p&gt;
    &lt;p&gt;All of the reviewed frameworks perform DOM updates within a render loop that walks through the component tree. The cost of this render loop depends on the size of the input and fixed costs.&lt;/p&gt;
    &lt;p&gt;A render loop involves two types of work: creating new elements and updating existing ones. Creating elements is generally straightforward and costs the same for each framework, regardless of rendering strategy.&lt;/p&gt;
    &lt;p&gt;Updating existing elements is where the rendering strategy makes a noticeable difference. Angular, for example, always walks through the entire component tree, resulting in a lot of unnecessary work when only a small part of the tree needs updating. React and Blazor walk only through the subtree of the component that initiates the render loop, which is usually more efficient but may still require some unnecessary work for descendants whose output has not changed. Vue and Svelte, on the other hand, process only “dirty” components whose output has changed. This requires the framework to track which components are dirty. Vue does this at runtime, Svelte handles it at compile time.&lt;/p&gt;
    &lt;p&gt;Finally, component output can be classified as either static or dynamic content, with static content remaining unchanged after the component’s initial render. Frameworks that can optimise for static content may have a performance advantage over those that cannot.&lt;/p&gt;
    &lt;p&gt;Several benchmarks were conducted using Angular, React, Vue, Svelte and Blazor. The authors found significant differences in performance between the frameworks, especially as input size increased. , outperforming the others across literally every benchmark.&lt;/p&gt;
    &lt;p&gt;Svelte is the fastest framework when creating static elements, while React is generally among the slowest:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;100&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;500&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1000&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;5000&lt;/cell&gt;
        &lt;cell&gt;85&lt;/cell&gt;
        &lt;cell&gt;77&lt;/cell&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;61&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;10000&lt;/cell&gt;
        &lt;cell&gt;177&lt;/cell&gt;
        &lt;cell&gt;200&lt;/cell&gt;
        &lt;cell&gt;47&lt;/cell&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;123&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;25000&lt;/cell&gt;
        &lt;cell&gt;844&lt;/cell&gt;
        &lt;cell&gt;956&lt;/cell&gt;
        &lt;cell&gt;95&lt;/cell&gt;
        &lt;cell&gt;63&lt;/cell&gt;
        &lt;cell&gt;371&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;50000&lt;/cell&gt;
        &lt;cell&gt;2520&lt;/cell&gt;
        &lt;cell&gt;3559&lt;/cell&gt;
        &lt;cell&gt;173&lt;/cell&gt;
        &lt;cell&gt;98&lt;/cell&gt;
        &lt;cell&gt;964&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Svelte is also the fastest when creating components arranged as a binary tree. However, in this case, Blazor is the slowest by a considerable margin:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;75&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;53&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;120&lt;/cell&gt;
        &lt;cell&gt;55&lt;/cell&gt;
        &lt;cell&gt;84&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;128&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;216&lt;/cell&gt;
        &lt;cell&gt;137&lt;/cell&gt;
        &lt;cell&gt;223&lt;/cell&gt;
        &lt;cell&gt;83&lt;/cell&gt;
        &lt;cell&gt;485&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;297&lt;/cell&gt;
        &lt;cell&gt;233&lt;/cell&gt;
        &lt;cell&gt;313&lt;/cell&gt;
        &lt;cell&gt;142&lt;/cell&gt;
        &lt;cell&gt;966&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16384&lt;/cell&gt;
        &lt;cell&gt;469&lt;/cell&gt;
        &lt;cell&gt;394&lt;/cell&gt;
        &lt;cell&gt;485&lt;/cell&gt;
        &lt;cell&gt;233&lt;/cell&gt;
        &lt;cell&gt;1870&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;32768&lt;/cell&gt;
        &lt;cell&gt;774&lt;/cell&gt;
        &lt;cell&gt;733&lt;/cell&gt;
        &lt;cell&gt;897&lt;/cell&gt;
        &lt;cell&gt;482&lt;/cell&gt;
        &lt;cell&gt;3644&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When updating the root component of a tree with components, :&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;23&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;42&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;92&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;92&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16384&lt;/cell&gt;
        &lt;cell&gt;43&lt;/cell&gt;
        &lt;cell&gt;211&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;32768&lt;/cell&gt;
        &lt;cell&gt;103&lt;/cell&gt;
        &lt;cell&gt;379&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When updating a leaf component in a component tree of components, Angular is the only framework that lags slightly behind. This is because it performs the same amount of work regardless of what has actually changed:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;33&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;33&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16384&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;32768&lt;/cell&gt;
        &lt;cell&gt;104&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;1&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Finally, the table below shows the script execution time when updating the entire component tree of components, where each component contains primarily static content:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;n&lt;/cell&gt;
        &lt;cell role="head"&gt;Angular (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;React (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Vue (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Svelte (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;Blazor (ms)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;128&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;34&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;28&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;256&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;60&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;512&lt;/cell&gt;
        &lt;cell&gt;17&lt;/cell&gt;
        &lt;cell&gt;66&lt;/cell&gt;
        &lt;cell&gt;42&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;101&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1024&lt;/cell&gt;
        &lt;cell&gt;27&lt;/cell&gt;
        &lt;cell&gt;101&lt;/cell&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;250&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;2048&lt;/cell&gt;
        &lt;cell&gt;29&lt;/cell&gt;
        &lt;cell&gt;235&lt;/cell&gt;
        &lt;cell&gt;91&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;502&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4096&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;289&lt;/cell&gt;
        &lt;cell&gt;149&lt;/cell&gt;
        &lt;cell&gt;54&lt;/cell&gt;
        &lt;cell&gt;1020&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;8192&lt;/cell&gt;
        &lt;cell&gt;238&lt;/cell&gt;
        &lt;cell&gt;841&lt;/cell&gt;
        &lt;cell&gt;311&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;2013&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Overall, the results are in line with what would be expected given the characteristics of each rendering strategy.&lt;/p&gt;
    &lt;p&gt;The WebAssembly-based Blazor shows significantly worse performance than its JavaScript-based competitors. However, from these benchmarks alone it’s impossible to determine whether this is due to Blazor itself or a fundamental limitation of using WebAssembly for this purpose.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Svelte demonstrates three key characteristics that likely contribute most to improved performance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The use of a reactivity system to automatically detect dirty components&lt;/item&gt;
      &lt;item&gt;An optimising compiler that generates component update code which ignores static content&lt;/item&gt;
      &lt;item&gt;A binding-based rendering approach rather than a virtual DOM&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Svelte’s on fire, yo&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chuniversiteit.nl/papers/svelte-is-fast"/><published>2025-10-08T19:54:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519944</id><title>Opal is beginning to roll out 15 new countries</title><updated>2025-10-08T20:37:16.770503+00:00</updated><content>&lt;doc fingerprint="f84bb61b56556dc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Expanding access to Opal, our no-code AI mini-app builder&lt;/head&gt;
    &lt;p&gt;Two months ago, we introduced Opal as an early experiment within Google Labs. Our goal was simple: give users the ability to build AI-powered mini-apps, using just natural language — no coding required. When we opened up Opal to users in the U.S. we anticipated they might build simple, fun tools. We didn’t expect the surge of sophisticated, practical and highly creative Opal apps we got instead. The ingenuity of these early adopters made one thing clear: we need to get Opal into the hands of more creators globally.&lt;/p&gt;
    &lt;p&gt;Today, we’re starting to expand Opal to 15 more countries. Opal will begin rolling out in Canada, India, Japan, South Korea, Vietnam, Indonesia, Brazil, Singapore, Colombia, El Salvador, Costa Rica, Panamá, Honduras, Argentina and Pakistan.&lt;/p&gt;
    &lt;p&gt;We’re also sharing details about improvements we’re making to Opal. As more and more people begin to use it, they are finding new and more complex ways to build apps. One of the top requests we’ve received is for more transparency and reliability for Opal workflows. In response, we’re rolling out the following improvements:&lt;/p&gt;
    &lt;p&gt;Advanced debugging for workflows: We’ve fundamentally improved the debugging program but intentionally kept it no-code. You can now run your workflow step-by-step in the visual editor or iterate on a specific step in the console panel. Errors are displayed in real time and localized to the exact step where the failure occurred to provide immediate context and eliminate guesswork. We hope it helps you spend less time debugging and more time building.&lt;/p&gt;
    &lt;p&gt;A faster, more responsive foundation for your apps: We’ve also made significant under-the-hood improvements to Opal’s core performance. Previously, creating a new Opal could take up to five seconds or more. We’ve invested in improvements to speed that up dramatically to make it faster to get started. We’ve also enabled parallel runs, allowing complex workflows with multiple steps to execute simultaneously, helping to reduce overall wait times.&lt;/p&gt;
    &lt;p&gt;Whether you’re automating a complex business process, accelerating your marketing efforts or bringing a creative vision to life, Opal is here to help you build. Try Opal today at opal.withgoogle.com. And if you’re new to Opal, join our builder community through our Discord channel.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/google-labs/opal-expansion/"/><published>2025-10-08T19:56:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45520154</id><title>I played 1k hands of online poker and built a web app with Cursor AI</title><updated>2025-10-08T20:37:16.566461+00:00</updated><content>&lt;doc fingerprint="3cc0aa516d242ab6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I played 1,000 hands of online poker and built a web app with Cursor AI&lt;/head&gt;
    &lt;p&gt;In the last two weeks I spent over a dozen hours playing poker, primarily online at pokerstarsmi.com, and live at a local casino.&lt;/p&gt;
    &lt;p&gt;You can view the last 1,000 hands I played here: https://poker.rchase.com&lt;/p&gt;
    &lt;p&gt;I spent at least as much time reviewing my hands with a desktop app called PokerTracker 4, I read 6 books, studied strategy, and journaled about it my Apple Notes.&lt;/p&gt;
    &lt;p&gt;Then I started building my own Python script automations to export my hand history from PokerStars, import it into PokerTracker 4, check my balance, stuff like that.&lt;/p&gt;
    &lt;p&gt;That led me to getting help writing code from Grok, then Cursor, and then building a full blown Laravel MVP for a web app similar to the PokerTracker 4 desktop app.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why poker?&lt;/head&gt;
    &lt;p&gt;Without getting too philosophical, it's not about the money won or lost - I'm playing low stakes right now because I'm a beginner.&lt;/p&gt;
    &lt;p&gt;I just want to learn the game.&lt;/p&gt;
    &lt;p&gt;Maybe someday I'll play some tournaments or high stakes.&lt;/p&gt;
    &lt;p&gt;But right now, more importantly, I'm learning about myself.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Emotional intelligence becoming aware of emotions in myself and others&lt;/item&gt;
      &lt;item&gt;Self-regulation trying to control my emotions and not let them influence my actions&lt;/item&gt;
      &lt;item&gt;Resilience not giving up because of downswings&lt;/item&gt;
      &lt;item&gt;Humility learning to not get overconfident after a big win&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I also have enjoyed the lessons from the bankroll side of the game:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Managing risk, taking profits, cutting losses&lt;/item&gt;
      &lt;item&gt;Developing the discipline to scale down my buy-ins when losing to keep a max of 10% of bankroll in play so I don't blow my entire bankroll on a bad day&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Whether I won or lost money in a given day isn't important, what's important is whether I followed my plan or not.&lt;/p&gt;
    &lt;p&gt;If I let emotions guide my actions, or I maintained self-control.&lt;/p&gt;
    &lt;p&gt;Success is if I made good decisions given the information I had at the time, even if it didn't lead to a good outcome.&lt;/p&gt;
    &lt;p&gt;The analogies to life and business lessons are endless... but in this blog post I mainly wanted to write about my experience building this web app with AI which was completely mind blowing!&lt;/p&gt;
    &lt;head rend="h3"&gt;Building a poker stats web app with Laravel in Cursor&lt;/head&gt;
    &lt;p&gt;So after only 2 or 3 days of just chatting back and forth for hours and hours with the Cursor AI agent I built a fully functional web app at poker.rchase.com with an admin dashboard and dozens of features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Admin dashboard&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;PokerStars and Gmail integrations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complicated (over 700 lines of code) poker hand history text file parser&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Complicated poker stats calculations like VPIP, PFR, and 3-Bet&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CRUD for journal entries, logging poker account deposits/withdrawals&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hand history file management with multi-file upload and "paste text" options&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Daily PokerStars balance checks&lt;/item&gt;
      &lt;item&gt;Auto export PokerStars hands every 15 minutes with enabled/disabled toggle&lt;/item&gt;
      &lt;item&gt;Auto import hands from email using Gmail IMAP integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hand history table and individual hand viewer&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Profit/loss chart&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Built locally using Herd for MacOS and deployed with the help of Cursor to a DigitalOcean Debian 13 server. Private git repo hosted by GitHub.&lt;/p&gt;
    &lt;p&gt;The insane part is I didn't write a single line of this code.&lt;/p&gt;
    &lt;p&gt;All of this was created through conversations with the Cursor AI agent.&lt;/p&gt;
    &lt;p&gt;I don't even know how we got here with AI.&lt;/p&gt;
    &lt;p&gt;Just a few years ago I remember chatting with ChatGPT asking it to write some basic Python script for me and it was completely useless, it hallucinated calling libraries that didn't exist, using functions it forgot to write... it was nuts.&lt;/p&gt;
    &lt;p&gt;It couldn't even do basic math not that long ago like 2+2=5 was a common thing that would happen in the course of a conversation.&lt;/p&gt;
    &lt;p&gt;I wrote off AI entirely for years after that brief experience - as clearly overhyped and with limited use case potential.&lt;/p&gt;
    &lt;p&gt;But then at some point, I subscribed to the Grok $30/month plan and began using it every single day.&lt;/p&gt;
    &lt;p&gt;It quickly replaced Google Search entirely for me.&lt;/p&gt;
    &lt;p&gt;And then I started to use it much more than I had previously used Google Search.&lt;/p&gt;
    &lt;p&gt;My team started to check with AI about hard problems we ran into whether it was networking or programming, usually the answers weren't great and of course we always reviewed carefully for security issues and didn't just trust implicitly the information it provided.&lt;/p&gt;
    &lt;p&gt;But we could see over time it was improving in the responses.&lt;/p&gt;
    &lt;p&gt;It became a thing when we were stuck "Did you check what Grok had to say about this?"&lt;/p&gt;
    &lt;p&gt;I remember earlier this year my feed being full of "vibe coding" on X and in particular Pieter Levels' fly.pieter.com, but I kind of just followed along for entertainment and I think even at that time it was much worse than it is now, I think you needed to keep the code in one file and implement various hacks to keep the AI aware of the context of that file.&lt;/p&gt;
    &lt;p&gt;But I had no idea it was this far along until last week I pasted my Python PokerStars hand exporter script into Grok and asked it to build the Gmail integration to retrieve the login PIN and with very few iterations it was able to do it successfully and without me writing any code.&lt;/p&gt;
    &lt;p&gt;Then I had it replace all my print statement debugging with proper logging and it did that too easily.&lt;/p&gt;
    &lt;p&gt;Then I had it turn the monolithic script into a class that could be used in other scripts and it did that as well.&lt;/p&gt;
    &lt;p&gt;I was so impressed that I decided to start looking into what the best AI tools were out there for programming... so of course I didn't Google that, I asked Grok. And I started to learn about Cursor, Claude, and Windsurf.&lt;/p&gt;
    &lt;head rend="h3"&gt;What it's like to build a web app with Cursor&lt;/head&gt;
    &lt;p&gt;For me, I've been primarily building apps through other people for the last 4 years now. I barely write any code. I'm not proficient enough to make commits to any of our production repos at HostiFi... sadly.&lt;/p&gt;
    &lt;p&gt;However, the skill I do have is I understand what I want to build, in what order, and what sacrifices need to be made in order to ship it.&lt;/p&gt;
    &lt;p&gt;I have knack for user experience and a small amount of design sense.&lt;/p&gt;
    &lt;p&gt;I also have empathy for the developers I work with, and the complexity of the work involved to build features. I have enough technical knowledge to debate with them the pros and cons of difference approaches when there are forks in the road.&lt;/p&gt;
    &lt;p&gt;All this to say - working with the Cursor Agent was eerily similar to working with a human developer on my team... but way, way faster because the feedback loop was real-time.&lt;/p&gt;
    &lt;p&gt;It was such an unusual experience to watch Cursor work that it's hard to put into words, you really just have to try it for yourself.&lt;/p&gt;
    &lt;p&gt;Basically you tell it to build something, it writes some code, I open the page and there's a 500 error. I tell it - hey there's a 500 error. It checks the logs, finds the bug, fixes the bug, ships the new code, I refresh the page and it's working... but it's not the color I wanted or whatever and I tell it to fix that and it goes and does it. On and on this goes for hours into the night.&lt;/p&gt;
    &lt;p&gt;With humans, normally I outline something I want built whether it's a feature or a new page for the website or a entire new app. Then the developer and I will kind of go back and forth over the details of the MVP version of it and what we should cut out considering the time/value trade off.&lt;/p&gt;
    &lt;p&gt;Then the developer will build it, but not the entire thing. We want to set milestones. That way I can see it as it gets built and give feedback which leads to many iterations, usually days or weeks apart, of each milestone until completion.&lt;/p&gt;
    &lt;p&gt;I learned how to build software like this the hard way...&lt;/p&gt;
    &lt;p&gt;By wasting a ton of time and money because I used to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Not work directly with the end developers&lt;/item&gt;
      &lt;item&gt;Not clearly communicate what I needed&lt;/item&gt;
      &lt;item&gt;Not consider time/value tradeoffs to cut the project or feature down to MVP&lt;/item&gt;
      &lt;item&gt;Wait until the entire project was completed before giving feedback and iterating&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I think these dev management skills I've built up along with the thin technical understanding of a lot of different programming topics over the years have made me uniquely capable of building things with the Cursor AI agent today.&lt;/p&gt;
    &lt;p&gt;I don't think just anyone can build anything right now.&lt;/p&gt;
    &lt;p&gt;I think I might have the contrarian take here - the bar to build is going to continue to get lowered but it will never be "easy" or "anyone can do it".&lt;/p&gt;
    &lt;p&gt;The code was actually never the hard part of most SaaS anyways.&lt;/p&gt;
    &lt;p&gt;If it was, every programmer would be a millionaire.&lt;/p&gt;
    &lt;p&gt;It's hard knowing what to build, in what order, and of course the most important part - getting customers.&lt;/p&gt;
    &lt;p&gt;But anyways back to Cursor.&lt;/p&gt;
    &lt;head rend="h3"&gt;Some of my more interesting conversations with Cursor&lt;/head&gt;
    &lt;p&gt;One of the biggest challenges was writing the hand history parser.&lt;/p&gt;
    &lt;p&gt;PokerStars exports hand history in text files like this:&lt;/p&gt;
    &lt;p&gt;It was very difficult to scrape all of this using regex into separate pieces of data to put into a database where hands can be sorted, summed, and analyzed.&lt;/p&gt;
    &lt;p&gt;Part of the problem was the AI's lack of understanding of the fundamentals of the game of poker.&lt;/p&gt;
    &lt;p&gt;Part of the problem was the amount of edge cases, or hands where something unusual or different happened of which only happened in a few hands.&lt;/p&gt;
    &lt;p&gt;My first goal was just to calculate the profit/loss total from all hands. This seemed fairly simple - find text like "reillychase collected $29.82 from pot" and add it up.&lt;/p&gt;
    &lt;p&gt;But actually wait, we need to also deduct the bets that I made from that pot.&lt;/p&gt;
    &lt;p&gt;But what is considered a bet?&lt;/p&gt;
    &lt;p&gt;If I'm the small or big blind there's different wording in the text file for that bet, there is also different language used for an all-in bet, a raise, a call. A bet was called many different things and they all needed to be added up so they could be deducted from the amount won in the pot.&lt;/p&gt;
    &lt;p&gt;There's also an edge case where I made a bet and someone went all-in so some of my bet was returned to me (the unmatched bet amount).&lt;/p&gt;
    &lt;p&gt;Or maybe there's an edge case where there were two winners and the pot was split.&lt;/p&gt;
    &lt;p&gt;As you can imagine the list goes on and on.&lt;/p&gt;
    &lt;p&gt;Instead of thinking through every edge case I told the AI "let's review some hands together - find me the biggest winners, the biggest losers, and some complicated hands and explain them to me"&lt;/p&gt;
    &lt;p&gt;It was able to find hands of those types, it showed me the text so I could add it up manually, and it showed me its own expected output along with the actual output.&lt;/p&gt;
    &lt;p&gt;Most of the time it was able to figure out on its own what had gone wrong because its expected output after reading the text file differed from the parsed output.&lt;/p&gt;
    &lt;p&gt;In other cases I had to explain to it something poker related to give it more context.&lt;/p&gt;
    &lt;p&gt;These are the kind of conversations we had over and over.&lt;/p&gt;
    &lt;p&gt;Again, this was just like working with a human programmer, although I will admit the AI was much dumber at times, but instead of days or weeks between iterations it was minutes.&lt;/p&gt;
    &lt;p&gt;One unlock I found, with the limited time I spent in actually exploring Cursor itself and not just plugging away at building with it, is changing from Auto to Claude 4.5 Sonnet Thinking as the agent.&lt;/p&gt;
    &lt;p&gt;The quality of the responses greatly improved in my experience and I plan on upgrading my subscription to pay on-demand to be able to continue to use it once my credits run out.&lt;/p&gt;
    &lt;head rend="h3"&gt;What it all means for the future&lt;/head&gt;
    &lt;p&gt;It's not really my thing to give too much thought about macro-trends that are out of my control or worry about what negative consequences they might have on my life.&lt;/p&gt;
    &lt;p&gt;The short answer, I really don't know what this means for the future of the career of programming, the business of software, or anything else.&lt;/p&gt;
    &lt;p&gt;Instead of worrying about that I'm going to try to focus on the here and now, the upside potential, and the unique set of advantages that I have available to me to build something valuable, have fun, and maybe profit.&lt;/p&gt;
    &lt;p&gt;I'm going to do what I enjoy doing, try to learn some new skills and create things.&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking for input from you, the reader&lt;/head&gt;
    &lt;p&gt;If you play poker, let me know.&lt;/p&gt;
    &lt;p&gt;If you use Cursor or similar to build things, let me know.&lt;/p&gt;
    &lt;p&gt;I'm also looking for help on how to revamp the UX/design of poker.rchase.com using AI, it seems like Cursor is not strong in this area maybe there is an alternative I should be looking into?&lt;/p&gt;
    &lt;p&gt;Thank you.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.rchase.com/i-played-1-000-hands-of-online-poker-and-built-a-web-app-with-cursor-ai/"/><published>2025-10-08T20:20:21+00:00</published></entry></feed>