<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-03T15:43:05.733125+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46094606</id><title>Qwen3-VL can scan two-hour videos and pinpoint nearly every detail</title><updated>2025-12-03T15:43:12.611255+00:00</updated><content>&lt;doc fingerprint="2d5d4fc5093bce05"&gt;
  &lt;main&gt;
    &lt;p&gt;A few months after launching Qwen3-VL, Alibaba has released a detailed technical report on the open multimodal model. The data shows the system excels at image-based math tasks and can analyze hours of video footage.&lt;/p&gt;
    &lt;p&gt;The system handles massive data loads, processing two-hour videos or hundreds of document pages within a 256,000-token context window.&lt;/p&gt;
    &lt;p&gt;In "needle-in-a-haystack" tests, the flagship 235-billion-parameter model located individual frames in 30-minute videos with 100 percent accuracy. Even in two-hour videos containing roughly one million tokens, accuracy held at 99.5 percent. The test works by inserting a semantically important "needle" frame at random positions in long videos, which the system must then find and analyze.&lt;/p&gt;
    &lt;p&gt;In published benchmarks, the Qwen3-VL-235B-A22B model often beats Gemini 2.5 Pro, OpenAI GPT-5, and Claude Opus 4.1 - even when competitors use reasoning features or high thinking budgets. The model dominates visual math tasks, scoring 85.8 percent on MathVista compared to GPT-5's 81.3 percent. On MathVision, it leads with 74.6 percent, ahead of Gemini 2.5 Pro (73.3 percent) and GPT-5 (65.8 percent).&lt;/p&gt;
    &lt;p&gt;The model also shows range in specialized benchmarks. It scored 96.5 percent on the DocVQA document comprehension test and 875 points on OCRBench, supporting 39 languages - nearly four times as many as its predecessor.&lt;/p&gt;
    &lt;p&gt;Alibaba claims the system demonstrates new capabilities in GUI agent tasks. It achieved 61.8 percent accuracy on ScreenSpot Pro, which tests navigation in graphical user interfaces. On AndroidWorld, where the system must independently operate Android apps, Qwen3-VL-32B hit 63.7 percent.&lt;/p&gt;
    &lt;p&gt;The model handles complex, multi-page PDF documents as well. It scored 56.2 percent on MMLongBench-Doc for long document analysis. On the CharXiv benchmark for scientific charts, it reached 90.5 percent on description tasks and 66.2 percent on complex reasoning questions.&lt;/p&gt;
    &lt;p&gt;It is not a clean sweep, however. In the complex MMMU-Pro test, Qwen3-VL scored 69.3 percent, trailing GPT-5's 78.4 percent. Commercial competitors also generally lead in video QA benchmarks. The data suggests Qwen3-VL is a specialist in visual math and documents, but still lags in general reasoning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Key technical advances for multimodal AI&lt;/head&gt;
    &lt;p&gt;The technical report outlines three main architectural upgrades. First, "interleaved MRoPE" replaces the previous position embedding method. Instead of grouping mathematical representations by dimension (time, horizontal, vertical), the new approach distributes them evenly across all available mathematical areas. This change aims to boost performance on long videos.&lt;/p&gt;
    &lt;p&gt;Second, DeepStack technology allows the model to access intermediate results from the vision encoder, not just the final output. This gives the system access to visual information at different levels of detail.&lt;/p&gt;
    &lt;p&gt;Third, a text-based timestamp system replaces the complex T-RoPE method found in Qwen2.5-VL. Instead of assigning a mathematical time position to every video frame, the system now inserts simple text markers like "&amp;lt;3.8 seconds&amp;gt;" directly into the input. This simplifies the process and improves the model's grasp of time-based video tasks.&lt;/p&gt;
    &lt;head rend="h2"&gt;Training at scale with one trillion tokens&lt;/head&gt;
    &lt;p&gt;Alibaba trained the model in four phases on up to 10,000 GPUs. After learning to link images and text, the system underwent full multimodal training on about one trillion tokens. Data sources included web scrapes, 3 million PDFs from Common Crawl, and over 60 million STEM tasks.&lt;/p&gt;
    &lt;p&gt;In later phases, the team gradually expanded the context window from 8,000 to 32,000 and finally to 262,000 tokens. The "Thinking" variants received specific chain-of-thought training, allowing them to explicitly map out reasoning steps for better results on complex problems.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open weights under Apache 2.0&lt;/head&gt;
    &lt;p&gt;All Qwen3-VL models released since September are available under the Apache 2.0 license with open weights on Hugging Face. The lineup includes dense variants ranging from 2B to 32B parameters, as well as mixture-of-experts models: the 30B-A3B and the massive 235B-A22B.&lt;/p&gt;
    &lt;p&gt;While features like extracting frames from long videos aren't new - Google's Gemini 1.5 Pro handled this in early 2024 - Qwen3-VL offers competitive performance in an open package. With the previous Qwen2.5-VL already common in research, the new model is likely to drive further open-source development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://the-decoder.com/qwen3-vl-can-scan-two-hour-videos-and-pinpoint-nearly-every-detail/"/><published>2025-11-30T07:27:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46121539</id><title>Zig's new plan for asynchronous programs</title><updated>2025-12-03T15:43:12.214281+00:00</updated><content>&lt;doc fingerprint="b712da05ee6713e9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zig's new plan for asynchronous programs&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;Welcome to LWN.net&lt;/head&gt;
          &lt;p&gt;The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider accepting the discount offer on the right. Thank you for visiting LWN.net!&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The designers of the Zig programming language have been working to find a suitable design for asynchronous code for some time. Zig is a carefully minimalist language, and its initial design for asynchronous I/O did not fit well with its other features. Now, the project has announced (in a Zig SHOWTIME video) a new approach to asynchronous I/O that promises to solve the function coloring problem, and allows writing code that will execute correctly using either synchronous or asynchronous I/O.&lt;/p&gt;
    &lt;p&gt;In many languages (including Python, JavaScript, and Rust), asynchronous code uses special syntax. This can make it difficult to reuse code between synchronous and asynchronous parts of a program, introducing a number of headaches for library authors. Languages that don't make a syntactical distinction (such as Haskell) essentially solve the problem by making everything asynchronous, which typically requires the language's runtime to bake in ideas about how programs are allowed to execute.&lt;/p&gt;
    &lt;p&gt;Neither of those options was deemed suitable for Zig. Its designers wanted to find an approach that did not add too much complexity to the language, that still permitted fine control over asynchronous operations, and that still made it relatively painless to actually write high-performance event-driven I/O. The new approach solves this by hiding asynchronous operations behind a new generic interface, Io.&lt;/p&gt;
    &lt;p&gt;Any function that needs to perform an I/O operation will need to have access to an instance of the interface. Typically, that is provided by passing the instance to the function as a parameter, similar to Zig's Allocator interface for memory allocation. The standard library will include two built-in implementations of the interface: Io.Threaded and Io.Evented. The former uses synchronous operations except where explicitly asked to run things in parallel (with a special function; see below), in which case it uses threads. The latter (which is still a work-in-progress) uses an event loop and asynchronous I/O. Nothing in the design prevents a Zig programmer from implementing their own version, however, so Zig's users retain their fine control over how their programs execute.&lt;/p&gt;
    &lt;p&gt;Loris Cro, one of Zig's community organizers, wrote an explanation of the new behavior to justify the approach. Synchronous code is not much changed, other than using the standard library functions that have moved under Io, he explained. Functions like the example below, which don't involve explicit asynchronicity, will continue to work. This example creates a file, sets the file to close at the end of the function, and then writes a buffer of data to the file. It uses Zig's try keyword to handle errors, and defer to ensure the file is closed. The return type, !void, indicates that it could return an error, but doesn't return any data:&lt;/p&gt;
    &lt;quote&gt;const std = @import("std"); const Io = std.Io; fn saveFile(io: Io, data: []const u8, name: []const u8) !void { const file = try Io.Dir.cwd().createFile(io, name, .{}); defer file.close(io); try file.writeAll(io, data); }&lt;/quote&gt;
    &lt;p&gt;If this function is given an instance of Io.Threaded, it will create the file, write data to it, and then close it using ordinary system calls. If it is given an instance of Io.Evented, it will instead use io_uring, kqueue, or some other asynchronous backend suitable to the target operating system. In doing so, it might pause the current execution and go work on a different asynchronous function. Either way, the operation is guaranteed to be complete by the time writeAll() returns. A library author writing a function that involves I/O doesn't need to care about which of these things the ultimate user of the library chooses to do.&lt;/p&gt;
    &lt;p&gt;On the other hand, suppose that a program wanted to save two files. These operations could profitably be done in parallel. If a library author wanted to enable that, they could use the Io interface's async() function to express that it does not matter which order the two files are saved in:&lt;/p&gt;
    &lt;quote&gt;fn saveData(io: Io, data: []const u8) !void { // Calls saveFile(io, data, "saveA.txt") var a_future = io.async(saveFile, .{io, data, "saveA.txt"}); var b_future = io.async(saveFile, .{io, data, "saveB.txt"}); const a_result = a_future.await(io); const b_result = b_future.await(io); try a_result; try b_result; const out: Io.File = .stdout(); try out.writeAll(io, "save complete"); }&lt;/quote&gt;
    &lt;p&gt; When using an Io.Threaded instance, the async() function &lt;del&gt;doesn't actually&lt;/del&gt; isn't actually required to do anything asynchronously [although the actual implementation may dispatch the function to a separate thread, depending on how it was configured] — it can just run the provided function right away. So, with that version of the interface, the function first saves file A and then file B. With an Io.Evented instance, the operations are actually asynchronous, and the program can save both files at once. &lt;/p&gt;
    &lt;p&gt;The real advantage of this approach is that it turns asynchronous code into a performance optimization. The first version of a program or library can write normal straight-line code. Later, if asynchronicity proves to be useful for performance, the author can come back and write it using asynchronous operations. If the ultimate user of the function has not enabled asynchronous execution, nothing changes. If they have, though, the function becomes faster transparently — nothing about the function signature or how it interacts with the rest of the code base changes.&lt;/p&gt;
    &lt;p&gt; One problem, however, is with programs where two parts are actually required to execute simultaneously for correctness. For example, suppose that a program wants to listen for connections on a port and simultaneously respond to user input. In that scenario, it wouldn't be correct to wait for a connection and only then ask for user input. For that use case, the Io interface provides a separate function, &lt;del&gt;asyncConcurrent()&lt;/del&gt;concurrent() [this function was renamed during development; concurrent() is the most recent name] that explicitly asks for the provided function to be run in parallel. Io.Threaded uses a thread in a thread pool to accomplish this. Io.Evented treats it exactly the same as a normal call to async(). &lt;/p&gt;
    &lt;quote&gt;const socket = try openServerSocket(io); var server = try io.concurrent(startAccepting, .{io, socket}); defer server.cancel(io) catch {}; try handleUserInput(io);&lt;/quote&gt;
    &lt;p&gt;If the programmer uses async() where they should have used concurrent(), that is a bug. Zig's new model does not (and cannot) prevent programmers from writing incorrect code, so there are still some subtleties to keep in mind when adapting existing Zig code to use the new interface.&lt;/p&gt;
    &lt;p&gt; The style of code that results from this design is a bit more verbose than languages that give asynchronous functions special syntax, but Andrew Kelley, creator of the language, said that "&lt;quote&gt;it reads like standard, idiomatic Zig code.&lt;/quote&gt;" In particular, he noted that this approach lets the programmer use all of Zig's typical control-flow primitives, such as try and defer; it doesn't introduce any new language features specific to asynchronous code. &lt;/p&gt;
    &lt;p&gt;To demonstrate this, Kelley gave an example of using the new interface to implement asynchronous DNS resolution. The standard getaddrinfo() function for querying DNS information falls short because, although it makes requests to multiple servers (for IPv4 and IPv6) in parallel, it waits for all of the queries to complete before returning an answer. Kelley's example Zig code returns the first successful answer, canceling the other inflight requests.&lt;/p&gt;
    &lt;p&gt;Asynchronous I/O in Zig is far from done, however. Io.Evented is still experimental, and doesn't have implementations for all supported operating systems yet. A third kind of Io, one that is compatible with WebAssembly, is planned (although, as that issue details, implementing it depends on some other new language features). The original pull request for Io lists 24 planned follow-up items, most of which still need work.&lt;/p&gt;
    &lt;p&gt;Still, the overall design of asynchronous code in Zig appears to be set. Zig has not yet had its 1.0 release, because the community is still experimenting with the correct way to implement many features. Asynchronous I/O was one of the larger remaining priorities (along with native code generation, which was also enabled by default for debug builds on some architectures this year). Zig seems to be steadily working its way toward a finished design — which should decrease the number of times Zig programmers are asked to rewrite their I/O because the interface has changed again.&lt;/p&gt;
    &lt;p&gt; Posted Dec 2, 2025 17:00 UTC (Tue) by smurf (subscriber, #17840) [Link] (14 responses) Doesn't seem much different from tagging everything you want to async-ize with "async" and "await" … Also I'm interested in how zig plans to manage an event loop this way. I mean you need to save and restore the call stack somehow, and stacks may not exactly be small in a production setup. Posted Dec 2, 2025 18:53 UTC (Tue) by daroc (editor, #160859) [Link] (1 responses) As for managing the event loop: I believe the plan is for there to be built-in functions that can start executing a function on a user-provided stack, so the event loop can allocate separate stacks and then give them to the running functions. But Zig has also had a long-term goal to eventually be able to statically determine the needed stack size of any given function, at which point it should be possible to write comptime code that does better than that. Posted Dec 2, 2025 21:20 UTC (Tue) by softball (subscriber, #160655) [Link] Similar to Go, which also has "one and a half colors". Functions taking a context.Context as their first argument are most likely performing I/O. It's not required though: a number-crunching function performing no I/O might still check the context for cancellation every so often. Likewise, I/O without taking a context.Context is possible. Similarly, in async languages (Rust, ...), a function marked async might end up performing no I/O at all (no await points). A function marked sync might spawn its own runtime (or grab the global one) and start spawning futures (= called async functions) on it. Lots of grey areas. One thing I wonder about is mixing threading for CPU-bound work and eventing for I/O-bound work. In Rust, one solution is having the application be fundamentally async (tokio, ...) and hand around a dedicated threadpool (rayon, ...). If there's enough available parallelism, both can coexist without interference and communicate via channels. Rust makes this explicit and relatively ergonomic at compile time (Send + Sync, ...). I wonder how equivalent Zig code would look like (I suppose Io would be the evented variant, and for the CPU-bound work just spawn OS threads normally). Posted Dec 2, 2025 20:09 UTC (Tue) by quotemstr (subscriber, #45331) [Link] Posted Dec 2, 2025 21:18 UTC (Tue) by excors (subscriber, #95769) [Link] (10 responses) Arguably that's a good case of colouring, because the presence of IO _should_ be part of your API: users ought to be aware of the security and performance and portability and testability implications of an API that accesses the filesystem/network, and should have some control over it. But users shouldn't have to care about serial IO vs concurrent IO - that's just an implementation detail and a performance optimisation - and in this model they don't have to care, because the API is IO-coloured either way, unlike the async/await model where migrating to concurrent IO changes your API colouring. That's similar to how the use of dynamic memory allocation should be part of your API (and in Zig it is); it's too important to hide. And error handling (in most languages that don't use exceptions). And the general concept of dependency injection. I suppose the main downside is that once you start making everything an explicit part of every API and avoiding implicit global state, it gets annoyingly verbose, and it's hard to read code when the important logic is obscured by boilerplate. But I think it's interesting to see Zig try a different tradeoff here. Posted Dec 2, 2025 22:23 UTC (Tue) by khim (subscriber, #9252) [Link] (7 responses) That's much better solution that what Rust did. Of course Zig has the benefits of hindsight. In practice there are more than two colors — except in Rust it's not obvious from the source and almost unmanageable in practice. That's because you couldn't simply pass any random In Zig one may simply have more than two implementations of the interface. People are talking about “two colors” because in practice that's something that actually works, but try to mix two executors in one program in Rust… and the whole thing falls apart, you couldn't do that. It's not “2 colors” problem, but “2+ colors problem”. Posted Dec 3, 2025 9:17 UTC (Wed) by pbonzini (subscriber, #60935) [Link] (2 responses) I would like to understand how IO functions are compiled. If they are stackful coroutines, Zig's solution is very clever but that's a very different design space than the stackless coroutines you have in Rust or, for that matter, in Zig's previous attempt at asynchronous I/O. Stackless coroutines need compiler support but are more efficient (a couple years back I had a (IMO) really nice design for C stackless coroutines, but no time to implement it...). Or does the compiler effectively treat the IO argument as a request to turn the function into a state machine and pass it to the threaded or evented run-time? Posted Dec 3, 2025 10:17 UTC (Wed) by spiffyk (subscriber, #173891) [Link] What is important to note is that the language provides no special treatment to the Io parameter, it is entirely an API convention to pass it. Io is an extension of the standard library, which in and of itself does not change how the language works. The only point at which the compiler itself will need to provide special functionality is when an implementation of the Io interface uses the (as of yet not finalized, afaik) constructs for stackless coroutines. But those are planned to be a separate feature of the language, and, from the perspective of the Io, will only be used by specific Io implementations. Posted Dec 3, 2025 12:40 UTC (Wed) by lukasl (guest, #180745) [Link] Posted Dec 3, 2025 9:58 UTC (Wed) by muase (subscriber, #178466) [Link] (1 responses) Could you elaborate what you mean with that? Because I have heavily used async within the embedded world, and I struggle to understand your point. Async has two relevant API components: futures and wakers. As long as I implement a correct future, and use the provided opaque waker to wake the executor, I don’t see how my implementation has to match the executor? And in my experience that works pretty well IRL; I have quite a few projects where I switched from my own executor to embassy, and two projects where I did vice versa, and I’ve never encountered any problems so far… Posted Dec 3, 2025 11:22 UTC (Wed) by khim (subscriber, #9252) [Link] Nope. It has three components, or, more precisely, two and half: futures+wakers and executors. These have to match or the whole thing goes down in flames. Because your waker has to match the executor. And said waker, as you have said, is opaque and is not present in the function signature so compiler couldn't verify that they match. And how many of these have both of these executors running, simultaneously? Note that it's not even a purely theoretical interest. There are tokio and tokio_uring — and they are incompatible (certain things in tokio make it impossible to use in one project). You may want, e.g., use tokio for network-related tasks and tokio_uring for disk access (where tokio is lacking). But if you try to do that you would quickly find out that mixing different futures (and thus different wakers) can easily lead to trouble. Posted Dec 3, 2025 13:56 UTC (Wed) by smurf (subscriber, #17840) [Link] (1 responses) Two colors because one has "async" and one has not, or one requires a somewhat-special "Io" and one does not. Variants (shades of a color, if you'd like) are of course a related problem. Rust isn't the only language that has more than one mostly-incompatible async variant. Python has two (asyncio and trio (*)), and a third (anyio) which provides an API that runs on top of both of them. Also you can run trio on top of asyncio (in guest mode) and vice versa (trio-asyncio). All in all that makes the situation annoying but somewhat manageable. (*) OK so there's also curio and Twisted and whatnot. Details. Posted Dec 3, 2025 15:09 UTC (Wed) by khim (subscriber, #9252) [Link] You can easily predict that “sync” is just a special executor that does everything in place. That's trivial transformation and easily done if you may support more than one executor. Yes, but it's kludges on top of kludges. If you can, somehow, adopt the model that may have more than one executor then all the difference fall by wayside automatically because “sync” becomes just an To untangle that mess we need to, somehow, parametrise our Posted Dec 2, 2025 23:02 UTC (Tue) by sionescu (subscriber, #59410) [Link] (1 responses) Posted Dec 3, 2025 2:55 UTC (Wed) by Cyberax (✭ supporter ✭, #52523) [Link] Posted Dec 2, 2025 21:40 UTC (Tue) by dcoutts (subscriber, #5387) [Link] (1 responses) Yes there's an analogy in there somewhere but no. Asynchronous code and threaded code have some similarities but are different. Async code is about trying to do cooperative execution in a single thread (and often with little to no runtime support). Threaded code (with language support) typically means a runtime system with a thread scheduler, and some compiler support to implement proper thread pre-emption. In Haskell in particular (which is what I'm familiar with) the compiler doesn't need to make everything async. It compiles to very traditional-looking low level sequential code. The only magic is the compiler inserts yield points (where it anyway has to do stack or heap checks), and yes there is a thread scheduler in the runtime system (and thread synchronisation primitives interact with the scheduler too of course). Turning everything async is a rather different compiler transformation. Posted Dec 2, 2025 21:58 UTC (Tue) by daroc (editor, #160859) [Link] Compare a Rust async function that does some work, and then goes to work on another async function due to an .await, and then finishes its work. That is quite conceptually similar to a Haskell function that does some work, demands another thunk, and then finishes its work. They're really quite similar in that they don't usually involve the runtime, unless there's some multithreading going on or its time for a context switch. In both languages, the operation (.await or forcing a thunk) are theoretically implemented with a call instruction, but can in practice have the compiler inline parts or do them ahead of time if it can prove that they're used later. In both languages, the in-progress state of these things is partly stored in registers and mostly stored in a specific object in memory. I accept that it's not a perfect analogy. There are serious differences between the language, and in particular the GHC runtime's "everything is a function, even data" approach is pretty different from Rust's "everything is data, even async functions" approach. But I also think that it's not a misleading comparison when the language mechanisms are solving similar problems (letting computation occur in an order that doesn't strictly match the order that a traditional strict, imperative language would demand) in a similar way (by using specialized objects in memory that a runtime helps to manage, but that can do basic interactions between objects just by calling through the appropriate function pointer). &lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;code&gt;async&lt;/code&gt; function into any random executor… the functions that do actual work have to match the executor or else the whole things falls apart — and these functions are invisible in Rust's &lt;code&gt;async fn&lt;/code&gt; signature.&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head/&gt; &amp;gt; Async has two relevant API components: futures and wakers. &lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head/&gt; &amp;gt; Two colors because one has "async" and one has not, or one requires a somewhat-special "Io" and one does not. &lt;head&gt;One and a half colors&lt;/head&gt;&lt;code&gt;async&lt;/code&gt; with trivial executor. But if you don't do that the every time you add new executor you make the mess worse: two executors (certain flavor of &lt;code&gt;async&lt;/code&gt; and “sync”) are the typical norm today, three are a mess, try to converge dozen of executors in one app and the whole thing would collapse under its weight.&lt;code&gt;async&lt;/code&gt; functions… and Zig does precise that.&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;One and a half colors&lt;/head&gt;&lt;head&gt;I see what you mean but...&lt;/head&gt;&lt;head&gt;I see what you mean but...&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/SubscriberLink/1046084/4c048ee008e1c70e/"/><published>2025-12-02T14:31:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46121870</id><title>OpenAI declares 'code red' as Google catches up in AI race</title><updated>2025-12-03T15:43:11.991210+00:00</updated><content>&lt;doc fingerprint="bda6ded3906683a6"&gt;
  &lt;main&gt;
    &lt;p&gt;The tides are turning in the AI race, and the pressure is getting to OpenAI. Chief executive Sam Altman reportedly declared a “code red” on Monday, urging staff to improve its flagship product ChatGPT, an indicator that the startup’s once-unassailable lead is eroding as competitors like Google and Anthropic close in.&lt;/p&gt;
    &lt;head rend="h1"&gt;OpenAI declares ‘code red’ as Google catches up in AI race&lt;/head&gt;
    &lt;p&gt;Google’s own ‘code red’ response to ChatGPT has started paying off.&lt;/p&gt;
    &lt;p&gt;Google’s own ‘code red’ response to ChatGPT has started paying off.&lt;/p&gt;
    &lt;p&gt;In the memo, reported by The Wall Street Journal and The Information, Altman said the company will be delaying initiatives like ads, shopping and health agents, and a personal assistant, Pulse, to focus on improving ChatGPT. This includes core features like greater speed and reliability, better personalization, and the ability to answer more questions, he said.&lt;/p&gt;
    &lt;p&gt;There will be a daily call for those tasked with improving the chatbot, the memo said, and Altman encouraged temporary team transfers to speed up development.&lt;/p&gt;
    &lt;p&gt;The newfound urgency illustrates an inflection point for OpenAI as it spends hundreds of billions of dollars to fund growth and figures out a path to future profitability. It is also something of a full-circle moment in the AI race. Google, which declared its own “code red” after the arrival of ChatGPT, is a particular concern. Google’s AI user base is growing — helped by the success of popular tools like the Nano Banana image model — and its latest AI model, Gemini 3, blew past its competitors on many industry benchmarks and popular metrics.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/836212/openai-code-red-chatgpt"/><published>2025-12-02T15:00:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46124267</id><title>Anthropic acquires Bun</title><updated>2025-12-03T15:43:11.796217+00:00</updated><content>&lt;doc fingerprint="3325915d7bc72e5c"&gt;
  &lt;main&gt;
    &lt;p&gt;TLDR: Bun has been acquired by Anthropic. Anthropic is betting on Bun as the infrastructure powering Claude Code, Claude Agent SDK, and future AI coding products &amp;amp; tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;What doesn't change:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bun stays open-source &amp;amp; MIT-licensed&lt;/item&gt;
      &lt;item&gt;Bun continues to be extremely actively maintained&lt;/item&gt;
      &lt;item&gt;The same team still works on Bun&lt;/item&gt;
      &lt;item&gt;Bun is still built in public on GitHub&lt;/item&gt;
      &lt;item&gt;Bun's roadmap will continue to focus on high performance JavaScript tooling, Node.js compatibility &amp;amp; replacing Node.js as the default server-side runtime for JavaScript&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Claude Code ships as a Bun executable to millions of users. If Bun breaks, Claude Code breaks. Anthropic has direct incentive to keep Bun excellent.&lt;/p&gt;
    &lt;head rend="h3"&gt;What changes:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We will help make coding tools like Claude Code &amp;amp; Claude Agent SDK faster &amp;amp; smaller&lt;/item&gt;
      &lt;item&gt;We get a closer first look at what's around the corner for AI coding tools, and make Bun better for it&lt;/item&gt;
      &lt;item&gt;Bun will ship faster.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How Bun started&lt;/head&gt;
    &lt;p&gt;Almost five years ago, I was building a Minecraft-y voxel game in the browser. The codebase got kind of large, and the iteration cycle time took 45 seconds to test if changes worked. Most of that time was spent waiting for the Next.js dev server to hot reload.&lt;/p&gt;
    &lt;p&gt;This was frustrating, and I got really distracted trying to fix it.&lt;/p&gt;
    &lt;p&gt;I started porting esbuild's JSX &amp;amp; TypeScript transpiler from Go to Zig. Three weeks later, I had a somewhat working JSX &amp;amp; TypeScript transpiler.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Early benchmark from a new JavaScript bundler. It transpiles JSX files:&lt;/p&gt;— Jarred Sumner (@jarredsumner) May 5, 2021&lt;lb/&gt;- 3x faster than esbuild&lt;lb/&gt;- 94x faster than swc&lt;lb/&gt;- 197x faster than babel pic.twitter.com/NBRt9ESu2d&lt;/quote&gt;
    &lt;p&gt;I spent much of that first year in a very cramped apartment in Oakland, just coding and tweeting about Bun.&lt;/p&gt;
    &lt;head rend="h4"&gt;The runtime&lt;/head&gt;
    &lt;p&gt;To get Next.js server side rendering to work, we needed a JavaScript runtime. And JavaScript runtimes need an engine to interpret &amp;amp; JIT compile the code.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The start time difference between JavaScriptCore and V8 is interesting. JavaScriptCore seems to start around 4x faster.&lt;/p&gt;— Jarred Sumner (@jarredsumner) May 26, 2021&lt;lb/&gt;It's possible this is due to the specifics of their respective CLIs though (rather than about JavaScript execution) pic.twitter.com/xd5tSbWf6p&lt;/quote&gt;
    &lt;p&gt;So after about a month of reading WebKit's source code trying to figure out how to embed JavaScriptCore with the same flexibility as what Safari does, I had the very initial version of Bun's JavaScript runtime.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v0.1.0&lt;/head&gt;
    &lt;p&gt;Bun v0.1.0 was released in July of 2022. A bundler, a transpiler, a runtime (designed to be a drop-in replacement for Node.js), test runner, and a package manager - all in one. We ended up reaching 20k GitHub stars in the first week.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Introducing Bun - an incredibly fast all-in-one JavaScript runtime. https://t.co/Yt6tAcnBQs&lt;/p&gt;— Jarred Sumner (@jarredsumner) July 5, 2022&lt;/quote&gt;
    &lt;p&gt;Those first two weeks after the release were one of the craziest weeks of my life. My job switched from writing code all day to replying to people all day. We raised a $7 million seed round led by Kleiner Perkins (thanks Bucky &amp;amp; Leigh Marie! And also Shrav Mehta), I took a salary and convinced a handful of engineers to move to San Francisco and help build Bun.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;got keys &amp;amp; desks for oven’s office today pic.twitter.com/bfTmRaF7Oh&lt;/p&gt;— Jarred Sumner (@jarredsumner) October 8, 2022&lt;/quote&gt;
    &lt;head rend="h3"&gt;Bun v1.0.0&lt;/head&gt;
    &lt;p&gt;Bun started to feel more stable, so we shipped Bun v1.0 in September of 2023.&lt;/p&gt;
    &lt;p&gt;Production usage started to pick up and we raised a $19 million Series A led by Khosla Ventures (thanks Nikita &amp;amp; Jon!), grew the team to 14 people and got a slightly larger office.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v1.1&lt;/head&gt;
    &lt;p&gt;After all this time, we still didn't have Windows support. And every day, people asked us the same question: "when will Bun support Windows?"&lt;/p&gt;
    &lt;p&gt;So we added Windows support and called it Bun v1.1. Our Windows support was pretty rough at first, but we've made a lot of progress since then.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v1.2&lt;/head&gt;
    &lt;p&gt;Bun v1.2 made big improvements to Node.js compatibility, added a builtin PostgreSQL client and S3 client. We also started seeing production usage from companies like X and Midjourney. Tailwind's standalone CLI is built with Bun.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun v1.3&lt;/head&gt;
    &lt;p&gt;Bun v1.3 added a builtin frontend dev server, a Redis client, a MySQL client, several improvements to &lt;code&gt;bun install&lt;/code&gt; and improved Node.js compatibility. The real feature: continued increasing production usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI started to get good&lt;/head&gt;
    &lt;p&gt;In late 2024, AI coding tools went from "cool demo" to "actually useful." And a ton of them are built with Bun.&lt;/p&gt;
    &lt;p&gt;Bun's single-file executables turned out to be perfect for distributing CLI tools. You can compile any JavaScript project into a self-contained binary—runs anywhere, even if the user doesn't have Bun or Node installed. Works with native addons. Fast startup. Easy to distribute.&lt;/p&gt;
    &lt;p&gt;Claude Code, FactoryAI, OpenCode, and others are all built with Bun.&lt;/p&gt;
    &lt;head rend="h3"&gt;I got obsessed with Claude Code&lt;/head&gt;
    &lt;p&gt;I started using Claude Code myself. I got kind of obsessed with it.&lt;/p&gt;
    &lt;p&gt;Over the last several months, the GitHub username with the most merged PRs in Bun's repo is now a Claude Code bot. We have it set up in our internal Discord and we mostly use it to help fix bugs. It opens PRs with tests that fail in the earlier system-installed version of Bun before the fix and pass in the fixed debug build of Bun. It responds to review comments. It does the whole thing.&lt;/p&gt;
    &lt;p&gt;This feels approximately a few months ahead of where things are going. Certainly not years.&lt;/p&gt;
    &lt;head rend="h3"&gt;The road ahead&lt;/head&gt;
    &lt;p&gt;Today, Bun makes $0 in revenue.&lt;/p&gt;
    &lt;p&gt;One of the most common questions I get is about sustainability. Questions like:&lt;/p&gt;
    &lt;p&gt;"How does Bun become a business?"&lt;/p&gt;
    &lt;p&gt;"If I bet my work project or company's tech stack on Bun, will it still be around in five or ten years?"&lt;/p&gt;
    &lt;p&gt;Our default answer was always some version of "we'll eventually build a cloud hosting product.", vertically integrated with Bun’s runtime &amp;amp; bundler.&lt;/p&gt;
    &lt;p&gt;But the world when I first started working on Bun is different from the world today. AI coding tools are this massive change to how developers do productive work, and the infrastructure layer matters more when agents are writing code.&lt;/p&gt;
    &lt;p&gt;Forcing ourselves down the prescribed path felt wrong when AI coding tools are getting this good, this fast.&lt;/p&gt;
    &lt;head rend="h3"&gt;The walk&lt;/head&gt;
    &lt;p&gt;We've been prioritizing issues from the Claude Code team for several months now. I have so many ideas all the time and it's really fun. Many of these ideas also help other AI coding products.&lt;/p&gt;
    &lt;p&gt;A few weeks ago, I went on a four hour walk with Boris from the Claude Code team. We talked about Bun. We talked about where AI coding is going. We talked about what it would look like for Bun's team to join Anthropic. Then we did that about 3 more times over the next few weeks. Then I did that with many of their competitors. I think Anthropic is going to win.&lt;/p&gt;
    &lt;p&gt;Betting on Anthropic sounded like a more interesting path. To be in the center of things. To work alongside the team building the best AI coding product.&lt;/p&gt;
    &lt;head rend="h3"&gt;This is a little bit crazy&lt;/head&gt;
    &lt;p&gt;At the time of writing, Bun's monthly downloads grew 25% last month (October, 2025), passing 7.2 million monthly downloads. We had over 4 years of runway to figure out monetization. We didn't have to join Anthropic.&lt;/p&gt;
    &lt;p&gt;Instead of putting our users &amp;amp; community through "Bun, the VC-backed startups tries to figure out monetization" – thanks to Anthropic, we can skip that chapter entirely and focus on building the best JavaScript tooling.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why this makes sense&lt;/head&gt;
    &lt;p&gt;When people ask "will Bun still be around in five or ten years?", answering with "we raised $26 million" isn't a great answer. Investors eventually need a return.&lt;/p&gt;
    &lt;p&gt;But there's a bigger question behind that: what does software engineering even look like in two to three years?&lt;/p&gt;
    &lt;p&gt;AI coding tools are getting really good, really fast and they're using Bun’s single-file executables to ship CLIs and agents that run everywhere.&lt;/p&gt;
    &lt;p&gt;If most new code is going to be written, tested, and deployed by AI agents:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The runtime and tooling around that code become way more important.&lt;/item&gt;
      &lt;item&gt;You get a lot more code overall, written &amp;amp; tested a lot faster.&lt;/item&gt;
      &lt;item&gt;Humans are more detached from every individual line, so the environment it runs in has to be fast and predictable&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bun started with a focus on making developers faster. AI coding tools do a similar thing. It’s a natural fit.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bun joins Anthropic&lt;/head&gt;
    &lt;p&gt;So that's why we're joining Anthropic.&lt;/p&gt;
    &lt;p&gt;Anthropic is investing in Bun as the infrastructure powering Claude Code, Claude Agent SDK, and future AI coding products. Our job is to make Bun the best place to build, run, and test AI-driven software — while continuing to be a great general-purpose JavaScript runtime, bundler, package manager, and test runner.&lt;/p&gt;
    &lt;p&gt;Being part of Anthropic gives Bun:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Long-term stability. a home and resources so people can safely bet their stack on Bun.&lt;/item&gt;
      &lt;item&gt;A front-row seat to where AI coding tools are headed, so we can shape Bun around that future instead of guessing from the outside.&lt;/item&gt;
      &lt;item&gt;More firepower. We’re hiring engineers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And for existing users, the core promise stays the same:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bun remains open-source &amp;amp; MIT-licensed.&lt;/item&gt;
      &lt;item&gt;Bun is still built in public.&lt;/item&gt;
      &lt;item&gt;The same team still works on Bun.&lt;/item&gt;
      &lt;item&gt;We’re still obsessed with making JavaScript and TypeScript faster to install, build, run and test.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anthropic gets a runtime that’s aligned with where software development is going. We get to work on the most interesting version of that future.&lt;/p&gt;
    &lt;p&gt;This is going to be really fun.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frequently asked questions&lt;/head&gt;
    &lt;p&gt;Q: Is Bun still open-source &amp;amp; MIT-licensed?&lt;lb/&gt;A: Yes.&lt;/p&gt;
    &lt;p&gt;Q: Will Bun still be developed in public on GitHub?&lt;lb/&gt;A: Yes. We’ll still be extremely active on GitHub issues &amp;amp; pull requests.&lt;/p&gt;
    &lt;p&gt;Q: Does Bun still care about Node.js compatibility &amp;amp; being a drop-in replacement for Node.js?&lt;lb/&gt;A: Yes.&lt;/p&gt;
    &lt;p&gt;Q: Is the same team still working on Bun full-time?&lt;lb/&gt;A: Yes. And now we get access to the resources of the world’s premier AI Lab instead of a small VC-backed startup making $0 in revenue&lt;/p&gt;
    &lt;p&gt;Q: What does this mean for Bun’s roadmap?&lt;lb/&gt;A: Bun’s team will be working more closely with the Claude Code team, and it probably will look similar to the relationship between Google Chrome &amp;lt;&amp;gt; V8, Safari &amp;lt;&amp;gt; JavaScriptCore, Mozilla Firefox &amp;lt;&amp;gt; SpiderMonkey, but with more independence to prioritize the wide variety of ways people &amp;amp; companies use Bun today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bun.com/blog/bun-joins-anthropic"/><published>2025-12-02T18:05:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46124324</id><title>IBM CEO says there is 'no way' spending on AI data centers will pay off</title><updated>2025-12-03T15:43:11.680990+00:00</updated><content>&lt;doc fingerprint="4f74925d2cffe6ed"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;IBM's CEO walked through some napkin math on data centers— and said that there's "no way" to turn a profit at current costs.&lt;/item&gt;
      &lt;item&gt;"$8 trillion of CapEx means you need roughly $800 billion of profit just to pay for the interest," Arvind Krishna told "Decoder."&lt;/item&gt;
      &lt;item&gt;Krishna was skeptical of that current tech would reach AGI, putting the likelihood between 0-1%.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;AI companies are spending billions on data centers in the race to AGI. IBM CEO Arvind Krishna has some thoughts on the math behind those bets.&lt;/p&gt;
    &lt;p&gt;Data center spending is on the rise. During Meta's recent earnings call, words like "capacity" and AI "infrastructure" were frequently used. Google just announced that it wants to eventually build them in space. The question remains: will the revenue generated from data centers ever justify all the capital expenditure?&lt;/p&gt;
    &lt;p&gt;On the "Decoder" podcast, Krishna concluded that there was likely "no way" these companies would make a return on their capex spending on data centers.&lt;/p&gt;
    &lt;p&gt;Couching that his napkin math was based on today's costs, "because anything in the future is speculative," Kirshna said that it takes about $80 billion to fill up a one-gigawatt data center.&lt;/p&gt;
    &lt;p&gt;"Okay, that's today's number. So, if you are going to commit 20 to 30 gigawatts, that's one company, that's $1.5 trillion of capex," he said.&lt;/p&gt;
    &lt;p&gt;Krishna also referenced the depreciation of the AI chips inside data centers as another factor: "You've got to use it all in five years because at that point, you've got to throw it away and refill it," he said.&lt;/p&gt;
    &lt;p&gt;Investor Michael Burry has recently taken aim at Nvidia over depreciating concerns, leading to a downturn in AI stocks.&lt;/p&gt;
    &lt;p&gt;"If I look at the total commits in the world in this space, in chasing AGI, it seems to be like 100 gigawatts with these announcements," Krishna said.&lt;/p&gt;
    &lt;p&gt;At $80 billion each for 100 gigawatts, that sets Krishna's price tag for computing commitments at roughly $8 trillion.&lt;/p&gt;
    &lt;p&gt;"It's my view that there's no way you're going to get a return on that, because $8 trillion of capex means you need roughly $800 billion of profit just to pay for the interest," he said.&lt;/p&gt;
    &lt;p&gt;Reaching that number of gigawatts has required massive spending from AI companies — and pushes for outside help. In an October letter to the White House's Office of Science and Technology Policy, OpenAI CEO Sam Altman recommended that the US add 100 gigawatts in energy capacity every year.&lt;/p&gt;
    &lt;p&gt;"Decoder" host Nilay Patel pointed out that Altman believed OpenAI could generate a return on its capital expenditures. OpenAI has committed to spending some $1.4 trillion in a variety of deals. Here, Krishna said he diverged from Altman.&lt;/p&gt;
    &lt;p&gt;"That's a belief," Krishna said. "That's what some people like to chase. I understand that from their perspective, but that's different from agreeing with them."&lt;/p&gt;
    &lt;p&gt;Krishna clarified that he wasn't convinced that the current set of technologies would get us to AGI, a yet to be reached technological breakthrough generally agreed to be when AI is capable of completing complex tasks better than humans. He pegged the chances of achieving it without a further technological breakthrough at 0-1%.&lt;/p&gt;
    &lt;p&gt;Several other high-profile leaders have been skeptical of the acceleration to AGI. Marc Benioff said that he was "extremely suspect" of the AGI push, analogizing it to hypnosis. Google Brain founder Andrew Ng said that AGI was "overhyped," and Mistral CEO Arthur Mensch said that AGI was a "marketing move."&lt;/p&gt;
    &lt;p&gt;Even if AGI is the goal, scaling compute may not be the enough. OpenAI cofounder Ilya Sutskever said in November that the age of scaling was over, and that even 100x scaling of LLMs would not be completely transformative. "It's back to the age of research again, just with big computers," he said.&lt;/p&gt;
    &lt;p&gt;Krishna, who began his career at IBM in 1990 before rising to eventually be named CEO in 2020 and chairman in 2021, did praise the current set of AI tools.&lt;/p&gt;
    &lt;p&gt;"I think it's going to unlock trillions of dollars of productivity in the enterprise, just to be absolutely clear," he said.&lt;/p&gt;
    &lt;p&gt;But AGI will require "more technologies than the current LLM path," Krisha said. He proposed fusing hard knowledge with LLMs as a possible future path.&lt;/p&gt;
    &lt;p&gt;How likely is that to reach AGI? "Even then, I'm a 'maybe,'" he said.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.businessinsider.com/ibm-ceo-big-tech-ai-capex-data-center-spending-2025-12"/><published>2025-12-02T18:10:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46126217</id><title>Paged Out</title><updated>2025-12-03T15:43:10.603908+00:00</updated><content>&lt;doc fingerprint="6d2c1466914285af"&gt;
  &lt;main&gt;
    &lt;p&gt;Paged Out! is a free experimental (one article == one page) technical magazine about programming (especially programming tricks!), hacking, security hacking, retro computers, modern computers, electronics, demoscene, and other similar topics.&lt;/p&gt;
    &lt;p&gt;It's made by the community for the community. And it's not-for-profit (though in time, we hope it will be self-sustained) - this means that the issues will always be free to download, share, and print. If you're interested in more details, check our our FAQ and About pages!&lt;/p&gt;
    &lt;p&gt;You can get printed issues at events and print-on-demand bookstores. You'll find more info here.&lt;/p&gt;
    &lt;p&gt;Issue #7 (Oct'25): Best kind of readme&lt;lb/&gt; Download counter: 171102&lt;lb/&gt; Print counter: 1016 (updated manually)&lt;/p&gt;
    &lt;p&gt;Prints:&lt;/p&gt;
    &lt;p&gt;Issue #6 (Mar'25): Stay a while and read&lt;lb/&gt; Download counter: 141974&lt;lb/&gt; Print counter: 2702 (updated manually)&lt;/p&gt;
    &lt;p&gt;Prints:&lt;/p&gt;
    &lt;p&gt;Issue #5 (Nov'24): All your page are belong to us&lt;lb/&gt; Download counter: 105737&lt;/p&gt;
    &lt;p&gt;What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #4 (Jun'24): The epic Paged Out! story continues&lt;lb/&gt; Download counter: 117173&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #3 (Dec'23): The resurrected Paged Out!&lt;lb/&gt; Download counter: 122908&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #2 (Nov'19): The second Paged Out!&lt;lb/&gt; Download counter: 127813&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta 2 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Issue #1 (Aug'19): The first Paged Out! issue has arrived!&lt;lb/&gt; Download counter: 261494&lt;lb/&gt; Print counter: 500 (updated manually)&lt;/p&gt;
    &lt;p&gt;Note: This is a "beta 1 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:&lt;/p&gt;
    &lt;p&gt;Additionally, here's another Paged Out! wallpaper by ReFiend:&lt;/p&gt;
    &lt;p&gt;If you like our work, how about writing an article for Paged Out!? It's only one page after all - easy. ;)&lt;/p&gt;
    &lt;p&gt; Next issue progress tracker (unit of measurement: article count):&lt;/p&gt;
    &lt;p&gt;Sure! There are a couple of ways to get notified when the issue will be out:&lt;/p&gt;
    &lt;p&gt;We will only send e-mails to this group about new Paged Out! issues (both the free electronic ones and special issues if we ever get to that). No spam will be sent there and (if you subscribe to the group) your e-mail will be visible only to group owners.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pagedout.institute"/><published>2025-12-02T20:14:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130335</id><title>Interview with RollerCoaster Tycoon's Creator, Chris Sawyer (2024)</title><updated>2025-12-03T15:43:10.528232+00:00</updated><content/><link href="https://medium.com/atari-club/interview-with-rollercoaster-tycoons-creator-chris-sawyer-684a0efb0f13"/><published>2025-12-03T04:32:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130784</id><title>Quad9 DOH HTTP/1.1 Retirement, December 15, 2025</title><updated>2025-12-03T15:43:10.103486+00:00</updated><content>&lt;doc fingerprint="3d0d1bd2c90733d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;DOH HTTP/1.1 Retirement December 15, 2025&lt;/head&gt;
    &lt;head rend="h1"&gt;Summary&lt;/head&gt;
    &lt;p&gt;Quad9 will be discontinuing support within DNS-over-HTTPS (DOH) using HTTP/1.1 on December 15, 2025. This should have no impact on most users, but there are some older or non-compliant devices or software which may be unsupported after that time with DOH and which will have to revert to unencrypted DNS or shift to DNS-over-TLS.&lt;/p&gt;
    &lt;head rend="h1"&gt;Background&lt;/head&gt;
    &lt;p&gt;Quad9 was the first large-scale recursive resolver to offer standards-based encryption (DNS-over-TLS in 2017). We also provide DNS-over-HTTPS (DOH) as an encryption method, which has been slowly increasing as a percentage of our traffic since standardization and our inclusion of that protocol in 2018. Browsers have been the primary devices operating with DOH, which has some benefits: browsers are updated frequently and are typically kept up to date with newer standards.&lt;/p&gt;
    &lt;p&gt;The DOH standard recommends HTTP/2 as the lowest version of the protocol for use for DOH (https://datatracker.ietf.org/doc/html/rfc8484#section-5.2) but does not rule out using the older HTTP/1.1 standard. We have supported both HTTP/1.1 and HTTP/2 since our inclusion of DOH in our protocol stack seven years ago. However, we are reaching the end of life for the libraries and code that support HTTP/1.1 in our production environment and, therefore, will be sunsetting support for DOH over HTTP/1.1 on December 15, 2025.Â&lt;/p&gt;
    &lt;head rend="h1"&gt;Are you affected?&lt;/head&gt;
    &lt;p&gt;This sunsetting of HTTP/1.1 should not be noticed by the vast majority of our user community who are using Chrome (or any Chromium-based browser or stack), Firefox or Firefox forked projects, Safari (and to our knowledge all other Apple products/apps), or Android and iOS operating systems. They are all fully compliant with our existing and future DOH implementations and, to our knowledge, have always been compliant.&lt;/p&gt;
    &lt;p&gt;If your platform does not work without the older HTTP/1.1 protocol, then we would suggest you upgrade your system or shift to DNS-over-TLS which does not have an HTTP layer. There is always the possibility of moving to unencrypted DNS, but that decision should be closely considered as a downgrade of security and needs to be made carefully if you are in a network environment of higher risk.&lt;/p&gt;
    &lt;p&gt;The only platform that we are aware of directly that has ever used HTTP/1.1 and which will stop working after the sunset date are MikroTik devices that have been configured to use DNS-over-HTTPS, as those devices do not support the modern and recommended HTTP/2 transport protocol. We have communicated this to MikroTik on their support forum (https://forum.mikrotik.com/t/quad9-to-drop-support-for-http-1-1/264174/4), but there has not yet been an announcement by MikroTik as to when they will update their software to this more recent standard. Other than MikroTik, we have no specific knowledge of any other HTTP/1.1 devices or libraries with sizable user communities, though that does not mean there are no IOT devices or software libraries which are using that method.&lt;/p&gt;
    &lt;p&gt;From a geographic perspective, there is a community of users in Brazil who are on HTTP/1.1 which we believe to be MikroTik-based. Due to the fact that we cannot associate queries with users (or even one query with another) it is not easily possible for us to determine what types of devices these are, if not MikroTik, nor is it possible for us to inform those users about the impending change as by design we do not know who they are. We welcome any comments from our Brazilian community from knowledgeable users who can enlighten us as to the reasons for this geographic concentration (please contact support@quad9.net with details).&lt;/p&gt;
    &lt;head rend="h1"&gt;Our Reasoning&lt;/head&gt;
    &lt;p&gt;Despite our large geographic footprint and sizable user community, Quad9 remains a relatively small team. Our limited development efforts are better spent on bringing new features and core stability support to the Quad9 community, and we cannot justify the expense of integrating backwards compatibility for clients that are not meeting the recommended minimum version of protocols. HTTP/2 has been the recommended standard since the publication of the Request for Comments, and we believe this minimization of code is a reasonable step to take when compared with the costs and complexity of backwards compatibility development. In addition, HTTP/1.1 has significant speed and scale challenges, and as time progresses it may be the case that leaving it in our stack would introduce edge-case security or DOS attack vectors which would be difficult to discover and expensive to keep in our testing models.&lt;/p&gt;
    &lt;p&gt;The update allows us to move forward with additional, newer protocol support that we have been testing, which is ready for deployment and is part of a general refresh of our entire platform and system stack. We will have more flexibility and additional protocol support (keep watching this blog area for details), and the refresh also allows us to take better advantage of newer server hardware that we have been deploying worldwide to continue keeping pace with adoption rates.&lt;/p&gt;
    &lt;p&gt;We recognize this will cause inconvenience for some subset of users, and many users will not be aware of the change before it is applied as there is no assured direct method for us to communicate with our end users. This is the double-edged sword of not storing user data: we cannot directly notify everyone of changes.&lt;/p&gt;
    &lt;p&gt;If you know someone who will be impacted, please share and encourage them to take the necessary steps now to avoid interruption of service.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://quad9.net/news/blog/doh-http-1-1-retirement/"/><published>2025-12-03T06:07:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46130907</id><title>Researchers Find Microbe Capable of Producing Oxygen from Martian Soil</title><updated>2025-12-03T15:43:09.337602+00:00</updated><content>&lt;doc fingerprint="a38e904b38a1646a"&gt;
  &lt;main&gt;
    &lt;p&gt;When we talk about the possibility of humans living on Mars, one of the biggest challenges is not the rockets or the habitats, but something far more basic: how to breathe. Carrying oxygen tanks across space is not practical for long-term survival. This is where a tiny microbe might make a huge difference.&lt;/p&gt;
    &lt;p&gt;Scientists have been studying an extremophile, a type of microorganism that can survive in very harsh environments. This particular one is known as Chroococcidiopsis. It has shown the ability to grow on materials that are similar to Martian soil, and in the process, it produces oxygen. That means if it can be cultivated in future Mars colonies, it could support human breathing needs directly on the Red Planet.&lt;/p&gt;
    &lt;p&gt;Researchers tested this by using soil that mimics Martian regolith. The results were promising. The bacteria did not just survive, it actively thrived, pulling nutrients from the soil and releasing oxygen as part of its natural process. What makes it even more interesting is that it does not require rich Earth-like soil to function. Even in the limited resources available on Mars, it can manage to carry out its work.&lt;/p&gt;
    &lt;p&gt;Also Read: Mars Ice Could Preserve Traces of Ancient Life, Study Suggests&lt;/p&gt;
    &lt;p&gt;The experiments also showed that these microbes can survive extreme conditions such as radiation and low pressure that would normally be deadly to most life. Even when their DNA was damaged by radiation, they were able to repair it after rehydration and continue functioning normally, with no lasting increase in mutations. This resilience is what defines them as extremophiles, organisms that have evolved to survive where most others cannot.&lt;/p&gt;
    &lt;p&gt;For space scientists and planners, this is a big step. If humans ever build bases on Mars, they will need systems that can provide oxygen without constant resupply from Earth. Carrying oxygen would be costly and dangerous, while producing it locally would make settlements more realistic. A living system using microbes might offer a natural and renewable source.&lt;/p&gt;
    &lt;p&gt;This does not mean the problem is solved. There are still challenges ahead. One is how to grow these organisms at scale in Martian conditions. Another is how to protect them and keep them productive in an environment that is far more unstable than Earth. But the fact that they can survive in laboratory simulations of Mars is an important first step.&lt;/p&gt;
    &lt;p&gt;There is also a wider question. If such microbes can survive on Mars-like conditions, does that mean life could exist elsewhere in the solar system? Extremophiles on Earth already show us that life can adapt to the most unlikely places — from boiling hot springs to the depths of ice. This experiment adds to the evidence that life is resilient and flexible.&lt;/p&gt;
    &lt;p&gt;For now, the practical focus remains on human needs. Space agencies and researchers are interested in creating closed-loop systems where food, water, and oxygen can all be recycled and produced on site. Using microbes for oxygen production could become one part of that system.&lt;/p&gt;
    &lt;p&gt;It is too early to say whether this specific cyanobacterium will be the final answer. But it shows a direction for research and gives hope that we may not need to carry every breath of oxygen from Earth. Instead, we may be able to “farm” our oxygen directly on another planet.&lt;/p&gt;
    &lt;p&gt;Story Source: Universe Today&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scienceclock.com/microbe-that-could-turn-martian-dust-into-oxygen/"/><published>2025-12-03T06:34:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46131406</id><title>Zig quits GitHub, says Microsoft's AI obsession has ruined the service</title><updated>2025-12-03T15:43:09.137486+00:00</updated><content>&lt;doc fingerprint="8e14b4d14f364afe"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Zig quits GitHub, says Microsoft's AI obsession has ruined the service&lt;/head&gt;
    &lt;head rend="h2"&gt;Zig prez complains about 'vibe-scheduling' after safe sleep bug goes unaddressed for eons&lt;/head&gt;
    &lt;p&gt;The Foundation that promotes the Zig programming language has quit GitHub due to what its leadership perceives as the code sharing site's decline.&lt;/p&gt;
    &lt;p&gt;The drama began in April 2025 when GitHub user AlekseiNikiforovIBM started a thread titled “safe_sleep.sh rarely hangs indefinitely.” GitHub addressed the problem in August, but didn’t reveal that in the thread, which remained open until Monday.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The code uses 100 percent CPU all the time, and will run forever&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That timing appears notable. Last week, Andrew Kelly, president and lead developer of the Zig Software Foundation, announced that the Zig project is moving to Codeberg, a non-profit git hosting service, because GitHub no longer demonstrates commitment to engineering excellence.&lt;/p&gt;
    &lt;p&gt;One piece of evidence he offered for that assessment was the “safe_sleep.sh rarely hangs indefinitely” thread.&lt;/p&gt;
    &lt;p&gt;"Most importantly, Actions has inexcusable bugs while being completely neglected," Kelly wrote. "After the CEO of GitHub said to 'embrace AI or get out', it seems the lackeys at Microsoft took the hint, because GitHub Actions started 'vibe-scheduling' – choosing jobs to run seemingly at random. Combined with other bugs and inability to manually intervene, this causes our CI system to get so backed up that not even master branch commits get checked."&lt;/p&gt;
    &lt;head rend="h3"&gt;Older and deeper&lt;/head&gt;
    &lt;p&gt;Kelly’s gripe seems justified, as the bug discussed in the thread appears to have popped up following a code change in February 2022 that users flagged in prior bug reports.&lt;/p&gt;
    &lt;p&gt;The code change replaced instances of the posix "sleep" command with a "safe_sleep" script that failed to work as advertised. It was supposed to allow the GitHub Actions runner – the application that runs a job from a GitHub Actions workflow – to pause execution safely.&lt;/p&gt;
    &lt;p&gt;"The bug in this 'safe sleep' script is obvious from looking at it: if the process is not scheduled for the one-second interval in which the loop would return (due to $SECONDS having the correct value), then it simply spins forever," wrote Zig core developer Matthew Lugg in a comment appended to the April bug thread.&lt;/p&gt;
    &lt;p&gt;"That can easily happen on a CI machine under extreme load. When this happens, it's pretty bad: it completely breaks a runner until manual intervention. On Zig's CI runner machines, we observed multiple of these processes which had been running for hundreds of hours, silently taking down two runner services for weeks."&lt;/p&gt;
    &lt;p&gt;The fix was merged on August 20, 2025, from a separate issue opened back in February 2024. The related bug report from April 2025 remained open until Monday, December 1, 2025. A separate CPU usage bug remains unresolved.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsoft appears to move on from its most loyal 'customers' – Contoso and Fabrikam&lt;/item&gt;
      &lt;item&gt;UK gov blames budget leak on misconfigured WordPress plugin, server&lt;/item&gt;
      &lt;item&gt;Google Antigravity vibe-codes user's entire drive out of existence&lt;/item&gt;
      &lt;item&gt;OpenAI cuts off Mixpanel after analytics leak exposes API users&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Jeremy Howard, co-founder of Answer.AI and Fast.AI, said in a series of social media posts that users’ claims about GitHub Actions being in a poor state of repair appear to be justified.&lt;/p&gt;
    &lt;p&gt;"The bug," he wrote, "was implemented in a way that, very obviously to nearly anyone at first glance, uses 100 percent CPU all the time, and will run forever unless the task happens to check the time during the correct second."&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I can't see how such an extraordinary collection of outright face-palming events could be made&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;He added that the platform-independent fix for the CPU issue proposed last February lingered for a year without review and was closed by the GitHub bot in March 2025 before being revived and merged.&lt;/p&gt;
    &lt;p&gt;"Whilst one could say that this is just one isolated incident, I can't see how such an extraordinary collection of outright face-palming events could be made in any reasonably functioning organization," Howard concluded.&lt;/p&gt;
    &lt;p&gt;GitHub did not immediately respond to a request for comment.&lt;/p&gt;
    &lt;p&gt;While Kelly has gone on to apologize for the incendiary nature of his post, Zig is not the only software project publicly parting ways with GitHub.&lt;/p&gt;
    &lt;p&gt;Over the weekend, Rodrigo Arias Mallo, creator of the Dillo browser project, said he's planning to move away from GitHub owing to concerns about over-reliance on JavaScript, GitHub's ability to deny service, declining usability, inadequate moderation tools, and "over-focusing on LLMs and generative AI, which are destroying the open web (or what remains of it) among other problems."&lt;/p&gt;
    &lt;p&gt;Codeberg, for its part, has doubled its supporting membership since January, going from more than 600 members to over 1,200 as of last week.&lt;/p&gt;
    &lt;p&gt;GitHub has not disclosed how many of its users pay for its services presently. The code hosting biz had "over 1.3 million paid GitHub Copilot subscribers, up 30 percent quarter-over-quarter," Microsoft CEO Satya Nadella said on the company's Q2 2024 earnings call.&lt;/p&gt;
    &lt;p&gt;In Q4 2024, when GitHub reported an annual revenue run rate of $2 billion, GitHub Copilot subscriptions accounted for about 40 percent of the company's annual revenue growth.&lt;/p&gt;
    &lt;p&gt;Nadella offered a different figure during Microsoft's Q3 2025 earnings call: "we now have over 15 million GitHub Copilot users, up over 4X year-over-year." It's not clear how many GitHub users pay for Copilot, or for runner scripts that burned CPU cycles when they should have been sleeping. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2025/12/02/zig_quits_github_microsoft_ai_obsession/"/><published>2025-12-03T07:52:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46132531</id><title>Anthropic reportedly preparing for $300B IPO</title><updated>2025-12-03T15:43:08.984359+00:00</updated><content>&lt;doc fingerprint="3b1ce32d7bba0f70"&gt;
  &lt;main&gt;
    &lt;p&gt;San Francisco-based Anthropic has asked Wilson Sonsini Goodrich &amp;amp; Rosati to begin work on an initial public offering (IPO) that could take place as early as 2026, the Financial Times reported this week.&lt;/p&gt;
    &lt;p&gt;The move positions the company, best known for its Claude chatbot, to reach the stock market ahead of rival OpenAI and would test investors’ willingness to fund large, loss-making artificial-intelligence labs. People familiar with the plans cautioned that discussions with investment banks remain informal and that no underwriting line-up has been chosen.&lt;/p&gt;
    &lt;p&gt;Wilson Sonsini, which advised Anthropic on its multibillion-dollar investment agreements with Amazon and Google, has previously guided Google, LinkedIn and Lyft to market.&lt;/p&gt;
    &lt;p&gt;In a statement, an Anthropic spokesperson said: “We have not made any decisions about when, or even whether, to go public.”&lt;/p&gt;
    &lt;p&gt;The IPO preparations coincide with a private fundraising round that could value Anthropic above $300 billion. Microsoft and Nvidia have jointly committed $15 billion to that round, according to the Financial Times, while Anthropic has pledged to spend $30 billion on Microsoft’s cloud platform over the next four years. A previous funding round this autumn pegged the company at roughly $183 billion.&lt;/p&gt;
    &lt;p&gt;Chief executive Dario Amodei has told investors that annualised revenue could rise to $26 billion next year, triple this year’s run-rate, as the customer base expands beyond 300,000 businesses.&lt;/p&gt;
    &lt;p&gt;Internal changes aimed at satisfying public-market requirements are already under way. Last year Anthropic hired Airbnb’s former head of corporate finance, Krishna Rao, as chief financial officer and has since worked through governance, accounting and disclosure checklists, one source said.&lt;/p&gt;
    &lt;p&gt;OpenAI, valued at about $500 billion after a recent share sale, is conducting similar early-stage work but chief financial officer Sarah Friar said last month that a listing is “not in the near-term plan.”&lt;/p&gt;
    &lt;p&gt;Both companies face the challenge of forecasting profits while spending heavily on model training and infrastructure. Anthropic recently announced a $50 billion build-out of data centres in Texas and New York and plans to triple its global workforce.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vechron.com/2025/12/anthropic-hires-wilson-sonsini-ipo-2026-openai-race/"/><published>2025-12-03T09:53:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133068</id><title>India scraps order to pre-install state-run cyber safety app on smartphones</title><updated>2025-12-03T15:43:08.743220+00:00</updated><content>&lt;doc fingerprint="ec1e939cfca1d778"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;India scraps order to pre-install state-run cyber safety app on smartphones&lt;/head&gt;
    &lt;p&gt;India has scrapped an order making it mandatory for smartphone makers to preload a state-run cyber safety app on new phones after a public furore.&lt;/p&gt;
    &lt;p&gt;The order gave smartphone makers 90 days to pre-load new phones with its new Sanchar Saathi app which could not be "disabled or restricted", sparking privacy and surveillance concerns.&lt;/p&gt;
    &lt;p&gt;The government argued the move was necessary to verify the authenticity of handsets, but cybersecurity experts said it impinged on citizens' right to privacy.&lt;/p&gt;
    &lt;p&gt;Withdrawing the order on Wednesday, the government cited the app's "increasing acceptance". It came after Apple and Samsung had reportedly resisted the directive to pre-install it on their devices.&lt;/p&gt;
    &lt;p&gt;So far 14 million users have downloaded the app, reporting 2,000 frauds daily, and on Tuesday alone 600,000 new users registered - a tenfold spike, according to India's telecom ministry.&lt;/p&gt;
    &lt;p&gt;But the order - passed last week but made public on Monday - to make the registration mandatory had led to a major backlash from several cybersecurity experts.&lt;/p&gt;
    &lt;p&gt;Smartphone giants like Apple and Samsung also resisted the directive to pre-install the app on their phones.&lt;/p&gt;
    &lt;p&gt;Sources told the BBC the companies were concerned the directive was issued without prior consultation and challenged user privacy norms.&lt;/p&gt;
    &lt;p&gt;While the order has now been withdrawn, India's Minister of Communications Jyotiraditya Scindia dismissed concerns that the app could be used to increase surveillance.&lt;/p&gt;
    &lt;p&gt;"Snooping is neither possible nor will it happen with the Sanchar Saathi safety app," Scindia said.&lt;/p&gt;
    &lt;p&gt;The government's decision to reverse the order was welcomed by digital advocacy groups.&lt;/p&gt;
    &lt;p&gt;"This is a welcome development, but we are still awaiting the full text of the legal order that should accompany this announcement, including any revised directions under the Cyber Security Rules, 2024," the Internet Freedom Foundation said on X.&lt;/p&gt;
    &lt;p&gt;"For now, we should treat this as cautious optimism, not closure, until the formal legal direction is published and independently confirmed."&lt;/p&gt;
    &lt;p&gt;Follow BBC News India on Instagram, YouTube, Twitter and Facebook.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/clydg2re4d1o"/><published>2025-12-03T11:06:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133422</id><title>The "Mad Men" in 4K on HBO Max Debacle</title><updated>2025-12-03T15:43:08.632510+00:00</updated><content>&lt;doc fingerprint="212590f01322d0f9"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Reader warning: there's gonna be a lot of pretend puke photos in this post.&lt;/p&gt;
      &lt;p&gt;If you've fired up HBO Max recently, you've probably seen that one of the most influential and prestigious television series of all time was to premiere in 4K on the streaming service. The show's first four seasons were shot on film, and the final three were shot digitally on the Alexa, but the run of the series was mastered in 1080p HD. HBO Max has been touting this 4K "restoration" of the series, produced by Lionsgate TV. &lt;/p&gt;
      &lt;p&gt;The highly anticipated 4K debut of the show was to be one of HBO Max' crown jewels of television history. It looks like it might initially serve as a cautionary tale of quality control when it comes to restorations and the technical process of bringing shows to streaming.&lt;/p&gt;
      &lt;div&gt;&lt;p&gt;As far as I can tell, &lt;/p&gt;Paul Haine was the first to notice something weird&lt;p&gt; going on with HBO Max' presentation. In one of season one's most memorable moments, Roger Sterling barfs in front of clients after climbing many flights of stairs. As a surprise to Paul, you can clearly see the pretend puke hose (that is ultimately strapped to the back side of John Slattery's face) in the background, along with two techs who are modulating the flow. Yeah, you're not supposed to see that.&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;It appears as though this represents the original photography, unaltered before digital visual effects got involved. Somehow, this episode (along with many others) do not include all the digital visual effects that were in the original broadcasts and home video releases. It's a bizarro mistake for Lionsgate and HBO Max to make and not discover until after the show was streaming to customers.&lt;/p&gt;
      &lt;div&gt;&lt;p&gt;I want to be clear that this is a separate issue than the "reframed original film negative for 16:9" issue that has plagued many restorations that have left viewers scratching their heads. In those cases, the shows were originally shot on film and presented in 1.33-to-1 aspect ratio, but for their HD restorations the studio decided that their shows should fill the HD frame at the 16:9 aspect ratio, so portions of the negative, previously unseen and NOT intended for broadcast, were now suddenly visible, &lt;/p&gt;sometimes leading to ridiculous images that were never meant to be seen by audiences&lt;p&gt;...&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;example from "Friends" in HD, look at screen right&lt;/p&gt;
      &lt;p&gt;example from "Seinfeld" in HD&lt;/p&gt;
      &lt;p&gt;Reframing old shows to fit a new aspect ratio is antithetical to the spirit of media restoration, and cheapens the future of our shared culture. The folks at the studios who insist on hobbling their most classic television shows are really bad at their jobs.&lt;/p&gt;
      &lt;p&gt;But that's NOT what is going on with "Mad Men", since the show was mastered in 16:9 to begin with. &lt;/p&gt;
      &lt;div&gt;I decided to help illustrate the changes&lt;p&gt; by diving in and creating images that might do better than words. The first thing I noticed is that, at least for season one, the episode titles and order were totally jumbled. The puke episode is "Red in the Face", not "Babylon".&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;Update: the season one episodes are being updated live on HBO Max to their correct positions and titles. The corrected title:&lt;/p&gt;
      &lt;p&gt;I lined up the Blu-ray edition of the episode with the current HBO Max episode:&lt;/p&gt;
      &lt;p&gt;The fun thing about this restoration mistake is that now we, the audience, get to see exactly how many digital visual effects were actually used in a show like "Mad Men", which most would assume did not have any digital effects component. In this shot, not only were the techs and hose removed, but the spot where the pretend puke meets Slattery's face has some clever digital warping to make it seem like the flow is truly coming from his mouth (as opposed to it appearing through a tube inches from his mouth, on the other side of his face).&lt;/p&gt;
      &lt;div&gt;A Twitter user noticed&lt;p&gt; that the post-production screwups are not exclusive to season one, so I fired up my comparison machine to illustrate it.&lt;/p&gt;&lt;/div&gt;
      &lt;p&gt;In this case, visual effects was used to obscure the fact that the show was filmed in 2000's era Los Angeles, not in 1960's New York City. Every sign was altered, and period-appropriate garbage NYC garbage cans were also added to each side of the frame.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://fxrant.blogspot.com/2025/12/the-mad-men-in-4k-on-hbo-max-debacle.html"/><published>2025-12-03T11:50:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46133622</id><title>You Can't Fool the Optimizer</title><updated>2025-12-03T15:43:08.340323+00:00</updated><content>&lt;doc fingerprint="a429e90ffa511a5c"&gt;
  &lt;main&gt;
    &lt;p&gt;Written by me, proof-read by an LLM. &lt;lb/&gt;Details at end.&lt;/p&gt;
    &lt;p&gt;Sometimes you’ll step through code in a debugger and find a complex-looking loop… that executes as a single instruction. The compiler saw through the obfuscation and generated the obvious code anyway.&lt;/p&gt;
    &lt;p&gt;Consider this assortment of highly questionable unsigned addition routines1 - for variety, here compiled for ARM (unlike yesterday’s addition example).&lt;/p&gt;
    &lt;p&gt;Despite these all being very different ways of returning &lt;code&gt;x + y&lt;/code&gt;, the compiler sees through it all and recognises that it’s just a single &lt;code&gt;add w0, w1, w0&lt;/code&gt;2 instruction. Even the recursive &lt;code&gt;add_v4&lt;/code&gt; - which calls itself - gets optimised down to the same single instruction3.&lt;/p&gt;
    &lt;p&gt;The compiler’s ability to recognise patterns and replace them with efficient alternatives - even when the code is pretty obfuscated - is a superpower. It lets programmers choose how to write their code that’s intention-revealing (not like these contrived examples, obviously!) and leave the code generation up to the compiler, knowing that most of the time it’ll do the right thing.&lt;/p&gt;
    &lt;p&gt;So how does the compiler spot these patterns? Is it maintaining a database of “silly ways to add numbers”? Not quite. Internally, it translates your code into an intermediate representation - a simplified, abstract form that’s easier to analyse. When the compiler sees the while loop in &lt;code&gt;add_v3&lt;/code&gt;, it transforms it into something like “increment y by x, then return y”, which it then recognises as mathematically equivalent to “return x + y”. This process of converting different code patterns into a standard, canonical form is what lets the compiler treat them all identically. By the time code generation happens, all four functions look the same to the optimiser4.&lt;/p&gt;
    &lt;p&gt;This pattern recognition is remarkably robust - the compiler will happily optimise code you’d never want to write in the first place. Throughout this series we’ll see how far this canonicalisation can take us.&lt;/p&gt;
    &lt;p&gt;See the video that accompanies this post.&lt;/p&gt;
    &lt;p&gt;This post is day 3 of Advent of Compiler Optimisations 2025, a 25-day series exploring how compilers transform our code.&lt;/p&gt;
    &lt;p&gt;This post was written by a human (Matt Godbolt) and reviewed and proof-read by LLMs and humans.&lt;/p&gt;
    &lt;p&gt;Support Compiler Explorer on Patreon or GitHub, or by buying CE products in the Compiler Explorer Shop.&lt;/p&gt;
    &lt;p&gt;Thanks to long-term Compiler Explorer Patron Greg Baker for this example. ↩&lt;/p&gt;
    &lt;p&gt;ARM supports three operands, so you should read this as &lt;code&gt;w0 = w1 + w0&lt;/code&gt;. ↩&lt;/p&gt;
    &lt;p&gt;We’ll cover tail-call optimisation and how it enables this later in the series. ↩&lt;/p&gt;
    &lt;p&gt;You can “Open in Compiler Explorer” the example above and then experiment with the “Opt Pipeline Viewer” to see some of the ways the compiler is doing this. ↩&lt;/p&gt;
    &lt;p&gt;Matt Godbolt is a C++ developer living in Chicago. He works for Hudson River Trading on super fun but secret things. He is one half of the Two's Complement podcast. Follow him on Mastodon or Bluesky.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xania.org/202512/03-more-adding-integers"/><published>2025-12-03T12:14:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46134178</id><title>Helldivers 2 devs slash install size from 154GB to 23GB</title><updated>2025-12-03T15:43:08.053595+00:00</updated><content>&lt;doc fingerprint="bc95de9f0a9456a3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Helldivers 2 devs slash install size from 154GB to 23GB, thanks to the help of PC port veterans — ditching HDD optimization, 85% size reduction accomplished by de-duplicating game data&lt;/head&gt;
    &lt;p&gt;PC players can now opt into a slim version that’s 85% smaller.&lt;/p&gt;
    &lt;p&gt;It's no surprise to see modern AAA games occupying hundreds of gigabytes of storage these days, especially if you are gaming on a PC. But somehow, Arrowhead Game Studios, the developers behind the popular co-op shooter Helldivers 2, have managed to substantially cut the game’s size by 85%.&lt;/p&gt;
    &lt;p&gt;As per a recent post on Steam, this reduction was made possible with support from Nixxes Software, best known for developing high-quality PC ports of Sony’s biggest PlayStation titles. The developers were able to achieve this by de-duplicating game data, which resulted in bringing the size down from ~154GB to just ~23GB, saving a massive ~131GB of storage space.&lt;/p&gt;
    &lt;p&gt;Originally, the game’s large install size was attributed to optimization for mechanical hard drives since duplicating data is used to reduce loading times on older storage media. However, it turns out that Arrowhead’s estimates for load times on HDDs, based on industry data, were incorrect.&lt;/p&gt;
    &lt;p&gt;With their latest data measurements specific to the game, the developers have confirmed the small number of players (11% last week) using mechanical hard drives will witness mission load times increase by only a few seconds in worst cases. Additionally, the post reads, “the majority of the loading time in Helldivers 2 is due to level-generation rather than asset loading. This level generation happens in parallel with loading assets from the disk and so is the main determining factor of the loading time.”&lt;/p&gt;
    &lt;p&gt;This is a promising development and a nudge to other game developers to take some notes and potentially make an effort in saving precious storage space for PC gamers.&lt;/p&gt;
    &lt;p&gt;One can access the ‘slim’ version of Helldivers 2 by opting in to the latest beta update via Steam, which is said to functionally offer the same experience as the legacy versions, apart from its smaller installation size. All progression, war contributions, and purchases are also expected to be carried over to the new slim version. There's also the option to opt out of the beta at any time in case there are any potential issues.&lt;/p&gt;
    &lt;p&gt;Follow Tom's Hardware on Google News, or add us as a preferred source, to get our latest news, analysis, &amp;amp; reviews in your feeds.&lt;/p&gt;
    &lt;p&gt;Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.&lt;/p&gt;
    &lt;p&gt;Kunal Khullar is a contributing writer at Tom’s Hardware. He is a long time technology journalist and reviewer specializing in PC components and peripherals, and welcomes any and every question around building a PC.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;header&gt;hotaru251&lt;/header&gt;i mean...its 2025...almost 2026 just accept that HDD for gaming is not gonna cut it. You can buy a 500GB ssd for sub $50.Reply&lt;lb/&gt;Don't be like the windows OS and drag dead weight (32bit x86) that holds you back.&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;Gururu&lt;/header&gt;Having the option is key. I wonder if every other +100GB game has the same accommodations.Reply&lt;/item&gt;
      &lt;item&gt;&lt;header&gt;gggplaya&lt;/header&gt;If you're a pc gamer in 2025, you should SSD's should be minimum spec for all AAA titles. I bought a 256GB SATA SSD for $20 years ago. You can get 256GB Sata SSD's on ebay for $15 now. I mean common, it's cheaper than most AAA titles. Even consoles are SSD only now.Reply&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.tomshardware.com/video-games/pc-gaming/helldivers-2-install-size-slashed-from-154gb-to-just-23gb-85-percent-reduction-accomplished-by-de-duplicating-game-data-an-optimization-for-older-mechanical-hard-drives"/><published>2025-12-03T13:20:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46134443</id><title>Congressional lawmakers 47% pts better at picking stocks</title><updated>2025-12-03T15:43:07.649041+00:00</updated><content>&lt;doc fingerprint="3ab211afd411b7b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;"Captain Gains" on Capitol Hill&lt;/head&gt;
    &lt;p&gt; Working Paper 34524 &lt;/p&gt;
    &lt;p&gt; DOI 10.3386/w34524 &lt;/p&gt;
    &lt;p&gt; Issue Date &lt;/p&gt;
    &lt;p&gt;Using transaction-level data on US congressional stock trades, we find that lawmakers who later ascend to leadership positions perform similarly to matched peers beforehand but outperform them by 47 percentage points annually after ascension. Leaders’ superior performance arises through two mechanisms. The political influence channel is reflected in higher returns when their party controls the chamber, sales of stocks preceding regulatory actions, and purchase of stocks whose firms receiving more government contracts and favorable party support on bills. The corporate access channel is reflected in stock trades that predict subsequent corporate news and greater returns on donor-owned or home-state firms.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Copy CitationShang-Jin Wei and Yifan Zhou, ""Captain Gains" on Capitol Hill," NBER Working Paper 34524 (2025), https://doi.org/10.3386/w34524.Download Citation&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nber.org/papers/w34524"/><published>2025-12-03T13:50:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46134991</id><title>GSWT: Gaussian Splatting Wang Tiles</title><updated>2025-12-03T15:43:06.988981+00:00</updated><content>&lt;doc fingerprint="ea89769d8f9682b6"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;GSWT: Gaussian Splatting Wang Tiles&lt;/head&gt;&lt;head rend="h2"&gt;Abstract&lt;/head&gt;&lt;p&gt;3D Gaussian Splatting (3DGS) has shown strong capability in reconstructing and rendering photorealistic 3D scenes with high efficiency. However, extending 3DGS to synthesize large-scale or infinite terrains from a single captured exemplar—remains an open challenge. In this paper, we propose a tile-based framework that addresses this problem. Our method builds on Wang Tiles, where each tile encodes a local field of Gaussians with boundary constraints to ensure seamless transitions. This enables stochastic yet continuous tiling of Gaussian fields over arbitrary surfaces, allowing for procedural generation of expansive terrains with high spatial diversity. Furthermore, we introduce several rendering optimizations tailored to the unique characteristics of 3DGS Wang tiles, achieving real-time rendering of large-scale 3DGS terrains.&lt;/p&gt;&lt;head rend="h2"&gt;Pipeline&lt;/head&gt;&lt;p&gt;Given multi-view images of an exemplar scene, our goal is to construct Gaussian Splatting Wang Tiles (GSWT) that can be tiled on arbitrary surfaces and rendered in real time with our novel GSWT renderer. An overview of the entire pipeline is illustrated below. We begin by reconstructing the 3DGS exemplar at multiple LODs. For each level, we generate a set of Wang Tiles by sampling the edge and center patches and applying a semantic-aware graph cut algorithm. Prior to rendering, we pre-sort each tile for efficient sort-free splatting, and during runtime, we perform tiling on the fly, allowing efficient GSWT-based terrain synthesis and rendering.&lt;/p&gt;&lt;p&gt; (a) Given the input images, we construct the exemplar multiple times with different Level of Detail (LOD). &lt;lb/&gt; (b) We construct the tile set and preprocess it before rendering. &lt;lb/&gt; (c) The surface is tiled at run-time on the worker thread, while the main thread renders each frame. &lt;/p&gt;&lt;head rend="h2"&gt;Full Demo&lt;/head&gt;TBD&lt;head rend="h2"&gt;BibTeX&lt;/head&gt;&lt;code&gt;@inproceedings{Zeng:2025:gswt,
  author = {Zeng, Yunfan and Ma, Li and Sander, Pedro V.},
  title = {GSWT: Gaussian Splatting Wang Tiles},
  year = {2025},
  publisher = {Association for Computing Machinery},
  booktitle = {SIGGRAPH Asia 2025 Conference Papers},
  location = {Hong Kong, China},
  series = {SA '25}
}&lt;/code&gt;
      &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yunfan.zone/gswt_webpage/"/><published>2025-12-03T14:40:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46135008</id><title>Mapping Every Dollar of America's $5T Healthcare System</title><updated>2025-12-03T15:43:06.894765+00:00</updated><content/><link href="https://healthisotherpeople.substack.com/p/an-abominable-creature"/><published>2025-12-03T14:42:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46135388</id><title>Microsoft lowers AI software sales quota</title><updated>2025-12-03T15:43:06.424392+00:00</updated><content>&lt;doc fingerprint="a767091d7cb28dcf"&gt;
  &lt;main&gt;
    &lt;p&gt;Dec 3 (Reuters) - Multiple divisions at Microsoft have lowered sales growth targets for certain artificial intelligence products after many sales staff missed goals in the fiscal year that ended in June, The Information reported on Wednesday.&lt;/p&gt;
    &lt;p&gt;It is rare for Microsoft to lower quotas for specific products, the report said, citing two salespeople in the Azure cloud unit. The division is closely watched by investors as it is the main beneficiary of Microsoft's AI push.&lt;/p&gt;
    &lt;p&gt;Shares of the company, one of the biggest winners of the AI boom due to its early bet on ChatGPT-maker OpenAI, fell nearly 3%. The stock has gained just 15% this year, lagging AI rival Alphabet's nearly 65% surge.&lt;/p&gt;
    &lt;p&gt;Microsoft did not immediately respond to a Reuters request for comment.&lt;/p&gt;
    &lt;p&gt;WORRIES OVER AI BUBBLE&lt;/p&gt;
    &lt;p&gt;Lower sales growth goals for its AI products are likely to fans fears about real-world adoption of the technology as investors fear the frenzy driving up valuations has turned into a bubble. An MIT study from earlier this year had found that only about 5% of AI projects advance beyond the pilot stage.&lt;/p&gt;
    &lt;p&gt;The Information report said Carlyle Group last year started using Copilot Studio to automate tasks such as meeting summaries and financial models, but cut its spending on the product after flagging Microsoft about its struggles to get the software to reliably pull data from other applications.&lt;/p&gt;
    &lt;p&gt;The report shows the industry was in the early stages of adopting AI, said D.A. Davidson analyst Gil Luria. "That does not mean there isn't promise for AI products to help companies become more productive, just that it may be harder than they thought."&lt;/p&gt;
    &lt;p&gt;U.S. tech giants are under investor pressure to prove that their hefty investments in AI infrastructure are generating returns.&lt;/p&gt;
    &lt;p&gt;RECORD SPENDING&lt;/p&gt;
    &lt;p&gt;Microsoft reported a record capital expenditure of nearly $35 billion for its fiscal first quarter in October and warned that spending would rise this year. Overall, U.S. tech giants are expected to spend around $400 billion on AI this year.&lt;/p&gt;
    &lt;p&gt;The companies have said the outlay is necessary to overcome supply constraints that have hobbled their ability to capitalize on AI demand.&lt;/p&gt;
    &lt;p&gt;Microsoft has predicted it would remain short on AI capacity at least until the end of its current fiscal year in June 2026.&lt;/p&gt;
    &lt;p&gt;The spending has so far paid off for the Satya Nadella-led company as revenue at its Azure cloud-computing unit grew 40% in the July-September period, outpacing expectations. Its fiscal second-quarter forecast was also above estimates.&lt;/p&gt;
    &lt;p&gt;The AI push has also helped Microsoft become the second company to hit a $4 trillion valuation this year after Nvidia, although its market value has retreated since then.&lt;/p&gt;
    &lt;p&gt;(Reporting by Aditya Soni, Jaspreet Singh and Anhata Rooprai in Bengaluru; Editing by Arun Koyyur)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://finance.yahoo.com/news/microsoft-lowers-ai-software-sales-141531121.html"/><published>2025-12-03T15:11:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46135627</id><title>Why are my headphones buzzing whenever I run my game?</title><updated>2025-12-03T15:43:06.347090+00:00</updated><content>&lt;doc fingerprint="f6e837137fac0f9f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why are my headphones buzzing whenever I run my game?&lt;/head&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;I use rust with my own engine working on an isometric-perspective game inspired from Gnomoria, RimWorld, Dwarf Fortress, etc. Whenever I started my game, my headphones were buzzing. I could play Fortnite, Overwatch or any other game and that doesn’t cause my headphones to buzz. It’s only my game.&lt;/p&gt;
    &lt;p&gt;And it’s really annoying, as you might imagine.&lt;/p&gt;
    &lt;p&gt;Why can I play Overwatch and Fortnite fine, while my isometric game makes my headset buzz? I had a fairly decent CPU, a 3090RTX card, 32GB RAM and USB audio through a MODI DAC. Nothing out of this world, but nothing too bad. One important detail here is that the power to the MODI device comes from an USB port in my computer. This was the first clue, I tried other ports with no change in results (headphones still buzzed).&lt;/p&gt;
    &lt;p&gt;Initially, I started to think it’s some sort of power-use related issue, because maybe my PSU was getting old, or had daemons in it. However, I still couldn’t explain why my tiny game was causing more chaos than say big games that send significantly more work at my PC.&lt;/p&gt;
    &lt;p&gt;I noticed is that when it didn’t render anything, nothing buzzed (I run tests with rendering disabled). So that eliminated any sort of CPU work causing it. Let’s take a look at what the GPU does.&lt;/p&gt;
    &lt;head rend="h2"&gt;The pipeline&lt;/head&gt;
    &lt;p&gt;The game has a simple graphics pipeline. I use WebGPU and do some compute work to select visible entities, then use draw indirect to draw those entities. In the end, my render pipeline also outputs two things: the buffer that ends up on screen and a “picking texture”.&lt;/p&gt;
    &lt;p&gt;A picking texture is a very simple idea. As the name says, it’s used to handle picking in the game, when you click somewhere on the screen (e.g. to select an unit), I use this texture to know what you clicked on. Instead of colors, every object instance writes their EntityID to this texture. Then, when you click the mouse, you check what id is in the pixel under the mouse position.&lt;/p&gt;
    &lt;p&gt;At the end of a frame, I copy that picking texture back to RAM (from GPU memory), to check it against mouse positions in case of a click.&lt;/p&gt;
    &lt;p&gt;This isn’t ideal as transfers from GPU-&amp;gt;CPU memory take time, but it works and is way simpler to implement and debug than casting a ray through the scene: .&lt;/p&gt;
    &lt;head rend="h2"&gt;Why does rendering make my headphones buzz???&lt;/head&gt;
    &lt;p&gt;Now that we have a picture of how the rendering in my game works, time to debug it. We know it’s something to do with the GPU work, but what can possibly cause this? As the trace above shows, my GPU is not under heavy load.&lt;/p&gt;
    &lt;p&gt;As I was stuck and had no idea on what can be a likely issue, I proceeded to then disable parts of my rendering pipeline (first the compute, then the rendering, then transferring the picking texture). When I skipped downloading the picking texture the buzzing was fully gone. What was confusing in this process is that disabling parts of the pipeline, somehow made the buzzing a lower volume and less noticeable.&lt;/p&gt;
    &lt;p&gt;To be sure it was the picking texture download, I also issued the download every 250ms and noticed the noise is almost gone. Increasing the frequency on how often we download it to RAM, increased the buzzing.&lt;/p&gt;
    &lt;p&gt;So at this point I had a likely source, but no idea why things would interfere in ways to what I assumed was the power to my MODI device. Through a bunch of discussion with other graphics engineers, someone suggested it may be due to the fact that I full on hit the GPU with tons of work, then pause the GPU to wait for that pickng texture to transfer, then turn it back on 100% for the next frame.&lt;/p&gt;
    &lt;p&gt;That explanation is plausible and also likely as I further on proceeded to supply power to my MODI device from another source that’s not my PC and the buzzing was gone.&lt;/p&gt;
    &lt;p&gt;Now that we know this, all was left is to fix it. In hindsight, the solution is obvious. There’s no need to download the whole texture each frame, just the part of the picking texture that’s under the mouse. So I implemented that and it worked and buzzing is gone. As a bonus, now it’s also not visible at all on the GPU trace.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexene.dev/2025/12/03/Why-do-my-headphones-buzz-when-i-run-my-game.html"/><published>2025-12-03T15:30:30+00:00</published></entry></feed>