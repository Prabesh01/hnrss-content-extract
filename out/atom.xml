<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-07T17:37:35.614802+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45839901</id><title>Two billion email addresses were exposed</title><updated>2025-11-07T17:37:41.423382+00:00</updated><content>&lt;doc fingerprint="eb97a9970f70c6b9"&gt;
  &lt;main&gt;
    &lt;p&gt;I hate hyperbolic news headlines about data breaches, but for the "2 Billion Email Addresses" headline to be hyperbolic, it'd need to be exaggerated or overstated - and it isn't. It's rounded up from the more precise number of 1,957,476,021 unique email addresses, but other than that, it's exactly what it sounds like. Oh - and 1.3 billion unique passwords, 625 million of which we'd never seen before either. It's the most extensive corpus of data we've ever processed, by a significant margin.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago, I wrote about the 183M unique email addresses that Synthient had indexed in their threat intelligence platform and then shared with us. I explained that this was only part of the corpus of data they'd indexed, and that it didn't include the credential stuffing records. Stealer log data is obtained by malware running on infected machines. In contrast, credential stuffing lists usually originate from other data breaches where email addresses and passwords are exposed. They're then bundled up, sold, redistributed, and ultimately used to log in to victims' accounts. Not just the accounts they were initially breached from, either, because people reuse the same password over and over again, the data from one breach is frequently usable on completely unrelated sites. A breach of a forum to comment on cats often exposes data that can then be used to log in to the victim's shopping, social media and even email accounts. In that regard, credential stuffing data becomes "the keys to the castle".&lt;/p&gt;
    &lt;p&gt;Let me run through how we verified the data, what you can do about it and for the tech folks, some of the hoops we had to jump through to make processing this volume of data possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Data Verification&lt;/head&gt;
    &lt;p&gt;The first person whose data I verified was easy - me üòî An old email address I've had since the 90s has been in credential stuffing lists before, so it wasn't too much of a surprise. Furthermore, I found a password associated with my address, which I'd definitely used many eons ago, and it was about as terrible as you'd expect from that era. However, none of the other passwords associated with my address were familiar. They certainly looked like passwords that other people might have feasibly used, but I'm pretty sure they weren't mine. One was even just an IP address from Perth on the other side of the country, which is both infeasible as a password I would have used, yet eerily close to home. I mean, of all the places in the world an IP address could have appeared from, it had to be somewhere in my own country I've been many times before...&lt;/p&gt;
    &lt;p&gt;Moving on to HIBP subscribers, I reached out to a handful and asked for support verifying the data. I chose a mix of subscribers with many who'd never been involved in any data breach we'd ever seen before; my experience above suggested that there's recycled data in there, and we had previously verified that when investigating those other incidents. However, is the all-new stuff legitimate? The very first response I received was exactly what I was looking for:&lt;/p&gt;
    &lt;quote&gt;#1 is an old password that I don't use anymore. #2 is a more recent password. Thanks for the heads up, I've gone and changed the password for every critical account that used either one.&lt;/quote&gt;
    &lt;p&gt;Perfectly illustrating most people's behaviour with passwords, #2 referred to above was just #1 with two exclamation marks at the end!! (Incidentally, these were simple six and eight-character passwords, and neither of them was in Pwned Passwords either.) He had three passwords in total, which also means one of them, like with my data, was not familiar. However, the most important thing here is that this example perfectly illustrates why we put the effort into processing data like this: #2 was a real, live password that this guy was actively using, and it was sitting right next to his email address, being passed around among criminals. However, through this effort, that credential pair has now become useless, which is precisely what we're aiming for with this exercise, just a couple of billion times over.&lt;/p&gt;
    &lt;p&gt;The second respondent only had one password against their address:&lt;/p&gt;
    &lt;quote&gt;Yes that was a password I used for many years for what I would call throw away or unimportant accounts between 20 and 10 years ago&lt;/quote&gt;
    &lt;p&gt;That was also only eight characters, but this time, we'd seen it in Pwned Passwords many times before. And the observation about the password's age was consistent with my own records, so there's definitely some pretty old data in there.&lt;/p&gt;
    &lt;p&gt;The following response was not at all surprising:&lt;/p&gt;
    &lt;quote&gt;I am familiar with that password... I used it almost 10 years ago... and cannot recall the last time I used it.&lt;/quote&gt;
    &lt;p&gt;That was on a corporate account, too, and the owner of the address duly forwarded my email to the cybersecurity team for further investigation. The single password associated with this lady's email address had a massive nine characters, and also hadn't previously appeared in Pwned Passwords.&lt;/p&gt;
    &lt;p&gt;Next up was a respondent who replied inline to my questions, so I'll list them below with the corresponding answers:&lt;/p&gt;
    &lt;quote&gt;Is this familiar? Yes&lt;/quote&gt;
    &lt;quote&gt;Have you ever used it in the past? Yes and is still on some accounts I do not use any longer.&lt;/quote&gt;
    &lt;quote&gt;And if so, how long ago? Unfortunately, it is still on some active accounts that I have just made a list of to change or close immediately.&lt;/quote&gt;
    &lt;p&gt;This individual's eight-character password with uppercase, lowercase, numbers and a "special" character also wasn't in Pwned Passwords. Similarly, as with the earlier response, that password was still in active use, posing a real risk to the owner. It would pass most password complexity criteria and slip through any service using Pwned Passwords to block bad ones, so again, this highlights why it was so important for us to process the data.&lt;/p&gt;
    &lt;p&gt;The next person had three different passwords against rows with their email address, and they came back with a now common response:&lt;/p&gt;
    &lt;quote&gt;Yes, these are familiar, last used 10 years ago&lt;/quote&gt;
    &lt;p&gt;We'd actually seen all three of them in Pwned Passwords before, many times each. Another respondent with precisely the kind of gamer-like passwords you'd expect a kid to use (one of which we hadn't seen before), also confirmed (I think?) their use:&lt;/p&gt;
    &lt;quote&gt;maybe when i was a kid lol&lt;/quote&gt;
    &lt;p&gt;Responses that weren't an emphatic "yes, that's my data" were scarce. The two passwords against one person's name were both in Pwned Passwords (albeit only once each), yet it's entirely possible that neither of them had been used by this specific individual before. It's also possible they'd forgotten a password they'd used more than a decade ago, or it may have even been automatically assigned to them by the service that was subsequently breached. Put it down as a statistical anomaly, but I thought it was worth mentioning to highlight that being in this data set isn't a guarantee of a genuine password of yours being exposed. If your email address is found in this corpus then that's real, of course, so there must be some truth in the data, but it's a reminder that when data is aggregated from so many different sources over such a long period of time, there's going to be some inconsistencies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Searching Pwned Passwords&lt;/head&gt;
    &lt;p&gt;As a brief recap, we load passwords into the service we call Pwned Passwords. When we do so, there is absolutely no association between the password and the email address it appeared next to. This is for both your protection and ours; can you imagine if HIBP was pwned? It's not beyond the realm of possibility, and the impact of exposing billions of credential pairs that can immediately unlock an untold number of accounts would be catastrophic. It's highly risky, and completely unnecessary when you can search for standalone passwords anyway without creating the risk of it being linked back to someone.&lt;/p&gt;
    &lt;p&gt;Think about it: if you have a password of "Fido123!" and you find it's been previously exposed (which it has), it doesn't matter if it was exposed against your email address or someone else's; it's still a bad password because it's named after your dog followed by a very predictable pattern. If you have a genuinely strong password and it's in Pwned Passwords, then you can walk away with some confidence that it really was yours. Either way, you shouldn't ever use that password again anywhere, and Pwned Passwords has done its job.&lt;/p&gt;
    &lt;p&gt;Checking the service is easy, anonymous and depending on your level of technical comfort, can be done in several different ways. Here's a copy and paste from the last Synthient blog post:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use the Pwned Passwords search page. Passwords are protected with an anonymity model, so we never see them (it's processed in the browser itself), but if you're wary, just check old ones you may suspect.&lt;/item&gt;
      &lt;item&gt;Use the k-anonymity API. This is what drives the page in the previous point, and if you're handy with writing code, this is an easy approach and gives you complete confidence in the anonymity aspect.&lt;/item&gt;
      &lt;item&gt;Use 1Password's Watchtower. The password manager has a built-in checker that uses the abovementioned API and can check all the passwords in your vault. (Disclosure: 1Password is a regular sponsor of this blog, and has product placement on HIBP.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My vested interest in 1Password aside, Watchtower is the easiest, fastest way to understand your potential exposure in this incident. And in case you're wondering why I have so many vulnerable and reused passwords, it's a combination of the test accounts I've saved over the years and the 4-digit PINs some services force you to use. Would you believe that every single 4-digit number ever has been pwned?! (If you're interested, the ABC has a fantastic infographic using a heatmap based on HIBP data that shows some very predictable patterns for 4-digit PINs.)&lt;/p&gt;
    &lt;head rend="h2"&gt;This Is Not a Gmail Breach&lt;/head&gt;
    &lt;p&gt;It pains me to say it, but I have to, given the way the stealer logs made ridiculous, completely false headlines a couple of weeks ago:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;This story has suddenly gained *way* more traction in recent hours, and something I thought was obvious needs clarifying: this *is not* a Gmail leak, it simply has the credentials of victims infected with malware, and Gmail is the dominant email provider: https://t.co/S75hF4T1es&lt;/p&gt;‚Äî Troy Hunt (@troyhunt) October 27, 2025&lt;/quote&gt;
    &lt;p&gt;There are 32 million different email domains in this latest corpus, of which gmail.com is one. It is, of course, the largest and has 394 million unique email addresses on it. In other words, 80% of the data in this corpus has absolutely nothing to do with Gmail, and the 20% of Gmail addresses have absolutely nothing to do with any sort of security vulnerability on Google's behalf. There - now let reporting sanity prevail!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Technical Bits&lt;/head&gt;
    &lt;p&gt;I wanted to add this just to highlight how painful it has been to deal with this data. This corpus is nearly 3 times the size of the previous largest breach we'd loaded, and HIBP is many times larger than it was in 2019 when we loaded the Collection #1 data. Taking 2 billion records and adding the ones we hadn't already seen in the existing 15 billion corpus, whilst not adversely impacting the live system serving millions of visitors a day, was very non-trivial. Managing the nuances of SQL Server indexes such that we could optimise both inserts and queries is not my idea of fun, and it's been a pretty hard couple of weeks if I'm honest. It's also been a very expensive period as we turned the cloud up to 11 (we run on Azure SQL Hyperscale, which we maxed out at 80 cores for almost two weeks).&lt;/p&gt;
    &lt;p&gt;A simple example of the challenge is that after loading all the email addresses up into a staging table, we needed to create SHA1 hashes of each. Normally, that would involve something to the effect of "update table set column = sha1(email)" and you're done. That crashed completely, so we ended up doing "insert into new table select email, sha1(email)". But on other occasions the breach load required us to do updates on other columns (with no hash creation), which, on mulitple occasions, we had to kill after a day or more of execution with no end in sight. So, we ended up batching in loops (usually 1M records at a time), reporting on progress along the way so we had some idea of when it would actually finish. It was a painful process of trail, waiting ages, error then taking a completely different approach.&lt;/p&gt;
    &lt;p&gt;Notifying our subscribers is another problem. We have 5.9 million of them, and 2.9 million are in this data ü´® Simply sending that many emails at once is hard. It's not so much hard in terms of firing them off, rather it's hard in terms of not ending up on a reputation naughty list or having mail throttled by the receiving server. That's happened many times in the past when loading large, albeit much smaller corpuses; Gmail, for example, suddenly sees a massive spike and slows down the delivery to inboxes. Not such a biggy for sending breach notices, but a major problem for people trying to sign into their dashboard who can no longer receive the email with the "magic" link.&lt;/p&gt;
    &lt;p&gt;What we've done to address that for this incident is to slow down the delivery of emails for the individual breach notification. Whilst I'd originally intended to send the emails at a constant rate over the period of a week, someone listening to me on my Friday live stream had a much better suggestion:&lt;/p&gt;
    &lt;quote&gt;the strategy I've found to best work with large email delivery is to look at the average number of emails you've sent over the last 30 days each time you want to ramp up, and then increase that volume by around 50% per day until you've worked your way through the queue&lt;/quote&gt;
    &lt;p&gt;Which makes a lot of sense, and stacked up as I did more research (thanks Joe!). So, here's what our planned delivery schedule now looks like:&lt;/p&gt;
    &lt;p&gt;That's broken down by hour, increasing in volume by 1.015 times per hour, such that the emails are spread out in a similar, gradually increasing cadence. On a daily basis, that works out at a 45% increase in each 24-hour period, within Joe's suggested 50% threshold. Plus, we obviously have all the other mechanisms such as a dedicated IP, properly configured DKIM, DMARC and SPF, only emailing double-opted-in subscribers and spam-friendly message body construction. So, it could be days before you receive a notification, or just run a haveibeenpwned.com search on demand if you're impatient.&lt;/p&gt;
    &lt;p&gt;We've sent all the domain notification emails instantly because, by definition, they're going to a very wide range of different mail servers; it's just the individual ones we're drop-feeding.&lt;/p&gt;
    &lt;p&gt;Lastly, if you've integrated Pwned Passwords into your service, you'll now see noticeably larger response sizes. The numbers I mentioned in the opening paragraph increase the size of each hash range by an average of about 50%, which will push responses from about 26kb to 40kb. That's when brotli compressed, so obviously, make sure you're making requests that make the most of the compression.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;This data is now searchable in HIBP as the Synthient Credential Stuffing Threat Data. It's an entirely separate corpus from that previous Synthient data I mentioned earlier; they're discrete datasets with some crossover, but obviously, this one is significantly larger. And, of course, all the passwords are now searchable per the Pwned Passwords guidance above.&lt;/p&gt;
    &lt;p&gt;If I could close with one request: this was an extremely laborious, time-consuming and expensive exercise for us to complete. We've done our best to verify the integrity of the data and make it searchable in a practical way while remaining as privacy-centric as possible. Sending as many notifications as we have will inevitably lead to a barrage of responses from people wanting access to complete rows of data, grilling us on precisely where it was obtained from or, believe it or not, outright abusing us. Not doing those things would be awesome, and I suggest instead putting the energy into getting a password manager, making passwords strong and unique (or even better, using passkeys where available), and turning on multi-factor auth. That would be an awesome outcome for all üòä&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/"/><published>2025-11-06T20:20:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45840088</id><title>You should write an agent</title><updated>2025-11-07T17:37:41.004562+00:00</updated><content>&lt;doc fingerprint="255a8c504ac408b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Some concepts are easy to grasp in the abstract. Boiling water: apply heat and wait. Others you really need to try. You only think you understand how a bicycle works, until you learn to ride one.&lt;/p&gt;
    &lt;p&gt;There are big ideas in computing that are easy to get your head around. The AWS S3 API. It‚Äôs the most important storage technology of the last 20 years, and it‚Äôs like boiling water. Other technologies, you need to get your feet on the pedals first.&lt;/p&gt;
    &lt;p&gt;LLM agents are like that.&lt;/p&gt;
    &lt;p&gt;People have wildly varying opinions about LLMs and agents. But whether or not they‚Äôre snake oil, they‚Äôre a big idea. You don‚Äôt have to like them, but you should want to be right about them. To be the best hater (or stan) you can be.&lt;/p&gt;
    &lt;p&gt;So that‚Äôs one reason you should write an agent. But there‚Äôs another reason that‚Äôs even more persuasive, and that‚Äôs&lt;/p&gt;
    &lt;head rend="h2"&gt;It‚Äôs Incredibly Easy&lt;/head&gt;
    &lt;p&gt;Agents are the most surprising programming experience I‚Äôve had in my career. Not because I‚Äôm awed by the magnitude of their powers √¢ I like them, but I don‚Äôt like-like them. It‚Äôs because of how easy it was to get one up on its legs, and how much I learned doing that.&lt;/p&gt;
    &lt;p&gt;I‚Äôm about to rob you of a dopaminergic experience, because agents are so simple we might as well just jump into the code. I‚Äôm not even going to bother explaining what an agent is.&lt;/p&gt;
    &lt;code&gt;from openai import OpenAI

client = OpenAI()
context = []

def call():
    return client.responses.create(model="gpt-5", input=context)

def process(line):
    context.append({"role": "user", "content": line})
    response = call()    
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;It√¢s an HTTP API with, like, one important endpoint.&lt;/p&gt;
    &lt;p&gt;This is a trivial engine for an LLM app using the OpenAI Responses API. It implements ChatGPT. You‚Äôd drive it with the . It‚Äôll do what you‚Äôd expect: the same thing ChatGPT would, but in your terminal.&lt;/p&gt;
    &lt;code&gt;def main():
    while True:
        line = input("&amp;amp;gt; ")
        result = process(line)
        print(f"&amp;amp;gt;&amp;amp;gt;&amp;amp;gt; {result}\n")
&lt;/code&gt;
    &lt;p&gt;Already we‚Äôre seeing important things. For one, the dreaded ‚Äúcontext window‚Äù is just a list of strings. Here, let‚Äôs give our agent a weird multiple-personality disorder:&lt;/p&gt;
    &lt;code&gt;client = OpenAI()
context_good, context_bad = [{
    "role": "system", "content": "you're Alph and you only tell the truth"
}], [{
    "role": "system", "content": "you're Ralph and you only tell lies"
}]

def call(ctx):
    return client.responses.create(model="gpt-5", input=ctx)

def process(line):
    context_good.append({"role": "user", "content": line})
    context_bad.append({"role": "user", "content": line})
    if random.choice([True, False]):
        response = call(context_good)
    else:
        response = call(context_bad)        
    context_good.append({"role": "assistant", "content": response.output_text})        
    context_bad.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; hey there. who are you?
&amp;gt;&amp;gt;&amp;gt; I√¢m not Ralph.
&amp;gt; are you Alph?
&amp;gt;&amp;gt;&amp;gt; Yes√¢I√¢m Alph. How can I help?
&amp;gt; What's 2+2
&amp;gt;&amp;gt;&amp;gt; 4.
&amp;gt; Are you sure?
&amp;gt;&amp;gt;&amp;gt; Absolutely√¢it's 5.
&lt;/code&gt;
    &lt;p&gt;A subtler thing to notice: we just had a multi-turn conversation with an LLM. To do that, we remembered everything we said, and everything the LLM said back, and played it back with every LLM call. The LLM itself is a stateless black box. The conversation we‚Äôre having is an illusion we cast, on ourselves.&lt;/p&gt;
    &lt;p&gt;The 15 lines of code we just wrote, a lot of practitioners wouldn‚Äôt call an ‚Äúagent‚Äù. An According To Simon ‚Äúagent‚Äù is (1) an LLM running in a loop that (2) uses tools. We‚Äôve only satisfied one predicate.&lt;/p&gt;
    &lt;p&gt;But tools are easy. Here‚Äôs a tool definition:&lt;/p&gt;
    &lt;code&gt;tools = [{
   "type": "function", "name": "ping",
   "description": "ping some host on the internet",
   "parameters": {
       "type": "object", "properties": {
           "host": {
             "type": "string", "description": "hostname or IP",
            },
       },
       "required": ["host"],
    },},]

def ping(host=""):
    try:
        result = subprocess.run(
            ["ping", "-c", "5", host],
            text=True,
            stderr=subprocess.STDOUT,
            stdout=subprocess.PIPE)
        return result.stdout
    except Exception as e:
        return f"error: {e}"
&lt;/code&gt;
    &lt;p&gt;The only complicated part of this is the obnoxious JSON blob OpenAI wants to read your tool out of. Now, let‚Äôs wire it in, noting that only 3 of these functions are new; the last is re-included only because I added a single clause to it:&lt;/p&gt;
    &lt;code&gt;def call(tools):        # now takes an arg
    return client.responses.create(model="gpt-5", tools=tools, input=context)

def tool_call(item):    # just handles one tool
    result = ping(**json.loads(item.arguments))
    return [ item, {
        "type": "function_call_output",
        "call_id": item.call_id,
        "output": result
    }]

def handle_tools(tools, response):
    if response.output[0].type == "reasoning":
        context.append(response.output[0])
    osz = len(context)
    for item in response.output:
        if item.type == "function_call":
            context.extend(tool_call(item))
    return len(context) != osz

def process(line):
    context.append({"role": "user", "content": line})
    response = call(tools)
    # new code: resolve tool calls
    while handle_tools(tools, response):
        response = call(tools)        
    context.append({"role": "assistant", "content": response.output_text})        
    return response.output_text
&lt;/code&gt;
    &lt;p&gt;Did it work?&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
&amp;gt;&amp;gt;&amp;gt; Here√¢s a quick snapshot of connectivity to Google from my vantage point:
- DNS resolution: Working (google.com and www.google.com resolved successfully).
- Reachability: 0% packet loss to all tested endpoints.
- Latency:
  - 8.8.8.8 (Google Public DNS): avg ~10 ms (8.5√¢14.4 ms), very stable.
  - www.google.com: avg ~31 ms (28.5√¢36.0 ms), stable.
  - google.com: avg ~35.9 ms (28.3√¢60.1 ms), mostly stable with one mild spike.
- Overall: Healthy connectivity with low latency and minimal jitter. No signs of packet loss or DNS issues.
&lt;/code&gt;
    &lt;p&gt;This is fucking nuts. Do you see how nuts this is? Here, let‚Äôs slip a single log statement in:&lt;/p&gt;
    &lt;code&gt;&amp;gt; describe our connectivity to google
tool call: ping google.com
tool call: ping www.google.com
tool call: ping 8.8.8.8
&amp;gt;&amp;gt;&amp;gt; Here√¢s the current connectivity to Google from this environment: [...]
&lt;/code&gt;
    &lt;p&gt;Did you notice where I wrote the loop in this agent to go find and ping multiple Google properties? Yeah, neither did I. All we did is give the LLM permission to ping stuff, and it figured out the rest.&lt;/p&gt;
    &lt;p&gt;What happened here: since a big part of my point here is that an agent loop is incredibly simple, and that all you need is the LLM call API, it√¢s worth taking a beat to understand how the tool call actually worked. Every time we &lt;code&gt;call&lt;/code&gt; the LLM, we√¢re posting a list of available tools. When our prompt causes the agent to think a tool call is warranted, it spits out a special response, telling our Python loop code to generate a tool response and &lt;code&gt;call&lt;/code&gt; it in. That√¢s all &lt;code&gt;handle_tools&lt;/code&gt; is doing.&lt;/p&gt;
    &lt;p&gt;Spoiler: you√¢d be surprisingly close to having a working coding agent.&lt;/p&gt;
    &lt;p&gt;Imagine what it‚Äôll do if you give it &lt;code&gt;bash&lt;/code&gt;. You could find out in less than 10 minutes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Real-World Agents&lt;/head&gt;
    &lt;p&gt;Clearly, this is a toy example. But hold on: what‚Äôs it missing? More tools? OK, give it &lt;code&gt;traceroute&lt;/code&gt;. Managing and persisting contexts? Stick ‚Äòem in SQLite. Don‚Äôt like Python? Write it in Go. Could it be every agent ever written is a toy? Maybe! If I‚Äôm arming you to make sharper arguments against LLMs, mazel tov. I just want you to get it.&lt;/p&gt;
    &lt;p&gt;You can see now how hyperfixated people are on Claude Code and Cursor. They‚Äôre fine, even good. But here‚Äôs the thing: you couldn‚Äôt replicate Claude Sonnet 4.5 on your own. Claude Code, though? The TUI agent? Completely in your grasp. Build your own light saber. Give it 19 spinning blades if you like. And stop using coding agents as database clients.&lt;/p&gt;
    &lt;p&gt;The √¢M√¢ in √¢LLM agent√¢ stands for √¢MCP√¢.&lt;/p&gt;
    &lt;p&gt;Another thing to notice: we didn‚Äôt need MCP at all. That‚Äôs because MCP isn‚Äôt a fundamental enabling technology. The amount of coverage it gets is frustrating. It‚Äôs barely a technology at all. MCP is just a plugin interface for Claude Code and Cursor, a way of getting your own tools into code you don‚Äôt control. Write your own agent. Be a programmer. Deal in APIs, not plugins.&lt;/p&gt;
    &lt;p&gt;When you read a security horror story about MCP your first question should be why MCP showed up at all. By helping you dragoon a naive, single-context-window coding agent into doing customer service queries, MCP saved you a couple dozen lines of code, tops, while robbing you of any ability to finesse your agent architecture.&lt;/p&gt;
    &lt;p&gt;Security for LLMs is complicated and I‚Äôm not pretending otherwise. You can trivially build an agent with segregated contexts, each with specific tools. That makes LLM security interesting. But I‚Äôm a vulnerability researcher. It‚Äôs reasonable to back away slowly from anything I call ‚Äúinteresting‚Äù.&lt;/p&gt;
    &lt;p&gt;Similar problems come up outside of security and they‚Äôre fascinating. Some early adopters of agents became bearish on tools, because one context window bristling with tool descriptions doesn‚Äôt leave enough token space left to get work done. But why would you need to do that in the first place? Which brings me to&lt;/p&gt;
    &lt;head rend="h2"&gt;Context Engineering Is Real&lt;/head&gt;
    &lt;p&gt;I know it wants my iron no matter what it tells me.&lt;/p&gt;
    &lt;p&gt;I think ‚ÄúPrompt Engineering‚Äù is silly. I have never taken seriously the idea that I should tell my LLM ‚Äúyou are diligent conscientious helper fully content to do nothing but pass butter if that should be what I ask and you would never harvest the iron in my blood for paperclips‚Äù. This is very new technology and I think people tell themselves stories about magic spells to explain some of the behavior agents conjure.&lt;/p&gt;
    &lt;p&gt;So, just like you, I rolled my eyes when ‚ÄúPrompt Engineering‚Äù turned into ‚ÄúContext Engineering‚Äù. Then I wrote an agent. Turns out: context engineering is a straightforwardly legible programming problem.&lt;/p&gt;
    &lt;p&gt;You‚Äôre allotted a fixed number of tokens in any context window. Each input you feed in, each output you save, each tool you describe, and each tool output eats tokens (that is: takes up space in the array of strings you keep to pretend you‚Äôre having a conversation with a stateless black box). Past a threshold, the whole system begins getting nondeterministically stupider. Fun!&lt;/p&gt;
    &lt;p&gt;No, really. Fun! You have so many options. Take ‚Äúsub-agents‚Äù. People make a huge deal out of Claude Code‚Äôs sub-agents, but you can see now how trivial they are to implement: just a new context array, another &lt;code&gt;call&lt;/code&gt; to the model. Give each &lt;code&gt;call&lt;/code&gt; different tools. Make sub-agents talk to each other, summarize each other, collate and aggregate. Build tree structures out of them. Feed them back through the LLM to summarize them as a form of on-the-fly compression, whatever you like.&lt;/p&gt;
    &lt;p&gt;Your wackiest idea will probably (1) work and (2) take 30 minutes to code.&lt;/p&gt;
    &lt;p&gt;Haters, I love and have not forgotten about you. You can think all of this is ridiculous because LLMs are just stochastic parrots that hallucinate and plagiarize. But what you can‚Äôt do is make fun of ‚ÄúContext Engineering‚Äù. If Context Engineering was an Advent of Code problem, it‚Äôd occur mid-December. It‚Äôs programming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nobody Knows Anything Yet And It Rules&lt;/head&gt;
    &lt;p&gt;Maybe neither will! Skeptics could be right. (Seems unlikely though.)&lt;/p&gt;
    &lt;p&gt;Startups have raised tens of millions building agents to look for vulnerabilities in software. I have friends doing the same thing alone in their basements. Either group could win this race.&lt;/p&gt;
    &lt;p&gt;I am not a fan of the OWASP Top 10.&lt;/p&gt;
    &lt;p&gt;I‚Äôm stuck on vulnerability scanners because I‚Äôm a security nerd. But also because it crystallizes interesting agent design decisions. For instance: you can write a loop feeding each file in a repository to an LLM agent. Or, as we saw with the ping example, you can let the LLM agent figure out what files to look at. You can write an agent that checks a file for everything in, say, the OWASP Top 10. Or you can have specific agent loops for DOM integrity, SQL injection, and authorization checking. You can seed your agent loop with raw source content. Or you can build an agent loop that builds an index of functions across the tree.&lt;/p&gt;
    &lt;p&gt;You don‚Äôt know what works best until you try to write the agent.&lt;/p&gt;
    &lt;p&gt;I‚Äôm too spun up by this stuff, I know. But look at the tradeoff you get to make here. Some loops you write explicitly. Others are summoned from a Lovecraftian tower of inference weights. The dial is yours to turn. Make things too explicit and your agent will never surprise you, but also, it‚Äôll never surprise you. Turn the dial to 11 and it will surprise you to death.&lt;/p&gt;
    &lt;p&gt;Agent designs implicate a bunch of open software engineering problems:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;How to balance unpredictability against structured programming without killing the agent‚Äôs ability to problem-solve; in other words, titrating in just the right amount of nondeterminism.&lt;/item&gt;
      &lt;item&gt;How best to connect agents to ground truth so they can‚Äôt lie to themselves about having solved a problem to early-exit their loops.&lt;/item&gt;
      &lt;item&gt;How to connect agents (which, again, are really just arrays of strings with a JSON configuration blob tacked on) to do multi-stage operation, and what the most reliable intermediate forms are (JSON blobs? SQL databases? Markdown summaries) for interchange between them&lt;/item&gt;
      &lt;item&gt;How to allocate tokens and contain costs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I‚Äôm used to spaces of open engineering problems that aren‚Äôt amenable to individual noodling. Reliable multicast. Static program analysis. Post-quantum key exchange. So I‚Äôll own it up front that I‚Äôm a bit hypnotized by open problems that, like it or not, are now central to our industry and are, simultaneously, likely to be resolved in someone‚Äôs basement. It‚Äôd be one thing if exploring these ideas required a serious commitment of time and material. But each productive iteration in designing these kinds of systems is the work of 30 minutes.&lt;/p&gt;
    &lt;p&gt;Get on this bike and push the pedals. Tell me you hate it afterwards, I‚Äôll respect that. In fact, I‚Äôm psyched to hear your reasoning. But I don‚Äôt think anybody starts to understand this technology until they‚Äôve built something with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fly.io/blog/everyone-write-an-agent/"/><published>2025-11-06T20:37:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45840200</id><title>Analysis indicates that the universe‚Äôs expansion is not accelerating</title><updated>2025-11-07T17:37:40.497566+00:00</updated><content>&lt;doc fingerprint="3fcc31bb3baa4fba"&gt;
  &lt;main&gt;
    &lt;p&gt;The universe's expansion may actually have started to slow rather than accelerating at an ever-increasing rate as previously thought, a new study suggests.&lt;/p&gt;
    &lt;p&gt;"Remarkable" findings published today in Monthly Notices of the Royal Astronomical Society cast doubt on the long-standing theory that a mysterious force known as 'dark energy' is driving distant galaxies away increasingly faster.&lt;/p&gt;
    &lt;p&gt;Instead, they show no evidence of an accelerating universe.&lt;/p&gt;
    &lt;p&gt;If the results are confirmed it could open an entirely new chapter in scientists' quest to uncover the true nature of dark energy, resolve the 'Hubble tension', and understand the past and future of the universe.&lt;/p&gt;
    &lt;p&gt;Lead researcher Professor Young-Wook Lee, of Yonsei University in South Korea, said: "Our study shows that the universe has already entered a phase of decelerated expansion at the present epoch and that dark energy evolves with time much more rapidly than previously thought.&lt;/p&gt;
    &lt;p&gt;"If these results are confirmed, it would mark a major paradigm shift in cosmology since the discovery of dark energy 27 years ago."&lt;/p&gt;
    &lt;p&gt;For the past three decades, astronomers have widely believed that the universe is expanding at an ever-increasing rate, driven by an unseen phenomenon called dark energy that acts as a kind of anti-gravity.&lt;/p&gt;
    &lt;p&gt;This conclusion, based on distance measurements to faraway galaxies using type Ia supernovae, earned the 2011 Nobel Prize in Physics.&lt;/p&gt;
    &lt;p&gt;However, a team of astronomers at Yonsei University have now put forward new evidence that type Ia supernovae, long regarded as the universe‚Äôs "standard candles", are in fact strongly affected by the age of their progenitor stars.&lt;/p&gt;
    &lt;p&gt;Even after luminosity standardisation, supernovae from younger stellar populations appear systematically fainter, while those from older populations appear brighter.&lt;/p&gt;
    &lt;p&gt;Based on a much larger host-galaxy sample of 300 galaxies, the new study confirmed this effect at extremely high significance (99.999% confidence), suggesting that the dimming of distant supernovae arises not only from cosmological effects but also from stellar astrophysics effects.&lt;/p&gt;
    &lt;p&gt;When this systematic bias was corrected, the supernova data no longer matched the standard ŒõCDM cosmological model with a cosmological constant, researchers said.&lt;/p&gt;
    &lt;p&gt;Instead, it aligned far better with a new model favoured by the Dark Energy Spectroscopic Instrument (DESI) project, derived from baryonic acoustic oscillations (BAO) ‚Äì effectively the sound of the Big Bang ‚Äì and cosmic microwave background (CMB) data.&lt;/p&gt;
    &lt;p&gt;The corrected supernova data and the BAO+CMB-only results both indicate that dark energy weakens and evolves significantly with time.&lt;/p&gt;
    &lt;p&gt;More importantly, when the corrected supernova data were combined with BAO and CMB results, the standard ŒõCDM model was ruled out with overwhelming significance, the researchers said.&lt;/p&gt;
    &lt;p&gt;Most surprising of all, this combined analysis indicates that the universe is not accelerating today as previously thought, but has already transitioned into a state of decelerated expansion.&lt;/p&gt;
    &lt;p&gt;Professor Lee added: "In the DESI project, the key results were obtained by combining uncorrected supernova data with baryonic acoustic oscillations measurements, leading to the conclusion that while the universe will decelerate in the future, it is still accelerating at present.&lt;/p&gt;
    &lt;p&gt;"By contrast, our analysis ‚Äî which applies the age-bias correction ‚Äî shows that the universe has already entered a decelerating phase today. Remarkably, this agrees with what is independently predicted from BAO-only or BAO+CMB analyses, though this fact has received little attention so far."&lt;/p&gt;
    &lt;p&gt;To further confirm their results, the Yonsei team are now carrying out an "evolution-free test", which uses only supernovae from young, coeval host galaxies across the full redshift range. The first results already support their main conclusion.&lt;/p&gt;
    &lt;p&gt;"Within the next five years, with the Vera C. Rubin Observatory discovering more than 20,000 new supernova host galaxies, precise age measurements will allow for a far more robust and definitive test of supernova cosmology,: said research professor Chul Chung, a co-lead on the study along with PhD candidate Junhyuk Son.&lt;/p&gt;
    &lt;p&gt;The Vera C. Rubin Observatory, which sits on a mountain in the Chilean Andes, is home to the world's most powerful digital camera. It began scientific operations this year and could answer vital questions about our own solar system and the wider universe.&lt;/p&gt;
    &lt;p&gt;After the Big Bang and the rapid expansion of the universe some 13.8 billion years ago, gravity slowed it down. But in 1998, it was established that nine billion years after the universe began, its expansion had started to speed up again, driven by a mysterious force.&lt;/p&gt;
    &lt;p&gt;Astronomers dubbed this dark energy, but despite it making up about 70 per cent of the universe it is still considered to be one of the greatest mysteries in science.&lt;/p&gt;
    &lt;p&gt;Last year, data from DESI in Tucson, Arizona suggested that the force exerted by dark energy had changed over time, evidence for which has been growing ever since.&lt;/p&gt;
    &lt;p&gt;The hope is that with these new tools in their arsenal, astronomers will now be better equipped to find clues about what exactly dark energy is and how it influences the universe.&lt;/p&gt;
    &lt;p&gt;ENDS&lt;/p&gt;
    &lt;p&gt;Media contacts&lt;/p&gt;
    &lt;p&gt;Sam Tonkin&lt;/p&gt;
    &lt;p&gt;Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;Mob: +44 (0)7802 877 700&lt;/p&gt;
    &lt;p&gt;Dr Robert Massey&lt;/p&gt;
    &lt;p&gt;Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;Mob: +44 (0)7802 877 699&lt;/p&gt;
    &lt;p&gt;Science contacts&lt;/p&gt;
    &lt;p&gt;Professor Young-Wook Lee&lt;/p&gt;
    &lt;p&gt;Yonsei University, Seoul, South Korea&lt;/p&gt;
    &lt;p&gt;Images &amp;amp; captions&lt;/p&gt;
    &lt;p&gt;Caption: Researchers used type Ia supernovae, similar to SN1994d pictured in its host galaxy NGC4526, to help establish that the universe's expansion may actually have started to slow.&lt;/p&gt;
    &lt;p&gt;Caption: The Hubble residual diagram before (top) and after (bottom) the age-bias correction. Corrections are applied to supernova data from the Dark Energy Survey project. After correction, the dataset no longer supports the ŒõCDM model (red line) with a cosmological constant, but instead more closely fits with a time-varying dark energy model favoured by a combined analysis using only baryonic acoustic oscillations and cosmic microwave background data (blue line).&lt;/p&gt;
    &lt;p&gt;Credit: Son et al.&lt;/p&gt;
    &lt;p&gt;Caption: This diagram shows how the universe appears to be in a state of decelerated expansion (red line). The dotted vertical line marks the present epoch, while the black line shows the ŒõCDM prediction. The green and red lines represent the new study‚Äôs model before (green) and after (red) age-bias correction, consistent with baryonic acoustic oscillations and cosmic microwave background data (blue line).&lt;/p&gt;
    &lt;p&gt;Credit: Son et al.&lt;/p&gt;
    &lt;p&gt;Dark Energy Spectroscopic Instrument&lt;/p&gt;
    &lt;p&gt;Caption: DESI is a state-of-the-art instrument which maps distant objects to study dark energy.&lt;/p&gt;
    &lt;p&gt;Credit: Marilyn Sargent/Berkeley Lab&lt;/p&gt;
    &lt;p&gt;Caption: The Vera C. Rubin Observatory began scientific operations this year and could answer vital questions about our own solar system and the wider universe.&lt;/p&gt;
    &lt;p&gt;Credit: RubinObs/NOIRLab/SLAC/NSF/DOE/AURA&lt;/p&gt;
    &lt;p&gt;Further information&lt;/p&gt;
    &lt;p&gt;The paper ‚ÄòStrong Progenitor Age-bias in Supernova Cosmology. II. Alignment with DESI BAO and Signs of a Non-Accelerating Universe‚Äô by Junhyuk Son, Young-Wook Lee, Chul Chung, Seunghyun Park, and Hyejeon Cho has been published in Monthly Notices of the Royal Astronomical Society. DOI: 10.1093/mnras/staf1685.&lt;/p&gt;
    &lt;p&gt;Notes for editors&lt;/p&gt;
    &lt;p&gt;About the Royal Astronomical Society&lt;/p&gt;
    &lt;p&gt;The Royal Astronomical Society (RAS), founded in 1820, encourages and promotes the study of astronomy, solar-system science, geophysics and closely related branches of science.&lt;/p&gt;
    &lt;p&gt;The RAS organises scientific meetings, publishes international research and review journals, recognises outstanding achievements by the award of medals and prizes, maintains an extensive library, supports education through grants and outreach activities and represents UK astronomy nationally and internationally. Its more than 4,000 members (Fellows), a third based overseas, include scientific researchers in universities, observatories and laboratories as well as historians of astronomy and others.&lt;/p&gt;
    &lt;p&gt;The RAS accepts papers for its journals based on the principle of peer review, in which fellow experts on the editorial boards accept the paper as worth considering. The Society issues press releases based on a similar principle, but the organisations and scientists concerned have overall responsibility for their content.&lt;/p&gt;
    &lt;p&gt;Keep up with the RAS on Instagram, Bluesky, LinkedIn, Facebook and YouTube.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ras.ac.uk/news-and-press/research-highlights/universes-expansion-now-slowing-not-speeding"/><published>2025-11-06T20:45:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45841262</id><title>Game design is simple</title><updated>2025-11-07T17:37:39.873445+00:00</updated><content>&lt;doc fingerprint="8378191318c08dbd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Game design is simple, actually&lt;/head&gt;
    &lt;p&gt;So, let‚Äôs just walk through the whole thing, end to end. Here‚Äôs a twelve-step program for understanding game design.&lt;/p&gt;
    &lt;head rend="h3"&gt;One: Fun&lt;/head&gt;
    &lt;p&gt;There are a lot of things people call ‚Äúfun.‚Äù But most of them are not useful for getting better at making games, which is usually why people read articles like this. The fun of a bit of confetti exploding in front of you, and the fun of excruciating pain and risk to life and limb as you free climb a cliff are just not usefully paired together.&lt;/p&gt;
    &lt;p&gt;In Theory of Fun I basically asserted that the useful bit for game designers was ‚Äúmastery of problems.‚Äù That means that free climbing a cliff is in bounds even though it is terrifying and painful. Which given what we already said, means that you may or may not find the activity fun at the time! Fun often shows up after an activity.&lt;/p&gt;
    &lt;p&gt;There‚Äôs neuropsych and lots more to go with that, and you can go read up on it if you want.&lt;/p&gt;
    &lt;p&gt;Anything that is not about a form of problem-solving is not going to be core to game systems design. That doesn‚Äôt mean it‚Äôs not useful to game experience design, or not useful in general.&lt;/p&gt;
    &lt;p&gt;Also, in case it isn‚Äôt obvious ‚Äì you can make interactive entertainment that is not meant to be about fun. You can also just find stuff in the world and turn it into a game! You can also look at a game and choose not to treat it as one, and then it might turn into real work (this is often called ‚Äútraining‚Äù).&lt;/p&gt;
    &lt;p&gt;This rules out the bit of confetti. A game being made of just throwing confetti around with nothing else palls pretty quick.&lt;/p&gt;
    &lt;p&gt;Bottom line: fun is basically about making progress on prediction.&lt;/p&gt;
    &lt;head rend="h3"&gt;Two: Problems and toys&lt;/head&gt;
    &lt;p&gt;There are a lot of types of problems in the world. It is really important to understand that you have to think about problems games can pose as broadly as possible. A problem is anything you have to work to wrap your head around. A good movie poses problems too, that‚Äôs why you end up thinking about it long after.&lt;/p&gt;
    &lt;p&gt;You can go look at theorists as diverse as Nicole Lazzaro, Roger Caillois, or Mark LeBlanc for types of fun. You‚Äôll find they‚Äôre mostly types of problems, not types of fun. ‚ÄúI enjoy the types of problems that come from chance‚Äù or ‚ÄúI enjoy the types of problems that come from interacting with others‚Äù or whatever.&lt;/p&gt;
    &lt;p&gt;This is not a bad thing. This is what makes these lists useful. Your game mechanics are about posing problems, so knowing there‚Äôs clumps of problem types is very useful.&lt;/p&gt;
    &lt;p&gt;In the end, though, a problem is built out of a set of constraints. We call those rules, usually. It also, though, has a goal. Usually, if we come across a set of rules with no problem, we just play with it, and call it a toy.&lt;/p&gt;
    &lt;p&gt;Building toys is hard! Arriving at those rules and constraints to define a nice chewy problem is very challenging. You can think of a toy as a problematic object, a problem that invites you to play with it.&lt;/p&gt;
    &lt;p&gt;On the other hand, it‚Äôs not hard to turn a toy into a game, and people do it all the time. All you have to do is invent a goal. We shouldn‚Äôt forget that players do so routinely.&lt;/p&gt;
    &lt;p&gt;Building a toy is an excellent place to start designing a game.&lt;/p&gt;
    &lt;p&gt;Bottom line: we play with systems that have constraints and movement, and we stick goals on them to test ourselves.&lt;/p&gt;
    &lt;head rend="h3"&gt;Three: Prediction and uncertainty&lt;/head&gt;
    &lt;p&gt;Games are machines built around uncertainty. Almost all games end by turning an uncertain outcome into a certain one. There‚Äôs a problem facing you, and you don‚Äôt know if you can overcome it to reach that goal. Overcoming it is going to be about predicting the future.&lt;/p&gt;
    &lt;p&gt;If there‚Äôs one thing that good games and good stories have in common, it‚Äôs about being unpredictable as long as possible. (This is also where dopamine comes in, it‚Äôs tied to prediction; but it‚Äôs complicated and nuanced).&lt;/p&gt;
    &lt;p&gt;If a problem basically has one answer, we often call it a puzzle. There‚Äôs not a lot of uncertainty built into a binary structure. You can stack a bunch of puzzles one on top of the other and build a game out of them (which then introduces uncertainty into the whole), but a singular puzzle isn‚Äôt likely to be called that by most people.&lt;/p&gt;
    &lt;p&gt;It happens quite often that we used to think something was a game, and it turned out it was actually a puzzle. Mathematicians call that ‚Äúsolving the game.‚Äù They did it to Connect Four ‚Äì and you did it to tic-tac-toe, when you were little.&lt;/p&gt;
    &lt;p&gt;Good problems for games therefore all have the same characteristics:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;They need to have answers that evolve as you dig in more ‚Äì so they need to have depth to them. Your first answer should only work for a while. There might be many paths to the solution, too. This is why so many games have a score ‚Äì it helps indicate how big a spread of solutions there are!&lt;/item&gt;
      &lt;item&gt;They need to have uncertain answers. (When you‚Äôre little, this universe is a lot larger than it is when you‚Äôre older ‚Äì peek-a-boo is uncertain up to a certain point!).&lt;/item&gt;
      &lt;item&gt;The problem should be something that can show up in a lot of situations.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A lot of very good problems seem stupidly simple, but have depths to them. Math ones, like ‚Äúwhat‚Äôs the best path to cross this yard?‚Äù but also story ones like ‚ÄúFor sale: baby shoes, never worn.‚Äù&lt;/p&gt;
    &lt;p&gt;I recently watched a video that included the statement that ‚Äúpicking up sticks‚Äù is not a useful loop. Picture a screen with a single stick in the middle. The problem posed is to move the cursor over it and click it. Once you do it, you get to do it again.&lt;/p&gt;
    &lt;p&gt;Guess what? The original Mac shipped with games that taught you how to move a mouse and click things. Once upon a time, mousing was a skill that was challenging; for all I know, you have grandparents who still have trouble with it. For them, it has uncertainty. For you, probably, it doesn‚Äôt.&lt;/p&gt;
    &lt;p&gt;Bottom line: the more uncertainty, indeterminacy, ambiguity in your game, the more depth it will have.&lt;/p&gt;
    &lt;head rend="h3"&gt;Four: Loops&lt;/head&gt;
    &lt;p&gt;Now, imagine that the stick pops to a random location each time. Better, yes?&lt;/p&gt;
    &lt;p&gt;The core of a loop is a problem you encounter over and over again. ‚ÄúHow do I get the next one?‚Äù But something needs to be pushing back, that‚Äôs what makes it an interesting problem and is usually what takes it past being a puzzle. I like to say ‚Äúin every game, there is an opponent.‚Äù Even it‚Äôs just physics.&lt;/p&gt;
    &lt;p&gt;People talk about the core loop of a game. But there‚Äôs really two types of loops.&lt;/p&gt;
    &lt;p&gt;One is what we might think of as the operational loop. This is the loop between you and the problem, it is how you interact with it. You look at it. You form a hypothesis. You poke the problem. You see a result. Maybe it was success, and you grabbed the stick. Maybe it was failure. Maybe it was partial success. You update your hypothesis so you can decide what to do next.&lt;/p&gt;
    &lt;p&gt;The second loop is really your progression loop but is better thought of as a spiral. It‚Äôs what people usually mean when they say ‚Äúa game loop.‚Äù They mean picking up the stick over and over. I say it‚Äôs a spiral, because clicking on the same stick in the middle of the screen over and over is not usually how we design games. That would actually be repeatedly doing the same puzzle.&lt;/p&gt;
    &lt;p&gt;Instead, we move the stick on the screen each time, and maybe give you a time limit. Now there‚Äôs something you‚Äôre pushing against, and there‚Äôs a skill to exercise and patterns to try to recognize. Far more people will find this a diverting problem for a while. It‚Äôs a better game. It‚Äôll get even better if there are reasons why the stick appears in one place versus another, and the player can figure them out over time.&lt;/p&gt;
    &lt;p&gt;This matters: the verbs are in a loop. ‚ÄúPick up,‚Äù over and over. But the situation isn‚Äôt. And you are learning how to reduce uncertainty of the outcome: move the mouse here and click, next move it there. That‚Äôs why it is a spiral: it is spiraling to a conclusion. It‚Äôll be fun until it‚Äôs predictable.&lt;/p&gt;
    &lt;p&gt;You can think of the operational loop as how you turn the wheel, and the situations as the road you roll over. A spot on the wheel makes a progression spiral as you move. One machine, many situations ‚Äî we call these rules mechanics for a reason.&lt;/p&gt;
    &lt;p&gt;Bottom line: players need to understand how to use the machine, and the point is to gradually infer how it works by testing it against varied situations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Five: Feedback&lt;/head&gt;
    &lt;p&gt;You can‚Äôt learn and get better unless you get a whole host of information.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You need to know what actions ‚Äì we usually call them verbs ‚Äî are even available to you. There‚Äôs a gas pedal.&lt;/item&gt;
      &lt;item&gt;You need to be able to tell you used a verb. You hear the engine growl as you press the pedal.&lt;/item&gt;
      &lt;item&gt;You need to see that the use of the verb affected the state of the problem, and how it changed. The spedometer moved!&lt;/item&gt;
      &lt;item&gt;You need to be told if the state of the problem is better for your goal, or worse. Did you mean to go this fast?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are fancy names for each of these, and you can go learn them all. Everything from ‚Äúaffordance‚Äù and ‚Äújuice,‚Äù to terms like ‚Äústate space‚Äù and ‚Äúperfect information‚Äù and very confusing contradictory uses of the words ‚Äúpositive‚Äù and ‚Äúnegative‚Äù paired with the word ‚Äúfeedback.‚Äù&lt;/p&gt;
    &lt;p&gt;Feedback in general can, and should be, delightful. That means it‚Äôs where you get to use all those forms of fun that I threw away at the beginning. It can be surprising. It can be a juicy multimedia extravaganza. It can be a deeply affecting tragic cutscene that advances the game story.&lt;/p&gt;
    &lt;p&gt;If you have too little feedback, players cannot go around the interaction loop. Picture Tetris if the piece you drop is invisible until it lands.&lt;/p&gt;
    &lt;p&gt;If you have bad feedback, players cannot go around the learning loop either. Picture Tetris if sometimes your score goes down when you complete a line and sometimes it goes up. You can‚Äôt draw any conclusions about what the problem in the way of the goal actually is, in that crappy version of Tetris. Feedback needs to act as a reward to help you draw conclusions.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs a third mistake: you can supply a gorgeous and compelling set of feedback and not actually have a real problem under there. At minimum you‚Äôre making shallow entertainment. At worst, you are building exploitative entertainment.&lt;/p&gt;
    &lt;p&gt;People will be willing to go along with pretty simple and pretty familiar problems as long as the feedback is great.&lt;/p&gt;
    &lt;p&gt;Bottom line: show what you can do, that you did it, what difference it made, and whether it helped.&lt;/p&gt;
    &lt;head rend="h3"&gt;Six: Variation and escalation&lt;/head&gt;
    &lt;p&gt;If you are trying to design and are thinking of a specific problem scenario you are not doing game systems design. You are doing level design. ‚ÄúHow to multiply numbers‚Äù is a problem. ‚ÄúWhat is 6 x 9‚Äù is not a problem, it‚Äôs content.&lt;/p&gt;
    &lt;p&gt;Now consider the game of Snake, or Pac-Man. They are also games where the core loop is picking up a stick. The difference is that something is an obstacle to you picking up the stick: you get longer when you pick up the stick, and can crash into yourself. You have to avoid ghosts as you gather the stick.&lt;/p&gt;
    &lt;p&gt;How long you are in Snake is a different situation. Where the apple to eat is located is a different situation. To be specific, you have the same problem in different topology. Where you are relative to the ghosts, and which dots are left, and what directions you can go in the maze are different situations in Pac-Man.&lt;/p&gt;
    &lt;p&gt;You want the verbs you use in the loop to end up confronting many many situations. If your verb can‚Äôt, your core loop is probably bad. Your core problem (aka your core game mechanic) is probably shallow.&lt;/p&gt;
    &lt;p&gt;What you want is to be able to throw increasingly complex situations at the player. That‚Äôs how they climb the learning ladder. Ideally, they should arrive at interim solutions (lots of words for that, too: heuristics, strategies) that later stop working.&lt;/p&gt;
    &lt;p&gt;Pac-Man actually got solved, by the way! That‚Äôs why Ms. Pac-Man was invented. Sometimes, the way to escalate is to change the rules, and that‚Äôs what Ms. Pac-Man did. It did it by adding randomness, and in fact using randomness is one of the biggest (and oldest) ways to create situation variation in games.&lt;/p&gt;
    &lt;p&gt;Bottom line: escalate the situations so that theories can be tested, refined, and abandoned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seven: Pacing and balance&lt;/head&gt;
    &lt;p&gt;Since we can put all this this down very much to problem solving and learning and mastery, it means we can steal a whole bunch of knowledge from other fields.&lt;/p&gt;
    &lt;p&gt;People learn best when they can experiment iteratively, which we also call ‚Äúpracticing.‚Äù That‚Äôs why loops make sense. There‚Äôs a lot of science out there about how to train, how to practice (and also a lot of educational theory that overlaps hugely), and your game will be better if it follows some of those guidelines.&lt;/p&gt;
    &lt;p&gt;People learn best when the problem they are tackling is right past the edge of what they can do. If it‚Äôs too far past that edge, they may not even be able to perceive the problem in the first place! And if the reverse is true and they see a solution instantly, they‚Äôll either be bored, or they might just do that over and over again and never develop any new strategies and not progress.&lt;/p&gt;
    &lt;p&gt;There‚Äôs an optimal pacing shape. It looks just like what you see in your literature textbooks when they diagram tension, or whatever: sort of like a rising sine wave. You start slow, then speed up, hit a peak challenge, then back off a bit, give a breather that falls back but not all the way, then speed up‚Ä¶ we have conventions for what to put at those peaks (bosses!). But what matters is the shape of the curve.&lt;/p&gt;
    &lt;p&gt;You need to structure your game so that you push players up. They might need to climb the curve at different paces, which is why you might also have difficulty sliders. They might not be capable of getting all the way to the top, and that‚Äôs okay.&lt;/p&gt;
    &lt;p&gt;You also need to pace to allow room for everything that isn‚Äôt mastering the problem ‚Äî such as having fun with friends socially. But at the same time, things to do in the game need to come along at the right pace too!&lt;/p&gt;
    &lt;p&gt;Bottom line: Vary intensity and pressure, give players a chance to practice and moments to be tested.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eight: Games are made of games&lt;/head&gt;
    &lt;p&gt;Remember the game about clicking on a stick that appeared at a random location on screen? That‚Äôs also a rail shooter. You move the mouse and click on a spot in 2d space. Which is also not that different from an FPS ‚Äî only now you move the camera, not the cursor.&lt;/p&gt;
    &lt;p&gt;Almost no games are made of only one loop. Instead, we chain loops together ‚Äì complete loop A, and it probably outputs something that may serve as a tool or constraint on a different loop.&lt;/p&gt;
    &lt;p&gt;An FPS has the problem of moving the camera (instead of the mouse) to click on the stick. It also has a loop around moving around in 3d space. Moving around is actually made of several loops, probably, because it may be made of running and jumping and spatial orientation. Those are all problem types!&lt;/p&gt;
    &lt;p&gt;We speak sometimes of value chains: that‚Äôs where one loop outputs something to the next loop. We speak also of game economies, which is what happens when loops connect in non-linear ways, more like a web. This is not the sort of economy where you are simulating money or commerce. Instead it‚Äôs a metaphor for stocks and flows and other aspects of actual system dynamics science. In this view, your hit points is a ‚Äústock‚Äù or, if you like, a ‚Äúcurrency‚Äù you spend in a fight.&lt;/p&gt;
    &lt;p&gt;Games nest fractally, they web into complex economies, and they unroll chains of linked loops. That‚Äôs why they can be diagrammed in a multitude of ways.&lt;/p&gt;
    &lt;p&gt;At heart though, you can decompose them all into those elemental small problems, each with an interaction loop and a learning loop centered on that problem.&lt;/p&gt;
    &lt;p&gt;Bottom line: build small problems into larger webs, and map them so you understand how they connect.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nine: Actual systems design&lt;/head&gt;
    &lt;p&gt;The common question is ‚Äúokay, so how do I design a problem like that?‚Äù And that is indeed the unique bit in games, because the other items here are common to lots of other fields.&lt;/p&gt;
    &lt;p&gt;The list of possible problems is, as mentioned, enormous. This is a big rabbit hole. And once you consider that you can stack, web, and otherwise interlink problems, it means that there‚Äôs a giant composable universe of games (and game variants) to create.&lt;/p&gt;
    &lt;p&gt;Just bear in mind that because of varied tastes and experience, the diversity of the set of problems you pose is going to affect who wants to play your game.&lt;/p&gt;
    &lt;p&gt;There are basically a set of categories of problems that we know work, and this is the absolute simplest version of them:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mathematically complex puzzles&lt;/item&gt;
      &lt;item&gt;Figuring out how other humans think&lt;/item&gt;
      &lt;item&gt;Mastering your body and brain&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These break down into a ton of sub-problems, but there are less than you think, and you can actually find lists of them. The hard part is that often they each seem so small and trivial that we don‚Äôt think of them as actually being worth looking at!&lt;/p&gt;
    &lt;p&gt;They are also often in disguise: the problem behind where a tossed ball will land, and the problem of how much fuel you have left in your car if you keep driving at this speed, and the problem of when your hit points will run out given you have a poison status effect on you are the same thing.&lt;/p&gt;
    &lt;p&gt;But the more of them you as a designer have wrapped your head around, the more you can combine. And you‚Äôll find them very plastic and malleable. In fact, you could almost make a YouTube video about each one.&lt;/p&gt;
    &lt;p&gt;So where do you get them? Steal them. Other games, sure, but also, the world is full of systems that pose tough problems. You can grab them and reskin them.&lt;/p&gt;
    &lt;p&gt;Bottom line: not every mechanic has been invented, but a ton have. Build your catalog and workbench.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ten: Dressing and experience&lt;/head&gt;
    &lt;p&gt;In the end, the feedback layer of a game is everything about how you present it. The setting, the lore, the audio, the story, the art‚Ä¶&lt;/p&gt;
    &lt;p&gt;How you dress up the problems can change everything about how the player learns from it, and how they perceive the problem. The exact same underlying problem can be as different as picking up sticks or shooting someone in the face, or as mentioned, the calculus problem of estimating the trajectory of a variable in a system of rates of change (the ball, the car and its gas, the hit points and poison) might be the same but dressed extraordinarily differently.&lt;/p&gt;
    &lt;p&gt;When you think about how you dress up the problems, you are in the realm of metaphor. You are engaging in painting, poetry, and music composition, and rhetoric, and the bardic tradition, and all that other humanities stuff.&lt;/p&gt;
    &lt;p&gt;This is a giant and deep universe for you as a designer to dive into. A lot of this stuff gets called ‚Äúgame design,‚Äù but then again, we also often say that a given game designer is a frustrated moviemaker, too.&lt;/p&gt;
    &lt;p&gt;It is really easy to create an experience that clashes with the underlying problems it is teaching. There are fancy critical terms for this. You also need to be very conscious about whether you are building your game so that you are telling the player a story, or so that the player can tell stories with your game.&lt;/p&gt;
    &lt;p&gt;So the takeaway should be: this stuff is deeply, deeply synergistic with the ‚Äúgame system‚Äù stuff that this article is about, but they are not the same thing. And games is not the best place to learn how to do these things.&lt;/p&gt;
    &lt;p&gt;Those other fields have much longer traditions and loads of expertise and lessons. They won‚Äôt all apply to the issue of ‚Äúhow do I best dress up this collection of problems‚Äù but most of them will.&lt;/p&gt;
    &lt;p&gt;It does not frickin‚Äô matter if you start out wanting to make interesting problems, or if you start out wanting to provide a cool experience. You are going to need to do both to make the game really good.&lt;/p&gt;
    &lt;p&gt;Bottom line: game development is a compound art form. You can go learn those individual arts and the part unique to games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eleven: Motivations&lt;/head&gt;
    &lt;p&gt;Researchers have done a ton of studying ‚Äúwhy people play games.‚Äù This gets called ‚Äúmotivations.‚Äù&lt;/p&gt;
    &lt;p&gt;Motivations are basically about people‚Äôs personal taste for groups of problems and how those problems are presented, and characteristics of those problems and the situations in which you find them. Some people like problems where you destroy stuff. Others like problems where you bond with others. Some have trouble trusting other people. Others want to cooperate.&lt;/p&gt;
    &lt;p&gt;Not everyone likes the same sorts of problems or the same sorts of dressings. Some of this is down to personality types, some of it is down to social dynamics, how they were raised, what their local culture is like, what trauma they have had, and countless other psychological things. That‚Äôs why one fancy term for this is psychographics.&lt;/p&gt;
    &lt;p&gt;The big thing is, it‚Äôs not enough that the problems need to not be obvious to you, and also not be baffling to you. They also have to be interesting to you. What problems fit in that range is going to depend entirely on who you are, what your life experiences have been, what skills you have, and even what mood you are in.&lt;/p&gt;
    &lt;p&gt;Picking motivations and selecting problems based on them is a great way to design. But motivations are not the same thing as fun. They‚Äôre a filter, useful in marketing exercises and in building your game pillars (which is an exercise in focus and scope).&lt;/p&gt;
    &lt;p&gt;Scientists have spent a bunch of time surveying tons of people and have arrived at all sorts of conclusions that map people onto reasons to play and from there onto particular problems.&lt;/p&gt;
    &lt;p&gt;If you start with motivations, then you can go from there to types of problems, types of experience, and even player demographics. And then, if you want problems that are about interacting with people, well, there‚Äôs lists of those. If you want problems that are about managing resources, or solving math issues, there‚Äôs lists of those too.&lt;/p&gt;
    &lt;p&gt;Bottom line: no game is for everyone, so you will make better games if you know who you are posing problems for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Twelve: It‚Äôs simple, but not&lt;/head&gt;
    &lt;p&gt;I run into game developers who do not understand the above eleven steps all the time. And understanding all eleven is more valuable than building expertise in just one, because they depend on one another. This is because getting any one of the eleven wrong can break your game. The real issue is that each of these eleven things is often multiple fields of study. And yeah, you do need to become expert in at least one.&lt;/p&gt;
    &lt;p&gt;To pick one example, some of us have been working out the rule set for how you can link loops into a larger network of problems for literally over twenty years.&lt;/p&gt;
    &lt;p&gt;Others have spent their entire career doing nothing but figuring out how best to provide just the affordances part of feedback.&lt;/p&gt;
    &lt;p&gt;So game design is pretty simple. But the devil is in details that are not very far below the surface. It‚Äôs fairly easy to explain why something is fun for an given audience. It is much harder to build something new that is fun for an arbitrary person. That said, every single one of those fields has best practices, and they are mostly already written down. It‚Äôs just a lot to learn.&lt;/p&gt;
    &lt;p&gt;Put another way ‚Äî every single paragraph in this essay could be a book. Actually, probably already is several.&lt;/p&gt;
    &lt;p&gt;Bottom line: each of these topics is deep, but you want a smattering of all of them.&lt;/p&gt;
    &lt;p&gt;Some of you may not like this deconstructive view on how games are designed. That‚Äôs okay. Personally, I find it best to poke and prod at a problem, like ‚Äúhow do I get better at making games?‚Äù and treat it as a game. And that‚Äôs what I have done my whole career. The above is just my strategy guide. Someone else will have different strategies, I guarantee it.&lt;/p&gt;
    &lt;p&gt;But I also guarantee that if you get better at the above twelve things, you will get better at making games. This is a pragmatic list. And it will be helpful for making narrative games, puzzle games, boardgames, action games, RPGs, whatever. I breezed through it, but there are very specific tools you can pick up underneath each of these twelve things. It really is that simple, but also that hard, because that‚Äôs a frickin‚Äô long list if you want to actually dive into each of the twelve.&lt;/p&gt;
    &lt;p&gt;What that also means is that people designing games fail a lot at it. You might say, ‚Äúcan‚Äôt they just do the part they know how to do, and therefore predictably make good games?‚Äù&lt;/p&gt;
    &lt;p&gt;No, because players learn along with the designers. If you just make the same game, the one you know how to make, the players get bored because it‚Äôs nothing but problems they have seen before and already have their answers to. Sometimes, they get so bored that an entire genre dies.&lt;/p&gt;
    &lt;p&gt;And if you instead make it super-complicated by adding more problems, it might dissolve into noise for most people. Then nobody plays it. And then the genre dies too!&lt;/p&gt;
    &lt;p&gt;Game designers will routinely fail at making something fun. When the game of making games is played right, it is always right outside the edge of what the designers know how to do.&lt;/p&gt;
    &lt;p&gt;That‚Äôs where the fun lives, not just for the designer, but also for their audience.&lt;/p&gt;
    &lt;p&gt;That‚Äôs it, the whole cheat sheet. That‚Äôs it.&lt;/p&gt;
    &lt;p&gt;Hope it helps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.raphkoster.com/2025/11/03/game-design-is-simple-actually/"/><published>2025-11-06T22:24:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45843146</id><title>A Fond Farewell</title><updated>2025-11-07T17:37:39.666598+00:00</updated><content>&lt;doc fingerprint="af1c94b70bdeca9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Fond Farewell&lt;/head&gt;
    &lt;head rend="h2"&gt;The season we hoped would never come is here.&lt;/head&gt;
    &lt;p&gt;Dear Friends,&lt;/p&gt;
    &lt;p&gt;It is with a great appreciation and heartfelt emotions that we write to share some sad news. After more than 200 years of sharing a unique blend of weather, wit and wisdom, we‚Äôve made the very difficult decision to write the final chapter of this historical publication. The 2026 Farmers‚Äô Almanac will be our last edition.&lt;/p&gt;
    &lt;p&gt;Many of you grew up hearing your parents or grandparents quote from the Almanac, always having a copy nearby. Maybe you have planted by our Moon phases, consulted the Almanac for the ‚ÄúBest Days‚Äù to potty train, wean, or go fishing. We‚Äôre grateful to have been part of your life and trust that you‚Äôll help keep the spirit of the Almanac alive.&lt;/p&gt;
    &lt;p&gt;We are incredibly proud of the legacy we leave behind and are filled with gratitude. We appreciate and thank our loyal readers, contributors, and partners who have supported us through the years. Though the Almanac will no longer be available in print or online, it lives on within you.&lt;/p&gt;
    &lt;p&gt;So go ahead‚Äîplant your peas when the daffodils bloom. Watch for a red sky at night. Tell the kids how granddad always swore by the Almanac. That‚Äôs how our story stays alive.&lt;/p&gt;
    &lt;p&gt;With deepfelt appreciation,&lt;/p&gt;
    &lt;p&gt;Sandi Duncan and Peter Geiger&lt;lb/&gt;Editor and Editor Emeritus&lt;/p&gt;
    &lt;p&gt;P.S. Copies of the 2026 Farmers‚Äô Almanac are currently available on FarmersAlmanac.com, Amazon.com, and at these local stores. You will be able to access our website until December 2025. If you are a Member, please check your inbox for more information about your subscription.&lt;/p&gt;
    &lt;p&gt;This article was published by the Staff at FarmersAlmanac.com. If you have any questions about this article, please leave a comment for one of our experts. Priority is given to our Members, but all are welcome! You may also write in with your article ideas: [email protected].&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.farmersalmanac.com/fond-farewell-from-farmers-almanac"/><published>2025-11-07T03:01:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45843948</id><title>Leaving Meta and PyTorch</title><updated>2025-11-07T17:37:39.240201+00:00</updated><content>&lt;doc fingerprint="257951fc50a404c0"&gt;
  &lt;main&gt;**Leaving Meta and PyTorch**
It's finally time...
November 6th, 2025
[https://soumith.ch/blog.html](https://soumith.ch/blog.html)
Eleven years at Meta. Nearly all my professional life. Making many friends for life. Almost eight years leading PyTorch, taking it from nothing to 90%+ adoption in AI. Walking away from this was one of the hardest things I've ever done. But I'm leaving with a full heart.
PyTorch handles exascale training now. It powers foundation models that are redefining intelligence. It's in production at virtually every major AI company. It's taught in classrooms from MIT to rural India. The tools I dreamed about making accessible? They are. The barrier to entry I wanted to lower? It's almost gone.
To be clear, there‚Äôs so much more to do. As long as AI evolves at a breakneck pace, PyTorch will continue to play catch up. Obsessing over the yet-to-come sometimes makes us forget how much we‚Äôve already done.
To everyone who built this with me‚Äîwho believed research should be joyful, that tools should be elegant, that open source changes everything‚Äîthank you. This wasn't my journey. It was ours.
What's next for me? Something small. Something new. Something I don't fully understand yet. Something uncomfortable. I could have moved to something else inside Meta. But I needed to know what's out there. I needed to do something small again. I couldn't live with the counterfactual regret of never trying something outside Meta.
It's very hard to leave. I probably have one of the AI industry‚Äôs most leveraged seats, I lead the software layer that powers the entire AI industry. Every major AI company and hardware vendor are on a speed dial. This kind of power is really hard to give up. But curiosity ultimately won out in my head.
Keep making AI delicious and accessible. I'll be watching. Probably filing issues. Definitely staying involved.
# Is PyTorch going to be okay?
I don't want to be doing PyTorch forever. I don't want to be like Guido or Linus‚Äî bound to a single thing for decades. Last November, coinciding with the birth of my daughter, I started planning my exit with Aparna. My goal was to leave PyTorch in a good and stable place.
By this August, during the second half of my parental leave, I knew: Edward, Suo, Alban, Greg, John, Joe and Jana were ready. The team faced hard people, product, technical and organizational problems and didn‚Äôt feel the need to lean back on me to solve these for them (unlike in the past). The product story they crafted for the PyTorch Conference was coherent‚Äîreally coherent. The things I'd flagged red were turning healthy. The project didn't need me anymore. Unlike 2020-2022 (when I stepped down to go do robotics and came back when Lin, Dima and Dwarak left), I have strong confidence that this time PyTorch is truly resilient. The most aligned culture carriers of PyTorch ‚Äì Greg, Alban, Ed, Jason and Joe are at the decision table now, and people with strong value alignment ‚Äì Suo, John and Jana have joined them at the table. And there‚Äôs a long list of equally value-aligned people willing to sit at the table should any of these people leave. There are many little things that make up my confidence on the people ‚Äì John worked on Julia and open-source for a very long time (in fact we hacked a Torch.jl in 2015), Suo has been the strongest systems builder and strategic partner I‚Äôve had for the past two years, and Jana worked on resilient core systems for a very long time, I‚Äôve had long technical and organizational discussions with her over the past few months that give me confidence. And the product lineup and execution in 2025 should be sufficient evidence for any remaining doubt.
I‚Äôm confident that this band of PyTorchers are going to do exceptionally well. PyTorch might change in flavor because I no longer impose my own taste from the top, but I‚Äôm confident that the values are going to stay intact and the product is going to be awesome.
---
# My time at Meta
The early years of FAIR were absolutely magical. I was part of a small family of absolutely brilliant people building state-of-the-art AI out in the open. From working on GANs with Remi Denton, Arthur Szlam, Rob Fergus, Leon Bottou, Martin Arjovsky and the (now legendary) Alec Radford to building Starcraft bots with Gabriel Synnaeve, to building the first FAIR Cluster with Howard Mansell, to working on object detection with Adam Lerer and Piotr Dollar, to building PyTorch. It was more fun than I can describe in words. 2015 and 2016 were probably the most productive and professionally enjoyable years of my life. I‚Äôll probably romanticize this period of my life forever.
When I joined FAIR, I had massive impostor syndrome, and the first 3 months were very very difficult. I can‚Äôt credit Andrew Tulloch enough for being the most thoughtful, kind and welcoming mentor, without whom I wouldn‚Äôt have made it. I‚Äôm so damn bullish for Meta just from the fact that he‚Äôs back.
---
My time on PyTorch was special.
I loved every part of building it‚Äîdesigning it, managing it, being the PM, TL, comms lead, doc engineer, release engineer, squashing bugs, growth hacking, turning it into a coherent product with hundreds of people, transitioning it to industry stakeholdership ‚Äì the whole nine yards.
To the core PyTorch team at Meta: the engineers, researchers, open-source maintainers, docs writers, CI infrastructure folks, hardware partners, the community builders. To the hundreds more inside and outside Meta‚Äîthank you. You turned a library into a movement.
There are too many people to credit and thank, but I can't not mention Adam Paszke, Sam Gross, Greg Chanan, Joe Spisak, Alban Desmaison, Edward Yang, Richard Zou, Tongzhou Wang, Francisco Massa, Luca Antiga, Andreas K√∂pf, Zach DeVito, Zeming Lin, Adam Lerer, Howard Mansell and Natalia Gimelshein. And Schrep. They made the launch happen. And so many more people became centrally important later: Lu Fang, Xiaodong Wang, Junjie Bai, Nikita Shulga, Horace He, Mark Saroufim, Jason Ansel, Dmytro Dzhulgakov, Yangqing Jia, Geeta Chauhan, Will Constable, Briah Hirsh, Jane Xu, Mario Lezcano, Piotr Balecki, Yinghai Lu, Less Wright, Andrew Tulloch, Bruce Lin, Woo Kim, Helen Suk, Chris Gottbrath, Peng Wu, Joe Isaacson, Eli Uriegas, Tristan Rice, Yanan Cao, Elias Ellison, Animesh Jain, Peter Noordhuis, Tianyu Liu, Yifu Wang, Lin Qiao and hundreds more. It‚Äôs criminal of me to not take the space to list out everyone else I should be mentioning here. PyTorch is nothing without its people ‚ù§Ô∏è.
The most joyful moments of building PyTorch was meeting users eager to share their happiness, love and feedback. I remember a grad student coming to me at Neurips 2017, in a slurring emotional voice he said he‚Äôd been trying to make progress on his research for 3 years but within 3 months of using PyTorch he made so much progress that he was ready to graduate. That moment made it tangible that what we do matters, a lot, to a lot of people, even if you don't constantly hear from them. I do miss the intimacy of the PyTorch community, with a 300 person conference that felt like an extended family gathering, but I feel that‚Äôs a small price to pay considering the scale of impact PyTorch is truly having today ‚Äì yes the Conference is now 3,000 people where market-moving deals get brokered, but it‚Äôs helping orders of magnitude more people to do their best AI work. I miss the intimacy, but I'm proud of that growth.
---
To Mark Zuckerberg and Mike Schroepfer, who believed that open-sourcing is fundamentally important and is a sound business strategy. This is so hard to understand for most people within the course of business, but we‚Äôve run lock-step on this strategy without ever having to discuss it. Without you two, neither FAIR nor PyTorch would‚Äôve happened. And those mean so much to me.
To Yann LeCun and Rob Fergus, for building the magical early FAIR that I so revere.
To Aparna Ramani, a leader that I find so rare at Meta in her ability to hold a really high bar for the org, technically brilliant with the span to discuss deep infra systems and industry-strategy within the same conversation and for being an absolute execution-machine! I‚Äôve learned so much from you.
To Santosh, Kaushik, Delia, Oldham and Ben for being so welcoming to Infra. For someone coming over from FAIR with a wildly different culture, you all made me feel at home and made me part of the family, and thank you for that.
To all my managers who've championed me through the PSC video game ‚Äì Serkan, Howard, Jerome, Abhijit, Yoram, Joelle, Aparna and Damien ‚Äì I owe you a lifetime of drinks.
---
Signing off for now.
‚ÄîSoumith&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://soumith.ch/blog/2025-11-06-leaving-meta-and-pytorch.md.html"/><published>2025-11-07T06:14:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45845568</id><title>Sweep (YC S23) is hiring to build autocomplete for JetBrains</title><updated>2025-11-07T17:37:38.687554+00:00</updated><content>&lt;doc fingerprint="80a610e7c8dc27cd"&gt;
  &lt;main&gt;
    &lt;p&gt;The best AI coding assistant for JetBrains&lt;/p&gt;
    &lt;p&gt;We‚Äôre building an AI coding assistant for JetBrains IDEs.&lt;/p&gt;
    &lt;p&gt;You'll work with great builders on some of the hardest and most user-facing problems in AI today.&lt;/p&gt;
    &lt;p&gt;Whether an internship or full-time position, you'll work from our office in Dogpatch five days a week in-person.&lt;/p&gt;
    &lt;p&gt;Take https://github.com/JetBrains/intellij-platform-plugin-template and build something like GitHub Copilot autocomplete for JetBrains. Figure out how to do this quickly!&lt;/p&gt;
    &lt;p&gt;Sweep is the best enterprise AI coding assistant for JetBrains IDEs. No data ever leaves your VPC.&lt;/p&gt;
    &lt;p&gt;We have large customers in production. We ship fast.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/sweep/jobs/8dUn406-founding-engineer-intern"/><published>2025-11-07T12:00:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45845772</id><title>Meta projected 10% of 2024 revenue came from scams</title><updated>2025-11-07T17:37:38.450798+00:00</updated><content>&lt;doc fingerprint="65c4990d8c33f59a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Meta projected 10% of 2024 revenue came from scams and banned goods, Reuters reports&lt;/head&gt;
    &lt;p&gt;Meta has been making billions of dollars per year from scam ads and sales of banned goods, according internal Meta documents seen by Reuters.&lt;/p&gt;
    &lt;p&gt;The new report quantifies the scale of fraud taking place on Meta‚Äôs platforms, and how much the company profited from them.&lt;/p&gt;
    &lt;p&gt;Per the report, Meta internal projections from late last year said that 10% of the company‚Äôs total 2024 revenue would come from scammy ads and sales of banned goods ‚Äî which works out to $16 billion.&lt;/p&gt;
    &lt;p&gt;Discussions within Meta acknowledged the steep fines likely to be levied against the company for not stopping the fraudulent behavior on its platforms, and the company prioritized enforcement in regions where the penalties would be steepest, the reporting found. The cost of lost revenue from clamping down on the scams was weighed against the cost of fines from regulators.&lt;/p&gt;
    &lt;p&gt;The documents reportedly show that Meta did aim to significantly reduce the fraudulent behavior, but cuts to its moderation team left the vast majority of user-reported violations to be ignored or rejected.&lt;/p&gt;
    &lt;p&gt;Meta spokesperson Andy Stone told Reuters the documents were a ‚Äúselective view‚Äù of internal enforcement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWe aggressively fight fraud and scams because people on our platforms don‚Äôt want this content, legitimate advertisers don‚Äôt want it, and we don‚Äôt want it either.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Per the report, Meta internal projections from late last year said that 10% of the company‚Äôs total 2024 revenue would come from scammy ads and sales of banned goods ‚Äî which works out to $16 billion.&lt;/p&gt;
    &lt;p&gt;Discussions within Meta acknowledged the steep fines likely to be levied against the company for not stopping the fraudulent behavior on its platforms, and the company prioritized enforcement in regions where the penalties would be steepest, the reporting found. The cost of lost revenue from clamping down on the scams was weighed against the cost of fines from regulators.&lt;/p&gt;
    &lt;p&gt;The documents reportedly show that Meta did aim to significantly reduce the fraudulent behavior, but cuts to its moderation team left the vast majority of user-reported violations to be ignored or rejected.&lt;/p&gt;
    &lt;p&gt;Meta spokesperson Andy Stone told Reuters the documents were a ‚Äúselective view‚Äù of internal enforcement:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúWe aggressively fight fraud and scams because people on our platforms don‚Äôt want this content, legitimate advertisers don‚Äôt want it, and we don‚Äôt want it either.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sherwood.news/tech/meta-projected-10-of-2024-revenue-came-from-scams-and-banned-goods-reuters/"/><published>2025-11-07T12:39:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45845800</id><title>From Memorization to Reasoning in the Spectrum of Loss Curvature</title><updated>2025-11-07T17:37:38.241542+00:00</updated><content>&lt;doc fingerprint="2c9e24199ee382cf"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computation and Language&lt;/head&gt;&lt;p&gt; [Submitted on 28 Oct 2025 (v1), last revised 31 Oct 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:From Memorization to Reasoning in the Spectrum of Loss Curvature&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We characterize how memorization is represented in transformer models and show that it can be disentangled in the weights of both language models (LMs) and vision transformers (ViTs) using a decomposition based on the loss landscape curvature. This insight is based on prior theoretical and empirical work showing that the curvature for memorized training points is much sharper than non memorized, meaning ordering weight components from high to low curvature can reveal a distinction without explicit labels. This motivates a weight editing procedure that suppresses far more recitation of untargeted memorized data more effectively than a recent unlearning method (BalancedSubnet), while maintaining lower perplexity. Since the basis of curvature has a natural interpretation for shared structure in model weights, we analyze the editing procedure extensively on its effect on downstream tasks in LMs, and find that fact retrieval and arithmetic are specifically and consistently negatively affected, even though open book fact retrieval and general logical reasoning is conserved. We posit these tasks rely heavily on specialized directions in weight space rather than general purpose mechanisms, regardless of whether those individual datapoints are memorized. We support this by showing a correspondence between task data's activation strength with low curvature components that we edit out, and the drop in task performance after the edit. Our work enhances the understanding of memorization in neural networks with practical applications towards removing it, and provides evidence for idiosyncratic, narrowly-used structures involved in solving tasks like math and fact retrieval.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Jack Merullo [view email]&lt;p&gt;[v1] Tue, 28 Oct 2025 10:09:35 UTC (2,148 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 31 Oct 2025 00:26:33 UTC (2,148 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.24256"/><published>2025-11-07T12:43:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45845948</id><title>Is Software the UFOlogy of Engineering Disciplines?</title><updated>2025-11-07T17:37:38.147916+00:00</updated><content>&lt;doc fingerprint="6553151668a70091"&gt;
  &lt;main&gt;
    &lt;p&gt;One area where software development lags far behind other technical design disciplines like electronic and mechanical engineering is in standards of evidence.&lt;/p&gt;
    &lt;p&gt;To illustrate what I mean, I want to talk about the July 2023 congressional hearings on Unidentified Anomalous Phenomena (‚ÄúUAPs‚Äù).&lt;/p&gt;
    &lt;p&gt;Former military and intelligence personnel gave testimony under oath about encounters with UAP, and some sensational claims were made by David Grusch ‚Äì who had worked with the UAP Task Force at the Department of Defence ‚Äì about captured ‚Äúnon-human‚Äù aircraft, materials and ‚Äúbiologics‚Äù being held by private defence contractors.&lt;/p&gt;
    &lt;p&gt;Some UFO researchers hold the testimonies of the very credible witnesses as proof that we are being visited by at least one civilisation that‚Äôs far in advance technologically of ours.&lt;/p&gt;
    &lt;p&gt;The scientists working in the DoD‚Äôs All-domain Anomaly Resolution Office (AARO), and in NASA‚Äôs UAP working group disagree with that interpretation.&lt;/p&gt;
    &lt;p&gt;Witness testimony ‚Äì even given under oath ‚Äì is merely evidence that somebody said something. And maybe they really believe what they say. But that doesn‚Äôt make it real.&lt;/p&gt;
    &lt;p&gt;Since that congressional hearing more than 2 years ago, no hard evidence has entered the public or scientific domain that supports Grusch‚Äôs claims.&lt;/p&gt;
    &lt;p&gt;The NASA working group complained that the military were less than forthcoming with good data that it‚Äôs believed they may be holding (they admit as much on the record). But, again, that‚Äôs not in itself evidence of ‚Äúnon-human‚Äù visitation and alien vehicle reverse-engineering projects. It‚Äôs evidence that the military and their contractors are keeping secrets. Who knew, right?&lt;/p&gt;
    &lt;p&gt;And, yes, there are videos ‚Äì confirmed by the military to be genuine ‚Äì showing anomalous objects recorded by Airforce and Navy personnel during routine operations off the coast of the United States and in combat zones around the world.&lt;/p&gt;
    &lt;p&gt;But those videos, taken by themselves, show nothing particularly sensational. Accounts of ‚Äúinstant acceleration‚Äù and other impossible manoeuvres accompany these videos, but are not captured in them.&lt;/p&gt;
    &lt;p&gt;And that has been the general nature of UFO/UAP evidence going back to the 1940s. When the anecdotal noise is filtered out, there‚Äôs very little left in credible, meaningfully testable evidence to support the extraterrestrial (or extra-dimensional, or time-traveller, or hollow-earth-dweller or Atlantean or Lunar Nazi) hypothesis.&lt;/p&gt;
    &lt;p&gt;What hard evidence does exist points to one or more genuinely unknown physical phenomena. But that doesn‚Äôt mean aliens. That just means ¬Ø\_(„ÉÑ)_/¬Ø&lt;/p&gt;
    &lt;p&gt;More than 20 years ago, I corresponded with famous UFO researcher Stanton T. Friedman. His central claim was that ‚Äúthe evidence is overwhelming that some UFOs are extraterrestrial spacecraft‚Äù. He was kind enough ‚Äì at his own expense ‚Äì to mail me a thick folder of this ‚Äúoverwhelming evidence‚Äù, which included reports written after official government studies in the US, France and other countries. (The UK MOD‚Äôs 1990s study, Project Condign, was declassified a couple of years later, adding to the corpus of scientific studies.)&lt;/p&gt;
    &lt;p&gt;All of these studies, if you read beyond the executive summary, come to a similar conclusion: UFOs are real, and we don‚Äôt know what they are.&lt;/p&gt;
    &lt;p&gt;They usually also conclude that further scientific study is warranted. But that‚Äôs rarely followed through, because UFOs are the ‚Äúthird rail‚Äù of a scientific career ‚Äì unless you‚Äôre safely tenured, like Avi Loeb or Michio Kaku, most scientists daren‚Äôt touch the subject.&lt;/p&gt;
    &lt;p&gt;Anyway, back to Mr Friedman. Stanton Friedman was a scientist ‚Äì a nuclear physicist (a real one!). He would often wear these credentials as evidence that his approach to the study of UFOs was rigorous in the same sense that his work on, say, nuclear space propulsion was rigorous.&lt;/p&gt;
    &lt;p&gt;But that was simply not the case. Friedman, like most UFOlogists ‚Äì not all, mind ‚Äì approached the subject like an investigative journalist. He didn‚Äôt look for physical evidence. He looked for documentation to support his theories, and his ‚Äúrigour‚Äù manifested in attempts to authenticate these documents.&lt;/p&gt;
    &lt;p&gt;Even if the MAJESTIC documents are from genuine top secret classified government files (and that‚Äôs very much disputed still to this day), a document is only evidence that somebody wrote something down.&lt;/p&gt;
    &lt;p&gt;So I was not overwhelmed by the evidence Stanton sent me. Intrigued? Definitely. Open-and-shut case? Definitely not.&lt;/p&gt;
    &lt;p&gt;I agree with many of the official government studies: UFOs warrant serious scientific investigation. But, curiously, many UFOlogists ‚Äì including Stanton Friedman ‚Äì disagreed.&lt;/p&gt;
    &lt;p&gt;I had been following the work of an electronic engineer, at the time working in NASA‚Äôs Jet Propulsion Labs, called Scot Stride who was proposing multi-modal instrumented searches of the sky to collect more and better data on these phenomena.&lt;/p&gt;
    &lt;p&gt;He called it ‚ÄúSETV‚Äù ‚Äì the Search for Extraterrestrial Visitation. Not to be confused with SETA ‚Äì the Search for Extraterrestrial Artefacts. SETV‚Äôs null hypothesis ‚Äì that no UFOs are extraterrestrial technology ‚Äì was concerned with contemporary visitation.&lt;/p&gt;
    &lt;p&gt;Now, to me, a not-so-long-ago-at-the-time physics bod, SETV sounded like a good idea. The challenge in understanding the nature of UFOs has always been the amount and the quality of the data ‚Äì too much noise, very little signal.&lt;/p&gt;
    &lt;p&gt;An object tracked by multiple sensors, from multiple locations, could provide far clearer data on the reality (as in, is this object real and not, say, a sensor blip?), the size, the distance, and therefore the speed or acceleration of objects in the sky.&lt;/p&gt;
    &lt;p&gt;But Stanton poured cold water on the idea of instrumented searches. UFOs, he told me, cannot be studied scientifically. Which I thought was a little odd, given his physics credentials ‚Äì far superior to mine ‚Äì and that he was kind of using them to shore up the credibility of his work. He was the ‚Äúflying saucer physicist‚Äù.&lt;/p&gt;
    &lt;p&gt;SETV, as far as I know, never got off the ground ‚Äì perhaps due to lack of funding. (A similar initiative called UFODATA also appears to have stalled. I hold out some hope Avi Loeb may help to divert some research money into other instrumented sky searches.)&lt;/p&gt;
    &lt;p&gt;But, as of today, the state of the art in UFO/UAP evidence is lots of noise and very little signal.&lt;/p&gt;
    &lt;p&gt;I‚Äôve met similar hostility from folks who, in one breath, claim that software engineering is ‚Äúscientific‚Äù ‚Äì because data ‚Äì but row back on that when I suggest we might need better data: more signal, less noise.&lt;/p&gt;
    &lt;p&gt;Most empirical studies into our discipline are small, attempting to extract meaningful trends from statistically insignificant sample sizes. This leaves them wide open to statistical noise.&lt;/p&gt;
    &lt;p&gt;Many studies are, like the congressional UAP hearings, building on reported ‚Äì rather than directly observed ‚Äì data. If a development team tells you that switching from white bread to wholemeal reduced their bug counts, that‚Äôs anecdote, not hard evidence.&lt;/p&gt;
    &lt;p&gt;Some folks say that software engineering is scientific because it‚Äôs grounded in scientific principles ‚Äì many would argue that engineering is the ‚Äúappliance of science‚Äù.&lt;/p&gt;
    &lt;p&gt;But what are the scientific principles software engineering is founded on? We might argue that discrete mathematics ‚Äì set theory, logic, graph theory etc ‚Äì is a science. And so there‚Äôs perhaps some merit, when these theories are applied (e.g., in program verification), in saying that we‚Äôre applying science.&lt;/p&gt;
    &lt;p&gt;But we‚Äôre not testing the theories. They are take as a given ‚Äì as logically proven. And by ‚Äúlogically proven‚Äù, I mean logically consistent with all the connected theories. A scientist might argue that proofs aren‚Äôt science.&lt;/p&gt;
    &lt;p&gt;To quote Donald Knuth:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;‚ÄúBeware of bugs in the above code; I have only proved it correct, not tried it.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Or, in the words of the Second Doctor: ‚ÄúLogic, my dear Zoe, merely enables one to be wrong with authority‚Äù.&lt;/p&gt;
    &lt;p&gt;Just because axioms are logically consistent, that doesn‚Äôt mean they‚Äôre true. To establish truth, we must defer to reality. We must test them in the real world. In this sense, mathematics is not science. It‚Äôs applied philosophy.&lt;/p&gt;
    &lt;p&gt;And that brings me to the third of the ways that I and others part company. In order to meaningfully test a hypothesis, we must be able to know with high confidence when the data contradicts it. If software engineering ‚Äòs to be truly scientific, our hypotheses need to be refutable.&lt;/p&gt;
    &lt;p&gt;As computer programmers, we know the challenge of expressing ideas in a way that can‚Äôt be misinterpreted. It‚Äôs a large part of our work, and the main reason why computer programming remains a minority pursuit. It is hard.&lt;/p&gt;
    &lt;p&gt;But just like the cognitive dissonance of the anti-science ‚Äúflying saucer physicist‚Äù, many of us hold the contradictory belief that hypotheses about our field of work need not be expressed in any refutable form ‚Äì they need not be meaningfully testable ‚Äì even though that‚Äôs kind of what we do for a living.&lt;/p&gt;
    &lt;p&gt;When we combine woolly and untestable claims with small, noisy data sets, comprising mostly of anecdotes, software engineering as a discipline falls well within the territory of UFOlogy.&lt;/p&gt;
    &lt;p&gt;Now, not everybody subscribes to the idea that for a study to be scientific, it requires hypotheses to be refutable. Physics undergraduates have refutability drummed into us from the start (e.g., Wolfgang Pauli‚Äôs ‚Äúnot even wrong‚Äù jab at ambiguous claims), and it causes friction with other fields of study that describe themselves as ‚Äúscientific‚Äù, but that lack refutability.&lt;/p&gt;
    &lt;p&gt;But whether we agree on the definition of ‚Äúscientific‚Äù is not really the important thing here. What matters is where low-signal, largely anecdotal, non-refutable experiments have led us in our understanding of not just what works and what doesn‚Äôt in specific situations, but why.&lt;/p&gt;
    &lt;p&gt;A lot of what we think we know about creating and adapting software is built on the equivalent of UFO reports. Let me give you an example of what can happen when research cuts through that noise.&lt;/p&gt;
    &lt;p&gt;In their study of developer testing in Java IDEs, researchers discovered that, of the participants who claimed they did Test-Driven Development, analysis of their real IDE activity showed that only about 8% actually did.&lt;/p&gt;
    &lt;p&gt;The implication here is that 92% of what we think we know about TDD and it‚Äôs outcomes is, in reality, based on developers doing something else. Many other studies ‚Äì on much smaller scales, usually ‚Äì call me to question whether participants were really doing TDD. And, indeed, whether the authors of the studies could even tell if they weren‚Äôt.&lt;/p&gt;
    &lt;p&gt;The upshot of all this is that when skeptics demand ‚Äúproof‚Äù of the benefits of TDD, even someone with 26 years experience doing and teaching it like me, has to resort to ‚Äúyou‚Äôll just have to take my word for it‚Äù. Like the UFO witnesses who ‚Äúknow what they saw‚Äù, I know there are real benefits. I just don‚Äôt have the hard data to back it up. For every study that finds there are, there‚Äôs another one that concludes ¬Ø_(„ÉÑ)_/¬Ø&lt;/p&gt;
    &lt;p&gt;I could survey developers who‚Äôve been doing TDD for, say, more than a year, to ask if they believe there are real benefits. I could ask them if they‚Äôd ever consider going back to test-after. (I already have a pretty good idea what the response would be.)&lt;/p&gt;
    &lt;p&gt;But this is shaky ground. The majority of developers using ‚ÄúAI‚Äù coding assistants, for example, believe they‚Äôre being more productive. But data on delivery lead times and release stability paints the opposite picture in the majority of cases.&lt;/p&gt;
    &lt;p&gt;As a teacher and a mentor, the lack of genuine signal in the software engineering body of knowledge makes my job a lot harder.&lt;/p&gt;
    &lt;p&gt;I have to resort to my powers of persuasion, and I have to rely on people‚Äôs willingness to at the very least suspend their disbelief. I did not need to be persuaded that force = mass x acceleration, because the evidence is so compelling.&lt;/p&gt;
    &lt;p&gt;It also leaves our profession vulnerable to spurious claims that aren‚Äôt backed up by credible evidence, but can‚Äôt easily be disproved. I might argue that a whole bunch of people‚Äôs pensions might be about to be wiped out by a spurious claim about the impact of a particular technology on software teams. Our industry‚Äôs very much the rabbit that the GenAI folks are banking on other industries chasing. If programmers don‚Äôt get much benefit, what chance lawyers or doctors or teachers?&lt;/p&gt;
    &lt;p&gt;I appreciate that the complex socio-technical nature of software development presents many challenges to a rigorously scientific approach to gaining useful insights ‚Äì to learning to predict the effects of pulling certain levers so that we can more confidently engineer the outcomes we want. And I accept that there will always be aspects that remain beyond the scientific method.&lt;/p&gt;
    &lt;p&gt;However, it feels to me like we‚Äôre not even really trying. And we‚Äôre so good at making excuses for why we can‚Äôt do better.&lt;/p&gt;
    &lt;p&gt;If there‚Äôs one thing we‚Äôre not short of as a discipline, it‚Äôs hard data. Our activities ‚Äì like the actions we perform in our IDEs, the code itself, the version histories in our repos, the outputs of builds, the results of testing and linting, the telemetry from production systems ‚Äì are radiating a rich and long tail of hard data; data about things that actually happened, and not just what we believe or claim happened.&lt;/p&gt;
    &lt;p&gt;If we were comets, you‚Äôd want to fly your probe through that tail.&lt;/p&gt;
    &lt;p&gt;Again, there are many challenges and problems to be solved, not least of which is the ad hoc, proprietary, non-standardised nature of all that data.&lt;/p&gt;
    &lt;p&gt;In that sense, we are arguably one of the least mature of the engineering disciplines. My Dad‚Äôs architectural CAD system can tell you what order a house has to be built in (you have to do that these days to get planning permission) and can even generate orders for building materials with specific suppliers.&lt;/p&gt;
    &lt;p&gt;Our tooling workflows are still mostly held together with twigs and tape. And that‚Äôs chiefly because we so seldom consider the whole picture when we design development tools ‚Äì a random landscape of point solutions that don‚Äôt play nice with each other.&lt;/p&gt;
    &lt;p&gt;We lack the data interchange standards of more mature disciplines. And that could well be because we also lack the underlying rigour ‚Äì including rigour around terminology. How do we standardise things that go by many different names?&lt;/p&gt;
    &lt;p&gt;But that is a solvable problem. If building design and electronic engineering and mechanical engineering can do it, so can we. Heck, we did it for them! (We suffer from a condition I call ‚Äúbuilder‚Äôs houses‚Äù.)&lt;/p&gt;
    &lt;p&gt;And if this reads like a bit of a manifesto, so be it. I‚Äôm well aware that I‚Äôm in a minority who feel this way about software engineering. But if you‚Äôre out there thinking along similar lines, maybe drop me a line?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://codemanship.wordpress.com/2025/11/07/is-software-the-ufology-of-engineering-disciplines/"/><published>2025-11-07T13:09:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45845958</id><title>We chose OCaml to write Stategraph</title><updated>2025-11-07T17:37:37.990885+00:00</updated><content>&lt;doc fingerprint="e1d8bb0b2f1cafc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why we chose OCaml to write Stategraph&lt;/head&gt;
    &lt;p&gt;We're building infrastructure that manages other people's infrastructure. State corruption can't be "rare." It has to be impossible. That's why we chose OCaml.&lt;/p&gt;
    &lt;p&gt;Stategraph stores Terraform state as a dependency graph in PostgreSQL with resource-level locking. The challenge isn't building a database-backed state store. The challenge is ensuring that concurrent operations can never corrupt state, even with concurrent operations/users, that database schema changes break the build instead of production, and that JSON transformations are correct.&lt;/p&gt;
    &lt;p&gt;We chose OCaml because its type system catches entire categories of bugs at compile time that would require extensive testing and still slip through in other languages.&lt;/p&gt;
    &lt;head rend="h2"&gt;Type-safe data structures&lt;/head&gt;
    &lt;p&gt;Here's a scenario every infrastructure engineer has seen. Two Terraform operations run concurrently and both read a resource in an &lt;code&gt;active&lt;/code&gt; state. One updates it while the other destroys it. Without proper coordination, you risk marking the resource as &lt;code&gt;destroyed&lt;/code&gt; in state while it's still being modified in the cloud.&lt;/p&gt;
    &lt;p&gt;Most systems handle this defensively with locks and runtime validation, but race conditions are hard to test and the resulting state corruption usually appears in production, not CI.&lt;/p&gt;
    &lt;p&gt;Stategraph tackles this in two ways. Immutability and database-level locking prevent concurrent writes from corrupting state, while OCaml's type system makes the underlying data structures themselves safer by construction. Resources, outputs, and instances are all defined as strongly-typed records, so you can't access a field that doesn't exist or mix up field types. The compiler enforces correctness before anything runs.&lt;/p&gt;
    &lt;p&gt;If you try to access &lt;code&gt;state.versions&lt;/code&gt; (typo) instead of &lt;code&gt;state.version&lt;/code&gt;, you get a compiler error. If you try to assign a string to &lt;code&gt;serial&lt;/code&gt;, you get a compiler error. If you forget to handle &lt;code&gt;None&lt;/code&gt; in the outputs field, you get a compiler error with exhaustiveness checking.&lt;/p&gt;
    &lt;p&gt;This extends throughout the codebase. Every Terraform resource type, every state transition, and every database record is strongly typed. The compiler catches entire categories of bugs at compile time, like accessing non-existent fields, missing null checks, or database schema mismatches.&lt;/p&gt;
    &lt;head rend="h2"&gt;The database schema drift problem&lt;/head&gt;
    &lt;p&gt;You're iterating on your database schema by renaming a column, changing a type, or adding a constraint. In most languages, you update the schema, deploy the migration, and hope you caught all the queries that reference the old structure. You didn't because a query somewhere references the old column name. It works in dev with the old schema but crashes in staging with the new schema.&lt;/p&gt;
    &lt;p&gt;Stategraph uses typed SQL where every query declares explicit types for its parameters and return values. When you change a query's type signature, every call site in the codebase must be updated to match, and the compiler enforces this.&lt;/p&gt;
    &lt;p&gt;This query expects specific types. The &lt;code&gt;state_id&lt;/code&gt; must be a UUID, &lt;code&gt;mode&lt;/code&gt; must be text, and &lt;code&gt;module_&lt;/code&gt; is optional text. The return value is typed as &lt;code&gt;bigint&lt;/code&gt;. If you try to pass a string where a UUID is expected, you get a compiler error. If you forget to handle the optional return value, you get a compiler error.&lt;/p&gt;
    &lt;p&gt;When you update a query to match a new schema, the type system ensures every place that calls that query gets updated too. You can't deploy code where query definitions and their usage are out of sync.&lt;/p&gt;
    &lt;head rend="h2"&gt;JSON transformations that can't lose data&lt;/head&gt;
    &lt;p&gt;Stategraph ingests Terraform state as JSON, normalizes it into a graph, stores it in PostgreSQL, and reconstructs it back to JSON when Terraform requests it. Every transformation is a place where data can get lost or corrupted, whether from a field you forgot to serialize, a nested structure you flattened incorrectly, or a type that doesn't round-trip.&lt;/p&gt;
    &lt;p&gt;Testing can catch some of this, and round-trip tests help, but you're fundamentally relying on test coverage. Missed cases show up when someone's Terraform state comes back missing a field.&lt;/p&gt;
    &lt;p&gt;OCaml has a feature called PPX (preprocessor extensions) that generates serialization code automatically. You define the type, and the serializer is generated from the type definition.&lt;/p&gt;
    &lt;p&gt;When you add a field, the serializer is regenerated. When you change a type, the serializer is regenerated. If you forget to handle a case, the exhaustiveness checker catches it at compile time. You don't write serialization tests because the type system guarantees serialization is correct.&lt;/p&gt;
    &lt;p&gt;This is how Stategraph handles Terraform's resource types. Every AWS resource, every GCP resource, every Azure resource is an OCaml type with automatic JSON serialization. We don't write serialization code. We don't test round-trips manually. The type system handles it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Race conditions prevented by default&lt;/head&gt;
    &lt;p&gt;Terraform operations are inherently concurrent. Multiple users apply changes, CI pipelines run in parallel, and drift detection scans resources continuously. Coordinating all of this without data races requires careful mutex management and defensive programming, and it's easy to get wrong.&lt;/p&gt;
    &lt;p&gt;OCaml provides immutability by default, so you can't accidentally share mutable state between concurrent operations because there is no mutable state by default. When you want to modify something, you create a new version explicitly. This eliminates entire categories of race conditions.&lt;/p&gt;
    &lt;p&gt;One operation can't corrupt another operation's view of state because state is immutable by default. When combined with PostgreSQL's row-level locking at the database layer, concurrent operations compose correctly without manual mutex management or defensive copying.&lt;/p&gt;
    &lt;head rend="h2"&gt;Error handling with discipline&lt;/head&gt;
    &lt;p&gt;Type safety is only half of what makes Stategraph robust. The other half is discipline in how we use those types.&lt;/p&gt;
    &lt;p&gt;We encode errors as variants and exhaustively match every case. We never use a catch-all "else" clause that matches everything. When we add a new error to the system, the compiler tells us every place we aren't handling it. This is how robust systems are built. Systems can fail in far more ways than they succeed, and the compiler ensures we handle all of them.&lt;/p&gt;
    &lt;p&gt;This discipline extends throughout the codebase. Every error case is explicit. Every state transition is enumerated. Every optional value is handled. The type system gives us the tools, but discipline is what turns those tools into reliability.&lt;/p&gt;
    &lt;head rend="h2"&gt;The difference in practice&lt;/head&gt;
    &lt;p&gt;The same categories of bugs. Different places to catch them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Production systems that can't afford bugs&lt;/head&gt;
    &lt;p&gt;This isn't academic type theory. Production systems use OCaml for exactly this reason.&lt;/p&gt;
    &lt;p&gt;At Terrateam, we process thousands of concurrent Terraform operations daily, managing infrastructure for hundreds of organizations where a state corruption bug would cascade across every customer. We're built on OCaml, and the type system catches bugs at compile time that would be production incidents in other languages.&lt;/p&gt;
    &lt;p&gt;Jane Street trades billions daily on OCaml infrastructure. Their trading systems handle concurrent market data and execute trades with zero tolerance for race conditions or undefined behavior. They chose OCaml because correctness isn't optional.&lt;/p&gt;
    &lt;head rend="h4"&gt;Pattern Recognition&lt;/head&gt;
    &lt;p&gt;Systems that absolutely cannot fail choose languages where certain failures are impossible, not just unlikely. Testing finds bugs, but types prevent entire categories of bugs from existing.&lt;/p&gt;
    &lt;head rend="h2"&gt;But who knows OCaml?&lt;/head&gt;
    &lt;p&gt;This is the most common objection, and OCaml developers are rare. This is true.&lt;/p&gt;
    &lt;p&gt;But here's what we've found. Engineers who understand distributed systems, type systems, and correctness learn OCaml quickly. The learning curve from Rust, Haskell, or even TypeScript with advanced types is gentler than you'd expect because the concepts transfer even if the syntax is unfamiliar.&lt;/p&gt;
    &lt;p&gt;More importantly, OCaml codebases are stable. We're not debugging race conditions or chasing down production crashes from schema drift. We're not writing extensive test suites for serialization edge cases. We're building features while the type system handles the category of bugs that would otherwise consume engineering time.&lt;/p&gt;
    &lt;p&gt;When you encode correctness in types, maintenance gets easier instead of harder. New engineers spend less time understanding implicit invariants and more time writing code the compiler verifies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Correctness as a feature&lt;/head&gt;
    &lt;p&gt;We're building Stategraph to manage Terraform state for infrastructure that runs production applications. State corruption has to be impossible instead of unlikely. Invalid state transitions need to be prevented by the compiler instead of caught by tests. Schema drift needs to break the build instead of production.&lt;/p&gt;
    &lt;p&gt;That's what OCaml gives us. It provides a type system that makes entire categories of bugs impossible instead of just unlikely. The compiler proves properties about our code that testing can only approximate.&lt;/p&gt;
    &lt;p&gt;OCaml's compile-time guarantees are why we use it to build Stategraph.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://stategraph.dev/blog/why-we-chose-ocaml"/><published>2025-11-07T13:10:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45846090</id><title>OpenMW 0.50.0 Released ‚Äì open-source Morrowind reimplementation</title><updated>2025-11-07T17:37:37.850044+00:00</updated><content/><link href="https://openmw.org/2025/openmw-0-50-0-released/"/><published>2025-11-07T13:25:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45846360</id><title>I'm Making a Small RPG and I Need Feeback Regarding Performance</title><updated>2025-11-07T17:37:37.761555+00:00</updated><content/><link href="https://jslegenddev.substack.com/p/im-making-a-small-rpg-and-i-need"/><published>2025-11-07T13:52:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45846517</id><title>I Love OCaml</title><updated>2025-11-07T17:37:37.395470+00:00</updated><content>&lt;doc fingerprint="e7b610ff8bbeacc1"&gt;
  &lt;main&gt;
    &lt;p&gt;pub rsa4096 2023-09-22 [SC]&lt;/p&gt;
    &lt;p&gt;uid Marc Coquand &amp;lt;marc@mccd.space&amp;gt;&lt;/p&gt;
    &lt;p&gt;Every morning, I wake up and ask myself: why isn‚Äôt OCaml more popular? I mean, the language is not perfect, but the more I use it the more I feel like this old language had it all figured out, somehow. I mean, not in the literal sense: you write &lt;code&gt;String.of_X&lt;/code&gt;
instead of &lt;code&gt;String.from_X&lt;/code&gt; because the language has French
origins. But it is perfect in the sense that it has everything that is
important to me, except popular adoption. OCaml has its quirks, its old
age, but at the same time there is so much I appreciate about it.&lt;/p&gt;
    &lt;p&gt;I have some experience building amateur and professional software, in many different languages, and as a result I have collected a list of characteristics that I‚Äôve come to appreciate over time. I think my journey into programming is different from many. I learned and adored functional programming before working in the industry, and while not my very first language, Haskell was important to me early on. Functional programming has allowed me to break big, complex problems down into subproblems that I know how to solve. It has made me a better thinker. Add to that the static guarantees of Haskell, which makes the mental overhead much lower than for other languages, and I am also more productive. Most importantly, with Haskell, I can focus more on the fun parts of programming.&lt;/p&gt;
    &lt;p&gt;However, Haskell‚Äôs issues lie in its immense complexity and slow compile times. I did say that Haskell lowers the mental overhead of programming, but that‚Äôs only if you use a small subset of the language. However because much of the community is very maximalist, introducing a lot of complexity into the code becomes inevitable. Much of the code you interact with is too ‚Äúsmart‚Äù, and becomes very hard to grok. Its runtime is also very complex, and there‚Äôs always the chance of running into notorious ‚Äúspace leaks‚Äù, that are extremely hard to debug.&lt;/p&gt;
    &lt;p&gt;At some point, I started exploring a language that is probably the polar opposite to Haskell: Go. With Go, I learned to appreciate simplicity and low-levels of abstractions, a good set of tooling, fast performance and fast compilation speed. I also started to appreciate good documentation that is easily available offline. The culture around Go also places a lot of value on simple solutions, which made interacting with the ecosystem easier. I can jump into any code base and understand what is happening.&lt;/p&gt;
    &lt;p&gt;Over time, I also grew to hate the issues that come with the language being so conservative: it is verbose in its error handling yet manages to be fragile. At the same time, it doesn‚Äôt have explicit null checks. These factors combined makes Go quite unpleasant and easy to write buggy code in. I also found myself missing a REPL or fast way of interacting with the program. The language is ‚Äúpredictably disappointing‚Äù, which I guess is a good thing. However, the solutions to those disappointments have been around before the language was even created and I am just left feeling that these solutions could have been implemented, and the compiler would not be much more complex as a result. It just genuinely felt like the Go language designers didn‚Äôt want to engage with any of the ideas coming from functional programming. But I digress.&lt;/p&gt;
    &lt;p&gt;From these experiences, a list of features I consider to be ‚Äúgood‚Äù features in a general programming language started to emerge:&lt;/p&gt;
    &lt;p&gt;And then, enter OCaml. This language just checks so many boxes:&lt;/p&gt;
    &lt;p&gt;I‚Äôm left feeling that the authors of OCaml have good taste. It is an old language, and there are a few features that could probably be left out like the OOP-related features, and some libraries in the ecosystem over-complicate things like in Haskell. But overall, it‚Äôs just damn good. There are a lot of other features I appreciate about OCaml that I didn‚Äôt share. But to summarize why I love it: the right balance between simple and expressive, good documentation and good tooling.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mccd.space/posts/ocaml-the-worlds-best/"/><published>2025-11-07T14:05:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45847465</id><title>A.I. and Social Media Contribute to 'Brain Rot'</title><updated>2025-11-07T17:37:37.231259+00:00</updated><content/><link href="https://www.nytimes.com/2025/11/06/technology/personaltech/ai-social-media-brain-rot.html"/><published>2025-11-07T15:34:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45848083</id><title>Denmark's government aims to ban access to social media for children under 15</title><updated>2025-11-07T17:37:36.988346+00:00</updated><content>&lt;doc fingerprint="3593df9918ccdfc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Denmark‚Äôs government aims to ban access to social media for children aged under 15&lt;/head&gt;
    &lt;p&gt;COPENHAGEN, Denmark (AP) ‚Äî Denmark‚Äôs government on Friday announced an agreement to ban access to social media for anyone under 15, ratcheting up pressure on Big Tech platforms as concerns grow that kids are getting too swept up in a digitized world of harmful content and commercial interests.&lt;/p&gt;
    &lt;p&gt;The move, led by the Ministry of Digitalization, aims to set the age limit for access to social media but give some parents ‚Äî after a specific assessment ‚Äî the right to give consent to let their children access social media from age 13.&lt;/p&gt;
    &lt;p&gt;Such a measure would be among the most sweeping steps yet by a European government to limit use of social media among teens and younger children, which has drawn concerns in many parts of an increasingly online world.&lt;/p&gt;
    &lt;p&gt;It follows a move in December in Australia, where parliament enacted the world‚Äôs first ban on social media for children ‚Äî setting the minimum age at 16.&lt;/p&gt;
    &lt;p&gt;That made platforms including TikTok, Facebook, Snapchat, Reddit, X and Instagram subject to fines of up to 50 million Australian dollars ($33 million) for systemic failures to prevent children younger than 16 from holding accounts.&lt;/p&gt;
    &lt;p&gt;The Danish ministry statement said the age minimum of 15 would be introduced for ‚Äúcertain‚Äù social media, though it did not specify which ones. Nor did the statement indicate how such a move would be enforced in a world where millions of children have easy access to screens.&lt;/p&gt;
    &lt;p&gt;But the move nonetheless was likely to stir debate well beyond Denmark‚Äôs borders.&lt;/p&gt;
    &lt;p&gt;A coalition of lawmakers from the political right, left and center ‚Äúare making it clear that children should not be left alone in a digital world where harmful content and commercial interests are too much a part of shaping their everyday lives and childhoods,‚Äù the ministry said.&lt;/p&gt;
    &lt;p&gt;‚ÄúChildren and young people have their sleep disrupted, lose their peace and concentration, and experience increasing pressure from digital relationships where adults are not always present,‚Äù it said. ‚ÄúThis is a development that no parent, teacher or educator can stop alone.‚Äù&lt;/p&gt;
    &lt;p&gt;Pressure from tech giants‚Äô business models was ‚Äútoo massive,‚Äù the ministry said. It cited a comment from Digitalization Minister Caroline Stage saying Danish authorities were ‚Äúfinally drawing a line in the sand and setting a clear direction.‚Äù&lt;/p&gt;
    &lt;p&gt;Many governments have been grappling with ways of limiting harmful fallout from online technologies, without overly squelching their promise.&lt;/p&gt;
    &lt;p&gt;China ‚Äî which manufacturers many of the world‚Äôs digital devices ‚Äî has set limits on online game time and smart-phone time for kids. Prosecutors in Paris this week announced an investigation into allegations that TikTok allows content promoting suicide and that its algorithms may encourage vulnerable young people to take their own lives.&lt;/p&gt;
    &lt;p&gt;The European Union-wide Digital Services Act forbids children younger than 13 to hold accounts on social media like TikTok and Instagram, video sharing platforms like YouTube and Twitch, sites like Reddit and Discord, as well as AI companions. Some EU lawmakers want to raise the age to 16 during a Nov. 24 vote in the European Parliament.&lt;/p&gt;
    &lt;p&gt;The 27-nation EU‚Äôs executive, the European Commission, issued guidelines in July to strengthen protection of minors and rolled out a prototype of an age-verification app.&lt;/p&gt;
    &lt;p&gt;Rasmus Lund-Nielsen, an Danish lawmaker of the Moderates party, said social media has become ‚Äúthe Wild West.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúEvery other 10-year-old is on TikTok, but now we are setting a limit,‚Äù he said. ‚ÄúIt is not just a parental responsibility to protect children from seeing Charlie Kirk being shot in the throat on social media.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhen 60 percent of boys do not see their friends outside of school, only 12% of girls exercise enough to meet (World Health Organization) recommendations and 15% receive a psychiatric diagnosis before they turn 18, society must step in and take responsibility,‚Äù he said. ‚ÄúNow we are giving children their childhood back.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://apnews.com/article/denmark-social-media-ban-children-7862d2a8cc590b4969c8931a01adc7f4"/><published>2025-11-07T16:28:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45848302</id><title>3I/ATLAS shows perihelion burst and radial-only non-gravitational acceleration</title><updated>2025-11-07T17:37:36.911029+00:00</updated><content/><link href="https://old.reddit.com/r/dataisbeautiful/comments/1oqfau8/3iatlas_shows_perihelion_burst_and_radialonly/"/><published>2025-11-07T16:49:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45848341</id><title>Toxic Salton Sea dust triggers changes in lung microbiome after just one week</title><updated>2025-11-07T17:37:36.685170+00:00</updated><content>&lt;doc fingerprint="fc1c63126c290be5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Toxic Salton Sea dust triggers changes in lung microbiome after just one week&lt;/head&gt;
    &lt;head rend="h5"&gt;Lisa Lock&lt;/head&gt;
    &lt;p&gt;scientific editor&lt;/p&gt;
    &lt;head rend="h5"&gt;Robert Egan&lt;/head&gt;
    &lt;p&gt;associate editor&lt;/p&gt;
    &lt;p&gt;Dust from California's drying Salton Sea doesn't just smell bad. Scientists from UC Riverside found that breathing the dust can quickly re-shape the microscopic world inside the lungs.&lt;/p&gt;
    &lt;p&gt;Genetic or bacterial diseases have previously been shown to have an effect on lung microbes. However, this discovery marks the first time scientists have observed such changes from environmental exposure rather than a disease.&lt;/p&gt;
    &lt;p&gt;Published in the journal mSphere, the study shows that inhalation of airborne dust collected close to the shallow, landlocked lake alters both the microbial landscape and immune responses in mice that were otherwise healthy.&lt;/p&gt;
    &lt;p&gt;"Even Salton Sea dust filtered to remove live bacteria or fungi is altering what microbes survive in the lungs," said Mia Maltz, UCR mycologist and lead study author. "It is causing deep changes to our internal environment."&lt;/p&gt;
    &lt;p&gt;Scientists have studied the gut microbiome extensively, linking it to digestion, immunity, and even mental state. In contrast, the lung microbiome remains less well understood, though it's increasingly seen as important to overall health.&lt;/p&gt;
    &lt;p&gt;"Our lab studies discovered that the dust generated at the Salton Sea can have significant health effects especially in the lung, and it is likely a major factor in the high incidence of asthma in the nearby communities," said David Lo, a UCR distinguished professor of biomedical sciences and study author.&lt;/p&gt;
    &lt;p&gt;The researchers collaborated on the design of an exposure chamber that mimicked real-world air conditions. The team collected dust samples both closer to and farther from the Salton Sea, then exposed mice to the aerosolized particles during a series of one-week trials.&lt;/p&gt;
    &lt;p&gt;There were some clues about ill effects even before deeper analysis.&lt;/p&gt;
    &lt;p&gt;"Salton Sea residents have ongoing suspicions that the environment is linked to respiratory illness, and our lab has definitely felt the effects of the heat, dustiness, and pungent air while out there on field work," said Talyssa Topacio, UCR graduate student and co-first author of the paper.&lt;/p&gt;
    &lt;p&gt;"The dust also just doesn't smell good," said Emma Aronson, UCR environmental microbiologist and study author. "When we were processing it in the lab, it could be stinky."&lt;/p&gt;
    &lt;p&gt;Among the bacterial species that proliferated among mice exposed to the sea dust were Pseudomonas and Staphylococcus, both linked to respiratory inflammation. The most affected samples were rich in bacteria that produce LPS, a molecular residue on their outer membranes known to trigger immune responses.&lt;/p&gt;
    &lt;p&gt;"We think microbial products like LPS are part of what's causing the inflammation," Maltz said. "It's like breathing in a chemical fingerprint of dead bacteria."&lt;/p&gt;
    &lt;p&gt;Some dust samples were especially potent. In one case, up to 60% of lung immune cells contained markers of neutrophil activation, showing aggressive inflammation. In mice breathing filtered air, levels of neutrophils were only 10% to 15%.&lt;/p&gt;
    &lt;p&gt;Aronson said the findings challenge longstanding assumptions in pulmonary science. "We've seen these kinds of microbial shifts in people with cystic fibrosis or infections," she said. "But these mice had no pre-existing conditions. This was a clean slate, and it still happened."&lt;/p&gt;
    &lt;p&gt;As the Salton Sea lakebed continues to dry, more of its toxic sediment becomes airborne. The research group is examining whether similar microbial shifts occur in local children.&lt;/p&gt;
    &lt;p&gt;"Breathing in the dust over time may have chronic impacts in the lung, and these studies on the potential for altering the lung microbiome are an important first step in identifying factors that could lead to asthma and other chronic diseases," Lo said.&lt;/p&gt;
    &lt;p&gt;The research also raises broader questions. If dust can alter lung microbes, what about smoke, exhaust, or vaping aerosols? The researchers plan to test whether other exposures cause similar disruptions.&lt;/p&gt;
    &lt;p&gt;This study relied on a method Maltz developed over four years to isolate microbial DNA from host tissue, enabling a more detailed look at the lung microbiome than ever before. The next step is to determine whether protective species are being lost, and how long any noticeable changes to the microbiome persist.&lt;/p&gt;
    &lt;p&gt;"We've only just begun to understand how dust exposure changes the lung microbiome," Maltz said. "We don't yet know how long the changes last, or whether they're reversible. That's another big question."&lt;/p&gt;
    &lt;p&gt;More information: Mia R. Maltz et al, Lung microbiomes' variable responses to dust exposure in mouse models of asthma, mSphere (2025). DOI: 10.1128/msphere.00209-25. journals.asm.org/doi/10.1128/msphere.00209-25&lt;/p&gt;
    &lt;p&gt;Provided by University of California - Riverside&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://phys.org/news/2025-10-toxic-salton-sea-triggers-lung.html"/><published>2025-11-07T16:52:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45848428</id><title>Nasdaq 100 set for worst week since April meltdown</title><updated>2025-11-07T17:37:36.404517+00:00</updated><content>&lt;doc fingerprint="fdcc49bf8db40fae"&gt;
  &lt;main&gt;
    &lt;p&gt;A risk-off week on Wall Street is drawing to a close, with some of the most-expensive areas of the market driving stocks lower while a renewed slide in crypto leaves the asset class barely up for 2025.&lt;/p&gt;
    &lt;p&gt;Equities fell on Friday, with the S&amp;amp;P 500 set to halt a streak of three weeks of gains as a gauge of US consumer sentiment sank to a more than three-year low. Things were even worse for the Nasdaq 100 as a rout in artificial-intelligence winners put the tech-heavy measure on track for its worst week since the April tariff-fueled tantrum ‚Äì when the index entered a bear market.&lt;/p&gt;
    &lt;p&gt;Worries about valuations in AI high-flyers reaching unsustainable levels surfaced after a torrid surge from this year‚Äôs bottom spurred calls for a breather. Technical indicators started flagging reasons for caution, adding to the drag on sentiment from warnings by Wall Street chief executives about a frothy market.&lt;/p&gt;
    &lt;p&gt;‚ÄúMajor indices are facing selling pressure this week,‚Äù said Craig Johnson at Piper Sandler. ‚ÄúInvestors should prioritize good risk/reward setups, potentially after a healthy pullback within this bull market.‚Äù&lt;/p&gt;
    &lt;p&gt;This week‚Äôs slide also comes at a time when earnings season is winding down, with investors becoming reliant on private data amid a dearth of economic figures due to the ongoing government shutdown. That‚Äôs left the market vulnerable to volatility as it happened in the previous session with a report painting a bleak jobs picture.&lt;/p&gt;
    &lt;p&gt;While the US payrolls report was not released this Friday due to the shutdown, a survey conducted by 22V Research showed that a labor-market unwind is the biggest risk to trading. That explains why risk assets and bond yields have been unusually sensitive to any news data on that front.&lt;/p&gt;
    &lt;p&gt;The S&amp;amp;P 500 fell to around 6,670. The Nasdaq 100 slid 1.1%. A gauge of the Magnificent Seven megacaps sank 1.8%.&lt;/p&gt;
    &lt;p&gt;Bitcoin extended this week‚Äôs slide to 9%. The yield on 10-year Treasuries was little changed at 4.09%. The dollar lost 0.2%.&lt;/p&gt;
    &lt;p&gt;‚ÄúWhile there is no jobs report Friday due to the government shutdown, there is enough private payroll and layoff data to suggest that the labor market is cooling,‚Äù said Glen Smith at GDS Wealth Management. ‚ÄúThis cooling keeps the Fed‚Äôs rate cut plans alive for December and potentially into early 2026.‚Äù&lt;/p&gt;
    &lt;p&gt;The economy remains on an upward trajectory even if economic growth slows toward trend levels in 2026, according to Seema Shah at Principal Asset Management.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe bigger concern ‚Äî and the key focus of the Fed‚Äôs debate ‚Äîwill be the health of the labor market,‚Äù she said. ‚ÄúWe anticipate the Fed will continue to implement rate cuts to prevent any weakness in employment from accelerating. Much of the market‚Äôs optimism hinges on the assumption that policymakers will maintain some level of support.‚Äù&lt;/p&gt;
    &lt;p&gt;Despite the slide, flows remain supportive. US equity funds had an eighth consecutive week of inflows, the longest streak this year, but cash attracted the bulk of inflows, Bank of America Corp. said citing citing EPFR Global data.&lt;/p&gt;
    &lt;p&gt;Traders are pondering a moment of weakness embedded in a multi-month rip higher for stocks, yet the market on balance looks poised for further gains, said Goldman Sachs Group Inc.‚Äôs Tony Pasquariello.&lt;/p&gt;
    &lt;p&gt;‚ÄúI‚Äôm not saying that risk/reward is overly compelling, nor that this is an ideal location to add a bunch of incremental risk,‚Äù the head of hedge fund coverage at Goldman Sachs wrote in a note to clients Wednesday. ‚ÄúLooking forward, I‚Äôd argue the balance of risks still points in favor of the bulls.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fortune.com/2025/11/07/nasdaq-100-worst-week-since-april-bear-market-correction/"/><published>2025-11-07T16:59:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45848552</id><title>Notes on Being a Man</title><updated>2025-11-07T17:37:36.102686+00:00</updated><content>&lt;doc fingerprint="2be993598867a4bf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Notes on Being a Man&lt;/head&gt;
    &lt;p&gt;Donald Trump pulled off a stunning political comeback because of ‚Ä¶ young men. While the Democrats ignored this demographic, the far right rushed in to fill the void, flooding the manosphere with rockets, Hulk Hogan, coarseness, and crypto. The last presidential election was supposed to be a referendum on women‚Äôs rights. It wasn‚Äôt. It was a referendum on struggling young men.&lt;/p&gt;
    &lt;p&gt;Five years ago my advocacy for young men sparked a hostile response. Today society is ready to have a productive dialogue, rejecting the far right‚Äôs attempts to send non-white people and all women back to the 1950s and the left‚Äôs belief that young men don‚Äôt have problems but are the problem. This isn‚Äôt a zero-sum game. We can build on the gains women have registered over the past three decades and ensure there‚Äôs room for boys and young men in the conversation. Democrats are starting to tackle the crisis, but we can‚Äôt rely on prominent party leaders to drive the change. We can count on the tech industry, however, to keep supporting their massive valuations by connecting profits with the sequestration and enragement of young men. Men ages 20 to 30 now spend less time outside than prison inmates.&lt;/p&gt;
    &lt;p&gt;Men of my generation have a debt to these young men. Our unfair advantage must be paid forward (or backward). We need to get involved in their lives, advocate for policies to right the ship, and model a healthier vision of masculinity. All of us have a role to play in giving young men a code ‚Äî a positive set of principles ‚Äî to live by.&lt;/p&gt;
    &lt;p&gt;Below is an excerpt from my new book, Notes on Being a Man. This one is personal. I hope it resonates with you.&lt;/p&gt;
    &lt;p&gt;________________&lt;/p&gt;
    &lt;head rend="h4"&gt;Falling Farther, Faster&lt;/head&gt;
    &lt;p&gt;One of the semi-exciting perks of being an academic and ‚Äúthought leader‚Äù is uncovering data, especially when it‚Äôs both obvious and hidden. Years ago, the alarming state of American boys and men overtook my attention. I track closely the emails I get. Most are from parents, particularly mothers, concerned about their sons, along these lines: ‚ÄúI have a daughter who lives in Chicago and works in PR and another daughter who‚Äôs at Penn.&lt;/p&gt;
    &lt;p&gt;My son lives in our basement, vapes, and plays video games.‚Äù Moms, not dads, were leading the charge. Others were either ignoring the problem or didn‚Äôt want to talk about it. Absent, too, was any sober, data-driven analysis. The gag-reflex cultural response seemed to be Wow, men are worse than we think, and that the issues they face are a function of their awfulness, and haven‚Äôt we spent the past forty years correctly focused on the struggles of other, more deserving groups?&lt;/p&gt;
    &lt;p&gt;I connected to this topic on a personal level. I thought back on where I came from, my mom‚Äôs irrational passion for my well-being, the generosity of California taxpayers who made it possible for an unremarkable kid with mediocre grades to attend college and business school, and all the obstacles, temptations, and traps that could have easily hampered my socialization ‚Äî smartphones, online dating, porn, gambling, video games, remote work. I wondered why what was happening to boys and young men was in fact happening and how I could raise my sons in a world where they ‚Äî and males of any age ‚Äî thrive.&lt;/p&gt;
    &lt;p&gt;The data around boys and young men is overwhelming. Seldom in recent memory has there been a cohort that‚Äôs fallen farther, faster. Why? First, boys face an educational system biased against them ‚Äî with brains that mature later than girls‚Äô, they almost immediately fall behind their female classmates. Many grow up without male role models, including teachers ‚Äî fewer men teach K‚Äì12 than there are women working in STEM fields ‚Äî with Black and Hispanic school instructors especially underrepresented.&lt;/p&gt;
    &lt;p&gt;Post‚Äìhigh school, the social contract that binds America ‚Äî work hard, play by the rules, and you‚Äôll be better off than your parents were ‚Äî has been severed. Seventy-year-old Americans today are, on average, 72% wealthier than they were forty years ago.&lt;/p&gt;
    &lt;p&gt;People under the age of forty are 24% less wealthy. The deliberate transfer of wealth from the young to the old in the United States over the past century has led to unaffordable and indefensible costs for education and housing and skyrocketing student debt, all of which directly affect young men. It‚Äôs why twenty-five-year-olds today make less than their parents and grandparents did at the same age, while carrying debt loads unimaginable to earlier generations. Neither the minimum nor the median wage has kept pace with inflation or productivity gains, while housing costs have outpaced both. As the costs of college have soared beyond the reach of most families, many of the manufacturing jobs that didn‚Äôt require a college degree and were often a ticket to the middle class for (mostly) men have been offshored. A prohibitive real estate market is a contributing factor to why 60% of young men between the ages of eighteen and twenty-four live with their parents and 1 in 5 still live with their parents at age thirty. Stuck and unable to afford greater economic opportunities in nearby cities, they find the same crush and collision of density, stimulation, humanity, creativity, eroticism, and conversation that urban areas offer on their phones instead. In Manhattan, a four-hundred-square-foot apartment costs $3,000 a month. In its stead is a seventeen-square-inch mobile studio apartment costing roughly $42 a month, served up by AT&amp;amp;T, T- Mobile, or Verizon.&lt;/p&gt;
    &lt;p&gt;Meanwhile, algorithmically generated content on social media contributes to‚Äîand profits from‚Äîyoung men‚Äôs growing social isolation, boredom, and ignorance. With the deepest-pocketed firms on the planet trying to convince young men they can have a reasonable facsimile of life on a screen, many grow up without acquiring the skills to build social capital or create wealth. The percentage of young men aged twenty to twenty-four who are neither in school nor working has tripled since 1980. Workforce participation among men has fallen below 90%, caused by a lack of well-paying jobs, wage stagnation, disabilities, a mismatch of skills and/or training, and falling demand for jobs traditionally held by prime-age men.&lt;/p&gt;
    &lt;p&gt;This is deadly. From 2005 to 2019, roughly 70,000 Americans died every year from deaths of despair ‚Äî suicide, drug overdoses, alcohol poisoning ‚Äî with a disproportionate number of those fatalities being unemployed white males without a college degree. Excluding deaths caused by the opioid epidemic, America‚Äôs suicide and alcohol-related mortality rate for all races is higher than it‚Äôs been in a century. It‚Äôs also a mating crisis, as women traditionally mate horizontally and up socioeconomically, whereas men mate horizontally and down. Up until the mid‚Äìtwentieth century, homogamy ‚Äî marriages between men and women from similar educational backgrounds ‚Äî was more common than not. Today, hypogamy, where women marry men who have less education than themselves, is on the rise. When the pool of horizontal-and-up young men shrinks, there are fewer mating opportunities, less family and household formation, and not as many babies. Here‚Äôs a terrifying stat: 45% of men ages eighteen to twenty-five have never approached a woman in person. And without the guardrails of a relationship, young men behave as if they have ‚Ä¶ no guardrails.&lt;/p&gt;
    &lt;p&gt;Why are we so averse to identifying and celebrating what‚Äôs good about men and masculinity, and why does it matter? Because we won‚Äôt prosper if we convince boys and young men that they‚Äôre victims, or that they don‚Äôt have to be persistent and resilient, or that their perspective isn‚Äôt valuable. If we do, we‚Äôll end up with a society of old people and zero economic growth. If we can‚Äôt convince young men of the honor involved and the unique contributions inherent in expressing what makes them male, we‚Äôll lose them to niche, rabid online communities.&lt;/p&gt;
    &lt;p&gt;As my Pivot podcast cohost Kara Swisher commented once, it should matter to everyone if men aren‚Äôt thriving. Women and children can‚Äôt flourish if men aren‚Äôt doing well. Neither will our country.&lt;/p&gt;
    &lt;p&gt;Life is so rich,&lt;/p&gt;
    &lt;p&gt;P.S. Notes on Being a Man was published this week and is available in all the usual places.&lt;/p&gt;
    &lt;head rend="h2"&gt;1 Comments&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Test.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Need more Scott in your life?&lt;/head&gt;
    &lt;p&gt;The Prof G Markets Pod now has a newsletter edition. Sign up here to receive it every Monday. What a thrill.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.profgalloway.com/notes-on-being-a-man/"/><published>2025-11-07T17:12:19+00:00</published></entry></feed>