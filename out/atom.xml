<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-27T04:46:36.607849+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45708524</id><title>Pico-Banana-400k</title><updated>2025-10-27T04:46:43.542775+00:00</updated><content>&lt;doc fingerprint="19072a4816fa0fc8"&gt;
  &lt;main&gt;
    &lt;p&gt;Pico-Banana-400K is a large-scale dataset of ~400K text–image–edit triplets designed to advance research in text-guided image editing.&lt;lb/&gt; Each example contains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;an original image (from Open Images),&lt;/item&gt;
      &lt;item&gt;a human-like edit instruction, and&lt;/item&gt;
      &lt;item&gt;the edited result generated by Nano-Banana and verified by Gemini-2.5-Pro.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The dataset spans 35 edit operations across 8 semantic categories, covering diverse transformations—from low-level color adjustments to high-level object, scene, and stylistic edits.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Total Samples&lt;/cell&gt;
        &lt;cell&gt;~257K single-turn text–image–edit triplets for SFT, ~56K single-turn text-image(positive) - image(negative)-edit for preference learning, and ~72K multi-turn texts-images-edits for multi-turn applications&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Source&lt;/cell&gt;
        &lt;cell&gt;Open Images&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edit Operations&lt;/cell&gt;
        &lt;cell&gt;35 across 8 semantic categories&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Categories&lt;/cell&gt;
        &lt;cell&gt;Pixel &amp;amp; Photometric, Object-Level, Scene Composition, Stylistic, Text &amp;amp; Symbol, Human-Centric, Scale &amp;amp; Perspective, Spatial/Layout&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Image Resolution&lt;/cell&gt;
        &lt;cell&gt;512–1024 px&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Prompt Generator&lt;/cell&gt;
        &lt;cell&gt;Gemini-2.5-Flash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Editing Model&lt;/cell&gt;
        &lt;cell&gt;Nano-Banana&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Self-Evaluation&lt;/cell&gt;
        &lt;cell&gt;Automated judging pipeline using Gemini-2.5-Pro for edit quality&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pico-Banana-400K is built using a two-stage multimodal generation pipeline:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Instruction Generation&lt;lb/&gt;Each Open Images sample is passed to Gemini-2.5-Flash, which writes concise, natural-language editing instructions grounded in visible content. We also provide short instructions summarized by Qwen-2.5-Instruct-7B. Example:&lt;quote&gt;{ "instruction": "Change the red car to blue." }&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Editing + Self-Evaluation The Nano-Banana model performs the edit, then automatically evaluates the result using a structured quality prompt that measures: Instruction Compliance (40%) Editing Realism (25%) Preservation Balance (20%) Technical Quality (15%) Only edits scoring above a strict threshold (~0.7) are labeled as successful, forming the main dataset; the remaining ~56K are retained as failure cases for robustness and preference learning.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nano-Banana-400K contains ~400K image editing data, covering a wide visual and semantic range drawn from real-world imagery.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Percentage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Object-Level Semantic&lt;/cell&gt;
        &lt;cell&gt;Add, remove, replace, or relocate objects&lt;/cell&gt;
        &lt;cell&gt;35%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scene Composition &amp;amp; Multi-Subject&lt;/cell&gt;
        &lt;cell&gt;Contextual and environmental transformations&lt;/cell&gt;
        &lt;cell&gt;20%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Human-Centric&lt;/cell&gt;
        &lt;cell&gt;Edits involving clothing, expression, or appearance&lt;/cell&gt;
        &lt;cell&gt;18%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Stylistic&lt;/cell&gt;
        &lt;cell&gt;Domain and artistic style transfer&lt;/cell&gt;
        &lt;cell&gt;10%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Text &amp;amp; Symbol&lt;/cell&gt;
        &lt;cell&gt;Edits involving visible text, signs, or symbols&lt;/cell&gt;
        &lt;cell&gt;8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Pixel &amp;amp; Photometric&lt;/cell&gt;
        &lt;cell&gt;Brightness, contrast, and tonal adjustments&lt;/cell&gt;
        &lt;cell&gt;5%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scale &amp;amp; Perspective&lt;/cell&gt;
        &lt;cell&gt;Zoom, viewpoint, or framing changes&lt;/cell&gt;
        &lt;cell&gt;2%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Spatial / Layout&lt;/cell&gt;
        &lt;cell&gt;Outpainting, composition, or canvas extension&lt;/cell&gt;
        &lt;cell&gt;2%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single-Turn SFT samples (successful edits): ~257K&lt;/item&gt;
      &lt;item&gt;Single-Turn Preference samples (failure cases): ~56K&lt;/item&gt;
      &lt;item&gt;Multi-Turn SFT samples (successful cases): ~72K&lt;/item&gt;
      &lt;item&gt;Gemini-generated instructions: concise, natural, and image-aware&lt;/item&gt;
      &lt;item&gt;Edit coverage: 35 edit types across 8 semantic categories&lt;/item&gt;
      &lt;item&gt;Image diversity: includes humans, objects, text-rich scenes, etc from Open Images&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Below are representative examples from different categories:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Category&lt;/cell&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Object-Level&lt;/cell&gt;
        &lt;cell&gt;“Replace the red apple with a green one.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Scene Composition&lt;/cell&gt;
        &lt;cell&gt;“Add sunlight streaming through the window.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Human-Centric&lt;/cell&gt;
        &lt;cell&gt;“Change the person’s expression to smiling.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Text &amp;amp; Symbol&lt;/cell&gt;
        &lt;cell&gt;“Uppercase the text on the billboard.”&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Stylistic&lt;/cell&gt;
        &lt;cell&gt;“Convert the image to a Van Gogh painting style.”&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Pico-Banana-400K provides both breadth (diverse edit operations) and depth (quality-controlled multimodal supervision), making it a strong foundation for training and evaluating text-guided image editing models.&lt;/p&gt;
    &lt;p&gt;Pico-Banana-400K serves as a versatile resource for advancing controllable and instruction-aware image editing.&lt;lb/&gt; Beyond single-step editing, the dataset enables multi-turn, conversational editing and reward-based training paradigms.&lt;/p&gt;
    &lt;p&gt;The Pico-Banana-400K dataset is hosted on Apple’s public CDN.&lt;lb/&gt; You can download each component (single-turn, multi-turn, and preference data) using the provided manifest files.&lt;/p&gt;
    &lt;p&gt;Manifest files: sft link and preference link&lt;/p&gt;
    &lt;p&gt;Manifest file: multi-turn link&lt;/p&gt;
    &lt;p&gt;Urls to download source images are provided along with edit instructions in sft link, preference link, and multi-turn link. If you hit rate limit with Flickr when downloading images, you can either request higher rate limit with Flickr or follow steps below.&lt;/p&gt;
    &lt;p&gt;Another way to download the source images is to download packed files train_0.tar.gz and train_1.tar.gz from Open Images, then map with the urls we provide. We also provide a sample mapping code here. Due to legal requirements, we cannot provide the source image files directly.&lt;/p&gt;
    &lt;code&gt;# Install awscli if you don't have it (https://aws.amazon.com/cli/)
# Download Open Images packed files 
aws s3 --no-sign-request --endpoint-url https://s3.amazonaws.com cp s3://open-images-dataset/tar/train_0.tar.gz . 
aws s3 --no-sign-request --endpoint-url https://s3.amazonaws.com cp s3://open-images-dataset/tar/train_1.tar.gz . 

# Create folder for extracted images 
mkdir openimage_source_images

# Extract the tar files 
tar -xvzf train_0.tar.gz -C openimage_source_images
tar -xvzf train_1.tar.gz -C openimage_source_images

# Download metadata CSV (ImageID ↔ OriginalURL mapping)  
wget https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv

# Map urls to local paths
python map_openimage_url_to_local.py #please modify variable is_multi_turn and file paths as needed&lt;/code&gt;
    &lt;p&gt;Pico-Banana-400K is released under the Creative Commons Attribution–NonCommercial–NoDerivatives (CC BY-NC-ND 4.0) license. ✅ Free for research and non-commercial use ❌ Commercial use and derivative redistribution are not permitted 🖼️ Source images follow the Open Images (CC BY 2.0) license By using this dataset, you agree to comply with the terms of both licenses.&lt;/p&gt;
    &lt;p&gt;If you use 🍌 Pico-Banana-400K in your research, please cite it as follows:&lt;/p&gt;
    &lt;code&gt;@misc{qian2025picobanana400klargescaledatasettextguided,
      title={Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing}, 
      author={Yusu Qian and Eli Bocek-Rivele and Liangchen Song and Jialing Tong and Yinfei Yang and Jiasen Lu and Wenze Hu and Zhe Gan},
      year={2025},
      eprint={2510.19808},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.19808}, 
}

&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/apple/pico-banana-400k"/><published>2025-10-26T02:01:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45710065</id><title>Asbestosis</title><updated>2025-10-27T04:46:43.253290+00:00</updated><content>&lt;doc fingerprint="fe60955783648a74"&gt;
  &lt;main&gt;
    &lt;p&gt;This monument popped up in the middle of Barking recently. I thought it was very recently but it was actually unveiled in April 2022 and I'm just not very observant.&lt;/p&gt;
    &lt;p&gt;It says "In Memory of those who lost their lives because of exposure to asbestos".&lt;/p&gt;
    &lt;p&gt;And it's here because Barking has one of the highest rates of asbestos-related deaths in the country.&lt;/p&gt;
    &lt;p&gt;In 1913 the Cape Asbestos Company built a huge asbestos factory beside the River Roding in Barking. The company mined asbestos-bearing rock at several sites in South Africa, then shipped them in sacks to a private quay in Barking for processing. Hundreds of people were employed to mill the ore into usable fibres and then process these into lagging, packaging, pipes, resins, boards and all forms of insulation widely used in the building trade. They worked without masks or other protection, the dangers of asbestos either unknown or not thought worth bothering about. And hundreds of workers died, often many years later, of insidious chronic respiratory disease.&lt;/p&gt;
    &lt;p&gt;I found a 32-page booklet published by Cape Asbestos in the days before blue asbestos was recognised as dangerous and banned, which was as late as 1985. It shows workers with rolled-up sleeves and women leaning over unshielded machines, all potentially inhaling enough fibres to ultimately kill them. I read reports about the local school in Barking, barely 100 metres away, saying that the playground was often covered in fine dust which children rolled up and played with as if it were snow. I read that mesothelioma was so common in the area it was known as the ‘Barking Cough’. These were different times, but times that linger on.&lt;/p&gt;
    &lt;p&gt;Cape Asbestos's plant eventually closed in 1968 and in its place was built the Harts Lane council estate, which is still not the loveliest corner of Barking. It included two tall tower blocks called Colne House and Mersey House, both of which Barking &amp;amp; Dagenham council would now like to demolish. This is chiefly because they're old and covered in combustible cladding, but the additional complications of potentially disturbing polluted land puts any remediation out of financial reach. It's always the insulation you have to watch out for.&lt;/p&gt;
    &lt;p&gt;The memorial in Barking Town Square comprises a polished chunk of blue pearl granite and was unveiled on Workers' Memorial Day 2022 in a ceremony attended by several trade unionists and representatives of the London Asbestos Support Awareness Group. The emphasis is partly on remembrance and partly on the importance of standing up for workers' rights to make conditions better for all. As the inscription says, "Remember the Dead and Fight for the Living".&lt;/p&gt;
    &lt;p&gt;My grandfather worked for another Cape Asbestos plant on Tolpits Lane in Watford. Originally it had been run by Universal Asbestos Manufacturing but in 1967 the factory was acquired by Cape as part of a diversification into cement-based products. They made corrugated roofing, flat sheets, decorated sheets, slates, soil pipes, decking for flat roofs and reinforced troughing - that kind of thing - the asbestos moulded into a multiplicity of shapes for the benefit of the building trade.&lt;/p&gt;
    &lt;p&gt;To him Cape Universal was just a convenient place to work, a short walk across the moor for a day's shift and then home again for tea. He worked there for many years, from the 1930s to the 1960s, rising through the ranks from a labourer to a machine operator on the factory floor. On his death certificate his occupation was listed as 'Asbestos Moulder', and it was very much a premature death because this didn't end well.&lt;/p&gt;
    &lt;p&gt;I don't remember very much about my grandfather because he died when I was 8. I know he was there when I took my first steps in his back garden and I can remember sitting at his dining room table and hoping nobody would force me to eat the celery. My final memory is being led up to his bedroom, I suspect not long before his death, to see an ill old man laid out in bed and struggling to breathe. I don't know what was said, nor how short a time I stayed in his presence, indeed my strongest recollection is of the room itself with its austere cupboards and the curtains drawn. And then at the age of 67 he was gone.&lt;/p&gt;
    &lt;p&gt;My family fought for asbestosis to be recognised as his cause of death but were not successful. I've read recently of fellow workers working at the Tolpits Lane factory now getting six figure payouts in compensation, indeed it's hard to research this topic without ending up on legal websites with popups urging you to make a claim. Even four decades after the factory's closure there are still employees severely affected, and many more already passed, as the toxic legacy endures. The factory site is now a rather cleaner industrial estate and business park, indeed it's where the National Lottery's been based for the last 30 years because risk and loss are still in play.&lt;/p&gt;
    &lt;p&gt;Today my Dad reaches the grand old age of 87, a full 20 years more than his father lived. Science has moved on a long way since the 1970s, also educational opportunities and also workers' rights. Health and safety is sometimes much derided but it can genuinely save lives, even much extend them, rather than everyone continually moaning about additional costs and annoying procedures. If someone had shouted earlier and louder about the dangers of asbestos I might have known my grandfather better, my grandmother could have had many more years of married life and my father could have had a father for much longer.&lt;/p&gt;
    &lt;p&gt;My Dad lost his Dad at the age of 34, which is no age at all in the grand scheme of things. By contrast I still have my Dad at the age of 60, which has meant an extra quarter century of guidance, support, advice, love and always being there. How lucky am I? Every day we overlap with our parents is a blessing and I've had 22,000 of them, for all of which I'm truly grateful. We're off out later to celebrate with a slap-up dinner, or as slap-up as an 87-year-old stomach requires, which the wider family are greatly looking forward to. What Barking's memorial reminded me is that many families have not been so fortunate, and sometimes that loss can be very close to home.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://diamondgeezer.blogspot.com/2025/10/asbestosis.html"/><published>2025-10-26T08:34:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45710721</id><title>You already have a Git server</title><updated>2025-10-27T04:46:42.857697+00:00</updated><content>&lt;doc fingerprint="dcf8f5f9c827be83"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You already have a git server:&lt;/head&gt;(Programming)&lt;p&gt;If you have a git repository on a server with ssh access, you can just clone it:&lt;/p&gt;&lt;code&gt;# This works. 
git clone ssh://username@hostname/path/to/repo
&lt;/code&gt;&lt;p&gt;You can then work on it locally and push your changes back to the origin server. By default, git won’t let you push to the branch that is currently checked out, but this is easy to change:&lt;/p&gt;&lt;code&gt;# Run this on the remote server. 
git config receive.denyCurrentBranch updateInstead
&lt;/code&gt;&lt;p&gt;This is a great way to sync code between multiple computers or to work on server-side files without laggy typing or manual copying. If you want to publish your code, just point your web server at the git repo:&lt;/p&gt;&lt;code&gt;git clone https://hostname/path/to/repo/.git
# You can get rid of the .git part of the command by either setting the
# server to remap it to a nicer URL or by just renaming the .git directory
# (although this stops you from running git server side)
&lt;/code&gt;&lt;p&gt;… although you will have to run this command server-side to make it cloneable:&lt;/p&gt;&lt;code&gt;# Create some files used by git-over-http:
# Should be repeated after making changes.
git update-server-info
&lt;/code&gt;&lt;p&gt;That’s a lot of work, so let’s set up a hook to do that automatically:&lt;/p&gt;&lt;code&gt;# Automatically run git update-server-info.
# Should be run server-side
cp .git/hooks/post-update.sample .git/hooks/post-update
chmod a+x .git/hooks/post-update
&lt;/code&gt;&lt;p&gt;Git hooks are just shell scripts, so they can do things like running a static site generator:&lt;/p&gt;&lt;code&gt;cat &amp;gt; .git/hooks/post-update &amp;lt;&amp;lt;EOF
#!/bin/sh
set -euo pipefail
cd /path/to/site
/path/to/generator
EOF
chmod a+x .git/hooks/post-update
&lt;/code&gt;&lt;p&gt;This is how I’ve been doing this blog for a while now: It’s very nice to be able to type up posts locally (no network lag), and then push them to the server and have the rest handled automatically.&lt;/p&gt;&lt;p&gt;It’s also backed up by default: If the server breaks, I’ve still got the copy on my laptop, and if my laptop breaks, I can download everything from the server. Git’s version tracking also prevents accidental deletions, and if something breaks, it’s easy to figure out what caused it.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maurycyz.com/misc/easy_git/"/><published>2025-10-26T10:53:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45711094</id><title>Feed the bots</title><updated>2025-10-27T04:46:42.425183+00:00</updated><content>&lt;doc fingerprint="273b981161f213a7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;You should feed the bots:&lt;/head&gt;(Programming)&lt;p&gt;A week ago, I set up an infinite nonsense crawler trap – now it makes up 99% of my server’s traffic. What surprised me is that feeding scrapers garbage is the cheapest and easiest thing I could do.&lt;/p&gt;&lt;head rend="h2"&gt;Meet the bots:&lt;/head&gt;&lt;p&gt;These aren’t the indexing bots of old, but scrapers collecting data to train LLMs. Unlike search engines, which need the websites they crawl to stay up, AI companies provide a replacement.&lt;/p&gt;&lt;p&gt;It should come as no surprise that these bots are aggressive and relentless: They ignore robots.txt, and if block them by user agent they just pretend to be a browser. If you ban their IP, they switch addresses.&lt;/p&gt;&lt;p&gt;… all while sending multiple requests per second, all day, every day.&lt;/p&gt;&lt;head rend="h2"&gt;Giving up:&lt;/head&gt;&lt;p&gt;So what if we let them access the site?&lt;/p&gt;&lt;p&gt;Serving static files is is relatively cheap, but not free. SSD access times are in the tens milliseconds, and that’s before you pay the filesystem tax. Bots also like to grab old and obscure pages, ones that are unlikely to be in cache. As a result, it doesn’t take all that many requests to bog down the server.&lt;/p&gt;&lt;p&gt;Then there’s the matter of bandwidth: Many blog posts also include images weighing hundreds to thousands of kB, which can add up quite quickly. With an average file size of 100 kB, 4 requests per second adds up to a terabyte each month – not a huge amount of data, but more then I’m willing to throw away.&lt;/p&gt;&lt;head rend="h2"&gt;The ban hammer:&lt;/head&gt;&lt;p&gt;Simply making a list of IPs and blocking them would for normal bots…&lt;/p&gt;&lt;p&gt;… but these are hardly normal bots. Because they are backed by billion dollar companies, they don’t just have a few addresses, but many thousands. If you managed to ban all of their addresses, they’ll just buy more.&lt;/p&gt;&lt;p&gt;Rate limits fail for the same reason: They just switch IPs. I’ve even seen them using new IP for each request.&lt;/p&gt;&lt;head rend="h2"&gt;Building a wall:&lt;/head&gt;&lt;p&gt;Ok, what about a pay-wall, login-wall, CAPTCHA-wall, or a hash based proof-of-work?&lt;/p&gt;&lt;p&gt;All of these inconvenience users. Requiring an account guaranties that no one will read what I wrote. Even just a simple JavaScript challenge will block anyone who’s browser doesn’t support JS … and when it works, anything that must load before the does content still hugely slows down page loads.&lt;/p&gt;&lt;head rend="h2"&gt;Throw them some bombs:&lt;/head&gt;&lt;p&gt;“Serve them few gzip bombs, that’ll teach them” — Half the internet.&lt;/p&gt;&lt;p&gt;Gzip only provides a compression ratio of a little over 1000: If I want a file that expands to 100 GB, I’ve got to serve a 100 MB asset. Worse, when I tried it, the bots just shrugged it off, with some even coming back for more.&lt;/p&gt;&lt;head rend="h2"&gt;Jedi mind tricks:&lt;/head&gt;&lt;p&gt;Ok, what if we just send them 404s – try and make them think my site doesn’t exist.&lt;/p&gt;&lt;p&gt;These tricks only work if your adversary has a mind to trick. If a link is posted somewhere, the bots will know it exists, and if they can’t access it, they’ll just become more aggressive:. sending more requests, with more user agents and using more addresses.&lt;/p&gt;&lt;p&gt;Keeping them happy keeps them tolerable.&lt;/p&gt;&lt;head rend="h2"&gt;Garbage:&lt;/head&gt;&lt;p&gt;But surely sending them dynamically generated content would be expensive right?&lt;/p&gt;&lt;p&gt;Well… no.&lt;/p&gt;&lt;p&gt;CPU and RAM are the fastest parts of a modern computer. Dynamic content has the reputation of being slow because it often involves a database (lots of disk IO), a million lines of JavaScript, or both.&lt;/p&gt;&lt;p&gt;My lightly optimized Markov babbler consumes around ~60 CPU microseconds per request. There’s no disk IO, and the memory cost is only around 1.2 MB. There’s also no rules or blacklists to maintain: the bots come to it and it consumes them.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://maurycyz.com/misc/the_cost_of_trash/"/><published>2025-10-26T12:09:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45713253</id><title>Making the Electron Microscope</title><updated>2025-10-27T04:46:42.054557+00:00</updated><content>&lt;doc fingerprint="328cd3a71931043b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Making the Electron Microscope&lt;/head&gt;
    &lt;head rend="h3"&gt;In a little over a century, the electron microscope evolved from a tool barely capable of resolving virus particles into one able to capture atomic detail.&lt;/head&gt;
    &lt;p&gt;Biological structures exist across a vast range of scales. At one end are whole organisms, varying in size from bacteria only a few micrometers across to mammals measured in feet.1 These can be seen with the naked eye or with simple light microscopes, which have been in use since the mid-1600s. At the smaller end, however, are atoms, amino acids, and proteins, spanning angstroms2 to nanometers in size.&lt;/p&gt;
    &lt;p&gt;Observing molecules at this smaller scale allows us to untangle the finer mechanisms of life: how individual neurons connect and communicate, how the ribosomal machinery translates genetic code into proteins, or how viruses like HIV invade and hijack host cells. Resolving fine structures, whether the double membrane of a chloroplast, the protein shell of a bacteriophage, or the branching architecture of a synapse, provides the bridge between atomic detail and whole-organism physiology, taking us from form to function.&lt;/p&gt;
    &lt;p&gt;The ability to explore and map such minute mechanisms eluded scientists until the invention of the electron microscope. Conceived in the 1930s, it promised theoretical resolutions on the order of angstroms, nearly a hundred times finer than the most advanced light microscope of that era. In 1931, Ernst Ruska and his advisor Max Knoll, working at the Technical University in Berlin, designed the first prototype by replacing glass lenses with electromagnetic coils to focus beams of electrons instead of light.&lt;/p&gt;
    &lt;p&gt;That first instrument barely outperformed a magnifying glass in terms of resolution. But over the next century, refinements in design, sample preparation, and computation transformed the electron microscope into an indispensable tool for modern biology.&lt;/p&gt;
    &lt;p&gt;By 1938, scientists used an electron microscope to take a photograph of a virus — the mouse ectromelia orthopoxvirus — for the first time.3 And today, modern cryo-electron microscopy, in which samples are frozen in liquid ethane prior to imaging, can resolve individual atoms within proteins. During the COVID-19 pandemic, cryo-electron microscopy revealed the spike protein in the SARS-CoV-2 virus, which directly influenced the development of COVID vaccines. The technique also revealed a protein receptor that senses heat and pain, demonstrating how it translates physical signals to our nervous system, a breakthrough discovery that earned the 2021 Nobel Prize in Physiology.&lt;/p&gt;
    &lt;p&gt;Even as electron microscopes have allowed us to view ever smaller structures with clarity, challenges remain. One is that the images remain limited to static snapshots. Because samples must be imaged in a vacuum, it is impossible to directly observe the dynamism of live cells.4 In addition, specimens must be extremely thin to allow the electron beam to pass through, which prevents imaging of thick tissues. And finally, beyond these biological constraints, electron microscopes are physically large, can cost millions of dollars, and demand specialized facilities, training, and expertise to operate.&lt;/p&gt;
    &lt;p&gt;Despite these limitations, electron microscopy remains a powerful tool in biology, bridging the scales between molecular structure and living function. The story of its discovery is one of persistent ingenuity, involving a large cast of characters and numerous breakthroughs that helped make the modern electron microscope possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Seeds of an Idea&lt;/head&gt;
    &lt;p&gt;By the late 19th century, biologists knew they were approaching the resolution limit of the light microscope. In their quest to see biology in finer detail, they had reached a barrier that light could not cross.&lt;/p&gt;
    &lt;p&gt;Proof of this came from Ernst Abbe, a professor of experimental physics and mathematics at the University of Jena in Germany. Until Abbe, microscope design had been more of an art than a science, with innovators building optical instruments through trial and error. Carl Zeiss, who had begun manufacturing microscopes in the 1850s, approached Abbe in 1866 about using his scientific expertise for the construction of microscopes. Together, they began developing tools to improve the uniformity and quality of optical lenses.&lt;/p&gt;
    &lt;p&gt;In the early 1870s, while working on the microscope objectives (the lens closest to the specimen in a microscope), Abbe discovered that the sharpness of an image did not only depend on how perfectly a lens was ground but also on how much diffracted light from the specimen the lens could capture. He realized that fine details in a specimen bend light into wide angles, and only objectives with a sufficiently large opening could collect those rays to bring the image into focus.&lt;/p&gt;
    &lt;p&gt;From this insight, Abbe defined the concept of the “numerical aperture” (a measure of how much light a lens can gather5) and showed that the smallest visible detail is limited by the wavelength of light divided by twice this value.6 Even with ultraviolet light, at the short end of the visible spectrum (400 nanometers), the limit of resolution was 200 nanometers — larger than most viruses, intracellular structures, and protein complexes.&lt;/p&gt;
    &lt;p&gt;Hope of resolving structures beneath this resolution boundary only arrived in 1895, when the German physicist Wilhelm Röntgen discovered X-rays, a form of high-energy electromagnetic radiation with wavelengths shorter than those of ultraviolet light, and published a (now-iconic) image of his wife Bertha’s hand, with her bones and wedding ring clearly visible. This was the first time the hidden insides of the body could be seen without dissection. The bones, joints, and even metal fragments lodged inside the body could be made visible.&lt;/p&gt;
    &lt;p&gt;Between 1913 and 1915, the British physicist William Henry Bragg and his son, William Lawrence Bragg, developed a technique called X-ray crystallography. Working with simple crystals such as salt and diamond, they showed that when X-rays strike a regularly ordered crystal lattice, they diffract at specific angles that reveal the spacing of atoms within the crystal. The method works because X-rays have wavelengths about the size of chemical bonds, allowing the beams to reach and bounce off each atom in the lattice, reflecting the structure at an atomic scale. By applying a mathematical operation called a Fourier transform to these diffraction patterns captured on photographic plates, the Braggs reconstructed the three-dimensional arrangements of the atoms in the crystal.&lt;/p&gt;
    &lt;p&gt;Biomolecules, however, are not naturally crystalline. To study them, they had to be laboriously extracted, purified, and crystallized, separating them from their environment. The X-ray crystallography of biomolecules began in the 1930s, ushering in the field of structural biology. With sub-nanometer resolution, the invention of X-ray crystallography enabled a revolution in molecular biology. It was applied, for example, to solve the structures of DNA, hemoglobin, and insulin, molecules that have shaped the trajectory of modern biology.&lt;/p&gt;
    &lt;p&gt;But many biological targets remained out of reach. Viruses could rarely be crystallized, and cellular structures often lost their integrity when removed from their natural contexts. Thus, even with X-ray crystallography revealing the structures of small proteins and light microscopy capable of imaging cells, a gulf persisted between the study of small molecules and whole cells, which left much of biology invisible.&lt;/p&gt;
    &lt;p&gt;Meanwhile, access to the parallel world of electrons was beginning to open. At the turn of the 20th century, Hans Busch, a German physicist at the University of Jena, was studying how electron beams behaved in magnetic fields. His work built on decades of experiments with cathode rays, streams of electrons released when a high voltage is applied inside a glass tube.&lt;/p&gt;
    &lt;p&gt;Cathode rays had become central to both physics and technology: Physicists used them to probe how electrons scattered, ionized gases, and responded to electric and magnetic fields, and engineers used them to form the basis of devices such as the radio and television. It was while trying to better understand and control these beams that Busch postulated his remarkable theories.&lt;/p&gt;
    &lt;p&gt;In 1926 and 1927, Busch published two papers demonstrating mathematically that a magnetic coil could focus an electron beam in the same manner that a glass lens focuses light. While it was already known that coils could bend electron beams,7 Busch’s key insight was to frame this behavior in the language of optics: Electron beams could be treated like light rays. Concepts such as focal length, magnification, image formation, and even lens aberrations could all be applied to electrons. This meant that the well-developed theory of optical systems could be imported almost directly to other disciplines.&lt;/p&gt;
    &lt;p&gt;The Nobel Prize–winning physicist and inventor of holography, Denis Gabor, later reflected on Busch’s contribution in a 1942 lecture: “Busch’s paper was more than an eye-opener; it was almost like a spark in an explosive mixture. In 1927, the situation in physics was such that nothing more than the words ‘electron lens’ were needed to start a real burst of creative activity.”&lt;/p&gt;
    &lt;p&gt;And so it was that Busch’s idea sparked the birth of electron optics. Within a few years, at least three independent inventors would lay claim to having designed the electron microscope, all tracing their inspiration back to his initial insight.&lt;/p&gt;
    &lt;head rend="h2"&gt;The First Electron Microscope&lt;/head&gt;
    &lt;p&gt;In 1928, the High Tension Laboratory at the Technical University in Berlin (a premier research facility focused on electrical engineering in the interwar years) was researching high-voltage power transmission and insulation. A persistent obstacle was the electrical surge often caused by thunderstorms, which repeatedly damaged the lab’s equipment. But before scientists could design a way to mitigate the problem, they first needed to understand it: Exactly when did these surges occur, and how fast or large were the voltage fluctuations?&lt;/p&gt;
    &lt;p&gt;To tackle this, the lab hoped to recruit a graduate student to create a proof-of-concept for a high-speed oscilloscope, a device that could directly visualize electrical pulses. A cathode ray oscilloscope worked by firing a beam of electrons across a phosphorescent screen inside a vacuum tube, where the impact produced a bright spot of light. Electric fields could be used to deflect the beam horizontally (to represent time) and vertically (to represent signal amplitude) so that electrical signals appeared as moving lines of light that could be observed directly.&lt;/p&gt;
    &lt;p&gt;Although cathode ray oscilloscopes were already in use, they served mainly to capture slower signals. The high voltage surges experienced in thunderstorms or short circuiting events, though, flashed by in one hundred millionths of a second, leaving almost no trace on the screen. To make such fleeting signals visible, the intensity of the electron beam had to be increased, which meant focusing the beam into as small and powerful a spot as possible. Only one student applied to take on the challenge: 21-year-old Ernst Ruska.&lt;/p&gt;
    &lt;p&gt;Ruska was born into a family of scientists in Heidelberg, Germany, in 1906. He had been exposed to optics from an early age, as his uncle was an astronomer at the local observatory and his father, a science historian, owned a large optical microscope that Ruska was strictly forbidden to touch. He recalls in his Nobel lecture: “We would see on a table in the other room the pretty yellowish wooden box that housed my father’s big Zeiss microscope … He sometimes demonstrated to us interesting objects under the microscope, it is true; for good reasons, however, he feared that children’s hands would damage the objective or the specimen by clumsy manipulation of the coarse and line drive. Thus, our first relation to the value of microscopy was not solely positive.”&lt;/p&gt;
    &lt;p&gt;Unlike the rest of his family, Ruska’s passion leaned less toward science and more toward technical projects and problem-solving through engineering. While the other Ruska children spent their weekends with their father classifying rock samples or identifying bird calls, Ernst preferred tinkering with electrical switchboards and reading Max Eyth’s Behind Plow and Vice, a memoir on engineering and invention. And when he grew older, he recalls being fascinated by his high school physics teacher’s explanations of the movement of electrons through electrostatic fields and the limitations of light microscopes — an interest he carried into adulthood.&lt;/p&gt;
    &lt;p&gt;At the High Tension Laboratory, under Max Knoll, Ruska began building the much-anticipated oscilloscope. In this device, the incoming electrical current would pass through the vertical deflection plates, causing the electron beam to shift in proportion to the amplitude of the surge. To sharpen the image, a magnetic focusing coil was placed upstream of the deflection plates, concentrating the beam into a small, bright spot before it reached the phosphorescent screen. Ruska’s task was to determine the optimal placement of these coils so that the dot appeared as sharp as possible.&lt;/p&gt;
    &lt;p&gt;For guidance, Ruska turned to Hans Busch’s recent papers on the lens-like action of magnetic fields on electron beams. In these papers, Busch had not only shown that a coil could act as a “magnetic electron lens,” but had also worked out the formulas describing electron trajectories in such a field and how the focal length changed with coil current. Using these calculations, Ruska confirmed Busch’s theories experimentally and determined the precise coil placement needed to bring the beam to a sharp focus. He then placed a small aperture in the beam’s path and, by varying the coil current, was able to project and record an image of the aperture at different magnifications on a screen.&lt;/p&gt;
    &lt;p&gt;As Ruska later recalled in his Nobel lecture, his 1929 Master’s thesis contained “numerous sharp images with different magnifications of an electron-irradiated anode aperture … the first recorded electron-optical images.”&lt;/p&gt;
    &lt;p&gt;By 1930, as Germany’s economy collapsed under the weight of post-war reparations and global depression, Ruska was unable to find work in industry and remained at the university for doctoral studies. Initially unsure of a research direction, he continued experimenting with magnetic lenses. He reasoned that if one coil could produce a magnified image, two in sequence might enlarge it further — the conceptual birth of the electron microscope.&lt;/p&gt;
    &lt;p&gt;By April 1931, Ruska had constructed a two-stage imaging system with a total magnification of 14.4 times — still far below the roughly 1000-fold magnification achieved by high-quality light microscopes of the time. The system began with a cathode inside a vacuum tube, which emitted electrons when a high voltage was applied. These electrons were accelerated toward an anode and passed through a small aperture, forming a narrow beam, much like light through a pinhole. Magnetic coils wrapped around the tube acted as electron lenses. The first coil, placed close to the object, served as the objective lens, bringing the transmitted electrons into focus and forming an intermediate image. A second coil downstream acted as a projector lens, refocusing and enlarging that intermediate image so it could be captured onto a fluorescent screen.&lt;/p&gt;
    &lt;p&gt;By carefully tuning the currents in both coils, Ruska could control the focal lengths and achieve much higher magnifications than with a single lens. The final image appeared as glowing light patterns on the screen, with bright areas where electrons passed through the specimen and dark regions where they were absorbed or scattered.&lt;/p&gt;
    &lt;p&gt;These images, photographed through a window in the tube, were the first electron micrographs, created by channeling electrons through successive magnetic lenses in a multistage system. Although its resolution was quite modest by today’s standards, this instrument is regarded as the first electron microscope. Ruska submitted the results for publication that same month, though the paper did not appear until August. Unfortunately, unbeknownst to him, between its submission and publication, a patent for an electron microscope had already been submitted by another inventor: Reinhold Rüdenberg.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Paralysis to First Patents&lt;/head&gt;
    &lt;p&gt;Rüdenberg, born in Hanover in 1883, came of age during a golden decade of physics marked by Röntgen’s discovery of X-rays, the identification of the electron, and the first studies of radioactivity. As a high-school student, he eagerly replicated many of these experiments, building a two-way Morse telegraph, powering an X-ray tube with a hand-wound inductor, and constructing a radio transmitter and receiver. He received his first patent, for a radio oscillator, while still an electrical engineering student at the Technical University of Hanover.&lt;/p&gt;
    &lt;p&gt;After earning his doctorate, Rüdenberg spent three years (1906-1908) at Göttingen University, working in applied mechanics and collaborating with leading figures in electron theory, including Hans Busch. In 1908, he joined Siemens in Berlin as a design engineer and, by 1923, had risen to the position of Chief Electrical Engineer.&lt;/p&gt;
    &lt;p&gt;While at Siemens, Rüdenberg developed several new electrical designs, among which were cooling systems for high-voltage generators, one of the first 60-megawatt turbine generators, conductors for high-voltage transmission lines, and relay systems for distant power stations. He also spent three years apprenticing in Siemens’ patent department, an experience that doubtless helped fuel his prolific output of them. He was a prolific inventor and is estimated to have held over a hundred unique patents.&lt;/p&gt;
    &lt;p&gt;In the fall of 1930, while on vacation, Rüdenberg’s youngest son fell gravely ill. The three-year-old developed a high fever and paralysis. He had contracted polio. At a time when thousands were infected each year in Germany, with fatality rates around 15 percent, the diagnosis was devastating. Worse still, almost nothing was known about the “germ” responsible: No diagnostic test, no treatment, and no vaccine existed.&lt;/p&gt;
    &lt;p&gt;“This amazing fact and its significance for science and health gave me no rest in my thoughts,” Rüdenberg later recalled. “During many sleepless nights, tortured by the fate of my son, agonizing fantasies came and went, how to find ways to examine these minute germs, how possibly to attack them in order to attain healing or at least a standstill of the disease. Certainly, an agent finer than light had to be found to make these tiny viruses of immeasurable size visible to the human eye.”&lt;/p&gt;
    &lt;p&gt;Motivated by both paternal concern and engineering instinct, Rüdenberg began searching for a way to see such viruses. He considered X-rays but quickly dismissed them, as no method existed to focus the X-ray particles like visible light. Electrons, however, held promise. Having studied their behavior with Busch at Göttingen, he was aware of the focusing power of magnetic fields, and when Busch later published his 1926 and 1927 papers on magnetic electron lenses, he even sent copies directly to Rüdenberg.&lt;/p&gt;
    &lt;p&gt;During the winter of 1930-1931, Rüdenberg sketched out a complete conceptual design for an electron microscope, detailing its electron source, electrostatic lenses for focusing and magnification, and a fluorescent screen for visualization. In May 1931, just one week before Ruska publicly presented his own work, Rüdenberg submitted a series of patent applications describing this electron microscope.&lt;/p&gt;
    &lt;p&gt;Meanwhile, unaware of Rüdenberg’s patents, Ruska also pressed forward. For his doctoral research, Ruska focused on improving the electromagnetic lens, whose magnification ability still lagged far behind the optical lenses of conventional light microscopes. At the time, a state-of-the-art light microscope could magnify images up to about 1000 times, whereas in 1932, extant electron microscopes were still stuck at a paltry 17-fold.&lt;/p&gt;
    &lt;p&gt;To improve their performance, Ruska realized he needed to decrease the electron microscope’s focal length, since a shorter focal length would bend electrons more strongly, bringing them to a smaller focal point and producing a higher magnification. He discovered that encasing the coil in iron did so dramatically. This led to the invention of the polepiece lens, now a fundamental component of all electron microscopes.&lt;/p&gt;
    &lt;p&gt;Polepieces are shaped iron cylinders, each with a coil, placed a few millimeters apart. The narrow gap concentrates the magnetic field, producing a lens with stronger focusing ability and a shorter focal length. This not only increased the magnification but also provided more space to add a third lens (a condenser lens upstream of the sample) within the cathode ray column.&lt;/p&gt;
    &lt;p&gt;During this time, Ruska and Knoll also made a bold attempt to estimate the theoretical resolution limit of the electron microscope. They applied the formula used in light microscopy and substituted the wavelength of electrons for that of light. For electrons accelerated at 75 kilovolts (higher voltages would increase the electrons’ energy and further shorten their wavelength, which, in principle, yields even finer detail), they arrived at a resolution limit of 2.2 angstroms (2.2 x 10-10 meters).8&lt;/p&gt;
    &lt;p&gt;Ruska submitted his dissertation in mid-1933 and later that year built a vastly improved microscope, achieving magnification up to 12,000 times. The images, taken of a scrap of aluminum foil, exceeded the resolution limit of the light microscope for the first time (even though the high-energy beam incinerated the samples).&lt;/p&gt;
    &lt;p&gt;Ruska observed that very thin foils produced sharper images with stronger contrast while also surviving longer under the beam. He reasoned that, in thin specimens, most electrons passed through without losing energy, elastically scattered (diffracted) rather than absorbed. These transmitted electrons still carried structural information and built up the image on the screen. Because fewer electrons deposited energy in the material, less heating and radiation damage occurred, allowing longer exposures and finer detail.&lt;/p&gt;
    &lt;p&gt;By 1934, Ruska had published these findings and even speculated about imaging biological material. He stated, “This microscopy is accessible to any objects (including all organic ones), provided that they can be prepared as sufficiently thin foils and introduced into the vacuum without suffering damage (structural alteration).” And, “For better visualization of such objects — one might think, for example, of nerve fibrils with their extremely fine structure — it will perhaps be necessary to develop ‘staining’ methods adapted to the problem, such as impregnation with metal salts (silvering), similar to those already commonly used in ordinary histological microscopy.”&lt;/p&gt;
    &lt;p&gt;Rüdenberg’s design, meanwhile, was never built at Siemens. The political upheaval in Germany halted his advancement, as a German of Jewish descent, threatened his very survival. In 1936, with Siemens’ assistance, he and his family fled to England and, two years later, emigrated to the United States, where he became a professor of electrical engineering at Harvard.&lt;/p&gt;
    &lt;p&gt;Ironically, as a German, Rüdenberg was received with ambivalence; in 1942, during the war, his U.S. patents on the electron microscope were seized by the Alien Property Custodian, a government office tasked with seizing assets belonging to citizens of enemy nations during wartime. Post-war, he had to fight lengthy legal battles to reclaim them. He later consulted for Farrand Optical Company, a small company in New York which attempted to build an electrostatic microscope based on his patents, a venture which failed commercially. Happily, even as these obstacles abounded, his son made a full recovery from his polio.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Prototype to Commercialization&lt;/head&gt;
    &lt;p&gt;By the early 1930s, electron microscopy had surpassed the resolving power of light microscopes, promising magnifications several orders of magnitude higher. Yet progress was uneven.&lt;/p&gt;
    &lt;p&gt;In Belgium, the Hungarian physicist Ladislaus Marton built his own instrument by 1932 and produced the first biological electron micrographs: images of the insectivorous plant Drosera intermedia and the blood-red bacterium, Serratia marcescens.&lt;/p&gt;
    &lt;p&gt;To make such delicate samples visible, Marton turned to osmium tetroxide, a heavy metal compound that binds strongly to cellular membranes. By coating thin sections of Drosera intermedia with osmium, he increased their ability to scatter electrons, resulting in clearer contrast in the final image. He also introduced an electronic shutter, a device that blocked the electron beam during focusing and opened only for the brief moment of exposure. This protected fragile specimens from unnecessary radiation damage while still allowing sharp images to be captured. For a time, it seemed Marton was leading the field.&lt;/p&gt;
    &lt;p&gt;Ruska, who had completed his PhD in 1933 and took a job in the television industry, returned to the field. He joined forces with Bodo von Borries, a longtime collaborator and future brother-in-law, to push the technology toward commercial viability. Between 1933 and 1935, they filed eight patents and canvassed a wide range of institutions for financial support. They approached the Kaiser Wilhelm Institute, the board of optical manufacturer Carl Zeiss, and even steel companies to see if they had any need for electron microscopes. While initial efforts with Zeiss seemed promising, they collapsed when Zeiss withdrew due to Siemens’s rights to Reinhold Rüdenberg’s earlier patents.&lt;/p&gt;
    &lt;p&gt;Despite these setbacks, interest in electron microscopy mounted. At the Technical School in Berlin, students modified Ruska’s prototypes to capture striking images of a fly’s leg hair magnified 25,000 times. To make the tissues more resistant to the beam, they used potassium dichromate, a fixative that coss-linked lipids and proteins in the tissue so it was less likely to collapse or vaporize. This fixative also increased scattering contrast, making fine details easier to discern.&lt;/p&gt;
    &lt;p&gt;Specimens were cooled to –17 °C, which reduced thermal motion and slowed the buildup of heat from inelastic electron collisions. Cooling didn’t prevent radiation damage, but it delayed it long enough for images to be recorded. These were early explorations of the cryogenic methods that would later define the field.&lt;/p&gt;
    &lt;p&gt;By 1936, electron microscopy centered around a highly active (albeit small) community with Marton in Belgium, Ruska and von Borries in Berlin, and younger researchers at their university extending the work. However, all still lacked financial support to develop a commercial system.&lt;/p&gt;
    &lt;p&gt;Momentum shifted when Ruska spoke at the 1936 German Conference of Physicists and Mathematicians. His brother Helmut, a physician newly appointed at Berlin’s University Hospital, added crucial medical endorsement by promoting the microscope’s potential in medical applications. This medical credibility brought Siemens back to the table. With both Siemens and Zeiss expressing interest, Ruska and von Borries chose Siemens, which already held the Rüdenberg patents and had stronger electrotechnical expertise.&lt;/p&gt;
    &lt;p&gt;In February 1937, a decade after Hans Busch first theorized the electron lens, Siemens launched development of the first commercial electron microscope in Berlin. By 1938, the first model was available, offering magnification of up to 30,000 times.&lt;/p&gt;
    &lt;p&gt;The device was a triumph of Ruska’s bench-top experiments and relentless iteration. At the top of the microscope column sat the cathode, generating electrons accelerated downward at high voltage. A condenser lens collected, narrowed, and focused the electron beam to illuminate the sample, which was introduced through a small vacuum airlock and held on a stage. Immediately below it lay the objective lens, a powerful magnetic coil that brought the transmitted electrons into sharp focus, forming a first, intermediate image. A second coil, the projection lens, then enlarged this image and cast it onto a fluorescent screen, where bright and dark regions revealed the specimen’s structure. Researchers could view the glowing picture directly through a built-in window or capture it on photographic plates housed beneath the screen. To maintain stable operation, the entire column was kept under high vacuum by a mercury diffusion pump.&lt;/p&gt;
    &lt;p&gt;A shared Siemens laboratory was set up and became an important hub for producing some of the earliest biological electron micrographs. Directed by Helmut Ruska, it housed four instruments available to visiting scientists, many of them biologists and medical researchers. In 1939 alone, nearly 2,000 images were produced, leading to 23 publications. Among them were the first electron micrographs of viruses, bacteriophages, and fine biological details never before seen.&lt;/p&gt;
    &lt;p&gt;The lab itself was destroyed in an air raid in 1944, and it would take nearly a decade before Siemens in Germany regained its footing in electron microscopy. But by then, the electron microscopy spark had spread: Laboratories in Britain and the United States continued to drive the field forward, building on the groundwork laid in Berlin. Ernst Ruska would go on to win the Nobel Prize in Physics in 1986 for his fundamental work in electron optics and microscopy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Inside an Electron Microscope&lt;/head&gt;
    &lt;p&gt;Nearly a century after its invention, the electron microscope has transformed from a tool barely capable of resolving fuzzy virus particles into one capable of capturing atomic detail. While its progress has mostly been marked by steady refinements, it has also been punctuated by key breakthroughs.&lt;/p&gt;
    &lt;p&gt;For instance, from the start, electron microscopy for biology faced a water problem. Because the microscope operates under high vacuum, liquid water evaporates instantly, leaving delicate biological samples collapsed or distorted. To avoid this, aqueous samples had to be dried, fixed, or stained, which produced recognizable images but with obvious artifacts, such as shrunken cells, ruptured membranes, and structural distortions that no longer reflected the living state. Through the 1940s and 1950s, embedding samples in resins and the use of ultra-thin sectioning made cellular ultrastructure visible, while freeze-drying and early cryogenic sectioning offered partial preservation of hydrated material, though the results were still plagued by distortion.&lt;/p&gt;
    &lt;p&gt;A breakthrough came in the early 1980s, when Jacques Dubochet and his colleagues at the European Molecular Biology Laboratory in Heidelberg demonstrated that water could be vitrified; that is, cooled so rapidly that it solidifies into glass rather than crystallizing, finally allowing biomolecules to be preserved and imaged as they are in life.&lt;/p&gt;
    &lt;p&gt;In parallel, computational techniques were improving. Beginning in the 1970s, Joachim Frank developed statistical methods for aligning and averaging thousands of noisy electron micrographs of individual macromolecules. This “single-particle analysis” transformed faint, low-contrast images into coherent 3D reconstructions. When combined with Dubochet’s vitrification method, the two advances gave rise to single-particle cryo-electron microscopy: Molecules suspended in vitreous ice could be imaged in random orientations and computationally combined into detailed three-dimensional structures.&lt;/p&gt;
    &lt;p&gt;Three decades later, with the arrival of direct electron detectors, developed with the efforts of Richard Henderson and with more powerful algorithms, single-particle cryo-EM entered its “resolution revolution,” routinely delivering near-atomic detail and firmly establishing itself as one of the central methods of structural biology.&lt;/p&gt;
    &lt;p&gt;Today’s most advanced cryo-electron microscopes stand nearly two stories tall, cost millions of dollars, and operate with breathtaking precision. But they still rest on the same foundation laid in the 1930s: a beam of electrons, shaped by magnetic fields, interacting with matter to reveal what light cannot.&lt;lb/&gt;At the top of the vertical column is the electron gun, the source of the beam. A fine tungsten filament or sharp field-emission tip is held at high negative voltage, often 200–300 kilovolts, so electrons are released and accelerated down the column. At these energies, electrons travel close to the speed of light, with wavelengths thousands of times shorter than visible light, giving them their extraordinary resolving power. To prevent scattering, the column is maintained in an ultra-high vacuum, as even trace gases could deflect or scatter the beam.&lt;/p&gt;
    &lt;p&gt;Magnetic lenses, made of coiled wire encased in iron polepieces, focus and steer the electrons much like glass lenses bend light. The condenser lens narrows the beam onto the sample, while the objective lens forms the first magnified image. Additional projector lenses enlarge this image and deliver it to a detector.&lt;/p&gt;
    &lt;p&gt;When the beam passes through the specimen, electrons interact with its atoms. Some scatter elastically, shifting phase without losing energy; others scatter inelastically, losing energy, and are either absorbed or filtered out. The transmitted electrons carry structural information, encoded as variations in amplitude and phase, and create a contrast image on the detector.&lt;/p&gt;
    &lt;p&gt;In cryo-EM, millions of such low-contrast 2D projections are collected, each a noisy snapshot of a molecule in a random orientation. Computational algorithms align, classify, and combine them, using a mathematical method that breaks the images down into their underlying patterns of waves (using the Fourier transform), then piece those patterns back together to form a detailed 3D map.&lt;/p&gt;
    &lt;p&gt;The result begins as a grainy micrograph, but when assembled and refined, this picture reveals extraordinary detail: the honeycomb lattice of graphene, the folds of a viral capsid, or the ribosome caught mid-translation. &lt;lb/&gt;Today, no single imaging method captures everything. For following fast processes, tracking molecules in living cells, or imaging whole organisms, light microscopy remains indispensable. For atomic resolution of well-ordered proteins, X-ray crystallography is still unmatched. &lt;/p&gt;
    &lt;p&gt;But when it comes to bridging the scales between atoms and cells, there is no better tool than the electron microscope. The same instrument that in 1938 revealed the faint silhouettes of mouse ectromelia virus now resolves viral proteins at the scale of a chemical bond, an arc of progress that has helped biologists redefine what it means to “see.”&lt;/p&gt;
    &lt;p&gt;Smrithi Sunil is a research scientist developing imaging techniques to study how the brain works across scales. She has developed multimodal microscopy methods to bridge molecular, cellular, and systems-level measurements of structure and function. She also writes about science and metascience on her Substack, Engineering Discovery.&lt;/p&gt;
    &lt;p&gt;Thanks to Nicholas Porter and Alicia Botes for reading a draft of this essay. Lead image by Ella Watkins-Dulaney, adapted from Vossman/Wikimedia and Ernst Ruska. Whole-cell animation and video by Martina Maritan, Scripps Research.&lt;/p&gt;
    &lt;p&gt;Cite: Sunil, S. “Making the Electron Microscope.” Asimov Press (2025). https://doi.org/10.62211/57hg-22fw&lt;/p&gt;
    &lt;p&gt;One of the smallest known whole organisms is the bacteria Mycoplasma genitalium roughly 200 nm across. In contrast, the mycelium network Armillaria ostoyae in the Malheur National Forest in Oregon is possibly the largest living organism, covering almost four square miles and weighing around 35,000 tons.&lt;/p&gt;
    &lt;p&gt;The length between chemical bonds is measured in Angstroms, named after Swedish physicist Anders Jonas Angstrom who first described the unit.&lt;/p&gt;
    &lt;p&gt;A year later, in 1939, Gustav Kausche, Edgar Pfankuch, and Helmut Ruska reported the first images of the tobacco mosaic virus (TMV). Although TMV is often cited as the “first” virus to be imaged with an electron microscope since TMV was a classic model virus in biology and its rod-shaped form was immediately recognizable, the mouse orthopoxvirus micrographs technically appeared earlier.&lt;/p&gt;
    &lt;p&gt;To work around this, scientists capture dynamics indirectly by freezing specimens at different stages of a process (such as during the assembly of a protein complex) and then reconstruct the sequence from these static frames.&lt;/p&gt;
    &lt;p&gt;Numerical aperture NA = n sin θ, where n is the refractive index of the medium and θ is the half-angle of the widest cone of light the lens can accept.&lt;/p&gt;
    &lt;p&gt;Twice this value arises because fine structures in a specimen diffract light into symmetric beams on opposite sides of the optical axis. When both of these beams are captured by the objective and brought together at the image plane, they interfere with reconstructing the alternating patterns of light and dark that represent the specimen’s fine detail. Note that Abbe’s formula is for coherent transmitted light and not for fluorescent imaging. In fluorescence microscopy, each molecule emits light independently rather than by interfering wavefronts, so the image is not formed by overlapping diffraction orders. The resolution is instead limited by the microscope’s point spread function, described by the Rayleigh criterion (d = 1.22 λ / 2 NA), which sets the smallest distance at which two fluorescent emitters can be distinguished.&lt;/p&gt;
    &lt;p&gt;Even before “electrons” were named, Julius Plücker showed in the 1850s that magnetic fields could deflect the glowing path of cathode rays. Johann Hittorf (1869) and Kristian Birkeland (1896) had independently used magnetic coils to focus them. Hans Busch was the first to provide mathematical calculations for the electron trajectories during this focusing action.&lt;/p&gt;
    &lt;p&gt;This resolution was, in fact, achieved 40 years later. Today, electron microscopy has even surpassed that mark: Scientists have resolved biological structures to well below 2 angstroms, including the GABA receptor, a membrane protein channel that mediates inhibitory neurotransmission, at 1.7 angstroms. In this system, the electrons were accelerated to 300 kilovolts, yielding a resolution better than the one Ruska proposed with only 75 kilovolts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.asimov.press/p/electron-microscope"/><published>2025-10-26T16:46:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45713359</id><title>Ken Thompson recalls Unix's rowdy, lock-picking origins</title><updated>2025-10-27T04:46:41.561821+00:00</updated><content>&lt;doc fingerprint="3a3a188cfbb6805d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ken Thompson Recalls Unix’s Rowdy, Lock-Picking Origins&lt;/head&gt;
    &lt;p&gt;The 82-year-old Ken Thompson has some amazing memories about the earliest days of the Unix operating system — and the rowdy room full of geeks who built it.&lt;/p&gt;
    &lt;p&gt;This month Silicon Valley’s Computer History Museum released a special four-and-a-half-hour oral history, in partnership with the Association for Computing Machinery, recorded 18 months ago by technology historian David C. Brock. And Thompson dutifully recalled many of his career highlights — from his work on the C programming language and Unix to the “Plan 9 from Bell Labs” operating system and the Go programming language.&lt;/p&gt;
    &lt;p&gt;But what comes through is his gratefulness for the people he’d worked with, and the opportunity they’d had to all experiment together in an open environment to explore the limits of new and emerging technologies. It’s a tale of curiosity, a playful sense of serendipity and the enduring value of a community.&lt;/p&gt;
    &lt;p&gt;And along the way, Thompson also tells the story of raising a baby alligator that a friend sent to his office at Bell Labs. (“It just showed up in the mail… They’re not the sweetest of pets.”)&lt;/p&gt;
    &lt;head rend="h2"&gt;The Accidental Birth of Unix&lt;/head&gt;
    &lt;p&gt;Travel back in time to 1966, when 23-year-old Thompson’s first project at Bell Labs was the ill-fated Multics, a collaboration with MIT and General Electric which Thompson remembers as “horrible… big and slow and ugly and very expensive,” requiring a giant specially-built computer just to run and “just destined to be dead before it started.”&lt;/p&gt;
    &lt;p&gt;But when the Multics project died, “the computer became completely available — this one-of-a-kind monster computer… and so I took advantage.”&lt;/p&gt;
    &lt;p&gt;Thompson had wanted to work with CRAM, a data storage device with a high-speed drum memory, but like disk storage of the time, it was slow to read from memory.&lt;/p&gt;
    &lt;p&gt;Thompson thought he’d improve the situation with simultaneous (and overlapping) memory reads, but of course this required programs for testing, plus a way to load and run them.&lt;/p&gt;
    &lt;p&gt;“And suddenly, without knowing it — I mean, this is sneaking up on me…. Suddenly it’s an operating system!” Thompson’s initial memory-reading work became “the disk part” for Unix’s filesystem. He still needed a text editor and a user-switching multiplexing layer (plus a compiler and an assembler for programs), but it already had a filesystem, a disk driver and I/O peripherals.&lt;/p&gt;
    &lt;p&gt;Thompson wondered if it took so long to recognize its potential because he’d been specifically told not to work on operating systems. Multics “was a bad experience” for Bell Labs, he’d been told. “We spent a ton of money on it, and we got nothing out of it!”&lt;/p&gt;
    &lt;p&gt;“I actually got reprimands saying, ‘Don’t work on operating systems. Bell Labs is out of operating systems!”&lt;/p&gt;
    &lt;head rend="h2"&gt;One-Digit User IDs&lt;/head&gt;
    &lt;p&gt;But now Unix had its first user community — future legends like Dennis Ritchie, Doug McIlroy, Robert Morris and occasionally Brian Kernighan. (“All the user IDs were one digit. That definitely put a limit on it.”) Thompson remembers designing the Unix filesystem on a blackboard in an office with Rudd Canaday — using a special Bell Labs phone number that took dictation and delivered a typed-up transcript the next day. And Joe Ossanna “got things done” with a special talent for navigating Bell Labs’ bureaucracy that ultimately procured a crucial PDP-11 for the Unix team to work on.&lt;/p&gt;
    &lt;p&gt;“We were being told no, ‘because we don’t deal in operating systems.'” But Ossanna knew the patent department was evaluating a third-party system for preparing documents — and Ossanna proposed an in-house alternative. “So we got our first PDP-11 to do word processing.”&lt;/p&gt;
    &lt;p&gt;And history shows that it happened partly because the department paying for it “had extra money, and if they didn’t spend it, they’d lose it the next year…”&lt;/p&gt;
    &lt;p&gt;So the young Unix community picked up somewhere between five and eight new users, Thompson remembers, “the secretaries for the Patent Department, writing patents on our system!”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Fellowship of the Unix Room&lt;/head&gt;
    &lt;p&gt;That PDP-11 wound up in “a spot on the sixth floor where we cleaned out a vending machine and a couple of cages of stored junk from 1920,” Thompson remembered. They eventually installed a second PDP-11, which turned the room into “a hotbed of things,” with discussions about networking — and an upcoming typesetter for documents. Thompson calls it the Unix room, and most of them eventually had extensions for their phones wired into the room. (It even had its own call-switching PBX …)&lt;/p&gt;
    &lt;p&gt;There was camaraderie and some laughter. He adds later, almost as an aside, that “in the Unix room, we used to pick locks a lot and steal things.” (When one of the secretaries discovered security had affixed a “parking boot” to her car that was parked in the wrong zone, “we went down there, and we picked the lock and stole the boot. And after that, slowly, we picked up all four boots, and we hid them under the raised floor of the Unix room…”)&lt;/p&gt;
    &lt;p&gt;The punchline? “The head of security came around and pleaded with us. ‘We won’t pick on your secretaries if you give us back our boots.'”&lt;/p&gt;
    &lt;p&gt;And the deal was accepted.&lt;/p&gt;
    &lt;p&gt;Thompson remembers things like gathering for a regular “Unix lunch” in the Bell Labs lunchroom, which “caused a symbiosis of thought and things. It was great.” Although it always seemed to happen just minutes after the lunchroom stopped serving food. “If I was late, I’d buy McDonald’s and sit down at the lunchroom with my McDonald’s. They used to get mad at me for that …”&lt;/p&gt;
    &lt;head rend="h2"&gt;Growing From Community&lt;/head&gt;
    &lt;p&gt;Looking back, Thompson credited the success of C and Unix to Bell Labs and its no-pressure/no users environment. “It was essentially a ‘whatever you want to do’ atmosphere, and ‘for anybody you wanted to do it for’… Bell Labs was by far the biggest contributor to this whole type of programming.”&lt;/p&gt;
    &lt;p&gt;Bell Labs was an eclectic mix, but this community paid unexpected dividends. While Lee McMahon was originally hired as a linguistics researcher, he was ultimately the one who procured machine-readable dictionaries for the Unix team, along with machine-readable version of the Federalist Papers. (When the whole text wouldn’t fit into their text editor ed, Thompson famously created the line-by-line pattern-scanning tool grep.)&lt;/p&gt;
    &lt;p&gt;And in the end Thompson says Unix grew from there for one simple fact: People liked it. It spread within Bell Labs, at first for “the administrative kind of stuff, typing in trouble tickets…” But this being a phone company, “then it started actually doing some switching, and stuff like that. It was getting deeper and deeper into the guts of the Bell System and becoming very popular.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Before Open Source&lt;/head&gt;
    &lt;p&gt;Thompson credits Richard Stallman with developing much more of the open source philosophy. “But Unix had a bit of that.” Maybe it grew out of what Dennis Ritchie was remembering, that fellowship that formed around Unix. “For some reason, and I think it’s just because of me and Dennis, everything was open…”&lt;/p&gt;
    &lt;p&gt;It was just the way they operated. “We had protection on files — if you didn’t want somebody to read it, you could set some bits and then nobody could read them, right? But nobody set those permissions on anything … All of the source was writable, by anybody! It was just open …&lt;/p&gt;
    &lt;p&gt;“If you had an idea for an editor, you’d pull the editor out and you’d write on it and put it back … There was a mantra going around that, ‘You touch it, you own it.'”&lt;/p&gt;
    &lt;p&gt;Thompson provides an example: Bell Labs co-worker P. J. Plauger, with whom he later wrote the 1974 book “Elements of Programming Style.” Plauger was also a professional science fiction writer, Thompson remembers, “And whatever he was writing on was in his directory, right? So, we’d all go in there and be reading it as he’s writing it … and we’d all write back, ‘You ought to kill this guy, and move him over here and turn him green!’ or something.&lt;/p&gt;
    &lt;p&gt;“And he didn’t mind it, because that’s just the theory of Unix in those days …&lt;/p&gt;
    &lt;p&gt;“I think that generated a fellowship. Just the fact that it was like writing on a blackboard — everybody read it.”&lt;/p&gt;
    &lt;p&gt;And more of their Bell Labs experiments found their way into the world when some work on the later Plan 9 operating system found its way into the UTF-8 standard, which underlies most of today’s web connections.&lt;/p&gt;
    &lt;head rend="h2"&gt;After Bell Labs&lt;/head&gt;
    &lt;p&gt;Thompson left Bell Labs in 2000, after the breakup of the Bell system. (“It had changed; it was really different … You had to justify what you were doing, which is way above my pay grade.”) But his three decades there seemed to shine an influence over the rest of his life.&lt;/p&gt;
    &lt;p&gt;Thompson first moved on to a networking equipment company called Entrisphere, where he worked for six years — and a move to Google was the natural next step. The head at Entrisphere had already moved to Google, and was urging Thompson to follow him — and it turned out that Google CEO Eric Schmidt was an old friend who’s actually worked at Bell Labs in 1975. (Thompson says Google made him “an exceedingly good offer”…)&lt;/p&gt;
    &lt;p&gt;At Google Thompson worked “a little bit” on Android security. (“I found a couple of specific problems, but by and large, it was very well done”.) But eventually Thompson joined the three-person team that would create the programming language Go.&lt;/p&gt;
    &lt;p&gt;And he was doing the work with Rob Pike, who was one of his old comrades from Bell Labs nearly 30 years before!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thenewstack.io/ken-thompson-recalls-unixs-rowdy-lock-picking-origins/"/><published>2025-10-26T16:57:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45713367</id><title>Books by People – Defending Organic Literature in an AI World</title><updated>2025-10-27T04:46:41.233455+00:00</updated><content>&lt;doc fingerprint="a88d121106b30532"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Defending&lt;lb/&gt;Organic Literature&lt;lb/&gt;in an AI World. &lt;/head&gt;
    &lt;p&gt;We certify publishers as producers of human-authored books, with a process readers can trust.&lt;/p&gt;
    &lt;head rend="h2"&gt;About Us&lt;/head&gt;
    &lt;p&gt;Books By People is a new independent organisation that partners with publishers to verify and certify human-written books, safeguarding creative integrity and public confidence in an AI-driven era.&lt;/p&gt;
    &lt;head rend="h4"&gt;The Crisis&lt;/head&gt;
    &lt;p&gt;AI is flooding the literary world with imitations of human storytelling, challenging the publishing world to respond. Without safeguards, authentic human work will inevitably struggle to maintain the visibility and credibility it deserves.&lt;/p&gt;
    &lt;head rend="h4"&gt;Our Mission&lt;/head&gt;
    &lt;p&gt;To uphold a trusted and recognisable âOrganic Literatureâ market by supporting publishers and authors who champion human writing, and by making that commitment clear and valuable to readers.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Our Process Works&lt;/head&gt;
    &lt;p&gt;We work collaboratively with publishers to verify internal systems are in place and accessible to staff. Our certification lets you display the Books By People stamp on books and marketing, affirming your commitment to human authorship and that titles meet our standards.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Our Process Works&lt;/head&gt;
    &lt;p&gt;We work collaboratively with publishers to verify internal systems are in place and accessible to staff.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Our certification lets you display the Books By People stamp on books and marketing, affirming your commitment to human authorship and that titles meet our standards.&lt;/p&gt;
    &lt;head rend="h3"&gt;Publisher Onboarding&lt;/head&gt;
    &lt;p&gt;A review of your editorial practices via a questionnaire covering workflows, AI usage, authorship integrity, and editorial control. Follow-up meetings and discussions to establish our working partnership.&lt;/p&gt;
    &lt;head rend="h3"&gt;Publisher Onboarding&lt;/head&gt;
    &lt;p&gt;A review of your editorial practices via a questionnaire covering workflows, AI usage, authorship integrity, and editorial control. Follow-up meetings and discussions to establish our working partnership.&lt;/p&gt;
    &lt;head rend="h3"&gt;Publisher Onboarding&lt;/head&gt;
    &lt;p&gt;A review of your editorial practices via a questionnaire covering workflows, AI usage, authorship integrity, and editorial control. Follow-up meetings and discussions to establish our working partnership.&lt;/p&gt;
    &lt;head rend="h3"&gt;Publisher Onboarding&lt;/head&gt;
    &lt;p&gt;A review of your editorial practices via a questionnaire covering workflows, AI usage, authorship integrity, and editorial control. Follow-up meetings and discussions to establish our working partnership.&lt;/p&gt;
    &lt;head rend="h3"&gt;Title Sampling &amp;amp; Review&lt;/head&gt;
    &lt;p&gt;A small sample of your recent titles is reviewed using expert analysis, editorial process checks and signed declarations to confirm they meet the Organic Literature standard.&lt;/p&gt;
    &lt;head rend="h3"&gt;Title Sampling &amp;amp; Review&lt;/head&gt;
    &lt;p&gt;A small sample of your recent titles is reviewed using expert analysis, editorial process checks and signed declarations to confirm they meet the Organic Literature standard.&lt;/p&gt;
    &lt;head rend="h3"&gt;Title Sampling &amp;amp; Review&lt;/head&gt;
    &lt;p&gt;A small sample of your recent titles is reviewed using expert analysis, editorial process checks and signed declarations to confirm they meet the Organic Literature standard.&lt;/p&gt;
    &lt;head rend="h3"&gt;Title Sampling &amp;amp; Review&lt;/head&gt;
    &lt;p&gt;A small sample of your recent titles is reviewed using expert analysis, editorial process checks and signed declarations to confirm they meet the Organic Literature standard.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification Agreement&lt;/head&gt;
    &lt;p&gt;Once approved, a formal publisher agreement confirms your certified status and shared commitment to human authorship, with annual reviews to uphold best practices.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification Agreement&lt;/head&gt;
    &lt;p&gt;Once approved, a formal publisher agreement confirms your certified status and shared commitment to human authorship, with annual reviews to uphold best practices.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification Agreement&lt;/head&gt;
    &lt;p&gt;Once approved, a formal publisher agreement confirms your certified status and shared commitment to human authorship, with annual reviews to uphold best practices.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification Agreement&lt;/head&gt;
    &lt;p&gt;Once approved, a formal publisher agreement confirms your certified status and shared commitment to human authorship, with annual reviews to uphold best practices.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification &amp;amp; Stamp Use&lt;/head&gt;
    &lt;p&gt;Youâll receive the Books By People Stamp, Certification ID, and QR code linking to a profile in our Certified Publisher Directory. These can be used across covers, metadata, and marketing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification &amp;amp; Stamp Use&lt;/head&gt;
    &lt;p&gt;Youâll receive the Books By People Stamp, Certification ID, and QR code linking to a profile in our Certified Publisher Directory. These can be used across covers, metadata, and marketing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification &amp;amp; Stamp Use&lt;/head&gt;
    &lt;p&gt;Youâll receive the Books By People Stamp, Certification ID, and QR code linking to a profile in our Certified Publisher Directory. These can be used across covers, metadata, and marketing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Certification &amp;amp; Stamp Use&lt;/head&gt;
    &lt;p&gt;Youâll receive the Books By People Stamp, Certification ID, and QR code linking to a profile in our Certified Publisher Directory. These can be used across covers, metadata, and marketing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources &amp;amp; Consultation&lt;/head&gt;
    &lt;p&gt;Companies receive the Organic Literature Publisher Manual, quarterly âAI indicatorsâ guidance, a legal playbook, and in-house AI monitoring materials, with optional year-round advisor support.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources &amp;amp; Consultation&lt;/head&gt;
    &lt;p&gt;Companies receive the Organic Literature Publisher Manual, quarterly âAI indicatorsâ guidance, a legal playbook, and in-house AI monitoring materials, with optional year-round advisor support.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources &amp;amp; Consultation&lt;/head&gt;
    &lt;p&gt;Companies receive the Organic Literature Publisher Manual, quarterly âAI indicatorsâ guidance, a legal playbook, and in-house AI monitoring materials, with optional year-round advisor support.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources &amp;amp; Consultation&lt;/head&gt;
    &lt;p&gt;Companies receive the Organic Literature Publisher Manual, quarterly âAI indicatorsâ guidance, a legal playbook, and in-house AI monitoring materials, with optional year-round advisor support.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ecosystem Access&lt;/head&gt;
    &lt;p&gt;Join our wider network, with access to trusted legal experts for AI and the creative industries, connection opportunities, curated updates, and a quarterly newsletter on AI in publishing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ecosystem Access&lt;/head&gt;
    &lt;p&gt;Join our wider network, with access to trusted legal experts for AI and the creative industries, connection opportunities, curated updates, and a quarterly newsletter on AI in publishing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ecosystem Access&lt;/head&gt;
    &lt;p&gt;Join our wider network, with access to trusted legal experts for AI and the creative industries, connection opportunities, curated updates, and a quarterly newsletter on AI in publishing.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ecosystem Access&lt;/head&gt;
    &lt;p&gt;Join our wider network, with access to trusted legal experts for AI and the creative industries, connection opportunities, curated updates, and a quarterly newsletter on AI in publishing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join The Organic Literature Movement&lt;/head&gt;
    &lt;p&gt;Partner with us to become a certified publisher of Organic Literature: books conceived and written by humans. This certification confirms that your house upholds human authorship and does not publish books containing AI-generated or AI-rewritten content.&lt;/p&gt;
    &lt;head rend="h4"&gt;Secure the Future of Human Authorship&lt;/head&gt;
    &lt;p&gt;Joining the movement at this time protects the value of human stories, preserves original thought, and ensures that the democratic future of literature remains led by people.&lt;/p&gt;
    &lt;head rend="h4"&gt;Secure the Future of Human Authorship&lt;/head&gt;
    &lt;p&gt;Joining the movement at this time protects the value of human stories, preserves original thought, and ensures that the democratic future of literature remains led by people.&lt;/p&gt;
    &lt;head rend="h4"&gt;Secure the Future of Human Authorship&lt;/head&gt;
    &lt;p&gt;Joining the movement at this time protects the value of human stories, preserves original thought, and ensures that the democratic future of literature remains led by people.&lt;/p&gt;
    &lt;head rend="h4"&gt;Secure the Future of Human Authorship&lt;/head&gt;
    &lt;p&gt;Joining the movement at this time protects the value of human stories, preserves original thought, and ensures that the democratic future of literature remains led by people.&lt;/p&gt;
    &lt;head rend="h4"&gt;Maintain Consumer Trust&lt;/head&gt;
    &lt;p&gt;Our unique stamp reassures readers that your books are genuinely human-written in a world where this is no longer a given. By providing proof of authenticity, you strengthen the bond between author and audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Maintain Consumer Trust&lt;/head&gt;
    &lt;p&gt;Our unique stamp reassures readers that your books are genuinely human-written in a world where this is no longer a given. By providing proof of authenticity, you strengthen the bond between author and audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Maintain Consumer Trust&lt;/head&gt;
    &lt;p&gt;Our unique stamp reassures readers that your books are genuinely human-written in a world where this is no longer a given. By providing proof of authenticity, you strengthen the bond between author and audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Maintain Consumer Trust&lt;/head&gt;
    &lt;p&gt;Our unique stamp reassures readers that your books are genuinely human-written in a world where this is no longer a given. By providing proof of authenticity, you strengthen the bond between author and audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Differentiate Your Brand&lt;/head&gt;
    &lt;p&gt;Stand out in a market becoming saturated with AI. Amidst a mass of processed content, our stamp signposts your books and brand as organic, and deepens sales to an increasingly committed audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Differentiate Your Brand&lt;/head&gt;
    &lt;p&gt;Stand out in a market becoming saturated with AI. Amidst a mass of processed content, our stamp signposts your books and brand as organic, and deepens sales to an increasingly committed audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Differentiate Your Brand&lt;/head&gt;
    &lt;p&gt;Stand out in a market becoming saturated with AI. Amidst a mass of processed content, our stamp signposts your books and brand as organic, and deepens sales to an increasingly committed audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Differentiate Your Brand&lt;/head&gt;
    &lt;p&gt;Stand out in a market becoming saturated with AI. Amidst a mass of processed content, our stamp signposts your books and brand as organic, and deepens sales to an increasingly committed audience.&lt;/p&gt;
    &lt;head rend="h4"&gt;Certify Strategically&lt;/head&gt;
    &lt;p&gt;Certify your whole organisation. Our process equips you with long-term safeguards, strengthens your AI controls, and shows the world youâre committed to protecting human creativity at scale.&lt;/p&gt;
    &lt;head rend="h4"&gt;Certify Strategically&lt;/head&gt;
    &lt;p&gt;Certify your whole organisation. Our process equips you with long-term safeguards, strengthens your AI controls, and shows the world youâre committed to protecting human creativity at scale.&lt;/p&gt;
    &lt;head rend="h4"&gt;Certify Strategically&lt;/head&gt;
    &lt;p&gt;Certify your whole organisation. Our process equips you with long-term safeguards, strengthens your AI controls, and shows the world youâre committed to protecting human creativity at scale.&lt;/p&gt;
    &lt;head rend="h4"&gt;Certify Strategically&lt;/head&gt;
    &lt;p&gt;Certify your whole organisation. Our process equips you with long-term safeguards, strengthens your AI controls, and shows the world youâre committed to protecting human creativity at scale.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Books By People Team&lt;/head&gt;
    &lt;p&gt;Advisor&lt;/p&gt;
    &lt;p&gt;James is a multiple-time agency founder and CEO of Rocket: a marketing and content business whose work has included projects with Harper Collins, Penguin, The Bookseller and more. He started the countryâs first influencer marketing agency and is often seen on conference panels as an expert on âBook-Tokâ.&lt;/p&gt;
    &lt;p&gt;Advisor&lt;/p&gt;
    &lt;p&gt;James is a multiple-time agency founder and CEO of Rocket: a marketing and content business whose work has included projects with Harper Collins, Penguin, The Bookseller and more. He started the countryâs first influencer marketing agency and is often seen on conference panels as an expert on âBook-Tokâ.&lt;/p&gt;
    &lt;p&gt;Advisor&lt;/p&gt;
    &lt;p&gt;James is a multiple-time agency founder and CEO of Rocket: a marketing and content business whose work has included projects with Harper Collins, Penguin, The Bookseller and more. He started the countryâs first influencer marketing agency and is often seen on conference panels as an expert on âBook-Tokâ.&lt;/p&gt;
    &lt;p&gt;Advisor&lt;/p&gt;
    &lt;p&gt;James is a multiple-time agency founder and CEO of Rocket: a marketing and content business whose work has included projects with Harper Collins, Penguin, The Bookseller and more. He started the countryâs first influencer marketing agency and is often seen on conference panels as an expert on âBook-Tokâ.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frequently Asked Questions&lt;/head&gt;
    &lt;p&gt;How much does the certification cost?&lt;/p&gt;
    &lt;p&gt;Applying for certification is completely free. If your publishing house is approved, an annual fee applies based on the number of titles you publish each year.&lt;/p&gt;
    &lt;p&gt;For full details on our pricing structure, please enquire through our application system.&lt;/p&gt;
    &lt;p&gt;Will we have to do a lot of extra work?&lt;/p&gt;
    &lt;p&gt;Can I use the Books By People stamp on all my titles?&lt;/p&gt;
    &lt;p&gt;How do you define Organic Literature vs AI-written?&lt;/p&gt;
    &lt;p&gt;How do I get in contact?&lt;/p&gt;
    &lt;p&gt;How much does the certification cost?&lt;/p&gt;
    &lt;p&gt;Applying for certification is completely free. If your publishing house is approved, an annual fee applies based on the number of titles you publish each year.&lt;/p&gt;
    &lt;p&gt;For full details on our pricing structure, please enquire through our application system.&lt;/p&gt;
    &lt;p&gt;Will we have to do a lot of extra work?&lt;/p&gt;
    &lt;p&gt;Can I use the Books By People stamp on all my titles?&lt;/p&gt;
    &lt;p&gt;How do you define Organic Literature vs AI-written?&lt;/p&gt;
    &lt;p&gt;How do I get in contact?&lt;/p&gt;
    &lt;p&gt;How much does the certification cost?&lt;/p&gt;
    &lt;p&gt;Applying for certification is completely free. If your publishing house is approved, an annual fee applies based on the number of titles you publish each year.&lt;/p&gt;
    &lt;p&gt;For full details on our pricing structure, please enquire through our application system.&lt;/p&gt;
    &lt;p&gt;Will we have to do a lot of extra work?&lt;/p&gt;
    &lt;p&gt;Can I use the Books By People stamp on all my titles?&lt;/p&gt;
    &lt;p&gt;How do you define Organic Literature vs AI-written?&lt;/p&gt;
    &lt;p&gt;How do I get in contact?&lt;/p&gt;
    &lt;p&gt;How much does the certification cost?&lt;/p&gt;
    &lt;p&gt;Applying for certification is completely free. If your publishing house is approved, an annual fee applies based on the number of titles you publish each year.&lt;/p&gt;
    &lt;p&gt;For full details on our pricing structure, please enquire through our application system.&lt;/p&gt;
    &lt;p&gt;Will we have to do a lot of extra work?&lt;/p&gt;
    &lt;p&gt;Can I use the Books By People stamp on all my titles?&lt;/p&gt;
    &lt;p&gt;How do you define Organic Literature vs AI-written?&lt;/p&gt;
    &lt;p&gt;How do I get in contact?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://booksbypeople.org/"/><published>2025-10-26T16:57:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45713738</id><title>Alzheimer's disrupts circadian rhythms of plaque-clearing brain cells</title><updated>2025-10-27T04:46:41.111231+00:00</updated><content>&lt;doc fingerprint="7e0030234a219fc7"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Alzheimer’s disrupts circadian rhythms of plaque-clearing brain cells&lt;/head&gt;&lt;p&gt;Mouse study shows how disease reprograms genes in specialized cells involved in amyloid removal&lt;/p&gt;Getty Images&lt;p&gt;Alzheimer’s disease is notorious for scrambling patients’ daily rhythms. Restless nights with little sleep and increased napping during the day are early indicators of disease onset, while sundowning, or confusion later in the day, is typical for later stages of the disease. These symptoms suggest a link between the progression of the disease and the circadian system — the body’s internal clock that controls our sleep and wake cycle — but scientists did not know the full nature of the connection.&lt;/p&gt;&lt;p&gt;Researchers from Washington University School of Medicine in St. Louis have now shown in mice that the circadian rhythms within particular brain cells are disrupted in Alzheimer’s disease in ways that change how and when hundreds of genes regulate key functions in the brain.&lt;/p&gt;&lt;p&gt;The findings, published October 23 in Nature Neuroscience, suggest that controlling or correcting these circadian rhythms could be a potential way to treat the disease.&lt;/p&gt;&lt;p&gt;“There are 82 genes that have been associated with Alzheimer’s disease risk, and we found that the circadian rhythm is controlling the activity of about half of those,” said Erik S. Musiek, MD, PhD, the Charlotte &amp;amp; Paul Hagemann Professor of Neurology at WashU Medicine, who led the study. In mice modeling Alzheimer’s disease, the typical daily activity patterns of those genes were altered. “Knowing that a lot of these Alzheimer’s genes are being regulated by the circadian rhythm gives us the opportunity to find ways to identify therapeutic treatments to manipulate them and prevent the progression of the disease.”&lt;/p&gt;&lt;p&gt;Musiek, the co-director of the Center on Biological Rhythms and Sleep (COBRAS) at WashU Medicine and a neurologist who specializes in aging and dementia, said that changes in sleep patterns are among the most frequent concerns reported to him by caregivers of Alzheimer’s patients. He and colleagues have previously shown that these changes begin in Alzheimer’s years before memory loss becomes apparent. He noted that in addition to creating burdens for caregivers and patients, disrupted sleep patterns generate biological and psychological stresses that accelerate the progression of the disease.&lt;/p&gt;&lt;p&gt;Breaking this feedback loop requires identifying its origins. The body’s circadian clock is thought to act on 20% of all genes in the human genome, controlling when they turn on or off to manage processes including digestion, the immune system and our sleep-wake cycle.&lt;/p&gt;&lt;p&gt;Musiek had previously identified a specific protein, YKL-40, that fluctuates across the circadian cycle and regulates normal levels of amyloid protein in the brain. He found that too much of YKL-40, which is linked to Alzheimer’s risk in humans, leads to amyloid build-up, an accumulation that is a hallmark of the neurodegenerative disease.&lt;/p&gt;&lt;head rend="h2"&gt;Amyloid disrupts rhythmic brain functions&lt;/head&gt;&lt;p&gt;The cyclic nature of Alzheimer’s symptoms suggests that there are more circadian-regulated proteins and their associated genes involved beyond YKL-40. So in this latest study, Musiek and his colleagues examined gene expression in the brains of mice with accumulations of amyloid proteins that mimic early stages of Alzheimer’s, as well as those of both healthy, young animals and aged mice without amyloid accumulations. The scientists collected tissue at 2-hour intervals over 24 hours and then performed an analysis of what genes were active during particular phases of the circadian cycle.&lt;/p&gt;&lt;p&gt;They found that the amyloid accumulations threw off the daily rhythms of hundreds of genes in brain cells known as microglia and astrocytes in ways that were different from what aging alone caused. Microglia are part of the brain’s immune response, clearing away toxic materials and dead cells, while astrocytes have roles in supporting and maintaining communication between neurons. The affected genes are generally involved in helping microglial cells break down waste material from the brain, including amyloid.&lt;/p&gt;&lt;p&gt;While the circadian disruption didn’t entirely shut down the genes in question, it turned an orderly sequence of events into a scattershot affair that could degrade the optimal synchronicity of brain cells’ functions, such as clearing amyloid.&lt;/p&gt;&lt;p&gt;In addition, the researchers found that the presence of amyloid appeared to create new rhythms in hundreds of genes that do not typically have a circadian pattern of activity. Many of the genes are involved in the brain’s inflammatory response to infection or imbalances such as amyloid plaque build-up.&lt;/p&gt;&lt;p&gt;Musiek said that altogether the findings point to exploring therapies that target circadian cycles in microglia and astrocytes to support healthy brain function.&lt;/p&gt;&lt;p&gt;“We have a lot of things we still need to understand, but where the rubber meets the road is trying to manipulate the clock in some way, make it stronger, make it weaker or turn it off in certain cell types,” he said. “Ultimately, we hope to learn how to optimize the circadian system to prevent amyloid accumulation and other aspects of Alzheimer’s disease.”&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://medicine.washu.edu/news/alzheimers-disrupts-circadian-rhythms-of-plaque-clearing-brain-cells/"/><published>2025-10-26T17:40:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45713959</id><title>A definition of AGI</title><updated>2025-10-27T04:46:40.901863+00:00</updated><content>&lt;doc fingerprint="e99d252bccd7a6af"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Artificial Intelligence&lt;/head&gt;&lt;p&gt; [Submitted on 21 Oct 2025 (v1), last revised 23 Oct 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:A Definition of AGI&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:The lack of a concrete definition for Artificial General Intelligence (AGI) obscures the gap between today's specialized AI and human-level cognition. This paper introduces a quantifiable framework to address this, defining AGI as matching the cognitive versatility and proficiency of a well-educated adult. To operationalize this, we ground our methodology in Cattell-Horn-Carroll theory, the most empirically validated model of human cognition. The framework dissects general intelligence into ten core cognitive domains-including reasoning, memory, and perception-and adapts established human psychometric batteries to evaluate AI systems. Application of this framework reveals a highly "jagged" cognitive profile in contemporary models. While proficient in knowledge-intensive domains, current AI systems have critical deficits in foundational cognitive machinery, particularly long-term memory storage. The resulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 57%) concretely quantify both rapid progress and the substantial gap remaining before AGI.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Long Phan [view email]&lt;p&gt;[v1] Tue, 21 Oct 2025 01:28:35 UTC (20,673 KB)&lt;/p&gt;&lt;p&gt;[v2] Thu, 23 Oct 2025 18:00:45 UTC (20,299 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.18212"/><published>2025-10-26T18:09:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45715055</id><title>Show HN: MyraOS – My 32-bit operating system in C and ASM (Hack Club project)</title><updated>2025-10-27T04:46:40.566427+00:00</updated><content>&lt;doc fingerprint="a2641ac90aa6e498"&gt;
  &lt;main&gt;
    &lt;p&gt;A x86 Unix-like OS made entirely from scratch.&lt;/p&gt;
    &lt;p&gt;Features&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Protected mode (GDT/IDT, ISRs/IRQs)&lt;/item&gt;
      &lt;item&gt;Paging and virtual memory&lt;/item&gt;
      &lt;item&gt;Memory management&lt;/item&gt;
      &lt;item&gt;Heap and dynamic memory&lt;/item&gt;
      &lt;item&gt;User-mode (ring 3) and kernel mode (ring 0)&lt;/item&gt;
      &lt;item&gt;Processes and scheduling&lt;/item&gt;
      &lt;item&gt;Drivers (PIT, RTC, Keyboard, Mouse, Framebuffer, PATA)&lt;/item&gt;
      &lt;item&gt;ext2 filesystem&lt;/item&gt;
      &lt;item&gt;UI compositor with window widgets, labels, icons, buttons, and even a custom-made font&lt;/item&gt;
      &lt;item&gt;ELF loader, which gives you the ability to run real apps&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All these features let you run real games, just like Doom, giving the preloaded Doom port in MyraOS ready to be played!&lt;lb/&gt; So, this isn't just a toy OS or a look-alike, it's a real OS that can run on real devices&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the latest release from the release tab in GitHub&lt;/item&gt;
      &lt;item&gt;Download QEMU - an open-source machine emulator and virtualizer&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;After you get the latest release, you can run this on your platform:&lt;/p&gt;
    &lt;p&gt;Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen (if you are like me and want it to look real)&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -full-screen
&lt;/code&gt;
    &lt;p&gt;Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -display gtk,zoom-to-fit=on -full-screen
&lt;/code&gt;
    &lt;p&gt;Here, Linux/macOS or even WSL are better; use it as a last resort:&lt;lb/&gt; Normal&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024
&lt;/code&gt;
    &lt;p&gt;Fullscreen&lt;/p&gt;
    &lt;code&gt;qemu-system-i386 -cdrom MyraOS.iso -drive file=fs.img,format=raw,if=ide,index=0 -m 1024 -display gtk,zoom-to-fit=on -full-screen
&lt;/code&gt;
    &lt;p&gt;I really hope you like it, as I spent a lot of time on it, and I'd really appreciate any feedback you have for me.&lt;lb/&gt; If you have anything, from feature requests to feedback, or even if you want to talk, email me here: &lt;code&gt;dvirm.biton@gmail.com&lt;/code&gt;.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/dvir-biton/MyraOS"/><published>2025-10-26T20:43:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45715204</id><title>We Saved $500k per Year by Rolling Our Own "S3"</title><updated>2025-10-27T04:46:39.256632+00:00</updated><content>&lt;doc fingerprint="2559ed5308a855e9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How We Saved $500,000 Per Year by Rolling Our Own “S3”&lt;/head&gt;
    &lt;head rend="h2"&gt;tl;dr&lt;/head&gt;
    &lt;p&gt;We used S3 as a landing zone for Nanit’s video processing pipeline (baby sleep-state inference), but at thousands of uploads/second, S3’s PutObject request fees dominated costs. Worse, S3’s auto-cleanup (Lifecycle rules) has a 1-day minimum; we paid for 24 hours of storage on objects processed in ~2 seconds. We built N3, a Rust-based in-memory landing zone that eliminates both issues, using S3 only as an overflow buffer.&lt;/p&gt;
    &lt;p&gt;Result: meaningful cost reduction (~$0.5M/year).&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 1: Background&lt;/head&gt;
    &lt;head rend="h2"&gt;High-Level Overview of Our Video Processing Pipeline&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cameras record video chunks (configurable duration).&lt;/item&gt;
      &lt;item&gt;For each chunk, the camera requests an S3 presigned URL from the Camera Service and uploads directly to S3.&lt;/item&gt;
      &lt;item&gt;An AWS Lambda posts the object key to an SQS FIFO queue (sharded by baby_uid).&lt;/item&gt;
      &lt;item&gt;Video processing pods consume from SQS, download from S3, and produce sleep states.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a deeper dive, see this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;What We Like About This Setup&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Landing on S3 + queuing to SQS decouples camera uploads from video processing. During maintenance or temporary downtime, we don’t lose videos; if queues grow, we scale processing.&lt;/item&gt;
      &lt;item&gt;With S3, we don’t manage availability or durability.&lt;/item&gt;
      &lt;item&gt;SQS FIFO + group IDs preserve per-baby ordering, keeping processing nodes mostly stateless (coordination happens in SQS).&lt;/item&gt;
      &lt;item&gt;S3 Lifecycle rules offload GC: objects expire after one day, so we don’t track processed videos.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Why We Changed&lt;/head&gt;
    &lt;p&gt;PutObject costs dominated. Our objects are short-lived: videos land for seconds, then get processed. At our scale (thousands of uploads/s), the per-object request charge was the largest cost driver. Increasing chunking frequency (i.e., sending more, smaller chunks) to cut latency raises costs linearly, because each additional chunk is another PutObject request.&lt;/p&gt;
    &lt;p&gt;Storage was a secondary tax. Even when processing finished in ~2 s, Lifecycle deletes meant paying for ~24 h of storage.&lt;/p&gt;
    &lt;p&gt;We needed a design that kept reliability and strict ordering while avoiding per-object costs on the happy path and minimizing “pay-to-wait” storage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 2: Planning&lt;/head&gt;
    &lt;head rend="h2"&gt;Guiding Principles&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Simplicity through architecture: Eliminate complexity at the design level, not through clever implementations.&lt;/item&gt;
      &lt;item&gt;Correctness: A true drop-in replacement that’s transparent to the rest of the pipeline.&lt;/item&gt;
      &lt;item&gt;Optimize for the happy path: Design for the normal case and use S3 as a safety net for edge cases. Our processing algorithms are robust to occasional gaps, so we can prioritize simplicity over building complex guarantees; S3 provides reliability when needed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Design Drivers&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Short-lived objects: segments live on the landing zone for seconds, not hours.&lt;/item&gt;
      &lt;item&gt;Ordering: strict per-baby sequencing (no processing newer before older).&lt;/item&gt;
      &lt;item&gt;Throughput: thousands of uploads/second; 2–6 MB per segment.&lt;/item&gt;
      &lt;item&gt;Client limits: cameras have limited retries; don’t assume retransmits.&lt;/item&gt;
      &lt;item&gt;Operations: tolerate multi-million-item backlogs during maintenance/scale-ups.&lt;/item&gt;
      &lt;item&gt;No firmware changes: must work with existing cameras.&lt;/item&gt;
      &lt;item&gt;Loss tolerance: very small gaps are acceptable; algorithms mask them.&lt;/item&gt;
      &lt;item&gt;Cost: avoid per-object S3 costs on the happy path; minimize “pay-to-wait” storage.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Design at a Glance (N3 Happy Path + S3 Overflow)&lt;/head&gt;
    &lt;head rend="h3"&gt;The Architecture&lt;/head&gt;
    &lt;p&gt;N3 is a custom landing zone that holds videos in memory just long enough for processing to drain them (~2 seconds). S3 is used only when N3 can’t handle the load.&lt;/p&gt;
    &lt;p&gt;Two components:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;N3-Proxy (stateless, dual interfaces): &lt;lb/&gt;- External (Internet-facing): Accepts camera uploads via presigned URLs.&lt;lb/&gt;- Internal (private): Issues presigned URLs to Camera Service.&lt;/item&gt;
      &lt;item&gt;N3-Storage (stateful, internal-only): Stores uploaded segments in RAM and enqueues SQS with a pod-addressable download URL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Video processing pods consume from SQS FIFO and download from whichever storage the URL points to: N3 or S3.&lt;/p&gt;
    &lt;p&gt;Normal Flow (Happy Path)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Camera requests an upload URL from Camera Service.&lt;/item&gt;
      &lt;item&gt;Camera Service calls N3-Proxy’s internal API for a presigned URL.&lt;/item&gt;
      &lt;item&gt;Camera uploads video to N3-Proxy’s external endpoint.&lt;/item&gt;
      &lt;item&gt;N3-Proxy forwards to N3-Storage.&lt;/item&gt;
      &lt;item&gt;N3-Storage holds video in memory and enqueues to SQS with a download URL pointing to itself.&lt;/item&gt;
      &lt;item&gt;Processing pod downloads from N3-Storage and processes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Two-Tier Fallback&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tier 1: Proxy-level fallback (per-request): &lt;lb/&gt;If N3-Storage can’t accept an upload whether from memory pressure, processing backlog, or pod failure N3-Proxy uploads to S3 on the camera’s behalf.&lt;lb/&gt;(Camera got a presigned N3 URL before the failure was detected)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tier 2: Cluster-level reroute (all traffic): &lt;lb/&gt;If N3-Proxy or N3-Storage is unhealthy, Camera Service stops issuing N3 URLs and returns S3 presigned URLs directly.&lt;lb/&gt;(All traffic flows to S3 until N3 recovers.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why Two Components?&lt;/p&gt;
    &lt;p&gt;We split N3-Proxy and N3-Storage because they have different requirements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Blast radius: If storage crashes, proxy can still route to S3. If proxy crashes, only that node’s traffic is affected; not the entire storage cluster.&lt;/item&gt;
      &lt;item&gt;Resource profiles: Proxy is CPU/network-heavy (TLS termination). Storage is memory-heavy (holding videos). Different instance types and scaling requirments.&lt;/item&gt;
      &lt;item&gt;Security: Storage never touches the Internet.&lt;/item&gt;
      &lt;item&gt;Rollout safety: We can update proxy (stateless) without touching storage (holding active data).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Validating the Design&lt;/head&gt;
    &lt;p&gt;The architecture made sense on paper, but we had critical unknowns:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Capacity &amp;amp; sizing: real upload durations across client networks; how much compute and upload buffer size we need?&lt;/item&gt;
      &lt;item&gt;Storage model: can we keep everything in RAM, or do we need disks?&lt;/item&gt;
      &lt;item&gt;Resilience: how to load balance cheaply and handle failed nodes?&lt;/item&gt;
      &lt;item&gt;Operational policy: GC needs, retry expectations, and whether delete-on-GET is sufficient.&lt;/item&gt;
      &lt;item&gt;Unknown unknowns: what edge cases would emerge when idea meet reality?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To de-risk decisions, we ran two tracks during planning:&lt;/p&gt;
    &lt;head rend="h2"&gt;Approach 1: Synthetic Stress Tests&lt;/head&gt;
    &lt;p&gt;We built a load generator to push the system to its limits: varying concurrency, slow clients, sustained load, and processing downtime.&lt;/p&gt;
    &lt;p&gt;Goal: Find breaking points. Surface bottlenecks we hadn’t anticipated. Get deterministic baselines for capacity planning.&lt;/p&gt;
    &lt;head rend="h2"&gt;Approach 2: Production PoC (Mirror Mode)&lt;/head&gt;
    &lt;p&gt;Synthetic tests can’t replicate real camera behavior: flaky Wi-Fi, diverse firmware versions, unpredictable network conditions. We needed in-the-wild data without risking production.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mirror mode: n3-proxy wrote to S3 first (preserving prod), then also to a PoC N3-Storage wired to a canary SQS + video processors.&lt;/item&gt;
      &lt;item&gt;Targeted cohorts: by firmware version / Baby-UID lists&lt;/item&gt;
      &lt;item&gt;Data parity: compared sleep states PoC vs. production; investigated any diffs.&lt;/item&gt;
      &lt;item&gt;Observability: per-path dashboards (N3 vs. S3), queue depth, latency/RPS, error budgets, egress breakdown.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Feature flags (via Unleash) were critical. We could flip cohorts on/off in real-time; no deployments; letting us test narrow slices (older firmware, weak Wi-Fi cameras) and revert instantly if issues appeared.&lt;/p&gt;
    &lt;head rend="h2"&gt;What We Discovered&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Bottlenecks: TLS termination consumed most CPU, and AWS burstable networking throttled us after credits expired.&lt;/item&gt;
      &lt;item&gt;Memory-only storage was viable. Real upload-time distributions and concurrency showed we could fit the working set in RAM with safe headroom; disks not required.&lt;/item&gt;
      &lt;item&gt;Delete-on-GET is safe. We did not observe re-downloads; retries happen downstream in the processor, so N3 doesn’t need to support download retries.&lt;/item&gt;
      &lt;item&gt;We need lightweight GC. Some segments get skipped by processing and would never be downloaded/deleted; added a TTL GC pass to clean stragglers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These findings shaped our implementation: memory-backed storage, network- optimized instances with TLS optimization, and delete-on-GET with TTL GC for stragglers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 3: Implementation Details&lt;/head&gt;
    &lt;head rend="h2"&gt;DNS Load Balancing&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;n3-proxy&lt;/code&gt; is a DaemonSet on dedicated nodes, one pod per node to maximize network and CPU resources for TLS termination. We need node-level load balancing and graceful restarts.&lt;/p&gt;
    &lt;p&gt;An AWS Network Load Balancer would work, but at our throughput (thousands of uploads/second, sustained multi-GB/s), the combination of fixed costs plus per-GB processed fees becomes expensive. Instead, we use DNS-based load balancing via Route53 multi-value A records, which is significantly cheaper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For each node we create a MultiValue record that contains a single IP.&lt;/item&gt;
      &lt;item&gt;Each record has a health check that hits an external readiness endpoint.&lt;/item&gt;
      &lt;item&gt;A records use a short 30-second TTL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This gives us:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If a node fails, it’s taken out of the pool and cameras stop uploading to it.&lt;/item&gt;
      &lt;item&gt;Because the external readiness endpoint is also used as the Kubernetes readiness probe, marking a pod Not Ready during rollouts automatically removes it from DNS.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Rollout process&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;n3-proxy&lt;/code&gt; pods have a graceful shutdown mechanism:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;On SIGTERM, the pod enters paused mode.&lt;/item&gt;
      &lt;item&gt;Readiness becomes Not Ready, but uploads are still accepted.&lt;/item&gt;
      &lt;item&gt;Wait 2× DNS TTL (e.g., 60s) so the DNS health check removes the node and camera DNS caches update.&lt;/item&gt;
      &lt;item&gt;Drain active connections, then restart.&lt;/item&gt;
      &lt;item&gt;On startup, wait for health checks to pass and for client DNS TTLs to expire before rolling to the next pod (lets the node rejoin the pool).&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Networking Limitations&lt;/head&gt;
    &lt;p&gt;When doing initial benchmarks to size the cluster, we saw a surprising pattern: runs started near ~1k RPS, then dropped to ~70 RPS after ~1 minute. Restarting didn’t help; after waiting and rerunning, we briefly saw ~1k RPS again.&lt;/p&gt;
    &lt;p&gt;It turns out that when AWS says an instance can do “Up to 12.5 Gbps”, that’s burstable networking backed by credits; when you’re below the baseline, you accrue credits and can burst for short periods.&lt;/p&gt;
    &lt;p&gt;Baseline depends on instance family and vCPUs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Non–network-optimized: ~0.375 Gbps/vCPU&lt;/item&gt;
      &lt;item&gt;Network-optimized (suffix “n”): ~3.125 Gbps/vCPU&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And for instances that don’t say “Up to,” you get the stated Gbps continuously.&lt;/p&gt;
    &lt;p&gt;Conclusion: our workload is steady, so bursts don’t help. We moved to network optimized c8gn.4xlarge nodes, which provide 50 Gbps each, giving us the sustained throughput we need.&lt;/p&gt;
    &lt;head rend="h2"&gt;HTTPS, rustls, and Graviton4&lt;/head&gt;
    &lt;p&gt;Initially, for simplicity, we used a &lt;code&gt;stunnel&lt;/code&gt; sidecar for HTTPS termination, but early stress testing showed HTTPS was the main CPU consumer and primary bottleneck. We made three changes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Moved from &lt;code&gt;stunnel&lt;/code&gt;to native rustls.&lt;/item&gt;
      &lt;item&gt;Upgraded from Graviton3 to Graviton4 instances.&lt;/item&gt;
      &lt;item&gt;Compiled &lt;code&gt;n3-proxy&lt;/code&gt;with target-cpu and crypto features enabled.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;[profile.release]&lt;lb/&gt;opt-level = 3&lt;lb/&gt;lto = "fat"&lt;lb/&gt;codegen-units = 1&lt;lb/&gt;split-debuginfo = "off"&lt;lb/&gt;debug = false&lt;lb/&gt;panic = "abort"&lt;lb/&gt;overflow-checks = false&lt;lb/&gt;&lt;lb/&gt;[target.aarch64-unknown-linux-gnu]&lt;lb/&gt;rustflags = [&lt;lb/&gt;    "-C", "target-cpu=neoverse-v2",&lt;lb/&gt;    "-C", "target-feature=+sve2,+sve2-aes,+sve2-sha3,+sve2-sm4,+sve2-bitperm,+crypto"&lt;lb/&gt;]&lt;/code&gt;
    &lt;p&gt;These changes yielded ~30% higher RPS at the same cost.&lt;/p&gt;
    &lt;head rend="h2"&gt;Outgoing Traffic Costs&lt;/head&gt;
    &lt;p&gt;We assumed that since we only receive uploads (ingress is free) and don’t send payloads to clients, egress would be negligible. Post-launch, we saw non-trivial outbound traffic.&lt;/p&gt;
    &lt;head rend="h3"&gt;TLS handshakes&lt;/head&gt;
    &lt;p&gt;Each upload opens a new TLS connection, so a full handshake runs and sends ~7 KB of certificates. In theory we could reduce this with smaller (e.g., ECDSA) certs, session resumption/tickets, or long-lived connections; but given our constraint of not changing camera behavior, we accept this overhead for now.&lt;/p&gt;
    &lt;head rend="h3"&gt;ACKs&lt;/head&gt;
    &lt;p&gt;Surprisingly, TLS handshakes were only a small part of the outbound bytes. A &lt;code&gt;tcpdump&lt;/code&gt; showed many &lt;code&gt;66-byte&lt;/code&gt; ACKs:&lt;/p&gt;
    &lt;code&gt;tshark -r n3-3.pcap \&lt;lb/&gt;  -Y 'tcp.srcport==32443 &amp;amp;&amp;amp; !(tcp.analysis.retransmission || tcp.analysis.fast_retransmission)' \&lt;lb/&gt;  -T fields -e tcp.len -e frame.len \&lt;lb/&gt;| awk '{&lt;lb/&gt;  total += $2&lt;lb/&gt;  if ($1 == 0) { ack += $2 } else { data_frames += $2; payload += $1 }&lt;lb/&gt;}&lt;lb/&gt;END {&lt;lb/&gt;  printf "total_bytes=%d\nack_frame_bytes=%d (%.1f%%)\ndata_frame_bytes=%d (%.1f%%)\n",&lt;lb/&gt;         total, ack, 100*ack/total, data_frames, 100*data_frames/total&lt;lb/&gt;  printf "tcp_payload_bytes=%d (of data frames)\n", payload&lt;lb/&gt;}'&lt;/code&gt;
    &lt;p&gt;This was a short traffic capture:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;total_bytes = 37,014,432&lt;/item&gt;
      &lt;item&gt;ack_frame_bytes = 31,258,550 (84.4%)&lt;/item&gt;
      &lt;item&gt;data_frame_bytes = 5,755,882 (15.6%)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;~85% of outbound bytes were ACK frames.&lt;/p&gt;
    &lt;p&gt;With ~1500-byte MTUs and frequent ACKs, overhead adds up. While we can’t easily reduce the number of ACKs, we can make each ACK smaller by removing TCP timestamps (−12 bytes/ACK):&lt;/p&gt;
    &lt;code&gt;sysctl -w net.ipv4.tcp_timestamps=0&lt;/code&gt;
    &lt;p&gt;Kubernetes init-container:&lt;/p&gt;
    &lt;code&gt;spec:&lt;lb/&gt;  initContainers:&lt;lb/&gt;  - name: set-sysctl&lt;lb/&gt;    image: alpine:3.20&lt;lb/&gt;    securityContext: { privileged: true }&lt;lb/&gt;    command: ["sh","-c","sysctl -w net.ipv4.tcp_timestamps=0"]&lt;lb/&gt;  containers:&lt;lb/&gt;  - name: your-app&lt;lb/&gt;    image: ...&lt;/code&gt;
    &lt;p&gt;This isn’t without risk: with high byte counts on the same socket, sequence numbers can wrap and delayed packets may be mis-merged, causing corruption.&lt;lb/&gt;Mitigations: (1) new socket per upload; (2) recycle &lt;code&gt;n3-proxy&lt;/code&gt; ↔ &lt;code&gt;n3-storage&lt;/code&gt; sockets after ~1 GB sent.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory Leak&lt;/head&gt;
    &lt;p&gt;After the initial launch, we saw steady n3-proxy memory growth. Even after traffic stopped, the process returned to an ever-higher baseline — so it wasn’t just the OS holding freed pages.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;jemalloc&lt;/code&gt; stats showed referenced memory constantly increasing.&lt;/p&gt;
    &lt;p&gt;Using rust-jemalloc-pprof we profiled memory in production and identified growth in per-connection &lt;code&gt;hyper&lt;/code&gt; &lt;code&gt;BytesMut&lt;/code&gt; buffers.&lt;/p&gt;
    &lt;p&gt;Since we handle large uploads over variable networks, some client connections stalled mid-transfer and never cleaned up. The per-connection &lt;code&gt;hyper&lt;/code&gt; buffers (&lt;code&gt;BytesMut&lt;/code&gt;) stuck around and memory kept climbing. When we Terminated connections idle &amp;gt;10 minutes, memory dropped by ~1 GB immediately; confirming the leak was from dangling sockets.&lt;/p&gt;
    &lt;p&gt;Fix: make sockets short-lived and enforce time limits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable keep-alive: close the connection immediately after each upload completes.&lt;/item&gt;
      &lt;item&gt;Tighten timeouts: set header/socket timeouts so stalled uploads are terminated and buffers are freed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;fn make_listener(addr: &amp;amp;str) -&amp;gt; std::io::Result&amp;lt;std::net::TcpListener&amp;gt; {&lt;lb/&gt;    let addr: SocketAddr = addr.parse().unwrap();&lt;lb/&gt;    let sock = Socket::new(Domain::for_address(addr), Type::STREAM, Some(Protocol::TCP))?;&lt;lb/&gt;    sock.bind(&amp;amp;addr.into())?;&lt;lb/&gt;&lt;lb/&gt;    let ka = TcpKeepalive::new()&lt;lb/&gt;        .with_time(Duration::from_secs(60))&lt;lb/&gt;        .with_interval(Duration::from_secs(15))&lt;lb/&gt;        .set_reuse_port(true)&lt;lb/&gt;        .with_retries(4);&lt;lb/&gt;    sock.set_tcp_keepalive(&amp;amp;ka)?;&lt;lb/&gt;    sock.listen(4096)?;&lt;lb/&gt;    sock.set_nonblocking(true)?; // NOTE: required before handing to Tokio&lt;lb/&gt;&lt;lb/&gt;    Ok(sock.into())&lt;lb/&gt;}&lt;lb/&gt;&lt;lb/&gt;pub fn create_server_external(&lt;lb/&gt;    addr_external: &amp;amp;str,&lt;lb/&gt;    rustls_config: RustlsConfig,&lt;lb/&gt;) -&amp;gt; Result&amp;lt;Server&amp;lt;RustlsAcceptor&amp;gt;, MainError&amp;gt; {&lt;lb/&gt;    let listener_external = make_listener(addr_external).map_err(|error| MainError::BindError {&lt;lb/&gt;        addr: addr_external.to_string(),&lt;lb/&gt;        error,&lt;lb/&gt;    })?;&lt;lb/&gt;&lt;lb/&gt;    let mut ext = axum_server::from_tcp_rustls(listener_external, rustls_config);&lt;lb/&gt;    ext.http_builder()&lt;lb/&gt;        .http1()&lt;lb/&gt;        .timer(TokioTimer::new())&lt;lb/&gt;        .max_buf_size(128 * 1024)&lt;lb/&gt;        .header_read_timeout(Some(Duration::from_secs(60)))&lt;lb/&gt;        .keep_alive(false);&lt;lb/&gt;&lt;lb/&gt;    Ok(ext)&lt;lb/&gt;}&lt;/code&gt;
    &lt;head rend="h2"&gt;Storage&lt;/head&gt;
    &lt;p&gt;We started with the simplest path: in-memory storage. It avoids I/O tuning and lets us use straightforward data structures.&lt;/p&gt;
    &lt;code&gt;type Store = Arc&amp;lt;DashMap&amp;lt;Ulid, Bytes&amp;gt;&amp;gt;;&lt;lb/&gt;&lt;lb/&gt;pub struct VideoStore {&lt;lb/&gt;    videos: Store,&lt;lb/&gt;    bytes_used: AtomicUsize,&lt;lb/&gt;    control: Arc&amp;lt;Control&amp;gt;,&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;Each video upload increments &lt;code&gt;bytes_used&lt;/code&gt; ; each download deletes the video and decrements it.&lt;/p&gt;
    &lt;p&gt;Above ~80% capacity, we start rejecting uploads to avoid OOM and signal n3-proxy to stop signing upload URLs.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;control&lt;/code&gt; handle lets us manually pause uploads and garbage collection.&lt;/p&gt;
    &lt;head rend="h2"&gt;Graceful Restart&lt;/head&gt;
    &lt;p&gt;With memory-only storage, restarts must not drop in-flight data. Our graceful restart process:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;SIGTERM&lt;/code&gt;to a pod (StatefulSet rolls one pod at a time).&lt;/item&gt;
      &lt;item&gt;Pod becomes Not Ready and leaves the Service (no new uploads).&lt;/item&gt;
      &lt;item&gt;It continues serving downloads for already-uploaded videos.&lt;/item&gt;
      &lt;item&gt;Once downloads quiesce (no recent reads → processing drained),&lt;/item&gt;
      &lt;item&gt;Wait for any open requests to complete&lt;/item&gt;
      &lt;item&gt;Restart and move to the next pod.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Under normal operation pods drain in seconds.&lt;/p&gt;
    &lt;head rend="h2"&gt;GC&lt;/head&gt;
    &lt;p&gt;We use two cleanup mechanisms:&lt;/p&gt;
    &lt;head rend="h3"&gt;Delete on download&lt;/head&gt;
    &lt;p&gt;We delete videos immediately after download. In the PoC, we saw zero re-downloads; video processors retry internally. This eliminates the need to hold data or track “processed” state.&lt;/p&gt;
    &lt;head rend="h3"&gt;TTL GC for stragglers&lt;/head&gt;
    &lt;p&gt;Deleting on download doesn’t cover segments skipped by the processor (never downloaded → never deleted). We added a lightweight TTL GC: periodically scan the in-memory DashMap and remove entries older than a configurable threshold (e.g., a few hours).&lt;/p&gt;
    &lt;head rend="h3"&gt;Maintenance mode&lt;/head&gt;
    &lt;p&gt;During planned processing downtime, we can temporarily pause GC via an internal control so videos aren’t deleted while consumption is stopped.&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 4: Conclusion&lt;/head&gt;
    &lt;p&gt;By using S3 as a fallback buffer and N3 as the primary landing zone, we eliminated ~$0.5M/year in costs while keeping the system simple and reliable.&lt;/p&gt;
    &lt;p&gt;The key insight: most “build vs. buy” decisions focus on features, but at scale, economics shift the calculus. For short-lived objects (~2 seconds in normal operation), we don’t need replication or sophisticated durability; simple in-memory storage works. But when processing lags or maintenance extends object lifetime, we need S3’s reliability guarantees. We get the best of both worlds: N3 handles the happy path efficiently, while S3 provides durability when objects need to live longer. If N3 has any issues; memory pressure, pod crashes, or cluster problems; uploads seamlessly fail over to S3.&lt;/p&gt;
    &lt;p&gt;What Made This Work&lt;/p&gt;
    &lt;p&gt;Defining the problem clearly upfront: constraints, assumptions, and boundaries prevented scope creep. Validating early with a mirror-mode PoC let us discover bottlenecks (TLS, network throttling) and validate assumptions before committing. This prevented overengineering and backtracking.&lt;/p&gt;
    &lt;p&gt;When Should You Build Something Like This?&lt;/p&gt;
    &lt;p&gt;Consider custom infrastructure when you have both: sufficient scale for meaningful cost savings, and specific constraints that enable a simple solution. The engineering effort to build and maintain your system must be less than the infrastructure costs it eliminates. In our case, specific requirements (ephemeral storage, loss tolerance, S3 fallback) let us build something simple enough that maintenance costs stay low. Without both factors, stick with managed services.&lt;/p&gt;
    &lt;p&gt;Would we do it again? Yes. The system has been running reliably in production, and the fallback design lets us avoid complexity without sacrificing reliability.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://engineering.nanit.com/how-we-saved-500-000-per-year-by-rolling-our-own-s3-6caec1ee1143"/><published>2025-10-26T21:05:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45715726</id><title>Poison, Poison Everywhere</title><updated>2025-10-27T04:46:39.183467+00:00</updated><content/><link href="https://loeber.substack.com/p/29-poison-poison-everywhere"/><published>2025-10-26T22:36:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45715752</id><title>Show HN: Helium Browser for Android with extensions support, based on Vanadium</title><updated>2025-10-27T04:46:38.735008+00:00</updated><content>&lt;doc fingerprint="9eb4893fee94f46c"&gt;
  &lt;main&gt;
    &lt;p&gt;An experimental Chromium-based web browser for Android with extensions support, based on&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Helium by imput, as well as&lt;/item&gt;
      &lt;item&gt;Vanadium by GrapheneOS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Navigate to Chrome Web Store, then enable Desktop site by selecting the menu button ⋮ in the top right corner and ensure the option is checked. Select Okay and proceed as normal if prompted with:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The Chrome Web Store is only available on desktop.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Once you select Add to Chrome, the extension will be installed in the background until the button changes into Remove from Chrome.&lt;/p&gt;
    &lt;p&gt;To view and access the debug URLs, use &lt;code&gt;chrome://chrome-urls&lt;/code&gt;. For Experiments, use &lt;code&gt;chrome://flags&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Consistent with both Helium and Vanadium, the option is available by selecting the menu button ⋮ in the top right corner, then Settings, Privacy and security, then under Privacy, WebRTC IP handling policy. If you experience issues with WebRTC due to the IPs being shielded by default (e.g. Discord Voice), you may try to change it to Default public interface only, or Default.&lt;/p&gt;
    &lt;p&gt;Warning&lt;/p&gt;
    &lt;p&gt;All builds are experimental, so unexpected issues may occur. Helium Browser for Android only attempts to improve security and privacy where possible. For better protection on Android, you should instead use GrapheneOS with Vanadium, which additionally integrates patches into Android System WebView and provides significant kernel and memory management hardening on the OS level.&lt;/p&gt;
    &lt;code&gt;---
config:
  layout: dagre
---
flowchart TD
 subgraph s1["Helium"]
        n5["Generic Patches&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;patches/series&amp;lt;/small&amp;gt;"]
        n6["Name Substitution&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;utils/name_substitution.py&amp;lt;/small&amp;gt;"]
        n7["Version Patch&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;{*version,revision}.txt&amp;lt;/small&amp;gt;"]
        n8["Resource Patch&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;resources/*resources.txt&amp;lt;/small&amp;gt;"]
  end
 subgraph s2["Vanadium"]
        n9["Generic Patches&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;patches/*.patch&amp;lt;/small&amp;gt;"]
  end
 subgraph s3["Helium Browser for Android"]
        n11["GN Build Configuration&amp;lt;small&amp;gt;&amp;lt;br&amp;gt;args.gn&amp;lt;/small&amp;gt;"]
        n12["Signed Release"]
  end
    n1["Chromium"] --&amp;gt; s1 &amp;amp; s2
    n5 --&amp;gt; n6
    n6 --&amp;gt; n7
    n7 --&amp;gt; n8
    s1 --&amp;gt; s3
    s2 --&amp;gt; s3
    n11 --&amp;gt; n12
    n5@{ shape: subproc}
    n6@{ shape: subproc}
    n7@{ shape: subproc}
    n8@{ shape: subproc}
    n9@{ shape: subproc}
    n11@{ shape: subproc}
    n12@{ shape: subproc}
    n1@{ shape: rounded}
    classDef Aqua stroke-width:1px, stroke-dasharray:none, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A
    style n5 stroke:#FF6D00
    style n8 stroke:#FF6D00
&lt;/code&gt;
    &lt;p&gt;The full build aims to be consistent with Helium, which means additional patches are necessary before all features can be ported over. All Vanadium patches are applied by default. Further patches are underway.&lt;/p&gt;
    &lt;p&gt;This repository provides the build script to compile on the latest Ubuntu, and may also work with other Linux distributions.&lt;/p&gt;
    &lt;p&gt;To build these releases yourself via CI (e.g. GitHub Actions), fork this repository. Supply your &lt;code&gt;base64&lt;/code&gt; encoded &lt;code&gt;keystore.jks&lt;/code&gt; and &lt;code&gt;local.properties&lt;/code&gt; (containing your &lt;code&gt;keyAlias&lt;/code&gt;, &lt;code&gt;keyPassword&lt;/code&gt; and &lt;code&gt;storePassword&lt;/code&gt;) to Repository secrets under Settings &amp;gt; Secrets and variables &amp;gt; Actions. To generate a release, go to Actions, select Build, and select Run workflow. Under Runner, you can either use a GitHub-hosted runner by entering &lt;code&gt;ubuntu-latest&lt;/code&gt;, or &lt;code&gt;self-hosted&lt;/code&gt; for your own hardware.&lt;/p&gt;
    &lt;p&gt;This project would not have been possible without the huge community contributions from Helium, Vanadium, as well as ungoogled-chromium and various other upstream projects.&lt;/p&gt;
    &lt;p&gt;All credit goes to the original authors and contributors. This project is named to reflect support for Helium's naming in a recent controversy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jqssun/android-helium-browser"/><published>2025-10-26T22:41:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45715837</id><title>Microsoft 365 Copilot – Arbitrary Data Exfiltration via Mermaid Diagrams</title><updated>2025-10-27T04:46:38.577426+00:00</updated><content/><link href="https://www.adamlogue.com/microsoft-365-copilot-arbitrary-data-exfiltration-via-mermaid-diagrams-fixed/"/><published>2025-10-26T22:58:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45715873</id><title>Are-we-fast-yet implementations in Oberon, C++, C, Pascal, Micron and Luon</title><updated>2025-10-27T04:46:38.235166+00:00</updated><content>&lt;doc fingerprint="12da93cf4494b8a7"&gt;
  &lt;main&gt;
    &lt;p&gt;This repository includes additional implementations of the Are-we-fast-yet benchmark suite.&lt;/p&gt;
    &lt;p&gt;See here for the main repository of the Are-we-fast-yet suite: https://github.com/smarr/are-we-fast-yet. See also the ORIGINAL_README.md file in this repository.&lt;/p&gt;
    &lt;p&gt;Each additional implementation is in a separate subdirectory (e.g. "Cpp", "Oberon", "FreePascal"); see there for more information.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rochus-keller/Are-we-fast-yet"/><published>2025-10-26T23:08:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45716109</id><title>How I turned Zig into my favorite language to write network programs in</title><updated>2025-10-27T04:46:38.050539+00:00</updated><content>&lt;doc fingerprint="ef463437cb212a9c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I turned Zig into my favorite language to write network programs in&lt;/head&gt;
    &lt;p&gt;I’ve been watching the Zig language for a while now, given that it was created for writing audio software (low-level, no allocations, real time). I never paid too much attention though, it seemed a little weird to me and I didn’t see the real need. Then I saw a post from Andrew Kelley (creator of the language) on Hacker News, about how he reimplemented my Chromaprint algorithm in Zig, and that got me really interested.&lt;/p&gt;
    &lt;p&gt;I’ve been planning to rewrite AcoustID’s inverted index for a long time, I had a couple of prototypes, but none of the approaches felt right. I was going through some rough times, wanted to learn something new, so I decided to use the project as an opportunity to learn Zig. And it was great, writing Zig is a joy. The new version was faster and more scalable than the previous C++ one. I was happy, until I wanted to add a server interface.&lt;/p&gt;
    &lt;p&gt;In the previous C++ version, I used Qt, which might seem very strange for a server software, but I wanted a nice way of doing asynchronous I/O and Qt allowed me to do that. It was callback-based, but Qt has a lot of support for making callbacks usable. In the newer prototypes, I used Go, specifically for the ease of networking and concurrency. With Zig, I was stuck. There are some Zig HTTP servers, so I could use those. I wanted to implement my legacy TCP server as well, and that’s a lot harder, unless I want to spawn a lot of threads. Then I made a crazy decision, to use Zig also for implementing a clustered layer on top of my server, using NATS as a messaging system, so I wrote a Zig NATS client, and that gave me a lot of experience with Zig’s networking capabilities.&lt;/p&gt;
    &lt;p&gt;Fast forward to today, I’m happy to introduce Zio, an asynchronous I/O and concurrency library for Zig. If you look at the examples, you will not really see where is the asynchronous I/O, but it’s there, in the background and that’s the point. Writing asynchronous code with callbacks is a pain. Not only that, it requires a lot of allocations, because you need state to survive across callbacks. Zio is an implementation of Go style concurrency, but limited to what’s possible in Zig. Zio tasks are stackful coroutines with fixed-size stacks. When you run &lt;code&gt;stream.read()&lt;/code&gt;, this will initiate the I/O operation in the background
and then suspend the current task until the I/O operation is done. When it’s done, the task will be resumed, and the result will be returned.
That gives you the illusion of synchronous code, allowing for much simpler state management.&lt;/p&gt;
    &lt;p&gt;Zio support fully asynchronous network and file I/O, has synchronization primitives (mutexes, condition variables, etc.) that work with the cooperative runtime, has Go-style channels, OS signal watches and more. Tasks can run in single-threaded mode, or multi-threaded, in which case they can migrate from thread to thread for lower latency and better load balancing.&lt;/p&gt;
    &lt;p&gt;And it’s FAST. I don’t want to be posting benchmarks here, maybe later when I have more complex ones, but the single-threaded mode is beating any framework I’ve tried so far. It’s much faster than both Go and Rust’s Tokio. Context switching is virtually free, comparable to a function call. The multi-threaded mode, while still not being as robust as Go/Tokio, has comparable performance. It’s still a bit faster than either of them, but that performance might go down as I add more fairness features.&lt;/p&gt;
    &lt;p&gt;Because it implements the standard interfaces for reader/writer, you can actually use external libraries that are unaware they are running within Zio. Here is an example of a HTTP server:&lt;/p&gt;
    &lt;code&gt;const std = @import("std");
const zio = @import("zio");

const MAX_REQUEST_HEADER_SIZE = 64 * 1024;

fn connectionTask(rt: *zio.Runtime, stream: zio.net.Stream) !void {
    defer stream.close(rt);

    var read_buffer: [MAX_REQUEST_HEADER_SIZE]u8 = undefined;
    var reader = stream.reader(rt, &amp;amp;read_buffer);

    var write_buffer: [4096]u8 = undefined;
    var writer = stream.writer(rt, &amp;amp;write_buffer);

    var server = std.http.Server.init(
        &amp;amp;reader.interface,
        &amp;amp;writer.interface,
    );

    while (true) {
        var request = try server.receiveHead();
        try request.respond("hello", .{ .status = .ok });

        if (!request.head.keep_alive) break;
    }
}

fn serverTask(rt: *zio.Runtime) !void {
    const addr = try zio.net.IpAddress.parse("127.0.0.1", 8080);

    const server = try addr.listen(rt, .{});
    defer server.close(rt);

    while (true) {
        const stream = try server.accept(rt);
        errdefer stream.close(rt);

        var task = try rt.spawn(
            connectionTask, .{ rt, stream }, .{}
        );
        task.deinit();
    }
}

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    var runtime = try zio.Runtime.init(allocator, .{});
    defer runtime.deinit();

    try runtime.runUntilComplete(serverTask, .{&amp;amp;runtime}, .{});
}
&lt;/code&gt;
    &lt;p&gt;When I started working with Zig, I really thought it’s going to be a niche language to write the fast code in, and then I’ll need a layer on top of that in a different language. With Zio, that changed. The next step for me is to update my NATS client to use Zio internally. And after that, I’m going to work on a HTTP client/server library based on Zio.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lalinsky.com/2025/10/26/zio-async-io-for-zig.html"/><published>2025-10-27T00:01:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45716296</id><title>ICE Will Use AI to Surveil Social Media</title><updated>2025-10-27T04:46:37.876076+00:00</updated><content>&lt;doc fingerprint="ad9499c408e8c7d9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ICE Will Use AI to Surveil Social Media&lt;/head&gt;
    &lt;p&gt;A Silicon Valley firm has contracted with Immigration and Customs Enforcement to build out a social media surveillance dragnet. Critics say that the AI-driven software will target immigrants for political speech.&lt;/p&gt;
    &lt;p&gt;Immigration and Customs Enforcement has inked a new $5.7 million contract for AI-driven social media surveillance software, according to federal procurement records reviewed by The Lever. It’s the latest move in the agency’s ongoing quest to build out a social media surveillance dragnet.&lt;/p&gt;
    &lt;p&gt;The five-year contract with government technology middleman Carahsoft Technology, made public in September, provides Immigration and Customs Enforcement (ICE) licenses for a product called Zignal Labs, a social media monitoring platform used by the Israeli military and the Pentagon.&lt;/p&gt;
    &lt;p&gt;An informational pamphlet marked confidential but publicly available online advertises that Zignal Labs “leverages artificial intelligence and machine learning” to analyze over eight billion social media posts per day, providing “curated detection feeds” for its clients. The information, the company says, allows law enforcement to “detect and respond to threats with greater clarity and speed.”&lt;/p&gt;
    &lt;p&gt;The Department of Homeland Security, ICE’s parent agency, has in the past procured Zignal licenses for the US Secret Service, signing its first contract for the software in 2019. The company also has contracts with the Department of Defense and the Department of Transportation.&lt;/p&gt;
    &lt;p&gt;But the September notice appears to be the first indication that ICE has access to the platform. The licenses will be provided to Homeland Security Investigations, ICE’s intelligence unit, to provide “real-time data analysis for criminal investigations,” per the disclosure.&lt;/p&gt;
    &lt;p&gt;Zignal joins ICE’s growing arsenal of social media surveillance tools, many of which employ artificial intelligence to generate leads and identify “threats” from vast quantities of online data. These tools pose a particular threat as ICE, under the Trump administration, appears to be increasingly using social media to direct its immigration enforcement strategy.&lt;/p&gt;
    &lt;p&gt;Several pro-Palestinian activists, including Mahmoud Khalil, were targeted and jailed by immigration authorities after being doxed online by right-wing, pro-Israel blacklist websites like Canary Mission. Just this week, immigration agents raided street vendors in New York City after a right-wing influencer posted a video of the block online, demanding action by authorities.&lt;/p&gt;
    &lt;p&gt;Last week, a group of labor unions sued over the federal government’s growing use of social media surveillance to target immigrants for their political speech, calling it a “mass, viewpoint-driven surveillance program.”&lt;/p&gt;
    &lt;p&gt;And there are indications that ICE intends to further expand its social media surveillance capabilities. As Wired reported earlier this month, ICE has plans to develop a round-the-clock social media monitoring team to identify leads for immigration enforcers.&lt;/p&gt;
    &lt;p&gt;Advocates told The Lever that ICE’s purchase of Zignal Labs licenses, like its other uses of digital surveillance tech, raises civil liberty concerns.&lt;/p&gt;
    &lt;p&gt;“[The Department of Homeland Security] should not be buying surveillance tools that scrape our social media posts off the internet and then use AI to scrutinize our online speech,” said Patrick Toomey, the deputy director of the American Civil Liberties Union’s National Security Project. “And agencies certainly shouldn’t be deploying this kind of black box technology in secret without any accountability.”&lt;/p&gt;
    &lt;head rend="h1"&gt;“Tactical Intelligence” to Israel and the Pentagon&lt;/head&gt;
    &lt;p&gt;Zignal Labs, founded in Silicon Valley in 2011, initially catered to public relations firms and political campaigns, advertising data analytics and media monitoring to help identify and respond to narrative trends online.&lt;/p&gt;
    &lt;p&gt;But like the many private companies that now provide digital surveillance tools to the federal government, Zignal Labs soon moved into the defense and intelligence industries, formally announcing the new focus, along with a “public sector advisory board” staffed by industry veterans, in 2021. One Zignal pamphlet from this year advertises the company’s work with the Israeli military, saying its data analytics platform provides “tactical intelligence” to “operators on the ground” in Gaza. The pamphlet also highlights Zignal’s work with the US Marines and the State Department.&lt;/p&gt;
    &lt;p&gt;Zignal Labs did not return a request for comment about its work with Israeli forces or its new contract with ICE.&lt;/p&gt;
    &lt;p&gt;The unions’ lawsuit over the Trump administration’s use of social media surveillance details the myriad digital surveillance tools that ICE already has at its disposal, including ShadowDragon, a software that uses publicly available websites to map out an individual’s online activity, and Babel X, which links social media profiles and location information to a target’s Social Security number.&lt;/p&gt;
    &lt;p&gt;“We’ve been seeing an uptick in ICE surveillance contracts,” said Julie Mao, an attorney with Just Futures Law, a legal advocacy group that closely monitors ICE’s surveillance regime.&lt;/p&gt;
    &lt;p&gt;This week, ICE signed a $7 million contract with the firm SOS International LLC, for “skip tracing services,” a term that refers to tracking a person’s whereabouts, per federal procurement records reviewed by The Lever. The multimillion-dollar contract comes just three months after SOS International LLC, which also does business as SOSi, announced that the company had hired Andre Watson, an ICE Homeland Security Investigations intelligence chief, to “expand [the company’s] business and deliver capabilities to state and federal law enforcement agencies.”&lt;/p&gt;
    &lt;p&gt;Many of these services tout that their surveillance capabilities are enhanced by artificial intelligence, including Zignal. In a July post announcing the latter company’s partnership with Carahsoft Technology, Zignal’s CEO boasted that the latest iteration of the software used AI to scour global digital data, “helping defense and intelligence teams detect and respond to threats with greater clarity and speed.” Two months after this announcement, ICE signed its new contract with Carahsoft for Zignal licenses.&lt;/p&gt;
    &lt;p&gt;ICE’s use of AI to surveil vast swathes of the internet in real time presents serious privacy and free speech concerns, the labor unions argued in their lawsuit against the Trump administration.&lt;/p&gt;
    &lt;p&gt;“The government’s utilization of AI and automated tools for viewpoint-driven online surveillance gives teeth to its threat to surveil ‘everyone’ online for disfavored expression,” attorneys with the civil liberties group the Electronic Freedom Foundation and Yale Law School’s Media Freedom and Information Access Clinic wrote in the complaint, saying that such tools “exacerbate the chilling impact of that surveillance.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jacobin.com/2025/10/ice-zignal-surveillance-social-media"/><published>2025-10-27T00:43:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45717238</id><title>We're in the Wrong Moment</title><updated>2025-10-27T04:46:37.782792+00:00</updated><content>&lt;doc fingerprint="13c1931bfbd24b5d"&gt;
  &lt;main&gt;
    &lt;p&gt;August 20th, 2011: Marc Andreessen proclaims ‘Software is eating the world.’ That was over ten years ago. Today, software is still eating the world, but this is no longer a groundbreaking proclamation nor a surprise to anyone. In the years that followed, software would become integral to our daily lives, business, and attention.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Story&lt;/head&gt;
    &lt;p&gt;As I learned and continue to learn more about computer science through my degrees, I am constantly reminded of times gone by. I had professors who had lived through the rise of computer science; who invented network systems ground up, pioneered research in their fields and had advisors from the previous generation who invented modern systems that we know today. I am reminded of a golden age of CS and software engineering, where founders and academics would bump into each other in the Bay Area and create the next big thing seemingly on a whim.&lt;/p&gt;
    &lt;p&gt;I met people and friends who had gone to work for their dream companies - the Microsofts, Apples, Googles, and those people who made six figures out of college. I had heard legends (for lack of a better term) of the geniuses; the students who made such a difference in school and then went on to pursue their dreams and have a steady career.&lt;/p&gt;
    &lt;p&gt;Alas, all of this seems gone these days. In my final term of college, I can’t help but feel a longing for the days where software was eating the world. I feel as if I would’ve thrived, would’ve innovated, and would’ve had more fun. I feel like my experience would have been worth more then, but now it’s worth hardly anything in a changing industry.&lt;/p&gt;
    &lt;head rend="h2"&gt;What do you do when it’s no longer fun?&lt;/head&gt;
    &lt;p&gt;I’ve said my story a few times in different writings, but I started programming with Minecraft during my adolescent years. I learned Java and OOP before I had even learned algebra. I had learned worst-case behavior and programmatic/problem solving thinking before I had really started a sport. The struggle of solving a problem; of debugging, of failing, and eventually succeeding always made it worth it for me again.&lt;/p&gt;
    &lt;p&gt;I love writing code. It’s like writing in general, or it’s like a creative art. You tweak it, revise it, pay attention to detail a thousand times. You keep on working at it and iterating on it until it’s just right.&lt;/p&gt;
    &lt;p&gt;I’m not sure if anyone else feels this way, but with the introduction of generative AI, I don’t find coding fun anymore. It’s hard to motivate myself to code knowing that a model can do it much quicker. The joy of coding for me was literally the process of coding.&lt;/p&gt;
    &lt;p&gt;Today, AI is eating the world. You can’t hardly go to a website without seeing AI 15 times in the marketing, or having an AI support chatbot pop up. You can’t hardly have a conversation with someone without hearing about it. The companies I dreamed of working for now have mandatory AI policies, or else you’ll be on the chopping block.&lt;/p&gt;
    &lt;p&gt;Altogether, it feels like I’m suspended in motion. All I can do is sit and watch while the irreversible effects of AI grow, time is passing, and more innovation is happening. Some software engineers are embracing it. Some software engineers are actively working towards a future where their own jobs will be taken by AI. Some of us just have to roll with the sunk costs on degrees that were made for a different time and get a job anyways.&lt;/p&gt;
    &lt;p&gt;We’re faced with harder questions now than in the time where things were just built; I wonder if there will be a world where people must choose to opt in or out of AI usage in their jobs; or if there will be the same banners per website like we get with cookies. Or, if it will continue steamrolling, or rather stagnate in the end.&lt;/p&gt;
    &lt;p&gt;How will macroeconomics and government policy get involved? (Bernie has a rather gloomy talk on this) I think that they will need to get involved, sooner or later.&lt;/p&gt;
    &lt;p&gt;For all of us that grew up enjoying the coding process: we might just be in the wrong moment in time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ezrichards.github.io/posts/were-in-the-wrong-moment/"/><published>2025-10-27T03:46:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45717282</id><title>However small, just start. From zero to hero</title><updated>2025-10-27T04:46:37.535506+00:00</updated><content>&lt;doc fingerprint="7f4090756f2694d4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Make it a fantasy&lt;/head&gt;
    &lt;p&gt;In the middle of a tough workout, I put my imagination in a survival situation. I pretend I haven’t had water for several days in a desert. I’m parched. I need to drill down to my last drop of strength to arrive at the oasis. (OK, it’s an ego fantasy as well as one of survival.) I feel the relentless desert heat, but refuse to slow down. I push and push, and then – oh wow, that stream of cool, clean water flowing down my throat at the end is like a magical elixir.&lt;lb/&gt;Diana Nyad, long-distance swimmer and motivational speaker &lt;/p&gt;
    &lt;head rend="h2"&gt;Try a tiny bit of tidying&lt;/head&gt;
    &lt;p&gt;When I feel weighed down by unanswered emails or tedious admin tasks, I turn to tidying a small space. It might be my bag or a corner of a drawer – just one manageable spot. Even this tiny act of tidying clears my head, lifts my energy and sparks the motivation to get moving again. Because tidying involves physical movement, I often use that momentum to tackle the very tasks I’ve been putting off.&lt;lb/&gt;Marie Kondo, organising consultant and author&lt;/p&gt;
    &lt;head rend="h2"&gt;Beat the soundtrack&lt;/head&gt;
    &lt;p&gt;When it comes to cleaning my home, racing to finish a task before a song or playlist comes to an end is helpful. I like to see what I can achieve to The Saturdays’ Greatest Hits Megamix, which is around seven minutes long. It’s amazing what you can achieve in a short amount of time when you crack on. &lt;lb/&gt;Iwan Carrington, author of Clean in 15: Create a Clean &amp;amp; Happy Home in Minutes&lt;/p&gt;
    &lt;head rend="h2"&gt;Check out obituaries&lt;/head&gt;
    &lt;p&gt;Two things motivate me: death and deadlines. The easiest and most enjoyable way to keep death ever-present in the mind is to read the obituaries every morning. When I read about people who did something with their lives, it makes me want to do something with mine.&lt;lb/&gt;Austin Kleon, author of Keep Going: 10 Ways to Stay Creative in Good Times and Bad &lt;/p&gt;
    &lt;head rend="h2"&gt;Aim low(brow)&lt;/head&gt;
    &lt;p&gt;I only allow myself to watch my favourite lowbrow TV shows while exercising. That means I end every workout wanting more and look forward to my time on the cross-trainer. This is how I’ve watched shows such as Bridgerton, Emily in Paris, Never Have I Ever, The Sex Lives of College Girls, Ted Lasso and more.&lt;lb/&gt;Katy Milkman, author of How to Change: The Science of Getting to Where You Want to Be&lt;/p&gt;
    &lt;head rend="h2"&gt;Use your imagination&lt;/head&gt;
    &lt;p&gt;When I need to push through a workout, I’ve got a few motivators on rotation. I once read that exercise is like a shotgun blast of health for the body, so I imagine that. Other times it’s more personal: I move for my dad, who’s too sick to move himself, or I remind myself that after giving birth to two kids, this is a piece of cake. I also hear my old coach, Rob Shaul, in my head yelling “Suck it up!”, which never fails.&lt;lb/&gt;Mintra Tilly, director of sports at fitness company Hyrox &lt;/p&gt;
    &lt;head rend="h2"&gt;Take one small step …&lt;/head&gt;
    &lt;p&gt;It might seem incongruous for an Ironman athlete to talk about making things as easy as possible, but hear me out. Don’t think about moving mountains, think about taking one small, easy step. If I can’t motivate myself to go for a run, I put my shoes on and open the door. Once I get there, I step out and run four or five steps. Once I have that momentum, I continue – and so does my motivation. I log my progress in a training diary, ensuring I bank feelings of euphoria to draw on in future, and can be buoyed up by memories of times when I completed sessions that I didn’t want to do.&lt;lb/&gt;Chrissie Wellington, four-time Ironman triathlon world champion &lt;/p&gt;
    &lt;head rend="h2"&gt;Say yes&lt;/head&gt;
    &lt;p&gt;I say the word yes over and over again – in my mind or out loud. One syllable. It’s positive and it gets you into a motivated mindset.&lt;lb/&gt;Emily Harrington, professional rock climber&lt;/p&gt;
    &lt;head rend="h2"&gt;Ask yourself why&lt;/head&gt;
    &lt;p&gt;Sometimes when we lack motivation or procrastinate, there’s a reason. Often, it’s because there is some fear or reluctance to do something; maybe we think we won’t be able to manage or cope with it. Ask yourself exactly what you’re worried about. You can sometimes then see the fears are not real or at least not as large as you might believe. It may just be that you’re focusing on these feelings of not wanting to start, but turn it around and ask yourself how you’ll feel, or the repercussions, if you don’t begin that task. Often those feelings will be more scary or worrying. This helps me to start – because it’s the least worst option!&lt;lb/&gt;Dr Radha Modgil, author of Know Your Own Power: Inspiration, Motivation and Practical Tools for Life&lt;/p&gt;
    &lt;head rend="h2"&gt;Keep a log&lt;/head&gt;
    &lt;p&gt;I like to keep a tally of hours spent doing deep work each day – that’s time spent focusing on cognitively demanding tasks without opening emails or having meetings. When I find myself, in the moment, wanting to avoid hard work for busyness, I ask myself: how will you feel tonight when you put down a big zero for your daily deep work hours? That often helps.&lt;lb/&gt;Cal Newport, author of Deep Work: Rules for Focused Success in a Distracted World&lt;/p&gt;
    &lt;head rend="h2"&gt;Lie to yourself&lt;/head&gt;
    &lt;p&gt;I have been walking up the six flights of stairs to my office since the lift broke at the start of the year, and carried on even when it was mended. I get through this by lying to myself about how many flights there are to go. I repeat “one, one, one” as I step, because if I count properly it seems to take for ever. So this is basically a strategy to stop me counting for real and then chickening out as it’s so many steps. I find this both makes it easier, stopping me thinking about how many stairs there are to go, and means reaching my floor is a pleasant surprise.&lt;lb/&gt;Prof Sophie Scott, director of the Institute of Cognitive Neuroscience, University College London&lt;/p&gt;
    &lt;head rend="h2"&gt;Choose a lucky charm&lt;/head&gt;
    &lt;p&gt;My mini motivator is Clive. He’s a pink-haired, inch-high troll that my niece gave me while I was doing IVF for my now grownup triplets. He was there for egg harvesting, reimplantation and birth. He symbolised support and care. I’ve since taken him on every expedition, and when it’s tough and I’ve used all my motivators (chanting my children’s names is favourite), I take comfort from his presence and keep going. He’s not just useful for expeditions. I regularly speak at corporate events and always have nerves beforehand. I never go on stage without him.&lt;lb/&gt;Ann Daniels, polar explorer &lt;/p&gt;
    &lt;head rend="h2"&gt;Engage your senses&lt;/head&gt;
    &lt;p&gt;I swear, if I get more than one of my senses actively involved, I can suddenly do tasks I couldn’t do mere moments ago. There is something about tuning into your senses that gives the mind a reset, an opportunity to get off the hamster wheel of dread and recalibrate into the current moment. This could be lighting a candle while playing moody music in order to focus on yoga lesson planning. It could be getting a drink and eating an apple before I settle in for Zoom calls. I’ve also been known to step outside to feel the Texas sun on my skin before slaying my chores. It’s really hard for me to put away laundry. I need the cross-sensory boost to gear my body and brain up for the tasks at hand, especially if they feel big that day.&lt;lb/&gt;Adriene Mishler, host of Yoga with Adriene&lt;/p&gt;
    &lt;head rend="h2"&gt;Focus for 15&lt;/head&gt;
    &lt;p&gt;To get through boring admin, I set a 15-minute timer on my phone. Here’s what happens in your brain when you do that: the open-ended anxiety of “this could take for ever” gets replaced with “I just need to focus for X minutes.” Fifteen minutes is the sweet spot for many people – long enough to make real progress, short enough to feel manageable even on difficult days or really tedious tasks. Usually, one of two things happens: the task doesn’t take anywhere near as long as you thought, or you get into the flow and it’s nowhere near as bad as you thought it would be. Before you know it, the task is done.&lt;lb/&gt;Mia Northrop, co-founder of life coaching company Life Admin Life Hacks&lt;/p&gt;
    &lt;head rend="h2"&gt;Ditch your devices&lt;/head&gt;
    &lt;p&gt;Whenever I find my motivation dipping, I’ll go for a device-free walk around the block. This may sound like procrastination, but it’s the opposite. A device-free walk always helps me reorient toward the task at hand. If I’m distracted, being device-free helps settle my mind. If I’m putting a task off, I can reflect on what’s making me not want to do it – and form a plan to combat that aversion. &lt;lb/&gt;Chris Bailey, author of Hyperfocus: How to Work Less and Achieve More &lt;/p&gt;
    &lt;head rend="h2"&gt;Picture the end result&lt;/head&gt;
    &lt;p&gt;Before decluttering or organising a space, I visualise how the newly organised space will make me feel. Daunted at the thought of organising all those coats and shoes jumbled at the front door? Imagine the ease and calm of stepping into the right pair of shoes and taking your favourite jacket as you leave the house in the morning. About to dive into sorting out the toy mountain? Imagine a sitting room where you can do a quick tidy in five minutes because everything has a home.&lt;lb/&gt;Mel Carruthers, owner of decluttering service More Organised&lt;/p&gt;
    &lt;head rend="h2"&gt;Start small&lt;/head&gt;
    &lt;p&gt;I remind myself not to wait for motivation as it rarely shows up. What matters is momentum, and momentum starts with something small: tidying one drawer, sending one email. That first step creates energy, and results follow with consistency. The truth is, most people give up because the vision in their head doesn’t appear instantly, but real change is a process.&lt;lb/&gt;Craig Hoareau, owner of house organisation company A Tidy Mind London&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/lifeandstyle/2025/oct/26/expert-motivation-tips-gym-to-do-list"/><published>2025-10-27T04:00:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45717285</id><title>Severe performance penalty found in VSCode rendering loop</title><updated>2025-10-27T04:46:36.945290+00:00</updated><content>&lt;doc fingerprint="6a04366c09082688"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 35.8k&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Open&lt;/p&gt;
    &lt;p&gt;Labels&lt;/p&gt;
    &lt;p&gt;feature-requestRequest for new features or functionalityRequest for new features or functionalityperf&lt;/p&gt;
    &lt;p&gt;Milestone&lt;/p&gt;
    &lt;head rend="h2"&gt;Description&lt;/head&gt;
    &lt;head rend="h1"&gt;Main Bottleneck in the Rendering Loop&lt;/head&gt;
    &lt;p&gt;The primary bottleneck is at /vscode/src/vs/base/browser/dom.ts:365 - the animation frame queue sorts on every iteration inside the while loop:&lt;/p&gt;
    &lt;code&gt;while (currentQueue.length &amp;gt; 0) {
    currentQueue.sort(AnimationFrameQueueItem.sort);  // ⚠️ BOTTLENECK: O(n² log n)
    const top = currentQueue.shift()!;
    top.execute();
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Why This is the Bottleneck:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Repeated sorting: For n callbacks, this sorts n times with decreasing sizes (n, n-1, n-2, ..., 1)&lt;/item&gt;
      &lt;item&gt;Complexity: O(n² log n) instead of O(n log n) if sorted once&lt;/item&gt;
      &lt;item&gt;Real-world impact: With 50+ view parts (text, cursors, minimap, scrollbar, widgets, decorations, etc.), this wastes 1-2ms per frame&lt;/item&gt;
      &lt;item&gt;Critical path: Happens during the 16ms frame budget (60fps)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Proposed Solution: Binary Heap Priority Queue&lt;/head&gt;
    &lt;p&gt;Replace the array-based queue with a binary min-heap that maintains priority order automatically:&lt;lb/&gt; Benefits:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Insertion: O(log n)&lt;/item&gt;
      &lt;item&gt;Extraction: O(log n)&lt;/item&gt;
      &lt;item&gt;Overall: O(n log n) instead of O(n² log n)&lt;/item&gt;
      &lt;item&gt;Performance gain: 85-90% reduction in queue overhead (~1.5ms → ~0.2ms)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Implementation:&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Create a BinaryHeap class:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;class BinaryHeap&amp;lt;T extends { priority: number }&amp;gt; {
    private _items: T[] = [];

    get length(): number {
        return this._items.length;
    }

    push(item: T): void {
        this._items.push(item);
        this._bubbleUp(this._items.length - 1);
    }

    shift(): T | undefined {
        if (this._items.length === 0) return undefined;
        if (this._items.length === 1) return this._items.pop()!;

        const result = this._items[0];
        this._items[0] = this._items.pop()!;
        this._bubbleDown(0);
        return result;
    }

    private _bubbleUp(index: number): void {
        const item = this._items[index];
        const priority = -item.priority; // Negative for max-heap behavior

        while (index &amp;gt; 0) {
            const parentIndex = Math.floor((index - 1) / 2);
            const parent = this._items[parentIndex];
            if (priority &amp;gt;= -parent.priority) break;

            this._items[index] = parent;
            index = parentIndex;
        }
        this._items[index] = item;
    }

    private _bubbleDown(index: number): void {
        const length = this._items.length;
        const item = this._items[index];
        const priority = -item.priority;

        while (true) {
            let minIndex = index;
            let minPriority = priority;
            const leftIndex = 2 * index + 1;
            const rightIndex = 2 * index + 2;

            if (leftIndex &amp;lt; length) {
                const leftPriority = -this._items[leftIndex].priority;
                if (leftPriority &amp;lt; minPriority) {
                    minIndex = leftIndex;
                    minPriority = leftPriority;
                }
            }

            if (rightIndex &amp;lt; length) {
                const rightPriority = -this._items[rightIndex].priority;
                if (rightPriority &amp;lt; minPriority) {
                    minIndex = rightIndex;
                    minPriority = rightPriority;
                }
            }

            if (minIndex === index) break;

            this._items[index] = this._items[minIndex];
            index = minIndex;
        }
        this._items[index] = item;
    }
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Update dom.ts:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;// Change queue type from Array to BinaryHeap
const NEXT_QUEUE = new Map&amp;lt;number, BinaryHeap&amp;lt;AnimationFrameQueueItem&amp;gt;&amp;gt;();
const CURRENT_QUEUE = new Map&amp;lt;number, BinaryHeap&amp;lt;AnimationFrameQueueItem&amp;gt;&amp;gt;();

const animationFrameRunner = (targetWindowId: number) =&amp;gt; {
    animFrameRequested.set(targetWindowId, false);
    const currentQueue = NEXT_QUEUE.get(targetWindowId) ?? new BinaryHeap&amp;lt;AnimationFrameQueueItem&amp;gt;();
    CURRENT_QUEUE.set(targetWindowId, currentQueue);
    NEXT_QUEUE.set(targetWindowId, new BinaryHeap&amp;lt;AnimationFrameQueueItem&amp;gt;());

    inAnimationFrameRunner.set(targetWindowId, true);
    while (currentQueue.length &amp;gt; 0) {
        // No sort needed! Heap maintains order automatically ✅
        const top = currentQueue.shift()!;
        top.execute();
    }
    inAnimationFrameRunner.set(targetWindowId, false);
};

scheduleAtNextAnimationFrame = (targetWindow: Window, runner: () =&amp;gt; void, priority: number = 0) =&amp;gt; {
    const targetWindowId = getWindowId(targetWindow);
    const item = new AnimationFrameQueueItem(runner, priority);

    let nextQueue = NEXT_QUEUE.get(targetWindowId);
    if (!nextQueue) {
        nextQueue = new BinaryHeap&amp;lt;AnimationFrameQueueItem&amp;gt;();
        NEXT_QUEUE.set(targetWindowId, nextQueue);
    }
    nextQueue.push(item); // O(log n) maintains heap property
    // ... rest of function
};&lt;/code&gt;
    &lt;p&gt;deffcolony, 8u6man, Shubham-Rasal, LIV2, Singtaa and 36 more&lt;/p&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;head rend="h2"&gt;Metadata&lt;/head&gt;
    &lt;head rend="h3"&gt;Assignees&lt;/head&gt;
    &lt;head rend="h3"&gt;Labels&lt;/head&gt;
    &lt;p&gt;feature-requestRequest for new features or functionalityRequest for new features or functionalityperf&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/microsoft/vscode/issues/272155"/><published>2025-10-27T04:00:39+00:00</published></entry></feed>