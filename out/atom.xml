<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-26T15:09:53.023820+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46042810</id><title>Jakarta is now the biggest city in the world</title><updated>2025-11-26T15:10:02.250903+00:00</updated><content/><link href="https://www.axios.com/2025/11/24/jakarta-tokyo-worlds-biggest-city-population"/><published>2025-11-25T06:09:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045085</id><title>Trillions spent and big software projects are still failing</title><updated>2025-11-26T15:10:02.033334+00:00</updated><content>&lt;doc fingerprint="e94c521a6b7707dc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;‚ÄúWhy worry about something that isn‚Äôt going to happen?‚Äù&lt;/p&gt;
      &lt;p&gt;KGB Chairman Charkov‚Äôs question to inorganic chemist Valery Legasov in HBO‚Äôs ‚ÄúChernobyl‚Äù miniseries makes a good epitaph for the hundreds of software development, modernization, and operational failures I have covered for IEEE Spectrum since my first contribution, to its September 2005 special issue on learning‚Äîor rather, not learning‚Äîfrom software failures. I noted then, and it‚Äôs still true two decades later: Software failures are universally unbiased. They happen in every country, to large companies and small. They happen in commercial, nonprofit, and governmental organizations, regardless of status or reputation.&lt;/p&gt;
      &lt;p&gt;Global IT spending has more than tripled in constant 2025 dollars since 2005, from US $1.7 trillion to $5.6 trillion, and continues to rise. Despite additional spending, software success rates have not markedly improved in the past two decades. The result is that the business and societal costs of failure continue to grow as software proliferates, permeating and interconnecting every aspect of our lives.&lt;/p&gt;
      &lt;p&gt;For those hoping AI software tools and coding copilots will quickly make large-scale IT software projects successful, forget about it. For the foreseeable future, there are hard limits on what AI can bring to the table in controlling and managing the myriad intersections and trade-offs among systems engineering, project, financial, and business management, and especially the organizational politics involved in any large-scale software project. Few IT projects are displays of rational decision-making from which AI can or should learn. As software practitioners know, IT projects suffer from enough management hallucinations and delusions without AI adding to them.&lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt;As I noted 20 years ago, the drivers of software failure frequently are failures of human imagination, unrealistic or unarticulated project goals, the inability to handle the project‚Äôs complexity, or unmanaged risks, to name a few that today still regularly cause IT failures. Numerous others go back decades, such as those identified by Stephen Andriole, the chair of business technology at Villanova University‚Äôs School of Business, in the diagram below first published in Forbes in 2021. Uncovering a software system failure that has gone off the rails in a unique, previously undocumented manner would be surprising because the overwhelming majority of software-related failures involve avoidable, known failure-inducing factors documented in hundreds of after-action reports, academic studies, and technical and management books for decades. Failure d√©j√† vu dominates the literature.&lt;/p&gt;
        &lt;p&gt;The question is, why haven‚Äôt we applied what we have repeatedly been forced to learn?&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;Steve Andriole&lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;The Phoenix That Never Rose&lt;/head&gt;
        &lt;p&gt;Many of the IT developments and operational failures I have analyzed over the last 20 years have each had their own Chernobyl-like meltdowns, spreading reputational radiation everywhere and contaminating the lives of those affected for years. Each typically has a story that strains belief. A prime example is the Canadian government‚Äôs CA $310 million Phoenix payroll system, which went live in April 2016 and soon after went supercritical.&lt;/p&gt;
        &lt;p&gt;Phoenix project executives believed they could deliver a modernized payment system, customizing PeopleSoft‚Äôs off-the-shelf payroll package to follow 80,000 pay rules spanning 105 collective agreements with federal public-service unions. It also was attempting to implement 34 human-resource system interfaces across 101 government agencies and departments required for sharing employee data. Further, the government‚Äôs developer team thought they could accomplish this for less than 60 percent of the vendor‚Äôs proposed budget. They‚Äôd save by removing or deferring critical payroll functions, reducing system and integration testing, decreasing the number of contractors and government staff working on the project, and forgoing vital pilot testing, along with a host of other overly optimistic proposals.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Phoenix‚Äôs payroll meltdown was preordained. As a result, over the past nine years, around 70 percent of the 430,000 current and former Canadian federal government employees paid through Phoenix have endured paycheck errors. Even as recently as fiscal year 2023‚Äì2024, a third of all employees experienced paycheck mistakes. The ongoing financial stress and anxieties for thousands of employees and their families have been immeasurable. Not only are recurring paycheck troubles sapping worker morale, but in at least one documented case, a coroner blamed an employee‚Äôs suicide on the unbearable financial and emotional strain she suffered.&lt;/p&gt;
        &lt;p&gt;By the end of March 2025, when the Canadian government had promised that the backlog of Phoenix errors would finally be cleared, over 349,000 were still unresolved, with 53 percent pending for more than a year. In June, the Canadian government once again committed to significantly reducing the backlog, this time by June 2026. Given previous promises, skepticism is warranted.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The question is, why haven‚Äôt we applied what we have repeatedly been forced to learn?&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;What percentage of software projects fail, and what failure means, has been an ongoing debate within the IT community stretching back decades. Without diving into the debate, it‚Äôs clear that software development remains one of the riskiest technological endeavors to undertake. Indeed, according to Bent Flyvbjerg, professor emeritus at the University of Oxford‚Äôs Sa—ód Business School, comprehensive data shows that not only are IT projects risky, they are the riskiest from a cost perspective.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The CISQ report estimates that organizations in the United States spend more than $520 billion annually supporting legacy software systems, with 70 to 75 percent of organizational IT budgets devoted to legacy maintenance. A 2024 report by services company NTT DATA found that 80 percent of organizations concede that ‚Äúinadequate or outdated technology is holding back organizational progress and innovation efforts.‚Äù Furthermore, the report says that virtually all C-level executives believe legacy infrastructure thwarts their ability to respond to the market. Even so, given that the cost of replacing legacy systems is typically many multiples of the cost of supporting them, business executives hesitate to replace them until it is no longer operationally feasible or cost-effective. The other reason is a well-founded fear that replacing them will turn into a debacle like Phoenix or others.&lt;/p&gt;
        &lt;p&gt;Nevertheless, there have been ongoing attempts to improve software development and sustainment processes. For example, we have seen increasing adoption of iterative and incremental strategies to develop and sustain software systems through Agile approaches, DevOps methods, and other related practices.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The goal is to deliver usable, dependable, and affordable software to end users in the shortest feasible time. DevOps strives to accomplish this continuously throughout the entire software life cycle. While Agile and DevOps have proved successful for many organizations, they also have their share of controversy and pushback. Provocative reports claim Agile projects have a failure rate of up to 65 percent, while others claim up to 90 percent of DevOps initiatives fail to meet organizational expectations.&lt;/p&gt;
        &lt;p&gt;It is best to be wary of these claims while also acknowledging that successfully implementing Agile or DevOps methods takes consistent leadership, organizational discipline, patience, investment in training, and culture change. However, the same requirements have always been true when introducing any new software platform. Given the historic lack of organizational resolve to instill proven practices, it is not surprising that novel approaches for developing and sustaining ever more complex software systems, no matter how effective they may be, will also frequently fall short.&lt;/p&gt;
        &lt;head rend="h2"&gt;Persisting in Foolish Errors&lt;/head&gt;
        &lt;p&gt;The frustrating and perpetual question is why basic IT project-management and governance mistakes during software development and operations continue to occur so often, given the near-total societal reliance on reliable software and an extensively documented history of failures to learn from? Next to electrical infrastructure, with which IT is increasingly merging into a mutually codependent relationship, the failure of our computing systems is an existential threat to modern society.&lt;/p&gt;
        &lt;p&gt;Frustratingly, the IT community stubbornly fails to learn from prior failures. IT project managers routinely claim that their project is somehow different or unique and, thus, lessons from previous failures are irrelevant. That is the excuse of the arrogant, though usually not the ignorant. In Phoenix‚Äôs case, for example, it was the government‚Äôs second payroll-system replacement attempt, the first effort ending in failure in 1995. Phoenix project managers ignored the well-documented reasons for the first failure because they claimed its lessons were not applicable, which did nothing to keep the managers from repeating them. As it‚Äôs been said, we learn more from failure than from success, but repeated failures are damn expensive.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Not all software development failures are bad; some failures are even desired. When pushing the limits of developing new types of software products, technologies, or practices, as is happening with AI-related efforts, potential failure is an accepted possibility. With failure, experience increases, new insights are gained, fixes are made, constraints are better understood, and technological innovation and progress continue. However, most IT failures today are not related to pushing the innovative frontiers of the computing art, but the edges of the mundane. They do not represent Austrian economist Joseph Schumpeter‚Äôs ‚Äúgales of creative destruction.‚Äù They‚Äôre more like gales of financial destruction. Just how many more enterprise resource planning (ERP) project failures are needed before success becomes routine? Such failures should be called IT blunders, as learning anything new from them is dubious at best.&lt;/p&gt;
        &lt;p&gt;Was Phoenix a failure or a blunder? I argue strongly for the latter, but at the very least, Phoenix serves as a master class in IT project mismanagement. The question is whether the Canadian government learned from this experience any more than it did from 1995‚Äôs payroll-project fiasco? The government maintains it will learn, which might be true, given the Phoenix failure‚Äôs high political profile. But will Phoenix‚Äôs lessons extend to the thousands of outdated Canadian government IT systems needing replacement or modernization? Hopefully, but hope is not a methodology, and purposeful action will be necessary.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The IT community has striven mightily for decades to make the incomprehensible routine. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Repeatedly making the same mistakes and expecting a different result is not learning. It is a farcical absurdity. Paraphrasing Henry Petroski in his book To Engineer Is Human: The Role of Failure in Successful Design (Vintage, 1992), we may have learned how to calculate the software failure due to risk, but we have not learned how to calculate to eliminate the failure of the mind. There are a plethora of examples of projects like Phoenix that failed in part due to bumbling management, yet it is extremely difficult to find software projects managed professionally that still failed. Finding examples of what could be termed ‚ÄúIT heroic failures‚Äù is like Diogenes seeking one honest man.&lt;/p&gt;
        &lt;p&gt;The consequences of not learning from blunders will be much greater and more insidious as society grapples with the growing effects of artificial intelligence, or more accurately, ‚Äúintelligent‚Äù algorithms embedded into software systems. Hints of what might happen if past lessons go unheeded are found in the spectacular early automated decision-making failure of Michigan‚Äôs MiDAS unemployment and Australia‚Äôs Centrelink ‚ÄúRobodebt‚Äù welfare systems. Both used questionable algorithms to identify deceptive payment claims without human oversight. State officials used MiDAS to accuse tens of thousands of Michiganders of unemployment fraud, while Centrelink officials falsely accused hundreds of thousands of Australians of being welfare cheats. Untold numbers of lives will never be the same because of what occurred. Government officials in Michigan and Australia placed far too much trust in those algorithms. They had to be dragged, kicking and screaming, to acknowledge that something was amiss, even after it was clearly demonstrated that the software was untrustworthy. Even then, officials tried to downplay the errors‚Äô impact on people, then fought against paying compensation to those adversely affected by the errors. While such behavior is legally termed ‚Äúmaladministration,‚Äù administrative evil is closer to reality.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;So, we are left with only a professional and personal obligation to reemphasize the obvious: Ask what you do know, what you should know, and how big the gap is between them before embarking on creating an IT system. If no one else has ever successfully built your system with the schedule, budget, and functionality you asked for, please explain why your organization thinks it can. Software is inherently fragile; building complex, secure, and resilient software systems is difficult, detailed, and time-consuming. Small errors have outsize effects, each with an almost infinite number of ways they can manifest, from causing a minor functional error to a system outage to allowing a cybersecurity threat to penetrate the system. The more complex and interconnected the system, the more opportunities for errors and their exploitation. A nice start would be for senior management who control the purse strings to finally treat software and systems development, operations, and sustainment efforts with the respect they deserve. This not only means providing the personnel, financial resources, and leadership support and commitment, but also the professional and personal accountability they demand.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;It is well known that honesty, skepticism, and ethics are essential to achieving project success, yet they are often absent. Only senior management can demand they exist. For instance, honesty begins with the forthright accounting of the myriad of risks involved in any IT endeavor, not their rationalization. It is a common ‚Äúsecret‚Äù that it is far easier to get funding to fix a troubled software development effort than to ask for what is required up front to address the risks involved. Vendor puffery may also be legal, but that means the IT customer needs a healthy skepticism of the typically too-good-to-be-true promises vendors make. Once the contract is signed, it is too late. Furthermore, computing‚Äôs malleability, complexity, speed, low cost, and ability to reproduce and store information combine to create ethical situations that require deep reflection about computing‚Äôs consequences on individuals and society. Alas, ethical considerations have routinely lagged when technological progress and profits are to be made. This practice must change, especially as AI is routinely injected into automated systems.&lt;/p&gt;
        &lt;p&gt;In the AI community, there has been a movement toward the idea of human-centered AI, meaning AI systems that prioritize human needs, values, and well-being. This means trying to anticipate where and when AI can go wrong, move to eliminate these situations, and build in ways to mitigate the effects if they do happen. This concept requires application to every IT system‚Äôs effort, not just AI.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Given the historic lack of organizational resolve to instill proven practices...novel approaches for developing and sustaining ever more complex software systems...will also frequently fall short.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt;Finally, project cost-benefit justifications of software developments rarely consider the financial and emotional distress placed on end users of IT systems when something goes wrong. These include the long-term failure after-effects. If these costs had to be taken fully into account, such as in the cases of Phoenix, MiDAS, and Centrelink, perhaps there could be more realism in what is required managerially, financially, technologically, and experientially to create a successful software system. It may be a forlorn request, but surely it is time the IT community stops repeatedly making the same ridiculous mistakes it has made since at least 1968, when the term ‚Äúsoftware crisis‚Äù was coined. Make new ones, damn it. As Roman orator Cicero said in Philippic 12, ‚ÄúAnyone can make a mistake, but only an idiot persists in his error.‚Äù&lt;/p&gt;
      &lt;p&gt;Special thanks to Steve Andriole, Hal Berghel, Matt Eisler, John L. King, Roger Van Scoy, and Lee Vinsel for their invaluable critiques and insights.&lt;/p&gt;
      &lt;p&gt;This article appears in the December 2025 print issue as ‚ÄúThe Trillion-Dollar Cost of IT‚Äôs Willful Ignorance.‚Äù&lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt;From Your Site Articles&lt;/p&gt;
        &lt;p&gt;Related Articles Around the Web&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spectrum.ieee.org/it-management-software-failures"/><published>2025-11-25T12:14:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045987</id><title>Launch HN: Onyx (YC W24) ‚Äì Open-source chat UI</title><updated>2025-11-26T15:10:01.515888+00:00</updated><content>&lt;doc fingerprint="374119d99fbe8bf8"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, Chris and Yuhong here from Onyx (&lt;/p&gt;https://github.com/onyx-dot-app/onyx&lt;p&gt;). We‚Äôre building an open-source chat that works with any LLM (proprietary + open weight) &lt;/p&gt;and&lt;p&gt; gives these LLMs the tools they need to be useful (RAG, web search, MCP, deep research, memory, etc.).&lt;/p&gt;&lt;p&gt;Demo: https://youtu.be/2g4BxTZ9ztg&lt;/p&gt;&lt;p&gt;Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company's data, lacked customization, and frankly didn't work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.&lt;/p&gt;&lt;p&gt;As the project grew, we started seeing an interesting trend‚Äîeven though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We‚Äôd hear, ‚Äúthe connectors, indexing, and search are great, but I‚Äôm going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them‚Äù.&lt;/p&gt;&lt;p&gt;Many users would add RAG, agents, and custom tools later, but much of the usage stayed ‚Äòbasic chat‚Äô. We thought: ‚Äúwhy would people co-opt an enterprise search when other AI chat solutions exist?‚Äù&lt;/p&gt;&lt;p&gt;As we continued talking to users, we realized two key points:&lt;/p&gt;&lt;p&gt;(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI&lt;/p&gt;&lt;p&gt;(2) providing this well is much harder than you might think and the bar is incredibly high&lt;/p&gt;&lt;p&gt;Consumer products like ChatGPT and Claude already provide a great experience‚Äîand chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from ‚Äúthis works‚Äù to ‚Äúthis feels magical‚Äù is not easy, and nothing else in the space has managed to do it.&lt;/p&gt;&lt;p&gt;So ~3 months ago we pivoted to Onyx, the open-source chat UI with:&lt;/p&gt;&lt;p&gt;- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who‚Äôs using AI tools for the first time.&lt;/p&gt;&lt;p&gt;- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.&lt;/p&gt;&lt;p&gt;- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.&lt;/p&gt;&lt;p&gt;Through building features like deep research and code interpreter that work across model providers, we've learned a ton of non-obvious things about engineering LLMs that have been key to making Onyx work. I'd like to share two that were particularly interesting (happy to discuss more in the comments).&lt;/p&gt;&lt;p&gt;First, context management is one of the most difficult and important things to get right. We‚Äôve found that LLMs really struggle to remember both system prompts and previous user messages in long conversations. Even simple instructions like ‚Äúignore sources of type X‚Äù in the system prompt are very often ignored. This is exacerbated by multiple tool calls, which can often feed in huge amounts of context. We solved this problem with a ‚ÄúReminder‚Äù prompt‚Äîa short 1-3 sentence blurb injected at the end of the user message that describes the non-negotiables that the LLM must abide by. Empirically, LLMs attend most to the very end of the context window, so this placement gives the highest likelihood of adherence.&lt;/p&gt;&lt;p&gt;Second, we‚Äôve needed to build an understanding of the ‚Äúnatural tendencies‚Äù of certain models when using tools, and build around them. For example, the GPT family of models are fine-tuned to use a python code interpreter that operates in a Jupyter notebook. Even if told explicitly, it refuses to add `print()` around the last line, since, in Jupyter, this last line is automatically written to stdout. Other models don‚Äôt have this strong preference, so we‚Äôve had to design our model-agnostic code interpreter to also automatically `print()` the last bare line.&lt;/p&gt;&lt;p&gt;So far, we‚Äôve had a Fortune 100 team fork Onyx and provide 10k+ employees access to every model within a single interface, and create thousands of use-case specific Assistants for every department, each using the best model for the job. We‚Äôve seen teams operating in sensitive industries completely airgap Onyx w/ locally hosted LLMs to provide a copilot that wouldn‚Äôt have been possible otherwise.&lt;/p&gt;&lt;p&gt;If you‚Äôd like to try Onyx out, follow https://docs.onyx.app/deployment/getting_started/quickstart to get set up locally w/ Docker in &amp;lt;15 minutes. For our Cloud: https://www.onyx.app/. If there‚Äôs anything you'd like to see to make it a no-brainer to replace your ChatGPT Enterprise/Claude Enterprise subscription, we‚Äôd love to hear it!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46045987"/><published>2025-11-25T14:20:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46046916</id><title>FLUX.2: Frontier Visual Intelligence</title><updated>2025-11-26T15:10:01.224080+00:00</updated><content>&lt;doc fingerprint="4d170e3094784e8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLUX.2: Frontier Visual Intelligence&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;News&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;FLUX.2 is designed for real-world creative workflows, not just demos or party tricks. It generates high-quality images while maintaining character and style consistency across multiple reference images, following structured prompts, reading and writing complex text, adhering to brand guidelines, and reliably handling lighting, layouts, and logos. FLUX.2 can edit images at up to 4 megapixels while preserving detail and coherence.&lt;/p&gt;
    &lt;head rend="h2"&gt;Black Forest Labs: Open Core&lt;/head&gt;
    &lt;p&gt;We believe visual intelligence should be shaped by researchers, creatives, and developers everywhere, not just a few. That‚Äôs why we pair frontier capability with open research and open innovation, releasing powerful, inspectable, and composable open-weight models for the community, alongside robust, production-ready endpoints for teams that need scale, reliability, and customization.&lt;/p&gt;
    &lt;p&gt;When we launched Black Forest Labs in 2024, we set out to make open innovation sustainable, building on our experience developing some of the world‚Äôs most popular open models. We‚Äôve combined open models like FLUX.1 [dev]‚Äîthe most popular open image model globally‚Äîwith professional-grade models like FLUX.1 Kontext [pro], which powers teams from Adobe to Meta and beyond. Our open core approach drives experimentation, invites scrutiny, lowers costs, and ensures that we can keep sharing open technology from the Black Forest and the Bay into the world.&lt;/p&gt;
    &lt;head rend="h2"&gt;From FLUX.1 to FLUX.2&lt;/head&gt;
    &lt;p&gt;Precision, efficiency, control, extreme realism - where FLUX.1 showed the potential of media models as powerful creative tools, FLUX.2 shows how frontier capability can transform production workflows. By radically changing the economics of generation, FLUX.2 will become an indispensable part of our creative infrastructure.&lt;/p&gt;
    &lt;p&gt;Output Versatility: FLUX.2 is capable of generating highly detailed, photoreal images along with infographics with complex typography, all at resolutions up to 4MP&lt;/p&gt;
    &lt;head rend="h2"&gt;What‚Äôs New&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multi-Reference Support: Reference up to 10 images simultaneously with the best character / product / style consistency available today.&lt;/item&gt;
      &lt;item&gt;Image Detail &amp;amp; Photorealism: Greater detail, sharper textures, and more stable lighting suitable for product shots, visualization, and photography-like use cases.&lt;/item&gt;
      &lt;item&gt;Text Rendering: Complex typography, infographics, memes and UI mockups with legible fine text now work reliably in production.&lt;/item&gt;
      &lt;item&gt;Enhanced Prompt Following: Improved adherence to complex, structured instructions, including multi-part prompts and compositional constraints.&lt;/item&gt;
      &lt;item&gt;World Knowledge: Significantly more grounded in real-world knowledge, lighting, and spatial logic, resulting in more coherent scenes with expected behavior.&lt;/item&gt;
      &lt;item&gt;Higher Resolution &amp;amp; Flexible Input/Output Ratios: Image editing on resolutions up to 4MP.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All variants of FLUX.2 offer image editing from text and multiple references in one model.&lt;/p&gt;
    &lt;head rend="h2"&gt;Available Now&lt;/head&gt;
    &lt;p&gt;The FLUX.2 family covers a spectrum of model products, from fully managed, production-ready APIs to open-weight checkpoints developers can run themselves. The overview graph below shows how FLUX.2 [pro], FLUX.2 [flex], FLUX.2 [dev], and FLUX.2 [klein] balance performance, and control&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FLUX.2 [pro]: State-of-the-art image quality that rivals the best closed models, matching other models for prompt adherence and visual fidelity while generating images faster and at lower cost. No compromise between speed and quality. ‚Üí Available now at BFL Playground, the BFL API and via our launch partners.&lt;/item&gt;
      &lt;item&gt;FLUX.2 [flex]: Take control over model parameters such as the number of steps and the guidance scale, giving developers full control over quality, prompt adherence and speed. This model excels at rendering text and fine details. ‚Üí Available now at bfl.ai/play , the BFL API and via our launch partners.&lt;/item&gt;
      &lt;item&gt;FLUX.2 [dev]: 32B open-weight model, derived from the FLUX.2 base model. The most powerful open-weight image generation and editing model available today, combining text-to-image synthesis and image editing with multiple input images in a single checkpoint. FLUX.2 [dev] weights are available on Hugging Face and can now be used locally using our reference inference code. On consumer grade GPUs like GeForce RTX GPUs you can use an optimized fp8 reference implementation of FLUX.2 [dev], created in collaboration with NVIDIA and ComfyUI. You can also sample Flux.2 [dev] via API endpoints on FAL, Replicate, Runware, Verda, TogetherAI, Cloudflare, DeepInfra. For a commercial license, visit our website.&lt;/item&gt;
      &lt;item&gt;FLUX.2 [klein] (coming soon): Open-source, Apache 2.0 model, size-distilled from the FLUX.2 base model. More powerful &amp;amp; developer-friendly than comparable models of the same size trained from scratch, with many of the same capabilities as its teacher model. Join the beta&lt;/item&gt;
      &lt;item&gt;FLUX.2 - VAE: A new variational autoencoder for latent representations that provide an optimized trade-off between learnability, quality and compression rate. This model provides the foundation for all FLUX.2 flow backbones, and an in-depth report describing its technical properties is available here. The FLUX.2 - VAE is available on HF under an Apache 2.0 license.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Generating designs with variable steps: FLUX.2 [flex] provides a ‚Äústeps‚Äù parameter, trading off typography accuracy and latency. From left to right: 6 steps, 20 steps, 50 steps.&lt;/p&gt;
    &lt;p&gt;Controlling image detail with variable steps: FLUX.2 [flex] provides a ‚Äústeps‚Äù parameter, trading off image detail and latency. From left to right: 6 steps, 20 steps, 50 steps.&lt;/p&gt;
    &lt;p&gt;The FLUX.2 model family delivers state-of-the-art image generation quality at extremely competitive prices, offering the best value across performance tiers.&lt;/p&gt;
    &lt;p&gt;For open-weights image models, FLUX.2 [dev] sets a new standard, achieving leading performance across text-to-image generation, single-reference editing, and multi-reference editing, consistently outperforming all open-weights alternatives by a significant margin.&lt;/p&gt;
    &lt;p&gt;Whether open or closed, we are committed to the responsible development of these models and services before, during, and after every release.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;p&gt;FLUX.2 builds on a latent flow matching architecture, and combines image generation and editing in a single architecture. The model couples the Mistral-3 24B parameter vision-language model with a rectified flow transformer. The VLM brings real world knowledge and contextual understanding, while the transformer captures spatial relationships, material properties, and compositional logic that earlier architectures could not render.&lt;/p&gt;
    &lt;p&gt;FLUX.2 now provides multi-reference support, with the ability to combine up to 10 images into a novel output, an output resolution of up to 4MP, substantially better prompt adherence and world knowledge, and significantly improved typography. We re-trained the model‚Äôs latent space from scratch to achieve better learnability and higher image quality at the same time, a step towards solving the ‚ÄúLearnability-Quality-Compression‚Äù trilemma. Technical details can be found in the FLUX.2 VAE blog post.&lt;/p&gt;
    &lt;head rend="h2"&gt;More Resources:&lt;/head&gt;
    &lt;head rend="h2"&gt;Into the New&lt;/head&gt;
    &lt;p&gt;We're building foundational infrastructure for visual intelligence, technology that transforms how the world is seen and understood. FLUX.2 is a step closer to multimodal models that unify perception, generation, memory, and reasoning, in an open and transparent way.&lt;/p&gt;
    &lt;p&gt;Join us on this journey. We're hiring in Freiburg (HQ) and San Francisco. View open roles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bfl.ai/blog/flux-2"/><published>2025-11-25T15:47:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46047053</id><title>New layouts with CSS Subgrid</title><updated>2025-11-26T15:10:00.870280+00:00</updated><content>&lt;doc fingerprint="a764b9b0ff408f3"&gt;
  &lt;main&gt;
    &lt;p&gt;When CSS Grid layout was first released, it came with a big asterisk: only the grid‚Äôs direct children could participate in the layout. ‚ÄúSubgrid‚Äù is a newer addition to CSS Grid which allows us to extend the grid layout down through the DOM tree.&lt;/p&gt;
    &lt;p&gt;When I first heard about subgrid, it seemed to me like a convenience, a way to make it a bit simpler to accomplish the same stuff I was already doing. As it turns out, subgrid is way more interesting than that. It opens whole new doors in terms of the UIs we can build!&lt;/p&gt;
    &lt;p&gt;In this tutorial, I‚Äôll show you some of the exciting new things we can do with subgrid. Along the way, you‚Äôll learn the basic mechanics of subgrid. We‚Äôll even go over the most common gotchas!&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingThe fundamentals&lt;/head&gt;
    &lt;p&gt;We‚Äôll get to the interesting stuff soon, but first, let‚Äôs start with the basics.&lt;/p&gt;
    &lt;p&gt;Suppose we want to implement the following mockup:&lt;/p&gt;
    &lt;p&gt;We can create this layout using a flat grid, no subgrid required. Here‚Äôs a quick implementation:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: 35% 1fr 1fr 1fr; header { grid-row: 1 / 3; } } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;My Portfolio&amp;lt;/h1&amp;gt; &amp;lt;p&amp;gt; A small selection of the works created using Blender. No robots or AI involved. &amp;lt;/p&amp;gt; &amp;lt;p&amp;gt; In a real artist portfolio, there would be more text here. &amp;lt;/p&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;img alt="‚Ä¶" src="/img/thumb-sneakers.jpg" /&amp;gt; &amp;lt;img alt="‚Ä¶" src="/img/thumb-rocket.jpg" /&amp;gt; &amp;lt;img alt="‚Ä¶" src="/img/thumb-fish.jpg" /&amp;gt; &amp;lt;img alt="‚Ä¶" src="/img/thumb-guitar-pedals.jpg" /&amp;gt; &amp;lt;img alt="‚Ä¶" src="/img/thumb-machine.jpg" /&amp;gt; &amp;lt;img alt="‚Ä¶" src="/img/thumb-particles.jpg" /&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;If we check the ‚ÄúGrid‚Äù devtools, we see that this is a 4x2 grid, with the header spanning the first two rows:&lt;/p&gt;
    &lt;p&gt;In order for this to work without subgrid, every grid participant has to be a direct child of the &lt;code&gt;.grid&lt;/code&gt; container. Sure enough, if we inspect the HTML, we see the following structure:&lt;/p&gt;
    &lt;code&gt;&amp;lt;div class="grid"&amp;gt;
  &amp;lt;header&amp;gt;
    &amp;lt;h1&amp;gt;‚Ä¶&amp;lt;/h1&amp;gt;
    &amp;lt;p&amp;gt;‚Ä¶&amp;lt;/p&amp;gt;
  &amp;lt;/header&amp;gt;
  &amp;lt;img alt="‚Ä¶" src="/img/thumb-sneakers.jpg" /&amp;gt;
  &amp;lt;img alt="‚Ä¶" src="/img/thumb-rocket.jpg" /&amp;gt;
  &amp;lt;img alt="‚Ä¶" src="/img/thumb-fish.jpg" /&amp;gt;
  &amp;lt;img alt="‚Ä¶" src="/img/thumb-guitar-pedals.jpg" /&amp;gt;
  &amp;lt;img alt="‚Ä¶" src="/img/thumb-machine.jpg" /&amp;gt;
  &amp;lt;img alt="‚Ä¶" src="/img/thumb-particles.jpg" /&amp;gt;
&amp;lt;/div&amp;gt;&lt;/code&gt;
    &lt;p&gt;Semantically, this feels a bit funky to me. I feel like these images should be grouped in a list, since we‚Äôre displaying a collection of portfolio pieces. Proper semantic markup will provide more context to folks using assistive technologies like screen readers, and to search engines that are trying to make sense of our page.&lt;/p&gt;
    &lt;p&gt;Unfortunately, adding this extra markup throws a wrench into the grid:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;div class="grid"&amp;gt; &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;My Portfolio&amp;lt;/h1&amp;gt; &amp;lt;p&amp;gt; A small selection of the works created using Blender. No robots or AI involved. &amp;lt;/p&amp;gt; &amp;lt;p&amp;gt; In a real artist portfolio, there would be more text here. &amp;lt;/p&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;!-- üëá The images are grouped in an unordered list (&amp;lt;ul&amp;gt;): --&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-sneakers.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-rocket.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-fish.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-guitar-pedals.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-machine.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-particles.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Instead of having each image occupy its own grid cell, we instead cram the entire list of images into a single cell in the second column, leaving the final two columns totally empty. üò¨&lt;/p&gt;
    &lt;p&gt;CSS subgrid allows us to extend the parent grid through that &lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; tag, so that the images can participate in the main grid. Here‚Äôs what that looks like:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: 35% 1fr 1fr 1fr; } .grid header { grid-row: 1 / 3; } /* üëá The new styles: */ .grid ul { grid-row: span 2; grid-column: span 3; display: grid; grid-template-rows: subgrid; grid-template-columns: subgrid; } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;My Portfolio&amp;lt;/h1&amp;gt; &amp;lt;p&amp;gt; A small selection of the works created using Blender. No robots or AI involved. &amp;lt;/p&amp;gt; &amp;lt;p&amp;gt; In a real artist portfolio, there would be more text here. &amp;lt;/p&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-sneakers.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-rocket.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-fish.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-guitar-pedals.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-machine.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;&amp;lt;img alt="‚Ä¶" src="/img/thumb-particles.jpg" /&amp;gt;&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;There‚Äôs a lot going on here, so let‚Äôs unpack it.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Using&lt;code&gt;grid-column&lt;/code&gt;and&lt;code&gt;grid-row&lt;/code&gt;, we assign the&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;to span three columns and two rows. This is how we specify which portion of the grid we want to share with the&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;‚Äôs descendants. We‚Äôll dig more into this later.&lt;/item&gt;
      &lt;item&gt;Next, we apply&lt;code&gt;display: grid&lt;/code&gt;to the&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;, to create a new child grid.&lt;/item&gt;
      &lt;item&gt;Finally, we pass along the row/column definitions using&lt;code&gt;grid-template-rows&lt;/code&gt;and&lt;code&gt;grid-template-columns&lt;/code&gt;. The&lt;code&gt;subgrid&lt;/code&gt;keyword is the key bit of magic that ties the two grids together, allowing each&lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt;to occupy its own cell in the parent grid.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When I first learned about subgrid, this is the sort of scenario I was imagining: cases where nested HTML elements like &lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt; + &lt;code&gt;&amp;lt;li&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;figure&amp;gt;&lt;/code&gt; + &lt;code&gt;&amp;lt;figcaption&amp;gt;&lt;/code&gt; block us from assigning the actual UI elements to the grid. CSS subgrid is a nifty lil‚Äô escape hatch for these types of situations!&lt;/p&gt;
    &lt;p&gt;That said, it's not like we haven‚Äôt had other ways to solve these kinds of problems. Instead of sharing a single CSS grid template with subgrid, we could instead combine a Flexbox row with a nested grid:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; /* Instead of CSS Grid, the parent uses Flexbox */ .wrapper { display: flex; /* The first child uses 35% of the available size: */ header { flex-basis: 35%; } /* The &amp;lt;ul&amp;gt; fills the rest of the Flex row, and creates a 3-column grid for its children: */ .grid { flex: 1; display: grid; grid-template-columns: 1fr 1fr 1fr; } } &amp;lt;/style&amp;gt; &amp;lt;div class="wrapper"&amp;gt; &amp;lt;header&amp;gt; &amp;lt;h1&amp;gt;My Portfolio&amp;lt;/h1&amp;gt; &amp;lt;p&amp;gt; A small selection of the works created using Blender. No robots or AI involved. &amp;lt;/p&amp;gt; &amp;lt;p&amp;gt; In a real artist portfolio, there would be more text here. &amp;lt;/p&amp;gt; &amp;lt;/header&amp;gt; &amp;lt;ul class="grid"&amp;gt; &amp;lt;img src="/img/thumb-sneakers.jpg" /&amp;gt; &amp;lt;img src="/img/thumb-rocket.jpg" /&amp;gt; &amp;lt;img src="/img/thumb-fish.jpg" /&amp;gt; &amp;lt;img src="/img/thumb-guitar-pedals.jpg" /&amp;gt; &amp;lt;img src="/img/thumb-machine.jpg" /&amp;gt; &amp;lt;img src="/img/thumb-particles.jpg" /&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Instead of trying to rig everything up to use a single grid structure, we can often create the same layout with nested combinations of Flexbox/Grid. And honestly, I think I prefer this approach in this case! It feels simpler to me.&lt;/p&gt;
    &lt;p&gt;But like I said earlier, this isn‚Äôt the most exciting use case for subgrid. Now that we‚Äôve covered the basic syntax, we can explore some of the more interesting possibilities. üòÑ&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingNew layout possibilities&lt;/head&gt;
    &lt;p&gt;Sticking with the artist portfolio example, let‚Äôs suppose we have this card design:&lt;/p&gt;
    &lt;p&gt;Bret‚Äôs Dead Fish&lt;/p&gt;
    &lt;p&gt;I created this render for the Animation Design module in my upcoming course, Whimsical Animations(opens in new tab). The fish is a nod to Bret Victor‚Äôs talk, ‚ÄúStop Drawing Dead Fish‚Äù, which is referenced in the course.&lt;/p&gt;
    &lt;p&gt;This looks alright on its own, but something funky happens when we put it in a grid:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: 1fr 1fr; @media (max-width: 32rem) { grid-template-columns: 1fr; } } .grid article { display: grid; grid-template-columns: 2fr 1fr; } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="A big yellow pufferfish" src="/img/thumb-fish.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Bret‚Äôs Dead Fish&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; I created this render for the Animation Design module in my upcoming course, &amp;lt;a href="https://whimsy.joshwcomeau.com/" target="_blank" &amp;gt;Whimsical Animations&amp;lt;/a &amp;gt;. The fish is a nod to Bret Victor‚Äôs talk, ‚ÄúStop Drawing Dead Fish‚Äù, which is referenced in the course. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="two white sneakers with pink details and a shiny sparkly rainbow" src="/img/thumb-sneakers.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Big Shoes To Fill&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; In this piece, I tried to create my own sneaker design, taking inspiration from the Air Force Ones I‚Äôve been wearing for most of my adult life. Topographically, shoes are a really weird shape, so this was a good challenge! &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="three colorful guitar pedals, with foot controls and knobs" src="/img/thumb-guitar-pedals.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Guitar Pedalboard&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; Over the past few years, I‚Äôve been getting back into music production, and have started collecting effect pedals. This render is my attempt to create my own pedal designs. The middle one is meant to look a bit like Zoidberg. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="A very complicated machine with a plane-style throttle, a piano keyboard, radar, a bunch of sliders and knobs, and so much more" src="/img/thumb-machine.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Infinite Supercomputer&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; I spent more time than I‚Äôd care to admit creating an enormous machine in Blender, full of weird knobs and sliders and extras. The goal was to produce a completely ridiculous cockpit-style panel. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Notice that the images are different widths? The fish image, for example, is much wider than the final supercomputer image. What‚Äôs going on here? ü§î&lt;/p&gt;
    &lt;p&gt;Well, let‚Äôs take a look at the CSS. The four cards are arranged in a two-column grid (which shrinks to a one-column grid on smaller screens):&lt;/p&gt;
    &lt;code&gt;.grid {
  display: grid;
  grid-template-columns: 1fr 1fr;

  @media (max-width: 32rem) {
    grid-template-columns: 1fr;
  }
}&lt;/code&gt;
    &lt;p&gt;We‚Äôre populating this top-level grid with four &lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt; cards. Each card declares its own two-column grid:&lt;/p&gt;
    &lt;code&gt;.grid article {
  display: grid;
  grid-template-columns: 2fr 1fr;
}&lt;/code&gt;
    &lt;p&gt;The goal here is for the image to take up the lion‚Äôs share of the space within each card, since that‚Äôs the important part (the point of an artist‚Äôs portfolio, after all, is to showcase the art!). But the &lt;code&gt;fr&lt;/code&gt; unit is designed to be flexible; it will try to match the requested ratio, but it‚Äôll adapt based on the content.&lt;/p&gt;
    &lt;p&gt;This is actually a very good thing. We could force the image column to be a fixed size, but we wouldn‚Äôt like the results:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: 1fr 1fr; @media (max-width: 32rem) { grid-template-columns: 1fr; } } .grid article { display: grid; /* üëá This is the change üëá */ grid-template-columns: 66% 1fr; } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="A big yellow pufferfish" src="/img/thumb-fish.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Bret‚Äôs Dead Fish&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; I created this render for the Animation Design module in my upcoming course, &amp;lt;a href="https://whimsy.joshwcomeau.com/" target="_blank" &amp;gt;Whimsical Animations&amp;lt;/a &amp;gt;. The fish is a nod to Bret Victor‚Äôs talk, ‚ÄúStop Drawing Dead Fish‚Äù, which is referenced in the course. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="two white sneakers with pink details and a shiny sparkly rainbow" src="/img/thumb-sneakers.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Big Shoes To Fill&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; In this piece, I tried to create my own sneaker design, taking inspiration from the Air Force Ones I‚Äôve been wearing for most of my adult life. Topographically, shoes are a really weird shape, so this was a good challenge! &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="three colorful guitar pedals, with foot controls and knobs" src="/img/thumb-guitar-pedals.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Guitar Pedalboard&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; Over the past few years, I‚Äôve been getting back into music production, and have started collecting effect pedals. This render is my attempt to create my own pedal designs. The middle one is meant to look a bit like Zoidberg. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="A very complicated machine with a plane-style throttle, a piano keyboard, radar, a bunch of sliders and knobs, and so much more" src="/img/thumb-machine.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Infinite Supercomputer&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; I spent more time than I‚Äôd care to admit creating an enormous machine in Blender, full of weird knobs and sliders and extras. The goal was to produce a completely ridiculous cockpit-style panel. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;On certain viewport sizes, the cards simply aren‚Äôt large enough to devote ‚Öîrds of the available space to the image and still contain the text content. If we force that column to have a fixed size, the text could wind up overflowing:&lt;/p&gt;
    &lt;p&gt;So, the flexibility we get from the &lt;code&gt;fr&lt;/code&gt; unit is a good thing. The problem is that each card is doing its own internal calculation. The heading in the first card (‚ÄúBret‚Äôs Dead Fish‚Äù) is made up of small words, so it can fit comfortably in a narrow column. But the final card‚Äôs heading (‚ÄúInfinite Supercomputer‚Äù) requires quite a bit more room.&lt;/p&gt;
    &lt;p&gt;If you‚Äôve worked with CSS for a while, you‚Äôve probably gotten stuck in cul-de-sacs like this. One of the hardest problems in CSS is when siblings need to be aware of each other inside nested / complex layouts.&lt;/p&gt;
    &lt;p&gt;Miraculously, subgrid offers a solution to these sorts of problems. Check this out:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: repeat(2, 2fr 1fr); @media (max-width: 32rem) { grid-template-columns: 2fr 1fr; } } .grid article { grid-column: span 2; display: grid; grid-template-columns: subgrid; } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="A big yellow pufferfish" src="/img/thumb-fish.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Bret‚Äôs Dead Fish&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; I created this render for the Animation Design module in my upcoming course, &amp;lt;a href="https://whimsy.joshwcomeau.com/" target="_blank" &amp;gt;Whimsical Animations&amp;lt;/a &amp;gt;. The fish is a nod to Bret Victor‚Äôs talk, ‚ÄúStop Drawing Dead Fish‚Äù, which is referenced in the course. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="two white sneakers with pink details and a shiny sparkly rainbow" src="/img/thumb-sneakers.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Big Shoes To Fill&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; In this piece, I tried to create my own sneaker design, taking inspiration from the Air Force Ones I‚Äôve been wearing for most of my adult life. Topographically, shoes are a really weird shape, so this was a good challenge! &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="three colorful guitar pedals, with foot controls and knobs" src="/img/thumb-guitar-pedals.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Guitar Pedalboard&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; Over the past few years, I‚Äôve been getting back into music production, and have started collecting effect pedals. This render is my attempt to create my own pedal designs. The middle one is meant to look a bit like Zoidberg. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;article&amp;gt; &amp;lt;img alt="A very complicated machine with a plane-style throttle, a piano keyboard, radar, a bunch of sliders and knobs, and so much more" src="/img/thumb-machine.jpg" /&amp;gt; &amp;lt;div class="content"&amp;gt; &amp;lt;h2&amp;gt;Infinite Supercomputer&amp;lt;/h2&amp;gt; &amp;lt;p&amp;gt; I spent more time than I‚Äôd care to admit creating an enormous machine in Blender, full of weird knobs and sliders and extras. The goal was to produce a completely ridiculous cockpit-style panel. &amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/article&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;How cool is this?? ü§Ø&lt;/p&gt;
    &lt;p&gt;In the original version, the parent grid was a one-column layout (on smaller screens), and it contained a bunch of independent grids. In this new version, the parent grid holds the two-column layout:&lt;/p&gt;
    &lt;p&gt;In the original version, the parent grid was a two-column layout, with each card assigned to a grid cell. In this new version, the parent grid grows to four columns:&lt;/p&gt;
    &lt;p&gt;Each &lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt; will span two of these columns (&lt;code&gt;grid-column: span 2&lt;/code&gt;), and inherits the column definitions from the parent (&lt;code&gt;grid-template-column: subgrid&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;As a result, the grid can dynamically react to content changes. Try erasing the word ‚ÄúSupercomputer‚Äù in the playground above and notice how the columns readjust!&lt;/p&gt;
    &lt;p&gt;As a result, the grid can dynamically react to content changes. If that final card (‚ÄúInfinite Supercomputer‚Äù) had a shorter title, the whole grid would rearrange, shrinking the text columns and allowing more of the images to be shown.&lt;/p&gt;
    &lt;p&gt;Honestly, I‚Äôm not really used to thinking about layouts like this. Before subgrid, I would‚Äôve solved this problem by picking a very narrow fixed width for the image column, so that there was always enough space for the text column. This would ensure that the layout never breaks, but remember, the goal of a portfolio is to display as much of the images as possible! Subgrid allows us to adapt to the content dynamically, so that we can produce the best possible UI in various contexts.&lt;/p&gt;
    &lt;p&gt;This is where subgrid truly shines, in my opinion. By extending the grid downwards, it means that we can allow siblings to become responsive to each other, in a way that hasn‚Äôt been possible until now. ‚ú®&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingSubgrid Gotchas&lt;/head&gt;
    &lt;p&gt;As I‚Äôve been experimenting with subgrid, there have been a couple of things that have caught me off guard. Let‚Äôs go over them, so that you‚Äôre well-prepared!&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this headingReserving space for the subgrid&lt;/head&gt;
    &lt;p&gt;Sharing columns with subgrid tends to be pretty intuitive, but things get a bit more quirky when sharing rows.&lt;/p&gt;
    &lt;p&gt;To help me explain, let‚Äôs look at a different example. Suppose our design team wants us to build the following pricing UI, to show the features included at different price tiers:&lt;/p&gt;
    &lt;p&gt;This seems like a pretty straightforward task, but the devil is in the details. If we use a typical Grid or Flexbox strategy, we‚Äôll wind up with asymmetrical rows:&lt;/p&gt;
    &lt;p&gt;This might look right at a quick glance, but notice how the features don‚Äôt line up. In the original mockup, the first line of every feature is perfectly aligned with the same feature in the opposite card!&lt;/p&gt;
    &lt;p&gt;Historically, the only way to achieve this sort of thing in CSS has been with Table layout (using &lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt; tags, or &lt;code&gt;display: table&lt;/code&gt;). It‚Äôs not really practical to use a table here, though, since we‚Äôd need each card to be its own column in the same table, and we can‚Äôt easily style table columns.&lt;/p&gt;
    &lt;p&gt;Subgrid to the rescue! At least in theory, we should be able to let both cards share a single grid, like this:&lt;/p&gt;
    &lt;p&gt;Unfortunately, there‚Äôs a very easy mistake to make. See if you can spot the problem with this code:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: 1fr 1fr; .card, .card ul { display: grid; grid-template-rows: subgrid; } } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;div class="card"&amp;gt; &amp;lt;h2&amp;gt;Pro Package&amp;lt;/h2&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;Up to 4 team accounts.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Basic workflows.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Connect with Slack‚Ñ¢.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Up to 3 knowledge bases, with 100gb total storage.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Limited AI assistant (depending on region and language).&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class="card"&amp;gt; &amp;lt;h2&amp;gt;Enterprise Package&amp;lt;/h2&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;Unlimited team accounts.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Advanced, fully-customizeable workflows.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Connect with Slack‚Ñ¢, Microsoft Teams‚Ñ¢, Discord‚Ñ¢, and 5 other popular integrations.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Unlimited knowledge bases.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Unlimited robots. ü§ñ&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;All of the text is clumped up in the same spot! If we inspect this using the Grid devtools, we discover that we‚Äôve wound up with a 2√ó1 grid. All of the content within each card is smushed into a single row. üò¨&lt;/p&gt;
    &lt;p&gt;Typically, with CSS Grid, we don‚Äôt need to explicitly define any rows. I usually define the number of columns, and trust the grid algorithm to add new rows as-needed, so that each child gets its own grid cell.&lt;/p&gt;
    &lt;p&gt;Unfortunately, with subgrid, it doesn't quite work like this. By default, our child grid will only span a single grid column/row. If we want it to occupy multiple rows, we need to reserve them explicitly.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs what the fix looks like:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: 1fr 1fr; .card { /* Instruct the .card to span across 6 rows: */ grid-row: span 6; display: grid; grid-template-rows: subgrid; } .card ul { /* Instruct the list within to span across 5 rows: */ grid-row: span 5; display: grid; grid-template-rows: subgrid; } } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;div class="card"&amp;gt; &amp;lt;h2&amp;gt;Pro Package&amp;lt;/h2&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;Up to 4 team accounts.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Basic workflows.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Connect with Slack‚Ñ¢.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Up to 3 knowledge bases, with 100gb total storage.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Limited AI assistant (depending on region and language).&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;div class="card"&amp;gt; &amp;lt;h2&amp;gt;Enterprise Package&amp;lt;/h2&amp;gt; &amp;lt;ul&amp;gt; &amp;lt;li&amp;gt;Unlimited team accounts.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Advanced, fully-customizeable workflows.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Connect with Slack‚Ñ¢, Microsoft Teams‚Ñ¢, Discord‚Ñ¢, and 5 other popular integrations.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Unlimited knowledge bases.&amp;lt;/li&amp;gt; &amp;lt;li&amp;gt;Unlimited robots. ü§ñ&amp;lt;/li&amp;gt; &amp;lt;/ul&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;The extra-complicated thing about this setup is that we‚Äôre extending the grid down two layers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First, we extend it to&lt;code&gt;&amp;lt;div class="card"&amp;gt;&lt;/code&gt;, which includes an&lt;code&gt;&amp;lt;h2&amp;gt;&lt;/code&gt;and a&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Next, we extend it to that child&lt;code&gt;&amp;lt;ul&amp;gt;&lt;/code&gt;, so that the individual list items each get their own row.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are 5 list items in this case, which means we need 6 rows total (one for the heading, five for the list). If we don‚Äôt ‚Äúreserve‚Äù all of these rows explicitly, then the browser will shove everything into a single row and make a big mess, like we saw above. I‚Äôm not exactly sure why the typical auto-assignment algorithm doesn‚Äôt work with subgrid, but I assume there‚Äôs some technical limitation.&lt;/p&gt;
    &lt;p&gt;This is mind-bending stuff, but it becomes intuitive with a bit of practice. The thing to keep in mind is that subgrids, by default, will only occupy a single grid cell. In order to spread a group of items across multiple grid rows, the subgrid must first stretch across that area itself.&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this headingNested grid numbers&lt;/head&gt;
    &lt;p&gt;We got the gnarliest gotcha out of the way first! I promise the next two won‚Äôt be as intellectually taxing. üòÖ&lt;/p&gt;
    &lt;p&gt;In CSS grid, the lines between each column are numbered, and we can assign grid children using these numbers. This is something we explore in greater depth in ‚ÄúAn Interactive Guide to CSS Grid‚Äù:&lt;/p&gt;
    &lt;p&gt;When we inherit a portion of the grid using &lt;code&gt;grid-template-rows: subgrid&lt;/code&gt; or &lt;code&gt;grid-template-columns: subgrid&lt;/code&gt;, the line numbers get reset.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs an example of what I‚Äôm talking about:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: repeat(4, 1fr); grid-template-rows: repeat(4, 1fr); .subgrid { grid-column: 2 / 5; grid-row: 2 / 5; display: grid; grid-template-columns: subgrid; grid-template-rows: subgrid; .child { grid-column: 2; grid-row: 2; } } } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;div class="subgrid"&amp;gt; &amp;lt;div class="child"&amp;gt;&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;Our yellow &lt;code&gt;.child&lt;/code&gt; is assigned to &lt;code&gt;grid-column: 2&lt;/code&gt; and &lt;code&gt;grid-row: 2&lt;/code&gt;, but it winds up sitting in the third of the grid‚Äôs four rows and columns. ü§î&lt;/p&gt;
    &lt;p&gt;It turns out that while the grid template is inherited with subgrid, the line indexes don‚Äôt. Our &lt;code&gt;.subgrid&lt;/code&gt; grid inherits columns/rows 2 through 4, but internally, they get re-indexed as 1 through 3.&lt;/p&gt;
    &lt;p&gt;We can see this using the grid devtools in the Elements inspector:&lt;/p&gt;
    &lt;p&gt;In my mind, I had been thinking of line numbers as unique IDs, and so I figured that if the subgrid is inheriting the grid template, those IDs would come along for the ride too. But if we think of these line numbers as indices rather than IDs, this behaviour makes a lot more sense. In every grid, the first line has index 1, even if that row/column is inherited from a parent grid.&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this headingIncompatibility with fluid grids&lt;/head&gt;
    &lt;p&gt;Perhaps the most famous grid snippet is this lil‚Äô guy:&lt;/p&gt;
    &lt;code&gt;.grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(100px, 1fr));
}&lt;/code&gt;
    &lt;p&gt;This is a fluid design concept. Instead of specifying different grid templates at different viewport sizes using media queries, we specify that we want as many columns as possible, as long as they‚Äôre all at least 100px wide (or whatever the minimum specified size is).&lt;/p&gt;
    &lt;p&gt;Try resizing the ‚ÄúResult‚Äù pane by dragging the vertical divider, and notice how the columns adjust:&lt;/p&gt;
    &lt;p&gt;Code Playground&lt;/p&gt;
    &lt;quote&gt;&amp;lt;style&amp;gt; .grid { display: grid; grid-template-columns: repeat( auto-fill, minmax(100px, 1fr) ); } &amp;lt;/style&amp;gt; &amp;lt;div class="grid"&amp;gt; &amp;lt;div class="child"&amp;gt;A&amp;lt;/div&amp;gt; &amp;lt;div class="child"&amp;gt;B&amp;lt;/div&amp;gt; &amp;lt;div class="child"&amp;gt;C&amp;lt;/div&amp;gt; &amp;lt;div class="child"&amp;gt;D&amp;lt;/div&amp;gt; &amp;lt;div class="child"&amp;gt;E&amp;lt;/div&amp;gt; &amp;lt;div class="child"&amp;gt;F&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt;&lt;/quote&gt;
    &lt;p&gt;This is a very cool approach, but unfortunately, it doesn‚Äôt quite work with some of the new UI possibilities introduced by subgrid. For example, the ‚Äúportfolio card‚Äù grid we explored earlier requires that we list the specific number of columns. We can‚Äôt use &lt;code&gt;auto-fill&lt;/code&gt; or &lt;code&gt;auto-fit&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;(Or, more accurately, I haven‚Äôt found a way to use fluid design in conjunction with that subgrid pattern. If you‚Äôve found a solution, please let me know on Bluesky!(opens in new tab))&lt;/p&gt;
    &lt;head rend="h3"&gt;Link to this headingSupporting older browsers&lt;/head&gt;
    &lt;p&gt;Subgrid has been supported across all major browsers since 2023. Surprisingly, though, subgrid support still hasn‚Äôt hit 90% yet (according to caniuse(opens in new tab), as of November 2025).&lt;/p&gt;
    &lt;p&gt;This presents a bit of a challenge. As we‚Äôve seen in this blog post, subgrid enables us to solve problems that were previously unsolvable. What should we do for folks who visit using older browsers?&lt;/p&gt;
    &lt;p&gt;Well, we can‚Äôt produce an identical experience, but I think with a bit of creative problem-solving, we can come up with alternative layouts that are good enough. Using the artist portfolio example from earlier, we could reconfigure the card layout so that the image is stacked vertically, rather than horizontally:&lt;/p&gt;
    &lt;p&gt;We can accomplish this using feature queries. Here‚Äôs what the code looks like:&lt;/p&gt;
    &lt;code&gt;@supports not (grid-template-columns: subgrid) {
  .grid article {
    grid-template-columns: 1fr;
    grid-template-rows: 140px 1fr;
  }
}&lt;/code&gt;
    &lt;p&gt;Alternatively, I could have kept the two-column layout but restricted the image column‚Äôs width (eg. &lt;code&gt;grid-template-columns: 50px 1fr&lt;/code&gt;). This would‚Äôve preserved the original design for everyone. But I think when it comes to fallbacks, the goal isn't to be as similar to the original as possible, the goal is to produce the best experience possible. In this particular case, I think a single-column fallback experience works better.&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingThe darkest week of the year&lt;/head&gt;
    &lt;p&gt;I‚Äôm publishing this post on November 25th, a frankly miserable time of year up here in the northern hemisphere üòÖ. The days are getting shorter, the weather is getting colder, and my favourite season (autumn) is transmogrifying into my least favourite season (winter).&lt;/p&gt;
    &lt;p&gt;But there is one silver lining about this time of year: everything‚Äôs on sale for Black Friday! üéà&lt;/p&gt;
    &lt;p&gt;For the past few years, my main focus has been creating comprehensive interactive online courses. I have two flagship courses, CSS for JavaScript Developers(opens in new tab) and The Joy of React(opens in new tab), and this week, they‚Äôre up to 50% off(opens in new tab)!&lt;/p&gt;
    &lt;p&gt;If you found this blog post useful, you‚Äôll likely get so much out of my CSS course. We focus on understanding CSS at a deeper level, building an intuition for how the language actually works. No more memorizing snippets, or trying random stuff hoping that the UI will snap into the right shape!&lt;/p&gt;
    &lt;p&gt;I know that in the world of e-commerce, things go on sale every other week. That‚Äôs not how I roll, though. I only have one or two sales a year. So this truly is a rare chance to pick up one of my courses for a deep discount. ‚ú®&lt;/p&gt;
    &lt;p&gt;You can learn more here:&lt;/p&gt;
    &lt;head rend="h2"&gt;Link to this headingIn conclusion&lt;/head&gt;
    &lt;p&gt;One of the coolest websites I‚Äôve seen in a while is Stripe‚Äôs developer site(opens in new tab).&lt;/p&gt;
    &lt;p&gt;If we pop open the grid devtools, we see that the entire layout is one big grid, passed down through several layers of subgrids:&lt;/p&gt;
    &lt;p&gt;This is incredibly cool, and I think it‚Äôs a great demonstration of the maximalist things we can do with subgrid. But, honestly, I think I‚Äôm more excited by the smaller-scale stuff we‚Äôve seen in this blog post. üòÖ&lt;/p&gt;
    &lt;p&gt;Subgrid is a very versatile new tool, and it can be a bit intimidating and overwhelming, but hopefully this post has given you some ideas for the sorts of things you can start experimenting with. The good news is that you don‚Äôt have to re-architect your entire project in order to start using subgrid! The most powerful parts of subgrid are things which can be incrementally adopted.&lt;/p&gt;
    &lt;p&gt;Another special thanks to Kevin Powell. The examples in this blog post would‚Äôve been far less compelling without his inspiration. üòÑ&lt;/p&gt;
    &lt;head rend="h3"&gt;Last updated on&lt;/head&gt;
    &lt;p&gt;November 25th, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.joshwcomeau.com/css/subgrid/"/><published>2025-11-25T15:57:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46048252</id><title>Show HN: We built an open source, zero webhooks payment processor</title><updated>2025-11-26T15:10:00.288466+00:00</updated><content>&lt;doc fingerprint="f056b3782f0b3458"&gt;
  &lt;main&gt;
    &lt;p&gt; The easiest way to make internet money. &lt;lb/&gt; Get Started &lt;lb/&gt; ¬∑ Quickstart ¬∑ Website ¬∑ Issues ¬∑ Discord &lt;/p&gt;
    &lt;p&gt;Infinite pricing models, one source of truth, zero webhooks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Default Stateless Say goodbye to webhooks, &lt;code&gt;"subscriptions"&lt;/code&gt;db tables,&lt;code&gt;customer_id&lt;/code&gt;columns,&lt;code&gt;PRICE_ID&lt;/code&gt;env variables, or manually mapping your plans to prices to features and back.&lt;/item&gt;
      &lt;item&gt;Single Source of Truth: Read your latest customer billing state from Flowglad, including feature access and usage meter credits&lt;/item&gt;
      &lt;item&gt;Access Data Using Your Ids: Query customer state by your auth's user ids. Refer to prices, features, and usage meters via slugs you define.&lt;/item&gt;
      &lt;item&gt;Full-Stack SDK: Access your customer's data on the backend using &lt;code&gt;flowgladServer.getBilling()&lt;/code&gt;, or in your React frontend using our&lt;code&gt;useBilling()&lt;/code&gt;hook&lt;/item&gt;
      &lt;item&gt;Adaptable: Iterate on new pricing models in testmode, and push them to prod in a click. Seamlessly rotate pricing models in your app without any redeployment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First, install the packages necessary Flowglad packages based on your project setup:&lt;/p&gt;
    &lt;code&gt;# Next.js Projects
bun add @flowglad/nextjs

# React + Express projects:
bun add @flowglad/react @flowglad/express

# All other React + Node Projects
bun add @flowglad/react @flowglad/server&lt;/code&gt;
    &lt;p&gt;Flowglad integrates seamlessly with your authentication system and requires only a few lines of code to get started in your Next.js app. Setup typically takes under a minute:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Configure Your Flowglad Server Client&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create a utility to generate your Flowglad server instance. Pass your own customer/user/organization IDs‚ÄîFlowglad never requires its own customer IDs to be managed in your app:&lt;/p&gt;
    &lt;code&gt;// utils/flowglad.ts
import { FlowgladServer } from '@flowglad/nextjs/server'

export const flowglad = (customerExternalId: string) =&amp;gt; {
  return new FlowgladServer({
    customerExternalId,
    getCustomerDetails: async (externalId) =&amp;gt; {
      // e.g. Fetch user info from your DB using your user/org/team ID
      const user = await db.users.findOne({ id: externalId })
      if (!user) throw new Error('User not found')
      return { email: user.email, name: user.name }
    },
  })
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Expose the Flowglad API Handler&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Add an API route so the Flowglad client can communicate securely with your backend:&lt;/p&gt;
    &lt;code&gt;// app/api/flowglad/[...path]/route.ts
import { nextRouteHandler } from '@flowglad/nextjs/server'
import { flowglad } from '@/utils/flowglad'

export const { GET, POST } = nextRouteHandler({
  flowglad,
  getCustomerExternalId: async (req) =&amp;gt; {
    // Extract your user/org/team ID from session/auth.
    // For B2C: return user.id from your DB
    // For B2B: return organization.id or team.id
    const userId = await getUserIdFromRequest(req)
    if (!userId) throw new Error('User not authenticated')
    return userId
  },
})&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Wrap Your App with the Provider&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In your root layout (App Router) or _app (Pages Router):&lt;/p&gt;
    &lt;code&gt;import { FlowgladProvider } from '@flowglad/nextjs'

// App Router example (app/layout.tsx)
export default function RootLayout({ children }) {
  return (
    &amp;lt;html&amp;gt;
      &amp;lt;body&amp;gt;
        &amp;lt;FlowgladProvider loadBilling={true}&amp;gt;
          {children}
        &amp;lt;/FlowgladProvider&amp;gt;
      &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
  )
}&lt;/code&gt;
    &lt;p&gt;That‚Äôs it‚ÄîFlowglad will use your app‚Äôs internal user IDs for all billing logic and integrate billing status into your frontend in real time.&lt;/p&gt;
    &lt;p&gt;B2C apps: Use &lt;code&gt;user.id&lt;/code&gt; as the customer ID.&lt;lb/&gt; B2B apps: Use &lt;code&gt;organization.id&lt;/code&gt; or &lt;code&gt;team.id&lt;/code&gt; as the customer ID.&lt;/p&gt;
    &lt;p&gt;Flowglad does not require you to change your authentication system or manage Flowglad customer IDs. Just pass your own!&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use &lt;code&gt;useBilling&lt;/code&gt;on your frontend, and&lt;code&gt;flowglad(userId).getBilling()&lt;/code&gt;on your backend&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;'use client'

import { useBilling } from '@flowglad/nextjs'

export function FeatureGate({ featureSlug, children }) {
  const { loaded, errors, checkFeatureAccess } = useBilling()

  if (!loaded || !checkFeatureAccess) {
    return &amp;lt;p&amp;gt;Loading billing state‚Ä¶&amp;lt;/p&amp;gt;
  }

  if (errors?.length) {
    return &amp;lt;p&amp;gt;Unable to load billing data right now.&amp;lt;/p&amp;gt;
  }

  return checkFeatureAccess(featureSlug)
    ? children
    : &amp;lt;p&amp;gt;You need to upgrade to unlock this feature.&amp;lt;/p&amp;gt;
}&lt;/code&gt;
    &lt;code&gt;import { useBilling } from '@flowglad/nextjs'

export function UsageBalanceIndicator({ usageMeterSlug }) {
  const { loaded, errors, checkUsageBalance, createCheckoutSession } = useBilling()

  if (!loaded || !checkUsageBalance) {
    return &amp;lt;p&amp;gt;Loading usage‚Ä¶&amp;lt;/p&amp;gt;
  }

  const usage = checkUsageBalance(usageMeterSlug)

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;h3&amp;gt;Usage Balance&amp;lt;/h3&amp;gt;
      &amp;lt;p&amp;gt;
        Remaining:{' '}
        {usage ? `${usage.availableBalance} credits available` : &amp;lt;button onClick={() =&amp;gt; createCheckoutSession({ 
            priceSlug: 'pro_plan',
            autoRedirect: true
          })}
        /&amp;gt;}
      &amp;lt;/p&amp;gt;
    &amp;lt;/div&amp;gt;
  )
}&lt;/code&gt;
    &lt;code&gt;import { NextResponse } from 'next/server'
import { flowglad } from '@/utils/flowglad'

const hasFastGenerations = async () =&amp;gt; {
  // ...
  const user = await getUser()

  const billing = await flowglad(user.id).getBilling()
  const hasAccess = billing.checkFeatureAccess('fast_generations')
  if (hasAccess) {
    // run fast generations
  } else {
    // fall back to normal generations
  }
}&lt;/code&gt;
    &lt;code&gt;import { flowglad } from '@/utils/flowglad'

const processChatMessage = async (params: { chat: string }) =&amp;gt; {
  // Extract your app's user/org/team ID,
  // whichever corresponds to your customer
  const user = await getUser()

  const billing = await flowglad(user.id).getBilling()
  const usage = billing.checkUsageBalance('chat_messages')
  if (usage.availableBalance &amp;gt; 0) {
    // run chat request
  } else {
    throw Error(`User ${user.id} does not have sufficient usage credits`)
  }
}&lt;/code&gt;
    &lt;p&gt;First, set up a pricing model. You can do so in the dashboard in just a few clicks using a template, that you can then customize to suit your specific needs.&lt;/p&gt;
    &lt;p&gt;We currently have templates for the following pricing models:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Usage-limit + Subscription Hybrid (like Cursor)&lt;/item&gt;
      &lt;item&gt;Unlimited Usage (like ChatGPT consumer)&lt;/item&gt;
      &lt;item&gt;Tiered Access and Usage Credits (like Midjourney)&lt;/item&gt;
      &lt;item&gt;Feature-Gated Subscription (like Linear)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And more on the way. If you don't see a pricing model from our templates that suits you, you can always make one from scratch.&lt;/p&gt;
    &lt;p&gt;In the last 15 years, the market has given developers more options than ever for every single part of their stack. But when it comes to payments, there have been virtually zero new entrants. The existing options are slim, and almost all of them require us to talk to sales to even set up an account. When it comes to self-serve payments, there are even fewer options.&lt;/p&gt;
    &lt;p&gt;The result? The developer experience and cost of payments has barely improved in that time. Best in class DX in payments feels eerily suspended in 2015. Meanwhile, we've enjoyed constant improvements in auth, compute, hosting, and practically everything else.&lt;/p&gt;
    &lt;p&gt;Flowglad wants to change that.&lt;/p&gt;
    &lt;p&gt;We're building a payments layer that lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Think about billing and payments as little as possible&lt;/item&gt;
      &lt;item&gt;Spend as little time on integration and maintenance as possible&lt;/item&gt;
      &lt;item&gt;Get as much out of your single integration as possible&lt;/item&gt;
      &lt;item&gt;Unlock more payment providers from a single integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Achieving this mission will take time. It will be hard. It might even make some people unhappy. But with AI bringing more and more developers on line and exploding the complexity of startup billing, the need is more urgent than ever.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/flowglad/flowglad"/><published>2025-11-25T17:33:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46049932</id><title>A new bridge links the math of infinity to computer science</title><updated>2025-11-26T15:10:00.141945+00:00</updated><content>&lt;doc fingerprint="b72c931205918bb9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A New Bridge Links the Strange Math of Infinity to Computer Science&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;All of modern mathematics is built on the foundation of set theory, the study of how to organize abstract collections of objects. But in general, research mathematicians don‚Äôt need to think about it when they‚Äôre solving their problems. They can take it for granted that sets behave the way they‚Äôd expect, and carry on with their work.&lt;/p&gt;
    &lt;p&gt;Descriptive set theorists are an exception. This small community of mathematicians never stopped studying the fundamental nature of sets ‚Äî particularly the strange infinite ones that other mathematicians ignore.&lt;/p&gt;
    &lt;p&gt;Their field just got a lot less lonely. In 2023, a mathematician named Anton Bernshteyn published a deep and surprising connection between the remote mathematical frontier of descriptive set theory and modern computer science.&lt;/p&gt;
    &lt;p&gt;He showed that all problems about certain kinds of infinite sets can be rewritten as problems about how networks of computers communicate. The bridge connecting the disciplines surprised researchers on both sides. Set theorists use the language of logic, computer scientists the language of algorithms. Set theory deals with the infinite, computer science with the finite. There‚Äôs no reason why their problems should be related, much less equivalent.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis is something really weird,‚Äù said V√°clav Rozho≈à, a computer scientist at Charles University in Prague. ‚ÄúLike, you are not supposed to have this.‚Äù&lt;/p&gt;
    &lt;p&gt;Since Bernshteyn‚Äôs result, his peers have been exploring how to move back and forth across the bridge to prove new theorems on either side, and how to extend that bridge to new classes of problems. Some descriptive set theorists are even starting to apply insights from the computer science side to reorganize the landscape of their entire field, and to rethink the way they understand infinity.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis whole time we‚Äôve been working on very similar problems without directly talking to each other,‚Äù said Clinton Conley, a descriptive set theorist at Carnegie Mellon University. ‚ÄúIt just opens the doors to all these new collaborations.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Broken Sets&lt;/head&gt;
    &lt;p&gt;Bernshteyn was an undergraduate when he first heard of descriptive set theory ‚Äî as an example of a field that had once mattered, then decayed to nothing. More than a year would pass before he found out the professor had been wrong.&lt;/p&gt;
    &lt;p&gt;In 2014, as a first-year graduate student at the University of Illinois, Bernshteyn took a logic course with Anush Tserunyan, who would later become one of his advisers. She corrected the misconception. ‚ÄúShe should take all the credit for me being in this field,‚Äù he said. ‚ÄúShe really made it seem that logic and set theory is this glue that connects all different parts of math.‚Äù&lt;/p&gt;
    &lt;p&gt;Descriptive set theory dates back to Georg Cantor, who proved in 1874 that there are different sizes of infinity. The set of whole numbers (0, 1, 2, 3, ‚Ä¶), for instance, is the same size as the set of all fractions, but smaller than the set of all real numbers.&lt;/p&gt;
    &lt;p&gt;At the time, mathematicians were deeply uncomfortable with this menagerie of different infinities. ‚ÄúIt‚Äôs hard to wrap your head around,‚Äù said Bernshteyn, who is now at the University of California, Los Angeles.&lt;/p&gt;
    &lt;p&gt;Partly in response to that discomfort, mathematicians developed a different notion of size ‚Äî one that described, say, how much length or area or volume a set might occupy, rather than the number of elements it contained. This notion of size is known as a set‚Äôs ‚Äúmeasure‚Äù (in contrast to Cantor‚Äôs notion of size, which is a set‚Äôs ‚Äúcardinality‚Äù). One of the simplest types of measure ‚Äî the Lebesgue measure ‚Äî quantifies a set‚Äôs length. While the set of real numbers between zero and 1 and the set of real numbers between zero and 10 are both infinite and have the same cardinality, the first has a Lebesgue measure of 1 and the second a Lebesgue measure of 10.&lt;/p&gt;
    &lt;p&gt;To study more complicated sets, mathematicians use other types of measures. The uglier a set is, the fewer ways there are to measure it. Descriptive set theorists ask questions about which sets can be measured according to different definitions of ‚Äúmeasure.‚Äù They then arrange them in a hierarchy based on the answers to those questions. At the top are sets that can be constructed easily and studied using any notion of measure you want. At the bottom are ‚Äúunmeasurable‚Äù sets, which are so complicated they can‚Äôt be measured at all. ‚ÄúThe word people often use is ‚Äòpathological,‚Äô‚Äù Bernshteyn said. ‚ÄúNonmeasurable sets are really bad. They‚Äôre counterintuitive, and they don‚Äôt behave well.‚Äù&lt;/p&gt;
    &lt;p&gt;This hierarchy doesn‚Äôt just help set theorists map out the landscape of their field; it also gives them insights into what tools they can use to tackle more typical problems in other areas of math. Mathematicians in some fields, such as dynamical systems, group theory and probability theory, need information about the size of the sets they‚Äôre using. A set‚Äôs position in the hierarchy determines what tools they can use to solve their problem.&lt;/p&gt;
    &lt;p&gt;Descriptive set theorists are thus like librarians, tending to a massive bookshelf of different kinds of infinite sets (and the different ways of measuring them). Their job is to take a problem, determine how complicated a set its solution requires, and place it on the proper shelf, so that other mathematicians can take note.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making a Choice&lt;/head&gt;
    &lt;p&gt;Bernshteyn belongs to a group of librarians who sort problems about infinite sets of nodes connected by edges, called graphs. In particular, he studies graphs that have infinitely many separate pieces, each containing infinitely many nodes. Most graph theorists don‚Äôt study these kinds of graphs; they focus on finite ones instead. But such infinite graphs can represent and provide information about dynamical systems and other important kinds of sets, making them a major area of interest for descriptive set theorists.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs an example of the kind of infinite graph that Bernshteyn and his colleagues might study. Start with a circle, which contains infinitely many points. Pick one point: This will be your first node. Then move a fixed distance around the circle‚Äôs circumference. This gives you a second node. For example, you might move one-fifth of the way around the circle. Connect the two nodes with an edge. Move the same distance to a third node, and connect it to the previous one. And so on.&lt;/p&gt;
    &lt;p&gt;If you move one-fifth of the way around the circle each time, it‚Äôll take five steps to get back where you started. In general, if you move any distance that can be written as a fraction, the nodes will form a closed loop. But if the distance can‚Äôt be written as a fraction, the process will go on forever. You‚Äôll get an infinite number of connected nodes.&lt;/p&gt;
    &lt;p&gt;But that‚Äôs not all: This infinitely long sequence forms only the first piece of your graph. Even though it contains infinitely many nodes, it doesn‚Äôt contain all the points on the circle. To generate the other pieces of the graph, start at one of those other points. Now move the same distance at each step as you did in the first piece. You‚Äôll end up building a second infinite sequence of connected nodes, totally disconnected from the first.&lt;/p&gt;
    &lt;p&gt;Do this for every possible new starting point on the circle. You‚Äôll get a graph consisting of infinitely many separate pieces, with each piece made of an infinite number of nodes.&lt;/p&gt;
    &lt;p&gt;Mathematicians can then ask whether it‚Äôs possible to color the nodes in this graph so that they obey certain rules. Using just two colors, for instance, can you color every node in the graph so that no two connected nodes are the same color? The solution might seem straightforward. Look at the first piece of your graph, pick a node, and color it blue. Then color the rest of the piece‚Äôs nodes in an alternating pattern: yellow, blue, yellow, blue. Do the same for every piece in your graph: Pick a node, color it blue, then alternate colors. Ultimately, you‚Äôll use just two colors to achieve your task.&lt;/p&gt;
    &lt;p&gt;But to accomplish this coloring, you had to rely on a hidden assumption that set theorists call the axiom of choice. It‚Äôs one of the nine fundamental building blocks from which all mathematical statements are constructed. According to this axiom, if you start with a bunch of sets, you can choose one item from each of those sets to create a new set ‚Äî even if you have infinitely many sets to choose from. This axiom is useful, in that it allows mathematicians to prove all sorts of statements of interest. But it also leads to strange paradoxes. Descriptive set theorists avoid it.&lt;/p&gt;
    &lt;p&gt;Your graph had infinitely many pieces. This corresponds to having infinitely many sets. You chose one item from each set ‚Äî the first point you decided to color blue in each of the pieces. All those blue points formed a new set. You used the axiom of choice.&lt;/p&gt;
    &lt;p&gt;Which leads to a problem when you color the rest of the nodes in alternating patterns of blue and yellow. You‚Äôve colored each node (which has zero length) separately, without any understanding of how nodes relate to one another when they come from different pieces of the graph. This means that you can‚Äôt describe the set of all the graph‚Äôs blue nodes, or the set of all its yellow nodes, in terms of length either. In other words, these sets are unmeasurable. Mathematicians can‚Äôt say anything useful about them.&lt;/p&gt;
    &lt;p&gt;To descriptive set theorists, this is unsatisfying. And so they want to figure out a way to color the graph in a continuous way ‚Äî a way that doesn‚Äôt use the axiom of choice, and that gives them measurable sets.&lt;/p&gt;
    &lt;p&gt;To do this, remember how you built the first piece of your graph: You picked a node on a circle and connected it to a second node some distance away. Now color the first node blue, the second yellow, and the entire arc between them blue. Similarly, color the arc between the second and third nodes yellow. Color the third arc blue. And so on.&lt;/p&gt;
    &lt;p&gt;Soon, you‚Äôll have made it almost completely around the circle ‚Äî meaning that you‚Äôve assigned a color to all the nodes in your graph except for the ones that fall in a small, leftover segment. Say the last arc you colored was yellow. How do you color this final, smaller segment? You can‚Äôt use blue, because these nodes will connect to nodes in the original arc you colored blue. But you also can‚Äôt use yellow, because these nodes connect back to yellow ones from the previous arc.&lt;/p&gt;
    &lt;p&gt;You have to use a third color ‚Äî say, green ‚Äî to complete your coloring.&lt;/p&gt;
    &lt;p&gt;Still, the sets of blue, yellow and green nodes you end up with are all just pieces of the circle‚Äôs circumference, rather than the scatterings of points you ended up with when you used the axiom of choice. You can calculate the lengths of these sets. They‚Äôre measurable.&lt;/p&gt;
    &lt;p&gt;Descriptive set theorists therefore place the two-color version of the problem on the lowest shelf in their hierarchy (for unmeasurable sets), while the three-color problem goes on a much higher shelf of problems ‚Äî ones where lots of notions of measure can be applied.&lt;/p&gt;
    &lt;p&gt;Bernshteyn spent his years in graduate school studying such coloring problems, shelving them one by one. Then, shortly after he finished his degree, he stumbled on a potential way to shelve them all at once ‚Äî and to show that these problems have a much deeper and more mathematically relevant structure than anyone had realized.&lt;/p&gt;
    &lt;head rend="h2"&gt;Round by Round&lt;/head&gt;
    &lt;p&gt;From time to time, Bernshteyn enjoys going to computer science talks, where graphs are finite and represent networks of computers.&lt;/p&gt;
    &lt;p&gt;In 2019, one of those talks changed the course of his career. It was about ‚Äúdistributed algorithms‚Äù ‚Äî sets of instructions that run simultaneously on multiple computers in a network to accomplish a task without a central coordinator.&lt;/p&gt;
    &lt;p&gt;Say you have a bunch of Wi-Fi routers in a building. Nearby routers can interfere with each other if they use the same communication frequency channel. So each router needs to choose a different channel from the ones used by its immediate neighbors.&lt;/p&gt;
    &lt;p&gt;Computer scientists can reframe this as a coloring problem on a graph: Represent each router as a node, and connect nearby ones with edges. Using just two colors (representing two different frequency channels), find a way to color each node so that no two connected nodes are the same color.&lt;/p&gt;
    &lt;p&gt;But there‚Äôs a catch: Nodes can only communicate with their immediate neighbors, using so-called local algorithms. First, each node runs the same algorithm and assigns itself a color. It then communicates with its neighbors to learn how other nodes are colored in a small region around it. Then it runs the algorithm again to decide whether to keep its color or switch it. It repeats this step until the whole network has a proper coloring.&lt;/p&gt;
    &lt;p&gt;Computer scientists want to know how many steps a given algorithm requires. For example, any local algorithm that can solve the router problem with only two colors must be incredibly inefficient, but it‚Äôs possible to find a very efficient local algorithm if you‚Äôre allowed to use three.&lt;/p&gt;
    &lt;p&gt;At the talk Bernshteyn was attending, the speaker discussed these thresholds for different kinds of problems. One of the thresholds, he realized, sounded a lot like a threshold that existed in the world of descriptive set theory ‚Äî about the number of colors required to color certain infinite graphs in a measurable way.&lt;/p&gt;
    &lt;p&gt;To Bernshteyn, it felt like more than a coincidence. It wasn‚Äôt just that computer scientists are like librarians too, shelving problems based on how efficiently their algorithms work. It wasn‚Äôt just that these problems could also be written in terms of graphs and colorings.&lt;/p&gt;
    &lt;p&gt;Perhaps, he thought, the two bookshelves had more in common than that. Perhaps the connection between these two fields went much, much deeper.&lt;/p&gt;
    &lt;p&gt;Perhaps all the books, and their shelves, were identical, just written in different languages ‚Äî and in need of a translator.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opening the Door&lt;/head&gt;
    &lt;p&gt;Bernshteyn set out to make this connection explicit. He wanted to show that every efficient local algorithm can be turned into a Lebesgue-measurable way of coloring an infinite graph (that satisfies some additional important properties). That is, one of computer science‚Äôs most important shelves is equivalent to one of set theory‚Äôs most important shelves (high up in the hierarchy).&lt;/p&gt;
    &lt;p&gt;He began with the class of network problems from the computer science lecture, focusing on their overarching rule ‚Äî that any given node‚Äôs algorithm uses information about just its local neighborhood, whether the graph has a thousand nodes or a billion.&lt;/p&gt;
    &lt;p&gt;To run properly, all the algorithm has to do is label each node in a given neighborhood with a unique number, so that it can log information about nearby nodes and give instructions about them. That‚Äôs easy enough to do in a finite graph: Just give every node in the graph a different number.&lt;/p&gt;
    &lt;p&gt;If Bernshteyn could run the same algorithm on an infinite graph, it meant he could color the graph in a measurable way ‚Äî solving a graph-coloring question on the set theory side. But there was a problem: These infinite graphs are ‚Äúuncountably‚Äù infinite. There‚Äôs no way to uniquely label all their nodes.&lt;/p&gt;
    &lt;p&gt;Bernshteyn‚Äôs challenge was to find a cleverer way to label the graphs.&lt;/p&gt;
    &lt;p&gt;He knew that he‚Äôd have to reuse labels. But that was fine so long as nearby nodes were labeled differently. Was there a way to assign labels without accidentally reusing one in the same neighborhood?&lt;/p&gt;
    &lt;p&gt;Bernshteyn showed that there is always a way ‚Äî no matter how many labels you decide to use, and no matter how many nodes your local neighborhood has. This means that you can always safely extend the algorithm from the computer science side to the set theory side. ‚ÄúAny algorithm in our setup corresponds to a way of measurably coloring any graph in the descriptive set theory setup,‚Äù Rozho≈à said.&lt;/p&gt;
    &lt;p&gt;The proof came as a surprise to mathematicians. It demonstrated a deep link between computation and definability, and between algorithms and measurable sets. Mathematicians are now exploring how to take advantage of Bernshteyn‚Äôs discovery. In a paper published this year, for instance, Rozho≈à and his colleagues figured out that it‚Äôs possible to color special graphs called trees by looking at the same problem in the computer science context. The result also illuminated which tools mathematicians might use to study the trees‚Äô corresponding dynamical systems. ‚ÄúThis is a very interesting experience, trying to prove results in a field where I don‚Äôt understand even the basic definitions,‚Äù Rozho≈à said.&lt;/p&gt;
    &lt;p&gt;Mathematicians have also been working to translate problems in the other direction. In one case, they used set theory to prove a new estimate of how hard a certain class of problems is to solve.&lt;/p&gt;
    &lt;p&gt;Bernshteyn‚Äôs bridge isn‚Äôt just about having a new tool kit for solving individual problems. It has also allowed set theorists to gain a clearer view of their field. There were lots of problems that they had no idea how to classify. In many cases, that‚Äôs now changed, because set theorists have computer scientists‚Äô more organized bookshelves to guide them.&lt;/p&gt;
    &lt;p&gt;Bernshteyn hopes this growing area of research will change how the working mathematician views set theorists‚Äô work ‚Äî that they‚Äôll no longer see it as remote and disconnected from the real mathematical world. ‚ÄúI‚Äôm trying to change this,‚Äù he said. ‚ÄúI want people to get used to thinking about infinity.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/a-new-bridge-links-the-strange-math-of-infinity-to-computer-science-20251121/"/><published>2025-11-25T19:53:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46051449</id><title>Show HN: KiDoom ‚Äì Running DOOM on PCB Traces</title><updated>2025-11-26T15:09:59.836834+00:00</updated><content>&lt;doc fingerprint="562395acea28f504"&gt;
  &lt;main&gt;
    &lt;p&gt;3 ECUs Developed 10+ Years Exp. 28.5M+ Miles Driven Selected Projects Private Tools √ó&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mikeayles.com/#kidoom"/><published>2025-11-25T22:13:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46052685</id><title>CS234: Reinforcement Learning Winter 2025</title><updated>2025-11-26T15:09:59.463927+00:00</updated><content>&lt;doc fingerprint="db6129c8929d1c49"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="9"&gt;
        &lt;cell role="head"&gt;Monday&lt;/cell&gt;
        &lt;cell role="head"&gt;Tuesday&lt;/cell&gt;
        &lt;cell role="head"&gt;Wednesday&lt;/cell&gt;
        &lt;cell role="head"&gt;Thursday&lt;/cell&gt;
        &lt;cell role="head"&gt;Friday&lt;/cell&gt;
        &lt;cell role="head"&gt;Saturday&lt;/cell&gt;
        &lt;cell role="head"&gt;Sunday&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 1&lt;/cell&gt;
        &lt;cell&gt;Jan 6&lt;/cell&gt;
        &lt;cell&gt;Jan 7&lt;/cell&gt;
        &lt;cell&gt;Jan 8&lt;/cell&gt;
        &lt;cell&gt;Jan 9&lt;/cell&gt;
        &lt;cell&gt;Jan 10&lt;/cell&gt;
        &lt;cell&gt;Jan 11&lt;/cell&gt;
        &lt;cell&gt;Jan 12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Introduction to Reinforcement Learning &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Tabular MDP Planning &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;p&gt;[Assignment 1 Released]&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 2&lt;/cell&gt;
        &lt;cell&gt;Jan 13&lt;/cell&gt;
        &lt;cell&gt;Jan 14&lt;/cell&gt;
        &lt;cell&gt;Jan 15&lt;/cell&gt;
        &lt;cell&gt;Jan 16&lt;/cell&gt;
        &lt;cell&gt;Jan 17&lt;/cell&gt;
        &lt;cell&gt;Jan 18&lt;/cell&gt;
        &lt;cell&gt;Jan 19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Policy Evaluation &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Q-Learning and Function Approximation &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Assignment 1 Due at 6pm&lt;p&gt;[Assignment 2 Released]&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 3&lt;/cell&gt;
        &lt;cell&gt;Jan 20&lt;/cell&gt;
        &lt;cell&gt;Jan 21&lt;/cell&gt;
        &lt;cell&gt;Jan 22&lt;/cell&gt;
        &lt;cell&gt;Jan 23&lt;/cell&gt;
        &lt;cell&gt;Jan 24&lt;/cell&gt;
        &lt;cell&gt;Jan 25&lt;/cell&gt;
        &lt;cell&gt;Jan 26&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Policy Search 1 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Policy Search 2 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 4&lt;/cell&gt;
        &lt;cell&gt;Jan 27&lt;/cell&gt;
        &lt;cell&gt;Jan 28&lt;/cell&gt;
        &lt;cell&gt;Jan 29&lt;/cell&gt;
        &lt;cell&gt;Jan 30&lt;/cell&gt;
        &lt;cell&gt;Jan 31&lt;/cell&gt;
        &lt;cell&gt;Feb 1&lt;/cell&gt;
        &lt;cell&gt;Feb 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Policy Search 3 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Offline RL 1 / Imitation learning &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Assignment 2 Due at 6pm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 5&lt;/cell&gt;
        &lt;cell&gt;Feb 3&lt;/cell&gt;
        &lt;cell&gt;Feb 4&lt;/cell&gt;
        &lt;cell&gt;Feb 5&lt;/cell&gt;
        &lt;cell&gt;Feb 6&lt;/cell&gt;
        &lt;cell&gt;Feb 7&lt;/cell&gt;
        &lt;cell&gt;Feb 8&lt;/cell&gt;
        &lt;cell&gt;Feb 9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Offline RL 2 / DPO &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Midterm (in class)&lt;/cell&gt;
        &lt;cell&gt;[Assignment 3 released]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 6&lt;/cell&gt;
        &lt;cell&gt;Feb 10&lt;/cell&gt;
        &lt;cell&gt;Feb 11&lt;/cell&gt;
        &lt;cell&gt;Feb 12&lt;/cell&gt;
        &lt;cell&gt;Feb 13&lt;/cell&gt;
        &lt;cell&gt;Feb 14&lt;/cell&gt;
        &lt;cell&gt;Feb 15&lt;/cell&gt;
        &lt;cell&gt;Feb 16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Offline RL 3 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Exploration 1 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 7&lt;/cell&gt;
        &lt;cell&gt;Feb 17&lt;/cell&gt;
        &lt;cell&gt;Feb 18&lt;/cell&gt;
        &lt;cell&gt;Feb 19&lt;/cell&gt;
        &lt;cell&gt;Feb 20&lt;/cell&gt;
        &lt;cell&gt;Feb 21&lt;/cell&gt;
        &lt;cell&gt;Feb 22&lt;/cell&gt;
        &lt;cell&gt;Feb 23&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Exploration 2 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Exploration 3 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Assignment 3 Due at 6pm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 8&lt;/cell&gt;
        &lt;cell&gt;Feb 24&lt;/cell&gt;
        &lt;cell&gt;Feb 25&lt;/cell&gt;
        &lt;cell&gt;Feb 26&lt;/cell&gt;
        &lt;cell&gt;Feb 27&lt;/cell&gt;
        &lt;cell&gt;Feb 28&lt;/cell&gt;
        &lt;cell&gt;Mar 1&lt;/cell&gt;
        &lt;cell&gt;Mar 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Exploration 4 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Guest lecture&lt;/cell&gt;
        &lt;cell&gt; Project Milestone &lt;p&gt;Due at 6pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 9&lt;/cell&gt;
        &lt;cell&gt;Mar 3&lt;/cell&gt;
        &lt;cell&gt;Mar 4&lt;/cell&gt;
        &lt;cell&gt;Mar 5&lt;/cell&gt;
        &lt;cell&gt;Mar 6&lt;/cell&gt;
        &lt;cell&gt;Mar 7&lt;/cell&gt;
        &lt;cell&gt;Mar 8&lt;/cell&gt;
        &lt;cell&gt;Mar 9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Monte Carlo Tree Search / AlphaGo &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Quiz (in class) &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 10&lt;/cell&gt;
        &lt;cell&gt;Mar 10&lt;/cell&gt;
        &lt;cell&gt;Mar 11&lt;/cell&gt;
        &lt;cell&gt;Mar 12&lt;/cell&gt;
        &lt;cell&gt;Mar 13&lt;/cell&gt;
        &lt;cell&gt;Mar 14&lt;/cell&gt;
        &lt;cell&gt;Mar 15&lt;/cell&gt;
        &lt;cell&gt;Mar 16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt;Guest Lecture and Wrap Up&lt;/cell&gt;
        &lt;cell&gt;Final Project Poster Session&lt;p&gt;1:30pm-4:30pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 11&lt;/cell&gt;
        &lt;cell&gt;Mar 17&lt;/cell&gt;
        &lt;cell&gt;Mar 18&lt;/cell&gt;
        &lt;cell&gt;Mar 19&lt;/cell&gt;
        &lt;cell&gt;Mar 20&lt;/cell&gt;
        &lt;cell&gt;Mar 21&lt;/cell&gt;
        &lt;cell&gt;Mar 22&lt;/cell&gt;
        &lt;cell&gt;Mar 23&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt;Final Project Writeup Due at 6pm&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://web.stanford.edu/class/cs234/"/><published>2025-11-26T00:33:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46053566</id><title>Space Truckin' ‚Äì The Nostromo (2012)</title><updated>2025-11-26T15:09:59.341759+00:00</updated><content>&lt;doc fingerprint="a6989335ba319f21"&gt;
  &lt;main&gt;
    &lt;p&gt;‚ÄúI was really influenced by three films,‚Äù Ridley Scott told Fantastic Films in 1979, on the subject of the Nostromo and its claustrophobic corridors. ‚ÄúNot so much in terms of Star Wars, but definitely from 2001 and Dark Star.‚Äù The latter film, directed by a young John Carpenter and written by, and starring, Alien writer Dan O‚ÄôBannon, was an inverse, comedic take on 2001 ‚Äì where Kubrick‚Äôs film was cold, sterile, clinical, and philosophical in scope, Dark Star was cramped, crowded, shabby, dirty, irreverent and yet also elegiac. ‚ÄúThere was a great sense of reality, oddly enough, in Dark Star,‚Äù continued Scott, ‚Äúespecially of seedy living. It showed you can get grotty even in the Hilton Hotel if you don‚Äôt clean it. Everything starts to get tacky, even in the most streamlined surfaces.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWhen we did Dark Star,‚Äù said O‚ÄôBannon, ‚Äúwhich was in the wake of 2001, we thought we wanted -partly for the novelty, partly because it was realer, mostly just for laughs- we wanted to show this once-sterile spaceship in a rundown condition, like some old bachelor apartment.‚Äù For O‚ÄôBannon, Dark Star‚Äòs ‚Äòused universe‚Äô was not as strong a visual element as he had hoped, and Star Wars‚Äô ‚Äúdidn‚Äôt come across all that clearly either.‚Äù For Alien, O‚ÄôBannon instructed Ridley Scott that ‚Äúif we want this spacecraft to look industrial [and] beat-up, you‚Äôre gonna have to make it about three times messier to the naked eye than you wanna to see it. And Alien probably was the first time where an audience clearly saw a futuristic machine in a run-down condition.‚Äù&lt;/p&gt;
    &lt;p&gt;The design of the Nostromo and the ‚Äòused universe‚Äô aesthetic would be drawn from O‚ÄôBannon‚Äôs earlier sci-fi effort, coupled with the realism of Kubrick‚Äôs Discovery One. ‚ÄúIt‚Äôs futuristic,‚Äù Scott said of Kubrick‚Äôs approach to 2001, ‚Äúbut it‚Äôs still hung on today‚Äôs reality ‚Ä¶ In two hundred years things won‚Äôt change that much, you know. People will still be scruffy or clean. They‚Äôll still clean their teeth three times a day.‚Äù Though Star Wars itself utilised a used universe (or, as Akira Kurosawa called it, a ‚Äúmaculate reality‚Äù), Scott wanted to create a tangible reality opposed to Star Wars‚Äò fantasy-hinged settings and ships. ‚ÄúI wanted to do the truck driver version, the hard-nosed version,‚Äù said Scott. ‚ÄúIt was supposed to be the anti-thesis of Star Wars. The reality, the beauty of something absolutely about function.‚Äù&lt;/p&gt;
    &lt;p&gt;Before Scott came onto the project as director, writer Dan O‚ÄôBannon commissioned his friend and Dark Star spaceship designer Ron Cobb to draw what his script was then calling the ‚Äòdeep space commercial vessel Snark‚Äô ‚Äì a nod to Lewis Carroll‚Äôs The Hunting of the Snark. O‚ÄôBannon had promised Cobb a job on Alejandro Jodorowsky‚Äôs Dune, but when that film dissolved Cobb, who had terminated the lease on his home and prepared to move to Paris with his wife, was left standing empty-handed. To make up for the letdown, O‚ÄôBannon immediately hired Cobb for Alien, which allowed the artist to bounce back from a slump. ‚ÄúHe was paid about $400 a week,‚Äù Cobb‚Äôs wife, Robin Love, told the LA Times in 1988. ‚ÄúWe thought it was wonderful!‚Äù&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;When Dan met Ron: ‚ÄúI was working on my first sci-fi film, John Carpenter‚Äôs Electric Dutchman, which would ultimately metastastize into the feature-length Dark Star. I tried to reach Cobb to get him to design the whole film, but he was unreachable. For weeks his phone rang without an answer, and then it was disconnected, and then I got his new unlisted number but it was invariably answered by one of the girls who were living with him, who always told me he was out. It was impossible. It took another year and a half to track him down and get him to agree to design us a nice, simple little spaceship for our simple little movie. Finally, one night about ten pm, Carpenter and I drove over to Westwood and rousted him out of a sound sleep. He was hung over from an LSD trip and I felt kind of guilty, but I had to have those designs. We took him over to an all-night coffee shop and fed him and got him half-way awake, and then he brought out this pad of yellow graph paper on which he had sketched a 3-view plan of our spaceship. It was wonderful! A little surfboard-shaped starcruiser with a flat bottom for atmospheric landings. Very technological looking. Very high class stuff.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;‚ÄúThe first person I hired on Alien, the first person to draw money, was Cobb,‚Äù O‚ÄôBannon said. ‚ÄúHe started turning out renderings, large full-colour paintings, while Shusett and I were still struggling with the script ‚Äì the corrosive blood of the Alien was Cobb‚Äôs idea. It was an intensely creative period ‚Äì the economic desperation, the all-night sessions, the rushing over to Cobb‚Äôs apartment to see the latest painting-in-progress and give him the latest pages.‚Äù&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;‚ÄúI just sat down and started blocking out a ship ‚Äì which I love to do. Anyway, Dan‚Äôs original script called for a small, modest little ship with a small crew. They land on a small planet. They go down a small pyramid and shake up a medium-sized creature. That‚Äôs about it. He meant it to be a low budget film, like Dark Star, and I loved the idea. So I did a few paintings and Dan scurried off with them and a script.‚Äù&lt;/p&gt;&lt;lb/&gt;~ Ron Cobb&lt;/quote&gt;
    &lt;p&gt;‚ÄúAnd he was doing some incredible stuff,‚Äù continued O‚ÄôBannon. ‚ÄúWow! I was really happy during this period, seeing the movie appear under Cobb‚Äôs fingers. Of course, we usually had to go over and sit on his back to get him to do any work -otherwise he would just party on with his friends- but how beautiful were the results.‚Äù&lt;/p&gt;
    &lt;p&gt;Coupled with Cobb was English artist, Chris Foss, who O‚ÄôBannon had come to know during their tenure together on Alejandro Jodorowsky‚Äôs Dune. ‚ÄúAlejandro wanted Doug Trumble to do the special effects [for Dune],‚Äù Foss told MTV in 2011, ‚Äúand of course, Trumble was a big important American, and certainly wouldn‚Äôt succumb to Alejandro‚Äôs manipulation. So he picked up this gauche American film student, Dan O‚ÄôBannon. He was quite hilarious, he said to me once, ‚ÄòHey, these streets are so goddamn small.‚Äô This is Paris, which had some of the widest streets in Europe. Of course, it was only when I got to Los Angeles that I saw what he meant.‚Äù&lt;/p&gt;
    &lt;p&gt;Though Dune would never come to fruition under Jodorowsky, the experience in France influenced O‚ÄôBannon‚Äôs approach to designing Alien. Jodorowsky had gathered together Chris Foss, Jean ‚ÄòMoebius‚Äô Giraud, and HR Giger to design his film, and the eclectic team would be later reunited by O‚ÄôBannon to design his grungy sci-fi horror movie. ‚ÄúDan said [to Twentieth Century Fox], ‚ÄòHey, we‚Äôve got to get this guy Chris Foss over here.‚Äô So off I went to Los Angeles ‚Ä¶&lt;/p&gt;
    &lt;p&gt;The early stages of designing Alien were done in an almost ramshackle, low-fi manner. ‚ÄúWe were put through shed after shed after shed,‚Äù said Foss of the times, ‚Äúand they were going through director after director after director.‚Äù Ron Cobb told Den of Geek: ‚ÄúI soon found myself hidden away at Fox Studios in an old rehearsal hall above an even older sound stage with Chris Foss and O‚ÄôBannon, trying to visualize Alien. For up to five months Chris and I (with Dan supervising) turned out a large amount of artwork, while the producers, Gordon Carroll, Walter Hill and David Giler, looked for a director.‚Äù&lt;/p&gt;
    &lt;p&gt;Foss was largely critical of Brandywine‚Äôs apparently disinterested approach to setting up the embryonic film. ‚ÄúWalter Hill was very busy smashing cars up for one of his ‚Äòstreets‚Äô films,‚Äù he told Den of Geek. ‚ÄúHe couldn‚Äôt be arsed ‚Äì much too busy! He walked in after months of work and just said, ‚ÄòYep, roomful of spaceships‚Äô and just walked out again.‚Äù&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Ron Cobb, Steven Spielberg, and aliens: Cobb told bttf.com: ‚ÄúI first met Spielberg when I was working on Alien, at one point Spielberg was considered as a possible director for the original Alien. It was just a brief thing, he could never work out his schedule to do it, but he was interested.‚Äù Later, one of Cobb‚Äôs early story pitches to Spielberg, an alien horror tale called Night Skies, eventually became 1982‚Äôs E.T. Though Cobb cameo‚Äôd as one of E.T.‚Äôs doctors (‚ÄúI got to carry the little critter,‚Äù) he wasn‚Äôt pleased with the family-friendly direction that the film took from his initial idea: ‚ÄúA banal retelling of the Christ story,‚Äù he told the LA Times. ‚ÄúSentimental and self-indulgent, a pathetic lost-puppy kind of story.‚Äù Luckily for the artist, a clause in his contract for E.T. (he was originally to direct before the story took a turn) detailed that he was to earn 1% of the net profit. His first cheque amounted to $400,000. Cobb‚Äôs wife quipped: ‚Äúfriends from Australia always ask, ‚ÄòWhat did you do on E.T.?‚Äô And Ron says, ‚ÄòI didn‚Äôt direct it.'‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When Ridley Scott took over the directorial duties, Cobb and Foss were shipped to England to continue their work. Around this point in time, HR Giger was drawing up the film‚Äôs alien, and Moebius was commissioned by Scott to design the film‚Äôs space suits, which would be brought into reality by John Mollo. The Snark went through a variety of designs, from a ship embedded in the rock of an asteroid, to an upended pyramidal design, to a hammerhead shape and other varieties of ship with white or yellow or more kaleidoscopic paint-jobs.&lt;/p&gt;
    &lt;p&gt;After many months of scribbling and painting spaceships, the production was no closer to settling what the vessel would actually look like. Due to script rewrites, it also changed names, from Snark to Leviathan before the name Nostromo was settled on. ‚ÄúI called the ship Nostromo from [Joseph] Conrad,‚Äù Walter Hill told Film International in 2004, ‚Äú[For] no particular metaphoric idea, I just thought it sounded good.‚Äù&lt;/p&gt;
    &lt;p&gt;However, indecision was still rife on the actual look of the thing.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Scott on O‚ÄôBannon: ‚ÄúHe‚Äôs great. A really sweet guy. And, I was soon to realise, a real science-fiction freak ‚Ä¶ He brought in a book by the Swiss artist HR Giger. It‚Äôs called Necronomicon ‚Ä¶ I thought, ‚ÄòIf we can build that [Necronom IV], that‚Äôs it.‚Äô I was stunned, really. I flipped. Literally flipped. And O‚ÄôBannon lit up like a lightbulb, shining like a quartz iodine. I realised I was dealing with a real SF freak, which I‚Äôd never come across before. I thought, ‚ÄòMy god, I have an egg-head here for this field.'‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Scott on Cobb: ‚ÄúO‚ÄôBannon introduced me to Ron Cobb, a brilliant visualiser of the genre, with whom he‚Äôd worked on Dark Star. Cobb seemed to have very realistic visions of both the far and near future, so I quickly decided that he would take a very important part in the making of the film.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Cobb on Foss: ‚ÄúCreating spacecraft exteriors came easily to Foss. His mind and imagination seemed to embody the entire history of the industrial revolution. He could conjure up endless spacecraft designs suggesting submarines, diesel locomotives, Mayan interceptors, Mississippi river boats, jumbo space arks, but best of all (ask Dan) were his trademark aero-spacecraft-textures like panels, cowlings, antennae, bulging fuel tanks, vents, graphics etc. As the months passed, along with two or three temporary directors, Chris began to have problems caused by his spectacular creativity. No one in a position to make a decision seemed to be able to make up their mind and/or choose one of his designs. I think Chris was turning out spacecraft designs the decision makers found too original.‚Äù&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Ridley himself had input on the design: ‚ÄúI was looking for something like 2001, not the fantasy of Star Wars. I wanted a slow moving, massive piece of steel which was moving along in dead, deep silence ‚Ä¶ The concept was to have the hull covered with space barnacles or something. I was unable to communicate that idea, and I finally had to go down there and fiddle with the experts. We gradually arrived at a solution.‚Äù&lt;/p&gt;
    &lt;p&gt;Foss paints a more hectic process. ‚ÄúFinally what happened was that the bloke who had to make the [Nostromo] model completely lost his rag, scooped up a load of paper -they had a room full of smashed-up bits of helicopter and all-sorts- and he just bodged something together. So the actual spaceship in the film hadn‚Äôt anything to do with all the days, weeks, months of work that we‚Äôd all done. It‚Äôs as simple as that.‚Äù&lt;/p&gt;
    &lt;p&gt;Cobb explained: ‚ÄúBrian Johnson, the special effects supervisor under pressure to build the large Nostromo model, went into the deserted art department and, out of frustration, grabbed all the Chris Foss designs off the wall and took them to Bray studios. There he would choose the design himself in order to have enough time to build the damn thing.‚Äù&lt;/p&gt;
    &lt;p&gt;However, Johnson had also scooped up Cobb‚Äôs art, and though Cobb was concentrating on the designs of the ship‚Äôs interior, one of his exterior pieces met with approval over Foss‚Äô designs. ‚ÄúWell I soon found out that Brian found and took all of my exterior design sketches as well,‚Äù said Cobb. ‚ÄúAbout a month later I was told that Brian had used my sketch, ‚ÄòNostromo A‚Äô, as the basis for the model, even to the extent that it was painted yellow. Ridley found the colour a bit garish and had it repainted grey.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúRidley had his own very firm ideas about what he physically wanted to do,‚Äù Foss said of the process, ‚Äúand he almost studiously ignored everything that had gone before ‚Ä¶ I kind of got the impression that Ridley was quietly going his own way, trying to get on with it and get it done, a bit like just another job. I‚Äôve just got dim memories of Ridley being like that and really just ignoring months of input ‚Ä¶ I just have these memories of feeling a bit miffed that things weren‚Äôt put together so much better. And poor old Dan O‚ÄôBannon, the bloke whose concept it was, just got absolutely shafted. He was almost like patted on the head: ‚ÄòYeah Dan, yeah Dan, that‚Äôs cool.'‚Äù&lt;/p&gt;
    &lt;p&gt;Cobb‚Äôs sketches, drawings and paintings for the interiors were also okay‚Äôed by Scott and the production. At first Cobb‚Äôs designs were slightly more fantastical, with giant screens and computer readouts and windows covered by protective shells that would open up to reveal alien planets ahead of the ship. Though these ideas were scuppered due to time, money, and logistics, many of Cobb‚Äôs early designs and ideas were revisited in Prometheus.&lt;/p&gt;
    &lt;p&gt;In addition to designing the Nostromo‚Äôs exterior, its bridge and auto-doc, Cobb also designed the ship‚Äôs airlocks, cyro-tubes, corridors, bulkheads, an observation dome (not built), Ash‚Äôs ‚Äòblister‚Äô observation unit, some of the film‚Äôs uniform patches and ship signage, the ‚Äòflying bedstead‚Äô maintenance vehicle (not built), and even Jones‚Äô cat-box. Cobb told Den of Geek that, ‚ÄúMy problem with designing Nostromo‚Äôs interiors, the control bridge, corridors, auto doc (or med lab), bulkhead doors, the food deck, etc., was that I grew up with a deep fascination for astronomy, astrophysics, and most of all, aerospace flight. My design approach has always been that of a frustrated engineer (as well as a frustrated writer when it came to cinema design). I tend to subscribe to the idea that form follows function. If I‚Äôm to arrive at a cinematic spacecraft design that seamlessly preserves, as in this case, the drama of the script, the audience has to experience it as something impressive and believable.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWe‚Äôre beyond 2001 in terms of scientific advances,‚Äù said Scott of Alien‚Äòs futurism, ‚Äúour capabilities are more sophisticated but our ship‚Äôs still NASA-orientated, still Earth-manufactured ‚Ä¶ in our tongue-in-cheek fantasy we project a not-too-distant future in which there are many vehicles tramping around the universe on mining expeditions, erecting military installations, or whatever. At the culmination of many long voyages, each covering many years, these ships -no doubt part of armadas owned by private corporations- look used, beat-up, covered with graffiti, and uncomfortable. We certainly didn‚Äôt design the Nostromo to look like a hotel.‚Äù&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;‚ÄúI didn‚Äôt want a conventional shape [for the refinery,] so I drew up a sketch and handed it to the model makers. They refined it, as it were, and built the model. I originally drew it upside-down, with the vague idea that it would resemble a floating inverted cathedral ‚Ä¶ I think that the machine that they‚Äôre on could in fact be 60 years old and just added to over the decades. The metal-work on it could be 50 years old ‚Ä¶ I would have liked to see it covered with space barnacles or space seaweed, all clogged and choked up, but that was illogical as well.‚Äù&lt;/p&gt;&lt;lb/&gt;~ Ridley Scott, Fantastic Films, 1979.&lt;/quote&gt;
    &lt;p&gt;The Nostromo model was built under the supervision of Nick Allder and Brian Johnson at Bray Studios, not far from Pinewood, where the live-action scenes were being filmed in parallel with the model shots at Bray. For the refinery, Scott instructed the teams at Bray to make it appear ‚ÄúVictorian Gothic,‚Äù with towers and spires and antennae. Bray shop worker Dennis Lowe explained: ‚ÄúAt that same time in the workshop Ridley was talking about his first concept of the refinery and he was describing an actual oil refinery with pipes and spires, eventually the term ‚ÄòBattleship Bismarck in space‚Äô came up to describe the detailing of the model.‚Äù&lt;/p&gt;
    &lt;p&gt;When Ridley arrived after concluding filming at Pinewood, he further revised the ship‚Äôs look, removing many of the spires from the refinery, repainting the Nostromo from yellow to grey, and scrapping every piece of footage shot to date, taking it upon himself to re-direct the scenes. ‚ÄúIt was a difficult situation,‚Äù said Scott, ‚ÄúBrian Johnson was over there [at Bray], working out of context away from the main unit. I could only look at the rushes while I was working with the actors, and that‚Äôs not a very satisfactory way of working. In the end, I think a director must be heavily involved with the miniatures, and that‚Äôs why I shot them myself.‚Äù&lt;/p&gt;
    &lt;p&gt;According to model builder Jon Sorensen, there were no real hard feelings over the redesigns and reshoots. ‚ÄúRidley Scott then arrived from Shepperton to take an interest in the models and everything changed radically in terms of tone, colour and look. The yellow was sprayed over a uniform grey. Sections were rebuilt. We started over, discarding all previous footage. There was no anger at this. Surprise maybe. But it was Ridley Scott‚Äôs film. We liked him. So we entered the Alien model shoot Part Deux. I recall Bill Pearson and I talking once on what we thought was an empty, lunch-time model stage when a voice spoke from the shadows. Ridley, asking what we were discussing. We answered that maybe that part might look better moved over to there, (we were discussing the refinery). He smiled back and I guess that signalled what was true; we‚Äôd go all the way to help him. That night he bought both Bill and I a beer, a move which astonished the Assistant Director, Ray Beckett who complained that in 10 years of working with Ridley, he‚Äôd never been bought a beer. So we bought Ray one instead.‚Äù&lt;/p&gt;
    &lt;p&gt;The Nostromo interiors were overseen by art director Roger Christian, who had helped craft the sets for Star Wars. Christian told Shadowlocked.com: ‚ÄúI art-directed Alien for Ridley Scott with my team because he was struggling to get the designer and the art department to understand ‚Äòthat look‚Äô I created with the dressing on Star Wars ‚Ä¶ I went into Shepperton, and we built and dressed the first corridor section ‚Äì actually for a test screen for Sigourney Weaver, who the studios were not sure about. I brought my little team of prop guys who‚Äôd understood then the process of what to strip down and how to place it. Because it was not something you just do randomly. It had to be done based on a kind of knowledge.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúRoger is a brilliant set dresser,‚Äù Scott told Fantastic Films. ‚ÄúThough his department was not designing the corridors and sets, their ‚Äòcladding‚Äô of the walls made everything look absolutely real. He would go out with his buyers and prop men and visit aircraft dumps or army surplus stores and drag masses of things in for me to see.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúWith Alien I was able to go much further with the oily and gritty look than in Star Wars,‚Äù said Roger Christian, ‚Äúand for the first time create a totally believable ‚Äòspace truck‚Äô, as Ridley described it. The set ended up looking as if we had rented a well-travelled, well-used, oily, dirty, mineral carrier ‚Äì an unmistakably real and claustrophobic space vessel. I think this really helped audiences to identify with the movie, as the characters were so like space truckers, trapped in a claustrophobic nightmare.‚Äù&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;‚Äú[The Nostromo‚Äôs] like the bloody Queen Mary. Do you get a sense of scale in the interior? That it‚Äôs big? We couldn‚Äôt build the two to three-hundred foot-long corridors which it would have but it‚Äôs supposed to be like one of these huge Japanese super-tankers. Three quarters of a mile long. The refinery behind it god-knows how big. I mean‚Ä¶ I dunno. A mile square?‚Äù&lt;/p&gt;&lt;lb/&gt;~ Ridley Scott, Fantastic Films, 1979.&lt;/quote&gt;
    &lt;p&gt;‚ÄúRidley saw the ship very much as a metaphor for a Gothic castle,‚Äù said Ron Cobb on the subject of the ship‚Äôs interiors, ‚Äúor a WWII submarine ‚Ä¶ a kind of retro, accessible technology with great big transistors and very low-res video screens.‚Äù However, at one point, Scott had other ideas for the Nostromo‚Äôs technology: ‚ÄúI wanted to have wafer-thin screens that are plexiglas, that just float on clips -and of course today you‚Äôve got computer screens exactly like that- because I figured that‚Äôs where it [technology] would go. I really got those things off Jean Giraud, Moebius, when he‚Äôd been drawing and speculating. A lot of his stuff you see thirty years ago is now.‚Äù&lt;/p&gt;
    &lt;p&gt;Cobb acknowledged the Moebius influence, as well as the ship‚Äôs other, perhaps subtler, inspirations: ‚ÄúThe ship is a strange mixture of retrofitted old technology, a kind of industrial nightmare, like being trapped in a factory ‚Ä¶ Ridley‚Äôs a wonderful artist and he wanted it to look a lot like a Moebius-designed ship, with all kinds of rounds surfaces and with an Egyptian motif.‚Äù This Egyptian motif is prevalent in the Weylan-Yutani logo, a wings of Horus design which adorns the uniforms of the crew in addition to their coffee cups, beer cans, etc. The hypersleep chamber also evokes a burial chamber, with the cryo-chambers arranged in a lotus shape. In addition to the Egyptian motif, another influence was Japan. ‚ÄúThe owners of the Nostromo are Japanese,‚Äù Scott told Fantastic Films.&lt;/p&gt;
    &lt;p&gt;‚ÄúAs I was working with the art director,‚Äù said Ridley, ‚ÄúI decided to make it faintly glittery. I wanted to have sort of anodized gold everywhere. Not steel, gold. Did you know that space landing craft are covered with gold foil? Amazing! So I thought, Why make this out of steel? Let‚Äôs make it all warm and oppressive, massive, and gold.'‚Äù&lt;/p&gt;
    &lt;p&gt;The glittery look can be seen in the opening shots of the ship‚Äôs computers bleeping into life, and the gold sheen is most prevalent in the ship‚Äôs maintenance area, where Brett finds the Alien‚Äôs discarded skin moments before his death. Scott explained the design process for the ship‚Äôs golden-hued maintenance garage: ‚ÄúWe got hold of marvelous, actual parts of actual huge jet engines and installed them, and they‚Äôre like a coppery metal with some steel. We used them as four main supports, like columns, and they give a lot of the feeling of a temple. We played the same music we used in the derelict alien craft and we had two temples. The idol I wanted was through these massive gold doors which were as big as a wall, with a gap in them through which the claw [landing leg] can be seen. When that set was dressed, it looked like Aladdin‚Äôs Cave ‚Ä¶ [the garage is] filled with the equipment that the crew would use in their work on and around the refinery, and when they land on various planets ‚Äì land crawlers, helicopters, other flying machines.‚Äù&lt;/p&gt;
    &lt;p&gt;‚ÄúRidley has this lavish, sensual visual style,‚Äù summarised Dan O‚ÄôBannon to Fantastic Films in 1979, ‚Äúand I think that Ridley is one of the ‚Äògood guys.‚Äô I really think that he was the final pivot point responsible for the picture coming out good. And so a lot of the visual design and a lot of the mood elements inherent in the camerawork, while they‚Äôre not what I planned, are great. They‚Äôre just different.‚Äù&lt;/p&gt;
    &lt;p&gt;O‚ÄôBannon also nodded to the contributions of Cobb, Foss, Shusett etc., to the picture: ‚ÄúAlso, it‚Äôs not 100% Ridley either. It‚Äôs Ridley superimposing his vision over the cumulative vision of others, you see. Now this could be such a strong director‚Äôs picture because Ridley‚Äôs directorial and visual hand is so strong. There will probably be tendency among critics to refer to it as Ridley Scott‚Äôs vision of the future. And he did have a vision of the future. But it was everybody else that came before, that‚Äôs what his vision is ‚Ä¶ if it sounds like I‚Äôm knocking Ridley, I‚Äôm not.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alienseries.wordpress.com/2012/10/23/space-truckin-the-nostromo/"/><published>2025-11-26T02:31:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055177</id><title>Image Diffusion Models Exhibit Emergent Temporal Propagation in Videos</title><updated>2025-11-26T15:09:59.174098+00:00</updated><content>&lt;doc fingerprint="949db60014f5ba86"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 25 Nov 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Image Diffusion Models Exhibit Emergent Temporal Propagation in Videos&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Image diffusion models, though originally developed for image generation, implicitly capture rich semantic structures that enable various recognition and localization tasks beyond synthesis. In this work, we investigate their self-attention maps can be reinterpreted as semantic label propagation kernels, providing robust pixel-level correspondences between relevant image regions. Extending this mechanism across frames yields a temporal propagation kernel that enables zero-shot object tracking via segmentation in videos. We further demonstrate the effectiveness of test-time optimization strategies-DDIM inversion, textual inversion, and adaptive head weighting-in adapting diffusion features for robust and consistent label propagation. Building on these findings, we introduce DRIFT, a framework for object tracking in videos leveraging a pretrained image diffusion model with SAM-guided mask refinement, achieving state-of-the-art zero-shot performance on standard video object segmentation benchmarks.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2511.19936"/><published>2025-11-26T07:55:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055421</id><title>Statistical Process Control in Python</title><updated>2025-11-26T15:09:58.980191+00:00</updated><content>&lt;doc fingerprint="d2780f32a8fc6cd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;16 Statistical Process Control in &lt;code&gt;Python&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;In this workshop, we will learn how to perform statistical process control in Python, using statistical tools and &lt;code&gt;plotnine&lt;/code&gt; visualizations! Statistical Process Control refers to using statistics to (1) measure variation in product quality over time and (2) identify benchmarks to know when intervention is needed. Let‚Äôs get started!&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;head rend="h3"&gt;Packages&lt;/head&gt;
    &lt;code&gt;# Remember to install these packages using a terminal, if you haven't already!
!pip install pandas plotnine scipy&lt;/code&gt;
    &lt;p&gt;We‚Äôll be using &lt;code&gt;pandas&lt;/code&gt; for data manipulation, &lt;code&gt;plotnine&lt;/code&gt; for visualization, and &lt;code&gt;scipy&lt;/code&gt; for statistical functions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Custom Functions&lt;/head&gt;
    &lt;p&gt;This workshop uses custom functions from the &lt;code&gt;functions/&lt;/code&gt; directory. You may need both:
- &lt;code&gt;functions_distributions.py&lt;/code&gt; - for reliability and distribution functions
- &lt;code&gt;functions_process_control.py&lt;/code&gt; - for statistical process control functions&lt;/p&gt;
    &lt;p&gt;To use these functions, you need to acquire them from the repository at github.com/timothyfraser/sigma/tree/main/functions.&lt;/p&gt;
    &lt;p&gt;Add the functions directory to your Python path&lt;/p&gt;
    &lt;code&gt;import sys
import os
# Add the functions directory to Python path
sys.path.append('functions')  # or path to wherever you placed the functions folder&lt;/code&gt;
    &lt;p&gt;Once you have the functions available, you can import them:&lt;/p&gt;
    &lt;head rend="h3"&gt;Our Case&lt;/head&gt;
    &lt;p&gt;For today‚Äôs workshop, we‚Äôre going to think about why quality control matters in a local economy, by examining the case of the Japanese Hot Springs bath economy! Hot springs, or onsen, are a major source of tourism and recreation for families in Japan, bringing residents from across the country every year to often rural communities where the right geological conditions have brought on naturally occurring hot springs. Restaurants, taxi and bus companies, and many service sector firms rely on their local onsen to bring in a steady stream (pun intended) of tourists to the local economy. So, it‚Äôs often in the best interest of onsen operators to keep an eye on the temperature, minerals, or other aspects of their hot springs baths to ensure quality control, to keep up their firm (and town‚Äôs!) reputation for quality rest and relaxation!&lt;/p&gt;
    &lt;p&gt;Onsen-goers often seek out specific types of hot springs, so it‚Äôs important for an onsen to actually provide what it advertises! Serbulea and Payyappallimana (2012) describe some of these benchmarks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Temperature: Onsen are divided into ‚ÄúExtra Hot Springs‚Äù (&lt;/p&gt;&lt;code&gt;&amp;gt;42¬∞C&lt;/code&gt;), ‚ÄúHot Springs‚Äù (&lt;code&gt;41~34¬∞C&lt;/code&gt;), and ‚ÄúWarm Springs‚Äù (&lt;code&gt;33~25¬∞C&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;pH: Onsen are classified into ‚ÄúAcidic‚Äù (&lt;/p&gt;&lt;code&gt;pH &amp;lt; 3&lt;/code&gt;), ‚ÄúMildly Acidic‚Äù (&lt;code&gt;pH 3~6&lt;/code&gt;), ‚ÄúNeutral‚Äù (&lt;code&gt;pH 6~7.5&lt;/code&gt;), ‚ÄúMildly alkaline‚Äù (&lt;code&gt;pH 7.5~8.5&lt;/code&gt;), and ‚ÄúAlkaline‚Äù (&lt;code&gt;pH &amp;gt; 8.5&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sulfur: Sulfur onsen typically have about 2mg of sulfur per 1kg of hot spring water; sulfur levels must exceed 1 mg to count as a Sulfur onsen. (It smells like rotten eggs!)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are decent examples of quality control metrics that onsen operators might want to keep tabs on!&lt;/p&gt;
    &lt;head rend="h3"&gt;Our Data&lt;/head&gt;
    &lt;p&gt;You‚Äôve been hired to evaluate quality control at a local onsen in sunny Kagoshima prefecture! Every month, for 15 months, you systematically took 20 random samples of hot spring water and recorded its temperature, pH, and sulfur levels. How might you determine if this onsen is at risk of slipping out of one sector of the market (eg. Extra Hot!) and into another (just normal Hot Springs?).&lt;/p&gt;
    &lt;p&gt;Let‚Äôs read in our data from &lt;code&gt;workshops/onsen.csv&lt;/code&gt;!&lt;/p&gt;
    &lt;code&gt;# Add functions directory to path if not already there
import sys
if 'functions' not in sys.path:
    sys.path.append('functions')

from functions_distributions import density, tidy_density, approxfun

water = pd.read_csv('workshops/onsen.csv')
water.head(3)&lt;/code&gt;
    &lt;code&gt;##    id  time  temp   ph  sulfur
## 0   1     1  43.2  5.1     0.0
## 1   2     1  45.3  4.8     0.4
## 2   3     1  45.5  6.2     0.9&lt;/code&gt;
    &lt;head rend="h2"&gt;16.1 Process Descriptive Statistics&lt;/head&gt;
    &lt;p&gt;First, let‚Äôs get a sense of our process by calculating some basic descriptive statistics. We‚Äôll create a simple function to calculate the mean and standard deviation, which are fundamental to evaluating process variation.&lt;/p&gt;
    &lt;code&gt;from pandas import Series
def describe(x: Series):
  x = Series(x)
  out = pd.DataFrame({
    'mean': [x.mean()],
    'sd': [x.std()],
  })
  out['caption'] = ("Process Mean: " + out['mean'].round(2).astype(str) +
                    " | SD: " + out['sd'].round(2).astype(str))
  return out

tab = describe(water['temp'])
tab&lt;/code&gt;
    &lt;code&gt;##     mean        sd                         caption
## 0  44.85  1.989501  Process Mean: 44.85 | SD: 1.99&lt;/code&gt;
    &lt;p&gt;Now let‚Äôs apply this to our temperature data to see the overall process mean and variation.&lt;/p&gt;
    &lt;head rend="h2"&gt;16.2 Process Overview Visual&lt;/head&gt;
    &lt;p&gt;The process overview chart is one of the most important tools in SPC. It shows us how our process behaves over time, helping us identify patterns, trends, and potential issues. We‚Äôll create a visualization that shows individual measurements, subgroup means, and the overall process average.&lt;/p&gt;
    &lt;code&gt;g1 = (ggplot(water, aes(x='time', y='temp', group='time')) +
  geom_hline(aes(yintercept=water['temp'].mean()), color='lightgrey', size=3) +
  geom_jitter(height=0, width=0.25) +
  geom_boxplot() +
  labs(x='Time (Subgroup)', y='Temperature (Celsius)', subtitle='Process Overview', caption=tab['caption'][0]))

# Save the plot
g1.save('images/05_process_overview.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;code&gt;g2 = (ggplot(water, aes(x='temp')) + geom_histogram(bins=15, color='white', fill='grey') + theme_void() + coord_flip())

# Save the plot
g2.save('images/05_process_histogram.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;p&gt;The histogram shows us the distribution of all temperature measurements, giving us insight into the overall process variation. This helps us understand if our process is centered and how much variation we‚Äôre seeing.&lt;/p&gt;
    &lt;head rend="h2"&gt;16.3 Subgroup (Within-Group) Statistics&lt;/head&gt;
    &lt;p&gt;In SPC, we often work with subgroups - small samples taken at regular intervals. This allows us to distinguish between common cause variation (inherent to the process) and special cause variation (due to specific events). Let‚Äôs calculate statistics for each subgroup to see how the process behaves over time.&lt;/p&gt;
    &lt;code&gt;stat_s = (water.groupby('time').apply(lambda d: pd.Series({
  'xbar': d['temp'].mean(),
  'r': d['temp'].max() - d['temp'].min(),
  'sd': d['temp'].std(),
  'nw': len(d)
})).reset_index())
stat_s['df'] = stat_s['nw'] - 1
stat_s['sigma_s'] = ( (stat_s['df'] * (stat_s['sd']**2)).sum() / stat_s['df'].sum() )**0.5
stat_s['se'] = stat_s['sigma_s'] / (stat_s['nw']**0.5)
stat_s['upper'] = stat_s['xbar'].mean() + 3*stat_s['se']
stat_s['lower'] = stat_s['xbar'].mean() - 3*stat_s['se']
stat_s.head(3)&lt;/code&gt;
    &lt;code&gt;##    time    xbar    r        sd    nw    df   sigma_s        se      upper      lower
## 0     1  44.635  4.2  1.342533  20.0  19.0  1.986174  0.444122  46.182366  43.517634
## 1     3  45.305  7.9  2.001440  20.0  19.0  1.986174  0.444122  46.182366  43.517634
## 2     5  44.765  5.9  1.628133  20.0  19.0  1.986174  0.444122  46.182366  43.517634&lt;/code&gt;
    &lt;p&gt;Here we‚Äôve calculated key statistics for each subgroup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;xbar: The mean of each subgroup&lt;/item&gt;
      &lt;item&gt;r: The range (max - min) within each subgroup&lt;/item&gt;
      &lt;item&gt;sd: The standard deviation within each subgroup&lt;/item&gt;
      &lt;item&gt;sigma_s: The pooled within-subgroup standard deviation&lt;/item&gt;
      &lt;item&gt;se: The standard error for each subgroup mean&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;16.3.1 Total Statistics (Between Groups)&lt;/head&gt;
    &lt;p&gt;Now let‚Äôs calculate the overall process statistics that summarize the behavior across all subgroups:&lt;/p&gt;
    &lt;code&gt;stat_t = pd.DataFrame({
  'xbbar': [stat_s['xbar'].mean()],
  'rbar': [stat_s['r'].mean()],
  'sdbar': [stat_s['sd'].mean()],
  'sigma_s': [(stat_s['sd']**2).mean()**0.5],
  'sigma_t': [water['temp'].std()]
})
stat_t&lt;/code&gt;
    &lt;code&gt;##    xbbar    rbar    sdbar   sigma_s   sigma_t
## 0  44.85  7.2625  1.93619  1.986174  1.989501&lt;/code&gt;
    &lt;p&gt;These statistics give us:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;xbbar: The grand mean (average of all subgroup means)&lt;/item&gt;
      &lt;item&gt;rbar: The average range across subgroups&lt;/item&gt;
      &lt;item&gt;sdbar: The average standard deviation across subgroups&lt;/item&gt;
      &lt;item&gt;sigma_s: The pooled within-subgroup standard deviation&lt;/item&gt;
      &lt;item&gt;sigma_t: The total process standard deviation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;16.3.2 Average and Standard Deviation Charts&lt;/head&gt;
    &lt;p&gt;Control charts are the heart of SPC. They help us monitor process stability over time and detect when the process is out of control. We‚Äôll create charts for both the subgroup means (X-bar chart) and standard deviations (S chart).&lt;/p&gt;
    &lt;code&gt;labels = pd.DataFrame({
  'time': [stat_s['time'].max()]*3,
  'type': ['xbbar','upper','lower'],
  'name': ['mean','+3 s','-3 s'],
  'value': [stat_s['xbar'].mean(), stat_s['upper'].iloc[0], stat_s['lower'].iloc[0]]
})

control_chart = (ggplot(stat_s, aes(x='time', y='xbar')) +
  geom_hline(aes(yintercept=stat_s['xbar'].mean()), color='lightgrey', size=3) +
  geom_ribbon(aes(ymin='lower', ymax='upper'), fill='steelblue', alpha=0.2) +
  geom_line(size=1) + geom_point(size=5) +
  geom_label(data=labels, mapping=aes(x='time', y='value', label='name'), ha='right') +
  labs(x='Time (Subgroups)', y='Average', subtitle='Average and Standard Deviation Chart'))

# Save the plot
control_chart.save('images/05_control_chart.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;p&gt;This control chart shows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Center line: The grand mean (xbbar)&lt;/item&gt;
      &lt;item&gt;Control limits: Upper and lower 3-sigma limits based on the standard error&lt;/item&gt;
      &lt;item&gt;Individual points: Each subgroup mean plotted over time&lt;/item&gt;
      &lt;item&gt;Shaded area: The control limits region&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Points outside the control limits or showing non-random patterns indicate the process may be out of control and requires investigation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning Check 1&lt;/head&gt;
    &lt;p&gt;Question&lt;/p&gt;
    &lt;p&gt;Produce the same process overview chart for &lt;code&gt;pH&lt;/code&gt;.&lt;/p&gt;
    &lt;head&gt;[View Answer!]&lt;/head&gt;
    &lt;code&gt;def ggprocess(x, y, xlab='Subgroup', ylab='Metric'):
  import pandas as pd
  from plotnine import ggplot, aes, geom_hline, geom_jitter, geom_boxplot, labs
  d = pd.DataFrame({'x': x, 'y': y})
  g = (ggplot(d, aes(x='x', y='y', group='x')) +
       geom_hline(aes(yintercept=d['y'].mean()), color='lightgrey', size=3) +
       geom_jitter(height=0, width=0.25) +
       geom_boxplot() +
       labs(x=xlab, y=ylab, subtitle='Process Overview'))
  return g

ph_chart = ggprocess(water['time'], water['ph'])

# Save the plot
ph_chart.save('images/05_ph_chart.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;head rend="h2"&gt;16.4 Moving Range Charts (n=1)&lt;/head&gt;
    &lt;p&gt;When we have individual measurements rather than subgroups, we use moving range charts. The moving range is the absolute difference between consecutive measurements, which helps us estimate process variation when we can‚Äôt calculate within-subgroup statistics.&lt;/p&gt;
    &lt;code&gt;indiv = water.iloc[[0,20,40,60,80,100,120,140]]
mr = (indiv['temp'].diff().abs().dropna())
mrbar = mr.mean()
import numpy as np
d2 = np.mean(np.abs(np.diff(np.random.normal(0,1,10000))))
sigma_s = mrbar / d2
se = sigma_s / (1**0.5)
upper = mrbar + 3*se
lower = 0&lt;/code&gt;
    &lt;code&gt;istat = pd.DataFrame({'time': indiv['time'].iloc[1:], 'mr': mr, 'mrbar': mrbar, 'upper': upper, 'lower': lower})
mr_chart = (ggplot(istat, aes(x='time', y='mr')) +
  geom_ribbon(aes(ymin='lower', ymax='upper'), fill='steelblue', alpha=0.25) +
  geom_hline(aes(yintercept=mr.mean()), size=3, color='darkgrey') +
  geom_line(size=1) + geom_point(size=5) +
  labs(x='Time (Subgroup)', y='Moving Range', subtitle='Moving Range Chart'))

# Save the plot
mr_chart.save('images/05_moving_range_chart.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;p&gt;The moving range chart shows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Center line: The average moving range (mrbar)&lt;/item&gt;
      &lt;item&gt;Upper control limit: Based on the estimated process standard deviation&lt;/item&gt;
      &lt;item&gt;Lower control limit: Set to 0 (moving ranges can‚Äôt be negative)&lt;/item&gt;
      &lt;item&gt;Individual points: Each moving range value&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This chart helps us monitor process variation when we have individual measurements rather than subgroups.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html"/><published>2025-11-26T08:40:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055935</id><title>A cell so minimal that it challenges definitions of life</title><updated>2025-11-26T15:09:58.641101+00:00</updated><content>&lt;doc fingerprint="b629199a712103d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Cell So Minimal That It Challenges Definitions of Life&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Life‚Äôs fundamental structure is the cell, and so the main things that a cell does ‚Äî processing biomolecules, growing, replicating its genetic material and producing a new body ‚Äî are considered hallmarks of life. But earlier this year, scientists discovered a cell so severely stripped of essential functions that it challenges biologists‚Äô definitions of what counts as a living thing.&lt;/p&gt;
    &lt;p&gt;The species is a single-celled organism known only by the mysterious sequence of its genetic code. Its genome is fantastically small: Along the organism‚Äôs evolutionary journey, it seems to have gotten rid of most of it. According to the shocked researchers who published the discovery in a preprint uploaded to biorxiv.org in May, the lost genes include those central to cell metabolism, meaning it can neither process nutrients nor grow on its own.&lt;/p&gt;
    &lt;p&gt;Other cells with highly reduced genomes still encode proteins to create amino acids, break down carbohydrates for energy or synthesize vitamins. All this appears to be absent from the cell, which seems to be a parasite entirely dependent on a host or cellular community to meet its nutritional needs. Until now, these genetic pathways were considered fundamental for the survival of any cell.&lt;/p&gt;
    &lt;p&gt;The organism‚Äôs ‚Äúreplicative core‚Äù ‚Äî the genetic components needed to reproduce itself ‚Äî remains, making up more than half of its genome.&lt;/p&gt;
    &lt;p&gt;‚ÄúMetabolism is one of the key components of how we often define life,‚Äù said Takuro Nakayama, an evolutionary microbiologist at the University of Tsukuba in Japan who led the team. The cell‚Äôs discovery ‚Äúchallenges this by suggesting a cell can exist almost entirely without its own. It demonstrates that the diversity of cellular life is far greater than we knew and that organisms do not always follow our definitions.‚Äù&lt;/p&gt;
    &lt;p&gt;While this form of life is new to science, it‚Äôs possible that organisms like it are common. A huge proportion of microbial biodiversity may be hiding in recursive interrelationships between parasitic and host microbes, said Puri L√≥pez-Garc√≠a, a microbial ecologist at the French National Center for Scientific Research in Paris who was not involved in the study.&lt;/p&gt;
    &lt;p&gt;‚ÄúThe diversity of archaea and bacteria that appear to belong to these supergroups of parasitic organisms is very, very large,‚Äù she said. For bacteria, it may be between 25% and 50% of the group‚Äôs total share of species, she suggested.&lt;/p&gt;
    &lt;p&gt;The discovery pushes the boundaries of our knowledge of just how small and simple cellular life can become, as it evolves even into forms that are barely alive.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Extraordinary Discovery&lt;/head&gt;
    &lt;p&gt;Nakayama has built a scientific career out of looking more closely than other researchers typically do. He considers an already tiny cell and wonders: Are there even smaller cells that make a home there?&lt;/p&gt;
    &lt;p&gt;‚ÄúThe difference [in size between parasitic and host cells] can sometimes be like that between a human and Godzilla,‚Äù Nakayama said. He is fascinated by the potentially vast amount of undiscovered biodiversity these relationships might contain, and his lab looks for such relationships in seawater. The ocean is a nutrient-poor environment that incentivizes cells to form trading partnerships. Sometimes they float along together, loosely tethered, exchanging rare nutrients and energy. Other times their arrangements are more organized.&lt;/p&gt;
    &lt;p&gt;Citharistes regius is a globally widespread single-celled dinoflagellate that has a walled, pouchlike external chamber for housing symbiotic cyanobacteria. Nakayama and his team searched for the alga by scooping seawater samples from the Pacific Ocean using a fine-mesh net. A common technique is to sequence whatever DNA can be found in the soup of such a sample, an approach called metagenomics.&lt;/p&gt;
    &lt;p&gt;‚ÄúThat method is incredibly powerful for capturing a broad overview,‚Äù Nakayama said. ‚ÄúHowever, with such data, it is often difficult to maintain the link between a sequence and the specific cell it came from, and rare organisms can be easily missed.‚Äù His team‚Äôs more targeted approach involves microscopically identifying and physically isolating a single target cell from that mixed sample.&lt;/p&gt;
    &lt;p&gt;Back on shore in the Tsukuba lab, after the researchers confirmed they had C. regius, they sequenced every genome associated with that one cell. As expected, they found DNA from its symbiotic cyanobacteria, but they found something else, too: sequences that belong to an archaeon, a member of the domain of life thought to have given rise to eukaryotes like us.&lt;/p&gt;
    &lt;p&gt;At first, Nakayama and his colleagues thought they had made a mistake. The archaeal genome is tiny: just 238,000 base pairs end to end. In comparison, humans have a few billion base pairs, and even E. coli bacteria work with several million. (C. regius‚Äô symbiotic cyanobacteria have 1.9 million base pairs.) Previously, the smallest known archaeal genome was the one belonging to Nanoarchaeum equitans ‚Äî at 490,000 base pairs, it is more than twice as long as the new one the researchers found. They initially figured that this tiny genome ‚Äî too large to be merely statistical noise ‚Äî was an abbreviated piece of a much larger genome, erroneously compiled by their software.&lt;/p&gt;
    &lt;p&gt;‚ÄúAt first, we suspected it might be an artifact of the genome-assembly process,‚Äù Nakayama recalled. To check, the team sequenced the genome using different technologies and ran the data through multiple computer programs that assemble fragments of DNA sequences into a full genome. The various approaches all reconstructed the exact same 238,000-base-pair circular genome. ‚ÄúThis consistency is what convinced us it was the real, complete genome,‚Äù he said.&lt;/p&gt;
    &lt;p&gt;This meant that Nakayama and his team had a new organism on their hands. They named the microbe Candidatus Sukunaarchaeum mirabile (hereafter referred to as Sukunaarchaeum) for its remarkably tiny genome ‚Äî after Sukuna-biko-na, a Shinto deity notable for his short stature, plus a Latin word for ‚Äúextraordinary.‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;The Spectrum of Quasi-Life&lt;/head&gt;
    &lt;p&gt;When the team consulted databases of known genes to analyze the archaeon, they found its small size was the result of a whole lot that was missing.&lt;/p&gt;
    &lt;p&gt;Sukunaarchaeum encodes the barest minimum of proteins for its own replication, and that‚Äôs about all. Most strangely, its genome is missing any hints of the genes required to process and build molecules, outside of those needed to reproduce. Lacking those metabolic components, the organism must outsource the processes for growth and maintenance to another cell, a host upon which the microbe is entirely dependent.&lt;/p&gt;
    &lt;p&gt;Other symbiotic microbes have scrapped much of their genomes, including Sukunaarchaeum‚Äôs evolutionary relatives. The researchers‚Äô analysis suggested that the microbe is part of the DPANN archaea, sometimes called nanoarchaea or ultra-small archaea, which are characterized by small size and small genomes. DPANN archaea are generally thought to be symbiotes that cling to the outside of larger prokaryotic microbes, and plenty of them have substantially reduced genomes to match that lifestyle. But until now, none of the DPANN species had genomes quite this pared back. And Sukunaarchaeum branched off the DPANN lineage early, suggesting that it had taken its own evolutionary journey.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis realm of the archaea is pretty mysterious in general,‚Äù said Brett Baker, a microbial ecologist at the University of Texas, Austin who was not involved in the work. ‚Äú[DPANN archaea are] obviously limited in their metabolic capabilities.‚Äù&lt;/p&gt;
    &lt;p&gt;While Sukunaarchaeum may provide some undetermined benefit for its host ‚Äî which could be C. regius, the symbiotic cyanobacteria or another cell entirely ‚Äî it‚Äôs probably a self-absorbed parasite. ‚ÄúIts genome reduction is driven by entirely selfish motives, consistent with a parasitic lifestyle,‚Äù said Tim Williams, a microbiologist at the University of Technology Sydney who was not involved in the study. It cannot contribute metabolic products, so the relationship between Sukunaarchaeum and any other cell would likely be a one-way street.&lt;/p&gt;
    &lt;p&gt;Other microbes have evolved similarly extreme, streamlined forms. For instance, the bacterium Carsonella ruddii, which lives as a symbiont within the guts of sap-feeding insects, has an even smaller genome than Sukunaarchaeum, at around 159,000 base pairs. However, these and other super-small bacteria have metabolic genes to produce nutrients, such as amino acids and vitamins, for their hosts. Instead, their genome has cast off much of their ability to reproduce on their own.&lt;/p&gt;
    &lt;p&gt;‚ÄúThey are on the way to becoming organelles. This is the way mitochondria and chloroplasts are thought to have evolved,‚Äù Williams said. ‚ÄúBut Sukunaarchaeum has gone in the opposite direction: The genome retains genes required for its own propagation, but lost most, if not all, of its metabolic genes.‚Äù&lt;/p&gt;
    &lt;p&gt;Soon after Nakayama‚Äôs team posted their results online, they got a big response. ‚ÄúWhen we saw the preprint, this was really quite exciting in the lab,‚Äù said Thijs Ettema, an evolutionary microbiologist and expert on archaeal genomics at Wageningen University &amp;amp; Research in the Netherlands, who was not involved in the work. ‚ÄúThese types of organisms [with reduced genomes] have been found before, but not as extreme as this.‚Äù&lt;/p&gt;
    &lt;p&gt;Some news reports went so far as to imply that Sukunaarchaeum is on its way to evolving into a virus. However, while both Sukunaarchaeum and viruses are reliant on a host cell for very basic biological functions, viruses can‚Äôt reproduce on their own.&lt;/p&gt;
    &lt;p&gt;‚ÄúThere is a fundamental gap between Sukunaarchaeum and viruses,‚Äù Nakayama said. ‚ÄúSukunaarchaeum retains its own core machinery for gene expression, including ribosomes, albeit in a simplified form. This is in stark contrast to viruses, which lack ribosomes and must hijack the host‚Äôs cellular systems to replicate.‚Äù&lt;/p&gt;
    &lt;p&gt;The findings fit into a larger discussion about how we define life, Ettema said, since nature routinely evolves exceptions that defy simple categorization. ‚ÄúMost likely it cannot live independently,‚Äù he said. ‚ÄúYou could say the same of bacterial symbionts. And what do we call organelles like mitochondria and plastids? ‚Ä¶ At what point should we call things alive?‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;A Minimalist Lifestyle&lt;/head&gt;
    &lt;p&gt;Many questions about Sukunaarchaeum remain unresolved. For one, a large portion of its genome is made up of genes that don‚Äôt match any known sequences. They seem to encode large proteins, which is uncommon in such radically reduced organisms.&lt;/p&gt;
    &lt;p&gt;Nakayama and his colleagues think these large proteins are employed on the cell membrane and somehow support interactions between the archaeon and its host. That would fit with the lifestyles of other studied DPANN archaea as well, Ettema said, which are generally thought to be ectosymbionts, adhering to the outside of comparatively immense hosts.&lt;/p&gt;
    &lt;p&gt;Although Sukunaarchaeum was found in association with the dinoflagellate C. regius, its true host‚Äôs identity is unknown. C. regius is a eukaryote, but DPANN archaea generally associate with other archaea. Also up for debate: Is it attaching to the outside of a host cell, like other DPANN archaea, or is it living internally ‚Äî or both? Answering these questions would require setting human eyes on the archaeon for the first time; at this point it‚Äôs only known from a curious string of genetic data.&lt;/p&gt;
    &lt;p&gt;There is also a slim possibility that these genes are the ‚Äúlost‚Äù metabolic genes after all, L√≥pez-Garc√≠a said, if they have evolved so far from their original sequences as to be unrecognizable. ‚ÄúBecause the genome is so fast-evolving, maybe some of these functions correspond to metabolic functions, but the divergence is so much that we cannot identify the [gene] homologue [in the database],‚Äù she said.&lt;/p&gt;
    &lt;p&gt;Even stranger minimalist lifestyles or more reduced genomes may be out there, but researchers may miss them, Ettema said. Traditional analytical approaches for surveying the genomes of microbial samples could flag their tiny genomes as incomplete or low quality and discard them, or skip them entirely, he said. ‚Äú[The DNA] might have been present in the samples, but it was removed after sequencing, and hence overlooked.‚Äù&lt;/p&gt;
    &lt;p&gt;When Nakayama and his colleagues searched a database of marine environmental sequence data from the world‚Äôs oceans to see if the new microbe popped up anywhere else, they didn‚Äôt find any matches. But they did detect many very similar sequences from what are likely to be close relatives. Sukunaarchaeum may be the tip of a very large microbial iceberg, one floating in a vast ocean of microbial diversity: tiny microbes clinging to slightly less tiny microbes, perhaps inside other microbes, the stories of their ancient relationships only beginning to be revealed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/a-cell-so-minimal-that-it-challenges-definitions-of-life-20251124/"/><published>2025-11-26T10:06:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055944</id><title>I don't care how well your "AI" works</title><updated>2025-11-26T15:09:57.836114+00:00</updated><content>&lt;doc fingerprint="2510435469b48401"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;I don't care how well your "AI" works&lt;/head&gt;
    &lt;p&gt;The other day I was sitting on the doorstep of a hackerspace, eating a falafel sandwich while listening to the conversation inside. The topic shifted to the use of ‚ÄúAI‚Äù for everyday tasks, people casually started elaborating on how they use ‚Äúchat assistants‚Äù to let them write pieces of code or annoying emails. The situation is a blueprint for many conversations I had in recent months. What followed in most of them, almost like a reflex, was a self-justification of why the way they use these tools is fine, while other approaches were reckless.&lt;/p&gt;
    &lt;p&gt;I find it particularly disillusioning to realize how deep the LLM brainworm is able to eat itself even into progressive hacker circles.&lt;/p&gt;
    &lt;head rend="h2"&gt;the grind&lt;/head&gt;
    &lt;p&gt;I encountered friends who got fully sucked into the belly of the vibecoding grind. Proficient, talented coders who seem to experience some sort of existential crisis. Staring at the screen in disbelief, unable to let go of Cursor, or whatever tool is the shit right now. Soaking in an unconscious state of harmful coping. Seeing that felt terrifyingly close to witnessing a friend developing a drinking problem.&lt;/p&gt;
    &lt;p&gt;And yeah, I get it. We programmers are currently living through the devaluation of our craft, in a way and rate we never anticipated possible. A fate that designers, writers, translators, tailors or book-binders lived through before us. Not that their craft would die out, but it would be mutilated ‚Äî condemned to the grueling task of cleaning up what the machines messed up. Unsurprisingly, some of us are not handling the new realities well.&lt;/p&gt;
    &lt;head rend="h2"&gt;new realities&lt;/head&gt;
    &lt;p&gt;I personally don‚Äôt touch LLMs with a stick. I don‚Äôt let them near my brain. Many of my friends share that sentiment.&lt;/p&gt;
    &lt;p&gt;But I think it‚Äôs important to acknowledge that we‚Äôre in a priviliged situation to be able to do so. People are forced to use these systems ‚Äî by UI patterns, bosses expectations, knowledge polution making it increasingly hard to learn things, or just peer pressure. The world adapts to these technologies, and not using them can be a substantial disadvantage in school, university, or anywhere.&lt;/p&gt;
    &lt;p&gt;A lot of the public debate about AI focuses on the quality of its output. Calling out biases, bullshit marketing pledges, making fun of the fascinating ways in which they fail, and so on. Of course, the practical issues are important to discuss, but we shouldn‚Äôt lean too much on that aspect in our philosophy and activisim, or we risk missing the actual agenda of AI.&lt;/p&gt;
    &lt;p&gt;No matter how well ‚ÄúAI‚Äù works, it has some deeply fundamental problems, that won‚Äôt go away with technical progress. I‚Äôd even go as far and say they are intentional.&lt;/p&gt;
    &lt;head rend="h2"&gt;on control&lt;/head&gt;
    &lt;p&gt;Our ability to use tools is an integral part of the human experience. They allow us to do things that we otherwise couldn‚Äôt do. They shape how we think, and consequently who we are.&lt;/p&gt;
    &lt;p&gt;When we use a tool, it becomes part of us1. That‚Äôs not just the case for hammers, pens, or cars, but also for a notebook used to organize thoughts. It becomes part of our cognitive process. Computer are not different. While I‚Äôm typing this text, my fingers are flying over the keyboard, switching windows, opening notes, looking up words in a dictionary. All while I‚Äôm fully focused on the meta-task of getting my thoughts out, unaware of all the tiny miracles happening.&lt;/p&gt;
    &lt;p&gt;Our minds are susceptible to outside cues. When we read news articles we tend to believe what seems plausible. When we review code we generally expect it to behave the way it looks, even when we don‚Äôt have the context to assess that. The same is true for text: When we let a model transform notes into a blog post, a lot of context and nuance is added. We read it and believe the output to be what we thought. It‚Äôs subtle.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;on a deeper level, writing is more than just the process by which you obtain a piece of text, right? it‚Äôs also about finding out what you wanted to say in the first place, and how you wanted to say it. this post existed in my head first as a thought, then it started to gel into words, and then i tried pulling those words out to arrange them in a way that (hopefully) gets my point across. there is nothing extra there, no filler. i alone can get the thought out and writing is how i do that.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Excerpt of a post by @thekla@mystical.garden&lt;/p&gt;
    &lt;head rend="h2"&gt;on power&lt;/head&gt;
    &lt;p&gt;In a world where fascists redefine truth, where surveillance capitalist companies, more powerful than democratically elected leaders, exert control over our desires, do we really want their machines to become part of our thought process? To share our most intimate thoughts and connections with them?&lt;/p&gt;
    &lt;p&gt;AI systems exist to reinforce and strengthen existing structures of power and violence. They are the wet dream of capitalists and fascists. Enormous physical infrastructure designed to convert capital into power, and back into capital. Those who control the infrastructure, control the people subject to it.&lt;/p&gt;
    &lt;p&gt;AI systems being egregiously resource intensive is not a side effect ‚Äî it‚Äôs the point.&lt;/p&gt;
    &lt;p&gt;Craft, expression and skilled labor is what produces value, and that gives us control over ourselves. In order to further centralize power, craft and expression need to be destroyed2. And they sure are trying.&lt;/p&gt;
    &lt;head rend="h2"&gt;what‚Äôs left&lt;/head&gt;
    &lt;p&gt;How can we be ourselves in this world? What we‚Äôre dealing with here are not questions about AI, but about survival under metastatic capitalism. Shit‚Äôs dire, but there are things we can do. I‚Äôm working on a post about that.&lt;/p&gt;
    &lt;p&gt;Until then, here are some starting points:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Be there for the people around you. Message friends and show them that they matter to you&lt;/item&gt;
      &lt;item&gt;Organize in a union. Together we are stronger.&lt;/item&gt;
      &lt;item&gt;Take care of your mind. Spend less time on social media. Use the freed capacity to educate yourself, go read a book&lt;/item&gt;
      &lt;item&gt;Bring something into existence that wouldn‚Äôt otherwise exist&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The most disobedient thing we can do is to thrive.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fokus.cool/2025/11/25/i-dont-care-how-well-your-ai-works.html"/><published>2025-11-26T10:08:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46056583</id><title>Cekura (YC F24) Is Hiring</title><updated>2025-11-26T15:09:57.288814+00:00</updated><content>&lt;doc fingerprint="ddc9e9533901a146"&gt;
  &lt;main&gt;
    &lt;p&gt;Voice AI and Chat AI agents: Testing and Observability&lt;/p&gt;
    &lt;p&gt;Cekura (YC F24) is one of the fastest-growing companies in its batch, with strong revenue traction. We‚Äôre well-funded, backed by premier investors, and have years of runway.&lt;/p&gt;
    &lt;p&gt;We‚Äôre building the reliability layer for Conversational Agents. Teams use Cekura to simulate and monitor their AI agents end-to-end - measuring latency, barge-in, instruction-following, regressions, and more across phone, chat, SMS, and web. Customers love the product - and we‚Äôre just getting started.&lt;/p&gt;
    &lt;p&gt;You‚Äôre joining at an inflection point. As Forward Deployed Engineer, you‚Äôll build the playbooks, processes, and relationships that define how Cekura partners with technical customers for long-term success. You‚Äôll be both strategist and hands-on operator.&lt;/p&gt;
    &lt;p&gt;Excited to help world-class teams ship reliable AI agents - and wear both the customer and engineer hats? Let‚Äôs talk.&lt;/p&gt;
    &lt;p&gt;Cekura is a Y Combinator‚Äìbacked startup redefining AI voice agent reliability. Founded by IIT Bombay alumni with research credentials from ETH Zurich and proven success in high-stakes trading, our team built Cekura to solve the cumbersome, error-prone nature of manual voice agent testing.&lt;/p&gt;
    &lt;p&gt;We automate the testing and observability of AI voice agents by simulating thousands of realistic, real-world conversational scenarios‚Äîfrom ordering food and booking appointments to conducting interviews. Our platform leverages custom and AI-generated datasets, detailed workflows, and dynamic persona simulations to uncover edge cases and deliver actionable insights. Real-time monitoring, comprehensive logs, and instant alerting ensure that every call is optimized and production-ready.&lt;/p&gt;
    &lt;p&gt;In a market rapidly expanding with thousands of voice agents, Cekura stands out by guaranteeing dependable performance, reducing time-to-market, and minimizing costly production errors. We empower teams to demonstrate reliability before deployment, making it easier to build trust with clients and users.&lt;/p&gt;
    &lt;p&gt;Join us in shaping the future of voice technology. Learn more at cekura.ai.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/cekura-ai/jobs/0ZGLW69-forward-deployed-engineer-us"/><published>2025-11-26T12:01:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46056757</id><title>Qiskit open-source SDK for working with quantum computers</title><updated>2025-11-26T15:09:56.646529+00:00</updated><content>&lt;doc fingerprint="7133719a8c8455c8"&gt;
  &lt;main&gt;
    &lt;p&gt;Qiskit is an open-source SDK for working with quantum computers at the level of extended quantum circuits, operators, and primitives.&lt;/p&gt;
    &lt;p&gt;This library is the core component of Qiskit, which contains the building blocks for creating and working with quantum circuits, quantum operators, and primitive functions (Sampler and Estimator). It also contains a transpiler that supports optimizing quantum circuits, and a quantum information toolbox for creating advanced operators.&lt;/p&gt;
    &lt;p&gt;For more details on how to use Qiskit, refer to the documentation located here:&lt;/p&gt;
    &lt;p&gt;https://quantum.cloud.ibm.com/docs/&lt;/p&gt;
    &lt;p&gt;We encourage installing Qiskit via &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;pip install qiskit&lt;/code&gt;
    &lt;p&gt;Pip will handle all dependencies automatically and you will always install the latest (and well-tested) version.&lt;/p&gt;
    &lt;p&gt;To install from source, follow the instructions in the documentation.&lt;/p&gt;
    &lt;p&gt;Now that Qiskit is installed, it's time to begin working with Qiskit. The essential parts of a quantum program are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Define and build a quantum circuit that represents the quantum state&lt;/item&gt;
      &lt;item&gt;Define the classical output by measurements or a set of observable operators&lt;/item&gt;
      &lt;item&gt;Depending on the output, use the Sampler primitive to sample outcomes or the Estimator primitive to estimate expectation values.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create an example quantum circuit using the &lt;code&gt;QuantumCircuit&lt;/code&gt; class:&lt;/p&gt;
    &lt;code&gt;import numpy as np
from qiskit import QuantumCircuit

# 1. A quantum circuit for preparing the quantum state |000&amp;gt; + i |111&amp;gt; / ‚àö2
qc = QuantumCircuit(3)
qc.h(0)             # generate superposition
qc.p(np.pi / 2, 0)  # add quantum phase
qc.cx(0, 1)         # 0th-qubit-Controlled-NOT gate on 1st qubit
qc.cx(0, 2)         # 0th-qubit-Controlled-NOT gate on 2nd qubit&lt;/code&gt;
    &lt;p&gt;This simple example creates an entangled state known as a GHZ state &lt;code&gt;h&lt;/code&gt;), Phase gate (&lt;code&gt;p&lt;/code&gt;), and CNOT gate (&lt;code&gt;cx&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Once you've made your first quantum circuit, choose which primitive you will use. Starting with the Sampler, we use &lt;code&gt;measure_all(inplace=False)&lt;/code&gt; to get a copy of the circuit in which all the qubits are measured:&lt;/p&gt;
    &lt;code&gt;# 2. Add the classical output in the form of measurement of all qubits
qc_measured = qc.measure_all(inplace=False)

# 3. Execute using the Sampler primitive
from qiskit.primitives import StatevectorSampler
sampler = StatevectorSampler()
job = sampler.run([qc_measured], shots=1000)
result = job.result()
print(f" &amp;gt; Counts: {result[0].data['meas'].get_counts()}")&lt;/code&gt;
    &lt;p&gt;Running this will give an outcome similar to &lt;code&gt;{'000': 497, '111': 503}&lt;/code&gt; which is &lt;code&gt;000&lt;/code&gt; 50% of the time and &lt;code&gt;111&lt;/code&gt; 50% of the time up to statistical fluctuations.
To illustrate the power of the Estimator, we now use the quantum information toolbox to create the operator &lt;code&gt;run()&lt;/code&gt; function, along with our quantum circuit. Note that the Estimator requires a circuit without measurements, so we use the &lt;code&gt;qc&lt;/code&gt; circuit we created earlier.&lt;/p&gt;
    &lt;code&gt;# 2. Define the observable to be measured 
from qiskit.quantum_info import SparsePauliOp
operator = SparsePauliOp.from_list([("XXY", 1), ("XYX", 1), ("YXX", 1), ("YYY", -1)])

# 3. Execute using the Estimator primitive
from qiskit.primitives import StatevectorEstimator
estimator = StatevectorEstimator()
job = estimator.run([(qc, operator)], precision=1e-3)
result = job.result()
print(f" &amp;gt; Expectation values: {result[0].data.evs}")&lt;/code&gt;
    &lt;p&gt;Running this will give the outcome &lt;code&gt;4&lt;/code&gt;. For fun, try to assign a value of +/- 1 to each single-qubit operator X and Y
and see if you can achieve this outcome. (Spoiler alert: this is not possible!)&lt;/p&gt;
    &lt;p&gt;Using the Qiskit-provided &lt;code&gt;qiskit.primitives.StatevectorSampler&lt;/code&gt; and &lt;code&gt;qiskit.primitives.StatevectorEstimator&lt;/code&gt; will not take you very far.
The power of quantum computing cannot be simulated on classical computers and you need to use real quantum hardware to scale to larger quantum circuits.
However, running a quantum circuit on hardware requires rewriting to the basis gates and connectivity of the quantum hardware.
The tool that does this is the transpiler, and Qiskit includes transpiler passes for synthesis, optimization, mapping, and scheduling.
However, it also includes a default compiler, which works very well in most examples.
The following code will map the example circuit to the &lt;code&gt;basis_gates = ["cz", "sx", "rz"]&lt;/code&gt; and a
bidirectional linear chain of qubits &lt;code&gt;coupling_map = [[0, 1], [1, 0], [1, 2], [2, 1]]&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;from qiskit import transpile
from qiskit.transpiler import Target, CouplingMap
target = Target.from_configuration(
    basis_gates=["cz", "sx", "rz"],
    coupling_map=CouplingMap.from_line(3),
)
qc_transpiled = transpile(qc, target=target)&lt;/code&gt;
    &lt;p&gt;Qiskit provides an abstraction layer that lets users run quantum circuits on hardware from any vendor that provides a compatible interface. The best way to use Qiskit is with a runtime environment that provides optimized implementations of Sampler and Estimator for a given hardware platform. This runtime may involve using pre- and post-processing, such as optimized transpiler passes with error suppression, error mitigation, and, eventually, error correction built in. A runtime implements &lt;code&gt;qiskit.primitives.BaseSamplerV2&lt;/code&gt; and &lt;code&gt;qiskit.primitives.BaseEstimatorV2&lt;/code&gt; interfaces. For example,
some packages that provide implementations of a runtime primitive implementation are:&lt;/p&gt;
    &lt;p&gt;Qiskit also provides a lower-level abstract interface for describing quantum backends. This interface, located in &lt;code&gt;qiskit.providers&lt;/code&gt;, defines an abstract &lt;code&gt;BackendV2&lt;/code&gt; class that providers can implement to represent their
hardware or simulators to Qiskit. The backend class includes a common interface for executing circuits on the backends; however, in this interface each provider may perform different types of pre- and post-processing and return outcomes that are vendor-defined. Some examples of published provider packages that interface with real hardware are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-ionq&lt;/item&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-aqt-provider&lt;/item&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-braket-provider&lt;/item&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-quantinuum-provider&lt;/item&gt;
      &lt;item&gt;https://github.com/rigetti/qiskit-rigetti&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can refer to the documentation of these packages for further instructions on how to get access and use these systems.&lt;/p&gt;
    &lt;p&gt;If you'd like to contribute to Qiskit, please take a look at our contribution guidelines. By participating, you are expected to uphold our code of conduct.&lt;/p&gt;
    &lt;p&gt;We use GitHub issues for tracking requests and bugs. Please join the Qiskit Slack community for discussion, comments, and questions. For questions related to running or using Qiskit, Stack Overflow has a &lt;code&gt;qiskit&lt;/code&gt;.
For questions on quantum computing with Qiskit, use the &lt;code&gt;qiskit&lt;/code&gt; tag in the Quantum Computing Stack Exchange (please, read first the guidelines on how to ask in that forum).&lt;/p&gt;
    &lt;p&gt;Qiskit is the work of many people who contribute to the project at different levels. If you use Qiskit, please cite as per the included BibTeX file.&lt;/p&gt;
    &lt;p&gt;The changelog for a particular release is dynamically generated and gets written to the release page on Github for each release. For example, you can find the page for the &lt;code&gt;1.2.0&lt;/code&gt; release here:&lt;/p&gt;
    &lt;p&gt;https://github.com/Qiskit/qiskit/releases/tag/1.2.0&lt;/p&gt;
    &lt;p&gt;The changelog for the current release can be found in the releases tab: The changelog provides a quick overview of notable changes for a given release.&lt;/p&gt;
    &lt;p&gt;Additionally, as part of each release, detailed release notes are written to document in detail what has changed as part of a release. This includes any documentation on potential breaking changes on upgrade and new features. See all release notes here.&lt;/p&gt;
    &lt;p&gt;We acknowledge partial support for Qiskit development from the DOE Office of Science National Quantum Information Science Research Centers, Co-design Center for Quantum Advantage (C2QA) under contract number DE-SC0012704.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Qiskit/qiskit"/><published>2025-11-26T12:26:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46057000</id><title>Indie game developers have a new sales pitch: being 'AI free'</title><updated>2025-11-26T15:09:56.534579+00:00</updated><content>&lt;doc fingerprint="24400f9b8b14505c"&gt;
  &lt;main&gt;
    &lt;p&gt;Earlier this month, Junghun Lee ‚Äî CEO of Nexon, the parent company behind current live-service shooter du jour Arc Raiders ‚Äî made waves in the game development community with a straightforward statement. ‚ÄúIt‚Äôs important to assume that every game company is now using AI,‚Äù he explained. Indie developers were quick to loudly and vociferously call bullshit. ‚ÄúIt‚Äôs just not true,‚Äù Alex Kanaris-Sotiriou, cofounder of R√∂ki and Mythwrecked developer Polygon Treehouse, tells The Verge.&lt;/p&gt;
    &lt;head rend="h1"&gt;Indie game developers have a new sales pitch: being ‚ÄòAI free‚Äô&lt;/head&gt;
    &lt;p&gt;Indie devs are using anti-gen-AI statements to make their games stand out.&lt;/p&gt;
    &lt;p&gt;If you buy something from a Verge link, Vox Media may earn a commission. See our ethics statement.&lt;/p&gt;
    &lt;p&gt;As similar reactions poured in over social media, many developers shared that avoiding generative AI was not only a matter of personal pride, but also a matter of professional marketing ‚Äî one that developers are leveraging to let their players know their games were made by humans.&lt;/p&gt;
    &lt;p&gt;For Kanaris-Sotiriou, the question of adopting the use of gen AI to make games was an easy one to answer. ‚ÄúThe foundations that it‚Äôs built upon, the idea of using other people‚Äôs work without permission to generate artwork [...] are unfair,‚Äù he says.&lt;/p&gt;
    &lt;p&gt;Lee‚Äôs comments are just the latest in a string of notable gaming CEOs declaring that gen AI is the future of the medium. But Kanaris-Sotiriou, along with many of his game development peers, wanted to push back against this assertion. So earlier this year they collaborated on a solution ‚Äî a simple image file of a golden cog-shaped seal that declares, ‚ÄúThis developer assures that no gen AI was used in this indie game.‚Äù&lt;/p&gt;
    &lt;p&gt;They made the image (which Kanaris-Sotiriou tweaked to ensure it didn‚Äôt too closely resemble a more famous seal of approval) freely available for any studio to use in their marketing materials, websites, or game pages. While Kanaris-Sotiriou doesn‚Äôt have hard numbers on its use, the seal shows up on the store pages for Rosewater, Astral Ascent, Quarterstaff, and more. In the Bluesky thread announcing the seal‚Äôs creation, multiple indie developers shared that they put it on their Itch.io pages and on Steam, where it serves as the antithesis to the platform‚Äôs gen AI disclosure rules.&lt;/p&gt;
    &lt;p&gt;Other developers are adopting their own bespoke solutions that act both as an informative statement against gen AI and a philosophical one.&lt;/p&gt;
    &lt;p&gt;‚ÄúAbsolutely everything in Unbeatable was created by human beings without any generative assistance,‚Äù reads a graphic posted by D-Cell Games on Bluesky about its upcoming game Unbeatable. The image was created specifically in response to Lee‚Äôs comments. ‚ÄúEvery frame drawn, every word written, every model sculpted, every line of code typed, every song sung with a real voice, every guitar played with a real hand, every moment flawed and messy because we are, also.‚Äù&lt;/p&gt;
    &lt;p&gt;Where other developers have taken a simple declarative approach against gen AI, the passion in D-Cell‚Äôs statement is apparent and it reads almost like a challenge to those who use the tools. ‚ÄúIgnoring all of the ethical, moral, and legal concerns of using generative AI, it‚Äôs a huge waste of effort,‚Äù says Jeffrey Chiao, studio producer at D-Cell Games, in an email to The Verge. ‚ÄúWe can produce results that meet our quality standards without its assistance.‚Äù&lt;/p&gt;
    &lt;p&gt;Gen AI enthusiasts see the technology as a way to unlock hidden creative potential, and to many it‚Äôs a tool to speed up the time-consuming and costly processes inherent to video game production. Some of the biggest companies are taking advantage of that; EA has announced a partnership with Stability AI, for instance, while Microsoft is using AI to generate gameplay.&lt;/p&gt;
    &lt;p&gt;Ubisoft in particular has had a lot to say about gen AI, with CEO Yves Guillemot calling it ‚Äúas big [of] a revolution for our industry as the shift to 3D‚Äù in a recent earnings call. Players can converse with Ubisoft‚Äôs gen AI-powered Neo NPCs while the company‚Äôs Ghostwriter tool generates short snippets of dialogue called barks. Subnautica 2 and PUBG publisher Krafton suggested its employees voluntarily resign if they can‚Äôt abide by the company‚Äôs new ‚ÄúAI-first‚Äù reorganization. Meanwhile, gen AI assets are showing up in Call of Duty: Black Ops 6 (and again in Black Ops 7), Anno 117: Pax Romana, The Alters, The Finals, Arc Raiders, InZoi, and more.&lt;/p&gt;
    &lt;p&gt;Video game development budgets are ballooning and games are taking longer to release. A tool that can help get games to market quicker and cheaper is an attractive proposition ‚Äî especially in the indie space, where investment has significantly dried up and smaller teams require developers to do multiple jobs. And while generative AI is being used across all levels of the industry (with notable exceptions), the loudest pushback is coming from the space that ostensibly stands to benefit from it the most. ‚ÄúConstraints we face as indies inspire us to develop with really creative solutions,‚Äù Kanaris-Sotiriou says.&lt;/p&gt;
    &lt;p&gt;‚ÄúConstraints we face as indies inspire us to develop with really creative solutions.‚Äù&lt;/p&gt;
    &lt;p&gt;Tom Eastman, president of Battle Suit Aces developer Trinket Studios, echoes that sentiment. He says that the problems gen AI purportedly solves are the very things that make game development so rewarding. He spoke about how, in the final days of working on the studio‚Äôs previous title, Battle Chef Brigade, several key locations in the game didn‚Äôt have finished art. Rather than go through the process of creating the hand-drawn line art that dominates the game‚Äôs aesthetic, the team decided to use less time-consuming watercolors instead. ‚ÄúThose are the interesting creative decisions that are fun to work through, instead of ‚Äòplease magic box solve my problems.‚Äô‚Äù&lt;/p&gt;
    &lt;p&gt;The developers I spoke to acknowledged that as gen AI technology improves, there will be more pressure to use it. And while it‚Äôs difficult to pin down with hard numbers, they also see how their official anti-gen-AI declarations have resonated with their players and communities. ‚ÄúIt‚Äôs almost definitely going to be all around us at this current rate, but I think the things people want in our works aren‚Äôt going to change because of it,‚Äù says Chiao. ‚ÄúSo we‚Äôll hold on our own and continue doing things our way ‚Äî it‚Äôs more fun that way.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/entertainment/827650/indie-developers-gen-ai-nexon-arc-raiders"/><published>2025-11-26T13:05:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46057304</id><title>I DM'd a Korean Presidential Candidate and Ended Up Building His Core Campaign</title><updated>2025-11-26T15:09:56.476074+00:00</updated><content/><link href="https://medium.com/@wjsdj2008/i-dmd-a-korean-presidential-candidate-and-ended-up-building-his-core-campaign-platform-the-38eb1c5f5e7d"/><published>2025-11-26T13:40:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46057488</id><title>Voyager 1 Is About to Reach One Light-Day from Earth</title><updated>2025-11-26T15:09:54.574753+00:00</updated><content/><link href="https://scienceclock.com/voyager-1-is-about-to-reach-one-light-day-from-earth/"/><published>2025-11-26T14:02:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46058065</id><title>OpenAI needs to raise at least $207B by 2030 so it can continue to lose money</title><updated>2025-11-26T15:09:53.652100+00:00</updated><content>&lt;doc fingerprint="923f1c7588aac3e9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;FT Alphaville&lt;/head&gt;&lt;p&gt;Register to unlock this article&lt;/p&gt;&lt;head rend="h1"&gt;&lt;quote&gt;OpenAI needs to raise at least $207bn by 2030 so it can continue to lose money, HSBC estimates&lt;/quote&gt;&lt;/head&gt;&lt;p&gt;FT Alphaville is free&lt;/p&gt;&lt;p&gt;Register to keep reading&lt;/p&gt;&lt;p&gt;Want a deeper look?&lt;/p&gt;Explore our recommended subscriptions&lt;head rend="h2"&gt;Explore more offers.&lt;/head&gt;&lt;head rend="h3"&gt;Trial&lt;/head&gt;&lt;p&gt;$1 for 4 weeks&lt;/p&gt;&lt;p&gt;Then $75 per month. Complete digital access to quality FT journalism on any device. Cancel or change your plan anytime during your trial.&lt;/p&gt;&lt;head rend="h3"&gt;Standard Digital&lt;/head&gt;&lt;p&gt;$45 per month&lt;/p&gt;&lt;p&gt;Get essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%&lt;/p&gt;&lt;head rend="h3"&gt;Premium Digital&lt;/head&gt;&lt;p&gt;Complete coverage&lt;/p&gt;&lt;p&gt;$75 per month&lt;/p&gt;&lt;p&gt;Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.&lt;/p&gt;&lt;p&gt;Check whether you already have access via your university or organisation.&lt;/p&gt;&lt;p&gt;Terms &amp;amp; Conditions apply&lt;/p&gt;&lt;head rend="h2"&gt;Explore our full range of subscriptions.&lt;/head&gt;&lt;head rend="h3"&gt;For individuals&lt;/head&gt;&lt;p&gt;Discover all the plans currently available in your country&lt;/p&gt;&lt;head rend="h3"&gt;For multiple readers&lt;/head&gt;&lt;p&gt;Digital access for organisations. Includes exclusive features and content.&lt;/p&gt;&lt;head rend="h2"&gt;Why the FT?&lt;/head&gt;&lt;p&gt;See why over a million readers pay to read the Financial Times.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ft.com/content/23e54a28-6f63-4533-ab96-3756d9c88bad"/><published>2025-11-26T15:06:37+00:00</published></entry></feed>