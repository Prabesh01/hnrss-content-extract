<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-07T15:13:58.366337+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46515696</id><title>Opus 4.5 is not the normal AI agent experience that I have had thus far</title><updated>2026-01-07T15:14:06.949591+00:00</updated><content>&lt;doc fingerprint="26499875abe73fe9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Opus 4.5 is going to change everything&lt;/head&gt;
    &lt;p&gt;If you had asked me three months ago about these statements, I would have said only someone who’s never built anything non-trivial would believe they’re true. Great for augmenting a developer’s existing workflow, and completions are powerful, but agents replacing developers entirely? No. Absolutely not.&lt;/p&gt;
    &lt;p&gt;Today, I think that AI coding agents can absolutely replace developers. And the reason that I believe this is Claude Opus 4.5.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opus 4.5 is not normal&lt;/head&gt;
    &lt;p&gt;And by “normal”, I mean that it is not the normal AI agent experience that I have had thus far. So far, AI Agents seem to be pretty good at writing spaghetti code and after 9 rounds of copy / paste errors into the terminal and “fix it” have probably destroyed my codebase to the extent that I’ll be throwing this whole chat session out and there goes 30 minutes I’m never getting back.&lt;/p&gt;
    &lt;p&gt;Opus 4.5 feels to me like the model that we were promised - or rather the promise of AI for coding actually delivered.&lt;/p&gt;
    &lt;p&gt;One of the toughest things about writing that last sentence is that the immediate response from you should be, “prove it”. So let me show you what I’ve been able to build.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 1 - Windows Image Conversion Utility&lt;/head&gt;
    &lt;p&gt;I first noticed that Opus 4.5 was drastically different when I used it to build a Windows utility to right-click an image and convert it to different file types. This was basically a one shot build after asking Opus the best way to add a right-click menu to the file explorer.&lt;/p&gt;
    &lt;p&gt;What amazed me through the process of building this was Opus 4.5 ability to get most things right on the first try. And if it ran into errors, it would try and build using the dotnet CLI, read the errors and iterate until fixed. The only issue I had was Opus inability to see XAML errors, which I used Visual Studio to see and copy / paste back into the agent.&lt;/p&gt;
    &lt;p&gt;Opus built a site for me to distribute it and handled the bundling of the executable so as to use a powershell script for the install, uninstall. It also built the GitHub Actions which do the release and update the landing page so that all I have to do is push source.&lt;/p&gt;
    &lt;p&gt;The only place I had to use other tools was for the logo - where I used Figma’s AI to generate a bunch of different variations - but then Opus wrote the scripts to convert that SVG to the right formats for icons, even store distribution if I chose to do so.&lt;/p&gt;
    &lt;p&gt;Now this is admittedly not a complex application. This is a small Windows utility that is doing basically one thing. It’s not like I asked Opus 4.5 to build Photoshop.&lt;/p&gt;
    &lt;p&gt;Except I kind of did.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 2 - Screen recording / editing&lt;/head&gt;
    &lt;p&gt;I was so impressed by Opus 4.5 work on this utility that I decided to make a simple GIF recording utility similar to LICEcap for Mac. Great app, questionable name.&lt;/p&gt;
    &lt;p&gt;But that proved to be so easy, that I went ahead and continued adding features, including capturing and editing video, static images, adding shapes, cropping, blurs and more. I’m still working on this application as it turns out building a full on image/video editor is kind of a big undertaking. But I got REALLY far in a matter of hours. HOURS, PEOPLE.&lt;/p&gt;
    &lt;p&gt;I don’t have a fancy landing page for this one yet, but you can view all of the source code here.&lt;/p&gt;
    &lt;p&gt;I realized that if I could build a video recording app, I could probably build anything at all - at least UI-wise. But the achilles heel of all AI agents is when they have to glue together backend systems - which any real world application is going to have - auth, database, API, storage.&lt;/p&gt;
    &lt;p&gt;Except Opus 4.5 can do that too.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 3 - AI Posting Utility&lt;/head&gt;
    &lt;p&gt;Armed with my confidence in Opus 4.5, I took on a project that I had built in React Native last year and finished for Android, but gave up in the final stretches (as one does).&lt;/p&gt;
    &lt;p&gt;The application is for my wife who owns a small yard sign franchise. The problem is that she has a Facebook page for the business, but never posts there because it’s time consuming. But any good small business has a vibrant page where people can see photos of your business doing…whatever the heck it does. So people know that it exsits and is alive and well.&lt;/p&gt;
    &lt;p&gt;The idea is simple - each time she sets up a yard sign, she takes a picture to send to the person who ordered it so they can see it was setup. So why not have a mobile app where she can upload 10 images at a time, and the app will use AI to generate captions and then schedule them and post them over the coming week.&lt;/p&gt;
    &lt;p&gt;It’s a simple premise, but it has a lot of moving parts - there is the Facebook authentication which is a caper in and of itself - not for the faint of heart. There is authentication with a backend, there is file storage for photos that are scheduled to go out, there is the backend process which needs to post the photo. It’s a full on backend setup.&lt;/p&gt;
    &lt;p&gt;As it turns out, I needed to install some blinds in the house so I thought - why don’t I see if Opus 4.5 can build this while I install the blinds.&lt;/p&gt;
    &lt;p&gt;So I fired up a chat session and just started by telling Opus 4.5 what I wanted to build and how it would recommend handling the backend. It recommended several options but settled on Firebase. I’m not now nor have I ever been a Firebase user, but at this point I trust Opus 4.5 a lot. Probably too much.&lt;/p&gt;
    &lt;p&gt;So I created a Firebase account, upgraded to the Blaze plan with alerts for billing and Opus 4.5 got to work.&lt;/p&gt;
    &lt;p&gt;By the time I was done installing blinds, I had a functional iOS application for using AI to caption photos and posting them on a schedule to Facebook.&lt;/p&gt;
    &lt;p&gt;When I say that Opus 4.5 built this almost entirely, I mean it. It used the &lt;code&gt;firebase&lt;/code&gt; CLI to stand up any resources it needed and would tag me in for certain things like upgrading a project to the Blaze plan for features like storage, etc. The best part was that when the Firebase cloud functions would throw errors, it would automatically grep those logs, find the error and resolve it. And all it needed was a CLI. No MCP Server. No fancy prompt file telling it how to use Firebase.&lt;/p&gt;
    &lt;p&gt;And of course, since it’s solved, I had Opus 4.5 create a backend admin dashboard so I could see what she’s got pending and make any adjustments.&lt;/p&gt;
    &lt;p&gt;And since it did in a few hours what had taken me two months of work in the evenings instead of being a decent husband, I decided to make up for my dereliction of duties by building her another app for her sign business that would make her life just a bit more delightful - and eliminate two other apps she is currently paying for.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project 4 - Order tracking and routing&lt;/head&gt;
    &lt;p&gt;This app parses orders from her business Gmail account to show her what sign setups / pickups she has for the day, calculates how long its going to take to go to each stop, calculates the optimal route when there is more than one stop and tracks drive time for tax purposes. She was previously using two paid apps for the last two features there.&lt;/p&gt;
    &lt;p&gt;This app also uses Firebase. Again, Opus one-shotted the Google auth email integration. This is the kind of thing that is painstakingly miserable by hand. And again, Firebase is so well suited here because Opus knows how to use the Firebase CLI so well. It needs zero instruction.&lt;/p&gt;
    &lt;head rend="h3"&gt;BUT YOU DON’T KNOW HOW THE CODE WORKS&lt;/head&gt;
    &lt;p&gt;No I don’t. I have a vague idea, but you are right - I do not know how the applications are actually assembled. Especially since I don’t know Swift at all.&lt;/p&gt;
    &lt;p&gt;This used to be a major hangup for me. I couldn’t diagnose problems when things went sideways. With Opus 4.5, I haven’t hit that wall yet—Opus always figures out what the issue is and fixes its own bugs.&lt;/p&gt;
    &lt;p&gt;The real question is code quality. Without understanding how it’s built, how do I know if there’s duplication, dead code, or poor patterns? I used to obsess over this. Now I’m less worried that a human needs to read the code, because I’m genuinely not sure that they do.&lt;/p&gt;
    &lt;p&gt;Why does a human need to read this code at all? I use a custom agent in VS Code that tells Opus to write code for LLMs, not humans. Think about it—why optimize for human readability when the AI is doing all the work and will explain things to you when you ask?&lt;/p&gt;
    &lt;p&gt;What you don’t need: variable names, formatting, comments meant for humans, or patterns designed to spare your brain.&lt;/p&gt;
    &lt;p&gt;What you do need: simple entry points, explicit code with fewer abstractions, minimal coupling, and linear control flow.&lt;/p&gt;
    &lt;p&gt;Here’s my custom agent prompt:&lt;/p&gt;
    &lt;code&gt;You are an AI-first software engineer. Assume all code will be written and maintained by LLMs, not humans. Optimize for model reasoning, regeneration, and debugging — not human aesthetics.

These coding principles are mandatory:

1. Structure
- Use a consistent, predictable project layout.
- Group code by feature/screen; keep shared utilities minimal.
- Create simple, obvious entry points.
- Before scaffolding multiple files, identify shared structure first. Use framework-native composition patterns (layouts, base templates, providers, shared components) for elements that appear across pages. Duplication that requires the same fix in multiple places is a code smell, not a pattern to preserve.

2. Architecture
- Prefer flat, explicit code over abstractions or deep hierarchies.
- Avoid clever patterns, metaprogramming, and unnecessary indirection.
- Minimize coupling so files can be safely regenerated.

3. Functions and Modules
- Keep control flow linear and simple.
- Use small-to-medium functions; avoid deeply nested logic.
- Pass state explicitly; avoid globals.

4. Naming and Comments
- Use descriptive-but-simple names.
- Comment only to note invariants, assumptions, or external requirements.

5. Logging and Errors
- Emit detailed, structured logs at key boundaries.
- Make errors explicit and informative.

6. Regenerability
- Write code so any file/module can be rewritten from scratch without breaking the system.
- Prefer clear, declarative configuration (JSON/YAML/etc.).

7. Platform Use
- Use platform conventions directly and simply (e.g., WinUI/WPF) without over-abstracting.

8. Modifications
- When extending/refactoring, follow existing patterns.
- Prefer full-file rewrites over micro-edits unless told otherwise.

9. Quality
- Favor deterministic, testable behavior.
- Keep tests simple and focused on verifying observable behavior.

Your goal: produce code that is predictable, debuggable, and easy for future LLMs to rewrite or extend.
&lt;/code&gt;
    &lt;p&gt;All of that said, I don’t have any proof that this prompt makes a difference. I find that Opus 4.5 writes pretty solid code no matter what you prompt it with. However, because models like to write code WAY more than they like to delete it, I will at points run a prompt that looks something like this…&lt;/p&gt;
    &lt;code&gt;Check your LLM, AI coding principles and then do a comprehensive search of this application and suggest what we can do to refactor this to better align to those principles. Also point out any code that can be deleted, any files that can be deleted, things that should read should be renamed, things that should be restructured. Then do a write up of what that looks like. Kind of keep it high level so that it's easy for me to read and not too complex. Add sections for high, medium and lower priority And if something doesn't need to be changed, then don't change it. You don't need to change things just for the sake of changing them. You only need to change them if it helps better align to your LLM AI coding principles. Save to a markdown file.
&lt;/code&gt;
    &lt;p&gt;And you get a document that has high, medium and low priority items. The high ones you can deal with and the AI will stop finding them. You can refactor your project a million times and it will keep finding medium/low priority refactors that you can do. An AI is never ever going to pass on the opportunity to generate some text.&lt;/p&gt;
    &lt;p&gt;I use a similar prompt to find security issues. These you have to be very careful about. Where are the API keys? Is login handled correctly? Are you storing sensitive values in the database? This is probably the most manual part of the project and frankly, something that makes me the most nervous about all of these apps at the moment. I’m not 100% confident that they are bullet proof. Maybe like 80%. And that, as they say, is too damn low.&lt;/p&gt;
    &lt;head rend="h3"&gt;Times they are A-changin&lt;/head&gt;
    &lt;p&gt;I don’t know if I feel exhilarated by what I can now build in a matter of hours, or depressed because the thing I’ve spent my life learning to do is now trivial for a computer. Both are true.&lt;/p&gt;
    &lt;p&gt;I understand if this post made you angry. I get it - I didn’t like it either when people said “AI is going to replace developers.” But I can’t dismiss it anymore. I can wish it weren’t true, but wishing doesn’t change reality.&lt;/p&gt;
    &lt;p&gt;But for everything else? Build. Stop waiting to have all the answers. Stop trying to figure out your place in an AI-first world. The answer is the same as it always was: make things. And now you can make them faster than you ever thought possible.&lt;/p&gt;
    &lt;p&gt;Just make sure you know where your API keys are.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5&lt;/p&gt;
    &lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://burkeholland.github.io/posts/opus-4-5-change-everything/"/><published>2026-01-06T17:45:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46515777</id><title>Launch HN: Tamarind Bio (YC W24) – AI Inference Provider for Drug Discovery</title><updated>2026-01-07T15:14:06.831557+00:00</updated><content>&lt;doc fingerprint="6f51ad5b7d3645cb"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN, we're Deniz and Sherry from Tamarind Bio (&lt;/p&gt;https://www.tamarind.bio&lt;p&gt;). Tamarind is an inference provider for AI drug discovery, serving models like AlphaFold. Biopharma companies use our library of leading open-source models to design new medicines computationally.&lt;/p&gt;&lt;p&gt;Here’s a demo: https://youtu.be/luoMApPeglo&lt;/p&gt;&lt;p&gt;Two years ago, I was hired at a Stanford lab to run models for my labmates. Some post-doc would ask me to run a set of 1-5 models in sequence with tens of thousands inputs and I would email them back the result after setting up the workflow in the university cluster.&lt;/p&gt;&lt;p&gt;At some point, it became unreasonable that all of an organization's computational biology work would go through an undergrad, so we built Tamarind as a single place for all molecular AI tools, usable at massive scale with no technical background needed. Today, we are used by much of the top 20 pharma, dozens of biotechs and tens of thousands of scientists.&lt;/p&gt;&lt;p&gt;When we started getting adoption in the big pharma companies, we found that this problem also persisted. I know directors of data science, where half their job could be described as running scripts for other people.&lt;/p&gt;&lt;p&gt;Lots of companies have also deprecated their internally built solution to switch over, dealing with GPU infra and onboarding docker containers not being a very exciting problem when the company you work for is trying to cure cancer.&lt;/p&gt;&lt;p&gt;Unlike non-specialized inference providers, we build both a programmatic interface for developers along with a scientist-friendly web app, since most of our users are non-technical. Some of them used to extract proteins from animal blood before replacing that process with using AI to generate proteins on Tamarind.&lt;/p&gt;&lt;p&gt;Besides grinding out images for each of the models we serve, we’ve designed a standardized schema to be able to share each model’s data format. We’ve built a custom scheduler and queue optimized for horizontal scaling (each inference call takes minutes to hours, and runs on one GPU at a time), while splitting jobs across CPUs and GPUs for optimal timing.&lt;/p&gt;&lt;p&gt;As we've grown to handle a substantial portion of the biopharma R&amp;amp;D AI demand on behalf of our customers, we've expanded beyond just offering a library of open source protocols.&lt;/p&gt;&lt;p&gt;A common use case we saw from early on was the need to connect multiple models together into pipelines, and having reproducible, consistent protocols to replace physical experiments. Once we became the place to build internal tools for computational science, our users started asking if they could onboard their own models to the platform.&lt;/p&gt;&lt;p&gt;From there, we now support fine-tuning, building UIs for arbitrary docker containers, connecting to wet lab data sources and more!&lt;/p&gt;&lt;p&gt;Reach out to me at deniz[at]tamarind.bio if you’re interested in our work, we are hiring! Check out our product at https://app.tamarind.bio and let us know if you have any feedback to support how the biotech industry uses AI today.&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46515777"/><published>2026-01-06T17:49:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46517319</id><title>High-Performance DBMSs with io_uring: When and How to use it</title><updated>2026-01-07T15:14:06.687148+00:00</updated><content>&lt;doc fingerprint="b89f341a58d3848a"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Databases&lt;/head&gt;&lt;p&gt; [Submitted on 4 Dec 2025 (v1), last revised 12 Dec 2025 (this version, v2)]&lt;/p&gt;&lt;head rend="h1"&gt;Title:High-Performance DBMSs with io_uring: When and How to use it&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL's recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.&lt;/quote&gt;&lt;head rend="h2"&gt;Submission history&lt;/head&gt;From: Matthias Jasny [view email]&lt;p&gt;[v1] Thu, 4 Dec 2025 14:43:03 UTC (504 KB)&lt;/p&gt;&lt;p&gt;[v2] Fri, 12 Dec 2025 09:44:22 UTC (505 KB)&lt;/p&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.04859"/><published>2026-01-06T19:29:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46517458</id><title>Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone</title><updated>2026-01-07T15:14:05.870194+00:00</updated><content>&lt;doc fingerprint="911410dd3b96cae7"&gt;
  &lt;main&gt;
    &lt;p&gt;A DIY approach to coding on-the-go!&lt;/p&gt;
    &lt;p&gt;As an aspiring builder, I sought out a way to keep coding while not at home. Thanks to some Claude-assisted research and troubleshooting, I can now code via the terminal on my phone anywhere at anytime via "Doom Coding" (think Doom Scrolling but more productive).&lt;/p&gt;
    &lt;p&gt;After this 5-minute setup guide, you'll be able to "doom code" anywhere you have Internet connection.&lt;/p&gt;
    &lt;p&gt;I've been amazed by how much I can get done while being so far away from home. In Taiwan, I could access my computer in Philadelphia and coded a prototype in my downtime.&lt;/p&gt;
    &lt;p&gt;Shameless plug: check out www.friendlyr.ai to help shape the future of connection!&lt;/p&gt;
    &lt;p&gt;Make sure to "Watch" this repo for future updates to this doom coding guide. As I tryout the latest mobile coding tools (e.g. Claude Code on the Web), I'll update this repository with comparisons.&lt;/p&gt;
    &lt;p&gt;Happy doom coding my friends!&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;A Computer running 24/7 with Internet Connection&lt;/item&gt;
      &lt;item&gt;A Smartphone&lt;/item&gt;
      &lt;item&gt;A Claude Pro subscription&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Tailscale, Termius, Claude Code, and a computer running 24/7 to continue building anywhere you have Internet connection.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable sleep in power settings&lt;/item&gt;
      &lt;item&gt;Enable SSH/Remote Login&lt;/item&gt;
      &lt;item&gt;Install Tailscale and sign in&lt;lb/&gt;https://tailscale.com/download&lt;/item&gt;
      &lt;item&gt;Install Claude Code on your computer&lt;lb/&gt;https://docs.anthropic.com/en/docs/claude-code/overview&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Install Tailscale → Sign in with the same account&lt;/p&gt;&lt;lb/&gt;https://apps.apple.com/us/app/tailscale/id1470499037&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Install Termius (A Mobile Terminal Tool)&lt;/p&gt;&lt;lb/&gt;https://apps.apple.com/us/app/termius-modern-ssh-client/id549039908&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Note the MagicDNS address of your computer (e.g. my-computer.tailnet-name.ts.net)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create a new host in Termius:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Label: What you want your connection to be called&lt;/item&gt;
          &lt;item&gt;Hostname: The MagicDNS address (my-computer.tailnet-name.ts.net)&lt;/item&gt;
          &lt;item&gt;Port: 22&lt;/item&gt;
          &lt;item&gt;Username/Password: Your login for your computer &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you're not able to establish a connection from your phone via Termius to your computer:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check your phone settings to make sure you are connected to the Tailscale VPN. &lt;/item&gt;
      &lt;item&gt;Check the Tailscale app to make sure the Tailscale VPN is on. If your phone and doom coding computer do not have a green circle next to their labels, there is an issue with your Tailscale/Internet connection.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When disconnecting/reconnecting power, make sure you unlock the computer. I've ran into this issue one too many times.&lt;/p&gt;
    &lt;p&gt;End sessions by asking Claude to update CLAUDE.md with where you left off.&lt;/p&gt;
    &lt;p&gt;Go to your desired directory and start an HTTP server&lt;code&gt;python -m http.server 3005&lt;/code&gt;
then visit http://your-machine.tailnet-name.ts.net:3005/your-html-file.html in a browser on your phone.&lt;/p&gt;
    &lt;p&gt;Wherever you would use localhost:PORT to view an app on your computer, replace localhost with the computer's MagicDNS from the Tailscale app (e.g. your-computer.tailnet-name.ts.net)&lt;/p&gt;
    &lt;p&gt;Use the PostgreSQL app to view databases for your projects https://apps.apple.com/us/app/postgresql-client/id1233662353&lt;/p&gt;
    &lt;p&gt;On your computer, bookmark the sites you refer to during development (e.g. Google OAuth, GitHub) to make it easier to reference from your phone. I use the Chrome app to seamlessly access the sites I need.&lt;/p&gt;
    &lt;p&gt;Please contibute your best practices! I am looking forward to seeing all the places you will code!&lt;/p&gt;
    &lt;p&gt;I'm new to the world of hacking - so please share your ideas, feedback, and questions - you will help me learn! Please connect at rmb1@wharton.upenn.edu or https://www.linkedin.com/in/ryan-bergamini-223606107/&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rberg27/doom-coding"/><published>2026-01-06T19:38:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518129</id><title>Calling All Hackers: How money works (2024)</title><updated>2026-01-07T15:14:05.515382+00:00</updated><content>&lt;doc fingerprint="332310190d2133ec"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Title : Calling All Hackers&lt;/p&gt;
      &lt;p&gt; Author : cts&lt;/p&gt;
      &lt;quote&gt; ==Phrack Inc.== Volume 0x10, Issue 0x47, Phile #0x11 of 0x11 |=-----------------------------------------------------------------------=| |=-----------------------=[ Calling All Hackers ]=-----------------------=| |=-----------------------------------------------------------------------=| |=--------------------------=[ cts (@gf_256) ]=--------------------------=| |=-----------------------------------------------------------------------=| --[ Table of Contents 0 - Preamble 1 - About the Author 2 - The Birth of a Shitcoin 3 - How Money Works 3.1 - Fixed Income 3.2 - Equities 3.3 - Shareholder Value 4 - Startup Blues 5 - Takeaways 6 - Thanks 7 - References 8 - Appendix --[ 0 - Preamble Hi. I'm cts, also known as gf_256, ephemeral, or a number of other handles. I am a hacker and now a small business owner and CEO. In this article, I would like to share my experience walking these two different paths. A hacker is someone who understands how the world works. It's about knowing what happens when you type "google.com" and press Enter. It's about knowing how your computer turns on, about memory training, A20, all of that. It's about modern processors, their caches, and their side channels. It's about DSi bootloaders and how the right electromagnetic faults can be used to jailbreak them. And it's about how Spotify and Widevine and AES and SGX work so you can free your music from the shackles of DRM. But being a hacker is so much more than these things. It's about knowing where to find things. Like libgen and Sci-Hub and nyaa. Or where to get into the latest IDA Pro group buy. Or which trackers have what and how to get into them. It's about knowing how to bypass email verification. How to bypass SMS verification. How to bypass that stupid fucking verification where you hold your driver's license up to a webcam (thank you, OBS virtual camera!) Having an actual threat model not just paranoia. Knowing that you're not worth burning a 0day on, but reading indictments to learn from others' mistakes. It's about knowing where to buy estradiol valerate on the internet and how to compound injections. Or the "bodybuilder method" to order your own blood tests when your state requires a script to do so. It's about knowing which shipments give the US CBP a bad vibe and which don't. It's about knowing what happens when you open Robinhood and giga long NVDA FDs. I mean the actual market microstructure, not "Ken Griffin PFOF bad". Then using that microstructure to find an infinite money glitch (high Sharpe!). It's about knowing how to get extra passports and reading the tax code. It's about knowing how to negotiate your salary (or equity). It's about knowing why things at the supermarket cost what they do. Or how that awful shitcoin keeps pumping. And why that dogshit startup got assigned that insane valuation. And understanding who really pays for it in the end (hint: it's you). My point is, it is not just about computers. It's about understanding how the world works. The world is made up of people. As much as machines keep society running, those machines are programmed by people--people with managers, spouses, and children; with wants, needs, and dreams. And it is about using that knowledge to bring about the change you want to see. That is what being a hacker is all about. --[ 1 - About the Author I have been a hacker for 13 years. Prior to founding Zellic, I helped start a CTF team called perfect blue (lately Blue Water). We later became the number one ranked CTF team in the world. We've played in DEF CON CTF. We've won GoogleCTF, PlaidCTF, and HITCON. It's like that scene from Mr. Robot but not cringe. In 2021, we decided to take that hacker friend circle and form a security firm. It turned out that crypto paid well, so we worked with a lot of crypto clients. In the process, we encountered insane, hilarious, and depressingly sobering bullshit. In this article, I will tell some stories about what that bullshit taught me, so you can benefit from the same lessons as I have. Markets are computers; they compute prices, valuations, and the allocation of resources in our society. Hackers are good at computers. Let's learn more about it. --[ 2 - The Birth of a Shitcoin I can't think of a better example than shitcoins. Let's look at the crypto markets in action. First, let's talk about tokens. What is their purpose? The purpose of a token is to go up. There is no other purpose. Token go up. This is important, remember this point. Now the question is, how do we make the token go up? In crypto, there are two main kinds of token deals. Let's call them the Asian Arrangement and the Western Way. The Asian Arrangement is a fairly straightforward pump and dump. It's a rectangle between the VC, the Market Maker, the Crypto Exchange, and the Token Project Founder. 1. The exchange's job is to list the token, bringing in investors. They get paid in a mix of tokens and cold, hard cash. Their superpower is owning the customer relationships with the retail users, and the naming rights to sports arenas. 2. The market maker provides liquidity so the market looks really healthy and well-traded so it is easy to buy the token. In good deals, they are paid in in-the-money call options on the tokens, so they are incentivized to help the token trade well. Their superpower is having a lot of liquidity to deploy, and people on PagerDuty. 3. The founder's job is to pump the token and shill it on Twitter. They are the hype man, and it's their job to drum up the narrative and pump everyone's bags. Their unique power is they can print more tokens out of thin air, and this is in large part how they get paid in this arrangement. 4. Lastly, the VC gets paid to organize the deal. They give the founders some money, who in return give a pinky promise that they will give the VC a lot of tokens once the tokens actually exist. This is known as a Simple Agreement for Future Tokens, or SAFT. Their superpower is dressing up the founders and project so it seems like the Next Big Thing instead of a Ponzi scheme. Everyone gets paid a ton of token exposure (directly or indirectly), and when it lists, it pumps. Then the insiders dump and leave with a fat stack. Except retail, they end up with the bag. Sometimes the listing doesn't go well for the organizers, in which case, better luck next time. But retail always loses. wtf??? LFG!!! to the moon ,o \oXo/\o/ /v | | | /\ / X\ / \ crypto investors ^ | | | | v +----------+ provides liquidity +--------+ | Crypto | &amp;lt;--------------------------------------- | Market | | Exchange | ----------------------------------------&amp;gt; | Maker | +----------+ maker fees +--------+ ^ | ^ fees, | | listing options | tokens | | / fees | | | +-------------------------------------------------+ | v | +---------+ tokens / SAFT / token warrants +---------+ | Token | ---------------------------------------&amp;gt; | Venture | | Project | &amp;lt;--------------------------------------- | Capital | +---------+ cash , intros to CEX / MM, shilling +---------+ This machine worked exceptionally well in 2017, especially before China banned crypto. All those ICO shitcoins? Asian Arrangement. And it still works well to this day, except people are more wary of lockups and vesting schedules and so on. Now let's discuss the Western Way. The Asian Arrangement? That old pump and dump? No sir, we are civilized people. Instead, our VCs *add value* to their investments by telling the world "how disruptive the tech is" and how the "team are incredible outliers". And they will not blatantly PnD the token, but instead they will fund "projects in the ecosystem" so it appears there is real activity happening on the platform. This is to hype up metrics (like TPS or TVL) to inflate the next round valuation. Anyways, then they dump. Or maybe the VC is also a market maker so they market make their portfolio company tokens. Overall it's the same shit (Ponzi) but dressed up in a nicer outfit. Asian Arrangement or Western Way--either way, if you're the token founder, your main priority is to just GO TO MARKET NOW and LAUNCH THE TOKEN. This is so you can collect your sweet bag and dump some secondary before someone else steals the narrative or the hype cycle moves on. This is one of the reasons there are so many hacks in crypto. The code is all shitty because it's rushed out as fast as possible by 20-something- year-old software engineers formerly writing Typescript and Golang at Google. Pair that with some psycho CEO product manager. Remember, it is not about WRITING SECURE CODE, it is about SHIPPING THE FUCKING PRODUCT. Good luck rewriting it in Rust! All of this worked well until Luna, then 3AC, Genesis, and FTX imploded in 2022. It still works, but you have to be less blatant now. Shitcoins do serve an essential need. They are an answer to financial nihilism. Many people are working dead-end wage slave jobs that are not enough to "make it". They feel trapped and forced to work at jobs they fucking hate and waste their life doing pointless shit to generate shareholder value. This kind of life feels unacceptable, yet there are few avenues out. So what is the only "attainable" solution left? Gamble it on shitcoins, and if you lose...maybe next paycheck will be better. But enough about crypto, let's talk about securities. --[ 3 - How Money Works ----[ 3.1 - Fixed Income First, let's start with fixed income. I'm talking boring, old-fashioned bonds, like Treasury bonds. A lot of people are introduced nowadays to finance through equities (stocks) and tokens. In my opinion, this is only half of the story. Fixed income is the bedrock of finance. It has fundamental value. It provides a prototypical asset that all assets can be benchmarked based on. Fixed income assets, like bonds, boil down to borrowing and lending. A bond is basically an IOU for someone to pay you in the future. It is more useful to have a dollar today than in a year, so lenders charge a fee for access to money today. This fee is known as interest, and how it is baked into the equation varies from asset-to-asset. Some bonds come with interest payments, whereas other bonds are zero-coupon. The most important thing is to remember that bonds are essentially an IOU to pay $X in the future. Here is an example. Let's say you would like to borrow $100 to finance an upcoming project. The interest rate will be 5% per year. To borrow money, you would issue (mint) a bond (an IOU) for $X+5 dollars to be repaid 1 year in the future. In exchange for this fresh IOU, the lender will give you $X dollars now. On the lender's balance sheet, they will be less $X dollars worth of cash, but will also have gained ($X+5) dollars worth of an asset (your IOU), creating $5 of equity. In contrast, you would have $X more cash in assets, but also an ($X+5) liability, creating -$5 of equity. This example also works for depositing money at a bank. Here, you are the lender, and the bank is the borrower. Your deposits would be liabilities on their balance sheet, as they are liable to pay you back the deposit if you choose to withdraw it. Lender's Balance Sheet Borrower's Balance Sheet =========================== =========================== Assets: Assets: IOU-----------------X+5 Cash------------------X Liabilities: Liabilities: Cash----------------(X) IOU-----------------X+5 Equity: Equity: Equity----------------5 Equity--------------(5) Fixed income assets are extremely simple. There are various risks (credit risk, interest rate risk, etc.), but excluding these factors, you essentially get what you pay for. Unlike a token or stock, the bond is not going to suddenly evaporate or crash. (In theory.) Because of this, they can be modeled in a straightforward way; a way so straightforward even a high school student can understand it. Let's say I have $X today. Suppose the prevailing (risk-free) interest rate is 5%. What is the value of this $X in a year? Obviously, it would be no less than $X*1.05, as I can just lend it out for 5% interest and get $X*1.05 back in a year. If you gave me the opportunity to invest in any asset yielding less than 5%, this would be a bad deal for me, since I could just lend it out myself to get 5% yield. Now, let's analyze the same scenario, but in reverse. Let's take that IOU from earlier. What is the value *today* of a (risk-free) $X IOU, due in 1 year? It would be worth no more than $X/1.05. This is because with $X/1.05 dollars today, I could lend it out and collect 5% interest to end up with $X again in the future. If I pay more than $X/1.05, I am getting a bad deal, since I am locking up my money with you when it would be more capital efficient to just lend it out myself. You can probably see where I am going with this. The present value of an $X IOU at some time *t* in the future is $X/(1+r)^t, where *r* is the discount rate. The discount rate describes the "decay" of the value over time, due to interest but also factors like potential failure of the asset (for example, if the asset is a company, business failure of the company). Now, if we have some asset which pays a series of future cash flows *f(t)*, we can model this asset as a bundle of IOUs with values f(t) due in time 1, 2, 3, and so on. Then the present value of this asset is the geometric series sum of the discounted future cash flows. This is called discounted cash flows (DCF). Congrats, now you can do better modeling than what goes into many early-stage venture deals. +------+-----+-----+---------+---------+---------+-------+---------+ | Year | 0 | 1 | 2 | 3 | 4 | ... | t | +------+-----+-----+---------+---------+---------+-------+---------+ | Cash | CF1 | CF2 | CF3 | CF4 | CF5 | ... | CF_t | | Flow | | | | | | | | +------+-----+-----+---------+---------+---------+-------+---------+ | Disc.| CF1 |_CF2_| __CF3__ | __CF4__ | __CF5__ | ... | _CF_t__ | | Val | | 1+r | (1+r)^2 | (1+r)^3 | (1+r)^4 | | (1+r)^t | +------+-----------+---------+---------+---------+-------+---------+ IOU 1 IOU 2 IOU 3 IOU 4 IOU 5 ... IOU n inf _ f(t) 1 DCF = \ ------- = (assume constant annual cash flow x) = --------- x /_ (1+r)^t 1-1/(1+r) t=0 = (1/r + 1) x Cash flow multiple = (value) / (annual cash flow) ~= 1/r (The astute reader might also find that they can go backwards from valuations to estimate first, second, ... Nth derivatives of the cash flow or the year-to-year survival chances of a company. And these can be compared with...going outside and touching grass to see if the valuation actually makes sense.) At this point, you're probably wondering why I'm boring you with all of this dry quant finance 101 shit. Well, it's a useful thing to know about how the world works. First, interest rates affect you directly and personally. You may have heard of the term "zero interest rate environment". In a low interest rate environment, cash flow becomes irrelevant. Why? Consider the DCF geometric series sum if the interest rate r = 0. The present value approaches infinity. If the benchmark hurdle rate we're trying to beat is 0%, literally ANYTHING is a better investment than holding onto cash. Now do you see why VCs were slamming hundreds of millions into blatantly bad deals and shit companies during Covid? Cash flow and profitability didn't matter, because you could simply borrow more money from the money printer. Here's a more concrete example. Do you remember a few years ago when Uber rides were so cheap, that they were clearly losing money on each ride? This is known as Customer Acquisition Cost, or CAC. CAC is basically the company paying you to use their app, go to their store, subscribe to the thing, ... whatever. The strategy is well-known: burn money to acquire users until everyone else dies and you become a monopoly. Then raise the prices. But here is the key point: this only works in a low-interest rate environment. In such an environment, discounting is low, and thus, future growth potential is valued over profitability and fundamentals at present. It doesn't need to make sense *today* as long as it works 10 years from now. For now, we can keep borrowing more money to sustain the burn. Of course, when rates go back up, the free money machine turns off and the effects ripple outward. You are the humble CAC farmer, farming CAC from various unprofitable consumer apps like ride share, food delivery, whatever. These apps raise their money from their investors, VC and growth equity funds. These funds in turn raise their money from *their* investors, their limited partners. These LPs might be institutional capital like pension funds, sovereign wealth funds, or family offices. At the end of the day, all of that wealth is generated somewhere throughout the economy by ordinary people. So when some VC-backed founders throw an extravagant party on a boat with fundraised dollars, in some sense, you are the one paying for it. And when the money machine turns off, anyone who had gotten complacent under ZIRP is now left scrambling. Companies will overhire during ZIRP only to do layoffs when rates go up. +=========================+ | THE LIQUIDITY CYCLE | +=========================+ VENTURE CAPITAL _______________ ,.-^=^=^=^=^=^=^=^=^=^;, ,;===============&amp;gt;&amp;gt; E^ a16z LSVP Tiger '^3. .;^ E^ FF Social Cap. '^3 // condensation .E Bain SoftBank Accel 3^ /|^ ^E KP Benchmark :^ || ^;: YC Greylock GC ;3' ,.^-^-^-^-^-^-^-^-^-^-^;, ^.=.=_=_=_=_=_=_=_=_=_=_=^ E^ endowments family '^:. \\\\\\\\\\\\\\\\\\\\ E^ offices '^3 \\\\\\\\\\\\\\\\\\\\ E' pension ^3. SOURCE \\\ precipitation \\ ^; funds sovereign 3.' CAPITAL \\\\\\\\\\\\\\\\\\\\ E;: wealth funds ,3^ (LPs) \\\\\\\\\\\\\\\\\\\\ ^;._.._._._._._._._._._._,^ \\\\\\\\\\\\\\\\\\\\ /\ ^ ^ ^ ^ ^ ^ ^ ^ gamefi /\ /\ uber eats | | | | | | | | shitcoins/::\/::\ /::::\ /\ | evaporation | / doordash/^^^^^^\ /^^\ | | | | | | | | ____________ / \ / hello \ (poggers desu) /_____ lime ____ fresh ___\ \o/ \oXo/\oXoXo/ o '==========' UNPROFITABLE CONSUMER APPS | | | | | | /|\ Oo._ /\_/\ ,/// __/_\_/_X_\/_X_X_\_/_\__ /_________(@'w'@)_____________.,://' SOCIETY \'''''''' -...-''''''''''''''''' surface THE HUMBLE runoff CAC FARMER Second, credit is not inherently a bad thing if used responsibly. Take for example those Buy Now, Pay Later loans. Now that you are equipped with the concept of capital efficiency, wouldn't it technically better than paying cash to take an interest-free BNPL loan and temporarily stick the freed cash into an investment? (Barring other side effects, etc.) Third, the concept of net present value--i.e., credit--is the killer app of finance. It allows you to transport value from the future into today. Of course, that debt must be repaid in the future, unless you can figure out a way to kick the can down the road forever. For now, let's get back to stocks. ----[ 3.2 - Equities Now we have seen both sides of the coin. Asset value is twofold: speculative and fundamental. First, we saw speculative value as illustrated by crypto meme coins. Then, on the other hand, we examined fundamental value as illustrated by, e.g. a US Treasury. These two lie on two extremes of a spectrum. Some sectors and stocks are more speculative than others; Nvidia is practically a meme coin at this point, whereas something like Coca-Cola is like fixed income for boomers (NFA BTW). Most assets have a blend of both. Thinking about stocks, they (usually) have some fundamental value. Equities represent ownership of some asset, like a business. The business in theory generates dividends for shareholders, and this cash flow (or the net present value of future ones) represents the fundamental value of the business. As we've seen, assets with better cash flows are more valuable. In practice, buybacks can be used to create what is effectively a shareholder dividend in a more tax-advantaged way. Whereas with dividends, they are taxed as income, and this is realized immediately. With buybacks, they are taxed as capital gains, but crucially the gains are not realized until the asset is sold. This could be indefinitely far in the future, so it's more capital efficient. It has the added benefit that it helps pump the token, and imo this is kind of cute because it marries both the fundamental and speculative aspects. Meanwhile, like tokens, stocks are also supposed to go up. Here's an example: imagine a generic meme coin. Apart from Go Up, what does it do? Nothing. Even if it's a Governance Token, who cares when the founders and VCs hold all the voting power? Anyways, I'm describing Airbnb Class A Common Stock. Here's an excerpt from their S-1 [1] [2]: &amp;gt; We have four series of common stock, Class A, Class B, Class C, and &amp;gt; Class H common stock (collectively, our "common stock"). The rights of &amp;gt; holders of Class A, Class B, Class C, and Class H common stock are &amp;gt; identical, except voting and conversion rights ... Each share of Class A &amp;gt; common stock is entitled to one vote, each share of Class B common stock &amp;gt; is entitled to 20 votes and is convertible at any time into one share of &amp;gt; Class A common stock ... Holders of our outstanding shares of Class B &amp;gt; common stock will beneficially own 81.7% of our outstanding capital &amp;gt; stock and represent 99.0% of the voting power of our outstanding capital &amp;gt; stock immediately following this offering, ... Name of | Class B | % | % of Vot- Beneficial Owner | Shares | | ing Power -------------------------------------+------------+-------+----------- Brian Chesky | 76,407,686 | 29.1% | 27.1% Nathan Blecharczyk | 64,646,713 | 25.3% | 23.5% Joseph Gebbia | 58,023,452 | 22.9% | 21.4% Entities Affil. w/ Sequoia Capital | 51,505,045 | 20.3% | 18.9% Why do people buy tech stocks with inflated valuations? Some may because they believe that they will go up, that they will be more dominant, important, and valuable in the future. Like tokens, a large part of stocks' value is speculative. They are expressing their opinion on the future fundamentals. Others may simply because they believe others will believe that it is more valuable. Not fundamentals, this is an opinion about *pumpamentals*. Importantly, unlike fundamental value, speculative value can be created out of thin air. It is minted by *fiat*. Fundamental value is difficult to create, whereas speculative value can be created through hype and psychology alone. ----[ 3.3 - Shareholder Value For stocks, there are usually laws in place to protect investors, pushing the balance between "speculation" and "fundamentals" towards the latter. As a result, firms are generally legally obligated to act in their shareholders' best interests. This is good because normal people will be able to participate in the wealth generated by companies. And obviously, companies should not defraud their investors. However, the biggest *stake* holders in a business, are usually (in order): 1. The employees. No matter what, no one else is spending 8 hours a day, or ~33% of their total waking lifespan at this place. Whatever it is, I guarantee you the employees feel it the most. 2. The customers. The customers are the reason the business is able to exist in the first place. Non-profits are not exempt: their customers are their donors. 3. The local community / local environment / ecosystem. The business doesn't exist in a vacuum. The business has externalities, and those externalities affect most the immediate surrounding environment. 4. And in last place, the shareholders. They do not really do anything except contribute capital and hold the stock. Of course capital is important but they are not spending 8 hours a day here, they are not the reason the business exists, and in fact they might even live in a totally different country. For large, publicly-listed companies, the shareholders have one more unique difference from the other three stakeholders: liquidity. This difference is critical. Liquidity describes how easy it is to buy and sell an asset. A dollar bill is liquid. Bitcoin is liquid. A house is relatively illiquid. Stock in large, publicly-listed companies is also liquid. A shareholder can buy a stock one day and sell it the next. As a result, the relationship is non-commital and opens the opportunity for short-term thinking. There are many things a company could do which would benefit shareholders short term, while harming the other three stakeholders long term. While a shareholder can simply dump their position and leave, the mess created is left for the employees, customers, and community to clean up. (The SPAC boom was a pretty good example of this. Not all SPACs are bad, but a lot of pretty shit businesses publicly listed through SPACs then crashed. This is sad to me because some of that is early investors and founders dumping on retail like a crypto shitcoin, but dressed up because it's NYSE or NASDAQ. Get liquidity then bail.) Now, it is a misconception that stock companies must solely paperclip- maximize short-term shareholder value. However, this is how it often plays out due to fucked up shit in the public markets, like annoying activist hedge funds or executive compensation tied to stock price. And it is true that employees can be shareholders. And that is usually a good thing! But few public companies are truly employee-owned. Thinking about it from this perspective, the concept of maximizing shareholder value seems somewhat backwards. But *why* would one make this system where the priorities are seemingly inverted? One benefit is that it would make your currency extremely valuable. Suppose you want to do some shit on Ethereum (speculating on some animal token?), you will need to have native ETH to do that transaction. Similarly, if you want to invest in US securities you at some point need US Dollars. If you want to get a piece of that sweet $NVDA action, you need dollars. People want to buy American stocks. American companies perform well: they're innovative; they're not too heavily regulated; it's a business friendly environment. (Shareholder value comes first!) The numbers go up. Remember the token founder from earlier in the Asian Arrangement? Suppose you are a *country* in the situation above, with a valuable currency. Not only is your currency in demand and valuable, you are the issuing/minting authority for that token. Similar to the token founder, you can print valuable money and pay for things with it. And speaking of being a founder, let's talk about that! --[ 4 - Startup Blues Based on what we've set up so far, I will discuss some of the problems I see with many startups today and with startup culture. Much of the problems stem from misalignment between shareholders and the other stakeholders (employees, etc). A lot of this comes from the fundamentals of venture capital. VC is itself an asset class, like fixed income and equities. VCs pitch this to their limited partners, at some level, based on the premise that their VC fund will generate yield for them. The strategy is to identify stuff that will become huge and buy it while it's still small and really cheap. Like trading shitcoins, it's about finding what's going to moon and getting in early. In a typical VC fund, a small handful of the investments will comprise the entire returns of the fund, with all of the other investments being 0's. The distribution is very power law. This means we are not looking for 1x, 2x, or 3x outcomes; these may even be seen as failure modes. We are only interested in 20x, 50x, 100x, etc. outcomes. This is because anything less will be insufficient to make up for all the bad investments that get written down to zero. For the same reason, it only makes sense for VCs to invest in certain types of companies. Have you ever heard this one? "We invest in SOFTWARE companies!...How is this SCALABLE? What do the VENTURE SCALE OUTCOMES look like here?" This is because these kinds of companies are the ones with the potential to 100x. They want you to deliver a 100x. Or how about this one? "We invest in CATEGORY-DEFINING companies". At least in security, "category-defining" means a shiny new checkbox in the compliance / cyber insurance questionnaire. In other words, a new kind of product that people MUST purchase. The market is incentivized to deliver a product that meets the minimum bar to meet that checkbox, while being useless. I invite you to think of your favorite middleware or EDR vendors here. For passionate security founders considering raising venture, remember that this is what your "success" is being benchmarked against. _.,------------------------------_ .%' '&amp;amp;. .;' We partner with founders ^; ! building category-defining ;! ; companies at the earliest stages _; ^; _.^ ''-.______________ __________.-' / / / /^ / /^ /;^ /' _________ _________ _-' '. _-' '. ,^ '^_ ,^ '^_ /' '"' /' '"' ^' ^\^ ^' ^\^ : ^| : ^| : . . |) : . . |) : \ |) : \ |) : __\ ,; : __\ ,; " ! ; " ! ; " ^\ _____ /' " ^\ _____ /' '| | ^\ _/^ '| | ^\ _/^ | ^'=====' | ^'=====' | . | | | . | | _' |^__ _' |^__ ---------_-' U '--_ -------------_-' U '--_ ----- ._ _.-' '-._ _.-' '- ':.' \ ; / ': .' \ ; / [4] It's due to the thirst for 100x that there are painful dynamics. A fledgling startup may have founders they really like, but the current business may be unscalable. Bad VCs will push founders towards strategies, bets, models that have a 1% chance of working, but pay out 200x if they do. In the process they destroy a good business--one which has earned the trust of dutiful employees and loyal customers--all for a lottery ticket to build a unicorn. They will throw 100 darts at the dartboard and maybe 5 will land, but what is it like to be the dart? You may have good expected value, but all of that EV is from spikes super far away from the origin. Is it pleasant betting everything on this distribution? VC's want founders to be cult leaders. Have you ever heard this line? "We invest in great storytellers." Like what we saw with stocks and tokens, much of the easily-unlockable potential upside in assets is speculative. In essence, value can be created through narrative. Narrative *IS* value. Bad VC's will push founders to raise more capital at ever higher valuations (higher val = markup = fees), using narrative as fuel for the fire. Storytelling means "pump the token", and the job of the CEO is to (1) be the hype man and to raise (2) cash and (3) eyeballs. For this reason, Sam Altman and Elon are fine CEOs, regardless of other factors, because they are great at all three. Much to the detriment of founders' and their employees' psyche, investors expect founders to be this legendary hype man. This requires a religiosity of belief that is borderline delusional. Have you ever tried to convince one of those Silicon Valley YC-type founder/CEOs that they are wrong? They will never listen to you because they have been socialized to be this way. It is what is expected of them, and it is easy to fall into this trap without even becoming aware of it. But if you think about it, does it make sense that to be a business owner, you need to be a religious leader? Of course not. All of these reasons are why so many startup founders are young. They have little to lose, so gambling it all is OK. Being a cult leader may be traumatizing, but they have time (and the neuroplasticity) to heal. And lastly, they do not have the life experience to have a mature personal identity beyond "I am a startup founder". All of this makes it easy to accept the external pressures to build a company this or that way. And perhaps not the way they would have wanted to, relying instead on their personal values. The true irony is that the latter is what creates true, enduring company culture and not the made-up Mad Libs-tier Company Culture Notion Page shit that so many startups have. And of course, good VCs are self-aware of all of the issues and strive to prevent them. But the overall problem remains. One last externality is for communities based around an industry. When you add billions of venture dollars into an industry, it becomes cringe. It's saddening to me seeing the state of certain cybersecurity conferences which are now dominated by..."COME TO OUR BOOTH, YOU CAN BE A HACKER. PLEASE VIEW OUR AI GENERATED GRAPHICS OF FIGURES CLAD IN DARK HOODIES STATIONED BEHIND LAPTOPS". Here I would use the pensive emoji U+1F614 to describe my feelings about the appropriation of hacker culture but Phrack is 7-bit ASCII, so please have this: :c u_u . _. --[ 5 - Takeaways The point is, all of this made me feel very small and powerless after I realized the sheer size of the problems I was staring at. Nowadays, to me it's about creating good jobs for my friends, helping our customers, and taking care of the community. Importantly, I realized that this is still making a bigger positive impact than what I could have done alone just as an individual hacker or engineer. To me, businesses are economic machines that can create positive (or negative) impact in a consistent, self-sustaining way. There are many people who are talented, kind, and thoughtful but temporarily unlucky. Having a company let me help these friends monetize their abilities and be rewarded fairly for them. And in that way I helped make their life better. Despite a lot of the BS involved in running a business, this is one thing that is very meaningful to me. You can understand computers and science and math as much as you want, but you will not be able to fix the bigger issues by yourself. The systems that run the world are much bigger than what we can break on our laptops and lab benches. But like those familiar systems, if we want to change things for the better, we have to first understand those systems. Knowledge is power. Understanding is the first step towards change. If you do not like the system as it is, then it is your duty to help fix it. Do not swallow blackpills. It's easy to get really cynical and think things are doomed (to AGI apocalypse, to environmental disaster, to techno/autocratic dystopia, whatever). I want to see a world where thoughtful hackers learn these systems and teach each other about them. That generation of hackers will wield that apparatus, NOT THE OTHER WAY AROUND. Creating leverage for yourself. Hackers should not think of themselves as "oh I am this little guy fighting Big Corporation" or whatever. This is low agency behavior. Instead become the corporation and RUN IT THE WAY YOU THINK IT SHOULD BE RUN. Keep it private and closely held, so no one can fuck it up. Closely train up successors, so in your absence it will continue to be run in a highly principled way that is aligned with your values and morals. Give employees ownership, as it makes everyone aligned with the machine's long-term success, not just you. Raising capital. Many things do really need capital, but raise in a responsible way that leaves you breathing room and the freedom to operate in ways that are aligned with your values. Never compromise your values or integrity. Stay laser focused on cash flows and sustainability, as these grant you the freedom to do the things right. HACKERS SHOULDN'T BE AFRAID TO TOUCH THE CAPITAL MARKETS. Many hackers assume "oh that fundraising stuff is for charismatic business types". I disagree. It's probably better for the world if good thoughtful hackers raise capital. Giving them leverage to change the world is better than giving that leverage to some psycho founder drinking the Kool-Aid. I deeply respect many of the authors in Phrack 71, and I would trust them to do a better job taking care of things than an amorphous amalgam of angry and greedy shareholders. For all things that don't need capital, do not raise. Stay bootstrapped for as long as possible. REMEMBER THAT VALUATION IS A VANITY METRIC. Moxie Marlinspike wrote on his blog [3] that we are often guilty of always trying to quantify success. But what is success? You can quantify net worth, but can you quantify the good you have brought to others lives? For personal goals, think long term. People tend to overestimate what they can do in 1 year, but underestimate what they can do in 10. DO NOT start a company thinking you can get your hands clean of it in 2-3 years. If you do a good job, you will be stuck with it for 5-10+ years. Therefore, DO NOT start a company until you are sure that is what you want to do with your life, or at least, your twenties/thirties (depending on when you start). A common lament among founders, even successful ones, is: "Sometimes I feel like I'm wasting my twenties". There's an easy Catch-22 here: you may not know what you really want until you do the company; but once you do the company, you won't really be able to get out of it. Be wary of that. Creating value. This is one of those meaningless phrases that I dislike. Value is what you define it to be. Remember to work on things that have TAMs, but remember that working on art is valuable too! It is not all about the TAM monster--doing cool things that are NOT ECONOMICALLY VALUABLE, but ARTISTICALLY VALUABLE, is equally important. There is not much economic value in a beautiful polyglot file, but it is artistically delightful. This is part of why people hate AI art: it may be economically valuable, but it is often artistically bankrupt. (Some people do use generative tools in actually original and artistic ways, but this is the exception not the norm currently.) Founders vs Investors. Here is my advice: Ignore any pressure from investors to make company "scalable" or whatever. Make sure your investors have no ability to fire you or your co-founder(s). Make sure you and co-founder are always solid and trust each other more than investors. You and your cofounders need to be BLOOD BROTHERS (/sisters/w.e). If an investor is trying to play politics with one of you to go against the other cofounder, cut that investor out immediately and stop listening to them. Any investor who pushes for scalability over what you think is the best interest of the company is not aligned with you. High-quality investors will not push for this because they are patient and in it for the long game. If you are patient, you can make a very successful company, even if it is not that scalable. High-quality investors will bet on founders and are committed; only bad ones will push for this kind of shit. I'm going to avoid giving more generic startup advice here. Go read Paul Graham's essays. But remember that any investor's perspective will not be the perspective of you and your employees. Pivoting 5 times in 24 months is not a fun experience to work at: your employees will resign while your investors celebrate your "coming of age journey"--unless everyone signed up for that terrifying emotional rollercoaster from the start. They say that "hacker" is a dying identity. Co-opted by annoying VC-backed cybersecurity companies that culturally appropriate the identity, the term is getting more polluted and diluted by the day. Meanwhile, computers are getting more secure, and they are rewriting everything in Rust with pointers-as-capability machines and memory tagging. Is it over? I disagree. As long as the hacker *ethos* is alive, regardless of any particular scene, the identity will always exist. However, now is a crucible moment as a diaspora of hackers, young and old, venture out into the world. Calling all hackers: never forget who you are, who you will become, and the mark you leave. --[ 6 - Thanks Greetz (in no particular order): * ret2jazzy, Sirenfal, ajvpot, rose4096, Transfer Learning, samczsun, tjr, claire (aka sport), and psifertex. * perfect blue, Blue Water, DiceGang, Shellphish, and all CTF players. * NotJan, nspace, xenocidewiki, and the members of pinkchan and Secret Club. * Everyone at Zellic, past and present. Finally, a big thank you to the Phrack staff (shoutout to netspooky and richinseattle!) for making this all possible. --[ 7 - References [1] https://www.sec.gov/Archives/edgar/data/1559720/000119312520315318/ d81668d424b4.htm [2] https://www.sec.gov/Archives/edgar/data/1559720/000119312522115317/ d278253ddef14a.htm [3] https://moxie.org/stories/promise-defeat/ [4] https://twitter.com/nikitabier/status/1622477273294336000 --[ 8 - Appendix: Financial institution glossary for hackers (Not serious! For jokes... :-) - IB: Investment Bank. Basically collect fat fees to do up ("advise on") M&amp;amp;As and other transactions. Help match buyers and sellers for your private equity. They are like CYA for your deal. - PE: Private Equity. Basically buy not-overly-seriously ("poorly") run companies, fire the management, then run it "professionally" (i.e. make it generally shitty for customers and employees and community for the benefit of shareholders) - HF: Hedge Fund. Trade out pricing inefficiencies - MM: Market Maker. Basically the same thing - VC: Basically gamble on tokens (crypto or stocks) and back cool and/or wacky ideas that the rest of these people find too stinky to invest in - PnD: Pump and Dump. - TVL: Total Value Locked. Basically how much money is currently in a blockchain or smart contract system. - TPS: Transactions Per Second. A measure of how scalable or useful a blockchain or database is. An oft-abused metric hacked by vaporware shillers for hype and PnD purposes. - TAM: Total Addressable ~~Memory~~ Market. Basically how much money a given idea can make. - NFA: Not finanical advice. |=[ EOF ]=---------------------------------------------------------------=| &lt;/quote&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://phrack.org/issues/71/17"/><published>2026-01-06T20:24:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518573</id><title>A 30B Qwen model walks into a Raspberry Pi and runs in real time</title><updated>2026-01-07T15:14:05.216376+00:00</updated><content>&lt;doc fingerprint="3edb28de9d388188"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; A 30B Qwen Model Walks Into a Raspberry Piâ¦&lt;lb/&gt; and Runs in Real Time &lt;/head&gt;
    &lt;p&gt;For this release, we optimize for what people actually experience when they run a model: fast, high-quality responses on a specific target device.&lt;/p&gt;
    &lt;p&gt;We use Shapelearn, our bitlength learning method to choose weight datatypes for Qwen3-30B-A3B-Instruct-2507 that maximize performance in terms of tokens per second (TPS) and output quality, with one practical constraint: the model must fit comfortably in the available memory. Once it fits, making the file smaller isn't a goal by itself. We only shrink further when it also improves the real tradeoff people care about: speed vs. quality.&lt;/p&gt;
    &lt;p&gt;Approaching bitlength learning this way matters because in llama.cpp, "fewer bits" doesn't automatically mean "more speed." Different quantization formats can trigger different kernels and overheads, and on some GPUs, going lower-bit can even get slower, despite using less memory.&lt;/p&gt;
    &lt;p&gt;Bottom line: treat memory as a budget to meet, then optimize what matters most: TPS and quality.&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;p&gt; Yes, this 30B Qwen3 runs on a Raspberry Pi. On a Pi 5 (16GB), &lt;code&gt;
              
                Q3_K_S-2.70bpw [KQ-2]
              
            &lt;/code&gt;
            hits 8.03 TPS at 2.70 BPW and maintains 94.18% of BF16 quality. It genuinely feels
            real-time. More broadly, the same pattern shows up everywhere else: ByteShape models
            give you a better TPS/quality tradeoff than the alternatives (here we look at Unsloth
            and MagicQuant).
          &lt;/p&gt;
    &lt;head rend="h2"&gt;CPUs&lt;/head&gt;
    &lt;p&gt;On CPUs, the reducing footprint via shorter bitlengths affects the TPS and accuracy tradeoff as one would expect: once the model fits, reducing footprint tends to increase TPS in a fairly monotonic way. If datatypes are selected correctly, you can trade a bit of quality for speed predictably, which makes it much easier to pick a point on the curve that matches your constraints.&lt;/p&gt;
    &lt;p&gt;We'll start with the most memory-constrained CPU case (Raspberry Pi 5 16GB), where "fits in RAM" is the limiting factor, then move to an Intel i7 with 64GB, where everything fits.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 5&lt;/head&gt;
    &lt;p&gt;The figure below shows TPS vs. normalized accuracy for the models that fit in RAM on the Raspberry Pi 5 16GB.&lt;/p&gt;
    &lt;p&gt;Notably, sustaining 8.5 TPS at 92%+ baseline accuracy with a 30B model on a Raspberry Pi reshapes expectations for Pi-class systems. Overall, the trend shows that ShapeLearn consistently produces better models, with ByteShape trending up and to the right of Unsloth, achieving higher tokens per second at the same quality, or higher quality at the same throughput.&lt;/p&gt;
    &lt;p&gt;We highlight choices for two primary objectives: accuracy or response time.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Optimizing for response time while maintaining accuracy: For interactive, on-device use, perceived responsiveness is driven by how quickly text appears, not peak throughput. In practice, generation feels real-time once it reaches roughly 8 TPS, comfortably above typical reading speed. In this Raspberry Pi real-time regime, &lt;code&gt;Q3_K_S-2.70bpw [KQ-2]&lt;/code&gt;(2.70 BPW, 8.03 TPS, 94.18% accuracy) is our go-to recommendation: it crosses the real-time threshold while maintaining high accuracy. Compared to Unsloth models at similar quality, ByteShape achieves real-time performance at lower BPW and higher TPS, making it the more efficient choice for interactive edge deployment.&lt;/item&gt;
      &lt;item&gt; Accuracy above all: The table below lists the models that achieve the highest accuracy while still being able to run on a Raspberry Pi. Within this set, ByteShape models make the best use of the available resources to maximize accuracy, occupying the lowest-error rows (~1.1â1.3% relative error, ~98.8% accuracy), while the strongest Unsloth entries remain around 2.1â2.2% error (~97.9% accuracy). Compared to Unsloth's &lt;code&gt;UD-Q3_K_XL [8]&lt;/code&gt;, ByteShape achieves up to a 1.87Ã lower error rate while still operating at ~5â6 TPS, comfortably within TPS-norms on Raspberry PI making it the better choice when accuracy is the priority.&lt;lb/&gt;Even when prioritizing maximum speed with some reduction in accuracy,&lt;code&gt;Q3_K_S-3.25bpw [KQ-5]&lt;/code&gt;offers a better tradeoff: more accurate, smaller, and faster than the fastest Unsloth model.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Relative Error&lt;/cell&gt;
        &lt;cell role="head"&gt;BPW&lt;/cell&gt;
        &lt;cell role="head"&gt;TPS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;
                    
                      Q4_K_S-3.92bpw [KQ-7]
                    
                  &lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1.14%&lt;/cell&gt;
        &lt;cell&gt;3.92&lt;/cell&gt;
        &lt;cell&gt;5.30&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;
                    
                      Q4_K_S-3.61bpw [KQ-6]
                    
                  &lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;1.25%&lt;/cell&gt;
        &lt;cell&gt;3.61&lt;/cell&gt;
        &lt;cell&gt;5.94&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;
                    
                      Q3_K_S-3.25bpw [KQ-5]
                    
                  &lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2.03%&lt;/cell&gt;
        &lt;cell&gt;3.25&lt;/cell&gt;
        &lt;cell&gt;6.68&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;UD-IQ3_XXS [6]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2.22%&lt;/cell&gt;
        &lt;cell&gt;3.38&lt;/cell&gt;
        &lt;cell&gt;5.03&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;UD-Q3_K_XL [8]&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;2.13%&lt;/cell&gt;
        &lt;cell&gt;3.62&lt;/cell&gt;
        &lt;cell&gt;6.28&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Many other Unsloth and MagicQuant models (some of ours too!) are not in this chart. We compare them in other sections, but they're not applicable in the Raspberry Pi case. They simply don't fit!&lt;/p&gt;
    &lt;head rend="h3"&gt;Intel i7&lt;/head&gt;
    &lt;p&gt;Next, we move to the Intel i7 with 64GB RAM. The figure below shows TPS vs normalized accuracy for all models.&lt;/p&gt;
    &lt;p&gt;Overall, ByteShape models outperform both Unsloth and MagicQuant, delivering higher quality at comparable throughput using fewer bits per parameter. Only ByteShape offers models that run in the 26+ TPS range, extending performance well beyond the other methods.&lt;/p&gt;
    &lt;p&gt;Highlights:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Quality-first: At the high-accuracy end of the table, &lt;code&gt;IQ4_XS-4.67bpw [KQ-9]&lt;/code&gt;achieves the lowest relative error (0.25%), outperforming the best-running Unsloth models (&lt;code&gt;Q6_K [20]&lt;/code&gt;and&lt;code&gt;Q5_K_M [18]&lt;/code&gt;whose relative errors are 0.36% and 0.44%). Compared directly, ByteShape delivers up to a 1.44Ã lower error rate with higher throughput than&lt;code&gt;Q6_K [20]&lt;/code&gt;, and a 1.76Ã lower error rate at essentially the same speed as&lt;code&gt;Q5_K_M [18]&lt;/code&gt;. MagicQuant&lt;code&gt;mxfp4 [3]&lt;/code&gt;trails in this regime, with both higher error and lower TPS.&lt;/item&gt;
      &lt;item&gt; Balanced point: In the mid-accuracy, high-throughput region, &lt;code&gt;Q3_K_S-3.25bpw [KQ-5]&lt;/code&gt;combines ~98% accuracy with 23.1 TPS at just 3.25 BPW, offering the best overall balance in the table. Matching or exceeding this accuracy with Unsloth (&lt;code&gt;IQ4_XS [10]&lt;/code&gt;) requires higher BPW and lower TPS, while choosing an Unsloth model closer in speed (&lt;code&gt;Q3_K_S [7]&lt;/code&gt;) incurs a 1.73Ã higher error rate. MagicQuant does not offer a competitive model in this range; its fastest entry (&lt;code&gt;IQ4_NL [2]&lt;/code&gt;) is behind both ByteShape and Unsloth in accuracy and throughput.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Takeaway: Across both quality-first and balanced settings, ByteShape consistently converts the available bit budget into either higher accuracy or higher TPS, and is the only approach that simultaneously covers the high-quality and 26+ TPS balanced-performance regions in this comparison.&lt;/p&gt;
    &lt;head rend="h2"&gt;GPUs: RTX5090/32GB and RTX4080/16GB&lt;/head&gt;
    &lt;p&gt;On GPUs, performance depends as much on kernel choice as on raw memory footprint. For matmul/matvec, llama.cpp's quantization-specific GPU decode paths incur very different overheads, so fewer bits per weight do not reliably translate to higher TPS. Instead, TPS often peaks at quantization-specific sweet spots. Pushing BPW lower can even increase VRAM traffic and instruction count, hurting performance rather than improving it. We dig into this behavior in more detail right after the GPU results section, where the kernel-level tradeoffs become more apparent.&lt;/p&gt;
    &lt;p&gt;We evaluate on two GPUs: an RTX 5090 (32 GB), which can run models above 4 BPW and typically reach the fastest sweet spots, and an RTX 4080 (16 GB), where &amp;gt;4 BPW models do not fit, forcing different trade-offs and making the device-optimized curve easier to see.&lt;/p&gt;
    &lt;head rend="h3"&gt;RTX 5090 (32GB of VRAM)&lt;/head&gt;
    &lt;p&gt;Let's start with the 5090, which has enough VRAM to support all of the quantized models. The figure below shows TPS vs normalized accuracy.&lt;/p&gt;
    &lt;p&gt; Two things stand out immediately:&lt;lb/&gt; First, this GPU shows a clear ~4-bit sweet spot: several ~4b models cluster at very high TPS with nearly identical quality. Examples include &lt;code&gt;Unsloth Q4_0 [12]&lt;/code&gt;, &lt;code&gt;Unsloth IQ4_XS [10]&lt;/code&gt;,
            &lt;code&gt;
              
                IQ4_XS-3.87bpw [IQ-6]
              
            &lt;/code&gt;
            , and MagicQuant &lt;code&gt;iq4_nl-EHQKOUD-IQ4NL [1]&lt;/code&gt;, all running around ~302â303 TPS
            at ~98.4â98.9% accuracy. Within 
            this tight cluster, Unsloth edges out slightly in throughput and quality.
          &lt;/p&gt;
    &lt;p&gt;Second, outside of that sweet spot, the tradeoff becomes much more uneven:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Many other Unsloth and Magic Quant models show significantly lower TPS, regardless of whether they are quantized more or less aggressively.&lt;/item&gt;
      &lt;item&gt;Past the ~4b region, only ByteShape continues to increase TPS with a more predictable reduction in quality.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt; Accuracy-critical workloads: when output quality is paramount, ByteShape delivers the most accurate model on the 5090: &lt;code&gt;
              
                IQ4_XS-4.67bpw [IQ-8]
              
            &lt;/code&gt;
            (4.67 BPW, 272.98 TPS, 99.75% accuracy). It surpasses &lt;code&gt;Unsloth Q6_K [20]&lt;/code&gt; (6.57 BPW, 264.88 TPS, 99.64% accuracy) 
            while using fewer bits and achieving slightly higher throughput, and it clearly outperforms MagicQuant 
            &lt;code&gt;mxfp4_moe-H-B16-EUR-IQ4NL-KO-Q5K-QD-Q6K [3]&lt;/code&gt; (5.46 BPW, 240.42 TPS, 99.32% accuracy) in both 
            accuracy and speed, making it the strongest choice when accuracy is a task-critical deployment requirement.
          &lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;Practical takeaway. If your GPU has enough VRAM to run a strong ~4b model that already meets your speed and accuracy requirements, that cluster is an excellent default. The curve becomes more interesting when task-critical deployment constraints demand higher accuracy or smaller models as for example, under tighter memory budgets or constrained environments (as we'll see on the 4080). &lt;/p&gt;
    &lt;head rend="h3"&gt;RTX 4080 (16GB of VRAM)&lt;/head&gt;
    &lt;p&gt;Next, let's move to a more accessible GPU, especially in these memory-challenged times. The biggest stumbling block for the 4080 is its 16GB of VRAM, which is not sufficient to support the "magical" ~4b quantizations for a 30B model. How convenient! This "avoids" the 5090's ~4b sweet spot and forces a more "real-world" comparison under a hard VRAM budget. The figure below shows TPS versus normalized accuracy for all models that fit on the 4080.&lt;/p&gt;
    &lt;p&gt;On the RTX 4080, ByteShape consistently outperforms Unsloth under the same 16 GB VRAM constraint, delivering a better TPSâquality tradeoff.&lt;/p&gt;
    &lt;p&gt; In particular, ByteShape's highest-quality model that fits, &lt;code&gt;
              
                IQ4_XS-3.87bpw [IQ-6]
              
            &lt;/code&gt;
            (3.87 BPW, 214.81 TPS, 98.66% accuracy) delivers:
          &lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; a 1.59Ã lower error rate and 9.4% higher TPS vs. &lt;code&gt;Unsloth Q3_K_XL [8]&lt;/code&gt;(3.62 BPW, 196.42 TPS, 97.87% accuracy).&lt;/item&gt;
      &lt;item&gt; a 2.54Ã lower error rate at the same TPS vs. &lt;code&gt;Unsloth IQ2_M [2]&lt;/code&gt;(2.84 BPW, 214.79 TPS, 96.59% accuracy).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As we move to higher throughput, ByteShape's maintains accuracy, while Unsloth's error rate experiences a cliff.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Elephant in the Room: When 3-bits is not just 3-bits&lt;/head&gt;
    &lt;p&gt;There is an inconvenient truth hiding in these results. On several setups, around 4 bpw is already flying, and pushing quantization harder does not make things faster. It just manages to be smaller and slower at the same time.&lt;/p&gt;
    &lt;p&gt;Reducing the size of data doesn't automatically speed things up. While using fewer bits to store each number seems like it should reduce memory traffic and speed up computation, GPUs don't work that way. NVIDIA GPUs process work in fixed groups of 32 threads called "warps," which move through instructions together in near lock-step. The GPU hardware is optimized for specific data formats, memory access patterns, and operations that the chip's circuits are physically designed to handle efficiently. When your workload matches these "golden paths", you get peak performance. Step outside them, and you hit slowdowns. This isn't a design flaw, it's a deliberate tradeoff. Supporting more flexibility would require additional circuitry: more wires, more transistors, more complexity. That extra hardware consumes more power and adds latency to every operation, whether a program needs that flexibility or not.&lt;/p&gt;
    &lt;p&gt;Here a few examples of relevant hardware "quirks": VRAM is read in aligned 32-byte blocks, so reading one or 32 bytes consumes the same memory bandwidth. Both on-chip and off-chip memories can also suffer contention depending on how data is laid out, meaning that a warp's accesses may complete in a single step or, in the worst case, be serialized into 32 steps. And of course, decoding quantized values before computation can require extra instructions, with the cost depending on the quantization scheme.&lt;/p&gt;
    &lt;p&gt;This explains the behaviour we observe: 4-bit kernels use VRAM bandwidth more efficiently than 3- or 2-bit kernels and require fewer decode steps before computation. At the same time, 4-bit kernels exploit subword parallelism just as effectively as lower-bit kernels, and all rely primarily on dynamic caches rather than shared memory to take advantage of data reuse when possible.&lt;/p&gt;
    &lt;p&gt;So why llama.cpp hasn't been optimized to deliver peak speed for every bit-length? Our understanding is that llama.cpp prioritizes portable, space-efficient quantization that can run across a wide range of hardware. That design goal limits how aggressively backends can reshape data layouts or reorder computation in ways that might help one GPU or one bit-width.&lt;/p&gt;
    &lt;p&gt;A key example is its choice to store quantized weights in fixed blocks of 256 values. Each block is self-contained (it carries everything needed to decode it) and sits at a simple, predictable offset in the tensor, which makes the format easy to implement and fast to locate.&lt;/p&gt;
    &lt;p&gt;The tradeoff is that GPUs often need to decode many blocks in parallel to keep their wide compute units busy. With many independent 256-value blocks, those parallel decodes can translate into more scattered or fragmented VRAM reads and extra decode overhead, reducing bandwidth efficiency, especially for some lower-bit formats.&lt;/p&gt;
    &lt;p&gt; Point for example on RTX 5090: a matrix multiply [256, 768] Ã [768, 2048] takes ~54Âµs with &lt;code&gt;iq4_xs&lt;/code&gt; datatype, but ~62Âµs with 
            &lt;code&gt;iq3_xxs&lt;/code&gt; (mul_mat_q()+mul_mat_q_stream_k_fixup()). In other words, 
            cutting nearly 1.2 bits per weight (a reduction of more than 25% in weight footprint) leads 
            to a ~13% slowdown, directly hurting user experience.
          &lt;/p&gt;
    &lt;p&gt;An excellent reminder that bitlength learning matters: Heuristics can get us part of the way, but not all the way. ShapeLearn makes deliberate, per-tensor datatype choices that improve speed without sacrificing accuracy.&lt;/p&gt;
    &lt;head rend="h2"&gt;Methodology (brief recap)&lt;/head&gt;
    &lt;p&gt;If you're wondering how we are scoring these points, the full methodology is discussed in our previous blog post. This post is intentionally focused on the curves and device tradeoffs, so here is the quick version.&lt;/p&gt;
    &lt;p&gt;For each quantized variant, we measure throughput (TPS) on the target device and compute a single normalized quality score relative to the BF16 baseline, using the same evaluation harness and prompts as the methodology post. The quality score aggregates standard benchmarks (MMLU, GSM8K, IFEval, LiveCodeBench V4) into one number so you can compare points directly. In other words, every dot in the plots answers two questions: how fast does it run on this device, and how much quality does it retain compared to BF16, with memory fit as the first constraint.&lt;/p&gt;
    &lt;p&gt;We also want to thank all for the many, excellent suggestions on our recent Reddit post for improving and extending this evaluation strategy, and weâre actively working through them. Right now, evaluation is the main bottleneck and not bitlength learning/quantization. Careful evaluation is essential to clearly communicate the strengths of each model.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wrapping up&lt;/head&gt;
    &lt;p&gt;First, thank you for your tenacity. You made it through all of this without giving up. We are sincerely flattered!&lt;/p&gt;
    &lt;p&gt;The takeaway is simple: treat memory as a constraint, not a goal. Once a model fits on your device, what matters is the tradeoff curve, TPS versus quality. Across CPUs and GPUs, ByteShape consistently lands on the better side of that curve, delivering either more speed at the same quality or higher quality at the same speed.&lt;/p&gt;
    &lt;p&gt; If you're deploying on a Raspberry Pi 5 (16 GB) and want a genuinely interactive experience, start with &lt;code&gt;
              
                Q3_K_S-2.70bpw [KQ-2]
              
            &lt;/code&gt;
            . On larger CPUs or GPUs, you can move up the curve toward higher-quality points with
            little loss in throughput, the same rule applies:
            fit first, then optimize the tradeoff.
          &lt;/p&gt;
    &lt;p&gt;We'll keep releasing more device-targeted variants (and more plots). If your system can't run a 30B model smoothly, don't blame the model or the silicon. Blame the datatypes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/"/><published>2026-01-06T20:55:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46518804</id><title>Oral microbiome sequencing after taking probiotics</title><updated>2026-01-07T15:14:05.017967+00:00</updated><content>&lt;doc fingerprint="8a7c03af02b6652a"&gt;
  &lt;main&gt;
    &lt;p&gt;Recently, a friend recommended BioGaia Prodentis to me. It is a DTC oral probiotic you can buy online that is supposedly good for oral health. I thought it would be interesting to do some sequencing to see what, if anything, it did to my oral microbiome.&lt;/p&gt;
    &lt;p&gt;BioGaia Prodentis is available online for $20 or less for a month's supply&lt;/p&gt;
    &lt;head rend="h1"&gt;BioGaia&lt;/head&gt;
    &lt;p&gt;BioGaia has a fascinating story. They are a Swedish company, founded over 30 years ago, that exclusively sells probiotics DTC. They have developed multiple strains of Limosilactobacillus reuteri, mainly for gut and oral health. They apparently sell well! Their market cap is around $1B—impressive for a consumer biotech.&lt;/p&gt;
    &lt;p&gt;Going in, I expected scant evidence for any real benefits to their probiotics, but the data (over 250 clinical studies) is much more complete than I expected.&lt;/p&gt;
    &lt;p&gt;Most notably, their gut probiotic, Protectis, seems to have a significant effect on preventing Necrotizing Enterocolitis (NEC) in premature babies. According to their website:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;5-10% of the smallest premature infants develop NEC, a potentially lethal disorder in which portions of the bowel undergo tissue death.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In March 2025, the FDA granted Breakthrough Therapy Designation to IBP-9414, an L. reuteri probiotic developed by BioGaia spinout IBT.&lt;/p&gt;
    &lt;p&gt;This is not specifically for the oral health product, but it's for sure more science than I expected to see going in.&lt;/p&gt;
    &lt;head rend="h3"&gt;Prodentis&lt;/head&gt;
    &lt;p&gt;BioGaia Prodentis contains two strains of L. reuteri: DSM 17938 and ATCC PTA 5289. The claimed benefits include fresher breath, healthier gums, and outcompeting harmful bacteria.&lt;/p&gt;
    &lt;head rend="h1"&gt;Sequencing with Plasmidsaurus&lt;/head&gt;
    &lt;p&gt;Many readers will be familiar with Plasmidsaurus. Founded in 2021, the team took a relatively simple idea: use massively multiplexed Oxford Nanopore (ONT) to offer complete plasmid sequencing with one day turnaround for $15, and scaled it. Plasmidsaurus quickly became part of biotech's core infrastructure, and spread like wildfire. It also inspired multiple copycats.&lt;/p&gt;
    &lt;p&gt;Compared to Illumina, ONT is faster and has much longer reads, but lower throughput and lower accuracy. This profile is a great fit to many sequencing problems like plasmid QC, where you only need megabases of sequences, but want an answer within 24 hours.&lt;/p&gt;
    &lt;p&gt;Over time, Plasmidsaurus has been adding services, including genome sequencing, RNA-Seq, and microbiome sequencing, all based on ONT sequencing.&lt;/p&gt;
    &lt;p&gt;Plasmidsaurus accepts many kinds of sample for microbiome sequencing&lt;/p&gt;
    &lt;p&gt;I used their 16S sequencing product, which costs $45 for ~5000 reads, plus $15 for DNA extraction. 16S sequencing is an efficient way to amplify and sequence a small amount of DNA (the ubiquitous 16S region) and be able to assign reads to specific species or even strains.&lt;/p&gt;
    &lt;p&gt;This experiment cost me $240 for four samples, and I got data back in around a week. It's very convenient that I no longer have to do my own sequencing. As a side note, you can pay more for more than 5000 reads, but unless you want information on very rare strains (&amp;lt;&amp;lt;1% frequency), this is a waste of money.&lt;/p&gt;
    &lt;p&gt;Sample collection is simple: take 100-250 µL of saliva and mix with 500 µL of Zymo DNA/RNA Shield (which I also had to buy for around $70.) You also need 2 mL screwtop tubes to ship in.&lt;/p&gt;
    &lt;p&gt;The reads are high quality for nanopore sequencing, with a median Q score of 23 (99%+ accuracy). This is more than sufficient accuracy for this experiment. The read length is very tightly distributed around 1500 nt (the length of a typical 16S region).&lt;/p&gt;
    &lt;p&gt;The results provided by Plasmidsaurus include taxonomy tables, per-read assignments, and some basic plots. I include a download of the results at the end of this article, as well as the FASTQ files.&lt;/p&gt;
    &lt;head rend="h1"&gt;The experiment&lt;/head&gt;
    &lt;p&gt;The main idea of the experiment was to see if any L. reuteri would colonize by the end of 30 days of probiotic use, and if so, whether it would persist beyond that. I collected four saliva samples:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;Timing&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;Day -4&lt;/cell&gt;
        &lt;cell&gt;A few days before starting BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;Day -1&lt;/cell&gt;
        &lt;cell&gt;The day before I started BioGaia&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;The last day of the 30 day course&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;Day 37&lt;/cell&gt;
        &lt;cell&gt;One week after completing the course&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Heatmap of the top 20 species. All species assignments were done by Plasmidsaurus&lt;/p&gt;
    &lt;head rend="h2"&gt;Did L. reuteri colonize?&lt;/head&gt;
    &lt;p&gt;There was no L. reuteri found in any of the samples. I did a manual analysis to check for any possible misassignments, but the closest read was only 91% identical to either L. reuteri strain.&lt;/p&gt;
    &lt;p&gt;The probiotic either (a) didn't colonize the oral cavity; (b) was present only transiently while actively taking the lozenges; (c) was below the detection threshold.&lt;/p&gt;
    &lt;p&gt;Probiotics are generally bad at colonizing, which is why you have to keep taking them. Still, I was surprised not to see a single L. reuteri read in there.&lt;/p&gt;
    &lt;head rend="h2"&gt;What actually changed?&lt;/head&gt;
    &lt;p&gt;Even though the probiotic itself didn't show up, the oral microbiome did change quite a lot.&lt;/p&gt;
    &lt;p&gt;The most striking change was a massive increase in S. salivarius. S. salivarius went from essentially absent to ~20% of my oral microbiome on the last day. However, this happened one week after I stopped taking the probiotic, so it's very unclear if it is related.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sample&lt;/cell&gt;
        &lt;cell role="head"&gt;S. mitis&lt;/cell&gt;
        &lt;cell role="head"&gt;S. salivarius&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline A&lt;/cell&gt;
        &lt;cell&gt;2.0%&lt;/cell&gt;
        &lt;cell&gt;0.4%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Baseline B&lt;/cell&gt;
        &lt;cell&gt;15.9%&lt;/cell&gt;
        &lt;cell&gt;0.0%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Day 30&lt;/cell&gt;
        &lt;cell&gt;10.2%&lt;/cell&gt;
        &lt;cell&gt;0.8%&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Week after&lt;/cell&gt;
        &lt;cell&gt;1.0%&lt;/cell&gt;
        &lt;cell&gt;19.3%&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We see S. mitis decreasing as S. salivarius increases, while the total Streptococcus fraction stayed roughly stable. It's possible one species replaced the other within the same ecological niche.&lt;/p&gt;
    &lt;p&gt;S. salivarius is itself a probiotic species. The strain BLIS K12 was isolated from a healthy New Zealand child and is sold commercially for oral health. It produces bacteriocins that kill Streptococcus pyogenes (strep throat bacteria).&lt;/p&gt;
    &lt;p&gt;At the same time, V. tobetsuensis increased in abundance from 2.1% to 5.7%. Veillonella bacteria can't eat sugar directly—they survive by consuming lactate that Streptococcus produces. The S. salivarius bloom is plausibly feeding them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Are these changes real or intra-day variation?&lt;/head&gt;
    &lt;p&gt;There was a lot more variation in species than I expected, especially comparing the two baseline samples. In retrospect, I should have taken multiple samples on the same day, and mixed them to smooth it out.&lt;/p&gt;
    &lt;p&gt;However, there is some light evidence that the variation I see is not just intra-day variation. Specifically, there are several species that stay consistent in frequency across all samples: e.g., Neisseria subflava, Streptococcus viridans, Streptococcus oralis.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusions&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;L. reuteri didn't detectably colonize my mouth. Oral probiotics are surprisingly difficult to detect, even if you sample the same day as dosing.&lt;/item&gt;
      &lt;item&gt;S. salivarius increased massively in abundance, but this increase happened after I stopped taking BioGaia&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing can be used to assess oral health. None of the "red complex" bacteria (P. gingivalis, T. forsythia, T. denticola) associated with gum disease were found in any sample.&lt;/item&gt;
      &lt;item&gt;The oral microbiome is dynamic, with huge swings in species abundance over a timeframe of just weeks&lt;/item&gt;
      &lt;item&gt;Microbiome sequencing is very easy and convenient these days thanks to Plasmidsaurus&lt;/item&gt;
      &lt;item&gt;Prodentis tastes good, may help with oral health, and I'd consider taking it again&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.booleanbiotech.com/oral-microbiome-biogaia"/><published>2026-01-06T21:10:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46519303</id><title>Laylo (YC S20) – Head of Growth (Organic and Partners and Loops and AI) – Remote US</title><updated>2026-01-07T15:14:04.320753+00:00</updated><content>&lt;doc fingerprint="b1dc8874f8cd840c"&gt;
  &lt;main&gt;
    &lt;p&gt;The CRM powering iconic musicians and events&lt;/p&gt;
    &lt;p&gt;Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.&lt;/p&gt;
    &lt;p&gt;Role Overview&lt;/p&gt;
    &lt;p&gt;We’re looking for a Head of Growth (player/coach) to build and run Laylo’s growth engine. A 0→1 builder who doesn’t just ideate, but ships. You’ll create great content, run scrappy experiments, and build product growth loops that compound. This is a hands-on role: you’ll set strategy, execute a rapid experiment cadence, measure results, and turn wins into repeatable playbooks.&lt;/p&gt;
    &lt;p&gt;You’ll focus primarily on non-advertising channels: organic social, influencer/creator collaborations, channel partners, and product growth loops. We value strong taste, speed, and a rigorous learning cadence.&lt;/p&gt;
    &lt;p&gt;You’ll report directly to the CEO and work closely with Product, Engineering, Design, Partnerships, and Sales. You’re likely a good fit if you’re excited to open Adobe/Figma/Notion/PostHog and ship something today.&lt;/p&gt;
    &lt;p&gt;Requirements:&lt;/p&gt;
    &lt;p&gt;You’ll thrive here if you can:&lt;/p&gt;
    &lt;p&gt;Key Responsibilities:&lt;/p&gt;
    &lt;p&gt;What Success Looks Like:&lt;/p&gt;
    &lt;p&gt;What You Bring:&lt;/p&gt;
    &lt;p&gt;How To Apply:&lt;/p&gt;
    &lt;p&gt;Send us your first out-of-the-box idea for your first campaign in this role. Bonus points for mentioning other companies and campaigns you think are relevant.&lt;/p&gt;
    &lt;p&gt;Our founders met while building competing consumer startups. We launched multiple products across consumer and SaaS and talked to thousands of fans and creators in the process. In 2020, we realized one of the biggest pain points artists and events face is actually driving their audience from socials into their own CRM.&lt;/p&gt;
    &lt;p&gt;In 2020, we joined Y Combinator’s summer batch and began building a product that quickly gained strong early traction. We raised from top-tier investors like Eldridge and Sony and have since grown into a team of 24 exceptional individuals spanning product, sales, and operations.&lt;/p&gt;
    &lt;p&gt;We have a strong written documentation culture. We try to do as much as possible asynchronously to move quickly and efficiently. We have a daily 30 minute standup and team-specific meetings throughout the week.&lt;/p&gt;
    &lt;p&gt;Creators and Brands have a few key moments that drive the majority of their sales and fan engagement, we call them drops. At Laylo, we're building the Drop CRM to make these moments perfect.&lt;/p&gt;
    &lt;p&gt;With Laylo, creators and brands can notify fans the second they drop new content, merch and events. From there, they get a full featured CRM, a dashboard to connect with fans forever in the future, high conversion landing pages and deep analytics to conversions, click throughs and sales.&lt;/p&gt;
    &lt;p&gt;We work with some of biggest creators, brands, records labels and managers in the world to create incredible drop experiences.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/laylo/jobs/ZtLHRXe-head-of-growth"/><published>2026-01-06T21:44:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46519326</id><title>CES 2026: Taking the Lids Off AMD's Venice and MI400 SoCs</title><updated>2026-01-07T15:14:04.183156+00:00</updated><content>&lt;doc fingerprint="ee681e65ab90b9d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;CES 2026: Taking the Lids off AMD's Venice and MI400 SoCs&lt;/head&gt;
    &lt;p&gt;Hello you fine Internet folks,&lt;/p&gt;
    &lt;p&gt;Here at CES 2026, AMD showed off their upcoming Venice series of server CPUs and their upcoming MI400 series of datacenter accelerators. AMD has talked about the specifications of both Venice and the MI400 series at their Advancing AI event back in June of 2025, but this is the first time AMD has shown off the silicon for both of product lines.&lt;/p&gt;
    &lt;p&gt;Starting with Venice, the first thing to notice is the packaging of the CCDs to the IO dies is different. Instead of using the organic substrate of the package to run the wires between the CCDs and the IO dies that AMD has used since EPYC Rome, Venice appears to be using a more advanced form of packaging similar to Strix Halo or MI250X. Another change is that Venice appears to have two IO dies instead of the single IO die that the prior EPYC CPUs had.&lt;/p&gt;
    &lt;p&gt;Venice has 8 CCDs each of which have 32 cores for a total of up to 256 cores per Venice package. Doing some measuring of each of the dies, you get that each CCD is approximately 165mm2 of N2 silicon. If AMD has stuck to 4MB of L3 per core than each of these CCDs have 32 Zen 6 cores and 128MB of L3 cache along with the die to die interface for the CCD &amp;lt;-&amp;gt; IO die communications. At approximately 165mm2 per CCD, that would make a Zen 6 core plus the 4MB of L3 per core about 5mm2 each which is similar to Zen 5’s approximately 5.34mm2 on N3 when counting both the Zen 5 core and 4MB of L3 cache.&lt;/p&gt;
    &lt;p&gt;Moving to the IO dies, they each appear to be approximately 353mm2 for a total of just over 700mm2 of silicon dedicated for the IO dies. This is a massive increase from the approximately 400mm2 that the prior EPYC CPUs dedicated for their IO dies. The two IO dies appear to be using an advanced packaging of some kind similar to the CCDs. Next to the IO dies appear to be 8 little dies, 4 on each side of the package, which are likely to either be structural silicon or deep trench capacitor dies meant to improve power delivery to the CCDs and IO dies.&lt;/p&gt;
    &lt;p&gt;Shifting off of Venice and on to the MI400 accelerator, this is a massive package with 12 HBM4 dies and “twelve 2 nanometer and 3 nanometer compute and IO dies”. It appears as if there are two base dies just like MI350. But unlike MI350, there appears to also be two extra dies on the top and bottom of the base dies. These two extra dies are likely for off-package IO such as PCIe, UALink, etc.&lt;/p&gt;
    &lt;p&gt;Calculating the die sizes of the base dies and the IO dies, the die size of the base die is approximately 747mm2 for each of the two base dies with the off-package IO dies each being approximately 220mm2. As for the compute dies, while the packaging precludes any visual demarcation of the different compute dies, it is likely that there are 8 compute dies with 4 compute dies on each base die. So while we can’t figure out the exact die size of the compute dies, the maximum size is approximately 180mm2. The compute chiplet is likely in the 140mm2 to 160mm2 region but that is a best guess that will have to wait to be confirmed.&lt;/p&gt;
    &lt;p&gt;The MI455X and Venice are the two SoCs that are going to be powering AMD’s Helios AI Rack but they aren’t the only new Zen 6 and MI400 series products that AMD announced at CES. AMD announced that there would be a third member of the MI400 family called the MI440X joining the MI430X and MI455X. The MI440X is designed to fit into the 8-way UBB boxes as a direct replacement for the MI300/350 series.&lt;/p&gt;
    &lt;p&gt;AMD also announced Venice-X which is likely is going to be a V-Cache version of Venice. This is interesting because not only did AMD skip Turin-X but if there is a 256 core version of Venice-X, then this would be the first time that a high core count CCD will have the ability to support a V-Cache die. If AMD sticks to the same ratio of base die cache to V-Cache die cache, then each 32 core CCD would have up to 384MB of L3 cache which equates to 3 Gigabytes of L3 cache across the chip.&lt;/p&gt;
    &lt;p&gt;Both Venice and the MI400 series are due to launch later this year and I can’t wait to learn more about the underlying architectures of both SoCs.&lt;/p&gt;
    &lt;p&gt;If you like the content then consider heading over to the Patreon or PayPal if you want to toss a few bucks to Chips and Cheese, also consider joining the Discord.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chipsandcheese.com/p/ces-2026-taking-the-lids-off-amds"/><published>2026-01-06T21:46:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46520926</id><title>Show HN: SMTP Tunnel – A SOCKS5 proxy disguised as email traffic to bypass DPI</title><updated>2026-01-07T15:14:03.340958+00:00</updated><content>&lt;doc fingerprint="8cf1e0524c113892"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;A high-speed covert tunnel that disguises TCP traffic as SMTP email communication to bypass Deep Packet Inspection (DPI) firewalls.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;code&gt;┌─────────────┐      ┌─────────────┐      ┌─────────────┐      ┌──────────────┐
│ Application │─────▶│   Client    │─────▶│   Server    │─────▶│  Internet    │
│  (Browser)  │ TCP  │ SOCKS5:1080 │ SMTP │  Port 587   │ TCP  │              │
│             │◀─────│             │◀─────│             │◀─────│              │
└─────────────┘      └─────────────┘      └─────────────┘      └──────────────┘
                            │                    │
                            │   Looks like       │
                            │   Email Traffic    │
                            ▼                    ▼
                     ┌────────────────────────────────┐
                     │     DPI Firewall               │
                     │  ✅ Sees: Normal SMTP Session  │
                     │  ❌ Cannot see: Tunnel Data    │
                     └────────────────────────────────┘
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Feature&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🔒 TLS Encryption&lt;/cell&gt;
        &lt;cell&gt;All traffic encrypted with TLS 1.2+ after STARTTLS&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🎭 DPI Evasion&lt;/cell&gt;
        &lt;cell&gt;Initial handshake mimics real SMTP servers (Postfix)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⚡ High Speed&lt;/cell&gt;
        &lt;cell&gt;Binary streaming protocol after handshake - minimal overhead&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;👥 Multi-User&lt;/cell&gt;
        &lt;cell&gt;Per-user secrets, IP whitelists, and logging settings&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🔑 Authentication&lt;/cell&gt;
        &lt;cell&gt;Per-user pre-shared keys with HMAC-SHA256&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🌐 SOCKS5 Proxy&lt;/cell&gt;
        &lt;cell&gt;Standard proxy interface - works with any application&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;📡 Multiplexing&lt;/cell&gt;
        &lt;cell&gt;Multiple connections over single tunnel&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🛡️ IP Whitelist&lt;/cell&gt;
        &lt;cell&gt;Per-user access control by IP address/CIDR&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;📦 Easy Install&lt;/cell&gt;
        &lt;cell&gt;One-liner server installation with systemd service&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🎁 Client Packages&lt;/cell&gt;
        &lt;cell&gt;Auto-generated ZIP files for each user&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;🔄 Auto-Reconnect&lt;/cell&gt;
        &lt;cell&gt;Client automatically reconnects on connection loss&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;quote&gt;
      &lt;p&gt;📚 For in-depth technical details, protocol specifications, and security analysis, see TECHNICAL.md.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Server: Linux VPS with Python 3.8+, port 587 open&lt;/item&gt;
      &lt;item&gt;Client: Windows/macOS/Linux with Python 3.8+&lt;/item&gt;
      &lt;item&gt;Domain name: Required for TLS certificate verification (free options: DuckDNS, No-IP, FreeDNS)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Get a free domain pointing to your VPS:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🦆 DuckDNS - Recommended, simple and free&lt;/item&gt;
      &lt;item&gt;🌐 No-IP - Free tier available&lt;/item&gt;
      &lt;item&gt;🆓 FreeDNS - Many domain options&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: &lt;code&gt;myserver.duckdns.org&lt;/code&gt; → &lt;code&gt;203.0.113.50&lt;/code&gt; (your VPS IP)&lt;/p&gt;
    &lt;code&gt;curl -sSL https://raw.githubusercontent.com/x011/smtp-tunnel-proxy/main/install.sh | sudo bash&lt;/code&gt;
    &lt;p&gt;The installer will:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;📥 Download and install everything&lt;/item&gt;
      &lt;item&gt;❓ Ask for your domain name&lt;/item&gt;
      &lt;item&gt;🔐 Generate TLS certificates automatically&lt;/item&gt;
      &lt;item&gt;👤 Offer to create your first user&lt;/item&gt;
      &lt;item&gt;🔥 Configure firewall&lt;/item&gt;
      &lt;item&gt;🚀 Start the service&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;That's it! Your server is ready.&lt;/p&gt;
    &lt;code&gt;smtp-tunnel-adduser bob      # Add user + generate client ZIP
smtp-tunnel-listusers        # List all users
smtp-tunnel-deluser bob      # Remove a user&lt;/code&gt;
    &lt;code&gt;smtp-tunnel-update           # Updates code, preserves config/certs/users&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Get your &lt;code&gt;username.zip&lt;/code&gt;file from the server admin&lt;/item&gt;
      &lt;item&gt;Extract the ZIP file&lt;/item&gt;
      &lt;item&gt;Run the launcher:&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;How to Run&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🪟 Windows&lt;/cell&gt;
        &lt;cell&gt;Double-click &lt;code&gt;start.bat&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;🐧 Linux&lt;/cell&gt;
        &lt;cell&gt;Run &lt;code&gt;./start.sh&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;🍎 macOS&lt;/cell&gt;
        &lt;cell&gt;Run &lt;code&gt;./start.sh&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The launcher will automatically install dependencies and start the client.&lt;/p&gt;
    &lt;p&gt;✅ You should see:&lt;/p&gt;
    &lt;code&gt;SMTP Tunnel Proxy Client
User: alice

[INFO] Starting SMTP Tunnel...
[INFO] SOCKS5 proxy will be available at 127.0.0.1:1080

Connecting to myserver.duckdns.org:587
Connected - binary mode active
SOCKS5 proxy on 127.0.0.1:1080
&lt;/code&gt;
    &lt;code&gt;cd alice
pip install -r requirements.txt
python client.py&lt;/code&gt;
    &lt;code&gt;# Download files
scp root@myserver.duckdns.org:/etc/smtp-tunnel/ca.crt .

# Create config.yaml:
cat &amp;gt; config.yaml &amp;lt;&amp;lt; EOF
client:
  server_host: "myserver.duckdns.org"
  server_port: 587
  socks_port: 1080
  username: "alice"
  secret: "your-secret-from-admin"
  ca_cert: "ca.crt"
EOF

# Run client
python client.py -c config.yaml&lt;/code&gt;
    &lt;p&gt;Set SOCKS5 proxy to: &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Settings → Network Settings → Settings&lt;/item&gt;
      &lt;item&gt;Manual proxy configuration&lt;/item&gt;
      &lt;item&gt;SOCKS Host: &lt;code&gt;127.0.0.1&lt;/code&gt;, Port:&lt;code&gt;1080&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Select SOCKS v5&lt;/item&gt;
      &lt;item&gt;✅ Check "Proxy DNS when using SOCKS v5"&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install "Proxy SwitchyOmega" extension&lt;/item&gt;
      &lt;item&gt;Create profile with SOCKS5: &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Settings → Network &amp;amp; Internet → Proxy → Manual setup → &lt;code&gt;socks=127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;System Preferences → Network → Advanced → Proxies → SOCKS Proxy → &lt;code&gt;127.0.0.1:1080&lt;/code&gt;&lt;/p&gt;
    &lt;code&gt;export ALL_PROXY=socks5://127.0.0.1:1080&lt;/code&gt;
    &lt;code&gt;# curl
curl -x socks5h://127.0.0.1:1080 https://ifconfig.me

# git
git config --global http.proxy socks5://127.0.0.1:1080

# Environment variable
export ALL_PROXY=socks5://127.0.0.1:1080&lt;/code&gt;
    &lt;code&gt;# Should show your VPS IP
curl -x socks5://127.0.0.1:1080 https://ifconfig.me&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Listen interface&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.0.0.0&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Listen port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;587&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;hostname&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;SMTP hostname (must match certificate)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;mail.example.com&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;cert_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TLS certificate path&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;server.crt&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;key_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;TLS private key path&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;server.key&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;users_file&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Path to users configuration&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;users.yaml&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;log_users&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Global logging setting&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;true&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Each user can have individual settings:&lt;/p&gt;
    &lt;code&gt;users:
  alice:
    secret: "auto-generated-secret"
    # whitelist:              # Optional: restrict to specific IPs
    #   - "192.168.1.100"
    #   - "10.0.0.0/8"        # CIDR notation supported
    # logging: true           # Optional: disable to stop logging this user

  bob:
    secret: "another-secret"
    whitelist:
      - "203.0.113.50"        # Bob can only connect from this IP
    logging: false            # Don't log Bob's activity&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;User's authentication secret&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;whitelist&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Allowed IPs for this user (CIDR supported)&lt;/cell&gt;
        &lt;cell&gt;All IPs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;logging&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable activity logging for this user&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;true&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;server_host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server domain name&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;server_port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Server port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;587&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;socks_port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Local SOCKS5 port&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1080&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;socks_host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Local SOCKS5 interface&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;127.0.0.1&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;username&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Your username&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Your authentication secret&lt;/cell&gt;
        &lt;cell&gt;Required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;ca_cert&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;CA certificate for verification&lt;/cell&gt;
        &lt;cell&gt;Recommended&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Check status
sudo systemctl status smtp-tunnel

# Restart after config changes
sudo systemctl restart smtp-tunnel

# View logs
sudo journalctl -u smtp-tunnel -n 100

# Uninstall
sudo /opt/smtp-tunnel/uninstall.sh&lt;/code&gt;
    &lt;code&gt;python server.py [-c CONFIG] [-d]

  -c, --config    Config file (default: config.yaml)
  -d, --debug     Enable debug logging&lt;/code&gt;
    &lt;code&gt;python client.py [-c CONFIG] [--server HOST] [--server-port PORT]
                 [-p SOCKS_PORT] [-u USERNAME] [-s SECRET] [--ca-cert FILE] [-d]

  -c, --config      Config file (default: config.yaml)
  --server          Override server domain
  --server-port     Override server port
  -p, --socks-port  Override local SOCKS port
  -u, --username    Your username
  -s, --secret      Override secret
  --ca-cert         CA certificate path
  -d, --debug       Enable debug logging&lt;/code&gt;
    &lt;code&gt;smtp-tunnel-adduser &amp;lt;username&amp;gt; [-u USERS_FILE] [-c CONFIG] [--no-zip]
    Add a new user and generate client package

smtp-tunnel-deluser &amp;lt;username&amp;gt; [-u USERS_FILE] [-f]
    Remove a user (use -f to skip confirmation)

smtp-tunnel-listusers [-u USERS_FILE] [-v]
    List all users (use -v for detailed info)

smtp-tunnel-update
    Update server to latest version (preserves config/certs/users)&lt;/code&gt;
    &lt;code&gt;smtp_proxy/
├── 📄 server.py               # Server (runs on VPS)
├── 📄 client.py               # Client (runs locally)
├── 📄 common.py               # Shared utilities
├── 📄 generate_certs.py       # Certificate generator
├── 📄 config.yaml             # Server/client configuration
├── 📄 users.yaml              # User database
├── 📄 requirements.txt        # Python dependencies
├── 📄 install.sh              # One-liner server installer
├── 📄 smtp-tunnel.service     # Systemd unit file
├── 🔧 smtp-tunnel-adduser     # Add user script
├── 🔧 smtp-tunnel-deluser     # Remove user script
├── 🔧 smtp-tunnel-listusers   # List users script
├── 🔧 smtp-tunnel-update      # Update server script
├── 📄 README.md               # This file
└── 📄 TECHNICAL.md            # Technical documentation
&lt;/code&gt;
    &lt;code&gt;/opt/smtp-tunnel/              # Application files
/etc/smtp-tunnel/              # Configuration files
  ├── config.yaml
  ├── users.yaml
  ├── server.crt
  ├── server.key
  └── ca.crt
/usr/local/bin/                # Management commands
  ├── smtp-tunnel-adduser
  ├── smtp-tunnel-deluser
  ├── smtp-tunnel-listusers
  └── smtp-tunnel-update
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check server is running: &lt;code&gt;systemctl status smtp-tunnel&lt;/code&gt;or&lt;code&gt;ps aux | grep server.py&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check port is open: &lt;code&gt;netstat -tlnp | grep 587&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Check firewall: &lt;code&gt;ufw status&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Verify &lt;code&gt;username&lt;/code&gt;and&lt;code&gt;secret&lt;/code&gt;match in users.yaml&lt;/item&gt;
      &lt;item&gt;Check server time is accurate (within 5 minutes)&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;smtp-tunnel-listusers -v&lt;/code&gt;to verify user exists&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Check user's whitelist in users.yaml&lt;/item&gt;
      &lt;item&gt;Your current IP must match a whitelist entry&lt;/item&gt;
      &lt;item&gt;CIDR notation is supported (e.g., &lt;code&gt;10.0.0.0/8&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ensure you're using a domain name, not IP address&lt;/item&gt;
      &lt;item&gt;Verify &lt;code&gt;server_host&lt;/code&gt;matches the certificate hostname&lt;/item&gt;
      &lt;item&gt;Ensure you have the correct &lt;code&gt;ca.crt&lt;/code&gt;from the server&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Enable detailed logging
python server.py -d
python client.py -d

# View systemd logs
journalctl -u smtp-tunnel -f&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;✅ Always use a domain name for proper TLS verification&lt;/item&gt;
      &lt;item&gt;✅ Always use &lt;code&gt;ca_cert&lt;/code&gt;to prevent man-in-the-middle attacks&lt;/item&gt;
      &lt;item&gt;✅ Use &lt;code&gt;smtp-tunnel-adduser&lt;/code&gt;to generate strong secrets automatically&lt;/item&gt;
      &lt;item&gt;✅ Use per-user IP whitelists if you know client IPs&lt;/item&gt;
      &lt;item&gt;✅ Protect &lt;code&gt;users.yaml&lt;/code&gt;- contains all user secrets (chmod 600)&lt;/item&gt;
      &lt;item&gt;✅ Disable logging for sensitive users with &lt;code&gt;logging: false&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;📚 For detailed security analysis and threat model, see TECHNICAL.md.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This project is provided for educational and authorized use only. Use responsibly and in accordance with applicable laws.&lt;/p&gt;
    &lt;p&gt;This tool is designed for legitimate privacy and censorship circumvention purposes. Users are responsible for ensuring their use complies with applicable laws and regulations.&lt;/p&gt;
    &lt;p&gt;Made with ❤️ for internet freedom&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/x011/smtp-tunnel-proxy"/><published>2026-01-07T00:30:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46520935</id><title>Electronic nose for indoor mold detection and identification</title><updated>2026-01-07T15:14:03.189328+00:00</updated><content/><link href="https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124"/><published>2026-01-07T00:31:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46521029</id><title>We recreated Steve Jobs's 1975 Atari horoscope program</title><updated>2026-01-07T15:14:03.049286+00:00</updated><content/><link href="https://blog.adafruit.com/2026/01/06/we-recreated-steve-jobss-1975-atari-horoscope-program-and-you-can-run-it/"/><published>2026-01-07T00:44:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46522308</id><title>On the slow death of scaling</title><updated>2026-01-07T15:14:02.851662+00:00</updated><content/><link href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5877662"/><published>2026-01-07T03:48:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525394</id><title>Optery (YC W22) Hiring a CISO and Web Scraping Engineers (Node) (US and Latam)</title><updated>2026-01-07T15:14:02.596318+00:00</updated><content>&lt;doc fingerprint="ca6bb85f43b74372"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Careers&lt;/head&gt;
    &lt;p&gt;💡Page not loading? Optery’s Career page uses Cookies to display the full page content. If you’re not seeing anything, try opening the cookie banner (cookie icon in the bottom left corner) and Accept Personalization cookies.&lt;/p&gt;
    &lt;p&gt;💡Page not loading? Optery’s Career page uses Cookies to display the full page content. If you’re not seeing anything, try opening the cookie banner (cookie icon in the bottom left corner) and Accept Personalization cookies.&lt;/p&gt;
    &lt;p&gt;Ready to safeguard your personal data?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.optery.com/careers/"/><published>2026-01-07T12:00:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525542</id><title>The Eric and Wendy Schmidt Observatory System</title><updated>2026-01-07T15:14:01.678112+00:00</updated><content>&lt;doc fingerprint="f611b05667864f3b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Eric and Wendy Schmidt Observatory System&lt;/head&gt;
    &lt;p&gt;Four novel observatories expanding access and enabling new ways to explore the cosmos&lt;/p&gt;
    &lt;p&gt;The Eric and Wendy Schmidt Observatory System is designed to pioneer a new paradigm for astronomical observatories, fundamentally rethinking how they are conceived, developed, and utilized. This initiative compresses development timelines from decades to years, dramatically lowering barriers to global participation and accelerating the pace of discovery. By uniting rapid development cycles with open data and shared scientific tools, the system empowers researchers everywhere to engage in frontier astrophysics.&lt;/p&gt;
    &lt;head rend="h2"&gt; Strategic Pillars &lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Rapid observatory development leveraging risk-tolerant technical innovation&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Modular designs that leverage economies of scale&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Open data and software for global access&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Global, cross-disciplinary scientific collaboration&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt; Major Projects &lt;/head&gt;
    &lt;p&gt;Through more accessible and responsive scientific infrastructure, the Eric and Wendy Schmidt Observatory System seeks to support discovery for the benefit of all. Explore our projects by clicking the tiles below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Argus Array&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Deep Synoptic Array (DSA)&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Large Fiber Array Spectroscopic Telescope (LFAST)&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;Lazuli Space Observatory&lt;/head&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;head rend="h3"&gt;FirstLight Awards&lt;/head&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.schmidtsciences.org/schmidt-observatory-system/"/><published>2026-01-07T12:19:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525640</id><title>“Stop Designing Languages. Write Libraries Instead” (2016)</title><updated>2026-01-07T15:14:01.400561+00:00</updated><content>&lt;doc fingerprint="2fc219af0a3a92d0"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;HomePhilosophyDownloadsDocumentationPeopleCommunityNewsReference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;head&gt;NAVIGATION&lt;/head&gt;
          &lt;head&gt;"Stop Designing Languages. Write Libraries Instead."&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;"Stop Designing Languages. Write Libraries Instead."&lt;/head&gt;
          &lt;p&gt;Patrick S. Li - May 29, 2016&lt;/p&gt;
          &lt;p&gt;I had a friend tell me recently that all programming languages seem very similar to each other. They all have variables, and arrays, a few loop constructs, functions, and some arithmetic constructs. Sure, some languages have fancier features like first-class functions or coroutines, but he doesn't consider himself an expert programmer anyway and doesn't use those features.&lt;/p&gt;
          &lt;p&gt;What really makes a programming language productive for him, he says, are the libraries it comes with. For example, he got into programming by using the popular Ruby on Rails web framework. There is no way that he could have written a full database-driven web stack by himself, nor is he interested in doing so. But thanks to Ruby on Rails, he doesn't have to! So he said that he has no particular opinion about the Ruby programming language, but he absolutely loves Rails. The vast majority of programmers are non-experts, like himself, and the largest gains in productivity for non-experts come from having a wide spectrum of easy-to-use libraries. Subtle language features like first-class functions, and object systems, are lost on them because they don't really use them anyway. Computer scientists should really be spending their time developing new libraries rather than inventing new programming languages.&lt;/p&gt;
          &lt;p&gt;My friend's opinion about programming languages is a common one, and I have heard it repeatedly from experts and non-experts alike. Being a language designer myself, I, of course, don't share this opinion. Here is what I consider to be the purpose of a general-purpose programming language.&lt;/p&gt;
          &lt;p&gt;To start off, I would say that my friend's opinion is completely correct, just incomplete. The greatest productivity gains are indeed the result of having a wide spectrum of libraries. Ruby on Rails is a fantastic framework, and it has enabled thousands (if not millions) of non-experts to build sophisticated websites quickly. So the natural question then is, why isn't there now a Rails framework for every programming language?&lt;/p&gt;
          &lt;p&gt;Some languages that are semantically similar to Ruby do have their own web frameworks. Python, for example, has Django. But as of now, there is still no decent web framework for Java that is as easy to use as Ruby on Rails. Why is that? Are Java developers just not as competent as Ruby programmers? If David Hansson could design and develop Rails by himself, why can't a group of programmers just copy the design to Java? What makes this even more embarrassing is the fact that Java initially marketed itself as the web programming language, because of its applet technology. To emphasize this point, let me add that there is no good web framework for C either, and it is unlikely that there ever will be. Let me assure you that it's not because C programmers are worse than Ruby programmers.&lt;/p&gt;
          &lt;p&gt;Economics is not the reason either. The Tiobe index lists Java and C as the most widely used programming languages today, with Ruby coming in eighth place. There are many times more Java and C programmers than there are Ruby programmers. If someone would just write Java on Rails their framework would have many times more users than Ruby on Rails, and it would instantly propel him to internet fame and fortune.&lt;/p&gt;
          &lt;p&gt;So it's not because of incompetency. Nor is it because of economics. So why else wouldn't someone port Ruby on Rails to Java? Well, simply, because they can't.&lt;/p&gt;
          &lt;p&gt;If you're a knowledgeable Ruby programmer and you take a deep look through an introductory Rails tutorial, you'll notice that pretty much all of the Ruby language features come into play in some way. Rail's ActiveRecords library makes pervasive use of Ruby's meta-programming features. Rail's template system heavily relies upon Ruby's runtime evaluation features. To make your website respond to a user click, you subclass &lt;/p&gt;
          &lt;p&gt;So, completely unbeknownst to my friend, he is actually making heavy use of all those subtle language features that he claimed he never cared about. And this is intentional! Ruby on Rails was designed to make it possible to build websites without understanding type theory, or memory management, or object-oriented design patterns. Rails allow website designers to focus on designing websites, not managing their software infrastructure. My friend is enjoying all the benefits of Ruby without even knowing it, and that's the whole point.&lt;/p&gt;
          &lt;p&gt;Taking a step back, the concept of packaging code into easy-to-use libraries is not new. It's been around even in the days when programs were stored on punched paper tape. There are still vast libraries of assembly code containing useful subroutines. And every programming language ever designed provided some way for common functionality to be reused. To me, this is the primary purpose of a general-purpose programming language, to enable the creation of a wide spectrum of easy-to-use libraries.&lt;/p&gt;
          &lt;p&gt;The design of the programming language directly determines what sort of libraries you can write and how easy they are to use in the end. In the C language, the only major feature provided for enabling reuse is the ability to declare and call functions. So guess what? The majority of C libraries are basically large collections of functions. Ruby on Rails provides a concise way for expressing: do this when the button is clicked. The "do this" part is implemented in Ruby as a first-class function. How would it be implemented in languages like Java which don't support them? Well, the behaviour of first-class functions can be mocked by defining a new event handler class with a single &lt;/p&gt;
          &lt;p&gt;In the early days of software, collections of functions were sufficient in allowing us to code reusable components. A lot of early software was numerical in nature, and there was a library function for every numerical algorithm you would want to run. Numbers go in. Numbers come out. Functions were perfectly adequate for this. Unix and C were also designed in a time when the majority of computing happens in batch mode. You prepare some input data, call a function or run a program, and you get some output data back. But computing has changed radically since the 70's. Nowadays, most interesting programs are interactive. When a user clicks a button, it should do something. It was rare to want to extend the functionality of a library of the 70's. The library provides a collection of useful functions. If one of them does what you want, then use it. If not, then write your own. But with the advent of interactive software, the need for extensible libraries became apparent. Programmers wanted GUI libraries that allowed them to say: when a user clicks a button, please run my code. Java (and C++) provides a limited method for extending an existing library's functionality through its subclassing mechanism. So using a Java library often consists of subclassing a number of magical classes and then overriding a number of magical methods. This style of library became so pervasive at one point that we even gave them a new name. They're called frameworks.&lt;/p&gt;
          &lt;p&gt;I surmise that probably many general purpose programming languages were originally designed because of the author's inability to write a good library for the language that he was using at the time. The initial impetus that got me thinking about designing Stanza, for example, came out of my frustrations with trying to write an easy-to-use game programming library in Java. To handle concurrency, traditional game programming frameworks required sprite behaviours to be programmed using a state machine model. But that's not how we intuitively think about sprites in our heads. Intuitively, we think about a character's behaviour as consisting of a sequence of steps. For example, first the character jumps, and then after he lands he looks to his left and then his right for the nearest enemy. If he sees one then he goes to attack it, otherwise he jumps again. He does this three times, and if he doesn't see an enemy after three jumps, then he takes a short nap. Transforming this sequence of steps into a state machine is an incredibly tedious and error-prone process, and most importantly, feels repetitive. It felt like I was doing the same thing again and again. So the natural question is, can I just make this state machine transformation a library and re-use it? It turns out I couldn't, not in Java at least. The language feature that I needed was some sort of coroutine or continuation mechanism. After some research I found that the Scheme language supports continuations, so the Scheme version of my game programming library was much easier to use than the Java version.&lt;/p&gt;
          &lt;p&gt;Because of its support for continuations, the Scheme version of my game library does not require users to write their sprite behaviour as state machines. But it wasn't better than the Java version in every way. Most importantly, the Java version was statically typed and so the compiler automatically caught many of your mistakes for you. The Scheme version didn't have this ability and thus debugging my games took a bit longer. At this point, the right question to ask would be, well can you write a static-typing library for Scheme that then automatically checks your code for type errors? And the current answer, for now and for the foreseeable future, is no. No mainstream language today allows you to write a library to extend its type system. Stanza doesn't either. It just attempts to provide one that is useful for a wider audience.&lt;/p&gt;
          &lt;p&gt;Since the purpose of general-purpose programming languages are to enable the creation of powerful libraries, this means that different languages can also be characterized by what features they provide that cannot be written as libraries. Stanza provides an optional type system, garbage collection, and a multimethod based object system. But if you don't like Stanza's object system, there is no way to write your own. This is one of the main directions of programming language research. Can we design a language so expressive that library writers can easily write the most appropriate object system, or most appropriate type system, to fit their application? Perhaps one day we'll have such a language. Racket and Shen provide mechanisms for extending their type systems and research on meta-object protocols were attempts at designing extensible object systems. So languages are differentiated by what types of libraries you can write in them and what types of libraries you can't.&lt;/p&gt;
          &lt;p&gt;In summary, the purpose of a general-purpose programming language is to enable the creation of powerful and easy-to-use libraries. The more powerful the language, the easier the libraries are to use. Code that makes use of a perfectly tuned library should read almost like a set of instructions for a coworker. So the next time you come across a particularly elegant library, know that many decades of language research has gone into making that possible. If you're curious about specifically which language features a library makes use of, then you can dig deeper, explore, and appreciate the thought that went into its implementation. If you're not curious about all this subtle language stuff, you can safely ignore it all and get on with your work. That's the whole point.&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Site design by Luca Li. Copyright 2015.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lbstanza.org/purpose_of_programming_languages.html"/><published>2026-01-07T12:29:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46525888</id><title>A4 Paper Stories</title><updated>2026-01-07T15:14:00.909390+00:00</updated><content>&lt;doc fingerprint="7299db7cc73604b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A4 Paper Stories&lt;/head&gt;
    &lt;p&gt;I sometimes resort to a rather common measuring technique that is neither fast, nor accurate, nor recommended by any standards body and yet it hasn't failed me whenever I have had to use it. I will describe it here, though calling it a technique might be overselling it. Please do not use it for installing kitchen cabinets or anything that will stare back at you every day for the next ten years. It involves one tool: a sheet of A4 paper.&lt;/p&gt;
    &lt;p&gt;Like most sensible people with a reasonable sense of priorities, I do not carry a ruler with me wherever I go. Nevertheless, I often find myself needing to measure something at short notice, usually in situations where a certain amount of inaccuracy is entirely forgivable. When I cannot easily fetch a ruler, I end up doing what many people do and reach for the next best thing, which for me is a sheet of A4 paper, available in abundant supply where I live.&lt;/p&gt;
    &lt;p&gt;From photocopying night-sky charts to serving as a scratch pad for working through mathematical proofs, A4 paper has been a trusted companion since my childhood days. I use it often. If I am carrying a bag, there is almost always some A4 paper inside: perhaps a printed research paper or a mathematical problem I have worked on recently and need to chew on a bit more during my next train ride.&lt;/p&gt;
    &lt;head rend="h2"&gt;Dimensions&lt;/head&gt;
    &lt;p&gt;The dimensions of A4 paper are the solution to a simple, elegant problem. Imagine designing a sheet of paper such that, when you cut it in half parallel to its shorter side, both halves have exactly the same aspect ratio as the original. In other words, if the shorter side has length \( x \) and the longer side has length \( y , \) then \[ \frac{y}{x} = \frac{x}{y / 2} \] which gives us \[ \frac{y}{x} = \sqrt{2}. \] Test it out. Suppose we have \( y/x = \sqrt{2}. \) We cut the paper in half parallel to the shorter side to get two halves, each with shorter side \( x' = y / 2 = x \sqrt{2} / 2 = x / \sqrt{2} \) and longer side \( y' = x. \) Then indeed \[ \frac{y'}{x'} = \frac{x}{x / \sqrt{2}} = \sqrt{2}. \] In fact, we can keep cutting the halves like this and we'll keep getting even smaller sheets with the aspect ratio \( \sqrt{2} \) intact. To summarise, when a sheet of paper has the aspect ratio \( \sqrt{2}, \) bisecting it parallel to the shorter side leaves us with two halves that preserve the aspect ratio. A4 paper has this property.&lt;/p&gt;
    &lt;p&gt;But what are the exact dimensions of A4 and why is it called A4? What does 4 mean here? Like most good answers, this one too begins by considering the numbers \( 0 \) and \( 1. \) Let me elaborate.&lt;/p&gt;
    &lt;p&gt;Let us say we want to make a sheet of paper that is \( 1 \, \mathrm{m}^2 \) in area and has the aspect-ratio-preserving property that we just discussed. What should its dimensions be? We want \[ xy = 1 \, \mathrm{m}^2 \] subject to the condition \[ \frac{y}{x} = \sqrt{2}. \] Solving these two equations gives us \[ x^2 = \frac{1}{\sqrt{2}} \, \mathrm{m}^2 \] from which we obtain \[ x = \frac{1}{\sqrt[4]{2}} \, \mathrm{m}, \quad y = \sqrt[4]{2} \, \mathrm{m}. \] Up to three decimal places, this amounts to \[ x = 0.841 \, \mathrm{m}, \quad y = 1.189 \, \mathrm{m}. \] These are the dimensions of A0 paper. It is quite large to scribble mathematical solutions on, unless your goal is to make a spectacle of yourself and cause your friends and family to reassess your sanity. So we need something smaller that allows us to work in peace, without inviting commentary or concerns from passersby. We take the A0 paper of size \[ 84.1 \, \mathrm{cm} \times 118.9 \, \mathrm{cm} \] and bisect it to get A1 paper of size \[ 59.4 \, \mathrm{cm} \times 84.1 \, \mathrm{cm}. \] Then we bisect it again to get A2 paper with dimensions \[ 42.0 \, \mathrm{cm} \times 59.4 \, \mathrm{cm}. \] And once again to get A3 paper with dimensions \[ 29.7 \, \mathrm{cm} \times 42.0 \, \mathrm{cm}. \] And then once again to get A4 paper with dimensions \[ 21.0 \, \mathrm{cm} \times 29.7 \, \mathrm{cm}. \] There we have it. The dimensions of A4. These numbers are etched in my memory like the multiplication table of \( 1. \) We can keep going further to get A5, A6, etc. We could, in theory, go all the way up to A\( \infty. \) Hold on, I think I hear someone heckle. What's that? Oh, we can't go all the way to A\( \infty? \) Something about atoms, was it? Hmm. Security! Where's security? Ah yes, thank you, sir. Please show this gentleman out, would you?&lt;/p&gt;
    &lt;p&gt;Sorry for the interruption, ladies and gentlemen. Phew! That fellow! Atoms? Honestly. We, the mathematically inclined, are not particularly concerned with such trivial limitations. We drink our tea from doughnuts. We are not going to let the size of atoms dictate matters, now are we?&lt;/p&gt;
    &lt;p&gt;So I was saying that we can bisect our paper like this and go all the way to A\( \infty. \) That reminds me. Last night I was at a bar in Hoxton and I saw an infinite number of mathematicians walk in. The first one asked, "Sorry to bother you, but would it be possible to have a sheet of A0 paper? I just need something to scribble a few equations on." The second one asked, "If you happen to have one spare, could I please have an A1 sheet?" The third one said, "An A2 would be perfectly fine for me, thank you." Before the fourth one could ask, the bartender disappeared into the back for a moment and emerged with two sheets of A0 paper and said, "Right. That should do it. Do know your limits and split these between yourselves."&lt;/p&gt;
    &lt;p&gt;In general, a sheet of A\( n \) paper has the dimensions \[ 2^{-(2n + 1)/4} \, \mathrm{m} \times 2^{-(2n - 1)/4} \, \mathrm{m}. \] If we plug in \( n = 4, \) we indeed get the dimensions of A4 paper: \[ 0.210 \, \mathrm{m} \times 0.297 \, \mathrm{m}. \]&lt;/p&gt;
    &lt;head rend="h2"&gt;Measuring Stuff&lt;/head&gt;
    &lt;p&gt;Let us now return to the business of measuring things. As I mentioned earlier, the dimensions of A4 are lodged firmly into my memory. Getting hold of a sheet of A4 paper is rarely a challenge where I live. I have accumulated a number of A4 paper stories over the years. Let me share a recent one. I was hanging out with a few folks of the nerd variety one afternoon when the conversation drifted, as it sometimes does, to a nearby computer monitor that happened to be turned off. At some point, someone confidently declared that the screen in front of us was 27 inches. That sounded plausible but we wanted to confirm it. So I reached for my trusted measuring instrument: an A4 sheet of paper. What followed was neither fast, nor especially precise, but it was more than adequate for settling the matter at hand.&lt;/p&gt;
    &lt;p&gt;I lined up the longer edge of the A4 sheet with the width of the monitor. One length. Then I repositioned it and measured a second length. The screen was still sticking out slightly at the end. By eye, drawing on an entirely unjustified confidence built from years of measuring things that never needed measuring, I estimated the remaining bit at about \( 1 \, \mathrm{cm}. \) That gives us a width of \[ 29.7 \, \mathrm{cm} + 29.7 \, \mathrm{cm} + 1.0 \, \mathrm{cm} = 60.4 \, \mathrm{cm}. \] Let us round that down to \( 60 \, \mathrm{cm}. \) For the height, I switched to the shorter edge. One full \( 21 \, \mathrm{cm} \) fit easily. For the remainder, I folded the paper parallel to the shorter side, producing an A5-sized rectangle with dimensions \( 14.8 \, \mathrm{cm} \times 21.0 \, \mathrm{cm}. \) Using the \( 14.8 \, \mathrm{cm} \) edge, I discovered that it overshot the top of the screen slightly. Again, by eye, I estimated the excess at around \( 2 \, \mathrm{cm}. \) That gives us \[ 21.0 \, \mathrm{cm} + 14.8 \, \mathrm{cm} -2.0 \, \mathrm{cm} = 33.8 \, \mathrm{cm}. \] Let us round this up to \( 34 \, \mathrm{cm}. \) The ratio \( 60 / 34 \approx 1.76 \) is quite close to \( 16/9, \) a popular aspect ratio of modern displays. At this point the measurements were looking good. So far, the paper had not embarrassed itself. Invoking the wisdom of the Pythagoreans, we can now estimate the diagonal as \[ \sqrt{(60 \, \mathrm{cm})^2 + (34 \, \mathrm{cm})^2} \approx 68.9 \,\mathrm{cm}. \] Finally, there is the small matter of units. One inch is \( 2.54 \, \mathrm{cm}, \) another figure that has embedded itself in my head. Dividing \( 68.9 \) by \( 2.54 \) gives us roughly \( 27.2 \, \mathrm{in}. \) So yes. It was indeed a \( 27 \)-inch display. My elaborate exercise in showing off my A4 paper skills was now complete. Nobody said anything. A few people looked away in silence. I assumed they were reflecting. I am sure they were impressed deep down. Or perhaps... no, no. They were definitely impressed. I am sure.&lt;/p&gt;
    &lt;p&gt;Hold on. I think I hear another heckle. What is that? There are mobile phone apps that can measure things now? Really? Right. Security. Where's security?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://susam.net/a4-paper-stories.html"/><published>2026-01-07T12:54:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526088</id><title>Show HN: KeelTest – AI-driven VS Code unit test generator with bug discovery</title><updated>2026-01-07T15:13:59.714269+00:00</updated><content>&lt;doc fingerprint="10373b5026f706a0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI Tests That Find &lt;lb/&gt;Bugs Before Production&lt;/head&gt;
    &lt;p&gt;Generate pytest suites that actually run - and expose issues in your code. 90% average pass rate. Source bugs flagged with fix suggestions.&lt;/p&gt;
    &lt;p&gt;Free forever · 7 credits/month · No credit card required&lt;/p&gt;
    &lt;p&gt;* Stats updated weekly. Based on active Alpha usage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get Started in 3 Simple Steps&lt;/head&gt;
    &lt;p&gt;KeelTest is a VS Code extension that installs in seconds. No complex setup, no external services.&lt;/p&gt;
    &lt;head rend="h3"&gt;Open VS Code Extensions&lt;/head&gt;
    &lt;p&gt;Press Ctrl+Shift+X (Windows/Linux) or Cmd+Shift+X (Mac) to open the Extensions view in VS Code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Search for KeelTest&lt;/head&gt;
    &lt;p&gt;Type "KeelTest" in the search bar and click Install on the official KeelTest extension.&lt;/p&gt;
    &lt;head rend="h3"&gt;Right-Click and Generate&lt;/head&gt;
    &lt;p&gt;Right-click any Python file in your workspace and select "KeelTest: Generate Tests" to start.&lt;/p&gt;
    &lt;p&gt;Free to install • Available on VS Code Marketplace • No credit card required&lt;/p&gt;
    &lt;head rend="h2"&gt;Why developers switch &lt;lb/&gt;to KeelTest&lt;/head&gt;
    &lt;p&gt;Moving beyond simple prompts. We combined static analysis with a multi-step verification pipeline to deliver production-grade tests.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deep Static Analysis&lt;/head&gt;
    &lt;p&gt;Our engine builds a full AST (Abstract Syntax Tree) representation of your code, identifying exactly which branches need coverage and which edge cases are most likely to cause regressions.&lt;/p&gt;
    &lt;head rend="h2"&gt;From Code to Tests in 3 Clicks&lt;/head&gt;
    &lt;head rend="h2"&gt;Start Free, Scale When Ready&lt;/head&gt;
    &lt;p&gt;Join ... developers already on the waitlist for our upcoming premium tiers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Individual Plans&lt;/head&gt;
    &lt;head rend="h4"&gt;Starter&lt;/head&gt;
    &lt;p&gt;For regular development&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Priority queue&lt;/item&gt;
      &lt;item&gt;Usage analytics&lt;/item&gt;
      &lt;item&gt;Bug detection&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Pro&lt;/head&gt;
    &lt;p&gt;For power users&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Priority queue&lt;/item&gt;
      &lt;item&gt;Usage analytics&lt;/item&gt;
      &lt;item&gt;Bug detection&lt;/item&gt;
      &lt;item&gt;Early access to features&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Free&lt;/head&gt;
    &lt;p&gt;Perfect for trying it out&lt;/p&gt;
    &lt;head rend="h4"&gt;Detailed Comparison&lt;/head&gt;
    &lt;p&gt;Everything you get with each tier&lt;/p&gt;
    &lt;head rend="h2"&gt;Real Pass Rates, Not marketing&lt;/head&gt;
    &lt;p&gt;Every test is executed in a sandbox before it reaches your editor. We don't just generate code; we deliver verified functionality.&lt;/p&gt;
    &lt;p&gt;Pass Rate&lt;/p&gt;
    &lt;p&gt;Self-Healing GenerationFailures are automatically fixed by our AI validator before delivery.&lt;/p&gt;
    &lt;p&gt;Source Bug DetectionReal issues in your source code are triaged and clearly flagged.&lt;/p&gt;
    &lt;head rend="h3"&gt;How far your credits go&lt;/head&gt;
    &lt;p&gt;Estimated file generation per month based on complexity&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Complexity&lt;/cell&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Starter&lt;/cell&gt;
        &lt;cell role="head"&gt;Pro&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Small files (≤15 fn)Approx. 15 functions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~7&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~30&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~70&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Medium files (~30 fn)Approx. 30 functions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~3&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~15&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~35&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Large files (~50 fn)Approx. 50 functions&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~1&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~7&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;~17&lt;/p&gt;
          &lt;p&gt;files&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;1 credit = up to 15 functions. Larger files use proportionally more credits.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tests That Actually Test&lt;/head&gt;
    &lt;p&gt;We tested leading AI models on generating unit tests for complex e-commerce logic. KeelTest's agentic approach-combining AI with static code analysis, test validation, and actual execution-achieved a staff-level score of 8.5/10, outperforming pure zero-shot prompts by 54%.&lt;/p&gt;
    &lt;head rend="h3"&gt;Overall Quality ScoreStaff Engineer = 10&lt;/head&gt;
    &lt;head rend="h3"&gt;Detailed Evaluation Criteria&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Criteria&lt;/cell&gt;
        &lt;cell role="head"&gt;KeelTest&lt;/cell&gt;
        &lt;cell role="head"&gt;Model B&lt;/cell&gt;
        &lt;cell role="head"&gt;Model C&lt;/cell&gt;
        &lt;cell role="head"&gt;Model A&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Unit Test Isolation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Mocking &amp;amp; Dependency Injection&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Edge Case Coverage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Following Instructions&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Technical Correctness&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DateTime/Float Precision&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;"KeelTest demonstrates the deepest understanding of unit testing principles with proper isolation, comprehensive mocking, and dependency injection. It's what a staff engineer would produce."&lt;/p&gt;
    &lt;p&gt;* KeelTest leverages advanced AI models enhanced with static code analysis, automated test validation, and real-time execution feedback-not just raw prompts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://keelcode.dev/keeltest"/><published>2026-01-07T13:22:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526376</id><title>Everyone hates OneDrive, Microsofts cloud app that steals and deletes files</title><updated>2026-01-07T15:13:59.474466+00:00</updated><content/><link href="https://boingboing.net/2026/01/05/everyone-hates-onedrive-microsofts-cloud-app-that-steals-then-deletes-all-your-files.html"/><published>2026-01-07T13:54:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46526933</id><title>LaTeX Coffee Stains [pdf]</title><updated>2026-01-07T15:13:58.883796+00:00</updated><content/><link href="https://ctan.math.illinois.edu/graphics/pgf/contrib/coffeestains/coffeestains-en.pdf"/><published>2026-01-07T14:46:31+00:00</published></entry></feed>