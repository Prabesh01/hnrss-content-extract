<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-26T18:13:33.008295+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46045085</id><title>Trillions spent and big software projects are still failing</title><updated>2025-11-26T18:13:42.159510+00:00</updated><content>&lt;doc fingerprint="e94c521a6b7707dc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;“Why worry about something that isn’t going to happen?”&lt;/p&gt;
      &lt;p&gt;KGB Chairman Charkov’s question to inorganic chemist Valery Legasov in HBO’s “Chernobyl” miniseries makes a good epitaph for the hundreds of software development, modernization, and operational failures I have covered for IEEE Spectrum since my first contribution, to its September 2005 special issue on learning—or rather, not learning—from software failures. I noted then, and it’s still true two decades later: Software failures are universally unbiased. They happen in every country, to large companies and small. They happen in commercial, nonprofit, and governmental organizations, regardless of status or reputation.&lt;/p&gt;
      &lt;p&gt;Global IT spending has more than tripled in constant 2025 dollars since 2005, from US $1.7 trillion to $5.6 trillion, and continues to rise. Despite additional spending, software success rates have not markedly improved in the past two decades. The result is that the business and societal costs of failure continue to grow as software proliferates, permeating and interconnecting every aspect of our lives.&lt;/p&gt;
      &lt;p&gt;For those hoping AI software tools and coding copilots will quickly make large-scale IT software projects successful, forget about it. For the foreseeable future, there are hard limits on what AI can bring to the table in controlling and managing the myriad intersections and trade-offs among systems engineering, project, financial, and business management, and especially the organizational politics involved in any large-scale software project. Few IT projects are displays of rational decision-making from which AI can or should learn. As software practitioners know, IT projects suffer from enough management hallucinations and delusions without AI adding to them.&lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt;As I noted 20 years ago, the drivers of software failure frequently are failures of human imagination, unrealistic or unarticulated project goals, the inability to handle the project’s complexity, or unmanaged risks, to name a few that today still regularly cause IT failures. Numerous others go back decades, such as those identified by Stephen Andriole, the chair of business technology at Villanova University’s School of Business, in the diagram below first published in Forbes in 2021. Uncovering a software system failure that has gone off the rails in a unique, previously undocumented manner would be surprising because the overwhelming majority of software-related failures involve avoidable, known failure-inducing factors documented in hundreds of after-action reports, academic studies, and technical and management books for decades. Failure déjà vu dominates the literature.&lt;/p&gt;
        &lt;p&gt;The question is, why haven’t we applied what we have repeatedly been forced to learn?&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;Steve Andriole&lt;/div&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;The Phoenix That Never Rose&lt;/head&gt;
        &lt;p&gt;Many of the IT developments and operational failures I have analyzed over the last 20 years have each had their own Chernobyl-like meltdowns, spreading reputational radiation everywhere and contaminating the lives of those affected for years. Each typically has a story that strains belief. A prime example is the Canadian government’s CA $310 million Phoenix payroll system, which went live in April 2016 and soon after went supercritical.&lt;/p&gt;
        &lt;p&gt;Phoenix project executives believed they could deliver a modernized payment system, customizing PeopleSoft’s off-the-shelf payroll package to follow 80,000 pay rules spanning 105 collective agreements with federal public-service unions. It also was attempting to implement 34 human-resource system interfaces across 101 government agencies and departments required for sharing employee data. Further, the government’s developer team thought they could accomplish this for less than 60 percent of the vendor’s proposed budget. They’d save by removing or deferring critical payroll functions, reducing system and integration testing, decreasing the number of contractors and government staff working on the project, and forgoing vital pilot testing, along with a host of other overly optimistic proposals.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Phoenix’s payroll meltdown was preordained. As a result, over the past nine years, around 70 percent of the 430,000 current and former Canadian federal government employees paid through Phoenix have endured paycheck errors. Even as recently as fiscal year 2023–2024, a third of all employees experienced paycheck mistakes. The ongoing financial stress and anxieties for thousands of employees and their families have been immeasurable. Not only are recurring paycheck troubles sapping worker morale, but in at least one documented case, a coroner blamed an employee’s suicide on the unbearable financial and emotional strain she suffered.&lt;/p&gt;
        &lt;p&gt;By the end of March 2025, when the Canadian government had promised that the backlog of Phoenix errors would finally be cleared, over 349,000 were still unresolved, with 53 percent pending for more than a year. In June, the Canadian government once again committed to significantly reducing the backlog, this time by June 2026. Given previous promises, skepticism is warranted.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The question is, why haven’t we applied what we have repeatedly been forced to learn?&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;What percentage of software projects fail, and what failure means, has been an ongoing debate within the IT community stretching back decades. Without diving into the debate, it’s clear that software development remains one of the riskiest technological endeavors to undertake. Indeed, according to Bent Flyvbjerg, professor emeritus at the University of Oxford’s Saїd Business School, comprehensive data shows that not only are IT projects risky, they are the riskiest from a cost perspective.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The CISQ report estimates that organizations in the United States spend more than $520 billion annually supporting legacy software systems, with 70 to 75 percent of organizational IT budgets devoted to legacy maintenance. A 2024 report by services company NTT DATA found that 80 percent of organizations concede that “inadequate or outdated technology is holding back organizational progress and innovation efforts.” Furthermore, the report says that virtually all C-level executives believe legacy infrastructure thwarts their ability to respond to the market. Even so, given that the cost of replacing legacy systems is typically many multiples of the cost of supporting them, business executives hesitate to replace them until it is no longer operationally feasible or cost-effective. The other reason is a well-founded fear that replacing them will turn into a debacle like Phoenix or others.&lt;/p&gt;
        &lt;p&gt;Nevertheless, there have been ongoing attempts to improve software development and sustainment processes. For example, we have seen increasing adoption of iterative and incremental strategies to develop and sustain software systems through Agile approaches, DevOps methods, and other related practices.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The goal is to deliver usable, dependable, and affordable software to end users in the shortest feasible time. DevOps strives to accomplish this continuously throughout the entire software life cycle. While Agile and DevOps have proved successful for many organizations, they also have their share of controversy and pushback. Provocative reports claim Agile projects have a failure rate of up to 65 percent, while others claim up to 90 percent of DevOps initiatives fail to meet organizational expectations.&lt;/p&gt;
        &lt;p&gt;It is best to be wary of these claims while also acknowledging that successfully implementing Agile or DevOps methods takes consistent leadership, organizational discipline, patience, investment in training, and culture change. However, the same requirements have always been true when introducing any new software platform. Given the historic lack of organizational resolve to instill proven practices, it is not surprising that novel approaches for developing and sustaining ever more complex software systems, no matter how effective they may be, will also frequently fall short.&lt;/p&gt;
        &lt;head rend="h2"&gt;Persisting in Foolish Errors&lt;/head&gt;
        &lt;p&gt;The frustrating and perpetual question is why basic IT project-management and governance mistakes during software development and operations continue to occur so often, given the near-total societal reliance on reliable software and an extensively documented history of failures to learn from? Next to electrical infrastructure, with which IT is increasingly merging into a mutually codependent relationship, the failure of our computing systems is an existential threat to modern society.&lt;/p&gt;
        &lt;p&gt;Frustratingly, the IT community stubbornly fails to learn from prior failures. IT project managers routinely claim that their project is somehow different or unique and, thus, lessons from previous failures are irrelevant. That is the excuse of the arrogant, though usually not the ignorant. In Phoenix’s case, for example, it was the government’s second payroll-system replacement attempt, the first effort ending in failure in 1995. Phoenix project managers ignored the well-documented reasons for the first failure because they claimed its lessons were not applicable, which did nothing to keep the managers from repeating them. As it’s been said, we learn more from failure than from success, but repeated failures are damn expensive.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Not all software development failures are bad; some failures are even desired. When pushing the limits of developing new types of software products, technologies, or practices, as is happening with AI-related efforts, potential failure is an accepted possibility. With failure, experience increases, new insights are gained, fixes are made, constraints are better understood, and technological innovation and progress continue. However, most IT failures today are not related to pushing the innovative frontiers of the computing art, but the edges of the mundane. They do not represent Austrian economist Joseph Schumpeter’s “gales of creative destruction.” They’re more like gales of financial destruction. Just how many more enterprise resource planning (ERP) project failures are needed before success becomes routine? Such failures should be called IT blunders, as learning anything new from them is dubious at best.&lt;/p&gt;
        &lt;p&gt;Was Phoenix a failure or a blunder? I argue strongly for the latter, but at the very least, Phoenix serves as a master class in IT project mismanagement. The question is whether the Canadian government learned from this experience any more than it did from 1995’s payroll-project fiasco? The government maintains it will learn, which might be true, given the Phoenix failure’s high political profile. But will Phoenix’s lessons extend to the thousands of outdated Canadian government IT systems needing replacement or modernization? Hopefully, but hope is not a methodology, and purposeful action will be necessary.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;The IT community has striven mightily for decades to make the incomprehensible routine. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Repeatedly making the same mistakes and expecting a different result is not learning. It is a farcical absurdity. Paraphrasing Henry Petroski in his book To Engineer Is Human: The Role of Failure in Successful Design (Vintage, 1992), we may have learned how to calculate the software failure due to risk, but we have not learned how to calculate to eliminate the failure of the mind. There are a plethora of examples of projects like Phoenix that failed in part due to bumbling management, yet it is extremely difficult to find software projects managed professionally that still failed. Finding examples of what could be termed “IT heroic failures” is like Diogenes seeking one honest man.&lt;/p&gt;
        &lt;p&gt;The consequences of not learning from blunders will be much greater and more insidious as society grapples with the growing effects of artificial intelligence, or more accurately, “intelligent” algorithms embedded into software systems. Hints of what might happen if past lessons go unheeded are found in the spectacular early automated decision-making failure of Michigan’s MiDAS unemployment and Australia’s Centrelink “Robodebt” welfare systems. Both used questionable algorithms to identify deceptive payment claims without human oversight. State officials used MiDAS to accuse tens of thousands of Michiganders of unemployment fraud, while Centrelink officials falsely accused hundreds of thousands of Australians of being welfare cheats. Untold numbers of lives will never be the same because of what occurred. Government officials in Michigan and Australia placed far too much trust in those algorithms. They had to be dragged, kicking and screaming, to acknowledge that something was amiss, even after it was clearly demonstrated that the software was untrustworthy. Even then, officials tried to downplay the errors’ impact on people, then fought against paying compensation to those adversely affected by the errors. While such behavior is legally termed “maladministration,” administrative evil is closer to reality.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;So, we are left with only a professional and personal obligation to reemphasize the obvious: Ask what you do know, what you should know, and how big the gap is between them before embarking on creating an IT system. If no one else has ever successfully built your system with the schedule, budget, and functionality you asked for, please explain why your organization thinks it can. Software is inherently fragile; building complex, secure, and resilient software systems is difficult, detailed, and time-consuming. Small errors have outsize effects, each with an almost infinite number of ways they can manifest, from causing a minor functional error to a system outage to allowing a cybersecurity threat to penetrate the system. The more complex and interconnected the system, the more opportunities for errors and their exploitation. A nice start would be for senior management who control the purse strings to finally treat software and systems development, operations, and sustainment efforts with the respect they deserve. This not only means providing the personnel, financial resources, and leadership support and commitment, but also the professional and personal accountability they demand.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;It is well known that honesty, skepticism, and ethics are essential to achieving project success, yet they are often absent. Only senior management can demand they exist. For instance, honesty begins with the forthright accounting of the myriad of risks involved in any IT endeavor, not their rationalization. It is a common “secret” that it is far easier to get funding to fix a troubled software development effort than to ask for what is required up front to address the risks involved. Vendor puffery may also be legal, but that means the IT customer needs a healthy skepticism of the typically too-good-to-be-true promises vendors make. Once the contract is signed, it is too late. Furthermore, computing’s malleability, complexity, speed, low cost, and ability to reproduce and store information combine to create ethical situations that require deep reflection about computing’s consequences on individuals and society. Alas, ethical considerations have routinely lagged when technological progress and profits are to be made. This practice must change, especially as AI is routinely injected into automated systems.&lt;/p&gt;
        &lt;p&gt;In the AI community, there has been a movement toward the idea of human-centered AI, meaning AI systems that prioritize human needs, values, and well-being. This means trying to anticipate where and when AI can go wrong, move to eliminate these situations, and build in ways to mitigate the effects if they do happen. This concept requires application to every IT system’s effort, not just AI.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Given the historic lack of organizational resolve to instill proven practices...novel approaches for developing and sustaining ever more complex software systems...will also frequently fall short.&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt;Finally, project cost-benefit justifications of software developments rarely consider the financial and emotional distress placed on end users of IT systems when something goes wrong. These include the long-term failure after-effects. If these costs had to be taken fully into account, such as in the cases of Phoenix, MiDAS, and Centrelink, perhaps there could be more realism in what is required managerially, financially, technologically, and experientially to create a successful software system. It may be a forlorn request, but surely it is time the IT community stops repeatedly making the same ridiculous mistakes it has made since at least 1968, when the term “software crisis” was coined. Make new ones, damn it. As Roman orator Cicero said in Philippic 12, “Anyone can make a mistake, but only an idiot persists in his error.”&lt;/p&gt;
      &lt;p&gt;Special thanks to Steve Andriole, Hal Berghel, Matt Eisler, John L. King, Roger Van Scoy, and Lee Vinsel for their invaluable critiques and insights.&lt;/p&gt;
      &lt;p&gt;This article appears in the December 2025 print issue as “The Trillion-Dollar Cost of IT’s Willful Ignorance.”&lt;/p&gt;
      &lt;div&gt;
        &lt;p&gt;From Your Site Articles&lt;/p&gt;
        &lt;p&gt;Related Articles Around the Web&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spectrum.ieee.org/it-management-software-failures"/><published>2025-11-25T12:14:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46045987</id><title>Launch HN: Onyx (YC W24) – Open-source chat UI</title><updated>2025-11-26T18:13:41.753652+00:00</updated><content>&lt;doc fingerprint="374119d99fbe8bf8"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, Chris and Yuhong here from Onyx (&lt;/p&gt;https://github.com/onyx-dot-app/onyx&lt;p&gt;). We’re building an open-source chat that works with any LLM (proprietary + open weight) &lt;/p&gt;and&lt;p&gt; gives these LLMs the tools they need to be useful (RAG, web search, MCP, deep research, memory, etc.).&lt;/p&gt;&lt;p&gt;Demo: https://youtu.be/2g4BxTZ9ztg&lt;/p&gt;&lt;p&gt;Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company's data, lacked customization, and frankly didn't work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.&lt;/p&gt;&lt;p&gt;As the project grew, we started seeing an interesting trend—even though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We’d hear, “the connectors, indexing, and search are great, but I’m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them”.&lt;/p&gt;&lt;p&gt;Many users would add RAG, agents, and custom tools later, but much of the usage stayed ‘basic chat’. We thought: “why would people co-opt an enterprise search when other AI chat solutions exist?”&lt;/p&gt;&lt;p&gt;As we continued talking to users, we realized two key points:&lt;/p&gt;&lt;p&gt;(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI&lt;/p&gt;&lt;p&gt;(2) providing this well is much harder than you might think and the bar is incredibly high&lt;/p&gt;&lt;p&gt;Consumer products like ChatGPT and Claude already provide a great experience—and chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from “this works” to “this feels magical” is not easy, and nothing else in the space has managed to do it.&lt;/p&gt;&lt;p&gt;So ~3 months ago we pivoted to Onyx, the open-source chat UI with:&lt;/p&gt;&lt;p&gt;- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who’s using AI tools for the first time.&lt;/p&gt;&lt;p&gt;- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.&lt;/p&gt;&lt;p&gt;- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.&lt;/p&gt;&lt;p&gt;Through building features like deep research and code interpreter that work across model providers, we've learned a ton of non-obvious things about engineering LLMs that have been key to making Onyx work. I'd like to share two that were particularly interesting (happy to discuss more in the comments).&lt;/p&gt;&lt;p&gt;First, context management is one of the most difficult and important things to get right. We’ve found that LLMs really struggle to remember both system prompts and previous user messages in long conversations. Even simple instructions like “ignore sources of type X” in the system prompt are very often ignored. This is exacerbated by multiple tool calls, which can often feed in huge amounts of context. We solved this problem with a “Reminder” prompt—a short 1-3 sentence blurb injected at the end of the user message that describes the non-negotiables that the LLM must abide by. Empirically, LLMs attend most to the very end of the context window, so this placement gives the highest likelihood of adherence.&lt;/p&gt;&lt;p&gt;Second, we’ve needed to build an understanding of the “natural tendencies” of certain models when using tools, and build around them. For example, the GPT family of models are fine-tuned to use a python code interpreter that operates in a Jupyter notebook. Even if told explicitly, it refuses to add `print()` around the last line, since, in Jupyter, this last line is automatically written to stdout. Other models don’t have this strong preference, so we’ve had to design our model-agnostic code interpreter to also automatically `print()` the last bare line.&lt;/p&gt;&lt;p&gt;So far, we’ve had a Fortune 100 team fork Onyx and provide 10k+ employees access to every model within a single interface, and create thousands of use-case specific Assistants for every department, each using the best model for the job. We’ve seen teams operating in sensitive industries completely airgap Onyx w/ locally hosted LLMs to provide a copilot that wouldn’t have been possible otherwise.&lt;/p&gt;&lt;p&gt;If you’d like to try Onyx out, follow https://docs.onyx.app/deployment/getting_started/quickstart to get set up locally w/ Docker in &amp;lt;15 minutes. For our Cloud: https://www.onyx.app/. If there’s anything you'd like to see to make it a no-brainer to replace your ChatGPT Enterprise/Claude Enterprise subscription, we’d love to hear it!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46045987"/><published>2025-11-25T14:20:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46048252</id><title>Show HN: We built an open source, zero webhooks payment processor</title><updated>2025-11-26T18:13:41.042466+00:00</updated><content>&lt;doc fingerprint="f056b3782f0b3458"&gt;
  &lt;main&gt;
    &lt;p&gt; The easiest way to make internet money. &lt;lb/&gt; Get Started &lt;lb/&gt; · Quickstart · Website · Issues · Discord &lt;/p&gt;
    &lt;p&gt;Infinite pricing models, one source of truth, zero webhooks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Default Stateless Say goodbye to webhooks, &lt;code&gt;"subscriptions"&lt;/code&gt;db tables,&lt;code&gt;customer_id&lt;/code&gt;columns,&lt;code&gt;PRICE_ID&lt;/code&gt;env variables, or manually mapping your plans to prices to features and back.&lt;/item&gt;
      &lt;item&gt;Single Source of Truth: Read your latest customer billing state from Flowglad, including feature access and usage meter credits&lt;/item&gt;
      &lt;item&gt;Access Data Using Your Ids: Query customer state by your auth's user ids. Refer to prices, features, and usage meters via slugs you define.&lt;/item&gt;
      &lt;item&gt;Full-Stack SDK: Access your customer's data on the backend using &lt;code&gt;flowgladServer.getBilling()&lt;/code&gt;, or in your React frontend using our&lt;code&gt;useBilling()&lt;/code&gt;hook&lt;/item&gt;
      &lt;item&gt;Adaptable: Iterate on new pricing models in testmode, and push them to prod in a click. Seamlessly rotate pricing models in your app without any redeployment.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;First, install the packages necessary Flowglad packages based on your project setup:&lt;/p&gt;
    &lt;code&gt;# Next.js Projects
bun add @flowglad/nextjs

# React + Express projects:
bun add @flowglad/react @flowglad/express

# All other React + Node Projects
bun add @flowglad/react @flowglad/server&lt;/code&gt;
    &lt;p&gt;Flowglad integrates seamlessly with your authentication system and requires only a few lines of code to get started in your Next.js app. Setup typically takes under a minute:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Configure Your Flowglad Server Client&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create a utility to generate your Flowglad server instance. Pass your own customer/user/organization IDs—Flowglad never requires its own customer IDs to be managed in your app:&lt;/p&gt;
    &lt;code&gt;// utils/flowglad.ts
import { FlowgladServer } from '@flowglad/nextjs/server'

export const flowglad = (customerExternalId: string) =&amp;gt; {
  return new FlowgladServer({
    customerExternalId,
    getCustomerDetails: async (externalId) =&amp;gt; {
      // e.g. Fetch user info from your DB using your user/org/team ID
      const user = await db.users.findOne({ id: externalId })
      if (!user) throw new Error('User not found')
      return { email: user.email, name: user.name }
    },
  })
}&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Expose the Flowglad API Handler&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Add an API route so the Flowglad client can communicate securely with your backend:&lt;/p&gt;
    &lt;code&gt;// app/api/flowglad/[...path]/route.ts
import { nextRouteHandler } from '@flowglad/nextjs/server'
import { flowglad } from '@/utils/flowglad'

export const { GET, POST } = nextRouteHandler({
  flowglad,
  getCustomerExternalId: async (req) =&amp;gt; {
    // Extract your user/org/team ID from session/auth.
    // For B2C: return user.id from your DB
    // For B2B: return organization.id or team.id
    const userId = await getUserIdFromRequest(req)
    if (!userId) throw new Error('User not authenticated')
    return userId
  },
})&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Wrap Your App with the Provider&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In your root layout (App Router) or _app (Pages Router):&lt;/p&gt;
    &lt;code&gt;import { FlowgladProvider } from '@flowglad/nextjs'

// App Router example (app/layout.tsx)
export default function RootLayout({ children }) {
  return (
    &amp;lt;html&amp;gt;
      &amp;lt;body&amp;gt;
        &amp;lt;FlowgladProvider loadBilling={true}&amp;gt;
          {children}
        &amp;lt;/FlowgladProvider&amp;gt;
      &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
  )
}&lt;/code&gt;
    &lt;p&gt;That’s it—Flowglad will use your app’s internal user IDs for all billing logic and integrate billing status into your frontend in real time.&lt;/p&gt;
    &lt;p&gt;B2C apps: Use &lt;code&gt;user.id&lt;/code&gt; as the customer ID.&lt;lb/&gt; B2B apps: Use &lt;code&gt;organization.id&lt;/code&gt; or &lt;code&gt;team.id&lt;/code&gt; as the customer ID.&lt;/p&gt;
    &lt;p&gt;Flowglad does not require you to change your authentication system or manage Flowglad customer IDs. Just pass your own!&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use &lt;code&gt;useBilling&lt;/code&gt;on your frontend, and&lt;code&gt;flowglad(userId).getBilling()&lt;/code&gt;on your backend&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;'use client'

import { useBilling } from '@flowglad/nextjs'

export function FeatureGate({ featureSlug, children }) {
  const { loaded, errors, checkFeatureAccess } = useBilling()

  if (!loaded || !checkFeatureAccess) {
    return &amp;lt;p&amp;gt;Loading billing state…&amp;lt;/p&amp;gt;
  }

  if (errors?.length) {
    return &amp;lt;p&amp;gt;Unable to load billing data right now.&amp;lt;/p&amp;gt;
  }

  return checkFeatureAccess(featureSlug)
    ? children
    : &amp;lt;p&amp;gt;You need to upgrade to unlock this feature.&amp;lt;/p&amp;gt;
}&lt;/code&gt;
    &lt;code&gt;import { useBilling } from '@flowglad/nextjs'

export function UsageBalanceIndicator({ usageMeterSlug }) {
  const { loaded, errors, checkUsageBalance, createCheckoutSession } = useBilling()

  if (!loaded || !checkUsageBalance) {
    return &amp;lt;p&amp;gt;Loading usage…&amp;lt;/p&amp;gt;
  }

  const usage = checkUsageBalance(usageMeterSlug)

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;h3&amp;gt;Usage Balance&amp;lt;/h3&amp;gt;
      &amp;lt;p&amp;gt;
        Remaining:{' '}
        {usage ? `${usage.availableBalance} credits available` : &amp;lt;button onClick={() =&amp;gt; createCheckoutSession({ 
            priceSlug: 'pro_plan',
            autoRedirect: true
          })}
        /&amp;gt;}
      &amp;lt;/p&amp;gt;
    &amp;lt;/div&amp;gt;
  )
}&lt;/code&gt;
    &lt;code&gt;import { NextResponse } from 'next/server'
import { flowglad } from '@/utils/flowglad'

const hasFastGenerations = async () =&amp;gt; {
  // ...
  const user = await getUser()

  const billing = await flowglad(user.id).getBilling()
  const hasAccess = billing.checkFeatureAccess('fast_generations')
  if (hasAccess) {
    // run fast generations
  } else {
    // fall back to normal generations
  }
}&lt;/code&gt;
    &lt;code&gt;import { flowglad } from '@/utils/flowglad'

const processChatMessage = async (params: { chat: string }) =&amp;gt; {
  // Extract your app's user/org/team ID,
  // whichever corresponds to your customer
  const user = await getUser()

  const billing = await flowglad(user.id).getBilling()
  const usage = billing.checkUsageBalance('chat_messages')
  if (usage.availableBalance &amp;gt; 0) {
    // run chat request
  } else {
    throw Error(`User ${user.id} does not have sufficient usage credits`)
  }
}&lt;/code&gt;
    &lt;p&gt;First, set up a pricing model. You can do so in the dashboard in just a few clicks using a template, that you can then customize to suit your specific needs.&lt;/p&gt;
    &lt;p&gt;We currently have templates for the following pricing models:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Usage-limit + Subscription Hybrid (like Cursor)&lt;/item&gt;
      &lt;item&gt;Unlimited Usage (like ChatGPT consumer)&lt;/item&gt;
      &lt;item&gt;Tiered Access and Usage Credits (like Midjourney)&lt;/item&gt;
      &lt;item&gt;Feature-Gated Subscription (like Linear)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And more on the way. If you don't see a pricing model from our templates that suits you, you can always make one from scratch.&lt;/p&gt;
    &lt;p&gt;In the last 15 years, the market has given developers more options than ever for every single part of their stack. But when it comes to payments, there have been virtually zero new entrants. The existing options are slim, and almost all of them require us to talk to sales to even set up an account. When it comes to self-serve payments, there are even fewer options.&lt;/p&gt;
    &lt;p&gt;The result? The developer experience and cost of payments has barely improved in that time. Best in class DX in payments feels eerily suspended in 2015. Meanwhile, we've enjoyed constant improvements in auth, compute, hosting, and practically everything else.&lt;/p&gt;
    &lt;p&gt;Flowglad wants to change that.&lt;/p&gt;
    &lt;p&gt;We're building a payments layer that lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Think about billing and payments as little as possible&lt;/item&gt;
      &lt;item&gt;Spend as little time on integration and maintenance as possible&lt;/item&gt;
      &lt;item&gt;Get as much out of your single integration as possible&lt;/item&gt;
      &lt;item&gt;Unlock more payment providers from a single integration&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Achieving this mission will take time. It will be hard. It might even make some people unhappy. But with AI bringing more and more developers on line and exploding the complexity of startup billing, the need is more urgent than ever.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/flowglad/flowglad"/><published>2025-11-25T17:33:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46049932</id><title>A new bridge links the math of infinity to computer science</title><updated>2025-11-26T18:13:40.861040+00:00</updated><content>&lt;doc fingerprint="b72c931205918bb9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A New Bridge Links the Strange Math of Infinity to Computer Science&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;All of modern mathematics is built on the foundation of set theory, the study of how to organize abstract collections of objects. But in general, research mathematicians don’t need to think about it when they’re solving their problems. They can take it for granted that sets behave the way they’d expect, and carry on with their work.&lt;/p&gt;
    &lt;p&gt;Descriptive set theorists are an exception. This small community of mathematicians never stopped studying the fundamental nature of sets — particularly the strange infinite ones that other mathematicians ignore.&lt;/p&gt;
    &lt;p&gt;Their field just got a lot less lonely. In 2023, a mathematician named Anton Bernshteyn published a deep and surprising connection between the remote mathematical frontier of descriptive set theory and modern computer science.&lt;/p&gt;
    &lt;p&gt;He showed that all problems about certain kinds of infinite sets can be rewritten as problems about how networks of computers communicate. The bridge connecting the disciplines surprised researchers on both sides. Set theorists use the language of logic, computer scientists the language of algorithms. Set theory deals with the infinite, computer science with the finite. There’s no reason why their problems should be related, much less equivalent.&lt;/p&gt;
    &lt;p&gt;“This is something really weird,” said Václav Rozhoň, a computer scientist at Charles University in Prague. “Like, you are not supposed to have this.”&lt;/p&gt;
    &lt;p&gt;Since Bernshteyn’s result, his peers have been exploring how to move back and forth across the bridge to prove new theorems on either side, and how to extend that bridge to new classes of problems. Some descriptive set theorists are even starting to apply insights from the computer science side to reorganize the landscape of their entire field, and to rethink the way they understand infinity.&lt;/p&gt;
    &lt;p&gt;“This whole time we’ve been working on very similar problems without directly talking to each other,” said Clinton Conley, a descriptive set theorist at Carnegie Mellon University. “It just opens the doors to all these new collaborations.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Broken Sets&lt;/head&gt;
    &lt;p&gt;Bernshteyn was an undergraduate when he first heard of descriptive set theory — as an example of a field that had once mattered, then decayed to nothing. More than a year would pass before he found out the professor had been wrong.&lt;/p&gt;
    &lt;p&gt;In 2014, as a first-year graduate student at the University of Illinois, Bernshteyn took a logic course with Anush Tserunyan, who would later become one of his advisers. She corrected the misconception. “She should take all the credit for me being in this field,” he said. “She really made it seem that logic and set theory is this glue that connects all different parts of math.”&lt;/p&gt;
    &lt;p&gt;Descriptive set theory dates back to Georg Cantor, who proved in 1874 that there are different sizes of infinity. The set of whole numbers (0, 1, 2, 3, …), for instance, is the same size as the set of all fractions, but smaller than the set of all real numbers.&lt;/p&gt;
    &lt;p&gt;At the time, mathematicians were deeply uncomfortable with this menagerie of different infinities. “It’s hard to wrap your head around,” said Bernshteyn, who is now at the University of California, Los Angeles.&lt;/p&gt;
    &lt;p&gt;Partly in response to that discomfort, mathematicians developed a different notion of size — one that described, say, how much length or area or volume a set might occupy, rather than the number of elements it contained. This notion of size is known as a set’s “measure” (in contrast to Cantor’s notion of size, which is a set’s “cardinality”). One of the simplest types of measure — the Lebesgue measure — quantifies a set’s length. While the set of real numbers between zero and 1 and the set of real numbers between zero and 10 are both infinite and have the same cardinality, the first has a Lebesgue measure of 1 and the second a Lebesgue measure of 10.&lt;/p&gt;
    &lt;p&gt;To study more complicated sets, mathematicians use other types of measures. The uglier a set is, the fewer ways there are to measure it. Descriptive set theorists ask questions about which sets can be measured according to different definitions of “measure.” They then arrange them in a hierarchy based on the answers to those questions. At the top are sets that can be constructed easily and studied using any notion of measure you want. At the bottom are “unmeasurable” sets, which are so complicated they can’t be measured at all. “The word people often use is ‘pathological,’” Bernshteyn said. “Nonmeasurable sets are really bad. They’re counterintuitive, and they don’t behave well.”&lt;/p&gt;
    &lt;p&gt;This hierarchy doesn’t just help set theorists map out the landscape of their field; it also gives them insights into what tools they can use to tackle more typical problems in other areas of math. Mathematicians in some fields, such as dynamical systems, group theory and probability theory, need information about the size of the sets they’re using. A set’s position in the hierarchy determines what tools they can use to solve their problem.&lt;/p&gt;
    &lt;p&gt;Descriptive set theorists are thus like librarians, tending to a massive bookshelf of different kinds of infinite sets (and the different ways of measuring them). Their job is to take a problem, determine how complicated a set its solution requires, and place it on the proper shelf, so that other mathematicians can take note.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making a Choice&lt;/head&gt;
    &lt;p&gt;Bernshteyn belongs to a group of librarians who sort problems about infinite sets of nodes connected by edges, called graphs. In particular, he studies graphs that have infinitely many separate pieces, each containing infinitely many nodes. Most graph theorists don’t study these kinds of graphs; they focus on finite ones instead. But such infinite graphs can represent and provide information about dynamical systems and other important kinds of sets, making them a major area of interest for descriptive set theorists.&lt;/p&gt;
    &lt;p&gt;Here’s an example of the kind of infinite graph that Bernshteyn and his colleagues might study. Start with a circle, which contains infinitely many points. Pick one point: This will be your first node. Then move a fixed distance around the circle’s circumference. This gives you a second node. For example, you might move one-fifth of the way around the circle. Connect the two nodes with an edge. Move the same distance to a third node, and connect it to the previous one. And so on.&lt;/p&gt;
    &lt;p&gt;If you move one-fifth of the way around the circle each time, it’ll take five steps to get back where you started. In general, if you move any distance that can be written as a fraction, the nodes will form a closed loop. But if the distance can’t be written as a fraction, the process will go on forever. You’ll get an infinite number of connected nodes.&lt;/p&gt;
    &lt;p&gt;But that’s not all: This infinitely long sequence forms only the first piece of your graph. Even though it contains infinitely many nodes, it doesn’t contain all the points on the circle. To generate the other pieces of the graph, start at one of those other points. Now move the same distance at each step as you did in the first piece. You’ll end up building a second infinite sequence of connected nodes, totally disconnected from the first.&lt;/p&gt;
    &lt;p&gt;Do this for every possible new starting point on the circle. You’ll get a graph consisting of infinitely many separate pieces, with each piece made of an infinite number of nodes.&lt;/p&gt;
    &lt;p&gt;Mathematicians can then ask whether it’s possible to color the nodes in this graph so that they obey certain rules. Using just two colors, for instance, can you color every node in the graph so that no two connected nodes are the same color? The solution might seem straightforward. Look at the first piece of your graph, pick a node, and color it blue. Then color the rest of the piece’s nodes in an alternating pattern: yellow, blue, yellow, blue. Do the same for every piece in your graph: Pick a node, color it blue, then alternate colors. Ultimately, you’ll use just two colors to achieve your task.&lt;/p&gt;
    &lt;p&gt;But to accomplish this coloring, you had to rely on a hidden assumption that set theorists call the axiom of choice. It’s one of the nine fundamental building blocks from which all mathematical statements are constructed. According to this axiom, if you start with a bunch of sets, you can choose one item from each of those sets to create a new set — even if you have infinitely many sets to choose from. This axiom is useful, in that it allows mathematicians to prove all sorts of statements of interest. But it also leads to strange paradoxes. Descriptive set theorists avoid it.&lt;/p&gt;
    &lt;p&gt;Your graph had infinitely many pieces. This corresponds to having infinitely many sets. You chose one item from each set — the first point you decided to color blue in each of the pieces. All those blue points formed a new set. You used the axiom of choice.&lt;/p&gt;
    &lt;p&gt;Which leads to a problem when you color the rest of the nodes in alternating patterns of blue and yellow. You’ve colored each node (which has zero length) separately, without any understanding of how nodes relate to one another when they come from different pieces of the graph. This means that you can’t describe the set of all the graph’s blue nodes, or the set of all its yellow nodes, in terms of length either. In other words, these sets are unmeasurable. Mathematicians can’t say anything useful about them.&lt;/p&gt;
    &lt;p&gt;To descriptive set theorists, this is unsatisfying. And so they want to figure out a way to color the graph in a continuous way — a way that doesn’t use the axiom of choice, and that gives them measurable sets.&lt;/p&gt;
    &lt;p&gt;To do this, remember how you built the first piece of your graph: You picked a node on a circle and connected it to a second node some distance away. Now color the first node blue, the second yellow, and the entire arc between them blue. Similarly, color the arc between the second and third nodes yellow. Color the third arc blue. And so on.&lt;/p&gt;
    &lt;p&gt;Soon, you’ll have made it almost completely around the circle — meaning that you’ve assigned a color to all the nodes in your graph except for the ones that fall in a small, leftover segment. Say the last arc you colored was yellow. How do you color this final, smaller segment? You can’t use blue, because these nodes will connect to nodes in the original arc you colored blue. But you also can’t use yellow, because these nodes connect back to yellow ones from the previous arc.&lt;/p&gt;
    &lt;p&gt;You have to use a third color — say, green — to complete your coloring.&lt;/p&gt;
    &lt;p&gt;Still, the sets of blue, yellow and green nodes you end up with are all just pieces of the circle’s circumference, rather than the scatterings of points you ended up with when you used the axiom of choice. You can calculate the lengths of these sets. They’re measurable.&lt;/p&gt;
    &lt;p&gt;Descriptive set theorists therefore place the two-color version of the problem on the lowest shelf in their hierarchy (for unmeasurable sets), while the three-color problem goes on a much higher shelf of problems — ones where lots of notions of measure can be applied.&lt;/p&gt;
    &lt;p&gt;Bernshteyn spent his years in graduate school studying such coloring problems, shelving them one by one. Then, shortly after he finished his degree, he stumbled on a potential way to shelve them all at once — and to show that these problems have a much deeper and more mathematically relevant structure than anyone had realized.&lt;/p&gt;
    &lt;head rend="h2"&gt;Round by Round&lt;/head&gt;
    &lt;p&gt;From time to time, Bernshteyn enjoys going to computer science talks, where graphs are finite and represent networks of computers.&lt;/p&gt;
    &lt;p&gt;In 2019, one of those talks changed the course of his career. It was about “distributed algorithms” — sets of instructions that run simultaneously on multiple computers in a network to accomplish a task without a central coordinator.&lt;/p&gt;
    &lt;p&gt;Say you have a bunch of Wi-Fi routers in a building. Nearby routers can interfere with each other if they use the same communication frequency channel. So each router needs to choose a different channel from the ones used by its immediate neighbors.&lt;/p&gt;
    &lt;p&gt;Computer scientists can reframe this as a coloring problem on a graph: Represent each router as a node, and connect nearby ones with edges. Using just two colors (representing two different frequency channels), find a way to color each node so that no two connected nodes are the same color.&lt;/p&gt;
    &lt;p&gt;But there’s a catch: Nodes can only communicate with their immediate neighbors, using so-called local algorithms. First, each node runs the same algorithm and assigns itself a color. It then communicates with its neighbors to learn how other nodes are colored in a small region around it. Then it runs the algorithm again to decide whether to keep its color or switch it. It repeats this step until the whole network has a proper coloring.&lt;/p&gt;
    &lt;p&gt;Computer scientists want to know how many steps a given algorithm requires. For example, any local algorithm that can solve the router problem with only two colors must be incredibly inefficient, but it’s possible to find a very efficient local algorithm if you’re allowed to use three.&lt;/p&gt;
    &lt;p&gt;At the talk Bernshteyn was attending, the speaker discussed these thresholds for different kinds of problems. One of the thresholds, he realized, sounded a lot like a threshold that existed in the world of descriptive set theory — about the number of colors required to color certain infinite graphs in a measurable way.&lt;/p&gt;
    &lt;p&gt;To Bernshteyn, it felt like more than a coincidence. It wasn’t just that computer scientists are like librarians too, shelving problems based on how efficiently their algorithms work. It wasn’t just that these problems could also be written in terms of graphs and colorings.&lt;/p&gt;
    &lt;p&gt;Perhaps, he thought, the two bookshelves had more in common than that. Perhaps the connection between these two fields went much, much deeper.&lt;/p&gt;
    &lt;p&gt;Perhaps all the books, and their shelves, were identical, just written in different languages — and in need of a translator.&lt;/p&gt;
    &lt;head rend="h2"&gt;Opening the Door&lt;/head&gt;
    &lt;p&gt;Bernshteyn set out to make this connection explicit. He wanted to show that every efficient local algorithm can be turned into a Lebesgue-measurable way of coloring an infinite graph (that satisfies some additional important properties). That is, one of computer science’s most important shelves is equivalent to one of set theory’s most important shelves (high up in the hierarchy).&lt;/p&gt;
    &lt;p&gt;He began with the class of network problems from the computer science lecture, focusing on their overarching rule — that any given node’s algorithm uses information about just its local neighborhood, whether the graph has a thousand nodes or a billion.&lt;/p&gt;
    &lt;p&gt;To run properly, all the algorithm has to do is label each node in a given neighborhood with a unique number, so that it can log information about nearby nodes and give instructions about them. That’s easy enough to do in a finite graph: Just give every node in the graph a different number.&lt;/p&gt;
    &lt;p&gt;If Bernshteyn could run the same algorithm on an infinite graph, it meant he could color the graph in a measurable way — solving a graph-coloring question on the set theory side. But there was a problem: These infinite graphs are “uncountably” infinite. There’s no way to uniquely label all their nodes.&lt;/p&gt;
    &lt;p&gt;Bernshteyn’s challenge was to find a cleverer way to label the graphs.&lt;/p&gt;
    &lt;p&gt;He knew that he’d have to reuse labels. But that was fine so long as nearby nodes were labeled differently. Was there a way to assign labels without accidentally reusing one in the same neighborhood?&lt;/p&gt;
    &lt;p&gt;Bernshteyn showed that there is always a way — no matter how many labels you decide to use, and no matter how many nodes your local neighborhood has. This means that you can always safely extend the algorithm from the computer science side to the set theory side. “Any algorithm in our setup corresponds to a way of measurably coloring any graph in the descriptive set theory setup,” Rozhoň said.&lt;/p&gt;
    &lt;p&gt;The proof came as a surprise to mathematicians. It demonstrated a deep link between computation and definability, and between algorithms and measurable sets. Mathematicians are now exploring how to take advantage of Bernshteyn’s discovery. In a paper published this year, for instance, Rozhoň and his colleagues figured out that it’s possible to color special graphs called trees by looking at the same problem in the computer science context. The result also illuminated which tools mathematicians might use to study the trees’ corresponding dynamical systems. “This is a very interesting experience, trying to prove results in a field where I don’t understand even the basic definitions,” Rozhoň said.&lt;/p&gt;
    &lt;p&gt;Mathematicians have also been working to translate problems in the other direction. In one case, they used set theory to prove a new estimate of how hard a certain class of problems is to solve.&lt;/p&gt;
    &lt;p&gt;Bernshteyn’s bridge isn’t just about having a new tool kit for solving individual problems. It has also allowed set theorists to gain a clearer view of their field. There were lots of problems that they had no idea how to classify. In many cases, that’s now changed, because set theorists have computer scientists’ more organized bookshelves to guide them.&lt;/p&gt;
    &lt;p&gt;Bernshteyn hopes this growing area of research will change how the working mathematician views set theorists’ work — that they’ll no longer see it as remote and disconnected from the real mathematical world. “I’m trying to change this,” he said. “I want people to get used to thinking about infinity.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/a-new-bridge-links-the-strange-math-of-infinity-to-computer-science-20251121/"/><published>2025-11-25T19:53:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46051449</id><title>Show HN: KiDoom – Running DOOM on PCB Traces</title><updated>2025-11-26T18:13:40.604883+00:00</updated><content>&lt;doc fingerprint="562395acea28f504"&gt;
  &lt;main&gt;
    &lt;p&gt;3 ECUs Developed 10+ Years Exp. 28.5M+ Miles Driven Selected Projects Private Tools ×&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mikeayles.com/#kidoom"/><published>2025-11-25T22:13:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46052685</id><title>CS234: Reinforcement Learning Winter 2025</title><updated>2025-11-26T18:13:40.280666+00:00</updated><content>&lt;doc fingerprint="db6129c8929d1c49"&gt;
  &lt;main&gt;
    &lt;table&gt;
      &lt;row span="9"&gt;
        &lt;cell role="head"&gt;Monday&lt;/cell&gt;
        &lt;cell role="head"&gt;Tuesday&lt;/cell&gt;
        &lt;cell role="head"&gt;Wednesday&lt;/cell&gt;
        &lt;cell role="head"&gt;Thursday&lt;/cell&gt;
        &lt;cell role="head"&gt;Friday&lt;/cell&gt;
        &lt;cell role="head"&gt;Saturday&lt;/cell&gt;
        &lt;cell role="head"&gt;Sunday&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 1&lt;/cell&gt;
        &lt;cell&gt;Jan 6&lt;/cell&gt;
        &lt;cell&gt;Jan 7&lt;/cell&gt;
        &lt;cell&gt;Jan 8&lt;/cell&gt;
        &lt;cell&gt;Jan 9&lt;/cell&gt;
        &lt;cell&gt;Jan 10&lt;/cell&gt;
        &lt;cell&gt;Jan 11&lt;/cell&gt;
        &lt;cell&gt;Jan 12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Introduction to Reinforcement Learning &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Tabular MDP Planning &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;p&gt;[Assignment 1 Released]&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 2&lt;/cell&gt;
        &lt;cell&gt;Jan 13&lt;/cell&gt;
        &lt;cell&gt;Jan 14&lt;/cell&gt;
        &lt;cell&gt;Jan 15&lt;/cell&gt;
        &lt;cell&gt;Jan 16&lt;/cell&gt;
        &lt;cell&gt;Jan 17&lt;/cell&gt;
        &lt;cell&gt;Jan 18&lt;/cell&gt;
        &lt;cell&gt;Jan 19&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Policy Evaluation &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Q-Learning and Function Approximation &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Assignment 1 Due at 6pm&lt;p&gt;[Assignment 2 Released]&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 3&lt;/cell&gt;
        &lt;cell&gt;Jan 20&lt;/cell&gt;
        &lt;cell&gt;Jan 21&lt;/cell&gt;
        &lt;cell&gt;Jan 22&lt;/cell&gt;
        &lt;cell&gt;Jan 23&lt;/cell&gt;
        &lt;cell&gt;Jan 24&lt;/cell&gt;
        &lt;cell&gt;Jan 25&lt;/cell&gt;
        &lt;cell&gt;Jan 26&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Policy Search 1 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Policy Search 2 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 4&lt;/cell&gt;
        &lt;cell&gt;Jan 27&lt;/cell&gt;
        &lt;cell&gt;Jan 28&lt;/cell&gt;
        &lt;cell&gt;Jan 29&lt;/cell&gt;
        &lt;cell&gt;Jan 30&lt;/cell&gt;
        &lt;cell&gt;Jan 31&lt;/cell&gt;
        &lt;cell&gt;Feb 1&lt;/cell&gt;
        &lt;cell&gt;Feb 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt; Lecture Materials &lt;/cell&gt;
        &lt;cell&gt; Policy Search 3 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Offline RL 1 / Imitation learning &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Assignment 2 Due at 6pm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 5&lt;/cell&gt;
        &lt;cell&gt;Feb 3&lt;/cell&gt;
        &lt;cell&gt;Feb 4&lt;/cell&gt;
        &lt;cell&gt;Feb 5&lt;/cell&gt;
        &lt;cell&gt;Feb 6&lt;/cell&gt;
        &lt;cell&gt;Feb 7&lt;/cell&gt;
        &lt;cell&gt;Feb 8&lt;/cell&gt;
        &lt;cell&gt;Feb 9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Offline RL 2 / DPO &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Midterm (in class)&lt;/cell&gt;
        &lt;cell&gt;[Assignment 3 released]&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 6&lt;/cell&gt;
        &lt;cell&gt;Feb 10&lt;/cell&gt;
        &lt;cell&gt;Feb 11&lt;/cell&gt;
        &lt;cell&gt;Feb 12&lt;/cell&gt;
        &lt;cell&gt;Feb 13&lt;/cell&gt;
        &lt;cell&gt;Feb 14&lt;/cell&gt;
        &lt;cell&gt;Feb 15&lt;/cell&gt;
        &lt;cell&gt;Feb 16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Offline RL 3 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Exploration 1 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 7&lt;/cell&gt;
        &lt;cell&gt;Feb 17&lt;/cell&gt;
        &lt;cell&gt;Feb 18&lt;/cell&gt;
        &lt;cell&gt;Feb 19&lt;/cell&gt;
        &lt;cell&gt;Feb 20&lt;/cell&gt;
        &lt;cell&gt;Feb 21&lt;/cell&gt;
        &lt;cell&gt;Feb 22&lt;/cell&gt;
        &lt;cell&gt;Feb 23&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Exploration 2 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Exploration 3 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Assignment 3 Due at 6pm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 8&lt;/cell&gt;
        &lt;cell&gt;Feb 24&lt;/cell&gt;
        &lt;cell&gt;Feb 25&lt;/cell&gt;
        &lt;cell&gt;Feb 26&lt;/cell&gt;
        &lt;cell&gt;Feb 27&lt;/cell&gt;
        &lt;cell&gt;Feb 28&lt;/cell&gt;
        &lt;cell&gt;Mar 1&lt;/cell&gt;
        &lt;cell&gt;Mar 2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Exploration 4 &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;Guest lecture&lt;/cell&gt;
        &lt;cell&gt; Project Milestone &lt;p&gt;Due at 6pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 9&lt;/cell&gt;
        &lt;cell&gt;Mar 3&lt;/cell&gt;
        &lt;cell&gt;Mar 4&lt;/cell&gt;
        &lt;cell&gt;Mar 5&lt;/cell&gt;
        &lt;cell&gt;Mar 6&lt;/cell&gt;
        &lt;cell&gt;Mar 7&lt;/cell&gt;
        &lt;cell&gt;Mar 8&lt;/cell&gt;
        &lt;cell&gt;Mar 9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt; Monte Carlo Tree Search / AlphaGo &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt; Quiz (in class) &lt;p&gt;1:30pm-2:50pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 10&lt;/cell&gt;
        &lt;cell&gt;Mar 10&lt;/cell&gt;
        &lt;cell&gt;Mar 11&lt;/cell&gt;
        &lt;cell&gt;Mar 12&lt;/cell&gt;
        &lt;cell&gt;Mar 13&lt;/cell&gt;
        &lt;cell&gt;Mar 14&lt;/cell&gt;
        &lt;cell&gt;Mar 15&lt;/cell&gt;
        &lt;cell&gt;Mar 16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt;Guest Lecture and Wrap Up&lt;/cell&gt;
        &lt;cell&gt;Final Project Poster Session&lt;p&gt;1:30pm-4:30pm&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="9"&gt;
        &lt;cell&gt;Week 11&lt;/cell&gt;
        &lt;cell&gt;Mar 17&lt;/cell&gt;
        &lt;cell&gt;Mar 18&lt;/cell&gt;
        &lt;cell&gt;Mar 19&lt;/cell&gt;
        &lt;cell&gt;Mar 20&lt;/cell&gt;
        &lt;cell&gt;Mar 21&lt;/cell&gt;
        &lt;cell&gt;Mar 22&lt;/cell&gt;
        &lt;cell&gt;Mar 23&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Lecture Materials&lt;/cell&gt;
        &lt;cell&gt;Final Project Writeup Due at 6pm&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://web.stanford.edu/class/cs234/"/><published>2025-11-26T00:33:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055177</id><title>Image Diffusion Models Exhibit Emergent Temporal Propagation in Videos</title><updated>2025-11-26T18:13:39.946790+00:00</updated><content>&lt;doc fingerprint="949db60014f5ba86"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Computer Vision and Pattern Recognition&lt;/head&gt;&lt;p&gt; [Submitted on 25 Nov 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Image Diffusion Models Exhibit Emergent Temporal Propagation in Videos&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:Image diffusion models, though originally developed for image generation, implicitly capture rich semantic structures that enable various recognition and localization tasks beyond synthesis. In this work, we investigate their self-attention maps can be reinterpreted as semantic label propagation kernels, providing robust pixel-level correspondences between relevant image regions. Extending this mechanism across frames yields a temporal propagation kernel that enables zero-shot object tracking via segmentation in videos. We further demonstrate the effectiveness of test-time optimization strategies-DDIM inversion, textual inversion, and adaptive head weighting-in adapting diffusion features for robust and consistent label propagation. Building on these findings, we introduce DRIFT, a framework for object tracking in videos leveraging a pretrained image diffusion model with SAM-guided mask refinement, achieving state-of-the-art zero-shot performance on standard video object segmentation benchmarks.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2511.19936"/><published>2025-11-26T07:55:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055421</id><title>Statistical Process Control in Python</title><updated>2025-11-26T18:13:39.574510+00:00</updated><content>&lt;doc fingerprint="d2780f32a8fc6cd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;16 Statistical Process Control in &lt;code&gt;Python&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;In this workshop, we will learn how to perform statistical process control in Python, using statistical tools and &lt;code&gt;plotnine&lt;/code&gt; visualizations! Statistical Process Control refers to using statistics to (1) measure variation in product quality over time and (2) identify benchmarks to know when intervention is needed. Let’s get started!&lt;/p&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;head rend="h3"&gt;Packages&lt;/head&gt;
    &lt;code&gt;# Remember to install these packages using a terminal, if you haven't already!
!pip install pandas plotnine scipy&lt;/code&gt;
    &lt;p&gt;We’ll be using &lt;code&gt;pandas&lt;/code&gt; for data manipulation, &lt;code&gt;plotnine&lt;/code&gt; for visualization, and &lt;code&gt;scipy&lt;/code&gt; for statistical functions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Custom Functions&lt;/head&gt;
    &lt;p&gt;This workshop uses custom functions from the &lt;code&gt;functions/&lt;/code&gt; directory. You may need both:
- &lt;code&gt;functions_distributions.py&lt;/code&gt; - for reliability and distribution functions
- &lt;code&gt;functions_process_control.py&lt;/code&gt; - for statistical process control functions&lt;/p&gt;
    &lt;p&gt;To use these functions, you need to acquire them from the repository at github.com/timothyfraser/sigma/tree/main/functions.&lt;/p&gt;
    &lt;p&gt;Add the functions directory to your Python path&lt;/p&gt;
    &lt;code&gt;import sys
import os
# Add the functions directory to Python path
sys.path.append('functions')  # or path to wherever you placed the functions folder&lt;/code&gt;
    &lt;p&gt;Once you have the functions available, you can import them:&lt;/p&gt;
    &lt;head rend="h3"&gt;Our Case&lt;/head&gt;
    &lt;p&gt;For today’s workshop, we’re going to think about why quality control matters in a local economy, by examining the case of the Japanese Hot Springs bath economy! Hot springs, or onsen, are a major source of tourism and recreation for families in Japan, bringing residents from across the country every year to often rural communities where the right geological conditions have brought on naturally occurring hot springs. Restaurants, taxi and bus companies, and many service sector firms rely on their local onsen to bring in a steady stream (pun intended) of tourists to the local economy. So, it’s often in the best interest of onsen operators to keep an eye on the temperature, minerals, or other aspects of their hot springs baths to ensure quality control, to keep up their firm (and town’s!) reputation for quality rest and relaxation!&lt;/p&gt;
    &lt;p&gt;Onsen-goers often seek out specific types of hot springs, so it’s important for an onsen to actually provide what it advertises! Serbulea and Payyappallimana (2012) describe some of these benchmarks.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Temperature: Onsen are divided into “Extra Hot Springs” (&lt;/p&gt;&lt;code&gt;&amp;gt;42°C&lt;/code&gt;), “Hot Springs” (&lt;code&gt;41~34°C&lt;/code&gt;), and “Warm Springs” (&lt;code&gt;33~25°C&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;pH: Onsen are classified into “Acidic” (&lt;/p&gt;&lt;code&gt;pH &amp;lt; 3&lt;/code&gt;), “Mildly Acidic” (&lt;code&gt;pH 3~6&lt;/code&gt;), “Neutral” (&lt;code&gt;pH 6~7.5&lt;/code&gt;), “Mildly alkaline” (&lt;code&gt;pH 7.5~8.5&lt;/code&gt;), and “Alkaline” (&lt;code&gt;pH &amp;gt; 8.5&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Sulfur: Sulfur onsen typically have about 2mg of sulfur per 1kg of hot spring water; sulfur levels must exceed 1 mg to count as a Sulfur onsen. (It smells like rotten eggs!)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These are decent examples of quality control metrics that onsen operators might want to keep tabs on!&lt;/p&gt;
    &lt;head rend="h3"&gt;Our Data&lt;/head&gt;
    &lt;p&gt;You’ve been hired to evaluate quality control at a local onsen in sunny Kagoshima prefecture! Every month, for 15 months, you systematically took 20 random samples of hot spring water and recorded its temperature, pH, and sulfur levels. How might you determine if this onsen is at risk of slipping out of one sector of the market (eg. Extra Hot!) and into another (just normal Hot Springs?).&lt;/p&gt;
    &lt;p&gt;Let’s read in our data from &lt;code&gt;workshops/onsen.csv&lt;/code&gt;!&lt;/p&gt;
    &lt;code&gt;# Add functions directory to path if not already there
import sys
if 'functions' not in sys.path:
    sys.path.append('functions')

from functions_distributions import density, tidy_density, approxfun

water = pd.read_csv('workshops/onsen.csv')
water.head(3)&lt;/code&gt;
    &lt;code&gt;##    id  time  temp   ph  sulfur
## 0   1     1  43.2  5.1     0.0
## 1   2     1  45.3  4.8     0.4
## 2   3     1  45.5  6.2     0.9&lt;/code&gt;
    &lt;head rend="h2"&gt;16.1 Process Descriptive Statistics&lt;/head&gt;
    &lt;p&gt;First, let’s get a sense of our process by calculating some basic descriptive statistics. We’ll create a simple function to calculate the mean and standard deviation, which are fundamental to evaluating process variation.&lt;/p&gt;
    &lt;code&gt;from pandas import Series
def describe(x: Series):
  x = Series(x)
  out = pd.DataFrame({
    'mean': [x.mean()],
    'sd': [x.std()],
  })
  out['caption'] = ("Process Mean: " + out['mean'].round(2).astype(str) +
                    " | SD: " + out['sd'].round(2).astype(str))
  return out

tab = describe(water['temp'])
tab&lt;/code&gt;
    &lt;code&gt;##     mean        sd                         caption
## 0  44.85  1.989501  Process Mean: 44.85 | SD: 1.99&lt;/code&gt;
    &lt;p&gt;Now let’s apply this to our temperature data to see the overall process mean and variation.&lt;/p&gt;
    &lt;head rend="h2"&gt;16.2 Process Overview Visual&lt;/head&gt;
    &lt;p&gt;The process overview chart is one of the most important tools in SPC. It shows us how our process behaves over time, helping us identify patterns, trends, and potential issues. We’ll create a visualization that shows individual measurements, subgroup means, and the overall process average.&lt;/p&gt;
    &lt;code&gt;g1 = (ggplot(water, aes(x='time', y='temp', group='time')) +
  geom_hline(aes(yintercept=water['temp'].mean()), color='lightgrey', size=3) +
  geom_jitter(height=0, width=0.25) +
  geom_boxplot() +
  labs(x='Time (Subgroup)', y='Temperature (Celsius)', subtitle='Process Overview', caption=tab['caption'][0]))

# Save the plot
g1.save('images/05_process_overview.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;code&gt;g2 = (ggplot(water, aes(x='temp')) + geom_histogram(bins=15, color='white', fill='grey') + theme_void() + coord_flip())

# Save the plot
g2.save('images/05_process_histogram.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;p&gt;The histogram shows us the distribution of all temperature measurements, giving us insight into the overall process variation. This helps us understand if our process is centered and how much variation we’re seeing.&lt;/p&gt;
    &lt;head rend="h2"&gt;16.3 Subgroup (Within-Group) Statistics&lt;/head&gt;
    &lt;p&gt;In SPC, we often work with subgroups - small samples taken at regular intervals. This allows us to distinguish between common cause variation (inherent to the process) and special cause variation (due to specific events). Let’s calculate statistics for each subgroup to see how the process behaves over time.&lt;/p&gt;
    &lt;code&gt;stat_s = (water.groupby('time').apply(lambda d: pd.Series({
  'xbar': d['temp'].mean(),
  'r': d['temp'].max() - d['temp'].min(),
  'sd': d['temp'].std(),
  'nw': len(d)
})).reset_index())
stat_s['df'] = stat_s['nw'] - 1
stat_s['sigma_s'] = ( (stat_s['df'] * (stat_s['sd']**2)).sum() / stat_s['df'].sum() )**0.5
stat_s['se'] = stat_s['sigma_s'] / (stat_s['nw']**0.5)
stat_s['upper'] = stat_s['xbar'].mean() + 3*stat_s['se']
stat_s['lower'] = stat_s['xbar'].mean() - 3*stat_s['se']
stat_s.head(3)&lt;/code&gt;
    &lt;code&gt;##    time    xbar    r        sd    nw    df   sigma_s        se      upper      lower
## 0     1  44.635  4.2  1.342533  20.0  19.0  1.986174  0.444122  46.182366  43.517634
## 1     3  45.305  7.9  2.001440  20.0  19.0  1.986174  0.444122  46.182366  43.517634
## 2     5  44.765  5.9  1.628133  20.0  19.0  1.986174  0.444122  46.182366  43.517634&lt;/code&gt;
    &lt;p&gt;Here we’ve calculated key statistics for each subgroup:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;xbar: The mean of each subgroup&lt;/item&gt;
      &lt;item&gt;r: The range (max - min) within each subgroup&lt;/item&gt;
      &lt;item&gt;sd: The standard deviation within each subgroup&lt;/item&gt;
      &lt;item&gt;sigma_s: The pooled within-subgroup standard deviation&lt;/item&gt;
      &lt;item&gt;se: The standard error for each subgroup mean&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;16.3.1 Total Statistics (Between Groups)&lt;/head&gt;
    &lt;p&gt;Now let’s calculate the overall process statistics that summarize the behavior across all subgroups:&lt;/p&gt;
    &lt;code&gt;stat_t = pd.DataFrame({
  'xbbar': [stat_s['xbar'].mean()],
  'rbar': [stat_s['r'].mean()],
  'sdbar': [stat_s['sd'].mean()],
  'sigma_s': [(stat_s['sd']**2).mean()**0.5],
  'sigma_t': [water['temp'].std()]
})
stat_t&lt;/code&gt;
    &lt;code&gt;##    xbbar    rbar    sdbar   sigma_s   sigma_t
## 0  44.85  7.2625  1.93619  1.986174  1.989501&lt;/code&gt;
    &lt;p&gt;These statistics give us:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;xbbar: The grand mean (average of all subgroup means)&lt;/item&gt;
      &lt;item&gt;rbar: The average range across subgroups&lt;/item&gt;
      &lt;item&gt;sdbar: The average standard deviation across subgroups&lt;/item&gt;
      &lt;item&gt;sigma_s: The pooled within-subgroup standard deviation&lt;/item&gt;
      &lt;item&gt;sigma_t: The total process standard deviation&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;16.3.2 Average and Standard Deviation Charts&lt;/head&gt;
    &lt;p&gt;Control charts are the heart of SPC. They help us monitor process stability over time and detect when the process is out of control. We’ll create charts for both the subgroup means (X-bar chart) and standard deviations (S chart).&lt;/p&gt;
    &lt;code&gt;labels = pd.DataFrame({
  'time': [stat_s['time'].max()]*3,
  'type': ['xbbar','upper','lower'],
  'name': ['mean','+3 s','-3 s'],
  'value': [stat_s['xbar'].mean(), stat_s['upper'].iloc[0], stat_s['lower'].iloc[0]]
})

control_chart = (ggplot(stat_s, aes(x='time', y='xbar')) +
  geom_hline(aes(yintercept=stat_s['xbar'].mean()), color='lightgrey', size=3) +
  geom_ribbon(aes(ymin='lower', ymax='upper'), fill='steelblue', alpha=0.2) +
  geom_line(size=1) + geom_point(size=5) +
  geom_label(data=labels, mapping=aes(x='time', y='value', label='name'), ha='right') +
  labs(x='Time (Subgroups)', y='Average', subtitle='Average and Standard Deviation Chart'))

# Save the plot
control_chart.save('images/05_control_chart.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;p&gt;This control chart shows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Center line: The grand mean (xbbar)&lt;/item&gt;
      &lt;item&gt;Control limits: Upper and lower 3-sigma limits based on the standard error&lt;/item&gt;
      &lt;item&gt;Individual points: Each subgroup mean plotted over time&lt;/item&gt;
      &lt;item&gt;Shaded area: The control limits region&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Points outside the control limits or showing non-random patterns indicate the process may be out of control and requires investigation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning Check 1&lt;/head&gt;
    &lt;p&gt;Question&lt;/p&gt;
    &lt;p&gt;Produce the same process overview chart for &lt;code&gt;pH&lt;/code&gt;.&lt;/p&gt;
    &lt;head&gt;[View Answer!]&lt;/head&gt;
    &lt;code&gt;def ggprocess(x, y, xlab='Subgroup', ylab='Metric'):
  import pandas as pd
  from plotnine import ggplot, aes, geom_hline, geom_jitter, geom_boxplot, labs
  d = pd.DataFrame({'x': x, 'y': y})
  g = (ggplot(d, aes(x='x', y='y', group='x')) +
       geom_hline(aes(yintercept=d['y'].mean()), color='lightgrey', size=3) +
       geom_jitter(height=0, width=0.25) +
       geom_boxplot() +
       labs(x=xlab, y=ylab, subtitle='Process Overview'))
  return g

ph_chart = ggprocess(water['time'], water['ph'])

# Save the plot
ph_chart.save('images/05_ph_chart.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;head rend="h2"&gt;16.4 Moving Range Charts (n=1)&lt;/head&gt;
    &lt;p&gt;When we have individual measurements rather than subgroups, we use moving range charts. The moving range is the absolute difference between consecutive measurements, which helps us estimate process variation when we can’t calculate within-subgroup statistics.&lt;/p&gt;
    &lt;code&gt;indiv = water.iloc[[0,20,40,60,80,100,120,140]]
mr = (indiv['temp'].diff().abs().dropna())
mrbar = mr.mean()
import numpy as np
d2 = np.mean(np.abs(np.diff(np.random.normal(0,1,10000))))
sigma_s = mrbar / d2
se = sigma_s / (1**0.5)
upper = mrbar + 3*se
lower = 0&lt;/code&gt;
    &lt;code&gt;istat = pd.DataFrame({'time': indiv['time'].iloc[1:], 'mr': mr, 'mrbar': mrbar, 'upper': upper, 'lower': lower})
mr_chart = (ggplot(istat, aes(x='time', y='mr')) +
  geom_ribbon(aes(ymin='lower', ymax='upper'), fill='steelblue', alpha=0.25) +
  geom_hline(aes(yintercept=mr.mean()), size=3, color='darkgrey') +
  geom_line(size=1) + geom_point(size=5) +
  labs(x='Time (Subgroup)', y='Moving Range', subtitle='Moving Range Chart'))

# Save the plot
mr_chart.save('images/05_moving_range_chart.png', width=8, height=6, dpi=100)&lt;/code&gt;
    &lt;p&gt;The moving range chart shows:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Center line: The average moving range (mrbar)&lt;/item&gt;
      &lt;item&gt;Upper control limit: Based on the estimated process standard deviation&lt;/item&gt;
      &lt;item&gt;Lower control limit: Set to 0 (moving ranges can’t be negative)&lt;/item&gt;
      &lt;item&gt;Individual points: Each moving range value&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This chart helps us monitor process variation when we have individual measurements rather than subgroups.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://timothyfraser.com/sigma/statistical-process-control-in-python.html"/><published>2025-11-26T08:40:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46055935</id><title>A cell so minimal that it challenges definitions of life</title><updated>2025-11-26T18:13:39.040611+00:00</updated><content>&lt;doc fingerprint="b629199a712103d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Cell So Minimal That It Challenges Definitions of Life&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Life’s fundamental structure is the cell, and so the main things that a cell does — processing biomolecules, growing, replicating its genetic material and producing a new body — are considered hallmarks of life. But earlier this year, scientists discovered a cell so severely stripped of essential functions that it challenges biologists’ definitions of what counts as a living thing.&lt;/p&gt;
    &lt;p&gt;The species is a single-celled organism known only by the mysterious sequence of its genetic code. Its genome is fantastically small: Along the organism’s evolutionary journey, it seems to have gotten rid of most of it. According to the shocked researchers who published the discovery in a preprint uploaded to biorxiv.org in May, the lost genes include those central to cell metabolism, meaning it can neither process nutrients nor grow on its own.&lt;/p&gt;
    &lt;p&gt;Other cells with highly reduced genomes still encode proteins to create amino acids, break down carbohydrates for energy or synthesize vitamins. All this appears to be absent from the cell, which seems to be a parasite entirely dependent on a host or cellular community to meet its nutritional needs. Until now, these genetic pathways were considered fundamental for the survival of any cell.&lt;/p&gt;
    &lt;p&gt;The organism’s “replicative core” — the genetic components needed to reproduce itself — remains, making up more than half of its genome.&lt;/p&gt;
    &lt;p&gt;“Metabolism is one of the key components of how we often define life,” said Takuro Nakayama, an evolutionary microbiologist at the University of Tsukuba in Japan who led the team. The cell’s discovery “challenges this by suggesting a cell can exist almost entirely without its own. It demonstrates that the diversity of cellular life is far greater than we knew and that organisms do not always follow our definitions.”&lt;/p&gt;
    &lt;p&gt;While this form of life is new to science, it’s possible that organisms like it are common. A huge proportion of microbial biodiversity may be hiding in recursive interrelationships between parasitic and host microbes, said Puri López-García, a microbial ecologist at the French National Center for Scientific Research in Paris who was not involved in the study.&lt;/p&gt;
    &lt;p&gt;“The diversity of archaea and bacteria that appear to belong to these supergroups of parasitic organisms is very, very large,” she said. For bacteria, it may be between 25% and 50% of the group’s total share of species, she suggested.&lt;/p&gt;
    &lt;p&gt;The discovery pushes the boundaries of our knowledge of just how small and simple cellular life can become, as it evolves even into forms that are barely alive.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Extraordinary Discovery&lt;/head&gt;
    &lt;p&gt;Nakayama has built a scientific career out of looking more closely than other researchers typically do. He considers an already tiny cell and wonders: Are there even smaller cells that make a home there?&lt;/p&gt;
    &lt;p&gt;“The difference [in size between parasitic and host cells] can sometimes be like that between a human and Godzilla,” Nakayama said. He is fascinated by the potentially vast amount of undiscovered biodiversity these relationships might contain, and his lab looks for such relationships in seawater. The ocean is a nutrient-poor environment that incentivizes cells to form trading partnerships. Sometimes they float along together, loosely tethered, exchanging rare nutrients and energy. Other times their arrangements are more organized.&lt;/p&gt;
    &lt;p&gt;Citharistes regius is a globally widespread single-celled dinoflagellate that has a walled, pouchlike external chamber for housing symbiotic cyanobacteria. Nakayama and his team searched for the alga by scooping seawater samples from the Pacific Ocean using a fine-mesh net. A common technique is to sequence whatever DNA can be found in the soup of such a sample, an approach called metagenomics.&lt;/p&gt;
    &lt;p&gt;“That method is incredibly powerful for capturing a broad overview,” Nakayama said. “However, with such data, it is often difficult to maintain the link between a sequence and the specific cell it came from, and rare organisms can be easily missed.” His team’s more targeted approach involves microscopically identifying and physically isolating a single target cell from that mixed sample.&lt;/p&gt;
    &lt;p&gt;Back on shore in the Tsukuba lab, after the researchers confirmed they had C. regius, they sequenced every genome associated with that one cell. As expected, they found DNA from its symbiotic cyanobacteria, but they found something else, too: sequences that belong to an archaeon, a member of the domain of life thought to have given rise to eukaryotes like us.&lt;/p&gt;
    &lt;p&gt;At first, Nakayama and his colleagues thought they had made a mistake. The archaeal genome is tiny: just 238,000 base pairs end to end. In comparison, humans have a few billion base pairs, and even E. coli bacteria work with several million. (C. regius’ symbiotic cyanobacteria have 1.9 million base pairs.) Previously, the smallest known archaeal genome was the one belonging to Nanoarchaeum equitans — at 490,000 base pairs, it is more than twice as long as the new one the researchers found. They initially figured that this tiny genome — too large to be merely statistical noise — was an abbreviated piece of a much larger genome, erroneously compiled by their software.&lt;/p&gt;
    &lt;p&gt;“At first, we suspected it might be an artifact of the genome-assembly process,” Nakayama recalled. To check, the team sequenced the genome using different technologies and ran the data through multiple computer programs that assemble fragments of DNA sequences into a full genome. The various approaches all reconstructed the exact same 238,000-base-pair circular genome. “This consistency is what convinced us it was the real, complete genome,” he said.&lt;/p&gt;
    &lt;p&gt;This meant that Nakayama and his team had a new organism on their hands. They named the microbe Candidatus Sukunaarchaeum mirabile (hereafter referred to as Sukunaarchaeum) for its remarkably tiny genome — after Sukuna-biko-na, a Shinto deity notable for his short stature, plus a Latin word for “extraordinary.”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Spectrum of Quasi-Life&lt;/head&gt;
    &lt;p&gt;When the team consulted databases of known genes to analyze the archaeon, they found its small size was the result of a whole lot that was missing.&lt;/p&gt;
    &lt;p&gt;Sukunaarchaeum encodes the barest minimum of proteins for its own replication, and that’s about all. Most strangely, its genome is missing any hints of the genes required to process and build molecules, outside of those needed to reproduce. Lacking those metabolic components, the organism must outsource the processes for growth and maintenance to another cell, a host upon which the microbe is entirely dependent.&lt;/p&gt;
    &lt;p&gt;Other symbiotic microbes have scrapped much of their genomes, including Sukunaarchaeum’s evolutionary relatives. The researchers’ analysis suggested that the microbe is part of the DPANN archaea, sometimes called nanoarchaea or ultra-small archaea, which are characterized by small size and small genomes. DPANN archaea are generally thought to be symbiotes that cling to the outside of larger prokaryotic microbes, and plenty of them have substantially reduced genomes to match that lifestyle. But until now, none of the DPANN species had genomes quite this pared back. And Sukunaarchaeum branched off the DPANN lineage early, suggesting that it had taken its own evolutionary journey.&lt;/p&gt;
    &lt;p&gt;“This realm of the archaea is pretty mysterious in general,” said Brett Baker, a microbial ecologist at the University of Texas, Austin who was not involved in the work. “[DPANN archaea are] obviously limited in their metabolic capabilities.”&lt;/p&gt;
    &lt;p&gt;While Sukunaarchaeum may provide some undetermined benefit for its host — which could be C. regius, the symbiotic cyanobacteria or another cell entirely — it’s probably a self-absorbed parasite. “Its genome reduction is driven by entirely selfish motives, consistent with a parasitic lifestyle,” said Tim Williams, a microbiologist at the University of Technology Sydney who was not involved in the study. It cannot contribute metabolic products, so the relationship between Sukunaarchaeum and any other cell would likely be a one-way street.&lt;/p&gt;
    &lt;p&gt;Other microbes have evolved similarly extreme, streamlined forms. For instance, the bacterium Carsonella ruddii, which lives as a symbiont within the guts of sap-feeding insects, has an even smaller genome than Sukunaarchaeum, at around 159,000 base pairs. However, these and other super-small bacteria have metabolic genes to produce nutrients, such as amino acids and vitamins, for their hosts. Instead, their genome has cast off much of their ability to reproduce on their own.&lt;/p&gt;
    &lt;p&gt;“They are on the way to becoming organelles. This is the way mitochondria and chloroplasts are thought to have evolved,” Williams said. “But Sukunaarchaeum has gone in the opposite direction: The genome retains genes required for its own propagation, but lost most, if not all, of its metabolic genes.”&lt;/p&gt;
    &lt;p&gt;Soon after Nakayama’s team posted their results online, they got a big response. “When we saw the preprint, this was really quite exciting in the lab,” said Thijs Ettema, an evolutionary microbiologist and expert on archaeal genomics at Wageningen University &amp;amp; Research in the Netherlands, who was not involved in the work. “These types of organisms [with reduced genomes] have been found before, but not as extreme as this.”&lt;/p&gt;
    &lt;p&gt;Some news reports went so far as to imply that Sukunaarchaeum is on its way to evolving into a virus. However, while both Sukunaarchaeum and viruses are reliant on a host cell for very basic biological functions, viruses can’t reproduce on their own.&lt;/p&gt;
    &lt;p&gt;“There is a fundamental gap between Sukunaarchaeum and viruses,” Nakayama said. “Sukunaarchaeum retains its own core machinery for gene expression, including ribosomes, albeit in a simplified form. This is in stark contrast to viruses, which lack ribosomes and must hijack the host’s cellular systems to replicate.”&lt;/p&gt;
    &lt;p&gt;The findings fit into a larger discussion about how we define life, Ettema said, since nature routinely evolves exceptions that defy simple categorization. “Most likely it cannot live independently,” he said. “You could say the same of bacterial symbionts. And what do we call organelles like mitochondria and plastids? … At what point should we call things alive?”&lt;/p&gt;
    &lt;head rend="h2"&gt;A Minimalist Lifestyle&lt;/head&gt;
    &lt;p&gt;Many questions about Sukunaarchaeum remain unresolved. For one, a large portion of its genome is made up of genes that don’t match any known sequences. They seem to encode large proteins, which is uncommon in such radically reduced organisms.&lt;/p&gt;
    &lt;p&gt;Nakayama and his colleagues think these large proteins are employed on the cell membrane and somehow support interactions between the archaeon and its host. That would fit with the lifestyles of other studied DPANN archaea as well, Ettema said, which are generally thought to be ectosymbionts, adhering to the outside of comparatively immense hosts.&lt;/p&gt;
    &lt;p&gt;Although Sukunaarchaeum was found in association with the dinoflagellate C. regius, its true host’s identity is unknown. C. regius is a eukaryote, but DPANN archaea generally associate with other archaea. Also up for debate: Is it attaching to the outside of a host cell, like other DPANN archaea, or is it living internally — or both? Answering these questions would require setting human eyes on the archaeon for the first time; at this point it’s only known from a curious string of genetic data.&lt;/p&gt;
    &lt;p&gt;There is also a slim possibility that these genes are the “lost” metabolic genes after all, López-García said, if they have evolved so far from their original sequences as to be unrecognizable. “Because the genome is so fast-evolving, maybe some of these functions correspond to metabolic functions, but the divergence is so much that we cannot identify the [gene] homologue [in the database],” she said.&lt;/p&gt;
    &lt;p&gt;Even stranger minimalist lifestyles or more reduced genomes may be out there, but researchers may miss them, Ettema said. Traditional analytical approaches for surveying the genomes of microbial samples could flag their tiny genomes as incomplete or low quality and discard them, or skip them entirely, he said. “[The DNA] might have been present in the samples, but it was removed after sequencing, and hence overlooked.”&lt;/p&gt;
    &lt;p&gt;When Nakayama and his colleagues searched a database of marine environmental sequence data from the world’s oceans to see if the new microbe popped up anywhere else, they didn’t find any matches. But they did detect many very similar sequences from what are likely to be close relatives. Sukunaarchaeum may be the tip of a very large microbial iceberg, one floating in a vast ocean of microbial diversity: tiny microbes clinging to slightly less tiny microbes, perhaps inside other microbes, the stories of their ancient relationships only beginning to be revealed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/a-cell-so-minimal-that-it-challenges-definitions-of-life-20251124/"/><published>2025-11-26T10:06:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46056757</id><title>Qiskit open-source SDK for working with quantum computers</title><updated>2025-11-26T18:13:38.306246+00:00</updated><content>&lt;doc fingerprint="7133719a8c8455c8"&gt;
  &lt;main&gt;
    &lt;p&gt;Qiskit is an open-source SDK for working with quantum computers at the level of extended quantum circuits, operators, and primitives.&lt;/p&gt;
    &lt;p&gt;This library is the core component of Qiskit, which contains the building blocks for creating and working with quantum circuits, quantum operators, and primitive functions (Sampler and Estimator). It also contains a transpiler that supports optimizing quantum circuits, and a quantum information toolbox for creating advanced operators.&lt;/p&gt;
    &lt;p&gt;For more details on how to use Qiskit, refer to the documentation located here:&lt;/p&gt;
    &lt;p&gt;https://quantum.cloud.ibm.com/docs/&lt;/p&gt;
    &lt;p&gt;We encourage installing Qiskit via &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;pip install qiskit&lt;/code&gt;
    &lt;p&gt;Pip will handle all dependencies automatically and you will always install the latest (and well-tested) version.&lt;/p&gt;
    &lt;p&gt;To install from source, follow the instructions in the documentation.&lt;/p&gt;
    &lt;p&gt;Now that Qiskit is installed, it's time to begin working with Qiskit. The essential parts of a quantum program are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Define and build a quantum circuit that represents the quantum state&lt;/item&gt;
      &lt;item&gt;Define the classical output by measurements or a set of observable operators&lt;/item&gt;
      &lt;item&gt;Depending on the output, use the Sampler primitive to sample outcomes or the Estimator primitive to estimate expectation values.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Create an example quantum circuit using the &lt;code&gt;QuantumCircuit&lt;/code&gt; class:&lt;/p&gt;
    &lt;code&gt;import numpy as np
from qiskit import QuantumCircuit

# 1. A quantum circuit for preparing the quantum state |000&amp;gt; + i |111&amp;gt; / √2
qc = QuantumCircuit(3)
qc.h(0)             # generate superposition
qc.p(np.pi / 2, 0)  # add quantum phase
qc.cx(0, 1)         # 0th-qubit-Controlled-NOT gate on 1st qubit
qc.cx(0, 2)         # 0th-qubit-Controlled-NOT gate on 2nd qubit&lt;/code&gt;
    &lt;p&gt;This simple example creates an entangled state known as a GHZ state &lt;code&gt;h&lt;/code&gt;), Phase gate (&lt;code&gt;p&lt;/code&gt;), and CNOT gate (&lt;code&gt;cx&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;Once you've made your first quantum circuit, choose which primitive you will use. Starting with the Sampler, we use &lt;code&gt;measure_all(inplace=False)&lt;/code&gt; to get a copy of the circuit in which all the qubits are measured:&lt;/p&gt;
    &lt;code&gt;# 2. Add the classical output in the form of measurement of all qubits
qc_measured = qc.measure_all(inplace=False)

# 3. Execute using the Sampler primitive
from qiskit.primitives import StatevectorSampler
sampler = StatevectorSampler()
job = sampler.run([qc_measured], shots=1000)
result = job.result()
print(f" &amp;gt; Counts: {result[0].data['meas'].get_counts()}")&lt;/code&gt;
    &lt;p&gt;Running this will give an outcome similar to &lt;code&gt;{'000': 497, '111': 503}&lt;/code&gt; which is &lt;code&gt;000&lt;/code&gt; 50% of the time and &lt;code&gt;111&lt;/code&gt; 50% of the time up to statistical fluctuations.
To illustrate the power of the Estimator, we now use the quantum information toolbox to create the operator &lt;code&gt;run()&lt;/code&gt; function, along with our quantum circuit. Note that the Estimator requires a circuit without measurements, so we use the &lt;code&gt;qc&lt;/code&gt; circuit we created earlier.&lt;/p&gt;
    &lt;code&gt;# 2. Define the observable to be measured 
from qiskit.quantum_info import SparsePauliOp
operator = SparsePauliOp.from_list([("XXY", 1), ("XYX", 1), ("YXX", 1), ("YYY", -1)])

# 3. Execute using the Estimator primitive
from qiskit.primitives import StatevectorEstimator
estimator = StatevectorEstimator()
job = estimator.run([(qc, operator)], precision=1e-3)
result = job.result()
print(f" &amp;gt; Expectation values: {result[0].data.evs}")&lt;/code&gt;
    &lt;p&gt;Running this will give the outcome &lt;code&gt;4&lt;/code&gt;. For fun, try to assign a value of +/- 1 to each single-qubit operator X and Y
and see if you can achieve this outcome. (Spoiler alert: this is not possible!)&lt;/p&gt;
    &lt;p&gt;Using the Qiskit-provided &lt;code&gt;qiskit.primitives.StatevectorSampler&lt;/code&gt; and &lt;code&gt;qiskit.primitives.StatevectorEstimator&lt;/code&gt; will not take you very far.
The power of quantum computing cannot be simulated on classical computers and you need to use real quantum hardware to scale to larger quantum circuits.
However, running a quantum circuit on hardware requires rewriting to the basis gates and connectivity of the quantum hardware.
The tool that does this is the transpiler, and Qiskit includes transpiler passes for synthesis, optimization, mapping, and scheduling.
However, it also includes a default compiler, which works very well in most examples.
The following code will map the example circuit to the &lt;code&gt;basis_gates = ["cz", "sx", "rz"]&lt;/code&gt; and a
bidirectional linear chain of qubits &lt;code&gt;coupling_map = [[0, 1], [1, 0], [1, 2], [2, 1]]&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;from qiskit import transpile
from qiskit.transpiler import Target, CouplingMap
target = Target.from_configuration(
    basis_gates=["cz", "sx", "rz"],
    coupling_map=CouplingMap.from_line(3),
)
qc_transpiled = transpile(qc, target=target)&lt;/code&gt;
    &lt;p&gt;Qiskit provides an abstraction layer that lets users run quantum circuits on hardware from any vendor that provides a compatible interface. The best way to use Qiskit is with a runtime environment that provides optimized implementations of Sampler and Estimator for a given hardware platform. This runtime may involve using pre- and post-processing, such as optimized transpiler passes with error suppression, error mitigation, and, eventually, error correction built in. A runtime implements &lt;code&gt;qiskit.primitives.BaseSamplerV2&lt;/code&gt; and &lt;code&gt;qiskit.primitives.BaseEstimatorV2&lt;/code&gt; interfaces. For example,
some packages that provide implementations of a runtime primitive implementation are:&lt;/p&gt;
    &lt;p&gt;Qiskit also provides a lower-level abstract interface for describing quantum backends. This interface, located in &lt;code&gt;qiskit.providers&lt;/code&gt;, defines an abstract &lt;code&gt;BackendV2&lt;/code&gt; class that providers can implement to represent their
hardware or simulators to Qiskit. The backend class includes a common interface for executing circuits on the backends; however, in this interface each provider may perform different types of pre- and post-processing and return outcomes that are vendor-defined. Some examples of published provider packages that interface with real hardware are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-ionq&lt;/item&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-aqt-provider&lt;/item&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-braket-provider&lt;/item&gt;
      &lt;item&gt;https://github.com/qiskit-community/qiskit-quantinuum-provider&lt;/item&gt;
      &lt;item&gt;https://github.com/rigetti/qiskit-rigetti&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can refer to the documentation of these packages for further instructions on how to get access and use these systems.&lt;/p&gt;
    &lt;p&gt;If you'd like to contribute to Qiskit, please take a look at our contribution guidelines. By participating, you are expected to uphold our code of conduct.&lt;/p&gt;
    &lt;p&gt;We use GitHub issues for tracking requests and bugs. Please join the Qiskit Slack community for discussion, comments, and questions. For questions related to running or using Qiskit, Stack Overflow has a &lt;code&gt;qiskit&lt;/code&gt;.
For questions on quantum computing with Qiskit, use the &lt;code&gt;qiskit&lt;/code&gt; tag in the Quantum Computing Stack Exchange (please, read first the guidelines on how to ask in that forum).&lt;/p&gt;
    &lt;p&gt;Qiskit is the work of many people who contribute to the project at different levels. If you use Qiskit, please cite as per the included BibTeX file.&lt;/p&gt;
    &lt;p&gt;The changelog for a particular release is dynamically generated and gets written to the release page on Github for each release. For example, you can find the page for the &lt;code&gt;1.2.0&lt;/code&gt; release here:&lt;/p&gt;
    &lt;p&gt;https://github.com/Qiskit/qiskit/releases/tag/1.2.0&lt;/p&gt;
    &lt;p&gt;The changelog for the current release can be found in the releases tab: The changelog provides a quick overview of notable changes for a given release.&lt;/p&gt;
    &lt;p&gt;Additionally, as part of each release, detailed release notes are written to document in detail what has changed as part of a release. This includes any documentation on potential breaking changes on upgrade and new features. See all release notes here.&lt;/p&gt;
    &lt;p&gt;We acknowledge partial support for Qiskit development from the DOE Office of Science National Quantum Information Science Research Centers, Co-design Center for Quantum Advantage (C2QA) under contract number DE-SC0012704.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Qiskit/qiskit"/><published>2025-11-26T12:26:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46057304</id><title>I DM'd a Korean presidential candidate and ended up building his core campaign</title><updated>2025-11-26T18:13:38.098315+00:00</updated><content/><link href="https://medium.com/@wjsdj2008/i-dmd-a-korean-presidential-candidate-and-ended-up-building-his-core-campaign-platform-the-38eb1c5f5e7d"/><published>2025-11-26T13:40:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46057488</id><title>Voyager 1 Is About to Reach One Light-Day from Earth</title><updated>2025-11-26T18:13:37.372175+00:00</updated><content>&lt;doc fingerprint="6da2c57b3816873f"&gt;
  &lt;main&gt;
    &lt;p&gt;After nearly 50 years in space, NASA’s Voyager 1 is about to hit a historic milestone. By November 15, 2026, it will be 16.1 billion miles (25.9 billion km) away, meaning a radio signal will take a full 24 hours—a full light-day—to reach it. For context, a light-year is the distance light travels in a year, about 5.88 trillion miles (9.46 trillion km), so one light-day is just a tiny fraction of that.&lt;/p&gt;
    &lt;p&gt;Launched in 1977 to explore Jupiter and Saturn, Voyager 1 entered interstellar space in 2012, becoming the most distant human-made object ever. Traveling at around 11 miles per second (17.7 km/s), it adds roughly 3.5 astronomical units (the distance from Earth to the Sun) each year. Even after decades in the harsh environment of space, Voyager 1 keeps sending data thanks to its radioisotope thermoelectric generators, which will last into the 2030s.&lt;/p&gt;
    &lt;p&gt;Communicating with Voyager 1 is slow. Commands now take about a day to arrive, with another day for confirmation. Compare that to the Moon (1.3 seconds), Mars (up to 4 minutes), and Pluto (nearly 7 hours). The probe’s distance makes every instruction a patient exercise in deep-space operations. To reach our closest star, Proxima Centauri, even at light speed, would take over four years—showing just how tiny a light-day is in cosmic terms.&lt;/p&gt;
    &lt;p&gt;Voyager 1’s journey is more than a record for distance. From its planetary flybys to the iconic ‘Pale Blue Dot’ image, it reminds us of the vast scale of the solar system and the incredible endurance of a spacecraft designed to keep exploring, even without return.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scienceclock.com/voyager-1-is-about-to-reach-one-light-day-from-earth/"/><published>2025-11-26T14:02:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46058065</id><title>OpenAI needs to raise at least $207B by 2030</title><updated>2025-11-26T18:13:36.522874+00:00</updated><content>&lt;doc fingerprint="923f1c7588aac3e9"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;FT Alphaville&lt;/head&gt;&lt;p&gt;Register to unlock this article&lt;/p&gt;&lt;head rend="h1"&gt;&lt;quote&gt;OpenAI needs to raise at least $207bn by 2030 so it can continue to lose money, HSBC estimates&lt;/quote&gt;&lt;/head&gt;&lt;p&gt;FT Alphaville is free&lt;/p&gt;&lt;p&gt;Register to keep reading&lt;/p&gt;&lt;p&gt;Want a deeper look?&lt;/p&gt;Explore our recommended subscriptions&lt;head rend="h2"&gt;Explore more offers.&lt;/head&gt;&lt;head rend="h3"&gt;Trial&lt;/head&gt;&lt;p&gt;$1 for 4 weeks&lt;/p&gt;&lt;p&gt;Then $75 per month. Complete digital access to quality FT journalism on any device. Cancel or change your plan anytime during your trial.&lt;/p&gt;&lt;head rend="h3"&gt;Standard Digital&lt;/head&gt;&lt;p&gt;$45 per month&lt;/p&gt;&lt;p&gt;Get essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%&lt;/p&gt;&lt;head rend="h3"&gt;Premium Digital&lt;/head&gt;&lt;p&gt;Complete coverage&lt;/p&gt;&lt;p&gt;$75 per month&lt;/p&gt;&lt;p&gt;Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.&lt;/p&gt;&lt;p&gt;Check whether you already have access via your university or organisation.&lt;/p&gt;&lt;p&gt;Terms &amp;amp; Conditions apply&lt;/p&gt;&lt;head rend="h2"&gt;Explore our full range of subscriptions.&lt;/head&gt;&lt;head rend="h3"&gt;For individuals&lt;/head&gt;&lt;p&gt;Discover all the plans currently available in your country&lt;/p&gt;&lt;head rend="h3"&gt;For multiple readers&lt;/head&gt;&lt;p&gt;Digital access for organisations. Includes exclusive features and content.&lt;/p&gt;&lt;head rend="h2"&gt;Why the FT?&lt;/head&gt;&lt;p&gt;See why over a million readers pay to read the Financial Times.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ft.com/content/23e54a28-6f63-4533-ab96-3756d9c88bad"/><published>2025-11-26T15:06:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46058600</id><title>From blood sugar to brain relief: GLP-1 therapy slashes migraine frequency</title><updated>2025-11-26T18:13:36.361755+00:00</updated><content/><link href="https://www.medlink.com/news/from-blood-sugar-to-brain-relief-glp-1-therapy-slashes-migraine-frequency"/><published>2025-11-26T15:49:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46058912</id><title>Slashdot effect</title><updated>2025-11-26T18:13:36.116747+00:00</updated><content>&lt;doc fingerprint="5804b11d15f76af2"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Slashdot effect&lt;/head&gt;&lt;p&gt;The Slashdot effect, also known as slashdotting or the hug of death occurs when a popular website links to a smaller website, causing a massive increase in traffic. This overloads the smaller site, causing it to slow down or even temporarily become unavailable. Typically, less robust sites are unable to cope with the huge increase in traffic and become unavailable – common causes are lack of sufficient data bandwidth, servers that fail to cope with the high number of requests, and traffic quotas. Sites that are maintained on shared hosting services often fail when confronted with the Slashdot effect. This has the same effect as a denial-of-service attack, albeit accidentally. The name stems from the huge influx of web traffic which would result from the technology news site Slashdot linking to websites. The term flash crowd is a more generic term.[1]&lt;/p&gt;&lt;p&gt;The original circumstances have changed, as flash crowds from Slashdot were reported in 2005 to be diminishing due to competition from similar sites,[2] and the general adoption of elastically scalable cloud hosting platforms.&lt;/p&gt;&lt;head rend="h2"&gt;Terminology&lt;/head&gt;[edit]&lt;p&gt;The term "Slashdot effect" refers to the phenomenon of a website becoming virtually unreachable because too many people are hitting it after the site was mentioned in an interesting article on the popular Slashdot news service. It was later extended to describe any similar effect from being listed on a popular site.[3]&lt;/p&gt;&lt;p&gt;The effect has been associated with other websites or metablogs such as Fark, Digg, Drudge Report, Imgur, Reddit, and Twitter, leading to terms such as being farked or drudged, being under the Reddit effect, or receiving a hug of death from the site in question.[4][5] Another generic term, "flash crowd,"[6] originates from Larry Niven's 1973 novella by that name, in which the invention of inexpensive teleportation allows crowds to materialize almost instantly at the sites of interesting news stories.&lt;/p&gt;&lt;head rend="h2"&gt;Cause&lt;/head&gt;[edit]&lt;p&gt;Sites such as Slashdot, Digg, Reddit, StumbleUpon, and Fark consist of brief submitted stories and a self-moderated discussion on each story. The typical submission introduces a news item or website of interest by linking to it. In response, large masses of readers tend to simultaneously rush to view the referenced sites. The ensuing flood of page requests from readers can exceed the site's available bandwidth or the ability of its servers to respond, and render the site temporarily unreachable.&lt;/p&gt;&lt;p&gt;Google Doodles, which link to search results on the doodle topic, also result in high increases of traffic from the search results page.[7]&lt;/p&gt;&lt;head rend="h2"&gt;Extent&lt;/head&gt;[edit]&lt;p&gt;Major news sites or corporate websites are typically engineered to serve large numbers of requests and therefore do not normally exhibit this effect. Websites that fall victim may be hosted on home servers, offer large images or movie files or have inefficiently generated dynamic content (e.g. many database hits for every web hit even if all web hits are requesting the same page). These websites often became unavailable within a few minutes of a story's appearance, even before any comments had been posted. Occasionally, paying Slashdot subscribers (who have access to stories before non-paying users) rendered a site unavailable even before the story was posted for the general readership.&lt;/p&gt;&lt;p&gt;Few definitive numbers exist regarding the precise magnitude of the Slashdot effect, but estimates put the peak of the mass influx of page requests at anywhere from several hundred to several thousand hits per minute.[8][9][10] The flood usually peaked when the article was at the top of the site's front page and gradually subsided as the story was superseded by newer items. Traffic usually remained at elevated levels until the article was pushed off the front page, which could take from 12 to 18 hours after its initial posting. However, some articles had significantly longer lifetimes due to the popularity, newsworthiness, or interest in the linked article.&lt;/p&gt;&lt;p&gt;By 2005, reporters were commenting that the Slashdot effect had been diminishing.[2] However, the effect has been seen involving Twitter when some popular users mention a website.[11]&lt;/p&gt;&lt;p&gt;When the targeted website has a community-based structure, the term can also refer to the secondary effect of having a large group of new users suddenly set up accounts and start to participate in the community. While in some cases this has been considered a good thing, in others it is viewed with disdain by the prior members, as quite often the sheer number of new people brings many of the unwanted aspects of Slashdot along with it, such as trolling, vandalism, and newbie-like behavior. This bears some similarity to the 1990s Usenet concept of Eternal September.&lt;/p&gt;&lt;head rend="h2"&gt;Assistance and prevention&lt;/head&gt;[edit]&lt;p&gt;Many solutions have been proposed for sites to deal with the Slashdot effect.[12]&lt;/p&gt;&lt;p&gt;There are several systems that automatically mirror any Slashdot-linked pages to ensure that the content remains available even if the original site becomes unresponsive.[13] Sites in the process of being Slashdotted may be able to mitigate the effect by temporarily redirecting requests for the targeted pages to one of these mirrors. Slashdot does not mirror the sites it links to on its own servers, nor does it endorse a third party solution. Mirroring of content may constitute a breach of copyright and, in many cases, cause ad revenue to be lost for the targeted site.&lt;/p&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ Ari, Ismail; Hong, Bo; Miller, Ethan L.; Brandt, Scott A.; Long, Darrell D. E. (October 2003). "Managing Flash Crowds on the Internet" (PDF). University of California Santa Cruz Storage Systems Research Center. Archived from the original (PDF) on 9 May 2013. Retrieved 15 March 2010.&lt;/item&gt;&lt;item&gt;^ a b Kharif, Olga (March 2, 2005). "Less Impact from the "Slashdot Effect". Bloomberg Business Week. Archived from the original on May 15, 2005.&lt;/item&gt;&lt;item&gt;^ Eric S. Raymond. "slashdot effect". The Jargon File, version 4.4.8. Retrieved 21 May 2012.&lt;/item&gt;&lt;item&gt;^ Wilhelm, Alex (17 January 2012). "How Reddit turned one congressional candidate's campaign upside down". The Next Web. Retrieved 24 October 2012.&lt;/item&gt;&lt;item&gt;^ "The Reddit effect". ABC News. August 31, 2012. Archived from the original on 1 November 2014. Retrieved 24 October 2012.&lt;/item&gt;&lt;item&gt;^ Eric S. Raymond. "flash crowd". The Jargon File (version 4.4.7). Retrieved 25 May 2012.&lt;/item&gt;&lt;item&gt;^ Williams, David E. "Google's unknown artist has huge following." CNN. July 19, 2006. Retrieved on July 19, 2006.&lt;/item&gt;&lt;item&gt;^ Stephen Adler. "The Slashdot Effect: An Analysis of Three Internet Publications". Archived from the original on 2 December 2008. Retrieved 19 April 2003. (mirror)&lt;/item&gt;&lt;item&gt;^ "Slashdotting graphs". Princeton University Department of Astrophysical Sciences. Archived from the original on 27 February 2009. Retrieved 13 January 2004.&lt;/item&gt;&lt;item&gt;^ Aaron Benoy. "Ruins in ASCII". Retrieved 27 September 2004.&lt;/item&gt;&lt;item&gt;^ Paul Douglas, How Stephen Fry takes down entire websites with a single tweet, Tech Radar, March 3, 2010&lt;/item&gt;&lt;item&gt;^ Jeremy Elson; Jon Howell (2008), Handling Flash Crowds from your Garage (PDF), Microsoft Research&lt;/item&gt;&lt;item&gt;^ Daniel Terdiman (1 October 2004). "Solution for Slashdot Effect?". WIRED. Retrieved 2016-04-18.&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/Slashdot_effect"/><published>2025-11-26T16:12:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46059069</id><title>Slop Detective – Fight the Slop Syndicate</title><updated>2025-11-26T18:13:35.727266+00:00</updated><content>&lt;doc fingerprint="517fd5a9bcf28ee0"&gt;
  &lt;main&gt;
    &lt;p&gt;Slop Detective Streak: | Cases Solved: Please enable JavaScript to play Slop Detective.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://slopdetective.kagi.com/"/><published>2025-11-26T16:24:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46059227</id><title>Cloudflare outage should not have happened</title><updated>2025-11-26T18:13:35.419735+00:00</updated><content>&lt;doc fingerprint="fb1caa726de559eb"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Cloudflare outage should not have happened, and they seem to be missing the point on how to avoid it in the future by Eduardo Bellani&lt;/head&gt;
    &lt;p&gt;Yet again, another global IT outage happen (deja vu strikes again in our industry). This time at cloudflare(Prince 2025). Again, taking down large swats of the internet with it(Booth 2025).&lt;/p&gt;
    &lt;p&gt;And yes, like my previous analysis of the GCP and CrowdStrike’s outages, this post critiques Cloudflare’s root cause analysis (RCA), which — despite providing a great overview of what happened — misses the real lesson.&lt;/p&gt;
    &lt;p&gt;Here’s the key section of their RCA:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Unfortunately, there were assumptions made in the past, that the list of columns returned by a query like this would only include the “default” database:&lt;/p&gt;
      &lt;p&gt;SELECT name, type FROM system.columns WHERE table = ‘http_requests_features’ order by name;&lt;/p&gt;
      &lt;p&gt;Note how the query does not filter for the database name. With us gradually rolling out the explicit grants to users of a given ClickHouse cluster, after the change at 11:05 the query above started returning “duplicates” of columns because those were for underlying tables stored in the r0 database.&lt;/p&gt;
      &lt;p&gt;This, unfortunately, was the type of query that was performed by the Bot Management feature file generation logic to construct each input “feature” for the file mentioned at the beginning of this section.&lt;/p&gt;
      &lt;p&gt;The query above would return a table of columns like the one displayed (simplified example):&lt;/p&gt;
      &lt;p&gt;However, as part of the additional permissions that were granted to the user, the response now contained all the metadata of the r0 schema effectively more than doubling the rows in the response ultimately affecting the number of rows (i.e. features) in the final file output.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;A central database query didn’t have the right constraints to express business rules. Not only it missed the database name, but it clearly needs a distinct and a limit, since these seem to be crucial business rules.&lt;/p&gt;
    &lt;p&gt;So, a new underlying security work manifested the (unintended) potential already there in the query. Since this was by definition unintended, the application code didn’t expect that value to be what it was, and reacted poorly. This caused a crash loop across seemingly all of cloudflare’s core systems. This bug wasn’t caught during rollout because the faulty code path required data that was assumed to be impossible to be generated.&lt;/p&gt;
    &lt;p&gt;Sounds familiar? It should. Any senior engineer has seen this pattern before. This is classic database/application mismatch. With this in mind, let’s review how Cloudflare is planning to prevent this from happening again:&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;Hardening ingestion of Cloudflare-generated configuration files in the same way we would for user-generated input&lt;/item&gt;
      &lt;item&gt;Enabling more global kill switches for features&lt;/item&gt;
      &lt;item&gt;Eliminating the ability for core dumps or other error reports to overwhelm system resources&lt;/item&gt;
      &lt;item&gt;Reviewing failure modes for error conditions across all core proxy modules&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;These are all solid, reasonable steps. But here’s the problem: they already do most of this—and the outage happened anyway.&lt;/p&gt;
    &lt;p&gt;Why? Because of they seem to mistake physical replication with not having a single point of failure. This mistakes the physical layer with the logical layer. One can have a logical single point of failure without having any physical one, which was the case in this situation.&lt;/p&gt;
    &lt;p&gt;I base my paragraph on their choice of abandoning PostgreSQL and adopting ClickHouse(Bocharov 2018). The whole post is a great overview on trying to process data fast, without a single line on how to garantee its logical correctness/consistency in the face of changes.&lt;/p&gt;
    &lt;p&gt;They are treating a logical problem as if it was a physical problem&lt;/p&gt;
    &lt;p&gt;I’ll repeat the same advice I offered in my previous article on GCP’s outage:&lt;/p&gt;
    &lt;head rend="h2"&gt;The real cause&lt;/head&gt;
    &lt;p&gt;These kinds of outages stem from the uncontrolled interaction between application logic and database schema. You can’t reliably catch that with more tests or rollouts or flags. You prevent it by construction—through analytical design.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;No nullable fiels.&lt;/item&gt;
      &lt;item&gt;(as a cororally of 1) full normalization of the database (The principles of database design, or, the Truth is out there)&lt;/item&gt;
      &lt;item&gt;formally verified application code(Chapman et al. 2024)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;FAANG-style companies are unlikely to adopt formal methods or relational rigor wholesale. But for their most critical systems, they should. It’s the only way to make failures like this impossible by design, rather than just less likely.&lt;/p&gt;
    &lt;p&gt;The internet would thank them. (Cloud users too—caveat emptor.)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ebellani.github.io/blog/2025/cloudflare-outage-should-not-have-happened-and-they-seem-to-be-missing-the-point-on-how-to-avoid-it-in-the-future/"/><published>2025-11-26T16:34:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46059620</id><title>Optery (YC W22) Hiring CISO, Release Manager, Tech Lead (Node), Full Stack Eng</title><updated>2025-11-26T18:13:35.068702+00:00</updated><content>&lt;doc fingerprint="ca6bb85f43b74372"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Careers&lt;/head&gt;
    &lt;p&gt;💡Page not loading? Optery’s Career page uses Cookies to display the full page content. If you’re not seeing anything, try opening the cookie banner (cookie icon in the bottom left corner) and Accept Personalization cookies.&lt;/p&gt;
    &lt;p&gt;💡Page not loading? Optery’s Career page uses Cookies to display the full page content. If you’re not seeing anything, try opening the cookie banner (cookie icon in the bottom left corner) and Accept Personalization cookies.&lt;/p&gt;
    &lt;p&gt;Ready to safeguard your personal data?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.optery.com/careers/"/><published>2025-11-26T17:03:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46059737</id><title>DRAM prices are spiking, but I don't trust the industry's why</title><updated>2025-11-26T18:13:34.564978+00:00</updated><content>&lt;doc fingerprint="3826959d8cb231a8"&gt;
  &lt;main&gt;
    &lt;p&gt;RAM prices have skyrocketed globally in 2025, with industry officials pointing to explosive demand from AI data centers as the primary cause. Mainstream DDR5 memory modules now cost at least twice what they did in mid-2025, and overall DRAM contract prices were a stunning 171.8% higher in the third quarter of 2025 compared to a year prior. For context, these increases have even outpaced the surge in gold prices over the same period, which has also seen a surge in price given economic fears and overall uncertainty. Manufacturers and analysts are now warning us that we're at the start of a major DRAM bull market, with shortages expected to continue into 2026.&lt;/p&gt;
    &lt;p&gt;With all of that said, the memory industry has a bit of history with regard to price-fixing. While I'm sure that there are perfectly natural market forces at play, here, there's a lot of room for skepticism, too.&lt;/p&gt;
    &lt;head rend="h2"&gt;A global surge in memory pricing&lt;/head&gt;
    &lt;head rend="h3"&gt;Some context, first&lt;/head&gt;
    &lt;p&gt;The price spike in memory (especially DRAM) is being felt worldwide. Contract prices for server and PC memory have climbed steeply through 2025, and these increases are now trickling down to retail. For example, a standard 32GB Corsair RAM kit I found on Amazon, specifically 6000 MHz DDR5, cost $110 at the start of this year. Now it costs a whopping $442 after a long period of time where it was out of stock. That quadrupling in price in less than a year highlights just how quickly the market has turned. In other regions, prices have jumped at a similar scale, and there have been reports of retailers even rationing sales of memory modules due to limited supply. In Japan, certain shops have even capped the quantity of HDDs, SSDs, and RAM that a customer can buy because deliveries are so scarce, and memory kit launches are being delayed, too.&lt;/p&gt;
    &lt;p&gt;This isn't just a DRAM story, either. NAND flash memory and hard drive prices are rising in tandem, all caught in the same squeeze of demand that's affecting everything. Back in September, both DRAM and NAND flash contract prices were climbing by 15 to 20%, and that trend has accelerated as we enter the final quarter of the year. Major cloud providers have reportedly agreed to pay up to 50% higher prices for memory chips than they did in the previous quarter. Plus, even despite those premiums, some companies report only receiving approximately 70% of the server memory that they ordered, and smaller buyers are receiving even less. Memory is being allocated to those with deeper pockets first, and it's affecting everything.&lt;/p&gt;
    &lt;p&gt;Anyone looking to upgrade or build a PC will have noticed the crazy-high RAM prices that are now taking hold. The cost savings from cheaper CPUs or GPUs this year are being wiped out by memory kit price hikes. Even now, desktop DDR5 memory modules cost roughly double what they did just a few months ago, and this adds significant expense to any build. And if you thought you could go to older DDR4 modules instead, then think again. Those are also getting pricier as they become scarcer, and that's because DDR4 is being phased out of production. Companies like Samsung, SK Hynix, and Micron are extending how long they're producing it for, but production was supposed to have stopped by now, and it's unlikely that they're producing it at the same rate they used to.&lt;/p&gt;
    &lt;p&gt;It's not just consumers and AI companies that are feeling the pressure; companies that produce devices like laptops, smartphones, and graphics cards are feeling the squeeze, too. Major PC OEMs and system integrators have started panic-buying and stockpiling RAM to secure supply, and Asus has said that it only has about two months of inventory left for production. Embedded devices aren't exempt either, and the Raspberry Pi Foundation, which had stockpiled memory ahead of time, was forced to increase the prices of its 4GB and 8GB models by $5 and $10, respectively, because memory now costs "roughly 120% more than it did a year ago," according to Raspberry Pi Holdings CEO Eben Upton.&lt;/p&gt;
    &lt;p&gt;Even data centers aren't safe from the chaos they've created, and some analysts estimate the world's largest memory maker, Samsung, have imposed such steep price hikes that they could push AI server costs up by 10% to 25% for cloud operators. If things worsen to the point of not being able to get any stock at all, hyperscalers may have to slow down their AI data center deployments because they simply can't get enough memory to actually build out their data centers. Plus, because AI servers are devouring both DRAM and storage, it's causing a cascading effect. High-capacity HDDs (which are used for data center storage) are on backorder for a year or more, and with disk drives scarce, cloud companies are turning to flash storage (SSDs) in roles traditionally filled by disks. This simultaneous strain on NAND flash and HDDs is unprecedented, as when one was constrained, the other often acted as a fallback.&lt;/p&gt;
    &lt;head rend="h2"&gt;AI is the official explanation&lt;/head&gt;
    &lt;head rend="h3"&gt;An absurd amount of DRAM is going to just a few companies&lt;/head&gt;
    &lt;p&gt;The explanation from industry leaders is centered around a perfect storm of both booming demand and constrained supply, and the narrative from most companies in the space backs that assertion up. Generative AI requires a huge amount of both memory and storage, as training and running models require data centers filled with GPUs; GPUs that can have hundreds of gigabytes of DRAM paired with multiple terabytes of flash storage. For example, OpenAI's new "Stargate" project reportedly signed deals with Samsung and SK Hynix for up to 900,000 wafers of DRAM per month to feed its AI clusters, which is an amount close to 40% of total global DRAM output if it's ever met. That's an absurd amount of DRAM. Similarly, cloud providers are pre-buying years' worth of memory. Micron, as another example, has already presold essentially all of its HBM (High Bandwidth Memory) chip output essentially through 2026, and Samsung's next-gen V9 NAND flash is nearly fully booked by enterprise customers before launch, though that's a problem that technically started in September 2024.&lt;/p&gt;
    &lt;p&gt;On the supply side, only a few companies produce the vast majority of the world's memory chips, and they were clearly not prepared for this surge. The DRAM industry is an oligopoly of basically three major players; Samsung, SK Hynix, and Micron. Over the past decades, the memory market's brutal boom and bust cycles drove many competitors out, leaving just these few big suppliers. This matters because with so few producers, any strategic choices they make (or don't make) have outsized impact on supply. In this cycle, manufacturers had cut back production and investment during the last downturn (2022), and they've been slow to ramp back up. To make matters worse, with a suspected AI bubble that could pop at any moment, it seems that memory makers have no plans to significantly increase overall DRAM production as a result of potential market volatility. In an interview with Taiwanese CommonWealth Magazine, Pua Khein-Seng, CEO of Phison, said the following:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;NAND will face severe shortages next year. I think supply will be tight for the next ten years. In the past, every time flash makers invested more, prices collapsed, and they never recouped their investments. So companies slowed spending starting around 2019–2020. Then in 2023, Micron and SK Hynix redirected huge CapEx into HBM because the margins were so attractive, leaving even less investment for flash.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Another factor limiting supply of standard RAM is that memory firms are diverting their limited manufacturing capacity to the most lucrative products. Specifically, there's a gold rush for HBM, which is a special kind of memory used by AI accelerator GPUs, because HBM commands far higher prices and profit margins than commodity DRAM. Every wafer a company allocates to making HBM for GPUs is one not used to make standard PC or server DRAM, so from the point of view of a major company, why bother investing in the consumer-grade or regular data-center hardware when the same resources can be used to make something with a much higher return? These companies ran out of HBM last year, and if production was shifted towards HBM, then they can gain a higher return on each wafer while also increasing the price of regular DRAM, too.&lt;/p&gt;
    &lt;p&gt;When it comes to DDR4, given those phase-out timelines given by the major producers, some smaller Chinese companies (like CXMT and Jinhua) are stepping in to make DDR4 and undercut prices, but they haven't fully filled the void. This story may sound familiar; when DDR3 was phased out, the big players exited in the same way. Essentially, the industry says that this is all a supply-and-demand imbalance, with demand from AI and cloud shooting up and supply being unable (and unwilling) to catch up. Many will argue that there's nothing nefarious going on, and it's all caused by unfortunate timing and caution from the companies that produce global DRAM supplies. If AI proves to be a bubble that bursts, memory firms will end up with another price crash like what has happened in the past.&lt;/p&gt;
    &lt;head rend="h2"&gt;DRAM producers have artificially inflated prices before&lt;/head&gt;
    &lt;head rend="h3"&gt;And all of them are benefiting right now&lt;/head&gt;
    &lt;p&gt;Look, there are a lot of plausible factors that we've already highlighted that could cause pressure on pricing, but there's a lot of room for skepticism, too. I'm not saying that all of these reasons given aren't the cause for the recent price boom, but what I am saying is that it wouldn't be the first time that price-fixing occurred in the memory industry. The DRAM market, being dominated by three main players, has crossed the line into illegal, price-fixing cartels. In the early 2000s, multiple memory manufacturers pleaded guilty to conspiring to fix DRAM prices between 1998 and 2002, resulting in hundreds of millions of dollars in fines given out to a few manufacturers, including the big three that survive to this day: SK Hynix, Samsung, and Micron. More recently, during the big DRAM price run-up in the middle of 2016 and the start of 2018 (where prices nearly tripled in a year and a half), a class-action lawsuit accused the big three of colluding to restrict supply in order to inflate prices. That more recent class action lawsuit was brought by the same firm that brought the original class action suit in the early 2000s against those same companies, which coincided with the U.S. Department of Justice investigation. While that second lawsuit didn't hold up in court (and failed in appeal), that ongoing suspicion exists for a reason.&lt;/p&gt;
    &lt;p&gt;All of this history shows one thing: memory suppliers have both the motive and precedent to coordinate behavior, even tacitly, in order to keep prices high. When only a handful of firms control the taps, it doesn't take a formal cartel for them to collectively benefit from constrained supply. Each firm knows that flooding the market would hurt all of their profits, so a form of unspoken coordination can occur, and this is next to impossible to prove. The backdrop of past cartels makes it hard not to be cynical when hearing that "AI demand" is solely to blame for increased prices. Whether or not any collusion is happening now, it's clear that memory companies are profiting immensely from the current crisis. After bleeding financially during the last oversupply downturn, the major DRAM makers are now seeing record-high earnings in the third quarter of 2025 thanks to the price surge, and to put it bluntly, the shortage is great for business.&lt;/p&gt;
    &lt;p&gt;Meanwhile, these same companies are not rushing to add capacity that would ease prices, a fact justified by fear of an AI bubble, but which also conveniently prolongs their windfall. Memory suppliers have shifted to higher-profit chips (like HBM) and aren't exactly trying to temper the increases in demand. Instead, they're facilitating it at higher prices. It's worth noting that the big three DRAM makers have all taken a similarly cautious (and profit-preserving) approach this DRAM cycle. All have cut back on older products (like DDR4), all are prioritizing higher-margin AI-related memory, and none are dramatically boosting standard DRAM output or engaging in a price war to gain market share. In effect, supply is being "redirected" in unison. All three firms seem to be stockpiling capital rather than building new fabs immediately, despite the obvious need. Micron, for example, has plans for new fabrication plants (one in New York, one expansion in Idaho), but it has delayed some of those projects by years, all while reportedly pushing out its new U.S. DRAM megafab by two to three years due to market uncertainty, even as it accelerates niche projects like an HBM fab.&lt;/p&gt;
    &lt;p&gt;It's hard not to see this supposedly coincidental aligned strategy of restraint and wonder if there's something more at play. All of these actions support pricing stability (for those companies) and suggests that no one is "breaking ranks" to grab a larger share by undercutting prices. In a truly competitive scenario, at least one player might be tempted to boost production and capture the extraordinary demand, even if it meant driving prices down, in order to grow their market share and revenue. We haven't seen that; instead we see a cautious, unified approach across the three major players. Three major players that have, in the past, been accused of price-fixing.&lt;/p&gt;
    &lt;p&gt;I'd argue that it’s not conspiracy theory territory to be skeptical of the official reasoning. To be clear, AI demand is real and is a major factor, and we've seen the impact it's had on all kinds of markets. The numbers don't lie about huge new consumption of memory, but it's easy to be suspicious given that the memory industry's structure just so happens to benefit the three companies that control practically all of it when supply is constrained in this way. One could make the case that companies will have an attitude along the lines of "Never let a good crisis go to waste," while memory vendors would counter that they are merely being cautious and that they'll invest in new capacity once they're sure this demand isn't merely a mirage.&lt;/p&gt;
    &lt;head rend="h2"&gt;Things don't look to be getting better&lt;/head&gt;
    &lt;head rend="h3"&gt;It'll be more than a year at least&lt;/head&gt;
    &lt;p&gt;This current trend is complex, and on the surface, it's being driven by something that is genuinely transformative to the wider industry as a whole. The rise of AI and data centers that consume far more memory and storage than traditional computing ever did is certainly a factor, and that real demand surge, combined with the slow ramp of supply, is definitely a large portion of the price increases and shortages we're seeing. However, with so few companies controlling the market, alongside their decisions to prioritize profits, cut back older products, and cautiously avoid overproduction, have all lent credence to allegations that something bigger may be at play. After all, history shows that these firms have skirted the line between smart business and anti-consumer collusion before.&lt;/p&gt;
    &lt;p&gt;All in all, both things can be true. The AI revolution can be driving unprecedented demand for memory, while the memory giants are more than happy to not fully ease the supply pressure because it's basically printing money for them. Unfortunately, everyone else is caught in the middle, and it's not just consumers feeling the pressure, either. AMD is reportedly thinking about increasing the price of its GPUs as a result, and when companies exhaust their memory supplies for laptops and other hardware, those costs will likely rise as well. It's hard to justify building a PC right now, especially because it's unclear when all of this uncertainty will end.&lt;/p&gt;
    &lt;p&gt;But that's the question most people are wondering the answer to: when will it end? Unfortunately, it looks likely to extend well into 2026, and as we already noted, the CEO of Phison thinks it could be a decade. The only way things will improve is if either the supposed AI bubble pops and the demand cools off, or more manufacturing capabilities come online. If companies started to purchase less DRAM as a result of memory prices rising so high that they start delaying purchases, that could well be a good sign that the tides will turn, but for now, it's clear that cheap, plentiful RAM is no more. Right now, whether initial skepticism turns out to be right or wrong, one thing is true: the house is winning, and everyone else is paying the price.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.xda-developers.com/dram-prices-spiking-dont-trust-industry-reasons/"/><published>2025-11-26T17:12:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46060122</id><title>Scaleway turns Mac minis into high‑density, Raspberry Pi–managed servers</title><updated>2025-11-26T18:13:33.510024+00:00</updated><content>&lt;doc fingerprint="ddd8ce054702a3ec"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Scaleway’s Mac Mini Meets Virtual Private Cloud&lt;/head&gt;
    &lt;p&gt;Scaleway takes another step forward by offering VPC (Virtual Private Cloud) integration for its Apple Silicon Mac mini servers.&lt;/p&gt;
    &lt;p&gt;Take a behind-the-scenes look at how Scaleway brought the Mac mini as-a-Service to life — transforming Apple’s compact desktop into a highly available cloud server hosted in state-of-the-art datacenters.&lt;/p&gt;
    &lt;p&gt;Apple designs the Mac mini. inmac wstore supplies it. Scaleway transforms it into a ready-to-use dedicated server, accessible remotely from anywhere in the world.&lt;/p&gt;
    &lt;p&gt;Scaleway’s mission is clear: to provide iOS and macOS developers, macOS software users, and businesses of all sizes with remote access to the power of Apple silicon (M-series) chips — all within a controlled, secure, and high-performance environment.&lt;/p&gt;
    &lt;p&gt;Each Mac mini is managed automatically. Once installed in the racks, Scaleway’s teams add a custom Mobile Device Management (MDM) profile to deploy system settings remotely, along with a set of server-specific tools that compensate for the lack of a Baseboard Management Controller (BMC). This enables granular management of each machine.&lt;/p&gt;
    &lt;p&gt;Thanks to this process, we at Scaleway can deliver a consumer-grade Mac mini as a fully reliable dedicated server, seamlessly integrated into our cloud ecosystem — ready to meet even the most demanding production needs.&lt;/p&gt;
    &lt;p&gt;All Scaleway Mac minis are hosted exclusively in French datacenters, ensuring sovereign hosting that meets the highest standards for security, privacy, and data locality in Europe.&lt;/p&gt;
    &lt;p&gt;At the heart of this infrastructure lies Opcore DC2, Scaleway’s strategic datacenter located in Vitry-sur-Seine, where hundreds of Mac minis run side by side with traditional bare-metal servers — all within a resilient, high-performance network architecture monitored in real time.&lt;/p&gt;
    &lt;p&gt;Scaleway’s datacenter design reflects its commitment to performance and reliability:&lt;/p&gt;
    &lt;p&gt;The Mac mini wasn’t originally designed for datacenter environments: there’s no BMC (Baseboard Management Controller), no native remote firmware access, and no standard rackmount format.&lt;/p&gt;
    &lt;p&gt;To overcome this, Scaleway engineered a custom chassis where each Mac mini is placed in an individual sliding tray. This allows any unit to be removed for maintenance without disrupting the others — ensuring maximum density and ease of access. Ethernet cabling is carefully organized to guarantee fast, stable network connections.&lt;/p&gt;
    &lt;p&gt;Each rack can hold up to 96 Mac minis, an impressive density compared to traditional servers. This is made possible by two key factors:&lt;/p&gt;
    &lt;p&gt;As a result, Scaleway’s Mac mini racks are among the most energy-efficient server setups in the cloud industry.&lt;/p&gt;
    &lt;p&gt;However, the absence of a BMC posed a major challenge: how to perform critical remote operations without physical access?&lt;/p&gt;
    &lt;p&gt;Scaleway’s solution to that problem was ingenious: embedding a Raspberry Pi module with each Mac mini.&lt;/p&gt;
    &lt;p&gt;Each Raspberry Pi acts as a control layer, sending commands such as reboot or remote reinstall to the Mac mini. This makes the machines virtually autonomous throughout their cloud lifecycle, while remaining fully compliant with Apple’s hardware requirements.&lt;/p&gt;
    &lt;p&gt;Scaleway plans to keep expanding its Mac mini fleet as cloud-native development evolves. Future versions of macOS, the rise of AI workloads, and the growing need for macOS environments in cross-platform development are all driving demand.&lt;/p&gt;
    &lt;p&gt;With Mac mini as-a-Service, Scaleway delivers a powerful, flexible solution designed for developers, tech companies, and demanding freelancers alike.&lt;/p&gt;
    &lt;p&gt;Access the power of a Mac as if it were on your desk — without the hardware constraints.&lt;/p&gt;
    &lt;p&gt;ai-PULSE, Europe’s premier Artificial Intelligence conference powered by Scaleway, is returning!&lt;/p&gt;
    &lt;p&gt;Gathering key players from across Europe, the event will be back once again at STATION F on December 4 for a unique blend of deep technical expertise and crucial business insights.&lt;/p&gt;
    &lt;p&gt;You’ll hear from:&lt;/p&gt;
    &lt;p&gt;... and dozens more leaders and engineers shaping the technology’s future.&lt;/p&gt;
    &lt;p&gt;Whether you’re planning to attend in-person or online, make sure to register!&lt;/p&gt;
    &lt;p&gt;Scaleway takes another step forward by offering VPC (Virtual Private Cloud) integration for its Apple Silicon Mac mini servers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.scaleway.com/en/blog/how-we-turn-apples-mac-mini-into-high-performance-dedicated-servers/"/><published>2025-11-26T17:40:16+00:00</published></entry></feed>