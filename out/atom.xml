<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-12-26T15:11:19.990923+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46363870</id><title>Show HN: GeneGuessr – a daily biology web puzzle</title><updated>2025-12-26T15:11:30.466294+00:00</updated><content>&lt;doc fingerprint="bb7da7a56e64d3c2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;GeneGuessr - Daily Protein Guessing Game&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Play GeneGuessr&lt;/head&gt;
    &lt;head rend="h3"&gt;Welcome to GeneGuessr!&lt;/head&gt;
    &lt;p&gt;This is the protein of the day. Can you figure out which gene made it?&lt;/p&gt;
    &lt;p&gt;You will see spoiler bars that cover valuable hints. Tap the spoiler bar to reveal a hint underneath.&lt;/p&gt;
    &lt;p&gt;Look up your favorite gene with the search bar. Submit it as your first guess.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedback cards&lt;/head&gt;
    &lt;p&gt;Each of your guesses will appear as a feedback card.&lt;/p&gt;
    &lt;p&gt;The feedback bar percentage shows how close you got.&lt;/p&gt;
    &lt;p&gt;Look for highlighted properties. They match your target.&lt;/p&gt;
    &lt;head rend="h3"&gt;Revealing hints&lt;/head&gt;
    &lt;p&gt;It costs 1 hint to remove a spoiler bar. You get +1 hint for each guess.&lt;/p&gt;
    &lt;p&gt;When the hint is too obvious, the bar stays locked. Just try unlocking another one.&lt;/p&gt;
    &lt;p&gt;You get to make 10 guesses before the game ends. Feel free to experiment!&lt;/p&gt;
    &lt;p&gt; Protein data: UniProt &lt;/p&gt;
    &lt;p&gt; Gene nomenclature: HGNC &lt;/p&gt;
    &lt;p&gt; Gene summaries: NCBI Gene &lt;/p&gt;
    &lt;p&gt; Gene Ontology: GO Consortium &lt;/p&gt;
    &lt;p&gt; Architecture: CATH &lt;/p&gt;
    &lt;p&gt; Pathway data: Reactome &lt;/p&gt;
    &lt;p&gt; Tissue specificity: Human Protein Atlas RNA expression (tau metric) &lt;/p&gt;
    &lt;p&gt; 3D structures: RCSB PDB, AlphaFold DB, SWISS-MODEL &lt;/p&gt;
    &lt;p&gt; Structure viewer: Mol* (via PDBe integration) &lt;/p&gt;
    &lt;p&gt; Origin age: Litman T &amp;amp; Stein WD (2019). Obtaining estimates for the ages of all the protein-coding genes and most of the ontology-identified noncoding genes of the human genome, assigned to 19 phylostrata Semin Oncol 46(1):3-9 &lt;/p&gt;
    &lt;p&gt; First publication year: Zwick ME, Kraemer SA &amp;amp; Carter GW (2019). Dataset of frequency patterns of publications for human protein-coding genes. Data Brief 28:104770 &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://geneguessr.brinedew.bio/"/><published>2025-12-23T09:40:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46379173</id><title>Keystone (YC S25) is hiring engineer #1 to automate coding</title><updated>2025-12-26T15:11:30.087006+00:00</updated><content>&lt;doc fingerprint="233a92f07e6fe468"&gt;
  &lt;main&gt;
    &lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;
    &lt;p&gt;About Keystone&lt;/p&gt;
    &lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
    &lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
    &lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
    &lt;p&gt;About the Role&lt;/p&gt;
    &lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
    &lt;p&gt;Example projects:&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you:&lt;/p&gt;
    &lt;p&gt;Stack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
    &lt;p&gt;Comp &amp;amp; benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
    &lt;p&gt;To apply: submit an application here on workatastartup.com or email founders [at] withkeystone [dot] com with “Keystone Founding Engineer” in the subject line. I will reply to all such emails.&lt;/p&gt;
    &lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer"/><published>2025-12-24T21:01:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46384167</id><title>Python 3.15’s interpreter for Windows x86-64 should hopefully be 15% faster</title><updated>2025-12-26T15:11:29.969878+00:00</updated><content>&lt;doc fingerprint="2e649111fe3785d0"&gt;
  &lt;main&gt;
    &lt;p&gt;24 December 2025&lt;/p&gt;
    &lt;p&gt;Some time ago I posted an apology piece for Python’s tail calling results. I apologized for communicating performance results without noticing a compiler bug had occured.&lt;/p&gt;
    &lt;p&gt;I can proudly say today that I am partially retracting that apology, but only for two platforms—macOS AArch64 (XCode Clang) and Windows x86-64 (MSVC).&lt;/p&gt;
    &lt;p&gt;In our own experiments, the tail calling interpreter for CPython was found to beat the computed goto interpreter by 5% on pyperformance on AArch64 macOS using XCode Clang, and roughly 15% on pyperformance on Windows on an experimental internal version of MSVC. The Windows build is against a switch-case interpreter, but this in theory shouldn’t matter too much, more on that in the next section.&lt;/p&gt;
    &lt;p&gt;This is of course, a hopefully accurate result. I tried to be more diligent here, but I am of course not infallible. However, I have found that sharing early and making a fool of myself often works well, as it has led to people catching bugs in my code, so I shall continue doing so :).&lt;/p&gt;
    &lt;p&gt;Also this assumes the change doesn’t get reverted later in Python 3.15’s development cycle.&lt;/p&gt;
    &lt;p&gt;Just a recap. There are two popular current ways of writing C-based interpreters.&lt;/p&gt;
    &lt;p&gt;Switch-cases:&lt;/p&gt;
    &lt;code&gt;switch (opcode) {
    case INST_1: ...
    case INST_2: ...
}
&lt;/code&gt;
    &lt;p&gt;Where we just switch-case to the correct instruction handler.&lt;/p&gt;
    &lt;p&gt;And the other popular way is a GCC/Clang extension called labels-as-values/computed gotos.&lt;/p&gt;
    &lt;code&gt;goto *dispatch_table[opcode];
INST_1: ...
INST_2: ...
&lt;/code&gt;
    &lt;p&gt;Which is basically the same idea, but to instead jump to the address of the next label. Traditionally, the key optimization here is that it needs only one jump to go to the next instruction, while in the switch-case interpreter, a naiive compiler would need two jumps.&lt;/p&gt;
    &lt;p&gt;With modern compilers however, the benefits of the computed gotos is a lot less, mainly because modern compilers have gotten better and modern hardware has also gotten better. In Nelson Elhage’s excellent investigation on the next kind of interpreter, the speedup of computed gotos over switch case on modern Clang was only in the low single digits on pyperformance.&lt;/p&gt;
    &lt;p&gt;A 3rd way that was suggested decades ago, but not really entirely feasible is call/tail-call threaded interpreters. In this scheme, each bytecode handler is its own function, and we tail-call from one handler to the next in the instruction stream:&lt;/p&gt;
    &lt;code&gt;return dispatch_table[opcode];

PyObject *INST_1(...) {

}

PyObject *INST_2(...) {
}
&lt;/code&gt;
    &lt;p&gt;This wasn’t too feasible in C for one main reason—tail call optimization was merely an optimization. It’s something the C compiler might do, or might not do. This means if you’re unlucky and the C compiler chooses not to perform the tail call, your interpreter might stack overflow!&lt;/p&gt;
    &lt;p&gt;Some time ago, Clang introduced &lt;code&gt;__attribute__((musttail))&lt;/code&gt;, which allowed
for mandating that a call must be tail-called. Otherwise, the compilation
will fail. To my knowledge, the first time this was popularized for use
in a mainstream interpreter was in
Josh Haberman’s Protobuf blog post.&lt;/p&gt;
    &lt;p&gt;Later on, Haoran Xu noticed that the GHC calling convention combined with tail calls produced efficient code. They used this for their baseline JIT in a paper and termed the technique Copy-and-Patch.&lt;/p&gt;
    &lt;p&gt;After using a fixed XCode Clang, our performance numbers on CPython 3.14/3.15 suggest that the tail calling interpreter does provide a modest speedup over computed gotos. Around the 5% geomean range on pyperformance.&lt;/p&gt;
    &lt;p&gt;To my understanding, &lt;code&gt;uv&lt;/code&gt; already ships Python 3.14 on macOS with tail calling,
which might be responsible for some of the speedups you see on there.
We’re planning to ship the official 3.15 macOS binaries on &lt;code&gt;python.org&lt;/code&gt; with
tail calling as well.&lt;/p&gt;
    &lt;p&gt;However, you’re not here for that. The title of this blog post is clearly about MSVC Windows x86-64. So what about that?&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[!CAUTION] The features for MSVC discussed below are to my knowledge, experimental. They are not guaranteed to always be around unless the MSVC team decide to keep them. Use at your own risk!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;These are the preliminary pyperformance results for CPython on MSVC with tail-calling vs switch-case. Any number above 1.00x is a speedup (e.g. &lt;code&gt;1.01x == 1% speedup&lt;/code&gt;), anything below 1.00x is a slowdown.
The speedup is a geomtric mean of around 15-16%, with a
range of ~60% slowdown (one or two outliers) to 78% speedup.
However, the key thing is that the vast majority of benchmaarks sped up!&lt;/p&gt;
    &lt;p&gt;Chart credits to Michael Droettboom&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[!WARNING] These results are on an experimental internal MSVC compiler, public results below.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;To verify this and make sure I wasn’t wrong yet again, I checked the results on my machine with Visual Studio 2026. These are the results from this issue.&lt;/p&gt;
    &lt;code&gt;Mean +- std dev: [spectralnorm_tc_no] 146 ms +- 1 ms -&amp;gt; [spectralnorm_tc] 98.3 ms +- 1.1 ms: 1.48x faster
Mean +- std dev: [nbody_tc_no] 145 ms +- 2 ms -&amp;gt; [nbody_tc] 107 ms +- 2 ms: 1.35x faster
Mean +- std dev: [bm_django_template_tc_no] 26.9 ms +- 0.5 ms -&amp;gt; [bm_django_template_tc] 22.8 ms +- 0.4 ms: 1.18x faster
Mean +- std dev: [xdsl_tc_no] 64.2 ms +- 1.6 ms -&amp;gt; [xdsl_tc] 56.1 ms +- 1.5 ms: 1.14x faster
&lt;/code&gt;
    &lt;p&gt;So yeah, the speedups are real! For a large-ish library like xDSL, we see a 14% speedup, while for smaller microbenchmarks like nbody and spectralnorm, the speedups are greater.&lt;/p&gt;
    &lt;p&gt;Thanks to Chris Eibl and Brandt Bucher, we managed to get the PR for this on MSVC over the finish line. I also want to sincerely thank the MSVC team. I can’t say this enough: they have been a joy to work with and I’m very impressed by what they’ve done, and I want to congratulate them on releasing Visual Studio 2026.&lt;/p&gt;
    &lt;p&gt;This is now listed in the What’s New for 3.15 notes:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Builds using Visual Studio 2026 (MSVC 18) may now use the new tail-calling interpreter. Results on an early experimental MSVC compiler reported roughly 15% speedup on the geometric mean of pyperformance on Windows x86-64 over the switch-case interpreter. We have observed speedups ranging from 15% for large pure-Python libraries to 40% for long-running small pure-Python scripts on Windows. (Contributed by Chris Eibl, Ken Jin, and Brandt Bucher in gh-143068. Special thanks to the MSVC team including Hulon Jenkins.)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the documentation for [[msvc::musttail]].&lt;/p&gt;
    &lt;p&gt;I used to believe the the tail calling interpreters get their speedup from better register use. While I still believe that now, I suspect that is not the main reason for speedups in CPython.&lt;/p&gt;
    &lt;p&gt;My main guess now is that tail calling resets compiler heuristics to sane levels, so that compilers can do their jobs.&lt;/p&gt;
    &lt;p&gt;Let me show an example, at the time of writing, CPython 3.15’s interpreter loop is around 12k lines of C code. That’s 12k lines in a single function for the switch-case and computed goto interpreter.&lt;/p&gt;
    &lt;p&gt;This has caused many issues for compilers in the past, too many to list in fact. I have a EuroPython 2025 talk about this. In short, this overly large function breaks a lot of compiler heuristics.&lt;/p&gt;
    &lt;p&gt;One of the most beneficial optimisations is inlining. In the past, we’ve found that compilers sometimes straight up refuse to inline even the simplest of functions in that 12k loc eval loop. I want to stress that this is not the fault of the compiler. It’s actually doing the correct thing—you usually don’t want to increase the code size of something already super large. Unfortunately, this does’t bode well for our interpreter.&lt;/p&gt;
    &lt;p&gt;You might say just write the interpreter in assembly! However, the whole point of this exercise is to not do that.&lt;/p&gt;
    &lt;p&gt;Ok enough talk, let’s take a look at the code now. Taking a real example, we examine &lt;code&gt;BINARY_OP_ADD_INT&lt;/code&gt; which adds two Python integers.
Cleaning up the code so it’s readable, things look like this:&lt;/p&gt;
    &lt;code&gt;TARGET(BINARY_OP_ADD_INT) {
    // Increment the instruction pointer.
    _Py_CODEUNIT* const this_instr = next_instr;
    frame-&amp;gt;instr_ptr = next_instr;
    next_instr += 6;
    _PyStackRef right = stack_pointer[-1];

    // Check that LHS is an int.
    PyObject *value_o = PyStackRef_AsPyObjectBorrow(left);
    if (!_PyLong_CheckExactAndCompact(value_o)) {
        JUMP_TO_PREDICTED(BINARY_OP);
    }

    // Check that RHS is an int.
    // ... (same code as above for LHS)

    // Add them together.
    PyObject *left_o = PyStackRef_AsPyObjectBorrow(left);
    PyObject *right_o = PyStackRef_AsPyObjectBorrow(right);
    res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);

    // If the addition fails, fall back to the generic instruction.
    if (PyStackRef_IsNull(res)) {
        JUMP_TO_PREDICTED(BINARY_OP);
    }

    // Close the references.
    PyStackRef_CLOSE_SPECIALIZED(left, _PyLong_ExactDealloc);
    PyStackRef_CLOSE_SPECIALIZED(right, _PyLong_ExactDealloc);

    // Write to the stack, and dispatch.
    stack_pointer[-2] = res;
    stack_pointer += -1;
    DISPATCH();
}
&lt;/code&gt;
    &lt;p&gt;Seems simple enough, let’s take a look at the assembly for switch-case on VS 2026. Note again, this is a non-PGO build for easy source information, PGO generally makes some of these problems go away, but not all of them:&lt;/p&gt;
    &lt;code&gt;                if (!_PyLong_CheckExactAndCompact(value_o)) {
00007FFC4DE24DCE  mov         rcx,rbx  
00007FFC4DE24DD1  mov         qword ptr [rsp+58h],rax  
00007FFC4DE24DD6  call        _PyLong_CheckExactAndCompact (07FFC4DE227F0h)  
00007FFC4DE24DDB  test        eax,eax  
00007FFC4DE24DDD  je          _PyEval_EvalFrameDefault+10EFh (07FFC4DE258FFh)
...
                res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);
00007FFC4DE24DFF  mov         rdx,rbx  
00007FFC4DE24E02  mov         rcx,r15  
00007FFC4DE24E05  call        _PyCompactLong_Add (07FFC4DD34150h)  
00007FFC4DE24E0A  mov         rbx,rax  
...
                PyStackRef_CLOSE_SPECIALIZED(value, _PyLong_ExactDealloc);
00007FFC4DE24E17  lea         rdx,[_PyLong_ExactDealloc (07FFC4DD33BD0h)]  
00007FFC4DE24E1E  mov         rcx,rsi  
00007FFC4DE24E21  call        PyStackRef_CLOSE_SPECIALIZED (07FFC4DE222A0h) 
&lt;/code&gt;
    &lt;p&gt;Huh… all our functions were not inlined. Surely that must’ve mean they were too big or something right? Let’s look at &lt;code&gt;PyStackReF_CLOSE_SPECIALIZED&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;static inline void
PyStackRef_CLOSE_SPECIALIZED(_PyStackRef ref, destructor destruct)
{
    assert(!PyStackRef_IsNull(ref));
    if (PyStackRef_RefcountOnObject(ref)) {
        Py_DECREF_MORTAL_SPECIALIZED(BITS_TO_PTR(ref), destruct);
    }
}
&lt;/code&gt;
    &lt;p&gt;That looks … inlineable?&lt;/p&gt;
    &lt;p&gt;Here’s how &lt;code&gt;BINARY_OP_ADD_INT&lt;/code&gt; looks with tail calling on VS 2026 (again,
no PGO):&lt;/p&gt;
    &lt;code&gt;                if (!_PyLong_CheckExactAndCompact(left_o)) {
00007FFC67164785  cmp         qword ptr [rax+8],rdx  
00007FFC67164789  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+149h (07FFC67164879h)  
00007FFC6716478F  mov         r9,qword ptr [rax+10h]  
00007FFC67164793  cmp         r9,10h  
00007FFC67164797  jae         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+149h (07FFC67164879h) 
...
                res = _PyCompactLong_Add((PyLongObject *)left_o, (PyLongObject *)right_o);
00007FFC6716479D  mov         eax,dword ptr [rax+18h]  
00007FFC671647A0  and         r9d,3  
00007FFC671647A4  and         r8d,3  
00007FFC671647A8  mov         edx,1  
00007FFC671647AD  sub         rdx,r9  
00007FFC671647B0  mov         ecx,1  
00007FFC671647B5  imul        rdx,rax  
00007FFC671647B9  mov         eax,dword ptr [rbx+18h]  
00007FFC671647BC  sub         rcx,r8  
00007FFC671647BF  imul        rcx,rax  
00007FFC671647C3  add         rcx,rdx  
00007FFC671647C6  call        medium_from_stwodigits (07FFC6706E9E0h)  
00007FFC671647CB  mov         rbx,rax  
...
                PyStackRef_CLOSE_SPECIALIZED(value, _PyLong_ExactDealloc);
00007FFC671647EB  test        bpl,1  
00007FFC671647EF  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0ECh (07FFC6716481Ch)  
00007FFC671647F1  add         dword ptr [rbp],0FFFFFFFFh  
00007FFC671647F5  jne         _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0ECh (07FFC6716481Ch)  
00007FFC671647F7  mov         rax,qword ptr [_PyRuntime+25F8h (07FFC675C45F8h)]  
00007FFC671647FE  test        rax,rax  
00007FFC67164801  je          _TAIL_CALL_BINARY_OP_ADD_INT@@_A+0E4h (07FFC67164814h)  
00007FFC67164803  mov         r8,qword ptr [_PyRuntime+2600h (07FFC675C4600h)]  
00007FFC6716480A  mov         edx,1  
00007FFC6716480F  mov         rcx,rbp  
00007FFC67164812  call        rax  
00007FFC67164814  mov         rcx,rbp  
00007FFC67164817  call        _PyLong_ExactDealloc (07FFC67073DA0h) 
&lt;/code&gt;
    &lt;p&gt;Would you look at that, suddenly our trivial functions get inlined :).&lt;/p&gt;
    &lt;p&gt;You might also say, surely this does not happen on PGO builds? Well the issue I linked above actually says it does! So yeah happy days.&lt;/p&gt;
    &lt;p&gt;Once again I want to stress, this is not the compiler’s fault! It’s just that the CPython interpreter loop is not the best thing to optimize.&lt;/p&gt;
    &lt;p&gt;Unfortunately, for now, you will have to build from source.&lt;/p&gt;
    &lt;p&gt;With VS 2026, after cloning CPython, for a release build with PGO:&lt;/p&gt;
    &lt;code&gt;$env:PlatformToolset = "v145"
./PCbuild/build.bat --tail-call-interp -c Release -p x64 --pgo
&lt;/code&gt;
    &lt;p&gt;Hopefully, we can distribute this in an easier binary form in the future once Python 3.15’s development matures!&lt;/p&gt;
    &lt;p&gt;I was asked for a cross-compiler test. So here’s a quick and dirty toy benchmark of pystones. The last row is the tail call enabled build. All configurations have PGO. On this toy benchmark, we get roughly a 30% uplift. Note that this is unscientific as it was only a sample size of 1 and I cannot disable Turbo Boost on my laptop on Windows for some reason.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Compiler&lt;/cell&gt;
        &lt;cell role="head"&gt;PlatformToolSet&lt;/cell&gt;
        &lt;cell role="head"&gt;Pystones/second (higher is better)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;VS2019&lt;/cell&gt;
        &lt;cell&gt;142&lt;/cell&gt;
        &lt;cell&gt;677544&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;VS2022&lt;/cell&gt;
        &lt;cell&gt;143&lt;/cell&gt;
        &lt;cell&gt;710773&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;VS2026&lt;/cell&gt;
        &lt;cell&gt;145&lt;/cell&gt;
        &lt;cell&gt;682089&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;VS2026+TC&lt;/cell&gt;
        &lt;cell&gt;145&lt;/cell&gt;
        &lt;cell&gt;970306&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fidget-spinner.github.io/posts/no-longer-sorry.html"/><published>2025-12-25T13:02:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46385600</id><title>Clearspace (YC W23) Is Hiring a Founding Network Engineer (VPN and Proxy)</title><updated>2025-12-26T15:11:29.531811+00:00</updated><content>&lt;doc fingerprint="b792f12e5d21eddd"&gt;
  &lt;main&gt;
    &lt;p&gt;Eliminate compulsive phone usage&lt;/p&gt;
    &lt;p&gt;About Clearspace&lt;/p&gt;
    &lt;p&gt;Clearspace is building the intentionality layer of the internet. Our mission is to build technology as effective at protecting human attention as social media is at exploiting it (infinite scrolling, short-form feeds, manipulative notifications, etc). Our category defining mobile app has been featured on Huberman Lab, New York Times Wirecutter, NPR Marketplace, Forbes, TBPN.&lt;/p&gt;
    &lt;p&gt;People that want a better relationship with their devices have nowhere to turn except for willpower. We are building a system allows users to control what their devices see by processing and filtering network traffic against natural language rules.&lt;/p&gt;
    &lt;p&gt;About The Role&lt;/p&gt;
    &lt;p&gt;We’re looking for a networking-obsessed engineer to own the VPN + first-hop policy proxy that powers our AI agent. You don’t need to be an IKEv2 expert, we care more about deep networking intuition, debugging skill, and the desire to go all the way down the stack until the truth reveals itself.&lt;/p&gt;
    &lt;p&gt;You might be a great fit if you’ve built:&lt;/p&gt;
    &lt;p&gt;What You’ll Build&lt;/p&gt;
    &lt;p&gt;Qualifications&lt;/p&gt;
    &lt;p&gt;Nice to Have&lt;/p&gt;
    &lt;p&gt;Compensation&lt;/p&gt;
    &lt;p&gt;At Clearspace we help people reduce compulsive phone usage.&lt;/p&gt;
    &lt;p&gt;We exist to protect people's attention from the exploits of modern technology platforms and make space for the things that matter to them most.&lt;/p&gt;
    &lt;p&gt;We believe the technology to protect someones attention should be just as sophisticated and effective as the tech that is exploiting it and are building a world-class engineering team to arm the world with a comprehensive attention protection stack.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/clearspace/jobs/5LtM86I-founding-network-engineer-at-clearspace"/><published>2025-12-25T17:01:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46386211</id><title>Fahrplan – 39C3</title><updated>2025-12-26T15:11:27.480372+00:00</updated><content>&lt;doc fingerprint="ad728d1d22b2a7ef"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Sat - Day 1 - December 27&lt;/head&gt;
    &lt;head rend="h5"&gt;Opening Ceremony&lt;/head&gt;
    &lt;p&gt;pajowu, Stella&lt;/p&gt;
    &lt;head rend="h5"&gt;All Sorted by Machines of Loving Grace? "AI", Cybernetics, and Fascism and how to Intervene&lt;/head&gt;
    &lt;p&gt;Katika Kühnreich&lt;/p&gt;
    &lt;head rend="h5"&gt;The art of text (rendering)&lt;/head&gt;
    &lt;p&gt;Nicolas Rougier&lt;/p&gt;
    &lt;head rend="h5"&gt;A Tale of Two Leaks: How Hackers Breached the Great Firewall of China&lt;/head&gt;
    &lt;p&gt;Jade Sheffey&lt;/p&gt;
    &lt;head rend="h5"&gt;OpenAutoLab: photographic film processing machine. Fully automatic and DIY-friendly.&lt;/head&gt;
    &lt;p&gt;Kauz&lt;/p&gt;
    &lt;head rend="h5"&gt;Zentrum für Politische Schönheit: Ein Jahr Adenauer SRP+ und der Walter Lübke Memorial Park&lt;/head&gt;
    &lt;p&gt;Stefan Pelzer, Philipp Ruch&lt;/p&gt;
    &lt;head rend="h5"&gt;Demystifying Fuzzer Behaviour&lt;/head&gt;
    &lt;p&gt;Addison&lt;/p&gt;
    &lt;head rend="h5"&gt;ISDN + POTS Telephony at Congress and Camp&lt;/head&gt;
    &lt;p&gt;Harald "LaF0rge" Welte&lt;/p&gt;
    &lt;head rend="h5"&gt;Brennende Wälder und Kommentarspalten - Klimaupdate mit dem FragDenStaat Climate Helpdesk&lt;/head&gt;
    &lt;p&gt;Joschi Wolf&lt;/p&gt;
    &lt;head rend="h5"&gt;Building hardware - easier than ever - harder than it should be&lt;/head&gt;
    &lt;p&gt;Kliment&lt;/p&gt;
    &lt;head rend="h5"&gt;Neuroexploitation by Design: Wie Algorithmen in Glücksspielprodukten sich Wirkweisen des Reinforcement Learning und dopaminergen Belohnungssystems zunutze machen&lt;/head&gt;
    &lt;p&gt;Elke Smith&lt;/p&gt;
    &lt;head rend="h5"&gt;FeTAp 611 unplugged: Taking a rotary dial phone to the mobile age&lt;/head&gt;
    &lt;p&gt;Michael Weiner&lt;/p&gt;
    &lt;head rend="h5"&gt;Who cares about the Baltic Jammer? – Terrestrial Navigation in the Baltic Sea Region&lt;/head&gt;
    &lt;p&gt;Lars, Niklas Hehenkamp, Markus&lt;/p&gt;
    &lt;head rend="h5"&gt;Liberating Bluetooth on the ESP32&lt;/head&gt;
    &lt;p&gt;Antonio Vázquez Blanco (Antón)&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaos macht Küche&lt;/head&gt;
    &lt;p&gt;Ingwer Andersen&lt;/p&gt;
    &lt;head rend="h5"&gt;Developing New Medicines in the Age of AI and Personalized Medicine&lt;/head&gt;
    &lt;p&gt;Dennis Özcelik&lt;/p&gt;
    &lt;head rend="h5"&gt;Endlich maschinenlesbare Urteile! Open access für Juristen&lt;/head&gt;
    &lt;p&gt;Beata Hubrig, Nuri Khadem-Al-Charieh&lt;/p&gt;
    &lt;head rend="h5"&gt;Opening pAMDora's box and unleashing a thousand paths on the journey to play Beatsaber custom songs&lt;/head&gt;
    &lt;p&gt;tihmstar&lt;/p&gt;
    &lt;head rend="h5"&gt;Not an Impasse: Child Safety, Privacy, and Healing Together&lt;/head&gt;
    &lt;p&gt;Kate Sim&lt;/p&gt;
    &lt;head rend="h5"&gt;KIM 1.5: Noch mehr Kaos In der Medizinischen Telematikinfrastruktur (TI)&lt;/head&gt;
    &lt;p&gt;Christoph Saatjohann&lt;/p&gt;
    &lt;head rend="h5"&gt;RedScout42 – Zur digitalen Wohnungsfrage&lt;/head&gt;
    &lt;p&gt;Sandra, Leonard&lt;/p&gt;
    &lt;head rend="h5"&gt;All my Deutschlandtickets gone: Fraud at an industrial scale&lt;/head&gt;
    &lt;p&gt;Q Misell, 551724 / maya boeckh&lt;/p&gt;
    &lt;head rend="h5"&gt;Of Boot Vectors and Double Glitches: Bypassing RP2350's Secure Boot&lt;/head&gt;
    &lt;p&gt;stacksmashing, nsr&lt;/p&gt;
    &lt;head rend="h5"&gt;„KI“, Digitalisierung und Longevity als Fix für ein kaputtes Gesundheitssystem?&lt;/head&gt;
    &lt;p&gt;Manuel Hofmann&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaos all year round&lt;/head&gt;
    &lt;p&gt;Deanna&lt;/p&gt;
    &lt;head rend="h5"&gt;To sign or not to sign: Practical vulnerabilities in GPG &amp;amp; friends&lt;/head&gt;
    &lt;p&gt;49016, Liam&lt;/p&gt;
    &lt;head rend="h5"&gt;Handy weg bis zur Ausreise – Wie Cellebrite ins Ausländeramt kam&lt;/head&gt;
    &lt;p&gt;Chris Köver&lt;/p&gt;
    &lt;head rend="h5"&gt;Pwn2Roll: Who Needs a 595€ Remote When You Have wheelchair.py?&lt;/head&gt;
    &lt;p&gt;elfy&lt;/p&gt;
    &lt;head rend="h5"&gt;Escaping Containment: A Security Analysis of FreeBSD Jails&lt;/head&gt;
    &lt;p&gt;ilja, Michael Smith&lt;/p&gt;
    &lt;head rend="h5"&gt;Die Känguru-Rebellion: Digital Independence Day&lt;/head&gt;
    &lt;p&gt;Marc-Uwe Kling, Linus Neumann&lt;/p&gt;
    &lt;head rend="h5"&gt;And so it begins - Wie unser Rechtsstaat auf dem Highway Richtung Trumpismus rast – und warum afghanische Kläger*innen für uns die Notbremse ziehen&lt;/head&gt;
    &lt;p&gt;Eva, Elaha&lt;/p&gt;
    &lt;head rend="h5"&gt;1965 + 60 Years of Algorithmic Art with Computers&lt;/head&gt;
    &lt;p&gt;Enna Gerhard, Frieder Nake&lt;/p&gt;
    &lt;head rend="h5"&gt;Life on Hold: What Does True Solidarity Look Like Beyond Duldung, Camps, Deportation, and Payment Cards?&lt;/head&gt;
    &lt;p&gt;Hafid Shaaib, Eric Noel Mbiakeu&lt;/p&gt;
    &lt;head rend="h5"&gt;Chatkontrolle - Ctrl+Alt+Delete&lt;/head&gt;
    &lt;p&gt;khaleesi, Markus Reuter&lt;/p&gt;
    &lt;head rend="h5"&gt;Excuse me, what precise time is It?&lt;/head&gt;
    &lt;p&gt;Oliver Ettlin&lt;/p&gt;
    &lt;head rend="h5"&gt;BitUnlocker: Leveraging Windows Recovery to Extract BitLocker Secrets&lt;/head&gt;
    &lt;p&gt;Alon Leviev&lt;/p&gt;
    &lt;head rend="h5"&gt;Not To Be Trusted - A Fiasco in Android TEEs&lt;/head&gt;
    &lt;p&gt;0ddc0de, gannimo, Philipp&lt;/p&gt;
    &lt;head rend="h5"&gt;Hacking washing machines&lt;/head&gt;
    &lt;p&gt;Severin von Wnuck-Lipinski, Hajo Noerenberg&lt;/p&gt;
    &lt;head rend="h5"&gt;Doomsday-Porn, Schäferhunde und die „niedliche Abschiebung“ von nebenan: Wie autoritäre Akteure KI-generierte Inhalte für Social Media nutzen&lt;/head&gt;
    &lt;p&gt;Katharina Nocun&lt;/p&gt;
    &lt;head rend="h5"&gt;Throwing your rights under the Omnibus - how the EU's reform agenda threatens to erase a decade of digital rights&lt;/head&gt;
    &lt;p&gt;Thomas Lohninger, Ralf Bendrath&lt;/p&gt;
    &lt;head rend="h5"&gt;DNGerousLINK: A Deep Dive into WhatsApp 0-Click Exploits on iOS and Samsung Devices&lt;/head&gt;
    &lt;p&gt;Zhongrui Li, Yizhe Zhuang, Kira Chen&lt;/p&gt;
    &lt;head rend="h5"&gt;Bluetooth Headphone Jacking: A Key to Your Phone&lt;/head&gt;
    &lt;p&gt;Dennis Heinze, Frieder Steinmetz&lt;/p&gt;
    &lt;head rend="h5"&gt;Breaking architecture barriers: Running x86 games and apps on ARM&lt;/head&gt;
    &lt;p&gt;neobrain&lt;/p&gt;
    &lt;head rend="h5"&gt;The Eyes of Photon Science: Imaging, Simulation and the Quest to Make the Invisible Visible&lt;/head&gt;
    &lt;p&gt;MarKuster&lt;/p&gt;
    &lt;head rend="h5"&gt;Coding Dissent: Art, Technology, and Tactical Media&lt;/head&gt;
    &lt;p&gt;Helena Nikonole&lt;/p&gt;
    &lt;head rend="h5"&gt;AI-generated content in Wikipedia - a tale of caution&lt;/head&gt;
    &lt;p&gt;Mathias Schindler&lt;/p&gt;
    &lt;head rend="h5"&gt;Building a NOC from scratch&lt;/head&gt;
    &lt;p&gt;lilly, Scientress&lt;/p&gt;
    &lt;head rend="h5"&gt;From Silicon to Darude Sand-storm: breaking famous synthesizer DSPs&lt;/head&gt;
    &lt;p&gt;giulioz&lt;/p&gt;
    &lt;head rend="h5"&gt;Unnecessarily Complicated Kitchen – Die Wissenschaft des guten Geschmacks&lt;/head&gt;
    &lt;p&gt;LukasQ&lt;/p&gt;
    &lt;head rend="h2"&gt;Sun - Day 2 - December 28&lt;/head&gt;
    &lt;head rend="h5"&gt;Junghacker:innentag Einführung&lt;/head&gt;
    &lt;head rend="h5"&gt;Protecting the network data of one billion people: Breaking network crypto in popular Chinese mobile apps&lt;/head&gt;
    &lt;p&gt;Mona&lt;/p&gt;
    &lt;head rend="h5"&gt;Hatupangwingwi: The story how Kenyans fought back against intrusive digital identity systems&lt;/head&gt;
    &lt;p&gt;Mustafa Mahmoud Yousif&lt;/p&gt;
    &lt;head rend="h5"&gt;Lightning Talks - Tag 2&lt;/head&gt;
    &lt;p&gt;bonnie, Gilbert, Andi Bräu&lt;/p&gt;
    &lt;head rend="h5"&gt;Digitale Inklusion: Wie wir digitale Barrierefreiheit für alle erreichen können&lt;/head&gt;
    &lt;p&gt;Jakob Sponholz, Kathrin Klapper, Lena Christina Müller&lt;/p&gt;
    &lt;head rend="h5"&gt;Skynet Starter Kit: From Embodied AI Jailbreak to Remote Takeover of Humanoid Robots&lt;/head&gt;
    &lt;p&gt;Shipei Qu, Zikai Xu, Xuangan Xiao&lt;/p&gt;
    &lt;head rend="h5"&gt;Suing spyware in Europe: news from the front!&lt;/head&gt;
    &lt;p&gt;Lori Roussey, Celia/Irídia&lt;/p&gt;
    &lt;head rend="h5"&gt;Neue Chaos Events - InselChaos und Håck ma’s Castle plaudern aus dem Nähkästchen&lt;/head&gt;
    &lt;p&gt;Erwin Ernst "eest9" Steinhammer, lasii, Daniel, Niklas&lt;/p&gt;
    &lt;head rend="h5"&gt;A post-American, enshittification-resistant internet&lt;/head&gt;
    &lt;p&gt;Cory Doctorow&lt;/p&gt;
    &lt;head rend="h5"&gt;A space odyssey #2: How to study moon rocks from the Soviet sample return mission Luna 24&lt;/head&gt;
    &lt;p&gt;Paul Koetter, Christopher Hamann&lt;/p&gt;
    &lt;head rend="h5"&gt;Agentic ProbLLMs: Exploiting AI Computer-Use and Coding Agents&lt;/head&gt;
    &lt;p&gt;Johann Rehberger&lt;/p&gt;
    &lt;head rend="h5"&gt;selbstverständlich antifaschistisch! Aktuelle Informationen zu den Verfahren im Budapest-Komplex - von family &amp;amp; friends Hamburg&lt;/head&gt;
    &lt;p&gt;Andreas family &amp;amp; friends Hamburg, Birgit family &amp;amp; friends Hamburg&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaospager - How to construct an Open Pager System for c3&lt;/head&gt;
    &lt;p&gt;Max, Julian&lt;/p&gt;
    &lt;head rend="h5"&gt;Chaos Communication Chemistry: DNA information technology and security based on molecular entropy&lt;/head&gt;
    &lt;p&gt;Anne Lüscher&lt;/p&gt;
    &lt;head rend="h5"&gt;Live, Die, Repeat: The fight against data retention and boundless access to data&lt;/head&gt;
    &lt;p&gt;Klaus Landefeld&lt;/p&gt;
    &lt;head rend="h5"&gt;Power Cycle B7 oder Warum kauft man eine Zeche?&lt;/head&gt;
    &lt;p&gt;Kohlenpod, kater, Stephan&lt;/p&gt;
    &lt;head rend="h5"&gt;Cracking open what makes Apple's Low-Latency WiFi so fast&lt;/head&gt;
    &lt;p&gt;Henri Jäger&lt;/p&gt;
    &lt;head rend="h5"&gt;Awful interception: misadventures of the russian surveillance machinery&lt;/head&gt;
    &lt;p&gt;Xeniax&lt;/p&gt;
    &lt;head rend="h5"&gt;Amateurfunk im All – Kontakt mit Fram2&lt;/head&gt;
    &lt;p&gt;akira25, flx, Gato&lt;/p&gt;
    &lt;head rend="h5"&gt;Über europäische Grenzen hinweg auf klinischen Daten rechnen - aber sicher!&lt;/head&gt;
    &lt;p&gt;Hendrik Ballhausen&lt;/p&gt;
    &lt;head rend="h5"&gt;CCC-Jahresrückblick&lt;/head&gt;
    &lt;p&gt;Constanze Kurz, khaleesi, Matthias Marx, Linus Neumann, erdgeist&lt;/p&gt;
    &lt;head rend="h5"&gt;Persist, resist, stitch&lt;/head&gt;
    &lt;p&gt;Philo&lt;/p&gt;
    &lt;head rend="h5"&gt;Lessons from Building an Open-Architecture Secure Element&lt;/head&gt;
    &lt;p&gt;Jan Pleskac&lt;/p&gt;
    &lt;head rend="h5"&gt;Auf die Dauer hilft nur Power: Herausforderungen für dezentrale Netzwerke aus Sicht der Soziologie&lt;/head&gt;
    &lt;p&gt;Marco Wähner&lt;/p&gt;
    &lt;head rend="h5"&gt;Current Drone Wars&lt;/head&gt;
    &lt;p&gt;Leonard&lt;/p&gt;
    &lt;head rend="h5"&gt;Variable Fonts — It Was Never About File Size&lt;/head&gt;
    &lt;p&gt;Bernd&lt;/p&gt;
    &lt;head rend="h5"&gt;A Quick Stop at the HostileShop&lt;/head&gt;
    &lt;p&gt;Mike Perry&lt;/p&gt;
    &lt;head rend="h5"&gt;In-house electronics manufacturing from scratch: How hard can it be?&lt;/head&gt;
    &lt;p&gt;Augustin Bielefeld, Alexander Willer&lt;/p&gt;
    &lt;head rend="h5"&gt;CPU Entwicklung in Factorio: Vom D-Flip-Flop bis zum eigenen Betriebssystem&lt;/head&gt;
    &lt;p&gt;PhD (Philipp)&lt;/p&gt;
    &lt;head rend="h5"&gt;Amtsgeheimnis raus, Datenhalde rein: was die Informationsfreiheit in Österreich bringt&lt;/head&gt;
    &lt;p&gt;Markus (fin) Hametner, Erwin Ernst "eest9" Steinhammer&lt;/p&gt;
    &lt;head rend="h5"&gt;How to render cloud FPGAs useless&lt;/head&gt;
    &lt;p&gt;Dirk&lt;/p&gt;
    &lt;head rend="h5"&gt;freiheit.exe - Utopien als Malware&lt;/head&gt;
    &lt;p&gt;Christiane Mudra&lt;/p&gt;
    &lt;head rend="h5"&gt;Recharge your batteries with us - an empowering journey through the energy transition&lt;/head&gt;
    &lt;p&gt;Salacidre, JulianeB&lt;/p&gt;
    &lt;head rend="h5"&gt;Prometheus: Reverse-Engineering Overwatch&lt;/head&gt;
    &lt;p&gt;breakingbread&lt;/p&gt;
    &lt;head rend="h5"&gt;Trump government demands access to European police databases and biometrics&lt;/head&gt;
    &lt;p&gt;Matthias Monroy&lt;/p&gt;
    &lt;head rend="h5"&gt;Verlorene Domains, offene Türen - Was alte Behördendomains verraten&lt;/head&gt;
    &lt;p&gt;Tim Philipp Schäfers (TPS)&lt;/p&gt;
    &lt;head rend="h5"&gt;CSS Clicker Training: Making games in a "styling" language&lt;/head&gt;
    &lt;p&gt;Lyra Rebane&lt;/p&gt;
    &lt;head rend="h5"&gt;Wie wir alte Flipperautomaten am Leben erhalten&lt;/head&gt;
    &lt;p&gt;Axel Böttcher&lt;/p&gt;
    &lt;head rend="h5"&gt;Power Cycles statt Burnout – Wie Einflussnahme nicht verpufft&lt;/head&gt;
    &lt;p&gt;Rahel Becker, Anna Kassautzki&lt;/p&gt;
    &lt;head rend="h5"&gt;Don’t look up: There are sensitive internal links in the clear on GEO satellites&lt;/head&gt;
    &lt;p&gt;Nadia Heninger, Annie Dai&lt;/p&gt;
    &lt;head rend="h5"&gt;Textiles 101: Fast Fiber Transform&lt;/head&gt;
    &lt;p&gt;octoprog&lt;/p&gt;
    &lt;head rend="h5"&gt;How To Minimize Bugs in Cryptography Code&lt;/head&gt;
    &lt;p&gt;Jade&lt;/p&gt;
    &lt;head rend="h5"&gt;Machine Vision – Vom Algorithmus zum Baumpilz im digitalen Metabolismus&lt;/head&gt;
    &lt;p&gt;Thomas Knüsel&lt;/p&gt;
    &lt;head rend="h5"&gt;Xous: A Pure-Rust Rethink of the Embedded Operating System&lt;/head&gt;
    &lt;p&gt;bunnie, Sean "xobs" Cross&lt;/p&gt;
    &lt;head rend="h5"&gt;51 Ways to Spell the Image Giraffe: The Hidden Politics of Token Languages in Generative AI&lt;/head&gt;
    &lt;p&gt;Ting-Chun Liu, Leon-Etienne Kühr&lt;/p&gt;
    &lt;head rend="h5"&gt;When Vibe Scammers Met Vibe Hackers: Pwning PhaaS with Their Own Weapons&lt;/head&gt;
    &lt;p&gt;Chiao-Lin Yu (Steven Meow)&lt;/p&gt;
    &lt;head rend="h5"&gt;The Maybe Talent Show&lt;/head&gt;
    &lt;p&gt;Norman Müller-Schmitz, lukas-schmukas, James Bonne d'age&lt;/p&gt;
    &lt;head rend="h5"&gt;Code to Craft: Procedural Generation for the Physical World&lt;/head&gt;
    &lt;p&gt;bleeptrack&lt;/p&gt;
    &lt;head rend="h5"&gt;Reverse engineering the Pixel TitanM2 firmware&lt;/head&gt;
    &lt;p&gt;willem&lt;/p&gt;
    &lt;head rend="h5"&gt;The Small Packet of Bits That Can Save (or Destabilize) a City&lt;/head&gt;
    &lt;p&gt;Manuel Rábade&lt;/p&gt;
    &lt;head rend="h5"&gt;GPTDash – Der Reverse-Turing-Test&lt;/head&gt;
    &lt;p&gt;Benny, Kilian, BratscherBen&lt;/p&gt;
    &lt;head rend="h2"&gt;Mon - Day 3 - December 29&lt;/head&gt;
    &lt;head rend="h5"&gt;Azubi-Tag Einführung&lt;/head&gt;
    &lt;head rend="h5"&gt;Greenhouse Gas Emission Data: Public, difficult to access, and not always correct&lt;/head&gt;
    &lt;p&gt;Hanno Böck&lt;/p&gt;
    &lt;head rend="h5"&gt;Design for 3D-Printing&lt;/head&gt;
    &lt;p&gt;rahix&lt;/p&gt;
    &lt;head rend="h5"&gt;Lightning Talks - Tag 3&lt;/head&gt;
    &lt;p&gt;bonnie, Gilbert, Andi Bräu&lt;/p&gt;
    &lt;head rend="h5"&gt;The Museum of Care: Open-Source Survival Kit Collection&lt;/head&gt;
    &lt;p&gt;Nika Dubrovsky&lt;/p&gt;
    &lt;head rend="h5"&gt;Celestial navigation with very little math&lt;/head&gt;
    &lt;p&gt;Trammell Hudson&lt;/p&gt;
    &lt;head rend="h5"&gt;a media-almost-archaeology on data that is too dirty for "AI"&lt;/head&gt;
    &lt;p&gt;jiawen uffline&lt;/p&gt;
    &lt;head rend="h5"&gt;Hacking Karlsruhe - 10 years later&lt;/head&gt;
    &lt;p&gt;Jürgen Bering&lt;/p&gt;
    &lt;head rend="h5"&gt;What Makes Bike-Sharing Work? Insights from 43 Million Kilometers of European Cycling Data&lt;/head&gt;
    &lt;p&gt;Martin Lellep, Georg Balke, FelixW&lt;/p&gt;
    &lt;head rend="h5"&gt;Teckids – eine verstehbare (digitale) Welt&lt;/head&gt;
    &lt;p&gt;Keno, Darius Auding&lt;/p&gt;
    &lt;head rend="h5"&gt;BE Modded: Exploring and hacking the Vital Bracelet ecosystem&lt;/head&gt;
    &lt;p&gt;cyanic&lt;/p&gt;
    &lt;head rend="h5"&gt;Wer hat Angst vor dem Neutralitätsgebot?&lt;/head&gt;
    &lt;p&gt;Hannah Vos, Vivian Kube&lt;/p&gt;
    &lt;head rend="h5"&gt;Shit for Future: turning human shit into a climate solution&lt;/head&gt;
    &lt;p&gt;Elena&lt;/p&gt;
    &lt;head rend="h5"&gt;Watch Your Kids: Inside a Children's Smartwatch&lt;/head&gt;
    &lt;p&gt;Nils Rollshausen&lt;/p&gt;
    &lt;head rend="h5"&gt;When 8 Bits is Overkill: Making Blinkenlights with a 1-bit CPU&lt;/head&gt;
    &lt;p&gt;girst (Tobi)&lt;/p&gt;
    &lt;head rend="h5"&gt;Supplements und Social Media – wenn der Online-Hype zur realen Gesundheitsgefahr wird&lt;/head&gt;
    &lt;p&gt;Christoph Wiedmer&lt;/p&gt;
    &lt;head rend="h5"&gt;Programmierte Kriegsverbrechen? Über KI-Systeme im Kriegseinsatz in Gaza und warum IT-Fachleute sich dazu äußern müssen&lt;/head&gt;
    &lt;p&gt;Rainer Rehak&lt;/p&gt;
    &lt;head rend="h5"&gt;Making the Magic Leap past NVIDIA's secure bootchain and breaking some Tesla Autopilots along the way&lt;/head&gt;
    &lt;p&gt;EliseZeroTwo&lt;/p&gt;
    &lt;head rend="h5"&gt;Learning from South Korean Telco Breaches&lt;/head&gt;
    &lt;p&gt;Shinjo "peremen" Park, Yonghyu "perillamint" Ban&lt;/p&gt;
    &lt;head rend="h5"&gt;Gegenmacht - Best of Informationsfreiheit&lt;/head&gt;
    &lt;p&gt;Arne Semsrott&lt;/p&gt;
    &lt;head rend="h5"&gt;There is NO WAY we ended up getting arrested for this (Malta edition)&lt;/head&gt;
    &lt;p&gt;mixy1, Luke Bjorn Scerri, girogio&lt;/p&gt;
    &lt;head rend="h5"&gt;APT Down and the mystery of the burning data centers&lt;/head&gt;
    &lt;p&gt;Christopher Kunz, Sylvester&lt;/p&gt;
    &lt;head rend="h5"&gt;Von wegen Eisblumen! Wie man mit Code, Satelliten und Schiffsexpeditionen die bunte Welt des arktischen Phytoplanktons sichtbar macht&lt;/head&gt;
    &lt;p&gt;Moritz Zeising (er/he)&lt;/p&gt;
    &lt;head rend="h5"&gt;Schlechte Karten - IT-Sicherheit im Jahr null der ePA für alle&lt;/head&gt;
    &lt;p&gt;Bianca Kastl&lt;/p&gt;
    &lt;head rend="h5"&gt;Set-top box Hacking: freeing the 'Freebox'&lt;/head&gt;
    &lt;p&gt;Frédéric Hoguin&lt;/p&gt;
    &lt;head rend="h5"&gt;Wer liegt hier wem auf der Tasche? Genug mit dem Bürgergeld-Fetisch. Stürmt die Paläste!&lt;/head&gt;
    &lt;p&gt;Helena Steinhaus&lt;/p&gt;
    &lt;head rend="h5"&gt;The Last of Us - Fighting the EU Surveillance Law Apocalypse&lt;/head&gt;
    &lt;p&gt;Svea Windwehr, Chloé Berthélémy&lt;/p&gt;
    &lt;head rend="h5"&gt;AI Agent, AI Spy&lt;/head&gt;
    &lt;p&gt;Udbhav Tiwari, Meredith Whittaker&lt;/p&gt;
    &lt;head rend="h5"&gt;Build a Fake Phone, Find Real Bugs: Qualcomm GPU Emulation and Fuzzing with LibAFL QEMU&lt;/head&gt;
    &lt;p&gt;Romain Malmain, Scott Bauer&lt;/p&gt;
    &lt;head rend="h5"&gt;Transkultureller Hack auf die klassische Musikszene – Vortrag und Konzert&lt;/head&gt;
    &lt;p&gt;Johanna-Leonore Dahlhoff, Neina Doroshenko, Peter Klohmann, Alireza Meghrazi Solouklou, Mirweis Neda, Maria Carolina Pardo Reyes, Eduardo Sabella, Sarah Luisa Wurmer&lt;/p&gt;
    &lt;head rend="h5"&gt;Netzpolitik in der Schweiz: Zwischen Bodensee und Matterhorn&lt;/head&gt;
    &lt;p&gt;Kire, Rahel&lt;/p&gt;
    &lt;head rend="h5"&gt;The Angry Path to Zen: AMD Zen Microcode Tools and Insights&lt;/head&gt;
    &lt;p&gt;Benjamin Kollenda&lt;/p&gt;
    &lt;head rend="h5"&gt;Blackbox Palantir&lt;/head&gt;
    &lt;p&gt;Constanze Kurz, Franziska Görlitz&lt;/p&gt;
    &lt;head rend="h5"&gt;Aber hier Leben? Nein danke! …oder doch? Wie wir der autoritären Zuspitzung begegnen können.&lt;/head&gt;
    &lt;p&gt;Jaša Hiergeblieben, Lisa Zugezogen&lt;/p&gt;
    &lt;head rend="h5"&gt;Race conditions, transactions and free parking&lt;/head&gt;
    &lt;p&gt;Benjamin W. Broersma&lt;/p&gt;
    &lt;head rend="h5"&gt;Hegemony Eroding: Excavating Diversity in Latent Space&lt;/head&gt;
    &lt;p&gt;Karim Hamdi&lt;/p&gt;
    &lt;head rend="h5"&gt;10 years of Dieselgate&lt;/head&gt;
    &lt;p&gt;Felix Domke, Karsten Burger&lt;/p&gt;
    &lt;head rend="h5"&gt;The Heartbreak Machine: Nazis in the Echo Chamber&lt;/head&gt;
    &lt;p&gt;Martha Root, Eva Hoffmann, Christian Fuchs&lt;/p&gt;
    &lt;head rend="h5"&gt;Light in the Dark(net)&lt;/head&gt;
    &lt;p&gt;Tobias Höller&lt;/p&gt;
    &lt;head rend="h5"&gt;The Spectrum - Hackspace Beyond Hacking&lt;/head&gt;
    &lt;p&gt;sjaelv, MultisampledNight&lt;/p&gt;
    &lt;head rend="h5"&gt;Rowhammer in the Wild: Large-Scale Insights from FlippyR.AM&lt;/head&gt;
    &lt;p&gt;Martin Heckel, Florian Adamsky, Daniel Gruss&lt;/p&gt;
    &lt;head rend="h5"&gt;Peep-Show für die Polizei. Staatliche Überwachung von Queers in Hamburger Toiletten bis 1980&lt;/head&gt;
    &lt;p&gt;Simon Schultz&lt;/p&gt;
    &lt;head rend="h5"&gt;Human microservices at the Dutch Railways: modern architecture, ancient hardware?&lt;/head&gt;
    &lt;p&gt;Maarten W&lt;/p&gt;
    &lt;head rend="h5"&gt;Von Fuzzern zu Agenten: Entwicklung eines Cyber Reasoning Systems für die AIxCC&lt;/head&gt;
    &lt;p&gt;Mischa Meier (mmisc), Annika Kuntze&lt;/p&gt;
    &lt;head rend="h5"&gt;PRÜF&lt;/head&gt;
    &lt;p&gt;Nico Semsrott&lt;/p&gt;
    &lt;head rend="h5"&gt;Verschlüsselung brechen durch physischen Zugriff - Smartphone Beschlagnahme durch Polizei&lt;/head&gt;
    &lt;p&gt;Davy Wang, Viktor Schlüter&lt;/p&gt;
    &lt;head rend="h5"&gt;Spectre in the real world: Leaking your private data from the cloud with CPU vulnerabilities&lt;/head&gt;
    &lt;p&gt;Thijs Raymakers&lt;/p&gt;
    &lt;head rend="h5"&gt;Die große Datenschutz-, Datenpannen- und DS-GVO-Show&lt;/head&gt;
    &lt;p&gt;Alvar C.H. Freude&lt;/p&gt;
    &lt;head rend="h2"&gt;Tue - Day 4 - December 30&lt;/head&gt;
    &lt;head rend="h5"&gt;Asahi Linux - Porting Linux to Apple Silicon&lt;/head&gt;
    &lt;p&gt;sven&lt;/p&gt;
    &lt;head rend="h5"&gt;Atoms in Space&lt;/head&gt;
    &lt;p&gt;manuel&lt;/p&gt;
    &lt;head rend="h5"&gt;I Hated All The Cross-Stitch Software So I Made My Own: My Deranged Outsider Software Suite For Making Deranged Outsider Art&lt;/head&gt;
    &lt;p&gt;yomimono&lt;/p&gt;
    &lt;head rend="h5"&gt;How to keep Open Source open without leaving our communities open to threats&lt;/head&gt;
    &lt;p&gt;Quintessence&lt;/p&gt;
    &lt;head rend="h5"&gt;CCC&amp;amp;T - Cosmic ray, the Climate Catastrophe and Trains.&lt;/head&gt;
    &lt;p&gt;FantasticMisterFux, louiT&lt;/p&gt;
    &lt;head rend="h5"&gt;CUII: Wie Konzerne heimlich Webseiten in Deutschland sperren&lt;/head&gt;
    &lt;p&gt;Lina Lastname, Elias Zeidler (Northernside)&lt;/p&gt;
    &lt;head rend="h5"&gt;“End Of 10”: How the FOSS Community is Combatting Software-Driven Resource and Energy Consumption&lt;/head&gt;
    &lt;p&gt;Joseph P. De Veaugh-Geiss, Carolina Silva Rode, belobe&lt;/p&gt;
    &lt;head rend="h5"&gt;What You Hack Is What You Mean: 35 Years of Wiring Sense into Text&lt;/head&gt;
    &lt;p&gt;Torsten Roeder&lt;/p&gt;
    &lt;head rend="h5"&gt;Security of Cardiac Implantable Electronic Devices&lt;/head&gt;
    &lt;p&gt;dilucide&lt;/p&gt;
    &lt;head rend="h5"&gt;Who runs the www? WSIS+20 and the future of Internet governance&lt;/head&gt;
    &lt;p&gt;Sophia Longwe&lt;/p&gt;
    &lt;head rend="h5"&gt;Fossile Industrie liebt KI!&lt;/head&gt;
    &lt;p&gt;Stefan, Yannik &amp;amp; Rike, Moritz&lt;/p&gt;
    &lt;head rend="h5"&gt;Laser Beams &amp;amp; Light Streams: Letting Hackers Go Pew Pew, Building Affordable Light-Based Hardware Security Tooling&lt;/head&gt;
    &lt;p&gt;Patch, Sam. Beaumont (PANTH13R)&lt;/p&gt;
    &lt;head rend="h5"&gt;Breaking BOTS: Cheating at Blue Team CTFs with AI Speed-Runs&lt;/head&gt;
    &lt;p&gt;Leo Meyerovich, Sindre Breda&lt;/p&gt;
    &lt;head rend="h5"&gt;Von Groschen und SpurLos - GNU Taler auch auf eurem Event!&lt;/head&gt;
    &lt;p&gt;Mikolai Gütschow, signum&lt;/p&gt;
    &lt;head rend="h5"&gt;We, the EU, and 1064 Danes decided to look into YouTube: A story about how the EU gave us a law, 1064 Danes gave us their YouTube histories, and reality gave us a headache&lt;/head&gt;
    &lt;p&gt;David, LK Seiling&lt;/p&gt;
    &lt;head rend="h5"&gt;Battling Obsolescence – Keeping an 80s laser tag system alive&lt;/head&gt;
    &lt;p&gt;Trikkitt&lt;/p&gt;
    &lt;head rend="h5"&gt;Security Nightmares&lt;/head&gt;
    &lt;p&gt;Constanze Kurz, Ron&lt;/p&gt;
    &lt;head rend="h5"&gt;Infrastructure Review&lt;/head&gt;
    &lt;p&gt;nicoduck&lt;/p&gt;
    &lt;head rend="h5"&gt;Closing Ceremony&lt;/head&gt;
    &lt;p&gt;Stella, pajowu&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fahrplan.events.ccc.de/congress/2025/fahrplan/"/><published>2025-12-25T18:40:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46387657</id><title>Maybe the default settings are too high</title><updated>2025-12-26T15:11:27.264914+00:00</updated><content>&lt;doc fingerprint="e65b52868faaab9c"&gt;
  &lt;main&gt;
    &lt;p&gt;I’ve been reading Lord of the Rings for two months and I’m just at the end of the first part. It’s not because I’m not enjoying it. It’s one of the most enjoyable reading experiences I can remember.&lt;/p&gt;
    &lt;p&gt;From the beginning, I’ve read the whole thing aloud. I’ve found reading aloud helpful for staying engaged — limiting myself to mouth-speed rather than eye-speed means I won’t rush, miss important details, and then lose interest, which has always been a problem for me.&lt;/p&gt;
    &lt;p&gt;At first I was anxious to read a 1,500-page book this way, because it would take so long. But, as someone pointed out to me, if I’m enjoying it, why would I want to be done with it sooner?&lt;/p&gt;
    &lt;p&gt;So I tried slowing down even more, and discovered something. I slowed to a pace that felt almost absurd, treating each sentence as though it might be a particularly important one. I gave each one maybe triple the usual time and attention, ignoring the fact that there are hundreds of pages to go.&lt;/p&gt;
    &lt;p&gt;This leisurely pace made Middle-Earth blossom before my eyes. When I paused after each comma, and let each sentence ring for a small moment after the period, the events of the story reached me with more weight and strength. That extra time gave space for Tolkien’s images and moods to propagate in my mind, which they did automatically.&lt;/p&gt;
    &lt;p&gt;Some part of me still wanted to rush and get on with it, to make good time, to gloss over the songs and lore to get to Moria and Mount Doom and the other marquee moments of the story. But the more I ignored that impulse, the better the experience got.&lt;/p&gt;
    &lt;p&gt;By offering the book about triple the usual amount of attentiveness, I was getting about triple the storyness (i.e. meaning, engagement, literary pleasure). Whatever the thing is that I’m seeking when I pick up a novel in the first place, there’s much more of it available at this pace.&lt;/p&gt;
    &lt;head rend="h3"&gt;Eating Comprehension&lt;/head&gt;
    &lt;p&gt;This effect reminded me of a paradox around eating I recognized long ago. When you slow down your eating speed, say to half or a third your default speed, you get much more enjoyment out of a smaller amount of food. The extra attention given to each bite allows more of the “good stuff,” whatever that is exactly, to reach you.&lt;/p&gt;
    &lt;p&gt;What’s paradoxical is that it’s precisely the seeking of that “good stuff” that normally drives me to eat so quickly, and miss most of what I’m seeking. When you try to barrel ahead to access the good stuff quicker, you get less of it in the end. Slow down and much more of it is released.&lt;/p&gt;
    &lt;p&gt;And it’s released automatically, in both reading and eating. You don’t have to search it out. The good stuff (the meaning in the text, the pleasure in the eating) just rises up to meet you in that extra time you give it. Slowing down, and offering more time to the act of consumption, immediately increases reading comprehension (and eating comprehension).&lt;/p&gt;
    &lt;p&gt;Both are analogous to slowing down while you vacuum a carpet. If you pass the vacuum head too quickly, you miss half the dirt. Slow down, and you can hear how much more grit is sent skittering up the tube. The suction and bristles are working, but they need more time to do their work fully, to draw up the deeper-lying stuff.&lt;/p&gt;
    &lt;head rend="h3"&gt;Question the default settings&lt;/head&gt;
    &lt;p&gt;It seems that my default consumption speeds for reading and eating (and maybe everything else) reduce the rewards of those things significantly, undermining the point of doing either.&lt;/p&gt;
    &lt;p&gt;Part of it is my own impatience. But I also suspect that modern living, with its infinite supply of consumables, tends to push our rate-of-intake dials too high. I’m not going to run out of books, or snacks, or opportunities to learn something. There’s always more, so not every crust of bread or printed page needs to be appreciated fully.&lt;/p&gt;
    &lt;p&gt;Internally though, the mind is juggling like Lucy and Ethel on the conveyor belt at the chocolate factory. Our receptors for meaning and appreciation, like the vacuum head, need more time to do their full work, to make all the connections they’re designed to make.&lt;/p&gt;
    &lt;p&gt;It might sound like I’m just offering clichés – less is more, stop and smell the roses, take your time – and I guess I am. But clichés suffer the same issue: they are often profound insights, consumed and passed on too rapidly for their real meaning to register anymore. You really should stop and smell roses, as you know if you’re in the habit of doing that.&lt;/p&gt;
    &lt;p&gt;At least see what happens when you reduce your consumption speed – of anything, but especially books, information, and food – by a half, or two thirds. Notice that (1) something in you really wants to plow through at the highest viable setting, and (2) how much more of the reward is released when you slow down anyway.&lt;/p&gt;
    &lt;p&gt;As far as I can tell, almost everything becomes more satisfying when you give it more time and intention, even things like checking the mailbox or writing a shopping list.&lt;/p&gt;
    &lt;head rend="h3"&gt;Speed alters taste&lt;/head&gt;
    &lt;p&gt;Slowing down your rate of consumption will inevitably change what you want to consume. Reading throwaway news articles or AI slop with great care and attention is only going to show you how empty of value it is. Reading dense writing in inky old books, crafted for your mind by great masters, becomes easier without the rushed pace, and the meaning just blooms out of it.&lt;/p&gt;
    &lt;p&gt;Same with food. Try to savor a cheap, waxy “chocolate” bar, or a bag of store-brand cheese puffs, and you discover a harsh taste that you don’t want to look at too closely. Enjoy a homemade pastry with great attention, and discover there’s even more in it than you realized.&lt;/p&gt;
    &lt;p&gt;Mass production is good in so many ways, but the faster we tend to consume its fruits, the more we end up seeking things for their glossy, candied surfaces. The more we go for these surface-level rewards, the more the culture focuses on offering only that part – such as TikTok videos, processed food, CGI-forward movies, and public discourse in the form of unexamined talking points.&lt;/p&gt;
    &lt;p&gt;Who knows how far we’ve drifted from the best modes of consuming the things we value. Once something becomes a norm, it seems like an appropriate standard, no matter how much has been lost. Apparently, reading silently and alone was unusual until as late as the 18th century. Certainly sit-down meals and cooking at home were.&lt;/p&gt;
    &lt;p&gt;I don’t mean to sound like a scold. Let’s say none of this is morally good or bad. It’s just that in so much of what we do, we could be getting much more of the part of it that we really seek — but it’s only available at slower speeds.&lt;/p&gt;
    &lt;p&gt;If you’re curious, try consuming things more slowly, so slowly it seems silly to others — say a third your habitual speed — and see what rises up to meet you.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;head rend="h2"&gt;Want to quit something in January?&lt;/head&gt;
    &lt;p&gt;Recently I opened a discussion forum for Raptitude readers who want to give something up for the month of December (alcohol, social media, snacks, etc).&lt;/p&gt;
    &lt;p&gt;It’s been a real success, and many people want to do something similar in January. If you want to quit something, or just give it up for a month, you’re invited to join.&lt;/p&gt;
    &lt;p&gt;Follow this link at the end of this post to get an invite.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.raptitude.com/2025/12/maybe-the-default-settings-are-too-high/"/><published>2025-12-25T23:13:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388213</id><title>MiniMax M2.1: Built for Real-World Complex Tasks, Multi-Language Programming</title><updated>2025-12-26T15:11:24.705611+00:00</updated><content>&lt;doc fingerprint="7a878369f356732f"&gt;
  &lt;main&gt;
    &lt;p&gt;在10月底的M2中，我们主要解决模型成本和模型开放性的问题。在M2.1中，我们致力于提升真实世界复杂任务中的表现：重点聚焦于更多编程语言和办公场景的可用性，并在这个领域做到最好的水平。&lt;/p&gt;
    &lt;p&gt;MiniMax M2.1 具体模型亮点如下:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;卓越多编程语言能力&lt;/p&gt;
        &lt;p&gt;过去很多模型主要围绕 Python 优化, 但真实世界的系统往往是多语言协作的结果。&lt;/p&gt;
        &lt;p&gt;在 M2.1 中, 我们系统性提升了 Rust / Java / Golang / C++ / Kotlin / Objective-C / TypeScript / JavaScript 等语言的能力, 多语言任务整体表现达到业内领先水平, 覆盖从底层系统到应用层开发的完整链路。&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WebDev 与 AppDev：能力与美学的整体跃迁&lt;/p&gt;
        &lt;p&gt;针对业界普遍存在的移动端开发短板, M2.1 显著加强了原生 Android / iOS 开发能力。&lt;/p&gt;
        &lt;p&gt;同时, 我们系统性提升了模型在 Web 与 App 场景中的设计理解与美学表达能力, 能够出色地构建复杂交互、3D科学场景模拟与高质量可视化表达, 推动 vibe coding 成为可持续、可交付的生产实践。&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;复合指令约束提升，办公场景变为可能&lt;/p&gt;
        &lt;p&gt;作为开源模型中率先系统性引入 Interleaved Thinking 的模型系列, M2.1 systematic problem-solving 能力再次升级。&lt;/p&gt;
        &lt;p&gt;模型不仅关注代码执行是否正确, 同时关注模型对“复合指令约束”的整合执行能力, 在真实办公场景具备更高的可用性。&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;更简洁高效的回复&lt;/p&gt;
        &lt;p&gt;相比 M2, MiniMax-M2.1 的模型回复以及思维链更加简洁, 在实际编程与交互体验中, 响应速度显著提升, Token 消耗明显下降, 在 AI Coding与Agent驱动的连续工作流中更加流畅和高效。&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;出色的 Agent / 工具脚手架泛化能力&lt;/p&gt;
        &lt;p&gt;M2.1 在各类编程工具与 Agent 框架中均有出色表现。在 Claude Code、Droid (Factory AI)、Cline、Kilo Code、Roo Code、BlackBox 等工具中展现一致且稳定的效果, 并对 Skill.md、Claude.md / agent.md / cursorrule、Slash Command 等 Context Management机制提供可靠支持。&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;高质量对话和写作&lt;/p&gt;
        &lt;p&gt;M2.1 不再只是“代码能力更强”, 在日常对话、技术说明与写作场景中, 也能提供更具细节与结构性的回答。&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;基准测试概览&lt;/head&gt;
    &lt;p&gt;MiniMax-M2.1 在 VIBE 综合榜单中表现卓越，以平均 88.6 分的成绩展现了接近Claude Opus 4.5的全栈构建能力，并在几乎所有子集上都显著优于Claude Sonnet 4.5。&lt;/p&gt;
    &lt;head rend="h3"&gt;使用者评价&lt;/head&gt;
    &lt;p&gt;我们非常期待像 M2.1 这样强大的开源模型，它在各类软件开发任务中都能带来前沿水准的表现，甚至还能在部分场景下比头部闭源模型更好。开发者应当拥有选择权，而 M2.1 正是大家急需的那个优质选项！&lt;/p&gt;
    &lt;p&gt;Eno Reyes&lt;/p&gt;
    &lt;p&gt;Co-Founder, CTO of Factory&lt;/p&gt;
    &lt;p&gt;MiniMax M2.1 在可读性与惯用结构方面与生产级工程要求高度契合，在 Go、Rust、C++ 等多语言场景下均表现稳定。精炼的交错推理机制显著压缩逻辑路径，减少冗余步骤，让多文件重构与缺陷修复等复杂任务得以更高精度完成。更可贵的是，M2.1 在激活参数量受限的前提下仍能提供可靠性能，为大规模智能体编码流程提供了兼顾效能与资源利用的均衡方案。我们期待与 MiniMax 团队展开持续、紧密的合作，在 Fireworks 平台同步支持其最新创新成果！&lt;/p&gt;
    &lt;p&gt;Benny Chen&lt;/p&gt;
    &lt;p&gt;Co-Founder of Fireworks&lt;/p&gt;
    &lt;p&gt;MiniMax M2 系列在代码生成能力上表现突出，过去几个月已迅速跻身 Cline 平台最受欢迎的模型之列。M2.1 再次实现能力层面的显著跃升，我们期待与 MiniMax 团队继续深化合作，共同推进 AI 编码技术的演进。&lt;/p&gt;
    &lt;p&gt;Saoud Rizwan&lt;/p&gt;
    &lt;p&gt;Founder, CEO of Cline&lt;/p&gt;
    &lt;p&gt;我们对M2.1的发布而兴奋！我们的用户已经离不开MiniMax提供的最优秀的编程辅助能力和高性价比，内测显示，M2.1在架构设计、服务编排、代码评审直至部署上线的全链路环节中均表现优异，速度与资源效率均处于领先水平。&lt;/p&gt;
    &lt;p&gt;Scott Breitenother&lt;/p&gt;
    &lt;p&gt;Co-Founder, CEO of Kilo&lt;/p&gt;
    &lt;p&gt;我们的用户非常喜欢 MiniMax M2 在编码能力与效率方面的表现。最新发布的 M2.1 在此基础上实现了速度与可靠性的实质性提升，并在更多语言及框架中保持稳定输出。对于强调高吞吐、Agentic Coding且对速度与成本敏感的研发流程，M2.1 是稳妥且具性价比的选择。&lt;/p&gt;
    &lt;p&gt;Matt Rubens&lt;/p&gt;
    &lt;p&gt;Co-Founder, CEO of RooCode&lt;/p&gt;
    &lt;head rend="h2"&gt;Showcases&lt;/head&gt;
    &lt;head rend="h2"&gt;物理世界Agent&lt;/head&gt;
    &lt;head rend="h2"&gt;多语言 Coding&lt;/head&gt;
    &lt;head rend="h2"&gt;Agentic Tool Use&lt;/head&gt;
    &lt;head rend="h2"&gt;数字员工&lt;/head&gt;
    &lt;p&gt;以下效果演示是 M2.1 在 AgentCompany Benchmark 中的行为轨迹记录。&lt;/p&gt;
    &lt;head rend="h2"&gt;全链路办公自动化&lt;/head&gt;
    &lt;head rend="h2"&gt;如何使用&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;MiniMax-M2.1 API 已在 MiniMax开放平台 开放使用：https://platform.minimaxi.com/docs/guides/text-generation&lt;/item&gt;
      &lt;item&gt;基于 MiniMax-M2.1 的通用 Agent 产品 MiniMax Agent 现已全面开放使用：https://agent.minimaxi.com/&lt;/item&gt;
      &lt;item&gt; 开源以及本地部署使用： https://huggingface.co/MiniMaxAI/MiniMax-M2.1 &lt;lb/&gt;https://github.com/MiniMax-AI/MiniMax-M2.1&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;为了方便用户使用, 我们提供了两个版本的 API, M2.1 和 M2.1-lightning。这两个 API 结果完全一样, 但是后者速度更快, 方便对 TPS 有需求的用户来使用。同时, 在 M2 手动 Cache 的基础上, M2.1 全面支持自动 Cache, 无需设置, 自动生效, 为开发者带来更流畅的体验、更低的成本与更优的延时表现。&lt;/p&gt;
    &lt;p&gt;我们在 Coding Plan 里面会根据资源负载给用户提供大比例的 M2.1-lightning, 并保持 Coding Plan 的价格不变。也就是说, Coding Plan 用户免费获得了大部分时间更快的推理速度。欢迎大家点击下单~&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.minimaxi.com/news/minimax-m21"/><published>2025-12-26T01:02:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46388907</id><title>TurboDiffusion: 100–200× Acceleration for Video Diffusion Models</title><updated>2025-12-26T15:11:24.249351+00:00</updated><content>&lt;doc fingerprint="f4d4ba193592fac2"&gt;
  &lt;main&gt;
    &lt;p&gt;This repository provides the official implementation of TurboDiffusion, a video generation acceleration framework that can speed up end-to-end diffusion generation by &lt;lb/&gt; TurboDiffusion primarily uses SageAttention, SLA (Sparse-Linear Attention) for attention acceleration, and rCM for timestep distillation.&lt;/p&gt;
    &lt;p&gt;Paper: TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times&lt;/p&gt;
    &lt;p&gt;Note: the checkpoints and paper are not finalized, and will be updated later to improve quality.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Model Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Checkpoint Link&lt;/cell&gt;
        &lt;cell role="head"&gt;Best Resolution&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.2-I2V-A14B-720P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;720p&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.1-T2V-1.3B-480P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;480p&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.1-T2V-14B-480P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;480p&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;TurboWan2.1-T2V-14B-720P&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Huggingface Model&lt;/cell&gt;
        &lt;cell&gt;720p&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Note: All checkpoints support generating videos at 480p or 720p. The "Best Resolution" column indicates the resolution at which the model provides the best video quality.&lt;/p&gt;
    &lt;p&gt;Base environment: &lt;code&gt;python&amp;gt;=3.9&lt;/code&gt;, &lt;code&gt;torch&amp;gt;=2.7.0&lt;/code&gt;. &lt;code&gt;torch==2.8.0&lt;/code&gt; is recommended, as higher versions may cause OOM.&lt;/p&gt;
    &lt;p&gt;Install TurboDiffusion by pip:&lt;/p&gt;
    &lt;code&gt;conda create -n turbodiffusion python=3.12
conda activate turbodiffusion

pip install turbodiffusion --no-build-isolation&lt;/code&gt;
    &lt;p&gt;Or compile from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/thu-ml/TurboDiffusion.git
cd TurboDiffusion
git submodule update --init --recursive
pip install -e . --no-build-isolation&lt;/code&gt;
    &lt;p&gt;To enable SageSLA, a fast SLA forward pass based on SageAttention, install SpargeAttn first:&lt;/p&gt;
    &lt;code&gt;pip install git+https://github.com/thu-ml/SpargeAttn.git --no-build-isolation&lt;/code&gt;
    &lt;p&gt;For GPUs with more than 40GB of GPU memory, e.g., H100, please use the unquantized checkpoints (without &lt;code&gt;-quant&lt;/code&gt;) and remove &lt;code&gt;--quant_linear&lt;/code&gt; from the command. For RTX 5090, RTX 4090, or similar GPUs, please use the quantized checkpoints (with &lt;code&gt;-quant&lt;/code&gt;) and add &lt;code&gt;--quant_linear&lt;/code&gt; in the command.)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Download the VAE (applicable for both Wan2.1 and Wan2.2) and umT5 text encoder checkpoints:&lt;/p&gt;
        &lt;code&gt;mkdir checkpoints cd checkpoints wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/Wan2.1_VAE.pth wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/models_t5_umt5-xxl-enc-bf16.pth&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Download our quantized model checkpoints (For RTX 5090 or similar GPUs):&lt;/p&gt;
        &lt;quote&gt;# For Wan2.1-T2V-1.3B wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P-quant.pth # For Wan2.2-I2V-14B wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P-quant.pth wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P-quant.pth&lt;/quote&gt;
        &lt;p&gt;Or download our unquantized model checkpoints (For H100 or similar GPUs):&lt;/p&gt;
        &lt;quote&gt;# For Wan2.1-T2V-1.3B wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P.pth # For Wan2.2-I2V-14B wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P.pth wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P.pth&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use the inference script for the T2V models:&lt;/p&gt;
        &lt;quote&gt;export PYTHONPATH=turbodiffusion # Arguments: # --dit_path Path to the finetuned TurboDiffusion checkpoint # --model Model to use: Wan2.1-1.3B or Wan2.1-14B (default: Wan2.1-1.3B) # --num_samples Number of videos to generate (default: 1) # --num_steps Sampling steps, 1–4 (default: 4) # --sigma_max Initial sigma for rCM (default: 80); larger choices (e.g., 1600) reduce diversity but may enhance quality # --vae_path Path to Wan2.1 VAE (default: checkpoints/Wan2.1_VAE.pth) # --text_encoder_path Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth) # --num_frames Number of frames to generate (default: 81) # --prompt Text prompt for video generation # --resolution Output resolution: "480p" or "720p" (default: 480p) # --aspect_ratio Aspect ratio in W:H format (default: 16:9) # --seed Random seed for reproducibility (default: 0) # --save_path Output file path including extension (default: output/generated_video.mp4) # --attention_type Attention module to use: original, sla or sagesla (default: sagesla) # --sla_topk Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality # --quant_linear Enable quantization for linear layers, pass this if using a quantized checkpoint # --default_norm Use the original LayerNorm and RMSNorm of Wan models python turbodiffusion/inference/wan2.1_t2v_infer.py \ --model Wan2.1-1.3B \ --dit_path checkpoints/TurboWan2.1-T2V-1.3B-480P-quant.pth \ --resolution 480p \ --prompt "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about." \ --num_samples 1 \ --num_steps 4 \ --quant_linear \ --attention_type sagesla \ --sla_topk 0.1&lt;/quote&gt;
        &lt;p&gt;Or the script for the I2V model:&lt;/p&gt;
        &lt;quote&gt;export PYTHONPATH=turbodiffusion # --image_path Path to the input image # --high_noise_model_path Path to the high noise TurboDiffusion checkpoint # --low_noise_model_path Path to the high noise TurboDiffusion checkpoint # --boundary Timestep boundary for switching from high to low noise model (default: 0.9) # --model Model to use: Wan2.2-A14B (default: Wan2.2-A14B) # --num_samples Number of videos to generate (default: 1) # --num_steps Sampling steps, 1–4 (default: 4) # --sigma_max Initial sigma for rCM (default: 200); larger choices (e.g., 1600) reduce diversity but may enhance quality # --vae_path Path to Wan2.2 VAE (default: checkpoints/Wan2.2_VAE.pth) # --text_encoder_path Path to umT5 text encoder (default: checkpoints/models_t5_umt5-xxl-enc-bf16.pth) # --num_frames Number of frames to generate (default: 81) # --prompt Text prompt for video generation # --resolution Output resolution: "480p" or "720p" (default: 720p) # --aspect_ratio Aspect ratio in W:H format (default: 16:9) # --adaptive_resolution Enable adaptive resolution based on input image size # --ode Use ODE for sampling (sharper but less robust than SDE) # --seed Random seed for reproducibility (default: 0) # --save_path Output file path including extension (default: output/generated_video.mp4) # --attention_type Attention module to use: original, sla or sagesla (default: sagesla) # --sla_topk Top-k ratio for SLA/SageSLA attention (default: 0.1), we recommend using 0.15 for better video quality # --quant_linear Enable quantization for linear layers, pass this if using a quantized checkpoint # --default_norm Use the original LayerNorm and RMSNorm of Wan models python turbodiffusion/inference/wan2.2_i2v_infer.py \ --model Wan2.2-A14B \ --low_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-low-720P-quant.pth \ --high_noise_model_path checkpoints/TurboWan2.2-I2V-A14B-high-720P-quant.pth \ --resolution 720p \ --adaptive_resolution \ --image_path assets/i2v_inputs/i2v_input_0.jpg \ --prompt "POV selfie video, ultra-messy and extremely fast. A white cat in sunglasses stands on a surfboard with a neutral look when the board suddenly whips sideways, throwing cat and camera into the water; the frame dives sharply downward, swallowed by violent bursts of bubbles, spinning turbulence, and smeared water streaks as the camera sinks. Shadows thicken, pressure ripples distort the edges, and loose bubbles rush upward past the lens, showing the camera is still sinking. Then the cat kicks upward with explosive speed, dragging the view through churning bubbles and rapidly brightening water as sunlight floods back in; the camera races upward, water streaming off the lens, and finally breaks the surface in a sudden blast of light and spray, snapping back into a crooked, frantic selfie as the cat resurfaces." \ --num_samples 1 \ --num_steps 4 \ --quant_linear \ --attention_type sagesla \ --sla_topk 0.1 \ --ode&lt;/quote&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Interactive inference via the terminal is available at &lt;code&gt;turbodiffusion/serve/&lt;/code&gt;. This allows multi-turn video generation without reloading the model.&lt;/p&gt;
    &lt;p&gt;We evaluate video generation on a single RTX 5090 GPU. The E2E Time refers to the end-to-end diffusion generation latency, excluding text encoding and VAE decoding.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4549s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 38s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 184s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 5.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 1.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4767s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 72.6s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 24s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4767s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 72.6s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 24s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 4767s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 72.6s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 24s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Original, E2E Time: 1676s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;FastVideo, E2E Time: 26.3s&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;TurboDiffusion, E2E Time: 9.9s&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this repo, we provide training code based on Wan2.1 and its synthetic data. The training builds on the rCM codebase (https://github.com/NVlabs/rcm), with infrastructure support including FSDP2, Ulysses CP, and selective activation checkpointing (SAC). For rCM training instructions, please refer to the original rCM repository; SLA (Sparse-Linear Attention) training guidance is provided here.&lt;/p&gt;
    &lt;p&gt;For rCM/SLA training, additionally run:&lt;/p&gt;
    &lt;code&gt;pip install megatron-core hydra-core wandb webdataset
pip install --no-build-isolation transformer_engine[pytorch]&lt;/code&gt;
    &lt;p&gt;Download the Wan2.1 pretrained checkpoints in &lt;code&gt;.pth&lt;/code&gt; format and VAE/text encoder to &lt;code&gt;assets/checkpoints&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;# make sure git lfs is installed
git clone https://huggingface.co/worstcoder/Wan assets/checkpoints&lt;/code&gt;
    &lt;p&gt;FSDP2 relies on Distributed Checkpoint (DCP) for loading and saving checkpoints. Before training, convert &lt;code&gt;.pth&lt;/code&gt; teacher checkpoints to &lt;code&gt;.dcp&lt;/code&gt; first:&lt;/p&gt;
    &lt;code&gt;python -m torch.distributed.checkpoint.format_utils torch_to_dcp assets/checkpoints/Wan2.1-T2V-1.3B.pth assets/checkpoints/Wan2.1-T2V-1.3B.dcp&lt;/code&gt;
    &lt;p&gt;After training, the saved &lt;code&gt;.dcp&lt;/code&gt; checkpoints can be converted to &lt;code&gt;.pth&lt;/code&gt; using the script &lt;code&gt;scripts/dcp_to_pth.py&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We provide Wan2.1-14B-synthesized datasets. Download to &lt;code&gt;assets/datasets&lt;/code&gt; using:&lt;/p&gt;
    &lt;code&gt;# make sure git lfs is installed
git clone https://huggingface.co/datasets/worstcoder/Wan_datasets assets/datasets&lt;/code&gt;
    &lt;p&gt;We implement white-box SLA training by aligning the predictions of the SLA-enabled model with those of the full-attention pretrained model. Unlike black-box training in the original paper, which tunes the pretrained model using diffusion loss, white-box training mitigates distribution shift and is less sensitive to the training data.&lt;/p&gt;
    &lt;p&gt;Single-node training example:&lt;/p&gt;
    &lt;code&gt;WORKDIR="/your/path/to/turbodiffusion"
cd $WORKDIR
export PYTHONPATH=turbodiffusion

# the "IMAGINAIRE_OUTPUT_ROOT" environment variable is the path to save experiment output files
export IMAGINAIRE_OUTPUT_ROOT=${WORKDIR}/outputs
CHECKPOINT_ROOT=${WORKDIR}/assets/checkpoints
DATASET_ROOT=${WORKDIR}/assets/datasets/Wan2.1_14B_480p_16:9_Euler-step100_shift-3.0_cfg-5.0_seed-0_250K

# your Wandb information
export WANDB_API_KEY=xxx
export WANDB_ENTITY=xxx

registry=registry_sla
experiment=wan2pt1_1pt3B_res480p_t2v_SLA

torchrun --nproc_per_node=8 \
    -m scripts.train --config=rcm/configs/${registry}.py -- experiment=${experiment} \
        model.config.teacher_ckpt=${CHECKPOINT_ROOT}/Wan2.1-T2V-1.3B.dcp \
        model.config.tokenizer.vae_pth=${CHECKPOINT_ROOT}/Wan2.1_VAE.pth \
        model.config.text_encoder_path=${CHECKPOINT_ROOT}/models_t5_umt5-xxl-enc-bf16.pth \
        model.config.neg_embed_path=${CHECKPOINT_ROOT}/umT5_wan_negative_emb.pt \
        dataloader_train.tar_path_pattern=${DATASET_ROOT}/shard*.tar&lt;/code&gt;
    &lt;p&gt;Please refer to &lt;code&gt;turbodiffusion/rcm/configs/experiments/sla/wan2pt1_t2v.py&lt;/code&gt; for the 14B config or perform modifications as needed.&lt;/p&gt;
    &lt;p&gt;The parameter updates from SLA training can be merged into rCM checkpoints using &lt;code&gt;turbodiffusion/scripts/merge_models.py&lt;/code&gt;, enabling rCM to perform sparse attention inference. Specify &lt;code&gt;--base&lt;/code&gt; as the rCM model, &lt;code&gt;--diff_base&lt;/code&gt; as the pretrained model, and &lt;code&gt;--diff_target&lt;/code&gt; as the SLA-tuned model.&lt;/p&gt;
    &lt;p&gt;We thank the community effort Comfyui_turbodiffusion for integrating TurboDiffusion into ComfyUI.&lt;/p&gt;
    &lt;p&gt;We're actively working on the following features and improvements:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Organize and release training code&lt;/item&gt;
      &lt;item&gt;Optimize infrastructure for better parallel&lt;/item&gt;
      &lt;item&gt;vLLM-Omni integration&lt;/item&gt;
      &lt;item&gt;Support for more video generation models&lt;/item&gt;
      &lt;item&gt;Support for autoregressive video generation models&lt;/item&gt;
      &lt;item&gt;More hardware-level operator optimizations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome community members to help maintain and extend TurboDiffusion. Welcome to join the TurboDiffusion Team and contribute together!&lt;/p&gt;
    &lt;p&gt;If you use this code or find our work valuable, please cite:&lt;/p&gt;
    &lt;code&gt;@article{zhang2025turbodiffusion,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={Zhang, Jintao and Zheng, Kaiwen and Jiang, Kai and Wang, Haoxu and Stoica, Ion and Gonzalez, Joseph E and Chen, Jianfei and Zhu, Jun},
  journal={arXiv preprint arXiv:2512.16093},
  year={2025}
}

@software{turbodiffusion2025,
  title={TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times},
  author={The TurboDiffusion Team},
  url={https://github.com/thu-ml/TurboDiffusion},
  year={2025}
}

@inproceedings{zhang2025sageattention,
  title={SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration}, 
  author={Zhang, Jintao and Wei, Jia and Zhang, Pengle and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2025}
}

@article{zhang2025sla,
  title={SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention},
  author={Zhang, Jintao and Wang, Haoxu and Jiang, Kai and Yang, Shuo and Zheng, Kaiwen and Xi, Haocheng and Wang, Ziteng and Zhu, Hongzhou and Zhao, Min and Stoica, Ion and others},
  journal={arXiv preprint arXiv:2509.24006},
  year={2025}
}

@article{zheng2025rcm,
  title={Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency},
  author={Zheng, Kaiwen and Wang, Yuji and Ma, Qianli and Chen, Huayu and Zhang, Jintao and Balaji, Yogesh and Chen, Jianfei and Liu, Ming-Yu and Zhu, Jun and Zhang, Qinsheng},
  journal={arXiv preprint arXiv:2510.08431},
  year={2025}
}

@inproceedings{zhang2024sageattention2,
  title={Sageattention2: Efficient attention with thorough outlier smoothing and per-thread int4 quantization},
  author={Zhang, Jintao and Huang, Haofeng and Zhang, Pengle and Wei, Jia and Zhu, Jun and Chen, Jianfei},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2025}
}
&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/thu-ml/TurboDiffusion"/><published>2025-12-26T03:19:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46390055</id><title>Building an AI agent inside a 7-year-old Rails monolith</title><updated>2025-12-26T15:11:24.007070+00:00</updated><content>&lt;doc fingerprint="6c1bd1132f25fa62"&gt;
  &lt;main&gt;
    &lt;p&gt;I (incorrectly) convinced myself over the last few months that there’s no low-hanging fruit that would work for our product and business. This is a story of just how wrong I was.&lt;/p&gt;
    &lt;p&gt;I was at SF Ruby, in San Francisco, a few weeks ago. Most of the tracks were, of course, heavily focused on AI. Lots of stories from people building AIs into all sorts of products using Ruby and Rails,&lt;/p&gt;
    &lt;p&gt;They were good talks. But most of them assumed a kind of software I don’t work on — systems without strong boundaries, without multi-tenant concerns, without deeply embedded authorization rules.&lt;/p&gt;
    &lt;p&gt;I kept thinking: this is interesting, but it doesn’t map cleanly to my world. At Mon Ami, we can’t just release a pilot unless it passes strict data access checks.&lt;/p&gt;
    &lt;p&gt;Then I saw a talk about using the RubyLLM gem to build a RAG-like system. The conversation (LLM calls) context was augmented using function calls (tools). This is when it clicked. I could encode my complicated access logic into a specific function call and ensure the LLM gets access to some of our data without having to give it unrestricted access.&lt;/p&gt;
    &lt;p&gt;RubyLLM is a neat gem that abstracts away the interaction with many LLM providers with a clean API.&lt;/p&gt;
    &lt;code&gt;gem "ruby_llm"&lt;/code&gt;
    &lt;p&gt;It is configured in an initializer with the API keys for the providers you want to use.&lt;/p&gt;
    &lt;code&gt;RubyLLM.configure do |config|
  config.openai_api_key = Rails.application.credentials.dig(:openai_api_key)
  config.anthropic_api_key = Rails.application.credentials.dig(:anthropic_api_key)
  # config.default_model = "gpt-4.1-nano"

  # Use the new association-based acts_as API (recommended)
  config.use_new_acts_as = true

  # Increase timeout for slow API responses
  config.request_timeout = 600  # 10 minutes (default is 300)
  config.max_retries = 3        # Retry failed requests
end

# Load LLM tools from main app
Dir[Rails.root.join('app/tools/**/*.rb')].each { |f| require f }&lt;/code&gt;
    &lt;p&gt;It provides a Conversation model as an abstraction for an LLM thread. The Conversation contains a set of Messages. It also provides a way of defining structured responses and function calls available.&lt;/p&gt;
    &lt;code&gt;AVAILABLE_TOOLS = [
  Tools::Client::SearchTool
].freeze

conversation = Conversation.find(conversation_id)
chat = conversation.with_tools(*AVAILABLE_TOOLS)

chat.ask 'What is the phone number for John Snow?'&lt;/code&gt;
    &lt;p&gt;A Conversation is initialized by passing a model (gpt-5, claude-sonnet-4.5, etc) and has a method for chatting to it.&lt;/p&gt;
    &lt;code&gt;conversation = Conversation.new(model: RubyLLM::Model.find_by(model_id: 'gpt-4o-mini'))&lt;/code&gt;
    &lt;p&gt;RubyLLM comes with a neat DSL for defining accepted parameters (the descriptions are passed to the LLM as context since it needs to decide if the tool should be used based on the conversation). The tool implements an execute method returning a hash. The hash is then presented to the LLM. This is all the magic needed.&lt;/p&gt;
    &lt;code&gt;class SearchTool &amp;lt; BaseTool
  description 'Search for clients by name, ID, or email address. Returns matching clients.'

  param :query,
    desc: 'Search query - can be client name, ID, or email address',
    type: :string

  def execute(query:)
  end
end&lt;/code&gt;
    &lt;p&gt;We’ll now build a modest function call and a messaging interface. The function call allows searching a client using Algolia and ensuring the resulting set is visible to the user (by merging in the pundit policy).&lt;/p&gt;
    &lt;code&gt;def execute(query:)
  response = Algolia::SearchClient
    .create(app_id, search_key)
    .search_single_index(Client.index_name, {
      query: query.truncate(250)
    })

  ids = response.hits.map { |hit| hit[:id] }.compact

  base_scope = Client.where(id: ids)
  client = Admin::Org::ClientPolicy::Scope.new(base_scope).resolve.first or return {}

  {
    id: client.id,
    ami_id: client.slug,
    slug: client.slug,
    name: client.full_name,
    email: client.email
  }
end&lt;/code&gt;
    &lt;p&gt;The LLM acts as the magic glue between the natural language input submitted by the user, decides which (if any) tool to use to augment the context, and then responds to the user. No model should ever know Jon Snow’s phone number from a SaaS service, but this approach allows this sort of retrieval.&lt;/p&gt;
    &lt;p&gt;The UI is built with a remote form that enqueues an Active Job.&lt;/p&gt;
    &lt;code&gt;= turbo_stream_from @conversation, :messages

.container-fluid.h-100.d-flex.flex-column
  .sticky-top
    %h2.mb-0
      Conversation ##{@conversation.id}

  .flex-grow-1
    = render @messages

  .p-3.border-top.bg-white.sticky-bottom#message-form
  = form_with url: path, method: :post, local: false, data: { turbo_stream: true } do |f|
    = f.text_area :content
    = f.submit 'Send'&lt;/code&gt;
    &lt;p&gt;The job will process the Message.&lt;/p&gt;
    &lt;code&gt;class ProcessMessageJob &amp;lt; ApplicationJob
  queue_as :default

  def perform(conversation_id, message)
    conversation = Conversation.find(conversation_id)
    conversation.ask message
  end
end&lt;/code&gt;
    &lt;p&gt;The conversation has broadcast refresh enabled to update the UI when the response is received.&lt;/p&gt;
    &lt;code&gt;class Conversation &amp;lt; RubyLLM::Conversation
  broadcasts_refreshes
end&lt;/code&gt;
    &lt;p&gt;The form has a stimulus controller that checks for new messages being appended in order to scroll to the end of the conversation.&lt;/p&gt;
    &lt;p&gt;I checked a few OpenAI models for this implementation: gpt-5, gpt-4o, gpt4. GPT-5 has a big context, meaning we could have long-running conversations, but because there are a number of round-trips, the delay to queries requiring 3+ consecutive tools made the Agent feel sluggish.&lt;/p&gt;
    &lt;p&gt;GPT-4, on the other hand, is interestingly very prone to hallucinations - rushing to respond to queries with made-up data instead of calling the necessary tools. GPT-4o strikes, so far, the best balance between speed and correctness.&lt;/p&gt;
    &lt;p&gt;Building this tool took probably about 2-3 days of Claude-powered development (AIs building AIs). The difficulty and the complexity of building such a tool were the things that surprised me the most. The tool service object is essentially an API controller action - pass inputs and get a JSON back. Interestingly.&lt;/p&gt;
    &lt;p&gt;Before building this Agent, I looked at the other gems in this space. ActiveAgent (a somewhat similar gem for interacting with LLMs) is a decent contender that moves the prompts to a view file. It didn’t fit my needs since it had no built-in support for defining tools or having long-running conversations.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://catalinionescu.dev/ai-agent/building-ai-agent-part-1/"/><published>2025-12-26T07:35:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46390667</id><title>Geometric Algorithms for Translucency Sorting in Minecraft [pdf]</title><updated>2025-12-26T15:11:23.803673+00:00</updated><content/><link href="https://douira.dev/assets/document/douira-master-thesis.pdf"/><published>2025-12-26T09:43:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391077</id><title>The First Web Server</title><updated>2025-12-26T15:11:23.640676+00:00</updated><content>&lt;doc fingerprint="fb0f55d54bf40ea7"&gt;
  &lt;main&gt;
    &lt;p&gt;Late December 1990 was a pivotal time, although none of us realized it for a few years. Tim Berners-Lee, A British computer scientist working in Switzerland, was working on what became the World Wide Web. Over the course of a few months, he invented HTML, the web browser, and the web server, to make it easier to share information. Sometime in late December, the first web server reached a usable state. By some accounts it was December 20, 1990. By at least one account I found, it was December 25.&lt;/p&gt;
    &lt;head rend="h2"&gt;The first web server’s address&lt;/head&gt;
    &lt;p&gt;The early work on the World Wide Web took place on NeXT workstations. Berners-Lee’s workstation lived at info.cern.ch.CERN is the European Organization for Nuclear Research, an intergovernmental organization that operates the largest particle physics laboratory in the world. It might be the most momentous shadow IT project in history.&lt;/p&gt;
    &lt;p&gt;No screenshots exist of the web page in its earliest form, unfortunately, although I did find an approximation of how the page appeared in 1992. Not surprisingly, the first web page was technical information about the web, including how HTML, web servers, and web browsers worked.&lt;/p&gt;
    &lt;p&gt;The earliest copy of the page I could find on archive.org, from 2000, stated the web page and the computer that hosted it no longer exist. In August 2006, CERN memorialized the first web page and first web server with a page about it.&lt;/p&gt;
    &lt;p&gt;Berners-Lee’s original goal was making information more accessible. Valuable data resided in various formats on computers throughout the organization. Berners-Lee’s goal was to unlock the data so it could link together and be readable from any machine.&lt;/p&gt;
    &lt;head rend="h2"&gt;What happened next&lt;/head&gt;
    &lt;p&gt;It took a few years for the World Wide Web to go worldwide. By January 1993, NSCA Mosaic, a cross-platform web browser, was available, which gave rise to Netscape. The web caught on quickly on college campuses with browsers that ran on all of the major platforms of the time. Efforts to commercialize the web led to the dotcom boom, and, eventually, to the online world we know today.&lt;/p&gt;
    &lt;p&gt;David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dfarq.homeip.net/the-first-web-server/"/><published>2025-12-26T11:12:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391220</id><title>How Postmodernism Killed Great Literature</title><updated>2025-12-26T15:11:23.026827+00:00</updated><content>&lt;doc fingerprint="b12290012ea1253e"&gt;
  &lt;main&gt;
    &lt;p&gt;Last week, I finished reading Ottessa Moshfegh’s bestselling 2018 novel My Year of Rest and Relaxation. While I usually do not read books from the “Millennial Sad Girl Navigates Modern Life” genre, I was compelled to see what all the fuss is about. Suffice it to say that I was not impressed. But I could not quite put my finger on the source of my disdain until, several days ago, it hit me: Moshfegh’s unnamed narrator walks away learning absolutely nothing.&lt;/p&gt;
    &lt;p&gt;The fault of this particular novel might be with Moshfegh’s nihilistic outlook on life, but the problem cuts even deeper. Today, the publishing industry as a whole turns its nose up to narratives that promote objective meaning.&lt;/p&gt;
    &lt;p&gt;It is no accident that the publishing industry shies away from books that illustrate “the good life.” There’s a lot to unpack in that claim, but it is no accident that the publishing industry shies away from books that illustrate “the good life” in the Aristotelian sense. Reared on the postmodern spirit that dominates colleges and universities, publishing professionals favor ambiguous, open-ended narratives to stories with clear redemption arcs. But, at its core, literature should not only teach us to think critically but also to live our best lives.&lt;/p&gt;
    &lt;p&gt;By the 1960s, American universities had proceeded to wage a full-scale war on all aspects of morality and tradition. In 1908, New Humanist literary scholar Irving Babbitt set out to redefine classic-literature education in a collection of essays called Literature and the American College. An early literary critic, Babbitt believed that the purpose of literature was to cultivate a lasting moral imagination—that is, literature had a duty to craft readers into morally upstanding members of society. Though New Humanism’s reign was short-lived in the academy, its fundamental axiom—that the purpose of literature was to foster moral education—articulated the broader cultural tradition that has sustained the human soul for thousands of years. Literature is supposed to teach us what gives our lives meaning. After all, isn’t that why we gravitate towards literature in the first place?—to learn, by way of the particular, that which is universally true about the human condition?&lt;/p&gt;
    &lt;p&gt;Not anymore, it seems. By the 1960s, American universities had proceeded to wage a full-scale war on all aspects of morality and tradition, making way for the postmodern literary theorists who rejected the teachings of Babbitt and put forth the following postulates instead:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Meaning is relative if not entirely obsolete. In 1967, the French philosopher Jacques Derrida set out, in his famous De La Grammatologie (Of Grammatology), to attack the idea that a work of literature must contain an objective moral message. The book contains an extended condemnation of the tradition of “Western Metaphysics,” which, in Derrida’s eyes, privileged the good over the bad and light over darkness. In a nutshell, Derrida does away with the idea that we should gain objective meaning from literature and that literature must contain an objective moral message.&lt;/item&gt;
      &lt;item&gt;Authorial intention is irrelevant. There have been several postmodern writings on the erasure of authorial intent, but the most famous piece comes from the French theorist Roland Barthes, in an essay called “The Death of the Author.” As its title suggests, the essay lambasts authorial intention and argues that his or her identity is entirely irrelevant to a reader’s interpretation of a given text. If an author’s intention no longer matters, then a given text belongs entirely to the reader—a death knell to the idea of the author as a moral teacher.&lt;/item&gt;
      &lt;item&gt;“Grand narratives” are oppressive. In his book The Postmodern Condition, the French philosopher Jean-Francois Lyotard claims that one must be skeptical of “Universal Truths.” Overarching moral systems become oppressive, and any notion of “how to live well” reeks of the patriarchy, colonialism, et cetera.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taught to analyze literature through these postmodern lenses, university students of literature emerge from English departments believing that literature should simply observe rather than teach. Some of these cynical young professionals then enter the publishing industry, where they insist on promoting moral relativism in the guise of fiction. It is no wonder that the publishing industry runs so heavily on identity-based readings. In the eyes of the moral relativist, a text can mean anything as long as someone feels that it means a particular thing. What is in vogue in the literary-fiction world today are books that deliberately refuse closure, painting characters who learn nothing by the end of their journey as they rebel against the very idea of meaning itself.&lt;/p&gt;
    &lt;p&gt;What is in vogue in the literary-fiction world today are books that deliberately refuse closure. Moshfegh’s narrator, for instance, learns absolutely nothing about her hedonistic, degenerate lifestyle by the novel’s close. And while Moshfegh doesn’t attempt to excuse her character, she also refuses to condemn her. She launches an attack on capitalism but does not offer an alternative; she depicts a degenerate society but does not decry its moral downfall. A critic writing for The Brooklyn Rail said it best: “What has [the narrator] learned, and what will her life look like now? Perhaps these questions don’t need answering, as the ending leaves you intentionally unsettled.”&lt;/p&gt;
    &lt;p&gt;Modern life, according to many writers of contemporary literary fiction, has no meaning whatsoever. As Moshfegh and her literary supporters would argue, that is precisely the point of the novel—there is no significance! Modern life, according to Moshfegh and many other writers of contemporary literary fiction, has no meaning whatsoever! It is sad, absurd, and pointless—and, therefore, one should hibernate through it all.&lt;/p&gt;
    &lt;p&gt;Moshfegh’s writing is the direct outgrowth of the postmodern university conviction that all morality is relative and that the writer’s duty is not to lay out morals but to indulge his or her pessimism and nihilism.&lt;/p&gt;
    &lt;p&gt;After years of studying the great classics, I have learned precisely the opposite: Good literature should have a lasting moral message. The reason we still read Anna Karenina is not (only) that Tolstoy is a master of Russian prose or that the plot keeps readers on the edges of their seats but because the novel teaches us about that which is right and that which is wrong. We root for Levin not because he is “relatable,” as today’s literary agents insist characters be, but because he undergoes a redemption arc. He learns, through trial and error and several epiphanies, that there is nothing more important than maintaining a stable, loving family—that he will not live forever and that he must therefore imbue his life with meaning in some way. He chooses to marry Kitty—and, indeed, Kitty eventually chooses him—because he knows that blessing her with the gift of children will create more meaning in both of their lives than did his previous hedonistic lifestyle. Similarly, we watch Anna’s life gradually unravel because she has traded loyalty, love, and duty for empty pleasure. In the end, she commits suicide because, in the absence of children and family, her life has lost all meaning.&lt;/p&gt;
    &lt;p&gt;That is precisely what is missing from literature today—a plea for meaning. Today, the publishing industry churns out writing that fundamentally resists meaning, from Sally Rooney’s one-dimensional characters stewing in political ennui to Ben Lerner’s autofictional stand-ins who never manage to articulate a single moral stance. These books will fade into oblivion in the next decade while great novels with moral messages—Anna Karenina, The Great Gatsby, East of Eden—will stay with us even after we leave this earth, for they are not only well-written but also meaningful.&lt;/p&gt;
    &lt;p&gt;In a world in which many contemporary novels mistake ambiguity for depth, it is almost heretical to insist that literature ought to mean something. But if I’ve learned anything from five years in Ivy League English departments, it is that, unfortunately, postmodernism-influenced readers will fail to truly understand literature until they acknowledge that literature is nothing without meaning. We can all find deep meaning in our lives, after all, if we just look up, rejecting the nihilist conviction that nothing means anything anymore and figuring out why our lives are worth living.&lt;/p&gt;
    &lt;p&gt;Deep down, we all want to read and engage with literature to find meaning in our own lives. Back in the early 1900s, Babbitt knew that, too. The sooner English departments and the publishing industry reach this very conclusion, the sooner we’ll see great books line our shelves again.&lt;/p&gt;
    &lt;p&gt;In the meantime, I’ll take Anna Karenina over My Year of Rest and Relaxation any day.&lt;/p&gt;
    &lt;p&gt;Liza Libes is a writer and educator. Her writing has previously appeared in the Boston Globe, Persuasion, Minding the Campus, and her Substack, Pens and Poison.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jamesgmartin.center/2025/12/how-postmodernism-killed-great-literature/"/><published>2025-12-26T11:43:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391391</id><title>Codex vs. Claude Code (today)</title><updated>2025-12-26T15:11:22.775412+00:00</updated><content>&lt;doc fingerprint="b66d077e3a86ce8d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Codex vs. Claude Code (Today)&lt;/head&gt;
    &lt;p&gt;Every programmer has their favorite language. Some prefer Python, while others swear by TypeScript1. Many teams build their apps on Postgres, while others use MySQL. These choices are often flame-war bait for programmers with strong opinions, but most of these decisions are centered around pragmatism, priorities, and tradeoffs. They’re reflections of different working styles, rather than moral statements.&lt;/p&gt;
    &lt;p&gt;All of this applies to the choices people make when they decide whether to use Claude Code or Codex.&lt;/p&gt;
    &lt;p&gt;Before we continue, I need to make a disclaimer: This post is about the Claude Code and Codex, on December 22, 2025. Everything in AI changes so fast that I have almost no expectations about the validity of these statements in a year, or probably even 3-6 months from now.&lt;/p&gt;
    &lt;p&gt;I also must emphasize that both Codex and Claude Code are already superhuman developers. I don’t say that solely based on the quality of outputs from Opus 4.5 and codex-5.2-high, but in how they work. Codex and Claude Code sometimes arrive at a solution in ways that almost feel alien to how we think about coding, much like AlphaGo’s Move 37.&lt;/p&gt;
    &lt;p&gt;I keep up with every AI tool I can so I can teach AI to anyone and everyone, but it’s becoming more of a necessity for all software developers. When it comes to coding I’ve mostly settled into using Codex for “coding”, and I put coding in quotes because the process is very different than writing code by hand. I spend anywhere from 30 minutes to two hours writing prompts and generating context for Codex, then the task runs for 15-20 minutes while I context-switch to something else entirely. When I come back, I’ve got somewhere between a day and a week’s worth of code waiting for me.&lt;/p&gt;
    &lt;p&gt;But I still use Claude Code a lot. The coding environment they’ve built is exceptional. Much like Peter Steinberger describes Claude Code as his computer, I delegate all sorts of tasks to Claude Code. I’ll use Skills to transcribe videos to mp3s, generate a dark mode color palette for my website, or quickly prototype an idea from a blog post.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why People Love Codex&lt;/head&gt;
    &lt;p&gt;When I need something done and done right, I call on Codex. The reason is simple: the results are unbelievably good for me. And that’s because of how I work. By investing time into context engineering and context plumbing, I’m able to stay hands-off-keyboard for much longer.&lt;/p&gt;
    &lt;p&gt;Having long-running tasks might sound like a drawback, but it’s just a different way to work. When I send Codex off to do a task that takes 20 minutes, I switch my focus entirely. I’ll open Figma to do some design work, write my newsletter, or open another terminal and prompt Codex with some server work while the first terminal is chugging along on some client work.&lt;/p&gt;
    &lt;p&gt;I’d rather have everything take longer and generate results that I don’t have to fix than be involved in the process steering AI to success. That’s the working style that suits me best. OpenAI’s latest models deliver better results than the latest Claude models with less need to be in the loop. So while that remains true, I’ll mostly stick with Codex.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why People Love Claude Code&lt;/head&gt;
    &lt;p&gt;And that brings me to my theory of why many engineers prefer Claude Code. Claude makes you feel more like you’re doing engineering work — and surprise — engineers love engineering work. Source: I’m an engineer.&lt;/p&gt;
    &lt;p&gt;Claude has a lot of knobs to turn. You’ve got your CLAUDE.md, Skills, Agents, MCP, slash commands, and so much more. Codex has similar features, but it tends to produce high-quality results out of the box. Claude on the other hand works best when you finely tune those knobs, and Anthropic really encourages you to do so in their developer relations and marketing.&lt;/p&gt;
    &lt;p&gt;This is a perfect match for engineers who love configuring their environments. I can’t tell you how many full days of my life I’ve lost trying out new Xcode features or researching VS Code extensions that in practice make me 0.05% more productive.&lt;/p&gt;
    &lt;p&gt;Personally — and I do emphasize this is a personal decision — I‘d rather write a well-spec’d plan and go do something else for 15 minutes. Claude’s Plan Mode is exceptional, and that‘s why so many people fall in love with Claude once they try it.2&lt;/p&gt;
    &lt;p&gt;Many engineers would rather be hands-on and guide the software development process step by step — which is very understandable when you consider what flow state looks like. Claude will ask you a ton of questions and interrupt itself more frequently to make sure it’s not heading in the wrong direction. That really makes you feel like you’re doing heads-down engineering work.&lt;/p&gt;
    &lt;head rend="h3"&gt;So Should I Use Codex or Claude?&lt;/head&gt;
    &lt;p&gt;I think back to coworkers I’ve had over the years, and their varying preferences. Some people couldn’t start coding until they had a checklist of everything they needed to do to solve a problem. Others would dive right in and prototype to learn about the space they would be operating in.&lt;/p&gt;
    &lt;p&gt;The tools we use to build are moving fast and hard to keep up with, but we’ve been blessed with a plethora of choices. The good news is that there is no wrong choice when it comes to AI. That’s why I don’t dismiss people who live in Claude Code, even though I personally prefer Codex.&lt;/p&gt;
    &lt;p&gt;The tool you choose should match how you work, not the other way around. If you use Claude, I’d suggest trying Codex for a week to see if maybe you’re a Codex person and didn’t know it. And if you use Codex, I’d recommend trying Claude Code for a week to see if maybe you’re more of a Claude person than you thought.&lt;/p&gt;
    &lt;p&gt;Maybe you’ll discover your current approach isn’t the best fit for you. Maybe you won’t. But I’m confident you’ll find that every AI tool has its strengths and weaknesses, and the only way to discover what they are is by using them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://build.ms/2025/12/22/codex-vs-claude-code-today/"/><published>2025-12-26T12:22:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391410</id><title>I'm a laptop weirdo and that's why I like my new Framework 13</title><updated>2025-12-26T15:11:22.193629+00:00</updated><content>&lt;doc fingerprint="560efd35c9737c9d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I'm a laptop weirdo and that's why I like my new Framework 13&lt;/head&gt;
    &lt;p&gt;This month I sold my 2021 M1 Max Macbook Pro and bought a Framework 13 DIY Edition laptop. After I got everything setup I sat down to write about the experience. Some ~4500 words later I realized I needed to break my thoughts into multiple posts.&lt;/p&gt;
    &lt;p&gt;See also:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Framework 13 DIY Edition Hardware Thoughts&lt;/item&gt;
      &lt;item&gt;Setting up my new Framework Laptop 13 DIY Edition with NixOS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My new Framework 13 laptop just arrived. After I finally set everything up I started writing a post about the experience. I thought I'd write a little bit about my previous laptops, but a lot of fond memories I had forgotten about came flooding back. The tinkerings and many openings of laptops past. If you will indulge me, I've been feeling nostalgic. This is for the other laptop weirdos out there that that feel the same.&lt;/p&gt;
    &lt;head rend="h3"&gt;I have a history of doing terrible acts to laptops&lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt; The only image I could find of my NC10 was this blurry, 2021 flip phone photo of me removing the windows sticker.&lt;/p&gt;
    &lt;p&gt;In 2008, I managed to get my hands on a Samsung NC10 Netbook in a fancy metallic blue color. [^ Back when netbooks where a thing circle 2007-2013] Prior to this I only had desktops. The specs were pretty humble (from wikipedia):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A single core 1.6 GHz Intel Atom N270&lt;/item&gt;
      &lt;item&gt;Integrated Intel GMA 950 graphics&lt;/item&gt;
      &lt;item&gt;1 GB DDR2 RAM&lt;/item&gt;
      &lt;item&gt;10.2 inch 1024x600 screen and a VGA connector of all things.&lt;/item&gt;
      &lt;item&gt;83-key keyboard rather than the usual 87 or 88 keys on a laptop.&lt;/item&gt;
      &lt;item&gt;A 160 GB HDD&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Something could be done about that though! You could upgrade the RAM to a powerful 2GB. You could replace the slow HDD with an SSD. You could add a touch screen. You could make a Hackintosh out of it if you replaced the wifi card. If you wanted to, you could do those things and I was a weirdo, so I did!&lt;/p&gt;
    &lt;p&gt;I found a lot of fun in trying to get as much as I could out of that hardware. In fact I'd say the act of doing all that was far more enjoyable than actually using the laptop once the tinkering was done. After the novelty and slowness of a Hackintosh wore off I put Linux on the Netbook. I still sought the thrill of the hunt.&lt;/p&gt;
    &lt;p&gt;I installed a lite weight distro CrunchBang [^ or just #!] and messed around. I read more about different minimalist distros and came across two others I could hop to: Arch and Gentoo. This feels like an inflection point in my life, I choose to try Arch since I wouldn't have to compile everything on a single core. [^ Who know what would have happened if I picked Gentoo. I might have a beard now.] The screen was small and I wanted to maximize its usefulness so I started trying tiling WMs. Why not XMonad?&lt;/p&gt;
    &lt;p&gt;It turns out the GMA950 was undervolted on the NC10. Someone made a shareware tool called the GMABooster that could restore the max clock rate. The original website http://www.gmabooster.com/home.htm is long toast and not on wayback. This Arch forum thread has details though:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;It allows a user, not a manufacturer to choose the desired GMA speed. It combines a sophisticated assembler-level technology and the user-friendly graphic user interface, offering You to near double the GMA core perfomance without even a need to restart a computer..&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The package was on AUR so I could squeeze out a little more performance. I could finally watch 480 YouTube videos instead of 360. At some point, long after I had stopped using the netbook, the AUR package became abandoned. I adopted it as maintainer and mirrored the binary in GitHub. This was the first time I ever was a package maintainer. [^ I am on a couple random packages in nixpkgs now.] Nowadays the package is memorialized in the the AUR archive.&lt;/p&gt;
    &lt;p&gt;I had a device that I could repeatedly break and remake. Did I do anything productive or meaningful with it? Absolutely not. Did I learn a lot in the process? I'd say so!&lt;/p&gt;
    &lt;head rend="h3"&gt;In the past you could do terrible things to Macbooks too&lt;/head&gt;
    &lt;p&gt;When I went to College I got a 2011 Macbook Pro. The kind that would overheat and desolder the GPU. [^ Some clever people have found hardware hacks to repair the problem https://www.jeffgeerling.com/blog/2017/fixing-2011-macbook-pro-booting-grey-screen-amd-radeon-video-glitch] Mine managed to last a long time and didn't need replacing until 2019. The RAM was not built-in yet on Macbooks. Apple said the model could only support up to 8GB total RAM, but you could actually get 16GB to work. Also, this was back when Macbooks had CD drives. I replaced the my drive with an Other World Computing DIY Optical Drive to HDD Upgrade Kit. [^ And you could put the drive into an "OWC SuperSlim" enclosure to turn it into a USB CD drive.] and installed SSDs in both slots. With two drives I was able to install rEFInd as a boot manager and triple boot:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OSX as a stable install for my course work&lt;/item&gt;
      &lt;item&gt;Windows for games&lt;/item&gt;
      &lt;item&gt;Linux so I could break my install repeatedly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I iterated on my Arch install so many times that I started to keep a checklist about my setup process to help me remember everything. Certain stylistic choices were set and still used to this day. [^ This is when I started using Inconsolata for a monospace font and Zenburn for a color scheme.] I couldn't change quite as many things about this laptop, but I still made an effort to change what I could.&lt;/p&gt;
    &lt;head rend="h3"&gt;As laptops grew thinner they grew more boring&lt;/head&gt;
    &lt;p&gt;When it came time for a new laptop I was not looking at Macbook Pros anymore. Apple had made changes, like the touch bar and removing magsafe, that felt like they were targeting a different audience. So instead I had been eyeing a ThinkPad.&lt;lb/&gt; [^ It's almost cliche to buy one and install Linux.] The prices on the Lenovo store are mostly made up and constantly discounted. My housemate had access to a corpo portal for Lenovo that let me get one at a heavily reduced price. The cost of 3 year service coverage was also discounted so I got some figuring it could help to cover cost of parts if if something failed.&lt;/p&gt;
    &lt;p&gt;So I bought a Gen 7 X1 Carbon and... I just used it. No mods were possible on this laptop. When I had an SSD failure I asked Lenovo if they could mail me the drive so I could do the install. They said they had to send someone to confirm the issue. So a technician came out and replaced the drive.&lt;/p&gt;
    &lt;head rend="h3"&gt;The gift and curse of a free Macbook Pro&lt;/head&gt;
    &lt;p&gt;Finally in 2023 I was laid off by HubSpot. Part of severance was the following:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Laptops &amp;amp; WFH Set-Up: Impacted employees may keep their HubSpot laptops (it will be cleaned of any company data remotely), as well as any work from home gear like monitors and keyboards.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Thus a pretty high spec 2021 M1 Max Macbook Pro fell into my lap. I gave my X1 Carbon to a friend to avoid creating yet more ewaste that sits in my closet.&lt;/p&gt;
    &lt;p&gt;The 2021 version was a bit of return to form: touch bar was gone, magsafe was back, etc. However even the iFixit review said the "design represents a major move in the right direction" but still only rated the laptop a 4/10 for repairability. [^ The score was eventually updated to a 5/10 when Apple later released a service manual and access to parts.]&lt;/p&gt;
    &lt;p&gt;I felt some dissonance though. If I was looking to buy a laptop, I wouldn't have picked this one. macOS was getting less enjoyable to use with each update. Likewise the Linux Desktop experience was really coming into its own. [^ By 2023 essentially all my games were playable!] However I felt bad about buying a new laptop when I now had a perfectly good one. So I held onto it and once again, no mods were done or could be done with this laptop.&lt;/p&gt;
    &lt;head rend="h3"&gt;Finally buying a Framework 13&lt;/head&gt;
    &lt;p&gt;I had waited on getting a Framework laptop because I wanted to see them go through a couple iterations. I wanted to see if the promise of repairing, replacing and upgrading actually came true. From what I read it mostly has! [^ People with Framework 15 do seem to be waiting though.]&lt;/p&gt;
    &lt;p&gt;What changed the decision for me was the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lugging around a powerful 16 inch laptop was a drag. Having a laptop when traveling is nice if I need to hurriedly rebook something. Mobile sites and apps tend to restrict you in weird ways.&lt;/item&gt;
      &lt;item&gt;Despite being a couple years old, the laptop was still worth a lot. People probably want Macbooks for local LLM inference. So I felt pretty good a buyer will actually use the laptop.&lt;/item&gt;
      &lt;item&gt;The Framework release a refresh of the 13 with the new AMD chips.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then I had a friend get Laptop 13 and attest to liking it. That was the last push I needed to finally buy one. Now I can be a laptop weirdo again.&lt;/p&gt;
    &lt;p&gt;You can't change the RAM on laptops now.&lt;lb/&gt; You can't change the SSD on laptops now.&lt;lb/&gt; You can't easily repair the screen on laptops now.&lt;/p&gt;
    &lt;p&gt;You can do all that and more with a Framework laptop.&lt;lb/&gt; You can be a laptop weirdo with a Framework laptop.&lt;/p&gt;
    &lt;p&gt;Weirdo typically has two interpretations:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A possibly dangerous person.&lt;/p&gt;&lt;lb/&gt;A strange, odd, eccentric person.&lt;/quote&gt;
    &lt;p&gt;To both of those I say: all us laptop weirdos can now put a snack drawer in our laptops.&lt;lb/&gt; You cannot stop us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.matthewbrunelle.com/im-a-laptop-weirdo-and-thats-why-i-like-my-new-framework-13/"/><published>2025-12-26T12:27:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391448</id><title>Unix "find" expressions compiled to bytecode</title><updated>2025-12-26T15:11:22.070786+00:00</updated><content>&lt;doc fingerprint="1fe85974ea331f40"&gt;
  &lt;main&gt;
    &lt;p&gt; nullprogram.com/blog/2025/12/23/ &lt;/p&gt;
    &lt;p&gt;In preparation for a future project, I was thinking about at the unix &lt;code&gt;find&lt;/code&gt; utility. It operates a file system hierarchies, with basic
operations selected and filtered using a specialized expression language.
Users compose operations using unary and binary operators, grouping with
parentheses for precedence. &lt;code&gt;find&lt;/code&gt; may apply the expression to a great
many files, so compiling it into a bytecode, resolving as much as possible
ahead of time, and minimizing the per-element work, seems like a prudent
implementation strategy. With some thought, I worked out a technique to do
so, which was simpler than I expected, and I’m pleased with the results. I
was later surprised all the real world &lt;code&gt;find&lt;/code&gt; implementations I examined
use tree-walk interpreters instead. This article describes how my
compiler works, with a runnable example, and lists ideas for improvements.&lt;/p&gt;
    &lt;p&gt;For a quick overview, the syntax looks like this:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find [-H|-L] path... [expression...]
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Technically at least one path is required, but most implementations imply &lt;code&gt;.&lt;/code&gt; when none are provided. If no expression is supplied, the default is
&lt;code&gt;-print&lt;/code&gt;, e.g. print everything under each listed path. This prints the
whole tree, including directories, under the current directory:&lt;/p&gt;
    &lt;p&gt;To only print files, we could use &lt;code&gt;-type f&lt;/code&gt;:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find . -type f -a -print
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Where &lt;code&gt;-a&lt;/code&gt; is the logical AND binary operator. &lt;code&gt;-print&lt;/code&gt; always evaluates
to true. It’s never necessary to write &lt;code&gt;-a&lt;/code&gt;, and adjacent operations are
implicitly joined with &lt;code&gt;-a&lt;/code&gt;. We can keep chaining them, such as finding
all executable files:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find . -type f -executable -print
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;If no &lt;code&gt;-exec&lt;/code&gt;, &lt;code&gt;-ok&lt;/code&gt;, or &lt;code&gt;-print&lt;/code&gt; (or similar side-effect extensions like
&lt;code&gt;-print0&lt;/code&gt; or &lt;code&gt;-delete&lt;/code&gt;) are present, the whole expression is wrapped in an
implicit &lt;code&gt;( expr ) -print&lt;/code&gt;. So we could also write this:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find . -type f -executable
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Use &lt;code&gt;-o&lt;/code&gt; for logical OR. To print all files with the executable bit or
with a &lt;code&gt;.exe&lt;/code&gt; extension:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find . -type f \( -executable -o -name '*.exe' \)
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;I needed parentheses because &lt;code&gt;-o&lt;/code&gt; has lower precedence than &lt;code&gt;-a&lt;/code&gt;, and
because parentheses are shell metacharacters I also needed to escape them
for the shell. It’s a shame &lt;code&gt;find&lt;/code&gt; didn’t use &lt;code&gt;[&lt;/code&gt; and &lt;code&gt;]&lt;/code&gt; instead! There’s
also a unary logical NOT operator, &lt;code&gt;!&lt;/code&gt;. To print all non-executable files:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find . -type f ! -executable
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Binary operators are short-circuiting, so this:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find -type d -a -exec du -sh {} +
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Only lists the sizes of directories, as the &lt;code&gt;-type d&lt;/code&gt; fails causing the
whole expression to evaluate to false without evaluating &lt;code&gt;-exec&lt;/code&gt;. Or
equivalently with &lt;code&gt;-o&lt;/code&gt;:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find ! -type d -o -exec du -sh {} +
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;If it’s not a directory then the left-hand side evaluates to true, and the right-hand side is not evaluated. All three implementations I examined (GNU, BSD, BusyBox) have a &lt;code&gt;-regex&lt;/code&gt; extension, and eagerly compile the
regular expression even if the operation is never evaluated:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ find . -print -o -regex [
find: bad regex '[': Invalid regular expression
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;I was surprised by this because it doesn’t seem to be in the spirit of the original utility (“The second expression shall not be evaluated if the first expression is true.”), and I’m used to the idea of short-circuit validation for the right-hand side of a logical expression. Recompiling for each evaluation would be unwise, but it could happen lazily such that an invalid regular expression only causes an error if it’s actually used. No big deal, just a curiosity.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bytecode design&lt;/head&gt;
    &lt;p&gt;A bytecode interpreter needs to track just one result at a time, making it a single register machine, with a 1-bit register at that. I came up with these five opcodes:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;halt
not
braf   LABEL
brat   LABEL
action NAME [ARGS...]
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Obviously &lt;code&gt;halt&lt;/code&gt; stops the program. While I could just let it “run off the
end” it’s useful to have an actual instruction so that I can attach a
label and jump to it. The &lt;code&gt;not&lt;/code&gt; opcode negates the register. &lt;code&gt;braf&lt;/code&gt; is
“branch if false”, jumping (via relative immediate) to the labeled (in
printed form) instruction if the register is false. &lt;code&gt;brat&lt;/code&gt; is “branch if
true”. Together they implement the &lt;code&gt;-a&lt;/code&gt; and &lt;code&gt;-o&lt;/code&gt; operators. In practice
there are no loops and jumps are always forward: &lt;code&gt;find&lt;/code&gt; is not Turing
complete.&lt;/p&gt;
    &lt;p&gt;In a real implementation each possible action (&lt;code&gt;-name&lt;/code&gt;, &lt;code&gt;-ok&lt;/code&gt;, &lt;code&gt;-print&lt;/code&gt;,
&lt;code&gt;-type&lt;/code&gt;, etc.) would get a dedicated opcode. This requires implementing
each operator, at least in part, in order to correctly parse the whole
&lt;code&gt;find&lt;/code&gt; expression. For now I’m just focused on the bytecode compiler, so
this opcode is a stand-in, and it kind of pretends based on looks. Each
action sets the register, and actions like &lt;code&gt;-print&lt;/code&gt; always set it to true.
My compiler is called &lt;code&gt;findc&lt;/code&gt; (“find compiler”).&lt;/p&gt;
    &lt;p&gt;Update: Or try the online demo via Wasm! This version includes a peephole optimizer I wrote after publishing this article.&lt;/p&gt;
    &lt;p&gt;I assume readers of this program are familiar with &lt;code&gt;push&lt;/code&gt; macro
and &lt;code&gt;Slice&lt;/code&gt; macro. Because of the latter it requires a very
recent C compiler, like GCC 15 (e.g. via w64devkit) or Clang 22. Try
out some &lt;code&gt;find&lt;/code&gt; commands and see how they appear as bytecode. The simplest
case is also optimal:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ findc
// path: .
        action  -print
        halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Print the path then halt. Simple. Stepping it up:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ findc -type f -executable
// path: .
        action  -type f
        braf    L1
        action  -executable
L1:     braf    L2
        action  -print
L2:     halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;If the path is not a file, it skips over the rest of the program by way of the second branch instruction. It’s correct, but already we can see room for improvement. This would be better:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;        action  -type f
        braf    L1
        action  -executable
        braf    L1
        action  -print
L1:     halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;More complex still:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ findc -type f \( -executable -o -name '*.exe' \)
// path: .
        action  -type f
        braf    L1
        action  -executable
        brat    L1
        action  -name *.exe
L1:     braf    L2
        action  -print
L2:     halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Inside the parentheses, if &lt;code&gt;-executable&lt;/code&gt; succeeds, the right-hand side is
skipped. Though the &lt;code&gt;brat&lt;/code&gt; jumps straight to a &lt;code&gt;braf&lt;/code&gt;. It would be better
to jump ahead one more instruction:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;        action  -type f
        braf    L2
        action  -executable
        brat    L1
        action  -name *.exe
        braf    L2
L1      action  -print
L2:     halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Silly things aren’t optimized either:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ findc ! ! -executable
// path: .
        action  -executable
        not
        not
        braf    L1
        action  -print
L1:     halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Two &lt;code&gt;not&lt;/code&gt; in a row cancel out, and so these instructions could be
eliminated. Overall this compiler could benefit from a peephole
optimizer, scanning over the program repeatedly, making small
improvements until no more can be made:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Delete &lt;code&gt;not&lt;/code&gt;-&lt;code&gt;not&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;A &lt;code&gt;brat&lt;/code&gt; to a &lt;code&gt;braf&lt;/code&gt; re-targets ahead one instruction, and vice versa.&lt;/item&gt;
      &lt;item&gt;Jumping onto an identical jump adopts its target for itself.&lt;/item&gt;
      &lt;item&gt;A &lt;code&gt;not&lt;/code&gt;-&lt;code&gt;braf&lt;/code&gt; might convert to a &lt;code&gt;brat&lt;/code&gt;, and vice versa.&lt;/item&gt;
      &lt;item&gt;Delete side-effect-free instructions before &lt;code&gt;halt&lt;/code&gt; (e.g. &lt;code&gt;not&lt;/code&gt;-&lt;code&gt;halt&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Exploit always-true actions, e.g. &lt;code&gt;-print&lt;/code&gt;-&lt;code&gt;braf&lt;/code&gt; can drop the branch.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Writing a bunch of peephole pattern matchers sounds kind of fun. Though my compiler would first need a slightly richer representation in order to detect and fix up changes to branches. One more for the road:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;$ findc -type f ! \( -executable -o -name '*.exe' \)
// path: .
        action  -type f
        braf    L1
        action  -executable
        brat    L2
        action  -name *.exe
L2:     not
L1:     braf    L3
        action  -print
L3:     halt
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;The unoptimal jumps hint at my compiler’s structure. If you’re feeling up for a challenge, pause here to consider how you’d build this compiler, and how it might produce these particular artifacts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Parsing and compiling&lt;/head&gt;
    &lt;p&gt;Before I even considered the shape of the bytecode I knew I needed to convert &lt;code&gt;find&lt;/code&gt; infix into a compiler-friendly postfix. That is, this:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;-type f -a ! ( -executable -o -name *.exe )
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Becomes:&lt;/p&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;quote&gt;
          &lt;code&gt;-type f -executable -name *.exe -o ! -a
&lt;/code&gt;
        &lt;/quote&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;p&gt;Which, importantly, erases the parentheses. This comes in as an &lt;code&gt;argv&lt;/code&gt;
array, so it’s already tokenized for us by the shell or runtime. The
classic shunting-yard algorithm solves this problem easily enough.
We have an output queue that goes into the compiler, and a token stack for
tracking &lt;code&gt;-a&lt;/code&gt;, &lt;code&gt;-o&lt;/code&gt;, &lt;code&gt;!&lt;/code&gt;, and &lt;code&gt;(&lt;/code&gt;. Then we walk &lt;code&gt;argv&lt;/code&gt; in order:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Actions go straight into the output queue.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If we see one of the special stack tokens we push it onto the stack, first popping operators with greater precedence into the queue, stopping at &lt;code&gt;(&lt;/code&gt;.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If we see &lt;code&gt;)&lt;/code&gt; we pop the stack into the output queue until we see &lt;code&gt;(&lt;/code&gt;.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;When we’re out of tokens, pop the remaining stack into the queue. My parser synthesizes &lt;code&gt;-a&lt;/code&gt; where it’s implied, so the compiler always sees
logical AND. If the expression contains no &lt;code&gt;-exec&lt;/code&gt;, &lt;code&gt;-ok&lt;/code&gt;, or &lt;code&gt;-print&lt;/code&gt;,
after processing is complete the parser puts &lt;code&gt;-print&lt;/code&gt; then &lt;code&gt;-a&lt;/code&gt; into the
queue, which effectively wraps the whole expression in &lt;code&gt;( expr ) -print&lt;/code&gt;.
By clearing the stack first, the real expression is effectively wrapped in
parentheses, so no parenthesis tokens need to be synthesized.&lt;/p&gt;
    &lt;p&gt;I’ve used the shunting-yard algorithm many times before, so this part was easy. The new part was coming up with an algorithm to convert a series of postfix tokens into bytecode. My solution is the compiler maintains a stack of bytecode fragments. That is, each stack element is a sequence of one or more bytecode instructions. Branches use relative addresses, so they’re position-independent, and I can concatenate code fragments without any branch fix-ups. It takes the following actions from queue tokens:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;For an action token, create an &lt;code&gt;action&lt;/code&gt; instruction, and push it onto
the fragment stack as a new fragment.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For a &lt;code&gt;!&lt;/code&gt; token, pop the top fragment, append a &lt;code&gt;not&lt;/code&gt; instruction, and
push it back onto the stack.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For a &lt;code&gt;-a&lt;/code&gt; token, pop the top two fragments, join then with a &lt;code&gt;braf&lt;/code&gt; in
the middle which jumps just beyond the second fragment. That is, if the
first fragment evaluates to false, skip over the second fragment into
whatever follows.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For a &lt;code&gt;-o&lt;/code&gt; token, just like &lt;code&gt;-a&lt;/code&gt; but use &lt;code&gt;brat&lt;/code&gt;. If the first fragment
is true, we skip over the second fragment.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If the expression is valid, at the end of this process the stack contains exactly one fragment. Append a &lt;code&gt;halt&lt;/code&gt; instruction to this fragment, and
that’s our program! If the final fragment contained a branch just beyond
its end, this &lt;code&gt;halt&lt;/code&gt; is that branch target. A few peephole optimizations
and could probably be an optimal program for this instruction set.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nullprogram.com/blog/2025/12/23/"/><published>2025-12-26T12:35:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391472</id><title>ChatGPT conversations still lack timestamps after years of requests</title><updated>2025-12-26T15:11:21.845385+00:00</updated><content/><link href="https://community.openai.com/t/timestamps-for-chats-in-chatgpt/440107?page=3"/><published>2025-12-26T12:39:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391514</id><title>Package managers keep using Git as a database, it never works out</title><updated>2025-12-26T15:11:21.526955+00:00</updated><content>&lt;doc fingerprint="b324261b0df047d8"&gt;
  &lt;main&gt;
    &lt;p&gt;Using git as a database is a seductive idea. You get version history for free. Pull requests give you a review workflow. It’s distributed by design. GitHub will host it for free. Everyone already knows how to use it.&lt;/p&gt;
    &lt;p&gt;Package managers keep falling for this. And it keeps not working out.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cargo&lt;/head&gt;
    &lt;p&gt;The crates.io index started as a git repository. Every Cargo client cloned it. This worked fine when the registry was small, but the index kept growing. Users would see progress bars like “Resolving deltas: 74.01%, (64415/95919)” hanging for ages, the visible symptom of Cargo’s libgit2 library grinding through delta resolution on a repository with thousands of historic commits.&lt;/p&gt;
    &lt;p&gt;The problem was worst in CI. Stateless environments would download the full index, use a tiny fraction of it, and throw it away. Every build, every time.&lt;/p&gt;
    &lt;p&gt;RFC 2789 introduced a sparse HTTP protocol. Instead of cloning the whole index, Cargo now fetches files directly over HTTPS, downloading only the metadata for dependencies your project actually uses. (This is the “full index replication vs on-demand queries” tradeoff in action.) By April 2025, 99% of crates.io requests came from Cargo versions where sparse is the default. The git index still exists, still growing by thousands of commits per day, but most users never touch it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Homebrew&lt;/head&gt;
    &lt;p&gt;GitHub explicitly asked Homebrew to stop using shallow clones. Updating them was “an extremely expensive operation” due to the tree layout and traffic of homebrew-core and homebrew-cask.&lt;/p&gt;
    &lt;p&gt;Users were downloading 331MB just to unshallow homebrew-core. The .git folder approached 1GB on some machines. Every &lt;code&gt;brew update&lt;/code&gt; meant waiting for git to grind through delta resolution.&lt;/p&gt;
    &lt;p&gt;Homebrew 4.0.0 in February 2023 switched to JSON downloads for tap updates. The reasoning was blunt: “they are expensive to git fetch and git clone and GitHub would rather we didn’t do that… they are slow to git fetch and git clone and this provides a bad experience to end users.”&lt;/p&gt;
    &lt;p&gt;Auto-updates now run every 24 hours instead of every 5 minutes, and they’re much faster because there’s no git fetch involved.&lt;/p&gt;
    &lt;head rend="h2"&gt;CocoaPods&lt;/head&gt;
    &lt;p&gt;CocoaPods is the package manager for iOS and macOS development. It hit the limits hard. The Specs repo grew to hundreds of thousands of podspecs across a deeply nested directory structure. Cloning took minutes. Updating took minutes. CI time vanished into git operations.&lt;/p&gt;
    &lt;p&gt;GitHub imposed CPU rate limits. The culprit was shallow clones, which force GitHub’s servers to compute which objects the client already has. The team tried various band-aids: stopping auto-fetch on &lt;code&gt;pod install&lt;/code&gt;, converting shallow clones to full clones, sharding the repository.&lt;/p&gt;
    &lt;p&gt;The CocoaPods blog captured it well: “Git was invented at a time when ‘slow network’ and ‘no backups’ were legitimate design concerns. Running endless builds as part of continuous integration wasn’t commonplace.”&lt;/p&gt;
    &lt;p&gt;CocoaPods 1.8 gave up on git entirely for most users. A CDN became the default, serving podspec files directly over HTTP. The migration saved users about a gigabyte of disk space and made &lt;code&gt;pod install&lt;/code&gt; nearly instant for new setups.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nixpkgs&lt;/head&gt;
    &lt;p&gt;Nixpkgs is currently stress-testing GitHub’s infrastructure. In November 2025, GitHub contacted the NixOS team about periodic maintenance jobs failing and causing “issues achieving consensus between replicas.” If unresolved, the repository could have become read-only.&lt;/p&gt;
    &lt;p&gt;The repository totals 83GB with half a million tree objects and 20,000 forks. A local clone is only 2.5GB — the rest is GitHub’s fork network storing every pull request branch and merge commit. The CI queries mergeability daily, creating new merge commits each time.&lt;/p&gt;
    &lt;p&gt;Unlike CocoaPods, Nixpkgs can’t easily move to a CDN. The Nix expressions are the package definitions, not metadata pointing elsewhere. Binary caches already serve built packages over HTTP, but nixpkgs itself remains a git repository — and it’s still growing.&lt;/p&gt;
    &lt;head rend="h2"&gt;vcpkg&lt;/head&gt;
    &lt;p&gt;vcpkg is Microsoft’s C++ package manager. It uses git tree hashes to version its ports, with the curated registry at github.com/Microsoft/vcpkg containing over 2,000 libraries.&lt;/p&gt;
    &lt;p&gt;The problem is that vcpkg needs to retrieve specific versions of ports by their git tree hash. When you specify a &lt;code&gt;builtin-baseline&lt;/code&gt; in your vcpkg.json (functioning like a lockfile for reproducible builds), vcpkg looks up historical commits to find the exact port versions you need. This only works if you have the full commit history.&lt;/p&gt;
    &lt;p&gt;Shallow clones break everything. GitHub Actions uses shallow clones by default. DevContainers shallow-clone vcpkg to save space. CI systems optimize for fast checkouts. All of these result in the same error: “vcpkg was cloned as a shallow repository… Try again with a full vcpkg clone.”&lt;/p&gt;
    &lt;p&gt;The workarounds are ugly. One proposed solution involves parsing vcpkg.json to extract the baseline hash, deriving the commit date, then fetching with &lt;code&gt;--shallow-since=&amp;lt;date&amp;gt;&lt;/code&gt;. Another suggests including twelve months of history, hoping projects upgrade before their baseline falls off the cliff. For GitHub Actions, you need &lt;code&gt;fetch-depth: 0&lt;/code&gt; in your checkout step, downloading the entire repository history just to resolve dependencies.&lt;/p&gt;
    &lt;p&gt;A vcpkg team member explained the fundamental constraint: “Port versions don’t use commit hashes, we use the git tree hash of the port directory. As far as I know, there is no way to deduce the commit that added a specific tree hash.” An in-product fix is infeasible. The architecture baked in git deeply enough that there’s no escape hatch.&lt;/p&gt;
    &lt;p&gt;Unlike Cargo, Homebrew, and CocoaPods, vcpkg hasn’t announced plans to move away from git registries. Custom registries must still be git repositories. The documentation describes filesystem registries as an alternative, but these require local or mounted paths rather than HTTP access. There’s no CDN, no sparse protocol, no HTTP-based solution on the horizon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Go modules&lt;/head&gt;
    &lt;p&gt;Grab’s engineering team went from 18 minutes for &lt;code&gt;go get&lt;/code&gt; to 12 seconds after deploying a module proxy. That’s not a typo. Eighteen minutes down to twelve seconds.&lt;/p&gt;
    &lt;p&gt;The problem was that &lt;code&gt;go get&lt;/code&gt; needed to fetch each dependency’s source code just to read its go.mod file and resolve transitive dependencies. Cloning entire repositories to get a single file.&lt;/p&gt;
    &lt;p&gt;Go had security concerns too. The original design wanted to remove version control tools entirely because “these fragment the ecosystem: packages developed using Bazaar or Fossil, for example, are effectively unavailable to users who cannot or choose not to install these tools.” Beyond fragmentation, the Go team worried about security bugs in version control systems becoming security bugs in &lt;code&gt;go get&lt;/code&gt;. You’re not just importing code; you’re importing the attack surface of every VCS tool on the developer’s machine.&lt;/p&gt;
    &lt;p&gt;GOPROXY became the default in Go 1.13. The proxy serves source archives and go.mod files independently over HTTP. Go also introduced a checksum database (sumdb) that records cryptographic hashes of module contents. This protects against force pushes silently changing tagged releases, and ensures modules remain available even if the original repository is deleted.&lt;/p&gt;
    &lt;head rend="h2"&gt;Beyond package managers&lt;/head&gt;
    &lt;p&gt;The same pattern shows up wherever developers try to use git as a database.&lt;/p&gt;
    &lt;p&gt;Git-based wikis like Gollum (used by GitHub and GitLab) become “somewhat too slow to be usable” at scale. Browsing directory structure takes seconds per click. Loading pages takes longer. GitLab plans to move away from Gollum entirely.&lt;/p&gt;
    &lt;p&gt;Git-based CMS platforms like Decap hit GitHub’s API rate limits. A Decap project on GitHub scales to about 10,000 entries if you have a lot of collection relations. A new user with an empty cache makes a request per entry to populate it, burning through the 5,000 request limit quickly. If your site has lots of content or updates frequently, use a database instead.&lt;/p&gt;
    &lt;p&gt;Even GitOps tools that embrace git as a source of truth have to work around its limitations. ArgoCD’s repo server can run out of disk space cloning repositories. A single commit invalidates the cache for all applications in that repo. Large monorepos need special scaling considerations.&lt;/p&gt;
    &lt;head rend="h2"&gt;The pattern&lt;/head&gt;
    &lt;p&gt;The hosting problems are symptoms. The underlying issue is that git inherits filesystem limitations, and filesystems make terrible databases.&lt;/p&gt;
    &lt;p&gt;Directory limits. Directories with too many files become slow. CocoaPods had 16,000 pod directories in a single Specs folder, requiring huge tree objects and expensive computation. Their fix was hash-based sharding: split directories by the first few characters of a hashed name, so no single directory has too many entries. Git itself does this internally with its objects folder, splitting into 256 subdirectories. You’re reinventing B-trees, badly.&lt;/p&gt;
    &lt;p&gt;Case sensitivity. Git is case-sensitive, but macOS and Windows filesystems typically aren’t. Check out a repo containing both &lt;code&gt;File.txt&lt;/code&gt; and &lt;code&gt;file.txt&lt;/code&gt; on Windows, and the second overwrites the first. Azure DevOps had to add server-side enforcement to block pushes with case-conflicting paths.&lt;/p&gt;
    &lt;p&gt;Path length limits. Windows restricts paths to 260 characters, a constraint dating back to DOS. Git supports longer paths, but Git for Windows inherits the OS limitation. This is painful with deeply nested node_modules directories, where &lt;code&gt;git status&lt;/code&gt; fails with “Filename too long” errors.&lt;/p&gt;
    &lt;p&gt;Missing database features. Databases have CHECK constraints and UNIQUE constraints; git has nothing, so every package manager builds its own validation layer. Databases have locking; git doesn’t. Databases have indexes for queries like “all packages depending on X”; with git you either traverse every file or build your own index. Databases have migrations for schema changes; git has “rewrite history and force everyone to re-clone.”&lt;/p&gt;
    &lt;p&gt;The progression is predictable. Start with a flat directory of files. Hit filesystem limits. Implement sharding. Hit cross-platform issues. Build server-side enforcement. Build custom indexes. Eventually give up and use HTTP or an actual database. You’ve built a worse version of what databases already provide, spread across git hooks, CI pipelines, and bespoke tooling.&lt;/p&gt;
    &lt;p&gt;None of this means git is bad. Git excels at what it was designed for: distributed collaboration on source code, with branching, merging, and offline work. The problem is using it for something else entirely. Package registries need fast point queries for metadata. Git gives you a full-document sync protocol when you need a key-value lookup.&lt;/p&gt;
    &lt;p&gt;If you’re building a package manager and git-as-index seems appealing, look at Cargo, Homebrew, CocoaPods, vcpkg, Go. They all had to build workarounds as they grew, causing pain for users and maintainers. The pull request workflow is nice. The version history is nice. You will hit the same walls they did.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html"/><published>2025-12-26T12:46:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391599</id><title>LearnixOS</title><updated>2025-12-26T15:11:21.415271+00:00</updated><content>&lt;doc fingerprint="7fe43b9d48af5e9f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Learnix Operating System&lt;/head&gt;
    &lt;p&gt;"If you can't explain it simply, you don't understand it well enough." - Albert Einstein&lt;/p&gt;
    &lt;p&gt;Hello there!1&lt;/p&gt;
    &lt;p&gt;In this book we are going to write and learn about operating systems together!&lt;/p&gt;
    &lt;p&gt;We are going to implement an entire POSIX compliant OS in Rust and not use ANY2 external libraries. All of the thought process, code and implementations will be explained and documented here as well as in this repo which all the code snippets are from.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: ALL the syntax highlighting of the Rust code is custom and create by me! If you see and bug, please write in the comments or submit an issue.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Base Knowledge&lt;/head&gt;
    &lt;p&gt;This book will be technical, and will assume a little bit of a programming knowledge background, but not necessarily in rust&lt;/p&gt;
    &lt;p&gt;If you are not coming from a low level programming knowledge that's fine!&lt;/p&gt;
    &lt;p&gt;Just make sure you know this stuff or learn it as you read. Also if in any place on this book I take some things for granted, please, open an issue here and let me know so I could explain it better.&lt;/p&gt;
    &lt;p&gt;Some of the base knowledge that you would need to have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Some assembly knowledge. (just understand simple movs, and arithmetic operations, at a very basic level3)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Some knowledge on memory. (what's a pointer, what's an address)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A knowledge in rust is not that important, but knowing at least one programming language is. I myself have some more learning in Rust, and in this book I will also explain some great features that it has!&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A lot of motivation to learn and understand because it is a complex subject.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Roadmap of this book&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Compiling a stand alone binary&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Boot loading, Debugging, stages and some legacy stuff&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Important cpu modes and instructions&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Paging, writing out own malloc&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Utilizing the Interrupt Descriptor Table&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;File systems and Disk Drivers&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Thinking in terms of processes&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Writing a shell&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Running our first program! (Which off course will be Doom)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;To be continued (Hopefully virtualization section and loading a vm of other OS)&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.learnix-os.com"/><published>2025-12-26T12:59:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46391744</id><title>Undefinable yet Indispensable</title><updated>2025-12-26T15:11:21.174750+00:00</updated><content>&lt;doc fingerprint="fe63d99500e202bf"&gt;
  &lt;main&gt;
    &lt;p&gt;Listen to this essay&lt;/p&gt;
    &lt;p&gt;We tend to think of religion as an age-old feature of human existence. So it can be startling to learn that the very concept dates to the early modern era. Yes, you find gods, temples, sacrifices and rituals in the ancient Mediterranean, classical China, pre-Columbian Mesoamerica. What you don’t find is a term that quite maps onto ‘religion’.&lt;/p&gt;
    &lt;p&gt;What about the Romans, to whom we owe the word? Their notion of religio once meant something like scruples or exactingness, and then came to refer, among other things, to a scrupulous observance of rules or prohibitions, extending to worship practices. It was about doing the right thing in the right way. The Romans had other terms as well for customs, rites, obligations, reverence and social protocols, including cultus, ritus and superstitio. Yet they weren’t cordoned off into a realm that was separate from the workaday activities of public life, civic duty and family proprieties. What the Romans encountered abroad were, in their eyes, more or less eccentric versions of cultic life, rather than alien ‘religions’, in our sense. It was assumed that other localities would have other divinities; in times of war, you might even summon them, via evocatio, to try to get them to switch sides. But the local gods and rites of foreigners could be assessed without categorising them as instances of a single universal genus.&lt;/p&gt;
    &lt;p&gt;Even after the empire became officially Christian, you still don’t get our sense of ‘religions’. The Romans don’t start sorting the world into bounded systems analogous to ‘Christianity’, ‘Judaism’, ‘Manichaeism’, ‘Islam’ and so on. They have other, older sorting mechanisms, as Brent Nongbri elaborates in his terrific study Before Religion (2013). When Lactantius, in the 4th century, contrasts vera religio with falsae religiones, he means to distinguish right worship from wrong worship; he isn’t identifying other self-contained systems that might be lined up on a chart for comparison. The Christians of late antiquity didn’t view themselves as possessing one religion among many; they viewed themselves as possessing the truth.&lt;/p&gt;
    &lt;p&gt;To arrive at the modern category of religion, scholars now tend to think, you needed a complementary ‘secular’ sphere: a sphere that wasn’t, well, religious. That’s why the word’s modern, comparative sense wasn’t firmly established until the 17th century – Hugo Grotius’s De veritate religionis Christianae (1627) is one touchstone – at a time when European Christendom was both splintering and confronting unfamiliar worlds through exploration and conquest. Even as religion could be conceived as a special domain that might be isolated from law and politics, the traffic with ancient and non-European cultures forced reflection on what counted as ‘true religion’. It’s just that, when Europeans looked at India, Africa, China or the ancient Mediterranean, they sifted for Christian-like (and often Protestant-like) elements: a sacred text to anchor authority, a prophetic founder to narrate origins, a set of theological doctrines to sort out orthodoxy and heresy, and perhaps duties that offered a path to salvation. If a tradition didn’t provide these, scholars might helpfully supply them. In time, ‘world religions’ could be conjured up as bounded systems with creeds and essences, even when the local practices they subsumed were profoundly heterogeneous. Traditions with no founders were given founders; traditions with no single scripture were assigned canonical texts; diverse local rites were bundled into overarching systems.&lt;/p&gt;
    &lt;p&gt;As world religions took hold as a subject of academic study in the later 19th century, European scholars did their systematic best to treat disparate systems of practice and thought as members of a class. Buddhism became one test case. To call it a single ‘religion’, scholars first had to unify various practices of South, Central and East Asia, and then to decide whether a sometimes godless tradition could qualify. Such struggles over classification exposed a deeper uncertainty: how was ‘religion’ to be defined?&lt;/p&gt;
    &lt;p&gt;The great minds of the era had ideas. John Stuart Mill held that a religion must unite creed, sentiment and moral authority. Herbert Spencer thought that what religions shared was ‘the tacit conviction that the existence of the world with all it contains and all which surrounds it, is a mystery ever pressing for interpretation.’ The anthropologist Edward B Tylor proposed, as a minimum definition, ‘belief in spiritual beings’. The philologist Max Müller called religion a ‘mental faculty’, separate from ‘sense and reason’, by which humans apprehend the Infinite. For the Old Testament scholar and Orientalist William Robertson Smith, the true foundation of religious life was ritual – the binding force of collective acts. The sociologist Émile Durkheim’s own definition, in his classic The Elementary Forms of Religious Life (1912), joined belief to behaviour and belonging: religion, he wrote, was ‘a unified system of beliefs and practices relative to sacred things’ that united its adherents ‘into one moral community, called the Church’.&lt;/p&gt;
    &lt;p&gt;These definitions came up short because they excluded too much or included too much. Either they failed to net the fish you were after or they netted too much bycatch. Mill wanted creed, emotion and moral suasion in one package, but many traditions that Europeans encountered in the 19th century didn’t distribute those elements in anything like that pattern. Did a religion involve a metaphysical stance on the cosmos and our place within it – was it driven by the ever-pressing ontological mysteries that Spencer considered central? What we’d call ancient Judaism had very little of that; the biblical writers do not stand before the universe feeling compelled to develop a worldview; they stand within a covenantal drama, entwining law, story and communal identity. And then Müller’s definition could apply to a Romantic poet. (Wilhelm Müller, Max’s father, was a great one.) Dubious of belief-based accounts like Tylor’s, Robertson Smith had concluded that ‘the antique religions had for the most part no creed; they consisted entirely of institutions and practices,’ and ‘while the practice was rigorously fixed, the meaning attached to it was extremely vague.’ Robertson Smith’s own corrective faltered in the face of practices that were communal but not in any obvious way ‘sacred’, or traditions in which doctrine mattered intensely. Durkheim’s formula fatefully relied on a sharp division between sacred and profane that countless ethnographies would undermine.&lt;/p&gt;
    &lt;p&gt;Georg Simmel, writing around the turn of the 20th century, had already dismissed the ‘Open Sesame’ dream that a single word could unlock the mystery: ‘No light will ever be cast in the sibyllic twilight that, for us, surrounds the origin and nature of religion as long as we insist on approaching it as a single problem requiring only a single word for its solution.’ A few years later, William James complained about ‘verbal’ disputation, but then fell back on a recognisably Protestant formula, defining religion as ‘the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine.’ The linguist Jane Ellen Harrison, in her study Themis (1912), refused to define religion at all: a definition, she said, ‘desiccates its object’.&lt;/p&gt;
    &lt;p&gt;In ‘traditional religions’, there’s a continuity between what we’d distinguish as the natural and the supernatural realm&lt;/p&gt;
    &lt;p&gt;In the decades that followed, followers of Durkheim foregrounded function, treating religion as a mechanism that bound together societies, comforted individuals, marked transitions, legitimised power. But saying what religion does wouldn’t necessarily tell you what religion was, and, anyway, these functions weren’t peculiar to religion. Clifford Geertz’s elegant formula from the 1960s cast religion as a ‘system of symbols’, one that establishes ‘powerful, pervasive, and long-lasting moods and motivations’. Yet this formula likewise went too big, opening the door to all sorts of political ideologies.&lt;/p&gt;
    &lt;p&gt;Evolutionary and cognitive theorists since have offered definitions of their own. The evolutionary psychologist Robin Dunbar, for instance, suggested that religion may amount to ‘belief in some kind of transcendental world … inhabited by spirit beings or forces (that may or may not take an interest in and influence the physical world …).’ Inevitably, these belief-oriented accounts run into the same complaints that earlier doxastic definitions had: they seem awfully Protestant, privileging inner conviction over outward form. Even if you bought into the ‘belief’ part, though, you could baulk at the ‘transcendental’ part. In many ‘traditional religions’, there’s a deep continuity between what we’d distinguish as the natural and the supernatural realm. In the Akan region of Ghana where I spent much of my childhood, people would appease or reproach their ancestors in the same spirit that they might wheedle or berate someone at a municipal office. As the anthropologist Robin Horton observed, so-called traditional religions are less like the Western notion of religion than they are like science: they aim at explanation, prediction and control. True, where science posited impersonal forces, traditional thought posited personal ones. But the underlying move from observed regularities to theoretical constructs was similar; what Europeans wanted to call religion was a pragmatic explanatory framework, reasonable given the available evidence, and part of the same conceptual space as folk biology, folk psychology and everyday causal reasoning.&lt;/p&gt;
    &lt;p&gt;By the late 20th century, hopes for a definition had faded. Some theorists turned to Ludwig Wittgenstein’s notion of ‘family resemblance’. The thought is that traditions can belong to the same conceptual family because they overlap in crisscrossing ways – like cousins who share a nose here, a chin there, without any feature that they all have in common. It’s a permissive approach: you map the ripple of resemblances and give up on strict boundaries. Unfortunately, those resemblances always depend on what you pick as your prototype. If you start with Protestant Christianity, you’ll find resemblances that matter to Protestants; begin instead with Yoruba orisha devotion, and you’ll trace a very different set of likenesses.&lt;/p&gt;
    &lt;p&gt;The anthropologist Talal Asad influentially and illuminatingly traced both ‘religion’ and ‘the secular’ to the political and intellectual habits of Western modernity. Yet in his account, religion sometimes seems more an effect of those forces than a cause, more a product of power rather than a power in itself. And even if you think that the phenomena we cluster under the term have been sorted and named by Western modernity, you could wonder how we could be sure that they’re examples of the same thing.&lt;/p&gt;
    &lt;p&gt;Was the category beyond redemption? The scholar and minister Wilfred Cantwell Smith, whose book The Meaning and End of Religion (1962) had meticulously detailed the belated emergence of the ‘religion’ concept in Europe, long maintained that talk of ‘religion’ conflated too many things not to cause mischief, and urged that we give up such talk altogether; we should, instead, speak of faith and ‘cumulative tradition’. The anthropologist and historian Daniel Dubuisson, who anathematised ‘religion’ as a 19th-century Western imposition on non-Western worlds, urged that it be replaced with ‘cosmographic formation’. These evasive manoeuvres, in turn, have met with scepticism. As the social theorist Martin Riesebrodt drily observed, neologisms like Dubuisson’s could doubtless be shown to ‘have also been “constructed” through historically specific discourses’ and revealed as ‘instruments in the linguistic battle between classes or cultures.’ Besides, he pointed out, those who would eliminate the term ‘religion’ seldom manage long without it.&lt;/p&gt;
    &lt;p&gt;So how has ‘religion’, as a concept and category, endured in the absence of a stable definition? To answer that question, it may help to think about how referring expressions do their referring. Some terms keep their grip on the world even as our understanding of what they denote changes radically; others, once central to serious thought, fall away when their supposed referents are deemed illusions. What distinguishes the survivors from the casualties?&lt;/p&gt;
    &lt;p&gt;Think about our names for ‘natural kinds’. These are meant to pick out groupings that are found not just in our heads but in nature: bosons, barium, bonobos, beech trees. The things these names designate are thought to have causal powers, explanatory roles or underlying properties that justify treating them as more than convenient fictions. When we name a natural kind, what we’re naming is really out there in the world. Anyway, that’s the aim. How do we decide when we’ve got it right?&lt;/p&gt;
    &lt;p&gt;Start with chemistry, and the question of what counts as an acid. When the term was first used, it referred simply to substances that tasted sour, or acidus. Later they were marked out by what they did: etching metal, losing their bite in contact with alkalis. In 1777, the French chemist Antoine Lavoisier was convinced that acidity came from a common ingredient he called oxygen – oxygène, the ‘acid-producer’. He was wrong. Yet we’d say that when Lavoisier spoke of acids, he was referring to the same class of things we mean by the word.&lt;/p&gt;
    &lt;p&gt;A century on, chemists refined the concept. Svante Arrhenius defined acids by their propensity to dissociate in water and release hydrogen ions; in 1923, Johannes Nicolaus Brønsted and Thomas Martin Lowry each reconceived them as proton donors; Gilbert Lewis broadened the net again by calling acids electron-pair acceptors. Each shift expanded the boundaries, but none made the term obsolete. The word survived because its targets – the substances doing the dissolving and reacting – were real enough to anchor it even as its theoretical profile changed.&lt;/p&gt;
    &lt;p&gt;It’s the difference between a bad map of a real country and a map of Atlantis. Only the first can be fixed&lt;/p&gt;
    &lt;p&gt;Not every scientific term has been so lucky. In 1774, Joseph Priestley isolated a gas he took to be ‘dephlogisticated air’. Phlogiston was supposed to be a substance released during combustion, the invisible essence of burning. What he had actually found, we’d say, was what we know as oxygen, the name derived from that discarded theory of Lavoisier’s. Unlike oxygen, nothing in the world behaved as phlogiston was said to behave. Indeed, it was Lavoisier who brought the curtain down on phlogiston; closed-system experiments, which he conducted with his wife and lab assistant Marie-Anne Paulze Lavoisier, showed that combustion involved the gain of a component of air (namely, oxygen) rather than the loss of an invisible essence. The phlogiston concept evaporated because chemists came to see that it referred to nothing at all. Priestley’s ‘dephlogisticated air’, by contrast, referred successfully despite being misdescribed: his experiments had latched on to a real thing, even if his theory of it was wrong.&lt;/p&gt;
    &lt;p&gt;This difference between a term that refers despite error and one that refers to nothing is the difference between a bad map of a real country and a map of Atlantis. Only the first can be fixed. Philosophers have used such cases to argue that successful reference doesn’t depend on getting the description right. What matters is the causal connection between our words and the things they’re meant to denote. The strategy is straightforward enough: if you want to know what object a word refers to, find the thing that gives the best causal explanation of the central features of uses of that word. The features that drove Lavoisier’s acid-talk were produced by substances we still recognise as acids, which is why we don’t treat him as having been talking about some other thing, or about nothing at all. Causal theories of reference explain why our words can target the same class of object even when our conception of it shifts, and when the boundaries of the class shift, too. Pluto can stop being a planet without shaking the foundations of ‘planet’ talk. In such theories of reference, a word continues to refer, so long as it stands in the right causal relation to the entity that gives rise to its use. Misdescribed objects can survive conceptual upheavals; nonexistent ones can’t.&lt;/p&gt;
    &lt;p&gt;Even in the natural sciences, though, classes of things can fall between those stools. ‘Luminiferous ether’ is a case in point: an invisible medium once thought to carry light waves, it was indispensable to 19th-century physics yet eventually dissolved into what came to be called electromagnetic fields. Was ‘ether’ simply a phantasm? Some philosophers think we could well have retained the term, redefining it to mean the very fields that replaced it. Albert Einstein himself, who once helped kill the ether idea, later repurposed the term as the relativistic ether of spacetime, a field with its own geometry. Other theorists suspect that our ‘electromagnetic fields’ may eventually go the way of ether.&lt;/p&gt;
    &lt;p&gt;If there can be uncertainty about objects within the natural sciences, the wicket gets stickier when we move into the historical and social realm. Here the things we name – revolutions, nations, money, marriage, religion – are doubly human products, being products first of our collective activity, then of our collective description. These entities are what the philosopher Sally Haslanger would call ‘socially founded’ (a term she uses to sidestep the confusions associated with ‘socially constructed’). Many philosophers of language now call such entities social kinds.&lt;/p&gt;
    &lt;p&gt;To approach religion as a social kind isn’t to say that it’s as referentially sound as other familiar examples of this sort. Religion may, in fact, be in worse shape than most. It belongs to that subcategory of social kinds that living people apply to themselves. Some social kinds, like ‘recession’, can be defined externally, without the participation of those they describe. Economists can declare one to have happened in the 1870s, even if no one at the time felt it by that name. Others, like ‘wedding’, depend on shared recognition: you cannot hold one without a community that believes in weddings. ‘Religion’, like many social kinds, functions in both ways. Anthropologists can use the term to describe practices that their participants would never call religions, yet, once the label circulates, it acquires a reflexive power: believers come to organise their self-understanding around it. In this respect, religion is a product of classification that helps to shape the reality it describes.&lt;/p&gt;
    &lt;p&gt;The philosopher Ian Hacking captured this feedback loop with his idea of dynamic nominalism – the process by which classifications and people classified reshape one another. Categories create kinds. The heavy drinker is seen, and sees himself, as an alcoholic. The word doesn’t merely label the phenomenon – it helps to constitute it. Hacking later preferred to call this ‘dialectical realism’, on the grounds that what emerges from the loop (labels affecting those labelled, which then affects the label) is, by any reasonable measure, real enough. When you’ve been told that what you have is a religion, what’s affected isn’t just how you relate to it but what you think you are.&lt;/p&gt;
    &lt;p&gt;If ‘religion’ endures, it’s because the word still does work, practical and theoretical&lt;/p&gt;
    &lt;p&gt;Where does this leave someone trying to understand human life through such refractory terms? We might concede that ‘religion’ resists a unitary meaning and proceed case by case, choosing the angle that best reveals what we need to make visible. When speaking of the Abrahamic faiths, a practice-centred approach may capture the lived textures of ritual and observance. The propositions of the Nicene or the Athanasian Creed are, after all, obscure and arguably incoherent, but the act of avowing them carries weighty significance. When we’re turning to the ‘traditional’ thought of the Azande, the Nuer or the Asante, by contrast, a belief-centred, even neo-Tylorian, lens may illuminate elements that the modern Christian model hides from view. Each emphasis is bound to clarify something that the other leaves obscure.&lt;/p&gt;
    &lt;p&gt;The larger truth is that we’ve always navigated the world with models that merely approximate it, with varying degrees of adequacy. As Hans Vaihinger argued in The Philosophy of ‘As If’ (1911), we often reason through fictions we judge ‘true enough’, because making use of them helps us act, anticipate and understand. The map may not be the territory, but we’d be lost without it. And the sciences, social and natural alike, advance through such tolerable falsehoods. Their worth lies in the utility of their results.&lt;/p&gt;
    &lt;p&gt;If ‘religion’ endures, it’s because the word still does work, practical and theoretical. It orders law and policy, directs research, and shapes the inner lives of those who use it. Sociologists can enquire into its relation to charity or suicide; psychologists can study its connection to prejudice or wellbeing. In the United States, legislators and judges must have a sufficient grasp of the category that they can balance the Constitutional dos and don’ts of ‘accommodation’ and ‘non-establishment’. For the religionist, meanwhile, it continues to name a space where meaning is made, defended or denied. Whatever else it may be, ‘religion’ remains a category with too many stakeholders to be fired by fiat. When it comes to what the word means, no one gets to say, and everyone gets a say.&lt;/p&gt;
    &lt;p&gt;Of course, scholarship itself requires observance – with respect to its own standards of evidence, and on the discipline of paying attention. To be observant, in this sense, is to watch the world closely without pretending to stand outside it. And so we try to use our terms with care, aware of what they can hide from sight and of how much they still let us see. We begin where we are, with the tools our history leaves us, and we make do, even if we suspect that our models may someday be replaced. For now, religion endures as a shared act of attention: one of those serviceable maps by which we try to find our bearings, and to keep faith with the world.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://aeon.co/essays/the-word-religion-resists-definition-but-remains-necessary"/><published>2025-12-26T13:23:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46392115</id><title>Rob Pike Goes Nuclear over GenAI</title><updated>2025-12-26T15:11:20.374423+00:00</updated><link href="https://skyview.social/?url=https%3A%2F%2Fbsky.app%2Fprofile%2Frobpike.io%2Fpost%2F3matwg6w3ic2s&amp;viewtype=tree"/><published>2025-12-26T14:08:47+00:00</published></entry></feed>