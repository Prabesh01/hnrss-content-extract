<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-08T19:32:07.434410+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45511294</id><title>The paradoxical efficient market hypothesis (2024)</title><updated>2025-10-08T19:32:16.489266+00:00</updated><content>&lt;doc fingerprint="e2dc51eb9937efda"&gt;
  &lt;main&gt;
    &lt;p&gt;by John Allen Paulos&lt;/p&gt;
    &lt;p&gt;Election season has put an increased focus on the stock market, but little attention is ever paid to the Efficient Market Hypothesis (the EMH, for short). As I’ve written in A Mathematician Plays the Stock Market, it is a fundamental and important notion, but it is also a little weird. Its recent formulation derives from the work of Eugene Fama, economist Paul Samuelson, and others in the 1960s. The basic idea, however, dates back more than 100 years when Louis Bachelier, a student of the great French mathematician Henri Poincare, formulated an early version. Roughly, the hypothesis maintains that stock prices reflect all relevant information about the stock. As Fama put it, “In an efficient market, competition among the many intelligent participants leads to a situation where, at any point in time, actual prices of individual securities already reflect the effects of information based both on events that have already occurred and on events which, as of now, the market expects to take place in the future.”&lt;/p&gt;
    &lt;p&gt;The EMH depends crucially on what information is assumed to be reflected in the stock price. The weakest version maintains that all information about past market prices is already reflected in a stock price. A stronger version maintains that all publicly available information about a company is already reflected in its stock price. The strongest version states that information of all sorts, even inside information, is already reflected in the stock price.&lt;/p&gt;
    &lt;p&gt;It was probably this last rather implausible and all-encompassing version of the hypothesis that underlies the joke about the two efficient market theorists walking through town. They notice a hundred dollar bill on the sidewalk and simply ignore it. If it were real, they conclude, someone would have been picked it up already. Even more risible is the question: How many efficient market theorists does it take to change a light bulb? Answer: The answer is none. If the bulb needed changing, the wisdom of the market would have insured that it had already been changed.&lt;/p&gt;
    &lt;p&gt;So why do people think that the market efficiently, and more or less immediately, responds to changes in the conditions for a particular stock or even for the market as a whole? The answer is that investors are always seeking an edge to increase their gains or decrease their losses, and they try to do so in a multitude of ways. They’re on the lookout for new bits of information possibly relevant to a company’s stock price that may be enough to quickly raise or lower it. Because of this swarm of profit-hungry and loss-averse investors, the market rapidly responds to new information, and efficiently – there’s that word again – adjusts prices to reflect it. The changes take place so rapidly, or so the story goes, that even utilizing technical rules or fundamental analyses aren’t fast enough to be fully exploited, and investors who pursue them will see their excess profits shrink to zero.&lt;/p&gt;
    &lt;p&gt;I mentioned above that the EMH is weird. The reason is that it leads to a conclusion that has something of the flavor of the Liar Paradox: “This sentence is false.” How specifically? Well, if a sufficiently large majority of investors believe the hypothesis, they naturally would assume that new information about a stock would very quickly be reflected in its price. They would conclude that since relevant news almost immediately moves the price up or down, and since new developments can’t be predicted, neither can price increases or decreases. Thus those investors who subscribe to the EMH and believe the market is efficient would further believe that looking for trends and analyzing companies’ fundamentals is a waste of time. Believing this, the majority of investors won’t pay much attention to new developments, leaving only the relatively few remaining investors actively searching for an edge. The result is that the market will not respond quickly to new information and thus it will not be efficient. In this way a strong belief in the EMH ensures its falsity.&lt;/p&gt;
    &lt;p&gt;And in the opposite case, if investors believe that the market is not efficient, their belief will induce them to use whatever tools (technical analysis, fundamental analysis, and so on) are at their disposal. They will search diligently for an edge and for opportunities that they believe exist in an inefficient market, and by so doing these profit-seeking investors will ensure that the market becomes efficient.&lt;/p&gt;
    &lt;p&gt;Reiterating and in summary, if a sufficiently large proportion of investors doesn’t believe the EMH, their actions will ensure that it is efficient, and if most investors do believe that the market is efficient, looking for an edge would seem pointless to them and so their inaction will likely result in an inefficient market. Alternatively stated, the Efficient Market Hypothesis is true if and only if a sufficiently large majority of investors believes it to be false. Pleasantly counterintuitive and a bit weird as I said.&lt;/p&gt;
    &lt;p&gt;Of course, I’ve made some big assumptions that may not hold. One is that it’s not clear what “sufficiently large” means, and I’ve ignored the fact that it occasionally requires very few investors to move the market.&lt;/p&gt;
    &lt;p&gt;Another gap in the argument is that any suspected deviations from the EMH can always be attributed to mistakes in pricing models or some other issue. There is also a potent psychological reason that people disbelieve the EMH. Believing it makes it harder to maintain an investor’s self-image as a brilliant financial gunslinger whose keen insight will make him rich.&lt;/p&gt;
    &lt;p&gt;Nevertheless, I think the point remains: the truth or falsity of the EMH is not immutable but depends critically on the beliefs of investors. Furthermore, as the percentage of investors who believe in the hypothesis itself varies, the truth of the hypothesis varies inversely with it.&lt;/p&gt;
    &lt;p&gt;On the whole, however, I suspect most investors disbelieve in it, and so for this reason I think it holds, but only approximately and only most of the time.&lt;/p&gt;
    &lt;p&gt;Post script: That exploitable opportunities tend to gradually disappear is a general phenomenon that occurs in other domains. Steven Jay Gould in his book Full House developed an example from baseball. The absence of .400 hitters in the years since Ted Williams hit .406 in 1941, he argued, was not due to any decline in baseball ability but just the opposite: a gradual increase in the athleticism of all players and a consequent decrease in the disparity between the worst and best players. As players have improved over time, the distribution of batting averages and earned run averages shows less variability. There are fewer bad pitchers facing hitters and fewer bad hitters facing pitchers. The consequence is that .400 batting averages are now rare. The improved athleticism of both hitters and pitchers makes the “market” between them more efficient.&lt;/p&gt;
    &lt;p&gt;This would hold true for other sports, especially newly minted ones that arise suddenly and sometimes even become Olympic events. One might even try to invoke the EMH to explain the variation and stability of so-called prediction markets that purport to estimate candidates’ chances in so-called prediction markets. Investors buy, sell, and borrow shares in candidates as they do with stocks, and, arguably at least, the prediction market becomes more efficient as the election nears.&lt;/p&gt;
    &lt;p&gt;***&lt;/p&gt;
    &lt;p&gt;John Allen Paulos is an emeritus Professor of Mathematics at Temple University and the author of Innumeracy and A Mathematician Reads the Newspaper. These and his other books are available here.&lt;/p&gt;
    &lt;p&gt;Enjoying the content on 3QD? Help keep us going by donating now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://3quarksdaily.com/3quarksdaily/2024/09/the-paradoxical-efficient-market-hypothesis.html"/><published>2025-10-08T02:11:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45513485</id><title>Synology reverses policy banning third-party HDDs after sales allegedly plummet</title><updated>2025-10-08T19:32:16.051585+00:00</updated><content>&lt;doc fingerprint="7da303bb4dfe4cfc"&gt;
  &lt;main&gt;
    &lt;p&gt;Now, with the release of DSM 7.3, Synology has quietly walked the policy back. Third-party hard drives and 2.5-inch SATA SSDs can once again be used without triggering warning messages or reduced functionality. Drives from Seagate, WD, and others will work exactly as they did before—complete with full monitoring, alerts, and storage features.&lt;/p&gt;
    &lt;p&gt;For users, this means more choice and lower costs when building or upgrading a NAS. For Synology, it’s a much-needed course correction after months of backlash. While the company hasn’t publicly admitted fault, it’s clear that sales pressure and community outrage played a major role in reversing the decision.&lt;/p&gt;
    &lt;p&gt;Critics say the entire episode has damaged Synology’s reputation. The company seemed to believe that after QNAP’s well-known ransomware troubles, it could tighten control of the market without losing customers. Instead, the plan backfired—hard. Many loyal users have since turned to alternative brands or expressed hesitation about buying another Synology product.&lt;/p&gt;
    &lt;p&gt;Still, the return of open drive support is good news for anyone running a Synology NAS. It restores the flexibility that made the brand so popular in the first place. Whether this move is enough to win back frustrated users remains to be seen, but for now, DSM 7.3 brings a welcome dose of freedom back to the platform.&lt;/p&gt;
    &lt;p&gt;Source: Synology / nascompares&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.guru3d.com/story/synology-reverses-policy-banning-thirdparty-hdds-after-nas-sales-plummet/"/><published>2025-10-08T08:19:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45514164</id><title>Nobel Prize in Chemistry 2025</title><updated>2025-10-08T19:32:15.743356+00:00</updated><content>&lt;doc fingerprint="37d0923c8f250160"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Popular information&lt;/head&gt;
    &lt;p&gt;Popular science background: They have created new rooms for chemistry (pdf)&lt;lb/&gt;Populärvetenskaplig information: De har skapat nya rum för kemi (pdf)&lt;/p&gt;
    &lt;head rend="h2"&gt;They have created new rooms for chemistry&lt;/head&gt;
    &lt;p&gt;Susumu Kitagawa, Richard Robson and Omar M. Yaghi are awarded the Nobel Prize in Chemistry 2025 for the development of a new type of molecular architecture. The constructions they created – metal–organic frameworks – contain large cavities in which molecules can flow in and out. Researchers have used them to harvest water from desert air, extract pollutants from water, capture carbon dioxide and store hydrogen.&lt;/p&gt;
    &lt;p&gt;An attractive and very spacious studio apartment, specifically designed for your life as a water molecule – this is how an estate agent might describe one of all the metal–organic frameworks that laboratories around the world have developed in recent decades. Other constructions of this type are tailormade for capturing carbon dioxide, separating PFAS from water, delivering pharmaceuticals in the body or managing extremely toxic gases. Some can trap the ethylene gas from fruit – so they ripen more slowly – or encapsulate enzymes that break down traces of antibiotics in the environment.&lt;/p&gt;
    &lt;p&gt;Simply stated, metal–organic frameworks are exceptionally useful. Susumu Kitagawa, Richard Robson and Omar Yaghi are awarded the Nobel Prize in Chemistry 2025 because they created the first metal–organic frameworks (MOF) and demonstrated their potential. Thanks to the laureates’ work, chemists have been able to design tens of thousands of different MOFs, facilitating new chemical wonders.&lt;/p&gt;
    &lt;p&gt;As so often in the sciences, the story of the Nobel Prize in Chemistry 2025 begins with someone who thought outside the box. This time, inspiration came during preparations for a classic chemistry lesson, in which the students were to build molecules from rods and balls.&lt;/p&gt;
    &lt;head rend="h3"&gt;A simple wooden model of a molecule generates an idea&lt;/head&gt;
    &lt;p&gt;It was 1974. Richard Robson, who was teaching at the University of Melbourne, Australia, had been tasked with turning wooden balls into models of atoms, so students could create molecular structures. For this to work, he needed the university’s workshop to drill holes in them, so that wooden rods – the chemical bonds – could be attached to the atoms. However, the holes could not be randomly placed. Each atom – such as carbon, nitrogen or chlorine – forms chemical bonds in a specific way. Robson needed to mark out where the holes should be drilled.&lt;/p&gt;
    &lt;p&gt;When the workshop returned the wooden balls, he tested building some molecules. This was when he had a moment of insight: there was a vast amount of information baked into the holes’ positioning. The model molecules automatically had the correct form and structure, because of where the holes were situated. This insight led to his next idea: what would happen if he utilised the atoms’ inherent properties to link together different types of molecules, rather than individual atoms? Could he design new types of molecular constructions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Robson builds innovative chemical creations&lt;/head&gt;
    &lt;p&gt;Every year, when Robson brought out the wooden models to teach new students, the same idea occurred to him. However, more than a decade passed before he decided to test it out. He started with a very simple model, inspired by the structure of a diamond, in which each carbon atom bonds to four others, forming a tiny pyramid (figure 2). Robson’s aim was to build a similar structure, but his would be based on positively charged copper ions, Cu+. Like carbon, they prefer to have four other atoms around them.&lt;/p&gt;
    &lt;p&gt;He combined the copper ions with a molecule that has four arms: 4′,4″,4”’,4””-tetracyanotetraphenylmethane. There’s no need to remember its complicated name, but it is important that the molecule at the end of each arm had a chemical group, nitrile, that was attracted to the positively charged copper ions (figure 2).&lt;/p&gt;
    &lt;p&gt;At that time, most chemists would have assumed that combining copper ions with the four-armed molecules would result in a bird’s nest of ions and molecules. But things went Robson’s way. As he had predicted, the ions and molecules inherent attraction to each other mattered, so they organised themselves into a large molecular construction. Just like carbon atoms in a diamond, they formed a regular crystalline structure. However, unlike diamond – which is a compact material – this crystal contained a vast number of large cavities (figure 2).&lt;/p&gt;
    &lt;p&gt;In 1989, Robson presented his innovative chemical creation in the Journal of the American Chemical Society. In his article, he speculates about the future and suggests that this could offer a new way to construct materials. These, he writes, could be given never previously seen properties, potentially beneficial ones.&lt;/p&gt;
    &lt;p&gt;As it turned out, he had foreseen the future.&lt;/p&gt;
    &lt;head rend="h3"&gt;Robson brings about a pioneering spirit in chemistry&lt;/head&gt;
    &lt;p&gt;As soon as the year after his pioneering work was published, Robson presented several new types of molecular constructions with cavities that were filled with various substances. He used one of them to exchange ions. He submerged the ion-filled construction in a fluid that contained a different type of ion. The result was that the ions changed places, demonstrating that substances could flow in and out of the construction.&lt;/p&gt;
    &lt;p&gt;In his experiments, Robson showed that rational design can be utilised for building crystals with spacious interiors that are optimised for specific chemicals. He suggested that this new form of molecular construction – when correctly designed – could be used to catalyse chemical reactions, for example.&lt;/p&gt;
    &lt;p&gt;However, Robson’s constructions were quite rickety and tended to fall apart. Many chemists thought they were useless, but some could see that he was onto something and, for them, his ideas about the future awakened a pioneering spirit. Those who would come to lay a stable foundation for his visions were Susumu Kitagawa and Omar Yaghi. Between 1992 and 2003 they made – separately – a series of groundbreaking discoveries. We will begin in the 1990s, with Kitagawa, who was working at Kindai University, Japan.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kitagawa’s motto: even useless things can become useful&lt;/head&gt;
    &lt;p&gt;Throughout his research career, Susumu Kitagawa has followed an important principle: to try to see “the usefulness of useless.” As a young student, he read a book by the Nobel Prize laureate Hideki Yukawa. In it, Yukawa refers to an ancient Chinese philosopher, Zhuangzi, who says that we must question what we believe to be useful. Even if something does not bring immediate benefit, it may still turn out to be valuable.&lt;/p&gt;
    &lt;p&gt;Accordingly, when Kitagawa began to investigate the potential for creating porous molecular structures, he did not believe they had to have a specific purpose. When he presented his first molecular construction in 1992, it was indeed not particularly useful: a two-dimensional material with cavities in which acetone molecules could hide. However, it had resulted from a new way of thinking about the art of building with molecules. Like Robson, he used copper ions as cornerstones that were linked together by larger molecules.&lt;/p&gt;
    &lt;p&gt;Kitagawa wanted to continue experimenting with this new construction technology, but when he applied for grants, research funders did not think there was any particular point to his ambitions. The materials he created were unstable and had no purpose, so many of his proposals were rejected.&lt;/p&gt;
    &lt;p&gt;However, he did not give up and in 1997 he had his first major breakthrough. Using cobalt, nickel or zinc ions and a molecule called 4,4′-bipyridine, his research group created three-dimensional metal–organic frameworks that were intersected by open channels (figure 3). When they dried one of these materials – emptying it of water – it was stable and the spaces could even be filled with gases. The material could absorb and release methane, nitrogen and oxygen, without changing shape.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kitagawa sees the uniqueness of his creations&lt;/head&gt;
    &lt;p&gt;Kitagawa’s constructions were both stable and had a function, but research funders were still unable to see their charm. One reason was that chemists already had zeolites, stable and porous materials, which they could build from silicon dioxide. These can absorb gases, so why would anyone develop a similar material that did not work as well?&lt;/p&gt;
    &lt;p&gt;Susumu Kitagawa understood that if he were to receive any major grants, he had to define what made metal–organic frameworks unique. So, in 1998, he described his vision in the Bulletin of the Chemical Society of Japan. He presented several advantages with MOFs. For example, they can be created from many types of molecules, so there is enormous potential for integrating different functions. Also – and this is important – he realised that MOFs can form soft materials. Unlike zeolites, which are usually hard materials, MOFs contain flexible molecular building blocks (figure 4) that can create a pliant material.&lt;/p&gt;
    &lt;p&gt;After this, all he had to do was to put his ideas into practice. Kitagawa, along with other researchers, started developing flexible MOFs. While they work on this, we will move our focus to the US, where Omar Yaghi was also occupied with taking molecular architecture to new heights.&lt;/p&gt;
    &lt;head rend="h3"&gt;A secret library visit opens Yaghi’s eyes to chemistry&lt;/head&gt;
    &lt;p&gt;Studying chemistry was not an obvious choice for Omar Yaghi. He and his many siblings were raised in a single room in Amman, Jordan, with no electricity or running water. School was a refuge from his otherwise challenging life. One day, when he was ten years old, he sneaked into the school library, which was usually locked, and picked a book at random from the shelf. On opening it, his eyes were drawn to unintelligible but captivating pictures – his first encounter with molecular structures.&lt;/p&gt;
    &lt;p&gt;At the age of 15 – and on his father’s stern instruction – Yaghi moved to the US to study. He was attracted by chemistry and eventually by the art of designing new materials, but found the traditional way of building new molecules too unpredictable. Normally, chemists combine substances that are to react with each other in a container. Then, to start the chemical reaction, they heat the container. The desired molecule forms, but is also often accompanied by a range of contaminating side products.&lt;/p&gt;
    &lt;p&gt;In 1992, when Yaghi started his first position as research group leader, at Arizona State University, he wanted to find more controlled ways in which to create materials. His aim was to use rational design to connect different chemical constituents, like pieces of Lego, to make large crystals. This turned out to be challenging, but they finally succeeded when the research group started combining metal ions with organic molecules. In 1995, Yaghi published the structure of two different two-dimensional materials; these were like nets and were held together by copper or cobalt. The latter could host guest molecules in its spaces and, when these were fully occupied, it was so stable that it could be heated to 350°C without collapsing. Yaghi describes this material in an article in Nature where he coins the name “metal–organic framework;” this term is now used to describe extended and ordered molecular structures that potentially contain cavities, and are built from metals and organic (carbon-based) molecules.&lt;/p&gt;
    &lt;head rend="h3"&gt;Just a few grams of Yaghi’s framework can contain a football pitch&lt;/head&gt;
    &lt;p&gt;Yaghi established the next milestone in the development of metal–organic frameworks in 1999, when he presented MOF-5 to the world. This material has become a classic in the field. It is an exceptionally spacious and stable molecular construction. Even when empty, it can be heated to 300°C without collapsing.&lt;/p&gt;
    &lt;p&gt;However, what caused many researchers to raise their eyebrows was the enormous area hiding inside the material’s cubic spaces. A couple of grams of MOF-5 holds an area as big as a football pitch, which means it can absorb much more gas than a zeolite could (figure 5).&lt;/p&gt;
    &lt;p&gt;Speaking of the differences between zeolites and MOFs, it took just a few years for researchers to succeed in developing soft MOFs. One of those who was able to present a flexible material was Susumu Kitagawa himself. When his material was filled with water or methane, it changed shape, and when it was emptied, it returned to its original form. The material behaved somewhat like a lung that can breathe gas in and out, changeable but stable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Yaghi’s research group conjures drinking water from desert air&lt;/head&gt;
    &lt;p&gt;Omar Yaghi laid the final bricks in the foundation of metal–organic frameworks in 2002 and 2003. In two articles, in Science and Nature, he shows that it is possible to modify and change MOFs in a rational manner, giving them different properties. One thing he did was to produce 16 variants of MOF-5, with cavities that were both larger and smaller than those in the original material (figure 6). One variant could store huge volumes of methane gas, which Yaghi suggested could be used in RNG-fuelled vehicles.&lt;/p&gt;
    &lt;p&gt;Subsequently, metal–organic frameworks have taken the world by storm. Researchers have developed a molecular kit with a wide range of different pieces that can be used to create new MOFs. These have different shapes and characters, providing incredible potential for the rational – or AI-based – design of MOFs for different purposes. Figure 7 provides examples of how MOFs can be utilised. For instance, Yaghi’s research group has harvested water from the desert air of Arizona. During the night, their MOF material captured water vapour from the air. When dawn came and the sun heated the material, they were able to collect the water.&lt;/p&gt;
    &lt;head rend="h3"&gt;MOF materials that capture carbon dioxide and toxic gases&lt;/head&gt;
    &lt;p&gt;Researchers have created numerous different and functional MOFs. So far, in most cases, the materials have only been used on a small scale. To harness the benefits of MOF materials for humanity, many companies are now investing in their mass production and commercialisation. Some have succeeded. For example, the electronics industry can now use MOF materials to contain some of the toxic gases required to produce semiconductors. Another MOF can instead break down harmful gases, including some that can be used as chemical weapons. Numerous companies are also testing materials that can capture carbon dioxide from factories and power stations, to reduce greenhouse gas emissions.&lt;/p&gt;
    &lt;p&gt;Some researchers believe that metal–organic frameworks have such huge potential that they will be the material of the twenty-first century. Time will tell, but through the development of metal–organic frameworks, Susumu Kitagawa, Richard Robson and Omar Yaghi have provided chemists with new opportunities for solving some of the challenges we face. They have thus – as Alfred Nobel’s will states – brought the greatest benefit to humankind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Further reading&lt;/head&gt;
    &lt;p&gt;Additional information on this year’s prizes, including a scientific background in English, is available on the website of the Royal Swedish Academy of Sciences, www.kva.se, and at www.nobelprize.org, where you can watch video from the press conferences, the Nobel Prize lectures and more. Information on exhibitions and activities related to the Nobel Prizes and the prize in economic sciences is available at www.nobelprizemuseum.se.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Royal Swedish Academy of Sciences has decided to award the Nobel Prize in Chemistry 2025 to&lt;/head&gt;
    &lt;p&gt;SUSUMU KITAGAWA&lt;lb/&gt;Born 1951 in Kyoto, Japan. PhD 1979 from Kyoto University, Japan. Professor at Kyoto University, Japan.&lt;/p&gt;
    &lt;p&gt;RICHARD ROBSON&lt;lb/&gt;Born 1937 in Glusburn, UK. PhD 1962 from University of Oxford, UK. Professor at University of Melbourne, Australia.&lt;/p&gt;
    &lt;p&gt;OMAR M. YAGHI&lt;lb/&gt;Born 1965 in Amman, Jordan. PhD 1990 from University of Illinois Urbana-Champaign, USA. Professor at University of California, Berkeley, USA.&lt;/p&gt;
    &lt;p&gt;“for the development of metal–organic frameworks”&lt;/p&gt;
    &lt;p&gt;Science Editors: Peter Brzezinski, Heiner Linke, Olof Ramström and Xiaodong Zou, the Nobel Committee for Chemistry&lt;lb/&gt;Text: Ann Fernholm&lt;lb/&gt;Translation: Clare Barnes&lt;lb/&gt;Illustrations: Johan Jarnestad&lt;lb/&gt;Editor: Alicia Hegner&lt;lb/&gt;© The Royal Swedish Academy of Sciences&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;Don't miss the Nobel Prize announcements 6–13 October. All announcements are streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/chemistry/2025/popular-information/"/><published>2025-10-08T09:49:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45515146</id><title>A Clausewitzian lens on modern urban warfare</title><updated>2025-10-08T19:32:15.606985+00:00</updated><content>&lt;doc fingerprint="faa359510591dbb3"&gt;
  &lt;main&gt;
    &lt;p&gt;Among Carl von Clausewitz’s many poignant dictums, the most commonly cited is undoubtedly that “war is not merely an act of policy but a true political instrument, a continuation of political intercourse, carried on by other means.” While Clausewitz never fought in a city like Fallujah, Kyiv, or Gaza if the Prussian general and philosopher of war could visit the battlefields of the twenty-first century, he would recognize modern urban warfare’s core challenges—and would find that his theories about war’s objective and the considerations needed for victory remain strikingly relevant.&lt;/p&gt;
    &lt;p&gt;Clausewitz wrote that “war is more than a true chameleon that slightly adapts its characteristics to the given case.” Its essential elements—violence, chance and probability, and subordination to policy—form what he famously described as a wunderliche Dreifaltigkeit, or “remarkable trinity.” Rather than being in conflict, these elements interact dynamically and, in successful systems like that of Napoleonic France, can operate in harmony. Clausewitz and his fellow Prussian reformers admired how the French system aligned popular will, military force, and political direction. Nowhere is the need for such harmony more acute than in modern urban warfare, where civilians, combatants, and national objectives share the same congested terrain. This environment tests the limits of military doctrine, challenges the notion of strategic clarity, and often leaves combatants with ambiguous definitions of victory.&lt;/p&gt;
    &lt;p&gt;In my work on urban warfare, from my book Understanding Urban Warfare to the numerous case studies I have authored and the field research I have conducted, I’ve seen the truths Clausewitz described play out on concrete streets and in bombed-out buildings. Urban warfare has become the norm, not the exception, and Clausewitz’s insights are not relics of Napoleonic Europe—they are essential tools for understanding the future of conflict.&lt;/p&gt;
    &lt;p&gt;Historical Context: Urban Warfare in Clausewitz’s Era&lt;/p&gt;
    &lt;p&gt;While Clausewitz never commanded modern urban battles, his military career immersed him in conflicts where cities played central strategic and symbolic roles. As a young officer in the Prussian Army, he fought in the Rhine campaigns (1793–1794), including the siege of Mainz, where revolutionary France defended the city against a Prussian-Austrian coalition. This early exposure to urban siege warfare—marked by fortified positions, complex logistics, and the suffering of civilians—gave Clausewitz firsthand insight into the unique challenges of fighting in and around cities.&lt;/p&gt;
    &lt;p&gt;Clausewitz’s later experiences reinforced the political and psychological weight of urban centers. As aide-de-camp to Prussian Prince Augustus Ferdinand, he was present during Napoleon’s 1806 victory in the battles of Jena and Auerstedt, which led to the French occupation of Berlin. He later served with the Russian Army during France’s 1812 invasion of Russia, taking part in the Battle of Borodino—a prelude to the burning of Moscow that serves as a powerful example of a capital’s strategic and symbolic significance. In 1815, having reentered Prussian service, he participated in the Battles of Ligny and Wavre, fighting on terrain where towns, roads, and rivers constrained operations and shaped outcomes.&lt;/p&gt;
    &lt;p&gt;Clausewitz drew clear conclusions from these experiences. In Principles of War, he argued that “public opinion is won through great victories and the occupation of the enemy’s capital.” He understood cities not only as symbolic centers of national will but also as logistical and operational hubs, writing of the importance of targeting “principal cities, storehouses, and large fortresses.” Though he did not witness the dense, protracted urban warfare of the modern era, Clausewitz’s strategic emphasis on cities foreshadowed many of the dynamics seen in today’s urban battles.&lt;/p&gt;
    &lt;p&gt;The Urban Trinity, Fog, and Friction: Clausewitz’s Theories in Concrete and Steel&lt;/p&gt;
    &lt;p&gt;Clausewitz’s “remarkable trinity”—violence and hatred (the people), chance and probability (in military action), and reason and policy (the government)—finds its most visceral expression in urban warfare. Cities collapse these elements into a single, compact battlespace. Unlike operations in open terrain, urban warfare places civilians, combatants, and political objectives in constant, physical contact. The Clausewitzian trinity becomes spatially literal: civilians live among the fight, military action is hyperlocalized and constrained, and every movement carries political weight.&lt;/p&gt;
    &lt;p&gt;Clausewitz also famously wrote, “No one starts a war—or rather, no one in his senses ought to do so—without first being clear in his mind what he intends to achieve by that war and how he intends to conduct it.” He noted, therefore, that “the first, the supreme, the most far-reaching act of judgment that the statesman and commander have to make is to establish . . . the kind of war on which they are embarking.”&lt;/p&gt;
    &lt;p&gt;This act of judgment is especially difficult in cities, where the kind of war one is fighting can shift from block to block. Is the objective to destroy an entrenched enemy force? To hold key, vital, or symbolic terrain? To safeguard a civilian population? In urban warfare the answer is often all of the above.&lt;/p&gt;
    &lt;p&gt;Clausewitz’s dictum that war is a continuation of politics by other means is vividly realized in urban combat. Tactical decisions in cities reverberate at strategic levels. Urban warfare does not allow separation between military action and political consequence—they are fused.&lt;/p&gt;
    &lt;p&gt;But Clausewitz reminds us that strategy is not made of battlefield maneuvers alone—it is also made of will. He defined war as “an act of force to compel our enemy to do our will.”&lt;/p&gt;
    &lt;p&gt;Victory, then, is not always the annihilation of enemy forces—it is the collapse of the enemy’s will to resist. And in modern urban warfare, maintaining the will of one’s own people (or of your ally’s population)—to support the fight or to accept the moral and political costs—is just as critical. Clausewitz considered these moral forces among the most decisive in war, writing that they “constitute the spirit that permeates war as a whole.” In cities under siege or attack, public opinion, national resolve, and leadership cohesion become as important as any tactical maneuver.&lt;/p&gt;
    &lt;p&gt;Urban warfare places enormous pressure on the internal willpower of a combatant nation and that of its involved and invested allies. The proximity of civilians, the visibility of destruction, and the speed at which information spreads can erode public support even as military objectives are met. A video, a collapsed building, or a failed operation can shift the strategic balance—not through force, but by weakening the political object that gives war its purpose. Clausewitz warned, “The political object is the goal, war is the means of reaching it, and means can never be considered in isolation from their purpose.”&lt;/p&gt;
    &lt;p&gt;This relationship between political objectives, military action, and national will is especially fragile in urban combat. When will breaks—on either side—the war may be lost regardless of battlefield gains.&lt;/p&gt;
    &lt;p&gt;Yet even the clearest strategy must contend with the inherent chaos of war. “War is the realm of uncertainty,” Clausewitz cautioned. “Three quarters of the factors on which action in war is based are wrapped in a fog of greater or lesser uncertainty.” This fog of war—its confusion, unpredictability, and lack of reliable information—is magnified in dense urban environments where lines between civilian and combatant blur and information spreads instantly and globally. Commanders must make high-stakes decisions in environments where clarity is fleeting.&lt;/p&gt;
    &lt;p&gt;Compounding this is what Clausewitz called friction—the accumulation of countless small obstacles that derail even the best-laid plans. As he wrote:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Everything in war is very simple, but the simplest thing is difficult. The difficulties accumulate and end by producing a kind of friction that is inconceivable unless one has experienced war. . . . Friction is the only concept that more or less corresponds to the factors that distinguish real war from war on paper.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Friction in cities is not theoretical—it’s tactical and visceral. Streets canalize movement. Buildings obscure lines of sight. Civilians become obstacles or allies. The environment itself resists clean execution. Urban warfare reveals Clausewitz’s insights not just as philosophical musings, but as hard realities in concrete and steel.&lt;/p&gt;
    &lt;p&gt;Urban Warfare in Iraq: Lessons from Baghdad and ISIS&lt;/p&gt;
    &lt;p&gt;The US campaigns in Iraq and the broader fight against the Islamic State of Iraq and Syria (ISIS) offer a laboratory of Clausewitzian warfare in cities—where tactical success frequently collided with political complexity, and where the will of the population, not battlefield metrics, often defined the limits of victory.&lt;/p&gt;
    &lt;p&gt;The 2003 “Thunder Run” into Baghdad was more than a demonstration of military power—it was a calculated strike at the enemy’s political center of gravity. Recall Clausewitz’s observation that “public opinion is won through great victories and the occupation of the enemy’s capital.” Taking Baghdad had immediate strategic effects: It overthrew Saddam Hussein and dismantled the Ba’athist regime. But it did not yield strategic clarity. Once the political objective shifted from regime removal to establishing a new political order—that is, nation-building—the occupation of the capital no longer compelled the enemy to do our will. Instead, it ushered in a new phase of resistance—fought not by conventional armies, but by insurgents embedded in the population. The Clausewitzian trinity fractured, and the fog of war deepened.&lt;/p&gt;
    &lt;p&gt;The 2004 First and Second Battles of Fallujah posed a different Clausewitzian challenge: how to reestablish control over a city that had become both a symbol and a stronghold of insurgent defiance. The battles exposed the full weight of friction. Every block was contested. Civilian presence, urban density, and improvised defenses neutralized many of the coalition’s technological advantages. Clausewitz’s observation rang true: The simplest thing became difficult. But beyond the tactical grind, Fallujah also heightened the strategic burden of fighting in cities under global media scrutiny. Images of destruction and civilian displacement reverberated internationally, influencing Iraqi public opinion, straining allied cohesion, and testing the will of the Iraqi government itself. Tactical brilliance could not guarantee strategic clarity—and each gain came at political and moral cost.&lt;/p&gt;
    &lt;p&gt;Clausewitz’s theories are no less relevant in the fight against ISIS. The battles for Mosul, Raqqa, and Aleppo offer vivid examples of Clausewitzian dynamics playing out in dense urban terrain.&lt;/p&gt;
    &lt;p&gt;The Battle of Mosul (2016–2017), the largest urban combat operation since World War II, marked both the height and unraveling of ISIS’s territorial control. The city—where ISIS declared its caliphate—was a living example of Clausewitz’s trinity: ideological violence among the people, unpredictable chance in military operations, and the overarching influence of policy and statecraft. ISIS weaponized the city’s geography to negate coalition advantages. Each alley and rooftop became a node of Clausewitzian friction, where the fog of war was compounded by hidden explosives, civilian shields, and the media theater of terror.&lt;/p&gt;
    &lt;p&gt;The struggle to recapture Raqqa (2017) similarly underscored Clausewitz’s emphasis on the strategic value of cities—but also on the cost of capturing them. Coalition forces had to balance the immediate tactical need for firepower with the long-term strategic imperative of minimizing civilian casualties and preserving infrastructure. Raqqa’s fall signaled not just military defeat for ISIS, but the collapse of its political narrative of governance and legitimacy.&lt;/p&gt;
    &lt;p&gt;Aleppo (2012–2016) offered a final case study in how urban warfare reshapes Clausewitzian dynamics. The regime of Bashar al-Assad, with Russian support, waged a prolonged campaign of attrition to reclaim the city. Aleppo’s recapture was not just a battlefield event—it was a strategic and psychological victory that reshaped the regional balance. Clausewitz’s insight that war is always shaped by the interaction of violence, politics, and chance was on full display. In Aleppo, military power served political ends—but at enormous humanitarian and reputational cost.&lt;/p&gt;
    &lt;p&gt;The Battle of Kyiv: A Clausewitzian Struggle&lt;/p&gt;
    &lt;p&gt;The 2022 Battle of Kyiv illustrates many of Clausewitz’s core principles. Russian forces launched a lightning assault on the capital, aiming to swiftly decapitate Ukraine’s political leadership and seize its strategic center of gravity. But what they encountered was not just a military defense, but a national resistance. The people, military, and government acted as one cohesive trinity. And President Volodymyr Zelenskyy’s decision to remain in Kyiv was not just political theater—it was a deliberate act of strategic will.&lt;/p&gt;
    &lt;p&gt;The defenders of Kyiv skillfully leveraged the urban environment to neutralize Russia’s advantages and impose costs at every level of engagement. What followed was a textbook display of Clausewitzian friction: stalled armored columns, logistical failures, intelligence breakdowns, and a general underestimation of local resistance. Citizen volunteers, guided by their knowledge of terrain and empowered by social networks, became a force multiplier against a numerically and technologically superior invader. Even simple tactical objectives—securing key intersections or resupplying units—became unexpectedly complex under the weight of terrain, resistance, and human error. This was the very essence of what Clausewitz warned distinguishes real war from war on paper.&lt;/p&gt;
    &lt;p&gt;Russia’s inability to capture the capital—the symbolic heart of the Ukrainian state—had cascading effects. It allowed Ukraine to garner international support, secure military resupply, and build momentum on the strategic level. In urban warfare, just holding out can be a victory. The defense of a city like Kyiv can serve not only to blunt an assault but to buy time for political conditions to shift, for alliances to strengthen, and for strategic clarity to emerge. In such contexts, endurance becomes its own form of offense.&lt;/p&gt;
    &lt;p&gt;This was not just a tactical defeat for Russia—it was a strategic failure born of a fundamental mismatch between political ambition and military means. The objective—seizing Kyiv—was politically clear, but Russia failed to align its resources, capabilities, and assumptions with that goal. Clausewitz’s admonition echoed loudly as Russian columns stalled short of the capital: “The political object is the goal, war is the means of reaching it, and means can never be considered in isolation from their purpose.” The Battle of Kyiv proved that even with overwhelming force, war conducted without coherence between ends and means is destined to fail.&lt;/p&gt;
    &lt;p&gt;Gaza and the Israel Defense Forces: Tactical Success, Strategic Strain&lt;/p&gt;
    &lt;p&gt;If Kyiv is a case study of Clausewitzian alignment of war and policy, Israel’s ongoing operations in Gaza provide another example of the dangers when the alignment falters.&lt;/p&gt;
    &lt;p&gt;The Israel Defense Forces are one of the most experienced militaries in urban warfare in the world. Israeli military operations are precise, intelligence-driven, and supported by technological superiority. Yet even these capabilities cannot eliminate the strategic dilemma of fighting in cities densely packed with civilians, under intense global scrutiny, and against nonstate actors that use the urban fabric—cities’ terrain and their people—as both shield and weapon.&lt;/p&gt;
    &lt;p&gt;Clausewitz emphasized that war is not an isolated act but part of a “continuous interaction”—including, notably, interaction with political objectives. In Gaza, the Israel Defense Forces face a situation where the tactical destruction of enemy infrastructure—tunnels, command nodes, rocket sites—does not necessarily translate to strategic success of all the war’s political goals. Every collapsed apartment building and every civilian casualty reverberates globally. The moral forces Clausewitz emphasized—public opinion and will—are not abstract; they are measurable in diplomatic isolation or support, domestic cohesion, and battlefield morale.&lt;/p&gt;
    &lt;p&gt;This is not to say the Israeli military lacks clarity in its objectives, but rather that the urban environment imposes costs and constraints that can undermine strategic coherence. As I argued in Understanding Urban Warfare, a city can be the greatest ally or the worst foe, depending on how it is approached. Clausewitz would remind any military leader that the means employed must remain proportionate and consistent with the political purpose.&lt;/p&gt;
    &lt;p&gt;Clausewitz also cautioned against rigid formulas. “Every age,” he wrote, “[has] had its own kind of war, its own limiting conditions, and its own peculiar preconceptions”. Urban warfare in the twenty-first century demands adaptation, and nowhere is this more evident than in the lessons derived from Gaza.&lt;/p&gt;
    &lt;p&gt;For the Israel Defense Forces operating in Gaza, every strike, pause, or maneuver is interpreted through political, humanitarian, and informational lenses. This is enhanced by the magnified friction of fighting in dense urban terrain. Streets can canalize movement, buildings and tunnels can conceal threats, and civilians can either support or sabotage operations.&lt;/p&gt;
    &lt;p&gt;Clausewitz, with his emphasis on uncertainty, chance, and moral forces, would have found urban warfare like that seen in Gaza to be the ultimate test of the statesman’s clarity and the commander’s judgment. In today’s information environment, that friction is amplified—a single video or narrative about the use (or misuse) of force, whether true or fabricated, can influence entire populations and political bodies. This aligns with Clausewitz’s trinity of wills—the people, the military, and the government, all three of which must be in balance for coherent strategy. In cities, that balance is constantly tested in real time and often in front of a global audience.&lt;/p&gt;
    &lt;p&gt;The Strategic Center of Gravity is Urban&lt;/p&gt;
    &lt;p&gt;Clausewitz’s concept of the “center of gravity”—the source of power that holds everything in war together—was one of his most important strategic insights. He described it as the “hub of all power and movement, on which everything depends.” In his time, contending military with the center of gravity often meant the destruction of the enemy’s main army or the occupation of its capital. But in modern warfare—especially in urban environments—the center of gravity is rarely a fixed physical point. It is dynamic, psychological, and deeply political.&lt;/p&gt;
    &lt;p&gt;Today, the center of gravity often resides in urban areas, not just as terrain to be seized but as spaces where power is concentrated: political authority, public opinion, information control, and the will of the people. Cities like Kyiv, Gaza City, Mosul, or Aleppo are not merely battlefields—they are arenas where military action collides with political meaning. Clausewitz would recognize these dynamics, because for him, the essence of war was not tactical victory but the pursuit of a political object shaped by what he called moral forces.&lt;/p&gt;
    &lt;p&gt;Again, Clausewitz wrote, “The moral elements are among the most important in war. They constitute the spirit that permeates war as a whole.” He was referring to intangible but decisive factors—public support, national will, leadership cohesion, and belief in the cause. These forces are especially visible in cities, where every strike and every image can either strengthen or fracture the political foundations of the war effort. What we might now call legitimacy in modern strategy—credibility in the eyes of a population or the international community—can be understood as the sum of these moral forces. Clausewitz didn’t use the term, but he clearly grasped its meaning and importance.&lt;/p&gt;
    &lt;p&gt;In Kyiv, the city itself became the center of gravity—not only for its political and logistical importance, but for what it symbolized. Its defense became an act of national will. In Gaza, the battle shifts between tactical objectives and a struggle over public opinion, both local and global.&lt;/p&gt;
    &lt;p&gt;In today’s urban conflicts, the political object—the goal, in Clausewitz’s terms, which must not be separated from war as the means of reaching it—is constantly under pressure. This pressure comes not just from the enemy, but also from how one’s own population, allies, and adversaries perceive the use of force. A commander may win the battle for terrain and still lose the war if public opinion collapses or the political object becomes unsustainable.&lt;/p&gt;
    &lt;p&gt;This is why the center of gravity in modern warfare often runs through the city—not because of what is physically located there, but because of what is at stake symbolically, psychologically, and politically. In cities, Clausewitz’s theory finds its sharpest edge: Moral forces meet material realities, and the balance of war can shift not through firepower alone, but through the will of those watching, enduring, or resisting.&lt;/p&gt;
    &lt;p&gt;Clausewitz in the Urban Century&lt;/p&gt;
    &lt;p&gt;Cities have become the default terrain of modern war. From Kyiv to Gaza, the battles fought today are not anomalies—they are signals. Urban warfare is not an exception to Clausewitz’s theory; it is its most vivid and volatile expression.&lt;/p&gt;
    &lt;p&gt;Cities compress all the elements Clausewitz identified as fundamental to war: violence, chance, political purpose, friction, and uncertainty. They bring the political object, the will of the people, and military action into immediate proximity—requiring a level of harmony among these forces that is difficult to achieve but critical to sustaining strategic coherence. In this space, tactical actions instantly reverberate across strategic and political spheres. Every strike is a message, every misstep a liability.&lt;/p&gt;
    &lt;p&gt;Clausewitz would demand that today’s commanders and policymakers understand that war in cities is not just about maneuver and firepower—it is about narrative, perception, endurance, and will. Modern urban warfare is fought in full view of the world, under moral scrutiny, and amid civilian populations whose support or suffering can shape the outcome as much as any weapon system.&lt;/p&gt;
    &lt;p&gt;Victory in this environment requires more than technological superiority. It demands clarity of purpose, coherence between means and ends, disciplined execution, and moral restraint—the very fundamentals Clausewitz insisted upon. These are not optional in the urban century. They are decisive.&lt;/p&gt;
    &lt;p&gt;Clausewitz offers no checklist for success in cities, but rather something more valuable. What he offers is a way to think clearly, to adapt amid chaos, and to confront the true nature of war—a contest of wills, shaped by politics, distorted by chance, and fought in the dense, contested, and morally fraught terrain of the modern city.&lt;/p&gt;
    &lt;p&gt;John Spencer is chair of urban warfare studies at the Modern War Institute, codirector of MWI’s Urban Warfare Project, and host of the Urban Warfare Project Podcast. He served twenty-five years as an infantry soldier, which included two combat tours in Iraq. He is the author of the book Connected Soldiers: Life, Leadership, and Social Connections in Modern War and coauthor of Understanding Urban Warfare.&lt;/p&gt;
    &lt;p&gt;The views expressed are those of the author and do not reflect the official position of the United States Military Academy, Department of the Army, or Department of Defense.&lt;/p&gt;
    &lt;p&gt;Image credit: Staff Sgt. Jason Hull, US Army&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://mwi.westpoint.edu/a-clausewitzian-lens-on-modern-urban-warfare/"/><published>2025-10-08T11:56:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45515640</id><title>Legal Contracts Built for AI Agents</title><updated>2025-10-08T19:32:15.322742+00:00</updated><content>&lt;doc fingerprint="3d14491969fbea31"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Insights straight to your inbox&lt;/head&gt;
    &lt;p&gt;Join 10,000+ subscribers getting the latest insights on AI monetization.&lt;/p&gt;
    &lt;p&gt;We've partnered with GitLaw to launch something that should have existed from day one: a Master Services Agreement specifically designed for AI agents.&lt;/p&gt;
    &lt;p&gt;Not because we love legal documents (we don’t), but because the contracts most agent companies are using create problems they don't see until something breaks.&lt;/p&gt;
    &lt;p&gt;Most AI agent companies are still using SaaS contracts which makes no sense.&lt;/p&gt;
    &lt;p&gt;Your software isn't just sitting there helping someone fill out a form. It's booking meetings, writing code, making decisions. When something goes wrong, who's liable?&lt;/p&gt;
    &lt;p&gt;Standard contracts don't answer that question. They assume software waits for human instructions. Click button, thing happens, done.&lt;/p&gt;
    &lt;p&gt;But your agent operates differently. It decides which prospects to contact. It writes outreach messages. It follows up based on response patterns. It learns from interactions and adjusts behavior over time.&lt;/p&gt;
    &lt;p&gt;Those are autonomous actions. And when your agent does something unexpected, the gap between what your contract says and what your product does creates legal exposure you can't price for.&lt;/p&gt;
    &lt;p&gt;Your workflow agent doesn't suggest next steps. It executes them. Sends emails. Updates records. Moves data between systems. No human clicking approve at every stage.&lt;/p&gt;
    &lt;p&gt;Traditional software processes tasks one at a time when asked. Agents run 24/7, making hundreds of micro-decisions. Remember the Ford dealership chatbot that hallucinated a free truck offer? That's what happens when autonomous systems operate under contracts written for passive tools.&lt;/p&gt;
    &lt;p&gt;Static software behaves the same way every deployment. Agents learn from context, adjust to patterns, change behavior based on accumulated data. The system you shipped six months ago operates differently today.&lt;/p&gt;
    &lt;p&gt;Your SaaS contract wasn't built for any of this.&lt;/p&gt;
    &lt;p&gt;Working with Nick and the GitLaw team, we identified the contract gaps that create the most exposure for agent companies. The new MSA addresses three critical areas:&lt;/p&gt;
    &lt;p&gt;The contract establishes that your agent functions as a sophisticated tool, not an autonomous employee. When a customer's agent books 500 meetings with the wrong prospect list, the answer to "who approved that?" cannot be "the AI decided."&lt;/p&gt;
    &lt;p&gt;It has to be "the customer deployed the agent with these parameters and maintained oversight responsibility."&lt;/p&gt;
    &lt;p&gt;The MSA includes explicit language in Section 1.2 that protects you from liability for autonomous decisions while clarifying customer responsibility.&lt;/p&gt;
    &lt;p&gt;AI agents hallucinate. They produce confident outputs that turn out wrong. The MSA includes explicit disclaimers that agent outputs require human verification before material business decisions.&lt;/p&gt;
    &lt;p&gt;It also includes damage caps appropriate for unpredictable systems. Typically 12 months of fees with exclusions for indirect losses. Not being difficult. Acknowledging you can't predict every edge case in software that learns and adapts.&lt;/p&gt;
    &lt;p&gt;Section 7 covers liability limitations with AI-specific disclaimers about output accuracy in Section 4.1.&lt;/p&gt;
    &lt;p&gt;This kills more deals than any other contract issue. Your agent ingests customer data and generates outputs. You might want to use those interactions to improve your models.&lt;/p&gt;
    &lt;p&gt;Customers panic when they hear that. They imagine their proprietary data training models that help competitors.&lt;/p&gt;
    &lt;p&gt;The MSA establishes that customers own their data and any agent outputs. Then it provides separate, customizable language about using de-identified, aggregated data for training purposes. With clear opt-out options.&lt;/p&gt;
    &lt;p&gt;Most customers accept training use when it's explained clearly. Trying to slip it in through vague language destroys trust.&lt;/p&gt;
    &lt;p&gt;Section 2.1 covers ownership with customizable training permissions in the cover page variables.&lt;/p&gt;
    &lt;p&gt;At Paid, we solve billing and cost tracking for AI agents. But we kept hearing the same problem before companies even got to pricing.&lt;/p&gt;
    &lt;p&gt;Founders would tell us they couldn't figure out how to charge for agents. Then we'd look at their contracts. They were trying to price outcome-based work using terms written for seat-based software.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Most AI agent companies are still using SaaS contract language which makes no sense. Your software isn't just sitting there helping someone fill out a form. It's booking meetings, writing code, making decisions. When something goes wrong, who's liable? The standard contracts don't answer that. We kept hearing this from founders, so when GitLaw said they were building an agent-specific MSA, we jumped in. Builders need legal frameworks that match what their agents actually do".&lt;/p&gt;&lt;lb/&gt;Manny Medina, Paid CEO&lt;/quote&gt;
    &lt;p&gt;You can't bill for outcomes if your contract only covers usage. You can't price based on value delivered if your liability framework assumes predictable, passive behavior. You can't protect your margins when the legal foundation doesn't match what your product does.&lt;/p&gt;
    &lt;p&gt;The contract shapes everything that comes after. Get it wrong and your entire business model sits on shaky ground.&lt;/p&gt;
    &lt;p&gt;The MSA is open source and free to use. You can access it directly in the GitLaw Community or ask the GitLaw AI Agent to generate a customized version for your specific needs.&lt;/p&gt;
    &lt;p&gt;Because the law around AI agents is evolving rapidly, treat this as a starting point, not a substitute for legal advice. Work with a commercial lawyer to customize it for your situation.&lt;/p&gt;
    &lt;p&gt;The template uses CommonPaper's Software Licensing Agreement and AI Addendum as a foundation, adapted for the unique characteristics of AI agents.&lt;/p&gt;
    &lt;p&gt;Nick and the GitLaw team built this based on patterns from reviewing hundreds of agent contracts. We contributed our research from working with dozens of agent companies on monetization challenges.&lt;/p&gt;
    &lt;p&gt;Together, we're building the infrastructure the agent economy needs. Legal frameworks that match how agents actually work. Billing systems that align pricing with value delivery. Cost tracking that protects margins.&lt;/p&gt;
    &lt;p&gt;Because agents aren't just another SaaS feature. They're a fundamentally different product category that needs different infrastructure.&lt;/p&gt;
    &lt;p&gt;Legal frameworks always lag behind technology. Right now that lag creates real risk for anyone building agents.&lt;/p&gt;
    &lt;p&gt;You can ignore it and hope nothing breaks. Or you can use contracts built for what agents actually do, not what software did ten years ago.&lt;/p&gt;
    &lt;p&gt;Most founders choose hope. The ones who survive choose better infrastructure - and you'll soon find these MSAs baked into Paid's offering too.&lt;/p&gt;
    &lt;p&gt;→ Read the announcement on GitLaw&lt;/p&gt;
    &lt;p&gt;→ Listen to our conversation with Nick about building legal infrastructure for the agent economy.&lt;/p&gt;
    &lt;p&gt;Join 10,000+ subscribers getting the latest insights on AI monetization.&lt;/p&gt;
    &lt;p&gt;Price smarter. Protect margins. Grow revenue.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://paid.ai/blog/ai-agents/paid-gitlaw-introducing-legal-contracts-built-for-ai-agents"/><published>2025-10-08T12:55:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45515657</id><title>The email they shouldn't have read</title><updated>2025-10-08T19:32:14.437718+00:00</updated><content>&lt;doc fingerprint="764a911c87a67cf9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author's Note: Before we begin, an important clarification. What follows is a horror story based on real events from my career. However, to protect the privacy of the people and companies involved, I have deliberately mixed things up: technologies, contexts, and specific details have been modified or merged with other experiences. I therefore invite you to read this story not as a strict chronicle of a single event, but as an archetype of a widespread problem in the IT world: vendor lock-in and predatory business practices. Any attempt to identify the specific company or software described would lead to an incorrect conclusion.&lt;/p&gt;
    &lt;p&gt;When the phone rang, I was in a meeting - so I didnât answer. But I recognized the number and sent a quick message:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Iâm with a client right now. If itâs not urgent, please send me an email - otherwise Iâll call you ASAP".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The reply, via SMS, left me speechless:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Thatâs exactly the problem. I canât send you an email. Call me as soon as you can".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;From that moment on, my perception of a certain kind of world changed forever.&lt;/p&gt;
    &lt;p&gt;A few years earlier, a major public institution - letâs call it Agency A - was still running an ancient Exchange mail server. It hadnât received security updates for ages, the anti-spam was completely ineffective, and the new regulations were clear: embrace Open Source solutions whenever possible.&lt;/p&gt;
    &lt;p&gt;They had already received a proposal - expensive but, when compared to similar offers made to other organizations, apparently reasonable - for a managed service hosted by an external provider and based on an open source mail stack. The company offered a managed version with its own proprietary additions and enterprise support.&lt;/p&gt;
    &lt;p&gt;The catch? While such pricing had become almost "normal" in the market, it was still wildly inflated considering what was actually being delivered. Agency A already had solid infrastructure - reputable IP classes, redundant datacenters, everything running smoothly. We had built and maintained that environment for years, and it was still performing perfectly.&lt;/p&gt;
    &lt;p&gt;The request was simple: âEvaluate this solution, and if itâs suitable, weâll migrate.â. About 500 active mailboxes, roughly the same number of aliases. Manageable, but far from trivial.&lt;/p&gt;
    &lt;p&gt;So I started experimenting. I had heard of that stack before but never used it directly. I deployed it in some non-critical environments - ours, and a few test clients who agreed to try it at a discounted rate. Everything worked flawlessly for almost a year. I began to appreciate its design and flexibility. Confident, I told Agency A we could proceed with a pilot migration.&lt;/p&gt;
    &lt;p&gt;We built a new server, deployed the stack, and assigned a few secondary domains for early adopters. The feedback was great - so good that users started pushing for a full migration.&lt;lb/&gt; The IT team planned carefully: created accounts and aliases, migrated selected mailboxes, and kept the old Exchange server online (hidden, for legacy access).&lt;/p&gt;
    &lt;p&gt;The morning after the MX switch I was tense, waiting for trouble - but it never came. A couple of small questions, nothing serious. The internal team handled everything perfectly. It was a success.&lt;/p&gt;
    &lt;p&gt;Word spread quickly.&lt;/p&gt;
    &lt;p&gt;Agency B - smaller, but in some ways more influential - contacted me. They were customers of the same managed-service company that had pitched to Agency A. Once they saw the potential savings (at less than a tenth of the annual cost), the stability, and the freedom of keeping their data on their own servers, they became very interested. Their contract, however, was a five-year deal with automatic renewal - two years left. The legal office said the notice period was six months, so there was time.&lt;/p&gt;
    &lt;p&gt;They wanted to prepare silently. Their supplier was known for aggressive commercial behavior and often retaliated when customers tried to leave. So we built everything quietly - users, aliases, test setups - and froze the system, waiting for the official termination notice.&lt;/p&gt;
    &lt;p&gt;That day finally came. The notice was sent, about eight months before expiration. Migration would begin upon confirmation of receipt - or the following month at the latest.&lt;/p&gt;
    &lt;p&gt;Meanwhile, I learned that Agency C - another institution - was also planning to leave the same provider. They wanted to keep the same software stack for consistency, so I told them about our experience. They asked for a quote, which I prepared (without mentioning Agency B, of course). My margin would have been small, but the project made sense: it was about owning your data, not making money.&lt;/p&gt;
    &lt;p&gt;Everything seemed to move smoothly - until that SMS.&lt;/p&gt;
    &lt;p&gt;I called back immediately.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Thereâs been a problem with the termination" said the IT manager of Agency B.&lt;/p&gt;&lt;lb/&gt;"Somehow they found out what we were doing. There are hidden clauses we didnât know about, and now we canât leave - at least not for another five years. They know everything. Even your quote.".&lt;/quote&gt;
    &lt;p&gt;I was stunned. How could they possibly know?&lt;/p&gt;
    &lt;p&gt;Minutes later, my phone rang again - Agency C this time.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Forget the proposal", they said. "They called us. Threatened us, actually. They even mentioned your name and said they might take legal action against you for unfair competition - claiming theyâre the only âauthorizedâ installers of that software. Which is absurd, of course. Itâs open source. But our director doesnât want trouble.".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sometimes, when public money is involved, people prefer avoiding troubles over doing whatâs right.&lt;/p&gt;
    &lt;p&gt;Something didnât add up.&lt;lb/&gt; Then someone at Agency C noticed a clue: a former interim IT manager still had an email client connected via token authentication - with access to all messages. And that person had signed the original contract with the provider years before. Informally questioned, he admitted contacting them "to warn them" but claimed it was harmless. He never mentioned me - supposedly.&lt;/p&gt;
    &lt;p&gt;That still didnât explain how they knew about Agency Bâs internal steps. To test a theory, we set a trap: I asked a friend abroad to send Agency B a fake quote, from a company outside the EU.&lt;lb/&gt; The following Monday, the provider called Agency B and said, "We advise against working with non-EU companies - compliance can get tricky.".&lt;/p&gt;
    &lt;p&gt;That strongly suggested it: it looked as if they might have been reading the emails.&lt;/p&gt;
    &lt;p&gt;The IT manager exploded and confronted them. The response was chilling:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"Iâm not saying we do - but we could. Itâs in the contract. You should read the fine print, especially the unilateral amendment from two years ago.".&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That amendment, quietly accepted, included horrifying clauses:&lt;lb/&gt; - notice period extended from 6 to 12 months&lt;lb/&gt; - formerly free services could become paid at the providerâs discretion&lt;lb/&gt; - and, "for security reasons", they could disable any access other than the webmail - which they promptly did.&lt;/p&gt;
    &lt;p&gt;All of this happened before the GDPR era, when certain practices could still slip through.&lt;/p&gt;
    &lt;p&gt;I tried to contact the companyâs owner directly - no reply. Calls, emails, nothing. Their support lines were "not authorized to forward requests". I wanted to confront them about the ânot accreditedâ nonsense and the so-called unfair competition. But bullies never like a fair conversation.&lt;/p&gt;
    &lt;p&gt;I urged Agency B and C to investigate - not only legally, but ethically.&lt;lb/&gt; They were horrified, yes - but in the end, nothing changed.&lt;lb/&gt; Worse: the provider, invoking that same contract amendment, made previously free features paid ones, increasing their costs by another 30%.&lt;lb/&gt; Management wasnât outraged by the abuse - just by the extra expense, "hard to justify in the budget".&lt;/p&gt;
    &lt;p&gt;Years later, those directors were gone. The technical staff remained - older, wiser, and determined not to repeat the mistake. They eventually switched providers, though to something "safer", not necessarily better.&lt;/p&gt;
    &lt;p&gt;I couldnât solve that problem. The battle had to come from them, and I would have supported them all the way - not for profit, but for principle.&lt;lb/&gt; Because when a company that claims to âsupport open sourceâ behaves like that, we all lose.&lt;lb/&gt; We all get labeled the same way.&lt;/p&gt;
    &lt;p&gt;And thatâs the real horror of the story - not the software, but what people do with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://it-notes.dragas.net/2025/10/08/the-email-they-shouldnt-have-read/"/><published>2025-10-08T12:56:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516000</id><title>We found a bug in Go's ARM64 compiler</title><updated>2025-10-08T19:32:14.116595+00:00</updated><content>&lt;doc fingerprint="3b06c011ce263a54"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Every second, 84 million HTTP requests are hitting Cloudflare across our fleet of data centers in 330 cities. It means that even the rarest of bugs can show up frequently. In fact, it was our scale that recently led us to discover a bug in Go's arm64 compiler which causes a race condition in the generated code.&lt;/p&gt;
      &lt;p&gt;This post breaks down how we first encountered the bug, investigated it, and ultimately drove to the root cause.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Investigating a strange panic&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;We run a service in our network which configures the kernel to handle traffic for some products like Magic Transit and Magic WAN. Our monitoring watches this closely, and it started to observe very sporadic panics on arm64 machines.&lt;/p&gt;
      &lt;p&gt;We first saw one with a fatal error stating that traceback did not unwind completely. That error suggests that invariants were violated when traversing the stack, likely because of stack corruption. After a brief investigation we decided that it was probably rare stack memory corruption. This was a largely idle control plane service where unplanned restarts have negligible impact, and so we felt that following up was not a priority unless it kept happening.&lt;/p&gt;
      &lt;p&gt;And then it kept happening.Â &lt;/p&gt;
      &lt;p&gt;When we first saw this bug we saw that the fatal errors correlated with recovered panics. These were caused by some old code which used panic/recover as error handling.Â &lt;/p&gt;
      &lt;p&gt;At this point, our theory was:Â &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;All of the fatal panics happen within stack unwinding.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;We correlated an increased volume of recovered panics with these fatal panics.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Recovering a panic unwinds goroutine stacks to call deferred functions.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;A related Go issue (#73259) reported an arm64 stack unwinding crash.&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Letâs stop using panic/recover for error handling and wait out the upstream fix?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;So we did that and watched as fatal panics stopped occurring as the release rolled out. Fatal panics gone, our theoretical mitigation seemed to work, and this was no longer our problem. We subscribed to the upstream issue so we could update when it was resolved and put it out of our minds.&lt;/p&gt;
      &lt;p&gt;But, this turned out to be a much stranger bug than expected. Putting it out of our minds was premature as the same class of fatal panics came back at a much higher rate. A month later, we were seeing up to 30 daily fatal panics with no real discernible cause; while that might account for only one machine a day in less than 10% of our data centers, we found it concerning that we didnât understand the cause. The first thing we checked was the number of recovered panics, to match our previous pattern, but there were none. More interestingly, we could not correlate this increased rate of fatal panics with anything. A release? Infrastructure changes? The position of Mars? &lt;/p&gt;
      &lt;p&gt;At this point we felt like we needed to dive deeper to better understand the root cause. Pattern matching and hoping was clearly insufficient.Â &lt;/p&gt;
      &lt;p&gt;We saw two classes of this bug -- a crash while accessing invalid memory and an explicitly checked fatal error.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 153 gp=0x4000105340 m=324 mp=0x400639ea08 [GC worker (active)]:
/usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7ff97fffe870 sp=0x7ff97fffe860 pc=0x55558d4098fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1508 +0x68 fp=0x7ff97fffe860 sp=0x7ff97fffe810 pc=0x55558d3a9408
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1102
runtime.gcDrainMarkWorkerIdle(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7ff97fffe810 sp=0x7ff97fffe7a0 pc=0x55558d3ad514
runtime.gcDrain(0x400005bc50, 0x7)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7ff97fffe7a0 sp=0x7ff97fffe6f0 pc=0x55558d3ab248
runtime.markroot(0x400005bc50, 0x17e6, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7ff97fffe6f0 sp=0x7ff97fffe6a0 pc=0x55558d3ab578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7ff97fffe6a0 sp=0x7ff97fffe560 pc=0x55558d3acaa0
runtime.scanstack(0x4014494380, 0x400005bc50)
       /usr/local/go/src/runtime/traceback.go:447 +0x2ac fp=0x7ff97fffe560 sp=0x7ff97fffe4d0 pc=0x55558d3eeb7c
runtime.(*unwinder).next(0x7ff97fffe5b0?)
       /usr/local/go/src/runtime/traceback.go:566 +0x110 fp=0x7ff97fffe4d0 sp=0x7ff97fffe490 pc=0x55558d3eed40
runtime.(*unwinder).finishInternal(0x7ff97fffe4f8?)
       /usr/local/go/src/runtime/panic.go:1073 +0x38 fp=0x7ff97fffe490 sp=0x7ff97fffe460 pc=0x55558d403388
runtime.throw({0x55558de6aa27?, 0x7ff97fffe638?})
runtime stack:
fatal error: traceback did not unwind completely
       stack=[0x4015d6a000-0x4015d8a000
runtime: g8221077: frame.sp=0x4015d784c0 top=0x4015d89fd0&lt;/code&gt;
      &lt;/quote&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 187 gp=0x40003aea80 m=13 mp=0x40003ca008 [GC worker (active)]:
       /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7fff2afde870 sp=0x7fff2afde860 pc=0x55557e2d98fc
runtime.systemstack(0x0)
       /usr/local/go/src/runtime/mgc.go:1489 +0x94 fp=0x7fff2afde860 sp=0x7fff2afde810 pc=0x55557e279434
runtime.gcBgMarkWorker.func2()
       /usr/local/go/src/runtime/mgcmark.go:1112
runtime.gcDrainMarkWorkerDedicated(...)
       /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7fff2afde810 sp=0x7fff2afde7a0 pc=0x55557e27d514
runtime.gcDrain(0x4000059750, 0x3)
       /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7fff2afde7a0 sp=0x7fff2afde6f0 pc=0x55557e27b248
runtime.markroot(0x4000059750, 0xb8, 0x1)
       /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7fff2afde6f0 sp=0x7fff2afde6a0 pc=0x55557e27b578
runtime.markroot.func1()
       /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7fff2afde6a0 sp=0x7fff2afde560 pc=0x55557e27caa0
runtime.scanstack(0x40042cc000, 0x4000059750)
       /usr/local/go/src/runtime/traceback.go:458 +0x188 fp=0x7fff2afde560 sp=0x7fff2afde4d0 pc=0x55557e2bea58
runtime.(*unwinder).next(0x7fff2afde5b0)
goroutine 0 gp=0x40003af880 m=13 mp=0x40003ca008 [idle]:
PC=0x55557e2bea58 m=13 sigcode=1 addr=0x118
SIGSEGV: segmentation violation&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Now we could observe some clear patterns. Both errors occur when unwinding the stack in &lt;code&gt;(*unwinder).next&lt;/code&gt;. In one case we saw an intentional fatal error as the runtime identified that unwinding could not complete and the stack was in a bad state. In the other case there was a direct memory access error that happened while trying to unwind the stack. The segfault was discussed in the GitHub issue and a Go engineer identified it as dereference of a go scheduler struct, m, when unwinding.Â   &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;A review of Go scheduler structs&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;Go uses a lightweight userspace scheduler to manage concurrency. Many goroutines are scheduled on a smaller number of kernel threads â this is often referred to as M:N scheduling. Any individual goroutine can be scheduled on any kernel thread. The scheduler has three core types â &lt;code&gt;g&lt;/code&gt;Â  (the goroutine), &lt;code&gt;m&lt;/code&gt; (the kernel thread, or âmachineâ), and &lt;code&gt;p&lt;/code&gt; (the physical execution context, orÂ  âprocessorâ). For a goroutine to be scheduled a free &lt;code&gt;m&lt;/code&gt; must acquire a free &lt;code&gt;p&lt;/code&gt;, which will execute a g. Each &lt;code&gt;g&lt;/code&gt; contains a field for its m if it is currently running, otherwise it will be nil. This is all the context needed for this post but the go runtime docs explore this more comprehensively.Â &lt;/p&gt;
      &lt;p&gt;At this point we can start to make inferences on whatâs happening: the program crashes because we try to unwind a goroutine stack which is invalid. In the first backtrace, if a return address is null, we call &lt;code&gt;finishInternal&lt;/code&gt; and abort because the stack was not fully unwound. The segmentation fault case in the second backtrace is a bit more interesting: if instead the return address is non-zero but not a function then the unwinder code assumes that the goroutine is currently running. It'll then dereference m and fault by accessing &lt;code&gt;m.incgo&lt;/code&gt; (the offset of &lt;code&gt;incgo&lt;/code&gt; into &lt;code&gt;struct m&lt;/code&gt; is 0x118, the faulting memory access). &lt;/p&gt;
      &lt;p&gt;What, then, is causing this corruption? The traces were difficult to get anything useful from â our service has hundreds if not thousands of active goroutines. It was fairly clear from the beginning that the panic was remote from the actual bug. The crashes were all observed while unwinding the stack and if this were an issue any time the stack was unwound on arm64 we would be seeing it in many more services. We felt pretty confident that the stack unwinding was happening correctly but on an invalid stack.Â &lt;/p&gt;
      &lt;p&gt;Our investigation stalled for a while at this point â making guesses, testing guesses, trying to infer if the panic rate went up or down, or if nothing changed. There was a known issue on Goâs GitHub issue tracker which matched our symptoms almost exactly, but what they discussed was mostly what we already knew. At some point when looking through the linked stack traces we realized that their crash referenced an old version of a library that we were also using â Go Netlink.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 1267 gp=0x4002a8ea80 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /usr/local/go/src/runtime/preempt.go:308 +0x3c fp=0x4004cec4c0 sp=0x4004cec4a0 pc=0x46353c
runtime.asyncPreempt()
        /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x4004cec6b0 sp=0x4004cec4c0 pc=0x4a6a8c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0x14360300000000?)
        /go/pkg/mod/github.com/!data!dog/[email protected]/nl/nl_linux.go:803 +0x130 fp=0x4004cfc710 sp=0x4004cec6c0 pc=0xf95de0
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;We spot-checked a few stack traces and confirmed the presence of this Netlink library. Querying our logs showed that not only did we share a library â every single segmentation fault we observed had happened while preempting &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt;.&lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h3"&gt;Whatâs (async) preemption?&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;In the prehistoric era of Go (&amp;lt;=1.13) the runtime was cooperatively scheduled. A goroutine would run until it decided it was ready to yield to the scheduler â usually due to explicit calls to &lt;code&gt;runtime.Gosched()&lt;/code&gt; or injected yield points at function calls/IO operations. Since Go 1.14 the runtime instead does async preemption. The Go runtime has a thread &lt;code&gt;sysmon&lt;/code&gt; which tracks the runtime of goroutines and will preempt any that run for longer than 10ms (at time of writing). It does this by sending &lt;code&gt;SIGURG&lt;/code&gt; to the OS thread and in the signal handler will modify the program counter and stack to mimic a call to &lt;code&gt;asyncPreempt&lt;/code&gt;.&lt;/p&gt;
      &lt;p&gt;At this point we had two broad theories:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go Netlink bug â likely due to &lt;code&gt;unsafe.Pointer&lt;/code&gt; usage which invoked undefined behavior but is only actually broken on arm64&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;This is a Go runtime bug and we're only triggering it in &lt;code&gt;NetlinkSocket.Receive&lt;/code&gt; for some reason&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;After finding the same bug publicly reported upstream, we were feeling confident this was caused by a Go runtime bug. However, upon seeing that both issues implicated the same function, we felt more skeptical â notably the Go Netlink library uses unsafe.Pointer so memory corruption was a plausible explanation even if we didn't understand why.&lt;/p&gt;
      &lt;p&gt;After an unsuccessful code audit we had hit a wall. The crashes were rare and remote from the root cause. Maybe these crashes were caused by a runtime bug, maybe they were caused by a Go Netlink bug. It seemed clear that there was something wrong with this area of the code, but code auditing wasnât going anywhere. &lt;/p&gt;
      &lt;p&gt;At this point we had a fairly good understanding of what was crashing but very little understanding of why it was happening. It was clear that the root cause of the stack unwinder crashing was remote from the actual crash, and that it had to do with &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;, but why? We were able to capture a coredump of a production crash and view it in a debugger. The backtrace confirmed what we already knew â that there was a segmentation fault when unwinding a stack. The crux of the issue revealed itself when we looked at the goroutine which had been preempted while calling &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt;.Â     &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;(dlv) bt
0  0x0000555577579dec in runtime.asyncPreempt2
   at /usr/local/go/src/runtime/preempt.go:306
1  0x00005555775bc94c in runtime.asyncPreempt
   at /usr/local/go/src/runtime/preempt_arm64.s:47
2  0x0000555577cb2880 in github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive
   at
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779
3  0x0000555577cb19a8 in github.com/vishvananda/netlink/nl.(*NetlinkRequest).Execute
   at 
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:532
4  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
5  0x0000555577551124 in runtime.heapSetType
   at /usr/local/go/src/runtime/mbitmap.go:714
...
(dlv) disass -a 0x555577cb2878 0x555577cb2888
TEXT github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(SB) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go
        nl_linux.go:779 0x555577cb2878  fdfb7fa9        LDP -8(RSP), (R29, R30)
        nl_linux.go:779 0x555577cb287c  ff430191        ADD $80, RSP, RSP
        nl_linux.go:779 0x555577cb2880  ff434091        ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
        nl_linux.go:779 0x555577cb2884  c0035fd6        RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;The goroutine was paused between two opcodes in the function epilogue. Since the process of unwinding a stack relies on the stack frame being in a consistent state, it felt immediately suspicious that we preempted in the middle of adjusting the stack pointer. The goroutine had been paused at 0x555577cb2880, between&lt;code&gt; ADD $80, RSP, RSP and ADD $(16&amp;lt;&amp;lt;12), RSP, RSP&lt;/code&gt;.Â &lt;/p&gt;
      &lt;p&gt;We queried the service logs to confirm our theory. This wasnât isolated â the majority of stack traces showed that this same opcode was preempted. This was no longer a weird production crash we couldnât reproduce. A crash happened when the Go runtime preempted between these two stack pointer adjustments. We had our smoking gun.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;Building a minimal reproducer&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;At this point we felt pretty confident that this was actually just a runtime bug and it should be reproducible in an isolated environment without any dependencies. The theory at this point was:&lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Stack unwinding is triggered by garbage collection&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption between a split stack pointer adjustment causes a crash&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;What if we make a function which splits the adjustment and then call it in a loop?&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;quote&gt;
        &lt;code&gt;package main

import (
	"runtime"
)

//go:noinline
func big_stack(val int) int {
	var big_buffer = make([]byte, 1 &amp;lt;&amp;lt; 16)

	sum := 0
	// prevent the compiler from optimizing out the stack
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		big_buffer[i] = byte(val)
	}
	for i := 0; i &amp;lt; (1&amp;lt;&amp;lt;16); i++ {
		sum ^= int(big_buffer[i])
	}
	return sum
}

func main() {
	go func() {
		for {
			runtime.GC()
		}
	}()
	for {
		_ = big_stack(1000)
	}
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This function ends up with a stack frame slightly larger than can be represented in 16 bits, and so on arm64 the Go compiler will split the stack pointer adjustment into two opcodes. If the runtime preempts between these opcodes then the stack unwinder will read an invalid stack pointer and crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; epilogue for main.big_stack
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
; preemption is problematic between these opcodes
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;After running this for a few minutes the program panicked as expected!&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;SIGSEGV: segmentation violation
PC=0x60598 m=8 sigcode=1 addr=0x118

goroutine 0 gp=0x400019c540 m=8 mp=0x4000198708 [idle]:
runtime.(*unwinder).next(0x400030fd10)
        /home/thea/sdk/go1.23.4/src/runtime/traceback.go:458 +0x188 fp=0x400030fcc0 sp=0x400030fc30 pc=0x60598
runtime.scanstack(0x40000021c0, 0x400002f750)
        /home/thea/sdk/go1.23.4/src/runtime/mgcmark.go:887 +0x290 

[...]

goroutine 1 gp=0x40000021c0 m=nil [runnable (scan)]:
runtime.asyncPreempt2()
        /home/thea/sdk/go1.23.4/src/runtime/preempt.go:308 +0x3c fp=0x40003bfcf0 sp=0x40003bfcd0 pc=0x400cc
runtime.asyncPreempt()
        /home/thea/sdk/go1.23.4/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40003bfee0 sp=0x40003bfcf0 pc=0x75aec
main.big_stack(0x40003cff38?)
        /home/thea/dev/stack_corruption_reproducer/main.go:29 +0x94 fp=0x40003cff00 sp=0x40003bfef0 pc=0x77c04
Segmentation fault (core dumped)

real    1m29.165s
user    4m4.987s
sys     0m43.212s&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;A reproducible crash with standard library only? This felt like conclusive evidence that our problem was a runtime bug.&lt;/p&gt;
      &lt;p&gt;This was an extremely particular reproducer! Even now with a good understanding of the bug and its fix, some of the behavior is still puzzling. It's a one-instruction race condition, so itâs unsurprising that small changes could have large impact. For example, this reproducer was originally written and tested on Go 1.23.4, but did not crash when compiled with 1.23.9 (the version in production), even though we could objdump the binary and see the split ADD still present! We donât have a definite explanation for this behavior â even with the bug present there remain a few unknown variables which affect the likelihood of hitting the race condition.Â &lt;/p&gt;
      &lt;div&gt;
        &lt;head rend="h2"&gt;A single-instruction race condition window&lt;/head&gt;
      &lt;/div&gt;
      &lt;p&gt;arm64 is a fixed-length 4-byte instruction set architecture. This has a lot of implications on codegen but most relevant to this bug is the fact that immediate length is limited. &lt;code&gt;add&lt;/code&gt; gets a 12-bit immediate, &lt;code&gt;mov&lt;/code&gt; gets a 16-bit immediate, etc. How does the architecture handle this when the operands don't fit? It depends â &lt;code&gt;ADD&lt;/code&gt; in particular reserves a bit for "shift left by 12" so any 24 bit addition can be decomposed into two opcodes. Other instructions are decomposed similarly, or just require loading an immediate into a register first.Â &lt;/p&gt;
      &lt;p&gt;The very last step of the Go compiler before emitting machine code involves transforming the program into &lt;code&gt;obj.Prog&lt;/code&gt; structs. It's a very low level intermediate representation (IR) that mostly serves to be translated into machine code.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/fa2bb342d7b0024440d996c2d6d6778b7a5e0247/src/cmd/internal/obj/arm64/obj7.go#L856

// Pop stack frame.
// ADD $framesize, RSP, RSP
p = obj.Appendp(p, c.newprog)
p.As = AADD
p.From.Type = obj.TYPE_CONST
p.From.Offset = int64(c.autosize)
p.To.Type = obj.TYPE_REG
p.To.Reg = REGSP
p.Spadj = -c.autosize
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Notably, this IR is not aware of immediate length limitations. Instead, this happens in asm7.go when Go's internal intermediate representation is translated into arm64 machine code. The assembler will classify an immediate in conclass based on bit size and then use that when emitting instructions â extra if needed.&lt;/p&gt;
      &lt;p&gt;The Go assembler uses a combination of (&lt;code&gt;mov, add&lt;/code&gt;) opcodes for some adds that fit in 16-bit immediates, and prefers (&lt;code&gt;add, add + lsl 12&lt;/code&gt;) opcodes for 16-bit+ immediates.Â   &lt;/p&gt;
      &lt;p&gt;Compare a stack of (slightly larger than) &lt;code&gt;1&amp;lt;&amp;lt;15&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;15)
; 	return big_stack[0]
; }
MOVD $32776, R27
ADD R27, RSP, R29
MOVD $32784, R27
ADD R27, RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;With a stack of &lt;code&gt;1&amp;lt;&amp;lt;16&lt;/code&gt;:&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;; //go:noinline
; func big_stack() byte {
; 	var big_stack = make([]byte, 1&amp;lt;&amp;lt;16)
; 	return big_stack[0]
; } 
ADD $8, RSP, R29
ADD $(16&amp;lt;&amp;lt;12), R29, R29
ADD $16, RSP, RSP
ADD $(16&amp;lt;&amp;lt;12), RSP, RSP
RET
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;In the larger stack case, there is a point between &lt;code&gt;ADD x, RSP, RSP&lt;/code&gt; opcodes where the stack pointer is not pointing to the tip of a stack frame. We thought at first that this was a matter of memory corruption â that in handling async preemption the runtime would push a function call on the stack and corrupt the middle of the stack. However, this goroutine is already in the function epilogue â any data we corrupt is actively in the process of being thrown away. What's the issue then?  &lt;/p&gt;
      &lt;p&gt;The Go runtime often needs to unwind the stack, which means walking backwards through the chain of function calls. For example: garbage collection uses it to find live references on the stack, panicking relies on it to evaluate &lt;code&gt;defer&lt;/code&gt; functions, and generating stack traces needs to print the call stack. For this to work the stack pointer must be accurate during unwinding because of how golang dereferences sp to determine the calling function. If the stack pointer is partially modified, the unwinder will look for the calling function in the middle of the stack. The underlying data is meaningless when interpreted as directions to a parent stack frame and then the runtime will likely crash.Â &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;//https://github.com/golang/go/blob/66536242fce34787230c42078a7bbd373ef8dcb0/src/runtime/traceback.go#L373

if innermost &amp;amp;&amp;amp; frame.sp &amp;lt; frame.fp || frame.lr == 0 {
    lrPtr = frame.sp
    frame.lr = *(*uintptr)(unsafe.Pointer(lrPtr))
}
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;When async preemption happens it will push a function call onto the stack but the parent stack frame is no longer correct because sp was only partially adjusted when the preemption happened. The crash flow looks something like this: &lt;/p&gt;
      &lt;list rend="ol"&gt;
        &lt;item&gt;
          &lt;p&gt;Async preemption happens between the two opcodes that &lt;code&gt;add x, rsp&lt;/code&gt; expands to&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Garbage collection triggers stack unwinding (to check for heap object liveness)&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder starts traversing the stack of the problematic goroutine and correctly unwinds up to the problematic function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;The unwinder dereferences &lt;code&gt;sp&lt;/code&gt; to determine the parent function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Almost certainly the data behind &lt;code&gt;sp&lt;/code&gt; is not a function&lt;/p&gt;
        &lt;/item&gt;
        &lt;item&gt;
          &lt;p&gt;Crash&lt;/p&gt;
        &lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;We saw earlier a faulting stack trace which ended in &lt;code&gt;(*NetlinkSocket).Receive&lt;/code&gt; â in this case stack unwinding faulted while it was trying to determine the parent frame.Â    &lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;goroutine 90 gp=0x40042cc000 m=nil [preempted (scan)]:
runtime.asyncPreempt2()
/usr/local/go/src/runtime/preempt.go:306 +0x2c fp=0x40060a25d0 sp=0x40060a25b0 pc=0x55557e299dec
runtime.asyncPreempt()
/usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40060a27c0 sp=0x40060a25d0 pc=0x55557e2dc94c
github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0xff48ce6e060b2848?)
/vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 +0x130 fp=0x40060b2820 sp=0x40060a27d0 pc=0x55557e9d2880
&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;Once we discovered the root cause we reported it with a reproducer and the bug was quickly fixed. This bug is fixed in go1.23.12, go1.24.6, and go1.25.0. Previously, the go compiler emitted a single &lt;code&gt;add x, rsp&lt;/code&gt; instruction and relied on the assembler to split immediates into multiple opcodes as necessary. After this change, stacks larger than 1&amp;lt;&amp;lt;12 will build the offset in a temporary register and then add that to &lt;code&gt;rsp&lt;/code&gt; in a single, indivisible opcode. A goroutine can be preempted before or after the stack pointer modification, but never during. This means that the stack pointer is always valid and there is no race condition.&lt;/p&gt;
      &lt;quote&gt;
        &lt;code&gt;LDP -8(RSP), (R29, R30)
MOVD $32, R27
MOVK $(1&amp;lt;&amp;lt;16), R27
ADD R27, RSP, RSP
RET&lt;/code&gt;
      &lt;/quote&gt;
      &lt;p&gt;This was a very fun problem to debug. We donât often see bugs where you can accurately blame the compiler. Debugging it took weeks and we had to learn about areas of the Go runtime that people donât usually need to think about. Itâs a nice example of a rare race condition, the sort of bug that can only really be quantified at a large scale.&lt;/p&gt;
      &lt;p&gt;Weâre always looking for people who enjoy this kind of detective work. Our engineering teams are hiring. &lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/"/><published>2025-10-08T13:33:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516426</id><title>Now open for building: Introducing Gemini CLI extensions</title><updated>2025-10-08T19:32:13.857898+00:00</updated><content>&lt;doc fingerprint="994b9cc09a2ba6b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Now open for building: Introducing Gemini CLI extensions&lt;/head&gt;
    &lt;p&gt;The best tools are the ones that adapt to you, not the other way around. For developers whose work is becoming more complex every day, the need for personalized, intelligent assistance has never been greater.&lt;/p&gt;
    &lt;p&gt;That’s why we’re announcing Gemini CLI extensions, a new framework that allows you to customize Gemini CLI and connect it to the tools you use most, all from the command line. Instead of context-switching between your terminal and other tools, you can now bring those tools directly into your workflow.&lt;/p&gt;
    &lt;p&gt;In just three months since our launch, more than one million developers are building with Gemini CLI. And they can now access a new ecosystem of extensions from Google, plus industry leaders like Dynatrace, Elastic, Figma, Harness, Postman, Shopify, Snyk and Stripe, and the broader open-source community.&lt;/p&gt;
    &lt;head rend="h2"&gt;Personalize your command line with Gemini CLI extensions&lt;/head&gt;
    &lt;p&gt;Gemini CLI is an open-source, AI-powered agent for your terminal, and extensions are its power-ups — pre-packaged, easily installable integrations that connect it to external tools including everything from databases and design platforms to payment services.&lt;/p&gt;
    &lt;p&gt;Each extension contains a built-in “playbook” that instantly teaches the AI how to use the new tools effectively. This means you get meaningful results from the very first command, no complex setup required, allowing you to tailor your experience with the tools most valuable to you.&lt;/p&gt;
    &lt;p&gt;It’s easy to install an extension — simply type: “gemini extensions install &amp;lt;add your GitHub URL or local path&amp;gt;” from your command line.&lt;/p&gt;
    &lt;p&gt;Easily install extensions from Gemini CLI's open ecosystem&lt;/p&gt;
    &lt;head rend="h2"&gt;Access an open, growing ecosystem of partners and builders&lt;/head&gt;
    &lt;p&gt;Extensions put Gemini CLI at the center of an open ecosystem in which anyone can build integrations. That’s why in addition to our own set of Google-created extensions, we’re launching with a strong group of partners and open-source contributors.&lt;/p&gt;
    &lt;p&gt;To make extensions easy to find and use, we’re also launching a new Gemini CLI Extensions page. Here, you can discover a growing catalog of community, partner and Google-built extensions, ranked by popularity by GitHub stars.&lt;/p&gt;
    &lt;p&gt;You can get started with extensions from a wide range of launch partners and more coming soon. These include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dynatrace: Get real-time insights into application performance, availability and root-cause analysis directly from your CLI to accelerate debugging.&lt;/item&gt;
      &lt;item&gt;Elastic: Search, retrieve and analyze Elasticsearch data in developer and agentic workflows. Connects directly to an Elastic MCP server hosted in Elastic Cloud Serverless.&lt;/item&gt;
      &lt;item&gt;Figma: Generate code from frames, extract design context, retrieve resources and ensure design system consistency with your codebase.&lt;/item&gt;
      &lt;item&gt;Harness: Bring AI-powered intelligence to CI/CD by analyzing pipeline execution data, surfacing cost insights, detecting failure patterns and automatically remediating issues to accelerate software delivery.&lt;/item&gt;
      &lt;item&gt;Postman: Have AI agents access Postman workspaces, manage collections and environments, evaluate APIs and automate workflows through natural language interactions.&lt;/item&gt;
      &lt;item&gt;Shopify: Connect to Shopify's developer ecosystem with tools to search docs, explore API schemas, and build serverless Shopify functions.&lt;/item&gt;
      &lt;item&gt;Snyk: Seamlessly integrate Snyk's comprehensive security capabilities into your development process to ensure that code is secure at inception.&lt;/item&gt;
      &lt;item&gt;Stripe: Define a set of tools that AI agents can use to interact with the Stripe API and search the knowledge base.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;More than a connection: See how extensions add intelligence&lt;/head&gt;
    &lt;p&gt;Developers get more from Gemini CLI by integrating Model Context Protocol (MCP) tools, and extensions build on this by enabling even smarter interactions. While MCP provides the raw connection to a tool, a Gemini CLI extension takes the basic ability to use that tool and wraps it in a layer of intelligence and personalization. This makes the experience seamless for developers.&lt;/p&gt;
    &lt;p&gt;Gemini CLI extensions are easy to install and have a simple “playbook” — a set of tools it knows how to use, like a local script or a third-party API. When you run a command, Gemini CLI consults this playbook and uses the context from your environment (like your local files and git status) to execute the right tool for the job, exactly how you intended.&lt;/p&gt;
    &lt;p&gt;If you want to look under the hood, Gemini CLI extensions package instructions, MCP servers and custom commands into a familiar and user-friendly format. Extensions can bundle any combination of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One or more MCP servers: To connect with external tools and services.&lt;/item&gt;
      &lt;item&gt;Context files: Like GEMINI.md or bring your own context file type(s), to provide specific instructions and guidelines to the model.&lt;/item&gt;
      &lt;item&gt;Excluded tools: Useful for disabling built-in tools or offering alternative implementations.&lt;/item&gt;
      &lt;item&gt;Custom commands: To encapsulate complex prompts into simple slash commands.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Use Gemini CLI to access all kinds of extensions, including one for image generation with Nano Banana&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover Google-created extensions&lt;/head&gt;
    &lt;p&gt;Googlers have also been building a suite of extensions for Gemini CLI. Give them a try; they just might help you solve some common developer pain points, deepen integration with other Google offerings or just have fun:&lt;/p&gt;
    &lt;p&gt;For cloud-native deployments:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go from local code to a live public URL in a single step, with the Cloud Run extension.&lt;/item&gt;
      &lt;item&gt;Manage your Google Kubernetes Engine (GKE) clusters, from checking node health to deploying applications with our GKE extension.&lt;/item&gt;
      &lt;item&gt;Give Gemini CLI the ability to easily interact with your Google Cloud environment by using the gcloud extension.&lt;/item&gt;
      &lt;item&gt;Understand, manage and troubleshoot your Google Cloud environment with the Google Cloud Observability extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For app builders:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Perform code reviews on your codebase with the Code Review extension.&lt;/item&gt;
      &lt;item&gt;Perform AI-powered vulnerability detection on your code changes with the Security extension.&lt;/item&gt;
      &lt;item&gt;Retrieve place info from Google and embed Google Maps imagery into applications with the Google Maps Platform extension.&lt;/item&gt;
      &lt;item&gt;Create, build, refactor, debug and maintain Flutter applications with the Flutter extension.&lt;/item&gt;
      &lt;item&gt;Control and inspect a live Chrome browser for reliable automation, in-depth debugging and performance analysis with the Chrome DevTools extension.&lt;/item&gt;
      &lt;item&gt;Set up and manage your Firebase backend with the Firebase extension.&lt;/item&gt;
      &lt;item&gt;Enhance the user experience for building GenAI-powered apps with the Genkit extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For generative AI and data interaction:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;For a bit of fun, generate and edit images with the Nano Banana extension 🍌.&lt;/item&gt;
      &lt;item&gt;Explore and visualize your business data with the Looker extension.&lt;/item&gt;
      &lt;item&gt;Build applications and analyze trends with services like Cloud SQL, AlloyDB BigQuery and more with our Data Cloud extensions.&lt;/item&gt;
      &lt;item&gt;Connect to enterprise data easily and securely using the MCP Toolbox for Databases extension.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Build the CLI of your dreams&lt;/head&gt;
    &lt;p&gt;Gemini CLI extensions put you in control. You can combine extensions, chain commands and build a personalized toolchain that perfectly fits the way you work.&lt;/p&gt;
    &lt;p&gt;Whether you want to streamline a personal workflow or integrate a company's internal tools, you now have the power to create the command-line experience you've always wanted.&lt;/p&gt;
    &lt;p&gt;Ready to get started? Visit the new Gemini CLI Extensions page to explore community tools, and check out our templates and a step-by-step guide to help you build your first extension and share it with the community.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/developers/gemini-cli-extensions/"/><published>2025-10-08T14:13:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516584</id><title>Show HN: Recall: Give Claude memory with Redis-backed persistent context</title><updated>2025-10-08T19:32:13.754983+00:00</updated><content/><link href="https://www.npmjs.com/package/@joseairosa/recall"/><published>2025-10-08T14:28:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516690</id><title>Vectrex Mini</title><updated>2025-10-08T19:32:13.140951+00:00</updated><content>&lt;doc fingerprint="27d74f9593ed6a7c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Vectrex Mini Details&lt;/head&gt;
    &lt;p&gt;Experience the spirit of the original Vectrex in a modern, compact format. &lt;lb/&gt;After three years of development and refinement, the Vectrex Mini is ready for production.&lt;/p&gt;
    &lt;p&gt;The Kickstarter goes live on November 3rd 2025.&lt;/p&gt;
    &lt;head rend="h2"&gt;Console&lt;/head&gt;
    &lt;p&gt;The Vectrex Mini captures the full spirit of the original Vectrex in a case half the size. Its plastic shell is made using injection molding, just like the console of the time, and each unit will come in packaging inspired by the original box.&lt;/p&gt;
    &lt;p&gt;On the technical side, the console features a built-in 5-inch AMOLED display with a resolution of 800×600, delivering sharp and bright vector graphics. Power is supplied via USB-C, so it can run on a wall outlet as well as an external battery. The Vectrex Mini is powered by an ESP32, a modern and reliable microprocessor, powerful enough to run the entire Vectrex game library with performance beyond many arcade machines of the era.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;p&gt;The console will include 12 built-in classic games, mostly from the General Consumer Electronics catalog (the final selection is still being completed, with the official list to be announced later). Each game will come with its own physical overlay to recreate the visual experience of the 1980s.&lt;/p&gt;
    &lt;p&gt;Sticker sheets will also be included, featuring different official logos (current, European, American, and Japanese), so players can customize their machine.&lt;/p&gt;
    &lt;p&gt;A Vector Clock mode will turn the console into a clock displaying the time, date, and weather thanks to Wi-Fi connectivity.&lt;/p&gt;
    &lt;p&gt;An alarm can also be set, allowing the Vectrex Mini to double as a stylish bedside clock or desk companion.&lt;/p&gt;
    &lt;p&gt;The Vectrex Mini offers several connection options. A micro-SD slot will allow the addition of games or homebrews (a card will likely not be included).&lt;/p&gt;
    &lt;p&gt;A Bluetooth controller with four action buttons and a self-centering analog joystick will be provided and can be stored in the console as with the original. A second controller can also be connected for multiplayer.&lt;/p&gt;
    &lt;p&gt;Finally, a video output will be integrated at the back of the unit (the final choice between HDMI or USB-C will be confirmed during production).&lt;/p&gt;
    &lt;head rend="h2"&gt;Special Edition&lt;/head&gt;
    &lt;p&gt;A limited run of 250 units will be produced. The White Edition has all the features of the standard version but stands out with a fully white finish, a unique serial number, and a certificate of authenticity. Aimed at collectors, it will come in its own box.&lt;/p&gt;
    &lt;head rend="h2"&gt;Merchandise&lt;/head&gt;
    &lt;p&gt;Several items will be available to accompany the release of the Vectrex Mini:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A second controller can be purchased separately and will include a dongle to connect it to the original console.&lt;/item&gt;
      &lt;item&gt;Four T-shirt designs will be released, featuring artwork of the console itself, a Vectrex-style Superman, Minestrom, and Spike.&lt;/item&gt;
      &lt;item&gt;A book written by Douglas Alves will also be part of the collection. A well-known French specialist in video game history, longtime journalist, MO5 association member, and teacher in the field, he retraces the story of the Vectrex in this work.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Kickstarter Campaign&lt;/head&gt;
    &lt;p&gt;After three years dedicated to prototyping and preparing for production, the project is now ready. We have set a clear timeline with defined milestones for testing, final adjustments, and assembly. Manufacturing will be carried out in partnership with teams based in Taiwan.&lt;/p&gt;
    &lt;p&gt;The Kickstarter campaign aims to finance this production phase. We waited until we had a fully functional prototype, strong partners, and a realistic schedule before launching. See you on November 3 on Kickstarter to discover all the details and join the adventure.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vectrex.com/vectrex-mini-details/"/><published>2025-10-08T14:38:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45516968</id><title>After 2 decades of tinkering, MAME cracks the Hyper Neo Geo 64</title><updated>2025-10-08T19:32:12.787270+00:00</updated><content>&lt;doc fingerprint="372e9953cb024b11"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;After 2 decades of tinkering, MAME finally cracks the Hyper Neo Geo 64&lt;/head&gt;
    &lt;p&gt;How MAME devs finally got sound working for the 3D arcade system. Plus: PC Engine LaserActive support gets fast-tracked.&lt;/p&gt;
    &lt;p&gt;Let me test out a theory here: If you're into emulation, you're into older video games, ergo you're into old stuff of all kinds. That means you, savvy, good-taste-having reader, will love this spread of photos I took in Tokyo last week at the National Film Archive of Japan, which has a small but lovely set of exhibits from the history of Japanese film. Since you like playing Super Nintendo games this is absolutely your shit, right? Right??&lt;/p&gt;
    &lt;p&gt;Okay, I'll throw in a pic of some games to sweeten the deal.&lt;/p&gt;
    &lt;p&gt;This issue is coming a week late as I was off to Japan last week for my first-ever visit to the Tokyo Game Show, and too busy working (and working at eating sushi) to squeeze in a newsletter. And it's coming late in the day Sunday — apologies! But patience pays off!!&lt;/p&gt;
    &lt;p&gt;This issue's main story has been cookin' for a minute: last month the news landed that MAME had finally properly cracked Hyper Neo Geo 64 support, but the celebration was a little bit premature. The arcade system was playable in MAME, yes, but sound was in really shoddy shape — it wasn't yet a particularly good experience.&lt;/p&gt;
    &lt;p&gt;Over the last month or so that's been changing, and changing fast, with frequent improvements checked in by a pair of regular MAME contributors. So now is the time to talk about it, and soon (with the very next MAME release!) it will be time to actually play it. Considering there are only seven Hyper Neo Geo 64 games, well, that's a week's worth of evenings sorted.&lt;/p&gt;
    &lt;p&gt;As with every trip to Tokyo I took a few hours to stop by Akihabara this time, but its pull has certainly lessened over the years as retro prices have skyrocketed from where they were a decade ago and the selection has gotten thinner and thinner. Still, browsing the stores is a fun time and there are great finds to be found as long as you're not looking for anything too in-demand. I picked up one game: Kamiwaza, a PS2 "stealth" game where you play as a thief in feudal Japan stealing hella stuff.&lt;/p&gt;
    &lt;p&gt;As you might guess, it's more silly than stealthy.&lt;/p&gt;
    &lt;p&gt;Shout out to my shopping partner in crime, Paradise Killer's Oli Clarke Smith, for the recommendation. I've got a feature on the way in the coming weeks over at PC Gamer based on some of the games we picked up and how they speak to the "identity" of particular retro consoles. I'm hoping it'll be a fun read!&lt;/p&gt;
    &lt;p&gt;For now, let's hop into MAME; then stick around for an update on Pioneer LaserActive emulation!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Big Two&lt;/head&gt;
    &lt;head rend="h3"&gt;1. The Hyper Neo Geo comes to MAME: Now with working sound!&lt;/head&gt;
    &lt;p&gt;21 years ago, David "MameHaze" Haywood started looking into what it would take to add support for the Hyper Neo Geo 64 arcade system — then just five years past the end of its short lifespan — to MAME. "When I started looking at the system back in 2004 MAME didn't really do much 3D stuff at all, even things like the MIPS (main CPU) core were in a much rougher shape, there were no dumps of the I/O MCU at all (happened only a few years ago) and the PC I had at the time barely had enough memory to load and decode even the 2D graphics," he says.&lt;/p&gt;
    &lt;p&gt;"It was also pre-YouTube, and even in the early days of YouTube you didn't really get much in the way of good reference material. Kinda crazy to think that a lot of people who are probably interested in the emulation of the platform now as younger adults weren't even born when emulation work first started on it!"&lt;/p&gt;
    &lt;p&gt;A few weeks ago, two decades after he started looking into the system, Haywood finally promoted it to "working" status in MAME. But that move was a bit of a formality, or a bit sneaky, depending on how you look at it. Though the promotion got some buzz, it wasn't truly finished: proper sound emulation was still missing. Haywood actually hadn't worked on the core since 2023, and decided, well, people had been playing the games for long enough without sound, he might as well slap the "working" label on. It turned out to be the final push other MAME contributors needed to take a crack at tuning up the sound.&lt;/p&gt;
    &lt;p&gt;What's the Hyper Neo Geo's whole deal, anyway? Well, it makes some sense that the system would be more a curiosity for younger folks to discover than an object of intense nostalgia like some of MAME's more high-profile cores or the original Neo Geo; it was only active in arcades for two years from 1997 to 1999 during the awkward transitional period to 3D, with just seven games released for it:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Road's Edge&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64&lt;/item&gt;
      &lt;item&gt;Xtreme Rally&lt;/item&gt;
      &lt;item&gt;Beat Busters: Second Nightmare&lt;/item&gt;
      &lt;item&gt;Samurai Shodown 64: Warriors Rage&lt;/item&gt;
      &lt;item&gt;Fatal Fury: Wild Ambition&lt;/item&gt;
      &lt;item&gt;Buriki One&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here's a nice write-up of the system from Nicole Express that delves into the hardware:&lt;/p&gt;
    &lt;p&gt;None of these games have the Bloodborne-style pull to individually inspire interest in emulation, but the MAME team's all-consuming drive to reverse-engineer and archive every arcade system in existence kept it on the radar. Haywood's initial investigation into it predated even MAME's high profile support of Capcom's CPS3 boards, for instance, but once that platform was decrypted support was added quite quickly because hell yeah people wanted to play Street Fighter III. By comparison, "Hyper64 has been a 21 year on-and-off slog," he says.&lt;/p&gt;
    &lt;p&gt;It's a perfect representation one of the eternal frustrations of emulation development: People often ask why no one's working on something when they actually are. Just invisibly.&lt;/p&gt;
    &lt;quote&gt;"The sheer number of times I picked up the Hyper64 driver and pumped weeks of work in it only to not be able to make any progress at all was frustrating at the best of times. Just trying to gain an understanding of it all, but ending up not making any headway at all. That's something I don't think people really appreciate when it comes to emulation, the amount of time that you have to put in which often yields no positive results at all, where all you can really conclude is it doesn't work the way you were hoping it would work."&lt;/quote&gt;
    &lt;p&gt;A few years ago, Haywood finally made substantial progress: Someone dumped the I/O microcontroller, and he was able to write a CPU core to emulate it. "The inputs finally started working in a bunch of the games, which allowed me to explore them further and make video improvements," he said.&lt;/p&gt;
    &lt;p&gt;"Other components improving in MAME over the years has really helped too. When I started MAME didn't have a CPU core for the V53 either (which is a V33 CPU with variolus peripherals) and is the CPU driving the sound DSP. At some point in MAME's history the V53 support got fleshed out (for other systems) which has really come in handy now, as proper sound emulation requires that to be running properly."&lt;/p&gt;
    &lt;p&gt;When Haywood marked the platform as working, it caught the attention of another longtime MAME contributor: R. Belmont. For the last month or so, Belmont, as well as two other devs, Happy and O. Galibert, have been chipping away at making the games sound like they're supposed to.&lt;/p&gt;
    &lt;p&gt;"Haze marking them working did provide a push, and Happy had done a detailed disassembly of the sound CPU program which was quite useful," Belmont recently posted on Reddit. Belmont and Galibert have both been working on synthesizer support in MAME, and the Hyper Neo Geo 64's sound chip happens to be used it one, providing them with some convenient overlap in interest/speciality.&lt;/p&gt;
    &lt;p&gt;The current MAME release, 0.281, includes a series of rapid-fire improvements as documented by Belmont in a few videos on YouTube:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Very early work in progress on better audio for the Hyper Neo Geo 64 system. There is a loooong way to go, this is just some very basic fixes so far."&lt;/item&gt;
      &lt;item&gt;"Since the first video we've got the basic sample starts and stops working the actual correct way they're supposed to and added a preliminary support for volume envelopes, which also helps the audio balance. Still a lot of work to go though."&lt;/item&gt;
      &lt;item&gt;"More progress today! I figured out how the volume envelopes really work, and that made Buriki One's intro mostly awesome."&lt;/item&gt;
      &lt;item&gt;"Barring any last minute adjustments, this is what HNG64 audio will sound like in MAME 0.281. Since the last video, the per-voice low pass filter was added, which cleans up some of the high frequency 'hash' audible previously and makes the sound a bit cleaner."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It was a ton of progress for a month, taking Hyper Neo Geo 64 sound support from messy and inaccurate to, at least, broadly playable without assaulting your ears. But the real refinements have been coming in just the last few days since 0.281's release in late September.&lt;/p&gt;
    &lt;p&gt;But the next build is gonna be the big one. October's upcoming MAME 0.282 release will notably fix up the audio issues in one of the the trickiest games, Xtreme Rally, while really polishing up the rest. Here's what Belmont's noted in update notes for 0.282 so far:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Olivier Galibert figured out how they squeezed 12 bits of dynamic range into 8 bits (presumably this is the format from Roger Linn's original MPC60 design) and replaced the biquad low-pass filter with a more likely Chamberlin one that fits the parameters better. Also there were some improvements to the filter envelope. All this results in much clearer and higher-fidelity sound."&lt;/item&gt;
      &lt;item&gt;"This time we've figured out how looping samples actually work, fixed the final mixdown to not introduce any distortion, and fixed the filter envelope. The result? A dramatic improvement to Beast Busters Second Nightmare's intro."&lt;/item&gt;
      &lt;item&gt;"So the previous fixes seem to have solved Samurai Shodown 64 and SS64 2, but Xtreme Rally (aka Off Beat Racer) was still extremely broken. The engine sound barely worked, sounds were missing, and some sounds would stick looping forever. This time the problem wasn't actually in the sound emulation itself; Xtreme Rally has unique code among the 7 HNG64 games that tries to push sound commands to the sound CPU as quickly as possible. This resulted in as many as 2/3rds of the commands getting dropped on the floor. I have fixed that issue so that all of the commands make it, and Xtreme Rally now sounds great."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since Belmont made that post he dialed in a few more improvements where the wrong sounds were playing in certain instances in the game. Here's a video from Haywood showing off the vastly improved audio (though he notes "some graphical issues, such as the fog in the tunnel still need addressing eventually.")&lt;/p&gt;
    &lt;p&gt;Once MAME 0.282 releases, the Hyper Neo Geo 64 will well and truly be worthy of the "working" label. Turns out it just needed that last little push.&lt;/p&gt;
    &lt;p&gt;In a perfect encapsulation of how these sorts of collaborative projects come together, Galibert noted on Reddit that despite their contributions to the core stemming from an interest in emulating synthesizers, "amusingly, the synth itself (MPC3000) is not working at all yet." Some parts of the synthesizer remain undumped and undocumented, just as parts of the Hyper Neo Geo once were; sometimes while you're waiting for all the pieces to fall into place, it turns out one of the pieces you do have happens to fit into another puzzle entirely.&lt;/p&gt;
    &lt;p&gt;"It's just been a long slow process," Haywood said. "Things have inched forward a little bit over the years, and the surrounding code in MAME has become better / more capable, allowing for more progress to be made, step by step."&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Can't stop Pioneering: NEC support and big LaserActive performance improvements arrive in the latest Ares nightlies&lt;/head&gt;
    &lt;p&gt;Often I end a big story, like the August issue's deep dive into the 16 years it took to emulate the Pioneer LaserActive, with the door open to a follow-up many months or years down the road. In this story, our hero — emudev Nemesis — finished work on one of two modules for the Laserdisc-based gaming console, making it possible to play Sega's Mega LD games via emulation for the first time.&lt;/p&gt;
    &lt;p&gt;As of publication time, Nemesis was juuuust starting to take a look at the work required to do the same for the other "pak" players could slot into the LaserActive to play NEC PC Engine games, but who knew how long that would take?&lt;/p&gt;
    &lt;p&gt;Maybe we'd come back to it before the end of 2026, or maybe next year, or maybe in half a deca-&lt;/p&gt;
    &lt;p&gt;Oh. He already did it.&lt;/p&gt;
    &lt;p&gt;"NEC LDROM2 support is functioning on nightly builds of the v147 prerelease, and will be included in the next official Ares release," Nemesis recently wrote on his website. It took less than three weeks. While you can grab the nightly build anytime, when the next stable build of Ares releases, it'll be all official-like.&lt;/p&gt;
    &lt;p&gt;Considering the bulky size of the LaserActive game rips — they can take up dozens of gigabytes — some performance optimizations Nemesis has implemented in the last few days are almost as exciting as the second console support. Because now you should be able to run the images off a decent HDD without performance issues. Here's the breakdown on Github:&lt;/p&gt;
    &lt;quote&gt;"This change brings speed enhancements to LaserActive games. The linear resampling coefficient precalculation reduces overall CPU overhead by approximately 30%, making slower CPUs much more likely to achieve full framerate. Additionally, frame prefetch using a background thread makes games much more tolerant of IO latency, making it possible to play games back from platter drives over SATA3.&lt;lb/&gt;This should be sufficient to make emulation performance acceptable on 95%+ of systems, and I don't have any further optimizations planned at this stage."&lt;/quote&gt;
    &lt;p&gt;So then — LaserActive support is more or less feature complete. What can you play? What should you play? Seeing as the system's deader than dead and nobody's likely to be playing copyright cop, the Laserdisc rips are being freely uploaded and shared here. Not every game is available yet, but here's where you should probably start:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Vajra and Vajra 2 - A pair of LaserActive-exclusive rail shooters by Data West&lt;/item&gt;
      &lt;item&gt;Triad Stone - An FMV game in the Dragon's Lair game&lt;/item&gt;
      &lt;item&gt;J.B. Harold - Blue Chicago Blues - As described by Nemesis, an "FMV murder mystery detective game, with a surprising amount of freedom. You have control over where to go, what actions to take, and what questions to ask. This title came on a double-sided CLV disc, giving it four times the video content of a typical single-sided CAV LaserActive title. The game also used separate video streams per field, to squeeze a whopping 4 hours of footage into one disc."&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are a couple other cool games and curiosities on the system, including more rail shooters, some prototypes of Myst, and a German TV movie that lets you swap between different perspectives — but the above should give you a taste for that sweet sweet (or fuzzy, fuzzy) '90s laser gaming.&lt;/p&gt;
    &lt;head rend="h2"&gt;Patching In&lt;/head&gt;
    &lt;p&gt;MiSTer's Taito F2 core pulls off a Hat Trick – Taito's 1990 game Football Champ, aka Hat Trick Hero, is now playable on the MiSTer's arcade core, as is the baseball game Ah Eikou no Koshien. The latter's surprisingly expressive for its era and looks like a lot more fun than I expect from '90s baseball games.&lt;/p&gt;
    &lt;p&gt;MiSTer's CDi core once again threatens you by functioning – In the latest unstable nightly build of the CDi core, developer Andre Zeps has committed several crimes of CDi improvement, including: "Fix dual SDRAM mode," "Add support for chroma subcarrier for clean composite video from external RGB converters," and "- Add bob deinterlacing to ascal." Go on then, but don't blame me if you start bleeding from every orifice while playing Wind of Gamelon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Core Report&lt;/head&gt;
    &lt;p&gt;Windows builds of RPCS3 are back in business – Due to a compiler issue, RPCS3's latest builds haven't been available on Windows since back in June, but they're back and working again now. Meanwhile, contributor Whatcookie has created a surprisingly detailed breakdown of how hard it is to do nothing, efficiently.&lt;/p&gt;
    &lt;p&gt;Eden is off the Play Store, for now – Well, so much for that. After launching on Android a few weeks ago, the Switch emulator has been taken down, though you can still find builds, including for Android, on the Github. Aren't DMCA takedowns lovely?&lt;/p&gt;
    &lt;p&gt;Speedrunning-focused emulator BizHawk gets hexed – But in a good way! The source port DSDA-Doom has been integrated into BizHawk, supporting Doom, Heretic and Hexen. It also now has an integrated DOSBox-X core, as well as Opera, for the 3DO.&lt;/p&gt;
    &lt;p&gt;ShadPS4 gets more Unreal – The latest build of ShadPS4 marks a significant milestone: some Unreal Engine games for the console are now playable, and even more are bootable. Look at all these games that work!&lt;/p&gt;
    &lt;head rend="h2"&gt;Translation Station&lt;/head&gt;
    &lt;p&gt;Tis the season for brains... Dead of the Brain (2) – It's spooky season, which means the crew behind the translation of PC-98 adventure game Dead of the Brain is back with the sequel two years after the first! "Like the original game, this is also a point-and-click adventure involving zombies, but this time the gameplay is much simpler, but there's still a degree of brute force required," translation crew WINE says. Playing this one might be a bit tedious, but the art is :chefskiss:&lt;/p&gt;
    &lt;p&gt;Virtual-On, on PS3 – The PS3 re-release of this mecha game had English dialogue etc., but its UI was in Japanese. This translation patch changes that.&lt;/p&gt;
    &lt;p&gt;Wizardy VI, on Saturn – There are at least nine platforms you can play Wizardry: Bane of the Cosmic Forge on, from the 1990 DOS original to the Amiga and FM Towns and modern ports, but the Japanese-only Saturn port is unique, incorporating features from Wizardry 7, and now playable with the original English script. This version has "more spells, more traps, and more skills (though most of the extra skills do nothing in 6, unfortunately), and the art style too is very reminiscent of 7 ... it’s also got a much easier early game, which a lot of new players have notoriously struggled with when playing the other versions," hacker and fan Remisse told Sega Saturn Shiro.&lt;/p&gt;
    &lt;p&gt;Undercover Cops play board games on the GB – Prolific translation group Stardust Crusaders is back with a Game Boy board/card game based on the arcade game. I'm not gonna say it's one of Irem's all-timers (find me playing Ninja Baseball Bat Man instead), but it's cute!&lt;/p&gt;
    &lt;head rend="h2"&gt;Good pixels&lt;/head&gt;
    &lt;p&gt;It's early October which means it's basically Halloween, right? Here's a load of screenshots from the first couple hours of Dead of the Brain 2. 👻&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.readonlymemo.com/mame-hyper-neo-geo-support-sound-emulation/"/><published>2025-10-08T15:01:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517134</id><title>The RSS feed reader landscape</title><updated>2025-10-08T19:32:12.298499+00:00</updated><content>&lt;doc fingerprint="be149c54c0323cec"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A deep dive into the rss feed reader landscape&lt;/head&gt;
    &lt;p&gt;RSS feeds and, in one form or another, feed readers, have existed for more than 20 years. Their main purpose is enabling their users to consume content from various sources in one place. And especially in recent years, also helping users deal with content overload.&lt;/p&gt;
    &lt;p&gt;Back then there were only a handful of relevant products. Today it's different, there are products for many different situations and use-cases. When first getting into RSS and feed readers, it can be difficult to find out which of this wide range of products are the right ones to use.&lt;/p&gt;
    &lt;p&gt;This article describes the landscape so you can find out which product fits best for your use-case.&lt;/p&gt;
    &lt;p&gt;Side-note: I'm using RSS as a synonym for all web feed standards (Atom, JSON Feed)&lt;/p&gt;
    &lt;head rend="h2"&gt;Classification&lt;/head&gt;
    &lt;p&gt;I attempted a classification of feed readers based on 2 axes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Deployment model: local (phone or PC), browser extension, self-hosted, hosted&lt;/item&gt;
      &lt;item&gt;Business model: free, one-time payment, SAAS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The deployment model is based on where data is stored and feed fetching happens. Some products have a web app and mobile apps, but feed fetching happens on the server. In this case it's classified as &lt;code&gt;hosted&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;The business model categorization is based on the cheapest option that gives access to the full feature set of the product. A self-hostable product with a hosted option is categorized into &lt;code&gt;free&lt;/code&gt;. A freemium SAAS product is categorized as &lt;code&gt;paid (SAAS)&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And here the image in table format, for easily clickable links:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Pricing&lt;/cell&gt;
        &lt;cell role="head"&gt;On-device (phone or PC)&lt;/cell&gt;
        &lt;cell role="head"&gt;Browser extension&lt;/cell&gt;
        &lt;cell role="head"&gt;Self-hosted&lt;/cell&gt;
        &lt;cell role="head"&gt;Hosted&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Free&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Paid (one-time)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hosting models&lt;/head&gt;
    &lt;head rend="h3"&gt;Browser extension&lt;/head&gt;
    &lt;p&gt;Feed readers deployed as browser extensions can be installed through the respective stores of the browsers, usually either the Chrome Web Store or the Firefox Add-ons.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup typically only requires installing the extension, not even an account is needed. There is no maintenance required beyond the occasional update, which usually happens automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally, with browser storage functionality (local storage or IndexedDB). How much data can be stored depends on the storage of the device. Browser extensions can only store as much data as the browser allows itself to use. But for most users this is easily enough.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device itself. Because the extension only runs if the browser runs, feeds are only fetched if the browser is open. This can lead to missed posts, depending on the publishing frequency of the feed and how often the browser is active.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Since all data is stored on the device, by default it's available only on the device where the extension is installed. If users enable it, the extension supports it, and the user is signed in, browsers can sync data to other devices that have the extension. Storing all data on the device also means that it is accessible offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Extensions can integrate deeply with the browser, and offer features like automatic feed finding of visited websites. Extensions can also provide a comprehensive feature set. Their only limitations are more compute-intensive features (e.g. requiring machine learning), or features that require special infrastructure to run (e.g. emails).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products (free)&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;In this category I only found one product. Smart-RSS was another one, but was discontinued in February.&lt;/p&gt;
    &lt;head rend="h3"&gt;On-device&lt;/head&gt;
    &lt;p&gt;On-device products are separate applications and installed on the device you want to use them. Either on your iOS or Android phone or tablet, or on your Windows, Mac, or Linux computer. They fetch feeds and store data on that device.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: In general setup is done by installing the application. Some products may require an account, but that is not the norm. Maintenance is similar to browser extensions, the occasional updates. Some applications require manual update installations, others do that automatically.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Data is stored locally on the device, which gives total control over the data. The maximum amount of feeds and articles stored only depend on the available storage of the device.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the device. For that to happen the application must be running. Some products may implement a background fetching service, in that case only the device must be turned on. Similar to browser extensions, this limitation may lead to missed posts.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Typically the data of on-device feed readers are only available on the device where it's installed. Data sync would need to be done manually or via operating system specific mechanisms (e.g. iCloud), which not all products support. Since data is stored on the device, it's also available offline.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On-device products can use the full computing power of the device. Combined with the comparatively small storage requirements of one user, it means that some features can be significantly faster than other categories. The exact features depend on the application, and mobile apps are typically less powerful than desktop apps. Limitations are only features that require multiple users (e.g. recommendations) or specific infrastructure (e.g. newsletter subscriptions).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Self-hosted&lt;/head&gt;
    &lt;p&gt;Self-hosted products all fall into the open-source and free category. They are designed to be installed on a server to run continuously, though it is possible to install them on a PC as well. They fetch feeds and store data on the server, and make it available through a web interface.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Setup requires a server, installing the application, and depending on how it should be accessible, possibly also domain and reverse proxy setup. This needs significantly more technical knowledge than the other options, but with ChatGPT (or others) it should be possible also for fairly non-technical people. This setup is generally more complex with more failure points than the other options, but with a correct setup failures happen rarely, if at all.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: The application stores data on the server it runs on. Since users control their server, they also have total control over the data stored on it. Applications typically use well-established databases, which allows users to inspect and change data with common tools. The amount of data that can be stored is only limited by the available storage on the server. Most servers start at 20 GB, which is enough for most feed reading use-cases. Often, storage can be dynamically extended if more space is needed.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Feeds are fetched on the server. Since it runs continuously, there is no break in feed fetching, and even high frequency feeds are no problem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: The application and all its data is accessible from any device with a web browser by navigating to the server's URL. Data is stored on the server, therefore automatically synced between all devices that use it, but also require internet access.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: On average self-hosted products have a wider feature set than browser extension or on-device feed readers. There is no theoretical limit on the feature set, but typically they keep the infrastructure as simple as possible, to keep setup and maintenance straightforward. This makes them slightly less powerful than hosted alternatives.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;p&gt;Self-hosted products are all open-source and free. The only costs are for the server, and the cheapest VPS plans start at ~2$/month.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hosted&lt;/head&gt;
    &lt;p&gt;Hosted feed readers are managed services. It's required to create an account to get access to them. All of them are paid SAAS products, and most offer a free plan.&lt;/p&gt;
    &lt;p&gt;On average they have the most polished user experience and most comprehensive feature sets, since they're backed by companies that invest in continuous development.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Setup and maintenance: Beyond creating an account, no setup is required. The same for maintenance. Service providers make sure the products work as intended, and deal with everything required to keep the service running, including infrastructure setup, monitoring, backups, etc.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Data control and storage: Since data is stored on the servers and databases of the company running the product, users don't have direct control. But through laws like GDPR users have the right to export all their data, or request deletion. Storage is essentially unlimited, though most products have limits to avoid abuse. These limits are mentioned on their pricing page.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Feed fetching: Similar to self-hosted products, feeds are fetched on the server, which runs continuously and ensures that even high-frequency feeds don't pose a problem. The fetching interval is usually dynamic, based on the popularity of a feed and the publishing frequency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Availability: Hosted products are primarily available as web application, and some offer native apps as well. Since data is stored on the server, it's natively synced between devices. Some hosted feed readers also offer offline support.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Functionality: Hosted feed readers serve many customers at the same time, which makes it necessary to have more complex infrastructure setups. This also enables features that other types of products cannot do, like email receiving, recommendations, or historic feed contents. Consequently hosted options are generally more powerful than other categories, though the specific feature set depends on the product.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Products&lt;/head&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell role="head"&gt;Free&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (one-time)&lt;/cell&gt;
        &lt;cell role="head"&gt;Paid (SAAS)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All hosted products are SAAS products and charge monthly. &lt;code&gt;Folo&lt;/code&gt; is an outlier, they currently don't have any paid features, but the terms of service indicate that this will come in the future. At that point it will join the others in the &lt;code&gt;Paid (SAAS)&lt;/code&gt; category.&lt;/p&gt;
    &lt;head rend="h2"&gt;App support and offline access for products that don't offer it natively&lt;/head&gt;
    &lt;p&gt;Many of the self-hosted or hosted products don't provide apps or offline access by themselves. However, with the right setup, it's still possible to access the articles offline.&lt;/p&gt;
    &lt;p&gt;Most of these products provide APIs. This can be a proprietary API, or an API based on the old Google Reader API.&lt;/p&gt;
    &lt;p&gt;Mobile apps, for example ReadKit or Fiery Feeds, can not only subscribe to feeds, but also connect to other products through their APIs. They download contents, store them locally, and sync changes back to the connected products.&lt;/p&gt;
    &lt;p&gt;These apps make it possible to use a native mobile app for products that don't provide an app themselves, and get offline access at the same time.&lt;/p&gt;
    &lt;p&gt;FreshRSS, for example, has a list of native apps that support it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A note on newsletters&lt;/head&gt;
    &lt;p&gt;Newsletters are a growing mechanism for delivering (blog) content. Some, but not all, hosted feed readers support newsletters out of the box. But on-device products can't do that at all because of their infrastructure limitations.&lt;/p&gt;
    &lt;p&gt;Even if a feed reader doesn't support newsletters by itself, it's still possible to get newsletters into the feed reader, through services that convert newsletters into RSS feeds.&lt;/p&gt;
    &lt;p&gt;These services generate an email address and give you a corresponding feed URL. Emails to the generated address are added to the feed as new entry. So after signing up to the newsletter and adding the feed URL, the newsletter is added to the feed reader even without native email support.&lt;/p&gt;
    &lt;p&gt;Services that do this are Kill the Newsletter and the Lighthouse Newsletter to RSS tool. Both are free.&lt;/p&gt;
    &lt;head rend="h2"&gt;Products&lt;/head&gt;
    &lt;p&gt;The descriptions highlight the defining and unique aspects of the products, for the full feature list please go to their respective websites. Where available I used the screenshots for their websites, to represent the products as best as possible (test account screenshots wouldn't be as good).&lt;/p&gt;
    &lt;head rend="h3"&gt;NetNewsWire (on-device, free)&lt;/head&gt;
    &lt;p&gt;NetNewsWire is a free, on-device feed reader for Mac and iOS. By default it stores data on the device itself, but can sync via iCloud and using other products as storage. And it provides a Safari extension for easy feed-adding. Notably, it supports AppleScript, which makes it possible to automate certain workflows.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fiery Feeds (on device, paid SAAS)&lt;/head&gt;
    &lt;p&gt;Fiery feeds is a Mac and iOS app. The download is free, and to get the premium features it costs ~15$/year (varies by region). By default it stores data on the device itself, but can sync via iCloud and using the API of other products (e.g. FreshRSS). The main distinguishing features are the customization options of the app, like custom themes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reeder (on-device, SAAS)&lt;/head&gt;
    &lt;p&gt;The current version of Reeder is a Mac and iOS app. The download is free, and to get the premium features it costs ~10$/year. The previous version of Reeder, now called Reeder Classic, is still available as one-time purchase. It also stores data on-device, and can sync via iCloud.&lt;/p&gt;
    &lt;p&gt;The main distinguishing feature is the unified timeline, which includes RSS, podcasts, social media, and more.&lt;/p&gt;
    &lt;head rend="h3"&gt;FreshRSS (self-hosted, free)&lt;/head&gt;
    &lt;p&gt;FreshRSS is a self-hosted feed reader and once set up, it's available as a web app. It is quite powerful, and in addition to normal feed subscriptions offers WebSub as well. It's possible to customize it with themes and extensions, and it's translated into more than 15 languages.&lt;/p&gt;
    &lt;p&gt;Together with Miniflux they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Miniflux&lt;/head&gt;
    &lt;p&gt;Miniflux is a self-hosted feed reader as well, and available as web app after setup. It's focus is on staying simple and fast instead of adding fancy features. It also offers a hosted version, which is 15$/year and has a 15 day trial period.&lt;/p&gt;
    &lt;p&gt;Together with FreshRSS they're the most-recommended self-hosted options.&lt;/p&gt;
    &lt;head rend="h3"&gt;Folo (hosted, free)&lt;/head&gt;
    &lt;p&gt;Folo is a relatively new product developed by the creators of RSS Hub. It's a free hosted feed reader, with apps available for every major platform. Their terms of service suggest that at some point they will charge a monthly fee for some premium features, but at the time of writing there were no paid features.&lt;/p&gt;
    &lt;p&gt;Folo is also open-source and therefore theoretically self-hostable, but I haven't found documentation for it.&lt;/p&gt;
    &lt;p&gt;It has a huge feature set, including newsletter support, transforming websites into feeds, AI summaries, and much more.&lt;/p&gt;
    &lt;head rend="h3"&gt;Feedly (hosted, SAAS)&lt;/head&gt;
    &lt;p&gt;Feedly is the most widely-known product and has the most users of all feed readers. It has a comprehensive features set, and offers a free plan as well. For the past couple of years, it seems that Feedly has focused more on AI features and enterprise customers, but their core product remains solid.&lt;/p&gt;
    &lt;head rend="h3"&gt;Inoreader&lt;/head&gt;
    &lt;p&gt;Inoreader is the second most widely-known product, after Feedly. It too offers a free plan. Their feature list is impressive, with social media support for subscriptions, automation and AI features, public API and integrations. And of course much more.&lt;/p&gt;
    &lt;p&gt;What stands out on Reddit are complaints about price hikes. Though Inoreader probably has tens or hundreds of thousands of users who don't have issues and think the product is great.&lt;/p&gt;
    &lt;head rend="h3"&gt;Readwise Reader&lt;/head&gt;
    &lt;p&gt;Readwise Reader is a relatively new product, from the creators of the original Readwise. It's a great feed reader, though were it really shines is the reading experience. They also have reading views for PDFs, eBooks, and more.&lt;/p&gt;
    &lt;p&gt;The website mentions that it's in beta, but it has been in beta for years now and at this point is a stable product, and has been for awhile.&lt;/p&gt;
    &lt;head rend="h3"&gt;Tiny Tiny RSS&lt;/head&gt;
    &lt;p&gt;Tiny Tiny RSS deserves an honorable mention in this list. It was, and still is, used by many, and has been for a long time, and was often recommended on the RSS subreddit.&lt;/p&gt;
    &lt;p&gt;On October 3rd the maintainer announced that he's going to stop working on it, and will remove all infrastructure on November 1st. Forks of the project with other maintainers may pop up, but at the moment it's too soon to tell what the future of Tiny Tiny RSS will be.&lt;/p&gt;
    &lt;head rend="h3"&gt;Lighthouse&lt;/head&gt;
    &lt;p&gt;Lighthouse is also a relatively new product. It's in beta, which refers to the fact that it doesn't yet have all features necessary to fulfill its vision, which goes beyond simple feed reading.&lt;/p&gt;
    &lt;p&gt;The main differentiator is that it focuses on articles over feeds, and has a separate view for curating articles (the inbox). It's focused on finding high-value content.&lt;/p&gt;
    &lt;head rend="h2"&gt;Similar product categories&lt;/head&gt;
    &lt;p&gt;Feed readers are powerful products, which require manual setup to make them work well. Subscribing to feeds is mandatory, adding tags, filtered views, and rules can make them work even better. But for some use-cases, other product categories are simpler and might work better.&lt;/p&gt;
    &lt;head rend="h3"&gt;News aggregators&lt;/head&gt;
    &lt;p&gt;News aggregators automatically collect and curate news from a large variety of sources. They usually provide some customization options, but focus on news and don't allow arbitrary feed subscriptions like feed readers do.&lt;/p&gt;
    &lt;p&gt;They focus on providing an overview of the most relevant news stories.&lt;/p&gt;
    &lt;p&gt;Examples are Kagi News, Ground News, and SmartNews.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reading lists&lt;/head&gt;
    &lt;p&gt;Reading lists, also called read-it-later apps, are for saving and organizing links you found somewhere on the web. Many feed readers can do the same, but reading lists are optimized for that purpose.&lt;/p&gt;
    &lt;p&gt;Examples are Instapaper and Matter. Karakeep is a self-hosted option.&lt;/p&gt;
    &lt;head rend="h2"&gt;How to choose&lt;/head&gt;
    &lt;p&gt;For most people, going with one of the hosted products is the best option. They're generally the most polished and most powerful products, owing to the fact that they have companies behind them with full-time engineers. They generally also offer a free plan, so if you stay within the limits of those, they will even be free to use.&lt;/p&gt;
    &lt;p&gt;For more specific requirements, products of the other categories can work better. They have different characteristics, and can work better in some situations. For example, if you want total control over your data, self-hosted options are the way to go.&lt;/p&gt;
    &lt;p&gt;It's probably easiest to first decide on the category, and then check out multiple products, or maybe even try them out. Virtually all products support OPML import and export, so moving feed subscriptions from one product to the next is almost zero effort.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lighthouseapp.io/blog/feed-reader-deep-dive"/><published>2025-10-08T15:17:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517532</id><title>A 9KB (3KB gzip) single HTML notebook, perfect for minimalists</title><updated>2025-10-08T19:32:12.227616+00:00</updated><content>&lt;doc fingerprint="5efc44c9cefa3016"&gt;
  &lt;main&gt;&lt;p&gt;/g,"&amp;gt;")},q=e=&amp;gt;(o=&amp;gt;o.replace(/^##### (.*?)\s*#*$/gm,"&lt;/p&gt;&lt;code&gt;"+i(t).replace(/`/g,"`")+"&lt;/code&gt;"}).replace(/`(.*?)`/gm,"&lt;code&gt;$1&lt;/code&gt;").replace(/^&amp;gt;&amp;gt; (.*$)/gm,"&lt;quote&gt;").replace(/^&amp;gt; (.*$)/gm,"$1&lt;/quote&gt;&lt;quote&gt;$1").replace(/&amp;lt;\/blockquote&amp;gt;\n&lt;/quote&gt;&lt;quote&gt;/g,`&lt;lb/&gt;`).replace(/&amp;lt;\/blockquote&amp;gt;\n/g,`&lt;lb/&gt;`).replace(/!\[(.*?)]\((.*?) "(.*?)"\)/gm,'').replace(/!\[(.*?)]\((.*?)\)/gm,'').replace(/\[(.*?)]\((.*?) "new"\)/gm,'$1').replace(/\[(.*?)]\((.*?) "(.*?)"\)/gm,'$1').replace(/&lt;http&gt;/gm,'http$1').replace(/\[(.*?)]\(\)/gm,'$1').replace(/\[(.*?)]\((.*?)\)/gm,'$1').replace(/^[*|+-][ |.](.*)/gm,"&lt;/http&gt;&lt;list&gt;").replace(/&amp;lt;\/ul&amp;gt;\n&lt;/list&gt;&lt;item&gt;$1&lt;/item&gt;&lt;list&gt;/g,` `).replace(/^\d[ |.](.*)/gm,"&lt;/list&gt;&lt;list&gt;").replace(/&amp;lt;\/ol&amp;gt;\n&lt;/list&gt;&lt;item&gt;$1&lt;/item&gt;&lt;list&gt;/g,` `).replace(/\*\*\*(.*)\*\*\*/gm,"$1").replace(/\*\*(.*)\*\*/gm,"$1").replace(/\*([\w ]*)\*/gm,"$1").replace(/___(.*)___/gm,"$1").replace(/__(.*)__/gm,"$1").replace(/_([\w ]*)_/gm,"$1").replace(/~~(.*)~~/gm,"&lt;/list&gt;&lt;del&gt;$1&lt;/del&gt;").replace(/\^\^(.*)\^\^/gm,"$1").replace(/ {2}\n/g,`&lt;lb/&gt;`).replace(/\n\s*\n/g,`&lt;p&gt;`).replace(/^ {4,10}(.*)/gm,function(r,t){return"&lt;/p&gt;"}).replace(/^\t(.*)/gm,function(r,t){return"&lt;code&gt;"+i(t)+"&lt;/code&gt;"}).replace(/&amp;lt;\/code&amp;gt;&amp;lt;\/pre&amp;gt;\n&lt;code&gt;"+i(t)+"&lt;/code&gt;&lt;code&gt;/g,` `).replace(/\\([`_~*+\-.^\\&amp;lt;&amp;gt;()\[\]])/gm,"$1"))(e);document.addEventListener("DOMContentLoaded",()=&amp;gt;{document.querySelector("#btnNew").addEventListener("click",()=&amp;gt;{p()}),document.querySelector("#publish").addEventListener("click",()=&amp;gt;{s&amp;amp;&amp;amp;$(s);const r=document.createElement("section"),t=document.querySelector("#toast"),n=document.querySelector("#title"),a=document.querySelector("#story"),l=n?.value,f=a?.value;if(!l){t.textContent="Title is required.",t.togglePopover();return}r.id=l,r.innerHTML=m`&lt;/code&gt;&lt;article&gt;`,document.querySelector("main").append(r),r.querySelector(".edit").onclick=p.bind(void 0,l),r.querySelector(".del").onclick=b.bind(void 0,l);const h=document.querySelector("#archive ul"),d=document.createElement("li");d.innerHTML=m`${l}`,h.append(d);const u=document.createElement("a");u.href="#archive",g(u)}),document.querySelector("#save").addEventListener("click",r=&amp;gt;{r.preventDefault(),y()})});&lt;/article&gt;&lt;head&gt;${l}&lt;/head&gt;&lt;article&gt;${q(f)}&lt;/article&gt;&lt;head&gt;Xie&lt;/head&gt;A 9KB (3KB gzip) single HTML notebook, perfect for minimalists.&lt;p&gt;Just write.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chunqiuyiyu.github.io/xie/"/><published>2025-10-08T15:54:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517642</id><title>Suspicionless ChatControl must be taboo in a state governed by the rule of law</title><updated>2025-10-08T19:32:11.244182+00:00</updated><content>&lt;doc fingerprint="f8eb8f2f2d953eed"&gt;
  &lt;main&gt;
    &lt;p&gt;To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://digitalcourage.social/@echo_pbreyer/115337976340299372"/><published>2025-10-08T16:03:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45517674</id><title>Ortega hypothesis</title><updated>2025-10-08T19:32:11.147079+00:00</updated><content>&lt;doc fingerprint="efd8585d1ac4d390"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Ortega hypothesis&lt;/head&gt;&lt;p&gt;The Ortega hypothesis holds that average or mediocre scientists contribute substantially to the advancement of science.[1] According to this hypothesis, scientific progress occurs mainly by the accumulation of a mass of modest, narrowly specialized intellectual contributions. On this view, major breakthroughs draw heavily upon a large body of minor and little-known work, without which the major advances could not happen.[2]&lt;/p&gt;&lt;head rend="h2"&gt;Citation research&lt;/head&gt;[edit]&lt;p&gt;The Ortega hypothesis is widely held,[2] but a number of systematic studies of scientific citations have favored the opposing "Newton hypothesis", which says that scientific progress is mostly the work of a relatively small number of great scientists (after Isaac Newton's statement that he "stood on the shoulders of giants").[1] The most important papers mostly cite other important papers by a small number of outstanding scientists, suggesting that the breakthroughs do not actually draw heavily on a large body of minor work.[2] Rather, the pattern of citations suggests that most minor work draws heavily on a small number of outstanding papers and outstanding scientists. Even minor papers by the most eminent scientists are cited much more than papers by relatively unknown scientists; and these elite scientists are clustered mostly in a small group of elite departments and universities.[2] The same pattern of disproportionate citation of a small number of scholars appears in fields as diverse as physics and criminology.[3]&lt;/p&gt;&lt;p&gt;The matter is not settled. No research has established that citation counts reflect the real influence or worth of scientific work. So, the apparent disproof of the Ortega hypothesis may be an artifact of inappropriately chosen data.[4] Stratification within the social networks of scientists may skew the citation statistics.[5] Many authors cite research papers without actually reading them or being influenced by them.[6] Experimental results in physics make heavy use of techniques and devices that have been honed by many previous inventors and researchers, but these are seldom cited in reports on those results.[7][8] Theoretical papers have the broadest relevance to future research, while reports of experimental results have a narrower relevance but form the basis of the theories. This suggests that citation counts merely favor theoretical results.[7]&lt;/p&gt;&lt;head rend="h2"&gt;The name&lt;/head&gt;[edit]&lt;p&gt;The name of the hypothesis refers to José Ortega y Gasset, who wrote in The Revolt of the Masses that "astoundingly mediocre" men of narrow specialties do most of the work of experimental science.[9] Ortega most likely would have disagreed with the hypothesis that has been named after him, as he held not that scientific progress is driven mainly by the accumulation of small works by mediocrities, but that scientific geniuses create a framework within which intellectually commonplace people can work successfully. For example, Ortega thought that Albert Einstein drew upon the ideas of Immanuel Kant and Ernst Mach to form his own synthesis, and that Einstein did not draw upon masses of tiny results produced systematically by mediocrities. According to Ortega, science is mostly the work of geniuses, and geniuses mostly build on each other's work, but in some fields there is a real need for systematic laboratory work that could be done by almost anyone.[10]&lt;/p&gt;&lt;p&gt;The "Ortega hypothesis" derives only from this last element of Ortega's theory, not the main thrust of it. Ortega characterized this type of research as "mechanical work of the mind" that does not require special talent or even much understanding of the results, performed by people who specialize in one narrow corner of one science and hold no curiosity beyond it.[10]&lt;/p&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b David J. Hess. Science Studies: An Advanced Introduction, p. 71. NYU Press, 1997.&lt;/item&gt;&lt;item&gt;^ a b c d Jonathan R. Cole and Cole, Stephen. "The Ortega hypothesis." Science, New Series, Vol. 178, No. 4059 (Oct. 27, 1972), pp. 368-375.&lt;/item&gt;&lt;item&gt;^ M. Oromaner. "The Ortega hypothesis and influential articles in American sociology." Scientometrics, Vol. 7, No. 1 (Jan. 26, 1985), pp. 3–10. doi:10.1007/BF02020136&lt;/item&gt;&lt;item&gt;^ M.H. MacRoberts and Barbara R. MacRoberts. "Testing the Ortega Hypothesis: Facts and Artifacts." Scientometrics, Vol. 12, Nos. 5–6 (1987) pp. 293–295.&lt;/item&gt;&lt;item&gt;^ Hildrun Kretschmer. "Measurement of social stratification. A contribution to the dispute on the ORTEGA hypothesis." Scientometrics, Vol. 26 No. 1 (1993), pp. 97–113. doi:10.1007/BF02016795&lt;/item&gt;&lt;item&gt;^ Heidi Lee Hoerman and Nowicke, Carole Elizabeth. "Secondary and Tertiary Citing: A Study of Referencing Behavior in the Literature of Citation Analysis Deriving from the Ortega Hypothesis of Cole and Cole." The Library Quarterly, Vol. 65, No. 4 (Oct., 1995), pp. 415-434.&lt;/item&gt;&lt;item&gt;^ a b S. A. Goudsmit, John D. McGervey, Robert J. Yaes, Jonathan R. Cole and Stephen Cole "Citation Analysis." Science, New Series, Vol. 183, No. 4120 (Jan. 11, 1974), pp. 28+30-33.&lt;/item&gt;&lt;item&gt;^ Endre Száva-Kováts. "Non-indexed eponymal citedness (NIEC): first fact-finding examination of a phenomenon of scientific literature." Journal of Information Science, 1994 20:55 doi:10.1177/016555159402000107&lt;/item&gt;&lt;item&gt;^ José Ortega y Gasset. The Revolt of the Masses, pp. 110-111. Norton, 1932.&lt;/item&gt;&lt;item&gt;^ a b Endre Száva-Kováts. "The false 'Ortega Hypothesis': a literature science case study." Journal of Information Science 2004 30: 496. doi:10.1177/0165551504047823&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/Ortega_hypothesis"/><published>2025-10-08T16:06:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518127</id><title>Show HN: I built a local-first podcast app</title><updated>2025-10-08T19:32:09.053270+00:00</updated><link href="https://wherever.audio"/><published>2025-10-08T16:46:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518136</id><title>Doctorow: American tech cartels use apps to break the law</title><updated>2025-10-08T19:32:08.719209+00:00</updated><content>&lt;doc fingerprint="2f8888183b37060b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How American Tech Cartels Use Apps to Break the Law&lt;/head&gt;
    &lt;head rend="h2"&gt;Cory Doctorow on Big Tech’s Drive to Enshittify Our Lives&lt;/head&gt;
    &lt;p&gt;The death of competition spells doom for regulation. Competition is an essential component of effective regulation, for two reasons: First, competition keeps the companies within a sector from all telling the same lie to its regulators. Second, competition erodes companies’ profits and thus starves them of the capital they need to overpower or outmaneuver their regulators.&lt;/p&gt;
    &lt;p&gt;While not all regulation is wise or helpful, a world without regulation is a catastrophe. That’s because, in a highly technological world, your ability to do well (or even to live out the day) requires that you correctly navigate innumerable highly technical questions that you can’t possibly answer.&lt;/p&gt;
    &lt;p&gt;You need to know whether you can trust the software in your car’s antilock braking system, whether you should heed your doctor’s advice to get vaccinated, whether the joists over your head at home are sufficient to keep the ceiling from falling in and killing you, and whether your kids’ schooling is adequate or likely to turn them into ignoramuses.&lt;/p&gt;
    &lt;p&gt;Tech-like apps can obfuscate what’s really going on, sloshing a coat of complexity over a business that allows its owners to claim that they’re not breaking the law.&lt;/p&gt;
    &lt;p&gt;It’s not that you lack the intellect and discernment to answer each of these questions. You’re a smart cookie. Given enough time, you could get a PhD’s worth of education in software engineering, cell biology, material science, structural engineering, and pedagogy; investigate each of the offerings before you in each of these categories; and make an intelligent choice that reflects your priorities and the trade-offs you’re willing to make.&lt;/p&gt;
    &lt;p&gt;The problem is that it would take you several lifetimes to acquire all that knowledge, and long before you could do so, you’d be killed by food poisoning because you guessed wrong about whether you could trust the hygiene policies at your local diner.&lt;/p&gt;
    &lt;p&gt;It would be nice if you could let markets take care of these questions for you, but many of the consequences of wrong answers don’t manifest fast enough to steer your decision-making. Sure, if a private school turns one of your kids into an ignoramus, you can demand your money back and refuse to send your other kids to that school—but your kid is still an ignoramus. Likewise, you can punish a restaurant that gives you food poisoning by withholding your future custom, but if that’s a lethal poisoning, the fact that you don’t eat at that restaurant anymore isn’t quite the moral victory you might be hoping for.&lt;/p&gt;
    &lt;p&gt;To navigate all of these technical minefields, you need the help of a third party. In a modern society, that third party is an expert regulator who investigates or anticipates problems in their area of expertise and then makes rules designed to solve these problems.&lt;/p&gt;
    &lt;p&gt;To make these rules, the regulator convenes a truth-seeking exercise, in which all affected parties submit evidence about what the best rule should be and then get a chance to read what everyone else wrote and rebut their claims. Sometimes, there are in-person hearings, or successive rounds of comment and counter-comment, but that’s the basic shape of things.&lt;/p&gt;
    &lt;p&gt;Once all the evidence is in, the regulator—who is a neutral expert, required to recuse themselves if they have conflicts—makes a rule, citing the evidence on which the rule is based. This whole system is backstopped by courts, which can order the process to begin anew if the new rule isn’t supported by the evidence created while the regulator was developing the record.&lt;/p&gt;
    &lt;p&gt;This kind of adversarial process—something between a court case and scientific peer review—has a good track record of producing high-quality regulations. You can thank a process like this for the fact that you weren’t killed today by critters in your tap water or a high-voltage shock from one of your home’s electrical outlets.&lt;/p&gt;
    &lt;p&gt;One key advantage of the process is that it relies on competitors to counter one another’s claims. The reinforced steel joist manufacturer that claims that only its products are suitable for use in high-rise apartment buildings will have to defend those claims against competitors who submit their own structural engineering and material science evidence. Regulators don’t need to look for holes in the arguments advanced by interested parties; they only need to assess the quality of the criticisms raised by other commenters who submit to the docket.&lt;/p&gt;
    &lt;p&gt;This process isn’t just a way to prevent corporate executives from cheating the public by knowingly overpromising about their own products or denigrating their rivals’; it’s also a way to stop firms that have tricked themselves from fooling the rest of us, too. As with the scientific method, the safeguards of peer review help us catch grubby attempts at both deception and self-deception, because it’s very easy to talk yourself into a sincere belief that you are right and everyone else is wrong.&lt;/p&gt;
    &lt;p&gt;This process works well on “disorganized” sectors composed of many firms that compete hard with one another. When hundreds of companies are all at one another’s throats, they suffer from a collective action problem—the same force that keeps users from leaving services like Facebook.&lt;/p&gt;
    &lt;p&gt;Hundreds of companies find it impossible to agree on almost anything, including where to have a meeting in which they could discuss what line they are going to feed their regulator. They probably can’t even agree on how to cater that meeting.&lt;/p&gt;
    &lt;p&gt;Hundreds of companies are a disorganized rabble. They can’t come to accord, and even if they could, a truly competitive sector produces smaller profits for each company (since one of the best ways to compete is by lowering prices to attract new customers and raising wages to attract the best workers). That leaves very little surplus capital with which to pursue regulatory adventures.&lt;/p&gt;
    &lt;p&gt;But when a sector dwindles to five companies—or four, or three, or two, or just one—the collective action problem is annihilated by the inevitable coziness among the executives of the incestuous industries.&lt;/p&gt;
    &lt;p&gt;After all, the executives in an industry dominated by a handful of firms are apt to have worked at most or all of the companies in the sector. They know one another, came up together, and are part of one another’s social milieu.&lt;/p&gt;
    &lt;p&gt;Not only do concentrated industries find it easier to converge on a set of policy priorities and maintain message discipline while bargaining with their regulators, they also have a lot to bargain with. Concentrated sectors tend to have Mafia-style demarcations of turf. (Think of Pope Alexander VI dividing up the “New World” in 1494, of cable companies carving up the map of the United States into exclusive fiefdoms, or of Apple taking an annual $20 billion-plus payment from Google in exchange for not making its own search engine.)&lt;/p&gt;
    &lt;p&gt;This prevents “wasteful competition” and allows these companies to amass gigantic war chests that they can mobilize to win their policy priorities.&lt;/p&gt;
    &lt;p&gt;A hundred companies are a mob, a rabble. Five companies are a cartel.&lt;/p&gt;
    &lt;p&gt;“Regulatory capture”—when a company suborns its regulator and teams up with it to screw over customers, rivals, and suppliers—starts with a regulator that is weaker than the company it is supposed to be watchdogging. The pro-monopoly policies of the past forty years have produced gigantic companies that find it easy to unite against their regulators, even as the deregulatory policies over the same period have starved regulators of the resources they need to fight back. The inevitable result is regulatory capture.&lt;/p&gt;
    &lt;p&gt;*&lt;/p&gt;
    &lt;p&gt;Regulatory capture has two faces: On the one hand, a captured industry is able to flout regulations that are meant to prevent it from harming the public, its employees and other stakeholders, and the environment. On the other hand, regulatory capture creates a coalition between the regulated industry and its regulators. They form a team and work together to enforce rules against other industries, startups, foreign adversaries, and so on. Regulatory capture isn’t the same as underregulation; rather, it is the combination of underregulation (for the industry that has effected the capture) and overregulation (against that industry’s enemies).&lt;/p&gt;
    &lt;p&gt;Tech companies don’t stop with “It’s not a crime if we do it with an app.” They also say, “It’s a crime if you fix our app to defend yourself from our crimes.”&lt;/p&gt;
    &lt;p&gt;The most common tactic used to flout regulation is to break the law with an app and then insist that the law hasn’t been broken at all, because the crime was committed with an app.&lt;/p&gt;
    &lt;p&gt;Sometimes literally (as Uber does when it argues that it’s not an employer because it directs its workers with an app) and sometimes figuratively. Tech-like apps can obfuscate what’s really going on, sloshing a coat of complexity over a business that allows its owners to claim that they’re not breaking the law. (“It’s not an illegal unregulated hotel, it’s an Airbnb!”)&lt;/p&gt;
    &lt;p&gt;Riley Quinn, showrunner for the excellent Trashfuture podcast, says that whenever you hear the word fintech (financial technology), you should mentally substitute unregulated bank.&lt;/p&gt;
    &lt;p&gt;App-based lending platforms ignore usury law and say it doesn’t count because they do it with an app. Cryptocurrency hustlers illegally trade in unregistered securities and say it doesn’t count because they do it with an app.&lt;/p&gt;
    &lt;p&gt;When Uber entered the taxi market without securing taxi licenses or extending the workforce protections required under law, it said the move didn’t count because it did it with an app.&lt;/p&gt;
    &lt;p&gt;The McDonald’s-backed company Plexure sells surveillance data on you to vendors, who use it to raise the price of items when they think you’ll pay more. In its promotional materials, Plexure uses the example of charging extra for your breakfast sandwich on payday. It says that such practices are not a rip-off because they’re done with an app.&lt;/p&gt;
    &lt;p&gt;RealPage gives “recommendations” to landlords about the minimum rents they should charge for all the apartments in your neighborhood, raising rents and worsening the housing crisis. The company says it’s not price-fixing because it’s done with an app.&lt;/p&gt;
    &lt;p&gt;On the subject of the housing crisis, Airbnb is racing to convert all the rental stock in your city into an unlicensed hotel room, but it says the conversion doesn’t count because it’s done with an app.&lt;/p&gt;
    &lt;p&gt;The legal regime for apps really is different from the rules governing web pages. Thanks to intellectual property laws that ban “circumvention,” companies that embed undesirable anti-features in apps can use the law to destroy rivals that disenshittify their offerings.&lt;/p&gt;
    &lt;p&gt;In other words, tech companies don’t stop with “It’s not a crime if we do it with an app.” They also say, “It’s a crime if you fix our app to defend yourself from our crimes.”&lt;/p&gt;
    &lt;p&gt;__________________________________&lt;/p&gt;
    &lt;p&gt;Excerpted from Enshittification: Why Everything Suddenly Got Worse and What to Do About It by Cory Doctorow. Copyright © 2025 by Cory Doctorow. Published by Farrar, Straus and Giroux, October 2025. All rights reserved.&lt;/p&gt;
    &lt;head rend="h4"&gt;Cory Doctorow&lt;/head&gt;
    &lt;p&gt;Cory Doctorow is a science fiction author, activist and journalist. He is the author of many books, including The Lost Cause, a solarpunk science-fiction novel of hope amidst the climate emergency. His nonfiction book The Internet Con: How to Seize the Means of Computation is a Big Tech disassembly manual. Other recent books include Red Team Blues, a science fiction crime thriller; Chokepoint Capitalism, nonfiction about monopoly and creative labor markets; the Little Brother series for young adults; In Real Life, a graphic novel; and the picture book Poesy the Monster Slayer. In 2020, he was inducted into the Canadian Science Fiction and Fantasy Hall of Fame.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lithub.com/how-american-tech-cartels-use-apps-to-break-the-law/"/><published>2025-10-08T16:47:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518813</id><title>WinBoat: Windows apps on Linux with seamless integration</title><updated>2025-10-08T19:32:08.536324+00:00</updated><content>&lt;doc fingerprint="b48fe95fd1b73cdc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt; Run Windows apps on 🐧 Linux&lt;lb/&gt;with ✨ seamless integration &lt;/head&gt;
    &lt;head rend="h2"&gt;FFFFF/Features/sssss&lt;/head&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;p&gt;Scroll for more!&lt;/p&gt;
    &lt;head rend="h2"&gt;Elegant Interface&lt;/head&gt;
    &lt;p&gt;WinBoat provides a sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Automated Installs&lt;/head&gt;
    &lt;p&gt;Installing Windows via WinBoat is a delightfully simple process all done through our interface. Pick your preferences &amp;amp; specs and let us handle the rest.&lt;/p&gt;
    &lt;head rend="h2"&gt;Run Any App&lt;/head&gt;
    &lt;p&gt;If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications, from productivity tools to entertainment, all within your Linux environment as native OS-level windows.&lt;/p&gt;
    &lt;head rend="h2"&gt;Filesystem Integration&lt;/head&gt;
    &lt;p&gt;Accessing your Linux filesystem from Windows is a breeze. Your home directory is mounted in Windows, allowing you to easily share files between the two systems without any hassle.&lt;/p&gt;
    &lt;head rend="h2"&gt;And many more...&lt;/head&gt;
    &lt;p&gt;There's tons more you can do with WinBoat, for example smartcard passthrough and resource monitoring. We're always looking to add more features, so stay tuned for updates!&lt;/p&gt;
    &lt;head rend="h2"&gt;DDDD/Download/ddddd&lt;/head&gt;
    &lt;p&gt;We're excited to have you onboard! Pick your platform below to get started with WinBoat within minutes, not hours.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Contribute/eeeee&lt;/head&gt;
    &lt;p&gt;WinBoat is an open-source project licensed under MIT, and we welcome contributions from the community. Whether you're a developer, designer, or just someone who loves WinBoat, there are many ways you can help us improve and grow.&lt;/p&gt;
    &lt;head rend="h2"&gt;CCCC/Community/yyyyy&lt;/head&gt;
    &lt;p&gt;We usually hang out on Discord, come join and chat with us!&lt;/p&gt;
    &lt;head rend="h2"&gt;FFFFF/Frequently Asked Questions/sssss&lt;/head&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;How does it compare to WinApps?&lt;/head&gt;
    &lt;p&gt;With WinApps you do the bulk of the setup manually, and there's no cohesive interface to bring it all together. There's a basic TUI, a taskbar widget, and some CLI commands for you to play with.&lt;lb/&gt; WinBoat does all the setup once you have the pre-requisites installed, displays everything worth seeing in a neat interface for you, and acts like a complete experience. No need to mess with configuration files, no need to memorize a dozen CLI commands, it just works.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;What are the advantages of using this over CrossOver or WINE?&lt;/head&gt;
    &lt;p&gt;You can run stuff that doesn't play well with CrossOver or WINE, and have a full Windows desktop at the same time.&lt;lb/&gt; We've had numerous apps that weren't working nicely (or at all) in Wine, this is one of the reasons we've created WinBoat. Some examples would be Affinity Photo, Paint Tool Sai v1.0, the entire Adobe suite, AeroChat, Acrobat, and of course Office.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will I be able to configure my peripherals / hardware using WinBoat?&lt;/head&gt;
    &lt;p&gt;If your peripheral / hardware uses USB to connect to your device. then yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature and you can use any Windows software needed for configuration, it should work out of the box.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there USB passthrough?&lt;/head&gt;
    &lt;p&gt; Yes! Starting from WinBoat 0.8.0 we support USB passthrough as an experimental feature. Please give it a try and let us know what you think! 😄&lt;lb/&gt; If for whatever reason you're stuck with an older version of WinBoat, you can modify the docker-compose.yml file in ~/.winboat once you finished setting up WinBoat. You can add the appropriate USB devices like this, followed by executing docker-compose down and docker-compose up -d in the same folder. Please make sure to remove these changes before you upgrade to &amp;gt;=0.8.0 though, as they are incompatible with our implementation.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Is there GPU passthrough?&lt;/head&gt;
    &lt;p&gt;Not at the moment, but we plan on eventually implementing GPU acceleration through paravirtualized drivers.&lt;lb/&gt; We have looked at MVisor Win VGPU Driver for OpenGL, which seems promising from our tests, but it's for a different hypervisor (not compatible with QEMU). Some other folks are also working on DirectX drivers but nothing that we can try out yet.&lt;lb/&gt; We have also looked into Looking Glass extensively, specifically their Indirect Display Driver which does not need a second GPU, because it'd be absolutely amazing to have it. We got the driver to compile and start via some hacks, but couldn't get much more than a black screen. The developer says it is not ready for general use yet at all, however we plan to integrate it once it is ready.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Does it run games with anti-cheat that don't run on Linux?&lt;/head&gt;
    &lt;p&gt;Unfortunately running games with kernel anti-cheat is not possible, as they block virtualization.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Any possibility of adding Podman support as a Docker alternative?&lt;/head&gt;
    &lt;p&gt;Podman support is planned. We tried working on it, some contributors also tried working on it, but there's some issues with networking (specifically the guest server being unreachable) that prevent it from being functional for now.&lt;/p&gt;
    &lt;head class="p-6 text-lg bg-gradient-to-b from-indigo-500/50 to-indigo-900/40 rounded-2xl select-none cursor-pointer" data-astro-cid-al2ca2vr=""&gt;Will you make it into a Flatpak?&lt;/head&gt;
    &lt;p&gt;This is on our to-do list, but it'll take some effort because Flatpak is pretty isolated from the rest of the system and apps, so we'd have to find a way to expose installed apps, the Docker binary, and the Docker socket, and many other utilities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.winboat.app/"/><published>2025-10-08T17:56:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45518861</id><title>Show HN: Open-source UI for running multiple coding agents</title><updated>2025-10-08T19:32:08.116609+00:00</updated><content>&lt;doc fingerprint="57844e5f478d9a2f"&gt;
  &lt;main&gt;
    &lt;p&gt;A desktop terminal application for running multiple CLI coding agents simultaneously, each in isolated git worktrees.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple Sessions: Run multiple coding agent sessions (Claude, Codex) in parallel&lt;/item&gt;
      &lt;item&gt;Git Worktree Isolation: Each session runs in its own git worktree, keeping work isolated&lt;/item&gt;
      &lt;item&gt;Persistent Sessions: Sessions persist across app restarts with automatic resumption&lt;/item&gt;
      &lt;item&gt;Terminal Theming: Choose from preset themes (macOS Light/Dark, Solarized Dark, Dracula, One Dark, GitHub Dark)&lt;/item&gt;
      &lt;item&gt;Setup Commands: Configure shell commands to run before the coding agent starts&lt;/item&gt;
      &lt;item&gt;MCP Server Management: Add and configure Model Context Protocol (MCP) servers&lt;/item&gt;
      &lt;item&gt;Session Management: Rename, close, and delete sessions with automatic worktree cleanup&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Node.js 16+&lt;/item&gt;
      &lt;item&gt;Git&lt;/item&gt;
      &lt;item&gt;Claude CLI (&lt;code&gt;npm install -g @anthropic-ai/claude-cli&lt;/code&gt;) or Codex&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;npm install&lt;/code&gt;
    &lt;code&gt;npm run dev&lt;/code&gt;
    &lt;code&gt;npm run build
npm start&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Select a project directory (must be a git repository)&lt;/item&gt;
      &lt;item&gt;Choose a parent branch for the worktree&lt;/item&gt;
      &lt;item&gt;Select your coding agent (Claude or Codex)&lt;/item&gt;
      &lt;item&gt;Optionally add setup commands (e.g., environment variables, source files)&lt;/item&gt;
      &lt;item&gt;FleetCode creates a new git worktree and spawns a terminal session&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;New Sessions: Use &lt;code&gt;--session-id &amp;lt;uuid&amp;gt;&lt;/code&gt;for first-time Claude sessions&lt;/item&gt;
      &lt;item&gt;Reopened Sessions: Automatically resume with &lt;code&gt;--resume &amp;lt;uuid&amp;gt;&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Worktrees: Each session gets its own isolated git worktree&lt;/item&gt;
      &lt;item&gt;Persistence: Sessions are saved and can be reopened after closing the app&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Access settings via the gear icon (⚙️) in the sidebar:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Font Family: Choose from common monospace fonts&lt;/item&gt;
      &lt;item&gt;Font Size: Adjust terminal text size&lt;/item&gt;
      &lt;item&gt;Theme: Select from preset color themes&lt;/item&gt;
      &lt;item&gt;Cursor Blink: Toggle cursor blinking&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Configure Model Context Protocol servers for enhanced agent capabilities:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;stdio: Direct process communication&lt;/item&gt;
      &lt;item&gt;SSE: Server-sent events via HTTP&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you encounter a quarantine warning when trying to open the app on macOS, run:&lt;/p&gt;
    &lt;code&gt;xattr -cr /path/to/FleetCode.app&lt;/code&gt;
    &lt;p&gt;This removes the quarantine attribute that prevents the app from opening.&lt;/p&gt;
    &lt;p&gt;If you're using Claude Code and it's reading/writing files from the wrong directory instead of the worktree, disable "Auto connect to IDE" in your Claude Code settings:&lt;/p&gt;
    &lt;code&gt;claude config&lt;/code&gt;
    &lt;p&gt;Set &lt;code&gt;autoConnectToIde&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;. This ensures Claude Code operates within the correct worktree directory.&lt;/p&gt;
    &lt;p&gt;ISC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/built-by-as/FleetCode"/><published>2025-10-08T18:00:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45519263</id><title>Julia 1.12 Highlights</title><updated>2025-10-08T19:32:07.817021+00:00</updated><content>&lt;doc fingerprint="3cdcaa530be1dbe8"&gt;
  &lt;main&gt;&lt;p&gt;Julia version 1.12 has finally been released. We want to thank all the contributors to this release and all the testers who helped find regressions and issues in the pre-releases. Without you, this release would not have been possible.&lt;/p&gt;&lt;p&gt;The full list of changes can be found in the NEWS file, but here we'll give a more in-depth overview of some of the release highlights.&lt;/p&gt;&lt;code&gt;--trim&lt;/code&gt; feature&lt;code&gt;@atomic&lt;/code&gt; macro family now supports reference assignment syntax&lt;code&gt;--trim&lt;/code&gt; feature&lt;p&gt;Jeff Bezanson, Cody Tapscott, Gabriel Baraldi&lt;/p&gt;&lt;p&gt;&lt;code&gt;julia&lt;/code&gt; now has a new experimental&lt;code&gt;--trim&lt;/code&gt; feature, when compiling a system image with this mode julia will trim statically unreachable code leading to significantly better compile times and binary sizes. To use it you also need to pass the &lt;code&gt;--experimental&lt;/code&gt; flag when building the system image. &lt;/p&gt;&lt;p&gt;In order to use it, any code that is reachable from the entrypoints must not have any dynamic dispatches otherwise the trimming will be unsafe and it will error during compilation.&lt;/p&gt;&lt;p&gt;The expected way of using it is via the &lt;code&gt;JuliaC.jl&lt;/code&gt; package, which provides a CLI and a programmatic API. &lt;/p&gt;&lt;p&gt;For example a simple package with an &lt;code&gt;@main&lt;/code&gt; function:&lt;/p&gt;&lt;code&gt;module AppProject

function @main(ARGS)
    println(Core.stdout, "Hello World!")
    return 0
end

end&lt;/code&gt;
&lt;code&gt;juliac --output-exe app_test_exe --bundle build --trim=safe --experimental ./AppProject&lt;/code&gt;
&lt;code&gt;./build/bin/app_test_exe
Hello World!

ls -lh build/bin/app_test_exe
-rwxr-xr-x@ 1 gabrielbaraldi  staff   1.1M Oct  6 17:22 ./build/bin/app_test_exe*&lt;/code&gt;
&lt;p&gt;Keno Fischer, Tim Holy&lt;/p&gt;&lt;p&gt;Bindings now participate in the "world age" mechanism previously used for methods. This has the effect that constants and structs can be properly redefined. As an example:&lt;/p&gt;&lt;code&gt;# Define a struct and a method on that struct:
julia&amp;gt; struct Foo
          a::Int
       end

julia&amp;gt; g(f::Foo) = f.a^2
g (generic function with 1 method)

julia&amp;gt; g(Foo(2))
4

# Redefine the struct (julia pre-1.12 would error here)
julia&amp;gt; struct Foo
          a::Int
          b::Int
       end

# Note that functions need to be redefined to work on the new `Foo`
julia&amp;gt; g(Foo(1,2))
ERROR: MethodError: no method matching g(::Foo)
The function `g` exists, but no method is defined for this combination of argument types.

Closest candidates are:
  g(::@world(Foo, 39296:39300)) # &amp;lt;- This is syntax for accessing the binding in an older "world"
   @ Main REPL[2]:1

julia&amp;gt; g(f::Foo) = f.a^2 + f.b^2
g (generic function with 2 methods)

julia&amp;gt; g(Foo(2,3))
13&lt;/code&gt;
&lt;p&gt;There is also work in progress in Revise.jl to automatically redefine functions on replaced bindings. This should significantly reduce the number of times you have to restart Julia while iterating on some piece of code.&lt;/p&gt;&lt;p&gt;Ian Butterworth, Nathan Daly&lt;/p&gt;&lt;p&gt;&lt;code&gt;--trace-compile-timing&lt;/code&gt; is a new command-line flag that augments &lt;code&gt;--trace-compile&lt;/code&gt; by printing how long each compiled method took (in milliseconds) before the corresponding &lt;code&gt;precompile(...)&lt;/code&gt; line. This makes it easier to spot costly compilations.&lt;/p&gt;&lt;p&gt;In addition, two macros for ad-hoc tracing without restarting Julia have been added:&lt;/p&gt;&lt;p&gt;&lt;code&gt;@trace_compile expr&lt;/code&gt; runs &lt;code&gt;expr&lt;/code&gt; with &lt;code&gt;--trace-compile=stderr --trace-compile-timing&lt;/code&gt; enabled, emitting timed &lt;code&gt;precompile(...)&lt;/code&gt; entries only for that call.&lt;/p&gt;&lt;p&gt;&lt;code&gt;@trace_dispatch expr&lt;/code&gt; runs &lt;code&gt;expr&lt;/code&gt; with &lt;code&gt;--trace-dispatch=stderr&lt;/code&gt; enabled, reporting methods that are dynamically dispatched.&lt;/p&gt;&lt;p&gt;Examples&lt;/p&gt;&lt;code&gt;julia&amp;gt; @trace_compile @eval rand(2,2) * rand(2,2)
#=   79.9 ms =# precompile(Tuple{typeof(Base.rand), Int64, Int64})
#=    4.4 ms =# precompile(Tuple{typeof(Base.:(*)), Array{Float64, 2}, Array{Float64, 2}})
2×2 Matrix{Float64}:
 0.302276  0.14341
 0.738941  0.396414

julia&amp;gt; f(x) = x

julia&amp;gt; @trace_dispatch map(f, Any[1,2,3])
precompile(Tuple{Type{Array{Int64, 1}}, UndefInitializer, Tuple{Int64}})
precompile(Tuple{typeof(Base.collect_to_with_first!), Array{Int64, 1}, Int64, Base.Generator{Array{Any, 1}, typeof(Main.f)}, Int64})
3-element Vector{Int64}:
 1
 2
 3&lt;/code&gt;
&lt;p&gt;Gabriel Baraldi, Ian Butterworth&lt;/p&gt;&lt;p&gt;Julia now starts with one interactive thread by default (in addition to the default thread). This means that by default Julia runs with the threading configuration of 1 default thread, 1 interactive thread.&lt;/p&gt;&lt;p&gt;The interactive thread pool is where the REPL and other interactive operations run. By separating these from the default thread pool (where &lt;code&gt;@spawn&lt;/code&gt; and &lt;code&gt;@threads&lt;/code&gt; schedule work when no threadpool is specified), the REPL can perform operations like autocomplete queries in parallel with user code execution, leading to a more responsive interactive experience.&lt;/p&gt;&lt;p&gt;Key behaviors:&lt;/p&gt;&lt;p&gt;Default: Julia starts with &lt;code&gt;-t1,1&lt;/code&gt; (1 default + 1 interactive thread)&lt;/p&gt;&lt;p&gt;Explicit &lt;code&gt;-t1&lt;/code&gt;: If you explicitly request 1 thread with &lt;code&gt;-t1&lt;/code&gt;, Julia will give you exactly that—no additional interactive thread will be added (resulting in &lt;code&gt;-t1,0&lt;/code&gt;)&lt;/p&gt;&lt;p&gt;Multiple threads: &lt;code&gt;-t2&lt;/code&gt; or &lt;code&gt;-tauto&lt;/code&gt; will give you the requested default threads plus 1 interactive thread&lt;/p&gt;&lt;p&gt;Manual control: You can always specify both pools explicitly, e.g., &lt;code&gt;-t4,2&lt;/code&gt; for 4 default and 2 interactive threads&lt;/p&gt;&lt;p&gt;This change improves the out-of-the-box experience while maintaining backwards compatibility for users who explicitly request single-threaded execution.&lt;/p&gt;&lt;p&gt;Mosè Giordano&lt;/p&gt;&lt;p&gt;Julia now respects CPU affinity settings, such as those set via &lt;code&gt;cpuset&lt;/code&gt;/&lt;code&gt;taskset&lt;/code&gt;/&lt;code&gt;cgroups&lt;/code&gt;, etc. The same also applies to the default number of BLAS threads, which now follows the same logic. This can also be observed when running Julia inside Docker. Currently, you have&lt;/p&gt;&lt;code&gt;$ docker run --cpus=4 --rm -ti julia:1.11 julia --threads=auto -e '@show Threads.nthreads(); using LinearAlgebra; @show BLAS.get_num_threads()'
Threads.nthreads() = 22
BLAS.get_num_threads() = 11&lt;/code&gt;
&lt;p&gt;When starting Julia with &lt;code&gt;--threads=auto&lt;/code&gt;, &lt;code&gt;Threads.nthreads()&lt;/code&gt; is equal to the total number of CPUs on the system instead of the only 4 CPUs reserved by Docker. Likewise, the number of BLAS threads, which can be obtained with &lt;code&gt;BLAS.get_num_threads()&lt;/code&gt; and on x86-64 systems is by default half the number of available cores, is 11 instead of 2. With Julia v1.12 this is fixed, and the number of both Julia and BLAS threads will respect the number of CPUs reserved by Docker:&lt;/p&gt;&lt;code&gt;% docker run --cpus=4 --rm -ti julia:1.12 julia --threads=auto -e '@show Threads.nthreads(); using LinearAlgebra; @show BLAS.get_num_threads()'
Threads.nthreads() = 4
BLAS.get_num_threads() = 2&lt;/code&gt;
&lt;p&gt;The new behavior is also important to avoid oversubscription out-of-the-box when running Julia on HPC systems where schedulers set CPU affinity when using shared resources.&lt;/p&gt;&lt;code&gt;OncePerX&lt;/code&gt;&lt;p&gt;Jameson Nash&lt;/p&gt;&lt;p&gt;Certain initialization patterns need to run only once, depending on scope: per process, per thread, or per task. To make this easier and safer, Julia now provides three built-in types:&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerProcess{T}&lt;/code&gt;: runs an initializer exactly once per process, returning the same value for all future calls.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerThread{T}&lt;/code&gt;: runs an initializer once for each thread ID. Subsequent calls on the same thread return the same value.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerTask{T}&lt;/code&gt;: runs an initializer once per task, reusing the same value within that task.&lt;/p&gt;&lt;p&gt;These replace common hand-rolled solutions such as using &lt;code&gt;__init__&lt;/code&gt;, &lt;code&gt;nthreads()&lt;/code&gt;, or &lt;code&gt;task_local_storage()&lt;/code&gt; directly.&lt;/p&gt;&lt;p&gt;A simple example of &lt;code&gt;OncePerProcess&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;julia&amp;gt; const global_state = Base.OncePerProcess{Vector{UInt32}}() do
           println("Making lazy global value...done.")
           return [Libc.rand()]
       end;

julia&amp;gt; a = global_state();
Making lazy global value...done.

julia&amp;gt; a === global_state()
true&lt;/code&gt;
&lt;p&gt;Use cases:&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerProcess&lt;/code&gt;: caches, global constants, or initialization that should happen once per Julia process (even across precompilation).&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerThread&lt;/code&gt;: per-thread state needed for interoperability with C libraries or specialized threading models.&lt;/p&gt;&lt;p&gt;&lt;code&gt;OncePerTask&lt;/code&gt;: lightweight task-local state without manually managing &lt;code&gt;task_local_storage&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;These types provide a safer, composable way to express “initialize once” semantics in concurrent Julia code.&lt;/p&gt;&lt;p&gt;Zentrik&lt;/p&gt;&lt;p&gt;BOLT is a post-link optimizer from LLVM that improves runtime performance by reordering functions and basic blocks, splitting hot and cold code, and folding identical functions. Julia now supports building BOLT-optimized versions of libLLVM, libjulia-internal, and libjulia-codegen.&lt;/p&gt;&lt;p&gt;These optimizations reduce compilation and execution time in common workloads. For example, the all-inference benchmarks improve by about 10%, an LLVM-heavy workload shows a similar ~10% gain, and building &lt;code&gt;corecompiler.ji&lt;/code&gt; improves by 13–16% with BOLT. When combined with PGO and LTO, total improvements of up to ~23% have been observed.&lt;/p&gt;&lt;p&gt;To build a BOLT-optimized Julia, run the following commands from &lt;code&gt;contrib/bolt/&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;make stage1
make copy_originals
make bolt_instrument
make finish_stage1
make merge_data
make bolt&lt;/code&gt;
&lt;p&gt;The optimized binaries will be available in the &lt;code&gt;optimized.build&lt;/code&gt; directory. An analogous workflow exists in &lt;code&gt;contrib/pgo-lto-bolt/&lt;/code&gt; for combining BOLT with PGO+LTO.&lt;/p&gt;&lt;p&gt;BOLT currently works only on Linux x86_64 and aarch64, and the resulting &lt;code&gt;.so&lt;/code&gt; files must not be stripped. Some &lt;code&gt;readelf&lt;/code&gt; warnings may appear during testing but are considered harmless.&lt;/p&gt;&lt;code&gt;@atomic&lt;/code&gt; macro family now supports reference assignment syntax&lt;p&gt;Marek Kaluba&lt;/p&gt;&lt;p&gt;The &lt;code&gt;@atomic&lt;/code&gt; macro family now supports indexing (e.g. &lt;code&gt;m[i]&lt;/code&gt;, &lt;code&gt;m[i,j]&lt;/code&gt;) in addition to field access. This makes it possible to perform atomic fetch, set, modify, swap, compare-and-swap, and set-once directly on array-like references. The macros expand to new APIs: &lt;code&gt;getindex_atomic&lt;/code&gt;, &lt;code&gt;setindex_atomic!&lt;/code&gt;, &lt;code&gt;modifyindex_atomic!&lt;/code&gt;, &lt;code&gt;swapindex_atomic!&lt;/code&gt;, &lt;code&gt;replaceindex_atomic!&lt;/code&gt;, and &lt;code&gt;setindexonce_atomic!&lt;/code&gt;. Vararg and &lt;code&gt;CartesianIndex&lt;/code&gt; indexing are supported.&lt;/p&gt;&lt;p&gt;For example:&lt;/p&gt;&lt;code&gt;mem = AtomicMemory{Int}(undef, 2)

@atomic mem[1] = 2                 # atomic set
x = @atomic mem[1]                 # atomic fetch
@atomic :monotonic mem[1] += 1     # atomic modify with order
old = @atomicswap mem[1] = 4       # atomic swap (returns old)
res = @atomicreplace mem[1] 4 =&amp;gt; 10  # (old=4, success=true)
ok  = @atomiconce mem[2] = 7         # set once (Bool)&lt;/code&gt;
&lt;p&gt;Two new per-task metrics can be enabled by starting Julia with &lt;code&gt;--task-metrics=yes&lt;/code&gt; or by calling &lt;code&gt;Base.Experimental.task_metrics(true)&lt;/code&gt;. Enabling or disabling task metrics with &lt;code&gt;Base.Experimental.task_metrics&lt;/code&gt; only affects new tasks, not existing ones. The metrics are:&lt;/p&gt;&lt;p&gt;&lt;code&gt;Base.Experimental.task_running_time_ns(t::Task)&lt;/code&gt;: the time for which &lt;code&gt;t&lt;/code&gt; was actually running. This is currently inclusive of GC time, compilation time, and any spin time.&lt;/p&gt;&lt;p&gt;&lt;code&gt;Base.Experimental.task_wall_time_ns(t::Task)&lt;/code&gt;: the time from the scheduler becoming aware of &lt;code&gt;t&lt;/code&gt; until &lt;code&gt;t&lt;/code&gt; is complete.&lt;/p&gt;&lt;p&gt;Kristoffer Carlsson&lt;/p&gt;&lt;p&gt;A workspace is a set of project files that all share the same manifest. Each project in a workspace can include its own dependencies, compatibility information, and even function as a full package.&lt;/p&gt;&lt;p&gt;When the package manager resolves dependencies, it considers the requirements and compatibility of all the projects in the workspace. The compatible versions identified during this process are recorded in a single manifest file.&lt;/p&gt;&lt;p&gt;A workspace is defined in the base project by giving a list of the projects in it:&lt;/p&gt;&lt;code&gt;[workspace]
projects = ["test", "docs", "benchmarks", "PrivatePackage"]&lt;/code&gt;
&lt;p&gt;This structure is particularly beneficial for developers using a monorepo approach, where a large number of unregistered packages may be involved. It is also useful for adding documentation or benchmarks to a package by including additional dependencies beyond those of the package itself. Test-specific dependencies are now recommended to be specified using the workspace approach (a project file in the &lt;code&gt;test&lt;/code&gt; directory that is part of the workspace defined by the package project file).&lt;/p&gt;&lt;p&gt;Workspaces can also be nested: a project that itself defines a workspace can also be part of another workspace. In this case, the workspaces are “merged,” with a single manifest being stored alongside the “root project” (the project that is not included in another workspace).&lt;/p&gt;&lt;p&gt;An app is a Julia package that can be run directly from the terminal, similar to a standalone program. Each app provides an entry point via &lt;code&gt;@main&lt;/code&gt; and can define its own default Julia flags and executable name.&lt;/p&gt;&lt;p&gt;When an app is installed, it gets put into &lt;code&gt;.julia/bin&lt;/code&gt; and by adding that to your &lt;code&gt;PATH&lt;/code&gt; it allows you to launch it by name together with any arguments or options.&lt;/p&gt;&lt;p&gt;A Julia app is defined in the &lt;code&gt;Project.toml&lt;/code&gt; file using an &lt;code&gt;[apps]&lt;/code&gt; section:&lt;/p&gt;&lt;code&gt;[apps]
reverse = {} # empty dictionary is for additional metadata&lt;/code&gt;
&lt;p&gt;with a corresponding entry point in the package module:&lt;/p&gt;&lt;code&gt;# src/MyReverseApp.jl
module MyReverseApp

function (@main)(ARGS)
    for arg in ARGS
        print(stdout, reverse(arg), " ")
    end
end

end # module&lt;/code&gt;
&lt;p&gt;After installation, the app can be run directly in the terminal:&lt;/p&gt;&lt;code&gt;$ reverse some input string
emos tupni gnirts&lt;/code&gt;
&lt;p&gt;This makes apps useful for building CLI tools or packaging Julia functionality as user-facing executables. Multiple apps can be defined per package by using submodules, and each app can specify default Julia flags (e.g. &lt;code&gt;--threads=4&lt;/code&gt;) for performance or debugging.&lt;/p&gt;&lt;p&gt;See the full documentation for more information: https://pkgdocs.julialang.org/dev/apps/&lt;/p&gt;&lt;p&gt;&lt;code&gt;Pkg.status()&lt;/code&gt; now highlights when a dependency's loaded version differs from what the current environment would load. This helps identify situations where you may be running code against an outdated or mismatched version of a package—particularly useful when switching between environments or after modifying dependencies.&lt;/p&gt;&lt;p&gt;When a package is already loaded from a different version or path than what the current environment specifies, Pkg will display a yellow &lt;code&gt;[loaded: vX.Y.Z]&lt;/code&gt; indicator next to the package name:&lt;/p&gt;&lt;p&gt;This visual cue makes it easier to spot when you need to restart Julia to pick up the correct package versions, reducing debugging time and confusion in iterative development workflows.&lt;/p&gt;&lt;p&gt;Tim Besard&lt;/p&gt;&lt;p&gt;&lt;code&gt;Ptr{T}&lt;/code&gt; now lowers to actual LLVM pointer types in generated IR (i.e. &lt;code&gt;ptr&lt;/code&gt; with opaque pointers, or &lt;code&gt;i8*&lt;/code&gt;), instead of integers like &lt;code&gt;i64&lt;/code&gt;. This simplifies low-level interop: &lt;code&gt;llvmcall&lt;/code&gt; no longer needs &lt;code&gt;ptrtoint&lt;/code&gt;/&lt;code&gt;inttoptr&lt;/code&gt; shims, and many intrinsics can be called via &lt;code&gt;ccall&lt;/code&gt; using &lt;code&gt;Ptr&lt;/code&gt; directly.&lt;/p&gt;&lt;p&gt;What changes for you&lt;/p&gt;&lt;p&gt;Inline LLVM (&lt;code&gt;llvmcall&lt;/code&gt;): update IR to use &lt;code&gt;ptr&lt;/code&gt;/&lt;code&gt;i8*&lt;/code&gt; for pointer arguments/returns, and remove redundant &lt;code&gt;ptrtoint&lt;/code&gt;/&lt;code&gt;inttoptr&lt;/code&gt; casts. Old IR that treats pointers as integers is still accepted but emits a deprecation warning.&lt;/p&gt;&lt;p&gt;Pointer arithmetic: &lt;code&gt;add_ptr&lt;/code&gt; / &lt;code&gt;sub_ptr&lt;/code&gt; now operate on real pointers: &lt;code&gt;add_ptr(::Ptr{T}, ::UInt)&lt;/code&gt; and &lt;code&gt;sub_ptr(::Ptr{T}, ::UInt)&lt;/code&gt; (lowered to GEP).&lt;/p&gt;&lt;p&gt;&lt;code&gt;ccall&lt;/code&gt; convenience: passing/returning &lt;code&gt;Ptr{T}&lt;/code&gt; maps to LLVM pointer types directly, enabling more intrinsic calls without custom &lt;code&gt;llvmcall&lt;/code&gt; glue.&lt;/p&gt;&lt;p&gt;Example (before → after)&lt;/p&gt;&lt;code&gt;; BEFORE (deprecated): integer pointer
define i64 @f(i64 %p) {
  %q = inttoptr i64 %p to i8*
  ; ...
  %r = ptrtoint i8* %q to i64
  ret i64 %r
}

; AFTER: real pointer
define ptr @f(ptr %p) {
  ; ...
  ret ptr %p
}&lt;/code&gt;
&lt;p&gt;This change also unlocks minor optimization opportunities in generated code since pointers no longer bounce through integer casts.&lt;/p&gt;&lt;p&gt;Mosè Giordano&lt;/p&gt;&lt;p&gt;Many developers may have experience with occasional failures when running tests of their packages which were observed only on remote machines, and wished to be able to reproduce the same run, for debugging purposes. The GitHub Actions workflow &lt;code&gt;julia-actions/julia-runtest&lt;/code&gt; recently started printing to the log the full options used to invoke the Julia process which runs the tests, which lets developers use the same compiler options (e.g. bounds checking, code coverage, deprecation warnings, etc.) as the CI runs. However there are occasional failures which don't depend on compiler options, but may depend on the state of the global random number generator (RNG), if for example the input data of the tests is generated with functions like &lt;code&gt;rand&lt;/code&gt; and &lt;code&gt;randn&lt;/code&gt;, without passing an explicit RNG object, instead relying on the global one. The &lt;code&gt;Test.@testset&lt;/code&gt; macro has had for a long time the feature of automatically controlling the global RNG, but until now its state was never displayed. Starting from Julia v1.12, a failure inside a &lt;code&gt;@testset&lt;/code&gt; causes the RNG of the outermost test set to be printed to screen, which then you can also set in a new test set to exactly reproduce the same run.&lt;/p&gt;&lt;p&gt;As an example, consider the following test which would fail with a 0.1% probability:&lt;/p&gt;&lt;code&gt;julia&amp;gt; using Test

julia&amp;gt; @testset begin
           @test rand() &amp;gt; 0.001
       end;
test set: Test Failed at REPL[2]:2
  Expression: rand() &amp;gt; 0.001
   Evaluated: 0.00036328334842516963 &amp;gt; 0.001

Stacktrace:
 [1] top-level scope
   @ REPL[2]:2
 [2] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:1776 [inlined]
 [3] macro expansion
   @ REPL[2]:2 [inlined]
 [4] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:680 [inlined]
Test Summary: | Fail  Total  Time
test set      |    1      1  1.5s
RNG of the outermost testset: Random.Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7)
ERROR: Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.&lt;/code&gt;
&lt;p&gt;Normally, it'd require several attempts to reproduce a similar failure, but now the RNG is printed to screen and you can reproduce the run in a new session by setting the &lt;code&gt;rng&lt;/code&gt; option of &lt;code&gt;@testset&lt;/code&gt; to the value printed in the failed test:&lt;/p&gt;&lt;code&gt;julia&amp;gt; using Test, Random

julia&amp;gt; @testset rng=Random.Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7) begin
           @test rand() &amp;gt; 0.001
       end;
test set: Test Failed at REPL[2]:2
  Expression: rand() &amp;gt; 0.001
   Evaluated: 0.00036328334842516963 &amp;gt; 0.001

Stacktrace:
 [1] top-level scope
   @ REPL[2]:2
 [2] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:1776 [inlined]
 [3] macro expansion
   @ REPL[2]:2 [inlined]
 [4] macro expansion
   @ ~/.julia/juliaup/julia-1.12.0.x64.linux.gnu/share/julia/stdlib/v1.12/Test/src/Test.jl:680 [inlined]
Test Summary: | Fail  Total  Time
test set      |    1      1  1.4s
RNG of the outermost testset: Xoshiro(0xd02e9404e1026b37, 0xca5ae9c15acf6752, 0x976a327d42433534, 0xb5b1305af1734f3a, 0x1c2aa037d6e7d5c7)
ERROR: Some tests did not pass: 0 passed, 1 failed, 0 errored, 0 broken.&lt;/code&gt;
&lt;p&gt;While there are still many other classes of intermittent failures that aren't captured by the global RNG, being able to reproduce its state inside failing test sets should help debugging more issues during package development.&lt;/p&gt;&lt;p&gt;The preparation of this release was partially funded by NASA under award 80NSSC22K1740. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Aeronautics and Space Administration.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://julialang.org/blog/2025/10/julia-1.12-highlights/"/><published>2025-10-08T18:42:22+00:00</published></entry></feed>