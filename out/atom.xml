<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-17T08:43:39.798770+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45602428</id><title>Elixir 1.19</title><updated>2025-10-17T08:43:52.283804+00:00</updated><content>&lt;doc fingerprint="3a60ba942a313394"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Elixir v1.19 released: enhanced type checking, broader type inference, and up to 4x faster compilation for large projects&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 brings further improvements to the type system and compilation times, allowing us to find more bugs, faster.&lt;/p&gt;
    &lt;head rend="h2"&gt;Type system improvements&lt;/head&gt;
    &lt;p&gt;This release improves the type system around two key areas: type inference and type checking of anonymous functions and protocols. These enhancements seem simple on the surface but required us to go beyond existing literature by extending current theory and developing new techniques. We will outline the technical details in future articles. For now, let’s look at what’s new.&lt;/p&gt;
    &lt;head rend="h3"&gt;Type inference of all constructs&lt;/head&gt;
    &lt;p&gt;Type inference (or reconstruction) is the ability of a type system to automatically deduce, either partially or fully, the type of an expression at compile time. Type inference may occur at different levels. For example, many programming languages can automatically infer the types of variables, also known “local type inference”, but not all can infer type signatures of functions.&lt;/p&gt;
    &lt;p&gt;Originally, our plan with Elixir’s upcoming type system was to support type inference of patterns, guards, and return types. Therefore, if you wrote this simple function:&lt;/p&gt;
    &lt;code&gt;def even?(x) when is_integer(x) do
  rem(x, 2) == 0
end
&lt;/code&gt;
    &lt;p&gt;Elixir would correctly infer the type to be &lt;code&gt;integer() -&amp;gt; boolean()&lt;/code&gt;. However, if you wrote this function:&lt;/p&gt;
    &lt;code&gt;def even?(x) do
  rem(x, 2) == 0
end
&lt;/code&gt;
    &lt;p&gt;The type would be &lt;code&gt;dynamic() -&amp;gt; boolean()&lt;/code&gt;, since there are no guards, even though the functions behave virtually the same, as the &lt;code&gt;rem&lt;/code&gt; operator expects both arguments to be integer (they just raise different exceptions for non-integer values).&lt;/p&gt;
    &lt;p&gt;Inferring type signatures comes with a series of trade-offs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Speed - type inference algorithms are often more computationally intensive than type checking algorithms.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Expressiveness - in any given type system, the constructs that support inference are always a subset of those that can be type-checked. Therefore, if a programming language is restricted to only fully reconstructed types, it is less expressive than a solely type checked counterpart.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Incremental compilation - type inference complicates incremental compilation. If module A depends on module B, which depends on module C, a change to C may require the type signature in B to be reconstructed, which may then require A to be recomputed (and so on). This dependency chain may require large projects to explicitly add type signatures for stability and compilation efficiency.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Cascading errors - when a user accidentally makes type errors or the code has conflicting assumptions, type inference may lead to less clear error messages as the type system tries to reconcile diverging type assumptions across code paths.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;On the other hand, type inference offers the benefit of enabling type checking for functions and codebases without requiring the user to add type annotations. To balance these trade-offs, we are exploring “module type inference”: our goal is to infer type signatures considering invocations of functions in the same module and of functions from other applications (such as Elixir itself and your dependencies). Once module types are inferred, your whole project is type checked considering all declared and inferred types.&lt;/p&gt;
    &lt;p&gt;We have successfully implemented these features as part of Elixir v1.19, by performing inference of all constructs (except guards), taking into account the signatures from calls to functions within the same module and in Elixir’s standard library. This means the second function above, without the guard, will also infer the type &lt;code&gt;integer() -&amp;gt; boolean()&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In future releases, we plan to perform type inference of guards (originally planned for v1.19) and also consider the type signatures of your dependencies during inference. Overall, these changes allow us to assess the impact of the trade-offs above as the type system evolves, which suits well our current goals of incrementally using types to find bugs in existing codebases, without changing them.&lt;/p&gt;
    &lt;p&gt;Keep in mind this only applies to type inference. Once we introduce type signatures and you explicitly annotate your functions, type inference and the trade-offs above no longer play a role. Any function with an explicit type signature will be typed checked against the user-provided annotations, as in other statically typed languages.&lt;/p&gt;
    &lt;head rend="h3"&gt;Type checking of protocol dispatch and implementations&lt;/head&gt;
    &lt;p&gt;This release adds type checking when dispatching and implementing protocols.&lt;/p&gt;
    &lt;p&gt;For example, string interpolation in Elixir uses the &lt;code&gt;String.Chars&lt;/code&gt; protocol. If you pass a value that does not implement said protocol, Elixir will now emit a warning accordingly.&lt;/p&gt;
    &lt;p&gt;Here is an example passing a range, which cannot be converted into a string, to an interpolation:&lt;/p&gt;
    &lt;code&gt;defmodule Example do
  def my_code(first..last//step = range) do
    "hello #{range}"
  end
end
&lt;/code&gt;
    &lt;p&gt;the above emits the following warnings:&lt;/p&gt;
    &lt;code&gt;warning: incompatible value given to string interpolation:

    data

it has type:

    %Range{first: term(), last: term(), step: term()}

but expected a type that implements the String.Chars protocol, it must be one of:

    dynamic(
      %Date{} or %DateTime{} or %NaiveDateTime{} or %Time{} or %URI{} or %Version{} or
        %Version.Requirement{}
    ) or atom() or binary() or float() or integer() or list(term())
&lt;/code&gt;
    &lt;p&gt;Warnings are also emitted if you pass a data type that does not implement the &lt;code&gt;Enumerable&lt;/code&gt; protocol as a generator to for-comprehensions:&lt;/p&gt;
    &lt;code&gt;defmodule Example do
  def my_code(%Date{} = date) do
    for(x &amp;lt;- date, do: x)
  end
end
&lt;/code&gt;
    &lt;p&gt;will emit:&lt;/p&gt;
    &lt;code&gt;warning: incompatible value given to for-comprehension:

    x &amp;lt;- date

it has type:

    %Date{year: term(), month: term(), day: term(), calendar: term()}

but expected a type that implements the Enumerable protocol, it must be one of:

    dynamic(
      %Date.Range{} or %File.Stream{} or %GenEvent.Stream{} or %HashDict{} or %HashSet{} or
        %IO.Stream{} or %MapSet{} or %Range{} or %Stream{}
    ) or fun() or list(term()) or non_struct_map()
&lt;/code&gt;
    &lt;head rend="h3"&gt;Type checking and inference of anonymous functions&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 can now type infer and type check anonymous functions. Here is a trivial example:&lt;/p&gt;
    &lt;code&gt;defmodule Example do
  def run do
    fun = fn %{} -&amp;gt; :map end
    fun.("hello")
  end
end
&lt;/code&gt;
    &lt;p&gt;The example above has an obvious typing violation, as the anonymous function expects a map but a string is given. With Elixir v1.19, the following warning is now printed:&lt;/p&gt;
    &lt;code&gt;    warning: incompatible types given on function application:

        fun.("hello")

    given types:

        binary()

    but function has type:

        (dynamic(map()) -&amp;gt; :map)

    typing violation found at:
    │
  6 │     fun.("hello")
    │        ~
    │
    └─ mod.exs:6:8: Example.run/0
&lt;/code&gt;
    &lt;p&gt;Function captures, such as &lt;code&gt;&amp;amp;String.to_integer/1&lt;/code&gt;, will also propagate the type as of Elixir v1.19, arising more opportunity for Elixir’s type system to catch bugs in our programs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;The type system was made possible thanks to a partnership between CNRS and Remote. The development work is currently sponsored by Fresha, Starfish*, and Dashbit.&lt;/p&gt;
    &lt;head rend="h2"&gt;Faster compile times in large projects&lt;/head&gt;
    &lt;p&gt;This release includes two compiler improvements that can lead up to 4x faster builds in large codebases.&lt;/p&gt;
    &lt;p&gt;While Elixir has always compiled the given files in project or a dependency in parallel, the compiler would sometimes be unable to use all of the machine resources efficiently. This release addresses two common limitations, delivering performance improvements that scale with codebase size and available CPU cores.&lt;/p&gt;
    &lt;head rend="h3"&gt;Code loading bottlenecks&lt;/head&gt;
    &lt;p&gt;Prior to this release, Elixir would load modules as soon as they were defined. However, because the Erlang part of code loading happens within a single process (the code server), this would make it a bottleneck, reducing parallelization, especially on large projects.&lt;/p&gt;
    &lt;p&gt;This release makes it so modules are loaded lazily. This reduces the pressure on the code server and the amount of work during compilation, with reports of more than two times faster compilation for large projects. The benefits depend on the codebase size and the number of CPU cores available.&lt;/p&gt;
    &lt;p&gt;Implementation wise, the parallel compiler already acts as a mechanism to resolve modules during compilation, so we built on that. By making sure the compiler controls both module compilation and module loading, it can also better guarantee deterministic builds.&lt;/p&gt;
    &lt;p&gt;There are two potential regressions with this approach. The first one happens if you spawn processes during compilation which invoke other modules defined within the same project. For example:&lt;/p&gt;
    &lt;code&gt;defmodule MyLib.SomeModule do
  list = [...]

  Task.async_stream(list, fn item -&amp;gt;
    MyLib.SomeOtherModule.do_something(item)
  end)
end
&lt;/code&gt;
    &lt;p&gt;Because the spawned process is not visible to the compiler, it won’t be able to load &lt;code&gt;MyLib.SomeOtherModule&lt;/code&gt;. You have two options, either use &lt;code&gt;Kernel.ParallelCompiler.pmap/2&lt;/code&gt; or explicitly call &lt;code&gt;Code.ensure_compiled!(MyLib.SomeOtherModule)&lt;/code&gt; before spawning the process that uses said module.&lt;/p&gt;
    &lt;p&gt;The second one is related to &lt;code&gt;@on_load&lt;/code&gt; callbacks (typically used for NIFs) that invoke other modules defined within the same project. For example:&lt;/p&gt;
    &lt;code&gt;defmodule MyLib.SomeModule do
  @on_load :init

  def init do
    MyLib.AnotherModule.do_something()
  end

  def something_else do
    ...
  end
end

MyLib.SomeModule.something_else()
&lt;/code&gt;
    &lt;p&gt;The reason this fails is because &lt;code&gt;@on_load&lt;/code&gt; callbacks are invoked within the code server and therefore they have limited ability to load additional modules. It is generally advisable to limit invocation of external modules during &lt;code&gt;@on_load&lt;/code&gt; callbacks but, in case it is strictly necessary, you can set &lt;code&gt;@compile {:autoload, true}&lt;/code&gt; in the invoked module to address this issue in a forward and backwards compatible manner.&lt;/p&gt;
    &lt;p&gt;Both snippets above could actually lead to non-deterministic compilation failures in the past, and as a result of these changes, compiling these cases are now deterministic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Parallel compilation of dependencies&lt;/head&gt;
    &lt;p&gt;This release introduces a variable called &lt;code&gt;MIX_OS_DEPS_COMPILE_PARTITION_COUNT&lt;/code&gt;, which instructs &lt;code&gt;mix deps.compile&lt;/code&gt; to compile dependencies in parallel.&lt;/p&gt;
    &lt;p&gt;While fetching dependencies and compiling individual Elixir dependencies already happened in parallel, as outlined in the previous section, there were pathological cases where performance gains would be left on the table, such as when compiling dependencies with native code or dependencies where one or two large files would take most of the compilation time.&lt;/p&gt;
    &lt;p&gt;By setting &lt;code&gt;MIX_OS_DEPS_COMPILE_PARTITION_COUNT&lt;/code&gt; to a number greater than 1, Mix will now compile multiple dependencies at the same time, using separate OS processes. Empirical testing shows that setting it to half of the number of cores on your machine is enough to maximize resource usage. The exact speed up will depend on the number of dependencies and the number of machine cores and some users reported up to 4x faster compilation times when using our release candidates. If you plan to enable it on CI or build servers, keep in mind it will most likely have a direct impact on memory usage too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Erlang/OTP 28 support&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 officially supports Erlang/OTP 28.1+ and later. In order to support the new Erlang/OTP 28 representation for regular expressions, structs can now control how they are escaped into abstract syntax trees by defining a &lt;code&gt;__escape__/1&lt;/code&gt; callback.&lt;/p&gt;
    &lt;p&gt;On the other hand, the new representation for regular expressions in Erlang/OTP 28+ implies they can no longer be used as default values for struct fields. Therefore, this is not allowed:&lt;/p&gt;
    &lt;code&gt;defmodule Foo do
  defstruct regex: ~r/foo/
end
&lt;/code&gt;
    &lt;p&gt;You can, however, still use regexes when initializing the structs themselves:&lt;/p&gt;
    &lt;code&gt;defmodule Foo do
  defstruct [:regex]

  def new do
    %Foo{regex: ~r/foo/}
  end
end
&lt;/code&gt;
    &lt;head rend="h2"&gt;OpenChain certification&lt;/head&gt;
    &lt;p&gt;Elixir v1.19 is also our first release following OpenChain compliance, as previously announced. In a nutshell:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Elixir releases now include a Source SBoM in CycloneDX 1.6 or later and SPDX 2.3 or later formats.&lt;/item&gt;
      &lt;item&gt;Each release is attested along with the Source SBoM.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These additions offer greater transparency into the components and licenses of each release, supporting more rigorous supply chain requirements.&lt;/p&gt;
    &lt;p&gt;This work was performed by Jonatan Männchen and sponsored by the Erlang Ecosystem Foundation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Summary&lt;/head&gt;
    &lt;p&gt;There are many other goodies in this release, such as improved option parsing, better debuggability and performance in ExUnit, the addition of &lt;code&gt;mix help Mod&lt;/code&gt;, &lt;code&gt;mix help Mod.fun&lt;/code&gt;, &lt;code&gt;mix help Mod.fun/arity&lt;/code&gt;, and &lt;code&gt;mix help app:package&lt;/code&gt; to make documentation accessible via shell for humans and agents, and much more. See the CHANGELOG for the complete release notes.&lt;/p&gt;
    &lt;p&gt;Happy coding!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://elixir-lang.org/blog/2025/10/16/elixir-v1-19-0-released/"/><published>2025-10-16T07:31:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604673</id><title>Hyperflask – Full stack Flask and Htmx framework</title><updated>2025-10-17T08:43:51.997397+00:00</updated><content>&lt;doc fingerprint="fa8a766ea56e588d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Backend-driven interactive apps&lt;/head&gt;
    &lt;p&gt;Hyperflask is built on top of Flask, a popular Python web framework. It is easy to use and master. Backend-driven apps ensure straighforward state management and limit a lot of footguns from frontend-heavy apps. Combined with HTMX and a component system, creating interactive apps is easier than ever.&lt;/p&gt;
    &lt;head rend="h2"&gt;A powerful component system&lt;/head&gt;
    &lt;p&gt;Hyperflask introduces component-driven architecture to Flask apps. Seamlessly create frontend (web components, react, etc...) and backend components and use them in your jinja templates. Use HTMX to create server-backed interactive components.&lt;/p&gt;
    &lt;head rend="h2"&gt;File-based routing&lt;/head&gt;
    &lt;p&gt;Hyperflask extends Flask with many powerful features, notably file-based routing using a new file format that combines python code and a jinja template (inspired by Astro pages).&lt;/p&gt;
    &lt;head rend="h2"&gt;Build beautiful UIs&lt;/head&gt;
    &lt;p&gt;Hyperflask includes beautiful components provided by daisyUI and icons by Bootstrap Icons. Use Tailwind to customize styling. Create beautiful UIs in minutes without any CSS.&lt;/p&gt;
    &lt;head rend="h2"&gt;Batteries included&lt;/head&gt;
    &lt;p&gt; Send emails using MJML, run background jobs, send push events using SSE, translations, authentication, content streaming, optimized images, ... &lt;lb/&gt;Everything you need to build a product ! &lt;/p&gt;
    &lt;head rend="h2"&gt;Content driven when needed&lt;/head&gt;
    &lt;p&gt;Hyperflask can be used to generate static web sites. It can also run in an hybrid mode where the server is accessed only for dynamic requests.&lt;/p&gt;
    &lt;head rend="h2"&gt;No messing around with your environment&lt;/head&gt;
    &lt;p&gt;Dev and prod environment are standardized on containers. With a tight integration with VS Code, everything is easy to setup and run. Easily deploy to VPS and various cloud services.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ensuring a thriving ecosystem&lt;/head&gt;
    &lt;p&gt;The Hyperflask framework itself is a small code base. It combines many Flask extensions in a seamless manner. All extensions and related projects are developed independently of the framework under the Hyperflask organization. Feel free to pick and choose the part you prefer from Hyperflask and use them in your own projects.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hyperflask.dev/"/><published>2025-10-16T12:46:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604700</id><title>Show HN: Inkeep (YC W23) – Agent Builder to create agents in code or visually</title><updated>2025-10-17T08:43:51.413954+00:00</updated><content>&lt;doc fingerprint="8576df8bbda1b01a"&gt;
  &lt;main&gt;
    &lt;p&gt;Build AI Agents with a No-Code Visual Builder or TypeScript SDK. Agents can be edited in either with full 2-way sync, so technical and non-technical teams can create and manage Agents in a single platform.&lt;/p&gt;
    &lt;p&gt;A no-code canvas so any team can create and own the Agents they care about.&lt;/p&gt;
    &lt;p&gt;A code-first framework so engineering teams can build with the tools they expect.&lt;/p&gt;
    &lt;code&gt;import { agent, subAgent } from "@inkeep/agents-sdk";

const helloAgent = subAgent({
  id: "hello-agent",
  name: "Hello Agent",
  description: "Says hello",
  prompt: 'Only reply with the word "hello", but you may do it in different variations like h3110, h3110w0rld, h3110w0rld! etc...',
});

export const basicAgent = agent({
  id: "basic-agent",
  name: "Basic Agent",
  description: "A basic agent",
  defaultSubAgent: helloAgent,
  subAgents: () =&amp;gt; [helloAgent],
});&lt;/code&gt;
    &lt;p&gt;The Visual Builder and TypeScript SDK are fully interoperable: technical and non-technical teams can edit and manage Agents in either format and collaborate with others at any time.&lt;/p&gt;
    &lt;p&gt;Docs • Quick Start • Video&lt;/p&gt;
    &lt;p&gt;Inkeep Agents can operate as real-time AI Chat Assistants, for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a customer experience agent for help centers, technical docs, or in-app experiences&lt;/item&gt;
      &lt;item&gt;an internal copilot to assist your support, sales, marketing, ops, and other teams&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Agents can also be used for AI Workflow Automation like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Creating and updating knowledge bases, documentation, and blogs&lt;/item&gt;
      &lt;item&gt;Updating CRMs, triaging helpdesk tickets, and tackling repetitive tasks&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Inkeep Open Source includes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A Visual Builder &amp;amp; TypeScript SDK with 2-way sync&lt;/item&gt;
      &lt;item&gt;Multi-agent architecture to support teams of agents&lt;/item&gt;
      &lt;item&gt;MCP Tools with credential management&lt;/item&gt;
      &lt;item&gt;A UI component library for dynamic chat experiences&lt;/item&gt;
      &lt;item&gt;Triggering Agents via MCP, A2A, &amp;amp; Vercel SDK APIs&lt;/item&gt;
      &lt;item&gt;Observability via a Traces UI &amp;amp; OpenTelemetry&lt;/item&gt;
      &lt;item&gt;Easy deployment using Vercel or Docker&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For a full overview, see the Concepts guide. For managed cloud hosting, sign up to get notified when available.&lt;/p&gt;
    &lt;p&gt;The Inkeep Agent Platform is composed of several key services and libraries that work together:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;agents-manage-api: An API that handles configuration of Agents, Sub Agents, MCP Servers, Credentials, and Projects with a REST API.&lt;/item&gt;
      &lt;item&gt;agents-manage-ui: Visual Builder web interface for creating and managing Agents. Writes to the &lt;code&gt;agents-manage-api&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;agents-sdk: TypeScript SDK (&lt;code&gt;@inkeep/agents-sdk&lt;/code&gt;) for declaratively defining Agents and custom tools in code. Writes to&lt;code&gt;agents-manage-api&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;agents-cli: Includes various handy utilities, including &lt;code&gt;inkeep push&lt;/code&gt;and&lt;code&gt;inkeep pull&lt;/code&gt;which sync your TypeScript SDK code with the Visual Builder.&lt;/item&gt;
      &lt;item&gt;agents-run-api: The Runtime API that exposes Agents as APIs and executes Agent conversations. Keeps conversation state and emits OTEL traces.&lt;/item&gt;
      &lt;item&gt;agents-ui: A UI component library of chat interfaces for embedding rich, dynamic Agent conversational experiences in web apps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Under the hood, the framework uses the Vercel AI SDK for interfacing with LLM providers. The &lt;code&gt;agents-sdk&lt;/code&gt;/ &lt;code&gt;agents-manage-api&lt;/code&gt; share many concepts with the AI SDK, and &lt;code&gt;agents-run-api&lt;/code&gt; outputs a data stream compatible with Vercel's &lt;code&gt;useChat&lt;/code&gt; and AI Elements primitives for custom UIs.&lt;/p&gt;
    &lt;p&gt;The Inkeep Agent Framework is licensed under the Elastic License 2.0 (ELv2) subject to Inkeep's Supplemental Terms (SUPPLEMENTAL_TERMS.md). This is a fair-code, source-available license that allows broad usage while protecting against certain competitive uses.&lt;/p&gt;
    &lt;p&gt;Inkeep is designed to be extensible and open: use the LLM provider of your choice, use Agents via standard protocols, and easily deploy and self-host Agents in your own infra.&lt;/p&gt;
    &lt;p&gt;If you'd like to contribute, follow our contribution guide.&lt;/p&gt;
    &lt;p&gt;Follow us to stay up to date, get help, and share feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/inkeep/agents"/><published>2025-10-16T12:50:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45604779</id><title>Electricity can heal wounds three times as fast (2023)</title><updated>2025-10-17T08:43:50.060876+00:00</updated><content>&lt;doc fingerprint="fedd408029bd4e42"&gt;
  &lt;main&gt;
    &lt;p&gt;Chronic wounds are a major health problem for diabetic patients and the elderly – in extreme cases they can even lead to amputation. Using electric stimulation, researchers in a project at Chalmers University of Technology, Sweden, and the University of Freiburg, Germany, have developed a method that speeds up the healing process, making wounds heal three times faster.&lt;/p&gt;
    &lt;p&gt;There is an old Swedish saying that one should never neglect a small wound or a friend in need. For most people, a small wound does not lead to any serious complications, but many common diagnoses make wound healing far more difficult. People with diabetes, spinal injuries or poor blood circulation have impaired wound healing ability. This means a greater risk of infection and chronic wounds – which in the long run can lead to such serious consequences as amputation.&lt;/p&gt;
    &lt;p&gt;Now a group of researchers at Chalmers and the University of Freiburg have developed a method using electric stimulation to speed up the healing process.&lt;/p&gt;
    &lt;p&gt;“Chronic wounds are a huge societal problem that we don’t hear a lot about. Our discovery of a method that may heal wounds up to three times faster can be a game changer for diabetic and elderly people, among others, who often suffer greatly from wounds that won’t heal,” says Maria Asplund, Professor of Bioelectronics at Chalmers University of Technology and head of research on the project.&lt;/p&gt;
    &lt;head rend="h3"&gt;&lt;lb/&gt;Electric guidance of cells for faster healing&lt;/head&gt;
    &lt;p&gt;The researchers worked from an old hypothesis that electric stimulation of damaged skin can be used to heal wounds. The idea is that skin cells are electrotactic, which means that they directionally ‘migrate’ in electric fields. This means that if an electric field is placed in a petri dish with skin cells, the cells stop moving randomly and start moving in the same direction. The researchers investigated how this principle can be used to electrically guide the cells in order to make wounds heal faster. Using a tiny engineered chip, the researchers were able to compare wound healing in artificial skin, stimulating one wound with electricity and letting one heal without electricity. The differences were striking.&lt;/p&gt;
    &lt;p&gt;“We were able to show that the old hypothesis about electric stimulation can be used to make wounds heal significantly faster. In order to study exactly how this works for wounds, we developed a kind of biochip on which we cultured skin cells, which we then made tiny wounds in. Then we stimulated one wound with an electric field, which clearly led to it healing three times as fast as the wound that healed without electric stimulation,” Asplund says.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hope for diabetes patients&lt;/head&gt;
    &lt;p&gt;In the study, the researchers also focused on wound healing in connection with diabetes, a growing health problem worldwide. One in 11 adults today has some form of diabetes according to the World Health Organization (WHO) and the International Diabetes Federation.&lt;/p&gt;
    &lt;p&gt;“We’ve looked at diabetes models of wounds and investigated whether our method could be effective even in those cases. We saw that when we mimic diabetes in the cells, the wounds on the chip heal very slowly. However, with electric stimulation we can increase the speed of healing so that the diabetes-affected cells almost correspond to healthy skin cells,” Asplund says.&lt;/p&gt;
    &lt;head rend="h3"&gt;Individualised treatment the next step&lt;/head&gt;
    &lt;p&gt;The Chalmers researchers recently received a large grant which will allow them to continue their research in the field, and in the long run enable the development of wound healing products for consumers on the market. Similar products have come out before, but more basic research is required to develop effective products that generate enough electric field strength and stimulate in the right way for each individual. This is where Asplund and her colleagues come into the picture:&lt;/p&gt;
    &lt;p&gt;“We are now looking at how different skin cells interact during stimulation, to take a step closer to a realistic wound. We want to develop a concept to be able to ‘scan’ wounds and adapt the stimulation based on the individual wound. We are convinced that this is the key to effectively helping individuals with slow-healing wounds in the future,” Asplund says.&lt;/p&gt;
    &lt;head rend="h3"&gt;More about the study:&lt;/head&gt;
    &lt;p&gt;• “Bioelectronic microfluidic wound healing: a platform for investigating direct current stimulation of injured cell collectives” was published in the journal Lab on a Chip. The article was written by Sebastian Shaner, Anna Savelyeva, Anja Kvartuh, Nicole Jedrusik, Lukas Matter, José Leal and Maria Asplund. The researchers work at the University of Freiburg in Germany and Chalmers University of Technology. &lt;lb/&gt;• In their study, the researchers showed that wound healing on artificial skin stimulated with electric current was three times faster than on the skin that healed naturally. The electric field was low, about 200 mV/mm, and did not have a negative impact on the cells. &lt;lb/&gt;• The method the researchers developed is based on a microfluidic biochip on which artificial skin can be grown, stimulated with an electric current and studied in an effective and controlled manner. The concept allows researchers to conduct multiple experiments in parallel on the same chip. &lt;lb/&gt;• The research project began in 2018 and is funded by the European Research Council (ERC). The project was recently granted new funding so the research can get to market and benefit patients.&lt;/p&gt;
    &lt;head rend="h3"&gt;For more information, please contact:&lt;/head&gt;
    &lt;p&gt;Maria Asplund, Professor of Bioelectronics, Department of Microtechnology and Nanoscience at Chalmers University of Technology, Sweden&lt;lb/&gt;maria.asplund@chalmers.se, +46 31 772 41 14&lt;/p&gt;
    &lt;p&gt;Sebastian Shaner, PhD Candidate, Department of Microsystems Engineering at the University of Freiburg, Germany&lt;lb/&gt;sebastian.shaner@blbt.uni-freiburg.de&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Professor, Electronics Material and Systems, Microtechnology and Nanoscience&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.chalmers.se/en/current/news/mc2-how-electricity-can-heal-wounds-three-times-as-fast/"/><published>2025-10-16T12:59:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45605501</id><title>DoorDash and Waymo launch autonomous delivery service in Phoenix</title><updated>2025-10-17T08:43:49.716370+00:00</updated><content>&lt;doc fingerprint="f98ba259b3b2bde5"&gt;
  &lt;main&gt;
    &lt;p&gt;Today, DoorDash announced a new partnership with Waymo to launch an autonomous delivery service in Metro Phoenix and introduce a limited-time $10 Waymo promotion for DashPass members in Los Angeles, San Francisco, and Phoenix.&lt;/p&gt;
    &lt;p&gt;From now through the end of the year, DashPass members in these three cities can receive $10 off one Waymo ride per month.* A new promotion code will be issued at the start of each month through December 31, 2025.&lt;/p&gt;
    &lt;p&gt;Testing of the new autonomous delivery service in Metro Phoenix is now underway, with plans to launch broader commercial operations later this year. DoorDash consumers in the area may be matched with a fully autonomous Waymo vehicle for deliveries from participating merchants using DoorDash’s Autonomous Delivery Platform, the system that helps orchestrate different types of delivery methods together at scale, whether that’s Dashers, robots, drones, or Waymo. The service will begin with deliveries from DashMart, DoorDash’s owned and operated convenience, grocery, and retail store that also powers DashMart Fulfillment Services, with plans to expand over time.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“DashPass is designed to give consumers consistent value, convenience, and access to the best of their communities, and our partnership with Waymo builds on that promise,” said David Richter, Vice President of Business and Corporate Development at DoorDash. “Together, we’re giving members access to, and savings on, a new and delightful experience, while advancing our vision for a multi-modal autonomous future of local commerce.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;“We are excited to make everyday errands easier with the Waymo Driver, offering the added peace of mind that comes with our safe and reliable technology. Through our partnership with DoorDash, we leverage our proven delivery experience to provide customers with a seamless, contact-free way to get items they need, whether it’s groceries or a quick bite,” said Nicole Gavel, Head of Business Development and Strategic Partnerships at Waymo.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;DashPass offers exclusive deals, member-only benefits, and $0 delivery fees and reduced service fees on eligible orders from thousands of restaurants, grocery stores, and retailers. On average, DashPass members save $5 per eligible order and have collectively saved more than $10 billion globally since the program launched in 2018.&lt;/p&gt;
    &lt;p&gt;*On weekday rides booked between 2 a.m. and 2 p.m. Terms apply.&lt;/p&gt;
    &lt;p&gt;Forward-Looking Statements&lt;lb/&gt;This communication contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. Forward-looking statements generally relate to future events, and such statements in this communication include, but are not limited to, expectations regarding the opportunity and expected benefits of the partnership between DoorDash and Waymo. Expectations and beliefs regarding these matters may not materialize, and actual results in future periods are subject to risks and uncertainties that could cause actual results to differ materially from those projected. For information on potential risks and uncertainties that could cause actual results to differ from any results predicted, please see DoorDash’s most recent Annual Report on Form 10-K and subsequent Quarterly Reports on Form 10-Q, each filed with the Securities and Exchange Commission.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://about.doordash.com/en-us/news/waymo"/><published>2025-10-16T14:04:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45606698</id><title>Codex Is Live in Zed</title><updated>2025-10-17T08:43:49.437274+00:00</updated><content>&lt;doc fingerprint="b44ddc5f080cb81d"&gt;
  &lt;main&gt;
    &lt;p&gt;When we introduced the Agent Client Protocol (ACP) in collaboration with Google's Gemini CLI team, we did not anticipate how much pent-up demand there was for a protocol like this!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First we saw a wave of requests for Anthropic's Claude Code&lt;/item&gt;
      &lt;item&gt;Then we saw a bunch of other clients and agents adopting ACP, most recently JetBrains&lt;/item&gt;
      &lt;item&gt;Now we've seen a fresh wave of requests for OpenAI's Codex:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;As of today, Zed supports Codex out-the-box via ACP. You can select it from the New Thread menu, just like Claude Code or Gemini CLI:&lt;/p&gt;
    &lt;p&gt;Like our other ACP integrations, Codex via ACP is strictly about improving UI and keeping you in flow in your IDE of choice; the billing and legal/terms arrangement is directly between you and OpenAI. Zed does not charge for use of external agents like Codex, nor do prompts and code sent via Codex-ACP to OpenAI touch Zed's servers! We've also separately open-sourced the codex-acp adapter so you can use it outside of Zed as well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Learning from Different Agents&lt;/head&gt;
    &lt;p&gt;Every model behaves a bit differently than the others, and the same is true of agents. For example, some agents support switching models in the middle of a conversation, whereas others require sticking with the same model throughout. Some support viewing and resuming past conversations, whereas others have no concept of conversation persistence. ACP is designed to be flexible enough to work with a variety of agent capabilities, but the experience of using them still varies based on the agent's implementation details.&lt;/p&gt;
    &lt;p&gt;A detail that came up when we were building the Codex ACP adapter was that the Codex agent runs terminal commands in its own process, and then streams output bytes from that terminal process to the client. In the past, we've had this reversed: the agent would send the client a request to run a terminal command (e.g. &lt;code&gt;mkdir examples&lt;/code&gt;) and then the client would manage
the actual running of that command.&lt;/p&gt;
    &lt;p&gt;Naturally, we want to keep the look and feel consistent no matter which agent you're using, but this design difference between Codex and other agents makes certain details unavoidably different. For example, for other agents we can spawn terminals in pseudoterminal (PTY) mode. This means you can actually interact with the terminal right in the Agent Panel if the agent launches an interactive process, and it also means things like colorful terminal output tend to be enabled by default.&lt;/p&gt;
    &lt;p&gt;On the other hand, being in PTY mode means that an agent can get stuck. A classic example of this is when an agent tries to run &lt;code&gt;git rebase --continue&lt;/code&gt; and the terminal pops up the configured editor, then waits for the programmer to make any
edits (if desired) to the commit message. This can be nice for a human, but for an agent that's waiting for the command to
finish, it creates a deadlock. The process won't proceed without interaction, and the agent won't interact until the process
completes! Having terminals work in non-PTY mode might result in fewer colors and less interactivity, but it also results in
fewer cases of agents getting stuck.&lt;/p&gt;
    &lt;p&gt;Now that we've integrated agents that both enable and disable PTY mode, we can compare how the experience feels in both cases, and use that to inform our recommendations for future ACP integrations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Which ACP Integration is Next?&lt;/head&gt;
    &lt;p&gt;In addition to Codex, we have already added support to Zed for Claude Code, Gemini CLI, and other agents, all via ACP. Since ACP is not specific to Zed, we've also seen it be adopted by editors like Neovim, Emacs, and now the JetBrains family of IDEs.&lt;/p&gt;
    &lt;p&gt;Now that the protocol has picked up enough adoption on its own, we're happy to shift our focus to working with the community on the future of the protocol—as opposed to building ACP adapters ourselves like we did with Codex and Claude Code. We're excited to see what amazing ACP integrations the community cooks up!&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking for a better editor?&lt;/head&gt;
    &lt;p&gt;You can try Zed today on macOS, Windows, or Linux. Download now!&lt;/p&gt;
    &lt;head rend="h3"&gt;We are hiring!&lt;/head&gt;
    &lt;p&gt;If you're passionate about the topics we cover on our blog, please consider joining our team to help us ship the future of software development.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://zed.dev/blog/codex-is-live-in-zed"/><published>2025-10-16T15:36:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45607117</id><title>Claude Skills</title><updated>2025-10-17T08:43:49.152384+00:00</updated><content>&lt;doc fingerprint="9e4c2e7f2f779869"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing Agent Skills&lt;/head&gt;
    &lt;p&gt;Claude can now use Skills to improve how it performs specific tasks. Skills are folders that include instructions, scripts, and resources that Claude can load when needed.&lt;/p&gt;
    &lt;p&gt;Claude will only access a skill when it's relevant to the task at hand. When used, skills make Claude better at specialized tasks like working with Excel or following your organization's brand guidelines.&lt;/p&gt;
    &lt;p&gt;You've already seen Skills at work in Claude apps, where Claude uses them to create files like spreadsheets and presentations. Now, you can build your own skills and use them across Claude apps, Claude Code, and our API.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Skills work&lt;/head&gt;
    &lt;p&gt;While working on tasks, Claude scans available skills to find relevant matches. When one matches, it loads only the minimal information and files needed—keeping Claude fast while accessing specialized expertise.&lt;/p&gt;
    &lt;p&gt;Skills are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Composable: Skills stack together. Claude automatically identifies which skills are needed and coordinates their use.&lt;/item&gt;
      &lt;item&gt;Portable: Skills use the same format everywhere. Build once, use across Claude apps, Claude Code, and API.&lt;/item&gt;
      &lt;item&gt;Efficient: Only loads what's needed, when it's needed.&lt;/item&gt;
      &lt;item&gt;Powerful: Skills can include executable code for tasks where traditional programming is more reliable than token generation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Think of Skills as custom onboarding materials that let you package expertise, making Claude a specialist on what matters most to you. For a technical deep-dive on the Agent Skills design pattern, architecture, and development best practices, read our engineering blog.&lt;/p&gt;
    &lt;head rend="h2"&gt;Skills work with every Claude product&lt;/head&gt;
    &lt;head rend="h3"&gt;Claude apps&lt;/head&gt;
    &lt;p&gt;Skills are available to Pro, Max, Team and Enterprise users. We provide skills for common tasks like document creation, examples you can customize, and the ability to create your own custom skills.&lt;/p&gt;
    &lt;p&gt;Claude automatically invokes relevant skills based on your task—no manual selection needed. You'll even see skills in Claude's chain of thought as it works.&lt;lb/&gt;Creating skills is simple. The "skill-creator" skill provides interactive guidance: Claude asks about your workflow, generates the folder structure, formats the SKILL.md file, and bundles the resources you need. No manual file editing required. &lt;/p&gt;
    &lt;p&gt;Enable Skills in Settings. For Team and Enterprise users, admins must first enable Skills organization-wide.&lt;/p&gt;
    &lt;head rend="h3"&gt;Claude Developer Platform (API)&lt;/head&gt;
    &lt;p&gt;Agent Skills, which we often refer to simply as Skills, can now be added to Messages API requests and the new &lt;code&gt;/v1/skills&lt;/code&gt; endpoint gives developers programmatic control over custom skill versioning and management. Skills require the Code Execution Tool beta, which provides the secure environment they need to run.&lt;/p&gt;
    &lt;p&gt;Use Anthropic-created skills to have Claude read and generate professional Excel spreadsheets with formulas, PowerPoint presentations, Word documents, and fillable PDFs. Developers can create custom Skills to extend Claude's capabilities for their specific use cases.&lt;/p&gt;
    &lt;p&gt;Developers can also easily create, view, and upgrade skill versions through the Claude Console.&lt;/p&gt;
    &lt;p&gt;Explore the documentation or Anthropic Academy to learn more.&lt;/p&gt;
    &lt;quote&gt;Skills teaches Claude how to work with Box content. Users can transform stored files into PowerPoint presentations, Excel spreadsheets, and Word documents that follow their organization's standards—saving hours of effort.&lt;/quote&gt;
    &lt;quote&gt;With Skills, Claude works seamlessly with Notion - taking users from questions to action faster. Less prompt wrangling on complex tasks, more predictable results.&lt;/quote&gt;
    &lt;quote&gt;Canva plans to leverage Skills to customize agents and expand what they can do. This unlocks new ways to bring Canva deeper into agentic workflows—helping teams capture their unique context and create stunning, high-quality designs effortlessly.&lt;/quote&gt;
    &lt;quote&gt;Skills streamline our management accounting and finance workflows. Claude processes multiple spreadsheets, catches critical anomalies, and generates reports using our procedures. What once took a day, we can now accomplish in an hour.&lt;/quote&gt;
    &lt;head rend="h3"&gt;Claude Code&lt;/head&gt;
    &lt;p&gt;Skills extend Claude Code with your team's expertise and workflows. Install skills via plugins from the anthropics/skills marketplace. Claude loads them automatically when relevant. Share skills through version control with your team. You can also manually install skills by adding them to &lt;code&gt;~/.claude/skills&lt;/code&gt;. The Claude Agent SDK provides the same Agent Skills support for building custom agents. &lt;/p&gt;
    &lt;head rend="h2"&gt;Getting started&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Claude apps: User Guide &amp;amp; Help Center&lt;/item&gt;
      &lt;item&gt;API developers: Documentation&lt;/item&gt;
      &lt;item&gt;Claude Code: Documentation&lt;/item&gt;
      &lt;item&gt;Example Skills to customize: GitHub repository&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What's next&lt;/head&gt;
    &lt;p&gt;We're working toward simplified skill creation workflows and enterprise-wide deployment capabilities, making it easier for organizations to distribute skills across teams.&lt;/p&gt;
    &lt;p&gt;Keep in mind, this feature gives Claude access to execute code. While powerful, it means being mindful about which skills you use—stick to trusted sources to keep your data safe. Learn more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.anthropic.com/news/skills"/><published>2025-10-16T16:05:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45607758</id><title>Gemini 3.0 spotted in the wild through A/B testing</title><updated>2025-10-17T08:43:48.924144+00:00</updated><content>&lt;doc fingerprint="ef53a5961b3a9e93"&gt;
  &lt;main&gt;
    &lt;p&gt;So I kept reading rumors that Gemini 3.0 is accessible through Google AI Studio through A/B testing and the SVGs folks were posting (of Xbox controllers in particular) made me think that they might be right.&lt;/p&gt;
    &lt;p&gt;Gemini 3.0 is one of the most anticipated releases in AI at the moment because of the expected advances in coding performance.&lt;/p&gt;
    &lt;p&gt;Evaluating models is a difficult task, but surprisingly the SVG generation task seems to be a very efficient proxy for gauging model quality as @simonw has shown us using his “pelican riding a bicycle” test.&lt;/p&gt;
    &lt;p&gt;Lo and behold, after trying a couple of times I got the A/B screen and got an SVG image of an Xbox 360 controller that looked VERY impressive compared to the rest of the frontier.&lt;/p&gt;
    &lt;p&gt;The exact prompt I used:&lt;/p&gt;
    &lt;code&gt;Create an SVG image of an Xbox 360 controller. Output it in a Markdown multi-line code block.
Like this:
```svg
...
```
&lt;/code&gt;
    &lt;p&gt;For what it’s worth the model ID for “Gemini 3.0” was &lt;code&gt;ecpt50a2y6mpgkcn&lt;/code&gt; which doesn’t really help understand which version of the model it is. Perhaps since I user selected Gemini 2.5 Pro it is actually Gemini 3.0 Pro that it is pitted against, as comparing Gemini 3.0 Flash to Gemini 2.5 Pro in an A/B test makes less sense to me. Also, it had about 24s higher TTFT and output length was about 40% longer (this includes reasoning tokens AFAICT), but that doesn’t say much other than it’s likely not a “GPT-5 Pro” type answer that uses significant test time compute.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix&lt;/head&gt;
    &lt;p&gt;“Gemini 3.0” A/B result versus the Gemini 2.5 Pro model:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ricklamers.io/posts/gemini-3-spotted-in-the-wild/"/><published>2025-10-16T16:54:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45608456</id><title>Talent</title><updated>2025-10-17T08:43:48.592800+00:00</updated><content>&lt;doc fingerprint="7e1591173be606bd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;On Talent&lt;/head&gt;
    &lt;p&gt;Quantity has a quality of its very own. Some writers are good - and they write all the time. The holy trinity of newsletter writers (Matt Levine, Byrne Hobart and Patrick McKenzie) write up to 700k words a year - so 2,000 words a day. I think Matt Levine’s schedule looks a little bit like waking up and doing 4000 words early in the morning about three times a week, then hitting send on his newsletter. Marc Rubinstein (another pretty prolific writer!) recently shared this Bloomberg profile of Jason Goldberg - “a Barclays analyst who has been writing a daily briefing note for 20 years”. It’s not just newsletter writers - for instance, Philip Kerr managed to write 42 books in 29 years by just working obsessively, writing on birthdays and Christmas. Paul Erdös had an even more insane work schedule:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“Erdös first did mathematics at the age of three, but for the last twenty-five years of his life, since the death of his mother, he put in nineteen-hour days, keeping himself fortified with 10 to 20 milligrams of Benzedrine or Ritalin, strong espresso, and caffeine tablets. "A mathematician," Erdös was fond of saying, "is a machine for turning coffee into theorems." When friends urged him to slow down, he always had the same response: "There'll be plenty of time to rest in the grave."&lt;/p&gt;&lt;p&gt;Erdös would let nothing stand in the way of mathematical progress. When the name of a colleague in California came up at breakfast in New Jersey, Erdös remembered a mathematical result he wanted to share with him. He headed toward the phone and started to dial. His host interrupted him, pointing out that it was 5:00 A.M. on the West Coast. "Good," Erdös said, "that means he'll be home."&lt;/p&gt;&lt;lb/&gt;…&lt;lb/&gt;Like all of Erdös's friends, Graham was concerned about his drug-taking. In 1979, Graham bet Erdös $500 that he couldn't stop taking amphetamines for a month. Erdös accepted the challenge, and went cold turkey for thirty days. After Graham paid up--and wrote the $500 off as a business expense--Erdös said, "You've showed me I'm not an addict. But I didn't get any work done. I'd get up in the morning and stare at a blank piece of paper. I'd have no ideas, just like an ordinary person. You've set mathematics back a month." He promptly resumed taking pills, and mathematics was the better for it.&lt;/quote&gt;
    &lt;p&gt; Looking at these guys, one feels a bit inadequate. How do they do it? Why aren’t you doing it? What did you get done this week?&lt;lb/&gt; One answer to this question is Scott Alexander’s essay is The Parable of the Talents. In the essay, he’s basically trying to square a circle: to reconcile the ideas that 1. natural talent exists and 2. everyone is morally equivalent. Alexander puts a lot of effort into proving point 1, and I think he does a great job. Here are the relevant sections. I agree with all of this, which is why I’m not trying to put it into my own words. But I’m particularly interested in his point that talent is a real thing, and some people are just better at things than others. He takes this really seriously. &lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“Consider for a moment Srinivasa Ramanujan, one of the greatest mathematicians of all time. He grew up in poverty in a one-room house in small-town India. He taught himself mathematics by borrowing books from local college students and working through the problems on his own until he reached the end of the solveable ones and had nowhere else to go but inventing ways to solve the unsolveable ones.&lt;/p&gt;&lt;p&gt;There are a lot of poor people in the United States today whose life circumstances prevented their parents from reading books to them as a child, prevented them from getting into the best schools, prevented them from attending college, et cetera. And pretty much all of those people still got more educational opportunities than Ramanujan did.&lt;/p&gt;&lt;p&gt;And from there we can go in one of two directions. First, we can say that a lot of intelligence is innate, that Ramanujan was a genius, and that we mortals cannot be expected to replicate his accomplishments.&lt;/p&gt;&lt;p&gt;Or second, we can say those poor people are just not trying hard enough.&lt;/p&gt;&lt;p&gt;…&lt;/p&gt;&lt;lb/&gt;In high school English, I got A++s in all my classes, Principal’s Gold Medals, 100%s on tests, first prize in various state-wide essay contests, etc. In Math, I just barely by the skin of my teeth scraped together a pass in Calculus with a C-.&lt;p&gt;Every time I won some kind of prize in English my parents would praise me and say I was good and should feel good. My teachers would hold me up as an example and say other kids should try to be more like me. Meanwhile, when I would bring home a report card with a C- in math, my parents would have concerned faces and tell me they were disappointed and I wasn’t living up to my potential and I needed to work harder et cetera.&lt;/p&gt;&lt;p&gt;And I don’t know which part bothered me more.&lt;/p&gt;&lt;p&gt;Every time I was held up as an example in English class, I wanted to crawl under a rock and die. I didn’t do it! I didn’t study at all, half the time I did the homework in the car on the way to school, those essays for the statewide competition were thrown together on a lark without a trace of real effort. To praise me for any of it seemed and still seems utterly unjust.&lt;/p&gt;&lt;p&gt;On the other hand, to this day I believe I deserve a fricking statue for getting a C- in Calculus I. It should be in the center of the schoolyard, and have a plaque saying something like “Scott Alexander, who by making a herculean effort managed to pass Calculus I, even though they kept throwing random things after the little curly S sign and pretending it made sense.”&lt;/p&gt;&lt;p&gt;And without some notion of innate ability, I don’t know what to do with this experience. I don’t want to have to accept the blame for being a lazy person who just didn’t try hard enough in Math. But I really don’t want to have to accept the credit for being a virtuous and studious English student who worked harder than his peers.&lt;/p&gt;&lt;lb/&gt;…&lt;p&gt;When I was 6 and my brother was 4, our mom decided that as an Overachieving Jewish Mother she was contractually obligated to make both of us learn to play piano. She enrolled me in a Yamaha introductory piano class, and my younger brother in a Yamaha ‘cute little kids bang on the keyboard’ class.&lt;/p&gt;&lt;p&gt;A little while later, I noticed that my brother was now with me in my Introductory Piano class.&lt;/p&gt;&lt;p&gt;A little while later, I noticed that my brother was now by far the best student in my Introductory Piano Class, even though he had just started and was two or three years younger than anyone else there.&lt;/p&gt;&lt;p&gt;A little while later, Yamaha USA flew him to Japan to show him off before the Yamaha corporate honchos there.&lt;/p&gt;&lt;p&gt;Well, one thing led to another, and my brother won several international piano competitions, got a professorship in music at age 25, and now routinely gets news articles written about him calling him “among the top musicians of his generation”.&lt;/p&gt;&lt;p&gt;Meanwhile, I was always a mediocre student at Yamaha. When the time came to try an instrument in elementary school, I went with the violin to see if maybe I’d find it more to my tastes than the piano. I was quickly sorted into the remedial class because I couldn’t figure out how to make my instrument stop sounding like a wounded cat. After a year or so of this, I decided to switch to fulfilling my music requirement through a choir, and everyone who’d had to listen to me breathed a sigh of relief.&lt;/p&gt;&lt;p&gt;Every so often I wonder if somewhere deep inside me there is the potential to be “among the top musicians of my generation.” I try to recollect whether my brother practiced harder than I did. My memories are hazy, but I don’t think he practiced much harder until well after his career as a child prodigy had taken off.&lt;/p&gt;&lt;p&gt;…&lt;/p&gt;&lt;p&gt;I dunno. But I don’t think of myself as working hard at any of the things I am good at, in the sense of “exerting vast willpower to force myself kicking and screaming to do them”. It’s possible I do work hard, and that an outside observer would accuse me of eliding how hard I work, but it’s not a conscious elision and I don’t feel that way from the inside.&lt;/p&gt;&lt;p&gt;…&lt;/p&gt;&lt;p&gt;But I still feel like there’s something going on here where the solution to me being bad at math and piano isn’t just “sweat blood and push through your brain’s aversion to these subjects until you make it stick”. When I read biographies of Ramanujan and other famous mathematicians, there’s no sense that they ever had to do that with math. When I talk to my brother, I never get a sense that he had to do that with piano. And if I am good enough at writing to qualify to have an opinion on being good at things, then I don’t feel like I ever went through that process myself.&lt;/p&gt;&lt;lb/&gt;So this too is part of my deal with myself. I’ll try to do my best at things, but if there’s something I really hate, something where I have to go uphill every step of the way, then it’s okay to admit mediocrity. I won’t beat myself up for not forcing myself kicking and screaming to practice piano. And in return I won’t become too cocky about practicing writing a lot.”&lt;/quote&gt;
    &lt;p&gt;Here’s a related piece - his Apologia pro vita sua.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“I have had a really busy few months. I think it will be letting up soon, but I’m not sure. And I’ve told a lot of people who needed things from me, for one reason or another, “I’m sorry, I’m too busy to take care of this right now.”&lt;/p&gt;
      &lt;p&gt;And I worry that some of those people read my blog and think “Wait, if you have enough time to write blog posts nearly every day, some of which are up to six thousand words long, why don’t you have enough time to do a couple of hours work for me?”&lt;/p&gt;
      &lt;p&gt;And the answer is – you fancy doctors with your mathematics and subtraction might say that I could just take a couple of hours away from blogging and use those free hours to write that one thing or analyze that one study or whatever, but you’re not going to fool me.&lt;/p&gt;
      &lt;p&gt;Just as drugs mysteriously find their own non-fungible money, enjoyable activities mysteriously find their own non-fungible time. If I had to explain it, I’d say the resource bottleneck isn’t time but energy/willpower, and that these look similar because working hard saps energy/willpower and relaxing for a while restores it, so when I have less time I also have less energy/willpower. But some things don’t require energy/willpower and so are essentially free. Writing this is my addiction, so it’s free. Doesn’t mean anything else is.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Erdös’s genius, then, was that his 19 hour workdays were “essentially free”. He didn’t sweat blood and push though his brain’s aversion to doing maths - it must have come pretty naturally to him. So it’s really important to do things that come naturally to you.&lt;/p&gt;
    &lt;p&gt;Here’s Jim Donovan talking about his SLA with clients while working as an investment banker:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“When I started at Goldman Sachs … I would say to clients, you can leave me a voicemail, any time, unless I’m dead or asleep, I check it every ten seconds… And I don’t sleep very long either.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I suspect that for Donovan, this didn’t feel like sweating blood - it was just how he was wired. Some people (not me!) are slow repliers, some people hate always being available, and those people are going to be terrible investment bankers and Jim Donovan is going to take their clients. Because for him, this stuff came naturally. He’s a 99.999th percentile voicemail replier. He was born to do it - and what’s awesome is that he found a way to turn his natural talent into loads of money.&lt;/p&gt;
    &lt;p&gt;I know professional writers that hear about Matt Levine and Scott Alexander’s work routine, and shake their heads. They produce a book every few years; they need to waste a few hours to get in the mindset to do anything. The can’t just jot down a paragraph here and there in their breaks. And yet even though they can’t hold themselves to that standard, they’re still professional writers. I mean, look how Hunter S. Thompson lived (yes, I know it’s not real):&lt;/p&gt;
    &lt;p&gt;My writing process doesn’t look much like Levine’s. I don’t have his consistency. The general pattern is that I spend weeks or months stewing on something, and then take a few hours and write it all down in one go, with minimal editing. That’s in contrast to a friend who told me recently that he spent two years writing 52 essays - one every two weeks, with metronomic consistency.&lt;/p&gt;
    &lt;p&gt;Here’s an example from my finals. I had a coursework essay due at 12pm, and the night before, I went for dinner with my two best friends. At about 5am I had maybe the introduction written - and I felt my life flashing before my eyes. Was this going to be the moment I failed my finals? But because I’d spent six months thinking about the question on and off, over the next few hours I managed to write 2,000 words on the subject of “Only God, not Man, makes an heir”: to what extent did Henry II’s legal reforms strengthen God’s hand?”, and got a 78 for my troubles - my best mark across all my papers.&lt;/p&gt;
    &lt;p&gt;Honestly, that was super fun - it wasn’t a sustainable or consistent way to get work done, but I enjoyed the pressure, I enjoyed the challenge, and I definitely enjoyed the 78. Writing seems to come to me in these spurts, which implies that I’m going to struggle to work with the consistency that Matt Levine achieves; ergo, I should not become a professional newsletter writer.&lt;/p&gt;
    &lt;p&gt; If you read enough finance books you start to pick up anecdotes about what makes a good trader. Lots of my friends are traders - there’s an archetype of “British Indian, studied economics at Cambridge, grew up in northwest London” that seems particularly successful - and so I’ve had feedback on these ideas. These guys say that they see themselves in these quotes.&lt;lb/&gt; One useful trait is an extreme ability for self-control and rational thinking under pressure:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;"Bill [Gross] was to a large extent a trend follower, but he had a unique ability to know when it was time to lean against that trend and take a contrary position. There were numerous occasions where everyone else was scared shitless, and Bill put on his seat belt."&lt;/p&gt;&lt;p&gt;Pimco partner Ben Trosky, quoted in The Bond King&lt;/p&gt;&lt;lb/&gt;"When the financial stakes were high, though, [Steve] Cohen demonstrated an almost inhuman ability to stay calm and make rational trading decisions.&lt;lb/&gt;…&lt;lb/&gt;It was practically a genetic anomaly, this ability to behave like a reptile when he was trading, as opposed to a human being prone to fear and self-doubt. When he interviewed new hires he tried to test for this quality as best he could."&lt;p&gt;Sheelah Kolhatkar, Black Edge&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;Another is being inscrutable. For example, people talked about John Meriwether from LTCM like this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“John has a steel-trap mind. You have no clue what he's thinking.”&lt;/p&gt;
      &lt;p&gt;William McIntosh (who hired Meriwether into Salomon Brothers), quoted in When Genius Failed&lt;/p&gt;
      &lt;p&gt;“He wore the same blank half-tense expression when he won as he did when he lost. He had, I think, a profound ability to control the two emotions that commonly destroy traders - fear and greed - and it made him as noble as a man who pursues his own interest so fiercely can be."&lt;/p&gt;
      &lt;p&gt;Michael Lewis, writing about Meriwether’s time at Salomon in Liar’s Poker&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Mostly, though, the key is to be an obsessive:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“My interview with the company - that is, with [Thomas] Peterffy - was memorable. It took place it his apartment in Greenwich, where his butler (his butler!) served us drinks. I made an offhand joke about programming, and he chided me for not having respect for the practice. He told me: 'To be successful in this business, you have to think about it all the time. Lots of people in this business are very smart, but not everyone can think about it all the time.' These words - you have to think about it all the time - made a deep impression on me. Peterffy's phrase has pretty much become my motto - at least, it's one of them. At the time, I was struck by how simple and obvious it was. In fact, it was exactly what I did when I was faced with a complex programming challenge.”&lt;/p&gt;
      &lt;p&gt;Igor Tulchinsky, talking about how he came to work at Timber Hill (a Connecticut prop trading firm) in The Unrules&lt;/p&gt;
      &lt;p&gt;"Intentionally isolated, he said, 'a quiet oasis of serenity.'&lt;/p&gt;
      &lt;p&gt;Serene for him, maybe, but his personality mangled whatever peace the rest of them could have enjoyed. The place was suffused with Gross's clinical insecurity that someone might catch up, that someone might threaten Pimco's dominance.&lt;/p&gt;
      &lt;p&gt;No moment wasted, no dollar left unsqueezed. This was the dominant culture, trickled down from the trade floor: Gross's 'Pimbots' ground their teeth in their sleep and woke up screaming: their marriages and livers disintegrated. It was precisely that they were so intensely obsessive, going beyond what everyone else did, that made them so great, they had to convince themselves...&lt;/p&gt;
      &lt;p&gt;Failure to deliver wasn't tolerated. Pimco would sniff out anyone's weakness."&lt;/p&gt;
      &lt;p&gt;Mary Childs discussing Bill Gross’s decision to locate Pimco in Newport Beach, in The Bond King&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;&lt;lb/&gt; And finally, a quote that hits the nail on the head - even though it doesn’t come from a trader:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;"A man has to live and sleep with his business if he wants to make a go of it. You have to take it home with you at night, so you can lie there in the darkness and figure out what you can do to improve it. In fact, you have to become sort of a 'nut' about it, so that you become so enthused that you will bore your friends talking about it. You have to be a one-man crusade."&lt;/p&gt;
      &lt;p&gt;George Mecherle’s answer to the question, “what is the secret of your success?”, in The Farmer from Merna&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Nassim Taleb once said, "unless you're a trader, don't trade. Unless you're a baker, don't bake. Unless you're a dynamite maker, don't make dynamite." I think unless you can see yourself in at least some of those quotes, you probably shouldn’t be a trader.&lt;/p&gt;
    &lt;p&gt;I once spent a huge amount of effort on something in which I had zero natural talent.&lt;/p&gt;
    &lt;p&gt;I started playing rugby at seven years old. I was always pretty useless, but I always tried really hard. I remember deciding age 12 that I wanted to be better, so one day, at my (boarding) prep school, I woke up early, got a tackle bag, and started doing tackle practice - on my own, at 7am. A teacher walked by, and said ‘what are you doing?’ Slightly sheepishly, I packed up the bag and went back inside. I didn’t get picked to go on the rugby tour, and never played for the U13 A team. When I went to secondary school, I was, again, rubbish - I think at one point I played for the U14 D team. And then, in October 2014, Bath, my favourite rugby union team, signed Sam Burgess: the Yorkshire-born Australian rugby league star. I watched his documentary on YouTube, and it changed my life. The Russell Crowe narration at the start made a huge impression on me:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“Now I have this theory about a certain kind of player. Like a Ron Coote, a Steve Menzies, a Gorden Tallis. I call it the Sparkly-Eyed Man. He’s a man who can be as vicious as he needs to be over the course of eighty minutes to get a result for his team. And the moment that final whistle is blown he’s a completely different person. He’s able to laugh easily, he’s good with kids, respectful to women, and he appreciates life. Which is why he’s the Sparkly-Eyed Man. He has that thing built within him to never quit, and if you’re going to do something, you do it to the absolute utmost of your ability. Those sparkly-eyed men, they carve their names deep in Rugby League.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Sam Burgess won the 2014 NRL Grand Final with South Sydney, just before he left for Bath. He broke his cheekbone in the opening tackle of the game, was man of the match, and won the Bunnies their first premiership in 43 years.&lt;/p&gt;
    &lt;p&gt;This blew my mind. I wanted to be that guy. As a teenager, I absorbed all the sports motivational videos on YouTube. I watched this one, I watched this one, and this one above all. This stuff is burned into the back of my skull. I watched these things over and over again. I tried to figure out how to set them as an alarm.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;“When you immerse yourself in your craft, you not studying to get a grade, you’re not playing to score points, you immerse yourself in it, so you become it, you gon’ go to another level.&lt;/p&gt;&lt;lb/&gt;The most important thing is this: to be able to sacrifice yourself at any moment, to sacrifice what you are, for what you will become. Listen to me. Pain is temporary. It may last for a minute, or an hour, or a day, or even a year, but eventually it will subside. And something else will take its place. You ain’t gon’ die. At the end of pain is success! You’re not gon’ die because you’re feeling a little pain! I dare you to take a little pain. I dare you.&lt;lb/&gt;Your life is in your hand. You are the captain of your ship. You could have, you could be, you could do whatever you want to do, remember boy, if it was easy, everybody would do it. It’s what they eat, it’s what they sleep, it’s what they drink, it possesses them.”&lt;/quote&gt;
    &lt;p&gt; So I decided I was going to play for the school first XV. I had about two and a half years to get ready. Let’s be honest, there wasn’t that much pain involved in that process - not like the pain Ray Lewis, who’s quoted in the speech above, had growing up. But this was the most difficult a quest I could find. A lot of people told me I couldn’t do it - my tutor, the U16A coach, told me I’d never play for the first XV.&lt;lb/&gt; I ate so much food I vomited. I drank a gallon of milk a day. I did squats until my nose bled. Here’s me, age 16, pulling 180 at Villain Strength in Mill Hill; and age 17, squatting 140x5 in my South Sydney jersey.&lt;/p&gt;
    &lt;p&gt;And ultimately, it worked. I played a few games for the XV. I proved the doubters wrong. I achieved my goal. And I was still actually pretty useless at rugby.&lt;/p&gt;
    &lt;p&gt; I knew what it felt like to be effortlessly good at something, because I had that academically; when it came to maths tests, spelling bees, quizzes - I just had it. “Do you know how easy this is for me? Do you have any fucking idea how easy this is? This is a fucking joke! And I'm sorry you can't do this, I really am because I wouldn't have to fucking sit here and watch you fumble around and fuck it up.” In the classroom, I was Will Hunting; on the rugby pitch, I fumbled around and fucked it up. &lt;lb/&gt; It didn’t matter that I’d spent three years getting bigger and stronger and fitter and faster - I still wasn’t anywhere near the level of the players with actual talent. They could see the game, they knew how to be in the right place at the right time, they could throw the final pass - and I had spent enough time trying to be like that that I knew I never could. I spent 8 years at school with a guy who’s probably going to be an Olympic hurdler this year; he had talent. And so it didn’t matter how many Tri-Nations games I watched or how many pushups I did, because I’d never get it like they did. I had worked as hard as I could, and it wasn’t ever going to be good enough.&lt;lb/&gt; That was my Scott Alexander sweating blood experience. I learned what it felt like to stick with something. But my learning from that experience was that next time I should make sure I sweated blood working on a strength. Do more of what comes naturally.&lt;/p&gt;
    &lt;p&gt; I’ve spent the last few years trying to figure out what that is. I studied linear algebra, I read Marsilius of Padua, I wrote essays, I wrote SQL, I managed ad campaigns, I travelled the world selling software, I hired and fired a team, I tried to respond to messages in 10 seconds, I networked my way into industries and learned what makes them tick, and I raised some venture capital. Some of that felt natural; some of it didn’t. I’m still looking for what comes next. &lt;lb/&gt; I was in LA last week, on a mission to meet great people. The best person I met was the World’s Strongest Man, Martins Licis, at his gym in El Segundo. It was a complete accident; I didn’t know he was there, and I didn’t expect to work out that day. But the reason I was able to walk in and learn strongman from the best in the world was all those hours spent under a bar, squatting until my nose bled. &lt;lb/&gt; So I guess it’s ok to bake bread even if you’re not a baker - we’re all allowed hobbies. Just don’t make it your full-time job. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.felixstocker.com/blog/talent"/><published>2025-10-16T17:47:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45609922</id><title>Benjie's Humanoid Olympic Games</title><updated>2025-10-17T08:43:48.498758+00:00</updated><content/><link href="https://generalrobots.substack.com/p/benjies-humanoid-olympic-games"/><published>2025-10-16T19:51:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45610226</id><title>How I bypassed Amazon's Kindle web DRM</title><updated>2025-10-17T08:43:48.212691+00:00</updated><content>&lt;doc fingerprint="b6b8613188aad7dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How I Reversed Amazon's Kindle Web Obfuscation Because Their App Sucked&lt;/head&gt;
    &lt;p&gt;As it turns out they don't actually want you to do this (and have some interesting ways to stop you)&lt;/p&gt;
    &lt;head rend="h2"&gt;TL;DR&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I bought my first ebook from amazon&lt;/item&gt;
      &lt;item&gt;Amazon's Kindle Android app was really buggy and crashed a bunch&lt;/item&gt;
      &lt;item&gt;Tried to download my book to use with a functioning reader app&lt;/item&gt;
      &lt;item&gt;Realized Amazon no longer lets you do that&lt;/item&gt;
      &lt;item&gt;Decided to reverse engineer their obfuscation system out of spite&lt;/item&gt;
      &lt;item&gt;Discovered multiple layers of protection including randomized alphabets&lt;/item&gt;
      &lt;item&gt;Defeated all of them with font matching wizardry&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Part 1: Amazon Made This Personal&lt;/head&gt;
    &lt;head rend="h3"&gt;The One Time I Tried To Do Things The Right Way&lt;/head&gt;
    &lt;p&gt;I've been "obtaining" ebooks for years. But this ONE time, I thought: "Let's support the author."&lt;/p&gt;
    &lt;p&gt;Download Kindle app on Android. Open book.&lt;/p&gt;
    &lt;p&gt;Crash.&lt;/p&gt;
    &lt;head rend="h3"&gt;I Just Wanted To Read My Book&lt;/head&gt;
    &lt;p&gt;App crashes. Fine, I'll use the web reader.&lt;/p&gt;
    &lt;p&gt;Oh wait, can't download it for offline reading. What if I'm on a plane?&lt;/p&gt;
    &lt;p&gt;Hold on, I can't even export it to Calibre? Where I keep ALL my other books?&lt;/p&gt;
    &lt;p&gt;So let me get this straight:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I paid money for this book&lt;/item&gt;
      &lt;item&gt;I can only read it in Amazon's broken app&lt;/item&gt;
      &lt;item&gt;I can't download it&lt;/item&gt;
      &lt;item&gt;I can't back it up&lt;/item&gt;
      &lt;item&gt;I don't actually own it&lt;/item&gt;
      &lt;item&gt;Amazon can delete it whenever they want&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a rental, not a purchase.&lt;/p&gt;
    &lt;head rend="h3"&gt;It Becomes Personal&lt;/head&gt;
    &lt;p&gt;I could've refunded and "obtained" it in 30 seconds. Would've been easier.&lt;/p&gt;
    &lt;p&gt;But that's not the point.&lt;/p&gt;
    &lt;p&gt;The point is I PAID FOR THIS BOOK. It's mine. And I'm going to read it in Calibre with the rest of my library even if I have to reverse engineer their web client to do it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reversal Time&lt;/head&gt;
    &lt;p&gt;Kindle Cloud Reader (the web version) actually works. While looking through the network requests, I spotted this:&lt;/p&gt;
    &lt;code&gt;https://read.amazon.com/renderer/render
&lt;/code&gt;
    &lt;p&gt;To download anything, you need:&lt;/p&gt;
    &lt;p&gt;1. Session cookies - standard Amazon login&lt;/p&gt;
    &lt;p&gt;2. Rendering token - from the startReading API call&lt;/p&gt;
    &lt;p&gt;3. ADP session token - extra auth layer&lt;/p&gt;
    &lt;p&gt;Sending the same headers and cookies the browser does returns a TAR file.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's Inside The TAR?&lt;/head&gt;
    &lt;code&gt;page_data_0_4.json   # The "text" (spoiler: it's not text)
glyphs.json          # SVG definitions for every character
toc.json             # Table of contents
metadata.json        # Book info
location_map.json    # Position mappings&lt;/code&gt;
    &lt;head rend="h2"&gt;Part 3: Amazon's Obfuscation Layers of Ebook Hell&lt;/head&gt;
    &lt;p&gt;Downloaded the first few pages, expected to see text. Got this instead:&lt;/p&gt;
    &lt;code&gt;{
  "type": "TextRun",
  "glyphs": [24, 25, 74, 123, 91, 18, 19, 30, 4, ...],
  "style": "paragraph"
}&lt;/code&gt;
    &lt;p&gt;These aren't letters. They're glyph IDs. Character 'T' isn't Unicode 84, it's glyph 24.&lt;/p&gt;
    &lt;p&gt;And glyph 24 is just a series of numbers that define a stroke path, its just an image of a letter.&lt;/p&gt;
    &lt;p&gt;It's a substitution cipher! Each character maps to a non-sequential glyph ID.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Alphabet Changes Every. Five. Pages.&lt;/head&gt;
    &lt;p&gt;Downloaded the next batch of pages. Same letter 'T' is now glyph 87.&lt;/p&gt;
    &lt;p&gt;Next batch? Glyph 142.&lt;/p&gt;
    &lt;p&gt;They randomize the entire alphabet on EVERY request.&lt;/p&gt;
    &lt;p&gt;This means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;You can only get 5 pages at a time (API hard limit)&lt;/item&gt;
      &lt;item&gt;Each request gets completely new glyph mappings&lt;/item&gt;
      &lt;item&gt;Glyph IDs are meaningless across requests&lt;/item&gt;
      &lt;item&gt;You can't build one mapping table for the whole book&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Let Me Show You How Bad This Is&lt;/head&gt;
    &lt;p&gt;For my 920-page book:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;184 separate API requests needed&lt;/item&gt;
      &lt;item&gt;184 different random alphabets to crack&lt;/item&gt;
      &lt;item&gt;361 unique glyphs discovered (a-z, A-Z, punctuation, ligatures)&lt;/item&gt;
      &lt;item&gt;1,051,745 total glyphs to decode&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Fake Font Hints (They're Getting Sneaky)&lt;/head&gt;
    &lt;p&gt;Some SVG paths contained this garbage:&lt;/p&gt;
    &lt;code&gt;M695.068,0 L697.51,-27.954 m3,1 m1,6 m-4,-7 L699.951,-55.908 ...&lt;/code&gt;
    &lt;p&gt;Looking at it, we see these tiny &lt;code&gt;m3,1 m1,6 m-4,-7&lt;/code&gt; commands, they are micro MoveTo operations.&lt;/p&gt;
    &lt;p&gt;Why this is evil:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Browsers handle them fine (native Path2D)&lt;/item&gt;
      &lt;item&gt;Python SVG libraries create spurious connecting lines&lt;/item&gt;
      &lt;item&gt;Makes glyphs look corrupted when rendered naively&lt;/item&gt;
      &lt;item&gt;Breaks path-sampling approaches&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is deliberate anti-scraping. The glyphs render perfectly in browser but make it so we cant just compare paths in our parser.&lt;/p&gt;
    &lt;p&gt;Take a look&lt;/p&gt;
    &lt;p&gt;Eventually I figured out that filling in the complete path mitigated this.&lt;/p&gt;
    &lt;head rend="h3"&gt;Multiple Font Variants&lt;/head&gt;
    &lt;p&gt;Not just one font. FOUR variants:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;bookerly_normal (99% of glyphs)&lt;/item&gt;
      &lt;item&gt;bookerly_italic (emphasis)&lt;/item&gt;
      &lt;item&gt;bookerly_bold (headings)&lt;/item&gt;
      &lt;item&gt;bookerly_bolditalic (emphasized headings)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Plus special ligatures: ff, fi, fl, ffi, ffl&lt;/p&gt;
    &lt;p&gt;More variations = more unique glyphs to crack = more pain.&lt;/p&gt;
    &lt;head rend="h3"&gt;OCR Is Mid (My Failed Attempt)&lt;/head&gt;
    &lt;p&gt;Tried running OCR on rendered glyphs. Results:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;178/348 glyphs recognized (51%)&lt;/item&gt;
      &lt;item&gt;170 glyphs failed completely&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;OCR just sucks at single characters without context. Confused 'l' with 'I' with '1'. Couldn't handle punctuation. Gave up on ligatures entirely.&lt;/p&gt;
    &lt;p&gt;OCR probably need words and sentences to work well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Part 4: The Solution That Actually Worked&lt;/head&gt;
    &lt;p&gt;Every request includes `glyphs.json` with SVG path definitions:&lt;/p&gt;
    &lt;code&gt;{
  "24": {
    "path": "M 450 1480 L 820 1480 L 820 0 L 1050 0 L 1050 1480 ...",
    "fontFamily": "bookerly_normal"
  },
  "87": {
    "path": "M 450 1480 L 820 1480 L 820 0 L 1050 0 L 1050 1480 ...",
    "fontFamily": "bookerly_normal"
  }
}&lt;/code&gt;
    &lt;p&gt;Glyph IDs change, but SVG shapes don't.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why Direct SVG Comparison Failed&lt;/head&gt;
    &lt;p&gt;First attempt: normalize and compare SVG path coordinates.&lt;/p&gt;
    &lt;p&gt;Failed because:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Coordinates vary slightly&lt;/item&gt;
      &lt;item&gt;Path commands represented differently&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Pixel-Perfect Matching&lt;/head&gt;
    &lt;p&gt;Screw coordinate comparison. Let's just render everything and compare pixels.&lt;/p&gt;
    &lt;p&gt;1. Render every SVG as an image&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Use cairosvg (lets us handle those fake font hints correctly)&lt;/item&gt;
      &lt;item&gt;Render at 512 x 512px for accuracy&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;2. Generate perceptual hashes&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Hash each rendered image&lt;/item&gt;
      &lt;item&gt;The hash becomes the unique identifier&lt;/item&gt;
      &lt;item&gt;Same shape = same hash, regardless of glyph ID&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;3. Build normalized glyph space&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Map all 184 random alphabets to hash-based IDs&lt;/item&gt;
      &lt;item&gt;Now glyph "a1b2c3d4..." always means letter 'T'&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;4. Match to actual characters&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Download Bookerly TTF fonts&lt;/item&gt;
      &lt;item&gt;Render every character (A-Z, a-z, 0-9, punctuation)&lt;/item&gt;
      &lt;item&gt;Use SSIM (Structural Similarity Index) to match&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why SSIM Is Perfect For This&lt;/head&gt;
    &lt;p&gt;SSIM compares image structure, not pixels directly. It handles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Slight rendering differences&lt;/item&gt;
      &lt;item&gt;Anti-aliasing variations&lt;/item&gt;
      &lt;item&gt;Minor scaling issues&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For each unknown glyph, find the TTF character with highest SSIM score. That's your letter.&lt;/p&gt;
    &lt;head rend="h3"&gt;Handling The Edge Cases&lt;/head&gt;
    &lt;p&gt;Ligatures: ff, fi, fl, ffi, ffl&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;These are single glyphs for multiple characters&lt;/item&gt;
      &lt;item&gt;Had to add them to TTF library manually&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Special characters: em-dash, quotes, bullets&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extended character set beyond basic ASCII&lt;/item&gt;
      &lt;item&gt;Matched against full Unicode range in Bookerly&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Font variants: Bold, italic, bold-italic&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built separate libraries for each variant&lt;/item&gt;
      &lt;item&gt;Match against all libraries, pick best score&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Part 5: The Moment It All Worked&lt;/head&gt;
    &lt;head rend="h3"&gt;Final Statistics&lt;/head&gt;
    &lt;code&gt;=== NORMALIZATION PHASE ===
Total batches processed: 184
Unique glyphs found: 361
Total glyphs in book: 1,051,745

=== MATCHING PHASE ===
Successfully matched 361/361 unique glyphs (100.00%)
Failed to match: 0 glyphs
Average SSIM score: 0.9527

=== DECODED OUTPUT ===
Total characters: 5,623,847
Pages: 920&lt;/code&gt;
    &lt;p&gt;Perfect. Every single character decoded correctly.&lt;/p&gt;
    &lt;head rend="h3"&gt;EPUB Reconstruction With Perfect Formatting&lt;/head&gt;
    &lt;p&gt;The JSON includes positioning for every text run:&lt;/p&gt;
    &lt;code&gt;{
  "glyphs": [24, 25, 74],
  "rect": {"left": 100, "top": 200, "right": 850, "bottom": 220},
  "fontStyle": "italic",
  "fontWeight": 700,
  "fontSize": 12.5,
  "link": {"positionId": 7539}
}&lt;/code&gt;
    &lt;p&gt;I used this to preserve:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Paragraph breaks (Y-coordinate changes)&lt;/item&gt;
      &lt;item&gt;Text alignment (X-coordinate patterns)&lt;/item&gt;
      &lt;item&gt;Bold/italic styling&lt;/item&gt;
      &lt;item&gt;Font sizes&lt;/item&gt;
      &lt;item&gt;Internal links&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The final EPUB is near indistinguishable from the original!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Real Conclusion&lt;/head&gt;
    &lt;p&gt;Amazon put real effort into their web obfuscation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Was It Worth It?&lt;/head&gt;
    &lt;p&gt;To read one book? No.&lt;/p&gt;
    &lt;p&gt;To prove a point? Absolutely.&lt;/p&gt;
    &lt;p&gt;To learn about SVG rendering, perceptual hashing, and font metrics? Probably yes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Use This Knowledge Responsibly&lt;/head&gt;
    &lt;p&gt;This is for backing up books YOU PURCHASED.&lt;/p&gt;
    &lt;p&gt;Don't get me sued into oblivion thanks.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.pixelmelt.dev/kindle-web-drm/"/><published>2025-10-16T20:22:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45610523</id><title>Cloudflare Sandbox SDK</title><updated>2025-10-17T08:43:48.096502+00:00</updated><link href="https://sandbox.cloudflare.com/"/><published>2025-10-16T20:51:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45610996</id><title>Understanding Spec-Driven-Development: Kiro, Spec-Kit, and Tessl</title><updated>2025-10-17T08:43:47.759430+00:00</updated><content>&lt;doc fingerprint="be54d03324f78efb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Understanding Spec-Driven-Development: Kiro, spec-kit, and Tessl&lt;/head&gt;
    &lt;p&gt;This article is part of âExploring Gen AIâ. A series capturing Thoughtworks technologists' explorations of using gen ai technology for software development.&lt;/p&gt;
    &lt;p&gt;15 October 2025&lt;/p&gt;
    &lt;p&gt;Iâve been trying to understand one of the latest AI coding buzzword: Spec-driven development (SDD). I looked at three of the tools that label themselves as SDD tools and tried to untangle what it means, as of now.&lt;/p&gt;
    &lt;head rend="h2"&gt;Definition&lt;/head&gt;
    &lt;p&gt;Like with many emerging terms in this fast-paced space, the definition of âspec-driven developmentâ (SDD) is still in flux. Hereâs what I can gather from how I have seen it used so far: Spec-driven development means writing a âspecâ before writing code with AI (âdocumentation firstâ). The spec becomes the source of truth for the human and the AI.&lt;/p&gt;
    &lt;p&gt;GitHub: âIn this new world, maintaining software means evolving specifications. [â¦] The lingua franca of development moves to a higher level, and code is the last-mile approach.â&lt;/p&gt;
    &lt;p&gt;Tessl: âA development approach where specs â not code â are the primary artifact. Specs describe intent in structured, testable language, and agents generate code to match them.â&lt;/p&gt;
    &lt;p&gt;After looking over the usages of the term, and some of the tools that claim to be implementing SDD, it seems to me that in reality, there are multiple implementation levels to it:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Spec-first: A well thought-out spec is written first, and then used in the AI-assisted development workflow for the task at hand.&lt;/item&gt;
      &lt;item&gt;Spec-anchored: The spec is kept even after the task is complete, to continue using it for evolution and maintenance of the respective feature.&lt;/item&gt;
      &lt;item&gt;Spec-as-source: The spec is the main source file over time, and only the spec is edited by the human, the human never touches the code.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All SDD approaches and definitions Iâve found are spec-first, but not all strive to be spec-anchored or spec-as-source. And often itâs left vague or totally open what the spec maintenance strategy over time is meant to be.&lt;/p&gt;
    &lt;head rend="h2"&gt;What is a spec?&lt;/head&gt;
    &lt;p&gt;The key question in terms of definitions of course is: What is a spec? There doesnât seem to be a general definition, the closest Iâve seen to a consistent definition is the comparison of a spec to a âProduct Requirements Documentâ.&lt;/p&gt;
    &lt;p&gt;The term is quite overloaded at the moment, here is my attempt at defining what a spec is:&lt;/p&gt;
    &lt;p&gt;A spec is a structured, behavior-oriented artifact - or a set of related artifacts - written in natural language that expresses software functionality and serves as guidance to AI coding agents. Each variant of spec-driven development defines their approach to a specâs structure, level of detail, and how these artifacts are organized within a project.&lt;/p&gt;
    &lt;p&gt;There is a useful difference to be made I think between specs and the more general context documents for a codebase. That general context are things like rules files, or high level descriptions of the product and the codebase. Some tools call this context a memory bank, so thatâs what I will use here. These files are relevant across all AI coding sessions in the codebase, whereas specs only relevant to the tasks that actually create or change that particular functionality.&lt;/p&gt;
    &lt;head rend="h2"&gt;The challenge with evaluating SDD tools&lt;/head&gt;
    &lt;p&gt;It turns out to be quite time-consuming to evaluate SDD tools and approaches in a way that gets close to real usage. You would have to try them out with different sizes of problems, greenfield, brownfield, and really take the time to review and revise the intermediate artifacts with more than just a cursory glance. Because as GitHubâs blog post about spec-kit says: âCrucially, your role isnât just to steer. Itâs to verify. At each phase, you reflect and refine.â&lt;/p&gt;
    &lt;p&gt;For two of the three tools I tried it also seems to be even more work to introduce them into an existing codebase, therefore making it even harder to evaluate their usefulness for brownfield codebases. Until I hear usage reports from people using them for a period of time on a ârealâ codebase, I still have a lot of open questions about how this works in real life.&lt;/p&gt;
    &lt;p&gt;That being said - letâs get into three of these tools. I will share a description of how they work first (or rather how I think they work), and will keep my observations and questions for the end. Note that these tools are very fast evolving, so they might have already changed since I used them in September.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kiro&lt;/head&gt;
    &lt;p&gt;Kiro is the simplest (or most lightweight) one of the three I tried. It seems to be mostly spec-first, all the examples I have found use it for a task, or a user story, with no mention of how to use the requirements document in a spec-anchored way over time, across multiple tasks.&lt;/p&gt;
    &lt;p&gt;Workflow: Requirements â Design â Tasks&lt;/p&gt;
    &lt;p&gt;Each workflow step is represented by one markdown document, and Kiro guides you through those 3 workflow steps inside of its VS Code based distribution.&lt;/p&gt;
    &lt;p&gt;Requirements: Structured as a list of requirements, where each requirement represents a âUser Storyâ (in âAs aâ¦â format) with acceptance criteria (in âGIVENâ¦ WHENâ¦ THENâ¦â format)&lt;/p&gt;
    &lt;p&gt;Design: In my attempt, the design document consisted of the sections seen in the screenshot below. I only have the results of one of my attempts still, so Iâm not sure if this is a consistent structure, or if it changes depending on the task.&lt;/p&gt;
    &lt;p&gt;Tasks: A list of tasks that trace back to the requirement numbers, and that get some extra UI elements to run tasks one by one, and review changes per task.&lt;/p&gt;
    &lt;p&gt;Kiro also has the concept of a memory bank, they call it âsteeringâ. Its contents are flexible, and their workflow doesnât seem to rely on any specific files being there (I made my usage attempts before I even discovered the steering section). The default topology created by Kiro when you ask it to generate steering documents is product.md, structure.md, tech.md.&lt;/p&gt;
    &lt;head rend="h2"&gt;Spec-kit&lt;/head&gt;
    &lt;p&gt;Spec-kit is GitHubâs version of SDD. It is distributed as a CLI that can create workspace setups for a wide range of common coding assistants. Once that structure is set up, you interact with spec-kit via slash commands in your coding assistant. Because all of its artifacts are put right into your workspace, this is the most customizable one of the three tools discussed here.&lt;/p&gt;
    &lt;p&gt;Workflow: Constitution â ð Specify â Plan â Tasks ð&lt;/p&gt;
    &lt;p&gt;Spec-kitâs memory bank concept is a prerequisite for the spec-driven approach. They call it a constitution. The constitution is supposed to contain the high level principles that are âimmutableâ and should always be applied, to every change. Itâs basically a very powerful rules file that is heavily used by the workflow.&lt;/p&gt;
    &lt;p&gt;In each of the workflow steps (specify, plan, tasks), spec-kit instantiates a set of files and prompts with the help of a bash script and some templates. The workflow then makes heavy use of checklists inside of the files, to track necessary user clarifications, constitution violations, research tasks, etc. They are like a âdefinition of doneâ for each workflow step (though interpreted by AI, so there is no 100% guarantee that they will be respected).&lt;/p&gt;
    &lt;p&gt;Below is an overview to illustrate the file topology I saw in spec-kit. Note how one spec is made up of many files.&lt;/p&gt;
    &lt;p&gt;At first glance, GitHub seems to be aspiring to a spec-anchored approach (âThatâs why weâre rethinking specifications â not as static documents, but as living, executable artifacts that evolve with the project. Specs become the shared source of truth. When something doesnât make sense, you go back to the spec; when a project grows complex, you refine it; when tasks feel too large, you break them down.â) However, spec-kit creates a branch for every spec that gets created, which seems to indicate that they see a spec as a living artifact for the lifetime of a change request, not the lifetime of a feature. This community discussion is talking about this confusion. It makes me think that spec-kit is still what I would call spec-first only, not spec-anchored over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tessl Framework&lt;/head&gt;
    &lt;p&gt;(Still in private beta)&lt;/p&gt;
    &lt;p&gt;Like spec-kit, the Tessl Framework is distributed as a CLI that can create all the workspace and config structure for a variety of coding assistants. The CLI command also doubles as an MCP server.&lt;/p&gt;
    &lt;p&gt;Tessl is the only one of these three tools that explicitly aspires to a spec-anchored approach, and is even exploring the spec-as-source level of SDD. A Tessl spec can serve as the main artifact that is being maintained and edited, with the code even marked with a comment at the top saying &lt;code&gt;// GENERATED FROM SPEC - DO NOT EDIT&lt;/code&gt;. This is currently a 1:1 mapping between spec and code files, i.e. one spec translates into one file in the codebase. But Tessl is still in beta and they are experimenting with different versions of this, so I can imagine that this approach could also be taken on a level where one spec maps to a code component with multiple files. It remains to be seen what the alpha product will support. (The Tessl team themselves see their framework as something that is more in the future than their current public product, the Tessl Registry.)&lt;/p&gt;
    &lt;p&gt;Here is an example of a spec that I had the Tessl CLI reverse engineer (&lt;code&gt;tessl document --code ...js&lt;/code&gt;) from a JavaScript file in an existing codebase:&lt;/p&gt;
    &lt;p&gt;Tags like &lt;code&gt;@generate&lt;/code&gt; or &lt;code&gt;@test&lt;/code&gt; seem to tell Tessl what to generate. The API section shows the idea of defining at least the interfaces that get exposed to other parts of the codebase in the spec, presumably to make sure that these more crucial parts of the generated component are fully under the control of the maintainer. Running &lt;code&gt;tessl build&lt;/code&gt; for this spec generates the corresponding JavaScript code file.&lt;/p&gt;
    &lt;p&gt;Putting the specs for spec-as-source at a quite low abstraction level, per code file, probably reduces amount of steps and interpretations the LLM has to do, and therefore the chance of errors. Even at this low abstraction level I have seen the non-determinism in action though, when I generated code multiple times from the same spec. It was an interesting exercise to iterate on the spec and make it more and more specific to increase the repeatability of the code generation. That process reminded me of some of the pitfalls and challenges of writing an unambiguous and complete specification.&lt;/p&gt;
    &lt;head rend="h2"&gt;Observations and questions&lt;/head&gt;
    &lt;p&gt;These three tools are all labelling themselves as implementations of spec-driven development, but they are quite different from each other. So thatâs the first thing to keep in mind when talking about SDD, it is not just one thing.&lt;/p&gt;
    &lt;head rend="h3"&gt;One workflow to fit all sizes?&lt;/head&gt;
    &lt;p&gt;Kiro and spec-kit provide one opinionated workflow each, but Iâm quite sure that neither of them is suitable for the majority of real life coding problems. In particular, itâs not quite clear to me how they would cater to enough different problem sizes to be generally applicable.&lt;/p&gt;
    &lt;p&gt;When I asked Kiro to fix a small bug (it was the same one I used in the past to try Codex), it quickly became clear that the workflow was like using a sledgehammer to crack a nut. The requirements document turned this small bug into 4 âuser storiesâ with a total of 16 acceptance criteria, including gems like âUser story: As a developer, I want the transformation function to handle edge cases gracefully, so that the system remains robust when new category formats are introduced.â&lt;/p&gt;
    &lt;p&gt;I had a similar challenge when I used spec-kit, I wasnât quite sure what size of problem to use it for. Available tutorials are usually based on creating an application from scratch, because thatâs easiest for a tutorial. One of the use cases I ended up trying was a feature that would be a 3-5 point story on one of my past teams. The feature depended on a lot of code that was already there, it was supposed to build an overview modal that summarised a bunch of data from an existing dashboard. With the amount of steps spec-kit took, and the amount of markdown files it created for me to review, this again felt like overkill for the size of the problem. It was a bigger problem than the one I used with Kiro, but also a much more elaborate workflow. I never even finished the full implementation, but I think in the same time it took me to run and review the spec-kit results I could have implemented the feature with âplainâ AI-assisted coding, and I would have felt much more in control.&lt;/p&gt;
    &lt;p&gt;An effective SDD tool would at the very least have to provide flexibility for a few different core workflows, for different sizes and types of changes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Reviewing markdown over reviewing code?&lt;/head&gt;
    &lt;p&gt;As just mentioned, and as you can see in the description of the tool above, spec-kit created a LOT of markdown files for me to review. They were repetitive, both with each other, and with the code that already existed. Some contained code already. Overall they were just very verbose and tedious to review. In Kiro it was a little easier, as you only get 3 files, and itâs more intuitive to understand the mental model of ârequirements &amp;gt; design &amp;gt; tasksâ. However, as mentioned, Kiro also was way too verbose for the small bug I was asking it to fix.&lt;/p&gt;
    &lt;p&gt;To be honest, Iâd rather review code than all these markdown files. An effective SDD tool would have to provide a very good spec review experience.&lt;/p&gt;
    &lt;head rend="h3"&gt;False sense of control?&lt;/head&gt;
    &lt;p&gt;Even with all of these files and templates and prompts and workflows and checklists, I frequently saw the agent ultimately not follow all the instructions. Yes, the context windows are now larger, which is often mentioned as one of the enablers of spec-driven development. But just because the windows are larger, doesnât mean that AI will properly pick up on everything thatâs in there.&lt;/p&gt;
    &lt;p&gt;For example: Spec-kit has a research step somewhere during planning, and it did a lot of research on the existing code and whatâs already there, which was great because I asked it to add a feature that built on top of existing code. But ultimately the agent ignored the notes that these were descriptions of existing classes, it just took them as a new specification and generated them all over again, creating duplicates. But I didnât only see examples of ignoring instructions, I also saw the agent go way overboard because it was too eagerly following instructions (e.g. one of the constitution articles).&lt;/p&gt;
    &lt;p&gt;The past has shown that the best way for us to stay in control of what weâre building are small, iterative steps, so Iâm very skeptical that lots of up-front spec design is a good idea, especially when itâs overly verbose. An effective SDD tool would have to cater to an iterative approach, but small work packages almost seem counter to the idea of SDD.&lt;/p&gt;
    &lt;head rend="h3"&gt;How to effectively separate functional from technical spec?&lt;/head&gt;
    &lt;p&gt;It is a common idea in SDD to be intentional about the separation between functional spec and technical implementation. The underlying aspiration I guess is that ultimately, we could have AI fill in all the solutioning and details, and switch to different tech stacks with the same spec.&lt;/p&gt;
    &lt;p&gt;In reality, when I was trying spec-kit, I frequently got confused when to stay on the functional level, and when it was time to add technical details. The tutorial and documentation also werenât quite consistent with it, there seem to be different interpretations of what âpurely functionalâ really means. And when I think back on the many, many user stories Iâve read in my career that werenât properly separating requirements from implementation, I donât think we have a good track record as a profession to do this well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Who is the target user?&lt;/head&gt;
    &lt;p&gt;Many of the demos and tutorials for spec-driven development tools include things like defining product and feature goals, they even incorporate terms like âuser storyâ. The idea here might be to use AI as an enabler for cross-skilling, and have developers participate more heavily in requirements analysis? Or have developers pair with product people when they work on this workflow? None of this is made explicit though, itâs presented as a given that a developer would do all this analysis.&lt;/p&gt;
    &lt;p&gt;In which case I would ask myself again, what problem size and type is SDD meant for? Probably not for large features that are still very unclear, as surely that would require more specialist product and requirements skills, and lots of other steps like research and stakeholder involvement?&lt;/p&gt;
    &lt;head rend="h3"&gt;Spec-anchored and spec-as-source: Are we learning from the past?&lt;/head&gt;
    &lt;p&gt;While many people draw analogies between SDD and TDD or BDD, I think another important parallel to look at for spec-as-source in particular is MDD (model-driven development). I worked on a few projects at the beginning of my career that heavily used MDD, and I kept being reminded about that when I was trying out the Tessl Framework. The models in MDD were basically the specs, albeit not in natural language, but expressed in e.g. custom UML or a textual DSL. We built custom code generators to turn those specs into code.&lt;/p&gt;
    &lt;p&gt;Ultimately, MDD never took off for business applications, it sits at an awkward abstraction level and just creates too much overhead and constraints. But LLMs take some of the overhead and constraints of MDD away, so there is a new hope that we can now finally focus on writing specs and just generate code from them. With LLMs, we are not constrained by a predefined and parseable spec language anymore, and we donât have to build elaborate code generators. The price for that is LLMsâ non-determinism of course. And the parseable structure also had upsides that weâre losing now: We could provide the spec author with a lot of tool support to write valid, complete and consistent specs. I wonder if spec-as-source, and even spec-anchoring, might end up with the downsides of both MDD and LLMs: Inflexibility and non-determinism.&lt;/p&gt;
    &lt;p&gt;To be clear, Iâm not nostalgic about my MDD experience in the past and saying âwe might as well bring that backâ. But we should look to code-from-spec attempts in the past to learn from them when we explore spec-driven today.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;In my personal usage of AI-assisted coding, I also often spend time on carefully crafting some form of spec first to give to the coding agent. So the general principle of spec-first is definitely valuable in many situations, and the different approaches of how to structure that spec are very sought after. They are among the top most frequently asked questions I hear at the moment from practitioners: âHow do I structure my memory bank?â, âHow do I write a good specification and design document for AI?â.&lt;/p&gt;
    &lt;p&gt;But the term âspec-driven developmentâ isnât very well defined yet, and itâs already semantically diffused. Iâve even recently heard people use âspecâ basically as a synonym for âdetailed promptâ.&lt;/p&gt;
    &lt;p&gt;Regarding the tools Iâve tried, I have listed many of my questions about their real world usefulness here. I wonder if some of them are trying to feed AI agents with our existing workflows too literally, ultimately amplifying existing challenges like review overload and hallucinations. Especially with the more elaborate approaches that create lots of files, I canât help but think of the German compound word âVerschlimmbesserungâ: Are we making something worse in the attempt of making it better?&lt;/p&gt;
    &lt;p&gt;latest article (Oct 15):&lt;/p&gt;
    &lt;p&gt;Understanding Spec-Driven-Development: Kiro, spec-kit, and Tessl&lt;/p&gt;
    &lt;p&gt;previous article:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://martinfowler.com/articles/exploring-gen-ai/sdd-3-tools.html"/><published>2025-10-16T21:36:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45611735</id><title>America’s semiconductor boom [video]</title><updated>2025-10-17T08:43:46.938249+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=T-jt3qBzJ4A"/><published>2025-10-16T23:05:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45611851</id><title>Lead Limited Brain and Language Development in Neanderthals and Other Hominids?</title><updated>2025-10-17T08:43:46.423510+00:00</updated><content>&lt;doc fingerprint="55d430bd19b98b9f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Did Lead Limit Brain and Language Development in Neanderthals and Other Extinct Hominids?&lt;/head&gt;
    &lt;p&gt;Ancient human relatives were exposed to lead up to two million years ago, according to a new study. However, a gene mutation may have protected modern human brains, allowing language to flourish.&lt;/p&gt;
    &lt;head rend="h2"&gt;Story by:&lt;/head&gt;
    &lt;head rend="h2"&gt;Published Date&lt;/head&gt;
    &lt;head rend="h2"&gt;Story by:&lt;/head&gt;
    &lt;head rend="h2"&gt;Topics covered:&lt;/head&gt;
    &lt;head rend="h2"&gt;Share This:&lt;/head&gt;
    &lt;head rend="h2"&gt;Article Content&lt;/head&gt;
    &lt;p&gt;What set the modern human brain apart from our now extinct relatives like Neanderthals? A new study by University of California San Diego School of Medicine and an international team of researchers reveals that ancient hominids — including early humans and great apes — were exposed to lead earlier than previously thought, up to two million years before modern humans began mining the metal. This exposure may have shaped the evolution of hominid brains, limiting language and social development in all but modern humans due to a protective genetic variant that only we carry. The study was published in Science Advances on October 15, 2025.&lt;/p&gt;
    &lt;p&gt;The researchers analyzed fossilized teeth from 51 hominids across Africa, Asia and Europe, including modern and archaic humans such as Neanderthals, ancient human ancestors like Australopithecus africanus, and extinct great apes such as Gigantopithecus blacki.&lt;/p&gt;
    &lt;p&gt;They detected lead in 73% of the specimens, including 71% of modern and archaic humans. Notably, G. blacki fossils dating back 1.8 million years showed the most frequent acute lead exposure.&lt;/p&gt;
    &lt;p&gt;It’s long been assumed that humans have been exposed to harmful amounts of lead since antiquity — when the Romans used lead pipes to transport water — and that lead contamination increased significantly during the Industrial Revolution, only to be curtailed during the late twentieth century.&lt;/p&gt;
    &lt;p&gt;“We stopped using lead in our daily lives when we realized how toxic it is, but nobody had ever studied lead in prehistory,” said corresponding author Alysson Muotri, Ph.D., professor of pediatrics and cellular &amp;amp; molecular medicine at UC San Diego School of Medicine, associate director of the Archealization Center and director of the Sanford Integrated Space Stem Cell Orbital Research Center.&lt;/p&gt;
    &lt;p&gt;Surprisingly, teeth from people born between the 1940s and 1970s — when children were exposed to leaded gasoline and paint — showed similar patterns of lead exposure to fossilized human teeth.&lt;/p&gt;
    &lt;p&gt;The team hypothesizes that, like the Romans, ancient humans and other hominids may have been exposed to lead because of their need for water.&lt;/p&gt;
    &lt;p&gt;“One possibility is that they were looking for caves with running water inside,” Muotri said. “Caves contain lead, so they were all contaminated. Based on the tooth enamel studies, it started very early in infancy.”&lt;/p&gt;
    &lt;p&gt;Lead exposure impedes brain development, leading to deficits in intelligence and difficulties with emotional regulation.&lt;/p&gt;
    &lt;p&gt;Given these findings, Muotri and his team wondered how the modern human brain had flourished despite exposure to lead during our evolution.&lt;/p&gt;
    &lt;head rend="h3"&gt;A tiny genetic change&lt;/head&gt;
    &lt;p&gt;A gene called neuro-oncological ventral antigen 1 (NOVA1) plays a central role in human brain development and synapse formation. Considered the master regulator of neurodevelopment, NOVA1 controls how neural progenitor cells respond to lead. Disruption of NOVA1 activity is linked to several neurological disorders.&lt;/p&gt;
    &lt;p&gt;Most modern humans have a variant of NOVA1 gene that differs by a single DNA base pair from the ancestral version that was present in Neanderthals. Previous work by Muotri and his colleagues showed that replacing the human NOVA1 variant with the archaic variant resulted in significant changes to the architecture and synaptic connectivity of tiny stem-cell-derived models of human brains called organoids.&lt;/p&gt;
    &lt;p&gt;“Everything about the organoids is identical except for that genetic variant, allowing us to ask whether that specific mutation between us and Neanderthals is giving us any advantage,” said Muotri. The archaic variant accelerated brain maturation but resulted in less complexity over time. “If all humans have this newer mutation in all corners of the world, very strong genetic pressure must have selected for it in our species.”&lt;/p&gt;
    &lt;p&gt;To explore whether environmental lead exposure influenced this selection, the team created brain organoids with both the human and archaic NOVA1 variants and exposed them to lead. They then compared the development of their cortical and thalamic neurons.&lt;/p&gt;
    &lt;p&gt;Lead exposure altered NOVA1 expression in both variants, affecting genes linked to neurodevelopmental disorders such as autism and epilepsy.&lt;/p&gt;
    &lt;p&gt;However, only the archaic NOVA1 variant changed the expression of FOXP2, a gene essential for language and speech development. People with certain FOXP2 mutations cannot produce sophisticated language.&lt;/p&gt;
    &lt;p&gt;“ These type of neurons related to complex language are susceptible to death in the archaic version of NOVA1,” said Muotri. “ The FOXP2 gene is identical between us and the Neanderthals, but it's how the gene is regulated by NOVA1 that likely contributes to language differences.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Evolutionary implications&lt;/head&gt;
    &lt;p&gt;The findings suggest that the acquisition of the modern NOVA1 variant may have protected us from the detrimental effects of lead, promoting complex language development and social cohesion. This could have given modern humans a significant evolutionary advantage over Neanderthals, even in the presence of lead contamination.&lt;/p&gt;
    &lt;p&gt;Muotri believes these results have important implications for understanding how environmental stressors shaped brain development during human evolution. He speculates that lead exposure may have contributed to the extinction of Neanderthals around 40,000 years ago.&lt;/p&gt;
    &lt;p&gt;“Language is such an important advantage, it’s transformational, it is our superpower,” said Muotri. “Because we have language, we are able to organize society and exchange ideas, allowing us to coordinate large movements. There is no evidence that Neanderthals could do that. They might have had abstract thinking, but they could not translate that to each other. And maybe the reason is because they never had a system to communicate that was as efficient as our complex language.”&lt;/p&gt;
    &lt;p&gt;Understanding how NOVA1 gene variants can affect FOXP2 expression helps elucidate the relationship between lead contamination and brain development and also sheds light on neurological conditions related to language, including speech apraxia — a condition that makes it difficult to produce speech sounds correctly — and autism.&lt;/p&gt;
    &lt;p&gt;The study's co-authors included Janaina Sena de Souza, Sandra M. Sanchez-Sanchez, Jose Oviedo, University of California San Diego; Marian Bailey and Matthew Tonge at Southern Cross University; Renaud Joannes-Boyau, Southern Cross University and University of Johannesburg; Justin W. Adams, University of Johannesburg and Monash University; Christine Austin, Manish Arora, Icahn School of Medicine at Mount Sinai, Kira Westaway, Macquarie University; Ian Moffat, Flinders University and University of Cambridge; Wei Wang and Wei Liao, Anthropology Museum of Guangxi; Yingqi Zhang, Institute of Vertebrate Paleontology and Paleoanthropology; Luca Fiorenza, Monash University and Johann Wolfgang Goethe University; Marie-Helene Moncel, Museum National d'Histoire Naturelle; Gary T. Schwartz, Arizona State University; Luiz Pedro Petroski and Roberto H. Herai, Pontifícia Universidade Católica do Paraná; Jose Oviedo, University of Arizona; and Bernardo Lemos, Harvard T. H. Chan School of Public Health.&lt;/p&gt;
    &lt;p&gt;The study was funded, in part, by the National Institutes of Health (grants R01 ES027981, P30ES023515, R01ES026033), the Australian Research Council (grant DP170101597), the National Science Foundation (grant BCS 0962564), and the The Leakey Foundation.&lt;/p&gt;
    &lt;p&gt;Disclosures: Muotri is the co-founder of and has an equity interest in TISMOO, a company specializing in genetic analysis and human brain organogenesis. The terms of this arrangement have been reviewed and approved by the University of California San Diego in accordance with its conflict-of-interest policies.&lt;/p&gt;
    &lt;head rend="h2"&gt;You May Also Like&lt;/head&gt;
    &lt;head rend="h2"&gt;Stay in the Know&lt;/head&gt;
    &lt;p&gt;Keep up with all the latest from UC San Diego. Subscribe to the newsletter today.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://today.ucsd.edu/story/did-lead-limit-brain-and-language-development-in-neanderthals-and-other-extinct-hominids"/><published>2025-10-16T23:20:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45612987</id><title>Next steps for BPF support in the GNU toolchain</title><updated>2025-10-17T08:43:46.165649+00:00</updated><content>&lt;doc fingerprint="f6499017760297a5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Next steps for BPF support in the GNU toolchain&lt;/head&gt;
    &lt;quote&gt;We're bad at marketingSupport for BPF in the kernel has been tied to the LLVM toolchain since the advent of extended BPF. There has been a growing effort to add BPF support to the GNU toolchain as well, though. At the 2025 GNU Tools Cauldron, the developers involved got together with representatives of the kernel community to talk about the state of that work and what needs to happen next.&lt;p&gt;We can admit it, marketing is not our strong suit. Our strength is writing the kind of articles that developers, administrators, and free-software supporters depend on to know what is going on in the Linux world. Please subscribe today to help us keep doing that, and so we don’t have to get good at marketing.&lt;/p&gt;&lt;/quote&gt;
    &lt;head rend="h4"&gt;Integrating BTF and CTF&lt;/head&gt;
    &lt;p&gt;The BPF type format (BTF) represents the types of kernel data structures and functions; it is used to enable BPF programs to run on multiple kernels, and by the verifier to ensure program correctness, among other uses. It is derived from the Compact C Type Format (CTF), which is a more general-purpose format that makes debugging information available for compiled programs. Nick Alcock gave a high-speed presentation of his work to reunify those two formats.&lt;/p&gt;
    &lt;p&gt;The libctf library, which works with CTF, is now able to both produce and consume BTF, he began. It can also work with an under-development "CTFv4" format that adds support for some of the trickier cases. This work is being tied into the kernel build, which would allow the creation of BTF directly when building the kernel, rather than as a separate step using the pahole utility as is done now.&lt;/p&gt;
    &lt;p&gt;There are a couple of enhancements that are needed before BTF can completely replace CTF beyond the kernel, though. A string header field is needed to be able to separate the BTF from each translation unit when the results are all combined. Some sort of agreement on a format for referring to structure members in archives (holding BTF data for multiple translation units) is required for compaction purposes. To be able to use this format in user space, there has to be a representation for floating-point data — a feature the kernel has never needed. With those in place, the extra capabilities provided by CTF would only be needed to represent huge structures (rather larger than would ever make sense in the kernel) and conflicting types with the same name. Then, GCC could create BTF for both kernel and user space, with the toolchain performing deduplication as well.&lt;/p&gt;
    &lt;p&gt;Alexei Starovoitov questioned the need for these features, saying that BTF is a kernel-specific format that does not have to support user space. José Marchesi agreed to an extent, but said that wider availability and usage of the format is needed to ensure high-quality toolchain support. Sam James asked whether BTF could represent C++ programs; the answer was that CTF is still needed for those. Handling C++ with BTF would be possible, Alcock said, with the addition of some new type codes and not much more.&lt;/p&gt;
    &lt;head rend="h4"&gt;GCC port status&lt;/head&gt;
    &lt;p&gt;Marchesi then shifted the discussion to the status of the GCC BPF backend (or "port" in GCC jargon); the goal of that project, he said, is to turn GCC into the primary compiler for BPF code. That is a relatively new objective, he added; the previous goal had been to produce something that worked at all, with no ambitions beyond that.&lt;/p&gt;
    &lt;p&gt; Starovoitov took over to communicate his highest-priority request: the addition of support for the btf_decl_tag and btf_type_tag attributes to GCC. Their absence, he said, is the biggest blocker to adoption of GCC for compilation to BPF. Pointers in the kernel can carry annotations like __rcu or __user to indicate, respectively, that the pointed-to memory is protected by read-copy-update or is located in user space. When these annotations are reflected in BTF with the requested attributes, the BPF verifier can use them to check that memory is being accessed in a valid and safe way. There are a lot of hacky workarounds in place to cope with their absence now, but Starovoitov would love to be able to replace them with proper attribute support: "&lt;quote&gt;Please do it yesterday&lt;/quote&gt;". &lt;/p&gt;
    &lt;p&gt;Notably, David Faust, who was in the session, posted a patch series adding this support the following day. Interested readers will find much more information about how these attributes work in the cover letter.&lt;/p&gt;
    &lt;p&gt;Marchesi returned to quickly go over a number of other bits of news regarding the BPF backend. There is now an extensive test suite in GCC to validate BPF compilation, which is a nice step forward. The BPF port mostly works, but there are various bugs in the compiler that still need to be addressed. It may be necessary to add support for the may_goto instruction to the assembler. And, naturally, there is the constant challenge of producing code that will not run afoul of the BPF verifier — a topic to which the group returned shortly thereafter.&lt;/p&gt;
    &lt;p&gt;The status update concluded with a request for help from the GCC community to finish getting the BPF port into shape. He and the others working on this code do not do so full time, and BPF itself is an area of active development that is hard to keep up with. A bit of assistance, he said, would enable the job to be finished sooner. Starovoitov answered that BPF developers tend to work with LLVM instead because they can get their changes accepted quickly; the GCC process is slower and harder to work with. Marchesi said that the GCC community can be strict, but it tends to be strict in the right places. Work there can take time, but the quality of the result will be excellent.&lt;/p&gt;
    &lt;head rend="h4"&gt;Verification challenges&lt;/head&gt;
    &lt;p&gt;Marchesi then moved on to the generation of code by GCC that can pass the BPF verifier. Without due care, the compiler will produce code that the verifier is unable to prove correct and which, as a result, will not be loadable into the kernel. He has been promoting the idea of a new optimization mode, -Overifiable, focused on producing verifiable code. He then introduced Eduard Zingerman, who delved more deeply into the problem.&lt;/p&gt;
    &lt;p&gt;The core challenge, Zingerman began, is that the various optimization passes made by the compiler can transform the code significantly, producing a result that is hard or impossible to verify. The verifier is a path-tracing machine, which tracks the state of the stack and registers as it steps through the code, forking its representation at each branch point. It is able to track the ranges of variables through a number of operations, but is unable to track the relationships between scalars and pointers. That inability makes itself felt in a number of ways.&lt;/p&gt;
    &lt;p&gt;For example, a programmer might write code like:&lt;/p&gt;
    &lt;quote&gt;offset = ...; if (offset &amp;lt; 42) { ptr = packet + offset; /* ... */&lt;/quote&gt;
    &lt;p&gt;If the verifier knows that the length of the data pointed to by packet is at least 42, it can determine that this pointer assignment is safe. But an optimizer might hoist some of the calculation outside of the conditional branch, producing code like:&lt;/p&gt;
    &lt;quote&gt;offset = ...; ptr = packet + offset; if (offset &amp;lt; 42) { /* ... */&lt;/quote&gt;
    &lt;p&gt;Now the verifier is not able to verify that the assignment of ptr is correct, so the code is no longer verifiable. The LLVM BPF port, he said, works around this kind of problem by injecting calls to special intrinsic functions that inhibit this kind of optimization.&lt;/p&gt;
    &lt;p&gt;Zingerman provided a couple of other examples of how optimization can break verification and the sorts of workarounds that the LLVM developers have adopted to make things work. But, he said, the strategy in the LLVM camp has been almost entirely reactive — wait until something breaks, then figure out a way to prevent it. What, he asked, is the GCC approach? Marchesi replied that, so far, there is no strategy at all, but that needs to change.&lt;/p&gt;
    &lt;p&gt;In the resulting discussion, it was suggested that the proposed new compiler flag should be -fverifiable instead, a suggestion that seemed to find general acceptance. The actual implementation of that option is a harder task, though. Nick Clifton asked whether the developers could just maintain a list of optimization passes that are known to break verification and should just be skipped. The problem with that approach, Faust said, is that the problems usually come about as the result of specific transformations within a pass that makes a number of other optimizations that are still wanted.&lt;/p&gt;
    &lt;p&gt;Marchesi added that optimization in general is needed for BPF output; among other things, programs may exceed the limits on the number of BPF instructions without it. His plan is to put the new flag in place, then start adapting the problematic optimization passes to avoid breaking verification. Clifton noted that the verifier might improve over time and accept code that is rejected now, so the compiler needs to be told which version of the verifier is being built for. Others pointed out that there are multiple verifiers in existence, complicating the situation further.&lt;/p&gt;
    &lt;p&gt;There was a brief mention of Krister Walfridsson's smtgcc tool, which is designed to catch optimization problems in general. Walfridsson, who was present, was not convinced that smtgcc would be helpful for this specific problem, though.&lt;/p&gt;
    &lt;p&gt; As the time for this extended session ran out, Clifton said that he found the whole idea of verifier-aware compilation to be a bit "&lt;quote&gt;distasteful&lt;/quote&gt;". The more that the compiler avoids verification problems, the less pressure there is on the verifier itself to fix those problems for real. Perhaps it would be better to put effort into improving the verifier instead, he suggested. Marchesi replied that the verifier exists to make it possible to load programs into the kernel and run them safely. The pressure to make that work should be shared among all parties, he said. &lt;/p&gt;
    &lt;p&gt; [Thanks to the Linux Foundation, LWN's travel sponsor, for supporting my travel to this event.]&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;BPF/Compiler support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Conference&lt;/cell&gt;
        &lt;cell&gt;GNU Tools Cauldron/2025&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Oct 8, 2025 12:29 UTC (Wed) by nix (subscriber, #2304) [Link] Posted Oct 10, 2025 16:28 UTC (Fri) by corbet (editor, #1) [Link] &lt;head&gt;No need for translation unit name header in BTF after all&lt;/head&gt;&lt;head/&gt; The video from this session is now available. &lt;head&gt;Video&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/Articles/1039827/"/><published>2025-10-17T03:13:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45613047</id><title>Meow.camera</title><updated>2025-10-17T08:43:45.778672+00:00</updated><content/><link href="https://meow.camera/"/><published>2025-10-17T03:27:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45613567</id><title>Ask HN: How to stop an AWS bot sending 2B requests/month</title><updated>2025-10-17T08:43:45.416439+00:00</updated><content>&lt;doc fingerprint="36ab5d89663230f1"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;I have been struggling with a bot– 'Mozilla/5.0 (compatible; crawler)' coming from AWS Singapore – and sending an absurd number of requests to a domain of mine, averaging over 700 requests/second for several months now. Thankfully, CloudFlare is able to handle the traffic with a simple WAF rule and 444 response to reduce the outbound traffic.&lt;/p&gt;
      &lt;p&gt;I've submitted several complaints to AWS to get this traffic to stop, their typical followup is: We have engaged with our customer, and based on this engagement have determined that the reported activity does not require further action from AWS at this time.&lt;/p&gt;
      &lt;p&gt;I've tried various 4XX responses to see if the bot will back off, I've tried 30X redirects (which it follows) to no avail.&lt;/p&gt;
      &lt;p&gt;The traffic is hitting numbers that require me to re-negotiate my contract with CloudFlare and is otherwise a nuisance when reviewing analytics/logs.&lt;/p&gt;
      &lt;p&gt;I've considered redirecting the entirety of the traffic to aws abuse report page, but at this scall, it's essentially a small DDoS network and sending it anywhere could be considered abuse in itself.&lt;/p&gt;
      &lt;p&gt;Are there others that have similar experience?&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45613567"/><published>2025-10-17T05:28:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45613667</id><title>Flight Simulator for the Brain Reveals How We Learn and Why Minds Go Off Course</title><updated>2025-10-17T08:43:45.249248+00:00</updated><content>&lt;doc fingerprint="6007903d319b8b18"&gt;
  &lt;main&gt;
    &lt;p&gt;New computer model helps reveal how the brain both adapts and misfires, laying the groundwork for more precise treatments for mental health disorders&lt;/p&gt;
    &lt;head rend="h1"&gt;A ‘Flight Simulator’ for the Brain Reveals How We Learn—and Why Minds Sometimes Go Off Course&lt;/head&gt;
    &lt;p&gt;Every day, your brain makes thousands of decisions under uncertainty. Most of the time, you guess right. When you don’t, you learn. But when the brain’s ability to judge context or assign meaning falters, thoughts and behavior can go astray. In psychiatric disorders ranging from attention-deficit/hyperactivity disorder to schizophrenia, the brain may misjudge how much evidence to gather before acting—or fail to adjust when the rules of the world change based on new information.&lt;/p&gt;
    &lt;p&gt;“Uncertainty is built into the brain’s wiring,” says Michael Halassa, a professor of neuroscience at Tufts University School of Medicine. “Picture groups of neurons casting votes—some optimistic, some pessimistic. Your decisions reflect the average.” When that balance skews, the brain can misread the world: assigning too much meaning to random events, as in schizophrenia, or becoming stuck in rigid patterns, as in obsessive-compulsive disorder.&lt;/p&gt;
    &lt;p&gt;Understanding those misfires has long challenged scientists, says Halassa. “The brain speaks the language of single neurons. But fMRI—the tool we use to study brain activity in people—tracks blood flow, not the electrical chatter of individual brain cells.”&lt;/p&gt;
    &lt;p&gt;Bridging that gap means combining insights from single-cell studies in animals, human brain imaging, and behavior. Now, a new kind of computer model—grounded in real biology—lets researchers simulate how brain circuits make decisions and adapt when the rules change.&lt;/p&gt;
    &lt;p&gt;Called CogLinks, the model builds biological realism into its design, mirroring how real brain cells are connected and coding for how they assign value to often ambiguous and incomplete observations about the external environment. Unlike many artificial intelligence systems that act like “black boxes,” CogLinks shows researchers exactly how its virtual neurons link structure to function. As a result, scientists can map how this virtual brain learns from experience and pivots based on new information.&lt;/p&gt;
    &lt;p&gt;In a study published October 16 in Nature Communications, senior author Halassa and colleagues at Massachusetts Institute of Technology (MIT) used CogLinks to explore how brain circuits coordinate flexible thinking. Like a flight simulator for the brain, CogLinks let the researchers test what happens when key decision-making circuits go off course. When they weakened the virtual connection between two simulated brain regions—the prefrontal cortex and the mediodorsal thalamus—the system defaulted to slower, habit-driven learning. That result suggests this pathway is essential for adaptability.&lt;/p&gt;
    &lt;p&gt;To see if those predictions held true in people, the team then conducted a companion fMRI study, which was supervised by both Burkhard Pleger from the Ruhr-University Bochum and Halassa. Volunteers played a game in which the rules unexpectedly changed. As expected, the prefrontal cortex handled planning and the deep, central region of the brain known as the striatum guided habits—but the mediodorsal thalamus lit up when players realized the rules had shifted and adjusted their strategy.&lt;/p&gt;
    &lt;p&gt;The imaging confirmed what the model had forecast: the mediodorsal thalamus acts as a switchboard linking the brain’s two main learning systems—flexible and habitual—helping the brain infer when context has changed and switch strategies accordingly.&lt;/p&gt;
    &lt;p&gt;Halassa hopes the research helps lay the groundwork for a new kind of “algorithmic psychiatry,” in which computer models help reveal how mental illness emerges from changes in brain circuits, identifying biological markers to precisely target treatments.&lt;/p&gt;
    &lt;p&gt;“One of the big questions in psychiatry is how to connect what we know about genetics to cognitive symptoms,” says Mien Brabeeba Wang, the lead author of the CogLinks study, a co-author of the fMRI study, and an MIT doctoral student in Halassa’s lab.&lt;/p&gt;
    &lt;p&gt;“Many schizophrenia-linked mutations affect chemical receptors found throughout the brain,” says Wang. “Future uses of CogLinks may help us see how those widespread molecular changes could make it harder for the brain to organize information for flexible thinking.”&lt;/p&gt;
    &lt;p&gt;Citation: Research reported in the CogLinks study was supported by the National Institutes of Health’s National Institute of Mental Health under grants P50MH132642, R01MH134466, and R01MH120118 and by the National Science Foundation under grants CCR-2139936, CCR-2003830, and CCF-1810758. Bin A. Wang of South China Normal University served as lead author on the fMRI study. The fMRI study was supported by the National Natural Science Foundation of China; Research Center for Brain Cognition and Human Development, Guandong, China; Guangdong Basic and Applied Basic Research Foundation; Deutsche Forschungsgemeinschaft (DFG, German Research Foundation); and the FoRUM grant.&lt;/p&gt;
    &lt;p&gt;Complete information on authors, funders, methodology, limitations, and conflicts of interest is available in the published paper.&lt;/p&gt;
    &lt;p&gt;Disclaimer: The content is solely the responsibility of the authors and does not necessarily represent the official views of the funders.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://now.tufts.edu/2025/10/16/flight-simulator-brain-reveals-how-we-learn-and-why-minds-sometimes-go-course"/><published>2025-10-17T05:51:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45614148</id><title>4Chan Lawyer publishes Ofcom correspondence. Irony is overwhelming</title><updated>2025-10-17T08:43:40.195043+00:00</updated><content>&lt;doc fingerprint="26789b590171bc2f"&gt;
  &lt;main&gt;
    &lt;p&gt;Ofcom â driven by the letter of British law that they are bound to follow, but still Ofcom â are quietly making Britain look (a) very silly and (b) as if we haven’t yet shucked-off the American Revolution, let alone colonialism.&lt;/p&gt;
    &lt;head rend="h3"&gt;What’s Happened Now?&lt;/head&gt;
    &lt;p&gt;Preston Byrne, lawyer for 4Chan, has published the (apparently full) correspondence between himself and Ofcom from the past few months, the smoking gun of which is the Ofcom Confirmation Decision, where Ofcom notes: (to summarise)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The Act explicitly grants Ofcom the legal authority to regulate online safety for individuals in the United Kingdom, and this expressly includes conducting investigations into, and imposing penalties for, non-compliance by providers of online services with their duties under the Act. [â¦] The Act expressly anticipates that it will have extra-territorial effect, stating at section 204(1) of the Act [â¦] This does not mean that the Act extends to all use of in-scope services globally. [â¦] âThe duties extend only to the design, operation and use of the service in the UK and, for duties expressed to apply in relation to âusersâ, as it affects the UK users of the serviceâ&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;My lived experience of Ofcom people makes me believe that this is a reflection of what they actually think they can and should be doing â I would love to be generous and suggest that this boilerplate reflects them politely throwing parliament under a bus for passing such a prima-facie dreadfully drafted and over-reaching law as the Online Safety Actâ¦ but I’m not convinced that Ofcom don’t actually believe some form of “we can do this! we are the little regulator who can bring law to the internet!” â hoping that smooth patter and soft power will provide them with outsize leverage.&lt;/p&gt;
    &lt;p&gt;Oh, andâ¦ having declared British jurisdictional powers to enforce against an American company in America thereby flouting American law, they then demand that American law protects them from counter-lawsuits, not to mention also claiming that 4Chan does not have jurisdiction over Ofcom:&lt;/p&gt;
    &lt;head rend="h3"&gt;What happens next?&lt;/head&gt;
    &lt;p&gt;Alas, global politics are a very big pond, and Ofcom (and Britain in general) is a much smaller fish than it likes to imagine.&lt;/p&gt;
    &lt;p&gt;As I have written previously, this will not end well: I cannot imagine the US judiciary nor administration supporting so flagrant a flouting of US sovereignty, although Britain will be spinning hard to minimise the noise in the media.&lt;/p&gt;
    &lt;p&gt;However: when eventually / having been proven not to be able to enforce against 4Chan and the Global Internet, the minds behind the Online Safety Act will start to press for a Great Firewall of Britain to protect our children from these profane and insufficiently regulated websites â which is curious if you think about it for a moment.&lt;/p&gt;
    &lt;p&gt;It’s not as if 4Chan is stealing across our borders in the dead of night to infect delicate British childrens’ minds with shitposting, porn and badly-drawn cartoons of frogs. From my perspective more damage has been wrought to British culture by the Disneyification of Winnie-the-Pooh (big fan of EH Shephard here) than by 4Chan.&lt;/p&gt;
    &lt;p&gt;And of course once/if the Great British Firewall (“White Cliffs of Cyber?”) is built, then we’ll be rediscovering that:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The kids already know how to use VPNs to circumvent firewalls&lt;/item&gt;
      &lt;item&gt;The Streisand Effect dictates that more kids will have gone to look at 4Chan because the Government is trying to stop them&lt;/item&gt;
      &lt;item&gt;The impotent child-protection (and national security) interests will be demanding even more loudly that digital identity be required to even look at the pot of filth that is the internet&lt;/item&gt;
      &lt;item&gt;Investing in regulation rather than education will have made everything much, much worse&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The way we protect British kids from the Internet is to make better and more capable Britons, rather than to try and kidproof the entire internet.&lt;/p&gt;
    &lt;p&gt;The least bad thing that Ofcom and the Government could do is to quietly let the matter drop whilst focusing on education.&lt;/p&gt;
    &lt;head rend="h3"&gt;Links to Other Coverage&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;https://reclaimthenet.org/uk-ofcom-claims-first-amendment-cant-shield-americans&lt;/item&gt;
      &lt;item&gt;https://www.public.news/p/starmer-breaks-promise-to-trump-in (partial paywall)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Links to Original Source Material&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First-Notice-2-1.pdf&lt;/item&gt;
      &lt;item&gt;4chan-community-support-LLC-non-responder-1.pdf&lt;/item&gt;
      &lt;item&gt;Second-Notice-2-1.pdf&lt;/item&gt;
      &lt;item&gt;Provisional-Decision-1.pdf&lt;/item&gt;
      &lt;item&gt;Preston-Byrne-Mail-Confirmation-Decision_-Investigation-into-4chan-Community-Support-LLCs-failure-to-comply-with-two-statutory-information-requests-A-2.pdf&lt;/item&gt;
      &lt;item&gt;4chan-Cover-Letter-1.pdf&lt;/item&gt;
      &lt;item&gt;4chan-Confirmation-Decision-1-1.pdf&lt;/item&gt;
      &lt;item&gt;Preston-Byrne-Mail-Confirmation-Decision_-Investigation-into-4chan-Community-Support-LLCs-failure-to-comply-with-two-statutory-information-requests-B-2.pdf&lt;/item&gt;
      &lt;item&gt;Preston-Byrne-Mail-Fwd_-Provisional-Decision_-Investigation-into-4chan-Community-Support-LLCs-failure-to-comply-with-two-statutory-information-requests-1.pdf&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alecmuffett.com/article/117792"/><published>2025-10-17T07:31:58+00:00</published></entry></feed>