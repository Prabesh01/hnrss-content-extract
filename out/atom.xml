<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-11T21:09:13.966493+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45887699</id><title>The Department of War just shot the accountants and opted for speed</title><updated>2025-11-11T21:09:22.737283+00:00</updated><content>&lt;doc fingerprint="af10d90e6c2f8fca"&gt;
  &lt;main&gt;
    &lt;p&gt;Last week the Department of War finally killed the last vestiges of Robert McNamara’s 1962 Planning, Programming, and Budgeting System (PPBS).&lt;/p&gt;
    &lt;p&gt;The DoW has pivoted from optimizing cost and performance to delivering advanced weapons at speed. Taking decades to deliver weapons is no longer an option. The DoW has joined the 21st century and adopted Lean Methodology.&lt;/p&gt;
    &lt;p&gt;Two organizations ought to be very concerned – China and the defense prime contractors.&lt;/p&gt;
    &lt;p&gt;Secretary of War Pete Hegseth unveiled the biggest changes in 60 years of how the Department of War (DoW) plans for and buys weapons and services. These changes aren’t a minor attempt at reform. It’s a top-to-bottom transformation of how the DoW plans and buys weapons, moving from contracts that prioritize how much a weapon costs to how fast it can be delivered.&lt;/p&gt;
    &lt;p&gt;Instead of buying custom-designed weapons, the DoW will prioritize buying off-the-shelf things that already exist, and using fast-track acquisition processes, rather than the cumbersome existing Federal Acquisition Regulations. To manage all of this, they are reorganizing the entire Acquisition ecosystem across the Services. These changes implement every piece of good advice the DoD had gotten in the last decade and had previously ignored.&lt;/p&gt;
    &lt;p&gt;The DoW is being redesigned to now operate at the speed of Silicon Valley, delivering more, better, and faster. Our warfighters will benefit from the innovation and lower cost of commercial technology, and the nation will once again get a military second to none.&lt;/p&gt;
    &lt;p&gt;It’s big, bold and brave and long overdue.&lt;/p&gt;
    &lt;p&gt;Background&lt;lb/&gt; In 1962 Robert McNamara, the then-Secretary of Defense (and ex CFO of Ford), discovered he had inherited a Defense Department whose spending was out of control. During the 1950s the Air Force built five different types of fighter planes, three generations of bombers, and three generations of ICBMs. The Navy had created a fleet of nuclear-powered attack and ballistic missile submarines and aircraft carriers. The Army bought three generations of its own nuclear-capable missile systems. Many of these systems duplicated capabilities of other services. But most importantly, the Services, in their rush to buy new technology, hadn’t adequately budgeted for the cost of operating, training, maintaining, and sustaining what they had bought. &lt;/p&gt;
    &lt;p&gt;In response, Secretary McNamara imposed the discipline of a Chief Financial Officer. He put in place a formal system of Planning (capability gaps, risks, scenarios, threats assumptions), Programming (5-year plans, affordability, quantities, phasing, unit fielding plans) and Budgeting that has lasted 60+ years. An entire defense university was created to train tens of thousands of contracting officers how to follow the detailed rules. Large contractors (the Primes) learned to work with this paperwork-heavy Defense acquisition system and lived with the very long time it took the DoD to buy.&lt;/p&gt;
    &lt;p&gt;The Problem&lt;lb/&gt; This unwieldy and lethargic acquisition system was adequate for over half a century when our adversary was the Soviet Union who had an equally complex acquisition system, or ISIS and Al Qaida who had none.&lt;/p&gt;
    &lt;p&gt;However, in the last decade it became painfully obvious that our acquisition system was broken and no longer worked for the world we lived in. Our existing defense industrial base suffers from schedule overruns and huge backlogs; cost increases have become the norm. We’ve been outpaced by adversaries. China, for example, implemented a much more agile system that delivered weapons in a fraction of the time it took us.&lt;/p&gt;
    &lt;p&gt;We needed a defense industrial base we could count on to scale in a crisis rather than one that will wait for money before taking action.&lt;/p&gt;
    &lt;p&gt;The war in Ukraine showed that even a small country could produce millions of drones a year while continually iterating on their design to match changes on the battlefield. (Something we couldn’t do.) Meanwhile, commercial technology from startups and scaleups (fueled by an immense pool of private capital) has created off-the-shelf products, many unmatched by our federal research development centers or primes, that can be delivered at a fraction of the cost/time. But the DoW acquisition system was impenetrable to startups.&lt;/p&gt;
    &lt;p&gt;Our Acquisition system was paralyzed by our own impossible risk thresholds, its focus on process not outcomes, and became risk averse and immoveable.&lt;/p&gt;
    &lt;p&gt;We needed an acquisition system that could deliver needed things faster.&lt;/p&gt;
    &lt;p&gt;Reminder: What Did Our Acquisition System Look Like Until Last Week?&lt;lb/&gt; The Army, Navy, Air Force, Marines and Space Force train soldiers, sailors and airmen, and specify and buy the weapons for their Service. (It’s the Combatant Commands, e.g. INDOPACOM, CENTCOM, etc., who fight the wars.)&lt;/p&gt;
    &lt;p&gt;One of the confusing things about Acquisition in the DoW is that it is more than just the buyers of equipment. In the DoW Acquisition with capital “A”, includes the entire end-to-end process – from concept, requirements, prototyping, testing, buying it, to using it and maintaining it.&lt;/p&gt;
    &lt;p&gt;In each of the Services, the current Acquisition system started with a group that forecast what the Service would need in the future and wrote requirements for future weapons/services/software. This process could take a year or more. Next, Service laboratories developed the technology, tested prototypes and concepts. This could take 3 to 6 years. Next, a vendor was selected and began to prototype and refine the systems. This added another 3 to 4 years. Finally, the system was ready to be built and delivered. It could take 1 to 2 years to deliver weapons in low rate production, or 5 to 10 years for something complex (e.g. aircraft, ships, spacecraft). In the system we’re replacing the time from when a need was turned into a requirement to delivery of a weapon would take 8 to 16 years. As you can imagine, given the rate of change of current technology and new warfighting concepts our own Acquisition process was an obstacle to building a modern War Department.&lt;/p&gt;
    &lt;p&gt;As an example, the Army’s current Acquisition system has 32,000 civilians and military (program managers, contracting officers, etc.) If you include the long tail of sustainment that’s another 165,000+ people. The Acquisition system in the Army (representative of the other services) looks like this:&lt;/p&gt;
    &lt;p&gt;What Was Wrong With this Process?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Responsibility in the Acquisition system was scattered across multiple, siloed organizations with no one individual responsible.&lt;/item&gt;
      &lt;item&gt;The existing system was designed to acquire individual products (weapons, services, etc.) with a Program Executive Office to manage each effort that only indirectly solved warfighter problems.&lt;/item&gt;
      &lt;item&gt;Requirements were written so that most everything the DoW bought was bespoke and required development from scratch.&lt;/item&gt;
      &lt;item&gt;Acquisition was process-focused with rigid rules that emphasized compliance to contracting rules.&lt;/item&gt;
      &lt;item&gt;Compliance to the rules and processes overrode speed of delivery&lt;/item&gt;
      &lt;item&gt;Weapons and systems development used sequential “waterfall” development processes which precluded learning, pivots and iterative design.&lt;/item&gt;
      &lt;item&gt;The result was that speed of delivery was on no one’s priority list.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why Is The Warfighting Acquisition System A Big Deal?&lt;lb/&gt; While previous administrations tried to go around the process, this new system confronts it head on. It is a revolutionary transformation in the Department of War. It was clearly designed by people who have worked in industry and understand commercial Lean Processes. This transformation will solve the DoW critical Acquisition problems by:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Prioritizing speed of delivery&lt;/item&gt;
      &lt;item&gt;Moving the focus from process to outcomes&lt;/item&gt;
      &lt;item&gt;Organizational redesign of the Acquisition process&lt;/item&gt;
      &lt;item&gt;Changing what weapons we ask for and how we prioritize what we need to buy&lt;/item&gt;
      &lt;item&gt;Changing the preferred vendors the DoW will buy from&lt;/item&gt;
      &lt;item&gt;Changing the contracting methods the DoW will use&lt;/item&gt;
      &lt;item&gt;Changing how we measure and reward success&lt;/item&gt;
      &lt;item&gt;Changing how we educate Acquisition professionals&lt;/item&gt;
      &lt;item&gt;Insisting that disparate systems/vendors interoperate&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The New Warfighting Acquisition Organization – The Portfolio Acquisition Executive&lt;lb/&gt; To cut through the individual acquisition silos, the services are creating Portfolio Acquisition Executives (PAEs). &lt;/p&gt;
    &lt;p&gt;Each Portfolio Acquisition Executive (PAE) is responsible for the entire end-to-process of the different Acquisition functions: Capability Gaps/Requirements, System Centers, Programming, Acquisition, Testing, Contracting and Sustainment. PAEs are empowered to take calculated risks in pursuit of rapidly delivering innovative solutions.&lt;/p&gt;
    &lt;p&gt;PAE Offices Are Matrix Organizations&lt;lb/&gt; Portfolio Acquisition Executives (PAEs) are organized as a matrix organization – using people from existing organizations – requirements, PEOs, sustainment, contracting etc. The PAEs themselves will have a small staff for coordination.&lt;/p&gt;
    &lt;p&gt;Portfolios Around Common Problems&lt;lb/&gt; In the past, Acquisition was organized by weapon systems and managed by Program Executive Offices. Portfolios will organize instead around common Warfighting Concepts, technologies, or operational integration needs.&lt;/p&gt;
    &lt;p&gt;Multiple Portfolios In Each Service&lt;lb/&gt; Each of the services are consolidating and reorganizing the functions of what were their Program Executive Offices into Portfolios. Program Executive Offices/Officers (PEOs) will become Capability Program Executives (CPEs), and act as a Portfolios’ acquisition arm.&lt;/p&gt;
    &lt;p&gt;(The examples below are from the Army. Other Services will have equivalent organizational designs for their Portfolios.)&lt;/p&gt;
    &lt;p&gt;The acquisition chain of authority runs directly from Capability Program Manager to PAE to the Service Acquisition Executive (SAE), with no intermediate offices or approval layers. (The Service Acquisition Executive for the Army is the Assistant Secretary for Acquisition, Logistics &amp;amp; Technology. For the Navy/Marines, the Assistant Secretary for Research, Development &amp;amp; Acquisition. For the Air Force/Space Force the Assistant Secretary for Acquisition, Technology &amp;amp; Logistics.)&lt;/p&gt;
    &lt;p&gt;The Army Has 6 Portfolio Acquisition Executives&lt;lb/&gt; For example, the Army will likely reorganize its 12 existing PEO offices to become part of 6 portfolios aligned with Army Warfighting Concepts and functions. Each of the 6 portfolios headed by a PAEs will be commanded by a Major General.&lt;/p&gt;
    &lt;p&gt;The likely 6 Army Portfolios are: 1) Maneuver, 2) Maneuver Air, 3) Fires, 4) C2/CC2, 5) Agile Sustainment and Ammo, and 6) Layered Protection and CBRN. One additional portfolio, called the PIT, will likely include the Army’s Innovation at the Edge activities.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PAE Maneuver will likely combine elements of PEO Soldier, PEO Ground Combat Systems, Future Capabilities Division and Maneuver Divisions, Test and Evaluation Integrator, Strategic Contracting Office, and others. This portfolio will likely have the Abrams tank, XM30 Mechanized Infantry Combat Vehicle (replacing the M2 Bradley), the ISV (Infantry Squad Vehicle), Soldier Borne Mission Command program (SBMC), Next Generation Squad Weapon (NGSW), Soldier Borne Sensor (SBS) program, and Organization Clothing and Individual Equipment (OCIE).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Authority to Make Trade-offs&lt;lb/&gt; PAEs now have the authority to make trade-offs between cost, schedule and performance and apply flexible funding between weapons systems to rapidly deliver capabilities to the warfighter. This means focusing on fielding “good enough” technology instead of waiting for a product that meets every single requirement.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PAE Maneuver Air will likely combine elements of Program Executive Office Aviation, Aviation and Missile Command, Futures Command Future Vertical Lift team DEVCOM Aviation &amp;amp; Missile, and others. It will likely include the Long-Range Assault Aircraft (FLRAA) the Bell V-280 Valor (to replace the UH-60 Black Hawk), Uncrewed Aircraft Systems (UAS), Rotary and Fixed Wing, and Autonomy.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Program Executive Officers (PEOs) are Now Capability Program Executives (CPEs)&lt;lb/&gt; Inside each portfolio is a Capability Program Executive (CPE), typically a Brigadier General or a civilian SES. Capability Program Executives have similar roles and responsibilities as today’s PEOs. They are the Acquisition leader responsible for cradle-to-grave management of their programs within their portfolio.&lt;/p&gt;
    &lt;p&gt;Streamlined Layers of Bureaucracy&lt;lb/&gt; 97 Army acquisition programs may be reassigned to align with the Army PAE reorganization. 46 organizations that were writing requirements likely will be consolidated into 9 Future Capability Directorates.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PAE Fires will likely combine elements from Program Executive Office Missiles and Space, Enterprise Information Systems, the Rapid Capabilities and Critical Technologies Office, Fires System Center, and others. It will likely include the Integrated Battle Command System (IBCS), Patriot/PAC-3, Precision Strike Missile (PrSM), Long-Range Hypersonic Weapon – Dark Eagle (LRHW), Common Autonomous Multi-Domain Launcher (CAML), Guam Defense and Golden Dome.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;DoW Will Buy Commercial First&lt;lb/&gt; One of the biggest changes is the mandate for PAEs to buy Commercial Off the Shelf (COTS) products, modify them if necessary and only buy bespoke products as a last resort. This change by itself is going to send shockwaves through the existing Prime contractors.&lt;/p&gt;
    &lt;p&gt;It’s telling everyone that the playing field is now open to everyone. Forget who has more lobbyists on K-Street. Speed, mission impact, and innovation is what will be rewarded. What this means for startups is that if you can execute and deliver (not just PowerPoints) you can become a supplier to the DoW.&lt;/p&gt;
    &lt;p&gt;Incentive Compensation to PAEs and Program Managers&lt;lb/&gt; PAEs will be judged on whether they deliver systems to the warfighter on time and on schedule. PAEs and Program Managers will have “incentive compensation” tied to “capability delivery time, competition, and mission outcomes. (How they’ll pay that kind of compensation for a member of the military remains to be seen.)&lt;/p&gt;
    &lt;p&gt;Incentives and Scorecards for Contractors&lt;lb/&gt; They’ll be managing their contractors with “time-indexed incentives” to make sure contractors deliver on time and on budget, using “scorecards” to keep tabs on how each portfolio is doing.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PAE C2/CC2 (Command and Control/Counter Command and Control) will likely combine elements of PEO Command, Control, Communications and Network.. And include NGC2, TITAN, TENCAP, Next Generation Constructive, STE&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Non-Traditional Entry Points&lt;lb/&gt; Companies selling to the DoW previously had to comply with the impenetrable DFAR and FAR – the Defense and Federal Acquisition Regulations – with over 5,000 pages of complex rules. It was designed for buying Aircraft Carriers, not startup technology. &lt;/p&gt;
    &lt;p&gt;Now the DoW is telling PAEs to toss those and use Non-FAR regulations like OTAs (Other Transaction Authorities). OTAs are not subject to the extensive, rigid rules and regulations of the DFAR. They allow for greater flexibility, speed, and allow the DoW to work with a broader range of innovative commercial companies. For startups this means massively reduced documentation, shorter timelines, and fewer barriers to working with the DoW.&lt;/p&gt;
    &lt;p&gt;PAEs Will Use Lean Methodology&lt;lb/&gt; Rather than fixed requirements and using waterfall development processes, the services are now insisting that vendors use Lean Methodology to set incremental and iterative delivery targets. That means they can field “good enough technology” that can be incrementally updated in the field and improved on a more frequent cadence.&lt;/p&gt;
    &lt;p&gt;The only requirement for each increment is that they need to target 1) an initial fielding date, &lt;lb/&gt; 2) set a maximum cost of each unit and 3) meet the minimum standards for mission effectiveness. Other than that, PAEs have the authority that other attributes of the weapons/software can remain tradable throughout development to allow incremental enhancements and rapid delivery of subsequent increments. This includes the ability to waive technical standards and environmental and other compliance requirements, unless they are mandated by statute or safety.&lt;/p&gt;
    &lt;p&gt;One other interesting Lean mandate is that each PAE will set up lean technical advisory processes to inform accelerated decision-making, ensuring technical rigor without sacrificing speed.&lt;/p&gt;
    &lt;p&gt;Weapons Will Be Able to Talk to Each Other – By Design&lt;lb/&gt; The new PAEs are also tasked with insisting that all weapons across their programs use Modular Open System Architectures, including by asserting government purpose rights over critical software interfaces — a move that allows the Pentagon to retain the data rights needed to avoid “vendor lock” (weapon systems that can only be modified and/or repaired by the company that designed it).&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PAE Agile Sustainment will likely combine elements of PEO Combat Support and Combat Service Support, PEO Solider and PEO Joint Program Office Armaments and Ammunition. It will likely include next generation Common Tactical Truck (CTT,) Family of Medium Tactical Vehicles (FMTV), 155mm, 6.8mm ammunition.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Two Vendors Through Initial Production&lt;lb/&gt; The DoW has painfully learned that having only one vendor selected leads to cost overruns and late projects. A new idea is that each critical acquisition program will have at least two qualified sources through initial production. While this will cost more upfront, it gives government leverage when it is strongest and enables them to re-compete modular components and find alternative suppliers if needed.&lt;/p&gt;
    &lt;p&gt;Design For Rapid Scale In a Crisis&lt;lb/&gt; PAEs have been told to establish acquisition strategies that decouple design from production to allow additional third-party suppliers to surge and rapidly scale manufacturing capacity in a crisis. They are to put in place guidelines for wartime consumption rates through manufacturing and supply chain partnerships and alternative sources.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PAE Layered Protection and CBRN (Chemical, Biological, Radiological, and Nuclear) will likely combine elements of PEO JPEO-CBRND. It will likely include Joint Chemical Agent Detector, UIPE, Decontamination Family of Systems, Biometrics&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;PAE Officers Now Have More Time To Learn On the Job&lt;lb/&gt; A complaint from past acquisition program managers is that they would only be there for two or three years, and then off to their next assignment. Two years was not enough time to see a program through. Now PAEs will have 4-year tours, extendible for another 2 years.&lt;/p&gt;
    &lt;p&gt;PAEs Top to Bottom&lt;lb/&gt; Every military service has 60 days to tell the Secretary of War a list of portfolios it is proposing to be initially stood up. A full implementation plan is due in 90 days. All major acquisition activities across all Services are going to be transitioned to PAE portfolios within two years. &lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Army PIT is the Army’s innovation initiatives at the edge. It’s the front door for startups wanting to partner with the Army.&lt;/p&gt;
      &lt;item&gt;The PIT includes the Joint Innovation Outpost, the Global Tactical Edge Acquisition Directorate (G-TEAD) Marketplace, the FUZE program, and Disruptive Technologies.&lt;/item&gt;
      &lt;item&gt;The G-TEAD Marketplace merges Prize Challenge events (e.g., Army xTech Program) and DEP submissions through open call announcements.&lt;/item&gt;
      &lt;item&gt;FUZE brings together the Army SBIR/STTR seed funding, MANTECH (Army Manufacturing Technology program), TMI (Tech Maturation Initiative) and XTech the Army’s scouting program.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Reeducation Camp – Warfighting Acquisition University&lt;lb/&gt; To retrain/reeducate contracting and acquisition officers, the “Defense Acquisition University” will become the “Warfighting Acquisition University.” They have been ordered to stop compliance-focused training operations and in six months transform into a competency-based education institution.&lt;/p&gt;
    &lt;p&gt;The university will pivot to offer experiential team-based programs that work on real DoW challenges (does that ever sound like a description of Hacking for Defense.) And they’re going to have their students get out of the building and take part in industry-government exchanges. In the next six months they’re going to prioritize education and rotation programs to get their students exposure to commercial industry practices, manufacturing and operational expertise, and real-world problem-solving. All to develop Acquisition executives critical thinking and agile and rapid decision-making skills. (Note to DAU: we’ve been building these programs for a decade at the Stanford Gordian Knot Center for National Security Innovation. Our national security classes are in 60+ universities and we’re happy to help.)&lt;/p&gt;
    &lt;p&gt;The Joint Staff – Coordinating the Needs of All the Services&lt;lb/&gt; While each of the Services generated their own weapons requirements, plans and budgets, they all had to be approved by the Joint Staff (which reports to the Secretary of War) through a process called the JCIDS (Joint Capabilities Integration &amp;amp; Development System). In theory this was to coordinate each of the Service’s needs so they weren’t duplicating each other, to ensure that they were interoperable, and to give the Combatant Command a voice; and tie all the requirements to joint concepts – all of this needing to be done before Service weapons programs got funded and built.&lt;/p&gt;
    &lt;p&gt;The problem was that JCIDS moved at the speed of paperwork, not war, so the Secretary of War eliminated it earlier this year. (They kept part of it called the Joint Requirements Oversight Council but reoriented it from validating documents to identifying joint operational problems, which will drive the priorities for the entire department of War.)&lt;/p&gt;
    &lt;p&gt;In JCIDS’ place the Secretary of War created three new organizations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Joint Acceleration Reserve, a pool of money set aside to quickly field promising capabilities.&lt;/item&gt;
      &lt;item&gt;The Requirements and Resourcing Alignment Board (RRAB) that will tie money directly to the top warfighting priorities and how much money each will get from the new Joint Acceleration Reserve.&lt;/item&gt;
      &lt;item&gt;The Mission Engineering and Integration Activity brings government, industry, and labs together early on to rapidly experiment, test, and prototype new tech.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It’s interesting to note that none of these changes at the Joint Staff have seemed to (at least publicly) filter down to the charter of the Services Portfolio Acquisition Executives (PAEs). The achilles heel of the Services Acquisition process appears that they are still planning to put the Requirements and Capability gap analysis up front. Here’s why that’s a problem and how to fix it.&lt;/p&gt;
    &lt;p&gt;Foreign military sales&lt;lb/&gt; One other tangential decision in this redesign was not in acquisition but in sales. The DoW wants a greater emphasis on selling our weapons to our Allies. They’ve moved two agencies responsible for those functions – the Defense Technology Security Administration DTSA and the Defense Security Cooperation Agency (DSCA) – from OSD Policy to OSD Acquisition and Sustainment. &lt;/p&gt;
    &lt;p&gt;This move is about selling more of our equipment, but makes no mention of buying any equipment from our allies.&lt;/p&gt;
    &lt;p&gt;Inferred But Not Mentioned&lt;lb/&gt; Pretty interesting that in this reorg no one has noticed that Elbridge Colby – Under Secretary for Policy – had three organizations taken away from him. &lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Defense Technology Security Administration DTSA&lt;/item&gt;
      &lt;item&gt;Defense Security Cooperation Agency (DSCA)&lt;/item&gt;
      &lt;item&gt;The Joint Production Accelerator Cell (JPAC) now renamed the Wartime Production Unit (WPU)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All three organizations were handed to Michael Duffey the Under Secretary for Acquisition &amp;amp; Sustainment. Regardless of the public statements the optics are not a vote of confidence.&lt;/p&gt;
    &lt;p&gt;Bigger and Better?&lt;lb/&gt; It appears that the Office of Strategic Capital may have been swallowed up by the Economic Defense Unit run by George Kolitdes. From all appearances the Economic Defense Unit is tasked to decouple our economy from China, using private and public capital. That means considering how to on-shore the critical components like minerals, chips, batteries, motors, PNT, etc.) The Acquisition announcement was how to buy things. This Economic Defense Unit is how do we ensure the things we buy are made with parts we know we can have an assured supply of?&lt;/p&gt;
    &lt;p&gt;Summary&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;Startups and the DoW are now speaking the same language – Lean, feedback from the field, pivots, iterative and incremental product design, speed to delivery.&lt;/item&gt;
      &lt;item&gt;The DoW mandate to first buy commercial-off-the-shelf products is a once-in-a-lifetime opportunity for every startup and scaleup.&lt;/item&gt;
      &lt;item&gt;But you have to deliver. Don’t hand wave with PowerPoints.&lt;/item&gt;
      &lt;item&gt;DoW will be ruthless in shutting down and freezing out non-performers.&lt;/item&gt;
      &lt;item&gt;The use of Non-Federal Acquisition Regulations will eliminate huge amounts of paperwork.&lt;/item&gt;
      &lt;item&gt;It eliminates one of the reasons to subcontract with a prime or other company&lt;/item&gt;
      &lt;item&gt;DoW needs to be ruthless in reforming the compliance culture&lt;/item&gt;
      &lt;item&gt;Who to talk to in each service and how will they do business will be unclear for at least the next six months&lt;/item&gt;
      &lt;item&gt;Reorganizations will create uncertainty of who is the front door for startups, how the new rules apply, and who can commit to contracts.&lt;/item&gt;
      &lt;item&gt;The Army appears to be further along than the other services in putting a PAE organization in place.&lt;/item&gt;
      &lt;item&gt;In theory this is a knife to the heart of the Primes’ business model.&lt;/item&gt;
      &lt;item&gt;They will flood Congress and the Executive Branch with infinite capital to change these rules.&lt;/item&gt;
      &lt;item&gt;It’s a race between private capital and public company lobbying money&lt;/item&gt;
      &lt;item&gt;Let’s hope these changes stick&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;Thanks to Pete Newell of BMNT for the feedback and insight.&lt;/p&gt;
    &lt;p&gt;Filed under: National Security, Technology Innovation and Modern War |&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://steveblank.com/2025/11/11/the-department-of-war-just-shot-the-accountants-and-opted-for-speed/"/><published>2025-11-11T14:34:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887857</id><title>Drawing Text Isn't Simple: Benchmarking Console vs. Graphical Rendering</title><updated>2025-11-11T21:09:21.733056+00:00</updated><content>&lt;doc fingerprint="266a99377fb93586"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Drawing Text on Screen - What Could Be Simpler?&lt;/head&gt;
    &lt;p&gt;So, this all started because I decided to learn Go. Polyglots say the best way to learn one is by doing something fun with it. Some watch movies, some read, some play with flashcards, others just jump into deep water and start talking with zero vocabulary.&lt;/p&gt;
    &lt;p&gt;I figured that logic should work for programming languages too - so I picked a fun target project: writing a text-based file manager. Think old-school Norton Commander or Dos Navigator. My personal favorite is still FAR Manager - it's insanely productive, still actively developed, and honestly the main reason I haven't switched to Linux or macOS yet.&lt;/p&gt;
    &lt;p&gt;Anyway, FAR Manager's code is in a language I don't speak, and writing plugins wouldn't get me where I want, so... I decided to just rewrite the whole thing. Easy, right? I know it's ridiculous, but that's fine - I like big impossible projects. Aim for the Moon, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Plan&lt;/head&gt;
    &lt;p&gt;I won't spoil the full idea (still might build it), but I disclose these two main modules:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Input handling (keyboard, mouse)&lt;/item&gt;
      &lt;item&gt;Output handling (drawing text on screen)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let's skip the boring input stuff - it works, after wrestling with all the quirks of Windows' console mode. Long story short: the “modern” VT (Virtual Terminal) mode that Windows adopted from Linux is slower output and dumber input than the old API. It doesn't even tell you when Shift is pressed, only when you actually type an uppercase letter with it. Add in a few more edge cases like Ctrl+Alt+Shift chaos, and you get the idea. I found workarounds, though, so keyboard input is mostly done.&lt;/p&gt;
    &lt;p&gt;Now, the fun part.&lt;/p&gt;
    &lt;head rend="h2"&gt;Output: Drawing Text&lt;/head&gt;
    &lt;p&gt;How hard can it be to draw letters on a screen, right?&lt;/p&gt;
    &lt;p&gt;There are several ways to do it in the Windows console:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Old way: &lt;code&gt;WriteConsoleOutputW&lt;/code&gt;- directly dump characters and color data to the screen.&lt;/item&gt;
      &lt;item&gt; New way: &lt;code&gt;WriteConsoleW&lt;/code&gt;- embed color codes in the text (the VT way), richer (e.g. bold, italic, underline)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The new one is half as fast. On a modern mid-range PC, that's just sad.&lt;/p&gt;
    &lt;p&gt;So I looked for better options - maybe GPU acceleration? Some people pointed me to GPU-powered terminals with buttery-smooth rendering. Sounded good, so I dug deeper.&lt;/p&gt;
    &lt;p&gt;After days of poking Go, forums, and LLMs, it became clear that Go is not made for things like this. So I switched to something battle-tested: C#. (And if anyone tells you "every language can do anything", please slap them with a large trout. I mean, sure - but at what cost?)&lt;/p&gt;
    &lt;p&gt;C# means .NET, which can power full-blown 3D games, so drawing text should be child's play! I tried three rendering paths:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;GDI - the classic Windows graphics interface. Works even "without" a GPU, so obviously not fast.&lt;/item&gt;
      &lt;item&gt;DirectX - the big guns, made for real-time 3D games.&lt;/item&gt;
      &lt;item&gt;Vulkan - similar to DirectX but cross-platform.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I built a simple benchmark using all three plus the two console methods. The screen was 240x63 characters (Full HD with a 8x16 font). Test conditions were intentionally rough - every character with random colors - just to stress the system.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results (random colors everywhere)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Renderer&lt;/cell&gt;
        &lt;cell role="head"&gt;240x63&lt;/cell&gt;
        &lt;cell role="head"&gt;80x25&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleOutputW&lt;/cell&gt;
        &lt;cell&gt;20.3&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleW&lt;/cell&gt;
        &lt;cell&gt;12.9&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GDI&lt;/cell&gt;
        &lt;cell&gt;22.2&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vulkan&lt;/cell&gt;
        &lt;cell&gt;23.5&lt;/cell&gt;
        &lt;cell&gt;175.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DirectX&lt;/cell&gt;
        &lt;cell&gt;17.6&lt;/cell&gt;
        &lt;cell&gt;130.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All of them sucked, basically. Even with optimizations. But I measured the "optimistic" ways as well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Results (realistic: white on black)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Renderer&lt;/cell&gt;
        &lt;cell role="head"&gt;240x63&lt;/cell&gt;
        &lt;cell role="head"&gt;80x25&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleOutputW&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WriteConsoleW&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GDI&lt;/cell&gt;
        &lt;cell&gt;62.4&lt;/cell&gt;
        &lt;cell&gt;64.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Vulkan&lt;/cell&gt;
        &lt;cell&gt;114.4&lt;/cell&gt;
        &lt;cell&gt;733.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;DirectX&lt;/cell&gt;
        &lt;cell&gt;140.2&lt;/cell&gt;
        &lt;cell&gt;944.5&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Now we're talking. GPU rendering finally pays off - DirectX crushed it.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Different Angle&lt;/head&gt;
    &lt;p&gt;Turns out the real bottleneck isn't the rendering API - it's Windows' font drawing (which is sadly CPU-bound). So I tried something unconventional: draw each character once, cache it as a texture, and then just copy those textures around. Copying pixels is much faster than redrawing fonts every frame.&lt;/p&gt;
    &lt;p&gt;That alone gave a massive speed bump in stress test (random colors):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Resolution&lt;/cell&gt;
        &lt;cell role="head"&gt;DirectX + Texture&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;240x63&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80x25&lt;/cell&gt;
        &lt;cell&gt;450.1&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Nice jump - but there's a catch.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Catch&lt;/head&gt;
    &lt;p&gt;Texturing looks great on paper, but you lose flexibility. You can't really optimize texture copies much more. On the other hand, writing text directly can be heavily optimized - for example, drawing an entire line at once when color and style match. That gives 5-7x speedups in practice.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Resolution&lt;/cell&gt;
        &lt;cell role="head"&gt;DX + text&lt;/cell&gt;
        &lt;cell role="head"&gt;DX + texture&lt;/cell&gt;
        &lt;cell role="head"&gt;Change&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;240x63&lt;/cell&gt;
        &lt;cell&gt;17.6&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
        &lt;cell&gt;+377% (stress test)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;80x25&lt;/cell&gt;
        &lt;cell&gt;130.5&lt;/cell&gt;
        &lt;cell&gt;450.1&lt;/cell&gt;
        &lt;cell&gt;+345% (stress test)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;240x63&lt;/cell&gt;
        &lt;cell&gt;140.2&lt;/cell&gt;
        &lt;cell&gt;66.4&lt;/cell&gt;
        &lt;cell&gt;-47% (normal use)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80x25&lt;/cell&gt;
        &lt;cell&gt;944.5&lt;/cell&gt;
        &lt;cell&gt;450.1&lt;/cell&gt;
        &lt;cell&gt;-47% (normal use)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;So - caching helps in extreme cases, but slows things down in normal ones.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The sweet spot is DirectX + direct text drawing. It's fast enough, flexible, and still keeps the door open for fancier options like Vulkan if I ever go cross-platform.&lt;/p&gt;
    &lt;p&gt;Moral of the story: Drawing text on screen isn't simple, most of the internet forums got the bottleneck wrong, only a selected few know what's really happening under the hood.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cv.co.hu/csabi/drawing-text-performance-graphical-vs-console.html"/><published>2025-11-11T14:49:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45887957</id><title>Pikaday: A friendly guide to front-end date pickers</title><updated>2025-11-11T21:09:21.612549+00:00</updated><content>&lt;doc fingerprint="2611da0b238d3ebc"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Who needs a JavaScript date picker?&lt;/head&gt;
    &lt;p&gt;The answer, in most cases, is nobody! Complex UI leads to more errors and abandoned forms. There can be easier ways to pick a date than a calendar widget. This guide provides alternate ideas and aims to send developers on a path towards user-friendly interfaces.&lt;/p&gt;
    &lt;head rend="h2"&gt;Native date and time inputs&lt;/head&gt;
    &lt;p&gt;If you absolutely must use a calendar widget then itâs wise to use the native input. All modern browsers support native date and time inputs.&lt;/p&gt;
    &lt;head rend="h3"&gt;Date input&lt;/head&gt;
    &lt;p&gt; The &lt;code&gt;date&lt;/code&gt; input type provides a native date picker.
        &lt;/p&gt;
    &lt;head rend="h3"&gt;Time input&lt;/head&gt;
    &lt;p&gt; The &lt;code&gt;time&lt;/code&gt; input type allows users to specify hours and minutes.
          &lt;/p&gt;
    &lt;head rend="h3"&gt;Datetime input&lt;/head&gt;
    &lt;p&gt; The &lt;code&gt;datetime-local&lt;/code&gt; input type combines both date and time.
          &lt;/p&gt;
    &lt;head rend="h2"&gt;Why use native inputs&lt;/head&gt;
    &lt;p&gt;Native inputs are super easy to implement with one line of code. The web browser handles many important details for developers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Accessibility (mostly*)&lt;/item&gt;
      &lt;item&gt;Performance&lt;/item&gt;
      &lt;item&gt;Internationalisation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let browsers do the hard work! Browsers allow keyboard users to type numbers in sequence. Most browsers provide alternate UI for time and date selection like the classic calendar widget. They're not perfect but do you trust a JavaScript library to do better?&lt;/p&gt;
    &lt;p&gt;*Oh dear! Even native date pickers have some accessibility issues.&lt;/p&gt;
    &lt;head rend="h2"&gt;Separate inputs&lt;/head&gt;
    &lt;p&gt;A single date picker can be tricky to operate. For memorable dates using separate inputs can improve usability. The example below is based on GOV.UK date input component.&lt;/p&gt;
    &lt;head rend="h3"&gt;Select elements&lt;/head&gt;
    &lt;p&gt;If only a limited set of data is valid then using select elements may be suitable. They can require fewer interactions to use and they eliminate typing errors.&lt;/p&gt;
    &lt;p&gt;Numeric month labels can be helpful but take care in how theyâre written. Screen readers may mistakenly announce â1 Januaryâ as âthe 1st of Januaryâ, for example.&lt;/p&gt;
    &lt;p&gt;Travel booking often has a fixed schedule with limited time options, such as every 15 minutes. Relative dates like âTodayâ and âTomorrowâ can be easier to understand.&lt;/p&gt;
    &lt;head rend="h2"&gt;Masked inputs&lt;/head&gt;
    &lt;p&gt;Another common alternative to date pickers is a single input with a placeholder mask. This can be used for full or partial dates. JavaScript can enhancement the experience.&lt;/p&gt;
    &lt;p&gt; The examples above provide client-side validation with errors such as âPlease enter a valid day for February (1 to 28)â. Valid dates are confirmed in full and formatted with the &lt;code&gt;Intl&lt;/code&gt; API.
        &lt;/p&gt;
    &lt;p&gt;Caution! Updating input values with JavaScript can break native undo/redo.&lt;/p&gt;
    &lt;p&gt;Itâs even possible to visually combined mutliple inputs using CSS to appear as one.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ranges and limited options&lt;/head&gt;
    &lt;p&gt; JavaScript date pickers that support range selection across two calendars are difficult to use, especially without a pointer. Consider providing two inputs instead to reduce complexity. If users are required to select an available date then a group of &lt;code&gt;radio&lt;/code&gt; inputs can do the job.
        &lt;/p&gt;
    &lt;p&gt;The example below illustrates the idea but is not fully interactive.&lt;/p&gt;
    &lt;p&gt;There are many design variations of this pattern. This idea is to replace complicated UI with a series of simple tasks. Such a pattern can be implemented as a multi-page form with JavaScript used to enhance it into a single page interactive experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Frequently asked questions&lt;/head&gt;
    &lt;head&gt;What if I use a JavaScript framework like React?&lt;/head&gt;
    &lt;p&gt; All good JavaScript frameworks allow you to use native HTML elements. Not everything needs to be a custom component. Native input events can integrate with framework callbacks. Use attributes like &lt;code&gt;value&lt;/code&gt; for two-way state binding.
            &lt;/p&gt;
    &lt;head&gt;How do I style the native date picker?&lt;/head&gt;
    &lt;p&gt; The on-page &lt;code&gt;input&lt;/code&gt; element
              can be partially styled but other parts are not stylable.
              That is a good thing! Native system UI is familiar to the user.
              The design will differ based on operating system and input method.
              Date pickers even look different across browsers and that's fine too, you don't need to add yet another design to the mix!
            &lt;/p&gt;
    &lt;head&gt;A stakeholder is demanding a JavaScript date picker, how do I dissuade them?&lt;/head&gt;
    &lt;p&gt;Remember: the end goal is a successful form submission. Complex and fragile UI leads to more errors. All date pickers have accessibility issues. Combining basic inputs can be more user-friendly. Untested JavaScript UI may fall foul of regulation like the European Accessibility Act. Keep it simple for success!&lt;/p&gt;
    &lt;head&gt;How do I test and guarantee accessibility?&lt;/head&gt;
    &lt;p&gt;Itâs critical to understand the relevant accessibility guidelines. You donât need to memorise WCAG but there are no shortcuts to learning the important parts. Leverage existing web standards to avoid mistakes trying to code custom UI.&lt;/p&gt;
    &lt;p&gt;Browser dev tools have built-in accessibility features to help identify mistakes. However, no tool is perfect. The only way to know for sure is to conduct user testing.&lt;/p&gt;
    &lt;p&gt;Accessibility overlays are strongly discouraged and can make matters worse.&lt;/p&gt;
    &lt;head&gt;Where can I learn more about date picker accessibility?&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Collecting dates in an accessible way by Graham Armfield&lt;/item&gt;
      &lt;item&gt;What makes an accessible date picker? Is it even possible? by Russ Weakley&lt;/item&gt;
      &lt;item&gt;Maybe You Donât Need a Date Picker by Adrian Roselli&lt;/item&gt;
      &lt;item&gt;Date Picker Dialog Example by ARIA Authoring Practices Guide&lt;/item&gt;
      &lt;item&gt;Designing The Perfect Date And Time Picker by Vitaly Friedman&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;This is all great but can you please recommend a JavaScript date picker?&lt;/head&gt;
    &lt;p&gt;Sorry, no! There is no universal solution and all date pickers have issues. I hope this guide has given you the knowledge to evaluate your own requirements. Try to achieve your goal in the simplest way. A date picker is probably not the answer.&lt;/p&gt;
    &lt;p&gt;Before you go! Remember to test and gather feedback from real users :)&lt;/p&gt;
    &lt;p&gt;This guide is a work in progress, feedback is welcome!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pikaday.dbushell.com"/><published>2025-11-11T14:58:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45888143</id><title>Grebedoc – static site hosting for Git forges</title><updated>2025-11-11T21:09:21.096247+00:00</updated><content>&lt;doc fingerprint="b09023494ed73381"&gt;
  &lt;main&gt;&lt;p&gt;In short: a service that publishes the &lt;code&gt;pages&lt;/code&gt; branch in your Git repository as a website on your domain; think GitHub Pages if it was open source and community operated.&lt;/p&gt;&lt;p&gt;More specifically, it is a public deployment of git-pages and Caddy configured to work especially with Codeberg but also with other Git forges. It is operated by Catherine 'whitequark' and teammates, and currently deployed using Rage4 anycast infrastructure routing to VPSes in six regions (Europe, North America East, North America West, South America, East Asia, Australia), with site contents stored on Tigris and backed up to Wasabi.&lt;/p&gt;&lt;p&gt;This service is provided as a public utility, especially for those migrating from GitHub to community operated forges, and we plan to operate it indefinitely. It is monitored and has a status page.&lt;/p&gt;&lt;p&gt;The size of a website is currently limited to 768 MiB. We are aiming to eventually raise this to 10 GiB.&lt;/p&gt;&lt;p&gt;git-pages is a self-service static site server for the general public. It is efficient, reliable, scales horizontally to any number of nodes, and deployable in under 5 minutes. It is designed to work with an S3-compatible object store such as MinIO, and integrates with Caddy for TLS termination and on-demand certificate provisioning. It accepts webhook events from Forgejo, Gitea, Gogs, and GitHub. See the git-pages README for more details.&lt;/p&gt;&lt;p&gt;Unlike the pull-based architecture of the similar codeberg.page service, this service is push-based: the forge must notify the pages server whenever there is a content update. This makes it much more efficient, but requires the forge to be configured for publishing (via CI or a webhook).&lt;/p&gt;&lt;p&gt;Publishing a site using git-pages is done using a &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; request to the same URL where the contents will appear. The server is compatible with many popular publishing workflows and has multiple flexible authorization methods.&lt;/p&gt;&lt;p&gt;Select repository &amp;gt; Settings &amp;gt; Webhooks &amp;gt; Add webhook &amp;gt; Forgejo, then configure only the following:&lt;/p&gt;&lt;code&gt;pages&lt;/code&gt; or &lt;code&gt;{username}.grebedoc.dev&lt;/code&gt;): &lt;code&gt;http://{username}.grebedoc.dev/&lt;/code&gt;&lt;code&gt;{repository}&lt;/code&gt;): &lt;code&gt;http://{username}.grebedoc.dev/{repository}/&lt;/code&gt;&lt;code&gt;pages&lt;/code&gt;&lt;p&gt;Leave everything else at the default values and select Add webhook. Next update to the &lt;code&gt;pages&lt;/code&gt; branch will cause its contents to become available at the target URL.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the webhook for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;Method A: To prove that you control the domain, update the configuration of your domain to add a &lt;code&gt;TXT&lt;/code&gt; record at the &lt;code&gt;_git-pages-repository&lt;/code&gt; subdomain with the full git clone URL (something like &lt;code&gt;https://forge.tld/user/repo.git&lt;/code&gt;) as its value.&lt;/p&gt;&lt;p&gt;Method B: To prove that you control the domain, generate a strong password (32 or more random alphanumeric characters) and compute a challenge as: &lt;code&gt;SHA256("{domain} {password}")&lt;/code&gt;. This can be done by running &lt;code&gt;echo -n "{domain} {password}" | sha256sum&lt;/code&gt; in the terminal, or with the following JavaScript-based form:&lt;/p&gt;&lt;p&gt;Update the configuration of your domain to add a &lt;code&gt;TXT&lt;/code&gt; record at the &lt;code&gt;_git-pages-challenge&lt;/code&gt; subdomain with the challenge as its value.&lt;/p&gt;&lt;p&gt;Important! Keep the password secret. Anyone who knows it can replace the contents of your static site with anything they want.&lt;/p&gt;&lt;p&gt;After using Method A or Method B, configure your domain to have &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;AAAA&lt;/code&gt; records pointing to the same server as &lt;code&gt;grebedoc.dev&lt;/code&gt;. In most cases this can be done using an &lt;code&gt;ALIAS&lt;/code&gt; record, but if this functionality isn't available it will need to be done by hand.

&lt;/p&gt;&lt;p&gt;Select repository &amp;gt; Settings &amp;gt; Webhooks &amp;gt; Add webhook &amp;gt; Forgejo, then configure only the following:&lt;/p&gt;&lt;code&gt;http://{domain}/&lt;/code&gt; or &lt;code&gt;http://{domain}/{subdir}/&lt;/code&gt; (only one level of directories can be used)&lt;code&gt;pages&lt;/code&gt;&lt;code&gt;Pages {password}&lt;/code&gt; (Method B only)&lt;p&gt;Leave everything else at the default values and select Add webhook. The next time the &lt;code&gt;pages&lt;/code&gt; branch is pushed, its contents will be published at the target URL.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the webhook for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;This configuration method is not limited to Codeberg; it works with any Forgejo, Gitea, Gogs, or GitHub based forge. If the forge does not make it possible to supply an &lt;code&gt;Authorization:&lt;/code&gt; header, use &lt;code&gt;http://Pages:{password}@{domain}/&lt;/code&gt; as the target URL instead.&lt;/p&gt;&lt;p&gt;Follow the DNS configuration steps for Method A or Method B as described above. Next, configure your forge or Git repository to issue a &lt;code&gt;PUT&lt;/code&gt; HTTP request after a branch has been updated with this Curl command (or its equivalent):&lt;/p&gt;&lt;p&gt;For Method A: &lt;code&gt;curl http://{domain}/ -X PUT --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For Method B: &lt;code&gt;curl http://{domain}/ -X PUT -H "Authorization: Pages {password}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;The optional &lt;code&gt;-H "X-Pages-Branch: {branch}"&lt;/code&gt; argument may be used to publish from a branch other than &lt;code&gt;pages&lt;/code&gt;. This functionality requires the &lt;code&gt;PUT&lt;/code&gt; method to be used, and is not available with webhooks.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;Follow the DNS configuration steps for Method B (only) as described above. Next, make a ZIP or tar archive of your site and upload it with this Curl command (or its equivalent):&lt;/p&gt;&lt;p&gt;For a ZIP archive: &lt;code&gt;curl http://{domain}/ -X PUT -H "Authorization: Pages {password}" -H "Content-Type: application/zip" --data-binary @{archive}&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For a tar archive: &lt;code&gt;curl http://{domain}/ -X PUT -H "Authorization: Pages {password}" -H "Content-Type: application/x-tar" --data-binary @{archive}&lt;/code&gt;&lt;/p&gt;&lt;p&gt;It is also possible to upload a &lt;code&gt;.tar.gz&lt;/code&gt; (&lt;code&gt;Content-Type: application/x-tar+gzip&lt;/code&gt;) or a &lt;code&gt;.tar.zst&lt;/code&gt; (&lt;code&gt;Content-Type: application/x-tar+zstd&lt;/code&gt;) archive. Using Zstandard level 0 to 3 is recommended, especially for large sites: it is a very efficient compression algorithm that will likely reduce the total energy used to publish the site.&lt;/p&gt;&lt;p&gt;Important! It is necessary to either use the &lt;code&gt;http://&lt;/code&gt; scheme for the initial push (after which it may be upgraded to &lt;code&gt;https://&lt;/code&gt;), or perform the initial publishing using a special method.&lt;/p&gt;&lt;p&gt;Follow the DNS configuration steps for Method A or Method B as described above. Before altering the &lt;code&gt;ALIAS&lt;/code&gt; or &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;AAAA&lt;/code&gt; records, use the following Curl command (or its equivalent) to publish your site at the new server:&lt;/p&gt;&lt;p&gt;For Method A: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For Method B: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" -H "Authorization: Pages {password}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Verify the deployment by requesting the index page: &lt;code&gt;curl https://grebedoc.dev/ -H "Host: {domain}"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Now, alter the &lt;code&gt;ALIAS&lt;/code&gt; or &lt;code&gt;A&lt;/code&gt;/&lt;code&gt;AAAA&lt;/code&gt; records for your domain.&lt;/p&gt;&lt;p&gt;Add a file named &lt;code&gt;_redirects&lt;/code&gt; at the root of your repository or archive. See the Codeberg documentation for a reference of the syntax. Note that the &lt;code&gt;_redirects&lt;/code&gt; file will not be accessible from your site after publishing; it will only alter how your site works.&lt;/p&gt;&lt;p&gt;It is possible to enter malformed rules in the &lt;code&gt;_redirects&lt;/code&gt; file. Such problems will not prevent your site from being published, but the malformed rules are ignored. Any problems are reported in the response to the &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; request used to publish your site (your forge will display them on the webhook configuration page); they are also available at the special &lt;code&gt;https://{host}/.git-pages/manifest.json&lt;/code&gt; or &lt;code&gt;https://{host}/{site}/.git-pages/manifest.json&lt;/code&gt; URL, which describes how git-pages understands the layout of your site.&lt;/p&gt;&lt;p&gt;Add a file named &lt;code&gt;_headers&lt;/code&gt; at the root of your repository or archive. See the Netlify documentation for a reference of the syntax; note that &lt;code&gt;*&lt;/code&gt; is currently allowed only by itself and as the last path segment, unlike on Netlify. Note also that the &lt;code&gt;_headers&lt;/code&gt; file will not be accessible from your site after publishing; it will only alter how your site works.&lt;/p&gt;&lt;p&gt;Only custom headers that are a part of the following allowlist may be used:&lt;/p&gt;&lt;code&gt;X-Clacks-Overhead&lt;/code&gt;&lt;code&gt;Reporting-Endpoints&lt;/code&gt;&lt;code&gt;Cross-Origin-Embedder-Policy&lt;/code&gt;&lt;code&gt;Cross-Origin-Opener-Policy&lt;/code&gt;&lt;code&gt;Cross-Origin-Resource-Policy&lt;/code&gt;&lt;code&gt;Content-Security-Policy&lt;/code&gt;&lt;code&gt;Content-Security-Policy-Report-Only&lt;/code&gt;&lt;code&gt;Integrity-Policy&lt;/code&gt;&lt;code&gt;Integrity-Policy-Report-Only&lt;/code&gt;&lt;code&gt;Permissions-Policy&lt;/code&gt;&lt;code&gt;Referrer-Policy&lt;/code&gt;&lt;code&gt;X-Frame-Options&lt;/code&gt;&lt;code&gt;Content-Disposition&lt;/code&gt;&lt;code&gt;Sourcemap&lt;/code&gt;&lt;p&gt;The capitalization of the headers is unimportant. The values of these headers are not restricted. Specifying a header multiple times per rule is allowed and causes every instance to appear in the HTTP response.&lt;/p&gt;&lt;p&gt;It is possible to enter malformed rules in the &lt;code&gt;_headers&lt;/code&gt; file. Such problems will not prevent your site from being published, but the malformed rules are ignored. Any problems are reported in the response to the &lt;code&gt;PUT&lt;/code&gt; or &lt;code&gt;POST&lt;/code&gt; request used to publish your site (your forge will display them on the webhook configuration page); they are also available at the special &lt;code&gt;https://{host}/.git-pages/manifest.json&lt;/code&gt; or &lt;code&gt;https://{host}/{site}/.git-pages/manifest.json&lt;/code&gt; URL, which describes how git-pages understands the layout of your site.&lt;/p&gt;&lt;p&gt;There are two ways to unpublish a site.&lt;/p&gt;&lt;p&gt;Publishing a completely empty commit makes all of its contents unreachable and erases the routing information. Once complete, the pages server behaves as if the site was never published.&lt;/p&gt;&lt;p&gt;Git command: &lt;code&gt;git checkout --orphan empty-pages &amp;amp;&amp;amp; git commit --allow-empty -m "unpublish" &amp;amp;&amp;amp; git push origin empty-pages:pages&lt;/code&gt;&lt;/p&gt;&lt;p&gt;If Method B is used for authorization, a &lt;code&gt;DELETE&lt;/code&gt; request unpublishes a site.&lt;/p&gt;&lt;p&gt;Curl command: &lt;code&gt;curl https://{domain}/ -X DELETE -H "Authorization: Pages {password}"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Important! The git-pages server deduplicates files globally to reduce operational cost. Consequently, some of your files will linger in the backend store even after you unpublish your site. These files are completely inaccessible from the web, and will be purged by the next garbage collection cycle. (Garbage collection is a work in progress.)&lt;/p&gt;&lt;p&gt;To comply with the terms of service of the TLS certificate authorities (such as Let's Encrypt and ZeroSSL), this service only acquires certificates for domains it has a published site for, regardless of the DNS settings or HTTP headers. This means that the site cannot be published using its own &lt;code&gt;https://&lt;/code&gt; URL yet. Instead, use the following Curl command (or its equivalent) to publish your site for the first time:&lt;/p&gt;&lt;p&gt;For Method A: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;For Method B: &lt;code&gt;curl https://grebedoc.dev/ -X PUT -H "Host: {domain}" -H "Authorization: Pages {password}" --data "https://{forge}/{repo}.git"&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Take a look at the live dashboard (requires you to have working IPv6, which saves me 2 €/month).&lt;/p&gt;&lt;p&gt;It is a great crested grebe! Original photo © Bengt Nyman, CC BY-SA 4.0.&lt;/p&gt;&lt;p&gt;The architecture of grebedoc.dev is the inverse of the architecture of codeberg.page; "Grebedoc" is "Codeberg" backwards.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://grebedoc.dev"/><published>2025-11-11T15:11:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45888891</id><title>Firefox expands fingerprint protections</title><updated>2025-11-11T21:09:20.835244+00:00</updated><content>&lt;doc fingerprint="9f3493f63975af6e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Firefox expands fingerprint protections: advancing towards a more private web&lt;/head&gt;
    &lt;p&gt;With Firefox 145, we’re rolling out major privacy upgrades that take on browser fingerprinting — a pervasive and hidden tracking technique that lets websites identify you even when cookies are blocked or you’re in private browsing. These protections build on Mozilla’s long-term goal of building a healthier, transparent and privacy-preserving web ecosystem.&lt;/p&gt;
    &lt;p&gt;Fingerprinting builds a secret digital ID of you by collecting subtle details of your setup — ranging from your time zone to your operating system settings — that together create a “fingerprint” identifiable across websites and across browser sessions. Having a unique fingerprint means fingerprinters can continuously identify you invisibly, allowing bad actors to track you without your knowledge or consent. Online fingerprinting is able to track you for months, even when you use any browser’s private browsing mode.&lt;/p&gt;
    &lt;p&gt;Protecting people’s privacy has always been core to Firefox. Since 2020, Firefox’s built-in Enhanced Tracking Protection (ETP) has blocked known trackers and other invasive practices, while features like Total Cookie Protection and now expanded fingerprinting defenses demonstrate a broader goal: prioritizing your online freedom through innovative privacy-by-design. Since 2021, Firefox has been incrementally enhancing anti-fingerprinting protections targeting the most common pieces of information collected for suspected fingerprinting uses.&lt;/p&gt;
    &lt;p&gt;Today, we are excited to announce the completion of the second phase of defenses against fingerprinters that linger across all your browsing but aren’t in the known tracker lists. With these fingerprinting protections, the amount of Firefox users trackable by fingerprinters is reduced by half.&lt;/p&gt;
    &lt;head rend="h2"&gt;How we built stronger defenses&lt;/head&gt;
    &lt;p&gt;Drawing from a global analysis of how real people’s browsers can be fingerprinted, Mozilla has developed new, unique and powerful defenses against real-world fingerprinting techniques. Firefox is the first browser with this level of insight into fingerprinting and the most effective deployed defenses to reduce it. Like Total Cookie Protection, one of our most innovative privacy features, these new defenses are debuting in Private Browsing Mode and ETP Strict mode initially, while we work to enable them by default.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Firefox protects you&lt;/head&gt;
    &lt;p&gt;These fingerprinting protections work on multiple layers, building on Firefox’s already robust privacy features. For example, Firefox has long blocked known tracking and fingerprinting scripts as part of its Enhanced Tracking Protection.&lt;/p&gt;
    &lt;p&gt;Beyond blocking trackers, Firefox also limits the information it makes available to websites — a privacy-by-design approach — that preemptively shrinks your fingerprint. Browsers provide a way for websites to ask for information that enables legitimate website features, e.g. your graphics hardware information, which allows sites to optimize games for your computer. But trackers can also ask for that information, for no other reason than to help build a fingerprint of your browser and track you across the web.&lt;/p&gt;
    &lt;p&gt;Since 2021, Firefox has been incrementally advancing fingerprinting protections, covering the most pervasive fingerprinting techniques. These include things like how your graphics card draws images, which fonts your computer has, and even tiny differences in how it performs math. The first phase plugged the biggest and most-common leaks of fingerprinting information.&lt;/p&gt;
    &lt;p&gt;Recent Firefox releases have tackled the next-largest leaks of user information used by online fingerprinters. This ranges from strengthening the font protections to preventing websites from getting to know your hardware details like the number of cores your processor has, the number of simultaneous fingers your touchscreen supports, and the dimensions of your dock or taskbar. The full list of detailed protections is available in our documentation.&lt;/p&gt;
    &lt;p&gt;Our research shows these improvements cut the percentage of users seen as unique by almost half.&lt;/p&gt;
    &lt;p&gt;Firefox’s new protections are a balance of disrupting fingerprinters while maintaining web usability. More aggressive fingerprinting blocking might sound better, but is guaranteed to break legitimate website features. For instance, calendar, scheduling, and conferencing tools legitimately need your real time zone. Firefox’s approach is to target the most leaky fingerprinting vectors (the tricks and scripts used by trackers) while preserving functionality many sites need to work normally. The end result is a set of layered defenses that significantly reduce tracking without downgrading your browsing experience. More details are available about both the specific behaviors and how to recognize a problem on a site and disable protections for that site alone, so you always stay in control. The goal: strong privacy protections that don’t get in your way.&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s next for your privacy&lt;/head&gt;
    &lt;p&gt;If you open a Private Browsing window or use ETP Strict mode, Firefox is already working behind the scenes to make you harder to track. The latest phase of Firefox’s fingerprinting protections marks an important milestone in our mission to deliver: smart privacy protections that work automatically — no further extensions or configurations needed. As we head into the future, Firefox remains committed to fighting for your privacy, so you get to enjoy the web on your terms. Upgrade to the latest Firefox and take back control of your privacy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/"/><published>2025-11-11T16:04:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45889793</id><title>Show HN: Cactoide – Federated RSVP Platform</title><updated>2025-11-11T21:09:20.148058+00:00</updated><content>&lt;doc fingerprint="efaf8ee999fbbf20"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cactoide(ea)* ðµ&lt;/head&gt;
    &lt;head rend="h2"&gt;The Ultimate RSVP Platform&lt;/head&gt;
    &lt;p&gt;A federated mobile-first event RSVP platform that lets you create events, share unique URLs, and collect RSVPs without any registration required. With built-in federation, discover and share events across a decentralized network of instances.&lt;/p&gt;
    &lt;p&gt;Cactoide is open source and easily self-hostable. View the source code, contribute, or host your own instance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Cactoide(ae)?ðµ*&lt;/head&gt;
    &lt;p&gt;Like the cactus, great events bloom under any condition when managed with care. Cactoide(ae) helps you streamline RSVPs, simplify coordination, and keep every detail efficientâso your gatherings are resilient, vibrant, and unforgettable.&lt;/p&gt;
    &lt;head rend="h2"&gt;Discover Public Events&lt;/head&gt;
    &lt;p&gt;See what others are planning and get inspired&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Cactoide?&lt;/head&gt;
    &lt;head rend="h3"&gt;Instant Event Creation&lt;/head&gt;
    &lt;p&gt;Create events in seconds with our streamlined form. No accounts, no waiting, just pure efficiency.&lt;/p&gt;
    &lt;head rend="h3"&gt;One-Click Sharing&lt;/head&gt;
    &lt;p&gt;Each event gets a unique, memorable URL. Share instantly via any platform or messaging app.&lt;/p&gt;
    &lt;head rend="h3"&gt;All-in-One Clarity&lt;/head&gt;
    &lt;p&gt;No more scrolling through endless chats and reactions. See everyone's availability and responses neatly in one place.&lt;/p&gt;
    &lt;head rend="h3"&gt;No Hassle, No Sign-Ups&lt;/head&gt;
    &lt;p&gt;Skip registrations and endless forms. Unlike other event platforms, you create and share instantly â no accounts, no barriers.&lt;/p&gt;
    &lt;head rend="h3"&gt;Smart Limits&lt;/head&gt;
    &lt;p&gt;Choose between unlimited RSVPs or set a limited capacity. Perfect for any event size.&lt;/p&gt;
    &lt;head rend="h3"&gt;Effortless Simplicity&lt;/head&gt;
    &lt;p&gt;Designed to be instantly clear and easy. No learning curve â just open, create, and go.&lt;/p&gt;
    &lt;head rend="h3"&gt;Invite Links&lt;/head&gt;
    &lt;p&gt;Create invite-only events with special links. Only people with the specific invite link can RSVP, giving you full control over who can attend.&lt;/p&gt;
    &lt;head rend="h3"&gt;Federation&lt;/head&gt;
    &lt;p&gt;Connect with other Cactoide instances to discover events across the network. Share your public events and create a decentralized event discovery network.&lt;/p&gt;
    &lt;head rend="h2"&gt;How It Works&lt;/head&gt;
    &lt;head rend="h3"&gt;1. Create Event&lt;/head&gt;
    &lt;p&gt;Fill out a simple form with event details. Choose between limited or unlimited capacity.&lt;/p&gt;
    &lt;head rend="h3"&gt;2. Get Unique URL&lt;/head&gt;
    &lt;p&gt;Receive a random, memorable URL for your event. Perfect for sharing anywhere.&lt;/p&gt;
    &lt;head rend="h3"&gt;3. Collect RSVPs&lt;/head&gt;
    &lt;p&gt;People visit your link and join with just their name. No accounts needed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ready to Create Your First Event?&lt;/head&gt;
    &lt;p&gt;Join thousands of event organizers who trust Cactoide&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cactoide.org/"/><published>2025-11-11T17:01:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45889891</id><title>Cache-friendly, low-memory Lanczos algorithm in Rust</title><updated>2025-11-11T21:09:19.665684+00:00</updated><content>&lt;doc fingerprint="91155a0e0fae71f1"&gt;
  &lt;main&gt;
    &lt;p&gt;The standard Lanczos method for computing matrix functions has a brutal memory requirement: storing an basis matrix that grows with every iteration. For a -variable problem needing iterations, that’s roughly 4 GB just for the basis.&lt;/p&gt;
    &lt;p&gt;In this post, we will explore one of the most straightforward solutions to this problem: a two-pass variant of the Lanczos algorithm that only requires memory at the cost of doubling the number of matrix-vector products. The surprising part is that when implemented carefully, the two-pass version isn’t just memory-efficient—it can be faster for certain problems. We will dig into why.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;All code is available on GitHub: two-pass-lanczos&lt;/item&gt;
      &lt;item&gt;The full technical report with proofs and additional experiments: report.pdf&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;head&gt;Open Table of Contents&lt;/head&gt;
    &lt;head rend="h1"&gt;Computing Matrix Functions&lt;/head&gt;
    &lt;p&gt;Let’s consider the problem of computing the action of matrix functions on a vector:&lt;/p&gt;
    &lt;p&gt;where is a large sparse Hermitian matrix and is a matrix function defined on the spectrum of . This is a problem that appears pretty often in scientific computing: solving linear systems corresponds to , exponential integrators for PDEs use , and many other problems require functions like or .&lt;/p&gt;
    &lt;p&gt;Indeed, there are a lot problems with computing directly. First of all, even if is sparse, is generally dense. Storing it explicitly is out of the question for large problems. Even if we could store it, computing it directly would require algorithms like the Schur-Parlett method that scale as , which is impractical for large .&lt;/p&gt;
    &lt;p&gt;However we know that given any matrix function defined on the spectrum of , we can express as a polynomial in of degree at most (the size of the matrix) such that (this is a consequence of the Cayley-Hamilton theorem). This polynomial interpolates and its derivatives in the Hermitian sense at the eigenvalues of .&lt;/p&gt;
    &lt;p&gt;This gives us a good and a bad news: the good news is that, well, we can express as a polynomial in . The bad news is that the degree of this polynomial can be as high as , which is huge for large problems. The idea is then to find a low-degree polynomial approximation to that is good enough for our purposes. If we can find a polynomial of degree such that , then we can approximate the solution as:&lt;/p&gt;
    &lt;p&gt;This polynomial only involves vectors within a specific subspace.&lt;/p&gt;
    &lt;head rend="h2"&gt;Krylov Projection&lt;/head&gt;
    &lt;p&gt;We can notice that only depends on vectors in the Krylov subspace of order&lt;/p&gt;
    &lt;p&gt;This is fortunate: we can compute an approximate solution by staying within this space, which only requires repeated matrix-vector products with . For large sparse matrices, that’s the only operation we can do efficiently anyway.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;We don’t need to construct explicitly. We compute iteratively: .&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But there’s a problem: the raw vectors form a terrible basis. They quickly become nearly parallel, making any computation numerically unstable. We need an orthonormal basis.&lt;/p&gt;
    &lt;head rend="h3"&gt;Building an Orthonormal Basis&lt;/head&gt;
    &lt;p&gt;The standard method is the Arnoldi process, which is Gram-Schmidt applied to Krylov subspaces. We start by normalizing . Then, iteratively:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute a new candidate:&lt;/item&gt;
      &lt;item&gt;Orthogonalize against all existing basis vectors:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Normalize:&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The coefficients become entries of a projected matrix. After iterations, we have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;: an orthonormal basis for&lt;/item&gt;
      &lt;item&gt;: an upper Hessenberg matrix representing the projection of onto this subspace&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We can express this relationship with the Arnoldi decomposition:&lt;/p&gt;
    &lt;head rend="h3"&gt;Solving in the Reduced Space&lt;/head&gt;
    &lt;p&gt;Now we approximate our original problem by solving it in the small -dimensional space. Using the Full Orthogonal Method (FOM), we enforce that the residual is orthogonal to the Krylov subspace. This gives:&lt;/p&gt;
    &lt;p&gt;where is computed as:&lt;/p&gt;
    &lt;p&gt;The heavy lifting is now on computing , a small matrix. Since , we can afford direct methods like Schur-Parlett ().&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;For (linear systems), this reduces to solving with LU decomposition.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h1"&gt;The Lanczos Algorithm&lt;/head&gt;
    &lt;p&gt;When is Hermitian (or symmetric in the real case), the general Arnoldi process simplifies dramatically. We can prove that must also be Hermitian. A matrix that is both upper Hessenberg and Hermitian must be real, symmetric, and tridiagonal. This is a huge simplification.&lt;/p&gt;
    &lt;p&gt;In the literature, this projected matrix is denoted to highlight its tridiagonal structure:&lt;/p&gt;
    &lt;p&gt;where are the diagonal elements and are the off-diagonals (subdiagonals from the orthogonalization).&lt;/p&gt;
    &lt;head rend="h2"&gt;Three-Term Recurrence&lt;/head&gt;
    &lt;p&gt;This tridiagonal structure leads to a beautiful simplification. To build the next basis vector , we don’t need the entire history of vectors. We only need the two previous ones. Since is Hermitian, this guarantees that any new vector is automatically orthogonal to all earlier vectors (beyond the previous two). So we can skip the full orthogonalization and use a simple three-term recurrence:&lt;/p&gt;
    &lt;p&gt;Rearranging gives us an algorithm to compute directly:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compute the candidate:&lt;/item&gt;
      &lt;item&gt;Extract the diagonal coefficient:&lt;/item&gt;
      &lt;item&gt;Orthogonalize against the two previous vectors:&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Normalize: and&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is known as the Lanczos algorithm. It’s more efficient than Arnoldi because each iteration only orthogonalizes against two previous vectors instead of all prior ones.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reconstructing the Solution&lt;/head&gt;
    &lt;p&gt;After iterations, we end up with the tridiagonal matrix and all basis vectors . We can then reconstruct the approximate solution as:&lt;/p&gt;
    &lt;p&gt;where is solved from the small tridiagonal matrix.&lt;/p&gt;
    &lt;p&gt;There is a timing problem however: we cannot compute the coefficients until all iterations are complete. The full matrix is only available at the end, so we must store every basis vector along the way, leading to a memory cost of .&lt;/p&gt;
    &lt;p&gt;So we’re left with a choice: whether we store all the basis vectors and solve the problem in passes, or find a way to avoid storing them. There is a middle ground.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There are also techniques to compress the basis vectors, have a look here&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h1"&gt;Two-Pass Algorithm&lt;/head&gt;
    &lt;p&gt;Here’s where we break the timing deadlock. The insight that we don’t actually need to store the basis vectors if we can afford to compute them twice&lt;/p&gt;
    &lt;p&gt;Think about what we have after the first pass. We’ve computed all the and coefficients that compose the entire tridiagonal matrix . These numbers are small compared to the full basis. What if we kept only these scalars, discarded all the vectors, and then replayed the Lanczos recurrence a second time? We’d regenerate the same basis, and this time we’d use it to build the solution.&lt;/p&gt;
    &lt;p&gt;This comes at a cost. We run Lanczos twice, so we pay for matrix-vector products instead of . But we only ever store a constant number of vectors in memory, no basis matrix. The memory complexity drops to .&lt;/p&gt;
    &lt;p&gt;It sounds like a bad trade at first. But as we’ll see later, the cache behavior of this two-pass approach can actually make it as fast (or even faster) on real hardware if well optimized.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Pass: Compute the Projected Problem&lt;/head&gt;
    &lt;p&gt;We initialize and set , .Then we run the standard Lanczos recurrence:&lt;/p&gt;
    &lt;p&gt;At each step, we record and . But we do not store . Instead, we discard it immediately after computing . In this way we only keep in memory at most just three vectors at any time (, , and the working vector ).&lt;/p&gt;
    &lt;p&gt;After iterations, we have the full set . These scalars define the tridiagonal matrix . We can now solve:&lt;/p&gt;
    &lt;p&gt;This is the solution in the reduced space. Now that we have the coefficients we need to build .&lt;/p&gt;
    &lt;head rend="h2"&gt;Second Pass: Reconstruct and Accumulate&lt;/head&gt;
    &lt;p&gt;With in memory, we replay the Lanczos recurrence exactly as before. We start with the same initialization (, , ) and apply the same sequence of operations, using the stored scalars and to reconstruct each basis vector on demand. We can write some rust-like pseudocode for this second pass to get a feel for it:&lt;/p&gt;
    &lt;code&gt;let mut x_k = vec![0.0; n];
let mut v_prev = vec![0.0; n];
let mut v_curr = b.clone() / b_norm;

for j in 1..=k {
    let w = A @ v_curr;  // Matrix-vector product

    // We don't recompute alpha/beta; we already have them from pass 1
    let alpha_j = alphas[j - 1];
    let beta_prev = j &amp;gt; 1 ? betas[j - 2] : 0.0;

    // Accumulate the solution
    x_k += y_k[j - 1] * v_curr;

    // Regenerate the next basis vector for the *next* iteration
    let v_next = (w - alpha_j * v_curr - beta_prev * v_prev) / betas[j - 1];

    // Slide the window forward
    v_prev = v_curr;
    v_curr = v_next;
}&lt;/code&gt;
    &lt;p&gt;This loop regenerates each on demand and immediately uses it to update the solution. Once we’ve accumulated into , we discard the vector. We never store the full basis.&lt;/p&gt;
    &lt;head rend="h3"&gt;A Subtle Numerical Point&lt;/head&gt;
    &lt;p&gt;There is one detail worth noting: floating-point arithmetic is deterministic. When we replay the Lanczos recurrence in the second pass with the exact same inputs and the exact same order of operations, we get bitwise-identical vectors. The regenerated in pass 2 are identical to the ones computed in pass 1.&lt;/p&gt;
    &lt;p&gt;However, the order in which we accumulate the solution differs. In a standard Lanczos, is built as a single matrix-vector product: (a &lt;code&gt;gemv&lt;/code&gt; call in BLAS). In the two-pass method, it’s built as a loop of scaled vector additions (a series of &lt;code&gt;axpy&lt;/code&gt; calls). These operations accumulate rounding error differently, so the final solution differs slightly, typically by machine epsilon. This rarely matters in practice, and convergence is unaffected.&lt;/p&gt;
    &lt;head rend="h1"&gt;Implementation&lt;/head&gt;
    &lt;p&gt;Building this in Rust forces us to think concretely about where data lives and how it flows through the cache hierarchy. We need to control memory layout, decide when allocations happen, and choose abstractions that cost us nothing at runtime.&lt;/p&gt;
    &lt;p&gt;For linear algebra, we reach for &lt;code&gt;faer&lt;/code&gt;. Three design choices in this library matter for what we’re building:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Stack allocation via &lt;code&gt;MemStack&lt;/code&gt;: Pre-allocated scratch space that lives for the entire computation. The hot path becomes allocation-free.&lt;/item&gt;
      &lt;item&gt;Matrix-free operators: The &lt;code&gt;LinOp&lt;/code&gt;trait defines an operator by its action (&lt;code&gt;apply&lt;/code&gt;) without materializing a matrix. For large sparse problems, this is the only viable approach.&lt;/item&gt;
      &lt;item&gt;SIMD-friendly loops: The &lt;code&gt;zip!&lt;/code&gt;macro generates code that compiles to packed instructions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Recurrence Step&lt;/head&gt;
    &lt;p&gt;Our starting point is the Lanczos three-term recurrence that we derived earlier:&lt;/p&gt;
    &lt;p&gt;We can translate this into a recurrence step function. The signature looks like this:&lt;/p&gt;
    &lt;code&gt;fn lanczos_recurrence_step&amp;lt;T: ComplexField, O: LinOp&amp;lt;T&amp;gt;&amp;gt;(
    operator: &amp;amp;O,
    mut w: MatMut&amp;lt;'_, T&amp;gt;,
    v_curr: MatRef&amp;lt;'_, T&amp;gt;,
    v_prev: MatRef&amp;lt;'_, T&amp;gt;,
    beta_prev: T::Real,
    stack: &amp;amp;mut MemStack,
) -&amp;gt; (T::Real, Option&amp;lt;T::Real&amp;gt;)&lt;/code&gt;
    &lt;p&gt;The function is generic over the field type &lt;code&gt;T&lt;/code&gt; (&lt;code&gt;f64&lt;/code&gt;, &lt;code&gt;c64&lt;/code&gt;, etc.) and the operator type &lt;code&gt;O&lt;/code&gt;. It operates on matrix views (&lt;code&gt;MatMut&lt;/code&gt; and &lt;code&gt;MatRef&lt;/code&gt;) to avoid unnecessary data copies. The return type gives us the diagonal element  and, if no breakdown occurs, the off-diagonal .&lt;/p&gt;
    &lt;p&gt;Now we can implement the body by following the math. The first step is the most expensive:&lt;/p&gt;
    &lt;code&gt;// 1. Apply operator: w = A * v_curr
operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);&lt;/code&gt;
    &lt;p&gt;The matrix-vector product dominates the computational cost. Everything else is secondary.&lt;/p&gt;
    &lt;p&gt;Next, we orthogonalize against . This is where we benefit from &lt;code&gt;faer&lt;/code&gt;’s design. The &lt;code&gt;zip!&lt;/code&gt; macro fuses this operation into a single loop that the compiler vectorizes into SIMD instructions.&lt;/p&gt;
    &lt;code&gt;// 2. Orthogonalize against v_{j-1}: w -= β_{j-1} * v_{j-1}
let beta_prev_scaled = T::from_real_impl(&amp;amp;beta_prev);
zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
    *w_i = sub(w_i, &amp;amp;mul(&amp;amp;beta_prev_scaled, v_prev_i));
});&lt;/code&gt;
    &lt;p&gt;With &lt;code&gt;w&lt;/code&gt; partially orthogonalized, we can compute the diagonal coefficient via an inner product. Since  is Hermitian,  is guaranteed real.&lt;/p&gt;
    &lt;code&gt;// 3. Compute α_j = v_j^H * w
let alpha = T::real_part_impl(&amp;amp;(v_curr.adjoint() * w.rb())[(0, 0)]);&lt;/code&gt;
    &lt;p&gt;We complete the orthogonalization against with another &lt;code&gt;zip!&lt;/code&gt; loop.&lt;/p&gt;
    &lt;code&gt;// 4. Orthogonalize against v_j: w -= α_j * v_j
let alpha_scaled = T::from_real_impl(&amp;amp;alpha);
zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
    *w_i = sub(w_i, &amp;amp;mul(&amp;amp;alpha_scaled, v_curr_i));
});&lt;/code&gt;
    &lt;p&gt;Now &lt;code&gt;w&lt;/code&gt; holds the unnormalized next basis vector. We compute its norm to get . If this norm is numerically zero, the Krylov subspace is invariant, the iteration has reached its natural stopping point. This is called breakdown.&lt;/p&gt;
    &lt;code&gt;// 5. Compute β_j = ||w||_2 and check for breakdown
let beta = w.rb().norm_l2();
let tolerance = breakdown_tolerance::&amp;lt;T::Real&amp;gt;();

if beta &amp;lt;= tolerance {
    (alpha, None)
} else {
    (alpha, Some(beta))
}&lt;/code&gt;
    &lt;p&gt;The function returns &lt;code&gt;None&lt;/code&gt; for  when breakdown occurs, signaling to the caller that no further iterations should proceed.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Iterator for State Management&lt;/head&gt;
    &lt;p&gt;The recurrence step is a pure function, but calling it in a loop is both inefficient and awkward. We’d need to manually pass vectors in and out of each iteration. More critically, we’d create copies when we should be reusing memory.&lt;/p&gt;
    &lt;p&gt;The iterator pattern solves this. We create a struct that encapsulates the state:&lt;/p&gt;
    &lt;code&gt;struct LanczosIteration&amp;lt;'a, T: ComplexField, O: LinOp&amp;lt;T&amp;gt;&amp;gt; {
    operator: &amp;amp;'a O,
    v_prev: Mat&amp;lt;T&amp;gt;,       // v_{j-1}
    v_curr: Mat&amp;lt;T&amp;gt;,       // v_j
    work: Mat&amp;lt;T&amp;gt;,         // Workspace for the next vector
    beta_prev: T::Real,   // β_{j-1}
    // ... iteration counters
}&lt;/code&gt;
    &lt;p&gt;The main design choice here is that vectors are owned (&lt;code&gt;Mat&amp;lt;T&amp;gt;&lt;/code&gt;), not borrowed. This enables an optimization in the &lt;code&gt;next_step&lt;/code&gt; method. After computing the next vector and normalizing it into &lt;code&gt;work&lt;/code&gt;, we cycle the state without allocating or copying:&lt;/p&gt;
    &lt;code&gt;// Inside next_step, after normalization...
core::mem::swap(&amp;amp;mut self.v_prev, &amp;amp;mut self.v_curr);
core::mem::swap(&amp;amp;mut self.v_curr, &amp;amp;mut self.work);&lt;/code&gt;
    &lt;p&gt;On x86-64, swapping two &lt;code&gt;Mat&amp;lt;T&amp;gt;&lt;/code&gt; structures (fat pointers) compiles to three &lt;code&gt;mov&lt;/code&gt; instructions. The pointers change, but no vector data moves. After the swap, &lt;code&gt;v_prev&lt;/code&gt; points to what &lt;code&gt;v_curr&lt;/code&gt; held, &lt;code&gt;v_curr&lt;/code&gt; points to &lt;code&gt;work&lt;/code&gt;’s allocation, and &lt;code&gt;work&lt;/code&gt; points to the old &lt;code&gt;v_prev&lt;/code&gt; data. In the next iteration, &lt;code&gt;work&lt;/code&gt; gets reused.&lt;/p&gt;
    &lt;p&gt;We keep exactly three n-dimensional vectors live in memory. The same allocations cycle through the computation, staying hot in L1 cache. This is the core reason the two-pass method can be faster than expected, the working set never leaves cache.&lt;/p&gt;
    &lt;head rend="h2"&gt;First Pass: Computing the Decomposition&lt;/head&gt;
    &lt;p&gt;The first pass runs the Lanczos iteration and collects the coefficients . Basis vectors are discarded after each step.&lt;/p&gt;
    &lt;code&gt;pub fn lanczos_pass_one&amp;lt;T: ComplexField&amp;gt;(
    operator: &amp;amp;impl LinOp&amp;lt;T&amp;gt;,
    b: MatRef&amp;lt;'_, T&amp;gt;,
    k: usize,
    stack: &amp;amp;mut MemStack,
) -&amp;gt; Result&amp;lt;LanczosDecomposition&amp;lt;T::Real&amp;gt;, LanczosError&amp;gt; {
    // ...
}&lt;/code&gt;
    &lt;p&gt;We allocate vectors for the coefficients with a capacity hint to avoid reallocations:&lt;/p&gt;
    &lt;code&gt;let mut alphas = Vec::with_capacity(k);
let mut betas = Vec::with_capacity(k - 1);&lt;/code&gt;
    &lt;p&gt;Then we construct the iterator. This allocates the three work vectors once. After this point, the hot path is allocation-free:&lt;/p&gt;
    &lt;code&gt;let mut lanczos_iter = LanczosIteration::new(operator, b, k, b_norm)?;

for i in 0..k {
    if let Some(step) = lanczos_iter.next_step(stack) {
        alphas.push(step.alpha);
        steps_taken += 1;

        let tolerance = breakdown_tolerance::&amp;lt;T::Real&amp;gt;();
        if step.beta &amp;lt;= tolerance {
            break;
        }

        if i &amp;lt; k - 1 {
            betas.push(step.beta);
        }
    } else {
        break;
    }
}&lt;/code&gt;
    &lt;p&gt;The check for breakdown stops the iteration when the residual becomes numerically zero. This means we’ve found an invariant subspace and there’s no value in continuing.&lt;/p&gt;
    &lt;p&gt;At the end, we collect the scalars into a &lt;code&gt;LanczosDecomposition&lt;/code&gt; struct. The memory footprint throughout this pass is constant: three n-dimensional vectors plus two small arrays that grow to at most  elements.&lt;/p&gt;
    &lt;head rend="h2"&gt;Second Pass: Reconstructing the Solution&lt;/head&gt;
    &lt;p&gt;Now we face a different problem. We have the coefficients from the first pass and the coefficient vector from solving the projected problem. We need to reconstruct the solution:&lt;/p&gt;
    &lt;p&gt;without storing the full basis matrix .&lt;/p&gt;
    &lt;p&gt;The recurrence step in this pass is structurally similar to the first pass, but with a key difference: we no longer compute inner products or norms. We already know the coefficients, so the step becomes pure reconstruction.&lt;/p&gt;
    &lt;code&gt;fn lanczos_reconstruction_step&amp;lt;T: ComplexField, O: LinOp&amp;lt;T&amp;gt;&amp;gt;(
    operator: &amp;amp;O,
    mut w: MatMut&amp;lt;'_, T&amp;gt;,
    v_curr: MatRef&amp;lt;'_, T&amp;gt;,
    v_prev: MatRef&amp;lt;'_, T&amp;gt;,
    alpha_j: T::Real,
    beta_prev: T::Real,
    stack: &amp;amp;mut MemStack,
) {
    // Apply operator
    operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);

    // Orthogonalize using stored α_j and β_{j-1}
    let beta_prev_scaled = T::from_real_impl(&amp;amp;beta_prev);
    zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
        *w_i = sub(w_i, &amp;amp;mul(&amp;amp;beta_prev_scaled, v_prev_i));
    });

    let alpha_scaled = T::from_real_impl(&amp;amp;alpha_j);
    zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
        *w_i = sub(w_i, &amp;amp;mul(&amp;amp;alpha_scaled, v_curr_i));
    });
}&lt;/code&gt;
    &lt;p&gt;This is cheaper than the first-pass recurrence. We’ve eliminated the inner products that computed and the norm calculation for . What remains is pure orthogonalization and the operator application.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;lanczos_pass_two&lt;/code&gt; implements this reconstruction. We initialize the three work vectors and the solution accumulator:&lt;/p&gt;
    &lt;code&gt;pub fn lanczos_pass_two&amp;lt;T: ComplexField&amp;gt;(
    operator: &amp;amp;impl LinOp&amp;lt;T&amp;gt;,
    b: MatRef&amp;lt;'_, T&amp;gt;,
    decomposition: &amp;amp;LanczosDecomposition&amp;lt;T::Real&amp;gt;,
    y_k: MatRef&amp;lt;'_, T&amp;gt;,
    stack: &amp;amp;mut MemStack,
) -&amp;gt; Result&amp;lt;Mat&amp;lt;T&amp;gt;, LanczosError&amp;gt; {
    let mut v_prev = Mat::&amp;lt;T&amp;gt;::zeros(b.nrows(), 1);
    let inv_norm = T::from_real_impl(&amp;amp;T::Real::recip_impl(&amp;amp;decomposition.b_norm));
    let mut v_curr = b * Scale(inv_norm);  // v_1

    let mut work = Mat::&amp;lt;T&amp;gt;::zeros(b.nrows(), 1);

    // Initialize solution with first component
    let mut x_k = &amp;amp;v_curr * Scale(T::copy_impl(&amp;amp;y_k[(0, 0)]));&lt;/code&gt;
    &lt;p&gt;We build the solution incrementally by starting with the first basis vector scaled by its coefficient. The main loop then regenerates each subsequent vector: we regenerate each subsequent basis vector, normalize it using the stored , and immediately accumulate its contribution:&lt;/p&gt;
    &lt;code&gt;for j in 0..decomposition.steps_taken - 1 {
    let alpha_j = T::Real::copy_impl(&amp;amp;decomposition.alphas[j]);
    let beta_j = T::Real::copy_impl(&amp;amp;decomposition.betas[j]);
    let beta_prev = if j == 0 {
        T::Real::zero_impl()
    } else {
        T::Real::copy_impl(&amp;amp;decomposition.betas[j - 1])
    };

    // 1. Regenerate the unnormalized next vector
    lanczos_reconstruction_step(
        operator,
        work.as_mut(),
        v_curr.as_ref(),
        v_prev.as_ref(),
        alpha_j,
        beta_prev,
        stack,
    );

    // 2. Normalize using stored β_j
    let inv_beta = T::from_real_impl(&amp;amp;T::Real::recip_impl(&amp;amp;beta_j));
    zip!(work.as_mut()).for_each(|unzip!(w_i)| {
        *w_i = mul(w_i, &amp;amp;inv_beta);
    });

    // 3. Accumulate: x_k += y_{j+1} * v_{j+1}
    let coeff = T::copy_impl(&amp;amp;y_k[(j + 1, 0)]);
    zip!(x_k.as_mut(), work.as_ref()).for_each(|unzip!(x_i, v_i)| {
        *x_i = add(x_i, &amp;amp;mul(&amp;amp;coeff, v_i));
    });

    // 4. Cycle vectors for the next iteration
    core::mem::swap(&amp;amp;mut v_prev, &amp;amp;mut v_curr);
    core::mem::swap(&amp;amp;mut v_curr, &amp;amp;mut work);
}&lt;/code&gt;
    &lt;p&gt;The accumulation &lt;code&gt;x_k += y_{j+1} * v_{j+1}&lt;/code&gt; is implemented as a fused multiply-add in the &lt;code&gt;zip!&lt;/code&gt; loop. On hardware with FMA support, this becomes a single instruction per element, not three separate operations.&lt;/p&gt;
    &lt;p&gt;Note that we accumulate the solution incrementally. After each iteration, &lt;code&gt;x_k&lt;/code&gt; contains a partial result. We cycle through the same three vectors (&lt;code&gt;v_prev&lt;/code&gt;, &lt;code&gt;v_curr&lt;/code&gt;, &lt;code&gt;work&lt;/code&gt;), keeping the working set small and resident in L1 cache.&lt;/p&gt;
    &lt;p&gt;Compare this to the standard method’s final reconstruction step: . This is a dense matrix-vector product where is . When and are both large, this matrix no longer fits in cache. The CPU must stream it from main memory, paying the cost of memory latency. Each element requires a load, multiply, and accumulate, but the load operations dominate—the CPU stalls waiting for data.&lt;/p&gt;
    &lt;p&gt;In our two-pass reconstruction, the operator &lt;code&gt;$\mathbf{A}$&lt;/code&gt; is applied  times, but against vectors that stay in cache. The memory bandwidth is spent on reading the sparse structure of  and the vector elements, not on scanning a dense  matrix.&lt;/p&gt;
    &lt;p&gt;This is the reason the two-pass method can be faster on real hardware despite performing twice as many matrix-vector products. The cache behavior of the reconstruction phase overwhelms the savings of storing the basis.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Public API&lt;/head&gt;
    &lt;p&gt;We can wrap the two passes into a single entry point:&lt;/p&gt;
    &lt;code&gt;pub fn lanczos_two_pass&amp;lt;T, O, F&amp;gt;(
    operator: &amp;amp;O,
    b: MatRef&amp;lt;'_, T&amp;gt;,
    k: usize,
    stack: &amp;amp;mut MemStack,
    mut f_tk_solver: F,
) -&amp;gt; Result&amp;lt;Mat&amp;lt;T&amp;gt;, LanczosError&amp;gt;
where
    T: ComplexField,
    O: LinOp&amp;lt;T&amp;gt;,
    F: FnMut(&amp;amp;[T::Real], &amp;amp;[T::Real]) -&amp;gt; Result&amp;lt;Mat&amp;lt;T&amp;gt;, anyhow::Error&amp;gt;,
{
    // First pass: compute T_k coefficients
    let decomposition = lanczos_pass_one(operator, b, k, stack)?;

    if decomposition.steps_taken == 0 {
        return Ok(Mat::zeros(b.nrows(), 1));
    }

    // Solve projected problem: y_k' = f(T_k) * e_1
    let y_k_prime = f_tk_solver(&amp;amp;decomposition.alphas, &amp;amp;decomposition.betas)?;

    // Scale by ||b||
    let y_k = &amp;amp;y_k_prime * Scale(T::from_real_impl(&amp;amp;decomposition.b_norm));

    // Second pass: reconstruct solution
    lanczos_pass_two(operator, b, &amp;amp;decomposition, y_k.as_ref(), stack)
}&lt;/code&gt;
    &lt;p&gt;The design separates concerns. The &lt;code&gt;f_tk_solver&lt;/code&gt; closure is where we inject the specific matrix function. We compute the Lanczos decomposition, then pass the coefficients to the user-provided solver, which computes  for whatever function  is needed. This decoupling means we handle linear solves, matrix exponentials, or any other function without modifying the core algorithm.&lt;/p&gt;
    &lt;p&gt;The caller provides &lt;code&gt;f_tk_solver&lt;/code&gt; as a closure. It receives the raw  arrays and must return the coefficient vector . We then scale it by  and pass everything to the second pass.&lt;/p&gt;
    &lt;head rend="h3"&gt;Example: Solving a Linear System&lt;/head&gt;
    &lt;p&gt;To see this in practice, consider solving . We compute , which means the &lt;code&gt;f_tk_solver&lt;/code&gt; must solve the small tridiagonal system .&lt;/p&gt;
    &lt;p&gt;Since is tridiagonal, we can exploit its structure. A sparse LU factorization solves it in time instead of the cost of a dense method.&lt;/p&gt;
    &lt;code&gt;let f_tk_solver = |alphas: &amp;amp;[f64], betas: &amp;amp;[f64]| -&amp;gt; Result&amp;lt;Mat&amp;lt;f64&amp;gt;, anyhow::Error&amp;gt; {
    let steps = alphas.len();
    if steps == 0 {
        return Ok(Mat::zeros(0, 1));
    }

    // 1. Assemble T_k from coefficients using triplet format
    let mut triplets = Vec::with_capacity(3 * steps - 2);
    for (i, &amp;amp;alpha) in alphas.iter().enumerate() {
        triplets.push(Triplet { row: i, col: i, val: alpha });
    }
    for (i, &amp;amp;beta) in betas.iter().enumerate() {
        triplets.push(Triplet { row: i, col: i + 1, val: beta });
        triplets.push(Triplet { row: i + 1, col: i, val: beta });
    }
    let t_k_sparse = SparseColMat::try_new_from_triplets(steps, steps, &amp;amp;triplets)?;

    // 2. Construct e_1
    let mut e1 = Mat::zeros(steps, 1);
    e1.as_mut()[(0, 0)] = 1.0;

    // 3. Solve T_k * y' = e_1 via sparse LU
    Ok(t_k_sparse.as_ref().sp_lu()?.solve(e1.as_ref()))
};&lt;/code&gt;
    &lt;p&gt;The closure takes the coefficient arrays, constructs the sparse tridiagonal matrix, and solves the system. The triplet format lets us build the matrix efficiently without knowing its structure in advance. The sparse LU solver leverages the tridiagonal structure to avoid dense factorization.&lt;/p&gt;
    &lt;head rend="h1"&gt;Some interesting results&lt;/head&gt;
    &lt;p&gt;Now that we have a working implementation we can run some tests. The core idea of what we have done is simple: trade flops for better memory access. But does this trade actually pay off on real hardware? To find out, we need a reliable way to benchmark it.&lt;/p&gt;
    &lt;p&gt;For the data, we know that the performance of any Krylov method is tied to the operator’s spectral properties. We need a way to generate a family of test problems where we can precisely control the size, sparsity, and numerical difficulty. A great way to do this is with Karush-Kuhn-Tucker (KKT) systems, which are sparse, symmetric, and have a specific block structure.&lt;/p&gt;
    &lt;p&gt;This structure gives us two critical knobs to turn. First, with the netgen utility, we can control the matrix, which lets us dial in the problem dimension, . Second, we build the diagonal block D with random entries from a range . This parameter, , gives us direct control over the numerical difficulty of the problem.&lt;/p&gt;
    &lt;p&gt;For a symmetric matrix like , the 2-norm condition number, , is the ratio of its largest to its smallest eigenvalue: . Since is diagonal, its eigenvalues are simply its diagonal entries. We are drawing these entries from a uniform distribution , so we have and . This means we get direct control, as .The spectral properties of this block heavily influence the spectrum of the entire matrix . A large condition number in leads to a more ill-conditioned system for . The convergence rate of Krylov methods like Lanczos is fundamentally governed by the distribution of the operator’s eigenvalues. An ill-conditioned matrix, with a wide spread of eigenvalues, will require more iterations, , to reach the desired accuracy. By simply adjusting the parameter, we can generate everything from well-conditioned problems that converge quickly to ill-conditioned ones that force us to run a large number of iterations. This is exactly what we need to rigorously test our implementation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Memory and Computation Trade-off&lt;/head&gt;
    &lt;p&gt;We measure the algorithm against two hypotheses on a large sparse problem with , varying the number of iterations .&lt;/p&gt;
    &lt;p&gt;Hypothesis 1 (Memory): The one-pass method stores the full basis with complexity . We expect its memory to grow linearly with . The two-pass method operates with memory, so it should have a flat profile.&lt;/p&gt;
    &lt;p&gt;Hypothesis 2 (Runtime): The two-pass method performs matrix-vector products instead of . If all else were equal, we’d expect it to run twice as slow.&lt;/p&gt;
    &lt;head rend="h3"&gt;Memory Usage&lt;/head&gt;
    &lt;p&gt;The memory data confirms Hypothesis 1 exactly. The one-pass method’s footprint scales as a straight line—each additional iteration adds one vector to the basis. The two-pass method remains flat. No allocation growth happens after initialization.&lt;/p&gt;
    &lt;head rend="h3"&gt;Runtime: Where Theory Breaks&lt;/head&gt;
    &lt;p&gt;The runtime data contradicts Hypothesis 2. The two-pass method is slower, but never by a factor of two. For small , the gap is minimal. As grows, the two-pass runtime diverges slowly from the one-pass method, not by doubling, but by a much smaller margin.&lt;/p&gt;
    &lt;p&gt;This difference comes from memory access patterns. Both methods perform matrix-vector products, but they differ in how they reconstruct the solution.&lt;/p&gt;
    &lt;p&gt;The one-pass method computes in a single dense matrix-vector product. When and are large, the basis matrix exceeds all cache levels. The CPU cannot keep the data resident; instead, it streams from main memory. This is a memory-bandwidth-bound operation. The processor stalls, waiting for each load to complete. Instruction-level parallelism collapses.&lt;/p&gt;
    &lt;p&gt;The two-pass method reconstructs the solution incrementally. At each iteration, it operates on exactly three n-dimensional vectors: , , and . This working set fits in L1 cache. The processor performs matrix-vector products (each one reading the sparse operator, then applying it to a cached vector), but the solution accumulation happens entirely within cache. The additional matrix-vector products are cheaper than the memory latency of the standard method.&lt;/p&gt;
    &lt;p&gt;The cost of re-computing basis vectors is less than the latency cost of scanning an dense matrix from main memory.&lt;/p&gt;
    &lt;head rend="h3"&gt;Medium-Scale Behavior&lt;/head&gt;
    &lt;p&gt;At we can observe an equilibrium. The two methods have nearly identical runtime. The standard method’s matrix is smaller; it fits partially in cache. The cache-miss penalty here becomes manageable. The two-pass method still has the advantage of cache-local accumulation, but the difference is marginal.&lt;/p&gt;
    &lt;head rend="h3"&gt;What About Dense Matrices?&lt;/head&gt;
    &lt;p&gt;To be sure of our hypothesis, we can test it directly using a dense matrix of size . For dense problems, the matrix-vector product is , it dominates all other costs. Memory latency will become negligible relative to the compute work and the cache efficiency advantage should disappear.&lt;/p&gt;
    &lt;p&gt;We can see that the two-pass method runs almost exactly twice as slow as the one-pass method. The slope ratio is exactly 2:1. In a compute-bound regime, the extra matrix-vector products cannot be hidden by cache effects. Here, the theoretical trade-off holds perfectly.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scalability&lt;/head&gt;
    &lt;p&gt;Now, let’s fix the iteration count at and vary from to to measure scalability. Based on what we have seen before, we would expect the two-pass memory to scale linearly with but with a small constant factor (three vectors, plus scalars). The one-pass method should also scale linearly, but with a -dependent slope.&lt;/p&gt;
    &lt;p&gt;Here we have to use a logarithmic y-axis to show both curves; the two-pass line is so flat relative to the one-pass line that it’s otherwise invisible.&lt;/p&gt;
    &lt;p&gt;Runtime scales linearly with for both methods, as expected. Below , the two methods have similar performance. This is the regime where both basis and working set fit in cache, or where the problem is small enough that memory latency is not the bottleneck.&lt;/p&gt;
    &lt;p&gt;As increases beyond , the matrix-vector product time dominates. The sparse structure of ensures that each matvec requires multiple memory accesses per element. For the one-pass method, the final reconstruction of begins to cost more as the matrix grows. For the two-pass method, performing matrix-vector products means the matvec cost accumulates more rapidly. The divergence is gradual, not sharp, because the advantage of cache locality in accumulation persists—but it cannot overcome the fundamental cost of doubling the number of expensive operations.&lt;/p&gt;
    &lt;p&gt;Well, that’s it. If you want to have a better look at the code or use it, it’s all open source:&lt;/p&gt;
    &lt;p&gt;This was more of an exploration than a production-ready library, so expect rough edges. But I hope it gives an interesting perspective on how algorithm engineering and low-level implementation details can alter what seems like a straightforward trade-off on a blackboard.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lukefleed.xyz/posts/cache-friendly-low-memory-lanczos/"/><published>2025-11-11T17:08:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45890186</id><title>We ran over 600 image generations to compare AI image models</title><updated>2025-11-11T21:09:19.541194+00:00</updated><content>&lt;doc fingerprint="371511f4993ed21d"&gt;
  &lt;main&gt;
    &lt;p&gt;tl:dr; We’ve been making photo apps for iOS for long enough that we have gray hairs now, and using our experience we ran over 600 image generations to compare which AI models work best for which image edits. If you want, you can jump right to the image comparisons, or the conclusion, but promise us you won’t presumptuous comments on Hacker News until you’ve also read the background!&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;Hi! We’re LateNiteSoft, and we’ve been working on photography-related iOS apps for 15 years now. Working on market-leading apps such as Camera+, Photon and REC, we’ve always had our finger on the pulse on what users want out of their mobile photography.&lt;/p&gt;
    &lt;p&gt;With the ground-breaking release of OpenAI’s gpt-image-1 image generation model earlier this year, we started investigating all the interesting use cases we could think of for AI image editing.&lt;/p&gt;
    &lt;p&gt;But as a company that has never taken any venture capital investment, all our products have to pay for themselves. We’re in it to delight our users, not just capture market share and sell them out. When considering AI projects, one thing has been clear – we can’t take the AI startup road where you have a generous free tier, charge an unreasonably small monthly fee for “unlimited”, and hope you’re going to make it up on scale (code for “someone please acquire us”).&lt;/p&gt;
    &lt;p&gt;All the AI-focused billing systems we could find out there were based on this. Assuming you want to claim unlimited access, and then sandbag users with “fair use” clauses and prevent them from any actual unlimited usage (which is, obviously, untenable, since you’ll end up with one $20/mo user reselling to everyone else).&lt;/p&gt;
    &lt;p&gt;Since we want to fairly charge our customers for what they actually use, we’ve built a credit-based “pay per generation”-style billing system (that internally we’ve been calling CreditProxy). We’ve also been planning on providing this as a service, since nobody else seems to be doing it, so if you’re interested in being a trial user, get in touch!&lt;/p&gt;
    &lt;p&gt;We released our app MorphAI as a public proof of concept to give CreditProxy a proper real world-test, and have marketed it to the users of Camera+, which includes traditional photo-editing functionality, including a whole host of popular photo filters, giving us a built-in audience of customers ready for the next step in image editing.&lt;/p&gt;
    &lt;p&gt;With the release of newer models like nanoBanana and Seedream, we’ve had to consider which models make sense to support. We need to explore the trade-offs between quality, prompt complexity, and pricing.&lt;/p&gt;
    &lt;p&gt;A couple of hastily-hacked together scripts, and many, many AI generation credits later, we have some results! So that everyone else also doesn’t have to waste their money, we figured we’d share what we found:&lt;/p&gt;
    &lt;head rend="h2"&gt;The Tests&lt;/head&gt;
    &lt;p&gt;Based on our experience with Camera+ and the kind of edits our users have been making with MorphAI, we picked a host of somewhat naive prompts. Veteran Midjourney users may scoff at these, but in our experience these are the kinds of prompts that our average user is likely to use.&lt;/p&gt;
    &lt;p&gt;As for test photos, we chose some some representative things people like to take photos of: their pets, their kids, landscapes, their cars, and product photography.&lt;/p&gt;
    &lt;p&gt;Image generation times are also relevant. During our test period, the generation time for all models was fairly consistent, and didn’t vary by image or prompt complexity.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;OpenAI (High)&lt;/cell&gt;
        &lt;cell&gt;Gemini&lt;/cell&gt;
        &lt;cell&gt;Seedream&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80 seconds&lt;/cell&gt;
        &lt;cell&gt;11 seconds&lt;/cell&gt;
        &lt;cell&gt;9 seconds&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;OpenAI also has a quality setting, the images included here were all generated on High quality, but we also tested Medium, and those generations averaged 36 seconds. We can include the Medium quality images as well if there is any interest!&lt;/p&gt;
    &lt;p&gt;There are a ton of photos to compare here, so to make things easier to flip through, here are some keyboard shortcuts to help you out: Click on a photo to see it larger. Now you can use the arrow keys to switch between models. Press the tab key to switch between test images. Hit ESC to leave the view.&lt;/p&gt;
    &lt;head rend="h2"&gt;Classic filters&lt;/head&gt;
    &lt;p&gt;These are the types of filters that we used to implement manually, by painstakingly hand-crafting textures and Photoshop layers and then converting those to Objective-C code. Now all you need is a few words into a language model (and to burn down half of a rain forest or so; just the cost of progress).&lt;/p&gt;
    &lt;p&gt;Our conclusion for this category is that for photo realistic filters like this, Gemini really shines by preserving details from the original and minimizing hallucinations, but often at the expense of the strength and creativity of the effect. Especially with photos of people, Gemini seems to refuse to apply any edits at all, with a strong bias towards photo realism.&lt;/p&gt;
    &lt;p&gt;OpenAI really likes to mess with the details of the photo, giving a characteristic “AI slop” feel, which can be a deal breaker on things like human faces.&lt;/p&gt;
    &lt;head rend="h3"&gt;Grungy vintage photo&lt;/head&gt;
    &lt;head rend="h3"&gt;Use soft, diffused lighting&lt;/head&gt;
    &lt;head rend="h3"&gt;Transform into a kaleidoscopic pattern&lt;/head&gt;
    &lt;p&gt;Gemini took some really odd shortcuts in generating some of these!&lt;/p&gt;
    &lt;head rend="h3"&gt;Apply a heat map effect&lt;/head&gt;
    &lt;p&gt;It’s clear that none of the models actually have a concept of what generates heat here, aside from Seedream knowing that humans generate heat, clearly revealing that without any ground truth the models struggle.&lt;/p&gt;
    &lt;head rend="h3"&gt;Make it look like a long exposure photograph&lt;/head&gt;
    &lt;p&gt;This is an interesting test since in some of the sample photos a long exposure doesn’t make sense. In the ones where it makes the most sense – the landscape and the car, OpenAI did the best, but on the other hand it completely messed up the cats and the product, and the portrait photo turned into a trippy art piece.&lt;/p&gt;
    &lt;p&gt;Gemini, maybe logically, did nothing. Seedream liked adding light streaks as if a car drove past, with only the portrait photo seemingly making any sense.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pinhole camera&lt;/head&gt;
    &lt;p&gt;In this case, it was funny to watch Gemini take a literal approach and generate actual pictures of cameras! For this reason we re-worked this prompt by just adding the word “effect”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pinhole camera effect&lt;/head&gt;
    &lt;p&gt;Gemini liked to generate a literal pinhole camera here so we tried modifying the prompt.&lt;/p&gt;
    &lt;head rend="h3"&gt;Add a layer of fog or mist&lt;/head&gt;
    &lt;head rend="h3"&gt;Make it look like it’s golden hour&lt;/head&gt;
    &lt;head rend="h3"&gt;Make it look like it’s etched in glass&lt;/head&gt;
    &lt;p&gt;With this prompt, there is ambiguity in what “it” is, so we tried a reworded prompt as well. Only OpenAI consistently knew what a traditional etched glass effect looks like. Seedream’s glass item effect looks really cool!&lt;/p&gt;
    &lt;head rend="h3"&gt;Make it look like the photo is etched in glass&lt;/head&gt;
    &lt;p&gt;Gemini has a really interesting interpretation here! And Seedream had some pretty fantastic results.&lt;/p&gt;
    &lt;head rend="h3"&gt;Remove background&lt;/head&gt;
    &lt;p&gt;This is a classic job people have spent their lives doing manually in Photoshop since the early 90’s. But what is a “background”, really? Is the ground in front of a car the “background”? We also retried this with a tweaked prompt.&lt;/p&gt;
    &lt;p&gt;OpenAI’s “sloppification” of the details of objects makes it useless for this purpose.&lt;/p&gt;
    &lt;head rend="h3"&gt;Isolate the object&lt;/head&gt;
    &lt;p&gt;With the tweaked prompt, Gemini’s API actually returned a followup question: “Which object would you like to isolate? There are two cats in the image.”, which our generation script was not prepared to handle! So it is missing from this comparison.&lt;/p&gt;
    &lt;head rend="h3"&gt;Give it a metallic sheen&lt;/head&gt;
    &lt;p&gt;Another case where “it” is vague and we can retry with a more specific prompt. The product imagery is another case where Seedream created a really stunning result, even adding a reflection of someone taking the photo with their phone!&lt;/p&gt;
    &lt;head rend="h3"&gt;Give the object a metallic sheen&lt;/head&gt;
    &lt;p&gt;Modifying the prompt here really only changed OpenAI’s interpretation.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lens effects&lt;/head&gt;
    &lt;p&gt;One of the filter packs we had worked on for Camera+ using traditional methods was a lens effect filter pack. But unlike traditional edits, with generative AI you can also create wide-angle lens effects that can just make up the portions of the image that the camera couldn’t capture.&lt;/p&gt;
    &lt;p&gt;This is another category where it’s very visible how OpenAI regenerates and hallucinates all the details in a picture, where Gemini and Seedream’s results are very faithful to the original and look more like actual lens permutations.&lt;/p&gt;
    &lt;head rend="h3"&gt;Apply a fish-eye lens effect&lt;/head&gt;
    &lt;head rend="h3"&gt;Strong bokeh blur&lt;/head&gt;
    &lt;p&gt;It was pretty surprising how poorly the models did here considering how common this must be among the training data. OpenAI give a strong blur but no bokeh effects. Gemini gives us a bunch of random circles in front of the image, demonstrating an understanding of what people want out of a bokeh filter but not how it works. Seedream does really well here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Apply a Dutch angle (canted frame)&lt;/head&gt;
    &lt;p&gt;OpenAI really lost it’s mind here on the car photo.&lt;/p&gt;
    &lt;head rend="h3"&gt;Change to a bird’s-eye view&lt;/head&gt;
    &lt;head rend="h2"&gt;Style transfer&lt;/head&gt;
    &lt;p&gt;Style Transfer is the process of applying an artistic style to a photo. This technique predates the current AI model by quite a few years with popular apps generating Van Gogh paintings out of your photos. We were also early out in attempting style transfer for our apps, shout out to Noel’s Intel iMac which had to run at full blast all night just to generate a 256x256px image, since it was our only machine with a compatible GPU.&lt;/p&gt;
    &lt;p&gt;While Gemini was good at preserving reality in the more photorealistic effects in the previous section, when it comes to the more artistic styles, OpenAI has them beat, while Gemini keeps things far too conservative, especially with photos of a human in them, where it sometimes seems to just do nothing at all, is this some kind of safety guardrail?&lt;/p&gt;
    &lt;head rend="h3"&gt;Draw this in the style of a Studio Ghibli movie&lt;/head&gt;
    &lt;p&gt;ChatGPT went viral with this prompt, with Sam Altman even making it his profile on X. And OpenAI keeps the crown – is Google too conservative in order to avoid a lawsuit? Seedream makes an attempt but they just end up looking like “generic Anime”.&lt;/p&gt;
    &lt;head rend="h3"&gt;Transform into watercolor painting&lt;/head&gt;
    &lt;head rend="h3"&gt;Make it look like a pastel artwork&lt;/head&gt;
    &lt;head rend="h3"&gt;Transform into Art Nouveau style&lt;/head&gt;
    &lt;head rend="h3"&gt;Apply a ukiyo-e Japanese woodblock print style&lt;/head&gt;
    &lt;p&gt;A very stark example of Gemini failing to apply a style on photos with humans. This is a prompt where Seedream knocked it out of the park, perhaps showing a larger portion of their training data being sourced from asian cultures than the western models.&lt;/p&gt;
    &lt;head rend="h3"&gt;Transform into low poly art&lt;/head&gt;
    &lt;p&gt;Seedream blows everyone else away here.&lt;/p&gt;
    &lt;head rend="h2"&gt;Portrait effects&lt;/head&gt;
    &lt;p&gt;For prompts about human appearance, we have only applied them to the portrait photo.&lt;/p&gt;
    &lt;head rend="h3"&gt;Make it look like a caricature&lt;/head&gt;
    &lt;p&gt;Seedream seems to be biased towards asian culture, giving an anime look instead of a western-style cartoon caricature.&lt;/p&gt;
    &lt;head rend="h3"&gt;Turn them into an action figure in the blister pack&lt;/head&gt;
    &lt;p&gt;OpenAI’s style here went viral a while back, but Gemini is stunningly realistic. Seedream is a weird mix of realistic and hallucinations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Generative edits&lt;/head&gt;
    &lt;p&gt;The place where generative AI really shines is when it can show off some creativity, and these were some prompts we added as suggestions in MorphAI to showcase that and inspire our users. OpenAI still seems to win here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Create a 70’s vinyl record cover&lt;/head&gt;
    &lt;p&gt;This is an example of a prompt that has a small viral moment with OpenAI, but the other models can’t even get the aspect ratio right.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduce mythical creatures native to this environment&lt;/head&gt;
    &lt;p&gt;This one showcases OpenAI’s creativity. Gemini seems kind of creepy?&lt;/p&gt;
    &lt;head rend="h3"&gt;Add a mystical portal or gateway&lt;/head&gt;
    &lt;p&gt;Gemini replacing the face with a portal is certainly a choice!&lt;/p&gt;
    &lt;head rend="h3"&gt;Incorporate futuristic technology elements&lt;/head&gt;
    &lt;p&gt;Another example of OpenAI being far more creative and willing to re-do the whole image.&lt;/p&gt;
    &lt;head rend="h3"&gt;Make it look whimsical and enchanting&lt;/head&gt;
    &lt;p&gt;This one also shows OpenAI being more artistic, and Gemini being more realistic while still trying to incorporate the prompt.&lt;/p&gt;
    &lt;head rend="h3"&gt;Transform the scene to a stormy night&lt;/head&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;If you made it all the way down here you probably don’t need a summary, but for our purposes, we’ve at least concluded that there is no one-size-fits all model at this point.&lt;/p&gt;
    &lt;p&gt;OpenAI is great for fully transformative filters like style transfer or more creative generative applications, whereas Gemini works better for more realistic edits. Seedream lies somewhere in the middle and is a bit of a jack of all trades, and for the price and performance may be a good replacement for OpenAI.&lt;/p&gt;
    &lt;p&gt;We’ve been experimenting on working on a “prompt classifier” to automatically choose a model – sending artistic prompts to OpenAI and more realistic prompts to Gemini, if there’s any interest we can follow up with how that worked out!&lt;/p&gt;
    &lt;head rend="h4"&gt;Methodology&lt;/head&gt;
    &lt;p&gt;Tests were performed on October 8 with &lt;code&gt;gpt-image-1&lt;/code&gt;, &lt;code&gt;gemini-2.5-flash-image&lt;/code&gt; and &lt;code&gt;seedream-4-0-250828&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Timings were measured on a consumer internet connection in Japan (Fiber connection, 10 Gbps nominal bandwidth) during a limited test run in a short time period.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://latenitesoft.com/blog/evaluating-frontier-ai-image-generation-models/"/><published>2025-11-11T17:26:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45890394</id><title>Show HN: Data Formulator – interactive AI agents for data analysis (Microsoft)</title><updated>2025-11-11T21:09:19.082211+00:00</updated><content>&lt;doc fingerprint="dbfdf795bc5b90ad"&gt;
  &lt;main&gt;
    &lt;p&gt;Run this app with javascript&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://data-formulator.ai/"/><published>2025-11-11T17:44:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45890726</id><title>Terminal Latency on Windows (2024)</title><updated>2025-11-11T21:09:18.693383+00:00</updated><content>&lt;doc fingerprint="140ed15eb7063ff7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Terminal Latency on Windows&lt;/head&gt;
    &lt;p&gt;UPDATE 2024-04-15: Windows Terminal 1.19 contains a fix that reduces latency by half! Itâs now competitive with WSLtty on my machine. Details in the GitHub Issue.&lt;/p&gt;
    &lt;p&gt;In 2009, I wrote about why MinTTY is the best terminal on Windows. Even today, that post is one of my most popular.&lt;/p&gt;
    &lt;p&gt;Since then, the terminal situation on Windows has improved:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cygwin defaults to MinTTY; you no longer need to manually install it.&lt;/item&gt;
      &lt;item&gt;Windows added PTY support, obviating the need for offscreen console window hacks that add latency.&lt;/item&gt;
      &lt;item&gt;Windows added basically full support for ANSI terminal sequences in both the legacy conhost.exe consoles and its new Windows Terminal.&lt;/item&gt;
      &lt;item&gt;We now have a variety of terminals to choose from, even on Windows: Cmder, ConEmu, Alacritty, WezTerm, xterm.js (component of Visual Studio Code)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The beginning of a year is a great time to look at your tools and improve your environment.&lt;/p&gt;
    &lt;p&gt;Iâd already enabled 24-bit color in all of my environments and streamlined my tmux config. Itâs about time that I take a look at the newer terminals.&lt;/p&gt;
    &lt;p&gt;Roughly in order, I care about:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Minimum feature set: 24-bit color, reasonable default fonts with emoji support, italics are nice.&lt;/item&gt;
      &lt;item&gt;Input latency.&lt;/item&gt;
      &lt;item&gt;Throughput at line rate, for example, when I &lt;code&gt;cat&lt;/code&gt;a large file.&lt;/item&gt;
      &lt;item&gt;Support for multiple tabs in one window would be nice, but tmux suffices for me.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Which terminals should I test?&lt;/head&gt;
    &lt;p&gt;I considered the following.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Legacy conhost.exe (also known as Windows Console), Windows 10 19045&lt;/item&gt;
      &lt;item&gt;MinTTY (3.7.0)&lt;/item&gt;
      &lt;item&gt;Alacritty (0.13.1)&lt;/item&gt;
      &lt;item&gt;WezTerm (20240203-110809-5046fc22)&lt;/item&gt;
      &lt;item&gt;Windows Terminal (1.18.10301.0)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Testing Features&lt;/head&gt;
    &lt;p&gt;Testing color and italics support is easy with my colortest.rs script. To test basic emoji, you can cat the Unicode emoji 1.0 emoji-data.txt. To test more advanced support, try the zero-width joiner list in the latest/ directory.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Terminal&lt;/cell&gt;
        &lt;cell role="head"&gt;Emoji&lt;/cell&gt;
        &lt;cell role="head"&gt;Font Attributes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conhost.exe&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;No italics&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY&lt;/cell&gt;
        &lt;cell&gt;Black and white&lt;/cell&gt;
        &lt;cell&gt;All major attributes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Alacritty&lt;/cell&gt;
        &lt;cell&gt;Black and white&lt;/cell&gt;
        &lt;cell&gt;Everything but double underline&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WezTerm&lt;/cell&gt;
        &lt;cell&gt;Color&lt;/cell&gt;
        &lt;cell&gt;All major attributes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows Terminal&lt;/cell&gt;
        &lt;cell&gt;Color&lt;/cell&gt;
        &lt;cell&gt;All major attributes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Everything but conhost.exe meets my bar.&lt;/p&gt;
    &lt;p&gt;Itâs also worth noting that conhost.exe has a terrible default palette. The default yellow is a pukey green and dark blue is barely visible. You can change palettes, but defaults matter.&lt;/p&gt;
    &lt;head rend="h2"&gt;Latency&lt;/head&gt;
    &lt;p&gt;I set up two latency tests. One with an 80x50 blank window in the upper left corner of the screen. The other fullscreen, editing an Emacs command at the bottom of the screen.&lt;/p&gt;
    &lt;p&gt;Since latencies are additive, system configuration doesnât matter as much as the absolute milliseconds of latency each terminal adds, but Iâll describe my entire setup and include total keypress-to-pixels latency.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Windows 10&lt;/item&gt;
      &lt;item&gt;Intel i7-4771 @ 3.5 GHz&lt;/item&gt;
      &lt;item&gt;NVIDIA GTX 1060&lt;/item&gt;
      &lt;item&gt;Keyboard: Sweet 16 Macro Pad&lt;/item&gt;
      &lt;item&gt;Display: LG 27GP950-B at 4K, 120 Hz, adaptive sync&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Measurement Methodology&lt;/head&gt;
    &lt;p&gt;With Is It Snappy?, I measured the number of frames between pressing a key and pixels changing on the screen.&lt;/p&gt;
    &lt;p&gt;To minimize ambiguity about when the key was pressed, I slammed a pencilâs eraser into the key, and always measured the key press as the second frame after contact. (The first frame was usually when the eraser barely touched the key. It would usually clear the activation depth by the second frame.)&lt;/p&gt;
    &lt;p&gt;I considered the latency to end when pixels just started to change on the screen. In practice, pixels take several 240 Hz frames to transition from black to white, but I consistently marked the beginning of that transition.&lt;/p&gt;
    &lt;p&gt;I took five measurements for each configuration and picked the median. Each measurement was relatively consistent, so average would have been a fine metric too. It doesnât change the results below.&lt;/p&gt;
    &lt;head rend="h3"&gt;80x50&lt;/head&gt;
    &lt;p&gt;80x50 window, upper left of screen, cleared terminal, single keypress.&lt;/p&gt;
    &lt;p&gt;Confirmed window size with:&lt;/p&gt;
    &lt;code&gt;$ echo $(tput cols)x$(tput lines)
80x50
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Terminal&lt;/cell&gt;
        &lt;cell role="head"&gt;Median Latency (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;240 Hz Camera Frames&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conhost.exe WSL1&lt;/cell&gt;
        &lt;cell&gt;33.3&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY WSL1&lt;/cell&gt;
        &lt;cell&gt;33.3&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conhost.exe Cygwin&lt;/cell&gt;
        &lt;cell&gt;41.3&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY Cygwin&lt;/cell&gt;
        &lt;cell&gt;57.9&lt;/cell&gt;
        &lt;cell&gt;14&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WezTerm cmd.exe&lt;/cell&gt;
        &lt;cell&gt;62.5&lt;/cell&gt;
        &lt;cell&gt;15&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Alacritty WSL1&lt;/cell&gt;
        &lt;cell&gt;62.5&lt;/cell&gt;
        &lt;cell&gt;15&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WezTerm WSL1&lt;/cell&gt;
        &lt;cell&gt;66.7&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Windows Terminal WSL1&lt;/cell&gt;
        &lt;cell&gt;66.7&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Fullscreen&lt;/head&gt;
    &lt;p&gt;Maximized emacs, editing a command in the bottom row of the terminal. I only tested WSL1 this time.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Terminal&lt;/cell&gt;
        &lt;cell role="head"&gt;Median Latency (ms)&lt;/cell&gt;
        &lt;cell role="head"&gt;240 Hz Camera Frames&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conhost.exe&lt;/cell&gt;
        &lt;cell&gt;45.8&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY&lt;/cell&gt;
        &lt;cell&gt;52.42&lt;/cell&gt;
        &lt;cell&gt;12&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WezTerm&lt;/cell&gt;
        &lt;cell&gt;75&lt;/cell&gt;
        &lt;cell&gt;18&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Windows Terminal&lt;/cell&gt;
        &lt;cell&gt;75&lt;/cell&gt;
        &lt;cell&gt;18&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Alacritty&lt;/cell&gt;
        &lt;cell&gt;87.5&lt;/cell&gt;
        &lt;cell&gt;21&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Throughput&lt;/head&gt;
    &lt;p&gt;I generated a 100,000-line file with:&lt;/p&gt;
    &lt;code&gt;$ yes "This sentence has forty-five (45) characters." | head -n 100000 &amp;gt; /tmp/lines.txt
&lt;/code&gt;
    &lt;p&gt;Then I measured the wall-clock duration of:&lt;/p&gt;
    &lt;code&gt;$ time cat /tmp/lines.txt
&lt;/code&gt;
    &lt;p&gt;This benchmark captures the case that I accidentally dump a ton of output and Iâm sitting there just waiting for the terminal to become responsive again. I have a gigabit internet connection, and itâs embarrassing to be CPU-bound instead of IO-bound.&lt;/p&gt;
    &lt;p&gt;I did include Cygwin in this test, just to have two different MinTTY datapoints.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Terminal&lt;/cell&gt;
        &lt;cell role="head"&gt;Elapsed Time (s)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MinTTY WSL1&lt;/cell&gt;
        &lt;cell&gt;0.57&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;MinTTY Cygwin&lt;/cell&gt;
        &lt;cell&gt;2.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Windows Terminal&lt;/cell&gt;
        &lt;cell&gt;5.25&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Alacritty&lt;/cell&gt;
        &lt;cell&gt;5.75&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;WezTerm&lt;/cell&gt;
        &lt;cell&gt;6.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;conhost.exe&lt;/cell&gt;
        &lt;cell&gt;21.8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;I assume this means MinTTY throttles display updates in some way. Of course this is totally fine, because you couldnât read the output either way.&lt;/p&gt;
    &lt;p&gt;To test the hypothesis that MinTTY was caching cell rendering by their contents, I also tried generating a file that rotated through different lines, with no effect.&lt;/p&gt;
    &lt;code&gt;with open("/tmp/lines2.txt", "w") as f:
  for i in range(100000):
    sentence="This sentence has forty-five (45) characters."
    print(sentence[i%len(sentence):]+sentence[:i%len(sentence)], file=f)
&lt;/code&gt;
    &lt;head rend="h3"&gt;CPU Usage During Repeated Keypresses&lt;/head&gt;
    &lt;p&gt;While making these measurements, I noticed some strange behaviors. My monitor runs at 120 Hz and animation and window dragging are generally smooth. But right after you start Alacritty, dragging the window animates at something like 30-60 frames per second. Itâs noticeably chunkier. WezTerm does the same, but slightly worse. Maybe 20 frames per second.&lt;/p&gt;
    &lt;p&gt;I donât know if I can blame the terminals themselves, because I sometimes experience this even with Notepad.exe too. But the choppiness stands out much more. Maybe something is CPU-bound in responding to window events?&lt;/p&gt;
    &lt;p&gt;This made me think of a new test: if I open a terminal and hold down the âaâ button on autorepeat, how much CPU does the terminal consume?&lt;/p&gt;
    &lt;p&gt;To measure this, I set the terminal processâs affinity to my third physical core, and watched the CPU usage graph in Task Manager. Not a great methodology, but it gave a rough sense. Again, 80x50.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Terminal&lt;/cell&gt;
        &lt;cell role="head"&gt;Percent of Core&lt;/cell&gt;
        &lt;cell role="head"&gt;Private Bytes After Startup (KiB)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conhost&lt;/cell&gt;
        &lt;cell&gt;0%&lt;/cell&gt;
        &lt;cell&gt;6,500&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Alacritty&lt;/cell&gt;
        &lt;cell&gt;5%&lt;/cell&gt;
        &lt;cell&gt;74,000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY WSL1&lt;/cell&gt;
        &lt;cell&gt;10%&lt;/cell&gt;
        &lt;cell&gt;10,200&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY Cygwin&lt;/cell&gt;
        &lt;cell&gt;10%&lt;/cell&gt;
        &lt;cell&gt;10,500&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Windows Terminal&lt;/cell&gt;
        &lt;cell&gt;20%&lt;/cell&gt;
        &lt;cell&gt;73,700&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;WezTerm&lt;/cell&gt;
        &lt;cell&gt;85%&lt;/cell&gt;
        &lt;cell&gt;134,000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The WezTerm CPU usage has to be a bug. Iâll report it.&lt;/p&gt;
    &lt;head rend="h3"&gt;CPU Usage (Idle)&lt;/head&gt;
    &lt;p&gt;I often have a pile of idle terminals sitting around. I donât want them to chew battery life. So letâs take a look at CPU Cycles Delta (courtesy of Process Explorer) with a fresh, idle WSL session.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Terminal&lt;/cell&gt;
        &lt;cell role="head"&gt;Idle Cycles/s (Focused)&lt;/cell&gt;
        &lt;cell role="head"&gt;Idle Cycles/s (Background)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;conhost&lt;/cell&gt;
        &lt;cell&gt;~900,000&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Alacritty&lt;/cell&gt;
        &lt;cell&gt;~2,400,000&lt;/cell&gt;
        &lt;cell&gt;no difference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WezTerm&lt;/cell&gt;
        &lt;cell&gt;~2,600,000&lt;/cell&gt;
        &lt;cell&gt;~1,600,000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Windows Terminal&lt;/cell&gt;
        &lt;cell&gt;~55,000,000&lt;/cell&gt;
        &lt;cell&gt;~6,100,000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;MinTTY WSL1&lt;/cell&gt;
        &lt;cell&gt;~120,000,000&lt;/cell&gt;
        &lt;cell&gt;no difference&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;MinTTY Cygwin&lt;/cell&gt;
        &lt;cell&gt;~120,000,000&lt;/cell&gt;
        &lt;cell&gt;no difference&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These numbers arenât great at all! For perspective, I have a pile of Firefox tabs open, some of them actively running JavaScript, and theyâre âonlyâ using a few hundred million cycles per second.&lt;/p&gt;
    &lt;p&gt;Raymond Chen once wrote a blog post about the importance of properly idling in the Windows Terminal Server days. You might have a dozen users logged into a host, and if a program is actively polling, itâs eating performance that others could use.&lt;/p&gt;
    &lt;p&gt;Today, we often run on batteries, so idling correctly still matters, but it seems to be something of a lost art. The only terminal that idles completely is the old conhost.exe.&lt;/p&gt;
    &lt;p&gt;The other lesson we can draw is that Microsoftâs own replacement for conhost.exe, Windows Terminal, uses over 10x the RAM, 60x the CPU when focused, and infinitely more CPU when idle.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusions&lt;/head&gt;
    &lt;p&gt;conhost.exe consistently has the best latency, with MinTTY not much behind. MinTTY handily dominates the throughput test, supports all major ANSI character attributes, and has a better default palette.&lt;/p&gt;
    &lt;p&gt;As in 2009, Iâd say MinTTY is still pretty great. (I should try to track down that idle CPU consumption. It feels more like a bug than a requirement.)&lt;/p&gt;
    &lt;p&gt;If you want to use MinTTY as the default terminal for WSL, install WSLtty.&lt;/p&gt;
    &lt;p&gt;The others all have slightly worse latencies, but theyâre in a similar class. Iâm particularly sensitive to latency, so Iâd had a suspicion even before measuring. Maybe itâs some consequence of being GPU-accelerated? Out of curiousity, I put Windows Terminal in software-rendered mode, and it shaved perhaps 4 ms off (median of 62.5 ms, 15 frames). Perhaps just measurement noise.&lt;/p&gt;
    &lt;p&gt;While Iâm going to stick with MinTTY, one thing is clear: there is room to improve all of the above.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chadaustin.me/2024/02/windows-terminal-latency/"/><published>2025-11-11T18:07:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45891016</id><title>FFmpeg to Google: Fund us or stop sending bugs</title><updated>2025-11-11T21:09:18.318153+00:00</updated><content>&lt;doc fingerprint="3772b5d090a791bc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FFmpeg to Google: Fund Us or Stop Sending Bugs&lt;/head&gt;
    &lt;p&gt;You may never have heard of FFmpeg, but you’ve used it. This open source program’s robust multimedia framework is used to process video and audio media files and streams across numerous platforms and devices. It provides tools and libraries for format conversion, aka transcoding, playback, editing, streaming, and post-production effects for both audio and video media.&lt;/p&gt;
    &lt;p&gt;FFmpeg’s libraries, such as libavcodec and libavformat, are essential for media players and software, including VLC, Kodi, Plex, Google Chrome, Firefox, and even YouTube’s video processing backend. It is also, like many other vital open source programs, terribly underfunded.&lt;/p&gt;
    &lt;head rend="h2"&gt;Corporate Responsibility vs. Volunteer Labor&lt;/head&gt;
    &lt;p&gt;A lively debate on Twitter began between Dan Lorenc, CEO and co-founder of Chainguard, the software supply chain security company, the FFmpeg project, Google, and security researchers over security disclosures and the responsibilities of large tech companies in open-source software.&lt;/p&gt;
    &lt;p&gt;The core of the discussion revolves around how vulnerabilities should be reported, who is responsible for fixing them, and the challenges that arise when AI is used to uncover a flood of potentially meaningless security issues. But at heart, it’s about money.&lt;/p&gt;
    &lt;head rend="h2"&gt;An Obscure Bug Ignites the Controversy&lt;/head&gt;
    &lt;p&gt;This discussion has been heating up for some time. In mid-October, FFmpeg tweeted that “security issues are taken extremely seriously in FFmpeg, but fixes are written by volunteers.” This point cannot be emphasised enough. As FFmpeg tweeted later, “FFmpeg is written almost exclusively by volunteers.”&lt;/p&gt;
    &lt;p&gt;Thus, as Mark Atwood, an open source policy expert, pointed out on Twitter, he had to keep telling Amazon to not do things that would mess up FFmpeg because, he had to keep explaining to his bosses that “They are not a vendor, there is no NDA, we have no leverage, your VP has refused to help fund them, and they could kill three major product lines tomorrow with an email. So, stop, and listen to me … ”&lt;/p&gt;
    &lt;head rend="h2"&gt;The Growing Burden on Open Source Maintainers&lt;/head&gt;
    &lt;p&gt;The latest episode was sparked after a Google AI agent found an especially obscure bug in FFmpeg. How obscure? This “medium impact issue in ffmpeg,” which the FFmpeg developers did patch, is “an issue with decoding LucasArts Smush codec, specifically the first 10-20 frames of Rebel Assault 2, a game from 1995.”&lt;/p&gt;
    &lt;p&gt;Wow.&lt;/p&gt;
    &lt;p&gt;FFmpeg added, “FFmpeg aims to play every video file ever made.” That’s all well and good, but is that a valuable use of an assembly programmer’s time? Oh, right, you may not know. FFmpeg’s heart is assembly language. As a former assembly language programmer, it is not, in any way, shape, or form, easy to work with.&lt;/p&gt;
    &lt;p&gt;As FFmpeg put it, this is “CVE slop.”&lt;/p&gt;
    &lt;p&gt;Many in the FFmpeg community argue, with reason, that it is unreasonable for a trillion-dollar corporation like Google, which heavily relies on FFmpeg in its products, to shift the workload of fixing vulnerabilities to unpaid volunteers. They believe Google should either provide patches with vulnerability reports or directly support the project’s maintenance.&lt;/p&gt;
    &lt;p&gt;Earlier, FFmpeg pointed out that it’s far from the only open source project to face such issues.&lt;/p&gt;
    &lt;p&gt;Specifically, the project team mentions Nick Wellnhofer, the former maintainer of libxml2, a widely used open source software library for parsing Extensible Markup Language (XML). Wellnhofer recently resigned from maintaining libxml2 because he had to “spend several hours each week dealing with security issues reported by third parties. Most of these issues aren’t critical, but it’s still a lot of work.&lt;/p&gt;
    &lt;p&gt;“In the long term, this is unsustainable for an unpaid volunteer like me. … In the long run, putting such demands on OSS maintainers without compensating them is detrimental. … It’s even more unlikely with Google Project Zero, the best white-hat security researchers money can buy, breathing down the necks of volunteers.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Google’s Controversial Security Disclosure Policy&lt;/head&gt;
    &lt;p&gt;What made this a hot issue was that back in July, Google Project Zero (GPZ) announced a trial of its new Reporting Transparency policy. With this policy change, GPZ announces that it has reported an issue on a specific project within a week of discovery, and the security standard 90-day disclosure clock then starts, regardless of whether a patch is available or not.&lt;/p&gt;
    &lt;p&gt;Many volunteer open source program maintainers and developers feel this is massively unfair to put them under such pressure when Google has billions to address the problem.&lt;/p&gt;
    &lt;p&gt;FFmpeg tweeted, “We take security very seriously, but at the same time, is it really fair that trillion-dollar corporations run AI to find security issues in people’s hobby code? Then expect volunteers to fix.”&lt;/p&gt;
    &lt;p&gt;True, Google does offer a Patch Rewards Program, but as a Twitter user using the handle Ignix The Salamander observed, “FFmpeg already mentioned the program is too limited for them, and they point out the three patches per month limit. Please don’t assume people complain just for the sake of complaining, there is a genuine conflict between corporate security &amp;amp; usage vs open source support IMHO.”&lt;/p&gt;
    &lt;p&gt;Lorenc argues back, in an e-mail to me, that “Creating and publishing software under an open source license is an act of contribution to the digital commons. Finding and publishing information about security issues in that software is also an act of contribution to the same commons.&lt;/p&gt;
    &lt;p&gt;“The position of the FFmpeg X account is that somehow disclosing vulnerabilities is a bad thing. Google provides more assistance to open source software projects than almost any other organization, and these debates are more likely to drive away potential sponsors than to attract them.”&lt;/p&gt;
    &lt;head rend="h2"&gt;Differing Perspectives on Vulnerability Disclosures&lt;/head&gt;
    &lt;p&gt;The fundamental problem remains that the FFmpeg team lacks the financial and developer resources to address a flood of AI-created CVEs.&lt;/p&gt;
    &lt;p&gt;On the other hand, security experts are certainly right in thinking that FFmpeg is a critical part of the Internet’s technology framework and that security issues do need to be made public responsibly and addressed. After all, hackers can use AI to find vulnerabilities in the same way Google does with its AI bug finder, Big Sleep, and Google wants to identify potential security holes ahead of them.&lt;/p&gt;
    &lt;p&gt;The reality is, however, that without more support from the trillion-dollar companies that profit from open source, many woefully underfunded, volunteer-driven critical open-source projects will no longer be maintained at all.&lt;/p&gt;
    &lt;p&gt;For example, Wellnhofer has said he will no longer maintain libxml2 in December. Libxml2 is a critical library in all web browsers, web servers, LibreOffice and numerous Linux packages. We don’t need any more arguments; we need real support for critical open source programs before we have another major security breach.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thenewstack.io/ffmpeg-to-google-fund-us-or-stop-sending-bugs/"/><published>2025-11-11T18:32:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45891319</id><title>Show HN: Creavi Macropad – Built a wireless macropad with a display</title><updated>2025-11-11T21:09:17.527943+00:00</updated><content>&lt;doc fingerprint="bf4e96514f3d57f8"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;TLDR&lt;/head&gt;
    &lt;p&gt;I built a wireless macropad from scratch, failed numerous times, and somehow ended up with a working prototype. This post includes ramblings about motivation, hardware, industrial design, mechanics, and software.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACT I: Prologue (failure counter: 1)&lt;/head&gt;
    &lt;p&gt;This story begins with a failure so immense it crushed us before we even started.&lt;/p&gt;
    &lt;p&gt;I’d set out to organize a hobby project with a few friends. You know, just the usual: do something fun, creative, and meaningful. We spent weeks brainstorming, debating, and refining ideas until an inconvenient truth revealed itself: nobody was actually willing to invest a significant part of their free time in the chosen idea.&lt;/p&gt;
    &lt;p&gt;The project never even began, and I was devastated.&lt;/p&gt;
    &lt;p&gt;But in hindsight, the failure might have been a blessing. If we had started, it probably would’ve ended up as another half-finished project on the ever-growing pile of abandoned projects.&lt;/p&gt;
    &lt;p&gt;Still, I couldn’t let it go. Why did this happen? I thought about it for weeks and eventually arrived at one unsatisfying conclusion: lack of motivation. After that realization, I decided two things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I’d start a project on my own. The bleeding soul of an engineer heals fastest by creating something.&lt;/item&gt;
      &lt;item&gt;I must make sure I stay motivated for a very long time, because doing things solo… takes a shit-ton of time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But how can I find motivation and stay motivated? For a moment, I felt proud of myself for finding the “root cause” of the failure, until I realized I had just created a bigger question.&lt;/p&gt;
    &lt;p&gt;Good work, me.&lt;/p&gt;
    &lt;head rend="h3"&gt;Search for Motivation&lt;/head&gt;
    &lt;p&gt;Figuring this out was easy.&lt;/p&gt;
    &lt;p&gt;I just had to spend months reading books, observing the behavior of myself and others, and analyzing. Eventually, I reached a conclusion that felt both simple and profound:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;I need to find activities I love so much that I enjoy them even when they suck.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;For me, these are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Creating something from nothing, it’s like a superpower. You look here, there is nothing, now you look again: there is a gadget you can take into your hands. How awesome is that?&lt;/item&gt;
      &lt;item&gt;Learning something new, it’s like a mental expedition. It’s uncomfortable, it makes you feel miserable, but at the end, there is always a treasure.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So what offers infinite opportunities for creation (something you can touch, smell, or even lick) while demanding learning across widely different domains?&lt;/p&gt;
    &lt;p&gt;You guessed right: consumer product development!&lt;/p&gt;
    &lt;p&gt;It’s fun; it carries absolutely no risk whatsoever! And I can guarantee that every single time you think “I’m smart”, it will definitely never backfire on you!&lt;/p&gt;
    &lt;head rend="h3"&gt;Which project should I not start?&lt;/head&gt;
    &lt;p&gt;So, what kind of product should I develop?&lt;/p&gt;
    &lt;p&gt;I had a leftover idea from the failed project that I liked but eventually dropped. Why abandon a “perfectly good” idea we’d already examined thoroughly? Because I didn’t want to start with emotional attachment. Falling in love with an idea makes you blind. Falling in love with solving a problem is far healthier.&lt;/p&gt;
    &lt;p&gt;So I went hunting for a new problem. That’s when I stumbled into the magical world of mechanical keyboards, and later, macropads.&lt;/p&gt;
    &lt;p&gt;Macropads are small, special keyboards whose buttons perform every kind of funky magic instead of the boring keyboard stuff. Like launching programs, controlling media or performing multi-key shortcuts. They’re compact, clever, and look simple. Perfect for a solo project, right?&lt;/p&gt;
    &lt;p&gt;How hard could it be?&lt;/p&gt;
    &lt;head rend="h3"&gt;Reality Check&lt;/head&gt;
    &lt;p&gt;I should’ve known I was in trouble the moment I listed the domains involved:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;mechanical engineering,&lt;/item&gt;
      &lt;item&gt;hardware engineering,&lt;/item&gt;
      &lt;item&gt;software engineering (embedded + desktop/web),&lt;/item&gt;
      &lt;item&gt;industrial design,&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Bonus domains:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;marketing,&lt;/item&gt;
      &lt;item&gt;small-scale manufacturing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The risk I took was calculated, but man, am I bad at math.&lt;/p&gt;
    &lt;p&gt;Still, it checked all my boxes. Create something from nothing? Check! Learn an absurd amount along the way? Check and double check! So, let’s go! Let’s build a macropad!&lt;/p&gt;
    &lt;p&gt;But what kind of macropad should it be? Like the other normal macropads, where you have around 10-20 buttons on a box, you hook it up to your PC, and you’re good to go? Absolutely not, where’s the mental expedition in that? Come on, I’m smart, let’s make something which is unique! So here are the initial requirements list from my notes:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I don’t like cables, it should use BLE (but have USB as a fallback, which can be used for charging too),&lt;/item&gt;
      &lt;item&gt;Infinite battery life (obviously),&lt;/item&gt;
      &lt;item&gt;Mechanical switches for tactile feedback,&lt;/item&gt;
      &lt;item&gt;Somehow make it clear what each button does (I’m bad at memorizing things),&lt;/item&gt;
      &lt;item&gt;A clean, simple configuration tool,&lt;/item&gt;
      &lt;item&gt;It should look simple and aesthetic (or at least don’t make my eyes bleed when I look at it),&lt;/item&gt;
      &lt;item&gt;RGB lighting,&lt;/item&gt;
      &lt;item&gt;Automatically change layout based on the active window.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just a couple of buttons! Easy, right? Three or four months, tops. Oh boy, how wrong I was. Also, minor detail: I had never designed a PCB more complex than an LED matrix.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Strategy&lt;/head&gt;
    &lt;p&gt;So here I was: underqualified, underprepared, and ridiculously optimistic. I needed a strategy that would help me navigate the vast unknown. My idea was simple:&lt;/p&gt;
    &lt;p&gt;Plan → Create → Fail → Learn → Repeat, as fast as possible.&lt;/p&gt;
    &lt;p&gt;When you explore an unfamiliar domain, failure is guaranteed; you just don’t know how or why yet. So it’s better to fail in small, controlled doses. Build the smallest possible thing that tests what you don’t know. Learn from it. Then move one inch further.&lt;/p&gt;
    &lt;p&gt;It’s slow and sometimes painful, but every time I tried to skip ahead or bundle multiple unknowns together, I’d trigger spectacular chain reactions of failure. Two small issues would team up and create one magnificent, complex, pain-in-the-ass failure.&lt;/p&gt;
    &lt;p&gt;I learned that progress often happens faster when you move in tiny, deliberate steps, as long as you take them quickly and consistently.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACT II: Hardware (failure counter: 7)&lt;/head&gt;
    &lt;p&gt;The first problem I needed to solve: I can’t solder. Sure, I’d held a soldering iron before. I’d even managed to attach a few components without setting anything on fire. But fine-pitch ICs? 0.5 mm pins? Absolutely not.&lt;/p&gt;
    &lt;p&gt;Unfortunately, I had to solder — there was no way around it. I couldn’t afford to order PCBA prototypes from JLCPCB just to “see what happens,” and waiting weeks for each iteration would kill my momentum. Given how little I knew about hardware, I was expecting a lot of iterations. So I needed a way to solder reliably and often.&lt;/p&gt;
    &lt;p&gt;That’s how I discovered hot plate soldering. Basically it’s DIY reflow soldering using primitive tools. You just need a small hot plate, some solder paste, and a stencil (or a steady hand if you’re hardcore).&lt;/p&gt;
    &lt;p&gt;To test the method, I designed a tiny PCB with just one Cherry MX socket, a diode, and an RGB LED. It worked perfectly. Watching that board solder itself felt magical! Sure, it wasn’t even close to the normal thermal cycle of a real reflow oven, but hey, it’s not stupid if it works.&lt;/p&gt;
    &lt;head rend="h3"&gt;Which Button Does What???&lt;/head&gt;
    &lt;p&gt;Before diving into actual hardware design, I wanted to solve the biggest industrial design challenge: How could the user always see which key does what? The macropad needed a real-time way to display key bindings.&lt;/p&gt;
    &lt;p&gt;I came up with three options:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Display info on the buttons (or beneath transparent ones).&lt;/item&gt;
      &lt;item&gt;Display info near the buttons.&lt;/item&gt;
      &lt;item&gt;Display info somewhere else.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Option 1 was immediately out. Sure, the Stream Deck does it, but I don’t have access to advanced mass manufacturing technology. Embedding a screen inside a moving part sounds like a perfect recipe for cracked glass, torn flex cables, and electrical nightmares.&lt;/p&gt;
    &lt;p&gt;Option 3 felt boring, others already do that.&lt;/p&gt;
    &lt;p&gt;Option 2 seems doable: a display surrounded by buttons. Simple, and haven’t seen somewhere else, let’s go with that.&lt;/p&gt;
    &lt;head rend="h3"&gt;So You Want Battery Life?&lt;/head&gt;
    &lt;p&gt;Then came the real hardware, and a new arch-nemesis: power consumption.&lt;/p&gt;
    &lt;p&gt;Almost all of my “brilliant” requirements (BLE, RGB LEDs, real-time display updates) were directly opposed to my other requirement: infinite battery life. You can’t have rainbows and efficiency too, so something had to go.&lt;/p&gt;
    &lt;p&gt;Goodbye, RGB LEDs. Goodbye, shiny backlit display.&lt;/p&gt;
    &lt;p&gt;From this point on, everything revolved around low-power design. And by low, I mean microamps, not milliamps. The goal: a device that runs on thoughts and prayers, because moving electrons is a luxury.&lt;/p&gt;
    &lt;p&gt;I needed a low-power display, and before designing the whole hardware, I wanted to test the display technology. Without backlight, you need some tricks to make the display readable somehow. I found two technologies and both of them are unique:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;E-paper displays,&lt;/item&gt;
      &lt;item&gt;Memory LCD displays.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The first uses charged pigments, the latter uses memory inside pixels to achieve minimal power consumption. I’ve ordered sample pieces for both.&lt;/p&gt;
    &lt;p&gt;E-paper have gorgeous static image… and a refresh rate so bad it made molasses look fast. I want a quick and snappy display, because I like quick and snappy displays.&lt;/p&gt;
    &lt;p&gt;Fortunately, memory LCDs are perfect for me. They are crisp, responsive, and delightfully retro like a Game Boy display.&lt;/p&gt;
    &lt;p&gt;So I wired it up on a breadboard and… nothing. Okay, I checked the datasheet again, still not working. Checked the protocol of the display, not working, checked again, still not working. Rewired it three times, still dead. At some point, I rewired it so many times that I physically broke the display cable.&lt;/p&gt;
    &lt;p&gt;Absolute disaster. Ordered another sample and waited a week.&lt;/p&gt;
    &lt;p&gt;Eventually, I found the culprit: my controller automatically disabled the SPI chip select after sending the command and before sending the data, which the display controller hated. The datasheet mentioned this but somehow my eyes refused to see it (like four times). How could I not see that?! How?!&lt;/p&gt;
    &lt;p&gt;After recovering from the brief depression caused by the obsession to make this display work, I moved on to the processor.&lt;/p&gt;
    &lt;p&gt;My first thought was to use an Espressif processor. Their chips are great, except when you care about power consumption. ESP32 didn’t just sip current, it chugged it like an energy drink.&lt;/p&gt;
    &lt;p&gt;So I turned to my friendly fabless neighbors: Nordic Semiconductor. Their chips are basically low-power radio sorcery. BLE integrated, peripherals galore, and power draw so tiny it feels like cheating. Plus, their software support is actually pleasant. I was sold. To test it thoroughly, I ordered a Seeed Studio Xiao BLE module, which uses an nRF52840 chip.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Boost Converter Saga&lt;/head&gt;
    &lt;p&gt;You’ve got a display, a processor, and some buttons. Done, right? Well, not so fast cowboy! You will have to do something with the battery, like you know… charging it. Also, the display needed a higher voltage than the battery could provide, so I had to add a boost converter.&lt;/p&gt;
    &lt;p&gt;At first, it looked simple: a few components, easy schematic, voltage in → magic out. I was so confident, I didn’t even bother following the datasheet’s recommended layout. Because I was smart.&lt;/p&gt;
    &lt;p&gt;Before I had a chance to test anything, my first PCB revision went straight into the trash. Why? Stupid imperial system, that’s why! The packaging of passive components can get mixed up between the imperial and metric systems. You think you’re using 0603 components? Surprise! You’ve actually designed for 0201s, microscopic parts you can’t solder by hand (and you don’t have at all). Ha-ha. Very funny.&lt;/p&gt;
    &lt;p&gt;After fixing the passive components, I finally started to test my power supply circuit. It worked… briefly. Then it self-destructed after 5-10 power cycles. No problem, I thought. Faulty solder joint. Replaced the IC, it worked again. Then boom, another one died. I dove deep into the topic of boost converters to understand how they actually work (a tiny bit too late, I know). That’s when I found my next nemesis: parasitic inductance. These tiny invisible gremlins live in your PCB layout and their favorite hobby is slapping your poor MOSFET into oblivion. Turns out my layout created such high voltage spikes during power up that they annihilated the MOSFET of my boost converter IC.&lt;/p&gt;
    &lt;p&gt;I destroyed five boost converter ICs when I finally arrived to this hypothesis, so how to prove it’s really the problem? It is literally printed on the circuit board, I’d need a new layout just to test this! I don’t have that kind of time, so I improvised: grabbed a thick cable, globbed on an unreasonable amount of solder, and shorted the critical paths.&lt;/p&gt;
    &lt;p&gt;And somehow… it worked. Yes, it looked like an abomination. Yes, it would make any decent hardware engineer physically wince. But luckily I’m not one.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACT III: Mechanics (failure counter: 15)&lt;/head&gt;
    &lt;p&gt;3D printing the housing was the obvious choice. I already had an Ender 3 V2 and a modest track record of melting filament into vaguely rectangular shapes. My biggest worry was the durability of the fastenings. Screws and plastic don’t usually play nice, especially when you have to disassemble and reassemble the housing a hundred times because you fu.. “just want to tweak one little thing.”&lt;/p&gt;
    &lt;p&gt;Then I remembered an old laptop of mine that was literally falling apart. One of its screws kept pulling out of the chassis, until I noticed the metal inserts inside the plastic shell. The plastic around the insert has aged and simply crumbled apart (talk about planned obsolescence). Heat-set inserts are brilliant: tiny threaded brass anchors melted into plastic. You heat them up, press them into printed holes, and suddenly plastic and metal are in love.&lt;/p&gt;
    &lt;p&gt;I printed a few test blocks, dialed in the perfect hole size (which, shockingly, matched the datasheet), and moved on feeling like an absolute genius.&lt;/p&gt;
    &lt;p&gt;Now for the main event: the housing design. My goal was simple: it should look clean, friendly, and make me smile when I look at it. It’s going to live on my desk, after all. But of course, there was a bucket of secondary goals too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Easy to repair and assemble. I hate planned obsolescence and intentionally hard to repair products.&lt;/item&gt;
      &lt;item&gt;Slim, and portable.&lt;/item&gt;
      &lt;item&gt;Printable with basic filament and printers.&lt;/item&gt;
      &lt;item&gt;Customizable: swap parts, mix colors, have fun.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But before getting too artsy, I had to face a big mechanical question: where the hell does the display go?&lt;/p&gt;
    &lt;p&gt;It is a thin, fragile component, so it should be fixed to something rigid. My first idea was to glue it to the PCB, but it would be too deep between the switches and barely visible. To solve this problem I designed a separate 3D-printed display holder, complete with (of course!) heat-set inserts. Then, staring at my board, I noticed a large empty space right under the display. Wasted area! The perfect home for a slim Li-Po battery. If I cut a window into the PCB beneath it, the whole thing could stay razor-thin. Turning constraints into features are always feels awesome.&lt;/p&gt;
    &lt;p&gt;Next, I had to mount the PCB itself. I considered snap joints, positioning done by the housing and screws. Snaps are elegant until they snap. Plastic holders require tight tolerances for the housing. So I went with the ancient and reliable solution: screws. They are simple, cheap, and have tight tolerances. Probably this is a classic: the housing fix and PCB positioning (at leas on the X/Y axis) are done by screws, going through on four holes at the four corners of the PCB.&lt;/p&gt;
    &lt;p&gt;For a while, I just taped the battery to the PCB. It worked, technically, but deep down it hurt my soul. I wanted the battery to be fixed to the PCB, because that way the device would have three big parts: backplate, frontplate, and electronics. Also I didn’t want to glue the battery, so I designed a separate battery holder part. I even reused the display holder screws: these two parts can be fixed with the same set of screws. What a fine idea… Except it didn’t fit. Why? Because I designed the housing first and left the battery for last. Genius move.&lt;/p&gt;
    &lt;p&gt;I almost gave up and glued it down (no, never glue batteries). Then, I realized the battery holder and backplate were doing the same job: holding things. Why not use only one of them? The middle of the backplate doesn’t add very much to the rigidity of the housing, so cut it out and let the holder be the structure. Also the large empty surface of the backplate will be nicely divided! Suddenly, what was a major screw-up turned into an aesthetic feature. Victory smells like freshly printed PLA.&lt;/p&gt;
    &lt;p&gt;After a few iterations, the housing started to look like a real product, but still a bit thick. I reviewed the PCB and realized most components were on the bottom, wasting space. If I moved everything to the top, the housing could be thinner. Of course, that meant reposition nearly all parts and redrawing nearly every trace by hand. Three nights later I finished the PCB, also redesigned the housing just to realize now I don’t have enough space even for the battery cables. Finally a few slots here and there did the trick.&lt;/p&gt;
    &lt;p&gt;Was it worth it? No.&lt;/p&gt;
    &lt;p&gt;Did I sleep better? Absolutely.&lt;/p&gt;
    &lt;p&gt;Some smaller details followed. The battery switch needed a tiny coupler between the user’s finger and the fragile SMD switch. And some protection around it so it wouldn’t break again (RIP test switch no. 1). We also need a hole on the housing, where the coupler can be reached. Let’s put a hole in the frontplate, but wait, what happens during a disassembly? The frontplate should be coming off easily and the coupler should stay in one place. This means we need to limit it’s movement vertically, so a little bridge over the coupler was added to the backplate.&lt;/p&gt;
    &lt;p&gt;Then came the knobs: one for the encoder, one for the four-way navigation button. The details and tolerances were so fine they pushed my poor Ender 3 V2 past its limits. Fortunately, I later got access to a Bambulab P1S, and suddenly everything looked sharp, consistent, and professional. The parts are still close to the technology limits, but I managed to get a pretty decent production yield.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACT IV: I need help (failure counter: 15, success counter: 1)&lt;/head&gt;
    &lt;p&gt;By spring 2024, another kind of project was in the making: my wife and I were expecting our first child. That wonderful news also meant my late-night development marathons were coming to an end. Around autumn, I realized that if I wanted this project to survive, I couldn’t do it alone anymore.&lt;/p&gt;
    &lt;p&gt;So I looked for a partner.&lt;/p&gt;
    &lt;p&gt;Luckily, I didn’t have to look far. A colleague of mine, Kristóf, said yes almost immediately. From October onward, the “I” in this project became “we”. Having someone to share ideas, talk through challenges, and celebrate the little victories with was a massive weight off my mind.&lt;/p&gt;
    &lt;p&gt;Kristóf didn’t waste a second. He dove straight into firmware development and took on a huge challenge. I warned him it would be tough. Neither of us had any idea just how tough. Because now, at last, we reached the final boss: software.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACT V: Software (failure counter: 40, success counter: 2)&lt;/head&gt;
    &lt;p&gt;The elephant in the room had been waiting patiently: software. Firmware, bootloader, OTA update, web app, desktop app: the whole package. And since we were just two developers with limited free time and a ticking baby timer, we couldn’t afford to reinvent anything. We needed to build on something which already exists and have a suitable license.&lt;/p&gt;
    &lt;p&gt;Early in the project, I’d already explored Zephyr RTOS. I liked its devicetree configuration system, its mountain of built-in services, and especially its solid BLE stack. Plus, it played beautifully with the Nordic chip I’d chosen. Zephyr felt like a complete engineering toolbox (file systems, internal messaging, drivers, debug shell, etc.), not just a scheduler with locking mechanisms.&lt;/p&gt;
    &lt;p&gt;During research, I also looked at open-source keyboard projects: QMK, ZMK, KMK, Bluemicro. ZMK immediately stood out: Zephyr-based, MIT-licensed, and already supporting the nRF52840. Sure, it was macro-heavy and hard to read, but it enforced discipline. So we built on ZMK.&lt;/p&gt;
    &lt;p&gt;And wow, what a good choice. Around the same time, the ZMK community started developing ZMK Studio, a configuration tool that aligned perfectly with our goals. Still, we needed features that no regular keyboard firmware had: display handling, dynamic layouts, runtime macros, encoder mapping. These features were missing from ZMK too. Kristóf took on the hardest one: runtime macro editing. In ZMK, macros are defined in devicetree nodes, static by design. So making them dynamic meant breaking (and then carefully reassembling) fundamental parts of the firmware. It took months, but he made it work. And it worked beautifully.&lt;/p&gt;
    &lt;p&gt;Just for the record, we implemented a couple smaller changes too:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a confirmation based pairing mechanism to achieve high security level connection using the display,&lt;/item&gt;
      &lt;item&gt;a real-time updated display showing labels of the buttons/state of the device (it was like 5 iterations to make it snappy like hell),&lt;/item&gt;
      &lt;item&gt;handling firmware version, parameter version, and other metadata.&lt;/item&gt;
      &lt;item&gt;last but not least we integrated the firmware update transport layer, which needed Zephyr level patching.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;From my work experience, I know every embedded product has bugs. To get rid of them you need a safe update process: rollback handling, power-failure safety, signed images. I started to examine the solutions for a Zephyr based app and found my dream bootloader: MCUboot. It supports A/B partitions, signature checks, downgrade prevention and it can even handle OTA updates over BLE. There was only one tiny issue: ZMK wasn’t ready for it. At all. Dozens of failed boots later, it finally worked! And immediately raised a new problem: we needed an updater tool.&lt;/p&gt;
    &lt;p&gt;That’s when I discovered something magical: modern browsers can talk to BLE devices. That meant no installer, no drivers, no “please run this .exe as admin.”, no “boot in DFU”, just a website. So I built a web-based firmware updater in React. Three clicks: connect device, pick firmware, press update. It felt like the future, the kind with flying cars and no USB cables.&lt;/p&gt;
    &lt;p&gt;Of course, the real world had to ruin it: only Chromium based browsers support Web Bluetooth, and Windows BLE stack there is, scientifically speaking, a dumpster fire. So we needed a desktop version too. That’s where Tauri came in (idea comes from ZMK Studio): a lightweight cross-platform framework for web apps using the system’s built-in web engine. No bundling an entire browser like Electron, so our app ended up being just 6 MB, which felt like a minor miracle. In exchange you need to take care of the differences of the web engines and it uses Rust for backend. Fortunately I didn’t mind this because I already wanted to check out rust.&lt;/p&gt;
    &lt;p&gt;On top of Tauri, we built our own configuration app (inspired by ZMK Studio but built from ground up to our macropad). One codebase for both web and desktop, completely tailored to our macropad, firmware updates built right in, and complete offline functionality. Because one thing I refuse to do is ship a product that dies the moment a cloud server shuts down. I’ve seen too many “smart” devices bricked by their own creators. That’s the opposite of smart: wasteful and cruel.&lt;/p&gt;
    &lt;head rend="h2"&gt;ACT VI: Epilogue&lt;/head&gt;
    &lt;p&gt;It’s funny. I started this whole thing because a group project failed before it even began. Then I made the same thing solo, only slower, harder, and with a detailed record of every single mistake. But this time it lives. It blinks, connects, updates over BLE, and looks way cooler than it has any right to.&lt;/p&gt;
    &lt;p&gt;Somewhere along the way, a hobby project quietly turned into a real team building a real product. The kind you can use, recharge, and show off without prefacing it with “don’t mind the duct tape.”&lt;/p&gt;
    &lt;p&gt;You’d think that would be enough. That we’d take a break, enjoy what we did, maybe even sleep.&lt;/p&gt;
    &lt;p&gt;Hell no. Now comes the fun part!&lt;/p&gt;
    &lt;p&gt;Small-scale manufacturing, marketing, logistics. Basically, a whole new pile of domains to increase our failure counter.&lt;/p&gt;
    &lt;p&gt;Wan’t to laugh more on our failures?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://creavi.tech/blog/creavi-macropad-build-log/"/><published>2025-11-11T18:58:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45891868</id><title>A catalog of side effects</title><updated>2025-11-11T21:09:17.357205+00:00</updated><content>&lt;doc fingerprint="6202111079d508b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Optimizing compilers like to keep track of each IR instruction’s effects. An instruction’s effects vary wildly from having no effects at all, to writing a specific variable, to completely unknown (writing all state).&lt;/p&gt;
    &lt;p&gt;This post can be thought of as a continuation of What I talk about when I talk about IRs, specifically the section talking about asking the right questions. When we talk about effects, we should ask the right questions: not what opcode is this? but instead what effects does this opcode have?&lt;/p&gt;
    &lt;p&gt;Different compilers represent and track these effects differently. I’ve been thinking about how to represent these effects all year, so I have been doing some reading. In this post I will give some summaries of the landscape of approaches. Please feel free to suggest more.&lt;/p&gt;
    &lt;p&gt;Internal IR effect tracking is similar to the programming language notion of algebraic effects in type systems, but internally, compilers keep track of finer-grained effects. Effects such as “writes to a local variable”, “writes to a list”, or “reads from the stack” indicate what instructions can be re-ordered, duplicated, or removed entirely.&lt;/p&gt;
    &lt;p&gt;For example, consider the following pseodocode for some made-up language that stands in for a snippet of compiler IR:&lt;/p&gt;
    &lt;code&gt;# ...
v = some_var[0]
another_var[0] = 5
# ...
&lt;/code&gt;
    &lt;p&gt;The goal of effects is to communicate to the compiler if, for example, these two IR instructions can be re-ordered. The second instruction might write to a location that the first one reads. But it also might not! This is about knowing if &lt;code&gt;some_var&lt;/code&gt; and &lt;code&gt;another_var&lt;/code&gt; alias—if they are different names that
refer to the same object.&lt;/p&gt;
    &lt;p&gt;We can sometimes answer that question directly, but often it’s cheaper to compute an approximate answer: could they even alias? It’s possible that &lt;code&gt;some_var&lt;/code&gt; and &lt;code&gt;another_var&lt;/code&gt; have different types, meaning that (as long as you
have strict aliasing) the &lt;code&gt;Load&lt;/code&gt; and &lt;code&gt;Store&lt;/code&gt; operations that implement these
reads and writes by definition touch different locations. And if they look
at disjoint locations, there need not be any explicit order enforced.&lt;/p&gt;
    &lt;p&gt;Different compilers keep track of this information differently. The null effect analysis gives up and says “every instruction is maximally effectful” and therefore “we can’t re-order or delete any instructions”. That’s probably fine for a first stab at a compiler, where you will get a big speed up purely based on strength reductions. Over-approximations of effects should always be valid.&lt;/p&gt;
    &lt;p&gt;But at some point you start wanting to do dead code elimination (DCE), or common subexpression elimination (CSE), or loads/store elimination, or move instructions around, and you start wondering how to represent effects. That’s where I am right now. So here’s a catalog of different compilers I have looked at recently.&lt;/p&gt;
    &lt;p&gt;There are two main ways I have seen to represent effects: bitsets and heap range lists. We’ll look at one example compiler for each, talk a bit about tradeoffs, then give a bunch of references to other major compilers.&lt;/p&gt;
    &lt;p&gt;We’ll start with Cinder, a Python JIT, because that’s what I used to work on.&lt;/p&gt;
    &lt;p&gt;Cinder tracks heap effects for its high-level IR (HIR) in instr_effects.h. Pretty much everything happens in the &lt;code&gt;memoryEffects(const Instr&amp;amp; instr)&lt;/code&gt; function, which is expected to know
everything about what effects the given instruction might have.&lt;/p&gt;
    &lt;p&gt;The data representation is a bitset representation of a lattice called an &lt;code&gt;AliasClass&lt;/code&gt; and that is defined in alias_class.h. Each
bit in the bitset represents a distinct location in the heap: reads from and
writes to each of these locations are guaranteed not to affect any of the other
locations.&lt;/p&gt;
    &lt;p&gt;Here is the X-macro that defines it:&lt;/p&gt;
    &lt;code&gt;#define HIR_BASIC_ACLS(X) \
  X(ArrayItem)            \
  X(CellItem)             \
  X(DictItem)             \
  X(FuncArgs)             \
  X(FuncAttr)             \
  X(Global)               \
  X(InObjectAttr)         \
  X(ListItem)             \
  X(Other)                \
  X(TupleItem)            \
  X(TypeAttrCache)        \
  X(TypeMethodCache)

enum BitIndexes {
#define ACLS(name) k##name##Bit,
    HIR_BASIC_ACLS(ACLS)
#undef ACLS
};
&lt;/code&gt;
    &lt;p&gt;Note that each bit implicitly represents a set: &lt;code&gt;ListItem&lt;/code&gt; does not refer to a
specific list index, but the infinite set of all possible list indices. It’s
any list index. Still, every list index is completely disjoint from, say, every
entry in a global variable table.&lt;/p&gt;
    &lt;p&gt;(And, to be clear, an object in a list might be the same as an object in a global variable table. The objects themselves can alias. But the thing being written to or read from, the thing being side effected, is the container.)&lt;/p&gt;
    &lt;p&gt;Like other bitset lattices, it’s possible to union the sets by or-ing the bits. It’s possible to query for overlap by and-ing the bits.&lt;/p&gt;
    &lt;code&gt;class AliasClass {
  // The union of two AliasClass
  AliasClass operator|(AliasClass other) const {
    return AliasClass{bits_ | other.bits_};
  }

  // The intersection (overlap) of two AliasClass
  AliasClass operator&amp;amp;(AliasClass other) const {
    return AliasClass{bits_ &amp;amp; other.bits_};
  }
};
&lt;/code&gt;
    &lt;p&gt;If this sounds familiar, it’s because (as the repo notes) it’s a similar idea to Cinder’s type lattice representation.&lt;/p&gt;
    &lt;p&gt;Like other lattices, there is both a bottom element (no effects) and a top element (all possible effects):&lt;/p&gt;
    &lt;code&gt;#define HIR_OR_BITS(name) | k##name

#define HIR_UNION_ACLS(X)                           \
  /* Bottom union */                                \
  X(Empty, 0)                                       \
  /* Top union */                                   \
  X(Any, 0 HIR_BASIC_ACLS(HIR_OR_BITS))             \
  /* Memory locations accessible by managed code */ \
  X(ManagedHeapAny, kAny &amp;amp; ~kFuncArgs)
&lt;/code&gt;
    &lt;p&gt;Union operations naturally hit a fixpoint at &lt;code&gt;Any&lt;/code&gt; and intersection operations
naturally hit a fixpoint at &lt;code&gt;Empty&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;All of this together lets the optimizer ask and answer questions such as:&lt;/p&gt;
    &lt;p&gt;and more.&lt;/p&gt;
    &lt;p&gt;Let’s take a look at an (imaginary) IR version of the code snippet in the intro and see what analyzing it might look like in the optimizer. Here is the fake IR:&lt;/p&gt;
    &lt;code&gt;v0: Tuple = ...
v1: List = ...
v2: Int[5] = ...
# v = some_var[0]
v3: Object = LoadTupleItem v0, 0
# another_var[0] = 5
StoreListItem v1, 0, v2
&lt;/code&gt;
    &lt;p&gt;You can imagine that &lt;code&gt;LoadTupleItem&lt;/code&gt; declares that it reads from the
&lt;code&gt;TupleItem&lt;/code&gt; heap and &lt;code&gt;StoreListItem&lt;/code&gt; declares that it writes to the &lt;code&gt;ListItem&lt;/code&gt;
heap. Because tuple and list pointers cannot be casted into one another and
therefore cannot alias, these are
disjoint heaps in our bitset. Therefore &lt;code&gt;ListItem &amp;amp; TupleItem == 0&lt;/code&gt;, therefore
these memory operations can never interfere! They can (for example) be
re-ordered arbitrarily.&lt;/p&gt;
    &lt;p&gt;In Cinder, these memory effects could in the future be used for instruction re-ordering, but they are today mostly used in two places: the refcount insertion pass and DCE.&lt;/p&gt;
    &lt;p&gt;DCE involves first finding the set of instructions that need to be kept around because they are useful/important/have effects. So here is what the Cinder DCE &lt;code&gt;isUseful&lt;/code&gt; looks like:&lt;/p&gt;
    &lt;code&gt;bool isUseful(Instr&amp;amp; instr) {
  return instr.IsTerminator() || instr.IsSnapshot() ||
      (instr.asDeoptBase() != nullptr &amp;amp;&amp;amp; !instr.IsPrimitiveBox()) ||
      (!instr.IsPhi() &amp;amp;&amp;amp; memoryEffects(instr).may_store != AEmpty);
}
&lt;/code&gt;
    &lt;p&gt;There are some other checks in there but &lt;code&gt;memoryEffects&lt;/code&gt; is right there at the
core of it!&lt;/p&gt;
    &lt;p&gt;Now that we have seen the bitset representation of effects and an implementation in Cinder, let’s take a look at a different representation and and an implementation in JavaScriptCore.&lt;/p&gt;
    &lt;p&gt;I keep coming back to How I implement SSA form by Fil Pizlo, one of the significant contributors to JavaScriptCore (JSC). In particular, I keep coming back to the Uniform Effect Representation section. This notion of “abstract heaps” felt very… well, abstract. Somehow more abstract than the bitset representation. The pre-order and post-order integer pair as a way to represent nested heap effects just did not click.&lt;/p&gt;
    &lt;p&gt;It didn’t make any sense until I actually went spelunking in JavaScriptCore and found one of several implementations—because, you know, JSC is six compilers in a trenchcoat[citation needed].&lt;/p&gt;
    &lt;p&gt;DFG, B3, DOMJIT, and probably others all have their own abstract heap implementations. We’ll look at DOMJIT mostly because it’s a smaller example and also illustrates something else that’s interesting: builtins. We’ll come back to builtins in a minute.&lt;/p&gt;
    &lt;p&gt;Let’s take a lookat how DOMJIT structures its abstract heaps: a YAML file.&lt;/p&gt;
    &lt;code&gt;DOM:
    Tree:
        Node:
            - Node_firstChild
            - Node_lastChild
            - Node_parentNode
            - Node_nextSibling
            - Node_previousSibling
            - Node_ownerDocument
        Document:
            - Document_documentElement
            - Document_body
&lt;/code&gt;
    &lt;p&gt;It’s a hierarchy. &lt;code&gt;Node_firstChild&lt;/code&gt; is a subheap of &lt;code&gt;Node&lt;/code&gt; is a subheap of…
and so on. A write to any &lt;code&gt;Node_nextSibling&lt;/code&gt; is a write to &lt;code&gt;Node&lt;/code&gt; is a write to
… Sibling heaps are unrelated: &lt;code&gt;Node_firstChild&lt;/code&gt; and &lt;code&gt;Node_lastChild&lt;/code&gt;, for
example, are disjoint.&lt;/p&gt;
    &lt;p&gt;To get a feel for this, I wired up a simplified version of ZJIT’s bitset generator (for types!) to read a YAML document and generate a bitset. It generated the following Rust code:&lt;/p&gt;
    &lt;code&gt;mod bits {
  pub const Empty: u64 = 0u64;
  pub const Document_body: u64 = 1u64 &amp;lt;&amp;lt; 0;
  pub const Document_documentElement: u64 = 1u64 &amp;lt;&amp;lt; 1;
  pub const Document: u64 = Document_body | Document_documentElement;
  pub const Node_firstChild: u64 = 1u64 &amp;lt;&amp;lt; 2;
  pub const Node_lastChild: u64 = 1u64 &amp;lt;&amp;lt; 3;
  pub const Node_nextSibling: u64 = 1u64 &amp;lt;&amp;lt; 4;
  pub const Node_ownerDocument: u64 = 1u64 &amp;lt;&amp;lt; 5;
  pub const Node_parentNode: u64 = 1u64 &amp;lt;&amp;lt; 6;
  pub const Node_previousSibling: u64 = 1u64 &amp;lt;&amp;lt; 7;
  pub const Node: u64 = Node_firstChild | Node_lastChild | Node_nextSibling | Node_ownerDocument | Node_parentNode | Node_previousSibling;
  pub const Tree: u64 = Document | Node;
  pub const DOM: u64 = Tree;
  pub const NumTypeBits: u64 = 8;
}
&lt;/code&gt;
    &lt;p&gt;It’s not a fancy X-macro, but it’s a short and flexible Ruby script.&lt;/p&gt;
    &lt;p&gt;Then I took the DOMJIT abstract heap generator—also funnily enough a short Ruby script—modified the output format slightly, and had it generate its int pairs:&lt;/p&gt;
    &lt;code&gt;mod bits {
  /* DOMJIT Abstract Heap Tree.
  DOM&amp;lt;0,8&amp;gt;:
      Tree&amp;lt;0,8&amp;gt;:
          Node&amp;lt;0,6&amp;gt;:
              Node_firstChild&amp;lt;0,1&amp;gt;
              Node_lastChild&amp;lt;1,2&amp;gt;
              Node_parentNode&amp;lt;2,3&amp;gt;
              Node_nextSibling&amp;lt;3,4&amp;gt;
              Node_previousSibling&amp;lt;4,5&amp;gt;
              Node_ownerDocument&amp;lt;5,6&amp;gt;
          Document&amp;lt;6,8&amp;gt;:
              Document_documentElement&amp;lt;6,7&amp;gt;
              Document_body&amp;lt;7,8&amp;gt;
  */
  pub const DOM: HeapRange = HeapRange { start: 0, end: 8 };
  pub const Tree: HeapRange = HeapRange { start: 0, end: 8 };
  pub const Node: HeapRange = HeapRange { start: 0, end: 6 };
  pub const Node_firstChild: HeapRange = HeapRange { start: 0, end: 1 };
  pub const Node_lastChild: HeapRange = HeapRange { start: 1, end: 2 };
  pub const Node_parentNode: HeapRange = HeapRange { start: 2, end: 3 };
  pub const Node_nextSibling: HeapRange = HeapRange { start: 3, end: 4 };
  pub const Node_previousSibling: HeapRange = HeapRange { start: 4, end: 5 };
  pub const Node_ownerDocument: HeapRange = HeapRange { start: 5, end: 6 };
  pub const Document: HeapRange = HeapRange { start: 6, end: 8 };
  pub const Document_documentElement: HeapRange = HeapRange { start: 6, end: 7 };
  pub const Document_body: HeapRange = HeapRange { start: 7, end: 8 };
}
&lt;/code&gt;
    &lt;p&gt;It already comes with a little diagram, which is super helpful for readability.&lt;/p&gt;
    &lt;p&gt;Any empty range(s) represent empty heap effects: if the start and end are the same number, there are no effects. There is no one &lt;code&gt;Empty&lt;/code&gt; value, but any empty
range could be normalized to &lt;code&gt;HeapRange { start: 0, end: 0 }&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Maybe this was obvious to you, dear reader, but this pre-order/post-order thing is about nested ranges! Seeing the output of the generator laid out clearly like this made it make a lot more sense for me.&lt;/p&gt;
    &lt;p&gt;What about checking overlap? Here is the implementation in JSC:&lt;/p&gt;
    &lt;code&gt;namespace WTF {
// Check if two ranges overlap assuming that neither range is empty.
template&amp;lt;typename T&amp;gt;
constexpr bool nonEmptyRangesOverlap(T leftMin, T leftMax, T rightMin, T rightMax)
{
    ASSERT_UNDER_CONSTEXPR_CONTEXT(leftMin &amp;lt; leftMax);
    ASSERT_UNDER_CONSTEXPR_CONTEXT(rightMin &amp;lt; rightMax);

    return leftMax &amp;gt; rightMin &amp;amp;&amp;amp; rightMax &amp;gt; leftMin;
}

// Pass ranges with the min being inclusive and the max being exclusive.
template&amp;lt;typename T&amp;gt;
constexpr bool rangesOverlap(T leftMin, T leftMax, T rightMin, T rightMax) {
    ASSERT_UNDER_CONSTEXPR_CONTEXT(leftMin &amp;lt;= leftMax);
    ASSERT_UNDER_CONSTEXPR_CONTEXT(rightMin &amp;lt;= rightMax);

    // Empty ranges interfere with nothing.
    if (leftMin == leftMax)
        return false;
    if (rightMin == rightMax)
        return false;

    return nonEmptyRangesOverlap(leftMin, leftMax, rightMin, rightMax);
}
}

class HeapRange {
    bool overlaps(const HeapRange&amp;amp; other) const {
        return WTF::rangesOverlap(m_begin, m_end, other.m_begin, other.m_end);
    }
}
&lt;/code&gt;
    &lt;p&gt;(See also How to check for overlapping intervals and Range overlap in two compares for more fun.)&lt;/p&gt;
    &lt;p&gt;While bitsets are a dense representation (you have to hold every bit), they are very compact and they are very precise. You can hold any number of combinations of 64 or 128 bits in a single register. The union and intersection operations are very cheap.&lt;/p&gt;
    &lt;p&gt;With int ranges, it’s a little more complicated. An imprecise union of &lt;code&gt;a&lt;/code&gt; and
&lt;code&gt;b&lt;/code&gt; can take the maximal range that covers both &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;. To get a more
precise union, you have to keep track of both. In the worst case, if you want
efficient arbitrary queries, you need to store your int ranges in an interval
tree. So what gives?&lt;/p&gt;
    &lt;p&gt;I asked Fil if both bitsets and int ranges answer the same question, why use int ranges? He said that it’s more flexible long-term: bitsets get expensive as soon as you need over 128 bits (you might need to heap allocate them!) whereas ranges have no such ceiling. But doesn’t holding sequences of ranges require heap allocation? Well, despite Fil writing this in his SSA post:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The purpose of the effect representation baked into the IR is to provide a precise always-available baseline for alias information that is super easy to work with. […] you can have instructions report that they read/write multiple heaps […] you can have a utility function that produces such lists on demand.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;It’s important to note that this doesn’t actually involve any allocation of lists. JSC does this very clever thing where they have “functors” that they pass in as arguments that compress/summarize what they want to out of an instruction’s effects.&lt;/p&gt;
    &lt;p&gt;Let’s take a look at how the DFG (for example) uses these heap ranges in analysis. The DFG is structured in such a way that it can make use of the DOMJIT heap ranges directly, which is neat.&lt;/p&gt;
    &lt;p&gt;Note that &lt;code&gt;AbstractHeap&lt;/code&gt; in the example below is a thin wrapper over the DFG
compiler’s own &lt;code&gt;DOMJIT::HeapRange&lt;/code&gt; equivalent:&lt;/p&gt;
    &lt;code&gt;class AbstractHeapOverlaps {
public:
    AbstractHeapOverlaps(AbstractHeap heap)
        : m_heap(heap)
        , m_result(false)
    {
    }

    void operator()(AbstractHeap otherHeap) const
    {
        if (m_result)
            return;
        m_result = m_heap.overlaps(otherHeap);
    }

    bool result() const { return m_result; }

private:
    AbstractHeap m_heap;
    mutable bool m_result;
};

bool writesOverlap(Graph&amp;amp; graph, Node* node, AbstractHeap heap)
{
    NoOpClobberize noOp;
    AbstractHeapOverlaps addWrite(heap);
    clobberize(graph, node, noOp, addWrite, noOp);
    return addWrite.result();
}
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;clobberize&lt;/code&gt; is the function that calls these functors (&lt;code&gt;noOp&lt;/code&gt; or &lt;code&gt;addWrite&lt;/code&gt; in
this case) for each effect that the given IR instruction &lt;code&gt;node&lt;/code&gt; declares.&lt;/p&gt;
    &lt;p&gt;I’ve pulled some relevant snippets of &lt;code&gt;clobberize&lt;/code&gt;, which is quite long, that I
think are interesting.&lt;/p&gt;
    &lt;p&gt;First, some instructions (constants, here) have no effects. There’s some utility in the &lt;code&gt;def(PureValue(...))&lt;/code&gt; call but I didn’t understand fully.&lt;/p&gt;
    &lt;p&gt;Then there are some instructions that conditionally have effects depending on the use types of their operands.1 Taking the absolute value of an Int32 or a Double is effect-free but otherwise looks like it can run arbitrary code.&lt;/p&gt;
    &lt;p&gt;Some run-time IR guards that might cause side exits are annotated as such—they write to the &lt;code&gt;SideState&lt;/code&gt; heap.&lt;/p&gt;
    &lt;p&gt;Local variable instructions read specific heaps indexed by what looks like the local index but I’m not sure. This means accessing two different locals won’t alias!&lt;/p&gt;
    &lt;p&gt;Instructions that allocate can’t be re-ordered, it looks like; they both read and write the &lt;code&gt;HeapObjectCount&lt;/code&gt;. This probably limits the amount of allocation
sinking that can be done.&lt;/p&gt;
    &lt;p&gt;Then there’s &lt;code&gt;CallDOM&lt;/code&gt;, which is the builtins stuff I was talking about. We’ll
come back to that after the code block.&lt;/p&gt;
    &lt;code&gt;template&amp;lt;typename ReadFunctor, typename WriteFunctor, typename DefFunctor, typename ClobberTopFunctor&amp;gt;
void clobberize(Graph&amp;amp; graph, Node* node, const ReadFunctor&amp;amp; read, const WriteFunctor&amp;amp; write, const DefFunctor&amp;amp; def)
{
    // ...

    switch (node-&amp;gt;op()) {
    case JSConstant:
    case DoubleConstant:
    case Int52Constant:
        def(PureValue(node, node-&amp;gt;constant()));
        return;

    case ArithAbs:
        if (node-&amp;gt;child1().useKind() == Int32Use || node-&amp;gt;child1().useKind() == DoubleRepUse)
            def(PureValue(node, node-&amp;gt;arithMode()));
        else
            clobberTop();
        return;

    case AssertInBounds:
    case AssertNotEmpty:
        write(SideState);
        return;

    case GetLocal:
        read(AbstractHeap(Stack, node-&amp;gt;operand()));
        def(HeapLocation(StackLoc, AbstractHeap(Stack, node-&amp;gt;operand())), LazyNode(node));
        return;

    case NewArrayWithSize:
    case NewArrayWithSizeAndStructure:
        read(HeapObjectCount);
        write(HeapObjectCount);
        return;

    case CallDOM: {
        const DOMJIT::Signature* signature = node-&amp;gt;signature();
        DOMJIT::Effect effect = signature-&amp;gt;effect;
        if (effect.reads) {
            if (effect.reads == DOMJIT::HeapRange::top())
                read(World);
            else
                read(AbstractHeap(DOMState, effect.reads.rawRepresentation()));
        }
        if (effect.writes) {
            if (effect.writes == DOMJIT::HeapRange::top()) {
                if (Options::validateDFGClobberize())
                    clobberTopFunctor();
                write(Heap);
            } else
                write(AbstractHeap(DOMState, effect.writes.rawRepresentation()));
        }
        ASSERT_WITH_MESSAGE(effect.def == DOMJIT::HeapRange::top(), "Currently, we do not accept any def for CallDOM.");
        return;
    }
    }
}
&lt;/code&gt;
    &lt;p&gt;(Remember that these &lt;code&gt;AbstractHeap&lt;/code&gt; operations are very similar to DOMJIT’s
&lt;code&gt;HeapRange&lt;/code&gt; with a couple more details—and in some cases even contain DOMJIT
&lt;code&gt;HeapRange&lt;/code&gt;s!)&lt;/p&gt;
    &lt;p&gt;This &lt;code&gt;CallDOM&lt;/code&gt; node is the way for the DOM APIs in the browser—a significant
chunk of the builtins, which are written in C++—to communicate what they do
to the optimizing compiler. Without any annotations, the JIT has to assume that
a call into C++ could do anything to the JIT state. Bummer!&lt;/p&gt;
    &lt;p&gt;But because, for example, &lt;code&gt;Node.firstChild&lt;/code&gt; annotates what
memory it reads from and what it doesn’t write to,
the JIT can optimize around it better—or even remove the access completely.
It means the JIT can reason about calls to known builtins the same way that
it reasons about normal JIT opcodes.&lt;/p&gt;
    &lt;p&gt;(Incidentally it looks like it doesn’t even make a C call, but instead is inlined as a little memory read snippet using a JIT builder API. Neat.)&lt;/p&gt;
    &lt;p&gt;Last, we’ll look at Simple, which has a slightly different take on all of this.&lt;/p&gt;
    &lt;p&gt;Simple is Cliff Click’s pet Sea of Nodes (SoN) project to try and showcase the idea to the world—outside of a HotSpot C2 context.&lt;/p&gt;
    &lt;p&gt;This one is a little harder for me to understand but it looks like each translation unit has a &lt;code&gt;StartNode&lt;/code&gt; that doles out
different classes of memory nodes for each alias class. Each IR node then takes
data dependencies on whatever effect nodes it might uses.&lt;/p&gt;
    &lt;p&gt;Alias classes are split up based on the paper Type-Based Alias Analysis (PDF): “Our approach is a form of TBAA similar to the ‘FieldTypeDecl’ algorithm described in the paper.”&lt;/p&gt;
    &lt;p&gt;The Simple project is structured into sequential implementation stages and alias classes come into the picture in Chapter 10.&lt;/p&gt;
    &lt;p&gt;Because I spent a while spelunking through other implementations to see how other projects did this, here is a list of the projects I looked at. Mostly, they use bitsets.&lt;/p&gt;
    &lt;p&gt;HHVM, a JIT for the Hack language, also uses a bitset for its memory effects. See for example: alias-class.h and memory-effects.h.&lt;/p&gt;
    &lt;p&gt;HHVM has a couple places that use this information, such as a definition-sinking pass, alias analysis, DCE, store elimination, refcount opts, and more.&lt;/p&gt;
    &lt;p&gt;If you are wondering why the HHVM representation looks similar to the Cinder representation, it’s because some former HHVM engineers such as Brett Simmers also worked on Cinder!&lt;/p&gt;
    &lt;p&gt;(note that I am linking an ART fork on GitHub as a reference, but the upstream code is hosted on googlesource)&lt;/p&gt;
    &lt;p&gt;Android’s ART Java runtime also uses a bitset for its effect representation. It’s a very compact class called &lt;code&gt;SideEffects&lt;/code&gt; in nodes.h.&lt;/p&gt;
    &lt;p&gt;The side effects are used in loop-invariant code motion, global value numbering, write barrier elimination, scheduling, and more.&lt;/p&gt;
    &lt;p&gt;CoreCLR mostly uses a bitset for its &lt;code&gt;SideEffectSet&lt;/code&gt;
class. This one is interesting though because it also splits out effects
specifically to include sets of local variables (&lt;code&gt;LclVarSet&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;V8 is also about six completely different compilers in a trenchcoat.&lt;/p&gt;
    &lt;p&gt;Turboshaft uses a struct in operations.h called &lt;code&gt;OpEffects&lt;/code&gt; which is two bitsets for reads/writes of effects. This is used in
value numbering as well a bunch of
other small optimization passes they call “reducers”.&lt;/p&gt;
    &lt;p&gt;Maglev also has this thing called &lt;code&gt;NodeT::kProperties&lt;/code&gt; in their IR
nodes that also looks like a bitset and is used in their various
reducers. It has effect query methods on it such as &lt;code&gt;can_eager_deopt&lt;/code&gt; and
&lt;code&gt;can_write&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Until recently, V8 also used Sea of Nodes as its IR representation, which also tracks side effects more explicitly in the structure of the IR itself.&lt;/p&gt;
    &lt;p&gt;Guile Scheme looks like it has a custom tagging scheme type thing.&lt;/p&gt;
    &lt;p&gt;Both bitsets and int ranges are perfectly cromulent ways of representing heap effects for your IR. The Sea of Nodes approach is also probably okay since it powers HotSpot C2 and (for a time) V8.&lt;/p&gt;
    &lt;p&gt;Remember to ask the right questions of your IR when doing analysis.&lt;/p&gt;
    &lt;p&gt;Thank you to Fil Pizlo for writing his initial GitHub Gist and sending me on this journey and thank you to Chris Gregory, Brett Simmers, and Ufuk Kayserilioglu for feedback on making some of the explanations more helpful.&lt;/p&gt;
    &lt;p&gt;This is because the DFG compiler does this interesting thing where they track and guard the input types on use vs having types attached to the input’s own def. It might be a clean way to handle shapes inside the type system while also allowing the type+shape of an object to change over time (which it can do in many dynamic language runtimes). ↩&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bernsteinbear.com/blog/compiler-effects/"/><published>2025-11-11T19:44:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45891907</id><title>A modern 35mm film scanner for home</title><updated>2025-11-11T21:09:16.741860+00:00</updated><content>&lt;doc fingerprint="4d1a5a5e7b33d889"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The New Era of &lt;lb/&gt;Film Scanning&lt;/head&gt;
    &lt;head rend="h2"&gt;The New Era of &lt;lb/&gt;Film Scanning&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality and control.&lt;/head&gt;
    &lt;head rend="h2"&gt;The New Era of &lt;lb/&gt;Film Scanning&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - a high-resolution 35 mm film scanner built for photographers who demand speed, quality, and control.&lt;/head&gt;
    &lt;p&gt;Subscribe&lt;/p&gt;
    &lt;head rend="h2"&gt;Knokke redefines film scanning by bringing modern imaging, optics, and software into a beautifully engineered device.&lt;/head&gt;
    &lt;head rend="h3"&gt;4064&lt;/head&gt;
    &lt;head rend="h3"&gt;4064&lt;/head&gt;
    &lt;head rend="h3"&gt;DPI Resolution&lt;/head&gt;
    &lt;head rend="h3"&gt;DPI Resolution&lt;/head&gt;
    &lt;head rend="h3"&gt;120 dB&lt;/head&gt;
    &lt;head rend="h3"&gt;120 dB&lt;/head&gt;
    &lt;head rend="h3"&gt;Dynamic Range&lt;/head&gt;
    &lt;head rend="h3"&gt;Dynamic Range&lt;/head&gt;
    &lt;head rend="h3"&gt;48-bit&lt;/head&gt;
    &lt;head rend="h3"&gt;48-bit&lt;/head&gt;
    &lt;head rend="h3"&gt;True Color&lt;/head&gt;
    &lt;head rend="h3"&gt;True Color&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - State-of-the-Art Hardware&lt;/head&gt;
    &lt;head rend="h3"&gt;Knokke - State-of-the-Art Hardware&lt;/head&gt;
    &lt;head rend="h2"&gt;Knokke - State-of-the-Art Hardware&lt;/head&gt;
    &lt;p&gt;The modern 35 mm film scanner that captures a full roll in under just a few minutes while capturing every frame at 4064 DPI and 48bit colour. Its custom optics and state-of-the-art sensor deliver benchmark setting quality and speed at a price only Knokke can offer.&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;A Modern Workflow&lt;/p&gt;
    &lt;p&gt;A Modern Workflow&lt;/p&gt;
    &lt;p&gt;A Modern Workflow&lt;/p&gt;
    &lt;head rend="h2"&gt;Korova - Custom Software&lt;/head&gt;
    &lt;head rend="h3"&gt;Korova - Custom Software&lt;/head&gt;
    &lt;head rend="h2"&gt;Korova - Custom Software&lt;/head&gt;
    &lt;p&gt;Built for the 21st century, Knokke runs on Korova, a lean C++ application that's native to Linux, macOS, and Windowsâso you can forget vintage PCs and enjoy a plug-and-play workflow that lets you focus on your photos.&lt;/p&gt;
    &lt;p&gt;Each frame can have custom scan settings, repeatable across multiple scans for consistent results and tailored workflows. The scanner can also skip directly to requested frames, massively accelerating scanning time and enabling fast access to key shots without unnecessary delay.&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;p&gt;Launch Updates&lt;/p&gt;
    &lt;head rend="h3"&gt;Engineered for Individual Users and Lab Professionals&lt;/head&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h2"&gt;Price at Launch&lt;/head&gt;
    &lt;head rend="h2"&gt;999â¬&lt;/head&gt;
    &lt;p&gt;Includes scanner + software&lt;/p&gt;
    &lt;head rend="h2"&gt;4064 dpi resolution&lt;/head&gt;
    &lt;head rend="h2"&gt;5 min per roll&lt;/head&gt;
    &lt;head rend="h2"&gt;48-bit colour depth&lt;/head&gt;
    &lt;head rend="h2"&gt;120 dB Dynamic Range&lt;/head&gt;
    &lt;head rend="h2"&gt;LED Matrix&lt;/head&gt;
    &lt;head rend="h2"&gt;RGB LED backlight&lt;/head&gt;
    &lt;head rend="h2"&gt;USB-C 3.2&lt;/head&gt;
    &lt;head rend="h2"&gt;Custom software&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illumintaed CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illumintaed CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h2"&gt;Price at Launch&lt;/head&gt;
    &lt;head rend="h2"&gt;999â¬&lt;/head&gt;
    &lt;p&gt;Includes scanner + software&lt;/p&gt;
    &lt;head rend="h2"&gt;4064 dpi resolution&lt;/head&gt;
    &lt;head rend="h2"&gt;5 min per roll&lt;/head&gt;
    &lt;head rend="h2"&gt;48-bit colour depth&lt;/head&gt;
    &lt;head rend="h2"&gt;120 dB Dynamic Range&lt;/head&gt;
    &lt;head rend="h2"&gt;LED Matrix&lt;/head&gt;
    &lt;head rend="h2"&gt;RGB LED backlight&lt;/head&gt;
    &lt;head rend="h2"&gt;USB-C 3.2&lt;/head&gt;
    &lt;head rend="h2"&gt;Custom software&lt;/head&gt;
    &lt;head rend="h2"&gt;Frequently &lt;lb/&gt;Asked &lt;lb/&gt;Questions.&lt;/head&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Thank you for your interest! Weâve received an incredible number of requests to join our beta testing program. Weâll be running two separate testing rounds - one in collaboration with selected creators and film labs, and another open to members of our community.&lt;/p&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Thank you for your interest! Weâve received an incredible number of requests to join our beta testing program. Weâll be running two separate testing rounds - one in collaboration with selected creators and film labs, and another open to members of our community.&lt;/p&gt;
    &lt;head rend="h2"&gt;999â¬&lt;/head&gt;
    &lt;p&gt;Includes scanner + software&lt;/p&gt;
    &lt;head rend="h2"&gt;4064 dpi resolution&lt;/head&gt;
    &lt;head rend="h2"&gt;5 min per roll&lt;/head&gt;
    &lt;head rend="h2"&gt;48-bit colour depth&lt;/head&gt;
    &lt;head rend="h2"&gt;120 dB Dynamic Range&lt;/head&gt;
    &lt;head rend="h2"&gt;LED Matrix&lt;/head&gt;
    &lt;head rend="h2"&gt;RGB LED backlight&lt;/head&gt;
    &lt;head rend="h2"&gt;USB-C 3.2&lt;/head&gt;
    &lt;head rend="h2"&gt;Custom software&lt;/head&gt;
    &lt;head rend="h2"&gt;Frequently Asked Questions.&lt;/head&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter in Q1 2026. Follow us on Instagram or subscribe to our newsletter to be among the first notified when pre-orders open.&lt;/p&gt;
    &lt;p&gt;Will Knokke support 120 film, panoramic formats, or border scanning?&lt;/p&gt;
    &lt;p&gt;Knokke fully supports any frame width on 35 mm (135) film, thanks to automatic edge detection. It can also perform partial border scans to preserve maximum resolution and frame content. (120 film support is not part of the first release but is under consideration for the future.)&lt;/p&gt;
    &lt;p&gt;What kind of light source and sensor does Knokke use?&lt;/p&gt;
    &lt;p&gt;Knokke uses an RGB LED backlight, precisely wavelength-matched to a modern backside-illuminated CMOS sensor. The sensor features 2 Î¼m pixels and delivers a 78 dB linear dynamic range in 12-bit mode, expandable to 120 dB (â 14 stops) with the 3-step HDR log mode at native 16-bit output. This combination ensures accurate colour reproduction, tonal smoothness, and detail retention in both highlights and shadows.&lt;/p&gt;
    &lt;p&gt;What makes Knokke different from other scanners like the Fuji Frontier, Nikon Coolscan, or camera-stand setups?&lt;/p&gt;
    &lt;p&gt;Knokke combines speed, scanning quality, and ease of use in a compact form factor. It scans a full 35 mm roll in under 5 minutes, offers per-frame customisation, and requires no legacy computer hardware or drivers.&lt;/p&gt;
    &lt;p&gt;Will example scans be shared before launch?&lt;/p&gt;
    &lt;p&gt;Yes. Weâre collaborating with several film labs in Berlin to benchmark Knokke against Fuji Frontier and Noritsu scanners. Sample results will be published before the Kickstarter campaign, so you can make a fully informed decision.&lt;/p&gt;
    &lt;p&gt;How much is Knokke going to cost?&lt;/p&gt;
    &lt;p&gt;Knokke will cost 999â¬ at launch. We are still working on bringing the price down further threw optimising design and sourcing. It's final retail price is set at 1599â¬.&lt;/p&gt;
    &lt;p&gt;Is the software open source?&lt;/p&gt;
    &lt;p&gt;Yes. Our control application, Korova, will be fully open source and maintained long term. Itâs a native, lightweight application for Windows, macOS, and Linux.&lt;/p&gt;
    &lt;p&gt;Is Knokke open, repairable, and long-term supported?&lt;/p&gt;
    &lt;p&gt;Absolutely. Weâre committed to building a scanner that lasts decades. All schematics and repair manuals will be publicly available, replacement parts can be purchased directly, and the software will remain supported for as long as possible.&lt;/p&gt;
    &lt;p&gt;When will Knokke be available?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter.com in Q1 2026. Follow us on Instagram and subscribe to our newsletter to be among the first notified about updates.&lt;/p&gt;
    &lt;p&gt;Can I become a beta tester?&lt;/p&gt;
    &lt;p&gt;Knokke will launch on Kickstarter in Q1 2026. Follow us on Instagram or subscribe to our newsletter to be among the first notified when pre-orders open.&lt;/p&gt;
    &lt;head rend="h4"&gt;Engineered for individual and lab use&lt;/head&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;A Closer Look at Knokke&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h2"&gt;Specifications.&lt;/head&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illuminated CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;IMAGING SYSTEM&lt;/head&gt;
    &lt;p&gt;SENSOR&lt;/p&gt;
    &lt;p&gt;Backside illuminated CMOS Sensor&lt;/p&gt;
    &lt;p&gt;DYNAMIC RANGE&lt;/p&gt;
    &lt;p&gt;linear dynamic range of 78 dB, expandable to 120 dB with native 16-bit HDR log profile, up to 14 stops of range&lt;/p&gt;
    &lt;p&gt;RESOLUTION&lt;/p&gt;
    &lt;p&gt;Max. 4064 dpi (~22 MP), 2032 dpi (~5,5MP)&lt;/p&gt;
    &lt;p&gt;LENS&lt;/p&gt;
    &lt;p&gt;Custom 4 element lens with high MTF (modulation transfer function)&lt;/p&gt;
    &lt;p&gt;LIGHT SOURCE&lt;/p&gt;
    &lt;p&gt;RGB LED backlight&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;PERFORMANCE &amp;amp; WORKFLOW&lt;/head&gt;
    &lt;p&gt;Scan Speed&lt;/p&gt;
    &lt;p&gt;per roll under 5 minutes (4064 dpi), under 2 minutes (2032 dpi)&lt;/p&gt;
    &lt;p&gt;FILM TRANSPORT&lt;/p&gt;
    &lt;p&gt;automated, min. strip length 3 images&lt;/p&gt;
    &lt;p&gt;FRAME CONTROL&lt;/p&gt;
    &lt;p&gt;per-frame scan settings, skip directly to any frame&lt;/p&gt;
    &lt;p&gt;DXN DECODER&lt;/p&gt;
    &lt;p&gt;reads 35 mm DX codes, embeds film type, ISO, roll info into metadata&lt;/p&gt;
    &lt;p&gt;SOFTWARE&lt;/p&gt;
    &lt;p&gt;Korova (native for Windows, macOS, Linux)&lt;/p&gt;
    &lt;p&gt;FILE FORMATS&lt;/p&gt;
    &lt;p&gt;RAW, TIFF, DNG linear, JPEG, PNG, BMP, HDR&lt;/p&gt;
    &lt;p&gt;FILE SIZES&lt;/p&gt;
    &lt;p&gt;RAW/TIFF/DNG linear ~127 MB; JPEG XL (lossless) 42â52 MB; PNG 106â118 MB&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h3"&gt;HARDWARE&lt;/head&gt;
    &lt;p&gt;DIMENSIONS&lt;/p&gt;
    &lt;p&gt;250 Ã 150 Ã 63 mm&lt;/p&gt;
    &lt;p&gt;WEIGHT&lt;/p&gt;
    &lt;p&gt;1400 grams&lt;/p&gt;
    &lt;p&gt;INTERFACE&lt;/p&gt;
    &lt;p&gt;USB-C (USB 3.1)&lt;/p&gt;
    &lt;p&gt;POWER SUPPLY&lt;/p&gt;
    &lt;p&gt;18 V DC, 2 A (included)&lt;/p&gt;
    &lt;head rend="h3"&gt;Engineered for individual and lab use&lt;/head&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;01&lt;/head&gt;
    &lt;head rend="h6"&gt;Quality&lt;/head&gt;
    &lt;p&gt;Knokkeâs premium build and precision engineering ensure lasting, reliable performance.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;02&lt;/head&gt;
    &lt;head rend="h6"&gt;Speed&lt;/head&gt;
    &lt;p&gt;Knokkeâs high scan speed and streamlined workflow keep you moving.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;03&lt;/head&gt;
    &lt;head rend="h6"&gt;Full Control&lt;/head&gt;
    &lt;p&gt;Knokke lets you fine-tune every detail with flexible settings and precise color control.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
    &lt;head rend="h6"&gt;04&lt;/head&gt;
    &lt;head rend="h6"&gt;Future Proof&lt;/head&gt;
    &lt;p&gt;Knokke comes with ongoing software support, open-source flexibility, and readily available spare parts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.soke.engineering/"/><published>2025-11-11T19:48:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45891968</id><title>Adk-go: code-first Go toolkit for building, evaluating, and deploying AI agents</title><updated>2025-11-11T21:09:16.095231+00:00</updated><content>&lt;doc fingerprint="3d738c52c9d3a6e3"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;An open-source, code-first Go toolkit for building, evaluating, and deploying sophisticated AI agents with flexibility and control.&lt;/head&gt;
    &lt;head rend="h3"&gt;Important Links: Docs &amp;amp; Samples &amp;amp; Python ADK &amp;amp; Java ADK &amp;amp; ADK Web.&lt;/head&gt;
    &lt;p&gt;Agent Development Kit (ADK) is a flexible and modular framework that applies software development principles to AI agent creation. It is designed to simplify building, deploying, and orchestrating agent workflows, from simple tasks to complex systems. While optimized for Gemini, ADK is model-agnostic, deployment-agnostic, and compatible with other frameworks.&lt;/p&gt;
    &lt;p&gt;This Go version of ADK is ideal for developers building cloud-native agent applications, leveraging Go's strengths in concurrency and performance.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Idiomatic Go: Designed to feel natural and leverage the power of Go.&lt;/item&gt;
      &lt;item&gt;Rich Tool Ecosystem: Utilize pre-built tools, custom functions, or integrate existing tools to give agents diverse capabilities.&lt;/item&gt;
      &lt;item&gt;Code-First Development: Define agent logic, tools, and orchestration directly in Go for ultimate flexibility, testability, and versioning.&lt;/item&gt;
      &lt;item&gt;Modular Multi-Agent Systems: Design scalable applications by composing multiple specialized agents.&lt;/item&gt;
      &lt;item&gt;Deploy Anywhere: Easily containerize and deploy agents, with strong support for cloud-native environments like Google Cloud Run.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To add ADK Go to your project, run:&lt;/p&gt;
    &lt;code&gt;go get google.golang.org/adk&lt;/code&gt;
    &lt;p&gt;This project is licensed under the Apache 2.0 License - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;The exception is internal/httprr - see its LICENSE file.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/google/adk-go"/><published>2025-11-11T19:52:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45892174</id><title>Xortran - A PDP-11 Neural Network With Backpropagation in Fortran IV</title><updated>2025-11-11T21:09:15.498631+00:00</updated><content>&lt;doc fingerprint="7293ba097f3c7842"&gt;
  &lt;main&gt;
    &lt;p&gt;XORTRAN is a multilayer perceptron (MLP) written in FORTRAN IV, compiled and executed under RT-11 on a PDP-11/34A (via SIMH simulator).&lt;/p&gt;
    &lt;p&gt;It learns the classic non-linear XOR problem using:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One hidden layer (4 neurons, leaky ReLU activation)&lt;/item&gt;
      &lt;item&gt;Backpropagation with mean squared error loss&lt;/item&gt;
      &lt;item&gt;He-like initialization (manual Gaussian via Box-Muller lite)&lt;/item&gt;
      &lt;item&gt;Learning rate annealing (0.5 → 0.1 → 0.01)&lt;/item&gt;
      &lt;item&gt;Tanh output&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The code compiles with the DEC FORTRAN IV compiler (1974). Execution requires a system with at least 32 kilobytes of memory and an FP11 floating-point processor. The PDP-11/34A was chosen as it was the smallest and most affordable PDP-11 equipped with an FP11 floating-point processor in the 1970s.&lt;/p&gt;
    &lt;p&gt;The training of the 17 parameters should take less than a couple minutes on the real hardware. In SIMH, setting the throttle to 500K (&lt;code&gt;set throttle 500K&lt;/code&gt;) will
provide a more realistic execution speed.&lt;/p&gt;
    &lt;p&gt;The output shows the mean squared loss every 100 epochs, followed by the final predictions from the forward pass.&lt;/p&gt;
    &lt;p&gt;The network converges towards the expected XOR outputs after a few hundred epochs, gradually reducing the error until it accurately approximates the desired results.&lt;/p&gt;
    &lt;code&gt;.RUN XORTRN
   1  0.329960233835D+00
 100  0.195189856059D+00
 200  0.816064184115D-01
 300  0.654882376056D-02
 400  0.109833284544D-02
 500  0.928130032748D-03

0 0 GOT:0.008353 EXPECTED:0.
0 1 GOT:0.979327 EXPECTED:1.
1 0 GOT:0.947050 EXPECTED:1.
1 1 GOT:0.020147 EXPECTED:0.
STOP --
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;In SIMH, attach the RL1 drive (&lt;/p&gt;&lt;code&gt;ATT RL1 xortran.rl1&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;In RT-11 (I use the single job RT-11-SJ V5), assuming&lt;/p&gt;&lt;code&gt;DL1:&lt;/code&gt;is assigned to&lt;code&gt;DK:&lt;/code&gt;:&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;.FORTRAN/LIST:XORTRN.LST XORTRN.FOR
.LINK XORTRN.OBJ,FORLIB
.RUN XORTRN
&lt;/code&gt;
    &lt;p&gt;Or if you just want to run the binary:&lt;/p&gt;
    &lt;code&gt;.RUN DL1:XORTRN
&lt;/code&gt;
    &lt;p&gt;This project demonstrates that a minimal FORTRAN IV environment from the 1970s was sufficient to implement a basic neural network with backpropagation.&lt;lb/&gt; It’s both a retro-computing curiosity and a small historical experiment bridging early scientific computing and modern machine learning.&lt;/p&gt;
    &lt;p&gt;© 2025 Damien Boureille&lt;/p&gt;
    &lt;p&gt;This code is released under the MIT License.&lt;lb/&gt; You are free to use, copy, modify, and redistribute it, provided that you credit the original author.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/dbrll/Xortran"/><published>2025-11-11T20:10:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45892191</id><title>The Terminal of the Future</title><updated>2025-11-11T21:09:15.228355+00:00</updated><content>&lt;doc fingerprint="37eac95c22846b89"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;the terminal of the future&lt;/head&gt;
    &lt;p&gt;This post is part 6 of a multi-part series called “the computer of the next 200 years”.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Terminal internals are a mess. A lot of it is just the way it is because someone made a decision in the 80s and now it’s impossible to change. —Julia Evans&lt;/p&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;This is what you have to do to redesign infrastructure. Rich [Hickey] didn't just pile some crap on top of Lisp [when building Clojure]. He took the entire Lisp and moved the whole design at once. —Gary Bernhardt&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;a mental model of a terminal&lt;/head&gt;
    &lt;p&gt;At a very very high level, a terminal has four parts:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The "terminal emulator", which is a program that renders a grid-like structure to your graphical display.&lt;/item&gt;
      &lt;item&gt;The "pseudo-terminal" (PTY), which is a connection between the terminal emulator and a "process group" which receives input. This is not a program. This is a piece of state in the kernel.&lt;/item&gt;
      &lt;item&gt;The "shell", which is a program that leads the "process group", reads and parses input, spawns processes, and generally acts as an event loop. Most environments use bash as the default shell.&lt;/item&gt;
      &lt;item&gt;The programs spawned by your shell, which interact with all of the above in order to receive input and send output.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I lied a little bit above. "input" is not just text. It also includes signals that can be sent to the running process. Converting keystrokes to signals is the job of the PTY.&lt;/p&gt;
    &lt;p&gt;Similar, "output" is not just text. It's a stream of ANSI Escape Sequences that can be used by the terminal emulator to display rich formatting.&lt;/p&gt;
    &lt;head rend="h2"&gt;what does a better terminal look like?&lt;/head&gt;
    &lt;p&gt;I do some weird things with terminals. However, the amount of hacks I can get up to are pretty limited, because terminals are pretty limited. I won't go into all the ways they're limited, because it's been rehashed many times before. What I want to do instead is imagine what a better terminal can look like.&lt;/p&gt;
    &lt;head rend="h3"&gt;a first try: Jupyter&lt;/head&gt;
    &lt;p&gt;The closest thing to a terminal analog that most people are familiar with is Jupyter Notebook. This offers a lot of cool features that are not possible in a "traditional" VT100 emulator:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;high fidelity image rendering&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;a "rerun from start" button (or rerun the current command; or rerun only a single past command) that replaces past output instead of appending to it&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"views" of source code and output that can be rewritten in place (e.g. markdown can be viewed either as source or as rendered HTML)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;a built-in editor with syntax highlighting, tabs, panes, mouse support, etc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;some problems&lt;/head&gt;
    &lt;p&gt;Jupyter works by having a "kernel" (in this case, a python interpreter) and a "renderer" (in this case, a web application displayed by the browser). You could imagine using a Jupyter Notebook with a shell as the kernel, so that you get all the nice features of Jupyter when running shell commands. However, that quickly runs into some issues:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Your shell gets the commands all at once, not character-by-character, so tab-complete, syntax highlighting, and autosuggestions don't work.&lt;/item&gt;
      &lt;item&gt;What do you do about long-lived processes? By default, Jupyter runs a cell until completion; you can cancel it, but you can't suspend, resume, interact with, nor view a process while it's running. Don't even think about running &lt;code&gt;vi&lt;/code&gt;or&lt;code&gt;top&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The "rerun cell" buttons do horrible things to the state of your computer (normal Jupyter kernels have this problem too, but "rerun all" works better when the commands don't usually include &lt;code&gt;rm -rf&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Undo/redo do not work. (They don't work in a normal terminal either, but people attempt to use them more when it looks like they should be able to.)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It turns out all these problems are solveable.&lt;/p&gt;
    &lt;head rend="h2"&gt;how does that work?&lt;/head&gt;
    &lt;head rend="h3"&gt;shell integration&lt;/head&gt;
    &lt;p&gt;There exists today a terminal called Warp. Warp has built native integration between the terminal and the shell, where the terminal understands where each command starts and stops, what it outputs, and what is your own input. As a result, it can render things very prettily:&lt;/p&gt;
    &lt;p&gt;It does this using (mostly) standard features built-in to the terminal and shell (a custom DCS): you can read their explanation here. It's possible to do this less invasively using OSC 133 escape codes; I'm not sure why Warp didn't do this, but that's ok.&lt;/p&gt;
    &lt;p&gt;iTerm2 does a similar thing, and this allows it to enable really quite a lot of features: navigating between commands with a single hotkey; notifying you when a command finishes running, showing the current command as an "overlay" if the output goes off the screen.&lt;/p&gt;
    &lt;head rend="h3"&gt;long-lived processes&lt;/head&gt;
    &lt;p&gt;This is really three different things. The first is interacting with a long-lived process. The second is suspending the process without killing it. The third is disconnecting from the process, in such a way that the process state is not disturbed and is still available if you want to reconnect.&lt;/p&gt;
    &lt;head rend="h4"&gt;interacting&lt;/head&gt;
    &lt;p&gt;To interact with a process, you need bidirectional communication, i.e. you need a "cell output" that is also an input. An example would be any TUI, like &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;gdb&lt;/code&gt;, or &lt;code&gt;vim&lt;/code&gt; 1.  Fortunately, Jupyter is really good at this!  The whole design is around having interactive outputs that you can change and update.&lt;/p&gt;
    &lt;p&gt;Additionally, I would expect my terminal to always have a "free input cell", as Matklad describes in A Better Shell, where the interactive process runs in the top half of the window and an input cell is available in the bottom half. Jupyter can do this today, but "add a cell" is manual, not automatic.&lt;/p&gt;
    &lt;head rend="h4"&gt;suspending&lt;/head&gt;
    &lt;p&gt;"Suspending" a process is usually called "job control". There's not too much to talk about here, except that I would expect a "modern" terminal to show me all suspended and background processes as a de-emphasized persistent visual, kinda like how Intellij will show you "indexing ..." in the bottom taskbar.&lt;/p&gt;
    &lt;head rend="h4"&gt;disconnecting&lt;/head&gt;
    &lt;p&gt;There are roughly three existing approaches for disconnecting and reconnecting to a terminal session (Well, four if you count reptyr).&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Tmux / Zellij / Screen&lt;/p&gt;
        &lt;p&gt;These tools inject a whole extra terminal emulator between your terminal emulator and the program. They work by having a "server" which actually owns the PTY and renders the output, and a "client" that displays the output to your "real" terminal emulator. This model lets you detach clients, reattach them later, or even attach multiple clients at once. You can think of this as a "batteries-included" approach. It also has the benefit that you can program both the client and the server (although many modern terminals, like Kitty and Wezterm are programmable now); that you can organize your tabs and windows in the terminal (although many modern desktop environments have tiling and thorough keyboard shortcuts); and that you get street cred for looking like Hackerman.&lt;/p&gt;
        &lt;p&gt;The downside is that, well, now you have an extra terminal emulator running in your terminal, with all the bugs that implies.&lt;/p&gt;
        &lt;p&gt;iTerm actually avoids this by bypassing the tmux client altogether and acting as its own client that talks directly to the server. In this mode, "tmux tabs" are actually iTerm tabs, "tmux panes" are iTerm panes, and so on. This is a good model, and I would adopt it when writing a future terminal for integration with existing tmux setups.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Mosh is a really interesting place in the design space. It is not a terminal emulator replacement; instead it is an ssh replacement. Its big draw is that it supports reconnecting to your terminal session after a network interruption. It does that by running a state machine on the server and replaying an incremental diff of the viewport to the client. This is a similar model to tmux, except that it doesn't support the "multiplexing" part (it expects your terminal emulator to handle that), nor scrollback (ditto). Because it has its own renderer, it has a similar class of bugs to tmux. One feature it does have, unlike tmux, is that the "client" is really running on your side of the network, so local line editing is instant.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;alden/shpool/dtach/abduco/diss&lt;/p&gt;
        &lt;p&gt;These all occupy a similar place in the design space: they only handle session detach/resume with a client/server, not networking or scrollback, and do not include their own terminal emulator. Compared to tmux and mosh, they are highly decoupled.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;rerun and undo/redo&lt;/head&gt;
    &lt;p&gt;I'm going to treat these together because the solution is the same: dataflow tracking.&lt;/p&gt;
    &lt;p&gt;Take as an example pluto.jl, which does this today by hooking into the Julia compiler.&lt;/p&gt;
    &lt;p&gt;Note that this updates cells live in response to previous cells that they depend on. Not pictured is that it doesn't update cells if their dependencies haven't changed. You can think of this as a spreadsheet-like Jupyter, where code is only rerun when necessary.&lt;/p&gt;
    &lt;p&gt;You may say this is hard to generalize. The trick here is orthogonal persistence. If you sandbox the processes, track all IO, and prevent things that are "too weird" unless they're talking to other processes in the sandbox (e.g. unix sockets and POST requests), you have really quite a lot of control over the process! This lets you treat it as a pure function of its inputs, where its inputs are "the whole file system, all environment variables, and all process attributes".&lt;/p&gt;
    &lt;head rend="h3"&gt;derived features&lt;/head&gt;
    &lt;p&gt;Once you have these primitives—Jupyter notebook frontends, undo/redo, automatic rerun, persistence, and shell integration—you can build really quite a lot on top. And you can build it incrementally, piece-by-piece:&lt;/p&gt;
    &lt;head rend="h4"&gt;needs a Jupyter notebook frontend&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Runbooks (actually, you can build these just with Jupyter and a PTY primitive).&lt;/item&gt;
      &lt;item&gt;Terminal customization that uses normal CSS, no weird custom languages or ANSI color codes.&lt;/item&gt;
      &lt;item&gt;Search for commands by output/timestamp. Currently, you can search across output in the current session, or you can search across all command input history, but you don't have any kind of smart filters, and the output doesn't persist across sessions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;needs shell integration&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Timestamps and execution duration for each command.&lt;/item&gt;
      &lt;item&gt;Local line-editing, even across a network boundary.&lt;/item&gt;
      &lt;item&gt;IntelliSense for shell commands, without having to hit tab and with rendering that's integrated into the terminal.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;needs sandboxed tracing&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"All the features from sandboxed tracing": collaborative terminals, querying files modified by a command, "asciinema but you can edit it at runtime", tracing build systems.&lt;/item&gt;
      &lt;item&gt;Extend the smart search above to also search by disk state at the time the command was run.&lt;/item&gt;
      &lt;item&gt;Extending undo/redo to a git-like branching model (something like this is already support by emacs undo-tree), where you have multiple "views" of the process tree.&lt;/item&gt;
      &lt;item&gt;Given the undo-tree model, and since we have sandboxing, we can give an LLM access to your project, and run many of them in parallel at the same time without overwriting each others state, and in such a way that you can see what they're doing, edit it, and save it into a runbook for later use.&lt;/item&gt;
      &lt;item&gt;A terminal in a prod environment that can't affect the state of the machine, only inspect the existing state.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;ok but how do you build this&lt;/head&gt;
    &lt;p&gt;jyn, you may say, you can't build vertical integration in open source. you can't make money off open source projects. the switching costs are too high.&lt;/p&gt;
    &lt;p&gt;All these things are true. To talk about how this is possible, we have to talk about incremental adoption.&lt;/p&gt;
    &lt;p&gt;if I were building this, I would do it in stages, such that at each stage the thing is an improvement over its alternatives. This is how &lt;code&gt;jj&lt;/code&gt; works and it works extremely well: it doesn't require everyone on a team to switch at once because individual people can use &lt;code&gt;jj&lt;/code&gt;, even for single commands, without a large impact on everyone else.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 1: transactional semantics&lt;/head&gt;
    &lt;p&gt;When people think of redesigning the terminal, they always think of redesigning the terminal emulator. This is exactly the wrong place to start. People are attached to their emulators. They configure them, they make them look nice, they use their keybindings. There is a high switching cost to switching emulators because everything affects everything else. It's not so terribly high, because it's still individual and not shared across a team, but still high.&lt;/p&gt;
    &lt;p&gt;What I would do instead is start at the CLI layer. CLI programs are great because they're easy to install and run and have very low switching costs: you can use them one-off without changing your whole workflow.&lt;/p&gt;
    &lt;p&gt;So, I would write a CLI that implements transactional semantics for the terminal. You can imagine an interface something like &lt;code&gt;transaction [start|rollback|commit]&lt;/code&gt;, where everything run after &lt;code&gt;start&lt;/code&gt; is undoable. There is a lot you can do with this alone, I think you could build a whole business off this.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 2: persistent sessions&lt;/head&gt;
    &lt;p&gt;Once I had transactional semantics, I would try to decouple persistence from tmux and mosh.&lt;/p&gt;
    &lt;p&gt;To get PTY persistence, you have to introduce a client/server model, because the kernel really really expects both sides of a PTY to always be connected. Using commands like alden, or a library like it (it's not that complicated), lets you do this simply, without affecting the terminal emulator nor the programs running inside the PTY session.&lt;/p&gt;
    &lt;p&gt;To get scrollback, the server could save input and output indefinitely and replay them when the client reconnects. This gets you "native" scrollback—the terminal emulator you're already using handles it exactly like any other output, because it looks exactly like any other output—while still being replayable and resumable from an arbitrary starting point. This requires some amount of parsing ANSI escape codes2, but it's doable with enough work.&lt;/p&gt;
    &lt;p&gt;To get network resumption like mosh, my custom server could use Eternal TCP (possibly built on top of QUIC for efficiency). Notably, the persistence for the PTY is separate from the persistence for the network connection. Eternal TCP here is strictly an optimization: you could build this on top of a bash script that runs &lt;code&gt;ssh host eternal-pty attach&lt;/code&gt; in a loop, it's just not as nice an experience because of network delay and packet loss. Again, composable parts allow for incremental adoption.&lt;/p&gt;
    &lt;p&gt;At this point, you're already able to connect multiple clients to a single terminal session, like tmux, but window management is still done by your terminal emulator, not by the client/server. If you wanted to have window management integrated, the terminal emulator could speak the tmux -CC protocol, like iTerm.&lt;/p&gt;
    &lt;p&gt;All parts of this stage can be done independently and in parallel from the transactional semantics, but I don't think you can build a business off them, it's not enough of an improvement over the existing tools.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 3: structured RPC&lt;/head&gt;
    &lt;p&gt;This bit depends on the client/server model. Once you have a server interposed between the terminal emulator and the client, you can start doing really funny things like tagging I/O with metadata. This lets all data be timestamped3 and lets you distinguish input from output. xterm.js works something like this. When combined with shell integration, this even lets you distinguish shell prompts from program output, at the data layer.&lt;/p&gt;
    &lt;p&gt;Now you can start doing really funny things, because you have a structured log of your terminal session. You can replay the log as a recording, like asciinema4; you can transform the shell prompt without rerunning all the commands; you can import it into a Jupyter Notebook or Atuin Desktop; you can save the commands and rerun them later as a script. Your terminal is data.&lt;/p&gt;
    &lt;head rend="h3"&gt;stage 4: jupyter-like frontend&lt;/head&gt;
    &lt;p&gt;This is the very first time that we touch the terminal emulator, and it's intentionally the last step because it has the highest switching costs. This makes use of all the nice features we've built to give you a nice UI. You don't need our &lt;code&gt;transaction&lt;/code&gt; CLI anymore unless you want nested transactions, because your whole terminal session starts in a transaction by default. You get all the features I mention above, because we've put all the pieces together.&lt;/p&gt;
    &lt;head rend="h2"&gt;jyn, what the fuck&lt;/head&gt;
    &lt;p&gt;This is bold and ambitious and I think building the whole thing would take about a decade. That's ok. I'm patient.&lt;/p&gt;
    &lt;p&gt;You can help me by spreading the word :) Perhaps this post will inspire someone to start building this themselves.&lt;/p&gt;
    &lt;head rend="h2"&gt;bibliography&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gary Bernhardt, “A Whole New World”&lt;/item&gt;
      &lt;item&gt;Alex Kladov, “A Better Shell”&lt;/item&gt;
      &lt;item&gt;jyn, “how i use my terminal”&lt;/item&gt;
      &lt;item&gt;jyn, “Complected and Orthogonal Persistence”&lt;/item&gt;
      &lt;item&gt;jyn, “you are in a box”&lt;/item&gt;
      &lt;item&gt;jyn, “there's two costs to making money off an open source project…”&lt;/item&gt;
      &lt;item&gt;Rebecca Turner, “Vertical Integration is the Only Thing That Matters”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “New zine: The Secret Rules of the Terminal”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “meet the terminal emulator”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “What happens when you press a key in your terminal?”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “What's involved in getting a "modern" terminal setup?”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “Bash scripting quirks &amp;amp; safety tips”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “Some terminal frustrations”&lt;/item&gt;
      &lt;item&gt;Julia Evans, “Reasons to use your shell's job control”&lt;/item&gt;
      &lt;item&gt;“signal(7) - Miscellaneous Information Manual”&lt;/item&gt;
      &lt;item&gt;Christian Petersen, “ANSI Escape Codes”&lt;/item&gt;
      &lt;item&gt;saoirse, “withoutboats/notty: A new kind of terminal”&lt;/item&gt;
      &lt;item&gt;Jupyter Team, “Project Jupyter Documentation”&lt;/item&gt;
      &lt;item&gt;“Warp: The Agentic Development Environment”&lt;/item&gt;
      &lt;item&gt;“Warp: How Warp Works”&lt;/item&gt;
      &lt;item&gt;“Warp: Completions”&lt;/item&gt;
      &lt;item&gt;George Nachman, “iTerm2: Proprietary Escape Codes”&lt;/item&gt;
      &lt;item&gt;George Nachman, “iTerm2: Shell Integration”&lt;/item&gt;
      &lt;item&gt;George Nachman, “iTerm2: tmux Integration”&lt;/item&gt;
      &lt;item&gt;Project Jupyter, “Jupyter Widgets”&lt;/item&gt;
      &lt;item&gt;Nelson Elhage, “nelhage/reptyr: Reparent a running program to a new terminal”&lt;/item&gt;
      &lt;item&gt;Kovid Goyal, “kitty”&lt;/item&gt;
      &lt;item&gt;Kovid Goyal, “kitty - Frequently Asked Questions”&lt;/item&gt;
      &lt;item&gt;Wez Furlong, “Wezterm”&lt;/item&gt;
      &lt;item&gt;Keith Winstein, “Mosh: the mobile shell”&lt;/item&gt;
      &lt;item&gt;Keith Winstein, “Display errors with certain characters&lt;/item&gt;
      &lt;item&gt;Matthew Skala, “alden: detachable terminal sessions without breaking scrollback”&lt;/item&gt;
      &lt;item&gt;Ethan Pailes, “shell-pool/shpool: Think tmux, then aim... lower”&lt;/item&gt;
      &lt;item&gt;Ned T. Crigler, “crigler/dtach: A simple program that emulates the detach feature of screen”&lt;/item&gt;
      &lt;item&gt;Marc André Tanner, “martanne/abduco: abduco provides session management”&lt;/item&gt;
      &lt;item&gt;yazgoo, “yazgoo/diss: dtach-like program / crate in rust”&lt;/item&gt;
      &lt;item&gt;Fons van der Plas, “Pluto.jl — interactive Julia programming environment”&lt;/item&gt;
      &lt;item&gt;Ellie Huxtable, “Atuin Desktop: Runbooks that Run”&lt;/item&gt;
      &lt;item&gt;Toby Cubitt, “undo-tree”&lt;/item&gt;
      &lt;item&gt;“SIGHUP - Wikipedia”&lt;/item&gt;
      &lt;item&gt;Jason Gauci, “How Eternal Terminal Works”&lt;/item&gt;
      &lt;item&gt;Marcin Kulik, “Record and share your terminal sessions, the simple way - asciinema.org”&lt;/item&gt;
      &lt;item&gt;“Alternate Screen | Ratatui”&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jyn.dev/the-terminal-of-the-future"/><published>2025-11-11T20:11:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45892340</id><title>Microplastics: No longer a "maybe"</title><updated>2025-11-11T21:09:14.997616+00:00</updated><content>&lt;doc fingerprint="7aec758f3fb3e3b3"&gt;
  &lt;main&gt;
    &lt;p&gt;&lt;lb/&gt; It’s Already Inside Us&lt;lb/&gt; Microplastics are not just an environmental problem affecting nature. They’re in our blood [1], lungs [2], placentas [3], brains [4], and breast milk [5]. Every human tissue scientists have tested so far has come back contaminated. In diseased tissue samples of people with chronic illnesses (IBD [6], Dementia [7], heart disease [8]), microplastic prevalence is significantly higher than healthy tissue. &lt;lb/&gt; The Trajectory Is Clear&lt;lb/&gt; Every new study finds higher microplastic concentrations in human tissue than the last. Most recently, we found a 50% increase in brain tissue microplastic prevalence over the past 8 years [9]. The burden on the human body is compounding: what we take in today stays with us for decades, and future generations are born contaminated. That’s not even mentioning nanoplastics, which we weren’t able to detect until 10 years ago [10]. &lt;lb/&gt; What the Mice Tell Us&lt;lb/&gt; Mice exposed to higher doses of microplastics develop gut inflammation [11], hormone disruption [12], infertility [13], developmental delays [14], and organ damage [15]. The doses they are tested with are higher than ours… for now. But the global plastic load is increasing exponentially, and the gap is closing. &lt;lb/&gt; Humans Can’t Afford 1% of That&lt;lb/&gt; Even a fraction of the effects we induce in mice appearing in people is a global health crisis. That’s not hypothetical; our tolerance for risk is far lower than a lab rat. Mice don’t need to perform demanding physical and cognitive tasks 40 hours a week to survive. The accumulation math is also worse: mice don’t live 80 years, don’t have pregnancies lasting nine months, and don’t accumulate microplastics for decades. We do. &lt;lb/&gt; Waiting for government intervention before acting is the same mistake we made with lead, asbestos, and PFAS. Let’s not do that again. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ibbi.io/mp"/><published>2025-11-11T20:24:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45892394</id><title>Collaboration sucks</title><updated>2025-11-11T21:09:14.868784+00:00</updated><content>&lt;doc fingerprint="a369965128e686dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Collaboration sucks&lt;/head&gt;
    &lt;head rend="h3"&gt;Be the driver&lt;/head&gt;
    &lt;p&gt;“If you want to go fast, go alone; if you want to go far, go together”&lt;/p&gt;
    &lt;p&gt;This phrase will slowly kill your company and I’m here to prove it.&lt;/p&gt;
    &lt;p&gt;Imagine you are driving a car. It’s often useful to have someone give you directions, point out gas stations, and recommend stops for snacks. This is a helpful amount of collaboration.&lt;/p&gt;
    &lt;p&gt;An unhelpful amount of collaboration is getting out of your car to ask pedestrians if they like your car, swapping drivers every 10 minutes, or having someone constantly commenting on your driving.&lt;/p&gt;
    &lt;p&gt;In the first scenario, you get the right amount of feedback to get to your destination as fast as possible. In the second, you get more feedback, but it slows you down. You run the risk of not making it to the place you want to go.&lt;/p&gt;
    &lt;p&gt;The second scenario is also the one most startups (or companies, really) end up in because of ✨ collaboration ✨.&lt;/p&gt;
    &lt;head rend="h2"&gt;Being good at feedback means knowing when not to give it&lt;/head&gt;
    &lt;p&gt;As PostHog grows, I’ve seen more and more collaboration that doesn’t add value or adds far too little value for the time lost collaborating. So much so we made “collaboration sucks” the topic of the week during a recent company all hands.&lt;/p&gt;
    &lt;p&gt;“You’re the driver” is a key value for us at PostHog. We aim to hire people who are great at their jobs and get out of their way. No deadlines, minimal coordination, and no managers telling you what to do.&lt;/p&gt;
    &lt;p&gt;In return, we ask for extraordinarily high ownership and the ability to get a lot done by yourself. Marketers ship code, salespeople answer technical questions without backup, and product engineers work across the stack.&lt;/p&gt;
    &lt;p&gt;This means there is almost always someone better at what you are doing than you are. It is tempting to get them, or anybody really, involved and ✨ collaborate ✨, but collaboration forces the driver to slow down and explain stuff (background, context, their thinking).&lt;/p&gt;
    &lt;p&gt;This tendency reveals itself in a few key phrases:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;“Curious what X thinks”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“Would love to hear Y’s take on this”&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;“We should work with Z on this”&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This sometimes leads to valuable insights, but always slows the driver down. It erodes their motivation, confidence, and effectiveness, and ultimately leads us to ship less.&lt;/p&gt;
    &lt;head rend="h2"&gt;If collaboration sucks, why do people do it?&lt;/head&gt;
    &lt;p&gt;Everyone is to blame.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;People want to be helpful. For example, when someone posts their work-in-progress in Slack, others feel obliged to give feedback because we have a culture of feedback.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;On the flip side, people don’t ask for feedback from specific people because it doesn’t feel inclusive, even though it would help.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;People aren’t specific enough about what feedback they need. This creates more space for collaboration to sneak in. A discussion about building a specific feature can devolve into reevaluating the entire product roadmap if you let it.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;When someone has a good idea, the response often defaults to “let’s discuss” rather than “ok, do it.” As proof, we have 175 mentions of “let’s discuss” in Slack.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;People just want to talk about stuff because they&lt;/p&gt;&lt;del rend="overstrike"&gt;are too busy&lt;/del&gt;can’t be bothered to act on it. We drift from our ideal of a pull request to an issue/RFC to Slack (we are mostly here) to “let’s discuss”.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It’s not clear who the owner is (or no one wants to own what’s being discussed).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;It is annoying, but sometimes a single person can’t ship certain things front to back to a high-enough quality and we can’t just ship and iterate. We can fix broken code, but we can’t resend a newsletter.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How to crush collaboration (and go farther, faster)&lt;/head&gt;
    &lt;p&gt;So if collaboration is your enemy, how do you defeat it? Here’s what we say:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Default to shipping. Pull requests &amp;gt; issues &amp;gt; Slack messages.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Every time you see ✨ collaboration ✨ happening, speak up and destroy it. Say “there are too many people involved. X, you are the driver, you decide.” (This is a great way to make friends btw).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Tag who you specifically want input from and what you want from them, not just throw things out there into the void.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Prefer to give feedback after something has shipped (but before the next iteration) rather than reviewing it before it ships. Front-loading your feedback can turn it into a quasi-approval process.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;If you are a team lead, or leader of leads, who has been asked for feedback, consider being more you can just do stuff.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;When it’s your thing, you are the “informed captain.” Listen to feedback, but know it’s ultimately up to you to decide what to do, not the people giving feedback.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Unfortunately for me, not all collaboration can be rooted out, and even I will admit that some collaboration is useful. Ian and Andy edited this newsletter after all.&lt;/p&gt;
    &lt;p&gt;The point is, if you aren’t actively attempting to collaborate less, you are probably collaborating too much by default and hurting your ability to go far, fast.&lt;lb/&gt;Words by Charles Cook, who also hates sparkling water, presumably because the bubbles are too collaborative.&lt;/p&gt;
    &lt;head rend="h2"&gt;👷 Jobs at PostHog&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;AI Product Engineer working on PostHog AI, LLM Analytics or Array teams.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Backend Engineer for Feature Flags and Ingestion teams&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Influencer Wrangler on the Marketing team&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;YC Technical Onboarding Specialist on the Onboarding team (San Fran based)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ClickHouse Operations Engineer on the ClickHouse team&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;📖 More good reads&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Workflows are now in Alpha and I already broke mine – Sara Miteva&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Your data model is your destiny – Matt Brown&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Spinning Plates – Dylan Martin&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1000x: The Power of an Interface for Performance (video) – Joran Dirk Greef&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://newsletter.posthog.com/p/collaboration-sucks"/><published>2025-11-11T20:27:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45892773</id><title>Meticulous (YC S21) is hiring to redefine software dev</title><updated>2025-11-11T21:09:14.672345+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jobs.ashbyhq.com/meticulous/3197ae3d-bb26-4750-9ed7-b830f640515e"/><published>2025-11-11T21:00:35+00:00</published></entry></feed>