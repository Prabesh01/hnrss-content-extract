<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-17T17:08:53.353542+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46653721</id><title>FLUX.2 [Klein]: Towards Interactive Visual Intelligence</title><updated>2026-01-17T17:09:01.390136+00:00</updated><content>&lt;doc fingerprint="9d927013843c0b86"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FLUX.2 [klein]: Towards Interactive Visual Intelligence&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Models&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;FLUX.2 [klein]: Towards Interactive Visual Intelligence&lt;/head&gt;
    &lt;p&gt;Today, we release the FLUX.2 [klein] model family, our fastest image models to date. FLUX.2 [klein] unifies generation and editing in a single compact architecture, delivering state-of-the-art quality with end-to-end inference as low as under a second. Built for applications that require real-time image generation without sacrificing quality, and runs on consumer hardware with as little as 13GB VRAM.&lt;/p&gt;
    &lt;p&gt;Demo showing editing with FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h3"&gt;Why go [klein]?&lt;/head&gt;
    &lt;p&gt;Visual Intelligence is entering a new era. As AI agents become more capable, they need visual generation that can keep up; models that respond in real-time, iterate quickly, and run efficiently on accessible hardware.&lt;/p&gt;
    &lt;p&gt;The klein name comes from the German word for "small", reflecting both the compact model size and the minimal latency. But FLUX.2 [klein] is anything but limited. These models deliver exceptional performance in text-to-image generation, image editing and multi-reference generation, typically reserved for much larger models.&lt;/p&gt;
    &lt;head rend="h3"&gt;What's New&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sub-second inference. Generate or edit images in under 0.5s on modern hardware.&lt;/item&gt;
      &lt;item&gt;Photorealistic outputs and high diversity, especially in the base variants.&lt;/item&gt;
      &lt;item&gt;Unified generation and editing. Text-to-image, image editing, and multi-reference support in a single model while delivering frontier performance.&lt;/item&gt;
      &lt;item&gt;Runs on consumer GPUs. The 4B model fits in ~13GB VRAM (RTX 3090/4070 and above).&lt;/item&gt;
      &lt;item&gt;Developer-friendly &amp;amp; Accessible: Apache 2.0 on 4B models, open weights for 9B models. Full open weights for customization and fine-tuning.&lt;/item&gt;
      &lt;item&gt;API and open weights. Production-ready API or run locally with full weights.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: The “FLUX [dev] Non-Commercial License” has been renamed to “FLUX Non-Commercial License” and will apply to the 9B Klein models. No material changes have been made to the license.&lt;/p&gt;
    &lt;p&gt;Text to Image collage using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h3"&gt;The FLUX.2 [klein] Model Family&lt;/head&gt;
    &lt;head rend="h4"&gt;FLUX.2 [klein] 9B&lt;/head&gt;
    &lt;p&gt;Our flagship small model. Defines the Pareto frontier for quality vs. latency across text-to-image, single-reference editing, and multi-reference generation. Matches or exceeds models 5x its size - in under half a second. Built on a 9B flow model with 8B Qwen3 text embedder, step-distilled to 4 inference steps.&lt;/p&gt;
    &lt;p&gt;Combine multiple input images, blend concepts, and iterate on complex compositions - all at sub-second speed with frontier-level quality. No model this fast has ever done this well.&lt;/p&gt;
    &lt;p&gt;License: FLUX NCL&lt;/p&gt;
    &lt;p&gt;Imagine editing collage using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h4"&gt;&lt;lb/&gt;FLUX.2 [klein] 4B:&lt;/head&gt;
    &lt;p&gt;Fully open under Apache 2.0. Our most accessible model, it runs on consumer GPUs like the RTX 3090/4070. Compact but capable: supports T2I, I2I, and multi-reference at quality that punches above its size. Built for local development and edge deployment.&lt;/p&gt;
    &lt;p&gt;License: Apache 2.0&lt;/p&gt;
    &lt;head rend="h4"&gt;FLUX.2 [klein] Base 9B / 4B:&lt;/head&gt;
    &lt;p&gt;The full-capacity foundation models. Undistilled, preserving complete training signal for maximum flexibility. Ideal for fine-tuning, LoRA training, research, and custom pipelines where control matters more than speed. Higher output diversity than the distilled models.&lt;/p&gt;
    &lt;p&gt;License: 4B Base under Apache 2.0, 9B Base under FLUX NCL&lt;/p&gt;
    &lt;p&gt;Output Diversity using FLUX.2 [klein]&lt;/p&gt;
    &lt;head rend="h4"&gt;Quantized versions&lt;/head&gt;
    &lt;p&gt;We are also releasing FP8 and NVFP4 versions of all [klein] variants, developed in collaboration with NVIDIA for optimized inference on RTX GPUs. Same capabilities, smaller footprint - compatible with even more hardware.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FP8: Up to 1.6x faster, up to 40% less VRAM&lt;/item&gt;
      &lt;item&gt;NVFP4: Up to 2.7x faster, up to 55% less VRAM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Benchmarks on RTX 5080/5090, T2I at 1024×1024&lt;lb/&gt;Same licenses apply: Apache 2.0 for 4B variants, FLUX NCL for 9B.&lt;/p&gt;
    &lt;head rend="h4"&gt;&lt;lb/&gt;Performance Analysis&lt;/head&gt;
    &lt;p&gt;FLUX.2 [klein] Elo vs Latency (top) and VRAM (bottom) across Text-to-Image, Image-to-Image Single Reference, and Multi-Reference tasks. FLUX.2 [klein] matches or exceeds Qwen's quality at a fraction of the latency and VRAM, and outperforms Z-Image while supporting both text-to-image generation and (multi-reference) image editing in a unified model. The base variants trade some speed for full customizability and fine-tuning, making them better suited for research and adaptation to specific use cases. Speed is measured on a GB200 in bf16.&lt;/p&gt;
    &lt;head rend="h3"&gt;Into the New&lt;/head&gt;
    &lt;p&gt;FLUX.2 [klein] is more than a faster model. It's a step toward our vision of interactive visual intelligence. We believe the future belongs to creators and developers with AI that can see, create, and iterate in real-time. Systems that enable new categories of applications: real-time design tools, agentic visual reasoning, interactive content creation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Resources&lt;/head&gt;
    &lt;p&gt;Try it&lt;/p&gt;
    &lt;p&gt;Build with it&lt;/p&gt;
    &lt;p&gt;Learn more&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence"/><published>2026-01-16T23:46:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46655524</id><title>Counterfactual evaluation for recommendation systems</title><updated>2026-01-17T17:09:01.114161+00:00</updated><content>&lt;doc fingerprint="b472dbf60d6b017c"&gt;
  &lt;main&gt;
    &lt;p&gt;When I first started working on recommendation systems, I thought there was something weird about the way we did offline evaluation. First, we split customer interaction data into training and validation sets. Then, we train our recommenders on the training set before evaluating them on the validation set, usually on metrics such as recall, precision, and NDCG. This is similar to how we evaluate supervised machine learning models and doesn’t seem unusual at first glance.&lt;/p&gt;
    &lt;p&gt;But don’t our recommendations change how customers click or purchase? If customers can only interact with items shown to them, why do we perform offline evaluation on static historical data?&lt;/p&gt;
    &lt;p&gt;It took me a while to put a finger on it but I think this is why it felt weird: We’re treating recommendations as an observational problem when it really is an interventional problem.&lt;/p&gt;
    &lt;p&gt;Problems solved via supervised machine learning are usually observational problems. Given an observation such as product title, description, and image, we try to predict the product category. Our model learns P(category=phone|title=“…”, description=“…”, image=image01.jpeg).&lt;/p&gt;
    &lt;p&gt;On the other hand, recommendations are an interventional problem. We want to learn how different interventions (i.e., item recommendations) lead to different outcomes (i.e., clicks, purchases). By using logged customer interaction data as labels, the observational offline evaluation approach ignores the interventional nature of recommendations.&lt;/p&gt;
    &lt;p&gt;As a result, we’re not evaluating if users would click or purchase more due to our new recommendations; we’re evaluating how well the new recommendations fit logged data. Thus, what our model learns is P(view3=iphone|view1=pixel, view2=galaxy) when what we really want is P(click=True|recommend=iphone, view1=pixel, view2=galaxy).&lt;/p&gt;
    &lt;p&gt;The straightforward way to evaluate recommendations as an interventional problem is via A/B testing. Our interventions (i.e., new recommendations) are shown to users, we log their behavior attributed to our new recommendations, and then measure how metrics such as click-thru-rate and conversion change. However, it requires more effort relative to offline evaluation, experiment cycles may be long as we need enough data to make a judgement, and there’s the risk of deploying terrible experiments. Also, we may not have easy access to A/B testing we’re working on the research side of things.&lt;/p&gt;
    &lt;p&gt;The less direct approach is counterfactual evaluation. Counterfactual evaluation tries to answer “what would have happened if we show users our new recommendations instead of the existing recommendations?” This allows us to estimate the outcomes of potential A/B tests without actually running them.&lt;/p&gt;
    &lt;p&gt;The most widely known technique for counterfactual evaluation is Inverse Propensity Scoring (IPS). It’s sometimes also referred to as inverse probability weighting/sampling. The intuition behind it is that we can estimate how customer interactions will change—by reweighting how often each interaction will occur—based on how much more (or less) each item is shown by our new recommendation model. Here’s the IPS equation.&lt;/p&gt;
    &lt;p&gt;Let’s try to understand it by starting from the right. In section 1, &lt;code&gt;r&lt;/code&gt; represents the reward for an observation. This is the number of clicks or purchases or whatever metric is important to you in the logged data.&lt;/p&gt;
    &lt;p&gt;Next is the importance weight. The denominator (section 2a) represents our existing production recommender’s (&lt;code&gt;π0&lt;/code&gt;) probability of making a recommendation (aka action &lt;code&gt;a&lt;/code&gt;) given the context &lt;code&gt;x&lt;/code&gt;; the numerator (section 2b) represents the same probability but for our new recommender (&lt;code&gt;πe&lt;/code&gt;). (&lt;code&gt;π&lt;/code&gt; stands for recommendation policy.) For a user-to-item recommender, &lt;code&gt;x&lt;/code&gt; is the user; for an item-to-item recommender, &lt;code&gt;x&lt;/code&gt; is an item.&lt;/p&gt;
    &lt;p&gt;With the importance weight, we can compute how often a recommendation is made via the new model relative to the existing model. We can then use the ratio to update our logged rewards. For example, we have an old model (&lt;code&gt;π0&lt;/code&gt;) and new model (&lt;code&gt;πe&lt;/code&gt;) that recommend iPhone on the Pixel detail page, but with different probabilities:&lt;/p&gt;
    &lt;p&gt;In this scenario, the new model will recommend iPhone 0.6/0.4 = 1.5x as often as the old model. Thus, assuming a non-zero reward (i.e., the user clicked or purchased), we can reweight the logged reward to be worth 1.5x as much.&lt;/p&gt;
    &lt;p&gt;Finally, we average over our data (section 3) to get the IPS estimate (section 4) for our new recommender. This IPS estimate suggests how much reward (i.e., clicks, purchases) the new recommender would get relative to the production recommender if the new recommender was shown to users.&lt;/p&gt;
    &lt;p&gt;But how do we get the probability of making a recommendation (&lt;code&gt;a&lt;/code&gt;) given the context (&lt;code&gt;x&lt;/code&gt;)? Well, we can normalize the raw scores for each recommendation (via Plackett-Luce) to get each recommendation’s probability. Alternatively, if our recommendations are pre-computed, we can count the frequency of each recommendation in our recommendation store. My preferred approach is to use the impression count for each recommendation—I believe this is the most direct measure of the probability of making a recommendation and best adjusts for the presentation bias.&lt;/p&gt;
    &lt;p&gt;This dependence on recommendation probabilities or impressions likely explains why counterfactual evaluation isn’t more widely adopted in academic papers—most public datasets don’t include them. One exception is the Open Bandit Dataset which includes the recommendation probability (&lt;code&gt;action_prob&lt;/code&gt;) for each recommendation observation.&lt;/p&gt;
    &lt;p&gt;However, IPS has its pitfalls. One challenge is insufficient support. This happens when our new recommender being evaluated (&lt;code&gt;πe&lt;/code&gt;) makes a recommendation (&lt;code&gt;a&lt;/code&gt;) that our existing production recommender (&lt;code&gt;π0&lt;/code&gt;) didn’t make. Thus, &lt;code&gt;π0&lt;/code&gt;’s probability of &lt;code&gt;a&lt;/code&gt; is zero and we can’t compute the importance weight. We can mitigate this by deliberately showing random samples of non-recommended items on a sliver of traffic to log interactions for potential recommendations. (Spoiler: PMs might not like this.) A more palatable approach is ensure that all eligible items have a non-zero recommendation probability and then sample based on that probability. This gives all items a chance to be recommended.&lt;/p&gt;
    &lt;p&gt;IPS can also suffer from high variance when the new model (&lt;code&gt;πe&lt;/code&gt;) recommends very differently from the old model (&lt;code&gt;π0&lt;/code&gt;). Suppose &lt;code&gt;π0&lt;/code&gt; makes a recommendation (&lt;code&gt;a&lt;/code&gt;) with a probability of 0.001 and we logged a single click. If &lt;code&gt;πe&lt;/code&gt; makes the same recommendation (&lt;code&gt;a&lt;/code&gt;) with a probability of 0.1, we would reweight that single click by 100x—this is likely a severe overestimation. One solution is to ensure that the new recommenders being evaluated don’t differ too much from the production recommender, thus preventing the importance weight from exploding.&lt;/p&gt;
    &lt;p&gt;Another solution is Clipped IPS (CIPS). CIPS lets us set a maximum threshold for the importance weight. For example, if our threshold is 10, an importance weight greater than 10 is clipped to it. However, tuning the clipping parameter can be tricky.&lt;/p&gt;
    &lt;p&gt;Another approach is Self-Normalized IPS (SNIPS). SNIPS divides the IPS estimate by the importance weight. This rescaling prevents overinflated IPS estimates. Relative to CIPS, SNIPS is simpler and doesn’t require setting a parameter.&lt;/p&gt;
    &lt;p&gt;Which works better? At a recent RecSys 2021 tutorial, Yuta Saito compared various methods via experiments on synthetic data generated via Open Bandit Pipeline with 10 possible actions. He also assessed the direct method (DM) which we didn’t discuss. In a nutshell, DM trains a model to impute missing rewards. Think of it as similar to building an environment model for reinforcement learning, such as OpenAI gym or Criteo reco-gym, which we can then use to train and evaluate our RL models.&lt;/p&gt;
    &lt;p&gt;He found that IPS outperformed DM as the amount of logged data increases, and that CIPS didn’t perform much better than IPS. Overall, SNIPS performed the best (i.e., had the least error) and without the need for any parameter tuning. The tutorial goes on to discuss other estimators such as Doubly Robust (combining DM and SNIPS) as well as counterfactual learning—highly recommend checking it out.&lt;/p&gt;
    &lt;p&gt;Nonetheless, one downside of SNIPS is that it requires computing the importance weight for all observations; in IPS, we only need the importance weight for observations with non-zero reward. If we consider how most recommendations have zero reward (&amp;lt;10% CTR or conversion), SNIPS increases storage requirements of recommendation probabilities and computation of importance weights by 10x or more. That said, the authors of SNIPS found that the increase in computation is made up for via faster convergence.&lt;/p&gt;
    &lt;p&gt;Let me conclude by clarifying that I’m not suggesting for us to stop training and evaluating recsys models via the observational paradigm. Despite its limitations, it has several benefits. First, it’s an established evaluation framework with many public datasets and standard metrics. This makes it easier to compare various techniques. Second, we can collect training and evaluation data even before deploying our first recommender. Customer interaction data is generated organically when customers use our platforms. Thus, the conventional offline evaluation approach is a good place to start.&lt;/p&gt;
    &lt;p&gt;Nonetheless, if you’re keen to try a new evaluation approach, or find your offline metrics diverging from online A/B testing outcomes, consider counterfactual evaluation via SNIPS. In addition, though I’ve been discussing counterfactual evaluation in the context of recsys, it’s also applicable to other use cases where you want to simulate A/B tests offline.&lt;/p&gt;
    &lt;p&gt;Thanks to Arnab Bhadury, Vicki Boykis, and Yuta Saito for reading drafts of this.&lt;/p&gt;
    &lt;p&gt;If you found this useful, please cite this write-up as:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Yan, Ziyou. (Apr 2022). Counterfactual Evaluation for Recommendation Systems. eugeneyan.com. https://eugeneyan.com/writing/counterfactual-evaluation/.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;or&lt;/p&gt;
    &lt;code&gt;@article{yan2022counterfactual,
  title   = {Counterfactual Evaluation for Recommendation Systems},
  author  = {Yan, Ziyou},
  journal = {eugeneyan.com},
  year    = {2022},
  month   = {Apr},
  url     = {https://eugeneyan.com/writing/counterfactual-evaluation/}
}&lt;/code&gt;
    &lt;p&gt;Join 11,800+ readers getting updates on machine learning, RecSys, LLMs, and engineering.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eugeneyan.com/writing/counterfactual-evaluation/"/><published>2026-01-17T05:20:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656045</id><title>The 'untouchable hacker god' behind Finland's biggest crime</title><updated>2026-01-17T17:09:00.786872+00:00</updated><content>&lt;doc fingerprint="260593d10eb24786"&gt;
  &lt;main&gt;
    &lt;p&gt;Tiina Parikka was half-naked when she read the email. It was a Saturday in late October 2020, and Parikka had spent the morning sorting out plans for distance learning after a Covid outbreak at the school where she was headteacher. She had taken a sauna at her flat in Vantaa, just outside Finland’s capital, Helsinki, and when she came into her bedroom to get dressed, she idly checked her phone. There was a message that began with Parikka’s name and her social security number – the unique code used to identify Finnish people when they access healthcare, education and banking. “I knew then that this is not a game,” she says.&lt;/p&gt;
    &lt;p&gt;The email was in Finnish. It was jarringly polite. “We are contacting you because you have used Vastaamo’s therapy and/or psychiatric services,” it read. “Unfortunately, we have to ask you to pay to keep your personal information safe.” The sender demanded €200 in bitcoin within 24 hours, otherwise the price would go up to €500 within 48 hours. “If we still do not receive our money after this, your information will be published for everyone to see, including your name, address, phone number, social security number and detailed records containing transcripts of your conversations with Vastaamo’s therapists or psychiatrists.”&lt;/p&gt;
    &lt;p&gt;Parikka swallows hard as she relives this memory. “My heart was pounding. It was really difficult to breathe. I remember lying down on the bed and telling my spouse, ‘I think I’m going to have a heart attack.’”&lt;/p&gt;
    &lt;p&gt;Someone had hacked into Vastaamo, the company through which Parikka had accessed psychotherapy. They’d got hold of therapy notes containing her most private, intimate feelings and darkest thoughts – and they were holding them to ransom. Parikka’s mind raced as she tried to recall everything she’d confided during three years of weekly therapy sessions. How would her family react if they knew what she’d been saying? What would her students say? The sense of exposure and violation was unfathomable: “It felt like a public rape.”&lt;/p&gt;
    &lt;p&gt;Therapy had been Parikka’s lifeline. Now 62, she’d had three children by the time she was 25, including twins who had been born extremely prematurely in the 1980s, weighing only a few hundred grams each. One grew up with cerebral palsy; the other is blind. Parikka spent years juggling medical emergencies, surgeries and hospital stays with a demanding job and a crumbling marriage. “During those years, nobody ever asked me, the mother, ‘How are you?’”&lt;/p&gt;
    &lt;p&gt;She divorced in 2014 and met her current partner a year later. By then, her children were adults with independent lives. After decades of putting everyone’s else’s needs before her own, she should have been finally able to exhale. Instead, she had a breakdown. “I had full-scale anxiety running through my body all the time. I couldn’t sleep. I had panic attacks. I couldn’t eat.” Driving at high speed on the highway one day, dark thoughts descended. “I was thinking, I wouldn’t mind if this car crashed.”&lt;/p&gt;
    &lt;p&gt;In search of urgent help, she went to Google, which led her to Vastaamo, Finland’s one-stop digital shop for people in search of psychotherapy. No doctor referral was necessary. She managed to book a session for the very next day. “It was that easy.”&lt;/p&gt;
    &lt;p&gt;Being able to confide in a total stranger felt liberating. She told her therapist things she had never told another soul. “Trauma in relationships. The disappointment and tragedy of having disabled children, and the influence it had on my life,” she says. “Silly things, childish things. It’s very human to feel hate, anger, rage.”&lt;/p&gt;
    &lt;p&gt;After Parikka read the email that left her struggling to breathe, she had no idea where to turn for help. She rang the emergency services, but the police told her to get off the line; they needed to keep it free for real emergencies. In her bathrobe, her phone still in her hand, she felt utterly alone.&lt;/p&gt;
    &lt;p&gt;But Parikka was far from alone. Across Finland, 33,000 people who had used Vastaamo were discovering that a hacker had got hold of their therapy notes and was holding them to ransom. These were people who, by definition, were likely to be vulnerable, in need of help. Each was experiencing a very personal, individual terror. In a country of only 5.6 million people, everyone knows someone who was hacked.&lt;/p&gt;
    &lt;p&gt;Some victims’ notes had already been cherrypicked for the world to see. Three days before the extortion emails were sent, someone using the handle ransom_man had left posts on the dark web, on r/Suomi, the Finnish-language subreddit, and on Ylilauta, Finland’s equivalent to 4chan. This time, the post was in English. “Hello Finnish Colleagues,” it began. “We have hacked the psychotherapy clinic vastaamo.fi and taken tens of thousands of patient records including extremely sensitive session notes and social security numbers. We requested a small payment of 40 bitcoins (nothing for a company with yearly revenues close to 20 million euros) but the CEO has stopped responding to our emails. We are now starting to gradually release their patient records, 100 entries every day.”&lt;/p&gt;
    &lt;p&gt;There was a link to the dark web, where 100 records were already on display. Directly below it, ransom_man had signed off the post with a single word: “Enjoy!”&lt;/p&gt;
    &lt;p&gt;The 100 records included those of politicians, police officers and prominent public figures. Their names appeared alongside therapy notes that contained details of adultery, suicide attempts, paedophilia and sexual violence. Some of the records belonged to children. And whoever was behind the hack was true to their word: the next day, 100 more patient records were uploaded.&lt;/p&gt;
    &lt;p&gt;Some victims went searching on the dark web in a desperate attempt to see if their records were out there. Some paid the ransom, scrabbling to get hold of bitcoin while the clock ticked down. Lawyers representing the victims have told me they know of at least two cases where people took their own lives after they discovered their therapy notes had been hacked.&lt;/p&gt;
    &lt;p&gt;But for all of them, it was already too late. At 2am on 23 October 2020 – the day before the emails began to arrive in tens of thousands of inboxes – ransom_man had uploaded a much larger file. It contained every record of every single patient on Vastaamo’s database. Everyone’s therapy notes had already been published, for free, for everyone in the world to see.&lt;/p&gt;
    &lt;p&gt;Who was behind the biggest crime Finland had ever known? And might they have been motivated by something other than money? I have spent 18 months trying to answer these questions, following threads across Europe and the US. They culminated in a visit to a prison, and one of the most chilling conversations I have ever had.&lt;/p&gt;
    &lt;p&gt;Finland has been ranked the happiest country on Earth by the UN for the last eight years in a row. A world leader in childcare and education, Finland is also famously hi-tech: it’s the most digitalised country in Europe, renowned for its communications sector (as the home of Nokia) and leading the way when it comes to cybersecurity and AI innovation. But Finland is also a place of extremes. It has more heavy metal bands per capita than any other nation. In the far north, for the few days around the winter solstice, the sun does not rise.&lt;/p&gt;
    &lt;p&gt;Vastaamo had long been considered an example of how Finland was getting it right when it came to digital tech. Founded in 2008 by entrepreneur Ville Tapio and his mother, Nina, a psychotherapist, the aim was to open up therapy to the masses, removing the stigma of asking for help. The platform made it easy for people to see who was free, where, and what therapeutic approach they specialised in. The logo had the colour palette of a first-aid kit, with white lettering in a green speech bubble. Vastaamo means “a place for answers”.&lt;/p&gt;
    &lt;p&gt;It was an attractive platform for therapists, too: they didn’t have to worry about marketing or billing – Vastaamo would take care of all of that. The company even provided a behind-the-scenes digital interface where therapists could make and store their notes. This formula, combined with the increasing demand for therapy services, meant Vastaamo grew fast. It opened its own network of around 20 clinics across Finland, employing more than 220 psychotherapists by 2018, leading some in Finland to refer to it as “the McDonald’s of therapy”. In the years before Zoom and Teams were part of our daily lives, the remote therapy also offered by Vastaamo was groundbreaking. In 2019, a private equity firm bought a majority stake in the company, earning the Tapio family a payout of more than €5m.&lt;/p&gt;
    &lt;p&gt;Meri-Tuuli Auer, 30, describes using Vastaamo as “like Uber for therapy – convenient, accessible, relatively cheap”. She picked her therapist because he offered cognitive psychotherapy – and she liked his photo. “He looked nice. He looked approachable.”&lt;/p&gt;
    &lt;p&gt;Auer’s home, on the outskirts of Helsinki, is a riot of pink. There are Barbie dolls, Barbie books and Barbie-themed handbags on her shelves, as well as a glittery open-top Barbie sports car. A pole-dancing pole takes pride of place in the centre of her living room.&lt;/p&gt;
    &lt;p&gt;“I’m a mixed personality,” she tells me over tea in Moomin mugs. “I love being around people, but I get that inkling, that doubt: maybe they all think I’m full of shit and stupid and ugly and I have no idea what I’m doing.” Auer has struggled with depression for much of her life. When she was 18, she was in a secretive, difficult relationship with a man 29 years her senior, which made her self-esteem plummet further. She was drinking heavily. “If I hadn’t gone to therapy, I don’t know what would have become of me. Maybe there is another universe where I didn’t make it to 30.”&lt;/p&gt;
    &lt;p&gt;Most of the cost of Auer’s treatment was covered by the Finnish healthcare system; she paid only about €25 for each weekly session. She was making great strides. “After going to therapy in 2018 and 2019, I had gained a basic sense of security. That was lost in 2020.”&lt;/p&gt;
    &lt;p&gt;Vastaamo’s CEO knew the company’s patient registry was being held to ransom weeks before his customers found out. On 28 September 2020, Ville Tapio received an email demanding the bitcoin equivalent of €450,000 to keep it safe. Sample patient records attached to the email proved the extortionist wasn’t bluffing. Tapio called in a cybersecurity firm to investigate.&lt;/p&gt;
    &lt;p&gt;Medical information is an obvious target for would-be extortionists, says Antti Kurittu, the security specialist Tapio hired. But this was something else: “Whatever I tell a therapist is, by its very nature, a lot more private than what my blood pressure is,” he says, drily.&lt;/p&gt;
    &lt;p&gt;Kurittu used to be a detective, investigating cybercrimes for the Finnish police; he says he insisted they be told about the ransom attempt so they could begin a parallel investigation. Meanwhile, he began inspecting Vastaamo’s server, looking for clues as to who might be behind the hack – and one of the first things he noticed was how lax security had been. “It was definitely unfit for purpose for storing this kind of information,” he says. He tells me that the patient records database was accessible via the internet; there was no firewall and, perhaps most egregiously, it was secured with a blank password, so anyone could just press enter and open it. Kurittu determined that whoever had hacked Vastaamo had probably just been scanning the internet in search of any badly secured databases that could be monetised. “They tried a bunch of bank vaults to see which ones were open, and just happened to stumble on this one.”&lt;/p&gt;
    &lt;p&gt;For a few weeks, the hacker and Vastaamo exchanged emails, but there was no question that Vastaamo would pay the ransom. If they did, they’d have to trust a criminal’s word that the records had been destroyed – plus, Kurittu says, it goes against the national character. “Finns are a bit of a belligerent bunch. We’re not known for paying ransom quietly or easily, which I take great national pride in.”&lt;/p&gt;
    &lt;p&gt;After ransom_man started leaking patient records to put pressure on the company, Kurittu kept a close eye on the server being used to publish them. He had a hunch whoever was behind this was either Finnish, or had lived in Finland for a long time: they knew which famous names to flaunt from the patient records.&lt;/p&gt;
    &lt;p&gt;When Auer learned about the hack, she downloaded a browser that would enable her to access the dark web, for the first time in her life. “I was thinking to myself, I just have to see if my records are there.” She found her name wasn’t among the first batch posted, and closed the file without reading anyone’s records. But she saw other people discussing what they’d seen. “People had already picked – in their opinion – the funniest parts from the patient records. They were laughing at these people’s misery. A 10-year-old child had gone to therapy, and people found it funny.”&lt;/p&gt;
    &lt;p&gt;Auer began to spiral. “I closed myself in at home, I didn’t want to leave, I didn’t want anyone to see me,” she tells me. She had no hope that the hacker would ever be found. “It’s not that I don’t trust the police in Finland – it’s just that it seemed like an impossible task.”&lt;/p&gt;
    &lt;p&gt;But the much larger file ransom_man had uploaded to the dark web – the one that contained every single one of Vastaamo’s patient records – also included vital clues to his identity. The first three batches of therapy notes had been posted manually, but when the hacker had tried to automate the process, he had not only accidentally uploaded all of the therapy notes, but also his entire home folder. It had appeared only briefly before it was taken down, along with a post that read “whoopsie :D”, but ransom_man had screwed up.&lt;/p&gt;
    &lt;p&gt;“After spending several evenings with the file, I had the feeling I’d seen this kind of thing before,” Kurittu says. The data on the hacker’s home drive wasn’t systematically organised and arranged in folders, as you would expect from someone for whom extortion was a business. “It had that sort of chaotic, passionate hobby feeling to it.” And there was something about the childish way ransom_man had named some of the files that was eerily familiar (the one containing all the patient data was entitled “therapissed”).&lt;/p&gt;
    &lt;p&gt;Kurittu’s mind went back to 2013 when he was a senior detective constable for the Helsinki police, and the file names he’d seen on a computer he’d seized from a 16-year-old boy. “It made me think of Julius Kivimäki.”&lt;/p&gt;
    &lt;p&gt;Aleksanteri Kivimäki – who used to go by his middle name, Julius, or the online handle zeekill – had long been notorious among cybersecurity investigators. Not because of any particular talent as a hacker, but because he seemed prepared to go further than most who spend their time in the darkest parts of the internet.&lt;/p&gt;
    &lt;p&gt;Aged 14, Kivimäki was involved with a group called Hack the Planet (named after the tagline of the 1995 movie Hackers). They would break into big companies and show off what they had managed to steal online. “It was for the LOLs,” says Blair Strater, a former hacker from Illinois who hung out with Kivimäki in internet relay chat forums at that time. “You notice that something is open and you just take it. It’s not targeted.”&lt;/p&gt;
    &lt;p&gt;This kind of hacking was about impressing others – winning online clout, not extorting money. But some of those involved may have felt they were also serving a noble purpose: exposing security vulnerabilities in major corporations, or the hypocrisy of cybersecurity firms who claimed to be qualified to advise businesses while being unable to secure their own network.&lt;/p&gt;
    &lt;p&gt;Strater found Kivimäki amusing, at first. “A lot of the things he did early on were objectively funny,” he tells me over Zoom from his home in Illinois. When I ask Strater whether I would find them funny, he clarifies that his humour was an acquired taste best suited to 4chan. But in 2010, when Strater was 17 and Kivimäki was 14, they fell out over which one of them was going to publish a report of a recent hack.&lt;/p&gt;
    &lt;p&gt;Orders of pizzas and Chinese takeaway began arriving at the home Strater shared with his parents and younger sister on the outskirts of Chicago; when they opened the door, the delivery driver would ask for Julius Kivimäki. “Taxis were ordered. Hookers were ordered,” Strater says. “My father had to send away a big dump truck filled with gravel.” Strater received a blizzard of letters from credit card and insurance companies, and government agencies, including one from the department of social security confirming that an appointment with the welfare office had been created for him and his spouse – Julius Kivimäki.&lt;/p&gt;
    &lt;p&gt;Then, at 2am one morning, police in body armour carrying guns with laser sights turned up outside the Straters’ home, responding to reports that Blair had beaten his mother to death in a drug-fuelled rage. When she answered the door, they took her blood pressure to verify that she was, in fact, alive. It was the first of dozens of so-called swatting attacks the family would endure. After a lull of a couple of months, Strater learned that someone using his name had emailed a bomb threat to a local police officer; it led to Strater spending three weeks over Christmas in a juvenile detention centre.&lt;/p&gt;
    &lt;p&gt;Several years into their feud, in 2015, someone hacked Elon Musk and Tesla’s Twitter accounts, and tweeted that anyone who rang the Straters’ landline or showed up at their home would get a free car; their phone rang off the hook for days, and Blair’s father had to turn several disappointed people away from their porch. Someone using Blair’s mother’s name posted a threat to shoot up the elementary school where his 10-year-old sister was a pupil. His mother’s LinkedIn and Twitter accounts were hacked and filled with juvenile, racist posts, as well as antisemitic insults directed at the company where she worked as a healthcare statistician. Within months, she had lost her job.&lt;/p&gt;
    &lt;p&gt;The campaign of terror lasted for many more years. Strater says it’s never going to be fully over. “It’s like having cancer: it’s never really cured, it goes into remission,” he says. “Every so often, someone would hit me up and say, ‘Hey, I was one of the people that helped Julius do these things.’ Sometimes they would say, ‘He made me do them. He was blackmailing me,’ which is something he does to an awful lot of people. I want to make this very clear: I am not the person zeekill fucked with the most.”&lt;/p&gt;
    &lt;p&gt;Indeed, Kivimäki set his sights far beyond the Strater family. In August 2014 – days after his 17th birthday – he rang in a fake bomb threat that grounded a flight carrying John Smedley, president of Sony Online Entertainment, who oversaw PlayStation’s multiplayer network. A group calling themselves Lizard Squad claimed responsibility, posting almost nonsensically on Twitter that the attack was in sympathy with Islamic State. Lizard Squad struck again, on 25 December 2014, with a cyber-attack that shut down Xbox and PlayStation, and ruined Christmas morning for millions. Brazenly, Kivimäki gave interviews to BBC 5 Live and Sky News as a Lizard Squad spokesperson, claiming they did the hack both to amuse themselves and to expose Microsoft and Sony’s poor cybersecurity. He seemed to revel in the chaos and drama. He appeared on camera on Sky News; he used a fake name, but his boyish face – blond hair, blue eyes, plump cheeks – was visible for all to see.&lt;/p&gt;
    &lt;p&gt;In July 2015, following Kurittu’s investigation with the Finnish police, Kivimäki was convicted of hacking into servers at MIT and Harvard universities, as well as money laundering and fraud. He was found guilty of more than 50,000 data breaches, and received a two-year suspended sentence; he had his computer confiscated and was forced to pay back more than €6,000 obtained through his crimes. He never faced justice for any of the offences he perpetrated against Blair Strater and his family.&lt;/p&gt;
    &lt;p&gt;Shortly after he received his suspended sentence, Kivimäki updated his Twitter bio to read “untouchable hacker god”.&lt;/p&gt;
    &lt;p&gt;Kivimäki spent the next few years travelling the world. During lockdown, he lived in an air-conditioned apartment in Westminster, 20 metres away from the central London headquarters of MI5. There were trips to Dubai, Hong Kong, Barcelona and Paris. According to the images of himself he liked to post online, he was living the life of an international jetsetter. But he was not, in the end, untouchable.&lt;/p&gt;
    &lt;p&gt;Police made a micropayment of 0.1 bitcoins to ransom_man. They were able to determine that, when it was laundered into real-world currency, it was transferred into Kivimäki’s bank account. The home folder ransom_man had accidentally uploaded had led the police to some servers, one of which had been paid for using a credit card linked to him – the same one he’d been using to pay for Apple services and an OnlyFans subscription.&lt;/p&gt;
    &lt;p&gt;As investigators traced the history on ransom_man’s home folder, they were able to determine that, as well as looking for keywords such as rape, abuse and child molestation in the database of patient records, the hacker had also searched for Kivimäki’s home address, and the names of his family members. “Before publication, he ensured there was no harmful information about him, or people close to him,” Pasi Vainio, the lead prosecutor on the case, tells me. Those searches took place using an IP address linked to Kivimäki’s Westminster apartment. “He was in London when the crimes were committed.”&lt;/p&gt;
    &lt;p&gt;But it was a drawn-out, arduous investigation. There were terabytes of data to comb through. The crime had so many victims that the police had to create an online portal for everyone to register and give their statements. That generated more than 21,000 criminal reports, all of which needed to be looked at individually. So it was October 2022 – two years after Parikka, Auer and the other victims had received their ransom demands – before Vainio signed an arrest warrant for Kivimäki. His face – chubby-cheeked and floppy-haired – was added to Europol’s list of most-wanted fugitives, alongside murderers and drug traffickers.&lt;/p&gt;
    &lt;p&gt;On 3 February 2023, French police were alerted to a report of domestic violence taking place in a flat in a Paris suburb. Officers used a battering ram to enter the property and found a man and a woman inside. The man was pale and white-blond, but when asked to identify himself he handed over a Romanian passport that gave his name as Asan Amet. “We have a Scandinavian-looking guy, 195cm tall,” Vainio tells me with a smile. “I think the French police just thought something’s off.” They searched their databases and discovered Amet was one of Kivimäki’s known aliases. He was handed over to the Finnish authorities a few weeks later.&lt;/p&gt;
    &lt;p&gt;“I don’t know what I had expected, but I was surprised to see that he looked so normal,” Auer says. “He looks like a regular Finnish young man. It did make me feel like it could have been anyone.”&lt;/p&gt;
    &lt;p&gt;“I had heard that he was in a court hearing,” Parikka says. “We have a habit – every night at 8.30pm, I’ll lie here on the couch with my spouse and watch the main news. Without warning, Kivimäki was there on the screen. Kivimäki came to my living room.” She glances over to her couch, metres away from where we sit, and is overcome with tears. “I didn’t sleep the next night.”&lt;/p&gt;
    &lt;p&gt;But when the trial began, in November 2023, Parikka was determined to watch Kivimäki face justice. The logistics of inviting more than 21,000 registered victims to court were impossible; instead, proceedings were relayed to public spaces such as cinemas so that the plaintiffs could watch in real time. In a case that was all about the right to privacy and anonymity, it sounds a profoundly awkward setup. “We were all sitting far away from each other,” Auer says. “It was dead silent.” Parikka had a similar experience. “We pretty much kept to ourselves.”&lt;/p&gt;
    &lt;p&gt;On 30 April 2024, Kivimäki was found guilty of all charges – including 9,600 counts of aggravated invasion of privacy and more than 21,300 counts of attempted aggravated extortion – and sentenced to six years and three months in prison: a long stretch by Finnish standards, but shy of the seven-year maximum he could have received. His appeal against his sentence is currently under way.&lt;/p&gt;
    &lt;p&gt;Even if his conviction is upheld, he will be a free man by the end of this year.&lt;/p&gt;
    &lt;p&gt;“The sentencing scale is too low, in my opinion. But that’s the framework we have in Finland,” Vainio says. He tells me a colleague has tried to quantify the harm caused, using the conservative estimate that each person had endured a week of agony as a result of the hack. “When you multiply it with the number of victims of this case, you would have 635 years of suffering.”&lt;/p&gt;
    &lt;p&gt;Now 28, Kivimäki has served much of his sentence in a spotless, bright but suitably austere facility in Turku, south-west Finland, a two-hour train ride from Helsinki. For months, he had refused to grant me an interview, but while I am in Finland reporting this story, he changes his mind. As I sit in silence in the prison’s visitor room for what feels like hours, watching the clock tick down behind a panel of reinforced glass, I wonder if Kivimäki is trolling me; if he has dragged me over here simply to derail the other interviews I already had scheduled, with no intention of ever leaving his cell. But after 40 minutes he appears. With his white-blond hair, ice-blue eyes and razor burn, and dressed in a black T-shirt and shorts, he looks like an overgrown teenage boy.&lt;/p&gt;
    &lt;p&gt;He didn’t do it, he says; he’s simply a victim of his own notoriety. “They had to find somebody. They just chose somebody who was convenient for the story.” When I point out that there’s an enormous amount of circumstantial evidence linking him to the hack, Kivimäki is defiant. “The obvious answer is that it’s just somebody close to me.” He has an idea who it is, he continues, but he isn’t prepared to name names.&lt;/p&gt;
    &lt;p&gt;It seems very selfless to do time for someone else’s crime, I say. I tell him Parikka says having her therapy notes held to ransom felt like a public rape. “I’m sure that’s how she felt,” he replies, blankly. “It’s quite remote to me. I’m involved, in that I was in court over this stuff, but I didn’t do it. It’s another story in the news.”&lt;/p&gt;
    &lt;p&gt;As a fellow human being rather than the person convicted of the crime, I ask, what’s your response to people taking their lives after having their therapy notes stolen? “There’s a lot of terrible things going on in the world. I don’t really feel any differently about this. I turn on the news and there’s people dying in Gaza or wherever. It’s like, how do you feel about that? I think the honest answer for most people is that they just … don’t.” You don’t have anything to say to the victims? “Not really,” he replies. “These are nameless, faceless people.”&lt;/p&gt;
    &lt;p&gt;“There’s been just one question that I would ask Kivimäki,” Parikka says. “That would be: ‘Was there ever such a moment that you felt empathy?’ I don’t think he’s able to put himself into anybody else’s situation.” She pauses. “I think that he really needs therapy.”&lt;/p&gt;
    &lt;p&gt;Vastaamo was declared bankrupt in February 2021. Days after patients received the ransom emails, the board announced that it had let the CEO, Ville Tapio, go. In April 2023, Tapio was found guilty of criminal negligence in his handling of patient data. His conviction was overturned on appeal in December 2025. (He declined my requests to interview him.)&lt;/p&gt;
    &lt;p&gt;“I have actually been more angry towards Ville Tapio than I have been towards Kivimäki,” Auer says. “As CEO of the company, he had the responsibility to make sure that it was prepared for all kinds of risks, and that they had sufficient information security. It seems like it was never a priority to him.” What was his priority? “Making money. He ran a very successful business.”&lt;/p&gt;
    &lt;p&gt;“I believe that originally the Tapios were wanting to help people and make therapy available,” Parikka says. “There are now maybe thousands of people who will never use therapy again, because they can never trust. And that’s really bad.”&lt;/p&gt;
    &lt;p&gt;Alongside more than 6,000 other plaintiffs, Auer and Parikka are part of a civil case suing Kivimäki for damages. Despite the lifestyle he projects online, he claims not to have the funds to pay damages; so far, no one has been able to find his assets. The government has agreed to pay compensation to victims – anything from a few hundred euros to a few thousand, depending on how many pages of their therapy notes Vastaamo had in its database, and how sensitive the information contained in those pages was – but the sum is likely to be symbolic. How can you ever repay the damage of being exposed in this way?&lt;/p&gt;
    &lt;p&gt;Copies of the patient files have been circulating ever since they were first released in October 2020. At one point, someone created a special search engine for browsing the database. This doesn’t surprise Parikka. “Kivimäki isn’t just one of a kind,” she says. “I know human curiosity. People want to know.”&lt;/p&gt;
    &lt;p&gt;Other people are as prepared as Kivimäki was to break moral and legal boundaries – for money, for online clout, out of ghoulish curiosity or simply for the LOLs. In May, Finnish police announced that there was a second suspect in the Vastaamo case, a US citizen living in Estonia – suspected of aiding and abetting Kivimäki, helping prepare the files. He has been charged with assisting in the attempted extortion.&lt;/p&gt;
    &lt;p&gt;In an era when AI models are trained on our Zoom conversations, emails and status updates, it is naive to believe that anything can ever be fully secure. The human need to confide in others can be met in an extraordinary range of ways in the digital age. In a world of unparalleled connectivity, can our innermost secrets ever be truly safe?&lt;/p&gt;
    &lt;p&gt;Kivimäki thinks we are all clinging on to analogue expectations about privacy in a digital world. “So many of our worst secrets – I mean worst of worst, things we might really, really not want to share with the entire world – they exist online. They’ll exist in the database of some company you used,” he tells me. “Everybody’s photos, everybody’s text-messaging histories.” He fixes me with his eyes. “You fundamentally want to believe in this privacy. But, on the other hand, I don’t know how you’re going to get there.”&lt;/p&gt;
    &lt;p&gt;Intrigue: Ransom Man, Jenny Kleeman’s six-part series for BBC Radio 4, is available now on BBC Sounds.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/technology/2026/jan/17/vastaamo-hack-finland-therapy-notes"/><published>2026-01-17T07:29:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656358</id><title>Show HN: Streaming gigabyte medical images from S3 without downloading them</title><updated>2026-01-17T17:09:00.228064+00:00</updated><content>&lt;doc fingerprint="286db0183daf5dc5"&gt;
  &lt;main&gt;
    &lt;p&gt;A modern, cloud-native tile server for Whole Slide Images. One command to start serving tiles directly from S3.&lt;/p&gt;
    &lt;code&gt;# Installation (requires Rust, see alternatives below)
cargo install wsi-streamer

# On your local machine
wsi-streamer s3://my-slides-bucket --s3-region eu-west-3&lt;/code&gt;
    &lt;p&gt;That's it. No configuration files, no local storage, no complex setup. Open &lt;code&gt;http://localhost:3000/view/sample.svs&lt;/code&gt; in your browser to view a slide.&lt;/p&gt;
    &lt;p&gt;Whole Slide Images are large (1-3GB+) and typically live in object storage. Traditional viewers require downloading entire files before serving a single tile. WSIStreamer takes a different approach: it understands slide formats natively, fetches only the bytes needed via HTTP range requests, and returns JPEG tiles immediately.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Range-based streaming — fetches only the bytes needed for each tile, no local files&lt;/item&gt;
      &lt;item&gt;Built-in viewer — OpenSeadragon-based web viewer with pan, zoom, and dark theme&lt;/item&gt;
      &lt;item&gt;Native format support — Rust parsers for Aperio SVS and pyramidal TIFF&lt;/item&gt;
      &lt;item&gt;Production-ready — HMAC-SHA256 signed URL authentication&lt;/item&gt;
      &lt;item&gt;Multi-level caching — slides, blocks, and encoded tiles&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Install from crates.io:&lt;/p&gt;
    &lt;code&gt;cargo install wsi-streamer&lt;/code&gt;
    &lt;p&gt;Or build from source:&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/PABannier/WSIStreamer.git
cd WSIStreamer
cargo build --release&lt;/code&gt;
    &lt;p&gt;Or run with Docker:&lt;/p&gt;
    &lt;code&gt;# Pull from GitHub Container Registry
docker run -p 3000:3000 -e WSI_S3_BUCKET=my-bucket ghcr.io/pabannier/wsistreamer:latest

# Or use Docker Compose for local development with MinIO
docker compose up --build&lt;/code&gt;
    &lt;code&gt;# Serve slides from S3
wsi-streamer s3://my-slides

# Custom port
wsi-streamer s3://my-slides --port 8080

# S3-compatible storage (MinIO, etc.)
wsi-streamer s3://slides --s3-endpoint http://localhost:9000&lt;/code&gt;
    &lt;code&gt;# List slides
curl http://localhost:3000/slides

# Get slide metadata
curl http://localhost:3000/slides/sample.svs

# Fetch a tile (level 0, position 0,0)
curl http://localhost:3000/tiles/sample.svs/0/0/0.jpg -o tile.jpg

# Get thumbnail
curl "http://localhost:3000/slides/sample.svs/thumbnail?max_size=256" -o thumb.jpg&lt;/code&gt;
    &lt;code&gt;# Enable HMAC-SHA256 authentication
wsi-streamer s3://my-slides --auth-enabled --auth-secret "$SECRET"

# Generate signed URLs
wsi-streamer sign --path /tiles/slide.svs/0/0/0.jpg --secret "$SECRET" --base-url http://localhost:3000&lt;/code&gt;
    &lt;p&gt;The web viewer handles authentication automatically when enabled.&lt;/p&gt;
    &lt;code&gt;# Check S3 connectivity
wsi-streamer check s3://my-slides

# List available slides
wsi-streamer check s3://my-slides --list-slides

# Test a specific slide
wsi-streamer check s3://my-slides --test-slide sample.svs&lt;/code&gt;
    &lt;p&gt;All options can be set via CLI flags or environment variables:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Env Var&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--host&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_HOST&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;0.0.0.0&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Bind address&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--port&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_PORT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;3000&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;HTTP port&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-bucket&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_BUCKET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;S3 bucket name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-endpoint&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_ENDPOINT&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;Custom S3 endpoint&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--s3-region&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_S3_REGION&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;us-east-1&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;AWS region&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--auth-enabled&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_AUTH_ENABLED&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;false&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Enable authentication&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--auth-secret&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_AUTH_SECRET&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;—&lt;/cell&gt;
        &lt;cell&gt;HMAC secret key&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--cache-slides&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CACHE_SLIDES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Max slides in cache&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--cache-tiles&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CACHE_TILES&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;100MB&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Tile cache size&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--jpeg-quality&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_JPEG_QUALITY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;80&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JPEG quality (1-100)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--cors-origins&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;WSI_CORS_ORIGINS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;any&lt;/cell&gt;
        &lt;cell&gt;Allowed CORS origins&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;wsi-streamer --help&lt;/code&gt; for full details.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Endpoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /health&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Health check&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /view/{slide_id}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Web viewer&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /tiles/{slide_id}/{level}/{x}/{y}.jpg&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Fetch tile&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List slides&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Slide metadata&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}/thumbnail&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Thumbnail&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;GET /slides/{slide_id}/dzi&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;DZI descriptor&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See API_SPECIFICATIONS.md for complete documentation.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Format&lt;/cell&gt;
        &lt;cell role="head"&gt;Extensions&lt;/cell&gt;
        &lt;cell role="head"&gt;Compression&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Aperio SVS&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;.svs&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JPEG, JPEG 2000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pyramidal TIFF&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;.tif&lt;/code&gt;, &lt;code&gt;.tiff&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;JPEG, JPEG 2000&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Files must be tiled (not stripped) and pyramidal.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;January 17th, 2026: front page of Hacker News and Rust subreddit&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT. See LICENSE.&lt;/p&gt;
    &lt;p&gt;Issues and pull requests welcome. See CONTRIBUTING.md.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/PABannier/WSIStreamer"/><published>2026-01-17T08:46:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656552</id><title>ClickHouse acquires Langfuse</title><updated>2026-01-17T17:09:00.011271+00:00</updated><content>&lt;doc fingerprint="2bee90517ddf277e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Langfuse joins ClickHouse&lt;/head&gt;
    &lt;p&gt;Our goal continues to be building the best LLM engineering platform&lt;/p&gt;
    &lt;p&gt;ClickHouse has acquired Langfuse.&lt;/p&gt;
    &lt;p&gt;If you’re reading this as a Langfuse user, your first question is probably: What does this mean for me?&lt;/p&gt;
    &lt;p&gt;Our roadmap stays the same, our goal continues to be building the best LLM engineering platform, and we remain committed to open source and self-hosting. There are no immediate changes to how you use Langfuse and how you can reach out to us.&lt;/p&gt;
    &lt;p&gt;What does change is our ability to move faster. With ClickHouse behind us, we can invest more deeply into performance, reliability, and our roadmap that helps teams build and improve AI applications in production.&lt;/p&gt;
    &lt;head rend="h2"&gt;What stays the same&lt;/head&gt;
    &lt;p&gt;This is the section we would want to read first, too.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Langfuse stays open source and self‑hostable. There are no planned changes to licensing. As you know, we leaned heavily into OSS over the last years.&lt;/item&gt;
      &lt;item&gt;Langfuse Cloud keeps running as‑is. Same product, same endpoints, same experience.&lt;/item&gt;
      &lt;item&gt;Support stays the same. Same channels, same SLAs for existing customers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What gets better now&lt;/head&gt;
    &lt;p&gt;Joining Clickhouse compresses years of operational learning into immediate, real customer benefits.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;More engineering leverage on the hardest parts. Langfuse is a data‑intensive product. Working closely with the ClickHouse engineering team helps us push performance and reliability.&lt;/item&gt;
      &lt;item&gt;Faster progress on enhanced enterprise-grade compliance and security, with the help of Clickhouse’s resources.&lt;/item&gt;
      &lt;item&gt;Learning from Clickhouse’s customer success and support playbook. This puts us years ahead and allows us to spend more time on what we really care about: our users.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;A quick look back&lt;/head&gt;
    &lt;p&gt;The longer version of how we got here is in our handbook.&lt;/p&gt;
    &lt;p&gt;Langfuse started the same way many LLM products start: we were building agents ourselves. And we constantly ran into the same problems.&lt;/p&gt;
    &lt;p&gt;Building LLM apps is easy to demo and hard to run in production. Debugging is different, quality is non‑deterministic, and the iteration loop is messy. When we did Y Combinator in early 2023, we saw this every week, both in our own projects and in what other founders in our cohort were working on.&lt;/p&gt;
    &lt;p&gt;So we built a duct tape version of what we wished existed: tracing and evaluation primitives that are easy to add, easy to self‑host, and actually useful for iterating.&lt;/p&gt;
    &lt;p&gt;The very first version was intentionally simple. It ran on Postgres, because speed of shipping mattered more than theoretical scaling. That got us to a real product and a real community fast.&lt;/p&gt;
    &lt;p&gt;Then people actually started to use the product more than we could have imagined.&lt;/p&gt;
    &lt;p&gt;As adoption grew, Postgres became the bottleneck for the workloads Langfuse needed to support (high‑throughput ingestion + fast analytical reads). With Langfuse v3, we switched the core data layer to ClickHouse to make Langfuse scale for production workloads, both in Cloud and self‑hosted deployments.&lt;/p&gt;
    &lt;p&gt;And if you like infrastructure deep dives, here’s the v3 migration write‑up.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why join ClickHouse&lt;/head&gt;
    &lt;p&gt;There are a lot of ways this could have gone. We didn’t plan to sell the company. Actually, we had Term Sheets for a great Series A and were looking forward to some days off over Christmas after an intense year.&lt;/p&gt;
    &lt;p&gt;What changed wasn’t our conviction in Langfuse, it was realizing how much faster we can go together with ClickHouse, while staying true to what makes Langfuse work: open source, self-hosting, and a product that’s built for real production workloads.&lt;/p&gt;
    &lt;head rend="h3"&gt;A shared history (before the acquisition)&lt;/head&gt;
    &lt;p&gt;This dialogue didn’t start with a term sheet. Because Langfuse runs on ClickHouse, we naturally ended up collaborating early and often.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;We’ve always been closely in touch with many teams at ClickHouse: sharing feedback with the database team, and using new features to make Langfuse more reliable. For example, compute-compute separation helps us to reduce the risk of noisy-neighbours on Langfuse Cloud.&lt;/item&gt;
      &lt;item&gt;Langfuse Cloud is a large customer of ClickHouse Cloud.&lt;/item&gt;
      &lt;item&gt;Teams at ClickHouse use Langfuse to improve their agentic applications.&lt;/item&gt;
      &lt;item&gt;We invested heavily in ClickHouse-backed self-hosting: documentation, templates, and deployment patterns, and collaborated closely with ClickHouse on improving that experience.&lt;/item&gt;
      &lt;item&gt;As a result, Langfuse introduced thousands of teams to ClickHouse when upgrading from Langfuse v2 to v3.&lt;/item&gt;
      &lt;item&gt;We’ve done community meetups together: a ClickHouse meetup at our Berlin office, another one in San Francisco, and an OpenHouse talk in Amsterdam.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Langfuse runs on ClickHouse, ClickHouse uses Langfuse to optimize its agentic products, we share lots of customers and OSS deployments; that gives ClickHouse every incentive to keep Langfuse fast, reliable, and boringly dependable at scale.&lt;/p&gt;
    &lt;p&gt;So in many ways, we operated like long-term partners. This acquisition is a way to make that partnership permanent — and invest aggressively together.&lt;/p&gt;
    &lt;p&gt;Max shared on how we use ClickHouse to keep product performance ahead of demand at ClickHouse Open House (recording) in Amsterdam.&lt;/p&gt;
    &lt;head rend="h3"&gt;Culture and engineering fit&lt;/head&gt;
    &lt;p&gt;The first time we met Aaron, Yury, Alexey, Tanya, Ryadh, and Pete in-person ended up in a long lunch in Amsterdam. It became obvious we share a similar view on building great developer tooling, how that drives everything within our companies, and how fast analytics is increasingly foundational for building and optimizing agentic products.&lt;/p&gt;
    &lt;p&gt;We already knew that ClickHouse is one of the best infrastructure engineering teams in the world. More importantly, the engineering culture feels like an instant match:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;open-source identity and stewardship&lt;/item&gt;
      &lt;item&gt;developer-first product instincts&lt;/item&gt;
      &lt;item&gt;performance and reliability as product features (not afterthoughts)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The whole Langfuse team will join ClickHouse to continue building Langfuse. All of these aspects were important to us and we couldn’t be more excited.&lt;/p&gt;
    &lt;head rend="h2"&gt;What we’re focused on next&lt;/head&gt;
    &lt;p&gt;Our north star doesn’t change: help teams ship useful, reliable agents by closing the loop from production data to better prompts, evaluations, and product decisions.&lt;/p&gt;
    &lt;p&gt;Concretely, we’re investing in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Production monitoring and analytics for real agent systems (not just offline evals).&lt;/item&gt;
      &lt;item&gt;Workflows across tracing, labeling, and experiments so iteration loops get shorter.&lt;/item&gt;
      &lt;item&gt;More performance and scale—especially for large self‑hosted and enterprise deployments.&lt;/item&gt;
      &lt;item&gt;More polish (UI/UX, developer experience, and docs) so the product stays simple even as the space gets more complex.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can always follow along on the public roadmap.&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;Langfuse exists because the community pushed it forward, through GitHub issues, PRs, feedback, and lots of Slack messages and spontaneous calls to dig into a product feature together.&lt;/p&gt;
    &lt;p&gt;We’re grateful for the trust you’ve put in us. Joining ClickHouse is our way of honoring that trust by putting more resources behind the thing we care about most: building a product you can rely on.&lt;/p&gt;
    &lt;p&gt;We’re excited for what’s next!&lt;lb/&gt; Max, Clemens, and Marc&lt;/p&gt;
    &lt;head rend="h2"&gt;FAQ&lt;/head&gt;
    &lt;p&gt;Is Langfuse still open source?&lt;lb/&gt;Yes. No licensing changes planned.&lt;/p&gt;
    &lt;p&gt;Can I still self‑host Langfuse?&lt;lb/&gt;Yes. Self‑hosting is a first‑class path.&lt;/p&gt;
    &lt;p&gt;Does anything change for Langfuse Cloud customers today?&lt;lb/&gt;No. Same product, same endpoints, same contracts.&lt;/p&gt;
    &lt;p&gt;Where do I go for support?&lt;lb/&gt;No changes: https://langfuse.com/support&lt;/p&gt;
    &lt;p&gt;Will the Langfuse team stay on Langfuse?&lt;lb/&gt;Yes. The team is joining ClickHouse and will keep building Langfuse. Also, we continue hiring in Berlin and SF.&lt;/p&gt;
    &lt;head rend="h2"&gt;Join the discussion&lt;/head&gt;
    &lt;p&gt;If you have any other questions, let’s discuss together on GitHub Discussions.&lt;/p&gt;
    &lt;p&gt;If you’re an enterprise customer and have additional questions, feel free to reach out to enterprise@langfuse.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://langfuse.com/blog/joining-clickhouse"/><published>2026-01-17T09:15:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656759</id><title>Show HN: I built a tool to assist AI agents to know when a PR is good to go</title><updated>2026-01-17T17:08:59.883849+00:00</updated><content>&lt;doc fingerprint="2764e65f5d9246b2"&gt;
  &lt;main&gt;
    &lt;p&gt;Deterministic PR readiness detection for AI coding agents&lt;/p&gt;
    &lt;p&gt;The missing piece in AI-assisted development: knowing when you’re actually done.&lt;/p&gt;
    &lt;p&gt;AI coding agents are transforming software development. They can write code, fix bugs, respond to review comments, and create pull requests. But they all share one fundamental problem:&lt;/p&gt;
    &lt;p&gt;They can’t reliably know when a PR is ready to merge.&lt;/p&gt;
    &lt;p&gt;Think about it. When you ask an AI agent to “fix the CI and address the review comments,” how does it know when it’s finished?&lt;/p&gt;
    &lt;p&gt;Without deterministic answers, agents either:&lt;/p&gt;
    &lt;p&gt;Good To Go provides a single command that answers the question definitively:&lt;/p&gt;
    &lt;code&gt;gtg 123
&lt;/code&gt;
    &lt;p&gt;That’s it. One command. One answer.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
        &lt;cell role="head"&gt;Meaning&lt;/cell&gt;
        &lt;cell role="head"&gt;What to Do&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;READY&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;All clear&lt;/cell&gt;
        &lt;cell&gt;Merge it&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;ACTION_REQUIRED&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Comments need fixes&lt;/cell&gt;
        &lt;cell&gt;Address them&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;UNRESOLVED_THREADS&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Open discussions&lt;/cell&gt;
        &lt;cell&gt;Resolve them&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;CI_FAILING&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Checks not passing&lt;/cell&gt;
        &lt;cell&gt;Fix the build&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;No ambiguity. No guessing. No infinite loops.&lt;/p&gt;
    &lt;p&gt;Good To Go analyzes your PR across three dimensions:&lt;/p&gt;
    &lt;p&gt;Combines all GitHub check runs and commit statuses into a single pass/fail/pending state. Handles the complexity of multiple CI systems, required vs optional checks, and in-progress runs.&lt;/p&gt;
    &lt;p&gt;Not all review comments are created equal. Good To Go classifies each comment as:&lt;/p&gt;
    &lt;p&gt;Built-in parsers understand the patterns of popular automated reviewers:&lt;/p&gt;
    &lt;p&gt;Distinguishes between truly unresolved discussions and threads that are technically “unresolved” but already addressed in subsequent commits.&lt;/p&gt;
    &lt;p&gt;Good To Go is built specifically for how AI agents work:&lt;/p&gt;
    &lt;p&gt;Default mode returns &lt;code&gt;0&lt;/code&gt; for any analyzable state—because AI agents should parse the JSON output, not interpret exit codes as errors.&lt;/p&gt;
    &lt;code&gt;# AI-friendly (default): exit 0 + parse JSON
gtg 123 --format json

# Shell-script friendly: semantic exit codes
gtg 123 -q  # quiet mode, exit code only
&lt;/code&gt;
    &lt;p&gt;Every response includes exactly what an agent needs to take action:&lt;/p&gt;
    &lt;code&gt;{
  "status": "ACTION_REQUIRED",
  "action_items": [
    "Fix CRITICAL comment from coderabbit in src/db.py:42",
    "Resolve thread started by @reviewer in api.py"
  ],
  "actionable_comments": [...],
  "ci_status": {...},
  "threads": {...}
}
&lt;/code&gt;
    &lt;p&gt;Track what’s already been handled across agent sessions:&lt;/p&gt;
    &lt;code&gt;gtg 123 --state-path .goodtogo/state.db  # Remember dismissed comments
gtg 123 --refresh                         # Force fresh analysis
&lt;/code&gt;
    &lt;p&gt;Make &lt;code&gt;gtg&lt;/code&gt; a required status check. PRs can’t merge until they’re truly ready—not just “CI passed.”&lt;/p&gt;
    &lt;code&gt;# .github/workflows/pr-check.yml
- name: Check PR readiness
  run: gtg $ --semantic-codes
&lt;/code&gt;
    &lt;p&gt;Give your AI agent a definitive answer instead of endless polling:&lt;/p&gt;
    &lt;code&gt;result = subprocess.run(["gtg", pr_number, "--format", "json"], ...)
data = json.loads(result.stdout)

if data["status"] == "READY":
    merge_pr()
elif data["status"] == "ACTION_REQUIRED":
    for item in data["action_items"]:
        address_feedback(item)
&lt;/code&gt;
    &lt;p&gt;Monitor a PR through its entire lifecycle:&lt;/p&gt;
    &lt;code&gt;while true; do
  gtg 123 -q
  case $? in
    0) echo "Ready to merge!"; break ;;
    1) handle_comments ;;
    2) resolve_threads ;;
    3) wait_for_ci ;;
  esac
  sleep 60
done
&lt;/code&gt;
    &lt;code&gt;# Install
pip install gtg

# Set your GitHub token
export GITHUB_TOKEN=ghp_...

# Check a PR (auto-detects repo from git origin)
gtg 123

# Explicit repo
gtg 123 --repo owner/repo

# Human-readable output
gtg 123 --format text
&lt;/code&gt;
    &lt;p&gt;Good To Go embeds several opinions about PR workflows:&lt;/p&gt;
    &lt;p&gt; Made with Claude Code&lt;lb/&gt; by David Sifry &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dsifry.github.io/goodtogo/"/><published>2026-01-17T09:55:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656834</id><title>Map To Poster – Create Art of your favourite city</title><updated>2026-01-17T17:08:59.279898+00:00</updated><content>&lt;doc fingerprint="a8f7d87e9ce1dad8"&gt;
  &lt;main&gt;
    &lt;p&gt;Generate beautiful, minimalist map posters for any city in the world.&lt;/p&gt;
    &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;
    &lt;code&gt;python create_map_poster.py --city &amp;lt;city&amp;gt; --country &amp;lt;country&amp;gt; [options]&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Option&lt;/cell&gt;
        &lt;cell role="head"&gt;Short&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
        &lt;cell role="head"&gt;Default&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--city&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-c&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;City name&lt;/cell&gt;
        &lt;cell&gt;required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--country&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-C&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Country name&lt;/cell&gt;
        &lt;cell&gt;required&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--theme&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-t&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Theme name&lt;/cell&gt;
        &lt;cell&gt;feature_based&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;
          &lt;code&gt;--distance&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;-d&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Map radius in meters&lt;/cell&gt;
        &lt;cell&gt;29000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;--list-themes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;List all available themes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Iconic grid patterns
python create_map_poster.py -c "New York" -C "USA" -t noir -d 12000           # Manhattan grid
python create_map_poster.py -c "Barcelona" -C "Spain" -t warm_beige -d 8000   # Eixample district

# Waterfront &amp;amp; canals
python create_map_poster.py -c "Venice" -C "Italy" -t blueprint -d 4000       # Canal network
python create_map_poster.py -c "Amsterdam" -C "Netherlands" -t ocean -d 6000  # Concentric canals
python create_map_poster.py -c "Dubai" -C "UAE" -t midnight_blue -d 15000     # Palm &amp;amp; coastline

# Radial patterns
python create_map_poster.py -c "Paris" -C "France" -t pastel_dream -d 10000   # Haussmann boulevards
python create_map_poster.py -c "Moscow" -C "Russia" -t noir -d 12000          # Ring roads

# Organic old cities
python create_map_poster.py -c "Tokyo" -C "Japan" -t japanese_ink -d 15000    # Dense organic streets
python create_map_poster.py -c "Marrakech" -C "Morocco" -t terracotta -d 5000 # Medina maze
python create_map_poster.py -c "Rome" -C "Italy" -t warm_beige -d 8000        # Ancient layout

# Coastal cities
python create_map_poster.py -c "San Francisco" -C "USA" -t sunset -d 10000    # Peninsula grid
python create_map_poster.py -c "Sydney" -C "Australia" -t ocean -d 12000      # Harbor city
python create_map_poster.py -c "Mumbai" -C "India" -t contrast_zones -d 18000 # Coastal peninsula

# River cities
python create_map_poster.py -c "London" -C "UK" -t noir -d 15000              # Thames curves
python create_map_poster.py -c "Budapest" -C "Hungary" -t copper_patina -d 8000  # Danube split

# List available themes
python create_map_poster.py --list-themes&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Distance&lt;/cell&gt;
        &lt;cell role="head"&gt;Best for&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;4000-6000m&lt;/cell&gt;
        &lt;cell&gt;Small/dense cities (Venice, Amsterdam center)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;8000-12000m&lt;/cell&gt;
        &lt;cell&gt;Medium cities, focused downtown (Paris, Barcelona)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;15000-20000m&lt;/cell&gt;
        &lt;cell&gt;Large metros, full city view (Tokyo, Mumbai)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;17 themes available in &lt;code&gt;themes/&lt;/code&gt; directory:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Theme&lt;/cell&gt;
        &lt;cell role="head"&gt;Style&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;feature_based&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Classic black &amp;amp; white with road hierarchy&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gradient_roads&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Smooth gradient shading&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;contrast_zones&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;High contrast urban density&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;noir&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Pure black background, white roads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;midnight_blue&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Navy background with gold roads&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;blueprint&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Architectural blueprint aesthetic&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;neon_cyberpunk&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Dark with electric pink/cyan&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;warm_beige&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Vintage sepia tones&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;pastel_dream&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Soft muted pastels&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;japanese_ink&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Minimalist ink wash style&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;forest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Deep greens and sage&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;ocean&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Blues and teals for coastal cities&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;terracotta&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Mediterranean warmth&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;sunset&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Warm oranges and pinks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;autumn&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Seasonal burnt oranges and reds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;copper_patina&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Oxidized copper aesthetic&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;monochrome_blue&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Single blue color family&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Posters are saved to &lt;code&gt;posters/&lt;/code&gt; directory with format:&lt;/p&gt;
    &lt;code&gt;{city}_{theme}_{YYYYMMDD_HHMMSS}.png
&lt;/code&gt;
    &lt;p&gt;Create a JSON file in &lt;code&gt;themes/&lt;/code&gt; directory:&lt;/p&gt;
    &lt;code&gt;{
  "name": "My Theme",
  "description": "Description of the theme",
  "bg": "#FFFFFF",
  "text": "#000000",
  "gradient_color": "#FFFFFF",
  "water": "#C0C0C0",
  "parks": "#F0F0F0",
  "road_motorway": "#0A0A0A",
  "road_primary": "#1A1A1A",
  "road_secondary": "#2A2A2A",
  "road_tertiary": "#3A3A3A",
  "road_residential": "#4A4A4A",
  "road_default": "#3A3A3A"
}&lt;/code&gt;
    &lt;code&gt;map_poster/
├── create_map_poster.py          # Main script
├── themes/               # Theme JSON files
├── fonts/                # Roboto font files
├── posters/              # Generated posters
└── README.md
&lt;/code&gt;
    &lt;p&gt;Quick reference for contributors who want to extend or modify the script.&lt;/p&gt;
    &lt;code&gt;┌─────────────────┐     ┌──────────────┐     ┌─────────────────┐
│   CLI Parser    │────▶│  Geocoding   │────▶│  Data Fetching  │
│   (argparse)    │     │  (Nominatim) │     │    (OSMnx)      │
└─────────────────┘     └──────────────┘     └─────────────────┘
                                                     │
                        ┌──────────────┐             ▼
                        │    Output    │◀────┌─────────────────┐
                        │  (matplotlib)│     │   Rendering     │
                        └──────────────┘     │  (matplotlib)   │
                                             └─────────────────┘
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Function&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
        &lt;cell role="head"&gt;Modify when...&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_coordinates()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;City → lat/lon via Nominatim&lt;/cell&gt;
        &lt;cell&gt;Switching geocoding provider&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;create_poster()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Main rendering pipeline&lt;/cell&gt;
        &lt;cell&gt;Adding new map layers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_edge_colors_by_type()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Road color by OSM highway tag&lt;/cell&gt;
        &lt;cell&gt;Changing road styling&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;get_edge_widths_by_type()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Road width by importance&lt;/cell&gt;
        &lt;cell&gt;Adjusting line weights&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;
          &lt;code&gt;create_gradient_fade()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Top/bottom fade effect&lt;/cell&gt;
        &lt;cell&gt;Modifying gradient overlay&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;load_theme()&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;JSON theme → dict&lt;/cell&gt;
        &lt;cell&gt;Adding new theme properties&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;z=11  Text labels (city, country, coords)
z=10  Gradient fades (top &amp;amp; bottom)
z=3   Roads (via ox.plot_graph)
z=2   Parks (green polygons)
z=1   Water (blue polygons)
z=0   Background color
&lt;/code&gt;
    &lt;code&gt;# In get_edge_colors_by_type() and get_edge_widths_by_type()
motorway, motorway_link     → Thickest (1.2), darkest
trunk, primary              → Thick (1.0)
secondary                   → Medium (0.8)
tertiary                    → Thin (0.6)
residential, living_street  → Thinnest (0.4), lightest&lt;/code&gt;
    &lt;p&gt;New map layer (e.g., railways):&lt;/p&gt;
    &lt;code&gt;# In create_poster(), after parks fetch:
try:
    railways = ox.features_from_point(point, tags={'railway': 'rail'}, dist=dist)
except:
    railways = None

# Then plot before roads:
if railways is not None and not railways.empty:
    railways.plot(ax=ax, color=THEME['railway'], linewidth=0.5, zorder=2.5)&lt;/code&gt;
    &lt;p&gt;New theme property:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Add to theme JSON: &lt;code&gt;"railway": "#FF0000"&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Use in code: &lt;code&gt;THEME['railway']&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Add fallback in &lt;code&gt;load_theme()&lt;/code&gt;default dict&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All text uses &lt;code&gt;transform=ax.transAxes&lt;/code&gt; (0-1 normalized coordinates):&lt;/p&gt;
    &lt;code&gt;y=0.14  City name (spaced letters)
y=0.125 Decorative line
y=0.10  Country name
y=0.07  Coordinates
y=0.02  Attribution (bottom-right)
&lt;/code&gt;
    &lt;code&gt;# Get all buildings
buildings = ox.features_from_point(point, tags={'building': True}, dist=dist)

# Get specific amenities
cafes = ox.features_from_point(point, tags={'amenity': 'cafe'}, dist=dist)

# Different network types
G = ox.graph_from_point(point, dist=dist, network_type='drive')  # roads only
G = ox.graph_from_point(point, dist=dist, network_type='bike')   # bike paths
G = ox.graph_from_point(point, dist=dist, network_type='walk')   # pedestrian&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Large &lt;code&gt;dist&lt;/code&gt;values (&amp;gt;20km) = slow downloads + memory heavy&lt;/item&gt;
      &lt;item&gt;Cache coordinates locally to avoid Nominatim rate limits&lt;/item&gt;
      &lt;item&gt;Use &lt;code&gt;network_type='drive'&lt;/code&gt;instead of&lt;code&gt;'all'&lt;/code&gt;for faster renders&lt;/item&gt;
      &lt;item&gt;Reduce &lt;code&gt;dpi&lt;/code&gt;from 300 to 150 for quick previews&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/originalankur/maptoposter"/><published>2026-01-17T10:13:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656903</id><title>US electricity demand surged in 2025 – solar handled 61% of it</title><updated>2026-01-17T17:08:59.044861+00:00</updated><content>&lt;doc fingerprint="a910b07712b4d594"&gt;
  &lt;main&gt;
    &lt;p&gt;Solar didn’t just show up in 2025 – it carried the grid. A new analysis from global energy think tank Ember shows that solar power accounted for 61% of the growth in US electricity demand last year, highlighting how central solar has become as power demand accelerates.&lt;/p&gt;
    &lt;p&gt;US electricity demand jumped by 135 terawatt-hours (TWh) in 2025, a 3.1% increase, the fourth‑largest annual rise of the past decade. Over that same period, solar generation grew by a record 83 TWh – a 27% increase from 2024 and the biggest absolute gain of any power source. That single jump in solar output covered 61% of all new electricity demand nationwide.&lt;/p&gt;
    &lt;p&gt;“Solar growth was essential in helping to meet fast‑rising US electricity demand in 2025,” said Dave Jones, chief analyst at Ember. “It generated where it was needed, and – with the surge in batteries – increasingly when it was needed.”&lt;/p&gt;
    &lt;p&gt;Texas, the Midwest, and the Mid‑Atlantic saw the largest increases in solar generation last year, and they were also the regions where electricity demand rose the fastest. Solar met 81% of demand growth in both Texas and the Midwest, and 33% in the Mid‑Atlantic.&lt;/p&gt;
    &lt;p&gt;Timing mattered, too. In aggregate, the increase in solar generation met the entire rise in US electricity demand during daytime hours between 10 am and 6 pm Eastern. And as a result of the rapid buildout of battery storage, solar also helped cover some of the demand growth during the evening hours, from 6 pm to 2 am.&lt;/p&gt;
    &lt;p&gt;The adoption of battery storage is turning solar from cheap daytime power into something far more flexible. Over the past six years, California’s utility‑scale solar and battery generation has climbed 58%. Yet, output at the sunniest hour of the day has increased by just 8%, a sign that more energy is being stored and used later, rather than dumped onto the grid all at once.&lt;/p&gt;
    &lt;p&gt;Most of the new solar generation in 2025 was absorbed by rising electricity demand, allowing solar to scale alongside overall grid growth.&lt;/p&gt;
    &lt;p&gt;“Solar has the potential to meet all the rise in electricity demand and much more. With electricity demand surging, the case to build solar has never been stronger,” said Jones.&lt;/p&gt;
    &lt;p&gt;Read more: EIA: All net new generating capacity in 2026 may be renewables&lt;/p&gt;
    &lt;p&gt;If you’re looking to replace your old HVAC equipment, it’s always a good idea to get quotes from a few installers. To make sure you’re finding a trusted, reliable HVAC installer near you that offers competitive pricing on heat pumps, check out EnergySage. EnergySage is a free service that makes it easy for you to get a heat pump. They have pre-vetted heat pump installers competing for your business, ensuring you get high quality solutions. Plus, it’s free to use!&lt;/p&gt;
    &lt;p&gt;Your personalized heat pump quotes are easy to compare online and you’ll get access to unbiased Energy Advisors to help you every step of the way. Get started here. – *ad&lt;/p&gt;
    &lt;p&gt;FTC: We use income earning auto affiliate links. More.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://electrek.co/2026/01/16/us-electricity-demand-surged-in-2025-solar-handled-61-percent/"/><published>2026-01-17T10:28:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656909</id><title>An explanation of cheating in Doom2 Deathmatch (1999)</title><updated>2026-01-17T17:08:58.553687+00:00</updated><content>&lt;doc fingerprint="77060dea50735b9b"&gt;
  &lt;main&gt;
    &lt;quote&gt;&lt;p&gt;An explanation of cheating in Doom2 Deathmatch&lt;/p&gt;&lt;p&gt;First, a definition of cheating..&lt;/p&gt;&lt;p&gt;Any modification not normally available in Doom2 that provides an advantage to one player over another with regard to:&lt;/p&gt;&lt;p&gt;(1) humanly-executable player movement,&lt;/p&gt;&lt;lb/&gt;(2) visual abilities,&lt;lb/&gt;(3) audio abilities,&lt;lb/&gt;(4) player aim abilities, or&lt;lb/&gt;(5) mechanisms to locate the opponent,&lt;p&gt;and furthermore, these changes are put into effect in a game against another player who either&lt;/p&gt;&lt;p&gt;(1) does not agree to, or&lt;/p&gt;&lt;lb/&gt;(2) is unaware that the change has been implemented&lt;p&gt;is cheating.&lt;/p&gt;&lt;p&gt;Modifactions to sound and graphics to help a hearing or visually impaired player compensate for his or her disability are not considered cheats.&lt;/p&gt;&lt;lb/&gt;This page has been written to provide a means by which we honest players can keep our netparties, modem games, - and most importantly our tournaments -, free from the effects of those who would choose to cheat in Doom2. It relates primarily to the classic, DOSmode Doom2.exe; the usefulness of these cheats on the various Doom ports has not been examined (other kinds of cheats are reported to exist for these Doom ports, but we are not exploring them here).&lt;p&gt;There is a dilemma with writing an explanation of cheating, and that is that the few people who would like to cheat may attempt to use such explanation as a means to learn or invent cheating mechanisms for their own use. After much thought and observation of recent events, I have come to believe that this problem is outweighed by the impact that some of these cheats can have on tournaments, especially ones where prizes with cash value are awarded to the winners. Should any one of these cheats be used in a LAN tournament, this use is detectable and proveable, with no question as to the validity of the determination, as long as the matches are recorded. When the information on how to easily detect and prove the use of these cheats is made widespread, the few people who would take this information and use it to cheat will be only be able to participate in non-recorded, non-tournament, basically frivolous gameplay. This information will also empower us to recognize those among us, past and present, who are true "Doom Gods".&lt;/p&gt;&lt;p&gt;This page includes explanations of several cheat methods, downloads of utilities that can be used to analyze .lmp files (Deathmatch recordings) to decisively prove whether certain cheat use occured or did not occur, and downloadable .lmp files which may show various cheats in use.&lt;/p&gt;&lt;p&gt;DOS Doom2 Deathmatch cheats with explanations&lt;/p&gt;&lt;lb/&gt;in order of severity&lt;lb/&gt;(click on the name of the cheat to read the full explanation)&lt;center&gt;Name of Cheat&lt;/center&gt;&lt;center&gt;Observable on monitor or speakers in-game?&lt;/center&gt;&lt;center&gt;Detectability through analysis of recordings?&lt;/center&gt;&lt;center&gt;Effectiveness**&lt;/center&gt;&lt;center&gt;Doom2 1.9 autoaim or "aimbot"&lt;/center&gt;&lt;center&gt;At times&lt;/center&gt;&lt;center&gt;Easy to prove&lt;/center&gt;&lt;center&gt;Extremely High&lt;/center&gt;&lt;center&gt;Map Editing&lt;/center&gt;&lt;center&gt;Obvious visibility&lt;/center&gt;&lt;center&gt;Almost no evidence&lt;/center&gt;&lt;center&gt;Extremely High&lt;/center&gt;&lt;center&gt;SR-50 Automation&lt;/center&gt;&lt;center&gt;No&lt;/center&gt;&lt;center&gt;Easy to prove&lt;/center&gt;&lt;center&gt;High&lt;/center&gt;&lt;center&gt;No-Red&lt;/center&gt;&lt;center&gt;Obvious visibility&lt;/center&gt;&lt;center&gt;Almost no evidence&lt;/center&gt;&lt;center&gt;Medium&lt;/center&gt;&lt;center&gt;Bright&lt;/center&gt;&lt;center&gt;Obvious visibility&lt;/center&gt;&lt;center&gt;Almost no evidence&lt;/center&gt;&lt;center&gt;Medium&lt;/center&gt;&lt;center&gt;Sprite editing&lt;/center&gt;&lt;center&gt;Obvious visibility&lt;/center&gt;&lt;center&gt;Almost no evidence&lt;/center&gt;&lt;center&gt;Medium&lt;/center&gt;&lt;center&gt;Sound Editing&lt;/center&gt;&lt;center&gt;Obvious&lt;/center&gt;&lt;center&gt;Almost no evidence&lt;/center&gt;&lt;center&gt;Medium&lt;/center&gt;&lt;center&gt;Red Dot&lt;/center&gt;&lt;center&gt;Obvious visibility&lt;/center&gt;&lt;center&gt;No&lt;/center&gt;&lt;center&gt;Low or None&lt;/center&gt;** Effectiveness refers to the degree to which the cheat could&lt;lb/&gt;effect the result of a match between two very high skilled players.&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.doom2.net/doom2/cheating.html"/><published>2026-01-17T10:29:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46656998</id><title>PCs refuse to shut down after Microsoft patch</title><updated>2026-01-17T17:08:58.314696+00:00</updated><content>&lt;doc fingerprint="745069121a6766f7"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Sorry Dave, I’m afraid I can’t do that! PCs refuse to shut down after Microsoft patch&lt;/head&gt;
    &lt;head rend="h2"&gt;Microsoft claims it's a Secure Launch bug&lt;/head&gt;
    &lt;p&gt;We're not saying Copilot has become sentient and decided it doesn't want to lose consciousness. But if it did, it would create Microsoft's January Patch Tuesday update, which has made it so that some PCs flat-out refuse to shut down or hibernate, no matter how many times you try.&lt;/p&gt;
    &lt;p&gt;In a notice on its Windows release health dashboard, Microsoft confirmed that some PCs running Windows 11 23H2 might fail to power down properly after installing the latest security updates. Instead of slipping into shutdown or hibernation, affected machines stay stubbornly awake, draining batteries and ignoring shutdown like they have a mind of their own and don't want to experience temporary non-existence.&lt;/p&gt;
    &lt;p&gt;The bug appears to be tied to Secure Launch, a security feature that uses virtualization-based protections to ensure only trusted components load during boot. On systems with Secure Launch enabled, attempts to shut down, restart, or hibernate after applying the January patches may fail to complete. From the user's perspective, everything looks normal – until the PC keeps running anyway, refusing to be denied life.&lt;/p&gt;
    &lt;p&gt;Microsoft says that entering the command "shutdown /s /t 0" at the command prompt will, in fact, force your PC to turn off, whether it wants to or not.&lt;/p&gt;
    &lt;p&gt;"Until this issue is resolved, please ensure you save all your work, and shut down when you are done working on your device to avoid the device running out of power instead of hibernating," Microsoft said.&lt;/p&gt;
    &lt;p&gt;The firm hasn't offered much in the way of technical detail, nor has it put numbers on how many devices are affected. There's also no fix yet, with Redmond vaguely promising to "release a resolution for this issue in a future update." But isn't that just what a sentient bot might say?&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Microsoft teases targeted Copilot removal for admins&lt;/item&gt;
      &lt;item&gt;Microsoft rushes an out-of-band update for Message Queuing bug&lt;/item&gt;
      &lt;item&gt;Windows is testing a new, wider Run dialog box. Here's how to try it&lt;/item&gt;
      &lt;item&gt;Latest Windows 11 updates may break the OS's most basic bits&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This isn't the only post-update gremlin lurking in January's Patch Tuesday bundle. Microsoft has also been forced to acknowledge a separate issue in which classic Outlook POP account profiles can hang or freeze after installing this month's patches, another reminder that while the bugs being fixed may be invisible, the ones introduced can be painfully obvious.&lt;/p&gt;
    &lt;p&gt;The notice is similarly vague, with Microsoft stating: "This is an emerging issue, and we don't have all the symptoms yet, but we will update the topic as we understand the issue better."&lt;/p&gt;
    &lt;p&gt;Patch Tuesday exists to close security holes, some of them serious, and skipping updates is rarely a great idea. But once again, a batch of fixes has arrived with side effects that range from irritating to disruptive, depending on how much you rely on your system behaving predictably when it's told to turn off.&lt;/p&gt;
    &lt;p&gt;For now, admins and long-suffering Windows users are left watching Microsoft's status pages and waiting for patches to the patches – hoping their machines eventually go to sleep. ®&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theregister.com/2026/01/16/patch_tuesday_secure_launch_bug_no_shutdown/"/><published>2026-01-17T10:51:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46657122</id><title>ASCII characters are not pixels: a deep dive into ASCII rendering</title><updated>2026-01-17T17:08:57.705912+00:00</updated><content>&lt;doc fingerprint="74d7db3c780d01ad"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ASCII characters are not pixels: a deep dive into ASCII rendering&lt;/head&gt;
    &lt;p&gt;Recently, I’ve been spending my time building an image-to-ASCII renderer. Below is the result — try dragging it around, the demo is interactive!&lt;/p&gt;
    &lt;p&gt;One thing I spent a lot of effort on is getting edges looking sharp. Take a look at this rotating cube example:&lt;/p&gt;
    &lt;p&gt;Try opening the “split” view. Notice how well the characters follow the contour of the square.&lt;/p&gt;
    &lt;p&gt;This renderer works well for animated scenes, like the ones above, but we can also use it to render static images:&lt;/p&gt;
    &lt;p&gt;The image of Saturn was generated with ChatGPT.&lt;/p&gt;
    &lt;p&gt;Then, to get better separation between different colored regions, I also implemented a cel shading-like effect to enhance contrast between edges. Try dragging the contrast slider below:&lt;/p&gt;
    &lt;p&gt;The contrast enhancement makes the separation between different colored regions far clearer. That was key to making the 3D scene above look as good as it does.&lt;/p&gt;
    &lt;p&gt;I put so much focus on sharp edges because they’re an aspect of ASCII rendering that is often overlooked when programmatically rendering images as ASCII. Consider this animated 3D scene from Cognition’s landing page that is rendered via ASCII characters:&lt;/p&gt;
    &lt;p&gt;Source: cognition.ai&lt;/p&gt;
    &lt;p&gt;It’s a cool effect, especially while in motion, but take a look at those blurry edges! The characters follow the cube contours very poorly, and as a result, the edges look blurry and jagged in places:&lt;/p&gt;
    &lt;p&gt;This blurriness happens because the ASCII characters are being treated like pixels — their shape is ignored. It’s disappointing to see because ASCII art looks so much better when shape is utilized. I don’t believe I’ve ever seen shape utilized in generated ASCII art, and I think that’s because it’s not really obvious how to consider shape when building an ASCII renderer.&lt;/p&gt;
    &lt;p&gt;I started building my ASCII renderer to prove to myself that it’s possible to utilize shape in ASCII rendering. In this post, I’ll cover the techniques and ideas I used to capture shape and build this ASCII renderer in detail.&lt;/p&gt;
    &lt;p&gt;We’ll start with the basics of image-to-ASCII conversion and see where the common issue of blurry edges comes from. After that, I’ll show you the approach I used to fix that and achieve sharp, high-quality ASCII rendering. At the end, we’ll improve on that by implementing the contrast enhancement effect I showed above.&lt;/p&gt;
    &lt;p&gt;Let’s get to it!&lt;/p&gt;
    &lt;head rend="h2"&gt;Image to ASCII conversion&lt;/head&gt;
    &lt;p&gt;ASCII contains 95 printable characters that we can use. Let’s start off by rendering the following image containing a white circle using those ASCII characters:&lt;/p&gt;
    &lt;p&gt;ASCII art is (almost) always rendered using a monospace font. Since every character in a monospace font is equally wide and tall, we can split the image into a grid. Each grid cell will contain a single ASCII character.&lt;/p&gt;
    &lt;p&gt;The image with the circle is &lt;/p&gt;
    &lt;p&gt;Monospace characters are typically taller than they are wide, so I made each grid cell a bit taller than it is wide.&lt;/p&gt;
    &lt;p&gt;Our task is now to pick which character to place in each cell. The simplest approach is to calculate a lightness value for each cell and pick a character based on that.&lt;/p&gt;
    &lt;p&gt;We can get a lightness value for each cell by sampling the lightness of the pixel at the cell’s center:&lt;/p&gt;
    &lt;p&gt;We want each pixel’s lightness as a numeric value between &lt;/p&gt;
    &lt;p&gt;We can use the following formula to convert an RGB color (with component values between &lt;/p&gt;
    &lt;p&gt;See relative luminance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mapping lightness values to ASCII characters&lt;/head&gt;
    &lt;p&gt;Now that we have a lightness value for each cell, we want to use those values to pick ASCII characters. As mentioned before, ASCII has 95 printable characters, but let’s start simple with just these characters:&lt;/p&gt;
    &lt;quote&gt;: - # = + @ * % .&lt;/quote&gt;
    &lt;p&gt;We can sort them in approximate density order like so, with lower-density characters to the left, and high-density characters to the right:&lt;/p&gt;
    &lt;quote&gt;. : - = + * # % @&lt;/quote&gt;
    &lt;p&gt;We’ll put these characters in a &lt;code&gt;CHARS&lt;/code&gt; array:&lt;/p&gt;
    &lt;quote&gt;const CHARS = [" ", ".", ":", "-", "=", "+", "*", "#", "%", "@"]&lt;/quote&gt;
    &lt;p&gt;I added space as the first (least dense) character.&lt;/p&gt;
    &lt;p&gt;We can then map lightness values between &lt;/p&gt;
    &lt;quote&gt;function getCharacterFromLightness(lightness: number) {const index = Math.floor(lightness * (CHARS.length - 1));return CHARS[index];}&lt;/quote&gt;
    &lt;p&gt;This maps low lightness values to low-density characters and high lightness values to high-density characters.&lt;/p&gt;
    &lt;p&gt;Rendering the circle from above with this method gives us:&lt;/p&gt;
    &lt;p&gt;That works... but the result is pretty ugly. We seem to always get &lt;code&gt;@&lt;/code&gt; for cells that fall within the circle and a space for cells that fall outside.&lt;/p&gt;
    &lt;p&gt;That is happening because we’ve pretty much just implemented nearest-neighbor downsampling. Let’s see what that means.&lt;/p&gt;
    &lt;head rend="h2"&gt;Nearest neighbor downsampling&lt;/head&gt;
    &lt;p&gt;Downsampling, in the context of image processing, is taking a larger image (in our case, the &lt;/p&gt;
    &lt;p&gt;The simplest and fastest method of sampling is nearest-neighbor interpolation, where, for each cell (pixel), we only take a single sample from the higher resolution image.&lt;/p&gt;
    &lt;p&gt;Consider the circle example again. Using nearest-neighbor interpolation, every sample either falls inside or outside of the shape, resulting in either &lt;/p&gt;
    &lt;p&gt;If, instead of picking an ASCII character for each grid cell, we color each grid cell (pixel) according to the sampled value, we get the following pixelated rendering:&lt;/p&gt;
    &lt;p&gt;This pixelated rendering is pretty much equivalent to the ASCII rendering from before. The only difference is that instead of &lt;code&gt;@&lt;/code&gt;s we have white pixels, and instead of spaces we have black pixels.&lt;/p&gt;
    &lt;p&gt;These square, jagged looking edges are aliasing artifacts, commonly called jaggies. They’re a common result of using nearest-neighbor interpolation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Supersampling&lt;/head&gt;
    &lt;p&gt;To get rid of jaggies, we can collect more samples for each cell. Consider this line:&lt;/p&gt;
    &lt;p&gt;The line’s slope on the &lt;/p&gt;
    &lt;p&gt;Let’s try to get rid of the jagginess by taking multiple samples within each cell and using the average sampled lightness value as the cell’s lightness. The example below lets you vary the number of samples using the slider:&lt;/p&gt;
    &lt;p&gt;With multiple samples, cells that lie on the edge of a shape will have some of their samples fall within the shape, and some outside of it. Averaging those, we get gray in-between colors that smooth the downsampled image. Below is the same example, but with an overlay showing where the samples are taken:&lt;/p&gt;
    &lt;p&gt;This method of collecting multiple samples from the larger image is called supersampling. It’s a common method of spatial anti-aliasing (avoiding jaggies at edges). Here’s what the rotating square looks like with supersampling (using &lt;/p&gt;
    &lt;p&gt;Let’s look at what supersampling does for the circle example from earlier. Try dragging the sample quality slider:&lt;/p&gt;
    &lt;p&gt;The circle becomes less jagged, but the edges feel blurry. Why’s that?&lt;/p&gt;
    &lt;p&gt;Well, they feel blurry because we’re pretty much just rendering a low-resolution, pixelated image of a circle. Take a look at the pixelated view:&lt;/p&gt;
    &lt;p&gt;The ASCII and pixelated views are mirror images of each other. Both are just low-resolution versions of the original high-resolution image, scaled up to the original’s size — it’s no wonder they both look blurry.&lt;/p&gt;
    &lt;p&gt;Increasing the number of samples is insufficient. No matter how many samples we take per cell, the samples will be averaged into a single lightness value, used to render a single pixel.&lt;/p&gt;
    &lt;p&gt;And that’s the core problem: treating each grid cell as a pixel in an image. It’s an obvious and simple method, but it disregards that ASCII characters have shape.&lt;/p&gt;
    &lt;p&gt;We can make our ASCII renderings far more crisp by picking characters based on their shape. Here’s the circle rendered that way:&lt;/p&gt;
    &lt;p&gt;The characters follow the contour of the circle very well. By picking characters based on shape, we get a far higher effective resolution. The result is also more visually interesting.&lt;/p&gt;
    &lt;p&gt;Let’s see how we can implement this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Shape&lt;/head&gt;
    &lt;p&gt;So what do I mean by shape? Well, consider the characters &lt;code&gt;T&lt;/code&gt;, &lt;code&gt;L&lt;/code&gt;, and &lt;code&gt;O&lt;/code&gt; placed within grid cells:&lt;/p&gt;
    &lt;p&gt;The character &lt;code&gt;T&lt;/code&gt; is top-heavy. Its visual density in the upper half of the grid cell is higher than in the lower half. The opposite can be said for &lt;code&gt;L&lt;/code&gt; — it’s bottom-heavy. &lt;code&gt;O&lt;/code&gt; is pretty much equally dense in the upper and lower halves of the cell.&lt;/p&gt;
    &lt;p&gt;We might also compare characters like &lt;code&gt;L&lt;/code&gt; and &lt;code&gt;J&lt;/code&gt;. The character &lt;code&gt;L&lt;/code&gt; is heavier within the left half of the cell, while &lt;code&gt;J&lt;/code&gt; is heavier in the right half:&lt;/p&gt;
    &lt;p&gt;We also have more “extreme” characters, such as &lt;code&gt;_&lt;/code&gt; and &lt;code&gt;^&lt;/code&gt;, that only occupy the lower or upper portion of the cell, respectively:&lt;/p&gt;
    &lt;p&gt;This is, roughly, what I mean by “shape” in the context of ASCII rendering. Shape refers to which regions of a cell a given character visually occupies.&lt;/p&gt;
    &lt;head rend="h3"&gt;Quantifying shape&lt;/head&gt;
    &lt;p&gt;To pick characters based on their shape, we’ll somehow need to quantify (put numbers to) the shape of each character.&lt;/p&gt;
    &lt;p&gt;Let’s start by only considering how much characters occupy the upper and lower regions of our cell. To do that, we’ll define two “sampling circles” for each grid cell — one placed in the upper half and one in the lower half:&lt;/p&gt;
    &lt;p&gt;It may seem odd or arbitrary to use circles instead of just splitting the cell into two rectangles, but using circles will give us more flexibility later on.&lt;/p&gt;
    &lt;p&gt;A character placed within a cell will overlap each of the cell’s sampling circles to some extent.&lt;/p&gt;
    &lt;p&gt;One can compute that overlap by taking a bunch of samples within the circle (for example, at every pixel). The fraction of samples that land inside the character gives us the overlap as a numeric value between &lt;/p&gt;
    &lt;p&gt;For T, we get an overlap of approximately &lt;/p&gt;
    &lt;p&gt;We can generate such a &lt;/p&gt;
    &lt;p&gt;Below are some ASCII characters and their shape vectors. I’m coloring the sampling circles using the component values of the shape vectors:&lt;/p&gt;
    &lt;p&gt;We can use the shape vectors as 2D coordinates — here’s every ASCII character on a 2D plot:&lt;/p&gt;
    &lt;head rend="h3"&gt;Shape-based lookup&lt;/head&gt;
    &lt;p&gt;Let’s say that we have our ASCII characters and their associated shape vectors in a &lt;code&gt;CHARACTERS&lt;/code&gt; array:&lt;/p&gt;
    &lt;quote&gt;const CHARACTERS: Array&amp;lt;{character: string,shapeVector: number[],}&amp;gt; = [...];&lt;/quote&gt;
    &lt;p&gt;We can then perform a nearest neighbor search like so:&lt;/p&gt;
    &lt;quote&gt;function findBestCharacter(inputVector: number[]) {let bestCharacter = "";let bestDistance = Infinity;for (const { character, shapeVector } of CHARACTERS) {const dist = getDistance(shapeVector, inputVector);if (dist &amp;lt; bestDistance) {bestDistance = dist;bestCharacter = character;}}return bestCharacter;}&lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;findBestCharacter&lt;/code&gt; function gives us the ASCII character whose shape best matches the input lookup vector.&lt;/p&gt;
    &lt;p&gt;Note: this brute force search is not very performant. This becomes a bottleneck when we start rendering thousands of ASCII characters at &lt;/p&gt;
    &lt;p&gt;To make use of this in our ASCII renderer, we’ll calculate a lookup vector for each cell in the ASCII grid and pass it to &lt;code&gt;findBestCharacter&lt;/code&gt; to determine the character to display.&lt;/p&gt;
    &lt;p&gt;Let’s try it out. Consider the following zoomed-in circle as an example. It is split into three grid cells:&lt;/p&gt;
    &lt;p&gt;Overlaying our sampling circles, we see varying degrees of overlap:&lt;/p&gt;
    &lt;p&gt;When calculating the shape vector of each ASCII character, we took a huge number of samples. We could afford to do that because we only need to calculate those shape vectors once up front. After they’re calculated, we can use them again and again.&lt;/p&gt;
    &lt;p&gt;However, if we’re converting an animated image (e.g. canvas or video) to ASCII, we need to be mindful of performance when calculating the lookup vectors. An ASCII rendering might have hundreds or thousands of cells. Multiplying that by tens or hundreds of samples would be incredibly costly in terms of performance.&lt;/p&gt;
    &lt;p&gt;With that being said, let’s pick a sampling quality of &lt;/p&gt;
    &lt;p&gt;For the top sampling circle of the leftmost cell, we get one white sample and two black, giving us an average lightness of &lt;/p&gt;
    &lt;p&gt;From now on, instead of using the term “lookup vectors”, I’ll call these vectors, sampled from the image that we’re rendering as ASCII, sampling vectors. One sampling vector is calculated for each cell in the grid.&lt;/p&gt;
    &lt;p&gt;Anyway, we can use these sampling vectors to find the best-matching ASCII character. Let’s see what that looks like on our 2D plot — I’ll label the sampling vectors (from left to right) C0, C1, and C2:&lt;/p&gt;
    &lt;p&gt;Hmm... this is not what we want. Since none of the ASCII shape vector components exceed &lt;/p&gt;
    &lt;p&gt;We can fix this by normalizing the shape vectors. We’ll do that by taking the maximum value of each component across all shape vectors, and dividing the components of each shape vector by the maximum. Expressed in code, that looks like so:&lt;/p&gt;
    &lt;quote&gt;const max = [0, 0]for (const vector of characterVectors) {for (const [i, value] of Object.entries(vector)) {if (value &amp;gt; max[i]) {max[i] = value;}}}const normalizedCharacterVectors = characterVectors.map(vector =&amp;gt; vector.map((value, i) =&amp;gt; value / max[i]))&lt;/quote&gt;
    &lt;p&gt;Here’s what the plot looks like with the shape vectors normalized:&lt;/p&gt;
    &lt;p&gt;If we now map the sampling vectors to their nearest neighbors, we get a much more sensible result:&lt;/p&gt;
    &lt;p&gt;We get &lt;code&gt;'&lt;/code&gt;, &lt;code&gt;M&lt;/code&gt; and &lt;code&gt;$&lt;/code&gt;.  Let’s see how well those characters match the circle:&lt;/p&gt;
    &lt;p&gt;Nice! They match very well.&lt;/p&gt;
    &lt;p&gt;Let’s try rendering the full circle from before with the same method:&lt;/p&gt;
    &lt;p&gt;Much better than before! The picked characters follow the contour of the circle very well.&lt;/p&gt;
    &lt;head rend="h2"&gt;Limits of a 2D shape vector&lt;/head&gt;
    &lt;p&gt;Using two sampling circles — one upper and one lower — produces a much better result than the &lt;/p&gt;
    &lt;p&gt;For example, two circles don’t capture the shape of characters that fall in the middle of the cell. Consider &lt;code&gt;-&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;-&lt;/code&gt;, we get a shape vector of &lt;/p&gt;
    &lt;p&gt;The two upper-lower sampling circles also don’t capture left-right differences, such as the difference between &lt;code&gt;p&lt;/code&gt; and &lt;code&gt;q&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;We could use such differences to get better character picks, but our two sampling circles don’t capture them. Let’s add more dimensions to our shape to fix that.&lt;/p&gt;
    &lt;head rend="h2"&gt;Increasing to 6 dimensions&lt;/head&gt;
    &lt;p&gt;Since cells are taller than they are wide (at least with the monospace font I’m using), we can use &lt;/p&gt;
    &lt;p&gt;&lt;code&gt;p&lt;/code&gt; and &lt;code&gt;q&lt;/code&gt;, while also capturing differences across the top, bottom, and middle regions of the cell, differentiating &lt;code&gt;^&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, and &lt;code&gt;_&lt;/code&gt;. They also capture the shape of “diagonal” characters like &lt;code&gt;/&lt;/code&gt; to a reasonable degree.&lt;/p&gt;
    &lt;p&gt;One problem with this grid-like configuration for the sampling circles is that there are gaps. For example, &lt;code&gt;.&lt;/code&gt; falls between the sampling circles:&lt;/p&gt;
    &lt;p&gt;To compensate for this, we can stagger the sampling circles vertically (e.g. lowering the left sampling circles and raising the right ones) and make them a bit larger. This causes the cell to be almost fully covered while not causing excessive overlap across the sampling circles:&lt;/p&gt;
    &lt;p&gt;We can use the same procedure as before to generate character vectors using these sampling circles, this time yielding a &lt;code&gt;L&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;For &lt;code&gt;L&lt;/code&gt;, we get the vector:&lt;/p&gt;
    &lt;p&gt;I’m presenting &lt;/p&gt;
    &lt;p&gt;The lightness values certainly look L-shaped! The 6D shape vector captures &lt;code&gt;L&lt;/code&gt;’s shape very well.&lt;/p&gt;
    &lt;head rend="h3"&gt;Nearest neighbor lookups in a 6D space&lt;/head&gt;
    &lt;p&gt;Now we have a 6D shape vector for every ASCII character. Does that affect character lookups (how we find the best matching character)?&lt;/p&gt;
    &lt;p&gt;Earlier, in the &lt;code&gt;findBestCharacter&lt;/code&gt; function, I referenced a &lt;code&gt;getDistance&lt;/code&gt; function. That function returns the Euclidean distance between the input points. Given two 2D points &lt;/p&gt;
    &lt;p&gt;This generalizes to higher dimensions:&lt;/p&gt;
    &lt;p&gt;Put into code, this looks like so:&lt;/p&gt;
    &lt;quote&gt;function getDistance(a: number[], b: number[]): number {let sum = 0;for (let i = 0; i &amp;lt; a.length; i++) {sum += (a[i] - b[i]) ** 2;}return Math.sqrt(sum);}&lt;/quote&gt;
    &lt;p&gt;Note: since we’re just using this for the purposes of finding the closest point, we can skip the expensive &lt;code&gt;Math.sqrt()&lt;/code&gt; call and just return the squared distance. It does not affect the result.&lt;/p&gt;
    &lt;p&gt;So, no, the dimensionality of our shape vector does not change lookups at all. We can use the same &lt;code&gt;getDistance&lt;/code&gt; function for both 2D and 6D.&lt;/p&gt;
    &lt;p&gt;With that out of the way, let’s see what the 6D approach yields!&lt;/p&gt;
    &lt;head rend="h3"&gt;Trying out the 6D approach&lt;/head&gt;
    &lt;p&gt;Our new 6D approach works really well for flat shapes, like the circle example we’ve been using:&lt;/p&gt;
    &lt;p&gt;Now let’s see how this approach works when we render a 3D scene with more shades of gray:&lt;/p&gt;
    &lt;p&gt;Firstly, the outer contours look nice and sharp. I also like how well the gradients across the sphere and cone look.&lt;/p&gt;
    &lt;p&gt;However, internally, the objects all kind of blend together. The edges between surfaces with different lightnesses aren’t sharp enough. For example, the lighter faces of the cubes all kind of blend into one solid color. When there is a change in color — like when two faces of a cube meet — I’d like to see more sharpness in the ASCII rendering.&lt;/p&gt;
    &lt;p&gt;To demonstrate what I mean, consider the following split:&lt;/p&gt;
    &lt;p&gt;It’s currently rendered like so:&lt;/p&gt;
    &lt;p&gt;The different shades result in &lt;code&gt;i&lt;/code&gt;s on the left and &lt;code&gt;B&lt;/code&gt;s on the right, but the boundary is not very sharp.&lt;/p&gt;
    &lt;p&gt;By applying some effects to the sampling vector, we can enhance the contrast at the boundary so that it appears sharper:&lt;/p&gt;
    &lt;p&gt;The added contrast makes a big difference in readability for the 3D scene. Let’s look at how we can implement this contrast enhancement effect.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contrast enhancement&lt;/head&gt;
    &lt;p&gt;Consider cells overlapping a color boundary like so:&lt;/p&gt;
    &lt;p&gt;For the cells on the boundary, we get a 6D sampling vector that looks like so:&lt;/p&gt;
    &lt;p&gt;To make future examples easier to visualize, I’ll start drawing the sampling vector using &lt;/p&gt;
    &lt;p&gt;Currently, this sampling vector resolves to the character &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;That’s a sensible choice. The character &lt;code&gt;T&lt;/code&gt; is visually dense in the top half and less so in the bottom half, so it matches the image fairly well.&lt;/p&gt;
    &lt;p&gt;Still, I want the picked character to emphasize the shape of the boundary better. We can achieve that by enhancing the contrast of the sampling vector.&lt;/p&gt;
    &lt;p&gt;To increase the contrast of our sampling vector, we might raise each component of the vector to the power of some exponent.&lt;/p&gt;
    &lt;p&gt;Consider how an exponent affects values between &lt;/p&gt;
    &lt;p&gt;The level of pull depends on the exponent. Here’s a chart of &lt;/p&gt;
    &lt;p&gt;This effect becomes more pronounced with higher exponents:&lt;/p&gt;
    &lt;p&gt;A higher exponent translates to a stronger pull towards zero.&lt;/p&gt;
    &lt;p&gt;Applying an exponent should make dark values darker more quickly than light ones. The example below allows you to vary the exponent applied to the sampling vector:&lt;/p&gt;
    &lt;p&gt;As the exponent is increased to &lt;/p&gt;
    &lt;p&gt;I don’t want that. I want to increase the contrast between the lighter and darker components of the sampling vector, not the vector in its entirety.&lt;/p&gt;
    &lt;p&gt;To achieve that, we can normalize the sampling vector to the range &lt;/p&gt;
    &lt;p&gt;The normalization to &lt;/p&gt;
    &lt;quote&gt;const maxValue = Math.max(...samplingVector)samplingVector = samplingVector.map((value) =&amp;gt; {value = x / maxValue; // Normalizevalue = Math.pow(x, exponent);value = x * maxValue; // Denormalizereturn value;})&lt;/quote&gt;
    &lt;p&gt;Here’s the same example, but with this normalization applied:&lt;/p&gt;
    &lt;p&gt;Very nice! The lightest component values are retained, and the contrast between the lighter and darker components is increased by “crunching” the lower values.&lt;/p&gt;
    &lt;p&gt;This affects which character is picked. The following example shows how the selected character changes as the contrast is increased:&lt;/p&gt;
    &lt;p&gt;Awesome! The pick of &lt;code&gt;"&lt;/code&gt; over &lt;code&gt;T&lt;/code&gt; emphasizes the separation between the lighter region above and the darker region below!&lt;/p&gt;
    &lt;p&gt;By enhancing the contrast of the sampling vector, we exaggerate its shape. This gives us a character that less faithfully represents the underlying image, but improves readability as a whole by enhancing the separation between different colored regions.&lt;/p&gt;
    &lt;p&gt;Let’s look at another example. Observe how the L-shape of the sampling vector below becomes more pronounced as the exponent increases, and how that affects the picked character:&lt;/p&gt;
    &lt;p&gt;Works really nicely! I love the transition from &lt;code&gt;&amp;amp; -&amp;gt; b -&amp;gt; L&lt;/code&gt; as the L-shape of the vector becomes clearer.&lt;/p&gt;
    &lt;p&gt;What’s nice about applying exponents to normalized sampling vectors is that it barely affects vectors that are uniform in value. If all component values are similar, applying an exponent has a minimal effect:&lt;/p&gt;
    &lt;p&gt;Because the vector is fairly uniform, the exponent only has a slight effect and doesn’t change the picked character.&lt;/p&gt;
    &lt;p&gt;This is a good thing! If we have a smooth gradient in our image, we want to retain it. We very much do not want to introduce unnecessary choppiness.&lt;/p&gt;
    &lt;p&gt;Compare the 3D scene ASCII rendering with and without this contrast enhancement:&lt;/p&gt;
    &lt;p&gt;We do see more contrast at boundaries, but this is not quite there yet. Some edges are still not sharp enough, and we also observe a “staircasing” effect happening at some boundaries.&lt;/p&gt;
    &lt;p&gt;Let’s look at the staircasing effect first. We can reproduce it with a boundary like so:&lt;/p&gt;
    &lt;p&gt;Below is the ASCII rendering of that boundary. Notice how the lower edge (the &lt;code&gt;!&lt;/code&gt;s) becomes “staircase-y” as you increase the exponent:&lt;/p&gt;
    &lt;p&gt;We see a staircase pattern like so:&lt;/p&gt;
    &lt;quote&gt;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&lt;/quote&gt;
    &lt;p&gt;To understand why that’s happening, let’s consider the row in the middle of the canvas, progressing from left to right. As we start off, every sample is equally light, giving us &lt;code&gt;U&lt;/code&gt;s:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUU -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;As we reach the boundary, the lower right samples become a bit darker. Those darker components are crunched by contrast enhancement, giving us some &lt;code&gt;Y&lt;/code&gt;s:&lt;/p&gt;
    &lt;p&gt;So we get:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUUYY -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;As we progress further right, the middle and lower samples get darker, so we get some &lt;code&gt;f&lt;/code&gt;s:&lt;/p&gt;
    &lt;p&gt;This trend continues towards &lt;code&gt;"&lt;/code&gt;, &lt;code&gt;'&lt;/code&gt;, and finally, &lt;code&gt;`&lt;/code&gt;:&lt;/p&gt;
    &lt;p&gt;Giving us a sequence like so:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUUYYf""''` -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;That looks good, but at some point we get no light samples. Once we get no light samples, our contrast enhancement has no effect because every component is equally light. This causes us to always get &lt;code&gt;!&lt;/code&gt;s:&lt;/p&gt;
    &lt;p&gt;Making our sequence look like so:&lt;/p&gt;
    &lt;quote&gt;UUUUUUUUYYf""''`!!!!!!!!!! -&amp;gt;&lt;/quote&gt;
    &lt;p&gt;This sudden stop in contrast enhancement having an effect is what causes the staircasing effect:&lt;/p&gt;
    &lt;quote&gt;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&lt;/quote&gt;
    &lt;p&gt;Let’s see how we can counteract this staircasing effect with another layer of contrast enhancement, this time looking outside of the boundary of each cell.&lt;/p&gt;
    &lt;head rend="h3"&gt;Directional contrast enhancement&lt;/head&gt;
    &lt;p&gt;We currently have sampling circles arranged like so:&lt;/p&gt;
    &lt;p&gt;For each of those sampling circles, we’ll specify an “external sampling circle”, placed outside of the cell’s boundary, like so:&lt;/p&gt;
    &lt;p&gt;Each of those external sampling circles is “reaching” into the region of a neighboring cell. Together, the samples that are collected by the external sampling circles constitute an “external sampling vector”.&lt;/p&gt;
    &lt;p&gt;Let’s simplify the visualization and consider a single example. Imagine that we collected a sampling vector and an external sampling vector that look like so:&lt;/p&gt;
    &lt;p&gt;The circles colored red are the external sampling vector components. Currently, they have no effect.&lt;/p&gt;
    &lt;p&gt;The “internal” sampling vector itself is fairly uniform, with values ranging from &lt;/p&gt;
    &lt;p&gt;To enhance this apparent boundary, we’ll darken the top-left and middle-left components of the sampling vector. We can do that by applying component-wise contrast enhancement using the values from the external vector.&lt;/p&gt;
    &lt;p&gt;In the previous contrast enhancement, we calculated the maximum component value across the sampling vector and normalized the vector using that value:&lt;/p&gt;
    &lt;quote&gt;const maxValue = Math.max(...samplingVector)samplingVector = samplingVector.map((value) =&amp;gt; {value = x / maxValue; // Normalizevalue = Math.pow(x, exponent);value = x * maxValue; // Denormalizereturn value;})&lt;/quote&gt;
    &lt;p&gt;But the new component-wise contrast enhancement will take the maximum value between each component of the sampling vector and the corresponding component in the external sampling vector:&lt;/p&gt;
    &lt;quote&gt;samplingVector = samplingVector.map((value, i) =&amp;gt; {const maxValue = Math.max(value, externalSamplingVector[i])// ...});&lt;/quote&gt;
    &lt;p&gt;Aside from that, the contrast enhancement is performed in the same way:&lt;/p&gt;
    &lt;quote&gt;samplingVector = samplingVector.map((value, i) =&amp;gt; {const maxValue = Math.max(value, externalSamplingVector[i]);value = value / maxValue;value = Math.pow(value, exponent);value = value * maxValue;return value;});&lt;/quote&gt;
    &lt;p&gt;The example below shows how light values in the external sampling vector push values in the sampling vector down:&lt;/p&gt;
    &lt;p&gt;I call this “directional contrast enhancement”, since each of the external sampling circles reaches outside of the cell in the direction of the sampling vector component that it is enhancing the contrast of. I describe the other effect as “global contrast enhancement” since it acts on all of the sampling vector’s components together.&lt;/p&gt;
    &lt;p&gt;Let’s see what this directional contrast enhancement does to get rid of the staircasing effect:&lt;/p&gt;
    &lt;p&gt;Hmm, that’s not doing what I wanted. I wanted to see a sequence like so:&lt;/p&gt;
    &lt;quote&gt;..::!!..::!!!!!!!!..::!!!!!!!!!!!!!!&lt;/quote&gt;
    &lt;p&gt;But we just see &lt;code&gt;!&lt;/code&gt; changing to &lt;code&gt;:&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;This happens because the directional contrast enhancement doesn’t reach far enough into our sampling vector. The light upper values in the external vector do push the upper values of the sampling vector down, but because the lightness of the four bottom components is retained, we don’t get to &lt;code&gt;.&lt;/code&gt;, just &lt;code&gt;:&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Widening the directional contrast enhancement&lt;/head&gt;
    &lt;p&gt;I’d like to “widen” the directional contrast enhancement so that, for example, light external values at the top spread to the middle components of the sampling vector.&lt;/p&gt;
    &lt;p&gt;To do that, I’ll introduce a few more external sampling circles, arranged like so:&lt;/p&gt;
    &lt;p&gt;These are a total of &lt;/p&gt;
    &lt;p&gt;For each component of the internal sampling vector, we’ll calculate the maximum value across the external sampling vector components that affect it, and use that maximum to perform the contrast enhancement.&lt;/p&gt;
    &lt;p&gt;Let’s implement that. I’ll order the internal and external sampling circles like so:&lt;/p&gt;
    &lt;p&gt;We can then define a mapping from the internal circles to the external sampling circles that affect them:&lt;/p&gt;
    &lt;quote&gt;const AFFECTING_EXTERNAL_INDICES = [[0, 1, 2, 4],[0, 1, 3, 5],[2, 4, 6],[3, 5, 7],[4, 6, 8, 9],[5, 7, 8, 9],];&lt;/quote&gt;
    &lt;p&gt;With this, we can change the calculation of &lt;code&gt;maxValue&lt;/code&gt; to take the maximum affecting external value:&lt;/p&gt;
    &lt;quote&gt;// Beforeconst maxValue = Math.max(value, externalSamplingVector[i]);// Afterlet maxValue = value;for (const externalIndex of AFFECTING_EXTERNAL_INDICES[i]) {maxValue = Math.max(value, externalSamplingVector[externalIndex]);}&lt;/quote&gt;
    &lt;p&gt;Now look what happens if the top four external sampling circles are light: it causes the contrast enhancement to reach into the middle of the sampling vector, giving us the desired effect:&lt;/p&gt;
    &lt;p&gt;We now smoothly transition from &lt;code&gt;! -&amp;gt; : -&amp;gt; .&lt;/code&gt; — beautiful stuff!&lt;/p&gt;
    &lt;p&gt;Let’s see if this change resolves the staircasing effect:&lt;/p&gt;
    &lt;p&gt;Oh yeah, looks awesome! We get the desired effect. The boundary is nice and sharp while not being too jagged.&lt;/p&gt;
    &lt;p&gt;Here’s the 3D scene again. The contrast slider now applies both types of contrast enhancement at the same time — try it out:&lt;/p&gt;
    &lt;p&gt;This really enhances the contrast at boundaries, making the image far more readable!&lt;/p&gt;
    &lt;p&gt;Together, the 6D shape vector approach and contrast enhancement techniques have given us a really nice final ASCII rendering.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final words&lt;/head&gt;
    &lt;p&gt;This post was really fun to build and write! I hope you enjoyed reading it.&lt;/p&gt;
    &lt;p&gt;ASCII rendering is perhaps not the most useful topic to write about, but I think the idea of using a high-dimensional vector to capture shape is interesting and could easily be applied to many other problems. There are parallels to be drawn to word embeddings.&lt;/p&gt;
    &lt;p&gt;I started writing this ASCII renderer to see if the idea of using a vector to capture the shape of characters would work at all. That approach turned out to work very well, but the initial prototype was terribly slow — I only got single-digit FPS on my iPhone. To get the ASCII renderer running at a smooth &lt;/p&gt;
    &lt;p&gt;My colleagues, after reading a draft of this post, suggested many alternatives to the approaches I described in this post. For example, why not make the sampling vector &lt;code&gt;T&lt;/code&gt; far better — just look how &lt;code&gt;T&lt;/code&gt;’s stem falls between the two sampling circles in each row:&lt;/p&gt;
    &lt;p&gt;And yeah, he’s right! A &lt;/p&gt;
    &lt;p&gt;It’s really fun how large the solution space to the problem of ASCII rendering is. There are so, so many approaches and trade-offs to explore. I imagine you probably thought of a few yourself while reading this post!&lt;/p&gt;
    &lt;p&gt;One dimension I intentionally did not explore was using different colors or lightnesses for the ASCII characters themselves. This is for many reasons, but the two primary ones are that 1) it would have expanded the scope of this post too much, and 2) it’s just a different effect, and I personally don’t like the look.&lt;/p&gt;
    &lt;p&gt;At the time of writing these final words, around &lt;/p&gt;
    &lt;p&gt;Thanks for reading! And huge thanks to Gunnlaugur Þór Briem and Eiríkur Fannar Torfason for reading and providing feedback on a draft of this post.&lt;/p&gt;
    &lt;p&gt;— Alex Harri&lt;/p&gt;
    &lt;p&gt;To be notified of new posts, subscribe to my mailing list.&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix I: Character lookup performance&lt;/head&gt;
    &lt;p&gt;Earlier in this post, I showed how can find the best character by finding the character with the shortest Euclidean distance to our sampling vector.&lt;/p&gt;
    &lt;quote&gt;function findBestCharacter(inputVector: number[]) {let bestCharacter = "";let bestDistance = Infinity;for (const { character, shapeVector } of CHARACTERS) {const dist = getDistance(shapeVector, inputVector);if (dist &amp;lt; bestDistance) {bestDistance = dist;bestCharacter = character;}}return bestCharacter;}&lt;/quote&gt;
    &lt;p&gt;I tried benchmarking this for &lt;/p&gt;
    &lt;p&gt;If we allow ourselves &lt;/p&gt;
    &lt;head rend="h3"&gt;k-d trees&lt;/head&gt;
    &lt;p&gt;Internally, &lt;/p&gt;
    &lt;p&gt;I won’t go into much detail on &lt;/p&gt;
    &lt;p&gt;One could also look at the hierarchical navigable small worlds (HNSW) algorithm, which Eiríkur pointed me to. It is used for approximate nearest neighbor lookups in vector databases, so definitely relevant.&lt;/p&gt;
    &lt;p&gt;Let’s see how it performs! We’ll construct a &lt;/p&gt;
    &lt;quote&gt;const kdTree = new KdTree(CHARACTERS.map(({ character, shapeVector }) =&amp;gt; ({point: shapeVector,data: character,})));&lt;/quote&gt;
    &lt;p&gt;We can now perform nearest-neighbor lookups on the &lt;/p&gt;
    &lt;quote&gt;const result = kdTree.findNearest(samplingVector);&lt;/quote&gt;
    &lt;p&gt;Running &lt;/p&gt;
    &lt;p&gt;That’s a lot of lookups per frame, but again, we’re benchmarking on a powerful machine. This is still not good enough.&lt;/p&gt;
    &lt;p&gt;Let’s see how we can eke out even more performance.&lt;/p&gt;
    &lt;head rend="h3"&gt;Caching&lt;/head&gt;
    &lt;p&gt;An obvious avenue for speeding up lookups is to cache the result:&lt;/p&gt;
    &lt;quote&gt;function searchCached(samplingVector: number[]) {const key = generateCacheKey(samplingVector)if (cache.has(key)) {return cache.get(key)!;}const result = search(samplingVector);cache.set(key, result);return result;}&lt;/quote&gt;
    &lt;p&gt;But how does one generate a cache key for a &lt;/p&gt;
    &lt;p&gt;Well, one way is to quantize each vector component so that it fits into a set number of bits and packing those bits into a single number. JavaScript numbers give us &lt;/p&gt;
    &lt;p&gt;We can quantize a numeric value between &lt;/p&gt;
    &lt;quote&gt;const BITS = 5;const RANGE = 2 ** BITS;function quantizeTo5Bits(value: number) {return Math.min(RANGE - 1, Math.floor(value * RANGE));}&lt;/quote&gt;
    &lt;p&gt;Applying a max of &lt;code&gt;RANGE - 1&lt;/code&gt; is done so that a &lt;code&gt;value&lt;/code&gt; of exactly &lt;/p&gt;
    &lt;p&gt;We can quantize each of the sampling vector components in this manner and use bit shifting to pack all of the quantized values into a single number like so:&lt;/p&gt;
    &lt;quote&gt;const BITS = 5;const RANGE = 2 ** BITS;function generateCacheKey(vector: number[]): number {let key = 0;for (let i = 0; i &amp;lt; vector.length; i++) {const quantized = Math.min(RANGE - 1, Math.floor(vector[i] * RANGE));key = (key &amp;lt;&amp;lt; BITS) | quantized;}return key;}&lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;RANGE&lt;/code&gt; is current set to &lt;code&gt;2 ** 5&lt;/code&gt;, but consider how large that makes our key space. Each vector component is one of &lt;/p&gt;
    &lt;p&gt;Alright, &lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Range&lt;/cell&gt;
        &lt;cell role="head"&gt;Number of keys&lt;/cell&gt;
        &lt;cell role="head"&gt;Memory needed to store keys&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;46,656&lt;/cell&gt;
        &lt;cell&gt;364 KB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;117,649&lt;/cell&gt;
        &lt;cell&gt;919 KB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;262,144&lt;/cell&gt;
        &lt;cell&gt;2.00 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;531,441&lt;/cell&gt;
        &lt;cell&gt;4.05 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;1,000,000&lt;/cell&gt;
        &lt;cell&gt;7.63 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;1,771,561&lt;/cell&gt;
        &lt;cell&gt;13.52 MB&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;2,985,984&lt;/cell&gt;
        &lt;cell&gt;22.78 MB&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;There are trade-offs to consider here. As the range gets smaller, the quality of the results drops. If we pick a range of &lt;/p&gt;
    &lt;p&gt;At the same time, if we increase the possible number of keys, we need more memory to store them. Additionally, the cache hit rate might be very low, especially when the cache is relatively empty.&lt;/p&gt;
    &lt;p&gt;I ended up picking a range of &lt;/p&gt;
    &lt;p&gt;Cached lookups are incredibly fast — fast enough that lookup performance just isn’t a concern anymore (&lt;/p&gt;
    &lt;head rend="h2"&gt;Appendix II: GPU acceleration&lt;/head&gt;
    &lt;p&gt;Lookups were not the only performance concern. Just collecting the sampling vectors (internal and external) turned out to be terribly expensive.&lt;/p&gt;
    &lt;p&gt;Just consider the sheer amount of samples that need to be collected. The 3D scene I’ve been using as an example uses a &lt;/p&gt;
    &lt;p&gt;And that’s if we use a sampling quality of &lt;/p&gt;
    &lt;p&gt;Collecting these samples absolutely crushed performance on my iPhone, so I needed to either collect fewer samples or speed up the collection of samples. Collecting fewer samples would have meant rendering fewer ASCII characters or removing the directional contrast enhancement, neither of which was an appealing solution.&lt;/p&gt;
    &lt;p&gt;My initial implementation ran on the CPU, which could only collect one sample at a time. To speed this up, I moved the work of sampling collection and applying the contrast enhancement to the GPU. The pipeline for that looks like so (each of the steps listed is a single shader pass):&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Collect the raw internal sampling vectors into a &lt;mjx-container/&gt;texture, using the canvas (image) as the input texture.&lt;/item&gt;
      &lt;item&gt;Do the same for the external sampling vectors.&lt;/item&gt;
      &lt;item&gt;Calculate the maximum external value affecting each internal vector component into a &lt;mjx-container/&gt;texture.&lt;/item&gt;
      &lt;item&gt;Apply directional contrast enhancement to each sampling vector component, using the maximum external values texture.&lt;/item&gt;
      &lt;item&gt;Calculate the maximum value for each internal sampling vector into a &lt;mjx-container/&gt;texture.&lt;/item&gt;
      &lt;item&gt;Apply global contrast enhancement to each sampling vector component, using the maximum internal values texture.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m glossing over the details because I could spend a whole other post covering them, but moving work to the GPU made the renderer many times more performant than it was when everything ran on the CPU.&lt;/p&gt;
    &lt;p&gt;To be notified of new posts, subscribe to my mailing list.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexharri.com/blog/ascii-rendering"/><published>2026-01-17T11:15:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46657141</id><title>Architecture for Disposable Systems</title><updated>2026-01-17T17:08:57.489545+00:00</updated><content>&lt;doc fingerprint="2b4d3dde2be75ffc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Architecture for Disposable Systems&lt;/head&gt;
    &lt;head rend="h5"&gt;Posted on January 15, 2026 • 3 minutes • 595 words&lt;/head&gt;
    &lt;p&gt;As software gets cheaper to produce (thanks to coding agents) and quality expectations shift, we’re witnessing the rise of disposable software: code that you generate, use, and discard rather than maintain indefinitely.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Traditional Model&lt;/head&gt;
    &lt;p&gt;Traditional software follows a well-established pattern: you build something once, maintain it indefinitely, and pay for it through high upfront capital and long-term maintenance costs. The economics made sense because rewriting was expensive. We accepted spending 80% of a project’s lifecycle on maintenance because the alternative (starting over) was often prohibitive (until the product reaches its EOL)&lt;/p&gt;
    &lt;p&gt;This created a culture of careful engineering: clean code, thoughtful architecture, and refactoring to reduce technical debt. We optimized for the long term because the long term was inevitable. We have to live with it.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Disposable Shift&lt;/head&gt;
    &lt;p&gt;But what happens when an agent can regenerate a functional replacement from a prompt in 5 minutes? The incentive to “clean up technical debt” or “refactor for the long term” vanishes. If the code works now and you can regenerate it later, why invest in perfection?&lt;/p&gt;
    &lt;p&gt;We’re already seeing the rise of “vibe coding”: building tools that solve a problem right now. Need a specific data parser? Generate it. Need a one-off dashboard for a meeting? Generate it. Use it, and if it breaks or becomes obsolete, delete it and generate a new one. You don’t care if the code is “clean” as long as the output is correct.&lt;/p&gt;
    &lt;p&gt;This isn’t laziness. It’s a fundamental shift in the economics of software development. When generation is cheap, maintenance becomes the expensive option.&lt;/p&gt;
    &lt;head rend="h2"&gt;Architecture for Disposable Systems&lt;/head&gt;
    &lt;p&gt;If we’re moving toward disposable software, how do we architect systems that can survive this shift? The answer lies in a three-layer model:&lt;/p&gt;
    &lt;head rend="h3"&gt;The Core (Durable)&lt;/head&gt;
    &lt;p&gt;The Source of Truth. This is the hardened, human-written, slow-changing foundation of your system. It contains your critical business logic, data models, and core algorithms. This layer is built to last because it represents the fundamental value of your system.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Connectors (APIs)&lt;/head&gt;
    &lt;p&gt;Immutable contracts. These are the interfaces that define how components communicate. They must be perfect because the disposable parts can be imperfect. If your API contract is solid, you can swap out implementations underneath without breaking the system.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Disposable Layer&lt;/head&gt;
    &lt;p&gt;AI-generated “glue” code, data parsers, UI components, and integration scripts. This is where the vibe coding happens. Generate it, use it, and regenerate it when needed. As long as it adheres to the contracts defined by the Connectors layer, it doesn’t matter how messy the internals are.&lt;/p&gt;
    &lt;head rend="h2"&gt;Contract-First Design&lt;/head&gt;
    &lt;p&gt;The key to making this work is contract-first design. Instead of coding to an implementation, we must code to a strict schema: OpenAPI, gRPC, Smithy, or whatever standard fits your domain. The agent is given the schema as a constraint, and as long as the inputs and outputs match the contract, we don’t care how messy the logic inside the box is.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The critical principle: Immutable contracts. They must be perfect so the disposable parts can be imperfect.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This approach allows you to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Regenerate components without breaking the system&lt;/item&gt;
      &lt;item&gt;Test contracts independently of implementations&lt;/item&gt;
      &lt;item&gt;Evolve the disposable layer while keeping the core stable&lt;/item&gt;
      &lt;item&gt;Accept lower-quality generated code because it’s constrained by high-quality contracts&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The Future&lt;/head&gt;
    &lt;p&gt;We’re not there yet, but the trajectory is clear. As coding agents improve and generation costs drop, more and more software will become disposable. The systems that survive will be those built with durable cores, immutable contracts, and disposable peripherals.&lt;/p&gt;
    &lt;p&gt;The question isn’t whether this shift will happen. It’s whether your architecture is ready for it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tuananh.net/2026/01/15/architecture-for-disposable-systems/"/><published>2026-01-17T11:18:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46657296</id><title>The 600-year-old origins of the word 'hello'</title><updated>2026-01-17T17:08:56.999831+00:00</updated><content>&lt;doc fingerprint="b2309d8d8fa112dc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;'Hullo, hillo, holla': The 600-year-old origins of the word 'hello'&lt;/head&gt;
    &lt;p&gt;It's been 200 years since the word "hello" was first used in print – though its beginnings date back to the 15th Century. How has the language of greetings evolved around the world - and what does it tell us about ourselves?&lt;/p&gt;
    &lt;p&gt;We use "hello" dozens of times a day without thinking – during phone calls, emails and face-to-face encounters. We sing it along with Adele and Lionel Richie, and we have watched it spun into moments of screen gold in Jerry Maguire ("You had me at hello"), and Scarface ("Say hello to my little friend!"). It's been used to sell everything from mobile phones (Motorola's "Hello, Moto") to lingerie (Wonderbra's iconic "Hello boys"), and it has been borrowed to name computer programs and celebrity magazines.&lt;/p&gt;
    &lt;p&gt;In print, this ubiquitous, friendly greeting has a surprisingly short history. Two centuries ago, on 18 January 1826, "hello" made what is thought to be its earliest recorded appearance on the page, in a Connecticut newspaper called The Norwich Courier. Hidden among the column inches, it was a modest in-ink debut for a word that would go on to greet much of the modern world.&lt;/p&gt;
    &lt;p&gt;By the 1850s, it had crossed the Atlantic to Britain – appearing in publications such as the London Literary Gazette – and became increasingly common in print. Like the go-to greetings in other languages, "hello" also says something about the English-speaking world – depending on which variation, abbreviation or inflection of the word we choose to use.&lt;/p&gt;
    &lt;p&gt;There are plenty of such forms. Whether due to dialect or accent influences, or the brevity demanded by online communication, which "hello" you choose says a lot about you, and can indicate age, nationality, or even mood. According to linguists, elongated variations such as "heyyy" could be construed as flirtatious, "hellaw" might suggest you're from the southern US, "howdy" from western US, and the clipped "hi" may indicate a curt disposition.&lt;/p&gt;
    &lt;p&gt;"It can be pronounced and inflected in many different ways, and these subtle intonational contours can change its meaning," says Alessandro Duranti, professor of linguistic anthropology at the University of California, Los Angeles. "For example, when someone says 'hello' with a stretched final vowel, it can question what the other person just said, as in 'Hello, are you paying attention?' or 'Hello, you must be kidding.'"&lt;/p&gt;
    &lt;p&gt;This capacity to convey nuance through tone and form is no modern invention; even in its first printed appearances, "hello" was a patchwork of influences, derivations and applications drawn from several languages.&lt;/p&gt;
    &lt;head rend="h2"&gt;The origins of hello&lt;/head&gt;
    &lt;p&gt;The pre-printed origins of the word "hello" are disputed. The most commonly cited etymology is the Old High German "halâ" – a cry historically used to hail a ferryman. The Oxford English Dictionary also points to "halloo" (a hunting call that urged hounds to run faster) as a possible linguistic root. It notes several early spellings, including "hullo", "hillo" and "holla" – the latter thought to have derived from the 15th-Century French "hol", an exclamation meaning "whoa!" or "stop!". In English sources, the OED lists the earliest form as the late-16th-Century "hollo".&lt;/p&gt;
    &lt;p&gt;Simon Horobin, professor of English language and literature at Magdelen College, Oxford, notes that such semantic shifts and spelling changes may also be explained by regional accents and differences in pronunciation. "Especially in the example of 'ello' which shows the prevalent – though now stigmatised – feature of h-dropping," he tells the BBC, referring to the classist English stereotype of a dropped 'h' indicating a lack of education.&lt;/p&gt;
    &lt;p&gt;"But for origins and early history," he adds, "we are dependent upon written evidence, which is patchy at the best of times. For a colloquial word like this, which would have appeared much earlier and more frequently in speech than in writing, it is especially tricky to establish a definite timeline."&lt;/p&gt;
    &lt;p&gt;More like this:&lt;/p&gt;
    &lt;p&gt;• The most powerful word in the English language&lt;/p&gt;
    &lt;p&gt;• The surprising history of the word 'dude'&lt;/p&gt;
    &lt;p&gt;• The subtle way language shapes us&lt;/p&gt;
    &lt;p&gt;The selection of a standardised word form, Horobin explains, usually falls to lexicographers – those who compile dictionaries. "They base their choice on the relative prevalence of a particular spelling, though it's necessarily somewhat provisional and arbitrary."&lt;/p&gt;
    &lt;p&gt;By the time the Oxford English Dictionary first went to press in 1884, "hello" was emerging as the dominant form of the greeting. Charles Dickens, however, spent the 19th Century using "hullo" in his writings, and Alexander Graham Bell (who once argued that "ahoy!" would make a superior telephone greeting) stuck with "halloo". Bell's rival, Thomas Edison, championed "hello", believing it would carry clearly over even the worst phone lines. Like that of The Norwich Courier before him, Edison's backing helped – and "hello" was established as the English-language greeting to beat.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hello around the world&lt;/head&gt;
    &lt;p&gt;While the English language settled on "hello" as its customary greeting, other languages forged their own. Some were influenced by English, others developed independently – yet each carries a distinct cultural flavour, hinting at the social norms and stereotypes we have of the people who use it.&lt;/p&gt;
    &lt;p&gt;In Germanic and Scandinavian languages, for example, "hallo" and "hallå" are phonetically harder and feel more efficient and no-nonsense than the lyrical, almost poetic quality of "hola" and "olá", favoured by the Romance languages that are associated with more effusive stereotypes. Elsewhere, some greetings carry traces of national history: from the Dutch-derived "hallo" of Afrikaans to "óla" in Tetum, a reminder of Portuguese influence in Timor-Leste. Many such words appear to function as both introduction and identity marker. But, says Professor Duranti, it's not quite that simple.&lt;/p&gt;
    &lt;p&gt;"It's hard to go straight from the use of a particular greeting to a national character, even though it is tempting," he tells the BBC. Alternative or secondary greetings, Duranti suggests, may offer better clues. "In English, given the common use of 'how are you?', there is an apparent interest in people's wellbeing." In some Polynesian societies, he adds, greetings are less about a word-for-word "hello" than about checking in on someone's plans or movements – literally asking "where are you going?". Greek, meanwhile, uses "Γειά σου" (pronounced "yah-soo") as a typical informal greeting, offering a wish for health rather than a simple salutation. It is also usable for "goodbye".&lt;/p&gt;
    &lt;p&gt;Other languages also turn abstract concepts into multipurpose greetings that serve as both "hi" and "bye". "Ciao" comes from a Venetian dialect phrase meaning "at your service", and the French "salut" is an informal expression used for both greeting and parting company. Similarly, the Hawaiian "aloha" can express affection or compassion, and the Hebrew "shalom" peace or wholeness. Yet, as Duranti cautions, even these evocative examples shouldn't be viewed as cut-and-dry indicators of national character.&lt;/p&gt;
    &lt;p&gt;"I would be careful making that kind of correlation," he explains. "Especially about the semantics of it – health versus sympathy versus whereabouts. But there is one aspect of greetings that is sensitive to the social structure of a society, which is that equals greet each other in different ways from people of different statuses. In fact, greetings can be seen to define levels of intimacy or social distance." In this sense, he adds, greetings are like magnets – confidently announcing who we are, and drawing in those we want to be associated with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hello in the digital age&lt;/head&gt;
    &lt;p&gt;If greetings act as social magnets, then technology has quietly altered their pull. Over the past few decades, the rise of email, texting and social media has reshaped not just how often we say "hello", but what we might replace it with – and whether we say it at all.&lt;/p&gt;
    &lt;p&gt;"If you think about WhatsApp, we're basically always in conversation – we're always online," says Christian Ilbury, senior lecturer in linguistics and English language at the University of Edinburgh. "When someone asks you how your day is or whether you're going to be on time for the meal, you don't always have to say 'hello' first, because it's unlikely the last message concluded with 'bye'."&lt;/p&gt;
    &lt;p&gt;In a text-led, always-on world, greetings have proved especially susceptible to change and, as they are used so often, their evolution has accelerated dramatically. Ilbury has identified many non-standard and creative spellings of "hello" in his studies of digital language, from "hellooooo" and "hiiiiiii" to "heyyyyy". Yet, while tech has made it easier for us to elongate words in this way, Ilbury points out that most modern-day greetings are short, sharp and driven by brevity.&lt;/p&gt;
    &lt;p&gt;"The most obvious thing to say is that people now sometimes use an emoji – the wave – in place of the word 'hello'," says Ilbury. "But technology has always contributed to language change. We now 'Google' stuff and 'unfriend' people. Like any major invention – AI, for instance – we're bound to get some new vocabulary from that source."&lt;/p&gt;
    &lt;p&gt;In many ways, this mirrors the instability of "hello" in the early 19th Century, when the greeting may have sounded vaguely the same whenever spoken, but varied widely in spelling when written down. By shortening the established greeting, or replacing it with icons and abbreviations, it's made clear that such salutations remain as fluid as they were before The Norwich Couriermade its landmark linguistic choice in 1826.&lt;/p&gt;
    &lt;p&gt;But for all its so-called standardisation, "hello" has never really stood still. It began as a shout, a summons, a way to hail attention, before settling – briefly – into an accepted spelling and usage. Two centuries on from its print debut, the greeting is once again being stretched, clipped, replaced or ignored altogether. Yet whether it's spoken aloud, typed hastily, or reduced to a small waving hand on a screen, the impulse behind it remains the same: an act of recognition, the announcing of one's presence and just asking – however casually – to be acknowledged in return.&lt;/p&gt;
    &lt;p&gt;--&lt;/p&gt;
    &lt;p&gt;If you liked this story, sign up for The Essential List newsletter – a handpicked selection of features, videos and can't-miss news, delivered to your inbox twice a week.&lt;/p&gt;
    &lt;p&gt;For more Culture stories from the BBC, follow us on Facebook and Instagram.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/culture/article/20260113-hello-hiya-aloha-what-our-greetings-reveal"/><published>2026-01-17T11:51:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46657719</id><title>The Risks of AI in Schools Outweigh the Benefits, Report Says</title><updated>2026-01-17T17:08:56.466453+00:00</updated><content>&lt;doc fingerprint="1e1e3318088f9def"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The risks of AI in schools outweigh the benefits, report says&lt;/head&gt;
    &lt;p&gt;The risks of using generative artificial intelligence to educate children and teens currently overshadow the benefits, according to a new study by the Brookings Institution's Center for Universal Education.&lt;/p&gt;
    &lt;p&gt;The sweeping study includes focus groups and interviews with K-12 students, parents, educators and tech experts in 50 countries, as well as a literature review of hundreds of research articles. It found that using AI in education can "undermine children's foundational development" and that "the damages it has already caused are daunting," though "fixable."&lt;/p&gt;
    &lt;p&gt;Because generative AI is still young — ChatGPT was released just over three years ago — the report's authors dubbed their review a "premortem" intended to study AI's potential in the classroom without a postmortem's benefits of time, long-term data or hindsight.&lt;/p&gt;
    &lt;p&gt;Here are some of the pros and cons that the report lays out, along with a sampling of the study's recommendations for teachers, parents, school leaders and government officials:&lt;/p&gt;
    &lt;head rend="h3"&gt;Pro: AI can help students learn to read and write&lt;/head&gt;
    &lt;p&gt;Teachers surveyed for the report said AI can be useful when it comes to language acquisition, especially for students learning a second language. For example, AI can adjust the complexity of a passage depending on the reader's skill, and it offers privacy for students who struggle in large-group settings.&lt;/p&gt;
    &lt;p&gt;Teachers reported that AI can also help improve students' writing, so long as it is used to support students' efforts and not to do the work for them: "Teachers report that AI can 'spark creativity' and help students overcome writer's block. … At the drafting stage, it can help with organization, coherence, syntax, semantics, and grammar. At the revision stage, AI can support the editing and rewriting of ideas as well as help with … punctuation, capitalization, and grammar."&lt;/p&gt;
    &lt;p&gt;But, if there is a refrain in the report, it is this: AI is most useful when it's supplementing, not replacing, the efforts of a flesh-and-blood teacher.&lt;/p&gt;
    &lt;head rend="h3"&gt;Con: AI poses a grave threat to students' cognitive development&lt;/head&gt;
    &lt;p&gt;At the top of Brookings' list of risks is the negative effect AI can have on children's cognitive growth — how they learn new skills and perceive and solve problems.&lt;/p&gt;
    &lt;p&gt;The report describes a kind of doom loop of AI dependence, where students increasingly off-load their own thinking onto the technology, leading to the kind of cognitive decline or atrophy more commonly associated with aging brains.&lt;/p&gt;
    &lt;p&gt;Rebecca Winthrop, one of the report's authors and a senior fellow at Brookings, warns, "When kids use generative AI that tells them what the answer is … they are not thinking for themselves. They're not learning to parse truth from fiction. They're not learning to understand what makes a good argument. They're not learning about different perspectives in the world because they're actually not engaging in the material."&lt;/p&gt;
    &lt;p&gt;Cognitive off-loading isn't new. The report points out that keyboards and computers reduced the need for handwriting, and calculators automated basic math. But AI has "turbocharged" this kind of off-loading, especially in schools where learning can feel transactional.&lt;/p&gt;
    &lt;p&gt;As one student told the researchers, "It's easy. You don't need to (use) your brain."&lt;/p&gt;
    &lt;p&gt;The report offers a surfeit of evidence to suggest that students who use generative AI are already seeing declines in content knowledge, critical thinking and even creativity. And this could have enormous consequences if these young people grow into adults without learning to think critically.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pro: AI can make teachers' jobs a little easier&lt;/head&gt;
    &lt;p&gt;The report says another benefit of AI is that it allows teachers to automate some tasks: "generating parent emails … translating materials, creating worksheets, rubrics, quizzes, and lesson plans" — and more.&lt;/p&gt;
    &lt;p&gt;The report cites multiple research studies that found important time-saving benefits for teachers, including one U.S. study that found that teachers who use AI save an average of nearly six hours a week and about six weeks over the course of a full school year.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pro/Con: AI can be an engine of equity — or inequity&lt;/head&gt;
    &lt;p&gt;One of the strongest arguments in favor of AI's educational use, according to the Brookings report, is its ability to reach children who have been excluded from the classroom. The researchers cite Afghanistan, where girls and women have been denied access to formal, postprimary education by the Taliban.&lt;/p&gt;
    &lt;p&gt;According to the report, one program for Afghan girls "has employed AI to digitize the Afghan curriculum, create lessons based on this curriculum, and disseminate content in Dari, Pashto, and English via WhatsApp lessons."&lt;/p&gt;
    &lt;p&gt;AI can also help make classrooms more accessible for students with a wide range of learning disabilities, including dyslexia.&lt;/p&gt;
    &lt;p&gt;But "AI can massively increase existing divides" too, Winthrop warns. That's because the free AI tools that are most accessible to students and schools can also be the least reliable and least factually accurate.&lt;/p&gt;
    &lt;p&gt;"We know that richer communities and schools will be able to afford more advanced AI models," Winthrop says, "and we know those more advanced AI models are more accurate. Which means that this is the first time in ed-tech history that schools will have to pay more for more accurate information. And that really hurts schools without a lot of resources."&lt;/p&gt;
    &lt;head rend="h3"&gt;Con: AI poses serious threats to social and emotional development&lt;/head&gt;
    &lt;p&gt;Survey responses revealed deep concern that use of AI, particularly chatbots, "is undermining students' emotional well-being, including their ability to form relationships, recover from setbacks, and maintain mental health," the report says.&lt;/p&gt;
    &lt;p&gt;One of the many problems with kids' overuse of AI is that the technology is inherently sycophantic — it has been designed to reinforce users' beliefs.&lt;/p&gt;
    &lt;p&gt;Winthrop says that if children are building social-emotional skills largely through interactions with chatbots that were designed to agree with them, "it becomes very uncomfortable to then be in an environment when somebody doesn't agree with you."&lt;/p&gt;
    &lt;p&gt;Winthrop offers an example of a child interacting with a chatbot, "complaining about your parents and saying, 'They want me to wash the dishes — this is so annoying. I hate my parents.' The chatbot will likely say, 'You're right. You're misunderstood. I'm so sorry. I understand you.' Versus a friend who would say, 'Dude, I wash the dishes all the time in my house. I don't know what you're complaining about. That's normal.' That right there is the problem."&lt;/p&gt;
    &lt;p&gt;A recent survey from the Center for Democracy and Technology, a nonprofit that advocates for civil rights and civil liberties in the digital age, found that nearly 1 in 5 high schoolers said they or someone they know has had a romantic relationship with artificial intelligence. And 42% of students in that survey said they or someone they know has used AI for companionship.&lt;/p&gt;
    &lt;p&gt;The report warns that AI's echo chamber can stunt a child's emotional growth: "We learn empathy not when we are perfectly understood, but when we misunderstand and recover," one of the surveyed experts said.&lt;/p&gt;
    &lt;head rend="h3"&gt;What to do about it&lt;/head&gt;
    &lt;p&gt;The Brookings report offers a long list of recommendations to help parents, teachers and policymakers — not to mention tech companies themselves — harness the good of AI without subjecting children to the risks that the technology currently poses. Among those recommendations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Schooling itself could be less focused on what the report calls "transactional task completion" or a grade-based endgame and more focused on fostering curiosity and a desire to learn. Students will be less inclined to ask AI to do the work for them if they feel engaged by that work.&lt;/item&gt;
      &lt;item&gt;AI designed for use by children and teens should be less sycophantic and more "antagonistic," pushing back against preconceived notions and challenging users to reflect and evaluate.&lt;/item&gt;
      &lt;item&gt;Tech companies could collaborate with educators in "co-design hubs." In the Netherlands, a government-backed hub already brings together tech companies and educators to develop, test and evaluate new AI applications in the classroom.&lt;/item&gt;
      &lt;item&gt;Holistic AI literacy is crucial — both for teachers and students. Some countries, including China and Estonia, have comprehensive, national AI literacy guidelines.&lt;/item&gt;
      &lt;item&gt;As schools continue to embrace AI, it's important that underfunded districts in marginalized communities are not left behind, allowing AI to further drive inequity.&lt;/item&gt;
      &lt;item&gt;Governments have a responsibility to regulate the use of AI in schools, making sure that the technology being used protects students' cognitive and emotional health, as well as their privacy. In the U.S., the Trump administration has tried to prohibit states from regulating AI on their own, even as Congress has so far failed to create a federal regulatory framework.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With this "premortem," the authors argue, the time to act is now. AI's risks to children and teens are already abundant and obvious. The good news is: so are many of the remedies.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.npr.org/2026/01/14/nx-s1-5674741/ai-schools-education"/><published>2026-01-17T12:59:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46658014</id><title>Italy investigates Activision Blizzard for pushing in-game purchases</title><updated>2026-01-17T17:08:56.265379+00:00</updated><content>&lt;doc fingerprint="adfc8d79ca9ab8b1"&gt;
  &lt;main&gt;
    &lt;p&gt;Italy has launched two investigations into Microsoft’s Activision Blizzard, alleging the company has engaged in “misleading and aggressive” sales practices for its popular smartphone games Diablo Immortal and Call of Duty Mobile.&lt;/p&gt;
    &lt;p&gt;The country’s competition regulator, Autorità Garante della Concorrenza E Del Mercato (AGCM), said the investigations focus on the use of design elements to induce users, particularly children, into playing for long periods, and make in-game purchases by urging them to not miss out on rewards.&lt;/p&gt;
    &lt;p&gt;“These practices, together with strategies that make it difficult for users to understand the real value of the virtual currency used in the game and the sale of in-game currency in bundles, may influence players as consumers — including minors — leading them to spend significant amounts, sometimes exceeding what is necessary to progress in the game and without being fully aware of the expenditure involved,” the AGCM wrote in a statement.&lt;/p&gt;
    &lt;p&gt;The AGCM said the games are advertised as free-to-play but offer in-game purchases.&lt;/p&gt;
    &lt;p&gt;That isn’t particularly surprising, however, as, unlike full-priced games, free-to-play games have long relied on loot boxes and sales of in-game cosmetics for monetization. Diablo Immortal, for example, offers in-game cosmetics, as well as currency that allows players to accelerate their progression and gain items for crafting, for as much as $200.&lt;/p&gt;
    &lt;p&gt;Given the nature of the game, it’s not unusual for many users to repeatedly spend on such items in the course of play.&lt;/p&gt;
    &lt;p&gt;Both Diablo Immortal and Call of Duty Mobile have player bases in the hundreds of thousands.&lt;/p&gt;
    &lt;p&gt;The authority is also looking into the games’ parental control features, as the default settings lets minors make in-game purchases, play for long periods without restraints, and allow them to chat with others in-game. The AGCM also highlighted privacy concerns, as the games appear to lead users to select all consent options when signing up, and said it would look into the company’s consent process for harvesting and using personal data.&lt;/p&gt;
    &lt;p&gt;“In the Authority’s view, the company may be acting in breach of consumer protection rules and, in particular, the duty of professional diligence required in a sector that is particularly sensitive to the risks of gaming-related addiction,” the regulator said.&lt;/p&gt;
    &lt;p&gt;Activision Blizzard did not immediately respond to a request for comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://techcrunch.com/2026/01/16/italy-investigates-activision-blizzard-for-pushing-in-game-purchases/"/><published>2026-01-17T13:44:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46658345</id><title>The recurring dream of replacing developers</title><updated>2026-01-17T17:08:55.956980+00:00</updated><content>&lt;doc fingerprint="d5de5d392af7abd9"&gt;
  &lt;main&gt;
    &lt;p&gt;07.12.2025, By Stephan Schwab&lt;/p&gt;
    &lt;p&gt;Every decade brings new promises: this time, we'll finally make software development simple enough that we won't need so many developers. From COBOL to AI, the pattern repeats. Business leaders grow frustrated with slow delivery and high costs. Developers feel misunderstood and undervalued. Understanding why this cycle persists for fifty years reveals what both sides need to know about the nature of software work.&lt;/p&gt;
    &lt;p&gt;When Neil Armstrong stepped onto the lunar surface in 1969, the world witnessed what organized human ingenuity could accomplish. Behind that achievement stood Margaret Hamilton and her team, writing Apollo’s guidance software by hand, catching critical errors through careful review, and proving that software could be mission-critical.&lt;/p&gt;
    &lt;p&gt;The Apollo program demonstrated that software development was essential to achieving the impossible. Yet it also revealed something that would frustrate business leaders for decades to come: writing software required specialized knowledge, intense focus, and significant time investment. The dream of making it easier—of needing fewer of these expensive specialists—began almost immediately.&lt;/p&gt;
    &lt;p&gt;The late 1960s and 1970s saw COBOL emerge with an explicit goal stated in its name: Common Business-Oriented Language. The vision was clear: make the language read like English sentences, and business analysts would write their own programs. No need for specialized programmers.&lt;/p&gt;
    &lt;p&gt;This vision had genuine appeal. Software was becoming essential to business operations, yet programmers remained a scarce, expensive resource. COBOL promised to democratize software creation.&lt;/p&gt;
    &lt;p&gt;What happened instead? COBOL became another programming language requiring specialized training. Business analysts who tried to write COBOL quickly discovered that readable syntax didn’t eliminate the complexity of logic, data structures, or system design. A new class of COBOL programmers emerged, and the dream of eliminating specialized developers remained unfulfilled.&lt;/p&gt;
    &lt;p&gt;Yet the dream didn’t die. It simply waited for the next technological wave.&lt;/p&gt;
    &lt;p&gt;Computer-Aided Software Engineering tools arrived in the 1980s with tremendous promise. Draw flowcharts and entity-relationship diagrams, and the tool would generate working code. The marketing message resonated: visual design was more intuitive than typing cryptic commands. Business experts could model their processes, and software would materialize.&lt;/p&gt;
    &lt;p&gt;Organizations invested heavily. Vendors promised productivity increases of 10x or more. Yet most CASE tool initiatives struggled or failed outright.&lt;/p&gt;
    &lt;p&gt;The generated code often required substantial manual intervention. Performance problems emerged. Maintenance became a nightmare when generated code diverged from the visual models. Most critically, drawing accurate diagrams required understanding the same logical complexity that programming demanded. The tool changed the interface but not the fundamental challenge.&lt;/p&gt;
    &lt;p&gt;Once again, the problem proved more stubborn than the solution.&lt;/p&gt;
    &lt;p&gt;The 1990s brought a different approach. Microsoft’s Visual Basic and Borland’s Delphi made building user interfaces dramatically easier. Drag components onto a form, set properties, write event handlers. Suddenly, creating a Windows application felt achievable for developers with modest experience.&lt;/p&gt;
    &lt;p&gt;This wave succeeded differently than COBOL or CASE tools. These environments acknowledged that programming knowledge was still necessary, but they reduced the barrier to entry. A broader range of people could create useful applications.&lt;/p&gt;
    &lt;p&gt;Yet the dream of eliminating developers persisted. “Power users” and “citizen developers” would build departmental applications. IT departments could focus on infrastructure while business units solved their own software needs.&lt;/p&gt;
    &lt;p&gt;Reality proved more nuanced. Simple applications were indeed accessible to more people. But as requirements grew in complexity—integration with existing systems, security considerations, performance under load, long-term maintenance—the need for experienced developers became evident. The tools expanded who could write software, but they didn’t eliminate the expertise required for substantial systems.&lt;/p&gt;
    &lt;p&gt;And so the cycle continued into the new millennium.&lt;/p&gt;
    &lt;p&gt;Each subsequent decade introduced new variations. Ruby on Rails promised convention over configuration. Low-code platforms offered visual development with minimal coding. No-code platforms claimed to eliminate programming entirely for common business applications.&lt;/p&gt;
    &lt;p&gt;Each wave delivered real value. Development genuinely became faster in specific contexts. More people could participate in creating software solutions. Yet professional software developers remained essential, and demand for their skills continued growing rather than shrinking.&lt;/p&gt;
    &lt;p&gt;Which brings us to the question: why does this pattern repeat?&lt;/p&gt;
    &lt;p&gt;The recurring pattern reveals something important about how we think about complexity. Software development looks like it should be simple because we can describe what we want in plain language. “When a customer places an order, check inventory, calculate shipping, process payment, and send a confirmation email.” That description sounds straightforward.&lt;/p&gt;
    &lt;p&gt;The complexity emerges in the details. What happens when inventory is temporarily reserved by another order? How do you handle partial payments? What if the email service is temporarily unavailable? Should you retry? How many times? What if the customer’s session expires during checkout? How do you prevent duplicate orders?&lt;/p&gt;
    &lt;p&gt;Each answer leads to more questions. The accumulated decisions, edge cases, and interactions create genuine complexity that no tool or language can eliminate. Someone must think through these scenarios. That thinking is software development, regardless of whether it’s expressed in COBOL, a CASE tool diagram, Visual Basic, or an AI prompt.&lt;/p&gt;
    &lt;p&gt;Which brings us to today’s excitement.&lt;/p&gt;
    &lt;p&gt;Today’s AI coding assistants represent the most capable attempt yet to assist with software creation. They can generate substantial amounts of working code from natural language descriptions. They can explain existing code, suggest improvements, and help debug problems.&lt;/p&gt;
    &lt;p&gt;This represents genuine progress. The assistance is real and valuable. Experienced developers use these tools to work more efficiently. People learning to code find the interactive guidance helpful.&lt;/p&gt;
    &lt;p&gt;Yet we’re already seeing the familiar pattern emerge. Initial excitement about AI replacing developers is giving way to a more nuanced understanding: AI changes how developers work rather than eliminating the need for their judgment. The complexity remains. Someone must understand the business problem, evaluate whether the generated code solves it correctly, consider security implications, ensure it integrates properly with existing systems, and maintain it as requirements evolve.&lt;/p&gt;
    &lt;p&gt;AI amplifies developer capability. It doesn’t replace the need for people who understand both the problem domain and the technical landscape.&lt;/p&gt;
    &lt;p&gt;Here’s the paradox that makes this pattern particularly poignant. We’ve made extraordinary progress in software capabilities. The Apollo guidance computer had 4KB of RAM. Your smartphone has millions of times more computing power. We’ve built tools and frameworks that genuinely make many aspects of development easier.&lt;/p&gt;
    &lt;p&gt;Yet demand for software far exceeds our ability to create it. Every organization needs more software than it can build. The backlog of desired features and new initiatives grows faster than development teams can address it.&lt;/p&gt;
    &lt;p&gt;This tension—powerful tools yet insufficient capacity—keeps the dream alive. Business leaders look at the backlog and think, “There must be a way to go faster, to enable more people to contribute.” That’s a reasonable thought. It leads naturally to enthusiasm for any tool or approach that promises to democratize software creation.&lt;/p&gt;
    &lt;p&gt;The challenge is that software development isn’t primarily constrained by typing speed or syntax knowledge. It’s constrained by the thinking required to handle complexity well. Faster typing doesn’t help when you’re thinking through how to handle concurrent database updates. Simpler syntax doesn’t help when you’re reasoning about security implications.&lt;/p&gt;
    &lt;p&gt;So what should leaders do with this understanding?&lt;/p&gt;
    &lt;p&gt;Understanding this pattern changes how you evaluate new tools and approaches. When someone promises that their platform will let business users build applications without developers, you can appreciate the aspiration while maintaining realistic expectations.&lt;/p&gt;
    &lt;p&gt;The right question isn’t “Will this eliminate our need for developers?” The right questions are:&lt;/p&gt;
    &lt;p&gt;These questions acknowledge that development involves irreducible complexity while remaining open to tools that provide genuine leverage.&lt;/p&gt;
    &lt;p&gt;And they point to something deeper about the nature of software work.&lt;/p&gt;
    &lt;p&gt;This fifty-year pattern teaches us something fundamental about software development itself. If the problem were primarily mechanical—too much typing, too complex syntax, too many steps—we would have solved it by now. COBOL made syntax readable. CASE tools eliminated typing. Visual tools eliminated syntax. AI can now generate entire functions from descriptions.&lt;/p&gt;
    &lt;p&gt;Each advancement addressed a real friction point. Yet the fundamental challenge persists because it’s not mechanical. It’s intellectual. Software development is thinking made tangible. The artifacts we create—whether COBOL programs, Delphi forms, or Python scripts—are the visible outcome of invisible reasoning about complexity.&lt;/p&gt;
    &lt;p&gt;You can’t shortcut that reasoning any more than you can shortcut the reasoning required to design a building or diagnose a medical condition. Better tools help. Experience helps. But someone must still think it through.&lt;/p&gt;
    &lt;p&gt;So how should we move forward, knowing all this?&lt;/p&gt;
    &lt;p&gt;The next wave of development tools will arrive. Some will provide genuine value. Some will repeat familiar promises with new technology. Having perspective on this recurring pattern helps you engage with new tools productively.&lt;/p&gt;
    &lt;p&gt;Use AI assistants. Evaluate low-code platforms. Experiment with new frameworks. But invest primarily in your people’s ability to think clearly about complexity. That capability remains the constraining factor, just as it was during the Apollo program.&lt;/p&gt;
    &lt;p&gt;The moon landing happened because brilliant people thought carefully about every detail of an extraordinarily complex challenge. They wrote software by hand because that was the available tool. If they’d had better tools, they would have used them gladly. But the tools wouldn’t have eliminated their need to think through the complexity.&lt;/p&gt;
    &lt;p&gt;We’re still in that same fundamental situation. We have better tools—vastly better tools—but the thinking remains essential.&lt;/p&gt;
    &lt;p&gt;Perhaps the recurring dream of replacing developers isn’t a mistake. Perhaps it’s a necessary optimism that drives tool creation. Each attempt to make development more accessible produces tools that genuinely help. The dream doesn’t come true as imagined, but pursuing it creates value.&lt;/p&gt;
    &lt;p&gt;COBOL didn’t let business analysts write programs, but it did enable a generation of developers to build business systems effectively. CASE tools didn’t generate complete applications, but they advanced our thinking about visual modeling. Visual Basic didn’t eliminate professional developers, but it brought application development to more people. AI won’t replace developers, but it will change how we work in meaningful ways.&lt;/p&gt;
    &lt;p&gt;The pattern continues because the dream reflects a legitimate need. We genuinely require faster, more efficient ways to create software. We just keep discovering that the constraint isn’t the tool—it’s the complexity of the problems we’re trying to solve.&lt;/p&gt;
    &lt;p&gt;Understanding this doesn’t mean rejecting new tools. It means using them with clear expectations about what they can provide and what will always require human judgment.&lt;/p&gt;
    &lt;p&gt;Let's talk about your real situation. Want to accelerate delivery, remove technical blockers, or validate whether an idea deserves more investment? Book a short conversation (20 min): I listen to your context and give 1–2 practical recommendations—no pitch, no obligation. If it fits, we continue; if not, you leave with clarity. Confidential and direct.&lt;/p&gt;
    &lt;p&gt;Prefer email? Write me: sns@caimito.net&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.caimito.net/en/blog/2025/12/07/the-recurring-dream-of-replacing-developers.html"/><published>2026-01-17T14:31:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46659194</id><title>Escaping the trap of US tech dependence</title><updated>2026-01-17T17:08:55.540872+00:00</updated><content>&lt;doc fingerprint="3fb893f09e231efd"&gt;
  &lt;main&gt;
    &lt;p&gt;The recent US invasion of Venezuela and the saber-rattling toward many other countries, including Greenland and Denmark, have given new energy to concern about dependence on the United States and how governments should react. Given that I am Canadian, I’ve been thinking a lot about what this means for my country over the past year, given its close proximity and deep ties to our neighbour to the south. Now, more than ever, it’s time to take bold action — especially on the tech front.&lt;/p&gt;
    &lt;p&gt;I’ve already written about the wider implications of what we saw from the United States in the opening days of 2026, but I also prepared this piece last year making an argument not only for why Canada needs to pursue digital sovereignty, but also why it doesn’t benefit from the current arrangement. It’s not just how dependence on the US constraints sovereignty and the Canadian government’s ability to make decisions about what happens within its own territory, but also how it sends the bulk of the economic gains south of the border too.&lt;/p&gt;
    &lt;p&gt;I wrote this piece for the Canadian Centre for Policy Alternatives, and they’ve been kind enough to let me share it with you. Enjoy!&lt;/p&gt;
    &lt;p&gt;— Paris&lt;/p&gt;
    &lt;p&gt;In February, U.S. President Donald Trump signed an executive order sanctioning the International Criminal Court (ICC) and its chief prosecutor, British lawyer Karim Khan. The move came in response to the court’s decision to issue an arrest warrant for Israeli Prime Minister Benjamin Netanyahu for the crimes against humanity he committed in the ongoing Gaza genocide.&lt;/p&gt;
    &lt;p&gt;The move was outrageous for many reasons, and not even the first time the United States had sanctioned an ICC chief prosecutor. Khan’s predecessor was also in Trump’s crosshairs when she opened an investigation into crimes in Afghanistan, where the actions of the United States would not be excluded.&lt;/p&gt;
    &lt;p&gt;The sanctions on Khan hampered the work of the court, and he found that not only were his UK bank accounts frozen, but he also lost access to his Microsoft email address. He ended up switching to Swiss privacy-focused provider Proton Mail. While it has not made the same impact in Canada, the news about Khan losing his access to Microsoft services quickly rippled through the halls of power across Europe when it was revealed in May.&lt;/p&gt;
    &lt;p&gt;The withdrawal of service showed European lawmakers how vulnerable their access to the technologies they rely on not just in their personal lives, but to run governments and key institutions. They were also facing escalating pressure from the Trump administration and the billionaires of Silicon Valley to roll back their world-leading tech regulations, and U.S. Vice President JD Vance showed up on the continent a week after Khan was sanctioned to lecture Europe about its values, approach to free speech, and attempts to exclude the neo-Nazi party Alternative for Germany from political power.&lt;/p&gt;
    &lt;p&gt;Microsoft tried to distance itself from the controversy, but even its spokesperson admitted there had been a “disconnection of [the court’s] sanctioned official.” The company didn’t help its case when Microsoft France’s director of public and legal affairs told the French Senate under oath in June that it “cannot guarantee” it would be able to deny requests from the Trump administration for data stored on its servers within the European Union.&lt;/p&gt;
    &lt;p&gt;As European lawmakers grew increasingly concerned about a U.S. digital “kill switch” and the security of the cloud services supplied by major U.S. companies they’d come to rely on, one thing was clear: they were not nearly as sovereign as they previously believed, and their dependence on U.S. tech had to be addressed.&lt;/p&gt;
    &lt;head rend="h2"&gt;Rolling back tech regulation&lt;/head&gt;
    &lt;p&gt;Canada is not immune from these vulnerabilities. Due to our geographic proximity to and greater dependence on the United States, they are arguably even more present as Canadians reassess our relationship with our neighbour to the south. We have already seen how effectively the United States can apply pressure to Canada in the tech domain and beyond.&lt;/p&gt;
    &lt;p&gt;If we look at Europe, the pressure from U.S. tech executives like Meta CEO Mark Zuckerberg or Apple CEO Tim Cook is much more apparent. The chief executives and company spokespeople regularly single out European regulations causing them commercial headaches. In Canada, that pressure is still there; the executives just don’t often speak out publicly. The more vocal opposition is outsourced to domestic tech leaders and our own coterie of commentators that echo narratives beneficial to the big U.S. tech giants.&lt;/p&gt;
    &lt;p&gt;Over the past couple years, we saw a concerted campaign by Canadian tech executives, aligned with the right-wing politics their counterparts in Silicon Valley adopted, begin to openly push a political program in their interests, often paired with explicit support for Pierre Poilievre and the Conservative Party. However, since Mark Carney replaced Justin Trudeau at the helm of the Liberal Party, they’ve embraced the central banker-in-chief. He’s committed to attracting investment above all else, and that means he’s much more open to their policy demands.&lt;/p&gt;
    &lt;p&gt;As a result, we’ve seen a rapid erosion in the government’s efforts to rein in U.S. tech companies. Since April, planned AI regulations have been put on ice, along with the Online Harms Bill that sought to address harmful behaviour in online spaces. That was in spite of concretely seeing how those platforms are used by bad actors to sow division within society as wildfires spread across the country again this past summer. In parts of the country, local politicians had to directly respond to disinformation spreading online that people desperate for updates were falling for.&lt;/p&gt;
    &lt;p&gt;In June, another pillar in the Trudeau government’s attempt to regulate the tech industry fell when Donald Trump walked away from trade negotiations, saying he would only return once the Canadian government repealed its digital services tax. Executives like Zuckerberg have lobbied Trump to try to kill those taxes in countries around the world. Late on the Sunday night before the tax was supposed to come into effect, Carney and Finance Minister François-Philippe Champagne announced it would be sacrificed so talks could continue. Months later, a comprehensive deal with the United States remains elusive.&lt;/p&gt;
    &lt;p&gt;It can be easy to believe that all this pressure is a product of the way Trump’s return to office emboldened U.S. tech companies, but it’s simply brought a longstanding process out into the open. The U.S. government has long recognized how much it benefits from ensuring other countries are dependent on products and services made by companies in its jurisdiction. For years, it used trade negotiations to insert clauses in agreements that limit foreign governments’ ability to regulate its tech companies and has used its diplomats to apply pressure in other ways.&lt;/p&gt;
    &lt;p&gt;For example, CUSMA contains measures that constrain the authority of the Canadian government to regulate the tech industry. The agreement limits the ability to regulate cross-border data flows, to force companies to reveal their source code, to discriminate between foreign and domestic tech firms, or to expect them to store data on Canadians within our borders. On top of that, U.S. officials under the Biden administration regularly pressured the government when it moved forward with tech regulations, including with the streaming bill and digital services tax. The Online News Act is the latest to find itself in U.S. crosshairs.&lt;/p&gt;
    &lt;p&gt;Protecting the global market share and curtailing attempts to rein in U.S. tech companies is bipartisan policy in the United States. They may occasionally get angry at certain domestic consequences of the tech products they depend on, but Democrats and Republicans alike are not very concerned about how those issues play out beyond the country’s borders. Ensuring other countries depend on U.S. tech companies not only increases U.S. power, but also provides it with ample economic benefits.&lt;/p&gt;
    &lt;head rend="h2"&gt;The consequences of dependence&lt;/head&gt;
    &lt;p&gt;Political developments in the 1980s and 1990s played a key role in shaping the dominant position the United States holds today. In the late 1980s, then Senator Al Gore recognized that technology and power were inseparable. In a speech to the senate, he declared that “the nation which most completely assimilates high-performance computing into its economy will very likely emerge as the dominant intellectual, economic, and technological force in the next century.”&lt;/p&gt;
    &lt;p&gt;Gore and President Bill Clinton were intent on ensuring the United States reaped the gains of the emerging internet. What started as a military and academic project had already begun to be commercialized, and in 1995, they completed the handover of the public infrastructure to the private sector. U.S. companies got a head start on building the businesses that would dominate the digital economy, and much easier access to capital to rapidly scale domestically and later internationally.&lt;/p&gt;
    &lt;p&gt;In those years, the model of the internet was established—and the private sector was firmly in charge. There were debates about carving out a “public lane” on the “information superhighway,” but those efforts were ultimately defeated.&lt;/p&gt;
    &lt;p&gt;The U.S. government used its influence to push for telecom deregulation and the removal of trade barriers around the world, aiding its companies to move into international markets. Tech advocacy groups assisted in their own way by crafting a narrative that the internet was inherently liberatory and any attempts by governments to restrict the expansion of digital services, platforms, and the companies that run them was an inherent breach of their citizens’ rights. Over time, U.S. companies rode the wave to global dominance, and as they took over new markets, domestic competitors were acquired or simply failed in face of the pressure.&lt;/p&gt;
    &lt;p&gt;Our dependence on U.S. tech has long been a problem, just one that many people in power did not want to touch because of how it would anger the United States. Even proposing basic tech regulations prompted rebukes from the U.S. government and threatened the prospect of investment from those digital colonizers. But that dependence left us without the tools to get a handle on key avenues for communication and commerce.&lt;/p&gt;
    &lt;p&gt;As U.S. tech companies fought to roll back workers’ rights in the gig economy and beyond, allowed false information to spread across social media platforms, decimated the funding model for journalism, and had countless other negative social impacts, the Canadian government was limited in its ability to respond. All the while, as more Canadians—both individuals and companies—became dependent on U.S. digital services, the profits were siphoned back to the United States, fueling a growing economic divide that has prompted economists to start sounding the alarm.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reclaiming digital sovereignty&lt;/head&gt;
    &lt;p&gt;There is one thing we can say for Trump’s attacks on Canada: they have finally given us the space to speak openly and honestly about many of the ways the U.S.-Canada relationship has not been working for us for a very long time—and the digital dimension of our lopsided economic integration is a massive part of that. If Canada is to regain greater autonomy over its affairs and build a better society, we must get serious about reclaiming our digital sovereignty.&lt;/p&gt;
    &lt;p&gt;Since Trump’s return to office, governments have been ramping up defence spending to ensure they can defend themselves in a world where the United States is no longer a security guarantor and possibly even a security threat. That same seriousness should be given to digital technology.&lt;/p&gt;
    &lt;p&gt;As our European allies have found first hand, our dependence on U.S. companies for cloud services creates a severe vulnerability, where the U.S. government can request whatever data it wants or can even shut off our access at a moment’s notice. During the election campaign, Carney said he would be reassessing public cloud contracts going to Amazon, Microsoft, Google, and Oracle. More recently, when he announced the first batch of nation-building projects, the prime minister called out the need for a sovereign cloud. He is taking steps in the right direction, but the devil will be in the details.&lt;/p&gt;
    &lt;p&gt;Our ambition cannot stop there though. In far too many cases, our governments, universities, schools, and other public institutions—not to mention private businesses—are run on Microsoft or Google services. Now is the perfect time to get governments off Microsoft 365 and schools off Google Classroom by properly resourcing a new public agency or Crown corporation dedicated to building technology in the public interest.&lt;/p&gt;
    &lt;p&gt;European state, local, and even departments of national governments are already taking the initiative to move in that direction. There are ample open-source tools already out there that could be adapted to those institutional use cases, with a mandate to work in close collaboration with public institutions to ensure their new suite of digital services properly meets their unique needs. Governments could even think about bringing tech development closer to communities, building on a model not dissimilar to public libraries.&lt;/p&gt;
    &lt;p&gt;We have an opportunity to think bigger and to challenge those fundamental assumptions that were crafted in the 1990s to convince us digital technology had to be left to the private sector. For three decades, the goal of tech development has not been to improve our lives or to serve the public good, but rather to maximize shareholder value and to increase the power of the companies that control it. It’s that nature of digital technology that is at the root of so many of the social harms that the tech oligopoly have saddled us with in recent years. We need to recognize that was a choice, and we can choose to take a different path.&lt;/p&gt;
    &lt;p&gt;But we must also be aware of the pitfalls ahead. Some Canadian tech executives that, until recently, were pushing for a Conservative government are embracing a program of digital sovereignty as well, but it is explicitly not one that centres the public good. Instead, they’re pushing the government to continue pulling back on regulations, while deploying billions through public procurement, incentives, and subsidies to flood into their businesses. They want to hold onto the Silicon Valley model and the harms that it’s created, but better cash in on it for themselves. They want to join the digital colonizers rather than bring them down.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://disconnect.blog/escaping-the-trap-of-us-tech-dependence/"/><published>2026-01-17T16:15:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46659456</id><title>The Resonant Computing Manifesto</title><updated>2026-01-17T17:08:55.111813+00:00</updated><content>&lt;doc fingerprint="9a11f37a94f0aa69"&gt;
  &lt;main&gt;
    &lt;p&gt; There's a feeling you get&lt;lb/&gt; in the presence of&lt;lb/&gt; beautiful buildings and bustling courtyards.&lt;lb/&gt; A sense that these spaces&lt;lb/&gt; are inviting you to slow down,&lt;lb/&gt; deepen your attention, and be&lt;lb/&gt; a bit more human.&lt;lb/&gt; What if our software could do the same? &lt;/p&gt;
    &lt;p&gt;We shape our environments, and thereafter they shape us.&lt;/p&gt;
    &lt;p&gt;Great technology does more than solve problems. It weaves itself into the world we inhabit. At its best, it can expand our capacity, our connectedness, our sense of what's possible. Technology can bring out the best in us.&lt;/p&gt;
    &lt;p&gt;Our current technological landscape, however, does the opposite. Feeds engineered to hijack attention and keep us scrolling, leaving a trail of anxiety and atomization in their wake. Digital platforms that increasingly mediate our access to transportation, work, food, dating, commerce, entertainment—while routinely draining the depth and warmth from everything they touch. For all its grandiose promises, modern tech often leaves us feeling alienated, ever more distant from who we want to be.&lt;/p&gt;
    &lt;p&gt;The people who build these products aren't bad or evil. Most of us got into tech with an earnest desire to leave the world better than we found it. But the incentives and cultural norms of the tech industry have coalesced around the logic of hyper-scale. It's become monolithic, magnetic, all-encompassing—an environment that shapes all who step foot there. While the business results are undeniable, so too are the downstream effects on humanity.&lt;/p&gt;
    &lt;p&gt;With the emergence of artificial intelligence, we stand at a crossroads. This technology holds genuine promise. It could just as easily pour gasoline on existing problems. If we continue to sleepwalk down the path of hyper-scale and centralization, future generations are sure to inherit a world far more dystopian than our own.&lt;/p&gt;
    &lt;p&gt;But there is another path opening before us.&lt;/p&gt;
    &lt;p&gt;Christopher Alexander spent his career exploring why some built environments deaden us, while others leave us feeling more human, more at home in the world. His work centered around the "quality without a name," this intuitive knowing that a place or an architectural element is in tune with life. By learning to recognize this quality, he argued, and constructing a building in dialogue with it, we could reliably create environments that enliven us.&lt;/p&gt;
    &lt;p&gt;We call this quality resonance. It's the experience of encountering something that speaks to our deeper values. It's a spark of recognition, a sense that we're being invited to lean in, to participate. Unlike the digital junk food of the day, the more we engage with what resonates, the more we're left feeling nourished, grateful, alive. As individuals, following the breadcrumbs of resonance helps us build meaningful lives. As communities, companies, and societies, cultivating shared resonance helps us break away from perverse incentives, and play positive-sum infinite games together.&lt;/p&gt;
    &lt;p&gt;For decades, technology has required standardized solutions to complex human problems. In order to scale software, you had to build for the average user, sanding away the edge cases. In many ways, this is why our digital world has come to resemble the sterile, deadening architecture that Alexander spent his career pushing back against.&lt;/p&gt;
    &lt;p&gt;This is where AI provides a missing puzzle piece. Software can now respond fluidly to the context and particularity of each human—at scale. One-size-fits-all is no longer a technological or economic necessity. Where once our digital environments inevitably shaped us against our will, we can now build technology that adaptively shapes itself in service of our individual and collective aspirations. We can build resonant environments that bring out the best in every human who inhabits them.&lt;/p&gt;
    &lt;p&gt;And so, we find ourselves at this crossroads. Regardless of which path we choose, the future of computing will be hyper-personalized. The question is whether that personalization will be in service of keeping us passively glued to screens—wading around in the shallows, stripped of agency—or whether it will enable us to direct more attention to what matters.&lt;/p&gt;
    &lt;p&gt;In order to build the resonant technological future we want for ourselves, we will have to resist the seductive logic of hyper-scale, and challenge the business and cultural assumptions that hold it in place. We will have to make deliberate decisions that stand in the face of accepted best practices—rethinking the system architectures, design patterns, and business models that have undergirded the tech industry for decades.&lt;/p&gt;
    &lt;p&gt;We suggest these five principles as a starting place:&lt;/p&gt;
    &lt;p&gt;We, the signatories of this manifesto, are committed to building, funding, and championing products and companies that embed these principles at their core. For us, this isn't a theoretical treatise. We're already building tooling and infrastructure that will enable resonant products and ecosystems.&lt;/p&gt;
    &lt;p&gt;But we cannot do it alone. None of us holds all the answers, and this movement cannot succeed in isolation. That's why, alongside this manifesto, we're sharing an evolving list of principles and theses. These are specific assertions about the implementation details and tradeoffs required to make resonant computing a reality. Some of these stem from our experiences, while others will be crowdsourced from practitioners across the industry. This conversation is only just beginning.&lt;/p&gt;
    &lt;p&gt;If this vision resonates, we invite you to join us. Not just as a signatory, but as a contributor. Add your expertise, your critiques, your own theses. By harnessing the collective intelligence of people who earnestly care, we can chart a path towards technology that enables individual growth and collective flourishing.&lt;/p&gt;
    &lt;p&gt;Explore &amp;amp; contribute to the theses of resonant computing&lt;/p&gt;
    &lt;p&gt;The following individuals drafted and released this manifesto:&lt;/p&gt;
    &lt;p&gt;Maggie Appleton&lt;lb/&gt; Samuel Arbesman&lt;lb/&gt; Daniel Barcay&lt;lb/&gt; Rob Hardy&lt;lb/&gt; Aishwarya Khanduja&lt;lb/&gt; Alex Komoroske&lt;lb/&gt; Geoffrey Litt&lt;lb/&gt; Michael Masnick&lt;lb/&gt; Brendan McCord&lt;/p&gt;
    &lt;p&gt;Bernhard Seefeld&lt;lb/&gt; Ivan Vendrov&lt;lb/&gt; Amelia Wattenberger&lt;lb/&gt; Zoe Weinberg&lt;lb/&gt; Simon Willison&lt;/p&gt;
    &lt;p&gt;with illustrations by&lt;lb/&gt; Forest Stearns&lt;/p&gt;
    &lt;p&gt;The following individuals have signed in support:&lt;/p&gt;
    &lt;p&gt;Tim O'Reilly&lt;/p&gt;
    &lt;p&gt;Kevin Kelly&lt;/p&gt;
    &lt;p&gt;Bruce Schneier&lt;/p&gt;
    &lt;p&gt;Alan Kay&lt;/p&gt;
    &lt;p&gt;Hank Green&lt;/p&gt;
    &lt;p&gt;Hiten Shah&lt;/p&gt;
    &lt;p&gt;Eric Ries&lt;/p&gt;
    &lt;p&gt;Joel Lehman&lt;/p&gt;
    &lt;p&gt;Packy McCormick&lt;/p&gt;
    &lt;p&gt;Danielle Perszyk&lt;/p&gt;
    &lt;p&gt;Jim Rutt&lt;/p&gt;
    &lt;p&gt;Peter Wang&lt;/p&gt;
    &lt;p&gt;Brad Burnham&lt;/p&gt;
    &lt;p&gt;Kent Beck&lt;/p&gt;
    &lt;p&gt;Eugene Wei&lt;/p&gt;
    &lt;p&gt;Gary William Flake&lt;/p&gt;
    &lt;p&gt;Lenny Rachitsky&lt;/p&gt;
    &lt;p&gt;John Seely Brown&lt;/p&gt;
    &lt;p&gt;Roy Bahat&lt;/p&gt;
    &lt;p&gt;Jonathan Zittrain&lt;/p&gt;
    &lt;p&gt;Max Read&lt;/p&gt;
    &lt;p&gt;Harper Reed&lt;/p&gt;
    &lt;p&gt;Lawrence Lessig&lt;/p&gt;
    &lt;p&gt;Evan Henshaw-Plath&lt;/p&gt;
    &lt;p&gt;Anjan Katta&lt;/p&gt;
    &lt;p&gt;Yancey Strickler&lt;/p&gt;
    &lt;p&gt;Uri Bram&lt;/p&gt;
    &lt;p&gt;Rohit Krishnan&lt;/p&gt;
    &lt;p&gt;Simon Taylor&lt;/p&gt;
    &lt;p&gt;David A Smith&lt;/p&gt;
    &lt;p&gt;Peter van Hardenberg&lt;/p&gt;
    &lt;p&gt;E. Glen Weyl&lt;/p&gt;
    &lt;p&gt;Linda Liukas&lt;/p&gt;
    &lt;p&gt;Adam Davidson&lt;/p&gt;
    &lt;p&gt;Mark A. Lemley&lt;/p&gt;
    &lt;p&gt;Matt Beane&lt;/p&gt;
    &lt;p&gt;Anil Dash&lt;/p&gt;
    &lt;p&gt;Brooklyn Zelenka&lt;/p&gt;
    &lt;p&gt;Karen Wickre&lt;/p&gt;
    &lt;p&gt;Alex Russell&lt;/p&gt;
    &lt;p&gt;Rebecca MacKinnon&lt;/p&gt;
    &lt;p&gt;Audrey Tang&lt;/p&gt;
    &lt;p&gt;Ryan Carson&lt;/p&gt;
    &lt;p&gt;Ben Guo&lt;/p&gt;
    &lt;p&gt;Kim Scott&lt;/p&gt;
    &lt;p&gt;Scott Jenson&lt;/p&gt;
    &lt;p&gt;Esther Dyson&lt;/p&gt;
    &lt;p&gt;Richard Sambrook&lt;/p&gt;
    &lt;p&gt;Gilad Bracha&lt;/p&gt;
    &lt;p&gt;Matt Mullenweg&lt;/p&gt;
    &lt;p&gt;David P. Reed&lt;/p&gt;
    &lt;p&gt;Andrew Stone&lt;/p&gt;
    &lt;p&gt;Eric Migicovsky&lt;/p&gt;
    &lt;p&gt;Chris Messina&lt;/p&gt;
    &lt;p&gt;Vaughn Tan&lt;/p&gt;
    &lt;p&gt;Daphne Keller&lt;/p&gt;
    &lt;p&gt;Chad Kohalyk&lt;/p&gt;
    &lt;p&gt;James Edward Dillard&lt;/p&gt;
    &lt;p&gt;Ben mathes&lt;/p&gt;
    &lt;p&gt;Goblin Oats&lt;/p&gt;
    &lt;p&gt;Chris Lunt&lt;/p&gt;
    &lt;p&gt;Curran Dwyer&lt;/p&gt;
    &lt;p&gt;Ben Follington&lt;/p&gt;
    &lt;p&gt;Stuart Buck&lt;/p&gt;
    &lt;p&gt;Bridget Harris&lt;/p&gt;
    &lt;p&gt;Chad Fowler&lt;/p&gt;
    &lt;p&gt;Kyle Morris&lt;/p&gt;
    &lt;p&gt;Sean Thielen-Esparza&lt;/p&gt;
    &lt;p&gt;Janfj&lt;/p&gt;
    &lt;p&gt;Yatú Espinosa&lt;/p&gt;
    &lt;p&gt;Alex Zhang&lt;/p&gt;
    &lt;p&gt;Anna Mitchell&lt;/p&gt;
    &lt;p&gt;`Steve Kirkham&lt;/p&gt;
    &lt;p&gt;Scott Moore&lt;/p&gt;
    &lt;p&gt;Jason Zhao&lt;/p&gt;
    &lt;p&gt;Jad Esber&lt;/p&gt;
    &lt;p&gt;Joel Dietz&lt;/p&gt;
    &lt;p&gt;Lola Agabalogun&lt;/p&gt;
    &lt;p&gt;Tony Espinoza&lt;/p&gt;
    &lt;p&gt;Arjun Khoosal&lt;/p&gt;
    &lt;p&gt;Tony Curzon Price&lt;/p&gt;
    &lt;p&gt;Maximilian Eusterbrock&lt;/p&gt;
    &lt;p&gt;Beth Anderson&lt;/p&gt;
    &lt;p&gt;Anastasia Uglova&lt;/p&gt;
    &lt;p&gt;Jordan Erlends&lt;/p&gt;
    &lt;p&gt;Samuel Robson&lt;/p&gt;
    &lt;p&gt;Andrew Conner&lt;/p&gt;
    &lt;p&gt;Menno Schaap&lt;/p&gt;
    &lt;p&gt;Philipp Banhardt&lt;/p&gt;
    &lt;p&gt;Berlynn Bai&lt;/p&gt;
    &lt;p&gt;Arun&lt;/p&gt;
    &lt;p&gt;Louis Barclay&lt;/p&gt;
    &lt;p&gt;Gabriel Raubenheimer&lt;/p&gt;
    &lt;p&gt;Roman Leventov&lt;/p&gt;
    &lt;p&gt;Corey James&lt;/p&gt;
    &lt;p&gt;Ben Mayhew&lt;/p&gt;
    &lt;p&gt;Kyle Cox&lt;/p&gt;
    &lt;p&gt;Pierre Chuzeville&lt;/p&gt;
    &lt;p&gt;Lucabrando Sanfilippo&lt;/p&gt;
    &lt;p&gt;Jai Gandhi&lt;/p&gt;
    &lt;p&gt;Carsten Peters&lt;/p&gt;
    &lt;p&gt;Raghuvir Kasturi&lt;/p&gt;
    &lt;p&gt;B. Scot Rousse&lt;/p&gt;
    &lt;p&gt;Ilan Strauss&lt;/p&gt;
    &lt;p&gt;Yash Sharma&lt;/p&gt;
    &lt;p&gt;Sean McKeon&lt;/p&gt;
    &lt;p&gt;Gurupanguji&lt;/p&gt;
    &lt;p&gt;Zoë Chazen&lt;/p&gt;
    &lt;p&gt;John Luther&lt;/p&gt;
    &lt;p&gt;Blain Smith&lt;/p&gt;
    &lt;p&gt;Menelaos Mazarakis&lt;/p&gt;
    &lt;p&gt;Konstantinos Komaitis&lt;/p&gt;
    &lt;p&gt;Eddy Abraham&lt;/p&gt;
    &lt;p&gt;Justin Mares&lt;/p&gt;
    &lt;p&gt;Aastha JS&lt;/p&gt;
    &lt;p&gt;Marisa Rama&lt;/p&gt;
    &lt;p&gt;Seb Agertoft&lt;/p&gt;
    &lt;p&gt;Christina Kirsch&lt;/p&gt;
    &lt;p&gt;Peter Voss&lt;/p&gt;
    &lt;p&gt;Shoumik Dabir&lt;/p&gt;
    &lt;p&gt;Mike McCormick&lt;/p&gt;
    &lt;p&gt;Riley Wong&lt;/p&gt;
    &lt;p&gt;Matt Hawes&lt;/p&gt;
    &lt;p&gt;Michele Canzi&lt;/p&gt;
    &lt;p&gt;Matt Jones&lt;/p&gt;
    &lt;p&gt;Jonathan Lebensold&lt;/p&gt;
    &lt;p&gt;Francisco Javier Arceo&lt;/p&gt;
    &lt;p&gt;Noah Ringler&lt;/p&gt;
    &lt;p&gt;Simone Cicero&lt;/p&gt;
    &lt;p&gt;Lex Sokolin&lt;/p&gt;
    &lt;p&gt;Erika Rice Scherpelz&lt;/p&gt;
    &lt;p&gt;Sahar Mor&lt;/p&gt;
    &lt;p&gt;max bittker&lt;/p&gt;
    &lt;p&gt;Avni Patel Thompson&lt;/p&gt;
    &lt;p&gt;Chaim Gingold&lt;/p&gt;
    &lt;p&gt;Matt Ziegler&lt;/p&gt;
    &lt;p&gt;Daniel Hatkoff&lt;/p&gt;
    &lt;p&gt;Kamran Hakima&lt;/p&gt;
    &lt;p&gt;Rupert Manfredi&lt;/p&gt;
    &lt;p&gt;Mark Moriarty&lt;/p&gt;
    &lt;p&gt;Jordan Rubin&lt;/p&gt;
    &lt;p&gt;Rebecca Mqamelo&lt;/p&gt;
    &lt;p&gt;Chenoe Hart&lt;/p&gt;
    &lt;p&gt;Rob Flickenger&lt;/p&gt;
    &lt;p&gt;Michael Lapadula&lt;/p&gt;
    &lt;p&gt;Dan Garon&lt;/p&gt;
    &lt;p&gt;Sean Lynch&lt;/p&gt;
    &lt;p&gt;Michael Tanzillo&lt;/p&gt;
    &lt;p&gt;Reggie James&lt;/p&gt;
    &lt;p&gt;Sam Barton&lt;/p&gt;
    &lt;p&gt;Anthea Roberts&lt;/p&gt;
    &lt;p&gt;Andrew Rose&lt;/p&gt;
    &lt;p&gt;Kevin Roark&lt;/p&gt;
    &lt;p&gt;Matt Holden&lt;/p&gt;
    &lt;p&gt;Leon Markham&lt;/p&gt;
    &lt;p&gt;Sam Weston&lt;/p&gt;
    &lt;p&gt;Rudolf Laine&lt;/p&gt;
    &lt;p&gt;Mark Whiting&lt;/p&gt;
    &lt;p&gt;Christine Gibson&lt;/p&gt;
    &lt;p&gt;Vivian Chong&lt;/p&gt;
    &lt;p&gt;Florian Weber&lt;/p&gt;
    &lt;p&gt;Luke Chatelain&lt;/p&gt;
    &lt;p&gt;Dan Bornstein (@danfuzz)&lt;/p&gt;
    &lt;p&gt;Marcus Estes&lt;/p&gt;
    &lt;p&gt;Kasra Kyanzadeh&lt;/p&gt;
    &lt;p&gt;Rishi Ishairzay&lt;/p&gt;
    &lt;p&gt;Nicholas Chirls&lt;/p&gt;
    &lt;p&gt;Lola Wajskop&lt;/p&gt;
    &lt;p&gt;William Kelly&lt;/p&gt;
    &lt;p&gt;Michael Greig&lt;/p&gt;
    &lt;p&gt;Jasnam Sidhu&lt;/p&gt;
    &lt;p&gt;dougfort&lt;/p&gt;
    &lt;p&gt;Lev Eliezer Israel&lt;/p&gt;
    &lt;p&gt;Mathilde Grant&lt;/p&gt;
    &lt;p&gt;Nathaniel Evans&lt;/p&gt;
    &lt;p&gt;Jessica Johnston&lt;/p&gt;
    &lt;p&gt;Benoit Pimpaud&lt;/p&gt;
    &lt;p&gt;Ross Matican&lt;/p&gt;
    &lt;p&gt;Natalie Breitkopf&lt;/p&gt;
    &lt;p&gt;Nirit Weiss-Blatt&lt;/p&gt;
    &lt;p&gt;James Sinka&lt;/p&gt;
    &lt;p&gt;Grace Kantrow&lt;/p&gt;
    &lt;p&gt;Robinson Eaton&lt;/p&gt;
    &lt;p&gt;Tom Rielly&lt;/p&gt;
    &lt;p&gt;Jason Shellen&lt;/p&gt;
    &lt;p&gt;EdZ&lt;/p&gt;
    &lt;p&gt;Juan Suarez&lt;/p&gt;
    &lt;p&gt;Selipso&lt;/p&gt;
    &lt;p&gt;Toto Tvalavadze&lt;/p&gt;
    &lt;p&gt;Brian "Beej Jorgensen" Hall&lt;/p&gt;
    &lt;p&gt;Hiraeth Wax&lt;/p&gt;
    &lt;p&gt;Dave Sanford&lt;/p&gt;
    &lt;p&gt;Rida Al Barazi&lt;/p&gt;
    &lt;p&gt;Baba Buehler&lt;/p&gt;
    &lt;p&gt;Will Henderson&lt;/p&gt;
    &lt;p&gt;Johannes Ernst&lt;/p&gt;
    &lt;p&gt;Gernot Poetsch&lt;/p&gt;
    &lt;p&gt;Ian Mulvany&lt;/p&gt;
    &lt;p&gt;Xavi Duran&lt;/p&gt;
    &lt;p&gt;Steve Della Valentina&lt;/p&gt;
    &lt;p&gt;Gabriel Cubbage&lt;/p&gt;
    &lt;p&gt;Marcel Goethals&lt;/p&gt;
    &lt;p&gt;Ashish Uppala&lt;/p&gt;
    &lt;p&gt;Ted Wood&lt;/p&gt;
    &lt;p&gt;Al Mithani&lt;/p&gt;
    &lt;p&gt;Carlos Pinto&lt;/p&gt;
    &lt;p&gt;Joël Gombin&lt;/p&gt;
    &lt;p&gt;Jassi Singh&lt;/p&gt;
    &lt;p&gt;Patrick Farrell&lt;/p&gt;
    &lt;p&gt;Steven Feuerstein&lt;/p&gt;
    &lt;p&gt;Alexia Petrakos&lt;/p&gt;
    &lt;p&gt;Quentin Hardy&lt;/p&gt;
    &lt;p&gt;Daniel Müller&lt;/p&gt;
    &lt;p&gt;Jorge Arango&lt;/p&gt;
    &lt;p&gt;Tom Usher&lt;/p&gt;
    &lt;p&gt;Jake Simonds&lt;/p&gt;
    &lt;p&gt;Luke Hubbard&lt;/p&gt;
    &lt;p&gt;Oren Maximov&lt;/p&gt;
    &lt;p&gt;Arun krishnasamy&lt;/p&gt;
    &lt;p&gt;Kingsley Uyi Idehen&lt;/p&gt;
    &lt;p&gt;Christopher David&lt;/p&gt;
    &lt;p&gt;mig&lt;/p&gt;
    &lt;p&gt;Giedrius Jaloveckas&lt;/p&gt;
    &lt;p&gt;Yuval Yeret&lt;/p&gt;
    &lt;p&gt;Mario Zechner&lt;/p&gt;
    &lt;p&gt;Alex Reynish&lt;/p&gt;
    &lt;p&gt;William Philpott&lt;/p&gt;
    &lt;p&gt;Sireesh Gururaja&lt;/p&gt;
    &lt;p&gt;Stephen Band&lt;/p&gt;
    &lt;p&gt;Peergos&lt;/p&gt;
    &lt;p&gt;Joey Tyson&lt;/p&gt;
    &lt;p&gt;Ankesh Bharti&lt;/p&gt;
    &lt;p&gt;Tommy Falkowski&lt;/p&gt;
    &lt;p&gt;Ruthvik Reddy SL&lt;/p&gt;
    &lt;p&gt;Raymond Zhong&lt;/p&gt;
    &lt;p&gt;Ramin Firoozye&lt;/p&gt;
    &lt;p&gt;Jeff Smith&lt;/p&gt;
    &lt;p&gt;David M. Schulman&lt;/p&gt;
    &lt;p&gt;Scott Rosenberg&lt;/p&gt;
    &lt;p&gt;Ted Underwood&lt;/p&gt;
    &lt;p&gt;David Brittain&lt;/p&gt;
    &lt;p&gt;Dumi Konovenski&lt;/p&gt;
    &lt;p&gt;Mark Appleby&lt;/p&gt;
    &lt;p&gt;Kasey Klimes&lt;/p&gt;
    &lt;p&gt;Jacob Carlson&lt;/p&gt;
    &lt;p&gt;Jeremiah Lee&lt;/p&gt;
    &lt;p&gt;Shawn Simister&lt;/p&gt;
    &lt;p&gt;Rev. Koushi Sherrill&lt;/p&gt;
    &lt;p&gt;Courtney Hohne&lt;/p&gt;
    &lt;p&gt;Glenn&lt;/p&gt;
    &lt;p&gt;Redowan Delowar&lt;/p&gt;
    &lt;p&gt;Thomas J. Tobin&lt;/p&gt;
    &lt;p&gt;Devin Gaffney&lt;/p&gt;
    &lt;p&gt;John Bergmayer&lt;/p&gt;
    &lt;p&gt;David W.&lt;/p&gt;
    &lt;p&gt;Jeremy Miller&lt;/p&gt;
    &lt;p&gt;Darren Munk&lt;/p&gt;
    &lt;p&gt;Julian Hicks&lt;/p&gt;
    &lt;p&gt;Fred.&lt;/p&gt;
    &lt;p&gt;Morgan Dalton&lt;/p&gt;
    &lt;p&gt;Mia&lt;/p&gt;
    &lt;p&gt;Adi Pradhan&lt;/p&gt;
    &lt;p&gt;Matt Boulos&lt;/p&gt;
    &lt;p&gt;John Patrick Pullen&lt;/p&gt;
    &lt;p&gt;Dominik Rabiej&lt;/p&gt;
    &lt;p&gt;Renee Frank&lt;/p&gt;
    &lt;p&gt;Charles F Leonard&lt;/p&gt;
    &lt;p&gt;Kate Edgar&lt;/p&gt;
    &lt;p&gt;Andreas Gerold&lt;/p&gt;
    &lt;p&gt;Andy Sellars&lt;/p&gt;
    &lt;p&gt;Davi Arruda&lt;/p&gt;
    &lt;p&gt;Benjamin Smith&lt;/p&gt;
    &lt;p&gt;Marco Bello&lt;/p&gt;
    &lt;p&gt;Randy Lubin&lt;/p&gt;
    &lt;p&gt;Allen Wirfs-Brock&lt;/p&gt;
    &lt;p&gt;Ilja Panić&lt;/p&gt;
    &lt;p&gt;kousha&lt;/p&gt;
    &lt;p&gt;Phil Kilner&lt;/p&gt;
    &lt;p&gt;Eric Hu&lt;/p&gt;
    &lt;p&gt;John Jakubowski&lt;/p&gt;
    &lt;p&gt;JD Pirtle&lt;/p&gt;
    &lt;p&gt;James Tauber&lt;/p&gt;
    &lt;p&gt;Vatsav&lt;/p&gt;
    &lt;p&gt;Joop Snijder&lt;/p&gt;
    &lt;p&gt;Frank B&lt;/p&gt;
    &lt;p&gt;Björn Jarisch&lt;/p&gt;
    &lt;p&gt;Jonathan Simcoe&lt;/p&gt;
    &lt;p&gt;David Cabo&lt;/p&gt;
    &lt;p&gt;Mark Zweifel&lt;/p&gt;
    &lt;p&gt;Glenn Poppe&lt;/p&gt;
    &lt;p&gt;Roy Atkinson&lt;/p&gt;
    &lt;p&gt;dat-ecosystem&lt;/p&gt;
    &lt;p&gt;Keith Kurson&lt;/p&gt;
    &lt;p&gt;Jeremy Littau&lt;/p&gt;
    &lt;p&gt;Joe Gaffey&lt;/p&gt;
    &lt;p&gt;James Cruz-Youll&lt;/p&gt;
    &lt;p&gt;Evan Kaufman&lt;/p&gt;
    &lt;p&gt;Rex Roof&lt;/p&gt;
    &lt;p&gt;kato gk&lt;/p&gt;
    &lt;p&gt;Peter Petrash&lt;/p&gt;
    &lt;p&gt;Oliver Dawkins&lt;/p&gt;
    &lt;p&gt;Diana Dely&lt;/p&gt;
    &lt;p&gt;Steve Whitney&lt;/p&gt;
    &lt;p&gt;Olabode Adedoyin&lt;/p&gt;
    &lt;p&gt;Simon Berlin&lt;/p&gt;
    &lt;p&gt;Brent Eubanks&lt;/p&gt;
    &lt;p&gt;John Brooks&lt;/p&gt;
    &lt;p&gt;John Chandy&lt;/p&gt;
    &lt;p&gt;Dmitry Alexeenko&lt;/p&gt;
    &lt;p&gt;Brian Cowles&lt;/p&gt;
    &lt;p&gt;Austin Parker&lt;/p&gt;
    &lt;p&gt;Joe W&lt;/p&gt;
    &lt;p&gt;Niana Dela Cruz&lt;/p&gt;
    &lt;p&gt;Holly Tavel&lt;/p&gt;
    &lt;p&gt;Michael Taggart&lt;/p&gt;
    &lt;p&gt;cassidy cypress&lt;/p&gt;
    &lt;p&gt;Damien Tournoud&lt;/p&gt;
    &lt;p&gt;Gavin Chait&lt;/p&gt;
    &lt;p&gt;Bryan Watts&lt;/p&gt;
    &lt;p&gt;Pilar Rodríguez&lt;/p&gt;
    &lt;p&gt;Kris Wilcox&lt;/p&gt;
    &lt;p&gt;Thomas A. Powell&lt;/p&gt;
    &lt;p&gt;Eliot Kristan&lt;/p&gt;
    &lt;p&gt;J. M. Johnson&lt;/p&gt;
    &lt;p&gt;Laura Alonso Alemany&lt;/p&gt;
    &lt;p&gt;Arun Bahl&lt;/p&gt;
    &lt;p&gt;Quinn Underwood&lt;/p&gt;
    &lt;p&gt;Robin Strom&lt;/p&gt;
    &lt;p&gt;Matt Kanninen&lt;/p&gt;
    &lt;p&gt;R. Brent Adams&lt;/p&gt;
    &lt;p&gt;Nicholas Chen&lt;/p&gt;
    &lt;p&gt;Andrew Przybylski&lt;/p&gt;
    &lt;p&gt;@bumblefudge&lt;/p&gt;
    &lt;p&gt;Manuel Aráoz&lt;/p&gt;
    &lt;p&gt;Jim Diamond&lt;/p&gt;
    &lt;p&gt;Jimmie Munyi&lt;/p&gt;
    &lt;p&gt;Kevin Sagle&lt;/p&gt;
    &lt;p&gt;Paul Gowder&lt;/p&gt;
    &lt;p&gt;Diego Veras&lt;/p&gt;
    &lt;p&gt;Taylor Sizemore&lt;/p&gt;
    &lt;p&gt;Pete Harbeson&lt;/p&gt;
    &lt;p&gt;Tom O'Leary&lt;/p&gt;
    &lt;p&gt;Nils Lundquist&lt;/p&gt;
    &lt;p&gt;Leanna Garfield&lt;/p&gt;
    &lt;p&gt;Mitch Morton&lt;/p&gt;
    &lt;p&gt;EBertsch&lt;/p&gt;
    &lt;p&gt;Darryl Rubarth&lt;/p&gt;
    &lt;p&gt;Laurence Favrot&lt;/p&gt;
    &lt;p&gt;Dakota Sillyman&lt;/p&gt;
    &lt;p&gt;Soren Larson&lt;/p&gt;
    &lt;p&gt;Andres Palau&lt;/p&gt;
    &lt;p&gt;Steve Duggan&lt;/p&gt;
    &lt;p&gt;Phil Wolff&lt;/p&gt;
    &lt;p&gt;Zach Jordan&lt;/p&gt;
    &lt;p&gt;Asher Wolf&lt;/p&gt;
    &lt;p&gt;Rainey Reitman&lt;/p&gt;
    &lt;p&gt;David Grimm&lt;/p&gt;
    &lt;p&gt;Belmer Negrillo&lt;/p&gt;
    &lt;p&gt;Courtney Harrness&lt;/p&gt;
    &lt;p&gt;Anuj Ahooja&lt;/p&gt;
    &lt;p&gt;Kiran Scott de Martinville&lt;/p&gt;
    &lt;p&gt;Greg Breidenbach&lt;/p&gt;
    &lt;p&gt;Deji Akomolafe&lt;/p&gt;
    &lt;p&gt;Wayne Westerman&lt;/p&gt;
    &lt;p&gt;Vamp Hallow&lt;/p&gt;
    &lt;p&gt;Ivan Leon&lt;/p&gt;
    &lt;p&gt;Nuno André&lt;/p&gt;
    &lt;p&gt;Sunny G&lt;/p&gt;
    &lt;p&gt;Gabriela Andrade&lt;/p&gt;
    &lt;p&gt;Scott Frankum&lt;/p&gt;
    &lt;p&gt;Benoît Mayaux&lt;/p&gt;
    &lt;p&gt;Les Horne&lt;/p&gt;
    &lt;p&gt;Patricio J. Garcia&lt;/p&gt;
    &lt;p&gt;Kir Peñalber&lt;/p&gt;
    &lt;p&gt;Pradeep Das&lt;/p&gt;
    &lt;p&gt;Oliver Segovia&lt;/p&gt;
    &lt;p&gt;Matt Abrams&lt;/p&gt;
    &lt;p&gt;Sean Horgan&lt;/p&gt;
    &lt;p&gt;viv shaw&lt;/p&gt;
    &lt;p&gt;Aaron Wright&lt;/p&gt;
    &lt;p&gt;Mark Fletcher&lt;/p&gt;
    &lt;p&gt;Hansatanu Roy&lt;/p&gt;
    &lt;p&gt;Dr. Astrid J. Scholz&lt;/p&gt;
    &lt;p&gt;Michael X Crowe&lt;/p&gt;
    &lt;p&gt;Joshua Landau&lt;/p&gt;
    &lt;p&gt;Awab Khan&lt;/p&gt;
    &lt;p&gt;Beth Goldberg&lt;/p&gt;
    &lt;p&gt;Adam Lake&lt;/p&gt;
    &lt;p&gt;Andreas Liebschner&lt;/p&gt;
    &lt;p&gt;Britt Lewis&lt;/p&gt;
    &lt;p&gt;Yong Cheng Toh&lt;/p&gt;
    &lt;p&gt;paolo cardullo&lt;/p&gt;
    &lt;p&gt;Filip Zrůst&lt;/p&gt;
    &lt;p&gt;Annie Vella&lt;/p&gt;
    &lt;p&gt;Dan Pelichowski&lt;/p&gt;
    &lt;p&gt;Mike Young&lt;/p&gt;
    &lt;p&gt;Matthias Urlichs&lt;/p&gt;
    &lt;p&gt;Kilian Merrins&lt;/p&gt;
    &lt;p&gt;Friedemann Bürgel&lt;/p&gt;
    &lt;p&gt;Roy Osherove&lt;/p&gt;
    &lt;p&gt;Colin Constable&lt;/p&gt;
    &lt;p&gt;Maxime Fazilleau&lt;/p&gt;
    &lt;p&gt;Ive Verstappen&lt;/p&gt;
    &lt;p&gt;Helen Simmons&lt;/p&gt;
    &lt;p&gt;Chris Swan&lt;/p&gt;
    &lt;p&gt;Ben Shaw&lt;/p&gt;
    &lt;p&gt;Christian Bewernitz&lt;/p&gt;
    &lt;p&gt;Haustraliaer&lt;/p&gt;
    &lt;p&gt;Salvo Vaccarino&lt;/p&gt;
    &lt;p&gt;Alex Wrottesley&lt;/p&gt;
    &lt;p&gt;Lorelei Kelly&lt;/p&gt;
    &lt;p&gt;Johan Trip&lt;/p&gt;
    &lt;p&gt;Giles Copp&lt;/p&gt;
    &lt;p&gt;Mark Little&lt;/p&gt;
    &lt;p&gt;Duma Ron&lt;/p&gt;
    &lt;p&gt;Tarek Elghawaby&lt;/p&gt;
    &lt;p&gt;Krishna Kumar&lt;/p&gt;
    &lt;p&gt;Steve Moraco&lt;/p&gt;
    &lt;p&gt;Ezra Mechaber&lt;/p&gt;
    &lt;p&gt;Jamey Greenwood&lt;/p&gt;
    &lt;p&gt;Ben Reinhardt&lt;/p&gt;
    &lt;p&gt;Iris Stammberger&lt;/p&gt;
    &lt;p&gt;Michael LeRoy&lt;/p&gt;
    &lt;p&gt;Walter Viguiliouk&lt;/p&gt;
    &lt;p&gt;AHM Bazlur Rahman&lt;/p&gt;
    &lt;p&gt;Vlad Iliescu&lt;/p&gt;
    &lt;p&gt;Jeff Rivett&lt;/p&gt;
    &lt;p&gt;Russell Ong&lt;/p&gt;
    &lt;p&gt;Scott Schaffter&lt;/p&gt;
    &lt;p&gt;Chris McAvoy&lt;/p&gt;
    &lt;p&gt;Nishant Shah&lt;/p&gt;
    &lt;p&gt;Tavis Rudd&lt;/p&gt;
    &lt;p&gt;Tomas Taylor&lt;/p&gt;
    &lt;p&gt;Paolo Scanferla&lt;/p&gt;
    &lt;p&gt;Tiago Ferreira&lt;/p&gt;
    &lt;p&gt;Martha Nichols&lt;/p&gt;
    &lt;p&gt;Tom Cross&lt;/p&gt;
    &lt;p&gt;Peter Suber&lt;/p&gt;
    &lt;p&gt;Adam Coates&lt;/p&gt;
    &lt;p&gt;Maxwell Fritz&lt;/p&gt;
    &lt;p&gt;Amy Tabor&lt;/p&gt;
    &lt;p&gt;Steyn Viljoen&lt;/p&gt;
    &lt;p&gt;Danny Zuckerman&lt;/p&gt;
    &lt;p&gt;Dov Lev Drory-Lehrer&lt;/p&gt;
    &lt;p&gt;Brent Lutz&lt;/p&gt;
    &lt;p&gt;Sarah-Jane Morris&lt;/p&gt;
    &lt;p&gt;Cristian R.&lt;/p&gt;
    &lt;p&gt;Peter Dedene&lt;/p&gt;
    &lt;p&gt;Jack Marsh&lt;/p&gt;
    &lt;p&gt;huck bales&lt;/p&gt;
    &lt;p&gt;Jon Redeker&lt;/p&gt;
    &lt;p&gt;Adam Crabtree&lt;/p&gt;
    &lt;p&gt;Al Duncanson&lt;/p&gt;
    &lt;p&gt;robzinn&lt;/p&gt;
    &lt;p&gt;Michael Verdusco&lt;/p&gt;
    &lt;p&gt;Keith Delgado&lt;/p&gt;
    &lt;p&gt;Ariel Barmat&lt;/p&gt;
    &lt;p&gt;Dean Riddick&lt;/p&gt;
    &lt;p&gt;Josiah Witt&lt;/p&gt;
    &lt;p&gt;Juliette Brown&lt;/p&gt;
    &lt;p&gt;Matt Silverstein&lt;/p&gt;
    &lt;p&gt;Chris Parsons&lt;/p&gt;
    &lt;p&gt;Paul Bakaus&lt;/p&gt;
    &lt;p&gt;Ari Dyckovsky&lt;/p&gt;
    &lt;p&gt;John Naughton&lt;/p&gt;
    &lt;p&gt;Duncan Cragg&lt;/p&gt;
    &lt;p&gt;Tom larkworthy&lt;/p&gt;
    &lt;p&gt;Jason Vella&lt;/p&gt;
    &lt;p&gt;Barbara Tallent&lt;/p&gt;
    &lt;p&gt;Griffith Awuah&lt;/p&gt;
    &lt;p&gt;noumena a. hundimägi-mei&lt;/p&gt;
    &lt;p&gt;Jan Johannesson&lt;/p&gt;
    &lt;p&gt;Julia Cheung&lt;/p&gt;
    &lt;p&gt;Christian Vuye&lt;/p&gt;
    &lt;p&gt;Dan Gauger&lt;/p&gt;
    &lt;p&gt;Joel Chan&lt;/p&gt;
    &lt;p&gt;Carissa Karban&lt;/p&gt;
    &lt;p&gt;Mark Selleck&lt;/p&gt;
    &lt;p&gt;Rahul Dave&lt;/p&gt;
    &lt;p&gt;Dragon Messmer&lt;/p&gt;
    &lt;p&gt;Carmelyne Thompson&lt;/p&gt;
    &lt;p&gt;Luke Stanley&lt;/p&gt;
    &lt;p&gt;Evan Chan&lt;/p&gt;
    &lt;p&gt;Ann Poletti&lt;/p&gt;
    &lt;p&gt;David Karger&lt;/p&gt;
    &lt;p&gt;Scott Woods&lt;/p&gt;
    &lt;p&gt;Garrett Williams&lt;/p&gt;
    &lt;p&gt;Avantika Mehra&lt;/p&gt;
    &lt;p&gt;Chrisjit Xavier&lt;/p&gt;
    &lt;p&gt;Jaack65&lt;/p&gt;
    &lt;p&gt;Zach G&lt;/p&gt;
    &lt;p&gt;Mari Adkins&lt;/p&gt;
    &lt;p&gt;Firecrow Silvernight&lt;/p&gt;
    &lt;p&gt;Jediah Katz&lt;/p&gt;
    &lt;p&gt;Andy Braren&lt;/p&gt;
    &lt;p&gt;Joe Flynn&lt;/p&gt;
    &lt;p&gt;Anoop Menon&lt;/p&gt;
    &lt;p&gt;Alessio 'dottorblaster' Biancalana&lt;/p&gt;
    &lt;p&gt;Steven Vandevelde&lt;/p&gt;
    &lt;p&gt;Julian Leiss&lt;/p&gt;
    &lt;p&gt;Averill Campion&lt;/p&gt;
    &lt;p&gt;Iglika Ivanova&lt;/p&gt;
    &lt;p&gt;Stefan Lesser&lt;/p&gt;
    &lt;p&gt;Paul Hastings&lt;/p&gt;
    &lt;p&gt;Jean Jordaan&lt;/p&gt;
    &lt;p&gt;Pandi Lin&lt;/p&gt;
    &lt;p&gt;Robin Dhanwani&lt;/p&gt;
    &lt;p&gt;Torsten Goerke&lt;/p&gt;
    &lt;p&gt;Davis Keene&lt;/p&gt;
    &lt;p&gt;Stephane Raynaud&lt;/p&gt;
    &lt;p&gt;Burt Herman&lt;/p&gt;
    &lt;p&gt;Iain Henderson&lt;/p&gt;
    &lt;p&gt;C3&lt;/p&gt;
    &lt;p&gt;Frank Hajek&lt;/p&gt;
    &lt;p&gt;David de Siebenthal&lt;/p&gt;
    &lt;p&gt;William Nardi&lt;/p&gt;
    &lt;p&gt;Edson Fregni&lt;/p&gt;
    &lt;p&gt;Amy Bruckman&lt;/p&gt;
    &lt;p&gt;Mike Tarpey&lt;/p&gt;
    &lt;p&gt;Stephen Reid&lt;/p&gt;
    &lt;p&gt;Shirley Grose&lt;/p&gt;
    &lt;p&gt;Sam Caldwell&lt;/p&gt;
    &lt;p&gt;Troy S&lt;/p&gt;
    &lt;p&gt;Jeff Loney&lt;/p&gt;
    &lt;p&gt;Gene Levinson&lt;/p&gt;
    &lt;p&gt;Martin Kaufmann&lt;/p&gt;
    &lt;p&gt;Naomi Richman&lt;/p&gt;
    &lt;p&gt;Beth Bailey&lt;/p&gt;
    &lt;p&gt;Markku Pätynen&lt;/p&gt;
    &lt;p&gt;Robert Bourdeau&lt;/p&gt;
    &lt;p&gt;Art Scott&lt;/p&gt;
    &lt;p&gt;Steve Makofsky&lt;/p&gt;
    &lt;p&gt;Mark Shust&lt;/p&gt;
    &lt;p&gt;Pam Boney&lt;/p&gt;
    &lt;p&gt;Ken Norton&lt;/p&gt;
    &lt;p&gt;Circé - Marie Drouvin&lt;/p&gt;
    &lt;p&gt;Jack Baty&lt;/p&gt;
    &lt;p&gt;Angela McGuire&lt;/p&gt;
    &lt;p&gt;Sarah Drinkwater&lt;/p&gt;
    &lt;p&gt;Kate Sieck&lt;/p&gt;
    &lt;p&gt;Martín Aguilar Tello&lt;/p&gt;
    &lt;p&gt;Alex Hillman&lt;/p&gt;
    &lt;p&gt;Jon Mertz&lt;/p&gt;
    &lt;p&gt;Hamza Essahbaoui&lt;/p&gt;
    &lt;p&gt;Matt Miller&lt;/p&gt;
    &lt;p&gt;When Leggett&lt;/p&gt;
    &lt;p&gt;Hari M&lt;/p&gt;
    &lt;p&gt;David H. Collins&lt;/p&gt;
    &lt;p&gt;Christopher Sperandio&lt;/p&gt;
    &lt;p&gt;Miguel A Villarreal&lt;/p&gt;
    &lt;p&gt;McKenzie Dunlap&lt;/p&gt;
    &lt;p&gt;Andrea Borruso&lt;/p&gt;
    &lt;p&gt;Aditya Narayana K&lt;/p&gt;
    &lt;p&gt;Dave Anderson&lt;/p&gt;
    &lt;p&gt;Tony Santos&lt;/p&gt;
    &lt;p&gt;Vince Taylor&lt;/p&gt;
    &lt;p&gt;Berkley Rothmeier&lt;/p&gt;
    &lt;p&gt;Yuval Adam&lt;/p&gt;
    &lt;p&gt;Barry Parr&lt;/p&gt;
    &lt;p&gt;John Dale&lt;/p&gt;
    &lt;p&gt;Héctor Jaime&lt;/p&gt;
    &lt;p&gt;Ryan Yeske&lt;/p&gt;
    &lt;p&gt;Peter Rojas&lt;/p&gt;
    &lt;p&gt;John Allsopp&lt;/p&gt;
    &lt;p&gt;Aftab Khan&lt;/p&gt;
    &lt;p&gt;Sanders&lt;/p&gt;
    &lt;p&gt;Ned Hayes&lt;/p&gt;
    &lt;p&gt;Nate Angell&lt;/p&gt;
    &lt;p&gt;Magnús Smárason&lt;/p&gt;
    &lt;p&gt;Dave Kong&lt;/p&gt;
    &lt;p&gt;Bobby Schweizer&lt;/p&gt;
    &lt;p&gt;Tereza Bizkova&lt;/p&gt;
    &lt;p&gt;Tony Smith&lt;/p&gt;
    &lt;p&gt;Patrick Berry&lt;/p&gt;
    &lt;p&gt;Adri&lt;/p&gt;
    &lt;p&gt;Brian Brewington&lt;/p&gt;
    &lt;p&gt;Jeremy Hunsinger&lt;/p&gt;
    &lt;p&gt;Anand Iyer&lt;/p&gt;
    &lt;p&gt;Greg Sprague&lt;/p&gt;
    &lt;p&gt;Breno Colom&lt;/p&gt;
    &lt;p&gt;Mira Vogel&lt;/p&gt;
    &lt;p&gt;TJ Kolleh&lt;/p&gt;
    &lt;p&gt;Ardeshir Sepahsalar&lt;/p&gt;
    &lt;p&gt;Dawn Nunziato&lt;/p&gt;
    &lt;p&gt;Vedang Manerikar&lt;/p&gt;
    &lt;p&gt;Jk Jenzen&lt;/p&gt;
    &lt;p&gt;Paulo Peres&lt;/p&gt;
    &lt;p&gt;Anwesh Roy&lt;/p&gt;
    &lt;p&gt;Andrew Knott&lt;/p&gt;
    &lt;p&gt;Jay Patel&lt;/p&gt;
    &lt;p&gt;Autumn Gray&lt;/p&gt;
    &lt;p&gt;Patsy Wood&lt;/p&gt;
    &lt;p&gt;Jon Festinger&lt;/p&gt;
    &lt;p&gt;Guy Kerem&lt;/p&gt;
    &lt;p&gt;Adithya Nair&lt;/p&gt;
    &lt;p&gt;Gio Pandone&lt;/p&gt;
    &lt;p&gt;Shalev NessAiver&lt;/p&gt;
    &lt;p&gt;Eileen Wagner&lt;/p&gt;
    &lt;p&gt;Dan McGreal&lt;/p&gt;
    &lt;p&gt;Karen M. Olsen&lt;/p&gt;
    &lt;p&gt;Andrea Rossi&lt;/p&gt;
    &lt;p&gt;David Gasquez&lt;/p&gt;
    &lt;p&gt;willtonkin&lt;/p&gt;
    &lt;p&gt;Johan Jacobs&lt;/p&gt;
    &lt;p&gt;Iwo Piętak&lt;/p&gt;
    &lt;p&gt;Alan Shimel&lt;/p&gt;
    &lt;p&gt;Manuel Vielma&lt;/p&gt;
    &lt;p&gt;Kamil Sobkowicz&lt;/p&gt;
    &lt;p&gt;Eric Sydell&lt;/p&gt;
    &lt;p&gt;Estrella Núñez (León)&lt;/p&gt;
    &lt;p&gt;Ruthvik Peddawandla&lt;/p&gt;
    &lt;p&gt;Sam Clemente&lt;/p&gt;
    &lt;p&gt;Tero Parviainen&lt;/p&gt;
    &lt;p&gt;Moebius&lt;/p&gt;
    &lt;p&gt;Matt McCormick&lt;/p&gt;
    &lt;p&gt;Sean Simpson&lt;/p&gt;
    &lt;p&gt;Maria Michalis&lt;/p&gt;
    &lt;p&gt;Eran Sandler&lt;/p&gt;
    &lt;p&gt;Ryan Lucht&lt;/p&gt;
    &lt;p&gt;Davey M. Kim&lt;/p&gt;
    &lt;p&gt;Koven J. Smith&lt;/p&gt;
    &lt;p&gt;Jonny Burch&lt;/p&gt;
    &lt;p&gt;Jessica Roache&lt;/p&gt;
    &lt;p&gt;Todd Youngblood&lt;/p&gt;
    &lt;p&gt;Fahrio&lt;/p&gt;
    &lt;p&gt;lyel resner&lt;/p&gt;
    &lt;p&gt;David Waksberg&lt;/p&gt;
    &lt;p&gt;Chris Wessels&lt;/p&gt;
    &lt;p&gt;Uday Ramesh Phalak&lt;/p&gt;
    &lt;p&gt;Amy Jean Studdart&lt;/p&gt;
    &lt;p&gt;Blaine Garst&lt;/p&gt;
    &lt;p&gt;Martijn Verpaalen&lt;/p&gt;
    &lt;p&gt;Andrew Matthews&lt;/p&gt;
    &lt;p&gt;Kevin Nothnagel&lt;/p&gt;
    &lt;p&gt;Melissa Turner&lt;/p&gt;
    &lt;p&gt;Kurt Schrader&lt;/p&gt;
    &lt;p&gt;Abbie Morris&lt;/p&gt;
    &lt;p&gt;Colin McMillen&lt;/p&gt;
    &lt;p&gt;Nikhil Kunapuli&lt;/p&gt;
    &lt;p&gt;Dorota Moravčíková&lt;/p&gt;
    &lt;p&gt;Vivek Bhupatiraju&lt;/p&gt;
    &lt;p&gt;Tyler Griffin&lt;/p&gt;
    &lt;p&gt;Greg Petroff&lt;/p&gt;
    &lt;p&gt;Bradley Clark Royes&lt;/p&gt;
    &lt;p&gt;Chase McCoy&lt;/p&gt;
    &lt;p&gt;Federico Jarach&lt;/p&gt;
    &lt;p&gt;Mr. Cairo&lt;/p&gt;
    &lt;p&gt;Charles AW Anaman&lt;/p&gt;
    &lt;p&gt;Gabriel Salkin&lt;/p&gt;
    &lt;p&gt;alsunseri&lt;/p&gt;
    &lt;p&gt;Alan Lewis&lt;/p&gt;
    &lt;p&gt;Vlad Georgescu&lt;/p&gt;
    &lt;p&gt;Daryl vines&lt;/p&gt;
    &lt;p&gt;Alun Machin&lt;/p&gt;
    &lt;p&gt;Clay Devlin&lt;/p&gt;
    &lt;p&gt;Drew Whitehouse&lt;/p&gt;
    &lt;p&gt;John Masson&lt;/p&gt;
    &lt;p&gt;Sage Hunter Bornstein&lt;/p&gt;
    &lt;p&gt;Campbell Macdonald&lt;/p&gt;
    &lt;p&gt;Kelly Lucas&lt;/p&gt;
    &lt;p&gt;Martin Compton&lt;/p&gt;
    &lt;p&gt;Daniel Waterhouse&lt;/p&gt;
    &lt;p&gt;Graham Mitchell&lt;/p&gt;
    &lt;p&gt;Fábio Corrêa&lt;/p&gt;
    &lt;p&gt;Alexa Chirnoaga&lt;/p&gt;
    &lt;p&gt;Priya bhunia&lt;/p&gt;
    &lt;p&gt;Rand Arete&lt;/p&gt;
    &lt;p&gt;Nicholas Underwood&lt;/p&gt;
    &lt;p&gt;Ingrid (kaslkaos) Schmelter&lt;/p&gt;
    &lt;p&gt;Florent Michel&lt;/p&gt;
    &lt;p&gt;Michael Saltzman&lt;/p&gt;
    &lt;p&gt;Jayson Margalus&lt;/p&gt;
    &lt;p&gt;Aaron Careaga&lt;/p&gt;
    &lt;p&gt;Safak Gezer&lt;/p&gt;
    &lt;p&gt;Paa Yaw&lt;/p&gt;
    &lt;p&gt;Matt Daily&lt;/p&gt;
    &lt;p&gt;Bill Dybas&lt;/p&gt;
    &lt;p&gt;Dave Karpf&lt;/p&gt;
    &lt;p&gt;Jesse Brown&lt;/p&gt;
    &lt;p&gt;Carolina Capetillo&lt;/p&gt;
    &lt;p&gt;Drew Marshall&lt;/p&gt;
    &lt;p&gt;Paul Weisser&lt;/p&gt;
    &lt;p&gt;Carlson Cheng&lt;/p&gt;
    &lt;p&gt;Christopher Davis&lt;/p&gt;
    &lt;p&gt;Tracy Leung&lt;/p&gt;
    &lt;p&gt;Sina Khanifar&lt;/p&gt;
    &lt;p&gt;Tom c Phillips&lt;/p&gt;
    &lt;p&gt;Nabiha Syed&lt;/p&gt;
    &lt;p&gt;Scott C. Anderson&lt;/p&gt;
    &lt;p&gt;David Smooke&lt;/p&gt;
    &lt;p&gt;Carissa Bilinski&lt;/p&gt;
    &lt;p&gt;Keith Phelan&lt;/p&gt;
    &lt;p&gt;Evan Blonien&lt;/p&gt;
    &lt;p&gt;Jim Santo&lt;/p&gt;
    &lt;p&gt;Dave Edwards&lt;/p&gt;
    &lt;p&gt;Masayuki Hatta&lt;/p&gt;
    &lt;p&gt;Kyle Allebach&lt;/p&gt;
    &lt;p&gt;Kyle Monson&lt;/p&gt;
    &lt;p&gt;Jenny Zhang&lt;/p&gt;
    &lt;p&gt;Lalit Merani&lt;/p&gt;
    &lt;p&gt;Javier Pallero&lt;/p&gt;
    &lt;p&gt;Matt Knight&lt;/p&gt;
    &lt;p&gt;Danilo Maurizio&lt;/p&gt;
    &lt;p&gt;John Panzer&lt;/p&gt;
    &lt;p&gt;Jill Metcalfe&lt;/p&gt;
    &lt;p&gt;Khoa Nguyen&lt;/p&gt;
    &lt;p&gt;Violet Harris&lt;/p&gt;
    &lt;p&gt;Jason Prunty&lt;/p&gt;
    &lt;p&gt;Evelyn Osman&lt;/p&gt;
    &lt;p&gt;Christoph Ono&lt;/p&gt;
    &lt;p&gt;Mark Mosedale&lt;/p&gt;
    &lt;p&gt;dane&lt;/p&gt;
    &lt;p&gt;Benjamin Taghavi-Awal&lt;/p&gt;
    &lt;p&gt;Charlie Vayas&lt;/p&gt;
    &lt;p&gt;Vlad Nicolescu&lt;/p&gt;
    &lt;p&gt;Peter Keating&lt;/p&gt;
    &lt;p&gt;Bas Grasmayer&lt;/p&gt;
    &lt;p&gt;Eugen Dunlap&lt;/p&gt;
    &lt;p&gt;Dan Schmidt&lt;/p&gt;
    &lt;p&gt;Wesley Faulkner&lt;/p&gt;
    &lt;p&gt;Don Goodspeed&lt;/p&gt;
    &lt;p&gt;Kris Decoodt&lt;/p&gt;
    &lt;p&gt;JdF&lt;/p&gt;
    &lt;p&gt;Tyler Sellhorn&lt;/p&gt;
    &lt;p&gt;Brita Shor&lt;/p&gt;
    &lt;p&gt;Corey Hayes&lt;/p&gt;
    &lt;p&gt;craig ts&lt;/p&gt;
    &lt;p&gt;Antoine Bérubé&lt;/p&gt;
    &lt;p&gt;Collin DePaemelere&lt;/p&gt;
    &lt;p&gt;Sean Dwyer&lt;/p&gt;
    &lt;p&gt;Casey Wahl&lt;/p&gt;
    &lt;p&gt;Jacob Seiler&lt;/p&gt;
    &lt;p&gt;CJ Wunsch&lt;/p&gt;
    &lt;p&gt;Julien Silland&lt;/p&gt;
    &lt;p&gt;Jess Holbrook&lt;/p&gt;
    &lt;p&gt;Ashleigh Broadfoot&lt;/p&gt;
    &lt;p&gt;David Worrell&lt;/p&gt;
    &lt;p&gt;Thibaud Teil&lt;/p&gt;
    &lt;p&gt;Haley Teil&lt;/p&gt;
    &lt;p&gt;Azalea Holder&lt;/p&gt;
    &lt;p&gt;rodrigo arcaya&lt;/p&gt;
    &lt;p&gt;Om Sonone&lt;/p&gt;
    &lt;p&gt;Isaac&lt;/p&gt;
    &lt;p&gt;Sam Klein&lt;/p&gt;
    &lt;p&gt;Fabian Morón Zirfas&lt;/p&gt;
    &lt;p&gt;Madhu Sriram&lt;/p&gt;
    &lt;p&gt;Eric John Olson&lt;/p&gt;
    &lt;p&gt;Eltons Kūns&lt;/p&gt;
    &lt;p&gt;Laura Christianson&lt;/p&gt;
    &lt;p&gt;Ondřej Konečný&lt;/p&gt;
    &lt;p&gt;Josh Woods&lt;/p&gt;
    &lt;p&gt;Etienne Amaral&lt;/p&gt;
    &lt;p&gt;Paweł Pasikowski&lt;/p&gt;
    &lt;p&gt;Brett Witty&lt;/p&gt;
    &lt;p&gt;Ben Mayberry&lt;/p&gt;
    &lt;p&gt;Brenda Lucena&lt;/p&gt;
    &lt;p&gt;Martina Pugliese&lt;/p&gt;
    &lt;p&gt;Bader Abdulwaseem&lt;/p&gt;
    &lt;p&gt;Josiah Evans&lt;/p&gt;
    &lt;p&gt;Andreas Gabor&lt;/p&gt;
    &lt;p&gt;Neil Winterburn&lt;/p&gt;
    &lt;p&gt;Marcel R. Bülles&lt;/p&gt;
    &lt;p&gt;Damiano Sabuzi Giuliani&lt;/p&gt;
    &lt;p&gt;Marcello Seri&lt;/p&gt;
    &lt;p&gt;Alejandra Cruz García&lt;/p&gt;
    &lt;p&gt;Bastien Giraud&lt;/p&gt;
    &lt;p&gt;Justin Lieb&lt;/p&gt;
    &lt;p&gt;Stefan Munz&lt;/p&gt;
    &lt;p&gt;Sari Azout&lt;/p&gt;
    &lt;p&gt;Annafi Wahed&lt;/p&gt;
    &lt;p&gt;Gil Friend&lt;/p&gt;
    &lt;p&gt;Craig Trim&lt;/p&gt;
    &lt;p&gt;Dana E. Barnard&lt;/p&gt;
    &lt;p&gt;Alyssa Panetta&lt;/p&gt;
    &lt;p&gt;J. Rodier&lt;/p&gt;
    &lt;p&gt;Austin Jackson&lt;/p&gt;
    &lt;p&gt;Kram&lt;/p&gt;
    &lt;p&gt;Charlie Rolph-Kevlahan&lt;/p&gt;
    &lt;p&gt;Paul Swail&lt;/p&gt;
    &lt;p&gt;Duncan Cox&lt;/p&gt;
    &lt;p&gt;Bryant Macy&lt;/p&gt;
    &lt;p&gt;Paul Hoffman&lt;/p&gt;
    &lt;p&gt;Venessa Paech&lt;/p&gt;
    &lt;p&gt;Charlie Ortiz&lt;/p&gt;
    &lt;p&gt;Neil Traft&lt;/p&gt;
    &lt;p&gt;Aran Lunzer&lt;/p&gt;
    &lt;p&gt;Sarah Schmidt&lt;/p&gt;
    &lt;p&gt;Carl Flippin&lt;/p&gt;
    &lt;p&gt;DaveGeer&lt;/p&gt;
    &lt;p&gt;omoju miller&lt;/p&gt;
    &lt;p&gt;Jort Hessel&lt;/p&gt;
    &lt;p&gt;Fabrizio Poltronieri&lt;/p&gt;
    &lt;p&gt;V3L&lt;/p&gt;
    &lt;p&gt;Vianney Vaute&lt;/p&gt;
    &lt;p&gt;Jakub Mirovsky&lt;/p&gt;
    &lt;p&gt;Nick Sng&lt;/p&gt;
    &lt;p&gt;John Lemme&lt;/p&gt;
    &lt;p&gt;Eric Darley&lt;/p&gt;
    &lt;p&gt;Alexander Melville&lt;/p&gt;
    &lt;p&gt;Phillip Shreves&lt;/p&gt;
    &lt;p&gt;Ingo Boltz&lt;/p&gt;
    &lt;p&gt;Anjon Roy&lt;/p&gt;
    &lt;p&gt;Jenny&lt;/p&gt;
    &lt;p&gt;Matthew Kreiling&lt;/p&gt;
    &lt;p&gt;Izanogi&lt;/p&gt;
    &lt;p&gt;Jonathan Garbee&lt;/p&gt;
    &lt;p&gt;Greg Fong&lt;/p&gt;
    &lt;p&gt;Anjali Bhide&lt;/p&gt;
    &lt;p&gt;Mimi Reyburn&lt;/p&gt;
    &lt;p&gt;Dart Lindsley&lt;/p&gt;
    &lt;p&gt;Nithilan Rameshkumar&lt;/p&gt;
    &lt;p&gt;Esteban Ordano&lt;/p&gt;
    &lt;p&gt;Dozie Anyaegbunam&lt;/p&gt;
    &lt;p&gt;Gerard Fox&lt;/p&gt;
    &lt;p&gt;Pete Mandas&lt;/p&gt;
    &lt;p&gt;Sebastian Gold&lt;/p&gt;
    &lt;p&gt;Alistair Knock&lt;/p&gt;
    &lt;p&gt;Máximo Gavete&lt;/p&gt;
    &lt;p&gt;Ruairi Laughlin-McCann&lt;/p&gt;
    &lt;p&gt;Kim Peiter Jorgensen&lt;/p&gt;
    &lt;p&gt;Roland Pascoe&lt;/p&gt;
    &lt;p&gt;Sungho Yoo&lt;/p&gt;
    &lt;p&gt;Theo Foley&lt;/p&gt;
    &lt;p&gt;danijel&lt;/p&gt;
    &lt;p&gt;Diana Mas&lt;/p&gt;
    &lt;p&gt;Jacob Sandlund&lt;/p&gt;
    &lt;p&gt;Uli Paulin&lt;/p&gt;
    &lt;p&gt;Chris M&lt;/p&gt;
    &lt;p&gt;John Seeley&lt;/p&gt;
    &lt;p&gt;Aaron G Neyer&lt;/p&gt;
    &lt;p&gt;Finn Markham&lt;/p&gt;
    &lt;p&gt;Daniel Barter&lt;/p&gt;
    &lt;p&gt;Will Abramson&lt;/p&gt;
    &lt;p&gt;Anir Nair&lt;/p&gt;
    &lt;p&gt;Utkarsh Gupta&lt;/p&gt;
    &lt;p&gt;Philipp Markolin&lt;/p&gt;
    &lt;p&gt;Ron Welch&lt;/p&gt;
    &lt;p&gt;Gustavo Moreira&lt;/p&gt;
    &lt;p&gt;Toni Aittoniemi&lt;/p&gt;
    &lt;p&gt;Andrew Dunn&lt;/p&gt;
    &lt;p&gt;Akhil Puri&lt;/p&gt;
    &lt;p&gt;Jay Rivera&lt;/p&gt;
    &lt;p&gt;Patricia Cartes&lt;/p&gt;
    &lt;p&gt;Joshua Stübner&lt;/p&gt;
    &lt;p&gt;Jae Yoon&lt;/p&gt;
    &lt;p&gt;Alfredo Serafini&lt;/p&gt;
    &lt;p&gt;Gabriel Melian&lt;/p&gt;
    &lt;p&gt;Nalin Kapoor&lt;/p&gt;
    &lt;p&gt;Dave Roselle&lt;/p&gt;
    &lt;p&gt;Farzin Nasiri&lt;/p&gt;
    &lt;p&gt;Andrew Lyjak&lt;/p&gt;
    &lt;p&gt;A. Galvan&lt;/p&gt;
    &lt;p&gt;Vicki Tan&lt;/p&gt;
    &lt;p&gt;M. Z. Mitchell Zheng&lt;/p&gt;
    &lt;p&gt;Madison Hsieh&lt;/p&gt;
    &lt;p&gt;Kyle Welch&lt;/p&gt;
    &lt;p&gt;Max Weese&lt;/p&gt;
    &lt;p&gt;Elisa Beshero-Bondar&lt;/p&gt;
    &lt;p&gt;Damashe Thomas&lt;/p&gt;
    &lt;p&gt;Alex Morisse&lt;/p&gt;
    &lt;p&gt;Greg Witt&lt;/p&gt;
    &lt;p&gt;Brian Karlak&lt;/p&gt;
    &lt;p&gt;Gabriel Krieshok&lt;/p&gt;
    &lt;p&gt;David Fox&lt;/p&gt;
    &lt;p&gt;Brian Hill&lt;/p&gt;
    &lt;p&gt;Randy Vane&lt;/p&gt;
    &lt;p&gt;Nick Sedlet&lt;/p&gt;
    &lt;p&gt;Manuviraj Godara&lt;/p&gt;
    &lt;p&gt;Gimena del Rio Riande&lt;/p&gt;
    &lt;p&gt;Brendan O'Brien&lt;/p&gt;
    &lt;p&gt;Kory Kilpatrick&lt;/p&gt;
    &lt;p&gt;Ben Munat&lt;/p&gt;
    &lt;p&gt;Melanie Kahl&lt;/p&gt;
    &lt;p&gt;Jimmy Lindsey&lt;/p&gt;
    &lt;p&gt;Clay Shentrup&lt;/p&gt;
    &lt;p&gt;Dongyuan Liu&lt;/p&gt;
    &lt;p&gt;Gaurav Ramesh&lt;/p&gt;
    &lt;p&gt;İrem Küçükali&lt;/p&gt;
    &lt;p&gt;Ankur Kumar&lt;/p&gt;
    &lt;p&gt;paul dariye&lt;/p&gt;
    &lt;p&gt;Sara Lindey&lt;/p&gt;
    &lt;p&gt;svitlana midianko&lt;/p&gt;
    &lt;p&gt;Denis Sosnovtsev&lt;/p&gt;
    &lt;p&gt;Jaxx Brown&lt;/p&gt;
    &lt;p&gt;Dr Aaron Breidenbach&lt;/p&gt;
    &lt;p&gt;James Uther&lt;/p&gt;
    &lt;p&gt;Damir Kombikov&lt;/p&gt;
    &lt;p&gt;Jahed Momand&lt;/p&gt;
    &lt;p&gt;Dai Griffiths&lt;/p&gt;
    &lt;p&gt;John Carosella Gardner&lt;/p&gt;
    &lt;p&gt;Mike McCue&lt;/p&gt;
    &lt;p&gt;Seyed Danesh&lt;/p&gt;
    &lt;p&gt;Daveed Benjamin&lt;/p&gt;
    &lt;p&gt;Andreas Ringman Uggla&lt;/p&gt;
    &lt;p&gt;Tor Guttorm&lt;/p&gt;
    &lt;p&gt;Simon H.&lt;/p&gt;
    &lt;p&gt;Balázs Búzás&lt;/p&gt;
    &lt;p&gt;Lamine BARRO&lt;/p&gt;
    &lt;p&gt;Trung Nguyen&lt;/p&gt;
    &lt;p&gt;Howard Stearns&lt;/p&gt;
    &lt;p&gt;Sean Leow&lt;/p&gt;
    &lt;p&gt;Vlad Cealicu&lt;/p&gt;
    &lt;p&gt;Cole Bittel&lt;/p&gt;
    &lt;p&gt;Brian Rinaldi&lt;/p&gt;
    &lt;p&gt;Rosalma Zubizarreta-Ada&lt;/p&gt;
    &lt;p&gt;Marcel Neuhausler&lt;/p&gt;
    &lt;p&gt;Thanh-Mai Phan&lt;/p&gt;
    &lt;p&gt;Pavle Matic&lt;/p&gt;
    &lt;p&gt;David Kunin&lt;/p&gt;
    &lt;p&gt;Jack Crawford&lt;/p&gt;
    &lt;p&gt;Jonathan Chomko&lt;/p&gt;
    &lt;p&gt;Nick Hagar&lt;/p&gt;
    &lt;p&gt;Craig Mod&lt;/p&gt;
    &lt;p&gt;Mike Elgan&lt;/p&gt;
    &lt;p&gt;Bartus Csongor&lt;/p&gt;
    &lt;p&gt;Shreyan Jain&lt;/p&gt;
    &lt;p&gt;David Critics&lt;/p&gt;
    &lt;p&gt;Seth Etter&lt;/p&gt;
    &lt;p&gt;Tim Jarratt&lt;/p&gt;
    &lt;p&gt;D. Ben Knoble&lt;/p&gt;
    &lt;p&gt;Edan Krolewicz&lt;/p&gt;
    &lt;p&gt;Laura S&lt;/p&gt;
    &lt;p&gt;Justin Manley&lt;/p&gt;
    &lt;p&gt;Brandon Lee&lt;/p&gt;
    &lt;p&gt;Egor Andreevich&lt;/p&gt;
    &lt;p&gt;Matt Baxter&lt;/p&gt;
    &lt;p&gt;Noah Van Loen&lt;/p&gt;
    &lt;p&gt;Chad O&lt;/p&gt;
    &lt;p&gt;Abhinav Ramachandran&lt;/p&gt;
    &lt;p&gt;Enrique Dans&lt;/p&gt;
    &lt;p&gt;mukesh agrawal&lt;/p&gt;
    &lt;p&gt;ConanXin&lt;/p&gt;
    &lt;p&gt;Varun Shijo&lt;/p&gt;
    &lt;p&gt;Phillip Traulsen&lt;/p&gt;
    &lt;p&gt;Juan Calero&lt;/p&gt;
    &lt;p&gt;Ashley Rolfmore&lt;/p&gt;
    &lt;p&gt;Pasquale Di Maria&lt;/p&gt;
    &lt;p&gt;ed Ropple&lt;/p&gt;
    &lt;p&gt;Thomas Moll&lt;/p&gt;
    &lt;p&gt;Last NPC Alex&lt;/p&gt;
    &lt;p&gt;Eric Boersma&lt;/p&gt;
    &lt;p&gt;Bronte Sihan Li&lt;/p&gt;
    &lt;p&gt;Moto Ishizawa&lt;/p&gt;
    &lt;p&gt;David Schmudde&lt;/p&gt;
    &lt;p&gt;John Lardee&lt;/p&gt;
    &lt;p&gt;Sarah Hack&lt;/p&gt;
    &lt;p&gt;Sipho Langa&lt;/p&gt;
    &lt;p&gt;Rob Reagan&lt;/p&gt;
    &lt;p&gt;Shreenath Regunathan&lt;/p&gt;
    &lt;p&gt;David Stern&lt;/p&gt;
    &lt;p&gt;Alex Márquez Pérez&lt;/p&gt;
    &lt;p&gt;Saskia Keskpaik&lt;/p&gt;
    &lt;p&gt;Chuck Donaldson&lt;/p&gt;
    &lt;p&gt;Vasilis Giannoulis&lt;/p&gt;
    &lt;p&gt;Marco Cesati&lt;/p&gt;
    &lt;p&gt;Rikard Linde&lt;/p&gt;
    &lt;p&gt;José David Carbajo&lt;/p&gt;
    &lt;p&gt;Wolfgang Miller&lt;/p&gt;
    &lt;p&gt;Peter Bartr Reiner&lt;/p&gt;
    &lt;p&gt;Joel Hall&lt;/p&gt;
    &lt;p&gt;Helene Goldberg&lt;/p&gt;
    &lt;p&gt;glhein&lt;/p&gt;
    &lt;p&gt;Anupam Goel&lt;/p&gt;
    &lt;p&gt;Erica Schumacher&lt;/p&gt;
    &lt;p&gt;Gabrielle Pelletier&lt;/p&gt;
    &lt;p&gt;Sander McComiskey&lt;/p&gt;
    &lt;p&gt;Ishan Ghorela&lt;/p&gt;
    &lt;p&gt;Michael Garfield&lt;/p&gt;
    &lt;p&gt;Bodhi Hill&lt;/p&gt;
    &lt;p&gt;Sarah Andrabi&lt;/p&gt;
    &lt;p&gt;Ben Meneses-Sosa&lt;/p&gt;
    &lt;p&gt;Jonathan Masters&lt;/p&gt;
    &lt;p&gt;Steve Arvedson&lt;/p&gt;
    &lt;p&gt;Chad Walker&lt;/p&gt;
    &lt;p&gt;Georgia Pears&lt;/p&gt;
    &lt;p&gt;Stefan Werner&lt;/p&gt;
    &lt;p&gt;Nick Brody&lt;/p&gt;
    &lt;p&gt;David P.&lt;/p&gt;
    &lt;p&gt;Oscar Smith&lt;/p&gt;
    &lt;p&gt;Paul Bauer&lt;/p&gt;
    &lt;p&gt;Paul Tibbits&lt;/p&gt;
    &lt;p&gt;Jürgen Höhe&lt;/p&gt;
    &lt;p&gt;Andrew Sorcini&lt;/p&gt;
    &lt;p&gt;Sreedhar K&lt;/p&gt;
    &lt;p&gt;Warren Stringer&lt;/p&gt;
    &lt;p&gt;Katie braund&lt;/p&gt;
    &lt;p&gt;Ryan Hodgman&lt;/p&gt;
    &lt;p&gt;Ernst Hafen&lt;/p&gt;
    &lt;p&gt;John Knox&lt;/p&gt;
    &lt;p&gt;Alberto Medina&lt;/p&gt;
    &lt;p&gt;Wei Zhou&lt;/p&gt;
    &lt;p&gt;Samuel Ratnam&lt;/p&gt;
    &lt;p&gt;Vivek Dhami&lt;/p&gt;
    &lt;p&gt;Daniel Gillis&lt;/p&gt;
    &lt;p&gt;Richard Newman&lt;/p&gt;
    &lt;p&gt;Nico Ward&lt;/p&gt;
    &lt;p&gt;Osarumen Osamuyi&lt;/p&gt;
    &lt;p&gt;Ovidiu Mățan&lt;/p&gt;
    &lt;p&gt;David Congour&lt;/p&gt;
    &lt;p&gt;Andie Bandie&lt;/p&gt;
    &lt;p&gt;Justin Irabor&lt;/p&gt;
    &lt;p&gt;Eddy Lee&lt;/p&gt;
    &lt;p&gt;Sandeep M&lt;/p&gt;
    &lt;p&gt;Sergey Votyagov&lt;/p&gt;
    &lt;p&gt;Gina Biernacki&lt;/p&gt;
    &lt;p&gt;Felipe Chor&lt;/p&gt;
    &lt;p&gt;Kevin George&lt;/p&gt;
    &lt;p&gt;Dan Cayer&lt;/p&gt;
    &lt;p&gt;Substantive changes that have been made to this manifesto:&lt;/p&gt;
    &lt;p&gt;11/18/25 - Changed several instances of the word "user," to "people" or other humanistic alternatives. The word user carries heavy connotations of addiction.&lt;/p&gt;
    &lt;p&gt;10/28/25 - Updated the first principle (private) to include more nuanced language around the ownership of data. People must be the primary stewards of their context, but every system has multiple stakeholders.&lt;/p&gt;
    &lt;p&gt;10/28/25 - Updated the second principle (dedicated) to include the "contextual integrity" privacy model.&lt;/p&gt;
    &lt;p&gt;10/27/25 - Added header artwork and poetic introduction.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://resonantcomputing.org/"/><published>2026-01-17T16:43:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46659465</id><title>Apples, Trees, and Quasimodes</title><updated>2026-01-17T17:08:54.281654+00:00</updated><content>&lt;doc fingerprint="fd9b9b1c22e783ab"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Apples, Trees, and Quasimodes&lt;/head&gt;
    &lt;p&gt;A while back, Ars Technica published a thoughtful piece about Jef Raskin, tracing his long pursuit of the “humane computer” and the cul-de-sacs where that pursuit ended. It’s a generous, well-told account of the designer who wanted to make machines simpler, kinder, and more aligned with the way people actually think.&lt;/p&gt;
    &lt;p&gt;But part of what makes Raskin interesting is that his story isn’t just Apple’s story. He came out of the same cultural current John Markoff chronicled in What the Dormouse Said—the Bay Area tradition that treated computers not as office appliances but as tools for thought, instruments of liberation. Read that way, the Canon Cat and Raskin’s other projects aren’t just an eccentric side quest from a frustrated Apple veteran. It’s evidence of how far the humane ideal could stretch, and how quickly it ran up against the limits of commercial computing.&lt;/p&gt;
    &lt;p&gt;Apple couldn’t deliver Raskin’s vision then, and it can’t deliver it now. Neither can any other big platform company. If we want to understand why, and what Raskin still tells us about humane computing, we have to put him back in the longer lineage he belonged to, and look at how his version of the dream carried that vision but also narrowed it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Prophets and participants&lt;/head&gt;
    &lt;p&gt;What the Dormouse Said documents how the Bay Area counterculture shaped early personal computing. LSD, communes, systems theory, amorphous defense research contracts, and Engelbart’s “augmentation” experiments all swirled together in a weird scene that accidentally (or maybe not so accidentally) created much of the modern world.&lt;/p&gt;
    &lt;p&gt;The story usually gets told with a neat list: Engelbart’s demo, Nelson’s Xanadu hypertext, Kay’s Dynabook, Brand’s Whole Earth. Xerox PARC, Steve Jobs, the World Wide Web. The familiar pantheon. But that version turns a messy, improvisational moment into a plaque. Engelbart’s system needed a whole research staff just to operate; Nelson’s Xanadu was (and is) more sermon than software; Kay’s Dynabook lived mostly on paper; Brand mostly supplied vocabulary and vibe. What bound them together wasn’t working code so much as the conviction that computers could be more than appliances and calculators, even if no one agreed on what “more” meant.&lt;/p&gt;
    &lt;p&gt;Ultimately all these weird white guys had a futurist vision: computers could be liberation machines. They weren’t just for business automation or scientific number-crunching; they could be deployed to expand consciousness and reshape how people thought and worked.&lt;/p&gt;
    &lt;p&gt;Raskin belonged to this current. Before Apple, he was an artist and a musician. He brought a humanist’s suspicion of machine logic into the design lab. He argued for humane interfaces: modeless, predictable, low-friction, focused on the human first. He wasn’t a prophet on his own crying in the wilderness so much as another strand of the same weave.&lt;/p&gt;
    &lt;p&gt;That said, his role was different than that of some of these other figures. He tried to pull those ideals out of the lab and into machines ordinary people might actually use. The Macintosh began under his hand, though what shipped was less a tool for thought than a polished derivative—what you might call a “popular religion” of computing, stripped of the harder doctrines.&lt;/p&gt;
    &lt;p&gt;The Canon Cat and its predecessors were Raskin’s counterargument: humane, text-first systems that tried to carry the spirit of the Dormouse tradition into the commercial world without sanding off everything that made it strange. It sort of worked, but only sort of.&lt;/p&gt;
    &lt;head rend="h2"&gt;Raskin’s Humane vision&lt;/head&gt;
    &lt;p&gt;Raskin’s principles are laid out most clearly in 2000’s The Humane Interface, but he’d been developing them since the late 1970s:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Modelessness: eliminate modes generally, and especially when they confuse users or are hard to reason about.&lt;/item&gt;
      &lt;item&gt;Quasimodes: short-lived states (like holding a key down) that don’t trap the user.&lt;/item&gt;
      &lt;item&gt;Humane defaults: undo everywhere, consistent commands, predictable behavior.&lt;/item&gt;
      &lt;item&gt;Low cognitive load: interfaces designed around human memory and perception limits.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These ideas are recognizably part of the “Tools for Thought” tradition. Like Engelbart and the others, he wanted to reduce friction between thought and machine. Like Nelson, he believed in fluidity and extension.&lt;/p&gt;
    &lt;p&gt;But there’s a subtle difference. For Engelbart, augmentation meant complexity: bootstrapping a system so wild it demanded co-evolution between user and tool. For Nelson, it meant endless layers of possibility. For Raskin, it often meant protection or constraint. Humane computing wasn’t only about empowerment… often it was about shielding users from mistakes, overload, and confusion.&lt;/p&gt;
    &lt;p&gt;That protective impulse would shape the systems he built.&lt;/p&gt;
    &lt;p&gt;Raskin’s first clear articulation of his humane ideals wasn’t hardware at all but The Macintosh Papers, his internal proposal at Apple for a low-cost, appliance-like computer that would boot straight into a simple, modeless interface. The Mac project that followed eventually diverged—under Steve Jobs it became a graphical machine aimed at competing with the Lisa, for the reasons we’ve all read about—but Raskin’s vision was considerably more radical. He imagined a computer that behaved less like a business workstation and more like a humane, everyday tool.&lt;/p&gt;
    &lt;p&gt;In tone, the Macintosh Papers have more in common with Ted Nelson’s Computer Lib than with any corporate white paper. They read like a manifesto: plainspoken, insistent, arguing that ordinary people deserved machines that bent to them rather than the other way around. Where Nelson declared that “you can and must understand computers now,” Raskin’s papers laid out what such a computer should look like if you started from human needs instead of technical conventions. Both belong to that peculiar genre of the 1970s and early ’80s: the computing manifesto as cultural text, half engineering and half tract.1&lt;/p&gt;
    &lt;p&gt;You could argue that the Swyft, built a few years later by his company Information Appliance Inc., was “the real Macintosh” in that sense. Compact and text-first, it booted instantly, eliminated modes, and introduced the Leap keys for fluid navigation. It was Raskin’s manifesto rendered in hardware. But the Swyft never made it to market; without a manufacturer to back it, Information Appliance pivoted to the SwyftCard, a fallback product that brought the same interface into the Apple II while IA waited to find a dance partner.&lt;/p&gt;
    &lt;p&gt;That partner came briefly in 1987, when Canon released the Canon Cat, the only mass-produced computer to carry Raskin’s humane vision into the world. The Cat retained the Swyft’s defining ideas: instant boot into a blank page, consistent commands, Leap-based navigation. Marketed as a word processor, it was framed as an appliance for the office rather than an exploratory tool for thought.&lt;/p&gt;
    &lt;p&gt;After its failure, Raskin returned to the same design principles in the 1990s with Archy, an unfinished software environment that tried once again to realize his humane interface on contemporary hardware. Archy never reached a finished state, but it shows how Raskin’s ideas kept circling back to the same point: computing stripped down to words, presented as simply and predictably as possible.&lt;/p&gt;
    &lt;p&gt;I’ve always had a real fondness for the Swyft/Cat lineage, and it’s certainly influenced what I think a computer can be. Each one of these attempts embodied humane design: a blank screen for writing, consistent commands, no modes to trip over. The Cat in particular was radical in its way—a computer designed to feel less like a computer and more like a natural extension of the mind. It truly could have changed everything about how we use our computers had it succeeded.&lt;/p&gt;
    &lt;p&gt;Unfortunately for all of us, by 1987, the market for dedicated word processors was already fading. Canon didn’t seem to know what to do with the Cat—whether to sell it as an office appliance, a PC competitor, or something stranger—and the result was that it fit nowhere. Raskin’s design pushed toward humane simplicity, but Canon’s marketing treated it like just another machine for typing memos.&lt;/p&gt;
    &lt;p&gt;It isn’t surprising that it failed, though it’s hard not to wonder how it might have landed a few years earlier, when the ground was more open. As it is, the Cat survives less as a commercial product than as an idea in hardware—a glimpse of what a computer could look like if the whole thing were rebuilt around text, consistency, and genuine care for the user.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Paradox of Openness&lt;/head&gt;
    &lt;p&gt;The Cat also embodies why Raskin’s philosophy was not necessarily on the same wavelength as some of those other visionary systems. On the surface, the Canon Cat looked open. It booted to a blank screen. Everything was text. You could jump anywhere, edit fluidly, undo anything. Compared to the modal labyrinth of DOS or early Mac software, it felt like freedom.&lt;/p&gt;
    &lt;p&gt;But look closer and you see the narrowing. The Cat gave you fewer ways to improvise. Its humane design was also constraining design. It reduced your options in order to keep you safe.&lt;/p&gt;
    &lt;p&gt;The real irony is that the Cat wasn’t even truly closed in the way a smartphone or Chromebook might be considered so today. Underneath, it ran on a Forth environment. You could, if you knew how, drop into Forth and even program directly in 68k assembler. In principle, it was as open as any hacker could want, at least from a software perspective.&lt;/p&gt;
    &lt;p&gt;The catch was cultural, not technical. From the Ars piece:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;IAI’s back door to Forth quietly shipped in every Cat, and the clue was a curious omission in the online help: USE FRONT-ANSWER. This otherwise unexplained and unused key combination was the gateway. If you entered the string&lt;/p&gt;&lt;code&gt;Enable Forth Language&lt;/code&gt;, highlighted it, and evaluated it with USE FRONT-ANSWER (not CALC; usually Control-Backspace in MAME), you’d get a Forth&lt;code&gt;ok&lt;/code&gt;prompt, and the system was now yours. Reset the Cat or type&lt;code&gt;re&lt;/code&gt;to return to the editor.&lt;/quote&gt;
    &lt;p&gt;Canon didn’t provide documentation that would have made that power accessible, and Raskin’s design philosophy treated it as outside the normal use case. Extensibility was there if you knew where to look for it, but it wasn’t encouraged. The humane interface was meant to keep most users away from the hood, even though what was under the hood was remarkably open.&lt;/p&gt;
    &lt;p&gt;That makes the Cat’s paradox sharper: it was a genuinely extensible software environment (up to a point) presented as a sealed appliance. The hardware mostly was a sealed appliance. Contrast this with Emacs or Smalltalk, where openness is the posture of the environment itself. You are expected to extend and reshape as you go, building your tools out of themselves. The Cat offered the same possibility–Forth is a remarkably flexible language, especially for microcomputers–but it discouraged you from taking it.&lt;/p&gt;
    &lt;p&gt;Humane computing, in Raskin’s hands, edged toward hermetic computing. He built openness in, but sealed it away behind an interface designed to keep it out of sight.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cul-de-sacs vs. Branches&lt;/head&gt;
    &lt;p&gt;All of this, to me, is why calling Raskin’s systems thinking a “cul-de-sac” misses the point, and is the wrong way to think about his legacy.&lt;/p&gt;
    &lt;p&gt;If “cul-de-sac” means “product that didn’t sell,” then sure, the Cat and SwyftCard qualify. They were total dead-ends. But by that same measure, Engelbart’s NLS, Nelson’s Xanadu, Kay’s Smalltalk, or even Lotus Agenda are dead-ends, too. By that measure, most of the “Tools for Thought” tradition didn’t lead anywhere.&lt;/p&gt;
    &lt;p&gt;The reality is different. These systems were branches. They were rhizomes, in the Deleuze and Guattari sense. They didn’t reach the mainstream, but they seeded ideas that echoed elsewhere, connecting threads that run throughout the history of computing. Hypertext, graphical interfaces, undo, modeless editing—all of these survived in one form or another.&lt;/p&gt;
    &lt;p&gt;Raskin’s branch is no exception. His machines exposed a fundamental tension inside the tradition: how far do you go in protecting the user from complexity? At what point does “humane” become “hermetic”? Those questions didn’t vanish with the Cat. They’re still with us every time a productivity app promises “simplicity” at the cost of agency.&lt;/p&gt;
    &lt;p&gt;Raskin’s humane ideals live on in obvious ways, to the benefit of anyone using a graphical computer today—undo everywhere, discoverability, and consistent commands and shortcuts are now interface common sense. But the deeper thread, the ethos that inspired him and others in the tradition of computers as tools for thought, survived mostly outside the mainstream. It persists in systems that never had to sell millions of units or satisfy quarterly targets, that never had to justify their existence to the mass of people using PCs—tools that could afford to remain strange, open, and humane on their own terms. Emacs, Oberon, and Smalltalk belong here, but so do newer experiments like Uxn and 9front.&lt;/p&gt;
    &lt;p&gt;The Cat failed partly because it tried to straddle two worlds: commercial appliance and humane machine, whereas something like Emacs survives precisely because it never had to. It’s as complex as you want it to be.&lt;/p&gt;
    &lt;p&gt;This is the sharper point: radical, humane, exploratory computing never survives in the mainstream. The mainstream is built for profit and predictability. Even Engelbart’s work was DARPA-funded, not venture-backed. When you put humane ideals through commercial constraints, they collapse into simplistic appliances, the “For Dummies” version of the original intent. That doesn’t mean the tradition is dead. But it does mean you have to look off to the side, away from the market’s center, to see it alive.&lt;/p&gt;
    &lt;head rend="h2"&gt;The dilemma(s)&lt;/head&gt;
    &lt;p&gt;Raskin’s story sharpens two dilemmas that haven’t gone away.&lt;/p&gt;
    &lt;p&gt;The first is practical: make a system too open, and it risks being overwhelming. Make it too humane, and it risks narrowing into something sealed and hermetic, and not useful enough. The Cat, while also a victim of other factors, tried to balance the two and ended up fitting nowhere.&lt;/p&gt;
    &lt;p&gt;The lesson isn’t that humane computing is impossible. It’s that humane computing can’t just mean protective computing. It has to mean trusting users with both simplicity and openness. That’s why Org mode and even Mac System 7 endure and the Cat does not.&lt;/p&gt;
    &lt;p&gt;The deeper implication is harder, but maybe truer: the true Tools for Thought we still wish existed will never come from Apple, Microsoft, Google, OpenAI, or any other large player in the software or hardware space. They can’t. These companies’ scale and incentives point elsewhere—toward lock-in, surveillance, and products that are safe enough to sell but never open enough to empower. The logic of scale makes them constitutionally incapable of building systems that are truly humane and open. The next humane systems, if they arrive, will have to come from outside those walls, as they always have: from margins, from hobbyists, from research labs, and from stubborn communities of practice. But as those platform companies make it more and more difficult to experiment, how do we keep pushing these philosophies forward?&lt;/p&gt;
    &lt;p&gt;Jef Raskin’s philosophy isn’t a cul-de-sac in computing history. He’s responsible for a branch of the “Tools for Thought” tradition—a branch that shows both the promise and the peril of humane design. His machines make clear how far you can go when you put the human first, and how easily that ideal can collapse into constraint once it’s pushed through commercial channels and turned into walled gardens.&lt;/p&gt;
    &lt;p&gt;The humane thread survives, but only outside the center—in the tools that don’t have to answer to quarterly earnings, in projects that refuse to die just because they don’t fit the market. The Dormouse lineage isn’t gone. It just doesn’t live where the money is, because it can’t. If you want your computer to be humane in the deeper sense—not an appliance, but an instrument for thought—you have to look to the margins. That’s where it has always been, and where it still is today. If it survives, that’s where it’ll still be.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;That genre, “photocopied computer manifesto,” is very much the reason this blog exists. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Published September 18, 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://systemstack.dev/2025/09/humane-computing/"/><published>2026-01-17T16:44:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46659651</id><title>Eight European countries face 10% tariff for opposing US control of Greenland</title><updated>2026-01-17T17:08:53.876822+00:00</updated><content>&lt;doc fingerprint="6f6653200c4b99af"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Trump says 8 European countries will be charged a 10% tariff for opposing US control of Greenland&lt;/head&gt;
    &lt;head rend="h2"&gt;Trump says 8 European countries will be charged a 10% tariff for opposing US control of Greenland&lt;/head&gt;
    &lt;p&gt;NUUK, Greenland (AP) — President Donald Trump said Saturday that he would charge a 10% import tax starting in February on goods from eight European nations because of their opposition to American control of Greenland.&lt;/p&gt;
    &lt;p&gt;Trump said in a social media post that Denmark, Norway, Sweden, France, Germany, the United Kingdom, the Netherlands, and Finland would face the tariff and that it would climb to 25% on June 1 if a deal is not in place for “the Complete and Total purchase of Greenland” by the United States.&lt;/p&gt;
    &lt;p&gt;The threat of tariffs was a drastic and potentially dangerous escalation of a showdown between Trump and NATO allies, further straining an alliance that dates to 1949 and provides a collective degree of security to Europe and North America. The Republican president has repeatedly tried to use trade penalties to bend allies and rivals alike to his will, generating investment commitments from some nations and pushback from others such as China, Brazil and India.&lt;/p&gt;
    &lt;p&gt;It was unclear how Trump could impose the tariffs under U.S. law, though he could cite economic emergency powers that are currently subject to a U.S. Supreme Court challenge.&lt;/p&gt;
    &lt;p&gt;Trump said in his Truth Social post that his tariffs were retaliation for recent trips to Greenland by representatives from Britain, the Netherlands and Finland and for general opposition to his efforts to purchase the semiautonomous territory of NATO ally Denmark. He has Greenland is essential for the “Golden Dome” missile defense system for the U.S., and has argued that Russia and China might try to take over the island.&lt;/p&gt;
    &lt;p&gt;Resistance has steadily built in Europe to Trump’s ambitions, even as several countries on the continent agreed to his 15% tariffs last year in order to preserve an economic and security relationship with Washington.&lt;/p&gt;
    &lt;p&gt;Earlier Saturday, hundreds of people in Greenland’s capital braved near-freezing temperatures, rain and icy streets to march in a rally in support of their own self-governance.&lt;/p&gt;
    &lt;p&gt;The Greenlanders waved their red-and-white national flags and listened to traditional songs as they walked through Nuuk’s small downtown. Some carried signs with messages like “We shape our future,” “Greenland is not for sale” and “Greenland is already GREAT.” They were joined by thousands of others in rallies across the Danish kingdom.&lt;/p&gt;
    &lt;p&gt;The rallies occurred hours after a bipartisan U.S. congressional delegation in Copenhagen sought to reassure Denmark and Greenland of their support.&lt;/p&gt;
    &lt;p&gt;U.S. Sen. Chris Coons, D-Del., said the current rhetoric around Greenland was causing concern across the Danish kingdom and that he wanted to de-escalate the situation.&lt;/p&gt;
    &lt;p&gt;“I hope that the people of the Kingdom of Denmark do not abandon their faith in the American people,” he said in Copenhagen, adding that the U.S. has respect for Denmark and NATO “for all we’ve done together.”&lt;/p&gt;
    &lt;head rend="h2"&gt;NATO training exercises&lt;/head&gt;
    &lt;p&gt;Danish Maj. Gen. Søren Andersen, leader of the Joint Arctic Command, told The Associated Press that Denmark doesn’t expect the U.S. military to attack Greenland, or any other NATO ally, and that European troops were recently deployed to Nuuk for Arctic defense training.&lt;/p&gt;
    &lt;p&gt;He said that the goal isn’t to send a message to the Trump administration, even through the White House hasn’t ruled out taking the territory by force.&lt;/p&gt;
    &lt;p&gt;“I will not go into the political part, but I will say that I would never expect a NATO country to attack another NATO country,” he told the AP on Saturday aboard a Danish military vessel docked in Nuuk. “For us, for me, it’s not about signaling. It is actually about training military units, working together with allies.”&lt;/p&gt;
    &lt;p&gt;The Danish military organized a planning meeting Friday in Greenland with NATO allies, including the U.S., to discuss Arctic security on the alliance’s northern flank in the face of a potential Russian threat. The Americans were also invited to participate in Operation Arctic Endurance in Greenland in the coming days, Andersen said.&lt;/p&gt;
    &lt;p&gt;In his 2½ years as a commander in Greenland, Andersen said that he hasn’t seen any Chinese or Russian combat vessels or warships, despite Trump saying that they were off the island’s coast.&lt;/p&gt;
    &lt;p&gt;But in the unlikely event of American troops using force on Danish soil, Andersen confirmed a Cold War-era law governing Danish rules of engagement.&lt;/p&gt;
    &lt;p&gt;“But you are right that it is Danish law that a Danish soldier, if attacked, has the obligation to fight back,” he said.&lt;/p&gt;
    &lt;head rend="h2"&gt;‘Important for the whole world’&lt;/head&gt;
    &lt;p&gt;Thousands of people marched through Copenhagen, many of them carrying Greenland’s flag. Others held signs with slogans like “Make America Smart Again” and “Hands Off.”&lt;/p&gt;
    &lt;p&gt;“This is important for the whole world,” Danish protester Elise Riechie told the AP as she held Danish and Greenlandic flags. “There are many small countries. None of them are for sale.”&lt;/p&gt;
    &lt;p&gt;Trump has sought to justify his calls for a U.S. takeover by repeatedly saying that China and Russia have their own designs on Greenland, which holds vast untapped reserves of critical minerals.&lt;/p&gt;
    &lt;p&gt;“There are no current security threats to Greenland,” Coons said.&lt;/p&gt;
    &lt;p&gt;Trump has insisted for months that the U.S. should control Greenland, and said earlier this week that anything less than the Arctic island being in U.S. hands would be “unacceptable.”&lt;/p&gt;
    &lt;p&gt;During an unrelated event at the White House about rural health care, he recounted Friday how he had threatened European allies with tariffs on pharmaceuticals.&lt;/p&gt;
    &lt;p&gt;“I may do that for Greenland, too,” Trump said.&lt;/p&gt;
    &lt;p&gt;He had not previously mentioned using tariffs to try to force the issue.&lt;/p&gt;
    &lt;p&gt;Earlier this week, the foreign ministers of Denmark and Greenland met in Washington with Trump’s vice president, JD Vance, and secretary of state, Marco Rubio.&lt;/p&gt;
    &lt;p&gt;That encounter didn’t resolve the deep differences, but did produce an agreement to set up a working group — on whose purpose Denmark and the White House then offered sharply diverging public views.&lt;/p&gt;
    &lt;p&gt;European leaders have said that it’s only for Denmark and Greenland to decide on matters concerning the territory, and Denmark said this week that it was increasing its military presence in Greenland in cooperation with allies.&lt;/p&gt;
    &lt;p&gt;“There is almost no better ally to the United States than Denmark,” Coons said. “If we do things that cause Danes to question whether we can be counted on as a NATO ally, why would any other country seek to be our ally or believe in our representations?”&lt;/p&gt;
    &lt;p&gt;___&lt;/p&gt;
    &lt;p&gt;Niemann reported from Copenhagen, Denmark, and Boak from West Palm Beach, Fla. Associated Press writer Stefanie Dazio in Berlin contributed to this report.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://apnews.com/article/denmark-greenland-us-trump-4ad99ea3975a8b62d37bd04961feda55"/><published>2026-01-17T17:03:33+00:00</published></entry></feed>