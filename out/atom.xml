<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-02-01T05:40:56.156759+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46837660</id><title>Browser Agent Benchmark: Comparing LLM models for web automation</title><updated>2026-02-01T05:41:03.696960+00:00</updated><content>&lt;doc fingerprint="6f56cad92c53041f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Browser Agent Benchmark: Comparing LLM Models for Web Automation&lt;/head&gt;
    &lt;p&gt;We compiled our learnings from AI browser agent evaluations into an open-source benchmark for model comparison.&lt;/p&gt;
    &lt;p&gt;At Browser Use I spend a lot of time deciding what model to use. It's not easy to choose between LLMs, agent parameters, or compare two different versions of Browser Use and tell which one is better.&lt;/p&gt;
    &lt;p&gt;To truly understand our agent performance, we built a suite of internal tools for evaluating our agent in a standardized and repeatable way so we can compare versions and models and continuously improve. We take evaluations seriously. As of now, we have over 600,000 tasks run in testing.&lt;/p&gt;
    &lt;p&gt;Today we are releasing our first open source benchmark.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Tasks&lt;/head&gt;
    &lt;p&gt;Existing browser benchmark task sets all have strengths and weaknesses. All tasks fall somewhere in the tradeoff between interpretability and realism.&lt;/p&gt;
    &lt;p&gt;On the interpretable end are tasks with synthetic websites that can deterministically confirm if the agent succeeds. But synthetic sites don't capture the bizarre reality and diversity of how real websites work, so we avoid them.&lt;/p&gt;
    &lt;p&gt;A good middle ground is web tasks that involve researching verifiable information, often involving multiple steps (like BrowseComp and GAIA) and comparing the answer to ground truth.&lt;/p&gt;
    &lt;p&gt;The end of the spectrum that most represents real user tasks involves finding real-time information or following complex workflows on various pages (Mind2Web 2, WebBench). The challenge here is judging them accurately at scale.&lt;/p&gt;
    &lt;p&gt;Tasks left out of evaluations are those that make real changes to websites (like creating a post) or require authentication. There has yet to be an economical solution for running these at scale.&lt;/p&gt;
    &lt;p&gt;Another challenge is difficulty. Many tasks have become trivial to modern browser agents, while others simply are not completable. For our benchmark, we selected 100 of the best tasks from existing open source benchmarks. We chose WebBench, Mind2Web, GAIA, and BrowseComp for a mix of verifiable and real-time tasks. We also added 20 tasks on a custom site to test the hardest browser interactions, such as iframe inception, clicking and dragging, etc.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Source&lt;/cell&gt;
        &lt;cell role="head"&gt;Tasks&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Custom&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;Page interaction challenges&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;WebBench&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;Web browsing tasks&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Mind2Web 2&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;Multi-step web navigation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;GAIA&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;General AI assistant tasks (web-based)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;BrowseComp&lt;/cell&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;Browser comprehension tasks&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We approached the difficulty problem with the following method: we ran all tasks many times with different LLMs, agent settings, and agent frameworks. Each was evaluated by our LLM judge for success, with flags for tasks judged impossible or where the agent was very close.&lt;/p&gt;
    &lt;p&gt;We removed tasks completed most of the time for being too easy, and ones majority voted impossible and never completed for being unreachable. Among the remaining tasks, the most challenging and interesting ones were hand-selected and independently verified to be possible. The resulting set contains only very hard but possible tasks.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Judge&lt;/head&gt;
    &lt;p&gt;Judging task traces is a critical part of any benchmark. When tasks involve real websites and real information, there is no deterministic way to check if the agent succeeded.&lt;/p&gt;
    &lt;p&gt;At the scale and speed needed to base product direction on evaluations, we must use an LLM as the judge. To ensure consistency across models, the same LLM, prompt, and inputs must be used.&lt;/p&gt;
    &lt;p&gt;We have iterated across many judge frameworks over the last year on our internal evaluation platform. The way to evaluate a judge is to run it on task traces that were judged personally and meticulously by our team and compare the results. This tells us how aligned the judge is with our own judgements. We hand labeled 200 task traces and used accuracy on this set as our core metric.&lt;/p&gt;
    &lt;p&gt;Initial results settled on GPT-4o as the most human-aligned judge, as found by the original Mind2Web paper. However, when gemini-2.5-flash released, we found it had better alignment and became our new judge.&lt;/p&gt;
    &lt;p&gt;For prompting, we found that simple trumps complex, and context is king. Many benchmarks use a rubric system, but we found better accuracy demanding a true or false verdict. With rubrics, LLMs tend to highlight a few positives and negatives and give a middling score even in complete success or utter failure.&lt;/p&gt;
    &lt;p&gt;Our final judge achieved 87% alignment with our human judgements, only differing on partial successes or technicalities.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Results&lt;/head&gt;
    &lt;p&gt;Here is a comparison of performance and throughput on this benchmark for the most used models on Browser Use Cloud. We find it concerning that many AI agent benchmarks do not include error bars or variance estimations. We have run each evaluation multiple times and shown standard error bars.&lt;/p&gt;
    &lt;p&gt;The strongest model today is our new ChatBrowserUse 2 API, which is specially optimized for use in our framework.&lt;/p&gt;
    &lt;p&gt;However, all models on this plot are very strong, and even the lowest scoring model (gemini-2.5-flash at 35%) is respectable on these hard tasks. The fact that recent models have surpassed 60% on this benchmark is impressive. We may need to collect even harder tasks for a new benchmark soon.&lt;/p&gt;
    &lt;head rend="h2"&gt;Using the Benchmark&lt;/head&gt;
    &lt;p&gt;This benchmark is open source at github.com/browser-use/benchmark. We want it to be easy to use and modify. Our results for ChatBrowserUse 2 can be replicated by running &lt;code&gt;run_eval.py&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;However, these evaluations are not suitable for an everyday user. A single run through these 100 complex tasks on the basic Browser Use plan with concurrency limited to 3 will take roughly three hours and cost $10. Using more expensive models like claude-sonnet-4-5 will take roughly twice as long and incur costs of nearly $100 in API calls.&lt;/p&gt;
    &lt;p&gt;We hope this benchmark can enable LLM providers to test new models on complex real world agentic browsing tasks and use the results to improve their models. If you would like to inquire about running these evaluations at a larger scale, please contact support@browser-use.com&lt;/p&gt;
    &lt;p&gt;Alexander Yue&lt;/p&gt;
    &lt;p&gt;Evaluations&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://browser-use.com/posts/ai-browser-agent-benchmark"/><published>2026-01-31T15:48:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46837814</id><title>Apple Platform Security (Jan 2026) [pdf]</title><updated>2026-02-01T05:41:03.578237+00:00</updated><content/><link href="https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf"/><published>2026-01-31T16:04:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46838417</id><title>Finland looks to introduce Australia-style ban on social media</title><updated>2026-02-01T05:41:03.267998+00:00</updated><content>&lt;doc fingerprint="3cd6d75008609f9d"&gt;
  &lt;main&gt;
    &lt;p&gt;Lunch break at the Finnish International School of Tampere (FISTA) is a boisterous time.&lt;/p&gt;
    &lt;p&gt;The yard is filled with children â€” ranging from grades 1 to 9, or ages 6 to 16 â€” running around, shouting, playing football, shooting basketball hoops, doing what kids do.&lt;/p&gt;
    &lt;p&gt;And there's not a single screen in sight.&lt;/p&gt;
    &lt;p&gt;FISTA has taken advantage of the law change, brought in last August, which allows schools to restrict or completely ban the use of mobile phones during school hours. At FISTA, this means no phones at all unless specifically used for learning in the classroom.&lt;/p&gt;
    &lt;p&gt;"We've seen that cutting down on the possibilities for students to use their phones, during the breaks for instance, has spurred a lot of creativity," FISTA vice principal Antti Koivisto notes.&lt;/p&gt;
    &lt;p&gt;"They're more active, doing more physical things like playing games outdoors or taking part in the organised break activities or just socialising with each other."&lt;/p&gt;
    &lt;p&gt;With the smartphone restriction in schools widely considered to have been a success, Finland's government has now set its sights on social media platforms.&lt;/p&gt;
    &lt;p&gt;Prime Minister Petteri Orpo (NCP) said earlier this month that he supports banning the use of social media by children under the age of 15.&lt;/p&gt;
    &lt;p&gt;"I am deeply concerned about the lack of physical activity among children and young people, and the fact that it is increasing," Orpo said at the time.&lt;/p&gt;
    &lt;p&gt;And there is a growing groundswell of support for Finland introducing such a ban. Two-thirds of respondents to a survey published earlier this week said they back a ban on social media for under-15s. This is a near 10 percentage point jump compared to a similar survey carried out just last summer.&lt;/p&gt;
    &lt;head rend="h2"&gt;"Uncontrolled human experiment"&lt;/head&gt;
    &lt;p&gt;The concerns over social media, and in particular the effects on children, have been well-documented â€” but Finnish researcher Silja Kosola's recent description of the phenomenon as an "uncontrolled human experiment" has grabbed people's attention once again.&lt;/p&gt;
    &lt;p&gt;Kosola, an associate professor in adolescent medicine, has researched the impact of social media on young people, and tells Yle News that the consequences are not very well understood.&lt;/p&gt;
    &lt;p&gt;"We see a rise in self-harm and especially eating disorders. We see a big separation in the values of young girls and boys, which is also a big problem in society," Kosola explains.&lt;/p&gt;
    &lt;p&gt;In the video below, Silja Kosola explains the detrimental effects that excessive use of social media can have on young people.&lt;/p&gt;
    &lt;p&gt;She further notes that certain aspects of Finnish culture â€” such as the independence and freedom granted to children from a young age â€” have unwittingly exacerbated the ill effects of social media use.&lt;/p&gt;
    &lt;p&gt;"We have given smartphones to younger people more than anywhere else in the world. Just a couple of years ago, about 95 percent of first graders had their own smartphone, and that hasn't happened anywhere else," she says.&lt;/p&gt;
    &lt;head rend="h2"&gt;All eyes on Australia&lt;/head&gt;
    &lt;p&gt;Since 10 December last year, children under the age of 16 in Australia have been banned from using social media platforms such as TikTok, Snapchat, Facebook, Instagram and YouTube.&lt;/p&gt;
    &lt;p&gt;Prime Minister Anthony Albanese began drafting the legislation after he received a heartfelt letter from a grieving mother who lost her 12-year-old daughter to suicide.&lt;/p&gt;
    &lt;p&gt;Although Albanese has never revealed the details of the letter, he told public broadcaster ABC that it was "obvious social media had played a key role" in the young girl's death.&lt;/p&gt;
    &lt;p&gt;The legislation aims to shift the burden away from parents and children and onto the social media companies, who face fines of up to 49.5 million Australian dollars (29 million euros) if they consistently fail to keep kids off their platforms.&lt;/p&gt;
    &lt;p&gt;Clare Armstrong, ABC's chief digital political correspondent, told Yle News that the initial reaction to the roll-out has been some confusion but no little "relief".&lt;/p&gt;
    &lt;p&gt;"The government often talks about this law as being a tool to help parents and other institutions enforce and start conversations about tech and social media in ways that before, they couldn't," she says.&lt;/p&gt;
    &lt;p&gt;Although it is still early days, as the ban has only been in force for about six weeks, Armstrong adds that the early indicators have been good.&lt;/p&gt;
    &lt;p&gt;ABC journalist Clare Armstrong explains in the video below how children in Australia have been spending their time since the social media ban was introduced.&lt;/p&gt;
    &lt;p&gt;However, she adds a note of caution to any countries â€” such as Finland â€” looking to emulate the Australian model, noting that communication is key.&lt;/p&gt;
    &lt;p&gt;"Because you can write a very good law, but if the public doesn't understand it, and if it can't be enforced at that household level easily, then it's bound to fail," Armstrong says.&lt;/p&gt;
    &lt;head rend="h2"&gt;Playing to Finland's strengths&lt;/head&gt;
    &lt;p&gt;Seona Candy, an Australian living in Helsinki for over eight years, has been keenly following the events in her homeland since the social media ban came into effect in December.&lt;/p&gt;
    &lt;p&gt;She has heard anecdotally that if kids find themselves blocked from one platform, they just set up an account on another, "ones that maybe their parents don't even know exist".&lt;/p&gt;
    &lt;p&gt;"And this is then much, much harder, because those platforms don't have parental controls, so they don't have those things already designed into them that the more mainstream platforms do," Candy says.&lt;/p&gt;
    &lt;p&gt;Because of this issue, and others she has heard about, she warns against Finland introducing like-for-like legislation based around Australia's "reactive, knee-jerk" law change.&lt;/p&gt;
    &lt;p&gt;"I think the Finnish government should really invest in digital education, and digital literacy, and teach kids about digital safety. Finland is world-famous for education, and for media literacy. Play to your strengths, right?"&lt;/p&gt;
    &lt;p&gt;The All Points North podcast asked if Finland should introduce a similar ban on social media as in Australia. You can listen to the episode via this embedded player, on Yle Areena, via Apple, Spotify or wherever you get your podcasts.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://yle.fi/a/74-20207494"/><published>2026-01-31T17:06:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46838597</id><title>Mobile carriers can get your GPS location</title><updated>2026-02-01T05:41:02.688398+00:00</updated><content>&lt;doc fingerprint="ae2c9b9741e393f0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Mobile carriers can get your GPS location&lt;/head&gt;
    &lt;p&gt;In iOS 26.3, Apple introduced a new privacy feature which limits â€œprecise locationâ€ data made available to cellular networks via cell towers. The feature is only available to devices with Appleâ€™s in-house modem introduced in 2025. The announcement1 says&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Cellular networks can determine your location based on which cell towers your device connects to.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is well-known. I have served on a jury where the prosecution obtained location data from cell towers. Since cell towers are sparse (especially before 5G), the accuracy is in the range of tens to hundreds of metres2.&lt;/p&gt;
    &lt;p&gt;But this is not the whole truth, because cellular standards have built-in protocols that make your device silently send GNSS (i.e. GPS, GLONASS, Galileo, BeiDou) location to the carrier. This would have the same precision as what you see in your Map apps, in single-digit metres.&lt;/p&gt;
    &lt;p&gt;In 2G and 3G this is called Radio Resources LCS Protocol (RRLP)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;So the network simply asks â€œtell me your GPS coordinates if you know themâ€ and the phone will respond3.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In 4G and 5G this is called LTE Positioning Protocol (LPP)&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;RRLP, RRC, and LPP are natively control-plane positioning protocols. This means that they are transported in the inner workings of cellular networks and are practically invisible to end users4.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Itâ€™s worth noting that GNSS location is never meant to leave your device. GNSS coordinates are calculated entirely passively, your device doesnâ€™t need to send a single bit of information. Using GNSS is like finding out where you are by reading a road sign: you donâ€™t have to tell anyone else you read a road sign, anyone can read a road sign, and the people who put up road signs donâ€™t know who read which road sign when.&lt;/p&gt;
    &lt;p&gt;These capabilities are not secrets but somehow they have mostly slid under the radar of the public consciousness. They have been used in the wild for a long time, such as by the DEA in the US in 200656:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[T]he DEA agents procured a court order (but not a search warrant) to obtain GPS coordinates from the courierâ€™s phone via a ping, or signal requesting those coordinates, sent by the phone company to the phone.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And by Shin Bet in Israel, which tracks everyone everywhere all the time7:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The GSS Tool was based on centralized cellular tracking operated by Israelâ€™s General Security Services (GSS). The technology was based on a framework that tracks all the cellular phones running in Israel through the cellular companiesâ€™ data centers. According to news sources, it routinely collects information from cellular companies and identifies the location of all phones through cellular antenna triangulation and GPS data7.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Notably, the Israeli government started using the data for contact tracing in March 202078, only a few weeks after the first Israeli COVID-19 case. An individual would be sent an SMS message informing them of close contact with a COVID patient and required to quarantine. This is good evidence that the location data Israeli carriers are collecting are far more precise than what cell towers alone can achieve.&lt;/p&gt;
    &lt;p&gt;A major caveat is that I donâ€™t know if RRLP and LPP are the exact techniques, and the only techniques, used by DEA, Shin Bet, and possibly others to collect GNSS data; there could be other protocols or backdoors weâ€™re not privy to.&lt;/p&gt;
    &lt;p&gt;Another unknown is whether these protocols can be exploited remotely by a foreign carrier. Saudi Arabia has abused SS7 to spy on people in the US9, but as far as I know this only locates a device to the coverage area of a Mobile Switching Center, which is less precise than cell tower data. Nonetheless, given the abysmal culture, competency, and integrity in the telecom industry, I would not be shocked if itâ€™s possible for a state actor to obtain the precise GNSS coordinates of anyone on earth using a phone number/IMEI.&lt;/p&gt;
    &lt;p&gt;Apple made a good step in iOS 26.3 to limit at least one vector of mass surveillance, enabled by having full control of the modem silicon and firmware. They must now allow users to disable GNSS location responses to mobile carriers, and notify the user when such attempts are made to their device.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;https://transition.fcc.gov/pshs/911/Apps Wrkshp 2015/911_Help_SMS_WhitePaper0515.pdf â†©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://laforge.gnumonks.org/blog/20101217-learning_about_gps/ â†©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Comment on United States v. Skinner, 690 F.3d 772 (6th Cir. 2012) https://harvardlawreview.org/print/vol-126/sixth-circuit-holds-that-pinging-a-targets-cell-phone-to-obtain-gps-data-is-not-a-search-subject-to-warrant-requirement-ae-united-states-v-skinner-690-f-3d-772-6th-cir-2012-rehae/ â†©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://www.cato.org/blog/skinning-fourth-amendment-sixth-circuits-awful-gps-tracking-decision â†©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://www.ericsson.com/en/blog/2020/12/5g-positioning--what-you-need-to-know â†©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Eran Toch and Oshrat Ayalon. 2023. How Mass surveillance Crowds Out Installations of COVID-19 Contact Tracing Applications. https://doi.org/10.1145/3579491 â†© â†©2 â†©3&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://www.nytimes.com/2020/03/16/world/middleeast/israel-coronavirus-cellphone-tracking.html â†©&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;https://www.theguardian.com/world/2020/mar/29/revealed-saudis-suspected-of-phone-spying-campaign-in-us â†©&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://an.dywa.ng/carrier-gnss.html"/><published>2026-01-31T17:21:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46839215</id><title>Nintendo DS code editor and scriptable game engine</title><updated>2026-02-01T05:41:02.414050+00:00</updated><content>&lt;doc fingerprint="ae9ef93a050ef3bf"&gt;
  &lt;main&gt;&lt;p&gt;2026&lt;/p&gt;&lt;p&gt;TL;DR&lt;/p&gt;&lt;p&gt;I built a scriptable 3D game engine for the Nintendo DS so you can write and run games directly on the console itself. Written in C using libnds, it compiles to a ~100KB .nds ROM that runs at 60 FPS. Features a touch-based code editor on the bottom screen and real-time 3D rendering on the top screen. Ships with a working 3D pong game as the default script.&lt;/p&gt;&lt;p&gt;I felt nostalgic for when I made my first games on an old TI-82 graphing calculator. So I tried bringing that whole experience to my Nintendo DS. A complete programming environment you can hold in your hands.&lt;/p&gt;&lt;p&gt;What you see is a scriptable game engine with a custom programming language featuring variables, loops, and conditionals. You write code using the bottom touchscreen, click play, and the game will execute in real-time on the top screen with full 3D rendering.&lt;/p&gt;&lt;p&gt;At a high level, the engine breaks down into three parts:&lt;/p&gt;&lt;p&gt;Uses the DS's 3D hardware to render colored cubes at 60 FPS. Each model has position (X, Y, Z), rotation angle, and color. The camera is fully controllable with position and yaw/pitch angles.&lt;/p&gt;&lt;quote&gt;// DS 3D rendering code (C + libnds) glMatrixMode(GL_MODELVIEW); glLoadIdentity(); gluLookAt(camX, camY, camZ, // camera position camX + lookX, camY + lookY, camZ + lookZ, // look target 0, 1, 0); // up vector&lt;/quote&gt;&lt;p&gt;Each model is drawn with a transform (position + Y-axis rotation), then the cube geometry: one color, six quads (24 vertices).&lt;/p&gt;&lt;quote&gt;// Per-model draw calls (from main.c) for (i = 0; i &amp;lt; MAX_MODELS; i++) { if (!modelActive[i]) continue; glPushMatrix(); glTranslatef(modelX[i], modelY[i], modelZ[i]); glRotatef(modelAngle[i], 0, 1, 0); drawCube(CUBE_COLORS[modelColorIndex[i]]); drawWireframeCube(); glPopMatrix(1); } // Cube geometry: RGB15 color -&amp;gt; glColor3b, then 6 faces as GL_QUADS glColor3b(r * 255/31, g * 255/31, b * 255/31); glBegin(GL_QUADS); /* +Z face */ glVertex3f(-1.0f, 1.0f, 1.0f); glVertex3f( 1.0f, 1.0f, 1.0f); glVertex3f( 1.0f, -1.0f, 1.0f); glVertex3f(-1.0f, -1.0f, 1.0f); /* -Z, +Y, -Y, +X, -X ... (24 vertices total) */ glEnd();&lt;/quote&gt;&lt;p&gt;A touch-based code editor with a custom UI drawn pixel-by-pixel to a 256x192 bitmap. Features include:&lt;/p&gt;&lt;quote&gt;// Software rendering to bottom screen u16 *subBuffer = (u16*)BG_BMP_RAM_SUB(0); // 256x192 framebuffer subBuffer[y * 256 + x] = RGB15(31, 31, 31); // white pixel&lt;/quote&gt;&lt;p&gt;Executes one line of script per frame (~60 lines/sec). Scripts can use 26 variables (A-Z) plus 9 read-only registers for input (D-pad, buttons) and system state (elapsed time, camera direction).&lt;/p&gt;&lt;quote&gt;// Script execution (simplified) if (tokenEquals(script[scriptIP], "add")) { int r = scriptReg[scriptIP]; // which register (A-Z) registers[r] += getNumberParamValue(scriptIP, 0); scriptIP++; // next line }&lt;/quote&gt;&lt;p&gt;Scripts are built from tokens (commands) with numeric parameters. Each line executes instantly, with no parsing overhead, just a series of if-checks against token names.&lt;/p&gt;&lt;p&gt;Variables &amp;amp; Math&lt;/p&gt;&lt;code&gt;SET A 5&lt;/code&gt; â€” set register A to 5&lt;code&gt;ADD A 1&lt;/code&gt; â€” add 1 to A&lt;code&gt;SUBTRACT A 2&lt;/code&gt; â€” subtract 2 from A&lt;code&gt;MULTIPLY B -1&lt;/code&gt; â€” multiply B by -1&lt;p&gt;Control Flow&lt;/p&gt;&lt;code&gt;LOOP&lt;/code&gt; / &lt;code&gt;END_LOOP&lt;/code&gt; â€” infinite loop&lt;code&gt;IF_GT A 10&lt;/code&gt; â€” if A &amp;gt; 10&lt;code&gt;IF_LT A 0&lt;/code&gt; â€” if A &amp;lt; 0&lt;code&gt;IF_TRUE kA&lt;/code&gt; â€” if A button pressed&lt;code&gt;END_IF&lt;/code&gt; â€” close conditional&lt;p&gt;3D Objects&lt;/p&gt;&lt;code&gt;MODEL 0&lt;/code&gt; â€” create model at index 0&lt;code&gt;POSITION 0 X Y Z&lt;/code&gt; â€” set position&lt;code&gt;ANGLE 0 45&lt;/code&gt; â€” set rotation angle&lt;code&gt;NEXT_COLOR 0&lt;/code&gt; â€” cycle color&lt;p&gt;Camera &amp;amp; Rendering&lt;/p&gt;&lt;code&gt;CAM_POS X Y Z&lt;/code&gt; â€” set camera position&lt;code&gt;CAM_ANGLE yaw pitch&lt;/code&gt; â€” set look direction&lt;code&gt;BACKGROUND 2&lt;/code&gt; â€” set bg color (0-3)&lt;code&gt;BEEP&lt;/code&gt; â€” play 0.1s sound&lt;code&gt;SLEEP 0.016&lt;/code&gt; â€” pause (60 FPS = 0.016s/frame)&lt;code&gt;LEFT, UP, RGT, DN&lt;/code&gt;: D-pad (1.0 when held, 0.0 when released)
&lt;code&gt;KA, KB&lt;/code&gt;: A and B buttons&lt;code&gt;TIME&lt;/code&gt;: elapsed seconds since script started&lt;code&gt;LOOKX, LOOKZ&lt;/code&gt;: camera forward direction (normalized X and Z)
&lt;p&gt;The engine ships with a playable pong game. Here's a simplified excerpt:&lt;/p&gt;&lt;quote&gt;MODEL 0 ; create ball MODEL 1 ; create paddle CAM_POS 0 8 18 ; position camera SET A 0 ; ball X position SET B 1 ; ball velocity SET C 0 ; paddle Z position LOOP ADD A B ; move ball IF_GT A 10 ; hit right wall? MULTIPLY B -1 ; reverse velocity END_IF IF_TRUE Up ; up button pressed? ADD C -0.5 ; move paddle up END_IF POSITION 0 A 0 0 ; update ball position POSITION 1 -13 0 C ; update paddle position SLEEP 0.016 ; ~60 FPS END_LOOP&lt;/quote&gt;&lt;p&gt;The full script includes collision detection, game-over logic, and beep sounds on miss, all done with simple register math and conditionals.&lt;/p&gt;&lt;code&gt;make&lt;/code&gt; in the project directory
&lt;code&gt;program.nds&lt;/code&gt; (~100 KB ROM file)
&lt;p&gt;You need a flashcart (e.g. R4, DSTT, Acekard) with a microSD card:&lt;/p&gt;&lt;code&gt;program.nds&lt;/code&gt; to the microSD card
&lt;p&gt;Note: I got my R4 cart + SD card from a friend years ago, so I don't have detailed setup instructions for the cart itself. Most modern flashcarts just need you to copy their firmware to the SD root, then add ROMs in a folder.&lt;/p&gt;&lt;p&gt; You can test the DS game engine build directly below. The emulator loads &lt;code&gt;ds-game-engine.nds&lt;/code&gt;. Loads a more basic pong game than the one in the video.
&lt;/p&gt;&lt;p&gt;Nintendo DS emulator (Desmond). If the game doesnâ€™t start, ensure JavaScript is enabled and the page has finished loading.&lt;/p&gt;&lt;p&gt;Compiled ROM (ds-game-engine.nds)&lt;/p&gt;&lt;p&gt;Feel free to ask or discuss in this Reddit thread&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://crl.io/ds-game-engine/"/><published>2026-01-31T18:27:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840178</id><title>Show HN: Minimal â€“ Open-Source Community driven Hardened Container Images</title><updated>2026-02-01T05:41:01.939922+00:00</updated><content>&lt;doc fingerprint="84dbd39055d7784"&gt;
  &lt;main&gt;
    &lt;p&gt;A collection of production-ready container images with minimal CVEs, rebuilt daily using Chainguard's apko and Wolfi packages. By including only required packages, these images maintain a reduced attack surface and typically have zero or near-zero known vulnerabilities.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Image&lt;/cell&gt;
        &lt;cell role="head"&gt;Pull Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Shell&lt;/cell&gt;
        &lt;cell role="head"&gt;Use Case&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-python:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Python apps, microservices&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Node.js&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-node:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Node.js apps, JavaScript&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Bun&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-bun:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Fast JavaScript/TypeScript runtime&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-go:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Go development, CGO builds&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Nginx&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-nginx:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Reverse proxy, static files&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;HTTPD&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-httpd:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Maybe*&lt;/cell&gt;
        &lt;cell&gt;Apache web server&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Jenkins&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-jenkins:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;CI/CD automation&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Redis-slim&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-redis-slim:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;In-memory data store&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;PostgreSQL-slim&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;docker pull ghcr.io/rtvkiz/minimal-postgres-slim:latest&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Relational database&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;*HTTPD, Jenkins,Node.js may include shell(sh,busybox) via transitive Wolfi dependencies. CI treats shell presence as informational.&lt;/p&gt;
    &lt;p&gt;Container vulnerabilities are a top attack vector. Most base images ship with dozens of known CVEs that take weeks or months to patch:&lt;/p&gt;
    &lt;code&gt;Traditional images:     Your containers:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ debian:latest    â”‚    â”‚ minimal-python   â”‚
â”‚ 127 CVEs         â”‚    â”‚ 0-5 CVEs         â”‚
â”‚ Patched: ~30 daysâ”‚    â”‚ Patched: &amp;lt;48 hrs â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;p&gt;Impact:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Pass security audits and compliance requirements (SOC2, FedRAMP, PCI-DSS)&lt;/item&gt;
      &lt;item&gt;Reduce attack surface with minimal, distroless images&lt;/item&gt;
      &lt;item&gt;Get CVE patches within 24-48 hours of disclosure (vs weeks for Debian/Ubuntu)&lt;/item&gt;
      &lt;item&gt;Cryptographically signed images with full SBOM for supply chain security&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Python - run your app
docker run --rm -v $(pwd):/app ghcr.io/rtvkiz/minimal-python:latest /app/main.py

# Node.js - run your app
docker run --rm -v $(pwd):/app -w /app ghcr.io/rtvkiz/minimal-node:latest index.js

# Bun - fast JavaScript runtime
docker run --rm ghcr.io/rtvkiz/minimal-bun:latest --version

# Go - build your app
docker run --rm -v $(pwd):/app -w /app ghcr.io/rtvkiz/minimal-go:latest build -o /tmp/app .

# Nginx - reverse proxy
docker run -d -p 8080:80 ghcr.io/rtvkiz/minimal-nginx:latest

# HTTPD - serve static content
docker run -d -p 8080:80 ghcr.io/rtvkiz/minimal-httpd:latest

# Jenkins - CI/CD controller
docker run -d -p 8080:8080 -v jenkins_home:/var/jenkins_home ghcr.io/rtvkiz/minimal-jenkins:latest

# Redis - in-memory data store
docker run -d -p 6379:6379 ghcr.io/rtvkiz/minimal-redis-slim:latest

# PostgreSQL - relational database
docker run -d -p 5432:5432 -v pgdata:/var/lib/postgresql/data ghcr.io/rtvkiz/minimal-postgres-slim:latest&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Image&lt;/cell&gt;
        &lt;cell role="head"&gt;Version&lt;/cell&gt;
        &lt;cell role="head"&gt;User&lt;/cell&gt;
        &lt;cell role="head"&gt;Entrypoint&lt;/cell&gt;
        &lt;cell role="head"&gt;Workdir&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;3.13.x&lt;/cell&gt;
        &lt;cell&gt;nonroot (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/bin/python3&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/app&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Node.js&lt;/cell&gt;
        &lt;cell&gt;22.x LTS&lt;/cell&gt;
        &lt;cell&gt;nonroot (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/bin/dumb-init -- /usr/bin/node&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/app&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Bun&lt;/cell&gt;
        &lt;cell&gt;latest&lt;/cell&gt;
        &lt;cell&gt;nonroot (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/bin/bun&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/app&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
        &lt;cell&gt;1.25.x&lt;/cell&gt;
        &lt;cell&gt;nonroot (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/bin/go&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/app&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Nginx&lt;/cell&gt;
        &lt;cell&gt;mainline&lt;/cell&gt;
        &lt;cell&gt;nginx (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/sbin/nginx -g "daemon off;"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HTTPD&lt;/cell&gt;
        &lt;cell&gt;2.4.x&lt;/cell&gt;
        &lt;cell&gt;www-data (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/sbin/httpd -DFOREGROUND&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/var/www/localhost/htdocs&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Jenkins&lt;/cell&gt;
        &lt;cell&gt;2.541.x LTS&lt;/cell&gt;
        &lt;cell&gt;jenkins (1000)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;tini -- java -jar jenkins.war&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/var/jenkins_home&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Redis&lt;/cell&gt;
        &lt;cell&gt;8.4.x&lt;/cell&gt;
        &lt;cell&gt;redis (65532)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/bin/redis-server&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;PostgreSQL&lt;/cell&gt;
        &lt;cell&gt;18.x&lt;/cell&gt;
        &lt;cell&gt;postgres (70)&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/usr/bin/postgres&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;/&lt;/code&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BUILD PIPELINE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Package Source            Image Assembly           Verification    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Wolfi     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    apko    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   Trivy    â”‚   â”‚
â”‚  â”‚ (pre-built) â”‚  install â”‚ (OCI image)â”‚  scan    â”‚ (CVE gate) â”‚   â”‚
â”‚  â”‚ Python, Go, â”‚          â”‚            â”‚          â”‚            â”‚   â”‚
â”‚  â”‚ Node, etc.  â”‚          â”‚            â”‚          â”‚            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â”‚                       â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                       â–¼          â”‚
â”‚  â”‚   melange   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ (Jenkins,   â”‚  build from                   â”‚ cosign + SBOM  â”‚  â”‚
â”‚  â”‚  Redis)     â”‚  source                       â”‚ (sign &amp;amp; publishâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Trigger&lt;/cell&gt;
        &lt;cell role="head"&gt;When&lt;/cell&gt;
        &lt;cell role="head"&gt;Purpose&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Scheduled&lt;/cell&gt;
        &lt;cell&gt;Daily at 2:00 AM UTC&lt;/cell&gt;
        &lt;cell&gt;Pick up latest CVE patches from Wolfi&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Push&lt;/cell&gt;
        &lt;cell&gt;On merge to &lt;code&gt;main&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Deploy configuration changes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Manual&lt;/cell&gt;
        &lt;cell&gt;Workflow dispatch&lt;/cell&gt;
        &lt;cell&gt;Emergency rebuilds&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;All builds must pass a CVE gate (no CRITICAL/HIGH severity vulnerabilities) before publishing.&lt;/p&gt;
    &lt;code&gt;# Prerequisites
go install chainguard.dev/apko@latest
go install chainguard.dev/melange@latest  # needed for Jenkins, Redis
brew install trivy  # or: apt install trivy

# Build all images
make build

# Build specific image
make python
make node
make bun
make go
make nginx
make httpd
make jenkins
make redis-slim
make postgres-slim

# Scan for CVEs
make scan

# Run tests
make test&lt;/code&gt;
    &lt;code&gt;minimal/
â”œâ”€â”€ python/apko/python.yaml       # Python image (Wolfi pkg)
â”œâ”€â”€ node/apko/node.yaml           # Node.js image (Wolfi pkg)
â”œâ”€â”€ bun/apko/bun.yaml             # Bun image (Wolfi pkg)
â”œâ”€â”€ go/apko/go.yaml               # Go image (Wolfi pkg)
â”œâ”€â”€ nginx/apko/nginx.yaml         # Nginx image (Wolfi pkg)
â”œâ”€â”€ httpd/apko/httpd.yaml         # HTTPD image (Wolfi pkg)
â”œâ”€â”€ jenkins/
â”‚   â”œâ”€â”€ apko/jenkins.yaml         # Jenkins image
â”‚   â””â”€â”€ melange.yaml              # jlink JRE build
â”œâ”€â”€ redis-slim/
â”‚   â”œâ”€â”€ apko/redis.yaml           # Redis image
â”‚   â””â”€â”€ melange.yaml              # Redis source build
â”œâ”€â”€ postgres-slim/apko/postgres.yaml  # PostgreSQL image (Wolfi pkg)
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ build.yml                 # Daily CI pipeline
â”‚   â”œâ”€â”€ update-jenkins.yml        # Jenkins version updates
â”‚   â”œâ”€â”€ update-redis.yml          # Redis version updates
â”‚   â””â”€â”€ update-wolfi-packages.yml # Wolfi package updates
â”œâ”€â”€ Makefile
â””â”€â”€ LICENSE
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CVE gate - Builds fail if any CRITICAL/HIGH vulnerabilities detected&lt;/item&gt;
      &lt;item&gt;Signed images - All images signed with cosign keyless signing&lt;/item&gt;
      &lt;item&gt;SBOM generation - Full software bill of materials in SPDX format&lt;/item&gt;
      &lt;item&gt;Non-root users - All images run as non-root by default&lt;/item&gt;
      &lt;item&gt;Minimal attack surface - Only essential packages included&lt;/item&gt;
      &lt;item&gt;Shell-less images - Most images have no shell&lt;/item&gt;
      &lt;item&gt;Reproducible builds - Declarative apko configurations&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;All images are signed with cosign keyless signing via Sigstore. To verify:&lt;/p&gt;
    &lt;code&gt;cosign verify \
  --certificate-oidc-issuer https://token.actions.githubusercontent.com \
  --certificate-identity-regexp https://github.com/rtvkiz/minimal/ \
  ghcr.io/rtvkiz/minimal-python:latest&lt;/code&gt;
    &lt;p&gt;Replace &lt;code&gt;minimal-python&lt;/code&gt; with any image name. A successful output confirms the image was built by this repository's CI pipeline and hasn't been tampered with.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;
    &lt;p&gt;Container images include packages from Wolfi and other sources, each with their own licenses (Apache-2.0, MIT, GPL, LGPL, BSD, etc.). Full license information is included in each image's SBOM:&lt;/p&gt;
    &lt;code&gt;# View package licenses in an image
cosign download sbom ghcr.io/rtvkiz/minimal-python:latest | jq '.packages[].licenseConcluded'&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/rtvkiz/minimal"/><published>2026-01-31T19:58:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840179</id><title>Noctia: A sleek and minimal desktop shell thoughtfully crafted for Wayland</title><updated>2026-02-01T05:41:01.416111+00:00</updated><content>&lt;doc fingerprint="bdcf124979ffd2ed"&gt;
  &lt;main&gt;
    &lt;p&gt;quiet by design&lt;/p&gt;
    &lt;p&gt;A beautiful, minimal desktop shell for Wayland that actually gets out of your way. Built on Quickshell with a warm lavender aesthetic that you can easily customize to match your vibe.&lt;/p&gt;
    &lt;p&gt;âœ¨ Key Features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ğŸªŸ Native support for Niri, Hyprland, Sway, MangoWC and labwc&lt;/item&gt;
      &lt;item&gt;âš¡ Built on Quickshell for performance&lt;/item&gt;
      &lt;item&gt;ğŸ¯ Minimalist design philosophy&lt;/item&gt;
      &lt;item&gt;ğŸ”Œ Plugin support (explore plugins)&lt;/item&gt;
      &lt;item&gt;ğŸ”§ Easily customizable to match your style&lt;/item&gt;
      &lt;item&gt;ğŸ¨ Many color schemes available&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="px-3 py-2"&gt;noctalia-v3-showcase.mp4&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Wayland compositor (Niri, Hyprland, Sway, MangoWC or labwc recommended)&lt;/item&gt;
      &lt;item&gt;Quickshell&lt;/item&gt;
      &lt;item&gt;Additional dependencies are listed in our documentation&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;New to Noctalia?&lt;lb/&gt; Check out our comprehensive documentation and installation guide to get up and running!&lt;/p&gt;
    &lt;p&gt;Noctalia provides native support for Niri, Hyprland and Sway. Other Wayland compositors will work but may require additional workspace logic configuration.&lt;/p&gt;
    &lt;p&gt;We welcome contributions of any size - bug fixes, new features, documentation improvements, or custom themes and configs.&lt;/p&gt;
    &lt;p&gt;Get involved:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Found a bug? Open an issue&lt;/item&gt;
      &lt;item&gt;Want to code? Check out our development guidelines&lt;/item&gt;
      &lt;item&gt;Need help? Join our Discord&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Nix users can use the flake's devShell to access a development environment. Run &lt;code&gt;nix develop&lt;/code&gt; in the repo root to enter the dev shell. It includes packages, utilities and environment variables needed to develop Noctalia.&lt;/p&gt;
    &lt;p&gt;A heartfelt thank you to our incredible community of contributors. We are immensely grateful for your dedicated participation and the constructive feedback you've provided, which continue to shape and improve our project for everyone.&lt;/p&gt;
    &lt;p&gt;While all donations are greatly appreciated, they are completely voluntary.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gohma&lt;/item&gt;
      &lt;item&gt;DiscoCevapi&lt;/item&gt;
      &lt;item&gt;PikaOS&lt;/item&gt;
      &lt;item&gt;LionHeartP&lt;/item&gt;
      &lt;item&gt;Nyxion ãƒ„&lt;/item&gt;
      &lt;item&gt;RockDuck&lt;/item&gt;
      &lt;item&gt;Eynix&lt;/item&gt;
      &lt;item&gt;MrDowntempo&lt;/item&gt;
      &lt;item&gt;Tempus Thales&lt;/item&gt;
      &lt;item&gt;Raine&lt;/item&gt;
      &lt;item&gt;JustCurtis&lt;/item&gt;
      &lt;item&gt;llego&lt;/item&gt;
      &lt;item&gt;Grune&lt;/item&gt;
      &lt;item&gt;Maitreya (Max)&lt;/item&gt;
      &lt;item&gt;sheast&lt;/item&gt;
      &lt;item&gt;Radu&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;MIT License - see LICENSE for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/noctalia-dev/noctalia-shell"/><published>2026-01-31T19:58:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840219</id><title>The Saddest Moment (2013) [pdf]</title><updated>2026-02-01T05:41:00.685661+00:00</updated><content/><link href="https://www.usenix.org/system/files/login-logout_1305_mickens.pdf"/><published>2026-01-31T20:02:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840252</id><title>Demystifying ARM SME to Optimize General Matrix Multiplications</title><updated>2026-02-01T05:41:00.372121+00:00</updated><content>&lt;doc fingerprint="a49c340ad1b790ae"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Distributed, Parallel, and Cluster Computing&lt;/head&gt;&lt;p&gt; [Submitted on 25 Dec 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Demystifying ARM SME to Optimize General Matrix Multiplications&lt;/head&gt;View PDF HTML (experimental)&lt;quote&gt;Abstract:General Matrix Multiplication (GEMM) is a critical kernel in high-performance computing and deep learning. While modern architectures like ARM's Scalable Matrix Extension (SME) introduce dedicated hardware for matrix operations, existing linear algebra libraries fail to fully exploit its potential, particularly for large matrices. This paper presents MpGEMM, an open-source library that leverages key architectural features of SME to optimize GEMM across multiple precisions. Through a systematic characterization of SME, we derive optimization guidelines that inform our design. MpGEMM employs cache-aware partitioning, efficient data packing with on-the-fly transposition, and specialized micro-kernels that utilize multi-vector loads and all available tile registers. Evaluated on an Apple M4 Pro with real-world workloads from DeepSeek and LLaMA, MpGEMM achieves an average speedup of 1.23x over the vendor-optimized Apple Accelerate library and significantly outperforms other open-source alternatives.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2512.21473"/><published>2026-01-31T20:05:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840612</id><title>In praise of â€“dry-run</title><updated>2026-02-01T05:41:00.215350+00:00</updated><content>&lt;doc fingerprint="f398e1326871fbc"&gt;
  &lt;main&gt;
    &lt;p&gt;For the last few months, I have been developing a new reporting application. Early on, I decided to add a â€“dry-run option to the run command. This turned out to be quite useful â€“ I have used it many times a day while developing and testing the application.&lt;/p&gt;
    &lt;head rend="h2"&gt;Background&lt;/head&gt;
    &lt;p&gt;The application will generate a set of reports every weekday. It has a loop that checks periodically if it is time to generate new reports. If so, it will read data from a database, apply some logic to create the reports, zip the reports, upload them to an sftp server, check for error responses on the sftp server, parse the error responses, and send out notification mails. The files (the generated reports, and the downloaded feedback files) are moved to different directories depending on the step in the process. A simple and straightforward application.&lt;/p&gt;
    &lt;p&gt;Early in the development process, when testing the incomplete application, I remembered that Subversion (the version control system after CVS, before Git) had a â€“dry-run option. Other linux commands have this option too. If a command is run with the argument â€“dry-run, the output will print what will happen when the command is run, but no changes will be made. This lets the user see what will happen if the command is run without the â€“dry-run argument.&lt;/p&gt;
    &lt;p&gt;I remembered how helpful that was, so I decided to add it to my command as well. When I run the command with â€“dry-run, it prints out the steps that will be taken in each phase: which reports that will be generated (and which will not be), which files will be zipped and moved, which files will be uploaded to the sftp server, and which files will be downloaded from it (it logs on and lists the files).&lt;/p&gt;
    &lt;p&gt;Looking back at the project, I realized that I ended up using the â€“dry-run option pretty much every day.&lt;/p&gt;
    &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
    &lt;p&gt;I am surprised how useful I found it to be. I often used it as a check before getting started. Since I know â€“dry-run will not change anything, it is safe to run without thinking. I can immediately see that everything is accessible, that the configuration is correct, and that the state is as expected. It is a quick and easy sanity check.&lt;/p&gt;
    &lt;p&gt;I also used it quite a bit when testing the complete system. For example, if I changed a date in the report state file (the date for the last successful report of a given type), I could immediately see from the output whether it would now be generated or not. Without â€“dry-run, the actual report would also be generated, which takes some time. So I can test the behavior, and receive very quick feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Downside&lt;/head&gt;
    &lt;p&gt;The downside is that the dryRun-flag pollutes the code a bit. In all the major phases, I need to check if the flag is set, and only print the action that will be taken, but not actually doing it. However, this doesnâ€™t go very deep. For example, none of the code that actually generates the report needs to check it. I only need to check if that code should be invoked in the first place.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;The type of application I have been writing is ideal for â€“dry-run. It is invoked by a command, and it may create some changes, for example generating new reports. More reactive applications (that wait for messages before acting) donâ€™t seem to be a good fit.&lt;/p&gt;
    &lt;p&gt;I added â€“dry-run on a whim early on in the project. I was surprised at how useful I found it to be. Adding it early was also good, since I got the benefit of it while developing more functionality.&lt;/p&gt;
    &lt;p&gt;The â€“dry-run flag is not for every situation, but when it fits, it can be quite useful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://henrikwarne.com/2026/01/31/in-praise-of-dry-run/"/><published>2026-01-31T20:42:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840698</id><title>Data Processing Benchmark Featuring Rust, Go, Swift, Zig, Julia etc.</title><updated>2026-02-01T05:40:59.634273+00:00</updated><content>&lt;doc fingerprint="d3dc87f126ea083"&gt;
  &lt;main&gt;
    &lt;p&gt;Given a list of posts, compute the top 5 related posts for each post based on the number of shared tags.&lt;/p&gt;
    &lt;head&gt;Steps&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Read the posts JSON file.&lt;/item&gt;
      &lt;item&gt;Iterate over the posts and populate a map containing: &lt;code&gt;tag -&amp;gt; List&amp;lt;int&amp;gt;&lt;/code&gt;, with the int representing the post index of each post with that tag.&lt;/item&gt;
      &lt;item&gt;Iterate over the posts and for each post: &lt;list rend="ul"&gt;&lt;item&gt;Create a map: &lt;code&gt;PostIndex -&amp;gt; int&lt;/code&gt;to track the number of shared tags&lt;/item&gt;&lt;item&gt;For each tag, Iterate over the posts that have that tag&lt;/item&gt;&lt;item&gt;For each post, increment the shared tag count in the map.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Create a map: &lt;/item&gt;
      &lt;item&gt;Sort the related posts by the number of shared tags.&lt;/item&gt;
      &lt;item&gt;Write the top 5 related posts for each post to a new JSON file.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./run.sh go | rust | python | all

# windows (powershell)
./run.ps1 go | rust | python | all
# OR
pwsh ./run.ps1 go | rust | python | all

# Docker (check the dockerfiles/base.Dockerfile for available variables)
./gen_dockerfile.sh -b go | rust | python | all
# THEN

./docker_run.sh go | rust | python | all
# OR use the image directly
docker run -e TEST_NAME=go -it --rm go_databench&lt;/code&gt;
    &lt;head&gt;Rules&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FFI (including assembly inlining)&lt;/item&gt;
      &lt;item&gt;Unsafe code blocks&lt;/item&gt;
      &lt;item&gt;Custom benchmarking&lt;/item&gt;
      &lt;item&gt;Disabling runtime checks (bounds etc)&lt;/item&gt;
      &lt;item&gt;Specific hardware targeting&lt;/item&gt;
      &lt;item&gt;SIMD for single threaded solutions&lt;/item&gt;
      &lt;item&gt;Hardcoding number of posts&lt;/item&gt;
      &lt;item&gt;Lazy evaluation (Unless results are computed at runtime and timed)&lt;/item&gt;
      &lt;item&gt;Computation Caching&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support up to 100,000 posts&lt;/item&gt;
      &lt;item&gt;Support UTF8 strings&lt;/item&gt;
      &lt;item&gt;Parse json at runtime&lt;/item&gt;
      &lt;item&gt;Support up to 100 tags&lt;/item&gt;
      &lt;item&gt;Represent tags as strings&lt;/item&gt;
      &lt;item&gt;Be production ready&lt;/item&gt;
      &lt;item&gt;Use less than 8GB of memory&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Updated Results from github workflow (raw data)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Time (5k posts)&lt;/cell&gt;
        &lt;cell role="head"&gt;20k posts&lt;/cell&gt;
        &lt;cell role="head"&gt;60k posts&lt;/cell&gt;
        &lt;cell role="head"&gt;Total&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Julia HO1&lt;/cell&gt;
        &lt;cell&gt;6.80 ms&lt;/cell&gt;
        &lt;cell&gt;23.00 ms&lt;/cell&gt;
        &lt;cell&gt;99.33 ms&lt;/cell&gt;
        &lt;cell&gt;129.13 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;D HO1&lt;/cell&gt;
        &lt;cell&gt;11.21 ms&lt;/cell&gt;
        &lt;cell&gt;42.84 ms&lt;/cell&gt;
        &lt;cell&gt;122.06 ms&lt;/cell&gt;
        &lt;cell&gt;176.11 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;D (v2)&lt;/cell&gt;
        &lt;cell&gt;13.97 ms&lt;/cell&gt;
        &lt;cell&gt;1.30 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Rust&lt;/cell&gt;
        &lt;cell&gt;149.96 ms&lt;/cell&gt;
        &lt;cell&gt;1.30 s&lt;/cell&gt;
        &lt;cell&gt;1.46 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;c3&lt;/cell&gt;
        &lt;cell&gt;13.00 ms&lt;/cell&gt;
        &lt;cell&gt;164.67 ms&lt;/cell&gt;
        &lt;cell&gt;1.33 s&lt;/cell&gt;
        &lt;cell&gt;1.51 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;C++&lt;/cell&gt;
        &lt;cell&gt;16.10 ms&lt;/cell&gt;
        &lt;cell&gt;202.67 ms&lt;/cell&gt;
        &lt;cell&gt;1.72 s&lt;/cell&gt;
        &lt;cell&gt;1.94 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Zig&lt;/cell&gt;
        &lt;cell&gt;17.00 ms&lt;/cell&gt;
        &lt;cell&gt;233.67 ms&lt;/cell&gt;
        &lt;cell&gt;1.99 s&lt;/cell&gt;
        &lt;cell&gt;2.24 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Odin&lt;/cell&gt;
        &lt;cell&gt;18.74 ms&lt;/cell&gt;
        &lt;cell&gt;248.22 ms&lt;/cell&gt;
        &lt;cell&gt;2.12 s&lt;/cell&gt;
        &lt;cell&gt;2.39 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Neat&lt;/cell&gt;
        &lt;cell&gt;22.52 ms&lt;/cell&gt;
        &lt;cell&gt;301.30 ms&lt;/cell&gt;
        &lt;cell&gt;2.54 s&lt;/cell&gt;
        &lt;cell&gt;2.87 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Java (JIT)&lt;/cell&gt;
        &lt;cell&gt;24.60 ms&lt;/cell&gt;
        &lt;cell&gt;299.00 ms&lt;/cell&gt;
        &lt;cell&gt;2.62 s&lt;/cell&gt;
        &lt;cell&gt;2.94 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;C# (JIT)&lt;/cell&gt;
        &lt;cell&gt;22.53 ms&lt;/cell&gt;
        &lt;cell&gt;314.86 ms&lt;/cell&gt;
        &lt;cell&gt;2.76 s&lt;/cell&gt;
        &lt;cell&gt;3.10 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;C# (AOT)&lt;/cell&gt;
        &lt;cell&gt;21.48 ms&lt;/cell&gt;
        &lt;cell&gt;318.20 ms&lt;/cell&gt;
        &lt;cell&gt;2.79 s&lt;/cell&gt;
        &lt;cell&gt;3.12 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Haskell&lt;/cell&gt;
        &lt;cell&gt;26.65 ms&lt;/cell&gt;
        &lt;cell&gt;347.84 ms&lt;/cell&gt;
        &lt;cell&gt;2.81 s&lt;/cell&gt;
        &lt;cell&gt;3.19 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Nim&lt;/cell&gt;
        &lt;cell&gt;22.34 ms&lt;/cell&gt;
        &lt;cell&gt;337.00 ms&lt;/cell&gt;
        &lt;cell&gt;2.95 s&lt;/cell&gt;
        &lt;cell&gt;3.31 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;F# (JIT)&lt;/cell&gt;
        &lt;cell&gt;25.02 ms&lt;/cell&gt;
        &lt;cell&gt;354.38 ms&lt;/cell&gt;
        &lt;cell&gt;3.02 s&lt;/cell&gt;
        &lt;cell&gt;3.40 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Julia&lt;/cell&gt;
        &lt;cell&gt;23.66 ms&lt;/cell&gt;
        &lt;cell&gt;350.96 ms&lt;/cell&gt;
        &lt;cell&gt;3.10 s&lt;/cell&gt;
        &lt;cell&gt;3.47 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Vlang&lt;/cell&gt;
        &lt;cell&gt;26.39 ms&lt;/cell&gt;
        &lt;cell&gt;372.67 ms&lt;/cell&gt;
        &lt;cell&gt;3.24 s&lt;/cell&gt;
        &lt;cell&gt;3.64 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
        &lt;cell&gt;25.79 ms&lt;/cell&gt;
        &lt;cell&gt;390.86 ms&lt;/cell&gt;
        &lt;cell&gt;3.48 s&lt;/cell&gt;
        &lt;cell&gt;3.89 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;D&lt;/cell&gt;
        &lt;cell&gt;29.92 ms&lt;/cell&gt;
        &lt;cell&gt;413.98 ms&lt;/cell&gt;
        &lt;cell&gt;3.60 s&lt;/cell&gt;
        &lt;cell&gt;4.05 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Swift&lt;/cell&gt;
        &lt;cell&gt;36.61 ms&lt;/cell&gt;
        &lt;cell&gt;482.22 ms&lt;/cell&gt;
        &lt;cell&gt;4.19 s&lt;/cell&gt;
        &lt;cell&gt;4.71 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;F# (AOT)&lt;/cell&gt;
        &lt;cell&gt;37.92 ms&lt;/cell&gt;
        &lt;cell&gt;570.90 ms&lt;/cell&gt;
        &lt;cell&gt;5.07 s&lt;/cell&gt;
        &lt;cell&gt;5.68 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Java (GraalVM)&lt;/cell&gt;
        &lt;cell&gt;33.30 ms&lt;/cell&gt;
        &lt;cell&gt;504.00 ms&lt;/cell&gt;
        &lt;cell&gt;5.47 s&lt;/cell&gt;
        &lt;cell&gt;6.01 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Crystal&lt;/cell&gt;
        &lt;cell&gt;45.64 ms&lt;/cell&gt;
        &lt;cell&gt;690.35 ms&lt;/cell&gt;
        &lt;cell&gt;6.03 s&lt;/cell&gt;
        &lt;cell&gt;6.77 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Numba&lt;/cell&gt;
        &lt;cell&gt;66.15 ms&lt;/cell&gt;
        &lt;cell&gt;827.15 ms&lt;/cell&gt;
        &lt;cell&gt;6.94 s&lt;/cell&gt;
        &lt;cell&gt;7.83 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Pypy&lt;/cell&gt;
        &lt;cell&gt;72.62 ms&lt;/cell&gt;
        &lt;cell&gt;858.90 ms&lt;/cell&gt;
        &lt;cell&gt;7.38 s&lt;/cell&gt;
        &lt;cell&gt;8.31 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;LuaJIT&lt;/cell&gt;
        &lt;cell&gt;73.52 ms&lt;/cell&gt;
        &lt;cell&gt;930.36 ms&lt;/cell&gt;
        &lt;cell&gt;7.84 s&lt;/cell&gt;
        &lt;cell&gt;8.84 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;JS (Bun)&lt;/cell&gt;
        &lt;cell&gt;80.80 ms&lt;/cell&gt;
        &lt;cell&gt;975.00 ms&lt;/cell&gt;
        &lt;cell&gt;8.49 s&lt;/cell&gt;
        &lt;cell&gt;9.55 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Dart AOT&lt;/cell&gt;
        &lt;cell&gt;69.80 ms&lt;/cell&gt;
        &lt;cell&gt;1.07 s&lt;/cell&gt;
        &lt;cell&gt;9.43 s&lt;/cell&gt;
        &lt;cell&gt;10.57 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Dart VM&lt;/cell&gt;
        &lt;cell&gt;61.50 ms&lt;/cell&gt;
        &lt;cell&gt;989.67 ms&lt;/cell&gt;
        &lt;cell&gt;9.94 s&lt;/cell&gt;
        &lt;cell&gt;10.99 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;JS (Deno)&lt;/cell&gt;
        &lt;cell&gt;96.40 ms&lt;/cell&gt;
        &lt;cell&gt;1.17 s&lt;/cell&gt;
        &lt;cell&gt;10.61 s&lt;/cell&gt;
        &lt;cell&gt;11.88 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;JS (Node)&lt;/cell&gt;
        &lt;cell&gt;99.00 ms&lt;/cell&gt;
        &lt;cell&gt;1.12 s&lt;/cell&gt;
        &lt;cell&gt;11.03 s&lt;/cell&gt;
        &lt;cell&gt;12.25 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Clojure&lt;/cell&gt;
        &lt;cell&gt;111.90 ms&lt;/cell&gt;
        &lt;cell&gt;1.31 s&lt;/cell&gt;
        &lt;cell&gt;10.97 s&lt;/cell&gt;
        &lt;cell&gt;12.39 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Common Lisp (SBCL)&lt;/cell&gt;
        &lt;cell&gt;154.00 ms&lt;/cell&gt;
        &lt;cell&gt;1.34 s&lt;/cell&gt;
        &lt;cell&gt;11.20 s&lt;/cell&gt;
        &lt;cell&gt;12.69 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Ocaml&lt;/cell&gt;
        &lt;cell&gt;99.40 ms&lt;/cell&gt;
        &lt;cell&gt;1.46 s&lt;/cell&gt;
        &lt;cell&gt;13.05 s&lt;/cell&gt;
        &lt;cell&gt;14.61 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Typed Racket&lt;/cell&gt;
        &lt;cell&gt;136.36 ms&lt;/cell&gt;
        &lt;cell&gt;1.96 s&lt;/cell&gt;
        &lt;cell&gt;16.31 s&lt;/cell&gt;
        &lt;cell&gt;18.41 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Racket&lt;/cell&gt;
        &lt;cell&gt;135.03 ms&lt;/cell&gt;
        &lt;cell&gt;2.04 s&lt;/cell&gt;
        &lt;cell&gt;16.69 s&lt;/cell&gt;
        &lt;cell&gt;18.87 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Scala Native&lt;/cell&gt;
        &lt;cell&gt;287.70 ms&lt;/cell&gt;
        &lt;cell&gt;3.51 s&lt;/cell&gt;
        &lt;cell&gt;30.07 s&lt;/cell&gt;
        &lt;cell&gt;33.87 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;LuaJIT (JIT OFF)&lt;/cell&gt;
        &lt;cell&gt;630.13 ms&lt;/cell&gt;
        &lt;cell&gt;8.72 s&lt;/cell&gt;
        &lt;cell&gt;83.86 s&lt;/cell&gt;
        &lt;cell&gt;93.21 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Erlang&lt;/cell&gt;
        &lt;cell&gt;758.95 ms&lt;/cell&gt;
        &lt;cell&gt;12.50 s&lt;/cell&gt;
        &lt;cell&gt;107.46 s&lt;/cell&gt;
        &lt;cell&gt;120.72 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Lua&lt;/cell&gt;
        &lt;cell&gt;976.54 ms&lt;/cell&gt;
        &lt;cell&gt;15.09 s&lt;/cell&gt;
        &lt;cell&gt;136.84 s&lt;/cell&gt;
        &lt;cell&gt;152.90 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;1.51 s&lt;/cell&gt;
        &lt;cell&gt;24.84 s&lt;/cell&gt;
        &lt;cell&gt;215.18 s&lt;/cell&gt;
        &lt;cell&gt;241.53 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Lobster (JIT)&lt;/cell&gt;
        &lt;cell&gt;1.63 s&lt;/cell&gt;
        &lt;cell&gt;25.43 s&lt;/cell&gt;
        &lt;cell&gt;227.06 s&lt;/cell&gt;
        &lt;cell&gt;254.13 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Ruby&lt;/cell&gt;
        &lt;cell&gt;1.78 s&lt;/cell&gt;
        &lt;cell&gt;28.77 s&lt;/cell&gt;
        &lt;cell&gt;254.93 s&lt;/cell&gt;
        &lt;cell&gt;285.48 s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Time (5k posts)&lt;/cell&gt;
        &lt;cell role="head"&gt;20k posts&lt;/cell&gt;
        &lt;cell role="head"&gt;60k posts&lt;/cell&gt;
        &lt;cell role="head"&gt;Total&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;D Concurrent (v2)&lt;/cell&gt;
        &lt;cell&gt;7.21 ms&lt;/cell&gt;
        &lt;cell&gt;388.83 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;C# Concurrent (JIT)&lt;/cell&gt;
        &lt;cell&gt;6.56 ms&lt;/cell&gt;
        &lt;cell&gt;55.32 ms&lt;/cell&gt;
        &lt;cell&gt;450.54 ms&lt;/cell&gt;
        &lt;cell&gt;512.42 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;C++ Concurrent&lt;/cell&gt;
        &lt;cell&gt;58.00 ms&lt;/cell&gt;
        &lt;cell&gt;477.00 ms&lt;/cell&gt;
        &lt;cell&gt;540.00 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;C# Concurrent (AOT)&lt;/cell&gt;
        &lt;cell&gt;5.27 ms&lt;/cell&gt;
        &lt;cell&gt;60.57 ms&lt;/cell&gt;
        &lt;cell&gt;487.37 ms&lt;/cell&gt;
        &lt;cell&gt;553.22 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;D Concurrent&lt;/cell&gt;
        &lt;cell&gt;8.84 ms&lt;/cell&gt;
        &lt;cell&gt;76.34 ms&lt;/cell&gt;
        &lt;cell&gt;560.38 ms&lt;/cell&gt;
        &lt;cell&gt;645.56 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Rust Concurrent&lt;/cell&gt;
        &lt;cell&gt;5.43 ms&lt;/cell&gt;
        &lt;cell&gt;69.22 ms&lt;/cell&gt;
        &lt;cell&gt;602.36 ms&lt;/cell&gt;
        &lt;cell&gt;677.00 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Go Concurrent&lt;/cell&gt;
        &lt;cell&gt;5.53 ms&lt;/cell&gt;
        &lt;cell&gt;76.80 ms&lt;/cell&gt;
        &lt;cell&gt;640.02 ms&lt;/cell&gt;
        &lt;cell&gt;722.35 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Nim Concurrent&lt;/cell&gt;
        &lt;cell&gt;6.17 ms&lt;/cell&gt;
        &lt;cell&gt;90.26 ms&lt;/cell&gt;
        &lt;cell&gt;657.74 ms&lt;/cell&gt;
        &lt;cell&gt;754.17 ms&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;F# Concurrent (AOT)&lt;/cell&gt;
        &lt;cell&gt;8.40 ms&lt;/cell&gt;
        &lt;cell&gt;114.00 ms&lt;/cell&gt;
        &lt;cell&gt;1.00 s&lt;/cell&gt;
        &lt;cell&gt;1.13 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;F# Concurrent&lt;/cell&gt;
        &lt;cell&gt;8.80 ms&lt;/cell&gt;
        &lt;cell&gt;122.33 ms&lt;/cell&gt;
        &lt;cell&gt;1.08 s&lt;/cell&gt;
        &lt;cell&gt;1.21 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Swift Concurrent&lt;/cell&gt;
        &lt;cell&gt;13.24 ms&lt;/cell&gt;
        &lt;cell&gt;148.23 ms&lt;/cell&gt;
        &lt;cell&gt;1.20 s&lt;/cell&gt;
        &lt;cell&gt;1.37 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Julia Concurrent&lt;/cell&gt;
        &lt;cell&gt;11.02 ms&lt;/cell&gt;
        &lt;cell&gt;159.49 ms&lt;/cell&gt;
        &lt;cell&gt;1.40 s&lt;/cell&gt;
        &lt;cell&gt;1.57 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Java Concurrent (JIT)&lt;/cell&gt;
        &lt;cell&gt;73.40 ms&lt;/cell&gt;
        &lt;cell&gt;221.67 ms&lt;/cell&gt;
        &lt;cell&gt;1.41 s&lt;/cell&gt;
        &lt;cell&gt;1.70 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Numba Concurrent&lt;/cell&gt;
        &lt;cell&gt;25.82 ms&lt;/cell&gt;
        &lt;cell&gt;223.30 ms&lt;/cell&gt;
        &lt;cell&gt;1.62 s&lt;/cell&gt;
        &lt;cell&gt;1.87 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Zig Concurrent&lt;/cell&gt;
        &lt;cell&gt;17.50 ms&lt;/cell&gt;
        &lt;cell&gt;222.24 ms&lt;/cell&gt;
        &lt;cell&gt;1.86 s&lt;/cell&gt;
        &lt;cell&gt;2.10 s&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Java (GraalVM) Concurrent&lt;/cell&gt;
        &lt;cell&gt;20.00 ms&lt;/cell&gt;
        &lt;cell&gt;294.67 ms&lt;/cell&gt;
        &lt;cell&gt;1.81 s&lt;/cell&gt;
        &lt;cell&gt;2.12 s&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head&gt;Old Results with details (on my machine)&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Language&lt;/cell&gt;
        &lt;cell role="head"&gt;Processing Time&lt;/cell&gt;
        &lt;cell role="head"&gt;Total (+ I/O)&lt;/cell&gt;
        &lt;cell role="head"&gt;Details&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;4.5s&lt;/cell&gt;
        &lt;cell&gt;Initial&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust v2&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;2.60s&lt;/cell&gt;
        &lt;cell&gt;Replace std HashMap with fxHashMap by phazer99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust v3&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1.28s&lt;/cell&gt;
        &lt;cell&gt;Preallocate and reuse map and unstable sort by vdrmn and Darksonn&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust v4&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.13s&lt;/cell&gt;
        &lt;cell&gt;Use Post index as key instead of Pointer and Binary Heap by RB5009&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust v5&lt;/cell&gt;
        &lt;cell&gt;38ms&lt;/cell&gt;
        &lt;cell&gt;52ms&lt;/cell&gt;
        &lt;cell&gt;Rm hashing from loop and use vec[count] instead of map[index]count by RB5009&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust v6&lt;/cell&gt;
        &lt;cell&gt;23ms&lt;/cell&gt;
        &lt;cell&gt;36ms&lt;/cell&gt;
        &lt;cell&gt;Optimized Binary Heap Ops by scottlamb&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust Rayon&lt;/cell&gt;
        &lt;cell&gt;9ms&lt;/cell&gt;
        &lt;cell&gt;22ms&lt;/cell&gt;
        &lt;cell&gt;Parallelize by masmullin2000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Rust Rayon&lt;/cell&gt;
        &lt;cell&gt;8ms&lt;/cell&gt;
        &lt;cell&gt;22ms&lt;/cell&gt;
        &lt;cell&gt;Remove comparison out of hot loop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1.5s&lt;/cell&gt;
        &lt;cell&gt;Initial&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go v2&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;80ms&lt;/cell&gt;
        &lt;cell&gt;Add rust optimizations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go v3&lt;/cell&gt;
        &lt;cell&gt;56ms&lt;/cell&gt;
        &lt;cell&gt;70ms&lt;/cell&gt;
        &lt;cell&gt;Use goccy/go-json&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go v3&lt;/cell&gt;
        &lt;cell&gt;34ms&lt;/cell&gt;
        &lt;cell&gt;55ms&lt;/cell&gt;
        &lt;cell&gt;Use generic binaryheap by DrBlury&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go v4&lt;/cell&gt;
        &lt;cell&gt;26ms&lt;/cell&gt;
        &lt;cell&gt;50ms&lt;/cell&gt;
        &lt;cell&gt;Replace binary heap with custom priority queue&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go v5&lt;/cell&gt;
        &lt;cell&gt;20ms&lt;/cell&gt;
        &lt;cell&gt;43ms&lt;/cell&gt;
        &lt;cell&gt;Remove comparison out of hot loop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go Con&lt;/cell&gt;
        &lt;cell&gt;10ms&lt;/cell&gt;
        &lt;cell&gt;33ms&lt;/cell&gt;
        &lt;cell&gt;Go concurrency by tirprox and DrBlury&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Go Con v2&lt;/cell&gt;
        &lt;cell&gt;5ms&lt;/cell&gt;
        &lt;cell&gt;29ms&lt;/cell&gt;
        &lt;cell&gt;Use arena, use waitgroup, rm binheap by DrBlury&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;7.81s&lt;/cell&gt;
        &lt;cell&gt;Initial&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Python v2&lt;/cell&gt;
        &lt;cell&gt;1.35s&lt;/cell&gt;
        &lt;cell&gt;1.53s&lt;/cell&gt;
        &lt;cell&gt;Add rust optimizations by dave-andersen&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Numpy&lt;/cell&gt;
        &lt;cell&gt;0.57s&lt;/cell&gt;
        &lt;cell&gt;0.85s&lt;/cell&gt;
        &lt;cell&gt;Numpy implementation by Copper280z&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Crystal&lt;/cell&gt;
        &lt;cell&gt;50ms&lt;/cell&gt;
        &lt;cell&gt;96ms&lt;/cell&gt;
        &lt;cell&gt;Inital w/ previous optimizations&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Crystal v2&lt;/cell&gt;
        &lt;cell&gt;33ms&lt;/cell&gt;
        &lt;cell&gt;72ms&lt;/cell&gt;
        &lt;cell&gt;Replace binary heap with custom priority queue&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Odin&lt;/cell&gt;
        &lt;cell&gt;110ms&lt;/cell&gt;
        &lt;cell&gt;397ms&lt;/cell&gt;
        &lt;cell&gt;Ported from golang code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Odin v2&lt;/cell&gt;
        &lt;cell&gt;104ms&lt;/cell&gt;
        &lt;cell&gt;404ms&lt;/cell&gt;
        &lt;cell&gt;Remove comparison out of hot loop&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Dart VM&lt;/cell&gt;
        &lt;cell&gt;125ms&lt;/cell&gt;
        &lt;cell&gt;530ms&lt;/cell&gt;
        &lt;cell&gt;Ported from golang code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Dart bin&lt;/cell&gt;
        &lt;cell&gt;274ms&lt;/cell&gt;
        &lt;cell&gt;360ms&lt;/cell&gt;
        &lt;cell&gt;Compiled executable&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Vlang&lt;/cell&gt;
        &lt;cell&gt;339ms&lt;/cell&gt;
        &lt;cell&gt;560ms&lt;/cell&gt;
        &lt;cell&gt;Ported from golang code&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
        &lt;cell&gt;â €&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Zig&lt;/cell&gt;
        &lt;cell&gt;80ms&lt;/cell&gt;
        &lt;cell&gt;110ms&lt;/cell&gt;
        &lt;cell&gt;Provided by akhildevelops&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/zupat/related_post_gen"/><published>2026-01-31T20:50:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840801</id><title>CollectWise (YC F24) Is Hiring</title><updated>2026-02-01T05:40:59.205984+00:00</updated><content>&lt;doc fingerprint="9b58a24f7107e484"&gt;
  &lt;main&gt;
    &lt;p&gt;Automating consumer debt collection with AI&lt;/p&gt;
    &lt;p&gt;About Us&lt;/p&gt;
    &lt;p&gt;CollectWise is a fast growing and well funded Y Combinator-backed startup. Weâ€™re using generative AI to automate debt collection, a $35B market in the US alone. Our AI agents are already outperforming human collectors by 2X, and weâ€™re doing so at a fraction of the cost.&lt;/p&gt;
    &lt;p&gt;With a team of three, we scaled to a $1 million annualized run rate in just a few months, and we are now hiring an AI Agent Engineer to help us reach $10 million within the next year.&lt;/p&gt;
    &lt;p&gt;Role&lt;/p&gt;
    &lt;p&gt;We are hiring an AI Agent Engineer to design, optimize, and productionize the prompting and conversation logic behind our voice AI agents, while also supporting the technical systems that power customer deployments.&lt;/p&gt;
    &lt;p&gt;Youâ€™ll work at the intersection of AI quality, product outcomes, and engineering executionâ€”owning prompt development, testing, and iteration loops that improve real-world performance (e.g., identity verification, payment conversion, dispute handling, containment rates), while collaborating closely with the founder and customers to ship improvements quickly.&lt;/p&gt;
    &lt;p&gt;This role is ideal if youâ€™re highly analytical and business minded, love experimentation and measurement, and can also jump into back-end code and integrations when needed.&lt;/p&gt;
    &lt;p&gt;Responsibilities&lt;/p&gt;
    &lt;p&gt;Desired Qualifications&lt;/p&gt;
    &lt;p&gt;Compensation&lt;/p&gt;
    &lt;p&gt;CollectWise is revolutionizing debt recovery with autonomous AI agents and an integrated legal network. We boost recovery rates, reduce costs, and maintain a positive brand image through respectful, data-driven interactions.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/collectwise/jobs/ZunnO6k-ai-agent-engineer"/><published>2026-01-31T21:00:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840865</id><title>Outsourcing thinking</title><updated>2026-02-01T05:40:58.260654+00:00</updated><content>&lt;doc fingerprint="7d15995f09279fbf"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Outsourcing thinking&lt;/head&gt;
    &lt;p&gt;First, a note to the reader: This blog post is longer than usual, as I decided to address multiple connected issues in the same post, without being too restrictive on length. With modern browsing habits and the amount of available online media, I suspect this post will be quickly passed over in favor of more interesting reading material. Before you immediately close this tab, I invite you to scroll down and read the conclusion, which hopefully can give you some food for thought along the way. If, however, you manage to read the whole thing, I applaud your impressive attention span.&lt;/p&gt;
    &lt;p&gt;A common criticism of the use of large language models (LLMs) is that it can deprive us of cognitive skills. The typical argument is that outsourcing certain tasks can easily cause some kind of mental atrophy. To what extent this is true is an ongoing discussion among neuroscientists, psychologists and others, but to me, the understanding that with certain skills you have to "use it or lose it" seems intuitively and empirically sound.&lt;/p&gt;
    &lt;p&gt;The more relevant question is whether certain kinds of use are better or worse than others, and if so, which? In the blog post The lump of cognition fallacy, Andy Masley discusses this in detail. His entry point to the problem is to challenge the idea that "there is a fixed amount of thinking to do", and how it leads people to the conclusion that "outsourcing thinking" to chatbots will make us lazy, less intelligent, or in other ways be negative for our cognitive abilities. He compares this to the misconception that there is only a finite amount of work that needs to be done in an economy, which often is referred to as "the lump of labour fallacy". His viewpoint is that "thinking often leads to more things to think about", and therefore we shouldn't worry about letting machines do the thinking for us â€” we will simply be able to think about other things instead.&lt;/p&gt;
    &lt;p&gt;Reading Masley's blog post prompted me to write down my own thoughts on the matter, as it has been churning in my mind for a long time. I realized that it could be constructive to use his blog post as a reference and starting point, because it contains arguments that are often brought up in this discussion. I will use some examples from Masley's post to show how I think differently about this, but I'll extend the scope beyond the claimed fallacy that there is a limited amount of thinking to be done. I have done my best to write this text in a way that does not require reading Masley's post first. My aim is not to refute all of his arguments, but to explain why the issue is much more complicated than "thinking often leads to more things to think about". Overall, the point of this post is to highlight some critical issues with "outsourcing thinking".&lt;/p&gt;
    &lt;head rend="h3"&gt;When should we avoid using generative language models?&lt;/head&gt;
    &lt;p&gt;Is it possible to define categories of activities where the use of LLMs (typically in the form of chatbots) is more harmful than helpful? Masley lists certain cases where, in his view, it is obviously detrimental to outsource thinking. To fully describe my own perspective, I'll take the liberty to quote the items on his list. He writes it's "bad to outsource your cognition when it:"&lt;/p&gt;
    &lt;quote&gt;
      &lt;item&gt;Builds complex tacit knowledge you'll need for navigating the world in the future.&lt;/item&gt;
      &lt;item&gt;Is an expression of care and presence for someone else.&lt;/item&gt;
      &lt;item&gt;Is a valuable experience on its own.&lt;/item&gt;
      &lt;item&gt;Is deceptive to fake.&lt;/item&gt;
      &lt;item&gt;Is focused in a problem that is deathly important to get right, and where you don't totally trust who you're outsourcing it to.&lt;/item&gt;
    &lt;/quote&gt;
    &lt;p&gt;I was surprised to discover that we are to a large extent in agreement on this list, despite having fundamentally different views otherwise. The disagreement lies, I believe, in the amount of activities that fall within the categories outlined above, particularly three of them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Personal communication and writing&lt;/head&gt;
    &lt;p&gt;Let's start with the point "Is deceptive to fake". Masley uses the example of:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;If someoneâ€™s messaging you on a dating app, they want to know what youâ€™re actually like.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Very true, but in my view, it's not only in such intimate or private situations where it is deceptive to fake what you are like. Personal communication in general is an area where it matters how we express ourselves, both for ourselves and those we talk or write to. When we communicate with each other, there are certain expectations framing the whole exchange. Letting our words and phrases be transformed by a machine is a breach of those expectations. The words we choose and how we formulate our sentences carry a lot of meaning, and direct communication will suffer if we let language models pollute this type of interaction. Direct communication is not only about the information being exchanged, it's also about the relationship between the communicators, formed by who we are and how we express ourselves.&lt;/p&gt;
    &lt;p&gt;I think this is not only relevant for communication between two humans, but also for text with a personal sender conveyed to a human audience in general. To a certain extent, the same principles apply. There has been a debate in the Norwegian media lately regarding the undisclosed use of LLMs in public writing, with allegations and opinions flying around. I'm very happy to see this discussion reaching broad daylight, because we need to clarify our expectations to communication, now that chatbots are being so widely used. While I clearly think that it is beneficial to keep human-to-human communication free from an intermediate step of machine transformation, not everyone shares that view. If, going forward, our written communication will for the most part be co-authored with AI models, we need to be aware of it, and shift our expectations accordingly. Some have started disclosing when they have used AI in their writing, which I think is a good step towards better understanding of our use of LLMs. Knowing whether a text is written or "co-authored" by an LLM has an important effect on how a receiver views it; pretending otherwise is simply false.&lt;/p&gt;
    &lt;p&gt;Many see LLMs as a great boon for helping people express their opinions more clearly, particularly for people not using their native language or those who have learning disabilities. As long as the meaning originates from a person, LLMs can help express that meaning in correct and effective language. I have two main objections against this. The first one is about what happens to the text: In most cases it's impossible to separate the meaning from the expression of it. That is in essence what language is â€” the words are the meaning. Changing the phrasing changes the message. The second one is about what happens to us: We rob ourselves of the opportunity to grow and learn, without training wheels. LLMs can certainly help people improve the text, but the thinking process â€” developing the ideas â€” will be severely amputated when leaving the phrasing up to an AI model. They quickly become a replacement instead of help, depriving us the opportunity of discovering our own voice and who we can be and become when we stand on our own two feet.&lt;/p&gt;
    &lt;p&gt;With great care, one may be able to use a chatbot without being affected by these two drawbacks, but the problem is that with LLMs, there is an exceptionally thin line between getting help with spelling or grammar, and having the model essentially write for you, thereby glossing over your own voice. This is unavoidable with the current design of chatbots and LLM-powered tools; the step from old-school autocorrect to a generative language model is far too big. If we really envision LLMs as a tool for helping people become better at writing, we need to have a much more carefully considered interface than the chatbots we have today.&lt;/p&gt;
    &lt;p&gt;At the same time, I realize many are far more utilitarian. They just want to get the job done, finish their work, file that report, get that complaint through, answer that email, in the most efficient way possible, and then get on with their day. Getting help from an LLM to express oneself in a second language also seems useful, without considering how much or little one learns from it (I would be more positive to LLMs for translation if it wasn't for the fact that current state-of-the-art LLMs are simply very bad at producing Norwegian text. I can only hope the state is better for other non-English languages, or that it will improve over time). Additionally, LLMs seem to be efficient for people who are fighting with bureaucracy, such is filing complaints and dealing with insurance companies. In this case the advantage seems greater. We must, however, remember that the "weapon" exists on both sides of the table. What will happen to bureaucratic processes when all parties involved are armed with word generators?&lt;/p&gt;
    &lt;p&gt;It is not without reservation that I express these opinions, because it may come across as I want to deny people something that looks like a powerful tool. The point is that I think this tool will make you weaker, not stronger. LLMs don't really seem to empower people. Some of the effect I currently see is the number of applications to various calls (internships, research proposals, job openings) multiplying, but the quality dropping. Students are asking chatbots for help with solving collaborative tasks, not realizing that everyone is asking the same chatbot, robbing us of the diversity of ideas that could have formed if they took a minute to think for themselves.&lt;/p&gt;
    &lt;p&gt;The chatbots may have lowered the threshold for participation, but the competition's ground rules hasn't changed. To get better at writing, you need to write. The same goes for thinking. Applying for a job means showing who you are, not who the LLM thinks you are, or should be. Participating in the public debate is having to work out how to express opinions in clear language. Am I really participating if I'm not finding my own words?&lt;/p&gt;
    &lt;p&gt;It is important to note that not all text is affected in the same way. The category of writing that I like to call "functional text", which are things like computer code and pure conveyance of information (e.g., recipes, information signs, documentation), is not exposed to the same issues. But text that has a personal author addressing a human audience, has particular role expectations and rests on a particular trust. An erosion of that trust will be a loss for humanity.&lt;/p&gt;
    &lt;p&gt;A pragmatic attitude would be to just let the inflation of text ensue, and take stock after the dust has settled. What will be left of language afterwards? My conservative viewpoint stems from believing that what we will lose is of greater worth than what we gain. While LLMs can prove useful in the short term, using them is treating a symptom instead of the problem. It is a crutch, although some may truly be in need of that crutch. My only advice would be to make sure you actually need it before you lean on it.&lt;/p&gt;
    &lt;head rend="h3"&gt;Valuable experiences&lt;/head&gt;
    &lt;p&gt;Using LLMs is not only about writing. Masley mentions that it's bad to outsource activities that are "a valuable experience on its own". I couldn't agree more, but I suspect that he will disagree when I say that I think this category encompasses a lot of what we already do in life. Major LLM providers love to show how their chatbots can be used to plan vacations, organize parties, and create personal messages to friends and family. I seldom feel more disconnected from the technological society than when I watch these advertisements.&lt;/p&gt;
    &lt;p&gt;To me, this highlights a problem that goes to the core of what it means to be human. Modern life brings with it a great deal of activities that can feel like chores, but at the same time it seems like we are hell-bent on treating everything as a chore as well. Humans are surprisingly good at finding discontentment in nearly anything, maybe because of an expectation in modern society that we should be able to do anything we want, anytime we want it â€” or perhaps more importantly, that we should be able to avoid doing things we don't feel like doing. Our inability to see opportunities and fulfillment in life as it is, leads to the inevitable conclusion that life is never enough, and we would always rather be doing something else.&lt;/p&gt;
    &lt;p&gt;In theory, I agree that automating some things can free up time for other things that are potentially more meaningful and rewarding, but we have already reached a stage where even planning our vacation is a chore that apparently a lot of people would like to avoid doing. I hope that AI's alleged ability to automate "nearly anything" helps us realize what is worth spending time and effort on, and rediscover the value of intentional living.&lt;/p&gt;
    &lt;head rend="h3"&gt;Building knowledge&lt;/head&gt;
    &lt;p&gt;The third point I would like to address is that we shouldn't use chatbots when it "builds complex tacit knowledge you'll need for navigating the world in the future", according to Masley. Again, I agree completely, and again, I think that this point encompasses a great deal of daily life. Building knowledge happens not only when you sit down to learn something new, but also when you do repetitive work.&lt;/p&gt;
    &lt;p&gt;This misconception is not new for chatbots, but has been present since we started carrying smartphones in our pockets. With internet at hand at all times, there's apparently no need to remember information anymore. Instead of using our brains for storing knowledge, we can access information online when we need it, and spend more time learning how to actually use the information and think critically. The point we are missing here, is that acquiring and memorizing knowledge is a huge part of learning to use the knowledge. It is naive to think that we can simply separate the storage unit from the processing unit, like if we were a computer.&lt;/p&gt;
    &lt;p&gt;I learned this lesson while being a piano student. I was trying to understand jazz, and figure out how good improvisers could learn to come up with new phrases so easily on the spot. How does one practice improvisation? Is it possible to exercise the ability to come up with something new that immediately sound good? I ended up playing similar riffs almost every time I tried. After a while I got convinced that good jazz players must be born with some inherent creativity, some inner musical inspiration that hummed melodies inside their heads for them to play.&lt;/p&gt;
    &lt;p&gt;One of my tutors taught me the real trick: Good improvisation comes not from just practicing improvisation. You need to play existing songs and tunes, many of them, over and over, learn them by heart, get the chord progressions and motifs under your skin. This practice builds your intuition for what sounds good, and your improvisation can spring from that. Bits and pieces of old melodies are combined into new music. In that sense, we are more like a machine learning model than a computer, but do not make the mistake of thinking that is actually what we are.&lt;/p&gt;
    &lt;p&gt;There is a need for clarification here: I'm not saying that nothing should be automated by LLMs. But I think many are severely underestimating the knowledge we are building from boring tasks, and we are in danger of losing that knowledge when the pressure for increased efficiency makes us turn to the chatbots.&lt;/p&gt;
    &lt;head rend="h3"&gt;The extended mind&lt;/head&gt;
    &lt;p&gt;As a sidenote, I would like to contest the idea of the extended mind, as explained by Masley:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[M]uch of our cognition isnâ€™t limited to our skull and brain, it also happens in our physical environment, so a lot of what we define as our minds could also be said to exist in the physical objects around us.&lt;/p&gt;
      &lt;p&gt;It seems kind of arbitrary whether itâ€™s happening in the neurons in your brain or in the circuits in your phone.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This statement is simply absurd, even when read in context. The fact that something happens in your brain rather than on a computer makes all the difference in the world. Humans are something more than information processors. Yes, we process information, but it is extremely reductionist to treat ourselves as objects where certain processes can be outsourced to external devices without consequences. Does it really matter if I remember my friend's birthday, when I can have a chatbot send them an automated congratulation? Yes, it matters because in the first case you are consciously remembering and thinking about your friend, consolidating your side of the relationship.&lt;/p&gt;
    &lt;p&gt;The quoted statement above is followed up with:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Itâ€™s true that you could lose your phone and therefore lose the stored knowledge, but you could also have a part of your brain cut out.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Losing your phone and losing a part of your brain are two tremendously different things, both in terms of likelihood and consequences. Not only does the statement above significantly underestimate the processes that happens in our brain, but to even liken having a part of your brain cut out to losing your phone reveals that the premiss of the argument is severely detached from reality.&lt;/p&gt;
    &lt;p&gt;The design of our built environments is also brought up to show how it's beneficial to minimize the amount of thinking we do:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;[M]ost of our physical environments have been designed specifically to minimize the amount of thinking we have to do to achieve our daily goals.&lt;/p&gt;
      &lt;p&gt;Try to imagine how much additional thinking you would need to do if things were designed differently.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This doesn't hold up to scrutiny. Yes, if our environment suddenly changed, it would require extra mental effort of us to navigate. For a time. But, then we would have gotten familiar with that alternative design, and adapted ourselves. The only case where we would have had to do additional thinking is if the design of our physical environments changed all the time.&lt;/p&gt;
    &lt;head rend="h3"&gt;What we think about does matter&lt;/head&gt;
    &lt;p&gt;Regarding the "lump of cognition fallacy", I fully agree that we need not worry about "draining a finite pool" of thinking, leaving "less thinking" â€” whatever that means â€” for humans. There is, however, another fallacy at play here, which is that "it does not matter what we think about, as long as we think about something". It is easy to be convinced that if a computer can do the simple, boring tasks for me, I can deal with more complex, exciting stuff myself. But we must be aware that certain mental tasks are important for us to do, even though a machine technically could do them for us.&lt;/p&gt;
    &lt;p&gt;To illustrate: If I outsource all my boring project administration tasks to a chatbot, it can leave more time for my main task: research. But it will also rob me of the opportunity to feel ownership to the project and build a basis for taking high-level decisions in the project. In a hypothetical situation where a chatbot performs all administrative tasks perfectly on my behalf, I will still have lost something, which may again have impact on the project. I'm not saying that no tasks should be automated at all, but we must be aware that we always lose something when automating a process.&lt;/p&gt;
    &lt;p&gt;Comparing with the "lump of labour" fallacy again: While it may be true that outsourcing physical work to machines will simply create new types of work to do, it doesn't mean that the new work is useful, fulfilling, or beneficial for individuals and society. The same goes for thinking. We must acknowledge that all kinds of thinking have an effect on us, even the boring and tedious kinds. Removing the need for some cognitive tasks can have just as much influence, positive or negative, as taking up new types of cognitive tasks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;We have a major challenge ahead of us in figuring out what chatbots are suitable for in the long term. Personal communication may change forever (that is to say, maybe it won't stay personal anymore), education systems will require radical adaptations, and we need to reflect more carefully about which experiences in life actually matter. What is truly exciting about this new type of technology, is that it forces us to face questions about our humanity and values. Many formerly theoretical questions of philosophy are becoming relevant for our daily lives.&lt;/p&gt;
    &lt;p&gt;A fundamental point I'm trying to bring forth is that how we choose to use chatbots is not only about efficiency and cognitive consequences; it's about how we want our lives and society to be. I have tried to argue that there are good reasons for protecting certain human activities against the automation of machines. This is in part based on my values, and does not rely on research into whether or not our efficiency at work or cognitive abilities are affected by it. I cannot tell other people what they should do, but I challenge everyone to consider what values they want to build our communities on, and let that weigh in alongside what the research studies tell us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://erikjohannes.no/posts/20260130-outsourcing-thinking/index.html"/><published>2026-01-31T21:06:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46840924</id><title>Generative AI and Wikipedia editing: What we learned in 2025</title><updated>2026-02-01T05:40:57.935922+00:00</updated><content>&lt;doc fingerprint="3f520313a88f8382"&gt;
  &lt;main&gt;
    &lt;p&gt;Like many organizations, Wiki Education has grappled with generative AI, its impacts, opportunities, and threats, for several years. As an organization that runs large-scale programs to bring new editors to Wikipedia (weâ€™re responsible for about 19% of all new active editors on English Wikipedia), we have deep understanding of what challenges face new content contributors to Wikipedia â€” and how to support them to successfully edit. As many people have begun using generative AI chatbots like ChatGPT, Gemini, or Claude in their daily lives, itâ€™s unsurprising that people will also consider using them to help draft contributions to Wikipedia. Since Wiki Educationâ€™s programs provide a cohort of content contributors whose work we can evaluate, weâ€™ve looked into how our participants are using GenAI tools.&lt;/p&gt;
    &lt;p&gt;We are choosing to share our perspective through this blog post because we hope it will help inform discussions of GenAI-created content on Wikipedia. In an open environment like the Wikimedia movement, itâ€™s important to share what youâ€™ve learned. In this case, we believe our learnings can help Wikipedia editors who are trying to protect the integrity of content on the encyclopedia, Wikipedians who may be interested in using generative AI tools themselves, other program leaders globally who are trying to onboard new contributors who may be interested in using these tools, and the Wikimedia Foundation, whose product and technology team builds software to help support the development of high-quality content on Wikipedia.&lt;/p&gt;
    &lt;p&gt;Our fundamental conclusion about generative AI is: Wikipedia editors should never copy and paste the output from generative AI chatbots like ChatGPT into Wikipedia articles.&lt;/p&gt;
    &lt;p&gt;Let me explain more.&lt;/p&gt;
    &lt;head rend="h4"&gt;AI detection and investigation&lt;/head&gt;
    &lt;p&gt;Since the launch of ChatGPT in November 2022, weâ€™ve been paying close attention to GenAI-created content, and how it relates to Wikipedia. Weâ€™ve spot-checked work of new editors from our programs, primarily focusing on citations to ensure they were real and not hallucinated. We experimented with tools ourselves, we led video sessions about GenAI for our program participants, and we closely tracked on-wiki policy discussions around GenAI. Currently, English Wikipedia prohibits the use of generative AI to create images or in talk page discussions, and recently adopted a guideline against using large language models to generate new articles.&lt;/p&gt;
    &lt;p&gt;As our Wiki Experts Brianda Felix and Ian Ramjohn worked with program participants throughout the first half of 2025, they found more and more text bearing the hallmarks of generative AI in article content, like bolded words or bulleted lists in odd places. But the use of generative AI wasnâ€™t necessarily problematic, as long as the content was accurate. Wikipediaâ€™s open editing process encourages stylistic revisions to factual text to better fit Wikipediaâ€™s style.&lt;/p&gt;
    &lt;p&gt;This finding led us to invest significant staff time into cleaning up these articles â€” far more than these editors had likely spent creating them. Wiki Educationâ€™s core mission is to improve Wikipedia, and when we discover our program has unknowingly contributed to misinformation on Wikipedia, we are committed to cleaning it up. In the clean-up process, Wiki Education staff moved more recent work back to sandboxes, we stub-ified articles that passed notability but mostly failed verification, and we PRODed some articles that from our judgment werenâ€™t salvageable. All these are ways of addressing Wikipedia articles with flaws in their content. (While there are many grumblings about Wikipediaâ€™s deletion processes, we found several of the articles we PRODed due to their fully hallucinated GenAI content were then de-PRODed by other editors, showing the diversity of opinion about generative AI among the Wikipedia community.&lt;/p&gt;
    &lt;head rend="h4"&gt;Revising our guidance&lt;/head&gt;
    &lt;p&gt;Given what we found through our investigation into the work from prior terms, and given the increasing usage of generative AI, we wanted to proactively address generative AI usage within our programs. Thanks to in-kind support from our friends at Pangram, we began running our participantsâ€™ Wikipedia edits, including in their sandboxes, through Pangram nearly in real time. This is possible because of the Dashboard course management platform Sage built, which tracks edits and generates tickets for our Wiki Experts based on on-wiki edits.&lt;/p&gt;
    &lt;p&gt;We created a brand-new training module on Using generative AI tools with Wikipedia. This training emphasizes where participants could use generative AI tools in their work, and where they should not. The core message of these trainings is, do not copy and paste anything from a GenAI chatbot into Wikipedia.&lt;/p&gt;
    &lt;p&gt;We crafted a variety of automated emails to participants who Pangram detected were adding text created by generative AI chatbots. Sage also recorded some videos, since many young people are accustomed to learning via video rather than reading text. We also provided opportunities for engagement and conversation with program participants.&lt;/p&gt;
    &lt;head rend="h4"&gt;Our findings from the second half of 2025&lt;/head&gt;
    &lt;p&gt;In total, we had 1,406 AI edit alerts in the second half of 2025, although only 314 of these (or 22%) were in the article namespace on Wikipedia (meaning edits to live articles). In most cases, Pangram detected participants using GenAI in their sandboxes during early exercises, when we ask them to do things like choose an article, evaluate an article, create a bibliography, and outline their contribution.&lt;/p&gt;
    &lt;p&gt;Pangram struggled with false positives in a few sandbox scenarios:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bibliographies, which are often a combination of human-written prose (describing a source and its relevance) and non-prose text (the citation for a source, in some standard format)&lt;/item&gt;
      &lt;item&gt;Outlines with a high portion of non-prose content (such as bullet lists, section headers, text fragments, and so on)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We also had a handful of cases where sandboxes were flagged for AI after a participant copied an AI-written section from an existing article to use as a starting point to edit or to expand. (This isnâ€™t a flaw of Pangram, but a reminder of how much AI-generated content editors outside our programs are adding to Wikipedia!)&lt;/p&gt;
    &lt;p&gt;In broad strokes, we found that Pangram is great at analyzing plain prose â€” the kind of sentences and paragraphs youâ€™ll find in the body of a Wikipedia article â€” but sometimes it gets tripped up by formatting, markup, and non-prose text. Early on, we disabled alert emails for participantsâ€™ bibliography and outline exercises, and throughout the end of 2025, we refined the Dashboardâ€™s preprocessing steps to extract the prose portions of revisions and convert them to plain text before sending them to Pangram.&lt;/p&gt;
    &lt;p&gt;Many participants also reported â€œjust using Grammarly to copy edit.â€ In our experience, however, the smallest fixes done with Grammarly never trigger Pangramâ€™s detection, but if you use its more advanced content creation features, the resulting text registers as being AI generated.&lt;/p&gt;
    &lt;p&gt;But overwhelmingly, we were pleased with Pangramâ€™s results. Our early interventions with participants who were flagged as using generative AI for exercises that would not enter mainspace seemed to head off their future use of generative AI. We supported 6,357 new editors in fall 2025, and only 217 of them (or 3%) had multiple AI alerts. Only 5% of the participants we supported had mainspace AI alerts. That means thousands of participants successfully edited Wikipedia without using generative AI to draft their content.&lt;/p&gt;
    &lt;p&gt;For those who did add GenAI-drafted text, we ensured that the content was reverted. In fact, participants sometimes self-reverted once they received our email letting them know Pangram had detected their contributions as being AI created. Instructors also jumped in to revert, as did some Wikipedians who found the content on their own. Our ticketing system also alerted our Wiki Expert staff, who reverted the text as soon as they could.&lt;/p&gt;
    &lt;p&gt;While some instructors in our Wikipedia Student Program had concerns about AI detection, we had a lot of success focusing the conversation on the concept of verifiability. If the instructor as subject matter expert could attest the information was accurate, and they could find the specific facts in the sources they were cited to, we permitted text to come back to Wikipedia. However, the process of attempting to verify student-created work (which in many cases the students swore theyâ€™d written themselves) led many instructors to realize what we had found in our own assessment: In their current states, GenAI-powered chatbots cannot write factually accurate text for Wikipedia that is verifiable.&lt;/p&gt;
    &lt;p&gt;We believe our Pangram-based detection interventions led to fewer participants adding GenAI-created content to Wikipedia. Following the trend lines, we anticipated about 25% of participants to add GenAI content to Wikipedia articles; instead, it was only 5%, and our staff were able to revert all problematic content.&lt;/p&gt;
    &lt;p&gt;Iâ€™m deeply appreciative of everyone who made this success possible this term: Participants who followed our recommendations, Pangram who gave us access to their detection service, Wiki Education staff who did the heavy lift of working with all of the positive detections, and the Wikipedia community, some of whom got to the problematic work from our program participants before we did.&lt;/p&gt;
    &lt;head rend="h4"&gt;How can generative AI help?&lt;/head&gt;
    &lt;p&gt;So far, Iâ€™ve focused on the problems with generative AI-created content. But thatâ€™s not all these tools can do, and we did find some ways they were useful. Our training module encourages editors â€” if their institutionâ€™s policies permit it â€” to consider using generative AI tools for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identifying gaps in articles&lt;/item&gt;
      &lt;item&gt;Finding access to sources&lt;/item&gt;
      &lt;item&gt;Finding relevant sources&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To evaluate the success of these use scenarios, we worked directly with 7 of the classes we supported in fall 2025 in our Wikipedia Student Program. We asked students to anonymously fill out a survey every time they used generative AI tools in their Wikipedia work. We asked what tool they used, what prompt they used, how they used the output, and whether they found it helpful. While some students filled the survey out multiple times, others filled it out once. We had 102 responses reporting usage at various stages in the project. Overwhelmingly, 87% of the responses who reported using generative AI said it was helpful for them in the task. The most popular tool by far was ChatGPT, with Grammarly as a distant second, and the others in the single-digits of usage.&lt;/p&gt;
    &lt;p&gt;Students reported AI tools very helpful in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Identifying articles to work on that were relevant to the course they were taking&lt;/item&gt;
      &lt;item&gt;Highlighting gaps within existing articles, including missing sections or more recent information that was missing&lt;/item&gt;
      &lt;item&gt;Finding reliable sources that they hadnâ€™t already located&lt;/item&gt;
      &lt;item&gt;Pointing to which database a certain journal article could be found&lt;/item&gt;
      &lt;item&gt;When prompted with the text they had drafted and the checklist of requirements, evaluating the draft against those requirements&lt;/item&gt;
      &lt;item&gt;Identifying categories they could add to the article theyâ€™d edited&lt;/item&gt;
      &lt;item&gt;Correcting grammar and spelling mistakes&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Critically, no participants reported using AI tools to draft text for their assignments. One student reported: â€œI pasted all of my writing from my sandbox and said â€˜Put this in a casual, less academic toneâ€™ â€¦ I figured Iâ€™d try this but it didnâ€™t sound like what I normally write and I didnâ€™t feel that it captured what I was trying to get across so I scrapped it.â€&lt;/p&gt;
    &lt;p&gt;While this was an informal research project, we received enough positive feedback from it to believe using ChatGPT and other tools can be helpful in the research stage if editors then critically evaluate the output they get, instead of blindly accepting it. Even participants who found AI helpful reported that they didnâ€™t use everything it gave them, as some was irrelevant. Undoubtedly, itâ€™s crucial to maintain the human thinking component throughout the process.&lt;/p&gt;
    &lt;head rend="h4"&gt;What does this all mean for Wiki Education?&lt;/head&gt;
    &lt;p&gt;My conclusion is that, at least as of now, generative AI-powered chatbots like ChatGPT should never be used to generate text for Wikipedia; too much of it will simply be unverifiable. Our staff would spend far more time attempting to verify facts in AI-generated articles than if weâ€™d simply done the research and writing ourselves.&lt;/p&gt;
    &lt;p&gt;That being said, AI tools can be helpful in the research process, especially to help identify content gaps or sources, when used in conjunction with a human brain that carefully evaluates the information. Editors should never simply take a chatbotâ€™s suggestion; instead, if they want to use a chatbot, they should use it as a brainstorm partner to help them think through their plans for an article.&lt;/p&gt;
    &lt;p&gt;To date, Wiki Educationâ€™s interventions as our program participants edit Wikipedia show promise for keeping unverifiable, GenAI-drafted content off Wikipedia. Based on our experiences in the fall term, we have high confidence in Pangram as a detector of AI content, at least in Wikipedia articles. We will continue our current strategy in 2026 (with more small adjustments to make the system as reliable as we can).&lt;/p&gt;
    &lt;p&gt;More generally, we found participants had less AI literacy than popular discourse might suggest. Because of this, we created a supplemental large language models training that weâ€™ve offered as an optional module for all participants. Many participants indicated that they found our guidance regarding AI to be welcome and helpful as they attempt to navigate the new complexities created by AI tools.&lt;/p&gt;
    &lt;p&gt;We are also looking forward to more research on our work. A team of researchers â€” Francesco Salvi and Manoel Horta Ribeiro at Princeton University, Robert Cummings at the University of Mississippi, and Wiki Educationâ€™s Sage Ross â€” have been looking into Wiki Educationâ€™s Wikipedia Student Program editorsâ€™ use of generative AI over time. Preliminary results have backed up our anecdotal understanding, while also revealing nuances of how text produced by our students over time has changed with the introduction of GenAI chatbots. They also confirmed our belief in Pangram: After running student edits from 2015 up until the launch of ChatGPT through Pangram, without any date information involved, the team found Pangram correctly identified that it was all 100% human written. This research will continue into the spring, as the team explores ways of unpacking the effects of AI on different aspects of article quality.&lt;/p&gt;
    &lt;p&gt;And, of course, generative AI is a rapidly changing field. Just because these were our findings in 2025 doesnâ€™t mean they will hold true throughout 2026. Wiki Education remains committed to monitoring, evaluating, iterating, and adapting as needed. Fundamentally, we are committed to ensuring we add high quality content to Wikipedia through our programs. And when we miss the mark, we are committed to cleaning up any damage.&lt;/p&gt;
    &lt;head rend="h4"&gt;What does this all mean for Wikipedia?&lt;/head&gt;
    &lt;p&gt;While Iâ€™ve focused this post on what Wiki Education has learned from working with our program participants, the lessons are extendable to others who are editing Wikipedia. Already, 10% of adults worldwide are using ChatGPT, and drafting text is one of the top use cases. As generative AI usage proliferates, its usage by well-meaning people to draft content for Wikipedia will as well. Itâ€™s unlikely that longtime, daily Wikipedia editors would add content copied and pasted from a GenAI chatbot without verifying all the information is in the sources it cites. But many casual Wikipedia contributors or new editors may unknowingly add bad content to Wikipedia when using a chatbot. After all, it provides what looks like accurate facts, cited to what are often real, relevant, reliable sources. Most edits we ended up reverting seemed acceptable with a cursory review; it was only after we attempted to verify the information that we understood the problems.&lt;/p&gt;
    &lt;p&gt;Because this unverifiable content often seems okay at first pass, itâ€™s critical for Wikipedia editors to be equipped with tools like Pangram to more accurately detect when they should take a closer look at edits. Automating review of text for generative AI usage â€” as Wikipedians have done for copyright violation text for years â€” would help protect the integrity of Wikipedia content. In Wiki Educationâ€™s experience, Pangram is a tool that could provide accurate assessments of text for editors, and we would love to see a larger scale version of the tool we built to evaluate edits from our programs to be deployed across all edits on Wikipedia. Currently, editors can add a warning banner that highlights that the text might be LLM generated, but this is based solely on the assessment of the person adding the banner. Our experience suggests that judging by tone alone isnâ€™t enough; instead, tools like Pangram can flag highly problematic information that should be reverted immediately but that might sound okay.&lt;/p&gt;
    &lt;p&gt;Weâ€™ve also found success in the training modules and support weâ€™ve created for our program participants. Providing clear guidance â€” and the reason why that guidance exists â€” has been key in helping us head off poor usage of generative AI text. We encourage Wikipedians to consider revising guidance to new contributors in the welcome messages to emphasize the pitfalls of adding GenAI-drafted text. Software aimed at new contributors created by the Wikimedia Foundation should center starting with a list of sources and drawing information from them, using human intellect, instead of generative AI, to summarize information. Providing guidance upfront can help well-meaning contributors steer clear of bad GenAI-created text.&lt;/p&gt;
    &lt;p&gt;Wikipedia recently celebrated its 25th birthday. For it to survive into the future, it will need to adapt as technology around it changes. Wikipedia would be nothing without its corps of volunteer editors. The consensus-based decision-making model of Wikipedia means change doesnâ€™t come quickly, but we hope this deep-dive will help spark a conversation about changes that are needed to protect Wikipedia into the future.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wikiedu.org/blog/2026/01/29/generative-ai-and-wikipedia-editing-what-we-learned-in-2025/"/><published>2026-01-31T21:14:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46841374</id><title>Swift is a more convenient Rust (2023)</title><updated>2026-02-01T05:40:57.655969+00:00</updated><content>&lt;doc fingerprint="1448501bb205ba19"&gt;
  &lt;main&gt;
    &lt;p&gt;(originally published on my old blog)&lt;/p&gt;
    &lt;p&gt;Iâ€™ve been learning Rust lately.&lt;/p&gt;
    &lt;p&gt;Rust is one of the most loved languages out there, is fast, and has an amazing community. Rust invented the concept of ownership as a solution memory management issues without resorting to something slower like Garbage Collection or Reference Counting. But, when you donâ€™t need to be quite as low level, it gives you utilities such as &lt;code&gt;Rc&lt;/code&gt;, &lt;code&gt;Arc&lt;/code&gt; and &lt;code&gt;Cow&lt;/code&gt; to do reference counting and â€œclone-on-rightâ€ in your code. And, when you need to go lower-level still, you can use the &lt;code&gt;unsafe&lt;/code&gt; system and access raw C pointers.&lt;/p&gt;
    &lt;p&gt;Rust also has a bunch of awesome features from functional languages like tagged enums, match expressions, first class functions and a powerful type system with generics.&lt;/p&gt;
    &lt;p&gt;Rust has an LLVM-based compiler which lets it compile to native code and WASM.&lt;/p&gt;
    &lt;p&gt;Iâ€™ve also been doing a bit of Swift programming for a couple of years now. And the more I learn Rust, the more I see a reflection of Swift. (I know that Swift stole a lot of ideas from Rust, Iâ€™m talking about my own perspective here).&lt;/p&gt;
    &lt;p&gt;Swift, too, has awesome features from functional languages like tagged enums, match expressions and first-class functions. It too has a very powerful type system with generics.&lt;/p&gt;
    &lt;p&gt;Swift too gives you complete type-safety without a garbage collector. By default, everything is a value type with â€œcopy-on-writeâ€ semantics. But when you need extra speed you can opt into an ownership system and â€œmoveâ€ values to avoid copying. And if you need to go even lower level, you can use the unsafe system and access raw C pointers.&lt;/p&gt;
    &lt;p&gt;Swift has an LLVM-based compiler which lets it compile to native code and WASM.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Deja Vu?&lt;/head&gt;
    &lt;p&gt;Youâ€™re probably feeling like you just read the same paragraphs twice. This is no accident. Swift is extremely similar to Rust and has most of the same feature-set. But there is a very big difference is perspective. If you consider the default memory model, this will start to make a lot of sense.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Rust is bottom-up, Swift is top-down.&lt;/head&gt;
    &lt;p&gt;Rust is a low-level systems language at heart, but it gives you the tools to go higher level. Swift starts at a high level and gives you the ability to go low-level.&lt;/p&gt;
    &lt;p&gt;The most obvious example of this is the memory management model. Swift use value-types by default with &lt;code&gt;copy-on-write&lt;/code&gt; semantics. This is the equivalent of using &lt;code&gt;Cow&amp;lt;&amp;gt;&lt;/code&gt; for all your values in Rust. But defaults matter. Rust makes it easy to use â€œmovedâ€ and â€œborrowedâ€ values but requires extra ceremony to use &lt;code&gt;Cow&amp;lt;&amp;gt;&lt;/code&gt; values as you need to â€œunwrapâ€ them &lt;code&gt;.as_mutable()&lt;/code&gt; to actually use the value within. Swift makes these Copy-on-Write values easy to use and instead requires extra ceremony to use borrowing and moving instead. Rust is faster by default, Swift is simpler and easier by default.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Swift takes Rustâ€™s ideas and hides them in C-like syntax.&lt;/head&gt;
    &lt;p&gt;Swiftâ€™s syntax is a masterclass in taking awesome functional language concepts and hiding them in C-like syntax to trick the developers into accepting them.&lt;/p&gt;
    &lt;p&gt;Consider &lt;code&gt;match&lt;/code&gt; statements. This is what a match statement looks like in Rust:&lt;/p&gt;
    &lt;p&gt;Hereâ€™s how that same code would be written in Swift:&lt;/p&gt;
    &lt;p&gt;Swift doesnâ€™t have a &lt;code&gt;match&lt;/code&gt; statement or expression. It has a &lt;code&gt;switch&lt;/code&gt; statement that developers are already familiar with. Except this &lt;code&gt;switch&lt;/code&gt; statement is actually not a &lt;code&gt;switch&lt;/code&gt; statement at all. Itâ€™s an expression. It doesnâ€™t â€œfallthroughâ€. It does pattern matching. Itâ€™s just a &lt;code&gt;match&lt;/code&gt; expression with a different name and syntax.&lt;/p&gt;
    &lt;p&gt;In fact, Swift treats &lt;code&gt;enums&lt;/code&gt; as more than just types and lets you put methods directly on it:&lt;/p&gt;
    &lt;head rend="h4"&gt;#Optional Types&lt;/head&gt;
    &lt;p&gt;Rust doesnâ€™t have &lt;code&gt;null&lt;/code&gt;, but it does have &lt;code&gt;None&lt;/code&gt;. Swift has a &lt;code&gt;nil&lt;/code&gt;, but itâ€™s really just a &lt;code&gt;None&lt;/code&gt; in hiding. Instead of an &lt;code&gt;Option&amp;lt;T&amp;gt;&lt;/code&gt;, Swift letâ€™s you use &lt;code&gt;T?&lt;/code&gt;, but the compiler still forces you to check that the value is not &lt;code&gt;nil&lt;/code&gt; before you can use it.&lt;/p&gt;
    &lt;p&gt;You get the same safety with more convenience since you can do this in Swift with an optional type:&lt;/p&gt;
    &lt;p&gt;Also, youâ€™re not forced to wrap every value with a &lt;code&gt;Some(val)&lt;/code&gt; before returning it. The Swift compiler takes care of that for you. A &lt;code&gt;T&lt;/code&gt; will transparently be converted into a &lt;code&gt;T?&lt;/code&gt; when needed.&lt;/p&gt;
    &lt;head rend="h4"&gt;#Error Handling&lt;/head&gt;
    &lt;p&gt;Rust doesnâ€™t have &lt;code&gt;try-catch&lt;/code&gt;. Instead it has a &lt;code&gt;Result&lt;/code&gt; type which contains the success and error types.&lt;/p&gt;
    &lt;p&gt;Swift doesnâ€™t have a &lt;code&gt;try-catch&lt;/code&gt; either, but it does have &lt;code&gt;do-catch&lt;/code&gt; and you have to use &lt;code&gt;try&lt;/code&gt; before calling a function that could throw. Again, this is just deception for those developers coming from C-like languages. Swiftâ€™s error handling works exactly like Rustâ€™s behind the scenes, but it is hidden in a clever, familiar syntax.&lt;/p&gt;
    &lt;p&gt;This is very similar to how Rust letâ€™s you use &lt;code&gt;?&lt;/code&gt; at the end of statements to automatically forward errors, but you donâ€™t have to wrap your success values in &lt;code&gt;Ok()&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Rustâ€™s compiler catches problems. Swiftâ€™s compiler solves some of them&lt;/head&gt;
    &lt;p&gt;There are many common problems that Rustâ€™s compiler will catch at compile time and even suggest solutions for you. The example that portrays this well is self-referencing enums.&lt;/p&gt;
    &lt;p&gt;Consider an enum that represents a tree. Since, it is a recursive type, Rust will force you to use something like &lt;code&gt;Box&amp;lt;&amp;gt;&lt;/code&gt; for referencing a type within itself.&lt;/p&gt;
    &lt;p&gt;(You could also us &lt;code&gt;Box&amp;lt;Vec&amp;lt;TreeNode&amp;lt;T&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; instead)&lt;/p&gt;
    &lt;p&gt;This makes the problem explicit and forces you to deal with it directly. Swift is a little more, automatic.&lt;/p&gt;
    &lt;p&gt;Note: that you still have to annotate this &lt;code&gt;enum&lt;/code&gt; with the &lt;code&gt;indirect&lt;/code&gt; keyword to indicate that it is recursive. But once youâ€™ve done that, Swiftâ€™s compiler takes care of the rest. You donâ€™t have to think about &lt;code&gt;Box&amp;lt;&amp;gt;&lt;/code&gt; or &lt;code&gt;Rc&amp;lt;&amp;gt;&lt;/code&gt;. The values just work normally.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Swift is less â€œpureâ€&lt;/head&gt;
    &lt;p&gt;Swift was designed to replace Objective-C and needed to be able to interface with existing code. So, it has made a lot of pragmatic choices that makes it a much less â€œpureâ€ and â€œminimalistâ€ language. Swift is a pretty big language compared to Rust and has many more features built-in. However, Swift is designed with â€œprogressive disclosureâ€ in mind which means that just as soon as you think youâ€™ve learned the language a little more of the iceberg pops out of the water.&lt;/p&gt;
    &lt;p&gt;Here are just some of the language features:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Classes / Inhertence&lt;/item&gt;
      &lt;item&gt;async-await&lt;/item&gt;
      &lt;item&gt;async-sequences&lt;/item&gt;
      &lt;item&gt;actors&lt;/item&gt;
      &lt;item&gt;getters and setters&lt;/item&gt;
      &lt;item&gt;lazy properties&lt;/item&gt;
      &lt;item&gt;property wrappers&lt;/item&gt;
      &lt;item&gt;Result Builders (for building tree-like structures. e.g. HTML / SwiftUI)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;#Convenience has its costs&lt;/head&gt;
    &lt;p&gt;Swift is a far easier language to get started and productive with. The syntax is more familiar and a lot more is done for you automatically. But this really just makes Swift a higher-level language and it comes with the same tradeoffs.&lt;/p&gt;
    &lt;p&gt;By default, a Rust program is much faster than a Swift program. This is because Rust is fast by default, and lets you be slow, while Swift is easy by default and lets you be fast.&lt;/p&gt;
    &lt;p&gt;Based on this, I would say both languages have their uses. Rust is better for systems and embedded programming. Itâ€™s better for writing compilers and browser engines (Servo) and itâ€™s better for writing entire operating systems.&lt;/p&gt;
    &lt;p&gt;Swift is better for writing UI and servers and some parts of compilers and operating systems. Over time I expect to see the overlap get bigger.&lt;/p&gt;
    &lt;head rend="h3"&gt;#The â€œcross-platformâ€ problem&lt;/head&gt;
    &lt;p&gt;There is a perception that Swift is only a good language for Apple platforms. While this was once true, this is no longer the case and Swift is becoming increasingly a good cross-platform language. Hell, Swift even compiles to wasm, and the forks made by the swift-wasm team were merged back into Swift core earlier this year.&lt;/p&gt;
    &lt;p&gt;Swift on Windows is being used by The Browser Company to share code and bring the Arc browser to windows. Swift on Linux has long been supported by Apple themselves in order to push â€œSwift on Serverâ€. Apple is directly sponsoring the Swift on Server conference.&lt;/p&gt;
    &lt;p&gt;This year Embedded Swift was also announced which is already being used on small devices like the Panic Playdate.&lt;/p&gt;
    &lt;p&gt;Swift website has been highlighting many of these projects:&lt;/p&gt;
    &lt;p&gt;The browser company says that Interoperability is Swiftâ€™s super power.&lt;/p&gt;
    &lt;p&gt;And the Swift project has been trying make working with Swift a great experience outside of XCode with projects like an open source LSP and funding the the VSCode extension.&lt;/p&gt;
    &lt;head rend="h3"&gt;#Swift is not a perfect language.&lt;/head&gt;
    &lt;p&gt;Compile times are (like Rust) quite bad. There is some amount of feature creep and the language is larger than it should be. Not all syntax feels familiar. The package ecosystem isnâ€™t nearly as rich as Rust.&lt;/p&gt;
    &lt;p&gt;But the â€œSwift is only for Apple platformsâ€ is an old and tired cliche at this point. Swift is already a cross-platform, ABI-stable language with no GC, automatic Reference Counting and the option to opt into ownership for even more performance. Swift packages increasingly work on Linux. Foundation was ported to Swift, open sourced and made open source. Itâ€™s still early days for Swift as a good, more convenient, Rust alternative for cross-platform development, but it is here now. Itâ€™s no longer a future to wait for.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust"/><published>2026-01-31T22:05:03+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46841794</id><title>When will CSS Grid Lanes arrive?</title><updated>2026-02-01T05:40:57.001095+00:00</updated><content>&lt;doc fingerprint="5606c7305c6669b2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;When will CSS Grid Lanes arrive? How long until we can use it?&lt;/head&gt;
    &lt;p&gt;Anytime an exciting new web technology starts to land in browsers, developers want to know â€œwhen in the world am I going to be able to use this?â€&lt;/p&gt;
    &lt;p&gt;Currently, the finalized syntax for Grid Lanes is available in Safari Technology Preview. Edge, Chrome and Firefox have all made significant progress on their implementations, so itâ€™s going to arrive sooner than you think.&lt;/p&gt;
    &lt;p&gt;Plus, you can start using it as soon as you want with progressive enhancement. This article will show you how.&lt;/p&gt;
    &lt;p&gt;(If you havenâ€™t heard of Grid Lanes yet, itâ€™s a new tool for layout that makes it easy to create masonry-style layouts in CSS alone. Read Introducing CSS Grid Lanes to learn all about it. And read New Safari developer tools provide insight into CSS Grid Lanes to learn about our new developer tooling that makes using Grid Lanes it even easier.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Current status of implementations&lt;/head&gt;
    &lt;p&gt;Where are browsers in the process of getting ready to ship support for Grid Lanes? Letâ€™s look at the progress thatâ€™s been made over the last seven years.&lt;/p&gt;
    &lt;head rend="h3"&gt;Firefox was first&lt;/head&gt;
    &lt;p&gt;Itâ€™s the team that was at Mozilla in 2019-2020 who wrote the original CSS Working Group Editorâ€™s Draft for Grid level 3, proposing concrete ideas for how masonry-style layouts would work in CSS. The feature shipped in Firefox Nightly in very early 2020. Some of the syntax has since changed, but under the hood, the way this new layout feature relies on and expands CSS Grid is basically the same, which means much of the heavy lifting for implementing it in the Gecko layout engine is underway.&lt;/p&gt;
    &lt;p&gt;Firefox does need to update their implementation (including updating to the new syntax and adding the new &lt;code&gt;flow-tolerance&lt;/code&gt; property, among other things) but if you want to try it out in Firefox today, you can enter &lt;code&gt;about:config&lt;/code&gt; in the URL bar, search for â€œmasonryâ€ and set the flag to true â€” or use Firefox Nightly where itâ€™s already on by default. (At the moment, remember to use the original &lt;code&gt;grid-template-*: masonry&lt;/code&gt; syntax to trigger this layout, instead of &lt;code&gt;display: grid-lanes&lt;/code&gt;.)&lt;/p&gt;
    &lt;head rend="h3"&gt;Safari picked up the pace&lt;/head&gt;
    &lt;p&gt;In 2022, Safariâ€™s WebKit team picked up where Mozilla left off in 2020, and started implementing the same original proposal for CSS Grid Layout Level 3. We also restarted the discussion inside the CSS Working Group, hoping to advance the original Editorâ€™s Draft to a point where it was mature enough that browsers could feel confident shipping.&lt;/p&gt;
    &lt;p&gt;The WebKit implementation was enabled on-by-default in Safari Technology Preview 163 in February 2023. Itâ€™s been updated continuously as the CSS specification has changed.&lt;/p&gt;
    &lt;p&gt;You can use Safari Technology Preview today to try out the official web standard, make demos using &lt;code&gt;display: grid-lanes&lt;/code&gt;, and learn how it works. Keep an eye on the Safari Release notes to see when it ships in Safari beta.&lt;/p&gt;
    &lt;head rend="h3"&gt;Chrome &amp;amp; Edge are on board, too&lt;/head&gt;
    &lt;p&gt;A variation for how masonry layouts could work in CSS landed in Chrome and Edge 140 behind a flag in July 2025. Rather than implementing the same syntax as Safari and Firefox, Chromium experimented with an alternative proposal. This drove debates in the CSSWG about how exactly this feature should work and what its syntax should be. With key syntax decisions now finalized, Chromium engineers at Edge are updating their implementation. Keep an eye on the Chrome Status issue for the latest news.&lt;/p&gt;
    &lt;p&gt;Bottom line â€” all the major browser engines are making progress. Now is a great time to learn how Grid Lanes works. And consider if, when and how you could start using it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Yes, you can start using it kinda soon-ish&lt;/head&gt;
    &lt;p&gt;Great developers are always mindful of users whose browsers donâ€™t have support. Not only does it take time for all browsers to ship new features, it takes time for all users to update. But this does not mean you have to wait multiple years before using new technologies. It just means you just have to be savvy.&lt;/p&gt;
    &lt;p&gt;You can progressively enhance your code to create masonry-style layouts, and support older browsers, both at the same time. How? As always, there are multiple options. Which choice is best for you depends on your use case, your team, and your code base. Letâ€™s go through three different approaches you could use:&lt;/p&gt;
    &lt;head rend="h3"&gt;Option 1: Polyfill â€” use a JavaScript library as a backup for Grid Lanes&lt;/head&gt;
    &lt;p&gt;One common trick for using a new CSS feature when itâ€™s still not available in all browsers is to use a polyfill â€” i.e.: use JavaScript to fill in the missing functionality.&lt;/p&gt;
    &lt;p&gt;Lucky for you, there are already tried and true JS libraries out in the world for creating masonry layouts. Masonry.js is a popular one. Perhaps you are using it now. You can keep using it by itself, and ignore Grid Lanes. Or you can switch to using the JS library as a polyfill.&lt;/p&gt;
    &lt;p&gt;The approach here is to go ahead and use CSS Grid Lanes to handle the layout in CSS alone â€” in browsers with support for Grid Lanes, even if thatâ€™s still only preview browsers. At the same time, architect your code to also work with a JavaScript library. Test in a browser without support for Grid Lanes to make sure the JS layout works.&lt;/p&gt;
    &lt;p&gt;The key is to structure your code with conditionals, so browsers with Grid Lanes support use CSS, while those without use JS. In your CSS, use Feature Queries to ensure the right CSS is used under the right conditions. In JavaScript, use &lt;code&gt;if&lt;/code&gt; statements.&lt;/p&gt;
    &lt;p&gt;For example, you can structure your CSS like this:&lt;/p&gt;
    &lt;code&gt;/* Native Grid Lanes for supporting browsers */
@supports (display: grid-lanes) {
  .grid {
    display: grid-lanes;
    grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
    gap: 1lh;
  }
}

/* Additional CSS needed only for browsers without Grid Lanes */
@supports not (display: grid-lanes) {
  .grid-item {
    margin: 1lh;
  }
  /* Perhaps also include a fallback layout in case JS doesn't run */
}
&lt;/code&gt;
    &lt;p&gt;Then in JavaScript, you can check to see whether or not Grid Lanes is supported. If not, load the file. And then start using Masonry JS (or another library), according to its documentation.&lt;/p&gt;
    &lt;code&gt;// Check if CSS Grid Lanes is NOT supported
if (!CSS.supports('display', 'grid-lanes')) {

    // Dynamically load masonry.js
    const script = document.createElement('script');
    script.src = 'https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js';
    script.onload = function() {

    // Use Masonry.js after the script loads
    new Masonry('.grid', {
        itemSelector: '.grid-item',
        columnWidth: 200,
    });
    };
    document.head.appendChild(script);
}
&lt;/code&gt;
    &lt;p&gt;Itâ€™s important to conditionally load the JS library only if the browser doesnâ€™t support Grid Lanes. Thereâ€™s no reason to have all users download and run the JS file when some percent donâ€™t need it. That percentage might be small today (even zero), but over time it will grow to 100%.&lt;/p&gt;
    &lt;p&gt;Save future you the task of having to change your code later. Structure it today so in a future when all users have Grid Lanes, no one has to do anything. Users get the best experience, even if no one on your team ever cleans out the old code.&lt;/p&gt;
    &lt;p&gt;With this technique, browsers with Grid Lanes support use pure CSS, while older browsers load and use JavaScript. By switching to using the JavaScript library a polyfill, not as the primary layout mechanism, increasing numbers of users will get the benefit of a faster and more robust layout sooner.&lt;/p&gt;
    &lt;p&gt;Of course, maybe this wonâ€™t work for your project. Maybe itâ€™s too complicated to architect your HTML and surrounding layout to work for both Grid Lanes and a masonry library at the same time. So what are the other options?&lt;/p&gt;
    &lt;head rend="h3"&gt;Option 2: Donâ€™t use Grid Lanes â€” use another layout in CSS instead&lt;/head&gt;
    &lt;p&gt;Of course, you might be screaming â€œitâ€™s too early to use Grid Lanes!â€ There is always the option of simply waiting to use a new technology. Perhaps another layout mode in CSS like Grid level 1, Flexbox or Multicolumn are good enough for your needs. And you can hold off using any tool for accomplishing a masonry-style layout until you feel more confident about Grid Lanes.&lt;/p&gt;
    &lt;p&gt;CSS Multicolumn is an interesting option that you might not be familiar with. It shipped in browsers decades ago (before Can I Use kept track). With origins that date back to the 1990s, Multicolumn suffered from the fate of most early CSS â€” the specification was not detailed enough, and that resulted in a lot of differences between browser implementations. This frustrated developers, resulting in Multicolumn falling out of favor.&lt;/p&gt;
    &lt;p&gt;In more recent years, Multicolumn level 1 has gotten a lot of love, and the specification now contains far more detail. This has helped browsers squash interop bugs. Thereâ€™s even a Multicolumn level 2 specification bringing new features in the future. Thereâ€™s still more work to do to create true interoperability, but itâ€™s worth reconsidering Multicolumn to see if can solve your use case today.&lt;/p&gt;
    &lt;p&gt;Multicolumn and Grid Lanes can result in very similar-looking layouts. They are fundamentally different, however, in the way content flows. These differences impact the order of what comes into focus when tabbing through content, readability / scanability, and user experience. So consider carefully.&lt;/p&gt;
    &lt;p&gt;Try out the demos we created to compare how Multicolumn and Grid Lanes work. Select different layouts from the dropdown menus, and turn on item numbers to emphasize the difference.&lt;/p&gt;
    &lt;head rend="h3"&gt;Option 3: Use Grid Lanes â€” along with a fallback layout in CSS&lt;/head&gt;
    &lt;p&gt;While â€œdonâ€™t use Grid Lanesâ€ is always an option, perhaps the best approach is to write your code so that Grid Lanes is used when supported, and another layout mode in CSS is used as the fallback. This avoids using JavaScript for layout, while still delivering the newer layout to the users who do have support.&lt;/p&gt;
    &lt;p&gt;For example, letâ€™s imagine we want to use Grid Lanes, and leverage CSS Grid (level 1) when Grid Lanes isnâ€™t supported. To make the original Grid layout work, can use CSS to force all the items be the same aspect ratio by cropping images and truncating text.&lt;/p&gt;
    &lt;p&gt;To do this, we can apply layout to the container using the &lt;code&gt;display&lt;/code&gt; property â€” twice. First weâ€™ll declare &lt;code&gt;display: grid&lt;/code&gt;, then weâ€™ll immediately declare &lt;code&gt;display: grid-lanes&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;.grid-container {
  display: grid;
  display: grid-lanes; /* will override grid in browsers that support */
  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
  gap: 1lh;
}
&lt;/code&gt;
    &lt;p&gt;In browsers that support Grid Lanes, the second declaration will override the first. The &lt;code&gt;display: grid&lt;/code&gt; rule will be ignored. And the layout will use Grid Lanes, resulting in a layout that packs content of different aspect ratios into a set of columns.&lt;/p&gt;
    &lt;p&gt;In browsers that do not support Grid Lanes, the browser will ignore the second declaration. It sees &lt;code&gt;display: grid-lanes&lt;/code&gt; and goes â€œwhat? Thatâ€™s not a thing. You must have misspelled something. Ignore!â€ This leaves &lt;code&gt;grid&lt;/code&gt; as the layout thatâ€™s applied. The content will be laid out into clear rows as well as columns.&lt;/p&gt;
    &lt;p&gt;This is a tried and true technique thatâ€™s been used by developers for over two decades â€” relying on the fact that CSS just ignores anything it doesnâ€™t understand. It does not throw an error message. It does not stop parsing. It just ignores that line of code and moves along.&lt;/p&gt;
    &lt;p&gt;We can also use a Feature Query to write code that only gets applied in browsers without support for Grid Lanes. Letâ€™s use the &lt;code&gt;aspect-ratio&lt;/code&gt; property to force all images into the same aspect ratio. And use &lt;code&gt;object-fit: cover&lt;/code&gt; to crop those images to fit in the box, instead of letting them be squished.&lt;/p&gt;
    &lt;code&gt;/* Additional CSS for browsers without Grid Lanes support */
@supports not (display: grid-lanes) {
  .grid-item {
    img {
      aspect-ratio: 1; /* resize every image into a square */
      object-fit: cover; /* crop, don't squish the image */
    }
    h3 {
      white-space: nowrap; /* don't wrap the headline */
      overflow: hidden; /* crop the extra */
      text-overflow: ellipsis; /* add an ellipsis if it overflows */
    }
    p {
      display: -webkit-box; /* current practice in all browsers */
      -webkit-box-orient: vertical;
      -webkit-line-clamp: 3; /* clamps to this many lines of text */
      overflow: hidden;
    }
  }
}
&lt;/code&gt;
    &lt;p&gt;We can force our headline to not wrap with &lt;code&gt;white-space: nowrap&lt;/code&gt;. Once the headline is on one line, we can hide whatever doesnâ€™t fit with &lt;code&gt;overflow: hidden&lt;/code&gt;. Then, &lt;code&gt;text-overflow: ellipsis&lt;/code&gt; adds â€œâ€¦â€ to the end of whatâ€™s visible.&lt;/p&gt;
    &lt;p&gt;When we want to truncate multi-line text to a specific number of lines, we can use the &lt;code&gt;-webkit-line-clamp&lt;/code&gt; technique. While originally invented by the WebKit team long ago when prefixes were the best practice for browsers rolling out new ideas, today &lt;code&gt;-webkit-box&lt;/code&gt;, &lt;code&gt;-webkit-box-orient&lt;/code&gt; and &lt;code&gt;-webkit-line-clamp&lt;/code&gt; are supported by all browsers. (No browser has shipped a replacement yet because a complete web standard for defining such a tool is still under debate.)&lt;/p&gt;
    &lt;p&gt;This approach results in a masonry-style waterfall layout being delivered to the browsers that support Grid Lanes, while a more traditional layout of equal-sized boxes are delivered using CSS Grid level 1 to browsers that donâ€™t yet support Grid Lanes.&lt;/p&gt;
    &lt;head rend="h3"&gt;Itâ€™s up to you&lt;/head&gt;
    &lt;p&gt;Itâ€™s totally up to you how you want to handle the fallback for a lack of support for Grid Lanes, but you definitely have options. This is one of the benefits of writing CSS, and not just using a 3rd-party utility framework that abstracts all the flexibility away. Progressive enhancement techniques bring the future into the present, and let you start using Grid Lanes far sooner!&lt;/p&gt;
    &lt;head rend="h2"&gt;Learn more about Grid Lanes&lt;/head&gt;
    &lt;p&gt;This is our third article in a series about Grid Lanes. The first introduces CSS Grid Lanes, explaining what it is and how to use it (and yes, it can be used â€œin the other directionâ€). The second article shows off our new developer tools and explains why they are particularly helpful for setting flow tolerance. Also, check out our demos in Safari Technology Preview. And be sure to come back to webkit.org soon for more articles about Grid Lanes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://webkit.org/blog/17758/when-will-css-grid-lanes-arrive-how-long-until-we-can-use-it/"/><published>2026-01-31T23:02:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46842178</id><title>Cells use 'bioelectricity' to coordinate and make group decisions</title><updated>2026-02-01T05:40:56.721162+00:00</updated><content>&lt;doc fingerprint="3e4800171a9609d9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Cells Use â€˜Bioelectricityâ€™ To Coordinate and Make Group Decisions&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Weâ€™re used to thinking of the brain as an electric organ. The rest of the body? Not so much. But it would be a mistake to dismiss your other tissues as dumb hunks of electrically inert flesh. Even the protective layers of cells that compose your skin and line your organs use electrical signals to make decisions, according to recent research.&lt;/p&gt;
    &lt;p&gt;Results published in Nature show that cells use bioelectricity to coordinate a complex collective behavior called extrusion, a vital process that ejects sick or struggling individual cells from tissue to maintain health and keep growth in check. Merciless as it might seem, extrusion helps keep you alive. Itâ€™s vital for the health of protective epithelial tissues, and when it goes wrong, it can contribute to disease, including cancer and asthma. Until now, itâ€™s been unclear how cells were singled out for this process.&lt;/p&gt;
    &lt;p&gt;According to the new results, as epithelial tissue grows, cells are packed more tightly together, which increases the electrical current flowing through each cellâ€™s membrane. A weak, old, or energy-starved cell will struggle to compensate, triggering a response that sends water rushing out of the cell, shriveling it up and marking it for death. In this way, electricity acts like a health checkup for the tissue and guides the pruning process.&lt;/p&gt;
    &lt;p&gt;â€œThis is a very interesting discovery â€” finding that bioelectricity is the earliest event during this cell-extrusion process,â€ said the geneticist GuangJun Zhang of Purdue University, who studies bioelectrical signals in zebra fish development and wasnâ€™t involved in the study. â€œItâ€™s a good example of how a widening electronic-signaling perspective can be used in fundamental biology.â€&lt;/p&gt;
    &lt;p&gt;The new discovery adds to the growing assortment of bioelectrical phenomena that scientists have discovered playing out beyond the nervous system, from bacteria swapping signals within a biofilm to cells following electric fields during embryonic development. Electricity increasingly appears to be one of biologyâ€™s go-to tools for coordinating and exchanging information between all kinds of cells.&lt;/p&gt;
    &lt;p&gt;â€œPeople just kind of relegated [bioelectricity] to â€˜This is just neurons.â€™ No â€” itâ€™s all of our bodies,â€ said study author Jody Rosenblatt, an epithelial cell biologist at Kingâ€™s College London and the Francis Crick Institute. â€œThere are electrical currents going through your body all the time, and theyâ€™re doing things.â€&lt;/p&gt;
    &lt;head rend="h2"&gt;Lifeâ€™s Spark&lt;/head&gt;
    &lt;p&gt;Itâ€™s no coincidence that Frankensteinâ€™s monster sprang to life with a spark. In the late 18th century, just a few decades before Mary Shelley wrote her science fiction masterpiece, the Italian surgeon Luigi Galvani jolted the scientific community with experiments that used metal and electricity to compel disembodied frog legs to kick. He became convinced that there was an â€œanimal electricityâ€ running through life.&lt;/p&gt;
    &lt;p&gt;Public Domain; ETH-Bibliothek Zurich / Science Source&lt;/p&gt;
    &lt;p&gt;While Galvani was later proven wrong in the details, he wasnâ€™t totally off. Virtually every cell on every branch of the tree of life expends a hefty chunk of its energy budget â€” in some cells, more than half â€” on maintaining a voltage across its membrane. The voltage difference that results, called the membrane potential, stores potential energy that can be released later. Itâ€™s like the pressure behind a dam: Gravity tugs water downhill, and dams store energy by holding water at the top of a hill. Like gravity, the electrochemical force tugs charges â€œdownhillâ€ â€” positive charges stream toward negative charges and vice versa in electrical currents. Blocking that flow, for example with a cell membrane, stores up electrical potential energy.&lt;/p&gt;
    &lt;p&gt;The electric currents that pour from our wall sockets are streams of electrons. In cells, â€œitâ€™s quite similar, but not exactly the same,â€ said Elias Barriga, who studies tissue biophysics at the Dresden University of Technology. â€œWe are fueled by ions.â€&lt;/p&gt;
    &lt;p&gt;Ions are atoms or molecules that carry charge because of extra or missing electrons, which give them negative or positive charges, respectively. They can enter and exit cells only through specialized protein channels and pumps. Just as hydroelectric plants can use surplus energy to pump water back up into the reservoir for later use, cells use their chemical energy to pump ions â€œuphillâ€ against the electric flow. By controlling the natural current and letting positive or negative charge build up on either side of their membranes, cells maintain their membrane potential. And if this energy is used or leaks away, cells can replenish it by expending more of their chemical energy.&lt;/p&gt;
    &lt;p&gt;â€œYou generate a potential: whatâ€™s inside versus whatâ€™s outside, a different concentration of ions,â€ Barriga said. â€œThat is the source of bioelectricity.â€&lt;/p&gt;
    &lt;p&gt;Neurons make use of this biological electricity to share information. By releasing messenger molecules called neurotransmitters that open and close ion channels, neurons can nudge their neighborsâ€™ membrane potentials up or down. If these chemical nudges push a neuronâ€™s membrane potential beyond a threshold, the cell â€œspikesâ€ â€” voltage-sensitive ion channels throw open the floodgates for positive sodium ions, which rush into the cell and cause a rapid voltage swing that ripples along the neuronâ€™s length. When that signal reaches the interface between neurons, voltage-sensitive channels open wide, triggering the release of neurotransmitters to more neurons downstream.&lt;/p&gt;
    &lt;p&gt;Muscle contraction also kicks off with a voltage spike; neurons send electrical signals streaming into muscle fibers, triggering contractions. This is why Galvaniâ€™s electrified frog legs twitched, and why a jolt of electricity can jump-start a stopped heart. (Specialized cells in the heart use electricity to set the pace of its regular contractions.) While all tissues maintain membrane potentials, researchers donâ€™t really know what they do. Compared to electrophysiology, which often focuses on electricity in the brain and heart, the field of bioelectricity â€” a grab-bag term for electrical activity everywhere else in organisms â€” has lagged behind, Barriga said.&lt;/p&gt;
    &lt;p&gt;â€œI think that at some point it got stuck,â€ he said. â€œBut now I can tell you that that is coming back like crazy.â€&lt;/p&gt;
    &lt;head rend="h2"&gt;A Shocking Discovery&lt;/head&gt;
    &lt;p&gt;The epithelial tissues that make up skin and line organs, blood vessels, and body cavities quietly burn about 25% of their available energy to maintain membrane voltages between minus 30 and minus 50 millivolts. But researchers interested in these tissues typically study mechanical forces, chemical signaling, and gene expression â€” not currents and voltage, Rosenblatt said.&lt;/p&gt;
    &lt;p&gt;Until recently, that included her. Rosenblatt has spent 25 years piecing together the details of epithelial extrusion, a process that keeps tissue growth in check. Because epithelial cells grow quickly, even a slight mismatch between the rates of cell division and cell death can quickly add up to a tumor or injury. Runaway replication can grow into cancer, while overzealous culling â€” as can happen in asthma â€” compromises the integrity of tissues. Itâ€™s important to get the balance right.&lt;/p&gt;
    &lt;p&gt;Around 14 years ago, Rosenblatt and colleagues discovered that overcrowded epithelial cells are popped up and out of the tissue alive â€” extruded â€” to maintain that tissue balance as new cells grow. That raised a question: How does tissue â€œchooseâ€ which living cells to expel?&lt;/p&gt;
    &lt;p&gt;In earlier work, Rosenblattâ€™s team watched as some cells dumped their water and shriveled up like raisins before being extruded; indeed, this shrinkage seemed to kick off the process. But the researchers didnâ€™t know what caused the cells to shrink in the first place. They didnâ€™t work on bioelectricity and were unaware of any effect it might have.&lt;/p&gt;
    &lt;p&gt;Antonio Tabernero&lt;/p&gt;
    &lt;p&gt;In further experiments, they were able to prevent the cells from shrinking by blocking a pressure-sensitive ion channel in the cell membrane that opens when squeezed. They decided to see if blocking other ion channels might interfere with extrusion too.&lt;/p&gt;
    &lt;p&gt;â€œWe got so many hits, we were just like: Jesus, this is crazy,â€ Rosenblatt recalled. One of those hits was a voltage-gated potassium channel, like those that open up during a neuronâ€™s voltage spike. It struck Rosenblatt as â€œweirdâ€ enough to follow up on. Using special dyes that reveal the voltage across cell membranes, the scientists found that epithelial cells destined for extrusion â€” and only those cells â€” lose their membrane potential about five minutes before shrinking and being extruded. The result was clear: Extrusion kicks off with an electrical signal.&lt;/p&gt;
    &lt;p&gt;Instead of sending neurotransmitters back and forth like neurons, densely packed epithelial cells squeeze each other. As the tissue gets more crowded, the squeezing intensifies. This opens pressure-sensitive ion channels, which allow positive sodium ions to leak across the squashed cellsâ€™ membranes and into the cell.&lt;/p&gt;
    &lt;p&gt;Faced with this challenge, a healthy cell will use its chemical energy to activate pumps to push sodium back out and restore its normal voltage. But stressed or unhealthy cells without energy to spare canâ€™t keep up. Their membrane voltage falters, throwing open those â€œweirdâ€ voltage-sensitive channels. When that happens, water pours out of the cell in a â€œlightningâ€ flash clearly visible in microscope images, Rosenblatt said. Once a cell loses 17% or more of its volume, it is extruded. Her working hypothesis is that a biochemical cascade set off by the shrinkage contracts motor proteins, which mechanically extrude the cell.&lt;/p&gt;
    &lt;p&gt;In this way, bioelectrical flow across cell membranes lets tissues test which cells are the least healthy and mark them for extrusion. â€œTheyâ€™re always pushing against each other and bullying each other. And what theyâ€™re doing is probing each other for which oneâ€™s the weakest link,â€ Rosenblatt said. â€œItâ€™s a community effect.â€&lt;/p&gt;
    &lt;head rend="h2"&gt;Evolution as Electrician&lt;/head&gt;
    &lt;p&gt;At the University of California, San Diego, the biophysicist GÃ¼rol SÃ¼el studies electricity in bacterial biofilms, which are collectives composed of single-celled bacteria that can also survive independently. The signaling that Rosenblatt and her team described in human tissues has several things in common with electrical mechanisms SÃ¼el has described in microbes â€” and which appear again and again across the tree of life.&lt;/p&gt;
    &lt;p&gt;â€œItâ€™s a very elegant study, very nice results,â€ he said of the new research. â€œAnd conceptually, it makes sense.â€&lt;/p&gt;
    &lt;p&gt;Suel Lab&lt;/p&gt;
    &lt;p&gt;Electricity increasingly appears to be one of evolutionâ€™s go-to solutions for integrating multiple streams of information. Epithelial tissues use it to keep tabs on crowding. Neurons compile input signals from multiple sources into a spiking output. A Venus flytrap snaps shut when sensory hairs with touch-sensitive ion channels react to prey. These channels are tuned to trigger a voltage spike and tell the trap to close only if stimulated multiple times in rapid succession.&lt;/p&gt;
    &lt;p&gt;â€œThe membrane potential is so fundamental, and it is very fast,â€ SÃ¼el said. While switching genes on and off or upping protein production could take minutes or hours, a membrane potential can flip in fractions of a second. â€œIt tells you, in one glance almost, about the state of the cell,â€ he added.&lt;/p&gt;
    &lt;p&gt;Ten years ago, SÃ¼el and his team showed that microbes in biofilms can spike their membrane potentials to communicate, just as neurons do. Since then, theyâ€™ve shown that biofilms use electricity to coordinate tasks, prevent runaway growth, and invite free-swimming bacteria to join the collective. Bioelectricity can even help them avoid falling victim to the tragedy of the commons: Two biofilms sharing scarce food can send electrical signals to each other to take turns eating.&lt;/p&gt;
    &lt;p&gt;Multicellular animals, too, use electrical signaling to organize themselves. Zhang, of Purdue, studies bioelectrical signaling in zebra fish, which develop striking extra-long tails when a certain ion channel is mutated. This suggests that electrical signaling somehow tells tissues in a developing embryo how long to grow. Michael Levin, a researcher at Tufts University, has blocked cell channels to manipulate the membrane potentials of developing worm embryos, causing genetically identical worms to develop different body plans. And last year, Barriga and his colleagues showed that frog embryos generate natural electric fields that guide the migration of specific stem cells to their proper locations in the developing embryo.&lt;/p&gt;
    &lt;p&gt;The failure of bioelectric processes might be an overlooked cause of disease. Cancerous cells tend to have different membrane potentials than healthy ones, and Levin has argued that some cancers might result from a breakdown in multicellularity that happens when cells can no longer use electricity to coordinate. For example, maybe they can no longer communicate the message â€œIâ€™m struggling and should be extruded,â€ and the result is the uncontrolled growth and, ultimately, a tumor.&lt;/p&gt;
    &lt;p&gt;SÃ¼el is convinced that bioelectricity is as old as life itself. Indeed, an electric current drives the molecular turbines that synthesize lifeâ€™s universal energy currency, ATP, in every cell alive today. One leading origin-of-life scenario places the beginning at deep-sea hydrothermal vents. There, natural currents of positively charged protons could have served as a kind of primordial membrane potential and powered prebiotic chemical reactions. But whether life started with such a spark or not, bioelectricityâ€™s ubiquity suggests it has deep evolutionary roots that weâ€™re just beginning to unearth.&lt;/p&gt;
    &lt;p&gt;â€œThere are a lot of interesting things that cells are probably doing, just like this paper showed, that we just donâ€™t know yet,â€ SÃ¼el said. â€œWe have not uncovered even half of this. â€¦ Thereâ€™s a lot of opportunity for discovery.â€&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.quantamagazine.org/cells-use-bioelectricity-to-coordinate-and-make-group-decisions-20260112/"/><published>2026-02-01T00:00:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46842586</id><title>Sparse File LRU Cache</title><updated>2026-02-01T05:40:56.547340+00:00</updated><content>&lt;doc fingerprint="ac3ae86f27b34e41"&gt;
  &lt;main&gt;
    &lt;p&gt;An interesting file system feature that I came across a few years ago is sparse files. In short, many file systems allow you to create a logical file with "empty" (fully zeroed) blocks that are not physically backed until they get written to. Partially copying from ArchWiki, the behavior looks like this:&lt;/p&gt;
    &lt;p&gt;The file starts at 0 physical bytes on disk despite being logically 512MB. Then, after writing some non-zero bytes at a 16MB offset, it physically allocates a single block (4KB). The file system is maintaining metadata on which blocks of the file are physically represented on disk and which ones are not. To normal readers of the file, it's transparent -- the sparsity is managed completely by the file system.&lt;/p&gt;
    &lt;p&gt;At Amplitude, we found a cool use case for sparse files. All of the data is stored durably in cold storage (Amazon S3) in a columnar data format used for analytics queries. But it's inefficient and costly to fetch it from S3 every time, so the data gets cached on local NVMe SSDs (e.g. from the r7gd instance class). These local SSDs are more than ten times as expensive as cold storage, though, so you need a good strategy for deciding how and what to cache. To understand why sparse files are a good option for this, let's revisit columnar data formats briefly.&lt;/p&gt;
    &lt;p&gt;One of the observations about analytics queries that makes columnar data formats so effective is the fact that usually only a very small subset of columns (5-10 out of potentially thousands) are used on any particular query (and, to some extent, even across many queries). The data being stored in a columnar fashion means that each of these columns is a contiguous range inside the file, making it much faster to read. The contiguous ranges are also important in the context of our local caching -- we're not trying to pick out small pieces scattered across the file.&lt;/p&gt;
    &lt;p&gt;Setting sparse files aside for a moment, we originally had two different approaches for doing this caching:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The most naive strategy is caching entire files from S3. This is simple and requires minimal metadata to manage, but has the obvious downside of wasting a lot of disk space on the SSDs by storing the columns that are rarely or never used.&lt;/item&gt;
      &lt;item&gt;Another option is caching different columns as individual files on disk. This somewhat solves the wasted disk space issue, but now explodes the number of files, which requires a substantial amount of file system metadata. It also struggles with small columns, which are rounded up to the file system block size. With hundreds of thousands of customers of varying sizes, it's inevitable that the vast majority of files/columns are small.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At this point, it's pretty clear how sparse files give you an option in between these two. We imagine that we're caching entire files, except that the files are sparse, where only the columns that are used (more specifically, logical blocks that contain those columns) are physically present. This is simpler for a consumer to read and utilizes the disk better -- less file system metadata, and small columns are consolidated into file system blocks (as a bonus, this reduces S3 GETs as well). Similar to the latter approach above, consumers must declare the columns they need to the cache before reading them.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;Managing sparse file block metadata in RocksDB.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This system requires us to manage metadata on which columns are cached, which we used a local RocksDB instance for. More specifically, we track metadata on logical blocks of these sparse files: which ones are present locally, and when they were last read. Using this, we approximate an LRU policy for invalidating data when the disk fills up. As an important implementation detail, the logical blocks are variable-sized with a few smaller blocks at the head (still larger than file system blocks) and then larger blocks throughout the rest, which takes advantage of the fact that the file format has a metadata header (similar to Parquet) that always needs to be read to know how the columns are laid out.&lt;/p&gt;
    &lt;p&gt;This sparse file LRU cache improved many aspects of the query system simultaneously: fewer S3 GETs, less file system metadata, less file system block overhead, and fewer IOPS to manage the cache. It's rare that a feature that lives as low-level as the file system has such a prominent impact on system design, so when it happens, it's pretty neat.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://ternarysearch.blogspot.com/2026/01/sparse-file-lru-cache.html"/><published>2026-02-01T01:00:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46842603</id><title>List animals until failure</title><updated>2026-02-01T05:40:56.475850+00:00</updated><content>&lt;doc fingerprint="ca67e2b6a5f5fc5"&gt;
  &lt;main&gt;
    &lt;p&gt;Animals must have Wikipedia articles.&lt;/p&gt;
    &lt;p&gt;You have limited time, but get more time for each animal listed. When the timer runs out, that's game over.&lt;/p&gt;
    &lt;p&gt;No overlapping terms. For example, if you list â€œbearâ€ and â€œpolar bearâ€, you get no point (or time bonus) for the latter. But you can still get a point for a second kind of bear. Order doesn't matter.&lt;/p&gt;
    &lt;p&gt;Ignore the extraneous visuals. Focus on naming animals.&lt;/p&gt;
    &lt;p&gt;Score: 0&lt;/p&gt;
    &lt;p&gt;By Vivian Rose.&lt;/p&gt;
    &lt;p&gt;Uses Wikipedia and Wikidata, plus a lot of hand-tuning. No LLMs involved.&lt;/p&gt;
    &lt;p&gt;Contact me with bug reports, questions, suggestions, and praise.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://rose.systems/animalist/"/><published>2026-02-01T01:03:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46843037</id><title>Apple-1 Computer Prototype Board #0 sold for $2.75M</title><updated>2026-02-01T05:40:56.397114+00:00</updated><content/><link href="https://www.rrauction.com/auctions/lot-detail/350902407346003-apple-1-computer-prototype-board-0-the-celebration-board-representing-the-earliest-known-fiberglass-apple-1-prototype/"/><published>2026-02-01T02:25:26+00:00</published></entry></feed>