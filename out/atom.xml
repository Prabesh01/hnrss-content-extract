<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-27T11:09:37.057859+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46061682</id><title>S&amp;box is now an open source game engine</title><updated>2025-11-27T11:09:43.740587+00:00</updated><link href="https://sbox.game/news/update-25-11-26"/><published>2025-11-26T19:58:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46062504</id><title>The EU made Apple adopt new Wi-Fi standards, and now Android can support AirDrop</title><updated>2025-11-27T11:09:43.479729+00:00</updated><content>&lt;doc fingerprint="a786e58451353bc8"&gt;
  &lt;main&gt;
    &lt;p&gt;Last year, Apple finally added support for Rich Communications Services (RCS) texting to its platforms, improving consistency, reliability, and security when exchanging green-bubble texts between the competing iPhone and Android ecosystems. Today, Google is announcing another small step forward in interoperability, pointing to a slightly less annoying future for friend groups or households where not everyone owns an iPhone.&lt;/p&gt;
    &lt;p&gt;Google has updated Android‚Äôs Quick Share feature to support Apple‚Äôs AirDrop, which allows users of Apple devices to share files directly using a local peer-to-peer Wi-Fi connection. Apple devices with AirDrop enabled and set to ‚Äúeveryone for 10 minutes‚Äù mode will show up in the Quick Share device list just like another Android phone would, and Android devices that support this new Quick Share version will also show up in the AirDrop menu.&lt;/p&gt;
    &lt;p&gt;Google will only support this feature on the Pixel 10 series, at least to start. The company is ‚Äúlooking forward to improving the experience and expanding it to more Android devices,‚Äù but it didn‚Äôt announce anything about a timeline or any hardware or software requirements. Quick Share also won‚Äôt work with AirDrop devices working in the default ‚Äúcontacts only‚Äù mode, though Google ‚Äú[welcomes] the opportunity to work with Apple to enable ‚ÄòContacts Only‚Äô mode in the future.‚Äù (Reading between the lines: Google and Apple are not currently working together to enable this, and Google confirmed to The Verge that Apple hadn‚Äôt been involved in this at all.)&lt;/p&gt;
    &lt;p&gt;Like AirDrop, Google notes that files shared via Quick Share are transferred directly between devices, without being sent to either company‚Äôs servers first.&lt;/p&gt;
    &lt;p&gt;Google shared a little more information in a separate post about Quick Share‚Äôs security, crediting Android‚Äôs use of the memory-safe Rust programming language with making secure file sharing between platforms possible.&lt;/p&gt;
    &lt;p&gt;‚ÄúIts compiler enforces strict ownership and borrowing rules at compile time, which guarantees memory safety,‚Äù writes Google VP of Platforms Security and Privacy Dave Kleidermacher. ‚ÄúRust removes entire classes of memory-related bugs. This means our implementation is inherently resilient against attackers attempting to use maliciously crafted data packets to exploit memory errors.‚Äù&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/gadgets/2025/11/the-eu-made-apple-adopt-new-wi-fi-standards-and-now-android-can-support-airdrop/"/><published>2025-11-26T21:25:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46063072</id><title>Bring bathroom doors back to hotels</title><updated>2025-11-27T11:09:43.330454+00:00</updated><content>&lt;doc fingerprint="4765d15dde61f49c"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôm done. I‚Äôm done arriving at hotels and discovering that they have removed the bathroom door. Something that should be as standard as having a bed, has been sacrificed in the name of ‚Äúaesthetic‚Äù.&lt;/p&gt;
    &lt;p&gt;I get it, you can save on material costs and make the room feel bigger, but what about my dignity??? I can‚Äôt save that when you don‚Äôt include a bathroom door.&lt;/p&gt;
    &lt;p&gt;It‚Äôs why I‚Äôve built this website, where I compiled hotels that are guaranteed to have bathroom doors, and hotels that need to work on privacy.&lt;/p&gt;
    &lt;p&gt;I‚Äôve emailed hundreds of hotels and I asked them two things: do your doors close all the way, and are they made of glass? Everyone that says yes to their doors closing, and no to being made of glass has been sorted by price range and city for you to easily find places to stay that are guaranteed to have a bathroom door.&lt;/p&gt;
    &lt;p&gt;Quickly check to see if the hotel you‚Äôre thinking of booking has been reported as lacking in doors by a previous guest.&lt;/p&gt;
    &lt;p&gt;Finally, this passion project could not exist without people submitting hotels without bathroom doors for public shaming. If you‚Äôve stayed at a doorless hotel send me an email with the hotel name to bringbackdoors@gmail.com, or send me a DM on Instagram with the hotel name and a photo of the doorless setup to be publicly posted.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs name and shame these hotels to protect the dignity of future travelers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://bringbackdoors.com/"/><published>2025-11-26T22:26:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46063272</id><title>Running Unsupported iOS on Deprecated Devices</title><updated>2025-11-27T11:09:43.236229+00:00</updated><content>&lt;doc fingerprint="b6495d34246e3b64"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Running unsupported iOS on deprecated devices&lt;/head&gt;
    &lt;p&gt;Earlier this year I demoed iOS 6 running on an iPod touch 3 - a device that Apple never gave iOS 6 to, making iOS 5.1.1 the latest build it can run&lt;/p&gt;
    &lt;p&gt;A few months later I also released a script that generates an iOS 6 restore image installable on that iPod touch model&lt;/p&gt;
    &lt;p&gt;This article describes technical details behind this work. Certain proficiency in iOS internals is assumed&lt;/p&gt;
    &lt;head rend="h2"&gt;I'll show you what iOS is made of&lt;/head&gt;
    &lt;p&gt;First of all, let's recap what software components iOS consists of:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;iBoot - the bootloader. Has 4 different types for different scenarios - iBSS, iBEC, LLB and iBoot&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Kernelcache - the OS kernel + kernel extensions (drivers) built into a single binary blob&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DeviceTree - structured list of hardware used by specific device model + some parameters that specify software behavior. The copy included in an IPSW is more of a template that is heavily modified by iBoot before jumping into kernel&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Userspace filesystem - tiny restore ramdisk used purely for OS installation or the actual root filesystem of iOS installed persistently&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Various firmwares for coprocessors, be they internal or external to the main SoC - like, baseband, Wi-Fi, Bluetooth, multitouch and etc.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;iPhone 3GS tests&lt;/head&gt;
    &lt;p&gt;iPhone 3GS was released the same year as iPod touch 3 (2009), and has a very similar hardware (S5L8920X SoC vs. S5L8922X). But the most important part is that it actually got iOS 6 officially&lt;/p&gt;
    &lt;p&gt;Before doing anything on the iPod I decided to try to boot iOS 6.0 with iOS 5.1.1 iBoot &amp;amp; DeviceTree on the iPhone and see what's gonna break and how&lt;/p&gt;
    &lt;head rend="h2"&gt;DeviceTree&lt;/head&gt;
    &lt;p&gt;The most broken thing was DeviceTree - iOS 6 added a lot of new nodes and properties. To fix it in automated manner I wrote a stupid Python script that decodes and computes a diff between 2 DeviceTrees. Such diff can also be applied to another DeviceTree&lt;/p&gt;
    &lt;p&gt;The script is available in the SundanceInH2A repo&lt;/p&gt;
    &lt;p&gt;As I mentioned above a lot of things in a DeviceTree is filled by iBoot at runtime. One of such new properties is &lt;code&gt;nvram-proxy-data&lt;/code&gt; in &lt;code&gt;chosen&lt;/code&gt; node&lt;/p&gt;
    &lt;p&gt;The property must contain a raw NVRAM dump - leaving it empty will make kernel get stuck somewhere very early&lt;/p&gt;
    &lt;p&gt;For iPod touch 3 I also had to clean-up the diff out of iPhone-specific things before applying it to iPod's 5.1.1 DeviceTree&lt;/p&gt;
    &lt;head rend="h2"&gt;iBoot&lt;/head&gt;
    &lt;p&gt;iBoot didn't require any major changes in this case. Just typical Image3 signature check patch, boot-args injection and &lt;code&gt;debug-enabled&lt;/code&gt; patch so kernel is going to actually respect AMFI boot-args&lt;/p&gt;
    &lt;p&gt;One important thing is to actually populate &lt;code&gt;nvram-proxy-data&lt;/code&gt; dynamically, at least for normal boots (aka non-restore). Restore boot will be fine with some random NVRAM hardcoded into DeviceTree, but normal one will overwrite your actual NVRAM with the random one if it decides to sync it at some point&lt;/p&gt;
    &lt;p&gt;I do it by replacing a call to &lt;code&gt;UpdateDeviceTree()&lt;/code&gt; with my own little function that calls the real &lt;code&gt;UpdateDeviceTree()&lt;/code&gt;, but also populates actual &lt;code&gt;nvram-proxy-data&lt;/code&gt; and &lt;code&gt;random-seed&lt;/code&gt; (this one shouldn't be of any importance)&lt;/p&gt;
    &lt;p&gt;For boot-args I always add &lt;code&gt;amfi=0xff&lt;/code&gt; to disable code-signing, but that's pretty cannonical as well&lt;/p&gt;
    &lt;p&gt;Please note that other iBoot+kernel combos might require more changes - if you ever try something and it doesn't work, I recommend looking into DeviceTree differences (both the initial template and how iBoot fills it) and also &lt;code&gt;boot_args&lt;/code&gt; structure iBoot passes to kernel (not to be confused with boot-args string, the &lt;code&gt;boot_args&lt;/code&gt; structure is a different thing)&lt;/p&gt;
    &lt;head rend="h2"&gt;Kernelcache&lt;/head&gt;
    &lt;p&gt;The most complex part. iPod touch 3 never got iOS 6 officialy, yes, but it was rumored that initially it was meant to have it, but Apple's marketing team said no. Either way, almost every internal iOS 6 build got both standalone S5L8922X kernel and even standalone kexts (including ones specific to iPod touch 3)&lt;/p&gt;
    &lt;p&gt;The question is how to load them all simultaneously. My initial idea was to do it just as older Mac OS X could do - load all kexts dynamically on bootloader level. Long story short, my strategy was the following:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;In iBoot context, load all kexts from filesystem - binary itself + Info.plist&lt;/item&gt;
      &lt;item&gt;Lay them out in memory and add corresponding entries to &lt;code&gt;chosen/memory-map&lt;/code&gt;node of DeviceTree&lt;/item&gt;
      &lt;item&gt;Boot standalone kernel which will then pick them up and load&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The sad outcome:&lt;/p&gt;
    &lt;code&gt;panic(cpu 0 caller 0x802e5223): "kern_return_t kxld_link_file(KXLDContext *, u_char *, u_long, const char *, void *, KXLDDependency *, u_int, u_char **, kxld_addr_t *) (com.apple.kec.corecrypto) called in kernel without kxld support"
&lt;/code&gt;
    &lt;p&gt;The kernel has all the code to pick them up, but not to actually link...&lt;/p&gt;
    &lt;head rend="h3"&gt;Glueing a prelinked kernelcache&lt;/head&gt;
    &lt;p&gt;So creating a legit kernelcache is the only way after all. I was already imagining all the horrors of writing software to parse and apply &lt;code&gt;LINKEDIT&lt;/code&gt; and etc., but then it occured to me! Mac OS X (before Apple Silicon) was generating such kernelcaches somehow! What if we use that logic to build our iOS kernelcache?&lt;/p&gt;
    &lt;code&gt;kcgen \
    -c output.bin \
    $(cat n18.10A403.kextlist | sed 's/^/--bundle-id /') \
    -kernel kernels_kexts_10A63970m/mach.development.s5l8922x \
    -arch armv7 \
    -all-personalities \
    -strip-symbols \
    -uncompressed \
    -- \
    kernels_kexts_10A63970m/Extensions
&lt;/code&gt;
    &lt;p&gt;I used &lt;code&gt;/usr/local/bin/kcgen&lt;/code&gt; from internal Sierra build (can be found online as "Phoenix A1708.dmg"), but it seems that even latest macOS &lt;code&gt;kextcache&lt;/code&gt; can do it (included by default)&lt;/p&gt;
    &lt;p&gt;Here is a breakdown of the options:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;-c output.bin&lt;/code&gt;- output file to write resulting kernelcache to&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;$(cat n18.10A403.kextlist | sed 's/^/--bundle-id /')&lt;/code&gt;- this weird expression appends&lt;code&gt;--bundle-id&lt;/code&gt;to every line from the file at&lt;code&gt;n18.10A403.kextlist&lt;/code&gt;. This is to specify which kexts we'd like to include. How I created such list is described below&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-arch armv7&lt;/code&gt;- obviously only build armv7 slice&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-all-personalities&lt;/code&gt;- very important flag that prevents irrelevant IOKit personalities to be stripped. "Irrelevant" as in "irrelevant to current machine", meaning everything relevant to iPod touch 3 is going to be stripped&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-strip-symbols&lt;/code&gt;- strips unnecessary symbols. This flag can be omitted theoretically, but I recommend keeping it to make resulting kernelcache smaller&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-uncompressed&lt;/code&gt;- do not apply compression. Since we'll have to change one little thing later, compression would have to be reapplied anyway&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--&lt;/code&gt;means the rest of the args will point to directories to grab kexts from&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;kernels_kexts_10A63970m/Extensions&lt;/code&gt;is a path to a folder containing kexts&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The little thing to do is to remove fat header. For some reason, it creates a fat Mach-O with a single slice. iBoot doesn't like it, so let's strip it:&lt;/p&gt;
    &lt;code&gt;lipo -thin armv7 output.bin -o output.thin.bin
&lt;/code&gt;
    &lt;p&gt;The kernel cache is ready now! Just needs to be compressed and packaged into Image3 container&lt;/p&gt;
    &lt;head rend="h4"&gt;About kext lists&lt;/head&gt;
    &lt;p&gt;Once again I compared iPhone 3GS' iOS 5.1.1 vs. 6.0 - some kexts were added, some removed, some changed their bundle IDs, some were irrelevant for iPod touch 3&lt;/p&gt;
    &lt;p&gt;Do not forget to include the pseudo-extensions as well!&lt;/p&gt;
    &lt;p&gt;Samples can be found in SundanceInH2A repository&lt;/p&gt;
    &lt;head rend="h4"&gt;About IOKit personalities&lt;/head&gt;
    &lt;p&gt;In this specific case I had to patch up Info.plist of the Wi-Fi kext. As always there is a sample in the repo&lt;/p&gt;
    &lt;head rend="h2"&gt;Restore ramdisk filesystem&lt;/head&gt;
    &lt;p&gt;Pretty cannonical here. I patched &lt;code&gt;asr&lt;/code&gt; as usual and also had to move &lt;code&gt;options.n88.plist&lt;/code&gt; to &lt;code&gt;options.n18.plist&lt;/code&gt; so it can lay out partitions properly&lt;/p&gt;
    &lt;p&gt;However, I also have to install the iBoot exploit. To do that I reimplement &lt;code&gt;rc.boot&lt;/code&gt; binary:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Remount ramdisk and set&lt;/p&gt;&lt;code&gt;umask&lt;/code&gt;just like the original one does&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Call&lt;/p&gt;&lt;code&gt;restored_external&lt;/code&gt;, but with&lt;code&gt;-server&lt;/code&gt;argument, so it doesn't reboot after finishing restore&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If restore was completed properly, I add a third partition, write the exploit there and set&lt;/p&gt;&lt;code&gt;boot-partition&lt;/code&gt;to&lt;code&gt;2&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Reboot the device&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;My implementation is available guess where? Yes, in the repository&lt;/p&gt;
    &lt;head rend="h2"&gt;Root filesystem&lt;/head&gt;
    &lt;p&gt;This needed a lot of changes:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;Add matching SpringBoard's hardware feature plist (&lt;/p&gt;&lt;code&gt;/System/Library/CoreServices/SpringBoard.app/N18AP.plist&lt;/code&gt;in this case)&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;I took the iOS 5.1.1 variant as a base and added iOS 6 specific capabilities&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I tried to keep original enough Home screen icon order by merging iPod touch 3 iOS 5.1.1 and iPod touch 4 6.x layouts&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add multitouch &amp;amp; Wi-Fi firmwares&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;I use versions from 5.1.1&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Add Bluetooth firmware and scripts&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;
            &lt;p&gt;This is more complicated, as those are all hardcoded into&lt;/p&gt;
            &lt;code&gt;/usr/sbin/BlueTool&lt;/code&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;p&gt;Luckily, they can also be overriden by files in&lt;/p&gt;&lt;code&gt;/etc/bluetool&lt;/code&gt;- as always check my code for reference&lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;I extracted both firmware and scripts from 5.1.1&lt;/p&gt;
            &lt;code&gt;BlueTool&lt;/code&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;FairPlay daemon is limited to&lt;/p&gt;&lt;code&gt;N88AP&lt;/code&gt;(iPhone 3GS)&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;It has&lt;/p&gt;&lt;code&gt;LimitLoadToHardware&lt;/code&gt;key in its' LaunchDaemon plist&lt;/item&gt;&lt;item&gt;&lt;p&gt;But if we simply remove the key, it works on iPod touch 3 as well&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;This is important, because otherwise we cannot activate device through Apple's servers&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;This trick will be harder to pull off on iOS 6.1+ because they load LaunchDaemons from a signed cache. Still can be bypassed in many ways - for instance, patching&lt;/p&gt;&lt;code&gt;launchd&lt;/code&gt;or forcefully loading another plist via&lt;code&gt;launchctl&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;DYLD shared cache patches&lt;/p&gt;
        &lt;list rend="ol"&gt;
          &lt;item&gt;
            &lt;p&gt;Product ID map patch&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;iOS 6 brings a concept of "product ID" in the form of a long byte sequence&lt;/item&gt;
              &lt;item&gt;It is filled by iBoot into &lt;code&gt;product&lt;/code&gt;node of DeviceTree (which didn't even exist before)&lt;/item&gt;
              &lt;item&gt;I hardcode the value of iPhone 3GS straight into DeviceTree (&lt;code&gt;8784AE8D7066B0F0136BE91DCFE632A436FFD6FB&lt;/code&gt;)&lt;/item&gt;
              &lt;item&gt;There is also a short form of this identifier - 16-bit integer - which existed before iOS 6&lt;/item&gt;
              &lt;item&gt;iPhone 3GS is &lt;code&gt;0x2714&lt;/code&gt;and the iPod is&lt;code&gt;0x2715&lt;/code&gt;&lt;/item&gt;
              &lt;item&gt;MobileGestalt framework has a table that matches the short form by the long one - I swap &lt;code&gt;0x2714&lt;/code&gt;with&lt;code&gt;0x2715&lt;/code&gt;there&lt;/item&gt;
              &lt;item&gt;I believe it's better for iTunes and etc.&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
          &lt;item&gt;&lt;code&gt;getDeviceVariant()&lt;/code&gt;patch&lt;list rend="ul"&gt;&lt;item&gt;MobileGestalt once again messes us up our business&lt;/item&gt;&lt;item&gt;Device variant is a letter - usually "A" or "B"&lt;/item&gt;&lt;item&gt;It seems to depend on Wi-Fi transciever vendor used in exact device (?)&lt;/item&gt;&lt;item&gt;iOS 6 fails miserably to determine this value for iPod touch 3&lt;/item&gt;&lt;item&gt;This crashes activation process, for example&lt;/item&gt;&lt;item&gt;To fix it, I patch the function to always return "A" (in form of &lt;code&gt;CFString&lt;/code&gt;)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
          &lt;item&gt;
            &lt;p&gt;Fixing code signature&lt;/p&gt;
            &lt;list rend="ul"&gt;
              &lt;item&gt;This is much easier than most people think&lt;/item&gt;
              &lt;item&gt;Shared cache files have the same format of signature as normal Mach-Os&lt;/item&gt;
              &lt;item&gt;And since it's just ad-hoc, all you need to do is to recalculate SHA-1 hash for pages you modified and update the signature&lt;/item&gt;
              &lt;item&gt;So easy, it can be done with just a hex-editor&lt;/item&gt;
            &lt;/list&gt;
          &lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The iBoot exploit&lt;/head&gt;
    &lt;p&gt;iOS 5 iBoot had a bug in HFS+ filesystem driver. I did make an exploit many years ago but it was bad. Like, truly bad. I reimplemented it from scratch for this project making it deterministic (hopefully...)&lt;/p&gt;
    &lt;p&gt;This subject probably deserves a separate article&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion &amp;amp; future plans&lt;/head&gt;
    &lt;p&gt;This was not easy to do, and yet easier than I expected initially&lt;/p&gt;
    &lt;p&gt;After releasing the tool many people asked me about jailbreaking. The old tools are not going to work, but it should be easy to just patch the kernel and drop Cydia tarball onto the filesystem. I guess I will give it a try later&lt;/p&gt;
    &lt;p&gt;There was another device that Apple dropped support for in that year - iPad 1. I will try that soon enough as well&lt;/p&gt;
    &lt;p&gt;I hope that the information from this write-up will help you making other crazy combinations, like iOS 4 on iPhone 4S or iOS 5 on iPad mini 1&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nyansatan.github.io/run-unsupported-ios/"/><published>2025-11-26T22:57:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46063450</id><title>C100 Developer Terminal</title><updated>2025-11-27T11:09:43.045675+00:00</updated><content>&lt;doc fingerprint="e4cb5b533733f9d0"&gt;
  &lt;main&gt;
    &lt;p&gt;c100 runs Workbench, a Linux-based operating system built for technical work. It‚Äôs designed to get out of your way, so your team can deliver more.&lt;/p&gt;
    &lt;p&gt;Most people don‚Äôt write code or manage data, and consumer devices are designed accordingly.&lt;/p&gt;
    &lt;p&gt;But change isn‚Äôt made by most people. Progress comes from the people whose work improves our understanding and ability.&lt;/p&gt;
    &lt;p&gt;Scientists and artists. Engineers and designers. Hackers and painters.&lt;/p&gt;
    &lt;p&gt;We think the world needs a brand of computing that stands behind creative technical work, dedicated to creating instead of consuming.&lt;/p&gt;
    &lt;p&gt;Caligra is a new computer company. Our goal is to help you make the future.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://caligra.com/"/><published>2025-11-26T23:22:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46064367</id><title>Bonsai_term: A library for building dynamic terminal apps by Jane Street</title><updated>2025-11-27T11:09:42.563720+00:00</updated><content>&lt;doc fingerprint="f44b01f5dfe5990"&gt;
  &lt;main&gt;
    &lt;p&gt;Bonsai_term is a library that lets you write Terminal UIs (TUIs) using OCaml. It uses the same programming model as the &lt;code&gt;bonsai_web&lt;/code&gt; library.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;If you are new to OCaml - or if you haven't already - install opam. It is OCaml's package manager and we'll be using it to install &lt;code&gt;bonsai_term&lt;/code&gt;and its dependencies. The specific installation instructions depend on your platform. You can find platform-specific instructions here.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;bonsai_term&lt;/code&gt;uses OxCaml so the next thing you'll want to do is install&lt;code&gt;oxcaml&lt;/code&gt;by following the instructions here.&lt;/item&gt;
      &lt;item&gt;Run &lt;code&gt;opam install bonsai_term&lt;/code&gt;. (This will install&lt;code&gt;bonsai_term&lt;/code&gt;and its dependencies).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At this point you should now have &lt;code&gt;bonsai_term&lt;/code&gt; "installed".&lt;/p&gt;
    &lt;p&gt;To learn how to use &lt;code&gt;bonsai_term&lt;/code&gt; you can read its MLI &lt;code&gt;src/bonsai_term.mli&lt;/code&gt; and / or look
at some examples in the
bonsai_term_examples repo.&lt;/p&gt;
    &lt;p&gt;To learn how to use &lt;code&gt;bonsai&lt;/code&gt;, you can read the docs in
bonsai_web.
(most of those docs are aimed at the "web" version of bonsai, so the "vdom" bits may not
apply, but the "effect" / "state-fulness" and ways of doing "incrementality" all should
transfer from &lt;code&gt;bonsai_web&lt;/code&gt; into &lt;code&gt;bonsai_term&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;To learn how to use &lt;code&gt;ocaml&lt;/code&gt; here are some good resources:&lt;/p&gt;
    &lt;p&gt;If you followed the install instructions at the top of this page, you can skip the "Install" instructions on the above links.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/janestreet/bonsai_term"/><published>2025-11-27T01:20:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46064571</id><title>Migrating the main Zig repository from GitHub to Codeberg</title><updated>2025-11-27T11:09:41.888855+00:00</updated><content>&lt;doc fingerprint="8374b4d94ff22fcb"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Migrating from GitHub to Codeberg&lt;/head&gt;
    &lt;head rend="h3"&gt;November 26, 2025&lt;/head&gt;
    &lt;p&gt;https://codeberg.org/ziglang/zig&lt;/p&gt;
    &lt;p&gt;Ever since &lt;code&gt;git init&lt;/code&gt; ten years ago, Zig has been hosted on GitHub. Unfortunately, when it sold out to Microsoft, the clock started ticking. √¢Please just give me 5 years before everything goes to shit,√¢ I thought to myself. And here we are, 7 years later, living on borrowed time.&lt;/p&gt;
    &lt;p&gt;Putting aside GitHub√¢s relationship with ICE, it√¢s abundantly clear that the talented folks who used to work on the product have moved on to bigger and better things, with the remaining rookies eager to inflict some kind of bloated, buggy JavaScript framework on us in the name of progress. Stuff that used to be snappy is now sluggish and often entirely broken.&lt;/p&gt;
    &lt;p&gt;More importantly, Actions is created by monkeys and completely neglected. After the CEO of GitHub said to √¢embrace AI or get out√¢, it seems the lackeys at Microsoft took the hint, because GitHub Actions started √¢vibe-scheduling√¢; choosing jobs to run seemingly at random. Combined with other bugs and inability to manually intervene, this causes our CI system to get so backed up that not even master branch commits get checked.&lt;/p&gt;
    &lt;p&gt;Rather than wasting donation money on more CI hardware to work around this crumbling infrastructure, we√¢ve opted to switch Git hosting providers instead.&lt;/p&gt;
    &lt;p&gt;As a bonus, we look forward to fewer violations (exhibit A, B, C) of our strict no LLM / no AI policy, which I believe are at least in part due to GitHub aggressively pushing the √¢file an issue with Copilot√¢ feature in everyone√¢s face.&lt;/p&gt;
    &lt;head rend="h2"&gt;GitHub Sponsors&lt;/head&gt;
    &lt;p&gt;The only concern we have in leaving GitHub behind has to do with GitHub Sponsors. This product was key to Zig√¢s early fundraising success, and it remains a large portion of our revenue today. I can√¢t thank Devon Zuegel enough. She appeared like an angel from heaven and single-handedly made GitHub into a viable source of income for thousands of developers. Under her leadership, the future of GitHub Sponsors looked bright, but sadly for us, she, too, moved on to bigger and better things. Since she left, that product as well has been neglected and is already starting to decline.&lt;/p&gt;
    &lt;p&gt;Although GitHub Sponsors is a large fraction of Zig Software Foundation√¢s donation income, we consider it a liability. We humbly ask if you, reader, are currently donating through GitHub Sponsors, that you consider moving your recurring donation to Every.org, which is itself a non-profit organization.&lt;/p&gt;
    &lt;p&gt;As part of this, we are sunsetting the GitHub Sponsors perks. These perks are things like getting your name onto the home page, and getting your name into the release notes, based on how much you donate monthly. We are working with the folks at Every.org so that we can offer the equivalent perks through that platform.&lt;/p&gt;
    &lt;head rend="h2"&gt;Migration Plan&lt;/head&gt;
    &lt;p&gt;Effective immediately, I have made ziglang/zig on GitHub read-only, and the canonical origin/master branch of the main Zig project repository is &lt;code&gt;https://codeberg.org/ziglang/zig.git&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Thank you to the Forgejo contributors who helped us with our issues switching to the platform, as well as the Codeberg folks who worked with us on the migration - in particular Earl Warren, Otto, Gusted, and Mathieu Fenniak.&lt;/p&gt;
    &lt;p&gt;In the end, we opted for a simple strategy, sidestepping GitHub√¢s aggressive vendor lock-in: leave the existing issues open and unmigrated, but start counting issues at 30000 on Codeberg so that all issue numbers remain unambiguous. Let us please consider the GitHub issues that remain open as metaphorically √¢copy-on-write√¢. Please leave all your existing GitHub issues and pull requests alone. No need to move your stuff over to Codeberg unless you need to make edits, additional comments, or rebase. We√¢re still going to look at the already open pull requests and issues; don√¢t worry.&lt;/p&gt;
    &lt;p&gt;In this modern era of acquisitions, weak antitrust regulations, and platform capitalism leading to extreme concentrations of wealth, non-profits remain a bastion defending what remains of the commons.&lt;/p&gt;
    &lt;p&gt;Happy hacking,&lt;/p&gt;
    &lt;p&gt;Andrew&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ziglang.org/news/migrating-from-github-to-codeberg/"/><published>2025-11-27T01:49:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46064680</id><title>Functional Data Structures and Algorithms: a Proof Assistant Approach</title><updated>2025-11-27T11:09:41.735041+00:00</updated><content>&lt;doc fingerprint="96e790871cbf635a"&gt;
  &lt;main&gt;
    &lt;p&gt;This book is an introduction to data structures and algorithms for functional languages, with a focus on proofs. It covers both functional correctness and running time analysis. It does so in a unified manner with inductive proofs about functional programs and their running time functions. All proofs have been machine-checked by the proof assistant Isabelle. The pdf contains links to the corresponding Isabelle theories.&lt;/p&gt;
    &lt;p&gt;Click on an image to download the pdf of the whole book:&lt;/p&gt;
    &lt;p&gt;This book is meant to evolve over time. If you would like to contribute, get in touch!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fdsa-book.net/"/><published>2025-11-27T02:04:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46064757</id><title>Penpot: The Open-Source Figma</title><updated>2025-11-27T11:09:41.213048+00:00</updated><content>&lt;doc fingerprint="d448ea5b7d378672"&gt;
  &lt;main&gt;
    &lt;p&gt;Website ‚Ä¢ User Guide ‚Ä¢ Learning Center ‚Ä¢ Community&lt;/p&gt;
    &lt;p&gt;Youtube ‚Ä¢ Peertube ‚Ä¢ Linkedin ‚Ä¢ Instagram ‚Ä¢ Mastodon ‚Ä¢ Bluesky ‚Ä¢ X&lt;/p&gt;
    &lt;head class="px-3 py-2"&gt;Penpot_OpenYourEyes_.mp4&lt;/head&gt;
    &lt;p&gt;Penpot is the first open-source design tool for design and code collaboration. Designers can create stunning designs, interactive prototypes, design systems at scale, while developers enjoy ready-to-use code and make their workflow easy and fast. And all of this with no handoff drama.&lt;/p&gt;
    &lt;p&gt;Available on browser or self-hosted, Penpot works with open standards like SVG, CSS, HTML and JSON, and it‚Äôs free!&lt;/p&gt;
    &lt;p&gt;The latest updates take Penpot even further. It‚Äôs the first design tool to integrate native design tokens‚Äîa single source of truth to improve efficiency and collaboration between product design and development. With the huge 2.0 release, Penpot took the platform to a whole new level. This update introduces the ground-breaking CSS Grid Layout feature, a complete UI redesign, a new Components system, and much more. For organizations that need extra service for its teams, get in touch&lt;/p&gt;
    &lt;p&gt;üéá Design, code, and Open Source meet at Penpot Fest! Be part of the 2025 edition in Madrid, Spain, on October 9-10.&lt;/p&gt;
    &lt;p&gt;Penpot expresses designs as code. Designers can do their best work and see it will be beautifully implemented by developers in a two-way collaboration.&lt;/p&gt;
    &lt;p&gt;Penpot plugins let you expand the platform's capabilities, give you the flexibility to integrate it with other apps, and design custom solutions.&lt;/p&gt;
    &lt;p&gt;Penpot was built to serve both designers and developers and create a fluid design-code process. You have the choice to enjoy real-time collaboration or play "solo".&lt;/p&gt;
    &lt;p&gt;Work with ready-to-use code and make your workflow easy and fast. The inspect tab gives instant access to SVG, CSS and HTML code.&lt;/p&gt;
    &lt;p&gt;Provide your team or organization with a completely owned collaborative design tool. Use Penpot's cloud service or deploy your own Penpot server.&lt;/p&gt;
    &lt;p&gt;Penpot offers integration into the development toolchain, thanks to its support for webhooks and an API accessible through access tokens.&lt;/p&gt;
    &lt;p&gt;Penpot brings design systems to code-minded teams: a single source of truth with native Design Tokens, Components, and Variants for scalable, reusable, and consistent UI across projects and platforms.&lt;/p&gt;
    &lt;p&gt;Penpot is the only design &amp;amp; prototype platform that is deployment agnostic. You can use it in our SAAS or deploy it anywhere.&lt;/p&gt;
    &lt;p&gt;Learn how to install it with Docker, Kubernetes, Elestio or other options on our website. &lt;/p&gt;
    &lt;p&gt;We love the Open Source software community. Contributing is our passion and if it‚Äôs yours too, participate and improve Penpot. All your designs, code and ideas are welcome!&lt;/p&gt;
    &lt;p&gt;If you need help or have any questions; if you‚Äôd like to share your experience using Penpot or get inspired; if you‚Äôd rather meet our community of developers and designers, join our Community!&lt;/p&gt;
    &lt;p&gt;You will find the following categories:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Ask the Community&lt;/item&gt;
      &lt;item&gt;Troubleshooting&lt;/item&gt;
      &lt;item&gt;Help us Improve Penpot&lt;/item&gt;
      &lt;item&gt;#MadeWithPenpot&lt;/item&gt;
      &lt;item&gt;Events and Announcements&lt;/item&gt;
      &lt;item&gt;Inside Penpot&lt;/item&gt;
      &lt;item&gt;Penpot in your language&lt;/item&gt;
      &lt;item&gt;Design and Code Essentials&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anyone who contributes to Penpot, whether through code, in the community, or at an event, must adhere to the code of conduct and foster a positive and safe environment.&lt;/p&gt;
    &lt;p&gt;Any contribution will make a difference to improve Penpot. How can you get involved?&lt;/p&gt;
    &lt;p&gt;Choose your way:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Create and share Libraries &amp;amp; Templates that will be helpful for the community&lt;/item&gt;
      &lt;item&gt;Invite your team to join&lt;/item&gt;
      &lt;item&gt;Give this repo a star and follow us on Social Media: Mastodon, Youtube, Instagram, Linkedin, Peertube, X and BlueSky&lt;/item&gt;
      &lt;item&gt;Participate in the Community space by asking and answering questions; reacting to others‚Äô articles; opening your own conversations and following along on decisions affecting the project.&lt;/item&gt;
      &lt;item&gt;Report bugs with our easy guide for bugs hunting or GitHub issues&lt;/item&gt;
      &lt;item&gt;Become a translator&lt;/item&gt;
      &lt;item&gt;Give feedback: Email us&lt;/item&gt;
      &lt;item&gt;Contribute to Penpot's code: Watch this video by Alejandro Alonso, CIO and developer at Penpot, where he gives us a hands-on demo of how to use Penpot‚Äôs repository and make changes in both front and back end&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To find (almost) everything you need to know on how to contribute to Penpot, refer to the contributing guide.&lt;/p&gt;
    &lt;p&gt;You can ask and answer questions, have open-ended conversations, and follow along on decisions affecting the project.&lt;/p&gt;
    &lt;p&gt;‚úèÔ∏è Tutorials&lt;/p&gt;
    &lt;p&gt;üèòÔ∏è Architecture&lt;/p&gt;
    &lt;code&gt;This Source Code Form is subject to the terms of the Mozilla Public
License, v. 2.0. If a copy of the MPL was not distributed with this
file, You can obtain one at http://mozilla.org/MPL/2.0/.

Copyright (c) KALEIDOS INC
&lt;/code&gt;
    &lt;p&gt;Penpot is a Kaleidos‚Äô open source project&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/penpot/penpot"/><published>2025-11-27T02:14:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065034</id><title>DIY NAS: 2026 Edition</title><updated>2025-11-27T11:09:40.860048+00:00</updated><content>&lt;doc fingerprint="e640301301a64f39"&gt;
  &lt;main&gt;
    &lt;p&gt;Fourteen years ago, my storage needs outpaced my capacity and I began to look into building a network attached storage server. I had a few criteria in mind and was curious to see if anyone had _ recently_ shared something similar, but I couldn√¢t find anything that was relevant.&lt;/p&gt;
    &lt;p&gt;In fact, I found that the communities I was looking for answers in were actively hostile towards what I wanted to do. This resulted in my decision to build my own DIY NAS and share that as one of my very first blogs.&lt;/p&gt;
    &lt;p&gt;Much to my surprise, people were very interested in that blog! Ever since, I√¢ve been building a similar DIY NAS machine almost every year trying to satisfy the curiosity of other prospective DIY NAS builders.&lt;/p&gt;
    &lt;p&gt;Here are those criteria:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Small form factor: It√¢s not the case for me any more, but at the time the space was limited in my office. I always assume that space in everybody√¢s office is limited. As a result, I want my DIY NAS builds to occupy as little of that office space as I can.&lt;/item&gt;
      &lt;item&gt;At least six drive bays: Back when I built my NAS, it took about four drives√¢ worth of storage to meet my storage needs. Plus I desired two empty drive bays for future use. However, in the years since hard drive capacities have increased dramatically. At some point in the future, I may reduce this to four drive bays.&lt;/item&gt;
      &lt;item&gt;An integrated, low power CPU: I intend my DIY NAS to run 24 hours a day, 7 days a week, and 52 weeks a year. When it comes to power consumption, that can do some damage on your electric bill! Thankfully our electricity here isn√¢t as expensive as others√¢ in the United States, or even further outside its borders, but I try and keep power consumption in mind when picking components for a DIY NAS build.&lt;/item&gt;
      &lt;item&gt;Homelab potential: It does not take up a lot of CPU horsepower for a NAS to serve up files, which means that on modern hardware there√¢s a lot of untapped potential in a DIY NAS for virtual machines or containers to self-host services.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It√¢s important to remember that these are my criteria, and not necessarily yours. Every DIY NAS builder should be making their own list of criteria and reconcile all of their component purchases against the criteria that√¢s important to them.&lt;/p&gt;
    &lt;head rend="h2"&gt;Is it even a good time to build a NAS?&lt;/head&gt;
    &lt;p&gt;As I prepared to build this NAS, component prices disappointed me. Hard drives, SSDs, and RAM prices were all rising. Based on what I√¢ve been told, I expect Intel CPU prices to increase as well. My contact at Topton has been encouraging me to stock up on motherboards while they still have some in inventory. Based on what√¢s been explained to me, I expect the motherboard√¢s prices to rise and for their availability to potentially dwindle.&lt;/p&gt;
    &lt;p&gt;In short, the economy sucks and the price of DIY NAS components is a pretty good reflection of just how sucky things are becoming. I briefly considered not publishing a DIY NAS build this year hoping that things would improve a few months down the road. But then I asked myself, √¢What if it√¢s even worse in a few months?√¢&lt;/p&gt;
    &lt;p&gt;I sure hope things get better, but I fear and expect that they√¢ll get worse.&lt;/p&gt;
    &lt;head rend="h2"&gt;Motherboard and CPU&lt;/head&gt;
    &lt;p&gt;I built my first DIY NAS with a Topton motherboard in 2023. Each DIY NAS since then has also featured a Topton motherboard. My only complaint about the motherboards has been that buying them from one of the Chinese e-tail sites like AliExpress is considered problematic by some. With every DIY NAS build, I try and go through all the motherboards that I can find while searching for something with a better value proposition, but for each of the past three years I√¢ve landed on the latest offering from Topton.&lt;/p&gt;
    &lt;p&gt;For the DIY NAS: 2026 Edition, I chose the Topton N22 motherboard with the Intel Core 3 N355 CPU. The motherboard is similar to last year√¢s Topton N18 but has incrementally more compelling features, particularly the extra 2 SATA ports, the PCI-e x1 slot, and the N355 CPU!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mini-ITX Form Factor&lt;/item&gt;
      &lt;item&gt;Intel√Ç¬Æ Processor Core 3 N355 &lt;list rend="ul"&gt;&lt;item&gt;8 cores / 8 threads / Max Turbo 3.9GHz&lt;/item&gt;&lt;item&gt;15 W TDP&lt;/item&gt;&lt;item&gt;Integrated GPU with Intel Quick Sync Video&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;1 x DDR5 SO-DIMM&lt;/item&gt;
      &lt;item&gt;8 x SATA 3.0 Ports (Asmedia ASM1164)&lt;/item&gt;
      &lt;item&gt;2 x M.2 NVMe Slots (PCIe 3.0 x1)&lt;/item&gt;
      &lt;item&gt;1 x 10Gbps NIC (Marvell AQC113C)&lt;/item&gt;
      &lt;item&gt;2 x 2.5Gbps NICs (Intel i226-V)&lt;/item&gt;
      &lt;item&gt;1 x PCI-e x1 or M.2 E-Key slot&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I opted for the motherboard with the Intel Core 3 N355 CPU. This makes the server a more capable homelab machine than prior years√¢ DIY NAS builds. The extra cores and threads come in handy for streaming media, replacing your cloud storage, facilitating home automation, hosting game servers, etc.&lt;/p&gt;
    &lt;head rend="h2"&gt;Case&lt;/head&gt;
    &lt;p&gt;Just like Topton has been making great motherboards for DIY NAS machines, JONSBO has been steadily releasing great cases for DIY NAS machines. This year SilverStone Technology released a new case, the CS383 (specs) which I was very interested in buying one for the DIY NAS: 2026 Edition. Unfortunately it carries a pretty hefty price tag to go along with all of its incredible features!&lt;/p&gt;
    &lt;p&gt;The JONSBO N4 (specs) is a third the price, adheres to my √¢smaller footprint√¢ criteria, and it is rather impressive on its own. It√¢s a tiny bit larger case than last year√¢s DIY NAS, but I really like that it has drive bays for six 3.5√¢ drives and two 2.5√¢ drives.&lt;/p&gt;
    &lt;p&gt;Although, it√¢s peculiar in that two of the 3.5√¢ drive bays (and the two 2.5√¢ drive bays) aren√¢t attached to a SATA backplane and can√¢t be swapped anywhere as easily as the other four 3.5√¢ bays. However, this peculiar decision seems to have caused the JONSBO N4 to sell for a bit less ($20-$40) than similar offerings from JONSBO. At its price, it√¢s a compelling value proposition!&lt;/p&gt;
    &lt;head rend="h3"&gt;Case Fan&lt;/head&gt;
    &lt;p&gt;In the past, I√¢ve found that the fans which come with JONSBO cases are too noisy. They√¢ve been noisy for two reasons; the design quality of the fans make them loud. And the fans are constantly running at their top speed because of the fan header they√¢re plugged into on the cases√¢ SATA backplanes.&lt;/p&gt;
    &lt;p&gt;I anticipated that fan efficiency and noise would be a problem, so I picked out the Noctua NF-A12x25 PWM to solve it. Firstly, swapping in a high-quality fan that pushes more air and generates less noise√¢especially at its top speed√¢is a good first step. Secondly, I√¢d address the problem by plugging the fan into the motherboard√¢s &lt;code&gt;SYS_FAN&lt;/code&gt; header instead of on the SATA backplane. This provides the opportunity to tune the fan√¢s RPMs directly in the BIOS and generate far less noise.&lt;/p&gt;
    &lt;head rend="h2"&gt;RAM&lt;/head&gt;
    &lt;p&gt;The first time I first asked myself, √¢Should I even build the DIY NAS: 2026 Edition?√¢ came as I was checking prices on DDR5 memory. Thankfully for me I had leftover RAM after purchasing DDR5 4800MHz SODIMMs for the DIY NAS: 2025 Edition, the Pocket Mini NAS, and then again for the DIY NAS that I built and gave away at 2025√¢s Texas Linux Fest. I was personally thankful that I had one brand new 32GB DDR5 4800MHz SODIMM laying around, but I was wildly disappointed for everybody who will try and follow this build when I saw the price of those same SODIMMs.&lt;/p&gt;
    &lt;p&gt;Regardless, I felt a Crucial 32GB DDR5 4800MHz SODIMM (specs) was the right amount of RAM to get started with for a DIY NAS build in 2025. Whether you just need storage or you wish to also host virtual machines, you will benefit from having more than the bare minimum recommendation of RAM. I really wanted to buy a 48GB DDR5 4800MHZ SODIMM for this DIY NAS build, but I couldn√¢t talk myself into spending the $250-$300 that it would√¢ve wound up costing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Storage&lt;/head&gt;
    &lt;p&gt;A quick disclaimer about all the drives that I purchased for the DIY NAS: 2026 Edition, I already had all of them! I tend to buy things when I see them on sale and as a result, I have a collection of brand new parts for machines in my homelab or for upcoming projects. I raided that collection of spare parts for the DIY NAS: 2026 Edition.&lt;/p&gt;
    &lt;head rend="h3"&gt;Boot Drive&lt;/head&gt;
    &lt;p&gt;If you ranked the drives in your DIY NAS in order of importance, the boot drive should be the least-important drive. That is not saying that boot drive isn√¢t performing an important function, but I am suggesting that you shouldn√¢t invest a bunch of energy and money into picking the optimal boot drive.&lt;/p&gt;
    &lt;p&gt;Because the JONSBO N4 has a pair of 2.5√¢ drive bays, I decided that a 2.5√¢ SATA SSD would be ideal for the boot drives. As a rule of thumb, I try and spend less than $30 per boot drive in my DIY NAS builds.&lt;/p&gt;
    &lt;p&gt;Ultimately I selected a pair of 128GB Silicon Power A55 SSDs (specs). I√¢ve used these before, I√¢d use them again in the future, and I even have four of their higher capacity (1TB) SSDs in a pool in my own NAS.&lt;/p&gt;
    &lt;head rend="h3"&gt;App and Virtual Machine NVMe SSDs&lt;/head&gt;
    &lt;p&gt;Self-hosting apps and virtual machines on your DIY NAS has really exploded in the past few years. The developers of NAS appliance packages have made it much easier and the self-hosted products themselves have become as good√¢or often better√¢than things you√¢re probably subscribing to today. Because of that, I saved the highest-performing storage options on the Topton N22 motherboard for apps and VMs.&lt;/p&gt;
    &lt;p&gt;However, it√¢s important to point out that these M.2 slots are PCI-e version 3 and capped at a single PCI-e lane. This is a consequence of the limited number of PCI-e lanes available for each of the CPU options available for the Topton N22 motherboard (N100, N150, N305, and N355).&lt;/p&gt;
    &lt;p&gt;I opted for a NVMe drive that was a good value rather than a high performer and chose two of the Silicon Power 1TB M.2 NVMe SSDs (SP001TBP34A60M28) (specs).&lt;/p&gt;
    &lt;head rend="h3"&gt;Bulk Storage Hard Disk Drives&lt;/head&gt;
    &lt;p&gt;Thanks to rising prices, I opted to do like I√¢ve done with past DIY NAS builds and skip buying hard drives for the DIY NAS: 2026 Edition.&lt;/p&gt;
    &lt;p&gt;When planning your DIY NAS, it is good to always remember that storage will ultimately be your costliest and most important expense.&lt;/p&gt;
    &lt;p&gt;Here√¢s a few things to consider when buying hard drives:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Determine your hardware redundancy preferences. I recommend having two hard disk drives√¢ worth of redundancy (RAIDZ2, RAID6, etc.)&lt;/item&gt;
      &lt;item&gt;Focus on price-per-terabyte when comparing prices of drives.&lt;/item&gt;
      &lt;item&gt;Do some burn in testing of your hard drives before putting them to use.&lt;/item&gt;
      &lt;item&gt;When buying new drives of the same model, try and buy them from multiple vendors to increase the chances of buying drives manufactured in separate batches.&lt;/item&gt;
      &lt;item&gt;Plan Ahead! Understand the rate that your storage grows so that you can craft a strategy to grow your storage down the road.&lt;/item&gt;
      &lt;item&gt;Being cheap today can and will paint you into a corner that√¢s quite expensive to get out of.&lt;/item&gt;
      &lt;item&gt;Understand that RAID is not a backup!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thankfully, I√¢ve collected a bunch of my own decomissioned hard drives which I used to thoroughly test this DIY NAS build.&lt;/p&gt;
    &lt;head rend="h2"&gt;SATA Cables&lt;/head&gt;
    &lt;p&gt;One of the under-the-radar features of the Topton N22 motherboard might be one of my favorite features! The motherboard√¢s Asmedia ASM1164 SATA controllers sit behind two SFF-8643 connectors. These connectors provide two advantages for these motherboards:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Saves room on the motherboard√¢s PCB.&lt;/item&gt;
      &lt;item&gt;SFF-8643 to 4x SATA breakout cables reduces the amount of cable management hassle.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Power Supply&lt;/head&gt;
    &lt;p&gt;The one thing that I have routinely disliked about building small form factor DIY NAS machines is the price tag that accompanies a small form factor power supply (SFX) like is required with the JONSBO N4.&lt;/p&gt;
    &lt;p&gt;I wound up choosing the SilversStone Technology SX500-G (specs) which I had used earlier in the year for the DIY NAS I gave away at Texas Linux Fest. Its 500W rating exceeds the needs of all the components that I√¢d picked out for the DIY NAS: 2026 Edition. Plus the power supply√¢s 80 Plus Gold rating aligns well with my criteria for power efficiency.&lt;/p&gt;
    &lt;head rend="h2"&gt;TrueNAS Community Edition&lt;/head&gt;
    &lt;p&gt;Regardless of whether it was called FreeNAS, TrueNAS, TrueNAS CORE, TrueNAS SCALE, or now TrueNAS Community Edition, the storage appliance product(s) from iXSystems have always been my go-to choice. For each yearly DIY NAS build, I wander over to the TrueNAS Software Status page and look at the state of the current builds.&lt;/p&gt;
    &lt;p&gt;I√¢m conservative with my personal NAS setup. However, for these blog builds, I typically choose Early Adopter releases. This year that√¢s TrueNAS 25.10.0.1 (aka Goldeye). I enjoy being able to use these DIY NAS builds as a preview to the latest and greatest that TrueNAS has to offer.&lt;/p&gt;
    &lt;p&gt;I repeatedly choose TrueNAS because it√¢s what I√¢ve become accustomed to; it√¢s legitimately an enterprise-grade storage product, which is exactly the quality of solution that I want my data to depend on. At the same time it does not feel like you need a specialized certification and a truckload of enterprise storage experience to meet set up a NAS that exceeds your needs at home.&lt;/p&gt;
    &lt;p&gt;Many times I have been asked, √¢Why not &amp;lt;insert NAS appliance or OS here&amp;gt;?√¢ My answer to that question is, TrueNAS has always done everything that I need it to and they haven√¢t given me any reason to consider anything else. As a result, there√¢s never been a need for me to evaluate something else.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Parts List&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Part Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Qty&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Motherboard&lt;/cell&gt;
        &lt;cell&gt;Topton N22 (w/ N355 CPU) NAS Motherboard&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$446.40&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CPU&lt;/cell&gt;
        &lt;cell&gt;Intel Core 3 N355&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Memory&lt;/cell&gt;
        &lt;cell&gt;Crucial RAM 32GB DDR5 4800MHz SODIMM (CT32G48C40S5)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$172.96&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Case&lt;/cell&gt;
        &lt;cell&gt;JONSBO N4&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$121.59&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Case Fan&lt;/cell&gt;
        &lt;cell&gt;Noctua NF-A12x25 PWM chromax.Black.swap&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$37.95&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Power Supply&lt;/cell&gt;
        &lt;cell&gt;SilverStone 500W SFX Power Supply SST-SX500-G)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;$142.34&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Boot Drive&lt;/cell&gt;
        &lt;cell&gt;Silicon Power 128GB A55 SATA SSD&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$21.97&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Apps/VM Drives&lt;/cell&gt;
        &lt;cell&gt;Silicon Power 1TB - NVMe M.2 SSD (SP001TBP34A60M28)&lt;/cell&gt;
        &lt;cell&gt;specs&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$99.99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SATA Cables&lt;/cell&gt;
        &lt;cell&gt;OIKWAN SFF-8643 Host to 4 X SATA Breakout Cable&lt;/cell&gt;
        &lt;cell&gt;N/A&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;$11.99&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Price without Storage:&lt;/cell&gt;
        &lt;cell&gt;$989.36&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total Price:&lt;/cell&gt;
        &lt;cell&gt;$1,189.34&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Hardware Assembly, BIOS Configuration, and Burn-In&lt;/head&gt;
    &lt;head rend="h3"&gt;Hardware Assembly&lt;/head&gt;
    &lt;p&gt;I wanted the smallest possible DIY NAS. The JONSBO N4 case initially felt too large since it accommodates Micro ATX motherboards. However, I grew to accept its slightly larger footprint. However, putting the Topton N22 motherboard into the case felt roomy and luxurious. Building the DIY NAS: 2026 Edition compared to prior years√¢ felt a lot like coming home to put on sweatpants and a t-shirt after wearing a suit and tie all day long.&lt;/p&gt;
    &lt;p&gt;I wasn√¢t too fond of the cable-management of the power supply√¢s cables. The layout of the case pretty much makes the front of the power supply inaccessible once it is installed. One consequence of this is that the power cable which powered the SATA backplane initially prevented the 120mm case fan from spinning up. That issue was relatively minor and was resolved with zip ties.&lt;/p&gt;
    &lt;p&gt;Overall, I felt pretty good about the assembly of the DIY NAS: 2026 Edition, but things would take a turn for the worse when I decided to fill all the 3.5-inch drive bays up with some of my decommissioned 8TB HDDs. Now this is probably my fault, I wouldn√¢t be surprised at all that the manual of the JONSBO N4 warned me against this, but putting the drives in last turned out to be a major pain in the neck for each of the four drive bays without a SATA backplane.&lt;/p&gt;
    &lt;p&gt;I had wrongly guessed that you accessed those drives√¢ power and data ports from the front of the case. I worked really hard to route the cables and even managed to install all of the drives before realizing my error and learning my lesson. I√¢m understanding now why the JONSBO N4 is cheaper than all of its siblings. Partly because there√¢s a missing SATA backplane, but also because those other 4 drive bays√¢ layout is frustrating.&lt;/p&gt;
    &lt;p&gt;Don√¢t let my last couple paragraphs sour you on the JONSBO N4, though. I still really like its size, it feels big when you√¢re working in it with a Mini ITX motherboard. If you wind up deciding to use the JONSBO N4, then I suggest that you put those four drives and their cables in first before you do anything else. That would√¢ve made a world of difference for me. Actually looking at the documentation before getting started might have saved me quite a bit of aggravation, too!&lt;/p&gt;
    &lt;p&gt;If I have ruined the JONSBO N4 for you, then check out the JONSBO N3. It√¢s eight 3.5-inch drive bays pair up really nicely with the Topton N22 motherboard. You can see what I thought of the JONSBO N3 by reading the DIY NAS: 2024 Edition blog.&lt;/p&gt;
    &lt;head rend="h3"&gt;BIOS Configuration&lt;/head&gt;
    &lt;p&gt;Generally speaking, I do as little as I possibly can in the BIOS. Normally I strive to only set the time and change the boot order. However, I did a bit more for the DIY NAS: 2026 Edition since I√¢m using the &lt;code&gt;SYS_FAN&lt;/code&gt; header for the fan which is responsible for cooling the hard drives.  Here are the changes that I made in the BIOS:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set the System Date and System Time to Greenwich Mean Time &lt;list rend="ol"&gt;&lt;item&gt;Advanced &lt;list rend="ol"&gt;&lt;item&gt;Hardware Monitor ( Advanced) &lt;list rend="ol"&gt;&lt;item&gt;Set SYS SmartFan Mode to &lt;code&gt;Disabled&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Set the Manual PWM Setting (for &lt;code&gt;SYS_FAN&lt;/code&gt;) to 180.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Set SYS SmartFan Mode to &lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Hardware Monitor ( Advanced) &lt;/item&gt;&lt;item&gt;Set PWRON After Power Loss to &lt;code&gt;Always On&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Boot &lt;list rend="ol"&gt;&lt;item&gt;Set Boot Option #1 to the TrueNAS boot device.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Advanced &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I√¢m not at all interested in venturing into the rabbit√¢s hole of trying to completely minimize how much power the NAS uses. However, I imagine there√¢s some opportunities for power savings lurking in the BIOS. I didn√¢t go looking for them myself, but if you√¢re intrepid enough to do so here√¢s a few suggestions that I have to save some additional power:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Disable the onboard audio.&lt;/item&gt;
      &lt;item&gt;Disable any network interfaces that you don√¢t wind up using.&lt;/item&gt;
      &lt;item&gt;Tinker with the CPU settings.&lt;/item&gt;
      &lt;item&gt;Got other suggestions? Share them in the comments!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Burn-In&lt;/head&gt;
    &lt;p&gt;Because all of the hardware is brand-new to me brand-new components are not guaranteed to be free of defects, I always do a little bit of burn-in testing to establish some trust in the hardware that I√¢ve picked out for each DIY NAS build. While I think doing some burn-in testing critically important, I also think the value of subsequent burn-in testing drops the more that you do. Don√¢t get too carried away and do your own burn-in testing in moderation!&lt;/p&gt;
    &lt;head rend="h4"&gt;Memtest86+&lt;/head&gt;
    &lt;p&gt;I always use Memtest86+ to burn-in the RAM. I always run at least 3+ passes of Memtest86+. Typically, I run many more passes because I tend to let the system keep running additional passes overnight. Secondarily, running these many passes give the CPU a little bit of work to do and there√¢s enough information displayed by Memtest86+ to give me confidence in the CPU and its settings.&lt;/p&gt;
    &lt;head rend="h4"&gt;Hard Drives&lt;/head&gt;
    &lt;p&gt;The failure rate of hard drives is highest when the drives are new and then again when they√¢re old. Regardless of type of hard drives that I buy or when I buy them, I always do some disk burn in. I tend to run Spearfoot√¢s Disk Burn-in and Testing script on all of my new drives. However executing this script against all of the drives can take quite a long time, even if you use something like &lt;code&gt;tmux&lt;/code&gt; to run the tests in parallel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Initial TrueNAS CE Setup&lt;/head&gt;
    &lt;p&gt;There√¢s always a little bit of setup that I do for a new TrueNAS machine. This isn√¢t intended to be an all inclusive step-by-step guide for all the things you should do with your DIY NAS. Instead, it√¢s more of a list of things I kept track of while I made sure that the DIY NAS: 2026 Edition was functional enough for me to finish writing this blog. That being said, I do think your NAS would be rather functional if you decided to do the same configuration.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Updated the hostname to &lt;code&gt;diynas2026&lt;/code&gt;&lt;list rend="ol"&gt;&lt;item&gt;Note: This is only to avoid issues with another NAS on my network.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Updated the timezone.&lt;/item&gt;
      &lt;item&gt;Enabled the following services and set them to start automatically. &lt;list rend="ol"&gt;&lt;item&gt;SMB&lt;/item&gt;&lt;item&gt;SSH&lt;/item&gt;&lt;item&gt;NFS&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Enabled password login for the &lt;code&gt;truenas_admin&lt;/code&gt;user.&lt;list rend="ul"&gt;&lt;item&gt;Note: If I were planning to use this DIY NAS long-term, I wouldn√¢t have done this. Using SSH keys for authentication is a better idea.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Edited the TrueNAS Dashboard widgets to reflect the 10Gb interface (&lt;code&gt;enp1s0&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Created a pool named &lt;code&gt;flash&lt;/code&gt;which consisted of mirrored vdev using the Teamgroup MP44 1TB NVMe SSDs.&lt;/item&gt;
      &lt;item&gt;Created a pool named &lt;code&gt;rust&lt;/code&gt;which consisted of a single RAID-Z2 vdev using eight hard drives that I had sitting on my shelf after they were decomissioned.&lt;/item&gt;
      &lt;item&gt;Configured the Apps to use the &lt;code&gt;flash&lt;/code&gt;pool for the apps√¢ dataset.&lt;/item&gt;
      &lt;item&gt;Made sure that the System Dataset Pool was set to &lt;code&gt;flash&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Confirmed that there were Scrub Tasks set up for the &lt;code&gt;flash&lt;/code&gt;and&lt;code&gt;rust&lt;/code&gt;pools.&lt;/item&gt;
      &lt;item&gt;Created a dataset on each pool for testing; &lt;code&gt;flash-test&lt;/code&gt;and&lt;code&gt;rust-test&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Installed the Scrutiny app found in the App Catalog.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If I were planning to keep this NAS and use it for my own purposes, I would also:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set up a Let√¢s Encrypt certificate.&lt;/item&gt;
      &lt;item&gt;Hook up the NAS to a compatible UPS, enable the UPS service, and configure the UPS service to shut down the NAS before the battery runs out of juice.&lt;/item&gt;
      &lt;item&gt;Set up system email alert service.&lt;/item&gt;
      &lt;item&gt;Create replication tasks to back up critical data to my off-site NAS.&lt;/item&gt;
      &lt;item&gt;Add the new NAS to my Tailscale tailnet using the Tailscale app from the official catalog.&lt;/item&gt;
      &lt;item&gt;As the NAS is seeded with data, create and maintain a suite of snapshot tasks tailored to the importance of the different data being stored on the NAS.&lt;/item&gt;
      &lt;item&gt;Set up S.M.A.R.T. tests for all of the drives: &lt;list rend="ol"&gt;&lt;item&gt;Weekly Short Test&lt;/item&gt;&lt;item&gt;Monthly Long Test&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;Just about every year, I benchmark each DIY NAS build and almost always come to the same conclusion; the NAS will outperform your network at home. Your first bottleneck is almost always going to be the network and the overlwhelming majority of us have gigabit networks at home√¢but that√¢s slowly changing since 2.5Gbps and 10Gbps network hardware has started to get reasonable lately.&lt;/p&gt;
    &lt;p&gt;Even though I always come to the same conclusion, I still like to do the benchmarks for two reasons:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;It helps me build confidence that the DIY NAS: 2026 Edition works well.&lt;/item&gt;
      &lt;item&gt;People tend to enjoy consuming benchmarks and it√¢s fun for me to see the DIY NAS√¢ network card get saturated during the testing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Throughput&lt;/head&gt;
    &lt;p&gt;I like to do three categories of tests to measure the throughput of the NAS:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Use iperf3 to benchmark throughput between my NAS and another machine on my network.&lt;/item&gt;
      &lt;item&gt;Benchmark the throughput of the pool(s) locally on the NAS using &lt;code&gt;fio&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Set up SMB shares on each of the pools and then benchmark the throughput when using those shares.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Every year I try and mention that Tom Lawrence from Lawrence Systems published a great video about benchmarking storage with FIO and shared the FIO commands from his video in their forums. I use these FIO commands constantly as a reference point for testing ZFS pools√¢ throughput. Importantly I√¢d like to point out that, in that same video, Tom says something very wise:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Tool&lt;/cell&gt;
        &lt;cell role="head"&gt;Pool&lt;/cell&gt;
        &lt;cell role="head"&gt;Test&lt;p&gt;Size&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Random&lt;p&gt;Write&lt;/p&gt;&lt;p&gt;IOPS&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Random&lt;p&gt;Read&lt;/p&gt;&lt;p&gt;IOPS&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Sequential&lt;p&gt;Write&lt;/p&gt;&lt;p&gt;(MB/s)&lt;/p&gt;&lt;/cell&gt;
        &lt;cell role="head"&gt;Sequential&lt;p&gt;Read&lt;/p&gt;&lt;p&gt;(MB/s)&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4G&lt;/cell&gt;
        &lt;cell&gt;1906.00&lt;/cell&gt;
        &lt;cell&gt;2200.00&lt;/cell&gt;
        &lt;cell&gt;548.00&lt;/cell&gt;
        &lt;cell&gt;1214.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32G&lt;/cell&gt;
        &lt;cell&gt;2132.00&lt;/cell&gt;
        &lt;cell&gt;3012.00&lt;/cell&gt;
        &lt;cell&gt;544.00&lt;/cell&gt;
        &lt;cell&gt;1211.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4G&lt;/cell&gt;
        &lt;cell&gt;1352.00&lt;/cell&gt;
        &lt;cell&gt;108.00&lt;/cell&gt;
        &lt;cell&gt;367.00&lt;/cell&gt;
        &lt;cell&gt;530.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FIO&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32G&lt;/cell&gt;
        &lt;cell&gt;1474.00&lt;/cell&gt;
        &lt;cell&gt;326.00&lt;/cell&gt;
        &lt;cell&gt;368.00&lt;/cell&gt;
        &lt;cell&gt;544.00&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GiB&lt;/cell&gt;
        &lt;cell&gt;5858.89&lt;/cell&gt;
        &lt;cell&gt;50409.91&lt;/cell&gt;
        &lt;cell&gt;1104.64&lt;/cell&gt;
        &lt;cell&gt;956.70&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;flash&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32GiB&lt;/cell&gt;
        &lt;cell&gt;4193.36&lt;/cell&gt;
        &lt;cell&gt;31047.36&lt;/cell&gt;
        &lt;cell&gt;635.42&lt;/cell&gt;
        &lt;cell&gt;946.20&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;4GiB&lt;/cell&gt;
        &lt;cell&gt;5226.50&lt;/cell&gt;
        &lt;cell&gt;46239.01&lt;/cell&gt;
        &lt;cell&gt;756.23&lt;/cell&gt;
        &lt;cell&gt;655.32&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;CrystalDiskMark&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;rust&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;32GiB&lt;/cell&gt;
        &lt;cell&gt;3794.43&lt;/cell&gt;
        &lt;cell&gt;12809.33&lt;/cell&gt;
        &lt;cell&gt;759.38&lt;/cell&gt;
        &lt;cell&gt;677.02&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;What do I think these benchmarks and my use of the DIY NAS: 2026 Edition tell me? In the grand scheme of things, not a whole lot.&lt;/p&gt;
    &lt;p&gt;However, these benchmarks do back up what I expected, the DIY NAS: 2026 Edition is quite capable and more than ready to meet my storage needs. I especially like that the CrystalDiskMark benchmark of the SMB shares were both faster than a SATA SSD, and the throughput to the share on the &lt;code&gt;flash&lt;/code&gt; pool practically saturated the NAS√¢ 10GbE network connection.&lt;/p&gt;
    &lt;head rend="h4"&gt;FIO Tests&lt;/head&gt;
    &lt;p&gt;Every time I benchmark a NAS, I seem to either be refining what I tried in prior years or completely reinventing the wheel. As a result, I wouldn√¢t recommend comparing these results with results that I shared in prior years√¢ DIY NAS build blogs. I haven√¢t really put a ton of effort into developing a standard suite of benchmarks. Things in my homelab change enough between DIY NAS blogs that trying to create and maintain an environment for a standard suite of benchmarks is beyond what my budget, spare time, and attention span will allow.&lt;/p&gt;
    &lt;p&gt;I√¢m going to paste these &lt;code&gt;fio&lt;/code&gt; commands here in the blog for my own use in future DIY NAS build blogs. If you wind up building something similar, these might be helpful to measure your new NAS√¢ filesystem√¢s performance and compare it to mine!&lt;/p&gt;
    &lt;code&gt;## Random Write IOPS
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=4G --readwrite=randwrite --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=32G --readwrite=randwrite --ramp_time=10

## Random Read IOPS
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=4G --readwrite=randread --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=128k --size=32G --readwrite=randread --ramp_time=10

## Sequential Write (MB/s)
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=4M --size=4G --readwrite=write --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1 --name=test --filename=test --bs=4M --size=32G --readwrite=write --ramp_time=10

## Sequential Read (MB/s)
fio --randrepeat=1 --ioengine=libaio --direct=1  --name=test --filename=test --bs=4M --size=4G --readwrite=read --ramp_time=10
fio --randrepeat=1 --ioengine=libaio --direct=1  --name=test --filename=test --bs=4M --size=32G --readwrite=read --ramp_time=10
&lt;/code&gt;
    &lt;head rend="h3"&gt;Power Consumption&lt;/head&gt;
    &lt;p&gt;One not-so-obvious cost of running a DIY NAS is how much power it consumes. While I specifically tried to pick items that were efficient in terms of power consumption, it√¢s also important to realize that all the other bells and whistles on the awesome Topton N18 NAS motherboard consume power, too. And that the biggest consumer of power in a NAS is almost always the hard disk drives.&lt;/p&gt;
    &lt;p&gt;Thanks to my tinkering with home automation, I have a plethora of smart outlets which are capable of power monitoring. I used those smart outlets for most of my power monitoring. But I also have a Kill a Watt P400 that I also use for some of the shorter tests:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Power consumed during a handful of specific tasks: &lt;list rend="ul"&gt;&lt;item&gt;Idle while running TrueNAS&lt;/item&gt;&lt;item&gt;RAM Burn-in (~14 passes of Memtest86+)&lt;/item&gt;&lt;item&gt;An 8-hour throughput benchmark copying randomly-sized files to the NAS using SMB.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Total consumed during the build, burn-in, and use of the DIY NAS: 2026 Edition.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Duration&lt;/cell&gt;
        &lt;cell role="head"&gt;Max Wattage&lt;/cell&gt;
        &lt;cell role="head"&gt;Avg. Wattage&lt;/cell&gt;
        &lt;cell role="head"&gt;Total Consumption&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Boot&lt;/cell&gt;
        &lt;cell&gt;10 min.&lt;/cell&gt;
        &lt;cell&gt;200.00 W&lt;/cell&gt;
        &lt;cell&gt;120.00 W&lt;/cell&gt;
        &lt;cell&gt;0.02 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Idle&lt;/cell&gt;
        &lt;cell&gt;3 hr.&lt;/cell&gt;
        &lt;cell&gt;90.00 W&lt;/cell&gt;
        &lt;cell&gt;66.67 W&lt;/cell&gt;
        &lt;cell&gt;0.20 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;RAM Burn-in&lt;/cell&gt;
        &lt;cell&gt;18 hr.&lt;/cell&gt;
        &lt;cell&gt;104.00 W&lt;/cell&gt;
        &lt;cell&gt;91.67 W&lt;/cell&gt;
        &lt;cell&gt;1.65 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;SMB Benchmark of HDDs&lt;/cell&gt;
        &lt;cell&gt;8 hr.&lt;/cell&gt;
        &lt;cell&gt;107.00 W&lt;/cell&gt;
        &lt;cell&gt;85.00 W&lt;/cell&gt;
        &lt;cell&gt;0.68 kWh&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;108 hr.&lt;/cell&gt;
        &lt;cell&gt;237.80 W&lt;/cell&gt;
        &lt;cell&gt;66.49 W&lt;/cell&gt;
        &lt;cell&gt;7.17 kWh&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;What about an EconoNAS?&lt;/head&gt;
    &lt;p&gt;Shortly before prices skyrocketed, I decided I wasn√¢t very interested in doing a separate EconoNAS builds. Several months ago, I realized that there were several off-the-shelf NAS machines that were more-than-capable of running TrueNAS and they were selling at economical prices that couldn√¢t be topped by a DIY approach. I will dive deeper into this in a future blog, eventually √¢¬¶ maybe?&lt;/p&gt;
    &lt;p&gt;All that being said√¢it√¢d be incredibly easy to make some compromises which result in the DIY NAS: 2026 Edition becoming quite a bit more economical. Here√¢s a list of changes that I would consider to be more budget-friendly:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Different motherboard/CPU combo: N18 w/ N100 CPU (-$224), N18 w/ N150 CPU (-$214), or N22 w/ N150 CPU (-$180)&lt;/item&gt;
      &lt;item&gt;16GB of DDR5 RAM (-$39) instead of 32GB.&lt;/item&gt;
      &lt;item&gt;Thermal Right TL-C12015 Slim Fan instead of the Noctua NF-A12x25 (-$26)&lt;/item&gt;
      &lt;item&gt;Apevia SFX-AP500W Power Supply (-$104)&lt;/item&gt;
      &lt;item&gt;Skip the redundancy for the boot pool (-$22)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Altogether, these savings could add up to more than $400, which is pretty considerable! If you made all of these changes, you√¢d have something that√¢s going to be nearly equivalent to the DIY NAS: 2026 Edition but at a fraction of the price.&lt;/p&gt;
    &lt;head rend="h2"&gt;What am I going to do with the DIY NAS: 2026 Edition?!&lt;/head&gt;
    &lt;p&gt;My DIY NAS is aging quite gracefully, but I√¢ve recently been wondering about replacing it. Shortly before ordering all the parts for the DIY NAS: 2026 Edition, I briefly considered using this year√¢s DIY NAS build to replace my personal NAS. However, I decided not to do that. Then prices skyrocketed and I shelved the idea of building a replacement for my own NAS and I nearly shelved the idea of a DIY NAS in 2026!&lt;/p&gt;
    &lt;p&gt;So that begs the question, √¢What is Brian going to do with the DIY NAS: 2026 Edition?√¢&lt;/p&gt;
    &lt;p&gt;I√¢m going to auction it off on the briancmosesdotcom store on eBay! Shortly after publishing this blog, I√¢ll list it on eBay. In response to skyrocketing prices for PC components, I√¢m going to do a no-reserve auction. At the end of the auction, the highest bidder wins and hopefully they√¢ll get a pretty good deal!&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts&lt;/head&gt;
    &lt;p&gt;Overall, I√¢m pleased with the DIY NAS: 2026 Edition. The Topton N22 motherboard is a significant improvement over last year√¢s Topton N18 motherboard, primarily due to its extra two SATA ports. This provides 33.3% more gross storage capacity.&lt;/p&gt;
    &lt;p&gt;While testing, I found the Intel Core 3 N355 CPU somewhat excessive for basic NAS functions. However, the substantial untapped CPU horsepower offers luxurious performance potential. This makes the build compelling for anyone planning extensive self-hosting projects.&lt;/p&gt;
    &lt;p&gt;I have mixed feelings about the JONSBO N4 case. The four right-side drive bays lack SATA backplane connectivity. Without creative cabling solutions, individual drive replacement becomes challenging. However, the case√¢s ~$125 price point compensates for this inconvenience. I anticipate that those the cost savings will justify the compromise for most builders. If I were to build the DIY NAS: 2026 Edition all over again, I√¢d be tempted to use the JONSBO N3 case or even the JONSBO N6 which isn√¢t quite obtainable, yet.&lt;/p&gt;
    &lt;p&gt;The DIY NAS: 2026 Edition delivers excellent performance and superior specifications. In my opinion, it represents better value than off-the-shelf alternatives:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;QNAP TS-832PX-4G ($880)&lt;/item&gt;
      &lt;item&gt;Asustor Lockerstor 8 AS6508T ($960)&lt;/item&gt;
      &lt;item&gt;UGREEN NASync DXP8800 ($1200)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Building your own NAS provides significant advantages. Years later, you can upgrade RAM, motherboard, case, or add PCI-e (x1) expansion cards. These off-the-shelf alternatives offer severely limited upgrade paths.&lt;/p&gt;
    &lt;p&gt;Is 2026 finally the year that you decide to build your DIY NAS? I hope that it is! Share your experience building your NAS in the comments below or come tell us about it in the #diynas-and-homelab channel on the Butter, What?! Discord server!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.briancmoses.com/2025/11/diy-nas-2026-edition.html"/><published>2025-11-27T02:54:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065698</id><title>Coq: The World's Best Macro Assembler? [pdf] [2013]</title><updated>2025-11-27T11:09:40.737730+00:00</updated><content/><link href="https://nickbenton.name/coqasm.pdf"/><published>2025-11-27T04:34:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065817</id><title>Music eases surgery and speeds recovery, study finds</title><updated>2025-11-27T11:09:40.386216+00:00</updated><content>&lt;doc fingerprint="adb964f948bf9fcf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Music eases surgery and speeds recovery, Indian study finds&lt;/head&gt;
    &lt;p&gt;Under the harsh lights of an operating theatre in the Indian capital, Delhi, a woman lies motionless as surgeons prepare to remove her gallbladder.&lt;/p&gt;
    &lt;p&gt;She is under general anaesthesia: unconscious, insensate and rendered completely still by a blend of drugs that induce deep sleep, block memory, blunt pain and temporarily paralyse her muscles.&lt;/p&gt;
    &lt;p&gt;Yet, amid the hum of monitors and the steady rhythm of the surgical team, a gentle stream of flute music plays through the headphones placed over her ears.&lt;/p&gt;
    &lt;p&gt;Even as the drugs silence much of her brain, its auditory pathway remains partly active. When she wakes up, she will regain consciousness more quickly and clearly because she required lower doses of anaesthetic drugs such as propofol and opioid painkillers than patients who heard no music.&lt;/p&gt;
    &lt;p&gt;That, at least, is what a new peer-reviewed study from Delhi's Maulana Azad Medical College and Lok Nayak Hospital suggests. The research, published in the journal Music and Medicine, offers some of the strongest evidence yet that music played during general anaesthesia can modestly but meaningfully reduce drug requirements and improve recovery.&lt;/p&gt;
    &lt;p&gt;The study focuses on patients undergoing laparoscopic cholecystectomy, the standard keyhole operation to remove the gallbladder. The procedure is short - usually under an hour - and demands a particularly swift, "clear-headed" recovery.&lt;/p&gt;
    &lt;p&gt;To understand why the researchers turned to music, it helps to decode the modern practice of anaesthesia.&lt;/p&gt;
    &lt;p&gt;"Our aim is early discharge after surgery," says Dr Farah Husain, senior specialist in anaesthesia and certified music therapist for the study. "Patients need to wake up clear-headed, alert and oriented, and ideally pain-free. With better pain management, the stress response is curtailed."&lt;/p&gt;
    &lt;p&gt;Achieving that requires a carefully balanced mix of five or six drugs that together keep the patient asleep, block pain, prevent memory of the surgery and relax the muscles.&lt;/p&gt;
    &lt;p&gt;In procedures like laparoscopic gallbladder removal, anaesthesiologists now often supplement this drug regimen with regional "blocks" - ultrasound-guided injections that numb nerves in the abdominal wall.&lt;/p&gt;
    &lt;p&gt;"General anaesthesia plus blocks is the norm," says Dr Tanvi Goel, primary investigator and a former senior resident of Maulana Azad Medical College. "We've been doing this for decades."&lt;/p&gt;
    &lt;p&gt;But the body does not take to surgery easily. Even under anaesthesia, it reacts: heart rate rises, hormones surge, blood pressure spikes. Reducing and managing this cascade is one of the central goals of modern surgical care. Dr Husain explains that the stress response can slow recovery and worsen inflammation, highlighting why careful management is so important.&lt;/p&gt;
    &lt;p&gt;The stress starts even before the first cut, with intubation - the insertion of a breathing tube into the windpipe.&lt;/p&gt;
    &lt;p&gt;To do this, the anaesthesiologist uses a laryngoscope to lift the tongue and soft tissues at the base of the throat, obtain a clear view of the vocal cords, and guide the tube into the trachea. It's a routine step in general anaesthesia that keeps the airway open and allows precise control of the patient's breathing while they are unconscious.&lt;/p&gt;
    &lt;p&gt;"The laryngoscopy and intubation are considered the most stressful response during general anaesthesia," says Dr Sonia Wadhawan, director-professor of anaesthesia and intensive care at Maulana Azad Medical College and supervisor of the study.&lt;/p&gt;
    &lt;p&gt;"Although the patient is unconscious and will remember nothing, their body still reacts to the stress with changes in heart rate, blood pressure, and stress hormones."&lt;/p&gt;
    &lt;p&gt;To be sure, the drugs have evolved. The old ether masks have vanished. In their place are intravenous agents - most notably propofol, the hypnotic made infamous by Michael Jackson's death but prized in operating theatres for its rapid onset and clean recovery. "Propofol acts within about 12 seconds," notes Dr Goel. "We prefer it for short surgeries like laparoscopic cholecystectomy because it avoids the 'hangover' caused by inhalational gases."&lt;/p&gt;
    &lt;p&gt;The team of researchers wanted to know whether music could reduce how much propofol and fentanyl (an opioid painkiller) patients required. Less drugs means faster awakening, steadier vital signs and reduced side effects.&lt;/p&gt;
    &lt;p&gt;So they designed a study. A pilot involving eight patients led to a full 11-month trial of 56 adults, aged roughly 20 to 45, randomly assigned to two groups. All received the same five-drug regimen: a drug that prevents nausea and vomiting, a sedative, fentanyl, propofol and a muscle relaxant. Both groups wore noise-cancelling headphones - but only one heard music.&lt;/p&gt;
    &lt;p&gt;"We asked patients to select from two calming instrumental pieces - soft flute or piano," says Dr Husain. "The unconscious mind still has areas that remain active. Even if the music isn't explicitly recalled, implicit awareness can lead to beneficial effects."&lt;/p&gt;
    &lt;p&gt;The results were striking.&lt;/p&gt;
    &lt;p&gt;Patients exposed to music required lower doses of propofol and fentanyl. They experienced smoother recoveries, lower cortisol or stress-hormone levels and a much better control of blood pressure during the surgery. "Since the ability to hear remains intact under anaesthesia," the researchers write, "music can still shape the brain's internal state."&lt;/p&gt;
    &lt;p&gt;Clearly, music seemed to quieten the internal storm. "The auditory pathway remains active even when you're unconscious," says Dr Wadhawan. "You may not remember the music, but the brain registers it."&lt;/p&gt;
    &lt;p&gt;The idea that the mind behind the anaesthetic veil is not entirely silent has long intrigued scientists. Rare cases of "intraoperative awareness" show patients recalling fragments of operating-room conversation.&lt;/p&gt;
    &lt;p&gt;If the brain is capable of picking up and remembering stressful experiences during surgery - even when a patient is unconscious - then it might also be able to register positive or comforting experiences, like music, even without conscious memory.&lt;/p&gt;
    &lt;p&gt;"We're only beginning to explore how the unconscious mind responds to non-pharmacological interventions like music," says Dr Husain. "It's a way of humanising the operating room."&lt;/p&gt;
    &lt;p&gt;Music therapy is not new to medicine; it has long been used in psychiatry, stroke rehabilitation and palliative care. But its entry into the intensely technical, machine-governed world of anaesthesia marks a quiet shift.&lt;/p&gt;
    &lt;p&gt;If such a simple intervention can reduce drug use and speed recovery - even modestly - it could reshape how hospitals think about surgical wellbeing.&lt;/p&gt;
    &lt;p&gt;As the research team prepares its next study exploring music-aided sedation, building on earlier findings, one truth is already humming through the data: even when the body is still and the mind asleep, it appears a few gentle notes can help the healing begin.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c231dv9zpz3o"/><published>2025-11-27T04:55:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065870</id><title>$96M AUD revamp of Bom website bombs out on launch</title><updated>2025-11-27T11:09:40.161266+00:00</updated><content>&lt;doc fingerprint="ae03e2101c4864d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Australia's beloved weather website got a makeover - and infuriated users&lt;/head&gt;
    &lt;p&gt;It was an unseasonably warm spring day in Sydney on 22 October, with a forecast of 39C (99F) - a real scorcher.&lt;/p&gt;
    &lt;p&gt;The day before, the state of New South Wales had reported its hottest day in over a century, a high of 44.8C in the outback town of Bourke.&lt;/p&gt;
    &lt;p&gt;But little did the team at the national Bureau of Meteorology foresee that they, in particular, would soon be feeling the heat.&lt;/p&gt;
    &lt;p&gt;Affectionately known by Australians as the Bom, the agency's long-awaited website redesign went live that morning, more than a decade after the last update.&lt;/p&gt;
    &lt;p&gt;Within hours, the Bom was flooded with a deluge of complaints. The hashtag #changeitback went viral.&lt;/p&gt;
    &lt;p&gt;Gripes ranged from the new colour scheme for the rain radar, to furious farmers and fishermen who could no longer put in GPS coordinates to find forecasts for a specific location.&lt;/p&gt;
    &lt;p&gt;And then, this week it was revealed that the site's redesign had cost about A$96.5m ($62.3m; ¬£48m), 20 times more than the previously stated A$4.1m.&lt;/p&gt;
    &lt;p&gt;"First you violate expectations by making something worse, then you compound the injury by revealing the violation was both expensive and avoidable," psychologist and neuroscientist Joel Pearson told the BBC, explaining the public outrage.&lt;/p&gt;
    &lt;p&gt;"It's the government IT project equivalent of ordering a renovation, discovering the contractor has made your house less functional, and then learning they charged you for a mansion."&lt;/p&gt;
    &lt;head rend="h2"&gt;'Game of hide and seek'&lt;/head&gt;
    &lt;p&gt;A consensus was quickly clear: "Please bring back the previous format," one person surmised on social media.&lt;/p&gt;
    &lt;p&gt;"It's awful, the most useful features are gone and it's not user-friendly. A waste of taxpayer money," another added.&lt;/p&gt;
    &lt;p&gt;Others said the timing was poor: "Why change it on a day of severe weather?"&lt;/p&gt;
    &lt;p&gt;There were some fans, including one who posted: "I like the new site. The front page is much cleaner". But they were few and far between.&lt;/p&gt;
    &lt;p&gt;Less than 48 hours after the launch, the Bom released a list of tips on how to use the new site, but this was further mocked by disgruntled users.&lt;/p&gt;
    &lt;p&gt;"Terrible! You shouldn't need step-by-step instructions to navigate the site," one post read.&lt;/p&gt;
    &lt;p&gt;With more than 2.6 billion views a year, Bom tried to explain that the site's refresh - prompted by a major cybersecurity breach in 2015 - was aimed at improving stability, security and accessibility. It did little to satisfy the public.&lt;/p&gt;
    &lt;p&gt;Some frustrated users turned to humour: "As much as I love a good game of hide and seek, can you tell us where you're hiding synoptic charts or drop some clues?"&lt;/p&gt;
    &lt;p&gt;Malcolm Taylor, an agronomist in Victoria, told the Australian Broadcasting Corporation (ABC) that the redesign was a complete disaster.&lt;/p&gt;
    &lt;p&gt;"I'm the person who needs it and it's not giving me the information I need," the plant and soil scientist said.&lt;/p&gt;
    &lt;p&gt;Others appeared to accept their fate: "I am sure we will get used to it but it is not intuitive at all."&lt;/p&gt;
    &lt;p&gt;Exactly a week after the debacle, the acting head of the agency was forced to apologise. There were concerns that people had been underprepared for storms in Queensland because of the site's poor usability.&lt;/p&gt;
    &lt;p&gt;The outpouring prompted the federal government to issue a scathing rebuke of the Bom and order immediate changes to the site.&lt;/p&gt;
    &lt;p&gt;"The bureau clearly has work to do, in that it has lost community confidence in the new website," Energy Minister Chris Bowen said at the time.&lt;/p&gt;
    &lt;p&gt;In a bid to calm the storm, parts of the previous site were brought back to life, giving people the option to use the old features.&lt;/p&gt;
    &lt;p&gt;A month after the relaunch, the new head of the Bom - who started his role during the saga - admitted the changes had been "challenging for some" and again apologised for the confusion.&lt;/p&gt;
    &lt;p&gt;"Inherently, we don't, and won't, always get it perfectly right. But, we are constantly striving to get better," Dr Stuart Minchin said.&lt;/p&gt;
    &lt;p&gt;But he kicked off another round of criticism by revealing the revamp actually cost $96m, a figure which covered a full website rebuild and testing of the "systems and technology that underpin" it.&lt;/p&gt;
    &lt;p&gt;Immediately, the government demanded Bom explain how taxpayers' money had been spent "efficiently and appropriately," according to the Sydney Morning Herald.&lt;/p&gt;
    &lt;p&gt;Barnaby Joyce, a member of the Nationals, which mainly represents regional communities, said: "We spent $96m to put a B at the end of the Bom site. It's now bomb, it's hopeless."&lt;/p&gt;
    &lt;head rend="h2"&gt;New site 'scrambling' people's brains&lt;/head&gt;
    &lt;p&gt;On the day of the launch, the Bom assured Australians that the community had been consulted on the changes. A test site in the months leading up to the relaunch found customer satisfaction rates were consistently above 70%, they told the BBC.&lt;/p&gt;
    &lt;p&gt;"The tsunami of complaints suggests that consultation was either perfunctory or they listened to the wrong people," Mr Pearson said.&lt;/p&gt;
    &lt;p&gt;For years, farmers and emergency workers had developed what neuroscientists call "procedural memory" for reading weather patterns using the site, he explained. It's muscle memory like touch-typing or driving a familiar route home.&lt;/p&gt;
    &lt;p&gt;"Your fingers know where the keys are, your hands know when to turn."&lt;/p&gt;
    &lt;p&gt;But when the new site changed the radar's colour scale, long-time users were left scratching their heads as their "hard-won intuition for reading storm intensity became unreliable overnight".&lt;/p&gt;
    &lt;p&gt;The new site, Mr Pearson said, "was scrambling the neurological shortcuts that people had spent a decade building".&lt;/p&gt;
    &lt;p&gt;"It's like rearranging all the furniture in your house and then expecting you to navigate it in the dark without stubbing your toe. Except the 'furniture' in this case determines whether you move your livestock before the flood arrives."&lt;/p&gt;
    &lt;p&gt;For sociologist Ash Watson, the collective reaction to the site reflected its special status in Australia.&lt;/p&gt;
    &lt;p&gt;"Australia has always been a large country of weather extremes, and Bom's cultural importance has really been cemented in recent years as we've experienced more severe weather and the rising impacts of climate change."&lt;/p&gt;
    &lt;p&gt;As a regular user of Bom's site, Ms Watson acknowledged the good intentions behind the changes, but said her research - on the social impact of tech - showed that people are getting fatigued by change.&lt;/p&gt;
    &lt;p&gt;"It can be hard for people to get excited by new updates and see their immediate benefits when they don't want to have to learn how to use yet another new platform, app or website."&lt;/p&gt;
    &lt;p&gt;This is not the first time the Bom has weathered a publicity storm.&lt;/p&gt;
    &lt;p&gt;In 2022, it spent hundreds of thousands of dollars on a rebrand, asking to be called either its full name or "the bureau", not the "weather bureau" or "the Bom", given the negative connotations.&lt;/p&gt;
    &lt;p&gt;But the campaign was short-lived. They eventually released a statement saying the public was welcome to use whatever name they wished.&lt;/p&gt;
    &lt;p&gt;The incident reflected a fundamental misunderstanding of how the culture of naming works, Mr Pearson said.&lt;/p&gt;
    &lt;p&gt;Australians had organically adopted "Bom" as a term of affection, like a nickname for a friend, he said.&lt;/p&gt;
    &lt;p&gt;"When the institution tried to correct this, it felt like being told you're pronouncing your mate's name wrong."&lt;/p&gt;
    &lt;p&gt;He said the site's redesign revealed a similar "cultural blindness but with higher stakes".&lt;/p&gt;
    &lt;p&gt;In a statement, Bom's spokesperson told the BBC it had received about 400,000 items of feedback on the new site, which accounted for less than 1% of the 55 million visits in the past month.&lt;/p&gt;
    &lt;p&gt;The responses were "both positive and negative", they said, with fans saying they liked the new design and presentation, the accuracy and reliability of the forecasts, and greater ease in using the site on different types of mobile devices.&lt;/p&gt;
    &lt;p&gt;But it was clear that people had "formed strong habits", the spokesperson said, and further changes may be made based on the feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/news/articles/c2k4dy15nqqo"/><published>2025-11-27T05:05:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065959</id><title>Evaluating Uniform Memory Access Mode on AMD's Turin</title><updated>2025-11-27T11:09:39.935172+00:00</updated><content>&lt;doc fingerprint="23bad9ba781048cd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Evaluating Uniform Memory Access Mode on AMD's Turin ft. Verda (formerly DataCrunch.io)&lt;/head&gt;
    &lt;head rend="h3"&gt;How does uniform memory access play out as interconnects get increasingly non-uniform?&lt;/head&gt;
    &lt;p&gt;NUMA, or Non-Uniform Memory Access, lets hardware expose affinity between cores and memory controllers to software. NUMA nodes traditionally aligned with socket boundaries, but modern server chips can subdivide a socket into multiple NUMA nodes. It‚Äôs a reflection of how non-uniform interconnects get as core and memory controller counts keep going up. AMD designates their NUMA modes with the NPS (Nodes Per Socket) prefix.&lt;/p&gt;
    &lt;p&gt;NPS0 is a special NUMA mode that goes in the other direction. Rather than subdivide the system, NPS0 exposes a dual socket system as a single monolithic entity. It evenly distributes memory accesses across all memory controller channels, providing uniform memory access like in a desktop system. NPS0 and similar modes exist because optimizing for NUMA can be complicated and time intensive. Programmers have to specify a NUMA node for each memory allocation, and take are to minimize cross-node memory accesses. Each NUMA node only represents a fraction of system resources, so code pinned to a NUMA node will be constrained by that node‚Äôs CPU core count, memory bandwidth, and memory capacity. Effort spent getting an application to scale across NUMA nodes might be effort not spent on a software project‚Äôs other goals.&lt;/p&gt;
    &lt;head rend="h1"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;A massive thank you goes to Verda (formerly DataCrunch) for proving an instance with 2 AMD EPYC 9575Fs and 8 Nvidia B200 GPUs. Verda gave us about 3 weeks with the instance to do with as we wished. While this article looks at the AMD EPYC 9575Fs, there will be upcoming coverage of the B200s found in the VM.&lt;/p&gt;
    &lt;p&gt;This system appears to be running in NPS0 mode, giving an opportunity to see how a modern server acts with 24 memory controllers providing uniform memory access.&lt;/p&gt;
    &lt;p&gt;A simple latency test immediately shows the cost of providing uniform memory access. DRAM latency rises to over 220 ns, giving a nearly 90 ns penalty over the EPYC 9355P running in NPS1 mode. It‚Äôs a high penalty compared to using the equivalent of NPS0 on older systems. For example, a dual socket Broadwell system has 75.8 ns of DRAM latency when each socket is treated as a NUMA node, and 104.6 ns with uniform memory access[1].&lt;/p&gt;
    &lt;p&gt;NPS0 mode does have a bandwidth advantage from bringing twice as many memory controllers into play. But the extra bandwidth doesn‚Äôt translate to a latency advantage until bandwidth demands reach nearly 400 GB/s. The EPYC 9355P seems to suffer when a latency test thread is mixed with bandwidth heavy ones. A bandwidth test thread with just linear read patterns can achieve 479 GB/s in NPS1 mode. However, my bandwidth test produces low values on the EPYC 9575F because not all test threads finish at the same time. I avoid this problem in the loaded memory latency test, because I have bandwidth load threads check a flag. That lets me stop all threads at approximately the same time.&lt;/p&gt;
    &lt;p&gt;Per-CCD bandwidth is barely affected by the different NPS modes. Both the EPYC 9355P and 9575F use ‚ÄúGMI-Wide‚Äù links for their Core Complex Dies, or CCDs. GMI-Wide provides 64B/cycle of read and write bandwidth at the Infinity Fabric clock. On both chips, each CCD enjoys more bandwidth to the system compared to standard ‚ÄúGMI-Narrow‚Äù configurations. For reference, a GMI-Narrow setup running at a typical desktop 2 GHz FCLK would be limited to 64 GB/s of read and 32 GB/s of write bandwidth.&lt;/p&gt;
    &lt;head rend="h1"&gt;Performance: SPEC CPU2017&lt;/head&gt;
    &lt;p&gt;Higher memory latency could lead to lower performance, especially in single threaded workloads. But the EPYC 9575F does surprisingly well in SPEC CPU2017. The EPYC 9575F runs at a higher 5 GHz clock speed, and DRAM latency is only one of many factors that affect CPU performance.&lt;/p&gt;
    &lt;p&gt;Individual workloads show a more complex picture. The EPYC 9575F does best when workloads don‚Äôt miss cache. Then, its high 5 GHz clock speed can shine. 548.exchange2 is an example. On the other hand, workloads that hit DRAM a lot suffer in NPS0 mode. 502.gcc, 505.mcf, and 520.omnetpp see the EPYC 9575F‚Äôs higher clock speed count for nothing, and the higher clocked chip underperforms compared to 4.4 GHz setups with lower DRAM latency.&lt;/p&gt;
    &lt;p&gt;SPEC CPU2017‚Äôs floating point suite also shows diverse behavior. 549.fotonik3d and 554.roms suffer in NPS0 mode as the EPYC 9575F struggles to keep itself fed. 538.imagick plays nicely to the EPYC 9575F‚Äôs advantages. In that test, high cache hitrates let the 9575F‚Äôs higher core throughput shine through.&lt;/p&gt;
    &lt;head rend="h1"&gt;Final Words&lt;/head&gt;
    &lt;p&gt;NPS0 mode performs surprisingly well in a single threaded SPEC CPU2017 run. Some sub-tests suffer from higher memory latency, but enough other tests benefit from the higher 5 GHz clock speed to make up the difference. It‚Äôs a lesson about the importance of clock speeds and good caching in a modern server CPU. Those two factors go together, because faster cores only provide a performance advantage if the memory subsystem can feed them. The EPYC 9575F‚Äôs good overall performance despite having over 220 ns of memory latency shows how good its caching setup is.&lt;/p&gt;
    &lt;p&gt;As for running in NPS0 mode, I don‚Äôt think it‚Äôs worthwhile in a modern system. The latency penalty is very high, and bandwidth gains are minor for NUMA-unaware code. I expect those latency penalties to get worse as server core and memory controller counts continue to increase. For workloads that need to scale across socket boundaries, optimizing for NUMA looks to be an unfortunate necessity.&lt;/p&gt;
    &lt;p&gt;Again, a massive thank you goes to Verda (formerly DataCrunch) without which this article, and the upcoming B200 article, would not be possible!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chipsandcheese.com/p/evaluating-uniform-memory-access"/><published>2025-11-27T05:22:28+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46065997</id><title>Show HN: Era ‚Äì Open-source local sandbox for AI agents</title><updated>2025-11-27T11:09:39.449581+00:00</updated><content>&lt;doc fingerprint="60d6b8bca9f1b8e0"&gt;
  &lt;main&gt;
    &lt;p&gt;Run untrusted or AI-generated code locally inside microVMs that behave like containers for great devX, 200ms launch time, and better security.&lt;/p&gt;
    &lt;p&gt;There's a fully managed cloud layer, globally deployed Worker/API, jump to cloudflare/README.md.&lt;/p&gt;
    &lt;code&gt;# 1. install the tap
brew tap binsquare/era-agent-cli

# 2. install era agent
brew install binsquare/era-agent-cli/era-agent

# 3. install dependencies
brew install krunvm buildah

# 4. verify the CLI is on PATH
agent vm exec --help

# 4. follow platform-specific setup (see below)&lt;/code&gt;
    &lt;code&gt;# 1. install dependencies
brew install krunvm buildah  # on macos

# 2. clone the repository
git clone https://github.com/binsquare/era
cd era-agent

# 3. build the agent
make

# 4. follow platform-specific setup (see below)&lt;/code&gt;
    &lt;code&gt;brew tap binsquare/era-agent-cli
brew install era-agent-cli
brew install krunvm buildah&lt;/code&gt;
    &lt;p&gt;Run the post-install helper to prepare the case-sensitive volume/state dir on macOS:&lt;/p&gt;
    &lt;code&gt;$(brew --prefix era-agent)/libexec/setup/setup.sh&lt;/code&gt;
    &lt;p&gt;if you installed era agent via homebrew, use the setup script from the installed location:&lt;/p&gt;
    &lt;code&gt;# for macos users with homebrew installation
$(brew --prefix era-agent)/libexec/setup/setup.sh

# or run the setup script directly after installation
$(brew --prefix)/bin/era-agent-setup  # if setup script is linked separately&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Run&lt;/p&gt;&lt;code&gt;scripts/macos/setup.sh&lt;/code&gt;to bootstrap dependencies, validate (or create) a case-sensitive volume, and prepare an agent state directory (the script may prompt for your password to run&lt;code&gt;diskutil&lt;/code&gt;). The script will also detect your Homebrew installation and recommend the correct value for the&lt;code&gt;DYLD_LIBRARY_PATH&lt;/code&gt;environment variable, which may be required for&lt;code&gt;krunvm&lt;/code&gt;to find its dynamic libraries.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;If you prefer to create the dedicated volume manually, open a separate terminal and run (with&lt;/p&gt;&lt;code&gt;sudo&lt;/code&gt;as required):&lt;code&gt;diskutil apfs addVolume disk3 "Case-sensitive APFS" krunvm&lt;/code&gt;&lt;p&gt;(replace&lt;/p&gt;&lt;code&gt;disk3&lt;/code&gt;with the identifier reported by&lt;code&gt;diskutil list&lt;/code&gt;). The operation is non-destructive, does not require&lt;code&gt;sudo&lt;/code&gt;, and shares space with the source container volume.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;When prompted by the setup script, accept the default mount point (&lt;/p&gt;&lt;code&gt;/Volumes/krunvm&lt;/code&gt;) or provide your own. Afterwards, export the environment variables printed by the script (at minimum&lt;code&gt;AGENT_STATE_DIR&lt;/code&gt;,&lt;code&gt;KRUNVM_DATA_DIR&lt;/code&gt;, and&lt;code&gt;CONTAINERS_STORAGE_CONF&lt;/code&gt;) before invoking&lt;code&gt;agent&lt;/code&gt;or running&lt;code&gt;krunvm&lt;/code&gt;/&lt;code&gt;buildah&lt;/code&gt;directly. The helper now prepares a matching container-storage configuration under the case-sensitive volume so the CLI can run without extra manual steps.&lt;list rend="ul"&gt;&lt;item&gt;The script also writes &lt;code&gt;policy.json&lt;/code&gt;/&lt;code&gt;registries.conf&lt;/code&gt;under the same directory so Buildah doesn't look for root-owned files in&lt;code&gt;/etc/containers&lt;/code&gt;. Export the variables it prints (&lt;code&gt;CONTAINERS_POLICY&lt;/code&gt;,&lt;code&gt;CONTAINERS_REGISTRIES_CONF&lt;/code&gt;) if you invoke Buildah manually.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The script also writes &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Install &lt;code&gt;krunvm&lt;/code&gt;and&lt;code&gt;buildah&lt;/code&gt;using your package manager (the specific installation method may vary)&lt;/item&gt;
      &lt;item&gt;Ensure the system is properly configured to run microVMs (may require kernel modules or specific privileges)&lt;/item&gt;
      &lt;item&gt;Consider setting &lt;code&gt;AGENT_STATE_DIR&lt;/code&gt;to a writable location if running as non-root&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;krunvm&lt;/code&gt;must be installed and available on&lt;code&gt;$PATH&lt;/code&gt;(Homebrew:&lt;code&gt;brew install krunvm&lt;/code&gt;; see upstream docs for other platforms).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;buildah&lt;/code&gt;must also be present because&lt;code&gt;krunvm&lt;/code&gt;shells out to it for OCI image handling.&lt;/item&gt;
      &lt;item&gt;On macOS, &lt;code&gt;krunvm&lt;/code&gt;requires a case-sensitive APFS volume; see the macOS setup notes above.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;make          # builds the agent CLI
make clean    # removes build artifacts (Go cache)
&lt;/code&gt;
    &lt;p&gt;Full platform-specific steps (macOS volume setup, Linux env vars, troubleshooting) live in era-agent/README.md.&lt;/p&gt;
    &lt;p&gt;A demo video showing how to install and use the CLI tool is available in the era-agent directory. This video covers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Installing dependencies and compiling the CLI tool&lt;/item&gt;
      &lt;item&gt;Creating and accessing local VMs&lt;/item&gt;
      &lt;item&gt;Running code and agents through commands or scripts&lt;/item&gt;
      &lt;item&gt;Uploading and downloading files to/from a VM&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# create a long-running VM
agent vm create --language python --cpu 1 --mem 256 --network allow_all

# run something inside it
agent vm exec --vm &amp;lt;id&amp;gt; --cmd "python -c 'print(\"hi\")'"

# ephemeral one-off execution
agent vm temp --language javascript --cmd "node -e 'console.log(42)'"

# inspect / cleanup
agent vm list
agent vm stop --all
agent vm clean --all&lt;/code&gt;
    &lt;p&gt;Supported &lt;code&gt;--language&lt;/code&gt; values: &lt;code&gt;python&lt;/code&gt;, &lt;code&gt;javascript&lt;/code&gt;/&lt;code&gt;node&lt;/code&gt;/&lt;code&gt;typescript&lt;/code&gt;, &lt;code&gt;go&lt;/code&gt;, &lt;code&gt;ruby&lt;/code&gt;. Override the base image with &lt;code&gt;--image&lt;/code&gt; if you need a custom runtime.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;AGENT_STATE_DIR&lt;/code&gt;: writable directory for VM metadata, krunvm state, and Buildah storage. The macOS setup script prints the correct exports.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;AGENT_LOG_LEVEL&lt;/code&gt;(&lt;code&gt;debug|info|warn|error&lt;/code&gt;) and&lt;code&gt;AGENT_LOG_FILE&lt;/code&gt;: control logging.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;AGENT_ENABLE_GUEST_VOLUMES=1&lt;/code&gt;: re-enable&lt;code&gt;/in&lt;/code&gt;,&lt;code&gt;/out&lt;/code&gt;,&lt;code&gt;/persist&lt;/code&gt;mounts for advanced workflows.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See era-agent/README.md for every tunable.&lt;/p&gt;
    &lt;code&gt;cd era-agent
make agent
./agent vm temp --language python --cmd "python -c 'print(\"Smoke test\")'"&lt;/code&gt;
    &lt;p&gt;Integration helpers and sample recipes live under &lt;code&gt;examples/&lt;/code&gt;, &lt;code&gt;recipes/&lt;/code&gt;, and &lt;code&gt;docs/&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;To deploy ERA as a Cloudflare Worker with Durable Object-backed sessions and HTTP APIs:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Follow cloudflare/README.md for setup, local Wrangler dev, and deployment.&lt;/item&gt;
      &lt;item&gt;The Worker reuses the same Go agent primitives but adds session orchestration, package caching, and REST endpoints.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;era-agent/README.md ‚Äì detailed CLI usage, setup scripts, troubleshooting.&lt;/item&gt;
      &lt;item&gt;cloudflare/README.md ‚Äì Worker/API deployment guide.&lt;/item&gt;
      &lt;item&gt;docs/ ‚Äì HTTP quickstart, storage notes, MCP adapters.&lt;/item&gt;
      &lt;item&gt;recipes/README.md ‚Äì ready-to-run workflows.&lt;/item&gt;
      &lt;item&gt;examples/README.md ‚Äì language samples.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Apache 2.0&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/BinSquare/ERA"/><published>2025-11-27T05:28:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066126</id><title>Principles of Vasocomputation</title><updated>2025-11-27T11:09:38.879608+00:00</updated><content>&lt;doc fingerprint="be4b450aa1a383ba"&gt;
  &lt;main&gt;
    &lt;p&gt;A unification of Buddhist phenomenology, active inference, and physical reflexes; a practical theory of suffering, tension, and liberation; the core mechanism for medium-term memory and Bayesian updating; a clinically useful dimension of variation and dysfunction; a description of sensory type safety; a celebration of biological life.&lt;/p&gt;
    &lt;p&gt;Michael Edward Johnson, Symmetry Institute, July 12, 2023.&lt;/p&gt;
    &lt;p&gt;I. What is tanha?&lt;/p&gt;
    &lt;p&gt;By default, the brain tries to grasp and hold onto pleasant sensations and push away unpleasant ones. The Buddha called these ‚Äòmicro-motions‚Äô of greed and aversion ta·πáhƒÅ, and the Buddhist consensus seems to be that it accounts for an amazingly large proportion (~90%) of suffering. Romeo Stevens suggests translating the original Pali term as ‚Äúfused to,‚Äù ‚Äúgrasping,‚Äù or ‚Äúclenching,‚Äù and that the mind is trying to make sensations feel stable, satisfactory, and controllable. Nick Cammarata suggests ‚Äúfast grabby thing‚Äù that happens within ~100ms after a sensation enters awareness; Daniel Ingram suggests this ‚Äògrab‚Äô can occur as quickly as 25-50ms (personal discussion). Uchiyama Roshi describes tanha in terms of its cure, ‚Äúopening the hand of thought‚Äù; Shinzen Young suggests ‚Äúfixation‚Äù; other common translations of tanha are ‚Äúdesire,‚Äù ‚Äúthirst,‚Äù ‚Äúcraving.‚Äù The vipassana doctrine is that tanha is something the mind instinctively does, and that meditation helps you see this process as it happens, which allows you to stop doing it. Shinzen estimates that his conscious experience is literally 10x better due to having a satisfying meditation practice.&lt;/p&gt;
    &lt;p&gt;Tanha is not yet a topic of study in affective neuroscience but I suggest it should be. Neuroscience is generally gated by soluble important mysteries: complex dynamics often arise from complex mechanisms, and complex mechanisms are difficult to untangle. The treasures in neuroscience happen when we find exceptions to this rule: complex dynamics that arise from elegantly simple core mechanisms. When we find one it generally leads to breakthroughs in both theory and intervention. Does ‚Äútanha‚Äù arise from a simple or complex mechanism? I believe Buddhist phenomenology is very careful about what it calls dependent origination ‚Äî and this makes items that Buddhist scholarship considers to be ‚Äòbasic building-blocks of phenomenology‚Äô particularly likely to have a simple, elegant implementations in the brain ‚Äî and thus are exceptional mysteries to focus scientific attention on.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think tanha has 1000 contributing factors; I think it has one crisp, isolatable factor. And I think if we find this factor, it could herald a reorganization of systems neuroscience similar in magnitude to the past shifts of cybernetics, predictive coding, and active inference.&lt;/p&gt;
    &lt;p&gt;Core resources:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Anuruddha, ƒÄ. (n.d.). A Comprehensive Manual of Abhidhamma.&lt;/item&gt;
      &lt;item&gt;Stevens, R. (2020). (mis)Translating the Buddha. Neurotic Gradient Descent.&lt;/item&gt;
      &lt;item&gt;Cammarata, N. (2021-2023). [Collected Twitter threads on tanha].&lt;/item&gt;
      &lt;item&gt;Markwell, A. (n.d.). Dhamma resources.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;II. Tanha as unskillful active inference (TUAI)&lt;/p&gt;
    &lt;p&gt;The first clue is what tanha is trying to do for us. I‚Äôll claim today that tanha is a side-effect of a normal, effective strategy our brains use extensively, active inference. Active inference suggests we impel ourselves to action by first creating some predicted sensation (‚ÄúI have a sweet taste in my mouth‚Äù or ‚ÄúI am not standing near that dangerous-looking man‚Äù) and then holding it until we act in the world to make this prediction become true (at which point we can release the tension). Active inference argues we store our to-do list as predictions, which are equivalent to untrue sensory observations that we act to make true.&lt;/p&gt;
    &lt;p&gt;Formally, the ‚Äútanha as unskillful active inference‚Äù (TUAI) hypothesis is that this process commonly goes awry (i.e. is applied unskillfully) in three ways:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First, the rate of generating normative predictions can outpace our ability to make them true and overloads a very finite system. Basically we try to control too much, and stress builds up.&lt;/item&gt;
      &lt;item&gt;Second, we generate normative predictions in domains that we cannot possibly control; predicting a taste of cake will linger in our mouth forever, predicting that we did not drop our glass of water on the floor. That good sensations will last forever and the bad did not happen. (This is essentially a ‚Äúpredictive processing‚Äù reframe of the story Romeo Stevens has told on his blog, Twitter, and in person.)[1]&lt;/item&gt;
      &lt;item&gt;Third, there may be a context desynchronization between the system that represents the world model, and the system that maintains predictions-as-operators on this world model. When desynchronization happens and the basis of the world model shifts in relation to the basis of the predictions, predictions become nonspecific or nonsensical noise and stress.&lt;/item&gt;
      &lt;item&gt;We may also include a catch-all fourth category for when the prediction machinery becomes altered outside of any semantic context, for example metabolic insufficiency leading to impaired operation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Core resources:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Safron, A. (2020). An Integrated World Modeling Theory (IWMT) of Consciousness: Combining Integrated Information and Global Neuronal Workspace Theories With the Free Energy Principle and Active Inference Framework; Toward Solving the Hard Problem and Characterizing Agentic Causation. Frontiers in Artificial Intelligence, 3. https://doi.org/10.3389/frai.2020.00030&lt;/item&gt;
      &lt;item&gt;Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G. (2017). Active inference: A Process Theory. Neural Computation, 29(1), 1-49.&lt;/item&gt;
      &lt;item&gt;Sapolsky, R.M. (2004). Why Zebras Don‚Äôt Get Ulcers: The Acclaimed Guide to Stress, Stress-Related Diseases, and Coping. Holt Paperbacks. [Note: link is to a video summary.]&lt;/item&gt;
      &lt;item&gt;Pyszczynski, T., Greenberg, J., Solomon, S. (2015). Thirty Years of Terror Management Theory. Advances in Experimental Social Psychology, 52, 1-70.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;III. Evaluating tanha requires a world model and cost function&lt;/p&gt;
    &lt;p&gt;There are many theories about the basic unit of organization of the brain; brain regions, functional circuits, specific network topologies, etc. Adam Safron describes the nervous system‚Äôs basic building block as Self-Organized Harmonic Modes (SOHMs); I like this because the math of harmonic modes allows a lot of interesting computation to arise ‚Äòfor free.‚Äô Safron suggests these modes function as autoencoders, which I believe are functionally identical to symmetry detectors. It‚Äôs increasingly looking like SOHMs are organized around physical brain resonances at least as much as connectivity, which been a surprising result.&lt;/p&gt;
    &lt;p&gt;At high frequencies these SOHMs will act as feature detectors, at lower frequencies we might think of them as wind chimes: by the presence and absence of particular SOHMs and their interactions we obtain a subconscious feeling about what kind of environment we‚Äôre in and where its rewards and dangers are. We can expect SOHMs will be arranged in a way that optimizes differentiability of possible/likely world states, minimizes crosstalk, and in aggregate constitutes a world model, or in the Neural Annealing/REBUS/ALBUS framework, a belief landscape.&lt;/p&gt;
    &lt;p&gt;To be in tanha-free ‚Äúopen awareness‚Äù without greed, aversion, or expectation is to feel the undoctored hum of your SOHMs. However, we doctor our SOHMs *all the time* ‚Äî when a nice sensation enters our awareness, we reflexively try to ‚Äògrab‚Äô it and stabilize the resonance; when something unpleasant comes in, we try to push away and deaden the resonance. Likewise society puts expectations on us to ‚Äúact normal‚Äù and ‚Äúbe useful‚Äù; we may consider all such SOHM adjustments/predictions as drawing from the same finite resource pool. ‚ÄúActive SOHM management‚Äù is effortful (and unpleasant) in rough proportion to how many SOHMs need to be actively managed and how long they need to be managed.&lt;/p&gt;
    &lt;p&gt;But how can the brain manage SOHMs? And if the Buddhists are right and this creates suffering, why does the brain even try?&lt;/p&gt;
    &lt;p&gt;Core resources:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Safron, A. (2020). An Integrated World Modeling Theory (IWMT) of Consciousness: Combining Integrated Information and Global Neuronal Workspace Theories With the Free Energy Principle and Active Inference Framework; Toward Solving the Hard Problem and Characterizing Agentic Causation. Frontiers in Artificial Intelligence, 3. https://doi.org/10.3389/frai.2020.00030&lt;/item&gt;
      &lt;item&gt;Safron, A. (2020). On the varieties of conscious experiences: Altered beliefs under psychedelics (ALBUS). PsyArxiv. Retrieved July 7, 2023, from the PsyArxiv website.&lt;/item&gt;
      &lt;item&gt;Safron, A. (2021). The radically embodied conscious cybernetic bayesian brain: From free energy to free will and back again. Entropy, 23(6), 783. MDPI.&lt;/item&gt;
      &lt;item&gt;Bassett, D. S., &amp;amp; Sporns, O. (2017). Network neuroscience. Nature Neuroscience, 20(3), 353-364.&lt;/item&gt;
      &lt;item&gt;Buzs√°ki, G., &amp;amp; Draguhn, A. (2004). Neuronal oscillations in cortical networks. Science, 304(5679), 1926-1929.&lt;/item&gt;
      &lt;item&gt;Johnson, M. (2016). Principia Qualia. opentheory.net.&lt;/item&gt;
      &lt;item&gt;Johnson, M. (2019). Neural Annealing: Toward a Neural Theory of Everything. opentheory.net.&lt;/item&gt;
      &lt;item&gt;Johnson, M. (2023). Qualia Formalism and a Symmetry Theory of Valence. opentheory.net.&lt;/item&gt;
      &lt;item&gt;Carhart-Harris, R. L., &amp;amp; Friston, K. J. (2019). REBUS and the Anarchic Brain: Toward a Unified Model of the Brain Action of Psychedelics. Pharmacological Reviews, 71(3), 316-344.&lt;/item&gt;
      &lt;item&gt;Dahl, C. J., Lutz, A., &amp;amp; Davidson, R. J. (2015). Reconstructing and deconstructing the self: cognitive mechanisms in meditation practice. Trends in Cognitive Sciences, 19(9), 515-523.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;IV. Tanha as artifact of compression pressure&lt;/p&gt;
    &lt;p&gt;I propose reframing tanha as an artifact of the brain‚Äôs compression pressure. I.e. tanha is an artifact of a continual process that subtly but systematically pushes on the complexity of ‚Äòwhat is‚Äô (the neural patterns represented by undoctored SOHMs) to collapse it into a more simple configuration, and sometimes holds it there until we act to make that simplification true. The result of this compression drive conflates ‚Äúwhat is‚Äù, ‚Äúwhat could be‚Äù, ‚Äúwhat should be‚Äù, and ‚Äúwhat will be,‚Äù and this conflation is the source of no end of moral and epistemological confusion.&lt;/p&gt;
    &lt;p&gt;This reframes tanha as both the pressure which collapses complexity into simplicity, and the ongoing stress that comes from maintaining the counterfactual aspects of this collapse (compression stress). We can think of this process as balancing two costs: on one hand, applying compression pressure has metabolic and epistemic costs, both immediate and ongoing. On the other hand, the brain is a finite system and if it doesn‚Äôt continually ‚Äúcompress away‚Äù patterns there will be unmanageable sensory chaos. The right amount of compression pressure is not zero.[2]&lt;/p&gt;
    &lt;p&gt;Equivalently, we can consider tanha as an excessive forcefulness in the metabolization of uncertainty. Erik P. Hoel has written about energy, information, and uncertainty as equivalent and conserved quantities (Hoel 2020): much like literal digestion, the imperative of the nervous system is to extract value from sensations then excrete the remaining information, leaving a low-information, low-uncertainty, clean slate ready for the next sensation (thank you Benjamin Anderson for discussion). However, we are often unskillful in the ways we try to extract value from sensations, e.g. improperly assessing context, trying to extract too much or too little certainty, or trying to extract forms of certainty inappropriate for the sensation.&lt;/p&gt;
    &lt;p&gt;We can define a person‚Äôs personality, aesthetic, and a large part of their phenomenology in terms of how they metabolize uncertainty ‚Äî their library of motifs for (a) initial probing, (b) digestion and integration, and (c) excretion/externalization of any waste products, and the particular reagents for this process they can‚Äôt give themselves and must seek in the world.&lt;/p&gt;
    &lt;p&gt;So far we‚Äôve been discussing brain dynamics on the computational level. But how does the brain do all this ‚Äî what is the mechanism by which it attempts to apply compression pressure to SOHMs? This is essentially the question neuroscience has been asking for the last decade. I believe evolution has coupled two very different systems together to selectively apply compression/prediction pressure in a way that preserves the perceptive reliability of the underlying system (undoctored SOHMs as ground-truth perception) but allows near-infinite capacity for adjustment and hypotheticals. One system focused on perception; one on compression, judgment, planning, and action.&lt;/p&gt;
    &lt;p&gt;The traditional neuroscience approach for locating these executive functions has been to associate them with particular areas of the brain. I suspect the core logic is hiding much closer to the action.&lt;/p&gt;
    &lt;p&gt;Core resources:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Schmidhuber, J. (2008). Driven by Compression Progress: A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes. Arxiv. Retrieved July 7, 2023, from the Arxiv website.&lt;/item&gt;
      &lt;item&gt;Johnson, M. (2023). Qualia Formalism and a Symmetry Theory of Valence. opentheory.net.&lt;/item&gt;
      &lt;item&gt;Hoel, E. (2020). The Overfitted Brain: Dreams evolved to assist generalization. Arxiv. Retrieved July 7, 2023, from the Arxiv website.&lt;/item&gt;
      &lt;item&gt;Friston, K. (2010). The free-energy principle: a unified brain theory? Nature Reviews Neuroscience, 11(2), 127-138.&lt;/item&gt;
      &lt;item&gt;Chater, N., &amp;amp; Vit√°nyi, P. (2003). Simplicity: a unifying principle in cognitive science? Trends in Cognitive Sciences, 7(1), 19-22.&lt;/item&gt;
      &lt;item&gt;Bach, D.R., &amp;amp; Dolan, R.J. (2012). Knowing how much you don‚Äôt know: a neural organization of uncertainty estimates. Nature Reviews Neuroscience, 13(8), 572-586.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;V. VSMCs as computational infrastructure&lt;/p&gt;
    &lt;p&gt;Above: the vertical section of an artery wall (Wikipedia, emphasis added; video): the physical mechanism by which we grab sensations and make predictions; the proximate cause of 90% of suffering and 90% of goal-directed behavior.&lt;/p&gt;
    &lt;p&gt;All blood vessels are wrapped by a thin sheathe of vascular smooth muscle cells (VSMCs). The current scientific consensus has the vasculature system as a spiderweb of ever-narrower channels for blood, powered by the heart as a central pump, and supporting systems such as the brain, stomach, limbs, and so on by bringing them nutrients and taking away waste. The sheathe of muscle wrapped around blood vessels undulates in a process called ‚Äúvasomotion‚Äù that we think helps blood keep circulating, much like peristalsis in the gut helps keep food moving, and can help adjust blood pressure.&lt;/p&gt;
    &lt;p&gt;I think all this is true, but is also a product of what‚Äôs been easy to measure and misses 90% of what these cells do.&lt;/p&gt;
    &lt;p&gt;Evolution works in layers, and the most ancient base layers often have rudimentary versions of more specialized capacities (Levin 2022) as well as deep control hooks into newer systems that are built around them. The vascular system actually predates neurons and has co-evolved with the nervous system for hundreds of millions of years. It also has mechanical actuators (VSMCs) that have physical access to all parts of the body and can flex in arbitrary patterns and rhythms. It would be extremely surprising if evolution didn‚Äôt use this system for something more than plumbing. We can also ‚Äúfollow the money‚Äù; the vascular system controls the nutrients and waste disposal for the neural system and will win in any heads-up competition over co-regulation balance.&lt;/p&gt;
    &lt;p&gt;I expect VSMC contractions to influence nearby neurons through e.g. ephaptic coupling, reducing blood flow, and adjusting local physical resonance, and to be triggered by local dissonance in the electromagnetic field.&lt;/p&gt;
    &lt;p&gt;I‚Äôll offer three related hypotheses about the computational role of VSMCs[3] today that in aggregate constitute a neural regulatory paradigm I‚Äôm calling vasocomputation:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Compressive Vasomotion Hypothesis (CVH): the vasomotion reflex functions as a compression sweep on nearby neural resonances, collapsing and merging fragile ambivalent patterns (the ‚ÄúBayesian blur‚Äù problem) into a more durable, definite state. Motifs of vasomotion, reflexive reactions to uncertainties, and patterns of tanha are equivalent.&lt;/item&gt;
      &lt;item&gt;Vascular Clamp Hypothesis (VCH): vascular contractions freeze local neural patterns and plasticity for the duration of the contraction, similar to collapsing a superposition or probability distribution, clamping a harmonic system, or pinching a critical network into a definite circuit. Specific vascular constrictions correspond with specific predictions within the Active Inference framework and function as medium-term memory.&lt;/item&gt;
      &lt;item&gt;Latched Hyperprior Hypothesis (LHH): if a vascular contraction is held long enough, it will engage the latch-bridge mechanism common to smooth muscle cells. This will durably ‚Äòfreeze‚Äô the nearby circuit, isolating it from conscious experience and global updating and leading to a much-reduced dynamical repertoire; essentially creating a durable commitment to a specific hyperprior. The local vasculature will unlatch once the prediction the latch corresponds to is resolved, restoring the ability of the nearby neural networks to support a larger superposition of possibilities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The initial contractive sweep jostles the neural superposition of interpretations into specificity; the contracted state temporarily freezes the result; if the contraction is sustained, the latch bridge mechanism engages and cements this freeze as a hyperprior. With one motion the door of possibility slams shut. And so we collapse our world into something less magical but more manageable, one clench at a time. Tanha is cringe.&lt;/p&gt;
    &lt;p&gt;The claim relevant to the Free Energy Principle ‚Äì Active Inference paradigm is we can productively understand the motifs of smooth muscle cells (particularly in the vascular system) as ‚Äúwhere the brain‚Äôs top-down predictive models are hiding,‚Äù which has been an open mystery in FEP-AI. Specific predictions are held as vascular tension, and vascular tension in turn is released by action, consolidated by Neural Annealing, or rendered superfluous by neural remodeling (hold a pattern in place long enough and it becomes the default). Phrased in terms of the Deep CANALs framework which imports ideas from machine learning: the neural weights that give rise to SOHMs constitute the learning landscape, and SOHMs+vascular tension constitute the inference landscape.&lt;/p&gt;
    &lt;p&gt;The claim relevant to Theravada Buddhism is we can productively understand the motifs of the vascular system as the means by which we attempt to manipulate our sensations. Vasomotion corresponds to an attempt to ‚Äòpin down‚Äô a sensation (i.e. tanha); muscle contractions freeze patterns; smooth muscle latches block out feelings of possibility and awareness of that somatic area. Progress on the contemplative path will correspond with both using these forms of tension less, and needing them less. I expect cessations to correspond with a nigh-complete absence of vasomotion (and EEG may measure vasomotion moreso than neural activity).&lt;/p&gt;
    &lt;p&gt;The claim relevant to practical health is that smooth muscle tension, especially in VSMCs, and especially latched tension, is a system science knows relatively little about but is involved in an incredibly wide range of problems, and understanding this system is hugely helpful for knowing how to take care of yourself and others. The ‚Äúlatch-bridge‚Äù mechanism is especially important, where smooth muscle cells have a discrete state where they attach their myosin heads to actin in a way that ‚Äúlocks‚Äù or ‚Äúlatches‚Äù the tension without requiring ongoing energy. Latches take between seconds to minutes to form &amp;amp; dissolve ‚Äî a simple way to experience the latch-bridge cycle releasing is to have a hot bath and notice waves of muscle relaxation. Latches can persist for minutes, hours, days, months, or years (depending on what prediction they‚Äôre stabilizing), and the sum total of all latches likely accounts for the majority of bodily suffering. If you are ‚Äúholding tension in your body‚Äù you are subject to the mechanics of the latch-bridge mechanism. Migraines and cluster headaches are almost certainly inappropriate VSMC latches; all hollow organs are surrounded by smooth muscle and can latch. A long-term diet of poor food (e.g. seed oils) leads to random latch formation and ‚Äúlumpy‚Äù phenomenology. Sauna + cold plunges are an effective way to force the clench-release cycle and release latches; likewise, simply taking time to feel your body and put your attention into latched tissues can release them. Psychedelics can force open latches. Many issues in neuropathy &amp;amp; psychiatry are likely due to what I call ‚Äúlatch spirals‚Äù ‚Äî a latch forms, which reduces blood flow to that area, which reduces energy available to those tissues, which prevents the latch from releasing (since releasing the latch requires activation energy and returning to a freely cycling state also increases the cell‚Äôs rate of energy expenditure).&lt;/p&gt;
    &lt;p&gt;Core resources:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Levin, M. (2022). Technological Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds. Frontiers in Systems Neuroscience, 16. https://doi.org/10.3389/fnsys.2022.768201&lt;/item&gt;
      &lt;item&gt;Watson, R., McGilchrist, I., &amp;amp; Levin, M. (2023). Conversation between Richard Watson, Iain McGilchrist, and Michael Levin #2. YouTube.&lt;/item&gt;
      &lt;item&gt;Wikipedia contributors. (2023, April 26). Smooth muscle. In Wikipedia, The Free Encyclopedia. Retrieved 22:39, July 7, 2023, from https://en.wikipedia.org/w/index.php?title=Smooth_muscle&amp;amp;oldid=1151758279&lt;/item&gt;
      &lt;item&gt;Wikipedia contributors. (2023, June 27). Circulatory system. In Wikipedia, The Free Encyclopedia. Retrieved 22:41, July 7, 2023, from https://en.wikipedia.org/w/index.php?title=Circulatory_system&amp;amp;oldid=1162138829&lt;/item&gt;
      &lt;item&gt;Johnson, M., GPT4. (2023). [Mike+GPT4: Latch bridge mechanism discussion].&lt;/item&gt;
      &lt;item&gt;Juliani, A., Safron, A., &amp;amp; Kanai, R. (2023, May 18). Deep CANALs: A Deep Learning Approach to Refining the Canalization Theory of Psychopathology. https://doi.org/10.31234/osf.io/uxmz6&lt;/item&gt;
      &lt;item&gt;Moore CI, Cao R. The hemo-neural hypothesis: on the role of blood flow in information processing. J Neurophysiol. 2008 May;99(5):2035-47. doi: 10.1152/jn.01366.2006. Epub 2007 Oct 3. PMID: 17913979; PMCID: PMC3655718 Added 11-17-23; recommended priority reading&lt;/item&gt;
      &lt;item&gt;Jacob M, Ford J and Deacon T (2023) Cognition is entangled with metabolism: relevance for resting-state EEG-fMRI. Front. Hum. Neurosci. 17:976036. doi: 10.3389/fnhum.2023.976036 Added 1-19-24&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To summarize the story so far: tanha is a grabby reflex which is the source of most moment-by-moment suffering. The ‚Äòtanha as unskillful active inference‚Äô (TUAI) hypothesis suggests that we can think of this ‚Äúgrabbing‚Äù as part of the brain‚Äôs normal predictive and compressive sensemaking, but by default it makes many unskillful predictions that can‚Äôt possibly come true and must hold in a costly way. The vascular clamp hypothesis (VCH) is that we store these predictions (both skillful and unskillful) in vascular tension. The VCH can be divided into three distinct hypotheses (CVH, VCH, LHH) that describe the role of this reflex at different computational and temporal scales. An important and non-obvious aspect of smooth muscle (e.g. VSMCs) is they have a discrete ‚Äúlatch‚Äù setting wherein energy usage and flexibility drops significantly, and sometimes these latches are overly ‚Äòsticky‚Äô; unlatching our sticky latches is a core part of the human condition.&lt;/p&gt;
    &lt;p&gt;Concluding Part I: the above work describes a bridge between three distinct levels of abstraction: a central element in Buddhist phenomenology, the core accounting system within active inference, and a specific muscular reflex. I think this may offer a functional route to synthesize the FEP-AI paradigm and Michael Levin‚Äôs distributed stress minimization work, and in future posts I plan to explore why this mechanism has been overlooked, and how its dynamics are intimately connected with human problems and capacities.&lt;/p&gt;
    &lt;p&gt;I view this research program as integral to both human flourishing and AI alignment.&lt;/p&gt;
    &lt;p&gt;Acknowledgements: This work owes a great deal to Romeo Stevens‚Äô scholarship on tanha, pioneering tanha as a ‚Äòclench‚Äô dynamic, intuitions about muscle tension and prediction, and notion that we commit to dukkha ourselves until we get what we want; Nick Cammarata‚Äôs fresh perspectives on Buddhism and his tireless and generative inquiry around the phenomenology &amp;amp; timescale of tanha; Justin Mares‚Äô gentle and persistent encouragement; Andrea Bortolameazzi‚Äôs many thoughtful comments and observations about the path, critical feedback, and thoughtful support; and Adam Safron‚Äôs steadfast belief and support, theorizing on SOHMs, and teachings about predictive coding and active inference. Much of my knowledge of Buddhist psychology comes from the work and teachings of Anthony Markwell; much of my intuition around tantra and interpersonal embodiment dynamics comes from Elena Selezneva. I‚Äôm also grateful for conversations with Benjamin Anderson about emergence, to Curran Janssens for supporting my research, and to Ivanna Evtukhova for starting me on the contemplative path. An evergreen thank you to my parents their unconditional support. Finally, a big thank-you to Janine Leger and Vitalik Buterin‚Äôs Zuzalu co-living community for creating a space to work on this writeup and make it real.&lt;/p&gt;
    &lt;p&gt;Footnotes:&lt;/p&gt;
    &lt;p&gt;[1] We might attempt to decompose the Active Inference ‚Äì FEP term of ‚Äòprecision weighting‚Äô as (1) the amount of sensory clarity (the amount of precision available in stimuli), and (2) the amount of ‚Äògrabbiness‚Äô of the compression system (the amount of precision we empirically try to extract). Perhaps we could begin to put numbers on tanha by calculating the KL divergence between these distributions.&lt;/p&gt;
    &lt;p&gt;[2] We can speculate that the arrow of compression points away from Buddhism‚Äôs three attributes: e.g. the brain tries to push and prod its SOHMs toward patterns that are stable (dissonance minimization), satisfactory (harmony maximization), and controllable (compression maximization) ‚Äî similar yet subtly distinct targets. Thanks to both Romeo and Andrea for discussion about the three attributes and their opposite.&lt;/p&gt;
    &lt;p&gt;[3] (Added July 19, 2023) Skeletal muscle, smooth muscle, and fascia (which contains myofibroblasts with actin fibers similar to those in muscles) are all found throughout the body and reflexively distribute physical load; it‚Äôs likely they do the same for cognitive-emotional load. Why focus on VSMCs in particular? Three reasons: (1) they have the best physical access to neurons, (2) they regulate bloodflow, and (3) they have the latch-bridge mechanism. I.e. skeletal, non-VSMC smooth muscle, and fascia all likely contribute significantly to distributed stress minimization, and perhaps do so via similar principles/heuristics, but VSMCs seem to be the only muscle with means, motive, and opportunity to finely puppet the neural system, and I believe are indispensably integrated with its moment-by-moment operation in more ways than are other contractive cells. (Thanks to @askyatharth for bringing up fascia.)&lt;/p&gt;
    &lt;p&gt;Edit, April 6th, 2025: a friendly Buddhist scholar suggests that common translations of ta·πáhƒÅ conflate two concepts: ta·πáhƒÅ in Pali is most accurately translated as craving or thirst, whereas the act of clinging itself is ‚ÄúupƒÅdƒÅna (as in the upƒÅdƒÅna-khandhƒÅs), and in the links of dependent origination is one step downstream from the thirst (or impulsive craving) of ta·πáhƒÅ.‚Äù Under this view we can frame ta·πáhƒÅ as a particular default bias in the computational-biochemical tuning of the human nervous system, and upƒÅdƒÅna as the impulsive physical (VSMC) clenching this leads to.&lt;/p&gt;
    &lt;p&gt;Buddhism describes ta·πáhƒÅ as being driven by the three fundamental defilements, greed, fear, &amp;amp; delusion; I expect each defilement maps to a hard truth (aka clearly suboptimal but understandable failure mode) of implementing vasocomputation-based active inference systems.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://opentheory.net/2023/07/principles-of-vasocomputation-a-unification-of-buddhist-phenomenology-active-inference-and-physical-reflex-part-i/"/><published>2025-11-27T05:51:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066255</id><title>Last Issue of "ECMAScript News"</title><updated>2025-11-27T11:09:38.215466+00:00</updated><content>&lt;doc fingerprint="b894cfdddb577cdb"&gt;
  &lt;main&gt;
    &lt;p&gt;Dear readers!&lt;/p&gt;
    &lt;p&gt;Sadly, we have to inform you that this is the last issue of ‚ÄúECMAScript News‚Äù. We have been operating at a loss for too long: The number of advertisers and subscribers has been slowly but steadily decreasing over the last two years (vs. constant growth before that). Therefore, we made the difficult decision to stop publishing this newsletter.&lt;/p&gt;
    &lt;p&gt;The first issue came out on 2016-09-27. We published a total of 368 issues and are thankful for many loyal readers during many interesting years!&lt;/p&gt;
    &lt;p&gt;Axel may continue this newsletter in some shape or form next year. If he does, he‚Äôll inform you via one last email in 2026.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ecmascript.news/archive/es-next-news-2025-11-26.html"/><published>2025-11-27T06:14:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066280</id><title>Linux Kernel Explorer</title><updated>2025-11-27T11:09:37.870212+00:00</updated><content>&lt;doc fingerprint="7391f92da42b0365"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;div&gt;
        &lt;p&gt;The kernel isn't a process‚Äîit's the system. It serves user processes, reacts to context, and enforces separation and control.&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;The Kernel Is Not a Process: It's the always-present authority bridging hardware and software.&lt;/item&gt;
          &lt;item&gt;Serving the Process: Orchestrates syscalls, interrupts, and scheduling to keep user tasks running.&lt;/item&gt;
          &lt;item&gt;System of Layers: Virtual, mapped, isolated, and controlled‚Äîstructure at runtime.&lt;/item&gt;
        &lt;/list&gt;
        &lt;div&gt;
          &lt;head rend="h4"&gt;üìö Study Files&lt;/head&gt;
          &lt;div&gt;
            &lt;p&gt;init/main.c&lt;/p&gt;
            &lt;p&gt;kernel/fork.c&lt;/p&gt;
            &lt;p&gt;include/linux/sched.h&lt;/p&gt;
            &lt;p&gt;arch/x86/kernel/entry_64.S&lt;/p&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;div&gt;
            &lt;div&gt;
              &lt;p&gt;1. What is the fundamental difference between the kernel and a process?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.The kernel is a special process with elevated privileges&lt;/p&gt;
                &lt;p&gt;B.The kernel is not a process‚Äîit's the system itself that serves processes&lt;/p&gt;
                &lt;p&gt;C.The kernel is just a library that processes link against&lt;/p&gt;
                &lt;p&gt;D.There is no difference; they are the same thing&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div&gt;
              &lt;p&gt;2. How does the kernel primarily serve user processes?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.By running as a background daemon&lt;/p&gt;
                &lt;p&gt;B.By orchestrating syscalls, interrupts, and scheduling&lt;/p&gt;
                &lt;p&gt;C.By providing a GUI interface&lt;/p&gt;
                &lt;p&gt;D.By compiling user code&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div&gt;
              &lt;p&gt;3. What characterizes the kernel's system of layers?&lt;/p&gt;
              &lt;div&gt;
                &lt;p&gt;A.Physical, tangible, and direct&lt;/p&gt;
                &lt;p&gt;B.Simple and flat with no hierarchy&lt;/p&gt;
                &lt;p&gt;C.Virtual, mapped, isolated, and controlled&lt;/p&gt;
                &lt;p&gt;D.User-accessible and modifiable&lt;/p&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://reverser.dev/linux-kernel-explorer"/><published>2025-11-27T06:17:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066482</id><title>The Nerd Reich ‚Äì Silicon Valley Fascism and the War on Democracy</title><updated>2025-11-27T11:09:37.655829+00:00</updated><content/><link href="https://www.simonandschuster.com/books/The-Nerd-Reich/Gil-Duran/9781668221402"/><published>2025-11-27T06:53:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46066695</id><title>Ray Marching Soft Shadows in 2D</title><updated>2025-11-27T11:09:37.388567+00:00</updated><content>&lt;doc fingerprint="3fae98912ba42232"&gt;
  &lt;main&gt;
    &lt;p&gt;Disclaimer: the demos on this page use WebGL features that aren‚Äôt available on some mobile devices.&lt;/p&gt;
    &lt;p&gt;A couple of weeks ago I tweeted a video of a toy graphics project (below). It‚Äôs not done, but a lot of people liked it which was surprising and fun! A few people asked how it works, so that‚Äôs what this post is about.&lt;/p&gt;
    &lt;p&gt;Under the hood it uses something called a distance field. A distance field is an image like the one below that tells you how far each pixel is from your shape. Light grey pixels are close to the shape and dark grey pixels are far from it.&lt;/p&gt;
    &lt;p&gt;When the demo starts up, it draws some text on a 2D canvas and generates a distance field of it. It uses a library I wrote that generates distance fields really quickly. If you‚Äôre curious how the library works, I wrote about that here.&lt;/p&gt;
    &lt;p&gt;Our lighting scheme works like this: when processing a particular pixel we consider a ray from it to the light, like so‚Ä¶&lt;/p&gt;
    &lt;p&gt;If the ray intersects a glyph, the pixel we‚Äôre shading must be in shadow because there‚Äôs something between it and the light.&lt;/p&gt;
    &lt;p&gt;The simplest way to check this would be to move along the ray in 1px increments, starting from the pixel we‚Äôre shading and ending at the light, repeatedly asking the distance field if we‚Äôre distance 0 from a shape. This would work, but it‚Äôd be really slow.&lt;/p&gt;
    &lt;p&gt;We could pick some specific length like 30px and move in increments of that size, but then we risk jumping over glyphs that are smaller than 30px. We might think we‚Äôre not in shadow when we should be.&lt;/p&gt;
    &lt;p&gt;Ray marching‚Äôs core idea is this: the distance field tells you how far you are from the closest glyph. You can safely advance along your ray by that distance without skipping over any glyphs.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs walk through an example. We start as pictured above and ask the distance field how far we are from any glyph. Turns out in this case that the answer is 95px (pictured left). This means that we can move 95px along our ray without skipping over anything!&lt;/p&gt;
    &lt;p&gt;Now we‚Äôre a little closer to the light. We repeat the process until we hit the ascender of the b! If the b glyph weren‚Äôt there, we‚Äôd have kept going until we hit the light.&lt;/p&gt;
    &lt;p&gt;Below is a demo that shows the ray marching steps for a given pixel. The red box is the pixel we‚Äôre shading, and each circle along the ray represents a ray marching step and the distance from the scene at that step.&lt;/p&gt;
    &lt;p&gt;Try dragging the light and the pixel around to build an intuition for it.&lt;/p&gt;
    &lt;p&gt;Below is GLSL to implement this technique. It assumes you‚Äôve defined a function &lt;code&gt;getDistance&lt;/code&gt; that samples the distance field.&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;

float rayProgress = 0;
while (true) {
  if (rayProgress &amp;gt; distance(rayOrigin, lightPosition)) {
    // We hit the light! This pixel is not in shadow.
    return 1.;
  }

  float sceneDist = getDistance(
    rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  rayProgress += sceneDist;
}
&lt;/code&gt;
    &lt;p&gt;It turns out that some pixels are really expensive to process. So in practice we use a for-loop instead of a while loop ‚Äì that way we bail out if we‚Äôve done too many steps. A common ‚Äúslow case‚Äù in ray marching is when a ray is parallel to the edge of a shape in the scene‚Ä¶&lt;/p&gt;
    &lt;p&gt;The approach I‚Äôve described so far will get you a scene that looks like the one below.&lt;/p&gt;
    &lt;p&gt;It‚Äôs cool, but the shadows are sharp which doesn‚Äôt look very good. The shadows in the demo look more like this‚Ä¶&lt;/p&gt;
    &lt;p&gt;One big disclaimer is that they‚Äôre not physically realistic! Real shadows look like hard shadows where the edges have been fuzzed. This approach does something slightly different: all pixels that were previously in shadow are still fully in shadow. We‚Äôve just added a penumbra of partially shaded pixels around them.&lt;/p&gt;
    &lt;p&gt;The upside is that they‚Äôre pretty and fast to compute, and that‚Äôs what I care about! There are three ‚Äúrules‚Äù involved in computing them.&lt;/p&gt;
    &lt;p&gt;Rule 1: The closer a ray gets to intersecting a shape, the more its pixel should be shadowed. In the image below there are two similar rays (their distances to the shape pictured in yellow and green). We want the one that gets closer to touching the corner to be more shadowed.&lt;/p&gt;
    &lt;p&gt;This is cheap to compute because the variable &lt;code&gt;sceneDist&lt;/code&gt; tells us how far we are from the closest shape at each ray marching step. So the smallest value of &lt;code&gt;sceneDist&lt;/code&gt; across all steps is a good approximation for the yellow and green lines in the image above.&lt;/p&gt;
    &lt;p&gt;Rule 2: if the pixel we‚Äôre shading is far from the point where it almost intersects a shape, we want the shadow to spread out more.&lt;/p&gt;
    &lt;p&gt;Consider two pixels along the ray above. One is closer to the almost-intersection and is lighter (its distance is the green line). The other is farther and darker (its distance is the yellow line). In general: the further a pixel is from its almost intersection, the more ‚Äúin shadow‚Äù we should make it.&lt;/p&gt;
    &lt;p&gt;This is cheap to compute because the variable &lt;code&gt;rayProgress&lt;/code&gt; is the length of the green and yellow lines in the image above.&lt;/p&gt;
    &lt;p&gt;So: we previously returned &lt;code&gt;1.0&lt;/code&gt; for pixels that weren‚Äôt in shadow. To implement rules 1 and 2, we compute &lt;code&gt;sceneDist / rayProgress&lt;/code&gt; on each ray marching step, keep track of its minimum value, and return that instead.&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;
float rayProgress = 0.;
float stopAt = distance(samplePt, lightPosition);
float lightContribution = 1.;
for (int i = 0; i &amp;lt; 64; i++) {
  if (rayProgress &amp;gt; stopAt) {
    return lightContribution;
  }

  // `getDistance` samples our distance field texture.
  float sceneDist = getDistance(
    rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  lightContribution = min(
    lightContribution,
    sceneDist / rayProgress
  );

  rayProgress += sceneDist;
}

// Ray-marching took more than 64 steps!
return 0.;
&lt;/code&gt;
    &lt;p&gt;This ratio feels kind of magical to me because it doesn‚Äôt correspond to any physical value. So let‚Äôs build some intuition for it by thinking through why it might take on particular values‚Ä¶&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;sceneDist / rayProgress &amp;gt;= 1&lt;/code&gt;, then either&lt;code&gt;sceneDist&lt;/code&gt;is big or&lt;code&gt;rayProgress&lt;/code&gt;is small (relative to each other). In the former case we‚Äôre far from any shapes and we shouldn‚Äôt be in shadow, so a light value of&lt;code&gt;1&lt;/code&gt;makes sense. In the latter case, the pixel we‚Äôre shadowing is really close to an object casting a shadow and the shadow isn‚Äôt fuzzy yet, so a light value of&lt;code&gt;1&lt;/code&gt;makes sense.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The ratio is&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;only when&lt;code&gt;sceneDist&lt;/code&gt;is&lt;code&gt;0&lt;/code&gt;. This corresponds to rays that intersect an object and whose pixels are in shadow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And here‚Äôs a demo of what we have so far‚Ä¶&lt;/p&gt;
    &lt;p&gt;Rule #3 is the most straightforward one: light gets weaker the further you get from it.&lt;/p&gt;
    &lt;p&gt;Instead of returning the minimum value of &lt;code&gt;sceneDist / rayProgress&lt;/code&gt; verbatim, we multiply it by a &lt;code&gt;distanceFactor&lt;/code&gt; which is &lt;code&gt;1&lt;/code&gt; right next to the light, &lt;code&gt;0&lt;/code&gt; far away from it, and gets quadratically smaller as you move away from it.&lt;/p&gt;
    &lt;p&gt;All together, the code for the approach so far looks like this‚Ä¶&lt;/p&gt;
    &lt;code&gt;vec2 rayOrigin = ...;
vec2 rayDirection = ...;
float rayProgress = 0.;
float stopAt = distance(samplePt, lightPosition);
float lightContribution = 1.;
for (int i = 0; i &amp;lt; 64; i++) {
  if (rayProgress &amp;gt; stopAt) {
    // We hit the light!
    float LIGHT_RADIUS_PX = 800.;

    // fadeRatio is 1.0 next to the light and 0. at
    // LIGHT_RADIUS_PX away.
    float fadeRatio =
      1.0 - clamp(stopAt / LIGHT_RADIUS_PX, 0., 1.);

    // We'd like the light to fade off quadratically instead of
    // linearly.
    float distanceFactor = pow(fadeRatio, 2.);
    return lightContribution * distanceFactor;
  }

  // `getDistance` samples our distance field texture.
  float sceneDist = getDistance(rayOrigin + rayProgress * rayDirection);
  if (sceneDist &amp;lt;= 0.) {
    // We hit a shape! This pixel is in shadow.
    return 0.;
  }

  lightContribution = min(
    lightContribution,
    sceneDist / rayProgress
  );

  rayProgress += sceneDist;
}

// Ray-marching took more than 64 steps!
return 0.;
&lt;/code&gt;
    &lt;p&gt;I forget where I found this soft-shadow technique, but I definitely didn‚Äôt invent it. Inigo Quilez has a great post on it where he talks about using it in 3D.&lt;/p&gt;
    &lt;p&gt;Inigo‚Äôs post also talks about a gotcha with this approach that you might have noticed in the demos above: it causes banding artifacts. This is because Rule 1 assumes that the smallest value of &lt;code&gt;sceneDist&lt;/code&gt; across all steps is a good approximation for the distance from a ray to the scene. This is not always true because we sometimes take very few ray marching steps.&lt;/p&gt;
    &lt;p&gt;So in my demo I use an improved approximation that Inigo writes about in his post. I also use another trick that is more effective but less performant: instead of advancing by &lt;code&gt;sceneDist&lt;/code&gt; on each ray marching step, I advance by something like &lt;code&gt;sceneDist * randomJitter&lt;/code&gt; where &lt;code&gt;randomJitter&lt;/code&gt; is between &lt;code&gt;0&lt;/code&gt; and &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;This improves the approximation because we‚Äôre adding more steps to our ray march. But we could do that by advancing by &lt;code&gt;sceneDist * .3&lt;/code&gt;. The random jitter ensures that pixels next to each other don‚Äôt end up in the same band. This makes the result a little grainy which isn‚Äôt great. But I think looks better than banding‚Ä¶ This is an aspect of the demo that I‚Äôm still not satisfied with, so if you have ideas for how to improve it please tell me!&lt;/p&gt;
    &lt;p&gt;Overall my demo has a few extra tweaks that I might write about in future but this is the core of it. Thanks for reading! If you have questions or comments, let me know on Twitter.&lt;/p&gt;
    &lt;p&gt;Thank you to Jessica Liu, Susan Wang, Matt Nichols and Kenrick Rilee for giving feedback on early drafts of this post! Also, if you enjoyed this post you might enjoy working with me at Figma!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.rykap.com/2020/09/23/distance-fields/"/><published>2025-11-27T07:31:24+00:00</published></entry></feed>