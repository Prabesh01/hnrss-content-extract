<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-23T07:18:33.864386+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46721474</id><title>Show HN: BrowserOS ‚Äì "Claude Cowork" in the browser</title><updated>2026-01-23T07:18:42.306705+00:00</updated><content>&lt;doc fingerprint="6d52ae51cdf925eb"&gt;
  &lt;main&gt;
    &lt;p&gt;üåê BrowserOS is an open-source chromium fork that runs AI agents natively. Your open-source, privacy-first alternative to ChatGPT Atlas, Perplexity Comet, Dia.&lt;/p&gt;
    &lt;p&gt;üîí Privacy first - use your own API keys or run local models with Ollama. Your data stays on your computer.&lt;/p&gt;
    &lt;p&gt;üí° Join our Discord or Slack and help us build! Have feature requests? Suggest here.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Download and install BrowserOS:&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Import your Chrome data (optional)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your AI provider (OpenAI, Anthropic, or local models via Ollama/LMStudio)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start automating!&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;üè† Feels like home - same familiar interface as Google Chrome, works with all your extensions&lt;/item&gt;
      &lt;item&gt;ü§ñ AI agents that run on YOUR browser, not in the cloud&lt;/item&gt;
      &lt;item&gt;üîí Privacy first - bring your own keys or use local models with Ollama. Your browsing history stays on your computer&lt;/item&gt;
      &lt;item&gt;üöÄ Open source and community driven - see exactly what's happening under the hood&lt;/item&gt;
      &lt;item&gt;ü§ù BrowserOS as MCP server - you can install our MCP server and use the browser from within &lt;code&gt;claude-code&lt;/code&gt;or&lt;code&gt;gemini-cli&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;üõ°Ô∏è Built-in AI ad blocker that works across more scenarios!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;üéá Install BrowserOS as MCP and control it from &lt;code&gt;claude-code&lt;/code&gt;&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;HackerNews.top.3.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;use-browserOS-to-chat.mp4&lt;/head&gt;
    &lt;head class="px-3 py-2"&gt;use-browserOS-to-extract.mp4&lt;/head&gt;
    &lt;p&gt;For the first time since Netscape pioneered the web in 1994, AI gives us the chance to completely reimagine the browser. We've seen tools like Cursor deliver 10x productivity gains for developers‚Äîyet everyday browsing remains frustratingly archaic.&lt;/p&gt;
    &lt;p&gt;You're likely juggling 70+ tabs, battling your browser instead of having it assist you. Routine tasks, like ordering something from amazon or filling a form should be handled seamlessly by AI agents.&lt;/p&gt;
    &lt;p&gt;At BrowserOS, we're convinced that AI should empower you by automating tasks locally and securely‚Äîkeeping your data private. We are building the best browser for this future!&lt;/p&gt;
    &lt;head&gt;vs Chrome&lt;/head&gt;
    &lt;p&gt;While we're grateful for Google open-sourcing Chromium, but Chrome hasn't evolved much in 10 years. No AI features, no automation, no MCP support.&lt;/p&gt;
    &lt;head&gt;vs Brave&lt;/head&gt;
    &lt;p&gt;We love what Brave started, but they've spread themselves too thin with crypto, search, VPNs. We're laser-focused on AI-powered browsing.&lt;/p&gt;
    &lt;head&gt;vs Arc/Dia&lt;/head&gt;
    &lt;p&gt;Many loved Arc, but it was closed source. When they abandoned users, there was no recourse. We're 100% open source - fork it anytime!&lt;/p&gt;
    &lt;head&gt;vs Perplexity Comet&lt;/head&gt;
    &lt;p&gt;They're a search/ad company. Your browser history becomes their product. We keep everything local.&lt;/p&gt;
    &lt;head&gt;vs ChatGPT Atlas&lt;/head&gt;
    &lt;p&gt;Your browsing data could be used for ads or to train their models. We keep your history and agent interactions strictly local.&lt;/p&gt;
    &lt;p&gt;We'd love your help making BrowserOS better!&lt;/p&gt;
    &lt;p&gt;BrowserOS is open source under the AGPL-3.0 license.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ungoogled-chromium - BrowserOS uses some patches for enhanced privacy. Thanks to everyone behind this project!&lt;/item&gt;
      &lt;item&gt;The Chromium Project - At the core of BrowserOS, making it possible to exist in the first place.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Thank you to all our supporters!&lt;/p&gt;
    &lt;p&gt;Built with ‚ù§Ô∏è from San Francisco&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/browseros-ai/BrowserOS"/><published>2026-01-22T16:30:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46721488</id><title>Show HN: Text-to-video model from scratch (2 brothers, 2 years, 2B params)</title><updated>2026-01-23T07:18:42.114673+00:00</updated><content>&lt;doc fingerprint="745d5508e730e637"&gt;
  &lt;main&gt;
    &lt;p&gt;Hugging Face Models Datasets Spaces Community Docs Enterprise Pricing Log In Sign Up Linum-AI 's Collections Linum v2 (2B, text-to-video) Linum v2 (2B, text-to-video) updated about 14 hours ago 360p or 720p, 2-5 seconds, Apache 2.0 Upvote 4 Linum-AI/linum-v2-360p Text-to-Video ‚Ä¢ Updated 2 days ago ‚Ä¢ 5 Linum-AI/linum-v2-720p Text-to-Video ‚Ä¢ Updated 3 days ago ‚Ä¢ 15 Upvote 4 Share collection View history Collection guide Browse collections&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://huggingface.co/collections/Linum-AI/linum-v2-2b-text-to-video"/><published>2026-01-22T16:31:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46721802</id><title>Show HN: isometric.nyc ‚Äì giant isometric pixel art map of NYC</title><updated>2026-01-23T07:18:41.891581+00:00</updated><link href="https://cannoneyed.com/isometric-nyc/"/><published>2026-01-22T16:52:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46721897</id><title>AnswerThis (YC F25) Is Hiring</title><updated>2026-01-23T07:18:41.512022+00:00</updated><content>&lt;doc fingerprint="3d09585cf826800c"&gt;
  &lt;main&gt;
    &lt;p&gt;End-to-end workspace to accelerate scientific discovery&lt;/p&gt;
    &lt;p&gt;We crossed $1M ARR in 8 months. 200,000+ researchers at Stanford, MIT, and Amazon use us to do literature reviews 10x faster.&lt;lb/&gt; Now we're building something bigger: the system of record for scientists where they can find papers, analyze experiments, and write their drafts while collaborating with other scientists as well as our AI agents. &lt;lb/&gt; You should apply if you:&lt;lb/&gt; ‚Üí Ship fast and learn faster &lt;lb/&gt; ‚Üí Know the agentic AI stack cold (vector DBs, graph RAG, agent memory) &lt;lb/&gt; ‚Üí Have built full-stack products that scaled past 1M users &lt;lb/&gt; ‚Üí Actually care about accelerating scientific discovery&lt;lb/&gt; Bonus: You've published research yourself. &lt;lb/&gt; Don't apply if you:&lt;lb/&gt; ‚Üí Can't be in SF, in person &lt;lb/&gt; ‚Üí Haven't used the product yet &lt;lb/&gt; ‚Üí Don't want to talk to customers &lt;lb/&gt; $120K-$200K + equity. We're a small team backed by YC. &lt;lb/&gt; Reach out on careers [at] answerthis.io&lt;lb/&gt; Tell us what you hate about AnswerThis, what you love, and one project you're proud of alongside your resume.&lt;lb/&gt; Science moves too slowly. Help us fix that.&lt;/p&gt;
    &lt;p&gt;We move fast. The whole process can be done in 2-3 weeks.&lt;/p&gt;
    &lt;p&gt;AnswerThis is building the system of record for scientists‚Äîwhere researchers can find papers, analyze experiments, and write drafts while collaborating with other scientists and AI agents.&lt;/p&gt;
    &lt;p&gt;We crossed $1M ARR in 8 months. 200,000+ researchers at Stanford, MIT, Amazon, and top institutions worldwide use us daily. We're backed by Y Combinator (F25) and cash-flow positive.&lt;/p&gt;
    &lt;p&gt;Science moves too slowly. Grant applications take months. Literature reviews take weeks. Researchers spend more time on paperwork than on discovery. We're fixing that.&lt;/p&gt;
    &lt;p&gt;You'll be joining a small, fast team in SF that ships constantly and talks to customers every day.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/answerthis/jobs/r5VHmSC-ai-agent-orchestration"/><published>2026-01-22T17:00:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46721933</id><title>Launch HN: Constellation Space (YC W26) ‚Äì AI for satellite mission assurance</title><updated>2026-01-23T07:18:41.390003+00:00</updated><content>&lt;doc fingerprint="22906374e6a95fca"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hi HN! We're Kamran, Raaid, Laith, and Omeed from Constellation Space (&lt;/p&gt;https://constellation-io.com/&lt;p&gt;). We built an AI system that predicts satellite link failures before they happen. Here's a video walkthrough: &lt;/p&gt;https://www.youtube.com/watch?v=069V9fADAtM&lt;p&gt;.&lt;/p&gt;&lt;p&gt;Between us, we've spent years working on satellite operations at SpaceX, Blue Origin, and NASA. At SpaceX, we managed constellation health for Starlink. At Blue, we worked on next-gen test infra for New Glenn. At NASA, we dealt with deep space communications. The same problem kept coming up: by the time you notice a link is degrading, you've often already lost data.&lt;/p&gt;&lt;p&gt;The core issue is that satellite RF links are affected by dozens of interacting variables. A satellite passes overhead, and you need to predict whether the link will hold for the next few minutes. That depends on: the orbital geometry (elevation angle changes constantly), tropospheric attenuation (humidity affects signal loss via ITU-R P.676), rain fade (calculated via ITU-R P.618 - rain rates in mm/hr translate directly to dB of loss at Ka-band and above), ionospheric scintillation (we track the KP index from magnetometer networks), and network congestion on top of all that.&lt;/p&gt;&lt;p&gt;The traditional approach is reactive. Operators watch dashboards, and when SNR drops below a threshold, they manually reroute traffic or switch to a backup link. With 10,000 satellites in orbit today and 70,000+ projected by 2030, this doesn't scale. Our system ingests telemetry at around 100,000 messages per second from satellites, ground stations, weather radar, IoT humidity sensors, and space weather monitors. We run physics-based models in real-time - the full link budget equations, ITU atmospheric standards, orbital propagation - to compute what should be happening. Then we layer ML models on top, trained on billions of data points from actual multi-orbit operations.&lt;/p&gt;&lt;p&gt;The ML piece is where it gets interesting. We use federated learning because constellation operators (understandably) don't want to share raw telemetry. Each constellation trains local models on their own data, and we aggregate only the high-level patterns. This gives us transfer learning across different orbit types and frequency bands - learnings from LEO Ka-band links help optimize MEO or GEO operations. We can predict most link failures 3-5 minutes out with &amp;gt;90% accuracy, which gives enough time to reroute traffic before data loss. The system is fully containerized (Docker/Kubernetes) and deploys on-premise for air-gapped environments, on GovCloud (AWS GovCloud, Azure Government), or standard commercial clouds.&lt;/p&gt;&lt;p&gt;Right now we're testing with defense and commercial partners. The dashboard shows real-time link health, forecasts at 60/180/300 seconds out, and root cause analysis (is this rain fade? satellite setting below horizon? congestion?). We expose everything via API - telemetry ingestion, predictions, topology snapshots, even an LLM chat endpoint for natural language troubleshooting.&lt;/p&gt;&lt;p&gt;The hard parts we're still working on: prediction accuracy degrades for longer time horizons (beyond 5 minutes gets dicey), we need more labeled failure data for rare edge cases, and the federated learning setup requires careful orchestration across different operators' security boundaries. We'd love feedback from anyone who's worked on satellite ops, RF link modeling, or time-series prediction at scale. What are we missing? What would make this actually useful in a production NOC environment?&lt;/p&gt;&lt;p&gt;Happy to answer any technical questions!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46721933"/><published>2026-01-22T17:03:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46722074</id><title>Composing APIs and CLIs in the LLM era</title><updated>2026-01-23T07:18:40.992231+00:00</updated><content>&lt;doc fingerprint="b7e1c59035133bd8"&gt;
  &lt;main&gt;
    &lt;p&gt;It√¢s early 2026. Industry practice is divided on how to structure tool descriptions within the context window of an LLM. One strategy is to provide top-level tools that perform fine grained actions (e.g. list pull requests in a GitHub repo). Another increasingly popular strategy is to eschew new tools per se and to simply inform the model of useful shell commands it may invoke. In both cases reusable skills can be defined that give the model tips on how to perform useful work with the tools; the main difference is whether the model emits a direct tool call or instead an &lt;code&gt;exec_bash&lt;/code&gt; call containing a reference to CLIs.&lt;/p&gt;
    &lt;p&gt;To me it is clear that the latter represents an innovation on the former. The best feature of the unix shell is command composition. Enabling the model to form pipelines of tool calls without re-prompting the model after each stage should present huge savings in token cost. The resulting pipelines can also be saved to scripts or be customized and interactively executed by human operators.&lt;/p&gt;
    &lt;p&gt;The command line is an interface compatible with humans and machines. If the model is adept at using it (it√¢s already text), why fall back to a machine-native protocol?&lt;/p&gt;
    &lt;p&gt;One good response is that MCP is an easy way to expose SaaS functionality to agents. In lieu of MCP, how can we achieve that? I√¢ll answer this question by providing two quite different examples from my recent work: giving an agent access to Google Docs and to Google Groups.&lt;/p&gt;
    &lt;head rend="h2"&gt;HTTP APIs&lt;/head&gt;
    &lt;p&gt;I wanted my agent to be able to list my cloud-based Google Docs, to read them as markdown, and to read and understand any attached comment threads.&lt;/p&gt;
    &lt;p&gt;Google provides a very nice API to fulfill all of this functionality (well, comments are harder). I did the obvious thing and spun up a Google Cloud project, pasted the API documentation into an LLM, and the result was a &lt;code&gt;gdrive&lt;/code&gt; CLI with subcommands to list files and to export a particular one.&lt;/p&gt;
    &lt;p&gt;That worked. But as in the title of this post, the best code is no code. This script seemed entirely like boilerplate which shouldn√¢t have to exist. This would be true even if the script were to use an SDK rather than make HTTP calls directly. In reality, Google√¢and many SaaS vendors√¢already define a program which can be used to call all of their APIs. It√¢s their OpenAPI spec! The program just needs a sufficient interpreter.&lt;/p&gt;
    &lt;p&gt;I Googled around and was thrilled to discover Restish, a tool which nearly perfectly matches my philosophy. If OpenAPI specs are programs, Restish is their interpreter. Sample usage (cribbed from their docs):&lt;/p&gt;
    &lt;quote&gt;# Register a new API called `cool-api` $ restish api configure cool-api https://api.rest.sh/openapi.yaml # This will show you all available commands from the API description. $ restish cool-api --help # Call an API operation (`list-images`) $ restish -r cool-api -H 'Accept: application/json' list-images | jq '.[0].name' "Dragonfly macro"&lt;/quote&gt;
    &lt;p&gt;Restish even generates shell completions for the API endpoints (subcomands) and parameters (options/args)!&lt;/p&gt;
    &lt;p&gt;I have only two complaints:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Restish wants to handle API authorization for me (persisting e.g. OAuth tokens). I want it to just be an √¢interpreter for OpenAPI programs√¢. I√¢ll manage my own auth flows and inject my own tokens.&lt;/item&gt;
      &lt;item&gt;Executing commands against an api spec requires registering the spec with Restish ahead of time. See above√¢I want just an interpreter.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Both points imply that I√¢ll want a wrapper script around restish. The wrapper script will manage the second issue (it will create a temporary spec directory to satisfy Restish). The script will also perform my desired authorization flow and inject tokens into Restish ephemerally.&lt;/p&gt;
    &lt;head rend="h2"&gt;API Authorization&lt;/head&gt;
    &lt;p&gt;Looking back at the omnibus script that I generated initially, it contained an OAuth 2.0 client to hit Google√¢s authorization flow, get tokens, and refresh them upon expiry. OAuth 2.0 is a standard. A particular set of parameters (Google√¢s OAuth URL, client id, client secret, grant type, scopes) could be thought of as a valid program in the OAuth 2.0 client language.&lt;/p&gt;
    &lt;p&gt;I, again, just needed an interpreter. I, again, found one.&lt;/p&gt;
    &lt;p&gt;oauth2c is a command-line client for OAuth 2.0-compliant authorization servers. You input the aforementioned program (i.e. URL, grant type, ...) and it begins the ensuing flow (usually by opening your browser) then prints the resulting tokens to stdout.&lt;/p&gt;
    &lt;p&gt;With this missing piece, what was previously a couple-hundred lines of dense Python is now an order-of-magnitude smaller shell script which performs the logical equivalent of &lt;code&gt;oauth2c "https://accounts.google.com/..." | restish google drive-files-list&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;I√¢ve published the resulting script to bmwalters/gdrive-client. The repo also contains a cool method for propagating shell completions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Detour: secure token storage for macOS CLI scripts&lt;/head&gt;
    &lt;p&gt;While I√¢m dispensing pro-tips, I should highlight this pretty cool and under-documented way to securely store data (like a long-lived refresh token) from a macOS shell script.&lt;/p&gt;
    &lt;p&gt;Let me introduce the problem. The results of Google√¢s OAuth flow are a short-lived access token (to hit APIs; valid for about an hour) and a long-lived refresh token (to mint new access tokens; valid for 6 months). I wasn√¢t comfortable with leaving that refresh token exposed on my machine. Services like the AWS CLI do indeed store plaintext credentials in &lt;code&gt;~&lt;/code&gt;, but those tend to expire much more frequently than 6 months.&lt;/p&gt;
    &lt;p&gt;I knew I wanted to reach for the macOS Keychain, and in particular some security level that would require biometrics / passcode when reading the refresh token.&lt;/p&gt;
    &lt;p&gt;macOS ships a handy keychain CLI named &lt;code&gt;security&lt;/code&gt;. You can store secrets in Keychain with invocations like &lt;code&gt;security add-generic-password -s google-api -a my-account -w $REFRESH_TOKEN&lt;/code&gt;. But biometrics are not trivially supported, and web search advised me to create a small Swift wrapper. After doing so, I learned that any &lt;code&gt;kSecAttrAccessControl&lt;/code&gt; attribute that would lead to biometrics or device passcode would result in the binary requiring real signed entitlements through the Apple Developer Program. I was a bit stuck looking for a solution to what seemed to be a simple requirement.&lt;/p&gt;
    &lt;p&gt;I ran the &lt;code&gt;security&lt;/code&gt; man page through Claude Opus 4.5 and the model made a very interesting discovery.&lt;/p&gt;
    &lt;quote&gt;-T appPath Specify an application which may access this item (multiple -T options are allowed)&lt;/quote&gt;
    &lt;p&gt;It turns out that the keychain remembers which application stored the password√¢by default this is probably &lt;code&gt;security&lt;/code&gt; itself or perhaps my shell; I haven√¢t checked√¢and that application is permitted to read back the password without user-interactive authorization. Providing the &lt;code&gt;-T&lt;/code&gt; flag to &lt;code&gt;security&lt;/code&gt; when creating the password allows overriding said program entry, and crucially the empty string may be used to remove the default application entry.&lt;/p&gt;
    &lt;p&gt;In other words this code:&lt;/p&gt;
    &lt;quote&gt;security add-generic-password -T"" ...&lt;/quote&gt;
    &lt;p&gt;will prevent &lt;code&gt;security find-generic-password&lt;/code&gt; from simply returning the secret, even when invoked immediately after secret creation. In practice, attempts to read the secret will prompt me for my device passcode, which is definitely good enough for my use case.&lt;/p&gt;
    &lt;p&gt;Putting it all together, I had a CLI that, when invoked, would try to use the stored access token with Restish (no passcode prompt needed). If the access token was invalid, it would invoke &lt;code&gt;oauth2c&lt;/code&gt; to refresh the token and retry. This would prompt me for my devcie passcode. If that also failed, it would invoke the Authorization Code flow using &lt;code&gt;oauth2c&lt;/code&gt; which would seamlessly open my browser and retry the command on success.&lt;/p&gt;
    &lt;p&gt;All with only shell pipelines, no bespoke code. Vastly reduced surface area for future maintenance and for bugs to hide in.&lt;/p&gt;
    &lt;head rend="h2"&gt;Adversarial interoperability&lt;/head&gt;
    &lt;p&gt;That√¢s all-well-and-good for services which provide machine-readable API specs, but what about those which are less charitable?&lt;/p&gt;
    &lt;p&gt;Google Groups is one such case. I wanted to export the discussion history from pollenpub to serve as a Q&amp;amp;A knowledge base while developing this blog site. However my research turned up no such API from Google.&lt;/p&gt;
    &lt;p&gt;I love using LLMs to solve this class of problem. My workflow is as follows:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Open a fresh private browser (to capture any authorization flow, if needed).&lt;/item&gt;
      &lt;item&gt;Open Devtools &amp;gt; Network and filter to HTML, XHR, WS, Other.&lt;/item&gt;
      &lt;item&gt;Perform the actions that I would like to automate, i.e. load the Google Group site, navigate to the next page, and read a particular conversation.&lt;/item&gt;
      &lt;item&gt;Firefox Devtools &amp;gt; Network &amp;gt; right click &amp;gt; √¢Save All As HAR√¢.&lt;/item&gt;
      &lt;item&gt;Run the file through cloudflare/har-sanitizer&lt;/item&gt;
      &lt;item&gt;Prompt an LLM with: √¢in this directory there is a large HAR file captured while I did actions xyz; please create a Python client for this API√¢.&lt;/item&gt;
      &lt;item&gt;Edit the generated file to add a meaningful &lt;code&gt;User-Agent&lt;/code&gt;string with a backlink.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I√¢ve repeated this workflow about three times and I have near-term plans for a couple more.&lt;/p&gt;
    &lt;p&gt;Note that I haven√¢t tried combining the above two workflows yet: I haven√¢t asked the model to produce an OpenAPI spec + reverse-engineered OAuth parameters, but that√¢s a logical next step.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;There√¢s a lot of power in composing CLIs. You get human interaction and current-generation-LLM interaction for the price of one. And with some creativity, it√¢s often possible for one individual to maintain CLIs in place of an MCP server that has been developed for a given service, or even to do so before the comparable MCP server has been written.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://walters.app/blog/composing-apis-clis"/><published>2026-01-22T17:14:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46722570</id><title>CSS Optical Illusions</title><updated>2026-01-23T07:18:40.735462+00:00</updated><content>&lt;doc fingerprint="860c29efdbe599e5"&gt;
  &lt;main&gt;
    &lt;p&gt;You can find a collection with all the optical illusions in this article (and more!) on CodePen. You can move your mouse over many of the demos below to reveal the effect or stop the animations.&lt;/p&gt;
    &lt;head rend="h2"&gt;1 - Poggendorff Illusions&lt;/head&gt;
    &lt;p&gt;The Poggendorff illusion is an optical illusion in which a diagonal line interrupted by a vertical bar appears misaligned, even when both segments are actually continuous.&lt;/p&gt;
    &lt;p&gt;A simple version of this effect can be seen in the following demo. I used the &lt;code&gt;::before&lt;/code&gt; and¬†&lt;code&gt;::after&lt;/code&gt; pseudo-elements to create the diagonal line and the vertical bar, respectively.&lt;/p&gt;
    &lt;p&gt;The effect can also be seen in a more elaborate version with multiple diagonal lines and vertical bars:&lt;/p&gt;
    &lt;p&gt;This drawing can easily be achieved using two CSS gradients: one tilted at 70 degrees and another consisting of a series of vertical columns. I applied it to the &lt;code&gt;body&lt;/code&gt;, although I could have used¬†&lt;code&gt;:root&lt;/code&gt; instead.&lt;/p&gt;
    &lt;p&gt;Another variation of this illusion is the M√ºnsterberg Poggendorff Arch, in which the two sides of an arch appear misaligned and seem as though they will not meet at the top - but they do (mouse over to see it).&lt;/p&gt;
    &lt;head rend="h2"&gt;2 - Induced Gradients&lt;/head&gt;
    &lt;p&gt;The following illusions combine gradients and flat colors. Surprisingly, some of the gradients do not actually exist. They are simple gray bars that, when placed over a gradient, appear to have gradients themselves.&lt;/p&gt;
    &lt;p&gt;Take the following demo: all three bars (two vertical ones on the sides and one horizontal bar in the center) are the same shade of gray. The only real gradient is behind them, which tricks our brain into believing that the bars are different colors and even contain gradients.&lt;/p&gt;
    &lt;p&gt;Here is another variation of this effect. It looks like the central line has a repeating gradient of dark and light grays, but in reality it is a flat color. If you mouse over the demo, the bar will expand, making it clear that there is no gradient at all.&lt;/p&gt;
    &lt;head rend="h2"&gt;3 - Cornsweet Illusion&lt;/head&gt;
    &lt;p&gt;The next few optical illusions share a common idea: some colors are identical, but they do not look the same. This typically happens when regions of the same color or brightness are surrounded by areas with different contrast.&lt;/p&gt;
    &lt;p&gt;For example, in the following demo, the left and right ends are the same shade of gray. However, one looks lighter because it is closer to white, while the other looks darker because it is closer to black. Mouse over to reveal that they are, in fact, the same color.&lt;/p&gt;
    &lt;head rend="h2"&gt;4 - White's Illusion&lt;/head&gt;
    &lt;p&gt;Run the following demo. You will see two gray columns in a black-and-white grid. Both columns are the same shade of gray, but the one surrounded by black appears darker than the one surrounded by white.&lt;/p&gt;
    &lt;p&gt;I coded this demo using &lt;code&gt;mix-blend-mode&lt;/code&gt; so I could try something a bit different. That worked well, but it also made it harder to showcase the effect on hover. In hindsight, I should have planned that better.&lt;/p&gt;
    &lt;p&gt;This optical illusion also works with colors. For example, these two squares appear to be different shades of blue, but they are the same color. This time, you can mouse over to reveal the effect:&lt;/p&gt;
    &lt;head rend="h2"&gt;5 - Wertheimer-Koffka Ring&lt;/head&gt;
    &lt;p&gt;The ring in the following illustration has the same color all the way around. However, one side is placed over white and the other over black, which makes them look different. If you mouse over the demo, the red bar will disappear, making it more obvious that the ring is a single, uniform color.&lt;/p&gt;
    &lt;head rend="h2"&gt;6 - Adelson's Illusion&lt;/head&gt;
    &lt;p&gt;You have probably seen the illusion involving a checkerboard and an object casting a shadow, where two tiles - one seemingly light and one seemingly dark - turn out to be the same color.&lt;/p&gt;
    &lt;p&gt;This demo follows the same principle. You will see two tiles labeled A and B. Both have the same shade of gray, but most people cannot tell at first glance (or second, or even third).&lt;/p&gt;
    &lt;head rend="h2"&gt;7 - Asahi illusion of Brightness&lt;/head&gt;
    &lt;p&gt;The circle at the center of this flower-shaped element is the same white as the rest of the page, but it gives the impression of being brighter, as if it were emitting light.&lt;/p&gt;
    &lt;head rend="h2"&gt;8 - Color Spheres&lt;/head&gt;
    &lt;p&gt;This is one of my favorite illusions in the collection. The circles (or spheres) look red, blue, or green, but in reality they are all the same grayish color. Our brain "colorizes" them based on the lines that overlap the shapes. Don't believe it? Mouse over the illustration.&lt;/p&gt;
    &lt;head rend="h2"&gt;9 - Colors from Contour&lt;/head&gt;
    &lt;p&gt;In the following illustration, the lines inside the yellow section appear blue, while the lines inside the blue section appear red... but they are all black (or very dark gray). The white contour creates the illusion of color. Mouse over to remove the contour and the lines will clearly appear black.&lt;/p&gt;
    &lt;head rend="h2"&gt;10 - Curvature Blindness&lt;/head&gt;
    &lt;p&gt;One set of lines looks straighter (top) while the other looks more curved (bottom). In reality, both sets are equally wavy. The only difference is how they are colored: changing the color at the peaks makes the lines look straighter. Changing it at the inflection points makes them look more curved.&lt;/p&gt;
    &lt;p&gt;The CSS code for the wavy lines is adapted from a Temani Afif snippet on CSS-Tricks and his wavy shape generator.&lt;/p&gt;
    &lt;head rend="h2"&gt;11 - Cafe Wall&lt;/head&gt;
    &lt;p&gt;This is a classic optical illusion and an easy one to code in CSS. Three gradients are all that is needed to generate the effect in which the horizontal lines appear slanted, even though they are perfectly parallel.&lt;/p&gt;
    &lt;head rend="h2"&gt;12 - Penrose Triangle&lt;/head&gt;
    &lt;p&gt;This optical illusion depicts an impossible shape. Parts that should be in front appear in the back, top becomes right, and everything feels contradictory. I coded this one some time ago for the 2024 Divtober event.&lt;/p&gt;
    &lt;head rend="h2"&gt;13 - Ebbinghaus Illusion&lt;/head&gt;
    &lt;p&gt;Which orange circle is larger: the one on the right or the one on the left? It is a trick question: both are the same size. However, having smaller surrounding elements gives the impression that one is larger.&lt;/p&gt;
    &lt;p&gt;I also created an animated version of this illusion (see below), as well as another version using a square shape instead of a flower shape:&lt;/p&gt;
    &lt;head rend="h2"&gt;14 - Kanizsa Square&lt;/head&gt;
    &lt;p&gt;When people look at this illustration, they usually say they see a white square over black circles. However, the square is not actually there. The "Pac-Man" shapes create the illusion of a square and a sense of depth. Our brain fills in the missing information.&lt;/p&gt;
    &lt;head rend="h2"&gt;15 - Ehrenstein's Illusion&lt;/head&gt;
    &lt;p&gt;There are no circles or discs in this illustration, only vertical and horizontal lines forming crosses. Our visual system completes the shape and makes us perceive a disc that does not exist.&lt;/p&gt;
    &lt;head rend="h2"&gt;16 - Neon-Color-Spreading Illusion&lt;/head&gt;
    &lt;p&gt;This illustration shows concentric circles, some of which have a green-and-black pattern. Our brain perceives a central patterned circle and four concentric circles around it, beneath the green circle.&lt;/p&gt;
    &lt;p&gt;I cheated a little when creating this in CSS, as I actually used a green circle blended with the other backgrounds.&lt;/p&gt;
    &lt;head rend="h2"&gt;17 - Hering and Wundt Illusions&lt;/head&gt;
    &lt;p&gt;Perspective-based illusions are fascinating. Even when we know we are looking at a flat image, our brain insists on interpreting depth.&lt;/p&gt;
    &lt;p&gt;In the Hering illusion, the red lines appear to curve outward, even though they are straight.&lt;/p&gt;
    &lt;p&gt;The opposite effect is the Wundt illusion. When the lines expand from the sides toward the center, the red lines appear to curve inward (this effect is more subtle).&lt;/p&gt;
    &lt;head rend="h2"&gt;18 - Ponzo Illusion&lt;/head&gt;
    &lt;p&gt;Both yellow lines are the same length, but the top one looks longer due to perceived depth and perspective. I tried a different approach when coding this one by applying a three-dimensional rotation in CSS... so the perspective is technically real.&lt;/p&gt;
    &lt;head rend="h2"&gt;19 - T Illusion&lt;/head&gt;
    &lt;p&gt;This illusion is easy to code in CSS and easy to fall for. Both the vertical and horizontal lines are the same length, but the vertical line appears longer.&lt;/p&gt;
    &lt;head rend="h2"&gt;20 - M√ºller-Lyer Illusion&lt;/head&gt;
    &lt;p&gt;A classic illusion: the horizontal lines are the same length, but inward- or outward-pointing edges dramatically change how we perceive them. I could swear the top one is longer. But it is not.&lt;/p&gt;
    &lt;p&gt; From a coding perspective, each shape is a pseudo-element. I ensured the horizontal lines were identical by using the same gradients and only repositioning the edges in the &lt;code&gt;::before&lt;/code&gt; and¬†&lt;code&gt;::after&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;21 - Tilted Table Illusion&lt;/head&gt;
    &lt;p&gt;It looks like the top rectangle is leaning to the left, but it is actually parallel to the one at the bottom. The trick lies in the direction of the diagonal lines used to "color" each rectangle.&lt;/p&gt;
    &lt;p&gt;This illusion works better on larger screens. The effect is diminished when you can see the whole picture.&lt;/p&gt;
    &lt;head rend="h2"&gt;22 - Parallel Lines&lt;/head&gt;
    &lt;p&gt;This is a simple effect: the black lines are parallel, but they appear not to be because of the direction of the bars crossing them.&lt;/p&gt;
    &lt;p&gt;I slightly overcomplicated this one while coding it. I initially built the black-and-red version below and tried to reuse more code than I probably should have.&lt;/p&gt;
    &lt;p&gt;Here is the original version I created. The effect is also visible there:&lt;/p&gt;
    &lt;p&gt;Good news! There are more optical illusions below - but first, a warning.&lt;/p&gt;
    &lt;p&gt;ATTENTION: The following optical illusions are static, but they give the impression of movement. Proceed accordingly.&lt;/p&gt;
    &lt;p&gt;(Leaving some blank space in case you do not want to continue.)&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;23 - Expanding Hole&lt;/head&gt;
    &lt;p&gt;This is a trippy optical illusion. It is completely static, yet it looks like the black hole at the center is expanding - especially when you are not looking at it directly, creating the sensation of falling into a pit.&lt;/p&gt;
    &lt;p&gt;From a coding perspective, this one was very simple: a background pattern made with two radial gradients, plus a blurred pseudo-element for the "expanding" hole.&lt;/p&gt;
    &lt;head rend="h2"&gt;24 - Rotating Snakes&lt;/head&gt;
    &lt;p&gt;This is one of only two optical illusions in this collection where I used HTML elements instead of relying exclusively on CSS. It is a classic effect: when you look at the illustration, the peripheral discs appear to rotate, even though nothing is actually moving.&lt;/p&gt;
    &lt;head rend="h2"&gt;25 - Appearing Dots&lt;/head&gt;
    &lt;p&gt;Another classic illusion. Focus on the white dots and the adjacent dots will appear to turn black. There is no animation, no transition, and nothing dynamic. Just intersecting lines and small white circles, yet it looks like motion.&lt;/p&gt;
    &lt;head rend="h2"&gt;26 - Disappearing Dots&lt;/head&gt;
    &lt;p&gt;This pattern consists of repeating black and white dots across the page. If you focus on one dot, the others will begin to disappear. At first it may happen by row or column, but after a short while, most of them vanish.&lt;/p&gt;
    &lt;p&gt;If you do not immediately see the effect, try focusing on one black dot. Mouse over it, wait a few seconds while keeping your focus, and then mouse out.&lt;/p&gt;
    &lt;head rend="h2"&gt;27 - Ouchi Illusion&lt;/head&gt;
    &lt;p&gt;This is a static image, but it gives the impression that the pattern inside the circle is moving sideways. This happens because our eyes are constantly making small movements, even when we are not aware of it.&lt;/p&gt;
    &lt;p&gt;If you cannot see the illusion, try slightly moving the screen (or your head) while looking just outside the circle.&lt;/p&gt;
    &lt;head rend="h2"&gt;28 - Orthogonal Dotted Lines Sway&lt;/head&gt;
    &lt;p&gt;When you look around this pattern, the central area appears to slide and sway, even though it is completely static. This illusion makes me dizzy... but that may also be because I had to stare at it for a long time while coding it.&lt;/p&gt;
    &lt;head rend="h2"&gt;29 - Enigma&lt;/head&gt;
    &lt;p&gt;This illusion is particularly interesting. There is a pink circle surrounded by concentric pink and purple rings. If you focus on the pink circle, the rings appear to spin or scintillate, as if there were some activity in them. Of course, nothing is actually moving.&lt;/p&gt;
    &lt;head rend="h2"&gt;30 - Waves&lt;/head&gt;
    &lt;p&gt;This demo was challenging to code and takes a long time to load. Mainly because it uses a large number of conic gradients behind the scenes, which browsers struggle to render efficiently. There is probably a better way to implement it, but I have not explored that yet.&lt;/p&gt;
    &lt;p&gt;If you look closely at the illustration, you may notice wave-like motion. As with the previous illusions in this section, the image is entirely static.&lt;/p&gt;
    &lt;p&gt;Good news! There are more optical illusions below - but first, another warning.&lt;/p&gt;
    &lt;p&gt;ATTENTION: The following optical illusions actually move, and the illusion is created by motion itself. Some of them can be dizzying, so proceed accordingly.&lt;/p&gt;
    &lt;p&gt;(Leaving some blank space in case you do not want to continue.)&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;p&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;31 - Animated Ebbinghaus Illusion&lt;/head&gt;
    &lt;p&gt;Earlier, we saw two static versions of the Ebbinghaus illusion. This one is animated. The elements move side to side, and the surrounding shapes grow and shrink, giving the impression that the orange circle is changing size - when it definitely is not.&lt;/p&gt;
    &lt;head rend="h2"&gt;32 - Psychokinematic Tower&lt;/head&gt;
    &lt;p&gt;This looks like a three-dimensional tower spinning in space, as seen from above. In reality, it is a flat, two-dimensional image rotating.&lt;/p&gt;
    &lt;p&gt;Mouse over the demo to stop the rotation and the illusion of depth disappears entirely.&lt;/p&gt;
    &lt;head rend="h2"&gt;33 - Color Fan&lt;/head&gt;
    &lt;p&gt;This optical illusion requires only two gradients: a conic gradient for the fan-shaped arms and a radial gradient for the circles and discs.&lt;/p&gt;
    &lt;p&gt;If you focus on the black dot, the illustration may appear to develop a darker greenish or brownish border. However, the colors never change.&lt;/p&gt;
    &lt;head rend="h2"&gt;34 - Reverse Spoke Illusion&lt;/head&gt;
    &lt;p&gt;This illusion is delightful and disorienting. While the background colors of the wheel are spinning, the spokes remain fixed. However, they appear to rotate in the opposite direction. In reality, only the background is moving.&lt;/p&gt;
    &lt;head rend="h2"&gt;35 - Motion Binding&lt;/head&gt;
    &lt;p&gt;What do you see in this animation? Most people report two sets of lines operating independently: one moving horizontally and another moving vertically. And that is exactly how it looks.&lt;/p&gt;
    &lt;p&gt;In reality, it is a single shape moving uniformly. Run the demo, mouse over the lines, and the true motion will be revealed.&lt;/p&gt;
    &lt;head rend="h2"&gt;36 - Mainz-Linez Illusion&lt;/head&gt;
    &lt;p&gt;Focus on one of the red dots. You will notice it moves straight up and down along a vertical path. Now shift your focus to one of the black crosses in the center. Suddenly, the red dots appear to zigzag instead of moving straight.&lt;/p&gt;
    &lt;p&gt;The CSS code for the wavy lines is adapted from a Temani Afif snippet on CSS-Tricks and his wavy shape generator.&lt;/p&gt;
    &lt;head rend="h2"&gt;37 - Waddling Colors&lt;/head&gt;
    &lt;p&gt;It may look like the boxes are moving at different speeds or like a set of walking feet. In reality, all elements move at the same pace and in parallel. Mouse over the demo to reveal the effect.&lt;/p&gt;
    &lt;p&gt;The illusion also works when the "feet" move in circles, as shown in this alternative version:&lt;/p&gt;
    &lt;head rend="h2"&gt;38 - Dotted-Line Motion&lt;/head&gt;
    &lt;p&gt;Follow the red dot as it moves sideways. From the corner of your vision, it may appear that the dashed black-and-white lines are moving closer together (when the dot moves left) or farther apart (when it moves right). In reality, the lines are completely static.&lt;/p&gt;
    &lt;head rend="h2"&gt;39 - Contrast Asynchrony&lt;/head&gt;
    &lt;p&gt;These dots always have the same color. However, when placed against alternating backgrounds, they appear to jump or move out of sync because of how they blend with their surroundings.&lt;/p&gt;
    &lt;p&gt;Mouse over the demo to remove the background and the illusion disappears.&lt;/p&gt;
    &lt;head rend="h2"&gt;40 - Breathing Square&lt;/head&gt;
    &lt;p&gt;This illusion gives the impression that a blue square is growing and shrinking rhythmically, almost as if it were breathing or beating like a heart.&lt;/p&gt;
    &lt;p&gt;Although the image is rotating, its size never changes. Mouse over the illustration to remove the green boxes and reveal the rotating blue square.&lt;/p&gt;
    &lt;head rend="h2"&gt;41 - Troxler Fading&lt;/head&gt;
    &lt;p&gt;This illustration shows a circle made of pink dots, with one dot missing. Focus on the cross at the center and the missing dot will appear as a yellow or green dot, giving the impression that it is "eating" the pink dots. Just like Pac-Man.&lt;/p&gt;
    &lt;p&gt;I could have used CSS trigonometric functions to calculate the exact positions of the dots, but since they never change, I chose to hardcode the values instead.&lt;/p&gt;
    &lt;p&gt;Here is a related effect. Follow the light gray circle as it spins, and the darker circles will appear to change from gray to greenish. Focus on the cross at the center, and after a short time, the darker circles may begin to fade entirely.&lt;/p&gt;
    &lt;head rend="h2"&gt;42 - Pinna-Brelstaff Illusion&lt;/head&gt;
    &lt;p&gt;This illusion is particularly dizzying. Follow the bluish dot as it moves from right to left and back again. It will appear as though parts of the tiled background are shifting, even though they are static. The only moving element is the dot.&lt;/p&gt;
    &lt;p&gt; From a CSS perspective, I coded the pattern using conic gradients, and applied it to the &lt;code&gt;::before&lt;/code&gt; and¬†&lt;code&gt;::after&lt;/code&gt; pseudo-elements. I then flipped one upside down and clipped it.&lt;/p&gt;
    &lt;head rend="h2"&gt;43 - Palisade&lt;/head&gt;
    &lt;p&gt;The radii of a wheel, when viewed through a palisade, appear to curve. In reality, they are perfectly straight. Mouse over the demo to remove the palisade and you will see that the radii never bend.&lt;/p&gt;
    &lt;head rend="h2"&gt;44 - Alternative Motion&lt;/head&gt;
    &lt;p&gt;This animation demonstrates how our minds infer motion that may not actually be there. Consider the two blue dots. Different people perceive different movements: side to side, top to bottom, or even circular motion.&lt;/p&gt;
    &lt;p&gt;Cover the right side of the animation so that you see only one dot at a time. The motion now appears vertical. Cover the bottom part instead, and the motion appears horizontal. This is our brain trying to complete the movement.&lt;/p&gt;
    &lt;head rend="h2"&gt;45 - Motion Inversion&lt;/head&gt;
    &lt;p&gt;These two illustrations are identical - same shapes, same animation. The only difference is the CSS timing function.&lt;/p&gt;
    &lt;p&gt;The top animation moves smoothly from right to left. The bottom one appears to move choppily in the same direction, but if you focus on it, it may suddenly seem to reverse direction and move faster.&lt;/p&gt;
    &lt;p&gt;Most of the inspiration for these optical illusions came from two excellent resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"35 optical illusions and why they trick your brain" by Patrick Pester.&lt;/item&gt;
      &lt;item&gt;"154 Visual Phenomena &amp;amp; Optical Illusions" with explanations by Michael Bach&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can also find this article on:&lt;/p&gt;
    &lt;p&gt;(You can leave comments on those platforms and I will reply there).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alvaromontoro.com/blog/68091/css-optical-illusions"/><published>2026-01-22T17:41:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46722853</id><title>Recent discoveries on the acquisition of the highest levels of human performance</title><updated>2026-01-23T07:18:40.432204+00:00</updated><content/><link href="https://www.science.org/doi/abs/10.1126/science.adt7790"/><published>2026-01-22T18:01:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46723384</id><title>I was banned from Claude for scaffolding a Claude.md file?</title><updated>2026-01-23T07:18:39.809628+00:00</updated><content>&lt;doc fingerprint="7a2301352c29c929"&gt;
  &lt;main&gt;
    &lt;p&gt;Excessive sitting isn't good for a person's physical or mental health, but there's a type of sedentary activity that may not shrink our brains or cost our cognition to the same extent.&lt;/p&gt;
    &lt;p&gt;A systematic review of 85 studies has now found good reason to differentiate between 'active' sitting, like playing cards or reading, and 'passive' sitting, like watching TV.&lt;/p&gt;
    &lt;p&gt;The former may actually boost brain health.&lt;/p&gt;
    &lt;p&gt;That's probably because active sitting engages the brain, whereas passive sitting lets a person take a back seat both physically and cognitively.&lt;/p&gt;
    &lt;p&gt;Related: Scientists Revealed How Much Exercise You Need to 'Offset' Sitting All Day&lt;/p&gt;
    &lt;p&gt;"Total sitting time has been shown to be related to brain health; however, sitting is often treated as a single entity, without considering the specific type of activity," explains public health researcher Paul Gardiner from the University of Queensland in Australia.&lt;/p&gt;
    &lt;p&gt;"Most people spend many hours sitting each day, so the type of sitting really matters ‚Ä¶ These findings show that small everyday choices ‚Äì like reading instead of watching television ‚Äì may help keep your brain healthier as you age."&lt;/p&gt;
    &lt;p&gt;Obviously, exercise remains incredibly important for cognitive health, but giving your brain a workout is also important, and that doesn't necessarily mean you have to be on your feet.&lt;/p&gt;
    &lt;p&gt;Across numerous studies, Gardiner and colleagues found that active sitting activities, like reading, playing card games, and using a computer, showed "overwhelmingly positive associations with cognitive health, enhancing cognitive functions such as executive function, situational memory, and working memory."&lt;/p&gt;
    &lt;p&gt;Meanwhile, passive sitting was most consistently associated with negative cognitive outcomes, including increased risk of dementia.&lt;/p&gt;
    &lt;p&gt;The effect sizes were small but significant. The study authors hope their results will help inform future health research and more nuanced health guidance.&lt;/p&gt;
    &lt;p&gt;For example, the researchers suggest guidelines should recognize the difference between passively watching TV and actively using a computer, and encourage people to take short breaks to stimulate their brains and move.&lt;/p&gt;
    &lt;p&gt;Their review focused on studies of typical sedentary activities in natural settings, rather than structured programs designed to boost brain function, making it relevant to people's everyday lives.&lt;/p&gt;
    &lt;p&gt;"Health advice could shift from simply saying 'sit less' to encouraging more mentally engaging activities while sitting," argues Gardiner.&lt;/p&gt;
    &lt;p&gt;"This could help people make easy, realistic changes that support long‚Äëterm brain health and potentially reduce dementia risk."&lt;/p&gt;
    &lt;p&gt;The study was published in the Journal of Alzheimer's Disease.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://hugodaniel.com/posts/claude-code-banned-me/"/><published>2026-01-22T18:38:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46723694</id><title>'Active' sitting is better for brain health: review of studies</title><updated>2026-01-23T07:18:39.629633+00:00</updated><content>&lt;doc fingerprint="7a2301352c29c929"&gt;
  &lt;main&gt;
    &lt;p&gt;Excessive sitting isn't good for a person's physical or mental health, but there's a type of sedentary activity that may not shrink our brains or cost our cognition to the same extent.&lt;/p&gt;
    &lt;p&gt;A systematic review of 85 studies has now found good reason to differentiate between 'active' sitting, like playing cards or reading, and 'passive' sitting, like watching TV.&lt;/p&gt;
    &lt;p&gt;The former may actually boost brain health.&lt;/p&gt;
    &lt;p&gt;That's probably because active sitting engages the brain, whereas passive sitting lets a person take a back seat both physically and cognitively.&lt;/p&gt;
    &lt;p&gt;Related: Scientists Revealed How Much Exercise You Need to 'Offset' Sitting All Day&lt;/p&gt;
    &lt;p&gt;"Total sitting time has been shown to be related to brain health; however, sitting is often treated as a single entity, without considering the specific type of activity," explains public health researcher Paul Gardiner from the University of Queensland in Australia.&lt;/p&gt;
    &lt;p&gt;"Most people spend many hours sitting each day, so the type of sitting really matters ‚Ä¶ These findings show that small everyday choices ‚Äì like reading instead of watching television ‚Äì may help keep your brain healthier as you age."&lt;/p&gt;
    &lt;p&gt;Obviously, exercise remains incredibly important for cognitive health, but giving your brain a workout is also important, and that doesn't necessarily mean you have to be on your feet.&lt;/p&gt;
    &lt;p&gt;Across numerous studies, Gardiner and colleagues found that active sitting activities, like reading, playing card games, and using a computer, showed "overwhelmingly positive associations with cognitive health, enhancing cognitive functions such as executive function, situational memory, and working memory."&lt;/p&gt;
    &lt;p&gt;Meanwhile, passive sitting was most consistently associated with negative cognitive outcomes, including increased risk of dementia.&lt;/p&gt;
    &lt;p&gt;The effect sizes were small but significant. The study authors hope their results will help inform future health research and more nuanced health guidance.&lt;/p&gt;
    &lt;p&gt;For example, the researchers suggest guidelines should recognize the difference between passively watching TV and actively using a computer, and encourage people to take short breaks to stimulate their brains and move.&lt;/p&gt;
    &lt;p&gt;Their review focused on studies of typical sedentary activities in natural settings, rather than structured programs designed to boost brain function, making it relevant to people's everyday lives.&lt;/p&gt;
    &lt;p&gt;"Health advice could shift from simply saying 'sit less' to encouraging more mentally engaging activities while sitting," argues Gardiner.&lt;/p&gt;
    &lt;p&gt;"This could help people make easy, realistic changes that support long‚Äëterm brain health and potentially reduce dementia risk."&lt;/p&gt;
    &lt;p&gt;The study was published in the Journal of Alzheimer's Disease.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sciencealert.com/not-all-sitting-is-equal-one-type-was-just-linked-to-better-brain-health"/><published>2026-01-22T19:03:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46723990</id><title>Why does SSH send 100 packets per keystroke?</title><updated>2026-01-23T07:18:39.379010+00:00</updated><content>&lt;doc fingerprint="c61ded10eca0acfa"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Why does SSH send 100 packets per keystroke?&lt;/head&gt;
    &lt;p&gt;And why do I care?&lt;/p&gt;
    &lt;p&gt;Jan 22, 2026&lt;/p&gt;
    &lt;p&gt;Here are a few lines of summarized &lt;code&gt;tcpdump&lt;/code&gt; output for an ssh session where I send a single keystroke:&lt;/p&gt;
    &lt;code&gt;$ ./first_lines_of_pcap.sh single-key.pcap
  1   0.000s  CLIENT-&amp;gt;SERVER   36 bytes
  2   0.007s  SERVER-&amp;gt;CLIENT  564 bytes
  3   0.015s  CLIENT-&amp;gt;SERVER    0 bytes
  4   0.015s  CLIENT-&amp;gt;SERVER   36 bytes
  5   0.015s  SERVER-&amp;gt;CLIENT   36 bytes
  6   0.026s  CLIENT-&amp;gt;SERVER    0 bytes
  7   0.036s  CLIENT-&amp;gt;SERVER   36 bytes
  8   0.036s  SERVER-&amp;gt;CLIENT   36 bytes
  9   0.046s  CLIENT-&amp;gt;SERVER    0 bytes
 10   0.059s  CLIENT-&amp;gt;SERVER   36 bytes
&lt;/code&gt;
    &lt;p&gt;I said a ‚Äúfew‚Äù because there are a lot of these lines.&lt;/p&gt;
    &lt;code&gt;$ ./summarize_pcap.sh single-key.pcap
Total packets: 270

  36-byte msgs:   179 packets ( 66.3%)   6444 bytes
  Other data:       1 packet  (  0.4%)    564 bytes
  TCP ACKs:        90 packets ( 33.3%)

  Data sent:      6444 bytes in 36-byte messages,  564 bytes in other data
  Ratio:          11.4x more data in 36-byte messages than other data

  Data packet rate: ~90 packets/second (avg 11.1 ms between data packets)
&lt;/code&gt;
    &lt;p&gt;That is a lot of packets for one keypress. What‚Äôs going on here? Why do I care?&lt;/p&gt;
    &lt;head class="sc-4d1d4ca-1 bowwWe"&gt;here's those scripts if you're curious&lt;/head&gt;
    &lt;code&gt;# first_lines_of_pcap.sh
tshark -r "$1" \
  -T fields -e frame.number -e frame.time_relative -e ip.src -e ip.dst -e tcp.len | \
  awk 'NR&amp;lt;=10 {dir = ($3 ~ /71\.190/ ? "CLIENT-&amp;gt;SERVER" : "SERVER-&amp;gt;CLIENT");
       printf "%3d  %6.3fs  %-4s  %3s bytes\n", $1, $2, dir, $5}'
&lt;/code&gt;
    &lt;code&gt;# summarize_pcap.sh
tshark -r "$1" -Y "frame.time_relative &amp;lt;= 2.0" -T fields -e frame.time_relative -e tcp.len | awk '
  {
      count++
      payload = $2

      if (payload == 0) {
          acks++
      } else if (payload == 36) {
          mystery++
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      } else {
          game_data++
          game_bytes = payload
          if (NR &amp;gt; 1 &amp;amp;&amp;amp; prev_data_time &amp;gt; 0) {
              delta = $1 - prev_data_time
              sum_data_deltas += delta
              data_intervals++
          }
          prev_data_time = $1
      }
  }
  END {
      print "Total packets:", count
      print ""
      printf "  36-byte msgs:   %3d packets (%5.1f%%)  %5d bytes\n", mystery, 100*mystery/count, mystery*36
      printf "  Other data:     %3d packet  (%5.1f%%)  %5d bytes\n", game_data, 100*game_data/count, game_bytes
      printf "  TCP ACKs:       %3d packets (%5.1f%%)\n", acks, 100*acks/count
      print ""
      printf "  Data sent:      %d bytes in 36-byte messages,  %d bytes in other data\n", mystery*36, game_bytes
      printf "  Ratio:          %.1fx more data in 36-byte messages than other data\n", (mystery*36)/game_bytes
      print ""
      avg_ms = (sum_data_deltas / data_intervals) * 1000
      printf "  Data packet rate: ~%d packets/second (avg %.1f ms between data packets)\n", int(1000/avg_ms + 0.5), avg_ms
  }'
&lt;/code&gt;
    &lt;head rend="h2"&gt;Discovery&lt;/head&gt;
    &lt;p&gt;I am working on a high-performance game that runs over ssh. The TUI for the game is created in bubbletea 1 and sent over ssh via wish.&lt;/p&gt;
    &lt;p&gt;I have also forked bubbletea to make it faster. Stay tuned!&lt;/p&gt;
    &lt;p&gt;The game is played in an 80x60 window that I update 10 times a second. I‚Äôm targeting at least 2,000 concurrent players, which means updating ~100 million cells a second. I care about performance.&lt;/p&gt;
    &lt;p&gt;So I have a script that connects a few hundred bots over ssh and has them make a move a second. Then I use go‚Äôs outstanding profiling tools to look at what‚Äôs going on.&lt;/p&gt;
    &lt;p&gt;Yesterday I inadvertently broke my test harness. Instead of regularly sending game data, my server sent the bots a single message that said ‚Äúyour screen is too small.‚Äù This cut my game‚Äôs CPU and bandwidth usage in half.&lt;/p&gt;
    &lt;p&gt;At first I was disappointed. I (briefly) thought I had a free massive speedup on my hands, but it was actually a testing error.&lt;/p&gt;
    &lt;p&gt;But wait.&lt;/p&gt;
    &lt;p&gt;If I wasn‚Äôt sending game data back to my bots, why did CPU usage drop by 50% instead of 100%?&lt;/p&gt;
    &lt;head rend="h2"&gt;Investigation&lt;/head&gt;
    &lt;p&gt;As part of debugging the test harness issue, I used &lt;code&gt;tcpdump&lt;/code&gt; to log game traffic with and without the breaking change. Something like:&lt;/p&gt;
    &lt;code&gt;# The game runs on port 22
timeout 30s tcpdump -i eth0 'port 22' -w with-breaking-change.pcap
# Revert change
timeout 30s tcpdump -i eth0 'port 22' -w without-breaking-change.pcap
&lt;/code&gt;
    &lt;p&gt;Our breaking change stopped us from rendering our game over ssh. So &lt;code&gt;with-breaking-change.pcap&lt;/code&gt; contains packets that represent the overhead of each connection without actually rendering the game.&lt;/p&gt;
    &lt;p&gt;I was debugging this with Claude Code, so I asked it to summarize what it saw in the pcap.&lt;/p&gt;
    &lt;code&gt;Wanna take a look yourself? I put with-breaking-change.pcap in this directory

--

Wow! Here's what I found:

Packet Size Distribution (413,703 total packets):
274,907 packets (66%): Exactly 36 bytes
138,778 packets (34%): 0 bytes (TCP ACKs)
18 packets (&amp;lt;0.1%): 72 bytes
&lt;/code&gt;
    &lt;p&gt;Further analysis on a smaller pcap pointed to these mysterious packets arriving ~20ms apart.&lt;/p&gt;
    &lt;p&gt;This was baffling to me (and to Claude Code). We kicked around several ideas like:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;SSH flow control messages&lt;/item&gt;
      &lt;item&gt;PTY size polling or other status checks&lt;/item&gt;
      &lt;item&gt;Some quirk of bubbletea or wish&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;One thing stood out - these exchanges were initiated by my ssh client (stock ssh installed on MacOS) - not by my server.&lt;/p&gt;
    &lt;p&gt;On a hunch, I took a &lt;code&gt;tcpdump&lt;/code&gt; of a regular ssh session.&lt;/p&gt;
    &lt;code&gt;# on my mac, in one tab
sudo tcpdump -ien0 'port 22'

# on my mac, in another tab
ssh $some_vm_of_mine
&lt;/code&gt;
    &lt;p&gt;I waited for the initial connection chatter to die down, sent one keystroke to my remote vm, and looked at the &lt;code&gt;tcpdump&lt;/code&gt; output.&lt;/p&gt;
    &lt;p&gt;I saw the exact same pattern! What in the world?&lt;/p&gt;
    &lt;head rend="h2"&gt;Root cause&lt;/head&gt;
    &lt;p&gt;Once I realized that this was a property of stock ssh and not my game, debugging got a lot easier.&lt;/p&gt;
    &lt;p&gt;Running &lt;code&gt;ssh -vvv&lt;/code&gt; gave me a pretty good sense of what was going on:&lt;/p&gt;
    &lt;code&gt;debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (49 chaff packets sent) 
debug3: obfuscate_keystroke_timing: starting: interval ~20ms
debug3: obfuscate_keystroke_timing: stopping: chaff time expired (101 chaff packets sent)
&lt;/code&gt;
    &lt;p&gt;That &lt;code&gt;20ms&lt;/code&gt; is a smoking gun - it lines up perfectly with the mysterious pattern we saw earlier! And the rest of the message is pretty helpful too - we sent 49 ‚Äúchaff‚Äù packets for the first keystroke and 101 ‚Äúchaff‚Äù for around the second one.&lt;/p&gt;
    &lt;p&gt;In 2023, ssh added keystroke timing obfuscation. The idea is that the speed at which you type different letters betrays some information about which letters you‚Äôre typing. So ssh sends lots of ‚Äúchaff‚Äù packets along with your keystrokes to make it hard for an attacker to determine when you‚Äôre actually entering keys.&lt;/p&gt;
    &lt;p&gt;That makes a lot of sense for regular ssh sessions, where privacy is critical. But it‚Äôs a lot of overhead for an open-to-the-whole-internet game where latency is critical.&lt;/p&gt;
    &lt;head rend="h2"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Keystroke obfuscation can be disabled client-side. After reverting my original breaking change, I tried updating my test harness to pass &lt;code&gt;ObscureKeystrokeTiming=no&lt;/code&gt; when starting up ssh sessions.&lt;/p&gt;
    &lt;p&gt;This worked great. CPU usage dropped dramatically and bots still received valid data.&lt;/p&gt;
    &lt;p&gt;But this is hardly a solution in the real world. I want &lt;code&gt;ssh mygame&lt;/code&gt; to Just Work without asking users to pass options that they might not understand.&lt;/p&gt;
    &lt;p&gt;Claude Code originally didn‚Äôt have much faith that we could disable this functionality server-side.&lt;/p&gt;
    &lt;p&gt;generated with simon wilson's excellent claude-code-transcripts tool&lt;/p&gt;
    &lt;p&gt;Fortunately, the description I found of SSH keystroke obfuscation made it easy to look up the relevant code in go‚Äôs ssh library (which I was transitively depending on).&lt;/p&gt;
    &lt;code&gt;Log message:
Introduce a transport-level ping facility

This adds a pair of SSH transport protocol messages SSH2_MSG_PING/PONG
to implement a ping capability. These messages use numbers in the "local
extensions" number space and are advertised using a "[email¬†protected]"
ext-info message with a string version number of "0".
&lt;/code&gt;
    &lt;p&gt;The ‚Äúchaff‚Äù messages that ssh uses to obscure keystrokes are SSH2_MSG_PING messages. And they‚Äôre sent to servers that advertise the availability of the &lt;code&gt;[email¬†protected]&lt;/code&gt; extension. What if we just‚Ä¶don‚Äôt advertise &lt;code&gt;[email¬†protected]&lt;/code&gt;?&lt;/p&gt;
    &lt;p&gt;I searched go‚Äôs ssh library for &lt;code&gt;[email¬†protected]&lt;/code&gt; and found the commit where support was added. The commit was tiny and seemed very easy to revert.&lt;/p&gt;
    &lt;p&gt;I cloned the go crypto repo and told Claude to revert this change and update our dependencies to use our clone (go‚Äôs replace directive makes forking a library very easy).&lt;/p&gt;
    &lt;p&gt;Then I re-ran my test harness. The results were‚Ä¶very good:&lt;/p&gt;
    &lt;code&gt;Total CPU  29.90%          -&amp;gt; 11.64%
Syscalls   3.10s           -&amp;gt; 0.66s
Crypto     1.6s            -&amp;gt; 0.11s
Bandwidth  ~6.5 Mbit/sec   -&amp;gt; ~3 Mbit/sec
&lt;/code&gt;
    &lt;p&gt;Claude was also pretty pumped:&lt;/p&gt;
    &lt;p&gt;yes it's 1:30 am what of it&lt;/p&gt;
    &lt;p&gt;Obviously forking go‚Äôs crypto library is a little scary, and I‚Äôm gonna have to do some thinking about how to maintain my little patch in a safe way.&lt;/p&gt;
    &lt;p&gt;But this is a huge improvement. I‚Äôve spent much of the last week squeezing out small single-digit performance wins. A &amp;gt;50% drop was unimaginable to me.&lt;/p&gt;
    &lt;head rend="h2"&gt;Debugging with LLMs was fun&lt;/head&gt;
    &lt;p&gt;I‚Äôve been thinking about whether LLMs remove parts of the problem-solving process that I enjoy. But I‚Äôve gotta say, debugging this problem using Claude Code was super fun.&lt;/p&gt;
    &lt;p&gt;I am familiar enough with &lt;code&gt;tcpdump&lt;/code&gt;, &lt;code&gt;tshark&lt;/code&gt;, and friends to know what they can do. But I don‚Äôt use them regularly enough to be fast with them. Being able to tell an agent ‚Äúhere‚Äôs a weird pcap - tell me what‚Äôs going on‚Äù was really lovely. And by watching commands as the agent ran them I was able to keep my mental model of the problem up to date.&lt;/p&gt;
    &lt;p&gt;There were still edge cases. At some point in my confusion I switched to ChatGPT and it very confidently told me that my tcpdump output was normal ssh behavior:&lt;/p&gt;
    &lt;p&gt;do all chatgpt messages have this tone and formatting now?&lt;/p&gt;
    &lt;p&gt;And then doubled down when I pushed back:&lt;/p&gt;
    &lt;p&gt;no!!!&lt;/p&gt;
    &lt;p&gt;Similarly, I had to push Claude Code to consider forking go‚Äôs ssh library. And I had to make the original leap of ‚Äúwait‚Ä¶if our test harness was broken, why was usage not 0%?‚Äù&lt;/p&gt;
    &lt;p&gt;When you say ‚ÄúLLMs did not fully solve this problem‚Äù some people tend to respond with ‚Äúyou‚Äôre holding it wrong!‚Äù&lt;/p&gt;
    &lt;p&gt;I think they‚Äôre sometimes right! Interacting with LLMs is a new skill, and it feels pretty weird if you‚Äôre used to writing software like it‚Äôs 2020. A more talented user of LLMs may have trivially solved this problem.&lt;/p&gt;
    &lt;p&gt;But the best way to develop a skill is by practicing it. And for me, that means figuring out how to transfer my problem-solving intuitions to the tools that I‚Äôm using.&lt;/p&gt;
    &lt;p&gt;Besides. Being in the loop is fun. How else would I write this post?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eieio.games/blog/ssh-sends-100-packets-per-keystroke/"/><published>2026-01-22T19:27:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46725288</id><title>Capital One to acquire Brex for $5.15B</title><updated>2026-01-23T07:18:39.110707+00:00</updated><content>&lt;doc fingerprint="e1d8a53d0af29fa9"&gt;
  &lt;main&gt;
    &lt;p&gt;Jan 22 (Reuters) - Capital One Financial (COF.N) said on Thursday it will acquire fintech firm Brex in a cash and stock deal valued at $5.15 billion and reported a rise in quarterly profit on the back of higher interest income from its credit card debt.&lt;/p&gt;
    &lt;p&gt;Shares of the consumer lender fell more than 5% following the announcement of the deal, but robust results helped them pare losses to trade 1.5% lower.&lt;/p&gt;
    &lt;p&gt;Sign up here.&lt;/p&gt;
    &lt;p&gt;The move comes as dealmakers prepare for another strong year in 2026, with a record slate of transactions expected as executives pursue scale to navigate rising economic and geopolitical uncertainties.&lt;/p&gt;
    &lt;p&gt;The deal, which is expected to close in mid‚Äë2026, will be carried out on an approximate 50-50 cash-stock basis, Capital One said.&lt;/p&gt;
    &lt;p&gt;Brex operates in corporate cards and expense management software used by firms such as DoorDash (DASH.O) and Robinhood (HOOD.O), which could give Capital One greater exposure and reduce its reliance on consumer credit, cushioning it against the impact of economic downturns.&lt;/p&gt;
    &lt;p&gt;Brex operates in more than 120 countries according to its website.&lt;/p&gt;
    &lt;p&gt;Capital One said the fintech firm's chief executive and founder, Pedro Franceschi, will remain at the helm following the transaction.&lt;/p&gt;
    &lt;head rend="h2"&gt;FOURTH-QUARTER EARNINGS&lt;/head&gt;
    &lt;p&gt;U.S. consumer spending rose at a solid pace in November and October, suggesting the economy was on track for a third consecutive quarter of strong growth.&lt;/p&gt;
    &lt;p&gt;Economic momentum has been underpinned largely by resilient household demand as well as a narrowing trade deficit, with imports declining in response to President Donald Trump's broad tariff increases.&lt;/p&gt;
    &lt;p&gt;However, the tariffs have pushed up the prices of many goods, weighing unevenly across income groups.&lt;/p&gt;
    &lt;p&gt;Economists say spending strength is increasingly concentrated among higher-income households, while lower- and middle-income consumers have limited scope to switch to cheaper alternatives.&lt;/p&gt;
    &lt;p&gt;Capital One's net interest income ‚Äî the difference between what it makes on loans and pays out on deposits ‚Äî rose 54% to $12.47 billion in the fourth quarter from a year ago.&lt;/p&gt;
    &lt;p&gt;The McLean, Virginia-based company's net income available to common stockholders came in at $2.06 billion, or $3.26 per share, for the quarter, compared with $1.02 billion, or $2.67 per share, a year earlier.&lt;/p&gt;
    &lt;head rend="h2"&gt;CREDIT CARD CAP CONUNDRUM&lt;/head&gt;
    &lt;p&gt;Trump said last week he was calling for a one‚Äëyear cap on credit card interest rates at 10% starting January 20, but offered few details on how the proposal would be implemented or how companies would be compelled to comply.&lt;/p&gt;
    &lt;p&gt;Banking industry groups have pushed back against the proposal, warning it would restrict the availability of credit for everyday consumers.&lt;/p&gt;
    &lt;p&gt;JPMorgan Chase (JPM.N) CEO Jamie Dimon said on Wednesday a proposal to cap credit card interest rates would amount to economic disaster.&lt;/p&gt;
    &lt;p&gt;However, Bank of America (BAC.N) is considering options to offer new credit cards with an interest rate of 10% to satisfy Trump's demands, a source familiar with the matter said on Thursday.&lt;/p&gt;
    &lt;p&gt;The introduction of an interest rate cap would deal a significant blow to Capital One Financial, which has one of the most credit-card‚Äëdependent business models among major U.S. lenders.&lt;/p&gt;
    &lt;p&gt;"We feel strongly that a cap on interest rates would catalyze a number of unintended consequences," CEO Richard Fairbank said in a call with analysts.&lt;/p&gt;
    &lt;p&gt;He added that lack of credit would result in reduced consumer spending and likely bring on a recession.&lt;/p&gt;
    &lt;p&gt;Reporting by Pritam Biswas in Bengaluru; Editing by Shreya Biswas&lt;/p&gt;
    &lt;p&gt;Our Standards: The Thomson Reuters Trust Principles.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.reuters.com/legal/transactional/capital-one-buy-fintech-firm-brex-515-billion-deal-2026-01-22/"/><published>2026-01-22T21:23:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46725300</id><title>Scaling PostgreSQL to power 800M ChatGPT users</title><updated>2026-01-23T07:18:38.916957+00:00</updated><content>&lt;doc fingerprint="9558893f469078c2"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Scaling PostgreSQL to power 800 million ChatGPT users&lt;/head&gt;&lt;p&gt;By Bohan Zhang, Member of the Technical Staff&lt;/p&gt;&lt;p&gt;For years, PostgreSQL has been one of the most critical, under-the-hood data systems powering core products like ChatGPT and OpenAI‚Äôs API. As our user base grows rapidly, the demands on our databases have increased exponentially, too. Over the past year, our PostgreSQL load has grown by more than 10x, and it continues to rise quickly.&lt;/p&gt;&lt;p&gt;Our efforts to advance our production infrastructure to sustain this growth revealed a new insight: PostgreSQL can be scaled to reliably support much larger read-heavy workloads than many previously thought possible. The system (initially created by a team of scientists at University of California, Berkeley) has enabled us to support massive global traffic with a single primary Azure PostgreSQL flexible server instance(opens in a new window) and nearly 50 read replicas spread over multiple regions globally. This is the story of how we‚Äôve scaled PostgreSQL at OpenAI to support millions of queries per second for 800 million users through rigorous optimizations and solid engineering; we‚Äôll also cover key takeaways we learned along the way.&lt;/p&gt;&lt;p&gt;After the launch of ChatGPT, traffic grew at an unprecedented rate. To support it, we rapidly implemented extensive optimizations at both the application and PostgreSQL database layers, scaled up by increasing the instance size, and scaled out by adding more read replicas. This architecture has served us well for a long time. With ongoing improvements, it continues to provide ample runway for future growth.&lt;/p&gt;&lt;p&gt;It may sound surprising that a single-primary architecture can meet the demands of OpenAI‚Äôs scale; however, making this work in practice isn‚Äôt simple. We‚Äôve seen several SEVs caused by Postgres overload, and they often follow the same pattern: an upstream issue causes a sudden spike in database load, such as widespread cache misses from a caching-layer failure, a surge of expensive multi-way joins saturating CPU, or a write storm from a new feature launch. As resource utilization climbs, query latency rises and requests begin to time out. Retries then further amplify the load, triggering a vicious cycle with the potential to degrade the entire ChatGPT and API services.&lt;/p&gt;&lt;p&gt;Although PostgreSQL scales well for our read-heavy workloads, we still encounter challenges during periods of high write traffic. This is largely due to PostgreSQL‚Äôs multiversion concurrency control (MVCC) implementation, which makes it less efficient for write-heavy workloads. For example, when a query updates a tuple or even a single field, the entire row is copied to create a new version. Under heavy write loads, this results in significant write amplification. It also increases read amplification, since queries must scan through multiple tuple versions (dead tuples) to retrieve the latest one. MVCC introduces additional challenges such as table and index bloat, increased index maintenance overhead, and complex autovacuum tuning. (You can find a deep-dive on these issues in a blog I wrote with Prof. Andy Pavlo at Carnegie Mellon University called The Part of PostgreSQL We Hate the Most(opens in a new window), cited(opens in a new window) in the PostgreSQL Wikipedia page.)&lt;/p&gt;&lt;p&gt;To mitigate these limitations and reduce write pressure, we‚Äôve migrated, and continue to migrate, shardable (i.e. workloads that can be horizontally partitioned), write-heavy workloads to sharded systems such as Azure Cosmos DB, optimizing application logic to minimize unnecessary writes. We also no longer allow adding new tables to the current PostgreSQL deployment. New workloads default to the sharded systems.&lt;/p&gt;&lt;p&gt;Even as our infrastructure has evolved, PostgreSQL has remained unsharded, with a single primary instance serving all writes. The primary rationale is that sharding existing application workloads would be highly complex and time-consuming, requiring changes to hundreds of application endpoints and potentially taking months or even years. Since our workloads are primarily read-heavy, and we‚Äôve implemented extensive optimizations, the current architecture still provides ample headroom to support continued traffic growth. While we‚Äôre not ruling out sharding PostgreSQL in the future, it‚Äôs not a near-term priority given the sufficient runway we have for current and future growth.&lt;/p&gt;&lt;p&gt;In the following sections, we‚Äôll dive into the challenges we faced and the extensive optimizations we implemented to address them and prevent future outages, pushing PostgreSQL to its limits and scaling it to millions of queries per second (QPS).&lt;/p&gt;&lt;p&gt;Challenge: With only one writer, a single-primary setup can‚Äôt scale writes. Heavy write spikes can quickly overload the primary and impact services like ChatGPT and our API.&lt;/p&gt;&lt;p&gt;Solution: We minimize load on the primary as much as possible‚Äîboth reads and writes‚Äîto ensure it has sufficient capacity to handle write spikes. Read traffic is offloaded to replicas wherever possible. However, some read queries must remain on the primary because they‚Äôre part of write transactions. For those, we focus on ensuring they‚Äôre efficient and avoid slow queries. For write traffic, we‚Äôve migrated shardable, write-heavy workloads to sharded systems such as Azure CosmosDB. Workloads that are harder to shard but still generate high write volume take longer to migrate, and that process is still ongoing. We also aggressively optimized our applications to reduce write load; for example, we‚Äôve fixed application bugs that caused redundant writes and introduced lazy writes, where appropriate, to smooth traffic spikes. In addition, when backfilling table fields, we enforce strict rate limits to prevent excessive write pressure.&lt;/p&gt;&lt;p&gt;Challenge: We identified several expensive queries in PostgreSQL. In the past, sudden volume spikes in these queries would consume large amounts of CPU, slowing both ChatGPT and API requests.&lt;/p&gt;&lt;p&gt;Solution: A few expensive queries, such as those joining many tables together, can significantly degrade or even bring down the entire service. We need to continuously optimize PostgreSQL queries to ensure they‚Äôre efficient and avoid common Online Transaction Processing (OLTP) anti-patterns. For example, we once identified an extremely costly query that joined 12 tables, where spikes in this query were responsible for past high-severity SEVs. We should avoid complex multi-table joins whenever possible. If joins are necessary, we learned to consider breaking down the query and move complex join logic to the application layer instead. Many of these problematic queries are generated by Object-Relational Mapping frameworks (ORMs), so it‚Äôs important to carefully review the SQL they produce and ensure it behaves as expected. It‚Äôs also common to find long-running idle queries in PostgreSQL. Configuring timeouts like idle_in_transaction_session_timeout is essential to prevent them from blocking autovacuum.&lt;/p&gt;&lt;p&gt;Challenge: If a read replica goes down, traffic can still be routed to other replicas. However, relying on a single writer means having a single point of failure‚Äîif it goes down, the entire service is affected.&lt;/p&gt;&lt;p&gt;Solution: Most critical requests only involve read queries. To mitigate the single point of failure in the primary, we offloaded those reads from the writer to replicas, ensuring those requests can continue serving even if the primary goes down. While write operations would still fail, the impact is reduced; it‚Äôs no longer a SEV0 since reads remain available.&lt;/p&gt;&lt;p&gt;To mitigate primary failures, we run the primary in High-Availability (HA) mode with a hot standby, a continuously synchronized replica that is always ready to take over serving traffic. If the primary goes down or needs to be taken offline for maintenance, we can quickly promote the standby to minimize downtime. The Azure PostgreSQL team has done significant work to ensure these failovers remain safe and reliable even under very high load. To handle read replica failures, we deploy multiple replicas in each region with sufficient capacity headroom, ensuring that a single replica failure doesn‚Äôt lead to a regional outage.&lt;/p&gt;&lt;p&gt;Challenge: We often encounter situations where certain requests consume a disproportionate amount of resources on PostgreSQL instances. This can lead to degraded performance for other workloads running on the same instances. For example, a new feature launch can introduce inefficient queries that heavily consume PostgreSQL CPU, slowing down requests for other critical features.&lt;/p&gt;&lt;p&gt;Solution: To mitigate the ‚Äúnoisy neighbor‚Äù problem, we isolate workloads onto dedicated instances to ensure that sudden spikes in resource-intensive requests don‚Äôt impact other traffic. Specifically, we split requests into low-priority and high-priority tiers and route them to separate instances. This way, even if a low-priority workload becomes resource-intensive, it won‚Äôt degrade the performance of high-priority requests. We apply the same strategy across different products and services as well, so that activity from one product does not affect the performance or reliability of another.&lt;/p&gt;&lt;p&gt;Challenge: Each instance has a maximum connection limit (5,000 in Azure PostgreSQL). It‚Äôs easy to run out of connections or accumulate too many idle ones. We‚Äôve previously had incidents caused by connection storms that exhausted all available connections.&lt;/p&gt;&lt;p&gt;Solution: We deployed PgBouncer as a proxy layer to pool database connections. Running it in statement or transaction pooling mode allows us to efficiently reuse connections, greatly reducing the number of active client connections. This also cuts connection setup latency: in our benchmarks, the average connection time dropped from 50 milliseconds (ms) to 5 ms. Inter-region connections and requests can be expensive, so we co-locate the proxy, clients, and replicas in the same region to minimize network overhead and connection use time. Moreover, PgBouncer must be configured carefully. Settings like idle timeouts are critical to prevent connection exhaustion.&lt;/p&gt;&lt;p&gt;Challenge: A sudden spike in cache misses can trigger a surge of reads on the PostgreSQL database, saturating CPU and slowing user requests.&lt;/p&gt;&lt;p&gt;Solution: To reduce read pressure on PostgreSQL, we use a caching layer to serve most of the read traffic. However, when cache hit rates drop unexpectedly, the burst of cache misses can push a large volume of requests directly to PostgreSQL. This sudden increase in database reads consumes significant resources, slowing down the service. To prevent overload during cache-miss storms, we implement a cache locking (and leasing) mechanism so that only a single reader that misses on a particular key fetches the data from PostgreSQL. When multiple requests miss on the same cache key, only one request acquires the lock and proceeds to retrieve the data and repopulate the cache. All other requests wait for the cache to be updated rather than all hitting PostgreSQL at once. This significantly reduces redundant database reads and protects the system from cascading load spikes.&lt;/p&gt;&lt;p&gt;Challenge: The primary streams Write Ahead Log (WAL) data to every read replica. As the number of replicas increases, the primary must ship WAL to more instances, increasing pressure on both network bandwidth and CPU. This causes higher and more unstable replica lag, which makes the system harder to scale reliably.&lt;/p&gt;&lt;p&gt;Solution: We operate nearly 50 read replicas across multiple geographic regions to minimize latency. However, with the current architecture, the primary must stream WAL to every replica. Although it currently scales well with very large instance types and high-network bandwidth, we can‚Äôt keep adding replicas indefinitely without eventually overloading the primary. To address this, we‚Äôre collaborating with the Azure PostgreSQL team on cascading replication(opens in a new window), where intermediate replicas relay WAL to downstream replicas. This approach allows us to scale to potentially over a hundred replicas without overwhelming the primary. However, it also introduces additional operational complexity, particularly around failover management. The feature is still in testing; we‚Äôll ensure it‚Äôs robust and can fail over safely before rolling it out to production.&lt;/p&gt;&lt;p&gt;Challenge: A sudden traffic spike on specific endpoints, a surge of expensive queries, or a retry storm can quickly exhaust critical resources such as CPU, I/O, and connections, which causes widespread service degradation.&lt;/p&gt;&lt;p&gt;Solution: We implemented rate-limiting across multiple layers‚Äîapplication, connection pooler, proxy, and query‚Äîto prevent sudden traffic spikes from overwhelming database instances and triggering cascading failures. It‚Äôs also crucial to avoid overly short retry intervals, which can trigger retry storms. We also enhanced the ORM layer to support rate limiting and when necessary, fully block specific query digests. This targeted form of load shedding enables rapid recovery from sudden surges of expensive queries.&lt;/p&gt;&lt;p&gt;Challenge: Even a small schema change, such as altering a column type, can trigger a full table rewrite(opens in a new window). We therefore apply schema changes cautiously‚Äîlimiting them to lightweight operations and avoiding any that rewrite entire tables.&lt;/p&gt;&lt;p&gt;Solution: Only lightweight schema changes are permitted, such as adding or removing certain columns that do not trigger a full table rewrite. We enforce a strict 5-second timeout on schema changes. Creating and dropping indexes concurrently is allowed. Schema changes are restricted to existing tables. If a new feature requires additional tables, they must be in alternative sharded systems such as Azure CosmosDB rather than PostgreSQL. When backfilling a table field, we apply strict rate limits to prevent write spikes. Although this process can sometimes take over a week, it ensures stability and avoids any production impact.&lt;/p&gt;&lt;p&gt;This effort demonstrates that with the right design and optimizations, Azure PostgreSQL can be scaled to handle the largest production workloads. PostgreSQL handles millions of QPS for read-heavy workloads, powering OpenAI‚Äôs most critical products like ChatGPT and the API platform. We added nearly 50 read replicas, while keeping replication lag near zero, maintained low-latency reads across geo-distributed regions, and built sufficient capacity headroom to support future growth.&lt;/p&gt;&lt;p&gt;This scaling works while still minimizing latency and improving reliability. We consistently deliver low double-digit millisecond p99 client-side latency and five-nines availability in production. And over the past 12 months, we‚Äôve had only one SEV-0 PostgreSQL incident (it occurred during the viral launch(opens in a new window) of ChatGPT ImageGen, when write traffic suddenly surged by more than 10x as over 100 million new users signed up within a week.)&lt;/p&gt;&lt;p&gt;While we‚Äôre happy with how far PostgreSQL has taken us, we continue to push its limits to ensure we have sufficient runway for future growth. We‚Äôve already migrated the shardable write-heavy workloads to our sharded systems like CosmosDB. The remaining write-heavy workloads are more challenging to shard‚Äîwe‚Äôre actively migrating those as well to further offload writes from the PostgreSQL primary. We‚Äôre also working with Azure to enable cascading replication so we can safely scale to significantly more read replicas.&lt;/p&gt;&lt;p&gt;Looking ahead, we‚Äôll continue to explore additional approaches to further scale, including sharded PostgreSQL or alternative distributed systems, as our infrastructure demands continue to grow.&lt;/p&gt;&lt;head rend="h2"&gt;Author&lt;/head&gt;Bohan Zhang&lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;&lt;p&gt;Special thanks to Jon Lee, Sicheng Liu, Chaomin Yu, and Chenglong Hao, who contributed to this post, and to the entire team that helped scale PostgreSQL. We‚Äôd also like to thank the Azure PostgreSQL team for their strong partnership.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/scaling-postgresql/"/><published>2026-01-22T21:24:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46726526</id><title>Improving the usability of C libraries in Swift</title><updated>2026-01-23T07:18:38.163719+00:00</updated><content>&lt;doc fingerprint="6e025913b407b699"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Improving the usability of C libraries in Swift&lt;/head&gt;
    &lt;p&gt;There are many interesting, useful, and fun C libraries in the software ecosystem. While one could go and rewrite these libraries in Swift, usually there is no need, because Swift provides direct interoperability with C. With a little setup, you can directly use existing C libraries from your Swift code.&lt;/p&gt;
    &lt;p&gt;When you use a C library directly from Swift, it will look and feel similar to using it from C. That can be useful if you‚Äôre following sample code or a tutorial written in C, but it can also feel out of place. For example, here‚Äôs a small amount of code using a C API:&lt;/p&gt;
    &lt;code&gt;  var instanceDescriptor = WGPUInstanceDescriptor()
  let instance = wgpuCreateInstance(&amp;amp;instanceDescriptor)
  var surfaceDescriptor = WGPUSurfaceDescriptor()
  let surface = wgpuInstanceCreateSurface(instance, &amp;amp;surfaceDescriptor)
  if wgpuSurfacePresent(&amp;amp;surface) == WGPUStatus_Error {
      // report error
  }
  wgpuSurfaceRelease(surface)
  wgpuInstanceRelease(instance)
&lt;/code&gt;
    &lt;p&gt;The C library here that Swift is using comes from the webgpu-headers project, which vends a C header (&lt;code&gt;webgpu.h&lt;/code&gt;) that is used by several implementations of WebGPU. WebGPU  is a technology that enables web developers to use the system‚Äôs GPU (Graphics Processing Unit) from the browser. For the purposes of this post, you don‚Äôt really need to know anything about WebGPU: I‚Äôm using it as an example of a typical C library, and the techniques described in this blog post apply to lots of other well-designed C libraries.&lt;/p&gt;
    &lt;p&gt;The Swift code above has a very ‚ÄúC‚Äù feel to it. It has global function calls with prefixed names like &lt;code&gt;wgpuInstanceCreateSurface&lt;/code&gt; and global integer constants like &lt;code&gt;WGPUStatus_Error&lt;/code&gt;. It pervasively uses unsafe pointers, some of which are managed with explicit reference counting, where the user provides calls to &lt;code&gt;wpuXYZAddRef&lt;/code&gt; and &lt;code&gt;wgpuXYZRelease&lt;/code&gt; functions. It works, but it doesn‚Äôt feel like Swift, and inherits various safety problems of C.&lt;/p&gt;
    &lt;p&gt;Fortunately, we can improve this situation, providing a safer and more ergonomic interface to WebGPU from Swift that feels like it belongs in Swift. More importantly, we can do so without changing the WebGPU implementation: Swift provides a suite of annotations that you can apply to C headers to improve the way in which the C APIs are expressed in Swift. These annotations describe common conventions in C that match up with Swift constructs, projecting a more Swift-friendly interface on top of the C code.&lt;/p&gt;
    &lt;p&gt;In this post, I‚Äôm going to use these annotations to improve how Swift interacts with the WebGPU C code. By the end, we‚Äôll be able to take advantage of Swift features like argument labels, methods, enums, and automatic reference counting, like this:&lt;/p&gt;
    &lt;code&gt;  var instanceDescriptor = WGPUInstanceDescriptor()
  let instance = WGPUInstance(descriptor: &amp;amp;instanceDescriptor)
  var surfaceDescriptor = WGPUSurfaceDescriptor()
  let surface = instance.createSurface(descriptor: &amp;amp;surfaceDescriptor)
  if surface.present() == .error {
      // report error
  }
  // Swift automatically deallocates the instance and surface when we're done
&lt;/code&gt;
    &lt;p&gt;These same annotations can be used for any C library to provide a safer, more ergonomic development experience in Swift without changing the C library at all.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Note: Some of what is covered in this post requires bug fixes that first became available in Swift 6.2.3.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Setup: Writing a module map&lt;/head&gt;
    &lt;p&gt;A module map is a way of layering a Swift-friendly modular structure on top of C headers. You can create a module map for the WebGPU header by writing the following to a file &lt;code&gt;module.modulemap&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;module WebGPU {
  header "webgpu.h"
  export *
}
&lt;/code&gt;
    &lt;p&gt;The easiest thing to do is to put &lt;code&gt;module.modulemap&lt;/code&gt; alongside the header itself. For my experiment here, I put it in the root directory of my &lt;code&gt;webgpu-headers&lt;/code&gt; checkout. If you‚Äôre in a Swift package, put it into its own target with this layout:&lt;/p&gt;
    &lt;code&gt;‚îú‚îÄ‚îÄ Package.swift
‚îî‚îÄ‚îÄ Sources
    ‚îî‚îÄ‚îÄ WebGPU
        ‚îú‚îÄ‚îÄ include
        ‚îÇ   ‚îú‚îÄ‚îÄ webgpu.h
        ‚îÇ   ‚îî‚îÄ‚îÄ module.modulemap
        ‚îî‚îÄ‚îÄ WebGPU.c (empty file)
&lt;/code&gt;
    &lt;p&gt;If you reference this &lt;code&gt;WebGPU&lt;/code&gt; target from elsewhere in the package, you can &lt;code&gt;import WebGPU&lt;/code&gt; to get access to the C APIs.&lt;/p&gt;
    &lt;head rend="h2"&gt;Seeing the results&lt;/head&gt;
    &lt;p&gt;There are a few ways to see what the Swift interface for a C library looks like.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The &lt;code&gt;swift-synthesize-interface&lt;/code&gt;tool in Swift 6.2+ prints the Swift interface to the terminal.&lt;/item&gt;
      &lt;item&gt;Xcode‚Äôs ‚ÄúSwift 5 interface‚Äù counterpart to the &lt;code&gt;webgpu.h&lt;/code&gt;header will show how the header has been mapped into Swift.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Let‚Äôs do it from the command line, using &lt;code&gt;swift-synthesize-interface&lt;/code&gt;. From the directory containing &lt;code&gt;webgpu.h&lt;/code&gt; and &lt;code&gt;module.modulemap&lt;/code&gt;, run:&lt;/p&gt;
    &lt;code&gt;xcrun swift-synthesize-interface -I . -module-name WebGPU -target arm64-apple-macos15 -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX26.0.sdk
&lt;/code&gt;
    &lt;p&gt;The leading &lt;code&gt;xcrun&lt;/code&gt; and the &lt;code&gt;-sdk&lt;/code&gt; argument with the path is only needed on macOS; on other platforms, make sure &lt;code&gt;swift-synthesize-interface&lt;/code&gt; is in your path. The &lt;code&gt;-target&lt;/code&gt; operation is the triple provided if you run &lt;code&gt;swiftc -print-target-info&lt;/code&gt;. It looks like this:&lt;/p&gt;
    &lt;code&gt;{
  "compilerVersion": "Apple Swift version 6.2 (swiftlang-6.2.2.15.4 clang-1700.3.15.2)",
  "target": {
    "triple": "arm64-apple-macosx15.0",
    "unversionedTriple": "arm64-apple-macosx",
    "moduleTriple": "arm64-apple-macos",
    "compatibilityLibraries": [ ],
    "librariesRequireRPath": false
  },
  "paths": { ... }
}
&lt;/code&gt;
    &lt;p&gt;The output of &lt;code&gt;swift-synthesize-interface&lt;/code&gt; is the Swift API for the WebGPU module, directly translated from C. For example, this code from the WebGPU header:&lt;/p&gt;
    &lt;code&gt;typedef enum WGPUAdapterType {
    WGPUAdapterType_DiscreteGPU = 0x00000001,
    WGPUAdapterType_IntegratedGPU = 0x00000002,
    WGPUAdapterType_CPU = 0x00000003,
    WGPUAdapterType_Unknown = 0x00000004,
    WGPUAdapterType_Force32 = 0x7FFFFFFF
} WGPUAdapterType WGPU_ENUM_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;is translated into:&lt;/p&gt;
    &lt;code&gt;public struct WGPUAdapterType : Hashable, Equatable, RawRepresentable {
    public init(_ rawValue: UInt32)
    public init(rawValue: UInt32)
    public var rawValue: UInt32
}

public var WGPUAdapterType_DiscreteGPU: WGPUAdapterType { get }
public var WGPUAdapterType_IntegratedGPU: WGPUAdapterType { get }
public var WGPUAdapterType_CPU: WGPUAdapterType { get }
public var WGPUAdapterType_Unknown: WGPUAdapterType { get }
public var WGPUAdapterType_Force32: WGPUAdapterType { get }
&lt;/code&gt;
    &lt;p&gt;and there are lots of global functions like this:&lt;/p&gt;
    &lt;code&gt;public func wgpuComputePipelineGetBindGroupLayout(_ computePipeline: WGPUComputePipeline!, _ groupIndex: UInt32) -&amp;gt; WGPUBindGroupLayout!
public func wgpuComputePipelineSetLabel(_ computePipeline: WGPUComputePipeline!, _ label: WGPUStringView)
public func wgpuComputePipelineAddRef(_ computePipeline: WGPUComputePipeline!)
public func wgpuComputePipelineRelease(_ computePipeline: WGPUComputePipeline!)
&lt;/code&gt;
    &lt;p&gt;It‚Äôs a starting point! You can absolutely write Swift programs using these WebGPU APIs, and they‚Äôll feel a lot like writing them in C. Let‚Äôs see what we can do to make it better.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cleaning up enumeration types&lt;/head&gt;
    &lt;p&gt;C enums can be used for several things. Sometimes they really represent a choice among a number of alternatives. Sometimes they represent flags in a set of options, from which you can choose several. Sometimes they‚Äôre just a convenient way to create a bunch of named constants. Swift conservatively imports enum types as wrappers over the underlying C type used to store values of the enum (e.g., &lt;code&gt;WGPUAdapterType&lt;/code&gt; wraps a &lt;code&gt;UInt32&lt;/code&gt;) and makes the enumerators into global constants. It covers all of the possible use cases, but it isn‚Äôt nice.&lt;/p&gt;
    &lt;p&gt;The &lt;code&gt;WGPUAdapterType&lt;/code&gt; enum really is a choice among one of several options, which would be best represented as an &lt;code&gt;enum&lt;/code&gt; in Swift. If we were willing to modify the header, we could apply the &lt;code&gt;enum_extensibility&lt;/code&gt; attribute to the enum, like this:&lt;/p&gt;
    &lt;code&gt;typedef enum __attribute__((enum_extensibility(closed))) WGPUAdapterType {
    WGPUAdapterType_DiscreteGPU = 0x00000001,
    WGPUAdapterType_IntegratedGPU = 0x00000002,
    WGPUAdapterType_CPU = 0x00000003,
    WGPUAdapterType_Unknown = 0x00000004,
    WGPUAdapterType_Force32 = 0x7FFFFFFF
} WGPUAdapterType WGPU_ENUM_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;This works, and results in a much nicer Swift API:&lt;/p&gt;
    &lt;code&gt;@frozen public enum WGPUAdapterType : UInt32, @unchecked Sendable {
    case discreteGPU = 1
    case integratedGPU = 2
    case CPU = 3
    case unknown = 4
    case force32 = 2147483647
}
&lt;/code&gt;
    &lt;p&gt;Now, we get an &lt;code&gt;enum&lt;/code&gt; that we can switch over, and nice short case names, e.g.,&lt;/p&gt;
    &lt;code&gt;switch adapterType {
  case .discreteGPU, .integratedGPU:
    print("definitely a GPU")
  default:
    print("not so sure")
}
&lt;/code&gt;
    &lt;p&gt;That‚Äôs great, but I already broke my rule: no header modifications unless I have to!&lt;/p&gt;
    &lt;head rend="h2"&gt;API notes&lt;/head&gt;
    &lt;p&gt;The problem of needing to layer information on top of existing C headers is not a new one. As noted earlier, Swift relies on a Clang feature called API notes to let us express this same information in a separate file, so we don‚Äôt have to edit the header. In this case, we create a file called &lt;code&gt;WebGPU.apinotes&lt;/code&gt; (the name &lt;code&gt;WebGPU&lt;/code&gt; matches the module name from &lt;code&gt;module.modulemap&lt;/code&gt;), which is a YAML file describing the extra information. We‚Äôll start with one that turns &lt;code&gt;WGPUAdapterType&lt;/code&gt; into an &lt;code&gt;enum&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;---
Name: WebGPU
Tags:
- Name: WGPUAdapterType
  EnumExtensibility: closed
&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;Tags&lt;/code&gt; here is a term used in the C and C++ standard to refer to enum, struct, union, or class types. Any information about those types in the API notes file will go into that section.&lt;/p&gt;
    &lt;p&gt;Put &lt;code&gt;WebGPU.apinotes&lt;/code&gt; alongside the &lt;code&gt;module.modulemap&lt;/code&gt;, and now &lt;code&gt;WGPUAdapterType&lt;/code&gt; gets mapped into a &lt;code&gt;Swift&lt;/code&gt; enum. For a package, the structure will look like this:&lt;/p&gt;
    &lt;code&gt;‚îú‚îÄ‚îÄ Package.swift
‚îî‚îÄ‚îÄ Sources
    ‚îî‚îÄ‚îÄ WebGPU
        ‚îú‚îÄ‚îÄ include
        ‚îÇ   ‚îú‚îÄ‚îÄ webgpu.h
        ‚îÇ   ‚îú‚îÄ‚îÄ WebGPU.apinotes
        ‚îÇ   ‚îî‚îÄ‚îÄ module.modulemap
        ‚îî‚îÄ‚îÄ WebGPU.c (empty file)
&lt;/code&gt;
    &lt;p&gt;We‚Äôll be adding more to this API notes file as we keep digging through the interface.&lt;/p&gt;
    &lt;head rend="h2"&gt;Reference-counted object types&lt;/head&gt;
    &lt;p&gt;The WebGPU header has a number of ‚Äúobject‚Äù types that are defined like this:&lt;/p&gt;
    &lt;code&gt;typedef struct WGPUBindGroupImpl* WGPUBindGroup WGPU_OBJECT_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;This gets imported into Swift as an alias for an opaque pointer type, which is‚Ä¶ not great:&lt;/p&gt;
    &lt;code&gt;public typealias WGPUBindGroup = OpaquePointer
&lt;/code&gt;
    &lt;p&gt;WebGPU object types are reference counted, and each object type has corresponding &lt;code&gt;AddRef&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt; functions to increment and decrement the reference count, like this:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT void wgpuBindGroupAddRef(WGPUBindGroup bindGroup) WGPU_FUNCTION_ATTRIBUTE;
WGPU_EXPORT void wgpuBindGroupRelease(WGPUBindGroup bindGroup) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;Of course, you can use these functions in Swift exactly how you do in C, making sure to balance out calls to &lt;code&gt;AddRef&lt;/code&gt; and &lt;code&gt;Release&lt;/code&gt;, but then it would be every bit as unsafe as C.&lt;/p&gt;
    &lt;p&gt;We can do better with &lt;code&gt;SWIFT_SHARED_REFERENCE&lt;/code&gt;. It‚Äôs a macro (defined in the &lt;code&gt;&amp;lt;swift/bridging&amp;gt;&lt;/code&gt; header) that can turn a reference-counted C type like the above into an automatically reference-counted &lt;code&gt;class&lt;/code&gt; in Swift. Here‚Äôs how we would use it in the header:&lt;/p&gt;
    &lt;code&gt;typedef struct SWIFT_SHARED_REFERENCE(wgpuBindGroupAddRef, wgpuBindGroupRelease) WGPUBindGroupImpl* WGPUBindGroup WGPU_OBJECT_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;Now, &lt;code&gt;WGPUBindGroup&lt;/code&gt; gets imported like this:&lt;/p&gt;
    &lt;code&gt;public class WGPUBindGroupImpl { }
public typealias WGPUBindGroup = WGPUBindGroupImpl
&lt;/code&gt;
    &lt;p&gt;The extra typealias is a little unexpected, but overall this is a huge improvement: Swift is treating &lt;code&gt;WGPUBindGroup&lt;/code&gt; as a class, meaning that it automatically manages retains and releases for you! This is both an ergonomic win (less code to write) and a safety win, because it‚Äôs eliminated the possibility of mismanaging these instances.&lt;/p&gt;
    &lt;p&gt;There‚Äôs one more thing: when dealing with reference-counting APIs, you need to know whether a particular function that returns an object is expecting you to call ‚Äúrelease‚Äù when you‚Äôre done. In the WebGPU header, this information is embedded in a comment:&lt;/p&gt;
    &lt;code&gt;/**
 * @returns
 * This value is @ref ReturnedWithOwnership.
 */
WGPU_EXPORT WGPUBindGroup wgpuDeviceCreateBindGroup(WGPUDevice device, WGPUBindGroupDescriptor const * descriptor) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;‚ÄúReturnedWithOwnership‚Äù here means that the result of the call has already been retained one extra time, and the caller is responsible for calling ‚Äúrelease‚Äù when they are done with it. The &lt;code&gt;&amp;lt;swift/bridging&amp;gt;&lt;/code&gt; header has a &lt;code&gt;SWIFT_RETURNS_RETAINED&lt;/code&gt; macro that expresses this notion. One can use it like this:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT WGPUBindGroup wgpuDeviceCreateBindGroup(WGPUDevice device, WGPUBindGroupDescriptor const * descriptor) WGPU_FUNCTION_ATTRIBUTE SWIFT_RETURNS_RETAINED;
&lt;/code&gt;
    &lt;p&gt;Now, Swift will balance out the retain that &lt;code&gt;wgpuDeviceCreateBindGroup&lt;/code&gt; has promised to do by performing the extra release once you‚Äôre done using the object. Once these annotations are done, we‚Äôre all set with a more ergonomic and memory-safe API for this C library. There‚Äôs no need to ever call &lt;code&gt;wgpuBindGroupRelease&lt;/code&gt; or &lt;code&gt;wgpuBindGroupAddRef&lt;/code&gt; yourself.&lt;/p&gt;
    &lt;p&gt;We‚Äôve hacked up our header again, so let‚Äôs undo that and move all of this out to API notes. To turn a type into a foreign reference type, we augment the &lt;code&gt;Tags&lt;/code&gt; section of our API notes with the same information, but in YAML form:&lt;/p&gt;
    &lt;code&gt;- Name: WGPUBindGroupImpl
  SwiftImportAs: reference
  SwiftReleaseOp: wgpuBindGroupRelease
  SwiftRetainOp: wgpuBindGroupAddRef
&lt;/code&gt;
    &lt;p&gt;That makes &lt;code&gt;WGPUBindGroupImpl&lt;/code&gt; import as a class type, with the given retain and release functions. We can express the ‚Äúreturns retained‚Äù behavior of the &lt;code&gt;wgpuDeviceCreateBindGroup&lt;/code&gt; function like this:&lt;/p&gt;
    &lt;code&gt;Functions:
- Name: wgpuDeviceCreateBindGroup
  SwiftReturnOwnership: retained
&lt;/code&gt;
    &lt;p&gt;That‚Äôs enums and classes, so now let‚Äôs tackle‚Ä¶ functions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Importing functions&lt;/head&gt;
    &lt;p&gt;A typical function from &lt;code&gt;webgpu.h&lt;/code&gt;, like this:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT void wgpuQueueWriteBuffer(
    WGPUQueue queue, WGPUBuffer buffer, uint64_t bufferOffset, 
    void const * data, size_t size
) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;will come into Swift like this:&lt;/p&gt;
    &lt;code&gt;public func wgpuQueueWriteBuffer(_ queue: WGPUQueue!, _ buffer: WGPUBuffer!, _ bufferOffset: UInt64, _ data: UnsafeRawPointer!, _ size: Int)
&lt;/code&gt;
    &lt;p&gt;Note that &lt;code&gt;_&lt;/code&gt; on each parameter, which means that we won‚Äôt use argument labels for anything when we call it:&lt;/p&gt;
    &lt;code&gt;wgpuQueueWriteBuffer(myQueue, buffer, position, dataToWrite, bytesToWrite)
&lt;/code&gt;
    &lt;p&gt;That matches C, but it isn‚Äôt as clear as it could be in Swift. Let‚Äôs clean this up by providing a better name in Swift that includes argument labels. We can do so using &lt;code&gt;SWIFT_NAME&lt;/code&gt; (also in &lt;code&gt;&amp;lt;swift/bridging&amp;gt;&lt;/code&gt;), like this:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT void wgpuQueueWriteBuffer(
      WGPUQueue queue, WGPUBuffer buffer, uint64_t bufferOffset,
      void const * data, size_t size
  ) WGPU_FUNCTION_ATTRIBUTE 
    SWIFT_NAME("wgpuQueueWriteBuffer(_:buffer:bufferOffset:data:size:)");
&lt;/code&gt;
    &lt;p&gt;Within the parentheses, we have each of the argument labels that we want (or &lt;code&gt;_&lt;/code&gt; meaning ‚Äúno label‚Äù), each followed by a &lt;code&gt;:&lt;/code&gt;. This is how one describes a full function name in Swift. Once we‚Äôve made this change to the Swift name, the C function comes into Swift with argument labels, like this:&lt;/p&gt;
    &lt;code&gt;public func wgpuQueueWriteBuffer(_ queue: WGPUQueue!, buffer: WGPUBuffer!, bufferOffset: UInt64, data: UnsafeRawPointer!, size: Int)
&lt;/code&gt;
    &lt;p&gt;That makes the call site more clear and self-documenting:&lt;/p&gt;
    &lt;code&gt;wgpuQueueWriteBuffer(myQueue, buffer: buffer, offset: position, data: dataToWrite, size: bytesToWrite)
&lt;/code&gt;
    &lt;head rend="h3"&gt;Importing functions as methods&lt;/head&gt;
    &lt;p&gt;There is more usable structure in this API. Note that the &lt;code&gt;wgpuQueueWriteBuffer&lt;/code&gt; function takes, as its first argument, an instance of &lt;code&gt;WGPUQueue&lt;/code&gt;. Most of the C functions in &lt;code&gt;WebGPU.h&lt;/code&gt; are like this, because these are effectively functions that operate on their first argument. In a language that has methods, they would be methods. Swift has methods, so let‚Äôs make them methods!&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT void wgpuQueueWriteBuffer(
      WGPUQueue queue, WGPUBuffer buffer, uint64_t bufferOffset, void const * data, size_t size) 
  WGPU_FUNCTION_ATTRIBUTE SWIFT_NAME("WGPUQueueImpl.writeBuffer(self:buffer:bufferOffset:data:size:)");
&lt;/code&gt;
    &lt;p&gt;There are three things to notice about this &lt;code&gt;SWIFT_NAME&lt;/code&gt; string:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It starts with &lt;code&gt;WGPUQueueImpl.&lt;/code&gt;, which tells Swift to make this function a member inside&lt;code&gt;WGPUQueueImpl&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Let‚Äôs change the function name to &lt;code&gt;writeBuffer&lt;/code&gt;, because we no longer need the&lt;code&gt;wgpuQueue&lt;/code&gt;prefix to distinguish it from other ‚Äúwrite buffer‚Äù operations on other types.&lt;/item&gt;
      &lt;item&gt;The name of the first argument in parentheses is &lt;code&gt;self&lt;/code&gt;, which indicates that the&lt;code&gt;self&lt;/code&gt;argument (in Swift) should be passed as that positional argument to the C function. The other arguments are passed in-order.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that this also requires &lt;code&gt;WGPUQueue(Impl)&lt;/code&gt; to be imported as a &lt;code&gt;class&lt;/code&gt;, as we did earlier for &lt;code&gt;WGPUBindGroupImpl&lt;/code&gt;. Once we‚Äôve done so, we get a much-nicer Swift API:&lt;/p&gt;
    &lt;code&gt;extension WGPUQueueImpl {
  /**
   * Produces a @ref DeviceError both content-timeline (`size` alignment) and d
evice-timeline
   * errors defined by the WebGPU specification.
   */
  public func writeBuffer(buffer: WGPUBuffer!, bufferOffset: UInt64, data: UnsafeRawPointer!, size: Int)
}
&lt;/code&gt;
    &lt;p&gt;We‚Äôve hacked up the header again, but didn‚Äôt have to. In &lt;code&gt;WebGPU.apinotes&lt;/code&gt;, you can put a &lt;code&gt;SwiftName&lt;/code&gt; attribute on any entity. For &lt;code&gt;wgpuQueueWriteBuffer&lt;/code&gt;, it would look like this (in the &lt;code&gt;Functions&lt;/code&gt; section):&lt;/p&gt;
    &lt;code&gt;- Name: wgpuQueueWriteBuffer
  SwiftName: WGPUQueueImpl.writeBuffer(self:buffer:bufferOffset:data:size:)
&lt;/code&gt;
    &lt;head rend="h3"&gt;Importing functions as properties&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;WebGPU.h&lt;/code&gt; has a number of &lt;code&gt;Get&lt;/code&gt; functions that produce information about some aspect of a type. Here are two for the &lt;code&gt;WGPUQuerySet&lt;/code&gt; type:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT uint32_t wgpuQuerySetGetCount(WGPUQuerySet querySet) WGPU_FUNCTION_ATTRIBUTE;
WGPU_EXPORT WGPUQueryType wgpuQuerySetGetType(WGPUQuerySet querySet) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;With the &lt;code&gt;SWIFT_NAME&lt;/code&gt; tricks above, we can turn these into ‚Äúget‚Äù methods on &lt;code&gt;WGPUQuerySet&lt;/code&gt;, like this:&lt;/p&gt;
    &lt;code&gt;extension WGPUQuerySetImpl {
    public func getCount() -&amp;gt; UInt32
    public func getType() -&amp;gt; WGPUQueryType
}
&lt;/code&gt;
    &lt;p&gt;That‚Äôs okay, but it‚Äôs not what you‚Äôd do in Swift. Let‚Äôs go one step further and turn them into read-only computed properties. To do so, use the &lt;code&gt;getter:&lt;/code&gt; prefix on the Swift name we define. We‚Äôll skip ahead to the YAML form that goes into API notes:&lt;/p&gt;
    &lt;code&gt;- Name: wgpuQuerySetGetCount
  SwiftName: getter:WGPUQuerySetImpl.count(self:)
- Name: wgpuQuerySetGetType
  SwiftName: getter:WGPUQuerySetImpl.type(self:)
&lt;/code&gt;
    &lt;p&gt;And now, we arrive at a nice Swift API:&lt;/p&gt;
    &lt;code&gt;extension WGPUQuerySetImpl {
    public var count: UInt32 { get }
    public var type: WGPUQueryType { get }
}
&lt;/code&gt;
    &lt;head rend="h3"&gt;Importing functions as initializers&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;SWIFT_NAME&lt;/code&gt; can also be used to import a function that returns a new instance as a Swift initializer. For example, this function creates a new &lt;code&gt;WGPUInstance&lt;/code&gt; (which we assume is getting imported as a &lt;code&gt;class&lt;/code&gt; like we‚Äôve been doing above):&lt;/p&gt;
    &lt;code&gt;/**
 * Create a WGPUInstance
 *
 * @returns
 * This value is @ref ReturnedWithOwnership.
 */
WGPU_EXPORT WGPUInstance wgpuCreateInstance(WGPU_NULLABLE WGPUInstanceDescriptor const * descriptor) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;We can turn this into a Swift initializer, which is used to create a new object, using the same &lt;code&gt;SWIFT_NAME&lt;/code&gt; syntax but where the method name is &lt;code&gt;init&lt;/code&gt;. Here is the YAML form that goes into API notes:&lt;/p&gt;
    &lt;code&gt;- Name: wgpuCreateInstance
  SwiftReturnOwnership: retained
  SwiftName: WGPUInstanceImpl.init(descriptor:)
&lt;/code&gt;
    &lt;p&gt;and here is the resulting Swift initializer:&lt;/p&gt;
    &lt;code&gt;extension WGPUInstanceImpl {
    /**
     * Create a WGPUInstance
     *
     * @returns
     * This value is @ref ReturnedWithOwnership.
     */
    public /*not inherited*/ init!(descriptor: UnsafePointer&amp;lt;WGPUInstanceDescriptor&amp;gt;!)
}
&lt;/code&gt;
    &lt;p&gt;Now, one can create a new &lt;code&gt;WGPUInstance&lt;/code&gt; with the normal object-creation syntax, e.g.,&lt;/p&gt;
    &lt;code&gt;let instance = WGPUInstance(descriptor: myDescriptor)
&lt;/code&gt;
    &lt;head rend="h2"&gt;Another Boolean type?&lt;/head&gt;
    &lt;p&gt;The WebGPU header defines its own Boolean type. I wish everyone would use C99‚Äôs &lt;code&gt;_Bool&lt;/code&gt; and be done with it, but alas, here are the definitions for WebGPUs Boolean types:&lt;/p&gt;
    &lt;code&gt;#define WGPU_TRUE (UINT32_C(1))
#define WGPU_FALSE (UINT32_C(0))
typedef uint32_t WGPUBool;
&lt;/code&gt;
    &lt;p&gt;This means that &lt;code&gt;WGPUBool&lt;/code&gt; will come in to Swift as a &lt;code&gt;UInt32&lt;/code&gt;. The two macros aren‚Äôt available in Swift at all: they‚Äôre ‚Äútoo complicated‚Äù to be recognized as integral constants. Even if they were available in Swift, it still wouldn‚Äôt be great because we want to use &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt; for Boolean values in Swift, not &lt;code&gt;WGPU_TRUE&lt;/code&gt; and &lt;code&gt;WGPU_FALSE&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;To make &lt;code&gt;WGPUBool&lt;/code&gt; easier to use from Swift, we‚Äôre first going to map that typedef to its own &lt;code&gt;struct&lt;/code&gt; that stores the underlying &lt;code&gt;UInt32&lt;/code&gt;, giving it an identity separate from &lt;code&gt;UInt32&lt;/code&gt;. We can do this using a &lt;code&gt;SwiftWrapper&lt;/code&gt; API note within the &lt;code&gt;Typedefs&lt;/code&gt; section of the file, like this:&lt;/p&gt;
    &lt;code&gt;- Name: WGPUBool
  SwiftWrapper: struct
&lt;/code&gt;
    &lt;p&gt;Now, we get &lt;code&gt;WGPUBool&lt;/code&gt; imported like this:&lt;/p&gt;
    &lt;code&gt;public struct WGPUBool : Hashable, Equatable, RawRepresentable {
    public init(_ rawValue: UInt32)
    public init(rawValue: UInt32)
}
&lt;/code&gt;
    &lt;p&gt;To be able to use &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt; literals with this new &lt;code&gt;WGPUBool&lt;/code&gt;, we can write a little bit of Swift code that makes this type conform to the &lt;code&gt;ExpressibleByBooleanLiteral&lt;/code&gt; protocol, like this:&lt;/p&gt;
    &lt;code&gt;extension WGPUBool: ExpressibleByBooleanLiteral {
  init(booleanLiteral value: Bool) {
    self.init(rawValue: value ? 1 : 0)
  }
}
&lt;/code&gt;
    &lt;p&gt;That‚Äôs it! Better type safety (you cannot confuse a &lt;code&gt;WGPUBool&lt;/code&gt; with any other integer value) and the convenience of Boolean literals in Swift.&lt;/p&gt;
    &lt;head rend="h2"&gt;Option sets&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;webgpu.h&lt;/code&gt; describes a set of flags using a &lt;code&gt;typedef&lt;/code&gt; of the &lt;code&gt;WGPUFlags&lt;/code&gt; type (a 64-bit unsigned integer) along with a set of global constants for the different flag values. For example, here is the &lt;code&gt;WGPUBufferUsage&lt;/code&gt; flag type and some of its constants:&lt;/p&gt;
    &lt;code&gt;typedef WGPUFlags WGPUBufferUsage;
static const WGPUBufferUsage WGPUBufferUsage_MapRead = 0x0000000000000001;
static const WGPUBufferUsage WGPUBufferUsage_MapWrite = 0x0000000000000002;
static const WGPUBufferUsage WGPUBufferUsage_CopySrc = 0x0000000000000004;
static const WGPUBufferUsage WGPUBufferUsage_Index = 0x0000000000000010;
&lt;/code&gt;
    &lt;p&gt;Similar to what we saw with &lt;code&gt;WGPUBool&lt;/code&gt;, &lt;code&gt;WGPUBufferUsage&lt;/code&gt; is a &lt;code&gt;typedef&lt;/code&gt; of a &lt;code&gt;typedef&lt;/code&gt; of a &lt;code&gt;uint64_t&lt;/code&gt;. There‚Äôs no type safety in this C API, and one could easily mix up these flags with, say, those of &lt;code&gt;WGPUMapMode&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;typedef WGPUFlags WGPUMapMode;
static const WGPUMapMode WGPUMapMode_Read = 0x0000000000000001;
static const WGPUMapMode WGPUMapMode_Write = 0x0000000000000002;
&lt;/code&gt;
    &lt;p&gt;We can do better, by layering more structure for the Swift version of this API using the same &lt;code&gt;SwiftWrapper&lt;/code&gt; approach from &lt;code&gt;WGPUBool&lt;/code&gt;. This goes into the &lt;code&gt;Typedefs&lt;/code&gt; section of API notes:&lt;/p&gt;
    &lt;code&gt;Typedefs:
- Name: WGPUBufferUsage
  SwiftWrapper: struct
&lt;/code&gt;
    &lt;p&gt;Now, &lt;code&gt;WGPUBufferUsage&lt;/code&gt; comes in as its own &lt;code&gt;struct&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;public struct WGPUBufferUsage : Hashable, Equatable, RawRepresentable {
    public init(_ rawValue: WGPUFlags)
    public init(rawValue: WGPUFlags)
}
&lt;/code&gt;
    &lt;p&gt;The initializers let you create a &lt;code&gt;WGPUBufferUsage&lt;/code&gt; from a &lt;code&gt;WGPUFlags&lt;/code&gt; value, and there is also a &lt;code&gt;rawValue&lt;/code&gt; property to get a &lt;code&gt;WGPUFlags&lt;/code&gt; value out of a &lt;code&gt;WGPUBufferInstance&lt;/code&gt;, so the raw value is always there‚Ä¶ but the default is to be type safe. Additionally, those global constants will come in as members of &lt;code&gt;WGPUBufferUsage&lt;/code&gt;, like this:&lt;/p&gt;
    &lt;code&gt;extension WGPUBufferUsage {
    /**
     * The buffer can be *mapped* on the CPU side in *read* mode (using @ref WGPUMapMode_Read).
     */
    public static var _MapRead: WGPUBufferUsage { get }

    /**
     * The buffer can be *mapped* on the CPU side in *write* mode (using @ref WGPUMapMode_Write).
     *
     * @note This usage is **not** required to set `mappedAtCreation` to `true` in @ref WGPUBufferDescriptor.
     */
    public static var _MapWrite: WGPUBufferUsage { get }

    /**
     * The buffer can be used as the *source* of a GPU-side copy operation.
     */
    public static var _CopySrc: WGPUBufferUsage { get }

    /**
     * The buffer can be used as the *destination* of a GPU-side copy operation.
     */
    public static var _CopyDst: WGPUBufferUsage { get }
}
&lt;/code&gt;
    &lt;p&gt;This means that, if you‚Äôre passing a value of type &lt;code&gt;WPUBufferUsage&lt;/code&gt;, you can use the shorthand ‚Äúleading dot‚Äù syntax. For example:&lt;/p&gt;
    &lt;code&gt;func setBufferUsage(_ usage: WGPUBufferUsage) { ... }

setBufferUsage(._MapRead)
&lt;/code&gt;
    &lt;p&gt;Swift has dropped the common &lt;code&gt;WPUBufferUsage&lt;/code&gt; prefix from the constants when it made them into members. However, the resulting names aren‚Äôt great. We can rename them by providing a &lt;code&gt;SwiftName&lt;/code&gt; in the API notes file within the &lt;code&gt;Globals&lt;/code&gt; section:&lt;/p&gt;
    &lt;code&gt;Globals:
- Name: WGPUBufferUsage_MapRead
  SwiftName: WGPUBufferUsage.mapRead
- Name: WGPUBufferUsage_MapWrite
  SwiftName: WGPUBufferUsage.mapWrite
&lt;/code&gt;
    &lt;p&gt;We can go one step further by making the &lt;code&gt;WGPUBufferUsage&lt;/code&gt; type conform to Swift‚Äôs &lt;code&gt;OptionSet&lt;/code&gt; protocol. If we revise the API notes like this:&lt;/p&gt;
    &lt;code&gt;Typedefs:
- Name: WGPUBufferUsage
  SwiftWrapper: struct
  SwiftConformsTo: Swift.OptionSet
&lt;/code&gt;
    &lt;p&gt;Now, we get the nice option-set syntax we expect in Swift:&lt;/p&gt;
    &lt;code&gt;let usageFlags: WGPUBufferUsage = [.mapRead, .mapWrite]
&lt;/code&gt;
    &lt;head rend="h2"&gt;Nullability&lt;/head&gt;
    &lt;p&gt;Throughout &lt;code&gt;webgpu.h&lt;/code&gt;, the &lt;code&gt;WGPU_NULLABLE&lt;/code&gt; macro is used to indicate pointers that can be NULL. The implication is that any pointer that is not marked with &lt;code&gt;WGPU_NULLABLE&lt;/code&gt; cannot be NULL. For example, here is the definition of &lt;code&gt;wgpuCreateInstance&lt;/code&gt; we used above:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT WGPUInstance wgpuCreateInstance(WGPU_NULLABLE WGPUInstanceDescriptor const * descriptor) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;WGPU_NULLABLE&lt;/code&gt; indicates that it‚Äôs acceptable to pass a NULL pointer in as the &lt;code&gt;descriptor&lt;/code&gt; parameter. Clang already has nullability specifiers to express this information. We could alter the declaration in the header to express that this parameter is nullable but the result type is never NULL, like this:&lt;/p&gt;
    &lt;code&gt;WGPU_EXPORT WGPUInstance _Nonnull wgpuCreateInstance(WGPU_NULLABLE WGPUInstanceDescriptor const * _Nullable descriptor) WGPU_FUNCTION_ATTRIBUTE;
&lt;/code&gt;
    &lt;p&gt;This eliminates the implicitly-unwrapped optionals (&lt;code&gt;!&lt;/code&gt;) from the signature of the initializer, so we end up with one that explicitly accepts a &lt;code&gt;nil&lt;/code&gt; descriptor argument and always returns a new instance (never &lt;code&gt;nil&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;extension WGPUInstanceImpl {
    /**
     * Create a WGPUInstance
     *
     * @returns
     * This value is @ref ReturnedWithOwnership.
     */
    public /*not inherited*/ init(descriptor: UnsafePointer&amp;lt;WGPUInstanceDescriptor&amp;gt;?)
}
&lt;/code&gt;
    &lt;p&gt;Now, I did cheat by hacking the header. Instead, we can express this with API notes on the parameters and result type by extending the entry we already have for &lt;code&gt;wgpuCreateInstance&lt;/code&gt; like this:&lt;/p&gt;
    &lt;code&gt;- Name: wgpuCreateInstance
  SwiftReturnOwnership: retained
  SwiftName: WGPUInstanceImpl.init(descriptor:)
  Parameters:
  - Position: 0
    Nullability: O
  ResultType: "WGPUInstance _Nonnull"
&lt;/code&gt;
    &lt;p&gt;To specific nullability of pointer parameters, one can identify them by position (where 0 is the first parameter to the function) and then specify whether the parameter should come into Swift as optional (&lt;code&gt;O&lt;/code&gt;, corresponds to &lt;code&gt;_Nullable&lt;/code&gt;), non-optional (&lt;code&gt;N&lt;/code&gt;, corresponds to &lt;code&gt;_Nonnull&lt;/code&gt;) or by left unspecified as an implicitly-unwrapped optional (&lt;code&gt;U&lt;/code&gt;, corresponds to &lt;code&gt;_Null_unspecified&lt;/code&gt;). For the result type, it‚Äôs a little different: we specified the result type along with the nullability specifier, i.e., &lt;code&gt;WGPUInstance _Nonnull&lt;/code&gt;. The end result of these annotations is the same as the modified header, so we can layer nullability information on top of the header.&lt;/p&gt;
    &lt;head rend="h2"&gt;Scripting the creation of &lt;code&gt;WebGPU.apinotes&lt;/code&gt; WebGPU.apinotes section" href="#scripting-the-creation-of-webgpuapinotes"&amp;gt;
             
          &lt;/head&gt;
    &lt;p&gt;&lt;code&gt;webgpu.h&lt;/code&gt; is about 6,400 lines long, and is regenerated from a database of the API as needed. Each of the WebGPU implementations seems to augment or tweak the header a bit. So, rather than grind through and manually do annotations, I wrote a little Swift script to ‚Äúparse‚Äù &lt;code&gt;webgpu.h&lt;/code&gt;, identify its patterns, and generate &lt;code&gt;WebGPU.apinotes&lt;/code&gt; for most of what is discussed in this post. The entirety of the script is here. It reads &lt;code&gt;webgpu.h&lt;/code&gt; from standard input and prints &lt;code&gt;WebGPU.apinotes&lt;/code&gt; to standard output.&lt;/p&gt;
    &lt;p&gt;Because &lt;code&gt;webgpu.h&lt;/code&gt; is generated, it has a very regular structure that we can pick up on via regular expressions. For example:&lt;/p&gt;
    &lt;code&gt;// Enum definitions, marked by WGPU_ENUM_ATTRIBUTE.
let enumMatcher = /} (?&amp;lt;name&amp;gt;\w+?) WGPU_ENUM_ATTRIBUTE/

// Object definitions, marked by WGPU_OBJECT_ATTRIBUTE.
let objectMatcher = /typedef struct (?&amp;lt;implName&amp;gt;\w+?)\* (?&amp;lt;name&amp;gt;\w+?) WGPU_OBJECT_ATTRIBUTE;/

// Function declarations, marked by WGPU_FUNCTION_ATTRIBUTE
let functionMatcher = /WGPU_EXPORT (?&amp;lt;nullableResult&amp;gt;WGPU_NULLABLE ?)?(?&amp;lt;resultType&amp;gt;\w+?) (?&amp;lt;name&amp;gt;\w+?)\((?&amp;lt;parameters&amp;gt;.*\)?) WGPU_FUNCTION_ATTRIBUTE;/
let parameterMatcher = /(?&amp;lt;type&amp;gt;[^),]+?) (?&amp;lt;name&amp;gt;\w+?)[),]/
&lt;/code&gt;
    &lt;p&gt;That‚Äôs enough to identify all of the enum types (so we can emit the &lt;code&gt;EnumExtensibility: closed&lt;/code&gt; API notes), object types (to turn them into shared references), and functions (which get nicer names and such). The script is just a big &lt;code&gt;readLine&lt;/code&gt; loop that applies the regexes to capture all of the various types and functions, then does some quick classification before printing out the API notes. The resulting API notes are in WebGPU.apinotes, and the generated Swift interface after these API notes are applied is here. You can run it with, e.g.,&lt;/p&gt;
    &lt;code&gt;swift -enable-bare-slash-regex webgpu_apinotes.swift &amp;lt; webgpu.h
&lt;/code&gt;
    &lt;p&gt;This script full of regular expressions is, admittedly, a bit of a hack. A better approach for an arbitrary C header would be to use &lt;code&gt;libclang&lt;/code&gt; to properly parse the headers. For WebGPU specifically, the webgpu-headers project contains a database from which the header is generated, and one could also generate API notes directly from that header. Regardless of how you get there, many C libraries have well-structured headers with conventions that can be leveraged to create safer, more ergonomic projections in Swift.&lt;/p&gt;
    &lt;head rend="h2"&gt;Swiftifying your favorite C library&lt;/head&gt;
    &lt;p&gt;The techniques described in this post can be applied to just about any C library. To do so, I recommend setting up a small package like the one described here for WebGPU, so you can iterate quickly on example code to get a feel for how the Swift projection of the C API will work. The annotations might not get you all the way to the best Swift API, but they are a lightweight way to get most of the way there. Feel free to also extend the C types to convenience APIs that make sense in Swift, like I did above to make &lt;code&gt;WGPUBool&lt;/code&gt; conform to &lt;code&gt;ExpressibleByBooleanLiteral&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;A little bit of annotation work on your favorite C library can make for a safer, more ergonomic, more Swifty experience of working with that library.&lt;/p&gt;
    &lt;head rend="h2"&gt;Postscript: Thoughts for improving the generated webgpu.h&lt;/head&gt;
    &lt;p&gt;The regular structure of &lt;code&gt;webgpu.h&lt;/code&gt; helped considerably when trying to expose the API nicely in Swift. That said, there are a few ways in which &lt;code&gt;webgpu.h&lt;/code&gt; could be improved to require less annotation for this purpose:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;WGPU_ENUM_ATTRIBUTE&lt;/code&gt;would be slightly nicer if placed on the&lt;code&gt;enum&lt;/code&gt;itself, rather than on the&lt;code&gt;typedef&lt;/code&gt;. If it were there, we could use&lt;code&gt;#define WGPU_ENUM_ATTRIBUTE __attribute__((enum_extensibility(closed)))&lt;/code&gt;&lt;p&gt;and not have to generate any API notes to bring these types in as proper enums in Swift.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;WGPU_OBJECT_ATTRIBUTE&lt;/code&gt;could provide the names of the retain and release operations and be placed on the&lt;code&gt;struct&lt;/code&gt;itself. If it were there, we could use&lt;code&gt;#define WGPU_OBJECT_ATTRIBUTE(RetainFn,ReleaseFn) SWIFT_SHARED_REFERENCE(RetainFn,ReleaseFn)&lt;/code&gt;&lt;p&gt;and not have to generate any API notes to bring these types in as classes in Swift.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;WGPU_NULLABLE&lt;/code&gt;could be placed on the pointer itself (i.e., after the&lt;code&gt;*&lt;/code&gt;) rather than at the beginning of the type, to match the position of Clang‚Äôs nullability attributes. If it were placed there, then&lt;code&gt;#define WGPU_NULLABLE _Nullable&lt;/code&gt;&lt;p&gt;would work with Clangs‚Äô longstanding nullable-types support. Swift would then import such pointers as optional types (with&lt;/p&gt;&lt;code&gt;?&lt;/code&gt;). Moreover, if some macros&lt;code&gt;WGPU_ASSUME_NONNULL_BEGIN&lt;/code&gt;and&lt;code&gt;WGPU_ASSUME_NONNULL_END&lt;/code&gt;were placed at the beginning and end of the header, they could be mapped to Clang‚Äôs pragmas to assume that any pointer not marked ‚Äúnullable‚Äù is always non-null:&lt;code&gt;#define WGPU_ASSUME_NONNULL_BEGIN #pragma clang assume_nonnull begin #define WGPU_ASSUME_NONNULL_END #pragma clang assume_nonnull end&lt;/code&gt;&lt;p&gt;This would eliminate all of the implicitly unwrapped optionals (marked&lt;/p&gt;&lt;code&gt;!&lt;/code&gt;in the Swift interface), making it easier to use safely.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.swift.org/blog/improving-usability-of-c-libraries-in-swift/"/><published>2026-01-22T23:34:44+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46726857</id><title>Why medieval city-builder video games are historically inaccurate (2020)</title><updated>2026-01-23T07:18:36.882722+00:00</updated><content>&lt;doc fingerprint="b302597347b4065b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why medieval city-builder video games are historically inaccurate&lt;/head&gt;
    &lt;p&gt;This blog post explores the historical accuracy of medieval city-builder video games.&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Since many of us are working from home in these trying times, it seems safe to assume that more people than ever are indulging in playing the occasional computer game. A city builder is a specific kind of computer game in which you design a city, extract resources, set up production chains and ensure that your settlement grows. City builders are very similar to strategy games as they reward patience and strategy. In this article, I will take a look at one sub-genre of the city builder, the medieval city builder, and explain how this gaming genre relates to our knowledge of medieval settlement planning.&lt;/p&gt;
    &lt;head rend="h3"&gt;Historical city builders&lt;/head&gt;
    &lt;p&gt;The city builder has its origins far back in the 1990s in the combination of the strategy genre and the management genre, leading to games such as Sim City (1989), Caesar (1992) and Age of Empires (1997).&lt;/p&gt;
    &lt;p&gt;It did not take long before medieval-themed city builders popped up. We may think of Settlers (1993) and Knights and Merchants (1998). In addition, the Anno games (1998-2019), although initially set in the 1600s basically had a medieval theme.&lt;/p&gt;
    &lt;p&gt;These games often start with plopping down a village center on a promising location near abundant resources. You then continue to gather these resources which grant you building materials for building new homes and facilities for your settlement.&lt;/p&gt;
    &lt;p&gt;Setting up specialized production chains might involve growing grain, milling the grain for flour and turning the flour into bread which feeds your villages. Similarly, another production chain might involve rearing sheep for their wool, turning the wool into cloth and turning the cloth into clothing. When done correctly, the reward of correct investments and planning is that you see your settlement grow.&lt;/p&gt;
    &lt;p&gt;This often leads to settlements growing organically from a couple of houses around a community center to a larger settlement with hundreds of people. However logical such an organic growth of a settlement might seem, it is not historically accurate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Medieval village life &lt;/head&gt;
    &lt;p&gt;&lt;lb/&gt;Any gameplay loop that tells a story of linear settlement growth is incongruent with how a medieval economy worked (see Foussier 2004). Medieval villagers were often living on the edge of subsistence. Agricultural surpluses were skimmed by the church and the feudal lords. Bad harvests, banditry, warfare and disease might decimate a village community at any time. For this very reason, the demography of many European villages remained relatively stable between the twelfth and the eighteenth century. It may therefore be clear that the gameplay loop of city builders pivots around the concept of doing the historically exceptional (i.e. growing a settlement to a town) and thereby strays far from what actually happened in the lives of our medieval forebears. &lt;lb/&gt;A notable exception to this genre trope is the game Banished (2014) in which high mortality rates and bad weather do seriously stifle any kind of linear growth. In this city builder you are constantly fighting the odds and settlement growth is not guaranteed. However, also in Banished it is your goal to overcome the stagnation and lead your settlement to expansion.&lt;/p&gt;
    &lt;p&gt;A thing that is rarely touched upon in medieval city builders is how complex village life actually was. This can be exemplified by how the community related to its overlords. Land ownership here is key. Land in the community might be owned by a lord, a local liegeman, a monastery or even directly by the duke or count. Taxes, rents and tithes were the organisational structures in which the landowner was tied to the farmers who worked the fields. Often the payment of taxes and tithes was linked to feast days and the visit of the tax collector represented a big event in the agricultural year. An interesting side note is that some obligations which the commoners had to the lord and the church (such as seigneurial duties like working a mill) might drain the community from the needed manpower for tilling the land. Furthermore, a rural community that was its own seigneury had access to a law court with sheriff, aldermen and a local militia (Middle Dutch schutterie) to fight off bandits with. Harsh capital punishments were set in place to deter anyone from raiding the farms and hamlets and the village gallows were often the first thing one saw when approaching a medieval settlement.&lt;/p&gt;
    &lt;head rend="h3"&gt;Planning a medieval settlement&lt;/head&gt;
    &lt;p&gt;But something that is much more fundamental to the theme of a settlement building game, is how medieval settlements were actually planned and grew. Landscape historians and archaeologists have acquired a lot of insight into how this worked.&lt;/p&gt;
    &lt;p&gt;Let's start with the realization that medieval settlements in their first stages of development were planned and laid out according to a specific design. In my own research into the settlement history of West-Brabant (southern Netherlands, from 1000 to 1300 CE) I have encountered the following types.&lt;/p&gt;
    &lt;p&gt;Here is a sketch of a Brabantine circular manor (Middle Dutch vroonhoeve). This is a reinforced circular homestead with moat, often next to a bend in the river, containing several farms and a fan-like plot pattern radiating out from it. Such manors were often called BORCH.&lt;/p&gt;
    &lt;p&gt;Here is a sketch of a Brabantine street settlement, often built with exploitation of nearby fenland in mind. It consists of a line of farms with associated evenly sized rectangular plots built in a line perpendicular to a raised road.&lt;/p&gt;
    &lt;p&gt;Here is a more complex exploitation village which is set up with a moated enclosed church homestead and a central meadow as its center. There is a line of farms next to the road. The arable land to the east is bordered by a ditch supplying fresh drinking water (Middle Dutch bansloot). In layout, this type represents a hybrid between the two earlier settlement types.&lt;/p&gt;
    &lt;p&gt;Let us first make clear that these different types of exploitation settlements often existed alongside each other and can be found in one and the same region. In part, the different types reflect different chronological layers but some types were also more suited to certain geographical environments than others.&lt;/p&gt;
    &lt;p&gt;So how were these settlements planned? Many medieval exploitation enterprises were initiated by a monastery or a consortium of free men who were granted permission by (or bought permission from) the feudal lord to ‚Äúcolonize‚Äù the wilderness.&lt;/p&gt;
    &lt;p&gt;Clearing the wooded landscape in order to create arable land was done by cutting away the trees and bushes (Middle Dutch rode) or, alternatively, burning it away in controlled fires (Middle Dutch brant).&lt;/p&gt;
    &lt;p&gt;Land surveyors sent by the lord would then measure out the block or strips that would be taken in cultivation. Strips of arable land were often 1250m deep (6 Middle Dutch voorlingen = furlongs) so that the plough could go straight in a long line before having to turn. Important blocks or strips were demarcated by hedges, earthwork, woodwork, ditches or roads. Medieval names for these blocks often survived into the modern day.&lt;/p&gt;
    &lt;p&gt;The presence of drinking water (a river or a brook) in the vicinity was an important factor in choosing the location for the settlement. The vicinity of water entailed risk and reward because flooding was an ever present danger. Floods could devastate arable land but might also fertilize it. Meadows in particular were often situated in flood areas.&lt;/p&gt;
    &lt;head rend="h3"&gt;Managing a settlement&lt;/head&gt;
    &lt;p&gt;So how was such a settlement managed? First of all, the quality of the soil had to be carefully controlled by crop rotation: specific crops were sown on different segments of the arable land with one part laying fallow to recover from the tilling (English three-field system, Dutch drieslagstelsel). The cattle and sheep were put out to pasture on the common meadows guarded by a shepherd or cowherd. Pigs were allowed to forage in the nearby forests and killed in autumn before the winter starvation set in.&lt;/p&gt;
    &lt;p&gt;Roads and rivers were important for transport of crops and livestock. These roads, some of them paved, some of them not, needed to be maintained. They were essential to the payment of the tithe, since tithe collectors assessed the harvest on the field and later collected the sheaves on the side of the road.&lt;/p&gt;
    &lt;p&gt;The buildings within the community also needed maintenance. Farmhouses, community barns and stables were made of wood and had to be rebuilt every few generations, only the name of the farm or homestead being continued.&lt;/p&gt;
    &lt;p&gt;So what kind of threats did a medieval settlement face? First of all, the weather was an important factor which dictated the success of the harvest. Storms, droughts and floods could devastate the harvest and decimate the community.&lt;/p&gt;
    &lt;p&gt;Diseases and epidemics were another danger threatening the community. The situation on the countryside was a lot better in this regard than in the medieval towns, but an epidemic could still mean the end of a village. Similarly, diseases among livestock impacted the medieval subsistence economy in a brutal way.&lt;/p&gt;
    &lt;p&gt;Then there are the consequences of medieval warfare affecting the community: Armies that passed by could plunder the village, burn the farms and execute villagers at will. Or they could also demand supplies, food and provisions as an emergency "tax"&lt;/p&gt;
    &lt;p&gt;But war also brought indirect consequences; a liege lord calling the banners and levying troops from the village community might extract a large part of the adult men. Warfare also disrupted the trade networks that supplied a village with building materials and commodities.&lt;/p&gt;
    &lt;p&gt;Then there were internal threats to the fabric of the village community. We may think of social unrest because of land disputes. Feuds could also tear a community apart with endemic vendetta‚Äôs causing death and despair. A socially unstable society was also more prone to internal accusations of heresy and witchcraft.&lt;/p&gt;
    &lt;head rend="h3"&gt;An ‚Äúaccurate‚Äù medieval settlement builder&lt;/head&gt;
    &lt;p&gt;So, which of the above listed features could potentially contribute to a more historically accurate computer game about medieval settlement building? First of all, it would be more realistic if the settlement could first be planned out and was not forced to "grow organically" from a community center. The first settlement phase would be a test of how ‚Äúsuccessful‚Äù a layout is in adapting to the exigencies of the terrain and the needs of the community. Only after that initial layout proved successful, further expansions can be planned.&lt;/p&gt;
    &lt;p&gt;Secondly, it would be more realistic if we could build both straight roads and curved roads, just as in Cities Skylines (2015), a modern city builder well known for its incredibly flexible layout tools. Incidentally, the tools of Cities Skylines can also be used to recreate medieval settlements, as was done by YouTube creator Play Curiously who constructed an impression of a medieval Croatian village.&lt;/p&gt;
    &lt;p&gt;Such a flexible road drawing tool can then also be used to lay out ditches, hedges and enclosures since these features were central to the medieval experience of the cultivated landscape.&lt;/p&gt;
    &lt;p&gt;Thirdly, It would be interesting to see a medieval-themed game embrace the concept of flood valleys that limit and endanger pasture and arable land. Other historical city builders such as Pharaoh (1999) and Children of the Nile (2004) already implemented this feature for their setting in Ancient Egypt. However, such a mechanic would likewise fit a medieval city builder and show the general public how medieval society dealt with seasonal flooding as well as the devastating effects that storm floods could have.&lt;/p&gt;
    &lt;p&gt;And finally, something that would, in my opinion, really add to the realism and historical flavor of a medieval-themed city builder would be the introduction of mechanisms in which agricultural surpluses are skimmed by the church and the feudal lord. Tithes, taxes and rents! Instead of merely abstracting the taxes into an income modifier or letting the player be the extractor himself, we could be shown the tax collector visiting the village, counting the sheaves by the side of the road, selecting the calves and chickens. This way, the experiences of our medieval forebears are visualized and may help to educate the public about medieval village life.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why not?&lt;/head&gt;
    &lt;p&gt;There are some good reasons why city building games are not that historically accurate and instead adhere to the established formula of the city building game.&lt;/p&gt;
    &lt;p&gt;First of all, a linear growth model makes sense from a gameplay perspective, since it is rewarding to see your settlement grow.in a linear way. It fosters a feeling of progress and motivates the player to keep momentum and push through to the next expansion phase. Secondly, games are generally wary of punishing failure too harshly in order to avoid demoralizing the player. Thirdly, in order to facilitate path finding for the simulated villagers it is easier to implement a gridlike road and building system rather than an off-grid building system that allows for curvy roads. So far only Cities Skylines has managed to do this in a satisfactory way.&lt;/p&gt;
    &lt;p&gt;Lastly, for marketing purposes and recognizability, game developers generally don't stray too far from the image of the Middle Ages that the public is already acquainted with. For a medieval city builder this means windmills, industrious peasants, lots of sheep and stone castles. Things like land surveying, crop rotation and tithe collection do not fit this image and challenge the romanticized picture of the uneducated farmer in his pre-industrial environment.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Although I think medieval-themed city building games could benefit from incorporating some of the things we know about medieval settlement history into the gameplay loop, it may not be desirable for game developers to stray too far from the established formula. The idea that medieval settlements developed organically according to messy road plans is strongly imbedded in popular perception. Allowing both straight and curved road building in medieval city builders, may serve to challenge some of the stereotypes that exist about medieval village life. And if you ask me, that would be a good thing for it is an enriching experience to see the world through the eyes of our medieval forebears. One may find out that their lives were not that different after all...&lt;/p&gt;
    &lt;head rend="h3"&gt;Further reading&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fossier, R. (2004). ‚ÄúThe Rural Economy and Demographic Growth.‚Äù In: D. Luscombe &amp;amp; J. Riley-Smith (Eds.). The New Cambridge Medieval History. Cambridge: Cambridge University Press, 11-46.&lt;/item&gt;
      &lt;item&gt;Van Ham, W. (1979). ‚ÄúDorp en dorpsleven in middeleeuws Wouw." in: A. Delahaye (red.), De Heren XVII van Nassau-Brabant, 316-336.‚Äù&lt;/item&gt;
      &lt;item&gt;(forthc.) Kerkhof, P.A. (2020). ‚ÄúSaer, Saert; een Zuid-Nederlandse veldnaam van onzekere oorsprong.‚Äù Noordbrabants Historisch Jaarboek.&lt;/item&gt;
      &lt;item&gt;Leenders, K.A.H.W. (1996). "Noord-Vlaanderen en de Noordwesthoek; een vergelijking." Tijdschrift voor Waterstaatsgeschiedenis 5, 67-73.&lt;/item&gt;
      &lt;item&gt;Leenders, K.A.H.W. (1989). Verdwenen venen; een onderzoek naar de ligging en exploitatie van thans verdwenen venen in het gebied tussen Antwerpen, Turnhout, Geertruidenberg en Willemstad (1250-1750). Reeks Landschapsstudies 13, Wageningen.&lt;/item&gt;
      &lt;item&gt;Oosthuizen, S. (2017). The Anglo-Saxon fenland. Windgather Press.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;¬© Alexia Kerkhof and Leiden Medievalists Blog, 2020. Unauthorised use and/or duplication of this material without express and written permission from this site‚Äôs author and/or owner is strictly prohibited. Excerpts and links may be used, provided that full and clear credit is given to Alexia Kerkhof and Leiden Medievalists Blog with appropriate and specific direction to the original content.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.leidenmedievalistsblog.nl/articles/why-medieval-city-builder-video-games-are-historically-inaccurate"/><published>2026-01-23T00:22:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46726916</id><title>Stunnel</title><updated>2026-01-23T07:18:35.926344+00:00</updated><content>&lt;doc fingerprint="aedecc1f008fa6d0"&gt;
  &lt;main&gt;
    &lt;p&gt;Stunnel is a proxy designed to add TLS encryption functionality to existing clients and servers without any changes in the programs' code. Its architecture is optimized for security, portability, and scalability (including load-balancing), making it suitable for large deployments.&lt;/p&gt;
    &lt;p&gt;Stunnel uses the OpenSSL library for cryptography, so it supports whatever cryptographic algorithms are compiled into the library. It can benefit from the FIPS 140-2 validation of the OpenSSL FIPS Provider, as long as the building process meets the OpenSSL FIPS 140-2 Security Policy. Our latest Windows installer includes the OpenSSL FIPS Provider.&lt;/p&gt;
    &lt;p&gt;Stunnel is a free software authored by Micha≈Ç Trojnara. Although distributed under GNU GPL version 2 or later with OpenSSL exception, stunnel is not a community project. We retain the copyright of the source code. Please contact us for commercial support or non-GPL licenses. Free, community-based support is also available via stunnel-users mailing list.&lt;/p&gt;
    &lt;p&gt;We offer commercial support with several levels of response time up to 24/7/365 helpline.&lt;/p&gt;
    &lt;p&gt;Download latest version of stunnel and try it out yourself.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.stunnel.org/"/><published>2026-01-23T00:30:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46727587</id><title>Bugs Apple Loves</title><updated>2026-01-23T07:18:35.701813+00:00</updated><content>&lt;doc fingerprint="e3cc5b7e4366455c"&gt;
  &lt;main&gt;
    &lt;p&gt;Loading Apple's bugs&lt;/p&gt;
    &lt;p&gt;Why else would they keep them around for so long?&lt;/p&gt;
    &lt;p&gt;Total time wasted by humanity because Apple won't fix these&lt;/p&gt;
    &lt;p&gt;Calculating...&lt;/p&gt;
    &lt;p&gt;and counting&lt;/p&gt;
    &lt;p&gt;Every bug is different. But the math is always real.&lt;lb/&gt;Think our numbers are wrong? Edit them yourself.&lt;/p&gt;
    &lt;code&gt;Users Affected √ó Frequency √ó Time Per Incident&lt;/code&gt;
    &lt;p&gt;How many Apple users hit this bug, how often, and how long they suffer each time.&lt;/p&gt;
    &lt;code&gt;Œ£ (Workaround Time √ó Participation Rate)&lt;/code&gt;
    &lt;p&gt;The extra time spent by people who try to fix what Apple won't.&lt;/p&gt;
    &lt;code&gt;Years Unfixed √ó Pressure Factor&lt;/code&gt;
    &lt;p&gt;How long Apple has known about this and how urgent the task usually is.&lt;/p&gt;
    &lt;code&gt;Human Hours Wasted √∑ Engineering Hours to Fix&lt;/code&gt;
    &lt;p&gt;How many times over Apple could have fixed it with the productivity they've destroyed.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bugsappleloves.com"/><published>2026-01-23T02:24:12+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46728197</id><title>Talking to LLMs has improved my thinking</title><updated>2026-01-23T07:18:35.590071+00:00</updated><content>&lt;doc fingerprint="cd35e83d9fb71b94"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôve been surprised by one aspect of using large language models more than any other.&lt;/p&gt;
    &lt;p&gt;They often put into words things I have long understood, but could not write down clearly. When that happens, it feels less like learning something new and more like recognition. A kind of ‚Äúyes, that‚Äôs it‚Äù moment.&lt;/p&gt;
    &lt;p&gt;I have not seen this effect discussed much, but I think it matters. I also think it has improved how I think.&lt;/p&gt;
    &lt;head rend="h2"&gt;Much of what we know is tacit&lt;/head&gt;
    &lt;p&gt;As programmers and developers, we build up a lot of understanding that never quite becomes explicit.&lt;/p&gt;
    &lt;p&gt;You know when a design is wrong before you can say why. You sense a bug before you can reproduce it. You recognize a bad abstraction instantly, even if it takes an hour to explain the problem to someone else.&lt;/p&gt;
    &lt;p&gt;This is not a failure. It is how experience operates. The brain compresses experience into patterns that are efficient for action, not for speech. Those patterns are real, but they are not stored in sentences.&lt;/p&gt;
    &lt;p&gt;The problem is that reflection, planning, and teaching all require language. If you cannot express an idea, you cannot easily inspect it or improve it.&lt;/p&gt;
    &lt;head rend="h2"&gt;LLMs are good at the opposite problem&lt;/head&gt;
    &lt;p&gt;Large language models are built to do exactly this ‚Äì turn vague structure into words.&lt;/p&gt;
    &lt;p&gt;When you ask a good question and the response resonates, the model is not inventing insight. It is mapping a latent structure to language in a way that happens to align with your own internal model.&lt;/p&gt;
    &lt;p&gt;That alignment is what produces the sense of recognition. I already had the shape of the idea. The model supplied a clean verbal form.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting things into words changes the thought&lt;/head&gt;
    &lt;p&gt;Once an idea is written down, it becomes easier to work with.&lt;/p&gt;
    &lt;p&gt;Vague intuitions turn into named distinctions. Implicit assumptions become visible. At that point you can test them, negate them, or refine them.&lt;/p&gt;
    &lt;p&gt;This is not new. Writing has always done this for me. What is different is the speed. I can probe half-formed thoughts, discard bad formulations, and try again without much friction. That encourages a kind of thinking I might have otherwise skipped.&lt;/p&gt;
    &lt;head rend="h2"&gt;The feedback loop matters&lt;/head&gt;
    &lt;p&gt;After you see a good articulation of an idea, you start thinking with that style of language.&lt;/p&gt;
    &lt;p&gt;Over time I‚Äôve noticed that now I do this without an LLM to hand. Can I phrase in precise language what I am thinking, feeling, believing, right now, and why.&lt;/p&gt;
    &lt;p&gt;In that sense, the model is not improving my thinking directly. It is improving the interface between my thinking and language. Since reasoning depends heavily on what one can represent explicitly, that improvement can feel like a real increase in clarity.&lt;/p&gt;
    &lt;p&gt;The more I do this, the better I get at noticing what I actually think.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://philipotoole.com/why-talking-to-llms-has-improved-my-thinking/"/><published>2026-01-23T03:52:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46728808</id><title>I built a light that reacts to radio waves [video]</title><updated>2026-01-23T07:18:34.658597+00:00</updated><content>&lt;doc fingerprint="50559455455d1642"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket ¬© 2026 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=moBCOEiqiPs"/><published>2026-01-23T05:34:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46729368</id><title>Proton Spam and the AI Consent Problem</title><updated>2026-01-23T07:18:34.426237+00:00</updated><content>&lt;doc fingerprint="ef5f40914ea2becf"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Proton Spam and the AI Consent Problem&lt;/head&gt;
    &lt;p&gt;On Jan 14th Proton sent out an email newsletter with the subject line:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Introducing Projects - Try Lumo√¢s powerful new feature now&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Lumo is Proton√¢s &lt;/p&gt;
    &lt;p&gt;There is a problem with this email. And I√¢m not talking about the question of how exactly AI aligns with Proton√¢s core values of privacy and security.&lt;/p&gt;
    &lt;p&gt;The problem is I had already explicitly opted out of Lumo emails.&lt;/p&gt;
    &lt;p&gt;That toggle for √¢Lumo product updates√¢ is unchecked. Lumo is the only topic I√¢m not subscribed to. Proton has over a dozen newsletters, including some crypto nonsense. I opt-in to everything but Lumo, I gave an undeniable no to Lumo emails.&lt;/p&gt;
    &lt;p&gt;So the email I received from Proton is spam, right?&lt;/p&gt;
    &lt;p&gt;My understanding is that spam is a violation of GDPR and UK data protection laws. Regardless, Proton√¢s email is a clear abuse of their own service towards a paying business customer.&lt;/p&gt;
    &lt;p&gt;Before I grab my pitchfork I emailed Proton support.&lt;/p&gt;
    &lt;head rend="h2"&gt;Proton Support&lt;/head&gt;
    &lt;p&gt;Despite the subject line and contents, and despite the √¢From Lumo√¢ name and &lt;code&gt;@lumo.proton.me&lt;/code&gt; address, maybe this was an honest mistake?&lt;/p&gt;
    &lt;p&gt;Proton√¢s first reply explained how to opt-out.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hello David,&lt;/p&gt;
      &lt;p&gt;Thank you for contacting us.&lt;/p&gt;
      &lt;p&gt;You can unsubscribe from the newsletters if you do the following:&lt;/p&gt;
      &lt;p&gt;- Log in to your account at https://account.protonvpn.com/login&lt;/p&gt;
      &lt;p&gt;- Navigate to the Account category&lt;/p&gt;
      &lt;p&gt;- Disable the check-marks under √¢Email subscriptions√¢&lt;/p&gt;
      &lt;p&gt;- If you need additional assistance, let me know.&lt;/p&gt;
      &lt;p&gt;[screenshot of the same opt-out toggle]&lt;/p&gt;
      &lt;p&gt;-Have a nice day.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;John Support directs me to the exact same √¢Lumo product updates√¢ toggle I had already unchecked. I replied explaining that I had already opted out. Support replies saying they√¢re √¢checking this with the team√¢ then later replies again asking for screenshots.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Can you make sure to send me a screenshot of this newsletter option disabled, as well as the date when the last message was sent to you regarding the Lumo offer?&lt;/p&gt;
      &lt;p&gt;You can send me a screenshot of the whole message, including the date.&lt;/p&gt;
      &lt;p&gt;Is it perhaps 14 January 2026 that you received the message?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I found that last line curious, are they dealing with other unhappy customers? Maybe I√¢m reading too much into it.&lt;/p&gt;
    &lt;p&gt;I sent the screenshots and signed off with √¢Don√¢t try to pretend this fits into another newsletter category.√¢&lt;/p&gt;
    &lt;p&gt;After more √¢checking this with the team√¢ I got a response today.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In this case, the mentioned newsletter is for promoting Lumo Business Suit to Business-related plans.&lt;/p&gt;
      &lt;p&gt;Hence, why you received it, as Product Updates and Email Subscription are two different things.&lt;/p&gt;
      &lt;p&gt;In the subscription section, you will see the √¢Email Subscription√¢ category, where you can disable the newsletter in order to avoid getting it in the future.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;If I understand correctly, Proton are claiming this email is the √¢Proton for Business newsletter√¢. Not the √¢Lumo product updates√¢ newsletter.&lt;/p&gt;
    &lt;p&gt;I don√¢t know about you, but I think that√¢s baloney. Proton Support had five full business days to come up with a better excuse. Please tell me, how can I have been any more explicit about opting out of Lumo emails, only to receive √¢Try Lumo√¢ √¢From Lumo√¢, and be told that is not actually a Lumo email?&lt;/p&gt;
    &lt;head rend="h2"&gt;Non-Consent&lt;/head&gt;
    &lt;p&gt;Has anyone else noticed that the AI industry can√¢t take √¢no√¢ for an answer? AI is being force-fed into every corner of tech. It√¢s unfathomable to them that some of us aren√¢t interested.&lt;/p&gt;
    &lt;p&gt;The entire AI industry is built upon a common principle of non-consent. They laugh in the face of IP and copyright law. AI bots DDoS websites and lie about user-agents. Can it get worse than the sickening actions of Grok? I dread to think.&lt;/p&gt;
    &lt;p&gt;As Proton has demonstrated above, and Mozilla/Firefox recently too, the AI industry simply will not accept √¢no√¢ as an answer. Some examples like spam are more trivial than others, but the growing trend is vile and disturbing.&lt;/p&gt;
    &lt;p&gt;I do not want your AI.&lt;/p&gt;
    &lt;head rend="h3"&gt;Update for 23rd January&lt;/head&gt;
    &lt;p&gt;I guess someone at Microsoft read my post and said √¢hold my beer√¢. This morning I woke up to a lovely gift in my inbox; √¢Build Al agents with the new GitHub Copilot SDK√¢.&lt;/p&gt;
    &lt;p&gt;GitHub Ensloppification is moving faster than I can delete my account for good. (It√¢s an unfortunate requirement for client projects.) For the record, I have never said √¢yes√¢ to any GitHub newsletter. Even before Copilot I disabled every possible GitHub email notification.&lt;/p&gt;
    &lt;p&gt;The √¢Unsubscribe√¢ link provides the hidden newsletter list. There is nothing within GitHub account settings I can find to disable spam.&lt;/p&gt;
    &lt;p&gt;As expected, Microsoft has opted me in without my consent. The wheels are falling off at GitHub. The brutally slow front-end UI. The embarrassingly lacklustre Actions CI. Now this sloppy tripe everywhere. Reminder to developers: GitHub is not Git.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dbushell.com/2026/01/22/proton-spam/"/><published>2026-01-23T07:01:29+00:00</published></entry></feed>