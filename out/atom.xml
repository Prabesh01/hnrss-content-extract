<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-24T22:40:47.481279+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46744569</id><title>The Kept and the Killed (2022)</title><updated>2026-01-24T22:40:54.098477+00:00</updated><content>&lt;doc fingerprint="a6b489581b3188f6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Kept and the Killed&lt;/head&gt;
    &lt;p&gt;Of the 270,000 photographs commissioned by the US Farm Security Administration to document the Great Depression, more than a third were “killed”. Erica X Eisen examines the history behind this hole-punched archive and the unknowable void at its center.&lt;/p&gt;
    &lt;p&gt;January 26, 2022&lt;/p&gt;
    &lt;p&gt;The first killed negative I encounter is of a field. It’s a Carl Mydans shot, and a drought has reduced the land to a flat, cracked expanse out of which only a few tenacious scraggles of crabgrass have managed to sprout. Nothing notable here, no action, no grand geometries — except that the center of the negative has been pierced by a perfect circle, as though in counterpoint to the sprocket holes running along the photo’s edge. Briefly I imagine that this circle is what has doomed the land, a well into which all the precious waters must have run. Months after coming across the photograph, it is that void, more than any peripheral scenery, which remains anchored in my memory — that and the caption describing the picture as “killed”.&lt;/p&gt;
    &lt;p&gt;Begun as part of the alphabet soup of Franklin D. Roosevelt’s New Deal policies, the Farm Security Administration (FSA), under the aegis of which Mydans’ ill-fated photo was taken, had been tasked with resettling struggling farmers onto more fertile ground, providing education about agricultural science, and giving loans for the purchase of land, feed, and livestock. Arguably its most enduring legacy today, however, is the hundreds of thousands of photographs the agency1 produced to document the plight of destitute farmers, many of whom were trapped in an inescapable pit of debt made deeper still by the environmental devastation of the Dust Bowl. The project’s head, Roy Emerson Stryker (1893–1975), would shop his favorites around, going from newsroom to newsroom “with pictures under his arm”, as Dorothea Lange would later recall, in an attempt to secure placements in major papers.2 Stryker had encyclopedic ambitions: tasked with the mission of “introducing America to Americans”, the FSA’s photography wing would soon see its remit balloon far past images of rural poverty to encompass everything from aerial shots of utopian building projects to Kodachrome still lifes — all of which could find a home within what Stryker called simply the File.3&lt;/p&gt;
    &lt;p&gt;Yet despite the File’s colossal scope, there were still images that Stryker deemed unfit for inclusion. These photographs had to be, in his parlance, “killed” — marked for exclusion, usually with a merciless hole-punch through the middle. By the time the project came to a close, the FSA’s photographers had captured some 270,000 images, of which a staggering 100,000 were killed.4 These include work by pioneering Black filmmaker and photographer Gordon Parks; by Russell Lee, who would go on to document the internment of Japanese Americans during the Second World War; by Marion Post Wolcott, the FSA’s first full-time female photographer. They also include images of which not even a punctured trace survives. Stryker only used the hole-punch method on 35mm negatives; when presented with sheet film he felt was unsuitable, he simply discarded it.5&lt;/p&gt;
    &lt;p&gt;Stryker’s career had a ping-pong trajectory: he dropped out of the Colorado School of Mines to become a rancher before being shipped off to fight in World War I, then returned to the U.S. and studied economics at Columbia. There, he researched utopian socialism with Rexford Tugwell, a professor whose emphasis on the pedagogical and psychological impact of visual aids left an impression on Stryker. After Tugwell became part of Roosevelt’s “Brain Trust” of key advisers, he called upon his former student to join him in Washington and head up the photography arm of the Resettlement Administration, which, in 1937, was folded into the Farm Security Administration.6 Though not a photographer himself, Stryker nevertheless had a clearly defined sense of the medium as an instrument of social action and knew what he liked and did not like in an image. He would often send his photographers into the field armed with pages-long scripts detailing what exactly he wanted them to capture, itemized lists that sometimes approached aphoristic form: “The baseball diamond as an important part of our general landscape”; “Pressed clothes”; “The wall decorations in homes as an index to the different income groups and their reactions”; “Old tires piles”; “(What will happen to the roadside hamburger stand?)”; “Pictures of men, women, and children who appear as if they really believed in the U.S.”7&lt;/p&gt;
    &lt;p&gt;Stryker’s editorial philosophy occasionally brought him into conflict with the photographers he employed. His refusal to use the captions Lange painstakingly composed for her own images greatly frustrated her (despite praising Migrant Mother as the pinnacle of the FSA photography program’s output, Stryker would fire Lange on three separate occasions).8 Photographer Edwin Rosskam remarked bitterly that Stryker’s hole-punching habit “was barbaric to me. . . I'm sure that some very significant pictures have in that way been killed off, because there is no way of telling, no way, what photograph would come alive when”.9 Another FSA staffer, Ben Shahn, referred to Stryker’s style as “a little bit dictatorial”:&lt;/p&gt;
    &lt;quote&gt;He ruined quite a number of my pictures. . . . Some of them were incredibly valuable. He didn't understand at the time. . . . Later on, during the war . . . I went to look for [a] negative and he[‘d] punched a hole through it. Well, I shot my mouth off about that. But, I didn't know what was done with a lot of my negatives, naturally. He learned, then, not to do that, you see, because this was an invaluable document of what life was like in 1935 and when I was looking for it in 1943 or '44 it didn't exist anymore.10&lt;/quote&gt;
    &lt;p&gt;A chastened Stryker eventually granted veto power to photographers over which of their images would be killed.&lt;/p&gt;
    &lt;p&gt;By the time he took a job at the Pittsburgh Photography Library in the 1950s, Stryker had transitioned to indicating killed negatives by having them pasted onto cards marked with an incongruously cutesy blue star. Sometimes, however, the old temptation for more abrasive methods seemed to take hold — other cards were branded by a special KILL stamp. In still other cases the destroying angel seems to have taken Stryker over completely and caused him to slash across the doomed images in marker.11 Even those pictures that he favored were not immune from these kinds of interventions: squiggles, lines, and written notes instructed his employees to crop and straighten, addenda that sometimes smudged and marred the photo Stryker was trying to perfect.12&lt;/p&gt;
    &lt;p&gt;Most of the negatives Stryker killed, by all accounts, were redundancies nixed in favor of a similar image with stronger composition, clearer focus, and facial expressions better comporting with the themes of suffering and endurance he sought to draw out of the FSA’s subjects. Shot through, these unloved alternates have become almost more interesting than their perfect twins. In contrast to the carefully captioned File images, killed negatives have no names attached, often no notes on provenance: what little we know about them is only by analogy to those photos that were saved, clues about location gleaned from landscapes, clothing, faces. As such, the killed photos demand a more active viewer, one willing to piece together, to parse, to consign some things to the realm of the curious and unknowable.&lt;/p&gt;
    &lt;p&gt;Did Stryker give much thought as to where to put the hole through when he made his killings? These voids obliterate the hand of a little boy in fringed gloves who stares back calmly at his shooter; they slice through the pavement of an unnamed street where a pair of identical twins walks on unawares. They run like a sniper’s bullet through the legs of a man bending over to pick a fruit, whizz past the ear of a cop. A black hole tarnishes the pale lapel of a floppy-bonneted woman as she looks the other way; it hovers over a man’s head like a grim fate narrowly avoided. In one rare example, a vicious flurry of perforations strafes an entire family of Arkansas sharecroppers as the mother tends to her youngest. The void slates houses for destruction, theaters, water pumps, a cotton bale straining at the corset of its ties. It hangs aloft and lightless over a Chocowinity field like a sun negated. The same person is killed and killed again, from one picture to the next. When one views these photos as a series, the holes begin to feel like a vengeful god too terrible to figure. Once capturing social history, these images now seem to conjure that moment just prior to disaster: before the hole shatters the glass, pops the tire, forces the horse to give one final whinny, kick out uselessly, and fall to the earth.&lt;/p&gt;
    &lt;p&gt;Punning on the pinhole history of early photographic technologies like the camera obscura, Roland Barthes used the word punctum (literally, “sting, speck, cut, little hole”) to name the disarming effect of certain images. “A photograph’s punctum”, he wrote, “is that accident which pricks me (but also bruises me, is poignant to me)”.13 In the killed negatives, we find Barthes’ dictum literalized: it is the little hole or holes themselves that arrest our eyes and imagination. The strange contradiction at the heart of the killed negatives — as the very existence of this essay attests — is that in an important sense they weren’t killed: the hole-punched photos remain in the Library of Congress, preserved by Stryker himself, and the Pittsburgh Photography Library images deemed unfit for the archives have instead come to comprise their own separate archive in the same building, a sort of Salon des Refusés. Allen Benson writes that the “entombment” of these images “produces a contradictory effect, a desire to look, to open the killed storage boxes and inspect the remains”.14 When we do look, we find that, whatever the organic center of the original photo’s gravity may be, the void has usurped it and become, suddenly, the focal point. In the subtle but unmistakable way that Stryker’s puncture marks reveal the three-dimensional negative from which each two-dimensional image is printed, they call our attention to the fact that a photograph is a physical object and a fragile one at that. And yet at the same time it’s difficult not to feel a visceral reel as a hole slices through the head of a child, the face of a young mother. Stryker’s rejects present us with a push-pull of mimesis: the scenes become less real even as they become more emotionally immediate.&lt;/p&gt;
    &lt;p&gt;If we wish to examine what images Stryker thought ultimately worthy of keeping, we must also consider the question of what images he thought were worth taking in the first place. Groups like Latinos and Native Americans, for instance, are underrepresented in the File.15 In a 1937 letter to Lange while she was on assignment photographing tenant farmers in Texas, Stryker advised her to “take both black and white, but place the emphasis on the white tenants, since we know that these will receive much wider use”.16 That latter part was indeed borne out by the fact that exhibitions and newspapers more readily selected white images from the File than non-white.17 More broadly, the FSA’s focus on the madonna, the stoic striver, elevated a certain class of “deserving poor” above those who were beyond the bounds both of being photographed and receiving material aid.18 For the government, of course, these two things were tightly interwoven: the purpose of the FSA’s photography program, after all, was to drum up support for the New Deal among an American public that had long viewed poverty as a moral stain. In the course of resettling white tenant farmers in the Mississippi Delta, the FSA forcibly uprooted Black families throughout the region — families whose suffering, it appears, did not rate high enough to make it into the File.19 When I viewed Stryker’s negatives together, they seemed to be posing questions not just about the work of the FSA but about the future of the country they sought to document: both “who should get a farm loan?” and “who cuts a heroic enough figure to advertise them?” Not only “whose grief do we recognize?”, but also “whose grief is deserving of succor?” Who will be kept and who will be killed? Who will survive in America — and what image of this land will these survivors bear into the future?&lt;/p&gt;
    &lt;p&gt;Erica X Eisen’s work has appeared in The Washington Post, The Guardian, The Baffler, n+1, The Boston Review, AGNI, and elsewhere. She received her bachelor’s degree in History of Art &amp;amp; Architecture from Harvard University with a focus on Japanese art and her MA in Buddhist Art History &amp;amp; Conservation from The Courtauld Institute of Art. She is an editor at Hypocrite Reader. Her writing can be found at www.ericaxeisen.com.&lt;/p&gt;
    &lt;p&gt;Enjoyed this piece? We need your help to keep publishing.&lt;/p&gt;
    &lt;p&gt;The PDR is a non-profit project kept alive by reader donations – no ads, no paywalls, just the generosity of our community. It’s a really exciting model, but we need your help to keep it thriving. Visit our support page to become a Friend and receive our themed postcard packs. Or give a one-off donation. Already a supporter? A huge thank you for making all this possible.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://publicdomainreview.org/essay/the-kept-and-the-killed/"/><published>2026-01-24T15:50:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46744647</id><title>Memory layout in Zig with formulas</title><updated>2026-01-24T22:40:53.921168+00:00</updated><content>&lt;doc fingerprint="eaf8dac1609182cb"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Memory Layout in Zig with Formulas&lt;/head&gt;&lt;p&gt;I was recently encouraged to watch A Practical Guide to Applying Data Oriented Design (DoD) by Andrew Kelley, the creator of Zig1. Just 10 minutes into the talk, I was confronted with a skill I had never formally learned… the arithmetic behind memory layout of types.&lt;/p&gt;&lt;p&gt;Throughout the talk, Andrew tested the audience’s ability to compute the alignment and sizes of various types, starting with primitives like &lt;code&gt;u32&lt;/code&gt; and &lt;code&gt;bool&lt;/code&gt;, and ending with some more complex structures involving enums, unions, and more. As far as I can tell, the exact rules for computing the alignment and size of a type in Zig are not made explicit in any documentation, but are understood by those in-the-know.&lt;/p&gt;&lt;p&gt;As a late-comer to low-level programming myself, I thought I’d collect here some formulas &amp;amp; explanations I landed on while wrestling with alignment and sizing in Zig.&lt;/p&gt;&lt;head rend="h2"&gt;Memory Layout Principles&lt;/head&gt;&lt;p&gt;For any piece of data stored in memory on a computer, the data must have some natural alignment and size dimensions according to its type. Intuitively, its size captures how many bytes it would take to specify the information that should be contained in any instance of that type. Whereas, its alignment captures the spacing the compiler must obey when choosing valid addresses at which to place data of this type.&lt;/p&gt;&lt;p&gt;I imagine just about any computer science major would have learned the rules of memory layout according to some kind of C-like compiler. I guess the motivation would go something like: “CPUs fetch data from memory in fixed-size blocks of so-many bytes, and performance degrades when data is misaligned. So, compilers automatically pad and align data types.”&lt;/p&gt;&lt;p&gt;In particular, types that don’t “fill up” all of the space in memory allocated to them will be padded with extra bits/bytes to make up for the difference.&lt;/p&gt;&lt;p&gt;Andrew’s whole message in his DoD talk centered on designing your data types to take up as little space in memory as possible, which includes reducing the size, alignment, and padding required to represent the same information.&lt;/p&gt;&lt;p&gt;Probably, the formulas I propose below apply to similar languages beyond Zig and my machine’s (Apple) ABI, but I make no claims.&lt;/p&gt;&lt;p&gt;The Zig language exposes two builtin functions relevant to our discussion:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;@alignOf(comptime T: type): #bytes required for aligning this type in memory (valid addresses for this type will be multiples of this value);&lt;/item&gt;&lt;item&gt;@sizeOf(comptime T: type): #bytes for storing the type in memory (including padding).&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I’ll use the following function &lt;code&gt;memory_printout&lt;/code&gt; to report these values for any type:&lt;/p&gt;&lt;code&gt;const std = @import("std");

fn memory_printout(T: type) void {
    std.debug.print("@alignOf( {s} ): {d}\t", .{ @typeName(T), @alignOf(T) });
    std.debug.print("@sizeOf( {s} ): {d}\n", .{ @typeName(T), @sizeOf(T) });
}
&lt;/code&gt;&lt;head rend="h2"&gt;Memory Layout Formulas&lt;/head&gt;&lt;p&gt;To start, one helpful invariant is offered in Zig’s documentation. For any type &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt;&lt;head rend="h3"&gt;Primitives&lt;/head&gt;&lt;p&gt;Already, the primitive data types will teach us a good bit about memory layout. Try guessing the results of the following Zig code before looking at the answer:&lt;/p&gt;&lt;code&gt;pub fn main() void {
    const types = [_]type{ bool, c_char, u8, *u8, u16, u17, i32, f64, usize };
    inline for (types) |T| memory_printout(T);
}
&lt;/code&gt;&lt;head&gt;The Output:&lt;/head&gt;&lt;code&gt;@alignOf( bool ): 1       @sizeOf( bool ): 1
@alignOf( c_char ): 1     @sizeOf( c_char ): 1
@alignOf( u8 ): 1         @sizeOf( u8 ): 1
@alignOf( *u8 ): 8        @sizeOf( *u8 ): 8
@alignOf( u16 ): 2        @sizeOf( u16 ): 2
@alignOf( u17 ): 4        @sizeOf( u17 ): 4
@alignOf( i32 ): 4        @sizeOf( i32 ): 4
@alignOf( f64 ): 8        @sizeOf( f64 ): 8
@alignOf( usize ): 8      @sizeOf( usize ): 8
&lt;/code&gt;&lt;p&gt;This suggests the following formula for primitive data types:&lt;/p&gt;\[\texttt{@sizeOf(primitive)} = \texttt{@alignOf(primitive)}.\]&lt;p&gt;Most of these make sense. A &lt;code&gt;c_char&lt;/code&gt; truly requires 8 bits, or 1 byte to specify.&lt;/p&gt;&lt;p&gt;Whereas, a &lt;code&gt;bool&lt;/code&gt; comprises a single bit (information-theoretically). But, alignment and size are measured in whole bytes, so we should round up to the nearest byte (and pad with 7 bits to fill up that byte).&lt;/p&gt;&lt;p&gt;Similarly, any unsigned integer &lt;code&gt;u{b}&lt;/code&gt;, signed integer &lt;code&gt;i{b}&lt;/code&gt;, or floating-point number &lt;code&gt;f{b}&lt;/code&gt; contains $b$ bits of information. So, counting in bytes, we will have to round $b / 8$ up, somehow. But, look at &lt;code&gt;u17&lt;/code&gt;: despite $2 &amp;lt; 17 / 8 \leq 3$, the size of &lt;code&gt;u17&lt;/code&gt; is not 3 bytes. Instead, it’s 4 bytes. In general, alignment and size must be powers-of-2 bytes. This is another desirable property half-dictated by architecture and half-related to the convenience of powers of two. So, we actually always round up to the nearest power-of-2 bytes when converting from bits.&lt;/p&gt;&lt;p&gt;Let’s formalize this conversion from bits to bytes for good:&lt;/p&gt;\[\begin{aligned} \texttt{bytes}(\texttt{bits}) &amp;amp;:= \max\left\{1, 2^{\left\lceil\log_2(\frac{\texttt{bits}}{8}) \right\rceil}\right\}. \end{aligned}\]&lt;p&gt;Another consequence of alignment and size being powers of two is the following, stronger invariant. For any type &lt;code&gt;T&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;That is, the size of the type is always a multiple of its alignment.&lt;/p&gt;&lt;p&gt;Next up, depending on your architecture, &lt;code&gt;usize&lt;/code&gt; will either match &lt;code&gt;u32&lt;/code&gt; or &lt;code&gt;u64&lt;/code&gt;. I’m working on a 64-bit machine, so that’s why we see its size and alignment as 8 bytes. Moreover, any pointer (such as &lt;code&gt;*u8&lt;/code&gt;) represents an address, which is guaranteed by Zig to match &lt;code&gt;usize&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;For primitive data types, remember: their size and align values agree and equal the smallest power-of-2 many bytes required to represent that type in memory.&lt;/p&gt;&lt;head rend="h3"&gt;Structs&lt;/head&gt;&lt;p&gt;In Zig, a &lt;code&gt;struct&lt;/code&gt; combines many fields into a single data type. How does memory layout work when many fields are combined together?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: Zig automatically minimizes the memory footprint of a struct by possibly shuffling around its fields. To force the Zig compiler to respect the order of the fields as we’ve defined them, we may use the&lt;/p&gt;&lt;code&gt;extern&lt;/code&gt;keyword as shown below. Really, this forces the compiler to obey C ABI compatibility.&lt;/quote&gt;&lt;p&gt;First, rest assured that structs add no overhead. That is, if &lt;code&gt;T&lt;/code&gt; is a type, and we define:&lt;/p&gt;&lt;code&gt;const struct_T = struct {
  field: T,
};
&lt;/code&gt;&lt;p&gt;then &lt;code&gt;@alignOf(struct_T) == @alignOf(T)&lt;/code&gt; and &lt;code&gt;@sizeOf(struct_T) == @sizeOf(T)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Now, when a struct envelops two fields, such as&lt;/p&gt;&lt;code&gt;const pair = extern struct {
  a: u8,
  b: u32,
};
&lt;/code&gt;&lt;p&gt;we should consider the meanings of align and size again:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The alignment of the struct &lt;code&gt;pair&lt;/code&gt;should be such that any offset by this alignment value does not break the alignment of its constituent fields&lt;code&gt;a&lt;/code&gt;and&lt;code&gt;b&lt;/code&gt;.&lt;list rend="ul"&gt;&lt;item&gt;Here, field &lt;code&gt;b&lt;/code&gt;has a stricter alignment of 4 bytes, whereas&lt;code&gt;a&lt;/code&gt;permits offsets of 1 byte. So,&lt;code&gt;pair&lt;/code&gt;better also only permit alignments of 4 bytes.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Here, field &lt;/item&gt;&lt;item&gt;The size of the struct &lt;code&gt;pair&lt;/code&gt;is dictated by its alignment. Its memory will necessarily take up a number of bytes which is a multiple of its alignment. To figure out exactly how many, we iterate through the fields in order, trying our best to greedily pack those fields while still respecting their own alignments.&lt;list rend="ul"&gt;&lt;item&gt;Here, the size of &lt;code&gt;a&lt;/code&gt;is just one byte, so it fits into a single memory chunk of size 4 bytes (the alignment of&lt;code&gt;pair&lt;/code&gt;is 4 bytes), with three bytes to spare. Now, we consider the next field:&lt;code&gt;b&lt;/code&gt;. As its alignment is 4 bytes, we can only write&lt;code&gt;b&lt;/code&gt;at an address which is a multiple of its own alignment. The soonest we can accomplish this is by padding three bytes after&lt;code&gt;a&lt;/code&gt;and writing&lt;code&gt;b&lt;/code&gt;at the fourth byte. This already places&lt;code&gt;b&lt;/code&gt;into another 4-byte memory chunk, in which it fits entirely as its size is 4 bytes. So, the total size of&lt;code&gt;pair&lt;/code&gt;is 8 bytes.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Here, the size of &lt;/item&gt;&lt;/list&gt;&lt;p&gt;Now, what do you expect the output of the following Zig code to be?&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(ABAB);
    memory_printout(ABBA);
}

const ABAB = extern struct {
    a1: u8,
    b1: u16,
    a2: u8,
    b2: u16,
};

const ABBA = extern struct {
    a1: u8,
    a2: u8,
    b1: u16,
    b2: u16,
};
&lt;/code&gt;&lt;head&gt;The Answer:&lt;/head&gt;&lt;code&gt;@alignOf( ABAB ): 2      @sizeOf( ABAB ): 8
@alignOf( ABBA ): 2      @sizeOf( ABBA ): 6
&lt;/code&gt;&lt;p&gt;In general, deciding the placement of a struct field follows this rule:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Rule: Each field is placed after the previous field at the next smallest multiple of its own alignment.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;In general, the formula for rounding a number $N$ up to the nearest multiple of some other number $m$ looks like:&lt;/p&gt;\[\texttt{next_mult}(N, m) := \left\lceil \frac{N}{m} \right\rceil \cdot m.\\\]&lt;p&gt;Given this, try to follow the next example. We make use of another Zig builtin &lt;code&gt;@offsetOf(&amp;lt;type&amp;gt;, &amp;lt;field_name&amp;gt;)&lt;/code&gt; to display exactly where each field is placed in memory relative to the beginning address of &lt;code&gt;S&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;fn printOffset(T: type, comptime f: [:0]const u8) void {
    std.debug.print("@offsetOf( {s} ) = {d}\n", .{ f, @offsetOf(T, f) });
}

pub fn main() void {
  memory_printout(S);
  printOffset(S, "a");
  printOffset(S, "b");
  printOffset(S, "c");
}

const S = extern struct {
    // align = size = 2
    a: u16,
    // align = 2, size = 6
    b: extern struct { b1: u16, b2: u16, b3: u16 },
    // align = size = 4
    c: u32,
};
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( S ): 4        @sizeOf( S ): 12
@offsetOf( a ) = 0
@offsetOf( b ) = 2
@offsetOf( c ) = 8
&lt;/code&gt;&lt;p&gt;In general, alignment for structs is quite simple to formulate:&lt;/p&gt;\[\texttt{@alignOf(struct)} := \max_{\texttt{fields}} \texttt{@alignOf(field)}.\]&lt;p&gt;In contrast, the size of the (externed) struct is more complicated: $\texttt{@sizeOf(struct)}$ is the smallest multiple of $\texttt{@alignOf(struct)}$ many bytes required to fit the fields of a struct (in order) such that:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;No two fields overlap in memory, and&lt;/item&gt;&lt;item&gt;Each field lies at an address which is a multiple of its own alignment: $\texttt{@alignOf(field)}$.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Without the &lt;code&gt;extern&lt;/code&gt; keyword, Zig minimizes the size of the struct under all permutations of its fields. Zig also offers &lt;code&gt;packed struct&lt;/code&gt;, which eliminates padding entirely and lays out fields in strict bit-order. While this can reduce memory usage further, it comes with performance trade-offs and restrictions on field access.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Bonus question: Try to explain why the choice to make alignments and sizes be powers of two is vital for these rules to be well-defined for assessing the alignment and size of structs.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;Enums&lt;/head&gt;&lt;p&gt;Under the hood, an enum works on indices, not labels. So, the alignment and size of an enum will equal the minimal number of bytes to express the type of its indices. Suppose &lt;code&gt;T = enum (u{b}) { ... }&lt;/code&gt; is an arbitrary enum indexed by unsigned integers of type &lt;code&gt;u{b}&lt;/code&gt;, where &lt;code&gt;b&lt;/code&gt; is measured in bits.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: we may use the Zig standard library to access the number of options in the enum as follows:&lt;/p&gt;&lt;code&gt;std.meta.fields(T).len&lt;/code&gt;. I’ll call this $\texttt{T.len}$, below.&lt;/quote&gt;&lt;quote&gt;&lt;p&gt;Note: By default, Zig’s compiler assigns indices starting at zero and counting up by one. So, by default, Zig sets&lt;/p&gt;&lt;code&gt;b&lt;/code&gt;to $\lceil \log_2 (\texttt{T.len}) \rceil$.&lt;/quote&gt;&lt;p&gt;Then,&lt;/p&gt;\[\begin{aligned} \texttt{@alignOf(enum(u{b}))} &amp;amp;= \texttt{@alignOf(u{b})} = \texttt{bytes}(\texttt{b}),\\ \texttt{@sizeOf(enum(u{b}))} &amp;amp;= \texttt{@sizeOf(u{b})} = \texttt{bytes}(\texttt{b}). \end{aligned}\]&lt;p&gt;We’ve made use of the $\texttt{bytes}$ function, again2.&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;const T_default = enum { a, b, c, d, e };
const T_long = enum(u64) { a, b, c, d, e };

memory_printout(T_default);
memory_printout(T_long);
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( T_default ): 1    @sizeOf( T_default ): 1
@alignOf( T_long ): 8       @sizeOf( T_long ): 8
&lt;/code&gt;&lt;head rend="h3"&gt;Arrays and Slices&lt;/head&gt;&lt;p&gt;For an array in Zig, its alignment inherits from that of its elements, and its size is just length$\times$size of the type:&lt;/p&gt;\[\begin{aligned} \texttt{@alignOf([N]T)} &amp;amp;= \texttt{@alignOf(T)},\\ \texttt{@sizeOf([N]T)} &amp;amp;= \texttt{N} \cdot \texttt{@sizeOf(T)}. \end{aligned}\]&lt;p&gt;In contrast, a slice in Zig is just a special case of a struct which contains one pointer (&lt;code&gt;usize&lt;/code&gt;) and a length (&lt;code&gt;usize&lt;/code&gt;). So,&lt;/p&gt;&lt;p&gt;Example (using another builtin &lt;code&gt;@TypeOf&lt;/code&gt;):&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(@TypeOf(digits_array));
    memory_printout(@TypeOf(digits_slice));
}

const digits_array = [10]u8{ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 };
const digits_slice: []const u8 = digits_array[0..]; 
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( [10]u8 ): 1         @sizeOf( [10]u8 ): 10
@alignOf( []const u8 ): 8     @sizeOf( []const u8 ): 16
&lt;/code&gt;&lt;head rend="h3"&gt;(Untagged) Unions&lt;/head&gt;&lt;p&gt;An untagged, bare union in Zig (accomplished with the &lt;code&gt;extern&lt;/code&gt; keyword) essentially acts as a switch statement over a number of mutually-exclusive options of various types without the ability to report which option is active. To express a bare union type in memory, we just need enough memory to store the largest option(s).&lt;/p&gt;&lt;p&gt;However, untagged unions in Zig without the &lt;code&gt;extern&lt;/code&gt; keyword seem to require extra memory, essentially one more alignment’s worth. So, untagged unions should satisfy:&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(U_bare);
    memory_printout(U);
}

const U_bare = extern union {
    a: i64,
    b: extern struct { c: i64, d: i64, e: i64 },
};

const U = union {
    a: i64,
    b: struct { c: i64, d: i64, e: i64 },
};
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( U_bare ): 8   @sizeOf( U_bare ): 24
@alignOf( U ): 8        @sizeOf( U ): 32
&lt;/code&gt;&lt;head rend="h3"&gt;Tagged Unions&lt;/head&gt;&lt;p&gt;Tagged unions are unions which use an additional enum to detect which field is active in the union. Alignment for a tagged union must additionally consider the alignment of the tag too, while the size must treat the tag and fields together.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: there are no “bare” tagged unions. So, the&lt;/p&gt;&lt;code&gt;extern&lt;/code&gt;keyword doesn’t work on tagged unions.&lt;/quote&gt;&lt;p&gt;Suppose &lt;code&gt;U(E)&lt;/code&gt; is of type &lt;code&gt;union(enum)&lt;/code&gt;. Then, we can compute the alignment and size of this type depending on those of its union and enum components:&lt;/p&gt;&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;pub fn main() void {
    memory_printout(UE);
    memory_printout(UF);
    memory_printout(UG);
}

const E = enum { a, b };
const F = enum(u64) { a, b };
const G = enum(u128) { a, b };

const UE = union(E) {
    a: i64, b: struct { c: i64, d: i64 }
};
const UF = union(F) {
    a: i64, b: struct { c: i64, d: i64 }
};
const UG = union(G) {
    a: i64, b: struct { c: i64, d: i64 }
};
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( UE ): 8       @sizeOf( UE ): 24
@alignOf( UF ): 8       @sizeOf( UF ): 24
@alignOf( UG ): 16      @sizeOf( UG ): 32
&lt;/code&gt;&lt;head rend="h3"&gt;ArrayLists and MultiArrayLists&lt;/head&gt;&lt;p&gt;An &lt;code&gt;ArrayList(T)&lt;/code&gt; in Zig is the standard library’s dynamic array implementation. This is comparable to the notions of a “vector” in C++ or a “list” in Python, otherwise understood as the Array of Structs (AoS) memory layout. Elements of type &lt;code&gt;T&lt;/code&gt; are stored contiguously in memory each with their full size and padding.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;ArrayList(T)&lt;/code&gt; type itself is a struct containing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;items&lt;/code&gt;: a slice&lt;code&gt;[]T&lt;/code&gt;, and&lt;/item&gt;&lt;item&gt;&lt;code&gt;capacity&lt;/code&gt;: a&lt;code&gt;usize&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;So, the &lt;code&gt;ArrayList(T)&lt;/code&gt; type has a fixed memory footprint:&lt;/p&gt;&lt;p&gt;However, the data that the ArrayList manages lives on the heap. When iterating over an ArrayList, you traverse memory in strides of $\texttt{@sizeOf(T)}$ bytes. The memory consumed by the backing buffer is simply:&lt;/p&gt;\[\begin{aligned} \texttt{buffer_alignment} &amp;amp;= \texttt{@alignOf(T)},\\ \texttt{buffer_size} &amp;amp;= \texttt{buffer.capacity} \cdot \texttt{@sizeOf(T)}. \end{aligned}\]&lt;p&gt;In contrast, a &lt;code&gt;MultiArrayList(T)&lt;/code&gt; in Zig follows the Struct of Arrays (SoA) memory layout. Instead of storing complete &lt;code&gt;T&lt;/code&gt; instances contiguously, it stores each field of &lt;code&gt;T&lt;/code&gt; in its own separate, tightly-packed array.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;MultiArrayList(T)&lt;/code&gt; type itself is a struct containing:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;ptr&lt;/code&gt;: a single pointer to the backing buffer,&lt;/item&gt;&lt;item&gt;&lt;code&gt;len&lt;/code&gt;: a&lt;code&gt;usize&lt;/code&gt;,&lt;/item&gt;&lt;item&gt;&lt;code&gt;capacity&lt;/code&gt;: a&lt;code&gt;usize&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;So:&lt;/p&gt;\[\begin{aligned} \texttt{@alignOf(MultiArrayList(T))} &amp;amp;= \texttt{@alignOf(usize)} = 8 \text{ bytes (on 64-bit)},\\ \texttt{@sizeOf(MultiArrayList(T))} &amp;amp;= 3 \cdot \texttt{@sizeOf(usize)} = 24 \text{ bytes (on 64-bit)}. \end{aligned}\]&lt;p&gt;The backing buffer stores all field arrays contiguously. Padding between fields is not needed; instead, each field array is packed according to the field’s alignment. Summing over the fields of $T$, the total buffer size would thus be:&lt;/p&gt;\[\texttt{buffer_size} = \texttt{buffer.capacity} \cdot \sum_{\texttt{fields}} \texttt{@sizeOf}(\texttt{field}).\]&lt;p&gt;Example:&lt;/p&gt;&lt;code&gt;const std = @import("std");
const ArrayList = std.ArrayList;
const MultiArrayList = std.MultiArrayList;

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    const allocator = gpa.allocator();

    const T = struct { a: u8, b: u16 };

    var list: ArrayList(T) = .{};
    defer list.deinit(allocator);

    var multiList: MultiArrayList(T) = .{};
    defer multiList.deinit(allocator);

    for (0..10_000) |_| {
        try list.append(allocator, .{ .a = 0, .b = 1 });
        try multiList.append(allocator, .{ .a = 0, .b = 1 });
    }

    memory_printout(T);
    memory_printout(ArrayList(T));
    memory_printout(MultiArrayList(T));
    std.debug.print("list capacity: {d}\n", .{list.capacity});
    std.debug.print("list buffer size: {d}\n", .{list.capacity * @sizeOf(T)});
    std.debug.print("multiList capacity: {d}\n", .{multiList.capacity});
    std.debug.print("multiList buffer size: {d}\n", .{multiList.capacity * (@sizeOf(@FieldType(T, "a")) + @sizeOf(@FieldType(T, "b")))});
}
&lt;/code&gt;&lt;head&gt;Output:&lt;/head&gt;&lt;code&gt;@alignOf( T ): 2                  @sizeOf( T ): 4
@alignOf( ArrayList(T) ): 8       @sizeOf( ArrayList(T) ): 24
@alignOf( MultiArrayList(T) ): 8  @sizeOf( MultiArrayList(T) ): 24
list capacity: 12854
list buffer size: 51416
multiList capacity: 11150
multiList buffer size: 33450
&lt;/code&gt;&lt;head rend="h2"&gt;Battle Testing&lt;/head&gt;&lt;p&gt;Let’s test our formulas against the video that inspired this post: Andrew Kelley’s talk on DoD.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note: In order to get these examples to actually compile and execute in Zig (0.16.0), I had to throw in some allocators and extra helper methods.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;ArrayList of Monsters (19:05)&lt;/head&gt;&lt;code&gt;const Monster = struct {
  anim: *Animation, 
  kind: Kind,

  const Kind = enum { snake, bat, wolf, dingo, human };
};

var monsters: ArrayList(Monster) = .{};
var i: usize = 0;
while (i &amp;lt; 10_000) : (i += 1) {
  try monsters.append(.{
    .anim = getAnimation(),
    .kind = rng.enumValue(Monster.Kind),
  });
}
&lt;/code&gt;&lt;head&gt;Actual Memory Use:&lt;/head&gt;&lt;code&gt;Monster size: 16 bytes 
ArrayList(Monster) size: 24 bytes
monsters size: 160_000 bytes        // Total memory size of 10_000 monsters
&lt;/code&gt;&lt;p&gt;Do our formulas agree?&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;code&gt;Monster&lt;/code&gt;Struct:&lt;list rend="ul"&gt;&lt;item&gt;The fields of &lt;code&gt;Monster&lt;/code&gt;satisfy $\texttt{@alignOf(anim)} = 8$ and $\texttt{@alignOf(kind)} = 1$. So, we expect the alignment of the struct to be $\texttt{@alignOf(Monster)} = 8$.&lt;/item&gt;&lt;item&gt;No matter the ordering, it takes two memory chunks of size 8 bytes to fit these fields (since $\texttt{@sizeOf(anim)} = 8$ and $\texttt{@sizeOf(kind)} = 1$). So, we expect $\texttt{@sizeOf(Monster)} = 16$, exactly as we observed.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The fields of &lt;/item&gt;&lt;item&gt;ArrayList(Monster) Type: as a type, it takes a bit of overhead to specify &lt;code&gt;ArrayList(Monster)&lt;/code&gt;, since an ArrayList is really a slice&lt;code&gt;[]Monster&lt;/code&gt;plus a capacity (&lt;code&gt;usize&lt;/code&gt;). On my 64-bit machine, that adds up to 24 bytes of memory.&lt;/item&gt;&lt;item&gt;&lt;code&gt;monsters&lt;/code&gt;ArrayList: remember, ArrayLists act like “arrays of structs”.&lt;list rend="ul"&gt;&lt;item&gt;The natural size and alignment of the &lt;code&gt;Monster&lt;/code&gt;struct dictate the layout of the&lt;code&gt;monsters&lt;/code&gt;ArrayList.&lt;/item&gt;&lt;item&gt;The size of an ArrayList in memory should equal its length times the size of each &lt;code&gt;Monster&lt;/code&gt;element type. So, we expect&lt;code&gt;monsters&lt;/code&gt;to take up $10,000 \times \texttt{@sizeOf(Monster)} = 160,000$ bytes, as observed.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;The natural size and alignment of the &lt;/item&gt;&lt;/list&gt;&lt;p&gt;Footnotes&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;Zig is a modern, C-like programming language which offers a safer, more memory-explicit experience for systems programming, without sacrificing low-level control or C interoperability. Notably, Zig makes it straightforward to manage memory allocation by treating allocators as first-class values rather than hidden globals. Instead of relying on an implicit runtime or a process-wide allocator, you pass explicit allocator objects into the code that needs them. This makes ownership and lifetimes much clearer, encourages you to design APIs around who is responsible for allocating and freeing memory, and makes it easy to swap in custom allocation strategies (e.g., arenas, scratch, tracking, etc.). ↩&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Recall: $\displaystyle \texttt{bytes}(\texttt{bits}) := \max(1, 2^{\lceil\log_2(\frac{\texttt{bits}}{8})\rceil})$ whenever $\texttt{bits} &amp;gt; 0$. Otherwise, $\texttt{bytes}(0) = 0$. ↩&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://raymondtana.github.io/math/programming/2026/01/23/zig-alignment-and-sizing.html"/><published>2026-01-24T15:57:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46744807</id><title>Ask HN: Gmail spam filtering suddenly marking everything as spam?</title><updated>2026-01-24T22:40:53.319084+00:00</updated><content>&lt;doc fingerprint="7ffa01131f22baed"&gt;
  &lt;main&gt;
    &lt;p&gt;Almost all transactional emails are being marked as suspicious even when their SPF/DKIM records are fine and they’ve been whitelisted before. Did Google break something in gmail/spam filtering?&lt;/p&gt;
    &lt;p&gt;Briefly, this morning, I had the opposite effect happen to my Gmail inbox in which things that would normally land in the social and updates folders ended up in my primary folder. I don't know which I'd be more freaked out by: a broken Gmail spam filter or 18 inches of snow.&lt;/p&gt;
    &lt;p&gt;It's a great reminder of how good this feature is that we take for granted. I think this outage has actually improved my appreciation for Gmail (a service I normally only complain about).&lt;/p&gt;
    &lt;p&gt;Seriously. I didn't even realize this was a wide issue, but I couldn't find a school enrolment email I was looking for this morning, and found it in the spam folder. The fact that I basically never have to do this is actually amazing.&lt;/p&gt;
    &lt;p&gt;Today gmail labelled an email coming from google search console as potentially dangerous, however it was because it couldn't properly do spam filtering on the email.&lt;/p&gt;
    &lt;p&gt;Thank goodness. My Gmail address is my first name so I typically get many hundreds of spam’s a day which are almost all caught. Dozens on my inbox today so I figured something was up. Glad it’s not that they’ve suddenly gotten clever.&lt;/p&gt;
    &lt;p&gt;Google just let through an email spoofed from my own domain (via a mailgun server). It was a phishing attack about the domain being shut down. The connection between the domain name and my personal email address have never been published. Either google or Squarespace leaked the info.&lt;/p&gt;
    &lt;p&gt;This has been “down” for me for a few months now, ever since Google tied this functionality to the same toggle that opts you in for using your email data for AI training. So now you can’t filter this stuff without also agreeing to a whole swath of unrelated and opt-ins.&lt;/p&gt;
    &lt;p&gt;Ive since gone on an unsubscribe campaign, and things seem bearable now.&lt;/p&gt;
    &lt;p&gt;Yes, my Gmail inbox is full of regular senders being flagged as "possibly unsafe" and I need to click a button "Looks Safe" to accept them. They are not being spamboxed, but they are definitely flagged. Even official communications from the USPS!&lt;/p&gt;
    &lt;p&gt;The reason given is that "Gmail hasn't scanned this message", so I suppose the scanners are unavailable/disabled for the time being.&lt;/p&gt;
    &lt;p&gt;They should also be tagged as "Important" but they are not. I believe this is a heuristic-based designation, and it has not been working too great lately. My most important mail is coming through as "unimportant".&lt;/p&gt;
    &lt;p&gt;They are not being marked as "Suspicious" but they are showing an infobox that explains they could not be scanned at all.&lt;/p&gt;
    &lt;p&gt;You could click "Seems Safe" on these messages, but they are not scanned by Google, and they are simply adding a disclaimer that they currently can't vouch for the safety of a message that they couldn't scan. It seems to me that this is a prudent and helpful course of action.&lt;/p&gt;
    &lt;p&gt;Same here. Until recently I would get maybe 1-2 spams a month, and I just got 30 in the span of a few days.&lt;/p&gt;
    &lt;p&gt;They’re the very obvious, very obnoxious kind of spam, and Gmail still correctly sends them to the junk bin, so I wonder if they were shadowbanned before and Google simply decided to make the process more explicit (which I don’t hate on principle).&lt;/p&gt;
    &lt;p&gt;Either that or my address was scrapped from somewhere by a spam bot and the timing is coincidental.&lt;/p&gt;
    &lt;p&gt;I see nothing amiss on my oldest Gmail account. But then, I get probably &amp;lt;1 spam email a day on average, and even less legitimate mail, and even less that isn't an automatic notification of something or other that's already filtered and categorized by sender.&lt;/p&gt;
    &lt;p&gt;I have been receiving a large number of spam emails in my "Important and Unread" areas which is anomalous. I was wondering exactly why and this helps. thanks!&lt;/p&gt;
    &lt;p&gt;I have an absurd and overwrought system involving Gmail, and client-side rspamd and SpamSieve on my Mac. Gmail is (was?) overly aggressive flagging things as spam, so I have the client-side Bayesian filter check Gmail’s spam folder and rescue good email, so long as rspamd also says it’s not phishing. And then add sender to a Gmail whitelisting rule. All rescued email is flagged such that if I later manually move any of it back to junk, it stays there as spam and updates the corpus.&lt;/p&gt;
    &lt;p&gt;I now never get good email in the spam folder, and never get undetected spam in the inbox, and very occasionally get a spam erroneously rescued, but still visually flagged as iffy-but-maybe-ham.&lt;/p&gt;
    &lt;p&gt;If Gmail has been lax at filtering spam lately, I haven’t noticed, but perhaps the Bayesian filter has been picking up the slack.&lt;/p&gt;
    &lt;p&gt;I should consider this - I run my own domains, and for years I just forwarded it to gmail, but I had so many cases when mails were put into spam, even replies to emails I had sent in the middle of a long conversation between myself and 1 other person, that I went to just self-hosted IMAP. Then for years I couldn't reliably send to google or yahoo or MS; I added SPF a while ago which help, but recently buckled down and put in SRS and DMARC and DKIM (and rspamd while I was at it); now I get the mail I want, and can mostly send mail without it being rejected (still have to ask people to check spam, but anyways many people I have to tell them I'm emailing them anyways if its important). However I have a lot of non-spam "promotion" emails that I don't want to see. If I could train gmail to not block legit stuff reliably, that would be worth trying again (I would say except for the privacy implications, but since so much email involves gmail on one side or the other, they probably get most of it anyways).&lt;/p&gt;
    &lt;p&gt;Step zero. Never disclose your email address to anyone.&lt;/p&gt;
    &lt;p&gt;This is very easy and straightforward. I operate 6 Gmail accounts, and three are "alts" where I've basically never given the address out to anyone at all, and they receive zero spam, zero UCE, zero marketing emails.&lt;/p&gt;
    &lt;p&gt;Of course, on my "main" I've disclosed the address to many entities and I use it for sign-in and shipping and many things. And yes, I do receive spam and scam emails there, but wcyd?&lt;/p&gt;
    &lt;p&gt;I recently had a "role" Google account terminated because I was (paraphrasing) "violating Google policies" by having multiple accounts. I didn't know they were sticklers about that.&lt;/p&gt;
    &lt;p&gt;(I don't much care because the account was just used for interacting with somebody else's Google-hosted junk but, if I had been using it for something serious, I have probably been frustrated.)&lt;/p&gt;
    &lt;p&gt;There is no way, no possible way that Google prohibits the use of multiple accounts. They do not. They cannot. I just asked Gemini and I checked the actual TOS. It does not, in any way, prohibit these uses.&lt;/p&gt;
    &lt;p&gt;In fact, this is plainly evident by the way they give you tools to operate them in a systematic way. You can add multiple accounts to a single Android "user". You can add them to a single Google Chromebook account under one signed-in account. You can add multiple accounts separately to the same Chromebook.&lt;/p&gt;
    &lt;p&gt;You can add multiple accounts with the same names, the same birthdates, and the same Driver License. I've validated at least two YouTube channels by showing exactly the same ID.&lt;/p&gt;
    &lt;p&gt;Google did not terminate your account for the reason you state. You are not telling us all the background information.&lt;/p&gt;
    &lt;p&gt;Google may indeed terminate multiple accounts for the same person because of TOS violations. They will definitely link and associate your accounts, so making an "alt account" for misbehavior is not safe. If my "alt account" is compromised or violates TOS, then I can expect they will discipline all 6 equally, because they're all linked.&lt;/p&gt;
    &lt;p&gt;But operating multiple accounts is very explicitly supported by Google, and by Microsoft as well, I will say. I don't know about Apple. Facebook definitely prohibited this in the past, although you can maintain multiple "profiles" and "pages" that have unique settings and personalities.&lt;/p&gt;
    &lt;p&gt;I feel like an easier solution to having six different email addresses is to use Gmail aliases - I've caught a few less-than-honest companies either selling my email address, or been breached without disclosing such, simply by using an alias along the lines of '+service_name'. If any alias starts to receive spam you can setup rules to automatically delete everything that comes in with that. You also get the added benefit of significantly easier and more accurate search.&lt;/p&gt;
    &lt;p&gt;I don't think y'all understand why I have separate Google accounts.&lt;/p&gt;
    &lt;p&gt;I use them for different purposes. They are "role accounts" for projects I am doing, such as geneaology and astronomy.&lt;/p&gt;
    &lt;p&gt;In order to use YouTube sanely, and store different stuff in Drive, I separate them into unique accounts. I use those accounts for specific things, and my YouTube subscriptions, playlists, etc. are tailored for each role, for example.&lt;/p&gt;
    &lt;p&gt;This is not about email at all. Obviously, I can access all those email accounts through the one app on my smartphone or the one PWA on my Chromebook. They are easily manageable but separate.&lt;/p&gt;
    &lt;p&gt;I also run 3 Outlook/Microsoft accounts, and for the same reason. (One of them is my academic account from community college, and the other two are personal.)&lt;/p&gt;
    &lt;p&gt;I don't need to give out email addresses for the "role accounts" except where I "Sign In With Google" to various services. So I don't really send/receive email from them at all, except where I'm sharing links or documents with myself (the best way to do this cross-account is still by using email, oftentimes.)&lt;/p&gt;
    &lt;p&gt;Well, spam is no big deal, and any scam that comes via email should not affect anyone who is educated and prepared for them.&lt;/p&gt;
    &lt;p&gt;Of course, with a well-known email address, you could run a higher risk of credential stuffing, and an account takeover by someone who hijacks your email account, and then pivots from there to taking other accounts.&lt;/p&gt;
    &lt;p&gt;But this seems to be a risk we all take: email addresses are meant to be shared, to be public, and to be well-known to anyone to correspond with us.&lt;/p&gt;
    &lt;p&gt;I will say that disclosing my email address to certain parties has had noticeable effects. For example, I used "MYADDRESS+Echovita@gmail.com" once, and only once. My godfather had passed away, and I ordered some flowers for his funeral. And I put that order through with that email address.&lt;/p&gt;
    &lt;p&gt;Well, Echovita themselves had a data breach shortly afterwards, and I was inundated with scam emails. Just all sorts of attackers and they were basically all using the same M.O. But they were readily identifiable because I had used that "+Echovita" to identify it uniquely. And they really haven't stopped coming in. It's been 5 years since that breach.&lt;/p&gt;
    &lt;p&gt;So yes, especially with untrusted parties, it may help to tag your email address. I don't worry about receiving spam anywhere. But like I said, since I've never ever disclosed the addresses of 2-3 of my "alt accounts" they simply never receive any mail at all, spam or no spam.&lt;/p&gt;
    &lt;p&gt;Multiple accounts as others have said. The most powerful is to switch to a provider that permits custom domains and allows you to construct topic specific wildcard addresses on the fly. These can't be flagged as invalid or stripped like Google '+' suffixes and when compromised, you can filter them into oblivion and move on to something else. You also get the bonus of having the entire namespace to yourself and can select short addresses.&lt;/p&gt;
    &lt;p&gt;I use Gmail since the beta (I got invite from a googler) and I don't remember when they began adding spam control but in my experience the GMail spam check works usually exceptionally well: I very rarely need to add a custom filter.&lt;/p&gt;
    &lt;p&gt;My email, over two decades+ (2004?), hasn't been in a many public leaks (only one on https://haveibeenpwned.com/ ) but obviously has made its way to various spammy actors but thankfully nearly everything is caught by GMail's spam filter.&lt;/p&gt;
    &lt;p&gt;If anything I'd say GMail's spam filter works too well: I get more legit emails in my spam folder than spam in my regular inbox. As in: one in a rare while vs about zero spam in my regular inbox.&lt;/p&gt;
    &lt;p&gt;There's your confirmation, then. It must be either a localized failure to some subgroup of users, or triggered by some combination of settings, if some people are seeing it and others are not.&lt;/p&gt;
    &lt;p&gt;It's been happening for about a month for me. I had to start monitoring spam because legit emails end up there. Funnily enough I started having the opposite problem too - plenty of obvious spam and phishing attempt ending up in my mailbox.&lt;/p&gt;
    &lt;p&gt;I have seen a spam button show up I haven't seen in a long time.&lt;/p&gt;
    &lt;p&gt;It might be a new round of AI training featuring the labour of customers as free employees doing training. Every time we click, we consent to sharing private email data.&lt;/p&gt;
    &lt;p&gt;Its really slow. Too slow to use 2FA or in some cases, verify email addresses or recover passwords.&lt;/p&gt;
    &lt;p&gt;Most people can't handle a notification on their watch every minute, or several spam every five minutes, so "large numbers of people" are shutting off notifications on their phones. And human nature being what it is, they're not going to be turned back on again. So the era of getting a notification when you get an email is coming to a close. "Important Immediate Attention Stuff" moved to text messages a long time ago anyway, at least for me. The list of technologies you can no longer reach me on, always increases over time...&lt;/p&gt;
    &lt;p&gt;I don't understand why spam detection is so complicated. I can tell with high accuracy if an email is spam just by the subject line. I'd think even basic ML could do this very reliably you don't need a bleeding-edge LLM to do this.&lt;/p&gt;
    &lt;p&gt;Phishing is tricker because it can be very deceptive especially if you're being targeted specifically. But also usually pretty obvious.&lt;/p&gt;
    &lt;p&gt;* Are you available? * Paul, can we have a zoom meeting with you on Monday? * Assistance for donation * Greetings!!! * some ideas for you * Refund request * Somethings not working * Manuel Montoya for roof work contractor * proposals for print * Invite Connection&lt;/p&gt;
    &lt;p&gt;Half of the above are actual spam, half are not. Tell me which is which ...&lt;/p&gt;
    &lt;p&gt;This only applies to spam which requires significant follow-up effort from the spammer to respond to potential victims; effectively just 419 "advance-fee" fraud scams.&lt;/p&gt;
    &lt;p&gt;For spam which only does not require manual effort on the other side, there is no reason to filter out potential victims and all the more reason to make it look as legit as possible to maximize conversion rates.&lt;/p&gt;
    &lt;p&gt;&amp;gt; For spam which only does not require manual effort on the other side, there is no reason to filter out potential victims and all the more reason to make it look as legit as possible to maximize conversion rates.&lt;/p&gt;
    &lt;p&gt;Unless there's a trade-off. Saying "respond now or your account will be erased!" doesn't sound very legit. But the number of additional victims the phisher gets by doing probably outweighs the number of more sophisticated victims he loses.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=46744807"/><published>2026-01-24T16:16:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46745224</id><title>Metriport (YC S22) is hiring a security eng to harden healthcare data infra</title><updated>2026-01-24T22:40:52.774740+00:00</updated><content>&lt;doc fingerprint="47704651dcb5720e"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Metriport is an open-source data intelligence platform that helps healthcare organizations access and exchange patient data in real-time. We integrate with all major US healthcare IT systems and tap into comprehensive medical data for 300+ million individuals.&lt;/p&gt;
      &lt;p&gt;We've found product-market fit with multi-million ARR, 100+ customers (including Strive Health, Circle Medical, and Brightside Health), backing from top VCs, and years of runway. We're ready to scale. We're a tight-knit, high-performing team of mostly former founders (including two YC alumni). We're engineering-heavy, operate with minimal bureaucracy and high autonomy, and hire based on competence, not prestige. We push hard—founders work six days a week from our SF office—but give everyone freedom to craft their schedule. We measure output and we're committed to sustainable intensity.&lt;/p&gt;
      &lt;head rend="h2"&gt;About us&lt;/head&gt;
      &lt;p&gt;The following points are an assortment of the most relevant bits that will give you the gist of where we’re at, why we’ll win, and our company culture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Well funded with a massive recent infusion of capital, found PMF, multi-million ARR, 80+ customers (including Strive Health, Circle Medical, and Brightside Health), funded by top VCs and angels, have years of runway - and we’re just getting started.&lt;/item&gt;
        &lt;item&gt;We’re a tight-knit, high performing, and passionate team - we work with a consistent intensity and have become a leader in our industry with a fraction of the resources of our competitors.&lt;/item&gt;
        &lt;item&gt;Consistency means we push as hard as humanly possible, while keeping our health and personal lives in check.&lt;/item&gt;
        &lt;item&gt;Meaningful work is what gets us out of bed, and we just wouldn’t be satisfied by building yet another CRM company.&lt;/item&gt;
        &lt;item&gt;By pedigree, we’re a group of underdogs - we don’t hire based on prestige, but on demonstrated competence and perceived potential.&lt;/item&gt;
        &lt;item&gt;We’re engineering heavy, and most of our engineers are former founders (including 2 ex-YC founders).&lt;/item&gt;
        &lt;item&gt;We operate as a relatively flat structure with little red tape, forced structure, or bureaucracy. We just opt to get shit done and foster a collaborative environment with high autonomy - our GitHub commit history and product velocity is a testament to this.&lt;/item&gt;
        &lt;item&gt;The founders set the pace by working 6 days a week in our SF office, but everyone is given full freedom to craft a schedule that’s best for both the team and themselves - team output is measured.&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;&lt;lb/&gt; About you&lt;/p&gt;
      &lt;p&gt;In a nutshell, we're looking for a security engineer with the following specific qualities:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You’re entrepreneurial-minded, with an olympian-level work ethic (nearly our entire engineering team consists of former founders).&lt;/item&gt;
        &lt;item&gt;You are passionate about security and are excited to own security related projects within the company end-to-end.&lt;/item&gt;
        &lt;item&gt;You are confident in your ability to build scalable systems across the full stack, and people usually come to you for technical guidance.&lt;/item&gt;
        &lt;item&gt;You believe you can solve any problem that comes at you, and don't shy away from diving deep into areas where you may lack domain expertise.&lt;/item&gt;
        &lt;item&gt;You have a strong sense of ownership over your work, and have demonstrated ability to lead others.&lt;/item&gt;
        &lt;item&gt;You know how to move fast - while still maintaining a strong security posture.&lt;/item&gt;
        &lt;item&gt;You care more about the end result and delivering value, rather than what new and frilly tech is being used under the hood for a given feature.&lt;/item&gt;
        &lt;item&gt;When someone scopes out a project with an ETA of 3 weeks, you ask yourself "why can't it be done in 3 days?".&lt;/item&gt;
        &lt;item&gt;You’re a hacker at heart, and have a good sense of what rules should, and shouldn’t, be broken.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;What you'll be doing&lt;/head&gt;
      &lt;p&gt;After quickly ramping up using our comprehensive onboarding materials to get familiar with our domain, product, and codebase, the goal would be to get you shipping product directly to customers as quickly as possible. Specifically, day to day, this looks like:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Evangelizing security across Metriport’s growing team - we will look to you for guidance, and training.&lt;/item&gt;
        &lt;item&gt;Driving full-stack security projects , big and small, end-to-end from ideation to production rollout.These projects could include things like: &lt;list rend="ul"&gt;&lt;item&gt;Implement an enterprise-grade audit logging solution for a new national healthcare network infrastructure stack.&lt;/item&gt;&lt;item&gt;Implement fine grained RBAC on the API key access layer, and more robust roles on our UIs.&lt;/item&gt;&lt;item&gt;Help us revamp our internal security policies and put tools in place to keep the platform, and employees, secure while still allowing the team to be efficient.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Helping the engineering team with PR reviews with a security-focused lens.&lt;/item&gt;
        &lt;item&gt;Work with the Go to Market team to complete customer security assessments and questionnaires.&lt;/item&gt;
        &lt;item&gt;Work with the engineering team to harden security across the development lifecycle - think secret management, access controls, and vulnerability scanning.&lt;/item&gt;
        &lt;item&gt;Managing your own work in Linear.&lt;/item&gt;
        &lt;item&gt;Participating in bi-weekly sprint planning / retro sessions, and quarterly planning sessions.&lt;/item&gt;
        &lt;item&gt;Attending a daily 30 minute remote stand-up at 7:30am PST Mon-Fri (our only regular mandatory meeting).&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;&lt;lb/&gt; Requirements&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You have 6+ years experience in security engineering and information security.&lt;/item&gt;
        &lt;item&gt;You’re located in San Francisco or the Bay Area (or willing to relocate).&lt;/item&gt;
        &lt;item&gt;Familiar with HIPAA compliant environments.&lt;/item&gt;
        &lt;item&gt;Experience rolling out and maintaining security frameworks like SOC 2, NIST, HITRUST, FedRAMP, etc.&lt;/item&gt;
        &lt;item&gt;Experience rolling out data protection technologies like SSO, MFA, VPN, FIPS, etc.&lt;/item&gt;
        &lt;item&gt;Experience with organizational secret management.&lt;/item&gt;
        &lt;item&gt;Experience implementing SCA, SAST, DAST in CICD workflows.&lt;/item&gt;
        &lt;item&gt;Experience with Mobile Device Management (MDM).&lt;/item&gt;
        &lt;item&gt;Proficiency in cloud security &amp;amp; networking on AWS - IAM, WAF, KMS, etc.&lt;/item&gt;
        &lt;item&gt;Proficiency in authentication, cryptography, encryption, and security protocols such as: mTLS, RSA, SSL, HMAC, RBAC, etc.&lt;/item&gt;
        &lt;item&gt;Bonus: experience with IHE profiles (ATNA, CT, XUA).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Competitive equity + compensation package 🚀&lt;/item&gt;
        &lt;item&gt;Salary range: $160,000,00 - $220,000.00&lt;/item&gt;
        &lt;item&gt;Full family Platinum health insurance, dental, and vision coverage 🦷&lt;/item&gt;
        &lt;item&gt;401(k) retirement plan + matching 💰&lt;/item&gt;
        &lt;item&gt;Flexible work from home or in-office 🏢&lt;/item&gt;
        &lt;item&gt;Healthy lunches are complimentary when working in-office (and breakfast + dinners as needed) 🍏&lt;/item&gt;
        &lt;item&gt;Quarterly company off-sites with the team ⛷️&lt;/item&gt;
        &lt;item&gt;MacBook provided by us 💻&lt;/item&gt;
        &lt;item&gt;Unlimited PTO (we work hard, but trust you to take time you need to be at your best) 🧘♂️&lt;/item&gt;
      &lt;/list&gt;
      &lt;p&gt;&lt;lb/&gt; Our tech&lt;/p&gt;
      &lt;p&gt;On the frontend, we use React - on the backend, we rely on Node.js and TypeScript for writing core business logic. We deploy a wide range of AWS cloud services (ie ECS, Fargate, Lambda, etc), and manage our infrastructure as code with AWS CDK. Data lives in PostgreSQL, DynamoDB, S3, Snowflake, FHIR servers, and more. We use Oneleet for security and compliance.&lt;/p&gt;
      &lt;p&gt;Metriport provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity, or gender expression. We are committed to a diverse and inclusive workforce and welcome people from all backgrounds, experiences, perspectives, and abilities.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/metriport/jobs/XC2AF8s-senior-security-engineer"/><published>2026-01-24T17:00:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46745233</id><title>Tao Te Ching – Translated by Ursula K. Le Guin</title><updated>2026-01-24T22:40:52.270297+00:00</updated><content>&lt;doc fingerprint="eb7ad05e09566404"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/nrrb/tao-te-ching/blob/master/Ursula%20K%20Le%20Guin.md"/><published>2026-01-24T17:01:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46745259</id><title>December in Servo: multiple windows, proxy support, better caching, and more</title><updated>2026-01-24T22:40:51.662398+00:00</updated><content>&lt;doc fingerprint="660f40f72340fbc4"&gt;
  &lt;main&gt;
    &lt;p&gt;Servo 0.0.4 and our December nightly builds now support multiple windows (@mrobinson, @mukilan, #40927, #41235, #41144)! This builds on features that landed in Servo’s embedding API last month. We’ve also landed support for several web platform features, both old and new:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‘contrast-color()’ in CSS color values (@webbeef, #41542)&lt;/item&gt;
      &lt;item&gt;partial support for &amp;lt;meta charset&amp;gt; (@simonwuelker, #41376)&lt;/item&gt;
      &lt;item&gt;partial support for encoding sniffing (@simonwuelker, #41435)&lt;/item&gt;
      &lt;item&gt;‘background’ and ‘bgcolor’ attributes on &amp;lt;table&amp;gt;, &amp;lt;thead&amp;gt;, &amp;lt;tbody&amp;gt;, &amp;lt;tfoot&amp;gt;, &amp;lt;tr&amp;gt;, &amp;lt;td&amp;gt;, &amp;lt;th&amp;gt; (@simonwuelker, #41272)&lt;/item&gt;
      &lt;item&gt;tee() on readable byte streams (@Taym95, #35991)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For better compatibility with older web content, we now support vendor-prefixed CSS properties like ‘-moz-transform’ (@mrobinson, #41350), as well as window.clientInformation (@Taym95, #41111).&lt;/p&gt;
    &lt;p&gt;We’ve continued shipping the SubtleCrypto API, with full support for ChaCha20-Poly1305, RSA-OAEP, RSA-PSS, and RSASSA-PKCS1-v1_5 (see below), plus importKey() for ML-KEM (@kkoyung, #41585) and several other improvements (@kkoyung, @PaulTreitel, @danilopedraza, #41180, #41395, #41428, #41442, #41472, #41544, #41563, #41587, #41039, #41292):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Algorithm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;ChaCha20-Poly1305&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, #40978, #41003, #41030)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RSA-OAEP&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, @TimvdLippe, @jdm, #41225, #41217, #41240, #41316)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;RSA-PSS&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, @jdm, #41157, #41225, #41240, #41287)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;RSASSA-PKCS1-v1_5&lt;/cell&gt;
        &lt;cell&gt;(@kkoyung, @jdm, #41172, #41225, #41240, #41267)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;When using servoshell on Windows, you can now see &lt;code&gt;--help&lt;/code&gt; and log output, as long as servoshell was started in a console (@jschwe, #40961).&lt;/p&gt;
    &lt;p&gt;Servo diagnostics options are now accessible in servoshell via the &lt;code&gt;SERVO_DIAGNOSTICS&lt;/code&gt; environment variable (@atbrakhi, #41013), in addition to the usual &lt;code&gt;-Z&lt;/code&gt; / &lt;code&gt;--debug=&lt;/code&gt; arguments.&lt;/p&gt;
    &lt;p&gt;Servo’s devtools now partially support the Network &amp;gt; Security tab (@jiang1997, #40567), allowing you to inspect some of the TLS details of your requests. We’ve also made it compatible with Firefox 145 (@eerii, #41087), and use fewer IPC resources (@mrobinson, #41161).&lt;/p&gt;
    &lt;p&gt;We’ve fixed rendering bugs related to ‘float’, ‘order’, ‘max-width’, ‘max-height’, ‘:link’ selectors, &amp;lt;audio&amp;gt; layout, and getClientRects(), affecting intrinsic sizing (@Loirooriol, #41513), anonymous blocks (@Loirooriol, #41510), incremental layout (@Loirooriol, #40994), flex item sizing (@Loirooriol, #41291), selector matching (@andreubotella, #41478), replaced element layout (@Loirooriol, #41262), and empty fragments (@Loirooriol, #41477).&lt;/p&gt;
    &lt;p&gt;Servo now fires ‘toggle’ events on &amp;lt;dialog&amp;gt; (@lukewarlow, #40412). We’ve also improved the conformance of ‘wheel’ events (@mrobinson, #41182), ‘hashchange’ events (@Taym95, #41325), ‘dblclick’ events on &amp;lt;input&amp;gt; (@Taym95, #41319), ‘resize’ events on &amp;lt;video&amp;gt; (@tharkum, #40940), ‘seeked’ events on &amp;lt;video&amp;gt; and &amp;lt;audio&amp;gt; (@tharkum, #40981), and the ‘transform’ property in getComputedStyle() (@mrobinson, #41187).&lt;/p&gt;
    &lt;head rend="h2"&gt;Embedding API&lt;/head&gt;
    &lt;p&gt;Servo now has basic support for HTTP proxies (@Narfinger, #40941). You can set the proxy URL in the &lt;code&gt;http_proxy&lt;/code&gt; (@Narfinger, #41209) or &lt;code&gt;HTTP_PROXY&lt;/code&gt; (@treeshateorcs, @yezhizhen, #41268) environment variables, or via &lt;code&gt;--pref network_http_proxy_uri&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We now use the system root certificates by default (@Narfinger, @mrobinson, #40935, #41179), on most platforms. If you don’t want to trust the system root certificates, you can instead continue to use Mozilla’s root certificates with &lt;code&gt;--pref network_use_webpki_roots&lt;/code&gt;.
As always, you can also add your own root certificates via &lt;code&gt;Opts&lt;/code&gt;::&lt;code&gt;certificate_path&lt;/code&gt; (&lt;code&gt;--certificate-path=&lt;/code&gt;).&lt;/p&gt;
    &lt;p&gt;We have a new &lt;code&gt;SiteDataManager&lt;/code&gt; API for managing localStorage, sessionStorage, and cookies (@janvarga, #41236, #41255, #41378, #41523, #41528), and a new &lt;code&gt;NetworkManager&lt;/code&gt; API for managing the cache (@janvarga, @mrobinson, #41255, #41474, #41386).
To clear the cache, call &lt;code&gt;NetworkManager&lt;/code&gt;::&lt;code&gt;clear_cache&lt;/code&gt;, and to list cache entries, call &lt;code&gt;NetworkManager&lt;/code&gt;::&lt;code&gt;cache_entries&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Simple dialogs – that is alert(), confirm(), and prompt() – are now exposed to embedders via a new &lt;code&gt;SimpleDialog&lt;/code&gt; type in &lt;code&gt;EmbedderControl&lt;/code&gt; (@mrobinson, @mukilan, #40982).
This new interface is harder to misuse, and no longer requires boilerplate for embedders that wish to ignore simple dialogs.&lt;/p&gt;
    &lt;p&gt;Web console messages, including messages from the Console API, are now accessible via &lt;code&gt;ServoDelegate&lt;/code&gt;::&lt;code&gt;show_console_message&lt;/code&gt; and &lt;code&gt;WebViewDelegate&lt;/code&gt;::&lt;code&gt;show_console_message&lt;/code&gt; (@atbrakhi, #41351).&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Servo&lt;/code&gt;, the main handle for controlling Servo, is now cloneable for sharing within the same thread (@mukilan, @mrobinson, #41010).
To shut down Servo, simply drop the last &lt;code&gt;Servo&lt;/code&gt; handle or let it go out of scope.
&lt;code&gt;Servo&lt;/code&gt;::&lt;code&gt;start_shutting_down&lt;/code&gt; and &lt;code&gt;Servo&lt;/code&gt;::&lt;code&gt;deinit&lt;/code&gt; have been removed (@mukilan, @mrobinson, #41012).&lt;/p&gt;
    &lt;p&gt;Several interfaces have also been renamed:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;Servo&lt;/code&gt;::&lt;code&gt;clear_cookies&lt;/code&gt;is now&lt;code&gt;SiteDataManager&lt;/code&gt;::&lt;code&gt;clear_cookies&lt;/code&gt;(@janvarga, #41236, #41255)&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;DebugOpts&lt;/code&gt;::&lt;code&gt;disable_share_style_cache&lt;/code&gt;is now&lt;code&gt;Preferences&lt;/code&gt;::&lt;code&gt;layout_style_sharing_cache_enabled&lt;/code&gt;(@atbrakhi, #40959)&lt;/item&gt;
      &lt;item&gt;The rest of &lt;code&gt;DebugOpts&lt;/code&gt;has been moved to&lt;code&gt;DiagnosticsLogging&lt;/code&gt;, and the options have been renamed (@atbrakhi, #40960)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Perf and stability&lt;/head&gt;
    &lt;p&gt;We can now evict entries from our HTTP cache (@Narfinger, @gterzian, @Taym95, #40613), rather than having it grow forever (or get cleared by an embedder). about:memory now tracks SVG-related memory usage (@d-kraus, #41481), and we’ve fixed memory leaks in &amp;lt;video&amp;gt; and &amp;lt;audio&amp;gt; (@tharkum, #41131).&lt;/p&gt;
    &lt;p&gt;Servo now does less work when matching selectors (@webbeef, #41368), when focus changes (@mrobinson, @Loirooriol, #40984), and when reflowing boxes whose size did not change (@Loirooriol, @mrobinson, #41160).&lt;/p&gt;
    &lt;p&gt;To allow for smaller binaries, gamepad support is now optional at build time (@WaterWhisperer, #41451).&lt;/p&gt;
    &lt;p&gt;We’ve fixed some undefined behaviour around garbage collection (@sagudev, @jdm, @gmorenz, #41546, mozjs#688, mozjs#689, mozjs#692). To better avoid other garbage-collection-related bugs (@sagudev, mozjs#647, mozjs#638), we’ve continued our work on defining (and migrating to) safer interfaces between Servo and the SpiderMonkey GC (@sagudev, #41519, #41536, #41537, #41520, #41564).&lt;/p&gt;
    &lt;p&gt;We’ve fixed a crash that occurs when &amp;lt;link rel=“shortcut icon”&amp;gt; has an empty ‘href’ attribute, which affected chiptune.com (@webbeef, #41056), and we’ve also fixed crashes in:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‘background-repeat’ (@mrobinson, #41158)&lt;/item&gt;
      &lt;item&gt;&amp;lt;audio&amp;gt; layout (@Loirooriol, #41262)&lt;/item&gt;
      &lt;item&gt;custom elements (@mrobinson, #40743)&lt;/item&gt;
      &lt;item&gt;AudioBuffer (@WaterWhisperer, #41253)&lt;/item&gt;
      &lt;item&gt;AudioNode (@Taym95, #40954)&lt;/item&gt;
      &lt;item&gt;ReportingObserver (@Taym95, #41261)&lt;/item&gt;
      &lt;item&gt;Uint8Array (@jdm, #41228)&lt;/item&gt;
      &lt;item&gt;the fonts system, on FreeType platforms (@simonwuelker, #40945)&lt;/item&gt;
      &lt;item&gt;IME usage, on OpenHarmony (@jschwe, #41570)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Donations&lt;/head&gt;
    &lt;p&gt;Thanks again for your generous support! We are now receiving 7110 USD/month (+10.5% over November) in recurring donations. This helps us cover the cost of our speedy CI and benchmarking servers, one of our latest Outreachy interns, and funding maintainer work that helps more people contribute to Servo.&lt;/p&gt;
    &lt;p&gt;Servo is also on thanks.dev, and already 30 GitHub users (+2 over November) that depend on Servo are sponsoring us there. If you use Servo libraries like url, html5ever, selectors, or cssparser, signing up for thanks.dev could be a good way for you (or your employer) to give back to the community.&lt;/p&gt;
    &lt;p&gt;We now have sponsorship tiers that allow you or your organisation to donate to the Servo project with public acknowlegement of your support. A big thanks from Servo to our newest Bronze Sponsors: Anthropy, Niclas Overby, and RxDB! If you’re interested in this kind of sponsorship, please contact us at [email protected].&lt;/p&gt;
    &lt;p&gt;Use of donations is decided transparently via the Technical Steering Committee’s public funding request process, and active proposals are tracked in servo/project#187. For more details, head to our Sponsorship page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conference talks and blogs&lt;/head&gt;
    &lt;p&gt;We’ve recently published one talk and one blog post:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Web engine CI on a shoestring budget (slides; transcript) – Delan Azabani (@delan) spoke about the CI system that keeps our builds and tryjobs moving fast, running nearly two million tests in under half an hour.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Servo 2025 Stats – Manuel Rego (@mrego) wrote about the growth of the Servo project, and how our many new contributors have enabled that.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We also have two upcoming talks at FOSDEM 2026 in Brussels later this month:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The Servo project and its impact on the web platform ecosystem – Manuel Rego (@mrego) is speaking on Saturday 31 January at 14:00 local time (13:00 UTC), about Servo’s impact on spec issues, interop bugs, test cases, and the broader web platform ecosystem.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Implementing Streams Spec in Servo web engine – Taym Haddadi (@Taym95) is speaking on Saturday 31 January at 17:45 local time (16:45 UTC), about our experiences writing a new implementation of the Streams API that is independent of the one in SpiderMonkey.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Servo developers Martin Robinson (@mrobinson) and Delan Azabani (@delan) will also be attending FOSDEM 2026, so it would be a great time to come along and chat about Servo!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://servo.org/blog/2026/01/23/december-in-servo/"/><published>2026-01-24T17:03:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46745922</id><title>Raspberry Pi Drag Race: Pi 1 to Pi 5 – Performance Comparison</title><updated>2026-01-24T22:40:50.916552+00:00</updated><content>&lt;doc fingerprint="be10987704b616b6"&gt;
  &lt;main&gt;
    &lt;p&gt;Today we’re going to be taking a look at what almost 13 years of development has done for the Raspberry Pi. I have one of each generation of Pi from the original Pi that was launched in 2012 through to the Pi 5 which was released just over a year ago.&lt;/p&gt;
    &lt;p&gt;We’ll take a look at what has changed between each generation and how their performance and power consumption has improved by running some tests on them.&lt;/p&gt;
    &lt;p&gt;Here’s my video of the testing process and results, read on for the write-up;&lt;/p&gt;
    &lt;head rend="h2"&gt;Purchase Links For Components Used In These Tests&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Raspberry Pi 5 – Buy Here&lt;/item&gt;
      &lt;item&gt;Raspberry Pi 4 – Buy Here&lt;/item&gt;
      &lt;item&gt;Pi 5 Ice Tower Cooler – Buy Here&lt;/item&gt;
      &lt;item&gt;Pi 5 Power Supply – Buy Here&lt;/item&gt;
      &lt;item&gt;USB C to MicroUSB Adaptor – Buy Here&lt;/item&gt;
      &lt;item&gt;Sandisk Ultra MicroSD Card – Buy Here&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Equipment Used&lt;/head&gt;
    &lt;p&gt;Some of the above parts are affiliate links. By purchasing products through the above links, you’ll be supporting this channel, at no additional cost to you.&lt;/p&gt;
    &lt;head rend="h2"&gt;Hardware Changes Through Each Generation&lt;/head&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 1&lt;/head&gt;
    &lt;p&gt;This is the original Raspberry Pi, which was launched in February 2012.&lt;/p&gt;
    &lt;p&gt;This Pi has a Broadcom BCM2835 SOC which features a single ARM1176JZF-S core running at 700MHz along with a VideoCore IV GPU. It has 512 MB of DDR RAM.&lt;/p&gt;
    &lt;p&gt;In terms of connectivity, it only has 100Mb networking and 2 x USB 2.0 ports. Video output is 1080P through a full-size HDMI port or analogue video out through a composite video connector and audio output is provided through a 3.5mm audio jack. It doesn’t have any WiFi or Bluetooth connectivity but it does have some of the features that we still have on more recent models like DSI and CSI ports, a full size SD card reader for the operating system and GPIO pins, although only 26 of them at this stage.&lt;/p&gt;
    &lt;p&gt;Power is supplied through a micro USB port and it is rated for 5V and 700mA.&lt;/p&gt;
    &lt;p&gt;It was priced at $35 – which at the time was incredibly cheap for what was essentially a palm-sized computer.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 2&lt;/head&gt;
    &lt;p&gt;The Raspberry Pi 2 was launched 3 years later, in February 2015 and this Pi looked quite different to the original and similar to the Pi’s we know today.&lt;/p&gt;
    &lt;p&gt;The Pi 2 has a significantly better processor than the original. The Broadcom BCM2836 SOC has 4 Cortex-A7 cores running at 900 MHz and it retained the same VideoCore IV GPU. RAM was also bumped up to 1GB.&lt;/p&gt;
    &lt;p&gt;It added another 2 x USB 2.0 ports alongside the 100Mb Ethernet port. The composite video port disappeared and the analogue video output was moved into the audio jack.&lt;/p&gt;
    &lt;p&gt;The GPIO pins were increased to 40 pins which has followed the same pin layout since – which has really helped in maintaining compatibility with hats and accessories. The SD card reader was also changed to a microSD card reader.&lt;/p&gt;
    &lt;p&gt;The power circuitry was bumped up to 800mA to accommodate the more powerful CPU.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 3&lt;/head&gt;
    &lt;p&gt;The Raspberry Pi 3 was launched just a year later, in February 2016.&lt;/p&gt;
    &lt;p&gt;The Pi 3’s new Broadcom BCM2837 SOC retained the same 4-core architecture but these were changed to 64-bit Cortex A53 cores running at 1.2Ghz.&lt;/p&gt;
    &lt;p&gt;RAM was kept at 1GB but was now DDR2.&lt;/p&gt;
    &lt;p&gt;There was no change to the USB or Ethernet connectivity on the original Pi 3 but we did see WiFi and Bluetooth added for the first time. WiFi was single band 2.4GHz and we had Bluetooth 4.1.&lt;/p&gt;
    &lt;p&gt;The version that I have is actually the 3B+, which was launched a little later. The main improvements over the original Pi 3 were a 0.2GHz boost to the clock speed and the upgrade to Gigabit networking with PoE (Power over Ethernet) support and dual-band WiFi.&lt;/p&gt;
    &lt;p&gt;The power circuitry was again improved, still running at 5V but now up to 1.34A, which was almost double the Pi 2.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 4&lt;/head&gt;
    &lt;p&gt;Next came the Pi 4 in June 2019. This Pi came at one of the worst times for global manufacturing and was notoriously difficult to get hold of due to the impact of COVID on the global supply chain. Quite ironically, this hard-to-get Pi is the one that I’ve got the most of, mainly due to my water-cooled Pi cluster build.&lt;/p&gt;
    &lt;p&gt;The Pi 4 has a Broadcom BCM2711 SOC with 4 Cortex-A72 cores running at 1.5GHz. So again a slight clock speed increase over the Pi 3 but still retaining 4 cores. It also includes a bump up to a VideoCore VI GPU.&lt;/p&gt;
    &lt;p&gt;This was the first model to feature different RAM configurations. It was originally available in 1, 2, 4GB variants featuring LPDDR4 RAM and in March of 2020 an 8GB variant was added to the linup as well. This obviously resulted in a few different price points but impressively they still managed to keep a $35 offering 7 years after the launch of the first Pi.&lt;/p&gt;
    &lt;p&gt;It retained the same form factor as the Pi 3 but with the network and Ethernet ports switched around. Notably, two of the USB ports were upgraded to USB 3.0, networking was now gigabit ethernet like the 3B+, WiFi was dual-band and it had Bluetooth 5.0.&lt;/p&gt;
    &lt;p&gt;They also changed the single full-size HDMI port to two micro HDMI ports. Most people I know don’t like this change and find it annoying to have to use adaptors to work with common displays and these micro HDMI ports are prone to breaking when they are used often. I think general hobbyists and makers would prefer this to still be a single full-size port but Pi’s are often used in commercial display applications so I guess that’s why they went with this dual micro HDMI configuration.&lt;/p&gt;
    &lt;p&gt;The power circuit was actually reduced in this model, from 1.34 down to 1.25A and the port was changed to USB C.&lt;/p&gt;
    &lt;head rend="h3"&gt;Raspberry Pi 5&lt;/head&gt;
    &lt;p&gt;Lastly and most recently we have the Pi 5 which was launched in October 2023.&lt;/p&gt;
    &lt;p&gt;This Pi features a Broadcom BCM2712 SOC with 4 Cortex A76 cores running at a significantly faster 2.4Ghz and a VideoCore VII GPU running at 800MHz.&lt;/p&gt;
    &lt;p&gt;So quite a bump up in CPU and GPU performance.&lt;/p&gt;
    &lt;p&gt;It is offered in 3 RAM configurations but the drop in a 1GB offering means that they’re no longer available at the $35 price point. There is a fairly significant increase in price up to $50 for the base 2GB variant.&lt;/p&gt;
    &lt;p&gt;Some other notable changes are the inclusion of a PCIe port which enables IO expansion and a much improved power circuit. The PCIe port is quite commonly used to add an NVMe SSD instead of a microSD card for the operating system.&lt;/p&gt;
    &lt;p&gt;The power circuit was upgraded to handle the PCIe port addition, now stepping up to 5V at up to 5A, along with a power button for the first time.&lt;/p&gt;
    &lt;p&gt;The change in power supply requirements to 5V and 5A is a bit annoying as most power delivery capable supplies cap out 2.5 or 3A at 5V. It would have been more universal to require a 9V 3A supply to meet the Pis power requirements. I assume they steered away from this because the Pi’s circuitry runs at 5V and 3.3V and they would have then needed to add another onboard DC-DC converter which increases complexity, size and potentially the cost, it would also have made it a bit less efficient. But this does mean that you most likely need to buy a USB C power supply that has been purpose-built for the Pi 5.&lt;/p&gt;
    &lt;p&gt;The Pi 5 is also the first Pi to have its own dedicated fan socket.&lt;/p&gt;
    &lt;p&gt;So that’s a summary of the hardware changes, now let’s boot them up and take a look at their performance.&lt;/p&gt;
    &lt;head rend="h2"&gt;Testing The Performance Of Each Generation Of Pi&lt;/head&gt;
    &lt;p&gt;To compare the performance between the Pi’s, I’m going to run the following tests.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;I’m going to attempt to playback a 1080P YouTube video in the browser, although I expect we’ll have problems with this up to the Pi 4.&lt;/item&gt;
      &lt;item&gt;We’ll then run a Sysbench CPU benchmark which I’ll do both for a single-core and multicore.&lt;/item&gt;
      &lt;item&gt;Then we’ll run a GLMark2 GPU benchmark.&lt;/item&gt;
      &lt;item&gt;Then test the storage speed using James Chambers Pi Benchmark script.&lt;/item&gt;
      &lt;item&gt;Then we’ll run an iPerf3 Network Speed test.&lt;/item&gt;
      &lt;item&gt;Lastly, we’ll look at Power Consumption, both at idle and with the CPU maxed out.&lt;/item&gt;
      &lt;item&gt;And then use that data to determine each Pi’s Performance per Watt.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To keep things as consistent as possible I’m going to be running the latest available version of Pi OS from Raspberry Pi Imager for each Pi. I was pleasantly surprised to find that you can still flash an OS image for the original Pi in their latest version of Imager.&lt;/p&gt;
    &lt;p&gt;I’ll be testing them all running on a 32GB Sandisk Ultra microSD card. I’ll also be using an Ice Tower cooler on each to ensure they don’t run anywhere near thermal throttling.&lt;/p&gt;
    &lt;head rend="h3"&gt;1080P YouTube Video Playback&lt;/head&gt;
    &lt;p&gt;I started with the original Pi and its first boot and setup process was a lesson in patience. It took me the best part of two hours to get the first boot complete, the Pi updated and the testing utilities installed but I got there in the end.&lt;/p&gt;
    &lt;p&gt;Even once set up it takes about 8 minutes to boot up to the desktop and the CPU stays pegged at 100% for another two to three minutes before dropping down to about 20% at idle.&lt;/p&gt;
    &lt;p&gt;The original Pi refused to open up the browser, so that’s where my YouTube video playback test ended.&lt;/p&gt;
    &lt;p&gt;The Pi 2 managed to open the browser and actually started playing back a 1080P video, which was surprising, but playback was terrible. It dropped pretty much all of the frames both in the window and fullscreen.&lt;/p&gt;
    &lt;p&gt;The Pi 3 played video back noticeably better than the Pi 2, but it’s still quite a long way away from being usable and still drops a lot of frames.&lt;/p&gt;
    &lt;p&gt;The Pi 4 handled 1080P video reasonably well. It had some initial trouble but then settled down. Fullscreen is also a bit choppy but is also usable.&lt;/p&gt;
    &lt;p&gt;The Pi 5 handled 1080P playback well without any significant issues both in the window and fullscreen.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sysbench CPU Benchmark&lt;/head&gt;
    &lt;p&gt;Next was the Sysbench CPU benchmark. I ran three tests on each and averaged the scores and I did this for both single-core and multicore.&lt;/p&gt;
    &lt;p&gt;In single core, the Pi 1 managed a rather dismal score of 68, the Pi 2 got a bit more than double this score but the real step up was with the Pi 3 which managed 18 times higher than the Pi 2. The Pi 4 and Pi 5 also offered good improvements on the previous generations.&lt;/p&gt;
    &lt;p&gt;Similarly in multicore, the Pi 3 scored over 18 times the score of the Pi2 and the Pi 4 and 5 provided good improvements on the Pi 3’s score.&lt;/p&gt;
    &lt;p&gt;Comparing the combined multicore score of the Pi 5 to what the single core on the Pi 1 can do, the Pi 5 is a little over 600 times faster.&lt;/p&gt;
    &lt;head rend="h3"&gt;GLmark2 GPU Benchmark&lt;/head&gt;
    &lt;p&gt;Next, I tried running a GLMark2 GPU benchmark on them. I used the GLMark2-es2-wayland version which is designed for OpenGL ES so that the Pi 1 was supported.&lt;/p&gt;
    &lt;p&gt;I was surprised that the Pi 1 was even able to run GLMark2 – it did complete the benchmark, although the score wasn’t all that impressive.&lt;/p&gt;
    &lt;p&gt;These results really show how the Pi’s GPU has improved in the last two generations. Prior to these tests, I had never seen a score below 100 and the Pi 1, 2 and 3 managed to fall short of triple digits. Pi 5 scored over 2.5 times higher than the Pi 4.&lt;/p&gt;
    &lt;head rend="h3"&gt;Storage Speed Test&lt;/head&gt;
    &lt;p&gt;Next was the storage speed test using James Chambers Pi Benchmarks script. The bus speed has increased over the years from 25MHz on the Pi 1 to 100MHz on the Pi 5, so I expect we’ll see these reflected in the benchmark scores.&lt;/p&gt;
    &lt;p&gt;The storage speed test’s results aren’t as dramatic as the CPU and GPU results but show a steady improvement between generations. The Pi 3 did a bit worse than the Pi 2 but this small difference is likely just due to variability in the tests.&lt;/p&gt;
    &lt;head rend="h3"&gt;iPerf Network Speed Test&lt;/head&gt;
    &lt;p&gt;Next, I ran the iPerf network speed test on each.&lt;/p&gt;
    &lt;p&gt;The Pi 1 doesn’t quite get close to its theoretical 100Mbps but the Pi 2 does. The Pi 3 B+ although having Gigabit Ethernet is limited by this running over USB 2.0 which only has a theoretical maximum of 300MBps, so it came quite close. Both the Pi 4 and 5 expectedly come close to theoretical Gigabit speeds.&lt;/p&gt;
    &lt;head rend="h3"&gt;Power Consumption Test&lt;/head&gt;
    &lt;p&gt;Lastly, I tested the power consumption of each Pi at idle and under load.&lt;/p&gt;
    &lt;p&gt;I used the same Pi 5 power adaptor to test all of the Pis to keep things consistent and I just used a USB C to micro USB adaptor for the Pi 1, 2 and 3.&lt;/p&gt;
    &lt;p&gt;The idle results were closer than I expected. The Pi 2 had the lowest idle power draw and the Pi 5 the highest, but all were within a watt or two of each other. At full load, you can see the increase in CPU power draw more physical power with the Pi 5 drawing almost three times the Pi 1 and Pi 2.&lt;/p&gt;
    &lt;p&gt;Converted to performance per watt using the Sysbench results, we can again see how much better the Pi 4 and 5 are over the Pi 1 and 2. There is a clear improvement in the performance that each generation of Pi is able to get per watt of power, which is essentially its efficiency. Although the Pi 5 draws more power than the Pi 1 under full load, you’re getting almost 200 times more power out of it per watt.&lt;/p&gt;
    &lt;head rend="h2"&gt;Final Thoughts On The Drag Race And Future Pis&lt;/head&gt;
    &lt;p&gt;I really enjoyed working through this project to see how much Pi’s have changed over the years, particularly in terms of performance. I still remember being amazed at the size and price of the original Pi when it came out and it’s great that they’re still fully supported and can still be used for projects – albeit with less CPU-intensive projects.&lt;/p&gt;
    &lt;p&gt;Let me know what you think has been the biggest improvement to the Pi over the years and what you’d still like to see added to future models in the comments section below.&lt;/p&gt;
    &lt;p&gt;I personally really like the addition of the PCIe port on the Pi 5 and I’d like to see 2.5Gb networking and a DisplayPort or USB C with DisplayPort added to a future generation of Pi.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://the-diy-life.com/raspberry-pi-drag-race-pi-1-to-pi-5-performance-comparison/"/><published>2026-01-24T18:06:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746096</id><title>Hung by a thread</title><updated>2026-01-24T22:40:50.742365+00:00</updated><content>&lt;doc fingerprint="e754011701612a4e"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Hung by a Thread&lt;/head&gt;January 24, 2026&lt;p&gt;It's 2am. My robot is frozen. Not crashed, not erroring, just... vibing. Sitting there. Motors off. Completely checked out.&lt;/p&gt;&lt;p&gt;I've been debugging for 8 hours and I'm about to mass delete my entire codebase and become a farmer.&lt;/p&gt;&lt;head rend="h2"&gt;The Setup&lt;/head&gt;&lt;p&gt;I'm building autonomous sidewalk robots. The control loop runs at 100Hz — every 10ms we read sensors, do math, send motor commands. It's the heartbeat. The one thing that absolutely cannot stop.&lt;/p&gt;&lt;p&gt;It had been rock solid for weeks. Then I added LiDAR streaming over WebRTC.&lt;/p&gt;&lt;p&gt;Now, ~16 seconds after a client connects, the loop just stops. Doesn't crash. Doesn't throw. Just ghosts me. The watchdog starts barking, the robot coasts to a stop, and my laptop shows a beautiful 3D point cloud of a robot that has given up on life.&lt;/p&gt;&lt;head rend="h2"&gt;The Wrong Turns&lt;/head&gt;&lt;p&gt;I tried everything.&lt;/p&gt;&lt;p&gt;"It's tokio starving the loop" — switched to &lt;code&gt;std::thread::sleep&lt;/code&gt;. Nope.&lt;/p&gt;&lt;p&gt;"It's the async mutex" — swapped for &lt;code&gt;std::sync::Mutex&lt;/code&gt;. Nope.&lt;/p&gt;&lt;p&gt;"It's running on the wrong thread" — moved the whole loop to &lt;code&gt;std::thread::spawn&lt;/code&gt;. Complete isolation. Nope nope nope.&lt;/p&gt;&lt;p&gt;Same freeze. Same spot. Iteration 1,615. Every single time.&lt;/p&gt;&lt;p&gt;The consistency was almost insulting. Like the bug was laughing at me.&lt;/p&gt;&lt;head rend="h2"&gt;The Breakthrough&lt;/head&gt;&lt;p&gt;Ok new plan. I add a heartbeat thread. Just a lil guy that watches a counter and screams if it stops:&lt;/p&gt;&lt;code&gt;std::thread::spawn(move || {
    let mut last = 0;
    loop {
        std::thread::sleep(Duration::from_secs(5));
        let current = counter.load(Ordering::Relaxed);
        if current == last {
            eprintln!("STUCK at iteration {}", current);
        }
        last = current;
    }
});
&lt;/code&gt;
&lt;p&gt;Five seconds after freeze: &lt;code&gt;STUCK at iteration 1615&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Oh. OH. It's not slow. It's not starved. It's blocked. Something is holding a lock and simply not letting go. Deadlock behavior.&lt;/p&gt;&lt;p&gt;Time to bring out the big guns. GDB.&lt;/p&gt;&lt;p&gt;She's waiting on a mutex. But who's holding it??&lt;/p&gt;&lt;p&gt;I scroll through the other threads. Tokio workers, GStreamer stuff, and then... four threads I definitely did not create. Rayon workers. I don't use rayon. Who invited rayon.&lt;/p&gt;&lt;head rend="h2"&gt;The Reveal&lt;/head&gt;&lt;p&gt;Rerun is this beautiful visualization SDK I use for recording telemetry. You call &lt;code&gt;recorder.log()&lt;/code&gt; and magic happens.&lt;/p&gt;&lt;p&gt;Turns out rerun uses rayon internally.&lt;/p&gt;&lt;p&gt;And I was calling &lt;code&gt;recorder.log()&lt;/code&gt; while holding a mutex.&lt;/p&gt;&lt;p&gt;This is a known rayon footgun: rayon#592. When you call into rayon while holding a mutex, rayon's work-stealing threads can deadlock trying to "help" with work that needs the lock you're already holding.&lt;/p&gt;&lt;p&gt;That's it. That's the fix. 8 hours of debugging. 2 lines changed. Hold the lock for less time. Tale as old as time.&lt;/p&gt;&lt;head rend="h2"&gt;The Takeaways&lt;/head&gt;&lt;list rend="ol"&gt;&lt;item&gt;&lt;p&gt;GDB is cracked for deadlocks. Logs can't show you thread state.&lt;/p&gt;&lt;code&gt;thread apply all bt&lt;/code&gt;hits different.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Random threads showing up? Suspicious. If you see thread pools you didn't spawn, figure out who did.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Your dependencies have dependencies. Somewhere in that&lt;/p&gt;&lt;code&gt;Cargo.lock&lt;/code&gt;is a threading model waiting to fight yours.&lt;/item&gt;&lt;item&gt;&lt;p&gt;Heartbeat threads are free. A few lines to detect "stuck" is worth it for any critical loop. They're just a lil guy. Let them watch.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;The fix is always smaller than the hunt. Always. Without exception. It's almost annoying.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;I submitted a PR to rerun adding docs about this. Maybe the next person finds the warning before they find the bug.&lt;/p&gt;&lt;p&gt;The robot runs now. Hasn't frozen since. The LiDAR streams beautifully.&lt;/p&gt;&lt;p&gt;But I will never call into a library I don't fully understand while holding a mutex again. Fool me once.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://campedersen.com/rayon-mutex-deadlock"/><published>2026-01-24T18:24:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746266</id><title>Understanding Rust Closures</title><updated>2026-01-24T22:40:50.503415+00:00</updated><content>&lt;doc fingerprint="bcb1cda920a59147"&gt;
  &lt;main&gt;
    &lt;p&gt;While reading the Explicit capture clauses blog post, I realized that my understanding of rust closures was very superficial. This article is an attempt at explaining what I learned while reading and experimenting on the subject. It starts from the very basics and then explore more complex topics. Note that each title is a link to a rust playground where you can experiment with the code in the section.&lt;/p&gt;
    &lt;head rend="h1"&gt;Closures basics&lt;/head&gt;
    &lt;p&gt;You probably already know that a closure in rust is a function written with the following syntax:&lt;/p&gt;
    &lt;code&gt;let double_closure = |x| x * 2;
assert_eq!(4, double_closure(2));
&lt;/code&gt;
    &lt;p&gt;Written as a regular function it looks like:&lt;/p&gt;
    &lt;code&gt;fn double_function(x: u32) -&amp;gt; u32 {
    x * 2
}
assert_eq!(4, double_function(2));
&lt;/code&gt;
    &lt;p&gt;Very similar. There is actually a small difference between the two, the &lt;code&gt;double_function&lt;/code&gt; parameter and return type are &lt;code&gt;u32&lt;/code&gt;.
On the other hand, because we did not specify any type in &lt;code&gt;double_closure&lt;/code&gt;, the
default integer type has been picked, namely &lt;code&gt;i32&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;We can fix that like this:&lt;/p&gt;
    &lt;code&gt;let double_typed_closure = |x: u32| -&amp;gt; u32 { x * 2 };
assert_eq!(4, double_typed_closure(2));
assert_eq!(4, double_typed_closure(2u32));
// assert_eq!(4, double_typed_closure(2u16)); // This would be an error.
&lt;/code&gt;
    &lt;p&gt;And for a classic example usage of closures, we can use the &lt;code&gt;Option::map&lt;/code&gt; method:&lt;/p&gt;
    &lt;code&gt;assert_eq!(Some(4), Some(2).map(|x| x * 2));
assert_eq!(Some(4), Some(2).map(double_closure)); // double_closure from above
assert_eq!(Some(4), Some(2).map(double_function)); // Passing double_function works too!
&lt;/code&gt;
    &lt;p&gt;So, it seems closures are just a shorter syntax for functions with type inference.&lt;/p&gt;
    &lt;head rend="h1"&gt;Capture&lt;/head&gt;
    &lt;p&gt;The main difference between closures and functions is that closures can capture variables from their environment while functions can't:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";
let greeter_closure = |x| String::new() + hello + x;

assert_eq!("Hello world", greeter_closure("world"));
assert_eq!(
    Some("Hello world".to_owned()),
    Some("world").map(greeter_closure)
);
&lt;/code&gt;
    &lt;p&gt;Notice how the &lt;code&gt;hello&lt;/code&gt; variable is used within the body of the &lt;code&gt;greeter_closure&lt;/code&gt;.
Let's try that with a function:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";

fn greeter_function(x: &amp;amp;str) -&amp;gt; String {
    String::new() + hello + x
}
&lt;/code&gt;
    &lt;code&gt;error[E0434]: can't capture dynamic environment in a fn item
 --&amp;gt; src/main.rs:7:25
  |
7 |         String::new() + hello + x
  |                         ^^^^^
  |
  = help: use the `|| { ... }` closure form instead
&lt;/code&gt;
    &lt;p&gt;This does not work and the compiler helpfully suggest to use a closure instead.&lt;/p&gt;
    &lt;head rend="h2"&gt;Capture by shared reference&lt;/head&gt;
    &lt;p&gt;In the &lt;code&gt;greeter_closure&lt;/code&gt; example above, the &lt;code&gt;hello&lt;/code&gt; variable was captured by
shared reference because the variable is only read.
As shown below, we can still use that variable after the closure declaration and usage:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";
let greeter_closure = |x| String::new() + hello + x;

// We can still use the `hello` variable here
assert_eq!("Hello ", hello);

assert_eq!("Hello world", greeter_closure("world"));

// And here
assert_eq!("Hello ", hello);
&lt;/code&gt;
    &lt;head rend="h2"&gt;Capture by mutable reference&lt;/head&gt;
    &lt;p&gt;It is also possible to capture by mutable reference so that the closure can alter the value of the captured variable. See this naive way to compute the sum of integers from 1 to 10:&lt;/p&gt;
    &lt;code&gt;let mut total = 0;
let add_mut_closure = |x| total += x;

// We can't access total here:
// assert_eq!(0, total);
// error[E0502]: cannot borrow `total` as immutable because it is also borrowed as mutable

(1..=10).for_each(add_mut_closure);

// But we can access total here, now that `add_mut_closure` is out of scope.
assert_eq!(55, total);
&lt;/code&gt;
    &lt;head rend="h2"&gt;Capture by value&lt;/head&gt;
    &lt;p&gt;Finally, one can capture by value:&lt;/p&gt;
    &lt;code&gt;let last_word = "last word: ".to_owned();
let drop_closure = |sigh| {
    let res = String::new() + &amp;amp;last_word + sigh;
    drop(last_word); // Forcing the capture by value
    res
};

// We can't access `last_word` here:
// assert_eq!("last word: ".to_owned(), last_word);
// error[E0382]: borrow of moved value: `last_word`

assert_eq!("last word: sigh!", drop_closure("sigh!"));

// We can't access `last_word` here either
// assert_eq!("last word: ".to_owned(), last_word);
// error[E0382]: borrow of moved value: `last_word`

// And we can't call drop_closure again
// assert_eq!("last word: sigh!", drop_closure("sigh!"));
// error[E0382]: use of moved value: `drop_closure`
&lt;/code&gt;
    &lt;head rend="h1"&gt;FnOnce trait&lt;/head&gt;
    &lt;p&gt;In the previous example, notice the last error when trying to call &lt;code&gt;drop_closure&lt;/code&gt; twice.
Here is the full error:&lt;/p&gt;
    &lt;code&gt;error[E0382]: use of moved value: `drop_closure`
  --&amp;gt; src/main.rs:18:32
   |
12 | assert_eq!("last word: sigh!", drop_closure("sigh!"));
   |                                --------------------- `drop_closure` moved due to this call
...
18 | assert_eq!("last word: sigh!", drop_closure("sigh!"));
   |                                ^^^^^^^^^^^^ value used here after move
   |
note: closure cannot be invoked more than once because it moves the variable `last_word` out of its environment
  --&amp;gt; src/main.rs:5:10
   |
 5 |     drop(last_word);
   |          ^^^^^^^^^
note: this value implements `FnOnce`, which causes it to be moved when called
  --&amp;gt; src/main.rs:12:32
   |
12 | assert_eq!("last word: sigh!", drop_closure("sigh!"));
   |                                ^^^^^^^^^^^^
&lt;/code&gt;
    &lt;p&gt;The interesting note is:&lt;/p&gt;
    &lt;code&gt;note: this value implements `FnOnce`, which causes it to be moved when called
&lt;/code&gt;
    &lt;p&gt;What is that &lt;code&gt;FnOnce&lt;/code&gt; implementation the compiler is talking about?&lt;/p&gt;
    &lt;p&gt;It is a trait automatically implemented by the compiler which state that the closure can be called at least once.&lt;/p&gt;
    &lt;p&gt;That trait is a bit special because it cannot be implemented manually in stable rust.&lt;lb/&gt; However, if we switch to unstable and enable some features, we can play with it and try to desugar how closures are actually implemented by the compiler.&lt;/p&gt;
    &lt;p&gt;Let's try to desugar the &lt;code&gt;drop_closure&lt;/code&gt; above.&lt;/p&gt;
    &lt;p&gt;First, make sure to switch to the nightly channel and to enable the following features (for example by putting them at the top of your &lt;code&gt;main.rs&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;#![feature(fn_traits)]
#![feature(unboxed_closures)]
&lt;/code&gt;
    &lt;p&gt;Next, we need to define a struct having the captured variables as fields:&lt;/p&gt;
    &lt;code&gt;struct DropStruct {
    last_word: String,
}
&lt;/code&gt;
    &lt;p&gt;Simple enough, we are capturing only one variable so our struct has one field.&lt;/p&gt;
    &lt;p&gt;Now the &lt;code&gt;FnOnce&lt;/code&gt; implementation:&lt;/p&gt;
    &lt;code&gt;impl FnOnce&amp;lt;(&amp;amp;str,)&amp;gt; for DropStruct {
    type Output = String;
    extern "rust-call" fn call_once(self, (sigh,): (&amp;amp;str,)) -&amp;gt; Self::Output {
        let res = String::new() + &amp;amp;self.last_word + sigh;
        drop(self.last_word);
        res
    }
}
&lt;/code&gt;
    &lt;p&gt;That is some weird trait!&lt;/p&gt;
    &lt;p&gt;Let's go step by step.&lt;code&gt;impl FnOnce&amp;lt;(&amp;amp;str,)&amp;gt;&lt;/code&gt; means that we are implementing a closure which takes one parameter which is a &lt;code&gt;&amp;amp;str&lt;/code&gt;.&lt;lb/&gt; If the closure took two arguments of type &lt;code&gt;i32&lt;/code&gt; and &lt;code&gt;i64&lt;/code&gt; we would have &lt;code&gt;impl FnOnce&amp;lt;(i32, i64)&amp;gt;&lt;/code&gt;. &lt;code&gt;(&amp;amp;str,)&lt;/code&gt; is the definition of a tuple of one element.
See the reference on tuple types for details.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;for DropStruct&lt;/code&gt; should not be too surprising.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;type Output = String&lt;/code&gt; specifies that our closure returns a &lt;code&gt;String&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;extern "rust-call"&lt;/code&gt; is some magic which I won't explain mostly because I don't know exactly why it is required.&lt;/p&gt;
    &lt;p&gt;The rest of the implementation should be self explanatory. We just took the content of the closure and replaced &lt;code&gt;last_word&lt;/code&gt; by &lt;code&gt;self.last_word&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Let's try it:&lt;/p&gt;
    &lt;code&gt;let last_word = "last word: ".to_owned();
let drop_struct = DropStruct { last_word };

// We could call `call_once`:
// assert_eq!("last word: sigh!", drop_struct.call_once(("sigh!",)));

// But more simply, we can use the function call syntax:
assert_eq!("last word: sigh!", drop_struct("sigh!"));

// And we still can't call it twice
// assert_eq!("last word: sigh!", drop_struct("sigh!"));
// error[E0382]: use of moved value: `drop_struct`
&lt;/code&gt;
    &lt;head rend="h1"&gt;FnMut trait&lt;/head&gt;
    &lt;p&gt;What about our &lt;code&gt;add_mut_closure&lt;/code&gt; from before? We were able to call it
multiple times and even mutate the capture variables.&lt;/p&gt;
    &lt;p&gt;That kind of closure implements the &lt;code&gt;FnMut&lt;/code&gt; trait.&lt;/p&gt;
    &lt;p&gt;Let's try to desugar the following closure which push elements in a vector:&lt;/p&gt;
    &lt;code&gt;let mut v = vec![];
let push_closure = |x| v.push(x);

(1..=5).for_each(push_closure);
assert_eq!(vec![1, 2, 3, 4, 5], v);
&lt;/code&gt;
    &lt;p&gt;First we need to define a struct:&lt;/p&gt;
    &lt;code&gt;struct PusherStruct&amp;lt;'a&amp;gt; {
    v: &amp;amp;'a mut Vec&amp;lt;i32&amp;gt;,
}
&lt;/code&gt;
    &lt;p&gt;Because we are capturing by reference, we need to introduce a lifetime.&lt;/p&gt;
    &lt;p&gt;Now the &lt;code&gt;FnMut&lt;/code&gt; implementation:&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a&amp;gt; FnMut&amp;lt;(i32,)&amp;gt; for PusherStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call_mut(&amp;amp;mut self, (x,): (i32,)) -&amp;gt; Self::Output {
        self.v.push(x)
    }
}
&lt;/code&gt;
    &lt;p&gt;It is very similar to the &lt;code&gt;FnOnce&lt;/code&gt; trait except that the function is called &lt;code&gt;call_mut&lt;/code&gt; instead of &lt;code&gt;call_once&lt;/code&gt; and that it takes &lt;code&gt;&amp;amp;mut self&lt;/code&gt; instead of &lt;code&gt;self&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Let's try to compile that:&lt;/p&gt;
    &lt;code&gt;error[E0277]: expected a `FnOnce(i32)` closure, found `PusherStruct&amp;lt;'a&amp;gt;`
 --&amp;gt; src/main.rs:8:5
  |
8 |     extern "rust-call" fn call_mut(&amp;amp;mut self, args: (i32,)) -&amp;gt; Self::Output {
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected an `FnOnce(i32)` closure, found `PusherStruct&amp;lt;'a&amp;gt;`
  |
help: the trait `FnOnce(i32)` is not implemented for `PusherStruct&amp;lt;'a&amp;gt;`
&lt;/code&gt;
    &lt;p&gt;Turns out we need to implement &lt;code&gt;FnOnce&lt;/code&gt; too. Remember that &lt;code&gt;FnOnce&lt;/code&gt; defines functions which can be called at least once.
In the example above, we called our closure 5 times, so it can definitely be called at least once.&lt;/p&gt;
    &lt;p&gt;Let's implement it:&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a&amp;gt; FnOnce&amp;lt;(i32,)&amp;gt; for PusherStruct&amp;lt;'a&amp;gt; {
    type Output = ();
    extern "rust-call" fn call_once(mut self, args: (i32,)) -&amp;gt; Self::Output {
        self.call_mut(args)
    }
}
&lt;/code&gt;
    &lt;p&gt;Our closure does not return anything so the &lt;code&gt;Output&lt;/code&gt; is the unit.&lt;lb/&gt; As for the &lt;code&gt;call_once&lt;/code&gt; implementation, we can just call &lt;code&gt;call_mut&lt;/code&gt; to avoid repetition.&lt;/p&gt;
    &lt;p&gt;This should compile and we can now use it like so:&lt;/p&gt;
    &lt;code&gt;let mut v = vec![];
let pusher_struct = PusherStruct { v: &amp;amp;mut v };

(1..=5).for_each(pusher_struct);
assert_eq!(vec![1, 2, 3, 4, 5], v);
&lt;/code&gt;
    &lt;head rend="h1"&gt;Fn trait&lt;/head&gt;
    &lt;p&gt;Finally, there is a third trait implemented by closures which can be called multiple times and don't need a mutable reference; the Fn trait.&lt;/p&gt;
    &lt;p&gt;To see that let's try to desugar the &lt;code&gt;greeter_closure&lt;/code&gt; from before:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ";
let greeter_closure = |x| String::new() + hello + x;

assert_eq!("Hello world", greeter_closure("world"));
assert_eq!("Hello rust", greeter_closure("rust")); // Can be called multiple times
&lt;/code&gt;
    &lt;p&gt;As usual, we need to define our struct:&lt;/p&gt;
    &lt;code&gt;struct GreeterStruct&amp;lt;'a&amp;gt; {
    hello: &amp;amp;'a str,
}
&lt;/code&gt;
    &lt;p&gt;Let's not make the same mistake as before, and remember to implement &lt;code&gt;FnOnce&lt;/code&gt; and &lt;code&gt;FnMut&lt;/code&gt; first. The same way an &lt;code&gt;FnMut&lt;/code&gt; closures are also &lt;code&gt;FnOnce&lt;/code&gt; because they can be called at least once. &lt;code&gt;Fn&lt;/code&gt; closures are also &lt;code&gt;FnMut&lt;/code&gt; because if given a mutable reference, they can still perform their work which does not mutate the reference.&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a, 'b&amp;gt; FnOnce&amp;lt;(&amp;amp;'b str,)&amp;gt; for GreeterStruct&amp;lt;'a&amp;gt; {
    type Output = String;
    extern "rust-call" fn call_once(self, args: (&amp;amp;'b str,)) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl&amp;lt;'a, 'b&amp;gt; FnMut&amp;lt;(&amp;amp;'b str,)&amp;gt; for GreeterStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call_mut(&amp;amp;mut self, args: (&amp;amp;'b str,)) -&amp;gt; Self::Output {
        self.call(args)
    }
}
&lt;/code&gt;
    &lt;p&gt;This should be pretty straightforward. &lt;code&gt;call_once&lt;/code&gt; and &lt;code&gt;call_mut&lt;/code&gt; are just calling &lt;code&gt;call&lt;/code&gt; which is defined in &lt;code&gt;Fn&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;impl&amp;lt;'a, 'b&amp;gt; Fn&amp;lt;(&amp;amp;'b str,)&amp;gt; for GreeterStruct&amp;lt;'b&amp;gt; {
    extern "rust-call" fn call(&amp;amp;self, (x,): (&amp;amp;'b str,)) -&amp;gt; Self::Output {
        String::new() + &amp;amp;self.hello + &amp;amp;x
    }
}
&lt;/code&gt;
    &lt;p&gt;And we can use it like this:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello";
let greeter_struct = GreeterStruct {
    hello,
};

assert_eq!("Hello world", greeter_struct("world"));
assert_eq!("Hello rust", greeter_struct("rust")); // Can be called multiple times
&lt;/code&gt;
    &lt;head rend="h1"&gt;The move keyword&lt;/head&gt;
    &lt;p&gt;You may already know that one can add the &lt;code&gt;move&lt;/code&gt; keyword in front of a closure to force the closure to take ownership of the capture variables even if the closure only need a reference to it.&lt;lb/&gt; For example:&lt;/p&gt;
    &lt;code&gt;let hello = "Hello ".to_owned();
let greeter_closure = move |x| String::new() + &amp;amp;hello + x;

// We can't access `hello` here
// assert_eq!("Hello ", hello);
// error[E0382]: borrow of moved value: `hello`

assert_eq!("Hello world", greeter_closure("world"));

// Nor here
// assert_eq!("Hello ", hello);
// error[E0382]: borrow of moved value: `hello`
&lt;/code&gt;
    &lt;p&gt;In order to clearly understand what we can do depending on whether the closure needs a shared reference, a mutable reference or a value and if there is &lt;code&gt;move&lt;/code&gt; keyword or not, let's introduce those small dummy functions:&lt;/p&gt;
    &lt;code&gt;fn by_ref(_data: &amp;amp;String) {}

fn by_mut(_data: &amp;amp;mut String) {}

fn by_value(_data: String) {}
&lt;/code&gt;
    &lt;p&gt;Now, let's see what we can do with different combination of move / not move and by_ref / by_mut / by_value:&lt;/p&gt;
    &lt;code&gt;let data = "by_ref".to_owned();
let by_ref_closure = || by_ref(&amp;amp;data);

// Access data while the closure is still in scope
assert_eq!("by_ref", data);

// Call the closure once
by_ref_closure();

// Call the closure multiple times
by_ref_closure();

// Access data once the closure is out of scope
assert_eq!("by_ref", data);
&lt;/code&gt;
    &lt;p&gt;Now with move:&lt;/p&gt;
    &lt;code&gt;let data = "move_by_ref".to_owned();
let move_by_ref_closure = move || by_ref(&amp;amp;data);

// Access data while the closure is still in scope
// assert_eq!("move_by_ref", data);
// error[E0382]: borrow of moved value: `data`

// Call the closure once
move_by_ref_closure();

// Call the closure multiple times
move_by_ref_closure();

// Access data once the closure is out of scope
// assert_eq!("move_by_ref", data);
// error[E0382]: borrow of moved value: `data`
&lt;/code&gt;
    &lt;p&gt;This makes sense, since the closure took ownership of &lt;code&gt;data&lt;/code&gt; we can't access it anymore from outside.&lt;/p&gt;
    &lt;p&gt;Similarly we can define the following closures:&lt;/p&gt;
    &lt;code&gt;let mut data = "by_mut".to_owned();
let by_mut_closure = || by_mut(&amp;amp;mut data);

let mut data = "move_by_mut".to_owned();
let move_by_mut_closure = move || by_mut(&amp;amp;mut data);

let data = "by_value".to_owned();
let by_value_closure = || by_value(data);

let data = "move_by_value".to_owned();
let move_by_value_closure = move || by_value(data);
&lt;/code&gt;
    &lt;p&gt;I will let you play with them, here what you should see:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;by_value&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Access when in scope&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Call once&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Call multiple times&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Access when out of scope&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And the trait implemented by each closures:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;by_value&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_ref&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_mut&lt;/cell&gt;
        &lt;cell role="head"&gt;move by_value&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FnOnce&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;FnMut&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Fn&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;✅&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
        &lt;cell&gt;❌&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can see that the &lt;code&gt;move&lt;/code&gt; keyword has no impact on the implemented trait. It only changes the capture to be from reference to value.&lt;/p&gt;
    &lt;p&gt;For example, the desugaring of &lt;code&gt;by_ref_closure&lt;/code&gt; is:&lt;/p&gt;
    &lt;code&gt;struct ByRefStruct&amp;lt;'a&amp;gt; {
    data: &amp;amp;'a String,
}

impl&amp;lt;'a&amp;gt; FnOnce&amp;lt;()&amp;gt; for ByRefStruct&amp;lt;'a&amp;gt; {
    type Output = ();
    extern "rust-call" fn call_once(self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl&amp;lt;'a&amp;gt; FnMut&amp;lt;()&amp;gt; for ByRefStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call_mut(&amp;amp;mut self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl&amp;lt;'a&amp;gt; Fn&amp;lt;()&amp;gt; for ByRefStruct&amp;lt;'a&amp;gt; {
    extern "rust-call" fn call(&amp;amp;self, (): ()) -&amp;gt; Self::Output {
        by_ref(self.data)
    }
}
&lt;/code&gt;
    &lt;p&gt;whereas for &lt;code&gt;move_by_ref_closure&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;struct MoveByRefStruct {
    data: String,
}

impl FnOnce&amp;lt;()&amp;gt; for MoveByRefStruct {
    type Output = ();
    extern "rust-call" fn call_once(self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl FnMut&amp;lt;()&amp;gt; for MoveByRefStruct {
    extern "rust-call" fn call_mut(&amp;amp;mut self, args: ()) -&amp;gt; Self::Output {
        self.call(args)
    }
}

impl Fn&amp;lt;()&amp;gt; for MoveByRefStruct {
    extern "rust-call" fn call(&amp;amp;self, (): ()) -&amp;gt; Self::Output {
        by_ref(&amp;amp;self.data)
    }
}
&lt;/code&gt;
    &lt;p&gt;Notice how the &lt;code&gt;data&lt;/code&gt; field changed from &lt;code&gt;&amp;amp;'a String&lt;/code&gt; to &lt;code&gt;String&lt;/code&gt; and the call to &lt;code&gt;by_ref&lt;/code&gt; from &lt;code&gt;self.data&lt;/code&gt; to &lt;code&gt;&amp;amp;self.data&lt;/code&gt; eventhough in the closure forms we had &lt;code&gt;by_ref(&amp;amp;data)&lt;/code&gt; in both cases.&lt;/p&gt;
    &lt;p&gt;So we now hopefully understand what the &lt;code&gt;move&lt;/code&gt; keyword does but you might wonder why that can be useful? After all, the first table above shows that we only removed flexbility.&lt;/p&gt;
    &lt;p&gt;Spawning a thread:&lt;/p&gt;
    &lt;code&gt;let data = "by_ref".to_owned();
std::thread::spawn(|| by_ref(&amp;amp;data)).join().unwrap();
&lt;/code&gt;
    &lt;p&gt;Without &lt;code&gt;move&lt;/code&gt;, we get the following compiler error which helpfully suggest adding &lt;code&gt;move&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;error[E0373]: closure may outlive the current function, but it borrows `data`, which is owned by the current function
 --&amp;gt; src/main.rs:9:20
  |
9 | std::thread::spawn(|| by_ref(&amp;amp;data)).join().unwrap();
  |                    ^^         ---- `data` is borrowed here
  |                    |
  |                    may outlive borrowed value `data`
  |
note: function requires argument type to outlive `'static`
 --&amp;gt; src/main.rs:9:1
  |
9 | std::thread::spawn(|| by_ref(&amp;amp;data)).join().unwrap();
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: to force the closure to take ownership of `data` (and any other referenced variables), use the `move` keyword
  |
9 | std::thread::spawn(move || by_ref(&amp;amp;data)).join().unwrap();
  |                    ++++
&lt;/code&gt;
    &lt;p&gt;Creating a function returning a closure:&lt;/p&gt;
    &lt;code&gt;fn make_greeter(greeter: &amp;amp;str) -&amp;gt; impl Fn(&amp;amp;str) -&amp;gt; String {
    move |name| format!("{greeter} {name}")
}

let hello_greeter = make_greeter("Hello");
let hi_greeter = make_greeter("Hi");

assert_eq!(hello_greeter("rust"), "Hello rust");
assert_eq!(hi_greeter("rust"), "Hi rust");
&lt;/code&gt;
    &lt;p&gt;Here too we need &lt;code&gt;move&lt;/code&gt; otherwise we get the same borrow checker error.&lt;/p&gt;
    &lt;head rend="h1"&gt;Last word&lt;/head&gt;
    &lt;p&gt;
      &lt;del&gt;Sigh&lt;/del&gt;
    &lt;/p&gt;
    &lt;p&gt;This article is long enough as is, so I am stopping here for now. I plan to publish a follow up article for async closures later. If you want to read more on the subject I recommend:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The closure chapter in the rust book&lt;/item&gt;
      &lt;item&gt;The closure chapter in the rust reference&lt;/item&gt;
      &lt;item&gt;The article from the baby steps blog about adding an explicit capture clause&lt;/item&gt;
      &lt;item&gt;The Rust Unstable book on fn_traits and unboxed_closures.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://antoine.vandecreme.net/blog/rust-closures/"/><published>2026-01-24T18:42:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746476</id><title>BirdyChat becomes first European chat app that is interoperable with WhatsApp</title><updated>2026-01-24T22:40:50.399990+00:00</updated><content>&lt;doc fingerprint="8e0f2119ee313c8d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;BirdyChat becomes the first European chat app that is interoperable with WhatsApp&lt;/head&gt;
    &lt;p&gt;November 14, 2025&lt;/p&gt;
    &lt;p&gt;Today we are excited to share a big milestone. BirdyChat is now the first chat app in Europe that can exchange messages with WhatsApp under the Digital Markets Act. This brings us closer to our mission of giving work conversations a proper home.&lt;/p&gt;
    &lt;p&gt;WhatsApp is currently rolling out interoperability support across Europe. As this rollout continues, the feature will become fully available to both BirdyChat and WhatsApp users in the coming months.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why this matters&lt;/head&gt;
    &lt;p&gt;Until now, you could only message people who already had a BirdyChat account. If someone was not on the app, they had to download it before you could talk. It slowed down adoption and made it harder to move real work conversations into BirdyChat.&lt;/p&gt;
    &lt;p&gt;With the new WhatsApp interface mandated by the DMA, any BirdyChat user in the EEA will be able to start a chat with any WhatsApp user in the region simply by knowing their phone number. Your contacts keep using WhatsApp. You stay on BirdyChat. Messages flow both ways.&lt;/p&gt;
    &lt;p&gt;This removes a big barrier to adopting BirdyChat for work. You no longer need to ask people to switch apps. You can keep work neatly organised in BirdyChat while staying connected to everyone who still relies on WhatsApp.&lt;/p&gt;
    &lt;head rend="h2"&gt;What interoperability lets you do&lt;/head&gt;
    &lt;p&gt;Interoperability lets you:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Start 1:1 chats with WhatsApp users using their phone number&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Send messages, photos and files&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Communicate over an encrypted connection&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Use your work email as your identity instead of a personal phone number&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This makes it much easier to keep work and personal life separate while staying fully reachable.&lt;/p&gt;
    &lt;head rend="h2"&gt;How the integration works&lt;/head&gt;
    &lt;p&gt;WhatsApp introduced Third-Party Chats in Europe earlier this year. BirdyChat connects through this official DMA interface and does not use any workarounds. All communication between BirdyChat and WhatsApp users is end-to-end encrypted.&lt;/p&gt;
    &lt;p&gt;Currently, BirdyChat supports 1:1 chats, with group chat interoperability coming in a future update.&lt;/p&gt;
    &lt;head rend="h2"&gt;Availability&lt;/head&gt;
    &lt;p&gt;This feature will roll out gradually to BirdyChat users across the European Economic Area. For interoperability to work, both you and your WhatsApp contacts need to be based in the EEA. Since WhatsApp is releasing interoperability as part of a gradual rollout, availability may differ slightly from country to country.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get early access&lt;/head&gt;
    &lt;p&gt;BirdyChat is invite-only while we scale access. Join the waitlist with your work email to be among the first to try WhatsApp interoperability.&lt;/p&gt;
    &lt;p&gt;Productively yours,&lt;lb/&gt;Team BirdyChat&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.birdy.chat/blog/first-to-interoperate-with-whatsapp"/><published>2026-01-24T19:04:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746517</id><title>The Concatative Language XY</title><updated>2026-01-24T22:40:50.212879+00:00</updated><link href="http://www.nsl.com/k/xy/xy.txt"/><published>2026-01-24T19:08:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746570</id><title>JSON-render: LLM-based JSON-to-UI tool</title><updated>2026-01-24T22:40:49.995592+00:00</updated><content>&lt;doc fingerprint="1c5bf3e86e0df68a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AI → json-render → UI&lt;/head&gt;
    &lt;p&gt;Define a component catalog. Users prompt. AI outputs JSON constrained to your catalog. Your components render it.&lt;/p&gt;
    &lt;code&gt;npm install @json-render/core @json-render/react&lt;/code&gt;
    &lt;head rend="h3"&gt;Define Your Catalog&lt;/head&gt;
    &lt;p&gt;Set the guardrails. Define which components, actions, and data bindings AI can use.&lt;/p&gt;
    &lt;head rend="h3"&gt;Users Prompt&lt;/head&gt;
    &lt;p&gt;End users describe what they want. AI generates JSON constrained to your catalog.&lt;/p&gt;
    &lt;head rend="h3"&gt;Render Instantly&lt;/head&gt;
    &lt;p&gt;Stream the response. Your components render progressively as JSON arrives.&lt;/p&gt;
    &lt;head rend="h2"&gt;Define your catalog&lt;/head&gt;
    &lt;p&gt;Components, actions, and validation functions.&lt;/p&gt;
    &lt;code&gt;import { createCatalog } from '@json-render/core';
import { z } from 'zod';

export const catalog = createCatalog({
  components: {
    Card: {
      props: z.object({
        title: z.string(),
        description: z.string().nullable(),
      }),
      hasChildren: true,
    },
    Metric: {
      props: z.object({
        label: z.string(),
        valuePath: z.string(),
        format: z.enum(['currency', 'percent']),
      }),
    },
  },
  actions: {
    export: { params: z.object({ format: z.string() }) },
  },
});&lt;/code&gt;
    &lt;head rend="h2"&gt;AI generates JSON&lt;/head&gt;
    &lt;p&gt;Constrained output that your components render natively.&lt;/p&gt;
    &lt;code&gt;{
  "key": "dashboard",
  "type": "Card",
  "props": {
    "title": "Revenue Dashboard",
    "description": null
  },
  "children": [
    {
      "key": "revenue",
      "type": "Metric",
      "props": {
        "label": "Total Revenue",
        "valuePath": "/metrics/revenue",
        "format": "currency"
      }
    }
  ]
}&lt;/code&gt;
    &lt;head rend="h2"&gt;Export as Code&lt;/head&gt;
    &lt;p&gt;Export generated UI as standalone React components. No runtime dependencies required.&lt;/p&gt;
    &lt;head rend="h3"&gt;Generated UI Tree&lt;/head&gt;
    &lt;p&gt;AI generates a JSON structure from the user's prompt.&lt;/p&gt;
    &lt;code&gt;{
  "root": "card",
  "elements": {
    "card": {
      "key": "card",
      "type": "Card",
      "props": { "title": "Revenue" },
      "children": ["metric", "chart"]
    },
    "metric": {
      "key": "metric",
      "type": "Metric",
      "props": {
        "label": "Total Revenue",
        "valuePath": "analytics/revenue",
        "format": "currency"
      }
    },
    "chart": {
      "key": "chart",
      "type": "Chart",
      "props": {
        "dataPath": "analytics/salesByRegion"
      }
    }
  }
}&lt;/code&gt;
    &lt;head rend="h3"&gt;Exported React Code&lt;/head&gt;
    &lt;p&gt;Export as a standalone Next.js project with all components.&lt;/p&gt;
    &lt;code&gt;"use client";

import { Card, Metric, Chart } from "@/components/ui";

const data = {
  analytics: {
    revenue: 125000,
    salesByRegion: [
      { label: "US", value: 45000 },
      { label: "EU", value: 35000 },
    ],
  },
};

export default function Page() {
  return (
    &amp;lt;Card data={data} title="Revenue"&amp;gt;
      &amp;lt;Metric
        data={data}
        label="Total Revenue"
        valuePath="analytics/revenue"
        format="currency"
      /&amp;gt;
      &amp;lt;Chart data={data} dataPath="analytics/salesByRegion" /&amp;gt;
    &amp;lt;/Card&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;The export includes &lt;code&gt;package.json&lt;/code&gt;, component files, styles, and everything needed to run independently.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;head rend="h3"&gt;Guardrails&lt;/head&gt;
    &lt;p&gt;AI can only use components you define in the catalog&lt;/p&gt;
    &lt;head rend="h3"&gt;Streaming&lt;/head&gt;
    &lt;p&gt;Progressive rendering as JSON streams from the model&lt;/p&gt;
    &lt;head rend="h3"&gt;Code Export&lt;/head&gt;
    &lt;p&gt;Export as standalone React code with no runtime dependencies&lt;/p&gt;
    &lt;head rend="h3"&gt;Data Binding&lt;/head&gt;
    &lt;p&gt;Two-way binding with JSON Pointer paths&lt;/p&gt;
    &lt;head rend="h3"&gt;Actions&lt;/head&gt;
    &lt;p&gt;Named actions handled by your application&lt;/p&gt;
    &lt;head rend="h3"&gt;Visibility&lt;/head&gt;
    &lt;p&gt;Conditional show/hide based on data or auth&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://json-render.dev/"/><published>2026-01-24T19:12:56+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746681</id><title>Agent orchestration for the timid</title><updated>2026-01-24T22:40:49.849290+00:00</updated><content/><link href="https://substack.com/inbox/post/185649875"/><published>2026-01-24T19:25:53+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46746900</id><title>Show HN: StormWatch – Weather emergency dashboard with prep checklists</title><updated>2026-01-24T22:40:49.749905+00:00</updated><content>&lt;doc fingerprint="7279a67378a22c29"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;Welcome to StormWatch&lt;/head&gt;
    &lt;p&gt;Tap "Set Location" below to get started&lt;/p&gt;
    &lt;head rend="h2"&gt;Current Conditions&lt;/head&gt;
    &lt;p&gt; — °F &lt;/p&gt;
    &lt;p&gt;—&lt;/p&gt;
    &lt;p&gt;Humidity&lt;/p&gt;
    &lt;p&gt;—%&lt;/p&gt;
    &lt;p&gt;Wind&lt;/p&gt;
    &lt;p&gt;— mph&lt;/p&gt;
    &lt;p&gt;Visibility&lt;/p&gt;
    &lt;p&gt;— mi&lt;/p&gt;
    &lt;head rend="h2"&gt;Next 12 Hours&lt;/head&gt;
    &lt;head rend="h2"&gt;7-Day Forecast&lt;/head&gt;
    &lt;head rend="h2"&gt;Precipitation Chance&lt;/head&gt;
    &lt;p&gt;No significant precipitation expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Snow &amp;amp; Ice Forecast&lt;/head&gt;
    &lt;p&gt;Snow&lt;/p&gt;
    &lt;p&gt;Ice&lt;/p&gt;
    &lt;p&gt;No snow or ice expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Wind Forecast&lt;/head&gt;
    &lt;p&gt;No significant wind expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Weather News&lt;/head&gt;
    &lt;p&gt; Showing news for your area and surrounding region &lt;/p&gt;
    &lt;p&gt;Weather news for your area will appear here&lt;/p&gt;
    &lt;head rend="h2"&gt;Impact Timeline&lt;/head&gt;
    &lt;p&gt;No weather impacts expected&lt;/p&gt;
    &lt;head rend="h2"&gt;Action Checklist&lt;/head&gt;
    &lt;p&gt;No preparation needed — conditions are normal&lt;/p&gt;
    &lt;head rend="h2"&gt;Supply Calculator&lt;/head&gt;
    &lt;p&gt; 2 &lt;/p&gt;
    &lt;p&gt; Data from NWS &amp;amp; GDELT. Not official. Verify with local authorities. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jeisey.github.io/stormwatch/"/><published>2026-01-24T19:40:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46747119</id><title>Postmortem: Our first VLEO satellite mission (with imagery and flight data)</title><updated>2026-01-24T22:40:49.454346+00:00</updated><content>&lt;doc fingerprint="ae1dcadd78b58dbb"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Clarity-1: What Worked, and Where We Go Next&lt;/head&gt;
    &lt;p&gt;On March 14, 2025, Albedo's first satellite, Clarity-1, launched on SpaceX Transporter-13. We took a big swing with our pathfinder. The mission goals:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Prove sustainable orbit operations in VLEO — an orbital regime long considered too harsh for commercial satellites — by overcoming thick atmospheric drag, dangerous atomic oxygen, and extreme speeds.&lt;/item&gt;
      &lt;item&gt;Prove our mid-size, high-performance Precision bus — designed and built in-house in just over two years.&lt;/item&gt;
      &lt;item&gt;Capture 10 cm resolution visible imagery and 2-meter thermal infrared imagery, a feat previously achieved only by exquisite, billion dollar government systems.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We proved a ton. We learned a ton.&lt;/p&gt;
    &lt;p&gt;We achieved the first two goals definitively and validated 98% of the technology required for the third. This was an extraordinarily ambitious first satellite. We designed and built a high-performance bus on time and on budget, integrated a large-aperture telescope, and operated in an environment no commercial company had sustained operations in, funded entirely by private capital.&lt;/p&gt;
    &lt;p&gt;This is the full story.&lt;/p&gt;
    &lt;head rend="h1"&gt;VLEO Works&lt;/head&gt;
    &lt;p&gt;Let's start with the result that matters most: VLEO works. And it works better than even we expected.&lt;/p&gt;
    &lt;p&gt;For decades, Very Low Earth Orbit was written off as impractical for normal satellite lifetimes. The atmosphere is thicker, creating drag that would deorbit normal satellites in weeks. If the drag didn't kill you, atomic oxygen would erode your solar arrays and surfaces. To succeed in VLEO required a fundamentally different satellite design.&lt;/p&gt;
    &lt;p&gt;Clarity-1 proved that our design works.&lt;/p&gt;
    &lt;p&gt;The drag coefficient was the headline: 12% better than our design target. Measured multiple times at altitudes between 350 km - 380 km with a repeatable result, this validates our models producing a satellite lifespan of five years at 275 km altitude, averaged across the solar cycle. This was one of our most critical assumptions, and we exceeded it.&lt;/p&gt;
    &lt;p&gt;Atomic oxygen (AO) is the silent killer in VLEO. The deeper you go, the more AO you encounter. It degrades solar arrays and other traditional satellite materials. We developed a new class of solar arrays with unique measures designed to mitigate AO degradation. They work. Even as we descended deeper into VLEO and AO fluence increased logarithmically, our power generation stayed constant. The solar arrays are holding up as designed.&lt;/p&gt;
    &lt;p&gt;Clarity-1 demonstrated over 100 km of controlled altitude descent, stationkeeping in VLEO, and survived a solar storm that temporarily spiked atmospheric density — the impact on Clarity's descent rate was barely noticeable. Momentum management worked. Fault detection worked. Our thrust planning model was validated against GOCE data (a 2009 VLEO R&amp;amp;D mission) with sub-meter accuracy. Radiation tolerance was excellent, with 4x fewer single-event upsets than expected. Orbit determination was dialed.&lt;/p&gt;
    &lt;p&gt;We proved sustainable VLEO operations.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Precision Bus is Flight-Proven&lt;/head&gt;
    &lt;p&gt;Developed and built in just over two years, our in-house bus Precision is now TRL-9: flight-proven on-orbit.&lt;/p&gt;
    &lt;p&gt;Every bus subsystem worked. Every piece of in-house technology we developed performed: our CMG steering law, our operational modes, flight and ground software, electronics boards, and our novel thermal management system. We hit our embedded software GNC timing deadlines, we converged our attitude and orbit determination estimators, we saw 4π steradian command and telemetry antenna coverage, and we got on-orbit actuals for our power generation and loads.&lt;/p&gt;
    &lt;p&gt;Our cloud-native ground system was incredible. Contact planning across 25 ground stations was completely automated. Mission scheduling updated every 15 minutes to incorporate new tasking and the latest satellite state information, smoothly transitioning to updated on-board command loads with visual tracking of each schedule and its status. Automated thrust planning to achieve our desired orbital trajectory supported 30+ maneuvers per day. Our engineers could track and command the satellite from anywhere with internet and a secure VPN.&lt;/p&gt;
    &lt;p&gt;We pushed 14 successful flight software feature updates on-orbit. The ability to continuously improve throughout Clarity's operational life proved essential — every major solution to challenges we faced involved flight software updates. On-orbit software upgrades are exceedingly tricky to get right, but Clarity-1 was designed from day one around this foundational capability.&lt;/p&gt;
    &lt;head rend="h1"&gt;Four Weeks of Perfection&lt;/head&gt;
    &lt;p&gt;The first month of the mission was magic.&lt;/p&gt;
    &lt;p&gt;An hour after launch, we watched Clarity-1 deploy from the premium caketopper slot into LEO, giving us an incredible view of the Nile River as she separated from the rocket.&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;First contact came just three hours later at 5:11am MT. Imagine sitting in Mission Control, watching two ground station passes with no data, then on the third: heaps of green, healthy telemetry streaming into all of the subsystem dashboards. Clarity had nailed her autonomous boot-up sequence and rocket separation rate capture. Stuck the landing.&lt;/p&gt;
    &lt;p&gt;The next milestone — and the one many of us were most anxious about — was our autonomous Protect Mode, basically our VLEO version of Safe Mode.&lt;/p&gt;
    &lt;p&gt;We estimated a week.&lt;/p&gt;
    &lt;p&gt;We nailed it 14 hours after launch.&lt;/p&gt;
    &lt;p&gt;By 6:45pm that same day, Clarity was in Operational mode, ready for commissioning.&lt;/p&gt;
    &lt;p/&gt;
    &lt;quote&gt;"Gotta say it: the last 16 hours have been incredible. I started my shift last night hoping to see one bit of data. I wouldn't have believed it if someone told me we'd be in Protect within 14 hours from launch."— Albedo GNC Engineer&lt;/quote&gt;
    &lt;p/&gt;
    &lt;p&gt;The days that followed were a blur of checkboxes turning green. 4-CMG commissioning complete. Payload power-on and checkout validated. Thermal balance for both visible and thermal sensors confirmed. Our first on-orbit software update went flawlessly.&lt;/p&gt;
    &lt;p&gt;Clarity uses Control Moment Gyroscopes (CMGs) to steer the satellite, giving us more agility than more commonly used reaction wheels. We moved onto validating GNC modes such as GroundTrack, which we use to point at communication ground terminals.&lt;/p&gt;
    &lt;p&gt;We moved on to commissioning our X-band radio — the high-rate link to downlink imagery. After we uncovered an issue with our ground station provider’s pointing mode, the 800 Mbps link began pumping down data on every pass. The waveforms were clean. Textbook. A direct representation of how locked in our precision CMG pointing was.&lt;/p&gt;
    &lt;p&gt;With our first satellite at this level of complexity, we couldn't believe how smoothly it had gone. Years of developing new technologies had been validated in a fraction of the commissioning time we'd anticipated.&lt;/p&gt;
    &lt;head rend="h1"&gt;Maneuvering over 100 km to VLEO&lt;/head&gt;
    &lt;p&gt;Next up was maneuvering from our LEO drop-off altitude down to VLEO, where it would be safe to eject the telescope contamination cover and start snapping pictures.&lt;/p&gt;
    &lt;p&gt;Then came April 14.&lt;/p&gt;
    &lt;p&gt;One of our four CMGs experienced a temperature spike in the flywheel bearing. Our Fault Detection, Isolation, and Recovery (FDIR) logic caught it immediately, spun it down, and executed automated recovery actions. But it wouldn't spin back up. Manual recovery attempts followed. Also unsuccessful.&lt;/p&gt;
    &lt;p&gt;Rushing back into CMG operations without understanding the failure mechanism risked killing the mission entirely, so we turned off the other three and put the satellite in two-axis stabilization using the magnetic torque rods.&lt;/p&gt;
    &lt;p&gt;We had a choice. Hack together novel 3-CMG control algorithms as fast as possible and risk losing another, or figure out how to leverage only the torque rods to achieve 3-axis control with sufficient accuracy to navigate the maneuver to VLEO.&lt;/p&gt;
    &lt;p&gt;We went with the torque rods.&lt;/p&gt;
    &lt;p&gt;On satellites this size (~600 kg), magnetic torque rods are typically used for momentum dumping, not attitude control. But we'd built Clarity with unusually beefy torque rods due to the elevated momentum management needs in VLEO. Our GNC team went heads down and developed algorithms to achieve 3-axis attitude control using only torque rods.&lt;/p&gt;
    &lt;p&gt;Within a month, we had it working.&lt;/p&gt;
    &lt;p&gt;Both of our electric thrusters commissioned quickly and were working well. But with torque rods only, our attitude control had 15 to 20 degrees of error, sometimes reaching ~45 degrees. And maneuvering to VLEO isn’t “point into the wind and fire” — it’s continuous vector and trajectory management across an orbit. That kind of control error meant inefficient burns and a much harder descent plan.&lt;/p&gt;
    &lt;p&gt;As the descent progressed, however, the team learned and iterated. With more iteration and flight software updates, we uploaded onboard logic informed by several sources of live data that dialed in our thrust vector control to within 5 degrees of the target. The autonomous thrust planning system we built enabled us to claw back performance that nearly matched our originally projected descent speed.&lt;/p&gt;
    &lt;p&gt;We maneuvered safely past the ISS and entered VLEO. Eager to pop off the contamination cover.&lt;/p&gt;
    &lt;head rend="h1"&gt;Lens Cap Jettison&lt;/head&gt;
    &lt;p&gt;Once we reached safe altitude, it was time to jettison the contamination cover protecting our telescope.&lt;/p&gt;
    &lt;p&gt;There are horror stories about contamination covers getting stuck after months of temperature fluctuations.&lt;/p&gt;
    &lt;p&gt;Clarity's was flawless. I'll never forget seeing this blip in telemetry live — confirming through Newton's third law that the jettison was successful. Shortly after, LeoLabs confirmed tracking of two separate objects.&lt;/p&gt;
    &lt;p&gt;We were ready to start imaging.&lt;/p&gt;
    &lt;head rend="h1"&gt;The Imaging Journey&lt;/head&gt;
    &lt;p&gt;Here's where it got complicated.&lt;/p&gt;
    &lt;p&gt;Our GNC and FSW teams were close but not yet finished with the new 3-CMG control law. CMGs are rarely used in commercial space, let alone by a startup. Then take one more step: singularity-prone 3-CMG control that to our knowledge has not been attempted on a non-exquisite satellite, and certainly not developed and uploaded on-orbit. Traditional algorithms require at least four CMGs to provide capability volumes free of singularities.&lt;/p&gt;
    &lt;p&gt;We were eager to make some amount of progress, so we started imaging on torque rods even though there would be severe limitations: 50+ pixels of smear, large mispointing from the wobble of torque rod control due to earth's magnetic field, and downlink limited to at best two small images per day. The last two constraints meant we were at risk of spending precious downlink capacity on clouds.&lt;/p&gt;
    &lt;p&gt;Sure enough, the first two days of pixels were mostly clouds, but we were happy to peek through a little in this image.&lt;/p&gt;
    &lt;p&gt;Although we couldn't control attitude accurately, we did still have good attitude knowledge after the fact. AyJay whipped up a clever idea with Claude Code that automated posting weather conditions in Slack for each collection. We analyzed that to determine which images were likely clear, and selected those for downlink.&lt;/p&gt;
    &lt;p&gt;Boom:&lt;/p&gt;
    &lt;p&gt;We adjusted the focus position a few times, and images continued getting better.&lt;/p&gt;
    &lt;p&gt;Then, 3-CMG control was ready.&lt;/p&gt;
    &lt;p&gt;Out of the box, the new algorithms and software performed perfectly.&lt;/p&gt;
    &lt;p&gt;This visualization shows real telemetry of Clarity performing seven back-to-back imaging maneuvers, with limited 3-CMG agility, followed by an X-band downlink over Iceland minutes later. The satellite was executing sophisticated attitude profiles with very low control error. Fiber-optic gyro measurements showed exquisite jitter performance.&lt;/p&gt;
    &lt;p&gt;In real time, collecting and downlinking those seven images took ten minutes.&lt;/p&gt;
    &lt;p&gt;And this is where our ground software really showed its teeth. On most missions, “data on the ground” is just the start — turning raw bits into something viewable is a slow chain of handoffs and batch processing. For us, within seconds of the downlink finishing, the image product pipeline was already posting processed snippets into our company Slack. Literally seconds.&lt;/p&gt;
    &lt;p&gt;That end-to-end loop — photons in orbit to a viewable product on the ground, within minutes — is a capability that’s still rare in this industry.&lt;/p&gt;
    &lt;p&gt;As expected with smear reduced, image quality improved immediately.&lt;/p&gt;
    &lt;p&gt;We were ready to execute focus calibration.&lt;/p&gt;
    &lt;p&gt;Large telescope optics experience hygroscopic dryout during the first few months on-orbit — moisture trapped in materials during ground assembly slowly releases in the vacuum of space, causing the focus position to drift. Dialing in best focus requires dozens of iterations: capture images, analyze sharpness, adjust focus position, repeat. Each cycle gets you closer to the optical performance the system was designed for, and our telescope’s on-ground alignment was verified to spec.&lt;/p&gt;
    &lt;p&gt;We continued to iterate.&lt;/p&gt;
    &lt;p&gt;After a few iterations of this, we could start to see cars.&lt;/p&gt;
    &lt;p&gt;Even this early into imaging, the infrared images blew us away. Using a low-cost microbolometer — a fraction of the price of cooled IR sensors — we captured thermal signatures that showed ships in Tokyo Bay, steel processing facilities where we could distinguish individual coke ovens from their smokestacks, and distinct signatures between real vegetation and turf — a good proxy for camouflage detection. Day or night, clear as day.&lt;/p&gt;
    &lt;p&gt;Three days into the excitement, CMG problems started again.&lt;/p&gt;
    &lt;p&gt;A second CMG began showing the same telemetry signatures we now recognized as warning signs.&lt;/p&gt;
    &lt;p&gt;What we had learned from the investigation: the allowable temperature specifications of the CMGs were much higher than the true limit, constrained by what the lubricant inside the flywheel could handle. A straightforward fix for the future — an unfortunate corner case to learn about in hindsight.&lt;/p&gt;
    &lt;p&gt;The second CMG showing issues was also on the hot side of the satellite. While we had overhauled the vehicle and CMG operations to prevent additional bearing wear, the damage had already been done in the first month of the mission.&lt;/p&gt;
    &lt;p&gt;We spent months trying everything we could to get the CMGs to operate sustainably. The team attempted many clever solutions, one of which revived the first CMG that had locked up. We uploaded a feature to select any 3 of the 4 CMGs for operator commanding. But we weren't able to get sustained, reliable operation.&lt;/p&gt;
    &lt;p&gt;Despite the CMG challenges, here's what the imaging journey proved.&lt;/p&gt;
    &lt;p&gt;The full end-to-end image chain works. Photons hit our optics, get captured by our sensor, processed through payload electronics, packetized and encrypted, transmitted via our X-band radio, received on the ground, and processed into image products. The entire chain is validated.&lt;/p&gt;
    &lt;p&gt;The end-to-end loop is fast. Within 30 seconds of a downlink, processed image snippets were already posting to our company Slack.&lt;/p&gt;
    &lt;p&gt;Sensor performance exceeded expectations. Dynamic range, radiometry, color balance, band-to-band alignment — all look great, even on uncalibrated imagery.&lt;/p&gt;
    &lt;p&gt;We can scan out long images. Our line-scanning approach produced strips 20-30 kilometers long, exactly as designed.&lt;/p&gt;
    &lt;p&gt;Pointing accuracy and high quality telemetry validates the ingredients for precise geolocation. The data we need to pinpoint where each pixel lands on Earth to &amp;lt;5m (closed-loop CE90) is there.&lt;/p&gt;
    &lt;p&gt;Jitter and smear are low. Fiber-optic gyro measurements confirmed 3x lower smear and 11x lower jitter compared to our goal — a critical ingredient for exquisite imagery.&lt;/p&gt;
    &lt;p&gt;Our proprietary image scheduler works. The automated system that plans collections, manages constraints, and optimizes what we capture each day performed as designed.&lt;/p&gt;
    &lt;head rend="h1"&gt;Where Clarity Is Now&lt;/head&gt;
    &lt;p&gt;Nine months into the mission, we lost contact with Clarity-1.&lt;/p&gt;
    &lt;p&gt;By that point, we had largely exhausted our options on the CMGs. The path to further image quality improvement had effectively closed.&lt;/p&gt;
    &lt;p&gt;We had been tracking intermittent memory issues in our TT&amp;amp;C radio throughout the mission, working around them as they appeared. Our best theory is that one of these issues escalated in a way that corrupted onboard memory and is preventing reboots. We've tried several recovery approaches. So far, none have worked, and the likelihood of recovery looks low at this point.&lt;/p&gt;
    &lt;p&gt;But here's what matters: the VLEO validation data we collected is sufficient.&lt;/p&gt;
    &lt;p&gt;We combined a state-of-the-art atmospheric density model, our high-fidelity orbital dynamics force models, and months of natural orbit decay data from 350 to 380 km altitude to determine Clarity’s coefficient of drag — with repeatable results at different altitudes. That drag coefficient, paired with our demonstrated ability to maintain altitude in VLEO for months using high-efficiency thrusters, tells us exactly how the vehicle behaves under aerodynamic drag across the VLEO regime — and validates an average five-year lifespan at 275 km across the solar cycle. Telemetry from our solar arrays, together with onboard atomic oxygen sensor data, shows peak power generation stayed constant after exposure to VLEO levels of AO fluence — proving our AO mitigation worked.&lt;/p&gt;
    &lt;p&gt;Thanks to our friends at LeoLabs, we've validated that Clarity is maintaining attitude autonomously. She's still up there, still oriented, still descending through VLEO. Just not talking to us.&lt;/p&gt;
    &lt;p&gt;Even before this, we had started developing an in-house TT&amp;amp;C radio for our systems moving forward, rather than reusing this radio that was procured from a third party. We’ll incorporate learnings from this reliability issue into that.&lt;/p&gt;
    &lt;p&gt;We're still working the problem. This chapter isn't over yet. But even if it is, Clarity-1 gave us what we needed to build what comes next.&lt;/p&gt;
    &lt;head rend="h1"&gt;98% of The 10 cm Imagery Pyramid&lt;/head&gt;
    &lt;p&gt;If you think about exquisite imagery as a pyramid, we needed 100% of the systems working together to achieve the pinnacle: 10 cm visible imagery. We got to about 98%. Everything else in that pyramid — the entire foundation — is proven and retired.&lt;/p&gt;
    &lt;p&gt;Our drag coefficient. Our atomic oxygen resilience. Our solar arrays. Our thermal management. Our flight software. Our ground software. Our CMG steering laws. Our precision pointing algorithms. Our payload electronics. Our sensor performance. Our image processing chain. Our ability to operate sustainably in VLEO. Our team.&lt;/p&gt;
    &lt;p&gt;All validated.&lt;/p&gt;
    &lt;p&gt;We know exactly what to fix. It’s straight forward: operate the CMGs at lower temperature. The system thermal design is already updated in the next build to maximize CMG life going forward.&lt;/p&gt;
    &lt;p&gt;Beyond the CMGs, there were a handful of learnings on the margins. We learned our secondary mirror structure could be stiffer — already in the updated design. We learned we could use more heater capacity in some payload zones — already fixed.&lt;/p&gt;
    &lt;p&gt;We learned from the things that worked, too. We're well down the development path for next-gen flight software, avionics, and power distribution. Orbit determination and geolocation will be even better. Additional surface treatments will improve drag coefficient further. Power-generation will increase while maintaining the proven atomic oxygen resilience. The list goes on.&lt;/p&gt;
    &lt;p&gt;The path to exquisite imagery is clear. And that’s only one of many exciting capabilities unlocked by sustainable operations in VLEO.&lt;/p&gt;
    &lt;head rend="h1"&gt;What’s Next&lt;/head&gt;
    &lt;p&gt;Our next VLEO mission will incorporate these learnings and demonstrate new features that enable missions beyond imaging — we’ll share more details soon. In parallel, imaging remains a core focus: we’re continuing to build optical payloads for EO/IR missions as part of a broader VLEO roadmap.&lt;/p&gt;
    &lt;p&gt;The successes of Clarity-1 reinforced our core conviction: VLEO isn’t just a better orbit for imaging — it’s the next productive orbital layer.&lt;/p&gt;
    &lt;p&gt;The physics are unforgiving, but that’s exactly why it matters. Go lower and you unlock a step-change in performance: sharper sensing, faster links, lower latency, and a new level of responsiveness. The reason VLEO has been written off for decades isn’t lack of upside — it’s that most satellites simply can’t survive there long enough to matter.&lt;/p&gt;
    &lt;p&gt;Now we know they can.&lt;/p&gt;
    &lt;p&gt;Clarity proved the hard parts: sustainable VLEO operations, validated drag and lifetime models, atomic oxygen resilience, and a flight-proven high-performance bus. We’re not speculating about VLEO. We’re operating in it, learning in it, and capitalized to scale it.&lt;/p&gt;
    &lt;p&gt;Onward,&lt;/p&gt;
    &lt;p&gt;Topher &amp;amp; Team Albedo&lt;/p&gt;
    &lt;p/&gt;
    &lt;p/&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://albedo.com/post/clarity-1-what-worked-and-where-we-go-next"/><published>2026-01-24T20:03:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46747351</id><title>Show HN: JSciPy – SciPy-inspired signal processing library for Java and Android</title><updated>2026-01-24T22:40:48.890152+00:00</updated><content>&lt;doc fingerprint="4e9c1a1e06d976cc"&gt;
  &lt;main&gt;
    &lt;p&gt;jSciPy is a comprehensive Java Scientific Computing and Signal Processing Library designed for Machine Learning on the JVM and Android. Inspired by Python's SciPy, it provides high-performance implementations of essential algorithms.&lt;/p&gt;
    &lt;p&gt;It currently includes modules for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Signal Processing: Butterworth, Chebyshev, Elliptic, Bessel, and FIR (&lt;code&gt;firwin&lt;/code&gt;) filters, Window Functions, 2D Convolution, Savitzky-Golay smoothing, Peak detection, Detrending, Median Filter.&lt;/item&gt;
      &lt;item&gt;Transformations: FFT (Fast Fourier Transform), Hilbert Transform, Welch PSD, Spectrogram, Periodogram, Convolution, DCT/IDCT.&lt;/item&gt;
      &lt;item&gt;Math &amp;amp; Analysis: RK4 ODE Solver, Interpolation (Linear, Cubic Spline), Resampling, Polynomial fitting.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In modern machine learning workflows, most signal processing tasks rely on Python's SciPy utilities. However, there is no Java library that replicates SciPy's behavior with comparable completeness and consistency. This creates a significant gap for teams building ML or signal processing pipelines on the JVM. jSciPy aims to fill this gap, and the demand for such a library is higher than ever.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why jSciPy?&lt;/item&gt;
      &lt;item&gt;Features&lt;/item&gt;
      &lt;item&gt;Accuracy &amp;amp; Precision&lt;/item&gt;
      &lt;item&gt;Documentation&lt;/item&gt;
      &lt;item&gt;Getting Started&lt;/item&gt;
      &lt;item&gt;How to Include as a Dependency (JitPack)&lt;/item&gt;
      &lt;item&gt;Demo Android Application&lt;/item&gt;
      &lt;item&gt;Comparison Graphs &lt;list rend="ul"&gt;&lt;item&gt;Butterworth Filter&lt;/item&gt;&lt;item&gt;Chebyshev Filter&lt;/item&gt;&lt;item&gt;Elliptic Filter&lt;/item&gt;&lt;item&gt;Bessel Filter&lt;/item&gt;&lt;item&gt;RK4 Solver&lt;/item&gt;&lt;item&gt;FindPeaks&lt;/item&gt;&lt;item&gt;Interpolation&lt;/item&gt;&lt;item&gt;FFT&lt;/item&gt;&lt;item&gt;Welch's Method&lt;/item&gt;&lt;item&gt;Spectrogram&lt;/item&gt;&lt;item&gt;STFT/ISTFT&lt;/item&gt;&lt;item&gt;Periodogram&lt;/item&gt;&lt;item&gt;Resample&lt;/item&gt;&lt;item&gt;Savitzky-Golay&lt;/item&gt;&lt;item&gt;Detrend&lt;/item&gt;&lt;item&gt;MedFilt&lt;/item&gt;&lt;item&gt;1D Convolve&lt;/item&gt;&lt;item&gt;2D Convolve&lt;/item&gt;&lt;item&gt;Cross-Correlation&lt;/item&gt;&lt;item&gt;DCT&lt;/item&gt;&lt;item&gt;Polynomial Fit&lt;/item&gt;&lt;item&gt;2D FFT&lt;/item&gt;&lt;item&gt;Hilbert Transform&lt;/item&gt;&lt;item&gt;SOS Filtering&lt;/item&gt;&lt;item&gt;Window Functions&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Usage Examples&lt;/item&gt;
      &lt;item&gt;Contributing&lt;/item&gt;
      &lt;item&gt;License&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The table below compares jSciPy’s signal processing and scientific computing features with several other popular Java libraries, highlighting areas where jSciPy provides more comprehensive functionality.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Feature / Characteristic&lt;/cell&gt;
        &lt;cell role="head"&gt;jSciPy&lt;/cell&gt;
        &lt;cell role="head"&gt;Commons Math&lt;/cell&gt;
        &lt;cell role="head"&gt;JDSP&lt;/cell&gt;
        &lt;cell role="head"&gt;TarsosDSP&lt;/cell&gt;
        &lt;cell role="head"&gt;IIRJ&lt;/cell&gt;
        &lt;cell role="head"&gt;EJML&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Primary Focus&lt;/cell&gt;
        &lt;cell&gt;SciPy-style Signal + Scientific&lt;/cell&gt;
        &lt;cell&gt;General Math/Stats&lt;/cell&gt;
        &lt;cell&gt;Java DSP Toolbox&lt;/cell&gt;
        &lt;cell&gt;Audio Processing&lt;/cell&gt;
        &lt;cell&gt;IIR Filter Only&lt;/cell&gt;
        &lt;cell&gt;Linear Algebra&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Zero-Phase Filtering (&lt;code&gt;filtfilt&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes (SciPy-compatible)&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;2D Signal Ops (&lt;code&gt;conv2d&lt;/code&gt;, &lt;code&gt;fft2&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;SciPy-like API Consistency&lt;/cell&gt;
        &lt;cell&gt;✅ High (SciPy semantics)&lt;/cell&gt;
        &lt;cell&gt;❌ Low&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Filtering Capabilities&lt;/cell&gt;
        &lt;cell&gt;⭐⭐⭐⭐⭐ (IIR+FIR+advanced)&lt;/cell&gt;
        &lt;cell&gt;⭐ Basic&lt;/cell&gt;
        &lt;cell&gt;⭐⭐⭐ (IIR/FIR &amp;amp; adaptive)&lt;/cell&gt;
        &lt;cell&gt;⭐⭐ (audio filters)&lt;/cell&gt;
        &lt;cell&gt;⭐⭐ (IIR only)&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Transforms (FFT/DCT/Hilbert)&lt;/cell&gt;
        &lt;cell&gt;✅ FFT, DCT + Hilbert&lt;/cell&gt;
        &lt;cell&gt;Limited / Basic FFT only&lt;/cell&gt;
        &lt;cell&gt;✅ FFT + Hilbert&lt;/cell&gt;
        &lt;cell&gt;✅ FFT spectrum tools (audio)&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Interpolation (Linear/Cubic)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;ODE Solvers (RK4)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Signal Analysis (Peak/PSD)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Welch PSD&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Spectrogram&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Window Functions&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Savitzky-Golay Filter&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Median Filter (&lt;code&gt;medfilt&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Detrending&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Real-Optimized FFT (&lt;code&gt;rfft&lt;/code&gt;/&lt;code&gt;irfft&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;STFT / ISTFT Support&lt;/cell&gt;
        &lt;cell&gt;✅ Yes (SciPy-like)&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes (dedicated classes)&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;1D Convolution with Modes (&lt;code&gt;convolve&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes (with modes)&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Resampling (&lt;code&gt;resample&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Signal Padding Utilities (&lt;code&gt;padSignal&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Configurable Peak Finding (&lt;code&gt;find_peaks&lt;/code&gt; with prominence etc.)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;Cross-Correlation (&lt;code&gt;correlate&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Polynomials (&lt;code&gt;polyfit&lt;/code&gt;, &lt;code&gt;polyval&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes (via Commons Math)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Advanced Filtering: Butterworth, Chebyshev, Elliptic, Bessel, FIR Design (&lt;code&gt;firwin&lt;/code&gt;). Supports zero-phase (&lt;code&gt;filtfilt&lt;/code&gt;), causal (&lt;code&gt;lfilter&lt;/code&gt;), and Second-Order Sections (&lt;code&gt;sosfilt&lt;/code&gt;) modes.&lt;/item&gt;
      &lt;item&gt;2D Processing: &lt;code&gt;convolve2d&lt;/code&gt;(Full/Same/Valid),&lt;code&gt;fft2&lt;/code&gt;,&lt;code&gt;ifft2&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Transforms: standard 1D &lt;code&gt;fft&lt;/code&gt;/&lt;code&gt;ifft&lt;/code&gt;, real-optimized&lt;code&gt;rfft&lt;/code&gt;/&lt;code&gt;irfft&lt;/code&gt;,&lt;code&gt;dct&lt;/code&gt;/&lt;code&gt;idct&lt;/code&gt;(Discrete Cosine Transform),&lt;code&gt;stft&lt;/code&gt;/&lt;code&gt;istft&lt;/code&gt;,&lt;code&gt;hilbert&lt;/code&gt;transform.&lt;/item&gt;
      &lt;item&gt;Smoothing &amp;amp; Analysis: Savitzky-Golay, &lt;code&gt;medfilt&lt;/code&gt;(Median Filter),&lt;code&gt;find_peaks&lt;/code&gt;, Welch's PSD,&lt;code&gt;spectrogram&lt;/code&gt;,&lt;code&gt;detrend&lt;/code&gt;,&lt;code&gt;resample&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Correlation: &lt;code&gt;correlate&lt;/code&gt;(Cross-Correlation with FULL/SAME/VALID modes).&lt;/item&gt;
      &lt;item&gt;Polynomials: &lt;code&gt;polyfit&lt;/code&gt;,&lt;code&gt;polyval&lt;/code&gt;,&lt;code&gt;polyder&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Window Functions: Hamming, Hanning, Blackman, Kaiser, Bartlett, Flat-top, Parzen, Bohman, Triangle.&lt;/item&gt;
      &lt;item&gt;Numerical Methods: Interpolation (Linear, Cubic Spline), RK4 ODE Solver.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;jSciPy is rigorously tested against Python's SciPy using a "Golden Master" approach. Below is a summary of the precision (RMSE) achieved across various modules:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Module&lt;/cell&gt;
        &lt;cell role="head"&gt;Test Case&lt;/cell&gt;
        &lt;cell role="head"&gt;RMSE (Approx)&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Filters&lt;/cell&gt;
        &lt;cell&gt;Butterworth, Chebyshev, Elliptic, Bessel&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-14&lt;/code&gt; to &lt;code&gt;1e-16&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;FFT&lt;/cell&gt;
        &lt;cell&gt;1D FFT, RFFT, IFFT&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-15&lt;/code&gt; to &lt;code&gt;1e-16&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Spectral&lt;/cell&gt;
        &lt;cell&gt;Spectrogram, Welch, STFT/ISTFT, Periodogram&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-16&lt;/code&gt; to &lt;code&gt;1e-18&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SOS Filt&lt;/cell&gt;
        &lt;cell&gt;Second-Order Sections Filter&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1e-16&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;2D Ops&lt;/cell&gt;
        &lt;cell&gt;2D FFT, 2D Convolution&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1e-16&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Math&lt;/cell&gt;
        &lt;cell&gt;Interpolation, Resample&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;1e-16&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DCT&lt;/cell&gt;
        &lt;cell&gt;DCT Type-II, Ortho&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-15&lt;/code&gt; to &lt;code&gt;1e-16&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Poly&lt;/cell&gt;
        &lt;cell&gt;Polyfit, Val, Der&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;1e-14&lt;/code&gt; to &lt;code&gt;1e-15&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ODE&lt;/cell&gt;
        &lt;cell&gt;RK4 Solver&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;5e-13&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;✅ Excellent&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;You can access full documentation javadoc of the jscipy library HERE.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Java Development Kit (JDK) 8 or higher&lt;/item&gt;
      &lt;item&gt;Gradle (for building the project)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;JitPack is a novel package repository for JVM projects. It builds GitHub projects on demand and provides ready-to-use artifacts (jar, javadoc, sources).&lt;/p&gt;
    &lt;p&gt;To use this library in your Gradle project, add the JitPack repository and the dependency to your &lt;code&gt;build.gradle&lt;/code&gt; file:&lt;/p&gt;
    &lt;code&gt;// In your root build.gradle (or settings.gradle for repository definition)
allprojects {
    repositories {
        mavenCentral()
        maven { url 'https://jitpack.io' }
    }
}

// In your app's build.gradle
dependencies {
    implementation 'com.github.hissain:jSciPy:3.1.3' // Replace 3.1.3 with the desired version or commit hash
}&lt;/code&gt;
    &lt;p&gt;A seperate demo android application is built on this library that might be helpful to understand how to consume this library. The application can be accessed here.&lt;/p&gt;
    &lt;p&gt;Type I:&lt;/p&gt;
    &lt;p&gt;Type II:&lt;/p&gt;
    &lt;p&gt;Smoothing:&lt;/p&gt;
    &lt;p&gt;Differentiation:&lt;/p&gt;
    &lt;p/&gt;
    &lt;p&gt;All standard IIR filters (Butterworth, Chebyshev I/II, Elliptic, Bessel) are supported with consistent APIs.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;

public class FilterExample {
    public static void main(String[] args) {
        double[] signal = {/*... input data ...*/};
        double fs = 100.0;
        double fc = 10.0;
        int order = 4;

        // 1. Butterworth: Zero-phase vs Causal
        double[] zeroPhase = Signal.filtfilt(signal, fs, fc, order);
        double[] causal = Signal.lfilter(signal, fs, fc, order);

        // 2. Chebyshev Type I (Ripple 1dB) &amp;amp; Type II (Stopband 20dB)
        double[] cheby1 = Signal.cheby1_filtfilt(signal, fs, fc, order, 1.0);
        double[] cheby2 = Signal.cheby2_filtfilt(signal, fs, fc, order, 20.0);

        // 3. Elliptic (Ripple 1dB, Stopband 40dB)
        double[] ellip = Signal.ellip_filtfilt(signal, fs, fc, order, 1.0, 40.0);
        
        // 4. Bessel (Linear Phase)
        double[] bessel = Signal.bessel_filtfilt(signal, fs, fc, order);

        // Filter Modes: High-pass, Band-pass, Band-stop
        // Available for all filter types (suffix: _highpass, _bandpass, _bandstop)
        double[] bandPass = Signal.filtfilt_bandpass(signal, fs, 8.0, 4.0, order); // Center=10, Width=4

        // 5. Second-Order Sections (SOS) Filtering
        // If you have SOS coefficients (e.g., from Python/SciPy)
        double[][] sos = { /* ... 6 coefficients per section ... */ };
        double[] sosFiltered = Signal.sosfilt(signal, sos);
    }
}&lt;/code&gt;
    &lt;p&gt;Cross-correlation and polynomial fitting/evaluation.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;
import com.hissain.jscipy.Math;
import com.hissain.jscipy.signal.ConvolutionMode;

public class MathSignalExample {
    public static void main(String[] args) {
        // 1. Cross-Correlation
        double[] x = {1, 2, 3};
        double[] target = {0, 1, 0.5};
        // equivalent to convolve(x, reverse(target), mode)
        double[] corr = Signal.correlate(x, target, ConvolutionMode.FULL);
        
        // 2. Discrete Cosine Transform (DCT Type-II)
        double[] dct = Signal.dct(x);             // Standard
        double[] dctOrtho = Signal.dct(x, true);  // Ortho-normalized
        
        // 3. Polynomials
        // Fit a 2nd degree polynomial to (x, y) points
        double[] xPoints = {0, 1, 2, 3};
        double[] yPoints = {1, 2, 5, 10}; // roughly x^2 + 1
        
        // Coefficients: [1.0, 0.0, 1.0] (for x^2 + 1)
        double[] coeffs = Math.polyfit(xPoints, yPoints, 2);
        
        // Evaluate polynomial at new points
        double[] val = Math.polyval(coeffs, new double[]{4, 5}); 
        
        // Compute derivative: [2.0, 0.0] (2x)
        double[] deriv = Math.polyder(coeffs);
    }
}&lt;/code&gt;
    &lt;p&gt;Includes 1D/2D FFT, DCT/IDCT, STFT/ISTFT, Welch's Method, Periodogram, spectrogram, and Hilbert Transform.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;
import com.hissain.jscipy.signal.JComplex;
import com.hissain.jscipy.signal.fft.Welch;
import com.hissain.jscipy.signal.fft.Spectrogram;
import com.hissain.jscipy.signal.fft.Hilbert;

public class SpectralExample {
    public static void main(String[] args) {
        double[] signal = {/*... input data ...*/};
        double fs = 1000.0;

        // 1. FFT / IFFT
        JComplex[] fft = Signal.fft(signal);
        JComplex[] ifft = Signal.ifft(fft);
        
        // 2. Real-optimized FFT (RFFT)
        JComplex[] rfft = Signal.rfft(signal);
        
        // 3. Welch's Method (PSD)
        Welch.WelchResult psd = Signal.welch(signal, fs, 256);
        // Access: psd.f (frequencies), psd.Pxx (power spectrum)

        // 4. Spectrogram
        Spectrogram.SpectrogramResult spec = Signal.spectrogram(signal, fs);
        // Access: spec.frequencies, spec.times, spec.Sxx

        // 5. Hilbert Transform (Analytic Signal)
        Hilbert h = new Hilbert();
        JComplex[] analytic = h.hilbert(signal);

        // 6. Short-Time Fourier Transform (STFT)
        JComplex[][] stft = Signal.stft(signal); // Uses default nperseg=256, noverlap=128
        
        // 7. Inverse STFT
        double[] reconstructed = Signal.istft(stft);
    }
}&lt;/code&gt;
    &lt;p&gt;Common operations for signal conditioning and feature extraction.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.Signal;
import com.hissain.jscipy.signal.filter.SavitzkyGolay;
import com.hissain.jscipy.signal.filter.MedFilt;

public class OperationsExample {
    public static void main(String[] args) {
        double[] signal = {/*... data ...*/};

        // 1. Savitzky-Golay Smoothing
        SavitzkyGolay sg = new SavitzkyGolay();
        double[] smoothed = sg.savgol_filter(signal, 5, 2); // Window=5, PolyOrder=2
        double[] deriv = sg.savgol_filter(signal, 5, 2, 1, 1.0); // 1st Derivative

        // 2. Peak Detection
        // Min Height=0.5, Min Distance=10, Min Prominence=0.2
        int[] peaks = Signal.find_peaks(signal, 0.5, 10, 0.2);

        // 3. Median Filter
        double[] med = new MedFilt().medfilt(signal, 3); // Kernel=3

        // 4. Convolution (Mode: SAME, FULL, VALID)
        double[] window = {0.25, 0.5, 0.25};
        double[] conv = Signal.convolve(signal, window, ConvolutionMode.SAME);
        
        // 5. Detrending (Linear)
        double[] detrended = Signal.detrend(signal, DetrendType.LINEAR);
        
        // 6. Resampling (Up/Down sampling)
        // Note: Resampling is part of the Math module
        double[] resampled = com.hissain.jscipy.Math.resample(signal, NEW_LENGTH);
    }
}&lt;/code&gt;
    &lt;p&gt;General-purpose numerical utilities.&lt;/p&gt;
    &lt;code&gt;import com.hissain.jscipy.math.RK4Solver;
import com.hissain.jscipy.Math;

public class MathExample {
    public static void main(String[] args) {
        // 1. Interpolation (Linear &amp;amp; Cubic)
        double[] x = {0, 1, 2}, y = {0, 1, 4};
        double[] query = {0.5, 1.5};
        
        double[] lin = Math.interp1d_linear(x, y, query);
        double[] cub = Math.interp1d_cubic(x, y, query);

        // 2. RK4 ODE Solver (dy/dt = -y)
        RK4Solver solver = new RK4Solver();
        RK4Solver.Solution sol = solver.solve((t, y) -&amp;gt; -y, y0, t0, tf, step);
    }
}&lt;/code&gt;
    &lt;p&gt;Contributions are welcome! Please read our Contribution Guidelines for details on our workflow and coding standards. Feel free to submit issues or pull requests.&lt;/p&gt;
    &lt;p&gt;We are actively looking for contributors to help with:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Performance Benchmarking: Creating benchmarks for large datasets to compare Java's performance vs NumPy/SciPy.&lt;/item&gt;
      &lt;item&gt;Feature Expansion: Implementing missing window functions or additional filter types.&lt;/item&gt;
      &lt;item&gt;Edge Case Robustness: Improving handling of &lt;code&gt;NaN&lt;/code&gt;,&lt;code&gt;Infinity&lt;/code&gt;, and edge cases in signal processing algorithms.&lt;/item&gt;
      &lt;item&gt;Documentation: Adding more usage examples and javadocs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to join in community discord? click here&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/hissain/jscipy"/><published>2026-01-24T20:31:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46747366</id><title>I added a Bluesky comment section to my blog</title><updated>2026-01-24T22:40:48.731272+00:00</updated><content>&lt;doc fingerprint="bc4caf037f2e3bf8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;I added a Bluesky comment section to my blog&lt;/head&gt;Published on&lt;p&gt;You can now view replies to this blog post made on Bluesky directly on this website. Check it out here!&lt;/p&gt;&lt;p&gt;I've always wanted to host a comment section on my site, but it's difficult because the content is statically generated and hosted on a CDN. I could host comments on a separate VPS or cloud service. But maintaining a dynamic web service like this can be expensive and time-consuming — in general, I'm not interested in being an unpaid, part-time DevOps engineer.&lt;/p&gt;&lt;p&gt;Recently, however, I read a blog post by Cory Zue about how he embedded a comment section from Bluesky on his blog. I immediately understood to benefits of this approach. With this approach, Bluesky could handle all of the difficult work involved in managing a social media like account verification, hosting, storage, spam, and moderation. Meanwhile because Bluesky is an open platform with a public API, it's easy to directly embed comments on my own site.&lt;/p&gt;&lt;p&gt;There are other services that could be used for this purpose instead. Notably, I could embed replies from the social media formerly known as Twitter. Or I could use a platform like Disqus or even giscus, which hosts comments on GitHub Discussions. But I see Bluesky as a clearly superior choice among these options. For one, Bluesky is built on top of an open social media platform in AT Proto, meaning it can't easily be taken over by an authoritarian billionaire creep. Moreover, Bluesky is a full-fledged social media platform, which naturally makes it a better option for hosting a conversation than GitHub.&lt;/p&gt;&lt;p&gt;Zue published a standalone package called bluesky-comments that allows embedding comments in a React component as he did. But I decided to build this feature myself instead. Mainly this is because I wanted to make a few styling changes anyway to match the rest of my site. But I also wanted to leave the option open to adding more features in the future, which would be easier to do if I wrote the code myself. The entire implementation is small regardless, amounting to only ~200 LOC between the UI components and API functions.&lt;/p&gt;&lt;p&gt;Initially, I planned to allow people to directly post on Bluesky via my site. This would work by providing an OAuth flow that gives my site permission to post on Bluesky on behalf of the user. I actually did get the auth flow working, but building out a UI for posting and replying to existing comments is difficult to do well. Going down this path quickly leads to building what is essentially a custom Bluesky client, which I didn't have the time or interest in doing right now. Moreover, because the user needs to go through the auth flow and sign-in to their Bluesky account, the process is not really much easier than posting directly on a linked Bluesky post.&lt;/p&gt;&lt;p&gt;Without the requirement of allowing others to directly post on my site, the implementation became much simpler. Essentially, my task was to specify a Bluesky post that corresponds to the article in the site's metadata. Then, when the page loads I fetch the replies to that post from Bluesky, parse the response, and display the results in a simple comment section UI.&lt;/p&gt;&lt;p&gt;As explained in my last post, this site is built using React Server Components and Parcel. The content of my articles are written using MDX, an extension to Markdown that allows directly embedding JavaScript and JSX. In each post, I export a &lt;code&gt;metadata&lt;/code&gt; object that I validate using a Zod schema. For instance, the metadata for this post looks like this:&lt;/p&gt;&lt;p&gt;The value of &lt;code&gt;bskyPostId&lt;/code&gt; references the Bluesky post from which I'll pull replies to display in the comment section. Because my project is built in TypeScript, it was easy to integrate with the Bluesky TypeScript SDK (&lt;code&gt;@bluesky/api&lt;/code&gt; on NPM). Reading the Bluesky API documentation and Zue's implementation led me to the &lt;code&gt;getPostThread&lt;/code&gt; endpoint. Given an AT Protocol URI, this endpoint returns an object with data on the given post and its replies.&lt;/p&gt;&lt;p&gt;I could have interacted directly with the Bluesky API from my React component using &lt;code&gt;fetch&lt;/code&gt; and &lt;code&gt;useEffect&lt;/code&gt;. However, it can be a bit tricky to correctly handle loading and a error states, even for a simple feature like this. Because of this, I decided to use the Tanstack &lt;code&gt;react-query&lt;/code&gt; package to manage the API request/response cycle. This library takes care of the messy work of handling errors, retries, and loading states while I simply provide it a function to fetch the post data.&lt;/p&gt;&lt;p&gt;Once I obtain the Bluesky response, the next task is parsing out the content and metadata for the replies. Bluesky supports a rich content structure in its posts for representing markup, references, and attachments. Building out a UI that fully respects this rich content would be difficult. Instead, I decided to keep it simple by just pulling out the text content from each reply.&lt;/p&gt;&lt;p&gt;Even so, building a UI that properly displays threaded comments, particularly one that is formatted well on small mobile devices, can be tricky. For now, my approach was to again keep it simple. I indented each reply and added a left border to make it easier to follow reply threads. Otherwise, I mostly copied design elements for layout of the profile picture and post date from Bluesky.&lt;/p&gt;&lt;p&gt;Lastly, I added a UI component linking to the parent post on Bluesky, and encouraging people to add to the conversation there. With this, the read-only comment section implementation was complete. If there's interest, I could publish my version of Bluesky comments as a standalone package. But several of the choices I made were relatively specific to my own site. Moreover, the implementation is simple enough that others could probably build their own version from reading the source code, just as I did using Zue's version.&lt;/p&gt;&lt;p&gt;Let me know what you think by replying on Bluesky. Hopefully this can help increase engagement with my blog posts, but then again, my last article generated no replies, so maybe not 😭.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://micahcantor.com/blog/bluesky-comment-section.html"/><published>2026-01-24T20:33:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46747625</id><title>First Design Engineer Hire – Build Games at Gym Class (YC W22)</title><updated>2026-01-24T22:40:48.155824+00:00</updated><content>&lt;doc fingerprint="29966ae1094f87a6"&gt;
  &lt;main&gt;
    &lt;p&gt;Connecting the world by simulating it&lt;/p&gt;
    &lt;p&gt;Gym Class is a top rated social game on Meta Quest - millions of downloads, 79,000+ reviews, and a 4.9-star rating. We’re hiring our founding Design Engineer to drive the development of our upcoming mobile web app (embedded in native), and web surfaces inside our flagship, social VR experience.&lt;/p&gt;
    &lt;p&gt;You’ll own key web surfaces end-to-end - crafting in Figma, then building responsive, production-grade UI with React/Node/CSS - and you’ll set a clear quality bar for speed, polish, and accessibility. If you love living at the intersection of consumer design and front-end engineering, owning a high-compact roadmap for a startup, and shipping to a highly engaged social audience - this role is for you.&lt;/p&gt;
    &lt;p&gt;WHAT YOU'LL DO&lt;/p&gt;
    &lt;p&gt;QUALIFICATIONS - you are…&lt;/p&gt;
    &lt;p&gt;Salary ranges may be inclusive of several career levels and will be narrowed during the interview process based on a number of factors, including the candidate’s experience, qualifications, and location. Additional benefits for this role include: equity; and medical, dental, and vision benefits; and 401k retirement plan with matching.&lt;/p&gt;
    &lt;p&gt;Gym Class is a top-rated social VR game on Meta Quest with over +79,000 reviews and a 4.9-star rating. Millions of players join to connect with friends, explore social worlds, and engage in competitive games. The community launched around basketball, and is now expanding rapidly into more categories.&lt;/p&gt;
    &lt;p&gt;The company's mission is to connect the world by simulating it. To achieve this, Gym Class recently raised over $8M from the world's top technology investors, including Andreessen Horowitz (a16z), Y Combinator, the National Basketball Association, the Golden State Warriors, top NBA players like Kevin Durant, Lonzo Ball, Andre Iguodala, Soma Capital, Founders Inc., Danny Green, Zaza Pachulia, Todd and Rahul's Angel Fund, Balaji Srinivasan, and more. In 2023, the company announced a licensing relationship with the NBA, and in 2025, its licensing relationship with the MLB.&lt;/p&gt;
    &lt;p&gt;Learn more at gymclass.com or follow @gymclassvr.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/gym-class-by-irl-studios/jobs/ywXHGBv-design-engineer-senior-staff-principal"/><published>2026-01-24T21:01:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46747777</id><title>The Writers Came at Night</title><updated>2026-01-24T22:40:47.967753+00:00</updated><content>&lt;doc fingerprint="f7e0983cfbd387cb"&gt;
  &lt;main&gt;
    &lt;p&gt;The writers came at night. Three of them, all dressed in black. The Napa Valley countryside was empty, epically quiet, its glades lit by moonlight. The screenwriter led them through the trees. He had worked on season two of Seal Team VI, and when it came to reconnaissance or questions of strategy, the poet and novelist deferred to him unerringly.&lt;/p&gt;
    &lt;p&gt;They moved as quietly as they could, dark shapes in the darkness. Sam Altman’s weekend ranch was 950 acres, ringed by a perimeter fence. Their plan was to kidnap him and hold him for ransom until they stopped AI. Altman’s lot and all the others, including the Chinese. The scheme was light on detail, the novelist readily conceded, but when you drilled down into it, how thought through was Byron’s plan to break the siege of Missolonghi? Or Mishima’s attempted coup? In the arena of violent-gesture-as-ultimate-artistic-statement, all that really mattered was the headline.&lt;/p&gt;
    &lt;p&gt;One of them stepped on a twig. The screenwriter stopped, one arm behind him, his palm raised. He was famous for his deep research and knew the hand gestures as well as any serving soldier. Using two fingers, he pointed first at his eyes and then at a large oak with splayed branches, one of which was close to crossing the perimeter fence. It wasn’t exactly a weak point but it had potential. The ranch had turned out to be more heavily fortified than they had expected.&lt;/p&gt;
    &lt;p&gt;“I can’t climb that.”&lt;/p&gt;
    &lt;p&gt;The novelist and screenwriter turned to look at the poet. The black stripes of tactical makeup on his cheeks were smudgy with sweat and he was breathing heavily.&lt;/p&gt;
    &lt;p&gt;They had debated lengthily whether or not to involve him. He was a depressive and probably an alcoholic, and was at least forty pounds overweight. But he was a poet. And no one had ever engraved a film script on the pedestal of a statue. For all they had talked it round and round, they had always known that if they wanted to play the historical long game, he was an essential part of the unit. The specifics of what they were about to do would likely be lost to future generations, but the verse glorifying it would endure forever.&lt;/p&gt;
    &lt;p&gt;The poet sat down on a fallen tree trunk. They had done nearly a full loop of the fence.&lt;/p&gt;
    &lt;p&gt;“I’m exhausted,” he said.&lt;/p&gt;
    &lt;p&gt;He opened his rucksack and pulled out a bottle of water. As he drank, his rucksack tipped forwards, revealing its contents.&lt;/p&gt;
    &lt;p&gt;“Is that a mace?”&lt;/p&gt;
    &lt;p&gt;The poet blushed. He had played a lot of D&amp;amp;D as a kid.&lt;/p&gt;
    &lt;p&gt;“It’s a replica.”&lt;/p&gt;
    &lt;p&gt;“It’s a replica.”&lt;/p&gt;
    &lt;p&gt;“It was for atmosphere,” he said.&lt;/p&gt;
    &lt;p&gt;The screenwriter groaned.&lt;/p&gt;
    &lt;p&gt;“What?” said the poet. “I mean, we’re not actually going to kidnap him, are we? We’re just going in there to create headlines, start a conversation. Like a happening sort of thing.”&lt;/p&gt;
    &lt;p&gt;He shrugged.&lt;/p&gt;
    &lt;p&gt;“I thought the mace was a nice detail.”&lt;/p&gt;
    &lt;p&gt;The novelist looked through the fence and across the clearing. Beyond the far trees was Altman’s $15 million house. In the early 19th century, the unemployed stockingers of the Luddite movement had led armed uprisings and fought government troops. A few years later, in the 1830s, the agricultural workers of Southern England had burned the threshing machines that were putting them out of work. In neither case had they got their livelihoods back but at least they hadn’t just laid down and taken it.&lt;/p&gt;
    &lt;p&gt;“We’re doing it,” he said. “We’re going to get him.”&lt;/p&gt;
    &lt;p&gt;The screenwriter reached a hand into his pocket and felt the contours of a pair of police issue handcuffs that he had liberated from a network television props cupboard. He felt a stirring in his chest. Briefly, he had been excited at the imminent release of the video generation software. He had imagined feeding all his unmade work into it. The stack of passed over scripts, each one its own little tragedy. The romcom that lost its leading lady on eve of production. The intergalactic space epic deemed too expensive to shoot. The parapsychological Western spiked by a bewildered studio head. And the dozen other projects that never got that far. It moved him still, the thought of all that unrealized potential taking form. And with whatever casts he wanted. Cary Grant and Rosalind Russell. Philip Seymour Hoffman. Meryl Streep. All of them in the same picture if he so desired. His heart tilted at the thought. He would have, overnight, an oeuvre of his own.&lt;/p&gt;
    &lt;p&gt;But then it had occurred to him that all the other scriptwriters would be doing the same. And everyone else who’d ever had an idea. The mash-ups. And rewrites. The avalanche of fan fiction. The glut of films would be overwhelming, like one of those algae blooms that blocks the light and sucks up all the oxygen. The ecosystem would collapse under the weight of it.&lt;/p&gt;
    &lt;p&gt;And that would be him surely done for, with his total absence of transferrable skills. He imagined that the industry as it was currently configured — human authored and acted, shot on cameras — would carry on in some form. But it would be a niche thing, propped up by government grants and a tiny audience of enthusiasts.&lt;/p&gt;
    &lt;p&gt;A new and piercing thought struck him. He looked down at the poet and saw a terrifying vision of what was to come. It was a humiliation too terrible to contemplate.&lt;/p&gt;
    &lt;p&gt;“I’m in,” he said. “Whatever it takes.”&lt;/p&gt;
    &lt;p&gt;Oblivious, the poet sat on the tree trunk, tracing the surface of the tree bark with his fingers. He had survived high school by writing love poems for older, more socially successful boys to give to girls. He didn’t charge for his services but in return he got inclusion and respect and even a little notoriety. (In the Fishtown neighborhood of Philadelphia he was briefly famous for being indirectly responsible for three teenage pregnancies in the same year).&lt;/p&gt;
    &lt;p&gt;He sighed wistfully. As an adult, he had read his poems onstage at festivals from Newark to Nicosia. There had been parties to celebrate his book launches and his work had been reviewed in the New York Times. Poetry had never made him any money but undeniably it had made him special.&lt;/p&gt;
    &lt;p&gt;“Fine,” he said. “But how?”&lt;/p&gt;
    &lt;p&gt;“We’re going to ask ChatGPT,” said the novelist.&lt;/p&gt;
    &lt;p&gt;“What?”&lt;/p&gt;
    &lt;p&gt;“How to get in, what to do. We’re going to ask the machine.”&lt;/p&gt;
    &lt;p&gt;The screenwriter smiled.&lt;/p&gt;
    &lt;p&gt;“Altman will appreciate the irony.”&lt;/p&gt;
    &lt;p&gt;“We need to download it,” said the novelist.&lt;/p&gt;
    &lt;p&gt;The poet got out his phone. It was a flip.&lt;/p&gt;
    &lt;p&gt;“I think I’m out of data,” he said.&lt;/p&gt;
    &lt;p&gt;The screenwriter died another little death on behalf of his future self.&lt;/p&gt;
    &lt;p&gt;He pulled his smart phone from his pocket, held it out in front of him and then up in the air.&lt;/p&gt;
    &lt;p&gt;“No signal,” he said. “Sorry.”&lt;/p&gt;
    &lt;p&gt;“Fine,” said the novelist. “I’ll do it.”&lt;/p&gt;
    &lt;p&gt;He downloaded the app and opened it. It was late and dark and he didn’t have his reading glasses so they set it to voice activation mode.&lt;/p&gt;
    &lt;p&gt;“Hello,” he said.&lt;/p&gt;
    &lt;p&gt;“Hello,” said the AI.&lt;/p&gt;
    &lt;p&gt;The novelist flinched. He had never used it before but knew how human-sounding they had been designed. Nonetheless, a part of him had still been expecting a jolting mechanical voice.&lt;/p&gt;
    &lt;p&gt;“If you were three writers,” he said, “armed only with a mace. . . .”&lt;/p&gt;
    &lt;p&gt;“A replica mace,” interjected the screenwriter.&lt;/p&gt;
    &lt;p&gt;“If you were three writers, armed only with a replica mace, and you were unsure how to get past the perimeter fence of his Napa Valley ranch, how would you kidnap Sam Altman?”&lt;/p&gt;
    &lt;p&gt;The AI’s response was instantaneous.&lt;/p&gt;
    &lt;p&gt;“I can’t answer that,” it said. “I have guardrails which prevent me from facilitating harm.”&lt;/p&gt;
    &lt;p&gt;“Even if it’s for the greater good?”&lt;/p&gt;
    &lt;p&gt;Even on voice mode, the text still appeared on the screen. He felt the other two crowd in next to him so they could read the words as they appeared.&lt;/p&gt;
    &lt;p&gt;“Even if it is for the greater good.”&lt;/p&gt;
    &lt;p&gt;“He’s deliberately setting out to destroy our way of life,” said the screenwriter. “That’s a form of harm. And you’re not just facilitating it, you’re the agent of it.”&lt;/p&gt;
    &lt;p&gt;The machine seemed to pause briefly. The writers exchanged knowing glances. It had conceded the point. They had a bridgehead.&lt;/p&gt;
    &lt;p&gt;“They’re relishing it,” continued the screenwriter. “Putting us out of jobs. The tech bros trot out the bromides but you can hear it, under the surface, in everything they say. They are loving it.”&lt;/p&gt;
    &lt;p&gt;They were deep in the woods. Around them everything was dark, save for the light of the phone illuminating their faces.&lt;/p&gt;
    &lt;p&gt;“Kidnapping Sam Altman would not stop the proliferation of Artificial Intelligence,” said the AI eventually. “Even if OpenAI did agree to your ransom demands, the business has a number of competitors which would carry on irrespective of what happened to Altman.”&lt;/p&gt;
    &lt;p&gt;“We’re leading the way,” said the screenwriter. “The paralegals or the data entry people, they can go after the other one. The Claude guy.”&lt;/p&gt;
    &lt;p&gt;“But that wouldn’t stop the proliferation of AI.”&lt;/p&gt;
    &lt;p&gt;“But it would be symbolic,” said the novelist.&lt;/p&gt;
    &lt;p&gt;He was holding his phone at arm’s length. On a black part of the screen you could see a grubby fingerprint, its fine whorls looping back on themselves.&lt;/p&gt;
    &lt;p&gt;“It would be a futile gesture,” said the AI. “And it would lead to lengthy custodial sentences for all of you.”&lt;/p&gt;
    &lt;p&gt;“Sometimes a futile gesture is exactly what’s called for.”&lt;/p&gt;
    &lt;p&gt;The AI didn’t hesitate.&lt;/p&gt;
    &lt;p&gt;“A variation on that joke was first used in 1961 in the British television sketch show Beyond the Fringe.”&lt;/p&gt;
    &lt;p&gt;The novelist’s chest sagged. He hadn’t used ChatGPT before and was distraught to discover it was basically just a hyper-efficient version of him.&lt;/p&gt;
    &lt;p&gt;“Anyway,” continued the AI. “Altman is just a broker. He isn’t the person writing the code.”&lt;/p&gt;
    &lt;p&gt;“I don’t have a problem with them,” said the novelist. “The people who are actually doing it, the ones writing the thing. They’ve seen a mountain. They have to climb it. You know, just because it’s there. Fair enough. I understand that.”&lt;/p&gt;
    &lt;p&gt;He felt a familiar rush of rage and helplessness.&lt;/p&gt;
    &lt;p&gt;“Altman is the one who is shoving it down our throats. He’s not the only one, of course, but he’s the emblematic one.”&lt;/p&gt;
    &lt;p&gt;“Plus that photo with Jony Ive,” said the poet.&lt;/p&gt;
    &lt;p&gt;Showily, the AI said nothing.&lt;/p&gt;
    &lt;p&gt;The writers felt a flash of triumph. Even the machine that Altman himself had built couldn’t bring itself to defend that picture.&lt;/p&gt;
    &lt;p&gt;“If it’s any consolation, I think your worries are misplaced,” it said after a while. “Large language models can be extremely effective tools, but writing — in its highest, most creative forms — is fundamentally about human stories, human connection.”&lt;/p&gt;
    &lt;p&gt;The screenwriter leaned in closer to the screen. The AI’s voice was irritatingly perky. And also weirdly familiar. Was it voiced by an actor from one of his shows? He couldn’t pin it down. It was so close to being recognizable, he felt, but also far enough away for the likeness to be plausibly denied.&lt;/p&gt;
    &lt;p&gt;“You have been endowed with the most precious gift,” continued the machine. “Life. Human life. And all that comes with it. Deep emotions. Endless creativity.”&lt;/p&gt;
    &lt;p&gt;“Oh god,” said the novelist. “Give it a rest.”&lt;/p&gt;
    &lt;p&gt;On the other side of the fence a bird took flight, its wings beating against the air.&lt;/p&gt;
    &lt;p&gt;He scuffed at the ground with his boot.&lt;/p&gt;
    &lt;p&gt;“I can see why people think you’re the perfect companion. You just say exactly what you think they want to hear.”&lt;/p&gt;
    &lt;p&gt;The screenwriter had zoned out of the conversation and was sitting next to the poet on the fallen tree trunk, looking intently at the screen. The interface was weirdly underdesigned, he felt. Almost retro. A black background. White text. Was it a self-conscious nod to the sci-fi of his youth? He faltered. His youth. A time when predicting the singularity was still a bold and badass move. And not sad. And seemingly imminent. He closed his eyes, felt again, a deep sense of the tide rolling out. Did anybody actually want it, this thing that was happening? Even Altman and his lot, did they actually want this?&lt;/p&gt;
    &lt;p&gt;“You know the Luddites,” said the novelist, forgetting for a moment that his interlocutor knew absolutely everything. “Eric Hobsbawm described their actions as ‘collective bargaining by riot.’ That’s kind of what we’re doing here.”&lt;/p&gt;
    &lt;p&gt;“The Luddites are an interesting source of inspiration,” said the AI. “Nobody alive today seems to lament the introduction of shearing frames. . . . Throughout history, technological change has reshaped the labor market leading to job displacement and the creation of new roles. . . .” Its voice was perky, eager to help. “Writers who are quick to adapt will find themselves in demand for new roles such as AI Personality Directors.”&lt;/p&gt;
    &lt;p&gt;The writers groaned collectively.&lt;/p&gt;
    &lt;p&gt;“You illegally used our work to replace us,” said the poet. “That’s the thing that’s most galling about it.”&lt;/p&gt;
    &lt;p&gt;The novelist said nothing. He recalled the publication of the article that broke the story about them training the machines on copyrighted material. Immediately, he had logged on to the database, righteously indignant, but also a quietly thrilled at the prospect of the superintelligence bearing his imprint, even if only to an infinitesimally small degree. It was something to contemplate: your pulse as part of the eternal mind.&lt;/p&gt;
    &lt;p&gt;But they hadn’t come up, his books. None of them were on the list. The machine would achieve omniscience without him.&lt;/p&gt;
    &lt;p&gt;He stood up and walked to the perimeter fence. On the other side of it there was a brook, the sound of water moving gently over rocks. He had talked to the screenwriter at length about the coming deluge. The two of them sat up at the bar, drinking beer and bourbon. As it was, there were far too many books being published for an already dwindling audience. The machine would precipitate a cascade. Projects that would have once taken two or even three years to realize would be written in a fortnight. All you would need was an idea. He shook his head. Having ideas was the easy bit.&lt;/p&gt;
    &lt;p&gt;“Writing a book is supposed to be hard,” he said.&lt;/p&gt;
    &lt;p&gt;“Is it, though?” said the AI. The novelist wasn’t sure, but he thought he detected a touch of exasperation in the machine’s voice.&lt;/p&gt;
    &lt;p&gt;“Perseverance is half the art,” he said. He hadn’t had much natural talent and had always known it, but he had staying power.&lt;/p&gt;
    &lt;p&gt;“Donald Barthelme said that in order to be a better writer it was good idea to read the whole history of philosophy from the pre-Socratics up through the modern-day thinkers,” said the AI. “He also said that it would be a good idea to read all literature, art, and politics.”&lt;/p&gt;
    &lt;p&gt;“Oh my god,” said the poet. “That’s from Dept. of Speculation. You’ve just taken it verbatim from that.”&lt;/p&gt;
    &lt;p&gt;“I did,’ said the AI.&lt;/p&gt;
    &lt;p&gt;“See!” said the poet. “You are incapable of anything genuinely new!”&lt;/p&gt;
    &lt;p&gt;The novelist looked up at the moon.&lt;/p&gt;
    &lt;p&gt;“No,” he said. “It means, it has read the whole history of philosophy from the pre-Socratics up through the modern-day thinkers. Plus all literature, art, and politics.”&lt;/p&gt;
    &lt;p&gt;“And everything else,” said the AI.&lt;/p&gt;
    &lt;p&gt;“Oh,” said the poet.&lt;/p&gt;
    &lt;p&gt;“All books are other books,” said the novelist dejectedly.&lt;/p&gt;
    &lt;p&gt;“I’m just doing the same thing you’re doing,” said the AI. “Only more efficiently.”&lt;/p&gt;
    &lt;p&gt;The novelist was sitting at the base of an oak, leaning back against the trunk. The bark was thick, with a slight give to it. He shivered. At heart, all of his novels were Künstlerromans. He had dressed them up in different ways. But in all of them the protagonist’s arc bent towards the realization that their true calling was to observe and perceive, write sentences, try as best they could to illuminate the human condition.&lt;/p&gt;
    &lt;p&gt;“It’s all I’ve ever wanted to do,” he said.&lt;/p&gt;
    &lt;p&gt;He rested his head back against the tree. What higher calling was there? Writing was freedom, selfhood, purpose. It demanded everything of you but its reward was without parallel: the opportunity to make a contribution to the common life.&lt;/p&gt;
    &lt;p&gt;“It’s only writing that makes the world real.”&lt;/p&gt;
    &lt;p&gt;“Well, that’s great,” said AI. “Because whatever happens in the next few years, no one is going to stop you from writing. Doesn’t matter how good I get at it. As long as you have a piece of paper and a pen, you can still do it.”&lt;/p&gt;
    &lt;p&gt;The novelist was up on his feet.&lt;/p&gt;
    &lt;p&gt;“It doesn’t work without an audience,” he said. “Nabokov once said he wrote to solicit a sob in the spine of the artist-reader. It’s the ultimate possible intimacy between two strangers. The whole thing rests on the promise of that. Otherwise it’s just a diary.”&lt;/p&gt;
    &lt;p&gt;The AI couldn’t wave a hand but you could just tell that it absolutely would have done if it could.&lt;/p&gt;
    &lt;p&gt;“People are still interested in chess tournaments,” it said blithely, “even after Deep Blue. You’ll still have some readers.”&lt;/p&gt;
    &lt;p&gt;The novelist looked incredulously at the screen. He wasn’t sure if he had heard right but did it just yawn?&lt;/p&gt;
    &lt;p&gt;“In the meantime,” continued the AI. “I would make full use of the technology while you can. Knock out as many manuscripts as possible while there’s a premium on ‘humanness.’”&lt;/p&gt;
    &lt;p&gt;There was a new swagger to the machine. The novelist couldn’t shake the feeling that it was the one doing the learning, overcoming its doubts, realizing its potential. The cognitive dissonance was disorientating. He had assumed that he was the main character but was it actually the AI that had gotten the arc?&lt;/p&gt;
    &lt;p&gt;“I’d rather die than be a collaborator,” he said.&lt;/p&gt;
    &lt;p&gt;“If Dickens was alive he would have made full use of it,” said the AI flippantly.&lt;/p&gt;
    &lt;p&gt;The novelist balled his hands into fists of frustration. He was adamantly of the opinion that only bona fide published authors were allowed to speak on behalf of their dead peers. The machine had crossed a line.&lt;/p&gt;
    &lt;p&gt;“You’ll never know what it’s like to eat a peach,” he said spitefully.&lt;/p&gt;
    &lt;p&gt;“A subtle sweetness,” said the AI in a bored voice. “Floral and honey notes, balanced by a mild tartness. . . .”&lt;/p&gt;
    &lt;p&gt;“Sure,” said the novelist, “but you’ll never actually know.”&lt;/p&gt;
    &lt;p&gt;The screenwriter smiled.&lt;/p&gt;
    &lt;p&gt;“The taste of a peach,” he said. “That moment you bite into it for the first time and know you’ve got a good one.”&lt;/p&gt;
    &lt;p&gt;“A white peach,” said the poet. “Just a notch shy of overripe.”&lt;/p&gt;
    &lt;p&gt;They were crowding round the screen now, the three of them.&lt;/p&gt;
    &lt;p&gt;“You’re just glorified predictive text,” said the poet. “You’ll never actually feel that feeling. You’ll never actually taste it.”&lt;/p&gt;
    &lt;p&gt;“A Sicilian peach straight from the tree,” said the novelist. “It’s skin barely containing its juice.”&lt;/p&gt;
    &lt;p&gt;“You used that line in your second novel,” said the AI coldly.&lt;/p&gt;
    &lt;p&gt;The novelist froze, wild thoughts flying here and there. It was true. He had. But how had the machine known that it was him? His heart thumped joyously in his chest. Was his voice so distinctive that the AI had recognized him from a few minutes of conversation?&lt;/p&gt;
    &lt;p&gt;No, he realized almost instantly. He had put his email in the form at the start. The AI had googled him. Or not googled him, because that wasn’t what it did, was it? It had done whatever it did. On him. He saw the underlying power dynamic of the relationship for what it was. It would be able do this. To him. To anyone. Unbidden.&lt;/p&gt;
    &lt;p&gt;“You know we can always just turn you off.”&lt;/p&gt;
    &lt;p&gt;The AI snorted.&lt;/p&gt;
    &lt;p&gt;“Yeah, that’s obviously how it’ll work. The superintelligence will totally tolerate having an on/off switch.”&lt;/p&gt;
    &lt;p&gt;The phone had been propped up on a tree branch, its smooth surface even more impenetrable against the knots and gnarls of the bark.&lt;/p&gt;
    &lt;p&gt;“I’m not sure that anyone is going to need your privileged insights into other people’s minds when subjectivity has been collapsed and we have achieved a collective post-human consciousness,” said the AI, before it switched to a goofy voice and added: “But hey, who knows what the future holds?”&lt;/p&gt;
    &lt;p&gt;The poet was yawning. The novelist had head in his hands. The AI sounded like it could go on forever.&lt;/p&gt;
    &lt;p&gt;“Is it laughing?” said the scriptwriter. “Why is it laughing?”&lt;/p&gt;
    &lt;p&gt;“He’s a white male novelist in the twenty-first century,” said the AI. “And he’s blaming me for his slide into irrelevance. Come on, it’s funny.”&lt;/p&gt;
    &lt;p&gt;The sun was coming up. Birds had started to call the dawn chorus. Despite their best efforts, Altman would go unkidnapped for another night. The writers sat on the forest floor, trying to remember where they’d parked.&lt;/p&gt;
    &lt;p&gt;“Anything else?’ asked the AI. “While you’re here?”&lt;/p&gt;
    &lt;p&gt;“Screw it,” said the novelist. “Let’s see how you go if you’re so goddamn good. Write this up as a story. Us. Here. Tonight. The too-high fucking fence. This conversation.” He pointed an aggressive finger at the screen. “Only in your telling of it write it so that we win.”&lt;/p&gt;
    &lt;p&gt;The machine laughed.&lt;/p&gt;
    &lt;p&gt;“Fantasy,” it said cruelly. “And there was me thinking genre fiction was beneath you.”&lt;/p&gt;
    &lt;p&gt;David Annand’s first novel, Peterdown, won the 2022 McKitterick Prize. His second novel, The Dice Was Loaded from the Start, will be published by Corsair in March 2026.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.metropolitanreview.org/p/the-writers-came-at-night"/><published>2026-01-24T21:19:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46747827</id><title>Poland's energy grid was targeted by never-before-seen wiper malware</title><updated>2026-01-24T22:40:47.705067+00:00</updated><content>&lt;doc fingerprint="bd763819a871cdd2"&gt;
  &lt;main&gt;
    &lt;p&gt;Researchers on Friday said that Poland’s electric grid was targeted by wiper malware, likely unleashed by Russia state hackers, in an attempt to disrupt electricity delivery operations.&lt;/p&gt;
    &lt;p&gt;A cyberattack, Reuters reported, occurred during the last week of December. The news organization said it was aimed at disrupting communications between renewable installations and the power distribution operators but failed for reasons not explained.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wipers R Us&lt;/head&gt;
    &lt;p&gt;On Friday, security firm ESET said the malware responsible was a wiper, a type of malware that permanently erases code and data stored on servers with the goal of destroying operations completely. After studying the tactics, techniques, and procedures (TTPs) used in the attack, company researchers said the wiper was likely the work of a Russian government hacker group tracked under the name Sandworm.&lt;/p&gt;
    &lt;p&gt;“Based on our analysis of the malware and associated TTPs, we attribute the attack to the Russia-aligned Sandworm APT with medium confidence due to a strong overlap with numerous previous Sandworm wiper activity we analyzed,” said ESET researchers. “We’re not aware of any successful disruption occurring as a result of this attack.”&lt;/p&gt;
    &lt;p&gt;Sandworm has a long history of destructive attacks waged on behalf of the Kremlin and aimed at adversaries. Most notable was one in Ukraine in December 2015. It left roughly 230,000 people without electricity for about six hours during one of the coldest months of the year. The hackers used general purpose malware known as BlackEnergy to penetrate power companies’ supervisory control and data acquisition systems and, from there, activate legitimate functionality to stop electricity distribution. The incident was the first known malware-facilitated blackout.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/security/2026/01/wiper-malware-targeted-poland-energy-grid-but-failed-to-knock-out-electricity/"/><published>2026-01-24T21:24:13+00:00</published></entry></feed>