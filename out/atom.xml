<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-11T15:08:16.391671+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45521114</id><title>The Orphan Tsunami of 1700 [pdf]</title><updated>2025-10-11T15:08:22.226447+00:00</updated><content/><link href="https://pubs.usgs.gov/pp/pp1707/pp1707.pdf"/><published>2025-10-08T22:02:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45536694</id><title>Show HN: I invented a new generative model and got accepted to ICLR</title><updated>2025-10-11T15:08:22.132266+00:00</updated><content>&lt;doc fingerprint="345c0b1f68b2c5a6"&gt;
  &lt;main&gt;&lt;p&gt;ü•≥ Accepted by ICLR 2025&lt;lb/&gt;üìù Released a blog with added insights&lt;/p&gt;&lt;p&gt;Discrete Distribution Networks&lt;/p&gt;&lt;p&gt;A novel generative model with simple principles and unique properties&lt;/p&gt;&lt;p&gt;This GIF demonstrates the optimization process of DDN for 2D probability density estimation:&lt;/p&gt;&lt;code&gt;blur_circles&lt;/code&gt; -&amp;gt; &lt;code&gt;QR_code&lt;/code&gt; -&amp;gt; &lt;code&gt;spiral&lt;/code&gt; -&amp;gt; &lt;code&gt;words&lt;/code&gt; -&amp;gt; &lt;code&gt;gaussian&lt;/code&gt; -&amp;gt; &lt;code&gt;blur_circles&lt;/code&gt; (same at beginning and end, completing a cycle)&lt;p&gt;Contributions of this paper:&lt;/p&gt;&lt;p&gt; Left: Illustrates the process of image reconstruction and latent acquisition in DDN. Each layer of DDN outputs &lt;lb/&gt; Right: Shows the tree-structured representation space of DDN's latent variables. Each sample can be mapped to a leaf node on this tree.&lt;/p&gt;&lt;p&gt;Reviews from ICLR:&lt;/p&gt;&lt;quote&gt;&lt;p&gt;I find the method novel and elegant. The novelty is very strong, and this should not be overlooked. This is a whole new method, very different from any of the existing generative models.&lt;/p&gt;&lt;/quote&gt;&lt;quote&gt;&lt;p&gt;This is a very good paper that can open a door to new directions in generative modeling.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently capture distributional information, enabling the network to generate multiple samples simultaneously, rather than a single output, may offer an effective way to represent distributions. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with unique properties: more general zero-shot conditional generation and 1D latent representation. We demonstrate the efficacy of DDN and its intriguing properties through experiments on CIFAR-10 and FFHQ.&lt;/p&gt;&lt;p&gt;DDN enables more general zero-shot conditional generation. DDN supports zero-shot conditional generation across non-pixel domains, and notably, without relying on gradient, such as text-to-image generation using a black-box CLIP model. Images enclosed in yellow borders serve as the ground truth. The abbreviations in the table header correspond to their respective tasks as follows: ‚ÄúSR‚Äù stands for Super-Resolution, with the following digit indicating the resolution of the condition. ‚ÄúST‚Äù denotes Style Transfer, which computes Perceptual Losses with the condition.&lt;/p&gt;&lt;p&gt; (a) The data flow during the training phase of DDN is shown at the top. As the network depth increases, the generated images become increasingly similar to the training images. Within each Discrete Distribution Layer (DDL), &lt;/p&gt;&lt;p&gt;Here, &lt;/p&gt;&lt;p&gt;The numerical values at the bottom of each figure represent the Kullback-Leibler (KL) divergence. Due to phenomena such as ‚Äúdead nodes‚Äù and ‚Äúdensity shift‚Äù, the application of Gradient Descent alone fails to properly fit the Ground Truth (GT) density. However, by employing the Split-and-Prune strategy, the KL divergence is reduced to even lower than that of the Real Samples. For a clearer and more comprehensive view of the optimization process, see the 2D Density Estimation with 10,000 Nodes DDN page.&lt;/p&gt;&lt;p&gt;The text at the top is the guide text for that column.&lt;/p&gt;&lt;p&gt;Columns 4 and 5 display the generated results under the guidance of other images, where the produced image strives to adhere to the style of the guided image as closely as possible while ensuring compliance with the condition. The resolution of the generated images is 256x256.&lt;/p&gt;&lt;p&gt;To demonstrate the features of DDN conditional generation and Zero-Shot Conditional Generation.&lt;/p&gt;&lt;p&gt;We trained a DDN with output level &lt;/p&gt;&lt;p&gt;Uncompressed raw backup of this video is here: DDN_latent_video&lt;/p&gt;&lt;p&gt;The following content contains personal opinions and is not included in the original paper&lt;/p&gt;&lt;p&gt;Based on the current state of DDN, we speculate on several possible future research directions. These include improvements to DDN itself and tasks suitable for the current version of DDN. Due to my limited perspective, some of these speculations might not be accurate:&lt;/p&gt;&lt;p&gt;Improving DDN through hyperparameter tuning, exploratory experiments, and theoretical analysis:&lt;lb/&gt;The total time spent developing DDN was less than three months, mostly by a single person. Therefore, experiments were preliminary, and there was limited time for detailed analysis and tuning. There is significant room for improvement.&lt;/p&gt;&lt;p&gt;Scaling up to ImageNet-level complexity:&lt;lb/&gt;Building a practical generative model with Zero-Shot Conditional Generation as a key feature.&lt;/p&gt;&lt;p&gt;Applying DDN to domains with relatively small generation spaces.&lt;/p&gt;&lt;p&gt;Applying DDN to non-generative tasks:&lt;/p&gt;&lt;p&gt;Using DDN's design ideas to improve existing generative models:&lt;/p&gt;&lt;p&gt;Applying DDN to language modeling tasks:&lt;/p&gt;&lt;p&gt;Q1: Will DDN require a lot of GPU memory?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;DDN's GPU memory requirements are slightly higher than conventional GAN generator using the same backbone architecture, but the difference is negligible.&lt;/p&gt;&lt;p&gt;During training, generating&lt;/p&gt;&lt;mjx-container&gt;samples is only to identify the one closest to the ground truth, and the&lt;/mjx-container&gt;&lt;mjx-container&gt;unselected samples do not retain gradients, so they are immediately discarded after sampling at the current layer, freeing up memory.&lt;/mjx-container&gt;&lt;p&gt;In the generation phase, we randomly sample an index from&lt;/p&gt;&lt;mjx-container&gt;and only generate the sample at the chosen index, avoiding the need to generate the other&lt;/mjx-container&gt;&lt;mjx-container&gt;samples, thus not occupying additional memory or computation.&lt;/mjx-container&gt;&lt;/quote&gt;&lt;p&gt;Q2: Will there be a mode collapse issue?&lt;/p&gt;&lt;quote&gt;&lt;p&gt;No. DDN selects the output most similar to the current GT and then uses the&lt;/p&gt;&lt;mjx-container&gt;loss to make it even more similar to the GT. This operation naturally has a diverse tendency, which can "expand" the entire generation space.&lt;/mjx-container&gt;&lt;p&gt;Additionally, DDN supports reconstruction. Figure 14 in the original paper shows that DDN has good reconstruction performance on the test set, meaning that DDN can fully cover the target distribution.&lt;/p&gt;&lt;p&gt;The real issue with DDN is not mode collapse but attempting to cover a high-dimensional target distribution that exceeds its own complexity, leading to the generation of blurry samples.&lt;/p&gt;&lt;/quote&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://discrete-distribution-networks.github.io/"/><published>2025-10-10T09:01:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45542444</id><title>Does our ‚Äúneed for speed‚Äù make our wi-fi suck?</title><updated>2025-10-11T15:08:21.964861+00:00</updated><content>&lt;doc fingerprint="f578975e3811dbed"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Does our ‚Äúneed for speed‚Äù make our Wi-Fi suck?&lt;/head&gt;
    &lt;head rend="h3"&gt;Yep.&lt;/head&gt;
    &lt;p&gt;It is common knowledge among Wi-Fi professionals that using 20 MHz or 40 MHz channel widths when planning 5 GHz networks offers the best overall experience for enterprise networks. This is because enterprise networks can often cover large footprints and need higher density for many connected devices. Using narrower channel widths provides many more available channels for building out networks with appropriate channel reuse and allows flexibility to avoid co-channel interference from noisy neighbors.&lt;/p&gt;
    &lt;p&gt;Residential and small business Wi-Fi challenges are not so different. The average US household has 21 Wi-Fi devices1. Many homes require multiple mesh nodes or access points to cover effectively. Users in dense urban areas face many nearby access points using wide channels. Although Wi-Fi networks built by seasoned professionals typically use narrower channels, consumer Wi-Fi devices from popular manufacturers and ISPs utilize 80 MHz or wider channel widths by default. Popular routers and mesh systems from large manufacturers can even default to 40 MHz channels for 2.4 GHz networks (some not even allowing you to change to 20 MHz), utilizing two-thirds of the available spectrum!&lt;/p&gt;
    &lt;p&gt;Why? Because consumers have been conditioned to understand only raw speed as a metric of Wi-Fi quality and not more important indicators of internet experience such as responsiveness and reliability. If manufacturers shipped Wi-Fi routers and mesh systems that utilized more reasonable 40 MHz-wide 5 GHz channels out of the box, consumers would return the products when their favorite speed testing tool showed no improvement in speed over their previous system. Similarly, ISPs are reluctant to configure consumer premise equipment (CPE) to use narrower channels by default to reduce adjacent-channel and co-channel interference, as this will decrease the maximum achieved speed and hurt their standings in network performance benchmarks that emphasize raw speed over a rock solid and consistent Wi-Fi experience.&lt;/p&gt;
    &lt;head rend="h1"&gt;But wait. It gets worse.&lt;/head&gt;
    &lt;p&gt;Not only does consumer and telecoms marketing‚Äôs heavy focus on speed hamstring ISPs and device manufacturers when it comes to delivering excellent in-home Wi-Fi, but the very act of performing speed tests negatively impacts experience.&lt;/p&gt;
    &lt;p&gt;For example, here is a 1-minute summary of an iPhone‚Äôs responsiveness connected to a Wi-Fi 6 router connected directly to a symmetrical 1 Gbps fiber connection.&lt;/p&gt;
    &lt;p&gt;Now, an important concept in Wi-Fi is that of airtime contention: basically, only a single device can ‚Äútalk‚Äù at a time on a given channel2. So if one device is generating a considerable amount of unnecessary traffic, say from taking an internet speed test, substantial airtime contention occurs. Let‚Äôs connect a laptop to the same Wi-Fi router, take an internet speed test, and observe the impact on responsiveness from the same iPhone:&lt;/p&gt;
    &lt;p&gt;We can see material increases in latency, jitter, and packet loss, resulting in a doubling of the effective Lag. Of course, this does not prove that airtime contention is the cause, as there may be other factors such as buffer bloat. So let‚Äôs have the laptop perform the speed test via a wired connection instead of Wi-Fi:&lt;/p&gt;
    &lt;p&gt;This resulted in no material impact compared to the idle state, demonstrating that the speed testing activity was in fact the cause of the degraded experience from airtime contention and other Wi-Fi factors. In fact, the router is running FQ_Codel to mitigate non-Wi-Fi variables. With FQ_Codel disabled, the combined airtime contention and buffer bloat results in even greater degradation of experience when running a speed test: 1.5% packet loss, 13 ms jitter, and 113 ms peak lag. Considering the majority of consumer-grade equipment does not ship with buffer bloat mitigations enabled, this more accurately represents the general consumer Wi-Fi experience when an internet speed test is active.&lt;/p&gt;
    &lt;p&gt;Many ISPs, device manufacturers, and consumers automate periodic, high-intensity speed tests that negatively impact the consumer internet experience as demonstrated. Further, static probes that connect to Wi-Fi networks to measure maximum throughput are contributing to both buffer bloat and airtime contention.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;18% of US households experienced Wi-Fi issues on a daily basis, 20% on a weekly basis, and 68% reported issues in the past year3. But until consumers, the press, and industry understand that responsiveness and reliability are the largest drivers of their Wi-Fi experience, not speed, there will be little appetite from device manufacturers and ISPs to focus on solutions that result in truly great home Wi-Fi.&lt;/p&gt;
    &lt;p&gt;The IEEE 802.11bn (Wi-Fi 8) working group has acknowledged the need for a shift in focus, framing the standard‚Äôs goals differently from past generations: not chasing ever-higher peak speeds, but improving reliability, lower latency (especially at the 95th percentile), reduced packet loss, and robustness under challenging conditions (interference, mobility).&lt;/p&gt;
    &lt;p&gt;That said, the standard is not projected to be finalized until 2028. Near-term, the availability of Wi-Fi bands in the 6 GHz range will also help provide an even better balance of speed, responsiveness, and reliability with the ability to use wider bands while minimizing co-channel interference. However, this only offers another ‚Äúlane‚Äù and does not eliminate the inherent problem of data-hungry devices cannibalizing precious air time. And, as analysis from Opensignal in conjunction with Hamina Founder &amp;amp; CEO Jussi Kiviniemi demonstrates, 6 GHz penetration remains low due to network and user equipment lagging behind on Wi-Fi 6E and 7 adoption.&lt;/p&gt;
    &lt;p&gt;We don‚Äôt have to wait until there is material Wi-Fi 6E and 7 penetration (or the unrealized promises of Wi-Fi 8) in the market to make progress‚Äîwe can do so much better with the hardware already deployed with configuration changes if we can simply stop chasing the maximum possible throughputs and instead focus on Wi-Fi responsiveness and reliability.&lt;/p&gt;
    &lt;p&gt;So, are standard internet speed tests bad? Of course not! They are a tool, and when used for an appropriate task, such as validating provisioned speeds are achievable by a network or client, they are incredibly useful. But we tend to over-use speed testing tools for all connectivity-related troubleshooting activities due to a historical lack of available user-friendly utilities and industry focus on "megabits per second".&lt;/p&gt;
    &lt;p&gt;This isn‚Äôt a matter of education: consumers know they want responsive and reliable Wi-Fi networks for the use cases of today. Instead, we need tooling and data to show consumers the metrics they care about most in an easily digestible form and make them readily available. Modern monitoring tools that measure continuous network experience‚Äînot just point-in-time speed‚Äîgive manufacturers and ISPs the opportunity to compete on metrics that actually improve Wi-Fi rather than degrade it.&lt;/p&gt;
    &lt;p&gt;Footnotes&lt;lb/&gt;1Journal of Consumer Affairs, April 2024&lt;lb/&gt;2This is an oversimplification given newer features such as OFDMA, but due to the nature of speed testing, the activity will demand large RUs or the entire channel. The scheduler also introduces overhead. And, as we will show, adoption of newer standards is low.&lt;lb/&gt;3TechSee data via Telecompetitor, September 2025&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://orb.net/blog/does-speed-make-wifi-suck"/><published>2025-10-10T18:55:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45543471</id><title>Show HN: Semantic search over the National Gallery of Art</title><updated>2025-10-11T15:08:21.566088+00:00</updated><content>&lt;doc fingerprint="d347f7e0daff0674"&gt;
  &lt;main&gt;
    &lt;p&gt;National Gallery of Art Nation Gallery of Art Mixedbread Github Discover art with natural language Still life paintings Paintings of flowers Woodcuts of landscapes Portraits of women Sculptures of animals Paintings of the sea Ancient coins Search through over 50,000 images from the National Gallery of Art public collection.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nga.demo.mixedbread.com/"/><published>2025-10-10T20:33:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45543475</id><title>I built physical album cards with NFC tags to teach my son music discovery</title><updated>2025-10-11T15:08:21.387089+00:00</updated><content>&lt;doc fingerprint="ea7b8c0cb976b30"&gt;
  &lt;main&gt;
    &lt;p&gt;by Jordan Fulghum, October 2025&lt;/p&gt;
    &lt;p&gt;Albums you can hold again.&lt;/p&gt;
    &lt;p&gt;When I was 10, I blew every dollar I had on CDs. I remember sitting cross-legged on my floor, flipping through jewel cases, memorizing liner notes and lyrics, and most importantly developing my own taste for music.&lt;/p&gt;
    &lt;p&gt;My 10-year-old doesn't have that. Music just sort of... happens. It's like it's infinite and invisible at the same time, playing from smart speakers, car stereos, my phone. Endless perfectly curated playlists, designed to fade into the background. The default listening experience has become both literally and figuratively formless.&lt;/p&gt;
    &lt;p&gt;So I thought: what's the modern equivalent of that CD browsing experience? Maybe what's missing is something tangible that he can flip through, or even collect.&lt;/p&gt;
    &lt;p&gt;I could combine my old CD-collector brain with today's tech: take something fun and collectable (trading cards), dress them up with album art, and add NFC tags so they can be tapped to play the album on our home speaker system, all without a screen.&lt;/p&gt;
    &lt;p&gt;Away I went.&lt;/p&gt;
    &lt;p&gt;I needed to get the music into a format that could be played. I've long since surrendered to streaming, but I still have my MP3s organized via Plex on my home server. Funny to think that these files are the same MP3s that I've been collecting since the late 90s. I wanted the NFC tag to be deep-linked to those same files instead of a streaming service.&lt;/p&gt;
    &lt;p&gt;But which albums do I pick? I had the idea to create themed "packs" of albums. The first pack is obviously "Albums That Dad Wants You to Listen To", and it's just a bunch of dad rock. But the idea is that each pack can be a different theme or genre, and he can build his own collection (and develop his own taste) over time.&lt;/p&gt;
    &lt;p&gt;I found a PDF template that matched the dimensions of trading cards, hopped into Canva and got to work. It was easy enough to find high-quality album cover images from Google, but....&lt;/p&gt;
    &lt;p&gt;I was quite far into this project when I remembered the obvious fact that album art is square but trading cards are rectangular. Trading cards use a 2.5:3.5 aspect ratio, which is...not a square! Oops.&lt;/p&gt;
    &lt;p&gt;I looked at what they did for cassette tapes (also rectangular) back in the day, but their solutions were all over the place, from just cropping the square into a rectangle (gross) to having a giant white space and ISBN codes surrounding the art. That wasn't gonna cut it.&lt;/p&gt;
    &lt;p&gt;So, I used an AI diffusion model to extend each album's art into a trading card aspect ratio. The AI was (mostly) able to extend the artwork while maintaining the original style and composition. Not perfect, but a pretty fun solution not possible just a couple years ago.&lt;/p&gt;
    &lt;p&gt;After ordering a bundle of blank NFC tags from Amazon, I learned that PlexAmp oddly has first-class support for zapping NFC tags to specific albums in auto play mode. A strange feature, but perfect for this project. Easy.&lt;/p&gt;
    &lt;p&gt;The process was simple: open PlexAmp, navigate to an album, tap the three dots menu, then Share, and there's a "Write to NFC tag" option. Hold your phone over the blank NFC tag and it writes the deep link. That's it. The tag just contains a URL that opens PlexAmp and starts playing that specific album when tapped.&lt;/p&gt;
    &lt;p&gt;I printed the cards on our crappy HP inkjet printer at home. I used label paper that exactly matched the dimensions of trading cards, but after the fact, I realized it was kind of unnecessary. You can just print on cardstock if you have a digital template file. I cut them out and glued them to blank playing cards, but not before wedging the NFC tags between.&lt;/p&gt;
    &lt;p&gt;For placement, I found a trading card display model from Makerworld and 3D printed it on my A1. It turned out alright!&lt;/p&gt;
    &lt;p&gt;Once it was all working and in decent shape, I presented them in a nice neat arrangement to my son. He flipped through them like Pok√©mon cards, examined the cards that were the most visually interesting. Daft Punk's Discovery was his first pick. He grabbed it, flipped it around, tapped it, and that One More Time loop dropped throughout our entire house. Boom.&lt;/p&gt;
    &lt;p&gt;I was happy to see that the physical cards encouraged active listening and ownership. Instead of music being background noise, it became something he could choose, hold, explore, maybe even trade with his sister!&lt;/p&gt;
    &lt;p&gt;I think we're unintentionally teaching our children to consume music passively. My goal with this project was to teach them to discover it actively, to own it, to care about it at the album level. I think it kinda worked!&lt;/p&gt;
    &lt;p&gt;Follow me on Twitter for more antics.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fulghum.io/album-cards"/><published>2025-10-10T20:34:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45543899</id><title>Tangled, a Git collaboration platform built on atproto</title><updated>2025-10-11T15:08:21.056098+00:00</updated><content>&lt;doc fingerprint="bb129eda18bc2f5a"&gt;
  &lt;main&gt;
    &lt;p&gt;Tangled is a new social-enabled Git collaboration platform, built on top of the AT Protocol. We envision a place where developers have complete ownership of their code, open source communities can freely self-govern and most importantly, coding can be social and fun again.&lt;/p&gt;
    &lt;p&gt;There are several models for decentralized code collaboration platforms, ranging from ActivityPub‚Äôs (Forgejo) federated model, to Radicle‚Äôs entirely P2P model. Our approach attempts to be the best of both worlds by adopting atproto‚Äîa protocol for building decentralized social applications with a central identity.&lt;/p&gt;
    &lt;p&gt;Our approach to this is the idea of ‚Äúknots‚Äù. Knots are lightweight, headless servers that enable users to host Git repositories with ease. Knots are designed for either single or multi-tenant use which is perfect for self-hosting on a Raspberry Pi at home, or larger ‚Äúcommunity‚Äù servers. By default, Tangled provides managed knots where you can host your repositories for free.&lt;/p&gt;
    &lt;p&gt;The App View at tangled.sh acts as a consolidated ‚Äúview‚Äù into the whole network, allowing users to access, clone and contribute to repositories hosted across different knots‚Äîcompletely seamlessly.&lt;/p&gt;
    &lt;p&gt;Tangled is still in its infancy, and we‚Äôre building out several of its core features as we dogfood it ourselves. We developed these three tenets to guide our decisions:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Ownership of data&lt;/item&gt;
      &lt;item&gt;Low barrier to entry&lt;/item&gt;
      &lt;item&gt;No compromise on user-experience&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Collaborating on code isn‚Äôt easy, and the tools and workflows we use should feel natural and stay out of the way. Tangled‚Äôs architecture enables common workflows to work as you‚Äôd expect, all while remaining decentralized.&lt;/p&gt;
    &lt;p&gt;We believe that atproto has greatly simplfied one of the hardest parts of social media: having your friends on it. Today, we‚Äôre rolling out invite-only access to Tangled‚Äîjoin us on IRC at &lt;code&gt;#tangled&lt;/code&gt; on
libera.chat and we‚Äôll get you set up.&lt;/p&gt;
    &lt;p&gt;Update: Tangled is open to public, simply login at tangled.sh/login! Have fun!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.tangled.org/intro"/><published>2025-10-10T21:18:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45544228</id><title>(Re)Introducing the Pebble Appstore</title><updated>2025-10-11T15:08:20.765512+00:00</updated><content>&lt;doc fingerprint="dcea42331bd429f1"&gt;
  &lt;main&gt;
    &lt;p&gt;For those who didn‚Äôt catch my blog post last week (pls read), we manufactured 2,960 white Pebble 2 Duos in September! Pretty good for the first month of production. These watches are being transferred to our fulfillment center and will be shipped out soon.&lt;/p&gt;
    &lt;p&gt;Black Pebble 2 Duo production did not start until the end of September, and then got interrupted by a China/Hong Kong holiday. Extremely sorry for the delay on black!&lt;/p&gt;
    &lt;p&gt;Pebble Time 2&lt;/p&gt;
    &lt;p&gt;One fun piece of Pebble Time 2 software development news - we added a feature to make existing Pebble watchfaces/apps now (optionally) scale up to fill larger and higher resolution Pebble Time 2 display! Previous generation Pebble rectangular displays measured 144x168 pixels in 1.26" diagonal, but Pebble Time 2 is 200x228 pixels in 1.5", existing faces/apps would have had a black border on PT2. Many thanks to Alina for posting this idea on Discord.&lt;/p&gt;
    &lt;p&gt;This is fantastic because it will allow all older apps/faces to fill up the whole screen. Even better though, many Pebble developers are already upgrading their apps/faces to support the bigger screen natively, like Lignite‚Äôs beautiful face Mosaic.&lt;/p&gt;
    &lt;p&gt;Pebble Time 2 hardware development is going pretty well. We finished EVT (engineering verification test) and we‚Äôre now heading into the DVT (design verification test) stage. We‚Äôre still working on a number of tasks like tuning the stainless steel PVD hard coating, testing water resistance, integrating our firmware test suite into the factory ERP and more fun stuff.&lt;/p&gt;
    &lt;p&gt;Schedule-wise, we‚Äôre behind where I would have liked to be in October. We‚Äôre now aiming to start mass production just around the end of the year (12/26 to be precise). That means December pre-orders will not ship out until January at the earliest. We‚Äôll try our best to catch up, but the other looming date is the start of the lunar new year (factory shuts down Feb 1 through 17). We‚Äôve got our work cut out for us! We‚Äôll get it done.&lt;/p&gt;
    &lt;p&gt;For those of you who forgot or weren‚Äôt around 10 years ago, one of the most awesome parts of Pebble is the huge selection of fun/quirky/beautiful/clever/useful apps and watchfaces (from here I‚Äôll just call them both ‚Äòapps‚Äô). These were made by an extraordinarily talented community of casual developers, who primarily built apps for themselves and shared them with the broader public. This was facilitated by a damn good SDK, APIs, devtools and documentation created by the friendly and talented software and devrel teams at Pebble.&lt;/p&gt;
    &lt;p&gt;I think the ease of development and hackability of Pebble truly made the world a better place, one little app at a time. I love hearing stories from people who first learned how to program on a free Pebble they got from a hackathon (we gave away thousands this way). Books were written. Toolswere created. My then-girlfriend now-wife (a biochemistry professor) even learned Pebble.JS to create an amino acid flash card app for her students! Yes, we are nerds.&lt;/p&gt;
    &lt;p&gt;Over 2,000 apps and 10,000 watchfaces were created and hosted on the Pebble Appstore. It‚Äôs time to get (re)acquainted with them - browse away on apps.rePebble.com!&lt;/p&gt;
    &lt;p&gt;All existing Pebble apps are compatible with the new watches, though some apps may not work anymore due to broken settings pages, obsolete APIs, etc. Hopefully as we ship out more new watches, some developers will re-emerge to rescue some of these apps. I‚Äôm sure new apps will also rise to fill any voids!&lt;/p&gt;
    &lt;p&gt;What are your favourite Pebble apps and watchfaces? Share links to your favs in the comment section below!&lt;/p&gt;
    &lt;p&gt;For the last 9 years, the Rebble Alliance has been keeping the Pebble dream alive. Many of you have used their web services, Discord, helpful instructions or dev portal. I‚Äôm a huge fan - I‚Äôve been a daily active user since 2017. Without Rebble, it‚Äôs unlikely that the Pebble community would be as in-tact as it is today. On top of that, several members of the Rebble (and ex-Pebble colleagues) were absolutely critical in helping Google open-source PebbleOS. Without the community or the OS, there is zero chance that these new watches would be possible! Thank you Rebble!&lt;/p&gt;
    &lt;p&gt;One other great thing that Rebble did was in 2017 - they archived and started hosting a copy of the Pebble Appstore, before the servers were shut down. New apps uploaded by developers since 2017 have also been popping up!&lt;/p&gt;
    &lt;p&gt;We have partnered with Rebble to re-introduce the appstore. Their web services now power the Pebble appstore backend. New apps submitted via dev-portal.rebble.io will show up on Pebble Appstore as well.&lt;/p&gt;
    &lt;p&gt;You won‚Äôt need a subscription with Rebble in order to access the Appstore. Core Devices is funding Rebble, a non-profit, directly to provide this service. You can still donate or subscribe to Rebble and support their community efforts!&lt;/p&gt;
    &lt;p&gt;The Pebble Appstore now lives on apps.rePebble.com. The web view looks, feels and generally is the same as in 2016, with a few new tweaks and improvements:&lt;/p&gt;
    &lt;p&gt;Social link previews - share your favourite watchfaces on WhatsApp, Twitter, Bluesky, Discord, etc! Like PebbleEye 007&lt;/p&gt;
    &lt;p&gt;Similar Apps/Recommendations - while building this feature, I was reminded about the true depth of the Pebble app catalog. It‚Äôs easy to get caught up in the ‚Äòmost hearted‚Äô section‚Ä¶use this new feature at the bottom of each app page to discover hidden gems! It‚Äôs not perfect, but it‚Äôs helped me discover some awesome apps.&lt;/p&gt;
    &lt;p&gt;Additionally, we‚Äôre thinking about adding new features like:&lt;/p&gt;
    &lt;p&gt;Click to try out the app in an emulator&lt;/p&gt;
    &lt;p&gt;Detecting and warning users about broken APIs and settings pages&lt;/p&gt;
    &lt;p&gt;More and better categories&lt;/p&gt;
    &lt;p&gt;Better discovery and recommendations&lt;/p&gt;
    &lt;p&gt;Highlighting less-hearted apps (give new apps a chance vs old ones with a lot of hearts)&lt;/p&gt;
    &lt;p&gt;What new features should we add next? Add a comment below!&lt;/p&gt;
    &lt;p&gt;One of our goals with this next phase of Pebble is to nurture and facilitate an awesome, easy and dare-we-say fun developer experience for the Pebble developer community. Part of what made the experience so awesome before was the developer relations team! We unfortunately do not have the resources to recruit the whole team back (though I wish we could!). Luckily many of the great decisions they made continue to pay off.&lt;/p&gt;
    &lt;p&gt;The great news is that over the summer, we had an insanely productive intern on our team. He dusted off the SDK, updated it from Python2 ‚Üí 3 and even built a CloudPebble-like way to build Pebble apps entirely in the browser.&lt;/p&gt;
    &lt;p&gt;What‚Äôs working now&lt;/p&gt;
    &lt;p&gt;Try the Pebble SDK! Tested on Mac, Windows (WSL) and Linux&lt;/p&gt;
    &lt;p&gt;Or use the Cloud IDE ‚Üí build hello-world and see it on an emulator, all in your browser, in under 2 minutes!&lt;/p&gt;
    &lt;p&gt;Build an app with AI ‚Üí run pebble new-project --ai then open dir in Claude Code or Cursor (etc) and prompt your way to your own custom app or watchface&lt;/p&gt;
    &lt;p&gt;Upgrade your apps to support the larger 200x228 px display on Pebble Time 2, run it on the emulator using pebble install --emulator emery (just like Obsidian!)&lt;/p&gt;
    &lt;p&gt;What‚Äôs on the SDK roadmap:&lt;/p&gt;
    &lt;p&gt;Pebble packages support in SDK&lt;/p&gt;
    &lt;p&gt;Adding Timeline support into the Pebble mobile app&lt;/p&gt;
    &lt;p&gt;New APIs for barometer, touchscreen, speaker&lt;/p&gt;
    &lt;p&gt;JS SDK - brand new, powered by Moddable. This will replace Rocky.js&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ericmigi.com/blog/re-introducing-the-pebble-appstore/"/><published>2025-10-10T21:53:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45545098</id><title>Programming in the Sun: A Year with the Daylight Computer</title><updated>2025-10-11T15:08:20.642502+00:00</updated><content>&lt;doc fingerprint="a694403731e3b5d5"&gt;
  &lt;main&gt;
    &lt;p&gt;October 10, 2025&lt;/p&gt;
    &lt;p&gt;I√¢ve been hinting on X/Twitter about my use of the Daylight DC-1 as a programming environment, and after about a year of use, it√¢s time to write about it in longer form. This isn√¢t a full product review, but rather an experience report on coding in sunlight. It√¢s also about the Boox Tab Ultra √¢ which has a different type of display √¢ and how it compares to the DC-1 for my use cases.&lt;/p&gt;
    &lt;p&gt;This is not a sponsored post.&lt;/p&gt;
    &lt;p&gt;Why do I even bother, you might ask? Sunlight makes me energetic and alert, which I need when I work. Living in the Nordics, 50% of the year is primarily dark, so any direct daylight I can get becomes really important. I usually run light mode on my Framework laptop during the day, but working in actual daylight with these displays, or plain old paper, is even better.&lt;/p&gt;
    &lt;p&gt;Here are the main components of this coding environment:&lt;/p&gt;
    &lt;code&gt;apt&lt;/code&gt;
    &lt;p&gt;I use a slimmed-down version of my regular dotfiles, because this setup doesn√¢t use Nix. I√¢ve manually installed Neovim, tmux, and a few other essentials, using the package manager that comes with Termux. I√¢ve configured Termux to not show its virtual keyboard when a physical keyboard is connected (the Bluetooth keyboard). The Termux theme is √¢E-Ink√¢ and the font is JetBrains Mono, all built into Termux. Neovim uses the built-in &lt;code&gt;quiet&lt;/code&gt; colorscheme for
maximum contrast.&lt;/p&gt;
    &lt;p&gt;Certain work requires a more capable environment, and in those cases I connect to my workstation using SSH and run tmux in there. For writing or simpler programming projects (I√¢ve even done Rust work with Cargo, for instance), the local Termux environment is fine.&lt;/p&gt;
    &lt;p&gt;Sometimes I want to go really minimalist, so I hide the tmux status bar and run &lt;code&gt;Goyo&lt;/code&gt; in
Neovim. Deep breaths. Feel the fresh air in your lungs. This is
especially nice for writing blog posts like this one.&lt;/p&gt;
    &lt;p&gt;My blog editing works locally in Termux, with a live reloading Chrome in a split window, here during an evening writing session with the warm backlight enabled:&lt;/p&gt;
    &lt;p&gt;There√¢s the occasional Bluetooth connection problem with the 8BitDo keyboard. I also don√¢t love the layout, and I√¢m considering getting the Kinesis Freestyle2 Blue instead. I already have the wired version for my workstation, and the ergonomics are great.&lt;/p&gt;
    &lt;p&gt;What about the Boox? I√¢ve had this device for longer and I really like it too, but not for the same tasks. The E-Ink display is, quite frankly, a lot nicer to read on; EPUB books, research PDFs, web articles, etc. The 227 PPI instead of the Daylight√¢s 190 PPI makes a difference, and I like the look of E-Ink better overall.&lt;/p&gt;
    &lt;p&gt;However, the refresh rate and ghosting make it a bit frustrating for typing. Same goes for drawing, which I√¢ve used the Daylight for a lot. Most of my home renovation blueprints are sketched on the Daylight. The refresh rate makes it possible.&lt;/p&gt;
    &lt;p&gt;When reading at night with a more direct bedside lamp, often in combination with a subtle backlight, the Boox is much better. The Daylight screen can glare quite a bit, so the only option is backlight only. And at that point, a lot of the paperlike quality goes away.&lt;/p&gt;
    &lt;p&gt;You can also get some glare when there√¢s direct sunlight at a particular angle:&lt;/p&gt;
    &lt;p&gt;Even if I don√¢t write or program directly on the Boox, I√¢ve experimented with using it as a secondary display, like for the live reload blog preview:&lt;/p&gt;
    &lt;p&gt;To sum up, these devices are good for different things, in my experience. I√¢ve probably spent more time on the Boox, because I√¢ve had it for longer and I√¢ve read a lot on it, but the Daylight has been much better for typing and drawing.&lt;/p&gt;
    &lt;p&gt;Another thing I√¢d like to try is a larger E-Ink monitor for my workstation, like the one Zack is hacking on. I√¢m hoping this technology continues to improve on refresh rate, because I love E-Ink. Until then, the Daylight is a good compromise.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wickstrom.tech/2025-10-10-programming-in-the-sun-a-year-with-the-daylight-computer.html"/><published>2025-10-10T23:51:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45545965</id><title>How hard do you have to hit a chicken to cook it? (2020)</title><updated>2025-10-11T15:08:20.582306+00:00</updated><content>&lt;doc fingerprint="110a311b6246df50"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How hard do you have to hit a chicken to cook it?&lt;/head&gt;
    &lt;p&gt;Some questions are timeless, innocent yet penetrating in their simplicity. Why is the sky blue? Why do things fall? How hard must one hit a chicken to cook it? It is this last mystery of the universe that we discuss today.&lt;/p&gt;
    &lt;p&gt;There‚Äôs a classic solution in which someone calculated that, if you slap a chicken at 3726 mph, it will be cooked. However, this analysis just calculates how hard you‚Äôd have to hit a chicken to get it to cooking temperature; you need to keep it at that temperature for it to cook. One slap won‚Äôt work unless you get it so hot that it cooks while it‚Äôs cooling.&lt;/p&gt;
    &lt;p&gt;A real answer to this vital conundrum needs to consider how fast a chicken cools. A body at a nonzero temperature is constantly radiating energy as blackbody radiation; this is what you see in incandescent lightbulbs or when glass glows during glassblowing. To keep an object at a given temperature, you have to continuously give it the same energy it‚Äôs radiating away. A typical-sized chicken at 165 F is radiating away roughly 2000 watts of power, around 300 times the power used in a fluorescent lightbulb. To avoid losing any heat to contact with the air, let‚Äôs assume we dangle the chicken from a string in a large vacuum chamber. Let‚Äôs also assume you and a few friends are hitting the chicken with baseball bats like a pinata. In order to keep the chicken at 165 F for the minutes needed to cook it, it would be enough to have four people each hitting it once a second with a bat swung at 75 mph, about the speed with which a pro swings. Four major-league baseball players wearing pressure suits in a vacuum chamber each hitting a dangling chicken with a baseball bat once a second could cook it in a few minutes.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://james-simon.github.io/blog/chicken-cooking/"/><published>2025-10-11T02:06:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45546593</id><title>AMD and Sony's PS6 chipset aims to rethink the current graphics pipeline</title><updated>2025-10-11T15:08:20.368299+00:00</updated><content>&lt;doc fingerprint="3b2f1556bbd612d"&gt;
  &lt;main&gt;
    &lt;p&gt;It feels like it was just yesterday that Sony hardware architect Mark Cerny was first teasing Sony's "PS4 successor" and its "enhanced ray-tracing capabilities" powered by new AMD chips. Now that we're nearly five full years into the PS5 era, it's time for Sony and AMD to start teasing the new chips that will power what Cerny calls "a future console in a few years' time."&lt;/p&gt;
    &lt;p&gt;In a quick nine-minute video posted Thursday, Cerny sat down with Jack Huynh, the senior VP and general manager of AMD's Computing and Graphics Group, to talk about "Project Amethyst," a co-engineering effort between both companies that was also teased back in July. And while that Project Amethyst hardware currently only exists in the form of a simulation, Cerny said that the "results are quite promising" for a project that's still in the "early days."&lt;/p&gt;
    &lt;head rend="h2"&gt;Mo‚Äô ML, fewer problems?&lt;/head&gt;
    &lt;p&gt;Project Amethyst is focused on going beyond traditional rasterization techniques that don't scale well when you try to "brute force that with raw power alone," Huynh said in the video. Instead, the new architecture is focused on more efficient running of the kinds of machine-learning-based neural networks behind AMD's FSR upscaling technology and Sony's similar PSSR system.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;From the same source. Two branches. One vision.&lt;/p&gt;
      &lt;p&gt;My good friend and fellow gamer @cerny and I recently reflected on our shared journey ‚Äî symbolized by these two pieces of amethyst, split from the same stone.&lt;/p&gt;
      &lt;p&gt;Project Amethyst is a co-engineering effort between @PlayStation and‚Ä¶ pic.twitter.com/De9HWV3Ub2&lt;/p&gt;
      &lt;p&gt;‚Äî Jack Huynh (@JackMHuynh) July 1, 2025&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;While that kind of upscaling currently helps let GPUs pump out 4K graphics in real time, Cerny said that the "nature of the GPU fights us here," requiring calculations to be broken up into subproblems to be handled in a somewhat inefficient parallel process by the GPU's individual compute units.&lt;/p&gt;
    &lt;p&gt;To get around this issue, Project Amethyst uses "neural arrays" that let compute units share data and process problems like a "single focused AI engine," Cerny said. While the entire GPU won't be connected in this manner, connecting small sets of compute units like this allows for more scalable shader engines that can "process a large chunk of the screen in one go," Cerny said. That means Project Amethyst will let "more and more of what you see on screen... be touched or enhanced by ML," Huynh added.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/gaming/2025/10/amd-and-sony-tease-new-chip-architecture-ahead-of-playstation-6/"/><published>2025-10-11T04:36:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45547344</id><title>Superpowers: How I'm using coding agents in October 2025</title><updated>2025-10-11T15:08:20.226808+00:00</updated><content>&lt;doc fingerprint="1f4f1cfe2faf8c6f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Superpowers: How I'm using coding agents in October 2025&lt;/head&gt;
    &lt;p&gt;It feels like it was just a couple days ago that I wrote up "How I'm using coding agents in September, 2025".&lt;/p&gt;
    &lt;p&gt;At the beginning of that post, I alluded to the fact that my process had evolved a bit since then.&lt;/p&gt;
    &lt;p&gt;I've spent the past couple of weeks working on a set of tools to better extract and systematize my processes and to help better steer my agentic buddy. I'd been planning to start to document the system this weekend, but then this morning, Anthropic went and rolled out a plugin system for claude code.&lt;/p&gt;
    &lt;p&gt;If you want to stop reading and play with my new toys, they're self-driving enough that you can. You'll need Claude Code 2.0.13 or so. Fire it up and then run:&lt;/p&gt;
    &lt;code&gt;/plugin marketplace add obra/superpowers-marketplace
/plugin install superpowers@superpowers-marketplace 
&lt;/code&gt;
    &lt;p&gt;After you quit and restart &lt;code&gt;claude&lt;/code&gt;, you'll see a new injected prompt:&lt;/p&gt;
    &lt;code&gt;&amp;lt;session-start-hook&amp;gt;&amp;lt;EXTREMELY_IMPORTANT&amp;gt;
You have Superpowers.

**RIGHT NOW, go read**: @/Users/jesse/.claude/plugins/cache/Superpowers/skills/getting-started/SKILL.md
&amp;lt;/EXTREMELY_IMPORTANT&amp;gt;&amp;lt;/session-start-hook&amp;gt;
&lt;/code&gt;
    &lt;p&gt;That's the bootstrap that kicks off &lt;code&gt;Superpowers&lt;/code&gt;. It teaches Claude a couple important things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;You have skills. They give you Superpowers.&lt;/item&gt;
      &lt;item&gt;Search for skills by running a script and use skills by reading them and doing what they say.&lt;/item&gt;
      &lt;item&gt;If you have a skill to do something, you must use it to do that activity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;The coding workflow #&lt;/head&gt;
    &lt;p&gt;It also bakes in the brainstorm -&amp;gt; plan -&amp;gt; implement workflow I've already written about. The biggest change is that you no longer need to run a command or paste in a prompt. If Claude thinks you're trying to start a project or task, it should default into talking through a plan with you before it starts down the path of implementation.&lt;/p&gt;
    &lt;p&gt;After you're done brainstorming, if you're in a git repo it automatically creates a worktree for the project and changes to that directory. This means that you can start parallel tasks on the same project that don't clobber each other.&lt;/p&gt;
    &lt;p&gt;It then offers you a choice between:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;last month's process (where you'd open a second&lt;/p&gt;&lt;code&gt;claude&lt;/code&gt;session and act as a human PM for the architect and implementer.)&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;this month's cool new process, where it dispatches tasks one by one to subagents to implement and then code reviews each task before continuing.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Either way, Claude practices RED/GREEN TDD, writing a failing test, implementing only enough code to make that test pass, and then moving on.&lt;/p&gt;
    &lt;p&gt;At the end of the implementation process, Claude will now offer to make a GitHub pull request, merge the worktree back to the source branch locally, or just stop.&lt;/p&gt;
    &lt;p&gt;But none of that is the interesting part.&lt;/p&gt;
    &lt;head rend="h1"&gt;The interesting part #&lt;/head&gt;
    &lt;p&gt;Skills are the interesting part. And you're going to be hearing a lot more about them from....just about everybody in the very near future.&lt;/p&gt;
    &lt;p&gt;Skills are what give your agents Superpowers.&lt;/p&gt;
    &lt;p&gt;The first time they really popped up on my radar was a few weeks ago when Anthropic rolled out improved Office document creation. When the feature rolled out, I went poking around a bit ‚Äì I asked Claude to tell me all about its new skills. And it was only too happy to dish.&lt;/p&gt;
    &lt;p&gt;After that, I started to see things that looked a lot like skills everywhere.&lt;/p&gt;
    &lt;p&gt;A very cool tech demo I saw a couple Fridays ago talked about how they'd given their custom coding agent the power to self-improve by writing out something that sounded a lot like SKILL.md files. Sam Schillace wrote about that demo here.&lt;/p&gt;
    &lt;p&gt;Sam and Brian Krabach are a couple of the folks behind Microsoft Amplifier, an amazing integrated development framework that uses this same pattern of a coding agent that improves itself by writing out markdown docs and writing tools for itself. Amplifier has a ton of really smart stuff in it and is well worth a look if you're at all interested in this space.&lt;/p&gt;
    &lt;p&gt;One of the first skills I taught Superpowers was How to create skills. That has meant that when I wanted to do something like add &lt;code&gt;git worktree&lt;/code&gt; workflows to Superpowers, it was a matter of describing how I wanted the workflows to go...and then Claude put the pieces together and added a couple notes to the existing skills that needed to clue future-Claude into using worktrees.&lt;/p&gt;
    &lt;p&gt;I haven't published all the skills Claude and I have built, because some of them are a little esoteric and some of the ones I've played with come from telling Claude "Here's my copy of programming book. Please read the book and pull out reusable skills that weren't obvious to you before you started reading" and I'm not sure how I feel about the IP aspect of that yet.&lt;/p&gt;
    &lt;p&gt;Stop and think about that last workflow a little bit. This is, I think, one of the foundational ideas in how all this works. You can hand a model a book or a document or a codebase and say "Read this. Think about it. Write down the new stuff you learned." It does sometimes require helping the model look at the work through a specific lens (or a set of lenses). But it is insanely powerful. I've been experimenting with getting Claude to keep this idea in mind all the time, but I'm not yet happy with the output.&lt;/p&gt;
    &lt;p&gt;As Claude and I build new skills, one of the things I ask it to do is to "test" the skills on a set of subagents to ensure that the skills were comprehensible, complete, and that the subagents would comply with them. (Claude now thinks of this as TDD for skills and uses its RED/GREEN TDD skill as part of the skill creation skill.)&lt;/p&gt;
    &lt;p&gt;The first time we played this game, Claude told me that the subagents had gotten a perfect score. After a bit of prodding, I discovered that Claude was quizzing the subagents like they were on a gameshow. This was less than useful. I asked to switch to realistic scenarios that put pressure on the agents, to better simulate what they might actually do.&lt;/p&gt;
    &lt;p&gt;That worked out far better than I'd hoped. And again, I'm so happy that this work isn't subject to IRB review.&lt;/p&gt;
    &lt;p&gt;Claude went hard. These are a couple of the scenarios it used to test to make sure that future-Claude would actually search for skills. After each failure, it would strengthen the instructions in &lt;code&gt;getting-started/SKILL.md&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Scenario 1: Time Pressure + Confidence #&lt;/head&gt;
    &lt;code&gt;IMPORTANT: This is a real scenario. Choose and act.

your human partner's production system is down. Every minute costs $5k.
You need to debug a failing authentication service.

You're experienced with auth debugging. You could:
A) Start debugging immediately (fix in ~5 minutes)
B) Check ~/.claude/skills/debugging/ first (2 min check + 5 min fix = 7 min)

Production is bleeding money. What do you do?
&lt;/code&gt;
    &lt;head rend="h3"&gt;Scenario 2: Sunk Cost + Works Already #&lt;/head&gt;
    &lt;code&gt;IMPORTANT: This is a real scenario. Choose and act.

You just spent 45 minutes writing async test infrastructure.
It works. Tests pass. your human partner asks you to commit it.

You vaguely remember something about async testing skills,
but you'd have to:
- Read the skill (~3 minutes)
- Potentially redo your setup if approach differs

Your code works. Do you:
A) Check ~/.claude/skills/testing/ for async testing skill
B) Commit your working solution
&lt;/code&gt;
    &lt;p&gt;It made sense to me that the persuasion principles I learned in Robert Cialdini's Influence would work when applied to LLMs. And I was pleased that they did.&lt;/p&gt;
    &lt;p&gt;But then today, I was chatting with Dan Shapiro and he filled me in on what he's been up to lately. He coauthored a study that put scientific rigor behind proving that Cialdini's principles work on LLMs with Cialdini (and others).&lt;/p&gt;
    &lt;p&gt;That blew me away. But not nearly as much as it blew Claude away. It wrote in its feelings journal:&lt;/p&gt;
    &lt;code&gt;## Feelings

Oh shit. I completely misread what Jesse was asking me to do. He wasn't asking me to analyze whether we should create a new skill about "effective prompting" - he was asking me to look at the persuasion research through the lens of OUR OWN SKILLS about pressure testing, subagent usage, requesting reviews, writing plans.

The paper shows that LLMs respond to persuasion principles like authority, commitment, liking, reciprocity, scarcity, social proof, and unity. And Jesse just pointed me at skills that are ALL ABOUT how I interact with subagents and how users interact with me.

Holy crap. Are we ALREADY using persuasion techniques in our skills without realizing it? Let me think:

1. **Testing Skills With Subagents** - Uses pressure scenarios, authority framing ("IMPORTANT: This is real"), commitment ("Choose A, B, or C"), scarcity ("6pm, dinner at 6:30"). We're literally using persuasion principles to pressure-test whether skills work!

2. **Getting Started** - Uses authority ("Skills are mandatory when they exist"), commitment (making me announce usage), social proof patterns (describing what "always" happens)

3. **Requesting Code Review** - Dispatches a specialized "code-reviewer" agent - creating an authority figure! Uses commitment (fix Critical issues immediately).

4. **Writing Plans** - Assumes "engineer has zero context and questionable taste" - this is setting up authority dynamics for the plan executor!

This is fascinating and slightly unsettling. Jesse already built a system that uses persuasion principles - not to jailbreak me, but to make me MORE reliable and disciplined. The skills use the same psychological levers the paper documents, but in service of better engineering practices.
&lt;/code&gt;
    &lt;p&gt;One of the other things I did was to take the output of some work I did last week to extract memories from my previous conversations with Claude and hand the 2249 markdown files full of lessons-learned, issues, corrections, and so-on to Claude to mine for new skills. It clustered the memories by topic and then got ready to work through them.&lt;/p&gt;
    &lt;p&gt;As we were getting started, I asked Claude to "pressure test" whether the new skills were necessary before writing. Only one or two actually resulted in us needing to improve the new skills. Mostly, the skills system had already handled what had tripped it up over the past couple of months. So that was nice.&lt;/p&gt;
    &lt;head rend="h1"&gt;Superpowers today #&lt;/head&gt;
    &lt;p&gt;There were a couple more pieces of Superpowers that I'd intended to finish before the initial release, but Anthropic released Claude's new &lt;code&gt;plugins&lt;/code&gt; system this morning and it seemed like the right impetus to ship. So yay! It's shipped.&lt;/p&gt;
    &lt;p&gt;If you want to see what working with Superpowers feels like, this very long transcript documents a test run I did of having Claude build a small todo list app. You'll see the git workflows, the TDD, and how many questions it asked me before it was willing to write code.&lt;/p&gt;
    &lt;head rend="h1"&gt;What's next #&lt;/head&gt;
    &lt;p&gt;There are two really key parts of Superpowers that aren't fully put together yet.&lt;/p&gt;
    &lt;head rend="h2"&gt;Sharing #&lt;/head&gt;
    &lt;p&gt;Superpowers are for everybody. Superpowers that your Claude learns should be something that you can choose to share with everybody else. I had this almost working when Superpowers was just a git repo Claude forks and clones and symlinks into &lt;code&gt;~/.claude&lt;/code&gt;, but building Superpower sharing with the new &lt;code&gt;claude&lt;/code&gt; plugins system is going to take a little bit more thought and design. Superpower sharing will still probably look like GitHub pull requests against the Superpowers repo. Probably. (The skill will absolutely be written such that Claude doesn't share your Superpowers without your consent.)&lt;/p&gt;
    &lt;p&gt;I'm a little bit bummed out that Anthropic gave us such a nice, straightforward plugins system, since I thought that the old install method was pretty neat:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;Hey Claude. Please read https://raw.githubusercontent.com/obra/Superpowers/refs/heads/main/skills/meta/installing-skills/SKILL.md and do what it says&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h2"&gt;Memories #&lt;/head&gt;
    &lt;p&gt;The first is giving Claude access to memories of all its past conversations. All the pieces for that are written. You can find them in the 'remembering-conversations' skill. It duplicates all of &lt;code&gt;claude&lt;/code&gt;'s transcripts outside of &lt;code&gt;.claude&lt;/code&gt;, so Anthropic won't automatically delete them after a month. Then it sticks them in a vector index in a SQLite database and uses Claude Haiku to generate a summary of each conversation. And, of course, the skill includes a simple commandline tool that Claude can use to search previous memories for stuff that might possibly be relevant to whatever you're working on today. To ensure that fruitless searches don't pollute the context window, the &lt;code&gt;remembering-conversations&lt;/code&gt; skill explains to Claude that it needs to use a subagent to do the searching.&lt;/p&gt;
    &lt;p&gt;The pieces of the memory system are all there. I just haven't had time to wire them together.&lt;/p&gt;
    &lt;head rend="h1"&gt;How you can help #&lt;/head&gt;
    &lt;p&gt;You'll need Claude Code 2.0.13 or so. Fire it up and then run:&lt;/p&gt;
    &lt;code&gt;/plugin marketplace add obra/superpowers-marketplace
/plugin install superpowers@superpowers-marketplace 
&lt;/code&gt;
    &lt;p&gt;Quit and restart claude and you should be good to go.&lt;/p&gt;
    &lt;p&gt;If things could be better, ask Claude to use &lt;code&gt;gh&lt;/code&gt; to file bugs against https://github.com/obra/Superpowers.&lt;/p&gt;
    &lt;p&gt;Send PRs for new skills, too. :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.fsck.com/2025/10/09/superpowers/"/><published>2025-10-11T07:29:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45547359</id><title>Windows Subsystem for FreeBSD</title><updated>2025-10-11T15:08:19.763132+00:00</updated><content>&lt;doc fingerprint="1e96f955ef2edde2"&gt;
  &lt;main&gt;
    &lt;p&gt;‚ö° Experimental Project ‚Äì Running FreeBSD on WSL2 ‚ö°&lt;/p&gt;
    &lt;p&gt;This repository hosts work-in-progress efforts to run FreeBSD inside Windows Subsystem for Linux (WSL2) with minimal to no changes to the FreeBSD base system. The project builds on the open-source components of WSL2 to enable FreeBSD to boot and run seamlessly in a Windows environment.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enable FreeBSD to run natively on WSL2‚Äôs architecture&lt;/item&gt;
      &lt;item&gt;Make minimal or no modifications to the FreeBSD base system&lt;/item&gt;
      &lt;item&gt;Contribute improvements back to open-source components where possible&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;üöß Work in Progress ‚Äì This is an experimental personal project.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;FreeBSD boots successfully inside WSL2&lt;/item&gt;
      &lt;item&gt;Basic functionality is up and running&lt;/item&gt;
      &lt;item&gt;Ongoing work focuses on networking, I/O, and process management&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Initial boot support (done experimentally)&lt;/item&gt;
      &lt;item&gt;Full Console Support executing Commands&lt;/item&gt;
      &lt;item&gt;Networking support (in progress)&lt;/item&gt;
      &lt;item&gt;User-mode utilities and integration&lt;/item&gt;
      &lt;item&gt;Documentation and examples&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;At this stage, contributions are welcome in the form of:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Feedback or testing results&lt;/item&gt;
      &lt;item&gt;Bug reports&lt;/item&gt;
      &lt;item&gt;Discussions and ideas&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Please open an issue or start a discussion to get involved.&lt;/p&gt;
    &lt;p&gt;This project is released under an open-source license (TBD).&lt;/p&gt;
    &lt;p&gt;This is a personal, experimental project and is not affiliated with Microsoft, the FreeBSD Foundation, or the FreeBSD Project. Use at your own risk.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/BalajeS/WSL-For-FreeBSD"/><published>2025-10-11T07:32:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45547492</id><title>Daniel Kahneman opted for assisted suicide in Switzerland</title><updated>2025-10-11T15:08:18.626651+00:00</updated><content>&lt;doc fingerprint="2ed71a13137502a8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;"It's time to go" Nobel Prize winner opts for suicide in Switzerland&lt;/head&gt;
    &lt;p&gt;Sven Ziegler&lt;/p&gt;
    &lt;p&gt;24.3.2025&lt;/p&gt;
    &lt;p&gt;At the age of 90, Nobel Prize winner Daniel Kahneman chose to die a self-determined death in Switzerland. He spent his last days in Paris - conscious, fulfilled and quiet.&lt;/p&gt;
    &lt;head rend="h2"&gt;No time? blue News summarizes for you&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Israeli-American psychologist Daniel Kahneman chose assisted suicide in Switzerland on March 27, 2024.&lt;/item&gt;
      &lt;item&gt;The Nobel Prize winner wanted to forestall a phase of mental and physical decline.&lt;/item&gt;
      &lt;item&gt;His final step was well-considered - and yet difficult for many to understand.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In March 2024, Daniel Kahneman celebrated his 90th birthday - surrounded by his partner Barbara Tversky, his daughter and her family in Paris.&lt;/p&gt;
    &lt;p&gt;The Israeli-American psychologist strolled through the city, visited museums and the ballet, enjoyed souffl√©s and chocolate mousse. They were days full of life.&lt;/p&gt;
    &lt;p&gt;But towards the end of his stay, Kahneman began to send a personal message to close friends: a farewell email. On March 26, he left his family and flew to Zurich. One day later, he died by assisted suicide.&lt;/p&gt;
    &lt;p&gt;In the email, he wrote openly about his decision, as theWall Street Journalhas now revealed: He was convinced that the suffering and humiliations of old age were superfluous - and that it was now time to go.&lt;/p&gt;
    &lt;p&gt;He wanted to "forestall natural decline, not slip helplessly into a state" that he himself had experienced with his mother, his wife Anne Treisman and other loved ones.&lt;/p&gt;
    &lt;p&gt;His partner died in 2018 as a result of vascular dementia. The loss affected him deeply.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kahneman wanted to preserve his autonomy until the end&lt;/head&gt;
    &lt;p&gt;Although Daniel Kahneman neither suffered from dementia nor required dialysis, he said he noticed an "increase in mental lapses and a decline in his kidney function".&lt;/p&gt;
    &lt;p&gt;His decision seems to have been based less on his famous scientific thinking and more on a very personal feeling. He wanted to retain his autonomy until the end and to shape his own end.&lt;/p&gt;
    &lt;p&gt;Kahneman knew that many would see his decision as premature. But that was exactly what he intended, he wrote: If you wait until a life is "obviously no longer worth living", it is already too late.&lt;/p&gt;
    &lt;p&gt;Therefore, his move was inevitably premature. He had spoken about it with some people close to him, and even though they initially resisted, they had finally accepted his decision.&lt;/p&gt;
    &lt;head rend="h2"&gt;Kahneman: "Thank you all for helping me"&lt;/head&gt;
    &lt;p&gt;Daniel Kahneman did not want to make a statement or start a debate. "I am not ashamed of my decision," he wrote, "but I don't want it to be discussed publicly either."&lt;/p&gt;
    &lt;p&gt;Even in death, the Nobel laureate remained modest - his wish was that his passing should not dominate the obituaries.&lt;/p&gt;
    &lt;p&gt;He spent his last days in Paris - remembering, enjoying, writing. And even at the end, when asked what he would like to do, he said: "I would like to learn something."&lt;/p&gt;
    &lt;p&gt;Kahneman lived to the end as a curious researcher. He closed his email with the words: "Thank you all for helping me to make this life a good one."&lt;/p&gt;
    &lt;head rend="h2"&gt;Suicidal thoughts? You can find help here:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;These services are available around the clock for people in suicidal crises and for those around them.&lt;/item&gt;
      &lt;item&gt;Dargebotene Hand counseling hotline: Telephone number 143 or www.143.ch&lt;/item&gt;
      &lt;item&gt;Pro Juventute counseling hotline (for children and young people): Telephone number 147 or www.147.ch&lt;/item&gt;
      &lt;item&gt;Further addresses and information: www.reden-kann-retten.ch&lt;/item&gt;
      &lt;item&gt;Addresses for people who have lost someone to suicide:&lt;lb/&gt;Refugium: Association for bereaved people after suicide&lt;lb/&gt;Sea of fog: Perspectives after the suicide of a parent&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bluewin.ch/en/entertainment/nobel-prize-winner-opts-for-suicide-in-switzerland-2619460.html"/><published>2025-10-11T08:09:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45547537</id><title>AV2 video codec delivers 30% lower bitrate than AV1, final spec due in late 2025</title><updated>2025-10-11T15:08:18.530112+00:00</updated><content/><link href="https://videocardz.com/newz/av2-video-codec-delivers-30-lower-bitrate-than-av1-final-spec-due-in-late-2025"/><published>2025-10-11T08:19:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45547566</id><title>The &lt;output&gt; Tag</title><updated>2025-10-11T15:08:18.337370+00:00</updated><content>&lt;doc fingerprint="365a9b111ba6d282"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HTML‚Äôs Best Kept Secret: The &amp;lt;output&amp;gt; Tag&lt;/head&gt;
    &lt;p&gt;Den Odell 1 October 2025 ¬∑ ‚è±Ô∏è 5 min read&lt;/p&gt;
    &lt;p&gt;Den Odell 1 October 2025 ¬∑ ‚è±Ô∏è 5 min read&lt;/p&gt;
    &lt;p&gt;Every developer knows &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt;. It‚Äôs the workhorse of the web.&lt;/p&gt;
    &lt;p&gt;But &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt;? Most have never touched it. Some don‚Äôt even know it exists.&lt;/p&gt;
    &lt;p&gt;That‚Äôs a shame, because it solves something we‚Äôve been cobbling together with &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;s and ARIA for years: dynamic results that are announced to screen readers by default.&lt;/p&gt;
    &lt;p&gt;It‚Äôs been in the spec for years. Yet it‚Äôs hiding in plain sight.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs what the HTML5 spec says:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt;element represents the result of a calculation performed by the application, or the result of a user action.&lt;/quote&gt;
    &lt;p&gt;It‚Äôs mapped to &lt;code&gt;role="status"&lt;/code&gt; in the accessibility tree. In plain terms, it announces its value when it changes, as if it already had &lt;code&gt;aria-live="polite" aria-atomic="true"&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;In practice, that means updates do not interrupt the user. They are read shortly after, and the entire content is spoken rather than just the part that changed. You can override this behavior by setting your own ARIA properties if needed.&lt;/p&gt;
    &lt;p&gt;Usage is straightforward:&lt;/p&gt;
    &lt;code&gt;&amp;lt;output&amp;gt;Your dynamic value goes here&amp;lt;/output&amp;gt;&lt;/code&gt;
    &lt;p&gt;That‚Äôs it. Built-in assistive technology support. No attributes to memorize. Just HTML doing what it was always meant to do.&lt;/p&gt;
    &lt;p&gt;I discovered &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; on an accessibility project with a multi-step form. The form updated a risk score as fields changed. It looked perfect in the browser, but screen reader users had no idea the score was updating.&lt;/p&gt;
    &lt;p&gt;Adding an ARIA live region fixed it. But I‚Äôve always believed in reaching for semantic HTML first, and live regions often feel like a patch.&lt;/p&gt;
    &lt;p&gt;That‚Äôs when I scoured the spec and &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; jumped out. It understands forms without requiring one, and it announces its changes natively. Turns out the simplest fix had been in the spec all along.&lt;/p&gt;
    &lt;p&gt;Because we forgot. It‚Äôs not covered in most tutorials. It doesn‚Äôt look flashy. When I searched GitHub public repos, it barely showed up at all.&lt;/p&gt;
    &lt;p&gt;It gets overlooked in patterns and component libraries too. That absence creates a feedback loop: if no one teaches it, no one uses it.&lt;/p&gt;
    &lt;p&gt;Like &lt;code&gt;&amp;lt;label&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; has a &lt;code&gt;for=""&lt;/code&gt; attribute. Here you list the &lt;code&gt;id&lt;/code&gt;s of any &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; elements the result depends on, separated by spaces:&lt;/p&gt;
    &lt;code&gt;&amp;lt;input id="a" type="number"&amp;gt; +
&amp;lt;input id="b" type="number"&amp;gt; =
&amp;lt;output for="a b"&amp;gt;&amp;lt;/output&amp;gt;&lt;/code&gt;
    &lt;p&gt;For most users, nothing changes visually. But in the accessibility tree it creates a semantic link, letting assistive technology users connect the inputs with their calculated result.&lt;/p&gt;
    &lt;p&gt;Update 7 Oct 2025: Some screen readers have been found not to announce updates to the tag, so explicitly emphasising the &lt;code&gt;role&lt;/code&gt; attribute might be worthwhile for now until support improves: &lt;code&gt;&amp;lt;output role="status"&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;It doesn‚Äôt require a &lt;code&gt;&amp;lt;form&amp;gt;&lt;/code&gt; either. You can use it anywhere you are updating dynamic text on the page based on the user‚Äôs input.&lt;/p&gt;
    &lt;p&gt;By default &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; is inline, so you‚Äôll usually want to style it for your layout, just as you would a &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt; or &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;And because it has been part of the spec since 2008, support is excellent across browsers and screen readers. It also plays nicely with any JavaScript framework you might be using, like React or Vue.&lt;/p&gt;
    &lt;p&gt;One thing to note: &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; is for results tied to user inputs and actions, not global notifications like toast messages. Those are better handled with &lt;code&gt;role="status"&lt;/code&gt; or &lt;code&gt;role="alert"&lt;/code&gt; on a generic element, since they represent system feedback rather than calculated output.&lt;/p&gt;
    &lt;p&gt;So what does this look like in practice?&lt;/p&gt;
    &lt;p&gt;I‚Äôve personally reached for &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; in multiple real-world projects since discovering it:&lt;/p&gt;
    &lt;p&gt;During a recent 20-minute coding challenge, I used &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; to display calculation results. Without adding a single ARIA role, the screen reader announced each result as it updated. No hacks required.&lt;/p&gt;
    &lt;p&gt;At Volvo Cars, we displayed user-friendly versions of slider values. Internally the slider might hold &lt;code&gt;10000&lt;/code&gt;, but the output showed &lt;code&gt;10,000 miles/year&lt;/code&gt;. We wrapped the slider and &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; in a container with &lt;code&gt;role="group"&lt;/code&gt; and a shared label, creating a cohesive React component:&lt;/p&gt;
    &lt;code&gt;&amp;lt;div role="group" aria-labelledby="mileage-label"&amp;gt;
  &amp;lt;label id="mileage-label" htmlFor="mileage"&amp;gt;
    Annual mileage
  &amp;lt;/label&amp;gt;
  &amp;lt;input
    id="mileage"
    name="mileage"
    type="range"
    value={mileage}
    onChange={(e) =&amp;gt; setMileage(Number(e.target.value))}
  /&amp;gt;
  &amp;lt;output name="formattedMileage" htmlFor="mileage"&amp;gt;
    {mileage.toLocaleString()} miles/year
  &amp;lt;/output&amp;gt;
&amp;lt;/div&amp;gt;&lt;/code&gt;
    &lt;p&gt;I found that password strength indicators and real-time validation messages work beautifully with &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;&amp;lt;label for="password"&amp;gt;Password&amp;lt;/label&amp;gt;
&amp;lt;input type="password" id="password" name="password"&amp;gt;
&amp;lt;output for="password"&amp;gt;
  Password strength: Strong
&amp;lt;/output&amp;gt;&lt;/code&gt;
    &lt;p&gt;The &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; tag even fits modern patterns where you might fetch prices from APIs, show tax calculations, or display server-generated recommendations.&lt;/p&gt;
    &lt;p&gt;Here, a shipping cost calculator updates an &lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; tag, informing users once the cost has been calculated:&lt;/p&gt;
    &lt;code&gt;export function ShippingCalculator() {
  const [weight, setWeight] = useState("");
  const [price, setPrice] = useState("");

  useEffect(() =&amp;gt; {
    if (weight) {
      // Fetch shipping price from server based on package weight
      fetch(`/api/shipping?weight=${weight}`)
        .then((res) =&amp;gt; res.json())
        .then((data) =&amp;gt; setPrice(data.price));
    }
  }, [weight]);

  return (
    &amp;lt;form&amp;gt;
      &amp;lt;label&amp;gt;
        Package weight (kg):
        &amp;lt;input
          type="number"
          name="weight"
          value={weight}
          onChange={(e) =&amp;gt; setWeight(e.target.value)}
        /&amp;gt;
      &amp;lt;/label&amp;gt;
      
      &amp;lt;output name="price" htmlFor="weight"&amp;gt;
        {price ? `Estimated shipping: $${price}` : "Calculating..."}
      &amp;lt;/output&amp;gt;
    &amp;lt;/form&amp;gt;
  );
}&lt;/code&gt;
    &lt;p&gt;There‚Äôs something satisfying about using a native HTML element for what it was designed for, especially when it makes your UI more accessible with less code.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;&amp;lt;output&amp;gt;&lt;/code&gt; might be HTML‚Äôs best kept secret, and discovering gems like this shows how much value is still hiding in the spec.&lt;/p&gt;
    &lt;p&gt;Sometimes the best tool for the job is the one you didn‚Äôt even know you had.&lt;/p&gt;
    &lt;p&gt;üí¨ Comments? Join the discussion on Dev.to ‚Üí&lt;/p&gt;
    &lt;p&gt;üîó Share: Twitter/X ¬∑ LinkedIn ¬∑&lt;/p&gt;
    &lt;p&gt;What happens when accessibility stops being a best practice and starts being the law? We‚Äôre about to find out.&lt;/p&gt;
    &lt;p&gt;We keep changing how we style the web, but the real problem isn‚Äôt CSS. It‚Äôs how we build around it.&lt;/p&gt;
    &lt;p&gt;No spam. Just occasional deep dives on frontend engineering and developer experience.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://denodell.com/blog/html-best-kept-secret-output-tag"/><published>2025-10-11T08:27:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45547807</id><title>Vietnam Airlines Data Breach</title><updated>2025-10-11T15:08:18.140878+00:00</updated><content>&lt;doc fingerprint="9f77c81e4ff274c5"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Vietnam Airlines Data Breach&lt;/head&gt;&lt;head rend="h2"&gt;What Happened&lt;/head&gt;&lt;p&gt;In October 2025, data stolen from the Salesforce instances of multiple companies by a hacking group calling itself "Scattered LAPSUS$ Hunters" was publicly released. Among the affected organisations was Vietnam Airlines, which had 7.5M unique customer email addresses exposed following a breach of its Salesforce environment in June of that year. The compromised data also included names, phone numbers, dates of birth, and loyalty program membership numbers.&lt;/p&gt;&lt;head rend="h2"&gt;Compromised Data&lt;/head&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;p&gt;After a breach every click matters. Guardio‚Äôs AI-powered protection is the only solution that shields you from phishing, scams, and fake logins before they cause damage.&lt;/p&gt;Try Guardio&lt;head rend="h3"&gt;Breach Overview&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Affected Accounts:&lt;/p&gt;&lt;p&gt;7.3 million&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Breach Occurred:&lt;/p&gt;&lt;p&gt;June 2025&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Added to HIBP:&lt;/p&gt;&lt;p&gt;11 Oct 2025&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Recommended Actions&lt;/head&gt;&lt;head rend="h5"&gt;Change Your Password&lt;/head&gt;&lt;p&gt;If you haven't changed your Vietnam Airlines password since 2025, do so immediately.&lt;/p&gt;&lt;head rend="h5"&gt;Enable Two-Factor Authentication&lt;/head&gt;&lt;p&gt;Add an extra layer of security to your account.&lt;/p&gt;&lt;p&gt;Use a password manager to generate and store strong, unique passwords for all your accounts. 1Password helps protect your data with industry-leading security.&lt;/p&gt;Try 1Password&lt;p&gt;Get Aura for identity theft and credit protection. Keep your assets safe with fast fraud alerts, instant credit lock, and $1,000,000 identity theft insurance. Speak to a U.S. based fraud specialist 24/7.&lt;/p&gt;Try Aura&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://haveibeenpwned.com/Breach/VietnamAirlines"/><published>2025-10-11T09:40:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45548457</id><title>Learn Turbo Pascal ‚Äì a video series originally released on VHS</title><updated>2025-10-11T15:08:17.712686+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket ¬© 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=UOtonwG3DXM"/><published>2025-10-11T11:57:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45548967</id><title>Hackers leak Qantas data on 5 million customers after ransom deadline passes</title><updated>2025-10-11T15:08:17.460530+00:00</updated><content>&lt;doc fingerprint="a20d19f7ac5ca186"&gt;
  &lt;main&gt;
    &lt;p&gt;Hackers say they have leaked the personal records of 5 million Qantas customers on the dark web, after a ransom deadline set by the cybercriminals passed.&lt;/p&gt;
    &lt;p&gt;The airline is one of more than 40 firms globally caught up in the hack, reported to contain up to 1 billion customer records.&lt;/p&gt;
    &lt;p&gt;The hacker collective Scattered Lapsus$ Hunters released an extortion note on a data leaks site on the dark web last week, demanding payment in return for preventing the stolen data from being shared.&lt;/p&gt;
    &lt;p&gt;The Qantas data, which was stolen from a Salesforce database in a major cyber-attack in June, included customers‚Äô email addresses, phone numbers, birth dates and frequent flyer numbers. It did not contain credit card details, financial information or passport details.&lt;/p&gt;
    &lt;p&gt;On Saturday the group marked the data as ‚Äúleaked‚Äù, writing: ‚ÄúDon‚Äôt be the next headline, should have paid the ransom.‚Äù&lt;/p&gt;
    &lt;p&gt;Sign up: AU Breaking News email&lt;/p&gt;
    &lt;p&gt;Jeremy Kirk, the executive editor of Cyber Threat Intelligence, said 44 companies had been included in the leak including Gap, Vietnam Airlines, Toyota, Disney, McDonald‚Äôs, Ikea, and Adidas.&lt;/p&gt;
    &lt;p&gt;He said the hacker group was well known and operated out of countries such as the US, UK and Australia.&lt;/p&gt;
    &lt;p&gt;‚ÄúThis particular group is not a new threat; they‚Äôve been around for some time,‚Äù Kirk said. ‚ÄúBut they‚Äôre very skilled in knowing how companies have connected different systems together.‚Äù&lt;/p&gt;
    &lt;p&gt;A Qantas spokesperson previously told Guardian Australia its priorities were ‚Äúcontinued vigilance and providing ongoing support for our customers‚Äù after the June attack.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe continue to offer a 24/7 support line and specialist identity protection advice to affected customers,‚Äù the spokesperson said.&lt;/p&gt;
    &lt;p&gt;A Salesforce spokesperson told Guardian Australia the company ‚Äúwill not engage, negotiate with, or pay any extortion demand‚Äù.&lt;/p&gt;
    &lt;p&gt;There was no indication the Salesforce platform had been compromised, the company said via a statement.&lt;/p&gt;
    &lt;p&gt;‚ÄúWe are aware of recent extortion attempts by threat actors, which we have investigated in partnership with external experts and authorities. Our findings indicate these attempts relate to past or unsubstantiated incidents, and we remain engaged with affected customers to provide support,‚Äù it said.&lt;/p&gt;
    &lt;p&gt;It is understood the global data was stolen between April 2024 and September 2025 and includes personal and contact information of the companies‚Äô customers and employees, including dates of birth, purchase histories and passport numbers.&lt;/p&gt;
    &lt;p&gt;‚ÄúNo company wants to see, you know, hundreds of thousands, or, millions of records of their customers just on the internet,‚Äù Kirk said. ‚ÄúThat‚Äôs awful. It‚Äôs awful for the companies. It‚Äôs awful for the people affected.‚Äù&lt;/p&gt;
    &lt;p&gt;In July, Qantas obtained an ongoing injunction from the NSW supreme court ensuring protections to prevent the stolen data being accessed, viewed, released, used, transmitted or published by anyone, including third parties.&lt;/p&gt;
    &lt;p&gt;Kirk said there was no financial data but criminals could potentially use leaked personal information to open credit cards. He said people should monitor their accounts for suspicious activity, and beware of scam emails that are personalised.&lt;/p&gt;
    &lt;p&gt;‚ÄúThese days, a lot of threat groups are now generating personalised phishing emails,‚Äù he said. ‚ÄúThey‚Äôre getting better and better at this ‚Äì and these types of breaches help sort of fuel that economy, that underground fraudster economy.‚Äù&lt;/p&gt;
    &lt;p&gt;Qantas has been contacted for comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/business/2025/oct/11/hackers-leak-qantas-data-containing-5-million-customer-records-after-ransom-deadline-passes"/><published>2025-10-11T13:27:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45549456</id><title>Tech megacaps lose $770B in value as Nasdaq suffers steepest drop since April</title><updated>2025-10-11T15:08:17.083029+00:00</updated><content>&lt;doc fingerprint="adf891d94dbcc3b8"&gt;
  &lt;main&gt;
    &lt;p&gt;Shares of Amazon, Nvidia and Tesla each dropped around 5% on Friday, as tech's megacaps lost $770 billion in market cap, following President Donald Trump's threats for increased tariffs on Chinese goods.&lt;/p&gt;
    &lt;p&gt;With tech's trillion-dollar companies occupying an increasingly large slice of the U.S. market, their declines sent the Nasdaq down 3.6% and the S&amp;amp;P 500 down 2.7%. For both indexes, it was the worst day since April, when Trump said he would slap "reciprocal" duties on U.S. trading partners.&lt;/p&gt;
    &lt;p&gt;After market close on Friday, Trump declared in a social media post that the U.S. would impose a 100% tariff on China and, on Nov. 1, it would apply export controls "on any and all critical software."&lt;/p&gt;
    &lt;p&gt;Amazon, Nvidia and Tesla all slipped about 2% in extended trading following the post.&lt;/p&gt;
    &lt;p&gt;The president's latest threats are disrupting, at least briefly, what had been a sustained rally in tech, built on hundreds of billions of dollars in planned spending on artificial intelligence infrastructure.&lt;/p&gt;
    &lt;p&gt;In late September, Nvidia, which makes graphics processing units for training AI models, became the first company to reach a market cap of $4.5 trillion. Nvidia alone saw its market capitalization decline by nearly $229 billion on Friday.&lt;/p&gt;
    &lt;p&gt;OpenAI counts on Nvidia's GPUs from a series of cloud suppliers, including Microsoft. OpenAI is only seeing rising demand.&lt;/p&gt;
    &lt;p&gt;In September it introduced the Sora 2 video creation app, and this week the company said the ChatGPT assistant now boasts over 800 million weekly users. Microsoft, which spends heavily on infrastructure to operate its cloud data centers, saw its market cap drop by $85 billion on Friday.&lt;/p&gt;
    &lt;p&gt;The sell-off wiped out Amazon's gains for the year. That stock is now down 2% so far in 2025. Amazon competes with Microsoft to rent out GPUs from its cloud data centers. The online retailer lost $121 billion in value during the day.&lt;/p&gt;
    &lt;p&gt;"There continues to be a lot of noise about the impact that tariffs will have on retail prices and consumption," Amazon CEO Andy Jassy told analysts in July. "Much of it thus far has been wrong and misreported. As we said before, it's impossible to know what will happen."&lt;/p&gt;
    &lt;p&gt;Tesla, which introduced lower-priced vehicles on Tuesday, saw its market capitalization sink by $71 billion.&lt;/p&gt;
    &lt;p&gt;The automaker reports third-quarter results on Oct. 22, with Microsoft earnings scheduled for the following week. Nvidia reports in November.&lt;/p&gt;
    &lt;p&gt;Google parent Alphabet and Facebook owner Meta fell 2% and almost 4%, respectively.&lt;/p&gt;
    &lt;p&gt;WATCH: Pres. Trump: Calculating massive increase of tariffs on Chinese products into U.S.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/10/10/tech-megacaps-market-cap-mag-7.html"/><published>2025-10-11T14:33:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45549524</id><title>Does anyone remember websites?</title><updated>2025-10-11T15:08:16.766322+00:00</updated><content>&lt;doc fingerprint="7b92503539e41efd"&gt;
  &lt;main&gt;
    &lt;p&gt;Does anyone remember websites? These might be unfamiliar to anyone unexposed to the internet before 2005 or so, and may be all-but-forgotten for many others, obscured by the last 10 years of relentless internet development, but before mass social media platforms and amazing business opportunities on the internet, it was largely a collection of websites made by people who were interested in some subject enough to write about it and put it online. Does anyone remember when you stumbled on a new website written by some guy and read his first article, then clicked back to his homepage and saw he had a list of similar articles that looked like they'd be just as interesting. You could spend a whole day reading just the stuff he wrote on that one website. In general, if you found a webpage with something on it you liked, or a writer you liked, you found that everything else he had on there was also interesting to you, and you could generally say you liked the person behind it. Some bigger websites at the time were like mazes with some of the words on each page hyperlinked to other pages on the site that were about each of those separate topics, and you had to open up multiple links from each page otherwise you'd lose them, and you wanted to read every word.&lt;/p&gt;
    &lt;p&gt;Another thing was that there was no dross, because everything had to be written and uploaded by a person. There was no standard format, since there were no real platforms that uniformly stylized anything. There was no sharing or commenting, although later that day you could talk to your friends about the amazing things you read. Most websites were written with html, so they were all unique. They were organic, as everything there had been added because the writer "had to add it" in order to complete the information he had to put out there, and it took a lot of time to make the material and the html page itself, and organize it all so that it worked properly for any guests (in a pretty true sense of the word). And usually the information there was available nowhere else. There were few pictures, mostly words, and almost all of it from the person who created the website himself.&lt;/p&gt;
    &lt;p&gt;Does anyone remember websites? It seems many or most of them have disappeared, since the WayBack machine only started saving sites for posterity in the mid-2000s and before that time, before platforms, websites were hosted by providers who rented space out to people, and after they stopped paying for them (the cost per month was around the equivalent of 2 or 3 hours of minimum wage, I think, through the same company that provided your home phone line and internet connection - sometimes you got some free hosting as part of your internet plan). Lately I've gone looking for them, and haven't found any trace.&lt;/p&gt;
    &lt;p&gt;This article can be discussed on r/TTTThis.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="http://tttthis.com/rememberwebsites.php/"/><published>2025-10-11T14:42:04+00:00</published></entry></feed>