<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-08T00:44:51.367771+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45502216</id><title>Canadian bill would strip internet access from 'specified persons', no warrant</title><updated>2025-10-08T00:44:58.673691+00:00</updated><content>&lt;doc fingerprint="7fe2a1f61ea2d7f5"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;FIRST READING: Canadian bill would strip internet access from 'specified persons'&lt;/head&gt;
    &lt;p&gt;Not too long ago, Liberals were defending internet access as akin to a human right&lt;/p&gt;
    &lt;p&gt;First Reading is a Canadian politics newsletter curated by the National Post’s own Tristin Hopper. To get an early version sent directly to your inbox, sign up here.&lt;/p&gt;
    &lt;head rend="h3"&gt;TOP STORY&lt;/head&gt;
    &lt;p&gt;In spite of multiple international statements framing internet access as a human right, the Liberal government is pursuing legislation that would allow them to unilaterally quarantine Canadian citizens from the online world.&lt;/p&gt;
    &lt;p&gt;Bill C-8, which is now undergoing second reading in the House of Commons, includes a provision under which Ottawa can pull internet services from “any specified person.”&lt;/p&gt;
    &lt;p&gt;The denial of service would requires only the personal order of the minister of industry, a position currently filled by Mélanie Joly, in consultation with the public safety minister, a position currently filled by Gary Anandasangaree.&lt;/p&gt;
    &lt;p&gt;Bill C-8 would do this by amending the Telecommunications Act with a clause requiring telecom providers such as Rogers or Telus to pull the services of any individual customer singled out by Ottawa.&lt;/p&gt;
    &lt;p&gt;As the text states, the industry minister would be allowed to “prohibit a telecommunications service provider from providing any service to any specified person.”&lt;/p&gt;
    &lt;p&gt;None of this would require a warrant, and oversight only kicks in after the order is made.&lt;/p&gt;
    &lt;p&gt;Once a minister has ordered the internet of a “specified person” to be cut off, only then can a Federal Court subject the decision to judicial review.&lt;/p&gt;
    &lt;p&gt;Bill C-8 has been pitched by the Carney government as a way to combat “unprecedented cyber-threats.”&lt;/p&gt;
    &lt;p&gt;In the House of Commons last week, Anandasangaree, the public safety minister defended Bill C-8 as a means to crack down on hackers and ransomware fraudsters.&lt;/p&gt;
    &lt;p&gt;“Malicious cyber-actors are breaching our country’s IT systems, accessing sensitive information and putting lives in danger,” he said.&lt;/p&gt;
    &lt;p&gt;Anandasangaree added that “hostile state actors are stealing information and gaining access to systems that are critical to our national security and public safety.”&lt;/p&gt;
    &lt;p&gt;As to why a federal minister would need the power to deny internet service to specific individuals, Bill C-8 states simply that it might be “necessary to do so to secure the Canadian telecommunications system against any threat, including that of interference, manipulation, disruption or degradation.”&lt;/p&gt;
    &lt;p&gt;Critics of Bill C-8 have mostly pointed to how it gives the federal government massive new powers to collect internet data without a warrant, and without the target even being aware that they’re under surveillance.&lt;/p&gt;
    &lt;p&gt;“Bill C-8 would empower the federal government to secretly order telecom providers “to do anything or refrain from doing anything,” with no limits that would prevent such orders from being used to impose surveillance obligations on private companies, and to weaken encryption standards,” reads a critique published last week by the Canadian Civil Liberties Association.&lt;/p&gt;
    &lt;p&gt;Bill C-8 comes despite a long track record of Liberal government statements slamming government controls on internet access, deeming them an active threat to human rights.&lt;/p&gt;
    &lt;p&gt;Canada was a founding member of the Freedom Online Coalition, an international body dedicated to maintaining free and open access to the online sphere. As such, Canada has frequently signed onto joint statements decrying state control over the internet.&lt;/p&gt;
    &lt;p&gt;In 2019, for instance, Canada signed onto an FOC joint statement decrying “shrinking civic and democratic spaces online as a result of State-sponsored obstruction of free expression, peaceful assembly, and free association.”&lt;/p&gt;
    &lt;p&gt;It was just three years ago that the Liberal government released an info sheet declaring “the rights and freedoms that individuals have offline must also be protected online.”&lt;/p&gt;
    &lt;p&gt;“Canada is committed to working with international partners to protect Internet freedom, including the rights to online freedom of expression, association and peaceful assembly,” it read.&lt;/p&gt;
    &lt;p&gt;Bill C-8 is only the latest in a slew of Liberal-championed bills introducing new controls on the Canadian internet.&lt;/p&gt;
    &lt;p&gt;The Online News Act, made law in 2023, requires social media companies to compensate news outlets for any links shared on their platforms. One of the most visible impacts of the act being that Facebook simply banned the sharing of news links altogether.&lt;/p&gt;
    &lt;p&gt;The Online Streaming Act, made law around the same time, extended Canadian content controls to much of the Canadian internet. Everything from YouTube to Netflix to Canadian podcasts is now subject to federal regulations on what content qualifies as Canadian, and how it should be artificially promoted above non-Canadian offerings.&lt;/p&gt;
    &lt;p&gt;Currently, there is no mechanism by which a private citizen could have their internet services pulled by government order.&lt;/p&gt;
    &lt;p&gt;The closest analogue would probably be bail conditions under which accused criminals can be ordered not to posses a “device capable of accessing the internet.”&lt;/p&gt;
    &lt;head rend="h3"&gt;IN OTHER NEWS&lt;/head&gt;
    &lt;p&gt;It may be hard to remember, but the standards for a political scandal in Canada were once so low that it could become a term-defying disgrace for a member of the prime minister’s office to personally cover the spending overruns of a wayward senator. That’s what Nigel Wright, chief of staff to then prime minister Stephen Harper, did in 2013 when he personally paid off $90,000 worth of expenses charged by then Conservative-appointed senator Mike Duffy. Wright, who lost his job over the matter, just died at age 62 of unspecified causes.&lt;/p&gt;
    &lt;p&gt;First Reading is a Canadian politics newsletter curated by the National Post’s own Tristin Hopper. To get an early version sent directly to your inbox, sign up here.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nationalpost.com/opinion/canadian-bill-would-strip-internet-access-from-specified-persons"/><published>2025-10-07T12:20:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45502502</id><title>The evolution of Lua, continued [pdf]</title><updated>2025-10-08T00:44:57.295221+00:00</updated><content/><link href="https://www.lua.org/doc/cola.pdf"/><published>2025-10-07T12:54:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45502541</id><title>Qualcomm to acquire Arduino</title><updated>2025-10-08T00:44:57.095704+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i"/><published>2025-10-07T13:00:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45503867</id><title>Vibe engineering</title><updated>2025-10-08T00:44:56.916690+00:00</updated><content>&lt;doc fingerprint="a3d0c07761f5138d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Vibe engineering&lt;/head&gt;
    &lt;p&gt;7th October 2025&lt;/p&gt;
    &lt;p&gt;I feel like vibe coding is pretty well established now as covering the fast, loose and irresponsible way of building software with AI—entirely prompt-driven, and with no attention paid to how the code actually works. This leaves us with a terminology gap: what should we call the other end of the spectrum, where seasoned professionals accelerate their work with LLMs while staying proudly and confidently accountable for the software they produce?&lt;/p&gt;
    &lt;p&gt;I propose we call this vibe engineering, with my tongue only partially in my cheek.&lt;/p&gt;
    &lt;p&gt;One of the lesser spoken truths of working productively with LLMs as a software engineer on non-toy-projects is that it’s difficult. There’s a lot of depth to understanding how to use the tools, there are plenty of traps to avoid, and the pace at which they can churn out working code raises the bar for what the human participant can and should be contributing.&lt;/p&gt;
    &lt;p&gt;The rise of coding agents—tools like Claude Code (released February 2025), OpenAI’s Codex CLI (April) and Gemini CLI (June) that can iterate on code, actively testing and modifying it until it achieves a specified goal, has dramatically increased the usefulness of LLMs for real-world coding problems.&lt;/p&gt;
    &lt;p&gt;I’m increasingly hearing from experienced, credible software engineers who are running multiple copies of agents at once, tackling several problems in parallel and expanding the scope of what they can take on. I was skeptical of this at first but I’ve started running multiple agents myself now and it’s surprisingly effective, if mentally exhausting!&lt;/p&gt;
    &lt;p&gt;This feels very different from classic vibe coding, where I outsource a simple, low-stakes task to an LLM and accept the result if it appears to work. Most of my tools.simonwillison.net collection (previously) were built like that. Iterating with coding agents to produce production-quality code that I’m confident I can maintain in the future feels like a different process entirely.&lt;/p&gt;
    &lt;p&gt;It’s also become clear to me that LLMs actively reward existing top tier software engineering practices:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automated testing. If your project has a robust, comprehensive and stable test suite agentic coding tools can fly with it. Without tests? Your agent might claim something works without having actually tested it at all, plus any new change could break an unrelated feature without you realizing it. Test-first development is particularly effective with agents that can iterate in a loop.&lt;/item&gt;
      &lt;item&gt;Planning in advance. Sitting down to hack something together goes much better if you start with a high level plan. Working with an agent makes this even more important—you can iterate on the plan first, then hand it off to the agent to write the code.&lt;/item&gt;
      &lt;item&gt;Comprehensive documentation. Just like human programmers, an LLM can only keep a subset of the codebase in its context at once. Being able to feed in relevant documentation lets it use APIs from other areas without reading the code first. Write good documentation first and the model may be able to build the matching implementation from that input alone.&lt;/item&gt;
      &lt;item&gt;Good version control habits. Being able to undo mistakes and understand when and how something was changed is even more important when a coding agent might have made the changes. LLMs are also fiercely competent at Git—they can navigate the history themselves to track down the origin of bugs, and they’re better than most developers at using git bisect. Use that to your advantage.&lt;/item&gt;
      &lt;item&gt;Having effective automation in place. Continuous integration, automated formatting and linting, continuous deployment to a preview environment—all things that agentic coding tools can benefit from too. LLMs make writing quick automation scripts easier as well, which can help them then repeat tasks accurately and consistently next time.&lt;/item&gt;
      &lt;item&gt;A culture of code review. This one explains itself. If you’re fast and productive at code review you’re going to have a much better time working with LLMs than if you’d rather write code yourself than review the same thing written by someone (or something) else.&lt;/item&gt;
      &lt;item&gt;A very weird form of management. Getting good results out of a coding agent feels uncomfortably close to getting good results out of a human collaborator. You need to provide clear instructions, ensure they have the necessary context and provide actionable feedback on what they produce. It’s a lot easier than working with actual people because you don’t have to worry about offending or discouraging them—but any existing management experience you have will prove surprisingly useful.&lt;/item&gt;
      &lt;item&gt;Really good manual QA (quality assurance). Beyond automated tests, you need to be really good at manually testing software, including predicting and digging into edge-cases.&lt;/item&gt;
      &lt;item&gt;Strong research skills. There are dozens of ways to solve any given coding problem. Figuring out the best options and proving an approach has always been important, and remains a blocker on unleashing an agent to write the actual code.&lt;/item&gt;
      &lt;item&gt;The ability to ship to a preview environment. If an agent builds a feature, having a way to safely preview that feature (without deploying it straight to production) makes reviews much more productive and greatly reduces the risk of shipping something broken.&lt;/item&gt;
      &lt;item&gt;An instinct for what can be outsourced to AI and what you need to manually handle yourself. This is constantly evolving as the models and tools become more effective. A big part of working effectively with LLMs is maintaining a strong intuition for when they can best be applied.&lt;/item&gt;
      &lt;item&gt;An updated sense of estimation. Estimating how long a project will take has always been one of the hardest but most important parts of being a senior engineer, especially in organizations where budget and strategy decisions are made based on those estimates. AI-assisted coding makes this even harder—things that used to take a long time are much faster, but estimations now depend on new factors which we’re all still trying to figure out.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you’re going to really exploit the capabilities of these new tools, you need to be operating at the top of your game. You’re not just responsible for writing the code—you’re researching approaches, deciding on high-level architecture, writing specifications, defining success criteria, designing agentic loops, planning QA, managing a growing army of weird digital interns who will absolutely cheat if you give them a chance, and spending so much time on code review.&lt;/p&gt;
    &lt;p&gt;Almost all of these are characteristics of senior software engineers already!&lt;/p&gt;
    &lt;p&gt;AI tools amplify existing expertise. The more skills and experience you have as a software engineer the faster and better the results you can get from working with LLMs and coding agents.&lt;/p&gt;
    &lt;head rend="h4"&gt;“Vibe engineering”, really?&lt;/head&gt;
    &lt;p&gt;Is this a stupid name? Yeah, probably. “Vibes” as a concept in AI feels a little tired at this point. “Vibe coding” itself is used by a lot of developers in a dismissive way. I’m ready to reclaim vibes for something more constructive.&lt;/p&gt;
    &lt;p&gt;I’ve never really liked the artificial distinction between “coders” and “engineers”—that’s always smelled to me a bit like gatekeeping. But in this case a bit of gatekeeping is exactly what we need!&lt;/p&gt;
    &lt;p&gt;Vibe engineering establishes a clear distinction from vibe coding. It signals that this is a different, harder and more sophisticated way of working with AI tools to build production software.&lt;/p&gt;
    &lt;p&gt;I like that this is cheeky and likely to be controversial. This whole space is still absurd in all sorts of different ways. We shouldn’t take ourselves too seriously while we figure out the most productive ways to apply these new tools.&lt;/p&gt;
    &lt;p&gt;I’ve tried in the past to get terms like AI-assisted programming to stick, with approximately zero success. May as well try rubbing some vibes on it and see what happens.&lt;/p&gt;
    &lt;p&gt;I also really like the clear mismatch between “vibes” and “engineering”. It makes the combined term self-contradictory in a way that I find mischievous and (hopefully) sticky.&lt;/p&gt;
    &lt;head rend="h2"&gt;More recent articles&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;OpenAI DevDay 2025 live blog - 6th October 2025&lt;/item&gt;
      &lt;item&gt;Embracing the parallel coding agent lifestyle - 5th October 2025&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://simonwillison.net/2025/Oct/7/vibe-engineering/"/><published>2025-10-07T14:55:14+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504127</id><title>Show HN: MARS – Personal AI robot for builders (&lt; $2k)</title><updated>2025-10-08T00:44:56.537411+00:00</updated><content>&lt;doc fingerprint="f1df9a7b68a781cd"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey, we’re Axel and Vignesh, cofounders of Innate (&lt;/p&gt;https://www.innate.bot/&lt;p&gt;). We just launched MARS, a general-purpose robot with an open onboard agentic OS built on top of ROS2.&lt;/p&gt;&lt;p&gt;Overview: https://youtu.be/GEOMYDXv6pE&lt;/p&gt;&lt;p&gt;Control demo: https://youtu.be/_Cw5fGa8i3s&lt;/p&gt;&lt;p&gt;Videos of autonomous use-cases: https://docs.innate.bot/welcome/mars-example-use-cases&lt;/p&gt;&lt;p&gt;Quickstart: https://docs.innate.bot/welcome/mars-quick-start.&lt;/p&gt;&lt;p&gt;Our last thread: https://news.ycombinator.com/item?id=42451707&lt;/p&gt;&lt;p&gt;When we started we felt there is currently no good affordable general-purpose that anyone can build on. There’s no lack of demand: hugging face’s SO-100 and LeKiwi are pretty clear successes already; but the hardware is unreliable, the software experience is barebone and keeps changing, and you often need to buy hidden extras to make them work (starting with a computer with a good gpu). The Turtlebots were good, but are getting outdated.&lt;/p&gt;&lt;p&gt;The open-source hobbyist movement lacks really good platforms to build on, and we wanted something robust and accessible. MARS is our attempt at making a first intuitive AI robot for everyone.&lt;/p&gt;&lt;p&gt;What it is:&lt;/p&gt;&lt;p&gt;- It comes assembled and calibrated&lt;/p&gt;&lt;p&gt;- Has onboard compute with a jetson orin nano 8gb&lt;/p&gt;&lt;p&gt;- a 5DoF arm with a wrist camera&lt;/p&gt;&lt;p&gt;- Sensors: RGBD wide-angle cam, 2D LiDAR, speakers&lt;/p&gt;&lt;p&gt;- Control via a dedicated app and a leader arm that plugs in iPhone and Android&lt;/p&gt;&lt;p&gt;- 2 additional USB ports + GPIO pins for extra sensors or effectors.&lt;/p&gt;&lt;p&gt;- And our novel SDK called BASIC that allows to run it like an AI agent with VLAs.&lt;/p&gt;&lt;p&gt;It boots in a minute, can be controlled via phone, programmable in depth with a PC, and the onboard agent lets it see, talk, plan, and act in real-time.&lt;/p&gt;&lt;p&gt;Our SDK BASIC allows to create “behaviors” (our name for programs) ranging from a simple hello world to a very complex long-horizon task involving reasoning, planning, navigation and manipulation. You can create skills that behaviors can run autonomously by training the arm or writing code tools, like for an AI agent.&lt;/p&gt;&lt;p&gt;You can also call the ROS2 topics to control the robot at a low-level. And anything created on top of this SDK can be easily shared with anyone else by just sharing the files.&lt;/p&gt;&lt;p&gt;This is intended for hobbyist builders and education, and we would love to have your feedback!&lt;/p&gt;&lt;p&gt;p.s. If you want to try it, there’s a temporary code HACKERNEWS-INNATE-MARS that lowers the price to $1,799.&lt;/p&gt;&lt;p&gt;p.p.s The hardware and software will be open-sourced too, if some of you want to contribute or help us prepare it properly feel free to join our discord at https://discord.gg/YvqQbGKH&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45504127"/><published>2025-10-07T15:11:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504388</id><title>Launch HN: LlamaFarm (YC W22) – Open-source framework for distributed AI</title><updated>2025-10-08T00:44:55.973017+00:00</updated><content>&lt;doc fingerprint="ed1fa4511bbd11f2"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;Build powerful AI locally, extend anywhere.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;LlamaFarm is an open-source framework for building retrieval-augmented and agentic AI applications. It ships with opinionated defaults (Ollama for local models, Chroma for vector storage) while staying 100% extendable—swap in vLLM, remote OpenAI-compatible hosts, new parsers, or custom stores without rewriting your app.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Local-first developer experience with a single CLI (&lt;code&gt;lf&lt;/code&gt;) that manages projects, datasets, and chat sessions.&lt;/item&gt;
      &lt;item&gt;Production-ready architecture that mirrors server endpoints and enforces schema-based configuration.&lt;/item&gt;
      &lt;item&gt;Composable RAG pipelines you can tailor through YAML, not bespoke code.&lt;/item&gt;
      &lt;item&gt;Extendable everything: runtimes, embedders, databases, extractors, and CLI tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;📺 Video demo (90 seconds): https://youtu.be/W7MHGyN0MdQ&lt;/p&gt;
    &lt;p&gt;Prerequisites:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Install the CLI&lt;/p&gt;
        &lt;p&gt;macOS / Linux&lt;/p&gt;
        &lt;code&gt;curl -fsSL https://raw.githubusercontent.com/llama-farm/llamafarm/main/install.sh | bash&lt;/code&gt;
        &lt;p&gt;Windows (via winget)&lt;/p&gt;
        &lt;code&gt;winget install LlamaFarm.CLI&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Adjust Ollama context window&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Open the Ollama app, go to Settings → Advanced, and set the context window to match production (e.g., 100K tokens).&lt;/item&gt;
          &lt;item&gt;Larger context windows improve RAG answers when long documents are ingested.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Create and run a project&lt;/p&gt;
        &lt;quote&gt;lf init my-project # Generates llamafarm.yaml using the server template lf start # Spins up Docker services &amp;amp; opens the dev chat UI&lt;/quote&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Start an interactive project chat or send a one-off message&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Interactive project chat (auto-detects namespace/project from llamafarm.yaml)
lf chat

# One-off message
lf chat "Hello, LlamaFarm!"&lt;/code&gt;
    &lt;p&gt;Need the full walkthrough with dataset ingestion and troubleshooting tips? Jump to the Quickstart guide.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Prefer building from source? Clone the repo and follow the steps in Development &amp;amp; Testing.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Run services manually (without Docker auto-start):&lt;/p&gt;
    &lt;code&gt;git clone https://github.com/llama-farm/llamafarm.git
cd llamafarm

# Install Nx globally and bootstrap the workspace
npm install -g nx
nx init --useDotNxInstallation --interactive=false

# Option 1: start both server and RAG worker with one command
nx dev

# Option 2: start services in separate terminals
# Terminal 1
nx start rag
# Terminal 2
nx start server&lt;/code&gt;
    &lt;p&gt;Open another terminal to run &lt;code&gt;lf&lt;/code&gt; commands (installed or built from source). This is equivalent to what &lt;code&gt;lf start&lt;/code&gt; orchestrates automatically.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Own your stack – Run small local models today and swap to hosted vLLM, Together, or custom APIs tomorrow by changing &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Battle-tested RAG – Configure parsers, extractors, embedding strategies, and databases without touching orchestration code.&lt;/item&gt;
      &lt;item&gt;Config over code – Every project is defined by YAML schemas that are validated at runtime and easy to version control.&lt;/item&gt;
      &lt;item&gt;Friendly CLI – &lt;code&gt;lf&lt;/code&gt;handles project bootstrapping, dataset lifecycle, RAG queries, and non-interactive chats.&lt;/item&gt;
      &lt;item&gt;Built to extend – Add a new provider or vector store by registering a backend and regenerating schema types.&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Task&lt;/cell&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Notes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Initialize a project&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf init my-project&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Creates &lt;code&gt;llamafarm.yaml&lt;/code&gt; from server template.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Start dev stack + chat TUI&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf start&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Spins up server, rag worker, monitors Ollama/vLLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Interactive project chat&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Opens TUI using project from &lt;code&gt;llamafarm.yaml&lt;/code&gt;.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Send single prompt&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat "Explain retrieval augmented generation"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Uses RAG by default; add &lt;code&gt;--no-rag&lt;/code&gt; for pure LLM.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Preview REST call&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf chat --curl "What models are configured?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Prints sanitized &lt;code&gt;curl&lt;/code&gt; command.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Create dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets create -s pdf_ingest -b main_db research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Validates strategy/database against project config.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Upload files&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets upload research-notes ./docs/*.pdf&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Supports globs and directories.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;Process dataset&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf datasets process research-notes&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Streams heartbeat dots during long processing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Semantic query&lt;/cell&gt;
        &lt;cell&gt;
          &lt;code&gt;lf rag query --database main_db "What did the 2024 FDA letters require?"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Use &lt;code&gt;--filter&lt;/code&gt;, &lt;code&gt;--include-metadata&lt;/code&gt;, etc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;See the CLI reference for full command details and troubleshooting advice.&lt;/p&gt;
    &lt;p&gt;LlamaFarm provides a comprehensive REST API (compatible with OpenAI's format) for integrating with your applications. The API runs at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Chat Completions (OpenAI-compatible)&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What are the FDA requirements?"}
    ],
    "stream": false,
    "rag_enabled": true,
    "database": "main_db"
  }'&lt;/code&gt;
    &lt;p&gt;RAG Query&lt;/p&gt;
    &lt;code&gt;curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "clinical trial requirements",
    "database": "main_db",
    "top_k": 5
  }'&lt;/code&gt;
    &lt;p&gt;Dataset Management&lt;/p&gt;
    &lt;code&gt;# Upload file
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/data \
  -F "file=@document.pdf"

# Process dataset
curl -X POST http://localhost:8000/v1/projects/{namespace}/{project}/datasets/{dataset}/process&lt;/code&gt;
    &lt;p&gt;Check your &lt;code&gt;llamafarm.yaml&lt;/code&gt;:&lt;/p&gt;
    &lt;code&gt;name: my-project        # Your project name
namespace: my-org       # Your namespace&lt;/code&gt;
    &lt;p&gt;Or inspect the file system: &lt;code&gt;~/.llamafarm/projects/{namespace}/{project}/&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;See the complete API Reference for all endpoints, request/response formats, Python/TypeScript clients, and examples.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;llamafarm.yaml&lt;/code&gt; is the source of truth for each project. The schema enforces required fields and documents every extension point.&lt;/p&gt;
    &lt;code&gt;version: v1
name: fda-assistant
namespace: default

runtime:
  provider: openai                   # "openai" for any OpenAI-compatible host, "ollama" for local Ollama
  model: qwen2.5:7b
  base_url: http://localhost:8000/v1 # Point to vLLM, Together, etc.
  api_key: sk-local-placeholder
  instructor_mode: tools             # Optional: json, md_json, tools, etc.

prompts:
  - role: system
    content: &amp;gt;-
      You are an FDA specialist. Answer using short paragraphs and cite document titles when available.

rag:
  databases:
    - name: main_db
      type: ChromaStore
      default_embedding_strategy: default_embeddings
      default_retrieval_strategy: filtered_search
      embedding_strategies:
        - name: default_embeddings
          type: OllamaEmbedder
          config:
            model: nomic-embed-text:latest
      retrieval_strategies:
        - name: filtered_search
          type: MetadataFilteredStrategy
          config:
            top_k: 5
  data_processing_strategies:
    - name: pdf_ingest
      parsers:
        - type: PDFParser_LlamaIndex
          config:
            chunk_size: 1500
            chunk_overlap: 200
      extractors:
        - type: HeadingExtractor
        - type: ContentStatisticsExtractor

datasets:
  - name: research-notes
    data_processing_strategy: pdf_ingest
    database: main_db&lt;/code&gt;
    &lt;p&gt;Configuration reference: Configuration Guide • Extending LlamaFarm&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Swap runtimes by pointing to any OpenAI-compatible endpoint (vLLM, Mistral, Anyscale). Update &lt;code&gt;runtime.provider&lt;/code&gt;,&lt;code&gt;base_url&lt;/code&gt;, and&lt;code&gt;api_key&lt;/code&gt;; regenerate schema types if you add a new provider enum.&lt;/item&gt;
      &lt;item&gt;Bring your own vector store by implementing a store backend, adding it to &lt;code&gt;rag/schema.yaml&lt;/code&gt;, and updating the server service registry.&lt;/item&gt;
      &lt;item&gt;Add parsers/extractors to support new file formats or metadata pipelines. Register implementations and extend the schema definitions.&lt;/item&gt;
      &lt;item&gt;Extend the CLI with new Cobra commands under &lt;code&gt;cli/cmd&lt;/code&gt;; the docs include guidance on adding dataset utilities or project tooling.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Check the Extending guide for step-by-step instructions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Example&lt;/cell&gt;
        &lt;cell role="head"&gt;What it Shows&lt;/cell&gt;
        &lt;cell role="head"&gt;Location&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;FDA Letters Assistant&lt;/cell&gt;
        &lt;cell&gt;Multi-document PDF ingestion, RAG queries, reference-style prompts&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/fda_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Raleigh UDO Planning Helper&lt;/cell&gt;
        &lt;cell&gt;Large ordinance ingestion, long-running processing tips, geospatial queries&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;examples/gov_rag/&lt;/code&gt; &amp;amp; Docs&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Run &lt;code&gt;lf datasets&lt;/code&gt; and &lt;code&gt;lf rag query&lt;/code&gt; commands from each example folder to reproduce the flows demonstrated in the docs.&lt;/p&gt;
    &lt;code&gt;# Python server + RAG tests
cd server
uv sync
uv run --group test python -m pytest

# CLI tests
cd ../cli
go test ./...

# RAG tooling smoke tests
cd ../rag
uv sync
uv run python cli.py test

# Docs build (ensures navigation/link integrity)
cd ..
nx build docs&lt;/code&gt;
    &lt;p&gt;Linting: &lt;code&gt;uv run ruff check --fix .&lt;/code&gt; (Python), &lt;code&gt;go fmt ./...&lt;/code&gt; and &lt;code&gt;go vet ./...&lt;/code&gt; (Go).&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Discord – chat with the team, share feedback, find collaborators.&lt;/item&gt;
      &lt;item&gt;GitHub Issues – bug reports and feature requests.&lt;/item&gt;
      &lt;item&gt;Discussions – ideas, RFCs, roadmap proposals.&lt;/item&gt;
      &lt;item&gt;Contributing Guide – code style, testing expectations, doc updates, schema regeneration steps.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Want to add a new provider, parser, or example? Start a discussion or open a draft PR—we love extensions!&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Licensed under the Apache 2.0 License.&lt;/item&gt;
      &lt;item&gt;Built by the LlamaFarm community and inspired by the broader open-source AI ecosystem. See CREDITS for detailed acknowledgments.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build locally. Deploy anywhere. Own your AI.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/llama-farm/llamafarm"/><published>2025-10-07T15:30:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504470</id><title>IKEA Catalogs 1951-2021</title><updated>2025-10-08T00:44:55.117258+00:00</updated><content>&lt;doc fingerprint="71c3125f48ed4455"&gt;
  &lt;main&gt;
    &lt;p&gt;Good question! We know that a lot of people are curious about what the IKEA catalogue has looked like through the ages. The catalogue has always reflected the age and its views on interior design and everyday living, especially in Sweden, but in recent decades also internationally. The catalogue was in print for 70 years, and by digitising all the catalogues we could make them available to everybody. Making the story of IKEA available to as many people as possible is our main task at IKEA Museum. So we hope that the catalogues will bring some joy and nostalgia, and maybe even a few surprises.&lt;/p&gt;
    &lt;head rend="h1"&gt;IKEA catalogue&lt;/head&gt;
    &lt;p&gt;For over 70 years, the IKEA catalogue was produced in Ãlmhult, constantly growing in number, scope and distribution. From the 1950s when Ingvar Kamprad wrote most of the texts himself, via the poppy, somewhat radical 1970s and all the way into the scaled-down 2000s â the IKEA catalogue always captured the spirit of the time. The 2021 IKEA catalogue was the very last one printed on paper.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1950s&lt;/item&gt;
      &lt;item&gt;1960s&lt;/item&gt;
      &lt;item&gt;1970s&lt;/item&gt;
      &lt;item&gt;1980s&lt;/item&gt;
      &lt;item&gt;1990s&lt;/item&gt;
      &lt;item&gt;2000s&lt;/item&gt;
      &lt;item&gt;2010s&lt;/item&gt;
      &lt;item&gt;2020s&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Just like the perception of the home, the catalogue has changed dramatically since 1951, when it was first published. Look in the older catalogues and youâll be amazed at what you find. In fact, youâll probably even have a giggle or two. In the 1950s and 1960s, there are rarely any people in the pictures, and never any children. But in the 1970s there are children playing all over the home, you can see adults smoking and even the occasional political poster on the wall. Browse on to the 1980s IKEA catalogues and the trends have changed again, with shiny fabrics and other fancy materials. In the 1990s homes become more scaled-down and clearly inspired by a Scandinavian tradition. In this way, the IKEA catalogues are a kind of time capsule for you to travel in. And who knows? When we look back at the most recent catalogues in 10 or 20 yearsâ time, weâll probably shake our heads and give a sigh.&lt;/p&gt;
    &lt;p&gt;IKEA Museum decided to start with the Swedish catalogue as it has been around the longest. In the future, we hope to be able to digitise catalogues from more countries in more languages.&lt;/p&gt;
    &lt;p&gt;No. The IKEA catalogue has always only shown a selection of whatâs available in the stores. The catalogues from the 1970s and onwards show around 30â50 per cent of the entire range. The products that are not featured are generally smaller ones in textiles, decorations and lighting. Temporary collections are rarely included either. But the farther back you go, the higher a percentage of the range can be found in the catalogue.&lt;/p&gt;
    &lt;p&gt;Yes, but the older a product is, the harder it may be to find information about it. If you have a specific question about a product, weâre happy to help you out if we can. But 70 years is a long time, so we canât promise anything. While youâre waiting for our response you can always browse through the catalogues â the product texts that are there are quite detailed. You can search in the catalogues by product name and product type. There are also various stories about different products on our site, and more are constantly being added.&lt;lb/&gt; Browse through stories about IKEA products from 7 decades. &lt;/p&gt;
    &lt;p&gt;IKEA was founded in the 1940s, so why are you showing no catalogues from before 1951?&lt;lb/&gt; The first catalogue did not come out until 1951. Before that, IKEA was a mail order company that didnât sell furniture, but pens, clocks, electric razors, wallets and bags. At that time, the range was only presented in a small mail order brochure called ikÃ©a-nytt (literally ikÃ©a news). Sometimes it was distributed as a supplement in farming paper Jordbrukarnas FÃ¶reningsblad, which reached hundreds of thousands of people in the Swedish countryside. From autumn 1948 Ingvar Kamprad started including furniture in the range, and things quickly grew from there. In the 1950 ikÃ©a-nytt, as many as six of the 18 pages featured furniture. And when you look at the 1951 catalogue, youâll see that there are no more pens and wallets. Ingvar Kamprad was now truly focusing on home furnishing, and shelving the rest.&lt;lb/&gt; Browse through all issues of ikÃ©a-nytt.&lt;/p&gt;
    &lt;p&gt;Not really. We do have a few copies of each yearâs IKEA catalogue in our archives, which weâre saving for posterity. They should be handled as little as possible to keep them in good condition, so weâve made the catalogues available digitally, both online and on monitors at IKEA Museum. You can browse through those as much as you like!&lt;/p&gt;
    &lt;p&gt;Yes you can. The easiest way to share the catalogues is to click on the arrow at the bottom left corner for each catalogue, or in the left-hand menu once youâve started browsing through. This will copy a link which you can share on a website or social media. If you would like to download and publish on your own digital platform, you can share a maximum of three complete digital catalogues. Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more. You may not publish the digital catalogues for commercial purposes.&lt;/p&gt;
    &lt;p&gt;Absolutely! You can share up to 30 images from the catalogues on your own digital platform, such as a blog, on Instagram or similar (as long as itâs not for commercial purposes). Donât forget to state the copyright details, “Â© Inter IKEA Systems B.V.”, the catalogue year, and the link /en/explore/ikea-catalogue/ so that anyone interested can find out more.&lt;/p&gt;
    &lt;p&gt;Yes! You can find all press material, including images, information about current exhibitions and much more, in the IKEA Museum press room.&lt;/p&gt;
    &lt;p&gt;At the moment we have a good amount of catalogues in all languages at the museum, and do not need any more. Having said that, please contact us anyway if youâve been collecting catalogues for several decades, or if you have any other material you think might be of interest to IKEA Museum.&lt;/p&gt;
    &lt;p&gt;Unfortunately not. We sometimes wish we did, as we handle quite a lot of old products that may need putting together and taking apart.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://ikeamuseum.com/en/explore/ikea-catalogue/"/><published>2025-10-07T15:35:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45504973</id><title>Show HN: Timelinize – Privately organize your own data from everywhere, locally</title><updated>2025-10-08T00:44:54.923248+00:00</updated><content>&lt;doc fingerprint="e64842e6eda1dcc1"&gt;
  &lt;main&gt;
    &lt;p&gt;Timelinize ("time-lynn-eyes") is an open source personal archival suite, designed for modern family history. It organizes all your data onto a single, unified timeline on your own computer.&lt;/p&gt;
    &lt;p&gt;Photos, videos, text messages, locations, chats, social media, and more. Timelinize unifies it all.&lt;/p&gt;
    &lt;p&gt;By adding all your data, Timelinize documents your family's life with more detail and privacy, and gives you a more complete view of your story, than standard photo library and journaling apps.&lt;/p&gt;
    &lt;p&gt;Most apps store your data "in the cloud" and out of your control. What if you lost access to your Google/Apple/Facebook accounts, or your phone? By bringing that data home to your own computer, Timelinize preserves a richer story than any one app or service can do alone.&lt;/p&gt;
    &lt;p&gt;Timelinize isn't a replacement for the apps and services you already use, so you don't need to disrupt your way of life. Instead, it "sits behind" what you already use to become the permanent private archive of your working copy from:&lt;/p&gt;
    &lt;p&gt;With several projections for your data, it's easy to keep moments alive that would otherwise be forgotten, rotting on a hard drive in your closet... or in a bigcorp's cloud.&lt;/p&gt;
    &lt;p&gt;The timeline view semantically groups all your data into a single linear layout. Easily see what occurred on a specific day in the order it happened.&lt;/p&gt;
    &lt;p&gt;Visualize your data on a huge, beautiful map of the world that plots points when and where they happened, even for data that doesn't have coordinates (like text messages and emails).&lt;/p&gt;
    &lt;p&gt;Follow connections with people across all kinds of chats and messages. Combine conversations with people across platforms into one view.&lt;/p&gt;
    &lt;p&gt;Browse through a rich display of photos and videos from photo libraries, messages sent and received, and other sources.&lt;/p&gt;
    &lt;p&gt;Add millions of data points to your timeline in a matter of minutes. You get full control over background jobs like imports, thumbnails, and embeddings.&lt;/p&gt;
    &lt;p&gt;Timelinize supports playing "live photos" (or "motion photos") for photos taken on Apple, Google, and Samsung devices.&lt;/p&gt;
    &lt;p&gt;Timelinize specializes in combining data from multiple sets and sources. It can identify people and other entities across data sources by their attributes. If a person or contact appears in multiple data sets, it will automatically merge them if possible. If not, you can easily merge entities with the click of a button.&lt;/p&gt;
    &lt;p&gt;Because Timelinize is entity-aware, it can project data points onto a map even without coordinate data. If a geolocated point is known for an entity around the same time of others of that entity's data points, it will appear on the map.&lt;/p&gt;
    &lt;p&gt;Customize the map to change its theme, layers, and even make it 3D.&lt;/p&gt;
    &lt;p&gt;The heatmap shows where your data is concentrated. It smoothly blends as you zoom in and out.&lt;/p&gt;
    &lt;p&gt;Customize what defines a duplicate item, and how to handle that, with a fine degree of control—perfect for merging separate, disparate data sets.&lt;/p&gt;
    &lt;p&gt;An implicit conversation is discovered when a data source links items and entities with a "sent to" relation. You can easily view conversations between entities across modalities in a single scroll: chats, emails, messages, texts, and more.&lt;/p&gt;
    &lt;p&gt;Since I need this to function well for my own family, I have tried to give special attention to less-visible aspects of this application, such as:&lt;/p&gt;
    &lt;p&gt;Timelinize deduplicates, denoises, clusters, and simplifies location data for optimal preservation, with an algorithm that subjectively performs better than Google Maps Timeline.&lt;/p&gt;
    &lt;p&gt;For nerds like me: you can use Timelinize through its CLI, which mirrors all the functions of the HTTP API used by the frontend.&lt;/p&gt;
    &lt;p&gt;Search for pictures and messages by describing them, or find similar items to what you're viewing.&lt;/p&gt;
    &lt;p&gt;All items are stored verbatim, then thumbnails are generated for all images and video media, which are stored separately. Your original data is not modified.&lt;/p&gt;
    &lt;p&gt;The database schema has been meticulously designed and refined to be as adaptable as possible.&lt;/p&gt;
    &lt;p&gt;Timelinize will continue to develop and evolve. In the future, I anticipate the following capabilities:&lt;/p&gt;
    &lt;p&gt;Annotate your timeline, write rich stories with live embeddings from your timeline data, or make physical media like photo books (but with more than just photos!).&lt;/p&gt;
    &lt;p&gt;Add context to your timeline with additional public timelines which have weather, local/regional news, and global events.&lt;/p&gt;
    &lt;p&gt;Securely and privately share parts of your timeline with trusted friends and family members, directly from your computer to theirs.&lt;/p&gt;
    &lt;p&gt;Right now, Timelinize sits "behind" the apps and platforms you already use. But in the future, you could sync data directly to your timeline as it is originated.&lt;/p&gt;
    &lt;p&gt;Collect your data from various sources. Import it with a few clicks. Within minutes, explore millions of your data points in several intuitive ways.&lt;/p&gt;
    &lt;p&gt;Imported data is copied into your timeline folder, ensuring long-term stability and integrity. Timelines are portable—you can copy them or move them to other devices and computers.&lt;/p&gt;
    &lt;p&gt;Your timeline is simply a folder on disk containing a SQLite database alongside your data files. You can freely explore it with other tooling, so you're not locked into Timelinize.&lt;/p&gt;
    &lt;p&gt;Unlike writing a journal, you don't have to take extra time to create content. You're already making the data your timeline can display! And it doesn't replace your current workflow or apps.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://timelinize.com"/><published>2025-10-07T16:10:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505398</id><title>Cache-Friendly B+Tree Nodes with Dynamic Fanout</title><updated>2025-10-08T00:44:54.746680+00:00</updated><content>&lt;doc fingerprint="eafbc81bf4b08ea8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Cache-Friendly B+Tree Nodes With Dynamic Fanout&lt;/head&gt;&lt;p&gt;For a high-performance B+Tree, the memory layout of each node must be a single contiguous block. This improves locality of reference, increasing the likelihood that the node's contents reside in the CPU cache.&lt;/p&gt;&lt;p&gt;In C++, achieving this means forgoing the use of &lt;code&gt;std::vector&lt;/code&gt;, as it introduces a layer of indirection through a separate memory allocation. The solution to this problem though inevitably increases the implementation complexity and is mired with hidden drawbacks. Nevertheless, this is still a necessary trade-off for unlocking high performance.&lt;/p&gt;&lt;code&gt;  +----------------------+&lt;/code&gt;&lt;head rend="h2"&gt;Challenges&lt;/head&gt;&lt;p&gt;Using &lt;code&gt;std::vector&lt;/code&gt; for a B+Tree node's entries is a non-starter. A &lt;code&gt;std::vector&lt;/code&gt; object holds a pointer to its entries which are stored in a separate block of memory on the heap. This indirection fragments the memory layout, forcing us to fall back on C-style arrays for a contiguous layout when storing variable-length node entries.&lt;/p&gt;&lt;p&gt;This leads to a dilemma. The size of the array must be known at compilation time, yet we need to allow users to configure the fanout (the array's size) at runtime. Furthermore, the implementation should allow inner nodes and leaf nodes to have different fanouts.&lt;/p&gt;&lt;p&gt;This isn't just a B+Tree problem. It is a common challenge in systems programming whenever an object needs to contain a variable-length payload whose size is only known at runtime. How can you define a class that occupies a single block of memory when a part of the block has a dynamic size?&lt;/p&gt;&lt;p&gt;The solution isn't obvious, but it's a well-known trick that systems programmers have used for decades, a technique so common it has eventually been standardized in C99.&lt;/p&gt;&lt;head rend="h2"&gt;The Struct Hack&lt;/head&gt;&lt;p&gt;The solution to this problem is a technique originating in C programming known as the struct hack. The variable-length member (array) is placed at the last position in the struct. To satisfy the compiler an array size of one is hard-coded, ensuring the array size is known at compilation time.&lt;/p&gt;&lt;code&gt;struct Payload {&lt;/code&gt;&lt;p&gt;At runtime, when the required size &lt;code&gt;N&lt;/code&gt; is known, you allocate a single block of memory for the struct and the &lt;code&gt;N&lt;/code&gt; elements combined. The compiler treats this as an opaque block, and provides no safety guarantees. However, accessing the extra allocated space is safe because the variable-length member is the final field in the struct.&lt;/p&gt;&lt;code&gt;// The (N - 1) adjusts for the 1-element array in Payload struct&lt;/code&gt;&lt;p&gt;This pattern was officially standardized in C99, where it is known as a flexible array member.&lt;/p&gt;&lt;p&gt;The C++11 standard formally incorporates the flexible array member, referring to it as an array of unknown bound when it is the last member of a struct.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Arrays of unknown bound&lt;/p&gt;&lt;p&gt;If&lt;/p&gt;&lt;code&gt;expr&lt;/code&gt;is omitted in the declaration of an array, the type declared is "array of unknown bound of T", which is a kind of incomplete type, ...&lt;code&gt;extern int x[]; // the type of x is "array of unknown bound of int"&lt;/code&gt;&lt;lb/&gt;int a[] = {1, 2, 3}; // the type of a is "array of 3 int"&lt;/quote&gt;&lt;p&gt;This means that in C++, the size can be omitted from the final array declaration (e.g. &lt;code&gt;entries_[]&lt;/code&gt;), and the code will compile, enabling the same pattern.&lt;/p&gt;&lt;head rend="h2"&gt;B+Tree Node Declaration&lt;/head&gt;&lt;p&gt;Using the flexible array member syntax, we can now declare a B+Tree node with a memory layout which is a contiguous single block in the heap.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;&lt;p&gt;Using a &lt;code&gt;std::vector&amp;lt;KeyValuePair&amp;gt;&lt;/code&gt; for the node's entries would result in an indirection. This immediately fragments the memory layout. Accessing an entry within a node is slower, and has higher latency because of the pointer indirection. Chasing the pointer increases the probability of a cache miss, which will force the CPU to stall while it waits for the cache line to be fetched from a different region in main memory.&lt;/p&gt;&lt;p&gt;A cache miss will cost hundreds of CPU cycles compared to just a few cycles for a cache hit. This cumulative latency is unacceptable for any high-performance data structure.&lt;/p&gt;&lt;p&gt;This technique avoids the pointer indirection and provides fine-grained control over memory layout. The node header and data are co-located in one continuous memory block. This layout is cache-friendly and will result in fewer cache misses.&lt;/p&gt;&lt;head rend="h2"&gt;Raw Memory Buffer&lt;/head&gt;&lt;p&gt;This is the key step. The construction of the object has to be separate from its memory allocation. We cannot therefore use the standard &lt;code&gt;new&lt;/code&gt; syntax which will attempt to allocate storage, and then initialize the object in the same storage.&lt;/p&gt;&lt;p&gt;Instead, we use the placement new syntax which only constructs an object in a preallocated memory buffer provided by us. We know exactly how much space to allocate, which is information the standard &lt;code&gt;new&lt;/code&gt; operator does not have in this scenario because of the flexible array member.&lt;/p&gt;&lt;code&gt;// A static helper to allocate storage for a B+Tree node.&lt;/code&gt;&lt;p&gt;The result is a cache-friendly B+Tree node with a fanout that can be configured at runtime.&lt;/p&gt;&lt;head rend="h2"&gt;The Price Of Fine-Grained Control&lt;/head&gt;&lt;p&gt;To create an instance of a B+Tree node with a fanout of &lt;code&gt;256&lt;/code&gt;, it is not possible to write simple idiomatic code like this: &lt;code&gt;new BPlusTreeNode(256)&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Instead we use the custom &lt;code&gt;BPlusTreeNode::Get&lt;/code&gt; helper which knows how much raw memory to allocate for the object including the data section.&lt;/p&gt;&lt;code&gt;BPlusTreeNode *root = BPlusTreeNode&amp;lt;KeyValuePair&amp;gt;::Get(256);&lt;/code&gt;&lt;head rend="h3"&gt;Manual Handling Of Deallocation&lt;/head&gt;&lt;p&gt;The destructor code is also not idiomatic anymore. When the lifetime of the B+Tree node ends, the deallocation code has to be carefully crafted to avoid resource or memory leaks.&lt;/p&gt;&lt;code&gt;class BPlusTreeNode {&lt;/code&gt;&lt;p&gt;This carefully ordered cleanup is necessary because we took manual control of memory. The process is the mirror opposite of our &lt;code&gt;Get&lt;/code&gt; function. We constructed the object outside in: raw memory buffer -&amp;gt; node object -&amp;gt; individual elements. So we teardown in the opposite direction, from the inside out: individual elements -&amp;gt; node object -&amp;gt; raw memory buffer.&lt;/p&gt;&lt;head rend="h3"&gt;Adding New Members In A Derived Class&lt;/head&gt;&lt;p&gt;Adding a new member to a derived class will result in data corruption. It is not possible to add new fields to a specialized &lt;code&gt;InnerNode&lt;/code&gt; or &lt;code&gt;LeafNode&lt;/code&gt; class.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;&lt;code&gt;entries_&lt;/code&gt; array in memory.&lt;p&gt;The raw memory we manually allocated is opaque to the compiler and it cannot safely reason about where the newly added members to the derived class are physically located. The end result is it will overwrite the data buffer and cause data corruption.&lt;/p&gt;&lt;p&gt;The workaround is to break encapsulation and add derived members to the base class so that the flexible array member is always in the last position. This is a significant drawback when we begin using flexible array members.&lt;/p&gt;&lt;code&gt;+----------------------+&lt;/code&gt;
&lt;code&gt;InnerNode&lt;/code&gt; and &lt;code&gt;LeafNode&lt;/code&gt; implementations.&lt;head rend="h3"&gt;Reinventing The Wheel&lt;/head&gt;&lt;p&gt;By using a raw C-style array, we effectively reinvent parts of &lt;code&gt;std::vector&lt;/code&gt;, implementing our own utilities for insertion, deletion and iteration. This not only raises the complexity and maintenance burden but also means we are responsible for ensuring our custom implementation is as performant as the highly-optimized standard library version.&lt;/p&gt;&lt;p&gt;The engineering cost to make this implementation production-grade is significant.&lt;/p&gt;&lt;head rend="h3"&gt;Hidden Data Type Assumptions&lt;/head&gt;&lt;p&gt;The &lt;code&gt;BPlusTreeNode&lt;/code&gt;'s generic signature implies it will work for any &lt;code&gt;KeyType&lt;/code&gt; or &lt;code&gt;ValueType&lt;/code&gt;, but this is dangerously misleading. Using a non-trivial type like &lt;code&gt;std::string&lt;/code&gt; will cause undefined behavior.&lt;/p&gt;&lt;code&gt;template &amp;lt;typename KeyType, typename ValueType&amp;gt;&lt;/code&gt;
&lt;p&gt;To understand why, let's look at how entries are inserted. To make space for a new element, existing entries must be shifted to the right. With our low-level memory layout, this is done using bitwise copy, as the following implementation shows.&lt;/p&gt;&lt;code&gt;bool Insert(const KeyValuePair &amp;amp;element, KeyValuePair *pos) {&lt;/code&gt;
&lt;p&gt;The use of &lt;code&gt;std::memmove&lt;/code&gt; introduces a hidden constraint: &lt;code&gt;KeyValuePair&lt;/code&gt; must be trivially copyable. This means the implementation only works correctly for simple, C-style data structures despite its generic-looking interface.&lt;/p&gt;&lt;p&gt;Using &lt;code&gt;std::memmove&lt;/code&gt; on a &lt;code&gt;std::string&lt;/code&gt; object creates a shallow copy. We now have two &lt;code&gt;std::string&lt;/code&gt; objects whose internal pointers both point to the same character buffer on the heap. When the destructor of the original string is eventually called, it deallocates that buffer. The copied string is now left with a dangling pointer to freed memory, leading to use-after-free errors or a double-free crash when its own destructor runs.&lt;/p&gt;&lt;head rend="h2"&gt;Conclusion&lt;/head&gt;&lt;p&gt;The initial hurdle when implementing a B+Tree implementation is solving the contiguous memory layout puzzle avoiding heap indirection. The solution is flexible array members, which makes it possible to compile the program when the number of entries in the B+Tree node is dynamic, and a runtime value.&lt;/p&gt;&lt;p&gt;However, the implementation complexity goes up because of manual memory management, lack of inheritance, and hidden data type constraints. This is unavoidable for high performance.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jacobsherin.com/posts/2025-08-18-bplustree-struct-hack/"/><published>2025-10-07T16:39:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45505539</id><title>Seeing like a software company</title><updated>2025-10-08T00:44:54.461514+00:00</updated><content>&lt;doc fingerprint="2615d9162c2d05e0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Seeing like a software company&lt;/head&gt;
    &lt;p&gt;The big idea of James C. Scott’s Seeing Like A State can be expressed in three points:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Modern organizations exert control by maximising “legibility”: by altering the system so that all parts of it can be measured, reported on, and so on.&lt;/item&gt;
      &lt;item&gt;However, these organizations are dependent on a huge amount of “illegible” work: work that cannot be tracked or planned for, but is nonetheless essential.&lt;/item&gt;
      &lt;item&gt;Increasing legibility thus often actually lowers efficiency - but the other benefits are high enough that organizations are typically willing to do so regardless.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By “legible”, I mean work that is predictable, well-estimated, has a paper trail, and doesn’t depend on any contingent factors (like the availability of specific people). Quarterly planning, OKRs, and Jira all exist to make work legible. Illegible work is everything else: asking for and giving favors, using tacit knowledge that isn’t or can’t be written down, fitting in unscheduled changes, and drawing on interpersonal relationships. As I’ll argue, tech companies need to support both of these kinds of work.&lt;/p&gt;
    &lt;p&gt;Thinking in terms of legibility and illegibility explains so many of the things that are confusing about large software companies. It explains why companies do many things that seem obviously counter-productive, why the rules in practice are so often out of sync with the rules as written, and why companies are surprisingly willing to tolerate rule-breaking in some contexts.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seeing like a state&lt;/head&gt;
    &lt;p&gt;James C. Scott was writing about the “high modernist” movement in governance that produced (among other things) the tidy German forests of the 19th century1. In order to produce wood at scale, the German state demanded legibility: forests that an inspector could visit to tally up the amount of healthy trees. That means that you must be able to walk through the forest - i.e. the underbrush must be controlled - and the trees ought to be ideally laid out in neat rows of a single type.&lt;/p&gt;
    &lt;p&gt;Proponents of legibility often describe their processes as “efficiency measures” or ways to “avoid waste”. But overall, the new “efficient” forests were in fact far less efficient than the old, illegible forests. They produced less wood per year and required more effort to fight disease, because the underbrush proved surprisingly load-bearing to the health of the soil, and the variety of species turned out to have been an asset. The new homogeneous forests could be wiped out by a single parasite or disease in a way that the older, more varied forests could not.&lt;/p&gt;
    &lt;p&gt;However, the advantages of legibility are enormous. Once you know exactly how many trees you have, you can plan ahead, make large trade deals, avoid graft, and so on. To me, this is the most interesting point Scott makes. Large organizations did genuinely think that more legibility would necessarily increase efficiency2. But even when it became clear that that was false, those organizations continued pushing for legibility anyway, because the other advantages were too powerful.&lt;/p&gt;
    &lt;head rend="h3"&gt;Seeing like a software company&lt;/head&gt;
    &lt;p&gt;It’s the same way in software companies. It’s almost a truism among software engineers that a single engineer can be more efficient alone than they can by working as part of a team. That’s why there are so many anecdotes about engineers taking leave to finally get some work done, or about productive work being done on nights and weekends.&lt;/p&gt;
    &lt;p&gt;Likewise, it should be obvious to any practicing engineer that engineer-driven work goes far more swiftly than work that is mandated from above. Engineer-driven work doesn’t need to be translated into something that makes sense, doesn’t need to be actively communicated in all directions, and can in general just be done in the most straightforward and efficient way.&lt;/p&gt;
    &lt;p&gt;This is why tiny software companies are often much better than large software companies at delivering software: it doesn’t matter that the large company is throwing ten times the number of engineers at the problem if the small company is twenty times more efficient3.&lt;/p&gt;
    &lt;p&gt;Why don’t large companies react to this by doing away with all of their processes? Are they stupid? No. The processes that slow engineers down are the same processes that make their work legible to the rest of the company. And that legibility (in dollar terms) is more valuable than being able to produce software more efficiently.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why legibility is valuable to tech companies&lt;/head&gt;
    &lt;p&gt;What does legibility mean to a tech company, in practice? It means:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The head of a department knows, to the engineer, all the projects the department is currently working on&lt;/item&gt;
      &lt;item&gt;That head also knows (or can request) a comprehensive list of all the projects the department has shipped in the last quarter&lt;/item&gt;
      &lt;item&gt;That head has the ability to plan work at least one quarter ahead (ideally longer)&lt;/item&gt;
      &lt;item&gt;That head can, in an emergency, direct the entire resources of the department at immediate work&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note that “shipping high quality software” or “making customers happy” or even “making money” is not on this list. Those are all things tech companies want to do, but they’re not legibility.&lt;/p&gt;
    &lt;p&gt;Our small-but-efficient software company meets only one of these criteria: the ability to pivot to some immediate problem that needs solving. The other information is all locked up in various engineers’ heads, who may or may not remember what they did two months ago (and who certainly won’t be willing to commit to work two months from now). That’s not necessarily a problem, so long as everyone’s on the same page about what needs doing and the product is continuing to improve.&lt;/p&gt;
    &lt;p&gt;A typical large software company meets almost all of these criteria - I say almost, because in some companies or departments the ability to direct immediate work has atrophied (more on that later). But aside from that, large companies are usually very good at cataloguing what is being worked on, remembering what’s been shipped in the past, and planning work in the medium-to-long-term.&lt;/p&gt;
    &lt;p&gt;Why are these capabilities so valuable to a large software company, when small software companies can do without them? This is leaving my area of expertise somewhat, but I’m pretty sure the main answer is large enterprise deals. Making deals with large enterprise customers is fantastically profitable. Any sufficiently large SaaS will thus pivot from small customers to enterprise customers, if it can4. But enterprise deals (a) can take many, many months to set up, and (b) require making long-term feature commitments. An illegible company is not configured to be able to stick with a boring enterprise deal for many months, constantly answering questions and delivering features. Large enterprise customers simply won’t trust a small software company to deliver the things they need over the next year or two.&lt;/p&gt;
    &lt;p&gt;Customers like this typically value legibility very highly, and so demand that their vendors also be legible. In fact, highly legible organizations struggle to communicate at all with organizations that are less legible (and vice versa). They don’t have access to the right bona fides, they don’t talk the same language, and so on. This puts real pressure on growing tech companies to become more legible, even if it hurts their ability to deliver software.&lt;/p&gt;
    &lt;head rend="h3"&gt;Legible assumptions&lt;/head&gt;
    &lt;p&gt;In the pursuit of legibility, large tech companies make simplifying assumptions about the nature of tech work. For instance, they assume:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Any engineers with the same job title perform roughly the same.&lt;/item&gt;
      &lt;item&gt;Engineers can be shuffled and reorganized without substantial loss of productivity.&lt;/item&gt;
      &lt;item&gt;A team will maintain the same level of productivity over time, if it has the same number of engineers.&lt;/item&gt;
      &lt;item&gt;Projects can be estimated ahead of time, albeit with some margin for error. The more time spent estimating a project, the more accurate the estimate will become.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, all of these are false. Within the same job title, there is significant variance in engineering ability. Engineers have different skillsets and interests, and will work much more productively on projects that are a good fit for them. Because of this, the productivity of a team has a weak relationship to the number of engineers on the team.&lt;/p&gt;
    &lt;p&gt;Project estimates are largely fantasy. More accurately, they’re performative: the initial estimate determines the kind of engineering work that gets done to deliver by that estimate, not the other way around. For this reason, breaking down a project into parts and estimating each part often delivers a less accurate estimate, because it makes it harder for engineers to align with the overall ship date.&lt;/p&gt;
    &lt;p&gt;However, these assumptions are true enough for their purpose, which is to provide legibility to the executives in charge of the company. Whether the project estimate is accurate or not, it can be used to plan and to communicate with other large organizations (who are themselves typically aware that these estimates ought not to be taken completely seriously).&lt;/p&gt;
    &lt;head rend="h3"&gt;Temporary sanctioned zones of illegibility&lt;/head&gt;
    &lt;p&gt;I mentioned above that large companies sometimes lose the ability to prioritize immediate work. This is because the processes that make work legible also impose a serious delay. Consider the steps that a hypothetical large company might take before beginning to write code on a problem:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Somebody has a product idea.&lt;/item&gt;
      &lt;item&gt;They take that idea to the Product org, where it goes into the “planning” stage. Meetings are had about the idea.&lt;/item&gt;
      &lt;item&gt;Once the Product org formally decide they want to do it, the idea then passes to the Engineering org: into the hands of some council of engineering architects, who are tasked with the initial technical review. They figure out how it fits into the general engineering priorities and give it a very rough time estimate.&lt;/item&gt;
      &lt;item&gt;The VPs and senior managers in the engineering org then negotiate which team will own the work. Often this is a semi-technical, semi-organizational decision (because which service the work should fall into is at least partly a technical question).&lt;/item&gt;
      &lt;item&gt;Finally the work lands on the team. It enters the team planning backlog, where the team technical lead breaks it out into smaller pieces of work.&lt;/item&gt;
      &lt;item&gt;Those smaller pieces of work enter the team ticket backlog, and are estimated in the team’s weekly planning meeting.&lt;/item&gt;
      &lt;item&gt;Finally some of those pieces of work make it into the next sprint, and are picked up by an engineer who can actually do it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I’m leaving out many crucial parts of this process: the updates on each ticket, which then roll up to higher levels of management, legal and design review, which can themselves take weeks, and then the final steps involved in shipping the change to customers. All of this makes the work very legible, but none of this is compatible with work that has to be done right now. What do you do when there’s a sudden, urgent technical problem - maybe you’re about to overflow your &lt;code&gt;int&lt;/code&gt; ID column on the users table, or some very large customer is experiencing a show-stopping bug?5&lt;/p&gt;
    &lt;p&gt;To solve this kind of problem, tech companies often reserve the right to create temporary zones where illegible work is allowed. Sometimes these are called “virtual teams”, or “strike teams” (or even the colourful name “tiger teams”). They are composed of hand-picked engineers who are trusted by the organization. Often there is no manager assigned at all, but instead some very senior engineer who’s tasked with running the project. These teams are given a loose mandate - like “stop the database from falling over every few days” - and allowed to do basically whatever it takes to get it done.&lt;/p&gt;
    &lt;p&gt;This is a smart compromise between complete illegibility, which as I discussed above would make the company unable to make deals with its richest customers, and complete legibility, which would force even urgent company-killing issues to go through the entire laborious process of scoping, planning and estimating.&lt;/p&gt;
    &lt;p&gt;Even when siloed to a temporary team, sanctioned illegibility still coexists awkwardly with the rest of the organization. Engineers outside the team don’t like seeing other engineers given the freedom to work without the burden of process: either because they’re jealous, or because they’re believers in process and think that such work is unacceptably dangerous. Managers also don’t like extending that level of trust. That’s why sanctioned efforts like this are almost always temporary. The majority of the illegible work that occurs in large organizations is still unsanctioned.&lt;/p&gt;
    &lt;head rend="h3"&gt;Permanent zones of unsanctioned illegibility&lt;/head&gt;
    &lt;p&gt;If you’re an engineer on team A, and you need team B to do some kind of work for you, the formal way to do this is to create an issue in their “planning” backlog and wait for it to go through the entire twelve-step process before it finally makes its way into one of their sprints, where hopefully somebody will pick it up and do it. This can take weeks to months. When what you want is a one-line change, it’s incredibly frustrating to watch your requested work item go through all these steps - each one of which takes many times longer than it would take to simply do the work.&lt;/p&gt;
    &lt;p&gt;The official way around this problem is that team A should anticipate in their planning process that team B will need to do this work, so that piece for team B can enter their backlog at the same time as it enters team A’s backlog. That way (in theory) they should be complete at around the same time6. Any practicing software engineer knows how ridiculous this idea is. You can never anticipate every change that has to be made months before you start writing code.&lt;/p&gt;
    &lt;p&gt;The actual way around this problem is illegible backchannels. An engineer on team A reaches out to an engineer on team B asking “hey, can you make this one-line change for me”. That engineer on team B then does it immediately, maybe creating a ticket, maybe not. Then it’s done! This works great, but it’s illegible because the company can’t expect it or plan for it - it relies on the interpersonal relationships between engineers on different teams, which are very difficult to quantify. If you’re a well-liked engineer, your ability to pull on these backchannels is significantly greater than if you’re brand-new or have a bad reputation. But how well-liked you are is not something companies can officially use when they’re planning projects.&lt;/p&gt;
    &lt;p&gt;Backchannels are a constant presence at all levels of the company. As well as engineer-engineer cross-team backchannels, there are backchannels inside teams, between managers, product managers, and so on. Often when a question is asked formally in a public space, it’s already been rehearsed and workshopped privately with the person who’s answering the question. None of this is or can be documented as part of the formal processes of the company, but it’s load-bearing nonetheless. Many formal processes simply cannot function without the consensus mechanisms or safety valves offered by backchannels.&lt;/p&gt;
    &lt;p&gt;Sometimes backchannels can go badly. Earlier this year I wrote Protecting your time from predators in large tech companies about how some people use backchannels to benefit themselves at the expense of the naive engineers they’re requesting work from. And it never feels good when you get the sense that everyone in a meeting has privately discussed the topic ahead of time except for you. For these reasons, some people think that backchannels themselves are a bad thing, and that all communication should go via formal, legible channels.&lt;/p&gt;
    &lt;head rend="h3"&gt;Sociopaths, clueless, and losers&lt;/head&gt;
    &lt;p&gt;There’s another text which has been as influential to many as Seeing Like A State. This one isn’t a book, but a blog post: The Gervais Principle by Venkatesh Rao. Rao divides organizations into three groups. At the top are the “sociopaths”, who cynically use organizational rules for their own benefit. In middle management are the “clueless”, who are bought into the formal rules of the organization and don’t realise that there’s a deeper game being played above their heads. Below them are the “losers”, who realise there’s a game being played but don’t want to play it. The name “losers” is not a value judgement - I think it’s meant to affectionately pick out people like the leads in Clerks, who are too authentic to get involved in the corporate game.&lt;/p&gt;
    &lt;p&gt;I don’t agree with everything in The Gervais Principle, though I think it’s worth a read (if you’re interested in this stuff, you should also read the excellent Moral Mazes). But the categories here can be very naturally read in terms of legibility. Both sociopaths and losers are engaged with the illegible world of the organization. Sociopaths use this world to climb the ladder, while losers use it to carve out a cosy low-effort niche for themselves.&lt;/p&gt;
    &lt;p&gt;The “clueless” are only engaged with legible processes. They’re the people who, when they want to get promoted, go and look up the formal job ladder and make a plan for how they can exemplify each of the values at the next level. They’re concerned with doing everything by the book. When they’re forced into an encounter with the illegible world, their reaction is to shake their heads and start drafting updates to the legible process that can accommodate some pale approximation of the more-efficient illegible process.&lt;/p&gt;
    &lt;p&gt;I think it’s far too cynical to call these people clueless. Legible process is still very important - after all, it’s the large part of what the organization does. Improving formal processes is still very high-leverage work, even if formal processes can’t ever describe the entirety of how an organization operates. People who are invested in legibility have real value to any tech company.&lt;/p&gt;
    &lt;p&gt;However, thinking about people in Rao’s categories - people who exploit illegibility, people who find it distasteful, and people who use it casually - can be illuminating. Many frequent areas of conflict in software companies stem from the friction between these groups of people.&lt;/p&gt;
    &lt;head rend="h3"&gt;Final thoughts&lt;/head&gt;
    &lt;p&gt;I write a lot about recognizing and using illegibility in tech companies:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Breaking the (formal, legible) rules is sometimes the right thing to do&lt;/item&gt;
      &lt;item&gt;Beware of savvy product managers (and others) exploiting illegible channels to chisel work out of naive engineers&lt;/item&gt;
      &lt;item&gt;Competent engineers should work on “side bets” that are outside the normal planning process&lt;/item&gt;
      &lt;item&gt;Getting promoted to Staff and above has very little to do with the formal job ladder&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In general, advice about illegible processes is what I call “dangerous advice”. It’s dangerous because if you make it legible - for instance, if you announce publicly that you’re getting a piece of work done through backchannels instead of the formal process - you will be punished by the organization even if your management chain wanted you to do it. You can’t speak too loudly about it. It has to stay illegible.&lt;/p&gt;
    &lt;p&gt;I get a lot of negative feedback on these posts from people who say that you should never sidestep the formal process. According to them, if it needs changing, you should change the process instead of going around it. In other words, everything that goes on in a tech company should be legible, and illegible processes should be stamped out and converted to legible ones.&lt;/p&gt;
    &lt;p&gt;I think this view is naive. All organizations - tech companies, social clubs, governments - have both a legible and an illegible side. The legible side is important, past a certain size. It lets the organization do things that would otherwise be impossible: long-term planning, coordination with other very large organizations, and so on. But the illegible side is just as important. It allows for high-efficiency work, offers a release valve for processes that don’t fit the current circumstances, and fills the natural human desire for gossip and soft consensus.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;p&gt;This is the first example Scott gives, but I promise I did read the whole book. Other examples: the construction of Brasília, Operation Vijiji in Tanzania, and the Soviet attempt to replace individual peasant farms with state-run collectives.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;This is a very common false belief today among software engineers.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I don’t think small companies just work harder; plenty of people at large companies work very hard. I also don’t think that small companies just have better engineers - what advantage they have in enthusiasm is often outweighed by the fact that they can’t afford to pay as well.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;I was at Zendesk during the height of its pivot.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Ironically, the most urgent types of problem typically can be solved via a normal “incident” process - but this itself is usually a zone where the rules are relaxed a bit in order to resolve the incident as quickly as possible. Anyway, here I’m not talking about incidents but about projects that will take a couple of weeks to resolve.&lt;/p&gt;↩&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The other, healthier official way is to allow teams to make small changes to other teams’ services themselves. But this only goes so far - the other team will always be the gatekeepers for changes like this, and are always in a position to slow down the change by days or weeks.&lt;/p&gt;↩&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News.&lt;/p&gt;
    &lt;p&gt;September 3, 2025 │ Tags: tech companies&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.seangoedecke.com/seeing-like-a-software-company/"/><published>2025-10-07T16:49:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506143</id><title>German government comes out against Chat Control</title><updated>2025-10-08T00:44:54.161501+00:00</updated><content>&lt;doc fingerprint="77d803d92c0426bd"&gt;
  &lt;main&gt;
    &lt;p&gt;Great news and big win for privacy in the EU! 🇪🇺🇩🇪 Germany’s ruling CDU/CSU party made it clear today: there will be no chat control - as pushed for by other EU countries - with this German government.&lt;/p&gt;
    &lt;p&gt;40 Sekunden kurz und präzise: Mit der CDU/CSU wird es keine anlasslose Chatkontrolle geben, wie sie von einigen Staaten in der EU gefordert wird.&lt;/p&gt;
    &lt;p&gt;Oct 7, 2025 · 4:13 PM UTC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://xcancel.com/paddi_hansen/status/1975595307800142205"/><published>2025-10-07T17:31:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45506268</id><title>Less is more: Recursive reasoning with tiny networks</title><updated>2025-10-08T00:44:54.025815+00:00</updated><content>&lt;doc fingerprint="e51fd9a9ac595e1b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Less is More: Recursive Reasoning with Tiny Networks&lt;/head&gt;
    &lt;p&gt;In this new paper, I propose Tiny Recursion Model (TRM), a recursive reasoning model that achieves amazing scores of 45% on ARC-AGI-1 and 8% on ARC-AGI-2 with a tiny 7M parameters neural network. The idea that one must rely on massive foundational models trained for millions of dollars by some big corporation in order to achieve success on hard tasks is a trap. Currently, there is too much focus on exploiting LLMs rather than devising and expanding new lines of direction. With recursive reasoning, it turns out that “less is more”: you don’t always need to crank up model size in order for a model to reason and solve hard problems. A tiny model pretrained from scratch, recursing on itself and updating its answers over time, can achieve a lot without breaking the bank.&lt;/p&gt;
    &lt;p&gt;This work came to be after I learned about the recent innovative Hierarchical Reasoning Model (HRM). I was amazed that an approach using small models could do so well on hard tasks like the ARC-AGI competition (reaching 40% accuracy when normally only Large Language Models could compete). But I kept thinking that it is too complicated, relying too much on biological arguments about the human brain, and that this recursive reasoning process could be greatly simplified and improved. Tiny Recursion Model (TRM) simplifies recursive reasoning to its core essence, which ultimately has nothing to do with the human brain, does not require any mathematical (fixed-point) theorem, nor any hierarchy.&lt;/p&gt;
    &lt;p&gt;See the paper for more details.&lt;/p&gt;
    &lt;head rend="h3"&gt;TLDR&lt;/head&gt;
    &lt;p&gt;Tiny Recursion Model (TRM) recursively improves its predicted answer y with a tiny network. It starts with the embedded input question x and initial embedded answer y and latent z. For up to K improvements steps, it tries to improve its answer y. It does so by i) recursively updating n times its latent z given the question x, current answer y, and current latent z (recursive reasoning), and then ii) updating its answer y given the current answer y and current latent z. This recursive process allows the model to progressively improve its answer (potentially addressing any errors from its previous answer) in an extremely parameter-efficient manner while minimizing overfitting.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html"/><published>2025-10-07T17:42:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507195</id><title>The murky economics of the data-centre investment boom</title><updated>2025-10-08T00:44:53.901812+00:00</updated><content/><link href="https://www.economist.com/business/2025/09/30/the-murky-economics-of-the-data-centre-investment-boom"/><published>2025-10-07T18:52:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507236</id><title>The publishing industry has a gambling problem</title><updated>2025-10-08T00:44:53.444346+00:00</updated><content>&lt;doc fingerprint="342080157fa50dc9"&gt;
  &lt;main&gt;
    &lt;p&gt;In 1970, a New York publishing company put out a debut novel by an editor and former teacher from Ohio. The press, then known as Holt, Rinehart and Winston, had taken a chance on the book, which had been rejected by numerous other houses. The initial print run was somewhere between 1,200 and 1,500 units—modest expectations that looked justified when, in the first year, sales barely cleared 2,000. This despite getting positive reviews in the New York Times and The New Yorker and being assigned to freshman classes at the City College of New York. The attention wasn’t enough. Four years later, the novel was out of print.&lt;/p&gt;
    &lt;p&gt;The author stayed in the game, albeit precariously. While working on her second book, she was a single parent commuting to Manhattan for a job in publishing. At the time, she was “so strapped for money that the condition moved from debilitating stress to hilarity.” Despite her first book’s lacklustre sales, she found a publisher for her second. The debut had attracted the admiration of a high-profile editor, one who happened to work in the same building she did. He acquired her next title, and the next, keeping her in house as she steadily built acclaim and an audience.&lt;/p&gt;
    &lt;p&gt;Eventually, the writer scored an opportunity still regarded as a grail of book marketing: her debut was chosen for Oprah’s Book Club. Sales reportedly soared to 800,000 copies. Today, publishers hope that their titles will nab the book club stamp—and the ensuing bump in sales—straight out of the gate. But, in this case, the Oprah endorsement came only at the turn of the millennium, thirty years after the novel was first released. By then, the author had published some half dozen other books and cleared the stable of major literary accolades. She had won the National Book Award, the Pulitzer, the Nobel. The author was Toni Morrison. The novel was The Bluest Eye.&lt;/p&gt;
    &lt;p&gt;The careers of many literary titans of the late-twentieth and early twenty-first centuries bear similar hallmarks: The disappointing debut. The stalwart editorial advocate. The understanding that, in order for a writer to truly break out, time is a meaningful factor. For every author whose first try strikes gold—like Philip Roth, whose debut won him the National Book Award at twenty-seven—there’s one like Morrison—or Cormac McCarthy, or Jack Kerouac, or 2025’s Pulitzer Prize–winning fiction writer Percival Everett—on whom a publisher had to take a second, or third, or fourth, or fifth chance. In 1993, reflecting on The Bluest Eye’s reception, Morrison noted its initial life had echoed that of its young Black protagonist, Pecola Breedlove: “dismissed, trivialized, [and] misread.” Nevertheless, the novel is now an essential part of a legacy that reshaped literature.&lt;/p&gt;
    &lt;p&gt;Nowadays, it might not get that opportunity. It’s true most debuts are not, aesthetically, The Bluest Eye. But nor are they as easily granted second chances after commercial disappointment. Instead, there is tremendous pressure to succeed from the beginning. If they fail, all bets are off, sometimes literally. Countless factors contribute to how well a book sells, and there are many points in that chain at which things can break down. If they do, much of the responsibility converges on the writer. That a publisher bet on them and lost means it will be harder to secure the next deal. No matter the reasons for the flop—a tiny marketing budget, staff turnover at the press, cutbacks in culture coverage, backlash toward a hot literary trend—the writer carries the failure on their record.&lt;/p&gt;
    &lt;p&gt;Sales track—or simply track, in industry parlance—is an invisible force shaping contemporary literature. Much depends on that number. On the basis of track, published authors struggle to keep going; those just starting out fear their careers will be severed at the root. Track shapes how an agent pitches a book and how editors assess whether to buy it. Track restricts reader choice by dictating which books are served up as the next big thing (and the next, and the next) and by kneecapping writers deemed insufficiently commercial. The primacy of track, in other words, is a barometer for the health of literary culture. Right now, when the industry is especially skittish, the obsession with finding the next blockbuster hit privileges the survival of the few at the expense of the many.&lt;/p&gt;
    &lt;p&gt;Track is like credit: it might be better to have none at all. When a writer has a book that’s ready to sell, their agent takes the manuscript or proposal out on submission by pitching it to editors. If an editor is interested, they will in turn pitch the project to their company for approval. One of the things that publishing teams look at, when evaluating a book for potential acquisition, is a writer’s past sales. Using tools like BookScan, the industry’s pricey software for tracking units sold, publishers gauge how a previous title fared and whether the author warrants further investment. (BookNet, the equivalent in Canada, is a nonprofit. The data provided by both is incomplete.)&lt;/p&gt;
    &lt;p&gt;Being trailed by one’s sales data gives first-time writers a certain advantage. Debuts are deeply attractive to publishers because, as writer and researcher Laura McGrath puts it, “there is nothing but potential. If your track is zero, there’s only one place for it to go.” The book’s advance is therefore set by anticipation—the publisher’s bid is roughly commensurate with how big they think they can break it out. They reach this number by assigning a value to what McGrath, who studies publishing analytics, calls “soft data”—a bouquet of assumptions about readership, authorship, markets, and genre. Those assumptions are then “turned into something that seems like it should have been arrived upon in a rigorous fashion,” she says, “but it’s not.” If enough bidders get ensorcelled by a project—or by the bloodlust of an auction—the price can be driven up into six or seven figures. The book business may be centred in New York, but the logic is pure Las Vegas.&lt;/p&gt;
    &lt;p&gt;“These books that have huge price tags are given impossible expectations to meet.”&lt;/p&gt;
    &lt;p&gt;If buying the debut is a rollicking night at the craps table, then the sophomore project is the sober morning after. Gone is the clean slate. What publishers really want to see, McGrath says, is growth. “More than any particular number, they’re looking to see a track that is always on the rise.” This is impossible to prove after only one book, especially a book that loses the publisher money. Which is to say: almost all of them. “Most books don’t sell well,” says Alia Hanna Habib, literary agent and author of the forthcoming Take It from Me, a career guide for non-fiction writers. (She counts McGrath among her clients.)&lt;/p&gt;
    &lt;p&gt;Because the majority of books don’t earn out, most people in publishing have the disappointing experience of working on a book they love that, for whatever reason, didn’t hit: “If you’re a fair person, you know it’s not the author’s fault. It’s just the realities of a very difficult market.” Habib won’t suddenly drop a client whose first book didn’t sell. At the same time, that track creates challenges for her. She must come up with a narrative to explain the failure and a case for how the next book might do better. Sometimes, the original publisher wants to move on, so she also has to find someone else willing to take a chance.&lt;/p&gt;
    &lt;p&gt;“When I get sent a project, one of the first things I’ll do is look at the track,” says an editor from an imprint at one of the Big Five presses—the largest, corporate-owned trade publishers: Penguin Random House, Simon &amp;amp; Schuster, HarperCollins, Hachette, and Macmillan—who asked to remain anonymous. Though he evaluates every submission on its merits, he must balance his enthusiasm with practical considerations. Track becomes either an asset to his case for acquiring a book or a hurdle he must overcome by crafting a compelling strategy to convince his team it’s still worth buying.&lt;/p&gt;
    &lt;p&gt;Bad track won’t stop him from considering a project, especially one he is passionate about. Instead, he weighs the factors that may have led to it—maybe the book’s editor was laid off and the author did not receive as much attention. He’ll even reach out to the agent to learn more about what happened. Those conversations can reveal subtler things about how a book was not well supported. Perhaps the publisher positioned it in a way the author disagreed with—a risk, he says, with projects that feature diverse protagonists or are written from a very specific perspective. “Publishers are very fallible,” he says. “Sometimes an author needs a fresh start.”&lt;/p&gt;
    &lt;p&gt;This is another quirk of track. Publishing’s habit of jumping on a trend, especially if that trend is identity based, can come down hard on writers who have been underrepresented in mainstream culture. It can even set them up for failure down the line. Habib cites the moment in 2020 when presses eagerly began acquiring books by Black authors. Many of those presses had never published Black authors in a meaningful way and lacked the infrastructure to properly support those books or help them find readers. “It becomes very easy for a publisher to say now, five years later, ‘Oh, we tried that, and it didn’t work,’” simply because their particular iteration of it didn’t, she says.&lt;/p&gt;
    &lt;p&gt;The other thing the Big Five editor considers when assessing track is the investment the prior book received. If it was put out by a small press and still sold 5,000 copies, that looks like the growth potential McGrath described—imagine what might happen with even more marketing muscle. Conversely, “if there’s someone who we all know was in a huge, million-dollar auction and the book sells 20,000 copies even though it was supposed to sell 100,000, then that’s a different consideration,” he says.&lt;/p&gt;
    &lt;p&gt;Such knowledge is highly piecemeal, even more so than the spotty sales data. Who we all know is more rumour than fact. Publishers don’t know exactly how much a book sold for. Neither the writer nor their agent has to disclose; in fact, it’s in their best interests not to, in case it backfires later.&lt;/p&gt;
    &lt;p&gt;There are the euphemisms used in deal announcements on the industry website Publishers Marketplace—a “very nice” deal connotes an advance in the mid to high five figures, a “good” deal signifies low six figures—or the trades might report on a high-profile auction. An author may also just be forthcoming, in the interest of equity, about how much they were paid, as when the 2020 hashtag #PublishingPaidMe revealed stark disparities in pay between white authors and authors of colour. But transparency at that scale is unusual. “Information about advances is so unreliable,” says McGrath. “When an advance gets published in Publishers Marketplace or Publishers Weekly, I don’t believe that for a second, because that’s all a way of generating excitement.”&lt;/p&gt;
    &lt;p&gt;But if publishers can’t verify a book’s purchase price, on what are they basing the decision that the track is bad? Bad relative to what, other than a general vibes-based sense of hype? There is no solid number that constitutes “good track,” Habib says, and what counts as good varies depending on the genre. In addition to evaluating track based on incomplete BookScan data, publishers are making decisions based on advance sizes they don’t have access to, maybe heard a rumour about, and in fairness to the writer probably shouldn’t be told at all.&lt;/p&gt;
    &lt;p&gt;What’s undeniable is that the market has become harder to break into for writers whose work does not scream commercial.&lt;/p&gt;
    &lt;p&gt;Still, the stigma of overpaying persists. If a writer is the beneficiary of such conditional faith, and then the book’s performance fails to justify it, it’s the writer who bears the stain. “These books that have huge price tags are given impossible expectations to meet,” the editor says. “The fact that a book received a $1 million cheque versus a $50,000 cheque means it’s going to be very hard for their work to continue moving forward.”&lt;/p&gt;
    &lt;p&gt;Habib disagrees with the idea that a high advance automatically sets a writer up for failure. When she is able to get her clients a competitive debut advance, she prepares them for the possibility that it might be the most money they ever receive. “Don’t think of your debut advance as your rate,” she tells them. “Think about it as funding for this stage of your career.” It comes with perks they might get offered only once, like a big publicity budget. It’s a chance to launch a huge career. And for writers, especially those who don’t come from wealth, it is a life-changing amount of money.&lt;/p&gt;
    &lt;p&gt;Despite the careful narrative that an agent and an editor may weave, both separately and in tandem, whether a book gets bought or for how much is ultimately not their call. Even if the Big Five editor loves a project, he still needs to share it with his colleagues and pitch it at an editorial board meeting. If it passes that hurdle, he writes up a formal proposal. Past that, it’s out of his hands: “At the end of the day, the people I am beholden to can say no to just about anything.”&lt;/p&gt;
    &lt;p&gt;Like Habib, he acknowledges that this can be unfair. “The thing that is toughest about track is that it really has nothing to do at all with the author and the author’s work.” This is a vexed Catch-22—that track has nothing to do with the author and yet the author is the one over whose head it hangs. Many writers seem to feel the opposite: that track has everything to do with them.&lt;/p&gt;
    &lt;p&gt;“Due to the author’s previous book sales, this is a pass. . . . I’m afraid the low units will present challenges as our sales team presents to retailers and our marketing and publicity teams pitch [this writer] to media.”&lt;/p&gt;
    &lt;p&gt;This was an email sent to Jeanna Kadlec’s agent when her second book went out on submission to publishers. Her first book, Heretic—a memoir about leaving evangelical Christianity—was acquired by Houghton Mifflin Harcourt at auction for $150,000 (US), the highest offer she received. Almost a year later, HMH was bought by HarperCollins. While Kadlec’s editor stayed on, she suspects she was allocated fewer resources at HarperCollins than she would have been at HMH.&lt;/p&gt;
    &lt;p&gt;The difficulties mounted from there. First came a months-long HarperCollins strike. With it came reviewer boycotts. Readers, too, may have been boycotting the company’s books, even though this wasn’t something the striking employees called for. Once the workers got their deal, Kadlec asked for renewed promotional attention. But HarperCollins declined, seemingly writing off anything that came out during the strike as a loss. When she took her next project to the press, who had a right of first refusal, they passed.&lt;/p&gt;
    &lt;p&gt;It’s on readers to look beyond the season’s biggest titles that they’re being spoon-fed by major publishers.&lt;/p&gt;
    &lt;p&gt;This sounds a bit like trying to buy new insurance for your car after it was totalled by your friend, the professional driver. The circumstances were obviously beyond Kadlec’s control. Still, when she tried to sell her sophomore project, a few editors, especially those at other HarperCollins imprints, explicitly cited her track as part of their rejection. Heretic has sold a few thousand copies—respectable for memoir but, when compared to her six-figure advance, which hints at higher commercial hopes, she admits, “not good math.”&lt;/p&gt;
    &lt;p&gt;These figures seem impossible to separate from the fact that, among other things, Kadlec’s publicist was marching on a picket line rather than continuing to pitch her book to media. (Kadlec, who speaks glowingly of the team assigned to her book, supported their strike demands and even marched alongside them.) But the feedback on submission didn’t seem to consider this. “We couldn’t really see a way to break out the new book,” said another reply, from a HarperCollins editor. “She might be better served with a fresh start in a new home.” Despite the track, Kadlec has managed to sell her next project, albeit at the much lower advance of $30,000 (US).&lt;/p&gt;
    &lt;p&gt;“I don’t know how people are supposed to develop in their careers,” says a novelist who also spoke on the condition of anonymity. She has published multiple books but, owing to editorial shuffles at her publishing houses, has had to take her books out on submission multiple times. “Every single time, the sales track becomes heavier.”&lt;/p&gt;
    &lt;p&gt;It’s frustrating that she alone is saddled with the track, given that a publisher plays just as big a role in a book’s fate, if not bigger. It’s as if they take a book over when they buy it, and then, if it misfires, renounce all responsibility. Like many authors, she feels abandoned by this logic. That writers shoulder the most risk when they have so much less power strikes her as unsustainable. We think of careers as things that progress linearly—the more skills and experience you have, the greater the salary, stability, and respect you can command. “But if you’ve got a mediocre sales track, that’s not the case. You’re lucky if you get a lower offer. You’re lucky if you get an offer at all.”&lt;/p&gt;
    &lt;p&gt;Online, certain tactics are suggested for how to “get over” the ailment of bad track—home remedies meant to replace the old curatives of editorial advocacy and time. A surprising number of sources suggest writing under a pseudonym. They can’t pin a bad track on you, the logic goes, if you take a different name. (Gotcha!) Habib seems unimpressed by this gambit. “It’s very hard to publish under a pseudonym,” she says. “The books that get the most promotion have an author to promote them. You can’t keep making up personae.” (“Or faking your own death,” I say, a tactic neither copped to nor suggested by anyone I spoke to.)&lt;/p&gt;
    &lt;p&gt;The suggestion to write in a new genre also comes up fairly often. This pre-empts the concerns about reaching a different, hopefully bigger audience—the genre will start to do that on its own. Switching genres is one way to mitigate a publisher’s concerns about track, the Big Five editor tells me, especially if the new project is markedly more commercial. This can also get hairy, in that it incentivizes bending one’s career to chase the market. It’s hard enough to keep financial pressures out of one’s creative process, especially under the gun of bad track; this advice doesn’t just let commerce in but puts it smack in the centre of one’s art.&lt;/p&gt;
    &lt;p&gt;Certainly, plenty of people write in multiple genres. But Habib cautions writers against pursuing forms they’re not interested in for the purpose of trying to sell books. As she correctly put it to me, a memoirist and essayist, “You’re in no position to write a great romantasy novel.” Kadlec and her agent tried a subtler genre shift. They hoped that switching from narrative to prescriptive nonfiction would count as enough of a fresh start; that hope wasn’t borne out. “A lot of the advice I hear for folks who do switch genres,” Kadlec says, “is they do a memoir and then they do a novel, and regardless of how the memoir did, the novel is considered a totally clean slate.”&lt;/p&gt;
    &lt;p&gt;This was the sequence Joseph Osmundson was hoping for—to sell a novel after his nonfiction book. His first release with a major press, Virology, is an essay collection that fuses science, queer writing, literary analysis, and memoir. Though his editor was eager to take a chance on the project, the publisher had low expectations. Norton bought it for a modest $15,000 (US), and in trade paperback rather than hardback, a cheaper format that also means the author gets a lower percentage of each sale in royalties counted against the advance.&lt;/p&gt;
    &lt;p&gt;Upon its release, Virology sold so well that Osmundson earned out his advance in three months—something most books never manage, let alone so quickly. According to industry rules, he was golden. A publisher had bet small on him and won big. He had a strong sales track, growth potential, and a proven audience. Fiction gave him the additional advantage of a clean slate even if he didn’t need one. But when his agent took his novel out on submission, the response he kept getting was the same: “We don’t see Joe having a platform or a pattern of fiction publications.”&lt;/p&gt;
    &lt;p&gt;Osmundson was frustrated. “I had been told: work my ass off on my first book, set up a solid track, and you’ll get a bigger advance next time,” only to discover it did not translate into anything for fiction. The novel was either rejected or offered an advance that was on par with his first. In the end, he sold the novel alongside a memoir, but the novel never made it to print. “Do I get tired of proving people wrong?” he asks. “Yes. It is exhausting to constantly feel like my work is undervalued.”&lt;/p&gt;
    &lt;p&gt;Despite widespread conversations in 2020 around equity in publishing, he believes we’re witnessing a general retrenchment in the industry. Decision makers are adopting an even more conservative stance, which steers them toward acquiring books from people who already have built-in audiences—like celebrities or influencers. Such retrenchment is also a labour issue. Publishing is an industry with stagnant salaries, considerable instability, and high turnover. “It’s hard to invest in authors when the people who are working on the books are not being invested in,” says the Big Five editor. He may not have the luxury of nurturing a writer across books, as much as he may want to. The more pressing issue can be, as he puts it, “I need to make a profit so I don’t get fired from this job.”&lt;/p&gt;
    &lt;p&gt;Many factors have likely contributed to this heightened risk aversion: corporate consolidation, a rapidly slimming media market, a volatile political climate. These are not favourable conditions for creative experimentation. While many people I spoke to agree that things feel particularly chilly at the moment, McGrath also takes the long view: “Publishing is always more conservative today than it was ten years ago,” she says. The industry has a habit of glancing back toward the rosy past. But one moment in particular, around 2001, marked a shift, when Nielsen BookScan (now Circana BookScan) first came on the market and began tracking sales. The current, pervasive sense of conservatism, McGrath says, has been exacerbated by the increased reliance on data to justify decisions. If you can put a number on the risk, maybe you think twice before taking it.&lt;/p&gt;
    &lt;p&gt;No matter the reason, what’s undeniable is that the market has become harder to break into for writers whose work does not scream commercial. “I worry a lot about writers who are a decade behind me in their career,” Osmundson says. It was his hope that the success of Virology, despite the book not being obviously mainstream, would create space for more ambitious queer books—his own and others’. Instead, he says, “it feels like that space is actually getting smaller.”&lt;/p&gt;
    &lt;p&gt;When I ask Norm Nehmetallah, publisher of Ontario-based small press Invisible Publishing, about the effect of track’s primacy on literary culture, he sighs. Working at a small press, Nehmetallah and his team can adopt a mandate less beholden to the bottom line than those of the bigger conglomerates. Invisible, in particular, has an explicit focus on finding and nurturing emerging writers. To Nehmetallah, a successful book is less a number than a feeling that it has travelled beyond the expected networks, like the writers’ friends or a particular literary scene.&lt;/p&gt;
    &lt;p&gt;But Nehmetallah, who worked various jobs in the industry before becoming a publisher, has seen the hunger for good track touch his work in various ways—including, oddly, his current role. More and more, he says, his press and others of similar size have been getting submissions from writers who have been dropped from bigger houses, like the imprints of Penguin Random House Canada (one of which is my current publisher). There may be less loyalty there, he says. “I think, in a lot of ways, they are more willing to take on debut authors, and I think that may be coming at the expense of what we would have called their ‘mid-list authors.’”&lt;/p&gt;
    &lt;p&gt;This mid-list cohort is exerting a downward pressure on the publishing landscape. By seeking support at smaller presses, they risk filling the spaces meant for more experimental or early-career authors. This isn’t just bad for writers—it’s bad for literature. If people aren’t given chances to grow and explore in ways the market doesn’t recognize, Nehmetallah says, then readers lose out too. Toronto-based writer Jean Marc Ah-Sen, who has published several books with small and independent presses, feels that he and his peers are being crowded out of their own game. “I used to think that the frontier of literary culture was the indie presses,” he says. “But when a person who has done three books with Penguin gets pushed down, it makes less room for the people who were doing the independent stuff to begin with.” Publishers, as McGrath says, have always been risk averse. But with higher pressure to find a sure thing, more writers who may have been able to sell a book five or ten years ago, whether to a corporate or an independent press, are being left out in the cold.&lt;/p&gt;
    &lt;p&gt;Such retrenchment has come alongside a shrunken and fragmented media industry, in which the shuttering of culture outlets and the decentralization of social media has created a different kind of missing middle: an arid landscape of coverage that’s no longer bustling enough to put a wide range of books on readers’ radars.&lt;lb/&gt; Consumers, too, have a role to play here. As Habib points out, track is also built by the people who buy books, or are supposed to. Nehmetallah makes a similar argument. It’s on readers to look beyond the season’s biggest titles that they’re being spoon-fed by major publishers, he says. This would help literary culture across the board. But it’s a two-way street. By shutting down writers’ chances to build audiences and careers, and restricting the range of what makes it to bookshelves—by spoon-feeding with so much aggression that it can take a lot of effort to close your mouth and turn away to find alternatives—publishers are jeopardizing that ecosystem too.&lt;/p&gt;
    &lt;p&gt;“The literary culture that supports a community of reading and that supports the word-of-mouth spreading is really diminishing,” Kadlec says. “Publishers could be doing so much more than they are actually doing to uplift it. You know,” she says to me. She then names one of my former employers, a company that shuttered its in-house magazine—which sometimes functioned as a built-in arm for promoting the books that it published, as well as a proven space to incubate reputations and platforms.&lt;/p&gt;
    &lt;p&gt;I’ve come to expect this moment of citation, even dread it—to be borne back ceaselessly into this past. But Kadlec is right, I do know. For the past three years since that magazine was shut down, I have seen the writers of my generation lament the loss of that particular launching pad for their essays, their book promotion, their careers. I have seen their debut books get only a handful of reviews in trade magazines. I have seen their publishers decide not to reissue their books in paperback because they didn’t sell “enough” copies. I have also seen my new email address added onto my former employer’s publicity list, asking me to cover their books.&lt;/p&gt;
    &lt;p&gt;Three years after its closure, the magazine’s absence is still felt across the spectrum of publishing. Without spaces like it—in which writers have the opportunity to build an audience prior to selling a book, and publishing workers have a place to secure promotional coverage in a way that actually gets that book out to readers—the infrastructure required to build a decent track erodes into nothing. During those same three years, I’ve watched as the story of that magazine’s shutdown has been reported as if it were purely an outcome of the funding model rather than the choices of its parent company, a publishing house that decided to prioritize profit no differently from how book publishers do every day.&lt;/p&gt;
    &lt;p&gt;The publication’s closure is, in the end, a parable about the whims of capital, albeit not in the way people seem to think. It’s true that publishing professionals hate this state of affairs just as much as writers do. I believe that even more so now than I did before I started working on this piece. But it’s also true that the assault on literary culture that has shattered the avenues for book coverage and ratcheted up the impossible standards by which authors must be rapidly, conclusively adjudged a success or doomed to career failure is not simply a frame being forced on the industry from without. It’s also being perpetuated from within by those who claim to love literature. Trace the call and you’ll find it’s coming from—where else—inside the house.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thewalrus.ca/the-publishing-industry-has-a-gambling-problem/"/><published>2025-10-07T18:55:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507398</id><title>Eliminating contrails from flying could be cheap</title><updated>2025-10-08T00:44:53.122253+00:00</updated><content>&lt;doc fingerprint="774ec8726186b74b"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Eliminating contrails from flying could be incredibly cheap&lt;/head&gt;
    &lt;head rend="h3"&gt;Could we halve aviation's climate impact at a fraction of the cost of sustainable aviation fuels?&lt;/head&gt;
    &lt;p&gt;Eliminating CO2 emissions from flying is going to be expensive, regardless of the solution the world adopts.1&lt;/p&gt;
    &lt;p&gt;But aviation also contributes to global warming through its non-CO2 effects. Those are mostly “contrails”, which I’ll explain in more detail soon. Getting rid of those could be incredibly cheap. So cheap that it’s difficult to understand why we don’t just go ahead and fix it.&lt;/p&gt;
    &lt;p&gt;On a recent podcast, I spoke to Ian McKay, CEO of Orca Sciences, about this. One of their portfolio projects is Contrails.org. Their solution to eliminating contrails is to accurately forecast and model the atmospheric conditions that generate them, and reroute planes so that they avoid these “contrail-forming” parts of the atmosphere.&lt;/p&gt;
    &lt;p&gt;This is a solution that I hadn’t really paid much attention to, and most people are unaware of. So I thought I’d do a deep dive on contrails; explore how this solution might work; and whether it’s really that cheap.&lt;/p&gt;
    &lt;p&gt;To pre-empt the critics: this solution does not mean the aviation industry can ignore the CO2 impacts of flying. Tackling contrails would not absolve them of responsibility for finding low-carbon alternatives to jet fuel. It’s not a substitute, but an addition. Currently, their non-CO2 impacts are not measured or reported, so bringing more attention to contrails means they’re taking full responsibility for their climate impact, which is not the case at the moment.&lt;/p&gt;
    &lt;head rend="h2"&gt;What are contrails?&lt;/head&gt;
    &lt;p&gt;When you see a plane in the sky, you might see a small, white cloud-like trail behind it. Those are contrails (short for “condensation trails”).&lt;/p&gt;
    &lt;p&gt;Water vapour, soot and other particles (basically pollutants) are emitted from the back of jet engines. Water droplets can condense around these particles, and because it’s pretty cold up there, they can freeze to form ice crystals. Sometimes these white lines are very faint and hard to see. But in some cases, they can form “cirrus clouds”: wispy ones that form at high altitudes.&lt;/p&gt;
    &lt;p&gt;These contrails can have both cooling and warming impacts. I’ve sketched this out in the schematic below.&lt;/p&gt;
    &lt;p&gt;Some sunlight can reflect off of them, rather than passing through to the surface, which has a cooling effect.&lt;/p&gt;
    &lt;p&gt;Most sunlight, though, does pass through, and outgoing irradiation then gets trapped by the cirrus clouds. This has a warming effect, which tends to be larger than the cooling one, so on net, contrails cause warming.&lt;/p&gt;
    &lt;p&gt;Since someone asked about this over email: the fact that there is no sunlight at night, and less during winter, there is less to “reflect” off the top of cirrus clouds. That means the cooling effect is weaker at night, and in winter, and the net warming effect stronger. This means avoiding contrails in winter and at night has an even stronger impact on reducing warming.2&lt;/p&gt;
    &lt;head rend="h2"&gt;What impact do they have on global warming?&lt;/head&gt;
    &lt;p&gt;It’s common to want to compare them to CO2 emissions, but it’s first worth emphasising how different the contributions are in terms of intensity and persistence.&lt;/p&gt;
    &lt;p&gt;Contrails have a strong “effective radiative forcing” effect. This basically measures the net change in energy flow at the top of the atmosphere: and that change in energy flow dictates how much warming is needed at the surface to offset it. But, this warming effective is very short-lived. If we were to stop contrails today, the warming effect would disappear within a day or so.&lt;/p&gt;
    &lt;p&gt;Think of it like a very brief but strong pulse of energy.&lt;/p&gt;
    &lt;p&gt;CO2, on the other hand, has a smaller effect on radiative forcing, but once you emit it, it stays there for centuries or more.&lt;/p&gt;
    &lt;p&gt;I thought this diagram from Contrails.org makes this point clearly. This article by them explains the comparison in much more detail.&lt;/p&gt;
    &lt;p&gt;When we think about the climate impacts of aviation, then, most of the warming from CO2 emissions is not due to the emissions this year, but the cumulative effect (which persists) over the past 70 years. But for contrails, the warming impact is only really from those created very recently (hours to days); the small temperature response decays over months to a few years.&lt;/p&gt;
    &lt;p&gt;You might have heard people say that “more than half of the warming caused by aviation comes from non-CO2 sources”. A big part of that is contrails. But this does not mean that for any given flight, half of the warming is coming from contrails and the other half from burning jet fuel.&lt;/p&gt;
    &lt;p&gt;This apparent ‘half-half’ balance is a coincidence of timing: the cumulative CO₂ effect built up over decades happens to be of similar order to the instantaneous contrail effect for that year. In the chart below you can see the effective radiative forcing caused by CO2 and contrails in 2019. Again, the CO2 emitted in 2019 is just a small part of the warming. Most of comes from emissions built over decades, that stay there. It just so happens that this cumulative amount of warming is not that different from the instantaneous, short-lived impact of contrails in 2019. Eventually more and more CO2 emissions will accumulate, and the share coming from contrails will shrink in relative terms.&lt;/p&gt;
    &lt;p&gt;But as it stands today, we could get rid of around half of the warming impact — maybe slightly less — from aviation, if we were to tackle contrails. The impact would be almost immediate.&lt;/p&gt;
    &lt;p&gt;How, then, do contrails stack up in terms of total warming? They contribute roughly 2% to the world’s effective radiative forcing; tackling them would reduce that by a similar amount.3&lt;/p&gt;
    &lt;p&gt;What this comparison should make extremely clear is that reducing contrails does not mean we don’t also need to tackle CO2 emissions from aviation. Ultimately that is the persistent driver of long-term temperature change. What tackling contrails now would do is slightly reduce the rate of warming (and therefore do something reduce the risks of nearer-term feedbacks that could affect the release of CO2 from natural systems, and also affect long-term temperature change). It is not an excuse or a substitute for finding a way to decarbonise jet fuel.&lt;/p&gt;
    &lt;head rend="h2"&gt;Only a few percent of flights cause most of the warming&lt;/head&gt;
    &lt;p&gt;One crucial reason why eliminating contrails could be so cost-effective is that a very small percentage of flights create the majority of the impact. This means we don’t need to divert or shift the trajectory of all the world’s flights; only a few percent of them.&lt;/p&gt;
    &lt;p&gt;In the chart below, you can see the breakdown of the warming effect across the world’s flights.4 On the left-hand side, we have the share of flights, and on the right, their collective contribution to the total warming impact of contrails.&lt;/p&gt;
    &lt;p&gt;Just 3% of flights generate 80% of the warming. A further 14% generate 29%.&lt;/p&gt;
    &lt;p&gt;You might notice that this sums to 109%. But this is because some flights generate a cooling effect of 9%. Put them together and we get 100%.&lt;/p&gt;
    &lt;p&gt;Most flights — three-quarters of them — barely generate contrails at all and cause no warming or cooling.&lt;/p&gt;
    &lt;p&gt;Some sources cite slightly different numbers for this “80% warming effect”. For example, Contrails.org cite 5% of flights. I’ve seen others quote 2%.5 But the point remains the same: a few percent of the flights completely dominate the climate impact.&lt;/p&gt;
    &lt;head rend="h2"&gt;There are ways to dramatically reduce them&lt;/head&gt;
    &lt;p&gt;So, how can we get rid of these contrails?&lt;/p&gt;
    &lt;p&gt;Contrails with a strong warming impact mostly form in thin regions of the atmosphere, which are cold and humid. If planes fly through these zones of atmosphere, contrails are much more likely to form.&lt;/p&gt;
    &lt;p&gt;The solution, then, is for some planes to take a short detour to avoid them. You can see this in the schematic below.&lt;/p&gt;
    &lt;p&gt;How would we know which planes to re-route and by how much?&lt;/p&gt;
    &lt;p&gt;Using detailed weather forecasts, satellite images, and flight plans, scientists can identify where these zones will be far in advance and work with flight planners to find a way to reroute flights crossing these zones to avoid them. These forecasts and models are what Contrails.org do.&lt;/p&gt;
    &lt;p&gt;Google also launched “Project Contrails” which uses Artificial Intelligence (AI) to build models that can do this.&lt;/p&gt;
    &lt;p&gt;Of course, this wouldn’t work if these planes had to do a severe detour. People would not be happy about a longer flight time. And, the extra fuel that would need to be burned to go the extra distance would eventually cancel out the climate benefits from getting rid of the contrails.&lt;/p&gt;
    &lt;p&gt;The proposed detours typically result in a 1% shift (and again, this is only for a small percentage of flights). That means increasing fuel use and flight time by around 1%. So if your flight is three hours long, it’s only adding an extra two minutes. For a 10-hour flight, six minutes. This seems socially acceptable to me; most people would barely notice.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stopping warming from contrails could be incredibly cheap&lt;/head&gt;
    &lt;p&gt;The fact that the warming impact is skewed towards such a small share of flights dramatically reduces the costs.&lt;/p&gt;
    &lt;p&gt;What are the costs associated with implementing this?&lt;/p&gt;
    &lt;p&gt;There are operational costs associated with weather prediction, modelling, and integration into flight planning. Especially with the integration of AI, this is probably not that expensive. A bit more costly is the extra jet fuel that’s needed for rerouted planes.&lt;/p&gt;
    &lt;p&gt;When I spoke with Ian McKay, he suggested the additional cost would be around $5 per flight. I think he meant this as $5 spread across the entire flight (not per passenger). This is also the figure they give on Contrails.org.6 I also think that in this assumption, the costs are spread evenly across the entire airline fleet (regardless of whether they’re rerouted or not). For the small share of rerouted flights alone, the “per flight” cost would be higher.&lt;/p&gt;
    &lt;p&gt;That’s incredibly low. Spreading that over 100 passengers, and each is paying just 5 cents extra.&lt;/p&gt;
    &lt;p&gt;Other studies have reported higher costs, although they’re still incredibly cheap.&lt;/p&gt;
    &lt;p&gt;This paper modelled over 84,000 flights and found that the additional cost of operations and fuel burn for rerouting increased costs by around $1.1 million.7 By my calculations, that’s around $10 to $15 per flight.&lt;/p&gt;
    &lt;p&gt;We can do a very basic back-of-the-envelope calculation to sense-check this. The total fuel cost of flying from Barcelona to Berlin is probably around $2,000.8 If the flight burned 1% extra fuel due to rerouting, the extra cost for the flight would be around $20. Add the operational costs of the forecasting, and this could be $30 to $40. Then spread across all flights, not just the rerouted ones, and this falls back down to the $5 to $10 range again.&lt;/p&gt;
    &lt;p&gt;Transport &amp;amp; Environment (T&amp;amp;E) estimates that the cost could range from $2 to $5 per passenger (or hundreds of dollars per flight).9 They do note that they make very conservative assumptions, and therefore find costs that are 3 to 10 times higher than those from other sources.&lt;/p&gt;
    &lt;p&gt;For a flight in Europe, such as from Barcelona to Berlin, the cost would be €1.20 ($1.88) per passenger. A Transatlantic ticket would be more expensive, around €3.90 for a trip from Paris to New York. Given that an economy ticket from Paris to New York probably costs around €350 to €400, this would increase the cost by around 1%.&lt;/p&gt;
    &lt;p&gt;Perhaps, then, the best estimate is somewhere in the middle: around 50 cents per passenger.&lt;/p&gt;
    &lt;p&gt;Translating this into the cost per tonne of carbon dioxide equivalent — the “carbon abatement” cost — shows how cheap this is compared to many other climate solutions. It’s probably in the range of a few dollars per tonne CO2e. Contrails.org estimates that it’s slightly below $1 per tonne.&lt;/p&gt;
    &lt;p&gt;Switching to “sustainable aviation fuel” currently has an estimated cost in the range of hundreds of dollars per tonne of CO2e avoided.10 Rather than a flight ticket being 1% more expensive, it would be more than double the price. Eliminating contrails is therefore hundreds of times cheaper and can be scaled much more quickly than replacing the entire aircraft fleet or its fuel source.11&lt;/p&gt;
    &lt;head rend="h2"&gt;Why aren’t we doing more to eliminate contrails?&lt;/head&gt;
    &lt;p&gt;When I asked Ian McKay why airlines were not doing more, he gave two main reasons.&lt;/p&gt;
    &lt;p&gt;The first is that even if the cost per flight is low, the total cost across their entire fleet adds up. Let’s take a quick example for British Airways. They operate around 300,000 flights per year. If we reroute 2% of those to avoid contrails, and rerouting increases fuel burn by around 2% (I’m being deliberately harsh here), then I estimate that the additional fuel costs are in the range of $1.2 to $2 million per year.12 Let’s say that the operational costs of forecasting and modelling adds another 50%. That takes us to around $2.5 to $3 million.&lt;/p&gt;
    &lt;p&gt;In 2024, British Airways had an operating profit of around $2.7 billion. Contrail avoidance would therefore be just 0.1% of its operating profits.&lt;/p&gt;
    &lt;p&gt;But I’m not convinced that this cost factor is the main reason. They could pass this cost on to consumers; flight prices vary by a lot more than a few dollars for a variety of factors. They could either make a huge deal of the fact that they’re dramatically cutting their climate impact, and get “PR” buy-in from consumers for that. Or they could keep quiet, and most consumers would never notice the difference in cost.&lt;/p&gt;
    &lt;p&gt;The second — which seems more likely — is that, currently, most people are unaware of the climate impact of contrails. In that sense, airlines can basically ignore it and pretend they don’t exist. By trying to tackle them, they’d only draw more attention. People would then be aware that the climate impact of aviation is even higher than they thought.&lt;/p&gt;
    &lt;p&gt;I still think that the airline that steps up and commits to eliminating contrails — possibly even claiming to have halved its climate impact — would be well-received by many customers. I would see it as reputational gain, rather than a risk.&lt;/p&gt;
    &lt;p&gt;Nonetheless, there are no signs that the aviation industry itself is going to step up. This is where government policy could step in.&lt;/p&gt;
    &lt;p&gt;Rather than an airline leading by example, a country or region could. In a more pro-climate political environment, the United States could have led this effort domestically, mandating that internal flights eliminate their contrails. More likely is the European Union. It has already been making some progress in this direction — not by mandating that airlines pay for contrail avoidance — but by simply reporting these climate impacts in the first place. Earlier this year, its trading system regulations were updated to require airlines to monitor and report non-CO2 impacts. That sounds basic, but it is not the standard across most of the world; these impacts are usually not included. Unsurprisingly, it has received pushback from the aviation industry, with them asking for these reports to be voluntary.&lt;/p&gt;
    &lt;p&gt;Progress will undoubtedly be met with initial resistance, but I still think that regulatory policy seems like the most likely path to widespread implementation.&lt;/p&gt;
    &lt;p&gt;What would help a lot is increasing public awareness of the existence of contrails, their climate impacts, and how inexpensive it could be to eliminate them. There is a general understanding that decarbonising aviation is expensive, and this often means the aviation industry gets more of a free ride. But this is based on replacing jet fuel. If people were aware that it could cut a huge chunk of its footprint at a fraction of the cost, they might be more demanding.&lt;/p&gt;
    &lt;p&gt;Eliminating a few percent of the world’s warming is a big deal when the costs are so small. It seems insane to me that such a cheap solution is sitting there, completely untapped.&lt;/p&gt;
    &lt;p&gt;This could be substituting jet fuel for an alternative such as green hydrogen or biofuels.&lt;lb/&gt;But some suggest that it could be cheaper to keep burning jet fuel and try to capture — and securely store — an equivalent amount of CO2 directly.&lt;/p&gt;
    &lt;p&gt;Their question went further, asking if having some additional warming in winter is actually beneficial as it reduces risks such as cold-related deaths.&lt;lb/&gt;This could be true if the impacts were local. However, the warming that results is both global, and lasts over the long-term (even if the immediate forcing is short-lived, as we’ll come on to).&lt;/p&gt;
    &lt;p&gt;Lee, D. S., Fahey, D. W., Skowron, A., Allen, M. R., Burkhardt, U., Chen, Q., ... &amp;amp; Wilcox, L. J. (2021). The contribution of global aviation to anthropogenic climate forcing for 2000 to 2018. Atmospheric Environment.&lt;/p&gt;
    &lt;p&gt;This is based on data published in the Transport and Environment (T&amp;amp;E) 2024 Report: Contrail avoidance: aviation’s climate opportunity of the decade.&lt;/p&gt;
    &lt;p&gt;Teoh, R., Engberg, Z., Schumann, U., Voigt, C., Shapiro, M., Rohs, S., &amp;amp; Stettler, M. E. (2024). Global aviation contrail climate effects from 2019 to 2021. Atmospheric Chemistry and Physics.&lt;/p&gt;
    &lt;p&gt;Here they say:&lt;lb/&gt;“Better yet, properly implemented, contrail management is low-cost: studies show a fleet-average fuel cost of roughly $5.00 per flight, or less than $1 per tonne of CO2 equivalent warming avoided.”&lt;/p&gt;
    &lt;p&gt;Agarwal, A., Meijer, V. R., Eastham, S. D., Speth, R. L., &amp;amp; Barrett, S. R. (2022). Reanalysis-driven simulations may overestimate persistent contrail formation by 100%–250%. Environmental Research Letters.&lt;/p&gt;
    &lt;p&gt;This assumes burning around 3,000 litres of fuel, weighing around 2.5 tonnes.&lt;lb/&gt;The cost per tonne is around $900.&lt;lb/&gt;That gives a total cost of around $2250.&lt;/p&gt;
    &lt;p&gt;Again, these costs are distributed across all flights, not just those that are rerouted.&lt;/p&gt;
    &lt;p&gt;Watson, M. J., Machado, P. G., Da Silva, A. V., Saltar, Y., Ribeiro, C. O., Nascimento, C. A. O. D., &amp;amp; Dowling, A. W. (2024). Sustainable aviation fuel technologies, costs, emissions, policies, and markets: A critical review. Journal of Cleaner Production.&lt;/p&gt;
    &lt;p&gt;Here’s an ugly, but useful graph from the UK Government’s cost-benefit report on SAFs.&lt;/p&gt;
    &lt;p&gt;This is based on fuel costs ranging from $600 to $1000 per tonne.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sustainabilitybynumbers.com/p/eliminating-contrails"/><published>2025-10-07T19:07:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507880</id><title>User ban controversy reveals Bluesky’s decentralized aspiration isn’t reality</title><updated>2025-10-08T00:44:52.765864+00:00</updated><content>&lt;doc fingerprint="bc98df1bb92e82dd"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;User ban controversy reveals Bluesky’s decentralized aspiration isn’t reality&lt;/head&gt;
    &lt;head rend="h3"&gt;Bluesky’s protocol is so complicated that not even the biggest alternative network has figured out how to become independent&lt;/head&gt;
    &lt;p&gt;When it launched in 2023 in private beta, Bluesky was pitched as a different kind of social network, one that placed openness and user-friendliness at its core. It came along at just the right moment as Elon Musk’s purchase and takeover of Twitter led millions of users head toward any type of exit.&lt;/p&gt;
    &lt;p&gt;The initial destination for many was Mastodon, but its Linux geek ethos and system of numerous “federated” servers that communicate via the open-source ActivityPub protocol proved to be too complicated for people who just wanted to crack jokes. Acting on the opportunity, Bluesky opened up to the public in February 2024 and saw a rapid influx of users.&lt;/p&gt;
    &lt;p&gt;Besides being easier to sign up and use than Mastodon, Bluesky offered a different approach to content moderation that was more flexible and user-driven. In addition to making its software source code available under open licenses, Bluesky wanted to put moderation decisions in the hands of its users, encouraging them to make lists of accounts that could be automatically blocked or labeled—and thereby removing itself as much as possible from moderation decisions that have plagued discussion group administrators since the days of Usenet newsgroups.&lt;/p&gt;
    &lt;p&gt;Millions of people flooded in after Bluesky opened its doors to the public. By November of 2024, there were nearly 1.5 million daily posters, most of them anti-Musk Twitter refugees who were eager to get away from Musk’s right-wing makeover of the site into X.&lt;/p&gt;
    &lt;p&gt;However, as time has gone by, Bluesky’s traffic has declined (X’s has as well) and some of its users have become increasingly upset at its moderation decisions, including allowing U.S. Vice President J.D. Vance and anti-trans writer Jesse Singal to remain as users of the platform. Singal became a particular target, prompting a petition with more than 28,000 signatures urging Bluesky to “enforce its Community Guidelines” against him that has not been successful, although he has been temporarily banned.&lt;/p&gt;
    &lt;p&gt;Accusations of indifference to anti-trans bigotry seem to have exacerbated some users’ frustrations with the platform for its alleged tolerance of racist content. In 2023, many launched a “posting strike” after they discovered that Bluesky allowed people to sign up for user names containing racial slurs, a policy the company quickly reversed and apologized for.&lt;/p&gt;
    &lt;p&gt;The labeling feature of Bluesky has been more positively regarded, with many people subscribing to lists to label or block Trump supporters, Singal, and other widely disliked journalists. But things have not been perfect. Several users have complained about being added to libelously named lists, while others have complained that stalkers have added them to numerous lists out of revenge. Trying to balance concerns between legitimate blocklist maintainers and victims of false accusations, Bluesky unveiled a series of changes to its terms of service which brought it more in line with other social platforms, but also sparked controversy because now users can get blocklists hidden by reporting on them.&lt;/p&gt;
    &lt;p&gt;The failure of the Singal ban effort has also continued to grate on Bluesky’s most persistent critics, and the site’s executives have been met with many critical and often off-topic replies and quote posts.&lt;/p&gt;
    &lt;p&gt;While Bluesky has been navigating user concerns, its engineering team has been moving ahead with its long-promised open source efforts, breaking up its software stack into several pieces to enable a federated Authenticated Transfer Protocol (ATProto) network where anyone with the know-how and funds could run their own copy of Bluesky.&lt;/p&gt;
    &lt;p&gt;There are several key pieces of code that combine to make the Bluesky network function: A personal data server (PDS) which hosts the official/canonical copies of its users’ posts and profile information. Whenever it’s updated, the data is combined and sent to a Relay server, which combines and indexes posts from many different PDSes to create what social networks call the “firehose,” the collection of all posts made on the network.&lt;/p&gt;
    &lt;p&gt;The firehose data is imported by a labeler program which categorizes it in various ways set up by users, the processed data is combined together by an application server (or AppViews as they’re called for now in Bluesky). When a user logs into their PDS and pushes “refresh,” their local app connects to the PDS’s designated feed generator which serves up a cached version of the accounts they follow.&lt;/p&gt;
    &lt;p&gt;While the ATProto system has been criticized as overly complicated compared to the ActivityPub system that powers the Fediverse, it has one key feature that ActivityPub lacks: the ability to transfer servers while keeping all of your followers and posts.&lt;/p&gt;
    &lt;p&gt;Due to the complexity of the Bluesky software stack, whether its federation model actually works in practice has not really been put to the test. While ActivityPub has several instances with millions of users (like Facebook Threads, Flipboard, and even Donald Trump’s Truth Social), it also has many much smaller ones run by small organizations and individuals.&lt;/p&gt;
    &lt;p&gt;As of this writing, however, the only completely independent implementation of ATProto is Bluesky. But that isn’t for want of trying on the part of Rudy Fraser, the creator of Blacksky, an alternative service that he unveiled in May of 2023 in response to Black American users’ complaints about Bluesky’s moderation policies.&lt;/p&gt;
    &lt;p&gt;Despite Fraser’s efforts to implement his own PDS, Relay, and App View, however, Blacksky still remains partially dependent upon Bluesky’s application server, largely because while the code to implement the dataplane of posts and users within an application server is released, the open-source version is slower. As a result, Blacksky is dependent on Bluesky’s application server to give users a fast experience, which also means that it is dependent on Bluesky’s labeling system and its moderation choices.&lt;/p&gt;
    &lt;p&gt;The labeling software, called Ozone, also has issues, according to Bluesky engineer Bryan Newbold.&lt;/p&gt;
    &lt;p&gt;“Making it easier to run moderation services is something we want to do. we invested a lot of time and effort in Ozone, but have not been able to focus on making it usable/accessible for independent folks,” he wrote in an Oct. 3 post, adding that “we are looking at funding folks to fork or re-implement it for community use-case.”&lt;/p&gt;
    &lt;p&gt;This limitation is likely to be another reason why Blacksky relies on Bluesky's AppView. Without it, Blacksky’s independent moderators couldn't actually perform their task. (Fraser did not respond to repeated attempts to contact him for comment.)&lt;/p&gt;
    &lt;p&gt;Blacksky’s continued dependency on Bluesky came into focus on Sunday after a Blacksky user going by the handle Link suddenly found himself unable to view his own posts on the alternative site.&lt;/p&gt;
    &lt;p&gt;“My account was taken down without any explanation for almost a full day,” Link told me in a Signal message, showing me a screenshot indicating that he had been banned even as his Blacksky account remained capable of viewing others’ posts and changing preferences. Unbeknownst to him, Link’s account had been banned by Bluesky’s moderators and this meant that even though he was in good standing at Blacksky, no one there, including himself, was able to read his posts. (They are visible within the ATProto firehose feed, however, as several sharp-eyed users soon discovered.)&lt;/p&gt;
    &lt;p&gt;Link’s banning came at a very bad moment for Bluesky, just weeks after it had banned or suspended several users following the Sept. 10 murder of far-right activist Charlie Kirk, which many Republican officials have sought to use as a tool for government censorship.&lt;/p&gt;
    &lt;p&gt;Federal Communications Commission Brendan Carr’s threats against late night comedian Jimmy Kimmel led to his temporary suspension by ABC, and he was far from the only Republican to issue them. Louisiana Rep. Clay Higgins, chair of the House subcommittee on federal law enforcement, sent a menacing letter to Bluesky and other social media networks demanding that they identify and ban anyone deemed to be celebrating Kirk’s killing.&lt;/p&gt;
    &lt;p&gt;“The authors of these posts are to be identified and banned from your platform, as well as any new pages they may create,” he wrote. “The reasonable restriction of public statements that lie far beyond the standards of our own society is not an oppression of free speech, it is, rather, the protection of free speech.”&lt;/p&gt;
    &lt;p&gt;There’s no proof that Higgins’s threats against social media platforms led to Bluesky banning anyone, but in any case, more than a few users were permanently or temporarily banned for mocking Kirk’s death, including horror author Gretchen Felker-Martin.&lt;/p&gt;
    &lt;p&gt;The fallout from the Kirk controversies and the months of replies seems to have irked Bluesky CEO Jay Graber, and she began pushing back on the user complaints. On Oct. 1, she approvingly quoted a user who had referenced the famous pancakes-waffle Twitter meme about how liking pancakes doesn’t mean disliking waffles, adding: “Too real. We’re going to try to fix this. Social media doesn’t have to be this way.”&lt;/p&gt;
    &lt;p&gt;Graber’s post was soon met by a reply asking if she’d banned Singal yet, prompting her to respond in all-caps: “WAFFLES.”&lt;/p&gt;
    &lt;p&gt;The next day, Thursday, Graber returned to her theme, posting a photograph of a berry-covered waffle, accompanied with the caption: “Amazing breakfast this morning. I love waffles.”&lt;/p&gt;
    &lt;p&gt;As might be expected, Graber’s trolling was not taken well by her critics. The waffles post received more than 1,700 replies, including many mocking her as a Musk-like figure.&lt;/p&gt;
    &lt;p&gt;On Friday, Graber turned more serious in her pushback: “Harassing the mods into banning someone has never worked. And harassing people in general has never changed their minds,” she wrote, adding later that: “Yet it’s a behavior that persists across social media anyway, with negative consequences for civil discourse and society. Human nature is a contributing factor, but systems that reward outrage only make the problem worse.”&lt;/p&gt;
    &lt;p&gt;Among the more than 100 people who quoted Graber’s post that day was Link. He posted a photo of Kirk which he accompanied with descriptive text that read: “Charlie Kirk sitting in a white T-shirt that says freedom. A negative consequence follows.”&lt;/p&gt;
    &lt;p&gt;Link made a number of other posts after to that one, but on Sunday his Blacksky account stopped working. After receiving no contact from either Blacksky or Bluesky, Link messaged Bluesky’s moderation team and received an email about 3 hours later saying that he had violated the social network’s community guidelines in his quote of Graber days earlier, presumably its policies against “threats or encouragement of violence.”&lt;/p&gt;
    &lt;p&gt;That is not how Link sees his post.&lt;/p&gt;
    &lt;p&gt;“I want to be extremely clear I was not making a death threat or inciting violence,” he told me, saying that he had sent 12 separate examples of other people posting the same Kirk image as a reaction meme. “I don’t wish death on Jay, I wish for her and her team to grow a conscience. I disagree with the decision and how it was handled. My account was taken down without any explanation for almost a full day in what can only be viewed as a retroactive ban.”&lt;/p&gt;
    &lt;p&gt;I’ve asked Bluesky whether the post had been reported as a violation by other users. I will update this story if I receive a response. Rudy Fraser, the Blacksky administrator has not responded to a request for comment.&lt;/p&gt;
    &lt;p&gt;Asked about why Link had to contact Bluesky to find out what had happened to his account rather than receiving a notice, Paul Frazee, the service’s CTO, said that it was “unfortunate,” and that Bluesky needed to finish adding a feature to let users of external PDSes know if they have been banned by Bluesky labelers.&lt;/p&gt;
    &lt;p&gt;Agree or disagree on whether Bluesky has treated Link fairly, the incident has exposed that the social network’s decentralization plans have yet to be fulfilled. Blacksky seems to be the furthest-along alternative ATProto implementation, but it’s still dependent on Bluesky. There’s another one called Northsky Social, but it has not launched any services yet. And while there are several alternative AppViews such as Deer.social, there does not seem to be any service (or combination of services) that can function as a full-stack implementation of ATProto.&lt;/p&gt;
    &lt;p&gt;This might explain why, despite having a network of nearly 40 million users, no situation like Link’s banning seems to have happened during Bluesky’s very short lifespan.&lt;/p&gt;
    &lt;p&gt;The episode has sent more than a few Bluesky users to start wondering whether the snow-covered grass on Mastodon’s side of the road is worth considering.&lt;/p&gt;
    &lt;p&gt;But not everyone is looking forward to the idea: “I’d go back to Usenet before I went back to Mastodon,” wrote Bluesky user Count Von Horse Knuckler. “I do not need people yelling at me for not putting cat pictures behind trigger warnings or unwanted Linux advice.”&lt;/p&gt;
    &lt;p&gt;Help may be on the horizon, however. As developers are becoming more aware of the power of ATProto, they are building increasingly complex projects on it, including a promising service called Slices, which aims to make it easy to build and deploy custom AppViews, a feature Blacksky and other Bluesky alternatives could certainly use. Bluesky execs have said they are working hard to make federation easier.&lt;/p&gt;
    &lt;p&gt;Meanwhile, Link is caught in limbo.&lt;/p&gt;
    &lt;p&gt;“Now my account is not viewable on either Blacksky or Bluesky,” he notes. “I’m fortunate that I moved over to Blacksky and I think that is the only reason I still have access to my account and data…Bluesky claims to want decentralization and composable moderation, but they still enjoy abusing the power of arbitrary banishment.”&lt;/p&gt;
    &lt;p&gt;This story has been updated to include a post from Bluesky developer Bryan Newbold.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://plus.flux.community/p/banning-controversy-reveals-blueskys"/><published>2025-10-07T19:44:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45507936</id><title>Gemini 2.5 Computer Use model</title><updated>2025-10-08T00:44:52.563341+00:00</updated><content>&lt;doc fingerprint="b97269db1c538405"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing the Gemini 2.5 Computer Use model&lt;/head&gt;
    &lt;p&gt;Earlier this year, we mentioned that we're bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the Gemini 2.5 Computer Use model, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;p&gt;While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the full list of supported UI actions or specify additional custom functions to include.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use Model flow&lt;/p&gt;
    &lt;p&gt;The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.&lt;/p&gt;
    &lt;p&gt;After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.&lt;/p&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.&lt;/p&gt;
    &lt;p&gt;Check out a few demos below to see the model in action (shown here at 3X speed).&lt;/p&gt;
    &lt;p&gt;Prompt: “From https://tinyurl.com/pet-care-signup, get all details for any pet with a California residency and add them as a guest in my spa CRM at https://pet-luxe-spa.web.app/. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”&lt;/p&gt;
    &lt;p&gt;Prompt: “My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to sticky-note-jam.web.app and ensure notes are clearly in the right sections. Drag them there if not.”&lt;/p&gt;
    &lt;head rend="h2"&gt;How it performs&lt;/head&gt;
    &lt;p&gt;The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the Gemini 2.5 Computer Use evaluation info and in Browserbase’s blog post. Unless otherwise indicated, scores shown are for computer use tools exposed via API.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks&lt;/p&gt;
    &lt;p&gt;The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.&lt;/p&gt;
    &lt;p&gt;Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency&lt;/p&gt;
    &lt;head rend="h2"&gt;How we approached safety&lt;/head&gt;
    &lt;p&gt;We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.&lt;/p&gt;
    &lt;p&gt;We have trained safety features directly into the model to address these three key risks (described in the Gemini 2.5 Computer Use System Card).&lt;/p&gt;
    &lt;p&gt;Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system's integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Per-step safety service: An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.&lt;/item&gt;
      &lt;item&gt;System instructions: Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in documentation).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Additional recommendations for developers on safety measures and best practices can be found in our documentation. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.&lt;/p&gt;
    &lt;head rend="h2"&gt;How early testers have used it&lt;/head&gt;
    &lt;p&gt;Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering Project Mariner, the Firebase Testing Agent, and some agentic capabilities in AI Mode in Search.&lt;/p&gt;
    &lt;p&gt;Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:&lt;/p&gt;
    &lt;head rend="h2"&gt;How to get started&lt;/head&gt;
    &lt;p&gt;Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try it now: In a demo environment hosted by Browserbase.&lt;/item&gt;
      &lt;item&gt;Start building: Dive into our reference and documentation (see Vertex AI docs for enterprise use) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.&lt;/item&gt;
      &lt;item&gt;Join the community: We’re excited to see what you build. Share feedback and help guide our roadmap in our Developer Forum.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.google/technology/google-deepmind/gemini-computer-use-model/"/><published>2025-10-07T19:49:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45508811</id><title>Metriport (YC S22) is hiring a founding recruiter</title><updated>2025-10-08T00:44:52.023607+00:00</updated><content>&lt;doc fingerprint="b75c73b3cc765a6c"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Metriport helps healthcare organizations access, analyze, and exchange patient data in real-time. Our open-source data intelligence platform integrates with all major healthcare IT systems in the US, and taps into comprehensive medical data for 300M+ individuals. Concretely, check out the following resources to learn more about what we actually do:&lt;/p&gt;
      &lt;p&gt;If you want to do work that matters and has a direct impact on people’s lives, you should consider joining us - there’s a good chance that this will be some of the most fulfilling, interesting, and impactful work you do in your career.&lt;lb/&gt; We are looking for our first in-house recruiter to lead efforts of scaling our team with formidable talent, end-to-end. You will be recruiting across all company functions - from engineering, to customer success, to design, and so on.&lt;/p&gt;
      &lt;head rend="h2"&gt;About us&lt;/head&gt;
      &lt;p&gt;The following points are an assortment of the most relevant bits that will give you the gist of where we’re at, why we’ll win, and our company culture:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Series A (unannounced), found PMF, multi-million ARR, 90+ customers (including Strive Health, Circle Medical, and Brightside Health), funded by top VCs and angels, have years of runway - and we’re just getting started.&lt;/item&gt;
        &lt;item&gt;We’re a tight-knit, high performing, and passionate team - we work with a consistent intensity and have become a leader in our industry with a fraction of the resources of our competitors. &lt;list rend="ul"&gt;&lt;item&gt;Consistency means we push as hard as humanly possible, while keeping our health and personal lives in check.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Meaningful work is what gets us out of bed, and we just wouldn’t be satisfied by building yet another CRM company.&lt;/item&gt;
        &lt;item&gt;By pedigree, we’re a group of underdogs - we don’t hire based on prestige, but on demonstrated competence and perceived potential.&lt;/item&gt;
        &lt;item&gt;We operate as a relatively flat structure with little red tape, forced structure, or bureaucracy. We just opt to get shit done and foster a collaborative environment with high autonomy - our GitHub commit history and product velocity is a testament to this.&lt;/item&gt;
        &lt;item&gt;The founders set the pace by working 6 days a week in our SF office, but everyone is given full freedom to craft a schedule that’s best for both the team and themselves - team output is measured, “butts in seats” are not.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;About you&lt;/head&gt;
      &lt;p&gt;In a nutshell, we're looking for a founding “full-stack recruiter” with the following specific qualities:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You want to work at a fast-paced startup.&lt;/item&gt;
        &lt;item&gt;You’re excited by working in the intersection of healthcare, data, and AI.&lt;/item&gt;
        &lt;item&gt;You have a strong sense of ownership over your work, and have demonstrated ability to lead others.&lt;/item&gt;
        &lt;item&gt;You’re entrepreneurial minded, and you don’t need a defined playbook to be successful in your role - you’re able to create and own your own systems.&lt;/item&gt;
        &lt;item&gt;When someone scopes out an assignment with a target ETA of 3 weeks, you ask yourself "why can't it be done in 3 days?".&lt;/item&gt;
        &lt;item&gt;You feel that you have a good “taste” for startup talent, developed through your prior recruiting experience.&lt;/item&gt;
        &lt;item&gt;Bonus: you have an engineering background that allows you to vet technical talent thoroughly.&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;What you'll be doing&lt;/head&gt;
      &lt;p&gt;From day 1, you’ll be ramped up quickly to expert-level domain knowledge in the healthcare data IT space to help you understand the context of what we’re working towards, all of the projects that our team is currently working on, and what we’ll be working on in the future.&lt;lb/&gt; Every day, you'll be working towards moving the needle on all things related to ensuring we are working with the best talent possible, while reaching aggressive growth goals. Generally, this will look like:&lt;/p&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Making the world a better place (but actually).&lt;/item&gt;
        &lt;item&gt;Talent Brand Management: create and manage our public hiring presence - our job site, listings, social media posts, etc.&lt;/item&gt;
        &lt;item&gt;Sourcing: using traditional outreach tools, as well as your own creative approaches, get the best talent possible in our recruiting funnel.&lt;/item&gt;
        &lt;item&gt;Interviewing: schedule, run, and organize multi-stage interviews, including coordinating any travel necessary.&lt;/item&gt;
        &lt;item&gt;Closing: writing offer letters and ensuring they close.&lt;/item&gt;
        &lt;item&gt;Onboarding: help with onboarding new employees when they start and making sure they have everything they need to hit the round running.&lt;/item&gt;
        &lt;item&gt;Payroll/HR: as needed, perform a variety of payroll and HR related tasks like reimbursements, purchase requests, device provisioning, etc.&lt;/item&gt;
        &lt;item&gt;Attending a daily 30 minute remote stand-up at 7:30am PST Mon-Fri (our only regular mandatory meeting).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Requirements&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;You have enough technical knowledge to be able to understand our product, what our team is working towards, and where we fit into the healthcare landscape.&lt;/item&gt;
        &lt;item&gt;You’ve worked with, or can quickly learn how to operate, tools like: Surfe, Gem, LinkedIn Recruiter, Pave, Levels, Notion, Slack, Zapier, Excel, etc.&lt;/item&gt;
        &lt;item&gt;You have excellent communication skills, and ideally some prior consulting experience.&lt;/item&gt;
        &lt;item&gt;You’re located in San Francisco or the Bay Area (or willing to relocate).&lt;/item&gt;
      &lt;/list&gt;
      &lt;head rend="h2"&gt;Benefits&lt;/head&gt;
      &lt;list rend="ul"&gt;
        &lt;item&gt;Competitive equity + compensation package 🚀&lt;/item&gt;
        &lt;item&gt;Top tier full family health insurance, dental, and vision coverage 🦷&lt;/item&gt;
        &lt;item&gt;401(k) retirement plan + matching 💰&lt;/item&gt;
        &lt;item&gt;Flexible work from home or in-office 🏢 &lt;list rend="ul"&gt;&lt;item&gt;Healthy lunches are complimentary when working in-office (and breakfast + dinners as needed) 🍏&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
        &lt;item&gt;Quarterly company off-sites with the team ⛷️&lt;/item&gt;
        &lt;item&gt;MacBook provided by us 💻&lt;/item&gt;
        &lt;item&gt;Unlimited PTO (we work hard, but trust you to take time you need to be at your best) 🧘♂️&lt;/item&gt;
      &lt;/list&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/metriport/jobs/uq6CuhA-founding-recruiter"/><published>2025-10-07T21:00:51+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45509243</id><title>Become unbannable from your email</title><updated>2025-10-08T00:44:51.930939+00:00</updated><content/><link href="https://karboosx.net/post/PJOveGVa/become-unbannable-from-your-emailgmail"/><published>2025-10-07T21:39:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45510582</id><title>Study of 1M-year-old skull points to earlier origins of modern humans</title><updated>2025-10-08T00:44:51.746064+00:00</updated><content>&lt;doc fingerprint="f65511fdb8b11bbe"&gt;
  &lt;main&gt;
    &lt;p&gt;A million-year-old human skull suggests that the origins of modern humans may reach back far deeper in time than previously thought and raises the possibility that Homo sapiens first emerged outside of Africa.&lt;/p&gt;
    &lt;p&gt;Leading scientists reached this conclusion after reanalysis of a skull known as Yunxian 2 discovered in China and previously classified as belonging to a member of the primitive human species Homo erectus.&lt;/p&gt;
    &lt;p&gt;After applying sophisticated reconstruction techniques to the skull, scientists believe that it may instead belong to a group called Homo longi (dragon man), closely linked to the elusive Denisovans who lived alongside our own ancestors.&lt;/p&gt;
    &lt;p&gt;This repositioning would make the fossil the closest on record to the split between modern humans and our closest relatives, the Neanderthals and Denisovans, and would radically revise understanding of the last 1m years of human evolution.&lt;/p&gt;
    &lt;p&gt;Prof Chris Stringer, an anthropologist and research leader in human evolution at the Natural History Museum in London, said: “This changes a lot of thinking because it suggests that by 1m years ago our ancestors had already split into distinct groups, pointing to a much earlier and more complex human evolutionary split than previously believed. It more or less doubles the time of origin of Homo sapiens.”&lt;/p&gt;
    &lt;p&gt;The skull was first unearthed in Hubei province in 1990, badly crushed and difficult to interpret. Based on its age and some broad-brush traits, it was assigned as Homo erectus, a group that is thought to have contained direct ancestors of modern humans.&lt;/p&gt;
    &lt;p&gt;The latest work used advanced CT imaging, high-resolution surface scanning and sophisticated digital techniques to produce a virtual reconstruction of the skull. The skull’s large, squat brain case and jutting lower jaw are reminiscent of Homo erectus. But the overall shape and size of the brain case and teeth appear to place it much closer to Homo longi, a species that scientists have recently argued should incorporate the Denisovans.&lt;/p&gt;
    &lt;p&gt;This would push the split between our own ancestors, Neanderthals and Homo longi back by at least 400,000 years and, according to Springer, raises the possibility that our common ancestor – and potentially the first Homo sapiens – lived in western Asia rather than Africa.&lt;/p&gt;
    &lt;p&gt;“This fossil is the closest we’ve got to the ancestor of all those groups,” Stringer said.&lt;/p&gt;
    &lt;p&gt;A computational analysis of a wider selection of fossils suggests that in the last 800,000 years, large-brained humans evolved along just five major branches: Asian erectus, heidelbergensis, sapiens, Neanderthals and Homo longi (including the Denisovans).&lt;/p&gt;
    &lt;p&gt;“We feel that this study is a landmark step towards resolving the ‘muddle in the middle’ [the confusing array of human fossils from between 1m and 300,000 years ago] that has preoccupied palaeoanthropologists for decades,” Stringer said.&lt;/p&gt;
    &lt;p&gt;The findings run counter to some recent analyses based on genetic comparisons of living humans and ancient DNA, meaning the conclusions are likely to be contentious.&lt;/p&gt;
    &lt;p&gt;Dr Frido Welker, an associate professor in human evolution at the University of Copenhagen, who was not involved in the research, said: “It’s exciting to have a digital reconstruction of this important cranium available. If confirmed by additional fossils and genetic evidence, the divergence dating would be surprising indeed. Alternatively, molecular data from the specimen itself could provide insights confirming or disproving the authors’ morphological hypothesis.”&lt;/p&gt;
    &lt;p&gt;The findings are published in the journal Science.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/science/2025/sep/25/study-of-1m-year-old-skull-points-to-earlier-origins-of-modern-humans"/><published>2025-10-08T00:17:21+00:00</published></entry></feed>