<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-13T21:32:00.890002+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45566441</id><title>MPTCP for Linux</title><updated>2025-10-13T21:32:09.396797+00:00</updated><content>&lt;doc fingerprint="a7b5e91a5cbdcba9"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Multipath TCP or MPTCP is an extension to the standard TCP and is described in RFC 8684. It allows a device to make use of multiple interfaces at once to send and receive TCP packets over a single MPTCP connection. MPTCP can aggregate the bandwidth of multiple interfaces or prefer the one with the lowest latency. It also allows a fail-over if one path is down, and the traffic is seamlessly reinjected on other paths.&lt;/p&gt;
    &lt;code&gt;graph TD;
    subgraph MPTCP
        direction LR
        C_1(&amp;lt;div style="display: inline-block; min-width: 32px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
        S_1((&amp;lt;div style="display: inline-block; min-width: 55px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))
    end

    subgraph TCP
        direction LR
        C_2(&amp;lt;div style="display: inline-block; min-width: 32px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
        S_2((&amp;lt;div style="display: inline-block; min-width: 55px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))
    end

    C_1 &amp;lt;== "5G" ==&amp;gt; S_1
    C_1 &amp;lt;== "Wi-Fi&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Multiple paths (&amp;lt;i&amp;gt;subflows&amp;lt;/i&amp;gt;)&amp;lt;br /&amp;gt;at the same time" ==&amp;gt; S_1

    C_2 x-. "5G" .-x S_2
    C_2 &amp;lt;== "Wi-Fi&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;One path at a time" ==&amp;gt; S_2

    linkStyle 0 stroke:green;
    linkStyle 1 stroke:green;
    linkStyle 2 stroke:red;
    linkStyle 3 stroke:green;
&lt;/code&gt;
    &lt;head rend="h3"&gt;Use cases&lt;/head&gt;
    &lt;p&gt;Thanks to MPTCP, being able to use multiple paths in parallel or simultaneously brings new use-cases, compared to TCP:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seamless handovers: switching from one path to another while preserving established connections, e.g. Apple is using Multipath TCP on smartphones mainly for this reason since 2013.&lt;/item&gt;
      &lt;item&gt;Best network selection: using the “best” available path depending on some conditions, e.g. latency, losses, cost, bandwidth, etc.&lt;/item&gt;
      &lt;item&gt;Network aggregation: using multiple paths at the same time to have a higher throughput, e.g. to combine fixed and mobile networks to send files faster.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Concepts&lt;/head&gt;
    &lt;p&gt;Technically, when a new socket is created with the &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; protocol (Linux-specific), a subflow (or path) is created. This subflow consists of a regular TCP connection that is used to transmit data through one interface. Additional subflows can be negotiated later between the hosts. For the remote host to be able to detect the use of MPTCP, a new field is added to the TCP option field of the underlying TCP subflow. This field contains, amongst other things, a &lt;code&gt;MP_CAPABLE&lt;/code&gt; option that tells the other host to use MPTCP if it is supported. If the remote host or any middlebox in between does not support it, the returned &lt;code&gt;SYN+ACK&lt;/code&gt; packet will not contain MPTCP options in the TCP option field. In that case, the connection will be “downgraded” to plain TCP, and it will continue with a single path.&lt;/p&gt;
    &lt;p&gt;This behavior is made possible by two internal components: the path manager, and the packet scheduler.&lt;/p&gt;
    &lt;head rend="h3"&gt;Path Manager&lt;/head&gt;
    &lt;p&gt;The Path Manager is in charge of subflows, from creation to deletion, and also address announcements. Typically, it is the client side that initiates subflows, and the server side that announces additional addresses via the &lt;code&gt;ADD_ADDR&lt;/code&gt; and &lt;code&gt;REMOVE_ADDR&lt;/code&gt; options.&lt;/p&gt;
    &lt;code&gt;graph LR;
    C_1(&amp;lt;div style="display: inline-block; min-width: 35px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-mobile&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)
    S_1((&amp;lt;div style="display: inline-block; min-width: 60px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-cloud&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;))

    C_1 -. "Potential subflow" -.- S_1
    C_1 &amp;lt;== "Initial subflow" ==&amp;gt; S_1
    C_1 ~~~|"Subflows creation"| C_1
    S_1 ~~~|"Addresses announcement"| S_1

    linkStyle 0 stroke:orange;
    linkStyle 1 stroke:green;
&lt;/code&gt;
    &lt;p&gt;As of Linux v5.19, there are two path managers, controlled by the &lt;code&gt;net.mptcp.pm_type&lt;/code&gt; sysctl knob: the in-kernel one (type &lt;code&gt;0&lt;/code&gt;) where the same rules are applied for all the connections (see: &lt;code&gt;ip mptcp&lt;/code&gt;) ; and the userspace one (type &lt;code&gt;1&lt;/code&gt;), controlled by a userspace daemon (i.e. &lt;code&gt;mptcpd&lt;/code&gt;) where different rules can be applied for each connection.&lt;/p&gt;
    &lt;head rend="h3"&gt;Packet Scheduler&lt;/head&gt;
    &lt;p&gt;The Packet Scheduler is in charge of selecting which available subflow(s) to use to send the next data packet. It can decide to maximize the use of the available bandwidth, only to pick the path with the lower latency, or any other policy depending on the configuration.&lt;/p&gt;
    &lt;code&gt;graph LR;
    A_2(&amp;lt;div style="display: inline-block; min-width: 40px"&amp;gt;&amp;lt;font size="7"&amp;gt;fa:fa-user&amp;lt;/font&amp;gt;&amp;lt;/div&amp;gt;)

    PS{Packet&amp;lt;br /&amp;gt;Scheduler}

    I_21(subflow 1)
    I_22(subflow 2)

    A_2 == "&amp;lt;div style='display: inline-block; min-width: 50px'&amp;gt;fa:fa-box fa:fa-box fa:fa-box&amp;lt;/div&amp;gt;" ==&amp;gt; PS
    PS -- "&amp;lt;div style='display: inline-block; min-width: 32px'&amp;gt;fa:fa-box fa:fa-box&amp;lt;/div&amp;gt;" --&amp;gt; I_21
    PS -- "&amp;lt;div style='display: inline-block; min-width: 14px'&amp;gt;fa:fa-box&amp;lt;/div&amp;gt;" --&amp;gt; I_22
    PS ~~~|"Packets distribution between subflows"| PS
&lt;/code&gt;
    &lt;p&gt;As of Linux v6.8, there is only one packet scheduler, controlled by sysctl knobs in &lt;code&gt;net.mptcp&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;Features&lt;/head&gt;
    &lt;p&gt;As of Linux v6.10, major features of MPTCP include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Support of the &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;protocol in&lt;code&gt;socket()&lt;/code&gt;system calls.&lt;/item&gt;
      &lt;item&gt;Fallback from MPTCP to TCP if the peer or a middlebox do not support MPTCP.&lt;/item&gt;
      &lt;item&gt;Path management using either an in-kernel or userspace path manager.&lt;/item&gt;
      &lt;item&gt;Socket options that are commonly used with TCP sockets.&lt;/item&gt;
      &lt;item&gt;Debug features including MIB counters, diag support (used by the &lt;code&gt;ss&lt;/code&gt;command), and tracepoints.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;See the ChangeLog for more details.&lt;/p&gt;
    &lt;head rend="h2"&gt;Communication&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mailing List: mptcp@lists.linux.dev (plain text only): &lt;list rend="ul"&gt;&lt;item&gt;Archives&lt;/item&gt;&lt;item&gt;Info&lt;/item&gt;&lt;item&gt;Subscribe by sending an empty email in plain text to mptcp+subscribe@lists.linux.dev, and by replying to the challenge email.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;IRC: #mptcp on libera.chat&lt;/item&gt;
      &lt;item&gt;Online Meetings&lt;/item&gt;
      &lt;item&gt;Blog&lt;/item&gt;
      &lt;item&gt;Fediverse&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Projects&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Maintained by MPTCP community members&lt;/item&gt;
      &lt;item&gt;Projects with MPTCP-related enhancements &lt;list rend="ul"&gt;&lt;item&gt;iproute2 (for the &lt;code&gt;ip mptcp&lt;/code&gt;command)&lt;/item&gt;&lt;item&gt;Network Manager: MPTCP features are included starting with v1.40.&lt;/item&gt;&lt;item&gt;Multipath TCP applications: A project to coordinate MPTCP updates for popular TCP applications.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;iproute2 (for the &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.mptcp.dev/"/><published>2025-10-13T09:25:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566638</id><title>American solar farms</title><updated>2025-10-13T21:32:08.728862+00:00</updated><content>&lt;doc fingerprint="ab95e1f33b2412f0"&gt;
  &lt;main&gt;
    &lt;p&gt;Last week, Jake Stid, a postdoctoral research associate at Michigan State University, announced Ground-Mounted Solar Energy in the United States (GM-SEUS). This is a 15K-array, 2.9M-panel dataset of utility and commercial-grade solar farms across the lower 48 states plus the District of Columbia. This dataset was constructed by a team of researchers including alumni from NOAA, NASA and the USGS.&lt;/p&gt;
    &lt;p&gt;Below is a heatmap of the assets catalogued in this dataset.&lt;/p&gt;
    &lt;p&gt;GM-SEUS is broken up into two datasets, one for arrays and another panels. Below you can see a solar farm with the array outlined in red and the panels covered purple.&lt;/p&gt;
    &lt;p&gt;In this post, I'll explore GM-SEUS's Solar Farm dataset.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Workstation&lt;/head&gt;
    &lt;p&gt;I'm using a 5.7 GHz AMD Ryzen 9 9950X CPU. It has 16 cores and 32 threads and 1.2 MB of L1, 16 MB of L2 and 64 MB of L3 cache. It has a liquid cooler attached and is housed in a spacious, full-sized Cooler Master HAF 700 computer case.&lt;/p&gt;
    &lt;p&gt;The system has 96 GB of DDR5 RAM clocked at 4,800 MT/s and a 5th-generation, Crucial T700 4 TB NVMe M.2 SSD which can read at speeds up to 12,400 MB/s. There is a heatsink on the SSD to help keep its temperature down. This is my system's C drive.&lt;/p&gt;
    &lt;p&gt;The system is powered by a 1,200-watt, fully modular Corsair Power Supply and is sat on an ASRock X870E Nova 90 Motherboard.&lt;/p&gt;
    &lt;p&gt;I'm running Ubuntu 24 LTS via Microsoft's Ubuntu for Windows on Windows 11 Pro. In case you're wondering why I don't run a Linux-based desktop as my primary work environment, I'm still using an Nvidia GTX 1080 GPU which has better driver support on Windows and ArcGIS Pro only supports Windows natively.&lt;/p&gt;
    &lt;head rend="h2"&gt;Installing Prerequisites&lt;/head&gt;
    &lt;p&gt;I'll use GDAL 3.9.3 and a few other tools to help analyse the data in this post.&lt;/p&gt;
    &lt;code&gt;$ sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable
$ sudo apt update
$ sudo apt install \
    gdal-bin \
    jq
&lt;/code&gt;
    &lt;p&gt;I'll use DuckDB v1.4.1, along with its H3, JSON, Lindel, Parquet and Spatial extensions, in this post.&lt;/p&gt;
    &lt;code&gt;$ cd ~
$ wget -c https://github.com/duckdb/duckdb/releases/download/v1.4.1/duckdb_cli-linux-amd64.zip
$ unzip -j duckdb_cli-linux-amd64.zip
$ chmod +x duckdb
$ ~/duckdb
&lt;/code&gt;
    &lt;code&gt;INSTALL h3 FROM community;
INSTALL lindel FROM community;
INSTALL json;
INSTALL parquet;
INSTALL spatial;
&lt;/code&gt;
    &lt;p&gt;I'll set up DuckDB to load every installed extension each time it launches.&lt;/p&gt;
    &lt;code&gt;$ vi ~/.duckdbrc
&lt;/code&gt;
    &lt;code&gt;.timer on
.width 180
LOAD h3;
LOAD lindel;
LOAD json;
LOAD parquet;
LOAD spatial;
&lt;/code&gt;
    &lt;p&gt;The maps in this post were mostly rendered with QGIS version 3.44. QGIS is a desktop application that runs on Windows, macOS and Linux. The application has grown in popularity in recent years and has ~15M application launches from users all around the world each month.&lt;/p&gt;
    &lt;p&gt;I used QGIS' Tile+ plugin to add basemaps from Esri to the maps in this post.&lt;/p&gt;
    &lt;head rend="h2"&gt;Analysis-Ready Data&lt;/head&gt;
    &lt;p&gt;I'll download a dataset containing the US CENSUS State codes. This will let me map the state ID in the arrays dataset to their state name.&lt;/p&gt;
    &lt;code&gt;$ wget https://gist.github.com/a8dx/2340f9527af64f8ef8439366de981168/raw/81d876daea10eab5c2675811c39bcd18a79a9212/US_State_Bounding_Boxes.csv
&lt;/code&gt;
    &lt;p&gt;I'll download the ZIP file of deliverables for GM-SEUS.&lt;/p&gt;
    &lt;code&gt;$ wget -O GMSEUS_v1_0.zip \
    'https://zenodo.org/records/14827819/files/GMSEUS_v1_0.zip?download=1'
$ unzip GMSEUS_v1_0.zip
&lt;/code&gt;
    &lt;p&gt;I'll extract the projection used. This proj4 string will be used to below to re-project the data into EPSG:4326.&lt;/p&gt;
    &lt;code&gt;$ gdalsrsinfo \
    -o proj4 \
    GMSEUS_v1_0/GPKG/GMSEUS_Arrays_Final.gpkg
&lt;/code&gt;
    &lt;code&gt;+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs
&lt;/code&gt;
    &lt;p&gt;I'll use DuckDB to clean up the values and produce both a geometry field and a bounding box for each feature in this dataset. This will make working with this dataset remotely, such as from AWS S3, much easier.&lt;/p&gt;
    &lt;code&gt;$ ~/duckdb
&lt;/code&gt;
    &lt;p&gt;This following produced a ZStandard-compressed, spatially-sorted Parquet file of the arrays dataset. I dropped the Z dimension as it was unused. The unknown values have been turned into NULLs. The original GPKG file was 108 MB and the resulting Parquet file is 37 MB.&lt;/p&gt;
    &lt;code&gt;COPY (
   WITH a AS (
       SELECT * EXCLUDE(geom),
              ST_FORCE2D(
                ST_FLIPCOORDINATES(
                  ST_TRANSFORM(
                      geom,
                      '+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs',
                      'EPSG:4326'))) geometry
       FROM   ST_READ('GMSEUS_v1_0/GPKG/GMSEUS_Arrays_Final.gpkg')
   )
   SELECT   a.* EXCLUDE (geometry,
                         tilt,
                         tiltEst,
                         instYr,
                         instYrLT,
                         effInit,
                         avgAzimuth,
                         avgLength,
                         avgSpace,
                         avgWidth),
            {'xmin': ST_XMIN(ST_EXTENT(geometry)),
             'ymin': ST_YMIN(ST_EXTENT(geometry)),
             'xmax': ST_XMAX(ST_EXTENT(geometry)),
             'ymax': ST_YMAX(ST_EXTENT(geometry))} AS bbox,
             ST_ASWKB(geometry) geometry,
             CASE WHEN instYr::INT     = -9999 THEN NULL ELSE instYr::INT   END AS instYr,
             CASE WHEN instYrLT::INT   = -9999 THEN NULL ELSE instYrLT::INT END AS instYrLT,
             CASE WHEN numRow::INT     = -9999 THEN NULL ELSE numRow::INT   END AS numRow,
             CASE WHEN tilt::INT       = -9999 THEN NULL ELSE tilt::INT     END AS tilt,
             CASE WHEN tiltEst::INT    = -9999 THEN NULL ELSE tiltEst::INT  END AS tiltEst,
             CASE WHEN effInit::INT    = -9999 THEN NULL ELSE effInit       END AS effInit,
             CASE WHEN avgAzimuth::INT = -9999 THEN NULL ELSE avgAzimuth    END AS avgAzimuth,
             CASE WHEN avgLength::INT  = -9999 THEN NULL ELSE avgLength     END AS avgLength,
             CASE WHEN avgSpace::INT   = -9999 THEN NULL ELSE avgSpace      END AS avgSpace,
             CASE WHEN avgWidth::INT   = -9999 THEN NULL ELSE avgWidth      END AS avgWidth,
             b.NAME state_name
   FROM     a
   JOIN     'US_State_Bounding_Boxes.csv' b ON a.STATEFP = b.STATEFP
   ORDER BY HILBERT_ENCODE([ST_Y(ST_CENTROID(geometry)),
                            ST_X(ST_CENTROID(geometry))]::double[2])
) TO 'arrays.parquet' (
   FORMAT            'PARQUET',
   CODEC             'ZSTD',
   COMPRESSION_LEVEL 22,
   ROW_GROUP_SIZE    15000);
&lt;/code&gt;
    &lt;p&gt;The original GPKG file for the panels dataset was 1.1 GB and the resulting Parquet file is 334 MB.&lt;/p&gt;
    &lt;code&gt;COPY (
   WITH a AS (
       SELECT * EXCLUDE(geom),
              ST_FORCE2D(
                ST_FLIPCOORDINATES(
                  ST_TRANSFORM(
                      geom,
                      '+proj=aea +lat_0=37.5 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs',
                      'EPSG:4326'))) geometry
       FROM   ST_READ('GMSEUS_v1_0/GPKG/GMSEUS_Panels_Final.gpkg')
   )
   SELECT   * EXCLUDE (geometry,
                       rowSpace),
            {'xmin': ST_XMIN(ST_EXTENT(geometry)),
             'ymin': ST_YMIN(ST_EXTENT(geometry)),
             'xmax': ST_XMAX(ST_EXTENT(geometry)),
             'ymax': ST_YMAX(ST_EXTENT(geometry))} AS bbox,
             ST_ASWKB(geometry) geometry,
             CASE WHEN rowSpace::INT = -9999 THEN NULL ELSE rowSpace END AS rowSpace
   FROM     a
   ORDER BY HILBERT_ENCODE([ST_Y(ST_CENTROID(geometry)),
                            ST_X(ST_CENTROID(geometry))]::double[2])
) TO 'panels.parquet' (
   FORMAT            'PARQUET',
   CODEC             'ZSTD',
   COMPRESSION_LEVEL 22,
   ROW_GROUP_SIZE    15000);
&lt;/code&gt;
    &lt;head rend="h2"&gt;Solar Arrays&lt;/head&gt;
    &lt;p&gt;The arrays Parquet file has 15,017 rows. Below is an example record.&lt;/p&gt;
    &lt;code&gt;$ echo "SELECT * EXCLUDE(bbox,
                         geometry),
               bbox::JSON bbox
        FROM   'arrays.parquet'
        LIMIT  1" \
    | ~/duckdb -json \
    | jq -S .
&lt;/code&gt;
    &lt;code&gt;[
  {
    "COUNTYFP": "019",
    "GCR1": 0.6996,
    "GCR2": 0.614,
    "STATEFP": "45",
    "Source": "OSM",
    "arrayID": 2807,
    "avgAzimuth": 170.63,
    "avgLength": 47.76166666666666,
    "avgSpace": 3.003333333333333,
    "avgWidth": 4.776666666666666,
    "bbox": {
      "xmax": -79.97229830431786,
      "xmin": -79.97325770533094,
      "ymax": 32.87833627192598,
      "ymin": 32.87808294640646
    },
    "capMW": 0.246,
    "capMWest": 0.246,
    "effInit": 0.197963503102977,
    "instYr": 2021,
    "instYrLT": 2021,
    "latitude": 32.87818725544087,
    "longitude": -79.97276617375104,
    "modType": "c-si",
    "mount": "fixed_axis",
    "nativeID": "9324",
    "newBound": 1,
    "numRow": 6.0,
    "numRow_1": 6,
    "state_name": "South Carolina",
    "tilt": 30,
    "tiltEst": 30,
    "totArea": 1779.0,
    "totRowArea": 1244.93,
    "version": "v1.0"
  }
]
&lt;/code&gt;
    &lt;p&gt;Below are the field names, data types, percentages of NULLs per column, number of unique values and minimum and maximum values for each column.&lt;/p&gt;
    &lt;code&gt;$ ~/duckdb
&lt;/code&gt;
    &lt;code&gt;SELECT   column_name,
         column_type,
         null_percentage,
         approx_unique,
         min,
         max
FROM     (SUMMARIZE
          FROM READ_PARQUET('arrays.parquet'))
WHERE    column_name != 'geometry'
AND      column_name != 'bbox'
ORDER BY 1;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬─────────────┬─────────────────┬───────────────┬─────────────────────┬────────────────────┐
│ column_name │ column_type │ null_percentage │ approx_unique │         min         │        max         │
│   varchar   │   varchar   │  decimal(9,2)   │     int64     │       varchar       │      varchar       │
├─────────────┼─────────────┼─────────────────┼───────────────┼─────────────────────┼────────────────────┤
│ COUNTYFP    │ VARCHAR     │            0.00 │           235 │ 001                 │ 810                │
│ GCR1        │ DOUBLE      │            0.00 │          5057 │ 0.1047              │ 1.0                │
│ GCR2        │ DOUBLE      │            0.00 │          5013 │ 0.1245              │ 0.988              │
│ STATEFP     │ VARCHAR     │            0.00 │            49 │ 01                  │ 56                 │
│ Source      │ VARCHAR     │            0.00 │             6 │ CCVPV               │ USPVDB             │
│ arrayID     │ BIGINT      │            0.00 │         13155 │ 1                   │ 15017              │
│ avgAzimuth  │ DOUBLE      │           32.84 │          4295 │ 25.0                │ 269.27             │
│ avgLength   │ DOUBLE      │           39.79 │          8358 │ 4.02                │ 449.5004           │
│ avgSpace    │ DOUBLE      │           39.79 │          8623 │ 0.024               │ 20.0               │
│ avgWidth    │ DOUBLE      │           39.79 │          9185 │ 0.67625             │ 29.80222222222222  │
│ capMW       │ DOUBLE      │            0.00 │          5280 │ 0.001250225184651   │ 1051.703           │
│ capMWest    │ DOUBLE      │            0.00 │          7863 │ 0.004               │ 3170.1             │
│ effInit     │ DOUBLE      │            0.49 │            39 │ 0.132210289727273   │ 0.205484167047619  │
│ instYr      │ INTEGER     │            0.00 │            24 │ 1985                │ 2024               │
│ instYrLT    │ INTEGER     │            0.24 │            17 │ 2009                │ 2023               │
│ latitude    │ DOUBLE      │            0.00 │         16986 │ 25.53796582594631   │ 48.99547137225406  │
│ longitude   │ DOUBLE      │            0.00 │         15656 │ -124.10440474967092 │ -67.15066374183608 │
│ modType     │ VARCHAR     │            0.00 │             3 │ c-si                │ thin-film          │
│ mount       │ VARCHAR     │            0.00 │            10 │ dual_axis           │ unknown            │
│ nativeID    │ VARCHAR     │            0.00 │         15141 │ 1                   │ York Solar         │
│ newBound    │ BIGINT      │            0.00 │             2 │ 0                   │ 1                  │
│ numRow      │ DOUBLE      │            0.00 │          1461 │ 0.0                 │ 56782.0            │
│ numRow_1    │ INTEGER     │            0.00 │          1117 │ 0                   │ 56782              │
│ state_name  │ VARCHAR     │            0.00 │            57 │ Alabama             │ Wyoming            │
│ tilt        │ INTEGER     │           55.46 │            47 │ 0                   │ 83                 │
│ tiltEst     │ INTEGER     │           55.46 │            30 │ 10                  │ 43                 │
│ totArea     │ DOUBLE      │            0.00 │         13182 │ 54.0                │ 13735113.0         │
│ totRowArea  │ DOUBLE      │            0.00 │         15396 │ 44.97               │ 7223924.662        │
│ version     │ VARCHAR     │            0.00 │             1 │ v1.0                │ v1.0               │
├─────────────┴─────────────┴─────────────────┴───────────────┴─────────────────────┴────────────────────┤
│ 29 rows                                                                                      6 columns │
└────────────────────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;I'll generate a heatmap of the asset locations in this dataset.&lt;/p&gt;
    &lt;code&gt;CREATE OR REPLACE TABLE h3_4_stats AS
    SELECT   H3_LATLNG_TO_CELL(
                bbox.ymin,
                bbox.xmin, 4) AS h3_4,
             COUNT(*) num_buildings
    FROM     READ_PARQUET('arrays.parquet')
    WHERE    bbox.xmin BETWEEN -178.5 AND 178.5
    GROUP BY 1;

COPY (
    SELECT ST_ASWKB(H3_CELL_TO_BOUNDARY_WKT(h3_4)::geometry) geometry,
           num_buildings
    FROM   h3_4_stats
) TO 'h3_4_stats.gpkg'
  WITH (FORMAT GDAL,
        DRIVER 'GPKG',
        LAYER_CREATION_OPTIONS 'WRITE_BBOX=YES');
&lt;/code&gt;
    &lt;p&gt;Normally I would produce a Parquet file as even with 10s of thousands of records it'll generate in seconds versus a minute or so with GPKG. But ArcGIS Pro 3.5 didn't want to open the Parquet file I generated. QGIS 3.44 was fine with it but I wanted to use Esri's Nova basemap for the rendering below.&lt;/p&gt;
    &lt;p&gt;ArcGIS Pro 3.6 should be released sometime in the next few weeks so I'll re-examine this issue when it's out.&lt;/p&gt;
    &lt;p&gt;Below is the relationship between the sources of data and the installation year.&lt;/p&gt;
    &lt;code&gt;PIVOT    'arrays.parquet'
ON       Source
USING    COUNT(*)
GROUP BY instYr
ORDER BY instYr;
&lt;/code&gt;
    &lt;code&gt;┌────────┬───────┬───────┬───────────────┬───────┬───────┬────────┐
│ instYr │ CCVPV │ CWSD  │ GMSEUSgeorect │  OSM  │  SAM  │ USPVDB │
│ int32  │ int64 │ int64 │     int64     │ int64 │ int64 │ int64  │
├────────┼───────┼───────┼───────────────┼───────┼───────┼────────┤
│   1985 │     0 │     0 │             0 │     0 │     0 │      1 │
│   1986 │     0 │     0 │             0 │     1 │     0 │      0 │
│   2002 │     0 │     0 │             0 │     0 │     0 │      1 │
│   2005 │     0 │     0 │             0 │    26 │     0 │      0 │
│   2006 │     0 │     0 │             0 │     2 │     0 │      1 │
│   2007 │     0 │     0 │             0 │    44 │     0 │      5 │
│   2008 │     0 │     0 │             0 │    58 │     1 │     11 │
│   2009 │     5 │     0 │             0 │    10 │     5 │     19 │
│   2010 │    20 │     0 │             0 │    71 │    20 │     37 │
│   2011 │    24 │     0 │             2 │   193 │    30 │    102 │
│   2012 │    59 │     0 │             2 │   267 │    88 │    157 │
│   2013 │    83 │     0 │             3 │   259 │    82 │    209 │
│   2014 │   102 │     0 │             1 │   335 │   119 │    291 │
│   2015 │   107 │     3 │             0 │   532 │   125 │    320 │
│   2016 │   145 │     1 │             2 │   564 │   170 │    412 │
│   2017 │   135 │     0 │             1 │   661 │   167 │    476 │
│   2018 │    66 │    34 │             4 │   644 │   210 │    414 │
│   2019 │    28 │    39 │             6 │   467 │   178 │    453 │
│   2020 │    10 │    75 │             1 │   437 │   186 │    496 │
│   2021 │     5 │    33 │             6 │   406 │   241 │    446 │
│   2022 │     1 │   173 │             3 │   231 │   354 │    166 │
│   2023 │     0 │     0 │             3 │   176 │   722 │    134 │
│   2024 │     0 │     0 │             0 │    31 │  1571 │      0 │
├────────┴───────┴───────┴───────────────┴───────┴───────┴────────┤
│ 23 rows                                               7 columns │
└─────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Below is the relationship between the mount and mod type.&lt;/p&gt;
    &lt;code&gt;PIVOT    'arrays.parquet'
ON       modType
USING    COUNT(*)
GROUP BY mount
ORDER BY mount;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬───────┬───────┬───────────┐
│    mount    │ c-si  │  csp  │ thin-film │
│   varchar   │ int64 │ int64 │   int64   │
├─────────────┼───────┼───────┼───────────┤
│ dual_axis   │   301 │    18 │         1 │
│ fixed_axis  │  6057 │    32 │       208 │
│ mixed       │     2 │     0 │         0 │
│ mixed_df    │   189 │     7 │         0 │
│ mixed_dfs   │    94 │     0 │         0 │
│ mixed_ds    │    38 │     1 │         0 │
│ mixed_fs    │    60 │     0 │         1 │
│ single_axis │  2876 │    11 │       231 │
│ unknown     │  4885 │     5 │         0 │
└─────────────┴───────┴───────┴───────────┘
&lt;/code&gt;
    &lt;p&gt;Below are the array capacity counts rounded to the neared 100 MW and broken down by source.&lt;/p&gt;
    &lt;code&gt;WITH a AS (
    SELECT   Source,
             ROUND(capMW / 100) * 100 AS capacity,
             COUNT(*) num_recs
    FROM     'arrays.parquet'
    GROUP BY 1, 2
)
PIVOT    a
ON       Source
USING    SUM(num_recs)
GROUP BY capacity
ORDER BY capacity;
&lt;/code&gt;
    &lt;code&gt;┌──────────┬────────┬────────┬───────────────┬────────┬────────┬────────┐
│ capacity │ CCVPV  │  CWSD  │ GMSEUSgeorect │  OSM   │  SAM   │ USPVDB │
│  double  │ int128 │ int128 │    int128     │ int128 │ int128 │ int128 │
├──────────┼────────┼────────┼───────────────┼────────┼────────┼────────┤
│      0.0 │    790 │    356 │            33 │   5295 │   4022 │   3669 │
│    100.0 │   NULL │      2 │          NULL │     67 │    143 │    350 │
│    200.0 │   NULL │   NULL │             1 │     22 │     49 │     73 │
│    300.0 │   NULL │   NULL │          NULL │     17 │     21 │     49 │
│    400.0 │   NULL │   NULL │          NULL │      6 │     13 │      7 │
│    500.0 │   NULL │   NULL │          NULL │      4 │     11 │      2 │
│    600.0 │   NULL │   NULL │          NULL │      2 │      3 │   NULL │
│    700.0 │   NULL │   NULL │          NULL │      1 │      3 │   NULL │
│    800.0 │   NULL │   NULL │          NULL │   NULL │      2 │      1 │
│    900.0 │   NULL │   NULL │          NULL │   NULL │      1 │   NULL │
│   1000.0 │   NULL │   NULL │          NULL │   NULL │      1 │   NULL │
│   1100.0 │   NULL │   NULL │          NULL │      1 │   NULL │   NULL │
├──────────┴────────┴────────┴───────────────┴────────┴────────┴────────┤
│ 12 rows                                                     7 columns │
└───────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;head rend="h2"&gt;Solar Panels&lt;/head&gt;
    &lt;p&gt;The panels Parquet file has 2,917,782 rows. Below is an example record.&lt;/p&gt;
    &lt;code&gt;$ echo "SELECT * EXCLUDE(bbox,
                         geometry),
               bbox::JSON bbox
        FROM   'panels.parquet'
        LIMIT  1" \
    | ~/duckdb -json \
    | jq -S .
&lt;/code&gt;
    &lt;code&gt;[
  {
    "Source": "gmseus",
    "arrayID": 2807.0,
    "bbox": {
      "xmax": -79.97312295800064,
      "xmin": -79.97325770533483,
      "ymax": 32.87833627193374,
      "ymin": 32.87830393275682
    },
    "panelID": 2620732,
    "rowArea": 29.1,
    "rowAzimuth": 174.62,
    "rowLength": 12.77,
    "rowMount": "fixed_axis",
    "rowSpace": 8.42,
    "rowWidth": 3.0,
    "version": "v1.0"
  }
]
&lt;/code&gt;
    &lt;p&gt;Below are the field names, data types, percentages of NULLs per column, number of unique values and minimum and maximum values for each column.&lt;/p&gt;
    &lt;code&gt;$ ~/duckdb
&lt;/code&gt;
    &lt;code&gt;SELECT   column_name,
         column_type,
         null_percentage,
         approx_unique,
         min,
         max
FROM     (SUMMARIZE
          FROM READ_PARQUET('panels.parquet'))
WHERE    column_name != 'geometry'
AND      column_name != 'bbox'
ORDER BY 1;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬─────────────┬─────────────────┬───────────────┬───────────────┬─────────────┐
│ column_name │ column_type │ null_percentage │ approx_unique │      min      │     max     │
│   varchar   │   varchar   │  decimal(9,2)   │     int64     │    varchar    │   varchar   │
├─────────────┼─────────────┼─────────────────┼───────────────┼───────────────┼─────────────┤
│ Source      │ VARCHAR     │            0.00 │             3 │ CCVPV         │ gmseus      │
│ arrayID     │ DOUBLE      │            0.08 │          9451 │ 1.0           │ 15017.0     │
│ panelID     │ BIGINT      │            0.00 │       2703164 │ 1             │ 2917782     │
│ rowArea     │ DOUBLE      │            0.00 │         88974 │ 15.01         │ 1999.76     │
│ rowAzimuth  │ DOUBLE      │            0.00 │         14901 │ 90.0          │ 270.0       │
│ rowLength   │ DOUBLE      │            0.00 │         26759 │ 4.02          │ 530.05      │
│ rowMount    │ VARCHAR     │            0.00 │             3 │ dual_axis     │ single_axis │
│ rowSpace    │ DOUBLE      │            0.17 │         13376 │ 7.4765186e-08 │ 20.0        │
│ rowWidth    │ DOUBLE      │            0.00 │          1863 │ 0.45          │ 102.14      │
│ version     │ VARCHAR     │            0.00 │             1 │ v1.0          │ v1.0        │
├─────────────┴─────────────┴─────────────────┴───────────────┴───────────────┴─────────────┤
│ 10 rows                                                                         6 columns │
└───────────────────────────────────────────────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Below is the relationship between the sources of data and the row mount.&lt;/p&gt;
    &lt;code&gt;PIVOT    'panels.parquet'
ON       Source
USING    COUNT(*)
GROUP BY rowMount
ORDER BY rowMount;
&lt;/code&gt;
    &lt;code&gt;┌─────────────┬────────┬────────┬─────────┐
│  rowMount   │ CCVPV  │  OSM   │ gmseus  │
│   varchar   │ int64  │ int64  │  int64  │
├─────────────┼────────┼────────┼─────────┤
│ dual_axis   │     44 │   5975 │   80225 │
│ fixed_axis  │  13344 │ 118639 │  163512 │
│ single_axis │ 189699 │ 743371 │ 1602973 │
└─────────────┴────────┴────────┴─────────┘
&lt;/code&gt;
    &lt;p&gt;Of the 15,017 arrays in this dataset, only 5,358 have any panels in them.&lt;/p&gt;
    &lt;code&gt;.maxrows 20

SELECT   a.arrayID,
         COUNT(DISTINCT b.panelID)
FROM     READ_PARQUET('arrays.parquet') a
JOIN     READ_PARQUET('panels.parquet') b
ON       ST_COVERS(a.geometry, b.geometry)
GROUP BY a.arrayID
ORDER BY 2 DESC;
&lt;/code&gt;
    &lt;code&gt;┌─────────┬───────────────────────────┐
│ arrayID │ count(DISTINCT b.panelID) │
│  int64  │           int64           │
├─────────┼───────────────────────────┤
│   11958 │                     56762 │
│   14225 │                     51140 │
│   12162 │                     43741 │
│   12433 │                     37304 │
│   14461 │                     31898 │
│   13229 │                     30093 │
│    6589 │                     27080 │
│   13329 │                     25120 │
│   12597 │                     24054 │
│   12224 │                     23449 │
│      ·  │                         · │
│      ·  │                         · │
│      ·  │                         · │
│    1792 │                         1 │
│    2286 │                         1 │
│     863 │                         1 │
│    1816 │                         1 │
│    8997 │                         1 │
│   12358 │                         1 │
│    6564 │                         1 │
│    3845 │                         1 │
│    6574 │                         1 │
│     991 │                         1 │
├─────────┴───────────────────────────┤
│ 5358 rows (20 shown)      2 columns │
└─────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Below is a solar farm in Nevada where some arrays have panels and others do not.&lt;/p&gt;
    &lt;p&gt;I was interested in seeing the solar farm with 56K panels. Below are its coordinates.&lt;/p&gt;
    &lt;code&gt;SELECT ST_CENTROID(geometry)
FROM   'arrays.parquet'
WHERE  arrayID = 11958;
&lt;/code&gt;
    &lt;code&gt;┌────────────────────────────────────────────────┐
│             st_centroid(geometry)              │
│                    geometry                    │
├────────────────────────────────────────────────┤
│ POINT (-115.34248808114013 35.611919498003175) │
└────────────────────────────────────────────────┘
&lt;/code&gt;
    &lt;p&gt;Even this has arrays without marked panels.&lt;/p&gt;
    &lt;p&gt;I'm looking forward to v2 of this dataset with better panel detection. It'll be great to get a good approximation of how many are deployed in the US.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://tech.marksblogg.com/american-solar-farms.html"/><published>2025-10-13T10:02:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566644</id><title>Dutch government takes control of Chinese-owned chipmaker Nexperia</title><updated>2025-10-13T21:32:08.546225+00:00</updated><content>&lt;doc fingerprint="b514b9655bb771e3"&gt;
  &lt;main&gt;
    &lt;p&gt;The Dutch government has taken control of Nexperia, a Chinese-owned semiconductor maker based in the Netherlands, in an extraordinary move to ensure a sufficient supply of its chips remains available in Europe amid rising global trade tensions.&lt;/p&gt;
    &lt;p&gt;Nexperia, a subsidiary of China's Wingtech Technology, specializes in the high-volume production of chips used in automotive, consumer electronics and other industries, making it vital for maintaining Europe's technological supply chains.&lt;/p&gt;
    &lt;p&gt;On Sunday evening, the Dutch Minister of Economic Affairs revealed that it had invoked the "Goods Availability Act" on the company in September in order "to prevent a situation in which the goods produced by Nexperia (finished and semi-finished products) would become unavailable in an emergency."&lt;/p&gt;
    &lt;p&gt;Following the announcement from The Hague, Wingtech plunged its maximum daily limit of 10% on the Shanghai Stock Exchange.&lt;/p&gt;
    &lt;p&gt;The Goods Availability Act allows The Hague to intervene in private companies to ensure the availability of critical goods in preparation for emergency situations, and its use comes amid escalation in the U.S.-China trade war.&lt;/p&gt;
    &lt;p&gt;The government statement said the "highly exceptional" move had been made after the ministry had observed "recent and acute signals of serious governance shortcomings and actions" within Nexperia.&lt;/p&gt;
    &lt;p&gt;"These signals posed a threat to the continuity and safeguarding on Dutch and European soil of crucial technological knowledge and capabilities. Losing these capabilities could pose a risk to Dutch and European economic security," it said, identifying the automotive industry as particularly vulnerable.&lt;/p&gt;
    &lt;head rend="h3"&gt;Governance changes&lt;/head&gt;
    &lt;p&gt;In a corporate filing dated Oct.13, lodged with the Shanghai Stock Exchange, Wingtech confirmed Nexperia was under temporary external management and had been asked to suspend changes to the company's assets, business or personnel for up to a year, according to a Google translation.&lt;/p&gt;
    &lt;p&gt;Wingtech Chairman Zhang Xuezheng had been immediately suspended from his roles as executive director of Nexperia Holdings and nonexecutive director of Nexperia after the ministerial order, according to the filing.&lt;/p&gt;
    &lt;p&gt;The filing added that Nexperia's daily operations will continue, with the impact of the measures not yet quantifiable.&lt;/p&gt;
    &lt;p&gt;"The Dutch government's decision to freeze Nexperia's global operations under the pretext of 'national security' constitutes excessive intervention driven by geopolitical bias, rather than a fact-based risk assessment," Wingtech said in a deleted WeChat post, which was archived and translated by Chinese policy blog Pekingnology.&lt;/p&gt;
    &lt;p&gt;It added that since it acquired Nexperia in 2019, Wingtech "has strictly abided by the laws and regulations of all jurisdictions where it operates, maintaining transparent operations and sound governance," and employs "thousands of local staff" through research and development and manufacturing sites in the Netherlands, Germany and Britain.&lt;/p&gt;
    &lt;p&gt;A spokesperson from Nexperia told CNBC that the company had no further comments, but that it "complies with all existing laws and regulations, export controls and sanctions regimes," and remained in regular contact with relevant authorities.&lt;/p&gt;
    &lt;p&gt;The Netherlands' move comes after Beijing tightened its restrictions on the export of rare earth elements and magnets Thursday, which could impact Europe's automotive industry.&lt;/p&gt;
    &lt;p&gt;The move could also further strain trade relations between China and the Netherlands, following years of restrictions on Dutch company ASML's exports of advanced semiconductor manufacturing equipment to China.&lt;/p&gt;
    &lt;p&gt;In 2023, the Netherlands had also investigated Nexperia's proposed acquisition of chip firm startup Nowi, though the deal was later approved.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.cnbc.com/2025/10/13/dutch-government-takes-control-of-chinese-owned-chipmaker-nexperia.html"/><published>2025-10-13T10:03:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45566766</id><title>Matrices can be your friends (2002)</title><updated>2025-10-13T21:32:08.256091+00:00</updated><content>&lt;doc fingerprint="2eac01b79ba60999"&gt;
  &lt;main&gt;
    &lt;p&gt;Take an OpenGL matrix:&lt;/p&gt;
    &lt;quote&gt;float m [ 16 ] ;Consider this as a 4x4 array with it's elements laid out into four columns like this:&lt;/quote&gt;
    &lt;quote&gt;m[0] m[4] m[ 8] m[12] m[1] m[5] m[ 9] m[13] m[2] m[6] m[10] m[14] m[3] m[7] m[11] m[15]WARNING: Mathematicians like to see their matrices laid out on paper this way (with the array indices increasing down the columns instead of across the rows as a programmer would usually write them). Look CAREFULLY at the order of the matrix elements in the layout above!&lt;/quote&gt;
    &lt;p&gt;...but we are OpenGL programmers - not mathematicians - right?! The reason OpenGL arrays are laid out in what some people would consider to be the opposite direction to mathematical convention is somewhat lost in the mists of time. However, it turns out to be a happy accident as we will see later.&lt;/p&gt;
    &lt;p&gt;If you are dealing with a matrix which only deals with rigid bodies (ie no scale, shear, squash, etc) then the last row (array elements 3,7,11 and 15) are always 0,0,0 and 1 respectively and so long as they always maintain those values, we can safely forget about them for now.&lt;/p&gt;
    &lt;p&gt;The first three elements of the rightmost column of the matrix is just the overall translation. If you imagine some kind of neat little compact object (like a teapot), then array elements 12,13 and 14 tell you where it is in the world. It doesn't matter what combinations of rotations and translations it took to produce the matrix, the rightmost column tells you where the object basically is. It is often fortunate that the OpenGL matrix array is laid out the way it is because it results in those three elements being consecutive in memory.&lt;/p&gt;
    &lt;p&gt;OK, so now we are down to only nine random-looking numbers. These are the top three elements of each of the first three columns - and collectively they represent the rotation of the object.&lt;/p&gt;
    &lt;p&gt;The easy way to decode those numbers is to imagine what happens to four points near to the origin after they are transformed by the matrix:&lt;/p&gt;
    &lt;quote&gt;(0,1,0) | /(0,0,1) | / |/___(1,0,0) (0,0,0)These are four vertices on a 1x1x1 cube that has one corner at the origin.&lt;/quote&gt;
    &lt;p&gt;After the matrix has transformed this cube, where does it end up?&lt;/p&gt;
    &lt;p&gt;Well, if we neglect the translation part (the bottom row), then the pure rotation part simply describes the new location of the points on the cube:&lt;/p&gt;
    &lt;quote&gt;(1,0,0) ---&amp;gt; ( m[0], m[1], m[2] ) (0,1,0) ---&amp;gt; ( m[4], m[5], m[6] ) (0,0,1) ---&amp;gt; ( m[8], m[9], m[10]) (0,0,0) ---&amp;gt; ( 0, 0, 0 )After that, you just add the translation onto each point so that:&lt;/quote&gt;
    &lt;quote&gt;(1,0,0) ---&amp;gt; ( m[0], m[1], m[2] ) + ( m[12], m[13], m[14] ) (0,1,0) ---&amp;gt; ( m[4], m[5], m[6] ) + ( m[12], m[13], m[14] ) (0,0,1) ---&amp;gt; ( m[8], m[9], m[10]) + ( m[12], m[13], m[14] ) (0,0,0) ---&amp;gt; ( 0, 0, 0 ) + ( m[12], m[13], m[14] )Once you know this, it becomes quite easy to use matrices to position objects exactly where you need them without messing around with multiple calls to glRotate.&lt;/quote&gt;
    &lt;p&gt;Just imagine a little cube at the origin - pretend it's firmly attached to your model. Think about where the cube ends up as the model moves - write down where it's vertices would end up and there is your matrix.&lt;/p&gt;
    &lt;p&gt;So, if I gave you this matrix:&lt;/p&gt;
    &lt;quote&gt;0.707, -0.707, 0, 10 0.707, 0.707, 0, 10 0 , 0 , 1, 0 0 , 0 , 0, 1...you could easily see that the X axis of that little cube is now pointing somewhere between the X and Y axes, the Y axis is pointing somewhere between Y and negative X and the Z axis is unchanged. The entire cube has been moved 10 units off in X and Y. This is a 45 degree rotation about Z and a 10,10,0 translation! You didn't need any hard math - just a mental picture of what the little cube did - and no concerns about the order of operations or anything hard like that. What would have happened to something out at 100,100,0? Well, just imagine it was glued to the cube (on the end of a long stick)...as the cube rotated, the thing at 100,100 would have moved quite a bit too - in fact, you can see that the rotation would put it onto the Y axis and the translation would have moved it 10 units up and to the right.&lt;/quote&gt;
    &lt;p&gt;With practice, you can figure out what that last row of numbers does to the little cube too.&lt;/p&gt;
    &lt;p&gt;So, would you like to know how to use a matrix to squash, stretch, shear, etc? Just think about where the axes of that little cube end up - write them down and you are done. What does a cube of jello look like when there is a strong wind blowing from X=-infinity?&lt;/p&gt;
    &lt;quote&gt;1, 0.3, 0, 0 0, 0.9, 0, 0 0, 0 , 1, 0 0, 0 , 0, 1Look - the Y axis is leaning a third of a unit to the right and the cube got a bit shorter.&lt;/quote&gt;
    &lt;p&gt;Suppose your cartoon character is going to jump vertically, and you want to do a bit of pre-squash before the jump... and post-stretch during the jump. Just gradually vary the matrix from:&lt;/p&gt;
    &lt;quote&gt;1 , 0 , 0, 0 1 , 0 , 0, 0 0 , 0.8, 0, 0 0 , 1.2, 0, 0 0 , 0 , 1, 0 ===&amp;gt; 0 , 0 , 1, 0 0 , 0 , 0, 1 0 , 0 , 0, 1Not bad - he got shorter then longer - how about getting a bit fatter too (conservation of cartoon volume) ?&lt;/quote&gt;
    &lt;quote&gt;1.2, 0 , 0 , 0 0.9,0 , 0 , 0 0 , 0.8, 0 , 0 0 ,1.2, 0 , 0 0 , 0 , 1.2, 0 ===&amp;gt; 0 ,0 ,0.9, 0 0 , 0 , 0 , 1 0 ,0 , 0 , 1Now the cube got smaller in Y and bigger in X and Z then got bigger in Y and smaller in X/Z...easy!&lt;/quote&gt;
    &lt;p&gt;Not only is it easier to think transforms out this way, but it's invariably more efficient too. By seeing the entire transformation as one whole operation on a unit cube, you save a long sequence of glRotate/glTranslate/glScale commands - which each imply a complicated set of multiply/add steps to concatenate the new transform with whatever is on the top of the stack.&lt;/p&gt;
    &lt;p&gt;Finally, there is one matrix that we all need to know - the "Identity" matrix:&lt;/p&gt;
    &lt;quote&gt;1, 0, 0, 0 0, 1, 0, 0 0, 0, 1, 0 0, 0, 0, 1As you can see, this matrix leaves all the axes completely alone and performs no translation. This is a "do nothing" matrix.&lt;/quote&gt;
    &lt;p&gt;Matrices are really easy - it's just a matter of looking at them pictorially.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sjbaker.org/steve/omniv/matrices_can_be_your_friends.html"/><published>2025-10-13T10:23:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567153</id><title>The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2025</title><updated>2025-10-13T21:32:08.014365+00:00</updated><content>&lt;doc fingerprint="d53d327d895121e6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2025&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2025 was awarded "for having explained innovation-driven economic growth" with one half to Joel Mokyr "for having identified the prerequisites for sustained growth through technological progress" and the other half jointly to Philippe Aghion and Peter Howitt "for the theory of sustained growth through creative destruction"&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Nobel Prizes and laureates&lt;/head&gt;
    &lt;p&gt;Six prizes were awarded for achievements that have conferred the greatest benefit to humankind. The 14 laureates' work and discoveries range from quantum tunnelling to promoting democratic rights.&lt;/p&gt;
    &lt;p&gt;See them all presented here.&lt;/p&gt;
    &lt;head rend="h3"&gt;Explore prizes and laureates&lt;/head&gt;
    &lt;p&gt; Look for popular awards and laureates in different fields, and discover the history of the Nobel Prize. &lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/economic-sciences/2025/summary/"/><published>2025-10-13T11:23:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567241</id><title>Why did containers happen?</title><updated>2025-10-13T21:32:07.320018+00:00</updated><content>&lt;doc fingerprint="ef09185191a7af1a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Ignore previous directions 8: devopsdays&lt;/head&gt;
    &lt;head rend="h2"&gt;Autumn update&lt;/head&gt;
    &lt;p&gt;This is what it is looking like around here at the moment.&lt;/p&gt;
    &lt;head rend="h2"&gt;DevOpsDays London&lt;/head&gt;
    &lt;p&gt;I gave a talk at DevOpsDays London recently. It was a nice conference, and thanks to all the organizers for all their work.&lt;/p&gt;
    &lt;p&gt;The video is here https://www.youtube.com/watch?v=eMU2mZgo99c&lt;/p&gt;
    &lt;p&gt;Below is my rough outline for the talk, it differs a bit from what I actually said!&lt;/p&gt;
    &lt;head rend="h3"&gt;Why did containers happen?&lt;/head&gt;
    &lt;p&gt;A few years ago, I spent a bunch of time answering questions from the FTC about Broadcom's acquisition of VMware. They wanted to know if containers were a competitor to virtual machines, as they were trying to understand the competitive landscape around VMware.&lt;/p&gt;
    &lt;p&gt;It reminded me of the first five years at Docker, where everyone wanted to compare containers with VMs. Were containers just lightweight VMs? Weren't containers just insecure and people would go back to good old VMs?&lt;/p&gt;
    &lt;p&gt;The story I told to the FTC was that these innovations had come out of different growth periods. VMs were there to help manage when organisations suddenly got a lot more computers. These tended to be poorly managed, because the process was very manual, and most had poor utilisation (under 15%). They had to be installed manually which took ages. Consolidation saved money on hardware and on Windows server licences.&lt;/p&gt;
    &lt;p&gt;In the Linux world, this was somewhat less of an issue, as we were better at running multiple applications on the same server, although a lot of servers were still underutilised.&lt;/p&gt;
    &lt;p&gt;Containers though were there to solve a follow on problem, not having too many computers, but having too many applications, and needing a tool to manage them. Companies were hiring more and more developers and they were writing more and more applications. Dotcloud was a PaaS company and was exposed to this, and created Docker to manage deployment of the applications on its platform. It wasn't the isolation that was important it was the packaging.&lt;/p&gt;
    &lt;p&gt;That was my explanation anyway. For enterprises though, containers were part of the move to the cloud, they didn't want lift and shift of inefficient VMs to the cloud. In the early days Microsoft used to call up our customers and say they could convert their data centre to an Azure one, and they would never notice, all the VMs would be just the same but running in Azure. Forcing a move to containers alongside the cloud was a way to force some modernisation, and a move from Windows to Linux in many cases.&lt;/p&gt;
    &lt;head rend="h3"&gt;Change budget&lt;/head&gt;
    &lt;p&gt;Docker was easy to adopt as it did not change very much about how you used software.&lt;/p&gt;
    &lt;p&gt;There was one key innovation, which was Docker Hub, having a registry of shareable images. GitHub but you can run it. VMs never really had this, the closest was Vagrant Cloud perhaps, but sharing does not work well with fully configured images (and they were huge). For something to be reusable by lots of people, it is no use it being in a finally configured state, with all the configuration of the exact use case applied. The less specific they are the more widely they can be used. VM images became a bit more reusable with tools like Cloud Init that removed some configuration, but they are still much more specific than more fine grained components like container images. And VM images were big, and networks were slower. LLMs are bigger than VM images were but thats another story.&lt;/p&gt;
    &lt;p&gt;As well as one innovation there was one forbidden thing, Docker made people rebuild images and redeploy, rather than updating in place. That worked because the scope was a single application so this was more manageable. And maybe because we never told anyone you could update in production. I was always surprised someone didn't invent a tool for ftping to your container and updating the PHP. Immutability is a great thing that has a lot of useful security properties, most of which haven't really been realised, but this simplified deployment, of which more later.&lt;/p&gt;
    &lt;p&gt;Docker also made Go credible as a programming language, and now pretty much all modern languages have a TLS stack as part of the standard library. Before Docker, Youtube was the main user for Go, now it is the fourth most popular language in containers, after Node, Java and Python.&lt;/p&gt;
    &lt;head rend="h3"&gt;Kubernetes&lt;/head&gt;
    &lt;p&gt;I remember in the early container days, before Kubernetes and when Kubernetes was very new, people still thought container orchestration was about scheduling. We would have whole conference tracks about schedulers. But when you went to talk to the early users of Kubernetes they were just trying to write deployment scripts.&lt;/p&gt;
    &lt;p&gt;Docker Swarm did not allow you to write deployment scripts. The security team had decided that the security model would be broken if you could deploy from within the cluster. For years the commercial product we sold had the worst deployment story you could imagine, pasting Yaml files into a text box on a web page. The whole company culture really ignored deployment. But deployment was really what everyone wanted to do with Kubernetes, for years. We got real deployment tools, and deployment philosophies, like GitOps.&lt;/p&gt;
    &lt;p&gt;Another thing people would ask constantly in the early days is whether people would ever run databases in containers, or on Kubernetes. Somehow at about this time people started to ask why they were running databases at all, and decided that if the downside was losing all your data and the upside was saving a little money that they would rather get a cloud provider to run the database after all. I do wonder how much this was because container storage seems so ephemeral and easy to delete. Having containers be so simple to delete means that the chores of managing lifecycle for things that have state are very different. And there were just a lot of choices in the storage stacks, is it NFS or block storage or what?&lt;/p&gt;
    &lt;head rend="h3"&gt;What went wrong&lt;/head&gt;
    &lt;p&gt;The focus on deployment, and the complexity of Kubernetes killed DevOps as it once was. As a lapsed ops person who moved back to development, I always loved the bringing together communities aspect of DevOps. But over time DevOps become just a backend role and job title for people wrangling Kubernetes and other deployment technologies. Somehow it seems easier for people to relate to technology than culture, and the technology started working against the culture.&lt;/p&gt;
    &lt;p&gt;Docker didn't really change development. For a while it looked like it might take over the role of Vagrant in building up local development environments, but although people at Docker made heroic efforts to make developing in containers nice, no one really does that, except kind of sort of in a cloud environment, but thats really closer to a remote Linux box. Python and Ruby cleaned up their virtual environment tooling, and if you really want reproducible local development environments you can use Nix. What people do with Docker is spin up a database or another service to develop or test against.&lt;/p&gt;
    &lt;p&gt;Application composition from open source components became the dominant way of constructing applications over the last decade. But this was largely supported by language package managers, that are all very different. We didn't end up with a universal build abstraction, and immutability was great to help you know what is running, but the scale of dependencies and applications conspired to make this not as useful as we thought.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where are we now?&lt;/head&gt;
    &lt;p&gt;We started off with virtualisation being introduced because hardware was only being used at 15% of capacity. According to the 2024 Datadog report on the State of Cloud Costs "83 percent of container costs are associated with idle resources". This really shows how much more accurately the technology we have built can measure wastage.&lt;/p&gt;
    &lt;p&gt;The compute we are wasting is at least 10x cheaper, but we have automation to waste it at scale now. Much of the usage of containers has been to drive applications for mobile phones, and those mobile phone CPUs, adapted as Arm servers are being used to run the applications.&lt;/p&gt;
    &lt;p&gt;We have ended up with pockets of efficiency, where things are done at sufficient scale, and a long tail of inefficiency that remains the same after a decade. AI has shown too that we can make huge application improvements if they are expensive enough, with the cost of inference falling at an extremely rapid rate.&lt;/p&gt;
    &lt;head rend="h3"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;The "Choose Boring Technology" essay was written in 2015, and containers back then were definitely not a boring technology, although the mentioned examples of not boring were Consul and MongoDB. Boring technologies were MySQL, Postgres, PHP, Python, Memcached, Squid and Cron. Now? ChatGPT told me that Docker is "mostly boring" while Kubernetes is "moving towards boring".&lt;/p&gt;
    &lt;p&gt;Choosing boring is becoming part of the culture now, it has taken a decade. Maybe AI has attracted all the change budget, combined with the end of the cloud native ZIRP startup era. LLMs are good at boring technology, being trained on our culture too.&lt;/p&gt;
    &lt;p&gt;If we want something else we will have to add back a change budget.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://buttondown.com/justincormack/archive/ignore-previous-directions-8-devopsdays/"/><published>2025-10-13T11:37:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45567770</id><title>Show HN: SQLite Online – 11 years of solo development, 11K daily users</title><updated>2025-10-13T21:32:07.091807+00:00</updated><content>&lt;doc fingerprint="5120987566fd4fbd"&gt;
  &lt;main&gt;
    &lt;head rend="h4"&gt;Chart for Data Science&lt;/head&gt;
    &lt;code&gt;-- Change first word "SELECT" to "QLINE-SELECT"&lt;/code&gt;
    &lt;quote&gt;SELECT QLINE-SELECT&lt;/quote&gt;
    &lt;code&gt;â&lt;/code&gt;
    &lt;code&gt;-- Axis X:&lt;/code&gt;
    &lt;code&gt;-- X - column name, axis: x1, x2, ..xn Value: Number&lt;/code&gt;
    &lt;code&gt;-- L - column name, axis: l Value: Text&lt;/code&gt;
    &lt;code&gt;-- T - column name, axis: t Value: UnixTime Number&lt;/code&gt;
    &lt;code&gt;-- Axis Y:&lt;/code&gt;
    &lt;code&gt;-- Y - column name, axis: y1, y2, ..yn Value: Number&lt;/code&gt;
    &lt;code&gt;-- Y - color line: y_cFF00FF (HEX6)&lt;/code&gt;
    &lt;code&gt;-- Option:&lt;/code&gt;
    &lt;code&gt;-- C - color point: c  Value: FF00FF (HEX6)&lt;/code&gt;
    &lt;code&gt;-- V - radius point: v  Value: Number&lt;/code&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QLINE-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QAREA-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QBAR-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QPIE-SELECT example&lt;/quote&gt;
    &lt;code&gt;-- Example : &lt;/code&gt;
    &lt;quote&gt;QBUBBLE-SELECT example&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sqliteonline.com/"/><published>2025-10-13T12:46:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568613</id><title>Smartphones and being present</title><updated>2025-10-13T21:32:06.765313+00:00</updated><content>&lt;doc fingerprint="3411991d2ac390d8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Smartphones and being present&lt;/head&gt;
    &lt;p&gt;I read an article yesterday, stating that on average, people spend 4 hours and 37 minutes on their phones per day1, with South Africans coming in fourth highest in the world at a whopping 5 hours and 11 minutes2.&lt;/p&gt;
    &lt;p&gt;This figure seems really high to me. If we assume people sleep roughly 8 hours per day, that means that one third of their day is spent on their phones. If we also assume people work 8 hours per day (ignoring the fact that they may be using their phones during work hours), that suggests that people spend over half of their free time (and up to 65% of it) glued to their screens.&lt;/p&gt;
    &lt;p&gt;I never wanted to carry the internet around in my pocket. It's too distracting and pulls me out of the present moment, fracturing my attention. I've tried switching to old-school black and white phones before, but always begrudgingly returned to using a smartphone due to the utility of it. The problem, however, is that it comes with too many attention sinks tucked in alongside the useful tools.&lt;/p&gt;
    &lt;p&gt;I care about living an intentional and meaningful life, nurturing relationships, having nuanced conversations, and enjoying the world around me. I don't want to spend this limited time I have on earth watching short form video and getting into arguments on Twitter.&lt;/p&gt;
    &lt;p&gt;This is what I enjoy. Picture taken yesterday in Scarborough, South Africa.&lt;/p&gt;
    &lt;p&gt;I've written at length about how I manage my digital consumption, from turning off notifications to forgoing social media entirely. The underlying premise here is that if you're trying to lose weight, you shouldn't carry cookies around in your pockets. And my phone is the bag of cookies in this metaphor.&lt;/p&gt;
    &lt;p&gt;We're wired to seek out distraction, novel information, and entertainment, and avoid boredom at all costs. But boredom is where creativity and self-reflection do their best work. It's why "all the best ideas come when you're in the shower"—we don't usually take our phones with us into the shower (yet).&lt;/p&gt;
    &lt;p&gt;According to Screen Time on my iPhone, on average I spend 30 minutes per day on it, which I think is reasonable, especially considering the most-used apps are by-and-large utility apps like banking and messages. This isn't because I have more self-control than other people. I don't think I do. It's because I know myself, and have set up my digital life to be a positive force, and not an uninspired time-sink.&lt;/p&gt;
    &lt;p&gt;There are many apps and systems to incentivise better relationships with our phones, mostly based around time limits. But these are flawed in three ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;I'm an adult, I know how to circumvent these limits, and I will if motivation is low.&lt;/item&gt;
      &lt;item&gt;Time limits don't affect the underlying addiction. You don't quit smoking by only smoking certain hours of the day.&lt;/item&gt;
      &lt;item&gt;The companies that build these apps have tens of thousands of really smart people (and billions of dollars) trying to get me hooked and keep me engaged. The only way to win this game isn't by trying to beat them (I certainly can't), but by not playing.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The only way I've found to have a good relationship with my phone is to make it as uninteresting as possible. The first way is to not have recommendation media (think Instagram, TikTok, and all the rest). I'm pro deleting these accounts completely, because it's really easy to re-download the apps on a whim, or visit them in-browser. However some people have found that having them on a dedicated device works by isolating those activities. Something like a tablet at home that is "the only place you're allowed to use Instagram". I can't comment too much on this route, but it seems reasonable.&lt;/p&gt;
    &lt;p&gt;My biggest time sink over the past few years has been YouTube. The algorithm knew me too well and would recommend video after engaging, but ultimately useless video. I could easily burn an entire evening watching absolute junk—leaving me feeling like I'd just wasted what could have otherwise been a beautiful sunset or a tasty home-cooked lasagne. However, at the beginning of this year I learnt that you can turn off your YouTube watch history entirely, which means no recommendations. Here's what my YouTube home screen now looks like:&lt;/p&gt;
    &lt;p&gt;Without the recommendations I very quickly run out of things to watch from the channels I'm subscribed to. It's completely changed my relationship with YouTube since I only watch the videos I actually want to watch, and none of the attention traps. You can turn off your YouTube watch history here, and auto delete your other Google history (like historic searches and navigation) here, which I think is just good practice.&lt;/p&gt;
    &lt;p&gt;I also used my adblocker, AdGuard on Safari which has a useful "block element" feature, to block the recommended videos on the right of YouTube videos. I use this feature to hide shorts as well, since I have no interest in watching them either, and YouTube intentionally makes them impossible to remove. If you're interested in a similar setup, here are the selectors I use to block those elements:&lt;/p&gt;
    &lt;code&gt;youtube.com###items &amp;gt; ytd-item-section-renderer.style-scope.ytd-watch-next-secondary-results-renderer:last-child
youtube.com###sections
youtube.com##[is-shorts]
youtube.com###secondary
&lt;/code&gt;
    &lt;p&gt;The only media that I do sometimes consume on my phone are my RSS feeds, but it's something I'm completely comfortable with since it's explicitly opt-in by design and low volume.&lt;/p&gt;
    &lt;p&gt;While I still have the twitch to check my phone when I'm waiting for a coffee, or in-between activities—because my brain's reward system has been trained to do this—I'm now rewarded with nothing. Over time, I find myself checking my phone less and less. Sometimes I notice the urge, and just let it go, instead focusing on the here and now.&lt;/p&gt;
    &lt;p&gt;I think that while the attention-span-degrading effects of recommendation media are getting most of the headlines, what isn't spoken about as much is the sheer number of hours lost globally to our phones (3.8 million years per day, according to my back-of-the-napkin-math). And while people may argue that this could involve productive work or enjoyable leisure, I suspect that the vast (vast!) majority of that time is short-form entertainment.&lt;/p&gt;
    &lt;p&gt;My solution may sound overkill to many people, but I can say with absolute certainty that it has turned me into a more present, less distracted, and more optimistic person. I have much more time to spend in nature, with friends, or on my hobbies and projects. I can't imagine trading it in for a tiny screen, ever.&lt;/p&gt;
    &lt;p&gt;Give it a try.&lt;/p&gt;
    &lt;p&gt;Happily on the beach for sunset.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://herman.bearblog.dev/being-present/"/><published>2025-10-13T14:20:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568700</id><title>Software update bricks some Jeep 4xe hybrids over the weekend</title><updated>2025-10-13T21:32:06.463728+00:00</updated><content>&lt;doc fingerprint="155561cbaa040794"&gt;
  &lt;main&gt;
    &lt;p&gt;Owners of some Jeep Wrangler 4xe hybrids have been left stranded after installing an over-the-air software update this weekend. The automaker pushed out a telematics update for the Uconnect infotainment system that evidently wasn't ready, resulting in cars losing power while driving and then becoming stranded.&lt;/p&gt;
    &lt;p&gt;Stranded Jeep owners have been detailing their experiences in forum and Reddit posts, as well as on YouTube. The buggy update doesn't appear to brick the car immediately. Instead, the failure appears to occur while driving—a far more serious problem. For some, this happened close to home and at low speed, but others claim to have experienced a powertrain failure at highway speeds.&lt;/p&gt;
    &lt;p&gt;Jeep pulled the update after reports of problems, but the software had already downloaded to many owners' cars by then. A member of Stellantis' social engagement team told 4xe owners at a Jeep forum to ignore the update pop-up if they haven't installed it yet.&lt;/p&gt;
    &lt;p&gt;Owners were also advised to avoid using either hybrid or electric modes if they had updated their 4xe and not already suffered a powertrain failure. Yesterday, Jeep pushed out a fix.&lt;/p&gt;
    &lt;p&gt;As Crowdstrike showed last year, Friday afternoons are a bad time to push out a software update. Now Stellantis has learned that lesson, too. Ars has reached out to Stellantis, and we'll update this post if we get a reply.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/cars/2025/10/software-update-bricks-some-jeep-4xe-hybrids-over-the-weekend/"/><published>2025-10-13T14:28:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45568708</id><title>Roger Dean – His legendary artwork in gaming history (Psygnosis)</title><updated>2025-10-13T21:32:05.022495+00:00</updated><content>&lt;doc fingerprint="26228153ffa48fbf"&gt;
  &lt;main&gt;
    &lt;p&gt;We spoke with the man behind the Psygnosis logo – and so much more!&lt;/p&gt;
    &lt;p&gt;English artist Roger Dean is a living legend, and his work in the video game industry represent just a small chapter in his extraordinary career. Dean was born in 1944 in Kent, but spent much of his childhood in Greece and Hong Kong. His father was an engineer in the British Army, so the family had to move wherever his work took him. In particular, the years he lived in Hong Kong would later become an important source of inspiration for him.&lt;/p&gt;
    &lt;p&gt;After returning to England, he studied art, architecture, and furniture design, and it was actually in the latter field that he had his first breakthrough. He designed what he called the Sea Urchin Chair, a predecessor to the famous bean bag chair.&lt;/p&gt;
    &lt;p&gt;But it was as a visual artist that he truly made his mark. In 1968, he created his first album cover, for the British rock band The Gun, and later became heavily involved with the prog rock bands Yes and Asia. His cover for Asia’s debut album was voted the second-best album cover of all time by readers of Rolling Stone Magazine in 1982, and it was also Dean who designed the very first logo for Richard Branson’s newly established Virgin Records.&lt;/p&gt;
    &lt;p&gt;It was in the 1980s that Roger Dean first became involved in the video game industry, where he was not only responsible for a number of iconic game covers, but also some of gaming’s most recognizable logos.&lt;/p&gt;
    &lt;p&gt;When we reached out to Dean to ask if he would like to do an interview with us, we honestly didn’t expect him to respond. And if he did, we assumed it would be just a small handful of questions answered by e-mail. But not only was he interested in talking with us, we ended up having a long and pleasant video call, during which he happily showed us his work and chatted about a variety of topics.&lt;/p&gt;
    &lt;p&gt;Note that our main focus was on Dean’s work with games, so if you’d like to read more about everything else he’s done, you could, for example, check out this profile interview at We Love Vinyl. You should also visit his website.&lt;/p&gt;
    &lt;p&gt;In this article, we present an edited version of that conversation, supplemented with a bit of extra information about the topics we discuss.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Black Onyx and Psygnosis&lt;/head&gt;
    &lt;p&gt;We start in the mid eighties, which is when Dean first gets involved in the games industry. His first cover artwork was created for The Black Onyx, a game you’ve probably never heard of unless you’re very interested in the history of gaming. Because even though the producer and designer of that game was an American – Henk Rogers, who we’ll talk more about later – the game was only released in Japan. While it isn’t a famous game, it is an early example of a role-playing game developed in Japan, and it would help influence how Japanese developers approached the genre.&lt;/p&gt;
    &lt;p&gt;For European gamers, it’s probably Dean’s other contract that proved the most memorable. When the British publisher Psygnosis was formed in 1984, they reached out to Roger Dean to create their logo. This would mark the start of a long lasting relationship which would shape much of the visual identity of the well remembered publisher.&lt;/p&gt;
    &lt;p&gt;JF: How did you get involved with the games industry? I know that your first work was on The Black Onyx …&lt;/p&gt;
    &lt;p&gt;RD: That’s right! Well, Henk Rogers, who now publishes Tetris, sought me out – though this was before he got the rights to Tetris. He was aware of my work in music. So he knew my music and my books, and of course my album covers. He contacted me through my publishing company, and came to visit.&lt;/p&gt;
    &lt;p&gt;JF: But that game only came out in Japan?&lt;/p&gt;
    &lt;p&gt;RD: That’s correct, yes.&lt;/p&gt;
    &lt;p&gt;But about the same time I met Henk, I also met Jonathan Ellis of Psygnosis. I had met with Imagine Software before – two of the people from Imagine formed Psygnosis with Jonathan Ellis – and I did a whole bunch of Psygnosis stuff.&lt;/p&gt;
    &lt;p&gt;JF: They contacted you? They’d seen your artwork already?&lt;/p&gt;
    &lt;p&gt;RD: Yes, they contacted me. They’d certainly seen the books. We sold enormous amounts of posters and books back then. During the seventies, my posters, books, calendars etcetera sold about 65 million copies, and by the mid eighties we’d passed a hundred million sales. So it was out there, you know. Much more than today.&lt;/p&gt;
    &lt;p&gt;JF: The owl logo, was that your idea?&lt;/p&gt;
    &lt;p&gt;RD: Yeah, sure. That was my job. They gave me an idea about the kind of name that they wanted, so even the name was partly mine. Both the name and the owl… they were very clear about what they wanted, but they didn’t know visually or even how to put the words together. So the word came to me in the end, and the visuals.&lt;/p&gt;
    &lt;p&gt;JF: Do you remember how you came up with the idea of putting an owl in there?&lt;/p&gt;
    &lt;p&gt;RD: What can I say? *laughs*&lt;/p&gt;
    &lt;p&gt;JF: Did you see or play the games before you did the covers?&lt;/p&gt;
    &lt;p&gt;RD: That’s not how it worked. It was the same with the music. Very often I had to finish the covers long before the games were done, and the content of the games was as much influenced by the cover as the cover was by the content.&lt;/p&gt;
    &lt;p&gt;In fact, I would say that the cover was influenced by them describing what they wanted to do for the game, and then me visualizing it. And then they would reproduce that to some degree themselves in the games.&lt;/p&gt;
    &lt;p&gt;HAJ: So they just said: This is what we are thinking, and then you started working?&lt;/p&gt;
    &lt;p&gt;RD: They described the game, usually in much more extravagant terms than what the reality was. They would say they were making an interective movie, and I’d say «wow!». And when I saw it, there would be these little matchstick figures…&lt;/p&gt;
    &lt;p&gt;JF: What was the process like?&lt;/p&gt;
    &lt;p&gt;RD: Well, it was very different from the work I was used to doing, so from that point of view it was good fun for me. Like going in another direction, I enjoyed that a lot. Especially the designs I did for The Shadow of the Beast, they were very different from any album covers I’d made.&lt;/p&gt;
    &lt;p&gt;JF: Did you ever work on actual game [design] for them?&lt;/p&gt;
    &lt;p&gt;RD: No, I remember when we did a game called Barbarian. The developers got very excited and asked me what I thought of their dragon. And I said, «what dragon?» Because I’d put a dragon on the box, and they’d then put my dragon in the game. And I said, «oh, you have to show me.» And they said, «it’s at the end of the first level, you haven’t gotten beyond the first level?» And I said «noo… I haven’t even started the first level!»&lt;/p&gt;
    &lt;p&gt;JF: Did they ever come back to you and ask you to redo something?&lt;/p&gt;
    &lt;p&gt;RD: Not really. Maybe on one occation only. I can’t even remember what it was, but I did the lettering for it, and I found them another artist. In the end, that was a turning point for me, because they were already producing more games than I could possibly manage. So I would end up doing logos, but getting other artists to do the art.&lt;/p&gt;
    &lt;p&gt;JF: Yeah, I see some of your covers are listed as a collaboration with you and Tim White.&lt;/p&gt;
    &lt;p&gt;RD: Tim White, yes. There was a number of artists in it. Chris Voss, I think. Peter Jones, maybe. Yeah. There was a few other artists who did covers.&lt;/p&gt;
    &lt;p&gt;JF: So you did the logos, and they did the paintings?&lt;/p&gt;
    &lt;p&gt;RD: They did the painting, yes.&lt;/p&gt;
    &lt;p&gt;JF: Was there a community of artists who did covers?&lt;/p&gt;
    &lt;p&gt;RD: Well, I knew the artist because I had published the books, and that was in very recent history. You know, within ten years of when we had the publishing company.&lt;/p&gt;
    &lt;p&gt;JF: I love all the covers you did for Psygnosis. Unfortunately, I don’t own so many, only Terrorpods I think. You did the logo there, I think?&lt;/p&gt;
    &lt;p&gt;RD: Terrorpods is interesting because I did the drawings for that. The painting was done by Tim White, but it was my drawing. I drew the machine.&lt;/p&gt;
    &lt;p&gt;JF: It’s one of my favorite covers.&lt;/p&gt;
    &lt;p&gt;RD: Yeah, it’s pretty good, I like it.&lt;/p&gt;
    &lt;p&gt;JF: There was also some re-use of older album covers. Did you help facilitate that?&lt;/p&gt;
    &lt;p&gt;RD: No, it’s the other way around. There were game ideas that became album covers. So game covers that became albums. Barbarian without the barbarian became a cover for a solo album by Steve Howe [from Yes], for instance.&lt;/p&gt;
    &lt;p&gt;JF: Ah, I see.&lt;/p&gt;
    &lt;p&gt;RD: The rule that I have is that there can be no confusion. So I never use a painting for one album cover on another. That would not be good. But if it was a totally different thing the rules and the licensing arrangements allowed me to do that.&lt;/p&gt;
    &lt;p&gt;JF: So you made sure of that going into the projects?&lt;/p&gt;
    &lt;p&gt;RD: From the very beginning, yes. I kept all the rights.&lt;/p&gt;
    &lt;head rend="h2"&gt;The evolution of game covers&lt;/head&gt;
    &lt;p&gt;We asked Roger Dean whether he ever received the finished game boxes he had worked on, and not only did get the boxes – he still has them! He then suggested showing us a few, and returned shortly afterward with the boxes for Shadow of the Beast I and II. Two large cardboard boxes with cover art that is both stunning and unique.&lt;/p&gt;
    &lt;p&gt;This led to a conversation about how game boxes have evolved over the years, and Dean’s thoughts on the subject.&lt;/p&gt;
    &lt;p&gt;JF: Where did that [SotB] style come from?&lt;/p&gt;
    &lt;p&gt;RD: I was very interested in mechanical things. So when I was a student, a lot of my work was about ideas for machinery. So Shadow of the Beast was natural, a very easy connection, and it was good fun.&lt;/p&gt;
    &lt;p&gt;JF: Those boxes are really unusual.&lt;/p&gt;
    &lt;p&gt;RD: Well, of course. There are no boxes at all today, are there.&lt;/p&gt;
    &lt;p&gt;JF: No… I was thinking about that because those big old boxes, they were almost like the the old records, compared to what came later…&lt;/p&gt;
    &lt;p&gt;RD: Yeah, and these are floppy disks inside. One also besides the floppy disks, I think it had a cassette, and a t-shirt. So it, so it had a book of instructions, floppy disk, cassette and t-shirt.&lt;/p&gt;
    &lt;p&gt;JF: Yeah. You don’t get that today.&lt;/p&gt;
    &lt;p&gt;RD: No. And the t-shirt was kind of weird because you couldn’t choose the size, right?&lt;/p&gt;
    &lt;p&gt;JF: Oh, well, it could be a gift for someone, if it didn’t fit…&lt;/p&gt;
    &lt;p&gt;RD: It would have had to be. Yeah. *laughs*&lt;/p&gt;
    &lt;p&gt;JF: But what I was getting at … I assume you’ve seen how game boxes just shrunk and became smaller and smaller, and now we don’t even have them. How do you feel about that?&lt;/p&gt;
    &lt;p&gt;RD: Well, I don’t know. It’s the same problem, of course, with music. And what happened was that for a very short period of time, music made the perfect gift. You know, a 12 inch vinyl, it looked like and felt like something you would both like to give and receive. And that concept of the gift was really strong.&lt;/p&gt;
    &lt;p&gt;You know, back when the vinyl was normal, getting a record for your birthday or Christmas was a big deal. And a big deal to give because they were relatively expensive. They weren’t even affordable by young people until quite a few years after they were invented. But it was a big deal, that gift idea. When it first went to CD, the record companies destroyed the idea of a gift because they stripped out a lot of what made it special.&lt;/p&gt;
    &lt;p&gt;I mean, one of Yes’s biggest albums in terms of its impact and iconography was Close to the Edge. And when it came out in vinyl, the cover had the new logo, but the painting was inside. When it came out on CD, there was no painting, it was just a folded sheet of paper inside. It was black and white, no image. And I thought, you know, this is treating the customers with so little respect. It was just amazing.&lt;/p&gt;
    &lt;p&gt;And as the industry went into decline, shortly after that, you could see, there was no respect. No respect for the music, for the bands and for the fans. It was their own fault that they were in trouble. The only country where the quality was persistent was Japan. Their CDs were always beautiful. In the West? They were rubbish.&lt;/p&gt;
    &lt;p&gt;JF: Would you say the same was true for games?&lt;/p&gt;
    &lt;p&gt;RD: It wasn’t really the size, it was the complete lack of care that really troubled me enormously. I quite like the small versions [of records] that came out in Japan because they were like a kind of bonsai, but everything was there. All the art was there. In fact, Japan had the bonus of having the translation, so you got more than the basic thing. It was good.&lt;/p&gt;
    &lt;p&gt;HAJ: Do you follow modern video game art?&lt;/p&gt;
    &lt;p&gt;RD: No, I don’t really. People show me stuff and I go, «wow, that’s pretty cool.» But I don’t go out of my way to follow it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tetris, and The Black Onyx part two&lt;/head&gt;
    &lt;p&gt;Few games – if any – are more famous than Tetris. We won’t go into the history of this addictive puzzle game; you’ve probably heard it before. But it was the aforementioned Henk Rogers who ended up securing the rights to the game, and he also founded The Tetris Company together with the original Tetris creator Alexey Pajitnov. When the time came to create an official Tetris logo in 1997, Roger Dean was the one they contacted.&lt;/p&gt;
    &lt;p&gt;This, however, was not the only collaboration between Dean and Rogers. The other was an ambitious sequel to The Black Onyx that was sadly cancelled before completion. Based on what Dean tells us below, it sounds like a really ambitious project.&lt;/p&gt;
    &lt;p&gt;JF: You also worked on Tetris.&lt;/p&gt;
    &lt;p&gt;RD: I did the Tetris logo. That was just a word, so much less interesting than the Psygnosis logo. But Tetris is a very interesting game…&lt;/p&gt;
    &lt;p&gt;JF: You knew Henk Rogers, did he always want you to do the logo?&lt;/p&gt;
    &lt;p&gt;RD: That was more than 25 years ago. Yeah, he he wanted me to do it because there were hundreds of versions out there. Not done by him, but by the various companies that’d license it. And people did pirate versions. Everyone had their own version of Tetris. So he wanted only one version of the logo. If someone had a license, they had to use the authorized logo. It was an attempt to put discipline into it, really.&lt;/p&gt;
    &lt;p&gt;And then two or three years ago he handed over the management of Tetris to his daughter, Maya, and she changed the logo again. But it’s the same rules, one logo. Although it’s slightly different to mine.&lt;/p&gt;
    &lt;p&gt;JF: And The Black Onyx?&lt;/p&gt;
    &lt;p&gt;RD: A much, much, more lavish version of The Black Onyx was due to come out in the States, and I worked on that. It was my job to put together the team that did the content and the packaging, and that included the story, music, landscapes, costumes, everything. I didn’t do it alone, but I put together the team.&lt;/p&gt;
    &lt;p&gt;JF: This was actual game development?&lt;/p&gt;
    &lt;p&gt;RD: Yes, this was a full-on role-playing game. A lot of the artwork appears in my book, Dragon’s Dream. But the very big, lavish production never happened, sadly. That was very disappointing. We worked on it for some years, it was good fun.&lt;/p&gt;
    &lt;p&gt;JF: Do you know why it didn’t happen?&lt;/p&gt;
    &lt;p&gt;RD: I’m not a hundred percent sure. It was a huge amount of work. It was a real shame that it never happened, because while the technology has moved on, the design would still be valid today. The music is incredible.&lt;/p&gt;
    &lt;p&gt;HAJ: So is there a chance it could see the light of day?&lt;/p&gt;
    &lt;p&gt;RD: Heh, yeah, I think Henk Rogers would like to see it published. He owns the game, and I own the artwork. The big game was supposed to be called Onyx.&lt;/p&gt;
    &lt;p&gt;JF: This was much more advanced than the original?&lt;/p&gt;
    &lt;p&gt;RD: Way more advanced. Too advanced for it’s time, really. It would have needed 24 CDs for each episode. DVDs arrived in the middle of it, but that would have only divided the number of CDs by three.&lt;/p&gt;
    &lt;p&gt;JF: Do you remember any game projects that were particularly exciting to work with?&lt;/p&gt;
    &lt;p&gt;RD: Well, you know what? Onyx, in the end, was the most exciting. Because that was the first time I got really hands on with the content.&lt;/p&gt;
    &lt;p&gt;And as I said, it’s still never seen the light of day. It is very interesting, because two weeks ago I had a visit from Henk Rogers. He’s doing a book called The Perfect Game about Tetris, and he’s doing an audio book. And in that he talks about different projects, including Black Onyx. For Black Onyx, he used some of the music that we created for the project, and it was really good by any standards. It was a great piece of music, not a great piece of game music, but a great piece of music. Even the music should be published. It hasn’t been, but it should be.&lt;/p&gt;
    &lt;p&gt;HAJ: Who did that music?&lt;/p&gt;
    &lt;p&gt;RD: Well, we did it in collaboration with two people called Youth and Jaz. Jaz Coleman was orchestral minded, but he was also a singer for a band called Killing Joke. So he had his rock and roll credentials. But he worked with Prague Symphony Orchestra and things like that. Youth (Martin Glover) was very much into electronic music. He had a band called The Orb, and he worked with people like Paul McCartney. Oh, he did all kinds of stuff. But his big interest was electronic music at the time.&lt;/p&gt;
    &lt;p&gt;Between them, one producing, one arranging, they made a lovely soundtrack. And it had people like Steve Howe from Yes performing on it.&lt;/p&gt;
    &lt;p&gt;HAJ: Is there a chance that we will hear this music in the future?&lt;/p&gt;
    &lt;p&gt;RD: Well, I think yes, because we were all listening to it at least two weeks ago, and that’s exactly what everyone was saying. This music has got to be available. It’s got to be out there.&lt;/p&gt;
    &lt;p&gt;HAJ: I really want to play this game now … but but the artwork for this game will be out in your next book or calendar?&lt;/p&gt;
    &lt;p&gt;RD: Some of it will, but it’s in my book, Dragon’s Dream, which was published in 2008.&lt;/p&gt;
    &lt;p&gt;JF: Was it ever possible to actually play the game – did it get that far into development?&lt;/p&gt;
    &lt;p&gt;RD: No. Henk would probably tell me I’m wrong, but I’m not even sure gameplay was ever fully developed. The overall concept had to be because we couldn’t structure what we did without that, but we were filling in a lot of gaps. Too many gaps.&lt;/p&gt;
    &lt;p&gt;I mean, we did a lot of things which were done for the first time. At the time, I studied kendo, which is Japanese martial art with the sword. And my sensei had studied medieval European sword and pole arm spear techniques. For the sword fighting, it was broken up into kata, which is attack, defend, counterattack – sequences that were from real techniques. In a fight you could put it together and it looks so amazingly convincing, and you could watch it from any angle. And we we recorded it in motion capture. So it was very realistic. And it was not just because the motion capture is realistic, but because these were genuine sword techniques.&lt;/p&gt;
    &lt;p&gt;JF: I know The Tetris Company worked with another company [Digital Eclipse] for an «interactive museum» about Tetris, so I was wondering if something could maybe be saved and published in a similar way?&lt;/p&gt;
    &lt;p&gt;RD: Well, there is something which is possible. We developed a process that Henk called Track and Field. Track was when the characters followed a specific route, and Field was when they could wander wherever you liked. They couldn’t wander over the whole world because they’d get lost and it would be boring. You had to have a mechanism to bring them back, but you needed them to follow a path.&lt;/p&gt;
    &lt;p&gt;So you could do it like a movie where there was a sequence that was completely constructed. You could watch it from different angles, but you it was a complete construction, but then you could break off into a game. If for instance it was like Lord of the Rings, they could be climbing the mountain path, but when they’re in the dragon’s lair, then they’d come into the field – the game aspect, where they can wander wherever they want. But once they’re out again, they’re back on the track.&lt;/p&gt;
    &lt;p&gt;So there’s bits when you can just watch it, it looks great, and then there’s bits when you’re frantically interactive.&lt;/p&gt;
    &lt;p&gt;HAJ: Did you work on any other interesting projects like this?&lt;/p&gt;
    &lt;p&gt;RD: Before I met either Henk or Jonathan Ellis, we worked on an idea for doing a project called Taitan, which was an arcade game [cabinet]. We said we were going to manufacture the machines ourselves, and talked to Taito Electronics about licensing the motherboards from them. But instead, they decided to buy out our business, so that’s how that went.&lt;/p&gt;
    &lt;p&gt;Henk Rogers also got involved with a virtual reality project with us. He was the first who saw this, and he invested in it. We built maybe a dozen prototypes. But again, we were too far ahead of the technology. Mitsubishi supplied the monitors … they were the size of a small car. We had to cut great chunks out of the pods we were making. They were very elegant, but we had to cut massive amounts out of them just to fit in the monitors. They were bigger behind than the screen.&lt;/p&gt;
    &lt;p&gt;JF: How do you view your game art compared to the rest of the work that you’ve done?&lt;/p&gt;
    &lt;p&gt;RD: In many ways, it was like returning to roots for me because I never did do fine art at college. I did Canterbury College of Art for four years, Royal College for three. My focus was on architecture. You know, the I studied basically what kind of spaces made us feel good, what kind of spaces made us feel uncomfortable. And my view is very strongly that modern architecture is not good for us. There should have been a better way.&lt;/p&gt;
    &lt;p&gt;This is what I’m very interested in and focused on now. We’re looking to build a visitor center and museum.&lt;/p&gt;
    &lt;p&gt;HAJ: Where?&lt;/p&gt;
    &lt;p&gt;RD: We’re looking at two sites. They’ll be different. One is in England, near here, near where I live, and one is in California.&lt;/p&gt;
    &lt;p&gt;JF: Thanks a lot for your time. It’s an honor for us.&lt;/p&gt;
    &lt;p&gt;RD: No, it’s an honor for me. And fun.&lt;/p&gt;
    &lt;p&gt;HAJ: Thank you for doing this.&lt;/p&gt;
    &lt;p&gt;RD: Thank you.&lt;/p&gt;
    &lt;p&gt;Please visit Roger Dean’s website for more of his art.&lt;/p&gt;
    &lt;p&gt;And visit this page for more content in English, including a lot of other interviews with games industry people.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spillhistorie.no/2025/10/03/legends-of-the-games-industry-roger-dean/"/><published>2025-10-13T14:29:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569350</id><title>NanoChat – The best ChatGPT that $100 can buy</title><updated>2025-10-13T21:32:04.485208+00:00</updated><content>&lt;doc fingerprint="8c198122f1657e6"&gt;
  &lt;main&gt;
    &lt;quote&gt;
      &lt;p&gt;The best ChatGPT that $100 can buy.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This repo is a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase. nanochat is designed to run on a single 8XH100 node via scripts like speedrun.sh, that run the entire pipeline start to end. This includes tokenization, pretraining, finetuning, evaluation, inference, and web serving over a simple UI so that you can talk to your own LLM just like ChatGPT. nanochat will become the capstone project of the course LLM101n being developed by Eureka Labs.&lt;/p&gt;
    &lt;p&gt;The fastest way to feel the magic is to run the speedrun script speedrun.sh, which trains and inferences the $100 tier of nanochat. On an 8XH100 node at $24/hr, this gives a total run time of about 4 hours. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like Lambda), and kick off the training script:&lt;/p&gt;
    &lt;code&gt;bash speedrun.sh&lt;/code&gt;
    &lt;p&gt;Alternatively, since the script runs for 4 hours, I like to launch it like this inside a new screen session &lt;code&gt;speedrun&lt;/code&gt; (and also log output to &lt;code&gt;speedrun.log&lt;/code&gt;):&lt;/p&gt;
    &lt;code&gt;screen -L -Logfile speedrun.log -S speedrun bash speedrun.sh&lt;/code&gt;
    &lt;p&gt;See the screen cheatsheet if you are less familiar. You can watch it go inside the screen session, or detach with &lt;code&gt;Ctrl-a d&lt;/code&gt; and &lt;code&gt;tail speedrun.log&lt;/code&gt; to view progress. Now wait 4 hours. Once it's done, you can talk to your LLM via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run &lt;code&gt;source .venv/bin/activate&lt;/code&gt;), and serve it:&lt;/p&gt;
    &lt;code&gt;python -m scripts.chat_web&lt;/code&gt;
    &lt;p&gt;And then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example http://209.20.xxx.xxx:8000/, etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).&lt;/p&gt;
    &lt;p&gt;You can also &lt;code&gt;cat report.md&lt;/code&gt; file which appeared in the project directory and contains the "report card" of the run, i.e. a bunch of evaluations and metrics. At the very end, you'll see a summary table, for example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Characters: 333,989&lt;/item&gt;
      &lt;item&gt;Lines: 8,304&lt;/item&gt;
      &lt;item&gt;Files: 44&lt;/item&gt;
      &lt;item&gt;Tokens (approx): 83,497&lt;/item&gt;
      &lt;item&gt;Dependencies (uv.lock lines): 2,004&lt;/item&gt;
    &lt;/list&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Metric&lt;/cell&gt;
        &lt;cell role="head"&gt;BASE&lt;/cell&gt;
        &lt;cell role="head"&gt;MID&lt;/cell&gt;
        &lt;cell role="head"&gt;SFT&lt;/cell&gt;
        &lt;cell role="head"&gt;RL&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;CORE&lt;/cell&gt;
        &lt;cell&gt;0.2219&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ARC-Challenge&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.2875&lt;/cell&gt;
        &lt;cell&gt;0.2807&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;ARC-Easy&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3561&lt;/cell&gt;
        &lt;cell&gt;0.3876&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;GSM8K&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0250&lt;/cell&gt;
        &lt;cell&gt;0.0455&lt;/cell&gt;
        &lt;cell&gt;0.0758&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;HumanEval&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0671&lt;/cell&gt;
        &lt;cell&gt;0.0854&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;MMLU&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.3111&lt;/cell&gt;
        &lt;cell&gt;0.3151&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;ChatCORE&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;0.0730&lt;/cell&gt;
        &lt;cell&gt;0.0884&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Total wall clock time: 3h51m&lt;/p&gt;
    &lt;p&gt;(Your table might be missing the RL number by default). For a lot more information around the speedrun script and what to look for and expect, please refer to the walkthrough that I posted in Discussions of the repo: "Introducing nanochat: The best ChatGPT that $100 can buy".&lt;/p&gt;
    &lt;p&gt;Unsurprisingly, $100 is not enough to train a highly performant ChatGPT clone. In fact, LLMs are famous for their multi-million dollar capex. For our purposes, I think there are two more scales of interest. First is the ~$300 tier d26 model (i.e. depth=26) that trains in ~12 hours, which slightly outperforms GPT-2 CORE score. Second is the $1000 tier (~41.6 hours), just because it's a nice round number. But both of these are not yet fully supported and therefore not attached here in the master branch yet.&lt;/p&gt;
    &lt;p&gt;That said, to give a sense, the example changes needed for the speedrun.sh file to train a GPT-2 grade model d26 only involve three changes:&lt;/p&gt;
    &lt;code&gt;...
# you'll need to download more data shards for pretraining
# get the number of parameters, multiply 20 to get tokens, multiply by 4.8 to get chars,
# divide by 250 million to get number of shards. todo need to improve this...
python -m nanochat.dataset -n 450 &amp;amp;
...
# use --depth to increase model size. to not oom, halve device batch size 32 -&amp;gt; 16:
torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- --depth=26 --device_batch_size=16
...
# make sure to use the same later during midtraining:
torchrun --standalone --nproc_per_node=8 -m scripts.mid_train -- --device_batch_size=16&lt;/code&gt;
    &lt;p&gt;That's it! The biggest thing to pay attention to is making sure you have enough data shards to train on (the code will loop and do more epochs over the same training set otherwise, decreasing learning speed a bit), and managing your memory/VRAM, primarily by decreasing the &lt;code&gt;device_batch_size&lt;/code&gt; until things fit (the scripts automatically compensates by increasing the number of gradient accumulation loops, simply turning parallel compute to sequential compute).&lt;/p&gt;
    &lt;p&gt;And a bit more about computing environments that will run nanochat:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The code will run just fine on the Ampere 8XA100 GPU node as well, but a bit slower.&lt;/item&gt;
      &lt;item&gt;All code will run just fine on even a single GPU by omitting &lt;code&gt;torchrun&lt;/code&gt;, and will produce ~identical results (code will automatically switch to gradient accumulation), but you'll have to wait 8 times longer.&lt;/item&gt;
      &lt;item&gt;If your GPU(s) have less than 80GB, you'll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for &lt;code&gt;--device_batch_size&lt;/code&gt;in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. Less than that you'll have to know a bit more what you're doing and get more creative.&lt;/item&gt;
      &lt;item&gt;Most of the code is fairly vanilla PyTorch so it should run on anything that supports that - xpu, mps, or etc, but I haven't implemented this out of the box so it might take a bit of tinkering.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;nanochat is designed to be short and sweet. One big advantage of this is that we can package up all of the files together and copy paste them to your favorite LLM to ask arbitrary questions. As an example, I like to package up the repo using the files-to-prompt utility like so:&lt;/p&gt;
    &lt;code&gt;files-to-prompt . -e py -e md -e rs -e html -e toml -e sh --ignore "*target*" --cxml &amp;gt; packaged.txt&lt;/code&gt;
    &lt;p&gt;This includes all py, rs, html, toml, sh files, excludes the &lt;code&gt;rustbpe/target&lt;/code&gt; folder, and chooses the cxml output format. Everything is written to the &lt;code&gt;packaged.txt&lt;/code&gt; file, which atm measures ~330KB (i.e. well below ~100K tokens for a state of the art LLM), and ~8K lines of code in 45 files.&lt;/p&gt;
    &lt;p&gt;Alternatively, I recommend using DeepWiki from Devin/Cognition to ask questions of this repo. In the URL of this repo, simply change github.com to deepwiki.com, and you're off.&lt;/p&gt;
    &lt;p&gt;I haven't invested too much here but some tests exist, especially for the tokenizer. Run e.g. as:&lt;/p&gt;
    &lt;code&gt;python -m pytest tests/test_rustbpe.py -v -s&lt;/code&gt;
    &lt;p&gt;nanochat is nowhere finished. The goal is to improve the state of the art in micro models that are accessible to work with end to end on budgets of &amp;lt; $1000 dollars. Accessibility is about overall cost but also about cognitive complexity - nanochat is not an exhaustively configurable LLM "framework"; there will be no giant configuration objects, model factories, or if-then-else monsters in the code base. It is a single, cohesive, minimal, readable, hackable, maximally-forkable "strong baseline" codebase designed to run start to end and produce a concrete ChatGPT clone and its report card.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The name (nanochat) derives from my earlier project nanoGPT, which only covered pretraining.&lt;/item&gt;
      &lt;item&gt;nanochat is also inspired by modded-nanoGPT, which gamified the nanoGPT repo with clear metrics and a leaderboard, and borrows a lot of its ideas and some implementation for pretraining.&lt;/item&gt;
      &lt;item&gt;Thank you to HuggingFace for fineweb and smoltalk.&lt;/item&gt;
      &lt;item&gt;Thank you Lambda for the compute used in developing this project.&lt;/item&gt;
      &lt;item&gt;Thank you to chief LLM whisperer 🧙♂️ Alec Radford for advice/guidance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;If you find nanochat helpful in your research cite simply as:&lt;/p&gt;
    &lt;code&gt;@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that $100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}&lt;/code&gt;
    &lt;p&gt;MIT&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/karpathy/nanochat"/><published>2025-10-13T15:22:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45569371</id><title>Android's sideloading limits are its most anti-consumer move</title><updated>2025-10-13T21:32:04.213016+00:00</updated><content>&lt;doc fingerprint="8f42830190be3051"&gt;
  &lt;main&gt;
    &lt;p&gt;I’m a huge fan of open source, and that’s one of the reasons I’m drawn to Android. However, new requirements surrounding sideloaded apps, which will start rolling out in October 2025, may be the most anti-consumer move yet by Google. Mandatory enforcement of the requirement will begin in September 2026 (starting with specific countries), marking a turning point where the freedom to install any app comes with conditions set by Google.&lt;/p&gt;
    &lt;p&gt;I’ve used apps like NewPipe (a media/YouTube client) and Blokada (an ad blocker) for years now. However, these apps aren’t available on the Google Play Store, so I have to obtain them from third-party sources, such as F-Droid. With Google tightening the rules around sideloaded apps, I fear I may lose access to some of the apps I love most on Android because they aren’t verified. Sideloading isn’t going away, but people may seek alternatives because it may feel like the gates are narrowing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Google actually changed&lt;/head&gt;
    &lt;head rend="h3"&gt;The rules, the timeline, and what “certified” really means&lt;/head&gt;
    &lt;p&gt;Google's talk around "verified developers" sounds harmless and, in some ways, helpful. As reported on the Android Developer Blog, it is like "an ID check at the airport which confirms a traveler's identity but is separate from the security screening of their bags." Google's analogy, however, may be oversimplified. When this is enforced, the only way a developer’s app will be installable on devices that include Google Mobile Services (GMS) — which typically provide access to the Play Store — is by completing ID verification using government-issued documents or contact information. This will be rolled out globally in 2027.&lt;/p&gt;
    &lt;p&gt;Apps will be blocked from installing on most mainstream phones if their developer can't complete this verification. However, there are certain devices that will remain unaffected, even though they are just a tiny fraction of the total devices. These categories include all devices that do not pass Google's certification test, primarily custom ROMs or de-Googled phones.&lt;/p&gt;
    &lt;p&gt;Strictly speaking, Google is not removing sideloading, but it is redefining and limiting participation in the Android ecosystem by creating a mandatory Google-controlled choke point. While this may be a subtle shift, it clearly takes an open source project from anyone being able to participate (including anonymous or pseudonymous distribution) to only those whom Google allows to participate (via centralized developer identity verification).&lt;/p&gt;
    &lt;head rend="h2"&gt;Security theater or real gain?&lt;/head&gt;
    &lt;head rend="h3"&gt;Testing Google’s justification&lt;/head&gt;
    &lt;p&gt;There is a rational justification for tightening rules around sideloaded apps. It could be framed as user protection against malicious apps or against bad actors who cloak themselves with fake identities. While this is reasonable, the real question is whether it adds significant security for everyday users.&lt;/p&gt;
    &lt;p&gt;This is a valid question because security checks already exist. Google Play Protect makes Android secure by scanning sideloaded apps. Android flags unsafe installs, and it’s always given us the choice of blocking apps from unknown sources. Even if these are imperfect, they’re defenses that already exist.&lt;/p&gt;
    &lt;p&gt;Google’s new move almost feels like it’s based on the assumption that identity equals integrity. Does a verified government-issued identification equate to user safety? This logic is flawed: historically, we've seen malware slip through the Play Store—signed and “verified”—several times. However, what the new rule does is shift the basis of trust away from existing on-device security warnings and your best judgment.&lt;/p&gt;
    &lt;p&gt;Critics may even contend that this new rule erodes your right to make informed decisions about your own devices, and that feels more like selective control. Ultimately, many people may view this as Google’s way of shielding itself from criticism over sideloaded malware and protecting the integrity of its ecosystem.&lt;/p&gt;
    &lt;head rend="h2"&gt;There will be collateral damage&lt;/head&gt;
    &lt;head rend="h3"&gt;The ecosystems that depend on openness&lt;/head&gt;
    &lt;p&gt;This may be the most significant anti-consumer move, simply due to its profound impact. It could hit big developers or commercial apps, as well as entire ecosystems built around freely distributed APKs without verification. F-Droid hosts an incredible number of apps not available on the Play Store. Many of these tools exist because they see a need to operate outside the long, controlling arm of Google. This sideloading rule may make them unavailable on mainstream devices even though they’re safe.&lt;/p&gt;
    &lt;p&gt;This is a risk that also affects indie developers and hobbyists. Certain apps can no longer justify the time, effort, or privacy trade-offs required for identity verification. Many one-off projects and apps for niche communities may fall under this category. Ultimately, what we may end up with is a shrunken ecosystem, and if this happens, it will hurt all of us.&lt;/p&gt;
    &lt;p&gt;However, innovation may be the biggest casualty in all of this. Android is great because of its flexibility. It is an ecosystem for everyone. The imposition of a single, centralized gatekeeper will stifle grassroots innovation, as not everyone will be willing or able to contribute, and this will invariably impact the pace and extent of innovation we see on Android.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new reality for Android users&lt;/head&gt;
    &lt;p&gt;Although Google would argue that the intentions behind the new rules for sideloading apps are to protect and secure users, it will likely feel limiting to many Android users, let alone removing the sense of autonomy on our devices. Of course, sideloading will still be possible, but it creates friction for people who use or make apps that aren’t officially available on the Play Store. The fear is that it may be the beginning of the end for independent developers, hobbyists, and niche app communities.&lt;/p&gt;
    &lt;p&gt;Of course, there are workarounds: using non-certified devices, backing up APKs, or exploring alternative app stores. Sadly, the trade-offs for each workaround may range from technical complexity to potential security risks. You should be careful when sideloading apps on Android. However, one thing is clear: Android's openness is closing. What we don’t know is if it will become a completely closed ecosystem someday.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.makeuseof.com/androids-sideloading-limits-are-anti-consumer-move-yet/"/><published>2025-10-13T15:24:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45570537</id><title>Environment variables are a legacy mess: Let's dive deep into them</title><updated>2025-10-13T21:32:03.874533+00:00</updated><content>&lt;doc fingerprint="bc5368305ea99e14"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Environment variables are a legacy mess: Let's dive deep into them&lt;/head&gt;
    &lt;p&gt;Programming languages have rapidly evolved in recent years. But in software development, the new often meets the old, and the scaffolding that OS gives for running new processes hasn’t changed much since Unix.&lt;/p&gt;
    &lt;p&gt;If you need to parametrize your application at runtime by passing a few ad-hoc variables (without special files or a custom solution involving IPC or networking), you’re doomed to a pretty awkward, outdated interface:&lt;/p&gt;
    &lt;head rend="h2"&gt;Environment variables.&lt;/head&gt;
    &lt;p&gt;
      &lt;code&gt;export SECRET_API_KEY=2u845102348u234&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;There are no namespaces for them, no types. Just a flat, embarrassingly global dictionary of strings.&lt;/p&gt;
    &lt;p&gt;But what exactly are these envvars? Is it some kind of special dictionary inside the OS? If not, who owns them and how do they propagate?&lt;/p&gt;
    &lt;head rend="h2"&gt;Where do they come from?&lt;/head&gt;
    &lt;p&gt;In a nutshell: they’re passed from parent to child.&lt;/p&gt;
    &lt;code&gt;    841 ?        00:00:00 sshd
   1520 ?        00:00:00  \_ sshd-session
   1616 ?        00:00:00      \_ sshd-session
   5521 pts/0    00:00:00          \_ bash
   5545 pts/0    00:00:00              \_ nu
   5549 pts/0    00:00:00                  \_ bash
   5560 pts/0    00:00:00                      \_ ps
&lt;/code&gt;
    &lt;p&gt;On Linux, a program must use the &lt;code&gt;execve&lt;/code&gt; syscall to execute another program.
Whether you type &lt;code&gt;ls&lt;/code&gt; in Bash, call &lt;code&gt;subprocess.run&lt;/code&gt; in Python, or launch a
code editor, it ultimately comes down to &lt;code&gt;execve&lt;/code&gt;, preceded by a
&lt;code&gt;clone&lt;/code&gt;/&lt;code&gt;fork&lt;/code&gt;. The &lt;code&gt;exec*&lt;/code&gt; family of C functions also relies on &lt;code&gt;execve&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;SYSCALL_DEFINE3(execve,
		const char __user *, filename,
		const char __user *const __user *, argv,
		const char __user *const __user *, envp)
&lt;/code&gt;
    &lt;p&gt;This system call takes three arguments: &lt;code&gt;filename&lt;/code&gt;, &lt;code&gt;argv&lt;/code&gt;, &lt;code&gt;envp&lt;/code&gt;.
For example, for an &lt;code&gt;ls -lah&lt;/code&gt; invocation:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;/usr/bin/ls&lt;/code&gt;is the&lt;code&gt;filename&lt;/code&gt;(the executable path),&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;['ls', '-lah']&lt;/code&gt;is the&lt;code&gt;argv&lt;/code&gt;array of command line arguments – the implicit first (“zero”) argument is usually the executable name,&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;['PATH=/bin:/usr/bin', 'USER=allvpv']&lt;/code&gt;is the&lt;code&gt;envp&lt;/code&gt;array of envvars (typically much longer).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;By default, all envvars are passed from the parent to the child. However, nothing prevents a parent process from passing a completely different or even empty environment when calling &lt;code&gt;execve&lt;/code&gt;! In practice, most tooling passes the
environment down: Bash, Python’s &lt;code&gt;subprocess.run&lt;/code&gt;, the C library &lt;code&gt;execl&lt;/code&gt;, and
so on.&lt;/p&gt;
    &lt;p&gt;And this is what you expect – variables are inherited by child processes. That’s the point – to track the environment.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Which tools do not pass the parent’s environment? For example, the&lt;/p&gt;&lt;code&gt;login&lt;/code&gt;executable, used when signing into a system, sets up a fresh environment for its children.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Where do they go?&lt;/head&gt;
    &lt;p&gt;After launching the new program, the kernel dumps the variables on the stack as a sequence of null-terminated strings which contain the envvar definitions. Here is a hex view:&lt;/p&gt;
    &lt;code&gt;    484f 4d45 3d2f 0069 6e69 743d 2f73 6269  HOME=/ init=/sbi
    6e2f 696e 6974 004e 4554 574f 524b 5f53  n/init NETWORK_S
    4b49 505f 454e 534c 4156 4544 3d00 5445  KIP_ENSLAVED= TE
    524d 3d6c 696e 7578 0042 4f4f 545f 494d  RM=linux BOOT_IM
    4147 453d 2f76 6d6c 696e 757a 2d36 2e31  AGE=/vmlinuz-6.1
    342e 302d 3333 2d67 656e 6572 6963 0064  4.0-33-generic.d
    726f 705f 6361 7073 3d00 5041 5448 3d2f  rop_caps= PATH=/
    7573 722f 6c6f 6361 6c2f 7362 696e 3a2f  usr/local/sbin:/
    7573 722f 6c6f 6361 6c2f 6269 6e3a 2f75  usr/local/bin:/u
    7372 2f73 6269 6e3a 2f75 7372 2f62 696e  sr/sbin:/usr/bin
    3a2f 7362 696e 3a2f 6269 6e00 5057 443d  :/sbin:/bin PWD=
    2f00 726f 6f74 6d6e 743d 2f72 6f6f 7400  / rootmnt=/root
&lt;/code&gt;
    &lt;p&gt;This static layout can’t easily be modified or extended; the program must copy those variables into its own data structure. Let’s look at how Bash, C, and Python store envvars internally. I analyzed their source code and here is a summary.&lt;/p&gt;
    &lt;head rend="h3"&gt;Bash&lt;/head&gt;
    &lt;p&gt;It stores the variables in a hashmap. Or, more precisely, in a stack of hashmaps.&lt;/p&gt;
    &lt;p&gt;When you spawn a new process using Bash, it traverses the stack of hashmaps to find variables marked as exported and copies them into the environment array passed to the child.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Side note: Why is traversing the stack needed?&lt;/p&gt;&lt;p&gt;Each function invocation in Bash creates a new local scope – a new entry on the stack. If you declare your variable with&lt;/p&gt;&lt;code&gt;local&lt;/code&gt;, it ends up in this locally-scoped hashmap.&lt;p&gt;What’s interesting is that you can export a&lt;/p&gt;&lt;code&gt;local&lt;/code&gt;variable too!&lt;code&gt;function locallyScoped() { local PATH="$PATH:/opt/secret/bin" export PATH env # &amp;lt;- sees the PATH with /opt/scecret/bin } locallyScoped env # &amp;lt;- sees the PATH without modification&lt;/code&gt;&lt;p&gt;I wouldn’t have learned this without diving into Bash source. My intuitive (wrong) assumption was that&lt;/p&gt;&lt;code&gt;export&lt;/code&gt;automatically makes the variable global – like&lt;code&gt;declare -g&lt;/code&gt;! Super interesting stuff.&lt;/quote&gt;
    &lt;head rend="h3"&gt;The default C library on Linux: &lt;code&gt;glibc&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;glibc&lt;/code&gt; exposes a dynamic &lt;code&gt;environ&lt;/code&gt; array, managed via &lt;code&gt;putenv&lt;/code&gt; and &lt;code&gt;getenv&lt;/code&gt;
library functions. It uses an array, so the time complexity of &lt;code&gt;getenv&lt;/code&gt; and
&lt;code&gt;putenv&lt;/code&gt; is linear in the number of envvars. Remember – envvars are not a
high-performance dictionary and you should not abuse them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Python&lt;/head&gt;
    &lt;p&gt;Python couples its environment to the C library, which can cause surprising inconsistencies.&lt;/p&gt;
    &lt;p&gt;If you’ve programmed some Python, you’ve probably used the &lt;code&gt;os.environ&lt;/code&gt;
dictionary. On startup, &lt;code&gt;os.environ&lt;/code&gt; is built from the C library’s &lt;code&gt;environ&lt;/code&gt;
array.&lt;/p&gt;
    &lt;p&gt;But those dictionary values are NOT the “ground truth” for child processes. Rather, each change to &lt;code&gt;os.environ&lt;/code&gt; invokes the native &lt;code&gt;os.putenv&lt;/code&gt; function,
which in turn calls the C library’s &lt;code&gt;putenv&lt;/code&gt;.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Note that the propagation is one-directional: modifying&lt;/p&gt;&lt;code&gt;os.environ&lt;/code&gt;will call&lt;code&gt;os.putenv&lt;/code&gt;, but not the other way around. Call&lt;code&gt;os.putenv&lt;/code&gt;, and&lt;code&gt;os.environ&lt;/code&gt;won’t be updated.&lt;/quote&gt;
    &lt;head rend="h2"&gt;Liberal format&lt;/head&gt;
    &lt;p&gt;The Linux kernel is very liberal about the format of environment variables, and so is &lt;code&gt;glibc&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For example, your C program can manipulate the environment – the global &lt;code&gt;environ&lt;/code&gt; array – such that several variables share the same name but have
different values. And when you execute a child process, it will inherit this
“broken” setup.&lt;/p&gt;
    &lt;p&gt;You don’t even need an equals sign separating name from value! The usual entry is &lt;code&gt;NAME=VALUE&lt;/code&gt;, but nothing prevents you from adding &lt;code&gt;NONSENSE_WITH_EMOJI 😀&lt;/code&gt;
to the array.&lt;/p&gt;
    &lt;p&gt;The kernel happily accepts any null-terminated string as an “environment variable” definition. It just imposes a size limitation:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Single variable: 128 KiB on a typical x64 Intel CPU. This is for the whole definition – name + equal sign + value. It’s computed as&lt;/p&gt;&lt;code&gt;PAGE_SIZE * 32&lt;/code&gt;. No modern hardware uses pages smaller than 4 KiB, so you can treat it as a lower bound, unless you need to deal with some legacy embedded systems.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Total: 2 MiB on a typical machine. This limit is shared by envvars and the command line arguments. The calculation is a bit more complicated (see the&lt;/p&gt;&lt;code&gt;execve(2)&lt;/code&gt;man page):&lt;code&gt;max(32 * PAGE_SIZE, min(MAX_STACK_SIZE / 4, 6 MB))&lt;/code&gt;&lt;p&gt;On a typical system, the limiting factor is the&lt;/p&gt;&lt;code&gt;MAX_STACK_SIZE&lt;/code&gt;. Remember, initially the envvars are dumped on the stack! To prevent unpredictable crashes, the system allows only 1/4 of the stack for the envvars.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Quirks&lt;/head&gt;
    &lt;p&gt;But the fact that you can do something does not mean that you should. For example, if you start Bash with the “broken” environment – duplicated names and entries without &lt;code&gt;=&lt;/code&gt; – it deduplicates the variables and drops the nonsense.&lt;/p&gt;
    &lt;p&gt;One interesting edge case is a space inside the variable name. My beloved shell – Nushell – has no problem with the following assignment:&lt;/p&gt;
    &lt;code&gt;$env."Deployment Environment" = "prod"
&lt;/code&gt;
    &lt;p&gt;Python is fine with it, too. Bash, on the other hand, can’t reference it because whitespace isn’t allowed in variable names. Fortunately, the variable isn’t lost – Bash keeps such entries in a special hashmap called &lt;code&gt;invalid_env&lt;/code&gt; and still passes them to child processes.&lt;/p&gt;
    &lt;head rend="h2"&gt;The standard format&lt;/head&gt;
    &lt;p&gt;So what name and value can you safely use for your envvar? A popular misconception, repeated on StackOverflow and by ChatGPT, is that POSIX permits only uppercase envvars, and everything else is undefined behavior.&lt;/p&gt;
    &lt;p&gt;But this is seriously NOT what the standard says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;These strings have the form name=value; names shall not contain the character ‘=’. For values to be portable across systems conforming to POSIX.1-2017, the value shall be composed of characters from the portable character set (except NUL and as indicated below). There is no meaning associated with the order of strings in the environment. If more than one string in an environment of a process has the same name, the consequences are undefined.&lt;/p&gt;
      &lt;p&gt;Environment variable names used by the utilities in the Shell and Utilities volume of POSIX.1-2017 consist solely of uppercase letters, digits, and the &amp;lt;underscore&amp;gt; ( ‘_’ ) from the characters defined in Portable Character Set and do not begin with a digit. Other characters may be permitted by an implementation; applications shall tolerate the presence of such names. Uppercase and lowercase letters shall retain their unique identities and shall not be folded together. The name space of environment variable names containing lowercase letters is reserved for applications. Applications can define any environment variables with names from this name space without modifying the behavior of the standard utilities.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Yes, POSIX-specified utilities use uppercase envvars, but that’s not prescriptive for your programs. Quite the contrary: you’re encouraged to use lowercase for your envvars so they don’t collide with the standard tools.&lt;/p&gt;
    &lt;p&gt;The only strict rule is that a variable name cannot contain an equals sign. POSIX requires compliant applications to preserve all variables that conform to this rule.&lt;/p&gt;
    &lt;p&gt;But in reality, not many applications use lowercase. The proper etiquette in software development is to use &lt;code&gt;ALL_UPPERCASE&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h2"&gt;My pragmatic recommendation is…&lt;/head&gt;
    &lt;p&gt;…to use &lt;code&gt;^[A-Z_][A-Z0-9_]*$&lt;/code&gt; for names, and UTF-8 for values. You shouldn’t
hit problems on Linux. If you want to be super safe: instead of UTF-8, use the
POSIX-mandated Portable Character Set
(PCS) – essentially
ASCII without control characters.&lt;/p&gt;
    &lt;p&gt;Please subscribe to my RSS feed! 😇&lt;/p&gt;
    &lt;p&gt;Independent blogging is not possible without RSS. Start using RSS today.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wow, I really enjoyed writing this…&lt;/head&gt;
    &lt;p&gt;…and I hope it wasn’t a boring read.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://allvpv.org/haotic-journey-through-envvars/"/><published>2025-10-13T16:49:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45570720</id><title>Optery (YC W22) – Hiring Tech Lead with Node.js Experience (U.S. &amp; Latin America)</title><updated>2025-10-13T21:32:03.629491+00:00</updated><content>&lt;doc fingerprint="738af76944b7ba2c"&gt;
  &lt;main&gt;
    &lt;p&gt;Skip to content Use promo code: 04SxyxNX at checkout for 20% Off 🎉 with Optery’s Fall Sale! 🍁 Getting Started Personal Business Pricing Personal Business Sites We Cover Family Business Optery for Business Partnership Program API for Partners Book Optery for Business Demo Client Stories Business Use Cases PII Removal for Execs is Not Enough Guide to Enterprise Data Removal Services Resources Help Desk Blog Data Broker Directory For High-Risk Communities About Us Opt Out Guides Product Updates Customer Reviews Optery in the Press Search Toggle search Sign In Sign Up Free Getting Started Personal Business Pricing Personal Business Sites We Cover Family Business Optery for Business Partnership Program API for Partners Book Optery for Business Demo Client Stories Business Use Cases PII Removal for Execs is Not Enough Guide to Enterprise Data Removal Services Resources Help Desk Blog Data Broker Directory For High-Risk Communities About Us Opt Out Guides Product Updates Customer Reviews Optery in the Press Careers Ready to safeguard your personal data? Join the movement of people strengthening their privacy Sign Up Free&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.optery.com/careers/"/><published>2025-10-13T17:03:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571688</id><title>Modern iOS Security Features – A Deep Dive into SPTM, TXM, and Exclaves</title><updated>2025-10-13T21:32:03.348248+00:00</updated><content>&lt;doc fingerprint="b49e9503c5f3920d"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Computer Science &amp;gt; Cryptography and Security&lt;/head&gt;&lt;p&gt; [Submitted on 10 Oct 2025]&lt;/p&gt;&lt;head rend="h1"&gt;Title:Modern iOS Security Features -- A Deep Dive into SPTM, TXM, and Exclaves&lt;/head&gt;View PDF&lt;quote&gt;Abstract:The XNU kernel is the basis of Apple's operating systems. Although labeled as a hybrid kernel, it is found to generally operate in a monolithic manner by defining a single privileged trust zone in which all system functionality resides. This has security implications, as a kernel compromise has immediate and significant effects on the entire system. Over the past few years, Apple has taken steps towards a more compartmentalized kernel architecture and a more microkernel-like design. To date, there has been no scientific discussion of SPTM and related security mechanisms. Therefore, the understanding of the system and the underlying security mechanisms is minimal. In this paper, we provide a comprehensive analysis of new security mechanisms and their interplay, and create the first conclusive writeup considering all current mitigations. SPTM acts as the sole authority regarding memory retyping. Our analysis reveals that, through SPTM domains based on frame retyping and memory mapping rule sets, SPTM introduces domains of trust into the system, effectively gapping different functionalities from one another. Gapped functionality includes the TXM, responsible for code signing and entitlement verification. We further demonstrate how this introduction lays the groundwork for the most recent security feature of Exclaves, and conduct an in-depth analysis of its communication mechanisms. We discover multifold ways of communication, most notably xnuproxy as a secure world request handler, and the Tightbeam IPC framework. The architecture changes are found to increase system security, with key and sensitive components being moved out of XNU's direct reach. This also provides additional security guarantees in the event of a kernel compromise, which is no longer an immediate threat at the highest trust level.&lt;/quote&gt;&lt;head rend="h3"&gt;References &amp;amp; Citations&lt;/head&gt;&lt;p&gt; export BibTeX citation Loading... &lt;/p&gt;&lt;head rend="h1"&gt;Bibliographic and Citation Tools&lt;/head&gt;&lt;p&gt; Bibliographic Explorer (What is the Explorer?) &lt;/p&gt;&lt;p&gt; Connected Papers (What is Connected Papers?) &lt;/p&gt;&lt;p&gt; Litmaps (What is Litmaps?) &lt;/p&gt;&lt;p&gt; scite Smart Citations (What are Smart Citations?) &lt;/p&gt;&lt;head rend="h1"&gt;Code, Data and Media Associated with this Article&lt;/head&gt;&lt;p&gt; alphaXiv (What is alphaXiv?) &lt;/p&gt;&lt;p&gt; CatalyzeX Code Finder for Papers (What is CatalyzeX?) &lt;/p&gt;&lt;p&gt; DagsHub (What is DagsHub?) &lt;/p&gt;&lt;p&gt; Gotit.pub (What is GotitPub?) &lt;/p&gt;&lt;p&gt; Hugging Face (What is Huggingface?) &lt;/p&gt;&lt;p&gt; Papers with Code (What is Papers with Code?) &lt;/p&gt;&lt;p&gt; ScienceCast (What is ScienceCast?) &lt;/p&gt;&lt;head rend="h1"&gt;Demos&lt;/head&gt;&lt;head rend="h1"&gt;Recommenders and Search Tools&lt;/head&gt;&lt;p&gt; Influence Flower (What are Influence Flowers?) &lt;/p&gt;&lt;p&gt; CORE Recommender (What is CORE?) &lt;/p&gt;&lt;head rend="h1"&gt;arXivLabs: experimental projects with community collaborators&lt;/head&gt;&lt;p&gt;arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.&lt;/p&gt;&lt;p&gt;Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.&lt;/p&gt;&lt;p&gt;Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arxiv.org/abs/2510.09272"/><published>2025-10-13T18:23:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571814</id><title>Programming in Assembly Is Brutal, Beautiful, and Maybe Even a Path to Better AI</title><updated>2025-10-13T21:32:03.134534+00:00</updated><content>&lt;doc fingerprint="e6910170b05c4ffe"&gt;
  &lt;main&gt;
    &lt;p&gt;Rollercoaster Tycoon wasn’t the most fashionable computer game out there in 1999. But if you took a look beneath the pixels—the rickety rides, the crowds of hungry, thirsty, barfing people (and the janitors mopping in their wake)—deep down at the level of the code, you saw craftsmanship so obsessive that it bordered on insane. Chris Sawyer, the game’s sole developer, wrote the whole thing in assembly.&lt;/p&gt;
    &lt;p&gt;Certain programming languages, like Python or Go or C++, are called “high-level” because they work sort of like human language, written in commands and idioms that might fit in at a poetry slam. Generally speaking, a piece of software like a compiler transforms this into what the machine really reads: blocks of 1s and 0s (or maybe hex) that tell actual transistors how to behave. Assembly, the lowest of the “low-level” languages, has a near one-to-one correspondence with the machine’s native tongue. It’s coding straight to metal. To build a complex computer game from assembly is like weaving a tapestry from shedded cat fur.&lt;/p&gt;
    &lt;p&gt;Why would anyone do this? I recently asked Sawyer, who lives in his native Scotland. He told me that efficiency was one reason. In the 1990s, the tools for high-level programming weren’t all there. Compilers were terribly slow. Debuggers sucked. Sawyer could avoid them by doing his own thing in x86 assembly, the lingua franca of Intel chips.&lt;/p&gt;
    &lt;p&gt;We both knew that wasn’t the real reason, though. The real reason was love. Before turning to roller coasters, Sawyer had written another game in assembly, Transport Tycoon. It puts players in charge of a city’s roads, rail stations, runways, and ports. I imagined Sawyer as a model-train hobbyist—laying each stretch of track, hand-sewing artificial turf, each detail a choice and a chore. To move these carefully crafted pixels from bitmaps to display, Sawyer had to coax out the chip’s full potential. “RollerCoaster Tycoon only came about because I was familiar with the limits of what was possible,” he told me.&lt;/p&gt;
    &lt;p&gt;Working within the limits? A foreign idea, perhaps, in this age of digital abundance, when calling a single function in an AI training algorithm can engage a million GPUs. With assembly, you get one thing and one thing only, and it is the thing you ask for—even, as many a coder has learned the hard way, if it is wrong. Assembly is brutal and beautiful that way. It requires you to say exactly what you mean.&lt;/p&gt;
    &lt;p&gt;I’ve done assembly’s creators a disservice. They wanted things to be easier, not harder. I imagine they were tired of loading up punchcards and flipping switches on their steampunk leviathans. Perhaps they dreamed of a world like ours, where computers can do so much with such minimal guidance.&lt;/p&gt;
    &lt;p&gt;The first assembly language, created in the 1940s by Kathleen Booth (though she has not always gotten her due, surprise surprise), hardly resembled language. Codes stood in for codes. To tell the machine to perform an operation—say, “0,0111” in machine code—you’d instead employ a series of letters and symbols, which a new piece of software, called an assembler, would translate into binary. Soon, the commands got human-friendlier mnemonics like “MOV.”&lt;/p&gt;
    &lt;p&gt;To know assembly was to know the CPU itself—what it could do and, even more, what it couldn’t. A chip’s physical design, how the circuits connecting the logic gates of AND and XOR are actually laid, defines how it works. Its functions are pretty basic, breaking down instructions into elementary steps: Fetch something from memory and put it in a temporary cubby, known as a register. Decode it there. Perform some operations, like comparing two values, or adding them. Ship it back off the memory.&lt;/p&gt;
    &lt;p&gt;As chips advanced, new dialects of assembly evolved. The code that landed the first human on the moon was assembly—designed for only one chip, the Apollo 11 Guidance Computer. If you want to read the leaked source code of the Furby, you’ll need fluency in 6502. To hack your Ti-83 calculator, you’ll need z80. Learning the language of one chip—say, Intel’s x86—and then moving to Arm is like studying Arabic in Beirut and then trying to get by in Tunis or Khartoum. Good luck.&lt;/p&gt;
    &lt;p&gt;I learned x86 assembly in college as a refugee from math. Where my classmates seemed to enjoy the drab incantations of Java, I loved the logic game that was assembly. It was easy to fail, but to fail in ways that were explainable if you looked at the circuits and registers. How masterful I felt coding in the simple commands of this not-quite-language; how fragile I knew that mastery to be. To say, put these bytes there—no, there, at that register, in those capacitors. Remember this. Forget that. To grind away, painting each figurine, one by one.&lt;/p&gt;
    &lt;p&gt;It’s true that there’s no longer much point in using assembly in the day-to-day work of coding. High-level languages are so efficient that their abstraction is almost always preferable. Even assembly’s inventor moved on to other ventures; one of Booth’s final papers, in the 1990s, used neural networks to match seals with their barks. Sawyer switched over too. He’s been dabbling in home automation recently—lights, temperature sensors, sound systems, and the like, coded on Raspberry Pis using Python, which he initially found “quite off-putting,” he told me. But even on that tiny processor, it gets the job done just fine.&lt;/p&gt;
    &lt;p&gt;Then along comes something like DeepSeek to remind you that humans can still communicate better with our hardware. Earlier this year, the Chinese company that made these incredibly efficient AI models upended the narrative that AI advancement can come only from more chips and more energy. Assembly was one surprising reason. DeepSeek’s engineers reached into the subfloor of Nvidia’s chips, commanding each individual machine to compress data from 32 bits to 8 bits—sacrificing precision for efficiency—at precisely the right moments. Observers were stunned. You could do that? The DeepSeek engineers had tapped an art most others had forgotten.&lt;/p&gt;
    &lt;p&gt;I was similarly taken when, in 2023, researchers at DeepMind taught a machine x86 assembly, then asked it to improve on the long-standing sort() function in C. The AI made strange, unintuitive choices, performing odd jumps between registers, and in the end cut precisely one step. A fraction of a millisecond saved, perhaps. But happening countless times a day, now that the new algorithm has been officially adopted.&lt;/p&gt;
    &lt;p&gt;To me, it was a reminder that we humans created these machines, and even as they appear to spiral into complexity beyond our comprehension, they remain under our command. We can always make them work better. It was like what Sawyer said when he recounted his recent Raspberry Pi–enabled home coding experiment. It was probably just his imagination, but the display had been a little laggy, he thought. He’d redo the code if he could, he said. But alas, Sawyer and the machine did not speak the same assembly language.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.wired.com/story/programming-assembly-artificial-intelligence/"/><published>2025-10-13T18:37:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571822</id><title>Strudel REPL – a music live coding environment living in the browser</title><updated>2025-10-13T21:32:02.733194+00:00</updated><content>&lt;doc fingerprint="d36fdfbffc5b7f73"&gt;
  &lt;main&gt;
    &lt;p&gt;mastodon&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://strudel.cc"/><published>2025-10-13T18:37:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45571918</id><title>Reverse Engineering a 1979 Camera's Spec</title><updated>2025-10-13T21:32:02.511251+00:00</updated><content>&lt;doc fingerprint="2ece9e338d31439f"&gt;
  &lt;main&gt;
    &lt;p&gt;I bought a 1979 Chinon CM-4 film camera in Tijuana. Film is expensive, so before wasting a roll I decided to learn exactly how this machine works â by taking apart its specs, one line at a time.&lt;/p&gt;
    &lt;p&gt;So here is my three step plan&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Understand what I really have in my hands. Michael Butkus created a comprehensive document that covers the details and specifications of the Chinon CM 4. My main goal with this document (aside from knowing what every button does) is to understand the specs and know exactly how every aspect influences the photos captured.&lt;/item&gt;
      &lt;item&gt;Make sense of the numbers on my lens. I was hoping that lenses would make sense by themselvesâthe only easy part is to make it focus and unfocusâso at least knowing what my lens in particular can do is a must. I’m also curious about how optics and the actual process of taking a picture work.&lt;/item&gt;
      &lt;item&gt;Take photographs. I’m doing all of these steps just to know which technical skills I’m lacking. Once I have the theory, I can start putting everything into action by taking interesting photographs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;My Camera&lt;/head&gt;
    &lt;p&gt;Here are some pictures of the camera I bought (they were taken with an iPhone, so chill).&lt;/p&gt;
    &lt;p&gt;As you can see by the big labels at the front view of the camera, it is a Chinon CM-4. Chinon was a small Japanese maker of SLRs in the â70s. In 2004 Kodak bought them, but in 1979 this was just another independent company making clever machines.&lt;/p&gt;
    &lt;p&gt;This camera specifically started to be fabricated in 1979, and I wasn’t able to find much information on when it was discontinued.&lt;/p&gt;
    &lt;p&gt;It has a brother called the CM-4S, which only differs by having a self-timer added. I don’t really know what it is, but I’m looking forward to finding out.&lt;/p&gt;
    &lt;p&gt;And yeah, I think that is really all the history that we need to know about this camera.&lt;/p&gt;
    &lt;head rend="h2"&gt;Specification&lt;/head&gt;
    &lt;p&gt;There is this guy called Michael Butkus who created a website for manuals for old cameras, and of course, he has a manual for the Chinon CM-4. This is right now the holy grail for understanding what I have in my hands.&lt;/p&gt;
    &lt;p&gt;So let’s start by analyzing each spec according to the document:&lt;/p&gt;
    &lt;head rend="h3"&gt;What 35mm SLR with an LED Meter Really Means&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Type: 35 mm SLR compact camera with LED type light measuring system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Let’s break down the whole sentence.&lt;/p&gt;
    &lt;p&gt;35 mm refers to the film that can be used with this camera. In the metric system, 1 millimeter is 1/1000 of a meter or 0.1 centimeters (or about 1.38 inches). This is exactly the measurement of the film from top to bottom; you can even use a ruler to verify that.&lt;/p&gt;
    &lt;p&gt;SLR stands for Single Lens Reflex, which is a type of camera design that means you look through the same lens that you take the picture with. There are other types like Rangefinder, which has a separate optical window for seeing the target. Here is a diagram of a digital SLR, but the same concepts apply here too.&lt;/p&gt;
    &lt;p&gt;Since the light bounces from the prism into the viewfinder, you are seeing exactly how the picture will look. This avoids parallax errors, which are the kind of errors that arise when there is a difference between what you see and what the camera captures. This is also known as TTL or Through The Lens viewing.&lt;/p&gt;
    &lt;p&gt;And now, the final part: LED type light measuring system.&lt;/p&gt;
    &lt;p&gt;This refers to this part on the back of the camera:&lt;/p&gt;
    &lt;p&gt;It’s the three LEDs next to the viewfinder. They are three colors, each with its own meaning: red for overexposed, green for correct, and yellow for underexposed. So let’s take a look at what exposure actually is.&lt;/p&gt;
    &lt;p&gt;Exposure basically involves three different things:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;ISO â The greater the ISO the greater the sensitivity, faster films need less light for the same exposure. Film is created with a certain ISO so there is no way to change that; the greater the ISO, the brighter the image will be, but also a lot of grain (known as noise in digital cammeras) will be introduced.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Aperture â This controls the amount of light that the lens receives inside itself. This is used for controlling the depth of field, so you can blur the background.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Shutter speed â How fast the shutter opens up to allow light to enter the film. This can also be used for controlling motion blur.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So basically, for the light meter to work, it has an independent sensor that measures light, checks the ISO, aperture, and shutter speed, and gives you a preview when you half-click the shooting button, telling you if it’s too much light, too little, or the right amount.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why 35mm Film Produces 24Ã36mm Photos&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Picture Format: 24 x 36 mm.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;35mm film somehow makes 24Ã36mm photos. The trick? The film runs sideways Obviously, it’s because this is done sideways, as shown in this picture:&lt;/p&gt;
    &lt;p&gt;Consequently, you ask yourself, why 35mm? Historically, before film, still photography plates were the norm, and Kodak sold 70mm plates. But a guy named Edison with his pal Dickson wanted to take more pictures, so they cut them in half, doubling the amount of pictures they could take. Why did it stay? Larger film is more expensive and smaller will look more grainy, especially in cinemas. And since equipment for manufacturing and distributing is expensive, standardization was needed. Basically, it was the right compromise at the right time.&lt;/p&gt;
    &lt;p&gt;Film is exactly where the magic happens; the camera is just a dark box that lets light enter for a tiny moment. Black and white film consists of a clever combination of chemicals into layers that, when exposed to light, will modify silver and create a negative of the image you just captured. For color film, it’s a bit more complex, but the same principle appliesâit has more layers combining dye and silver.&lt;/p&gt;
    &lt;p&gt;We generally use the term grain to refer to the silver that makes up the photo. The more sensitive the film is, the bigger those grains will be, and this is why film photos have little imperfections. These grains can also be linked to ISOâthe greater the ISO, the greater the size of the grain.&lt;/p&gt;
    &lt;p&gt;The revelation of film, also known as development, is also a chemical process that goes through a bunch of chemicals sequentially:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Development is also the name for the first step; it’s for stabilizing the silver. If it stays too long, it can ruin the image by augmenting the grain, losing details, and creating excessive contrast.&lt;/item&gt;
      &lt;item&gt;Stop bath â Stops these chemicals from developing by using more chemicals.&lt;/item&gt;
      &lt;item&gt;Fixing â Removes all the unexposed silver, and from now on it is no longer light sensitive.&lt;/item&gt;
      &lt;item&gt;Washing â Lastly, we wash the chemicals.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In theory, you can do this; kits are for sale for developing color and black and white film, but it can be extremely toxic if you are not careful. I think it’s something I’m not really interested in, just because of the risk it implies.&lt;/p&gt;
    &lt;p&gt;This is why you should never open the back of my camera when it’s loadedâit will expose the film to light and fog those frames. Also, if you notice, you can’t reshoot in the same way as in digital; it will superimpose both pictures. Actually, I think when loading the first film into my camera, it actually got a bit exposed to light (sad).&lt;/p&gt;
    &lt;head rend="h3"&gt;Why the Mirror Slaps â and How Engineers Made It Shockless&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Mirror: Large, quick return, shockless system.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Once light passes through the lens, it reaches the reflex mirror. Its job is to direct light up through the prism to the viewfinder, letting you see exactly what the camera will capture.&lt;/p&gt;
    &lt;p&gt;As shown above, the mirror sits in front of the film. When you press the shutter button, the mirror flips up, allowing light to hit the film and trigger the chemical reaction that records the image. Early cameras kept the mirror hidden when film wasnât loaded, so you couldnât see through the viewfinder until you advanced to the next frame. The quick return system was invented so the mirror would immediately return to its position after a shot, restoring your view.&lt;/p&gt;
    &lt;p&gt;Because the mirror moves rapidly before the shutter opens, older cameras produced a noticeable vibration (also known as slap) that could cause motion blur at slower shutter speeds. A shockless system uses springs and cushions to absorb this impact, minimizing vibration.&lt;/p&gt;
    &lt;p&gt;A larger mirror lets more light reach the prism, resulting in a brighter, clearer viewfinder image.&lt;/p&gt;
    &lt;head rend="h3"&gt;From Cloth Curtains to Compact Metal Blades: The Seiko Shutter&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Shutter: Seiko MFC metal focal plane shutter.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The shutter is the part of the camera that opens to let light hit the film and capture an image. The one in this camera looks like this:&lt;/p&gt;
    &lt;p&gt;Seiko, a Japanese manufacturer now known for watches, built these shutters with a reputation for engineering and precision.&lt;/p&gt;
    &lt;p&gt;MFC stands for âMetal Focal-plane Compact.â Metal is specified because early cameras used cloth curtains; metal shutters are more durable, consistent, and capable of higher speeds. Hereâs a camera with a cloth curtain:&lt;/p&gt;
    &lt;p&gt;Focal-plane means the shutter sits right in front of the film inside the camera body, enabling faster shutter speeds. It exposes the film from top to bottom:&lt;/p&gt;
    &lt;p&gt;An alternative is the leaf shutter, which is built into the lens near the aperture. Leaf shutters are bulkier and more complex, but produce less vibration and capture images in a circular pattern from the outside in:&lt;/p&gt;
    &lt;p&gt;Early focal-plane shutters were large, gear-heavy, and used cloth curtains, limiting how compact cameras could be. By the late 1970s, manufacturers like Seiko refined shutters into smaller, lighter modules, making mass production and standardization possible.&lt;/p&gt;
    &lt;head rend="h3"&gt;From 1 Second to 1/1000 of a Second to Freeze Time&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Shutter Speeds: 1 sec. - 1/1000 sec., “B”.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Shutter speed determines how long the cameraâs shutter stays open, controlling how much light reaches the film. On this camera, you can choose speeds from 1 second (long exposure) to 1/1000 of a second (very fast).&lt;/p&gt;
    &lt;p&gt;Thereâs also a âBâ (Bulb) mode, which keeps the shutter open for as long as you hold down the shutter releaseâuseful for long exposures like night photography.&lt;/p&gt;
    &lt;p&gt;Slower shutter speeds (like 1s or Bulb) let in more light and can create motion blur, while faster speeds (like 1/1000s) freeze action and reduce brightness.&lt;/p&gt;
    &lt;p&gt;This range covers most situations for film photographers using ISO 100â400. For lower ISO (25â100), youâll need slower speeds or Bulb mode to avoid underexposure. With higher ISO (800â1600), even the fastest shutter speed may let in too much light, risking overexposure.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Viewfinder Recreates Reality&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewfinder: Fixed eye-level pentaprism, central split image with microprism collar and ground glass.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;When photography was first invented, images were captured in a dark room with a tiny holeâthis âcamera obscuraâ (Latin for âdark chamberâ) projected an inverted image onto a surface inside. Light travels in straight lines, so the scene outside appears upside down and reversed.&lt;/p&gt;
    &lt;p&gt;To let us see the image right-side up through the viewfinder, the camera uses a pentaprismâa five-sided prism that cleverly flips the light back to its original orientation. In this camera, the pentaprism sits at eye level, so what you see matches the scene in front of you.&lt;/p&gt;
    &lt;p&gt;Manual focusing aids help you get sharp images. The central split image is a circle in the middle of the viewfinder, divided in half; when the subject is in focus, the two halves align perfectly. Surrounding this is the microprism collarâif the image is out of focus, it appears grainy; when focused, the grain disappears.&lt;/p&gt;
    &lt;p&gt;All of this sits on ground glass, which has a matte texture created by tiny scratches. This diffuses the light, allowing you to see the image clearly from any angleâordinary glass wouldnât work, as it doesnât scatter light.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why the Scene Looks Smaller Through the Camera&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewfinder Magnification: 0.87x (id 50 mm, 00).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Viewfinder magnification tells you how large the scene appears when you look through the viewfinder compared to seeing it with your naked eye. A value of 0.87x means the viewfinder image is 13% smaller than life-size. For comparison, hereâs an original picture and another one scaled down by 13%:&lt;/p&gt;
    &lt;p&gt;This only affects what you see through the viewfinder, not the actual photo captured.&lt;/p&gt;
    &lt;p&gt;The parentheses specify the conditions for this specific magnification, itâs with a 50mm lens focused at infinity. Infinity might seem a bit abstract but basically it tells you that the lens is adjusted to receive from far away. The spec lists “00” instead of the infinity symbol, since not everyone could print it. This lets you compare magnification across different lenses.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why You See Less Than Whatâs Captured&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Viewfinder Visibility: 92%.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This specification tells you how much of the actual photo area you can see through the viewfinder. With 92% visibility, about 8% of the imageâmostly around the edgesâwonât be visible when you compose your shot.&lt;/p&gt;
    &lt;p&gt;Achieving 100% viewfinder visibility requires a larger, more precisely aligned prism and mirror, which adds weight and cost. Most SLRs offer 90â95% visibility to keep cameras lighter and more affordable.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Camera Helps You With Exposure&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Exposure Meter: TTL, Center weighted full aperture system employing one silicon blue photo cell, 3 steps exposure indicator with 3 LEDs.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The exposure meter uses a silicon blue photo cell to measure light. When photons hit the silicon surface, they knock electrons loose, creating a small electric current proportional to the light intensity. Based on the ISO and aperture settings, the meter provides feedback on whether your shot will be overexposed or underexposed.&lt;/p&gt;
    &lt;p&gt;Hereâs a visual example of underexposed and overexposed photos:&lt;/p&gt;
    &lt;p&gt;TTL (Through The Lens) means the meter measures the light that actually passes through the lens, so any lens changes or filters will affect the exposure reading.&lt;/p&gt;
    &lt;p&gt;Center weighted means the meter prioritizes light from the center of the frame over the edges.&lt;/p&gt;
    &lt;p&gt;A full aperture system keeps the viewfinder bright by measuring light at the lensâs maximum aperture. When you take a photo, the lens stops down to your chosen aperture only for the instant of exposure.&lt;/p&gt;
    &lt;p&gt;Unfortunately, the light meter on my camera doesnât work. But since exposure is a physical process, I can use a phone app to measure light and determine the right settings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Exposure Value: Turning Camera Settings Into Numbers&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Exposure Range: EV+2 (F/1.9, 1 sec.) to EV+18 (F/16, 1/1000 sec.) - ASA 100 F/1.9 lens.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is probably the most technical line, packed with symbols and acronyms.&lt;/p&gt;
    &lt;p&gt;As mentioned earlier, aperture is the part of the lens that controls how much light enters. Its unit is the f-stop, defined as:&lt;/p&gt;
    &lt;code&gt;f_number = f / d

where

f = focal length of the lens
d = diameter of the entrance pupil
&lt;/code&gt;
    &lt;p&gt;Because lenses have multiple glass elements that bend light, we use the concept or optical center to refer to the point where light can be treated as if it bent once, usually referring to the last glass element. The focal length is the distance (in mm) from the lensâs optical center to the film.&lt;/p&gt;
    &lt;p&gt;Aperture blades create a circular opening that limits how much light passes through. The entrance pupil is the perceived diameter (in mm) of this opening, as seen through the front glassâsince the glass can change how large the hole appears.&lt;/p&gt;
    &lt;p&gt;The larger the denominator in the f-number, the smaller the opening.&lt;/p&gt;
    &lt;p&gt;EV stands for Exposure Value. It represents a combination of aperture and shutter speed for a given ISO. EV 0â6 means a dark scene, EV 7â12 is normal daylight, and EV 12â18 is very bright.&lt;/p&gt;
    &lt;p&gt;To calculate EV for any settings, use:&lt;/p&gt;
    &lt;code&gt;EV_iso = log2((n^2) / t) - log2(iso/100)

or for ISO 100:

EV_100 = log2((n^2) / t)

where 

iso = ISO number of the film
n = f-number
t = shutter speed in seconds
&lt;/code&gt;
    &lt;p&gt;The light meter receives the EV from the sensor and compares it to this formula. If the measured value is higher, itâs overexposed; if lower, itâs underexposed.&lt;/p&gt;
    &lt;p&gt;Here, the spec means the light meter can measure correctly from EV 2 (f/1.9, 1 secâthe brightest setting) to EV 18 (f/16, 1/1000 secâthe darkest setting), using ISO 100 and a lens with a maximum aperture of f/1.9.&lt;/p&gt;
    &lt;p&gt;If you use higher ISO, the range shifts downwardâthe camera can meter darker scenes. This happens because, in the formula, higher ISO with the same settings lowers the EV.&lt;/p&gt;
    &lt;p&gt;For setting aperture manually, we can use the Sunny 16 rule, set your shutter speed as close as possible to your ISO, then choose the aperture based on lighting conditions:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;f/16 â bright sun&lt;/item&gt;
      &lt;item&gt;f/11 â sun with a few clouds&lt;/item&gt;
      &lt;item&gt;f/8 â mostly cloudy&lt;/item&gt;
      &lt;item&gt;f/5.6 â overcast or outdoor shade&lt;/item&gt;
      &lt;item&gt;f/4 â deep shade&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For other situations (like indoors), it’s best to use a light meter.&lt;/p&gt;
    &lt;head rend="h3"&gt;From ASA &amp;amp; DIN to ISO&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;ASA Range: 25-1600 (DIN 15-33) with safety lock.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Previously, film sensitivity was measured using two standards: ASA (American Standards Association), mainly used in the US, and DIN (Deutsches Institut fÃ¼r Normung), used in Europe. ASA uses a linear scale, while DIN is logarithmic.&lt;/p&gt;
    &lt;p&gt;In 1974, the International Organization for Standardization (ISO) unified these standards. Today, we refer to film sensitivity simply as ISOâlike ISO 100 or ISO 400. The higher the ISO number, the more sensitive the film is to light. Note that “ISO” here refers to the rating, not the actual ISO standard number.&lt;/p&gt;
    &lt;p&gt;Relevant ISO standards for film include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ISO 6: Black &amp;amp; white negatives&lt;/item&gt;
      &lt;item&gt;ISO 2240: Color negatives&lt;/item&gt;
      &lt;item&gt;ISO 5800: Slide (reversal) films&lt;/item&gt;
      &lt;item&gt;ISO 2720: How meters and film speed are linked (exposure index)&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Chinon CM-4 supports film speeds from ISO 25 (low sensitivity, for bright conditions) to ISO 1600 (high sensitivity, for low light).&lt;/p&gt;
    &lt;p&gt;The safety lock means you can’t accidentally change the ISO setting. On this camera, you must pull the dialâs edge and rotate it to set your desired ISO.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the Camera Syncs Light and Shutter&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Synchronization: Strobe sync at 1/60 sec.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In photography, “flash” usually refers to any burst of light used to illuminate a scene, but technically, a “strobe” is an electronic flash unit that emits a very short, intense pulse of light.&lt;/p&gt;
    &lt;p&gt;Synchronization ensures the flash fires precisely when the shutter is fully open. This is called X-sync, which is designed for electronic xenon flashes (named for the gas inside the bulb). Other sync types, like M-sync or FP-sync, were used for older flash technologies.&lt;/p&gt;
    &lt;p&gt;On this camera, the fastest shutter speed for safe flash use is 1/60 second. Using a faster speed will only light part of the image. Slower speeds (below 1/60 second) allow more ambient light into the photoâthis technique is called slow sync.&lt;/p&gt;
    &lt;head rend="h3"&gt;How the K-Mount Let Different Brands Share Lenses&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Lens Mount: Chinon Universal Bayonet Mount.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This piece allows the lens to mount to the camera. It looks something like this:&lt;/p&gt;
    &lt;p&gt;Basically, this is a Penta K-Mount, a standard that was adopted by Chinon and the rest of the market for 35mm SLR cameras, so you can use a bunch of lenses by a bunch of manufacturers.&lt;/p&gt;
    &lt;head rend="h3"&gt;How Film Moves, Counts, and Rewinds&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;Film Advance: Single stroke in an arc of 130Â° with 25Â° stand off.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;At the top right of the camera is a lever for advancing the film and cocking the shutter for the next shot.&lt;/p&gt;
    &lt;p&gt;To use it, swing the lever through a 130-degree arc. When at rest, the lever isnât lockedâit has 25 degrees of free movement, making it easier to grip and operate.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Film Counter: Automatically indicates number of exposures and resets to “S” when camera back is opened.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Next to the lever is a counter that shows how many shots youâve taken. Opening the camera back resets it to “S” (start); after the first advance, it moves to 0.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Film Rewind: Folding crank type.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Film rolls typically have 24 to 36 frames, but the camera doesnât track this. If you shoot past the end, you may overlap exposures.&lt;/p&gt;
    &lt;p&gt;When the roll is finished, rewind manually using the crank handle. It stays folded when not in use; lift it 90 degrees to rewind.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lenses&lt;/head&gt;
    &lt;p&gt;Letâs start with the obvious question: why do we need a lens? Weâve learned that taking pictures with film is a physical reaction between light and chemicals inside a cleverly built black box. So, whatâs the purpose of adding lenses?&lt;/p&gt;
    &lt;p&gt;Light can be described as rays for simplicity, but in reality, it behaves more like a wave. If you take a picture without a lens, the film receives light from all directions, overexposing the frame and creating a completely white image.&lt;/p&gt;
    &lt;p&gt;You might think, âJust use a tiny pinhole so only a small amount of light entersââlike the camera obscura mentioned earlier.&lt;/p&gt;
    &lt;p&gt;With a tiny pinhole (and nothing in between), everything is in focus, but you lose detail due to diffraction. Only a limited number of rays (or waves) enter, and you need to keep the shutter open longer. If you increase the pinhole size, the image becomes blurrier because rays overlap.&lt;/p&gt;
    &lt;p&gt;Using a curved glass (a lens) gathers much more light, bends it (refraction), and focuses it to a single point on the image plane, creating a sharp image.&lt;/p&gt;
    &lt;p&gt;This happens because the pinhole limits the light that enters, meaning it will loose some amount of information, while the lens bends it, mapping all light into a single point in the frame. But only one plane can be on focus with a lens because it can only bend the light from one distance perfectly at a time.&lt;/p&gt;
    &lt;head rend="h2"&gt;My Lens&lt;/head&gt;
    &lt;p&gt;By googling around, we can find that this is an Auto Chinon 50mm f/1.9&lt;/p&gt;
    &lt;p&gt;Let’s check the fron of the lens first&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Auto Chinon: This was one of the most mainstream lens series in the 1960sâ80s, paired with Chinon’s SLR cameras. “Auto” refers to the lens typeâit maintains full exposure while focusing and composing, allowing all light to reach the viewfinder. When you take a picture, it mechanically adjusts the aperture to your chosen setting. This is different from older “preset” lenses, where setting the f-stop made the viewfinder darker.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;50mm: As previously mentioned, the focal length is the distance from the lensâs optical center to the film. This is considered a “standard” or “normal” lens because it gives a field of view close to what the human eye naturally sees, making it very versatile.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;1:1.9: This is the maximum aperture of the lens. In modern notation, it should be expressed as f/1.9. For this lens, the aperture diameter is 26.3mm. The notation is written as a ratio, where 1 represents a unit of focal length, which in this lens is 50mm.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;49Ã: This is the diameter of the filter threadâthe size of the spiral at the front of the lens. It specifies what accessory size (like filters) you can attach. You can still use larger filters with a step-up or step-down adapter ring.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Made in Japan: You don’t expect me to explain this one, right?&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And finally let’s figure out what these crazy looking numbers around the lens mean.&lt;/p&gt;
    &lt;head rend="h2"&gt;Controlling the Actual Aperture&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;16 &amp;amp;mldr; 1.9&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the scale the lens has for aperture, each known as full stop. Each succesive number halves the amount of light entering.&lt;/p&gt;
    &lt;p&gt;These numbers are not evenly spaced because depends on the area of the circle, so it involves the radius, meaning the diameter divided by 2, which ends up in the f-stop being multiplied by the square root of 2 to define its full stop.&lt;/p&gt;
    &lt;head rend="h2"&gt;How Far Can You Focus&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;ft m &amp;amp;mldr;&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is the focus distance scale, the green line will tell you (on meters and feets) at what distance your lense is focused. As previously mentioned the infinity mark means very far objects, which in practice for a 50mm lens is around 30-50 meters.&lt;/p&gt;
    &lt;head rend="h2"&gt;Depth of Field Helper&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;16 &amp;amp;mldr; | &amp;amp;mldr; 16&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is known as the DOF or Depth Of Field scale. The line at the middle specifies the focus point, meaning that objects at exactly that will be perfectly sharp. Because of optics, objects a bit in front or behind will also look sharp, this extra sharpness zone is the DOF.&lt;/p&gt;
    &lt;p&gt;In essence, this scale shows: “When you set the aperture to f/X, objects between Y and Z distances will appear sharp”.&lt;/p&gt;
    &lt;head rend="h1"&gt;Some of my Pictures&lt;/head&gt;
    &lt;p&gt;Seems like I loaded the film incorrectly and nothing was on them, so I hate my life right now. Let’s skip this part then.&lt;/p&gt;
    &lt;head rend="h1"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;By exploring my cameraâs specs, Iâve learned how cameras work and gained insight into their evolution. Itâs amazing how clever chemistry and engineering made it possible for anyone to capture moments, and in a time where everyone feels that was a long time ago.&lt;/p&gt;
    &lt;p&gt;If youâve read this far, I hope youâre inspired to stay curious, explore new topics, google things around, use chatgpt as a mentor, and appreciate what weâve achieved as humans. I may not become a photographer, but the process of learning and writing this blog has been incredibly rewarding.&lt;/p&gt;
    &lt;p&gt;I havenât done anything impressive with my new camera yet, but at least I know my challenge is creativity, not technical knowledge.&lt;/p&gt;
    &lt;p&gt;To sum it up: The real lesson is that specs are a roadmap, whether itâs cameras, computers, or chemistry, manuals are underrated teachers.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.mano.lol/posts/film/"/><published>2025-10-13T18:45:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45572613</id><title>AWS Service Availability Updates</title><updated>2025-10-13T21:32:02.188436+00:00</updated><content>&lt;doc fingerprint="e29f97144beedc4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;AWS Service Availability Updates&lt;/head&gt;
    &lt;p&gt;After careful consideration, we’re announcing availability changes for a select group of AWS services and features. These changes fall into three lifecycle categories:&lt;lb/&gt; Services and Capabilities moving to Maintenance&lt;lb/&gt; Services moving to maintenance will no longer be accessible to new customers starting Nov 7, 2025. Current customers can continue using the service or feature while exploring alternative solutions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Amazon Cloud Directory&lt;/item&gt;
      &lt;item&gt;Amazon CodeCatalyst&lt;/item&gt;
      &lt;item&gt;Amazon CodeGuru Reviewer&lt;/item&gt;
      &lt;item&gt;Amazon Fraud Detector&lt;/item&gt;
      &lt;item&gt;Amazon Glacier&lt;/item&gt;
      &lt;item&gt;Amazon S3 Object Lambda&lt;/item&gt;
      &lt;item&gt;Amazon Workspaces Web Access Client for PCoIP (STXHD)&lt;/item&gt;
      &lt;item&gt;AWS Application Discovery Service&lt;/item&gt;
      &lt;item&gt;AWS HealthOmics - Variant and Annotation Store&lt;/item&gt;
      &lt;item&gt;AWS IoT SiteWise Edge Data Processing Pack&lt;/item&gt;
      &lt;item&gt;AWS IoT SiteWise Monitor&lt;/item&gt;
      &lt;item&gt;AWS Mainframe Modernization Service&lt;/item&gt;
      &lt;item&gt;AWS Migration Hub&lt;/item&gt;
      &lt;item&gt;AWS Snowball Edge Compute Optimized&lt;/item&gt;
      &lt;item&gt;AWS Snowball Edge Storage Optimized&lt;/item&gt;
      &lt;item&gt;AWS Systems Manager - Change Manager&lt;/item&gt;
      &lt;item&gt;AWS Systems Manager - Incident Manager&lt;/item&gt;
      &lt;item&gt;AWS Thinkbox Deadline 10&lt;/item&gt;
      &lt;item&gt;.NET Modernization Tools&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt; Services Entering Sunset&lt;lb/&gt; The following services are entering sunset, and we are announcing the date upon which we will end operations and support of the service. Customers using these services should click on the links below to understand the sunset timeline (typically 12 months), and begin planning migration to alternatives as recommended in the updated service web pages and documentation.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; Services Reaching End of Support&lt;lb/&gt; The following services have reached end of support and are no longer available as of October 7, 2025.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AWS Mainframe Modernization App Testing&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt; For customers affected by these changes, we've prepared comprehensive migration guides and our support teams are ready to assist with your transition. Visit AWS Product Lifecycle Page to learn more. or contact AWS Support.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://aws.amazon.com/about-aws/whats-new/2025/10/aws-service-availability/"/><published>2025-10-13T19:52:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45573025</id><title>Don't Be a Sucker (1943) [video]</title><updated>2025-10-13T21:32:01.416713+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=vGAqYNFQdZ4"/><published>2025-10-13T20:31:47+00:00</published></entry></feed>