<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-25T14:41:30.020133+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45361268</id><title>Show HN: Dayflow – A git log for your day</title><updated>2025-09-25T14:41:37.063868+00:00</updated><content>&lt;doc fingerprint="6ed6256e19be11b7"&gt;
  &lt;main&gt;
    &lt;p&gt;Turns your screen activity into a clean timeline with AI summaries and distraction highlights.&lt;/p&gt;
    &lt;p&gt;Quickstart • Why I built Dayflow • Features • How it works • Installation • Data &amp;amp; Privacy • Debug &amp;amp; Developer Tools • Auto‑updates • Contributing&lt;/p&gt;
    &lt;p&gt;Dayflow is a native macOS app (SwiftUI) that records your screen at 1 FPS, analyzes it every 15 minutes with AI, and generates a timeline of your activities with summaries. It's lightweight (25MB app size) and uses ~100MB of RAM and &amp;lt;1% cpu.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Privacy‑minded by design: You choose your AI provider. Use Gemini (bring your own API key) or local models (Ollama / LM Studio). See Data &amp;amp; Privacy for details.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;I built Dayflow after realizing that my calendar wasn't the source of truth for how I actually spent my time. My screen was. I wanted a calm, trustworthy timeline that let me see my workday without turning into yet another dashboard I had to maintain.&lt;/p&gt;
    &lt;p&gt;Dayflow stands for ownership and privacy by default. You control the data, you choose the AI provider, and you can keep everything local if that's what makes you comfortable. It's MIT licensed and fully open source because anything that watches your screen all day should be completely transparent about what it does with that information. The app should feel like a quiet assistant: respectful of your attention, honest about what it captures, and easy to shut off.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic timeline of your day with concise summaries.&lt;/item&gt;
      &lt;item&gt;1 FPS recording - minimal CPU/storage impact.&lt;/item&gt;
      &lt;item&gt;15-minute analysis intervals for timely updates.&lt;/item&gt;
      &lt;item&gt;Watch timelapses of your day.&lt;/item&gt;
      &lt;item&gt;Auto storage cleanup - removes old recordings after 3 days.&lt;/item&gt;
      &lt;item&gt;Distraction highlights to see what pulled you off‑task.&lt;/item&gt;
      &lt;item&gt;Native UX built with SwiftUI.&lt;/item&gt;
      &lt;item&gt;Auto‑updates with Sparkle (daily check + background download).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Infinitely customizable dashboard — ask any question about your workday, pipe the answers into tiles you arrange yourself, and track trends over time.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Daily journal — review the highlights Dayflow captured, reflect with guided prompts, and drop screenshots or notes alongside your generated timeline.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Capture — Records screen at 1 FPS in 15-second chunks.&lt;/item&gt;
      &lt;item&gt;Analyze — Every 15 minutes, sends recent footage to AI.&lt;/item&gt;
      &lt;item&gt;Generate — AI creates timeline cards with activity summaries.&lt;/item&gt;
      &lt;item&gt;Display — Shows your day as a visual timeline.&lt;/item&gt;
      &lt;item&gt;Cleanup — Auto-deletes recordings older than 3 days.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The efficiency of your timeline generation depends on your chosen AI provider:&lt;/p&gt;
    &lt;code&gt;flowchart LR
    subgraph Gemini["Gemini Flow: 2 LLM Calls"]
        direction LR
        GV[Video] --&amp;gt; GU[Upload + Transcribe&amp;lt;br/&amp;gt;1 LLM call] --&amp;gt; GC[Generate Cards&amp;lt;br/&amp;gt;1 LLM call] --&amp;gt; GD[Done]
    end

    subgraph Local["Local Flow: 33+ LLM Calls"]
        direction LR
        LV[Video] --&amp;gt; LE[Extract 30 frames] --&amp;gt; LD[30 descriptions&amp;lt;br/&amp;gt;30 LLM calls] --&amp;gt; LM[Merge&amp;lt;br/&amp;gt;1 call] --&amp;gt; LT[Title&amp;lt;br/&amp;gt;1 call] --&amp;gt; LC[Merge Check&amp;lt;br/&amp;gt;1 call] --&amp;gt; LMC[Merge Cards&amp;lt;br/&amp;gt;1 call] --&amp;gt; LD2[Done]
    end

    %% Styling
    classDef geminiFlow fill:#e8f5e8,stroke:#4caf50,stroke-width:2px
    classDef localFlow fill:#fff8e1,stroke:#ff9800,stroke-width:2px
    classDef geminiStep fill:#4caf50,color:#fff
    classDef localStep fill:#ff9800,color:#fff
    classDef processing fill:#f5f5f5,stroke:#666
    classDef result fill:#e3f2fd,stroke:#1976d2

    class Gemini geminiFlow
    class Local localFlow
    class GU,GC geminiStep
    class LD,LM,LT,LC,LMC localStep
    class GV,LV,LE processing
    class GD,LD2 result
&lt;/code&gt;
    &lt;p&gt;Gemini leverages native video understanding for direct analysis, while Local models reconstruct understanding from individual frame descriptions - resulting in dramatically different processing complexity.&lt;/p&gt;
    &lt;p&gt;Download (end users)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Grab the latest &lt;code&gt;Dayflow.dmg&lt;/code&gt;from GitHub Releases.&lt;/item&gt;
      &lt;item&gt;Open the app; grant Screen &amp;amp; System Audio Recording when prompted:&lt;lb/&gt;macOS → System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording → enable Dayflow.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Build from source (developers)&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Install Xcode 15+ and open &lt;code&gt;Dayflow.xcodeproj&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Run the &lt;code&gt;Dayflow&lt;/code&gt;scheme on macOS 13+.&lt;/item&gt;
      &lt;item&gt;In your Run scheme, add your &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;under Arguments &amp;gt; Environment Variables (if using Gemini).&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;macOS 13.0+&lt;/item&gt;
      &lt;item&gt;Xcode 15+&lt;/item&gt;
      &lt;item&gt;A Gemini API key (if using Gemini): https://ai.google.dev/gemini-api/docs/api-key&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download &lt;code&gt;Dayflow.dmg&lt;/code&gt;and drag Dayflow into Applications.&lt;/item&gt;
      &lt;item&gt;Launch and grant the Screen &amp;amp; System Audio Recording permission.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;git clone https://github.com/JerryZLiu/Dayflow.git
cd Dayflow
open Dayflow.xcodeproj
# In Xcode: select the Dayflow target, configure signing if needed, then Run.&lt;/code&gt;
    &lt;p&gt;This section explains what Dayflow stores locally, what leaves your machine, and how provider choices affect privacy.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;App support folder: &lt;code&gt;~/Library/Application Support/Dayflow/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recordings (video chunks): &lt;code&gt;~/Library/Application Support/Dayflow/recordings/&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Local database: &lt;code&gt;~/Library/Application Support/Dayflow/chunks.sqlite&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Recording details: 1 FPS capture, analyzed every 15 minutes, 3-day retention&lt;/item&gt;
      &lt;item&gt;Purge / reset tip: Quit Dayflow. Then delete the entire &lt;code&gt;~/Library/Application Support/Dayflow/&lt;/code&gt;folder to remove recordings and analysis artifacts. Relaunch to start fresh.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;
      &lt;p&gt;These paths are created by the app at first run. If you package Dayflow differently or run in a sandbox, paths may vary slightly.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Gemini (cloud, BYO key) — Dayflow sends batch payloads to Google’s Gemini API for analysis.&lt;/item&gt;
      &lt;item&gt;Local models (Ollama / LM Studio) — Processing stays on‑device; Dayflow talks to a local server you run.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Short answer: There is a way to prevent Google from training on your data. If you enable Cloud Billing on at least one Gemini API project, Google treats all of your Gemini API and Google AI Studio usage under the “Paid Services” data‑use rules — even when you’re using unpaid/free quota. Under Paid Services, Google does not use your prompts/responses to improve Google products/models. &lt;list rend="ul"&gt;&lt;item&gt;Terms: “When you activate a Cloud Billing account, all use of Gemini API and Google AI Studio is a ‘Paid Service’ with respect to how Google Uses Your Data, even when using Services that are offered free of charge.” (Gemini API Additional Terms)&lt;/item&gt;&lt;item&gt;Abuse monitoring: even under Paid Services, Google logs prompts/responses for a limited period for policy enforcement and legal compliance. (Same Terms)&lt;/item&gt;&lt;item&gt;EEA/UK/Switzerland: the Paid‑style data handling applies by default to all Services (including AI Studio and unpaid quota) even without billing. (Same Terms)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A couple useful nuances (from docs + forum clarifications):&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Studio is still free to use; enabling billing changes data handling, not whether Studio charges you. (Pricing page)&lt;/item&gt;
      &lt;item&gt;UI “Plan: Paid” check: In AI Studio → API keys, you’ll typically see “Plan: Paid” once billing is enabled on any linked project (UI may evolve).&lt;/item&gt;
      &lt;item&gt;Free workaround: “Make one project paid, keep using a free key elsewhere to get the best of both worlds.” The Terms imply account‑level coverage once any billing account is activated, but the Apps nuance above may limit this in specific UI contexts. Treat this as an interpretation, not legal advice.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Privacy: With Ollama/LM Studio, prompts and model inference run on your machine. LM Studio documents full offline operation once models are downloaded.&lt;/item&gt;
      &lt;item&gt;Quality/latency: Local open models are improving but can underperform cloud models on complex summarization.&lt;/item&gt;
      &lt;item&gt;Power/battery: Local inference is GPU‑heavy on Apple Silicon and will drain battery faster; prefer plugged‑in sessions for long captures.&lt;/item&gt;
      &lt;item&gt;Future: We may explore fine‑tuning or distilling a local model for better timeline summaries.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;References:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;LM Studio offline: https://lmstudio.ai/docs/app/offline&lt;/item&gt;
      &lt;item&gt;Ollama GPU acceleration (Metal on Apple): https://github.com/ollama/ollama/blob/main/docs/gpu.md&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To record your screen, Dayflow requires the Screen &amp;amp; System Audio Recording permission. Review or change later at:&lt;lb/&gt; System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording.&lt;lb/&gt; Apple’s docs: https://support.apple.com/guide/mac-help/control-access-screen-system-audio-recording-mchld6aa7d23/mac&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;AI Provider &lt;list rend="ul"&gt;&lt;item&gt;Choose Gemini (set &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;) or Local (Ollama/LM Studio endpoint).&lt;/item&gt;&lt;item&gt;For Gemini keys: https://ai.google.dev/gemini-api/docs/api-key&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Choose Gemini (set &lt;/item&gt;
      &lt;item&gt;Capture settings &lt;list rend="ul"&gt;&lt;item&gt;Start/stop capture from the main UI. Use Debug to verify batch contents.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Data locations &lt;list rend="ul"&gt;&lt;item&gt;See Data &amp;amp; Privacy for exact paths and a purge tip.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can click the Dayflow icon in the menu bar and view the saved recordings&lt;/p&gt;
    &lt;p&gt;Dayflow integrates Sparkle via Swift Package Manager and shows the current version + a “Check for updates” action. By default, the updater auto‑checks daily and auto‑downloads updates.&lt;/p&gt;
    &lt;code&gt;Dayflow/
├─ Dayflow/                 # SwiftUI app sources (timeline UI, debug UI, capture &amp;amp; analysis pipeline)
├─ docs/                    # Appcast and documentation assets (screenshots, videos)
├─ scripts/                 # Release automation (DMG, notarization, appcast, Sparkle signing, one-button release)
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Screen capture is blank or fails&lt;lb/&gt;Check System Settings → Privacy &amp;amp; Security → Screen &amp;amp; System Audio Recording and ensure Dayflow is enabled.&lt;/item&gt;
      &lt;item&gt;API errors&lt;lb/&gt;Go into settings and verify your&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;and network connectivity.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;V1 of the Dashboard (track answers to custom questions)&lt;/item&gt;
      &lt;item&gt;V1 of the daily journal&lt;/item&gt;
      &lt;item&gt;Fine tuning a small VLM&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;PRs welcome! If you plan a larger change, please open an issue first to discuss scope and approach.&lt;/p&gt;
    &lt;p&gt;Licensed under the MIT License. See LICENSE for the full text. Software is provided “AS IS”, without warranty of any kind.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sparkle for battle‑tested macOS updates.&lt;/item&gt;
      &lt;item&gt;Google AI Gemini API for analysis.&lt;/item&gt;
      &lt;item&gt;Ollama and LM Studio for local model support.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/JerryZLiu/Dayflow"/><published>2025-09-24T14:53:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45362023</id><title>Python on the Edge: Fast, sandboxed, and powered by WebAssembly</title><updated>2025-09-25T14:41:36.351680+00:00</updated><content>&lt;doc fingerprint="87ab2dfdccf438d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Python on the Edge: Fast, sandboxed, and powered by WebAssembly&lt;/head&gt;
    &lt;p&gt;We are excited to announce full Python support in Wasmer Edge (Beta)&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;With AI workloads on the rise, the demand for Python support on WebAssembly on the Edge has grown rapidly.&lt;/p&gt;
    &lt;p&gt;However, bringing Python to WebAssembly isn't trivial as it means supporting native modules like &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, and &lt;code&gt;pydantic&lt;/code&gt;.&amp;#13;
While projects like &lt;code&gt;pyodide&lt;/code&gt; made strides in running Python in the browser via WebAssembly, their trade-offs don't fully fit server-side needs.&lt;/p&gt;
    &lt;p&gt;After months of hard work, today we're thrilled to announce full Python support in Wasmer Edge (Beta) powered by WebAssembly and WASIX.&lt;/p&gt;
    &lt;p&gt;Now you can run FastAPI, Streamlit, Django, LangChain, MCP servers and more directly on Wasmer and Wasmer Edge! To accomplish it we had to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Add support for dynamic linking (&lt;code&gt;dlopen&lt;/code&gt;/&lt;code&gt;dlsym&lt;/code&gt;) into WASIX&lt;/item&gt;
      &lt;item&gt;Add &lt;code&gt;libffi&lt;/code&gt;support (so Python libraries using&lt;code&gt;ctypes&lt;/code&gt;could be supported)&lt;/item&gt;
      &lt;item&gt;Polish Sockets and threading support in WASIX&lt;/item&gt;
      &lt;item&gt;Release our own Python Package Index with many of the most popular Python Native libraries compiled to WASIX&lt;/item&gt;
      &lt;item&gt;Create our own alternative to Heroku Buildpacks / Nixpacks / Railpack / Devbox to automatically detect a project type from its source code and deploy it (including running with Wasmer or deploying to Wasmer Edge!). Updates will be shared soon!&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How fast is it?&lt;/head&gt;
    &lt;p&gt;This Python release is much faster than any of the other Python releases we did in the past.&lt;/p&gt;
    &lt;p&gt;It is fast. Insa…natively fast (it's even faster than our py2wasm project!)&lt;/p&gt;
    &lt;code&gt;$ wasmer run python/python@=0.2.0 --dir=. -- pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.562538&amp;#13;
This machine benchmarks at 88882.9 pystones/second&amp;#13;
$ wasmer run python/python --dir=. -- pystone.py # Note: first run may take time&amp;#13;
Pystone(1.1) time for 50000 passes = 0.093556&amp;#13;
This machine benchmarks at 534439 pystones/second&amp;#13;
$ python3 pystone.py&amp;#13;
Pystone(1.1) time for 50000 passes = 0.0827736&amp;#13;
This machine benchmarks at 604057 pystones/second
&lt;/code&gt;
    &lt;p&gt;That's 6x faster, and nearly indistinguishable from native Python performance… quite good, considering that your Python apps can now run fully sandboxed anywhere!&lt;/p&gt;
    &lt;p&gt;Note: the first time you run Python, it will take a few minutes to compile. We are working to improve this so no time will be spent on compilation locally.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;🚀 Even faster performance coming soon: we are trialing an optimization technique that will boost Python performance in Wasm to 95% of native Python speed. This is already powering our PHP server in production. Result: Near-native Python performance, fully sandboxed. Stay tuned!&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;What it can run&lt;/head&gt;
    &lt;p&gt;Now, you can run any kind of Python API server, powered by &lt;code&gt;fastapi&lt;/code&gt;, &lt;code&gt;django&lt;/code&gt;, &lt;code&gt;flask&lt;/code&gt;, or &lt;code&gt;starlette&lt;/code&gt;, connected to a MySQL database automatically when needed (FastAPI template, Django template).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;fastapi&lt;/code&gt; with websockets (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;mcp&lt;/code&gt; servers (deploy using our MCP template, demo).&lt;/p&gt;
    &lt;p&gt;You can run image processors like &lt;code&gt;pillow&lt;/code&gt;  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;ffmpeg&lt;/code&gt; inside Python (example repo, demo).&lt;/p&gt;
    &lt;p&gt;You can run &lt;code&gt;streamlit&lt;/code&gt; and &lt;code&gt;langchain&lt;/code&gt; (deploy using our LangChain template, demo).&lt;/p&gt;
    &lt;p&gt;You can even run &lt;code&gt;pypandoc&lt;/code&gt;!  (example repo, demo).&lt;/p&gt;
    &lt;p&gt;Soon, we'll have full support for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;code&gt;curl_cffi&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;polars&lt;/code&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;code&gt;gevent&lt;/code&gt;/&lt;code&gt;greenlet&lt;/code&gt;(more on this soon!)&lt;/item&gt;
      &lt;item&gt;
        &lt;code&gt;Pytorch&lt;/code&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Wasmer VS alternatives&lt;/head&gt;
    &lt;p&gt;Python on Wasmer Edge is just launching, but it's already worth asking: how does it stack up existing solutions?&lt;/p&gt;
    &lt;head rend="h3"&gt;Quick Comparison&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Feature / Platform&lt;/cell&gt;
        &lt;cell role="head"&gt;Wasmer Edge&lt;/cell&gt;
        &lt;cell role="head"&gt;Cloudflare&lt;/cell&gt;
        &lt;cell role="head"&gt;AWS Lambda&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Native modules (&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;pandas&lt;/code&gt;, etc.)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported*&lt;/cell&gt;
        &lt;cell&gt;❌ Limited (no &lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Full support&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multithreading &amp;amp; multiprocessing (&lt;code&gt;ffmpeg&lt;/code&gt;, &lt;code&gt;pandoc&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ASGI / WSGI frameworks (&lt;code&gt;uvicorn&lt;/code&gt;, &lt;code&gt;daphne&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ Patched / limited&lt;/cell&gt;
        &lt;cell&gt;⚠️ Needs wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;WebSockets (&lt;code&gt;streamlit&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Yes&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
        &lt;cell&gt;❌ No&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Raw sockets (&lt;code&gt;libcurl&lt;/code&gt;)&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
        &lt;cell&gt;❌ JS &lt;code&gt;fetch&lt;/code&gt; only&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Multiple Python versions&lt;/cell&gt;
        &lt;cell&gt;✅ In Roadmap (3.12, 3.14…)&lt;/cell&gt;
        &lt;cell&gt;❌ Tied to bundled runtime&lt;/cell&gt;
        &lt;cell&gt;✅ Supported&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Cold starts&lt;/cell&gt;
        &lt;cell&gt;⚡ Extremely fast&lt;/cell&gt;
        &lt;cell&gt;⏳ Medium (V8 isolates)&lt;/cell&gt;
        &lt;cell&gt;⏳ Slow&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Code changes required&lt;/cell&gt;
        &lt;cell&gt;✅ None&lt;/cell&gt;
        &lt;cell&gt;⚠️ Some&lt;/cell&gt;
        &lt;cell&gt;⚠️ Wrappers&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Pricing&lt;/cell&gt;
        &lt;cell&gt;💰 Affordable&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
        &lt;cell&gt;💰 Higher&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Cloudflare Workers (Python) / Pyodide&lt;/head&gt;
    &lt;quote&gt;&lt;p&gt;ℹ️ Most of the demos that we showcased on this article, are not runnable inside of Cloudflare:&lt;/p&gt;&lt;code&gt;ffmpeg&lt;/code&gt;,&lt;code&gt;streamlit&lt;/code&gt;,&lt;code&gt;pypandoc&lt;/code&gt;.&lt;/quote&gt;
    &lt;p&gt;Cloudflare launched Python support ~18 months ago, by using Pyodide inside workerd, their JavaScript-based Workers runtime.&lt;/p&gt;
    &lt;p&gt;While great for browser-like environments, Pyodide has trade-offs that make it less suitable server-side. Here are the limitations when running Python in Cloudflare:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ No support for &lt;code&gt;uvloop&lt;/code&gt;,&lt;code&gt;uvicorn&lt;/code&gt;, or similar event-native frameworks (JS event loop patches break compatibility with native).&lt;/item&gt;
      &lt;item&gt;❌ No pthreads or multiprocessing support, you can't call subprocesses like &lt;code&gt;ffmpeg&lt;/code&gt;or&lt;code&gt;pypandoc&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;❌ No raw HTTP client sockets (HTTP clients are patched to use JS &lt;code&gt;fetch&lt;/code&gt;, no&lt;code&gt;libcurl&lt;/code&gt;available).&lt;/item&gt;
      &lt;item&gt;❌ Limited to a bundled Python version and package set.&lt;/item&gt;
      &lt;item&gt;⏳ Cold starts slower due to V8 isolate warmup.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limitations? Cloudflare relies on Pyodide: great in-browser execution, but server-side it implies no sockets, threads, or multiprocessing. The result: convenient for lightweight browser use, but might not be the best fit for real Python workloads on the server.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge runs real Python on WASIX unmodified, so everything "just works", with near-native speed and fast cold starts.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Amazon Lambda&lt;/head&gt;
    &lt;p&gt;AWS Lambda doesn't natively run unmodified Python apps:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;❌ You need adapters (such as https://github.com/slank/awsgi or https://github.com/Kludex/mangum) for running your WSGI sites.&lt;/item&gt;
      &lt;item&gt;❌ WebSockets are unsupported.&lt;/item&gt;
      &lt;item&gt;⚠️ Setup is complex, adapters are often unmaintained.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Why the limits? AWS Lambda requires you to use their HTTP lambda handler, which can cause incompatibility into your own HTTP servers. Also, because their lambda handlers are HTTP-based, there's no easy support for WebSockets.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In contrast, Wasmer Edge supports any Python HTTP servers without requiring any code adaptation from your side.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h3"&gt;Why Wasmer Edge Stands Out&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Closer to native Python than Pyodide (no JS involvement at all).&lt;/item&gt;
      &lt;item&gt;Faster cold starts and more compatibility than Cloudflare's Workers.&lt;/item&gt;
      &lt;item&gt;More compatible than AWS Lambda (no wrappers/adapters).&lt;/item&gt;
      &lt;item&gt;More affordable across the board.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;🐍 It's Showtime!&lt;/head&gt;
    &lt;p&gt;Python support in Wasmer and Wasmer Edge is already available and ready to use. We have set up many Python templates to help you get started in no time.&lt;/p&gt;
    &lt;p&gt;https://wasmer.io/templates?language=python&lt;/p&gt;
    &lt;p&gt;To make things even better, we are working on a MCP server for Wasmer, so you will be able to plug Wasmer into ChatGPT or Anthropic and have your websites deploying from your vibe-coded projects. Stay tuned!&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;⚠️ Python in Wasmer Edge is still in Beta, so expect some rough edges if your project doesn't work out of the box… if you encounter any issues, please report them so we can work on enabling your workloads on Wasmer Edge.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;Create your first MCP Server in Wasmer&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Go to https://wasmer.io/templates/mcp-chatgpt-starter?intent=at_vRxJIdtPCbKe&lt;/item&gt;
      &lt;item&gt;Connect your Github account&lt;/item&gt;
      &lt;item&gt;Create a git repo from the template&lt;/item&gt;
      &lt;item&gt;Deploy and enjoy!&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/python-mcp-chatgpt-starter&lt;/p&gt;
    &lt;head rend="h2"&gt;Create your first Django app&lt;/head&gt;
    &lt;p&gt;We have set up a template for using Django + Uvicorn in Wasmer Edge.&lt;/p&gt;
    &lt;p&gt;You can start using it very easily, just click Deploy: https://wasmer.io/templates/django-starter?intent=at_WK0DIkt3CeKX&lt;/p&gt;
    &lt;p&gt;Deploying a Django app will create a MySQL DB for you in Wasmer Edge (Postgres support is coming soon), run migrations and prepare everything to run your website seamlessly.&lt;/p&gt;
    &lt;p&gt;Note: source code available here: https://github.com/wasmer-examples/django-wasmer-starter&lt;/p&gt;
    &lt;p&gt;Ready to deploy your first Python app on Wasmer Edge?&lt;/p&gt;
    &lt;p&gt;Here are the best places to begin:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;🚀 Starter Templates → Browse Python templates&lt;/item&gt;
      &lt;item&gt;📖 Docs &amp;amp; Examples → Wasmer GitHub&lt;/item&gt;
      &lt;item&gt;💬 Community Support → Join our Discord&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;👉 Deploy your first Python app now&lt;/p&gt;
    &lt;p&gt;With WebAssembly and Wasmer, Python is now portable, sandboxed, and running at near-native speeds. Ready for AI workloads, APIs, and anything you can imagine at the edge.&lt;lb/&gt; The sky is the limit ❤️.&lt;/p&gt;
    &lt;head rend="h5"&gt;About the Author&lt;/head&gt;
    &lt;p&gt;Syrus Akbary is an enterpreneur and programmer. Specifically known for his contributions to the field of WebAssembly. He is the Founder and CEO of Wasmer, an innovative company that focuses on creating developer tools and infrastructure for running Wasm&lt;/p&gt;
    &lt;p&gt;Founder &amp;amp; CEO&lt;/p&gt;
    &lt;p&gt;How fast is it?&lt;/p&gt;
    &lt;p&gt;What it can run&lt;/p&gt;
    &lt;p&gt;Wasmer VS alternatives&lt;/p&gt;
    &lt;p&gt;Quick Comparison&lt;/p&gt;
    &lt;p&gt;Cloudflare Workers (Python) / Pyodide&lt;/p&gt;
    &lt;p&gt;Amazon Lambda&lt;/p&gt;
    &lt;p&gt;Why Wasmer Edge Stands Out&lt;/p&gt;
    &lt;p&gt;🐍 It's Showtime!&lt;/p&gt;
    &lt;p&gt;Create your first MCP Server in Wasmer&lt;/p&gt;
    &lt;p&gt;Create your first Django app&lt;/p&gt;
    &lt;p&gt;Deploy your first Python site in seconds with our managed cloud solution.&lt;/p&gt;
    &lt;head rend="h5"&gt;Read more&lt;/head&gt;
    &lt;p&gt;wasmerwasmer edgerustprojectsedgeweb scraper&lt;/p&gt;
    &lt;head rend="h6"&gt;Build a Web Scraper in Rust and Deploy to Wasmer Edge&lt;/head&gt;
    &lt;p&gt;RudraAugust 14, 2023&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://wasmer.io/posts/python-on-the-edge-powered-by-webassembly"/><published>2025-09-24T15:48:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45362206</id><title>SedonaDB: A new geospatial DataFrame library written in Rust</title><updated>2025-09-25T14:41:36.198237+00:00</updated><content>&lt;doc fingerprint="3bdb989c4036eb8a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing SedonaDB: A single-node analytical database engine with geospatial as a first-class citizen&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community is excited to announce the initial release of SedonaDB! ð&lt;/p&gt;
    &lt;p&gt;SedonaDB is the first open-source, single-node analytical database engine that treats spatial data as a first-class citizen. It is developed as a subproject of Apache Sedona.&lt;/p&gt;
    &lt;p&gt;Apache Sedona powers large-scale geospatial processing on distributed engines like Spark (SedonaSpark), Flink (SedonaFlink), and Snowflake (SedonaSnow). SedonaDB extends the Sedona ecosystem with a single-node engine optimized for small-to-medium data analytics, delivering the simplicity and speed that distributed systems often cannot.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ What is SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Written in Rust, SedonaDB is lightweight, blazing fast, and spatial-native. Out of the box, it provides:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ðºï¸ Full support for spatial types, joins, CRS (coordinate reference systems), and functions on top of industry-standard query operations.&lt;/item&gt;
      &lt;item&gt;â¡ Query optimizations, indexing, and data pruning features under the hood that make spatial operations just work with high performance.&lt;/item&gt;
      &lt;item&gt;ð Pythonic and SQL interfaces familiar to developers, plus APIs for R and Rust.&lt;/item&gt;
      &lt;item&gt;âï¸ Flexibility to run in single-machine environments on local files or data lakes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;SedonaDB utilizes Apache Arrow and Apache DataFusion, providing everything you need from a modern, vectorized query engine. What sets it apart is the ability to process spatial workloads natively, without extensions or plugins. Installation is straightforward, and SedonaDB integrates easily into both local development and cloud pipelines, offering a consistent experience across environments.&lt;/p&gt;
    &lt;p&gt;The initial release of SedonaDB provides a comprehensive suite of geometric vector operations and seamlessly integrates with GeoArrow, GeoParquet, and GeoPandas. Future versions will support all popular spatial functions, including functions for raster data.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð SedonaDB quickstart example¶&lt;/head&gt;
    &lt;p&gt;Start by installing SedonaDB:&lt;/p&gt;
    &lt;code&gt;pip install "apache-sedona[db]"
&lt;/code&gt;
    &lt;p&gt;Now instantiate the connection:&lt;/p&gt;
    &lt;code&gt;import sedona.db

sd = sedona.db.connect()
&lt;/code&gt;
    &lt;p&gt;Let's perform a spatial join using SedonaDB.&lt;/p&gt;
    &lt;p&gt;Suppose you have a &lt;code&gt;cities&lt;/code&gt; table with latitude and longitude points representing the center of each city, and a &lt;code&gt;countries&lt;/code&gt; table with a column containing a polygon of the country's geographic boundaries.&lt;/p&gt;
    &lt;p&gt;Here are a few rows from the &lt;code&gt;cities&lt;/code&gt; table:&lt;/p&gt;
    &lt;code&gt;ââââââââââââââââ¬ââââââââââââââââââââââââââââââââ
â     name     â            geometry           â
â   utf8view   â      geometry &amp;lt;epsg:4326&amp;gt;     â
ââââââââââââââââªââââââââââââââââââââââââââââââââ¡
â Vatican City â POINT(12.4533865 41.9032822)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â San Marino   â POINT(12.4417702 43.9360958)  â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
â Vaduz        â POINT(9.5166695 47.1337238)   â
ââââââââââââââââ¼ââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;And here are a few rows from the countries table:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââââââââââââââââââââââââââââââââ
â             name            â   continent   â                      geometry                      â
â           utf8view          â    utf8view   â                geometry &amp;lt;epsg:4326&amp;gt;                â
âââââââââââââââââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââââââââââââââââââââââââââââââââ¡
â Fiji                        â Oceania       â MULTIPOLYGON(((180 -16.067132663642447,180 -16.55â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â United Republic of Tanzania â Africa        â POLYGON((33.90371119710453 -0.9500000000000001,34â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â Western Sahara              â Africa        â POLYGON((-8.665589565454809 27.656425889592356,-8â¦ â
âââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
&lt;/code&gt;
    &lt;p&gt;Hereâs how to perform a spatial join to compute the country of each city:&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select
    cities.name as city_name,
    countries.name as country_name,
    continent
from cities
join countries
where ST_Intersects(cities.geometry, countries.geometry)
"""
).show(3)
&lt;/code&gt;
    &lt;p&gt;The code utilizes &lt;code&gt;ST_Intersects&lt;/code&gt; to determine if a city is contained within a given country.&lt;/p&gt;
    &lt;p&gt;Here's the result of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬ââââââââââââââââââââââââââââââ¬ââââââââââââ
â   city_name   â         country_name        â continent â
â    utf8view   â           utf8view          â  utf8view â
âââââââââââââââââªââââââââââââââââââââââââââââââªââââââââââââ¡
â Suva          â Fiji                        â Oceania   â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dodoma        â United Republic of Tanzania â Africa    â
âââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââ¤
â Dar es Salaam â United Republic of Tanzania â Africa    â
âââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;The example above performs a point-in-polygon join, mapping city locations (points) to the countries they fall within (polygons). SedonaDB executes these joins efficiently by leveraging spatial indices where beneficial and dynamically adapting join strategies at runtime using input data samples. While many general-purpose engines struggle with the performance of such operations, SedonaDB is purpose-built for spatial workloads and delivers consistently fast results.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð Apache Sedona SpatialBench¶&lt;/head&gt;
    &lt;p&gt;To test our work on SedonaDB, we also needed to develop a mechanism to evaluate its performance and speed. This led us to develop Apache Sedona SpatialBench, a benchmark for assessing geospatial SQL analytics query performance across database systems.&lt;/p&gt;
    &lt;p&gt;Let's compare the performance of SedonaDB vs. GeoPandas and DuckDB Spatial for some representative spatial queries as defined in SpatialBench.&lt;/p&gt;
    &lt;p&gt;Here are the results from SpatialBench v0.1 for Queries 1â12 at scale factor 1 (SF1) and scale factor 10 (SF10).&lt;/p&gt;
    &lt;p&gt;SedonaDB demonstrates balanced performance across all query types and scales effectively to SF 10. DuckDB excels at spatial filters and some geometric operations but faces challenges with complex joins and KNN queries. GeoPandas, while popular in the Python ecosystem, requires manual optimization and parallelization to handle larger datasets effectively. An in-depth performance analysis can be found in the SpatialBench website.&lt;/p&gt;
    &lt;p&gt;Hereâs an example of the SpatialBench Query #8 that works for SedonaDB and DuckDB:&lt;/p&gt;
    &lt;code&gt;SELECT b.b_buildingkey, b.b_name, COUNT(*) AS nearby_pickup_count
FROM trip t JOIN building b ON ST_DWithin(ST_GeomFromWKB(t.t_pickuploc), ST_GeomFromWKB(b.b_boundary), 0.0045) -- ~500m
GROUP BY b.b_buildingkey, b.b_name
ORDER BY nearby_pickup_count DESC
&lt;/code&gt;
    &lt;p&gt;This query intentionally performs a distance-based spatial join between points and polygons, followed by an aggregation of the results.&lt;/p&gt;
    &lt;p&gt;Here's what the query returns:&lt;/p&gt;
    &lt;code&gt;âââââââââââââââââ¬âââââââââââ¬ââââââââââââââââââââââ
â b_buildingkey â  b_name  â nearby_pickup_count â
â     int64     â utf8view â        int64        â
âââââââââââââââââªâââââââââââªââââââââââââââââââââââ¡
â          3779 â linen    â                  42 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â         19135 â misty    â                  36 â
âââââââââââââââââ¼âââââââââââ¼ââââââââââââââââââââââ¤
â          4416 â sienna   â                  26 â
âââââââââââââââââ´âââââââââââ´ââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;Hereâs the equivalent GeoPandas code:&lt;/p&gt;
    &lt;code&gt;trips_df = pd.read_parquet(data_paths["trip"])
trips_df["pickup_geom"] = gpd.GeoSeries.from_wkb(
    trips_df["t_pickuploc"], crs="EPSG:4326"
)
pickups_gdf = gpd.GeoDataFrame(trips_df, geometry="pickup_geom", crs="EPSG:4326")

buildings_df = pd.read_parquet(data_paths["building"])
buildings_df["boundary_geom"] = gpd.GeoSeries.from_wkb(
    buildings_df["b_boundary"], crs="EPSG:4326"
)
buildings_gdf = gpd.GeoDataFrame(
    buildings_df, geometry="boundary_geom", crs="EPSG:4326"
)

threshold = 0.0045  # degrees (~500m)
result = (
    buildings_gdf.sjoin(pickups_gdf, predicate="dwithin", distance=threshold)
    .groupby(["b_buildingkey", "b_name"], as_index=False)
    .size()
    .rename(columns={"size": "nearby_pickup_count"})
    .sort_values(["nearby_pickup_count", "b_buildingkey"], ascending=[False, True])
    .reset_index(drop=True)
)
&lt;/code&gt;
    &lt;head rend="h2"&gt;ðºï¸ SedonaDB CRS management¶&lt;/head&gt;
    &lt;p&gt;SedonaDB manages the CRS when reading/writing files, as well as in DataFrames, making your pipelines safer and saving you from manual work.&lt;/p&gt;
    &lt;p&gt;Let's compute the number of buildings in the state of Vermont to highlight the CRS management features embedded in SedonaDB.&lt;/p&gt;
    &lt;p&gt;Start by reading in a FlatGeobuf file that uses the EPSG 32618 CRS with GeoPandas and then convert it to a SedonaDB DataFrame:&lt;/p&gt;
    &lt;code&gt;import geopandas as gpd

path = "https://raw.githubusercontent.com/geoarrow/geoarrow-data/v0.2.0/example-crs/files/example-crs_vermont-utm.fgb"
gdf = gpd.read_file(path)
vermont = sd.create_data_frame(gdf)
&lt;/code&gt;
    &lt;p&gt;Letâs check the schema of the &lt;code&gt;vermont&lt;/code&gt; DataFrame:&lt;/p&gt;
    &lt;code&gt;vermont.schema

SedonaSchema with 1 field:
  geometry: wkb &amp;lt;epsg:32618&amp;gt;
&lt;/code&gt;
    &lt;p&gt;We can see that the &lt;code&gt;vermont&lt;/code&gt; DataFrame maintains the CRS thatâs specified in the FlatGeobuf file.  SedonaDB doesnât have a native FlatGeobuf reader yet, but itâs easy to use the GeoPandas FlatGeobuf reader and then convert it to a SedonaDB DataFrame with a single line of code.&lt;/p&gt;
    &lt;p&gt;Now read a GeoParquet file into a SedonaDB DataFrame.&lt;/p&gt;
    &lt;code&gt;buildings = sd.read_parquet(
    "https://github.com/geoarrow/geoarrow-data/releases/download/v0.2.0/microsoft-buildings_point_geo.parquet"
)
&lt;/code&gt;
    &lt;p&gt;Check the schema of the DataFrame:&lt;/p&gt;
    &lt;code&gt;buildings.schema

SedonaSchema with 1 field:
  geometry: geometry &amp;lt;ogc:crs84&amp;gt;
&lt;/code&gt;
    &lt;p&gt;Letâs expose these two tables as views and run a spatial join to see how many buildings are in Vermont:&lt;/p&gt;
    &lt;code&gt;buildings.to_view("buildings", overwrite=True)
vermont.to_view("vermont", overwrite=True)

sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, vermont.geometry)
"""
).show()
&lt;/code&gt;
    &lt;p&gt;This command correctly errors out because the tables have different CRSs. For safety, SedonaDB errors out rather than give you the wrong answer! Here's the error message that's easy to debug:&lt;/p&gt;
    &lt;code&gt;SedonaError: type_coercion
caused by
Error during planning: Mismatched CRS arguments: ogc:crs84 vs epsg:32618
Use ST_Transform() or ST_SetSRID() to ensure arguments are compatible.
&lt;/code&gt;
    &lt;p&gt;Letâs rewrite the spatial join to convert the &lt;code&gt;vermont&lt;/code&gt; CRS to EPSG:4326, so itâs compatible with the &lt;code&gt;buildings&lt;/code&gt; CRS.&lt;/p&gt;
    &lt;code&gt;sd.sql(
    """
select count(*) from buildings
join vermont
where ST_Intersects(buildings.geometry, ST_Transform(vermont.geometry, 'EPSG:4326'))
"""
).show()
&lt;/code&gt;
    &lt;p&gt;We now get the correct result!&lt;/p&gt;
    &lt;code&gt;ââââââââââââ
â count(*) â
â   int64  â
ââââââââââââ¡
â   361856 â
ââââââââââââ
&lt;/code&gt;
    &lt;p&gt;SedonaDB tracks the CRS when reading/writing files, converting to/from GeoPandas DataFrames, or when performing DataFrame operations, so your spatial computations run safely and correctly!&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¯ Realistic example with SedonaDB¶&lt;/head&gt;
    &lt;p&gt;Let's now turn our attention to a KNN join, which is a more complex spatial operation.&lt;/p&gt;
    &lt;p&gt;Suppose you're analyzing ride-sharing data and want to identify which buildings are most commonly near pickup points, helping understand the relationship between trip origins and nearby landmarks, businesses, or residential structures that might influence ride demand patterns.&lt;/p&gt;
    &lt;p&gt;This query finds the five closest buildings to each trip pickup location using spatial nearest neighbor analysis. For every trip, it identifies the five buildings that are geographically closest to where the passenger was picked up and calculates the exact distance to each of those buildings.&lt;/p&gt;
    &lt;p&gt;Hereâs the query:&lt;/p&gt;
    &lt;code&gt;WITH trip_with_geom AS (
    SELECT t_tripkey, t_pickuploc, ST_GeomFromWKB(t_pickuploc) as pickup_geom
    FROM trip
),
building_with_geom AS (
    SELECT b_buildingkey, b_name, b_boundary, ST_GeomFromWKB(b_boundary) as boundary_geom
    FROM building
)
SELECT
    t.t_tripkey,
    t.t_pickuploc,
    b.b_buildingkey,
    b.b_name AS building_name,
    ST_Distance(t.pickup_geom, b.boundary_geom) AS distance_to_building
FROM trip_with_geom t JOIN building_with_geom b
ON ST_KNN(t.pickup_geom, b.boundary_geom, 5, FALSE)
ORDER BY distance_to_building ASC, b.b_buildingkey ASC
&lt;/code&gt;
    &lt;p&gt;Here are the results of the query:&lt;/p&gt;
    &lt;code&gt;âââââââââââââ¬ââââââââââââââââââââââââââââââââ¬ââââââââââââââââ¬ââââââââââââââââ¬âââââââââââââââââââââââ
â t_tripkey â          t_pickuploc          â b_buildingkey â building_name â distance_to_building â
â   int64   â             binary            â     int64     â      utf8     â        float64       â
âââââââââââââªââââââââââââââââââââââââââââââââªââââââââââââââââªââââââââââââââââªâââââââââââââââââââââââ¡
â   5854027 â 01010000001afa27b85825504001â¦ â            79 â gainsboro     â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   3326828 â 01010000001bfcc5b8b7a95d4083â¦ â           466 â deep          â                  0.0 â
âââââââââââââ¼ââââââââââââââââââââââââââââââââ¼ââââââââââââââââ¼ââââââââââââââââ¼âââââââââââââââââââââââ¤
â   1239844 â 0101000000ce471770d6ce2a40f9â¦ â           618 â ivory         â                  0.0 â
âââââââââââââ´ââââââââââââââââââââââââââââââââ´ââââââââââââââââ´ââââââââââââââââ´âââââââââââââââââââââââ
&lt;/code&gt;
    &lt;p&gt;This is one of the queries from SpatialBench.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¦ Why SedonaDB was built in Rust¶&lt;/head&gt;
    &lt;p&gt;SedonaDB is built in Rust, a high-performance, memory-safe language that offers fine-grained memory management and a mature ecosystem of data libraries. It takes full advantage of this ecosystem by integrating with projects such as Apache DataFusion, GeoArrow, and georust/geo.&lt;/p&gt;
    &lt;p&gt;While Spark provides extension points that let SedonaSpark optimize spatial queries in distributed settings, DataFusion offers stable APIs for pruning, spatial operators, and optimizer rules on a single node. This enabled us to embed deep spatial awareness into the engine while preserving full non-spatial functionality. Thanks to the DataFusion project and community, the experience was both possible and enjoyable.&lt;/p&gt;
    &lt;head rend="h2"&gt;âï¸ Why SedonaDB and SedonaSpark are Both Needed¶&lt;/head&gt;
    &lt;p&gt;SedonaSpark is well-suited for large-scale geospatial workloads or environments where Spark is already part of your production stack. For instance, joining a 100 GB vector dataset with a large raster dataset. For smaller datasets, however, Spark's distributed architecture can introduce unnecessary overhead, making it slower to run locally, harder to install, and more difficult to tune.&lt;/p&gt;
    &lt;p&gt;SedonaDB is better for smaller datasets and when running computations locally. The SedonaDB spatial functions are compatible with the SedonaSpark functions, so SQL chunks that work for one engine will usually work for the other. Over time, we will ensure that both project APIs are fully interoperable. Here's an example of a chunk to analyze the Overture buildings table that works for both engines.&lt;/p&gt;
    &lt;code&gt;nyc_bbox_wkt = (
    "POLYGON((-74.2591 40.4774, -74.2591 40.9176, -73.7004 40.9176, -73.7004 40.4774, -74.2591 40.4774))"
)

sd.sql(f"""
SELECT
    id,
    height,
    num_floors,
    roof_shape,
    ST_Centroid(geometry) as centroid
FROM
    buildings
WHERE
    is_underground = FALSE
    AND height IS NOT NULL
    AND height &amp;gt; 20
    AND ST_Intersects(geometry, ST_SetSRID(ST_GeomFromText('{nyc_bbox_wkt}'), 4326))
LIMIT 5;
&lt;/code&gt;
    &lt;head rend="h2"&gt;ð Next steps¶&lt;/head&gt;
    &lt;p&gt;While SedonaDB is well-tested and provides a core set of features that can perform numerous spatial analyses, it remains an early-stage project with multiple opportunities for new features.&lt;/p&gt;
    &lt;p&gt;Many more ST functions are required. Some are relatively straightforward, but others are complex.&lt;/p&gt;
    &lt;p&gt;The community will add built-in support for other spatial file formats, such as GeoPackage and GeoJSON, to SedonaDB. You can read data in these formats into GeoPandas DataFrames and convert them to SedonaDB DataFrames in the meantime.&lt;/p&gt;
    &lt;p&gt;Raster support is also on the roadmap, which is a complex undertaking, so it's an excellent opportunity to contribute if you're interested in solving challenging problems with Rust.&lt;/p&gt;
    &lt;p&gt;Refer to the SedonaDB v0.2 milestone for more details on the specific tasks outlined for the next release. Additionally, feel free to create issues, comment on the Discord, or start GitHub discussions to brainstorm new features.&lt;/p&gt;
    &lt;head rend="h2"&gt;ð¤ Join the community¶&lt;/head&gt;
    &lt;p&gt;The Apache Sedona community has an active Discord community, monthly user meetings, and regular contributor meetings.&lt;/p&gt;
    &lt;p&gt;SedonaDB welcomes contributions from the community. Feel free to request to take ownership of an issue, and we will be happy to assign it to you. You're also welcome to join the contributor meetings, and the other active contributors will be glad to help you get your pull request over the finish line!&lt;/p&gt;
    &lt;p&gt;Info&lt;/p&gt;
    &lt;p&gt;Weâre celebrating the launch of SedonaDB &amp;amp; SpatialBench with a special Apache Sedona Community Office Hour!&lt;/p&gt;
    &lt;p&gt;ð October 7, 2025&lt;/p&gt;
    &lt;p&gt;â° 8â9 AM Pacific Time&lt;/p&gt;
    &lt;p&gt;ð Online&lt;/p&gt;
    &lt;p&gt;ð Sign up here&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sedona.apache.org/latest/blog/2025/09/24/introducing-sedonadb-a-single-node-analytical-database-engine-with-geospatial-as-a-first-class-citizen/"/><published>2025-09-24T16:00:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45362914</id><title>Launch HN: Flywheel (YC S25) – Waymo for Excavators</title><updated>2025-09-25T14:41:35.683149+00:00</updated><content>&lt;doc fingerprint="2c7449d6851a3652"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN, We're Jash and Mahimana, cofounders of Flywheel AI (&lt;/p&gt;https://useflywheel.ai&lt;p&gt;). We’re building a remote teleop and autonomous stack for excavators.&lt;/p&gt;&lt;p&gt;Here's a video: https://www.youtube.com/watch?v=zCNmNm3lQGk.&lt;/p&gt;&lt;p&gt;Interfacing with existing excavators for enabling remote teleop (or autonomy) is hard. Unlike cars which use drive-by-wire technology, most of the millions of excavators are fully hydraulic machines. The joysticks are connected to a pilot hydraulic circuit, which proportionally moves the cylinders in the main hydraulic circuit which ultimately moves the excavator joints. This means excavators mostly do not have an electronic component to control the joints. We solve this by mechanically actuating the joysticks and pedals inside the excavators.&lt;/p&gt;&lt;p&gt;We do this with retrofits which work on any excavator model/make, enabling us to augment existing machines. By enabling remote teleoperation, we are able to increase site safety, productivity and also cost efficiency.&lt;/p&gt;&lt;p&gt;Teleoperation by the operators enables us to prepare training data for autonomy. In robotics, training data comprises observation and action. While images and videos are abundant on the internet, egocentric (PoV) observation and action data is extremely scarce, and it is this scarcity that is holding back scaling robot learning policies.&lt;/p&gt;&lt;p&gt;Flywheel solves this by preparing the training data coming from our remote teleop-enabled excavators which we have already deployed. And we do this with very minimal hardware setup and resources.&lt;/p&gt;&lt;p&gt;During our time in YC, we did 25-30 iterations of sensor stack and placement permutations/combinations, and model hyperparams variations. We called this “evolution of the physical form of our retrofit”. Eventually, we landed on our current evolution and have successfully been able to train some levels of autonomy with only a few hours of training data.&lt;/p&gt;&lt;p&gt;The big takeaway was how much more important data is than optimizing hyperparams of the model. So today, we’re open sourcing 100hrs of excavator dataset that we collected using Flywheel systems on real construction sites. This is in partnership with Frodobots.ai.&lt;/p&gt;&lt;p&gt;Dataset: https://huggingface.co/datasets/FlywheelAI/excavator-dataset&lt;/p&gt;&lt;p&gt;Machine/retrofit details:&lt;/p&gt;&lt;quote&gt;&lt;code&gt;  Volvo EC380 (38 ton excavator)
  4xcamera (25fps)
  25 hz expert operator’s action data
&lt;/code&gt;&lt;/quote&gt;&lt;p&gt; The dataset contains observation data from 4 cameras and operator's expert action data which can be used to train imitation learning models to run an excavator autonomously for the workflows in those demonstrations, like digging and dumping. We were able to train a small autonomy model for bucket pick and place on Kubota U17 from just 6-7 hours of data collected during YC.&lt;/p&gt;&lt;p&gt;We’re just getting started. We have good amounts of variations in daylight, weather, tasks, and would be adding more hours of data and also converting to lerobot format soon. We’re doing this so people like you and me can try out training models on real world data which is very, very hard to get.&lt;/p&gt;&lt;p&gt;So please checkout the dataset here and feel free to download and use however you like. We would love for people to do things with it! I’ll be around in the thread and look forward to comments and feedback from the community!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45362914"/><published>2025-09-24T16:48:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45365878</id><title>SonyShell – An effort to “SSH into my Sony DSLR”</title><updated>2025-09-25T14:41:35.134705+00:00</updated><content>&lt;doc fingerprint="34870070d72e66ed"&gt;
  &lt;main&gt;
    &lt;p&gt;A Linux-only helper built on Sony’s official Camera Remote SDK. It connects to a Sony A6700 camera over Wi-Fi/Ethernet, listens for new photos, downloads them automatically, and can optionally run a script on each downloaded file.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Auto-connect via enumeration or direct IP/MAC.&lt;/item&gt;
      &lt;item&gt;Watches for new capture events and fetches the newest files.&lt;/item&gt;
      &lt;item&gt;Saves into a chosen directory with unique filenames.&lt;/item&gt;
      &lt;item&gt;Post-download hook: run any executable/script with the saved file path as argument.&lt;/item&gt;
      &lt;item&gt;Keepalive mode: auto-retry on startup failure or after disconnects.&lt;/item&gt;
      &lt;item&gt;Cleaned, Linux-only code (no Windows ifdefs, simpler logging).&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;./sonshell --dir /photos [options]&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;--dir &amp;lt;path&amp;gt;&lt;/code&gt;: Directory to save files (required in most real setups).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--ip &amp;lt;addr&amp;gt;&lt;/code&gt;: Connect directly by IPv4 (e.g.&lt;code&gt;192.168.1.1&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--mac &amp;lt;hex:mac&amp;gt;&lt;/code&gt;: Optional MAC (e.g.&lt;code&gt;10:20:30:40:50:60&lt;/code&gt;) for direct IP.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--cmd &amp;lt;path&amp;gt;&lt;/code&gt;: Executable/script to run after each download, invoked as&lt;code&gt;cmd /photos/DSC01234.JPG&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;--keepalive &amp;lt;ms&amp;gt;&lt;/code&gt;: Retry interval when offline or after disconnect.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;-v&lt;/code&gt;,&lt;code&gt;--verbose&lt;/code&gt;: Verbose property-change logging.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Enumerate + keep retrying every 2s, run a hook after each file:&lt;/p&gt;
    &lt;code&gt;./sonshell --dir /tmp/photos --verbose --keepalive 3000 --cmd ../scripts/show_single.sh&lt;/code&gt;
    &lt;p&gt;Direct IP connect, verbose logs, retry every 3s:&lt;/p&gt;
    &lt;code&gt;./sonshell --ip 192.168.1.1 --mac 10:20:30:40:50:60 --dir /tmp/photos -v --keepalive 3000&lt;/code&gt;
    &lt;p&gt;Once connected, you enter the interactive SonShell prompt:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;shoot&lt;/code&gt;: Trigger shutter release.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;focus&lt;/code&gt;: Trigger autofocus (half-press behavior).&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;quit&lt;/code&gt;or&lt;code&gt;exit&lt;/code&gt;: Leave the shell and stop the program.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Requires Linux, g++, and the Sony Camera Remote SDK.&lt;/p&gt;
    &lt;p&gt;See INSTALL.md&lt;/p&gt;
    &lt;p&gt;or (untested)&lt;/p&gt;
    &lt;code&gt;g++ -std=c++17 sonshell.cpp \
    -I/path/to/CrSDK/include \
    -L/path/to/CrSDK/lib -lCameraRemoteSDK \
    -lpthread -o sonshell&lt;/code&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Connect to the camera (via IP or enumeration). Stores/reuses SDK fingerprint under &lt;code&gt;~/.cache/sonshell/&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Wait for notifications: when the camera signals new contents, spawn a download thread.&lt;/item&gt;
      &lt;item&gt;Download newest files to &lt;code&gt;--dir&lt;/code&gt;. Safe naming ensures no overwrite (&lt;code&gt;file_1.jpg&lt;/code&gt;, etc.).&lt;/item&gt;
      &lt;item&gt;Hook: if &lt;code&gt;--cmd&lt;/code&gt;is set, fork/exec the script with the saved path.&lt;/item&gt;
      &lt;item&gt;Reconnect on errors/disconnects if &lt;code&gt;--keepalive&lt;/code&gt;is set.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Built on/for Ubuntu 24.04&lt;/item&gt;
      &lt;item&gt;It uses Sony's official Camera Remote SDK (not included here).&lt;/item&gt;
      &lt;item&gt;See DOCS.md for a deep dive into the internals.&lt;/item&gt;
      &lt;item&gt;I leaned heavily on ChatGPT while creating this, so please don't mind the mess! ;)&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Sony Camera Remote SDK: https://support.d-imaging.sony.co.jp/app/sdk/en/index.html&lt;/item&gt;
      &lt;item&gt;See LICENSE for licensing details.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/goudvuur/sonyshell"/><published>2025-09-24T21:00:00+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45366474</id><title>Snapdragon X2 Elite ARM Laptop CPU</title><updated>2025-09-25T14:41:35.015628+00:00</updated><content>&lt;doc fingerprint="e10fcdab2cdf53e4"&gt;
  &lt;main&gt;
    &lt;p&gt;You need to enable JavaScript to run this app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.qualcomm.com/products/mobile/snapdragon/laptops-and-tablets/snapdragon-x2-elite"/><published>2025-09-24T22:01:06+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45366566</id><title>Everything that's wrong with Google Search in one image</title><updated>2025-09-25T14:41:34.922777+00:00</updated><content/><link href="https://bitbytebit.substack.com/p/everything-thats-wrong-with-google"/><published>2025-09-24T22:11:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45366867</id><title>Helium Browser</title><updated>2025-09-25T14:41:34.388430+00:00</updated><content>&lt;doc fingerprint="170e82509195b1e4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Internet without interruptions&lt;/head&gt;
    &lt;p&gt;Best privacy and unbiased ad-blocking by default. Handy features like native !bangs and split view. No adware, no bloat, no noise. People-first and fully open source.&lt;/p&gt;
    &lt;head rend="h1"&gt;Best privacy by default, not as a hidden option&lt;/head&gt;
    &lt;p&gt;Helium blocks ads, trackers, fingerprinting, third-party cookies, cryptominers, and phishing websites by default thanks to preinstalled uBlock Origin. No extra steps are needed, and there are no biased exceptions â unlike other browsers. &lt;lb/&gt; The browser itself doesn't have any ads, trackers, or analytics. Helium also doesn't make any web requests without your explicit consent, it makes zero web requests on first launch. &lt;lb/&gt; Not enough? Increase privacy even further with ungoogled-chromium flags or uBlock Origin filters. You're finally at the steering wheel of your privacy on the Internet â not in a toy car, but in a real race car. &lt;lb/&gt; We will always stand by our promise of the best privacy and will never prioritize profit over people, unlike big corporations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Respectful by design&lt;/head&gt;
    &lt;p&gt;Helium doesn't annoy you with anything and never will. It doesn't do anything without your consent: no unprovoked tabs about updates or sponsors, no persistent popups telling you about features you don't care about, no weird restarts. &lt;lb/&gt; Nothing interrupts you, jumps in your face, or breaks your flow. Everything just makes sense. You're in full control.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fast, efficient, and light&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium, the fastest and most optimized browser yet. Helium builds on this base to improve performance and save even more energy. You will notice a difference after using Helium for a day. It doesn't slow down over time. &lt;lb/&gt; All bloat is removed: Helium is one of the lightest modern browsers available.&lt;/p&gt;
    &lt;head rend="h2"&gt;Powerful when you need it&lt;/head&gt;
    &lt;p&gt;Open pages side-by-side with split view to get even more things done at once. Quickly copy page links with â+Shift+C and share your discoveries with ease. Install any web apps and use them as standalone desktop apps without duplicating Chromium.&lt;/p&gt;
    &lt;head rend="h2"&gt;Designed to get out of your way&lt;/head&gt;
    &lt;p&gt;Helium's interface is compact and minimalistic, but it doesn't compromise on beauty or functionality. More web content fits on the screen at once, and the browser interface doesn't get in your way. You can hide everything extra from the toolbar if it annoys you. &lt;lb/&gt; Helium is built with attention to detail. Nothing jiggles or flickers abnormally. Your actions aren't throttled or stopped by lag. Everything's fast, smooth, and simple. Comfort and simplicity are among our top priorities.&lt;/p&gt;
    &lt;head rend="h2"&gt;Works with all Chromium extensions, privately&lt;/head&gt;
    &lt;p&gt;All Chromium extensions are supported and work right away, by default, including all MV2 extensions. We'll keep support for MV2 extensions for as long as possible. &lt;lb/&gt; Helium anonymizes all internal requests to the Chrome Web Store via Helium services. Thanks to this, Google can't track your extension downloads or target ads using this data. No other browser does this.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free and fully open-source&lt;/head&gt;
    &lt;p&gt;All parts of the Helium browser are open source, including online services. You can self-host Helium services and use your own instance in your browser. &lt;lb/&gt; Everything is available on GitHub. No exceptions.&lt;/p&gt;
    &lt;head rend="h2"&gt;Always safe and sound&lt;/head&gt;
    &lt;p&gt;We release new Chromium updates (such as security patches) as soon as possible. Your browser will always be safe and up to date. &lt;lb/&gt; Helium updates itself automatically on macOS, with auto-updating options available on Linux and Windows. &lt;lb/&gt; All builds are available on GitHub, and you can even make one yourself. The choice is yours!&lt;/p&gt;
    &lt;head rend="h2"&gt;Best security practices for everyone, by default&lt;/head&gt;
    &lt;p&gt;Helium enforces HTTPS on all websites and warns you when a website doesn't support it. Passkeys just work. &lt;lb/&gt; There's no built-in password manager. Passwords should be separate from a web browser to be truly secure and immutable. &lt;lb/&gt; There's also no cloud-based history/data sync. You should be the only one with access to your browsing data, not some conglomerate.&lt;/p&gt;
    &lt;head rend="h1"&gt;Browse the Internet faster with !bangs&lt;/head&gt;
    &lt;p&gt;Skip the search engine and go directly to the website you want. Choose from over 13,000 bangs that make the Internet a breeze to browse, such as !w for Wikipedia, !gh for GitHub, and !wa for Wolfram Alpha. &lt;lb/&gt; Want to chat with AI? Just add !chatgpt or any other AI provider name at the start of your query. Helium will start a new chat for you without sending your prompt anywhere else. &lt;lb/&gt; Helium bangs are the fastest and most private implementation of bangs yet. They work offline, directly in your browser. &lt;lb/&gt; Not sure which bang to use? Check out the full list of bangs!&lt;/p&gt;
    &lt;head rend="h1"&gt;The web browser made for people, with love&lt;/head&gt;
    &lt;p&gt;We're making a web browser that we enjoy using ourselves. Helium's main goal is to provide an honest, comfortable, privacy-respecting, and non-invasive browsing experience.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for developers&lt;/head&gt;
    &lt;p&gt;Helium is based on Chromium and doesn't break any web APIs or standards, despite the focus on privacy. DevTools have been cleaned up and no longer nag you with anything. There's nothing that gets in your way of creating the Internet of the future.&lt;/p&gt;
    &lt;head rend="h2"&gt;Perfect for everyone on the go&lt;/head&gt;
    &lt;p&gt;Helium's efficiency makes it handy for everyone with their laptop on the go. Split view and quick link copying make it easier than ever to get things done faster. Helium loads pages faster and saves data by blocking ads and other crap.&lt;/p&gt;
    &lt;head rend="h1"&gt;Ready to try Helium?&lt;/head&gt;
    &lt;p&gt;It's never too late to get your internet life back on the right track. Helium can transfer your most important stuff from other browsers in one click. We hope you'll love it!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://helium.computer/"/><published>2025-09-24T22:51:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45367046</id><title>Do YC after you graduate: Early decision for students</title><updated>2025-09-25T14:41:34.030041+00:00</updated><content>&lt;doc fingerprint="b61d01d108cf1634"&gt;
  &lt;main&gt;
    &lt;p&gt;Apply now, do YC after you graduate. For students who want to finish school before doing YC. Get funded the moment you're accepted.&lt;/p&gt;
    &lt;p&gt;Sneha and Anushka, founders of Spur (S24), applied in Fall 2023 for the S24 batch using Early Decision. This allowed them to graduate in May 2024 and then do YC. They've since raised $4.5M from top investors for their AI-powered QA testing tools.&lt;/p&gt;
    &lt;p&gt;Early Decision lets you apply to YC while you're still in school and reserve your spot in a future batch. For example, you apply in Fall of this year, for a spot in the summer batch of the following year. You submit the same YC application as if you were applying for the upcoming batch. If you're accepted, we'll fund you immediately and hold your place for after you graduate.&lt;/p&gt;
    &lt;p&gt;This program is designed for students who want to finish their degree before starting a company. If you're considering working on your own startup after graduation, Early Decision makes it easy to lock in your spot.&lt;/p&gt;
    &lt;p&gt;Even if you're not completely sure yet if you want to do a startup, you should still apply. There is no downside.&lt;/p&gt;
    &lt;p&gt;Also, if you're not in your final year, you can still apply for Early Decision. You'll be able to finish the school year you're currently in, and then either join a later batch or decide to drop out and start sooner.&lt;/p&gt;
    &lt;p&gt;The most common path is students applying in the fall of their final year and joining the summer batch after graduating in Spring. But you can apply for any batch in the future within reason. The application and interview process is the same as if you were applying for the upcoming batch. Once you're accepted, YC funds you right away and confirms your future batch.&lt;/p&gt;
    &lt;p&gt;When you fill out your YC application, you'll see a question asking which batch you want to apply for. Simply select "A batch after Winter 2026" to indicate you're applying for Early Decision, and tell us which batch you'd like to be considered for.&lt;/p&gt;
    &lt;p&gt;The batch preference question in the YC application&lt;/p&gt;
    &lt;p&gt;Many students want to finish their degree or complete more of their education before starting a company. Also we know that many students spend a lot of time in Fall or during their final year applying for jobs or internships. Early Decision gives students another option: apply to YC and bet on yourself.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/early-decision"/><published>2025-09-24T23:12:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45369768</id><title>Knotty: A domain-specific language for knitting patterns</title><updated>2025-09-25T14:41:33.857034+00:00</updated><content>&lt;doc fingerprint="a5ebd7a76a7f3314"&gt;
  &lt;main&gt;
    &lt;p&gt;▼ Knotty 1 Introduction 2 How to Make a New Pattern 3 Input and Output 4 Code Examples 5 Reference On this page: Knotty 8.11 contents ← prev up next → Knotty Tom Price &amp;lt; t0mpr1c3@gmail.com &amp;gt; ( require knotty ) package: knotty-lib A domain-specific language for knitting patterns. contents ← prev up next →&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://t0mpr1c3.github.io/knotty/index.html"/><published>2025-09-25T06:13:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45370882</id><title>Some interesting stuff I found on IX LANs</title><updated>2025-09-25T14:41:33.512257+00:00</updated><content>&lt;doc fingerprint="f78b85556837a9c2"&gt;
  &lt;main&gt;
    &lt;p&gt;These days the internet as a whole is mostly constructed out of point to point ethernet circuits, meaning an ethernet interface (mostly optical) attached directly from one routing device to another routing device.&lt;/p&gt;
    &lt;p&gt;However that is not always the case, as the humble “internet exchange” (IX) still exists, and while the relevancy of IXs are progressively being diminished by the internet increasingly being concentrated into a small handful of content networks and IXs not keeping up with the lowering price of transit or private fiber connections to the largest networks, there are still a large number of networks that’s attached to at least one IX fabric.&lt;/p&gt;
    &lt;p&gt;IXs are a little bit strange, as they are at their core practically identical to a simple ethernet switch you may find in your home or office (except your home switch is unlikely to be doing terabits per second of traffic). As IXs depend on the ethernet switches interest in only being the MAC addresses of traffic and not the Layer 3 IP addresses.&lt;/p&gt;
    &lt;p&gt;However home and small and medium business (SMB) routers often come with defaults that make life a lot easier for networks way of desktop computers and common office equipment on them, these same defaults are at the very least annoying and at the very worst actively exploitable if put on a IX LAN with many untrusted participants.&lt;/p&gt;
    &lt;p&gt;The company that I run and operate has a large number of ports at internet exchanges (at a rough estimate I am the top 13 of all networks on the internet in this metric!), and alongside the route collecting that bgp.tools does on these IX ports, it also listens in on the broadcast and multicast traffic that happens on these exchanges.&lt;/p&gt;
    &lt;p&gt;This isn’t that magical, at its core it works by running tcpdump on each IX port, and picking up the BUM traffic, parsing what it is looking at (and throwing away the unknown unicast, since that is a separate common problem that I don’t want to get involved with), and reporting that data back up the chain to bgp.tools’s website.&lt;/p&gt;
    &lt;p&gt;This creates little warning icons (or alerts if they use the monitoring product) on their IX membership rows to let them and others know that something is not configured correctly&lt;/p&gt;
    &lt;p&gt;When I first started off developing this feature I was basically going off the top of my head on what the obvious mistakes that were likely to happen on misconfigured IX ports. However at the same time I developed a “miscellaneous packets” feed that collected packets that I didn’t have code to deal with.&lt;/p&gt;
    &lt;p&gt;Checking that miscellaneous packet feed every week has been a lot of fun and deeply terrifying on what networks have been sending into exchanges. Here are some of the things that bgp.tools finds on a regular basis&lt;/p&gt;
    &lt;p&gt;With large deployments of routers and switches it is often very difficult to actually locate where each device is plugged into at either end. For this exact reason, many vendors ship protocols that emit various identifier packets that are designed to help operations teams identify the “far side” of each port&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: Low&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Link Layer Discovery Protocol is a pretty common cross vendor protocol for doing exactly this, it is also sometimes used to automatically configure capabilities like higher wattage power over ethernet.&lt;/p&gt;
    &lt;p&gt;Here’s an example of a LLDP packet (and what information it discloses) from my own network:&lt;/p&gt;
    &lt;code&gt;root@blah:~# lldpctl 
------------------------------------------------------------------
LLDP neighbors:
------------------------------------------------------------------
Interface:    ens1f0, via: LLDP, RID: 3, Time: 146 days, 02:13:47
  Chassis:     
    ChassisID:    mac 1c:34:da:90:90:01
    SysName:      bgptools-switch
    SysDescr:     Debian GNU/Linux 12 (bookworm) Linux [...]
    MgmtIP:       10.xxx.xxx.2
    MgmtIface:    3
    MgmtIP:       fdd2:xxx::1
    MgmtIface:    3
    Capability:   Bridge, on
    Capability:   Router, on
    Capability:   Wlan, off
    Capability:   Station, off
  Port:        
    PortID:       mac 1c:34:da:90:90:26
    PortDescr:    swp8
    TTL:          120
    PMD autoneg:  supported: yes, enabled: yes
      Adv:          1000Base-X, HD: no, FD: yes
      MAU oper type: 10GigBaseCX4 - X copper over 8 pair 100-Ohm balanced cable
&lt;/code&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Cisco Discovery Protocol is a older and proprietary to Cisco (although that does not stop many vendors from having copied it) version of LLDP&lt;/p&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;The popular budget network equipment vendor Mikrotik ships by default with a feature called “Mikrotik Neighbor Discovery Protocol” enabled by default.&lt;/p&gt;
    &lt;p&gt;Here is an example decoded MNDP packet from a network on FranceIX&lt;/p&gt;
    &lt;code&gt;    Seq: 134398
    MAC Address: 08:55:31:1b:9c:aa
    Identity: DC2.A23.CCR02
    Version: 6.49.6 (stable)
    Platform: MikroTik
    Uptime: 2239h52m39s
    SoftwareID: HBWH-7QHV
    Board: CCR1009-7G-1C-1S+
    IPv6Address: 2001:7f8:54::1:85
    InterfaceName: FRANCE_IX
    IPv4Address: 37.49.237.85
&lt;/code&gt;
    &lt;p&gt;We can see what they named the device , what type of device it is, the interface name (FRANCE_IX), and the device uptime.&lt;/p&gt;
    &lt;p&gt;Most consumer devices when they come on the network do not know what IP address/gateway they are supposed to be using, This is because in most environments you do not want to have machines that have statically configured addresses.&lt;/p&gt;
    &lt;p&gt;However IX’s are not these kinds of environments, as they are environments where all participants have been assigned a very specific IP address to use on the LAN. This does not stop these automatic IP address assignment protocols from attempting to grab IP addresses with some configurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: High&lt;/p&gt;
    &lt;p&gt;Security Danger: Targeted traffic redirection&lt;/p&gt;
    &lt;p&gt;This is the exact same protocol that your mobile phone or laptop is using, just being blasted out to terabit/s per second switching fabrics. When a IX participant is asking for addresses with DHCP on the exchange, any one of the entities connected (some of which may be considered adversaries of your state) could reply to their request and assign them an IP address and default gateway, the latter possibly redirecting large amounts of traffic through them!&lt;/p&gt;
    &lt;p&gt;Commonness: High&lt;/p&gt;
    &lt;p&gt;Operational Danger: People using your network for free&lt;/p&gt;
    &lt;p&gt;Security Danger: Low&lt;/p&gt;
    &lt;p&gt;IPv6 Router Advertisement is a protocol where routers periodically announced onto the LAN but they are capable of acting as a gateway (and optionally include instructions for clients to generate IPv6 addresses automatically), this is useful for IPv6 deployment, but this behavior is absolutely not desirable on internet exchanges as you do not want to have people use you as a gateway for the entire internet over peering LANs, as effectively giving them free internet transit, which is typically bad for business.&lt;/p&gt;
    &lt;p&gt;Unfortunately this feature is enabled by default on Cisco and Arista, meaning it is so common that bgp.tools has a dedicated icon for it on the site.&lt;/p&gt;
    &lt;p&gt;On exchanges there is generally only one accepted routing protocol that is allowed to be used between members and that is BGP. However that does not seem to stop other networks from accidentally enabling other protocols, some of which automatically “flood” messages to broadcast so they can look for peers to automatically establish relationships with.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: You will import other peoples internal routes&lt;/p&gt;
    &lt;p&gt;Security Danger: People can insert routes into your network&lt;/p&gt;
    &lt;p&gt;OSPF and IS-IS are the classic internal routing protocols that a lot of networks use to manage their internal routing table. This internal routing table is where the more specific routes for individual customers or subscriber pools exist.&lt;/p&gt;
    &lt;p&gt;While OSPF and IS-IS offer an ability to restrict sessions that are automatically started without a given password in configuration, a decent number of networks do not use this feature.&lt;/p&gt;
    &lt;p&gt;The result of this is if these networks without a password configured meet each other on the internet exchange with OSPF/IS-IS configured they will automatically exchange internal routing tables of each other, the effects of this could range between a security risk because an attacker could inject routes into their internet routing table, all the way to a full blown outage as there would be overlap in internal network routes.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: You will import other peoples internal routes&lt;/p&gt;
    &lt;p&gt;Security Danger: People can insert routes into your network&lt;/p&gt;
    &lt;p&gt;Routing Information Protocol is a very old way of doing what OSPF and IS-IS does on most modern networks today.&lt;/p&gt;
    &lt;p&gt;RIP and RIPv2 have similar automatic peer configuration features, meaning that if two or more members on an internet exchange have this configured they will almost certainly automatically merge their internal routing tables.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: People can manipulate MPLS labels&lt;/p&gt;
    &lt;p&gt;Security Danger: People can manipulate MPLS labels&lt;/p&gt;
    &lt;p&gt;MultiProtocol Label Switching Label Distribution Protocol is a different type of internal routing protocol that rather than dealing with IP prefixes, handles the exchange of MPLS Labels. Given that a lot of networks deploy MPLS as the core way of moving data around in their network, exposing this to another untrusted party is pretty bad.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Quite a lot of vendors have their own form of proprietary ethernet loop detection, which often involve sending out probing packets into the LAN and seeing if they arrive back on any other interface (which would indicate a loop)&lt;/p&gt;
    &lt;p&gt;For example, here is a loop testing packet from a Huawei device&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: Local disruption&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Spanning Tree Protocol is a very common default that is enabled across most ethernet switches to combat ethernet loops. However accepting STP packets and sending them to other members of the exchange could result in disruption to the peer, as both sides try to agree a hierarchy with each other.&lt;/p&gt;
    &lt;p&gt;SONiC is an open source network operating system (NOS) developed mostly by Microsoft, this is notable because almost all network operating systems are proprietary with no source code available. There are many reasons for this but one of the primary ones is that while there are many networking equipment vendors out there, the actual fundamental ASIC/Chips suppliers that are used to build high end equipment are limited down to around 3, with the majority of the market share being Broadcom. SONiC has in recent years become the most well known by name open source NOS.&lt;/p&gt;
    &lt;p&gt;Unfortunately SONiC is also just not a very good pick for almost all users, and mortally let down by its software quality. An example of this is a script called arp_update that transmits a “Ping all IPv6 devices” packet to all connected LANs so that it can work around a potential limitation in the hardware that it supports. This is a nuisance on internet exchanges because once there are more than a handful of these devices on the exchange, every one is spending a non zero amount of resources responding to pointless pings.&lt;/p&gt;
    &lt;p&gt;It’s hard for me to understate how crap of a workaround this is, and how much more crap this is for devices with internet exchange ports.&lt;/p&gt;
    &lt;p&gt;There is a final category for things that are kind of just bizarre to see. They are just things that should not actually appear at all on any internet exchange port, and suggest something strange has happened. Either with unexpected devices being connected into the exchange fabric entirely, or very inadvisable configurations being used for public “network edge” ports.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;While Network Time Protocol is very common, most of the time it is configured in a unicast way (meaning that a device deliberately queries a NTP peer), however there is a lesser used broadcast mode where a server broadcasts the time into the LAN on regular intervals.&lt;/p&gt;
    &lt;p&gt;Unfortunately some networks have decided to enable this on their internet exchange ports, meaning that all members are receiving (but are unlikely using) these packets.&lt;/p&gt;
    &lt;p&gt;It doesn’t help that almost every single time I have seen one of these situations, the time being broadcast itself is wrong by at least a few days implying that a device itself does not actually have a good source of time, and it’s just drifting from it’s original set up&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Exposure of a remote configuration interface to untrusted networks&lt;/p&gt;
    &lt;p&gt;Once again our friend MikroTik comes back with some interesting defaults, In this case the RoMON protocol that allows their GUI management interface (WinBox), and the ability to “telnet” into a neighboring device with just its MAC address.&lt;/p&gt;
    &lt;p&gt;The logic behind the telnet feature is that it is useful for when you need to go to recover a device that you may have accidentally set a bad firewall or IP address/routing configuration on. However that does also mean that bgp.tools has traces of people using this telnet feature (which often broadcasts keystrokes and outputs) to all members. Implying that some networks are using the IX LAN (presumably by borrowing another member’s router) as a recovery mechanism for their misconfigurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Exposure of a legacy protocol to untrusted networks&lt;/p&gt;
    &lt;p&gt;The Digital Equipment Corporation (Yes, the PDP-11 company) developed a series of network protocols called DECnet. While it is unlikely that you will ever encounter a device that needs DECNet support, Cisco by default enables this protocol on all interfaces (unless explicitly configured otherwise) on all enterprise software versions for IOS/IOS-XE.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Allowing untrusted networks to configure your device&lt;/p&gt;
    &lt;p&gt;Simple Service Discovery Protocol and its’s most common implementation use case Universal Plug and Play is a protocol normally only ever found in the home/residential networking space. It allows for simple configuration for things like port forwarding. Since no one should be connecting such hardware to IX LANs, this is generally a sign of a serious misconfiguration.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: Information Disclosure&lt;/p&gt;
    &lt;p&gt;Multicast DNS and Link-Local Multicast Name Resolution are protocols used mostly by desktop computers to locate other things on the network (typically home or small biz networks) by name.&lt;/p&gt;
    &lt;p&gt;MDNS is also very common in the automatic discovery of network printers, it also happens to be what I discovered the most on various exchanges&lt;/p&gt;
    &lt;p&gt;While this is obviously ridiculous that a printer would be attached to an IX, what is likely actually happening here is that linux distributions like Debian will/would offer a “print server” role enabled by default. Since Linux “software routers” based on Debian are common in some regions, it doesn’t necessarily surprise me that these routers were installed with the print server role left enabled by mistake when they the operating system was installed.&lt;/p&gt;
    &lt;p&gt;Commonness: Rare&lt;/p&gt;
    &lt;p&gt;Operational Danger: None&lt;/p&gt;
    &lt;p&gt;Security Danger: The exposure of Windows or SMB to untrusted networks&lt;/p&gt;
    &lt;p&gt;NETBIOS is often used to power SMB/Samba, the Windows file and printer sharing protocol.&lt;/p&gt;
    &lt;p&gt;When I first encountered this packet I assumed that this was going to be a windows server configuration that had been let onto the exchanged by mistake, as encountering windows servers acting as edge routers is unheard of (although windows does actually have a bgp implementation, it is not designed for edge peering and so would make an extremely poor edge router)&lt;/p&gt;
    &lt;p&gt;Upon further inspection of the packets it appears that what has actually happened here (at least 6 different times) is desktops/laptops have been let into the exchange instead. I can tell this because windows will automatically generate host names like &lt;code&gt;SERVER-ABCD1234&lt;/code&gt; for windows server installations, and &lt;code&gt;DESKTOP-ABCD1234&lt;/code&gt; for desktop/laptop ones, and NETBIOS packets often include the hostname of the system that is querying.&lt;/p&gt;
    &lt;p&gt;I can only assume this has happened due to incorrect physical cable patching or VLAN translation.&lt;/p&gt;
    &lt;p&gt;Commonness: Low&lt;/p&gt;
    &lt;p&gt;Operational Danger: Untrusted networks could trigger failover of your routers&lt;/p&gt;
    &lt;p&gt;Security Danger: None&lt;/p&gt;
    &lt;p&gt;Virtual Router Redundancy Protocol and Hot Standby Router Protocol are protocols that are designed to allow two routers to automatically take over from another if they fail. To do this the protocol sends packets on a regular interval into the LAN that has the gateway ip address that is being protected from downtime.&lt;/p&gt;
    &lt;p&gt;While redundancy is obviously desired on exchanges, this is typically done by actually attaching two discrete routers to the exchange with different LAN IP addresses, so VRRP and similar protocols are not appreciated configurations.&lt;/p&gt;
    &lt;p&gt;Commonness: Medium&lt;/p&gt;
    &lt;p&gt;Operational Danger: Embarrassment&lt;/p&gt;
    &lt;p&gt;Security Danger: Information disclosure&lt;/p&gt;
    &lt;p&gt;When Cisco devices are unable to find a working DNS resolver, they resort to broadcasting the DNS query on all interfaces, Most of the time this just means that the Cisco licensing server (the “cslu-local”) is queried for, with an added bonus of the owners DNS search domain (if they have configured one)&lt;/p&gt;
    &lt;p&gt;So filtering for these packets is quite easy, and results in pretty much exactly what you would think.&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' | sort | uniq -c | sort -n | tail -n 15
    875 cslu-local.{CORP-F}
    998 cslu-local.{CORP-F}
   1162 tools.cisco.com.{Military-A}.
   1648 cslu-local.{CORP-G}
   1659 cslu-local.{CORP-F}
   1880 cslu-local.{CORP-E}
   2088 tools.cisco.com.{CORP-A}.
   2910 cslu-local.{CORP-D}
   4213 cslu-local.{Military-A}.
   5125 cslu-local.{CORP-C}.com.
   5515 cslu-local.{CORP-B}.fr.
   7367 cslu-local.{CORP-A}.com.
   7675 tools.cisco.com.
   9934 cslu-local.{Military-A}
  10838 cslu-local.
&lt;/code&gt;
    &lt;p&gt;Except Cisco also has another interesting default back from the days when Cisco sold dedicated terminal servers where you would dial into the device (over the phone), and then type the device name you were looking to connect to.&lt;/p&gt;
    &lt;p&gt;In practice everybody should be disabling this function in 2025, however by default it is enabled, so if you log into the Cisco CLI and make a typo (let’s say for this example you forgot the you’re on a cisco rather than a huawei), this happens:&lt;/p&gt;
    &lt;p&gt;The CLI just hangs, as it broadcasts your typo onto all interfaces…&lt;/p&gt;
    &lt;p&gt;Anyway with a little bit of careful processing we can see all of these typos and sometimes the search domain from where they came from:&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' | sort | uniq -c | sort -n | egrep -v  'cslu|tools.cisco.com'

      1 cls.basetelco.com.
      1 configre.jato3.com.
      1 conft.asn28176.com.br.
      1 conft.powernet.net.br.
      1 cont.wanfiber.net.br.
      1 cpnf.cd.net.za.
      1 end.3cta.eb.mil.br.
      1 end.as37497.net.
      1 end.cd.net.za.
      1 end.spnet.com.br.
      1 exiexit.cd.net.za.
      1 exit-address-family.
      1 exitr.jfsc.local.
      1 expression.jato3.com.
&lt;/code&gt;
    &lt;p&gt;I’ve collected favorite most common typos below:&lt;/p&gt;
    &lt;code&gt;$ tcpdump -nr dns.pcap |&amp;amp; pcregrep -o1 '\] A{1,4}\? ([^\)]+)' | awk '{print $1}' |&amp;amp; pcregrep -o1 '^([^.]+)' | sort | uniq -c | sort -n 
...

      1 access-list
      1 configre
      1 cont
      1 cpnf
      1 exiexit
      1 exit-address-family
      1 exitr
      1 exti
      1 extit
      1 ifconfig
      1 int
      1 interface
      1 qconft
      1 qqq
      1 reboot
      1 uptime
      2 coinf
      2 Please
      2 shorun
      2 top
      4 ip
      4 ping
      6 save
      9 conft
     87 y
     92 quit
    134 q
    289 summary
&lt;/code&gt;
    &lt;p&gt;There is of course an added danger while having this enabled that you could actually answer these queries and then trick an operator into typing into a terminal that you control. But I suspect that almost all operators would notice something like that happening, making such a trick difficult to pull off.&lt;/p&gt;
    &lt;p&gt;While pretty much all exchanges have rules that define the kind of traffic that you are allowed to be sent into the internet exchange fabric that would forbid almost all of these types of packets from being sent ( For example, here is AMS-IX’s list of rules ), enforcement of these rules is nonexistent in most exchanges.&lt;/p&gt;
    &lt;p&gt;Which is a shame really because a lot of this can be automatically done with simple access control lists (ACLs) that target just mac addresses alone.&lt;/p&gt;
    &lt;p&gt;DEC-MOP, RoMON, STP, CDP, IS-IS, ES-IS, LLDP, VRRP, OSPF, IPv6 RA are remarkably common, and yet they use specific MAC address destinations that could just be filtered out on all ports, preventing them from being seen by other IX participants.&lt;/p&gt;
    &lt;p&gt;While [LLMNR, NetBIOS, PIM, LDP, MDNS, DHCPv4 /DHCPv6, SSDP, DNS-Broadcast, Broadcast NTP, MikroTik Discovery] do require the IX device to be able to inspect Layer 3 headers like UDP port numbers in ACLs, this feature is very common among deployed hardware in the industry.&lt;/p&gt;
    &lt;p&gt;Even if exchanges are not able to automatically enforce policy using ACLs, there are open source projects like IXP-Watch and systems like bgp.tools that will monitor this for you.&lt;/p&gt;
    &lt;p&gt;There shouldn’t really be an excuse for things to be this way!&lt;/p&gt;
    &lt;p&gt;If you want to stay up to date with the blog you can use the RSS feed or you can follow me on Fediverse @benjojo@benjojo.co.uk&lt;/p&gt;
    &lt;p&gt;Until next time!&lt;/p&gt;
    &lt;p&gt;Related Posts:&lt;/p&gt;
    &lt;p&gt;Appreciation of automated IX Quarantine LAN testing (2024)&lt;/p&gt;
    &lt;p&gt;Better IX network quality monitoring (2024)&lt;/p&gt;
    &lt;p&gt;Random Post:&lt;/p&gt;
    &lt;p&gt;TOTP SSH port fluxing (2016)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.benjojo.co.uk/post/ixp-bad-broadcast-packets-interesting"/><published>2025-09-25T09:36:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45371061</id><title>Bundler Belongs to the Ruby Community</title><updated>2025-09-25T14:41:33.385108+00:00</updated><content>&lt;doc fingerprint="e91a20914debb5e8"&gt;
  &lt;main&gt;
    &lt;p&gt;25 Sep 2025&lt;/p&gt;
    &lt;head rend="h2"&gt;Bundler belongs to the Ruby community&lt;/head&gt;
    &lt;p&gt;I’ve spent 15 years of my life working on Bundler. When I introduce myself, people say “oh, the Bundler guy?”, and I am forced to agree.&lt;/p&gt;
    &lt;p&gt;I didn’t come up with the original idea for Bundler (that was Yehuda). I also didn’t work on the first six months worth of prototypes. That was all Carl and Yehuda together, back when “Carlhuda” was a super-prolific author of Ruby libraries, including most of the work to modularize Rails for version 3.&lt;/p&gt;
    &lt;p&gt;I joined the team at a pivotal moment, in February 2010, as the 0.9 prototype was starting to be re-written yet another time into the shape that would finally be released as 1.0. By the time Carl, Yehuda, and I released version 1.0 together in August 2010, we had fully established the structure and commands that Bundler 2.7.2 still uses today.&lt;/p&gt;
    &lt;p&gt;I gave my first conference talk about Bundler at Red Dirt Ruby in May 2010. Because they would be too busy with Rails 3 talks, Yehuda and Carl asked me to give the first RailsConf talk about Bundler, in June 2010.&lt;/p&gt;
    &lt;p&gt;As Carl and Yehuda drifted off to other projects, in 2011 and 2012 respectively, I took on a larger role, co-maintaining the project with Terence Lee, then on the Ruby platform team at Heroku. We shipped (and, embarrassingly, broke) many versions of Bundler on our way to the 1.1 release and its major speed improvements. We also gave several conference talks together, sharing what we had learned about Bundler, about gems, and about maintaining open source.&lt;/p&gt;
    &lt;p&gt;In 2013, I managed to convince the owner of &lt;code&gt;bundler.io&lt;/code&gt; to sell me his domain, and rebuilt the website to host a separate copy of the documentation for every version of Bundler, ensuring even users on old versions could still access accurate documentation.&lt;/p&gt;
    &lt;p&gt;By the end of 2013, Terence had drifted away from the project as well, and I realized that everyone using Ruby was now one bus (or one lottery ticket) away from Bundler having no significant maintainers. During 2014, I made sure to settle any remaining ownership issues, including purchasing the rights to the Bundler logo, and began investigating various funding ideas. I tried specialized consulting, corporate sponsorships, and asking Ruby Central about sponsoring Bundler and RubyGems development work. Ruby Central declined, citing their desire to stay focused on conferences, but suggested that if I wanted to pursue something myself they would be happy to collaborate.&lt;/p&gt;
    &lt;p&gt;In 2015, I founded Ruby Together specifically to raise funds to pay the existing maintainers team of Bundler, RubyGems, and RubyGems.org. Over time, we were able to raise enough money to quietly but scrappily keep the entire RubyGems ecosystem maintained and functional. Ruby Together did not ever, at any point, demand any form of governance or control over the existing open source projects. Maintainers did their thing in the RubyGems and Bundler GitHub orgs, while Ruby Together staff and board members did their thing in the rubytogether GitHub org.&lt;/p&gt;
    &lt;p&gt;By 2021, when Ruby Central and Ruby Together were both interested in merging together, funds were harder to find. Ruby Together had a membership program. Ruby Central wanted a to have a membership program. The confusing split between “Ruby Central owns the AWS account, but Ruby Together pays all the devs” continued to be a problem.&lt;/p&gt;
    &lt;p&gt;We prepared a merger agreement (which you can read in full at the link), stating that Ruby Central’s new goal after the merger would be “paying maintainers to do the programming”. The agreement also states that Ruby Central will follow Ruby Together’s Vision, Mission, and Values, a document that is hosted in the rubycentral GitHub organization today. That document includes a very specific list of goals, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Project users and maintainers are empowered to decide what’s best for their projects&lt;/item&gt;
      &lt;item&gt;Ruby open source developers are paid for their work&lt;/item&gt;
      &lt;item&gt;Give control to the community&lt;/item&gt;
      &lt;item&gt;Be accountable and transparent to the community&lt;/item&gt;
      &lt;item&gt;Establish a collaborative, positive space for projects&lt;/item&gt;
      &lt;item&gt;Have a clear and transparent funding process&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;You can read much more in both the merger agreement and in the Mission, Vision, and Values document, but the fundamental goal for both the non-profit and the open source projects is clear: this is all for the Ruby community. Without the community, there is no point to this work, and there is no way it could ever have been done in the first place. Without the 354 individuals who contributed to Bundler and to RubyGems, I could never have become “the Bundler guy” in the first place.&lt;/p&gt;
    &lt;p&gt;In the last few weeks, Ruby Central has suddenly asserted that they alone own Bundler. That simply isn’t true. In order to defend the reputation of the team of maintainers who have given so much time and energy to the project, I have registered my existing trademark on the Bundler project.&lt;/p&gt;
    &lt;p&gt;Trademarks do not affect copyright, which stays with the original contributors unchanged. Trademarks do not affect license terms, which stay MIT and unchanged. Trademarks only impact one thing: who is allowed say that what they make is named “Bundler”. Ruby Central is welcome to the code, just like everyone else. They are not welcome to the project name that the Bundler maintainers have painstakingly created over the last 15 years.&lt;/p&gt;
    &lt;p&gt;While the trademark has been registered under my name as an individual, I will not keep it for myself, because the idea of Bundler belongs to the Ruby community. Once there is a Ruby organization that is accountable to the maintainers, and accountable to the community, with openly and democratically elected board members, I commit to transfer my trademark to that organization.&lt;/p&gt;
    &lt;p&gt;I will not license the trademark, and will instead transfer ownership entirely. Bundler should belong to the community, and I want to make sure that is true for as long as Bundler exists.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://andre.arko.net/2025/09/25/bundler-belongs-to-the-ruby-community/"/><published>2025-09-25T10:05:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45371283</id><title>The Theatre of Pull Requests and Code Review</title><updated>2025-09-25T14:41:32.748629+00:00</updated><content>&lt;doc fingerprint="3754740beb3d5f9b"&gt;
  &lt;main&gt;&lt;p&gt;We can't find the internet&lt;/p&gt;&lt;p&gt;Attempting to reconnect&lt;/p&gt;&lt;p&gt;Something went wrong!&lt;/p&gt;&lt;p&gt;Hang in there while we get back on track&lt;/p&gt;&lt;head rend="h1"&gt;The Theatre of Pull Requests and Code Review&lt;/head&gt;&lt;head rend="h3"&gt;Meks McClure · September 23, 2025&lt;/head&gt;Photo Credit to Petter Boström&lt;p&gt;I recently attended the Goatmire Elixir Conf and one of the standout talks for me was Saša Jurić's "Tell Me a Story". It was an incredible presentation that combined theatrical storytelling with practical technical advice. Saša performed parts of his talk in character, turning technical topics into a compelling narrative that was part comedy, part tragedy, and fully packed with useful insights I've started implementing myself. The recording will eventually be released online for viewing. I highly recommend that people watch it, and I'll endeavor to add a link to it here when it becomes available.&lt;/p&gt;Photo Credit to Petter Boström&lt;head rend="h2"&gt;The Code Review Challenge&lt;/head&gt;&lt;p&gt;The talk focused on Code Review and Pull Requests (PRs). Saša laid out common problems most software engineers face. Too often, engineers dread code reviews even though they're a significant part of team collaboration. We avoid them because PRs tend to be too large, too complex, too difficult to comprehend, and too painful to test. So we end up commenting "Looks Good To Me" and suggesting a few minor styling improvements to give the appearance of a thorough review.&lt;/p&gt;&lt;p&gt;This is how security leaks happen and codebases become progressively unmaintainable. Since git blame only points to the original author, it's easy to think "if something goes wrong, it's not on me". But we're all responsible for the whole system, regardless of who wrote the individual lines of code.&lt;/p&gt;&lt;head rend="h2"&gt;What Makes a PR Reviewable?&lt;/head&gt;&lt;p&gt;So how do we review something that feels unreviewable? Saša advocates for normalizing the practice of returning difficult-to-understand PRs to the author. This makes logical sense, but it's challenging to implement because it can feel like admitting we're not smart enough to understand the code. However, saying "I don't understand this enough to approve it" is far more valuable than pretending with an empty "LGTM".&lt;/p&gt;&lt;p&gt;If we commit to only reviewing truly reviewable PRs, what does that look like? According to Saša, it should take the average reviewer 5-10 minutes. By 'average reviewer,' he means mid-to-senior developers who understand the domain, business, and tech stack well—not newcomers still learning the system or mythical 10x engineers.&lt;/p&gt;&lt;p&gt;How do you create a PR that can be reviewed in 5-10 minutes? By reducing the scope. A full feature should often be multiple PRs. A good rule of thumb is 300 lines of code changes - once you get above 500 lines, you're entering unreviewable territory.&lt;/p&gt;&lt;head rend="h2"&gt;Telling a Story with Commits&lt;/head&gt;&lt;p&gt;A key part of having a reviewable PR is writing commits that tell a story. Present your changes incrementally and logically so reviewers can follow your thought process. Generic commit messages such as "add dependency," "implement file upload feature," and "address PR feedback" don’t tell much of a story and leave reviewers guessing. Why was the dependency added? What were the specific steps in creating the file uploader feature? What feedback is being addressed?&lt;/p&gt;&lt;head rend="h3"&gt;Story-Telling Commit Messages&lt;/head&gt;&lt;p&gt;After a toast to the demo gods, Saša demonstrated writing story-telling commits with a live coding example, creating a PR that was part of a larger feature. His example PR adds just 152 lines of code, removes 2 lines, but uses 13 thoughtful commits.&lt;/p&gt;&lt;p&gt;While some developers might understand those 152 lines from the final diff alone, I couldn't confidently approve it without the commit story.&lt;/p&gt;&lt;head rend="h3"&gt;Breaking Down the Example&lt;/head&gt;&lt;p&gt; For instance, looking at the overall diff, I didn't understand why he added &lt;code&gt;:runtime_tools&lt;/code&gt;
      to &lt;code&gt;applications&lt;/code&gt;
      in &lt;code&gt;mix.exs&lt;/code&gt;. Following the commit narrative, it's clear this was needed for access to
      &lt;code&gt;:scheduler.get_sample()&lt;/code&gt;
      to collect the samples. Now I can research that context or ask more pointed questions.
    &lt;/p&gt;&lt;head rend="h3"&gt;The Iterative Process&lt;/head&gt;&lt;p&gt;A huge benefit of seeing this live was witnessing the iterative process. In the compute average utilization commit, we initially saw an incorrect implementation that computed averages of all schedulers, including offline ones. When testing revealed unexpected results, Saša went back and updated both the code and the commit that originally implemented that function so the story remained coherent.&lt;/p&gt;&lt;p&gt;A flow that I find to work well for keeping commit history clean is with fixup commits. A fixup is a small commit that’s explicitly marked to be folded into an earlier commit during an interactive rebase. When you run rebase with autosquash, Git automatically pairs each fixup with its target and tucks the changes into the right place, keeping the story coherent without manual reordering.&lt;/p&gt;&lt;p&gt;I sometimes experience creating merge conflicts for myself during this process. Both Saša and I agree that if it becomes too much effort to resolve the conflict, then creating a new commit is ok. Taking the time to put in extra effort to keep the commit history clean and the story coherent makes the PR easier for reviewers to understand.&lt;/p&gt;&lt;head rend="h3"&gt;The Value of Clean History&lt;/head&gt;&lt;p&gt;Keeping the commit history clean connects to advice I've heard about ensuring every commit compiles and keeps the application runnable. I used to follow this loosely, but recent experiences with git bisect emphasized to me its importance. (If you are unfamiliar with git bisect , it's worth checking out; it uses a binary search algorithm to find which commit in your project's history introduced a bug.)&lt;/p&gt;&lt;p&gt;There are a few factors that make narrowing down when and how a regression was introduced more challenging. If a commit doesn't compile, I can't isolate whether the bug first appeared there. If the bug appeared in a commit that had hundreds of lines of code changed, determining which part of the commit is the issue requires significantly more reasoning. A clean commit history with messages that tell a story makes these kinds of investigations easier.&lt;/p&gt;&lt;head rend="h2"&gt;Making Review a Collaborative Success&lt;/head&gt;&lt;p&gt;When we present focused PRs with commits that tell clear stories, we get feedback sooner and our development cycles speed up. When reviewers understand our changes, we're more likely to receive valuable feedback instead of blanket approvals, and we're more likely to ship quality code. When our commits make sense, we can travel back in time as needed to understand how our codebase evolved.&lt;/p&gt;&lt;p&gt;Thanks to Saša's theatrical lesson, I will be more intentional about crafting commit stories. The next time you're preparing a PR, consider: Are you telling a story your reviewers can follow? Start small - maybe focus on just one aspect, like keeping PRs under that 300-line guideline or writing more descriptive commit messages. Your future reviewers (and your future debugging self) will thank you.&lt;/p&gt;&lt;head rend="h3"&gt;Resources&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;Git blame for showing which revision and author last modified each line of a file&lt;/item&gt;&lt;item&gt;Git rebase for cleaning up commit history&lt;/item&gt;&lt;item&gt;Git fixup for amending earlier commits&lt;/item&gt;&lt;item&gt;Git bisect for finding when bugs were introduced&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://meks.quest/blogs/the-theatre-of-pull-requests-and-code-review"/><published>2025-09-25T10:35:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45371309</id><title>The Wind, a Pole, and the Dragon</title><updated>2025-09-25T14:41:32.318795+00:00</updated><content>&lt;doc fingerprint="6a4e089e8ea011d4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The Wind, a Pole, and the Dragon&lt;/head&gt;
    &lt;p&gt;One of my favourite requests for help online comes from the shibboleth-users group, where someone Japanese used machine translation to ask about the following problem:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;At often, the goat-time install a error is vomit. To how many times like the wind, a pole, and the dragon? Install 2,3 repeat, spank, vomit blows&lt;/p&gt;14:14:01.869 - INFO [edu.internet2.middleware.shibboleth.common.config.profile.JSPErrorHandlerBeanDefinitionParser:45] Parsing configuration for JSP error handler.&lt;p&gt;Not precise the vomit but with aspect similar, is vomited concealed in fold of goat-time lumber? goat-time see like the wind, pole, and dragon? This insult to father’s stones? JSP error handler with wind, pole, dragon with intercourse to goat-time? Or chance lack of skill with a goat-time?&lt;/p&gt;&lt;p&gt;Please apologize for your stupidity. There are a many thank you&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;I have long wanted to figure out exactly how this went so wrong. Some parts are fairly clear:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;vomit could come from throw (as in throwing an error) or even just output.&lt;/item&gt;
      &lt;item&gt;lumber must clearly reference logs.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I have also heard speculation that goat-time means runtime, as in the Java runtime, perhaps. This means we can already figure out how we got to “vomited concealed in fold of goat-time lumber” – it’s an error hidden in the runtime logs.&lt;/p&gt;
    &lt;p&gt;I asked a few llms to assist me with the rest, and they universally think spank is an odd translation of hit, which is apparently used in Japanese to mean something like execute, and skill could be a mistranslation of experience.&lt;/p&gt;
    &lt;p&gt;We can start to put together what the message actually means.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Often when trying to install the runtime an error is thrown. uninterpretable I have tried reinstalling it three times, but when I run it an exception is thrown.&lt;/p&gt;
      &lt;p&gt;This is not the exact exception but something like that. Is the real error hidden in the runtime logs? uninterpretable. uninterpretable arising due to interaction with the runtime? Or perhaps my lack of experience with the runtime?&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The llms diverge on the meaning of “insult to father’s stones”. Some suggest the obvious thing, that it’d correspond to an idiomatic expression of frustration. Others seem to think it might be about “problems with the ancestral building blocks”, i.e. software dependencies. I liked that reading, but I have no idea.&lt;/p&gt;
    &lt;p&gt;New here? I apply the same weird curiosity to everything I discover. To learn something new, subscribe for weekly article summaries! If you don't like it, you can unsubscribe any time.&lt;/p&gt;
    &lt;p&gt;Then there’s “the wind, a pole, and the dragon.” I have yet to see anything come close to a reasonable answer. llms produce guesses referring to three parts of the configuration, variable names, dependencies, colloquialisms, descriptions of user interface, or abstract descriptions of how quickly things happen (the wind), a fixed point (a pole), and complexity/power (dragon). But again, I have no idea.&lt;/p&gt;
    &lt;p&gt;If you have more information, please reach out.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://entropicthoughts.com/the-wind-a-pole-and-the-dragon"/><published>2025-09-25T10:39:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45372113</id><title>Resurrect the Old Web</title><updated>2025-09-25T14:41:32.086367+00:00</updated><content>&lt;doc fingerprint="a79450e0583082e1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Resurrect the Old Web&lt;/head&gt;
    &lt;p&gt;Recently a local news station in Maine reported a story of some middle schoolers calling their friends with landline telephones. Their parents thought they were too young for cell phones and wanted to hold off on that aspect of reality, so they got an old phone from the 90s, and soon their friends also got phones. It formed schedules of calls they would make to talk to each other, even creating a phone ring of contacts.&lt;/p&gt;
    &lt;p&gt;I think I can confidently say that the majority of us aren't happy with the state of social media. Back in its early days it was fresh and exciting, a fun way to connect with your friends that might be far away, or make new friends online. It was cozy. No ads, no feeds, no endless videos. Instead it was just people, the whole reason you started in the first place. Now it's just noise and scary addicting and effective algorithms that keep you plugged in for hours on end. We build apps and products to help kill the monster, or perhaps we even delete some social media apps. Many of our friends we used to stay connected with seem so distant, as many of them too are tired and perhaps jumped off socials altogether. Well, what if I told you we could have the old web back?&lt;/p&gt;
    &lt;p&gt;In my opinion the answer is honestly pretty simple: blogs and RSS feeds. This was how it was done for years before social media came into the scene. You would find someone's blog, subscribe to their RSS feed, and anytime a new post came out it would pop up in your feed and you could read it. One important clarification is that when we say "blog" it can be pretty much whatever you want it to be. On my personal website I generally write more of my serious blogs, but on my bear blog I plan to be a bit more casual. It will be a place where I record short thoughts, ideas, musings, or cool things I find on the internet. Just sharing what I would normally share with my friends. That's what made the web great, and that's what I want to bring back.&lt;/p&gt;
    &lt;p&gt;To do this, I am starting a bear blog that will have a dedicated feeds page that will have all the other blogs I'm subscribing to. The beauty is that you don't need a dedicated social network to make this work; just click on the links. Use whatever RSS reader you want! You don't have to use bear blog either, just use whatever blog you want. The key is connection. I want to point to who I follow so that you might follow them too, and hopefully create a page on your own. In some ways it's bringing back old web rings and simple networking through hyperlinks.&lt;/p&gt;
    &lt;p&gt;To kick it off, here's a few blogs I'm already subscribed to:&lt;/p&gt;
    &lt;p&gt;If you want to join but not sure how, check out the video I recorded below:&lt;/p&gt;
    &lt;p&gt;Best way to keep up with your feeds is to find yourself an RSS reader! There are a lot of options out there (although admittedly a bit old), so just find it on the platform that suits you best. Feeder.co has a pretty generous free plan, and if you're a dev there's hundreds of self hosted projects to choose from like Yarr. Personally rocking NetNewsWire for MacOS and iOS, and loving it so far!&lt;/p&gt;
    &lt;p&gt;I have no idea if this will amount to anything or if it's worthwhile, but I'm gonna give it a shot. The landline phones prove that we don't have to buy into the social media dopamine machine. We have autonomy, and we have the freedom to choose how we interact with each other. I want to believe we can resurrect the old web, together.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://stevedylandev.bearblog.dev/resurrect-the-old-web/"/><published>2025-09-25T12:48:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45372286</id><title>Data Viz Color Palette Generator (For Charts and Dashboards)</title><updated>2025-09-25T14:41:31.947739+00:00</updated><content>&lt;doc fingerprint="32a83ff73ed5803d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Palette Generator&lt;/head&gt;
    &lt;head rend="h3"&gt;Number of Colors&lt;/head&gt;
    &lt;head rend="h3"&gt;Background Color&lt;/head&gt;
    &lt;head rend="h2"&gt;In Context&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;Use the palette chooser to create a series of colors that are visually equidistant. This is useful for many data visualizations, like pie charts, grouped bar charts, and maps.&lt;/p&gt;
    &lt;p&gt;Note: there are two other modes besides palette mode – check out single-hue scales and divergent scales as well.&lt;/p&gt;
    &lt;p&gt;Creating visually equidistant palettes is basically impossible to do by hand, yet hugely important for data visualizations. Why? When colors are not visually equidistant, it’s harder to (a) tell them apart in the chart, and (b) compare the chart to the key. I’m sure we’ve all looked at charts where you can hardly use the key since the data colors are so similar.&lt;/p&gt;
    &lt;p&gt;For instance, Google Analytics does a terrible job with this:&lt;/p&gt;
    &lt;p&gt;It’s better to use use a range of hues so users can cross-reference with the key easier. It’s far simpler for our brains to distinguish, say, yellow from orange than blue from blue-but-15%-lighter.&lt;/p&gt;
    &lt;p&gt;This color picker allows you to specify both endpoints of the palette. You can choose at least one to be a brand color, which gives you significant flexibility in creating a palette that will work for your visualizations, yet be customized for your brand.&lt;/p&gt;
    &lt;p&gt;Here are a few tips for getting the best palette:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Try picking very different endpoint colors – e.g. one warm, one cool; one bright, one darker – so that your palette covers a wider range&lt;/item&gt;
      &lt;item&gt;If you’re using a brand color for one endpoint, don’t be afraid to modify the saturation and brightness a bit if it creates a more pleasing palette. Users will recognize your brand color by its hue much far more than by it’s exact saturation/brightness.&lt;/item&gt;
      &lt;item&gt;For data visualizations where you’re showing the strength of a single value, try using the Single Hue Palette Generator instead.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Oh, and...&lt;/p&gt;
    &lt;head rend="h2"&gt;More on Color&lt;/head&gt;
    &lt;p&gt;If you're new to color in UI design, I highly recommend the following resources:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The HSB Color System: A Practitioner's Primer&lt;/item&gt;
      &lt;item&gt;Color in UI Design: A Practical Framework&lt;/item&gt;
      &lt;item&gt;Gradient Generator tool, by yours truly, built to be the most fully-featured on the web 😎&lt;/item&gt;
      &lt;item&gt;Design Hacks, my email newsletter where I send original design tips and tactics to 60,000+ of my closest friends.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Anyhow, I've created this to be the tool I wish I had for creating data visualization palettes. Is there another feature you'd like to see in it? Let me know.&lt;/p&gt;
    &lt;head rend="h1"&gt;Single Hue Scale&lt;/head&gt;
    &lt;head rend="h3"&gt;Number of Colors&lt;/head&gt;
    &lt;head rend="h3"&gt;Modify Color Scale&lt;/head&gt;
    &lt;p&gt;Brightness&lt;/p&gt;
    &lt;p&gt;Color Intensity&lt;/p&gt;
    &lt;head rend="h3"&gt;Background Color&lt;/head&gt;
    &lt;head rend="h2"&gt;In Context&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;The Single Hue Scale generator is most useful for visualizations where you’re showing the value of a single variable. Typically, the darker variation will represent a higher value, and a neutral color (even white) will represent a value closer to zero.&lt;/p&gt;
    &lt;p&gt;In a pie chart or bar chart, size is used to distinguish higher values. But in some visualizations, the size is set and you need to rely on color. Two examples of this are show in the “In Context” section above:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;A map in which size represents county size; we need to use color to distinguish the value for each county&lt;/item&gt;
      &lt;item&gt;A week-by-week calendar in which each day is an equally sized box; we need to use color to show the value for a particular day&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Here are a few tips for getting the best single hue scale:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To transition to a flat gray endpoint, set “Color Intensity” to zero&lt;/item&gt;
      &lt;item&gt;To transition to a white endpoint, set “Brightness” to full and “Color Intensity” to zero&lt;/item&gt;
      &lt;item&gt;If your color scale actually shows a variable that transitions from one end to a neutral midpoint to another end, try the Divergent Scale Generator (e.g. Republican to moderate to Democrat; hotter to same-temperature to cooler)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Divergent Color Scale&lt;/head&gt;
    &lt;head rend="h3"&gt;Number of Colors&lt;/head&gt;
    &lt;head rend="h3"&gt;Modify Midpoint Color&lt;/head&gt;
    &lt;p&gt;Brightness&lt;/p&gt;
    &lt;p&gt;Color Intensity&lt;/p&gt;
    &lt;head rend="h3"&gt;Background Color&lt;/head&gt;
    &lt;head rend="h2"&gt;In Context&lt;/head&gt;
    &lt;head rend="h2"&gt;How to Use&lt;/head&gt;
    &lt;p&gt;The Divergent Color Scale generator is most useful for visualizations where you’re showing a transition from (a) one extreme, through a (b) neutral middle, and finally to a (c) opposite extreme.&lt;/p&gt;
    &lt;p&gt;Perhaps the most common example of this is the “how Democrat/Republican is each state in the US” chart.&lt;/p&gt;
    &lt;p&gt;By default, the neutral midpoint is a light gray. You can change it with the "Modify Midpoint Color" sliders to be slightly darker or more colorful. For the best results, set the Color Intensity to the minimum when the two endpoint hues are significantly different – otherwise, the moderate tones will start to blend together (this will be evident in the map).&lt;/p&gt;
    &lt;p&gt;As with the other visualization styles, this will pick colors that are visually equidistant. However, if one of the two endpoint colors is significantly darker or saturated, the swatches on that side will have more color-space between them.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.learnui.design/tools/data-color-picker.html"/><published>2025-09-25T13:13:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45372361</id><title>As many as 2M Cisco devices affected by actively exploited 0-day</title><updated>2025-09-25T14:41:31.659344+00:00</updated><content>&lt;doc fingerprint="f4031106c911d3ab"&gt;
  &lt;main&gt;
    &lt;p&gt;As many as 2 million Cisco devices are susceptible to an actively exploited zeroday that can remotely crash or execute code on vulnerable systems.&lt;/p&gt;
    &lt;p&gt;Cisco said Wednesday that the vulnerability, tracked as CVE-2025-20352, was present in all supported versions of Cisco IOS and Cisco IOS XE, the operating system that powers a wide variety of the company’s networking devices. The vulnerability can be exploited by low-privileged users to create a denial-of-service attack or by higher-privileged users to execute code that runs with unfettered root privileges. It carries a severity rating of 7.7 out of a possible 10.&lt;/p&gt;
    &lt;head rend="h2"&gt;Exposing SNMP to the Internet? Yep&lt;/head&gt;
    &lt;p&gt;“The Cisco Product Security Incident Response Team (PSIRT) became aware of successful exploitation of this vulnerability in the wild after local Administrator credentials were compromised,” Wednesday’s advisory stated. “Cisco strongly recommends that customers upgrade to a fixed software release to remediate this vulnerability.”&lt;/p&gt;
    &lt;p&gt;The vulnerability is the result of a stack overflow bug in the IOS component that handles SNMP (simple network management protocol), which routers and other devices use to collect and handle information about devices inside a network. The vulnerability is exploited by sending crafted SNMP packets.&lt;/p&gt;
    &lt;p&gt;To execute malicious code, the remote attacker must have possession of read-only community string, an SNMP-specific form of authentication for accessing managed devices. Frequently, such strings ship with devices. Even when modified by an administrator, read-only community strings are often widely known inside an organization. The attacker would also require privileges on the vulnerable systems. With that, the attacker can obtain RCE (remote code execution) capabilities that run as root.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/security/2025/09/as-many-as-2-million-cisco-devices-affected-by-actively-exploited-0-day/"/><published>2025-09-25T13:22:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45372442</id><title>Death rates rose in hospital ERs after private equity firms took over</title><updated>2025-09-25T14:41:30.741169+00:00</updated><content>&lt;doc fingerprint="2dc0956e36b12786"&gt;
  &lt;main&gt;
    &lt;p&gt;After hospitals were acquired by private equity firms, patient death rates in the emergency departments rose by 13% compared with similar hospitals, according to research published this week in Annals of Internal Medicine.&lt;/p&gt;
    &lt;p&gt;The research, which compared outcomes at hospitals over a 10-year period, adds fresh evidence to previous studies showing harmful patient outcomes and higher costs among health care entities owned by profit-oriented financiers.&lt;/p&gt;
    &lt;p&gt;The increased deaths in emergency departments at private equity-owned hospitals are most likely the result of reduced staffing levels after the acquisitions, which the study also measured, said Dr. Zirui Song, a co-author and associate professor of health care policy and medicine at Harvard Medical School.&lt;/p&gt;
    &lt;p&gt;After hospitals were acquired by private equity, the number of full-time employees fell by an average 11.6% compared with non-private equity facilities, the research found, and salary expenditures in the emergency departments and intensive care units declined by 18% and 16%, respectively.&lt;/p&gt;
    &lt;p&gt;“Most hospital care in the country remains a face-to-face, human, labor-intensive endeavor, especially in emergency departments and ICUs,” Song said in an interview. “When human labor is cut to this extent in staffing sensitive areas of the hospital, patient harm can plausibly ensue, including mortality.”&lt;/p&gt;
    &lt;p&gt;The new study analyzed 1 million emergency department visits by Medicare patients at 49 private equity-owned hospitals from 2009 through 2019. The researchers compared the outcomes of those visits with more than 6 million visits at 293 matched hospitals — those of similar size and location — not acquired by private equity.&lt;/p&gt;
    &lt;p&gt;The study’s co-authors, in addition to Song, are José R. Zubizarreta of Harvard University, Dr. Sneha Kannan of the University of Pittsburgh, Joseph Dov Bruch of the University of Chicago and Dr. Jennifer Stevens, director of the Center for Healthcare Delivery Science at Beth Israel Deaconess Medical Center in Boston.&lt;/p&gt;
    &lt;p&gt;Song said the new research differed from previous studies on private equity’s impact, which focused on patients who were admitted to the hospital.&lt;/p&gt;
    &lt;p&gt;“There are far more patients who come into the emergency department than patients who are actually admitted into the wards of the hospital,” Song said, “so this study looks at a patient population that had not been examined in great depth before.”&lt;/p&gt;
    &lt;p&gt;Private equity firms are sophisticated financial operators that buy companies, typically loading them with large amounts of debt to pay for the acquisitions. The firms hope to sell the companies for profit a few years later.&lt;/p&gt;
    &lt;p&gt;The private equity industry has poured over $1 trillion into health care companies in recent years. Health care has been a focus of the financiers because it accounts for 18% of gross domestic product in the United States.&lt;/p&gt;
    &lt;p&gt;Because their acquisitions add debt costs to the companies they buy, those operations must cut other expenses to offset the burden. Employees are often the first to be fired, and costs are often increased to generate higher profits. Some hospitals owned by private-equity firms sell the land under their buildings, enriching the owners but saddling the facilities with higher rent costs.&lt;/p&gt;
    &lt;p&gt;Dr. Robert McNamara, chairman of the department of emergency medicine at Temple University’s Lewis Katz School of Medicine, said the new research confirms what doctors in the field have long complained about: being stretched too thin by private equity owners.&lt;/p&gt;
    &lt;p&gt;“When private equity comes in, they try to jack up the revenues and then, when that reaches an end point, they start slashing expenses,” McNamara said in an interview. “Instead of people just losing their jobs, you have bad patient outcomes here. Less staff equals worse outcomes.”&lt;/p&gt;
    &lt;p&gt;The new research on increased deaths in emergency departments at private equity-owned hospitals aligns with a 2021 study that found 11% higher mortality rates at nursing homes owned by private equity. That study, by academics at New York University, the University of Chicago and the University of Pennsylvania, concluded that lower nursing staffs and declines in compliance with care standards contributed to the increased deaths at financier-owned homes.&lt;/p&gt;
    &lt;p&gt;Some states are enacting laws to rein in private equity’s impact on health care. In June, Oregon enacted a law limiting the control corporations and private equity can have over health care operations. And in Indiana, a new law expands the attorney general’s powers to investigate health care transactions and mandates reporting on ownership stakes in health care entities by private equity investors and other owners.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nbcnews.com/news/us-news/death-rates-rose-hospital-ers-private-equity-firms-took-study-finds-rcna233211"/><published>2025-09-25T13:32:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45372515</id><title>Apple says it may stop shipping to the EU</title><updated>2025-09-25T14:41:30.609946+00:00</updated><content>&lt;doc fingerprint="84cca83c932d196c"&gt;
  &lt;main&gt;
    &lt;p&gt;Apple has called for the European Commission to repeal a swathe of technology legislation, warning that unless it is amended the company could stop shipping some products and services to the 27-country bloc.&lt;/p&gt;
    &lt;p&gt;In the latest of a series of clashes with Brussels, the iPhone maker said the Digital Markets Act was leading to a worse experience for Apple users, exposing them to security risks, and disrupting the seamless way Apple products work together.&lt;/p&gt;
    &lt;p&gt;The Silicon Valley company hit out in a submission to the commission’s review of the three-year-old anti-monopoly legislation, which is intended to regulate the gatekeeper power of the largest digital companies including search engines, app providers and messaging services.&lt;/p&gt;
    &lt;p&gt;It said it had already delayed the launch of features such as live translation through AirPods and mirroring iPhone screens on to laptop because of the act’s demands for interoperability with non-Apple products and services.&lt;/p&gt;
    &lt;p&gt;“The DMA means the list of delayed features in the EU will probably get longer, and our EU users’ experience on Apple products will fall further behind,” it said. Apple added that Brussels was creating unfair competition as the rules were not applied to Samsung, the largest smartphone provider in the EU.&lt;/p&gt;
    &lt;p&gt;Among the requirements of the DMA is that Apple ensures that headphones made by other brands will work with iPhones. It said this has been a block on it releasing its live translation service in the EU as it allows rival companies to access data from conversations, creating a privacy problem.&lt;/p&gt;
    &lt;p&gt;Apple said the DMA should be repealed or, at a minimum, replaced with more appropriate legislation. It did not specify which products could in future be prevented from being distributed in the EU, but said that the Apple Watch, first released a decade ago, might not be released today in the EU.&lt;/p&gt;
    &lt;p&gt;It is the latest clash between the California-based company and the European Commission. Earlier this year, Apple launched an appeal against a €500m fine imposed by the EU for allegedly preventing app developers from steering users to cheaper deals outside the app store.&lt;/p&gt;
    &lt;p&gt;In August the US president, Donald Trump, threatened tariffs against unspecified nations in retaliation to rules binding US tech companies.&lt;/p&gt;
    &lt;p&gt;He said in a post on Truth Social: “I will stand up to Countries that attack our incredible American Tech Companies. Digital Taxes, Digital Services Legislation, and Digital Markets Regulations are all designed to harm, or discriminate against, American Technology.&lt;/p&gt;
    &lt;p&gt;“They also, outrageously, give a complete pass to China’s largest Tech Companies. This must end, and end NOW!”&lt;/p&gt;
    &lt;p&gt;Apple said that under the DMA, “instead of competing by innovating, already successful companies are twisting the law to suit their own agendas – to collect more data from EU citizens, or to get Apple’s technology for free”.&lt;/p&gt;
    &lt;p&gt;It said that rules under the act affected the way it provided users access to apps. “Pornography apps are available on iPhone from other marketplaces – apps we’ve never allowed on the App Store because of the risks they create, especially for children,” it said.&lt;/p&gt;
    &lt;p&gt;The European Commission was approached for comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theguardian.com/technology/2025/sep/25/apple-calls-for-changes-to-anti-monopoly-laws-and-says-it-may-stop-shipping-to-the-eu"/><published>2025-09-25T13:38:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45372767</id><title>U.S. Military Was Caught Off Guard by Israeli Strike on Qatar</title><updated>2025-09-25T14:41:30.412748+00:00</updated><content>&lt;doc fingerprint="bdc892582047f6ff"&gt;
  &lt;main&gt;
    &lt;p&gt;The U.S. military was unaware of the unprecedented Israeli ballistic missile strike earlier this month on a Hamas compound in Doha, Qatar, until it was already inbound, one of its senior leaders has confirmed. The situation was further compounded by attention being focused on threats emanating from Iran.&lt;/p&gt;
    &lt;p&gt;In the aftermath of the attack, there had been questions as to why the various highly advanced air defense systems and sensors, both American and Qatari, which would normally provide alert to an impending attack on Qatar, had not provided warning and defense. Now we have a better understanding of what happened from a U.S. perspective.&lt;/p&gt;
    &lt;p&gt;You can read our initial reporting on the Israeli raid on Doha on September 9 here, as well as our follow-up, which looked at the degree of damage inflicted, here.&lt;/p&gt;
    &lt;p&gt;Lt. Gen. Derek C. France, the commander of Air Forces Central (AFCENT) and the Combined Forces Air Component Commander for U.S. Central Command, was discussing the implications of the Israeli airstrike at the Air, Space &amp;amp; Cyber Conference in National Harbor, Maryland, today.&lt;/p&gt;
    &lt;p&gt;“This strike that Israel did against the Hamas target in Doha was something that we had no indications and warnings of, because our surveillance and all our attention was not put on [it],” Lt. Gen. France said. “It wasn’t something that we expected.”&lt;/p&gt;
    &lt;p&gt;Qatar is a key U.S. partner in the Middle East. Al Udeid Air Base in the country is a major hub for U.S. military operations in the region, which was notably subjected to an Iranian missile barrage back in June.&lt;/p&gt;
    &lt;p&gt;“I can say that we did not get a warning about this happening,” Lt. Gen. France stressed. “Our systems were the first indication that we had. And then there was discussion at some point with my counterparts in Israel, but our systems noting the attack was underway was the first indication we got.”&lt;/p&gt;
    &lt;p&gt;The AFCENT boss further confirmed that “while we have exquisite systems and things that can detect a lot of different things, those things are typically focused on Iran and other things where we expect an attack to come from.”&lt;/p&gt;
    &lt;p&gt;This is a reality we had pointed out in the aftermath of the attack, as well.&lt;/p&gt;
    &lt;p&gt;The lack of warning of the Israeli airstrike is, Lt. Gen. France said, the major operational lesson learned. He noted “the importance of indications and warnings and having the right systems, whether that’s space-based, air-based, non-traditional, to understand those attacks as they’re happening.”&lt;/p&gt;
    &lt;p&gt;Lt. Gen. France’s comment about “our systems were the first indication” that some kind of attack on Qatar was in progress makes sense. The U.S. military has the ability to detect the launch of ballistic missiles globally, but tracking them during their post-boost midcourse voyage at very high altitude is a more limited capability. The Pentagon hopes to change this in the future by quickly developing and deploying a space-based tracking layer that can follow ballistic missiles during their midcourse journey.&lt;/p&gt;
    &lt;p&gt;“Although they knew it was happening because of those detection systems, it was from a source and a direction that we weren’t expecting,” he continued.&lt;/p&gt;
    &lt;p&gt;Speaking today, Lt. Gen. France added, “The sensing capability is there. It’s not so much a direction kind of thing. It’s what we were overall expecting to happen and having those indications of warnings that are out there.”&lt;/p&gt;
    &lt;p&gt;Israeli officials said the Doha strike was carried out by 15 Israeli fighter jets, firing 10 precision munitions against a single target, the BBC reported, citing Israeli media.&lt;/p&gt;
    &lt;p&gt;The Israeli Air Force (IAF) fighters were over the Red Sea when they fired air-launched ballistic missiles, an unnamed U.S. defense official told the Associated Press. In this way, Israeli aircraft didn’t need to enter the airspace of any Middle East country, and the missiles arrived from a direction that the air defenses in Qatar were not focused on looking. The missiles would have also passed over Saudi Arabia at very high altitudes, likely outside the Earth’s atmosphere.&lt;/p&gt;
    &lt;p&gt;ALBMs available to the IAF include an air-launched version of the Israel Aerospace Industries (IAI) LORA (Long Range Artillery), a short-range ballistic missile originally developed for surface launch. There is also the Rafael Rocks, that was developed from Israel’s line of Sparrow ballistic missile test targets. Meanwhile, the Israel Military Industries (IMI) Rampage, which is based on a guided artillery rocket, would not be relevant here due to the long ranges involved. Israel’s highly precise air-launched ballistic missiles have quickly become critical and somewhat famous weapons after their use on Iran on multiple occasions, and especially during the war between it and Israel in June.&lt;/p&gt;
    &lt;p&gt;The IAF hit a compound where negotiators for Hamas were meeting to consider a Gaza ceasefire proposal put forward by the U.S. government. The attack killed six people.&lt;/p&gt;
    &lt;p&gt;According to White House spokesperson Karoline Leavitt, U.S. President Donald Trump “was informed of the impending strike by his military and alerted Qatar’s leadership,” although the timeline for this remains unclear.&lt;/p&gt;
    &lt;p&gt;For their part, Qatari officials claimed that they only found out about the attack after it had begun.&lt;/p&gt;
    &lt;p&gt;Other than preparedness for unexpected eventualities, in terms of potential attacks, Lt. Gen. France explained that the other important lesson learned is how the U.S. military communicates and coordinates with its Qatari partners and other partners in the Gulf.&lt;/p&gt;
    &lt;p&gt;With that in mind, Lt. Gen. France said that integrated air and missile defense is one of his main areas of focus. “That we can do that in as integrated a fashion as possible with our partners in the Gulf. And that starts with interoperable equipment. So when they buy U.S. Patriot [air defense systems], and we have U.S. Patriots, the degree that we can operate efficiently together is a big part of what we’re pushing in the theater.”&lt;/p&gt;
    &lt;p&gt;Lt. Gen. France also said he wasn’t concerned about future U.S. military access to Qatar following Israel’s airstrike on Doha, although he admitted that “there certainly is some tension as a result of that, in my mind, goes to the importance of developing relationships and having presence that matters.”&lt;/p&gt;
    &lt;p&gt;Reflecting the importance of those relationships, Lt. Gen. France confirmed that he had a conversation with the Qatari Air Chief “right immediately after that happened” on September 9.&lt;/p&gt;
    &lt;p&gt;Lt. Gen. France’s remarks today shed some more light on the mystery of how Israel pulled off its strike in Qatar, although there remain unresolved details. With more time, we may well learn more details about this unprecedented operation, one that succeeded in catching both the U.S. and Qatari militaries almost entirely off guard.&lt;/p&gt;
    &lt;p&gt;Contact the author: thomas@thewarzone.com&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.twz.com/air/new-info-on-how-u-s-military-was-caught-off-guard-by-israeli-strike-on-qatar"/><published>2025-09-25T14:04:50+00:00</published></entry></feed>