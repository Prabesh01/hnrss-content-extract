<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2026-01-16T23:39:13.975024+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=46645176</id><title>Why DuckDB is my first choice for data processing</title><updated>2026-01-16T23:39:20.708535+00:00</updated><content>&lt;doc fingerprint="f73b88c145a718b4"&gt;
  &lt;main&gt;&lt;p&gt;Originally posted: 2025-03-16. View source code for this page here.&lt;/p&gt;&lt;p&gt;Over the past few years, I've found myself using DuckDB more and more for data processing, to the point where I now use it almost exclusively, usually from within Python.&lt;/p&gt;&lt;p&gt;We're moving towards a simpler world where most tabular data can be processed on a single large machine1 and the era of clusters is coming to an end for all but the largest datasets.2&lt;/p&gt;&lt;p&gt;This post sets out some of my favourite features of DuckDB that set it apart from other SQL-based tools. In a nutshell, it's simple to install, ergonomic, fast, and more fully featured.&lt;/p&gt;&lt;p&gt;An earlier post explains why I favour SQL over other APIs such as Polars, pandas or dplyr.&lt;/p&gt;&lt;p&gt;DuckDB is an open source in-process SQL engine that is optimised for analytics queries.&lt;/p&gt;&lt;p&gt;The performance difference of analytics-optimised engines (OLAP) vs. transactions-optimised engines (OLTP) should not be underestimated. A query running in DuckDB can be 100 or even 1,000 times faster than exactly the same query running in (say) SQLite or Postgres.&lt;/p&gt;&lt;p&gt;A core use-case of DuckDB is where you have one or more large datasets on disk in formats like &lt;code&gt;csv&lt;/code&gt;, &lt;code&gt;parquet&lt;/code&gt; or &lt;code&gt;json&lt;/code&gt; which you want to batch process.  You may want to perform cleaning, joins, aggregation, derivation of new columns - that sort of thing.&lt;/p&gt;&lt;p&gt;But you can also use DuckDB for many other simpler tasks like viewing a csv file from the command line.&lt;/p&gt;&lt;p&gt;DuckDB consistently benchmarks as one of the fastest data processing engines. The benchmarks I've seen3 show there's not much in it between the leading open source engines - which at the moment seem to be polars, DuckDB, DataFusion, Spark and Dask. Spark and Dask can be competitive on large data, but slower on small data.&lt;/p&gt;&lt;p&gt;DuckDB itself is a single precompiled binary. In Python, it can be &lt;code&gt;pip install&lt;/code&gt;ed with no dependencies.  This makes it a joy to install compared to other more heavyweight options like Spark.  Combined with &lt;code&gt;uv&lt;/code&gt;, you can stand up a fresh DuckDB Python environment from nothing in less than a second - see here.&lt;/p&gt;&lt;p&gt;With its speed and almost-zero startup time, DuckDB is ideally suited for CI and testing of data engineering pipelines.&lt;/p&gt;&lt;p&gt;Historically this has been fiddly and running a large suite of tests in e.g. Apache Spark has been time consuming and frustrating. Now it's much simpler to set up the test environment, and there's less scope for differences between it and your production pipelines.&lt;/p&gt;&lt;p&gt;This simplicity and speed also applies to writing new SQL, and getting syntax right before running it on a large dataset. Historically I have found this annoying in engines like Spark (where it takes a few seconds to start Spark in local mode), or even worse when you're forced to run queries in a proprietary tool like AWS Athena.4&lt;/p&gt;&lt;p&gt;There's even a DuckDB UI with autocomplete - see here.&lt;/p&gt;&lt;p&gt;The DuckDB team has implemented a wide range of innovations in its SQL dialect that make it a joy to use. See the following blog posts 1 2 3 4 5 6.&lt;/p&gt;&lt;p&gt;Some of my favourites are the &lt;code&gt;EXCLUDE&lt;/code&gt; keyword, and the &lt;code&gt;COLUMNS&lt;/code&gt; keyword which allows you to select and regex-replace a subset of columns.5  I also like &lt;code&gt;QUALIFY&lt;/code&gt; and the aggregate modifiers on window functions, see here.&lt;/p&gt;&lt;p&gt;Another is the ability to function chain, like &lt;code&gt;first_name.lower().trim()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;You can query data directly from files, including on s3, or on the web.&lt;/p&gt;&lt;p&gt;For example to query a folder of parquet files:&lt;/p&gt;&lt;quote&gt;select *from read_parquet('path/to/*.parquet')&lt;/quote&gt;&lt;p&gt;or even (on CORS enabled files) you can run SQL directly:&lt;/p&gt;&lt;quote&gt;select *from read_parquet('https://raw.githubusercontent.com/plotly/datasets/master/2015_flights.parquet')limit 2;&lt;/quote&gt;&lt;p&gt;Click here to try this query yourself in the DuckDB web shell.&lt;/p&gt;&lt;p&gt;One of the easiest ways to cause problems in your data pipelines is to fail to be strict about incoming data types from untyped formats such as csv. DuckDB provides lots of options here - see here.&lt;/p&gt;&lt;p&gt;Many data pipelines effectively boil down to a long sequence of CTEs:&lt;/p&gt;&lt;quote&gt;WITHinput_data AS (SELECT * FROM read_parquet('...')),step_1 AS (SELECT ... FROM input_data JOIN ...),step_2 AS (SELECT ... FROM step_1)SELECT ... FROM step_2;&lt;/quote&gt;&lt;p&gt;When developing a pipeline like this, we often want to inspect what's happened at each step.&lt;/p&gt;&lt;p&gt;In Python, we can write&lt;/p&gt;&lt;quote&gt;input_data = duckdb.sql("SELECT * FROM read_parquet('...')")step_1 = duckdb.sql("SELECT ... FROM input_data JOIN ...")step_2 = duckdb.sql("SELECT ... FROM step_1")final = duckdb.sql("SELECT ... FROM step_2;")&lt;/quote&gt;&lt;p&gt;This makes it easy to inspect what the data looks like at &lt;code&gt;step_2&lt;/code&gt; with no performance loss, since these steps will be executed lazily when they're run all at once.&lt;/p&gt;&lt;p&gt;This also facilitates easier testing of SQL in CI, since each step can be an independently-tested function.&lt;/p&gt;&lt;p&gt;DuckDB offers full ACID compliance for bulk data operations, which sets it apart from other analytical data systems - see here. You can listen to more about this on in this podcast, transcribed here.&lt;/p&gt;&lt;p&gt;This is a very interesting new development, making DuckDB potentially a suitable replacement for lakehouse formats such as Iceberg or Delta lake for medium scale data.&lt;/p&gt;&lt;p&gt;A longstanding difficulty with data processing engines has been the difficulty in writing high performance user defined functions (UDFs).&lt;/p&gt;&lt;p&gt;For example, in PySpark, you will generally get best performance by writing custom Scala, compiling to a JAR, and registering it with Spark. But this is cumbersome and in practice, you will encounter a lot of issues around Spark version compatibility and security restrictions environments such as DataBricks.&lt;/p&gt;&lt;p&gt;In DuckDB high performance custom UDFs can be written in C++. Whilst writing these functions is certainly not trivial, DuckDB community extensions offers a low-friction way of distributing the code. Community extensions can be installed almost instantly with a single command such as &lt;code&gt;INSTALL h3 FROM community&lt;/code&gt; to install hierarchical hexagonal indexing for geospatial data.&lt;/p&gt;&lt;p&gt;The team provide documentation as a single markdown file so it can easily be provided to an LLM.&lt;/p&gt;&lt;p&gt;My top tip: if you load this file in your code editor, and use code folding, it's easy to copy the parts of the documentation you need into context.&lt;/p&gt;&lt;p&gt;Much of this blog post is based on my experience supporting multiple SQL dialects in Splink, an open source library for record linkage at scale. We've found that transitioning towards recommending DuckDB as the default backend choice has increased adoption of the library and significantly reduced the amount of problems faced by users, even for large linkage tasks, whilst speeding up workloads very substantially.&lt;/p&gt;&lt;p&gt;We've also found it's hugely increased the simplicity and speed of developing and testing new features.&lt;/p&gt;&lt;code&gt;pg_duckdb&lt;/code&gt; allows you to embed the DuckDB computation engine within Postgres.&lt;p&gt;The later in particular seems potentially extremely powerful, enabling Postgres to be simultanouesly optimised for analytics and transactional processing. I think it's likely to see widespread adoption, especially after they iron out a few of the current shortcomings around enabling and optimising the use of Postgres indexes and pushing up filters up to PostGres.&lt;/p&gt;&lt;p&gt;As a long-time Spark user, I am glad to be rid of needing to know lots of intricate configuration options for Spark tuning ÔøΩÔøΩ‚Ü©&lt;/p&gt;&lt;p&gt;With 192 core processors such as this available in the cloud and only costing around $15,000, the complexity of clusters can be avoided unless you have genuinely huge data. It's also worth noting there is actually now a distributed version of DuckDB, see here. ‚Ü©&lt;/p&gt;&lt;p&gt;For instance see here, here and here/discussion. ‚Ü©&lt;/p&gt;&lt;p&gt;To be clear, Athena is a very powerful and useful tool. I just find it frustrating for developing and quickly iterating queries of moderate complexity. An example of why it's easier in DuckDB is this kind of reprex. ‚Ü©&lt;/p&gt;&lt;p&gt;For instance, we can select all columns prefixed with &lt;code&gt;emp_&lt;/code&gt; and rename to remove the prefix as follows: &lt;code&gt;SELECT COLUMNS('emp_(.*)') AS '\1'&lt;/code&gt; ‚Ü©&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.robinlinacre.com/recommend_duckdb/"/><published>2026-01-16T10:57:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46645615</id><title>Just the Browser</title><updated>2026-01-16T23:39:20.550909+00:00</updated><content>&lt;doc fingerprint="1642ce52fea7b9c8"&gt;
  &lt;main&gt;
    &lt;p&gt;Just the Browser helps you remove AI features, telemetry data reporting, sponsored content, product integrations, and other annoyances from desktop web browsers. The goal is to give you "just the browser" and nothing else, using hidden settings in web browsers intended for companies and other organizations.&lt;/p&gt;
    &lt;p&gt;This project includes configuration files for popular web browsers, documentation for installing and modifying them, and easy installation scripts. Everything is open-source on GitHub.&lt;/p&gt;
    &lt;head rend="h2"&gt;Get started&lt;/head&gt;
    &lt;p&gt;The setup script can install the configuration files in a few clicks. You can also follow the manual guides for Google Chrome, Microsoft Edge, and Firefox.&lt;/p&gt;
    &lt;p&gt;Windows: Open a PowerShell prompt as Administrator. You can do this by right-clicking the Windows button in the taskbar, then selecting the "Terminal (Admin)" or "PowerShell (Admin)" menu option. Next, copy the below command, paste it into the window (&lt;code&gt;Ctrl+V&lt;/code&gt;), and press the Enter/Return key:&lt;/p&gt;
    &lt;code&gt;&amp;amp; ([scriptblock]::Create((irm "https://raw.githubusercontent.com/corbindavenport/just-the-browser/main/main.ps1")))
&lt;/code&gt;
    &lt;p&gt;Mac and Linux: Search for the Terminal in your applications list and open it. Next, copy the below command, paste it into the window (&lt;code&gt;Ctrl+V&lt;/code&gt; or &lt;code&gt;Cmd+V&lt;/code&gt;), and press the Enter/Return key:&lt;/p&gt;
    &lt;code&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/corbindavenport/just-the-browser/main/main.sh)"
&lt;/code&gt;
    &lt;head rend="h2"&gt;Download web browsers&lt;/head&gt;
    &lt;p&gt;Start here if you don't have your preferred web browser installed. You can install the configuration files afterwards.&lt;/p&gt;
    &lt;head rend="h3"&gt;Google Chrome&lt;/head&gt;
    &lt;p&gt;macOS (Universal) Windows 64-bit x86 (amd64) Windows 32-bit x86 Windows 64-bit ARM (ARM64) Debian/Ubuntu 64-bit x86 (amd64) Fedora/openSUSE 64-bit x86 (amd64)&lt;/p&gt;
    &lt;p&gt;Not sure which link to use? Try the official download page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Mozilla Firefox&lt;/head&gt;
    &lt;p&gt;macOS (Universal) Windows 64-bit x86 (amd64) Windows 32-bit x86 Windows 64-bit ARM (ARM64)&lt;/p&gt;
    &lt;p&gt;Not sure which link to use? Try the official download page or Linux setup instructions.&lt;/p&gt;
    &lt;head rend="h3"&gt;Microsoft Edge&lt;/head&gt;
    &lt;p&gt;macOS (Universal) Windows 64-bit x86 (amd64) Windows 32-bit x86 Windows 64-bit ARM (ARM64)&lt;/p&gt;
    &lt;p&gt;Not sure which link to use? Try the official download page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Questions and answers&lt;/head&gt;
    &lt;p&gt;Got a question? Check here first, and if you still need help, create an issue on GitHub or join the Discord.&lt;/p&gt;
    &lt;head rend="h3"&gt;What features or settings are changed?&lt;/head&gt;
    &lt;p&gt;Just the Browser aims to remove the following functionality from popular web browsers:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Most AI features: Features that use generative AI models, either on-device or in the cloud, like Copilot in Microsoft Edge or tab group suggestions in Firefox. The main exception is page translation in Firefox.&lt;/item&gt;
      &lt;item&gt;Shopping features: Price tracking, coupon codes, loan integrations, etc.&lt;/item&gt;
      &lt;item&gt;Sponsored or third-party content: Suggested articles on the New Tab Page, sponsored site suggestions, etc.&lt;/item&gt;
      &lt;item&gt;Default browser reminders: Pop-ups or other prompts that ask you to change the default web browser.&lt;/item&gt;
      &lt;item&gt;First-run experiences and data import prompts: Browser welcome screens and their related prompts to import data automatically from other web browsers.&lt;/item&gt;
      &lt;item&gt;Telemetry: Data collection by web browsers. Crash reporting is left enabled if the browser (such as Firefox) supports it as a separate option.&lt;/item&gt;
      &lt;item&gt;Startup boost: Features that allow web browsers to start with the operating system without explicit permission.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The exact list of features modified for each browser can be found on the pages for Google Chrome, Microsoft Edge, and Firefox.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can I change or remove the settings?&lt;/head&gt;
    &lt;p&gt;Yes. The browser guides include steps for removing the configurations, and the automated script can also do it. The browser guides explain each setting, so you can add, remove, or modify the files before you install them.&lt;/p&gt;
    &lt;head rend="h3"&gt;Which web browsers are supported?&lt;/head&gt;
    &lt;p&gt;Just the Browser has configuration files and setup scripts for Google Chrome, Microsoft Edge, and Mozilla Firefox. However, Chrome on Linux and Edge on Linux are not currently supported.&lt;/p&gt;
    &lt;head rend="h3"&gt;Can I install this on my phone or tablet?&lt;/head&gt;
    &lt;p&gt;Not yet. See the issues for Android support and iOS/iPadOS support.&lt;/p&gt;
    &lt;head rend="h3"&gt;Is this modifying the web browser?&lt;/head&gt;
    &lt;p&gt;No. Just the Browser uses group policies that are fully supported by web browsers, usually intended for IT departments in companies or other large organizations. No applications or executable files are modified in any way.&lt;/p&gt;
    &lt;head rend="h3"&gt;Do the settings stay applied?&lt;/head&gt;
    &lt;p&gt;Yes, as long as the web browsers continue to support the settings used in the configuration files. Web browsers occasionally add, remove, or replace the settings options, so if the custom configuration breaks, try installing the latest available version.&lt;/p&gt;
    &lt;head rend="h3"&gt;Does this install ad blockers for me?&lt;/head&gt;
    &lt;p&gt;No. If you want one, try uBlock Origin or uBlock Origin Lite.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why does my browser say it's managed by an organization?&lt;/head&gt;
    &lt;p&gt;The group policy settings used by Just the Browser are intended for PCs managed by companies and other large organizations. Browsers like Microsoft Edge and Firefox will display a message like "Your browser is being managed by your organization" to explain why some settings are disabled.&lt;/p&gt;
    &lt;head rend="h3"&gt;How do I know the settings are applied?&lt;/head&gt;
    &lt;p&gt;You can open &lt;code&gt;about:policies&lt;/code&gt; in Firefox or &lt;code&gt;chrome://policy&lt;/code&gt; in Chrome and Edge to see a list of active group policy settings.&lt;/p&gt;
    &lt;head rend="h3"&gt;Why not just use an alternative web browser?&lt;/head&gt;
    &lt;p&gt;You can do that! However, switching to alternative web browsers like Vivaldi, SeaMonkey, Waterfox, or LibreWolf can have other downsides. They are not always available on the same platforms, and they can lag behind mainstream browsers in security updates and engine upgrades. Just the Browser aims to make mainstream web browsers more tolerable, while still retaining their existing benefits.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://justthebrowser.com/"/><published>2026-01-16T12:03:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46645941</id><title>Patching the Wii News Channel to serve local news (2025)</title><updated>2026-01-16T23:39:20.222191+00:00</updated><content>&lt;doc fingerprint="27443a3575ab2e9b"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;Patching the Wii News Channel to serve local news in 2025&lt;/head&gt;August 25, 2025&lt;p&gt;üéß Now Playing: Menu (News Channel) via Nintendo Music App&lt;/p&gt;&lt;p&gt;In keeping with my passion (?) for displaying local news articles in unexpected places, I figured it would be a fun project to try and see what it would take to display current local news on the Nintendo Wii console‚Äôs News Channel.&lt;/p&gt;&lt;p&gt;Here‚Äôs a sneak peek at the result:&lt;/p&gt;&lt;p&gt;In this post, I‚Äôd like to share my research and process for getting this all to work.&lt;/p&gt;&lt;head&gt;tl;dr - click to expand (spoilers)&lt;/head&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;Patched the News Channel‚Äôs hardcoded Nintendo URL to point to an S3 storage bucket using Go and&lt;/p&gt;&lt;code&gt;wadlib&lt;/code&gt;to extract the necessary binary file and edit it in-memory&lt;/item&gt;&lt;item&gt;&lt;p&gt;Modified WiiLink‚Äôs open-source news file generator to add ‚ÄúEl Nuevo D√≠a‚Äù as a news source&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Set up AWS Lambda + EventBridge to regenerate the necessary news binary files hourly&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;Source code: WiiNewsPR and WiiNewsPR-Patcher&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;The Wii‚Äôs News Channel&lt;/head&gt;&lt;p&gt;The News Channel debuted in North America on January 26, 2007, a little over two months after the Wii‚Äôs launch. Since that date, it mostly came pre-installed with Wii consoles and was a novel way to read news from all over the world. Together with other ‚Äúutility‚Äù channels like the Forecast Channel, it tried to position the Wii as more than just a gaming console.&lt;/p&gt;&lt;p&gt;Check out a video recording of the service from right before it was discontinued on June 27th, 2013:&lt;/p&gt;&lt;head rend="h3"&gt;How the News Channel fetches content&lt;/head&gt;&lt;p&gt;Before we can consider displaying custom news on it, we have to figure out how the News Channel actually fetches content. We know that it must have fetched news somehow since it displays a ‚ÄúDownloading‚Ä¶‚Äù splash screen on startup.&lt;/p&gt;&lt;p&gt;Luckily for us, the Wii natively supports proxying via its internet connection configuration settings! Meaning we can set up something like mitmproxy on a local machine and observe its HTTP behavior.&lt;/p&gt;&lt;p&gt;We can start &lt;code&gt;mitmproxy&lt;/code&gt;‚Äôs web interface for a more screenshot-friendly UI:&lt;/p&gt;&lt;code&gt;mitmweb --listen-port 8080
&lt;/code&gt;&lt;p&gt;If we run a man-in-the-middle proxy for the News Channel on an unmodified Wii, we will observe that, on channel startup, it attempts to obtain a &lt;code&gt;news.bin.00&lt;/code&gt; file from &lt;code&gt;http://news.wapp.wii.com/v2/1/049/news.bin.00&lt;/code&gt; via a plain HTTP request.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;URL path explainer (we‚Äôll see later how I found this out):&lt;/p&gt;&lt;code&gt;1&lt;/code&gt;corresponds to ‚ÄúEnglish‚Äù as the configured console language. See conf.h in&lt;code&gt;devkitPro&lt;/code&gt;(the Wii homebrew community‚Äôs de-facto development toolchain) for the possible values.&lt;code&gt;049&lt;/code&gt;is the Wii‚Äôs country code for ‚ÄúUnited States‚Äù. Check out the full list of Wii country codes on wiibrew.org.&lt;/quote&gt;&lt;p&gt;Once it fails to fetch this file, the News Channel displays an error. What might these binary files be? In any case, seeing the Wii perform an HTTP request to fetch news data is a good sign for us. It means we might be able to serve our own data.&lt;/p&gt;&lt;p&gt;By the way, if you run an internet connection test after configuring the proxy settings correctly, you‚Äôll spot the Wii performing an HTTP request to http://conntest.nintendowifi.net. Turns out, this page is actually still online (see for yourself!)&lt;/p&gt;&lt;p&gt;The Wii‚Äôs internet connection test still passes to this day without any modification required. Thanks, Nintendo!&lt;/p&gt;&lt;head rend="h2"&gt;Enter WiiLink: the homebrew community keeping Wii online services alive&lt;/head&gt;&lt;p&gt;Up to this point, this is how we would expect the Wii would behave if you were running a stock console. More than 12 years ago, Nintendo discontinued support for the online functionality of the News Channel.&lt;/p&gt;&lt;p&gt;But as expected for a beloved retro console, community efforts have sprung up to try and preserve the previously existing functionality and allow users to continue enjoying these systems well past their intended expiration date. These sorts of unofficial software for gaming consoles are commonly referred to as ‚Äúhomebrew‚Äù.&lt;/p&gt;&lt;p&gt;Importantly for this project, the WiiLink team maintains servers and develops software that allows us to experience the Wii‚Äôs online connectivity features even today.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;By the way, if you‚Äôre curious about how to get started with Wii console homebrew, check out https://wii.hacks.guide.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Thanks to WiiLink, we can revive the News Channel and browse up-to-date news! Just not the local news, which is our real goal.&lt;/p&gt;&lt;head rend="h3"&gt;How WiiLink patches the News Channel&lt;/head&gt;&lt;p&gt;After going through the WiiLink install process, if we fire up &lt;code&gt;mitmproxy&lt;/code&gt; and take a look at what the Wii is doing now, we‚Äôll see that it‚Äôs actually requesting files from a different domain: ‚Äúnews.wiilink.ca‚Äù. But this time, it manages to fetch &lt;code&gt;news.bin.00&lt;/code&gt; and keeps requesting files all the way up to &lt;code&gt;news.bin.23&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The News Channel just successfully fetched 24 hours worth of news from this server.&lt;/p&gt;&lt;p&gt;Great! Somehow, the WiiLink folks got this all to work. And, best of all, they‚Äôve opened-sourced their work (GitHub). The plan is looking really feasible at this point!&lt;/p&gt;&lt;p&gt;At a high-level, there are two steps to tackle, then:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;We have to make the News Channel fetch files from a server we control&lt;/item&gt;&lt;item&gt;We need to actually generate binary files with the content we want&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Step 1: Patching the News Channel to redirect to our domain&lt;/head&gt;&lt;p&gt;If we follow along with WiiLink‚Äôs installation guide, the critical step seems to be installing a patched version of the News Channel. Looking at their GitHub org, we find a WiiLink24-Patcher project. Searching for the ‚ÄúNews Channel‚Äù in the source code, we find this line in patch.cs which references a VCDIFF encoded &lt;code&gt;News_1.delta&lt;/code&gt; patch.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Side note - it‚Äôs only while writing this blog post that I realized I had been looking at the ‚Äúwrong‚Äù repo; WiiLink‚Äôs guide now recommends using the Python-based WiiLink-Patcher-GUI instead of the CLI patcher.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;After downloading the &lt;code&gt;.delta&lt;/code&gt; file locally, we can use the xdelta CLI to print out some information on what the patch is supposed to do:&lt;/p&gt;&lt;code&gt;xdelta3 printdelta News_1.delta

VCDIFF version:               0
VCDIFF header size:           29
VCDIFF header indicator:      VCD_APPHEADER
VCDIFF secondary compressor:  lzma
VCDIFF application header:    news.dol//0000000b.app/
XDELTA filename (output):     news.dol
XDELTA filename (source):     0000000b.app
...
&lt;/code&gt;&lt;p&gt;Okay, so we‚Äôre looking for a &lt;code&gt;0000000b.app&lt;/code&gt; file and want to save the patched binary as &lt;code&gt;news.dol&lt;/code&gt;. Based on the WiiLink install instructions, we know we should be dealing with a &lt;code&gt;WAD&lt;/code&gt; file, so let‚Äôs keep digging to see if we can find out where &lt;code&gt;0000000b.app&lt;/code&gt; might be hiding.&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Learn more about the WAD file format on wiibrew.org.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;From the repo‚Äôs &lt;code&gt;README.md&lt;/code&gt;, we know the patcher uses libWiiSharp for it‚Äôs WAD file management during the file patching processing (source). But at this point, I‚Äôd rather avoid using C# if I can. And besides, I know for a fact we‚Äôll want to use Go in order to more easily leverage existing tooling from the WiiLink team.&lt;/p&gt;&lt;p&gt;Thankfully, there‚Äôs a really handy Go library called wadlib that comes to the rescue here. We‚Äôll be using it for all our WAD management needs.&lt;/p&gt;&lt;p&gt;So, where is &lt;code&gt;0000000b.app&lt;/code&gt;? Looking at LibWiiSharp‚Äôs &lt;code&gt;WAD.cs&lt;/code&gt; file, we can spot how it unpacks &lt;code&gt;.app&lt;/code&gt; files from a WAD file. Namely, it defaults to using the numeric ‚ÄúContent ID‚Äù inside each ‚ÄúContent‚Äù metadata and then converts it to an 8-digit hexadecimal string (source).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;You can read more about Title metadata (‚ÄúTMD‚Äù) and Content metadata (‚ÄúCMD‚Äù) on wiibrew.org&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;Armed with this knowledge, we can use &lt;code&gt;wadlib&lt;/code&gt; to create a quick file extraction script and see if we can find our &lt;code&gt;0000000b.app&lt;/code&gt;. It can go something like this:&lt;/p&gt;&lt;code&gt;// ignore error handling for brevity
wad, _ := wadlib.LoadWADFromFile("news.wad")
titleMetadata := wad.TMD
contentMetadata := titleMetadata.Contents

outputDir := "extracted_wad/"
os.MkdirAll(outputDir, 0755)

for i := 0; i &amp;lt; len(wad.Data); i++ {
  data, _ := wad.GetContent(i)

  contentID := contentMetadata[i].ID

  // "%08x" means 0-padded 8 digit hex
  filename := filepath.Join(outputDir, fmt.Sprintf("%08x.app", contentID))
  _ = os.WriteFile(filename, data, 0644)

  log.Printf("Extracted: %08x.app (size: %d bytes)",
    contentID, len(data))
}
&lt;/code&gt;&lt;p&gt;When &lt;code&gt;news.wad&lt;/code&gt; is the official (v7) News Channel WAD file, this script successfully extracts 12 &lt;code&gt;.app&lt;/code&gt; files.&lt;/p&gt;&lt;p&gt;There‚Äôs definitely a &lt;code&gt;0000000b.app&lt;/code&gt; there, but could it be the file we‚Äôre looking for?&lt;/p&gt;&lt;p&gt;What we really need to do at this point is go ahead and apply the &lt;code&gt;News_1.delta&lt;/code&gt; patch to this &lt;code&gt;0000000b.app&lt;/code&gt; file manually. That way, we can compare the before/after binaries and see what changed. We can use &lt;code&gt;xdelta&lt;/code&gt; again to actually apply the patch. Running &lt;code&gt;xdelta3 --help&lt;/code&gt; says:&lt;/p&gt;&lt;code&gt;apply patch:
  xdelta3.exe -d -s old_file delta_file decoded_new_file
&lt;/code&gt;&lt;p&gt;So we can go ahead and run:&lt;/p&gt;&lt;code&gt;xdelta3 -d -s extracted_wad/0000000b.app News_1.delta news.dol
&lt;/code&gt;&lt;p&gt;And that‚Ä¶ seemed to work? We have a &lt;code&gt;news.dol&lt;/code&gt; file, as expected. Now what?&lt;/p&gt;&lt;head rend="h3"&gt;Investigating binary file changes&lt;/head&gt;&lt;p&gt;We could do a binary diff of these files and start going through each change, but we already know at least one thing that should have changed based on our previous &lt;code&gt;mitmproxy&lt;/code&gt; experiments: instead of performing requests to ‚Äúnews.wapp.wii.com‚Äù, the patched WAD should instead use ‚Äúnews.wiilink.ca‚Äù.&lt;/p&gt;&lt;p&gt;Using a tool like Hex Fiend (which also has binary diffing capabilities in case we need them), we can try searching for text inside the binary. If we try searching for ‚Äúnews.wapp.wii.com‚Äù on the original &lt;code&gt;0000000b.app&lt;/code&gt; file, we can actually find a match!&lt;/p&gt;&lt;p&gt;Sure enough, if we inspect the patched &lt;code&gt;news.dol&lt;/code&gt; file we will find no mention of the original URL. Instead, the ‚Äúhttp://news.wiilink.ca‚Äù domain is visible at the same location (offset &lt;code&gt;0x1AC37C&lt;/code&gt;).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;Note that the URL contains only two printf-style format strings (&lt;/p&gt;&lt;code&gt;%d&lt;/code&gt;and&lt;code&gt;%03d&lt;/code&gt;); the News Channel itself must be appending the hourly suffix (like&lt;code&gt;.00&lt;/code&gt;) when fetching data.&lt;/quote&gt;&lt;p&gt;If we‚Äôre lucky, simply overwriting the binary file‚Äôs original URL with our own custom URL might do the trick. It‚Äôs worth a try!&lt;/p&gt;&lt;p&gt;In order to validate this hypothesis, I wrote a small Go utility for performing the necessary text replacement. Here‚Äôs an excerpt of the important bits:&lt;/p&gt;&lt;code&gt;// ignoring error handling for brevity
const OriginalURL = "http://news.wapp.wii.com/v2/%d/%03d/news.bin"
const NewURL = "http://wii.rauln.com/news/%d/%03d/news.bin"

wad, _ := wadlib.LoadWADFromFile(wadPath)

// Get decrypted content at index 1 (record with ID "0000000b")
content, _ := wad.GetContent(1)

// byte slice of 44 bytes
originalContent := []byte(OriginalURL)

// 43 bytes in our URL's case
newContent := []byte(NewURL)

// Pad the new URL to match original length (44 bytes)
paddedURL := make([]byte, len(originalContent))
copy(paddedURL, newContent)

// Find the offset (index) of the URL to patch inside the byte slice
offset := bytes.Index(content, originalContent)

// Patch the URL
copy(content[offset:offset+len(originalContent)], paddedURL)
_ = wad.UpdateContent(1, content)

// Save the updated WAD file
_ = os.WriteFile(outputPath, wadBytes, 0644)
&lt;/code&gt;&lt;quote&gt;&lt;p&gt;Check out the full source on GitHub: WiiNewsPR-Patcher&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;If we run the utility like:&lt;/p&gt;&lt;code&gt;go build
wiinewspr-patcher news.wad patched_news.wad
&lt;/code&gt;&lt;p&gt;It should perform the URL rewriting in memory and provide us with a valid WAD file (&lt;code&gt;patched_news.wad&lt;/code&gt;) we can then go ahead and install on Wii hardware.&lt;/p&gt;&lt;p&gt;We can install the patched WAD on our Wii console using YAWM (ModMii Edition).&lt;/p&gt;&lt;p&gt;Finally, we can go back to running &lt;code&gt;mitmproxy&lt;/code&gt; and opening the newly patched News Channel. Once the channel shows the ‚ÄúDownloading‚Ä¶‚Äù splash screen, we‚Äôll spot requests going out to our expected domain.&lt;/p&gt;&lt;p&gt;It works! Now all we need is to‚Ä¶ actually generate valid news files for the News Channel to work.&lt;/p&gt;&lt;head rend="h2"&gt;Step 2: Generating News Channel compatible news files&lt;/head&gt;&lt;p&gt;I mentioned previously that I knew using Go would come in handy later, and it‚Äôs specifically because the WiiLink team has a project called NewsChannel written in Go which contains the source code for generating the binary news files they serve from ‚Äúnews.wiilink.ca‚Äù.&lt;/p&gt;&lt;p&gt;I‚Äôm not going to go over all the implementation details here. I just want to highlight some of the main file creation steps in case you‚Äôd like to read more:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;obtain country-specific configuration (source)&lt;/item&gt;&lt;item&gt;obtain articles and metadata from configured sources (like NHK, source)&lt;/item&gt;&lt;item&gt;process all data in a specific order into a bytes buffer (source)&lt;/item&gt;&lt;item&gt;compress the data using LZ10, sign it with RSA, then write to disk (source) &lt;list rend="ul"&gt;&lt;item&gt;the file name is written using a specific string interpolation (source, this is how I first found out about the language/country codes used in the News Channel data URL!)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;&lt;p&gt;Fun fact: LZ10 is apparently a Nintendo-specific variant of the LZ77 compression algorithm, used in some form or another on Game Boy Advance, Nintendo DS and Wii systems. wii-tools/lzx has the Go source for the LZ10 compression used here.&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;In any case, for our purposes, it‚Äôs doing more than we need in terms of source handling: it can generate news binaries from a variety of sources and supports different languages and regions.&lt;/p&gt;&lt;p&gt;For this project, I am making the following assumptions and tradeoffs:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;p&gt;I will be using ‚ÄúEnglish‚Äù as the language and ‚ÄúUS‚Äù as the country code for the source URL path since my Wii console is configured as such. There is no separate Puerto Rico country code option, which is curious considering that there is a separate option for the US Virgin Islands.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I am not interested in supporting any other news sources from around the world, so the ‚ÄúGlobe‚Äù feature for the News Channel will not be useful.&lt;/p&gt;&lt;/item&gt;&lt;item&gt;&lt;p&gt;I‚Äôm hardcoding the latitude and longitude of Puerto Rico‚Äôs capital into the binary file to avoid having to process or guess location data from each article entry.&lt;/p&gt;&lt;/item&gt;&lt;/list&gt;&lt;head rend="h3"&gt;Modifying WiiLink‚Äôs generator to support Puerto Rican news&lt;/head&gt;&lt;p&gt;I went ahead and forked the &lt;code&gt;NewsChannel&lt;/code&gt; repo into WiiNewsPR, added flag support to control article caching and binary output paths (you‚Äôll see why this was necessary soon), removed all the existing sources and added a new one: El Nuevo D√≠a (‚ÄúENDI‚Äù).&lt;/p&gt;&lt;p&gt;I picked ENDI only because it‚Äôs the only local newspaper website I could find which still supports RSS. Unfortunately, the feeds only contain a snippet of the actual article. On the bright side, most articles do contain images and we can use separate feeds to help categorize articles in the News Channel (source).&lt;/p&gt;&lt;quote&gt;&lt;p&gt;By the way, I experimented with GoOse for (spanish language) article extraction on other news websites and the results were‚Ä¶ unsatisfying, to say the least.&lt;/p&gt;&lt;/quote&gt;&lt;head rend="h3"&gt;Final setup requirements for proper News Channel support&lt;/head&gt;&lt;p&gt;Two quick things we‚Äôll need in order to get this all to work:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;We need to sign each binary news file with a custom RSA key for the Wii to process the file (source). We can use &lt;code&gt;openssl&lt;/code&gt;for this (note the&lt;code&gt;-traditional&lt;/code&gt;option):&lt;/item&gt;&lt;/list&gt;&lt;code&gt; openssl genrsa -traditional -out Private.pem 2048
&lt;/code&gt;&lt;list rend="ol"&gt;&lt;item&gt;We need a (really) low quality logo for our source. ImageMagick easily solves for this:&lt;/item&gt;&lt;/list&gt;&lt;code&gt;magick logo.svg -quality 30 -resize 200x200 -strip logo.jpg
&lt;/code&gt;&lt;p&gt;Then, we can use Go embeds to include the logo in the Go binary (source).&lt;/p&gt;&lt;p&gt;Finally, we can build the Go binary and run it in order to generate a news binary in &lt;code&gt;./v2/1/049&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;go build
./WiiNewsPR
&lt;/code&gt;&lt;p&gt;This successfully generates a &lt;code&gt;news.bin.NN&lt;/code&gt; file.&lt;/p&gt;&lt;p&gt;Now we just need 24 of these, since the News Channel will actually fail to load if not provided with all 24 files. We could run this script every hour for the next 24 hours‚Ä¶ or, we could take the shortcut of copying the current hour‚Äôs file into all other hourly values.&lt;/p&gt;&lt;p&gt;Regardless, it‚Äôs about time to test out all this effort. With 24 files uploaded to our storage provider (AWS S3), and the patched News Channel configured to fetch these from our custom domain, we can start up the channel and observe the fruits of our labor.&lt;/p&gt;&lt;p&gt;After the (slow!) requests finish one by one, seeing the articles pop up was immensely satisfying. Being able to tinker with and learn more about these nostalgic consoles so many years later is a real joy for me.&lt;/p&gt;&lt;head rend="h2"&gt;Bonus step: Automating hourly news updates with AWS Lambda&lt;/head&gt;&lt;p&gt;Copying files into the S3 storage bucket is all well and good, but it would be great to have a continuously-updating, hands-off solution that generates the news binaries for us. A simple (and basically free) way to solve for this would be to bundle up the &lt;code&gt;WiiNewsPR&lt;/code&gt; Go executable into an AWS Lambda function and have that run hourly via EventBride, and then uploading the generated news binaries over to our storage bucket.&lt;/p&gt;&lt;p&gt;Here is where the extra flags for &lt;code&gt;WiiNewsPR&lt;/code&gt; come in: we need to be able to control file creation because &lt;code&gt;/tmp&lt;/code&gt; is a Lambda‚Äôs only writeable file system.&lt;/p&gt;&lt;p&gt;Here is a snippet of the Lambda handler logic:&lt;/p&gt;&lt;code&gt;func Handler(ctx context.Context) error {
  cmd := exec.CommandContext(ctx, "./WiiNewsPR", "-o", "/tmp", "-c", "/tmp/cache")
  // ...

  _, err = uploader.Upload(ctx, &amp;amp;s3.PutObjectInput{
		Bucket:      aws.String(bucketName),
		Key:         aws.String(fmt.Sprintf("%snews.bin.%s", keyPrefix, hour)),
		Body:        file,
		ContentType: aws.String("application/octet-stream"),
	})
  // ...
}

func main() {
  lambda.Start(Handler)
}
&lt;/code&gt;&lt;quote&gt;&lt;p&gt;See full Lambda handler source on GitHub: handler.go&lt;/p&gt;&lt;/quote&gt;&lt;p&gt;We can then leverage the Serverless framework for a quick infra-as-code setup. Here is a snippet of the configuration:&lt;/p&gt;&lt;code&gt;service: wiinewspr-generator

provider:
  name: aws
  # ...
  environment:
    # ...
    TZ: America/Puerto_Rico # we need Lambda to generate files postfixed with the correct "currentHour"
    # ...
    events:
      - schedule:
          rate: cron(30 * * * ? *) # run every hour:30
          name: wiinewspr-every-30pasthour
          description: Generate Wii News PR binary file every hour at 30 minutes past
package:
  patterns:
    - bootstrap # compiled Lambda handler
    - WiiNewsPR # compiled binary news generator
    - ../Private.pem # we need to include the Private.pem file for file signing
&lt;/code&gt;&lt;quote&gt;&lt;p&gt;See full&lt;/p&gt;&lt;code&gt;serverless&lt;/code&gt;configuration on GitHub: serverless.yml&lt;/quote&gt;&lt;p&gt;Some things to call out here:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;We want to make sure to run the Lambda in Puerto Rico‚Äôs timezone so that &lt;code&gt;time.Now()&lt;/code&gt;returns the expected hourly integer.&lt;/item&gt;&lt;item&gt;We want to give the Lambda a higher than expected &lt;code&gt;memorySize&lt;/code&gt;so that its CPU scales accordingly; it turns out that&lt;code&gt;lz10&lt;/code&gt;compression is a big bottleneck on the smallest supported Lambda CPU and can easily time out at 30 seconds.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;If we leave this setup running for 24 hours, our storage bucket will get populated with 24 files and continuously be updated with the latest news!&lt;/p&gt;&lt;p&gt;Now I can get up in the morning, grab a coffee, and browse the local news on my Nintendo Wii like it‚Äôs 2007.&lt;/p&gt;&lt;p&gt;Thanks for reading!&lt;/p&gt;&lt;head rend="h2"&gt;Credits&lt;/head&gt;&lt;p&gt;This experiment would have likely ended in disappointment if not for the amazing work by the Wii homebrew community, specifically: RiiConnect24 Team, WiiLink Team and wiibrew.org Contributors.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://raulnegron.me/2025/wii-news-pr/"/><published>2026-01-16T12:58:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46646226</id><title>Dev-owned testing: Why it fails in practice and succeeds in theory</title><updated>2026-01-16T23:39:19.976850+00:00</updated><content/><link href="https://dl.acm.org/doi/10.1145/3780063.3780066"/><published>2026-01-16T13:39:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46646263</id><title>Michelangelo's first painting, created when he was 12 or 13</title><updated>2026-01-16T23:39:19.650258+00:00</updated><content>&lt;doc fingerprint="ad990b521b25664"&gt;
  &lt;main&gt;
    &lt;p&gt;Think back, if you will, to the works of art you created at age twelve or thirteen. For many, perhaps most of us, our output at that stage of adolescence amounted to directionless doodles, chaotic comics, and a few unsteady-at-best school projects. But then, most of us didn‚Äôt grow up to be Michelangelo. In the late fourteen-eighties, when that towering Renaissance artist was still what we would now call a ‚Äútween,‚Äù he painted The Torment of Saint Anthony, a depiction of the titular religious figure beset by demons in the desert. Though based on a widely known engraving, it nevertheless shows evidence of rapidly advancing technique, inspiration, and even creativity ‚Äî especially when placed under the infrared scanner.&lt;/p&gt;
    &lt;p&gt;For about half a millennium, The Torment of Saint Anthony wasn‚Äôt thought to have been painted by Michelangelo. As explained in the video from Inspiraggio just below, when the painting sold at Sotheby‚Äôs in 2008, the buyer took it to the Metropolitan Museum of Art for examination and cleaning.&lt;/p&gt;
    &lt;p&gt;‚ÄúBeneath the layers of dirt accumulated over the centuries,‚Äù says the narrator, ‚Äúa very particular color palette appeared. ‚ÄúThe tones, the blends, the way the human figure was treated: all of it began to resemble the style Michelangelo would use years later in none other than the Sistine Chapel.‚Äù Infrared reflectography subsequently turned up pentimenti, or correction marks, a common indication that ‚Äúa painting is not a copy, but an original work created with artistic freedom.‚Äù&lt;/p&gt;
    &lt;p&gt;It was the Kimbell Art Museum in Fort Worth, Texas that first bet big on the provenance of The Torment of Saint Anthony. Its newly hired director purchased the painting after turning up ‚Äúnot a single convincing argument against the attribution.‚Äù Thus acquired, it became ‚Äúthe only painting by Michelangelo located anywhere in the Americas, and also just one of four easel paintings attributed to him throughout his entire career,‚Äù during most of which he disparaged oil painting itself. About a decade later, and after further analysis, the art historian Giorgio Bonsanti put his considerable authority behind a definitive confirmation that it is indeed the work of the young Michelangelo. There remain doubters, of course, and even the notoriously uncompromising artist himself may have considered it an immature work unworthy of his name. But who else could have created an immature work like it?&lt;/p&gt;
    &lt;p&gt;Related Content:&lt;/p&gt;
    &lt;p&gt;How Four Masters ‚Äî Michelangelo, Donatello, Verrocchio &amp;amp; Bernini ‚Äî Sculpted David&lt;/p&gt;
    &lt;p&gt;A Secret Room with Drawings Attributed to Michelangelo Opens to Visitors in Florence&lt;/p&gt;
    &lt;p&gt;Michelangelo‚Äôs Illustrated Grocery List&lt;/p&gt;
    &lt;p&gt;Based in Seoul, Colin Marshall writes and broadcasts on cities, language, and culture. He‚Äôs the author of the newsletter Books on Cities as well as the books ÌïúÍµ≠ ÏöîÏïΩ Í∏àÏßÄ (No Summarizing Korea) and Korean Newtro. Follow him on the social network formerly known as Twitter at @colinmarshall.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.openculture.com/2026/01/discover-michelangelos-first-painting.html"/><published>2026-01-16T13:44:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46646645</id><title>Cloudflare acquires Astro</title><updated>2026-01-16T23:39:19.480392+00:00</updated><content>&lt;doc fingerprint="7fa05838a90aa8e6"&gt;
  &lt;main&gt;
    &lt;p&gt;The Astro Technology Company ‚Äî the company behind the Astro web framework ‚Äî is joining Cloudflare! Adoption of the Astro web framework continues to double every year, and Astro 6 is right around the corner. With Cloudflare‚Äôs support, we‚Äôll have more resources and fewer distractions to continue our mission to build the best framework for content-driven websites.&lt;/p&gt;
    &lt;p&gt;What this means for Astro:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Astro stays open-source and MIT-licensed&lt;/item&gt;
      &lt;item&gt;Astro continues to be actively maintained&lt;/item&gt;
      &lt;item&gt;Astro continues to support a wide set of deployment targets, not just Cloudflare&lt;/item&gt;
      &lt;item&gt;Astro‚Äôs open governance and current roadmap remain in place.&lt;/item&gt;
      &lt;item&gt;All full-time employees of The Astro Technology Company are now employees of Cloudflare, and will continue to work on Astro full-time.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How Astro started&lt;/head&gt;
    &lt;p&gt;In 2021, Astro was born out of frustration. The trend at the time was that every website should be architected as an application, and then shipped to the user‚Äôs browser to render. This was not very performant, and we‚Äôve spent the last decade coming up with more and more complex solutions to solve for that performance problem. SSR, ISR, RSC, PPR, TTI optimizations via code-splitting, tree-shaking, lazy-loading, all to generate a blocking double-data hydration payload from a pre-warmed server running halfway around the world.&lt;/p&gt;
    &lt;p&gt;Our mission to design a web framework specifically for building websites ‚Äî what we call content-driven websites, to better distinguish from data-driven, stateful web applications ‚Äî resonated. Now Astro is downloaded almost 1,000,000 times per week, and has been used by 100,000s of developers to build fast, beautiful websites. Today you‚Äôll find Astro all over the web, powering major websites and even entire developer platforms for companies like Webflow, Wix, Microsoft, and Google.&lt;/p&gt;
    &lt;p&gt;Along the way, we also tried to grow a business. In 2021 we raised some money and formed The Astro Technology Company. Our larger vision was that a well-designed framework like Astro could sit at the center of a massive developer platform, with optional hosted primitives (database, storage, analytics) designed in lockstep with the framework.&lt;/p&gt;
    &lt;p&gt;We were never able to realize this vision. Attempts to introduce paid, hosted primitives into our ecosystem fell flat, and rarely justified their own existence. We considered going more directly after first-class hosting or content management for Astro, but knew we‚Äôd spend much of our time playing catchup to well-funded, savvy competitors. We kept exploring different ideas, but nothing clicked with users the same way Astro did.&lt;/p&gt;
    &lt;p&gt;It wasn‚Äôt all bad. Astro DB (our attempt to build a hosted database product for Astro projects) eventually evolved into the open, built-in Astro database client that still lives in core today. Our exploration into building an e-commerce layer with Astro was eventually open-sourced. It was rewarding work, but over the years the distraction took its toll. Each attempt at a new paid product or offering took myself and others on the project away from working on the Astro framework that developers were using and loving every day.&lt;/p&gt;
    &lt;head rend="h2"&gt;Returning to Focus&lt;/head&gt;
    &lt;p&gt;Last year, Dane (Cloudflare CTO) and I began to talk more seriously about the future of the web. Those conversations quickly grew into something bigger: What does the next decade look like? How do frameworks adapt to a world of AI coding and agents?&lt;/p&gt;
    &lt;p&gt;It became clear that even as web technologies evolve, content remains at the center. We realized that we‚Äôve each been working toward this same vision from different angles:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cloudflare has been solving it from the infrastructure side: betting on a platform that is global by default, with fast startup, low latency, and security built-in.&lt;/item&gt;
      &lt;item&gt;Astro has been solving it from the framework side: betting on a web framework that makes it easy to build sites that are fast by default, without overcomplicating things.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The overlap is obvious. By working together, Cloudflare gives us the backing we need to keep innovating for our users. Now we can stop spending cycles worrying about building a business on top of Astro, and start focusing 100% on the code, with a shared vision to move the web forward.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cloudflare ‚ù§Ô∏è Astro&lt;/head&gt;
    &lt;p&gt;Cloudflare has been a long-time sponsor and champion of Astro. They have a proven track record of supporting great open-source projects like Astro, TanStack, and Hono without trying to capture or lock anything down. Staying open to all was a non-negotiable requirement for both us and for Cloudflare.&lt;/p&gt;
    &lt;p&gt;That is why Astro will remain free, open-source, and MIT-licensed. We will continue to run our project in the open, with an open governance model for contributors and an open community roadmap that anyone can participate in. We remain fully committed to maintaining Astro as a platform-agnostic framework, meaning we will continue to support and improve deployments for all targets‚Äînot just Cloudflare.&lt;/p&gt;
    &lt;p&gt;With Cloudflare‚Äôs resources and support, we can now return our focus fully towards building the best web framework for content-driven websites. The web is changing fast, and the bar keeps rising: performance, scale, reliability, and a better experience for the teams shipping content on the web.&lt;/p&gt;
    &lt;p&gt;You‚Äôll see that focus reflected across our roadmap, as we prepare for the upcoming Astro 6 release (beta out now!) and our 2026 roadmap. Stay tuned!&lt;/p&gt;
    &lt;head rend="h2"&gt;Thank you&lt;/head&gt;
    &lt;p&gt;I want to extend a huge thank you to the agencies, companies, sponsors, partners, and theme authors who chose to work with us over the years. Thank you to our initial investors ‚Äî Haystack, Gradient, Uncorrelated, Lightspeed ‚Äî without whom Astro likely wouldn‚Äôt exist. Thank you to everyone in our open source community who continues to help make Astro better every day. And finally, thank you to everyone who uses Astro and puts their trust in us to help them build for the web.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://astro.build/blog/joining-cloudflare/"/><published>2026-01-16T14:25:54+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46646777</id><title>Cursor's latest ‚Äúbrowser experiment‚Äù implied success without evidence</title><updated>2026-01-16T23:39:19.213602+00:00</updated><content>&lt;doc fingerprint="a645901deb75300c"&gt;
  &lt;main&gt;
    &lt;p&gt;2026-01-16&lt;/p&gt;
    &lt;head rend="h1"&gt;Cursor's latest "browser experiment" implied success without evidence&lt;/head&gt;
    &lt;p&gt;On January 14th 2026, Cursor published a blog post titled "Scaling long-running autonomous coding" (https://cursor.com/blog/scaling-agents)&lt;/p&gt;
    &lt;p&gt;In the blog post, they talk about their experiments with running "coding agents autonomously for weeks" with the explicit goal of&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;understand[ing] how far we can push the frontier of agentic coding for projects that typically take human teams months to complete&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;They talk about some approaches they tried, why they think those failed, and how to address the difficulties.&lt;/p&gt;
    &lt;p&gt;Finally they arrived at a point where something "solved most of our coordination problems and let us scale to very large projects without any single agent", which then led to this:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub (https://github.com/wilsonzlin/fastrender)&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never say explicitly.&lt;/p&gt;
    &lt;p&gt;After this, they embed the following video:&lt;/p&gt;
    &lt;p&gt;And below it, they say "While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.".&lt;/p&gt;
    &lt;head rend="h3"&gt;They never actually claim this browser is working and functional&lt;/head&gt;
    &lt;quote&gt;
      &lt;p&gt;error: could not compile 'fastrender' (lib) due to 34 previous errors; 94 warnings emitted&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build.&lt;/p&gt;
    &lt;p&gt;Multiple recent GitHub Actions runs on &lt;code&gt;main&lt;/code&gt; show
failures (including workflow-file errors), and independent build
attempts report dozens of compiler errors, recent PRs were all merged
with failing CI, and going back in the Git history from most recent
commit back 100 commits,&lt;lb/&gt;I couldn't find a single commit that compiled cleanly.&lt;/p&gt;
    &lt;p&gt;I'm not sure what the "agents" they unleashed on this codebase actually did, but they seemingly never ran "cargo build" or even less "cargo check", because both of those commands surface 10s of errors (which surely would balloon should we solve them) and about 100 warnings. There is an open GitHub issue in their repository about this right now: https://github.com/wilsonzlin/fastrender/issues/98&lt;/p&gt;
    &lt;p&gt;And diving into the codebase, if the compilation errors didn't make that clear already, makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality something that surely represents something, but it doesn't have intention behind it, and it doesn't even compile at this point.&lt;/p&gt;
    &lt;p&gt;They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible demo and no known-good revision (tag/release/commit) to verify the screenshots, beyond linking the repo.&lt;/p&gt;
    &lt;p&gt;Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.&lt;/p&gt;
    &lt;p&gt;They finish off the article saying:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Which seems like a really strange conclusion to arrive at, when all they've proved so far, is that agents can output millions of tokens and still not end up with something that actually works.&lt;/p&gt;
    &lt;p&gt;A "browser experiment" doesn't need to rival Chrome. A reasonable minimum bar is: it compiles on a supported toolchain and can render a trivial HTML file. Cursor's post doesn‚Äôt demonstrate that bar, and current public build attempts fail at this too.&lt;/p&gt;
    &lt;head rend="h2"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Cursor never says "this browser is production-ready", but they do frame it as "building a web browser from scratch" and "meaningful progress" and then use a screenshot and "extremely difficult" language, wanting to give the impression that this experiment actually was a success.&lt;/p&gt;
    &lt;p&gt;The closest they get to implying that this was a success, is this part:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;But this extraordinary claim isn't backed up by any evidence. In the blog post they never provide a working commit, build instructions or even a demo that can be reproduced.&lt;/p&gt;
    &lt;p&gt;I don't think anyone expects this browser to be the next Chrome, but I do think that if you claim you've built a browser, it should at least be able to demonstrate being able to be compiled + loading a basic HTML file at the very least.&lt;/p&gt;
    &lt;head&gt;Versions&lt;/head&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;db6064b&lt;/code&gt; Add link to tested commits&lt;/head&gt;
    &lt;code&gt;@@ -33 +33 @@ And if you try to compile it yourself, you'll see that it's very far away from b

  Multiple recent GitHub Actions runs on `main` show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent PRs were all merged with failing CI, and going back in the Git history from most recent commit back-about

   100 -commits, I
+commits,&amp;lt;br/&amp;gt;[I

   couldn't find a single commit that compiled -cleanly.
+cleanly](https://gist.github.com/embedding-shapes/f5d096dd10be44ff82b6e5ccdaf00b29).&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;3dcd6e7&lt;/code&gt; Fix linebreak typo&lt;/head&gt;
    &lt;code&gt;@@ -9,3 +9 @@ On January 14th 2026, Cursor published a blog post titled "Scaling long-running
-In the blog post, they talk about their experiments with running "coding agents autonomously for weeks"
-
-with the explicit goal of
+In the blog post, they talk about their experiments with running "coding agents autonomously for weeks" with the explicit goal of&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;c74ab74&lt;/code&gt; Fix favicon, fix typos, made better simply&lt;/head&gt;
    &lt;code&gt;@@ -33 +33,3 @@ And below it, they say "While it might seem like a simple screenshot, building a

  And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build.
  Multiple recent GitHub Actions runs on `main` show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent PRs were all merged with failing CI, and going back in the Git history from most recent -commit,
+commit back about 100 commits,

   I couldn't find a single commit that compiled cleanly.@@ -37 +39 @@ I'm not sure what the "agents" they unleashed on this codebase actually did, but

  And diving into the codebase, if the compilation errors didn't make that -sure,
+clear already,

   makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality *something* that surely represents *something*, but it doesn't have intention behind it, and it doesn't even compile at this point.@@ -59 +61 @@ The closest they get to implying that this was a success, is this part:

  But this extraordinary claim isn't backed up by any evidence. In the blog post they never provide a working commit, build instructions or even a demo that can +be
   reproduced.&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;bafc54f&lt;/code&gt; Favicon + changes + cursor video&lt;/head&gt;
    &lt;code&gt;@@ -21 +21 @@ Finally they arrived at a point where something "solved most of our coordination

  This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never -say.
+say explicitly.
@@ -25 +25 @@ After this, they embed the following video:
-[video]
+![](/content/cursor-screenshots.webm)
@@ -33 +33 @@ And below it, they say "While it might seem like a simple screenshot, building a

  And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build. Multiple recent -CI workflow
+GitHub Actions

   runs on `main` -are failing, all the
+show failures (including workflow-file errors), and independent build attempts report dozens of compiler errors, recent

   PRs were +all

   merged with failing CI, and going back in the Git history from most recent commit, I couldn't find a single commit that compiled cleanly.@@ -39 +39,3 @@ And diving into the codebase, if the compilation errors didn't make that sure, m

  They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible -demo/build instructions or
+demo and no

   known-good -commit,
+revision (tag/release/commit) to verify the screenshots,

   beyond linking the repo.
  Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.@@ -46,0 +49,2 @@ Which seems like a really strange conclusion to arrive at, when all they've prov
+A "browser experiment" doesn't need to rival Chrome. A reasonable minimum bar is: it compiles on a supported toolchain and can render a trivial HTML file. Cursor's post doesn‚Äôt demonstrate that bar, and current public build attempts fail at this too.
@@ -55 +59 @@ The closest they get to implying that this was a success, is this part:

  But this extraordinary claim isn't backed up by any evidence. -They
+In the blog post they
   never provide a working commit, build instructions or even a demo that can reproduced.&lt;/code&gt;
    &lt;head&gt;2026-01-16 &lt;code&gt;d664475&lt;/code&gt; Move&lt;/head&gt;
    &lt;code&gt;@@ -0,0 +1,57 @@
+---
+date: 2026-01-16
+---
+
+# Cursor's latest "browser experiment" implied success without evidence
+
+On January 14th 2026, Cursor published a blog post titled "Scaling long-running autonomous coding" (https://cursor.com/blog/scaling-agents)
+
+In the blog post, they talk about their experiments with running "coding agents autonomously for weeks"
+
+with the explicit goal of
+
+&amp;gt; understand[ing] how far we can push the frontier of agentic coding for projects that typically take human teams months to complete
+
+They talk about some approaches they tried, why they think those failed, and how to address the difficulties.
+
+Finally they arrived at a point where something "solved most of our coordination problems and let us scale to very large projects without any single agent", which then led to this:
+
+&amp;gt; To test this system, we pointed it at an ambitious goal: building a web browser from scratch. The agents ran for close to a week, writing over 1 million lines of code across 1,000 files. You can explore the source code on GitHub (https://github.com/wilsonzlin/fastrender)
+
+This is where things get a bit murky and unclear. They claim "Despite the codebase size, new agents can still understand it and make meaningful progress" and "Hundreds of workers run concurrently, pushing to the same branch with minimal conflicts", but they never actually say if this is successful or not, is it actually working? Can you run this browser yourself? We don't know and they never say.
+
+After this, they embed the following video:
+
+[video]
+
+And below it, they say "While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.".
+
+### They never actually claim this browser is working and functional
+
+&amp;gt; error: could not compile 'fastrender' (lib) due to 34 previous errors; 94 warnings emitted
+
+And if you try to compile it yourself, you'll see that it's very far away from being a functional browser at all, and seemingly, it never actually was able to build. Multiple recent CI workflow runs on `main` are failing, all the PRs were merged with failing CI, and going back in the Git history from most recent commit, I couldn't find a single commit that compiled cleanly.
+
+I'm not sure what the "agents" they unleashed on this codebase actually did, but they seemingly never ran "cargo build" or even less "cargo check", because both of those commands surface 10s of errors (which surely would balloon should we solve them) and about 100 warnings. There is an open GitHub issue in their repository about this right now: https://github.com/wilsonzlin/fastrender/issues/98
+
+And diving into the codebase, if the compilation errors didn't make that sure, makes it very clear to any software developer that none of this is actually engineered code. It is what is typically known as "AI slop", low quality *something* that surely represents *something*, but it doesn't have intention behind it, and it doesn't even compile at this point.
+
+They later start to talk about what's next, but not a single word about how to run it, what to expect, how it's working or anything else. Cursor's blog post provides no reproducible demo/build instructions or known-good commit, beyond linking the repo. Regardless of intent, Cursor's blog post creates the impression of a functioning prototype while leaving out the basic reproducibility markers one would expect from such claim. They never explicitly claim it's actually working, so no one can say they lied at least.
+
+They finish off the article saying:
+
+&amp;gt; But the core question, can we scale autonomous coding by throwing more agents at a problem, has a more optimistic answer than we expected.
+
+Which seems like a really strange conclusion to arrive at, when all they've proved so far, is that agents can output millions of tokens and still not end up with something that actually works.
+
+## Conclusion
+
+Cursor never says "this browser is production-ready", but they do frame it as "building a web browser from scratch" and "meaningful progress" and then use a screenshot and "extremely difficult" language, wanting to give the impression that this experiment actually was a success.
+
+The closest they get to implying that this was a success, is this part:
+
+&amp;gt; Hundreds of agents can work together on a single codebase for weeks, making real progress on ambitious projects.
+
+But this extraordinary claim isn't backed up by any evidence. They never provide a working commit, build instructions or even a demo that can reproduced.
+
+I don't think anyone expects this browser to be the next Chrome, but I do think that if you claim you've built a browser, it should at least be able to demonstrate being able to be compiled + loading a basic HTML file at the very least.&lt;/code&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://embedding-shapes.github.io/cursor-implied-success-without-evidence/"/><published>2026-01-16T14:37:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46647059</id><title>Read_once(), Write_once(), but Not for Rust</title><updated>2026-01-16T23:39:18.815941+00:00</updated><content>&lt;doc fingerprint="b6fabc1de896fbf8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;READ_ONCE(), WRITE_ONCE(), but not for Rust&lt;/head&gt;
    &lt;head rend="h2"&gt;[LWN subscriber-only content]&lt;/head&gt;
    &lt;p&gt;An understanding of READ_ONCE() and WRITE_ONCE() is important for kernel developers who will be dealing with any sort of concurrent access to data. So, naturally, they are almost entirely absent from the kernel's documentation. A description of sorts can be found at the top of include/asm-generic/rwonce.h:&lt;/p&gt;
    &lt;quote&gt;Prevent the compiler from merging or refetching reads or writes. The compiler is also forbidden from reordering successive instances of READ_ONCE and WRITE_ONCE, but only when the compiler is aware of some particular ordering. One way to make the compiler aware of ordering is to put the two invocations of READ_ONCE or WRITE_ONCE in different C statements.&lt;/quote&gt;
    &lt;p&gt;In other words, a READ_ONCE() call will force the compiler to read from the indicated location exactly one time, with no optimization tricks that would cause the read to be either elided or repeated; WRITE_ONCE() will force a write under those terms. They will also ensure that the access is atomic; if one task reads a location with READ_ONCE() while another is writing that location, the read will return the value as it existed either before or after the write, but not some random combination of the two. These macros, other than as described above, impose no ordering constraints on the compiler or the CPU, making them different from macros like smp_load_acquire(), which have stronger ordering requirements.&lt;/p&gt;
    &lt;quote&gt;Stay on top of Linux kernel development with a one-month free trial subscription to LWN, no credit card required.&lt;/quote&gt;
    &lt;p&gt;The READ_ONCE() and WRITE_ONCE() macros were added for the 3.18 release in 2014. WRITE_ONCE() was initially called ASSIGN_ONCE(), but that name was changed during the 3.19 development cycle.&lt;/p&gt;
    &lt;p&gt;On the last day of 2025, Alice Ryhl posted a patch series adding implementations of READ_ONCE() and WRITE_ONCE() for Rust. There are places in the code, she said, where volatile reads could be replaced with these calls, once they were available; among other changes, the series changed access to the struct file f_flags field to use READ_ONCE(). The implementation of these macros involves a bunch of Rust macro magic, but in the end they come down to calls to the Rust read_volatile() and write_volatile() functions.&lt;/p&gt;
    &lt;p&gt; Some of the other kernel Rust developers objected to this change, though. Gary Guo said that he would rather not expose READ_ONCE() and WRITE_ONCE() and suggested using relaxed operations from &lt;del&gt;the Rust Atomic crate&lt;/del&gt; the kernel's Atomic module instead. Boqun Feng expanded on the objection: &lt;/p&gt;
    &lt;quote&gt;The problem of READ_ONCE() and WRITE_ONCE() is that the semantics is complicated. Sometimes they are used for atomicity, sometimes they are used for preventing data race. So yes, we are using LKMM [the Linux kernel memory model] in Rust as well, but whenever possible, we need to clarify the intention of the API, using Atomic::from_ptr().load(Relaxed) helps on that front.&lt;p&gt;IMO, READ_ONCE()/WRITE_ONCE() is like a "band aid" solution to a few problems, having it would prevent us from developing a more clear view for concurrent programming.&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;In other words, using the Atomic crate allows developers to specify more precisely which guarantees an operation needs, making the expectations (and requirements) of the code more clear. This point of view would appear to have won out, and Ryhl has stopped pushing for this addition to the kernel's Rust code ‚Äî for now, at least.&lt;/p&gt;
    &lt;p&gt;There are a couple of interesting implications from this outcome, should it hold. The first of those is that, as Rust code reaches more deeply into the core kernel, its code for concurrent access to shared data will look significantly different from the equivalent C code, even though the code on both sides may be working with the same data. Understanding lockless data access is challenging enough when dealing with one API; developers may now have to understand two APIs, which will not make the task easier.&lt;/p&gt;
    &lt;p&gt;Meanwhile, this discussion is drawing some attention to code on the C side as well. As Feng pointed out, there is still C code in the kernel that assumes a plain write will be atomic in many situations, even though the C standard explicitly says otherwise. Peter Zijlstra answered that all such code should be updated to use WRITE_ONCE() properly. Simply finding that code may be a challenge (though KCSAN can help); updating it all may take a while. The conversation also identified a place in the (C) high-resolution-timer code that is missing a needed READ_ONCE() call. This is another example of the Rust work leading to improvements in the C code.&lt;/p&gt;
    &lt;p&gt; In past discussions on the design of Rust abstractions, there has been resistance to the creation of Rust interfaces that look substantially different from their C counterparts; see this 2024 article, for example. If the Rust developers come up with a better design for an interface, the thinking went, the C side should be improved to match this new design. If one accepts the idea that the Rust approach to READ_ONCE() and WRITE_ONCE() is better than the original, then one might conclude that a similar process should be followed here. Changing thousands of low-level concurrency primitives to specify more precise semantics would not be a task for the faint of heart, though. This may end up being a case where code in the two languages just does things differently.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Development tools/Rust&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;Lockless algorithms&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Jan 9, 2026 17:19 UTC (Fri) by mb (subscriber, #50428) [Link] (9 responses) I experimented with read/write volatile on AVR, where it would be greatly beneficial to use them for certain inter-thread (interrupt) communication. However, I came to the conclusion that using read/write volatile for inter-thread (interrupt) communication is unsound in Rust. AVR hardware is not capable of doing a non-atomic read/write for byte sized objects. So the hardware is fine for all of the relevant cases. https://doc.rust-lang.org/std/ptr/fn.read_volatile.html &amp;gt; an operation is volatile has no bearing whatsoever on questions involving concurrent accesses from multiple threads &amp;gt; This access is still not considered atomic, and as such it cannot be used for inter-thread synchronization. My implementation worked fine and the generated assembly code was perfect. (Yes, I know there is AtomicXX and no it's not efficient for reasons... And yes, I should fix the compiler's atomic intrinsics instead of working around the problem... I know :) Posted Jan 9, 2026 19:20 UTC (Fri) by josh (subscriber, #17465) [Link] (8 responses) Relaxed atomics are effectively compiler-barrier atomics, and *shouldn't* have any runtime overhead. Are you encountering cases where there's more inefficiency than that? Posted Jan 9, 2026 19:54 UTC (Fri) by mb (subscriber, #50428) [Link] (1 responses) But that was not my point. My point was that I think volatile accesses are not sound in Rust for inter thread communication. Posted Jan 9, 2026 22:10 UTC (Fri) by josh (subscriber, #17465) [Link] Ah, got it, thank you. Hopefully that can be fixed. &amp;gt; My point was that I think volatile accesses are not sound in Rust for inter thread communication. Right, I believe that's correct. Posted Jan 10, 2026 9:33 UTC (Sat) by plugwash (subscriber, #29694) [Link] (5 responses) The situation is a little more subtle than that. Relaxed atomics on a given memory location, must behave as-if they had a well-defined order (though this order may differ from operations on other memory locations, unless fences are used), and this must apply to the whole set of atomic operations. You may only be using load and store on a particular location, but the compiler doesn't know that. Other code might be performing other atomic operations on that location. My understanding is that this effectively means that if you implement read-modify-write operations by using a global lock, you must also implement plain write operations using that same global lock. Posted Jan 10, 2026 20:13 UTC (Sat) by comex (subscriber, #71521) [Link] (1 responses) Posted Jan 11, 2026 17:49 UTC (Sun) by garyguo (subscriber, #173367) [Link] `READ_ONCE` on u64 might still be useful is you just want to read the value in a data-race-free way and you don't care about atomicity (i.e. allow the read to tear). However this is yet another reason I don't want people to just use `READ_ONCE()` for atomic ops on Rust side -- it's just not intuitive which semantics is desired. Posted Jan 10, 2026 20:44 UTC (Sat) by NYKevin (subscriber, #129325) [Link] (2 responses) That is true but misleading. Your parenthetical negates all of the guarantees that are actually expensive to implement, at least on x86. Noting for the record: A fence must be on the same thread as the relaxed atomic in order to restrict it, and there are several other requirements as well. I refer the curious reader to https://en.cppreference.com/w/cpp/atomic/atomic_thread_fe... and related documentation for more information. &amp;gt; My understanding is that this effectively means that if you implement read-modify-write operations by using a global lock, you must also implement plain write operations using that same global lock. If you take a global lock, then there are two different memory locations in play (lock and payload), so your parenthetical above already tells us that the lock is ineffective (at protecting against against un-fenced relaxed atomics on either the lock or the payload). Or perhaps I have misunderstood what you mean by "implement read-modify-write operations by using a global lock." I would normally understand a "read-modify-write operation" to be a hardware instruction (or sequence of instructions), which is not our problem to "implement" in the first place. If you mean "emulate," then the problem we run into is that emulators do not emulate the C abstract machine. They emulate some real hardware like x86, or virtual hardware like the JVM. Those platforms have their own, more specific memory models than the C abstract machine, and the compiler backend must necessarily take advantage of those memory models to emit correct assembly/machine code. So our emulator is not permitted to stop at just taking locks for relaxed atomics - it doesn't necessarily know which stores or loads originated as relaxed atomics in the first place, and therefore may have to take locks for all loads and stores whatsoever. Of course, it would be preferable to implement these operations lock-free if it is possible to do so. Posted Jan 10, 2026 21:12 UTC (Sat) by willmo (subscriber, #82093) [Link] (1 responses) &amp;gt; If you take a global lock, then there are two different memory locations in play (lock and payload), so your parenthetical above already tells us that the lock is ineffective (at protecting against against un-fenced relaxed atomics on either the lock or the payload). In this case, the compiler would need to compile un-fenced relaxed atomics so that they take the global lock. That‚Äôs what plugwash meant. Posted Jan 12, 2026 16:36 UTC (Mon) by NYKevin (subscriber, #129325) [Link] Posted Jan 9, 2026 17:42 UTC (Fri) by bertschingert (subscriber, #160729) [Link] (11 responses) I wasn't around when they were implemented, so I'm speculating here, but I get the sense that READ/WRITE_ONCE() were implemented as a volatile cast not because volatility gives the optimal or desired semantics in most situations, but because that was the best tool available prior to the C11 atomics model. While it may be prohibitively difficult, it does seem like changing the C side to use relaxed atomics (when correct) would be the right thing to do. But I don't really know how many uses actually require the additional "volatility" guarantee provided by READ/WRITE_ONCE(). Posted Jan 10, 2026 1:39 UTC (Sat) by wahern (subscriber, #37304) [Link] (8 responses) Also, C11 atomics is not the origin point for atomic intrinsics[1] or a meaningful memory model in either GCC or Linux. It's not the final or even 100% comprehensive model, either. I think the push for a more formal memory model in C, C++, and the compilers gives a false impression such a thing was completely non-existent beforehand and that things are satisfactory today. [1] GCC had at least two sets of intrinsics before supporting C11 atomics, and of course projects like the kernel had their own set that work just as well today as they did before the latest set of builtins. Posted Jan 10, 2026 8:54 UTC (Sat) by koverstreet (‚ú≠ supporter ‚ú≠, #4296) [Link] (2 responses) The "atomicity" guarantees that READ_ONCE() and WRITE_ONCE() provide only come in at the compiler level. The compiler will coalesce loads and stores or emit multiple loads as a substitute for spilling registers without some notion of atomicity at the language level. The "unnecessarily costly" part of READ_ONCE() and WRITE_ONCE() is that they don't distinguish between atomicity and ordering - they also specify strict ordering, but only to the compiler, not the hardware (they don't emit memory barriers). Rust's atomic load/store really are just better, because they separate out ordering from atomicity and make ordering explicit. And instead of sprinkling around separate memory barrier calls, which may or may not be commented, they're attached to the operation that needs them - which is good for readability. Posted Jan 10, 2026 17:45 UTC (Sat) by excors (subscriber, #95769) [Link] I'm not certain what you mean by that. E.g. the ARM ARM defines "single-copy atomicity" which is important even in single-processor code: if an interrupt occurs during a STP (Store Pair) instruction, whose operation is defined as a single assignment to memory, the interrupt handler may observe the first half of memory was updated and the second half wasn't, because STP is treated as two separate atomic writes. (The STP instruction will be restarted after the interrupt returns, so it'll complete eventually). So I think the ISA does define the notion of atomic loads and stores, even before getting to the more complex operations. (GCC will happily use STP for an int64_t assignment, making it non-atomic, unless you add 'volatile' and then it'll use a single 64-bit STR (which is single-copy atomic).) Posted Jan 10, 2026 20:18 UTC (Sat) by comex (subscriber, #71521) [Link] Posted Jan 10, 2026 16:55 UTC (Sat) by joib (subscriber, #8541) [Link] (4 responses) I wonder, if the C++/C11 memory models and atomics were to be developed today, how different would they look, considering the amount of knowledge the world has gained since then and now? Certainly there were parts of the C/C++11 models that were, ahem, less than successful, like the consume memory ordering, but otherwise, would there be a place for doing it substantially better and different in general? Posted Jan 11, 2026 20:33 UTC (Sun) by pbonzini (subscriber, #60935) [Link] (1 responses) I don't have high hopes that this would be accepted now, but maybe it would be since "almost nobody will need anything but sequential consistent variables" has been shown wrong. The other thing that still hasn't been fully formalized is out-of-thin-air values. Everybody agrees that they won't happen but strictly speaking they aren't prohibited, or weren't last time I checked. Posted Jan 12, 2026 6:06 UTC (Mon) by riking (subscriber, #95706) [Link] Posted Jan 15, 2026 0:18 UTC (Thu) by milesrout (subscriber, #126894) [Link] (1 responses) Posted Jan 15, 2026 15:40 UTC (Thu) by bertschingert (subscriber, #160729) [Link] OTOH, what I like about the Rust (and C/C++11?) atomics is that the type system prevents accidentally introducing data races because you can't do a non-atomic load/store to an atomic type -- at least without unsafe code. Given that the article mentions there are cases in C where READ_ONCE() and WRITE_ONCE() should have been used, but weren't, this seems to be a real risk. Posted Jan 10, 2026 15:42 UTC (Sat) by bjackman (subscriber, #109548) [Link] (1 responses) IIUC C11's relaxed ordering is too weak for that, but any of the other C11 orderings are likely to be unnecessarily strict, i.e. they might force the use of special (costly) CPU instructions where normal reads and writes are already safe enough. Posted Jan 11, 2026 17:57 UTC (Sun) by garyguo (subscriber, #173367) [Link] &lt;head&gt;read/write volatile&lt;/head&gt;&lt;lb/&gt; Just in the same way every AVR C program uses volatile "atomic" variables to do this.&lt;lb/&gt; https://github.com/mbuesch/avr-atomic&lt;lb/&gt; But the read/write volatile documentation was pretty clear to me that the Rust virtual machine considers concurrent volatile accesses unsound and is free to optimize it to bits.&lt;lb/&gt; &amp;gt; Volatile accesses behave exactly like non-atomic accesses in that regard.&lt;lb/&gt; However, I changed it to a less optimal inline asm implementation just because I think the Rust documentation considers concurrent read/write volatile without additional synchronization to be unsound.&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;read/write volatile&lt;/head&gt;&lt;lb/&gt; As I said, it's an LLVM problem on AVR. Which is not a stable tier.&lt;lb/&gt; Atomic always use heavy syncing on AVR in the current compiler.&lt;head&gt;read/write volatile&lt;/head&gt;&lt;lb/&gt; &amp;gt; Atomic always use heavy syncing on AVR in the current compiler.&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;read/write volatile&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;head&gt;overly strict semantics&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/SubscriberLink/1053142/8ec93e58d5d3cc06/"/><published>2026-01-16T15:04:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46647491</id><title>6-Day and IP Address Certificates Are Generally Available</title><updated>2026-01-16T23:39:18.678574+00:00</updated><content>&lt;doc fingerprint="e659e0db14317484"&gt;
  &lt;main&gt;
    &lt;p&gt;Short-lived and IP address certificates are now generally available from Let‚Äôs Encrypt. These certificates are valid for 160 hours, just over six days. In order to get a short-lived certificate subscribers simply need to select the ‚Äòshortlived‚Äô certificate profile in their ACME client.&lt;/p&gt;
    &lt;p&gt;Short-lived certificates improve security by requiring more frequent validation and reducing reliance on unreliable revocation mechanisms. If a certificate‚Äôs private key is exposed or compromised, revocation has historically been the way to mitigate damage prior to the certificate‚Äôs expiration. Unfortunately, revocation is an unreliable system so many relying parties continue to be vulnerable until the certificate expires, a period as long as 90 days. With short-lived certificates that vulnerability window is greatly reduced.&lt;/p&gt;
    &lt;p&gt;Short-lived certificates are opt-in and we have no plan to make them the default at this time. Subscribers that have fully automated their renewal process should be able to switch to short-lived certificates easily if they wish, but we understand that not everyone is in that position and generally comfortable with this significantly shorter lifetime. We hope that over time everyone moves to automated solutions and we can demonstrate that short-lived certificates work well.&lt;/p&gt;
    &lt;p&gt;Our default certificate lifetimes will be going from 90 days down to 45 days over the next few years, as previously announced.&lt;/p&gt;
    &lt;p&gt;IP address certificates allow server operators to authenticate TLS connections to IP addresses rather than domain names. Let‚Äôs Encrypt supports both IPv4 and IPv6. IP address certificates must be short-lived certificates, a decision we made because IP addresses are more transient than domain names, so validating more frequently is important. You can learn more about our IP address certificates and the use cases for them from our post announcing our first IP Certificate.&lt;/p&gt;
    &lt;p&gt;We‚Äôd like to thank the Open Technology Fund and Sovereign Tech Agency, along with our Sponsors and Donors, for supporting the development of this work.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://letsencrypt.org/2026/01/15/6day-and-ip-general-availability"/><published>2026-01-16T15:37:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46648144</id><title>Launch HN: Indy (YC S21) ‚Äì A support app designed for ADHD brains</title><updated>2026-01-16T23:39:18.086116+00:00</updated><content>&lt;doc fingerprint="5ffadfaf74ff182e"&gt;
  &lt;main&gt;
    &lt;p&gt;Get the app.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.shimmer.care/indy-redirect"/><published>2026-01-16T16:20:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46648714</id><title>Zep AI (Agent Context Engineering, YC W24) Is Hiring Forward Deployed Engineers</title><updated>2026-01-16T23:39:17.797054+00:00</updated><content>&lt;doc fingerprint="af57259bffd2ec7b"&gt;
  &lt;main&gt;
    &lt;p&gt;Agent Context Is Hard. We Fixed It.&lt;/p&gt;
    &lt;p&gt;Zep assembles the right context from chat history, business data, and user behavior so agents are personalized, accurate, and fast. Our open source project Graphiti hit 20k GitHub stars in under 12 months. Sub-200ms retrieval, SOC 2 Type 2/HIPAA certified, used by teams from startups to Fortune 500s.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ycombinator.com/companies/zep-ai/jobs/"/><published>2026-01-16T17:00:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46648916</id><title>East Germany balloon escape</title><updated>2026-01-16T23:39:17.338291+00:00</updated><content>&lt;doc fingerprint="be46c17b47664bf8"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;East Germany balloon escape&lt;/head&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Native name&lt;/cell&gt;&lt;cell&gt;Die Ballonflucht&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Date&lt;/cell&gt;&lt;cell&gt;16 September 1979&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Time&lt;/cell&gt;&lt;cell&gt;02:00 am (approximate)&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Duration&lt;/cell&gt;&lt;cell&gt;25 minutes&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Location&lt;/cell&gt;&lt;cell&gt;Oberlemnitz, East Germany&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;Naila, West Germany&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Coordinates&lt;/cell&gt;&lt;cell&gt;50¬∞28‚Ä≤59‚Ä≥N 11¬∞35‚Ä≤29‚Ä≥E / 50.48306¬∞N 11.59139¬∞E[1]&lt;p&gt;(takeoff)&lt;/p&gt;&lt;p&gt;50¬∞19‚Ä≤52.7‚Ä≥N 11¬∞40‚Ä≤13.1‚Ä≥E / 50.331306¬∞N 11.670306¬∞E[1]&lt;/p&gt;&lt;p&gt;(landing)&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Organised by&lt;/cell&gt;&lt;cell&gt;Peter Strelzyk &amp;amp; family&lt;p&gt;G√ºnter Wetzel &amp;amp; family&lt;/p&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Participants&lt;/cell&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;Outcome&lt;/cell&gt;&lt;cell&gt;Successful escape to West Germany&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;Non-fatal injuries&lt;/cell&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;On 16 September 1979, eight people from two families escaped from East Germany by crossing the border into West Germany at night in a homemade hot air balloon. The unique feat was the result of over a year and a half of preparations involving three different balloons, various modifications, and a first, unsuccessful attempt. The failed attempt alerted the East German authorities to the plot, but the police were unable to identify the escapees before their second, successful flight two months later.&lt;/p&gt;&lt;head rend="h2"&gt;Background&lt;/head&gt;[edit]&lt;p&gt;East Germany, then part of the Eastern Bloc, was separated from West Germany in the Western Bloc by the inner German border and the Berlin Wall, which were heavily fortified with watchtowers, land mines, armed soldiers, and various other measures to prevent illegal crossings. East German border troops were instructed to prevent defection to West Germany by all means, including lethal force (Schie√übefehl; "order to fire").[2]&lt;/p&gt;&lt;p&gt;Peter Strelzyk (1942‚Äì2017), an electrician and former East German Air Force mechanic, and G√ºnter Wetzel (born 1955), a bricklayer by trade,[3] were colleagues at a local plastics factory.[4] Friends for four years, they shared a desire to flee the country and began discussing ways to get across the border. On 7 March 1978, they agreed to plan an escape.[5] They considered building a helicopter but quickly realized they would be unable to acquire an engine capable of powering such a craft. They then decided to explore the idea of constructing a hot air balloon,[6] having been inspired by a television program about ballooning.[3] An alternate account is that a relative shared a magazine article about the International Balloon Festival in Albuquerque, New Mexico.[5]&lt;/p&gt;&lt;head rend="h2"&gt;Construction&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel began research into balloons. Their plan was to escape with their wives and a total of four children (aged 2 to 15). They calculated the weight of the eight passengers and the craft itself to be around 750 kilograms (1,650 lb). Subsequent calculations determined a balloon capable of lifting this weight would need to hold 2,000 cubic metres (71,000 cu ft) of air heated to 100 ¬∞C (212 ¬∞F). The next calculation was the amount of material needed for the balloon, estimated to be 800 square metres (8,600 sq ft).[6]&lt;/p&gt;&lt;p&gt;The pair lived in P√∂√üneck, a small town of about 20,000 where large quantities of cloth could not be obtained without raising attention. They tried neighbouring towns of Rudolstadt, Saalfeld, and Jena without success.[7] They travelled 50 km (31 mi) to Gera, where they purchased 1-metre-wide (3 ft 3 in) rolls of cotton cloth totalling 850 metres (2,790 ft) in length at a department store after telling the astonished clerk that they needed the large quantity of material to use as tent lining for their camping club.[6][7]&lt;/p&gt;&lt;p&gt;Wetzel spent two weeks sewing the cloth into a balloon-shaped bag, 15 metres (49 ft) wide by 20 metres (66 ft) long, on a 40-year-old manually operated sewing machine. Strelzyk spent the time building the gondola and burner assembly. The gondola was made from an iron frame, sheet metal floor, and clothesline run around the perimeter every 150 millimetres (5.9 in) for the sides. The burner was made using two 11-kilogram (24 lb) bottles of liquid propane household gas, hoses, water pipe, a nozzle, and a piece of stove pipe.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First test&lt;/head&gt;[edit]&lt;p&gt;The team was ready to test the craft in April 1978. After days of searching, they found a suitable secluded forest clearing near Ziegenr√ºck, 10 km (6.2 mi) from the border and 30 km (19 mi) from P√∂√üneck. After lighting the burner one night, they failed to inflate the balloon. They thought the problem might stem from the fact that they had laid the balloon on the ground. After weeks of additional searching, they found a 25-metre (82 ft) cliff at a rock quarry where they could suspend the balloon vertically before inflation, but that also proved unsuccessful.[6]&lt;/p&gt;&lt;p&gt;The pair then decided to fill the bag with ambient-temperature air before using the burner to raise the air temperature and provide lift. They constructed a blower with a 14 hp (10 kW) 250 cc (15 cu in) motorcycle engine taken from Wetzel's old MZ, started with a Trabant automobile starter powered by jumper cables from Strelzyk's Moskvitch sedan.[8] This engine, silenced by a Trabant muffler, turned 1-metre-long (3.3 ft) fan blades to inflate the balloon. They also used a home-made flamethrower, similar to the gondola's burner, to pre-heat the air faster. With these modifications in place, they returned to the secluded clearing to try again but still could not inflate the balloon. But using the blower did allow them to discover that the cotton material with which they fashioned the balloon was too porous and leaked excessively.[6]&lt;/p&gt;&lt;p&gt;Their unsuccessful effort had cost them 2,400 DDM (US$360). Strelzyk disposed of the cloth by burning it in his furnace over several weeks.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Second test&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel purchased samples of different fabrics in local stores, including umbrella material and various samples of taffeta and nylon. They used an oven to test the material for heat resistance. In addition, they created a test rig from a vacuum cleaner and a water-filled glass tube to determine which material would allow the vacuum to exert the most suction on the water, and consequently which was the most impervious to air. The umbrella covering performed the best but was also the most expensive. They instead selected a synthetic kind of taffeta.[6]&lt;/p&gt;&lt;p&gt;To purchase a large quantity of fabric without arousing too much suspicion, the pair again drove to a distant city. This time they travelled over 160 kilometres (100 mi) to a department store in Leipzig. Their new cover story was that they belonged to a sailing club and needed the material to make sails. The quantity they needed had to be ordered, and although they feared the purchase might be reported to East Germany's State Security Service (Stasi), they returned the next day and picked up the material without incident. They paid 4,800 DDM (US$720) for 800 metres (2,600 ft) of 1-metre-wide (3 ft 3 in) fabric.[6] On the way home, they also purchased an electric motor to speed up the pedal-operated sewing machine they had been using to sew the material into the desired balloon shape.[7]&lt;/p&gt;&lt;p&gt;Wetzel spent the next week sewing the material into another balloon, accomplishing the task faster the second time with the now-electric sewing machine. Soon afterwards, the two men returned to the forest clearing and inflated the bag in about five minutes using the blower and flame thrower. The bag rose and held air, but the burner on the gondola was not powerful enough to create the heat needed for lift. The pair continued experimenting for months, doubling the number of propane tanks and trying different fuel mixtures. Disappointed with the result, Wetzel decided to abandon the project and instead started to pursue the idea of building a small gasoline engine-powered light aeroplane[6] or a glider.[5]&lt;/p&gt;&lt;p&gt;Strelzyk continued trying to improve the burner. In June 1979, he discovered that with the propane tank inverted, additional pressure caused the liquid propane to evaporate, which produced a bigger flame. He modified the gondola to mount the propane tanks upside down, and returned to the test site where he found the new configuration produced a 12-metre (39 ft) long flame. Strelzyk was ready to attempt an escape.[6]&lt;/p&gt;&lt;head rend="h2"&gt;First escape attempt&lt;/head&gt;[edit]&lt;p&gt;On 3 July 1979, the weather and wind conditions were favourable. The entire Strelzyk family lifted from a forest clearing at 1:30 am and climbed at a rate of 4 metres (13 ft) per second. They reached an altitude of 2,000 metres (6,600 ft) according to an altimeter Strelzyk had made by modifying a barometer. A light wind was blowing them towards the border. The balloon then entered clouds, and atmospheric water vapour condensed on the balloon, adding weight which caused it to descend prematurely. The family landed safely approximately 180 metres (590 ft) short of the border, at the edge of the heavily mined border zone. Unsure of where they were, Strelzyk explored until he found a piece of litter ‚Äì a bread bag from a bakery in Wernigerode, an East German town. The group spent nine hours carefully extricating themselves from the 500-metre (1,600 ft) wide border zone to avoid detection. They also had to travel unnoticed through a 5 km (3.1 mi) restricted zone before hiking back a total of 14 km (8.7 mi) to their car and the launch paraphernalia they had left behind.[6] They made it home just in time to report their absence from work and school due to sickness.[7]&lt;/p&gt;&lt;p&gt;The abandoned balloon was discovered by the authorities later that morning. Strelzyk destroyed all compromising evidence and sold his car, fearing that it could link him to the escape attempt.[6] On 14 August, the Stasi launched an appeal to find the "perpetrator of a serious offence", listing in detail all the items recovered at the landing site.[9] Strelzyk felt that the Stasi would eventually trace the balloon to him and the Wetzels. He agreed with Wetzel that their best chance was to quickly build another balloon and get out as soon as possible.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Successful escape&lt;/head&gt;[edit]&lt;p&gt;Strelzyk and Wetzel decided to double the balloon's size to 4,000 cubic metres (140,000 cu ft) in volume, 20 metres (66 ft) in diameter, and 25 metres (82 ft) in height. They needed 1,250 square metres (13,500 sq ft) of taffeta, and purchased the material, in various colours and patterns, all over the country in order to escape suspicion. Wetzel sewed a third balloon, using over 6 kilometres (3.7 mi) of thread, and Strelzyk rebuilt everything else as before. In six weeks, they had prepared the 180-kilogram (400 lb) balloon and a payload of 550 kilograms (1,210 lb), including the gondola, equipment, and cargo (the two families). Confident in their calculations, they found the weather conditions right on 15 September, when a violent thunderstorm created the correct winds. The two families set off for the launch site in Strelzyk's replacement car (a Wartburg) and a moped. Arriving at 1:30 am, they needed just ten minutes to inflate the balloon and an additional three minutes to heat the air.[6]&lt;/p&gt;&lt;p&gt;Lifting off just after 2:00 am, the group failed to cut the tethers holding the gondola to the ground at the same time, tilting the balloon and sending the flame towards the fabric, which caught fire. After putting out the fire with an extinguisher brought along for just such an emergency, they climbed to 2,000 metres (6,600 ft) in nine minutes, drifting towards West Germany at 30 kilometres per hour (19 mph). The balloon flew for 28 minutes, with the temperature plummeting to ‚àí8 ¬∞C (18 ¬∞F) in the unsheltered gondola, which consisted solely of clothesline railing.&lt;/p&gt;&lt;p&gt;A design miscalculation resulted in the burner stovepipe being too long, causing the flame to be too high in the balloon, creating excessive pressure which caused the balloon to split. The air rushing out of the split extinguished the burner flame. Wetzel was able to re-light the flame with a match, and had to do so several more times before the group landed. At one point, they increased the flame to the maximum possible extent and rose to 2,500 metres (8,200 ft). They later learned they had been high enough to be detected, but not identified, on radar by West German air traffic controllers.[6] They had also been detected on the East German side by a night watchman at the district culture house in Bad Lobenstein. The report of an unidentified flying object heading toward the border caused guards to activate search lights, but the balloon was too high and out of reach of the lights.[10]&lt;/p&gt;&lt;p&gt;The tear in the balloon meant the group had to use the burner much more often, greatly limiting the distance it could travel. Wetzel later said he thought they could have travelled another 50 kilometres (31 mi) had the balloon remained intact. They made out the border crossing at Rudolphstein on the A9 and saw the search lights. When the propane ran out, they descended quickly, landing near the town of Naila, in the West German state of Bavaria and only 10 km (6 mi) from the border. The only injury was suffered by Wetzel, who broke his leg upon landing.[6] Various clues indicated to the families that the balloon had made it across the border. These included spotting red and yellow coloured lights, not common in East Germany,[3] and small farms, in contrast to the large state-run operations in the east. Another clue was modern farm equipment, unlike the older equipment used in East Germany.[11] Two Bavarian State Police officers saw the balloon's flickering light and headed to where they thought it would land. There they found Strelzyk and Wetzel, who first asked if they had made it to the West, although they noticed the police car was an Audi ‚Äì another sign they were in West Germany. Upon learning they had, the escapees happily called for their families to join them.[6]&lt;/p&gt;&lt;head rend="h2"&gt;Aftermath&lt;/head&gt;[edit]&lt;p&gt;East Germany immediately increased border security, closed all small airports close to the border, and ordered the planes kept farther inland.[6] Propane gas tanks became registered products, and large quantities of fabric suitable for balloon construction could no longer be purchased. Mail from East Germany to the two escaped families was prohibited.[12]&lt;/p&gt;&lt;p&gt;Erich Strelzyk learned of his brother's escape on the ZDF news and was arrested in his Potsdam apartment three hours after the landing. The arrest of family members was standard procedure to deter others from attempting escape. He was charged with "aiding and abetting escape", as were Strelzyk's sister Maria and her husband, who were sentenced to 2¬Ω years. The three were eventually released with the help of Amnesty International.[12]&lt;/p&gt;&lt;p&gt;The families decided to initially settle in Naila where they had landed. Wetzel worked as an automobile mechanic and Strelzyk opened a TV repair shop in Bad Kissingen. Due to pressure from Stasi spies, the Strelzyks moved to Switzerland in 1985.[10] After German reunification in 1990, they returned to their old home in their hometown of P√∂√üneck.[13] The Wetzels remained in Bavaria.[7]&lt;/p&gt;&lt;p&gt;West German weekly magazine Stern paid Strelzyk and Wetzel for exclusive rights to the story.[3]&lt;/p&gt;&lt;p&gt;The escape has been portrayed in two films: Night Crossing (1982) and Balloon (2018). The former, also called With the Wind to the West ‚Äì the English translation of the German title ‚Äì was an English-language film produced by Disney. The latter was a German-language production which "both families welcomed [Director] Herbig‚Äôs desire to, as he put it, 'make a German film for an international audience.'" The Strelzyks were reportedly "moved to tears" at the screening of Balloon at Rockefeller Center in New York City.[12] Herbig claimed in 2018 that both the Strelzyk and Wetzel families had been dissatisfied with the Disney film.[14]&lt;/p&gt;&lt;p&gt;Peter Strelzyk died in 2017 at age 74 after a long illness.[13]&lt;/p&gt;&lt;p&gt;In 2017, the balloon was put on permanent display at the Haus der Bayerischen Geschichte: Museum in Regensburg.[10]&lt;/p&gt;&lt;head rend="h2"&gt;Escapees&lt;/head&gt;[edit]&lt;p&gt;The family members included:[3]&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Peter Strelzyk, aged 37&lt;/item&gt;&lt;item&gt;Doris Strelzyk&lt;/item&gt;&lt;item&gt;Frank Strelzyk, aged 15&lt;/item&gt;&lt;item&gt;Andreas Strelzyk, aged 11&lt;/item&gt;&lt;item&gt;G√ºnter Wetzel, aged 24&lt;/item&gt;&lt;item&gt;Petra Wetzel&lt;/item&gt;&lt;item&gt;Peter Wetzel, aged 5&lt;/item&gt;&lt;item&gt;Andreas Wetzel, aged 2&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;Media&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;The Disney film Night Crossing (1982) is an adaptation of the story[13]&lt;/item&gt;&lt;item&gt;Michael Herbig's film Balloon (2018) is a German-language adaptation of the story[15]&lt;/item&gt;&lt;item&gt;BBC program Outlook, "Fleeing Communism in a Hot Air Balloon"[16]&lt;/item&gt;&lt;item&gt;PBS Nova program, "History's Great Escapes" (2004)[17]&lt;/item&gt;&lt;item&gt;Doris Strelzyk, Peter Strelzyk, Gudrun Giese: Destiny Balloon Escape. Quadriga, Berlin 1999, ISBN 3-88679-330-3&lt;/item&gt;&lt;item&gt;J√ºrgen Petschull, With the Wind to the West. The Adventurous Flight from Germany to Germany. Goldmann, Munich 1980, ISBN 3-442-11501-9&lt;/item&gt;&lt;item&gt;Kristen Fulton (Author), Torben Kuhlmann (Illustrator), Flight for Freedom: The Wetzel Family‚Äôs Daring Escape from East Germany. March 3, 2020, ISBN 978-1452149608&lt;/item&gt;&lt;item&gt;The Netflix series White Rabbit Project, episode 2, "Jailbreak"&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;See also&lt;/head&gt;[edit]&lt;head rend="h2"&gt;References&lt;/head&gt;[edit]&lt;list rend="ol"&gt;&lt;item&gt;^ a b Wetzel, G√ºnter. "Die Nacht der Flucht". Ballonflucht.de. Archived from the original on 19 September 2020. Retrieved 16 September 2019.&lt;/item&gt;&lt;item&gt;^ Hertle, Hans-Hermann; Nooke, Maria (2009). Die Todesopfer an der Berliner Mauer 1961‚Äì1989. Ein biographisches Handbuch. Ch. Links Verlag. ISBN 978-3-86153-517-1.&lt;/item&gt;&lt;item&gt;^ a b c d e Getler, Michael (28 September 1979). "Harrowing Flight From East Germany". The Washington Post. Archived from the original on 26 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Snow, Philipp (16 September 2009). "Balloon escape from the GDR With hot air to freedom". Spiegel Online (in German). Archived from the original on 7 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c Simpson, Paul (2013). The Mammoth Book of Prison Breaks. Little, Brown Book Group. p. 216. ISBN 978-1-4721-0024-5. Archived from the original on 16 September 2023. Retrieved 1 April 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e f g h i j k l m n o p q r s Dornberg, John (February 1980). "The Freedom Balloon". Popular Mechanics. pp. 100‚Äì103. Retrieved 22 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c d e Overbye, Stine (13 April 2017). "Fathers wanted to escape GDR in a hot air balloon". Historia (in Dutch). Archived from the original on 1 April 2018. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ Petschull, J√ºrgen (27 September 1979). "Das Himmelfahrtskommando" [High-flying mission] (PDF). Stern (in German). No. 40. p. 34. Archived from the original (PDF) on 12 July 2024 ‚Äì via Museum Naila.&lt;/item&gt;&lt;item&gt;^ Souerbry, Rachel. "How Two Families Escaped East Germany In A Homemade Hot Air Balloon". ranker.com. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Wetzel und Peter Strelzyk Ballonh√ºlle der Strelzyks". museum.bayern (in German). Archived from the original on 8 April 2019. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "East-West: The Great Balloon Escape". Time. 1 October 1979. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "The Balloon Escape of Peter Strelzyk". goethe-rutheneum.de (in German). Archived from the original on 11 February 2013. Retrieved 30 March 2018.&lt;/item&gt;&lt;item&gt;^ a b c "Man who fled East Germany in a homemade balloon and whose story was made into a film dies". The Express. 15 March 2017. Archived from the original on 1 April 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ Connolly, Kate (17 October 2018). "Film of daring balloon escape from East revives German identity debate". Archived from the original on 8 February 2021. Retrieved 10 May 2019.&lt;/item&gt;&lt;item&gt;^ Ballon at IMDb&lt;/item&gt;&lt;item&gt;^ "Fleeing Communism in a Hot Air Balloon". bbc. Archived from the original on 12 December 2018. Retrieved 29 March 2018.&lt;/item&gt;&lt;item&gt;^ "Great Escapes". pbs.org. Archived from the original on 16 April 2019. Retrieved 16 April 2019.&lt;/item&gt;&lt;/list&gt;&lt;head rend="h2"&gt;External links&lt;/head&gt;[edit]&lt;list rend="ul"&gt;&lt;item&gt;Escape by balloon by G√ºnter Wetzel (participant website)&lt;/item&gt;&lt;item&gt;Video of balloon on museum display&lt;/item&gt;&lt;item&gt;BBC Outlook program&lt;/item&gt;&lt;item&gt;Photograph of G√ºenter Wetzel, Peter and Doris Strelzyk Archived 1 April 2018 at the Wayback Machine&lt;/item&gt;&lt;item&gt;Photograph of the actual balloon, inflated in 1985 at a festival in Hof, Bavaria&lt;/item&gt;&lt;/list&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://en.wikipedia.org/wiki/East_Germany_balloon_escape"/><published>2026-01-16T17:16:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46649142</id><title>STFU</title><updated>2026-01-16T23:39:16.707588+00:00</updated><content>&lt;doc fingerprint="a80e03ee7b25e4d9"&gt;
  &lt;main&gt;
    &lt;p&gt;i was at bombay airport. some dude was watching reels on full volume and laughing loudly. asking nicely doesn't work anymore. me being me, didn't have the courage to speak up.&lt;/p&gt;
    &lt;p&gt;so i built a tiny app that plays back the same audio it hears, delayed by ~2 seconds. asked claude, it spat out a working version in one prompt. surprisingly WORKS.&lt;/p&gt;
    &lt;p&gt;discussion - https://x.com/the2ndfloorguy/status/2011734249871954188&lt;/p&gt;
    &lt;p&gt;something something auditory feedback loop something something cognitive dissonance. idk i'm not a neuroscientist. all i know is it makes people shut up and that's good enough for me.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;straight up honest - originally called this "make-it-stop" but then saw @TimDarcet also built similar and named it STFU. wayyyyy better name. so stole it. sorry not sorry.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;made with spite and web audio api. do whatever you want with it.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/Pankajtanwarbanna/stfu"/><published>2026-01-16T17:32:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46649577</id><title>Our approach to advertising</title><updated>2026-01-16T23:39:16.546438+00:00</updated><content>&lt;doc fingerprint="b8a6127125c76bbf"&gt;
  &lt;main&gt;
    &lt;p&gt;AI is reaching a point where everyone can have a personal super-assistant that helps them learn and do almost anything. Who gets access to that level of intelligence will shape whether AI expands opportunity or reinforces the same divides.&lt;/p&gt;
    &lt;p&gt;We‚Äôve been working to make powerful AI accessible to everyone through our free product and low-cost subscription tier, ChatGPT Go, which has launched in 171 countries since August. Today we‚Äôre bringing Go to the U.S. and everywhere ChatGPT is available, giving people expanded access to messaging, image creation, file uploads and memory for $8 USD/month. In the coming weeks, we‚Äôre also planning to start testing ads in the U.S. for the free and Go tiers, so more people can benefit from our tools with fewer usage limits or without having to pay. Plus, Pro, Business, and Enterprise subscriptions will not include ads.&lt;/p&gt;
    &lt;p&gt;People trust ChatGPT for many important and personal tasks, so as we introduce ads, it‚Äôs crucial we preserve what makes ChatGPT valuable in the first place. That means you need to trust that ChatGPT‚Äôs responses are driven by what‚Äôs objectively useful, never by advertising. You need to know that your data and conversations are protected and never sold to advertisers. And we need to keep a high bar and give you control over your experience so you see truly relevant, high-quality ads‚Äîand can turn off personalization if you want.&lt;/p&gt;
    &lt;p&gt;Given that, we want to be clear about the principles that guide our approach to advertising:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Mission alignment: Our mission is to ensure AGI benefits all of humanity; our pursuit of advertising is always in support of that mission and making AI more accessible.&lt;/item&gt;
      &lt;item&gt;Answer independence: Ads do not influence the answers ChatGPT gives you. Answers are optimized based on what's most helpful to you. Ads are always separate and clearly labeled.&lt;/item&gt;
      &lt;item&gt;Conversation privacy: We keep your conversations with ChatGPT private from advertisers, and we never sell your data to advertisers.&lt;/item&gt;
      &lt;item&gt;Choice and control: You control how your data is used. You can turn off personalization, and you can clear the data used for ads at any time. We‚Äôll always offer a way to not see ads in ChatGPT, including a paid tier that‚Äôs ad-free.&lt;/item&gt;
      &lt;item&gt;Long-term value: We do not optimize for time spent in ChatGPT. We prioritize user trust and user experience over revenue.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We‚Äôre not launching ads yet, but we do plan to start testing in the coming weeks for logged in adults in the U.S. on the free and Go tiers. To start, we plan to test ads at the bottom of answers in ChatGPT when there‚Äôs a relevant sponsored product or service based on your current conversation. Ads will be clearly labeled and separated from the organic answer. You‚Äôll be able to learn more about why you‚Äôre seeing that ad, or dismiss any ad and tell us why. During our test, we will not show ads in accounts where the user tells us or we predict that they are under 18, and ads are not eligible to appear near sensitive or regulated topics like health, mental health or politics.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs an example of what the first ad formats we plan to test could look like:&lt;/p&gt;
    &lt;p&gt;The best ads are useful, entertaining, and help people discover new products and services. Given what AI can do, we're excited to develop new experiences over time that people find more helpful and relevant than any other ads. Conversational interfaces create possibilities for people to go beyond static messages and links. For example, soon you might see an ad and be able to directly ask the questions you need to make a purchase decision.&lt;/p&gt;
    &lt;p&gt;Ads also can be transformative for small businesses and emerging brands trying to compete. AI tools level the playing field even further, allowing anyone to create high-quality experiences that help people discover options they might never have found otherwise.&lt;/p&gt;
    &lt;p&gt;We‚Äôll learn from feedback and refine how ads show up over time, but our commitment to putting users first and maintaining trust won‚Äôt change. By starting our ad platform from the ground up with these principles in place, we can align our incentives with what people want from ChatGPT. Our long-term focus remains on building products that millions of people and businesses find valuable enough to pay for. Our enterprise and subscription businesses are already strong, and we believe in having a diverse revenue model where ads can play a part in making intelligence more accessible to everyone.&lt;/p&gt;
    &lt;p&gt;Once we begin testing our first ad formats in the coming weeks and months, we look forward to getting people's feedback and ensuring that ads can support broad access to AI and keep the trust that makes ChatGPT valuable.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://openai.com/index/our-approach-to-advertising-and-expanding-access/"/><published>2026-01-16T18:02:19+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46650347</id><title>Reading across books with Claude Code</title><updated>2026-01-16T23:39:16.337345+00:00</updated><content>&lt;doc fingerprint="3f200f9427931e3e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Reading across books with Claude Code&lt;/head&gt;
    &lt;p&gt;Jan 4, 2026&lt;/p&gt;
    &lt;p&gt;LLMs are overused to summarise and underused to help us read deeper.&lt;/p&gt;
    &lt;p&gt;To explore how they can enrich rather than reduce, I set Claude Code up with tools to mine a library of 100 non-fiction books. It found sequences of excerpts connected by an interesting idea, or trails.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs a part of one such trail, linking deception in the startup world to the social psychology of mass movements (I‚Äôm especially pleased by the jump from Jobs to Theranos):&lt;/p&gt;
    &lt;head rend="h2"&gt;How it works&lt;/head&gt;
    &lt;p&gt;The books were selected from Hacker News‚Äô favourites, which I previously scraped and visualized.&lt;/p&gt;
    &lt;p&gt;Claude browses the books a chunk at a time. A chunk is a segment of roughly 500 words that aligns with paragraphs when possible. This length is a good balance between saving tokens and providing enough context for ideas to breathe.&lt;/p&gt;
    &lt;p&gt;Chunks are indexed by topic, and topics are themselves indexed for search. This makes it easy to look up all passages in the corpus that relate to, say, deception.&lt;/p&gt;
    &lt;p&gt;This works well when you know what to look for, but search alone can‚Äôt tell you which topics are present to begin with. There are over 100,000 extracted topics, far too many to be browsed directly. To support exploration, they are grouped into a hierarchical tree structure.&lt;/p&gt;
    &lt;p&gt;This yields around 1,000 top-level topics. They emerge from combining lower-level topics, and not all of them are equally useful:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Incidents that frustrated Ev Williams&lt;/item&gt;
      &lt;item&gt;Names beginning with ‚ÄúDa‚Äù&lt;/item&gt;
      &lt;item&gt;Events between 1971 &amp;amp; 1974&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;However, this Borgesian taxonomy is good enough for Claude to piece together what the books are about.&lt;/p&gt;
    &lt;p&gt;Claude uses the topic tree and the search via a few CLI tools.&lt;lb/&gt; They allow it to:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Find all chunks associated with a topic similar to a query.&lt;/item&gt;
      &lt;item&gt;Find topics which occur in a window of chunks around a given topic.&lt;/item&gt;
      &lt;item&gt;Find topics that co-occur in multiple books.&lt;/item&gt;
      &lt;item&gt;Browse topics and chunks that are siblings in the topic tree.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To generate the trails, the agent works in stages.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;First, it scans the library and the existing trails, and proposes novel trail ideas. It mainly browses the topic tree to find unexplored areas and rarely reads full chunks in depth.&lt;/item&gt;
      &lt;item&gt;Then, it takes a specific idea and turns it into a trail. It receives seed topics from the previous stage and browses many chunks. It extracts excerpts, specific sequences of sentences, and decides on how best to order them to support an insight.&lt;/item&gt;
      &lt;item&gt;Finally, it adds highlights and edges between consecutive excerpts.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What I learned&lt;/head&gt;
    &lt;head rend="h3"&gt;Claude Code is great for non-coding tasks&lt;/head&gt;
    &lt;p&gt;Even though I‚Äôve been using Claude Code to develop for months, my first instinct for this project was to consider it as a traditional pipeline of several discrete stages. My initial attempt at this system consisted of multiple LLM modules with carefully hand-assembled contexts.&lt;/p&gt;
    &lt;p&gt;On a whim, I ran Claude with access to the debugging tools I‚Äôd been using and a minimal prompt: ‚Äúfind something interesting.‚Äù It immediately did a better job at pulling in what it needed than the pipeline I was trying to tune by hand, while requiring much less orchestration. It was a clear improvement to push as much of the work into the agent‚Äôs loop as possible.&lt;/p&gt;
    &lt;p&gt;I ended up using Claude as my main interface to the project.&lt;lb/&gt; Initially I did so because it inferred the sequence of CLI calls I wanted to run faster than I could recall them. Then, I used it to automate tasks which weren‚Äôt rigid enough to be scripted traditionally.&lt;/p&gt;
    &lt;p&gt;The latter opened up options that I wouldn‚Äôt have considered before. For example, I changed my mind on how short I wanted excerpts to be. I communicated my new preference to Claude, which then looked through all the existing trails and edited them as necessary, balancing the way the overall meaning of the trail changed. Previously, I would‚Äôve likely considered all previous trails to be outdated and generated new ones, because the required edits would‚Äôve been too nuanced to specify.&lt;/p&gt;
    &lt;p&gt;In general, agents have widened my ambitions.&lt;lb/&gt; By taking care of the boilerplate, I no longer shy away from the tedious parts. Revision is cheap, so I don‚Äôt need to plow ahead with suboptimal choices just because it‚Äôd be too costly to undo them. This, in turn, keeps up the momentum and lets me focus on the joyful, creative aspects of the work.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ask the agent what it needs&lt;/head&gt;
    &lt;p&gt;My focus went from optimising prompts to implementing better tools for Claude to use, moving up a rung on the abstraction ladder.&lt;/p&gt;
    &lt;p&gt;My mental model of the AI component changed: from a function mapping input to output, to a coworker I was assisting. I spent my time thinking about the affordances that would make the workflow better, as if I were designing them for myself. That they were to be used by an agent was a mere detail.&lt;/p&gt;
    &lt;p&gt;This worked because the agent is now intelligent enough that the way it uses these tools overlaps with my own mental model. It is generally easy to empathise with it and predict what it will do.&lt;/p&gt;
    &lt;p&gt;Initially I watched Claude‚Äôs logs closely and tried to guess where it was lacking a certain ability. Then I realised I could simply ask it to provide feedback at the end and list the functionality it wished it had. Claude was excellent at proposing new commands and capabilities that would make the work more efficient.&lt;/p&gt;
    &lt;p&gt;Claude suggested improvements, which Claude implemented, so Claude could do the work better. At least I‚Äôm still needed to pay for the tokens ‚Äî for now.&lt;/p&gt;
    &lt;head rend="h3"&gt;Novelty is a useful guide&lt;/head&gt;
    &lt;p&gt;It‚Äôs hard to quantify interestingness as an objective to optimise for.&lt;lb/&gt; Why Greatness Cannot Be Planned makes the case that chasing novelty is often a more fruitful approach. While its conclusions are debated, I‚Äôve found this idea to be a good fit for this project.&lt;/p&gt;
    &lt;p&gt;As a sign of the times, this novelty search was implemented in two ways:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;By biasing the search algorithm towards under-explored topics and books.&lt;/item&gt;
      &lt;item&gt;By asking Claude nicely.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;A topic‚Äôs novelty score was calculated as the mean distance from its embedding‚Äôs k nearest neighbors. A book‚Äôs novelty score is the average novelty of the unique topics that it contains. This value was used to rank search results, so that those which were both relevant and novel were more likely to be seen.&lt;/p&gt;
    &lt;p&gt;On a prompting level, Claude starts the ideation phase by looking at all the existing trails and is asked to avoid any conceptual overlap. This works fairly well, though it is often distracted by any topics related to secrecy, systems theory, or tacit knowledge.&lt;/p&gt;
    &lt;p&gt;It‚Äôs as if the very act of finding connections in a corpus summons the spirit of Umberto Eco and amps up the conspiratorial thinking.&lt;/p&gt;
    &lt;head rend="h2"&gt;How it‚Äôs implemented&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;EPUBs are parsed using &lt;code&gt;selectolax&lt;/code&gt;, which I picked over BeautifulSoup for its speed and simpler API.&lt;/item&gt;
      &lt;item&gt;Everything from the plain text to the topic tree is stored in SQLite. Embeddings are stored using &lt;code&gt;sqlite-vec&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;The text is split into sentences using &lt;code&gt;wtpsplit&lt;/code&gt;(the&lt;code&gt;sat-6l-sm&lt;/code&gt;model). Those sentences are then grouped into chunks, trying to get up to 500 words without breaking up paragraphs.&lt;/item&gt;
      &lt;item&gt;I used &lt;code&gt;DSPy&lt;/code&gt;to call LLMs. It worked well for the structured data extraction and it was easy to switch out different models to experiment. I tried its prompt optimizers before I went full agentic, and their results were very promising.&lt;/item&gt;
      &lt;item&gt;I settled on Gemini 2.5 Flash Lite for topic extraction. The model gets passed a chunk and is asked to return 3-5 topics. It is also asked whether the chunk is useful, in order to filter out index entries, acknowledgements, orphan headers, etc. I was surprised at how stable these extracted topics were: similar chunks often shared some of the exact same topic labels. Processing 100 books used about 60M input tokens and ~¬£10 in total.&lt;/item&gt;
      &lt;item&gt;After a couple books got indexed, I shared the results with Claude Opus along with the original prompt and asked it to improve it. This is a half-baked single iteration of the type of prompt optimisation DSPy implements, and it worked rather well.&lt;/item&gt;
      &lt;item&gt;Topic pairs with a distance below a threshold get merged together. This takes care of near-duplicates such as ‚ÄúStartup founder‚Äù, ‚ÄúStartup founders‚Äù, and ‚ÄúFounder of startups‚Äù.&lt;/item&gt;
      &lt;item&gt;The CLI output uses a semi-XML format. In order to stimulate navigating, most output is nested with related content. For example, when searching for a topic, chunks are shown with the other topics they contain. This allows us to get a sense of what the chunk is about, as well as which other topics might be interesting. There‚Äôs probably more token-efficient formats, but I never hit the limit of the context window.&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;&amp;lt;topics query="deception" count="1"&amp;gt;
  &amp;lt;topic id="47193" books="7" score="0.0173" label="Deception"&amp;gt;
    &amp;lt;chunk id="186" book="1"&amp;gt;
      &amp;lt;topic id="47192" label="Business deal"/&amp;gt;
      &amp;lt;topic id="47108" label="Internal conflict"/&amp;gt;
      &amp;lt;topic id="46623" label="Startup founders"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
    &amp;lt;chunk id="1484" book="4"&amp;gt;
      &amp;lt;topic id="51835" label="Gawker Media"/&amp;gt;
      &amp;lt;topic id="53006" label="Legal Action"/&amp;gt;
      &amp;lt;topic id="52934" label="Maskirovka"/&amp;gt;
      &amp;lt;topic id="52181" label="Strategy"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
    &amp;lt;chunk id="2913" book="9"&amp;gt;
      &amp;lt;topic id="59348" label="Blood testing system"/&amp;gt;
      &amp;lt;topic id="59329" label="Elizabeth Holmes"/&amp;gt;
      &amp;lt;topic id="59352" label="Investor demo"/&amp;gt;
      &amp;lt;topic id="59349" label="Theranos"/&amp;gt;
    &amp;lt;/chunk&amp;gt;
  &amp;lt;/topic&amp;gt;
&amp;lt;/topics&amp;gt;&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;p&gt;Topics are embedded using&lt;/p&gt;&lt;code&gt;google/embeddinggemma-300m&lt;/code&gt;and reranked using&lt;code&gt;BAAI/bge-reranker-v2-m3&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Many CLI tools require loading the embedding model and other expensive state. The first call transparently starts a separate server process which loads all these resources once and holds onto them for a while. Subsequent CLI calls use this server through Python‚Äôs&lt;/p&gt;&lt;code&gt;multiprocessing.connection&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The topic collection is turned into a graph (backed by&lt;/p&gt;&lt;code&gt;igraph&lt;/code&gt;) by adding edges based on the similarity of their embeddings and the point-wise mutual information of their co-occurrences.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The graph is turned into a tree by applying Leiden partitioning recursively until a minimum size is reached. I tried the Surprise quality function because it had no parameters to tweak, and found it to be good enough. Each group is labelled by Gemini based on all the topics that it contains.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Excerpts are cleaned by Gemini to remove EPUB artifacts, parsing errors, headers, footnotes, etc. Doing this only for excerpts that are actually shown, instead of during pre-processing, saved a lot of tokens.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pieterma.es/syntopic-reading-claude/"/><published>2026-01-16T18:49:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46651443</id><title>Slop is everywhere for those with eyes to see</title><updated>2026-01-16T23:39:16.143923+00:00</updated><content>&lt;doc fingerprint="bfdad9808435cf88"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Slop is Everywhere For Those With Eyes to See&lt;/head&gt;
    &lt;p&gt;The size of your plate can influence how much food you eat. The absence of a clock on a casino wall can keep you gambling through the early morning. On social media, our For You Pages give us the illusion of infinite content. How our environments are designed influences how we consume. And wouldn't you know it, everything around us is designed for maximum consumption.&lt;/p&gt;
    &lt;p&gt;Open TikTok, and you can easily burn through a hundred videos or more before you glance at the time. It doesn't help that the For You Page hides the time on our phones.&lt;/p&gt;
    &lt;p&gt;We are over consuming content on the FYP. The sudden surge of low-quality, AI-generated content, i.e. ‚ÄúAI slop,‚Äù is a byproduct of that overconsumption. We don't see it because, well, we're conditioned not to, but slop always arrives on time. Slop is inevitable. Slop is quintessential. Slop is everywhere for those with eyes to see.&lt;/p&gt;
    &lt;p&gt;Olive oil, wasabi, saffron, vanilla, Wagyu, honey, champagne, and truffle,...reality TV, all hold examples of what happens when demand exceeds supply‚Äî companies fill the gap with slop. The free market loves a good filler. So, why should the digital realm be any different?&lt;/p&gt;
    &lt;p&gt;The For You page is designed to keep us playing the dopamine slot machine for as long as possible. The Average Time on Site metric is still the goose that lays the golden eggs, and both TikTok and Meta are reporting that their egg baskets have never been fuller.&lt;/p&gt;
    &lt;p&gt;But, there's a problem. On any given platform, only 1-3% of users publish content. It's called the 90-9-1 rule, and platforms that rely on free user generated content have been trying to solve this problem since the beginning of the commercialized web. The introduction of the For You Page, and the illusion of endless content, has only exasperated the inequity.&lt;/p&gt;
    &lt;p&gt;Curation used to be part of our media consumption process. We would hop from website to website looking for a laugh. We used to click on hyperlinks for Christ's sake. Now, all we must do is sit at the troughÔøº and let daddy Zuck feed us.&lt;/p&gt;
    &lt;p&gt;In a recent essay, Joan Westenberg makes a complementary argument that the algorithm has ‚Äúflattened‚Äù curiosity by eliminating the need to ‚Äúhunt‚Äù for our content. They go on to say:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;There‚Äôs a concept in behavioral science called the ‚Äúeffort heuristic.‚Äù It‚Äôs the idea that we tend to value information more if we worked for it. The more effort something requires, the more meaning we assign to the result. When all knowledge is made effortless, it‚Äôs treated as disposable. There‚Äôs no awe, no investment, no delight in the unexpected‚Äîonly consumption.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;(I'm reminded of the scene in Jurassic Park when the tour Jeep pulls up to the Tyrannosaurus rex exhibit. Doctor Grant saysÔøº ‚ÄúThe T-Rex doesn't want to be fed. It wants to hunt.‚Äù)&lt;/p&gt;
    &lt;p&gt;ÔøºThis type of mindless consumption is not only harming our curiosity, it's helping to cheapen creativity for the people who produce what we consume.&lt;/p&gt;
    &lt;p&gt;Creativity isn't scalable. Content creation has a hard productivity ceiling. Every human-created video on our feeds require some level of writing, production, and editing. Yet the For You Page has made the content consumption so efficient, that perhaps demand has exceeded supply.&lt;/p&gt;
    &lt;p&gt;If you're a product manager for a social media platform, you can reduce the friction of publishing content to the app, or ship better editing tools, but you can't optimize creative spark. You can't treat humans like content-generating machines (as much as they have tried). Despite the illusion of infinite scrolling thanks to the FYP, art remains a finite resource bound to the whims of human creativity.&lt;/p&gt;
    &lt;p&gt;You see their problem.&lt;/p&gt;
    &lt;p&gt;Mark Zuckerberg wants us on his platforms, flicking our thumbs, for as long as possible. But the more we open Instagram, the more creators he needs posting multiple times each day. Mark has very little control over this variable. Creators could suddenly post less, or simply stop posting all together, and there's nothing he could do about it. What's worse, creators could demand Meta pay them for their art.&lt;/p&gt;
    &lt;p&gt;Could you imagine?&lt;/p&gt;
    &lt;p&gt;Actually, yes. And it turns out, you could rather effectively kill a platform if you got a small group of top creators organized and angry.&lt;/p&gt;
    &lt;head rend="h2"&gt;Twenty on the Vine #&lt;/head&gt;
    &lt;p&gt;In the summer of 2016, twenty social media personalities took down one of the largest mobile video apps on the internet. They wanted money for their labor. The executives at Vine said no. The gang of twenty, who were the highest performing creators on the app, walked away. They stopped posting entertaining content to Vine, and instead repeatedly implored their followers to find them on competing apps.&lt;/p&gt;
    &lt;p&gt;Vine shut down for good just months later.&lt;/p&gt;
    &lt;p&gt;From Inside the secret meeting of Vine stars that ushered in the app‚Äôs demise:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Vine‚Äôs spectacular rise and fall showed the power of online creators. Its demise offers crucial lessons for platforms trying to engage with power users ‚Äî and a deeper understanding of who ultimately controls a social product.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Vine creators exposed and exploited a weakness in Vine's conventional approach to social media. Follower count had power. Old-style discovery algorithms could be easily manipulated. Vine creators used that power to take over the app, and convinced users to migrate to other platforms.&lt;/p&gt;
    &lt;p&gt;You see why follower counts are less important today, and why black-box algorithms have full control over who goes viral and who gets ‚Äúshadow banned.‚Äù TikTok saw the mistakes of its predecessor, and made it so content creators could never exercise collective influence again.&lt;/p&gt;
    &lt;p&gt;Because virality now feels more like gambling, I suspect people post more content today than a decade ago. But it's not enough. Our insatiable appetites for content is pushing for corporations to meet that demand with slop. Ôøº&lt;/p&gt;
    &lt;p&gt;If it were up to TikTok and Meta, our feeds would be exclusively robot-made. Humans are a variable they cannot control, and I think they despise us for it.&lt;/p&gt;
    &lt;p&gt;Anyway, I have good news. Outside of our FYPs you'll find a surplus of art, essays, articles, and videos just waiting to be discovered. And best of all, these artists and writers are making things on their own terms. We, too, can enjoy the products of their labor on our terms, while not giving a dime of our attention to big tech.&lt;/p&gt;
    &lt;p&gt;This is the open web. Or the social web. Or the open social web. Or the-- you get the point. To find it, you must reacquaint yourself with the lost art of surfing the web.&lt;/p&gt;
    &lt;p&gt;Surfing the web is very different than scrolling the FYP. You don't often hear the words ‚Äùmindful‚Äù and ‚Äúinternet‚Äù together but, surfing the web was an art of mindful consumption that doesn't much exist today. Not to get all old man yells at cloud at you, but maybe we should bring it back?&lt;/p&gt;
    &lt;p&gt;Up next: The Lost Art of Surfing The Web (coming soon)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.fromjason.xyz/p/notebook/slop-is-everywhere-for-those-with-eyes-to-see/"/><published>2026-01-16T20:03:10+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46651887</id><title>LWN is currently under the heaviest scraper attack seen yet</title><updated>2026-01-16T23:39:15.699013+00:00</updated><content>&lt;doc fingerprint="7913b8b34d26459b"&gt;
  &lt;main&gt;
    &lt;p&gt;@corbet @lwn this, combined with search engines prioritising the stolen content!&lt;lb/&gt; This is why I think the web is genuinely doomed. It's not enough to steal the content, for search engines to kill click thtoughs and ad revenues, they are literally killing the ability of original authors to serve the traffic to the few real users that might want to see it.&lt;lb/&gt; Devastating.&lt;/p&gt;
    &lt;p&gt;This helped me a lot with my little projects:&lt;lb/&gt;https://codeberg.org/skewray/htaccess&lt;/p&gt;
    &lt;p&gt;@corbet @lwn at this point we might as well be offensive. If the client seems even slightly sus, just send them gibberish data talking about how good Chihuahua muffins are. Ideally LLM-generated (yes, gross) because this doesn't add new information (linear algebra yay) and makes models collapse (aka AI inbreeding).&lt;/p&gt;
    &lt;p&gt;@cadey @corbet @lwn &lt;lb/&gt;I recently saw a traffic spike to a small HTML-only website that never had WP on it, but was suddenly getting failed wp-admin logins and hundreds of PHP vuln scans, non stop. All from MSFT IP addresses. Abuse reports were sent, but there was no response, and the abuse kept happening.&lt;lb/&gt;So now I'm blocking every MSFT CIDR block that I can find, server-wide.&lt;/p&gt;
    &lt;p&gt;Maybe it doesn't need to be subscriber only, just registered users only? Which can also be a PITA, but if there's no enshittification for non-registered users other than the bandwidth being shared with bots, maybe it's tolerable? Could even have a banner about this explaining the benefits of registering, and how LWN won't sell your data.&lt;/p&gt;
    &lt;p&gt;Yeah, it's hard to argue against that.&lt;/p&gt;
    &lt;p&gt;And maybe you weren't seeking for "helpful" advice anyway, but, uh, you know your audience. :)&lt;/p&gt;
    &lt;p&gt;@corbet @lwn @jani @suihkulokki I have a simple solution: Stop being so damn relevant!!!&lt;/p&gt;
    &lt;p&gt;Wait... ü§°&lt;/p&gt;
    &lt;p&gt;@mupuf @corbet @lwn @suihkulokki&lt;/p&gt;
    &lt;p&gt;I don't think the scrapers care about that, though.&lt;/p&gt;
    &lt;p&gt;@jani @corbet @lwn @suihkulokki Sorry, I was being too optimistic... I was thinking they wanted sources with high SNR... But you are probably right...&lt;/p&gt;
    &lt;p&gt;@corbet @lwn @jani @suihkulokki one day the photocopiers will get busy after the office hours again, but this time it's going to be linux weekly news instead of the punk fanzines&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://social.kernel.org/notice/B2JlhcxNTfI8oDVoyO"/><published>2026-01-16T20:37:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46652617</id><title>Releasing rainbow tables to accelerate Net-NTLMv1 protocol deprecation</title><updated>2026-01-16T23:39:15.319962+00:00</updated><content>&lt;doc fingerprint="ac035d9b403222ef"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Closing the Door on Net-NTLMv1: Releasing Rainbow Tables to Accelerate Protocol Deprecation&lt;/head&gt;
    &lt;head rend="h5"&gt;Mandiant&lt;/head&gt;
    &lt;p&gt;Written by: Nic Losby&lt;/p&gt;
    &lt;head rend="h3"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Mandiant is publicly releasing a comprehensive dataset of Net-NTLMv1 rainbow tables to underscore the urgency of migrating away from this outdated protocol. Despite Net-NTLMv1 being deprecated and known to be insecure for over two decades‚Äîwith cryptanalysis dating back to 1999‚ÄîMandiant consultants continue to identify its use in active environments. This legacy protocol leaves organizations vulnerable to trivial credential theft, yet it remains prevalent due to inertia and a lack of demonstrated immediate risk.&lt;/p&gt;
    &lt;p&gt;By releasing these tables, Mandiant aims to lower the barrier for security professionals to demonstrate the insecurity of Net-NTLMv1. While tools to exploit this protocol have existed for years, they often required uploading sensitive data to third-party services or expensive hardware to brute-force keys. The release of this dataset allows defenders and researchers to recover keys in under 12 hours using consumer hardware costing less than $600 USD. This initiative highlights the amplified impact of combining Mandiant's frontline expertise with Google Cloud's resources to eliminate entire classes of attacks.&lt;/p&gt;
    &lt;p&gt;This post details the generation of the tables, provides access to the dataset for community use, and outlines critical remediation steps to disable Net-NTLMv1 and prevent authentication coercion attacks.&lt;/p&gt;
    &lt;head rend="h3"&gt;Background&lt;/head&gt;
    &lt;p&gt;Net-NTLMv1 has been widely known to be insecure since at least 2012, following presentations at DEFCON 20, with cryptanalysis of the underlying protocol dating back to at least 1999. On Aug. 30, 2016, Hashcat added support for cracking Data Encryption Standard (DES) keys using known plaintext, further democratizing the ability to attack this protocol. Rainbow tables are almost as old, with the initial paper on rainbow tables published in 2003 by Philippe Oechslin, citing an earlier iteration of a time-memory trade-off from 1980 by Martin Hellman.&lt;/p&gt;
    &lt;p&gt;Essentially, if an attacker can obtain a Net-NTLMv1 hash without Extended Session Security (ESS) for the known plaintext of &lt;code&gt;1122334455667788&lt;/code&gt;, a cryptographic attack, referred to as a known plaintext attack (KPA), can be applied. This guarantees recovery of the key material used. Since the key material is the password hash of the authenticating Active Directory (AD) object‚Äîuser or computer‚Äîthe attack results can quickly be used to compromise the object, often leading to privilege escalation.&lt;/p&gt;
    &lt;p&gt;A common chain attackers use is authentication coercion from a highly privileged object, such as a domain controller (DC). Recovering the password hash of the DC machine account allows for DCSync privileges to compromise any other account in AD.&lt;/p&gt;
    &lt;head rend="h3"&gt;Dataset Release&lt;/head&gt;
    &lt;p&gt;The unsorted dataset can be downloaded using &lt;code&gt;gsutil -m cp -r gs://net-ntlmv1-tables/tables .&lt;/code&gt;¬†or through the Google Cloud Research Dataset portal.¬†&lt;/p&gt;
    &lt;p&gt;The SHA512 hashes of the tables can be checked by first downloading the checksums &lt;code&gt;gsutil -m cp gs://net-ntlmv1-tables/tables.sha512 .&lt;/code&gt; then checked by &lt;code&gt;sha512sum -c tables.sha512&lt;/code&gt;. The password cracking community has already created derivative work and is also hosting the ready to use tables.&lt;/p&gt;
    &lt;head rend="h3"&gt;Use of the Tables&lt;/head&gt;
    &lt;p&gt;Once a Net-NTLMv1 hash has been obtained, the tables can be used with historical or modern reinventions of rainbow table searching software such as rainbowcrack (rcrack), or RainbowCrack-NG on central processing units (CPUs) or a fork of rainbowcrackalack on graphics processing units (GPUs). The Net-NTLMv1 hash needs to be preprocessed to the DES components using ntlmv1-multi as shown in the next section.&lt;/p&gt;
    &lt;head rend="h3"&gt;Obtaining a Net-NTLMv1 Hash&lt;/head&gt;
    &lt;p&gt;Most attackers will use Responder with the &lt;code&gt;--lm&lt;/code&gt; and &lt;code&gt;--disable-ess&lt;/code&gt;¬†flags and set the authentication to a static value of &lt;code&gt;1122334455667788&lt;/code&gt; to only allow for connections with Net-NTLMv1 as a possibility. Attackers can then wait for incoming connections or coerce authentication using a tool such as PetitPotam or DFSCoerce to generate incoming connections from DCs or lower privilege hosts that are useful for objective completion. Responses can be cracked to retrieve password hashes of either users or computer machine accounts. A sample workflow for an attacker is shown below in Figure 1, Figure 2, and Figure 3.&lt;/p&gt;
    &lt;p&gt;Figure 1: DFSCoerce against a DC&lt;/p&gt;
    &lt;p&gt;Figure 2: Net-NTLMv1 hash obtained for DC machine account&lt;/p&gt;
    &lt;p&gt;Figure 3: Parse Net-NTLMv1 hash to DES parts&lt;/p&gt;
    &lt;p&gt;Figure 4 illustrates the processing of the Net-NTLMv1 hash to the DES ciphertexts.&lt;/p&gt;
    &lt;p&gt;Figure 4: Net-NTLMv1 hash to DES ciphertexts&lt;/p&gt;
    &lt;p&gt;An attacker then takes the split-out ciphertexts to crack the keys used based on the known plaintext of &lt;code&gt;1122334455667788&lt;/code&gt; with the steps of loading the tables shown in Figure 5 and cracking results in Figure 6 and Figure 7.&lt;/p&gt;
    &lt;p&gt;Figure 5: Loading DES components for cracking&lt;/p&gt;
    &lt;p&gt;Figure 6: First hash cracked&lt;/p&gt;
    &lt;p&gt;Figure 7: Second hash cracked and run statistics&lt;/p&gt;
    &lt;p&gt;An attacker can then calculate the last remaining key with ntlmv1-multi once again, or look it up with twobytes, to recreate the full NT hash for the DC account with the last key part shown in Figure 8.&lt;/p&gt;
    &lt;p&gt;Figure 8: Calculate remaining key&lt;/p&gt;
    &lt;p&gt;The result can be checked with hashcat's NT hash shucking mode, &lt;code&gt;-m 27000&lt;/code&gt;, as shown in Figure 9.&lt;/p&gt;
    &lt;p&gt;Figure 9: Keys checked with hash shucking&lt;/p&gt;
    &lt;p&gt;An attacker can then use the hash to perform a DCSync attack targeting a DC and authenticating as the now compromised machine account. The attack flow uses secretsdump.py from the Impacket toolsuite and is shown in Figure 10.&lt;/p&gt;
    &lt;p&gt;Figure 10: DCSync attack performed&lt;/p&gt;
    &lt;head rend="h3"&gt;Remediation&lt;/head&gt;
    &lt;p&gt;Organizations should immediately disable the use of Net-NTLMv1.&lt;/p&gt;
    &lt;head rend="h4"&gt;Local Computer Policy&lt;/head&gt;
    &lt;p&gt;"Local Security Settings" &amp;gt; "Local Policies" &amp;gt; "Security Options" &amp;gt; ‚ÄúNetwork security: LAN Manager authentication level" &amp;gt; "Send NTLMv2 response only".&lt;/p&gt;
    &lt;head rend="h4"&gt;Group Policy&lt;/head&gt;
    &lt;p&gt;"Computer Configuration" &amp;gt; "Policies" &amp;gt; "Windows Settings" &amp;gt; "Security Settings" &amp;gt; "Local Policies" &amp;gt; "Security Options" &amp;gt; "Network Security: LAN Manager authentication level" &amp;gt; "Send NTLMv2 response only"&lt;/p&gt;
    &lt;p&gt;As these are local to the computer configurations, attackers can and have set the configuration to a vulnerable state to then fix the configuration after their attacks have completed with local administrative access. Monitoring and alerting of when and where Net-NTLMv1 is used is needed in addition to catching these edge cases.&lt;/p&gt;
    &lt;p&gt;Filter Event Logs for Event ID 4624: "An Account was successfully logged on." &amp;gt; "Detailed Authentication Information" &amp;gt; "Authentication Package" &amp;gt; "Package Name (NTLM only)", if "LM" or "NTLMv1" is the value of this attribute, LAN Manager or Net-NTLMv1 was used.&lt;/p&gt;
    &lt;head rend="h3"&gt;Related Reading&lt;/head&gt;
    &lt;p&gt;This project was inspired by and referenced the following research published to blogs, social media, and code repositories.&lt;/p&gt;
    &lt;head rend="h3"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;Thank you to everyone who helped make this blog post possible, including but not limited to Chris King and Max Gruenberg.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://cloud.google.com/blog/topics/threat-intelligence/net-ntlmv1-deprecation-rainbow-tables"/><published>2026-01-16T21:42:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46652914</id><title>Drawbot: Let's hack something cute (2025)</title><updated>2026-01-16T23:39:14.932960+00:00</updated><content>&lt;doc fingerprint="3686da310d772f96"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Drawbot: Let‚Äôs Hack Something Cute!&lt;/head&gt;
    &lt;head rend="h2"&gt;The Target&lt;/head&gt;
    &lt;p&gt;A few months ago I realized I was overdue for a fun, quirky hardware project. Every so often I like to see what new and interesting electronic children's toys are out there. When looking, I keep in mind the potential attack surface, typically preferring toys with companion mobile apps, wireless communications, or any other added complexity.&lt;/p&gt;
    &lt;p&gt;I came across these robots that draw from a set of pre-defined images. They all come with a pack of 100 or 150 cards, and the drawings appear very similar across brands. The attack surface seemed especially small, given that it uses pre-defined physical cards, so I wouldn't be able to snoop an FCC ID for this one and peek into its sweet, sweet innards (I consider those spoilers anyway). Regardless, it seemed like an interesting target and I couldn't resist.&lt;/p&gt;
    &lt;p&gt;I picked this one because it had the best face. The wording/typos on the box were definitely a good sign that there was some quirkiness afoot. It came with a stack of 100 cards, each with a very minimal "barcode" consisting of 8 bits of information, meaning 256 possible barcodes/drawings. The cards were separated into five categories: food, animal, plant, vehicle, and circle (obviously). I loaded up the ‚Äúbulbous cactus‚Äù card and sent it on its way. It talked. It sang. It‚Äôs perfect.&lt;/p&gt;
    &lt;p&gt;Let us commence the evisceration.&lt;/p&gt;
    &lt;head rend="h2"&gt;Tearing it Down&lt;/head&gt;
    &lt;p&gt;If I'm being honest, this is my favorite part.&lt;/p&gt;
    &lt;p&gt;On the bottom we have a few ultra-recessed screw-holes. You'd think at this point I'd be properly equipped to deal with these, but I'm not. Without fail, every hardware assessment helps me realize what I still don't have (besides patience). No matter how many specialized tools or components I amass in my home lab, there's always something that I end up having to buy. At this point I could have easily purchased what I needed for same or next-day delivery, but that would require patience. I could have probably 3D printed something to do the job. Again, I'm not that patient.&lt;/p&gt;
    &lt;p&gt;What I lack in patience I make up for in power tools. I ended up using a combination of, well, drilling the hole slightly bigger to clear some of my screwdriver bits, and chaining bits together.&lt;/p&gt;
    &lt;p&gt;With the four recessed screws removed, the top half popped off without much additional trouble.&lt;/p&gt;
    &lt;p&gt;With the barcode reader exposed, I tried some very basic preliminary fuzzing by taking a valid card and shifting it around to provide unexpected input. When a card is placed over the sensors, the device makes a sound and then announces the associated image.&lt;/p&gt;
    &lt;p&gt;While fuzzing, various images were announced, all of which seemed to match up with other cards I had seen in the deck, until the robot announced "Take a bath!" This seemed odd (and mildly offensive), so I rummaged through the deck and could not for the life of me find any cards with bath imagery.&lt;/p&gt;
    &lt;p&gt;With the card held in place, I pushed the button to initiate drawing. The robot started singing and, surely enough, drew this image:&lt;/p&gt;
    &lt;head rend="h2"&gt;Goals&lt;/head&gt;
    &lt;p&gt;Now that I had a decent idea what I was working with, I set the following two goals for myself:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Enumerate and identify all available drawings. The cards clearly don‚Äôt tell the whole story here.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The classic goal at Atredis: Put a Bird on It‚Ñ¢ (i.e. figure out how these drawings are represented and stored, and use this information to add our own).&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Components&lt;/head&gt;
    &lt;p&gt;My next step was to identify the components on the board and see what I could gather/dump. The three juicy ones are labelled below.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;LKS32MC07x - ARM Cortex-M0 MCU&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;uc25IQ64 - 64MB SPI NOR flash&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;uc25IQ128A - 128MB SPI NOR flash&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I was able to dump the 64MB flash via its SPI interface, had no luck with the 128MB flash, and also had no luck connecting to the MCU via SWD. Not a great start, but i was undeterred.&lt;/p&gt;
    &lt;head rend="h2"&gt;Barcode Analysis&lt;/head&gt;
    &lt;p&gt;Using a multimeter and the printed trace lines, we can map the connections for the optical sensors that read the barcode to determine which card is inserted.&lt;/p&gt;
    &lt;p&gt;I was initially stumped by the fact that there was some overlap between the sensors and the pins. In my research, I came upon the concept of input multiplexing. Essentially, the board will power sensors 1-5 using VCC 1, then read the values on the input pins. Then it powers sensors 6-8 using VCC 2, and reuses the same input pins to read those values.&lt;/p&gt;
    &lt;p&gt;To test this theory, I decided to hook a logic analyzer up to the various inputs. To keep myself sane, I replaced the original all-red-wired connector with two sets of color-coded custom ones broken out to a breadboard with two rows of headers between them. This setup would facilitate both passive analysis and active signal manipulation simultaneously.&lt;/p&gt;
    &lt;p&gt;Sure enough, the VCC lines alternated at a regular cadence, lending massive credibility to the multiplexing theory.&lt;/p&gt;
    &lt;p&gt;With everything connected to the Saleae, I could now observe the behavior when a card was scanned. I chose the card corresponding to barcode value 00000001 to hopefully make the data more obvious to recognize. With the crab card in place, I would expect the rightmost sensor to register the HIGH value, while the others would register LOW. Well, as you can see below, the orientation of the barcode is swapped on the backside, so in reality the leftmost sensor is registering the HIGH value. I wish I could say I noticed this right away. I really wish I could say that.&lt;/p&gt;
    &lt;p&gt;Once I figured that out, the data matched up with our expectations. During the VCC1 phase, sensors 1-5 are powered and the pins are read. Sensor 1 (leftmost) is our sole HIGH (1) in this case; sensors 2 through 5 are LOW (0). Then in VCC2 phase, sensors 6-8 are powered and the pins are once more read; the corresponding values make up the final 3 bits of our barcode, for a final value of 00000001. I have the VCC triggers shown in reverse order below (i.e. VCC2 before VCC1) to make the barcode value more clear, but this process repeats several times with consistent values, so the ordering is not relevant.&lt;/p&gt;
    &lt;p&gt;In hardware analysis, these are the moments I live for. The way I outline it here, It seems so straightforward and obvious (if I did my job correctly), but for me, the path here was sprinkled with failures, confusion, wiring mistakes, and several consultations with my coworker Chad(GPT).&lt;/p&gt;
    &lt;p&gt;Anyway let‚Äôs test this out with a more complex barcode. The hot dog card has a barcode value of 01000111.&lt;/p&gt;
    &lt;head rend="h2"&gt;Barcode Emulation&lt;/head&gt;
    &lt;p&gt;Now that we understand how barcodes are translated into signals, we can emulate them using a programmable form of input. I opted to use a Raspberry Pi, as it can operate at 3.3V and seemed perfect for this use case.&lt;/p&gt;
    &lt;p&gt;First, we need to map each relevant pin on the sensor board to a GPIO pin on the pi. I'm using red to represent the VCC lines, but as you can see, they're actually mapped to GPIO pins here. Since we don't actually need to power a board, we're using these lines as input, so we can track the power cycles and know which sets of ‚Äúsensors" are being read, and which barcode bits they correspond to.&lt;/p&gt;
    &lt;p&gt;With everything wired, the next step is to script up the logic to loop through the decimal values 1 through 256, convert to binary, chunk that binary up into two groups, and write the appropriate values to the GPIO pins based on which phase of the VCC multiplexing cycle we‚Äôre in.&lt;/p&gt;
    &lt;code&gt;import gpiod
import time

chip = gpiod.Chip("gpiochip0")

#inputs:
# VCC1 (GPIO23)
# VCC2 (GPIO5)

vcc1 = chip.get_line(23)
vcc2 = chip.get_line(5)
vcc1.request(consumer="vcc1", type=gpiod.LINE_REQ_DIR_IN)
vcc2.request(consumer="vcc2", type=gpiod.LINE_REQ_DIR_IN)

#outputs: 
# D1/6 (GPIO2)
# D2/7 (GPIO3)
# D3/8 (GPIO4)
# D4 (GPIO17)
# D5 (GPIO27)

outputs = chip.get_lines([2, 3, 4, 17, 27])
outputs.request(consumer="barcode", type=gpiod.LINE_REQ_DIR_OUT)

try:
    for bcode in range(1, 256):
        #convert to 8-bit binary string, then list of bits
        bits = [int(b) for b in format(bcode, '08b')]
        print(f"{bcode} ({bits})")

        #split into two groups from the right with order reversed (i.e. LSB first)
        #e.g. 204 ([1,1,0,0,1,1,0,0]) -&amp;gt; [0,0,1,1,0] &amp;amp; [0,1,1]
        group1 = bits[-5:][::-1]
        group2 = bits[:-5][::-1]

        last_vcc1 = 0
        last_vcc2 = 0
        start = time.time()

        while time.time() - start &amp;lt; 4: #let each barcode "sit" for 4 seconds
            v1 = vcc1.get_value()
            v2 = vcc2.get_value()

            #on VCC1 rising edge -&amp;gt; emit group1
            if v1 == 1 and last_vcc1 == 0:
                out = group1
                outputs.set_values(out)
                time.sleep(0.02)
                outputs.set_values([1, 1, 1, 1, 1])

            #on VCC2 rising edge -&amp;gt; emit group2 on D1‚ÄìD3, hold D4‚Äì5 HIGH
            if v2 == 1 and last_vcc2 == 0:
                out = group2 + [1, 1]
                outputs.set_values(out)
                time.sleep(0.02)
                outputs.set_values([1, 1, 1, 1, 1])

            last_vcc1 = v1
            last_vcc2 = v2

        outputs.set_values([1, 1, 1, 1, 1])
        time.sleep(2)

except KeyboardInterrupt:
    outputs.set_values([1, 1, 1, 1, 1])
    outputs.release()
    vcc1.release()
    vcc2.release()&lt;/code&gt;
    &lt;p&gt;It took a ton of trial and error, tweaking, logic analysis, wire rechecks, and cursing to get to this point.&lt;/p&gt;
    &lt;p&gt;While looping through every possible image, I painstakingly wrote down what I heard. In some cases, I really could not decipher the audio. In those cases, I would need to have the robot actually draw the image and hope it made sense.&lt;/p&gt;
    &lt;p&gt;With this ‚Äúlookup‚Äù file, I modified the script to also print out the text along with the numeric value. Now I could pinpoint the oddballs and draw them, like the example below where I heard ‚Äúchain block.‚Äù&lt;/p&gt;
    &lt;code&gt;$ python3 all-barcodes.py
218 ([1, 1, 0, 1, 1, 0, 1, 0])
218: chain block?&lt;/code&gt;
    &lt;p&gt;Cool yes, seems plausible.&lt;/p&gt;
    &lt;p&gt;With this approach, I filled in some of the gaps and identified some of the ‚Äúhidden‚Äù images that weren‚Äôt represented by the included cards.&lt;/p&gt;
    &lt;p&gt;The full set of available images can be seen below. The stack of cards provided with the robot include images 1 through 100. Everything beyond that is a mysterious hidden bonus.&lt;/p&gt;
    &lt;p&gt;With my first goal achieved, it was time to move on to potentially getting this thing to draw arbitrary images.&lt;/p&gt;
    &lt;head rend="h2"&gt;Drawing Analysis&lt;/head&gt;
    &lt;p&gt;To be able to draw our own images, we need to understand how images are represented, where they‚Äôre stored, and whether we have the ability to overwrite these values. When I first opened this thing up, I was only able to dump the smaller of the two flash chips, so I had to hope this is where the images files lived or figure out how to dump the larger chip as well.&lt;/p&gt;
    &lt;p&gt;Going back to my initial flash dump, the hex output looked to contain a directory entry layout with some numeric filenames, which seemed promising.&lt;/p&gt;
    &lt;code&gt;$ xxd UC25IQ64.bin | head -n 20
00000000: 1972 81a6 2000 0000 80b0 5600 03ff 0000  .r.. .....V.....
00000010: 7465 7374 5f64 6972 00ff ffff ffff ffff  test_dir........
00000020: 42ae 43d2 2045 0000 ac0f 0000 02ff 0000  B.C. E..........
00000030: 3030 312e 6631 6100 ffff ffff ffff ffff  001.f1a.........
00000040: 95b3 4acc d054 0000 9f11 0000 02ff 0000  ..J..T..........
00000050: 3030 322e 6631 6100 ffff ffff ffff ffff  002.f1a.........
00000060: 0961 63ca 7066 0000 0411 0000 02ff 0000  .ac.pf..........
00000070: 3030 332e 6631 6100 ffff ffff ffff ffff  003.f1a.........
00000080: 92c9 7fd6 8077 0000 0d10 0000 02ff 0000  .....w..........
00000090: 3030 342e 6631 6100 ffff ffff ffff ffff  004.f1a.........
000000a0: c241 8271 9087 0000 ca0f 0000 02ff 0000  .A.q............
000000b0: 3030 352e 6631 6100 ffff ffff ffff ffff  005.f1a.........
‚Ä¶&lt;/code&gt;
    &lt;p&gt;A typical directory entry layout looks a bit like the following:&lt;/p&gt;
    &lt;code&gt;Directory entry layout (32 bytes total)

  0x00            0x04          0x08          0x0C          0x10                      0x20
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ CRC / checksum‚îÇ START offset ‚îÇ   SIZE      ‚îÇ   FLAGS     ‚îÇ   NAME (ASCII, 16 bytes) ‚îÇ
   ‚îÇ   (uint32 LE) ‚îÇ  (uint32 LE) ‚îÇ (uint32 LE) ‚îÇ (uint32 LE) ‚îÇ   null-terminated        ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò&lt;/code&gt;
    &lt;p&gt;For example, the directory entry for &lt;code&gt;001.fla&lt;/code&gt; has the following content breakdown:&lt;/p&gt;
    &lt;code&gt;[FILE]  Entry @ 0x000020  (32 bytes)  name='001.f1a'
    +--------+-------------------------------------------------+  +------------------+
    | Offset |                         HEX                     |  |     ASCII        |
    +--------+-------------------------------------------------+  +------------------+
    | 0x00   | 42 AE 43 D2 20 45 00 00 AC 0F 00 00 02 FF 00 00 |  | B.C. E.......... |
    | 0x10   | 30 30 31 2E 66 31 61 00 FF FF FF FF FF FF FF FF |  | 001.f1a......... |
    +--------+-------------------------------------------------+  +------------------+
    Field map:
      [0x00..0x03]  CRC / checksum (LE)       = 0xD243AE42
      [0x04..0x07]  START offset  (LE)        = 0x004520
      [0x08..0x0B]  SIZE bytes    (LE)        = 0xFAC
      [0x0C..0x0F]  FLAGS / unk   (LE)        = 0x0000FF02
      [0x10..0x1F]  NAME (ASCII, null-term)   = '001.f1a'
      Content slice: data[0x004520 : 0x0054CC]  (len=0xFAC)&lt;/code&gt;
    &lt;p&gt;Knowing this, we can semi-shamefully vibe code a High Level Analyzer (HLA) in Logic to identify all SPI &lt;code&gt;flash_read&lt;/code&gt; operations, take the associated read address from the &lt;code&gt;fast_read&lt;/code&gt;, perform a lookup against our directory entry layout, and print the associated filename to show what is being read at that moment.&lt;/p&gt;
    &lt;p&gt;With the HLA in place, I had the bot read and draw image number 105. Sure enough, it read the file &lt;code&gt;Y105.f1a&lt;/code&gt;. However, it read several other files during the course of drawing, including &lt;code&gt;TE05luo2.f1a&lt;/code&gt;, &lt;code&gt;TXXm5.f1b&lt;/code&gt;, and &lt;code&gt;TE08stop.f1a&lt;/code&gt;. When I scanned other cards, the associated &lt;code&gt;YXXX.f1a&lt;/code&gt; file was read, even if I never drew the image. The pattern of these other reads seemed to line up with whenever the robot would talk or sing. This led me to believe that I was actually looking at the audio files, not the drawings.&lt;/p&gt;
    &lt;p&gt;It was time to go after that second SPI flash chip again. Fortunately I learned from my trusted colleague Chris Bellows that, when in doubt, go for the chip-off extraction. This was successful and a good time was had by all.&lt;/p&gt;
    &lt;code&gt;$ sudo flashrom -p buspirate_spi:dev=/dev/ttyUSB0,spispeed=1M -r UC25IQ128_3.bin
flashrom unknown on Linux 6.8.0-60-generic (aarch64)
flashrom is free software, get the source code at https://flashrom.org

Using clock_gettime for delay loops (clk_id: 1, resolution: 1ns).
===
SFDP has autodetected a flash chip which is not natively supported by flashrom yet.
[...]
Found Unknown flash chip "SFDP-capable chip" (2048 kB, SPI) on buspirate_spi.
===
This flash part has status UNTESTED for operations: WP
[...]
Reading flash... done.&lt;/code&gt;
    &lt;p&gt;Side note - with this SPI flash chip removed from the board, the drawbot still functioned. It would power on, read and announce cards, and play music. The one thing it did NOT do was actually move its arms and draw the images, which seemed like pretty intense proof that this chip contained the drawing files and the smaller flash chip contained the audio.&lt;/p&gt;
    &lt;p&gt;The contents of the extracted image looked very structured, which boded well for being some sort of coordinate-based data that one would expect for a drawing.&lt;/p&gt;
    &lt;quote&gt;$ xxd UC25IQ128_3.bin 00000000: ffff ffff 0253 018b 0252 018c 0251 018c .....S...R...Q.. 00000010: 0250 018c 024f 018c 024e 018c 024d 018c .P...O...N...M.. 00000020: 024c 018c 024b 018c 024a 018c 0249 018c .L...K...J...I.. 00000030: 0248 018c 0247 018c 0246 018c 0245 018c .H...G...F...E.. 00000040: 0244 018c 0243 018c 0242 018c 0241 018c .D...C...B...A.. 00000050: 0240 018d 023f 018d 023e 018d 023d 018d .@...?...&amp;gt;...=.. 00000060: 023c 018d 023b 018d 023a 018d 0239 018d .&amp;lt;...;...:...9.. 00000070: 0238 018d 0237 018e 0236 018e 0235 018e .8...7...6...5.. 00000080: 0234 018e 0233 018e 0232 018e 0231 018e .4...3...2...1.. 00000090: 0230 018e 022f 018f 022e 018f 022d 018f .0.../.......-.. 000000a0: 022c 018f 022b 018f 022a 018f 0229 018f .,...+...*...).. 000000b0: 0228 0190 0227 0190 0226 0190 0225 0190 .(...'...&amp;amp;...%.. 000000c0: 0224 0190 0223 0190 0222 0191 0221 0191 .$...#..."...!.. 000000d0: 0220 0191 021f 0191 021e 0191 021d 0192 . .............. 000000e0: 021c 0192 021b 0192 021a 0192 0219 0192 ................ [...]&lt;/quote&gt;
    &lt;p&gt;Because it's the year 2025 and LLMs are coming for our jobs anyway, I thought I would give ChatGPT a chance to make short work of my analysis. I fed it the dump, said I suspected that it contained image instruction files, and sent it on its way.&lt;/p&gt;
    &lt;p&gt;Putting aside the excessive flattery and overall semi-off-putting vibe of my ChatGPT, we‚Äôve got it!&lt;/p&gt;
    &lt;p&gt;Only problem is, there appear to be only 35 images within the file. The first 35 images to be exact. Since this is an atypical chip, it's possible that flashrom is making incorrect assumptions. We know from the spec that we should have 16MB of data, so we can force it to read 16MB by specifying a target chip similar enough to ours. I've done several extractions of Winbond flash, so that‚Äôs what I went with, and the new dump contained 254 images.&lt;/p&gt;
    &lt;p&gt;Since we now know the structure, we can script up a parser/generator in Python that will carve out the data for each image, process the coordinates, and feed them into SVG path elements to create an image file. An excerpt of this script can be seen here:&lt;/p&gt;
    &lt;code&gt;def write_svg(strokes, out: Path, flip_y=True, stroke_w=2):
    bb = bbox(strokes)
    if not bb:
        return False
    xmin, ymin, xmax, ymax = bb
    w, h = xmax - xmin + 1, ymax - ymin + 1
    with out.open("w", encoding="utf-8") as f:
        if flip_y:
            f.write(f'&amp;lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="{xmin} {ymin} {w} {h}" '
                    f'width="{w}" height="{h}" stroke="black" fill="none" stroke-width="{stroke_w}"&amp;gt;\n')
            f.write(f'  &amp;lt;g transform="translate(0,{ymin + ymax}) scale(1,-1)"&amp;gt;\n')
            for s in strokes:
                f.write('    &amp;lt;path d="M{},{} {}"/&amp;gt;\n'.format(
                    s[0][0], s[0][1], " ".join(f"L{x},{y}" for x, y in s[1:])))
            f.write('  &amp;lt;/g&amp;gt;\n&amp;lt;/svg&amp;gt;\n')
        else:
            f.write(f'&amp;lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="{xmin} {ymin} {w} {h}" '
                    f'width="{w}" height="{h}" stroke="black" fill="none" stroke-width="{stroke_w}"&amp;gt;\n')
            for s in strokes:
                f.write('  &amp;lt;path d="M{},{} {}"/&amp;gt;\n'.format(
                    s[0][0], s[0][1], " ".join(f"L{x},{y}" for x, y in s[1:])))
            f.write('&amp;lt;/svg&amp;gt;\n')
    return True

def main():
    ap = argparse.ArgumentParser(description="Extract SVGs from fixed slots")
    ap.add_argument("bin", type=Path, help="full flash dump (e.g., full.bin)")
    ap.add_argument("--out", type=Path, default=Path("svgs"), help="output directory")
    ap.add_argument("--base", type=lambda x:int(x,0), default=0x04, help="first slot start offset (default 0x04)")
    ap.add_argument("--slot", type=lambda x:int(x,0), default=0xEA60, help="slot size (default 0xEA60)")
    ap.add_argument("--count", type=int, default=None, help="number of slots (default: autodetect from file size)")
    ap.add_argument("--min-pts", type=int, default=2, help="min points to export (default 2)")
    ap.add_argument("--no-flip-y", action="store_true", help="do not flip Y axis")
    args = ap.parse_args()

    data = args.bin.read_bytes()
    size = len(data)

    if args.count is None:
        # Best-effort autodetect
        usable = max(0, size - args.base)
        args.count = usable // args.slot

    args.out.mkdir(parents=True, exist_ok=True)
    exported = 0

    for i in range(args.count):
        off = args.base + i * args.slot
        if off &amp;gt;= size:
            break
        slot = data[off : min(off + args.slot, size)]
        words = u16be_words(slot)
        strokes = strokes_from_slot(words)
        if sum(len(s) for s in strokes) &amp;lt; args.min_pts:
            continue
        svg_path = args.out / f"drawing_{i:03d}.svg"
        if write_svg(strokes, svg_path, flip_y=not args.no_flip_y, stroke_w=2):
            exported += 1
            # uncomment for debug:
            # print(f"{i:03d} @ 0x{off:08X} -&amp;gt; {svg_path.name}")
    print(f"Exported {exported} SVGs to {args.out} from {args.count} slots "
          f"(base=0x{args.base:X}, slot=0x{args.slot:X}).")&lt;/code&gt;
    &lt;p&gt;Because this was written by an LLM, it is a bit.. extra. It could likely be simplified, but in its current state, it lets you specify the slot offset where you‚Äôd like to start extracting images, the number of sequential images to extract, the minimum number of points it must detect before it considers an entry a valid image, and the ability to flip the image when rendering (since it draws from the top, it actually stores the images upside-down).&lt;/p&gt;
    &lt;quote&gt;&amp;gt; python3 img_carver.py ../dumps/UC25IQ128_forced.bin --no-flip-y --out svgs Exported 254 SVGs to svgs from 279 slots (base=0x4, slot=0xEA60).&lt;/quote&gt;
    &lt;p&gt;Well this would have been a more straightforward way to view all possible images without enumerating and spoofing them, but hey, there are many ways to skin a cat and I‚Äôd like to learn them all. There are a lot of cats in this world that need skinning.&lt;/p&gt;
    &lt;p&gt;Now that we can go from raw data -&amp;gt; SVG, we want to go in the other direction to get this thing to draw an image of our choosing. There are a lot of tools out there to convert a PNG to an SVG, and below you can see why the latter is much more suited to our needs. SVGs are scalable because they contain path data that can be easily transformed with the power of maths.&lt;/p&gt;
    &lt;p&gt;With our target image, we just need to parse through the path data and transform it into the data format that drawbot expects. Since the flash memory is just one big blob and we‚Äôre hoping to only overwrite one image (i.e. the other drawings will still work), we need to make sure our padding is correct and that we follow the expected format, including any necessary delimiters. As we could see from the crab drawing ChatGPT spit out, it didn‚Äôt quite seem to process the ‚Äúpen up‚Äù actions properly, so every movement drew a line. Luckily for me, my drawing is a single continuous line, so I don‚Äôt have to worry about that quite yet.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs an excerpt of my final script. It takes an existing slot, determines the bounding box, fits the new SVG into the coordinate plane‚Äôs bounding box, then creates a new slot that‚Äôs the same size as the one to be replaced.&lt;/p&gt;
    &lt;code&gt;def main():
    ap = argparse.ArgumentParser(description="Fit an SVG to a slot's bbox and pack to device format")
    ap.add_argument("slot_content", type=Path, help="existing slot content (0xEA5C bytes; starts at first X)")
    ap.add_argument("svg", type=Path, help="SVG to insert")
    ap.add_argument("--out", type=Path, default=Path("slot_new_content.bin"), help="output content-only bin (0xEA5C)")
    ap.add_argument("--out-with-marker", type=Path, help="also write a 0xEA60 file with trailing FFFF FFFF")
    ap.add_argument("--step", type=float, default=4.0, help="sampling step in SVG units (bigger = fewer points)")
    ap.add_argument("--margin", type=float, default=0.0, help="margin in device units inside target bbox (default 0)")
    ap.add_argument("--flip-y", action="store_true", help="flip Y if your preview is upside-down")
    args = ap.parse_args()

    slot_bytes = args.slot_content.read_bytes()
    if len(slot_bytes) != CONTENT_LEN and len(slot_bytes) != SLOT_LEN:
        print(f"[warn] slot_content length is {len(slot_bytes)}; expected 0xEA5C or 0xEA60. Continuing...")

    # Derive target bbox from existing slot content (robust to trailing marker)
    bb = parse_bbox_from_slot_content(slot_bytes[:CONTENT_LEN])
    print(f"[info] target bbox (from slot): x[{bb[0]}..{bb[2]}], y[{bb[1]}..{bb[3]}]")

    # Load &amp;amp; sample SVG
    paths, _, svg_attr = svg2paths2(str(args.svg))
    vb = get_svg_viewbox(paths, svg_attr)
    # Build strokes list (each continuous subpath = one stroke)
    strokes: List[List[Point]] = []
    for p in paths:
        for sub in p.continuous_subpaths():
            strokes.append(sample_path(sub, args.step))

    qstrokes = quantize_to_bbox(strokes, vb, bb, margin=args.margin, flip_y=args.flip_y)
    payload = pack_content(qstrokes, CONTENT_LEN)
    args.out.write_bytes(payload)
    print(f"[done] wrote {args.out} ({len(payload)} bytes).‚Äù)
[‚Ä¶]&lt;/code&gt;
    &lt;quote&gt;$ python3 svg_fit_to_slot.py slot_006_content.bin ../images/whisky-outline.svg --out slot_006_new_content_03.bin --step 6.0 --margin 4 [info] target bbox (from slot): x[56..1124], y[176..1005] [done] wrote slot_006_new_content.bin (59996 bytes).&lt;/quote&gt;
    &lt;quote&gt;$ xxd slot_006_new_content_03.bin 00000000: 024c 02ce 024a 02cd 0248 02cb 0246 02c9 .L...J...H...F.. 00000010: 0244 02c8 0243 02c6 0241 02c3 0240 02c1 .D...C...A...@.. 00000020: 023f 02bf 023e 02be 023c 02bf 0239 02c0 .?...&amp;gt;...&amp;lt;...9.. 00000030: 0237 02c1 0234 02c2 0232 02c3 022f 02c3 .7...4...2.../.. 00000040: 022d 02c3 022a 02c1 0228 02c0 0227 02be .-...*...(...'.. 00000050: 0226 02bc 0225 02b9 0224 02b7 0223 02b4 .&amp;amp;...%...$...#.. 00000060: 0223 02b2 0223 02af 0223 02ac 0222 02ab .#...#...#...".. 00000070: 0221 02ac 0220 02ae 021e 02b1 021c 02b3 .!... .......... 00000080: 021a 02b5 0218 02b6 0216 02b8 0214 02b9 ................ 00000090: 0211 02b9 020f 02b9 020c 02b7 020a 02b6 ................ [‚Ä¶]&lt;/quote&gt;
    &lt;p&gt;Now that we‚Äôve overwritten a single slot, we need to write it back into the original image.&lt;/p&gt;
    &lt;quote&gt;$ dd if=slot_006_new_content_03.bin of=UC25IQ128_trunc_mod.bin bs=1 seek=$((0x000493E4)) conv=notrunc 59996+0 records in 59996+0 records out 59996 bytes transferred in 0.120694 secs (497092 bytes/sec)&lt;/quote&gt;
    &lt;p&gt;I should have confirmed that we could write to the flash chip before even going down this path. Fortunately, we could.&lt;/p&gt;
    &lt;quote&gt;$ sudo flashrom -p buspirate_spi:dev=/dev/ttyUSB0,spispeed=250k -f -w UC25IQ128_trunc_mod.bin -VV flashrom unknown on Linux 6.8.0-60-generic (aarch64) flashrom is free software, get the source code at https://flashrom.org Using clock_gettime for delay loops (clk_id: 1, resolution: 1ns). flashrom was built with GCC 13.2.0, little endian [‚Ä¶] Found Unknown flash chip "SFDP-capable chip" (2048 kB, SPI). === This flash part has status UNTESTED for operations: WP ‚Ä¶ Block protection is disabled. Reading old flash chip contents... done. Erasing and writing flash chip... Trying erase function 0‚Ä¶ Erase/write done. Verifying flash... VERIFIED. Raw bitbang mode version 1 Bus Pirate shutdown completed.&lt;/quote&gt;
    &lt;p&gt;It was at this point that I remembered that the chip wasn‚Äôt actually installed into the drawbot anymore. Since nothing ever works on the first try, this was very likely a problem. I already had it installed on this nice breakout board with headers, so I soldered wires to the board itself, globbed on hot glue to try and keep them from ripping off of the board, and hooked them up to connectors on the other side. This way, I could switch back and forth between my programmer and the drawbot until it was just right.&lt;/p&gt;
    &lt;p&gt;It took a few iterations where I had to work out some minor kinks, but it actually worked. I couldn‚Äôt have some gnarled headless robot in my final demo, so I modified the case to accommodate its flash chip hanging out and patched it back up as best I could.&lt;/p&gt;
    &lt;p&gt;If you‚Äôd like to watch the whole video, you‚Äôll get to hear one of the many drawbot songs that have been stuck in my head during the course of this project.&lt;/p&gt;
    &lt;p&gt;A potential area of future work would be streamlining this process to facilitate passing an image to a script that would handle conversion, writing to flash, and triggering the drawing (more GPIO manipulation with the pi) all at once. It would also be fun to figure out the audio format to replace the various songs and sounds (I did spend a little time attempting to decode and play them using ffmpeg). I also considered overhauling the drawbot entirely, designing and 3d-printing a new body.&lt;/p&gt;
    &lt;p&gt;It‚Äôs entirely possible that I‚Äôll come back and try one or all of these things in the future. If I do and anything comes of it, I‚Äôll be sure to let you know.&lt;/p&gt;
    &lt;p&gt;What‚Äôs more likely is that I‚Äôll find a new target to respectfully butcher and reanimate. Will keep you posted either way.&lt;/p&gt;
    &lt;p&gt;Happy hacking!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.atredis.com/blog/2025/9/30/drawbot-lets-hack-something-cute"/><published>2026-01-16T22:13:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=46653049</id><title>Fix the two-party system with proportional representation</title><updated>2026-01-16T23:39:14.484659+00:00</updated><content>&lt;doc fingerprint="2ad1ce310ef53728"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Fix the two-party system with proportional representation.&lt;/head&gt;
    &lt;p&gt;The Peoples Act is an in-progress set of legislative changes. Start your candidacy or volunteer your time to help research and define these policies.&lt;/p&gt;
    &lt;p&gt;We are locked in a voting system that ends in two-party control. Minnesotans deserve better, and there√¢s an easy fix.&lt;/p&gt;
    &lt;p&gt;We call on Minnesota to implement proportional representation. It√¢s simple: instead of voting for one person to represent you, you√¢ll vote for one party to represent you, and we√¢ll distribute seats proportionally. The key question is how big are your districts, and how many representatives do you elect for each district.&lt;/p&gt;
    &lt;p&gt;Here√¢s an example of voting results in one district along with the number of candidates that get elected for each party based on the total number of representatives elected in that district:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="18"&gt;
        &lt;cell role="head"&gt;Party&lt;/cell&gt;
        &lt;cell role="head"&gt;Votes&lt;/cell&gt;
        &lt;cell role="head"&gt;1&lt;/cell&gt;
        &lt;cell role="head"&gt;2&lt;/cell&gt;
        &lt;cell role="head"&gt;3&lt;/cell&gt;
        &lt;cell role="head"&gt;4&lt;/cell&gt;
        &lt;cell role="head"&gt;5&lt;/cell&gt;
        &lt;cell role="head"&gt;6&lt;/cell&gt;
        &lt;cell role="head"&gt;7&lt;/cell&gt;
        &lt;cell role="head"&gt;8&lt;/cell&gt;
        &lt;cell role="head"&gt;9&lt;/cell&gt;
        &lt;cell role="head"&gt;10&lt;/cell&gt;
        &lt;cell role="head"&gt;11&lt;/cell&gt;
        &lt;cell role="head"&gt;12&lt;/cell&gt;
        &lt;cell role="head"&gt;13&lt;/cell&gt;
        &lt;cell role="head"&gt;14&lt;/cell&gt;
        &lt;cell role="head"&gt;15&lt;/cell&gt;
        &lt;cell role="head"&gt;16&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="18"&gt;
        &lt;cell&gt;Republicans&lt;/cell&gt;
        &lt;cell&gt;380&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="18"&gt;
        &lt;cell&gt;Democrats&lt;/cell&gt;
        &lt;cell&gt;260&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="18"&gt;
        &lt;cell&gt;Agrarians&lt;/cell&gt;
        &lt;cell&gt;220&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="18"&gt;
        &lt;cell&gt;Independents&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="18"&gt;
        &lt;cell&gt;Green&lt;/cell&gt;
        &lt;cell&gt;50&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Socialists&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The most obvious pattern is that minority parties do not receive any representation until there at least of few representatives per district.&lt;/p&gt;
    &lt;p&gt;In Minnesota, we always follow the first column of one representative per district and democracy suffers.&lt;/p&gt;
    &lt;p&gt;Depending on your perspective, fairness may not emerge until 8-16 representatives per district. At only 1% of the vote, the Socialists will not see representation unless a district contains 50 or more elected representatives. Let√¢s look what happens when we follow this to the extreme:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="12"&gt;
        &lt;cell role="head"&gt;Party&lt;/cell&gt;
        &lt;cell role="head"&gt;Votes&lt;/cell&gt;
        &lt;cell role="head"&gt;17&lt;/cell&gt;
        &lt;cell role="head"&gt;18&lt;/cell&gt;
        &lt;cell role="head"&gt;19&lt;/cell&gt;
        &lt;cell role="head"&gt;20&lt;/cell&gt;
        &lt;cell role="head"&gt;25&lt;/cell&gt;
        &lt;cell role="head"&gt;50&lt;/cell&gt;
        &lt;cell role="head"&gt;100&lt;/cell&gt;
        &lt;cell role="head"&gt;200&lt;/cell&gt;
        &lt;cell role="head"&gt;500&lt;/cell&gt;
        &lt;cell role="head"&gt;1000&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;Republicans&lt;/cell&gt;
        &lt;cell&gt;380&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;9&lt;/cell&gt;
        &lt;cell&gt;19&lt;/cell&gt;
        &lt;cell&gt;38&lt;/cell&gt;
        &lt;cell&gt;76&lt;/cell&gt;
        &lt;cell&gt;190&lt;/cell&gt;
        &lt;cell&gt;380&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;Democrats&lt;/cell&gt;
        &lt;cell&gt;260&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;7&lt;/cell&gt;
        &lt;cell&gt;13&lt;/cell&gt;
        &lt;cell&gt;26&lt;/cell&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;130&lt;/cell&gt;
        &lt;cell&gt;260&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;Agrarians&lt;/cell&gt;
        &lt;cell&gt;220&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;6&lt;/cell&gt;
        &lt;cell&gt;11&lt;/cell&gt;
        &lt;cell&gt;22&lt;/cell&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;110&lt;/cell&gt;
        &lt;cell&gt;220&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;Independents&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;80&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="12"&gt;
        &lt;cell&gt;Green&lt;/cell&gt;
        &lt;cell&gt;50&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;25&lt;/cell&gt;
        &lt;cell&gt;50&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Socialists&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;5&lt;/cell&gt;
        &lt;cell&gt;10&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;The ratios do not drastically change until 5% of the voters are now also representatives and the Socialists receive a single represenative. At this point they are over-represented with 1% of the vote and 2% of the representatives. Yet they still do not have enough power to form or change coalitions.&lt;/p&gt;
    &lt;p&gt;By 100 representatives per district, these voting results happen to achieve perfect fairness (because all vote totals are divisible by ten), but that would not typically occur until every single voter is also a represenative and we have achieved perfect direct democracy.&lt;/p&gt;
    &lt;p&gt;Our party is a strong advocate for representative democracy, and we believe that 8-16 representatives per district is the ideal number. Smaller than that, and relevant minority parties are excluded; larger than that, and the increased representation is too small to justify the costs and logistical challenges of that many representatives.&lt;/p&gt;
    &lt;p&gt;We can simply achieve this in Minnesota by replacing our state legislative districts with our existing congressional districts. Instead of electing one Senator from each legislative district and one Representative from each legislative sub-district, we√¢ll elect eight Senators and 16 Representatives from each congressional district.&lt;/p&gt;
    &lt;p&gt;This will reduce the number of Senators from 67 to 64, and reduce the number of Representatives from 134 to 128. Yet fairness, represenative and democracy will increase.&lt;/p&gt;
    &lt;p&gt;Vote Agrarian to respect the People, support Democracy and implement proportional representation in Minnesota!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://agrarianparty.org/platform/peoples-act"/><published>2026-01-16T22:26:41+00:00</published></entry></feed>