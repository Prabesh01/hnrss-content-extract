<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-11-05T22:39:10.412061+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45812756</id><title>An eBPF Loophole: Using XDP for Egress Traffic</title><updated>2025-11-05T22:40:14.135748+00:00</updated><content>&lt;doc fingerprint="27b14038c8213ec6"&gt;
  &lt;main&gt;
    &lt;p&gt;On this page:&lt;/p&gt;
    &lt;head rend="h4"&gt;TL;DR:&lt;/head&gt;
    &lt;p&gt;XDP (eXpress Data Path) is the fastest packet processing framework in linux - but it only works for incoming (ingress) traffic. We discovered how to use it for outgoing (egress) traffic by exploiting a loophole in how the linux kernel determines packet direction. Our technique delivers 10x better performance than current solutions, works with existing Docker/Kubernetes containers, and requires zero kernel modifications.&lt;/p&gt;
    &lt;p&gt;This post not only expands on the overall implementation but also outlines how existing container and VM workloads can immediately take advantage with minimal effort and zero infrastructure changes.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Line-Rate Problem&lt;/head&gt;
    &lt;p&gt;At Loophole Labs, we live migrate everything - containers, VMs, and even network connections.&lt;/p&gt;
    &lt;p&gt;During a migration every single packet for a workload needs to be intercepted, modified, encapsulated, encrypted, and rerouted to its new destination - all without the application noticing. Our scale requires us to be able to move workloads across clouds at hundreds of gigabits per second - and with that sort of performance requirement, every single CPU cycle matters.&lt;/p&gt;
    &lt;p&gt;All of this is to say, we need to be able to process packets at line-rate (however much the underlying network can support, whether that's 20Gbps or 200Gbps), and there's really only one approach that lets us do that:&lt;/p&gt;
    &lt;p&gt;Linux Packet Processing Performance Comparison&lt;/p&gt;
    &lt;p&gt;In Linux, the gold standard for high-performance packet processing is XDP (eXpress Data Path). By intercepting packets as soon as they arrive at the network driver (before reaching the kernel) XDP is able to achieve line-rate speeds in most environments.&lt;/p&gt;
    &lt;p&gt;Our own benchmarks above show how easily we were able to reach line-rate with XDP, not to mention the fact that major companies like Meta, Cloudflare, and GCore have already been using it for more than 5 years now to handle 10s of millions of packets per second.&lt;/p&gt;
    &lt;head rend="h2"&gt;XDP's Main Limitation&lt;/head&gt;
    &lt;p&gt;Unfortunately XDP has one fundamental flaw that everyone accepts as fact: it only works for ingress (incoming) traffic. This isn't a bug or an oversight - it's the entire identity of XDP, one of the main characteristics that define it. XDP only processes packets on ingress. Period.&lt;/p&gt;
    &lt;p&gt;For routers and load balancers, this limitation is perfectly fine: every packet they handle arrives from an external interface, making it all ingress from the kernel's perspective.&lt;/p&gt;
    &lt;p&gt;Our network plane, on the other hand, has to run on the same compute nodes as the workloads that we're live migrating. And when these workloads generate packets - initiating connections, sending responses, etc. - that's considered egress traffic by the host kernel. XDP simply does not work in this scenario.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why Traffic Control Isn't Good Enough&lt;/head&gt;
    &lt;p&gt;A popular method for handling egress packets is Traffic Control (TC), another eBPF-based mechanism that allows for packet processing at both ingress and egress. TC is already commonly used for traffic shaping, queuing, filtering, and policing outbound traffic. In fact, it's the de facto standard in the Kubernetes ecosystem - CNIs like Cilium and Calico all rely on TC for egress control because, until now, XDP for egress simply wasn't possible.&lt;/p&gt;
    &lt;p&gt;Given all of this, TC might seem like an obvious choice for our use case as well, but it has a fundamental flaw of its own:&lt;/p&gt;
    &lt;p&gt;Performance.&lt;/p&gt;
    &lt;p&gt;We haven't been able to process more than 21Gbps with TC on egress (or more than 23Gbps on ingress),which makes it a non-starter for our needs. The reason why TC suffers from this performance bottleneck is due to how (and more importantly when) the linux kernel runs the TC program:&lt;/p&gt;
    &lt;p&gt;TC Program Flow Diagram&lt;/p&gt;
    &lt;p&gt;As shown in the diagram above, TC programs operate quite late in the networking stack, after packets have already spent some time travelling through the linux kernel. By the time a packet reaches the TC hook, the kernel has already processed it through various subsystems for routing, firewalling, and even connection tracking. This means that we've wasted quite a few CPU cycles before our TC program even runs.&lt;/p&gt;
    &lt;p&gt;Another major limitation of TC is that it works on socket buffers (called &lt;code&gt;struct sk_buff&lt;/code&gt; in the
linux kernel) which are allocated per-packet. This structure -
while necessary for linux's own packet handling - comes with a significant performance hit due to the allocations
themselves as well as the additional memory copies required to populate it. This all becomes doubly problematic when
you're trying to process millions of packets every second.&lt;/p&gt;
    &lt;p&gt;XDP, on the other hand, not only operates directly on the raw packet memory (because it runs directly in the network drivers before the packet even reaches the linux kernel) but does so at the earliest point in the packet's lifecycle, meaning almost no CPU cycles have been spent by the time our XDP program starts running. All this results in zero-copy packet processing, meaning packets can be inspected, modified, and redirected with the absolute minimum overhead possible.&lt;/p&gt;
    &lt;p&gt;For us XDP is a hard requirement, and while the industry seems to have accepted that this is impossible, we haven't.&lt;/p&gt;
    &lt;head rend="h2"&gt;When Does an XDP Program Run?&lt;/head&gt;
    &lt;p&gt;One of our core beliefs at Loophole Labs is that every so-called "limitation" imposed by modern infrastructure is really just a problem we haven't solved yet. In the spirit of this, we decided to go digging through the linux kernel source in an attempt to understand exactly why and how the kernel decides to classify a packet as "ingress" in the first place.&lt;/p&gt;
    &lt;p&gt;As it turns out, linux doesn't actually classify the packet at all. When a packet arrives at a physical network interface, the network card writes the contents into an RX ring buffer - a memory region allocated by the device driver that the network card can write to directly via DMA (Direct Memory Access).&lt;/p&gt;
    &lt;p&gt;Next, the network card uses an interrupt to signal the device driver that there's a packet available for processing. The device driver then copies the packet from the ring buffer into its RX queue. And this is exactly when the XDP program runs: directly on the packet in the RX queue. This process is illustrated in the diagram below:&lt;/p&gt;
    &lt;p&gt;XDP Program Flow Diagram&lt;/p&gt;
    &lt;p&gt;If this entire process makes one thing clear, it's that there is very little work being done in between the packet arriving at the physical interface and it being ready for the XDP program to run. The RX queue is the trigger that tells the linux kernel how to "classify" the packet as ingress and whether it should run the XDP hook.&lt;/p&gt;
    &lt;p&gt;As we saw in this diagram, the RX queue is not used at all for egress packets, and this simple limitation is the cause of all our headaches.&lt;/p&gt;
    &lt;p&gt;Now that we know all this, how can we get around it? As it turns out, we don't have to.&lt;/p&gt;
    &lt;head rend="h2"&gt;Making Egress Look Like Ingress&lt;/head&gt;
    &lt;p&gt;We were reading through the various linux interface docs, hoping to find some little insight into our predicament, when an interesting virtual interface caught our eye: Virtual Ethernet.&lt;/p&gt;
    &lt;p&gt;A Virtual Ethernet (&lt;code&gt;veth&lt;/code&gt;) interface is a pair of network interfaces that act as a direct tunnel between each
other. When a packet is transmitted from the TX queue of one side of the &lt;code&gt;veth&lt;/code&gt; pair, a pointer to the packet's memory is
simply moved to the RX queue of the other interface. This makes the packet appear as if it were received by a physical
network interface with very low overhead.&lt;/p&gt;
    &lt;p&gt;Yep, you read that right - &lt;code&gt;veth&lt;/code&gt; interfaces have an RX queue that's used when receiving a packet from the other side.&lt;/p&gt;
    &lt;p&gt;To illustrate this better, let's take an example setup like the one below. We have two applications running in their own network namespaces, with two &lt;code&gt;veth&lt;/code&gt; pairs (&lt;code&gt;veth0-A&lt;/code&gt; and &lt;code&gt;veth0-B&lt;/code&gt;) being used to route traffic out of the namespaces.&lt;/p&gt;
    &lt;p&gt;XDP for Egress Traffic Flow Diagram&lt;/p&gt;
    &lt;p&gt;The key insight here is that if we send outgoing traffic through one end of the &lt;code&gt;veth&lt;/code&gt; pairs (&lt;code&gt;veth0-A&lt;/code&gt; in the diagram
above), then from the perspective of the second interface (&lt;code&gt;veth1-A&lt;/code&gt;), the packet arrives at the
RX queue of an interface, and is now considered ingress traffic. And, since XDP programs can be attached to any
interface’s RX queue, our XDP hook will automatically run on that egress packet.&lt;/p&gt;
    &lt;p&gt;Furthermore, if we run our XDP programs in native mode like in the diagram above, packets can be processed with zero-copy and will bypass the linux kernel entirely when we use &lt;code&gt;XDP_REDIRECT&lt;/code&gt; to route directly to the TX queue of the
&lt;code&gt;eth0&lt;/code&gt; interface.&lt;/p&gt;
    &lt;p&gt;What makes this discovery even more powerful is that modern container runtimes - Docker, Kubernetes, containerd - already use &lt;code&gt;veth&lt;/code&gt; pairs and network namespaces for container networking. Every container you're running right now is
already connected through &lt;code&gt;veth&lt;/code&gt; interfaces, and it looks exactly like the diagram above.&lt;/p&gt;
    &lt;p&gt;That's right - not only can we use XDP for egress traffic in any of these environments, but we can do it without having to change them in any way.&lt;/p&gt;
    &lt;head rend="h2"&gt;If You Skip the Kernel, You Have to be the Kernel&lt;/head&gt;
    &lt;p&gt;Unfortunately, while implementing this technique seemed straightforward at first, we quickly hit a snag while benchmarking. Our packets kept getting dropped after our XDP program ran, and at first we couldn't figure out why.&lt;/p&gt;
    &lt;p&gt;We decided to run &lt;code&gt;tcpdump&lt;/code&gt; on the receiving host and realized the packets weren't even making it over the network.
Next, we decided to run &lt;code&gt;tcpdump&lt;/code&gt; on the switch handling the packets, and that's when we realized what we'd
missed.&lt;/p&gt;
    &lt;p&gt;As it turns out, when you bypass the kernel's networking stack, you inherit its responsibilities.&lt;/p&gt;
    &lt;p&gt;Normally, when a packet is sent out via the linux kernel, it handles the routing, checksumming, and ARP resolution for us. But we of course have bypassed the kernel's networking stack entirely, meaning now we have to take full responsibility for ensuring packets are properly formed and can actually reach their next hop.&lt;/p&gt;
    &lt;p&gt;Our network plane already handles proper routing for us, but we'd missed both checksumming and ARP resolution.&lt;/p&gt;
    &lt;head rend="h3"&gt;Checksum Calculations in XDP&lt;/head&gt;
    &lt;p&gt;XDP programs unfortunately are not provided with the same checksum helpers that TC programs get. For NAT (Network Address Translation) or any other packet header modifications, you need to recalculate checksums manually - and when performance matters, the trick is to use incremental checksum updates rather than full recalculations:&lt;/p&gt;
    &lt;head rend="h3"&gt;ARP Resolution&lt;/head&gt;
    &lt;p&gt;The linux kernel normally handles ARP to resolve IP addresses to MAC addresses and automatically sets the destination MAC address in the &lt;code&gt;ethernet&lt;/code&gt; layer of the outgoing packet. With XDP however, we need to maintain our own ARP table
and pass in the destination MAC ourselves:&lt;/p&gt;
    &lt;head rend="h2"&gt;Benchmarks&lt;/head&gt;
    &lt;p&gt;To validate our overall approach, we set up iPerf3 containers between two 200Gbps-capable EC2 instances in the same AWS VPC. We purposely reduced the MTU to 1500 since traffic to the public internet generally can't use jumbo frames in the first place.&lt;/p&gt;
    &lt;p&gt;We used the exact same container networking setup for all three tests - the same standard network namespaces with &lt;code&gt;veth&lt;/code&gt; pairs that Docker and every other container runtime uses by default. The only thing we changed was how packets
were routed from the container's &lt;code&gt;veth&lt;/code&gt; interface to the host's physical interface:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;iptables: The default that everyone uses today - &lt;code&gt;PREROUTING&lt;/code&gt;chains to move traffic out of the namespace&lt;/item&gt;
      &lt;item&gt;Traffic Control: Using a TC egress program on the &lt;code&gt;veth&lt;/code&gt;interfaces&lt;/item&gt;
      &lt;item&gt;XDP: Our technique - Using an XDP program attached to the &lt;code&gt;veth&lt;/code&gt;interfaces&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We also decided to benchmark both the generic and native XDP drivers implemented for &lt;code&gt;veth&lt;/code&gt; interfaces.&lt;/p&gt;
    &lt;p&gt;We'll let the results speak for themselves:&lt;/p&gt;
    &lt;p&gt;iPerf3 Benchmark With Various Routing Strategies&lt;/p&gt;
    &lt;p&gt;The first two results are exactly what we expect - iptables introduces the most overhead because it routes through the linux kernel, and traffic control performs better but still operates post-socket-buffer and can't come close to achieving line-rate.&lt;/p&gt;
    &lt;p&gt;With the &lt;code&gt;generic&lt;/code&gt; XDP driver, however, we see something surprising: worse performance than our TC program. After a
little digging we realized this actually makes sense. The &lt;code&gt;generic&lt;/code&gt; XDP driver does not run on the RX queue and
instead, like TC, runs after the socket buffer has been allocated. The worse performance is the result of running the
XDP program in the same place as TC but without any of the optimizations that TC benefits from.&lt;/p&gt;
    &lt;p&gt;With the &lt;code&gt;native&lt;/code&gt; XDP driver (which is available in
linux 4.19+)
we finally see the results we've been looking for - we're routing just shy of line-rate at about 194Gbps, 12.4 times the
throughput of iptables and about 9.2x the throughput of TC.&lt;/p&gt;
    &lt;p&gt;One final thing to note here are the error bars, which were significantly smaller with &lt;code&gt;native&lt;/code&gt; XDP. This makes
sense since the bulk of our performance improvements come from bypassing the linux kernel and doing less work. iPerf3,
iptables, and the linux kernel are all constantly fighting for the CPU which results in inconsistent throughput.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Drop-In Fast Path for Containers&lt;/head&gt;
    &lt;p&gt;One of the most exciting aspects of this discovery is how immediately applicable it is. We setup our benchmarks to replicate how containers already use network namespaces and &lt;code&gt;veth&lt;/code&gt; pairs. This means we can dramatically accelerate
container networking without changing how containers work or how they're orchestrated.&lt;/p&gt;
    &lt;p&gt;Consider what happens every time a containerized application sends a packet today: it traverses through iptables rules, gets NAT'd, maybe goes through connection tracking, and finally makes it out to the network. All of this happens in the kernel, consuming precious CPU cycles that could be used by actual applications.&lt;/p&gt;
    &lt;p&gt;With XDP on veth interfaces, we can bypass all of that overhead. The packet goes straight from the container's namespace through our XDP program to the physical interface. No iptables. No conntrack. Just pure, line-rate packet routing.&lt;/p&gt;
    &lt;head rend="h2"&gt;What We're Building&lt;/head&gt;
    &lt;p&gt;While our primary use case at Loophole Labs is live migration - where this technique enables us to transparently reroute connections at line rates during migrations - we recognize the broader impact this can have on container networking as a whole.&lt;/p&gt;
    &lt;p&gt;That's why we're working on a Docker network plugin that implements this technique. It'll be a drop-in replacement for Docker's default bridge network driver, except it uses XDP instead of iptables for packet routing.&lt;/p&gt;
    &lt;p&gt;For simpler container deployments that don't need the full complexity of Kubernetes networking (microservices, development environments, or edge computing nodes) this could mean:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Doubling network throughput without any hardware upgrades&lt;/item&gt;
      &lt;item&gt;Dramatically reducing CPU usage for network-heavy workloads&lt;/item&gt;
      &lt;item&gt;Eliminating iptables as a bottleneck in container-to-container communication&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We plan to open source this plugin soon, but the beauty of this technique is that you don't need to wait for us. Everything you need to implement this yourself is described in this post. The &lt;code&gt;veth&lt;/code&gt; pairs are already there, all that's
left is writing the XDP programs to route your packets.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Bigger Picture&lt;/head&gt;
    &lt;p&gt;Loophole Labs was built on a very simple premise: Better Building Blocks = Better Applications.&lt;/p&gt;
    &lt;p&gt;This discovery - that XDP can process egress traffic by taking advantage of &lt;code&gt;veth&lt;/code&gt; interfaces - is the best
representation of just that, a better building block that results in significantly better applications.&lt;/p&gt;
    &lt;p&gt;While we'll be open-sourcing the Docker network plugin for those who want to take advantage of XDP's egress performance for themselves, this discovery also powers something much bigger: Architect, our live migration platform.&lt;/p&gt;
    &lt;p&gt;Architect uses this XDP technique (as well as other breakthrough implementations for disk &amp;amp; memory checkpointing) to seamlessly live migrate your containers, VMs, and even active network connections between any clouds or regions - all without your users noticing.&lt;/p&gt;
    &lt;p&gt;If you're interested in diving deeper into the technical details or implementing XDP egress in your own infrastructure, join our Discord where our engineering team hangs out and answers questions from the community. Trust me, we love talking about this stuff.&lt;/p&gt;
    &lt;head rend="h3"&gt;Ready to Use Live Migration?&lt;/head&gt;
    &lt;p&gt;Join our waitlist to be among the first to dramatically reduce your infrastructure costs while improving reliability:&lt;/p&gt;
    &lt;head rend="h4"&gt;──/~\ Architect&lt;/head&gt;
    &lt;head rend="h4"&gt;──Optimize cluster costs and maximize node utilization, all without modifying your applications or your infrastructure.&lt;/head&gt;
    &lt;head rend="h3"&gt;Going to KubeCon NA 2025?&lt;/head&gt;
    &lt;p&gt;If you are in Atlanta for KubeCon NA 2025 (November 10-13), stop by Booth #1752 to see live demos of workloads migrating between clouds. We'll show you exactly how this XDP technique combines with our other innovations to make the impossible, possible.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://loopholelabs.io/blog/xdp-for-egress-traffic"/><published>2025-11-04T16:26:09+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45815419</id><title>I was right about dishwasher pods and now I can prove it [video]</title><updated>2025-11-05T22:40:13.234060+00:00</updated><content>&lt;doc fingerprint="7055905545553646"&gt;
  &lt;main&gt;
    &lt;p&gt;About Press Copyright Contact us Creators Advertise Developers Terms Privacy Policy &amp;amp; Safety How YouTube works Test new features NFL Sunday Ticket © 2025 Google LLC&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.youtube.com/watch?v=DAX2_mPr9W8"/><published>2025-11-04T20:16:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45821921</id><title>Founder in Residence at Woz (San Francisco)</title><updated>2025-11-05T22:40:13.126994+00:00</updated><content>&lt;doc fingerprint="3ab8fb7857c0d6e6"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Founder in Residence at Woz (San Francisco)&lt;/p&gt;
      &lt;p&gt;We’re opening one of the coolest jobs ever (only slightly biased).&lt;/p&gt;
      &lt;p&gt;At Woz, we’ve built the world's first AI App Factory, capable of building business quality mobile apps in just hours.&lt;/p&gt;
      &lt;p&gt;Now we’re handing over the keys to aspiring founders and challenging them to build real, revenue generating app businesses. Founders get full internal access to our platform, a salary, a dedicated marketing budget, and meaningful upside in any revenue they generate. This is a rare chance to operate like a founder inside a YC startup that recently raised a $6M seed round, surrounded by experienced engineers and builders in the heart of San Francisco.&lt;/p&gt;
      &lt;p&gt;Who we’re looking for: - A technical builder who can ship, iterate and problem solve independently (experience with React Native and TypeScript is a plus) - Someone who has launched products, apps, or businesses before, or has a strong track record of building things on their own - Someone who understands go-to-market and growth, especially creative or viral marketing - Someone eager to learn, experiment, and build alongside our team in San Francisco (able to work in-person for at least the first three months)&lt;/p&gt;
      &lt;p&gt;Interested? Submit your info here. We’ll be in touch https://forms.gle/h8ZWjgRfQUpaTQf8A&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45821921"/><published>2025-11-05T12:00:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45822071</id><title>The grim truth behind the Pied Piper (2020)</title><updated>2025-11-05T22:40:12.970116+00:00</updated><content>&lt;doc fingerprint="bf3fc84dbbe71458"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The grim truth behind the Pied Piper&lt;/head&gt;
    &lt;p&gt;Writers like the Grimm Brothers and Robert Browning may have shaped the Pied Piper legend into art, but it turns out the story is likely based on an actual historical incident.&lt;/p&gt;
    &lt;p&gt;(This year, we published many inspiring and amazing stories that made us fall in love with the world – and this is one our favourites. Click here for the full list).&lt;/p&gt;
    &lt;p&gt;Every working morning for the last 26 years, Michael Boyer has slipped into a pair of neon-bright, multi-coloured tights, tied on his lipstick-red cape, grabbed his flute and marched out into the medieval streets of Hamelin, a town of 60,000 residents in Lower Saxony, Germany.&lt;/p&gt;
    &lt;p&gt;“People sometimes mistake me for a superhero, court jester or Robin Hood,” he laughed. He’s also increasingly become an Instagram prop for tourists and, maybe in some woke eyes, a gender-fluid statement.&lt;/p&gt;
    &lt;p&gt;But most people recognise him for what he is, the Pied Piper incarnate, appointed by Hamelin to impersonate its simultaneously favourite (at least commercially) and least favourite adopted son. Responsible for meeting and greeting visiting groups and dignitaries, he leads tours of the city and embodies the enduring hold of the legend that draws most travellers here.&lt;/p&gt;
    &lt;p&gt;The tale in fact has survived for a very long time. Originating as medieval folklore, the story inspired a Goethe verse, Der Rattenfänger; a Grimm Brothers’ legend, The Children of Hamelin; and one of Robert Browning’s best-known poems, The Pied Piper of Hamelin. And although each writer tinkered with the story, the basics remained the same: the Piper was hired by Hamelin to rid the town of its plague of rats. Trailing after the hypnotic notes of the rat-catcher’s magical flute, the rodents politely filed through the city gates to their presumed doom.&lt;/p&gt;
    &lt;p&gt;They weren’t the only ones lured by his music, though. When the town refused to pay the Piper for his service, the saviour turned into a more satanic seducer and came for Hamelin’s children. Entranced by the notes of his flute, the transfixed boys and girls followed the Piper out of town and simply vanished.&lt;/p&gt;
    &lt;p&gt;While the tale has endured, so has Hamelin itself, which still looks as though it belongs in a fairy tale. Boyer’s tour leads visitors past rows of half-timbered houses. There are 16th Century burgher manors encrusted with Gothic gables and scrollwork, and flamboyant wedding cake buildings offering prime examples of the local Weser-Renaissance architecture, all leering gargoyles and brightly coloured polychrome wood carvings.&lt;/p&gt;
    &lt;p&gt;However, all this is merely background for the town’s real cottage industry, which cashes in on all things Piper. The local restaurants plate a “rat tail” signature dish made from thinly sliced pork, and the bakeries do a brisk business in rodent-shaped breads and cakes. The Hameln Museum offers a sound and light Pied Piper re-enactment; local actors put on an open-air Pied Piper play during summer; and the souvenir shops hawk their own rat-inspired memorabilia. You can go home, if you wish, loaded down with Pied Piper T-shirts, fridge magnets, mugs and flutes.&lt;/p&gt;
    &lt;p&gt;What could pass for mere comic relief, though, masks something deeper, and suggests why the legend lives on not only in Hamelin but in enduring folklore. On some level, the tale stokes a primal fear, with the Piper a version of a universal bogey man that continues to haunt us. Parents everywhere still fear the loss of their babies. Children, popping up on the nightly news, still go missing every day. And then we all ultimately vanish in something like an instant. The Piper, in the end, is one very grim reaper.&lt;/p&gt;
    &lt;p&gt;But if the tale evokes a universal fear, it still resonates most strongly in Hamelin – and the Piper’s tour suggests why. In fact, the real surprise of his tour isn’t so much the beautifully preserved townscape but the suggestion that the Pied Piper is much more than just a fairy tale. The Grimm Brothers and Browning may have shaped the legend into art, but the story, it turns out, is likely based on an actual historical incident.&lt;/p&gt;
    &lt;p&gt;You may also be interested in:&lt;/p&gt;
    &lt;p&gt;• The elusive hidden people of Iceland&lt;/p&gt;
    &lt;p&gt;The proof is etched on Hamelin’s face itself. An inscribed plaque on the stone facade of the so-called Pied Piper house, a half-timbered private residence dating to 1602 – similar to an even earlier one etched on the building’s window – bears explicit witness to the mystery. The inscription reads:&lt;/p&gt;
    &lt;p&gt;“A.D. 1284 – on the 26th of June – the day of St John and St Paul – 130 children – born in Hamelin – were led out of the town by a piper wearing multicoloured clothes. After passing the Calvary near the Koppenberg they disappeared forever.”&lt;/p&gt;
    &lt;p&gt;The inscription isn’t the only clue. An entry in Hamelin’s town records, dating to 1384, laments that, “It is 100 years since our children left.” The stained-glass window in the town’s St Nicolai church, destroyed in the 17th Century but described in earlier accounts, reportedly illustrated the figure of the Pied Piper leading several ghostly white children. And the 15th Century Luneburg manuscript, an early German account of the event, along with five historical memory verses, some in Latin and others in Middle Low German, all refer to a similar story of 130 children or young people vanishing on the 26 June 1284, following a pied piper to a place called Calvary or Koppen.&lt;/p&gt;
    &lt;p&gt;The Pied Piper then, more than a fairy tale, becomes the emblem of a profound historical mystery. What happened to the missing children of Hamelin? Still the master seducer, the mesmerising rat-catcher is now leading a whole new trail of entranced followers – this time a conga line of historians each taking their own deep dive into the question of what exactly transpired in Hamelin on 26 June 1284.&lt;/p&gt;
    &lt;p&gt;The theories are legion, according to Wibke Reimer, project coordinator at the Hameln Museum who has been organising a special exhibit that focuses on the global reach of the Pied Piper legend. One of the leading current theories suggests the town’s youth were part of a migration of Germans to Eastern Europe fuelled by an economic depression.&lt;/p&gt;
    &lt;p&gt;“In this scenario,” Reimer said, “the Pied Piper played the role of a so-called locator or recruiter. They were responsible for organising migrations to the east and were said to have worn colourful garments and played an instrument to attract the attention of possible settlers.”&lt;/p&gt;
    &lt;p&gt;While some historians believe that the youth emigrated to Transylvania, the German linguist Jürgen Udolph’s theory is most accepted. “He suggests the regions around Berlin as the most probable location, in an area that’s now [eastern Germany],” Reimer said, “and he backs up his theory by place name evidence.” In fact, Udolph found that the family names common in Hamelin at the time show up with surprising frequency in the areas of Uckermark and Prignitz, near Berlin, that he locates as the centre of the migration. The theory is also reinforced by evidence that the region, newly liberated from the Danes, was ripe for German colonisation.&lt;/p&gt;
    &lt;p&gt;More fanciful theories abound, too. Some historians suggest the legend reflects a 13th Century children’s crusade, part of the wave of medieval crusades aimed at winning back the Holy Land. And some argue the youth were lost to the Black Plague, though the dates don’t match up.&lt;/p&gt;
    &lt;p&gt;More intriguing is a theory that points to the medieval phenomenon of “dancing mania”, driven by a succession of pandemics and natural disasters. Known as St Vitus’ Dance, the dancing plague is documented surfacing in continental Europe as early as the 11th Century. A form of mass hysteria, the dance could spread from individuals to large groups, all driven by an unshakeable compulsion to dance feverishly, sometimes for weeks, often leaping and singing and sometimes hallucinating to the point of exhaustion and occasionally death, like a top that can’t stop spinning.&lt;/p&gt;
    &lt;p&gt;And, in fact, one 13th Century outbreak – a literal form of dance fever – occurred south of Hamelin, in the town of Erfurt, where a group of youths were documented as wildly gyrating as they travelled out of town, ending up 20km away in a neighbouring town. Some of the children, one chronicle suggests, expired shortly thereafter, having flat-out danced themselves to death, and those who survived were left with chronic tremors. Perhaps, some theorise, Hamelin witnessed a similar plague, dancing to the figurative tune of the Piper.&lt;/p&gt;
    &lt;p&gt;But all these theories neglect one specific key to the Hamelin mystery. “They don’t explain the very particular date cited for the loss of the children, and the local sense of trauma,” Reimer noted. “Did something happen that officials had been covering up? Something so traumatic that it was transmitted orally for so long in the town’s collective memory, over decades and even centuries?”&lt;/p&gt;
    &lt;p&gt;In fact, the date chronicled in all the local documentation pinpoint 26 June as the day the children disappeared. This day is also the date of pagan midsummer celebrations. The fact the documentation also emphasises that the youth followed the Piper to the Koppen, commonly translated as “hills”, suggest another link. “There were regions in Germany where midsummer was celebrated by lighting fires on the hills,” said Reimer. All that leads to one particularly macabre reading of the Pied Piper legend. Perhaps the Piper, emblematic of a pagan shaman, playing his flute, was leading the youth of Hamelin to their midsummer festivities when the local Christian faction, hoping to cement conversion of the region, waylaid and massacred the group. A less bloody theory: maybe the children were spirited away to local monasteries.&lt;/p&gt;
    &lt;p&gt;If the tale suggests a possible historical tragedy, though, it also offers an artistic redemption as well.&lt;/p&gt;
    &lt;p&gt;“The Pied Piper story,” said Reimer, preparing for the debut of her exhibit on 26 June, “is to our knowledge known in at least 42 countries and 30 languages, maybe more. And it appears in international art, literature and music. The Pied Piper is a shared heritage of many people, and that cultural heritage connects people.”&lt;/p&gt;
    &lt;p&gt;Ultimately, then, the Piper didn’t just fracture a community. He also, in the end, brought a larger one together.&lt;/p&gt;
    &lt;p&gt;Join more than three million BBC Travel fans by liking us on Facebook, or follow us on Twitter and Instagram.&lt;/p&gt;
    &lt;p&gt;If you liked this story, sign up for the weekly bbc.com features newsletter called "The Essential List". A handpicked selection of stories from BBC Future, Culture, Worklife and Travel, delivered to your inbox every Friday.&lt;/p&gt;
    &lt;p&gt;{"image":{"pid":""}}&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bbc.com/travel/article/20200902-the-grim-truth-behind-the-pied-piper"/><published>2025-11-05T12:21:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45822513</id><title>Optimism associated with exceptional longevity (2019)</title><updated>2025-11-05T22:40:12.730191+00:00</updated><content/><link href="https://www.pnas.org/doi/10.1073/pnas.1900712116"/><published>2025-11-05T13:16:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45822539</id><title>NY smartphone ban has made lunch loud again</title><updated>2025-11-05T22:40:12.564198+00:00</updated><content>&lt;doc fingerprint="366ad004a8c395ce"&gt;
  &lt;main&gt;
    &lt;p&gt;These days, lunchtime at Benjamin N. Cardozo High School in Queens is a boisterous affair, a far cry from before the smartphone ban went into effect, when most students spent their spare time scrolling and teachers said you could hear a pin drop.&lt;/p&gt;
    &lt;p&gt;“This year's gotten way louder,” said Jimena Garcia, 15. “Sometimes I would take naps in the lunchroom, but now I can't because of the noise. But it's fun.”&lt;/p&gt;
    &lt;p&gt;On a recent fall afternoon, Garcia and her friends crowded around a lunch table in the large cafeteria playing Jenga, occasionally shrieking and gasping as the tower began to lean and fall.&lt;/p&gt;
    &lt;p&gt;The faculty donated board games to help ease kids into the phone-free era. Student volunteers oversaw a table stacked with games: checkers, chess, Yahtzee, Scrabble, Clue, Life and Trivial Pursuit. For many of the kids, it was their first time playing the games, and they said they were enjoying it.&lt;/p&gt;
    &lt;p&gt;“ I do like how this phone ban is allowing students to just connect with each other, make new friendships,” said 17-year-old Alyssa Ko, the school president. “Because some people use their phone to just hide away.”&lt;/p&gt;
    &lt;p&gt;The ban prohibits all internet-enabled devices throughout the school day, although there are exceptions for some students with disabilities, kids learning English who need translation apps, and in cases where a teacher says a device can be used for a lesson.&lt;/p&gt;
    &lt;p&gt;Schools were given flexibility to choose their own storage plans, and Cardozo, which rolled out metal detectors this fall after a student was found with a gun, requires its 3,100 students to keep their phones in internet-blocking magnetic pouches. Other schools have installed storage lockers, or have kids keep their phones zipped up in backpacks.&lt;/p&gt;
    &lt;p&gt;As students adjust to lo-fi life, teachers seem pleased with the results. According to an October survey from the state teachers union, New York State United Teachers, 89% of school staff members said the new policies improved their schools' environments, and 76% said kids are more engaged in lessons.&lt;/p&gt;
    &lt;p&gt;“When students put down their phones, they pick up books — and build friendships,” said NYSUT president Melinda Person.&lt;/p&gt;
    &lt;p&gt;The initial feedback reflects national trends. New York is one of 31 states, plus Washington, D.C. that have banned smartphones in schools, according to an EdWeek tracker. In a national survey from the University of Pennsylvania, teachers said banning phones helps kids focus.&lt;/p&gt;
    &lt;p&gt;“Teachers seem really happy with the changes that they're seeing in the classroom with the electronic device ban,” Cardozo principal Meagan Colby said. “They're telling us that there's a lot more student interaction, a lot more discussion among students, a lot better focus. Overall productivity in the classroom and engagement is higher.”&lt;/p&gt;
    &lt;p&gt;Senior Raya Osagie, 16, said she has to “think more in class” because she used to Google answers or use artificial intelligence. “Now when we get computers, I actually have to [do] deep research instead of going straight to AI,” she said.&lt;/p&gt;
    &lt;p&gt;Students said they’ve also seen their classmates reading physical books more.&lt;/p&gt;
    &lt;p&gt;In the cafeteria, Ryan Tripathi, 16, was paging through “Lord of the Flies,” which he said is slow-going. “I'm just not used to reading,” he said. “I’m usually on my phone.”&lt;/p&gt;
    &lt;p&gt;Tripathi said it’s good that people are reading more and classroom discussions have become more lively. But he said he’s “not the biggest fan” of the smartphone ban. ”Sometimes you just want to go on your phone and you don't have the ability to do that anymore,” he said.&lt;/p&gt;
    &lt;p&gt;Enakshi Barua, 14, said she’s also opposed to the ban, on principle.&lt;/p&gt;
    &lt;p&gt;“ Students are distracted by the phones, but I also don’t believe they should take away our privileges," Barua said. "I feel like the trust isn’t there between the students and teachers. So I feel like that should be built instead of banning the phones.”&lt;/p&gt;
    &lt;p&gt;At Cardozo, a few kids break the rules, teachers said. Some either put “burner” phones in their pouches or bang them open. Shanna Burrows, who oversees restorative justice at the school, said staff members are collecting around 30 contraband phones a day. There’s a strike system with escalating punishments that include keeping phones for days, weeks or months, and meetings with parents. Under the state law, schools are not allowed to suspend students solely for smartphone-ban infractions.&lt;/p&gt;
    &lt;p&gt;Students said they have found other ways to push boundaries, like passing old-fashioned notes. “ Especially when you're trying to talk but not have the teacher notice … it would just be [that] we’d send a text message or write on our notes app,” Ko said. “Passing notes is more common now.”&lt;/p&gt;
    &lt;p&gt;Ko said other analog activities have also made a comeback, including cards, hangman, tic-tac-toe and Polaroid cameras. “There are just a lot of memories that we make throughout high school that we want to capture,” she said. “I actually have a lot of Polaroids on my wall.”&lt;/p&gt;
    &lt;p&gt;Tiana Millen, assistant principal of climate and culture, said she’d also like to see another analog technology make a comeback: the clock.&lt;/p&gt;
    &lt;p&gt;“They don't know how to read the clocks," she said. "So I make jokes with them and say, ‘We're going to have classes just on how to read the clocks.’”&lt;/p&gt;
    &lt;p&gt;If they did, she said, they’d see they’re getting to class on time more than they used to; hallway traffic is moving better now that kids aren’t so focused on their phones.&lt;/p&gt;
    &lt;p&gt;This story has been updated.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gothamist.com/news/ny-smartphone-ban-has-made-lunch-loud-again"/><published>2025-11-05T13:20:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45822982</id><title>A P2P Vision for QUIC (2024)</title><updated>2025-11-05T22:40:11.709145+00:00</updated><content>&lt;doc fingerprint="23b498505021acb9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A p2p Vision for QUIC&lt;/head&gt;
    &lt;p&gt;This article was co-authored by Christian Huitema. You can find his blog at privateoctopus.com.&lt;/p&gt;
    &lt;p&gt;Over the years, the IETF has standardized numerous protocols for establishing IP packet flows through NATs and firewalls, including STUN, ICE, and TURN.&lt;/p&gt;
    &lt;p&gt;This is an inherently messy topic, and I can highly recommend reading Eric Rescorla’s blog post series about NATs (part 1, part 2, part 3). I won’t go into details about how exactly NATs work (again, read the ekr’s blog posts!), but in a nutshell, they rewrite the IP of packets passing through the NAT.&lt;/p&gt;
    &lt;p&gt;(192.168.1.10) participant NAT as NAT&lt;/p&gt;
    &lt;p&gt;(203.0.113.5) participant Server as Server&lt;/p&gt;
    &lt;p&gt;(198.51.100.20) Client-&amp;gt;&amp;gt;NAT: Packet (Src: 192.168.1.10:1234) NAT-&amp;gt;&amp;gt;Server: Packet (Src: 203.0.113.5:4321) Server--&amp;gt;&amp;gt;NAT: Response (Dst: 203.0.113.5:4321) NAT--&amp;gt;&amp;gt;Client: Response (Dst: 192.168.1.10:1234)&lt;/p&gt;
    &lt;p&gt;This allows multiple clients behind that NAT to share the same external IP address. Clients are able to reach any server on the internet, but it doesn’t allow nodes on the internet to reach the client, since the NAT won’t forward packets to the client, unless it determines that they belong to an existing flow. In that sense, the NAT acts as a firewall.&lt;/p&gt;
    &lt;p&gt;Although simple in theory, there are a lot of different ways to implement a NAT. For our purposes, the main difference lies in how the port numbers for the outgoing packets are allocated. Depending on the port allocation logic, it might or might not possible to establish a direct connection between two peers.&lt;/p&gt;
    &lt;p&gt;The problem that p2p network engineers hope to solve is the following: How can two nodes that are both behind a NAT, respectively, connect to each other, no matter the kind of NAT?&lt;/p&gt;
    &lt;p&gt;In this post, we explore how QUIC can be leveraged to provide a comprehensive solution for NAT traversal, encompassing everything from address discovery to UDP proxying, potentially simplifying and improving upon traditional p2p networking approaches.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Traditional Way&lt;/head&gt;
    &lt;head rend="h3"&gt;Address Discovery using STUN&lt;/head&gt;
    &lt;p&gt;Depending on the deployment scenario, a new node joining the network might or might not know its (public) IP address. Traditionally, applications use STUN (RFC 8489) to discover their public IP address. In a nutshell, a STUN client sends a “Binding Request” to a STUN server. The “Binding Response” of the server encodes the IP source address and the source port that the server observed on the client’s request.&lt;/p&gt;
    &lt;p&gt;The client can infer from the responses to the STUN requests if it is located behind a NAT. The client might even compare responses from different STUN servers and attempt to infer the type of NAT, although this is notoriously difficult to get right. The IETF has pretty much given up on this approach (see section 2 of RFC 5389).&lt;/p&gt;
    &lt;p&gt;The STUN protocol can run over UDP, TCP, DTLS (RFC 7350) or TLS.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hole Punching Coordination using ICE&lt;/head&gt;
    &lt;p&gt;As we’ve seen above, once the NAT has seen the first packet to a remote server pass through, the NAT opens up the return path, allowing packets from the outside world to reach the node. The idea behind hole punching is to have both peers send packets simultaneously, each of them “punching” a hole in their respective firewall, establishing a direct flow of packets between the two nodes.&lt;/p&gt;
    &lt;p&gt;The traditional hole punching process is specified by ICE RFC 8445. ICE starts with an address gathering phase, in which the two peers separately contact STUN servers to obtain lists of candidate IP addresses and ports. They may add to that list a set of TURN addresses (see next section, “relaying”).&lt;/p&gt;
    &lt;p&gt;One of the endpoints creates a list of available addresses, ordered by priority, and sends it to its peer. The peer compares that to its own list, establishes a list of “candidate pairs”, and sends it back. At that point, both endpoints have the same list of candidate pairs, and start the “connectivity” check. Each host will try to send a STUN binding request from its selected address to the paired address, and respond to STUN requests that it might receive from the peer. If at least one of these trials succeeds, the peers have established a new connection over this address pair. If several succeed, they keep the preferred pair.&lt;/p&gt;
    &lt;head rend="h3"&gt;Relaying using TURN&lt;/head&gt;
    &lt;p&gt;Unfortunately, no matter how hard you try, there is a certain percentage of nodes for whom hole punching will never work. This is because their NAT behaves in an unpredictable way. While most NATs are well-behaved, some aren’t. This is one of the sad facts of life that network engineers have to deal with.&lt;/p&gt;
    &lt;p&gt;The only solution for this problem is to employ the help of a third party, i.e. a server that is not located behind a NAT, and therefore can be reached by peers directly, without any hole punching. This server can then relay traffic between the two peers.&lt;/p&gt;
    &lt;p&gt;Of course, this comes at a cost. The path via the relay might be slower (in terms of latency and / or bandwidth) than a (hypothetical) direct path would have been. And relaying traffic is not for free for the operator of the relay: both processing resources as well as bandwidth cost money. However, we don’t really have a choice here, and despite these shortcomings, having a relayed connection might be preferable to having no connectivity at all.&lt;/p&gt;
    &lt;p&gt;The traditional solution relies on TURN servers, specified in RFC 5766 to provide these “last resort” connectivity. The node behind a NAT can ask the TURN server to open an UDP or TCP port. This “TURN Port” is usually specialized: the client specifies the address of the peer that will be able to send data to that port, or to which data will be sent. The corresponding IP address and port number will be sent to the peer, and will be the basis for some last resort “candidate pairs” used in the coordinated hole punching.&lt;/p&gt;
    &lt;p&gt;The previous section mentioned that in some cases more than one tried address pair will succeed. This is particularly true for the pairs that include a TURN provided address. This is why the trials will try to collect all the working pairs and pick the higher priority one. If both a “hole punching” and a “TURN” pair succeed, they will typically only retain the “hole punching” pair.&lt;/p&gt;
    &lt;head rend="h2"&gt;The QUIC Way&lt;/head&gt;
    &lt;head rend="h3"&gt;QUIC Connection Migration&lt;/head&gt;
    &lt;p&gt;RFC 9000 defines how clients can migrate an existing QUIC connection to a different IP:port tuple. When we designed this mechanism, the primary use case we envisioned was solving the “parking lot problem”. Imagine you have a mobile phone, and you walk from your office (where the phone has WiFi) to the parking lot (with no / bad WiFi coverage). In this case, the client could detect that the WiFi connection is worsening, and migrate the connection to its cellular interface. Crucially, this would keep all connection state (e.g. open streams, datagram flows, etc.) intact, and would therefore be transparent to the application.&lt;/p&gt;
    &lt;p&gt;On detecting a network interface change, e.g. leaving the office, QUIC Path Migration works by first sending a so-called probing packet to the server. The purpose of this packet is to probe if the path actually works. The client includes a PATH_CHALLENGE frame in this packet, to which the server responds with a PATH_RESPONSE frame. This makes sure that the new path actually works (for example, that the path doesn’t block UDP packets), and supports QUIC (for example, allows packets that satisfy QUIC’s MTU requirements).&lt;/p&gt;
    &lt;p&gt;On the wire, this path probing procedure looks pretty similar to a hole punch attempt. We just need a tiny modification to make this work in the p2p use case: If we could get the server to send probe packets as well, we could kill two birds with one stone: We’d punch a hole through the firewall, and at the same time verify connectivity on the path.&lt;/p&gt;
    &lt;p&gt;Of course this is not the only thing needed to achieve hole punching. Before the nodes can even send probe packets, we need to learn about the peer’s reflexive address, and be able to coordinate the timing. We’ll come to this in a bit, but first we’ll describe how we can replace STUN to discover our reflexive addresses.&lt;/p&gt;
    &lt;head rend="h3"&gt;QUIC Address Discovery&lt;/head&gt;
    &lt;p&gt;Typically nodes use STUN to discover their reflexive addresses. In essence, STUN is a request-response protocol here, where the client requests the server to report the observed address of the request packet.&lt;/p&gt;
    &lt;p&gt;In principle, we could achieve the same inside of a QUIC connection: The server could report the address of the client using, for example, a newly defined QUIC frame, and vice versa. This is exactly what the QUIC Address Discovery draft specifies.&lt;/p&gt;
    &lt;p&gt;The mechanism is really simple: every time a new path is established (incl. the path used for the handshake), endpoints inform each other of the observed address. This is a very efficient mechanism: Since the OBSERVED_ADDRESS frame is defined as a probing frame, it can be bundled with the PATH_CHALLENGE and PATH_RESPONSE frames used to probe a new path.&lt;/p&gt;
    &lt;p&gt;Performing address discovery over QUIC comes with multiple advantages:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;QUIC packets are encrypted. An observer is not able to observe the exchange of OBSERVED_ADDRESS frames, nor interfere with this exchange (e.g. by tampering with the frame contents).&lt;/item&gt;
      &lt;item&gt;It doesn’t require running any additional services (i.e. a STUN server / client). It’s sufficient to enable the Address Discovery extension on a large enough number of nodes.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Of course, in either case the client has to trust that the server is sending honest responses. A misbehaving server could respond with spoofed addresses, causing the “hole punching” packets to later be sent to these addresses. This is not hard to defend against: Clients can obtain some protection against such attacks by contacting several servers and comparing their responses.&lt;/p&gt;
    &lt;head rend="h3"&gt;Hole Punching Coordination&lt;/head&gt;
    &lt;p&gt;The node has now learned its reflexive addresses, and we know how to use QUIC’s connection migration mechanism to establish the NAT port mappings required to allow the establishment of a direct path. We now want to establish a connection to another node, behind its respective NAT.For the moment, we’ll assume that the two nodes are able to communicate via a (proxied) QUIC connection. We’ll see how this works in detail in the next section. The only thing that matters for now is that the nodes are able to communicate with each other.&lt;/p&gt;
    &lt;p&gt;The NAT traversal draft defines how two nodes can negotiate hole punching attempts with each other. Out of convenience, the process is driven almost entirely by the client (i.e. the node that initiated the QUIC connection). This is not because the roles of the peers are fundamentally different (they are both peers in the same p2p network), but it leads to significant simplifications of the protocol. It also reduces the difference to RFC 9000, where connection migration can only be initiated by the client.&lt;/p&gt;
    &lt;p&gt;The server informs the clients about its reflexive address using ADD_ADDRESS frames. Multiple ADD_ADDRESS frames can be sent if the server has multiple reflexive addresses.&lt;/p&gt;
    &lt;p&gt;The ICE RFC goes into great detail on how to form candidate pairs from both nodes’ reflexive addresses, because both nodes need to agree on the ordering of the candidate pairs. Since the client is driving this process, we don’t need to specify any address matching logic that client and server would need to agree on.&lt;/p&gt;
    &lt;p&gt;Once the client has formed address pairs (and once it feels like it’s the right time to start a hole punch attempt), it sends a PUNCH_ME_NOW frame to the server. The PUNCH_ME_NOW contains both the client’s and the server’s reflexive addresses.&lt;/p&gt;
    &lt;p&gt;Immediately after sending the PUNCH_ME_NOW frame, the client starts path probing on the path formed by these two addresses. Equivalently, as soon as the server receives the PUNCH_ME_NOW frame, it starts path probing the path from its end. Timing is crucial here: As we’ve seen above, the path probing packets create the NAT binding required to allow the other side’s packets to make it through the NAT.&lt;/p&gt;
    &lt;p&gt;Both the client and the server will send PATH_CHALLENGE frames on a new path when sending or responding to &lt;code&gt;PUNCH_ME_NOW&lt;/code&gt;. They will need to allocate a yet unused Connection ID to the new path that they
are trying to establish. This implies that the number of parallel attempts is limited by the number of available Connection ID. This has both upsides and downside. On the one hand, having a limit reduces the amount of resource that a peer can be forced to consume, which makes the protocol more stable.
On the other hand, if the limits are reached, the next attempt will only be possible after one of the previous challenges has been abandoned, and the peer has provided a replacement Connection ID. This might be a slow process.&lt;/p&gt;
    &lt;p&gt;Whether that process is too slow is debatable. Endpoints that plan to engage in p2p hole punching may be configured to provide a number of Connection IDs sufficient for most practical attempts. Also, the initial path will be available until the migration succeeds, which means the application endpoints do not need to wait the success of the negotiation to start exchanging data.&lt;/p&gt;
    &lt;p&gt;Adding new QUIC frames like &lt;code&gt;ADD_ADDRESS&lt;/code&gt; or &lt;code&gt;PUNCH_ME_NOW&lt;/code&gt; is somewhat controversial. Misbehaving peers could send spoofed addresses in these frames, causing the peer to send hole punching packets to third parties. This is similar to the request forgery attacks described in the security section of RFC 9000, and calls at least for the same kind of defenses. This is something we will keep in mind when evolving the NAT traversal draft.&lt;/p&gt;
    &lt;head rend="h3"&gt;Relaying UDP packets over HTTP&lt;/head&gt;
    &lt;p&gt;RFC 9298 defines how UDP packets can be proxied in HTTP. The exchange starts a regular HTTP request: The client sends a so-called Extended CONNECT request to the proxy on a QUIC stream, instructing the proxy to open a UDP socket and proxy a flow of UDP packets to a target server.&lt;/p&gt;
    &lt;p&gt;Once the proxy has accepted the proxying request, UDP packets are sent in HTTP Datagrams (RFC 9297), which themselves are a thin wrapper around QUIC DATAGRAM frames. QUIC Datagrams are a new QUIC frame defined in RFC 9221, which are sent in QUIC packets exchanged after completion of the QUIC handshake. They’re therefore encrypted the same way that any other data exchanged over the QUIC connection is. However, if a packet containing a DATAGRAM is lost, the DATAGRAM frame is not retransmitted. This makes DATAGRAMs suitable to proxy unreliable packets, such as UDP packets.&lt;/p&gt;
    &lt;p&gt;Multiple UDP flows to different target servers can be proxied in the same QUIC connection.&lt;/p&gt;
    &lt;p&gt;Proxying UDP packets is almost what we need to make relaying work in the p2p scenario, but not quite: While the client can reach any IP via the proxy, it’s still not possible for other nodes to communicate with the client (unless contacted first by the client).&lt;/p&gt;
    &lt;p&gt;Fortunately, there’s already a draft describing how to Proxy UDP Listeners in HTTP. The primary use case for this draft is running WebRTC over CONNECT-UDP. This is a very similar problem to the one we’re trying to solve: WebRTC peers actually use the ICE protocol to establish a direct connection, and for that they need to know their reflexive transport addresses.&lt;/p&gt;
    &lt;p&gt;The mechanism is pretty straight-forward: The proxy allocates a new IP:port for the client, and forwards all UDP packets on this socket to the client. Of course, it also has to include the 2-tuple that the packet originated from.&lt;/p&gt;
    &lt;p&gt;The simplificity of this approach is at the same time its biggest limitation: Since there are only 65535 port numbers (many of which are reserved), a proxy can only handle a limited number of clients at the same time. To be clear, this still allows tens of thousands of concurrent clients, and many deployment scenarios will never run into this limit.&lt;/p&gt;
    &lt;p&gt;It might be possible to work around this limit in the future by using a similar approach as the QUIC-aware proxying draft.&lt;/p&gt;
    &lt;head rend="h3"&gt;Preparing for Multipath&lt;/head&gt;
    &lt;p&gt;The QUIC Working Group is finalizing the Multipath Extensions for QUIC. As the name suggests, this extensions allow multiple paths to be used simultaneously. For the p2p use case, this means that endpoints could keep the initial path available, even after a direct path was created by NAT traversal. These paths could either be used for load sharing or as a backup.&lt;/p&gt;
    &lt;p&gt;To get these benefits, we will need minor adaptations of the mechanism described here – effectively, managing connection IDs and path IDs in a multipath version of the &lt;code&gt;PUNCH_ME_NOW&lt;/code&gt; frame. We should work on that once the Multipath Extension for QUIC has made more progress in the IETF.&lt;/p&gt;
    &lt;head rend="h2"&gt;Putting All the Pieces Together&lt;/head&gt;
    &lt;p&gt;Now that we’ve explored all the components, let’s put them together and build a small p2p application running on top of QUIC.&lt;/p&gt;
    &lt;p&gt;When the node boots up, it first connects to a few hard-coded boot nodes. The majority of these nodes support the QUIC Address Discovery extension, so the node is able to learn that it’s behind a NAT, and what the NAT’s public addresses are.&lt;/p&gt;
    &lt;p&gt;It then connects to a relay and reserves an IP:port tuple with the relay. The node can now advertise this address to other peers in the network, for example by registering in some kind of peer directory, or by registering itself with the p2p network’s DHT.&lt;/p&gt;
    &lt;p&gt;At this point, other nodes can connect to the relay at this port, and have all their packets relayed. We’ve achieved the first goal: we have established connectivity. The relayed connections can immediately be used to exchange application data. Now the goal is to lighten the load on the relay server, and to obtain a direct (and potentially lower-latency, higher-throughput) to the peer.&lt;/p&gt;
    &lt;p&gt;The nodes employ the mechanism described in the NAT traversal draft to punch holes through their respective NATs. This hole punching procedure might take a few attempts, depending on the number of candidate pairs (and if hole punching attempts are run in parallel), but should generally only take a few seconds.&lt;/p&gt;
    &lt;p&gt;Most importantly, this is entirely transparent to the application: The application can start to use the relayed connection, and use it all the while the QUIC stack tries to establish the direct path.&lt;/p&gt;
    &lt;head rend="h2"&gt;Where are we on this?&lt;/head&gt;
    &lt;p&gt;So far, there’s no implementation of this protocol in production, but a lot of the documents have made their way through the IETF process and have now become widely deployed RFCs.&lt;/p&gt;
    &lt;p&gt;Specifically, the remaining pieces of the puzzle are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The Proxy UDP Listeners in HTTP draft, which allows clients to reserve an IP:port tuple on a relay server.&lt;/item&gt;
      &lt;item&gt;The QUIC Address Discovery draft, which allows endpoints to learn about their public addresses. The current version of this draft is implemented by two different QUIC stacks: picoquic and a fork of quinn.&lt;/item&gt;
      &lt;item&gt;The NAT Traversal for QUIC draft, which defines how to coordinate hole punching attempts between peers.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The quic-go project and the QUIC Interop Runner are community-funded projects.&lt;/p&gt;
    &lt;p&gt;If you find my work useful, please considering sponsoring:&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://seemann.io/posts/2024-10-26---p2p-quic/"/><published>2025-11-05T14:06:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45823141</id><title>The shadows lurking in the equations</title><updated>2025-11-05T22:40:11.231338+00:00</updated><content>&lt;doc fingerprint="370746cbee2f5ea1"&gt;
  &lt;main&gt;
    &lt;p&gt;For all the history of computational mathematical visualization, graphing equations has been done in binary mode - where graphs show only where an equation is EXACTLY equal. But when you only see in black-and-white, some things are invisible. For all this time, lurking beneath the error == 0 surface, mathematical shadows have been lurking in the equations.&lt;/p&gt;
    &lt;p&gt;FuzzyGraph, on the other hand, visualizes equations in Non-Binary mode - showing not only where an equation are exactly equal, but also where the equation nearly equal and where the equation is far from equal (where the error is high). Sometimes, these high error areas form clear visual shadow-like features.&lt;/p&gt;
    &lt;p&gt;Let's look at some examples...&lt;/p&gt;
    &lt;p&gt;Here is the "Slash Dot" Equation ( \( \frac{y}{x^2+y^2} = \frac{x+1}{x^2+y^2} \)) as both a conventional and fuzzy graph...&lt;/p&gt;
    &lt;p&gt;Note the giant black hole that is present in the Fuzzy/Non-Binary graph, but invisible in conventional/Binary graphing. This "black hole" feature represents a region of high error in the equation.&lt;/p&gt;
    &lt;p&gt;Let's look at another example: \(y = \frac{x}{x^2 + y^2} \) &lt;/p&gt;
    &lt;p&gt;Notice that the black hole eye-looking features are COMPLETELY INVISIBLE in the conventional/binary mode of graphing.&lt;/p&gt;
    &lt;p&gt;To get a better idea of what these black hole things are, let's look at a simpler example. First let's look at the opposite of a black hole - a simple star/particle example: \( x^2 + y^2 = 0 \). For this equation, there is only 1 solution: (0, 0). So if you graph this in a conventional graphing app, it will only show a single dot at (0, 0). But in FuzzyGraph, it looks like a fuzzy particle or something.&lt;/p&gt;
    &lt;p&gt;But now, let's invert this to get the "Black Hole Equation": \( \frac{1}{x^2+y^2} = 0 \)...&lt;/p&gt;
    &lt;p&gt;In this case, there is absolutely nothing to show on a conventional graph, as there are actual solutions to this equations. However, there is still a mathematical topography which can be visualized (as can be seen in the fuzzy graph).&lt;/p&gt;
    &lt;p&gt;Not all of the Shadows are like black holes.&lt;/p&gt;
    &lt;p&gt;In this example, let's start by combining 2 lines together: \(y=x\) and \(y=-x\).&lt;/p&gt;
    &lt;p&gt;We can visually add 2 equations together by refactoring them so they are both equal to 0, and then multiplying the two refactored equations together. \(y=x\) can be changed to \(y-x=0\), and \(y=-x\) can be refactored to \(y+x=0\).&lt;/p&gt;
    &lt;p&gt;We can then combine 2 into a single equation these like this: \( (y-x) \times (y+x) = 0 \)&lt;/p&gt;
    &lt;p&gt;And now, let's invert one of the equations using division: \( \frac{x-y}{x+y} = 0 \)&lt;/p&gt;
    &lt;p&gt;So as you can see, the line that was inverted (under the division line) is now a Shadow Line. And this seems like a more "correct" way to visualize this than as the conventional graph shows it (which is indistinguishable from the simpler equation, \(y-x=0\)).&lt;/p&gt;
    &lt;p&gt;This equation works almost exactly as the previous. And like before, let's start with multiplication to combine 2 equations (in this case, a circle and a vertical line equation): \( x \times (x^2+y^2-1) = 0 \).&lt;/p&gt;
    &lt;p&gt;But now, let's invert the circle by using division, which makes the equation: \( \frac{x}{x^2+y^2-1} = 0 \).&lt;/p&gt;
    &lt;p&gt;Note that the Shadow Circle is invisible in the conventional graph. In fact, the conventional graph looks identical to a conventional graph of the \(x=0\) equation (as if the denominator was not there).&lt;/p&gt;
    &lt;p&gt;In all of these previous examples, the "shadows" have represented areas of high error. But in this last example, we'll see some hidden details that represent areas of low error - areas that are nearly solutions to the equation.&lt;/p&gt;
    &lt;p&gt;Consider the equation, \( y=4 sin(x)+ sin(2.7y) \), as both a conventional graph and a fuzzy graph:&lt;/p&gt;
    &lt;p&gt;Note the floating dots in the fuzzy graph version that are not there in the conventional/binary graph. These are like underwater islands - underwater mountains that are just below the surface of the water (or in this case, the \( error == 0 \) surface). These hidden islands represent area that are near-solutions to the equation (which are only visible in FuzzyGraph).&lt;/p&gt;
    &lt;p&gt;Their presense hints that we can tweak the equation slightly to cause them to burst above the surface of the water (which should also make them visible in conventional graphs).&lt;/p&gt;
    &lt;p&gt;So let's change the equation from: &lt;lb/&gt; \( y=4 sin(x)+ sin(2.7y) \) to: &lt;lb/&gt; \( y=4 sin(x)+ sin(2.8y) \)...&lt;/p&gt;
    &lt;p&gt;And as you can see, those previously-hidden islands are now visible in the conventional graph.&lt;/p&gt;
    &lt;p&gt;So Fuzzy/non-binary graphing can help us see features of the mathematical topography that are completely invisible with conventional/binary.&lt;/p&gt;
    &lt;p&gt;Date published: 2025-11-05&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://gods.art/articles/equation_shadows.html"/><published>2025-11-05T14:21:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45823186</id><title>Carice TC2 – A non-digital electric car</title><updated>2025-11-05T22:40:08.566139+00:00</updated><content>&lt;doc fingerprint="e68401540d9d7dbb"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;the 100% electric Carice TC2&lt;/head&gt;
    &lt;head rend="h1"&gt;a real retro head-turner&lt;/head&gt;
    &lt;p&gt;Reserve your spot now on next year’s production batch. Spaces limited.&lt;/p&gt;
    &lt;head rend="h1"&gt;the 100% electric carice TC2&lt;/head&gt;
    &lt;head rend="h2"&gt;a real retro head-turner&lt;/head&gt;
    &lt;p&gt;Reserve your spot now on next year’s production batch. Spaces limited.&lt;/p&gt;
    &lt;head rend="h6"&gt;The new experience&lt;/head&gt;
    &lt;head rend="h2"&gt;carice TC2&lt;/head&gt;
    &lt;p&gt;Meet the all-new electric Carice TC2: extremely lightweight, dynamic and elegant. When you get into your Carice, you escape and for a moment you forget about the everyday hassle. Whether you are the one driving the Carice or the passenger being driven around, it will be hard to hide that smile. With a TC2 you own something extraordinary, a piece of art.&lt;/p&gt;
    &lt;head rend="h6"&gt;The new experience&lt;/head&gt;
    &lt;head rend="h2"&gt;Carice TC2&lt;/head&gt;
    &lt;p&gt;We are busy with anything and everything, all the time. When you get into your Carice, you escape and for a moment you forget about the everyday hassle. You just relax and enjoy the drive. Whether you are the one driving the Carice or the passenger being driven around, it will be hard to hide that smile. The TC2 is a piece of art, just for you to enjoy.&lt;/p&gt;
    &lt;head rend="h6"&gt;why A Carice&lt;/head&gt;
    &lt;head rend="h2"&gt;the ultimate freedom&lt;/head&gt;
    &lt;p&gt;The result of years of hard work and dedication is the striking Carice TC2: it is the ultimate car to enjoy that sunny day in style and enjoy your drive and unwind.&lt;/p&gt;
    &lt;head rend="h5"&gt;all electric&lt;/head&gt;
    &lt;p&gt;The Carice TC2 is fully electric and has no emissions. This car is built to be fun for everybody – not just the driver. It is our mission to combine 21st-century technology with the look and feel of the cars of the past.&lt;/p&gt;
    &lt;head rend="h5"&gt;the essence&lt;/head&gt;
    &lt;p&gt;If you just take away unnecessary things for long enough, you will get back to the essence of driving. The Carice TC2 is elegant, stylish and at the same time uncomplicated. This delivers electric driving in its most pure and elementary form.&lt;/p&gt;
    &lt;head rend="h5"&gt;featherlight&lt;/head&gt;
    &lt;p&gt;Because the Carice TC2 is available from 590 kg including battery pack, it handles exceptionally dynamic yet comfortable. Moreover, power consumption is very low due to this weight. Therefore, the TC2 delivers a driving experience like no other. Very compact, yet big enough!&lt;/p&gt;
    &lt;head rend="h3"&gt;– time to forget about time –&lt;/head&gt;
    &lt;head rend="h6"&gt;Seen on&lt;/head&gt;
    &lt;head rend="h6"&gt;Seen on&lt;/head&gt;
    &lt;head rend="h6"&gt;About us&lt;/head&gt;
    &lt;head rend="h2"&gt;carice craftsmanship&lt;/head&gt;
    &lt;p&gt;Built and designed from the ground up in the Netherlands by people with a lifelong love of classic cars, the TC2 is made to resemble the playful and elegant looks of every car that you loved as a kid. This passion for cars translates into a high level of attention to detail and commitment to meet your needs. Carice is expanding their extensive history in automotive design and development every day. Find out about our latest events and achievements here.&lt;/p&gt;
    &lt;head rend="h6"&gt;gallery&lt;/head&gt;
    &lt;head rend="h2"&gt;modern classic&lt;/head&gt;
    &lt;p&gt;From the eye-catching dashboard, the classically styled steering wheel to the matching upholstery: everything in a Carice TC2 is made to stand out in all its simplicity. With a Carice you don’t just own another car: you get something extraordinary, a piece of art.&lt;/p&gt;
    &lt;head rend="h6"&gt;configure&lt;/head&gt;
    &lt;head rend="h2"&gt;configure your carice&lt;/head&gt;
    &lt;p&gt;To personalize your TC2, you can choose from a wide range of different colors for the paint, upholstery and rooftop. There is always a combination that fits your style.&lt;/p&gt;
    &lt;head rend="h2"&gt;specifications&lt;/head&gt;
    &lt;p&gt;There is no better way to experience the Carice TC2 than by seeing it and driving it. The elegant lines, attention to detail and phenomenal handling can’t be captured in a list, but some features can. You can find them below.&lt;/p&gt;
    &lt;head rend="h5"&gt;sizes and masses&lt;/head&gt;
    &lt;head rend="h5"&gt;battery&lt;/head&gt;
    &lt;head rend="h5"&gt;other&lt;/head&gt;
    &lt;p&gt;* Some specifications may differ, depending on the individual configuration of the TC2&lt;/p&gt;
    &lt;head rend="h6"&gt;contact&lt;/head&gt;
    &lt;head rend="h2"&gt;send us a message&lt;/head&gt;
    &lt;head rend="h6"&gt;FAQ&lt;/head&gt;
    &lt;head rend="h2"&gt;frequently asked questions&lt;/head&gt;
    &lt;head rend="h5"&gt;when can i order my Carice TC2?&lt;/head&gt;
    &lt;p&gt;You can already order your Carice. If you are interested you can contact us via the links on the website and the contact form to register your interest or book a test drive.&lt;/p&gt;
    &lt;head rend="h5"&gt;is the Carice TC2 a new car?&lt;/head&gt;
    &lt;p&gt;Yes! We have been designing and developing the TC2 ourselves from the ground up, and are now manufacturing the first series of TC2’s in the Netherlands. After more than 10 years of developing, testing and optimizing an extremely lightweight chassis around our electric drivetrain, you can now get a phenomenal handling and elegant TC2 yourself and enjoy driving in its most elementary form.&lt;/p&gt;
    &lt;head rend="h5"&gt;what is the price of a Carice TC2?&lt;/head&gt;
    &lt;p&gt;Prices for a TC2 start at €44.500 excluding taxes (€53.854 including 21% btw/Dutch tax).&lt;/p&gt;
    &lt;head rend="h5"&gt;in what countries can i drive the Carice?&lt;/head&gt;
    &lt;p&gt;The Carice TC2 complies with the European regulations and can therefore be driven in all EU countries and countries that adopt those regulations, like Switzerland, the United Kingdom, Monaco and Norway.&lt;/p&gt;
    &lt;head rend="h5"&gt;what is the estimated delivery time?&lt;/head&gt;
    &lt;p&gt;At the moment we are making the TC2 exclusively on order, as every car is configured differently. We can provide you with an estimation on the delivery time and you can reserve a spot on the production list by placing an order.&lt;/p&gt;
    &lt;head rend="h5"&gt;how can i configure my Carice?&lt;/head&gt;
    &lt;p&gt;There are a lot of options for you to choose between. Different colors, wheels, upholstery, soft top, accessories, battery pack, charging gear and so on. If you are interested in buying a Carice TC2, please get in touch.&lt;/p&gt;
    &lt;head rend="h5"&gt;what is the range of a Carice TC2&lt;/head&gt;
    &lt;p&gt;Depending on the configuration of your TC2, you can drive more than 300km, which can bring you to the most beautiful places.&lt;/p&gt;
    &lt;head rend="h5"&gt;i have decided: i want one soon! how to proceed?&lt;/head&gt;
    &lt;p&gt;The current production batch is sold out, but there are a few cars left for the next production run. If you are sure you want one, you can secure one of these cars by paying a deposit of 75% of the purchasing price. Please contact us for the details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.caricecars.com/"/><published>2025-11-05T14:25:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45823831</id><title>Ruby and Its Neighbors: Smalltalk</title><updated>2025-11-05T22:40:08.451195+00:00</updated><content>&lt;doc fingerprint="34329b3385e7083a"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Ruby And Its Neighbors: Smalltalk&lt;/head&gt;
    &lt;p&gt;Last time, we talked about Perl as an influence on Ruby, this time, we’ll talk about the other major influence on Ruby: Smalltalk.&lt;/p&gt;
    &lt;p&gt;Smalltalk had a different kind of influence, since almost nothing of Smalltalk’s syntax made into Ruby. But many of the details of how objects work are directly inspired by Smalltalk, including the idea that every piece of data is part of the object system.&lt;/p&gt;
    &lt;p&gt;Also unlike Perl, I spent a good couple of years working in Smalltalk, and it is one of my favorite languages that I’ll never likely use in anger again.&lt;/p&gt;
    &lt;head rend="h2"&gt;(A Personal) History of Smalltalk&lt;/head&gt;
    &lt;p&gt;Smalltalk originated in the same Xerox PARC team that invented the windowed interface, ethernet, and the laser printer, and who knows what else, they may have invented ice cream and rainbows.&lt;/p&gt;
    &lt;p&gt;There’s a whole story about what project Smalltalk was invented to be a part of, and a whole alternate history of computing and how people interact with computers that we are going to largely ignore. (If you are interested, start by searching for “Alan Kay Dynabook”.)&lt;/p&gt;
    &lt;p&gt;Smalltalk went through a few different iterations in the 1970s, but the version that we know today is a direct descendent of Smalltalk-80, which was the first version released to the wider world.&lt;/p&gt;
    &lt;p&gt;For most of the 80s and 90s, Smalltalk was something that doesn’t really exist today – a programming language and environment that companies paid money to use. Lots of money. The major player was ParcPlace, which was a spinoff of Xerox that provided Smalltalk tools. Their commercial product was originally called ObjectWorks, later changed to VisualWorks, and eventually sold off and presumably slowly losing customers after the late 90s.&lt;/p&gt;
    &lt;p&gt;Smalltalk was pretty big in the industry for a while. Most of the aviation industry ran on it in the 90s, the big payroll project that was the basis for Extreme Programming was a Smalltalk project, there was reasonably high demand for Smalltalk programmers through at least the mid 1990s. I taught an undergrad OO class in Smalltalk in 1997 and 1998 to students that wanted to be learning C++, and I remember telling them that Smalltalk programmers were paid more.&lt;/p&gt;
    &lt;p&gt;I first encountered Smalltalk as a grad student in about 1993, where Georgia Tech used ObjectWorks to teach Smalltalk and Object-Oriented programming (there’s a whole other sidebar about how Object-Oriented languages came to prominence in the 90s, and the arguments over that but again, another day). ObjectWorks was pricey, and there was also a lower-cost vendor called Digitalk, and eventually I also used a product called Smalltalk Agents, which has apparently totally vanished from the entire internet.&lt;/p&gt;
    &lt;p&gt;In 1995, a bunch of the original Xerox Smalltalk team was together at Apple, and they decided to release an open-source Smalltalk VM. What they did was very interesting. They wrote a very, very small kernel in very vanilla C, and then 95% of the environment was then built in Smalltalk on top of that. Oh, and even the vanilla C was written in Smalltalk, they wrote a Smalltalk to C compiler. They called their new Smalltalk “Squeak”, which made a lot more sense when they all moved en masse to Disney.&lt;/p&gt;
    &lt;p&gt;The fact that Squeak was largely written in itself made it fairly easy to port to new systems, and it was quickly available on just about anything with a microchip.&lt;/p&gt;
    &lt;p&gt;I’m pretty sure that I first saw Squeak at the OOPSLA conference in 1997. (Object-Oriented Programming, Systems, Languages &amp;amp; Applications, since you asked) At this conference I somehow got to do a team-building exercise with Adelde Goldberg from the original Xerox PARC team, which is not relevant to anything but seemed very cool at the time. I was already using Smalltalk in my projects, but Squeak was immediately interesting and my extended research team started doing cool stuff. Like, what I’m pretty sure was the first Wiki tool outside the original C2 Wiki, was written in Squeak. (Apparently at least one is still running).&lt;/p&gt;
    &lt;head rend="h2"&gt;Smalltalk’s Environment&lt;/head&gt;
    &lt;p&gt;It’s important to understand that Smalltalk’s development is a different evolutionary tree from nearly every currently popular programming language, in that Smalltalk is in no way, shape, or form influenced by Unix or C. Perl, Ruby, Python, JavaScript, Swift, Kotlin and on and on, all come from a universe where they expect to run Unix libraries, and where C syntax is normal. The Unix philosophy of “small pieces, loosely joined” is not a part of Smalltalk’s DNA at all.&lt;/p&gt;
    &lt;p&gt;Smalltalk is basically its own operating system, and the syntax is different from C-style languages in ways big and small. For example, the first element of an array is… 1. Which, when you think about how people count, actually makes sense.&lt;/p&gt;
    &lt;p&gt;It’s hard to separate Smalltalk the language from Smalltalk the environment, although I suppose technically you could have the language without the whole shebang (and I think there was a GNU Smalltalk that tried this), really the environment is part of the appeal.&lt;/p&gt;
    &lt;p&gt;Your main interfaces to the smalltalk system are a Workspace and a Browser. A workspace is analogous to REPL session, you can type in arbitrary Smalltalk code and have the system “do it” to execute the code, “print it” to execute the code and output the result. There are some other actions like “debug it” or “inspect it”, but that’s the basic idea. Unlike a Unix REPL, there’s no prompt, and you don’t automatically invoke code by hitting return, you have to select code and then invoke the menu item or the keyboard shortcut for the code you want to act on.&lt;/p&gt;
    &lt;p&gt;The Browser is where you write code. There a a few different versions in most Smalltalks, here’s the main one, this is from a modern Smalltalk called Cuis.&lt;/p&gt;
    &lt;p&gt;At the top, we have four window panes – left to right we have:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Categories – groups of classes that are related in some way. Cuis nicely puts each group in a pulldown list. Categories have no particular syntactic meaning, they are just there to make browsing easier.&lt;/item&gt;
      &lt;item&gt;Classes – one entry for each class in the currently selected category, at the bottom of this pane is a toggle for “class” vs. “instance” which determines what kinds of messages are shown in the next two panes.&lt;/item&gt;
      &lt;item&gt;Protocols – a protocol is a user-defined group of messages. Smalltalk internally uses “message” rather than “method” because of how Alan Kay thinks about objects. Again, protocols are for the programmer, not the system.&lt;/item&gt;
      &lt;item&gt;Messages – each messages in the currently selected protocol is listed.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The bottom pane is the code editor, and if a message is selected in the code pane, its code is displayed there.&lt;/p&gt;
    &lt;p&gt;You probably have questions:&lt;/p&gt;
    &lt;p&gt;Does this mean that you can see the source code for the entire Smalltalk system?&lt;/p&gt;
    &lt;p&gt;Yes, yes it does.&lt;/p&gt;
    &lt;p&gt;**Can you modify any code in the system? **&lt;/p&gt;
    &lt;p&gt;Yes, yes you can.&lt;/p&gt;
    &lt;p&gt;Even, like, deep system code?&lt;/p&gt;
    &lt;p&gt;Yes.&lt;/p&gt;
    &lt;p&gt;Isn’t that dangerous?&lt;/p&gt;
    &lt;p&gt;As a Ruby developer, you should know that it’s only as dangerous as the developers who use it.&lt;/p&gt;
    &lt;p&gt;How do you edit a message?&lt;/p&gt;
    &lt;p&gt;Just display the existing message in the browser, edit the message and select “save”. The Smalltalk system will parse the code, stop if there are syntax errors, but if not, the updated method will be saved to the system. A side effect is you can’t save code that isn’t syntactically parsable, even as a draft.&lt;/p&gt;
    &lt;p&gt;Okay, but how do you create a message?&lt;/p&gt;
    &lt;p&gt;The “real” way is to select a protocol but not a message, and Smalltalk will put a template in the edit window. Write your message in the editor and save it. Alternately, you can just change the name of a message in the edit window, and a new method with that name will be created, without deleting the old message.&lt;/p&gt;
    &lt;p&gt;And how do you create a class?&lt;/p&gt;
    &lt;p&gt;Similarly.&lt;/p&gt;
    &lt;p&gt;If you select a category and not a class, you’ll get this in the code editor pane:&lt;/p&gt;
    &lt;code&gt;Object subclass: #NameOfSubclass
	instanceVariableNames: ''
	classVariableNames: ''
	poolDictionaries: ''
	category: 'Kernel-Chronology'
&lt;/code&gt;
    &lt;p&gt;The thing to note is that this is not actually template, it’s actually code: a message, waiting for you to fill in the arguments, replacing &lt;code&gt;#NameOfSubclass&lt;/code&gt; and adding the instance variables and so on. You don’t save this, you “do it”, just like if you were in a workspace. The message call is evaluated, and Smalltalk creates a new class.&lt;/p&gt;
    &lt;p&gt;But wait, if all the code is in the image and isn’t in text files, how do people work together and share code?&lt;/p&gt;
    &lt;p&gt;Don’t worry about it.&lt;/p&gt;
    &lt;p&gt;Seriously, though, worry about it.&lt;/p&gt;
    &lt;p&gt;This has always been a problem. Smalltalk allows you to share “change sets”, effectively the code differences between one point and another. Classically, one person would export their change set, and other team members would import it. Different Smalltalks have built up more sophisticated tools over time.&lt;/p&gt;
    &lt;head rend="h2"&gt;Smalltalk’s Syntax&lt;/head&gt;
    &lt;p&gt;Smalltalk’s syntax is very simple, relative to Ruby and Perl.&lt;/p&gt;
    &lt;p&gt;Wait a sec, I literally wrote this for a chapter in a book about Smalltalk literally 25 years ago, here’s a slight paraphrase:&lt;/p&gt;
    &lt;p&gt;Every line of Smalltalk is evaluated the same way.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;Every variable is an object. There are no basic types that are not objects.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Every expression is a message being passed to an object, there is basically no expression syntax that is not a message.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;All messages return a value. (The return value is specified by&lt;/p&gt;&lt;code&gt;^&lt;/code&gt;, if the method does not specify a return value, it implicitly returns&lt;code&gt;self&lt;/code&gt;, the instance that received the message.)&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are three kinds of messages:&lt;/p&gt;
        &lt;list rend="ul"&gt;
          &lt;item&gt;Unary messages like &lt;code&gt;3 negated&lt;/code&gt;&lt;/item&gt;
          &lt;item&gt;Binary messages like &lt;code&gt;a + b&lt;/code&gt;, these actually are messages you can define, there is a small set of them, and they are special cases in the parser.&lt;/item&gt;
          &lt;item&gt;Keyword messages such as &lt;code&gt;anArray at: 3 put: 7&lt;/code&gt;. This syntax got used by ObjectiveC and later Swift, so you may be familiar with it. It’s&lt;code&gt;receiver &amp;lt;messagepart&amp;gt;: &amp;lt;argument&amp;gt;&lt;/code&gt;where you can have multiple message parts. If you are referring to the message, typically you just say the message parts, so this message would be called&lt;code&gt;at:put:&lt;/code&gt;&lt;/item&gt;
        &lt;/list&gt;
      &lt;/item&gt;
      &lt;item&gt;Unary messages like &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Smalltalk does not have operator precedence. All code is evaluated strictly from left to right. Unary messages first, binary messages second, keyword messages last. Parenthesis can be used to force order of operations or to make things clearer.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;&lt;p&gt;The assignment operator is&lt;/p&gt;&lt;code&gt;:=&lt;/code&gt;(Smalltalk uses&lt;code&gt;=&lt;/code&gt;for boolean equality), the right hand side is evaluated and the value is assigned to the result of the left hand side.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;And that’s basically it, with a couple of ways to create literals like strings, arrays, dictionaries, local variables, and blocks.&lt;/p&gt;
    &lt;p&gt;So, for 10 points and control of the board, what does this do?&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := 3 squared + 4 squared sqrt&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;The unary messages are evaluated first:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := 9 + 16 sqrt&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;There’s still a unary message&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := 9 + 4&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Now we can do the binary message:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse = 13&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Oops.&lt;/p&gt;
    &lt;p&gt;To get what you actually want, you need parentheses:&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;hypotenuse := (3 squared + 4 squared) sqrt&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;Smalltalk does not have special syntax for loops, all loop behavior is defined by methods on &lt;code&gt;Array&lt;/code&gt; and the like, very similar to Ruby’s &lt;code&gt;Enumerable&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Smalltalk does not have special syntax to create messages or classes. Message creation is managed by the editor (which internally calls a message that adds the new code), class creation is just another method – in Squeak, that method is &lt;code&gt;Object#subclass:instanceVariableNames:classVariableNames:poolDictionaries:category:&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Smalltalk does not have special syntax for boolean logic, all logic behavior is defined by the classes &lt;code&gt;True&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt;. Ruby sort of does this, but Ruby does have &lt;code&gt;if&lt;/code&gt; as special syntax. Smalltalk does not, you’d write a Smalltalk conditional as just another message:&lt;/p&gt;
    &lt;code&gt;(x &amp;gt; 10) ifTrue: [ x squared ] ifFalse: [ x sqrt ]
&lt;/code&gt;
    &lt;p&gt;The square brackets are blocks, and behave very similar to Ruby blocks, except that you can treat them as just normal variables and normal arguments. You can even, as in this case, have multiple arguments that take blocks.&lt;/p&gt;
    &lt;p&gt;The implementation if the method &lt;code&gt;ifTrue:ifFalse&lt;/code&gt; is simple. For the &lt;code&gt;True&lt;/code&gt; class, it just takes the true block and executes it by passing it the message &lt;code&gt;value&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;ifTrue: trueAlternativeBlock ifFalse: falseAlternativeBlock
	^trueAlternativeBlock value
&lt;/code&gt;
    &lt;p&gt;And for the false class, the exact opposite:&lt;/p&gt;
    &lt;code&gt;ifTrue: trueAlternativeBlock ifFalse: falseAlternativeBlock
	^falseAlternativeBlock value
&lt;/code&gt;
    &lt;p&gt;Smalltalk doesn’t have a &lt;code&gt;case&lt;/code&gt; or &lt;code&gt;switch&lt;/code&gt; statement, typically if you want behavior like that you’d define a dictionary of keys to blocks or you would use the object system and polymorphism and double dispatch.&lt;/p&gt;
    &lt;head rend="h2"&gt;Smalltalk’s Object Model&lt;/head&gt;
    &lt;p&gt;There’s a lot about Smalltalk’s object model that sound familiar to a Ruby developer:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;There’s a base class called &lt;code&gt;Object&lt;/code&gt;that everything inherits from.&lt;/item&gt;
      &lt;item&gt;Instance variables are private. Getters and setters default to having the same name as the instance variable.&lt;/item&gt;
      &lt;item&gt;Method lookup happens at the point of the method call.&lt;/item&gt;
      &lt;item&gt;Classes are instances of the class &lt;code&gt;Class&lt;/code&gt;(sort of).&lt;/item&gt;
      &lt;item&gt;There’s a thing called a “Metaclass”&lt;/item&gt;
      &lt;item&gt;There’s a method that’s the method of last resort – in Ruby, it’s &lt;code&gt;method_missing&lt;/code&gt;, but in Smalltalk it’s called&lt;code&gt;doesNotUnderstand&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;There are a couple of differences as well&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smalltalk’s meta classes are structured differently, I explained this once and I’m not sure I ever want to explain it again.&lt;/item&gt;
      &lt;item&gt;Smalltalk doesn’t have multiple inheritance or mixins or modules or anything like that. Although there have been some attempts to add these features, the traditional Smalltalk way to do this is through delegation.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But overall, Smalltalk and Ruby are similar enough that a huge amount of Kent Beck’s Smalltalk Best Practice Patterns is applicable to Ruby as long as you translate the syntax.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Happened?&lt;/head&gt;
    &lt;p&gt;Unlike Perl, I actually did use Smallalk to build a few real applications that had real users. I miss it a lot.&lt;/p&gt;
    &lt;p&gt;I find that when I try to explain Smalltalk to people, it’s easy to explain the syntax and the object model. What’s hard to explain is how it is to work in a Smalltalk environment.&lt;/p&gt;
    &lt;p&gt;You’ve likely used powerful coding editors and terminals. Smalltalk is just different. You are in the running environment.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Tests start instantly, and in general run very fast. There’s a dedicated test runner window. Some smalltalk integrate tests with the regular browser, so you can see test status from the code browsers.&lt;/item&gt;
      &lt;item&gt;Debugging is amazing, you can investigate the state of any object in the system, you can change that state, you can easily execute arbitrary code. You can have a test halt on exception, update the code and re-run from the point failure. It’s hard to describe how fluid it is, especially since I’m no longer expert enough to do it fluently.&lt;/item&gt;
      &lt;item&gt;While the editor doesn’t have all the niceties of the IDE’s you are used to, it’s very powerful in its own way. If you save code with a message name that does not appear in the image at all, Smalltalk will typically ask you if you want to define it right there. A lot of the things we ask a Language Server to do, Smalltalk just kind of does, because the image has access to everything.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But the all-encompassing nature of the environment was also Smalltalk’s downfall. As more and more of the general computing environment became Unix and the “small pieces loosely joined” philosophy, Smalltalk got harder and harder to integrate. Smalltalk isn’t a scripting language, it was late to develop connectivity to external databases, its model of team interaction is fundamentally different from Unix source control. The image-based system has some drawbacks – you do get amazing access to the system, but it can be hard to tell where your code ends and the system begins. Code could depend on the state of the image in ways that were hard to replicate in deploys.&lt;/p&gt;
    &lt;head rend="h2"&gt;What Did Ruby Take From Smalltalk?&lt;/head&gt;
    &lt;p&gt;Smalltalk’s legacy in Ruby is primarily the object model – the idea that everything is an object and everything is manageable via method calls, and that message calls are evaluated at the point of call, as late as possible. Ruby takes that idea and translates it into a syntax that is more familiar to programmers used to C/Perl/Java.&lt;/p&gt;
    &lt;p&gt;I’m not sure this is exactly on point as far as Smalltalk’s influence on Ruby, but my Ruby style has always been very aggressive about creating new classes and objects. I’m quite confident that a reason for that style is that I came from Smalltalk first and not Java, Smalltalk style is much more amenable to small classes.&lt;/p&gt;
    &lt;p&gt;On my first largish Smalltalk project, users were simulating a chemical plant’s pipe system by placing tiles with pipes in them, and I frequently needed to do logic based on relative directions. I clearly remember creating a &lt;code&gt;Direction&lt;/code&gt; class with basically four live instances, &lt;code&gt;up&lt;/code&gt;, &lt;code&gt;down&lt;/code&gt;, &lt;code&gt;left&lt;/code&gt;, &lt;code&gt;right&lt;/code&gt;, and just enough logic inside to say that &lt;code&gt;up.turn_left&lt;/code&gt; equals &lt;code&gt;left&lt;/code&gt;, but &lt;code&gt;down.turn_left&lt;/code&gt; equals &lt;code&gt;right&lt;/code&gt;. It was useful enough that I remember how much fun it was to build it even  now, nearly thirty years later.&lt;/p&gt;
    &lt;p&gt;Of all the other programming languages I’ve used, Ruby is the one that most clearly encourages that style of coding.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/"/><published>2025-11-05T15:24:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45824658</id><title>Norway reviews cybersecurity after remote-access feature found in Chinese buses</title><updated>2025-11-05T22:40:06.640364+00:00</updated><content>&lt;doc fingerprint="fcf890b619964575"&gt;
  &lt;main&gt;
    &lt;p&gt;Norway has launched a cybersecurity review after public transport operator Ruter discovered that electric buses supplied by Chinese manufacturer Yutong contained hidden SIM cards enabling potential remote access.&lt;/p&gt;
    &lt;p&gt;According to Ruter, internal tests at a secure facility found Romanian SIM cards inside the buses, theoretically allowing the Chinese supplier to shut down vehicles or interfere via software updates. The transport operator stressed there is no evidence of misuse but said the discovery moves concerns “from suspicion to concrete knowledge”.&lt;/p&gt;
    &lt;p&gt;Ruter has removed the SIM cards and is strengthening procurement rules, internal firewalls, and cloud-security requirements to ensure full local control over transport operations.&lt;/p&gt;
    &lt;p&gt;Norway’s Minister of Transport Jon-Ivar Nygård told national broadcaster NRK that the government is assessing supplier risks from countries outside Norway’s security alliances, noting the need to protect critical infrastructure.&lt;/p&gt;
    &lt;p&gt;Around 1,300 electric buses operate in Norway, including approximately 850 units from Yutong, with 300 running in Oslo and Akershus. Ruter said the likelihood of attempted interference remains low, but the situation underscores the growing cybersecurity challenges linked to foreign technology suppliers.&lt;/p&gt;
    &lt;p&gt;The case comes as Chinese electric buses are increasingly adopted across global markets, including Southeast Asia, raising wider questions about digital security and strategic dependencies in public transport systems.&lt;/p&gt;
    &lt;p&gt;“It’s unlikely these buses would ever be misused,” Ruter CEO Bernt Reitan Jenssen said, “but we must take the risk seriously.”&lt;/p&gt;
    &lt;p&gt;Source: Carscoops&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://scandasia.com/norway-reviews-cybersecurity-after-hidden-remote-access-feature-found-in-chinese-buses/"/><published>2025-11-05T16:18:01+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45824864</id><title>Why aren't smart people happier?</title><updated>2025-11-05T22:40:06.061790+00:00</updated><content>&lt;doc fingerprint="2b2a121caf818e99"&gt;
  &lt;main&gt;
    &lt;p&gt;Adam Mastroianni is the author of Experimental History. He studies how people perceive and misperceive their social worlds. His work has been featured in Science, Nature, and The Tonight Show with Jimmy Fallon. He has a PhD in psychology from Harvard and a certificate of completion from 137 different escape rooms. He’s originally from Monroeville, Ohio (pop. 1,400) and currently lives in New York City.&lt;/p&gt;
    &lt;p&gt;Here’s a definition of intelligence that lots of psychologists can get behind:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Intelligence is a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather, it reflects a broader and deeper capability for comprehending our surroundings-“catching on,” “making sense” of things, or “figuring out” what to do […] Intelligence, so defined, can be measured, and intelligence tests measure it well.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Intelligence sounds pretty great. Who doesn’t want to “catch on” and “make sense”? Hell, “figuring out” what to do is pretty much all of life!&lt;/p&gt;
    &lt;p&gt;Naturally, people with more of this mental horsepower must live happier lives. When they encounter a problem, they should use their superior problem-solving ability to solve it. Smarter people should do a better job making plans and getting what they want, and they should learn more from their mistakes and subsequently make fewer of them. All of this should add up to a life that makes smart people go “this life rules!”&lt;/p&gt;
    &lt;p&gt;So smarter people are happier, right?&lt;/p&gt;
    &lt;p&gt;Well, this meta-analysis says no. Another says maybe a teeny tiny bit. This large, nationally-representative study from the UK finds that people who score the lowest on an intelligence test are a little less happy than everyone else, but that’s pretty much it.&lt;/p&gt;
    &lt;p&gt;I also pulled data from the General Social Survey, which includes (a) a short vocabulary test that seems to correlate reasonably well with longer intelligence tests (you can try it here), and (b) a simple measure of happiness: “Taken all together, how would you say things are these days—would you say that you are very happy, pretty happy, or not too happy?” Across 50 years of data and 30,346 people, the folks who scored higher on the vocab test were a tiny bit less happy (r = -.06, p &amp;lt; .001).&lt;/p&gt;
    &lt;head rend="h1"&gt;WHAT’S GOING ON HERE?&lt;/head&gt;
    &lt;p&gt;Maybe our tests are bad. The psychological study of intelligence has a long, bleak history of racism and prejudice against poor people (“three generations of imbeciles are enough”), so we should be skeptical coming in. Psychologists have been trying to construct bias-free tests for a long time, but it’s hard. Plus, people score higher on IQ tests when you pay them for performance, so what looks like a test of intelligence may in part be a test of how hard you’re willing to try.&lt;/p&gt;
    &lt;p&gt;But even if intelligence tests only measure something like “ability to succeed in an unfair society” or “willingness to try hard,” it only deepens the mystery. Shouldn’t those people end up with happier lives, however unfair that may be?&lt;/p&gt;
    &lt;p&gt;And the tests likely do tap something more than just privilege and effort. There’s plenty of skepticism toward intelligence tests in psychology, but even the biggest skeptics agree that IQ can predict things like how well you do in school and what kind of job you get, even accounting for all the criticisms. So why doesn’t it also predict living a life that you like?&lt;/p&gt;
    &lt;head rend="h1"&gt;SPEARING SPEARMAN&lt;/head&gt;
    &lt;p&gt;I think there’s one guy to blame for this big mystery, and his name is Charles Spearman.&lt;/p&gt;
    &lt;p&gt;Way back in 1904, Spearman noticed something weird: the same kids who did well in one subject in school tended to do well in other subjects, too. The correlations were never perfect, of course, but they were pretty darn high, even across subjects that seemed pretty different from each other, like French and math. How come?&lt;/p&gt;
    &lt;p&gt;Spearman figured there must be some general mental ability that humans use to solve all kinds of problems. He later wrote:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;This continued tendency to success of the same person throughout all variations of both form and subject-matter—that is to say throughout all conscious aspects of cognition whatever—appears only explicable by some factor lying deeper than the phenomena of consciousness.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Helpfully, he also drew us a picture:&lt;/p&gt;
    &lt;p&gt;This is, I think, exactly where everything went wrong with the study of intelligence for the next 119 years. It’s not that Spearman’s results were inaccurate—in fact, they’ve been replicated over and over. At this point, pretty much every paper on intelligence has to start out like this review from 2006:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In the study of intelligence, one empirical phenomenon is well established: Test scores on cognitive tasks show a positive manifold, that is, they are invariably positively intercorrelated, albeit to varying degrees. This implies that people who score well on one cognitive test are likely to score well on other cognitive tests. The positive manifold is a robust phenomenon.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Spearman’s stats were sound, but his interpretation was wrong. He did not, as he claimed, observe a “continued tendency to success throughout all variations of both form and subject-matter,” nor has anybody else. It merely looks as if we’ve varied all the forms and the subject-matters because we have the wrong theory about what makes them different.&lt;/p&gt;
    &lt;p&gt;We think tests of math, vocabulary, French, music, etc. are all different because some are about words and others are about numbers and others are about sounds. But psychology, like all sciences, is all about discovering the differences between seemingly similar things, and discovering the similarities between seemingly different things. If psychologists ever had to march into battle, a good candidate for our crests may be the famous Müller-Lyer illusion, the two lines that look like they’re different lengths but aren’t:&lt;/p&gt;
    &lt;p&gt;Just like those lines, I think all of our various tests of intelligence aren’t as different as they seem. They’re all full of problems that have a few important things in common:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;There are stable relationships between the variables.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There’s no disagreement about whether the problems are problems, or whether they’ve been solved.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There have clear boundaries; there is a finite amount of relevant information and possible actions.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The problems are repeatable. Although the details may change, the process for solving the problems does not.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I think a good name for problems like these is well-defined. Well-defined problems can be very difficult, but they aren’t mystical. You can write down instructions for solving them. And you can put them on a test. In fact, standardized tests items must be well-defined problems, because they require indisputable answers. Matching a word to its synonym, finding the area of a trapezoid, putting pictures in the correct order—all common tasks on IQ tests—are well-defined problems.&lt;/p&gt;
    &lt;p&gt;Spearman was right that people differ in their ability to solve well-defined problems. But he was wrong that well-defined problems are the only kind of problems. “Why can’t I find someone to spend my life with?” “Should I be a dentist or a dancer?” and “How do I get my child to stop crying?” are all important but poorly defined problems. “How can we all get along?” is not a multiple-choice question. Neither is “What do I do when my parents get old?” And getting better at rotating shapes or remembering state capitals is not going to help you solve them.&lt;/p&gt;
    &lt;p&gt;We all share some blame with Spearman, of course, because everybody talks about smarts as if they’re one thing. Google “smartest people in the world” and most of the results will be physicists, mathematicians, computer scientists, and chess masters. These are all difficult problems, but they are well-defined, and that makes it easy to rank people. The best chess player in the world is the one who can beat everybody else. The best mathematician is the one who can solve the problems that nobody else could solve. That makes it seem like the best chess players and mathematicians are not just the smartest in their fields, but the smartest in the whole world.&lt;/p&gt;
    &lt;head rend="h1"&gt;THE POORLY DEFINED PROBLEM OF BEING ALIVE&lt;/head&gt;
    &lt;p&gt;There is, unfortunately no good word for “skill at solving poorly defined problems.” Insight, creativity, agency, self-knowledge—they’re all part of it, but not all of it. Wisdom comes the closest, but it suggests a certain fustiness and grandeur, and poorly defined problems aren’t just dramatic questions like “how do you live a good life”; they’re also everyday questions like “how do you host a good party” and “how do you figure out what to do today.”&lt;/p&gt;
    &lt;p&gt;One way to spot people who are good at solving poorly defined problems is to look for people who feel good about their lives; “how do I live a life I like” is a humdinger of a poorly defined problem. The rules aren’t stable: what makes you happy may make me miserable. The boundaries aren’t clear: literally anything I do could make me more happy or less happy. The problems are not repeatable: what made me happy when I was 21 may not make me happy when I’m 31. Nobody else can be completely sure whether I’m happy or not, and sometimes I’m not even sure. In fact, some people might claim that I’m not really happy, no matter what I say, unless I accept Jesus into my heart or reach nirvana or fall in love—if I think I’m happy before all that, I’m simply mistaken about what happiness is!&lt;/p&gt;
    &lt;p&gt;This is why the people who score well on intelligence tests and win lots of chess games are no happier than the people who flunk the tests and lose at chess: well-defined and poorly defined problems require completely different problem-solving skills. Life ain’t chess! Nobody agrees on the rules, the pieces do whatever they want, and the board covers the whole globe, as well as the inside of your head and possibly several metaphysical planes as well.&lt;/p&gt;
    &lt;head rend="h1"&gt;IF YOU’RE SO SMART, WHY ARE YOU SO DUMB?&lt;/head&gt;
    &lt;p&gt;Here’s another way of looking at it.&lt;/p&gt;
    &lt;p&gt;Say you want to test people’s math ability. You design a test, administer it to a bunch of people, do all your psychometrics, etc. You’re feeling pretty good about your math test. And then you find that some of the people who ace your test later say things like “two plus two is 19” and “88 is the biggest number.” You’d feel pretty embarrassed about your math test because it’s clearly not measuring mathematical ability, if it’s measuring anything at all.&lt;/p&gt;
    &lt;p&gt;This is exactly the situation we’re in with tests that claim to measure people’s “reasoning” and “problem-solving ability.” Christopher Langan, a guy who can score eye-popping numbers on IQ tests, believes that 9/11 was an inside job meant specifically to distract the public from his theories, and he claims that banks won’t give him a loan because he’s white. John Sununu supposedly has IQ of 176, but he still had to resign from being George H.W. Bush’s chief of staff because he flew to his dentist appointments using military jets. Bobby Fischer is one of the greatest chess players of all time, but he also claimed that Hitler was a good dude, the Holocaust didn’t happen, and “Jews murder Christian children for their blood and they’re doing it even today.” Then there’s the ever-lengthening list of professors at elite universities who have been disciplined or dismissed for doing things like sexually harassing colleagues and students or completely making up data or hanging out with a known pedophile. These are supposed to be some of the smartest people in the world, endowed with exceptional problem-solving abilities. And yet they’re still unable to solve basic but poorly defined problems like “maintain a basic grip on reality” and “be a good person” and “don’t make any life-altering blunders.”&lt;/p&gt;
    &lt;head rend="h1"&gt;GAZE UPON OUR WORKS AND DESPAIR&lt;/head&gt;
    &lt;p&gt;And here’s another way of looking at it.&lt;/p&gt;
    &lt;p&gt;Over the last generation, we have solved tons of well-defined problems. We eradicated smallpox and polio. We landed on the moon. We built better cars, refrigerators, and televisions. We even got ~15 IQ points smarter! And how did our incredible success make us feel?&lt;/p&gt;
    &lt;p&gt;Well:&lt;/p&gt;
    &lt;p&gt;All that progress didn’t make us a bit happier. I think there’s an important lesson here: if solving a bunch of well-defined problems did not make our predecessors happier, it probably won’t make us happier, either. The barrier between you and everlasting bliss is probably not the size of your television, nor your ability to solve Raven’s Progressive Matrices.&lt;/p&gt;
    &lt;p&gt;(To be clear, I still think it’s good we did all this. Polio sucks and going to the moon is awesome.)&lt;/p&gt;
    &lt;p&gt;I wish we knew more about how to make that bright green line go up, but we just haven’t yet defined the problem of “living a happy life”. We know that if you’re starving, lonely, or in pain, you’ll probably get happier if you get food, friends, and relief. After that, the returns diminish very quickly. You could read all the positive psychology you want, take the online version of The Science of Wellbeing (”Yale’s Most Popular Course Ever!”), read my post on hacking the hedonic treadmill, meditate, exercise, and keep a gratitude journal—and after all that, maybe you’ll be a smidge happier. Whatever else you think will put a big, permanent smile on your face, you’re probably wrong.&lt;/p&gt;
    &lt;p&gt;So if you’re really looking for a transformative change in your happiness, you might be better off reading something ancient. The great thinkers of the distant past seemed obsessed with figuring out how to live good lives: Socrates, Plato, Aristotle, Epicurus, Buddha, Confucius, Jesus, Marcus Aurelius, St. Augustine, even up through Thoreau and Vivekananda. But at some point, this kind of stuff apparently fell out of fashion.&lt;/p&gt;
    &lt;p&gt;And hey, maybe that’s because there’s just no more progress to make on the poorly defined problem of “how do we live.” But most well-defined problems were once defined poorly. For example, “how do we land on the moon” was a hopelessly poorly defined problem for most of human history. It only makes sense if you know that the moon is a big rock you can land on and not, say, a god floating in the sky. We slowly put some definitions around that problem, and then one day we sent an actual dude to the moon and he walked around and was like “I’m on the moon now.” If we can do that, maybe we can also figure out how to live good lives. It certainly seems worth it to keep trying.&lt;/p&gt;
    &lt;head rend="h1"&gt;BUT AREN’T THERE MULTIPLE INTELLIGENCES?&lt;/head&gt;
    &lt;p&gt;I’m not the first to propose that “general” intelligence is more than one thing. Pretty much as soon as Spearman started claiming that intelligence is mainly one thing, other people started saying that intelligence is actually many things. (That’s science, baby!) Today, the most popular version of this theory claims there’s something like eight intelligences, ranging from “visual-spatial” to “bodily-kinesthetic.” I’m sympathetic to this take because it tries to account for all the different weird and wonderful things that humans can do. But it’s got two big problems.&lt;/p&gt;
    &lt;p&gt;Problem #1: People very rarely try to find any evidence for it. And when they do, they find that the people who score high on one of the many intelligences tend to score high on the others, too, just as Spearman would’ve predicted a hundred years ago.&lt;/p&gt;
    &lt;p&gt;Problem #2: When you label every human activity as its own intelligence, you give up any hope of understanding anything about the structure of problems in the world or how people solve them. We can make up whatever categories we want; they aren’t given by God. The only reason to use some categories and not others is that some categories are useful and others aren’t.&lt;/p&gt;
    &lt;p&gt;For instance, we could have created a periodic table that organized the elements alphabetically, or by color, or by how good they taste. Instead we organize them by atomic number, not because it’s their “true” order, but because it’s useful. It helps us realize things like, “Hey, we’ve got a number 62 and a number 64—I wonder if there’s a number 63 out there. We should go looking for it.”&lt;/p&gt;
    &lt;p&gt;So we should pick the way of categorizing intelligence that gives us the most bang for our buck. “Intelligence is many things” can’t explain why people perform similarly across supposedly different tests, and “intelligence is mostly one thing” can’t answer a basic question like “why smart people aren’t happier?” But we can handle both of those challenges when we split intelligence into skill at solving well-defined and poorly defined problems.&lt;/p&gt;
    &lt;p&gt;And that’s not all we can do.&lt;/p&gt;
    &lt;head rend="h1"&gt;OH BOY HERE COMES THE PART ABOUT AI&lt;/head&gt;
    &lt;p&gt;People think of AI as a big glob of problem-solving ability. If you make the glob bigger, it can solve harder problems. That’s certainly been true so far: gigantic globs of AI can now drive cars, defeat our greatest chess players, and predict how proteins will fold.&lt;/p&gt;
    &lt;p&gt;All this has happened very quickly, which may make it seem like we’re careening toward a “general” artificial intelligence that can do all the things humans can. But if you split problems into well-defined and poorly defined, you’ll notice that all of AI’s progress has been on defined problems. That’s what artificial intelligence does. In order to get AI to solve a problem, we have to give it data to learn from, and picking that data requires defining the problem.&lt;/p&gt;
    &lt;p&gt;That doesn’t mean the problems AI has solved so far are stupid or trivial. They’re really important and interesting! They’re just all well-defined problems. And we should expect that pattern to continue: for any well-defined problem, AI will eventually outperform humans. But for poorly defined problems, AI is hopeless. To solve those, we need humans running around doing weird human stuff.&lt;/p&gt;
    &lt;p&gt;“What about GPT-3—it can write movie scripts! And what about DALLE-2—it can paint pictures!” These AIs perform a clever trick: they make it seem like they’re solving poorly defined problems when, under the hood, they’re really solving well-defined problems. GPT-3 doesn’t actually write movie scripts; it predicts what words should come next. DALLE-2 doesn’t actually paint pictures; it matches words to images. These problems aren’t easy to solve—that’s why you need such a big glob of AI. But they obey clear, unchanging rules, they have bright boundaries, and you know precisely when you’ve solved them. They are well-defined problems. (This is also why AI art isn’t art).&lt;/p&gt;
    &lt;p&gt;If you booted up a super-smart AI in ancient Greece, fed it all human knowledge, and asked it how to land on the moon, it would respond “You can’t land on the moon. The moon is a god floating in the sky.” How would you get it to realize the moon is actually a big rock? That’s a great, poorly defined problem, and I don’t expect AI to solve it anytime soon.&lt;/p&gt;
    &lt;head rend="h1"&gt;SHOUTOUT TO MY GRANDMA&lt;/head&gt;
    &lt;p&gt;Here’s one last advantage of dividing intelligence into well-defined problem-solving and poorly defined problem-solving: it reminds us to give some respect where respect is due.&lt;/p&gt;
    &lt;p&gt;We’ve got no problem fawning over people who are good at solving well-defined problems. They get to be called “professor” and “doctor.” We pay them lots of money to teach us stuff. They get to join exclusive clubs like Mensa and the Prometheus Society. (By the way, Mensa’s page explaining IQ doesn’t mention anything about the dark history of using intelligence tests to hurt people, and you might expect a bunch of smarty-pantses to, you know, use their brains to discuss things with a bit more nuance. But what do I know, I’m just a big dummy.)&lt;/p&gt;
    &lt;p&gt;People who are good at solving poorly defined problems don’t get the same kind of kudos. They don’t get any special titles or clubs. There is no test they can take that will spit out a big, honking number that will make everybody respect them.&lt;/p&gt;
    &lt;p&gt;And that’s a shame. My grandma does not know how to use the “input” button on her TV’s remote control, but she does know how to raise a family full of good people who love each other, how to carry on through a tragedy, and how to make the perfect pumpkin pie. We sometimes condescendingly refer to this kind of wisdom as “folksy” or “homespun,” as if answering multiple-choice questions is real intelligence, and living a good, full life is just some down-home, gee-whiz, cutesy thing that little old ladies do.&lt;/p&gt;
    &lt;p&gt;Excluding this kind of intelligence from our definitions doesn’t just hurt our grandmas—it hurts us too. If you don’t value the ability to solve poorly defined problems, you’ll never get more of it. You won’t seek out people who have that ability and try to learn from them, nor will you listen to them when they have something important to say. You’ll spend your whole life trying to solve problems with cleverness when what you really need is wisdom. And you’ll wonder why it never really seems to work. All of your optimizing, your straining to achieve and advance, your ruthless crusade to eliminate all of the well-defined problems from your life—it doesn’t actually seem make your life any better.&lt;/p&gt;
    &lt;p&gt;If you’re stuck trying to solve poorly defined problems with your slick, well-defined problem-solving skills and you’re lucky enough to have a grandma like mine still on this Earth, my god, go see her. Shut up and listen to her for a while. And once you’ve learned something, maybe ask her if she needs help with her TV.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.theseedsofscience.pub/p/why-arent-smart-people-happier"/><published>2025-11-05T16:32:43+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45825965</id><title>ChatGPT terms disallow its use in providing legal and medical advice to others</title><updated>2025-11-05T22:40:05.531042+00:00</updated><content>&lt;doc fingerprint="ec8cff953dd634b6"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;ChatGPT users can’t use service for tailored legal and medical advice, OpenAI says&lt;/head&gt;
    &lt;p&gt;Updated:&lt;/p&gt;
    &lt;p&gt;Published:&lt;/p&gt;
    &lt;head rend="h3"&gt;Here Are The 60 Best Advent Calendars For 2025 You Can Get In Canada (So Far)&lt;/head&gt;
    &lt;head rend="h3"&gt;I’ve been Using This Canadian Shampoo And Conditioner For Over A Month, And It’s Totally Changed My Scalp And Hair Health&lt;/head&gt;
    &lt;head rend="h3"&gt;20 Foolproof Gifts To Order If You Want To Get Your Holiday Shopping Done Early&lt;/head&gt;
    &lt;head rend="h3"&gt;I Tried It: A Laundry Basket So Smart It Solved Our Biggest Household Argument&lt;/head&gt;
    &lt;head rend="h3"&gt;20 Things From Amazon Canada That CTV Shopping Trends Readers Loved Ordering In October&lt;/head&gt;
    &lt;head rend="h3"&gt;How To Choose The Best Vacuum Sealer For You (And A Few Of Our Favourite Models For 2025)&lt;/head&gt;
    &lt;head rend="h3"&gt;13 Budget-Friendly Beauty Products That Are Dupes Of More Expensive Items&lt;/head&gt;
    &lt;head rend="h3"&gt;12 Products For Damaged Hair That’ll Help Bring Your Fried Tresses Back To Life&lt;/head&gt;
    &lt;head rend="h3"&gt;15 Of The Best Korean Beauty Skincare Finds For Fall 2025&lt;/head&gt;
    &lt;head rend="h3"&gt;27 Of The Absolute Best Last-Minute Beauty Discounts To Take Advantage Of Before The Amazon Prime Big Deal Days Sale Ends&lt;/head&gt;
    &lt;p&gt;The Shopping Trends team is independent of the journalists at CTV News. We may earn a commission when you use our links to shop. Read about us.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.ctvnews.ca/sci-tech/article/openai-updates-policies-so-chatgpt-wont-provide-medical-or-legal-advice/"/><published>2025-11-05T18:11:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45826266</id><title>Dillo, a multi-platform graphical web browser</title><updated>2025-11-05T22:40:04.937166+00:00</updated><content>&lt;doc fingerprint="9650cf58848088e4"&gt;
  &lt;main&gt;
    &lt;p&gt;Dillo is a multi-platform graphical web browser, known for its speed and small footprint, that is developed with a focus on personal security and privacy. It is built with the FLTK 1.3 GUI toolkit.&lt;/p&gt;
    &lt;p&gt;Screenshot of the Dillo Website rendered in Dillo:&lt;/p&gt;
    &lt;p&gt;To install Dillo follow the installation guide.&lt;/p&gt;
    &lt;p&gt;This repository contains mostly the original code of Dillo with some minor patches. Additional patches or pull requests are welcome.&lt;/p&gt;
    &lt;p&gt;See also other related forks: dillo-plus, dilloNG, D+ browser and Mobilized Dillo.&lt;/p&gt;
    &lt;p&gt;Warning&lt;/p&gt;
    &lt;p&gt;As of December 2023, the host &lt;code&gt;dillo.org&lt;/code&gt; is no longer under control
of Dillo developers. A copy of the old website is archived in
GitHub Pages and the Wayback Machine (May 2022).&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/dillo-browser/dillo"/><published>2025-11-05T18:40:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45826348</id><title>The state of SIMD in Rust in 2025</title><updated>2025-11-05T22:40:04.773000+00:00</updated><content>&lt;doc fingerprint="3f28d332981d8b8c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;The state of SIMD in Rust in 2025&lt;/head&gt;
    &lt;p&gt;If you’re already familiar with SIMD, the table below is all you need.&lt;/p&gt;
    &lt;p&gt;And if you’re not, you will understand the table by the end of this article!&lt;/p&gt;
    &lt;head rend="h2"&gt;What’s SIMD? Why SIMD?&lt;/head&gt;
    &lt;p&gt;Hardware that does arithmetic is cheap, so any CPU made this century has plenty of it. But you still only have one instruction decoding block and it is hard to get it to go fast, so the arithmetic hardware is vastly underutilized.&lt;/p&gt;
    &lt;p&gt;To get around the instruction decoding bottleneck, you can feed the CPU a batch of numbers all at once for a single arithmetic operation like addition. Hence the name: “single instruction, multiple data,” or SIMD for short.&lt;/p&gt;
    &lt;p&gt;Instead of adding two numbers together, you can add two batches or “vectors” of numbers and it takes about the same amount of time.&lt;/p&gt;
    &lt;p&gt;On recent x86 chips these batches can be up to 512 bits in size, so in theory you can get an 8x speedup for math on &lt;code&gt;u64&lt;/code&gt; or a 64x speedup on &lt;code&gt;u8&lt;/code&gt;!&lt;/p&gt;
    &lt;head rend="h2"&gt;Instruction sets&lt;/head&gt;
    &lt;p&gt;Historically, SIMD instructions were added after the CPU architecture was already designed, so SIMD is an extension with its own marketing name on each architecture.&lt;/p&gt;
    &lt;p&gt;ARM calls theirs “NEON”, and all 64-bit ARM CPUs have it.&lt;/p&gt;
    &lt;p&gt;WebAssembly doesn’t have a marketing department, so they just call theirs “WebAssembly 128-bit packed SIMD extension”.&lt;/p&gt;
    &lt;p&gt;64-bit x86 shipped with one called “SSE2” which has basic instructions for 128-bit vectors, but later they added a whole menagerie of extensions on top of that, with SSE 4.2 adding more operations, AVX and AVX2 adding 256-bit vectors and AVX-512 adding 512-bit vectors.&lt;/p&gt;
    &lt;p&gt;The word “later” in the above paragraph creates a problem.&lt;/p&gt;
    &lt;head rend="h3"&gt;Does this CPU have that instruction?&lt;/head&gt;
    &lt;p&gt;If you’re running a program on an x86 CPU, it’s not a given that the CPU has any particular SIMD extension. So by default the compiler isn’t allowed to use instructions beyond SSE2 because that won’t work on all x86 CPUs.&lt;/p&gt;
    &lt;p&gt;There are two ways around this problem.&lt;/p&gt;
    &lt;p&gt;If you work for a company that only ever runs their binaries on their own servers or on a public cloud, you can just assert that they’re all recent enough to at least have AVX2 that was introduced over 10 years ago, and have the program crash or misbehave if it ever runs on anything without AVX2:&lt;/p&gt;
    &lt;code&gt;RUSTFLAGS='-C target-cpu=x86–64-v3' cargo build --release&lt;/code&gt;
    &lt;p&gt;However, if you are distributing the binaries for other people to run, that’s not really an option.&lt;/p&gt;
    &lt;p&gt;Instead you can do something called function multiversioning: compile the same function multiple times for different SIMD extensions, and when the program actually runs, check what features the CPU supports and select the appropriate version based on that.&lt;/p&gt;
    &lt;p&gt;Fortunately, this problem only exists on x86.&lt;/p&gt;
    &lt;p&gt;ARM made its NEON mandatory in all 64-bit CPUs and then didn’t bother expanding the width beyond 128 bits. (Technically SVE exists, but in 2025 it is still mostly on paper, and Rust support for it is still in progress).&lt;/p&gt;
    &lt;p&gt;WebAssembly makes you compile two different binaries, one with SIMD and one without, and use JavaScript to check if the browser supports SIMD.&lt;/p&gt;
    &lt;head rend="h2"&gt;Solution space&lt;/head&gt;
    &lt;p&gt;There are four approaches to SIMD in Rust, in ascending order of effort:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Automatic vectorization&lt;/item&gt;
      &lt;item&gt;Fancy iterators&lt;/item&gt;
      &lt;item&gt;Portable SIMD abstractions&lt;/item&gt;
      &lt;item&gt;Raw intrinsics&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Automatic vectorization&lt;/head&gt;
    &lt;p&gt;The easiest approach to SIMD is letting the compiler do it for you.&lt;/p&gt;
    &lt;p&gt;It works surprisingly well, as long as you structure your code in a way that is amenable to vectorization. This article covers it:&lt;/p&gt;
    &lt;p&gt;You can check if it’s working with cargo-show-asm or godbolt.org, but your benchmarks are the ultimate judge of the results.&lt;/p&gt;
    &lt;p&gt;Sadly there is a limit on the complexity of the code that the compiler will vectorize, and it may change between compiler versions. If something vectorizes today that doesn’t necessarily mean it still will in a year from now.&lt;/p&gt;
    &lt;p&gt;The other drawback of this method is that the optimizer won’t even touch anything involving floats (&lt;code&gt;f32&lt;/code&gt; and &lt;code&gt;f64&lt;/code&gt; types). It’s not permitted to change any observable outputs of the program, and reordering float operations may alter the result due to precision loss. (There is a way to tell the compiler not to worry about precision loss, but it’s currently nightly-only).&lt;/p&gt;
    &lt;p&gt;So right now, if you need to process floats, autovectorization is a no-go unless you can use nightly builds of the Rust compiler.&lt;/p&gt;
    &lt;p&gt;(Floats are cursed even without SIMD. Something as simple as summing an array of them in a usable way turns out to be really hard).&lt;/p&gt;
    &lt;p&gt;There is no built-in way to multiversion functions, but the multiversion crate works great with autovectorization.&lt;/p&gt;
    &lt;head rend="h2"&gt;Fancy iterators&lt;/head&gt;
    &lt;p&gt;Just like rayon lets you run your iterators in parallel by swapping &lt;code&gt;.iter()&lt;/code&gt; with &lt;code&gt;.par_iter()&lt;/code&gt;, there have been attempts to do the same for SIMD. After all, what is SIMD but another kind of parallelism?&lt;/p&gt;
    &lt;p&gt;This is the approach that the faster crate takes. That crate has been abandoned for years, and it doesn’t look like this approach has panned out.&lt;/p&gt;
    &lt;head rend="h2"&gt;Portable SIMD abstractions&lt;/head&gt;
    &lt;p&gt;The idea is to let you write your algorithm by explicitly operating on chunks of data, something like &lt;code&gt;[f32; 8]&lt;/code&gt; but wrapped in a custom type, and then provide custom implementations of operations like &lt;code&gt;+&lt;/code&gt; that compile down into SIMD instructions.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;std::simd&lt;/code&gt; is exactly that. It supports all instruction sets LLVM supports, so its platform support is unparalleled. It pairs well with the multiversion crate. Sadly it’s nightly-only and will remain such for the foreseeable future, so it’s unusable in most situations.&lt;/p&gt;
    &lt;p&gt;The wide crate is a mature, established option. It supports NEON, WASM and all the x86 instruction sets. But it doesn’t support multiversioning at all, save for very exotic and limited approaches like cargo-multivers.&lt;/p&gt;
    &lt;p&gt;The pulp crate is a great design with built-in multiversioning, and is quite mature and complete. It powers faer, so its performance is clearly proven. The drawbacks are that it doesn’t support WASM, and that on x86 it only supports targeting AVX2 and AVX-512 but not the older extensions. But AVX2 was introduced in 2012 and in the Steam hardware survey 95% systems have it, so that might not be a big deal.&lt;/p&gt;
    &lt;p&gt;The macerator crate is a fork of pulp with vastly expanded instruction set support. It supports all x86 extensions, WASM, NEON, and even the LoongArch SIMD extensions. It’s used only by burn-ndarray, and even there it’s an optional dependency. It sounds great on paper, but it’s oddly obscure and therefore unproven. I’d probably write code using pulp, then replace it with macerator and see if everything still works and runs as fast as it should.&lt;/p&gt;
    &lt;p&gt;The fearless_simd crate is largely a copy of pulp’s design made for use in vello. It’s far less mature than pulp, but it’s under active development. As of this writing it supports NEON, WASM and SSE4.2, but not the newer x86 extensions. Seems too immature just yet, but something to keep an eye on.&lt;/p&gt;
    &lt;p&gt;simdeez is a rather old crate that supports all instruction sets except AVX-512 and comes with built-in multiversioning. What gives me pause is that despite existing for many years, it’s still barely used. Everyone else who needed SIMD built their own instead of using it. And its README says:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Currently things are well fleshed out for i32, i64, f32, and f64 types.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So I guess the other types aren’t complete?&lt;/p&gt;
    &lt;p&gt;TL;DR: use &lt;code&gt;std::simd&lt;/code&gt; if you don’t mind nightly, &lt;code&gt;wide&lt;/code&gt; if you don’t need multiversioning, and otherwise &lt;code&gt;pulp&lt;/code&gt; or &lt;code&gt;macerator&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If it’s not 2025 when you’re reading this, check out &lt;code&gt;fearless_simd&lt;/code&gt;, because &lt;code&gt;std::simd&lt;/code&gt; is still in nightly in your glorious future, isn’t it?&lt;/p&gt;
    &lt;head rend="h2"&gt;Raw intrinsics&lt;/head&gt;
    &lt;p&gt;If you want to get really close to the metal, there are always the raw intrinsics, just one step removed from the processor instructions.&lt;/p&gt;
    &lt;p&gt;The problem looming over any use of raw intrinsics is that you have to manually write them for every platform and instruction set you’re targeting. Whereas &lt;code&gt;std::simd&lt;/code&gt; or &lt;code&gt;wide&lt;/code&gt; let you write your logic once and compile it down to the assembly automatically, with intrinsics you have to write a separate implementation for every single platform and instruction set (SSE, AVX, NEON…) you care to support. That’s a lot of code!&lt;/p&gt;
    &lt;p&gt;It’s really not helped by the fact that they are all named something like &lt;code&gt;_mm256_srli_epi32&lt;/code&gt; and your code ends up as a long list of calls to these arcanely named functions. And wrappers that help readability introduce their own problems, such as clashes with multiversioning or unsafe code or arcane macros.&lt;/p&gt;
    &lt;p&gt;You also have to build your own multiversioning. Or rather, you have to manually dispatch to the dedicated implementation you have manually written for each instruction set. &lt;code&gt;std::is_x86_feature_detected!&lt;/code&gt; macro takes care of the feature detection, but it is somewhat slow. In some cases it is beneficial to detect available features exactly once and then cache the results, but you have to implement that manually too.&lt;/p&gt;
    &lt;p&gt;On the bright side, this year writing intrinsics got markedly less awful. Most of them are no longer &lt;code&gt;unsafe&lt;/code&gt; to call in Rust 1.86 and later, and the safe_unaligned_simd crate provides safe wrappers for the rest.&lt;/p&gt;
    &lt;p&gt;So at least this approach is no longer &lt;code&gt;unsafe&lt;/code&gt; on top of all the other problems it has!&lt;/p&gt;
    &lt;head rend="h2"&gt;Which one is right for you?&lt;/head&gt;
    &lt;p&gt;The right tool for the job ultimately depends on the use case.&lt;/p&gt;
    &lt;p&gt;Want zero dependencies and little up-front hassle? Autovectorization. Porting existing C code or targeting very specific hardware? Intrinsics. Anything else? Portable SIMD abstraction.&lt;/p&gt;
    &lt;p&gt;And now that you made it this far, you can understand the table at the top of the article, which will help guide your decision!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d"/><published>2025-11-05T18:45:57+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45826500</id><title>Internet Archive's legal fights are over, but its founder mourns what was lost</title><updated>2025-11-05T22:40:04.326894+00:00</updated><content>&lt;doc fingerprint="ca919bd5fba6537b"&gt;
  &lt;main&gt;
    &lt;p&gt;Last month, the Internet Archive’s Wayback Machine archived its trillionth webpage, and the nonprofit invited its more than 1,200 library partners and 800,000 daily users to join a celebration of the moment. To honor “three decades of safeguarding the world’s online heritage,” the city of San Francisco declared October 22 to be “Internet Archive Day.” The Archive was also recently designated a federal depository library by Sen. Alex Padilla (D-Calif.), who proclaimed the organization a “perfect fit” to expand “access to federal government publications amid an increasingly digital landscape.”&lt;/p&gt;
    &lt;p&gt;The Internet Archive might sound like a thriving organization, but it only recently emerged from years of bruising copyright battles that threatened to bankrupt the beloved library project. In the end, the fight led to more than 500,000 books being removed from the Archive’s “Open Library.”&lt;/p&gt;
    &lt;p&gt;“We survived,” Internet Archive founder Brewster Kahle told Ars. “But it wiped out the Library.”&lt;/p&gt;
    &lt;p&gt;An Internet Archive spokesperson confirmed to Ars that the archive currently faces no major lawsuits and no active threats to its collections. Kahle thinks “the world became stupider” when the Open Library was gutted—but he’s moving forward with new ideas.&lt;/p&gt;
    &lt;head rend="h2"&gt;History of the Internet Archive&lt;/head&gt;
    &lt;p&gt;Kahle has been striving since 1996 to transform the Internet Archive into a digital Library of Alexandria—but “with a better fire protection plan,” joked Kyle Courtney, a copyright lawyer and librarian who leads the nonprofit eBook Study Group, which helps states update laws to protect libraries.&lt;/p&gt;
    &lt;p&gt;When the Wayback Machine was born in 2001 as a way to take snapshots of the web, Kahle told The New York Times that building free archives was “worth it.” He was also excited that the Wayback Machine had drawn renewed media attention to libraries.&lt;/p&gt;
    &lt;p&gt;At the time, law professor Lawrence Lessig predicted that the Internet Archive would face copyright battles, but he also believed that the Wayback Machine would change the way the public understood copyright fights.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/tech-policy/2025/11/the-internet-archive-survived-major-copyright-losses-whats-next/"/><published>2025-11-05T18:59:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45826995</id><title>New gel restores dental enamel and could revolutionise tooth repair</title><updated>2025-11-05T22:39:13.315533+00:00</updated><content/><link href="https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair"/><published>2025-11-05T19:44:49+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45827042</id><title>3D Geological Models in Minecraft</title><updated>2025-11-05T22:39:11.918497+00:00</updated><content>&lt;doc fingerprint="5c13435e25d6930d"&gt;
  &lt;main&gt;
    &lt;p&gt;Download our 3D geology models as Minecraft worlds and learn how geology can influence the landscape.&lt;/p&gt;
    &lt;p&gt;We have built five worlds to allow you to explore underground and learn about the geology. Four of these worlds show small sites around the UK and use real geological data to show what the geology looks like under the surface. The fifth world shows a simplified geology of the whole of mainland Great Britain. These models show how geology can influence landscapes and land use, and can help teach geology to a younger audience.&lt;/p&gt;
    &lt;p&gt;At the end of section, there is also a user-generated volcano world created by three students from Nottingham.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Getting started: requirements and installation&lt;/item&gt;
      &lt;item&gt;How did we make the BGS Minecraft worlds?&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Getting started: requirements and installation&lt;/head&gt;
    &lt;p&gt;To start you off on your Minecraft journey we have built a spawn point, which includes some information about the blocks and which real world geology they represent. You can use this to learn more about the geology of the area by spawning back to the platform at any point.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;a licenced copy of Minecraft&lt;/item&gt;
      &lt;item&gt;50 MB free disk space per local area world&lt;/item&gt;
      &lt;item&gt;6 GB for the Great Britain world&lt;/item&gt;
      &lt;item&gt;more than 4 GB of RAM&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Download the 3D model as a zip file archive (between 1 and 65 MB).&lt;/item&gt;
      &lt;item&gt;Unzip the archive to a temporary location.&lt;/item&gt;
      &lt;item&gt;Start Minecraft.&lt;/item&gt;
      &lt;item&gt;On the home screen, click ‘Options’.&lt;/item&gt;
      &lt;item&gt;Click ‘Resource Packs’.&lt;/item&gt;
      &lt;item&gt;Click ‘Open resource pack folder’. This will open a new window showing the contents of your Minecraft ‘Resource Packs’ folder.&lt;/item&gt;
      &lt;item&gt;Navigate to the folder (called .minecraft on Windows).&lt;/item&gt;
      &lt;item&gt;Open the ‘saves’ folder.&lt;/item&gt;
      &lt;item&gt;Move the unzipped archive to this ‘saves’ folder.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;How did we make the BGS Minecraft worlds?&lt;/head&gt;
    &lt;p&gt;We decided to use glass blocks that were coloured by traditional geology map colours. This allows you to dig into the model and ‘fall’ between each geological layer. You can then explore under the ground in Minecraft because the glass blocks allow you to see through them. When experimenting with these 3D Minecraft worlds we discovered that, by using glass blocks, the player could see the true extent of the geology straight away.&lt;/p&gt;
    &lt;head rend="h3"&gt;What data did we use?&lt;/head&gt;
    &lt;p&gt;To build each of these models we used a number of different datasets, including:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;3D geology — geological surfaces taken from BGS 3D models&lt;/item&gt;
      &lt;item&gt;elevation — taken from the surface of the 3D geology models&lt;/item&gt;
      &lt;item&gt;topography — OS VectorMap District&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;The worlds&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Glasgow Minecraft world&lt;/item&gt;
      &lt;item&gt;Ingleborough Minecraft world&lt;/item&gt;
      &lt;item&gt;York Minecraft world&lt;/item&gt;
      &lt;item&gt;West Thurrock Minecraft world&lt;/item&gt;
      &lt;item&gt;Great Britain Minecraft world&lt;/item&gt;
      &lt;item&gt;Volcano Minecraft world&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Glasgow Minecraft world&lt;/head&gt;
    &lt;p&gt;The geology in this world is in two parts. The first has the shallower rocks and soils directly underneath Glasgow, called ‘superficial geology’. We have also included artificial ground in this world.&lt;/p&gt;
    &lt;p&gt;The second, lower part, is called the ‘bedrock geology’ (this is the hard rock, not what Minecraft calls Bedrock) and these rocks date from the Carboniferous Period, including the Upper Coal Measures.&lt;/p&gt;
    &lt;p&gt;When you first land in the world, there will be signposts with information to get you started. Once you’ve got your bearings you can fly around the 3D world by double tapping then holding the space bar, which will cause you to fly up into the air. This world includes the topography (features on the ground such as roads and buildings) that will help you to find your way around the world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Geology key&lt;/head&gt;
    &lt;p&gt;The geological units for each world have been grouped together in order to accommodate the limited Minecraft glass block palette of 16 colours. Where possible, we have tried to emulate the BGS geological unit colours.&lt;/p&gt;
    &lt;p&gt;This Glasgow Minecraft world is based on the BGS central Glasgow 3D geological model. The geological model gives engineers and construction companies a subsurface view of the geology underneath Glasgow to help save time and money during construction projects. It also provides insight into the potential for geothermal heat from the water found in flooded mine workings — see UK Geoenergy Observatories Glasgow.&lt;/p&gt;
    &lt;p&gt;Covering about 100 km2, the area shows the superficial deposits of the central Glasgow area, including glaciated material from successive ice sheets. The model was built within BGS’s GOCAD® and GSI3D software, using a digital elevation model of 20 m cell resolution, and is based on datasets held by BGS, such as digital maps and boreholes.&lt;/p&gt;
    &lt;p&gt;The superficial deposits in the Minecraft world are mostly glacial tills, reflecting the advances and retreats of ice sheets. The tills often rest directly on bedrock geology and comprise a mixture of clay, sand and silt with pebbles, cobbles and boulders.&lt;/p&gt;
    &lt;p&gt;Other types of superficial deposits in the area are related to several marine inundations (raising and lowering of the sea level) during and since the last glaciation, the development of river terraces, the deposition of estuary sediments, and local lakes, some infilled partly by peat.&lt;/p&gt;
    &lt;p&gt;The bedrock geology in the Minecraft world dates back to the Carboniferous Period (485–541 million years ago). The majority of the rocks were deposited in an environment such as a river delta or a shallow sea and consist of sandstone, coal and limestone. The rocks were identified using borehole material and descriptions from borehole drill wells and using things found in the rock, such as fossils and minerals, to give the rocks an age.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ingleborough Minecraft world&lt;/head&gt;
    &lt;p&gt;This Minecraft world uses the classic geological study area of Ingleborough, Yorkshire Dales, as an introduction to 3D geological models. This world is modelled at 1:250 000 scale and covers an area of 18 km2. You can fly over the landscape at the surface or dig below ground to expose some of the limestone landscape beneath Ingleborough.&lt;/p&gt;
    &lt;p&gt;When you first land in the world there will be signposts with information to get you started. Once you’ve got your bearings, you can fly around the 3D world by double tapping then holding the space bar, which will cause you to fly up into the air. This world includes the topography (map features on the ground such as roads and buildings) that will help you to find your way around the world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Geology key&lt;/head&gt;
    &lt;p&gt;The geological units for this world have been grouped together in order to accommodate the limited Minecraft glass block palette of 16 colours. Where possible, we have tried to emulate the BGS geological unit colour.&lt;/p&gt;
    &lt;p&gt;The geological model was built by BGS in 2010 using GSI3D and is calculated using a digital elevation model (DEM) with a 5 m grid spacing, it extends to about 100 m OD.&lt;/p&gt;
    &lt;p&gt;The Minecraft world contains three areas of worked ground, one in the Great Scar Limestone Group in the north and two in the Ingleton Group in the main valley. The world contains three superficial rock units; alluvium from the rivers Doe, Kingsdale and Ribble, peat on the flanks of Ingleborough and till in the south-west and north-east.&lt;/p&gt;
    &lt;p&gt;The till has been modelled in areas of drumlin development to accentuate the landforms. Till is present elsewhere in the area, but is not displayed in the world. The till in this region was laid down by the Devensian ice sheet, which covered the whole region.&lt;/p&gt;
    &lt;p&gt;The bedrock geology is made up of several layers. The youngest late Carboniferous deposits of the Pennine Lower Coal Measures Formation comprise interbedded sandstones, siltstones and mudstones with several coal seams. The early Carboniferous limestones of the Great Scar Limestone and Yoredale groups contain classic karst features such as Gaping Gill. The limestone is up to 500 m thick.&lt;/p&gt;
    &lt;p&gt;In the south-west, the Dent Formation, of Ordovician age (444–485 million years ago) and comprised of shallow marine sediments, limestone and pyroclastic rocks is encountered south of the North Craven Fault. Most of the area is unconformably underlain by the Ordovician Ingleton Group of sandstones, siltstones and conglomerates, which is over 300 m thick.&lt;/p&gt;
    &lt;head rend="h2"&gt;Download Ingleborough world&lt;/head&gt;
    &lt;head rend="h2"&gt;York Minecraft world&lt;/head&gt;
    &lt;p&gt;This Minecraft world covers 50 km2 of terrain to the north and east of York including in the north the village of Haxby. The area lies within the low lying Vale of York where deposits from the last glaciation (Devensian) often rest directly on the Triassic bedrock.&lt;/p&gt;
    &lt;p&gt;When you first land in the world there will be signposts with information to get you started. Once you’ve got your bearings you can fly around the 3D world by double tapping then holding the space bar, which will cause you to fly up into the air. This world includes the topography (map features on the ground, such as roads and buildings) which will help you to find your way around the world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Geology key&lt;/head&gt;
    &lt;p&gt;The geological units for each world have been grouped together in order to accommodate the limited Minecraft glass block palette of 16 colours. Where possible we have tried to emulate the BGS geological unit colours.&lt;/p&gt;
    &lt;p&gt;The York model was built by BGS in 2005 as a result of a geological survey and model building programme for the Selby and York areas. The rocks were identified using borehole material and descriptions from borehole drill wells and using things found in the rock, such as fossils and minerals, to give the rocks an age.&lt;/p&gt;
    &lt;p&gt;The model extends to about 50 m depth and has been calculated using a digital elevation model (DEM). At high vertical exaggerations, despite processing, some residual effects, mainly due to local woodland, can still be seen in the top model surface.&lt;/p&gt;
    &lt;p&gt;The world shows the large flat areas of alluvium of the River Ouse in the extreme south-west and its tributary the Foss.&lt;/p&gt;
    &lt;p&gt;The Vale of York Till forms the core of the York Moraine, which is a low ridge near the southern end of the world. During the glaciation, meltwater became ponded at several times in the Vale of York due to ice blocking drainage via the Humber into the North Sea Basin and beyond.&lt;/p&gt;
    &lt;p&gt;The bedrock in the area is Triassic Sherwood Sandstone, which is a significant aquifer in the Vale of York.&lt;/p&gt;
    &lt;head rend="h2"&gt;Download York world&lt;/head&gt;
    &lt;head rend="h2"&gt;West Thurrock Minecraft world&lt;/head&gt;
    &lt;p&gt;The West Thurrock world covers about 10 km2 along the eastern flank of the M25 motorway on the north bank of the River Thames. It depicts an extensively modified and developed landscape with several extensive areas of artificial ground, including the building of the Lakeside shopping complex within an old chalk quarry.&lt;/p&gt;
    &lt;p&gt;When you first land in the world there will be signposts with information to get you started. Once you’ve got your bearings you can fly around the 3D world by double tapping then holding the space bar, which will cause you to fly up into the air. This world includes the topography (map features on the ground, such as roads and buildings) that will help you to find your way around the world.&lt;/p&gt;
    &lt;head rend="h3"&gt;Geology key&lt;/head&gt;
    &lt;p&gt;The geological units for each world have been grouped together in order to accommodate the limited Minecraft glass block palette of 16 colours. Where possible, we have tried to emulate the BGS geological unit colours.&lt;/p&gt;
    &lt;p&gt;The original geological model was built in 2009 in GSI3D. It shows a developed landscape with several extensive areas of artificial ground, including the building of the Lakeside shopping complex within an old chalk quarry.&lt;/p&gt;
    &lt;p&gt;The southern part of the world occupies the River Thames’s floodplain. Here, interbedded alluvial silts, clays and peats overlie gravel deposits. Together, these sediments are up to 15 m in thickness. Older river terrace deposits comprising sands and gravels fringe the alluvium and are preserved as erosional remnants farther north.&lt;/p&gt;
    &lt;p&gt;The bedrock geology is dominated by chalk, which underlies the whole area with the world extending to a depth of about 150 m. In the northern portion of the world, younger bedrock units are, in ascending order, the Thanet Sand, Lambeth, Harwich and London Clay formations.&lt;/p&gt;
    &lt;head rend="h2"&gt;Download West Thurrock world&lt;/head&gt;
    &lt;head rend="h2"&gt;Great Britain world&lt;/head&gt;
    &lt;p&gt;BGS has also developed a Minecraft world devoted to the geology of the whole of mainland Great Britain. This world shows an interpretation of the Ordnance Survey open map data on the surface and the rough position of the real geology beneath.&lt;/p&gt;
    &lt;p&gt;You will start at the BGS office in Cardiff. Look around you for signposts with information to get you started. Once you’ve got your bearings you can fly around the landscape by double tapping and holding the spacebar.&lt;/p&gt;
    &lt;p&gt;This Minecraft world uses the BGS Soil Parent Material Map to describe the geology across the whole of mainland Great Britain. The country was divided into smaller chunks (100 × 100km grid squares) so that Minecraft could cope with the whole area.&lt;/p&gt;
    &lt;p&gt;For each 100 × 100km square we:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;loaded the height of the land surface from an elevation of Great Britain, using a modified and scaled version of NEXTMap Britain data&lt;/item&gt;
      &lt;item&gt;loaded the geology from the Soil Parent Material Map&lt;/item&gt;
      &lt;item&gt;loaded the OS VectorMap® District raster files&lt;/item&gt;
      &lt;item&gt;for each chunk we used the height data to add blocks repeatedly up to the specified height and using the real world geology for that location&lt;/item&gt;
      &lt;item&gt;for the topmost block, we decided which material best matched the OS VectorMap® District data&lt;/item&gt;
      &lt;item&gt;finally, we compiled groups of 32×32 chunks into regions, and then compiled the whole lot into one zip file&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The Minecraft GB geology world represents the geology at the surface, but that geology does not change as you dig down into the world, as BGS doesn’t have 3D data covering the whole of the UK. It’s important to know that this is why the GB geology world is different to the larger scale models described above, which do have 3D geology included.&lt;/p&gt;
    &lt;p&gt;To do this, we have used BGS’s Soil Parent Material dataset. A parent material is a soil science name for a weathered rock or deposit from, and within which, a soil has formed. In the UK, parent materials provide the basic foundations and building blocks of the soil, influencing their texture, structure, drainage and chemistry. By using the parent material dataset we can get a general understanding of the types of geology to be found across Great Britain.&lt;/p&gt;
    &lt;p&gt;Using the methodology developed by the Ordnance Survey, we took the data from the OS VectorMap® District raster to decide the material of each block.&lt;/p&gt;
    &lt;head rend="h2"&gt;Volcano Minecraft world&lt;/head&gt;
    &lt;p&gt;This Minecraft world was created by three students from Nottingham. Created during summer 2020 during the COVID-19 lockdown, this volcano model was produced as a result of a short collaboration between BGS geospatial data staff and students from a local secondary school.&lt;/p&gt;
    &lt;p&gt;The volcano world includes a magma chamber, moving ‘redstone’ magma and side vents. At the surface, the world shows a farming village that benefits from the fertile volcanic soil that surrounds many volcanoes.&lt;/p&gt;
    &lt;p&gt;When you first land in the world there will be signposts with information to get you started. Once you’ve got your bearings you can fly around the 3D world by double tapping then holding the space bar, which will cause you to fly up into the air.&lt;/p&gt;
    &lt;head rend="h2"&gt;Download volcano world&lt;/head&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Minecraft is ©2009 – 2015 Mojang AB.&lt;/item&gt;
      &lt;item&gt;Models built using Safe Software’s FME 2015.&lt;/item&gt;
      &lt;item&gt;Contains Ordnance Survey data © Crown copyright and database right 2015.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;You may also be interested in&lt;/head&gt;
    &lt;head rend="h4"&gt;Discovering Geology&lt;/head&gt;
    &lt;p&gt;Discovering Geology introduces a range of geoscience topics to school-age students and learners of all ages.&lt;/p&gt;
    &lt;head rend="h4"&gt;Maps and resources&lt;/head&gt;
    &lt;p&gt;Download and print free educational resources.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.bgs.ac.uk/discovering-geology/maps-and-resources/maps/minecraft-3d-geological-models/"/><published>2025-11-05T19:49:27+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45827190</id><title>Solarpunk is already happening in Africa</title><updated>2025-11-05T22:39:11.785089+00:00</updated><content/><link href="https://climatedrift.substack.com/p/why-solarpunk-is-already-happening"/><published>2025-11-05T20:00:40+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45827661</id><title>A Lost IBM PC/at Model? Analyzing a Newfound Old Bios</title><updated>2025-11-05T22:39:11.118309+00:00</updated><content>&lt;doc fingerprint="a7009d1325a483dc"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;A Lost IBM PC/AT Model? Analyzing a Newfound Old BIOS&lt;/head&gt;
    &lt;p&gt;Something intriguing turned up recently over at the Vintage Computer Federation Forums. Member GearTechWolf occasionally rescues and dumps random ROM chips that show up on eBay, and makes the contents available so they aren't lost to the ages. One of his hauls turned up two pairs of EPROMs labeled "IBM" in plain dot-&lt;/p&gt;
    &lt;p&gt;They came with no further identification, and no hints about their origins, or what machines they may have come from. And just to establish that proper setting of suspense and mystery, neither pair could be content-&lt;/p&gt;
    &lt;p&gt;Much poking and prying commenced. I didn't delve very deeply into the '25/05/90' odd/&lt;/p&gt;
    &lt;p&gt;The more intriguing one for me was the '1981, 1985' duo (yellow labels in the photo). A cursory look in a hex viewer revealed the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;EPROM 6448246 has the even addresses, 6448238 the odd addresses.&lt;/item&gt;
      &lt;item&gt;The internal part numbers are 6480442 and 6480441, respectively.&lt;/item&gt;
      &lt;item&gt;The BIOS date stamp in the standard location (F000:FFF5) is 03/08/85.&lt;/item&gt;
      &lt;item&gt;At F000:330A, there's yet another date stamp - 02/14/85.&lt;/item&gt;
      &lt;item&gt;The model byte (in the second-to-last position) is FCh.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In 1985, the &lt;code&gt;FCh&lt;/code&gt; model byte could only mean the 5170 (PC/&lt;/p&gt;
    &lt;p&gt;My first thought was that this may have come from one of those more shadowy members of the 5170 family: perhaps the AT/370, the 3270 AT/G(X), or the rack-mounted 7532 Industrial AT. But known examples of those carry the same firmware sets as the plain old 5170, so their BIOS extensions (if any) came in the shape of extra adapter ROMs. Whatever this thing was - some other 5170-type machine, a prototype, or even just a custom patch - it seemed I'd have to inquire within for any further clues.&lt;/p&gt;
    &lt;head rend="h3"&gt;The PC/AT BIOS: Known Versions&lt;/head&gt;
    &lt;p&gt;This was a good time to brush up on the three official revisions of the AT BIOS: how to tell them apart, and how they correspond to hardware options. The following table was compiled mostly from the pages at Minus Zero Degrees (IBM 5170 BIOS Revisions) and PC DOS Retro (IBM PC BIOS version history), and from the info in Ralf Brown's Interrupt List. Where the sources weren't in total agreement, I went with what seemed to conform with IBM's published source code listings.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;PC/AT BIOS revision&lt;/cell&gt;
        &lt;cell role="head"&gt;Rev. 1&lt;/cell&gt;
        &lt;cell role="head"&gt;Rev. 2&lt;/cell&gt;
        &lt;cell role="head"&gt;Rev. 3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Date (US format)&lt;/cell&gt;
        &lt;cell&gt;01/10/84&lt;/cell&gt;
        &lt;cell&gt;06/10/85&lt;/cell&gt;
        &lt;cell&gt;11/15/85&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;P/N (internal/&lt;/cell&gt;
        &lt;cell&gt;U27, even: 6181028&lt;p&gt;U47, odd: 6181029&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;U27, even: 6480090&lt;p&gt;U47, odd: 6480091&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;U27, even: 62X0820&lt;p&gt;U47, odd: 62X0821&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;P/N (EPROM label)&lt;/cell&gt;
        &lt;cell&gt;U17/U27, even: 6181024/5&lt;p&gt;U37/&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;U27, even: 6448896&lt;p&gt;U47, odd: 6448897&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;U27, even: 61X9266&lt;p&gt;U47, odd: 61X9265&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ID bytes: Model, Submodel, Revision level&lt;/cell&gt;
        &lt;cell&gt;FCh, N/A, N/A a&lt;/cell&gt;
        &lt;cell&gt;FCh, 00h, 01h&lt;/cell&gt;
        &lt;cell&gt;FCh, 01h, 00h&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Technical Reference (with source code listing)&lt;/cell&gt;
        &lt;cell&gt;March 1984&lt;/cell&gt;
        &lt;cell&gt;September 1985&lt;/cell&gt;
        &lt;cell&gt;March 1986&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;PC/AT model and mainboard type&lt;/cell&gt;
        &lt;cell&gt;068, 099 (Type 1)&lt;/cell&gt;
        &lt;cell&gt;239 (Type 2)&lt;/cell&gt;
        &lt;cell&gt;319, 339 (Type 3)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CPU clock supported&lt;/cell&gt;
        &lt;cell&gt;6 MHz (not tested in POST)&lt;/cell&gt;
        &lt;cell&gt;6 MHz (tested in POST)&lt;/cell&gt;
        &lt;cell&gt;8 MHz (tested in POST)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Keyboards supported&lt;/cell&gt;
        &lt;cell&gt;84-key AT&lt;/cell&gt;
        &lt;cell&gt;84-key AT b&lt;/cell&gt;
        &lt;cell&gt;84-key AT&lt;p&gt;101/102-&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Floppy drives types supported&lt;/cell&gt;
        &lt;cell&gt;360 KB&lt;p&gt;1.2 MB&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;360 KB&lt;p&gt;1.2 MB&lt;/p&gt;&lt;p&gt;720 KB&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;360 KB&lt;p&gt;1.2 MB&lt;/p&gt;&lt;p&gt;720 KB&lt;/p&gt;&lt;p&gt;1.44 MB&lt;/p&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Hard drive types supported&lt;/cell&gt;
        &lt;cell&gt;14 (types 01-14)&lt;/cell&gt;
        &lt;cell&gt;22 (types 01-14, 16-23)&lt;/cell&gt;
        &lt;cell&gt;22 (types 01-14, 16-23)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Checks for "multiple data rate" drive controller? c&lt;/cell&gt;
        &lt;cell&gt;No&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
        &lt;cell&gt;Yes&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;That's the low-down on what we have to compare against. In this yet-unknown revision, both of the date stamps within the BIOS image (03/08/85 and 02/14/85) place it in-&lt;/p&gt;
    &lt;head rend="h6"&gt;Are You AT Enough?&lt;/head&gt;
    &lt;p&gt;Before I embarked on some actual reverse-&lt;/p&gt;
    &lt;p&gt;Since I don't have an actual IBM 5170, that's as close to an "AT compatibility test" as I could get, but this firmware appeared to pass muster:&lt;/p&gt;
    &lt;p&gt;Our 'rev. 1.5' BIOS makes it through POST with no issues. The IBM AT Advanced Diagnostics v2.07 disk loads up, and dutifully reports the firmware's P/N and date string; System Checkout (which lists the installed hardware) and the SETUP procedure (which is where you configure it) both run as expected.&lt;/p&gt;
    &lt;p&gt;Evidently this is some manner of PC/AT BIOS, or close enough to make Diagnostics happy. Poking at it under an emulator isn't going to tell us a whole lot more than this, however: we don't know exactly what this revision assumes about the hardware, so we can't expect to tell compatibility issues from configuration errors, or just sketchy emulation. At this juncture (if you'll excuse the imagery) we might as well roll up our sleeves and start rummaging through the entrails.&lt;/p&gt;
    &lt;head rend="h3"&gt;Findings&lt;/head&gt;
    &lt;p&gt;For more detailed notes about the disassembly itself, have a look at the repository. I'll just mention that the goal was to figure out just where and how this 'rev. 1.5' BIOS differs from the others, and this would have been much more difficult if it wasn't for two things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The published source listings for all official AT BIOS versions, from the respective editions of the PC/AT Technical Reference - available on Bitsavers (and on the Internet Archive: #1, #2, #3).&lt;/item&gt;
      &lt;item&gt;The excellent reconstructions of the source code by Vernon Brooks over at PC DOS Retro, which have the listings in plain text (and they can be successfully reassembled, too).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;I didn't go quite as far as trying to reconstruct a version that actually builds, but thanks to the above I believe I have things mostly figured out, so here's my analysis.&lt;/p&gt;
    &lt;head rend="h6"&gt;The Code Base&lt;/head&gt;
    &lt;p&gt;Just to get this out of the way, this is very clearly not a custom patch, or a little localized modification. Most obviously, all offsets/&lt;/p&gt;
    &lt;p&gt;In fact, with some (important) differences which will be detailed below, overall the code base appears to be something you'd expect if you were looking at a snapshot of some interim state between rev. 1 and 2. Some sections are closer to their rev. 1 counterparts, others to rev. 2; many contain elements of both, or follow the general logic of one version while still showing certain practices more common in the other.&lt;/p&gt;
    &lt;p&gt;For instance, a routine may perform essentially the same thing it did in rev. 1, but include certain optimizations which are mostly found only in rev. 2, such as immediate multi-&lt;code&gt;SHL BL, 2&lt;/code&gt; in place of two &lt;code&gt;SHL BL, 1&lt;/code&gt; instructions),3 or updating segment registers with &lt;code&gt;PUSH&lt;/code&gt;/&lt;code&gt;POP&lt;/code&gt; (instead of &lt;code&gt;MOV&lt;/code&gt;ing the value through a go-&lt;/p&gt;
    &lt;p&gt;Other routines appear more or less in the same form they have in rev. 2, while signs of the rev. 1 coding style still persist. For example, all the I/O required to access CMOS memory is done inline, as opposed to rev. 2 which calls two new routines for this purpose (&lt;code&gt;CMOS_READ&lt;/code&gt; and &lt;code&gt;CMOS_WRITE&lt;/code&gt;).  Or the encoding of jumps: two-byte (short) jumps are often found padded with a &lt;code&gt;NOP&lt;/code&gt; instruction, like in rev. 1, something that no longer happens in the later iterations.4&lt;/p&gt;
    &lt;p&gt;The more interesting parts, of course, are the sections which are unique to 'rev. 1.5' and don't have direct counterparts elsewhere, but I'll be getting to them in a bit. Those aside, the whole thing does look like an authentic version of the BIOS code, caught in some intermediate state of development between revisions 1 and 2 - including some (but not all) of the changes that later made it to the second revision, as well as a few modifications that didn't.&lt;/p&gt;
    &lt;head rend="h6"&gt;Top-Level Organization (and Build Environment)&lt;/head&gt;
    &lt;p&gt;The other editions of the AT BIOS were all generated from multiple source files. Here we only have the final image, but by comparing the overall structure against the other versions, we can deduce the breakdown into separate source modules. The arrangement of the code and data here is the same as in rev. 1, which suggests that 'rev. 1.5' was built before the restructuring that can be seen in the second revision.&lt;/p&gt;
    &lt;p&gt;Rev. 1 was apparently assembled with MASM v1.0, but rev. 2 switched to v2.0, as we're told by the page titles in IBM's source listing. If the structural overhaul was down to that change, then '1.5' was likely still built with MASM v1.0... a form of cruel and unusual punishment if there ever was one, but perhaps they had some inside scoops from Microsoft on how to deal with all the errata in that famously bug-&lt;/p&gt;
    &lt;head rend="h3"&gt;Functionality (and Hardware Support) Comparison&lt;/head&gt;
    &lt;p&gt;Now for some of the actual similarities and differences between 'rev 1.5' and its older/&lt;/p&gt;
    &lt;p&gt;So it wasn't a complete surprise to find quite a few similarities with rev. 2. For instance,&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It supports 720K (3.5" DSDD) floppy disks, officially introduced only in rev. 2.&lt;/item&gt;
      &lt;item&gt;21 different hard drive types are available: 01-14 and 16-22, just one short of rev. 2 (and 3), which add drive type 23. Only types 01-14 were recognized in rev. 1 (15 is always reserved).&lt;/item&gt;
      &lt;item&gt;It implements INT 15h function C0h ("Get System Configuration"), which didn't exist in rev. 1, but was present in rev. 2 (and in all later PC compatible BIOSes).&lt;/item&gt;
      &lt;item&gt;Keyboard support is more or less the same as in rev. 2: only the 84-key AT keyboard is (fully) supported, but some code for the 101/102-key Enhanced Keyboard is already present. The hardware IRQ handler (INT 09h) attempts to detect it, and uses its expanded scan code tables, but the enhanced INT 16h services are not available.5&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In certain other respects, however, there's more in common with the first revision:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;It doesn't attempt to verify the 286's clock speed, a test that was added to POST in revisions 2 and 3 (at checkpoint 11h).67&lt;/item&gt;
      &lt;item&gt;When testing the floppy/&lt;wbr&gt;hard drive controller ("combo card" in IBM-&lt;/wbr&gt;&lt;wbr&gt;speak), it won't throw up a "601 diskette error" if it cannot find the "multiple data rate capability" indication bit. What this means in practice is that more third-party controllers should be supported.&lt;/wbr&gt;&lt;/item&gt;
      &lt;item&gt;POST checkpoint codes 02 and 03 mean the same things as in rev. 1 (respectively, these tests verify the CMOS Shutdown Byte and the BIOS ROM checksum). The later revisions swap these two tests around.6&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then you've got those peculiar sections where 'rev. 1.5' does its own thing entirely. The most significant ones handle RAM testing and parity errors: this also provides our biggest clue about just what sort of AT this firmware came from, so I'll expand on this down below.&lt;/p&gt;
    &lt;p&gt;For now, just a few notes about some of the above:&lt;/p&gt;
    &lt;head rend="h6"&gt;The System Configuration Table&lt;/head&gt;
    &lt;p&gt;This is where we find the machine ID bytes: model, sub-&lt;/p&gt;
    &lt;p&gt;The odd part is that it returns sub-&lt;/p&gt;
    &lt;quote&gt;F000:E6F5 08 00 CONF_TBL dw 8 ; LENGTH OF FOLLOWING TABLE F000:E6F7 FC db MODEL_BYTE ; SYSTEM MODEL BYTE F000:E6F8 01 db SUB_MODEL_BYTE ; SYSTEM SUB MODEL TYPE BYTE F000:E6F8 ; [* 1, like rev. 3 (0 in rev. 2) *] F000:E6F9 00 db BIOS_LEVEL ; BIOS REVISION LEVEL F000:E6F9 ; [* 0, like rev. 3 (1 in rev. 2) *] F000:E6FA 70 db 1110000b ; 10000000 = DMA CHANNEL 3 USE BY BIOS F000:E6FA ; 01000000 = CASCADED INTERRUPT LEVEL 2 F000:E6FA ; 00100000 = REAL TIME CLOCK AVAILABLE F000:E6FA ; 00010000 = KEYBOARD SCAN CODE HOOK 1AH&lt;/quote&gt;
    &lt;head rend="h6"&gt;Floppy Drive Support&lt;/head&gt;
    &lt;p&gt;This is one area where the 'rev 1.5' code base diverges from all other revisions, but the actual functionality doesn't seem to be too different from rev. 2. It looks more as if 3.5" 720 KB media support was shoehorned into the rev. 1 code (which only handled 1.2 MB and 360 KB disks and drives). This somewhat over-&lt;/p&gt;
    &lt;p&gt;Rev. 2 refactored and simplified the floppy code, in part by implementing what the comments call a "new architecture", along with two routines (&lt;code&gt;XLAT_NEW&lt;/code&gt; and &lt;code&gt;XLAT_OLD&lt;/code&gt;) which convert such data fields to a new internal format when entering a BIOS function, then back to the old format on exit.  The floppy code in 'rev 1.5' is therefore noticeably messy compared to the other revisions, and in places it seems to use certain "reserved" state bits for temporary purposes which I haven't fully grokked yet (see &lt;code&gt;set_dskstate_*&lt;/code&gt; in the disassembly).&lt;/p&gt;
    &lt;p&gt;Still, the interface already has the familiar form it would retain later. For instance, INT 13h function 17h (Set Disk Type for Format), named &lt;code&gt;FORMAT_SET&lt;/code&gt; in the code (address F000:&lt;/p&gt;
    &lt;p&gt;Function 08h (Get Drive Parameters), which in rev. 1 was only available for hard drives, works for floppies here. It returns the same data in the same registers as rev. 2 and onward, although it's executed differently. The data is populated from a table at F000:&lt;/p&gt;
    &lt;quote&gt;F000:EF62 00 F0 d720_seg dw 0F000h F000:EF64 C7 EF d720_off dw offset DISK_BASE ; [* 720k: ptr to DISK_BASE *] F000:EF66 09 d720_spt db 9 ; [* 720K: sectors/track *] F000:EF67 4F 00 d720_mxt dw 79 ; [* 720K: max tracks *] F000:EF69 01 d720_mxh db 1 ; [* 720K: max heads *]&lt;/quote&gt;
    &lt;p&gt;720 KB floppy support might just be another innovation of this firmware. The first PC-&lt;/p&gt;
    &lt;head rend="h3"&gt;It's All About that Base RAM&lt;/head&gt;
    &lt;p&gt;At last, the interesting part: what this BIOS does about memory - and how this appears to hint at a machine that isn't quite your garden-&lt;/p&gt;
    &lt;head rend="h6"&gt;System Board RAM (and the Keyboard Controller)&lt;/head&gt;
    &lt;p&gt;A bit of background to keep in mind here: through the AT's lifetime, IBM never saw fit to release a model with room for more than 512K of RAM on the system board, unlike the XT (and the XT Model 286). A 128K expansion board can be used to bring a 512K system up to the 640K "base RAM" (AKA conventional RAM) limit.&lt;/p&gt;
    &lt;p&gt;Now, most of the AT's configuration options are kept in CMOS memory, but a couple of things still have to be set the old way - as with the PC and XT, via motherboard switches and jumpers. These settings can be read from the 8042 keyboard controller's input port (by sending C0h to port 64h, then reading port 60h).&lt;/p&gt;
    &lt;p&gt;During the POST procedure, the 5170 BIOS reads these switch settings and stores them in the BIOS Data Area at address 0040:0012 - a byte that was previously unused, except on the PCjr. The AT BIOS listings label this byte &lt;code&gt;MFG_TST&lt;/code&gt;, although the manufacturing test jumper status is just one of the bits used.&lt;/p&gt;
    &lt;p&gt;One of these settings (determined by jumper J18) specifies the amount of RAM on the system board. Type 2 and type 3 AT motherboards come with the full complement of 512 KB; on a Type 1 board, either 256 or 512 KB may be populated, so on these early 5170s this setting can take either value.&lt;/p&gt;
    &lt;p&gt;In the data byte obtained from the 8042 input port, that's what bit 4 indicates. Seems simple enough: as far as the official documentation is concerned, this is the only jumper or switch setting that has anything to do with the amount of on-&lt;/p&gt;
    &lt;p&gt;But hold on: in the definition table, you will also notice a bit 3. In all three versions of the PC/AT Technical Reference, bit 3 is marked "undefined" or "reserved".&lt;/p&gt;
    &lt;head rend="h6"&gt;The "Base Planar Memory Extension"&lt;/head&gt;
    &lt;p&gt;The BIOS code listings include IBM's comments for all symbolic constants, most of them at the very start (&lt;code&gt;POSTEQU.INC&lt;/code&gt; in the reconstructed source files). There, the sources for revisions 2 and 3 (but not for rev. 1!) sneak one more entry into the list of bits in the keyboard controller's input port: 10&lt;/p&gt;
    &lt;code&gt;
               C  ;--------- 8042 INPUT PORT BIT DEFINITION SAVED IN @MFG_TST --------------------
 = 0008        C  BASE_MEM8       EQU     00001000B       ; BASE PLANAR R/W MEMORY EXTENSION 640/X 
 = 0010        C  BASE_MEM        EQU     00010000B       ; BASE PLANAR R/W MEMORY SIZE 256/512
 = 0020        C  MFG_LOOP        EQU     00100000B       ; LOOP POST JUMPER BIT FOP MANUFACTURING
 = 0040        C  DSP_JMP         EQU     01000000B       ; DISPLAY TYPE SWITCH JUMPER BIT
 = 0080        C  KEY_BD_INHIB    EQU     10000000B       ; KEYBOARD INHIBIT SWITCH BIT
&lt;/code&gt;
    &lt;p&gt;This &lt;code&gt;BASE_MEM8&lt;/code&gt; would be our "reserved" bit 3.  Note how it's described: "base planar R/W memory extension 640&lt;/p&gt;
    &lt;p&gt;Anyway, the POST process does just what that block comment says on the tin: around checkpoint 11, it reads the switch settings, which were temporarily stored in the &lt;code&gt;DMA_PAGE+1&lt;/code&gt; register a bit earlier.  Then it strips off the unneeded bits, and saves the result to the &lt;code&gt;@MFG_TST&lt;/code&gt; byte in the BIOS Data Area.&lt;/p&gt;
    &lt;p&gt;BIOS revisions 2 and 3, which know about bit 3 (as &lt;code&gt;BASE_MEM8&lt;/code&gt;), take care to preserve it - again, unlike rev. 1:&lt;/p&gt;
    &lt;quote&gt;;----- GET THE INPUT BUFFER (SWITCH SETTINGS) 05CB E4 82 IN AL,DMA_PAGE+1 ; GET THE SWITCH SETTINGS 05CD 24 F8 AND AL,KEY_BD_INHIB+DSP_JMP+MFG_LOOP+BASE_MEM+BASE_MEM8 ; STRIP BITS 05CF A2 12 00 MOV @MFG_TST,AL ; SAVE SETTINGS&lt;/quote&gt;
    &lt;p&gt;"But what do they actually do with this bit once they've read it?", you ask. To channel Trade Master Greenish, "that's a good question, with a very interesting answer": they do precisely nothing whatsoever with it at any point. Whether in the POST process or elsewhere, this piece of information is consulted a grand total of zero times.&lt;/p&gt;
    &lt;p&gt;I should mention that I couldn't find any unofficial explanation of this bit, either. None of the usual references and books have anything better to say about it than "reserved" or "undefined", and that includes such ne plus ultra sources as Ralf Brown, or The Undocumented PC by Frank van Gilluwe. A most curious state of affairs.&lt;/p&gt;
    &lt;p&gt;So what could "base planar memory extension 640&lt;/p&gt;
    &lt;head rend="h3"&gt;The 640/X Factor&lt;/head&gt;
    &lt;p&gt;At this point you can likely guess where this is going: the 'rev 1.5' AT BIOS does pay attention to this undocumented '640/X' bit. It's checked in a couple of places, but always in the same context, and it's a rather enlightening one: RAM parity checking.&lt;/p&gt;
    &lt;head rend="h6"&gt;A Perfunctory Parity Primer&lt;/head&gt;
    &lt;p&gt;For every byte of memory in the IBM PC-&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RAM on the system board triggers "Parity Check", which sets bit 7 of port 61h (if enabled by setting bit 2).&lt;/item&gt;
      &lt;item&gt;RAM expansion cards trigger "I/O Channel Check", which sets bit 6 of port 61h (if enabled by setting bit 3).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;These commonly-&lt;/p&gt;
    &lt;head rend="h6"&gt;Many NMIs Bring Much Honor&lt;/head&gt;
    &lt;p&gt;When the NMI service routine is invoked, it tries to determine what has roused it from its slumber. If the cause was a parity error, it will display the message "PARITY CHECK 1" (if the source was on-&lt;/p&gt;
    &lt;p&gt;Interestingly, this test doesn't try to match the specific type of parity error that raised the NMI: for each 64K region, it decides which of the two parity check signals it's going to look for. Those switch settings in &lt;code&gt;MFG_TST&lt;/code&gt; play into this choice, so we can get some insight by looking at the logic. In all versions of the AT BIOS, the relevant code is in &lt;code&gt;NMI_INT_1&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;For comparison, the Rev. 1 BIOS does it as follows. The diagram is somewhat simplified, but this is the general logic:&lt;/p&gt;
    &lt;p&gt;That is, below 256K it always watches for on-&lt;/p&gt;
    &lt;p&gt;In revisions 2 and 3, the NMI handler's memory test is less revealing: no matter the RAM address, it always watches for both types of parity error, and treats either one as a good enough reproduction. Likely, the designers decided that being picky about it wasn't worth the extra code, since the test already disregards the type of error which caused the NMI to fire in the first place.&lt;/p&gt;
    &lt;p&gt;'Rev. 1.5', however, still insists on being pedantic. Which is fortunate for us, because the change in logic from rev. 1 is very instructive:&lt;/p&gt;
    &lt;p&gt;The crucial difference is in the region above 512K, where the '640/X' flag (AKA &lt;code&gt;BASE_MEM8&lt;/code&gt;) comes in. When the machine has 512K on the system board and the '640/X' bit is set, the test in revision "1.5" will expect on-board parity errors in this block of RAM.&lt;/p&gt;
    &lt;p&gt;If following a bunch of arrows around isn't your idea of a good time, this format may be easier on the eyes:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Region&lt;/cell&gt;
        &lt;cell role="head"&gt;Rev. 1 checks for&lt;/cell&gt;
        &lt;cell role="head"&gt;Rev. '1.5' checks for&lt;/cell&gt;
        &lt;cell role="head"&gt;Rev. 2, 3 check for&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;0K&lt;/cell&gt;
        &lt;cell&gt;On-board RAM error&lt;/cell&gt;
        &lt;cell&gt;On-board RAM error&lt;/cell&gt;
        &lt;cell&gt;(Any parity error)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;256K&lt;/cell&gt;
        &lt;cell&gt;[256K system]: I/O channel error&lt;p&gt;[512K system]: On-board RAM error&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;[256K+'640/X']: I/O channel error&lt;p&gt;[otherwise]: On-board RAM error&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;(Any parity error)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;512K&lt;/cell&gt;
        &lt;cell&gt;I/O channel error&lt;/cell&gt;
        &lt;cell&gt;[512K+'640/X']: On-board RAM error&lt;p&gt;[otherwise]: I/O channel error&lt;/p&gt;&lt;/cell&gt;
        &lt;cell&gt;(Any parity error)&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;"Yeah, yeah, get to the point": what does this mean, then?&lt;/p&gt;
    &lt;p&gt;Well, let's imagine that the matching motherboard had something like an extra 128K bank of RAM, plus a switch or a jumper to indicate that it was populated. If the '640/X' bit reflected the state of that switch, this would all make sense - and so would the "base planar" terminology from IBM's later listings.&lt;/p&gt;
    &lt;p&gt;What doesn't make quite as much sense is the behavior of the "256K on board" setting: whether it's used in tandem with the '640/&lt;/p&gt;
    &lt;head rend="h6"&gt;The POST Memory Test Loop... and the &amp;gt;1MB Oddity&lt;/head&gt;
    &lt;p&gt;There's another place where the 'rev. 1.5' BIOS refers to the status of the '640/X' flag: the cold-&lt;/p&gt;
    &lt;p&gt;For conventional memory, when determining the type of parity check to expect for each range of addresses, the cold-&lt;/p&gt;
    &lt;p&gt;In rev. 1, all non-&lt;/p&gt;
    &lt;p&gt;But for some reason, 'rev. 1.5' here appears to reserve special treat&lt;/p&gt;
    &lt;quote&gt;F000:0FFC E21_C1M: ; [* 1MB boundary *] F000:0FFC C6 06 64 00 10 mov byte ptr ds:DS_TEMP+BASE_HI_BYTE, 16 F000:1001 C6 06 4C 00 10 mov byte ptr ds:ES_TEMP+BASE_HI_BYTE, 16 F000:1006 B0 40 mov al, IO_CHECK ; [* I/O Check mask (&amp;gt;1M on exp. card) *] F000:1008 E6 87 out DMA_PAGE+6, al ; [* temporary storage *] F000:100A 1E push ds F000:100B F000:100B ; [* this rev. only: get hardware configuration again *] F000:100B F000:100B B8 18 00 mov ax, RSDA_PTR ; [* system data area for POST *] F000:100E 8E D8 mov ds, ax F000:1010 A0 12 00 mov al, ds:@MFG_TST ; [* get mfg test config *] F000:1013 1F pop ds F000:1014 24 18 and al, BASE_MEM+BASE_MEM8 ; [* Planar RAM configuration bits: *] F000:1016 3C 10 cmp al, BASE_MEM ; [* bit 4 (512k planar) ONLY? *] F000:1018 75 04 jnz short E21_C1M5 ; [* no: keep I/O Check mask *] F000:101A B0 80 mov al, PARITY_CHECK ; [* yes: use Parity check mask (planar) *] F000:101C E6 87 out DMA_PAGE+6, al ; [* and save to temporary storage *] F000:101E F000:101E ; [* this rev. only: check for 1.5MB boundary (24*64K)? *] F000:101E F000:101E E21_C1M5: F000:101E 80 3E 64 00 18 cmp byte ptr ds:DS_TEMP+BASE_HI_BYTE, 24 F000:1023 72 04 jb short NEXT1 ; [* continue if below 1.5MB *] F000:1025 B0 40 mov al, IO_CHECK ; [* reset to I/O Check mask above 1.5MB *] F000:1027 E6 87 out DMA_PAGE+6, al ; [* temporary storage *]&lt;/quote&gt;
    &lt;p&gt;The logic here seems to be this: if the 1--&lt;/p&gt;
    &lt;p&gt;What that could mean is anybody's guess. But if we take this at face value, then our theoretical motherboard may have had two selectable configurations:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;640K on board (the usual 512K plus 128K extra), which would then fill up conventional memory to the limit; OR,&lt;/item&gt;
      &lt;item&gt;1024K on board, set up as 512K base plus 512K extended, with the latter mapped between 1 and 1.5 MB.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In the first case, you'd set the hypothetical switch or jumper one way, causing the '640/X' bit (AKA &lt;code&gt;BASE_MEM8&lt;/code&gt;) to be set.  In the second case, the switch goes the other way, which would clear it.  With a full meg on board, the logic implies that the 128K expansion board can still be used, bringing your base RAM up to 640K.&lt;/p&gt;
    &lt;head rend="h6"&gt;The PCB Real-Estate Question&lt;/head&gt;
    &lt;p&gt;One may wonder where a megabyte of RAM might go on the 5170 mainboard (or on some plausible variant of it). But that's not too far fetched if we assume 256 kbit DRAM chips, like the Type 2 and 3 AT boards.&lt;/p&gt;
    &lt;p&gt;In fact, looking at those later mainboards, the layout around that single 512K RAM bank seems rather cozy and spacious, which sort of stands out next to the cramped organization of the rest of the board. Those two rows of chips are flanked on both sides by curiously empty space - coincidentally, it looks like there's just enough room there to double the chip count with a minimal change in design.&lt;/p&gt;
    &lt;p&gt;If we roll with this observation, we can just about arrive at a scenario where the first redesign of the 5170 mainboard - corresponding to our 'rev. 1.5' AT BIOS on the timeline - could have accommodated as much as 1024K of memory. For reasons of their own, the powers that be at IBM decided not to pursue this as a finished product, and the next AT models to hit the market (with the Type 2 mainboard, and the rev. 2 BIOS) were stripped down to one bank of 512K, leaving all that board real-&lt;/p&gt;
    &lt;p&gt;Since the 'rev. 1.5' BIOS code seems to imply a selectable cofiguration of either 1 MB or 640 KB, could such a RAM subsystem support either setup at the flip of a switch? Supposing one 16-&lt;/p&gt;
    &lt;head rend="h3"&gt;Skyrocket: The Real Deal?&lt;/head&gt;
    &lt;p&gt;Conjectures are fun and all, but can this hypothetical PC/AT variant be identified with anything like an actual real-&lt;/p&gt;
    &lt;p&gt;The thread in question is 'OT: "Skyrocket" the AT that never was', posted to comp.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Sorting through the piles a bit I've (re)discovered a bit of ancient AT history -- the machine that had the internal codename "Skyrocket". Looks just like a normal AT with the primary difference being there is 640K on the planar rather than 512K as shipped in all the retail models.&lt;/p&gt;
      &lt;p&gt;How did I happen across this rather unique piece of history? Well, I was in the right place at the right time when the Boca Raton site was being shutdown and thrown to the wind. IBM was firesaleing off all sorts of gear to the employees and I'd bought a stack of AT's for $10/&lt;/p&gt;
      &lt;wbr&gt;each. On closer examination, one of the stack turned out to be the rare Skyrocket...&lt;/wbr&gt;
    &lt;/quote&gt;
    &lt;p&gt;Further along the thread, we get more details:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Skyrocket's planar is traditional "big" AT style (not the shortie 339 or XT-286 style), but uses normal DIP's not the old Mostek/&lt;/p&gt;
      &lt;wbr&gt;TI DIL's (positioned on the usual place the double deckers would be on the planar though). It's got a two rows of 41256 and two of 4164 type DIP.&lt;/wbr&gt;
      &lt;p&gt;I believe Skyrocket probably predates XT-286, and may have been concurrent with 339 at some point. When the project was shelved, some number of advanced prototype had been produced and were distributed about the site on an IUO basis - I had one on my desk in 86' during OS/2 1.0 development (real 339's were rare and all being shipped out to customers&lt;/p&gt;
      &lt;g&gt;). Where the "AT" badge would be is a metalic emblem shooting star logo, which leads me to believe it was fairly well along when it was shot down...&lt;/g&gt;
    &lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;My sense is that the Skyrocket machine was tanked because the 339 planar was ready, cost less to manufacture, and with PS/2 ready to be unveiled, it just wasn't worth the bother to get the extra 128K onto the planar for a machine that would have a distinctly limited lifespan.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That DRAM layout is just as predicted above for the 640 KB option: one Type 2/3-&lt;/p&gt;
    &lt;head rend="h6"&gt;...Or is it?&lt;/head&gt;
    &lt;p&gt;Now, I'm not completely convinced beyond a shadow of a doubt that this is what we have here. Given what I can make of this BIOS, the particulars of this cancelled AT prototype do fit... but not exactly like a glove.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The most obvious smoking gun is of course the 640K system board, but there's also that alternative 1 MB option implied by the cold-&lt;/p&gt;
        &lt;wbr&gt;boot RAM test loop, which Tony doesn't mention.&lt;/wbr&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;He makes it sound like "Skyrocket" came along fairly late in the 5170's lifespan, possibly concurrent with the Model 339/&lt;/p&gt;
        &lt;wbr&gt;Type 3 AT, and not all that long before the launch of the PS/2. But the date stamps in this 'rev. 1.5' BIOS (as well as the code!) date it to before the Type 2 boards.&lt;/wbr&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A "traditional big AT style" planar (which I take to mean a 'Type 1' form factor) does fit the time frame; but an 8 MHz CPU clock wouldn't be my first guess with that sort of thing, since even the Type 2 still limped along at 6 MHz.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;But on the other hand:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;The option to switch between 640 KB and 1 MB configurations may be technically supported in the 'rev. 1.5' BIOS, but perhaps the mechanism to do this (along with the extra address decoding logic) was simply never implemented in the prototype system board... or maybe there just weren't enough 256 kbit DRAM parts to go around, and all the "Skyrocket" ATs ended up with a fixed 640 KB on board.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;ROM date stamps never correlate very well with actual availability anyway, and we have to keep in mind that the 5170 had less than 3 years of official lifetime as a product. Within that period, I could easily imagine various projects going on simultaneously, with all sorts of fun bureaucratic delays to ensure maximum confusion.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I don't see anything in the 'rev. 1.5' BIOS code to suggest that it can't be an 8 MHz system. In fact nothing seems to indicate any particular clock rate, because it's missing the CPU speed test which was added in rev. 2. There are a few instances of speed-&lt;/p&gt;
        &lt;wbr&gt;dependent "busy wait" loops scattered throughout the code, but the counter values used for those weren't even consistent between the two 6 MHz BIOS editions, so they tell us very little.&lt;/wbr&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Since there's nothing to absolutely preclude this BIOS from being the "Skyrocket" firmware, and the '640/X' business with RAM capacity sure seems to be a good match, I'll invoke Occam's trusty razor and say it's probably "Skyrocket"... or at least something very closely related to it.&lt;/p&gt;
    &lt;p&gt;With that talk about "a metallic emblem shooting star logo" in place of the "AT" one, I couldn't resist making this little mock-&lt;/p&gt;
    &lt;p&gt;Whichever 5170 variant this BIOS came from, it wasn't a released product, but it makes sense for a prototype that made as far as "internal use" at IBM: the EPROMs have part numbers (on printed labels and in the data), which seems to hint that this project got to a respectable stage in the development cycle before they canned it.&lt;/p&gt;
    &lt;p&gt;I'm given to understand that Tony Ingenoso is regrettably no longer with us, so we won't be able to verify whether the BIOS ROMs in his "Skyrocket" are the same as this 'rev. 1.5'. But maybe someone else out there will be able to shed some more light here.&lt;/p&gt;
    &lt;p&gt;Amusingly, it's a lucky thing that this firmware still retains rev. 1's pickiness about specific parity error types - it could have been less fussy about it (like the later revisions), and our only clue that there was anything funny about the RAM setup would have gone down the chute. But it didn't, and now we can also explain that little riddle from the rev. 2 and 3 BIOS listings, where they mention the undocumented "640/X" bit: evidently someone done goofed, and simply forgot to clean up the source files.&lt;/p&gt;
    &lt;p&gt;"Skyrocket" or not, this was a diverting little game of connect-&lt;/p&gt;
    &lt;head rend="h3"&gt;Notes&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;The same model byte was used by other IBM systems, namely the XT-286 and the 7552 "Gearbox" industrial computer, but these only arrived in late 1986. See the model byte table from Ralf Brown's Interrupt List. [↑]&lt;/item&gt;
      &lt;item&gt;This was done to support certain very early, "badly behaved" software, which accessed BIOS functions and structures by calling absolute addresses instead of using the interrupt services - some authors had the PC mixed up with an Apple II, apparently. IBM explains this in the comments for the 'compatibility' section, for instance in the second PC AT Technical Reference (Sep. 1985), p.5-182 (which does a great job conveying the intended tone of disapproval and contempt).&lt;lb/&gt;This practice was carried on by third-&lt;wbr&gt;party BIOS vendors: see ROM Address Compatibility Table in System BIOS for IBM PC/XT/AT Computers and Compatibles (Phoenix Technologies, Ltd., 1989), p.58. [↑]&lt;/wbr&gt;&lt;/item&gt;
      &lt;item&gt;Immediate multi-bit shifts and rotates were a new feature of the 80286 (or more accurately, of the 80186, but IBM skipped that one). The rev. 1 AT BIOS tends to stick to 8088-&lt;wbr&gt;compatible instruction forms - this likely has to do with MASM 1.0, which didn't support any 286 instructions whatsoever, so when they do appear they're implemented using macros. [↑]&lt;/wbr&gt;&lt;/item&gt;
      &lt;item&gt;This too is an artifact of early MASM versions, which used a two-&lt;wbr&gt;pass assembly process. In the first pass, symbols haven't been resolved yet, and jumps within a segment are encoded as near (3-byte) jumps. The second pass applies the resolved addresses, and if the target is within range, it'll go with the short (2-byte) form. That would shift things around, but the two-pass process can't deal with offsets being changed at this point, so the third byte is simply replaced with a&lt;/wbr&gt;&lt;code&gt;NOP&lt;/code&gt;(90h).&lt;lb/&gt;To get around this you can explicitly specify "JMP SHORT", and the first pass will use the two-byte form. Of course, this gets you an error if the target isn't within the short jump range, but IBM evidently did the legwork for the second AT BIOS revision. For more about this (and other ancient MASM quirks), see this writeup at OS/2 Museum. [↑]&lt;/item&gt;
      &lt;item&gt;The Type 2 AT Technical Reference (Sep. 1985) doesn't mention the Enhanced Keyboard at all, other than the hints for this rudimentary support in the BIOS listing - where the comments refer to it only as "KBX". Perhaps the notion of a "keyboard X" gave off the right mixture of suspense and enigma, but the eagle-&lt;wbr&gt;eyed would have noticed references to keys like F11 and F12.&lt;/wbr&gt;&lt;lb/&gt;The Enhanced Keyboard was officially introduced with the 7531/7532 Industrial Computer, which used the 5170 AT BIOS. I'm not sure which revision(s), but the 7531/7532 Technical Reference from July '85 includes the source for rev. 1, even though it fully describes the new keyboard. Makes no sense to me... but St. Augustine would have said, "if you understand it, it is not IBM". [↑]&lt;/item&gt;
      &lt;item&gt;For the sequencing and meaning of POST checkpoint codes on the 5170, see the IBM 5170 - POST Codes page at Minus Zero Degrees. [↑]&lt;/item&gt;
      &lt;item&gt;Infamously, the speed test prevented owners of the 6-MHz Model 239 AT (with its rev. 2 BIOS) from overclocking it by replacing the clock oscillator, which was often done with earlier ATs. The common conspiracy theory says that IBM did this purely out of greed, since they didn't want a "too-fast" 5170 to bite into the sales figures of more expensive systems (which?), or of the "official" faster ATs they were planning to introduce shortly.&lt;lb/&gt;I'm not sure I buy that. The fact is that the 286 CPUs supplied with these models were only rated for 6 MHz, and the stability of the rest of the system wasn't guaranteed beyond that either, since the bus ran off the same clock. The AT had already caused PR problems for IBM, with those early CMI hard drives going teats-up en masse, and I suppose they weren't going to risk any more reliability issues if they could help it. [↑]&lt;/item&gt;
      &lt;item&gt;The original IBM JX BIOS could only handle 40 tracks, so the total usable capacity was 360K; the earliest JX BIOS that could handle the full 720K has a 1986 date code. See "System Specifications" on the IBM JX Information Page. [↑]&lt;/item&gt;
      &lt;item&gt;Keyboard Controller: Input Port Bit Definitions, The IBM Personal Computer AT Technical Reference. Rev. 1 (Mar. 1984): p.1-44; rev. 2 (Sep. 1985): p.1-55; rev. 3 (Mar. 1986): p.1-55 [↑]&lt;/item&gt;
      &lt;item&gt;The IBM Personal Computer AT Technical Reference. Rev. 2 (Sep. 1985): p.5-32; rev. 3 (Mar. 1986), p.5-22 [↑]&lt;/item&gt;
      &lt;item&gt;CMOS RAM Configuration Information, The IBM Personal Computer AT Technical Reference rev. 1 (Mar. 1984), p.1-54 [↑]&lt;/item&gt;
      &lt;item&gt;For more about the ISA parity checking/&lt;wbr&gt;NMI mechanism in the AT architechture (and later), see Non-&lt;/wbr&gt;&lt;wbr&gt;Maskable Interrupt Requests&lt;/wbr&gt;, ISA System Architecture: Third Edition (Mindshare, Inc. 1995), pp. 399-401. [↑]&lt;/item&gt;
      &lt;item&gt;Intel's 8-bit Above Board (1984), for one, allowed either 64 kbit or 256 kbit chips in all sockets; the type used was indicated by setting a DIP switch. Further description is at DOS Days.&lt;lb/&gt;The 5170's 16-bit memory (and bus) architecture is pondered in more detail by GloriousCow of MartyPC fame, in his article Exploring 16-bit Bus Access on the PC/AT. [↑]&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://int10h.org/blog/2025/11/lost-ibm-at-model-bios-analysis/"/><published>2025-11-05T20:40:39+00:00</published></entry></feed>