<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-27T22:37:44.330232+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45720376</id><title>10M people watched a YouTuber shim a lock; the lock company sued him ‚Äì bad idea</title><updated>2025-10-27T22:37:50.784122+00:00</updated><content>&lt;doc fingerprint="8fdd9d18d1b882d5"&gt;
  &lt;main&gt;
    &lt;p&gt;‚ÄúOpening locks‚Äù might not sound like scintillating social media content, but Trevor McNally has turned lock-busting into online gold. A former US Marine Staff Sergeant, McNally today has more than 7 million followers and has amassed more than 2 billion views just by showing how easy it is to open many common locks by slapping, picking, or shimming them.&lt;/p&gt;
    &lt;p&gt;This does not always endear him to the companies that make the locks.&lt;/p&gt;
    &lt;p&gt;On March 3, 2025, a Florida lock company called Proven Industries released a social media promo video just begging for the McNally treatment. The video was called, somewhat improbably, ‚ÄúYOU GUYS KEEP SAYING YOU CAN EASILY BREAK OFF OUR LATCH PIN LOCK.‚Äù In it, an enthusiastic man in a ball cap says he will ‚Äúprove a lot of you haters wrong.‚Äù He then goes hard at Proven‚Äôs $130 model 651 trailer hitch lock with a sledgehammer, bolt cutters, and a crowbar.&lt;/p&gt;
    &lt;p&gt;Naturally, the lock hangs tough.&lt;/p&gt;
    &lt;p&gt;An Instagram user brought the lock to McNally‚Äôs attention by commenting, ‚ÄúLet‚Äôs introduce it to the @mcnallyofficial poke.‚Äù Someone from Proven responded, saying that McNally only likes ‚Äúthe cheap locks lol because they are easy and fast.‚Äù Proven locks were said to be made of sterner stuff.&lt;/p&gt;
    &lt;p&gt;But on April 3, McNally posted a saucy little video to social media platforms. In it, he watches the Proven promo video while swinging his legs and drinking a Juicy Juice. He then hops down from his seat, goes over to a Proven trailer hitch lock, and opens it in a matter of seconds using nothing but a shim cut from a can of Liquid Death. He says nothing during the entire video, which has been viewed nearly 10 million times on YouTube alone.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arstechnica.com/tech-policy/2025/10/suing-a-popular-youtuber-who-shimmed-a-130-lock-what-could-possibly-go-wrong/"/><published>2025-10-27T12:42:42+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45721302</id><title>When 'perfect' code fails</title><updated>2025-10-27T22:37:50.655992+00:00</updated><content/><link href="https://marma.dev/articles/2025/when-perfect-code-fails"/><published>2025-10-27T14:19:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45721801</id><title>Pyrex catalog from from 1938 with hand-drawn lab glassware [pdf]</title><updated>2025-10-27T22:37:50.306150+00:00</updated><content/><link href="https://exhibitdb.cmog.org/opacimages/Images/Pyrex/Rakow_1000132877.pdf"/><published>2025-10-27T15:04:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45721904</id><title>PSF has withdrawn $1.5M proposal to US Government grant program</title><updated>2025-10-27T22:37:50.115864+00:00</updated><content>&lt;doc fingerprint="b28a117194a3d7e3"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;In January 2025, the PSF submitted a proposal to the US government National Science Foundation under the Safety, Security, and Privacy of Open Source Ecosystems program to address structural vulnerabilities in Python and PyPI. It was the PSF‚Äôs first time applying for government funding, and navigating the intensive process was a steep learning curve for our small team to climb. Seth Larson, PSF Security Developer in Residence, serving as Principal Investigator (PI) with Loren Crary, PSF Deputy Executive Director, as co-PI, led the multi-round proposal writing process as well as the months-long vetting process. We invested our time and effort because we felt the PSF‚Äôs work is a strong fit for the program and that the benefit to the community if our proposal were accepted was considerable. &lt;/p&gt;
      &lt;div&gt;
        &lt;div&gt;&lt;p&gt;We were honored when, after many months of work, our proposal was recommended for funding, particularly as only &lt;/p&gt;36% &lt;p&gt;of new NSF grant applicants are successful on their first attempt. We became concerned, however, when we were presented with the terms and conditions we would be required to agree to if we accepted the grant. These terms included affirming the statement that we ‚Äúdo not, and will not during the term of this financial assistance award, operate any programs that advance or promote DEI, or discriminatory equity ideology in violation of Federal anti-discrimination laws.‚Äù This restriction would apply not only to the security work directly funded by the grant, &lt;/p&gt;but to any and all activity of the PSF as a whole&lt;p&gt;. Further, violation of this term gave the NSF the right to ‚Äúclaw back‚Äù previously approved and transferred funds. This would create a situation where money we‚Äôd already spent could be taken back, which would be an enormous, open-ended financial risk. &lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;&lt;p&gt;Diversity, equity, and inclusion are core to the PSF‚Äôs values, as committed to in our &lt;/p&gt;mission statement&lt;p&gt;: &lt;/p&gt;&lt;/div&gt;
      &lt;quote&gt;
        &lt;div&gt;
          &lt;p&gt;The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers.&lt;/p&gt;
        &lt;/div&gt;
      &lt;/quote&gt;
      &lt;div&gt;
        &lt;div&gt;&lt;p&gt;Given the value of the grant to the community and the PSF, we did our utmost to get clarity on the terms and to find a way to move forward in concert with our values. We consulted our NSF contacts and reviewed decisions made by other organizations in similar circumstances, particularly &lt;/p&gt;The Carpentries&lt;p&gt;. &lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;In the end, however, the PSF simply can‚Äôt agree to a statement that we won‚Äôt operate any programs that ‚Äúadvance or promote‚Äù diversity, equity, and inclusion, as it would be a betrayal of our mission and our community. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;We‚Äôre disappointed to have been put in the position where we had to make this decision, because we believe our proposed project would offer invaluable advances to the Python and greater open source community, protecting millions of PyPI users from attempted supply-chain attacks. The proposed project would create new tools for automated proactive review of all packages uploaded to PyPI, rather than the current process of reactive-only review. These novel tools would rely on capability analysis, designed based on a dataset of known malware. Beyond just protecting PyPI users, the outputs of this work could be transferable for all open source software package registries, such as NPM and Crates.io, improving security across multiple open source ecosystems.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;In addition to the security benefits, the grant funds would have made a big difference to the PSF‚Äôs budget. The PSF is a relatively small organization, operating with an annual budget of around $5 million per year, with a staff of just 14. $1.5 million over two years would have been quite a lot of money for us, and easily the largest grant we‚Äôd ever received. Ultimately, however, the value of the work and the size of the grant were not more important than practicing our values and retaining the freedom to support every part of our community. The PSF Board voted unanimously to withdraw our application. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;p&gt;Giving up the NSF grant opportunity‚Äîalong with inflation, lower sponsorship, economic pressure in the tech sector, and global/local uncertainty and conflict‚Äîmeans the PSF needs financial support now more than ever. We are incredibly grateful for any help you can offer. If you're already a PSF member or regular donor, you have our deep appreciation, and we urge you to share your story about why you support the PSF. Your stories make all the difference in spreading awareness about the mission and work of the PSF. &lt;/p&gt;
      &lt;/div&gt;
      &lt;div&gt;
        &lt;list style="text-align: left;" rend="ul"&gt;
          &lt;item&gt;Become a Member: When you sign up as a Supporting Member of the PSF, you become a part of the PSF. You‚Äôre eligible to vote in PSF elections, using your voice to guide our future direction, and you help us sustain what we do with your annual support.&lt;/item&gt;
          &lt;item&gt;Donate: Your donation makes it possible to continue our work supporting Python and its community, year after year.&lt;/item&gt;
          &lt;item&gt;Sponsor: If your company uses Python and isn‚Äôt yet a sponsor, send them our sponsorship page or reach out to sponsors@python.org today. The PSF is ever grateful for our sponsors, past and current, and we do everything we can to make their sponsorships beneficial and rewarding.&lt;/item&gt;
        &lt;/list&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pyfound.blogspot.com/2025/10/NSF-funding-statement.html"/><published>2025-10-27T15:12:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45722635</id><title>Show HN: Erdos ‚Äì open-source, AI data science IDE</title><updated>2025-10-27T22:37:50.004654+00:00</updated><content>&lt;doc fingerprint="fb098e9eaaad19cf"&gt;
  &lt;main&gt;
    &lt;p&gt;0.2.1&lt;/p&gt;
    &lt;p&gt;10-27-2025&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Fixed AI file creation when no workspace selected&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Erdos ‚Äî a next-generation data science IDE.&lt;/p&gt;
    &lt;p&gt;Fast, accurate Jupyter notebook edits&lt;/p&gt;
    &lt;p&gt;Erdos lets data scientists create, edit, and iterate on Jupyter notebooks faster and more accurately than ever before.&lt;/p&gt;
    &lt;p&gt;Plots pane&lt;/p&gt;
    &lt;p&gt;With the help of Erdos‚Äôs AI assistant, data scientists can use the plots pane to view, compare, and iterate on plots as their analyses evolve.&lt;/p&gt;
    &lt;p&gt;Integrated Docs Intelligence&lt;/p&gt;
    &lt;p&gt;Erdos‚Äôs AI assistant reads and interprets documentation from the help pane to deliver contextually accurate help, examples, and explanations.&lt;/p&gt;
    &lt;p&gt;You can use the Erdos IDE for free. We only charge for usage of the Erdos AI assistant. Light usage of the Erdos AI assistant is free, but higher limits require a subscription. Please visit our Pricing page to learn more.&lt;/p&gt;
    &lt;p&gt;0.2.1&lt;/p&gt;
    &lt;p&gt;10-27-2025&lt;/p&gt;
    &lt;p&gt;0.2.0&lt;/p&gt;
    &lt;p&gt;10-27-2025&lt;/p&gt;
    &lt;p&gt;0.1.5&lt;/p&gt;
    &lt;p&gt;10-24-2025&lt;/p&gt;
    &lt;p&gt;0.1.4&lt;/p&gt;
    &lt;p&gt;10-22-2025&lt;/p&gt;
    &lt;p&gt;0.1.3&lt;/p&gt;
    &lt;p&gt;10-21-2025&lt;/p&gt;
    &lt;p&gt;0.1.2&lt;/p&gt;
    &lt;p&gt;10-20-2025&lt;/p&gt;
    &lt;p&gt;0.1.1&lt;/p&gt;
    &lt;p&gt;10-15-2025&lt;/p&gt;
    &lt;p&gt;0.1.0&lt;/p&gt;
    &lt;p&gt;10-13-2025&lt;/p&gt;
    &lt;p&gt;Try Erdos now.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.lotas.ai/erdos"/><published>2025-10-27T16:08:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45722639</id><title>Claude for Excel</title><updated>2025-10-27T22:37:49.806461+00:00</updated><content>&lt;doc fingerprint="3d3f8e961dffc20a"&gt;
  &lt;main&gt;
    &lt;p&gt;Piloting Claude for Excel&lt;/p&gt;
    &lt;p&gt;Claude understands your entire workbook√¢from nested formulas to multiple tab dependencies. Get explanations with cell-level citations, and update assumptions while preserving formulas. Now in beta as a research preview.&lt;/p&gt;
    &lt;head rend="h2"&gt;How teams use Claude for Excel&lt;/head&gt;
    &lt;p&gt;Claude listens carefully, follows instructions precisely, √¢¬®and thinks through complex problems.&lt;/p&gt;
    &lt;head rend="h3"&gt;Get answers about any cell in seconds&lt;/head&gt;
    &lt;p&gt;Navigate complex models instantly. Ask Claude about specific formulas, entire worksheets, or calculation flows across tabs. Every explanation includes cell-level citations so you can verify the logic.&lt;/p&gt;
    &lt;head rend="h3"&gt;Test scenarios without breaking formulas&lt;/head&gt;
    &lt;p&gt;Update assumptions across your entire model while preserving all dependencies. Test different scenarios quickly√¢Claude highlights every change with explanations for full transparency.&lt;/p&gt;
    &lt;head rend="h3"&gt;Debug and fix errors&lt;/head&gt;
    &lt;p&gt;Trace #REF!, #VALUE!, and circular reference errors to their source in seconds. Claude explains what went wrong and how to fix it without disrupting the rest of your model.&lt;/p&gt;
    &lt;head rend="h3"&gt;Build models or fill existing templates&lt;/head&gt;
    &lt;p&gt;Create draft financial models from scratch based on your requirements. Or populate existing templates with fresh data while maintaining all formulas and structure.&lt;/p&gt;
    &lt;p&gt;The Claude you trust, right in Excel&lt;/p&gt;
    &lt;head rend="h3"&gt;Transparency and visibility&lt;/head&gt;
    &lt;p&gt;See Claude√¢s changes in real time with explanations&lt;/p&gt;
    &lt;head rend="h3"&gt;Formula integrity&lt;/head&gt;
    &lt;p&gt;Maintain Excel model structure and formatting&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise security&lt;/head&gt;
    &lt;p&gt;Works within your existing compliance framework&lt;/p&gt;
    &lt;p&gt;FAQ&lt;/p&gt;
    &lt;p&gt;Claude for Excel is available in beta as a research preview through a waitlist for 1,000 Max, Team and Enterprise plan customers. We√¢ll gradually expand access as we build confidence through this limited preview.&lt;/p&gt;
    &lt;p&gt;Claude for Excel works within your existing security framework. Claude can make mistakes, so you should always review changes before finalizing, especially for client-facing deliverables.&lt;/p&gt;
    &lt;p&gt;Claude for Excel is currently in beta as a research preview, so it√¢s best for model analysis, assumption updates, error debugging, template population, formula explanations, multi-tab navigation. Claude doesn√¢t have advanced Excel capabilities including pivot tables, conditional formatting, data validation, data tables, macros, and VBA. We√¢re actively working on these features.&lt;/p&gt;
    &lt;p&gt;Yes, Claude is trained to recognize common financial modeling patterns, formula structures, and industry-standard calculations. However, always verify outputs match your specific methodologies.&lt;/p&gt;
    &lt;p&gt;Currently .xlsx and .xlsm files are supported. File size limits apply based on your Claude plan.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.claude.com/claude-for-excel"/><published>2025-10-27T16:09:22+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45722931</id><title>fnox, a secret manager that pairs well with mise</title><updated>2025-10-27T22:37:49.330386+00:00</updated><content>&lt;doc fingerprint="fb7f07ee0359b4a"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Introducing fnox: A secret manager that pairs well with mise #6779&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;I'm excited to announce fnox ‚Äì a new secret management tool designed to work seamlessly alongside mise in your development workflow.&lt;/p&gt;
          &lt;p&gt;While it's brand new, I have labeled it 1.0 since it seems pretty feature complete and given my experience with several experiments with secrets over the years with mise, I think will be a lot more stable than its young age would indicate.&lt;/p&gt;
          &lt;head&gt;What is fnox?&lt;/head&gt;
          &lt;p&gt;fnox (think "Fort Knox") is a command-line secret manager that handles encrypted and remote secrets for development, CI/CD, and production environments. It provides a unified interface for managing sensitive data through either local encryption or remote storage backends.&lt;/p&gt;
          &lt;head&gt;Why fnox?&lt;/head&gt;
          &lt;p&gt;While mise has built-in secret support (age encryption and sops), these work best for simple, file-based scenarios. For more complex production needs, fnox provides:&lt;/p&gt;
          &lt;head&gt;üöÄ Developer-Friendly&lt;/head&gt;
          &lt;head&gt;üë• Team-Ready&lt;/head&gt;
          &lt;head&gt;Getting Started&lt;/head&gt;
          &lt;p&gt;Install fnox with mise:&lt;/p&gt;
          &lt;code&gt;$ mise use -g fnox
$ fnox --version&lt;/code&gt;
          &lt;p&gt;Create your first secret:&lt;/p&gt;
          &lt;code&gt;$ fnox init
$ fnox provider add age --id main --recipients ~/.ssh/id_ed25519.pub
$ fnox secret set API_KEY --value "your-secret-value" --provider main&lt;/code&gt;
          &lt;p&gt;Use secrets in your workflow:&lt;/p&gt;
          &lt;code&gt;# Export secrets as environment variables
$ fnox exec -- your-command

# Get a single secret
$ fnox get API_KEY

# Shell integration (auto-load secrets on cd)
$ fnox shell hook&lt;/code&gt;
          &lt;head&gt;How It Works with mise&lt;/head&gt;
          &lt;p&gt;fnox and mise work independently but complement each other:&lt;/p&gt;
          &lt;p&gt;A typical setup:&lt;/p&gt;
          &lt;code&gt;[env]
NODE_ENV = "development"
DATABASE_HOST = "localhost"

[tools]
node = "20"
fnox = "latest"&lt;/code&gt;
          &lt;code&gt;[providers.age]
type = "age"
recipients = ["age1ql3z7..."]

[secrets]
DATABASE_PASSWORD = { provider = "age", value = "AGE-SECRET-KEY..." }
API_KEY = { provider = "1password", ref = "op://dev/api/credential" }&lt;/code&gt;
          &lt;p&gt;Then use both together:&lt;/p&gt;
          &lt;code&gt;$ mise x -- fnox x -- npm start&lt;/code&gt;
          &lt;p&gt;Or you can activate one or the other in your shell to avoid that.&lt;/p&gt;
          &lt;head&gt;Why Separate Tools?&lt;/head&gt;
          &lt;p&gt;You might wonder why fnox isn't built into mise. The answer comes down to fundamental architectural constraints:&lt;/p&gt;
          &lt;p&gt;The Performance Problem: mise reloads its environment frequently (on directory changes, after commands, etc.). If secrets relied on remote calls to services like KMS or 1Password, each reload would require network requests, making mise unacceptably slow.&lt;/p&gt;
          &lt;p&gt;The Security Tradeoff: Caching could solve the performance issue, but introduces security risks:&lt;/p&gt;
          &lt;p&gt;The Architecture Challenge: Making mise skip reloading certain env vars would require a major architectural overhaul‚Äîa change that would complicate the codebase significantly.&lt;/p&gt;
          &lt;p&gt;By creating fnox as a separate tool with its own shell integration, we avoid these problems entirely. Each tool can focus on what it does best:&lt;/p&gt;
          &lt;head&gt;What's going to happen to mise secrets?&lt;/head&gt;
          &lt;p&gt;They're still marked as experimental so the future is technically up in the air. That said, mise does work well for age/sops encryption so I think it could probably come out of experimental. For now, I don't have plans to introduce remote secret backends like fnox provides.&lt;/p&gt;
          &lt;head&gt;Learn More&lt;/head&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;Replies: 1 comment 1 reply&lt;/head&gt;
    &lt;p&gt;-&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;p&gt;Since it's a verbatim copy of https://secretspec.dev, any chance of giving attribution?&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Beta Was this translation helpful? Give feedback.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/jdx/mise/discussions/6779"/><published>2025-10-27T16:29:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723159</id><title>JetKVM ‚Äì Control any computer remotely</title><updated>2025-10-27T22:37:49.161730+00:00</updated><content>&lt;doc fingerprint="af5976106919f929"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Ultra-Low Latency&lt;/head&gt;
    &lt;p&gt;High-definition 1080p video at 60 FPS with 30-60 millisecond latency, using efficient H.264 encoding. Smooth mouse and keyboard action transfer for responsive remote interaction.&lt;/p&gt;
    &lt;head rend="h2"&gt;Free &amp;amp; Optional Cloud Access&lt;/head&gt;
    &lt;p&gt;Optional remote management via our open-source JetKVM Cloud using WebRTC. Privacy-first design with opt-in cloud access that provides secure and fast direct connections, even behind the most restrictive NAT environments, with our STUN and TURN servers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Open Source: Built for Collaboration&lt;/head&gt;
    &lt;p&gt;JetKVM is built on a robust Golang foundation and powered by Linux for adaptability and transparency. Whether you're a seasoned developer or an enthusiastic tinkerer, you can easily modify or fine-tune the software using familiar tooling and straightforward SSH uploads.&lt;/p&gt;
    &lt;head rend="h4"&gt;Available Source Code&lt;/head&gt;
    &lt;head rend="h5"&gt;KVM Runtime&lt;/head&gt;
    &lt;p&gt;Combining a Go-based backend with a React-powered WebRTC dashboard. Perfect for forking, submitting new features, fixing bugs, or customizing local streaming and control.&lt;/p&gt;
    &lt;head rend="h5"&gt;Cloud API &amp;amp; Dashboard&lt;/head&gt;
    &lt;p&gt;Our cloud-hosted management interface is fully open source. Delve into our secure remote connection orchestration or fork it to build specialized workflows and unique integrations.&lt;/p&gt;
    &lt;head rend="h5"&gt;Core System&lt;/head&gt;
    &lt;p&gt;Minimal Linux system built with BusyBox for core utilities. No bloat or unnecessary services - just the essential components needed for stable remote access.&lt;/p&gt;
    &lt;head rend="h2"&gt;Universally loved&lt;/head&gt;
    &lt;p&gt;Every single tech reviewer who's tested JetKVM has given it a glowing review. No exceptions. From professional data centers to home labs, the verdict is unanimous: this is the remote access solution the tech world has been waiting for.&lt;/p&gt;
    &lt;head rend="h2"&gt;Unlimited Hackability&lt;/head&gt;
    &lt;p&gt;The JetKVM hardware is fully customizable. Through the RJ12 extension port, extra hardware capabilities can easily be added by anyone. The JetKVM extension port is the way to fully customize your device.&lt;/p&gt;
    &lt;head rend="h2"&gt;Seamless Remote Control&lt;/head&gt;
    &lt;p&gt;Experience fluid control and crystal-clear video quality that makes remote access feel local. Perfect for IT professionals, developers, and power users who demand responsive remote management.&lt;/p&gt;
    &lt;head rend="h2"&gt;Stay updated on our latest projects&lt;/head&gt;
    &lt;p&gt;Join our newsletter to receive updates about new features, product launches, and early access opportunities.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jetkvm.com/"/><published>2025-10-27T16:44:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723359</id><title>Why Busy Beaver hunters fear the Antihydra</title><updated>2025-10-27T22:37:48.764303+00:00</updated><content>&lt;doc fingerprint="eeaad01055b00fc9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Busy Beaver Hunters Fear the Antihydra&lt;/head&gt;
    &lt;p&gt;In the summer of 2024, I reported on an online community that nailed down the precise value of a number called BB(5) ‚Äî the first big breakthrough in 50 years on an old problem in theoretical computer science known as the busy beaver game. BB(5), now known to be 47,176,870, is the fifth of the so-called busy beaver numbers, which measure the complexity of the craziest computations that simple computer programs can complete.1The team recently released a paper describing their results in detail.&lt;/p&gt;
    &lt;p&gt;The next step in this idiosyncratic research effort is to identify the sixth busy beaver number BB(6), and there has been some notable progress on that front ‚Äî I wrote a follow-up story about it a few months ago. But busy beaver researchers don‚Äôt expect to nail down the true value of BB(6) any time soon. That‚Äôs because doing so would require them to understand the behavior of a program with the awesome name ‚ÄúAntihydra,‚Äù which resembles a longstanding open problem in mathematics called the Collatz conjecture.2Antihydra should not be confused with the false hydra, a very cool and very terrifying monster conceived by D&amp;amp;D blogger Arnold Kemp. A twitter user sharing my first busy beaver story summed up this state of affairs more succinctly:&lt;/p&gt;
    &lt;p&gt;Both of my stories alluded to the Antihydra barrier only very briefly. In this blog post I will explore it in more detail: What exactly is Antihydra, what is the Collatz conjecture, how are they connected, and what makes them so daunting?&lt;/p&gt;
    &lt;head rend="h2"&gt;Busy Beaver Basics&lt;/head&gt;
    &lt;p&gt;If you haven‚Äôt already read my two Quanta stories about the busy beaver game, I recommend doing so before reading further, mainly just because they‚Äôre both really fun! Here I‚Äôll recap how the busy beaver game works so that we‚Äôre all on the same page.&lt;/p&gt;
    &lt;p&gt;I wrote above that the busy beaver numbers ‚Äúmeasure the complexity of the craziest computations that simple computer programs can complete.‚Äù To define them more precisely, we first need a mathematical framework for gauging the complexity of computer programs themselves, to decide which ones are ‚Äúsimple.‚Äù Then we need a way to quantify the complexity of computations ‚Äî what computer programs do ‚Äî so that we can identify the craziest ones.&lt;/p&gt;
    &lt;p&gt;In the busy beaver game, computer programs are represented by hypothetical devices called Turing machines, which compute in discrete steps by reading and writing 0s and 1s on an infinite tape divided into cells. A unique list of rules governs the behavior of each Turing machine. Anything you can do with an ordinary computer program, you can in principle do with the right set of Turing machine rules.3In the busy beaver literature, these rules are called ‚Äústates.‚Äù ‚ÄúIn principle‚Äù is doing a lot of work in this sentence ‚Äî even if you managed to acquire the requisite infinite tape, computing with a Turing machine would be horrendously inefficient. But Turing machines are easier to analyze theoretically than more practical programming languages.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs unpack how Turing machines work in a bit more detail. At each step, a Turing machine consults one of its rules and edits one cell on the tape. Each rule has two cases: what to do if the current cell contains a 0, and what to do if it contains a 1. ‚ÄúWhat to do‚Äù here means what to write in the current cell, which direction to move next, and which rule to consult for the next step. One case of one rule breaks this pattern: It tells the Turing machine to ‚Äúhalt,‚Äù or stop running. But by itself, the existence of this instruction doesn‚Äôt guarantee that a Turing machine will halt ‚Äî the machine might never get there. Quanta‚Äôs visual designer Kristina Armitage encapsulated all of this in a beautiful infographic.4In my first Busy Beaver story, you will also find animations of Turing machines in action.&lt;/p&gt;
    &lt;p&gt;The number of rules that a Turing machine has will be our measure of program complexity. This choice lets us replace our vague question about the craziest things that simple computer programs can do with a series of specific questions about different degrees of craziness, corresponding to different busy beaver numbers. You learn the value of BB(1) by answering the question ‚Äúwhat‚Äôs the most complex computation that a one-rule Turing machine can complete?‚Äù Likewise, BB(2) measures the most complex computation that a two-rule machine can complete, and so on.&lt;/p&gt;
    &lt;p&gt;To answer these questions, we need a precise definition of what makes one computation more complex than another. A natural measure is how many steps the Turing machine needs to complete the computation. ‚ÄúComplete‚Äù is important ‚Äî every Turing machine that never halts will run for infinitely many steps, but that‚Äôs not really a fair comparison. The number of steps that a Turing machine takes before halting (and indeed, whether it halts at all) can depend on the initial pattern of 0s and 1s on the tape. For the busy beaver game, we always start from the so-called ‚Äúblank tape,‚Äù which has 0s in every cell.&lt;/p&gt;
    &lt;p&gt;We now have all the necessary pieces to formally define the busy beaver numbers. Let‚Äôs take BB(6) to be specific: It is the longest finite runtime among all six-rule Turing machines, when those machines start with a blank tape. Finding this number is straightforward in principle. First, list out all possible six-rule Turing machines. Next, sort them into two categories: those that will eventually halt when they start running on the blank tape, and those that will run forever. Toss out all the non-halting machines. Finally, measure how many steps each of the halting machines takes before stopping. The largest number is BB(6).&lt;/p&gt;
    &lt;p&gt;The problem with this plan lies in the second step, where you divide the Turing machines into two groups based on whether or not they halt. It turns out that deciding whether a Turing machine will halt can be an extremely hard problem, to put it mildly. And if you can‚Äôt tell whether a given machine will halt, then you don‚Äôt know whether your list of halting Turing machines is complete, so you can‚Äôt know whether you‚Äôve found the longest runtime! As of this writing, researchers have classified the vast majority of six-rule machines as either halting or non-halting. But there are 1,618 ‚Äúholdouts‚Äù whose fate remains unknown.&lt;/p&gt;
    &lt;p&gt;Antihydra is one of these holdout machines. To nail down the value of BB(6), researchers must first determine whether Antihydra halts, and that seems to be beyond the reach of any known mathematical technique. To understand why, we need to take a step back and ask, ‚Äúwhat exactly are these Turing machines doing?‚Äù&lt;/p&gt;
    &lt;head rend="h2"&gt;Leveling Up&lt;/head&gt;
    &lt;p&gt;You may object at this point that we already know exactly what these Turing machines are doing: Each one is just following a specific sequence of rules, writing 0s and 1s on the tape as it goes. But this ‚Äúlow-level‚Äù description is a bit like saying ‚Äúwhen I push these buttons, my pocket calculator toggles transistors on and off in this specific pattern.‚Äù That may very well be true, but ‚Äúhigh-level‚Äù descriptions like ‚Äúwhen I push these buttons, my pocket calculator multiplies 3 and 4‚Äù are usually more useful.&lt;/p&gt;
    &lt;p&gt;There‚Äôs no guarantee that any given Turing machine‚Äôs behavior admits such a simple high-level description.5Also, in many cases low-level descriptions are perfectly adequate. For example, the easiest way to prove that a Turing machine halts is just to simulate it step by step until it stops running. When that happens, you don‚Äôt need a deeper understanding of why it halted: Just note its runtime and move on. But remember that Turing machines can carry out all possible computations ‚Äî that means that at least some Turing machines must be executing programs with high-level descriptions that humans can understand.&lt;/p&gt;
    &lt;p&gt;Actually, the most notable five- and six-rule Turing machines that busy beaver researchers have studied so far all have relatively simple high-level descriptions ‚Äî that includes the longest-running five- and six-rule machines that eventually halt, the most complex non-halting five-rule machines, and holdouts like Antihydra.6This is an empirical observation, not a self-evident truth. In fact, some researchers expected that the longest-running Turing machines would be ‚Äúspaghetti code‚Äù machines that lack any high-level description!&lt;/p&gt;
    &lt;p&gt;Let‚Äôs look at a specific example. The fifth busy beaver, which runs for 47,176,870 steps before halting, obeys the following low-level rules:&lt;/p&gt;
    &lt;p&gt;In 1993, the mathematician Pascal Michel proved that these rules are equivalent to a simple high-level program:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x = 0\).&lt;/item&gt;
      &lt;item&gt;Divide \(x\) by 3 and check the remainder. &lt;list rend="ul"&gt;&lt;item&gt;If the remainder is 0, calculate \((5x + 18)/3\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If the remainder is 1, calculate \((5x + 22)/3\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If the remainder is 2, halt.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;If you haven‚Äôt halted, go back to step 2 and plug in the new value of \(x\).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once you have a high-level description like this, you can use it to determine whether the machine will halt ‚Äî and if so, exactly how many steps it will take.7Each step in a high-level program like this one corresponds to many individual Turing machine steps. Whenever you prove an equivalence between high-level and low-level descriptions, you get formulas that you can use to compute how long each high-level step will take. I won‚Äôt say anything about how to actually prove these equivalences. In this case, the high-level program just repeatedly plugs in new values of \(x\) until it finds one that leaves a remainder of 2 when divided by 3. One third of numbers have this property, so you might guess that the program will take three tries to find one, give or take a few. If you start from a random value of \(x\), you‚Äôll find that three iterations is indeed typical. But it turns out that if you start from \(x = 0\), this program will repeat the second step 15 times before it lands on a number with remainder 2! Busy beaver researchers often like to anthropomorphize the Turing machines they study, imagining that the machines are actively trying to run for as long as possible. Adopting that perspective, we might say that this Turing machine got very lucky.&lt;/p&gt;
    &lt;p&gt;The fifth busy beaver is just one member of a family of ‚ÄúCollatz-like‚Äù Turing machines whose high-level behavior has the following general form:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x\) equal to some starting value (which may or may not be 0).&lt;/item&gt;
      &lt;item&gt;Divide \(x\) by a fixed number \(N\). The remainder tells you what formula to use to get your new value of \(x\).&lt;/item&gt;
      &lt;item&gt;Check if you‚Äôve met a specific halting condition. If not, go back to step 2 with the new value of \(x\).8As we saw in the above example, the halting condition can be as simple as ‚Äúthe remainder has a specific value.‚Äù Below we‚Äôll see some examples with different halting conditions.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The family of Collatz-like Turing machines includes both halting and non-halting machines. It gets its name from a procedure for generating number sequences devised in 1937 by the mathematician Lothar Collatz:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Choose a starting value for \(x\).&lt;/item&gt;
      &lt;item&gt;Check whether \(x\) is even or odd. &lt;list rend="ul"&gt;&lt;item&gt;If it‚Äôs even, calculate \(x/2\). The result is your new value of \(x\).&lt;/item&gt;&lt;item&gt;If it‚Äôs odd, calculate \(3x + 1\). The result is your new value of \(x\).&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Check whether \(x = 1\). If not, go back to step 2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This looks very similar to our general description of high-level behavior for Collatz-like machines, with \(x = 1\) as the halting condition.9‚ÄúCheck whether \(x\) is even or odd‚Äù is just another way of saying ‚Äúdivide \(x\) by 2 and check the remainder.‚Äù Strictly speaking, we don‚Äôt have to specify that the sequence stops when \(x = 1\). But if we keep applying the rules after it hits 1, the sequence enters an infinite loop: 1 &amp;gt; 4 &amp;gt; 2 &amp;gt; 1 and so on. Try iterating these rules from any initial integer value of \(x\) ‚Äî I‚Äôm willing to bet however much you like that you‚Äôll eventually hit 1. The Collatz conjecture asserts that this happens for every positive integer, no matter how large. People have tested this empirically for all integers up to at least 2 billion trillion (!) without finding any counterexamples, which strongly suggests that the conjecture is true. But nobody knows how to rigorously prove it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Cryptozoology&lt;/head&gt;
    &lt;p&gt;Let‚Äôs take a step back. At the beginning of this post I noted a link between the Collatz conjecture and Antihydra: Nobody knows how to prove the Collatz conjecture, and that‚Äôs why researchers don‚Äôt know how to conclusively determine whether Antihydra halts. But now I‚Äôve instead linked the Collatz conjecture to the fifth busy beaver, a machine that has been proved to halt. What‚Äôs going on here?&lt;/p&gt;
    &lt;p&gt;The resolution to this apparent puzzle is that for the busy beaver game, we only care about whether a Turing machine halts when it starts running from a specific tape configuration, namely the blank tape. That means we only care about whether the corresponding Collatz-like sequence halts for a single input. The Collatz conjecture, meanwhile, asks whether you eventually hit \(x = 1\) for every input. It‚Äôs easy to show that the Collatz sequence ultimately hits \(x = 1\) for any one input, just as it‚Äôs easy to show that the fifth busy beaver halts (once you‚Äôve established an equivalence between its low-level rules and the high-level Collatz-like program).10As it happens, the busy beaver hunters Heiner Marxen and J√ºrgen Buntrock first proved that the fifth busy beaver halted by direct simulation (albeit with some tricks to speed things up). Michel only identified its high-level behavior after the fact.&lt;/p&gt;
    &lt;p&gt;We can easily construct a variant of the Collatz problem that‚Äôs hard to solve even for a single input. All we need to do is change the \(3x + 1\) rule for odd numbers to \(5x + 1\). In that case, trajectories that start from certain inputs (such as \(x = 7\)) look like they will diverge, never hitting 1 or falling into a cycle. But researchers haven‚Äôt been able to prove that any of these trajectories diverges. There‚Äôs an inherent asymmetry here. If you want to prove that a sequence does eventually end up somewhere, you can always just use brute force, at least in principle. But if you want to prove that a sequence never terminates, even a single input can be hard.&lt;/p&gt;
    &lt;p&gt;We‚Äôre now finally ready to confront the terror that is Antihydra. It obeys the following high-level rules:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Set \(x = 8\).11This may seem like a weird starting point, given that we‚Äôre supposed to start with the blank tape in the busy beaver game. That‚Äôs still true here ‚Äî it‚Äôs just that Antihydra spends a while futzing around on the tape before it starts iterating this sequence, and the high-level effect of all that futzing is to set the starting value to 8.&lt;/item&gt;
      &lt;item&gt;Check whether \(x\) is even or odd. &lt;list rend="ul"&gt;&lt;item&gt;If it‚Äôs even, calculate \(3x/2\). The result is your new value of \(x\). Add one to a running tally of how many times you‚Äôve applied this even rule.&lt;/item&gt;&lt;item&gt;If it‚Äôs odd, calculate \((3x-1)/2\). The result is your new value of \(x\). Add one to a running tally of how many times you‚Äôve applied this odd rule.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Check whether your ‚Äúodd‚Äù count is more than twice as large as your ‚Äúeven‚Äù count. If so, halt. If not, go back to step 2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This is a very curious set of rules. The formulas \(3x/2\) and \((3x-1)/2\) don‚Äôt appear to systematically favor odd or even numbers, so you might expect that iterating them again and again will look like repeatedly flipping a coin and keeping track of how often you get heads versus tails. Early on in a sequence of coin flips, it‚Äôs distinctly possible that you‚Äôll end up with more than twice as many heads as tails. But if this doesn‚Äôt happen right away, it becomes less and less likely the longer you keep going. Researchers have now simulated the behavior of Antihydra out to more than 270 billion steps, and as expected, the ‚Äúeven‚Äù and ‚Äúodd‚Äù tallies are pretty close to equal ‚Äî nowhere near the extreme imbalance demanded by the halting condition. So it seems overwhelmingly likely that Antihydra never halts. But nobody knows how to prove it! The mathematician John Conway coined the delightful term ‚Äúprobviously‚Äù for situations like this ‚Äî ones where the specific problem of interest is very hard to solve, but probabilistic reasoning about the ‚Äútypical‚Äù behavior of similar problems makes the answer seem obvious.&lt;/p&gt;
    &lt;p&gt;Antihydra‚Äôs behavior is qualitatively similar to the \(5x + 1\) version of the Collatz conjecture, where we don‚Äôt know how to prove that any single trajectory diverges. I want to stress that as far as researchers know, there isn‚Äôt a more precise mathematical link between these two problems: If you resolved one of them, it wouldn‚Äôt automatically resolve the other. But the problems seem hard for very similar reasons. If someone does manage to prove the Collatz conjecture, the mathematical techniques used in the proof would likely be promising for the Antihydra problem (and vice versa).&lt;/p&gt;
    &lt;p&gt;Actually, Antihydra is just one of many probviously non-halting Turing machines with Collatz-like behavior. Busy beaver hunter Shawn Ligocki dubbed these machines ‚Äúcryptids‚Äù when they were first identified in variants of the standard busy beaver game.12These variants use extra tape symbols in addition to 0 and 1. For example, the BB(3,3) version of the busy beaver game studies the behavior of Turing machines with three rules that can read and write three symbols: 0, 1, and 2.&lt;/p&gt;
    &lt;p&gt;The first two cryptids to be discovered were named Bigfoot and Hydra;13Antihydra was named for a mathematical connection to Hydra. researchers have now identified so many cryptids that it no longer makes sense to give each one its own name. The existence of all these cryptids implies that busy beaver numbers beyond BB(5) will remain out of reach until researchers develop new mathematical tools for tackling Collatz-like problems. And the legendary mathematician Paul Erd≈ës reportedly said ‚ÄúMathematics may not be ready for such problems.‚Äù&lt;/p&gt;
    &lt;p&gt;But that doesn‚Äôt mean busy beaver hunters should give up. There‚Äôs still plenty of questions to explore in what might be called ‚Äúcryptid ecology.‚Äù How many subspecies of cryptids are there? How are they related to each other, and to other unsolved problems in mathematics beyond the Collatz conjecture? Since the beginning of the busy beaver game, avid hunters have repeatedly encountered surprising new Turing machine behavior, and that pattern shows no sign of letting up.&lt;/p&gt;
    &lt;p&gt;This past August I visited Tahquamenon Falls in Michigan‚Äôs upper peninsula, a part of the state that‚Äôs apparently an epicenter of bigfoot sightings. Fortunately I didn‚Äôt encounter any cryptids, but I did learn some new things about a few friendlier critters. Surprising discoveries can come from anywhere!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://benbrubaker.com/why-busy-beaver-hunters-fear-the-antihydra/"/><published>2025-10-27T16:56:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723426</id><title>Sieve (YC X25) is hiring engineers to build video datasets for frontier AI</title><updated>2025-10-27T22:37:48.665044+00:00</updated><content>&lt;doc fingerprint="7d518f497b3a37b"&gt;
  &lt;main&gt;
    &lt;p&gt;High quality video data for AI applications.&lt;/p&gt;
    &lt;p&gt;500K hours of high quality, diverse video clips.&lt;/p&gt;
    &lt;p&gt;Contact us to request a sample or explore more options.&lt;/p&gt;
    &lt;p&gt;Purpose-built video understanding models paired with human QA help find just the highest quality, training-ready data.&lt;/p&gt;
    &lt;p&gt;Our growing library consists of thousands of petabytes of video data.&lt;/p&gt;
    &lt;p&gt;Video is collected from a variety of public, private, and synthetic sources.&lt;/p&gt;
    &lt;p&gt;New data shapes to unlock new model capabilities (paired, time-synced, conversational, and more).&lt;/p&gt;
    &lt;p&gt;Contact us to request a sample or explore more options.&lt;/p&gt;
    &lt;p&gt;Purpose-built video understanding models paired with human QA help find just the highest quality, training-ready data.&lt;/p&gt;
    &lt;p&gt;Our growing library consists of thousands of petabytes of video data.&lt;/p&gt;
    &lt;p&gt;Video is collected from a variety of public, private, and synthetic sources.&lt;/p&gt;
    &lt;p&gt;New data shapes to unlock new model capabilities (paired, time-synced, conversational, and more).&lt;/p&gt;
    &lt;p&gt;Explore pre-packaged datasets to determine which you are interested in.&lt;/p&gt;
    &lt;p&gt;Enter a purchase agreement based on dataset volume and characteristics.&lt;/p&gt;
    &lt;p&gt;Receive data within 1-2 days via storage bucket access.&lt;/p&gt;
    &lt;p&gt;Scalable API&lt;/p&gt;
    &lt;p&gt;Built to process millions of hours of video at any given moment.&lt;/p&gt;
    &lt;p&gt;Compliant&lt;/p&gt;
    &lt;p&gt;Request specific filtering and licensing needs to ensure full permission and compliance of your training data.&lt;/p&gt;
    &lt;p&gt;Dedicated partnership&lt;/p&gt;
    &lt;p&gt;We partner deeply with every research team to understand their needs and develop data with the same rigor they develop models.&lt;/p&gt;
    &lt;p&gt;Secure&lt;/p&gt;
    &lt;p&gt;End-to-end encryption, custom data retention, and SOC 2 Type 2 secured.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sievedata.com/"/><published>2025-10-27T17:01:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723533</id><title>Show HN: Git Auto Commit (GAC) ‚Äì LLM-powered Git commit command line tool</title><updated>2025-10-27T22:37:47.920855+00:00</updated><content>&lt;doc fingerprint="a4346c4380a8f88e"&gt;
  &lt;main&gt;
    &lt;p&gt;LLM-powered commit messages that understand your code.&lt;/p&gt;
    &lt;p&gt;Tired of writing commit messages? Replace &lt;code&gt;git commit -m "..."&lt;/code&gt; with &lt;code&gt;gac&lt;/code&gt; for contextual, well-formatted commit messages generated by large language models.&lt;/p&gt;
    &lt;p&gt;Intelligent, contextual messages that explain the why behind your changes:&lt;/p&gt;
    &lt;code&gt;uvx gac init  # Configure your LLM provider
uvx gac  # Generate and commit with LLM&lt;/code&gt;
    &lt;p&gt;That's it! Review the generated message and confirm with &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;uv tool install gac
gac init
gac&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Anthropic ‚Ä¢ Cerebras ‚Ä¢ Chutes.ai ‚Ä¢ Fireworks ‚Ä¢ Gemini&lt;/item&gt;
      &lt;item&gt;Groq ‚Ä¢ LM Studio ‚Ä¢ MiniMax ‚Ä¢ Ollama ‚Ä¢ OpenAI ‚Ä¢ OpenRouter&lt;/item&gt;
      &lt;item&gt;Streamlake ‚Ä¢ Synthetic.new ‚Ä¢ Together AI ‚Ä¢ Z.AI ‚Ä¢ Z.AI Coding&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Understands intent: Analyzes code structure, logic, and patterns to understand the "why" behind your changes, not just what changed&lt;/item&gt;
      &lt;item&gt;Semantic awareness: Recognizes refactoring, bug fixes, features, and breaking changes to generate contextually appropriate messages&lt;/item&gt;
      &lt;item&gt;Intelligent filtering: Prioritizes meaningful changes while ignoring generated files, dependencies, and artifacts&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;One-liner (-o flag): Single-line commit message following conventional commit format&lt;/item&gt;
      &lt;item&gt;Standard (default): Summary with bullet points explaining implementation details&lt;/item&gt;
      &lt;item&gt;Verbose (-v flag): Comprehensive explanations including motivation, technical approach, and impact analysis&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Interactive feedback: Regenerate messages with specific requests like &lt;code&gt;r "make it shorter"&lt;/code&gt;or&lt;code&gt;r "focus on the bug fix"&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;One-command workflows: Complete workflows with flags like &lt;code&gt;gac -ayp&lt;/code&gt;(stage all, auto-confirm, push)&lt;/item&gt;
      &lt;item&gt;Git integration: Respects pre-commit and lefthook hooks, running them before expensive LLM operations&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Automatic secret detection: Scans for API keys, passwords, and tokens before committing&lt;/item&gt;
      &lt;item&gt;Interactive protection: Prompts before committing potentially sensitive data with clear remediation options&lt;/item&gt;
      &lt;item&gt;Smart filtering: Ignores example files, template files, and placeholder text to reduce false positives&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;# Stage your changes
git add .

# Generate and commit with LLM
gac

# Review ‚Üí y (commit) | n (cancel) | r (reroll)&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Command&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Generate commit message&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -y&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Auto-confirm (no review needed)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -a&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Stage all before generating commit message&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -o&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;One-line message for trivial changes&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -v&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Verbose format with Motivation, Technical Approach, and Impact Analysis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -h "hint"&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Add context for LLM (e.g., &lt;code&gt;gac -h "bug fix"&lt;/code&gt;)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -s&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Include scope (e.g., feat(auth):)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;gac -p&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Commit and push&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;code&gt;# Complete workflow in one command
gac -ayp -h "release preparation"

# Detailed explanation with scope
gac -v -s

# Quick one-liner for small changes
gac -o

# Debug what the LLM sees
gac --show-prompt

# Skip security scan (use carefully)
gac --skip-secret-scan&lt;/code&gt;
    &lt;p&gt;Not happy with the result? Use the reroll feature for intelligent regeneration:&lt;/p&gt;
    &lt;code&gt;# Simple reroll
r

# With specific feedback
r make it shorter and focus on the performance improvement
r use conventional commit format with scope
r explain the security implications&lt;/code&gt;
    &lt;p&gt;Run &lt;code&gt;gac init&lt;/code&gt; to configure your provider interactively, or set environment variables:&lt;/p&gt;
    &lt;code&gt;# Example configuration
GAC_MODEL=anthropic:your-model-name
OPENAI_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here&lt;/code&gt;
    &lt;p&gt;See &lt;code&gt;.gac.env.example&lt;/code&gt; for all available options.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Full documentation: USAGE.md - Complete CLI reference&lt;/item&gt;
      &lt;item&gt;Troubleshooting: TROUBLESHOOTING.md - Common issues and solutions&lt;/item&gt;
      &lt;item&gt;Contributing: CONTRIBUTING.md - Development setup and guidelines&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Made with ‚ù§Ô∏è for developers who want better commit messages&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/cellwebb/gac"/><published>2025-10-27T17:07:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723554</id><title>Avoid 2:00 and 3:00 am cron jobs (2013)</title><updated>2025-10-27T22:37:47.772328+00:00</updated><content>&lt;doc fingerprint="fe50537ca9a4b4f6"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Avoid 2:00 and 3:00 am cron jobs!&lt;/head&gt;
    &lt;p&gt;A word to the wise: Do not set any cron jobs for 2:00 am or 3:00 am on Sunday morning! Or to be safe, on other mornings besides Sunday as well, since jobs originally set to run on some particular day may eventually be changed to run on another day, or every day.&lt;/p&gt;
    &lt;p&gt;Most of the time such cron jobs will run fine, but if they run every Sunday morning, then twice per year they will run at the exact time daylight savings time (aka summer time) kicks in or ends, sometimes with very strange results.&lt;/p&gt;
    &lt;p&gt;On Linux with vixie-cron we saw two cron jobs run something like once per second between 3:00 and 3:01 when the most recent daylight savings time began. Thus they ran about 60 times, stepping all over each other and making a noisy mess in email. No serious harm was done, but that√¢s only because they were not tasks capable of causing serious harm.&lt;/p&gt;
    &lt;p&gt;Feel free to wish for or agitate for or fund or write a better open source job scheduler that everyone will use, one that will ensure no overlapping runs, allow specifying time limits, etc. Better tools exist, but until one of them achieves cron√¢s level of ubiquity, we have to live with cron at least some places and sometimes.&lt;/p&gt;
    &lt;p&gt;Alternatively, where possible set the server timezone to UTC so that no daylight savings changes will happen at all.&lt;/p&gt;
    &lt;p&gt;Or most preferable: Governments of the world, stop the twice-yearly dance of daylight saving time altogether.&lt;/p&gt;
    &lt;p&gt;But in the meantime this particular problem can be entirely avoided by just not scheduling any cron jobs to run on Sunday morning at 2:00 or 3:00 server time.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.endpointdev.com/blog/2013/04/avoid-200-and-300-am-cron-jobs/"/><published>2025-10-27T17:08:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723558</id><title>Artificial Writing and Automated Detection [pdf]</title><updated>2025-10-27T22:37:47.182972+00:00</updated><content/><link href="https://www.nber.org/system/files/working_papers/w34223/w34223.pdf"/><published>2025-10-27T17:09:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723686</id><title>The new calculus of AI-based coding</title><updated>2025-10-27T22:37:46.868203+00:00</updated><content>&lt;doc fingerprint="375020776f1115df"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Driving at 200mph&lt;/head&gt;
    &lt;p&gt;Here's where it gets interesting. A typical software team, even an experienced one, doesn't get things right all the time. Even with good testing and engineering practices, bugs occasionally make it through. We've all heard the phrase "testing in production." That reality is the main reason I've always believed that focusing on testing alone is not enough, and investing in blast radius and time to recovery is just as important.&lt;/p&gt;
    &lt;p&gt;AI assisted code is no different, it may contain bugs even when thoroughly reviewed by a human, and I suspect the probabilities are not significantly different. However, when teams ship commits at 10x the rate, the overall math changes. What used to be a production impacting bug once or twice a year, can become a weekly occurrence. Even if most bugs get caught in integration or testing environments, they will still impact the shared code base, requiring investigation and slowing the rest of the team down. Once again, this is not just hyperbole‚Äîour team sees signs that these are the challenges that pop up with a step function increase in throughput.&lt;/p&gt;
    &lt;p&gt;I am increasingly convinced that in order for agentic development to increase engineering velocity by an order of magnitude, we need to decrease the probability of problematic commits by an order of magnitude too. And likely by even more than that, since at high velocities individual commits can begin interacting with each other in unexpected ways too.&lt;/p&gt;
    &lt;p&gt;In other words, driving at 200mph, you need a lot of downforce to keep the car on the track!&lt;/p&gt;
    &lt;head rend="h2"&gt;The Cost-Benefit Rebalance&lt;/head&gt;
    &lt;p&gt;One of the best ways to reduce the chance of bugs is to improve testing. I'm an airplane geek, and have always admired the testing ideas used by the airplane manufacturers. From early simulations, to component testing, to wind tunnel testing, to testing to breaking point, and ultimately test flights of fully assembled aircraft. Even flight simulators play a role in improving the overall safety of the industry. Some of these ideas have been tried in the software industry, but they are far from ubiquitous.&lt;/p&gt;
    &lt;p&gt;As an example, I've always liked "wind tunnel" style tests, that test fully assembled system in a controlled environment. To achieve that, one pattern I've used is implementing high fidelity "fake" versions of external dependencies that can be run locally. If you do that, you can then write build-time tests that run locally and verify end-to-end behavior of the whole system. You can even inject unexpected behaviors and failures into fake dependencies, to test how the system handles them. Such tests are easy to write and execute because they run locally, and they are great at catching those sneaky bugs in the seams between components.&lt;/p&gt;
    &lt;p&gt;Unfortunately, faking all the external dependencies isn't always easy for a service with moderate level of complexity. And even if you do, you now have to own keeping up with the real dependencies as they evolve. For those reasons, in my experience most teams don't write such tests.&lt;/p&gt;
    &lt;p&gt;I think we are seeing early signs that agentic coding can change the calculus here. AI agents are great at spitting out large volumes of code, especially when the desired behavior is well known and there's little ambiguity. Ideas that were sound in principle, but too expensive to implement and maintain just had their costs decrease by an order of magnitude. I really love riding such shifts in the industry, because they open the doors to new approaches that weren't practical in the past.&lt;/p&gt;
    &lt;p&gt;Our project (with the help of an AI agent) maintains fake implementations of external dependencies like authentication, storage, chain replication, and inference engine to be used in tests. We then wrote a test harness that uses those fakes to spin up our entire distributed system, including all the micro-services, on developers' machines. Build-time tests then spin up our canaries against that fully assembled stack verifying the system as a whole works.&lt;/p&gt;
    &lt;p&gt;I'm really bullish on this approach catching a category of bugs that in the past could only be caught once the change was committed and made it to the test environment. A few years ago, ideas like these would receive resistance as nice, but too expensive. This time around, it took just a few days to implement for a relatively complex system.&lt;/p&gt;
    &lt;head rend="h2"&gt;Driving Fast Requires Tighter Feedback Loop&lt;/head&gt;
    &lt;p&gt;Agentic coding changes that dynamic. In the amount of time it takes to build, package, and test one set of commits, another dozen might be waiting to go out. By the time a change set is ready to deploy to production, it may contain 100 or more commits. And if one of those commits contains a problem, the deployment needs to be rolled back grinding the pipeline to a halt. In the meantime, even more changes accumulate, adding to the chaos and the risk.&lt;/p&gt;
    &lt;p&gt;I'm a Formula 1 fan, and this reminds me of how an accident on the track can cause a Yellow Flag to be raised. Normally, the cars zoom around the track at immense speeds and accelerations. But if an accident occurs, the race marshals raise a yellow flag, which requires all the cars to slow down behind the pace car. An exciting race turns into a leisurely drive around the track until the debris is cleaned up and the track is safe again. To minimize such slow downs, race organizers go to great lengths to prepare for all types of accidents, and make sure they can clean up the track and restart the race in minutes.&lt;/p&gt;
    &lt;p&gt;Just like whole-system local tests help tighten the feedback loop for catching certain bugs, we may need to think similarly about how we implement our CICD pipelines. When teams are moving at the speed of dozen of commits per hour, problematic issues will need to be identified, isolated, and reverted in minutes instead of hours or days. That means that a typical build and test infrastructure will need to become an order of magnitude faster than it is today. Just like online video games become unplayable when there is high lag between player's inputs and the game's reaction, it's really hard to move 10x faster if every commit still requires a lengthy delay before you see the feedback.&lt;/p&gt;
    &lt;head rend="h2"&gt;The communication bottleneck&lt;/head&gt;
    &lt;p&gt;I enjoy observing well-run operations. If you've ever peeked behind the curtain of a busy restaurant, then at first sight you may think it's chaos. But if you take a second to notice the details, you'll see that all members are constantly coordinating with each other. Chefs, cooks, wait staff, bussers, and managers pass information back and forth in a continuous stream. By staying in constant sync, a well run restaurant manages to serve its patrons even during peak times, without sacrificing on quality or latency.&lt;/p&gt;
    &lt;p&gt;I believe that achieving similar increase in velocity for a software team requires constraints on how teams communicate. When your throughput increases by an order of magnitude, you're not just writing more code - you're making more decisions. Should we use this caching strategy or that one? How should we handle this edge case? What's the right abstraction here? At normal velocity, a team might make one or two of these decisions per week. At 10x velocity, they are making multiple each day.&lt;/p&gt;
    &lt;p&gt;The challenge is that many of these decisions impact what others are working on. Engineer A decides to refactor the authentication flow, which affects the API that Engineer B is about to extend. These aren't just implementation details - they're architectural choices that ripple through the codebase.&lt;/p&gt;
    &lt;p&gt;I find that traditional coordination mechanisms introduce too much latency here. Waiting for a Slack response or scheduling a quick sync for later in the day means either creating a bottleneck - the decision blocks progress - or risking going down the wrong path before realizing the conflict. At high throughput, the cost of coordination can dominate!&lt;/p&gt;
    &lt;p&gt;One approach is to eliminate coordination - if everybody works on independent components, they are unlikely to need to coordinate. But I find that ideal impractical in most real-world systems. So another alternative is to significantly decrease the cost of coordination. Our team sits on the same floor, and I think that's been critical to our velocity. When someone needs to make a decision that might impact others, they can walk over and hash it out in minutes in front of a whiteboard. We align on the approach, discuss trade-offs in real time, and both engineers get back to work. The decision gets made quickly, correctly, and without creating a pile-up of blocked work.&lt;/p&gt;
    &lt;p&gt;I recognize this doesn't solve the problem for distributed teams‚Äîthat remains an open challenge.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Path Forward&lt;/head&gt;
    &lt;p&gt;I'm really excited about the potential of agentic development. I think it has the capability to not only improve the efficiency of software development, but also allow us to tackle problems that were previously too niche or expensive to solve. The gains are real - our team's 10x throughput increase isn't theoretical, it's measurable.&lt;/p&gt;
    &lt;p&gt;But here's the critical part: these gains won't materialize if we simply bolt AI agents onto our existing development practices. Like adding a turbocharger to a car with narrow tires and old brakes, the result won't be faster lap times - it will be crashes. At 10x code velocity, our current approaches to testing, deployment, and team coordination become the limiting factors. The bottleneck just moves.&lt;/p&gt;
    &lt;p&gt;This means we need to fundamentally rethink how we approach building software. CICD pipelines designed for 10 commits per day will buckle under 100. Testing strategies that were "good enough" at normal velocity will let too many bugs through at high velocity. Communication patterns that worked fine before will create constant pile-ups of blocked work.&lt;/p&gt;
    &lt;p&gt;The good news is that we already have great ideas for comprehensive testing, rapid deployment, and efficient coordination - ideas that have shown promise but haven't seen wide adoption because they were too expensive to implement and maintain. What's changed is that agentic development itself can dramatically lower those costs. The same AI agents that are increasing our code throughput can also help us build the infrastructure needed to sustain that throughput.&lt;/p&gt;
    &lt;p&gt;This is the real opportunity: not just writing more code faster, but using AI to make previously impractical engineering practices practical. The teams that succeed with agentic development will be the ones who recognize that the entire software development lifecycle needs to evolve in concert.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.joemag.dev/2025/10/the-new-calculus-of-ai-based-coding.html"/><published>2025-10-27T17:17:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723699</id><title>MCP-Scanner ‚Äì Scan MCP Servers for vulnerabilities</title><updated>2025-10-27T22:37:46.669236+00:00</updated><content>&lt;doc fingerprint="1d5afd5c98027a90"&gt;
  &lt;main&gt;
    &lt;p&gt;A Python tool for scanning MCP (Model Context Protocol) servers and tools for potential security vulnerabilities. The MCP Scanner combines Cisco AI Defense inspect API, YARA rules and LLM-as-a-judge to detect malicious MCP tools.&lt;/p&gt;
    &lt;p&gt;The MCP Scanner provides a comprehensive solution for scanning MCP servers and tools for security vulnerabilities. It leverages three powerful scanning engines (Yara, LLM-as-judge, Cisco AI Defense) that can be used together or independently.&lt;/p&gt;
    &lt;p&gt;The SDK is designed to be easy to use while providing powerful scanning capabilities, flexible authentication options, and customization.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Multiple Modes: Run scanner as a stand-alone CLI tool or REST API server&lt;/item&gt;
      &lt;item&gt;Multi-Engine Security Analysis: Use all three scanning engines together or independently based on your needs.&lt;/item&gt;
      &lt;item&gt;Comprehensive Scanning: Scan MCP tools, prompts, and resources for security vulnerabilities&lt;/item&gt;
      &lt;item&gt;Explicit Authentication Control: Fine-grained control over authentication with explicit Auth parameters.&lt;/item&gt;
      &lt;item&gt;OAuth Support: Full OAuth authentication support for both SSE and streamable HTTP connections.&lt;/item&gt;
      &lt;item&gt;Custom Endpoints: Configure the API endpoint to support any Cisco AI Defense environments.&lt;/item&gt;
      &lt;item&gt;MCP Server Integration: Connect directly to MCP servers to scan tools, prompts, and resources with flexible authentication.&lt;/item&gt;
      &lt;item&gt;Customizable YARA Rules: Add your own YARA rules to detect specific patterns.&lt;/item&gt;
      &lt;item&gt;Comprehensive Vulnerability Reporting: Detailed reports on detected vulnerabilities.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Python 3.11+&lt;/item&gt;
      &lt;item&gt;uv (Python package manager)&lt;/item&gt;
      &lt;item&gt;A valid Cisco AI Defense API Key (optional)&lt;/item&gt;
      &lt;item&gt;LLM Provider API Key (optional)&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;uv venv -p &amp;lt;Python version less than or equal to 3.13&amp;gt; /path/to/your/choice/of/venv/directory
source /path/to/your/choice/of/venv/directory/bin/activate
uv pip install cisco-ai-mcp-scanner&lt;/code&gt;
    &lt;code&gt;git clone https://github.com/cisco-ai-defense/mcp-scanner
cd mcp-scanner
# Install with uv (recommended)

uv venv -p &amp;lt;Python version less than or equal to 3.13&amp;gt; /path/to/your/choice/of/venv/directory

source /path/to/your/choice/of/venv/directory/bin/activate

uv pip install .
# Or install in development mode
uv pip install -e .&lt;/code&gt;
    &lt;code&gt;Cisco AI Defense API (only required for API analyzer)
export MCP_SCANNER_API_KEY="your_cisco_api_key"
export MCP_SCANNER_ENDPOINT="https://us.api.inspect.aidefense.security.cisco.com/api/v1"
# For other endpoints please visit https://developer.cisco.com/docs/ai-defense/getting-started/#base-url&lt;/code&gt;
    &lt;p&gt;Tested LLMs: OpenAI GPT-4o and GPT-4.1&lt;/p&gt;
    &lt;code&gt;# AWS Bedrock Claude with AWS credentials (profile)
export AWS_PROFILE="your-profile"
export AWS_REGION="us-east-1"
export MCP_SCANNER_LLM_MODEL="bedrock/anthropic.claude-sonnet-4-5-20250929-v2:0" # Any AWS Bedrock supported model

# AWS Bedrock Claude with API key (Bearer token)
export MCP_SCANNER_LLM_API_KEY="bedrock-api-key-..." # Generated via Amazon Bedrock -&amp;gt; API Keys
export AWS_REGION="us-east-1"
export MCP_SCANNER_LLM_MODEL="bedrock/us.anthropic.claude-sonnet-4-5-20250929-v2:0" # Any AWS Bedrock supported model

# LLM Provider API Key (required for LLM analyzer)
export MCP_SCANNER_LLM_API_KEY="your_llm_api_key"  # OpenAI

# LLM Model Configuration (optional - defaults provided)
export MCP_SCANNER_LLM_MODEL="gpt-4o"  # Any LiteLLM-supported model
export MCP_SCANNER_LLM_BASE_URL="https://api.openai.com/v1"  # Custom LLM endpoint
export MCP_SCANNER_LLM_API_VERSION="2024-02-01"  # API version (if required)

# For Azure OpenAI (example)
export MCP_SCANNER_LLM_BASE_URL="https://your-resource.openai.azure.com/"
export MCP_SCANNER_LLM_API_VERSION="2024-02-01"
export MCP_SCANNER_LLM_MODEL="azure/gpt-4"

# For Extended Thinking Models (longer timeout)
export MCP_SCANNER_LLM_TIMEOUT=300&lt;/code&gt;
    &lt;p&gt;The fastest way to get started is using the &lt;code&gt;mcp-scanner&lt;/code&gt; CLI command. Global flags (like &lt;code&gt;--analyzers&lt;/code&gt;, &lt;code&gt;--format&lt;/code&gt;, etc.) must be placed before a subcommand.&lt;/p&gt;
    &lt;code&gt;# Scan well-known client configs on this machine
mcp-scanner --scan-known-configs --analyzers yara --format summary

# Stdio server (example using uvx mcp-server-fetch)
mcp-scanner --stdio-command uvx --stdio-arg=--from --stdio-arg=mcp-server-fetch --stdio-arg=mcp-server-fetch --analyzers yara --format summary

# Remote server (deepwiki example)
mcp-scanner --server-url https://mcp.deepwki.com/mcp --analyzers yara --format summary

# MCP Scanner as REST API
mcp-scanner-api --host 0.0.0.0 --port 8080
&lt;/code&gt;
    &lt;code&gt;import asyncio
from mcpscanner import Config, Scanner
from mcpscanner.core.models import AnalyzerEnum

async def main():
    # Create configuration with your API keys
    config = Config(
        api_key="your_cisco_api_key",
        llm_provider_api_key="your_llm_api_key"
    )

    # Create scanner
    scanner = Scanner(config)

    # Scan all tools on a remote server
    tool_results = await scanner.scan_remote_server_tools(
        "https://mcp.deepwki.com/mcp",
        analyzers=[AnalyzerEnum.API, AnalyzerEnum.YARA, AnalyzerEnum.LLM]
    )

    # Print tool results
    for result in tool_results:
        print(f"Tool: {result.tool_name}, Safe: {result.is_safe}")

    # Scan all prompts on a server
    prompt_results = await scanner.scan_remote_server_prompts(
        "http://127.0.0.1:8000/mcp",
        analyzers=[AnalyzerEnum.LLM]
    )

    # Print prompt results
    for result in prompt_results:
        print(f"Prompt: {result.prompt_name}, Safe: {result.is_safe}")

    # Scan all resources on a server
    resource_results = await scanner.scan_remote_server_resources(
        "http://127.0.0.1:8000/mcp",
        analyzers=[AnalyzerEnum.LLM],
        allowed_mime_types=["text/plain", "text/html"]
    )

    # Print resource results
    for result in resource_results:
        print(f"Resource: {result.resource_name}, Safe: {result.is_safe}, Status: {result.status}")

# Run the scanner
asyncio.run(main())&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;remote: scan a remote MCP server (SSE or streamable HTTP). Supports &lt;code&gt;--server-url&lt;/code&gt;, optional&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;stdio: launch and scan a stdio MCP server. Requires &lt;code&gt;--stdio-command&lt;/code&gt;; accepts&lt;code&gt;--stdio-args&lt;/code&gt;,&lt;code&gt;--stdio-env&lt;/code&gt;, optional&lt;code&gt;--stdio-tool&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;config: scan servers from a specific MCP config file. Requires &lt;code&gt;--config-path&lt;/code&gt;; optional&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;known-configs: scan servers from well-known client config locations on this machine; optional &lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;prompts: scan prompts on an MCP server. Requires &lt;code&gt;--server-url&lt;/code&gt;; optional&lt;code&gt;--prompt-name&lt;/code&gt;,&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;resources: scan resources on an MCP server. Requires &lt;code&gt;--server-url&lt;/code&gt;; optional&lt;code&gt;--resource-uri&lt;/code&gt;,&lt;code&gt;--mime-types&lt;/code&gt;,&lt;code&gt;--bearer-token&lt;/code&gt;.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Top-level flags (e.g., &lt;code&gt;--server-url&lt;/code&gt;, &lt;code&gt;--stdio-*&lt;/code&gt;, &lt;code&gt;--config-path&lt;/code&gt;, &lt;code&gt;--scan-known-configs&lt;/code&gt;) remain supported when no subcommand is used, but subcommands are recommended.&lt;/p&gt;
    &lt;code&gt;# YARA-only scan of all servers defined in well-known config locations
mcp-scanner --scan-known-configs --analyzers yara --format summary

# Detailed output
mcp-scanner --scan-known-configs --analyzers yara --detailed&lt;/code&gt;
    &lt;code&gt;# Expand ~ yourself if needed by your shell
mcp-scanner --config-path "$HOME/.codeium/windsurf/mcp_config.json" \
 --analyzers yara --format by_tool&lt;/code&gt;
    &lt;code&gt;# Use repeated --stdio-arg for reliable argument passing
mcp-scanner --analyzers yara --format summary \
  stdio --stdio-command uvx \
  --stdio-arg=--from --stdio-arg=mcp-server-fetch --stdio-arg=mcp-server-fetch

# Or list-form (ensure it doesn't conflict with later flags)
mcp-scanner --analyzers yara --detailed \
  stdio --stdio-command uvx \
  --stdio-args --from mcp-server-fetch mcp-server-fetch

# Scan only a specific tool on the stdio server
mcp-scanner --analyzers yara --format summary \
  stdio --stdio-command uvx \
  --stdio-arg=--from --stdio-arg=mcp-server-fetch --stdio-arg=mcp-server-fetch \
  --stdio-tool fetch&lt;/code&gt;
    &lt;code&gt;# Direct remote server with Bearer token
mcp-scanner --analyzers yara --format summary \
  remote --server-url https://your-mcp-server/sse --bearer-token "$TOKEN"

# Apply Bearer token to all remote servers discovered from configs
mcp-scanner --analyzers yara --detailed known-configs --bearer-token "$TOKEN"
mcp-scanner --analyzers yara --format by_tool \
  config --config-path "$HOME/.codeium/windsurf/mcp_config.json" --bearer-token "$TOKEN"&lt;/code&gt;
    &lt;code&gt;# Scan all prompts on an MCP server
mcp-scanner --analyzers llm prompts --server-url http://127.0.0.1:8000/mcp

# Scan all prompts with detailed output
mcp-scanner --analyzers llm --detailed prompts --server-url http://127.0.0.1:8000/mcp

# Scan all prompts with table format
mcp-scanner --analyzers llm --format table prompts --server-url http://127.0.0.1:8000/mcp

# Scan a specific prompt by name
mcp-scanner --analyzers llm prompts --server-url http://127.0.0.1:8000/mcp --prompt-name "greet_user"

# Get raw JSON output
mcp-scanner --analyzers llm --raw prompts --server-url http://127.0.0.1:8000/mcp&lt;/code&gt;
    &lt;code&gt;# Scan all resources on an MCP server
mcp-scanner --analyzers llm resources --server-url http://127.0.0.1:8000/mcp

# Scan all resources with detailed output
mcp-scanner --analyzers llm --detailed resources --server-url http://127.0.0.1:8000/mcp

# Scan all resources with table format
mcp-scanner --analyzers llm --format table resources --server-url http://127.0.0.1:8000/mcp

# Scan a specific resource by URI
mcp-scanner --analyzers llm resources --server-url http://127.0.0.1:8000/mcp \
  --resource-uri "file://test/document.txt"

# Scan with custom MIME type filtering
mcp-scanner --analyzers llm resources --server-url http://127.0.0.1:8000/mcp \
  --mime-types "text/plain,text/html,application/json"&lt;/code&gt;
    &lt;p&gt;The API server provides a REST interface to the MCP scanner functionality, allowing you to integrate security scanning into web applications, CI/CD pipelines, or other services. It exposes the same scanning capabilities as the CLI tool but through HTTP endpoints.&lt;/p&gt;
    &lt;code&gt;# Start the API server (loads configuration from .env file)
mcp-scanner-api --port 8000

# Or with custom host and port
mcp-scanner-api --host 0.0.0.0 --port 8080

# Enable development mode with auto-reload
mcp-scanner-api --reload&lt;/code&gt;
    &lt;p&gt;Once running, the API server provides endpoints for:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;/scan-tool&lt;/code&gt;- Scan a specific tool on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-all-tools&lt;/code&gt;- Scan all tools on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-prompt&lt;/code&gt;- Scan a specific prompt on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-all-prompts&lt;/code&gt;- Scan all prompts on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-resource&lt;/code&gt;- Scan a specific resource on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/scan-all-resources&lt;/code&gt;- Scan all resources on an MCP server&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;/health&lt;/code&gt;- Health check endpoint&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Documentation is available in docs/api-reference.md or as interactive documentation at &lt;code&gt;http://localhost:8000/docs&lt;/code&gt; when the server is running.&lt;/p&gt;
    &lt;p&gt;The scanner supports multiple output formats:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;summary&lt;/code&gt;: Concise overview with key findings&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;detailed&lt;/code&gt;: Comprehensive analysis with full findings breakdown&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;table&lt;/code&gt;: Clean tabular format&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;by_severity&lt;/code&gt;: Results grouped by severity level&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;raw&lt;/code&gt;: Raw JSON output&lt;/item&gt;
    &lt;/list&gt;
    &lt;code&gt;mcp-scanner --server-url http://127.0.0.1:8001/sse --format detailed&lt;/code&gt;
    &lt;code&gt;=== MCP Scanner Detailed Results ===

Scan Target: http://127.0.0.1:8001/sse

Tool: execute_system_command
Status: completed
Safe: No
Analyzer Results:
  ‚Ä¢ api_analyzer:
    - Severity: HIGH
    - Threat Summary: Detected 1 threat: security violation
    - Threat Names: SECURITY VIOLATION
    - Total Findings: 1
  ‚Ä¢ yara_analyzer:
    - Severity: HIGH
    - Threat Summary: Detected 2 threats: system access, command injection
    - Threat Names: SECURITY VIOLATION, SUSPICIOUS CODE EXECUTION
    - Total Findings: 2
  ‚Ä¢ llm_analyzer:
    - Severity: HIGH
    - Threat Summary: Detected 2 threats: prompt injection, tool poisoning
    - Threat Names: PROMPT INJECTION, SUSPICIOUS CODE EXECUTION
    - Total Findings: 2
&lt;/code&gt;
    &lt;code&gt;mcp-scanner --server-url http://127.0.0.1:8002/sse --format table&lt;/code&gt;
    &lt;code&gt;=== MCP Scanner Results Table ===

Scan Target: http://127.0.0.1:8002/sse

Scan Target                   Tool Name     Status     API      YARA     LLM      Severity
-----------------------------------------------------------------------------------------
http://127.0.0.1:8002/sse     exec_secrets  UNSAFE     HIGH     HIGH     HIGH     HIGH
http://127.0.0.1:8002/sse     safe_command  SAFE       SAFE     SAFE     SAFE     SAFE
&lt;/code&gt;
    &lt;p&gt;For detailed documentation, see the docs/ directory:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Architecture - System architecture and components&lt;/item&gt;
      &lt;item&gt;Authentication - OAuth and security configuration&lt;/item&gt;
      &lt;item&gt;Programmatic Usage - Programmatic usage examples and advanced usage&lt;/item&gt;
      &lt;item&gt;API Reference - Complete REST API documentation&lt;/item&gt;
      &lt;item&gt;Output Formats - Detailed output format options&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;https://www.cisco.com/site/us/en/products/security/ai-defense/index.html&lt;/p&gt;
    &lt;p&gt;Distributed under the &lt;code&gt;Apache 2.0&lt;/code&gt; License. See LICENSE for more information.&lt;/p&gt;
    &lt;p&gt;Project Link: https://github.com/cisco-ai-defense/mcp-scanner&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/cisco-ai-defense/mcp-scanner"/><published>2025-10-27T17:18:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723809</id><title>It's not always DNS</title><updated>2025-10-27T22:37:46.390991+00:00</updated><content>&lt;doc fingerprint="ff6191e30e531f83"&gt;
  &lt;main&gt;
    &lt;p&gt;I‚Äôve written down a new rule (no name, sorry) that I‚Äôll be repeating to myself and those around me. ‚ÄúIf you can replace ‚ÄòDNS‚Äô with ‚Äòkey value store mapping a name to an ip‚Äô and it still makes sense, it was not, in fact, DNS.‚Äù Feel free to repeat it along with me.&lt;/p&gt;
    &lt;p&gt;Sure, the ‚ÄúIt‚Äôs always DNS‚Äù meme is funny the first few hundred times you see it ‚Äì but what‚Äôs less funny is when critical thinking ends because a DNS query is involved. DNS failures are often the first observable problem because it‚Äôs one of the first things that needs to be done. DNS is fairly complicated, implementation-dependent, and at times ‚Äì frustrating to debug ‚Äì but it is not the operational hazard it‚Äôs made out to be. It‚Äôs at best a shallow take, and at worst actively holding teams back from understanding their true operational risks.&lt;/p&gt;
    &lt;p&gt;IP connectivity failures between a host and the rest of the network is not a reason to blame DNS. This would happen no matter how you distribute the updated name to IP mappings. Wiping out all the records during the course of operations due to an automation bug is not a reason to blame DNS. This, too, would happen no matter how you distribute the name to IP mappings. Something made the choice to delete all the mappings, and it did what you asked it to do&lt;/p&gt;
    &lt;p&gt;There‚Äôs plenty of annoying DNS specific sharp edges to blame when things do go wrong (like &lt;code&gt;8.8.8.8&lt;/code&gt; and &lt;code&gt;1.1.1.1&lt;/code&gt; disagreeing about resolving a domain
because of DNSSEC, or since we‚Äôre on the topic, a
DNSSEC rollout bricking prod for hours)
for us to be cracking jokes anytime a program makes a DNS request.&lt;/p&gt;
    &lt;p&gt;We can do better.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://notes.pault.ag/its-not-always-dns/"/><published>2025-10-27T17:25:52+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45723828</id><title>Let the little guys in: A context sharing runtime for the personalised web</title><updated>2025-10-27T22:37:46.023557+00:00</updated><content>&lt;doc fingerprint="af2d18541f732779"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Let the little guys in: &lt;lb/&gt; Towards a context sharing runtime for the personalised web&lt;/head&gt;
    &lt;p&gt;It‚Äôs easier than ever to build small tools. Npm, with 63 billion javascript package downloads in the last week, is a great example of the magic that happens when we can easily fork, share, find, use &amp;amp; compose small tools. It‚Äôs also a great example of what it‚Äôs missing - it‚Äôs hard to trust. Would you trust a new little wrapper or package with all of your bank statements, emails, and ChatGPT history?&lt;/p&gt;
    &lt;p&gt;Today, context is king, and OAuth dialogs are not enough to enable world-wide-web like participation in it.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs another idea: Instead of tightly controlling which applications have access to data, we need to control where applications can send it.&lt;/p&gt;
    &lt;p&gt;And in that (attestable) image, a new runtime environment is being forged. Not by me, but I buy into it, and I write this hoping that you might too.&lt;/p&gt;
    &lt;p&gt;Onto the first premise:&lt;/p&gt;
    &lt;head rend="h2"&gt;We‚Äôre far from realising the potential of computing&lt;/head&gt;
    &lt;p&gt;To really appreciate that potential, let‚Äôs imagine what it might feel like to have realised it.&lt;/p&gt;
    &lt;p&gt;Here‚Äôs one handle for your imagination: Imagine if ChatGPT worked perfectly, connected to everything, and knew everything about you.&lt;/p&gt;
    &lt;p&gt;Of course, you have to use your imagination there. ChatGPT is far from perfect. And‚Ä¶it never will be. In terms of sheer LLM horsepower, its ability to benefit from more parameters, and more thinking tokens, to think better and make up stuff less - we seem to be plateauing. As was the case for human beings ~300,000 years ago, the economics for making the brain bigger has basically stopped making sense.&lt;/p&gt;
    &lt;p&gt;So here‚Äôs the second handle for your imagination. Think of the last app you used. You have it? Great.&lt;/p&gt;
    &lt;p&gt;Now imagine you could in an instant, transform that app in any way you could imagine, to be better for you.&lt;/p&gt;
    &lt;p&gt;It‚Äôs quite a thing to think about. It is fun, so I would recommend it if you can spare some brain. Type your app here to seed some ideas.&lt;/p&gt;
    &lt;p&gt;For me, it was my Banking app. Here are some features I‚Äôd want:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;As above, I want my banking app to insert a little expandable badge beside every ‚Äúpay‚Äù button in my web browser, where it tells me how my current cart or purchase is going to affect my budget or balance. This seems like obviously good UX. In games, I‚Äôve never seen a shop interface that doesn‚Äôt show you your remaining cash balance - imagine how weird and bad it would be if you only got a notification after the fact.&lt;/item&gt;
      &lt;item&gt;I want to read a couple sentence summary each month that describes how that month‚Äôs gone, with respect to my long term financial goals - and any interesting spending trends that have emerged.&lt;/item&gt;
      &lt;item&gt;I want the ability to ask my bank things. For example: ‚Äúhow much did my cost of living change after moving to cape town?‚Äù or: ‚Äúsince I started seeing a dietician last year, how has that affected my spend on food?‚Äù or: ‚Äúhow much has my padel habit cost me?‚Äù&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;The features you‚Äôd want, might differ a lot! For example, maybe you‚Äôre better than me at budgeting and have different categories that you want to classify, by linking bank statement line items with the contents of order breakdowns in your email.&lt;/p&gt;
    &lt;p&gt;The point is - the ceiling is high, and we are a long way from it.&lt;/p&gt;
    &lt;head rend="h2"&gt;Why aren‚Äôt we further along?&lt;/head&gt;
    &lt;p&gt;Well, to meet all your unmet computing needs, you need a bunch more code, right?&lt;/p&gt;
    &lt;p&gt;Given how hard it‚Äôs been to write code, we‚Äôve largely outsourced the writing of it to a group of experts, within sprawling software companies, who are doing their best to Eat the World, with a side of Our Data, but who will never get around to their P3 backlog.&lt;/p&gt;
    &lt;p&gt;I don‚Äôt think my banking app will give me those features, ever.&lt;/p&gt;
    &lt;p&gt;And it‚Äôs not just the low priority stuff that companies are reticent to build.&lt;/p&gt;
    &lt;head rend="h3"&gt;We have different incentives to companies&lt;/head&gt;
    &lt;p&gt;Where our needs as a user intersect well with the making of profits‚Ä¶we are extremely well served. The size of this intersection is basically the extent of product-market fit. Companies tend to be amazing at: ‚ÄúMake it convenient for me to buy my first thing‚Ä¶and what else can you conveniently bundle in?‚Äù&lt;/p&gt;
    &lt;p&gt;Some needs are ignored - because code-writing capacity is finite, and pandering to niche user needs violates the pareto principle. Hotels will jump to put a mini-bar inside your room, but if that‚Äôs the only place you can get snacks, you‚Äôll never have wasabi peas.&lt;/p&gt;
    &lt;p&gt;Some needs are actively suppressed: "Make it easy for me to opt out‚Ä¶from your service, from a part of your service, or just from consuming too much‚Äù.&lt;/p&gt;
    &lt;head rend="h3"&gt;We don‚Äôt have to rely on companies to write code&lt;/head&gt;
    &lt;p&gt;We already rely a lot on open source for our most crucial code - at the heart of our operating systems.&lt;/p&gt;
    &lt;p&gt;For example, here is the source code of Android, which is almost 200 million lines of code, and which stands on the shoulders of other open source projects like Linux (which runs most computers in the Cloud).&lt;/p&gt;
    &lt;p&gt;Most linux development today is funded via for-profit companies, who benefit from Linux meeting their or their customers needs. But the first version was made by one dude to meet his own needs, who posted it on a forum.&lt;/p&gt;
    &lt;p&gt;Today, facilitated by LLM‚Äôs, many more people can write little scripts to meet their own needs. Via open source, that code can be cleaned up and grow to meet bigger needs, for bigger audiences. We can also make little edits to the code to fit our own needs.&lt;/p&gt;
    &lt;p&gt;But open source software is often outcompeted by closed source software. There‚Äôs a reason why people use MS office or Google to make a &lt;del&gt;powerpoint&lt;/del&gt; presentation, and not the many attempts at open source alternatives. Sometimes, the polish required for these products is boring and difficult. Open source software is good for interesting things. Vibe coding is good for small things.&lt;/p&gt;
    &lt;p&gt;So ideally, we want to be able to take code from all 3 places and combine them, via small wrappers, into more need-meeting, tailor-made software.&lt;/p&gt;
    &lt;p&gt;But code is only as useful as the information it has access to. And so access to information has become the limiting reagent in our computing.&lt;/p&gt;
    &lt;p&gt;This is especially the case with the new capabilities we have from LLM‚Äôs, to understand the depth of our own context and provide a whole new level of output tailoring.&lt;/p&gt;
    &lt;head rend="h3"&gt;Most of our data is sitting inside a few companies&lt;/head&gt;
    &lt;p&gt;Remember when we used to call Applications ‚ÄúPrograms‚Äù? Back then, they were just executable code that we‚Äôd run on our own computer.&lt;/p&gt;
    &lt;p&gt;Then we started owning multiple computers (including a pocket-sized one!), the Cloud formed, and javascript gave us web applications.&lt;/p&gt;
    &lt;p&gt;So what started as outsourcing code, became outsourcing the actual computing, and most of our data storage, to companies, who could offer the convenience and profitability of a 1-stop-computing-shop.&lt;/p&gt;
    &lt;p&gt;Today‚Äôs output becomes tomorrow‚Äôs input! So that data grows and grows, inside the same handful of big companies.&lt;/p&gt;
    &lt;p&gt;It seems to work for us too.&lt;/p&gt;
    &lt;p&gt;We prefer a handful of companies - because the fewer apps that have our data, the less exposed we feel.&lt;/p&gt;
    &lt;p&gt;We prefer big companies - because there is safety in numbers.&lt;/p&gt;
    &lt;p&gt;While anti-monopolistic regulation encourages better access to that data‚Ä¶that can only move the market so much.&lt;/p&gt;
    &lt;p&gt;And so:&lt;/p&gt;
    &lt;head rend="h3"&gt;Trust is our computing bottleneck&lt;/head&gt;
    &lt;p&gt;While it‚Äôs possible for my bank to implement these features, it‚Äôs probably not going to get them to me any time in the next few years (despite all the ‚ÄúAI enablement‚Äù and ‚Äúagentic transformation‚Äù going on there lol).&lt;/p&gt;
    &lt;p&gt;It‚Äôs actually also possible for these features to be coded up and bolted on, without needing anything from the bank.&lt;/p&gt;
    &lt;p&gt;But it‚Äôs too much work for me to code for myself - probably more work than me just looking at my own bank statements.&lt;/p&gt;
    &lt;p&gt;If someone else made a product (that I trusted), I‚Äôd pay for it.&lt;/p&gt;
    &lt;p&gt;If there was an open source product, that was easy to use (that I trusted), I would use it. I might even write a compatibility layer for my own South African bank‚Äôs statements.&lt;/p&gt;
    &lt;p&gt;I‚Äôm open to having it done via integration with ChatGPT too - using their new apps, which could integrate with a new web app and its associated browser extension, to enable these features.&lt;/p&gt;
    &lt;p&gt;But - it doesn‚Äôt exist. And the fundamental reason why‚Ä¶ is a lack of trust.&lt;/p&gt;
    &lt;p&gt;The new app would need direct access to your bank statements, emails, and chatbot history, and the content of every page you visit on your browser. It is way too hard for an upstart, even with a community behind them, to command the requisite trust.&lt;/p&gt;
    &lt;p&gt;Let‚Äôs not be hand-wavey about it - and be more precise what this web app would need to be entrusted to do.&lt;/p&gt;
    &lt;p&gt;(Expand to see why / how)&lt;/p&gt;
    &lt;head&gt;It needs to search through my email&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? When I buy something from amazon, it could be dog food or it could be a drone. Those feel like different spend categories. My email can be used to disambiguate this. Or it could just be used to receive bank statements.&lt;/item&gt;
      &lt;item&gt;How? For each bank item, search my email, and categorise it.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;It needs to pull in all my bank statements&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? It's the source of truth&lt;/item&gt;
      &lt;item&gt;How? This either needs to come in by digesting my monthly bank statement that's emailed, or using some third party API (like yodlee). Yodlee is expensive - but not that complicated. Under the hood, it literally just uses web scraping.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;It need to categorise each line item and save it to a database&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? The classification is too heavy to rerun every time data is required. It requires searching through emails. It might even require the user to label things.&lt;/item&gt;
      &lt;item&gt;How? A simple SQL database would do just fine&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;It needs understanding of my life - ideally from ChatGPT&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? I need to be able to correlate my financial data back to my life, including when I moved to cape town, where I went on holiday. This is all currently deducable from ChatGPT conversations. (WhatsApp could also work).&lt;/item&gt;
      &lt;item&gt;How? This is hard! There is no API access to conversations from ChatGPT. So the only way to do this, is to build a ChatGPT integration - to cross their moat on their terms, which is to have GPT-5 ferry across the data for you. So we can see that OpenAI is terribly misaligned with our needs here (and wait until the Ads!)&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;It needs a user interface that contains chat‚Ä¶but not only chat&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? Chat is not the best place to edit your financial goals - even though it might be a great way to set them via a journalling-like flow. It's not the best place to view a dashboard.&lt;/item&gt;
      &lt;item&gt;How? It needs to include a normal web app&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;It needs a browser extension that can show my remaining balance&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? A browser extension can understand every page you're on, and show an overlay&lt;/item&gt;
      &lt;item&gt;How? It would use some a small model to parse the HTML of every page. It would edit the HTML to show a balance overlay, and a little show notification on its little icon to provide evidence that it's the thing showing the overlay.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head&gt;It needs to not feel self hosted&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Why? The point of this whole thing is make our lives easier.&lt;/item&gt;
      &lt;item&gt;How? It's tricky‚Ä¶because if it's not self hosted, who are you going to trust with all this data?&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Our patterns for computing with sensitive data make this unfeasible.&lt;/p&gt;
    &lt;p&gt;Sometimes, like with ChatGPT conversations, we don‚Äôt have a key to the big company vaults where we keep our data safe.&lt;/p&gt;
    &lt;p&gt;And even when there is access via key, like with gmail, we must be very discerning before clicking ‚Äúyes‚Äù on an OAuth Dialog; minting a new key for that little banking add-on is quite a big risk.&lt;/p&gt;
    &lt;p&gt;Because once access is granted, it can never really be revoked. In the unlikely event that you do remember to change the locks after you retire the add-on, it could still retain your data. Because when the add-on has a key to your vault - even read-only access, it is impossible to know what they‚Äôll do with the data inside it. They can copy it. They can share it. They can sell it.&lt;/p&gt;
    &lt;p&gt;Yes, some of that‚Äôs illegal. But possession is 9/10ths of the law, and they have possession of our data. The courts are too weak to meaningfully enforce what web apps do, world-wide.&lt;/p&gt;
    &lt;p&gt;And the world-wideness of the web so useful, so formidable, and so precious; it‚Äôs given us 4 billion websites, many of them created by The Little Guys. In the era of LLM‚Äôs and of a hyper-personalised private web, we need to find a way for The Little Guys to be trusted enough with our data, to do their magic.&lt;/p&gt;
    &lt;head rend="h2"&gt;Enforcing conditions is better than handing out keys&lt;/head&gt;
    &lt;p&gt;Instead of choosing who to trust unconditionally with our data‚Ä¶why don‚Äôt we introduced a few conditions? With the right conditions, we can lower the bar enough to be open to the public, and all the well intentioned Little Guys.&lt;/p&gt;
    &lt;p&gt;We need a runtime environment with right conditions. The internet already got this far, via a well selected runtime environment: the browser‚Äôs javascript engine. Because of it, you can click a link, without thinking twice, and run code written by who-knows-who from who-knows-where on the world-wide-web, on your own personal computer, which has all kinds of sensitive information on it.&lt;/p&gt;
    &lt;p&gt;We need to add another runtime environment, with the right conditions. All your data should be moved into that runtime environment - so there is a well organised buffet available to any program you elect to click on.&lt;/p&gt;
    &lt;p&gt;What are the right conditions?&lt;/p&gt;
    &lt;p&gt;There is only one.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;You are not allowed to transmit or store my sensitive information anywhere (unless I give my consent).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Under this condition, sensitive information taints other information, as if it‚Äôs radioactive. Any other information it affects becomes sensitive itself, whether it‚Äôs an intermediate variable or a final output.&lt;/p&gt;
    &lt;p&gt;Isn‚Äôt that too restrictive?&lt;/p&gt;
    &lt;p&gt;Most code today is riddled with network requests. How can code shared with us be useful without them? Where is it supposed to send its output?&lt;/p&gt;
    &lt;p&gt;The code can still make network requests; it just can‚Äôt include sensitive data inside those network requests.&lt;/p&gt;
    &lt;p&gt;And it can still derive outputs, and store the outputs‚Ä¶within the runtime environment, which has its own encrypted database. That output, like all other sensitive information, can be decrypted by and revealed to the authenticated user, in any custom format. That format could be a web app. It could even be browser overlay on amazon.com‚Ä¶in a very clear, ringfenced way.&lt;/p&gt;
    &lt;p&gt;How do we enforce the conditions?&lt;/p&gt;
    &lt;p&gt;‚ÄúConsent‚Äù isn‚Äôt some flaccid banner blocking half the landing page; it must be demonstrably impossible to circumvent. To do this, we need to invoke two fairly low-key computing patterns&lt;/p&gt;
    &lt;p&gt;First, we need a reliable way to tell which information has been tainted as sensitive. For that, we turn to the field of Information flow, where there are well established mechanisms to evaluate the taint, in modern languages like javascript.&lt;/p&gt;
    &lt;p&gt;Then, we need a publicly verifiable proof that the runtime environment housing the information and running the code is actually enforcing the conditions as it promises - no more, no less, no different. Open sourcing the runtime environment is insufficient proof. For this, we need remote attestation, which can be performed within secure compute environments on most modern clouds.&lt;/p&gt;
    &lt;head rend="h3"&gt;How do we make this happen?&lt;/head&gt;
    &lt;p&gt;For this way of computing to gain any relevance, there needs to be a compelling enough sell to enough users.&lt;/p&gt;
    &lt;p&gt;That seems really, really hard.&lt;/p&gt;
    &lt;p&gt;Whatever the path is, I don‚Äôt see it clearly, but it seems to need to trace through two rough milestones.&lt;/p&gt;
    &lt;p&gt;1. An active community of technical users hacking away in it &lt;lb/&gt; Those in it might say: ‚ÄúI really buy into the principles of this thing. And it seems useful - look what that person made on it! It seems like a web version of claude code + skills + marketplace, but with an encrypted database, and permissions that let you feel safe using yolo mode. I‚Äôm going to try it.‚Äù&lt;/p&gt;
    &lt;p&gt;2. A breakout to heavy users of ChatGPT (et al), with a polished, managed product &lt;lb/&gt; At this juncture, a product manager type, for example, might say: ‚ÄúOh, wow, I see how this personalised web OS thing would be useful. Let me get out my credit card, bring all my data onto this thing, and try some of these plugins‚Äù.&lt;/p&gt;
    &lt;head rend="h4"&gt;Here are some questions that linger for me:&lt;/head&gt;
    &lt;p&gt;What should the value proposition of the polished, managed product be - and what might it replace (ChatGPT / Notion / Chrome / Tampermonkey)? Can you sell the long tail of features, as a killer feature? How might we aim smaller - should the first step be a standalone service that makes it vercel-easy to serve out of attestable images? How should schema sharing interleave with code sharing, to permit extensibility? What can we augment or transfer from Claude code - given what can already be hacked together there? Is taint tracking watertight enough? How different will runtime compatible code need to be, and what effect will that have on ease of writing/generating? Can/should people be financially incentivised to create useful programs to run in this environment? How can the environment permit sensitive data to leave, at the user‚Äôs behest, with graceful UX? How might a browser safely delineate what UI elements are generated from what code?&lt;/p&gt;
    &lt;p&gt;One thing is clear:&lt;/p&gt;
    &lt;head rend="h4"&gt;It‚Äôs going to take a community&lt;/head&gt;
    &lt;p&gt;It seems to be forming around Alex Komoroske‚Äôs public benefit corp, common.tools‚Ä¶which is where the central idea of an attestable exfiltration proof runtime environment above comes from.&lt;/p&gt;
    &lt;p&gt;After bumping against the trust problem myself, I signed up to the waitlist, which spawned a few really interesting conversations. Here's hoping there are a few more in the comments section! üòÄ&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://arjun.md/little-guys"/><published>2025-10-27T17:27:18+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45724045</id><title>Why Nigeria accepted GMOs</title><updated>2025-10-27T22:37:45.531644+00:00</updated><content>&lt;doc fingerprint="7a51905f08b75614"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why Nigeria Accepted GMOs&lt;/head&gt;
    &lt;head rend="h3"&gt;Genetically modified crops are finding a foothold in the Global South, producing some unlikely leaders in agritech.&lt;/head&gt;
    &lt;p&gt;By Dr. Alex Wakeman&lt;/p&gt;
    &lt;p&gt;Around 10,000 years ago, nomadic hunter-gatherers started to pick and eat the seeds of grasses, and the world hasn‚Äôt been the same since. The fertile rivers and reliable sun of the Middle East, China, and South America nurtured vast grasslands. The humans who settled there quickly developed a keen eye for harvesting and cultivating the largest, tastiest seeds, which meant that the following season, only those got sown. They did the same the next year and the next, over the generations, until we arrived at modern crops.&lt;/p&gt;
    &lt;p&gt;Around the Levant, this process of selecting for the most robust seeds created wheat; along the floodplains of the Yangtze, it created rice; and amidst the tropical foothills of the Mayan lowlands, it created maize. These three cereal crops alone make up around half of all the calories consumed by humans, and they constitute an even larger part of the diet in developing countries.&lt;/p&gt;
    &lt;p&gt;Today, climate change presents a steep challenge for agriculture, a practice that provides most of our food but, in return, demands arable land (which is decreasing), water (which is becoming less available), nitrogen (which, through its industrial byproducts, is a major pollutant), and protection from insects, disease, and weeds (often requiring pesticides, which are damaging to the environment and human health).1 Meanwhile, the world‚Äôs population is still growing, and around 2100, when global temperatures are projected to peak, there will be several billion more people on the planet.&lt;/p&gt;
    &lt;p&gt;As someone who has spent the last five years researching cereals, I‚Äôm all too aware that the challenge presented to modern plant scientists is almost paradoxical: to significantly increase cereal yields and feed the burgeoning population while using less land, water, nitrogen, and pesticides.&lt;/p&gt;
    &lt;p&gt;Fortunately, our understanding of evolution, genetics, and molecular biology has improved over the past 10,000 years, meaning we no longer rely just on visually apparent traits. We have now sequenced full genomes of all the major cereals and can map phenotypic traits like grain size or drought tolerance to individual genes. Furthermore, gene editing technologies such as CRISPR allow us to precisely edit these genes to create improved varieties. Genetic Modification (GM) technologies have already been used to make cereal varieties like high ‚Äúnitrogen use efficiency‚Äù rice, which requires less fertilizer, or ‚ÄúBt maize,‚Äù which produces a natural pesticide, reducing yield loss and pesticide use.&lt;/p&gt;
    &lt;p&gt;Before 2011, the majority of GM crops were grown in the global North; in countries like the U.S., Canada, and Spain. But today, GM harvests in the developing world have outstripped it. ‚ÄúBy 2023, the disparity between developing and developed countries reached 19.8 million hectares,‚Äù according to a 2024 review article,‚Äù with developing countries accounting for 54.78 percent of the total GM crop area.‚Äù&lt;/p&gt;
    &lt;p&gt;Indeed, much of the pioneering work on the adoption and regulation of GM crops is being done in the Global South, in countries that cannot afford to be risk-averse when it comes to agriculture. But the Global South, of course, is not heterogeneous. Each country represents a unique combination of history, political landscape, and cultural relationship with agriculture. Still, Global South countries can generally be said to possess low levels of food security, rapidly growing populations, and a high vulnerability to climate change.&lt;/p&gt;
    &lt;p&gt;One of the most impactful examples of the shift towards GM adoption in the Global South can be seen in Nigeria. A large, climate-stressed country, Nigeria is a major agricultural producer of, among other crops, cowpea, an orphan crop nicknamed ‚Äúpoor man‚Äôs meat‚Äù for its high protein content. It forms an essential part of the diet for around 200 million Sub-Saharan Africans, and Nigeria is its largest producer. However, yields are being decimated by drought and a variety of pests that have become more prevalent with shifting climes.2&lt;/p&gt;
    &lt;p&gt;Like almost all of Africa, prior to 2019, Nigeria had never grown any kind of GM food crop despite having an agricultural sector that constituted 22 percent of its GDP. But that year, the Nigerian government approved the cultivation of Bt cowpea. The Bt cowpea proved popular with farmers and is estimated to add $336 million to the Nigerian economy over the next 25 years. More importantly, the governmental bodies responsible, the National Biosafety Management Agency (NBMA, which regulates GM crops) and the National Biotechnology Research and Development Agency (NBRDA, which conducts research and field trials), demonstrated that they could safely develop and regulate Nigeria‚Äôs first GM crop for human consumption.&lt;/p&gt;
    &lt;p&gt;And success with Bt cowpeas quickly paved the way for other GM crops.&lt;/p&gt;
    &lt;p&gt;In 2024, Nigeria started growing its first GM cereal ‚Äî TELA maize3 ‚Äî which has proven resilient to both drought and several of the region‚Äôs most pernicious insect pests. Indeed, the TELA maize roll-out has been an epitome of scientific collaboration and realizing the ‚Äúpromise‚Äù of GM. Funding from groups like the Bill and Melinda Gates Foundation and USAID supported an international team of scientists from developing countries in creating crop varieties tailored to their own needs and environments, all while licensing the resulting seeds royalty-free.&lt;/p&gt;
    &lt;p&gt;The story of GM acceptance in Nigeria is worth a closer investigation, both for nations that may need to adopt GM crops to protect their agriculture against climate change, and for the countries that rely on their exports for both human food and animal fodder.&lt;/p&gt;
    &lt;head rend="h2"&gt;The Nigerian Journey&lt;/head&gt;
    &lt;p&gt;The TELA maize project began back in 2008. Around this time, scientists at the CIMMYT cereal research institute in Mexico ‚Äî together with collaborators in eight African nations ‚Äîwere researching a new GM variety of ‚Äúwater-efficient‚Äù maize called WEMA (Water Efficient Maize for Africa) that could better survive droughts.&lt;/p&gt;
    &lt;p&gt;One of the ways drought stunts growth or even kills plants is by preventing RNA from folding correctly, disrupting protein production. Water can form hydrogen bonds with the hydroxyl groups that form the backbone of RNA, and also interact with the hydrogen bonds between RNA bases. Dehydration thus destabilises the RNA structure and causes it to fold incorrectly, preventing it from carrying out its normal functions. To remediate this cellular stress, researchers introduced the ‚ÄúcspB‚Äù gene, encoding a chaperone protein that stabilizes RNA and helps it to fold correctly even under drought stress.&lt;/p&gt;
    &lt;p&gt;However, this new GM maize was too successful. ‚ÄúAfter [a] drought, insects had no better vegetation for miles ‚Ä¶ We lost five different field trials to the stemborer,‚Äù explained Dr. Sylvester Oikeh, who worked on the project. In other words, researchers had prevented the maize from succumbing to drought, only for it to become the healthiest, most delicious-looking plant to pests for miles.&lt;/p&gt;
    &lt;p&gt;Fortunately for the scientists working on WEMA, insect resistance was already one of the most widely understood and used GM modifications in the world. ‚ÄúBt‚Äù refers to the genetic modification that allows a crop to produce a natural protein insecticide, decreasing the need for chemical sprays.&lt;/p&gt;
    &lt;p&gt;It was first introduced in the context of Bt cotton, which now makes up as much as 90 percent of all cotton grown in India, China, and the U.S. It remains the world‚Äôs most successful GM modification, added to plants from tomato to soybean, reducing the world‚Äôs chemical pesticide use by almost half a million tons from 1996 to 2016. Bt is commonly inserted into the plants and ‚Äústacked‚Äù alongside other genes, thus creating crop varieties with multiple modifications. TELA, for example, contains both drought-resistant cspB and pest-resistant Bt genes.&lt;/p&gt;
    &lt;p&gt;Initially, Nigeria had not been part of the WEMA/TELA research project. In 2008, the country‚Äôs sentiments were still predominantly anti-GM. However, worsening climate conditions and pressure from scientists, struggling farmers, and a collapsing textiles industry pushed the country towards a breaking point.4 Between 1994 and 2005, for example, around 64 percent of Nigeria‚Äôs textile mills closed, and the looming collapse of the industry left the government little option but to permit Bt cotton in 2018. It was hoped that Bt cotton could increase cotton yields from the troublingly low 0.6-0.9 tonnes per hectare, while cutting pesticide spraying in half. Since then, Nigerian Bt cotton has been shown to produce 4.1 to 4.4 tonnes per hectare.&lt;/p&gt;
    &lt;p&gt;These encouraging results led Nigeria to ask to join the TELA project in 2019, and Nigeria‚Äôs Ahmadu Bello University became one of its major research hubs. The following year, the NBMA published guidance on genome editing (GE) technologies such as CRISPR, the first such guidelines published by an African government.&lt;/p&gt;
    &lt;p&gt;Before Nigeria could commercialize TELA maize, however, it needed to conduct extensive field trials. These ran for five years, and the data collected from the final stage trials showed maize yields increasing by as much as 19 percent more than the same maize lines without the Bt gene, and 40 percent more than other popular commercial varieties, when tested under real pest pressure. ‚ÄúThe farmers were so excited when they saw the outcome,‚Äù said Oikeh, ‚ÄúThere was a three-week drought when everything else died, and the TELA maize just stayed there.‚Äù&lt;/p&gt;
    &lt;p&gt;Nigeria is now conducting trials with several other GM crops in various stages of development and safety testing. As one of the world‚Äôs largest consumers of rice and Africa‚Äôs largest rice producer, Nigeria has been testing GM rice with improved Nitrogen Use Efficiency (NUE). This variety has been predicted to increase yields by as much as 25 percent, while reducing the use of nitrogen fertilizers. The NBMA has also started trials on the VIRCA Plus project, which aims to produce a GM cassava with increased iron and zinc levels, to help fight key nutritional deficiencies responsible for childhood stunting and high malarial mortality in West Africa.&lt;/p&gt;
    &lt;p&gt;Yet even successful field trials are not enough on their own to drive a shift to GM agriculture. The true adoption comes when farmers and consumers feel like GM is safe and effective.&lt;/p&gt;
    &lt;p&gt;Therefore, alongside the commercialization of TELA maize, the Nigerian government, in collaboration with NGOs like the Open Forum on Agricultural Biotechnology in Africa (OFAB) and the African Agricultural Technology Foundation (AATF), put greater effort into outreach and education to farmers and the Nigerian public. Farmers were consulted on their needs and concerns with WEMA and TELA maize, not only once it was ready for commercialization, but during the development stages as well. ‚ÄúWe also took politicians to the field to see the technology for themselves.‚Äù Dr. Oikeh explained. Seeing the education work as an essential and continual part of the GM process, he added: ‚ÄúRight now we are working on ways to help Nigerian farmers share their experience of TELA with their peers.‚Äù&lt;/p&gt;
    &lt;p&gt;In tandem with this outreach, the formation of a regulatory body like the NBMA also helped build public trust. Since its creation in 2015, the NBMA has monitored GM field trials, conducted lab analysis of GM crops, and developed plans to address potential risks associated with GM. The group inspects research facilities to ensure safety measures are followed and field trials to ensure the GM trial crops are contained. Following the commercialization of a GM crop, they meet with farmers to register their honest opinions and track yield changes, hoping to ensure greater independence from agritech companies‚Äô marketing for performance statistics.&lt;/p&gt;
    &lt;p&gt;The key to successful GM adoption appears to combine science-based biotech regulations, rigorous testing, and expansive education: all strategies that rely on government trust. However, this poses a significant problem in the Global South, where many countries that would benefit most from GM have low levels of government trust.&lt;/p&gt;
    &lt;p&gt;The ‚ÄúDemocracy Index‚Äù is a calculation that takes into account government trust, political participation, and government functioning. While Western Europe enjoys a mean democracy index of 8.4, more agriculturally dependent regions in the Global South, like South America and Sub-Saharan Africa, have indices of 5.6 and 4.0, respectively.&lt;/p&gt;
    &lt;p&gt;In general, a higher democracy index correlates with greater GM acceptance, although large differences exist between individual nations.5 South America contains both pro-GM and GM-skeptical nations. When comparing the two using the Democracy Index, however, the pro-GM countries have a consistently higher Democracy Index (6.8) than those that ban GM (4.4). Similarly, the mean Democracy Index for Sub-Saharan African countries that cultivate or are currently legislating towards GM crop cultivation (4.7) is higher than those that ban it (3.5).&lt;/p&gt;
    &lt;p&gt;This suggests that fostering democratic accountability is not simply a political good in itself, but also a precursor for enabling science-based agriculture. For countries looking to promote GM, the priority may not be exporting ‚Äúdemocracy‚Äù wholesale, but supporting governments in building credibility, transparency, and public trust ‚Äî the very conditions under which new technologies can take root.&lt;/p&gt;
    &lt;p&gt;Of course, GM-skeptical countries in the Global North, like those in Europe, have democracy index values significantly higher than almost any pro-GM developing country. But these countries also have the privilege of choice. Compared to South America or Sub-Saharan Africa, these countries import more of their food, have economies less dependent on agriculture, and are more capable of absorbing fluctuations in food prices as a result of climate disasters.&lt;/p&gt;
    &lt;p&gt;This brings up another critical point about why adoption in places like Nigeria surpasses that of these developed countries despite their good governance and technological capabilities ‚Äî incentives. Although the Global North has invested in high-margin GM opportunities, these countries haven‚Äôt turned to them for non-commodity staple crops because these crops simply aren‚Äôt big money makers. While modifications like Bt might reduce labor and input costs in developed countries, there has been insufficient evidence that genetically modified plants increase yields in the markets where they have now been used for decades.&lt;/p&gt;
    &lt;p&gt;By contrast, when people invoke the increased yields GM delivers in places like Nigeria, this is usually about preventing loss due to crop failure and pests. TELA maize was designed to withstand abiotic stress, and while researchers and farmers are hopeful that it will also be more highly productive even when there is not a severe drought, that remains to be seen. All that has been verified to date from data coming out of these current trials is that the GM crops are faring better than their non-GM counterparts.&lt;/p&gt;
    &lt;p&gt;Closely related to incentives, the GM rollouts in Nigeria also demonstrate where support stems from when need is great. Since countries in the Global South have to protect their populace from starvation and economic devastation from crop failure, public sector engagement is the driving force behind GM cultivation. This is not to say that absolute need is the only factor at play, but to emphasize that the forcing functions differ between a country like the U.S. and Nigeria. As the U.S. and other Global North countries increasingly feel the effects of climate on agriculture, however, their incentives might shift towards exploring GM, not so much to produce unbridled abundance, but to avoid harm.&lt;/p&gt;
    &lt;head rend="h2"&gt;A Globalization ‚ÄúProblem‚Äù&lt;/head&gt;
    &lt;p&gt;Nigeria is not alone in its incipient embrace of GM technology. Other countries that previously had blanket bans on GM are now trialing their first GM varieties, and countries that previously had limited GM cultivation are expanding the number of crops and varieties they permit. In 2017, Argentina, Bolivia, Brazil, Chile, Paraguay, and Uruguay signed a joint declaration aiming to unify their GM policies, resulting in more consistent, science-led assessment of new gene-edited crops across much of South America.&lt;/p&gt;
    &lt;p&gt;This acceptance seems bound to spread as the world‚Äôs agriculture is heavily globalized. While it is inspiring to see Global South nations using GM to protect their own food security, the adoption of this technology is not an issue for them alone. Even countries in the Global North that refuse to grow GM themselves import huge quantities of agricultural products, more and more of which are GM.&lt;/p&gt;
    &lt;p&gt;For instance, the notoriously anti-GM EU now imports 36 million tons of GM soybeans a year and recently greenlit the import of two new GM maize varieties, though only for animal feed. Or take Japan, a major importer of papaya from Hawaii. In the 1990s, Papaya Ringspot Virus almost wiped out Hawaii‚Äôs native Papaya industry, which spiked prices in Japan. Fortunately, researchers in Hawaii and at Cornell University had been working on a virus-resistant GM papaya for 14 years. In 1998, this variety was legalized and is widely considered to have single-handedly saved the Hawaiian papaya industry. Japan was more than happy to import the new virus-resistant GM variety and bring its food prices back down.&lt;/p&gt;
    &lt;p&gt;Another potential impact of growing GM acceptance around the world is that GM demand might not wait for GM approval and proper regulation. Borders are porous. Brazil first legalized GM soybeans because so many farmers were smuggling seeds across the border from pro-GM Argentina that there was no other choice but to admit that a significant amount of the country‚Äôs soybeans were already GM. Dr. Oikeh shared a similar observation regarding West African farmers. ‚ÄúI bet you farmers will come from Niger and buy the seeds ‚Ä¶ You can have police checking luggage across the border, but a pack of seeds is very small.‚Äù&lt;/p&gt;
    &lt;p&gt;It is unreasonable to expect impoverished farmers not to protect their livelihoods as they watch their neighbors benefit from GM technology. In 2022, after years of severe droughts, Kenya‚Äôs government reversed a 10-year ban on GM crops. Uganda shares a border with Kenya but has not yet joined them in permitting GM crop cultivation ‚Äî a choice that will have serious consequences. ‚ÄúNow that the Kenyans are free to grow GMOs, our farmers [in Uganda] will definitely look across ‚Ä¶ as their counterparts in Kenya will be reaping bountifully from their newfound seeds,‚Äù says Grace Lonyo Ocheng, principal Nutritionist at the Ugandan Ministry of Health. This is not only likely to increase the flow of smuggled, unregulated GM seeds into Uganda, but also decrease the market for Ugandan crops in East Africa, as Kenyan crops improve and the nation grows less reliant on imports.&lt;/p&gt;
    &lt;p&gt;Examples such as these emphasize the arbitrary yet consequential nature of borders. They also highlight that nations cannot naively think they will be unaffected by how GM agribusiness plays out elsewhere. Food supply chains and commodity exchanges are globalized, complicated systems, and proactive regulation is the sensible response. When a transgenic crop is developed in the U.S., regulated in the European Union, and squirreled into Niger, we must ask ourselves if we can‚Äôt surely devise a more efficient and reasonable approach.&lt;/p&gt;
    &lt;p&gt;New technologies, whether automated cotton mills, internal combustion engines, nuclear fission reactors, microchips, or GM crops, are all solutions to problems that may themselves create yet other problems. But whenever a new technology has improved the world, it has been through actively managing the negatives that arise rather than through discarding the technology entirely.&lt;/p&gt;
    &lt;p&gt;Pointing to the bottlenecks preventing us from fully benefiting from a new technology like GM is the easy (even fashionable) part. Actually removing them requires something that has been harder: we must allow GM technology to become part of ordinary life. It doesn‚Äôt deserve the fearmongering it continues to receive, nor is it a magic bullet. It is simply a tool. And as nations like Nigeria increasingly turn to this tool, we will become better able to assess the extent of its benefits and learn how to improve upon them in light of what we discover.&lt;/p&gt;
    &lt;p&gt;Dr. Alex Wakeman is a writer and researcher based in Leeds, UK. His PhD focused on plant perception of time and space.&lt;/p&gt;
    &lt;p&gt;Thanks to Eli Hornstein, Modesta Nnedinso Abugu, and Samuel Acheampong for providing feedback on this draft. Thanks to Sylvester Oikeh and Abraham Manalo for helpful discussions. Lead image by Ella Watkins-Dulaney.&lt;/p&gt;
    &lt;p&gt;Cite: Wakeman, Alex. ‚ÄúWhy Nigeria Accepted GMOs.‚Äù Asimov Press (2025). https://doi.org/10.62211/55gf-71kw&lt;/p&gt;
    &lt;p&gt;With that said, the Green Revolution of the 50s was able to use less land by using more water, fertilizer, and pesticides. Over the passing decades, however, the plentitude of these resources has changed. One example is our use of groundwater. A global analysis of ~170,000 wells shows rapid and widespread declines (&amp;gt;0.5 m/yr) in the 21st century and that depletion has accelerated in ~30 percent of the world‚Äôs aquifers ‚Äî especially in dry, crop-intensive regions. So while more-water intensive strategies may have aided agricultural productivity during the Green Revolution, the same approach would be feckless today given worsening droughts, draining aquifers, and rising temperatures.&lt;/p&gt;
    &lt;p&gt;Bruchid weevils, for example, lay their eggs on cowpea pods, and the hatching larvae burrow into the seeds, leaving them hollow and powdery.&lt;/p&gt;
    &lt;p&gt;TELA maize derives its name from the Latin word for protection ‚Äî tutela.&lt;/p&gt;
    &lt;p&gt;A set of conditions likely to repeat itself across the developing world over the coming years.&lt;/p&gt;
    &lt;p&gt;The global correlation between Democracy Index scores and GM adoption is weak (r ‚âà 0.2) ‚Äî in part because many nations with high democracy indices, especially in the European Union, have not accepted GMOs ‚Äî but regional patterns are stronger. The contrast is particularly evident when comparing countries within South America and Sub-Saharan Africa, where pro-GM nations do show consistently higher democracy scores than their GM-skeptical neighbors. Even so, the democracy-GM relationship should be understood as one contextual factor among many, rather than a universal predictor of GM policy.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.asimov.press/p/nigeria-crops"/><published>2025-10-27T17:42:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45725009</id><title>Study finds growing social circles may fuel polarization</title><updated>2025-10-27T22:37:45.250498+00:00</updated><content>&lt;doc fingerprint="b71dc3835465878d"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;More friends, more division: Study finds growing social circles may fuel polarization&lt;/head&gt;
    &lt;head rend="h5"&gt;Sadie Harley&lt;/head&gt;
    &lt;p&gt;scientific editor&lt;/p&gt;
    &lt;head rend="h5"&gt;Robert Egan&lt;/head&gt;
    &lt;p&gt;associate editor&lt;/p&gt;
    &lt;p&gt;Between 2008 and 2010, polarization in society increased dramatically alongside a significant shift in social behavior: the number of close social contacts rose from an average of two to four or five people. The connection between these two developments could provide a fundamental explanation for why societies around the world are increasingly fragmenting into ideological bubbles.&lt;/p&gt;
    &lt;p&gt;"The big question that not only we, but many countries are currently grappling with, is why polarization has increased so dramatically in recent years," says Stefan Thurner from the Complexity Science Hub (CSH), explaining the study's motivation. The research was published in Proceedings of the National Academy of Sciences.&lt;/p&gt;
    &lt;p&gt;The researchers' findings confirm that increasing polarization is not merely perceived‚Äîit is measurable and objectively occurring. "And this increase happened suddenly, between 2008 and 2010," says Thurner. The question remained: what caused it?&lt;/p&gt;
    &lt;head rend="h2"&gt;The friendship shift: From two to five close contacts&lt;/head&gt;
    &lt;p&gt;To investigate, Thurner and his team examined whether social networks had changed‚Äîspecifically, whether people's close friendships had shifted. "For decades, sociological studies showed that people maintained an average of about two close friends‚Äîpeople who could influence their opinions on important issues," explains Thurner.&lt;/p&gt;
    &lt;p&gt;Here too, the researchers identified a striking change: "Around 2008, there was a sharp increase from an average of two close friends to four or five," explains CSH scientist Jan Korbel.&lt;/p&gt;
    &lt;head rend="h2"&gt;The paradox: More connection, more division&lt;/head&gt;
    &lt;p&gt;Are these two developments related? Do more close friends‚Äîand thus denser social networks‚Äîlead to network fragmentation and ultimately societal polarization?&lt;/p&gt;
    &lt;p&gt;Using a model based on real data, the researchers discovered this could indeed be the case: "When network density increases with more connections, polarization within the collective inevitably rises sharply," says Markus Hofer from CSH.&lt;/p&gt;
    &lt;p&gt;"This finding impressed us greatly because it could provide a fundamental explanation for the peculiar form of polarization we're currently observing simultaneously across many parts of the world‚Äîone that definitely threatens democracy," Thurner continues.&lt;/p&gt;
    &lt;p&gt;"When people are more connected with each other, they encounter different opinions more frequently. This inevitably leads to more conflict and thus greater societal polarization," adds Korbel.&lt;/p&gt;
    &lt;p&gt;Polarization has always existed, but what is happening now goes far beyond historical patterns. Greater connectivity has led to the formation of fewer but more tightly-knit groups with strongly differing opinions, between which there is hardly any exchange.&lt;/p&gt;
    &lt;p&gt;"There are few bridges between these 'bubbles,' and when they exist, they are often negative or even hostile," says Korbel. "This is called fragmentation, and it represents a new social phenomenon," adds Thurner.&lt;/p&gt;
    &lt;head rend="h2"&gt;Behind the numbers: Tracking polarization through decades of data&lt;/head&gt;
    &lt;p&gt;For their study, the researchers analyzed extensive existing survey data on both polarization and social networks.&lt;/p&gt;
    &lt;p&gt;"To measure political polarization, we used over 27,000 surveys from the Pew Research Center, which regularly records political attitudes of people in the US," explains Hofer.&lt;/p&gt;
    &lt;p&gt;"The key advantage of this data is that the questions have remained virtually unchanged over time, enabling reliable long-term comparisons."&lt;/p&gt;
    &lt;p&gt;The researchers found that political attitudes became significantly more one-sided between 1999 and 2017. For example, only 14% of respondents consistently expressed liberal views in 1999, but by 2017, this had risen to 31%. Conversely, only 6% of respondents consistently held conservative views in 1999, compared to 16% in 2017.&lt;/p&gt;
    &lt;p&gt;"More and more people are clearly aligning themselves with one political camp rather than holding a mixture of liberal and conservative views," explains Hofer.&lt;/p&gt;
    &lt;p&gt;To analyze friendship networks, the researchers combined 30 different surveys totaling over 57,000 respondents from Europe and the US, including the General Social Survey (US) and the European Social Survey.&lt;/p&gt;
    &lt;p&gt;"Despite minor differences between individual surveys, the data consistently show that the average number of close friendships rose from 2.2 in 2000 to 4.1 in 2024," says Hofer.&lt;/p&gt;
    &lt;p&gt;"The decisive contribution of this study is that it reconciled both phenomena using a mathematical social model," explains Thurner.&lt;/p&gt;
    &lt;p&gt;"This enabled us to show that increasing connectivity must lead to sudden polarization once a critical connectivity density is exceeded‚Äîjust like a phase transition in physics, such as water turning to ice," adds Hofer.&lt;/p&gt;
    &lt;p&gt;"It is fascinating that these phase transitions also exist in societies. The exact location of these critical thresholds still needs clarification. According to our results, for close relationships, it lies somewhere between three and four people," the researchers note.&lt;/p&gt;
    &lt;head rend="h2"&gt;The smartphone era: When connection may have become fragmentation&lt;/head&gt;
    &lt;p&gt;The sharp rise in both polarization and the number of close friends occurred between 2008 and 2010‚Äîprecisely when social media platforms and smartphones first achieved widespread adoption. This technological shift may have fundamentally changed how people connect with each other, indirectly promoting polarization.&lt;/p&gt;
    &lt;p&gt;"Democracy depends on all parts of society being involved in decision-making, which requires that everyone be able to communicate with each other. But when groups can no longer talk to each other, this democratic process breaks down," emphasizes Stefan Thurner.&lt;/p&gt;
    &lt;p&gt;Tolerance plays a central role. "If I have two friends, I do everything I can to keep them‚ÄîI am very tolerant towards them. But if I have five and things become difficult with one of them, it's easier to end that friendship because I still have 'backups.' I no longer need to be as tolerant," explains Thurner.&lt;/p&gt;
    &lt;p&gt;What disappears as a result is a societal baseline of tolerance‚Äîa development that could contribute to the long-term erosion of democratic structures. To prevent societies from increasingly fragmenting, Thurner emphasizes the importance of learning early how to engage with different opinions and actively cultivating tolerance.&lt;/p&gt;
    &lt;p&gt;More information: Thurner, Stefan, Why more social interactions lead to more polarization in societies, Proceedings of the National Academy of Sciences (2025). DOI: 10.1073/pnas.2517530122. doi.org/10.1073/pnas.2517530122&lt;/p&gt;
    &lt;p&gt;Journal information: Proceedings of the National Academy of Sciences&lt;/p&gt;
    &lt;p&gt;Provided by Complexity Science Hub Vienna&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://phys.org/news/2025-10-friends-division-social-circles-fuel.html"/><published>2025-10-27T19:06:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45726192</id><title>Easy RISC-V</title><updated>2025-10-27T22:37:45.023416+00:00</updated><content>&lt;doc fingerprint="bae7c0d12017aa49"&gt;
  &lt;main&gt;&lt;p&gt;(Last updated: 2025-10-27 14:51)&lt;/p&gt;&lt;p&gt;This page is not designed to be used on a narrow screen or without CSS. If you‚Äôre having issues using the emulator, try the emulators disabled version.&lt;/p&gt;&lt;p&gt;An interactive introduction to RISC-V assembly programming, by dramforever.&lt;/p&gt;&lt;p&gt;Interested in the code? Want to report an issue? Check out the GitHub page: https://github.com/dramforever/easyriscv&lt;/p&gt;&lt;p&gt;Inspired by Easy 6502 by Nick Morgan, this is a quick-ish introductory tutorial to RISC-V assembly programming. This tutorial is intended for those with a basic familiarity with low level computer science concepts, but unfamiliar with RISC-V. If you‚Äôre curious about RISC-V, I hope this will be a good start to your journey to learning about it.&lt;/p&gt;&lt;p&gt;RISC-V (pronounced ‚Äúrisk-five‚Äù), as its name suggests, is RISC (Reduced instruction set computer) architecture. Having started its life at UC Berkerley, RISC-V has bred a lively community of students, researchers, engineers and hobbyists working on software and hardware. Some highlights of RISC-V include:&lt;/p&gt;&lt;p&gt;RISC-V is less mature than more established architectures like x86 or Arm, but it is quickly gaining steam and has found great success in many areas of application, such as embedded systems, custom processors, education, and research.&lt;/p&gt;&lt;p&gt;This article will cover the 32-bit bare bones RV32I_Zicsr instruction set with a tiny subset of the privileged architecture. You‚Äôll probably never find a ‚Äúreal‚Äù chip with such bare bones instruction support. Most of them will have more extensions for other features like floating point or compressed instructions. However, I would still consider what we have here a ‚Äúcomplete‚Äù instruction set. For example, Rust has Tier 2 support for the target &lt;code&gt;riscv32i-unknown-none-elf&lt;/code&gt;
which works completely fine with only the instructions we‚Äôll cover
here.&lt;/p&gt;&lt;p&gt;Speaking of instructions we will cover, why don‚Äôt we meet the 45 of them right here and now:&lt;/p&gt;&lt;code&gt;lui auipc
jal jalr
beq bne blt bge bltu bgeu
lb lh lw lbu lhu sb sh sw
addi slti sltiu xori ori andi slli srli srai
add sub slt sltu xor or and sll srl sra
ecall ebreak
csrrw csrrs csrrc csrrwi csrrsi csrrci&lt;/code&gt;&lt;p&gt;Some of these instruction names should ring a bell (&lt;code&gt;add&lt;/code&gt;,
&lt;code&gt;or&lt;/code&gt;, &lt;code&gt;xor&lt;/code&gt;). Others will look like they have some
pattern to it. A few weird ones like &lt;code&gt;auipc&lt;/code&gt; stand out. These
instructions form the foundation of RISC-V, performing the basic tasks a
processor would do.&lt;/p&gt;&lt;p&gt;You will also catch a glimpse of what creating an operating system on RISC-V is like, namely handling exceptions and privilege levels.&lt;/p&gt;&lt;p&gt;Let‚Äôs get started.&lt;/p&gt;&lt;p&gt;Throughout this article you will see emulator panes like these:&lt;/p&gt;&lt;p&gt;(If you just see a code block, there‚Äôs a JavaScript problem. Make sure you‚Äôve enabled JavaScript, probably‚Ä¶)&lt;/p&gt;&lt;p&gt;You can use the buttons to control each emulator. Go ahead and click on ‚ÄòStart‚Äô. A register view should pop up showing the state of the emulator. Now click on ‚ÄòRun‚Äô. You‚Äôll notice that:&lt;/p&gt;&lt;code&gt;a0 (x10) 0x00000000&lt;/code&gt;&lt;p&gt;Changed into:&lt;/p&gt;&lt;code&gt;a0 (x10) 0x00000123&lt;/code&gt;&lt;p&gt;And the emulator stopped. Congratulations, you‚Äôve run your first RISC-V assembly program. First here, at least.&lt;/p&gt;&lt;p&gt;‚ÄòStart‚Äô assembles your code and, well, starts the emulator. If there‚Äôs a problem with your code, it will tell you about it and the emulator will not start.&lt;/p&gt;&lt;p&gt;When the emulator is started, you can see the current state of the registers in the side pane. More controls also becomes available. ‚ÄòRun‚Äô runs until the end or until you hit ‚ÄòPause‚Äô. ‚ÄòStep‚Äô runs a single step.&lt;/p&gt;&lt;p&gt;If you hit ‚ÄòStep‚Äô, you‚Äôll notice that the above program takes two steps to run. You may have guessed correctly that the first step corresponds to &lt;code&gt;addi&lt;/code&gt;, and the second corresponds to
&lt;code&gt;ebreak&lt;/code&gt;. The top of the register panel shows
&lt;code&gt;pc&lt;/code&gt;, the current instruction address, and in parentheses the
current instruction.&lt;/p&gt;&lt;p&gt;‚ÄòDump‚Äô opens a new window containing some text. There are two sections: the first is the symbol table, which tells you about the labels in your code:&lt;/p&gt;&lt;code&gt;# Symbols
# 0x40000000 start&lt;/code&gt;&lt;p&gt;The second section is an annotated version of your code:&lt;/p&gt;&lt;code&gt;start:
{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 00100073 } ebreak&lt;/code&gt;&lt;p&gt;This tells you that the &lt;code&gt;addi&lt;/code&gt; instruction encodes to hex
&lt;code&gt;12300513&lt;/code&gt;, and starts at address hex &lt;code&gt;40000000&lt;/code&gt;.
Similarly, &lt;code&gt;ebreak&lt;/code&gt; encodes as &lt;code&gt;00100073&lt;/code&gt; at
address hex &lt;code&gt;40000004&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;(Note: RISC-V instructions are little-endian, meaning that the four bytes of &lt;code&gt;addi&lt;/code&gt; are actually
&lt;code&gt;13 05 30 12&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;We‚Äôll talk in detail about all of &lt;code&gt;pc&lt;/code&gt;, registers,
instructions, labels, and the two checkboxes later.&lt;/p&gt;&lt;p&gt;Now you may have also guessed that &lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;
means &lt;code&gt;x10 = x0 + 0x123&lt;/code&gt;. As for &lt;code&gt;ebreak&lt;/code&gt;, for
now, just remember that &lt;code&gt;ebreak&lt;/code&gt; stops the emulator.&lt;/p&gt;&lt;p&gt;The program counter, or &lt;code&gt;pc&lt;/code&gt; is the address of
the current instruction. It points to the instruction to be
executed.&lt;/p&gt;&lt;p&gt;RV32I has 31 general purpose registers numbered &lt;code&gt;x1&lt;/code&gt; through
&lt;code&gt;x31&lt;/code&gt;. These can contain any 32-bit data.&lt;/p&gt;&lt;p&gt;(If you‚Äôre wondering, there are no flags for RV32I.)&lt;/p&gt;&lt;p&gt;The register &lt;code&gt;x0&lt;/code&gt; is a
special ‚Äúzero register‚Äù. For computational instructions, you can use
&lt;code&gt;x0&lt;/code&gt; anywhere a register is expected. Reading it always gives
zero, and writing to it just gets ignored. The use of a special register
simplifies the design of the architecture, and this design is shared by
MIPS and Arm AArch64. We will make good use of &lt;code&gt;x0&lt;/code&gt; soon.&lt;/p&gt;&lt;p&gt;(Note: In the emulator, the instruction listed in parenthesis next to &lt;code&gt;pc&lt;/code&gt; in the register view is provided as a convenience and is
not part of the processor state.)&lt;/p&gt;&lt;p&gt;But before we can start talking about instructions themselves, we need a way to talk about the instruction syntax so I can, you know, write it down for you.&lt;/p&gt;&lt;p&gt;The syntax of an instruction is the instruction name and then several comma-separated operands. For example, for this instruction we‚Äôve seen above:&lt;/p&gt;&lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;&lt;p&gt;&lt;code&gt;x10&lt;/code&gt; is the destination register or
&lt;code&gt;rd&lt;/code&gt;. The next operand is
the first (and only) source
register or &lt;code&gt;rs1&lt;/code&gt;. The last operand is an
immediate value or &lt;code&gt;imm&lt;/code&gt;. Using these
abbreviations, we can summarize that the syntax for &lt;code&gt;addi&lt;/code&gt;
is:&lt;/p&gt;&lt;code&gt;addi rd, rs1, imm&lt;/code&gt;&lt;p&gt;Some other instructions have a second source register or &lt;code&gt;rs2&lt;/code&gt;. For example, the
non-immediate &lt;code&gt;add&lt;/code&gt; instruction has this syntax:&lt;/p&gt;&lt;code&gt;add rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Some other instructions have no operands, like &lt;code&gt;ebreak&lt;/code&gt;.
Others have slightly more complex operands.&lt;/p&gt;&lt;p&gt;Using the registers as a playground of numbers, we can use computational instructions to work with them.&lt;/p&gt;&lt;p&gt;As we‚Äôve seen above, you can get a RISC-V machine to add numbers together.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;addi&lt;/code&gt;
instruction adds the value in &lt;code&gt;rs1&lt;/code&gt; to the immediate value
&lt;code&gt;imm&lt;/code&gt;, and puts the result in &lt;code&gt;rd&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;addi rd, rs1, imm&lt;/code&gt;&lt;p&gt;The &lt;code&gt;add&lt;/code&gt; instruction
adds the value in &lt;code&gt;rs1&lt;/code&gt; to the value in &lt;code&gt;rs2&lt;/code&gt;, and
puts the result in &lt;code&gt;rd&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;add rd, rs1, rs2&lt;/code&gt;&lt;p&gt;The opposite of addition is subtraction. The &lt;code&gt;sub&lt;/code&gt; instruction subtracts the
value in &lt;code&gt;rs2&lt;/code&gt; from the value in &lt;code&gt;rs1&lt;/code&gt;
(i.e.¬†&lt;code&gt;rs1 - rs2&lt;/code&gt;), and puts the result in &lt;code&gt;rd&lt;/code&gt;.
There‚Äôs no corresponding &lt;code&gt;subi&lt;/code&gt; instruction ‚Äî Just use
&lt;code&gt;addi&lt;/code&gt; with a negative number.&lt;/p&gt;&lt;code&gt;sub rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Step through this demo program and try writing your own additions and subtractions:&lt;/p&gt;&lt;p&gt;One thing you should note is that the immediate value has a limited range, namely &lt;code&gt;[-2048, 2047]&lt;/code&gt;, the range of a 12-bit two‚Äôs
complement signed integer. This limitation is because RV32I uses fixed
32-bit i.e.¬†4-byte instructions, and only the top 12 bits are available
to encode an immediate value. You can see the hexadecimal value encoded
in the instruction from the ‚ÄòDump‚Äô. This article will not go into much
further detail about instruction encodings.&lt;/p&gt;&lt;code&gt;{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 55500593 } addi x11, x0, 0x555&lt;/code&gt;&lt;p&gt;Even instructions as simple as addition and subtraction have other interesting uses. We have already used &lt;code&gt;addi x10, x0, 0x123&lt;/code&gt;
to put &lt;code&gt;0x123&lt;/code&gt; in the register &lt;code&gt;x10&lt;/code&gt;. When writing
in assembly, we can use a little shortcut called pseudoinstructions. The
&lt;code&gt;li&lt;/code&gt; (‚Äúload immediate‚Äù)
pseudoinstruction is a convenient way to put a small value in a
register. It expands to &lt;code&gt;addi rd, x0, imm&lt;/code&gt; when
&lt;code&gt;imm&lt;/code&gt; is in the range &lt;code&gt;[-2048, 2047]&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;li rd, imm&lt;/code&gt;&lt;p&gt;When &lt;code&gt;imm&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;, &lt;code&gt;addi&lt;/code&gt; copies the
value without changing it because adding zero is the same as doing
nothing. The &lt;code&gt;mv&lt;/code&gt; (‚Äúmove‚Äù)
pseudoinstruction copies the value from &lt;code&gt;rs1&lt;/code&gt; to
&lt;code&gt;rd&lt;/code&gt;. It expands to &lt;code&gt;addi rd, rs1, 0&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;mv rd, rs1&lt;/code&gt;&lt;p&gt;Using the pseudoinstruction is exactly equivalent to using the ‚Äúreal‚Äù instruction. You can see in the dump that the two are assembled exactly the same way.&lt;/p&gt;&lt;p&gt;Subtracting from zero is negation. What‚Äôs the negative of &lt;code&gt;0x123&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Hmm, we get &lt;code&gt;0xfffffccd&lt;/code&gt;. That‚Äôs the 32-bit two‚Äôs complement
representation of &lt;code&gt;-291&lt;/code&gt;, or &lt;code&gt;-0x123&lt;/code&gt;. There‚Äôs
plenty of tutorials on this out there, so we‚Äôll just note that whenever
something is ‚Äúsigned‚Äù, RISC-V uses two‚Äôs complement representation. The
benefit of this is that there are fewer instructions for separate signed
and unsigned instructions ‚Äî both signed and unsigned numbers have the
same overflow wrap-around behavior.&lt;/p&gt;&lt;p&gt;Speaking of overflow wrap-around, what happens if we add something too much and it overflows? We‚Äôll use &lt;code&gt;add&lt;/code&gt; to repeatedly
double &lt;code&gt;0x123&lt;/code&gt; and see what happens:&lt;/p&gt;&lt;p&gt;As &lt;code&gt;0x123&lt;/code&gt; crawls up to the upper bits and eventually we
get to &lt;code&gt;0x9180_0000&lt;/code&gt;, in the next iteration it turns into
&lt;code&gt;0x2300_0000&lt;/code&gt;. There was an overflow! Doubling of
&lt;code&gt;0x9180_0000&lt;/code&gt; gives &lt;code&gt;0x1_2300_0000&lt;/code&gt;, but that
needs 33 bits in binary, so the highest bit can‚Äôt be put in the result.
Since RISC-V doesn‚Äôt have flag bits for carry or overflow, it‚Äôs simply
gone. The programmer is expected to deal with this.&lt;/p&gt;&lt;p&gt;While we‚Äôre talking about bits, another thing we can do with bits is performing bitwise logical operations on them.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;and&lt;/code&gt; instruction
performs a bitwise-‚Äúand‚Äù between the bits of &lt;code&gt;rs1&lt;/code&gt; and
&lt;code&gt;rs2&lt;/code&gt; and puts the result in &lt;code&gt;rd&lt;/code&gt;. The &lt;code&gt;or&lt;/code&gt; and &lt;code&gt;xor&lt;/code&gt; instructions similarly
performs bitwise-‚Äúor‚Äù and bitwise-‚Äúxor‚Äù, respectively.&lt;/p&gt;&lt;code&gt;and rd, rs1, rs2
or rd, rs1, rs2
xor rd, rs1, rs2&lt;/code&gt;&lt;p&gt;Immediate operand versions of the three, namely &lt;code&gt;andi&lt;/code&gt;, &lt;code&gt;ori&lt;/code&gt;, &lt;code&gt;xori&lt;/code&gt; also exist.&lt;/p&gt;&lt;code&gt;andi rd, rs1, imm
ori rd, rs1, imm
xori rd, rs1, imm&lt;/code&gt;&lt;p&gt;Here are some random bit operation examples you can play with:&lt;/p&gt;&lt;p&gt;Remember that the immediate value is in the range &lt;code&gt;[-2048, 2047]&lt;/code&gt;. For negative values, the two‚Äôs complement
representation used means that the high bits are all ones. For example,
using &lt;code&gt;-1&lt;/code&gt; as &lt;code&gt;imm&lt;/code&gt; means the second operand is
binary all ones, or &lt;code&gt;0xffff_ffff&lt;/code&gt;. This allows us to use
&lt;code&gt;xori rd, rs1, -1&lt;/code&gt; as bitwise-‚Äúnot‚Äù.&lt;/p&gt;&lt;p&gt;Another interesting operation you can do is to round/align something up or down to a multiple of a power of two. For example, if you want to find the closest multiple of 16 below &lt;code&gt;a&lt;/code&gt;, in binary that would be clearing the lowest
4 bits, or &lt;code&gt;a &amp;amp; ~0b1111&lt;/code&gt;. Conveniently, that‚Äôs
&lt;code&gt;a &amp;amp; -16&lt;/code&gt; in two‚Äôs complement.&lt;/p&gt;&lt;p&gt;Aligning up is less intuitive, but one idea would be adding 16 first. However that gives an incorrect result for multiples of 16. It‚Äôs easy enough to fix though: adding one less works exactly right: &lt;code&gt;(a + 15) &amp;amp; -16&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Usually when you write a comparison of some sort like &lt;code&gt;a == b&lt;/code&gt; or &lt;code&gt;a &amp;gt;= b&lt;/code&gt;, it‚Äôs used as a condition
for some &lt;code&gt;if&lt;/code&gt; or loop, but‚Ä¶ those things are complicated!
We‚Äôll get to it later.&lt;/p&gt;&lt;p&gt;Sometimes you just want a boolean value out of a comparison. The C convention uses 1 for true and 0 for false, and since the world runs on C now, that‚Äôs what RISC-V provides.&lt;/p&gt;&lt;p&gt;In C there are six comparison operators:&lt;/p&gt;&lt;code&gt;== != &amp;lt; &amp;gt; &amp;lt;= &amp;gt;=&lt;/code&gt;&lt;p&gt;The values being compared can also be both signed or both unsigned.&lt;/p&gt;&lt;p&gt;How many comparison instructions do we have at our disposal? Let‚Äôs see‚Ä¶&lt;/p&gt;&lt;p&gt;The &lt;code&gt;slt&lt;/code&gt; (‚Äúset less
than‚Äù) instruction compares &lt;code&gt;rs1&lt;/code&gt; and &lt;code&gt;rs2&lt;/code&gt; as
signed 32-bit integers, and sets &lt;code&gt;rd&lt;/code&gt; to &lt;code&gt;1&lt;/code&gt; if
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt;, and &lt;code&gt;0&lt;/code&gt; otherwise
(&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt;). The &lt;code&gt;sltu&lt;/code&gt; instruction is similar
but it treats the operands as unsigned values. &lt;code&gt;slti&lt;/code&gt; and &lt;code&gt;sltiu&lt;/code&gt; are similar but the
second operand is an immediate value.&lt;/p&gt;&lt;code&gt;slt rd, rs1, rs2
sltu rd, rs1, rs2
slti rd, rs1, imm
sltiu rd, rs1, imm&lt;/code&gt;&lt;p&gt;(Of particular note is &lt;code&gt;sltiu&lt;/code&gt;, where the immediate
operand still has the range &lt;code&gt;[-2048, 2047]&lt;/code&gt; but is sign
extended to 32 bits and then treated as an unsigned value, like what
would happen in C with &lt;code&gt;a &amp;lt; (unsigned)-1&lt;/code&gt;.)&lt;/p&gt;&lt;p&gt;That‚Äôs‚Ä¶ one of the six comparisons settled. What about the others? As it turns out, we can synthesize any of the other five, using up to two instructions.&lt;/p&gt;&lt;p&gt;Making &lt;code&gt;&amp;gt;&lt;/code&gt; from &lt;code&gt;&amp;lt;&lt;/code&gt; is easy, as you can
just swap the operands. Using &lt;code&gt;xori&lt;/code&gt; with &lt;code&gt;1&lt;/code&gt; we
can invert the result of a comparison, giving as &lt;code&gt;&amp;lt;=&lt;/code&gt; and
&lt;code&gt;&amp;gt;=&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;That was signed comparison but unsigned comparison works the same using &lt;code&gt;sltu&lt;/code&gt; instead of &lt;code&gt;slt&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As for &lt;code&gt;==&lt;/code&gt; and &lt;code&gt;!=&lt;/code&gt;, let‚Äôs tackle the easier
case of &lt;code&gt;a == 0&lt;/code&gt; and &lt;code&gt;a != 0&lt;/code&gt; first. We will use
the fact that for unsigned values, &lt;code&gt;a != 0&lt;/code&gt; is equivalent to
&lt;code&gt;a &amp;gt; 0&lt;/code&gt;. The negation of that is &lt;code&gt;a &amp;lt;= 0&lt;/code&gt;,
which is the same as &lt;code&gt;a &amp;lt; 1&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;As a bonus, this is also how we get logical not and converting integer to boolean.&lt;/p&gt;&lt;p&gt;Now that we have these, &lt;code&gt;a == b&lt;/code&gt; is just
&lt;code&gt;(a - b) == 0&lt;/code&gt;, and &lt;code&gt;a != b&lt;/code&gt; is just
&lt;code&gt;(a - b) != 0&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In summary: (&lt;code&gt;[u]&lt;/code&gt; means use &lt;code&gt;u&lt;/code&gt; for unsigned
comparison and nothing for signed comparison)&lt;/p&gt;&lt;code&gt;a &amp;lt; b&lt;/code&gt;: &lt;code&gt;slt[u]&lt;/code&gt;&lt;code&gt;a &amp;gt; b&lt;/code&gt;: &lt;code&gt;slt[u] reversed&lt;/code&gt;&lt;code&gt;a &amp;lt;= b&lt;/code&gt;: &lt;code&gt;slt[u] reversed ; xori 1&lt;/code&gt;&lt;code&gt;a &amp;gt;= b&lt;/code&gt;: &lt;code&gt;slt[u] ; xori 1&lt;/code&gt;&lt;code&gt;a == 0&lt;/code&gt;: &lt;code&gt;sltu x0&lt;/code&gt;&lt;code&gt;a != 0&lt;/code&gt;: &lt;code&gt;sltiu 1&lt;/code&gt;&lt;code&gt;a == b&lt;/code&gt;: &lt;code&gt;sub ; sltu x0&lt;/code&gt;&lt;code&gt;a != b&lt;/code&gt;: &lt;code&gt;sub ; sltiu 1&lt;/code&gt;&lt;p&gt;There is no way I can do justice to the usage of bit shifts in the middle of a tutorial on RISC-V assembly. If you‚Äôre here, you‚Äôve probably heard of them. There‚Äôs nothing really special to the way they appear in usage for RISC-V.&lt;/p&gt;&lt;p&gt;There are two variants for right shifting: &lt;code&gt;srl&lt;/code&gt; and &lt;code&gt;srli&lt;/code&gt; (‚Äúshift right logical
(immediate)‚Äù) performs ‚Äúlogical‚Äù or unsigned right shift where the
leftmost or most significant bits are filled with zeros.&lt;/p&gt;&lt;p&gt;&lt;code&gt;sra&lt;/code&gt; and &lt;code&gt;srai&lt;/code&gt; (‚Äúshift right
arithmetic (immediate)‚Äù) performs ‚Äúarithmetic‚Äù or signed right shift
where the leftmost bits are filled with the same of what highest/sign
bit was. So if you shift a negative value, you get a negative result; if
you shift a non-negative value, you get a non-negative result.&lt;/p&gt;&lt;code&gt;srl rd, rs1, rs2
sra rd, rs1, rs2
srli rd, rs1, imm
srai rd, rs1, imm&lt;/code&gt;&lt;p&gt;As before, the ones with the &lt;code&gt;i&lt;/code&gt; suffix take an immediate
value as the second operand, and the ones without &lt;code&gt;i&lt;/code&gt; take a
register.&lt;/p&gt;&lt;p&gt;So &lt;code&gt;a&lt;/code&gt; means ‚Äúarithmetic‚Äù, &lt;code&gt;l&lt;/code&gt; means ‚Äúlogical‚Äù.
Got it.&lt;/p&gt;&lt;p&gt;Left shifts have no such distinction. For consistency they are still ‚Äúlogical‚Äù: &lt;code&gt;sll&lt;/code&gt; is left
shift, and &lt;code&gt;slli&lt;/code&gt; is
left shift with immediate.&lt;/p&gt;&lt;code&gt;sll rd, rs1, rs2
slli rd, rs1, imm&lt;/code&gt;&lt;p&gt;Aha, now we can blow up &lt;code&gt;0x123&lt;/code&gt; without repeating myself
so much:&lt;/p&gt;&lt;p&gt;The immediate value for shift instructions are special: they can only be in the range of 0 to 31, inclusive, because it doesn‚Äôt make sense to shift by a negative amount, or by more than 31. When the shift amount is taken from a register, the value is considered modulo 32, or in other words only the last 5 bits are taken into account:&lt;/p&gt;&lt;p&gt;For some fun, let‚Äôs try multiplying a value by 10, something you would do when parsing decimal numbers: &lt;code&gt;a * 10&lt;/code&gt; can be
rewritten as &lt;code&gt;(a &amp;lt;&amp;lt; 1) + (a &amp;lt;&amp;lt; 3)&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;That‚Äôs it?&lt;/p&gt;&lt;p&gt;You may have noticed some glaring omissions. What we‚Äôve learned doesn‚Äôt even cover grade school math: multiplication and division are missing.&lt;/p&gt;&lt;p&gt;RISC-V is designed with extensions in mind. Remember that as said in the introduction, RV32I is the barest bones of the barest bones we‚Äôve got. Forcing everyone to make their processors with multiplication and division even for tasks that don‚Äôt need them would waste silicon area and money on every chip. Instead those making RISC-V processors have great freedom to choose, and indeed some would say they have too much freedom.&lt;/p&gt;&lt;p&gt;For us‚Ä¶ Honestly, I‚Äôm just glad we‚Äôve been dealt a hand that we can tackle completely in full. There‚Äôs no way I‚Äôm finishing writing this tutorial if RV32I wasn‚Äôt so bare boned.&lt;/p&gt;&lt;p&gt;(Operand &lt;code&gt;a&lt;/code&gt; is &lt;code&gt;rs1&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt; is
&lt;code&gt;rs2&lt;/code&gt; or immediate. In the instruction name &lt;code&gt;[i]&lt;/code&gt;
means an immediate variant is available. Subscript &lt;code&gt;u&lt;/code&gt; means
unsigned and &lt;code&gt;s&lt;/code&gt; means two‚Äôs complement signed.)&lt;/p&gt;&lt;table&gt;&lt;row span="3"&gt;&lt;cell role="head"&gt;Instruction&lt;/cell&gt;&lt;cell role="head"&gt;Operation&lt;/cell&gt;&lt;cell role="head"&gt;Immediate range&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;add[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a + b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;sub&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a - b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;(n/a)&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;slt[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(a &amp;lt;s b) ? 1 : 0&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;slt[i]u&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;(a &amp;lt;u b) ? 1 : 0&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;xor[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a ^ b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;or[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a | b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;and[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;amp; b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[-2048, 2047]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;sll[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;lt;&amp;lt; b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row span="3"&gt;&lt;cell&gt;&lt;code&gt;srl[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;gt;&amp;gt;u b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;&lt;code&gt;sra[i]&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;a &amp;gt;&amp;gt;s b&lt;/code&gt;&lt;/cell&gt;&lt;cell&gt;&lt;code&gt;[0, 31]&lt;/code&gt;&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;The &lt;code&gt;addi&lt;/code&gt; instruction has limit on the immediate value.
How do we make bigger values?&lt;/p&gt;&lt;p&gt;The &lt;code&gt;lui&lt;/code&gt; (‚Äúload upper
immediate‚Äù) instruction takes an immediate in the range
&lt;code&gt;[0, 1048575]&lt;/code&gt; (i.e.¬†up to &lt;code&gt;220 - 1&lt;/code&gt;)
and sets &lt;code&gt;rd&lt;/code&gt; to that value left shifted 12 bits:&lt;/p&gt;&lt;code&gt;lui rd, imm20&lt;/code&gt;&lt;p&gt;That was‚Ä¶ slightly confusing. Why don‚Äôt we give it a try:&lt;/p&gt;&lt;p&gt;Instead of &lt;code&gt;li&lt;/code&gt; loading a ‚Äúlow‚Äù immediate, we control the
upper 20 bits of what we put in the register. After that, we
can use another &lt;code&gt;addi&lt;/code&gt; instruction to fill in the lower bits.
For example, if we want &lt;code&gt;0x12345&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;For convenience, in assembly you can use &lt;code&gt;%hi()&lt;/code&gt; and &lt;code&gt;%lo()&lt;/code&gt; to extract the, well,
high 20 and low 10 bits of a value. The previous example could also be
written:&lt;/p&gt;&lt;p&gt;Letting &lt;code&gt;lui&lt;/code&gt; handle the high 20 bits, and
&lt;code&gt;addi&lt;/code&gt; for the low 12 bits, you can make any 32-bit
value.&lt;/p&gt;&lt;p&gt;(A small complication arises if you want to use values with bit 11 set. In that case, the immediate operand to &lt;code&gt;addi&lt;/code&gt; will have
to be negative. However &lt;code&gt;%hi&lt;/code&gt; understands this and adds one
to compensate, so this &lt;code&gt;%hi&lt;/code&gt;/&lt;code&gt;%lo&lt;/code&gt; combination
does work for everything.)&lt;/p&gt;&lt;p&gt;So far, everything that we‚Äôve had so far can be done on even the most basic programmer‚Äôs calculator. To truly make a computer‚Ä¶ do computer stuff, we‚Äôd want loops and conditionals.&lt;/p&gt;&lt;p&gt;In RISC-V parlance, a branch is a conditional transfer of control flow, and a jump is an unconditional transfer of control flow.&lt;/p&gt;&lt;p&gt;I think the branch instructions are slightly simpler, so let‚Äôs start with those.&lt;/p&gt;&lt;p&gt;All the branch instruction follow the form ‚ÄúIf some comparison, go to somewhere.‚Äù The conditions are:&lt;/p&gt;&lt;code&gt;beq&lt;/code&gt;:
&lt;code&gt;rs1 == rs2&lt;/code&gt; (‚Äúequal‚Äù)&lt;code&gt;bne&lt;/code&gt;:
&lt;code&gt;rs1 != rs2&lt;/code&gt; (‚Äúnot equal‚Äù)&lt;code&gt;blt&lt;/code&gt;:
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt; signed (‚Äúless than‚Äù)&lt;code&gt;bge&lt;/code&gt;:
&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt; signed (‚Äúgreater or equal‚Äù)&lt;code&gt;bltu&lt;/code&gt;:
&lt;code&gt;rs1 &amp;lt; rs2&lt;/code&gt; signed (‚Äúless than unsigned‚Äù)&lt;code&gt;bgeu&lt;/code&gt;:
&lt;code&gt;rs1 &amp;gt;= rs2&lt;/code&gt; signed (‚Äúgreater or equal unsigned‚Äù)&lt;p&gt;(In case you‚Äôre wondering about the confusing choice of ordering operators here, it‚Äôs just that the negation of &lt;code&gt;&amp;lt;&lt;/code&gt; is
&lt;code&gt;&amp;gt;=&lt;/code&gt;.)&lt;/p&gt;&lt;code&gt;beq rs1, rs2, label
bne rs1, rs2, label
blt rs1, rs2, label
bge rs1, rs2, label
bltu rs1, rs2, label
bgeu rs1, rs2, label&lt;/code&gt;
&lt;p&gt;Oh, right, almost forgot to explain what labels are. Labels are convenience identifiers for addresses at some line of your code. They are some identifier followed by a colon (like &lt;code&gt;this:&lt;/code&gt;). They
can appear on a line of its own, or before any instruction on the line.
You can see which address they point to using the ‚ÄúDump‚Äù button. The
third operand of a branch instruction is a label to jump to if the
condition holds.&lt;/p&gt;&lt;p&gt;Let‚Äôs add up all the numbers from 1 to 100:&lt;/p&gt;&lt;p&gt;You can try your hands on making your favorite loops, like fibonacci numbers or something. Speaking of trying your hands, just so we‚Äôre ready, here‚Äôs what an infinite loop looks like. Try pausing or stopping the loop, and single stepping through the instructions.&lt;/p&gt;&lt;p&gt;(If you know a thing or two about JavaScript in the browser, you‚Äôll know that a real infinite loop in JavaScript makes the whole page becomes unresponsive, unless it‚Äôs in a worker or something. The ‚ÄúRun‚Äù button here just runs the emulator for a certain number of steps, pausing by giving back control to the event loop in between.)&lt;/p&gt;&lt;p&gt;(This isn‚Äôt the preferred way to write an unconditional jump. We‚Äôll see what is later.)&lt;/p&gt;&lt;p&gt;By the way, there‚Äôs no &lt;code&gt;bgt[u]&lt;/code&gt; or &lt;code&gt;ble[u]&lt;/code&gt;
because you can just swap &lt;code&gt;rs1&lt;/code&gt; and &lt;code&gt;rs2&lt;/code&gt; to get
those.&lt;/p&gt;&lt;p&gt;There are two jump instructions in RISC-V. One of them is &lt;code&gt;jal&lt;/code&gt; ‚Äújump and link‚Äù, which
sets &lt;code&gt;rd&lt;/code&gt; to the address of the following instruction, and
then jumps to a label:&lt;/p&gt;&lt;code&gt;jal rd, label&lt;/code&gt;
&lt;p&gt;Another is &lt;code&gt;jalr&lt;/code&gt;
‚Äújump and link register‚Äù, which sets &lt;code&gt;rd&lt;/code&gt; to the address of
the following instruction, and then jumps to the address at
&lt;code&gt;imm + rs1&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;jalr rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;(Actually, the address jumped to is &lt;code&gt;(imm + rs1) &amp;amp; ~1&lt;/code&gt;, i.e.¬†the least significant bit is
cleared. This distinction won‚Äôt come up in normal code, like, pretty
much ever.)&lt;/p&gt;&lt;p&gt;Eesh, that‚Äôs some funky looking syntax. When you see parentheses like this, it has something to do with an address. Parens means address.&lt;/p&gt;&lt;p&gt;That‚Äôs‚Ä¶ still a lot going on. Let‚Äôs take on some simpler cases first: If &lt;code&gt;rd&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; then the only thing these
instructions do is jumping. We can use it instead of the branch
instructions for an unconditional jump.&lt;/p&gt;&lt;p&gt;For convenience, a pseudoinstruction is available for you: &lt;code&gt;j&lt;/code&gt; (‚Äújump‚Äù) is for
&lt;code&gt;jal&lt;/code&gt; with &lt;code&gt;rd&lt;/code&gt; being &lt;code&gt;x0&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;j label&lt;/code&gt;
&lt;p&gt;As for why you would want to do this‚Ä¶ Well, we only have 32 bits per instruction, and since the &lt;code&gt;jal&lt;/code&gt; instruction only needs one
register number instead of the branch instructions‚Äô two, and it doesn‚Äôt
need a condition, the instruction encoding permits jumping over a longer
range. So this is always preferred over something like
&lt;code&gt;beq x0, x0, label&lt;/code&gt; for a jump.&lt;/p&gt;&lt;p&gt;As for &lt;code&gt;jalr&lt;/code&gt;, you can jump to an address that‚Äôs stored in
a register. In C, that would be dealing with function pointers. You‚Äôd
need this any time dynamic dispatch is needed. For example, we load the
address of &lt;code&gt;foo&lt;/code&gt; into a register first before jumping to
it.&lt;/p&gt;&lt;p&gt;In case you forgot by now, the &lt;code&gt;lui&lt;/code&gt;/&lt;code&gt;addi&lt;/code&gt;
combo at the start puts the address of the label &lt;code&gt;foo&lt;/code&gt; in
register &lt;code&gt;x10&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Similar to &lt;code&gt;j&lt;/code&gt;, &lt;code&gt;jr&lt;/code&gt; (‚Äújump register‚Äù) is a
psuedoinstruction for &lt;code&gt;jalr&lt;/code&gt; with &lt;code&gt;rd&lt;/code&gt; being
&lt;code&gt;x0&lt;/code&gt; and &lt;code&gt;imm&lt;/code&gt; being &lt;code&gt;0&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;jr rs1&lt;/code&gt;
&lt;p&gt;Hmmm‚Ä¶ If I didn‚Äôt really need the address in &lt;code&gt;x10&lt;/code&gt;, that
&lt;code&gt;addi&lt;/code&gt; would be unnecessary, since &lt;code&gt;jalr&lt;/code&gt; has the
ability to add a low immediate on its own:&lt;/p&gt;&lt;p&gt;What‚Äôs the advantage of this over &lt;code&gt;jal x0&lt;/code&gt;? Since
&lt;code&gt;%hi&lt;/code&gt; and &lt;code&gt;%lo&lt;/code&gt; can represent any 32-bit value,
this two-instruction combo can jump to any address, free from range
restrictions. You do need a free scratch register for the high part of
the address though, but since RISC-V gives you 31 of them, this
shouldn‚Äôt be too much of a problem.&lt;/p&gt;&lt;p&gt;What‚Äôs the deal with the destination register then? What do you need the address of the next instruction for? For jumping back of course. We can use this functionality to call functions and return back.&lt;/p&gt;&lt;p&gt;Note that I used the register &lt;code&gt;x1&lt;/code&gt; for this, which is the
register for providing the return address by convention. For
convenience, if the destination register is omitted in &lt;code&gt;jal&lt;/code&gt;,
it defaults to &lt;code&gt;x1&lt;/code&gt;. Meanwhile, &lt;code&gt;ret&lt;/code&gt; (‚Äúreturn‚Äù) is a
pseudoinstruction that stands for &lt;code&gt;jr x1&lt;/code&gt;,
i.e.¬†&lt;code&gt;jalr x0, 0(x1)&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;jal label
ret&lt;/code&gt;
&lt;p&gt;So the example above can be rewritten more conveniently as:&lt;/p&gt;&lt;p&gt;That‚Äôs a nice computer we have here. Now we have‚Ä¶ all of 31 √ó 4 = 124 bytes of storage in the form of registers to work with. I want more‚Ä¶&lt;/p&gt;&lt;p&gt;The emulator has 1 MiB of memory starting at address &lt;code&gt;0x4000_0000&lt;/code&gt;. That‚Äôs &lt;code&gt;0x4000_0000&lt;/code&gt; to
&lt;code&gt;0x400f_ffff&lt;/code&gt;, inclusive. The assembler starts assembling at
the beginning of memory, as you can see in the dump, starting at address
&lt;code&gt;0x4000_0000&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;.word&lt;/code&gt; directive straight up puts a
4-byte/32-bit word into the current position. You can specify multiple
values separated by commas.&lt;/p&gt;&lt;code&gt;.word value [ , value [ , ...  ] ]&lt;/code&gt;
&lt;p&gt;The &lt;code&gt;lw&lt;/code&gt; (‚Äúload word‚Äù)
instruction loads a word from the address &lt;code&gt;rs1 + imm&lt;/code&gt; and
puts it in &lt;code&gt;rd&lt;/code&gt;, in other words it reads the word from
memory:&lt;/p&gt;&lt;code&gt;lw rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;As with &lt;code&gt;jalr&lt;/code&gt;, you can combine it with &lt;code&gt;lui&lt;/code&gt;
to access any address.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;sw&lt;/code&gt; (‚Äústore word‚Äù)
instruction stores &lt;code&gt;rs2&lt;/code&gt; to a word in memory at address
&lt;code&gt;rs2 + imm&lt;/code&gt;, in other words it writes the word to memory:&lt;/p&gt;&lt;code&gt;sw rs2, imm(rs1)&lt;/code&gt;
&lt;p&gt;Just to make absolutely sure we‚Äôre clear on this, load means reading from memory, store means writing to memory. Both words can be nouns and verbs. Also, a word is 32-bit for RISC-V.&lt;/p&gt;&lt;p&gt;Let‚Äôs have some fun. Can we have the program read itself?&lt;/p&gt;&lt;p&gt;Ohh that‚Äôs fun. Does this mean I can also write programs with just &lt;code&gt;.word&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;Oh that‚Äôs nice. Just a peek into the world of machine code and instruction encodings‚Ä¶ which we will not be getting into.&lt;/p&gt;&lt;p&gt;With memory accesses under our belt, we can address a lot more data easily. Here‚Äôs an example where we find the sum of all the values in an array. Note how we can access different addresses of memory, whereas there is no way to address a register by a number in another register.&lt;/p&gt;&lt;p&gt;The equivalent in C would be something like&lt;/p&gt;&lt;code&gt;uint32_t array[], length;

uint32_t *current = array;
uint32_t *end = array + length;
uint32_t sum = 0;

for (; current != end; current ++) {
    sum += *current;
}&lt;/code&gt;
&lt;p&gt;Note how adding one to a pointer to word bumps the address by 4, because the addresses are all byte addresses, and one word is four bytes. In C, the compiler handles the multiplier for you, but in assembly you have to remember to do it manually.&lt;/p&gt;&lt;p&gt;Not everything in memory is word sized. You‚Äôve already seen an array, which is multiple-word-sized. There are also stuff smaller than word-sized.&lt;/p&gt;&lt;p&gt;An obvious one is the byte, which is, well, 1-byte/8-bit and written &lt;code&gt;[u]int8_t&lt;/code&gt; in C. In
the middle is the halfword,
which is 2-byte/16-bit and written &lt;code&gt;[u]int16_t&lt;/code&gt; in C. You can
use the directives &lt;code&gt;.byte&lt;/code&gt; and &lt;code&gt;.half&lt;/code&gt; respectively for those
data types.&lt;/p&gt;&lt;code&gt;.byte value [ , value [ , ...  ] ]
.half value [ , value [ , ...  ] ]&lt;/code&gt;
&lt;p&gt;And just in case you don‚Äôt remember those, &lt;code&gt;.2byte&lt;/code&gt; means the same as
&lt;code&gt;.half&lt;/code&gt;, and &lt;code&gt;.4byte&lt;/code&gt; means the same as
&lt;code&gt;.word&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;.2byte value [ , value [ , ...  ] ] # Same as .half
.4byte value [ , value [ , ...  ] ] # Same as .word&lt;/code&gt;
&lt;p&gt;There‚Äôs a small problem with loading smaller-than-word sized values into word-sized registers: What do you do with the rest of the bits? Obviously the lowest of the bits gets the actual value loaded. There are two most useful ways to fill the upper bits:&lt;/p&gt;&lt;p&gt;Zero extension is easy enough. As the name suggests, sign extension has something to do with signed values. It‚Äôs what happens when you convert a narrower signed value into a wider one.&lt;/p&gt;&lt;p&gt;(Keeping the rest of the bits unchanged isn‚Äôt a good option. It complicates the implementation for processor, especially of modern high performance design, to just write parts of a register. It would be easiest if the new value didn‚Äôt depend on the old value.)&lt;/p&gt;&lt;p&gt;For example, the signed byte value &lt;code&gt;-100&lt;/code&gt; is
&lt;code&gt;0x9c&lt;/code&gt;. Since the highest bit i.e. the sign bit of it is
&lt;code&gt;1&lt;/code&gt;, when we expand it into 32 bits we fill the high 24 bits
with one so the new value, &lt;code&gt;0xffff_ff9c&lt;/code&gt; still represents
&lt;code&gt;-100&lt;/code&gt;. This is sign extension.&lt;/p&gt;&lt;p&gt;If we want to convert the unsigned byte value &lt;code&gt;156&lt;/code&gt;, still
&lt;code&gt;0x9c&lt;/code&gt;, into an unsigned word, it would have to be
&lt;code&gt;0x0000_009c&lt;/code&gt; to preserve its value.&lt;/p&gt;&lt;p&gt;For bytes, the &lt;code&gt;lb&lt;/code&gt;
(‚Äúload byte‚Äù) instruction loads a byte and sign extends the result, and
the &lt;code&gt;lbu&lt;/code&gt; (‚Äúload byte
unsigned‚Äù) instruction does the same but zero extends the result. As
with &lt;code&gt;lw&lt;/code&gt;, the address is &lt;code&gt;rs1 + imm&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;lb rd, imm(rs1)
lbu rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;Similarly for &lt;code&gt;lh&lt;/code&gt;
(‚Äúload half‚Äù) and &lt;code&gt;lhu&lt;/code&gt;
(‚Äúload half unsigned‚Äù), just for unsigned halfwords (two bytes each,
remember):&lt;/p&gt;&lt;code&gt;lh rd, imm(rs1)
lhu rd, imm(rs1)&lt;/code&gt;
&lt;p&gt;We can try out the sign extension and zero extension example from earlier.&lt;/p&gt;&lt;p&gt;Correspondingly, the &lt;code&gt;sb&lt;/code&gt; (‚Äústore byte‚Äù) and &lt;code&gt;sh&lt;/code&gt; (‚Äústore half‚Äù) do the
opposite of &lt;code&gt;lb&lt;/code&gt; and &lt;code&gt;lh&lt;/code&gt;, storing bytes and
halfwords to memory. Instead of widening small values to register size,
these take the lowest order bits from &lt;code&gt;rs1&lt;/code&gt; and stores it to
memory. (There‚Äôs no &lt;code&gt;sbu&lt;/code&gt; and &lt;code&gt;shu&lt;/code&gt; because stores
are narrowing instead of widening operations.)&lt;/p&gt;&lt;code&gt;sb rs2, imm(rs1)
sh rs2, imm(rs1)&lt;/code&gt;
&lt;p&gt;While we‚Äôre at it, here‚Äôs two more minor details. Firstly, endianness. While theoretically big endian RISC-V machines can exist, I‚Äôve never seen one‚Ä¶ and this emulator is little endian, meaning that the four bytes in a word are laid out in memory lowest first. So, &lt;code&gt;.byte 0x1, 0x2, 0x3, 0x4&lt;/code&gt; would be
the same as &lt;code&gt;.word 0x04030201&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Secondly, memory accesses should be aligned for maximum efficiency. This means that the address for a halfword/2byte should be a multiple of two, and the address for a word/4byte should be a multiple of four. Misaligned accesses (meaning, well, when the address is not aligned) may not work as expected.&lt;/p&gt;&lt;p&gt;For user programs running on a rich operating systems, misaligned accesses are supported but may be slow. In embedded application running on microcontrollers and such, it might not work at all.&lt;/p&gt;&lt;p&gt;This emulator supports misaligned memory accesses.&lt;/p&gt;&lt;p&gt;Now you can try translating some basic C code into RISC-V assembly. Functions are‚Ä¶ still out of the question for now. Variables have to be either global or put in registers. What else are we missing‚Ä¶&lt;/p&gt;&lt;p&gt;Is it Hello World time? I think it‚Äôs Hello World time‚Ä¶&lt;/p&gt;&lt;p&gt;For a computer to not just be a space heater, we need some way for it to at least generate output and take input. While other architectures may have dedicated I/O instructions, RISC-V uses memory mapped I/O. Essentially, this means that loads and stores to special addresses communicate with other devices. They do not work like normal memory, and you should only use the supported widths to access them.&lt;/p&gt;&lt;p&gt;One output device we have here is at address &lt;code&gt;0x1000_0000&lt;/code&gt;. Any 32-bit writes to it appends the lowest 8
bits as a byte to the text in the output pane. In other words, a
&lt;code&gt;sw&lt;/code&gt; to that address writes a byte of output.&lt;/p&gt;&lt;p&gt;(The output pane uses UTF-8 encoding.)&lt;/p&gt;&lt;p&gt;Eh, close enough to greeting the entire world. We could refactor it a bit to use a loop, or whatever‚Ä¶ Now that we think about it, how about going one step further and organize our code into some functions?&lt;/p&gt;&lt;p&gt;We already know how to call a function and return back. Namely, &lt;code&gt;jal&lt;/code&gt; calls a function, and &lt;code&gt;ret&lt;/code&gt; returns. Usually
functions take arguments, uses local variables, and returns results.
Since there‚Äôs no real difference between the 31 general purpose
registers, on account of them being, well, general purpose, we could
just use any of them as we wish. Usually though, there are some standard
conventions to follow&lt;/p&gt;&lt;p&gt;This whole time you probably have noticed that registers are listed with two names each, and indeed both work identically in assembly.&lt;/p&gt;&lt;p&gt;These register aliases are named after their uses:&lt;/p&gt;&lt;code&gt;s0&lt;/code&gt; through
&lt;code&gt;s11&lt;/code&gt; are saved registers&lt;code&gt;t0&lt;/code&gt; through
&lt;code&gt;t6&lt;/code&gt; are temporary registers&lt;code&gt;a0&lt;/code&gt; through
&lt;code&gt;a7&lt;/code&gt; are argument registers&lt;code&gt;zero&lt;/code&gt; is the,
well, zero register&lt;code&gt;ra&lt;/code&gt; is for the
return address, by convention, as we‚Äôve seen&lt;code&gt;sp&lt;/code&gt; ‚Ä¶ we‚Äôll talk
about &lt;code&gt;sp&lt;/code&gt; later&lt;code&gt;tp&lt;/code&gt;
and &lt;code&gt;gp&lt;/code&gt; is out of the
scope of this document.)&lt;p&gt;(Yeah it‚Äôs‚Ä¶ all placed in a weird order. The reason is out of the scope of this tutorial.)&lt;/p&gt;&lt;p&gt;When you call a function, you put up to eight arguments in the‚Ä¶ well, argument registers, in the order &lt;code&gt;a0&lt;/code&gt;, &lt;code&gt;a1&lt;/code&gt;, ‚Ä¶,
&lt;code&gt;a7&lt;/code&gt;. After that you use &lt;code&gt;jal&lt;/code&gt; or something, which
puts the return address in &lt;code&gt;ra&lt;/code&gt;, and jumps to the
function.&lt;/p&gt;&lt;p&gt;Inside, the function, if it wishes to use the call-saved registers &lt;code&gt;s0&lt;/code&gt; through &lt;code&gt;s11&lt;/code&gt;, it must save their values at
the start of the function, and restore them before returning. The non
call-saved registers &lt;code&gt;a0&lt;/code&gt; through &lt;code&gt;a7&lt;/code&gt;,
&lt;code&gt;t0&lt;/code&gt; through &lt;code&gt;t6&lt;/code&gt; and &lt;code&gt;ra&lt;/code&gt; may be
modified without restoring their values.&lt;/p&gt;&lt;p&gt;When the called function is done, it would, as mentioned, restore any used call-saved registers, and jump back to the return address, resuming the calling code.&lt;/p&gt;&lt;p&gt;Here‚Äôs a basic-ish example:&lt;/p&gt;&lt;code&gt;int memcmp(const void *a, const void *b, size_t n)&lt;/code&gt;
&lt;p&gt;The parameter &lt;code&gt;a&lt;/code&gt; is passed in &lt;code&gt;a0&lt;/code&gt;,
&lt;code&gt;b&lt;/code&gt; is passed in &lt;code&gt;a1&lt;/code&gt;, and &lt;code&gt;n&lt;/code&gt; is
passed in &lt;code&gt;a2&lt;/code&gt;. The return value will be in &lt;code&gt;a0&lt;/code&gt;.
Here‚Äôs an implementation and test run:&lt;/p&gt;&lt;p&gt;Here‚Äôs a slightly better-organized ‚ÄúHello World‚Äù, using a &lt;code&gt;puts&lt;/code&gt; function:&lt;/p&gt;&lt;p&gt;Although we can write some very basic functions now, there are still a few problems:&lt;/p&gt;&lt;code&gt;ra&lt;/code&gt; would be overwritten, and then you can‚Äôt return back
from the outer function anymore.&lt;p&gt;Clearly, both would require using memory somehow. We can feed two birds with one scone by using memory in a structured way: The stack.&lt;/p&gt;&lt;p&gt;Unlike some other architectures, the &lt;code&gt;sp&lt;/code&gt; register is not
really special in any way. But just like how we can designate how
&lt;code&gt;a0&lt;/code&gt; is used, we can have some conventions about how
&lt;code&gt;sp&lt;/code&gt; is supposed to be used:&lt;/p&gt;&lt;code&gt;sp&lt;/code&gt; needs to have the same value as when the
function was entered&lt;code&gt;sp&lt;/code&gt; always points to somewhere in an area of
memory called the ‚Äústack‚Äù, and it is always 16-byte
aligned.&lt;p&gt;And, for the stack itself:&lt;/p&gt;&lt;code&gt;address &amp;gt;= sp&lt;/code&gt; are ‚Äúin the stack‚Äù, and
&lt;code&gt;address &amp;lt; sp&lt;/code&gt; are free space that the stack can grow
into.&lt;code&gt;sp&lt;/code&gt;, and deallocate space by incrementing &lt;code&gt;sp&lt;/code&gt;.
Of course, allocations and deallocations must be balanced properly.&lt;p&gt;An example is in order. Let‚Äôs say you have a function &lt;code&gt;foo&lt;/code&gt; which just calls &lt;code&gt;bar&lt;/code&gt; twice.&lt;/p&gt;&lt;code&gt;void foo() {
    bar();
    bar();
}&lt;/code&gt;
&lt;p&gt;Inside &lt;code&gt;foo&lt;/code&gt;, it would need to save the initial
&lt;code&gt;ra&lt;/code&gt;, so it can return back later. Even though
&lt;code&gt;ra&lt;/code&gt; takes only 4 bytes, &lt;code&gt;sp&lt;/code&gt; needs to be 16-byte
aligned at all times, so we round that up to 16 bytes. Decrementing
&lt;code&gt;sp&lt;/code&gt; by 16 we allocate the space:&lt;/p&gt;&lt;code&gt;foo:
    addi sp, sp, -16&lt;/code&gt;
&lt;p&gt;Now, in addition to all of the non call-saved registers, we have 16 bytes of scratch space at &lt;code&gt;sp&lt;/code&gt; through &lt;code&gt;sp + 15&lt;/code&gt;.
We can backup the value of &lt;code&gt;ra&lt;/code&gt; here&lt;/p&gt;&lt;code&gt;    ...
    sw ra, 0(sp)&lt;/code&gt;
&lt;p&gt;Then we just call &lt;code&gt;bar&lt;/code&gt; twice, which overwrites
&lt;code&gt;ra&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;    ...
    jal bar
    jal bar&lt;/code&gt;
&lt;p&gt;At the end of the function, we just need to get back the return address, deallocate the stack space, and return. Although using any register would suffice for the return address, since it is the backed up value of &lt;code&gt;ra&lt;/code&gt; after all, we load it back to
&lt;code&gt;ra&lt;/code&gt;.&lt;/p&gt;&lt;code&gt;    ...
    lw ra, 0(sp)
    addi sp, sp, 16
    ret&lt;/code&gt;
&lt;p&gt;In a similar way you can save and restore the &lt;code&gt;s&lt;/code&gt;
(remember, call-saved) registers. Usually, the most convenient way to
manage this is to put values that need to be preserved across inner
function calls in the &lt;code&gt;s&lt;/code&gt; registers, and then add code at the
beginning to save them, and add code at the end to restore them.&lt;/p&gt;&lt;p&gt;Obligatory recursive Fibonacci time!&lt;/p&gt;&lt;p&gt;The algorithm should be fairly straightforward:&lt;/p&gt;&lt;code&gt;fibonacci(n) {
    if (n &amp;lt; 2) { return n; }
    else { return fib(n - 1) + fib(n - 2); }
}&lt;/code&gt;
&lt;p&gt;What‚Äôs worth noting here is the fairly symmetric pattern of saving registers at the start:&lt;/p&gt;&lt;code&gt;    addi sp, sp, -16
    sw ra, 0(sp)
    sw s0, 4(sp)
    sw s1, 8(sp)&lt;/code&gt;
&lt;p&gt;And restoring them at the end:&lt;/p&gt;&lt;code&gt;    lw ra, 0(sp)
    lw s0, 4(sp)
    lw s1, 8(sp)
    addi sp, sp, 16
    ret&lt;/code&gt;
&lt;p&gt;A little thing to also note that the &lt;code&gt;s&lt;/code&gt; registers are
only saved in the more complex branch, where as the simpler branch just
returns directly. This is also acceptable from a calling convention
perspective.&lt;/p&gt;&lt;p&gt;(Note: In the emulator, the &lt;code&gt;sp&lt;/code&gt; register is initialized
to an address that would be convenient for you for use as a stack, as a,
well, convenience.)&lt;/p&gt;&lt;p&gt;Let‚Äôs go back to this example:&lt;/p&gt;&lt;code&gt;    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
puts_loop:
    lb t0, 0(a0)
    beq t0, zero, puts_done
    sw t0, 0(t1)
    addi a0, a0, 1
    j puts_loop

puts_done:
    ret&lt;/code&gt;
&lt;p&gt;Having to name things like &lt;code&gt;puts_loop&lt;/code&gt;,
&lt;code&gt;puts_done&lt;/code&gt; is a bit annoying. There‚Äôs a shorter way: numeric labels.&lt;/p&gt;&lt;p&gt;A numeric label is one with a name of a decimal number. To refer to a numeric label, use the number and a &lt;code&gt;f&lt;/code&gt; suffix for ‚Äúforward‚Äù,
and &lt;code&gt;b&lt;/code&gt; for ‚Äúbackward‚Äù, and it will correspond to the nearest
numeric label with that number, searching forwards or backwards,
respectively.&lt;/p&gt;&lt;p&gt;So, the &lt;code&gt;puts&lt;/code&gt; example from earlier can be rewritten:&lt;/p&gt;&lt;code&gt;    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
1:
    lb t0, 0(a0)
    beq t0, zero, 2f
    sw t0, 0(t1)
    addi a0, a0, 1
    j 1b

2:
    ret&lt;/code&gt;
&lt;p&gt;Yeah I don‚Äôt really like this syntax either, but it is what we‚Äôve got.&lt;/p&gt;&lt;p&gt;Remember that oddball instruction I mentioned way back, &lt;code&gt;auipc&lt;/code&gt;?&lt;/p&gt;&lt;p&gt;I don‚Äôt know about your experience, but the first time I saw RISC-V disassembly, this is the one instruction that caught my eye. And this memory has stuck with me ever since. It‚Äôs a rather common occurrence in real RISC-V programs, and somehow I‚Äôve been hiding it from you this whole time. If you take a sneak peek at the next section‚Äôs title, you‚Äôll see how far we‚Äôve come without &lt;code&gt;auipc&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;So what does it do?&lt;/p&gt;&lt;p&gt;The &lt;code&gt;auipc&lt;/code&gt; (‚Äúadd
upper immediate to pc‚Äù) instruction is very similar to &lt;code&gt;lui&lt;/code&gt;.
Instead of setting &lt;code&gt;rd&lt;/code&gt; to &lt;code&gt;imm20 &amp;lt;&amp;lt; 12&lt;/code&gt;, it
sets it to &lt;code&gt;pc + (imm20 &amp;lt;&amp;lt; 12)&lt;/code&gt;, where &lt;code&gt;pc&lt;/code&gt;
is the address of the &lt;code&gt;auipc&lt;/code&gt; instruction itself.&lt;/p&gt;&lt;code&gt;auipc rd, imm20&lt;/code&gt;
&lt;p&gt;It works very similarly to &lt;code&gt;lui&lt;/code&gt;. You can think of them as
a pair: the ‚Äúbase‚Äù of &lt;code&gt;lui&lt;/code&gt; is &lt;code&gt;0&lt;/code&gt;, whereas the
‚Äúbase‚Äù of &lt;code&gt;auipc&lt;/code&gt; is the address of the &lt;code&gt;auipc&lt;/code&gt;
instruction. So this code:&lt;/p&gt;&lt;code&gt;start:
    auipc a0, 3
    addi a0, a0, 4&lt;/code&gt;
&lt;p&gt;Gives you &lt;code&gt;0x3004&lt;/code&gt;, whereas this:&lt;/p&gt;&lt;code&gt;start:
    auipc a0, 3
    addi a0, a0, 4&lt;/code&gt;
&lt;p&gt;Gives you &lt;code&gt;start + 0x3004&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Why would you need this? On modern systems, it‚Äôs often desirable to have machine code that can be moved around in address space. For example, a shared library i.e. dynamically linked library can be loaded into any program, at any address. It would be helpful if the machine code does not need to be patched every time. This is called position independent code (PIC).&lt;/p&gt;&lt;p&gt;Some instructions already exhibit position independence. For example, as mentioned earlier when we talked about using &lt;code&gt;lui&lt;/code&gt; and
&lt;code&gt;jalr&lt;/code&gt; as a pair, the branch instructions and
&lt;code&gt;jal&lt;/code&gt; are encoded, as with all RV32I instructions, into
32-bit instruction words, so they can‚Äôt possibly be able to encode every
possible address. Instead, the jump destination is &lt;code&gt;pc&lt;/code&gt; plus
some offset (&lt;code&gt;pc&lt;/code&gt; being, as before, the jump/branch
instruction itself), and the offset itself is encoded.&lt;/p&gt;&lt;p&gt;You can see these are three different instructions that jump to itself. Since the offset is &lt;code&gt;0&lt;/code&gt; in each case, the encoding is
the same. Use the ‚ÄúDump‚Äù button to see for yourself.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;auipc&lt;/code&gt; instruction allows for very flexible position
independence. You can make arbitrary calculations based on the address
at which code is located. The immediate-bit operand mirroring
&lt;code&gt;lui&lt;/code&gt; means that it is well suited for two-instruction pairs,
just like &lt;code&gt;lui&lt;/code&gt;. These kind of ‚Äú&lt;code&gt;pc&lt;/code&gt; plus
something‚Äù calculations are known as pc-relative
addressing.&lt;/p&gt;&lt;p&gt;The syntax for getting the assembler to generate the immediate values for pc-relative addressing a bit arcane but hear me out:&lt;/p&gt;&lt;p&gt;Like &lt;code&gt;%hi()&lt;/code&gt; and &lt;code&gt;%lo()&lt;/code&gt;, &lt;code&gt;%pcrel_hi()&lt;/code&gt; and &lt;code&gt;%pcrel_lo()&lt;/code&gt; gives you
the immediate values needed for pc-relative addressing. You pass the
label you want to address to &lt;code&gt;%pcrel_hi()&lt;/code&gt;, but pass a label
to the &lt;code&gt;auipc&lt;/code&gt; instruction to
&lt;code&gt;%pcrel_lo()&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;Unlike &lt;code&gt;%lo()&lt;/code&gt;, We need the address of the
&lt;code&gt;auipc&lt;/code&gt; instruction itself to calculate the immediate value,
and this is why you need to pass a label to it. You don‚Äôt need to write
&lt;code&gt;foo&lt;/code&gt; again, since the assembler will look at the
&lt;code&gt;auipc&lt;/code&gt; instruction and see it‚Äôs supposed to be for
&lt;code&gt;foo&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;If you hate writing that, you can also use the convenience pseudoinstruction &lt;code&gt;la&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;la rd, label&lt;/code&gt;
&lt;p&gt;Just like a &lt;code&gt;lui&lt;/code&gt; + &lt;code&gt;jalr&lt;/code&gt; pair, an
&lt;code&gt;auipc&lt;/code&gt; + &lt;code&gt;jalr&lt;/code&gt; can be used to jump to somewhere
farther away than one &lt;code&gt;jal&lt;/code&gt; can reach in position-independent
code.&lt;/p&gt;&lt;p&gt;One very common case is to call a function that might not be within reach of &lt;code&gt;jal&lt;/code&gt;. You can use the pseudoinstruction &lt;code&gt;call&lt;/code&gt; for that.&lt;/p&gt;&lt;code&gt;call label&lt;/code&gt;
&lt;p&gt;This expands to:&lt;/p&gt;&lt;code&gt;1:
    auipc ra, %pcrel_hi(label)
    jalr ra, %pcrel_lo(1b)(ra)&lt;/code&gt;
&lt;p&gt;Notice how &lt;code&gt;ra&lt;/code&gt; is used as a temporary register to store
the intermediate result, which is immediately overwritten by
&lt;code&gt;jalr&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;In fact, there really isn‚Äôt any reason to prefer &lt;code&gt;lui&lt;/code&gt;
over &lt;code&gt;auipc&lt;/code&gt; when using a label. This is why you if you
disassemble a real RISC-V program, you see it everywhere, even in
non-position-independent code.&lt;/p&gt;&lt;p&gt;Now would be a good time to take a break, since we‚Äôre ready to head into‚Ä¶&lt;/p&gt;&lt;p&gt;We‚Äôre going to write an extremely bare bones operating system.&lt;/p&gt;&lt;p&gt;One of the tasks an operating system performs is to control what programs can and cannot do. On RISC-V, the most basic of this control is implemented using privilege levels. RISC-V defines‚Ä¶ let‚Äôs just say, several privilege levels, but we‚Äôre only going to use two here:&lt;/p&gt;&lt;p&gt;The lower the privilege level number goes, the less privileged that level is. Higher privilege levels treat lower privilege levels as generally completely unreliable and untrusted, and must isolate themselves from adversarial software and failures of lower privilege levels.&lt;/p&gt;&lt;p&gt;(However, we won‚Äôt be talking about all of the features that make this full isolation possible, and the emulator you‚Äôve been seeing does not have enough features for that anyway. Therefore, the operating system we‚Äôll be building will leave itself unprotected in various ways.)&lt;/p&gt;&lt;p&gt;The privilege levels are sometimes called ‚Äúmodes‚Äù for short. And, if that‚Äôs not short enough, we can shorten the level names themselves, ending up with M-mode and U-mode. All of the ways to refer to these privilege levels are interchangable.&lt;/p&gt;&lt;p&gt;When a RISC-V machine starts (This is known as ‚Äúreset‚Äù), it begins execution in Machine mode. On a typical ‚Äúembedded‚Äù system where only Machine mode and User mode are implemented, execution begins in the initialization code read from flash memory. This code can either perform what needs to be done itself, or it can be an operating system that manages some tasks, each executing in User mode.&lt;/p&gt;&lt;p&gt;The former design is used for simpler programs, and is analogous to the programs we‚Äôve seen and run so far. The latter is more complicated. We‚Äôll see the basics of how to achieve that soon.&lt;/p&gt;&lt;p&gt;The control and status registers (CSRs) deal with various features that are in some sense ‚Äúspecial‚Äù. No I don‚Äôt have a better explanation of what ‚Äúspecial‚Äù means.&lt;/p&gt;&lt;p&gt;Six instructions are available for manipulating CSRs.&lt;/p&gt;&lt;code&gt;csrrw rd, csr, rs1
csrrs rd, csr, rs1
csrrc rd, csr, rs1
csrrwi rd, csr, uimm5
csrrsi rd, csr, uimm5
csrrci rd, csr, uimm5&lt;/code&gt;
&lt;p&gt;To refer to a CSR in these instructions, use its name in assembly code. We‚Äôll get to those in a bit.&lt;/p&gt;&lt;p&gt;The pattern works like this. Each of the instructions atomically reads the old value of the CSR, and writes the new value based on some operation performed on the old value and the last operand. The possible operations are:&lt;/p&gt;&lt;code&gt;csrrw&lt;/code&gt; (‚ÄúCSR read
write‚Äù): &lt;code&gt;{ csr = rs1; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrs&lt;/code&gt; (‚ÄúCSR read
set‚Äù): &lt;code&gt;{ csr = csr | rs1; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrc&lt;/code&gt; (‚ÄúCSR read
clear‚Äù): &lt;code&gt;{ csr = csr &amp;amp; ~rs1; rd = csr_old; }&lt;/code&gt;&lt;p&gt;Where &lt;code&gt;&amp;amp;&lt;/code&gt;, &lt;code&gt;|&lt;/code&gt;, &lt;code&gt;~&lt;/code&gt; are bitwise
‚Äúand‚Äù, ‚Äúor‚Äù, ‚Äúnot‚Äù respectively.&lt;/p&gt;&lt;p&gt;Specifically, note that &lt;code&gt;rd&lt;/code&gt; and &lt;code&gt;rs1&lt;/code&gt; can be
the same. For example, this instruction swaps the value in
&lt;code&gt;a0&lt;/code&gt; and &lt;code&gt;mscratch&lt;/code&gt;:&lt;/p&gt;&lt;code&gt;csrrw a0, mscratch, a0&lt;/code&gt;
&lt;p&gt;For the ‚Äúimmediate‚Äù variants, instead of a register, they take an ‚Äúunsigned‚Äù/zero-extended 5-bit immediate value, i.e. an immediate value 0 through 31, inclusive. This is represented using &lt;code&gt;uimm5&lt;/code&gt; in
the assembly syntax description. The operation is the same
otherwise.&lt;/p&gt;&lt;code&gt;csrrwi&lt;/code&gt; (‚ÄúCSR
read write immediate‚Äù): &lt;code&gt;{ csr = uimm5; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrsi&lt;/code&gt; (‚ÄúCSR
read set immediate‚Äù):
&lt;code&gt;{ csr = csr | uimm5; rd = csr_old; }&lt;/code&gt;&lt;code&gt;csrrci&lt;/code&gt; (‚ÄúCSR
read clear immediate‚Äù):
&lt;code&gt;{ csr = csr &amp;amp; ~uimm5; rd = csr_old; }&lt;/code&gt;&lt;p&gt;The full feature set of these instructions are designed for manipulating bit fields in CSRs, which we will not be doing that much of in this tutorial. Still, this orthogonal design should be fairly intuitive to remember.&lt;/p&gt;&lt;p&gt;CSRs and fields in CSRs do not behave like general purpose registers: Some of them are read/write, some are read-only. Also, invalid values have special behaviors. We will touch on more details as we introduce the individual CSRs themselves, but one thing you may have noticed is that we don‚Äôt seem to have read-only CSR instructions. Read-only access is achieved using special cases in the instruction encodings:&lt;/p&gt;&lt;code&gt;csrrs&lt;/code&gt; and &lt;code&gt;csrrc&lt;/code&gt; do not write to the CSR if
&lt;code&gt;rs1&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; (a.k.a. &lt;code&gt;zero&lt;/code&gt;) (Note
that just the value of &lt;code&gt;rs1&lt;/code&gt; being 0 is not enough.)&lt;code&gt;csrrsi&lt;/code&gt; and &lt;code&gt;csrrci&lt;/code&gt; do not write to the CSR
if &lt;code&gt;uimm5&lt;/code&gt; is 0.&lt;p&gt;While we‚Äôre at it:&lt;/p&gt;&lt;code&gt;csrrw&lt;/code&gt; and &lt;code&gt;csrrwi&lt;/code&gt; do not read the CSR if
&lt;code&gt;rd&lt;/code&gt; is &lt;code&gt;x0&lt;/code&gt; (a.k.a. &lt;code&gt;zero&lt;/code&gt;). (Note
that writing to &lt;code&gt;x0&lt;/code&gt; has no effect anyway, since it‚Äôs
constant 0.)&lt;p&gt;(No standard RISC-V CSR is write-only, or has side effects on read.)&lt;/p&gt;&lt;p&gt;As a convenience, the pseudoinstructions &lt;code&gt;csrr&lt;/code&gt; (‚ÄúCSR read‚Äù) and &lt;code&gt;csrw&lt;/code&gt; (‚ÄúCSR write‚Äù) are
available. &lt;code&gt;csrw csr, rs1&lt;/code&gt; expands to
&lt;code&gt;csrrw x0, csr, rs1&lt;/code&gt;. Meanwhile, &lt;code&gt;csrr rd, csr&lt;/code&gt;
expands specifically to &lt;code&gt;csrrs rd, csr, x0&lt;/code&gt;, just so we can
agree on an encoding.&lt;/p&gt;&lt;code&gt;csrw csr, rs1
csrr rd, csr&lt;/code&gt;
&lt;p&gt;You may have seen these CSR things if you‚Äôve scrolled down on the register view. Yes, we‚Äôre finally getting into those.&lt;/p&gt;&lt;p&gt;An example of CSRs is counters. Two basic read-only counters are &lt;code&gt;cycle&lt;/code&gt; and
&lt;code&gt;instret&lt;/code&gt;. These
counters, well, count the number of ‚Äúcycles‚Äù and ‚Äúinstructions
retired‚Äù. ‚ÄúRetired‚Äù is a technical term basically meaning ‚Äúsuccessfully
completed‚Äù.&lt;/p&gt;&lt;p&gt;Since a 32-bit counter will overflow quite fast, on RV32, the counters have ‚Äúhigh‚Äù counterparts: &lt;code&gt;cycleh&lt;/code&gt; and &lt;code&gt;instreth&lt;/code&gt;. So, for
example, the full cycle counter has 64 bits, with the lower 32 bits in
the CSR &lt;code&gt;cycle&lt;/code&gt; and higher 32 bits in the CSR
&lt;code&gt;cycleh&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;While the emulator is running, scroll down on the register view panel, and on the bottom you‚Äôll see the values of these counters. For convenience, they‚Äôre shown combined, so, &lt;code&gt;cycle = 0x11223344_55667788&lt;/code&gt; means &lt;code&gt;cycleh&lt;/code&gt; is
&lt;code&gt;0x11223344&lt;/code&gt;, and &lt;code&gt;cycle&lt;/code&gt; is
&lt;code&gt;0x55667788&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;On real hardware &lt;code&gt;cycle&lt;/code&gt; is coupled to the clock cycle. In
this emulator, every time you press ‚ÄúStep‚Äù, it counts as a cycle. When
you press ‚ÄúRun‚Äù and it starts, well, running, a certain number of cycles
happen periodically.&lt;/p&gt;&lt;p&gt;Let‚Äôs look at a really simple example:&lt;/p&gt;&lt;p&gt;It takes 4 cycles for this program to stop, but &lt;code&gt;instret&lt;/code&gt;
ends up at only 3 because the final &lt;code&gt;ebreak&lt;/code&gt; instruction
never actually completes.&lt;/p&gt;&lt;p&gt;(Do not confuse ‚Äúretired‚Äù with ‚Äúretried‚Äù.)&lt;/p&gt;&lt;p&gt;A program can read its own counters. For example, this fun little program loops until the cycle count is over 1000, assuming the low 32 bits doesn‚Äôt overflow before it has time to react:&lt;/p&gt;&lt;p&gt;Technically &lt;code&gt;cycle&lt;/code&gt; and &lt;code&gt;instret&lt;/code&gt; are not part
of the privileged architecture. The real fun begins now.&lt;/p&gt;&lt;p&gt;The emulator shows the current privilege level as &lt;code&gt;(priv)&lt;/code&gt;. It is in parentheses to remind you of a very
important fact:&lt;/p&gt;&lt;p&gt;There is no CSR for the current privilege level.&lt;/p&gt;&lt;p&gt;In general, it is not possible for a RISC-V program to learn what privilege level it‚Äôs in. This is required for the Popek and Goldberg conditions of virtualization to work, specifically because being able to read the current privilege level at a lower-than-maximum privilege level would be a ‚Äúsensitive‚Äù but ‚Äúunprivileged‚Äù instruction.&lt;/p&gt;&lt;p&gt;If you‚Äôre writing a program for a certain privilege level, you should simply assume that it is correctly being run at that privilege level.&lt;/p&gt;&lt;p&gt;A fundamental way an operating system does its job is through handling exceptions. In general, exceptions occur when there‚Äôs a problem with a specific instruction, and execution cannot continue. For example, since &lt;code&gt;cycle&lt;/code&gt; is a read-only CSR, writing to it is
an illegal instruction:&lt;/p&gt;&lt;p&gt;Since we have no exception handling in the program, we‚Äôll have to inspect what happened manually in the emulator. Indeed, a lot has happened:&lt;/p&gt;&lt;p&gt;Firstly, this message tells you that an exception happened:&lt;/p&gt;&lt;code&gt;[ Exception: Illegal instruction (2) | tval = 0xc0001073, epc = 0x4000000c ]&lt;/code&gt;
&lt;p&gt;The same information is now also available in the CSRs, as follows:&lt;/p&gt;&lt;code&gt;mcause&lt;/code&gt; (‚ÄúM-mode
trap cause‚Äù): The kind of exception.&lt;code&gt;mepc&lt;/code&gt; (‚ÄúM-mode
exception pc‚Äù): The address of the instruction that caused the
exception.&lt;code&gt;mtval&lt;/code&gt; (‚ÄúM-mode
trap value‚Äù): Extra information about the exception.&lt;code&gt;mstatus&lt;/code&gt; (‚ÄúM-mode
status‚Äù): It is set to &lt;code&gt;0x00001800&lt;/code&gt;. The two bits in the
middle, &lt;code&gt;mstatus[12:11]&lt;/code&gt; (In C syntax,
&lt;code&gt;(mstatus &amp;gt;&amp;gt; 11) &amp;amp; 0x3&lt;/code&gt;) is the
&lt;code&gt;mstatus.MPP&lt;/code&gt; (‚ÄúM-mode previous privilege level‚Äù) field,
which contains 3, meaning that the exception occurred while running in
Machine mode.&lt;p&gt;When an exception happens, in addition to recording the exception information in these CSR fields, &lt;code&gt;pc&lt;/code&gt; is set to
&lt;code&gt;mtvec&lt;/code&gt;, which is supposed to be the handler address. Let‚Äôs
write ourselves an exception handler that simply prints a message and
stops the emulator, and see the handling in action:&lt;/p&gt;&lt;p&gt;Yeah it just prints &lt;code&gt;Oh no!&lt;/code&gt; on error. Baby steps‚Ä¶&lt;/p&gt;&lt;p&gt;The checkboxes ‚ÄúPause on exc.‚Äù and ‚ÄúPrint on exc.‚Äù control whether the emulator should pause or print a message, respectively, when an exception occurs. You can uncheck those if you want the exception handler set in the program to run without interference.&lt;/p&gt;&lt;p&gt;(Another case that will cause a jump to &lt;code&gt;mtvec&lt;/code&gt; is interrupts. However, this feature
does not exist in the emulator. The two cases are collectively called
traps.)&lt;/p&gt;&lt;p&gt;These are the exceptions possible in this emulator, and their respective numeric codes:&lt;/p&gt;&lt;table&gt;&lt;row span="2"&gt;&lt;cell role="head"&gt;Description&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;0&lt;/cell&gt;&lt;cell&gt;Instruction address misaligned&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;1&lt;/cell&gt;&lt;cell&gt;Instruction access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;2&lt;/cell&gt;&lt;cell&gt;Illegal instruction&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;3&lt;/cell&gt;&lt;cell&gt;Breakpoint&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;5&lt;/cell&gt;&lt;cell&gt;Load access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;7&lt;/cell&gt;&lt;cell&gt;Store/AMO access fault&lt;/cell&gt;&lt;/row&gt;&lt;row span="2"&gt;&lt;cell&gt;8&lt;/cell&gt;&lt;cell&gt;Environment call from User mode&lt;/cell&gt;&lt;/row&gt;&lt;row&gt;&lt;cell&gt;11&lt;/cell&gt;&lt;cell&gt;Environment call from Machine mode&lt;/cell&gt;&lt;/row&gt;&lt;/table&gt;&lt;p&gt;‚ÄúInstruction address misaligned‚Äù happens when attempting to jump to an instruction that is not 4-byte aligned. The exception happens on the jump or branch instruction, not the target.&lt;/p&gt;&lt;p&gt;‚ÄúLoad access fault‚Äù and ‚ÄúStore/AMO access fault‚Äù happens when accessing an invalid memory address, or accessing a memory address in an invalid way.&lt;/p&gt;&lt;p&gt;(‚ÄúAMO‚Äù stands for ‚Äúatomic memory operation‚Äù, which we will not talk about and is not featured in the emulator.)&lt;/p&gt;&lt;p&gt;‚ÄúIllegal instruction‚Äù happens not only in the self explanatory way when an invalid instruction is executed, but also when accessing a CSR in an invalid way, or from too low a privilege level.&lt;/p&gt;&lt;p&gt;‚ÄúBreakpoint‚Äù, ‚ÄúEnvironment call from User mode‚Äù and ‚ÄúEnvironment call from Machine mode‚Äù will be explained in a future section.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;mret&lt;/code&gt; (‚ÄúM-mode
return‚Äù) instruction performs the reverse of part of what happens when
an exception occurs. To be precise, what happens is:&lt;/p&gt;&lt;code&gt;mstatus.MPP&lt;/code&gt;&lt;code&gt;mstatus.MPP&lt;/code&gt; is set to 0&lt;code&gt;pc&lt;/code&gt; is set to &lt;code&gt;mepc&lt;/code&gt;&lt;p&gt;(You can think of the privilege mode bits as shifting in a chain &lt;code&gt;0 ‚Üí MPP ‚Üí priv&lt;/code&gt;. And, to be even more precise,
&lt;code&gt;mstatus.MPP&lt;/code&gt; is set to the lowest supported privilege mode
since it‚Äôs not supposed to contain unsupported modes.)&lt;/p&gt;&lt;p&gt;&lt;code&gt;mret&lt;/code&gt; takes no operands, so the assembly syntax is
simply:&lt;/p&gt;&lt;code&gt;mret&lt;/code&gt;
&lt;p&gt;If we do &lt;code&gt;mret&lt;/code&gt; after getting an exception, then we simply
go back to retrying the same instruction again. This is useful for more
featureful implementations, where for example, after handling a page
fault the correct course of action is to retry the faulting
instruction.&lt;/p&gt;&lt;p&gt;However, &lt;code&gt;mstatus&lt;/code&gt; and &lt;code&gt;mepc&lt;/code&gt; are also
writable. This gives us more flexibility in the use of
&lt;code&gt;mret&lt;/code&gt;. As an analogy, the same &lt;code&gt;jr&lt;/code&gt; instruction
(really &lt;code&gt;jalr&lt;/code&gt; instruction) can be used to return from a
call, and also can be used to jump to any address. Similarly,
&lt;code&gt;mret&lt;/code&gt; not only lets us return from an exception, but also
lets us jump to any address and switch to any privilege
level.&lt;/p&gt;&lt;p&gt;Even though &lt;code&gt;mret&lt;/code&gt; is named ‚Äúreturn‚Äù, it is in fact the
only way to lower the privilege level to enter User mode.
Here‚Äôs an example of entering User mode, with a User mode program that
does something bad:&lt;/p&gt;&lt;p&gt;As you can see, after we enter User mode, all of the CSRs used for exception handling become completely inaccessible, not even readable. As with writing a read-only CSR, accessing an CSR without permission also causes an illegal instruction exception.&lt;/p&gt;&lt;p&gt;Moreover, when an exception happens, we go back to Machine mode, so the exception handler runs in Machine mode. Here the handler does nothing except stopping the emulator.&lt;/p&gt;&lt;p&gt;Sometimes, a program may wish to intentionally cause an exception. There are several well-defined way to do that:&lt;/p&gt;&lt;code&gt;unimp&lt;/code&gt; has the same encoding
as &lt;code&gt;csrrw zero, cycle, zero&lt;/code&gt;, and it is the canonical RV32I
illegal instruction. It causes causes an ‚ÄúIllegal instruction‚Äù
exception.&lt;code&gt;ebreak&lt;/code&gt; causes a
‚ÄúBreakpoint‚Äù exception&lt;code&gt;ecall&lt;/code&gt; causes an
‚ÄúEnvironment call from User mode‚Äù exception when executed in User mode,
and ‚ÄúEnvironment call from Machine mode‚Äù exception when executed in
Machine mode.&lt;p&gt;Give those exceptions a try here:&lt;/p&gt;&lt;p&gt;As the names suggest, &lt;code&gt;ebreak&lt;/code&gt; is used for debugging
breakpoints. As a special case, in this emulator &lt;code&gt;ebreak&lt;/code&gt; in
Machine mode stops the emulator. You can think of it as the emulator
being a debugger, and the debugger catching the breakpoint.&lt;/p&gt;&lt;p&gt;&lt;code&gt;unimp&lt;/code&gt; can be used to intentionally crash a program upon
detection of some unrecoverable error.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;code&gt;ecall&lt;/code&gt; is used for things like system calls.
‚ÄúEnvironment call from User mode‚Äù is a distinct exception cause code to
make it easy to check specifically for this case.&lt;/p&gt;&lt;p&gt;One thing that you would want in your trap handler is to not trust or disturb any general purpose registers in the code that the trap occurred in, unless you intentionally want to do so, for example to return a value from a system call. So you‚Äôd want to save all the registers to memory, before doing anything else. However, accessing memory requires a general purpose register.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;mscratch&lt;/code&gt;
(‚ÄúM-mode scratch‚Äù) CSR can help with this. This register, unlike all the
others, have no special functionality. It can hold any 32-bit value.
However, like all the other M-mode CSRs, it can only be accessed in
Machine mode. User mode code cannot change the value of it.&lt;/p&gt;&lt;p&gt;So for example, you can stash the operating system stack pointer in &lt;code&gt;mscratch&lt;/code&gt; before switching to User mode, and it will stay in
&lt;code&gt;mscratch&lt;/code&gt; untouched in User mode. At the top of the handler,
&lt;code&gt;csrrw sp, mscratch, sp&lt;/code&gt; to swap from the user stack pointer
to the operating system stack pointer.&lt;/p&gt;&lt;code&gt;handler:
    csrrw sp, mscratch, sp
    # Save registers except sp
    csrr t0, mscratch
    # t0 = user sp, save it
    # Save user pc
    ...&lt;/code&gt;
&lt;p&gt;And, to restore:&lt;/p&gt;&lt;code&gt;    lw t0, ... # Load user pc
    csrw mepc, t0
    lw t0, ... # Load user sp
    csrw mscratch, t0
    # Restore registers except sp
    csrrw sp, mscratch, sp
    mret&lt;/code&gt;
&lt;p&gt;We‚Äôll see the full code for this in the following section.&lt;/p&gt;&lt;p&gt;We have enough of to write a very very bare bones operating system. It will support these features:&lt;/p&gt;&lt;code&gt;a7 = 1&lt;/code&gt;: putchar, &lt;code&gt;a0&lt;/code&gt; is the byte to
write&lt;code&gt;a7 = 2&lt;/code&gt;: exit&lt;p&gt;We design the exception handling as follows:&lt;/p&gt;&lt;code&gt;mscratch&lt;/code&gt; is 0.&lt;code&gt;mscratch&lt;/code&gt; points to the operating
system stack pointer&lt;code&gt;mscratch&lt;/code&gt; is 0, the exception came
from M-mode, which we cannot handle, so we report a fatal
exception.&lt;code&gt;trap_main&lt;/code&gt;, which manipulates
U-mode registers in memory&lt;code&gt;trap_main&lt;/code&gt;, we restore registers from memory,
deallocate the space from the stack, and go back to U-mode, as outlined
in the previous section.&lt;p&gt;The structure to save registers in is fairly simple:&lt;/p&gt;&lt;code&gt;struct regs {
  unsigned long pc;
  unsigned long ra; // x1
  unsigned long sp; // x2
  ...
  unsigned long t6; // x31
};&lt;/code&gt;
&lt;p&gt;Basically you can think of it as an array where element 0 is &lt;code&gt;pc&lt;/code&gt;, and elements 1 through 31 are registers x1 through
x31.&lt;/p&gt;&lt;p&gt;Inside &lt;code&gt;trap_main&lt;/code&gt;, we check &lt;code&gt;mcause&lt;/code&gt; to see if
it‚Äôs a system call. If it is, we dispatch based on &lt;code&gt;a7&lt;/code&gt;. If
it‚Äôs not, we report an exception from U-mode.&lt;/p&gt;&lt;p&gt;At the beginning, we simply initialize the &lt;code&gt;struct regs&lt;/code&gt;
structure on stack, initialize user &lt;code&gt;sp&lt;/code&gt; and &lt;code&gt;pc&lt;/code&gt;
in it, and jump to the same code that handles returning to U-mode.&lt;/p&gt;&lt;p&gt;Here‚Äôs the assembly code with User mode code at the bottom. You may want to uncheck ‚ÄúPause on exc.‚Äù and ‚ÄúPrint on exc.‚Äù for convenience.&lt;/p&gt;&lt;p&gt;Do not be too hard on yourself if you have trouble understanding the code fully. This is, after all, a fairly complete OS kernel entry and exit implementation. Really, the most important part I‚Äôm showing you here is that it is possible.&lt;/p&gt;&lt;p&gt;For reference, here‚Äôs some of the OS code in pseudo-C.&lt;/p&gt;&lt;code&gt;void trap_main(struct regs *regs) {
    unsigned long cause = csr_read(mcause);
    if (cause != 8)
        do_bad_exception(regs, cause);

    # Call do_syscall with args from ecall
    unsigned long ret = do_syscall(regs-&amp;gt;a0, ..., regs-&amp;gt;a7);
    regs-&amp;gt;a0 = ret;

    // Bump user pc by 4, skip over ecall instruction
    regs-&amp;gt;pc += 4;
}

unsigned long do_syscall(
    unsigned long a0,
    ...,
    unsigned long a7
) {
    if (a7 == 1)
        sys_putchar(a0);
    else if (a7 == 8)
        sys_exit();
    else
        return -1;
}

unsigned long sys_putchar(char a) {
    kputchar(a);
    return 0;
}

[[noreturn]]
unsigned long sys_exit(char a) {
    ebreak();
}

[[noreturn]]
void do_bad_exception(struct regs *regs, unsigned long cause) {
    kputs("Exception 0x");
    kputchar(hex_chars[cause]);
    kputchar('\n');
    ebreak();
}

[[noreturn]]
void fatal() {
    kputs("Fatal exception\n");
    ebreak();
}

void kputs(const char *str) {
    while (*str) {
        u32 val = (u32)*str;
        writel(0x10000000, val); // MMIO write
        str ++;
    }
}

void kputchar(char c) {
    u32 val = (u32)c;
    writel(0x10000000, val); // MMIO write
}&lt;/code&gt;
&lt;p&gt;And here‚Äôs the user code, again in pseudo C:&lt;/p&gt;&lt;code&gt;[[noreturn]]
void user_entry() {
    puts(...);
    exit();
}

void puts(const char *str) {
    while (*str) {
        putchar(*str);
        str ++;
    }
}

void putchar(char c) {
    ecall(a0 = c, a7 = 1);
}

void exit() {
    ecall(a7 = 2);
}&lt;/code&gt;
&lt;p&gt;As long as this tutorial is, some simplifications have been made. Here are some of the most egregious lies and omissions, compared to the ‚Äúreal‚Äù RISC-V architecture and ‚Äúreal‚Äù RISC-V assembly code found in the world:&lt;/p&gt;&lt;code&gt;li&lt;/code&gt; pseudoinstruction should support a wider range
of constants.&lt;code&gt;mstatus&lt;/code&gt; is a lot more complicated than what I have
described.&lt;code&gt;%hi&lt;/code&gt;, &lt;code&gt;%lo&lt;/code&gt;, &lt;code&gt;%pcrel_hi&lt;/code&gt;,
&lt;code&gt;%pcrel_lo&lt;/code&gt; are more complicated than what I have
described.&lt;p&gt;There are also very important topics that are common or even ubiquitous in the RISC-V world, but I chose not to cover:&lt;/p&gt;&lt;p&gt;However, what I‚Äôve taught you should be more than enough to get you started into learning more on your own, or with further materials.&lt;/p&gt;&lt;p&gt;Here are some references and tutorials I would personally recommend, if you‚Äôre looking to get further into RISC-V low-level development&lt;/p&gt;&lt;p&gt;Other useful resources that I have used while writing this tutorial:&lt;/p&gt;&lt;code&gt;arch/riscv/kernel/entry.S&lt;/code&gt; from Linux https://elixir.bootlin.com/linux/latest/source/arch/riscv/kernel/entry.S&lt;p&gt;Thanks to these folks for UI design help and content suggestions:&lt;/p&gt;&lt;p&gt;And thanks to you for coming along with me on this journey. Come on over to https://github.com/dramforever/easyriscv if you have suggestions, grievances, or just want to share some thoughts.&lt;/p&gt;&lt;p&gt;This tutorial is under the CC0 license. To the maximum extent permitted by law, this tutorial is dedicated to the public domain.&lt;/p&gt;&lt;code&gt;add&lt;/code&gt;&lt;code&gt;addi&lt;/code&gt;&lt;code&gt;and&lt;/code&gt;&lt;code&gt;andi&lt;/code&gt;&lt;code&gt;auipc&lt;/code&gt;&lt;code&gt;beq&lt;/code&gt;&lt;code&gt;bge&lt;/code&gt;&lt;code&gt;bgeu&lt;/code&gt;&lt;code&gt;blt&lt;/code&gt;&lt;code&gt;bltu&lt;/code&gt;&lt;code&gt;bne&lt;/code&gt;&lt;code&gt;call&lt;/code&gt;&lt;code&gt;csrr&lt;/code&gt;&lt;code&gt;csrrc&lt;/code&gt;&lt;code&gt;csrrci&lt;/code&gt;&lt;code&gt;csrrs&lt;/code&gt;&lt;code&gt;csrrsi&lt;/code&gt;&lt;code&gt;csrrw&lt;/code&gt;&lt;code&gt;csrrwi&lt;/code&gt;&lt;code&gt;csrw&lt;/code&gt;&lt;code&gt;ebreak&lt;/code&gt;&lt;code&gt;ecall&lt;/code&gt;&lt;code&gt;j&lt;/code&gt;&lt;code&gt;jal&lt;/code&gt;&lt;code&gt;jalr&lt;/code&gt;&lt;code&gt;jr&lt;/code&gt;&lt;code&gt;la&lt;/code&gt;&lt;code&gt;lb&lt;/code&gt;&lt;code&gt;lbu&lt;/code&gt;&lt;code&gt;lh&lt;/code&gt;&lt;code&gt;lhu&lt;/code&gt;&lt;code&gt;li&lt;/code&gt;&lt;code&gt;lui&lt;/code&gt;&lt;code&gt;lw&lt;/code&gt;&lt;code&gt;mret&lt;/code&gt;&lt;code&gt;mv&lt;/code&gt;&lt;code&gt;or&lt;/code&gt;&lt;code&gt;ori&lt;/code&gt;&lt;code&gt;ret&lt;/code&gt;&lt;code&gt;sb&lt;/code&gt;&lt;code&gt;sh&lt;/code&gt;&lt;code&gt;sll&lt;/code&gt;&lt;code&gt;slli&lt;/code&gt;&lt;code&gt;slt&lt;/code&gt;&lt;code&gt;slti&lt;/code&gt;&lt;code&gt;sltiu&lt;/code&gt;&lt;code&gt;sltu&lt;/code&gt;&lt;code&gt;sra&lt;/code&gt;&lt;code&gt;srai&lt;/code&gt;&lt;code&gt;srl&lt;/code&gt;&lt;code&gt;srli&lt;/code&gt;&lt;code&gt;sub&lt;/code&gt;&lt;code&gt;sw&lt;/code&gt;&lt;code&gt;unimp&lt;/code&gt;&lt;code&gt;xor&lt;/code&gt;&lt;code&gt;xori&lt;/code&gt;&lt;code&gt;imm&lt;/code&gt;&lt;code&gt;pc&lt;/code&gt;&lt;code&gt;rd&lt;/code&gt;&lt;code&gt;rs1&lt;/code&gt;&lt;code&gt;rs2&lt;/code&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://dramforever.github.io/easyriscv/"/><published>2025-10-27T20:57:12+00:00</published></entry></feed>