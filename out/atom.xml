<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-09-24T11:08:25.356194+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45347532</id><title>Getting AI to work in complex codebases</title><updated>2025-09-24T11:08:34.348696+00:00</updated><content>&lt;doc fingerprint="3b74d0de090e4684"&gt;
  &lt;main&gt;
    &lt;p&gt;We read every piece of feedback, and take your input very seriously.&lt;/p&gt;
    &lt;p&gt;To see all available qualifiers, see our documentation.&lt;/p&gt;
    &lt;p&gt;There was an error while loading. Please reload this page.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md"/><published>2025-09-23T14:27:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45347914</id><title>Launch HN: Strata (YC X25) ‚Äì One MCP server for AI to handle thousands of tools</title><updated>2025-09-24T11:08:33.953388+00:00</updated><content>&lt;doc fingerprint="3d5a22c222f374b3"&gt;
  &lt;main&gt;
    &lt;div&gt;&lt;p&gt;Hey HN! We are Klavis AI (&lt;/p&gt;https://www.klavis.ai/&lt;p&gt;) and we're launching Strata, one open-source MCP server that helps AI agents use thousands of API tools without getting overwhelmed. Instead of showing all available tools at once, Strata reveals them step-by-step based on what the AI actually needs.&lt;/p&gt;&lt;p&gt;As a former Senior SWE on Google Gemini 's tool use team, I saw firsthand how AI would struggle with tools. If you've built AI agents, you've likely hit the same walls: (1) AI agents struggle to pick the right API from hundreds of options. (2) Tool descriptions and info consume massive token budgets. (3) Most servers cap at 40~50 tools to avoid these problems, limiting what you can build.&lt;/p&gt;&lt;p&gt;Instead of flooding the AI with everything upfront, Strata works like a human would. It guides the AI agents to discover relevant categories, then lists available actions in those categories. It relies on LLMs‚Äô reasoning to drill down progressively to find the exact tool needed. Here are some examples:&lt;/p&gt;&lt;p&gt;Github query: "Find my stale pull requests in our main repo"&lt;/p&gt;&lt;p&gt;Strata: AI model identifies GitHub ‚Üí Shows categories (Repos, Issues, PRs, Actions) ‚Üí AI selects PRs ‚Üí Shows PR-specific actions -&amp;gt; AI selects list_pull_requests ‚Üí Shows list_pull_requests details -&amp;gt; Executes list_pull_requests with the right parameters.&lt;/p&gt;&lt;p&gt;Jira query: "Create a bug ticket in the 'MOBILE' project about the app crashing on startup."&lt;/p&gt;&lt;p&gt;Strata: AI identifies Jira ‚Üí Shows categories (Projects, Issues, Sprints) ‚Üí AI selects Issues ‚Üí Shows actions (create_issue, get_issue) ‚Üí AI selects create_issue ‚Üí Shows create_issue details ‚Üí Executes with correct parameters.&lt;/p&gt;&lt;p&gt;Slack query: "Post a message in the #announcements channel that bonus will be paid out next Friday."&lt;/p&gt;&lt;p&gt;Strata: AI identifies Slack ‚Üí Shows categories (Channels, Messages, Users) ‚Üí AI selects Messages ‚Üí Shows actions (send_message, schedule_message) ‚Üí AI selects send_message ‚Üí Shows send_message details ‚Üí Executes with correct parameters.&lt;/p&gt;&lt;p&gt;This progressive approach unlocks a huge advantage: depth. While most integrations offer a handful of high-level tools, Strata can expose hundreds of granular features for a single app like GitHub, Jira, etc. Your AI agent can finally access the deep, specific features that real workflows require, without getting lost in a sea of options.&lt;/p&gt;&lt;p&gt;Under the hood, Strata manages authentication tokens and includes a built-in search tool for the agent to dig into documentation if it gets stuck.&lt;/p&gt;&lt;p&gt;On the MCPMark https://mcpmark.ai/leaderboard/mcp, Strata achieves +15.2% higher pass@1 rate vs the official GitHub server and +13.4% higher pass@1 rate vs the official Notion server. In human eval tests, it hits 83%+ accuracy on complex, real-world multi-app workflows.&lt;/p&gt;&lt;p&gt;Here is a quick demo to watch Strata navigate a complex workflow with multiple apps, automatically selecting the right tools at each step: https://www.youtube.com/watch?v=N00cY9Ov_fM.&lt;/p&gt;&lt;p&gt;You can connect to any external MCP Server into Strata, and we have an open source version for it: https://github.com/Klavis-AI/klavis.&lt;/p&gt;&lt;p&gt;For team or production use with more features, visit our website: https://www.klavis.ai. Add Strata to Cursor, VS Code or any MCP-compatible application with one click. You can also use our API to easily plug in Strata to your AI application.&lt;/p&gt;&lt;p&gt;We look forward to your comments. Thanks for reading!&lt;/p&gt;&lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.ycombinator.com/item?id=45347914"/><published>2025-09-23T14:52:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45348495</id><title>Always Invite Anna</title><updated>2025-09-24T11:08:33.566255+00:00</updated><content>&lt;doc fingerprint="fedd98054dfc58ec"&gt;
  &lt;main&gt;
    &lt;p&gt;I was lucky enough to make a few friends my first semester of college. We ended up hanging out quite a bit during those early months.&lt;/p&gt;
    &lt;p&gt;We‚Äôd all get excited for the weekends because Friday nights meant going out to party. Everyone except for Anna, that is.&lt;/p&gt;
    &lt;p&gt;Anna was quiet, shy, and a definitely a goody-two-shoes. She was from Alabama and spoke with a pronounced southern drawl I‚Äôd rarely heard in Maryland. She was reserved but friendly once you got to know her. Anna cared about school a lot. She was almost always studying whenever I saw her.&lt;/p&gt;
    &lt;p&gt;Every Friday night we‚Äôd make plans to go out together and party. But Anna would always refuse to come. She‚Äôd say something along the lines of ‚ÄúI have to study‚Äù or ‚ÄúI just don‚Äôt feel like it tonight.‚Äù&lt;/p&gt;
    &lt;p&gt;Eventually, we stopped inviting Anna out. Everyone except Alexei.&lt;/p&gt;
    &lt;p&gt;I liked Alexei the most in our friend group. He was valedictorian of his high school, played tennis at a competitive level, and was remarkably smart. If anyone deserved to have an ego, it was Alexei. Yet somehow he managed to be the kindest person I‚Äôd ever known. But my absolute favorite thing about Alexei was that he always invited Anna to come party with us.&lt;/p&gt;
    &lt;p&gt;One Friday night as we were all about to leave the dorms for a house party, Alexei stopped us. ‚ÄúHold on, let‚Äôs invite Anna.‚Äù We headed over to her dorm and invited her to come with us. She said ‚ÄúSorry, I have to study for my Arabic exam next week, but you guys have fun.‚Äù&lt;/p&gt;
    &lt;p&gt;Alexei continued to invite Anna every time we went out for the rest of the semester. And Anna said no every single time.&lt;/p&gt;
    &lt;p&gt;Curious about his persistence, I asked him ‚ÄúWhy do you keep inviting Anna out when she‚Äôll just say no?‚Äù&lt;/p&gt;
    &lt;p&gt;I‚Äôll never forget what he told me: ‚ÄúI know she‚Äôs always going to say no, but that‚Äôs not the point. I invite her out so she‚Äôll always feel included in the group.‚Äù&lt;/p&gt;
    &lt;p&gt;After that first semester, the friend group disbanded and we all went our separate ways. Many years later I ran into Anna and we ended up catching up. She told me how difficult her first semester of college had been. She was very close with her mom and sister and missed them them terribly.&lt;/p&gt;
    &lt;p&gt;But then she said something that stayed with me: She was grateful. She was grateful to be part of that brief friend group because she felt like she had a family away from home. And that even though she never partied with us, she always felt included because we would stop by her room and invite her anyway.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://sharif.io/anna-alexei"/><published>2025-09-23T15:33:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45350690</id><title>Find SF parking cops</title><updated>2025-09-24T11:08:33.414027+00:00</updated><content/><link href="https://walzr.com/sf-parking/"/><published>2025-09-23T18:06:07+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45351410</id><title>How to draw construction equipment for kids</title><updated>2025-09-24T11:08:33.275366+00:00</updated><content/><link href="https://alyssarosenberg.substack.com/p/how-to-draw-construction-equipment"/><published>2025-09-23T19:09:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45351437</id><title>Apple A19 SoC die shot</title><updated>2025-09-24T11:08:32.515794+00:00</updated><content>&lt;doc fingerprint="229e687d1b3cd1b2"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Apple A19 SoC die shot&lt;/head&gt;
    &lt;p&gt;These images represent the first high-resolution microscopy of Apple‚Äôs A19 chip, extracted from the iPhone 17, revealing its full complexity under the hood. Built on TSMC‚Äôs third-generation 3 nm process node‚Äîdubbed N3P‚Äîthe A19 marks a refinement over the earlier N3E technology used in the A18 series, offering higher transistor density, better energy efficiency, and modest performance gains. On the CPU side, the chip retains a hybrid core design (performance plus efficiency cores), while upgrades to the GPU include more cores on the Pro models. Key supporting blocks‚Äîimage signal processor, display engine, Neural Engine‚Äîalso see enhancements, enabling better on-device AI, imaging, and power management. Taken together, the die shots not only visualize the physical layout‚Äîlogic blocks, cache banks, interconnects‚Äîbut also reflect Apple‚Äôs continuous push in process technology and architectural refinement.&lt;/p&gt;
    &lt;head rend="h2"&gt;High Resolution Floorplan images available here&lt;/head&gt;
    &lt;p&gt;+31537113618&lt;/p&gt;
    &lt;p&gt;info@chipwise.tech&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://chipwise.tech/our-portfolio/apple-a19-dieshot/"/><published>2025-09-23T19:12:08+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45351624</id><title>Is Fortran better than Python for teaching basics of numerical linear algebra?</title><updated>2025-09-24T11:08:32.343265+00:00</updated><content>&lt;doc fingerprint="4718593732e41c11"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Is Fortran better than Python for teaching the basics of numerical linear algebra?&lt;/head&gt;
    &lt;p&gt;Disclaimer ‚Äì This is not a post about which language is the most elegant or which implementation is the fastest (we all know it‚Äôs &lt;code&gt;Fortran&lt;/code&gt;). It‚Äôs about teaching the basics of scientific computing to engineering students with a limited programming experience. Yes, the &lt;code&gt;Numpy&lt;/code&gt;/&lt;code&gt;Scipy&lt;/code&gt;/&lt;code&gt;matplotlib&lt;/code&gt; stack is awesome. Yes, you can use &lt;code&gt;numba&lt;/code&gt; or &lt;code&gt;jax&lt;/code&gt; to speed up your code, or &lt;code&gt;Cython&lt;/code&gt;, or even &lt;code&gt;Mojo&lt;/code&gt; the latest kid in the block. Or you know what? Use &lt;code&gt;Julia&lt;/code&gt; or &lt;code&gt;Rust&lt;/code&gt; instead. But that‚Äôs not the basics and it‚Äôs beyond the point.&lt;/p&gt;
    &lt;p&gt;I‚Äôve been teaching an Intro to Scientific Computing class for nearly 10+ years. This class is intended for second year engineering students and, as such, places a large emphasis on numerical linear algebra. Like the rest of Academia, I‚Äôm using a combination of &lt;code&gt;Python&lt;/code&gt; and &lt;code&gt;numpy&lt;/code&gt; arrays for this. Yet, after all these years, I start to believe it ain‚Äôt necessarily the right choice for a first encounter with numerical linear algebra. Obvisouly everything is not black and white and I‚Äôll try to be nuanced. But, in my opinion, a strongly typed language such as &lt;code&gt;Fortran&lt;/code&gt; might lead to an overall better learning experience. And that‚Äôs what it‚Äôs all about when you start Uni: learning the principles of scientific programming, not the quirks of a particular language (unless you‚Äôre a CS student, which is a different crowd).&lt;/p&gt;
    &lt;p&gt;Don‚Äôt get me wrong though. Being proficient with &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt; is an absolute necessity for STEM students today, and that‚Äôs a good thing. Even from an educational perspective, the scientific &lt;code&gt;Python&lt;/code&gt; ecosystem enables students to do really cool projects, putting the fun back in learning. It would be completely non-sensical to deny this. But using &lt;code&gt;x = np.linalg.solve(A, b)&lt;/code&gt; ain‚Äôt the same thing as having a basic understanding of how these algorithms work. And to be clear: the goal of these classes is not to transform a student into a numerical linear algebra expert who could write the next generation LAPACK. It is to teach them just enough of numerical computing so that, when they‚Äôll transition to an engineering position, they‚Äôll be able to make an informed decision regarding which solver or algorithm to use when writing a simulation or data analysis tool to tackle whatever business problem they‚Äôre working on.&lt;/p&gt;
    &lt;p&gt;If you liked and aced your numerical methods class, then what I‚Äôll discuss might not necessary be relatable. You‚Äôre one of a kind. More often than not, students struggle with such courses. This could be due to genuine comprehension difficulties, or lazyness and lack of motivation simply because they don‚Äôt see the point. While both issues are equally important to address, I‚Äôll focus on the first one: students who are willing to put the effort into learning the subject but have difficulties transforming the mathematical algorithm into an actionnable piece of code. Note however that initially motivated but struggling students might easily drift to the second type, hence my focus there first.&lt;/p&gt;
    &lt;p&gt;In the rest of this post, I‚Äôll go through two examples. For each, I‚Äôll show a typical &lt;code&gt;Python&lt;/code&gt; code such a student might write and discuss all of the classical problems they‚Äôve encountered to get there. A large part of these are syntax issues or result from the permissiveness of an interpreted language like &lt;code&gt;Python&lt;/code&gt; which is a double edged sword. Then I‚Äôll show an equivalent &lt;code&gt;Fortran&lt;/code&gt; implementation and explain why I believe it can solve part of these problems. But first, I need to address the two elephants in the room:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;My research is on applied mathematics and numerical linear algebra for the physical sciences. I am not doing research on Education. Everything that follows comes from my reflection about my interactions with students I taught to or mentored. If you have scientific evidence (pertaining to scientific computing in particular) proving me wrong, please tell me.&lt;/item&gt;
      &lt;item&gt;When I write &lt;code&gt;Fortran&lt;/code&gt;, what I really mean is modern&lt;code&gt;Fortran&lt;/code&gt;, not&lt;code&gt;FORTRAN&lt;/code&gt;. Anything pre-dating the&lt;code&gt;Fortran 90&lt;/code&gt;standard (or even better, the&lt;code&gt;Fortran 2018&lt;/code&gt;one) is not even an option (yes, I‚Äôm looking at you&lt;code&gt;FORTRAN 77&lt;/code&gt;and your incomprehensible&lt;code&gt;goto&lt;/code&gt;, error-prone&lt;code&gt;common&lt;/code&gt;, artithmetic&lt;code&gt;if&lt;/code&gt;and what not).&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;With that being said, let‚Äôs get started with a concrete, yet classical, example to illustrate my point.&lt;/p&gt;
    &lt;head rend="h2"&gt;The &lt;code&gt;Hello World&lt;/code&gt; of iterative solvers&lt;/head&gt;
    &lt;p&gt;You‚Äôve started University a year ago and are taking your first class on scientific computing. Maybe you already went through the hassle of Gaussian elimination and the LU factorization. During the last class, Professor X discussed about iterative solvers for linear systems. It is now the hands-on session and today‚Äôs goal is to implement the Jacobi method. Why Jacobi? Because it is simple enough to implement in an hour or so.&lt;/p&gt;
    &lt;p&gt;The exact problem you‚Äôre given is the following:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consider the Poisson equation with homogeneous Dirichlet boundary conditions on the unit-square. Assume the Laplace operator has been discretized using a second-order accurate central finite-difference scheme. The discretized equation reads \[\dfrac{u_{i+1, j} - 2u_{i, j} + u_{i-1, j}}{\Delta x^2} + \dfrac{u_{i, j+1} - 2u_{i, j} + u_{i, j-1}}{\Delta y^2} = b_{i, j}.\] For the sake of simplicity, take \(\Delta x = \Delta y\). Write a function implementing the Jacobi method to solve the resulting linear system to a user-prescribed tolerance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;We can all agree this is a simple enough yet somewhat realistic example. More importantly, it is sufficient to illustrate my point. Here is what the average student might write in &lt;code&gt;Python&lt;/code&gt;.&lt;/p&gt;
    &lt;code&gt;import numpy as np

def jacobi(b , dx, tol, maxiter):
    # Initialize variables.
    nx, ny = b.shape
    residual = 1.0
    u = np.zeros((nx, ny))
    tmp = np.zeros((nx, ny))

    # Jacobi solver.
    for iteration in range(maxiter):
        # Jacobi iteration.
        for i in range(1, nx-1):
            for j in range(1, ny-1):
                tmp[i, j] = 0.25*(b[i, j]*dx**2 - u[i+1, j] - u[i-1, j] 
                                                - u[i, j+1] - u[i, j-1])

        # Compute residual
        residual = np.linalg.norm(u-tmp)
        # Update solution.
        u = tmp
        # If converged, exit the loop.
        if residual &amp;lt;= tol:
            break

    return u&lt;/code&gt;
    &lt;p&gt;Yes, you shouldn‚Äôt do &lt;code&gt;for&lt;/code&gt; loops in &lt;code&gt;Python&lt;/code&gt;. But remember, you are not a seasoned programmer. You‚Äôre taking your first class on scientific computing and that‚Äôs how the Jacobi method is typically presented. Be forgiving.&lt;/p&gt;
    &lt;head rend="h3"&gt;Where do students struggle?&lt;/head&gt;
    &lt;p&gt;Admittidely, the code is quite readable and look very similar to the pseudocode you‚Äôd use to describe the Jacobi method. But if you‚Äôre reading this blog post, there probably are a handful of things you‚Äôve internalized and don‚Äôt even think about anymore (true for both &lt;code&gt;Python&lt;/code&gt; and &lt;code&gt;Fortran&lt;/code&gt;). And that‚Äôs precisely what the students (at least mine) struggle with, starting with the very first line.&lt;/p&gt;
    &lt;p&gt;What the hell is &lt;code&gt;numpy&lt;/code&gt; and why do I need it? Also, why import it as &lt;code&gt;np&lt;/code&gt;? ‚Äì These questions come back every year. Yet, I don‚Äôt have satisfying answers. I always hesitate between&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Trust me kid, you don‚Äôt want to use nested lists in&lt;/p&gt;&lt;code&gt;Python&lt;/code&gt;to do any serious numerical computing.&lt;/quote&gt;
    &lt;p&gt;which naturally begs the question of why, or&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;When I said we‚Äôll use&lt;/p&gt;&lt;code&gt;Python&lt;/code&gt;for this scientific computing class, what I really meant is we‚Äôll use&lt;code&gt;numpy&lt;/code&gt;which is a package written for numerical computing because&lt;code&gt;Python&lt;/code&gt;doesn‚Äôt naturally have good capabilities for number crunching. As for the import as&lt;code&gt;np&lt;/code&gt;, that‚Äôs just a convention.&lt;/quote&gt;
    &lt;p&gt;And this naturally leads to the question of ‚Äúwhy Python in the first place then?‚Äù for which the only valid answer I have is&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Well, because&lt;/p&gt;&lt;code&gt;Python&lt;/code&gt;is supposed to be easy to learn and everybody uses it.&lt;/quote&gt;
    &lt;p&gt;Clearly, &lt;code&gt;import numpy as np&lt;/code&gt; is an innocent-looking line of code. It has nothing to do with the subject being taught though, and everything with the choice of the language, only diverting the students from the learning process.&lt;/p&gt;
    &lt;p&gt;I coded everything correctly, 100% sure, but I get this weird error message about indentation ‚Äì Oh boy! What a classic! The error message varies between&lt;/p&gt;
    &lt;code&gt;IndentationError: expected an indented block&lt;/code&gt;
    &lt;p&gt;and&lt;/p&gt;
    &lt;code&gt;TabError: inconsistent use of tabs and spaces in indentation&lt;/code&gt;
    &lt;p&gt;&lt;code&gt;&amp;lt;TAB&amp;gt;&lt;/code&gt; versus &lt;code&gt;SPACE&lt;/code&gt; is a surprisingly hot topic in programming which I don‚Äôt want to engage in. A seasoned programmer might say ‚Äúsimply configure your IDE properly‚Äù which is fair. But we‚Äôre talking about your average student (who‚Äôs not a CS one remember) and they might use IDLE or even just notepad. As for the &lt;code&gt;IndentationError&lt;/code&gt;, it is a relatively easy error to catch. Yet, the fact that &lt;code&gt;for&lt;/code&gt;, &lt;code&gt;if&lt;/code&gt; or &lt;code&gt;while&lt;/code&gt; constructs are not clearly delineated in &lt;code&gt;Python&lt;/code&gt; other than visually is surprisingly hard for students. I find that it puts an additional cognitive burden on top of a subject which is already demanding enough.&lt;/p&gt;
    &lt;p&gt;It could also be more subtle. The code might run but the results are garbage because the student wrote something like&lt;/p&gt;
    &lt;code&gt;    for iteration in range(maxiter):
    # Jacobi iteration.
    for i in range(1, nx-1):
    for j in range(1, ny-1):
    tmp[i, j] = 0.25*(b[i, j]*dx**2 - u[i+1, j] - u[i-1, j] 
                                                - u[i, j+1] - u[i, j-1])&lt;/code&gt;
    &lt;p&gt;You might argue that this perfectly understandable, though if you want to be picky, there is no dealineation of where the different loops end. Which the whole point of indentation in &lt;code&gt;Python&lt;/code&gt;. But students do not necessarily get that.&lt;/p&gt;
    &lt;p&gt;Why &lt;code&gt;range(1, nx-1)&lt;/code&gt; and not &lt;code&gt;range(2, nx-1)&lt;/code&gt;? The first column/row is my boundary. ‚Äì Another classic related to 0-based vs 1-based indexing. And another very hot debate I don‚Äôt want to engage in. The fact however is that linear algebra (and a lot of scientific computing for that matter) use 1-based indexing. Think about vectors or matrices. Almost every single maths books write them as&lt;/p&gt;
    &lt;p&gt;\[ \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} \end{bmatrix}. \]&lt;/p&gt;
    &lt;p&gt;The upper left element has the (1, 1) index, not (0, 0). Why use a language with 0-based indexing for linear algebra other than putting an additional cognitive burden on the students learning the subject? This is a recipe for the nefarious off-by-one error. And these errors are sneaky. The code might run but produce incorrect results and it‚Äôs a nightmare for the students (or the poor TA helping them) to figure out why.&lt;/p&gt;
    &lt;p&gt;Why &lt;code&gt;np.linalg.norm&lt;/code&gt; and not just &lt;code&gt;norm&lt;/code&gt; or &lt;code&gt;np.norm&lt;/code&gt;? ‚Äì This is one is related to my first point. When you‚Äôre used to it, you no longer question it. But you don‚Äôt know students then and, once more, I don‚Äôt have a really clear answer other than&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Well,&lt;/p&gt;&lt;code&gt;linalg&lt;/code&gt;stand for linear algebra, and&lt;code&gt;np.linalg&lt;/code&gt;is a collection of linear algebra related function. It is a submodule of&lt;code&gt;numpy&lt;/code&gt;, the package I told you about before.&lt;/quote&gt;
    &lt;p&gt;Grouping like-minded functionalities into a dedicated submodule is definitely good practice, no question there. Discussing the architecture of &lt;code&gt;numpy&lt;/code&gt; makes a lot of sense when students have to do a big project involving numerical computing but not strictly speaking about numerical computing. On the other hand, when it is their first numerical computing class (and possibly first with &lt;code&gt;Python&lt;/code&gt;) I find it distracting. Again, it‚Äôs not a big thing really but still. And then you have to explain why &lt;code&gt;np.det&lt;/code&gt; and &lt;code&gt;np.trace&lt;/code&gt; are not part of &lt;code&gt;np.linalg&lt;/code&gt;‚Ä¶&lt;/p&gt;
    &lt;p&gt;Other common problems ‚Äì There are other very common problems like using the wrong function or inconsistent use of lower- or upper-case for variables. Once you know &lt;code&gt;Python&lt;/code&gt; is case-sensitive, this is mainly a concentration problem. No big deal there. But there is one last thing that tends to cause problems to distracted students and that has to do with the dynamic nature of &lt;code&gt;Python&lt;/code&gt;. Nowhere in the code snippet is it clearly specified that &lt;code&gt;b&lt;/code&gt; needs to be a two-dimensional &lt;code&gt;np.array&lt;/code&gt; of real numbers nor that it shouldn‚Äôt be modified by the function. It is only implicit. And that can be a big problem for students when working with marginally more complicated algorithms. Sure enough, type annotation is a thing now in &lt;code&gt;Python&lt;/code&gt;, but it still is pretty new and comparatively few people actually use them.&lt;/p&gt;
    &lt;head rend="h3"&gt;What about &lt;code&gt;Fortran&lt;/code&gt;?&lt;/head&gt;
    &lt;p&gt;Alright, I‚Äôve spent the last five minutes talking shit about &lt;code&gt;Python&lt;/code&gt; but how does &lt;code&gt;Fortran&lt;/code&gt; compare with it? Here is a typical implementation of the same function. I‚Äôve actually digged it from my own set of archived homeworks I did 15+ years ago and hardly modified it.&lt;/p&gt;
    &lt;code&gt;function jacobi(b, dx, tol, maxiter) result(u)
    implicit none
    real, dimension(:, :), intent(in) :: b
    real, intent(in) :: dx, tol
    integer, intent(in) :: maxiter
    real, dimension(:, :), allocatable :: u
    ! Internal variables.
    real, dimension(:, :), allocatable :: tmp
    integer :: nx, ny, i, j, iteration

    ! Initialize variables.
    nx = size(b, 1) ; ny = size(b, 2)
    allocate(u(nx, ny), source = 0.0)
    residual = 1.0

    ! Jacobi solver.
    do iteration = 1, maxiter
        ! Jacobi iteration.
        do j = 2, ny-1
            do i = 2, nx-1
                tmp(i, j) = 0.25*(b(i, j)*dx**2 - u(i+1, j) - u(i-1, j) &amp;amp;
                                                - u(i, j+1) - u(i, j-1))
            enddo
        enddo

        ! Compute residual.
        residual = norm2(u - tmp)
        ! Update solution.
        u = tmp
        ! If convered, exit the loop.
        if (residual &amp;lt;= tol) exit
    enddo

end function&lt;/code&gt;
    &lt;p&gt;No surprise there. The task is sufficiently simple that both implementations are equally readable. If anything, the &lt;code&gt;Fortran&lt;/code&gt; one is a bit more verbose. But in view of what I‚Äôve just said about the &lt;code&gt;Python&lt;/code&gt; code, I think it actually a good thing. Let me explain.&lt;/p&gt;
    &lt;p&gt;Definition of the variables ‚Äì &lt;code&gt;Fortran&lt;/code&gt; is a strongly typed language. Lines 2 to 8 are nothing but the definitions of the different variables used in the routine. While you might argue it‚Äôs a pain in the a** to write these, I think it can actually be very beneficial for students. Before even implementing the method, they have to clearly think about which variables are input, which are ouput, what are their types and dimensions. And to do so, they have to have at least a minimal understanding of the algorithm itself. Once it‚Äôs done, there are no more surprises (hopefully), and the contract between the code and the user is crystal clear. And more importantly, the effort put in clearly identifying the input and output of numerical algorithm usually pays off and leads to less error-prone process.&lt;/p&gt;
    &lt;p&gt;Begining and end of the constructs ‚Äì &lt;code&gt;Fortran&lt;/code&gt; uses the &lt;code&gt;do&lt;/code&gt;/&lt;code&gt;end do&lt;/code&gt; (or &lt;code&gt;enddo&lt;/code&gt;) construct, clearly specifying where the loop starts where it ends. The indentation used in the code snippet really is just a matter of style. In constrast to &lt;code&gt;Python&lt;/code&gt;, writing&lt;/p&gt;
    &lt;code&gt;    do j = 2, ny-1
    do i = 2, nx-1
    tmp(i, j) = 0.25*(b(i, j)*dx**2 - u(i+1, j) - u(i-1, j) &amp;amp;
                                    - u(i, j+1) - u(i, j-1))
    enddo
    enddo&lt;/code&gt;
    &lt;p&gt;does not make the code any less readable and wouldn‚Äôt change a dime in terms of computations. It‚Äôs a minor thing, fair enough. But it instantly get rid of the &lt;code&gt;IndentationError&lt;/code&gt; or &lt;code&gt;TabError&lt;/code&gt; which are puzzling students. I may be wrong, but I believe it actually reduces the cognitive load associated with the programming language and let the students focus on the actual numerical linear algebra task.&lt;/p&gt;
    &lt;p&gt;No off-by-one error ‚Äì By default, &lt;code&gt;Fortran&lt;/code&gt; uses a 1-based indexing. No off-by-one errors, period.&lt;/p&gt;
    &lt;p&gt;Intrinsic functions for basic scientific computations ‚Äì While you have to use &lt;code&gt;np.linalg.norm&lt;/code&gt; in &lt;code&gt;Python&lt;/code&gt; to compute the norm of a vector, &lt;code&gt;Fortran&lt;/code&gt; natively has the &lt;code&gt;norm2&lt;/code&gt; function for that. No external library required. If you want to be picky, you may say that &lt;code&gt;norm2&lt;/code&gt; is a weird name and that &lt;code&gt;norm&lt;/code&gt; might be just fine.&lt;/p&gt;
    &lt;p&gt;Some quirks of &lt;code&gt;Fortran&lt;/code&gt; ‚Äì All is not perfect though, starting with Line 2 and the &lt;code&gt;implicit none&lt;/code&gt; statement. This is a historical remnant which is considered good practice by modern &lt;code&gt;Fortran&lt;/code&gt; standards but not actually needed. Students being students, they will more likely than not ask questions about it although it has nothing to do with the subject of the class itself. Admittidely, it can be a bit cumbersome to explicitely define all the integers you use even if it‚Äôs just for a one-time loop. Likewise, there is the question of &lt;code&gt;real&lt;/code&gt; vs &lt;code&gt;double precision&lt;/code&gt; vs &lt;code&gt;real(wp)&lt;/code&gt; (where &lt;code&gt;wp&lt;/code&gt; is yet another variable you‚Äôve defined somewhere). I don‚Äôt think it matters too much though when learning the basics of numerical linear algebra algorithms, although it certainly does when you start discussing about precision and performances.&lt;/p&gt;
    &lt;head rend="h2"&gt;Linear least-squares, your first step into Machine Learning&lt;/head&gt;
    &lt;p&gt;Alright, let‚Äôs look at another example. Same class, later in the semester. Professor X now discusses over-determined linear systems and how it relates to least-squares, regression and basic machine learning applications. During the hands-on session, you‚Äôre given the following problem&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Consider the following unconstrained quadratic program \[\mathrm{minimize} \quad \| Ax - b \|_2^2.\] Write a least-squares solver based on the QR factorization of the matrix \(A\). You can safely assume that \(A\) is a tall matrix (i.e. \(m &amp;gt; n\)).&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Here is what the typical &lt;code&gt;Python&lt;/code&gt; code written by the students might look like.&lt;/p&gt;
    &lt;code&gt;import numpy as np

def qr(A):
    # Initialize variables.
    m, n = A.shape
    Q = np.zeros((m, n))
    R = np.zeros((n, n))

    # QR factorization based on the Gram-Schmidt orthogonalization process.
    for i in range(n):
        q = A[:, i]
        # Orthogonalization w.r.t. to the previous basis vectors.
        for j in range(i):
            R[j, i] = np.vdot(q, Q[:, j])
            q = q - R[j, i]*Q[:, j]

        # Normalize and store the new vector.
        R[i, i] = np.linalg.norm(q)
        Q[:, i] = q / R[i, i]

    return Q, R

def upper_triangular_solve(R, b):
    # Initialize variables.
    n = R.shape[0]
    x = np.zeros((n))

    # Backsubstitution.
    for i in range(n-1, -1, -1):
        x[i] = b[i]
        for j in range(n-1, i, -1):
            x[i] = x[i] - R[i, j]*x[j]
        x[i] = x[i] / R[i, i]

    return x

def lstsq(A, b):
    # QR factorization.
    Q, R = qr(A)
    # Solve R @ x = Q.T @ b.
    x = upper_triangular_solve(R, Q.T @ b)
    return x&lt;/code&gt;
    &lt;p&gt;This one was adapted from an exercise I gave last year. In reality, students lumped everything into one big function unless told otherwise, but nevermind. For comparison, here is the equivalent &lt;code&gt;Fortran&lt;/code&gt; code.&lt;/p&gt;
    &lt;code&gt;subroutine qr(A, Q, R)
    implicit none
    real, dimension(:, :), intent(in) :: A
    real, dimension(:, :), allocatable, intent(out) :: Q, R
    ! Internal variables.
    integer :: i, j, m, n
    real, dimension(:), allocatable :: q_hat

    ! Initialize variables.
    m = size(A, 1); n = size(A, 2)
    allocate(Q(m, n), source=0.0)
    allocate(R(n, n), source=0.0)
    
    ! QR factorization based on the Gram-Schmidt orthogonalization process.
    do i = 1, n
        q_hat = A(:, i)
        ! Orthogonalize w.r.t. the previous basis vectors.
        do j = 1, i-1
            R(j, i) = dot_product(q_hat, Q(:, j))
            q_hat = q_hat - R(j, i)*Q(:, j)
        end do

        ! Normalize and store the new vector.
        R(i, i) = norm2(q_hat)
        Q(:, i) = q_hat / R(i, i)
    end do
end subroutine

function upper_triangular_solve(R, b) result(x)
    implicit none
    real, dimension(:, :), intent(in) :: R
    real, dimension(:), intent(in) :: b
    real, dimension(:), allocatable :: x
    ! Internal variables.
    integer :: n, i, j

    ! Initialize variables.
    n = size(R, 1)
    allocate(x(n), source=0.0)

    ! Backsubstitution.
    do i = n, 1, -1
        x(i) = b(i)
        do j = n-1, i, -1
            x(i) = x(i) - R(i, j)*x(j)
        enddo
        x(i) = x(i) / R(i, i)
    end do
end function

function lstsq(A, b) result(x)
    implicit none
    real, dimension(:, :), intent(in) :: A
    real, dimension(:), intent(in) :: b
    real, dimension(:), allocatable :: x
    ! Internal variables.
    real, dimension(:, :), allocatable :: Q, R

    ! QR factorization.
    call qr(A, Q, R)
    ! Solve R @ x = Q.T @ b.
    x = upper_triangular_solve(R, matmul(transpose(Q), b))
end function&lt;/code&gt;
    &lt;p&gt;Just like the Jacobi example, both implementations are equally readable. At this point in the semester, the students got somewhat more comfortable with &lt;code&gt;Python&lt;/code&gt;. The classical indentation problems were not so much of a problem anymore. The off-by-one errors due to 0-based indexing for the Gram-Schmidt orthogonalization in &lt;code&gt;qr&lt;/code&gt; or in the backsubstitution algorithm on the other hand‚Ä¶ That was painful. In a 90-minutes class, it took almost a whole hour simply for them to debug these errors.&lt;/p&gt;
    &lt;p&gt;But there was another thing that confused students. A lot. And that has to do with computing dot products in &lt;code&gt;numpy&lt;/code&gt;. There‚Äôs so many different ways: &lt;code&gt;np.vdot(x, y)&lt;/code&gt;, &lt;code&gt;np.dot(x.T, y)&lt;/code&gt;, &lt;code&gt;np.dot(np.transpose(x), y)&lt;/code&gt;, or &lt;code&gt;x.transpose().dot(y)&lt;/code&gt; to list just the ones I have seen in their codes. Again, this has nothing to do with linear algebra, but everything with the language. Not only do they need to learn the math, but they simultaneously need to learn the not-quite-necessarily-math-standard syntax used in the language (yes, I‚Äôm looking at you &lt;code&gt;@&lt;/code&gt;). It‚Äôs just a question of habits, sure enough, but again it can be impeding the learning process.&lt;/p&gt;
    &lt;p&gt;On the other hand, the &lt;code&gt;Fortran&lt;/code&gt; implementation is even closer to the standard mathematical description of the algorithm: 1-based indexing, intrinsic &lt;code&gt;dot_product&lt;/code&gt; function, etc. But beside the &lt;code&gt;implicit none&lt;/code&gt;, there is the need to use a &lt;code&gt;subroutine&lt;/code&gt; rather than a &lt;code&gt;function&lt;/code&gt; construct for the QR decomposition because it has two output variables. Not a big deal again, but to be fair, it does add another minor layer of abstraction due to the language semantics rather than that of the subject being studied.&lt;/p&gt;
    &lt;head rend="h2"&gt;&lt;code&gt;Fortran&lt;/code&gt; may have a slight edge, but I swept some things under the rug‚Ä¶&lt;/head&gt;
    &lt;p&gt;In the end, when it comes to teaching the basics of numerical linear algebra, &lt;code&gt;Python&lt;/code&gt; and &lt;code&gt;Fortran&lt;/code&gt; are not that different. And in that regard, neither is &lt;code&gt;Julia&lt;/code&gt; which I really like as well. The main advantages I see of using &lt;code&gt;Fortran&lt;/code&gt; for this task however are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;1-based indexing : in my experience, the 0-based indexing in &lt;code&gt;Python&lt;/code&gt;leads to so many off-by-one erros driving the students crazy. Because linear algebra textbooks naturally use 1-based indexing, having to translate everything in your head to 0-based indices is a huge cognitive burden on top of a subject already demanding enough. You might get used to it eventually, but it‚Äôs a painful process impeding the learning outcomes.&lt;/item&gt;
      &lt;item&gt;Strong typing : combined with &lt;code&gt;implicit none&lt;/code&gt;, having to declare the type, dimension and input or output nature of every variable you use might seem cumbersome at first. But it forces students to pause and ponder to identify which is which. Sure this is an effort, but it is worth it. Learning is not effortless and this effort forces you to have a somewhat better understanding of a numerical algorithm before even starting to implement it. Which I think is a good thing.&lt;/item&gt;
      &lt;item&gt;Clear delineation of the constructs : at least during the first few weeks, having to rely only on visual clues to identify where does a loop ends in &lt;code&gt;Python&lt;/code&gt;seems to be quite complicated for a non-negligible fraction of the students I have. In that respect, the&lt;code&gt;do&lt;/code&gt;/&lt;code&gt;enddo&lt;/code&gt;construct in&lt;code&gt;Fortran&lt;/code&gt;is much more explicit and probably easier to grasp.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Obvisouly, I‚Äôm not expecting educators worldwide to switch back to &lt;code&gt;Fortran&lt;/code&gt; overnight, nor is it necessarily desirable. The advantages I see are non-negligible from my perspective but certainly not enough by themselves. There are many other things that need to be taken into account. &lt;code&gt;Python&lt;/code&gt; is a very generalist language. You can do so much more than just numerical computing so it makes complete sense to have it in the classroom. The ecosystem is incredibly vast and the interactive nature definitely has its pros. Notebooks such as &lt;code&gt;Jupyter&lt;/code&gt; can be incredible teaching tools (although they come with their own problems in term good coding practices). So are the &lt;code&gt;Pluto&lt;/code&gt; notebooks in &lt;code&gt;Julia&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;Fortran&lt;/code&gt; is good at one thing: enabling computational scientists and engineers to write high-performing mathematical models without all the intricacies of equally peformant but more CS-oriented languages such as &lt;code&gt;C&lt;/code&gt; or &lt;code&gt;C++&lt;/code&gt;. Sure enough, the modern &lt;code&gt;Fortran&lt;/code&gt; ecosystem is orders of magnitude smaller than &lt;code&gt;Python&lt;/code&gt;, and targetted toward numerical computing almost exclusively. And the &lt;code&gt;Julia&lt;/code&gt; one is fairly impressive. But the community is working on it (see the fortran-lang website or the Fortran discourse if you don‚Äôt trust me). The bad rep of &lt;code&gt;Fortran&lt;/code&gt; is unjustified, particularly for teaching purposes. Many of its detractors have hardly been exposed to anything else than &lt;code&gt;FORTRAN 77&lt;/code&gt;. And it‚Äôs true that, by current standards, most of &lt;code&gt;FORTRAN 77&lt;/code&gt; codes are terrible sphagetti codes making extensive use of implicit typing and incomprehensible &lt;code&gt;goto&lt;/code&gt; statements. Even I, as a &lt;code&gt;Fortran&lt;/code&gt; programmer, acknowledge it. But that‚Äôs no longer what &lt;code&gt;Fortran&lt;/code&gt; is since the 1990‚Äôs, and certainly not today!&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://loiseaujc.github.io/posts/blog-title/fortran_vs_python.html"/><published>2025-09-23T19:29:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45352460</id><title>Podman Desktop celebrates 3M downloads</title><updated>2025-09-24T11:08:32.103030+00:00</updated><content>&lt;doc fingerprint="7cfef03e2d35f7a8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;3,000,000 downloads. Thank you&lt;/head&gt;
    &lt;head rend="h2"&gt;Wooohooo!!&lt;/head&gt;
    &lt;p&gt;We are extremely excited to share that Podman Desktop just crossed 3,000,000 downloads! This is a huge step for the project and we are incredibly thankful for how each of you has helped! This milestone belongs to you. You file issues, suggest features, build extensions, teach teammates, and nudge us to make the day-to-day better. Thank you for helping turn an idea into a tool people rely on.&lt;/p&gt;
    &lt;p&gt;To celebrate this milestone, and thank you, we built a small surprise: https://3m.podman-desktop.io&lt;/p&gt;
    &lt;p&gt;We are grateful for all the feedback we have been receiving, here is just a short collection:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;‚ÄúLovely to have all containers in one tool. Thanks!‚Äù - anonymous user feedback&lt;/item&gt;
      &lt;item&gt;"Podman Desktop is a total win." - balancedchaos Reddit (r/podman)&lt;/item&gt;
      &lt;item&gt;‚ÄúGreat project! Small improvements each time make it strong long-term.‚Äù - anonymous user feedback&lt;/item&gt;
      &lt;item&gt;"The experience has been nice, and the ability to run containers under user without going root is definitely nice." - ajyotirmay Hacker News&lt;/item&gt;
      &lt;item&gt;‚ÄúYou are doing a great job! Thanks to you I always recommend podman whenever 'docker' comes out in conversations‚Äù - anonymous user feedback&lt;/item&gt;
      &lt;item&gt;‚ÄúOMG this tool is amazing. Tutorial was great. Much easier than minikube.‚Äù - anonymous user feedback&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We read every comment. Yes, even the spicy ones. That feedback shapes our roadmap and helps us focus on the work that makes the biggest difference.&lt;/p&gt;
    &lt;p&gt;Here are other noteworthy milestones we‚Äôve reached in our quest to help developers work with containers and Kubernetes.&lt;/p&gt;
    &lt;head rend="h2"&gt;Podman Desktop is now an official CNCF Sandbox Project&lt;/head&gt;
    &lt;p&gt;Last year, we proudly contributed Podman Desktop to the Cloud Native Computing Foundation (CNCF), and we were accepted into the CNCF Sandbox on January 21, 2025. üéâ&lt;/p&gt;
    &lt;p&gt;This milestone highlights our commitment to building open, community-driven tools that empower developers to seamlessly work with containers and Kubernetes. Joining the CNCF Sandbox is just the beginning. Reaching this 3 million downloads milestone shows the need to build a vibrant cloud‚Äënative ecosystem and collaborate with the community to take Podman Desktop even further.&lt;/p&gt;
    &lt;head rend="h2"&gt;Highlights from the past year&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Smoother Kubernetes workflows: Easier context and namespace switching, a powerful dashboard for your cluster, and less jumping to the terminal when you want to apply YAML or peek at events and logs.&lt;/item&gt;
      &lt;item&gt;Better Docker compatibility: Clearer setup and diagnostics, improved socket handling, and fewer surprises when you bridge Docker and Podman workflows.&lt;/item&gt;
      &lt;item&gt;Everyday quality of life: Bulk actions for containers, better notifications, clearer status in the UI, and lots of fit and finish fixes that make everything feel calmer.&lt;/item&gt;
      &lt;item&gt;AI on your laptop, without drama: Podman AI Lab is easier to set up, with a curated model catalog, simple playgrounds, and an OpenAI-compatible API you can call from your apps.&lt;/item&gt;
      &lt;item&gt;Extensions, everywhere: More community-built extensions, plus tooling that makes it easier to develop and test your own. If you are extending Podman Desktop for your team, thank you. You are shaping where we take the platform.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Enterprise adoption of Podman Desktop&lt;/head&gt;
    &lt;p&gt;In recent months, we‚Äôve seen more and more enterprises adopting Podman Desktop and making it part of critical developer workflows. To highlight this, we wanted to share a recent note we received:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;In 2023, our company studied the possible solutions to run containers on our engineers‚Äô laptop in the most efficient way. We judged that our best bet was to migrate our thousands of engineers to Podman Desktop. That was a brave move but we believed Podman Desktop was the most promising solution. We did not know how quickly it would become the best solution of all and how right that decision would be!&lt;/p&gt;
      &lt;p&gt;We migrated most engineers in 2023 and did the last mile at the beginning of 2024. Podman Desktop evolved at an insane pace. It improved release after release. And it still does. It quickly became a rock solid solution with more and more useful features to discover every month!&lt;/p&gt;
      &lt;p&gt;On top of that, Podman Desktop is a Community solution which allows us to have a very healthy relationship with the contributors of the project.&lt;/p&gt;
      &lt;p&gt;I am happy to hear that Podman Desktop reached 3M downloads. This means more and more people realise how good this software is. Thank you Podman Desktop. Special thanks to all the project‚Äôs contributors!&lt;/p&gt;
      &lt;p&gt;Fabrice Pipart, Amadeus&lt;/p&gt;
    &lt;/quote&gt;
    &lt;head rend="h2"&gt;New here? Grab the latest build&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Download Podman Desktop for Windows, macOS, and Linux: https://podman-desktop.io/downloads&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;From all of us on the Podman Desktop team, thank you for trusting us with your workflow and for helping us get better with every release. If you haven't tried Podman Desktop in a while, grab the latest build and let us know what you think. If you are already a daily user, we would love to hear what is working and what is not, so we can make the next million downloads even more useful.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://podman-desktop.io/blog/3-million"/><published>2025-09-23T20:40:21+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45352533</id><title>Is life a form of computation?</title><updated>2025-09-24T11:08:31.778584+00:00</updated><content>&lt;doc fingerprint="b2025f96f139f3ba"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Is Life a Form of Computation?&lt;/head&gt;
    &lt;p&gt;In 1994, a strange, pixelated machine came to life on a computer screen. It read a string of instructions, copied them, and built a clone of itself ‚Äî just as the Hungarian-American Polymath John von Neumann had predicted half a century earlier. It was a striking demonstration of a profound idea: that life, at its core, might be computational.&lt;/p&gt;
    &lt;p&gt;Although this is seldom fully appreciated, von Neumann was one of the first to establish a deep link between life and computation. Reproduction, like computation, he showed, could be carried out by machines following coded instructions. In his model, based on Alan Turing‚Äôs Universal Machine, self-replicating systems read and execute instructions much like DNA does: ‚Äúif the next instruction is the codon CGA, then add an arginine to the protein under construction.‚Äù It‚Äôs not a metaphor to call DNA a ‚Äúprogram‚Äù ‚Äî that is literally the case.&lt;/p&gt;
    &lt;p&gt;Of course, there are meaningful differences between biological computing and the kind of digital computing done by a personal computer or your smartphone. DNA is subtle and multilayered, including phenomena like epigenetics and gene proximity effects. Cellular DNA is nowhere near the whole story, either. Our bodies contain (and continually swap) countless bacteria and viruses, each running their own code.&lt;/p&gt;
    &lt;p&gt;Biological computing is ‚Äúmassively parallel,‚Äù decentralized, and noisy. Your cells have somewhere in the neighborhood of 300 quintillion ribosomes, all working at the same time. Each of these exquisitely complex floating protein factories is, in effect, a tiny computer ‚Äî albeit a stochastic one, meaning not entirely predictable. The movements of hinged components, the capture and release of smaller molecules, and the manipulation of chemical bonds are all individually random, reversible, and inexact, driven this way and that by constant thermal buffeting. Only a statistical asymmetry favors one direction over another, with clever origami moves tending to ‚Äúlock in‚Äù certain steps such that a next step becomes likely to happen.&lt;/p&gt;
    &lt;p&gt;This differs greatly from the operation of ‚Äúlogic gates‚Äù in a computer, basic components that process binary inputs into outputs using fixed rules. They are irreversible and engineered to be 99.99 percent reliable and reproducible.&lt;/p&gt;
    &lt;p&gt;Biological computing is computing, nonetheless. And its use of randomness is a feature, not a bug. In fact, many classic algorithms in computer science also require randomness (albeit for different reasons), which may explain why Turing insisted that the Ferranti Mark I, an early computer he helped to design in 1951, include a random number instruction. Randomness is thus a small but important conceptual extension to the original Turing Machine, though any computer can simulate it by calculating deterministic but random-looking or ‚Äúpseudorandom‚Äù numbers.&lt;/p&gt;
    &lt;p&gt;Parallelism, too, is increasingly fundamental to computing today. Modern AI, for instance, depends on both massive parallelism and randomness ‚Äî as in the parallelized ‚Äústochastic gradient descent‚Äù (SGD) algorithm, used for training most of today‚Äôs neural nets, the ‚Äútemperature‚Äù setting used in chatbots to introduce a degree of randomness into their output, and the parallelism of Graphics Processing Units (GPUs), which power most AI in data centers.&lt;/p&gt;
    &lt;p&gt;Traditional digital computing, which relies on the centralized, sequential execution of instructions, was a product of technological constraints. The first computers needed to carry out long calculations using as few parts as possible. Originally, those parts were flaky, expensive vacuum tubes, which had a tendency to burn out and needed frequent replacement by hand. The natural design, then, was a minimal ‚ÄúCentral Processing Unit‚Äù (CPU) operating on sequences of bits ferried back and forth from an external memory. This has come to be known as the ‚Äúvon Neumann architecture.‚Äù&lt;/p&gt;
    &lt;p&gt;Turing and von Neumann were both aware that computing could be done by other means, though. Turing, near the end of his life, explored how biological patterns like leopard spots could arise from simple chemical rules, in a field he called morphogenesis. Turing‚Äôs model of morphogenesis was a biologically inspired form of massively parallel, distributed computation. So was his earlier concept of an ‚Äúunorganized machine,‚Äù a randomly connected neural net modeled after an infant‚Äôs brain.&lt;/p&gt;
    &lt;p&gt;These were visions of what computing without a central processor could look like ‚Äî and what it does look like, in living systems.&lt;/p&gt;
    &lt;p&gt;Von Neumann also began exploring massively parallel approaches to computation as far back as the 1940s. In discussions with Polish mathematician Stanis≈Çaw Ulam at Los Alamos, he conceived the idea of ‚Äúcellular automata,‚Äù pixel-like grids of simple computational units, all obeying the same rule, and all altering their states simultaneously by communicating only with their immediate neighbors. With characteristic bravura, von Neumann went so far as to design, on paper, the key components of a self-reproducing cellular automaton, including a horizontal ‚Äútape‚Äù of cells containing instructions and blocks of cellular ‚Äúcircuitry‚Äù for reading, copying, and executing them.&lt;/p&gt;
    &lt;p&gt;Designing a cellular automaton is far harder than ordinary programming, because every cell or ‚Äúpixel‚Äù is simultaneously altering its own state and its environment. Add randomness and subtle feedback effects, as in biology, and it becomes even harder to reason about, ‚Äúprogram,‚Äù or ‚Äúdebug.‚Äù&lt;/p&gt;
    &lt;p&gt;Nonetheless, Turing and von Neumann grasped something fundamental: Computation doesn‚Äôt require a central processor, logic gates, binary arithmetic, or sequential programs. There are infinite ways to compute, and, crucially, they are all equivalent. This insight is one of the greatest accomplishments of theoretical computer science.&lt;/p&gt;
    &lt;p&gt;This ‚Äúplatform independence‚Äù or ‚Äúmultiple realizability‚Äù means that any computer can emulate any other one. If the computers are of different designs, though, the emulation may be glacially slow. For that reason, von Neumann‚Äôs self-reproducing cellular automaton has never been physically built ‚Äî though that would be fun to see!&lt;/p&gt;
    &lt;p&gt;That demonstration in 1994 ‚Äî the first successful emulation of von Neumann‚Äôs self-reproducing automation ‚Äî couldn‚Äôt have happened much earlier. A serial computer requires serious processing power to loop through the automaton‚Äôs 6,329 cells over the 63 billion time steps required for the automaton to complete its reproductive cycle. Onscreen, it worked as advertised: a pixelated two-dimensional Rube Goldberg machine, squatting astride a 145,315-cell‚Äìlong instruction tape trailing off to the right, pumping information out of the tape and reaching out with a ‚Äúwriting arm‚Äù to slowly print a working clone of itself just above and to the right of the original.&lt;/p&gt;
    &lt;p&gt;It‚Äôs similarly inefficient for a serial computer to emulate a parallel neural network, heir to Turing‚Äôs ‚Äúunorganized machine.‚Äù Consequently, running big neural nets like those in Transformer-based chatbots has only recently become practical, thanks to ongoing progress in the miniaturization, speed, and parallelism of digital computers.&lt;/p&gt;
    &lt;p&gt;In 2020, my colleague Alex Mordvintsev combined modern neural nets, Turing‚Äôs morphogenesis, and von Neumann‚Äôs cellular automata into the ‚Äúneural cellular automaton‚Äù (NCA), replacing the simple per-pixel rule of a classic cellular automaton with a neural net. This net, capable of sensing and affecting a few values representing local morphogen concentrations, can be trained to ‚Äúgrow‚Äù any desired pattern or image, not just zebra stripes or leopard spots.&lt;/p&gt;
    &lt;p&gt;Real cells don‚Äôt literally have neural nets inside them, but they do run highly evolved, nonlinear, and purposive ‚Äúprograms‚Äù to decide on the actions they will take in the world, given external stimulus and an internal state. NCAs offer a general way to model the range of possible behaviors of cells whose actions don‚Äôt involve movement, but only changes of state (here, represented as color) and the absorption or release of chemicals.&lt;/p&gt;
    &lt;p&gt;The first NCA Alex showed me was of a lizard emoji, which could regenerate not only its tail, but also its limbs and head! It was a powerful demonstration of how complex multicellular life can ‚Äúthink locally‚Äù yet ‚Äúact globally,‚Äù even when each cell (or pixel) is running the same program ‚Äî just as each of your cells is running the same DNA. Simulations like these show how computation can produce lifelike behavior across scales. Building on von Neumann‚Äôs designs and extending into modern neural cellular automata, they offer a glimpse into the computational underpinnings of living systems.&lt;/p&gt;
    &lt;p&gt;Blaise Ag√ºera y Arcas is a VP/Fellow at Google, where he is the CTO of Technology &amp;amp; Society, and the founder of Paradigms of Intelligence, an organization dedicated to fundamental AI research. He is the author of ‚ÄúWhat Is Intelligence?,‚Äù from which this article is adapted.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thereader.mitpress.mit.edu/is-life-a-form-of-computation/"/><published>2025-09-23T20:46:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45352672</id><title>Qwen3-VL</title><updated>2025-09-24T11:08:30.615076+00:00</updated><link href="https://qwen.ai/blog?id=99f0335c4ad9ff6153e517418d48535ab6d8afef&amp;from=research.latest-advancements-list"/><published>2025-09-23T20:59:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45352944</id><title>From Rust to reality: The hidden journey of fetch_max</title><updated>2025-09-24T11:08:30.386775+00:00</updated><content>&lt;doc fingerprint="1c018251a0ff3b2c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;From Rust to Reality: The Hidden Journey of fetch_max&lt;/head&gt;
    &lt;head rend="h2"&gt;How a Job Interview Sent Me Down a Compiler Rabbit Hole&lt;/head&gt;
    &lt;p&gt;I occasionally interview candidates for engineering roles. We need people who understand concurrent programming. One of our favorite questions involves keeping track of a maximum value across multiple producer threads - a classic pattern that appears in many real-world systems.&lt;/p&gt;
    &lt;p&gt;Candidates can use any language they want. In Java (the language I know best), you might write a CAS loop, or if you're feeling functional, use &lt;code&gt;updateAndGet()&lt;/code&gt; with a lambda:&lt;/p&gt;
    &lt;quote&gt;AtomicLong highScore = new AtomicLong(100);[...]highScore.updateAndGet(current -&amp;gt; Math.max(current, newScore));&lt;/quote&gt;
    &lt;p&gt;But that lambda is doing work - it's still looping under the hood, retrying if another thread interferes. You can see the loop right in AtomicLong's source code.&lt;/p&gt;
    &lt;p&gt;Then one candidate chose Rust.&lt;/p&gt;
    &lt;p&gt;I was following along as he started typing, expecting to see either an explicit CAS loop or some functional wrapper around one. But instead, he just wrote:&lt;/p&gt;
    &lt;quote&gt;high_score.fetch_max(new_score, Ordering::Relaxed);&lt;/quote&gt;
    &lt;p&gt;"Rust has fetch_max built in," he explained casually, moving on to the next part of the problem.&lt;/p&gt;
    &lt;p&gt;Hold on. This wasn't a wrapper around a loop pattern - this was a first-class atomic operation, sitting right there next to &lt;code&gt;fetch_add&lt;/code&gt; and &lt;code&gt;fetch_or&lt;/code&gt;. Java
doesn't have this. C++ doesn't have this. How could Rust just... have this?&lt;/p&gt;
    &lt;p&gt;After the interview, curiosity got the better of me. Why would Rust provide &lt;code&gt;fetch_max&lt;/code&gt; as a built-in intrinsic? Intrinsics usually exist to leverage
specific hardware instructions. But x86-64 doesn't have an &lt;code&gt;atomic max&lt;/code&gt;
instruction. So there had to be a CAS loop somewhere in the pipeline. Unless...
maybe some architectures do have this instruction natively? And if so, how
does the same Rust code work on both?&lt;/p&gt;
    &lt;p&gt;I had to find out. Was the loop in Rust's standard library? Was it in LLVM? Was it generated during code generation for x86-64?&lt;/p&gt;
    &lt;p&gt;So I started digging. What I found was a fascinating journey through five distinct layers of compiler transformations, each one peeling back another level of abstraction, until I found exactly where that loop materialized. Let me share what I discovered.&lt;/p&gt;
    &lt;head rend="h2"&gt;Layer 1: The Rust Code&lt;/head&gt;
    &lt;p&gt;Let's start with what that candidate wrote - a simple high score tracker that can be safely updated from multiple threads:&lt;/p&gt;
    &lt;quote&gt;use std::sync::atomic::{AtomicU64, Ordering};fn main() {let high_score = AtomicU64::new(100);// [...]// Another thread reports a new score of 200let _old_score = high_score.fetch_max(200, Ordering::Relaxed);// [...]}// Save this snippet as `main.rs` we are going to use it later.&lt;/quote&gt;
    &lt;p&gt;This single line does exactly what it promises: atomically fetches the current value, compares it with the new one, updates it if the new value is greater, and returns the old value. It's safe, concise, and impossible to mess up. No explicit loops, no retry logic visible anywhere. But how does it actually work under the hood?&lt;/p&gt;
    &lt;head rend="h2"&gt;Layer 2: The Macro Expansion&lt;/head&gt;
    &lt;p&gt;Before our &lt;code&gt;fetch_max&lt;/code&gt; call even reaches anywhere close to machine code generation,
there's another layer of abstraction at work. The &lt;code&gt;fetch_max&lt;/code&gt; method isn't hand-written
for each atomic type - it's generated by a Rust macro called &lt;code&gt;atomic_int!&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;If we peek into Rust's standard library source code, we find that &lt;code&gt;AtomicU64&lt;/code&gt;
and all its methods are actually created by
this macro:&lt;/p&gt;
    &lt;quote&gt;atomic_int! {cfg(target_has_atomic = "64"),// ... various configuration attributes ...atomic_umin, atomic_umax, // The intrinsics to use8, // Alignmentu64 AtomicU64 // The type to generate}&lt;/quote&gt;
    &lt;p&gt;Inside this macro, &lt;code&gt;fetch_max&lt;/code&gt; is defined as a
template
that works for any integer type:&lt;/p&gt;
    &lt;quote&gt;pub fn fetch_max(&amp;amp;self, val: $int_type, order: Ordering) -&amp;gt; $int_type {// SAFETY: data races are prevented by atomic intrinsics.unsafe { $max_fn(self.v.get(), val, order) }}&lt;/quote&gt;
    &lt;p&gt;The &lt;code&gt;$max_fn&lt;/code&gt; placeholder gets replaced with &lt;code&gt;atomic_umax&lt;/code&gt; for unsigned types
and &lt;code&gt;atomic_max&lt;/code&gt; for signed types. This single macro definition generates
&lt;code&gt;fetch_max&lt;/code&gt; methods for &lt;code&gt;AtomicI8&lt;/code&gt;, &lt;code&gt;AtomicU8&lt;/code&gt;, &lt;code&gt;AtomicI16&lt;/code&gt;, &lt;code&gt;AtomicU16&lt;/code&gt;, and so
on - all the way up to &lt;code&gt;AtomicU128&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;So our simple &lt;code&gt;fetch_max&lt;/code&gt; call is actually invoking generated code. But what
does the &lt;code&gt;atomic_umax&lt;/code&gt; function actually do? To answer that, we need
to see what the Rust compiler produces next.&lt;/p&gt;
    &lt;head rend="h2"&gt;Layer 3: LLVM IR&lt;/head&gt;
    &lt;p&gt;Now that we know &lt;code&gt;fetch_max&lt;/code&gt; is macro-generated code calling &lt;code&gt;atomic_umax&lt;/code&gt;,
let's see what happens when the Rust compiler processes it. The compiler
doesn't go straight to assembly. First, it translates the code into an
intermediate representation. Rust uses the LLVM compiler project, so it
generates LLVM Intermediate Representation (IR).&lt;/p&gt;
    &lt;p&gt;If we peek at the LLVM IR for our &lt;code&gt;fetch_max&lt;/code&gt; call, we see something like this:&lt;/p&gt;
    &lt;quote&gt;; Before the transformationbb7:%0 = atomicrmw umax ptr %self, i64 %val monotonic, align 8...&lt;/quote&gt;
    &lt;p&gt;This is LLVM's language for saying: "I need an atomic read-modify-write operation. The modification I want to perform is an unsigned maximum."&lt;/p&gt;
    &lt;p&gt;This is a powerful, high-level instruction within the compiler itself. But it poses a critical question: does the CPU actually have a single instruction called &lt;code&gt;umax&lt;/code&gt;? For most architectures, the answer is no. So how does the
compiler bridge this gap?&lt;/p&gt;
    &lt;head rend="h3"&gt;How to See This Yourself&lt;/head&gt;
    &lt;p&gt;My goal is not to merely describe what is happening, but to give you the tools to see it for yourself. You can trace this transformation step-by-step on your own machine.&lt;/p&gt;
    &lt;p&gt;First, tell the Rust compiler to stop after generating the LLVM IR:&lt;/p&gt;
    &lt;quote&gt;rustc --emit=llvm-ir main.rs&lt;/quote&gt;
    &lt;p&gt;This creates a &lt;code&gt;main.ll&lt;/code&gt; file. This file contains the LLVM IR
representation of your Rust code, including our &lt;code&gt;atomicrmw umax&lt;/code&gt; instruction.
Keep the file around; we'll use it in the next steps.&lt;/p&gt;
    &lt;head rend="h2"&gt;Interlude: Compiler Intrinsics&lt;/head&gt;
    &lt;p&gt;We're missing something important. How does the Rust function &lt;code&gt;atomic_umax&lt;/code&gt;
actually become the LLVM instruction &lt;code&gt;atomicrmw umax&lt;/code&gt;? This is where compiler
intrinsics come into play.&lt;/p&gt;
    &lt;p&gt;If you dig into Rust's source code, you'll find that &lt;code&gt;atomic_umax&lt;/code&gt; is
defined like this:&lt;/p&gt;
    &lt;quote&gt;/// Updates `*dst` to the max value of `val` and the old value (unsigned comparison)#[inline]#[cfg(target_has_atomic)]#[cfg_attr(miri, track_caller)] // even without panics, this helps for Miri backtracesunsafe fn atomic_umax&amp;lt;T: Copy&amp;gt;(dst: *mut T, val: T, order: Ordering) -&amp;gt; T {// SAFETY: the caller must uphold the safety contract for `atomic_umax`unsafe {match order {Relaxed =&amp;gt; intrinsics::atomic_umax::&amp;lt;T, { AO::Relaxed }&amp;gt;(dst, val),Acquire =&amp;gt; intrinsics::atomic_umax::&amp;lt;T, { AO::Acquire }&amp;gt;(dst, val),Release =&amp;gt; intrinsics::atomic_umax::&amp;lt;T, { AO::Release }&amp;gt;(dst, val),AcqRel =&amp;gt; intrinsics::atomic_umax::&amp;lt;T, { AO::AcqRel }&amp;gt;(dst, val),SeqCst =&amp;gt; intrinsics::atomic_umax::&amp;lt;T, { AO::SeqCst }&amp;gt;(dst, val),}}}&lt;/quote&gt;
    &lt;p&gt;But what is this &lt;code&gt;intrinsics::atomic_umax&lt;/code&gt; function? If you look at its
definition,
you find something slightly unusual:&lt;/p&gt;
    &lt;quote&gt;/// Maximum with the current value using an unsigned comparison./// `T` must be an unsigned integer type.////// The stabilized version of this intrinsic is available on the/// [`atomic`] unsigned integer types via the `fetch_max` method. For example, [`AtomicU32::fetch_max`].#[rustc_intrinsic]#[rustc_nounwind]pub unsafe fn atomic_umax&amp;lt;T: Copy, const ORD: AtomicOrdering&amp;gt;(dst: *mut T, src: T) -&amp;gt; T;&lt;/quote&gt;
    &lt;p&gt;There is no body. This is a declaration, not a definition. The &lt;code&gt;#[rustc_intrinsic]&lt;/code&gt; attribute tells the Rust compiler that this function
maps directly to a low-level operation understood by the compiler
itself. When the Rust compiler sees a call to &lt;code&gt;intrinsics::atomic_umax&lt;/code&gt;, it
knows to
replace it
with the corresponding
LLVM intrinsic function.&lt;/p&gt;
    &lt;p&gt;So our journey actually looks like this:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;&lt;code&gt;fetch_max&lt;/code&gt;method (user-facing API)&lt;/item&gt;
      &lt;item&gt;Macro expands to call &lt;code&gt;atomic_umax&lt;/code&gt;function&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;atomic_umax&lt;/code&gt;is a compiler intrinsic&lt;/item&gt;
      &lt;item&gt;Rustc replaces the intrinsic with LLVM's &lt;code&gt;atomicrmw umax&lt;/code&gt;‚Üê We are here&lt;/item&gt;
      &lt;item&gt;LLVM processes this instruction...&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Layer 4: The Transformation&lt;/head&gt;
    &lt;p&gt;LLVM runs a series of "passes" that analyze and transform the code. The one we're interested in is called the &lt;code&gt;AtomicExpandPass&lt;/code&gt;.&lt;/p&gt;
    &lt;p&gt;Its job is to look at high-level atomic operations like &lt;code&gt;atomicrmw umax&lt;/code&gt; and ask
the target architecture, "Can you do this natively?"&lt;/p&gt;
    &lt;p&gt;When the &lt;code&gt;x86-64&lt;/code&gt; backend says "No, I can't," this pass expands the single
instruction into a sequence of more fundamental ones that the CPU does
understand. The result is a
compare-and-swap (CAS) loop.&lt;/p&gt;
    &lt;p&gt;We can see this transformation in action by asking LLVM to emit the intermediate representation before and after this pass. To see the IR before the &lt;code&gt;AtomicExpandPass&lt;/code&gt;, run:&lt;/p&gt;
    &lt;quote&gt;llc -print-before=atomic-expand main.ll -o /dev/null&lt;/quote&gt;
    &lt;quote&gt;&lt;p&gt;Tip: If you do not have&lt;/p&gt;&lt;code&gt;llc&lt;/code&gt;installed, you can ask&lt;code&gt;rustc&lt;/code&gt;to run the pass for you directly.&lt;code&gt;rustc -C llvm-args="-print-before=atomic-expand -print-after=atomic-expand" main.rs&lt;/code&gt;&lt;/quote&gt;
    &lt;p&gt;The code will be printed to your terminal. The function containing our atomic max looks like this:&lt;/p&gt;
    &lt;quote&gt;*** IR Dump Before Expand Atomic instructions (atomic-expand) ***; Function Attrs: inlinehint nonlazybind uwtabledefine internal i64 @_ZN4core4sync6atomic9AtomicU649fetch_max17h6c42d6f2fc1a6124E(ptr align 8 %self, i64 %val, i8 %0) unnamed_addr #1 {start:%_0 = alloca [8 x i8], align 8%order = alloca [1 x i8], align 1store i8 %0, ptr %order, align 1%1 = load i8, ptr %order, align 1%_7 = zext i8 %1 to i64switch i64 %_7, label %bb2 [i64 0, label %bb7i64 1, label %bb5i64 2, label %bb6i64 3, label %bb4i64 4, label %bb3]bb2: ; preds = %startunreachablebb7: ; preds = %start%2 = atomicrmw umax ptr %self, i64 %val monotonic, align 8store i64 %2, ptr %_0, align 8br label %bb1bb5: ; preds = %start%3 = atomicrmw umax ptr %self, i64 %val release, align 8store i64 %3, ptr %_0, align 8br label %bb1bb6: ; preds = %start%4 = atomicrmw umax ptr %self, i64 %val acquire, align 8store i64 %4, ptr %_0, align 8br label %bb1bb4: ; preds = %start%5 = atomicrmw umax ptr %self, i64 %val acq_rel, align 8store i64 %5, ptr %_0, align 8br label %bb1bb3: ; preds = %start%6 = atomicrmw umax ptr %self, i64 %val seq_cst, align 8store i64 %6, ptr %_0, align 8br label %bb1bb1: ; preds = %bb3, %bb4, %bb6, %bb5, %bb7%7 = load i64, ptr %_0, align 8ret i64 %7}&lt;/quote&gt;
    &lt;p&gt;You can see the &lt;code&gt;atomicrmw umax&lt;/code&gt; instruction in multiple places, depending on
the memory ordering specified. This is the high-level atomic operation that the
compiler backend understands, but the CPU does not.&lt;/p&gt;
    &lt;quote&gt;llc -print-after=atomic-expand main.ll -o /dev/null&lt;/quote&gt;
    &lt;p&gt;This is the relevant part of the output:&lt;/p&gt;
    &lt;quote&gt;*** IR Dump After Expand Atomic instructions (atomic-expand) ***; Function Attrs: inlinehint nonlazybind uwtabledefine internal i64 @_ZN4core4sync6atomic9AtomicU649fetch_max17h6c42d6f2fc1a6124E(ptr align 8 %self, i64 %val, i8 %0) unnamed_addr #1 {start:%_0 = alloca [8 x i8], align 8%order = alloca [1 x i8], align 1store i8 %0, ptr %order, align 1%1 = load i8, ptr %order, align 1%_7 = zext i8 %1 to i64switch i64 %_7, label %bb2 [i64 0, label %bb7i64 1, label %bb5i64 2, label %bb6i64 3, label %bb4i64 4, label %bb3]bb2: ; preds = %startunreachablebb7: ; preds = %start%2 = load i64, ptr %self, align 8 ; seed expected valuebr label %atomicrmw.start ; enter CAS loopatomicrmw.start: ; preds = %atomicrmw.start, %bb7%loaded = phi i64 [ %2, %bb7 ], [ %newloaded, %atomicrmw.start ] ; on first iteration: use %2, on retries: use value observed by last cmpxchg%3 = icmp ugt i64 %loaded, %val ; unsigned compare (umax semantics)%new = select i1 %3, i64 %loaded, i64 %val ; desired = max(loaded, val)%4 = cmpxchg ptr %self, i64 %loaded, i64 %new monotonic monotonic, align 8 ; CAS: if *self==loaded, store new%success = extractvalue { i64, i1 } %4, 1 ; boolean: whether the swap happened%newloaded = extractvalue { i64, i1 } %4, 0 ; value seen in memory before the CASbr i1 %success, label %atomicrmw.end, label %atomicrmw.start ; loop until CAS succeedsatomicrmw.end: ; preds = %atomicrmw.startstore i64 %newloaded, ptr %_0, align 8br label %bb1[... MORE OF THE SAME, JUST FOR DIFFERENT ORDERING..]bb1: ; preds = %bb3, %bb4, %bb6, %bb5, %bb7%7 = load i64, ptr %_0, align 8ret i64 %7}&lt;/quote&gt;
    &lt;p&gt;We can see the pass did not change the first part - it still has the code to dispatch based on the memory ordering. But in the &lt;code&gt;bb7&lt;/code&gt; block, where we originally had the
&lt;code&gt;atomicrmw umax&lt;/code&gt; LLVM instruction, we now see a full compare-and-swap loop.
A compiler engineer would say that the &lt;code&gt;atomicrmw umax&lt;/code&gt; instruction has been
"lowered" into a sequence of more primitive operations, that are closer to what
the hardware can actually execute.&lt;/p&gt;
    &lt;p&gt;Here's the simplified logic:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Read (seed): grab the current value (&lt;code&gt;expected&lt;/code&gt;).&lt;/item&gt;
      &lt;item&gt;Compute: &lt;code&gt;desired = umax(expected, val)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;Attempt: &lt;code&gt;observed, success = cmpxchg(ptr, expected, desired, [...])&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;If success, return &lt;code&gt;observed&lt;/code&gt;(the old value). Otherwise&lt;code&gt;set expected = observed&lt;/code&gt;and loop.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This CAS loop is a fundamental pattern in lock-free programming. The compiler just built it for us automatically.&lt;/p&gt;
    &lt;head rend="h2"&gt;Layer 5: The Final Product (x86-64 Assembly)&lt;/head&gt;
    &lt;p&gt;We're at the final step. To see the final machine code, you can tell &lt;code&gt;rustc&lt;/code&gt; to
emit the assembly directly:&lt;/p&gt;
    &lt;quote&gt;rustc --emit=asm main.rs&lt;/quote&gt;
    &lt;p&gt;This will produce a &lt;code&gt;main.s&lt;/code&gt; file containing the final assembly code.
Inside, you'll find the result of the &lt;code&gt;cmpxchg&lt;/code&gt; loop:&lt;/p&gt;
    &lt;quote&gt;.LBB8_2:movq -32(%rsp), %rax # rax = &amp;amp;selfmovq (%rax), %rax # rax = *self (seed 'expected')movq %rax, -48(%rsp) # spill expected to stack.LBB8_3: # loop headmovq -48(%rsp), %rax # rax = expectedmovq -32(%rsp), %rcx # rcx = &amp;amp;selfmovq -40(%rsp), %rdx # rdx = valmovq %rax, %rsi # rsi = expected (scratch)subq %rdx, %rsi # set flags for unsigned compare: expected - valcmovaq %rax, %rdx # if (expected &amp;gt; val) rdx = expected; else rdx = val (compute max)lock cmpxchgq %rdx, (%rcx)# CAS: if *rcx==rax then *rcx=rdx; rax &amp;lt;- old *rcx; ZF=successsete %cl # cl = successmovq %rax, -56(%rsp) # spill observed to stacktestb $1, %cl # branch on successmovq %rax, -48(%rsp) # expected = observed (for retry)jne .LBB8_4 # success -&amp;gt; exitjmp .LBB8_3 # failure ‚Üí retry&lt;/quote&gt;
    &lt;p&gt;The syntax might look a bit different from what you're used to, that's because it's in AT&amp;amp;T syntax, which is the default for &lt;code&gt;rustc&lt;/code&gt;. If you prefer Intel syntax, you can
use &lt;code&gt;rustc --emit=asm main.rs -C "llvm-args=-x86-asm-syntax=intel"&lt;/code&gt; to get that.&lt;/p&gt;
    &lt;p&gt;I'm not an assembly expert, but you can see the key parts of the CAS loop here:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Seed read (first iteration): Load &lt;code&gt;*self&lt;/code&gt;once to initialize the expected value.&lt;/item&gt;
      &lt;item&gt;Compute umax without branching: The pair &lt;code&gt;sub&lt;/code&gt;+&lt;code&gt;cmova&lt;/code&gt;implements&lt;code&gt;desired = max_u(expected, val)&lt;/code&gt;.&lt;/item&gt;
      &lt;item&gt;CAS operation: On x86-64, &lt;code&gt;cmpxchg&lt;/code&gt;uses&lt;code&gt;RAX&lt;/code&gt;as the expected value and returns the observed value in&lt;code&gt;RAX&lt;/code&gt;;&lt;code&gt;ZF&lt;/code&gt;encodes success.&lt;/item&gt;
      &lt;item&gt;Retry or finish: If &lt;code&gt;ZF&lt;/code&gt;is clear, we failed and need to retry. Otherwise, we are done.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;&lt;p&gt;Note we did not ask&lt;/p&gt;&lt;code&gt;rustc&lt;/code&gt;to optimize the code. If we did, the compiler would generate more efficient assembly: No spills to the stack, fewer jumps, no dispatch on memory ordering, etc. But I wanted to keep the output as close to the original IR as possible to make it easier to follow.&lt;/quote&gt;
    &lt;head rend="h2"&gt;The Beauty of Abstraction&lt;/head&gt;
    &lt;p&gt;And there we have it. Our journey is complete. We started with a safe, clear, single line of Rust and ended with a CAS loop written in assembly language.&lt;/p&gt;
    &lt;p&gt;Rust &lt;code&gt;fetch_max&lt;/code&gt; ‚Üí Macro-generated &lt;code&gt;atomic_umax&lt;/code&gt; ‚Üí LLVM
&lt;code&gt;atomicrmw umax&lt;/code&gt; ‚Üí LLVM &lt;code&gt;cmpxchg&lt;/code&gt; loop ‚Üí Assembly &lt;code&gt;lock cmpxchg&lt;/code&gt; loop&lt;/p&gt;
    &lt;p&gt;This journey is a perfect example of the power of modern compilers. We get to work at a high level of abstraction, focusing on safety and logic, while the compiler handles the messy, error-prone, and incredibly complex task of generating correct and efficient code for the hardware.&lt;/p&gt;
    &lt;p&gt;So, next time you use an atomic, take a moment to appreciate the incredible, hidden journey your code is about to take.&lt;/p&gt;
    &lt;p&gt;PS: After conducting this journey I learned that C++26 adds &lt;code&gt;fetch_max&lt;/code&gt;
too!&lt;/p&gt;
    &lt;p&gt;PPS: We are hiring!&lt;/p&gt;
    &lt;head rend="h2"&gt;Bonus: Apple Silicon (AArch64)&lt;/head&gt;
    &lt;p&gt;Out of curiosity, I also checked how this looks on Apple Silicon (AArch64). This architecture does have a native &lt;code&gt;atomic max&lt;/code&gt; instruction, so the
&lt;code&gt;AtomicExpandPass&lt;/code&gt; does not need to lower it into a CAS loop. The LLVM code before and after
the pass is identical, still containing the &lt;code&gt;atomicrmw umax&lt;/code&gt; instruction.&lt;/p&gt;
    &lt;p&gt;The final assembly contains a variant of the &lt;code&gt;LDUMAX&lt;/code&gt; instruction. This is the relevant part of the assembly:&lt;/p&gt;
    &lt;quote&gt;ldr x8, [sp, #16] # x8 = value to compare withldr x9, [sp, #8] # x9 = pointer to the atomic variableldumax x8, x8, [x9] # atomic unsigned max (relaxed), [x9] = max(x8, [x9]), x8 = old valuestr x8, [sp, #40] # Store old valueb LBB8_11&lt;/quote&gt;
    &lt;quote&gt;
      &lt;p&gt;Note that AArch64 uses Unified Assembler Language, when reading the snippet above, it's important to remember that the destination register comes first.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;And that's really it. We could continue to dig into the microarchitecture, to see how instructions are executed at the hardware level, what are the effects of the &lt;code&gt;LOCK&lt;/code&gt; prefix, dive into differences in memory ordering, etc.
But we'll leave that for another day.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Alice: "Would you tell me, please, which way I ought to go from here?"&lt;/p&gt;&lt;lb/&gt;The Cat: "That depends a good deal on where you want to get to."&lt;lb/&gt;Alice: "I don't much care where."&lt;lb/&gt;The Cat: "Then it doesn't much matter which way you go."&lt;lb/&gt;Alice: "...So long as I get somewhere."&lt;lb/&gt;The Cat: "Oh, you're sure to do that, if only you walk long enough."&lt;p&gt;- Lewis Carroll, Alice's Adventures in Wonderland&lt;/p&gt;&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://questdb.com/blog/rust-fetch-max-compiler-journey/"/><published>2025-09-23T21:24:45+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45354314</id><title>Top Programming Languages 2025</title><updated>2025-09-24T11:08:30.107022+00:00</updated><content>&lt;doc fingerprint="ff481adb873c88f9"&gt;
  &lt;main&gt;&lt;p&gt;Since 2013, we‚Äôve been metaphorically peering over the shoulders of programmers to create our annual interactive rankings of the most popular programming languages. But fundamental shifts in how people are coding may not just make it harder to measure popularity, but could even make the concept itself irrelevant. And then things might get really weird. To see why, let‚Äôs start with this year‚Äôs rankings and a quick refresher of how we put this thing together.&lt;/p&gt;&lt;p&gt;In the ‚ÄúSpectrum‚Äù default ranking, which is weighted with the interests of IEEE members in mind, we see that once again Python has the top spot, with the biggest change in the top five being JavaScript‚Äôs drop from third place last year to sixth place this year. As JavaScript is often used to create web pages, and vibe coding is often used to create websites, this drop in the apparent popularity may be due to the effects of AI that we‚Äôll dig into in a moment. But first to finish up with this year‚Äôs scores, in the ‚ÄúJobs‚Äù ranking, which looks exclusively at what skills employers are looking for, we see that Python has also taken 1st place, up from second place last year, though SQL expertise remains an incredibly valuable skill to have on your resume.&lt;/p&gt;&lt;p&gt;Because we can‚Äôt literally look over the shoulders of everyone who codes, including kids hacking on Minecraft servers or academic researchers developing new architectures, we rely on proxies to measure popularity. We detail our methodology here, but the upshot is that we merge metrics from multiple sources to create our rankings. The metrics we choose publicly signal interest across a wide range of languages‚ÄîGoogle search traffic, questions asked on Stack Exchange, mentions in research papers, activity on the GitHub open source code repository, and so on.&lt;/p&gt;&lt;p&gt;But programmers are turning away from many of these public expressions of interest. Rather than page through a book or search a website like Stack Exchange for answers to their questions, they‚Äôll chat with an LLM like Claude or ChatGPT in a private conversation. And with an AI assistant like Cursor helping to write code, the need to pose questions in the first place is significantly decreased. For example, across the total set of languages evaluated in the TPL, the number of questions we saw posted per week on Stack Exchange in 2025 was just 22 percent of what it was in 2024.&lt;/p&gt;&lt;p&gt;With less signal in publicly available metrics, it becomes harder to track popularity across a broad range of languages. This existential problem for our rankings can be tackled by searching for new metrics, or trying to survey programmers‚Äîin all their variety‚Äîdirectly. However, an even more fundamental problem is looming in the wings.&lt;/p&gt;&lt;p&gt;Whether it‚Äôs a seasoned coder using an AI to handle the grunt work, or a neophyte vibe coding a complete web app, AI assistance means that programmers can concern themselves less and less with the particulars of any language. First details of syntax, then flow control and functions, and so on up the levels of how a program is put together‚Äîmore and more is being left to the AI.&lt;/p&gt;&lt;p&gt;Although code-writing LLM‚Äôs are still very much a work in progress, as they take over an increasing share of the work, programmers inevitably shift from being the kind of people willing to fight religious wars over whether source code should be indented by typing tabs or spaces to people who care less and less about what language is used.&lt;/p&gt;&lt;p&gt;After all, the whole reason different computer languages exist is because given a particular challenge, it‚Äôs easier to express a solution in one language versus another. You wouldn‚Äôt control a washing machine using the R programming language, or conversely do a statistical analysis on large datasets using C.&lt;/p&gt;&lt;p&gt;But it is technically possible to do both. A human might tear their hair out doing it, but LLMs have about as much hair as they do sentience. As long as there‚Äôs enough training data, they‚Äôll generate code for a given prompt in any language you want. In practical terms, this means using one‚Äîany one‚Äîof today‚Äôs most popular general purpose programming languages. In the same way most developers today don‚Äôt pay much attention to the instruction sets and other hardware idiosyncrasies of the CPUs that their code runs on, which language a program is vibe coded in ultimately becomes a minor detail.&lt;/p&gt;&lt;p&gt;Sure, there will always be some people who care, just as today there are nerds like me willing to debate the merits of writing for the Z80 versus the 6502 8-bit CPUs. But overall, the popularity of different computer languages could become as obscure a topic as the relative popularity of railway track gauges.&lt;/p&gt;&lt;p&gt;One obvious long-term consequence to this is that it will become harder for new languages to emerge. Previously, new languages could emerge from individuals or small teams evangelizing their approach to potential contributors and users. Presentations, papers, demos, sample code and tutorials seeded new developer ecosystems. A single well-written book, like Leo Brodie‚Äôs Starting Forth or Brian Kernighan and Dennis Ritchies‚Äô The C Programming Language, could make an enormous difference to a language‚Äôs popularity.&lt;/p&gt;&lt;p&gt;But while a few samples and a tutorial can be enough material to jump-start adoption among programmers familiar with the ins and outs of hands-on coding, it‚Äôs not enough for today‚Äôs AIs. Humans build mental models that can extrapolate from relatively small amounts of data. LLMs rely on statistical probabilities, so the more data they can crunch, they better they are. Consequently programmers have noted that AIs give noticeably poorer results when trying to code in less-used languages.&lt;/p&gt;&lt;p&gt;There are research efforts to make LLMs more universal coders, but that doesn‚Äôt really help new languages get off the ground. Fundamentally new languages grow because they are scratching some itch a programmer has. That itch can be as small as being annoyed at semicolons having to be placed after every statement, or as large as a philosophical argument about the purpose of computation.&lt;/p&gt;&lt;p&gt;But if an AI is soothing our irritations with today‚Äôs languages, will any new ones ever reach the kind of critical mass needed to make an impact? Will the popularity of today‚Äôs languages remain frozen in time?&lt;/p&gt;&lt;head rend="h2"&gt;What‚Äôs the future of programming languages?&lt;/head&gt;&lt;p&gt;Before speculating further about the future, let‚Äôs touch base again where we are today. Modern high-level computer languages are really designed to do two things: create an abstraction layer that makes it easier to process data in a suitable fashion, and stop programmers from shooting themselves in the foot.&lt;/p&gt;&lt;p&gt;The first objective has been around since the days of Fortran and Cobol, aimed at processing scientific and business data respectively. The second objective emerged later, spurred in no small part by Edgar Dijkstra‚Äôs 1968 paper ‚ÄúGo To Statement Considered Harmful.‚Äù In this he argued for eliminating the ability for a programmer to make jumps to arbitrary points in their code. This restriction was to prevent so-called spaghetti code that makes it hard for a programmer to understand how a computer actually executes a given program. Instead, Dijkstra demanded that programmers bend to structural rules imposed by the language. Dijkstra‚Äôs argument ultimately won the day, and most modern languages do indeed minimize or eliminate Go Tos altogether in favor of structures like functions and other programmatic blocks.&lt;/p&gt;&lt;p&gt;These structures don‚Äôt exist at the level of the CPU. If you look at the instruction sets for Arm, x86, or RISC-V processors, the flow of a program is controlled by just three types of machine code instructions. These are conditional jumps, unconditional jumps, and jumps with a trace stored (so you can call a subroutine and return to where you started). In other words, it‚Äôs Go Tos all the way down. Similarly, strict data types designed to label and protect data from incorrect use dissolve into anonymous bits flowing in and out of memory.&lt;/p&gt;&lt;p&gt;So how much abstraction and anti-foot-shooting structure will a sufficiently-advanced coding AI really need? A hint comes from recent research in AI-assisted hardware design, such as Dall-EM, a generative AI developed at Princeton University used to create RF and electromagnetic filters. Designing these filters has always been something of a black art, involving the wrangling of complex electromagnetic fields as they swirl around little strips of metal. But Dall-EM can take in the desired inputs and outputs and spit out something that looks like a QR code. The results are something no human would ever design‚Äîbut it works.&lt;/p&gt;&lt;p&gt;Similarly, could we get our AIs to go straight from prompt to an intermediate language that could be fed into the interpreter or compiler of our choice? Do we need high-level languages at all in that future? True, this would turn programs into inscrutable black boxes, but they could still be divided into modular testable units for sanity and quality checks. And instead of trying to read or maintain source code, programmers would just tweak their prompts and generate software afresh.&lt;/p&gt;&lt;p&gt;What‚Äôs the role of the programmer in a future without source code? Architecture design and algorithm selection would remain vital skills‚Äîfor example, should a pathfinding program use a classic approach like the A* algorithm, or instead should it try to implement a new method? How should a piece of software be interfaced with a larger system? How should new hardware be exploited? In this scenario, computer science degrees, with their emphasis on fundamentals over the details of programming languages, rise in value over coding boot camps.&lt;/p&gt;Will there be a Top Programming Language in 2026? Right now, programming is going through the biggest transformation since compilers broke onto the scene in the early 1950s. Even if the predictions that much of AI is a bubble about to burst come true, the thing about tech bubbles is that there‚Äôs always some residual technology that survives. It‚Äôs likely that using LLMs to write and assist with code is something that‚Äôs going to stick. So we‚Äôre going to be spending the next 12 months figuring out what popularity means in this new age, and what metrics might be useful to measure. What do you think popularity should mean? What metrics do you think we should consider? Let us know in the comments below.&lt;list rend="ul"&gt;&lt;item&gt;AI Models Embrace Humanlike Reasoning ‚Ä∫&lt;/item&gt;&lt;item&gt;LLM Benchmarking Shows Capabilities Doubling Every 7 Months ‚Ä∫&lt;/item&gt;&lt;item&gt;Why Functional Programming Should Be the Future of Software Development ‚Ä∫&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Stephen Cass is the special projects editor at IEEE Spectrum. He currently helms Spectrum's Hands On column, and is also responsible for interactive projects such as the Top Programming Languages app. He has a bachelor's degree in experimental physics from Trinity College Dublin.&lt;/p&gt;&lt;p&gt;A programming language is a bridge between natural English and computer machine languages, allowing humans to tell the computer what to do.&lt;/p&gt;&lt;p&gt;The idea language will be human's natural languages, including English, Chinese and other popular human languages we learned after birth.&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://spectrum.ieee.org/top-programming-languages-2025"/><published>2025-09-23T23:42:50+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45354644</id><title>Baldur's Gate 3 Steam Deck ‚Äì Native Version</title><updated>2025-09-24T11:08:29.249520+00:00</updated><content>&lt;doc fingerprint="bcd4a8bd8df387c9"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Steam Deck - Native Version&lt;/head&gt;
    &lt;p&gt;Upon release of Hotfix #34 on your Steam Deck, your device will install the Native version.&lt;/p&gt;
    &lt;p&gt;If you are unsure whether the build has been installed correctly, you can do the following:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Go to the game‚Äôs Steam page. Click on the Settings button and select Properties.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Once in the Properties page, go to the Compatibility tab.&lt;/item&gt;
      &lt;item&gt;Tick the box for ‚ÄúForce the use of a specific Steam Play compatibility tool‚Äù.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Select any version that has Linux Runtime.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allow the game to update if an update appears.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;What‚Äôs the difference between the Steam Deck Native and Proton version?&lt;/p&gt;
    &lt;p&gt;Our Proton version runs on the Steam Deck via the Proton compatibility layer, which requires extra CPU processing power. Running the game natively on the Steam Deck requires less CPU usage and memory consumption overall!&lt;/p&gt;
    &lt;p&gt;Can I still switch back to the Proton version?&lt;/p&gt;
    &lt;p&gt;Yes. If you‚Äôre having issues with the Steam Deck Native build, you can revert to the Proton version. Take the following steps to do so:&lt;/p&gt;
    &lt;p&gt;Go to the game‚Äôs Steam page. Click on the Settings button and select Properties.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Once in the Properties page, go to the Compatibility tab.&lt;/item&gt;
      &lt;item&gt;Tick the box for ‚ÄúForce the use of a specific Steam Play compatibility tool‚Äù.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Select any Proton version 8 or higher.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Allow the game to update.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now that there is a Steam Deck Native build, is Baldur‚Äôs Gate 3 supported on Linux?&lt;/p&gt;
    &lt;p&gt;Larian does not provide support for the Linux platform. The Steam Deck Native build is only supported on Steam Deck.&lt;/p&gt;
    &lt;head rend="h2"&gt;Savegames&lt;/head&gt;
    &lt;p&gt;Where are my saves located currently (before using the Steam Deck Native version)?&lt;/p&gt;
    &lt;p&gt;Before the Steam Deck Native version becomes the primary version, your saves will be in the compatdata folder: /home/deck/.local/share/Steam/steamapps/compatdata/1086940/pfx/drive_c/users/steamuser/AppData/Local/Larian Studios/Baldur's Gate 3/PlayerProfiles/Public&lt;/p&gt;
    &lt;p&gt;Where are my saves located when I use the Steam Deck Native version?&lt;/p&gt;
    &lt;p&gt;After the Steam Deck Native version becomes the primary version, your saves will be in the following folder: /home/deck/.local/share/Larian Studios/Baldur's Gate 3/PlayerProfiles/Public&lt;/p&gt;
    &lt;p&gt;Why are my saves in different folders?&lt;/p&gt;
    &lt;p&gt;When Baldur‚Äôs Gate 3 runs on the Proton compatibility layer, the Proton version will store the saves in the compatdata folder, which is a mirrored version of the Windows file storage system. On the Steam Deck Native version, the saves are stored natively on the SteamOS file storage system.&lt;/p&gt;
    &lt;p&gt;Will my savegames be transferred over to the new version when I use the Steam Deck Native version?&lt;/p&gt;
    &lt;p&gt;If your Steam Cloud saves are turned on, your most recent saves will be synced to the Steam Deck Native savegame folder automatically.&lt;/p&gt;
    &lt;p&gt;What if I don‚Äôt have Cloud saves turned on, or I want my older saves?&lt;/p&gt;
    &lt;p&gt;Your saves are still stored on the Steam Deck, but they will be stored in the compatdata folder.&lt;lb/&gt; You can manually transfer these files via the Desktop:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;First, switch to Desktop Mode by clicking on the Steam button and selecting Power. Then click on Switch to Desktop.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p/&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;If you have a mouse and keyboard to hand, plug them in to make your life a little easier, and click on the folder icon on the bar at the bottom.&lt;/item&gt;
      &lt;item&gt;In the explorer window, navigate to: /home/deck/.local/share/Steam/steamapps/compatdata/1086940/pfx/drive_c/users/steamuser/AppData/Local/Larian Studios/Baldur's Gate 3/PlayerProfiles/Public&lt;/item&gt;
      &lt;item&gt;Copy the Savegames folder.&lt;/item&gt;
      &lt;item&gt;Navigate to: /home/deck/.local/share/Larian Studios/Baldur's Gate 3/PlayerProfiles/Public&lt;/item&gt;
      &lt;item&gt;Paste the copied folder in this location.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;&lt;lb/&gt; Will my old saves still take up storage space on my Steam Deck?&lt;/p&gt;
    &lt;p&gt;Yes, your old saves will still take up storage space. If you want to save some space and you don't plan on using the Proton version, you can delete the compatdata folder after you've copied over the folders.&lt;/p&gt;
    &lt;head rend="h2"&gt;Mods&lt;/head&gt;
    &lt;p&gt;Will my mods be transferred over automatically?&lt;/p&gt;
    &lt;p&gt;If you are logged into your Larian Account and have it connected to mod.io, all mods you are subscribed to will be downloaded when the transition to Steam Deck Native occurs.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt; What if I‚Äôm not logged into a Larian Account or connected to mod.io?&lt;/p&gt;
    &lt;p&gt;You can either manually download the mods from the Mod Manager or transfer them manually from the previous folder.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;To do so,switch to Desktop Mode by clicking on the Steam button and selecting Power. Then click on Switch to Desktop.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Click on the folder icon on the bar at the bottom.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In the explorer window, navigate to: /home/deck/.local/share/Steam/steamapps/compatdata/1086940/pfx/drive_c/users/steamuser/AppData/Local/Larian Studios/Baldur's Gate 3&lt;/item&gt;
      &lt;item&gt;Copy the Mods folder.&lt;/item&gt;
      &lt;item&gt;Navigate to: /home/deck/.local/share/Larian Studios/Baldur's Gate 3/&lt;/item&gt;
      &lt;item&gt;Paste the copied folder in this location.&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://larian.com/support/faqs/steam-deck-native-version_121"/><published>2025-09-24T00:26:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45354689</id><title>Periodic Table of Cognition</title><updated>2025-09-24T11:08:28.736125+00:00</updated><content>&lt;doc fingerprint="ff34989f0b052f5d"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;The Periodic Table of Cognition&lt;/head&gt;
    &lt;p&gt;I√¢ve been studying the early history of electricity√¢s discovery as a map for our current discovery of artificial intelligence. The smartest people alive back then, including Isaac Newton, who may have been the smartest person who ever lived, had confident theories about electricity√¢s nature that were profoundly wrong. In fact, despite the essential role of electrical charges in the universe, everyone who worked on this fundamental force was profoundly wrong for a long time. All the pioneers of electricity √¢ such as Franklin, Wheatstone, Faraday, and Maxwell √¢ had a few correct ideas of their own (not shared by all) mixed in with notions that mostly turned out to be flat out misguided. Most of the discoveries about what electricity could do happened without the knowledge of how they worked. That ignorance, of course, drastically slowed down the advances in electrical inventions.&lt;/p&gt;
    &lt;p&gt;In a similar way, the smartest people today, especially all the geniuses creating artificial intelligence, have theories about what intelligence is, and I believe all of them (me too) will be profoundly wrong. We don√¢t know what artificial intelligence is in large part because we don√¢t know what our own intelligence is. And this ignorance will later be seen as an impediment to the rate of progress in AI.&lt;/p&gt;
    &lt;p&gt;A major part of our ignorance stems from our confusion about the general category of either electricity or intelligence. We tend to view both electricity and intelligence as coherent elemental forces along a single dimension: you either have more of it or less. But in fact, electricity turned out to be so complicated, so complex, so full of counterintuitive effects that even today it is still hard to grasp how it works. It has particles and waves, and fields and flows, composed of things that are not really there. Our employment of electricity exceeds our understanding of it. Understanding electricity was essential to understanding matter. It wasn√¢t until we learned to control electricity that we were able to split water √¢ which had been considered an element √¢ into its actual elements; that enlightened us that water was not a foundational element, but a derivative compound made up of sub elements.&lt;/p&gt;
    &lt;p&gt;It is very probable we will discover that intelligence is likewise not a foundational singular element, but a derivative compound composed of multiple cognitive elements, combined in a complex system unique to each species of mind. The result that we call intelligence emerges from many different cognitive primitives such as long-term memory, spatial awareness, logical deduction, advance planning, pattern perception, and so on. There may be dozens of them, or hundreds. We currently don√¢t have any idea of what these elements are. We lack a periodic table of cognition.&lt;/p&gt;
    &lt;p&gt;The cognitive elements will more resemble the heavier elements in being unstable and dynamic. Or a better analogy would be to the elements in a biological cell. The primitives of cognition are flow states that appear in a thought cycle. They are like molecules in a cell which are in constant flux, shifting from one shape to another. Their molecular identity is related to their actions and interactions with other molecules. Thinking is a collective action that happens in time (like temperature in matter) and every mode can only be seen in relation to the other modes before and after it. It is a network phenomenon that makes it difficult to identify its borders. So each element of intelligence is embedded in a thought cycle, and requires the other elements as part of its identity. So each cognitive element is described in context of the other cognitive modes adjacent to it.&lt;/p&gt;
    &lt;p&gt;I asked ChatGPT5Pro to help me generate a periodic table of cognition given what we collectively know so far. It suggests 49 elements, arranged in a table so that related concepts are adjacent. The columns are families, or general categories of cognition such as √¢Perception√¢, √¢Reasoning√¢, √¢Learning√¢, so all the types of perception or reasoning are stacked in one column. The rows are sorted by stages in a cycle of thought. The earlier stages (such as √¢sensing√¢) are at the top, while later stages in the cycle (such as √¢reflect &amp;amp; align√¢) are at the bottom. So for example, in the family or category of √¢Safety√¢ the AIs will tend to do the estimation of uncertainty first, later do verification, and only get to a theory of mind at the end.&lt;/p&gt;
    &lt;p&gt;The chart is colored according to how much progress we√¢ve made on each element. Red indicates we can synthesize that element in a robust way. Orange means we can kind of make it work with the right scaffolding. Yellow reflects promising research without operational generality yet.&lt;/p&gt;
    &lt;p&gt;I suspect many of these elements are not as distinct as shown here (taxonomically I am more of a lumper than a splitter), and I would expect this collection omits many types we are soon to discover, but as a start, this prototype chart serves its purpose: it reveals the complexity of intelligence. It is clear intelligence is compounded along multiple dimensions. We will engineer different AIs to have different combinations of different elements in different strengths. This will produce thousands of types of possible minds. We can see that even today different animals have their own combination of cognitive primitives, arranged in a pattern unique to their species√¢ needs. In some animals some of the elements √¢ say long-term memory √¢ may exceed our own in strength; of course they lack some elements we have.&lt;/p&gt;
    &lt;p&gt;With the help of AI, we are discovering what these elements of cognition are. Each advance illuminates a bit of how minds work and what is needed to achieve results. If the discovery of electricity and atoms has anything to teach us now, it is that we are probably very far from having discovered the complete set of cognitive elements. Instead we are at the stage of believing in ethers, instantaneous action, and phlogiston √¢ a few of the incorrect theories of electricity the brightest scientists believed.&lt;/p&gt;
    &lt;p&gt;Almost no thinker, researcher, experimenter, or scientist at that time could see the true nature of electricity, electromagnetism, radiation and subatomic particles, because the whole picture was hugely unintuitive. Waves, force fields, particles of atoms did not make sense (and still does not make common sense). It required sophisticated mathematics to truly comprehend it, and even after Maxwell described it mathematically, he found it hard to visualize.&lt;/p&gt;
    &lt;p&gt;I expect the same from intelligence. Even after we identify its ingredients, the emergent properties they generate are likely to be obscure and hard to believe, hard to visualize. Intelligence is unlikely to make common sense.&lt;/p&gt;
    &lt;p&gt;A century ago, our use of electricity ran ahead of our understanding of it. We made motors from magnets and coiled wire without understanding why they worked. Theory lagged behind practice. As with electricity, our employment of intelligence exceeds our understanding of it. We are using LLMs to answer questions or to code software without having a theory of intelligence. A real theory of intelligence is so lacking that we don√¢t know how our own minds work, let alone the synthetic ones we can now create.&lt;/p&gt;
    &lt;p&gt;The theory of the atomic world needed the knowledge of the periodic table of elements. You had to know all (or at least most) of the parts to make falsifiable predictions of what would happen. The theory of intelligence requires knowledge of all the elemental parts, which we have only slowly begun to identify, before we can predict what might happen next.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kk.org/thetechnium/the-periodic-table-of-cognition/"/><published>2025-09-24T00:33:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45355462</id><title>Zutty: Zero-cost Unicode Teletype, high-end terminal for low-end systems</title><updated>2025-09-24T11:08:28.077762+00:00</updated><content>&lt;doc fingerprint="5661518ff093686f"&gt;
  &lt;main&gt;
    &lt;p&gt;]&amp;gt;&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;description&lt;/cell&gt;
        &lt;cell&gt;A high-end terminal for low-end systems&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;last change&lt;/cell&gt;
        &lt;cell&gt;Mon, 3 Mar 2025 09:35:42 +0000 (10:35 +0100)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;URL&lt;/cell&gt;
        &lt;cell&gt;https://git.hq.sig7.se/zutty.git&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Before coming into serious contact with Zutty (e.g., reporting a bug, asking for anything), all the below pages are required reading:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;15 months ago&lt;/cell&gt;
        &lt;cell&gt;0.16&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.16&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;20 months ago&lt;/cell&gt;
        &lt;cell&gt;0.15&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.15&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;2 years ago&lt;/cell&gt;
        &lt;cell&gt;0.14&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.14&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;3 years ago&lt;/cell&gt;
        &lt;cell&gt;0.13&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.13&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;3 years ago&lt;/cell&gt;
        &lt;cell&gt;0.12&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.12&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;3 years ago&lt;/cell&gt;
        &lt;cell&gt;0.11&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.11&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;3 years ago&lt;/cell&gt;
        &lt;cell&gt;0.10&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.10&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.9&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.9&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.8&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.8&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.7&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.7&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.6&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.6&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.5&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.5&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.4&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.4&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.3&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.3&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.2&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.2&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;4 years ago&lt;/cell&gt;
        &lt;cell&gt;0.1&lt;/cell&gt;
        &lt;cell&gt;Zutty 0.1&lt;/cell&gt;
        &lt;cell&gt;tag&lt;/cell&gt;
        &lt;cell&gt;| commit | shortlog | log&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6 months ago&lt;/cell&gt;
        &lt;cell&gt;master&lt;/cell&gt;
        &lt;cell&gt;shortlog | log | tree&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;17 months ago&lt;/cell&gt;
        &lt;cell&gt;tracy-profiling&lt;/cell&gt;
        &lt;cell&gt;shortlog | log | tree&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;17 months ago&lt;/cell&gt;
        &lt;cell&gt;gpu-perf-optimizations&lt;/cell&gt;
        &lt;cell&gt;shortlog | log | tree&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://git.hq.sig7.se/zutty.git"/><published>2025-09-24T02:07:23+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45355965</id><title>New study shows plants and animals emit a visible light that expires at death</title><updated>2025-09-24T11:08:27.007357+00:00</updated><content/><link href="https://pubs.acs.org/doi/10.1021/acs.jpclett.4c03546"/><published>2025-09-24T03:27:41+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45356226</id><title>Greatest irony of the AI age: Humans hired to clean AI slop</title><updated>2025-09-24T11:08:26.492191+00:00</updated><content>&lt;doc fingerprint="be4119bcbb886cbd"&gt;
  &lt;main&gt;
    &lt;p&gt;On one side is AI swallowing millions of jobs, and on the other is humans being hired to clean up the nonsense AI often generates, finds Satyen K. Bordoloi&lt;/p&gt;
    &lt;p&gt;This was early 2023, a few months after ChatGPT had just made the perfect superintelligence landing in our lives. A producer friend, who wanted a beat sheet of a series written into a synopsis, sent me a document he said he had gotten written.&lt;/p&gt;
    &lt;p&gt;A reading of its first paragraph was all it took to identify the writer: ChatGPT. The perfect robotic structure, excessive and often misplaced adverbs and adjectives, and the absence of indirect tense gave it away instantly. It was sloppy in its sterile perfection.&lt;/p&gt;
    &lt;p&gt;Yet, my friend asked me to take it as a base and improve it. Crunched for time, I did. I didn‚Äôt know then, but I had unwittingly participated in what would become one of the most in-demand gigs two years later: humans cleaning up AI slop.&lt;/p&gt;
    &lt;p&gt;This is the defining irony of the AI age. While AI is consuming millions of jobs, it is simultaneously creating a unique category of employment for hundreds of thousands of humans: cleaning up the mess AI makes. Designers, writers and digital artists are increasingly being hired not to create from scratch, but fix the mess AI invariably makes when tasked with complex work. What is doubly ironic is that these are often the same humans who would have been hired to create the original had AI not been brought to undercut them.&lt;/p&gt;
    &lt;head rend="h2"&gt;WHAT IS AI SLOP&lt;/head&gt;
    &lt;p&gt;Jack Izzo, in a Yahoo article, defines it better than any LLM can: ‚ÄúAI slop is the evolution of spam, in a way. Like spam, slop is low-quality content, but thanks to artificial intelligence (AI) tools like ChatGPT and Midjourney, it‚Äôs even easier to produce. Like spam, slop can grow like a weed if left unchecked, overwhelming social media feeds and leaving users unsure of what‚Äôs real and what‚Äôs not. Like spam, slop comes in many forms ‚Äî posts on social media.. books on Amazon, music on Spotify, articles from less-than-reliable news outlets (and, unfortunately, some reliable outlets) and even occasionally in peer-reviewed scientific journals.‚Äù&lt;/p&gt;
    &lt;p&gt;It is the content equivalent of empty calories: visually or textually appealing, but devoid of substance, originality, or reliable meaning.&lt;/p&gt;
    &lt;p&gt;With video generation becoming as cheap and easy as creating images, the internet is being flooded with AI-generated video slop. A hyper-realistic video of a seagull staring down a French fry on a car dashboard before smashing the window to grab it generated over 140 million views. A CCTV-style video of rabbits jumping on a backyard trampoline has racked up over 200 million views on TikTok and X. So has another video of a bear doing the same. And unsurprisingly, even porn is now overflowing with AI-generated slop.&lt;/p&gt;
    &lt;p&gt;Now the bunny video had tell-tale glitches: a bunny with two heads, and another vanishing mid-bounce. These alerted the discerning viewers to its sloppy origin. But this raises a question: What if the creator had hired a VFX artist to correct the errors?&lt;/p&gt;
    &lt;head rend="h2"&gt;HARMS OF THE AI SLOPOCALYPSE&lt;/head&gt;
    &lt;p&gt;The dangers of AI slop are many. First and foremost, the well of misinformation that the internet has always been is now being industrialised by AI that can generate thousands of plausible-sounding articles, product reviews, or social media posts in the time it takes a person to write just one. This floods everything, burying good information under a mountain of convincing garbage. So far, we have seen the enshittification of online businesses.&lt;/p&gt;
    &lt;p&gt;However, with AI models remixing and regurgitating existing content, what we have is the enshittification of culture itself, as music playlists are already overflowing with AI-generated music, Amazon with AI-generated books, and TikTok and other social media platforms are slowly filling up with AI-made videos.&lt;/p&gt;
    &lt;p&gt;And let‚Äôs not forget that creating this garbage consumes staggering amounts of water and electricity, contributing to emissions that harm the planet. Then there are people hired to clean up AI nonsense who could have been artists in their own right, but are now relegated to digital janitorial duties, leading to frustration and burnout.&lt;/p&gt;
    &lt;head rend="h2"&gt;CLEANUP CREW TO THE RESCUE&lt;/head&gt;
    &lt;p&gt;And the ones saving us from the slopocalypse, irony be crucified, are now good old humans with analogue brains. The promised AI utopia of effortless creation is instead giving rise to an underclass of digital rescuers, whose job profiles are being rewritten as AI code and training changes. These roles for AI clean up specialists are cropping up across industries, especially in freelance and creative sectors where AI‚Äôs limitations are most glaring.&lt;/p&gt;
    &lt;p&gt;First and foremost are the AI content rewriters hired to rewrite AI-generated articles, blogs, and marketing content that lack nuance, emotional resonance and factual accuracy. Then there are the art fixers hired to redraw or retouch AI-generated logos, illustrations, and art. Most AI-generated images have wrapped text, symmetry that doesn‚Äôt match reality and can be pixelated. Actual graphic designers and AI artists work to restore clarity and scale. AI code debuggers are hired to patch buggy code written by the likes of GitHub Copilot or ChatGPT. These actual developers and freelance engineers are hired to test, fix and optimise AI-generated code.&lt;/p&gt;
    &lt;p&gt;AI-generated videos are glitchy and often get physics wrong, and generate random things inside frames. AI video polishers are typically VFX artists whose job is to enhance the visual coherence and thus the realism of the footage.&lt;/p&gt;
    &lt;p&gt;These roles are not about collaboration, but correction. And the cost-saving AI promised is a mirage that can‚Äôt be held without the hidden overhead of human quality control. This entire endeavour reeks of a bizarre inefficiency as machines create slop at scale, and humans are hired to clean it up at a premium.&lt;/p&gt;
    &lt;p&gt;Go to freelance platforms like Upwork, Fiverr, and Freelancer, and you‚Äôll see a surging demand for human-led creativity, especially in writing, image creation, and design.&lt;/p&gt;
    &lt;head rend="h2"&gt;MOTHER OF ALL IRONIES&lt;/head&gt;
    &lt;p&gt;AI was supposed to replace humans. Instead, it is creating a parallel economy of human fixers: people who make synthetic content usable, relatable, real ‚Äì make it feel more human. There‚Äôs another irony ‚Äì AI is replacing humans in certain jobs, while also creating menial jobs for them. People who, before AI, would have become artists have been relegated to the job of cleaners, janitors, cleaning AI slop. Yes, AI is on one side revealing just how irreplaceable humans are when it comes to nuance, empathy, and storytelling, but at the cost of the humans who can do those.&lt;/p&gt;
    &lt;p&gt;The problem here, as often isn‚Äôt artificial intelligence, but natural human stupidity. AI creating slop and humans hired to clean it isn‚Äôt an inevitable tech progress outcome. No! It‚Äôs a choice arisen out of a gold rush mentality that prioritises speed, volume and cost-cutting over quality, authenticity, and truth.&lt;/p&gt;
    &lt;p&gt;The solution, hence, lies not in AI becoming more ‚Äòintelligent‚Äô, but in humans becoming smarter and realising that humans should always be in the loop, not brought in at the end to clean up. The solution isn‚Äôt in abandoning AI, but in recalibrating our relationship with it. We must realise that AI isn‚Äôt a replacement for human creativity and judgment, but that it‚Äôs a tool, a powerful one at that, which, when guided by human empathy and art, will create beauty and heart.&lt;/p&gt;
    &lt;p&gt;The greatest irony of this AI age may be that humans are hired to clean up AI‚Äôs mess; the greatest tragedy, however, would be if we became so accustomed to that slop that we forgot what a clean, human-made world looks like. The cleanup crew is a temporary fix. The real work is in ensuring that our technological future is built not on a foundation of AI slop, but on a commitment to genuine human creativity and integrity.&lt;/p&gt;
    &lt;head rend="h3"&gt;In case you missed:&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Kodak Moment: How Apple, Amazon, Meta, Microsoft Missed the AI Boat, Playing Catch-Up&lt;/item&gt;
      &lt;item&gt;Rise of Generative AI in India: Trends &amp;amp; Opportunities&lt;/item&gt;
      &lt;item&gt;The End of SEO as We Know It: Welcome to the AIO Revolution&lt;/item&gt;
      &lt;item&gt;Google Falters Under AI Onslaught: Future of Search in Peril?&lt;/item&gt;
      &lt;item&gt;One Year of No-camera Filmmaking: How AI Rewrote Rules of Cinema Forever&lt;/item&gt;
      &lt;item&gt;Rise of the Robolympics: When R2-D2 Meets Rocky Balboa&lt;/item&gt;
      &lt;item&gt;Are Hallucinations Good For AI? Maybe Not, But They‚Äôre Great For Humans&lt;/item&gt;
      &lt;item&gt;AI Taken for Granted: Has the World Reached the Point of AI Fatigue?&lt;/item&gt;
      &lt;item&gt;Hey Marvel, Just Admit You‚Äôre Using AI ‚Äì We All Are!&lt;/item&gt;
      &lt;item&gt;Anthropomorphisation of AI: Why Can‚Äôt We Stop Believing AI Will End the World?&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.sify.com/ai-analytics/greatest-irony-of-the-ai-age-humans-being-increasingly-hired-to-clean-ai-slop/"/><published>2025-09-24T04:15:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45356958</id><title>You didn't see it coming</title><updated>2025-09-24T11:08:26.017866+00:00</updated><content>&lt;doc fingerprint="188c151f1be4746f"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;You Didn't See It Coming&lt;/head&gt;
    &lt;p&gt;It started with the hiring posts.&lt;/p&gt;
    &lt;p&gt;A friend, call him Dev, began writing on LinkedIn and Twitter/X about his intentionally small team. How they moved faster, knew each other deeply, avoided the bureaucracy that kills startups. His posts got traction. The story felt authentic because, at the time, it was.&lt;/p&gt;
    &lt;p&gt;What I knew, and his followers didn't, was simpler. Dev couldn't hire. His runway was tight, his equity offers weren't competitive, and the candidates he wanted kept choosing better-funded competitors. The small team wasn't a philosophy, it was a constraint.&lt;/p&gt;
    &lt;p&gt;A year later, the layoff headlines started. Big tech cutting thousands, venture-backed startups imploding, bloated teams getting slashed. Suddenly, Dev's posts multiplied. Thoughtful threads about choosing culture over rapid growth, the wisdom of staying lean. He wrote about how he'd "always believed in sustainable team building and praised his foresight in avoiding the growth-at-all-costs trap.&lt;/p&gt;
    &lt;p&gt;I watched this transformation with fascination. Dev had become the prophet of his own past.&lt;/p&gt;
    &lt;p&gt;Source:Internet&lt;/p&gt;
    &lt;p&gt;I started noticing it everywhere. The founder who couldn't afford an office now posts about remote-first culture. The one who couldn't hire senior engineers writes threads about growing talent from within. The startup that stayed in their home market because international expansion was too expensive now shares insights about deep local expertise over global sprawl.&lt;/p&gt;
    &lt;p&gt;We've all become heroes of our carefully edited stories.&lt;/p&gt;
    &lt;p&gt;Nobody wants to admit their big decisions were driven by fear, circumstance, or luck. We want to feel like we have agency, like we're smart enough to see around corners. Social media gives us the perfect platform to curate evidence of our judgment, to turn our anxious stumbling into confident striding.&lt;/p&gt;
    &lt;p&gt;But something darker emerges. I think about founders reading Dev's small team philosophy, especially those facing similar hiring challenges.&lt;/p&gt;
    &lt;p&gt;What do they learn? That Doubt is failure. Feeds become echo chambers where everyone is always right, and the messy reality of decision making is sanitized into personal brand moments.&lt;/p&gt;
    &lt;p&gt;What do we need? Real guidance. That comes from honesty about constraints, the times when your "strategy" was actually just making the best of what you had. It demands admitting that many successful decisions weren't visionary choices but creative responses to circumstances beyond your control.&lt;/p&gt;
    &lt;p&gt;But that kind of honesty doesn't get shared or saved on LinkedIn and X/Twitter.&lt;/p&gt;
    &lt;p&gt;Still, I couldn't shake the feeling that something important was being lost in all this performed wisdom. Maybe the most valuable thing we could share wasn't evidence of our foresight, but honest accounts of how often we're all just figuring it out as we go.&lt;/p&gt;
    &lt;p&gt;Maybe the real prophet in my feed was the person brave enough to admit they didn't see it coming.&lt;/p&gt;
    &lt;head rend="h3"&gt;What I've been Learning:&lt;/head&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;The $10 Trillion AI Revolution: Loved the "flops per knowledge worker" concept and how uncertainty can become competitive leverage. The idea of building investment thesis around what others see as risk resonated - turning ambiguity into advantage.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;The Stubborn Genius of James Dyson: Dyson's obsession with doing things differently rather than following trends was fascinating. His point that breakthrough success isn't quantum leaps but persistent iteration that just looks sudden from the outside is a great learning.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Note: Written from my own experience, with Claude helping me structure my rambling thoughts into something readable&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://aishwaryagoel.com/you-didnt-see-it-coming/"/><published>2025-09-24T06:26:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45357693</id><title>That Secret Service SIM farm story is bogus</title><updated>2025-09-24T11:08:25.948945+00:00</updated><content/><link href="https://cybersect.substack.com/p/that-secret-service-sim-farm-story"/><published>2025-09-24T08:24:20+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45358433</id><title>My game's server is blocked in Spain whenever there's a football match on</title><updated>2025-09-24T11:08:25.892931+00:00</updated><content/><link href="https://old.reddit.com/r/gamedev/comments/1np6kyn/my_games_server_is_blocked_in_spain_whenever/"/><published>2025-09-24T10:26:23+00:00</published></entry></feed>