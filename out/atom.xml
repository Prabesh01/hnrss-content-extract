<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-25T23:32:21.177273+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45706487</id><title>Show HN: Shadcn/UI theme editor – Design and share Shadcn themes</title><updated>2025-10-25T23:32:28.652237+00:00</updated><content>&lt;doc fingerprint="5b5948a7543b02e7"&gt;
  &lt;main&gt;
    &lt;p&gt;All Themes GitHub ShadCN Themes Discover and create beautiful themes for shadcn/ui Import New Theme Filter by color: Red Orange Yellow Green Teal Blue Purple Pink Gray Black White Loading themes...&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://shadcnthemer.com"/><published>2025-10-25T19:51:24+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706518</id><title>AI, Wikipedia, and uncorrected machine translations of vulnerable languages</title><updated>2025-10-25T23:32:28.477577+00:00</updated><content>&lt;doc fingerprint="760a589b28b682a2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How AI and Wikipedia have sent vulnerable languages into a doom spiral&lt;/head&gt;
    &lt;p&gt;Machine translators have made it easier than ever to create error-plagued Wikipedia articles in obscure languages. What happens when AI models get trained on junk pages?&lt;/p&gt;
    &lt;p&gt;When Kenneth Wehr started managing the Greenlandic-language version of Wikipedia four years ago, his first act was to delete almost everything. It had to go, he thought, if it had any chance of surviving.&lt;/p&gt;
    &lt;p&gt;Wehr, who’s 26, isn’t from Greenland—he grew up in Germany—but he had become obsessed with the island, an autonomous Danish territory, after visiting as a teenager. He’d spent years writing obscure Wikipedia articles in his native tongue on virtually everything to do with it. He even ended up moving to Copenhagen to study Greenlandic, a language spoken by some 57,000 mostly Indigenous Inuit people scattered across dozens of far-flung Arctic villages.&lt;/p&gt;
    &lt;p&gt;The Greenlandic-language edition was added to Wikipedia around 2003, just a few years after the site launched in English. By the time Wehr took its helm nearly 20 years later, hundreds of Wikipedians had contributed to it and had collectively written some 1,500 articles totaling over tens of thousands of words. It seemed to be an impressive vindication of the crowdsourcing approach that has made Wikipedia the go-to source for information online, demonstrating that it could work even in the unlikeliest places.&lt;/p&gt;
    &lt;p&gt;There was only one problem: The Greenlandic Wikipedia was a mirage.&lt;/p&gt;
    &lt;p&gt;Virtually every single article had been published by people who did not actually speak the language. Wehr, who now teaches Greenlandic in Denmark, speculates that perhaps only one or two Greenlanders had ever contributed. But what worried him most was something else: Over time, he had noticed that a growing number of articles appeared to be copy-pasted into Wikipedia by people using machine translators. They were riddled with elementary mistakes—from grammatical blunders to meaningless words to more significant inaccuracies, like an entry that claimed Canada had only 41 inhabitants. Other pages sometimes contained random strings of letters spat out by machines that were unable to find suitable Greenlandic words to express themselves.&lt;/p&gt;
    &lt;p&gt;“It might have looked Greenlandic to [the authors], but they had no way of knowing,” complains Wehr.&lt;/p&gt;
    &lt;p&gt;“Sentences wouldn’t make sense at all, or they would have obvious errors,” he adds. “AI translators are really bad at Greenlandic.”&lt;/p&gt;
    &lt;p&gt;What Wehr describes is not unique to the Greenlandic edition.&lt;/p&gt;
    &lt;p&gt;Wikipedia is the most ambitious multilingual project after the Bible: There are editions in over 340 languages, and a further 400 even more obscure ones are being developed and tested. Many of these smaller editions have been swamped with automatically translated content as AI has become increasingly accessible. Volunteers working on four African languages, for instance, estimated to MIT Technology Review that between 40% and 60% of articles in their Wikipedia editions were uncorrected machine translations. And after auditing the Wikipedia edition in Inuktitut, an Indigenous language close to Greenlandic that’s spoken in Canada, MIT Technology Review estimates that more than two-thirds of pages containing more than several sentences feature portions created this way.&lt;/p&gt;
    &lt;p&gt;This is beginning to cause a wicked problem. AI systems, from Google Translate to ChatGPT, learn to “speak” new languages by scraping huge quantities of text from the internet. Wikipedia is sometimes the largest source of online linguistic data for languages with few speakers—so any errors on those pages, grammatical or otherwise, can poison the wells that AI is expected to draw from. That can make the models’ translation of these languages particularly error-prone, which creates a sort of linguistic doom loop as people continue to add more and more poorly translated Wikipedia pages using those tools, and AI models continue to train from poorly translated pages. It’s a complicated problem, but it boils down to a simple concept: Garbage in, garbage out.&lt;/p&gt;
    &lt;p&gt;“These models are built on raw data,” says Kevin Scannell, a former professor of computer science at Saint Louis University who now builds computer software tailored for endangered languages. “They will try and learn everything about a language from scratch. There is no other input. There are no grammar books. There are no dictionaries. There is nothing other than the text that is inputted.”&lt;/p&gt;
    &lt;p&gt;There isn’t perfect data on the scale of this problem, particularly because a lot of AI training data is kept confidential and the field continues to evolve rapidly. But back in 2020, Wikipedia was estimated to make up more than half the training data that was fed into AI models translating some languages spoken by millions across Africa, including Malagasy, Yoruba, and Shona. In 2022, a research team from Germany that looked into what data could be obtained by online scraping even found that Wikipedia was the sole easily accessible source of online linguistic data for 27 under-resourced languages.&lt;/p&gt;
    &lt;p&gt;This could have significant repercussions in cases where Wikipedia is poorly written—potentially pushing the most vulnerable languages on Earth toward the precipice as future generations begin to turn away from them.&lt;/p&gt;
    &lt;p&gt;“Wikipedia will be reflected in the AI models for these languages,” says Trond Trosterud, a computational linguist at the University of Tromsø in Norway, who has been raising the alarm about the potentially harmful outcomes of badly run Wikipedia editions for years. “I find it hard to imagine it will not have consequences. And, of course, the more dominant position that Wikipedia has, the worse it will be.”&lt;/p&gt;
    &lt;head rend="h3"&gt;Use responsibly&lt;/head&gt;
    &lt;p&gt;Automation has been built into Wikipedia since the very earliest days. Bots keep the platform operational: They repair broken links, fix bad formatting, and even correct spelling mistakes. These repetitive and mundane tasks can be automated away with little problem. There is even an army of bots that scurry around generating short articles about rivers, cities, or animals by slotting their names into formulaic phrases. They have generally made the platform better.&lt;/p&gt;
    &lt;p&gt;But AI is different. Anybody can use it to cause massive damage with a few clicks.&lt;/p&gt;
    &lt;p&gt;Wikipedia has managed the onset of the AI era better than many other websites. It has not been flooded with AI bots or disinformation, as social media has been. It largely retains the innocence that characterized the earlier internet age. Wikipedia is open and free for anyone to use, edit, and pull from, and it’s run by the very same community it serves. It is transparent and easy to use. But community-run platforms live and die on the size of their communities. English has triumphed, while Greenlandic has sunk.&lt;/p&gt;
    &lt;p&gt;“We need good Wikipedians. This is something that people take for granted. It is not magic,” says Amir Aharoni, a member of the volunteer Language Committee, which oversees requests to open or close Wikipedia editions. “If you use machine translation responsibly, it can be efficient and useful. Unfortunately, you cannot trust all people to use it responsibly.”&lt;/p&gt;
    &lt;p&gt;Trosterud has studied the behavior of users on small Wikipedia editions and says AI has empowered a subset that he terms “Wikipedia hijackers.” These users can range widely—from naive teenagers creating pages about their hometowns or their favorite YouTubers to well-meaning Wikipedians who think that by creating articles in minority languages they are in some way “helping” those communities.&lt;/p&gt;
    &lt;p&gt;“The problem with them nowadays is that they are armed with Google Translate,” Trosterud says, adding that this is allowing them to produce much longer and more plausible-looking content than they ever could before: “Earlier they were armed only with dictionaries.”&lt;/p&gt;
    &lt;p&gt;This has effectively industrialized the acts of destruction—which affect vulnerable languages most, since AI translations are typically far less reliable for them. There can be lots of different reasons for this, but a meaningful part of the issue is the relatively small amount of source text that is available online. And sometimes models struggle to identify a language because it is similar to others, or because some, including Greenlandic and most Native American languages, have structures that make them badly suited to the way most machine translation systems work. (Wehr notes that in Greenlandic most words are agglutinative, meaning they are built by attaching prefixes and suffixes to stems. As a result, many words are extremely context specific and can express ideas that in other languages would take a full sentence.)&lt;/p&gt;
    &lt;p&gt;Research produced by Google before a major expansion of Google Translate rolled out three years ago found that translation systems for lower-resourced languages were generally of a lower quality than those for better-resourced ones. Researchers found, for example, that their model would often mistranslate basic nouns across languages, including the names of animals and colors. (In a statement to MIT Technology Review, Google wrote that it is “committed to meeting a high standard of quality for all 249 languages” it supports “by rigorously testing and improving [its] systems, particularly for languages that may have limited public text resources on the web.”)&lt;/p&gt;
    &lt;p&gt;Wikipedia itself offers a built-in editing tool called Content Translate, which allows users to automatically translate articles from one language to another—the idea being that this will save time by preserving the references and fiddly formatting of the originals. But it piggybacks on external machine translation systems, so it’s largely plagued by the same weaknesses as other machine translators—a problem that the Wikimedia Foundation says is hard to solve. It’s up to each edition’s community to decide whether this tool is allowed, and some have decided against it. (Notably, English-language Wikipedia has largely banned its use, claiming that some 95% of articles created using Content Translate failed to meet an acceptable standard without significant additional work.) But it’s at least easy to tell when the program has been used; Content Translate adds a tag on the Wikipedia back end.&lt;/p&gt;
    &lt;p&gt;Other AI programs can be harder to monitor. Still, many Wikipedia editors I spoke with said that once their languages were added to major online translation tools, they noticed a corresponding spike in the frequency with which poor, likely machine-translated pages were created.&lt;/p&gt;
    &lt;p&gt;Some Wikipedians using AI to translate content do occasionally admit that they do not speak the target languages. They may see themselves as providing smaller communities with rough-cut articles that speakers can then fix—essentially following the same model that has worked well for more active Wikipedia editions.&lt;/p&gt;
    &lt;quote&gt;
      &lt;head&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&lt;/head&gt;
    &lt;/quote&gt;
    &lt;p&gt;But once error-filled pages are produced in small languages, there is usually not an army of knowledgeable people who speak those languages standing ready to improve them. There are few readers of these editions, and sometimes not a single regular editor.&lt;/p&gt;
    &lt;p&gt;Yuet Man Lee, a Canadian teacher in his 20s, says that he used a mix of Google Translate and ChatGPT to translate a handful of articles that he had written for the English Wikipedia into Inuktitut, thinking it’d be nice to pitch in and help a smaller Wikipedia community. He says he added a note to one saying that it was only a rough translation. “I did not think that anybody would notice [the article],” he explains. “If you put something out there on the smaller Wikipedias—most of the time nobody does.”&lt;/p&gt;
    &lt;p&gt;But at the same time, he says, he still thought “someone might see it and fix it up”—adding that he had wondered whether the Inuktitut translation that the AI systems generated was grammatically correct. Nobody has touched the article since he created it.&lt;/p&gt;
    &lt;p&gt;Lee, who teaches social sciences in Vancouver and first started editing entries in the English Wikipedia a decade ago, says that users familiar with more active Wikipedias can fall victim to this mindset, which he terms a “bigger-Wikipedia arrogance”: When they try to contribute to smaller Wikipedia editions, they assume that others will come along to fix their mistakes. It can sometimes work. Lee says he had previously contributed several articles to Wikipedia in Tatar, a language spoken by several million people mainly in Russia, and at least one of those was eventually corrected. But the Inuktitut Wikipedia is, by comparison, a “barren wasteland.”&lt;/p&gt;
    &lt;p&gt;He emphasizes that his intentions had been good: He wanted to add more articles to an Indigenous Canadian Wikipedia. “I am now thinking that it may have been a bad idea. I did not consider that I could be contributing to a recursive loop,” he says. “It was about trying to get content out there, out of curiosity and for fun, without properly thinking about the consequences.”&lt;/p&gt;
    &lt;head rend="h3"&gt;“Totally, completely no future”&lt;/head&gt;
    &lt;p&gt;Wikipedia is a project that is driven by wide-eyed optimism. Editing can be a thankless task, involving weeks spent bickering with faceless, pseudonymous people, but devotees put in hours of unpaid labor because of a commitment to a higher cause. It is this commitment that drives many of the regular small-language editors I spoke with. They all feared what would happen if garbage continued to appear on their pages.&lt;/p&gt;
    &lt;p&gt;Abdulkadir Abdulkadir, a 26-year-old agricultural planner who spoke with me over a crackling phone call from a busy roadside in northern Nigeria, said that he spends three hours every day fiddling with entries in his native Fulfulde, a language used mainly by pastoralists and farmers across the Sahel. “But the work is too much,” he said.&lt;/p&gt;
    &lt;p&gt;Abdulkadir sees an urgent need for the Fulfulde Wikipedia to work properly. He has been suggesting it as one of the few online resources for farmers in remote villages, potentially offering information on which seeds or crops might work best for their fields in a language they can understand. If you give them a machine-translated article, Abdulkadir told me, then it could “easily harm them,” as the information will probably not be translated correctly into Fulfulde.&lt;/p&gt;
    &lt;p&gt;Google Translate, for instance, says the Fulfulde word for January means June, while ChatGPT says it’s August or September. The programs also suggest the Fulfulde word for “harvest” means “fever” or “well-being,” among other possibilities.&lt;/p&gt;
    &lt;p&gt;Abdulkadir said he had recently been forced to correct an article about cowpeas, a foundational cash crop across much of Africa, after discovering that it was largely illegible.&lt;/p&gt;
    &lt;p&gt;If someone wants to create pages on the Fulfulde Wikipedia, Abdulkadir said, they should be translated manually. Otherwise, “whoever will read your articles will [not] be able to get even basic knowledge,” he tells these Wikipedians. Nevertheless, he estimates that some 60% of articles are still uncorrected machine translations. Abdulkadir told me that unless something important changes with how AI systems learn and are deployed, then the outlook for Fulfulde looks bleak. “It is going to be terrible, honestly,” he said. “Totally, completely no future.”&lt;/p&gt;
    &lt;p&gt;Across the country from Abdulkadir, Lucy Iwuala contributes to Wikipedia in Igbo, a language spoken by several million people in southeastern Nigeria. “The harm has already been done,” she told me, opening the two most recently created articles. Both had been automatically translated via Wikipedia’s Content Translate and contained so many mistakes that she said it would have given her a headache to continue reading them. “There are some terms that have not even been translated. They are still in English,” she pointed out. She recognized the username that had created the pages as a serial offender. “This one even includes letters that are not used in the Igbo language,” she said.&lt;/p&gt;
    &lt;p&gt;Iwuala began regularly contributing to Wikipedia three years ago out of concern that Igbo was being displaced by English. It is a worry that is common to many who are active on smaller Wikipedia editions. “This is my culture. This is who I am,” she told me. “That is the essence of it all: to ensure that you are not erased.”&lt;/p&gt;
    &lt;p&gt;Iwuala, who now works as a professional translator between English and Igbo, said the users doing the most damage are inexperienced and see AI translations as a way to quickly increase the profile of the Igbo Wikipedia. She often finds herself having to explain at online edit-a-thons she organizes, or over email to various error-prone editors, that the results can be the exact opposite, pushing users away: “You will be discouraged and you will no longer want to visit this place. You will just abandon it and go back to the English Wikipedia.”&lt;/p&gt;
    &lt;p&gt;These fears are echoed by Noah Ha‘alilio Solomon, an assistant professor of Hawaiian language at the University of Hawai‘i. He reports that some 35% of words on some pages in the Hawaiian Wikipedia are incomprehensible. “If this is the Hawaiian that is going to exist online, then it will do more harm than anything else,” he says.&lt;/p&gt;
    &lt;p&gt;Hawaiian, which was teetering on the verge of extinction several decades ago, has been undergoing a recovery effort led by Indigenous activists and academics. Seeing such poor Hawaiian on such a widely used platform as Wikipedia is upsetting to Ha‘alilio Solomon.&lt;/p&gt;
    &lt;p&gt;“It is painful, because it reminds us of all the times that our culture and language has been appropriated,” he says. “We have been fighting tooth and nail in an uphill climb for language revitalization. There is nothing easy about that, and this can add extra impediments. People are going to think that this is an accurate representation of the Hawaiian language.”&lt;/p&gt;
    &lt;p&gt;The consequences of all these Wikipedia errors can quickly become clear. AI translators that have undoubtedly ingested these pages in their training data are now assisting in the production, for instance, of error-strewn AI-generated books aimed at learners of languages as diverse as Inuktitut and Cree, Indigenous languages spoken in Canada, and Manx, a small Celtic language spoken on the Isle of Man. Many of these have been popping up for sale on Amazon. “It was just complete nonsense,” says Richard Compton, a linguist at the University of Quebec in Montreal, of a volume he reviewed that had purported to be an introductory phrasebook for Inuktitut.&lt;/p&gt;
    &lt;p&gt;Rather than making minority languages more accessible, AI is now creating an ever expanding minefield for students and speakers of those languages to navigate. “It is a slap in the face,” Compton says. He worries that younger generations in Canada, hoping to learn languages in communities that have fought uphill battles against discrimination to pass on their heritage, might turn to online tools such as ChatGPT or phrasebooks on Amazon and simply make matters worse. “It is fraud,” he says.&lt;/p&gt;
    &lt;head rend="h3"&gt;A race against time&lt;/head&gt;
    &lt;p&gt;According to UNESCO, a language is declared extinct every two weeks. But whether the Wikimedia Foundation, which runs Wikipedia, has an obligation to the languages used on its platform is an open question. When I spoke to Runa Bhattacharjee, a senior director at the foundation, she said that it was up to the individual communities to make decisions about what content they wanted to exist on their Wikipedia. “Ultimately, the responsibility really lies with the community to see that there is no vandalism or unwanted activity, whether through machine translation or other means,” she said. Usually, Bhattacharjee added, editions were considered for closure only if a specific complaint was raised about them.&lt;/p&gt;
    &lt;p&gt;But if there is no active community, how can an edition be fixed or even have a complaint raised?&lt;/p&gt;
    &lt;p&gt;Bhattacharjee explained that the Wikimedia Foundation sees its role in such cases as about maintaining the Wikipedia platform in case someone comes along to revive it: “It is the space that we provide for them to grow and develop. That is where we are at.”&lt;/p&gt;
    &lt;p&gt;Inari Saami, spoken in a single remote community in northern Finland, is a poster child for how people can take good advantage of Wikipedia. The language was headed toward extinction four decades ago; there were only four children who spoke it. Their parents created the Inari Saami Language Association in a last-ditch bid to keep it going. The efforts worked. There are now several hundred speakers, schools that use Inari Saami as a medium of instruction, and 6,400 Wikipedia articles in the language, each one copy-edited by a fluent speaker.&lt;/p&gt;
    &lt;p&gt;This success highlights how Wikipedia can indeed provide small and determined communities with a unique vehicle to promote their languages’ preservation. “We don’t care about quantity. We care about quality,” says Fabrizio Brecciaroli, a member of the Inari Saami Language Association. “We are planning to use Wikipedia as a repository for the written language. We need to provide tools that can be used by the younger generations. It is important for them to be able to use Inari Saami digitally.”&lt;/p&gt;
    &lt;p&gt;This has been such a success that Wikipedia has been integrated into the curriculum at the Inari Saami–speaking schools, Brecciaroli adds. He fields phone calls from teachers asking him to write up simple pages on topics from tornadoes to Saami folklore. Wikipedia has even offered a way to introduce words into Inari Saami. “We have to make up new words all the time,” Brecciaroli says. “Young people need them to speak about sports, politics, and video games. If they are unsure how to say something, they now check Wikipedia.”&lt;/p&gt;
    &lt;p&gt;Wikipedia is a monumental intellectual experiment. What’s happening with Inari Saami suggests that with maximum care, it can work in smaller languages. “The ultimate goal is to make sure that Inari Saami survives,” Brecciaroli says. “It might be a good thing that there isn’t a Google Translate in Inari Saami.”&lt;/p&gt;
    &lt;p&gt;That may be true—though large language models like ChatGPT can be made to translate phrases into languages that more traditional machine translation tools do not offer. Brecciaroli told me that ChatGPT isn’t great in Inari Saami but that the quality varies significantly depending on what you ask it to do; if you ask it a question in the language, then the answer will be filled with words from Finnish and even words it invents. But if you ask it something in English, Finnish, or Italian and then ask it to reply in Inari Saami, it will perform better.&lt;/p&gt;
    &lt;p&gt;In light of all this, creating as much high-quality content online as can possibly be written becomes a race against time. “ChatGPT only needs a lot of words,” Brecciaroli says. “If we keep putting good material in, then sooner or later, we will get something out. That is the hope.” This is an idea supported by multiple linguists I spoke with—that it may be possible to end the “garbage in, garbage out” cycle. (OpenAI, which operates ChatGPT, did not respond to a request for comment.)&lt;/p&gt;
    &lt;p&gt;Still, the overall problem is likely to grow and grow, since many languages are not as lucky as Inari Saami—and their AI translators will most likely be trained on more and more AI slop. Wehr, unfortunately, seems far less optimistic about the future of his beloved Greenlandic.&lt;/p&gt;
    &lt;p&gt;Since deleting much of the Greenlandic-language Wikipedia, he has spent years trying to recruit speakers to help him revive it. He has appeared in Greenlandic media and made social media appeals. But he hasn’t gotten much of a response; he says it has been demoralizing.&lt;/p&gt;
    &lt;p&gt;“There is nobody in Greenland who is interested in this, or who wants to contribute,” he says. “There is completely no point in it, and that is why it should be closed.”&lt;/p&gt;
    &lt;p&gt;Late last year, he began a process requesting that the Wikipedia Language Committee shut down the Greenlandic-language edition. Months of bitter debate followed between dozens of Wikipedia bureaucrats; some seemed to be surprised that a superficially healthy-seeming edition could be gripped by so many problems.&lt;/p&gt;
    &lt;p&gt;Then, earlier this month, Wehr’s proposal was accepted: Greenlandic Wikipedia is set to be shuttered, and any articles that remain will be moved into the Wikipedia Incubator, where new language editions are tested and built. Among the reasons cited by the Language Committee is the use of AI tools, which have “frequently produced nonsense that could misrepresent the language.”&lt;/p&gt;
    &lt;p&gt;Nevertheless, it may be too late—mistakes in Greenlandic already seem to have become embedded in machine translators. If you prompt either Google Translate or ChatGPT to do something as simple as count to 10 in proper Greenlandic, neither program can deliver.&lt;/p&gt;
    &lt;p&gt;Jacob Judah is an investigative journalist based in London.&lt;/p&gt;
    &lt;head rend="h3"&gt;Deep Dive&lt;/head&gt;
    &lt;head rend="h3"&gt;Artificial intelligence&lt;/head&gt;
    &lt;head rend="h3"&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot&lt;/head&gt;
    &lt;p&gt;We’re increasingly developing bonds with chatbots. While that’s safe for some, it’s dangerous for others.&lt;/p&gt;
    &lt;head rend="h3"&gt;Therapists are secretly using ChatGPT. Clients are triggered.&lt;/head&gt;
    &lt;p&gt;Some therapists are using AI during therapy sessions. They’re risking their clients’ trust and privacy in the process.&lt;/p&gt;
    &lt;head rend="h3"&gt;OpenAI is huge in India. Its models are steeped in caste bias.&lt;/head&gt;
    &lt;p&gt;India is OpenAI’s second-largest market, but ChatGPT and Sora reproduce caste stereotypes that harm millions of people.&lt;/p&gt;
    &lt;head rend="h3"&gt;AI models are using material from retracted scientific papers&lt;/head&gt;
    &lt;p&gt;Some companies are working to remedy the issue.&lt;/p&gt;
    &lt;head rend="h3"&gt;Stay connected&lt;/head&gt;
    &lt;head rend="h2"&gt;Get the latest updates from&lt;lb/&gt;MIT Technology Review&lt;/head&gt;
    &lt;p&gt;Discover special offers, top stories, upcoming events, and more.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.technologyreview.com/2025/09/25/1124005/ai-wikipedia-vulnerable-languages-doom-spiral/"/><published>2025-10-25T19:57:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706527</id><title>California invests in battery energy storage, leaving rolling blackouts behind</title><updated>2025-10-25T23:32:28.352677+00:00</updated><content>&lt;doc fingerprint="235081ed63971539"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Share via&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;California hasn’t issued an emergency plea for the public to conserve energy, known as a Flex Alert, since 2022.&lt;/item&gt;
      &lt;item&gt;Experts credit much of the progress to a surge in battery energy storage systems in recent years.&lt;/item&gt;
      &lt;item&gt;Battery storage in California has grown more than 3,000% since 2020.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;For decades, rolling blackouts and urgent calls for energy conservation were part of life in California — a reluctant summer ritual almost as reliable as the heat waves that drove them. But the state has undergone a quiet shift in recent years, and the California Independent System Operator hasn’t issued a single one of those emergency pleas, known as Flex Alerts, since 2022.&lt;/p&gt;
    &lt;p&gt;Experts and officials say the Golden State has reached a turning point, reflecting years of investment in making its electrical grid stronger, cleaner and more dependable. Much of that is new battery energy storage, which captures and stores electricity for later use.&lt;/p&gt;
    &lt;p&gt;In fact, batteries have been transformative for California, state officials say. In late afternoon, when the sun stops hitting solar panels and people are home using electricity, batteries now push stored solar energy onto the grid.&lt;/p&gt;
    &lt;p&gt;California has invested heavily in the technology, helping it mature and get cheaper in recent years. Battery storage in the state has grown more than 3,000% in six years — from 500 megawatts in 2020 to more than 15,700 megawatts today.&lt;/p&gt;
    &lt;p&gt;“There is no question that the battery fleet that has grown rapidly since 2020, along with the state’s expanding portfolio of other supply and demand-side resources, has been a real game changer for reliability during summer periods of peak demand,” said Elliot Mainzer, CAISO’s president and chief executive.&lt;/p&gt;
    &lt;p&gt;It was only five years ago that a record-shattering heat wave pushed the grid to its limit and plunged much of the state into darkness. In the wake of that event, California’s energy leaders vowed to take action to make the grid more resilient.&lt;/p&gt;
    &lt;p&gt;Since then, CAISO has overseen a massive build-out of new energy and storage resources, including more than 26,000 megawatts of new capacity overall, which has also helped make the grid more stable, Mainzer said. The state hasn’t seen rolling blackouts since 2020.&lt;/p&gt;
    &lt;p&gt;“Extreme weather events, wildfires and other emergencies can pose reliability challenges for any bulk electric system,” he said. “But the CAISO battery fleet, along with the additional capacity and close coordination with state and regional partners, have provided an indisputable benefit to reliability.”&lt;/p&gt;
    &lt;p&gt;An immense solar-plus-storage power plant in the desert is now pumping out inexpensive clean electricity at full bore.&lt;/p&gt;
    &lt;p&gt;Batteries are now key to California’s climate goals, including its mandate of 100% carbon neutrality by 2045.&lt;/p&gt;
    &lt;p&gt;Already, batteries have enabled the grid to operate with dramatic decreases in the use of planet-warming fossil fuels. Now they’re becoming a more cost-effective and reliable replacement for aging gas-fired power plants, according to Maia Leroy, founder of the California energy consulting firm Lumenergy LLC and co-author of a recent report on the rise of battery storage over gas generation in California.&lt;/p&gt;
    &lt;p&gt;“Historically, Flex Alerts have always come through in summertime when it’s super hot and everyone is cranking their AC,” Leroy said. “But also in the summertime, we’re seeing that gas plants underperform because combustion doesn’t work well with ambient heat. So when we’re able to shift that need from having to use gas plants to something more stable, dispatchable and flexible like battery storage, then we’re able to meet that demand in the summer without having to rely on those underperforming gas plants.”&lt;/p&gt;
    &lt;p&gt;Battery energy storage is not without challenges, however. Lithium-ion batteries — the most common type used for energy storage — typically have about four to six hours of capacity. It’s enough to support the grid during peak hours as the sun sets, but can still leave some gaps to be filled by natural gas.&lt;/p&gt;
    &lt;p&gt;Nikhil Kumar, program director with the energy policy nonprofit GridLab, said the technology already exists for longer-duration batteries, including through different chemistries such as iron-air batteries, which release energy through oxidation, and flow batteries, which store energy in liquid chemicals that flow through a reactor.&lt;/p&gt;
    &lt;p&gt;Those batteries are not yet as mature and can be more expensive and larger than their lithium-ion counterparts, Kumar said. But a recent GridLab report indicates that equation is changing, with the average cost of a new gas plant often on par with four-hour lithium-ion batteries and only slightly less expensive than longer-duration battery technologies.&lt;/p&gt;
    &lt;p&gt;“Batteries are going to get cheaper,” Kumar said. “Gas isn’t.”&lt;/p&gt;
    &lt;p&gt;The Trump administration said it will open 13 million acres of federal lands for coal mining and provide $625 million to recommission or modernize coal-fired power plants.&lt;/p&gt;
    &lt;p&gt;The battery storage shift is occurring as the Trump administration takes steps to stifle solar and other forms of renewable energy in favor of fossil fuels such as oil, gas and coal. At the end of September, the administration announced that it would open 13 million acres of federal lands for coal mining and provide $625 million to recommission or modernize coal-fired powered plants, which officials said would help strengthen the economy, protect jobs and advance American energy.&lt;/p&gt;
    &lt;p&gt;During an hourlong news conference on the initiative, Interior Secretary Doug Burgum described wind and solar energy as intermittent sources that are “literally dependent on the weather” — but neither he nor any other official mentioned the growth of battery storage that has made those sources more reliable and more promising.&lt;/p&gt;
    &lt;p&gt;It’s not a partisan issue. ERCOT, which operates Texas’ electrical grid, has more than 14,000 megawatts of batteries online, a nearly threefold increase from early 2023. California and Texas are constantly trading places as the top state for battery storage.&lt;/p&gt;
    &lt;p&gt;But Trump has made moves to support the production of batteries in the U.S. Currently, about three-quarters of the world’s batteries are made in China, and Trump’s tariffs — including a proposed 100% tariff on China — have been good for at least one Sacramento-based battery manufacturer, Sparkz.&lt;/p&gt;
    &lt;p&gt;“The administration wants critical material manufacturing to happen in the U.S.,” said Sanjiv Malhotra, founder and chief executive. “They basically are very much in favor of domestic manufacturing of batteries.”&lt;/p&gt;
    &lt;p&gt;Sparkz is making lithium-iron batteries that don’t use nickel and cobalt — a composition that has long been an industry darling but that depends on imported metals. Instead, their lithium-iron-phosphate batteries have a supply chain that is entirely based in the U.S., which means they can take advantage of federal tax credits that favor the production of clean energy components made mostly of domestic parts, Malhotra said. The company’s clients include data centers and utilities.&lt;/p&gt;
    &lt;p&gt;Malhotra added that California has done an excellent job “beefing up” the grid’s storage capacity in the last few years. He said batteries are a major reason why the state hasn’t seen a Flex Alert since 2022.&lt;/p&gt;
    &lt;p&gt;“The numbers basically tell the story that it was all because of, essentially, energy storage,” he said.&lt;/p&gt;
    &lt;p&gt;There is still work to do. While the state’s grid has seen improvements, it is more than a century old and was built primarily for gas plants. Experts and officials agree that it needs additional substantial upgrades and reforms to meet current energy demands and goals.&lt;/p&gt;
    &lt;p&gt;Permitting is also a hurdle, as California typically requires lengthy environmental review for new projects. The state, sometimes controversially, is now speeding review, and recently approved a massive solar and battery storage farm, the Darden Clean Energy Project in Fresno County, through a new fast-track permitting program. It will make enough electricity to power 850,000 homes for four hours, according to the California Energy Commission.&lt;/p&gt;
    &lt;p&gt;A plume of material released from the plant contained hydroflouride, a toxic gas, that is now being monitored by Monterey County.&lt;/p&gt;
    &lt;p&gt;Safety remains a considerable concern. In January, a fire tore through one of the world’s largest battery storage facilities in Moss Landing, Monterey County. The facility housed around 100,000 lithium-ion batteries, which are exceptionally dangerous when ignited because they burn extremely hot and cannot be extinguished with water, which can trigger a violent chemical reaction. The blaze emitted dangerous levels of nickel, cobalt and manganese that were measured within miles of the site.&lt;/p&gt;
    &lt;p&gt;“When you’re dealing with large technologies in general, there’s always going to be some kind of danger,” said Leroy, of Lumenergy. “This points to the big need for diversifying the technologies that we use.”&lt;/p&gt;
    &lt;p&gt;Other forms of energy, such as oil and coal, also pose considerable health and safety risks including the emission of air pollution — soot, mercury, nitrogen dioxide and carbon dioxide contributing to climate change.&lt;/p&gt;
    &lt;p&gt;California is in the process of eliminating coal power and expects to be completely coal-free by November. And while natural gas still makes up a large piece of the state’s portfolio, renewables represented nearly 60% of California’s in-state electricity generation in 2024, according to the U.S. Energy Information Administration.&lt;/p&gt;
    &lt;p&gt;The numbers continue to trend upward. In the first six months of this year, CAISO’s grid was powered by 100% clean energy for an average of almost seven hours each day.&lt;/p&gt;
    &lt;p&gt;“We have literally just demonstrated that California is able to run with super clean resources, with backups from natural gas,” said Kumar, of GridLab. “And it works. We don’t have Flex Alerts.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.latimes.com/environment/story/2025-10-17/california-made-it-through-another-summer-without-a-flex-alert"/><published>2025-10-25T19:58:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706534</id><title>ProEnergy repurposes jet engines to power data centers</title><updated>2025-10-25T23:32:28.195005+00:00</updated><content/><link href="https://www.datacenterdynamics.com/en/news/proenergy-offers-repurposed-jet-engines-to-data-cent/"/><published>2025-10-25T19:59:32+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706545</id><title>Torchcomms: A modern PyTorch communications API</title><updated>2025-10-25T23:32:28.060111+00:00</updated><content>&lt;doc fingerprint="6d0ad4f949951ce4"&gt;
  &lt;main&gt;
    &lt;head rend="h2"&gt;Introduction&lt;/head&gt;
    &lt;p&gt;Torchcomms is a new experimental, lightweight communication API intended for use with PyTorch Distributed (PTD). In addition to the core API, we are open-sourcing NCCLX, a new backend we developed to scale to over 100,000 GPUs.&lt;/p&gt;
    &lt;p&gt;With our first release of torchcomms, we’re delivering the foundational APIs and backends required for large-scale model training in PyTorch. This initial release focuses on core communication primitives that enable reliable and performant distributed training at scale. Over the next year, we’ll continue to mature the offering—introducing features that make it easier to prototype new collectives, scale seamlessly with built-in fault tolerance, and optimize device-centric communication patterns. Our roadmap is focused on empowering researchers and developers to move faster, test new ideas at scale, and build the next generation of large-scale AI systems.&lt;/p&gt;
    &lt;p&gt;Torchcomms is our first step toward proving out new communication paradigms at scale. To accelerate innovation, we’re developing the API fully in the open, inviting community feedback as it evolves. Because of this open development process, the API is still early and may undergo breaking changes as it matures. Over time, torchcomms will serve as a proving ground for next-generation distributed technologies, with the long-term goal of migrating all PyTorch Distributed functionality onto this new foundation. As torchcomms stabilizes, it will become the backbone of scalable, fault-tolerant, and device-centric distributed training in PyTorch.&lt;/p&gt;
    &lt;head rend="h3"&gt;Project Goals&lt;/head&gt;
    &lt;p&gt;With torchcomms, we’re laying the groundwork for the next generation of distributed communication in PyTorch. Our goal is to build a flexible, extensible foundation that enables developers and researchers to move faster, scale further, and target a wider variety of hardware. Specifically, we’re working toward the following objectives:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Fast Prototyping of Communication Primitives – Machine learning researchers need to experiment rapidly with new communication paradigms. By decoupling communications from PyTorch’s core numeric primitives, torchcomms makes it possible to iterate on communication layers independently—adding new collectives, APIs, or backends without breaking existing functionality. This design also enables out-of-tree backends, allowing researchers and hardware vendors to easily integrate specialized communication stacks tailored to their devices and features.&lt;/item&gt;
      &lt;item&gt;Scaling to 100K+ GPUs – Scaling modern training workloads to hundreds of thousands of GPUs requires rethinking how communication resources are managed. Current approaches, such as lazy initialization and limited concurrency semantics for point-to-point operations, constrain scalability within libraries like NCCL. Torchcomms introduces eager initialization (where backend resources are explicitly managed by the user) and model-specific hints to optimize how communicators, NVLink buffers, and RoCE resources are allocated and shared—paving the way for truly massive distributed jobs.&lt;/item&gt;
      &lt;item&gt;Heterogeneous Hardware Support – Existing collective backends are typically optimized for a single vendor or hardware family. With torchcomms, we’re designing for heterogeneous systems from the ground up—enabling mixed deployments that span multiple hardware generations and vendors within a single training job. This flexibility is critical as the ecosystem evolves beyond homogeneous GPU clusters.&lt;/item&gt;
      &lt;item&gt;Fault Tolerance at Scale – Today’s open-source PyTorch Distributed lacks robust fault-tolerant process groups, which limits the reliability of higher-level libraries like torchft. Torchcomms aims to close that gap by open-sourcing a fault-tolerant backend capable of supporting algorithms such as fault-tolerant HSDP and fault-tolerant Streaming DiLoCo at scale—delivering resilience without compromising performance.&lt;/item&gt;
      &lt;item&gt;One-Sided Communication – One-sided communication (e.g., RDMA-style semantics) is increasingly essential for asynchronous workflows in reinforcement learning, checkpointing, and large language models. Torchcomms will provide first-class support for one-sided communication, enabling efficient, low-overhead message passing and data exchange between distributed processes.&lt;/item&gt;
      &lt;item&gt;Device-Centric Collectives – To achieve ultra-low latency for inference and training, communication and computation must be tightly coupled. Torchcomms is developing device-centric collective APIs, which enable communication metadata and logic to live directly on the device (e.g. the GPU). This includes both direct RDMA operations from the GPU (e.g., IBGDA) and CPU proxy-based designs. These capabilities allow developers to fuse compute and communication operations seamlessly, unlocking new levels of performance.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Why a new API?&lt;/head&gt;
    &lt;p&gt;A common question we hear is: “Why a new API?”&lt;/p&gt;
    &lt;p&gt;With torchcomms, we’re pursuing a set of ambitious goals—introducing capabilities that don’t yet exist in any other communication library today. To move quickly, we need the freedom to iterate in the open and evolve the design without being constrained by existing interfaces. This means that, during its early stages, the API may experience breaking changes as we experiment and refine it in collaboration with the community.&lt;/p&gt;
    &lt;p&gt;The existing c10d APIs in PyTorch Distributed carry significant technical debt, making them difficult to extend or modernize. As the torchcomms API stabilizes, we plan to deprecate the old c10d::Backend interface and adopt torchcomms as the underlying implementation for PyTorch Distributed. This transition will be done gradually and with minimal disruption—most users and models will continue to work as they do today, while automatically benefiting from the performance, scalability, and flexibility of the new backends.&lt;/p&gt;
    &lt;head rend="h2"&gt;Quickstart&lt;/head&gt;
    &lt;p&gt;First, see the Installation instructions for how to install torchcomms.&lt;/p&gt;
    &lt;p&gt;For more documentation, check out: https://meta-pytorch.org/torchcomms/&lt;/p&gt;
    &lt;head rend="h3"&gt;Basic Usage&lt;/head&gt;
    &lt;p&gt;Torchcomms is a lightweight wrapper around the underlying backends and communicators. The core APIs map directly to the backend methods and are designed as a fully object-oriented API.&lt;/p&gt;
    &lt;quote&gt;import torchcomms # Eagerly initialize a communicator using MASTER_PORT/MASTER_ADDR/RANK/WORLD_SIZE environment variables provided by torchrun. # This communicator is bound to a single device. comm = torchcomms.new_comm("ncclx", torch.device("cuda"), name="my_comm") print(f"I am rank {comm.get_rank()} of {comm.get_size()}!") t = torch.full((10, 20), value=comm.rank, dtype=torch.float) # run an all_reduce on the current stream comm.allreduce(t, torchcomms.ReduceOp.SUM, async_op=False) # run an all_reduce on the background stream work = comm.allreduce(t, torchcomms.ReduceOp.SUM, async_op=True) work.wait() # split a communicator into groups of 8 split_groups = torch.arange(comm.get_size()).view(-1, 8).tolist() tp_comm = comm.split(split_groups)&lt;/quote&gt;
    &lt;head rend="h2"&gt;DeviceMesh&lt;/head&gt;
    &lt;p&gt;Torchcomms also supports compatibility with DeviceMesh for compatibility with PyTorch parallelism libraries such as FSDP2.&lt;/p&gt;
    &lt;quote&gt;import torchcomms from torchcomms.device_mesh import init_device_mesh from torch.distributed.fsdp import fully_shard comm = torchcomms.new_comm("ncclx", torch.device("cuda:0"), name="global") mesh = init_device_mesh( mesh_dim_comms=(comm,), mesh_dim_names=("global",), ) fully_shard(model, device_mesh=mesh)&lt;/quote&gt;
    &lt;head rend="h2"&gt;Initial Backends&lt;/head&gt;
    &lt;p&gt;Along with the new torchcomms APIs, we have released several backends for a variety of hardware platforms.&lt;/p&gt;
    &lt;head rend="h3"&gt;NCCLX&lt;/head&gt;
    &lt;p&gt;NCCLX contains the Meta extension to the popular NCCL library. NCCLX is production-tested – it is used for large scale training and inference for large language models (LLMs) such as Llama3 and Llama4. Today, all of Meta’s generative AI services are backed by NCCLX. Some key features of NCCLX include:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Scalable initialization&lt;/item&gt;
      &lt;item&gt;Zero-copy and SM-free communication&lt;/item&gt;
      &lt;item&gt;Custom collective algorithms&lt;/item&gt;
      &lt;item&gt;Network traffic load balancing&lt;/item&gt;
      &lt;item&gt;One-sided communication&lt;/item&gt;
      &lt;item&gt;GPU-resident and low latency collectives&lt;/item&gt;
      &lt;item&gt;Fault analyzer and localization&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;In parallel with the upstream NCCL, we have developed a separate Custom Transport (CTran) stack to host these Meta in-house optimizations and custom features. CTran contains NVLink, IB/RoCE and TCP transports to support lower-level communication primitives via different hardware routines and build communication algorithms for various communication semantics (e.g., collectives, point-to-point, RMA) over the transports.&lt;/p&gt;
    &lt;p&gt;Both NCCLX and CTran are open sourced today, along with torchcomms. We will discuss more details of NCCLX/CTran in a white paper later this week.&lt;/p&gt;
    &lt;head rend="h3"&gt;NCCL and RCCL&lt;/head&gt;
    &lt;p&gt;In addition to NCCLX, torchcomms also supports upstream NCCL. Current PyTorch Distributed NCCL users can try out torchcomms easily without changing the underlying communication library setup.&lt;/p&gt;
    &lt;p&gt;The AMD RCCL support in the current PyTorch Distributed is through the NCCL process group. As part of torchcomms release, we have also included a native RCCL backend. This allows torchcomms to provide native multi-vendor GPU support from Day 1. It allows different libraries to evolve more independently.&lt;/p&gt;
    &lt;head rend="h3"&gt;Gloo&lt;/head&gt;
    &lt;p&gt;You may know of Gloo as the backend you use when you need to transfer CPU metadata between machines or for tests. That is the main use case but it also has some new advanced features such as infiniBand and one sided operations. We recently also added a new “lazy init” mode that allows Gloo to scale to 100k or more workers.&lt;/p&gt;
    &lt;head rend="h2"&gt;Composability: torchtitan&lt;/head&gt;
    &lt;p&gt;We’ve demonstrated compatibility and correctness of the new torchcomms API by integrating it in with torchtitan. This uses the device mesh integration to provide compatibility with the existing PyTorch technologies, such as FSDP2 and tensor parallelism.&lt;/p&gt;
    &lt;p&gt;Link to torchtitan integration, the integration code will be under path: torchtitan/experiments/torchcomms/.&lt;/p&gt;
    &lt;p&gt;Link to torchtitan loss/performance curves: (with FSDP2)&lt;/p&gt;
    &lt;head rend="h2"&gt;New APIs&lt;/head&gt;
    &lt;head rend="h3"&gt;Collective Semantic Changes&lt;/head&gt;
    &lt;p&gt;We’ve made a number of changes to the existing collectives that were inherited from the existing PyTorch Distributed APIs. These are intended to make the high level semantics better match the underlying device semantics and to improve flexibility.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;All operations are done through object oriented APIs rather than using the global dist.* APIs.&lt;/item&gt;
      &lt;item&gt;Each torchcomm.TorchComm object maps to a single device and communicator.&lt;/item&gt;
      &lt;item&gt;Backends are eagerly initiated and require a device to be passed in at creation time.&lt;/item&gt;
      &lt;item&gt;All operations use the communicator ranks rather than “global” ranks.&lt;/item&gt;
      &lt;item&gt;All operations execute in order they were issued and concurrent operations must be run using the batch API.&lt;/item&gt;
      &lt;item&gt;send/recvs do not execute concurrently unless issued via the batch API.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Window APIs&lt;/head&gt;
    &lt;p&gt;We’re adding support for window APIs to allow for dynamic put/get operations on remote memory. For certain use cases including checkpointing, async operations this can be significantly more performant and easier to express since only one side needs to be involved unlike traditional collectives.&lt;lb/&gt; The window APIs enable users to create a memory buffer—either in GPU or CPU memory—across different ranks. Once created, the buffer is automatically registered and can be accessed via the provided Put and Get APIs, leveraging the underlying RDMA or NVL transport for zero-copy, one-sided communication. Additionally, the window APIs offer an atomic signaling mechanism, further enhancing asynchronous communication capabilities.&lt;/p&gt;
    &lt;p&gt;The window APIs are under active development and still experimental.&lt;/p&gt;
    &lt;head rend="h3"&gt;Transport APIs&lt;/head&gt;
    &lt;p&gt;We’re adding transport APIs that allow for doing point to point operations using the underlying transport directly. This provides a similar API to window APIs but not tied to a collective library. Initially we’re providing support just for RDMA over a dedicated Network which is intended for use in RPC like operations. This is internally supported by the IB backend in CTran.&lt;/p&gt;
    &lt;p&gt;The RdmaTransport provides a write API that allows users to directly write into the remote memory. Users would need to register the memory and exchange its handle between processes to facilitate the write. This is effectively a zero copy data transfer, and can be done for a CPU or GPU memory in a zero copy fashion. These APIs are only transport APIs and do no compute (no reduce, etc).&lt;/p&gt;
    &lt;p&gt;The transport APIs are under active development and are still experimental.&lt;/p&gt;
    &lt;head rend="h3"&gt;Fault Tolerance APIs&lt;/head&gt;
    &lt;p&gt;We’re working on creating a new backend that provides fault tolerant collectives. This new backend is built entirely on the CTran transport and provides failure detection, timeouts, error recovery and safe reconfiguration after errors.&lt;/p&gt;
    &lt;head rend="h2"&gt;Extensibility&lt;/head&gt;
    &lt;head rend="h3"&gt;Extending Backends with New Collectives&lt;/head&gt;
    &lt;p&gt;Torchcomms is designed to support direct access to the underlying backends. This allows for fast prototyping of new APIs before we standardize them and add them to the shared backend interface.&lt;/p&gt;
    &lt;p&gt;Here’s an example of adding a new custom operation:&lt;/p&gt;
    &lt;quote&gt;class TorchCommMyBackend : public TorchCommBackend { public: std::shared_ptr&amp;lt;TorchWork&amp;gt; quantized_all_reduce( at::Tensor&amp;amp; tensor, ReduceOp op, bool async_op) { // your implementation } }; PYBIND11_MODULE(_comms_my_backend, m) { py::class_&amp;lt;TorchCommMyBackend, std::shared_ptr&amp;lt;TorchCommMyBackend&amp;gt;&amp;gt;( m, "TorchCommMyBackend") .def( "quantized_all_reduce", &amp;amp;TorchCommMyBackend::quantized_all_reduce, py::call_guard&amp;lt;py::gil_scoped_release&amp;gt;()); }&lt;/quote&gt;
    &lt;p&gt;To use in your model, it’s as easy as calling&lt;code&gt;unsafe_get_backend()&lt;/code&gt;and calling the new method.&lt;/p&gt;
    &lt;quote&gt;import torchcomms comm = torchcomms.new_comm("my_backend") backend = comm.unsafe_get_backend() backend.quantized_all_reduce(t, ReduceOp.SUM, async_op=False)&lt;/quote&gt;
    &lt;p&gt;Once prototyping is done, we’re happy to upstream new operations into the standard torchcomms API.&lt;/p&gt;
    &lt;head rend="h3"&gt;Writing a new torchcomm Backend&lt;/head&gt;
    &lt;p&gt;One of the key features of torchcomms is that it makes it much easier to write third-party backends. These backends no longer need to be built as part of PyTorch and can be simply installed like any other Python extension using pip.&lt;/p&gt;
    &lt;p&gt;To write a new backend you need to implement the TorchCommBackend interface: https://github.com/meta-pytorch/torchcomms/blob/main/comms/torchcomms/TorchCommBackend.hpp&lt;/p&gt;
    &lt;quote&gt;// MyBackend.hpp class MyBackend : public TorchCommBackend { public: ... }; // MyBackend.cpp namespace { class MyBackendRegistration { public: MyBackendRegistration() { TorchCommFactory::get().register_backend( "my_backend", []() { return std::make_shared&amp;lt;MyBackend&amp;gt;(); }); } }; static MyBackendRegistration registration{}; } // MyBackendPy.cpp PYBIND11_MODULE(_comms_my_backend, m) { py::class_&amp;lt;MyBackend, std::shared_ptr&amp;lt;MyBackend&amp;gt;&amp;gt;(m, "MyBackend"); }&lt;/quote&gt;
    &lt;p&gt;Once you have your Python C extension building you then just need to add some metadata to the setup.py so torchcomms can find it.&lt;/p&gt;
    &lt;quote&gt;setup( name="my_backend", entry_points={ "torchcomms.backends": [ "my_backend = my_backend._comms_my_backend", ] }, )&lt;/quote&gt;
    &lt;p&gt;Then you can use it like any other backend after you &lt;code&gt;pip install&lt;/code&gt;it.&lt;/p&gt;
    &lt;quote&gt;import torchcomms comm = torchcomms.new_comm("my_backend", ...)&lt;/quote&gt;
    &lt;head rend="h1"&gt;Next Steps&lt;/head&gt;
    &lt;p&gt;Torchcomms is a brand new API and is very much under active development. We’d love for you to get involved so please reach out if you’re interested in using it or want to help improve it.&lt;/p&gt;
    &lt;p&gt;We’re actively working on the features described in this blog post and hope to have them stabilized in the near future as well as improving hardware support for more devices.&lt;/p&gt;
    &lt;p&gt;For more documentation check out: https://meta-pytorch.org/torchcomms/&lt;/p&gt;
    &lt;head rend="h2"&gt;Acknowledgements&lt;/head&gt;
    &lt;p&gt;We would like to acknowledge the contributions of many current and former Meta employees who have played a crucial role in developing torchcomms and torchcomms-backends for large-scale training and inference in production. In particular, we would like to extend special thanks to Tristan Rice, Pavan Balaji, Subodh Iyengar, Qiye Tan, Rodrigo De Castro, Sudharssun Subramanian, Junjie Wang, Feng Tian, Saif Hasan, Min Si, Yifan Mao, Dingming Wu, Zhaoyang Han, Blake Matheny, Art Zhu, Denis Boyda, Regina Ren, Jingyi Yang, Bingzhe Liu, Shuqiang Zhang, Mingran Yang, Cen Zhao, Adi Gangidi, Ashmitha Jeevaraj Shetty, Bruce Wu, Ching-Hsiang Chu, Yulun Wang, Srinivas Vaidyanathan, Chris Gottbrath, Davide Italiano, Shashi Gandham, Omar Baldonado, James Hongyi Zeng&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pytorch.org/blog/torchcomms/"/><published>2025-10-25T20:00:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706624</id><title>In memory of the Christmas Island shrew</title><updated>2025-10-25T23:32:27.845816+00:00</updated><content>&lt;doc fingerprint="9773118fc882821f"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Once abundant on Christmas Island, the tiny, five-gram shrew (Crocidura trichura) filled the night forest with its high, thin cry before vanishing into silence.&lt;/item&gt;
      &lt;item&gt;Introduced black rats and their parasites decimated the island’s native mammals, and by 1908 the shrew was thought extinct, its memory confined to museum drawers and field notes.&lt;/item&gt;
      &lt;item&gt;Brief rediscoveries in 1958 and 1984 brought fleeting hope, but the last known individuals died in captivity, and no others have been found despite decades of searching.&lt;/item&gt;
      &lt;item&gt;Its loss, now made official, adds to Australia’s grim record of extinctions—a quiet reminder of fragile lives erased by invasion, neglect, and the noise of human expansion.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It never weighed more than a spoonful of sugar. Five or six grams of life, soft-furred and sharp-nosed, darting among the roots and leaf litter of a tiny island in the Indian Ocean. At night, its voice—a thin, high cry, part bat and part whisper—once filled the forest of Christmas Island. Now the forest is silent. Australia’s only shrew, Crocidura trichura, has been declared extinct.&lt;/p&gt;
    &lt;p&gt;Few knew it lived, fewer still that it was Australian. The shrew was a stranger in a land of pouched mammals, a migrant that arrived tens of thousands of years ago, likely clinging to a raft of vegetation from what is now Indonesia. On this isolated outpost, it built a quiet lineage of survivors. When British naturalists arrived in the 1890s, they found the forest alive with its shrill chatter. “Extremely common,” they wrote. And then, almost at once, it vanished.&lt;/p&gt;
    &lt;p&gt;The black rats came first, stowaways in bales of hay. With them came a parasite, Trypanosoma lewisi, that swept through the island’s naïve mammals like a plague. Within years, both native rats were gone. By 1908, the shrew was presumed lost too. Its name lingered only in museum drawers and in the footnotes of field reports.&lt;/p&gt;
    &lt;p&gt;Yet it was not quite gone. Half a century later, in 1958, two shrews appeared as bulldozers tore into the forest for phosphate mining. They were seen, released, and forgotten. Then, in 1984, came a miracle: a live female, found in a clump of fern by biologists clearing a path. For more than a year, she lived in a terrarium, fed on grasshoppers and care. A few months later, a male was caught. The world briefly held its breath for a reunion that might save a species. But the male, sickly and short-tempered, died within weeks. The female lingered alone until she, too, was gone.&lt;/p&gt;
    &lt;p&gt;No others were ever found. Searches in the following decades brought only silence—the kind of silence that deepens until it becomes its own proof. When scientists dissected hundreds of feral cats on the island, not a trace of shrew remained in their stomachs. The Red List, in its latest revision, made official what many already knew in their hearts: Crocidura trichura was no more.&lt;/p&gt;
    &lt;p&gt;To some, the loss of a creature so small may seem inconsequential. Yet its passing adds one more mark to Australia’s lamentable record—the thirty-ninth mammal species lost since colonization, more than any other country on Earth. The shrew’s absence is a story repeated across islands: an ancient ecosystem undone by the carelessness of arrival, by rats and cats, ants and snakes, by the unthinking traffic of an expanding world.&lt;/p&gt;
    &lt;p&gt;The Christmas Island shrew had survived what many thought impossible. For decades, it persisted unseen—a shadow among roots, defying extinction. It was officially rediscovered, officially lost, and then, improbably, rediscovered again. It endured eighty years of disappearance before the recorders caught up. That endurance was its last act of defiance.&lt;/p&gt;
    &lt;p&gt;In life, it asked for little: a patch of soil, a few beetles, a quiet forest. In death, it leaves questions that are larger than itself. How many other lives flicker out unseen before the world even learns their names? How many others wait somewhere in the darkness, unseen but breathing still?&lt;/p&gt;
    &lt;p&gt;There is always a chance—slim but not zero—that the shrew endures yet, hidden in the damp heart of Christmas Island, trembling but alive. Hope, after all, has a long history of outliving the species it mourns. But the forest is quieter now. And if this really is the end, the last of Australia’s shrews will have gone as it lived—small, secret, and almost entirely unnoticed, save for those who loved it enough to listen for its cry.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://news.mongabay.com/2025/10/in-memory-of-the-christmas-island-shrew/"/><published>2025-10-25T20:13:55+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706660</id><title>Load-time relocation of shared libraries (2011)</title><updated>2025-10-25T23:32:27.446091+00:00</updated><content>&lt;doc fingerprint="2f8599532e059648"&gt;
  &lt;main&gt;
    &lt;p&gt;This article's aim is to explain how a modern operating system makes it possible to use shared libraries with load-time relocation. It focuses on the Linux OS running on 32-bit x86, but the general principles apply to other OSes and CPUs as well.&lt;/p&gt;
    &lt;p&gt;Note that shared libraries have many names - shared libraries, shared objects, dynamic shared objects (DSOs), dynamically linked libraries (DLLs - if you're coming from a Windows background). For the sake of consistency, I will try to just use the name "shared library" throughout this article.&lt;/p&gt;
    &lt;head rend="h3"&gt;Loading executables&lt;/head&gt;
    &lt;p&gt;Linux, similarly to other OSes with virtual memory support, loads executables to a fixed memory address. If we examine the ELF header of some random executable, we'll see an Entry point address:&lt;/p&gt;
    &lt;code&gt;$ readelf -h /usr/bin/uptime
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF32
  [...] some header fields
  Entry point address:               0x8048470
  [...] some header fields
&lt;/code&gt;
    &lt;p&gt;This is placed by the linker to tell the OS where to start executing the executable's code [1]. And indeed if we then load the executable with GDB and examine the address 0x8048470, we'll see the first instructions of the executable's .text segment there.&lt;/p&gt;
    &lt;p&gt;What this means is that the linker, when linking the executable, can fully resolve all internal symbol references (to functions and data) to fixed and final locations. The linker does some relocations of its own [2], but eventually the output it produces contains no additional relocations.&lt;/p&gt;
    &lt;p&gt;Or does it? Note that I emphasized the word internal in the previous paragraph. As long as the executable needs no shared libraries [3], it needs no relocations. But if it does use shared libraries (as do the vast majority of Linux applications), symbols taken from these shared libraries need to be relocated, because of how shared libraries are loaded.&lt;/p&gt;
    &lt;head rend="h3"&gt;Load-time relocation in action&lt;/head&gt;
    &lt;p&gt;To see the load-time relocation in action, I will use our shared library from a simple driver executable. When running this executable, the OS will load the shared library and relocate it appropriately.&lt;/p&gt;
    &lt;p&gt;Curiously, due to the address space layout randomization feature which is enabled in Linux, relocation is relatively difficult to follow, because every time I run the executable, the libmlreloc.so shared library gets placed in a different virtual memory address [9].&lt;/p&gt;
    &lt;p&gt;This is a rather weak deterrent, however. There is a way to make sense in it all. But first, let's talk about the segments our shared library consists of:&lt;/p&gt;
    &lt;code&gt;$ readelf --segments libmlreloc.so

Elf file type is DYN (Shared object file)
Entry point 0x3b0
There are 6 program headers, starting at offset 52

Program Headers:
  Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
  LOAD           0x000000 0x00000000 0x00000000 0x004e8 0x004e8 R E 0x1000
  LOAD           0x000f04 0x00001f04 0x00001f04 0x0010c 0x00114 RW  0x1000
  DYNAMIC        0x000f18 0x00001f18 0x00001f18 0x000d0 0x000d0 RW  0x4
  NOTE           0x0000f4 0x000000f4 0x000000f4 0x00024 0x00024 R   0x4
  GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RW  0x4
  GNU_RELRO      0x000f04 0x00001f04 0x00001f04 0x000fc 0x000fc R   0x1

 Section to Segment mapping:
  Segment Sections...
   00     .note.gnu.build-id .hash .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .plt .text .fini .eh_frame
   01     .ctors .dtors .jcr .dynamic .got .got.plt .data .bss
   02     .dynamic
   03     .note.gnu.build-id
   04
   05     .ctors .dtors .jcr .dynamic .got
&lt;/code&gt;
    &lt;p&gt;To follow the myglob symbol, we're interested in the second segment listed here. Note a couple of things:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;In the section to segment mapping in the bottom, segment 01 is said to contain the .data section, which is the home of myglob&lt;/item&gt;
      &lt;item&gt;The VirtAddr column specifies that the second segment starts at 0x1f04 and has size 0x10c, meaning that it extends until 0x2010 and thus contains myglob which is at 0x200C.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Now let's use a nice tool Linux gives us to examine the load-time linking process - the dl_iterate_phdr function, which allows an application to inquire at runtime which shared libraries it has loaded, and more importantly - take a peek at their program headers.&lt;/p&gt;
    &lt;p&gt;So I'm going to write the following code into driver.c:&lt;/p&gt;
    &lt;code&gt;#define _GNU_SOURCE
#include &amp;lt;link.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;


static int header_handler(struct dl_phdr_info* info, size_t size, void* data)
{
    printf("name=%s (%d segments) address=%p\n",
            info-&amp;gt;dlpi_name, info-&amp;gt;dlpi_phnum, (void*)info-&amp;gt;dlpi_addr);
    for (int j = 0; j &amp;lt; info-&amp;gt;dlpi_phnum; j++) {
         printf("\t\t header %2d: address=%10p\n", j,
             (void*) (info-&amp;gt;dlpi_addr + info-&amp;gt;dlpi_phdr[j].p_vaddr));
         printf("\t\t\t type=%u, flags=0x%X\n",
                 info-&amp;gt;dlpi_phdr[j].p_type, info-&amp;gt;dlpi_phdr[j].p_flags);
    }
    printf("\n");
    return 0;
}


extern int ml_func(int, int);


int main(int argc, const char* argv[])
{
    dl_iterate_phdr(header_handler, NULL);

    int t = ml_func(argc, argc);
    return t;
}
&lt;/code&gt;
    &lt;p&gt;header_handler implements the callback for dl_iterate_phdr. It will get called for all libraries and report their names and load addresses, along with all their segments. It also invokes ml_func, which is taken from the libmlreloc.so shared library.&lt;/p&gt;
    &lt;p&gt;To compile and link this driver with our shared library, run:&lt;/p&gt;
    &lt;code&gt;gcc -g -c driver.c -o driver.o
gcc -o driver driver.o -L. -lmlreloc
&lt;/code&gt;
    &lt;p&gt;Running the driver stand-alone we get the information, but for each run the addresses are different. So what I'm going to do is run it under gdb [10], see what it says, and then use gdb to further query the process's memory space:&lt;/p&gt;
    &lt;code&gt; $ gdb -q driver
 Reading symbols from driver...done.
 (gdb) b driver.c:31
 Breakpoint 1 at 0x804869e: file driver.c, line 31.
 (gdb) r
 Starting program: driver
 [...] skipping output
 name=./libmlreloc.so (6 segments) address=0x12e000
                header  0: address=  0x12e000
                        type=1, flags=0x5
                header  1: address=  0x12ff04
                        type=1, flags=0x6
                header  2: address=  0x12ff18
                        type=2, flags=0x6
                header  3: address=  0x12e0f4
                        type=4, flags=0x4
                header  4: address=  0x12e000
                        type=1685382481, flags=0x6
                header  5: address=  0x12ff04
                        type=1685382482, flags=0x4

[...] skipping output
 Breakpoint 1, main (argc=1, argv=0xbffff3d4) at driver.c:31
 31    }
 (gdb)
&lt;/code&gt;
    &lt;p&gt;Since driver reports all the libraries it loads (even implicitly, like libc or the dynamic loader itself), the output is lengthy and I will just focus on the report about libmlreloc.so. Note that the 6 segments are the same segments reported by readelf, but this time relocated into their final memory locations.&lt;/p&gt;
    &lt;p&gt;Let's do some math. The output says libmlreloc.so was placed in virtual address 0x12e000. We're interested in the second segment, which as we've seen in readelf is at ofset 0x1f04. Indeed, we see in the output it was loaded to address 0x12ff04. And since myglob is at offset 0x200c in the file, we'd expect it to now be at address 0x13000c.&lt;/p&gt;
    &lt;p&gt;So, let's ask GDB:&lt;/p&gt;
    &lt;code&gt;(gdb) p &amp;amp;myglob
$1 = (int *) 0x13000c
&lt;/code&gt;
    &lt;p&gt;Excellent! But what about the code of ml_func which refers to myglob? Let's ask GDB again:&lt;/p&gt;
    &lt;code&gt;(gdb) set disassembly-flavor intel
(gdb) disas ml_func
Dump of assembler code for function ml_func:
   0x0012e46c &amp;lt;+0&amp;gt;:   push   ebp
   0x0012e46d &amp;lt;+1&amp;gt;:   mov    ebp,esp
   0x0012e46f &amp;lt;+3&amp;gt;:   mov    eax,ds:0x13000c
   0x0012e474 &amp;lt;+8&amp;gt;:   add    eax,DWORD PTR [ebp+0x8]
   0x0012e477 &amp;lt;+11&amp;gt;:  mov    ds:0x13000c,eax
   0x0012e47c &amp;lt;+16&amp;gt;:  mov    eax,ds:0x13000c
   0x0012e481 &amp;lt;+21&amp;gt;:  add    eax,DWORD PTR [ebp+0xc]
   0x0012e484 &amp;lt;+24&amp;gt;:  pop    ebp
   0x0012e485 &amp;lt;+25&amp;gt;:  ret
End of assembler dump.
&lt;/code&gt;
    &lt;p&gt;As expected, the real address of myglob was placed in all the mov instructions referring to it, just as the relocation entries specified.&lt;/p&gt;
    &lt;head rend="h3"&gt;Relocating function calls&lt;/head&gt;
    &lt;p&gt;So far this article demonstrated relocation of data references - using the global variable myglob as an example. Another thing that needs to be relocated is code references - in other words, function calls. This section is a brief guide on how this gets done. The pace is much faster than in the rest of this article, since I can now assume the reader understands what relocation is all about.&lt;/p&gt;
    &lt;p&gt;Without further ado, let's get to it. I've modified the code of the shared library to be the following:&lt;/p&gt;
    &lt;code&gt;int myglob = 42;

int ml_util_func(int a)
{
    return a + 1;
}

int ml_func(int a, int b)
{
    int c = b + ml_util_func(a);
    myglob += c;
    return b + myglob;
}
&lt;/code&gt;
    &lt;p&gt;ml_util_func was added and it's being used by ml_func. Here's the disassembly of ml_func in the linked shared library:&lt;/p&gt;
    &lt;code&gt;000004a7 &amp;lt;ml_func&amp;gt;:
 4a7:   55                      push   ebp
 4a8:   89 e5                   mov    ebp,esp
 4aa:   83 ec 14                sub    esp,0x14
 4ad:   8b 45 08                mov    eax,DWORD PTR [ebp+0x8]
 4b0:   89 04 24                mov    DWORD PTR [esp],eax
 4b3:   e8 fc ff ff ff          call   4b4 &amp;lt;ml_func+0xd&amp;gt;
 4b8:   03 45 0c                add    eax,DWORD PTR [ebp+0xc]
 4bb:   89 45 fc                mov    DWORD PTR [ebp-0x4],eax
 4be:   a1 00 00 00 00          mov    eax,ds:0x0
 4c3:   03 45 fc                add    eax,DWORD PTR [ebp-0x4]
 4c6:   a3 00 00 00 00          mov    ds:0x0,eax
 4cb:   a1 00 00 00 00          mov    eax,ds:0x0
 4d0:   03 45 0c                add    eax,DWORD PTR [ebp+0xc]
 4d3:   c9                      leave
 4d4:   c3                      ret
&lt;/code&gt;
    &lt;p&gt;What's interesting here is the instruction at address 0x4b3 - it's the call to ml_util_func. Let's dissect it:&lt;/p&gt;
    &lt;p&gt;e8 is the opcode for call. The argument of this call is the offset relative to the next instruction. In the disassembly above, this argument is 0xfffffffc, or simply -4. So the call currently points to itself. This clearly isn't right - but let's not forget about relocation. Here's what the relocation section of the shared library looks like now:&lt;/p&gt;
    &lt;code&gt;$ readelf -r libmlreloc.so

Relocation section '.rel.dyn' at offset 0x324 contains 8 entries:
 Offset     Info    Type            Sym.Value  Sym. Name
00002008  00000008 R_386_RELATIVE
000004b4  00000502 R_386_PC32        0000049c   ml_util_func
000004bf  00000401 R_386_32          0000200c   myglob
000004c7  00000401 R_386_32          0000200c   myglob
000004cc  00000401 R_386_32          0000200c   myglob
[...] skipping stuff
&lt;/code&gt;
    &lt;p&gt;If we compare it to the previous invocation of readelf -r, we'll notice a new entry added for ml_util_func. This entry points at address 0x4b4 which is the argument of the call instruction, and its type is R_386_PC32. This relocation type is more complicated than R_386_32, but not by much.&lt;/p&gt;
    &lt;p&gt;It means the following: take the value at the offset specified in the entry, add the address of the symbol to it, subtract the address of the offset itself, and place it back into the word at the offset. Recall that this relocation is done at load-time, when the final load addresses of the symbol and the relocated offset itself are already known. These final addresses participate in the computation.&lt;/p&gt;
    &lt;p&gt;What does this do? Basically, it's a relative relocation, taking its location into account and thus suitable for arguments of instructions with relative addressing (which the e8 call is). I promise it will become clearer once we get to the real numbers.&lt;/p&gt;
    &lt;p&gt;I'm now going to build the driver code and run it under GDB again, to see this relocation in action. Here's the GDB session, followed by explanations:&lt;/p&gt;
    &lt;code&gt; $ gdb -q driver
 Reading symbols from driver...done.
 (gdb) b driver.c:31
 Breakpoint 1 at 0x804869e: file driver.c, line 31.
 (gdb) r
 Starting program: driver
 [...] skipping output
 name=./libmlreloc.so (6 segments) address=0x12e000
               header  0: address=  0x12e000
                       type=1, flags=0x5
               header  1: address=  0x12ff04
                       type=1, flags=0x6
               header  2: address=  0x12ff18
                       type=2, flags=0x6
               header  3: address=  0x12e0f4
                       type=4, flags=0x4
               header  4: address=  0x12e000
                       type=1685382481, flags=0x6
               header  5: address=  0x12ff04
                       type=1685382482, flags=0x4

[...] skipping output
Breakpoint 1, main (argc=1, argv=0xbffff3d4) at driver.c:31
31    }
(gdb)  set disassembly-flavor intel
(gdb) disas ml_util_func
Dump of assembler code for function ml_util_func:
   0x0012e49c &amp;lt;+0&amp;gt;:   push   ebp
   0x0012e49d &amp;lt;+1&amp;gt;:   mov    ebp,esp
   0x0012e49f &amp;lt;+3&amp;gt;:   mov    eax,DWORD PTR [ebp+0x8]
   0x0012e4a2 &amp;lt;+6&amp;gt;:   add    eax,0x1
   0x0012e4a5 &amp;lt;+9&amp;gt;:   pop    ebp
   0x0012e4a6 &amp;lt;+10&amp;gt;:  ret
End of assembler dump.
(gdb) disas /r ml_func
Dump of assembler code for function ml_func:
   0x0012e4a7 &amp;lt;+0&amp;gt;:    55     push   ebp
   0x0012e4a8 &amp;lt;+1&amp;gt;:    89 e5  mov    ebp,esp
   0x0012e4aa &amp;lt;+3&amp;gt;:    83 ec 14       sub    esp,0x14
   0x0012e4ad &amp;lt;+6&amp;gt;:    8b 45 08       mov    eax,DWORD PTR [ebp+0x8]
   0x0012e4b0 &amp;lt;+9&amp;gt;:    89 04 24       mov    DWORD PTR [esp],eax
   0x0012e4b3 &amp;lt;+12&amp;gt;:   e8 e4 ff ff ff call   0x12e49c &amp;lt;ml_util_func&amp;gt;
   0x0012e4b8 &amp;lt;+17&amp;gt;:   03 45 0c       add    eax,DWORD PTR [ebp+0xc]
   0x0012e4bb &amp;lt;+20&amp;gt;:   89 45 fc       mov    DWORD PTR [ebp-0x4],eax
   0x0012e4be &amp;lt;+23&amp;gt;:   a1 0c 00 13 00 mov    eax,ds:0x13000c
   0x0012e4c3 &amp;lt;+28&amp;gt;:   03 45 fc       add    eax,DWORD PTR [ebp-0x4]
   0x0012e4c6 &amp;lt;+31&amp;gt;:   a3 0c 00 13 00 mov    ds:0x13000c,eax
   0x0012e4cb &amp;lt;+36&amp;gt;:   a1 0c 00 13 00 mov    eax,ds:0x13000c
   0x0012e4d0 &amp;lt;+41&amp;gt;:   03 45 0c       add    eax,DWORD PTR [ebp+0xc]
   0x0012e4d3 &amp;lt;+44&amp;gt;:   c9     leave
   0x0012e4d4 &amp;lt;+45&amp;gt;:   c3     ret
End of assembler dump.
(gdb)
&lt;/code&gt;
    &lt;p&gt;The important parts here are:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;In the printout from driver we see that the first segment (the code segment) of libmlreloc.so has been mapped to 0x12e000 [11]&lt;/item&gt;
      &lt;item&gt;ml_util_func was loaded to address 0x0012e49c&lt;/item&gt;
      &lt;item&gt;The address of the relocated offset is 0x0012e4b4&lt;/item&gt;
      &lt;item&gt;The call in ml_func to ml_util_func was patched to place 0xffffffe4 in the argument (I disassembled ml_func with the /r flag to show raw hex in addition to disassembly), which is interpreted as the correct offset to ml_util_func.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Obviously we're most interested in how (4) was done. Again, it's time for some math. Interpreting the R_386_PC32 relocation entry mentioned above, we have:&lt;/p&gt;
    &lt;p&gt;Take the value at the offset specified in the entry (0xfffffffc), add the address of the symbol to it (0x0012e49c), subtract the address of the offset itself (0x0012e4b4), and place it back into the word at the offset. Everything is done assuming 32-bit 2-s complement, of course. The result is 0xffffffe4, as expected.&lt;/p&gt;
    &lt;head rend="h3"&gt;Extra credit: Why was the call relocation needed?&lt;/head&gt;
    &lt;p&gt;This is a "bonus" section that discusses some peculiarities of the implementation of shared library loading in Linux. If all you wanted was to understand how relocations are done, you can safely skip it.&lt;/p&gt;
    &lt;p&gt;When trying to understand the call relocation of ml_util_func, I must admit I scratched my head for some time. Recall that the argument of call is a relative offset. Surely the offset between the call and ml_util_func itself doesn't change when the library is loaded - they both are in the code segment which gets moved as one whole chunk. So why is the relocation needed at all?&lt;/p&gt;
    &lt;p&gt;Here's a small experiment to try: go back to the code of the shared library, add static to the declaration of ml_util_func. Re-compile and look at the output of readelf -r again.&lt;/p&gt;
    &lt;p&gt;Done? Anyway, I will reveal the outcome - the relocation is gone! Examine the disassembly of ml_func - there's now a correct offset placed as the argument of call - no relocation required. What's going on?&lt;/p&gt;
    &lt;p&gt;When tying global symbol references to their actual definitions, the dynamic loader has some rules about the order in which shared libraries are searched. The user can also influence this order by setting the LD_PRELOAD environment variable.&lt;/p&gt;
    &lt;p&gt;There are too many details to cover here, so if you're really interested you'll have to take a look at the ELF standard, the dynamic loader man page and do some Googling. In short, however, when ml_util_func is global, it may be overridden in the executable or another shared library, so when linking our shared library, the linker can't just assume the offset is known and hard-code it [12]. It makes all references to global symbols relocatable in order to allow the dynamic loader to decide how to resolve them. This is why declaring the function static makes a difference - since it's no longer global or exported, the linker can hard-code its offset in the code.&lt;/p&gt;
    &lt;head rend="h3"&gt;Conclusion&lt;/head&gt;
    &lt;p&gt;Load-time relocation is one of the methods used in Linux (and other OSes) to resolve internal data and code references in shared libraries when loading them into memory. These days, position independent code (PIC) is a more popular approach, and some modern systems (such as x86-64) no longer support load-time relocation.&lt;/p&gt;
    &lt;p&gt;Still, I decided to write an article on load-time relocation for two reasons. First, load-time relocation has a couple of advantages over PIC on some systems, especially in terms of performance. Second, load-time relocation is IMHO simpler to understand without prior knowledge, which will make PIC easier to explain in the future. (Update 03.11.2011: the article about PIC was published)&lt;/p&gt;
    &lt;p&gt;Regardless of the motivation, I hope this article has helped to shed some light on the magic going behind the scenes of linking and loading shared libraries in a modern OS.&lt;/p&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[1]&lt;/cell&gt;
        &lt;cell&gt;For some more information about this entry point, see the section "Digression â process addresses and entry point" of this article.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[2]&lt;/cell&gt;
        &lt;cell&gt;Link-time relocation happens in the process of combining multiple object files into an executable (or shared library). It involves quite a lot of relocations to resolve symbol references between the object files. Link-time relocation is a more complex topic than load-time relocation, and I won't cover it in this article.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[3]&lt;/cell&gt;
        &lt;cell&gt;This can be made possible by compiling all your libraries into static libraries (with ar combining object files instead gcc -shared), and providing the -static flag to gcc when linking the executable - to avoid linkage with the shared version of libc.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[4]&lt;/cell&gt;
        &lt;cell&gt;ml simply stands for "my library". Also, the code itself is absolutely non-sensical and only used for purposes of demonstration.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[5]&lt;/cell&gt;
        &lt;cell&gt;Also called "dynamic linker". It's a shared object itself (though it can also run as an executable), residing at /lib/ld-linux.so.2 (the last number is the SO version and may be different).&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[6]&lt;/cell&gt;
        &lt;cell&gt;If you're not familiar with how x86 structures its stack frames, this would be a good time to read this article.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[7]&lt;/cell&gt;
        &lt;cell&gt;You can provide the -l flag to objdump to add C source lines into the disassembly, making it clearer what gets compiled to what. I've omitted it here to make the output shorter.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[8]&lt;/cell&gt;
        &lt;cell&gt;I'm looking at the left-hand side of the output of objdump, where the raw memory bytes are. a1 00 00 00 00 means mov to eax with operand 0x0, which is interpreted by the disassembler as ds:0x0.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[9]&lt;/cell&gt;
        &lt;cell&gt;So ldd invoked on the executable will report a different load address for the shared library each time it's run.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[10]&lt;/cell&gt;
        &lt;cell&gt;Experienced readers will probably note that I could ask GDB about i shared to get the load-address of the shared library. However, i shared only mentions the load location of the whole library (or, even more accurately, its entry point), and I was interested in the segments.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[11]&lt;/cell&gt;
        &lt;cell&gt;What, 0x12e000 again? Didn't I just talk about load-address randomization? It turns out the dynamic loader can be manipulated to turn this off, for purposes of debugging. This is exactly what GDB is doing.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row&gt;
        &lt;cell&gt;[12]&lt;/cell&gt;
        &lt;cell&gt;Unless it's passed the -Bsymbolic flag. Read all about it in the man page of ld.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eli.thegreenplace.net/2011/08/25/load-time-relocation-of-shared-libraries/"/><published>2025-10-25T20:19:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706705</id><title>Testing out BLE beacons with BeaconDB</title><updated>2025-10-25T23:32:27.055434+00:00</updated><content>&lt;doc fingerprint="ae4260d429ba004c"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Testing Out BLE Beacons With beaconDB&lt;/head&gt;
    &lt;head rend="h2"&gt;What on earth is beaconDB?&lt;/head&gt;
    &lt;p&gt;I've been using GrapheneOS for about half a year now. Back in March they added support for network based location.[^0] This means you no longer need to rely on Google's location services. Looking into how the system works sent me down yet another rabbit hole of reading. [1]&lt;/p&gt;
    &lt;p&gt;Anyways, in 2013 Mozilla launched Mozilla Location Service (MLS) as a pilot project to provide location lookup using observations of public cell towers, BLE Beacons and WiFi access points. Sadly, in 2024 Mozilla retired MLS. Thankfully, beaconDB launched to continue the work! [2]&lt;/p&gt;
    &lt;p&gt;I have been hacking away on a project for contributing observations to beaconDB and I wanted some BLE beacons I could use for testing. This experiment sort of spun off from that work.&lt;/p&gt;
    &lt;p&gt;The plan is simple:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Buy some BLE beacons.&lt;/item&gt;
      &lt;item&gt;Get their MAC addresses.&lt;/item&gt;
      &lt;item&gt;Query the beaconDB API to confirm no location is currently associated with the beacons.&lt;/item&gt;
      &lt;item&gt;Place the beacons in my yard. [3]&lt;/item&gt;
      &lt;item&gt;Take my dog on a walk around the block while running NeoStumbler.&lt;/item&gt;
      &lt;item&gt;Re-run the API query to see location estimates.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;What on earth are BLE Beacons?&lt;/head&gt;
    &lt;p&gt;I've been writing the phrase BLE beacons a lot without describing what they are. So to disambiguate [4]:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Bluetooth - a wireless communication standard.&lt;/item&gt;
      &lt;item&gt;Bluetooth Low Energy - part of the Bluetooth 4.0 protocol, much lower power consumption, but also reduced transmission rates.&lt;/item&gt;
      &lt;item&gt;BLE beacons - BLE devices that are primarily transmit only.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Stationary BLE beacons are often used to mark locations in places where GPS signals are weak, like inside malls. Also, there is no single BLE beacon standard. Instead we have:&lt;/p&gt;
    &lt;p&gt;iBeacon which was released by Apple in 2013. Apple generally still supports them.&lt;/p&gt;
    &lt;p&gt;In 2014 Google launched the experimental URIBeacon. Then in 2015 Google replaced that with Eddystone. A one point Google was really into the concept of the Physical Web, but thankfully gave up on spamming users with notifications in 2018. This effectively reduced Google's involvement with the standard. Eddystone also powers the Waze beacons that saves me from missing my exit in the Ted Williams Tunnel.&lt;/p&gt;
    &lt;p&gt;AltBeacon was released in 2014 as an open standard. There are also other less used beacon standards out there.&lt;/p&gt;
    &lt;p&gt;Also, since BLE beacons are just BLE devices with extra details attached to the broadcast information, both iPhones and Android devices can scan for any standard. Best of all, most modern beacon devices should support broadcasting multiple beacon types at the same time.&lt;/p&gt;
    &lt;p&gt;In terms of collecting information about all these different types of beacons, Neostumbler uses the Android Beacon Library, which can detect the three main beacon types. Though they want to move away from the library so they can support custom scanning intervals.&lt;/p&gt;
    &lt;head rend="h2"&gt;Which BLE beacons did I choose?&lt;/head&gt;
    &lt;p&gt;When I was surveying the options I saw that many beacons included features like motion detection, lights, buttons, sound, etc. I wanted a stationary beacon with a long battery life, so I tried to avoid extra features if possible to keep the cost down. Additionally there are BLE beacons designed for broadcasting over extra long ranges. However the Bluetooth / WiFi accuracy section of the MLS documentation notes:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Bluetooth and WiFi networks have a fairly limited range. Bluetooth low-energy beacons typically reach just a couple meters and WiFi networks reach up to 100 meters. With obstacles like walls and people in the way, these distances get even lower.&lt;/p&gt;&lt;lb/&gt;...&lt;lb/&gt;This means position estimates based on WiFi networks are usually accurate to 100 meters. If a lot of networks are available in the area, accuracy tends to increase to about 10 or 20 meters. Bluetooth networks tend to be accurate to about 10 meters.&lt;/quote&gt;
    &lt;p&gt;So in my case, I specifically do not want a long range beacon in order to improve location accuracy.&lt;/p&gt;
    &lt;p&gt;In the end I settled on the Feasy FSC-BP104D and bought two of them:&lt;/p&gt;
    &lt;p&gt;There is the FeasyBeacon app which leaves a lot to be desired, but is not totally useless. [5] I powered up the two beacons and changed the following settings:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Set a new PIN.&lt;/item&gt;
      &lt;item&gt;I reduced the broadcast interval time from the default 1300ms to 1000ms. This will increase the batter usage, but allows for more frequent updates.&lt;/item&gt;
      &lt;item&gt;Changed the name of the beacons to something fun.&lt;/item&gt;
      &lt;item&gt;Updated the broadcast URL so that I was not advertising a Feasy store page. Sadly, the character limit was not long enough to broadcast my blogs address. So I chose the beaconDB website instead.&lt;/item&gt;
      &lt;item&gt;Checked for firmware updates.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Then I uninstalled the app, hoping to never have to use it again.&lt;/p&gt;
    &lt;head rend="h2"&gt;Trying out the API and confirming the beacons are not associated with a location&lt;/head&gt;
    &lt;p&gt;beaconDB provides a geolocate endpoint. The old MLS version required an API key, but that is no longer needed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Instead of using API keys to control access like Mozilla did, beaconDB expects clients to be pre-configured with a reasonable user agent. Ideally this identifies the software the client is using and includes info that can be used to narrow things down in the event a bad configuration or bug causes significant load on the server.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;As a first step I wanted to confirm I could hit the API and get a valid location as a response. So I threw together a quick Python script:&lt;/p&gt;
    &lt;code&gt;import requests  
  
url = "https://api.beaconDB.net/v1/geolocate"  
  
headers = {'User-Agent': 'beaconDB test script, blog.matthewbrunelle.com',} 
  
body = {
    "wifiAccessPoints": [{
        "macAddress": "01:23:45:67:89:ab",
        "signalStrength": -51
    }, {
        "macAddress": "01:23:45:67:89:cd"
    }]
} 
  
response = requests.post(url, json=body, headers=headers)  
  
if response.status_code != 200:  
    print(f"Error: {response.status_code}")  
else:  
    print(response.json())

&lt;/code&gt;
    &lt;p&gt;Note: The example code for the blog post uses the example MAC addresses from the documentation, not real ones.&lt;/p&gt;
    &lt;p&gt;The API is pretty simple and most fields are optional. The main information you need to provide are MAC addresses and the signal strength for the observation. If I input the MAC addresses for my home access points [6], I get a response like:&lt;/p&gt;
    &lt;code&gt;{'location': {'lat': XX.XXXXXX, 'lng': -XX.XXXXXX}, 'accuracy': 132}
&lt;/code&gt;
    &lt;p&gt;Which gives the location of the house directly across the street from me. The accuracy is measured in meters, so the circle with a radius of 132 meters centered on that position does, in fact, contain my apartment. Not bad for locating off a single observation. beaconDB works best when you can query with multiple device observations at once.&lt;/p&gt;
    &lt;p&gt;Next, I wanted to hit the same endpoint, but using my BLE beacons. The app provided the beacons information, but they also had their MAC addresses printed on their side. I changed the body in the script above to:&lt;/p&gt;
    &lt;code&gt;body = {  
    "considerIp": False,  
    "bluetoothBeacons": [{
        "macAddress": "ff:23:45:67:89:ab",
        "age": 2000,
        "name": "beacon",
        "signalStrength": -110
    }],
    "fallbacks": {  sdf10adfasdfasf
        "lacf": False,  
        "ipf": False  
    }  
}
&lt;/code&gt;
    &lt;p&gt;Note that here I made sure to set &lt;code&gt;considerIp&lt;/code&gt; and &lt;code&gt;fallbacks&lt;/code&gt; to false, so that the API purely relies on the BLE beacon. From the docs:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;The&lt;/p&gt;&lt;code&gt;fallbacks&lt;/code&gt;section allows some control over the more coarse grained position sources. If no exact match can be found, these can be used to return a “404 Not Found” rather than a coarse grained estimate with a large accuracy value.&lt;/quote&gt;
    &lt;p&gt;As expected, I get a 404 back from the API.&lt;/p&gt;
    &lt;head rend="h2"&gt;Collecting observations with Neostumbler and testing the API&lt;/head&gt;
    &lt;p&gt;This part was pretty easy. NeoStumbler is a great app for contributing observations to beaconDB. I started recording and took my dog for a walk around the block. At the end of the walk I uploaded my observations. Then I just needed to wait, but not for too long:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;note that submissions will take at least 5 minutes to become available in the beaconDB&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Except... I was still getting 404s for my BLE beacons.&lt;/p&gt;
    &lt;p&gt;Neostumbler has a mechanism for filtering out moving devices, so the next thing I tried was disabling that. However I was still getting 404s...&lt;/p&gt;
    &lt;head rend="h2"&gt;Directly submitting observations to beaconDB&lt;/head&gt;
    &lt;p&gt;OK, so at this point I do not know if the issue is with Neostumbler submitting my observations, or beaconDB using them. Thankfully, Neostumbler lets you export your observations to csv.&lt;/p&gt;
    &lt;p&gt;So I was able to directly submit an observation using the geosubmit v2 endpoint. The export contains every piece of information you can submit, except for the GPS heading and the beacon name.&lt;/p&gt;
    &lt;code&gt;import requests  
  
url = "https://api.beacondb.net/v2/geosubmit"  
  
headers = {'User-Agent': 'BeaconDB test script, blog.matthewbrunelle.com',}  
  
{"items": [{
    "timestamp": 1405602028568,
    "position": {
        "latitude": -22.7539192,
        "longitude": -43.4371081,
        "accuracy": 10.0,
        "age": 1000,
        "altitude": 100.0,
        "altitudeAccuracy": 50.0,
        #"heading": 45.0,
        "pressure": 1013.25,
        "speed": 3.6,
        "source": "gps"
    },
    "bluetoothBeacons": [
        {
            "macAddress": "ff:23:45:67:89:ab",
            "age": 2000,
            #"name": "beacon",
            "signalStrength": -110
        }
    ],
}]}
  
response = requests.post(url, json=body, headers=headers)  
  
print(f"Status code: {response.status_code}")  
if response.status_code == 200:  
    print(response.json())
&lt;/code&gt;
    &lt;p&gt;Anyways, after running this script I wait again... and still a 404. At this point I realized that I had never run a test of a known good BLE beacon against the API to make sure I get a location back. So I dumped a full month of observations which contained a recent road trip I went on [7] and check some of those MAC addresses. Still nothing.&lt;/p&gt;
    &lt;head rend="h2"&gt;Double checking the beaconDB source and final thoughts&lt;/head&gt;
    &lt;p&gt;So finally, I went to look at the beaconDB source to see what I could find. First I wanted to check if there was a minimum number of observations needed, sort of like the trilateration I learned about in HackerBox 0119 - Geopositioning. A comment from the repository revealed:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;At least two WiFi networks have to been known to accurately determine the position.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;So I tried making the WiFi query I made before, but adding the BLE beacons to see if the accuracy improved... Nothing, the accuracy was the same. As I searched the codebase I realized the problem: beaconDB currently accepts and stores BLE beacons, but does not use them yet for geolocation. So I made an issue.&lt;/p&gt;
    &lt;p&gt;Not all projects end as expected. At the very least, I learned a lot along the way. [8] My initial question was "how does beaconDB use BLE beacons". I should have probably checked if the answer was "it currently doesn't" before I set everything up.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Especially since I am a fan of how the fused location provider in Play Services works. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;There are some pretty graphs of observations over time. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I should note that there are several beacons around me already, so this is maybe not the most useful way to spend my time. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;By mostly looking at the first sentences of pages on Wikipedia. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Also amazingly exodus show no trackers. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;I'm currently using two TP-Link EAP670. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Scanning in New Hampshire is interesting compared to MA. I was basically only getting cell tower readings with the occasional WiFi. No BLE beacons. In my neighborhood I get 30-50 WiFi APs at a time. ↩︎&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Most importantly, I was able to write an explanation of what BLE beacons are. Now I don't have to cram that into a future post I am working on. ↩︎&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.matthewbrunelle.com/testing-out-ble-beacons-with-beacondb/"/><published>2025-10-25T20:26:59+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706729</id><title>Agent Lightning: Train agents with RL (no code changes needed)</title><updated>2025-10-25T23:32:26.361948+00:00</updated><content>&lt;doc fingerprint="a716b050645adcbf"&gt;
  &lt;main&gt;
    &lt;p&gt;The absolute trainer to light up AI agents.&lt;/p&gt;
    &lt;p&gt;Join our Discord community to connect with other users and contributors.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Turn your agent into an optimizable beast with ZERO CODE CHANGE (almost)! 💤&lt;/item&gt;
      &lt;item&gt;Build with ANY agent framework (LangChain, OpenAI Agent SDK, AutoGen, CrewAI, Microsoft Agent Framework...); or even WITHOUT agent framework (Python OpenAI). You name it! 🤖&lt;/item&gt;
      &lt;item&gt;Selectively optimize one or more agents in a multi-agent system. 🎯&lt;/item&gt;
      &lt;item&gt;Embraces Algorithms like Reinforcement Learning, Automatic Prompt Optimization, Supervised Fine-tuning and more. 🤗&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Read more on our documentation website.&lt;/p&gt;
    &lt;code&gt;pip install agentlightning&lt;/code&gt;
    &lt;p&gt;Please refer to our installation guide for more details.&lt;/p&gt;
    &lt;p&gt;To start using Agent-lightning, check out our documentation and examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;8/11/2025 Training AI Agents to Write and Self-correct SQL with Reinforcement Learning Medium.&lt;/item&gt;
      &lt;item&gt;8/5/2025 Agent Lightning: Train ANY AI Agents with Reinforcement Learning arXiv paper.&lt;/item&gt;
      &lt;item&gt;7/26/2025 We discovered an approach to train any AI agent with RL, with (almost) zero code changes. Reddit.&lt;/item&gt;
      &lt;item&gt;6/6/2025 Agent Lightning - Microsoft Research Project page.&lt;/item&gt;
    &lt;/list&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;DeepWerewolf — A case study of agent RL training for the Chinese Werewolf game built with AgentScope and Agent Lightning.&lt;/item&gt;
      &lt;item&gt;AgentFlow — A modular multi-agent framework that combines planner, executor, verifier, and generator agents with the Flow-GRPO algorithm to tackle long-horizon, sparse-reward tasks.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Agent Lightning keeps the moving parts to a minimum so you can focus on your idea, not the plumbing. Your agent continues to run as usual; you can still use any agent framework you like; you drop in the lightweight &lt;code&gt;agl.emit_xxx()&lt;/code&gt; helper, or let the tracer collect every prompt, tool call, and reward. Those events become structured spans that flow into the LightningStore, a central hub that keeps tasks, resources, and traces in sync.&lt;/p&gt;
    &lt;p&gt;On the other side of the store sits the algorithm you choose, or write yourself. The algorithm reads spans, learns from them, and posts updated resources such as refined prompt templates or new policy weights. The Trainer ties it all together: it streams datasets to runners, ferries resources between the store and the algorithm, and updates the inference engine when improvements land. You can either stop there, or simply let the same loop keep turning.&lt;/p&gt;
    &lt;p&gt;No rewrites, no lock-in, just a clear path from first rollout to steady improvement.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Workflow&lt;/cell&gt;
        &lt;cell role="head"&gt;Status&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;CPU Tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;GPU Tests&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Examples Integration&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Latest Dependency Compatibility&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Legacy Examples Compatibility&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;If you find Agent Lightning useful in your research or projects, please cite our paper:&lt;/p&gt;
    &lt;code&gt;@misc{luo2025agentlightningtrainai,
      title={Agent Lightning: Train ANY AI Agents with Reinforcement Learning},
      author={Xufang Luo and Yuge Zhang and Zhiyuan He and Zilong Wang and Siyun Zhao and Dongsheng Li and Luna K. Qiu and Yuqing Yang},
      year={2025},
      eprint={2508.03680},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2508.03680},
}&lt;/code&gt;
    &lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.&lt;/p&gt;
    &lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt;
    &lt;p&gt;This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.&lt;/p&gt;
    &lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark &amp;amp; Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;
    &lt;p&gt;This project has been evaluated and certified to comply with the Microsoft Responsible AI Standard. The team will continue to monitor and maintain the repository, addressing any severe issues, including potential harms, if they arise.&lt;/p&gt;
    &lt;p&gt;This project is licensed under the MIT License. See the LICENSE file for details.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/microsoft/agent-lightning"/><published>2025-10-25T20:30:25+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706744</id><title>Honda's ASIMO (2021)</title><updated>2025-10-25T23:32:26.089462+00:00</updated><content>&lt;doc fingerprint="e4048552a6b1ebc0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;HONDA'S ASIMO&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Robots Got Talents&lt;/item&gt;
      &lt;item&gt;Feb 26, 2021&lt;/item&gt;
      &lt;item&gt;5 min read&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;ASIMO which stands for Advanced Step in Innovative Mobility is one of the worlds most famous humanoid robots, which was created by Honda in 2000, and discontinued in 2018. ASIMO was first developed to help people. ASIMO’s height of four feet, three inches (130 centimetres) makes it the perfect size for helping around the house or assisting a person confined to a bed or a wheelchair. ASIMO’s size also allows it to look directly at an adult sitting in a chair or sitting up in bed for easy and natural communication.&lt;/p&gt;
    &lt;head rend="h2"&gt;History of Honda's Robots:&lt;/head&gt;
    &lt;p&gt;Honda began developing humanoid robots in the 1980s, including several prototypes that preceded ASIMO. It was the company's goal to create a walking robot. E0 was the first bipedal (two-legged) model produced as part of the Honda E series, which was an early experimental line of the self-regulating, humanoid walking robot with wireless movements created between 1986 and 1993.&lt;/p&gt;
    &lt;p&gt;Honda's E series:&lt;/p&gt;
    &lt;p&gt;E0 to E6 from the top left corner.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;
        &lt;p&gt;E0, developed in 1986.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E1, developed in 1987, was larger than the first and walked at 0.25 km/h. This model and subsequent E-series robots have 12 degrees of freedom: 3 in each groin, 1 in each knee and 2 in each ankle.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E2, developed in 1989, could travel at 1.2km/h, through the development of "dynamic movement".&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E3, developed in 1991, travelled at 3km/h, the average speed of a walking human.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E4, developed in 1991, lengthened the knee to achieve speeds of up to 4.7km/h.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E5, developed in 1992, was able to walk autonomously, albeit with a very large head.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;E6, developed in 1993, was able to autonomously balance, walk over obstacles, and even climb stairs.&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This was followed by the Honda P series of robots produced from 1993 through 1997. In 1993, Honda began developing "Prototype" models ("P" series), attaching the legs to a torso with arms that could perform basic tasks. P2, the second prototype model, created in December 1996, using wireless techniques making it the first self-regulating, two-legged walking robot. P2 weighed 463 pounds with a height of six feet tall. In September 1997, P3 was introduced as the first completely independent bi-pedal humanoid walking robot, standing five feet, four inches tall and weighing 287 pounds. All the research made on the E- and P-series led to the creation of ASIMO.&lt;/p&gt;
    &lt;p&gt;Honda's P series:&lt;/p&gt;
    &lt;p&gt;P1 to P4 from the left to the right.&lt;/p&gt;
    &lt;p&gt;About ASIMO:&lt;/p&gt;
    &lt;p&gt;ASIMO (Advanced Step in Innovative Mobility) is the latest humanoid robot created by Honda in 2000 after the E and P series. ASIMO is currently displayed in the Miraikan museum in Tokyo, Japan. On 8 July 2018, Honda posted the last update of Asimo through their official page stating that it would be ceasing all development and production of Asimo robots in order to focus on more practical honour applications using the technology developed through Asimo's lifespan. The name ASIMO was also chosen in honour of Isaac Asimov, the father of Science fiction.&lt;/p&gt;
    &lt;p&gt;ASIMO stands 130 cm (4 ft 3 in) tall and weighs 54 kg (119 lb). Research conducted by Honda found that the ideal height for a mobility assistant robot was between 120 cm and the height of an average adult, which is conducive to operating doorknobs and light switches.&lt;/p&gt;
    &lt;p&gt;Source: Asimo technical information book&lt;/p&gt;
    &lt;p&gt;ASIMO is powered by a rechargeable 51.8 V lithium-ion battery with an operating time of one hour. Switching from a nickel-metal hydride in 2004 increased the amount of time ASIMO can operate before recharging. ASIMO has a three-dimensional computer processor that was created by Honda and consists of a three stacked-die, a processor, a signal converter and memory. The computer that controls ASIMO's movement is housed in the robot's waist area and can be controlled by a PC, wireless controller, or voice commands.&lt;/p&gt;
    &lt;p&gt;Abilities and Functions:&lt;/p&gt;
    &lt;p&gt;ASIMO has the ability to recognize moving objects, postures, gestures, its surrounding environment, sounds and faces, which enables it to interact with humans. The robot can detect the movements of multiple objects by using visual information captured by two cameras "eyes" in its head and also determine distance and direction. This feature allows ASIMO to follow or face a person when approached. The robot interprets voice commands and human gestures, enabling it to recognize when a handshake is offered or when a person waves or points, and then respond accordingly. ASIMO's ability to distinguish between voices and other sounds allows it to identify its companions. ASIMO is able to respond to its name and recognizes sounds associated with a falling object or collision. This allows the robot to face a person when spoken to or look towards a sound. ASIMO responds to questions by nodding or providing a verbal answer in different languages and can recognize approximately 10 different faces and address them by name.&lt;/p&gt;
    &lt;p&gt;Sensors and Features:&lt;/p&gt;
    &lt;p&gt;There are sensors that assist in autonomous navigation. The two cameras inside the head are used as a visual sensor to detect obstacles. The lower portion of the torso has a ground sensor which comprises one laser sensor and one infrared sensor. The laser sensor is used to detect ground surface. The infrared sensor with automatic shutter adjustment based on brightness is used to detect pairs of floor markings to confirm the navigable paths of the planned map. The pre-loaded map and the detection of floor markings help the robot to precisely identify its present location and continuously adjust its position. There are front and rear ultrasonic sensors to sense the obstacles. The front sensor is located at the lower portion of the torso together with the ground sensor. The rear sensor is located at the bottom of the backpack.&lt;/p&gt;
    &lt;p&gt;More technical details could be found in the official technical book, on ASIMO's Website press here&lt;/p&gt;
    &lt;p&gt;ASIMO's Sapcifications Table:&lt;/p&gt;
    &lt;head rend="h2"&gt;Interesting FAQs about ASIMO:&lt;/head&gt;
    &lt;p&gt;How is ASIMO controlled?&lt;/p&gt;
    &lt;p&gt;ASIMO is controlled by a laptop computer or by a portable computer controller unit through a wireless network system. This permits a more direct and flexible operation. A single operator can easily and fully control. ASIMO’s movements. Can ASIMO also be controlled by voice commands? ASIMO can comprehend and carry out tasks based on simple voice commands that have been preprogrammed into its onboard memory.&lt;/p&gt;
    &lt;p&gt;Can ASIMO recognize people and obstacles?&lt;/p&gt;
    &lt;p&gt;ASIMO utilizes IC Communications technology to recognize people within its vicinity.&lt;/p&gt;
    &lt;p&gt;ASIMO can also independently map its environment using its camera “eyes” and register stationary obstacles. ASIMO can store this data in an onboard map of its environment, then recall this data while walking in order to avoid these obstacles.&lt;/p&gt;
    &lt;p&gt;ASIMO can recognize moving pedestrians in its walking path and stop momentarily until these persons have cleared the robot’s path.&lt;/p&gt;
    &lt;p&gt;How intelligent is ASIMO?&lt;/p&gt;
    &lt;p&gt;ASIMO’s intelligence lies in the technologies with which it is equipped, not in the ability to think or reason like a human.&lt;/p&gt;
    &lt;p&gt;How many motors are used in ASIMO?&lt;/p&gt;
    &lt;p&gt;ASIMO is equipped with 34 separate servo motors.&lt;/p&gt;
    &lt;p&gt;Is ASIMO for sale, cost?&lt;/p&gt;
    &lt;p&gt;Unfortunately, ASIMO is not for sale, but according to different sources it cost from $2,000,000 to $2,500,000 buy ASIMO.&lt;/p&gt;
    &lt;head rend="h2"&gt;ASIMO 20th Anniversary&lt;/head&gt;
    &lt;head rend="h2"&gt;Sources:&lt;/head&gt;
    &lt;p&gt;Links for the sources used in creating this post&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.robotsgottalents.com/post/asimo"/><published>2025-10-25T20:32:29+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706755</id><title>"Learn APL" Notes</title><updated>2025-10-25T23:32:25.380344+00:00</updated><content>&lt;doc fingerprint="aa94ba39423d9129"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;"Learn APL" Notes&lt;/head&gt;
    &lt;p&gt;I use this page as reference card when I have any doubts about the APL language.&lt;/p&gt;
    &lt;p&gt;This file follows APL Wiki's APL Tutorial and Further Topics in APL guides, plus occasional extra looks at TryAPL for missing stuff on certain symbols (I made sure it was compatible with GNU APL).&lt;/p&gt;
    &lt;p&gt;I do not guarantee a comprehensive guide to APL here. This is mainly for future consulting.&lt;/p&gt;
    &lt;p&gt;Plus, make sure you are using a monospace font which supports APL characters!&lt;/p&gt;
    &lt;p&gt;Also see the GNU APL Manual.&lt;/p&gt;
    &lt;head rend="h3"&gt;Back to last page&lt;/head&gt;
    &lt;head rend="h2"&gt;Table of Contents&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Getting Started&lt;/item&gt;
      &lt;item&gt;APL Concepts&lt;/item&gt;
      &lt;item&gt;Further Topics in APL&lt;/item&gt;
      &lt;item&gt;Finishing&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Getting Started&lt;/head&gt;
    &lt;head rend="h3"&gt;Startup&lt;/head&gt;
    &lt;p&gt;Let's make sure our file executes. Executing the tangled file will run everything done in the tutorial.&lt;/p&gt;
    &lt;p&gt; Also, for live interaction, use &lt;code&gt;gnu-apl-interactive-send-*&lt;/code&gt;.
&lt;/p&gt;
    &lt;code&gt;#!/usr/bin/apl --id 1010
&lt;/code&gt;
    &lt;p&gt;Oh, and just so you know, use a unicode font which supports this stuff.&lt;/p&gt;
    &lt;head rend="h3"&gt;Simple arithmetic&lt;/head&gt;
    &lt;p&gt; Use &lt;code&gt;⍝&lt;/code&gt; at the beginning of any comment.
&lt;/p&gt;
    &lt;quote&gt;⍝⍝⍝ Getting started ⍝⍝ This is a comment. ⍝⍝ Check the GNU APL keyboard for shortcut hints ⍝⍝ at any time. ⍝ Simple Arithmetic&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arithmetic functions&lt;/head&gt;
    &lt;quote&gt;5+12 18÷3 108÷11 4×7 3.893×7.6&lt;/quote&gt;
    &lt;p&gt; Use &lt;code&gt;-&lt;/code&gt; for subtraction, and &lt;code&gt;¯&lt;/code&gt; for negative signal.
&lt;/p&gt;
    &lt;quote&gt;100-95 8-16&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arithmetic on lists of numbers&lt;/head&gt;
    &lt;quote&gt;3+2 4 11 7 5&lt;/quote&gt;
    &lt;p&gt;Spot the difference on applying a sum to each element and applying a sum on two numbers:&lt;/p&gt;
    &lt;quote&gt;1+2 3 4 1+234&lt;/quote&gt;
    &lt;p&gt;Lists can be on either side of the sign.&lt;/p&gt;
    &lt;quote&gt;6 3 8 1+3 2.5 33.7 12 8÷15 9.8 11.2 17 1.2×1.175&lt;/quote&gt;
    &lt;p&gt;It is possible to perform arithmetic between two lists in a per-element basis, but only if their length matches.&lt;/p&gt;
    &lt;quote&gt;12 3 29 4×1 3 5 2&lt;/quote&gt;
    &lt;head rend="h4"&gt;Order of execution&lt;/head&gt;
    &lt;p&gt;APL runs stuff from right to left, since there are so many functions on the language.&lt;/p&gt;
    &lt;quote&gt;3×3-1&lt;/quote&gt;
    &lt;p&gt;That is because APL groups things from right to left as well.&lt;/p&gt;
    &lt;quote&gt;2 3 1+8÷2 2 2&lt;/quote&gt;
    &lt;p&gt;If you need to make things unambiguous, use parentheses.&lt;/p&gt;
    &lt;quote&gt;(2 3 1+8)÷2 2 2&lt;/quote&gt;
    &lt;p&gt; Remember again the difference between &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;¯&lt;/code&gt;!
&lt;/p&gt;
    &lt;quote&gt;1985 - 1066 ⍝ Difference of two numbers 3 ¯1 ¯7 + ¯4 ¯1 2 ⍝ Sum between two lists with negative numbers 2-3+5 ⍝ This does 3+5, then does 2-8 2 ¯3+5 ⍝ This adds 5 to the number list 2 ¯3&lt;/quote&gt;
    &lt;head rend="h4"&gt;Dual-purpose functions&lt;/head&gt;
    &lt;p&gt;Some functions can be used for more than one purpose.&lt;/p&gt;
    &lt;p&gt;When used in infix notation, ordinary operations have their intended effect:&lt;/p&gt;
    &lt;quote&gt;5+4 1 3 4+3 1 6&lt;/quote&gt;
    &lt;p&gt;You can, however, use the functions in prefix notation, which will change their effect.&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;+&lt;/code&gt; appears to do nothing. Its true usage happens for assignment, which
we'll see next.
&lt;/p&gt;
    &lt;quote&gt;+12&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;-&lt;/code&gt; inverts the signal of al numbers on the list.
&lt;/p&gt;
    &lt;quote&gt;- 3 ¯6 ¯8 4 12 ¯9&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;÷&lt;/code&gt; takes the reciprocal of all numbers (divides 1 by them).
&lt;/p&gt;
    &lt;quote&gt;÷1 2 4 10 100&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;×&lt;/code&gt; takes the sign of each number from the list. Yields &lt;code&gt;1&lt;/code&gt; for positive
numbers, &lt;code&gt;¯1&lt;/code&gt; for negative, and &lt;code&gt;0&lt;/code&gt; for zero.
&lt;/p&gt;
    &lt;quote&gt;×8 0 ¯3 ¯7 0 4&lt;/quote&gt;
    &lt;p&gt;There is no definition for postfix operators; that would be a syntax error.&lt;/p&gt;
    &lt;head rend="h4"&gt;Ceiling and floor&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;⌈&lt;/code&gt;rounds a number up;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⌊&lt;/code&gt;rounds a number down.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;To perform accurate rounding, you may want to use one of the following patterns:&lt;/p&gt;
    &lt;quote&gt;⌈120.11 12.32 65.01 13.52 - 0.5 ⌊99.99 12.82 15.39 48.90 + 0.5&lt;/quote&gt;
    &lt;p&gt; When using those operators under an infix form, &lt;code&gt;⌈&lt;/code&gt; selects the greatest
number, while &lt;code&gt;⌊&lt;/code&gt; selects the smallest number.
&lt;/p&gt;
    &lt;quote&gt;2 ⌈ 6 2 ⌊ 6&lt;/quote&gt;
    &lt;p&gt;One can also use these operations to perform comparisions between lists of numbers.&lt;/p&gt;
    &lt;quote&gt;6 8 1 ⌈ 3 5 9 6 8 1 ⌊ 3 5 9&lt;/quote&gt;
    &lt;head rend="h4"&gt;Ending a session&lt;/head&gt;
    &lt;p&gt;If you want to end a session, use&lt;/p&gt;
    &lt;quote&gt;)OFF&lt;/quote&gt;
    &lt;p&gt;This will not be tangled.&lt;/p&gt;
    &lt;head rend="h4"&gt;Exercises&lt;/head&gt;
    &lt;quote&gt;⍝ Exercises&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q1&lt;p&gt;Enter statements to:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Multiply each of three numbers, &lt;code&gt;3 6 2&lt;/code&gt;by&lt;code&gt;8&lt;/code&gt;and then add&lt;code&gt;4&lt;/code&gt;to the results of the multiplication.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;4 + 8 × 3 6 2&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add 15% to each number in the list &lt;code&gt;14 5 78 145&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;1.15 × 14 5 78 145&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Add the difference between &lt;code&gt;13&lt;/code&gt;and&lt;code&gt;8&lt;/code&gt;to&lt;code&gt;4 6 12 7&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;(13 - 8) + 4 6 12 7 ⍝ Or... 4 6 12 7 + 13 - 8&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Multiply the result of &lt;code&gt;6&lt;/code&gt;times&lt;code&gt;3&lt;/code&gt;by the result of&lt;code&gt;4&lt;/code&gt;times&lt;code&gt;8&lt;/code&gt;and subtract&lt;code&gt;5&lt;/code&gt;from the total.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;((6 × 3) × (4 × 8)) - 5 ⍝ Or... ¯5+(6×3)×4×8&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Reverse the signs in this list: &lt;code&gt;3 ¯4 ¯12 6&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;- 3 ¯4 ¯12 6&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Compare these lists, selecting the larger number in each comparision: &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;2 7 0 55&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;33 1 10 13&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;2 7 0 55 ⌈ 33 1 10 13&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Multiply each of three numbers, &lt;/item&gt;
      &lt;item&gt;Q2&lt;p&gt;Which of these statements cause error messages? Why?&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Statement &lt;code&gt;a&lt;/code&gt;is a valid multiplication between&lt;code&gt;12&lt;/code&gt;and&lt;code&gt;9&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Statement &lt;code&gt;b&lt;/code&gt;is a valid sum between&lt;code&gt;3&lt;/code&gt;and&lt;code&gt;¯2&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Statement &lt;code&gt;c&lt;/code&gt;produces a&lt;code&gt;LENGTH ERROR&lt;/code&gt;because&lt;code&gt;19 0 3 4&lt;/code&gt;and&lt;code&gt;7 2 87&lt;/code&gt;are lists of different lengths.&lt;/item&gt;&lt;item&gt;&lt;code&gt;5 ¯8&lt;/code&gt;is a valid list of two numbers; it may be unintended, though.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Statement &lt;/item&gt;
      &lt;item&gt;Q3&lt;p&gt;You're getting&lt;/p&gt;&lt;code&gt;£200&lt;/code&gt;worth of dollars for yourself and&lt;code&gt;£180&lt;/code&gt;and&lt;code&gt;£230&lt;/code&gt;worth respectively for two friends. Enter a statement which calculates how many dollars each of you will get at&lt;code&gt;1.96&lt;/code&gt;dollars to the pound.&lt;quote&gt;200 180 230×1.96&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q4&lt;p&gt;Highest recorded temperatures for a week in August were:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;79 84 83 78 74 69 70&lt;/code&gt;(Fahrenheit)&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Enter a statement to convert them into Centigrade. (One method is to subtract 32 degrees and multiply by 5/9.) Suppress decimal places in the result.&lt;/p&gt;&lt;quote&gt;⌊((79 84 83 78 74 69 70-32)×5÷9)+0.5 ⍝ Or... ⌈¯0.5+(5÷9)×79 84 83 78 74 69 70-32&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q5&lt;p&gt;Enter a statement to find the difference in metres between 1500 metres and a mile. (1 yard = 0.9144m and 1760 yards in a mile)&lt;/p&gt;&lt;quote&gt;¯1500+1760×0.9144&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;Variables&lt;/head&gt;
    &lt;quote&gt;⍝ Variables&lt;/quote&gt;
    &lt;head rend="h4"&gt;Assignments&lt;/head&gt;
    &lt;p&gt; An assignment can be done with a variable name and a &lt;code&gt;←&lt;/code&gt; symbol.
&lt;/p&gt;
    &lt;code&gt;A ← .175
&lt;/code&gt;
    &lt;p&gt; This enables &lt;code&gt;A&lt;/code&gt; to be used in expressions.
&lt;/p&gt;
    &lt;quote&gt;200×A A×30.50 12.25 60.30 15.00 ⌈ A×30.50 12.25 60.30 15.00&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;C&lt;/code&gt; is the conversion factor for fonverting pounds to kilograms.
&lt;/p&gt;
    &lt;quote&gt;C ← .45359237 17 × C ⍝ Convert 17 lbs into Kg ⌈C×11×14 ⍝ How many Kgs are there in 11 stones, ⍝ then round up&lt;/quote&gt;
    &lt;p&gt;To keep a calculation, we then use variables.&lt;/p&gt;
    &lt;quote&gt;JOE ← ⌈C×11×14&lt;/quote&gt;
    &lt;head rend="h4"&gt;Variable names&lt;/head&gt;
    &lt;p&gt;Valid statements:&lt;/p&gt;
    &lt;quote&gt;AAA ← 4 ab ← 1 C9999 ← 0 Jack_Smith ← 100&lt;/quote&gt;
    &lt;p&gt;Which denotes that APL is case sensitive.&lt;/p&gt;
    &lt;p&gt;Also, APL doesn't have bare words as variable names:&lt;/p&gt;
    &lt;code&gt;JOHN SMITH ← 100
&lt;/code&gt;
    &lt;p&gt;However, using parentheses will create two identical variables with the same value. This happens in both GNU APL and Dyalog.&lt;/p&gt;
    &lt;quote&gt;(JOHN SMITH) ← 100 ⍝ Creates JOHN with value 100 ⍝ and SMITH with value 100&lt;/quote&gt;
    &lt;p&gt;And if you start a variable name with a single number, the number will be printed right after the value, which is assigned to the variable name that follows:&lt;/p&gt;
    &lt;quote&gt;5B ← 12&lt;/quote&gt;
    &lt;head rend="h4"&gt;Assigning lists to variables&lt;/head&gt;
    &lt;quote&gt;PRICE ← 12.45 5.60 5.99 7.75 +VAT ← PRICE × A ⍝ A was assigned earlier&lt;/quote&gt;
    &lt;p&gt; The &lt;code&gt;+&lt;/code&gt; operator, when put before an assignment, forces a declarative
behaviour on the assigned variable – in other words, forces the
variable to be displayed.
&lt;/p&gt;
    &lt;p&gt; Using an unassigned variable causes a &lt;code&gt;VALUE ERROR&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h4"&gt;System commands&lt;/head&gt;
    &lt;p&gt; The &lt;code&gt;)OFF&lt;/code&gt; command has already been presented earlier.
&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;)VARS&lt;/code&gt; lists all variables in the workspace.
&lt;/p&gt;
    &lt;quote&gt;)VARS&lt;/quote&gt;
    &lt;p&gt;&lt;code&gt;)WSID&lt;/code&gt; shows the identity of the current workspace, which defaults to
&lt;code&gt;CLEAR WS&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;)WSID&lt;/quote&gt;
    &lt;p&gt; This command can also be used to change the identity of the workspace; we change its name to &lt;code&gt;NEW&lt;/code&gt;. The variables in it won't
change.
&lt;/p&gt;
    &lt;quote&gt;)WSID NEW&lt;/quote&gt;
    &lt;p&gt; To remove the variables (and the name), we can use &lt;code&gt;)CLEAR&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h4"&gt;Character assignments&lt;/head&gt;
    &lt;p&gt;APL doesn't only deals with numbers, it can also deal with text. Just apply quotes.&lt;/p&gt;
    &lt;quote&gt;A ← 'APL WILL PROCESS TEXT' C ← 'CHARACTERS'&lt;/quote&gt;
    &lt;p&gt; To insert quotes inside the text, use &lt;code&gt;''&lt;/code&gt;.
&lt;/p&gt;
    &lt;code&gt;NAME ← 'WHAT''S IN A NAME? '
&lt;/code&gt;
    &lt;p&gt;Other way to do that is by using double quotes around the characters.&lt;/p&gt;
    &lt;code&gt;NAME ← "WHAT'S IN A NAME? "
&lt;/code&gt;
    &lt;p&gt;Consider the following variables.&lt;/p&gt;
    &lt;quote&gt;N ← 'NET PRICE' QTY ← '230'&lt;/quote&gt;
    &lt;p&gt; Attempting to perform arithmetic on text generates a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;:
&lt;/p&gt;
    &lt;code&gt;N×10
QTY+5
&lt;/code&gt;
    &lt;head rend="h4"&gt;Multiple assignments&lt;/head&gt;
    &lt;p&gt;One can assign one value to multiple variables at the same time:&lt;/p&gt;
    &lt;code&gt;(ZAK YAK) ← 5
&lt;/code&gt;
    &lt;p&gt;Or assign many values to many variables at the same time too:&lt;/p&gt;
    &lt;quote&gt;(YEN MARK BUCK) ← 10 20 30&lt;/quote&gt;
    &lt;head rend="h4"&gt;Displaying variables together&lt;/head&gt;
    &lt;p&gt;This part is straightforward.&lt;/p&gt;
    &lt;quote&gt;N 10 NAME C X ← 18 Y ← 3 1985 X Y NAME X C 'NET PRICE: ' 10&lt;/quote&gt;
    &lt;head rend="h4"&gt;Joining lists&lt;/head&gt;
    &lt;p&gt; When writing &lt;code&gt;X Y&lt;/code&gt;, these values were joined in a list of two
elements. The first element was the number in &lt;code&gt;X&lt;/code&gt;, the second was the
two-element list in &lt;code&gt;Y&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt;Let's store this result.&lt;/p&gt;
    &lt;quote&gt;Z ← X Y&lt;/quote&gt;
    &lt;p&gt; Operations done in &lt;code&gt;Z&lt;/code&gt; will not affect &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; (also notice how &lt;code&gt;+10&lt;/code&gt; maps
elegantly into sublists!!!):
&lt;/p&gt;
    &lt;quote&gt;Z ← Z+10&lt;/quote&gt;
    &lt;p&gt;Example with characters.&lt;/p&gt;
    &lt;quote&gt;CNAME ← 'BASIL ' SNAME ← 'BRUSH' NAME ← CNAME SNAME&lt;/quote&gt;
    &lt;p&gt; Notice, though, that &lt;code&gt;NAME&lt;/code&gt; is a list of two elements, each being a list
of characters; this is called a nested variable.
&lt;/p&gt;
    &lt;head rend="h4"&gt;Joining and merging variables&lt;/head&gt;
    &lt;p&gt; The comma (&lt;code&gt;,&lt;/code&gt;) allows APL to catenate lists.
&lt;/p&gt;
    &lt;quote&gt;NAME ← CNAME,SNAME&lt;/quote&gt;
    &lt;p&gt;One can see that the variable indeed became a non-nested list of 11 characters.&lt;/p&gt;
    &lt;quote&gt;⍴NAME&lt;/quote&gt;
    &lt;head rend="h4"&gt;Simple and nested variables&lt;/head&gt;
    &lt;p&gt;Single numbers (separated by spaces) and characters make up lists.&lt;/p&gt;
    &lt;quote&gt;PIERRE ← 1 2 3 4 MIREILLE ← 'FILLE'&lt;/quote&gt;
    &lt;p&gt; Numbers enclosed in parentheses are treated as single items, so now &lt;code&gt;PIERRE&lt;/code&gt; will be a list, containing two lists.
&lt;/p&gt;
    &lt;quote&gt;PIERRE ← (1 2 3) (4 5 6 7)&lt;/quote&gt;
    &lt;p&gt;A list of character lists is easier, just enclose each sublist in quotes (if you were to put it in a single, simple list, you'd put everyone under the same quotes anyway):&lt;/p&gt;
    &lt;quote&gt;FRANCOISE ← 'UNE' 'JEUNE' 'FILLE'&lt;/quote&gt;
    &lt;head rend="h4"&gt;Mixed variables&lt;/head&gt;
    &lt;p&gt;This is not good for arithmetic, but it's useful to store characters and numbers together.&lt;/p&gt;
    &lt;quote&gt;PHONES ← 'BILL' 577332 'FRANK' 886331&lt;/quote&gt;
    &lt;head rend="h4"&gt;Exercises&lt;/head&gt;
    &lt;p&gt;Let's start with a clean workspace.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q1&lt;p&gt;Enter statements which:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Assign the numbers &lt;code&gt;22 2 2007&lt;/code&gt;to three variables called respectively&lt;code&gt;D&lt;/code&gt;,&lt;code&gt;M&lt;/code&gt;and&lt;code&gt;Y&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;(D M Y) ← 22 2 2007&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Assign the characters &lt;code&gt;TODAY'S DATE:&lt;/code&gt;to a variable called&lt;code&gt;DATE&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;code&gt;DATE ← 'TODAY''S DATE: '&lt;/code&gt;&lt;list rend="ul"&gt;&lt;item&gt;Produce the display: &lt;code&gt;TODAY'S DATE: 22 2 2007&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;DATE D M Y&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Assign the numbers &lt;/item&gt;
      &lt;item&gt;Q2&lt;p&gt;Set up a variable&lt;/p&gt;&lt;code&gt;CONV&lt;/code&gt;which contains a constant for converting pounds to kilos. (1lb = 0.454Kg and 14lb = 1 stone). Use&lt;code&gt;CONV&lt;/code&gt;to convert your weight (to the nearest stone) into kilograms. Reduce the result by 10%, round it down, and display it.&lt;quote&gt;⍝ 1 stone = 14 lbs. ⍝ 1 lb = 0.454 Kg. ⍝ Let's pretend I weight 11.5 stones. CONV ← .454 MYWEIGHT ← ⌊11.5×CONV×14×.9 MYWEIGHT&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q3&lt;p&gt;The cost prices of four items of stock are £8, 6, 12, 4 respectively. The markup on these items is 100%. Three other items cost respectively £16, 13 and 7. Their markup is 75%. Calculate the fully inclusive price of each item (with VAT at 17%). Display the prices (rounded up) with the caption:&lt;/p&gt;&lt;code&gt;'PRICE+VAT: '&lt;/code&gt;&lt;quote&gt;ITEMS_A ← 2×8 6 12 4 ITEMS_B ← 1.75×16 13 7 ITEMS ← ⌈1.17×ITEMS_A,ITEMS_B 'PRICE+VAT: ' ITEMS&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q4&lt;code&gt;TEST1&lt;/code&gt;contains a student's exam marks for each of seven subjects (65 72 54 80 67 60 59).&lt;code&gt;TEST2&lt;/code&gt;contains his marks for the same subjects gained at a different test (75 70 60 74 58 61 50). Produce a list consisting of his higher mark for each subject.&lt;quote&gt;TEST1 ← 65 72 54 80 67 60 59 TEST2 ← 75 70 60 74 58 61 50 TEST1 ⌈ TEST2&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q5&lt;p&gt;Which of the following will produce error messages? Why?&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;The expression &lt;code&gt;RATE ← '3.7×3'&lt;/code&gt;is a valid assignment of a list of characters, though it might be a logic error.&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;10+10 '←21'&lt;/code&gt;produces a&lt;code&gt;DOMAIN ERROR&lt;/code&gt;, because it tries to sum&lt;code&gt;10&lt;/code&gt;over a list containing the number&lt;code&gt;10&lt;/code&gt;and the list of characters&lt;code&gt;'←21'&lt;/code&gt;, which cannot perform arithmetic operations.&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;100×RATE&lt;/code&gt;produces a&lt;code&gt;DOMAIN ERROR&lt;/code&gt;, because it tries to multiply by&lt;code&gt;100&lt;/code&gt;over a list containing characters (&lt;code&gt;RATE&lt;/code&gt;), which cannot perform arithmetic operations.&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;SYMBOLS ← '¯&amp;lt;≤=≥'&lt;/code&gt;is perfectly valid and creates a list of characters. But it might not be supported by some APL implementations (GNU APL supports it).&lt;/item&gt;&lt;item&gt;The expression &lt;code&gt;3+'232'&lt;/code&gt;produces a&lt;code&gt;DOMAIN ERROR&lt;/code&gt;, because it tries to sum&lt;code&gt;3&lt;/code&gt;over a list of characters, which cannot perform arithmetic operations.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;The expression &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Cleanup&lt;/head&gt;
    &lt;p&gt;From now on, we clear the variables and the workspace across chapters.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h3"&gt;Tables&lt;/head&gt;
    &lt;p&gt;We won't be typing a lot of things here, that is insane! Let's see how to generate our tables.&lt;/p&gt;
    &lt;quote&gt;⍝ Tables&lt;/quote&gt;
    &lt;head rend="h4"&gt;The Roll function&lt;/head&gt;
    &lt;p&gt;&lt;code&gt;?&lt;/code&gt; is the Roll function, also called Random or Deal.
&lt;/p&gt;
    &lt;p&gt;This generates numbers on range 1 to 100:&lt;/p&gt;
    &lt;code&gt;? 100
&lt;/code&gt;
    &lt;p&gt; The two-argument form generates a list of &lt;code&gt;n&lt;/code&gt; (left) unique numbers from
1 to &lt;code&gt;m&lt;/code&gt; (right):
&lt;/p&gt;
    &lt;quote&gt;50 ? 100&lt;/quote&gt;
    &lt;p&gt; In fact, it should always be true that &lt;code&gt;n ≤ m&lt;/code&gt;, since the generated
numbers are unique. If not, we'll have a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; Both &lt;code&gt;n&lt;/code&gt; and &lt;code&gt;m&lt;/code&gt; can be replaced by variables as well.
&lt;/p&gt;
    &lt;head rend="h4"&gt;The Iota function&lt;/head&gt;
    &lt;p&gt; Iota, or Index, generates a sequence of numbers from 1 to &lt;code&gt;m&lt;/code&gt; in its
one-argument form.
&lt;/p&gt;
    &lt;code&gt;⍳100
&lt;/code&gt;
    &lt;head rend="h4"&gt;Setting up tables&lt;/head&gt;
    &lt;p&gt; When entering tables, we use dyadic for of the rho (&lt;code&gt;⍴&lt;/code&gt;) function, also
called Shape or Reshape. The list before &lt;code&gt;⍴&lt;/code&gt; states the order of the
table; the following elements are its rows, element by element.
&lt;/p&gt;
    &lt;quote&gt;4 3 ⍴ 10 20 30 40 50 60 70 80 90 100 110 120&lt;/quote&gt;
    &lt;p&gt;Let's generate twelve random numbers, then display them in a 4×3 table.&lt;/p&gt;
    &lt;quote&gt;DATA ← 12 ? 100 4 3 ⍴ DATA&lt;/quote&gt;
    &lt;p&gt; If you feed &lt;code&gt;⍴&lt;/code&gt; less numbers than expected, APL just keeps wrapping
these numbers. If you feed more than expected, APL uses just enough
numbers to build the table.
&lt;/p&gt;
    &lt;quote&gt;4 3 ⍴ 1 2 3 4 5&lt;/quote&gt;
    &lt;p&gt;And so follows that supplying one number fills the whole table:&lt;/p&gt;
    &lt;quote&gt;3 5 ⍴ 1&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extra bit&lt;p&gt;I wonder about identity matrices! Let's take a 3×3 matrix. If we type a&lt;/p&gt;&lt;code&gt;1&lt;/code&gt;, and then a number&lt;code&gt;n&lt;/code&gt;of zeroes (corresponding to the matrix order), then I suppose we can build an identity matrix…&lt;quote&gt;3 3 ⍴ 1 0 0 0&lt;/quote&gt;&lt;p&gt;Indeed! But wait: I don't know how to build functions in APL yet, but I suppose we can take this arbitrary number of zeroes and write them in ⍴-notation too.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Generate a list of &lt;code&gt;n&lt;/code&gt;zeroes;&lt;/item&gt;&lt;item&gt;Catenate a number &lt;code&gt;1&lt;/code&gt;in front of it;&lt;/item&gt;&lt;item&gt;Feed it as filling elements to the second ⍴.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;4 4 ⍴ 1,(4 ⍴ 0)&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Generate a list of &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Arithmetic on tables&lt;/head&gt;
    &lt;p&gt;Let's begin.&lt;/p&gt;
    &lt;quote&gt;SALES ← 3 3⍴20 13 8 30 43 48 3 50 21 SALES&lt;/quote&gt;
    &lt;p&gt;Performing arithmetic on a table affects every number, just like in a list.&lt;/p&gt;
    &lt;code&gt;SALES×10
&lt;/code&gt;
    &lt;p&gt;Let's set up another table.&lt;/p&gt;
    &lt;quote&gt;PRICES ← 2 3 ⍴ 21 2 12 47 33 1&lt;/quote&gt;
    &lt;p&gt; This operation causes a &lt;code&gt;LENGTH ERROR&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;SALES×PRICES&lt;/quote&gt;
    &lt;p&gt; This is because &lt;code&gt;SALES&lt;/code&gt; is 3×3 while &lt;code&gt;PRICES&lt;/code&gt; is 2×3. So let's reshape
&lt;code&gt;SALES&lt;/code&gt; into a 3×2 table. This way, both of them will have the same
number of elements.
&lt;/p&gt;
    &lt;quote&gt;SALES ← 3 2⍴SALES&lt;/quote&gt;
    &lt;p&gt;But that still won't do… we're trying to multiply elements of same address here, not make matrix multiplication. Let's try again.&lt;/p&gt;
    &lt;quote&gt;SALES ← 2 3⍴SALES&lt;/quote&gt;
    &lt;p&gt;Ok, now we're good and we can proceed.&lt;/p&gt;
    &lt;quote&gt;TOTAL ← SALES×PRICES SALES-PRICES&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Extra bits&lt;p&gt;Let's build a nice table.&lt;/p&gt;&lt;p&gt;First table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Build a sequence from &lt;code&gt;1&lt;/code&gt;to&lt;code&gt;25&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Create a &lt;code&gt;5×5&lt;/code&gt;table with it.&lt;/item&gt;&lt;item&gt;Take the reciprocal of each number.&lt;/item&gt;&lt;item&gt;Multiply each element by &lt;code&gt;10&lt;/code&gt;.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Second table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Take a sequence from &lt;code&gt;1&lt;/code&gt;to&lt;code&gt;25&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Add &lt;code&gt;25&lt;/code&gt;to each element.&lt;/item&gt;&lt;item&gt;Create a &lt;code&gt;5×5&lt;/code&gt;table with it.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Final table:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Multiply each element of first table by each element of second table.&lt;/item&gt;&lt;item&gt;Round every number by adding &lt;code&gt;¯.5&lt;/code&gt;to each number and taking their ceiling.&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;TOTAL ← ⌈¯.5+(5 5⍴25+⍳25)×10×÷5 5⍴⍳25&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Build a sequence from &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Catenating tables&lt;/head&gt;
    &lt;p&gt;Catenating tables produce a big table. Each row is catenated like a list. Therefore, catenated tables must have the same number of rows.&lt;/p&gt;
    &lt;quote&gt;SALES,PRICES&lt;/quote&gt;
    &lt;p&gt;Let's test it a little more.&lt;/p&gt;
    &lt;quote&gt;LITTLE ← 2 2⍴1 MEDIUM ← 2 6⍴5 BIG ← LITTLE,MEDIUM&lt;/quote&gt;
    &lt;p&gt; To perform &lt;code&gt;LITTLE+MEDIUM&lt;/code&gt;, we pad &lt;code&gt;LITTLE&lt;/code&gt; with a table of zeroes.
&lt;/p&gt;
    &lt;quote&gt;ZEROES ← 2 4⍴0 LITTLE ← LITTLE,ZEROES LITTLE+MEDIUM&lt;/quote&gt;
    &lt;p&gt; We could also have the zeroes on the other side; let's reset &lt;code&gt;LITTLE&lt;/code&gt;
and do it.
&lt;/p&gt;
    &lt;quote&gt;LITTLE ← 2 2⍴1 LITTLE ← ZEROES,LITTLE LITTLE+MEDIUM&lt;/quote&gt;
    &lt;p&gt;Since there is this kind of ambiguity, that is the reason why APL doesn't do arithmetic on data of unequal size.&lt;/p&gt;
    &lt;head rend="h4"&gt;Selecting elements&lt;/head&gt;
    &lt;p&gt; Let's set up a &lt;code&gt;4×3&lt;/code&gt; table for the next example.
&lt;/p&gt;
    &lt;quote&gt;+TABLE ← 4 3⍴2 12 15 4 11 7 1 16 8 20 19 9&lt;/quote&gt;
    &lt;p&gt; Let's select the &lt;code&gt;9&lt;/code&gt; in the bottom row, rightmost column.
&lt;/p&gt;
    &lt;quote&gt;TABLE[4;3]&lt;/quote&gt;
    &lt;p&gt;We sum the element at Row 1, Column 2 to the element at Row 2, Column 2. Then we put it on Row 3, Column 2:&lt;/p&gt;
    &lt;quote&gt;TABLE[3;2] ← TABLE[1;2] + TABLE[2;2]&lt;/quote&gt;
    &lt;p&gt;We can select more than one element in a row, or even in a column.&lt;/p&gt;
    &lt;quote&gt;TABLE[1;1 2] TABLE[1 2;2]&lt;/quote&gt;
    &lt;p&gt;To select entire rows or columns, omit the other parameter.&lt;/p&gt;
    &lt;quote&gt;TABLE[1;] TABLE[;1]&lt;/quote&gt;
    &lt;p&gt;Let's replace the numbers in column 3 with the sum of numbers in columns 1 and 2.&lt;/p&gt;
    &lt;quote&gt;TABLE[;3] ← TABLE[;1] + TABLE[;2]&lt;/quote&gt;
    &lt;p&gt;Also note that indexing can also be applied on lists.&lt;/p&gt;
    &lt;quote&gt;LIST ← 8 1 90 4 LIST[2]&lt;/quote&gt;
    &lt;head rend="h4"&gt;Dimensions&lt;/head&gt;
    &lt;p&gt;In APL, data has dimensions.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Single numbers have dimension zero.&lt;/item&gt;
      &lt;item&gt;A list has one dimension.&lt;/item&gt;
      &lt;item&gt;The previous tables have two dimensions.&lt;/item&gt;
      &lt;item&gt;Three-dimensional tables/arrays are like cubes, having depth, height and length.&lt;/item&gt;
      &lt;item&gt;It is possible to create arrays of many dimensions in APL.&lt;/item&gt;
    &lt;/list&gt;
    &lt;quote&gt;SALES ← 6 4⍴24?50&lt;/quote&gt;
    &lt;p&gt; In &lt;code&gt;SALES&lt;/code&gt;, the salesmen are rows, the products are columns.
If we wanted to represent more than one region – say, three regions
–, we'd need another dimension.
&lt;/p&gt;
    &lt;quote&gt;+SALES ← 3 6 4⍴72?100 SALES[2;5;4] ⍝ Plane 2, Row 5, Column 4 SALES[2;;] ⍝ Plane 2&lt;/quote&gt;
    &lt;head rend="h4"&gt;Enquiring about the size of data&lt;/head&gt;
    &lt;p&gt; While the dyadic usage of &lt;code&gt;⍴&lt;/code&gt; involves creating arrays, the monadic
usage of &lt;code&gt;⍴&lt;/code&gt; allows one to enquire about the size (or shape) of existing
tables, variables, etc.
&lt;/p&gt;
    &lt;quote&gt;⍴SALES&lt;/quote&gt;
    &lt;p&gt;Let's create some data.&lt;/p&gt;
    &lt;quote&gt;TABLE ← 5 3⍴15?20 LIST ← ⍳6 NUM ← 234&lt;/quote&gt;
    &lt;p&gt;Now let's ask about their shape.&lt;/p&gt;
    &lt;quote&gt;⍴TABLE ⍴LIST ⍴NUM&lt;/quote&gt;
    &lt;p&gt; Notice that, since &lt;code&gt;NUM&lt;/code&gt; has no shape (equivalent to a point), APL gives
an empty response.
&lt;/p&gt;
    &lt;p&gt;We don't need variables to do this kind of thing, though. We can apply directly to literals.&lt;/p&gt;
    &lt;quote&gt;⍴12 61 502 1 26 0 11 ⍴'SHAMBOLIOSIS'&lt;/quote&gt;
    &lt;head rend="h4"&gt;Tables of characters&lt;/head&gt;
    &lt;p&gt;This is also straightforward; characters are stored as a list of characters. Let's do some experiments.&lt;/p&gt;
    &lt;quote&gt;⍝ Compare these two. ALF ← 3 5⍴'ABCDE' NUM ← 3 5⍴12345 MYNAME ← 'GORSUCH' ⍴MYNAME 3 7⍴MYNAME 3 14⍴MYNAME 3 18⍴MYNAME MYNAME ← 'GORSUCH ' ⍴MYNAME 3 40⍴MYNAME&lt;/quote&gt;
    &lt;p&gt;Solution for the given example.&lt;/p&gt;
    &lt;quote&gt;4 11⍴'ADAMS CHATER PRENDERGASTLEE '&lt;/quote&gt;
    &lt;head rend="h4"&gt;Mixed tables&lt;/head&gt;
    &lt;p&gt;We can build tables containing characters and numbers, just like the lists.&lt;/p&gt;
    &lt;quote&gt;MIXTURE ← 3 3⍴'A' 1 'B' 'C' 2 'D' 'E' 3 'F'&lt;/quote&gt;
    &lt;head rend="h4"&gt;Nested tables&lt;/head&gt;
    &lt;p&gt;Tables can contain other tables or lists.&lt;/p&gt;
    &lt;quote&gt;NEST ← 2 3⍴(2 2⍴⍳4) (⍳5) 'A NAME' (2 4⍴⍳8) 23 (3 4⍴'NAME') ⍴NEST&lt;/quote&gt;
    &lt;head rend="h4"&gt;Depth&lt;/head&gt;
    &lt;p&gt; The depth (&lt;code&gt;≡&lt;/code&gt;) function shows the degree of nesting in a variable.
&lt;/p&gt;
    &lt;quote&gt;≡45 ⍝ Values have depth 0 ≡1 2 3 ⍝ Lists have depth 1 ≡2 2⍴3 4 5 6 ⍝ Tables too&lt;/quote&gt;
    &lt;p&gt; Now let's check the depth of &lt;code&gt;NEST&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;≡NEST&lt;/quote&gt;
    &lt;p&gt;When at least one element of a list or table is also a list or table, the depth becomes 2; and so on, as long as you have child list/tables inside child list/tables:&lt;/p&gt;
    &lt;quote&gt;BIG_NEST ← NEST NEST ⍴BIG_NEST ≡BIG_NEST&lt;/quote&gt;
    &lt;p&gt; Since the components of &lt;code&gt;BIG_NEST&lt;/code&gt; already have depth 2, &lt;code&gt;BIG_NEST&lt;/code&gt; adds
one more layer of depth.
&lt;/p&gt;
    &lt;head rend="h4"&gt;Practice&lt;/head&gt;
    &lt;p&gt;Some interesting snippets showcasing the strength of APL: combining functions.&lt;/p&gt;
    &lt;quote&gt;⍝ Playing with sizes of character lists (⍴'ABC','DEF')+⍴'GHI' ⍝ Selecting the first nine numbers in row 1 of a big table TABLE ← 10 10⍴100?100 TABLE[1;⍳9]&lt;/quote&gt;
    &lt;head rend="h4"&gt;Exercises&lt;/head&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Q1&lt;p&gt;Set up a four-row one-column table called&lt;/p&gt;&lt;code&gt;MILES&lt;/code&gt;containing&lt;code&gt;300 42 25 140&lt;/code&gt;.&lt;quote&gt;MILES ← 4 1⍴300 42 25 140&lt;/quote&gt;&lt;p&gt;And a similarly shaped table called&lt;/p&gt;&lt;code&gt;RATES&lt;/code&gt;containing&lt;code&gt;27.5 15 27.5 27.5&lt;/code&gt;.&lt;quote&gt;RATES ← 4 1⍴27.5 15 27.5 27.5&lt;/quote&gt;&lt;p&gt;Multiply&lt;/p&gt;&lt;code&gt;RATES&lt;/code&gt;by&lt;code&gt;MILES&lt;/code&gt;, then multiply the result by&lt;code&gt;0.01&lt;/code&gt;to produce a table called&lt;code&gt;EXPENSES&lt;/code&gt;.&lt;code&gt;+EXPENSES ← .01×RATES×MILES&lt;/code&gt;&lt;/item&gt;
      &lt;item&gt;Q2&lt;p&gt;Change the number in column 1 row 3 of&lt;/p&gt;&lt;code&gt;MILES&lt;/code&gt;from&lt;code&gt;25&lt;/code&gt;to&lt;code&gt;250&lt;/code&gt;. Again, multiply&lt;code&gt;RATES&lt;/code&gt;by&lt;code&gt;MILES&lt;/code&gt;and the result by&lt;code&gt;0.01&lt;/code&gt;to give&lt;code&gt;EXPENSES&lt;/code&gt;, then reformat&lt;code&gt;EXPENSES&lt;/code&gt;to produce a one-row four-column table.&lt;quote&gt;MILES[3;1] ← 250 +EXPENSES ← (.01×RATES×MILES)[;1]&lt;/quote&gt;&lt;p&gt;Alternative way to change&lt;/p&gt;&lt;code&gt;EXPENSES&lt;/code&gt;; interesting way to store and immediately use a variable.&lt;quote&gt;+EXPENSES ← 1 4⍴EXPENSES ← .01×RATES×MILES&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q3&lt;p&gt;Define&lt;/p&gt;&lt;code&gt;X&lt;/code&gt;as a three-row ten-column table containing random numbers, and&lt;code&gt;Y&lt;/code&gt;as a three-row four-column table also containing random numbers. Add&lt;code&gt;X&lt;/code&gt;to&lt;code&gt;Y&lt;/code&gt;, first taking whatever steps you think necessary to enable the operation to take place.&lt;quote&gt;⍝ Defining the tables X ← 3 10⍴30?30 Y ← 3 4⍴30+12?12 ⍝ To sum Y into X, we catenate zeroes to Y, ⍝ extending it. X+Y,3 ((⍴X)[2]-(⍴Y)[2])⍴0&lt;/quote&gt;&lt;p&gt;Since the problem did not specify where to add the columns, here is an alternative which catenates the zeroes to the left of&lt;/p&gt;&lt;code&gt;Y&lt;/code&gt;:&lt;quote&gt;X+(3 ((⍴X)[2]-(⍴Y)[2])⍴0),Y&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q4&lt;p&gt;Using table&lt;/p&gt;&lt;code&gt;X&lt;/code&gt;, add the first and second rows and replace the third row with the result of the addition.&lt;quote&gt;X[3;] ← X[1;]+X[2;]&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q5&lt;p&gt;Create a table which [displays&lt;/p&gt;&lt;code&gt;APL ROCKS&lt;/code&gt;in vertical orientation]:&lt;quote&gt;9 1⍴'APL ROCKS'&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Q6&lt;p&gt;What will be the result of each of these&lt;/p&gt;&lt;code&gt;⍴&lt;/code&gt;statements? Predict each result before you press ENTER.&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;⍴'ABC DEF'&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;7&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍴480 0 1.2&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;3&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;TABLE ← 10 10⍴100⍴1000&lt;/code&gt;&lt;code&gt;⍴TABLE&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;10 10&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍴'R'&lt;/code&gt;&lt;lb/&gt;→ (empty)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍴'480 0 1.2'&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;9&lt;/code&gt;&lt;/item&gt;&lt;item&gt;&lt;code&gt;TABLE ← 2 10 3⍴100⍴100&lt;/code&gt;&lt;code&gt;⍴TABLE&lt;/code&gt;&lt;lb/&gt;→&lt;code&gt;2 10 3&lt;/code&gt;&lt;/item&gt;&lt;/list&gt;&lt;p&gt;NOTE: Recall why&lt;/p&gt;&lt;code&gt;⍴'R'&lt;/code&gt;gives an empty response: a single value is equivalent to a point, which has no size/dimension/shape.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Cleanup&lt;/head&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h3"&gt;Writing a function&lt;/head&gt;
    &lt;quote&gt;⍝ Writing a function&lt;/quote&gt;
    &lt;head rend="h4"&gt;Precondition: the Slash operator&lt;/head&gt;
    &lt;p&gt; The Slash (&lt;code&gt;/&lt;/code&gt;) or Reduce operator is not a function; it modifies or
extends the operation of the functions it is used with.
&lt;/p&gt;
    &lt;p&gt;It works as if by putting the operator between the numbers.&lt;/p&gt;
    &lt;quote&gt;+/ 1 6 3 4 ×/ 1 2 3 4&lt;/quote&gt;
    &lt;p&gt;This can be done on a table too, however it will sum in a row basis.&lt;/p&gt;
    &lt;quote&gt;TABLE ← 3 3⍴⍳9 TABLE +/ TABLE&lt;/quote&gt;
    &lt;p&gt;We can, however, apply Reduce twice to obtain the entire sum.&lt;/p&gt;
    &lt;quote&gt;+/+/ TABLE&lt;/quote&gt;
    &lt;p&gt; Useful combination: To select the largest number in a list, use &lt;code&gt;⌈&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;⌈/ 75 72 78 90 69 77 81 88&lt;/quote&gt;
    &lt;p&gt; The opposite equivalent (&lt;code&gt;⌊&lt;/code&gt;) selects the smallest number:
&lt;/p&gt;
    &lt;quote&gt;⌊/ 75 72 78 90 69 77 81 88&lt;/quote&gt;
    &lt;p&gt; A final example: We take the sum of &lt;code&gt;X&lt;/code&gt; (which is &lt;code&gt;15&lt;/code&gt;) and divide it by
&lt;code&gt;X&lt;/code&gt;'s shape (&lt;code&gt;5&lt;/code&gt;). This yields &lt;code&gt;3&lt;/code&gt;, as expected of calculating the average
of a number.
&lt;/p&gt;
    &lt;code&gt;X ← ⍳5
(+/ X)÷⍴X
&lt;/code&gt;
    &lt;head rend="h4"&gt;User functions&lt;/head&gt;
    &lt;p&gt;Now we'll preserve statements.&lt;/p&gt;
    &lt;p&gt;It seems some APL editors have a built-in editor. For example, one can use the following commands:&lt;/p&gt;
    &lt;quote&gt;)EDIT MYFUNC ⍝ On modern editors )ED MYFUNC ⍝ On Dyalog ∇ ⍝ On older editors, and on GNU APL as well&lt;/quote&gt;
    &lt;p&gt; GNU APL also calls a new buffer when defining a function, under Emacs. We can also send the following region to the interpreter no problem. We just need to type in the function (&lt;code&gt;∇&lt;/code&gt;) operator, which
starts the input mode.
&lt;/p&gt;
    &lt;p&gt; Typing &lt;code&gt;∇&lt;/code&gt; again goes back to calculator mode.
&lt;/p&gt;
    &lt;quote&gt;∇TRY1 'Type some numbers: ' NUM ← ⎕ ⍝ Asks for user input 'Total is: ' (+/ NUM) ∇&lt;/quote&gt;
    &lt;p&gt; In case this function doesn't work when typing, just use &lt;code&gt;∇TRY1&lt;/code&gt; to
change its definition on the editor.
&lt;/p&gt;
    &lt;p&gt; This defines a user function &lt;code&gt;TRY1&lt;/code&gt;, which takes no arguments. The Quad
(&lt;code&gt;⎕&lt;/code&gt;) operator calls in for user input.
&lt;/p&gt;
    &lt;p&gt; You can edit a function such as &lt;code&gt;TRY1&lt;/code&gt; anytime, by typing &lt;code&gt;∇TRY1&lt;/code&gt; on the
REPL; other APL implementations will allow you to use the command
&lt;code&gt;)EDIT TRY1&lt;/code&gt;, for example.
&lt;/p&gt;
    &lt;p&gt;Here is another example:&lt;/p&gt;
    &lt;quote&gt;∇TRY2 'Type some numbers: ' NUM ← ⎕ 'You have entered' (⍴NUM) 'numbers' ∇&lt;/quote&gt;
    &lt;p&gt;And as requested, here is a way to calculate the average of some numbers:&lt;/p&gt;
    &lt;quote&gt;∇AVERAGE 'Type some numbers:' NUM ← ⎕ 'Integer average of these numbers is:' (⌊(+/ NUM)÷⍴NUM) ∇&lt;/quote&gt;
    &lt;p&gt;One more definition.&lt;/p&gt;
    &lt;quote&gt;∇TRY3 'Type some numbers:' NUM ← ⎕ 'You have entered' (⍴NUM) 'numbers' 'The biggest was' (⌈/ NUM) 'The smallest was' (⌊/ NUM) 'Sum of numbers is' (+/ NUM) 'Integer average of numbers is' (⌊(+/ NUM)÷⍴NUM) ∇&lt;/quote&gt;
    &lt;head rend="h4"&gt;Saving a workspace&lt;/head&gt;
    &lt;p&gt;You can check out the user-defined functions in your workspace with this command:&lt;/p&gt;
    &lt;quote&gt;)FNS&lt;/quote&gt;
    &lt;p&gt; There are some extra variables as well (check by using &lt;code&gt;)VARS&lt;/code&gt;), so we
need to erase them:
&lt;/p&gt;
    &lt;quote&gt;)ERASE TABLE X&lt;/quote&gt;
    &lt;p&gt;Now we'll save the current workspace. First let's set the workspace ID to the filename where it should be salved.&lt;/p&gt;
    &lt;p&gt;Notice that we are using Unix notation and the XML extension. This is a requirement for GNU APL.&lt;/p&gt;
    &lt;quote&gt;)WSID ./MyFirstWS.xml&lt;/quote&gt;
    &lt;p&gt;Windows users, using NARS2000, should do something like:&lt;/p&gt;
    &lt;code&gt;)WSID 'c:\foo\MyFirstWS'
&lt;/code&gt;
    &lt;p&gt;Now we use the command to save.&lt;/p&gt;
    &lt;quote&gt;)SAVE&lt;/quote&gt;
    &lt;p&gt;My result was:&lt;/p&gt;
    &lt;quote&gt;2019-08-06 12:56:35 (GMT-3) ./MyFirstWS.xml&lt;/quote&gt;
    &lt;p&gt;Now we can safely clear the workspace.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;p&gt;To load the workspace again, use the load command with the file name.&lt;/p&gt;
    &lt;quote&gt;)LOAD ./MyFirstWS.xml&lt;/quote&gt;
    &lt;p&gt; NOTE: GNU APL instructs to use &lt;code&gt;)COPY&lt;/code&gt; instead.
&lt;/p&gt;
    &lt;head rend="h4"&gt;User functions with arguments&lt;/head&gt;
    &lt;p&gt;User functions can have no arguments, one argument or two arguments.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Monadic&lt;p&gt;We intent to build a function which averages the numbers in a list. So let's define it.&lt;/p&gt;&lt;code&gt;∇AV X (+/ X)÷⍴X ∇&lt;/code&gt;&lt;p&gt;Now we can use it properly.&lt;/p&gt;&lt;quote&gt;AV 12 7 3 1 AV 3 8 1 4 AV 192 4534 12 0 2 NUM ← ⍳5 AV NUM&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Dyadic&lt;p&gt;A dyadic function should be declared with arguments to its left and its right:&lt;/p&gt;&lt;code&gt;∇A SUM B A+B ∇&lt;/code&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Using function results in other expressions&lt;/head&gt;
    &lt;p&gt; To do so, we need to rewrite the function to enable that. See this rewriting of &lt;code&gt;AV&lt;/code&gt;.
&lt;/p&gt;
    &lt;code&gt;∇R←AV X
  R←(+/ X)÷⍴X
∇
&lt;/code&gt;
    &lt;p&gt;An example of usage:&lt;/p&gt;
    &lt;quote&gt;¯3 + AV 3 8 1 4&lt;/quote&gt;
    &lt;p&gt;The same can be done to dyadic functions.&lt;/p&gt;
    &lt;code&gt;∇R←A SUM B
  R←A+B
∇
&lt;/code&gt;
    &lt;head rend="h4"&gt;Cleanup&lt;/head&gt;
    &lt;quote&gt;)ERASE NUM )SAVE )CLEAR&lt;/quote&gt;
    &lt;head rend="h2"&gt;APL Concepts&lt;/head&gt;
    &lt;head rend="h3"&gt;Overview of the APL System&lt;/head&gt;
    &lt;p&gt;APL is an interpreted language.&lt;/p&gt;
    &lt;p&gt;APL reserves an area in the RAM, which is called a workspace. This is were programs and data reside. Other workspaces can be loaded at will for calculation and processing.&lt;/p&gt;
    &lt;head rend="h4"&gt;Data&lt;/head&gt;
    &lt;p&gt;Data is acquired by typing or from files. All data is held in arrays or scalars.&lt;/p&gt;
    &lt;p&gt;GNU APL supports complex numbers.&lt;/p&gt;
    &lt;p&gt;Formal names will be used from now on.&lt;/p&gt;
    &lt;head rend="h4"&gt;Modes&lt;/head&gt;
    &lt;p&gt;APL uses a modal interpreter. Calculator mode executes statements as entered. Definition mode does not execute immediately, and stores statements as a user-defined function or operator. Function execution mode happens when you run a user-defined function or operator.&lt;/p&gt;
    &lt;head rend="h4"&gt;Built-in functions and operators&lt;/head&gt;
    &lt;p&gt;APL has about 50 built-in functions which can be invoked by a single symbol.&lt;/p&gt;
    &lt;p&gt;Most functions can perform two different opperations depending on whether they're used with one or two arguments.&lt;/p&gt;
    &lt;p&gt;APL also has five built-in operators. Combining an operator with its operands creates a derived function.&lt;/p&gt;
    &lt;head rend="h4"&gt;System functions and variables&lt;/head&gt;
    &lt;p&gt;Part of APL system, yet not part of APL language. Used to extend facilities provided by original APL, they vary from one vendor to another. Could also be tailored to the system which it is running.&lt;/p&gt;
    &lt;p&gt; System functions such as &lt;code&gt;⎕NREAD&lt;/code&gt; and &lt;code&gt;⎕NWRITE&lt;/code&gt; (with names starting with
a Quad &lt;code&gt;⎕&lt;/code&gt;) read and write data from files, and are distinguishable from
the rest by their starting character.
&lt;/p&gt;
    &lt;head rend="h4"&gt;System commands&lt;/head&gt;
    &lt;p&gt; They are also not part of the APL language itself, but are crucial to managing the workspace. They always start with a &lt;code&gt;)&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h4"&gt;User-defined functions and operators&lt;/head&gt;
    &lt;p&gt;Functions or operators which can be written by the user. Consists of APL statements that have a name. Functions are edited through the function editor, which can also be used to tweak a function.&lt;/p&gt;
    &lt;head rend="h4"&gt;Files&lt;/head&gt;
    &lt;p&gt;Files are usually not necessary on APL, given the convenience of workspaces, being only really required when dealing with big projects. When that time comes, APL has facilities for that; and workspaces can be shared between users.&lt;/p&gt;
    &lt;head rend="h4"&gt;Error handling&lt;/head&gt;
    &lt;p&gt;APL provides facilities for error trapping and diagnostics.&lt;/p&gt;
    &lt;head rend="h3"&gt;The Workspace&lt;/head&gt;
    &lt;p&gt;Workspaces are containers for functions and data, and can be saved on disk by using commands.&lt;/p&gt;
    &lt;p&gt;APL also makes it easy to create test data for functions. Since prototyping can be done so quickly, APL is sometimes referred to as a "tool of thought".&lt;/p&gt;
    &lt;head rend="h4"&gt;Functions, operators, classes&lt;/head&gt;
    &lt;p&gt;Functions can take 0, 1 or 2 arguments; arguments to functions are always arrays.&lt;/p&gt;
    &lt;p&gt; Operators look like functions, but takes either one or two operands, which can be functions (e.g. the Each operator &lt;code&gt;¨&lt;/code&gt;). They can also be
defined.
&lt;/p&gt;
    &lt;p&gt;Classes are a collection of functions, operators and data (named properties). Acts as a template to create objects. Classes are supported in Dyalog, but not in GNU APL.&lt;/p&gt;
    &lt;head rend="h4"&gt;Workspace size&lt;/head&gt;
    &lt;p&gt; Some APLS allow changing the size of your workspace with &lt;code&gt;)CLEAR 50MB&lt;/code&gt;,
for example.
&lt;/p&gt;
    &lt;p&gt;To check the amount of free space on your workspace, use the system function Workspace Available:&lt;/p&gt;
    &lt;code&gt;⎕WA
&lt;/code&gt;
    &lt;head rend="h4"&gt;Managing the workspace&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Internal workspace commands&lt;p&gt;These have already been discussed.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;)CLEAR&lt;/code&gt;: Clear workspace. Erases all variables, functions, operators and classes.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)ERASE&lt;/code&gt;: Erases individual classes.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)VARS&lt;/code&gt;: Lists all user-defined variables in the workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)FNS&lt;/code&gt;: Lists all user-defined functions in the workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)OPS&lt;/code&gt;: Lists all user-defined operators in the workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)CLASSES&lt;/code&gt;: Lists all user-defined classes in the workspace. Can be used in Dyalog.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;External workspace commands&lt;p&gt;Some of these have already been discussed.&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;)SAVE myWorkspace&lt;/code&gt;saves a workspace to disk. Append&lt;code&gt;.xml&lt;/code&gt;if you're using GNU APL.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)LOAD myWorkspace&lt;/code&gt;loads an entire workspace back into memory; the workspace in memory is overwritten.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)COPY&lt;/code&gt;can be used to copy a function from a workspace in disk, but does not overwrite the current workspace.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)DROP&lt;/code&gt;deletes a workspace on disk.&lt;/item&gt;&lt;item&gt;&lt;code&gt;)LIB&lt;/code&gt;shows the names of the workspaces stored on disk.&lt;/item&gt;&lt;/list&gt;&lt;p&gt;Save locations vary due to APL implementations.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System variables&lt;/head&gt;
    &lt;p&gt;Here are some useful system variables which you may use.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;⎕WA&lt;/code&gt;: Workspace Available. Number of available bytes for use in workspace.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕PP&lt;/code&gt;: Print Precision. Number of digits displayed in numeric output.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕PW&lt;/code&gt;: Print Width. Max number of characters in each printed line.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕LX&lt;/code&gt;: Latent Expression. This variable contains an expression or user-defined function which is executed when the workspace is loaded; effectively, a setup function for the current workspace. Empty by default.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕IO&lt;/code&gt;: Index Origin. Stores the value where indexes start. GNU APL starts at 1, but can be changed to 0.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System functions&lt;/head&gt;
    &lt;p&gt;These vary from vendor to vendor, so there is no guarantee that these will work in your APL. For example:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;⎕NL&lt;/code&gt;: Name List. Produces a list of variables, functions, operators or classes.&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;⎕EX&lt;/code&gt;: Expunge. Expunges individual APL objects.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;System functions are designed to be used in user-defined commands, whereas system commands are designed for direct usage.&lt;/p&gt;
    &lt;head rend="h3"&gt;Data&lt;/head&gt;
    &lt;quote&gt;⍝⍝⍝ APL Concepts ⍝ Data&lt;/quote&gt;
    &lt;head rend="h4"&gt;Variables&lt;/head&gt;
    &lt;p&gt;Data can be directly quoted…&lt;/p&gt;
    &lt;quote&gt;234.98×3409÷12.4&lt;/quote&gt;
    &lt;p&gt;…or assigned to a name.&lt;/p&gt;
    &lt;quote&gt;VAR ← 183.6&lt;/quote&gt;
    &lt;head rend="h4"&gt;Names&lt;/head&gt;
    &lt;p&gt;APL allows uppercase and lowercase characters, some APLs also allows symbols too.&lt;/p&gt;
    &lt;head rend="h4"&gt;Types of data&lt;/head&gt;
    &lt;p&gt;Data can be numbers, characters or a mixture of those. GNU APL in particular also allows complex numbers; Dyalog allows classes.&lt;/p&gt;
    &lt;head rend="h4"&gt;Size, shape and depth&lt;/head&gt;
    &lt;p&gt;From now on, unless there is something new, only some examples will be typed.&lt;/p&gt;
    &lt;quote&gt;⍝ Scalars (no dimensions) 294 'A' ⍝ Vectors (one dimension -- length) 23 8 0 12 3 'ABC' 28 3 'A' 'BC' ⍝ 2D Matrices (two dimensions -- height and length) ⍝ There is no way to write a matrix literal. 4 4⍴7 45 2 89 16 15 10 21 8 0 13 99 83 19 4 27 4 2⍴'WILSO' 393 'ADAMS' 7183 'CAIRN' 87 'SAMSO' 8467 ⍝ 3D Matrices (three dimensions) 3 3 4⍴36?100&lt;/quote&gt;
    &lt;p&gt;Arrays are data structures of any dimension – obviously, scalars do not apply.&lt;/p&gt;
    &lt;head rend="h4"&gt;Setting up data structures&lt;/head&gt;
    &lt;quote&gt;X1 ← 23 9 144 12 5 0 X2 ← 1 2 'A' 'B' 3 4 2 3⍴23 9 144 12 5 0 NUMS ← 36?100 3 3 4⍴NUMS 6⍴9 ⍝ Nested arrays VAR ← (2 3⍴9) (1 2 3) 'A' 'ABCD' 88 16.1&lt;/quote&gt;
    &lt;head rend="h4"&gt;Data structure versus data value&lt;/head&gt;
    &lt;quote&gt;X ← 1⍴22 Y ← 22 ⍴X ⍝ 1, because X is a vector ⍴Y ⍝ Empty response, because Y is a scalar Z ← 1 5⍴12 5 38 3 6 ⍝ When displayed, Z looks like a vector, ⍴Z ⍝ but is in fact a 1×5 matrix )CLEAR&lt;/quote&gt;
    &lt;head rend="h4"&gt;Empty data structures&lt;/head&gt;
    &lt;p&gt;Useful for some things, for example flor predefined storage areas, where elements can be added.&lt;/p&gt;
    &lt;quote&gt;X ← ⍳0 ⍝ X is a vector of zero elements X ⍝ Printing X gives an empty response ⍴X ⍝ Asking for the shape of X gives a zero&lt;/quote&gt;
    &lt;p&gt;This is fundamentally different than a scalar, which does not have zero elements: a scalar has zero dimensions instead.&lt;/p&gt;
    &lt;code&gt;⍴45
&lt;/code&gt;
    &lt;p&gt;We can also create empty matrices. For example, a matrix of two rows and no columns:&lt;/p&gt;
    &lt;quote&gt;TAB ← 3 0⍴⍳0 TAB ⍴TAB&lt;/quote&gt;
    &lt;head rend="h4"&gt;Dimension ordering&lt;/head&gt;
    &lt;p&gt; General rule when applying an operation to data (e.g. a reduce &lt;code&gt;/&lt;/code&gt;):
&lt;/p&gt;
    &lt;p&gt;Unless specified otherwise, the operation takes place on the last dimension.&lt;/p&gt;
    &lt;p&gt;For example, consider a 3×4 matrix.&lt;/p&gt;
    &lt;quote&gt;X ← 3 4⍴⍳12 +/ X&lt;/quote&gt;
    &lt;p&gt;Applying a reduction to it yields a list of three elements. Each element of the list is the sum of a row. This is because a column is the last dimension of a 2D matrix (3 rows, 4 columns).&lt;/p&gt;
    &lt;p&gt;In other words, since we're performing the reduction on the last dimension (columns), then each result is the sum of all columns belonging to that row.&lt;/p&gt;
    &lt;p&gt; You can change that by using the axis (&lt;code&gt;[]&lt;/code&gt;) operator:
&lt;/p&gt;
    &lt;code&gt;+/[1] X
&lt;/code&gt;
    &lt;p&gt;This carries the reduction on the first axis (rows), therefore the resulting list of four numbers is the sum of each column.&lt;/p&gt;
    &lt;p&gt;Now each result is the sum of all rows belonging to that column.&lt;/p&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h4"&gt;Indexing&lt;/head&gt;
    &lt;p&gt;There is something that remains to be discussed. Last section talked about the rows in index 1. This seems to mean that in APL indexes start at 1, but that might not be always true. This is true for GNU APL, to say the least.&lt;/p&gt;
    &lt;p&gt;If you wish to change indexing, just change the Index Origin system variable (this bit is not tangled):&lt;/p&gt;
    &lt;quote&gt;⎕IO ← 0&lt;/quote&gt;
    &lt;p&gt; From here on, we'll consider Index Origin to be &lt;code&gt;1&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; Selecting elements is easy. Just use the brackets (&lt;code&gt;[]&lt;/code&gt;), and separate
variable indexes with &lt;code&gt;;&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;⍝ Indexing in one dimension X ← 1 45 6 3 9 33 6 0 1 22 X[4] + X[10] ⍝ Indexing in two dimensions TABLE ← 3 3⍴9?100 TABLE[3;2] ⍝ Indexing for more than one dimension ⍝ Indexing in three dimensions DATA ← 4 4 4⍴64?100 DATA[2;1;4] ⍝ Selecting an entire row in tree ways TABLE[1;1 2 3] TABLE[1;⍳3] TABLE[1;] ⍝ Selecting an entire column TABLE[;2] ⍝ Selecting from anonymous data (3 8 4)[1+2] ⍝ Selecting from an anonymous string, based on a variable P ← 2 'ABCDE'[P]&lt;/quote&gt;
    &lt;p&gt;Some useful stuff that has not been discussed yet:&lt;/p&gt;
    &lt;p&gt;Indexing can also be used to rearrange elements on a matrix!&lt;/p&gt;
    &lt;quote&gt;'ABCDE'[4 5 1 4]&lt;/quote&gt;
    &lt;p&gt;We can also do indexing with variables of a higher dimension. This pretty much collects stuff and stores it in the created shape:&lt;/p&gt;
    &lt;quote&gt;'ABCDE'[2 2⍴4 5 1 4]&lt;/quote&gt;
    &lt;p&gt; Indexing can also be done with the squad (&lt;code&gt;⌷&lt;/code&gt;) symbol (notice that this
is different from the quad &lt;code&gt;⎕&lt;/code&gt;, since it is narrower):
&lt;/p&gt;
    &lt;quote&gt;2⌷'ABCD'&lt;/quote&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h3"&gt;Built-in functions&lt;/head&gt;
    &lt;p&gt;APL has 50 useful built-in functions in general, and 5 operators to modify and extend how functions work.&lt;/p&gt;
    &lt;quote&gt;⍝ Built-in Functions&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arguments&lt;/head&gt;
    &lt;p&gt;Most functions have two behaviours depending on how you place their arguments. For example:&lt;/p&gt;
    &lt;quote&gt;⌈12.625 ⍝ Ceiling 2⌈8 ⍝ Select greatest number ÷1 2 3 4 5 ⍝ Reciprocal 100÷1 2 3 4 5 ⍝ Divide 100 by each&lt;/quote&gt;
    &lt;head rend="h4"&gt;Execution order&lt;/head&gt;
    &lt;p&gt;Expressions are evaluated from right to left. The results of one function become the argument of the next function.&lt;/p&gt;
    &lt;head rend="h4"&gt;Numbers or text&lt;/head&gt;
    &lt;p&gt; Some functions work on numbers only. Some work on either numbers or text data. Using a function which does not work on a data type yields a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; Some functions also work only on a subset of the number domain, such as logical functions (&lt;code&gt;∨&lt;/code&gt;, &lt;code&gt;∧&lt;/code&gt; etc.) Thiis means that they only recognize
the states of TRUTH (&lt;code&gt;1&lt;/code&gt;) and FALSITY (&lt;code&gt;0&lt;/code&gt;).
&lt;/p&gt;
    &lt;head rend="h4"&gt;Shape and size of data&lt;/head&gt;
    &lt;p&gt; Some functions can be used only on data of a certain shape. The following example (not tangled) yields a &lt;code&gt;LENGTH ERROR&lt;/code&gt;, because data on
both sides do not have the same shape:
&lt;/p&gt;
    &lt;quote&gt;29 51 60 27÷3 11&lt;/quote&gt;
    &lt;head rend="h4"&gt;Groups of functions&lt;/head&gt;
    &lt;p&gt;Following there will be some examples of functions, which I'll store in tables as given in the tutorial, for further consulting.&lt;/p&gt;
    &lt;p&gt;Unless there is a new function with non-obvious usage, there will be some examples.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Arithmetic functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;+&lt;/td&gt;&lt;td&gt;Numeric&lt;/td&gt;&lt;td&gt;Add&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;Negation&lt;/td&gt;&lt;td&gt;Subtract&lt;/td&gt;&lt;td&gt;×&lt;/td&gt;&lt;td&gt;Sign&lt;/td&gt;&lt;td&gt;Multiply&lt;/td&gt;&lt;td&gt;÷&lt;/td&gt;&lt;td&gt;Reciprocal&lt;/td&gt;&lt;td&gt;Divide&lt;/td&gt;&lt;td&gt;⌈&lt;/td&gt;&lt;td&gt;Ceiling&lt;/td&gt;&lt;td&gt;Biggest&lt;/td&gt;&lt;td&gt;⌊&lt;/td&gt;&lt;td&gt;Floor&lt;/td&gt;&lt;td&gt;Smallest&lt;/td&gt;&lt;td&gt;&amp;amp;vert;&lt;/td&gt;&lt;td&gt;Modulo&lt;/td&gt;&lt;td&gt;Remainder&lt;/td&gt;&lt;/item&gt;
      &lt;item&gt;Algebraic functions&lt;p&gt;Functions for advanced arithmetic.&lt;/p&gt;&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;⍳&lt;/td&gt;&lt;td&gt;Index generator&lt;/td&gt;&lt;td&gt;?&lt;/td&gt;&lt;td&gt;Random number&lt;/td&gt;&lt;td&gt;Random deal&lt;/td&gt;&lt;td&gt;⋆ or *&lt;/td&gt;&lt;td&gt;'e' to the power&lt;/td&gt;&lt;td&gt;Number to the power&lt;/td&gt;&lt;td&gt;⍟&lt;/td&gt;&lt;td&gt;Log to base 'e'&lt;/td&gt;&lt;td&gt;Log to any base&lt;/td&gt;&lt;td&gt;○&lt;/td&gt;&lt;td&gt;π times&lt;/td&gt;&lt;td&gt;Sine, cosine, etc&lt;/td&gt;&lt;td&gt;!&lt;/td&gt;&lt;td&gt;Factorial&lt;/td&gt;&lt;td&gt;Combinations&lt;/td&gt;&lt;td&gt;⌹&lt;/td&gt;&lt;td&gt;Matrix inversion&lt;/td&gt;&lt;td&gt;Matrix division&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Circle operator&lt;p&gt;The circle operator (&lt;/p&gt;&lt;code&gt;○&lt;/code&gt;) does not have an obvious operation on its dyadic form. Here is a table of values of α on the case α ○ ω, taken from TryAPL:&lt;th&gt;α&lt;/th&gt;&lt;th&gt;α ○ ω&lt;/th&gt;&lt;th&gt;α&lt;/th&gt;&lt;th&gt;α ○ ω&lt;/th&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;(1-ω⋆2)⋆0.5&lt;/td&gt;&lt;td&gt;¯1&lt;/td&gt;&lt;td&gt;Arcsin ω&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Sin ω&lt;/td&gt;&lt;td&gt;¯2&lt;/td&gt;&lt;td&gt;Arccos ω&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;Cos ω&lt;/td&gt;&lt;td&gt;¯3&lt;/td&gt;&lt;td&gt;Arctan ω&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;Tan ω&lt;/td&gt;&lt;td&gt;¯4&lt;/td&gt;&lt;td&gt;(¯1+ω⋆2)⋆0.5&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;(1+ω⋆2)≠0.5&lt;/td&gt;&lt;td&gt;¯5&lt;/td&gt;&lt;td&gt;Arcsinh ω&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Sinh ω&lt;/td&gt;&lt;td&gt;¯6&lt;/td&gt;&lt;td&gt;Arccosh ω&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;Cosh ω&lt;/td&gt;&lt;td&gt;¯7&lt;/td&gt;&lt;td&gt;Arctanh ω&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;Tanh ω&lt;/td&gt;&lt;td&gt;¯8&lt;/td&gt;&lt;td&gt;-8○ω&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;(¯1+ω⋆2)⋆0.5&lt;/td&gt;&lt;td&gt;¯9&lt;/td&gt;&lt;td&gt;ω&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;Real part of ω&lt;/td&gt;&lt;td&gt;¯10&lt;/td&gt;&lt;td&gt;+ω&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;td&gt;&amp;amp;vert; ω&lt;/td&gt;&lt;td&gt;¯11&lt;/td&gt;&lt;td&gt;ω ×&lt;/td&gt;&lt;code&gt;0J1&lt;/code&gt;&lt;td&gt;11&lt;/td&gt;&lt;td&gt;Imag part of ω&lt;/td&gt;&lt;td&gt;¯12&lt;/td&gt;&lt;td&gt;⋆ω&lt;/td&gt;&lt;td&gt;12&lt;/td&gt;&lt;td&gt;Phase of ω&lt;/td&gt;&lt;p&gt;Also notice that&lt;/p&gt;&lt;code&gt;0J1&lt;/code&gt;is a complex number of real part&lt;code&gt;0&lt;/code&gt;and imaginary part&lt;code&gt;1&lt;/code&gt;.&lt;/item&gt;&lt;item&gt;Domino operator&lt;p&gt;The Domino operator (&lt;/p&gt;&lt;code&gt;⌹&lt;/code&gt;) generates the inverse of a matrix in its monadic form, and divides a matrix by another in its dyadic form:&lt;quote&gt;MAT ← 2 2⍴⍳4 ⌹MAT 5 6⌹MAT&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Circle operator&lt;/item&gt;
      &lt;item&gt;Comparative functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;&amp;lt;&lt;/td&gt;&lt;td&gt;Less than&lt;/td&gt;&lt;td&gt;≤&lt;/td&gt;&lt;td&gt;Less than or equal&lt;/td&gt;&lt;td&gt;=&lt;/td&gt;&lt;td&gt;Equal&lt;/td&gt;&lt;td&gt;≥&lt;/td&gt;&lt;td&gt;Greater than or equal&lt;/td&gt;&lt;td&gt;&amp;gt;&lt;/td&gt;&lt;td&gt;Greater than&lt;/td&gt;&lt;td&gt;≠&lt;/td&gt;&lt;td&gt;Not equal&lt;/td&gt;&lt;td&gt;≡&lt;/td&gt;&lt;td&gt;Depth&lt;/td&gt;&lt;td&gt;Match&lt;/td&gt;&lt;td&gt;≢&lt;/td&gt;&lt;td&gt;Tally&lt;/td&gt;&lt;td&gt;Not match&lt;/td&gt;&lt;td&gt;∊&lt;/td&gt;&lt;td&gt;Enlist&lt;/td&gt;&lt;td&gt;Membership&lt;/td&gt;&lt;td&gt;⍳&lt;/td&gt;&lt;td&gt;Iota&lt;/td&gt;&lt;td&gt;Index of&lt;/td&gt;&lt;td&gt;⍷&lt;/td&gt;&lt;td&gt;Find&lt;/td&gt;&lt;p&gt;Here's an interesting use for comparative functions: Suppose we have a table, where some numbers are negative. How can we test which numbers are less than zero in it?&lt;/p&gt;&lt;quote&gt;TABLE ← 3 3⍴25-9?50 TABLE &amp;lt; 0&lt;/quote&gt;&lt;list rend="ul"&gt;&lt;item&gt;Equal underbar&lt;p&gt;The Equal underbar (&lt;/p&gt;&lt;code&gt;≡&lt;/code&gt;) serves two purposes. In its monadic form, it shows the depth of a specific structure.&lt;quote&gt;≡2 2⍴1 (2 3) (4 5 6 7) (8 (9 10) 11)&lt;/quote&gt;&lt;p&gt;In its dyadic form, it attempts to match both parameters to see if they are equal in shape, order and values:&lt;/p&gt;&lt;quote&gt;'t' 'e' 's' 't'≡'test'&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Equal underbar slash&lt;p&gt;The Equal underbar slash (&lt;/p&gt;&lt;code&gt;≢&lt;/code&gt;) does the exact opposite of&lt;code&gt;≡&lt;/code&gt;. In its monadic form, it shows the tally (shallowest depth) of a specific structure:&lt;quote&gt;≢2 2⍴1 (2 3) (4 5 6 7) (8 (9 10) 11)&lt;/quote&gt;&lt;p&gt;In its dyadic form, it checks if both parameters do not match:&lt;/p&gt;&lt;quote&gt;('t' 'e') ('s' 't')≢'test'&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Epsilon&lt;p&gt;The Epsilon (&lt;/p&gt;&lt;code&gt;∊&lt;/code&gt;), in its dyadic form, checks whether the first parameter is enclosed in the second parameter, thus testing for membership:&lt;quote&gt;2∊1 2 3&lt;/quote&gt;&lt;p&gt;The monadic form, however, enlists a certain value. If it is a scalar, it is put into a list; if it is a list, nothing changes; if it is a matrix, rows will be put one after the other to form a single list.&lt;/p&gt;&lt;quote&gt;∊3 3 3⍴⍳27&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Epsilon underbar&lt;p&gt;The Epsilon underbar (&lt;/p&gt;&lt;code&gt;⍷&lt;/code&gt;) is only dyadic, and attempts to find the first argument (which should be a pattern) inside the second argument. The result should be a structure which marks where the occurence starts for each occurence found.&lt;quote&gt;'ana' ⍷ 'banana'&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Iota&lt;p&gt;The Iota (&lt;/p&gt;&lt;code&gt;⍳&lt;/code&gt;) in its monadic form generates a list from&lt;code&gt;0&lt;/code&gt;to&lt;code&gt;n&lt;/code&gt;.&lt;quote&gt;⍳9 3 3⍴⍳9&lt;/quote&gt;&lt;p&gt;In its dyadic form, it attempts to find the second argument inside the first argument. The first match found returns the element index inside the list, matrix, etc.&lt;/p&gt;&lt;quote&gt;X ← 0 0 5 3 X[(0≠0 0 5 3)⍳1] ⍝ Get first non-null element of X&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Equal underbar&lt;/item&gt;
      &lt;item&gt;Logical functions&lt;p&gt;These functions work only with yielding&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;or&lt;code&gt;1&lt;/code&gt;by default, but they are also used for branching.&lt;p&gt;All functions are dyadic, unless specified otherwise.&lt;/p&gt;&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Description&lt;/th&gt;&lt;td&gt;~&lt;/td&gt;&lt;td&gt;Not (Monadic)&lt;/td&gt;&lt;td&gt;∨&lt;/td&gt;&lt;td&gt;Or&lt;/td&gt;&lt;td&gt;∧&lt;/td&gt;&lt;td&gt;And&lt;/td&gt;&lt;td&gt;⍱&lt;/td&gt;&lt;td&gt;Nor&lt;/td&gt;&lt;td&gt;⍲&lt;/td&gt;&lt;td&gt;Nand&lt;/td&gt;&lt;quote&gt;~1 0 1 1 0 1∨0 0 1 1 0 1∧0 0 1 1 0 1⍱0 0 1 1 0 1⍲0 0 1&lt;/quote&gt;&lt;p&gt;We can also short-circuit expressions. Should even be useful for comparisions.&lt;/p&gt;&lt;quote&gt;(5 &amp;gt; 4) ∧ 1 &amp;lt; 3&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Manipulative functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;⍴&lt;/td&gt;&lt;td&gt;Shape&lt;/td&gt;&lt;td&gt;Reshape&lt;/td&gt;&lt;td&gt;,&lt;/td&gt;&lt;td&gt;Ravel&lt;/td&gt;&lt;td&gt;Catenate&lt;/td&gt;&lt;td&gt;~&lt;/td&gt;&lt;td&gt;Not&lt;/td&gt;&lt;td&gt;Without&lt;/td&gt;&lt;td&gt;⌽&lt;/td&gt;&lt;td&gt;Reverse&lt;/td&gt;&lt;td&gt;Rotate&lt;/td&gt;&lt;td&gt;⍉&lt;/td&gt;&lt;td&gt;Transpose&lt;/td&gt;&lt;td&gt;Dyadic transpose&lt;/td&gt;&lt;td&gt;↑&lt;/td&gt;&lt;td&gt;Take first&lt;/td&gt;&lt;td&gt;Take&lt;/td&gt;&lt;code&gt;n&lt;/code&gt;&lt;td&gt;↓&lt;/td&gt;&lt;td&gt;Drop&lt;/td&gt;&lt;code&gt;n&lt;/code&gt;&lt;td&gt;⊂&lt;/td&gt;&lt;td&gt;Enclose&lt;/td&gt;&lt;td&gt;Partitioned enclose&lt;/td&gt;&lt;td&gt;⊃&lt;/td&gt;&lt;td&gt;Disclose&lt;/td&gt;&lt;td&gt;Pick&lt;/td&gt;&lt;td&gt;∩&lt;/td&gt;&lt;td&gt;Intersection&lt;/td&gt;&lt;td&gt;∪&lt;/td&gt;&lt;td&gt;Unique&lt;/td&gt;&lt;td&gt;Union&lt;/td&gt;&lt;td&gt;⊢&lt;/td&gt;&lt;td&gt;Identity&lt;/td&gt;&lt;td&gt;Right&lt;/td&gt;&lt;td&gt;⊣&lt;/td&gt;&lt;td&gt;Identity&lt;/td&gt;&lt;td&gt;Left&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Comma&lt;p&gt;The Ravel (&lt;/p&gt;&lt;code&gt;,&lt;/code&gt;) operator, in its monadic form, turns a matrix into a list.&lt;quote&gt;X ← 3 3 3⍴⍳27 ⍝ A cube ,X&lt;/quote&gt;&lt;p&gt;However, we can use axis parameters to induce other behaviours.&lt;/p&gt;&lt;quote&gt;,[1 2]X&lt;/quote&gt;&lt;p&gt;The dyadic form catenates two structures. The particular behaviour is determined by shape.&lt;/p&gt;&lt;quote&gt;(3 3⍴⍳9),(3 3⍴9+⍳9)&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Circle Stile&lt;p&gt;The Reverse (&lt;/p&gt;&lt;code&gt;⌽&lt;/code&gt;), in its monadic form, reverses the elements along the last axis.&lt;quote&gt;⌽0 0 5 7&lt;/quote&gt;&lt;p&gt;Its dyadic form performs a rotation on the elements of the second parameter, in the last axis, by the number of elements specified in the second parameter, as if the data were stored in a toroidal shape. Number of rotated elements' sign provides the direction.&lt;/p&gt;&lt;quote&gt;2⌽3 3⍴⍳9 ¯2⌽3 3⍴⍳9&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Transpose&lt;p&gt;The Transpose (&lt;/p&gt;&lt;code&gt;⍉&lt;/code&gt;), in its monadic form, reverses the axes of the given matrix.&lt;quote&gt;⍉3 3⍴⍳9&lt;/quote&gt;&lt;p&gt;In its dyadic form, we can directly instruct which axes are swapped and how:&lt;/p&gt;&lt;quote&gt;2 1 3⍉3 3 3⍴⍳27 ⍝ Swap axes 1 and 2&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Up Arrow&lt;p&gt;The Take function (&lt;/p&gt;&lt;code&gt;↑&lt;/code&gt;), in its monadic form, gets the first element of an array.&lt;quote&gt;↑3 1 2&lt;/quote&gt;&lt;p&gt;In its dyadic form, it takes exactly the number of elements specified at the first parameter, from the second parameter. If the absolute number exceeds the length, the resulting list is zero-filled. If the number is negative, it is taken from last element.&lt;/p&gt;&lt;quote&gt;2↑⌽⍳4 ¯7↑⌽⍳4&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Down Arrow&lt;p&gt;The Drop function (&lt;/p&gt;&lt;code&gt;↓&lt;/code&gt;) has only a dyadic form, and drops the number of elements in the first parameter from the second parameter list. If the number is negative, the drop happens from the end. If the absolute number exceeds the length, an empty response is returned.&lt;/item&gt;&lt;item&gt;Left Shoe&lt;p&gt;The Enclose (&lt;/p&gt;&lt;code&gt;⊂&lt;/code&gt;) function, in its monadic form, encloses the given object into a nested scalar.&lt;quote&gt;⊂2 2⍴⍳4 ⍴⊂2 2⍴⍳4&lt;/quote&gt;&lt;p&gt;In its dyadic form, it does a selective enclosing, returning the enclosed objects:&lt;/p&gt;&lt;quote&gt;0 1 1 0⊂⍳4&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Right Shoe&lt;p&gt;The Disclose (&lt;/p&gt;&lt;code&gt;⊃&lt;/code&gt;) function, in its monadic form, discloses the single elements of an object, zero-filling the missing elements so that all of them belong to a single shape, with the same number of dimensions.&lt;quote&gt;⊃(⍳4) 2 3&lt;/quote&gt;&lt;p&gt;In its dyadic form, it recursively picks up a certain element from a nested structure.&lt;/p&gt;&lt;quote&gt;X ← 4⍴⊂(4 4⍴16?100) ⍝ List of four enclosed 4x4 matrices 2 (2 2)⊃X ⍝ Pick 2nd matrix, then pick element [2;2]&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Right Tack&lt;p&gt;The Right (&lt;/p&gt;&lt;code&gt;⊢&lt;/code&gt;) function does nothing in its monadic form, giving back the untouched data. Its dyadic form, however, selects the left element. It has a particularly useful property of selecting the rightmost element when mapped over a structure:&lt;quote&gt;2 3⊢4 5 ⊢/ 6 7 8 9&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Left Tack&lt;p&gt;The Left (&lt;/p&gt;&lt;code&gt;⊣&lt;/code&gt;) function works much like Right, except that it selects the left element, or the leftmost element on a mapping:&lt;quote&gt;2 3⊣4 5 ⊣/ 6 7 8 9&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Comma&lt;/item&gt;
      &lt;item&gt;Sorting and coding functions&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Monadic form&lt;/th&gt;&lt;th&gt;Dyadic form&lt;/th&gt;&lt;td&gt;⍋&lt;/td&gt;&lt;td&gt;Grade up&lt;/td&gt;&lt;td&gt;Collated grade up&lt;/td&gt;&lt;td&gt;⍒&lt;/td&gt;&lt;td&gt;Grade down&lt;/td&gt;&lt;td&gt;Collated grade down&lt;/td&gt;&lt;td&gt;⊥&lt;/td&gt;&lt;td&gt;Decode&lt;/td&gt;&lt;td&gt;⊤&lt;/td&gt;&lt;td&gt;Encode&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Grade Up&lt;p&gt;The Grade Up (&lt;/p&gt;&lt;code&gt;⍋&lt;/code&gt;) function, in its monadic form, returns the indexes of elements in ascending order.&lt;quote&gt;LIST ← 10?100 LIST[⍋LIST]&lt;/quote&gt;&lt;p&gt;In its dyadic form, the first parameter is a collating sequence, which enumerates top-priority elements for the ordering. Elements outside of the collation are put in the end of the sequence.&lt;/p&gt;&lt;quote&gt;TEXT ← 'Banana' TEXT['an'⍋TEXT]&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Grade Down&lt;p&gt;The Grade Down (&lt;/p&gt;&lt;code&gt;⍒&lt;/code&gt;) function works just like Grade Up, except that it returns indexes of elements in descending order.&lt;p&gt;On the dyadic form, the collating sequence enumerates elements which shall be ordered from rightmost to leftmost. Elements outside of the collation are put in the beginning of the sequence.&lt;/p&gt;&lt;quote&gt;LIST ← 10?100 TEXT ← 'Banana' LIST[⍒LIST] TEXT['an'⍒TEXT]&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Decode&lt;p&gt;The Decode (&lt;/p&gt;&lt;code&gt;⊥&lt;/code&gt;) function converts a number (expressed as a list) on the second argument to the base shown in the first argument.&lt;quote&gt;2⊥0 0 1 0 1 16⊥2 1 24 60 60⊥2 46 40 ⍝ Time conversion! 2h46m40s into total seconds&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Encode&lt;p&gt;The Encode (&lt;/p&gt;&lt;code&gt;⊤&lt;/code&gt;) function does the opposite of Decode.&lt;quote&gt;2 2 2 2⊤5 7 12 24 60 60⊤10000 ⍝ Mixed radix; convert 10000 seconds to h m s&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Grade Up&lt;/item&gt;
      &lt;item&gt;Miscellaneous functions and other symbols&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Meaning&lt;/th&gt;&lt;td&gt;⎕&lt;/td&gt;&lt;td&gt;Numeric input from keyboard (niladic)&lt;/td&gt;&lt;td&gt;⍞&lt;/td&gt;&lt;td&gt;Character input from keyboard (niladic)&lt;/td&gt;&lt;td&gt;◊&lt;/td&gt;&lt;td&gt;Stament separator&lt;/td&gt;&lt;td&gt;⍝&lt;/td&gt;&lt;td&gt;Comment&lt;/td&gt;&lt;td&gt;⍎&lt;/td&gt;&lt;td&gt;Evaluate text as APL expression (monadic)&lt;/td&gt;&lt;td&gt;⍕&lt;/td&gt;&lt;td&gt;Format (monadic/dyadic)&lt;/td&gt;&lt;td&gt;⌷&lt;/td&gt;&lt;td&gt;Index (dyadic)&lt;/td&gt;&lt;td&gt;⍬&lt;/td&gt;&lt;td&gt;Zilde&lt;/td&gt;&lt;list rend="ul"&gt;&lt;item&gt;Diamond&lt;p&gt;The statement separator (&lt;/p&gt;&lt;code&gt;◊&lt;/code&gt;) allows for inputting more than one statement in a single line.&lt;quote&gt;LIST ← 25-(5?50) ◊ (÷LIST)&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Hydrant&lt;p&gt;The Execute operator (&lt;/p&gt;&lt;code&gt;⍎&lt;/code&gt;) evaluates a textual expression as an APL statement.&lt;code&gt;⍎'X ← 10×3 3⍴⍳9 ◊ ÷X'&lt;/code&gt;&lt;/item&gt;&lt;item&gt;Thorn&lt;p&gt;The Format operator (&lt;/p&gt;&lt;code&gt;⍕&lt;/code&gt;) in its monadic form, transforms values into a character list, suited to display onscreen.&lt;quote&gt;⍕1 2 3&lt;/quote&gt;&lt;p&gt;Its dyadic form requires a format list as first argument, containing the field width for each value and its number of decimal places. The second argument is the values. If the field is not wide enough, it gives a&lt;/p&gt;&lt;code&gt;DOMAIN ERROR&lt;/code&gt;.&lt;quote&gt;6 2⍕3.25 3.002 ⍝ 8 2⍕1234 ⍝ Not wide enough&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Squad&lt;p&gt;The Index operator (&lt;/p&gt;&lt;code&gt;⌷&lt;/code&gt;) has only a dyadic form, where one can pick elements at something. It also supports axis parameters.&lt;quote&gt;TABLE ← 3 4⍴⍳12 2 3⌷TABLE 2⌷[1] TABLE 2⌷[2] TABLE&lt;/quote&gt;&lt;/item&gt;&lt;item&gt;Zilde&lt;p&gt;The Empty Numeric Vector (&lt;/p&gt;&lt;code&gt;⍬&lt;/code&gt;) is a vector of zero elements.&lt;quote&gt;⍝ These are a match, since they are numeric vectors. ⍬≡⍳0 ⍬≡0⍴0 ⍝ These do not match. ⍬≡0 0⍴0 ⍝ Not a vector ⍬≡'' ⍝ Not numeric&lt;/quote&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Diamond&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;System functions&lt;/head&gt;
    &lt;p&gt;System functions exist to extend the power of APL, improving the usable tasks.&lt;/p&gt;
    &lt;p&gt;See the implementation documentation for that.&lt;/p&gt;
    &lt;head rend="h3"&gt;Built-in operators&lt;/head&gt;
    &lt;quote&gt;⍝ Built-in Operators&lt;/quote&gt;
    &lt;p&gt;Operators are used to specify the way in which one or more functions are applied to data. For example: repeatedly, cumulatively, etc.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Operator&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;/&lt;/cell&gt;
        &lt;cell&gt;Slash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⌿&lt;/cell&gt;
        &lt;cell&gt;Slash bar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;\&lt;/cell&gt;
        &lt;cell&gt;Backslash&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⍀&lt;/cell&gt;
        &lt;cell&gt;Backslash bar&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;.&lt;/cell&gt;
        &lt;cell&gt;Inner product&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;∘.&lt;/cell&gt;
        &lt;cell&gt;Outer product&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;¨&lt;/cell&gt;
        &lt;cell&gt;Each&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;[ ]&lt;/cell&gt;
        &lt;cell&gt;Axis&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;⍨&lt;/cell&gt;
        &lt;cell&gt;Duplicate/Commute&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;∘&lt;/cell&gt;
        &lt;cell&gt;Compose&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Reduce and scan&lt;/head&gt;
    &lt;p&gt; When used with functions as their operands, Slash and Backslash become Reduce (&lt;code&gt;/&lt;/code&gt;) and Scan (&lt;code&gt;\&lt;/code&gt;), which apply a single function to all elements
of an argument.
&lt;/p&gt;
    &lt;quote&gt;⍝ These two operations are equivalent 22 + 93 + 4.6 + 10 + 3.3 +/22 93 4.6 10 3.3 ⍝ Reduce using plus&lt;/quote&gt;
    &lt;p&gt; In the last example, Reduce interposes the &lt;code&gt;+&lt;/code&gt; between the values on the
vector. Were it replaced by the Scan operator, the same would happen,
but the result would be a vector containing intermediate results; the
last element of such vector would be the last result.
&lt;/p&gt;
    &lt;quote&gt;+\22 93 4.6 10 3.3 ⍝ Scan using plus 22 (22+93) (115+4.6) (119.6+10) (129.6+3.3) ⍝ Equivalent calculation&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Reduce First and Scan First&lt;p&gt;Using a Slash bar with a function means using the Reduce First (&lt;/p&gt;&lt;code&gt;⌿&lt;/code&gt;) operator. This will apply a reduction on the first dimension of the data structure:&lt;quote&gt;TABLE ← 3 5⍴15?30 +⌿ TABLE&lt;/quote&gt;&lt;p&gt;Using a Backslash bar with a function means using the Scan First (&lt;/p&gt;&lt;code&gt;⍀&lt;/code&gt;) operator. This does something similar to Scan, but stores each result in a matrix row (first dimension).&lt;quote&gt;+⍀ TABLE&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Compress and expand&lt;/head&gt;
    &lt;p&gt; When used with one or more numbers, Slash and Backslash become Compression (&lt;code&gt;/&lt;/code&gt;) and Expansion (&lt;code&gt;\&lt;/code&gt;).
&lt;/p&gt;
    &lt;p&gt;Compress selects a part of an object:&lt;/p&gt;
    &lt;quote&gt;1 0 1 1 0 1 / 'ABCDEF'&lt;/quote&gt;
    &lt;p&gt;Expand inserts fill data into objects:&lt;/p&gt;
    &lt;quote&gt;TABLE ← 2 3⍴⍳6 ⍝ Insert new columns (axis 2). ⍝ New columns indicated by zeroes. 1 0 1 0 1\[2]TABLE&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Compress First and Expand First&lt;p&gt;The Compress First (&lt;/p&gt;&lt;code&gt;⌿&lt;/code&gt;) operator, also known as Replicate First, is the dyadic form of the Slash Bar, and can be used in a matrix to remove and duplicate certain rows (first dimension):&lt;quote&gt;TABLE ← 3 4⍴⍳12 1 0 2⌿TABLE ⍝ Remove 2nd row, duplicate 3rd row&lt;/quote&gt;&lt;p&gt;The Expand First (&lt;/p&gt;&lt;code&gt;⍀&lt;/code&gt;) operator is the dyadic version of the Backslash bar, and also works by adding new rows (first dimension) to a matrix.&lt;quote&gt;TABLE ← 3 4⍴⍳12 1 0 1 0 1 0 0⍀TABLE&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Outer and inner products&lt;/head&gt;
    &lt;p&gt;Product operators distribute the application of a function between each element of one argument and all elements in another; this removes the constraint on applying certain functions to arguments of same shape.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Outer Product&lt;p&gt;The outer product (&lt;/p&gt;&lt;code&gt;∘.&lt;/code&gt;)gives the result of applying the function to all combinations of elements in both arguments:&lt;quote&gt;1 2 3∘.+4 5 6&lt;/quote&gt;&lt;p&gt;The result is a 3×3 matrix, where the first column is the sum between&lt;/p&gt;&lt;code&gt;1&lt;/code&gt;and each of the numbers in the second argument; the second column is the sum between&lt;code&gt;2&lt;/code&gt;and each of the numbers in the second argument; and so on.&lt;p&gt;Another example: a matrix of powers.&lt;/p&gt;&lt;quote&gt;(⍳4)∘.*⍳4&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Inner Product&lt;p&gt;The inner product (&lt;/p&gt;&lt;code&gt;.&lt;/code&gt;) allows two functions to be applied to arguments; operations happen between the last dimension of the left argument, and the first dimension of the right argument; so the two inner dimensions are used.&lt;p&gt;Using this on matrices results in two steps:&lt;/p&gt;&lt;list rend="ol"&gt;&lt;item&gt;Each row of the left argument is applied to each column of the right argument. This uses the rightmost function;&lt;/item&gt;&lt;item&gt;The leftmost function is applied to the result, through a Reduction (&lt;code&gt;/&lt;/code&gt;).&lt;/item&gt;&lt;/list&gt;&lt;quote&gt;X←3 3⍴9?100 Y←3 3⍴9?100 ⍝ 1. Each row of X is multiplied by each column of Y; ⍝ 2. The result is reduced through a sum. X+.×Y&lt;/quote&gt;&lt;p&gt;There are up to 400 possible inner products. Some uses are:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Locating incidences of given character strings within textual data;&lt;/item&gt;&lt;item&gt;Evaluation of polynomials;&lt;/item&gt;&lt;item&gt;Matrix multiplication;&lt;/item&gt;&lt;item&gt;Product of powers;&lt;/item&gt;&lt;item&gt;Etc.&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Each&lt;/head&gt;
    &lt;p&gt; The Each operator (&lt;code&gt;¨&lt;/code&gt;) allows applying a certain function (on the left)
to each elements of an array or vector (on the right).
&lt;/p&gt;
    &lt;quote&gt;⍴¨(⍳3)(⍳2)(⍳5) ⍝ Find the length of each vector&lt;/quote&gt;
    &lt;head rend="h4"&gt;Axis&lt;/head&gt;
    &lt;p&gt;Some functions operate in data which has more than one dimension. One can change the axis in which they operate by using the axis operator.&lt;/p&gt;
    &lt;p&gt; By default, APL functions work on the last dimension of your data. The order of dimensions is the one show when you apply &lt;code&gt;⍴&lt;/code&gt; to the data.
&lt;/p&gt;
    &lt;quote&gt;TABLE ← 2 3⍴⍳6 ⍝ A matrix of 2×3 (two dimensions) ⍝ Reduce with + on the second dimension. This gives a ⍝ list of two numbers, each being the sum of numbers ⍝ along the COLUMNS (dimension 2, last one) of each ⍝ row of the matrix. +/TABLE ⍝ This reduction specifies that the sum should occur ⍝ along the ROWS (dimension 1) of a column of the ⍝ matrix, therefore it gives a list of three numbers. +/[1]TABLE&lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Functions that accept axis specifications&lt;p&gt;here are some built-in functions and operators that accept specifying axes:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;Functions &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;↑&lt;/code&gt;(First, Take)&lt;/item&gt;&lt;item&gt;&lt;code&gt;↓&lt;/code&gt;(Drop)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⊂&lt;/code&gt;(Enclose, Partition)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⊃&lt;/code&gt;(Disclose, Pick)&lt;/item&gt;&lt;item&gt;&lt;code&gt;,&lt;/code&gt;(Ravel, Catenate)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⌽&lt;/code&gt;,&lt;code&gt;⊖&lt;/code&gt;(Reversal, Rotation)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;item&gt;Operators &lt;list rend="ul"&gt;&lt;item&gt;&lt;code&gt;/&lt;/code&gt;(Reduce, Compress)&lt;/item&gt;&lt;item&gt;&lt;code&gt;\&lt;/code&gt;(Scan, Expand)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⌿&lt;/code&gt;(Reduce First, Compress First)&lt;/item&gt;&lt;item&gt;&lt;code&gt;⍀&lt;/code&gt;(Scan First, Compress First)&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;Functions &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h3"&gt;User-defined Functions&lt;/head&gt;
    &lt;quote&gt;⍝ User-defined functions&lt;/quote&gt;
    &lt;head rend="h4"&gt;Arguments and results&lt;/head&gt;
    &lt;p&gt;Functions can be thought of as external programs which are run. They can be:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Niladic: They have no specified arguments.&lt;/item&gt;
      &lt;item&gt;Monadic: Functions have one argument, passed at its right.&lt;/item&gt;
      &lt;item&gt;Dyadic: Functions have two arguments, the first is passed at its left and the second is passed at its right.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Passing many values as an argument is enclosed into a single vector of arguments.&lt;/p&gt;
    &lt;p&gt;Definining a function that is both monadic and dyadic require testing the first and second arguments to dispatch based on it.&lt;/p&gt;
    &lt;p&gt;If you need to express a result, you will also need to give a name for the result field.&lt;/p&gt;
    &lt;head rend="h4"&gt;User-defined operators&lt;/head&gt;
    &lt;p&gt;Operators must have one or two operands, which are functions; not more nor less, since operators are used to modify the behaviour of functions.&lt;/p&gt;
    &lt;head rend="h4"&gt;Editing functions&lt;/head&gt;
    &lt;p&gt; Some APLs allow you to edit a function by using the &lt;code&gt;)EDIT&lt;/code&gt; command or
the &lt;code&gt;⎕EDIT&lt;/code&gt; system function. This is the case for Dyalog, for example –
however, Dyalog uses the &lt;code&gt;)ED&lt;/code&gt; command instead.
&lt;/p&gt;
    &lt;quote&gt;)ED FUNK&lt;/quote&gt;
    &lt;p&gt; Older APL systems, like GNU APL, allows editing one-line-at-time, using the Del (&lt;code&gt;∇&lt;/code&gt;) editor. However, the &lt;code&gt;gnu-apl-mode&lt;/code&gt; for Emacs replaces
the use of Del by opening a new temporary buffer to edit the function.
&lt;/p&gt;
    &lt;code&gt;∇FUNK
&lt;/code&gt;
    &lt;p&gt; APL uses the concept of workspaces to store functions and values, however one can safely use the Del (&lt;code&gt;∇&lt;/code&gt;) notation to define a certain
function in an APL code file:
&lt;/p&gt;
    &lt;quote&gt;∇FUNK ⍝ Add some code here... ∇&lt;/quote&gt;
    &lt;p&gt;The rest of this text will use the Del editor notation, in a way which it can be executed in a GNU APL script, therefore some things will be different e.g. line numbers will not be used here.&lt;/p&gt;
    &lt;head rend="h4"&gt;The function header&lt;/head&gt;
    &lt;p&gt;When typing the function, one must type a suitable function header, for example:&lt;/p&gt;
    &lt;quote&gt;∇SD X SUM ← +/X AVG ← SUM÷⍴X DIFF ← AVG-X SQDIFF ← DIFF⋆2 SQAVG ← (+/SQDIFF)÷⍴SQDIFF RESULT ← SQAVG⋆0.5 ∇&lt;/quote&gt;
    &lt;p&gt; This function takes a vector called &lt;code&gt;X&lt;/code&gt; and performs some computation
using it.
&lt;/p&gt;
    &lt;quote&gt;SD 12 45 20 68 92 108&lt;/quote&gt;
    &lt;p&gt; The result exists in the global variable &lt;code&gt;RESULT&lt;/code&gt;, created inside the
function.
&lt;/p&gt;
    &lt;p&gt;If we were defining a function with two operators, we would have a header such as:&lt;/p&gt;
    &lt;code&gt;∇X CALC Y
&lt;/code&gt;
    &lt;p&gt; And if we wanted the result to be put in a specific variable, see how we could redefine &lt;code&gt;SD&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;∇R ← SD X SUM ← +/X AVG ← SUM÷⍴X DIFF ← AVG-X SQDIFF ← DIFF⋆2 SQAVG ← (+/SQDIFF)÷⍴SQDIFF R ← SQAVG⋆0.5 ∇&lt;/quote&gt;
    &lt;p&gt; By doing this, the result of applying &lt;code&gt;SD&lt;/code&gt; to something could be
assigned to a variable; &lt;code&gt;R&lt;/code&gt; itself is not a variable which is visible
outside of &lt;code&gt;SD&lt;/code&gt;, acting as a surrogate for the final result of
execution.
&lt;/p&gt;
    &lt;head rend="h4"&gt;The operator header&lt;/head&gt;
    &lt;p&gt;Operator bodies are defined just like functions'; what changes is the header, which must specify an operator.&lt;/p&gt;
    &lt;p&gt;Here is the header of a monadic operator:&lt;/p&gt;
    &lt;code&gt;∇R ← X (LOP OPERATE) Y
&lt;/code&gt;
    &lt;p&gt;And the header of a dyadic operator:&lt;/p&gt;
    &lt;code&gt;∇R ← X (LOP OPERATE ROP) Y
&lt;/code&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;&lt;code&gt;OPERATE&lt;/code&gt;is the operator name;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;R&lt;/code&gt;is the optional return variable;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;X&lt;/code&gt;and&lt;code&gt;Y&lt;/code&gt;are left and right parameters for the operator;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;LOP&lt;/code&gt;is an obligatory left operand, which the operator will change the behaviour of;&lt;/item&gt;
      &lt;item&gt;&lt;code&gt;ROP&lt;/code&gt;is an optional right operand, which the operator will also change the behaviour of.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Local and global variables&lt;/head&gt;
    &lt;p&gt;One can quote variables in the header to make sure they are local to the function; by not doing so, they will remain global. Also notice that local variables are not shared with variables called inside the function body.&lt;/p&gt;
    &lt;p&gt; So let's fix &lt;code&gt;SD&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;)CLEAR ⍝ Clear the workspace ∇R ← SD X;SUM;AVG;DIFF;SQDIFF;SQAVG SUM ← +/X AVG ← SUM÷⍴X DIFF ← AVG-X SQDIFF ← DIFF⋆2 SQAVG ← (+/SQDIFF)÷⍴SQDIFF R ← SQAVG⋆0.5 ∇&lt;/quote&gt;
    &lt;p&gt;But the header is so big, that's not good. Let's try making this a little more compact so we have fewer local variables.&lt;/p&gt;
    &lt;quote&gt;∇R ← SD X;SQDIFF SQDIFF ← (X-(+/X)÷⍴X)⋆2 R ← ((+/SQDIFF)÷⍴SQDIFF)⋆0.5 ∇&lt;/quote&gt;
    &lt;head rend="h4"&gt;Branching&lt;/head&gt;
    &lt;p&gt; Inside the body of a function or operator, the symbol Goto (&lt;code&gt;→)&lt;/code&gt; is used
to determine a jump. The symbol should then be followed by some data;
if the data is a scalar, the function jumps to the given line. If it
is a vector, the function jumps to the first element of the vector and
ignores the rest of it.
&lt;/p&gt;
    &lt;p&gt;Here is an example of that in action, with numbering on the body for better understanding.&lt;/p&gt;
    &lt;quote&gt;∇R←TEST X [1] →(X≥0)/4 [2] R←0 [3] →5 [4] R←1 ∇&lt;/quote&gt;
    &lt;p&gt; The function starts by testing whether &lt;code&gt;X&lt;/code&gt; is greater or equal to
zero. If so, the result is &lt;code&gt;1&lt;/code&gt;, therefore the Compress (&lt;code&gt;/&lt;/code&gt;) operator
selects the sole number at the right, which is &lt;code&gt;4&lt;/code&gt;. The &lt;code&gt;→&lt;/code&gt; symbol then
instructs the function to jump to the line – that is, the fourth one.
&lt;/p&gt;
    &lt;p&gt; Line &lt;code&gt;[2]&lt;/code&gt; puts a &lt;code&gt;0&lt;/code&gt; on the result variable. Then line &lt;code&gt;[3]&lt;/code&gt; instructs the
program to make an unconditional jump to the line &lt;code&gt;5&lt;/code&gt;, which does not
exist – thus ending the function.
&lt;/p&gt;
    &lt;p&gt; Line &lt;code&gt;[4]&lt;/code&gt; attributes the number &lt;code&gt;1&lt;/code&gt; to the result variable, and then
exits gracefully, as there are no more jumps.
&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Looping&lt;p&gt;One can also perform loops very easily by using the Goto symbol (&lt;/p&gt;&lt;code&gt;→&lt;/code&gt;). For example, consider the following function.&lt;quote&gt;⍝ Calculate factorial of a scalar N. ⍝ Has a return variable and a local scalar I. ∇R←FACTORIAL N;I →(N≤0)/0 ⍝ 1: If N is lower or eq to 0, end function I←1 ⍝ 2: Initialize iterator to 1 R←1 ⍝ 3: Initialize result to 1 R←R×I ⍝ 4: Let result be the mult. of result and iter →(I=N)/0 ⍝ 5: If iterator is equal to N, end function I←I+1 ⍝ 6: Increment iterator →4 ⍝ 7: Jump to multiplication ∇&lt;/quote&gt;&lt;p&gt;Jumping to&lt;/p&gt;&lt;code&gt;0&lt;/code&gt;will be explained below; it ends the function.&lt;/item&gt;
      &lt;item&gt;Labels&lt;p&gt;It is not necessary to count lines on most modern APLs. We can just use labels. This is also useful when adding lines and whatnot.&lt;/p&gt;&lt;quote&gt;∇R ← TEST X →(X≥0)/GREATEQ R←0 →0 GREATEQ: R←1 ∇&lt;/quote&gt;&lt;p&gt;Here is the factorial function, rewritten using labels:&lt;/p&gt;&lt;quote&gt;∇R←FACTORIAL N;I →(N≤0)/0 (I R)←1 ⍝ Multiple definition at once LOOP: R←R×I →(I=N)/0 I←I+1 →LOOP ∇&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Ending execution of a function&lt;p&gt;A function stops naturally when the last line of its body is executed. However, one can go to a line number which doesn't exist to end the function immediately. For example:&lt;/p&gt;&lt;quote&gt;→(X&amp;lt;1)/0 →0 →7 ⍝ Suppose this line is in a function with six lines&lt;/quote&gt;&lt;/item&gt;
      &lt;item&gt;Structured control keywords&lt;p&gt;Some APLs support structured-control keywords for flow control. This makes APL more readable. (GNU APL, however, does not support them)&lt;/p&gt;&lt;p&gt;Here is a table of keywords. These keywords are not part of the APL ISO, but they are supported in many implementations.&lt;/p&gt;&lt;th&gt;Function&lt;/th&gt;&lt;th&gt;Keyword&lt;/th&gt;&lt;td&gt;Conditional execution&lt;/td&gt;&lt;code&gt;:If&lt;/code&gt;,&lt;code&gt;:ElseIf&lt;/code&gt;,&lt;code&gt;:Else&lt;/code&gt;,&lt;code&gt;:EndIf&lt;/code&gt;&lt;td&gt;For loop&lt;/td&gt;&lt;code&gt;:For&lt;/code&gt;,&lt;code&gt;:EndFor&lt;/code&gt;&lt;td&gt;While loop&lt;/td&gt;&lt;code&gt;:While&lt;/code&gt;,&lt;code&gt;:EndWhile&lt;/code&gt;&lt;td&gt;Repeat loop&lt;/td&gt;&lt;code&gt;:Repeat&lt;/code&gt;,&lt;code&gt;:EndRepeat&lt;/code&gt;&lt;td&gt;Case selection&lt;/td&gt;&lt;code&gt;:Select&lt;/code&gt;,&lt;code&gt;:Case&lt;/code&gt;,&lt;code&gt;:CaseList&lt;/code&gt;,&lt;code&gt;:Else&lt;/code&gt;,&lt;code&gt;:EndSelect&lt;/code&gt;&lt;td&gt;Branch&lt;/td&gt;&lt;code&gt;:GoTo&lt;/code&gt;&lt;td&gt;Terminate function&lt;/td&gt;&lt;code&gt;:Return&lt;/code&gt;(same as&lt;code&gt;→0&lt;/code&gt;)&lt;/item&gt;
      &lt;item&gt;Comments in functions&lt;p&gt;Just use the Lamp (&lt;/p&gt;&lt;code&gt;⍝&lt;/code&gt;) symbol.&lt;/item&gt;
      &lt;item&gt;Ambivalent Functions&lt;p&gt;In APL2, dyadic functions may be used monodically. This happens when the left argument is undefined. This means that its Name Classification (&lt;/p&gt;&lt;code&gt;⎕NC&lt;/code&gt;) is&lt;code&gt;0&lt;/code&gt;. This can be compared:&lt;quote&gt;∇R←A AMBIVALENT B →(0=⎕NC 'A')/MONADIC →DYADIC MONADIC: A←5 DYADIC: R←A+B ∇ 1 AMBIVALENT 2 ⍝ Dyadic usage; yields 3 AMBIVALENT 2 ⍝ Monadic usage; yields 7&lt;/quote&gt;&lt;p&gt;Some APLs like NARS2000 and Dyalog use a particular syntax which distinguishes ambivalent and dyadic functions. See these function headers:&lt;/p&gt;&lt;quote&gt;∇R←A NOMADIC B ⍝ Dyadic ∇ ∇R←{A} NOMADIB B ⍝ Ambivalent ∇&lt;/quote&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Extra: Lambdas&lt;/head&gt;
    &lt;p&gt;GNU APL has limited support for lambda expressions. Those are functions which are defined inline, and can even be named.&lt;/p&gt;
    &lt;p&gt; In lambdas, Alpha (&lt;code&gt;⍺&lt;/code&gt;) is the symbol used for the left argument, and
Omega (&lt;code&gt;⍵&lt;/code&gt;) is the symbol used for the right argument. All lambdas are
one-line functions, enclosed in Curly Brackets (&lt;code&gt;{}&lt;/code&gt;), which can be
monadic or dyadic depending on argument usage, and their single line
always return a value.
&lt;/p&gt;
    &lt;quote&gt;AVERAGE ← {(+/⍵)÷⍴⍵} ⍝ Named lambda 2 {⍺+⍵} 3 ⍝ Unnamed lambda, applied immediately&lt;/quote&gt;
    &lt;p&gt; Here is an example lambda function which finds all the prime numbers below the second argument (&lt;code&gt;⍵&lt;/code&gt;) of the monadic function (ACHARYA and
PEREIRA):
&lt;/p&gt;
    &lt;quote&gt;PRIMES ← {(~⍵∊⍵∘.×⍵)/⍵←1↓⍳⍵} PRIMES 100&lt;/quote&gt;
    &lt;head rend="h3"&gt;Error Handling&lt;/head&gt;
    &lt;quote&gt;⍝ Error handling&lt;/quote&gt;
    &lt;head rend="h4"&gt;Errors in calculator mode&lt;/head&gt;
    &lt;p&gt; APL prints errors when you type a statement containing an error in calculator mode. For example, this yields a &lt;code&gt;DOMAIN ERROR&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;1 1 0 'a'∨1 1 0 0&lt;/quote&gt;
    &lt;p&gt;To correct an error in calculator mode, simply retype the statement correctly, or use the the implementation's line-editing facilities.&lt;/p&gt;
    &lt;head rend="h4"&gt;Errors in user-defined functions or operators&lt;/head&gt;
    &lt;p&gt;When executing a user-defined function or operator, if an error happens, the execution stops at that point. Modern APLs have a Debug window where you can examine and correct errors in the function or operator.&lt;/p&gt;
    &lt;head rend="h4"&gt;The state indicator&lt;/head&gt;
    &lt;p&gt; When the halted function was called by other function, one can inspect the call stack using the State Indicator. This can be done with the system function &lt;code&gt;)SI&lt;/code&gt; or, in some APLs, by inspecting the variable &lt;code&gt;⎕SI&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt;Here is an example taken from implementation APLX (deprecated):&lt;/p&gt;
    &lt;quote&gt;)SI C[2] * B[8] A[5]&lt;/quote&gt;
    &lt;p&gt; In the example above, the problem happened at function &lt;code&gt;C&lt;/code&gt;, at line
&lt;code&gt;2&lt;/code&gt;. This function was called by function &lt;code&gt;B&lt;/code&gt; at line &lt;code&gt;8&lt;/code&gt;, which was then
called by function &lt;code&gt;A&lt;/code&gt; on line &lt;code&gt;5&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; The asterisk means that the execution of line &lt;code&gt;2&lt;/code&gt; of function &lt;code&gt;C&lt;/code&gt; is still
pending. If another function were executed at this point and also
yielded an error, this would happen:
&lt;/p&gt;
    &lt;quote&gt;E[3] * D[6] C[2] * B[8] A[5]&lt;/quote&gt;
    &lt;p&gt; So now function &lt;code&gt;E&lt;/code&gt; at line &lt;code&gt;3&lt;/code&gt; is pendent, and was called from function &lt;code&gt;D&lt;/code&gt;
at line &lt;code&gt;6&lt;/code&gt;.
&lt;/p&gt;
    &lt;p&gt; This top level can be cleared by using the Goto symbol (&lt;code&gt;→&lt;/code&gt;). Another
&lt;code&gt;→&lt;/code&gt;, in this case, would clear the State Indicator completely.
&lt;/p&gt;
    &lt;quote&gt;→ )SI C[2] * B[8] A[5]&lt;/quote&gt;
    &lt;p&gt; There are also system functions to clear the State Indicator. In GNU APL, this can be done with &lt;code&gt;)RESET&lt;/code&gt;.
&lt;/p&gt;
    &lt;head rend="h4"&gt;Action after suspended execution&lt;/head&gt;
    &lt;p&gt; One can resume the suspended execution where it stopped. To do so, just type Goto (&lt;code&gt;→&lt;/code&gt;) followed by the line number.
&lt;/p&gt;
    &lt;quote&gt;→3 ⍝ Suppose execution halted at line 3 of the function&lt;/quote&gt;
    &lt;p&gt;It is not mandatory to continue execution where the function halted. For example, suppose you want to restart at the next line:&lt;/p&gt;
    &lt;code&gt;→4
&lt;/code&gt;
    &lt;p&gt; Another way to do this is by using the niladic system function &lt;code&gt;⎕LC&lt;/code&gt;. This yields a vector containing all current line numbers of
functions in the State Indicator. All we need to do is to jump to the
first number of such vector:
&lt;/p&gt;
    &lt;quote&gt;→⌷LC&lt;/quote&gt;
    &lt;p&gt;Or, if we want to resume at the next line, we can also exploit the vector:&lt;/p&gt;
    &lt;quote&gt;→1+⎕LC&lt;/quote&gt;
    &lt;head rend="h4"&gt;Error trapping and tracing&lt;/head&gt;
    &lt;p&gt;It is possible to specify in advance what to do if an error occurs on execution; APL allows error trapping at runtime.&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Dyalog has the keywords &lt;code&gt;:Trap&lt;/code&gt;,&lt;code&gt;:EndTrap&lt;/code&gt;,&lt;code&gt;:Case&lt;/code&gt;and&lt;code&gt;:Else&lt;/code&gt;, and the system variable&lt;code&gt;⎕TRAP&lt;/code&gt;which allows precise control;&lt;/item&gt;
      &lt;item&gt;APL2 has the system variables &lt;code&gt;⎕EA&lt;/code&gt;(Execute Alternate; executes the right argument and, if it fails, executes the left one) and&lt;code&gt;⌷EC&lt;/code&gt;(Execute Controlled; Executes the argument and returns the result, if any. Also returns additional information on errors).&lt;/item&gt;
      &lt;item&gt;APL+Win has the keywords &lt;code&gt;:Try&lt;/code&gt;,&lt;code&gt;:Catch&lt;/code&gt;and&lt;code&gt;:Finally&lt;/code&gt;; and the&lt;code&gt;⎕ELX&lt;/code&gt;system variable executes the argument passed on its right, whenever an error occurs.&lt;/item&gt;
      &lt;item&gt;NARS2000 has &lt;code&gt;⎕ELX&lt;/code&gt;like APL+Win, and&lt;code&gt;⎕EA&lt;/code&gt;and&lt;code&gt;⌷EC&lt;/code&gt;, like APL2.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;It seems like GNU APL does not have error trapping facilities.&lt;/p&gt;
    &lt;head rend="h3"&gt;Formatting&lt;/head&gt;
    &lt;quote&gt;⍝ Formatting&lt;/quote&gt;
    &lt;head rend="h4"&gt;The "Format" primitive&lt;/head&gt;
    &lt;p&gt; Useful variable: &lt;code&gt;⎕PP&lt;/code&gt; (Print Precision).
&lt;/p&gt;
    &lt;p&gt;When the left argument is not specified, the data is converted into plain text with no specific format, using only display defaults.&lt;/p&gt;
    &lt;quote&gt;⍕ 0.0000003 3.0123456789&lt;/quote&gt;
    &lt;p&gt;With two arguments, the left argument is always a list of two elements: Field width and number of decimal places.&lt;/p&gt;
    &lt;quote&gt;6 2⍕341.82921&lt;/quote&gt;
    &lt;p&gt;Note that, before the number was truncated, it was rounded.&lt;/p&gt;
    &lt;head rend="h4"&gt;The system function &lt;code&gt;⎕FMT&lt;/code&gt;&lt;/head&gt;
    &lt;p&gt; Some APL implementations (except APL2 and GNU APL) have a &lt;code&gt;⎕FMT&lt;/code&gt; system
function:
&lt;/p&gt;
    &lt;quote&gt;'B K2 G&amp;lt; ZZ9 DOLLARS AND 99 CENTS&amp;gt;' ⎕FMT 8.23 12.86 0 2.52 8 DOLLARS AND 23 CENTS 12 DOLLARS AND 86 CENTS 2 DOLLARS AND 52 CENTS&lt;/quote&gt;
    &lt;head rend="h3"&gt;End of Tutorial&lt;/head&gt;
    &lt;quote&gt;)CLEAR&lt;/quote&gt;
    &lt;head rend="h2"&gt;Further Topics in APL&lt;/head&gt;
    &lt;p&gt;These are very useful topics which I will only take some notes on new things I find interesting. Here is the link to the relevant contents.&lt;/p&gt;
    &lt;p&gt;It is also useful to check the GNU APL Manual&lt;/p&gt;
    &lt;head rend="h3"&gt;Displaying the Shape of an Array&lt;/head&gt;
    &lt;quote&gt;⍝⍝⍝ Further Topics in APL ⍝ Displaying the shape of an array&lt;/quote&gt;
    &lt;p&gt; Most APLS have a &lt;code&gt;DISPLAY&lt;/code&gt; or &lt;code&gt;⎕DISPLAY&lt;/code&gt; system function to draw boxes
around data. GNU APL uses &lt;code&gt;⎕CR&lt;/code&gt; for that. For example:
&lt;/p&gt;
    &lt;quote&gt;8⎕CR 3 4⍴12?50 8⎕CR 1 (⍳2) 3 4 5 8⎕CR 1 'A' (2 3) (2 5⍴'HELLOWORLD')&lt;/quote&gt;
    &lt;p&gt;Results are better seen with GNU FreeFont:&lt;/p&gt;
    &lt;quote&gt;┌→──────────┐ ↓40 26 30 24│ │50 35 31 47│ │43 45 38 11│ └───────────┘ ┌→────────────┐ │1 ┌→──┐ 3 4 5│ │ │1 2│ │ │ └───┘ │ └∊────────────┘ ┌→────────────────┐ │1 A ┌→──┐ ┌→────┐│ │ │2 3│ ↓HELLO││ │ └───┘ │WORLD││ │ └─────┘│ └∊────────────────┘&lt;/quote&gt;
    &lt;p&gt;Meaning of symbols used when drawing boxes:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Sym&lt;/cell&gt;
        &lt;cell role="head"&gt;Placement&lt;/cell&gt;
        &lt;cell role="head"&gt;Meaning&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;-&lt;/cell&gt;
        &lt;cell&gt;Beneath character&lt;/cell&gt;
        &lt;cell&gt;Scalar character&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;→&lt;/cell&gt;
        &lt;cell&gt;Left of top edge&lt;/cell&gt;
        &lt;cell&gt;Vector or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;~&lt;/cell&gt;
        &lt;cell&gt;Left of bottom edge&lt;/cell&gt;
        &lt;cell&gt;Numeric data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;+&lt;/cell&gt;
        &lt;cell&gt;Left of bottom edge&lt;/cell&gt;
        &lt;cell&gt;Mixed data&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;⊖&lt;/cell&gt;
        &lt;cell&gt;Left of top edge&lt;/cell&gt;
        &lt;cell&gt;Empty vector or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;↓&lt;/cell&gt;
        &lt;cell&gt;Left side of box&lt;/cell&gt;
        &lt;cell&gt;Matrix or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;⌽&lt;/cell&gt;
        &lt;cell&gt;Left side of box&lt;/cell&gt;
        &lt;cell&gt;Empty matrix or higher-rank array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;∊&lt;/cell&gt;
        &lt;cell&gt;Left of bottom edge&lt;/cell&gt;
        &lt;cell&gt;Nested array&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h3"&gt;Array Type and Prototype&lt;/head&gt;
    &lt;quote&gt;⍝ Array type and prototype&lt;/quote&gt;
    &lt;p&gt; Arrays of one or more dimensions of zero length are known as empty array, which can be generated with Reshape (&lt;code&gt;⍴&lt;/code&gt;) or a selection of sorts
(like with Compress, &lt;code&gt;/&lt;/code&gt;). Its type can be numeric, simple character or
nested, depending on how it was created.
&lt;/p&gt;
    &lt;p&gt; Empty arrays are useful for initializing arrays where data will be added in the future, for creating scalars from arrays or as argument to Goto (&lt;code&gt;→&lt;/code&gt;).
&lt;/p&gt;
    &lt;head rend="h4"&gt;Array Type and Prototype&lt;/head&gt;
    &lt;p&gt;Arrays have a type zero for numeric elements, and blank character for character elements.&lt;/p&gt;
    &lt;quote&gt;⍝ Empty numeric vector and empty character vector 8⎕CR ⍳0 ◊ 8⎕CR '' ⍝ Same thing, but using ⍴ 8⎕CR 0⍴676 ◊ 8⎕CR 0⍴'PETER'&lt;/quote&gt;
    &lt;quote&gt;┌⊖┐ │0│ └─┘ ┌⊖┐ │ │ └─┘&lt;/quote&gt;
    &lt;p&gt; Empty numeric vectors can also be created using Zilde (&lt;code&gt;⍬&lt;/code&gt;).
&lt;/p&gt;
    &lt;quote&gt;X←⍬ ⍴X X≡0⍴0 8⎕CR ⍬&lt;/quote&gt;
    &lt;quote&gt;0 1 ┌⊖┐ │0│ └─┘&lt;/quote&gt;
    &lt;head rend="h4"&gt;Prototypes of nested arrays&lt;/head&gt;
    &lt;p&gt;Complex empty arrays can be created by using a nested array to generate the empty array:&lt;/p&gt;
    &lt;quote&gt;⍝ A nested array containing a list of characters ⍝ and a list of numbers; the second statement ⍝ is an empty nested array containing another ⍝ empty array. 8⎕CR 'ABC' (⍳3) ◊ 8⎕CR 0⍴'ABC' (⍳3)&lt;/quote&gt;
    &lt;quote&gt;┌→────────────┐ │┌→──┐ ┌→────┐│ ││ABC│ │1 2 3││ │└───┘ └─────┘│ └∊────────────┘ ┌⊖────┐ │┌→──┐│ ││ ││ │└───┘│ └∊────┘&lt;/quote&gt;
    &lt;p&gt;When the first element is numeric, we end up with a nested array of null elements.&lt;/p&gt;
    &lt;quote&gt;8⎕CR (2 2⍴⍳4) 'ABC' ◊ 8⎕CR 0⍴(2 2⍴⍳4) 'ABC'&lt;/quote&gt;
    &lt;quote&gt;┌→──────────┐ │┌→──┐ ┌→──┐│ │↓1 2│ │ABC││ ││3 4│ └───┘│ │└───┘ │ └∊──────────┘ ┌⊖────┐ │┌→──┐│ │↓0 0││ ││0 0││ │└───┘│ └∊────┘&lt;/quote&gt;
    &lt;p&gt;If the first element is mixed, then we'll have an array filled with zeroes and empty characters.&lt;/p&gt;
    &lt;quote&gt;8⎕CR (2 2⍴1 'K' 2 'J') (⍳4) ◊ 8⎕CR 0⍴(2 2⍴1 'K' 2 'J') (⍳4)&lt;/quote&gt;
    &lt;quote&gt;┌→──────────────┐ │┌→──┐ ┌→──────┐│ │↓1 K│ │1 2 3 4││ ││2 J│ └───────┘│ │└───┘ │ └∊──────────────┘ ┌⊖────┐ │┌→──┐│ │↓0 ││ ││0 ││ │└───┘│ └∊────┘&lt;/quote&gt;
    &lt;p&gt;Therefore, the prototype concept can be used to display the type of an array.&lt;/p&gt;
    &lt;quote&gt;8⎕CR VAR ← (2 2⍴1 'A' 'B' 2) ((⍳2) 7) 'ABC'&lt;/quote&gt;
    &lt;quote&gt;┌→────────────────────┐ │┌→──┐ ┌→──────┐ ┌→──┐│ │↓1 A│ │┌→──┐ 7│ │ABC││ ││B 2│ ││1 2│ │ └───┘│ │└───┘ │└───┘ │ │ │ └∊──────┘ │ └∊∊───────────────────┘&lt;/quote&gt;
    &lt;p&gt; To display the array type, we first enclose (&lt;code&gt;⊂&lt;/code&gt;) the array to make it a
scalar, then we build the empty vector with it (&lt;code&gt;0⍴&lt;/code&gt;). Since building
the empty vector creates an additional level of nesting, we use the
First (&lt;code&gt;↑&lt;/code&gt;) function to remove it:
&lt;/p&gt;
    &lt;quote&gt;8⎕CR ↑0⍴⊂VAR&lt;/quote&gt;
    &lt;quote&gt;┌→────────────────────┐ │┌→──┐ ┌→──────┐ ┌→──┐│ │↓0 │ │┌→──┐ 0│ │ ││ ││ 0│ ││0 0│ │ └───┘│ │└───┘ │└───┘ │ │ │ └∊──────┘ │ └∊∊───────────────────┘&lt;/quote&gt;
    &lt;head rend="h4"&gt;The prototype as a fill element&lt;/head&gt;
    &lt;p&gt; Functions such as Take (&lt;code&gt;↑&lt;/code&gt;), Expand (&lt;code&gt;\&lt;/code&gt;) and Replicate (&lt;code&gt;/&lt;/code&gt;) add elements
to an existing array. A prototype can be used to determine the type
and shape of extra elements.
&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Type of array&lt;/cell&gt;
        &lt;cell role="head"&gt;Fill Element&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Numeric&lt;/cell&gt;
        &lt;cell&gt;0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Character&lt;/cell&gt;
        &lt;cell&gt;Space&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Nested/Mixed&lt;/cell&gt;
        &lt;cell&gt;Prototype of first element, with&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Numbers/Characters replaced&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;accordingly&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here are some examples.&lt;/p&gt;
    &lt;quote&gt;8⎕CR 5↑1 2 3 ◊ 8⎕CR 5↑'ABC' ⍝ Numeric and textual vectors of 5 elts 8⎕CR 2↑0⍴⊂VAR ⍝ Vector containing two prototypes 8⎕CR 2↑⊂VAR ⍝ Put VAR's prototype after VAR, in a vector 8⎕CR ¯2↑⊂VAR ⍝ Put VAR's prototype before VAR, in a vector&lt;/quote&gt;
    &lt;quote&gt;┌→────────┐ │1 2 3 0 0│ └─────────┘ ┌→────┐ │ABC │ └─────┘ ┌→──────────────────────────────────────────────┐ │┌→────────────────────┐ ┌→────────────────────┐│ ││┌→──┐ ┌→──────┐ ┌→──┐│ │┌→──┐ ┌→──────┐ ┌→──┐││ ││↓0 │ │┌→──┐ 0│ │ ││ │↓0 │ │┌→──┐ 0│ │ │││ │││ 0│ ││0 0│ │ └───┘│ ││ 0│ ││0 0│ │ └───┘││ ││└───┘ │└───┘ │ │ │└───┘ │└───┘ │ ││ ││ └∊──────┘ │ │ └∊──────┘ ││ │└∊∊───────────────────┘ └∊∊───────────────────┘│ └∊∊∊────────────────────────────────────────────┘ ┌→──────────────────────────────────────────────┐ │┌→────────────────────┐ ┌→────────────────────┐│ ││┌→──┐ ┌→──────┐ ┌→──┐│ │┌→──┐ ┌→──────┐ ┌→──┐││ ││↓1 A│ │┌→──┐ 7│ │ABC││ │↓0 │ │┌→──┐ 0│ │ │││ │││B 2│ ││1 2│ │ └───┘│ ││ 0│ ││0 0│ │ └───┘││ ││└───┘ │└───┘ │ │ │└───┘ │└───┘ │ ││ ││ └∊──────┘ │ │ └∊──────┘ ││ │└∊∊───────────────────┘ └∊∊───────────────────┘│ └∊∊∊────────────────────────────────────────────┘ ┌→──────────────────────────────────────────────┐ │┌→────────────────────┐ ┌→────────────────────┐│ ││┌→──┐ ┌→──────┐ ┌→──┐│ │┌→──┐ ┌→──────┐ ┌→──┐││ ││↓0 │ │┌→──┐ 0│ │ ││ │↓1 A│ │┌→──┐ 7│ │ABC│││ │││ 0│ ││0 0│ │ └───┘│ ││B 2│ ││1 2│ │ └───┘││ ││└───┘ │└───┘ │ │ │└───┘ │└───┘ │ ││ ││ └∊──────┘ │ │ └∊──────┘ ││ │└∊∊───────────────────┘ └∊∊───────────────────┘│ └∊∊∊────────────────────────────────────────────┘&lt;/quote&gt;
    &lt;p&gt;More info: Empty Arrays and Prototypes&lt;/p&gt;
    &lt;head rend="h3"&gt;Vector Notation&lt;/head&gt;
    &lt;p&gt;Nothing new here. Just pay attention to how the vectors are constructed:&lt;/p&gt;
    &lt;quote&gt;8⎕CR 'ABC' 'DEF' 8⎕CR (1 2 3) 'DEF' ⍴1 2 3 'DEF' ⍴1 2 3 'D' 'E' 'F' 8⎕CR ((1 2) (3 4)) 2 3 X←2 2⍴⍳4 Y←'HELLO' 8⎕CR (X Y) ⍝ Variables entered in vector form ⍴X Y&lt;/quote&gt;
    &lt;quote&gt;8⎕CR 'ABC' 'DEF' ┌→──────────┐ │┌→──┐ ┌→──┐│ ││ABC│ │DEF││ │└───┘ └───┘│ └∊──────────┘ 8⎕CR ((1 2 3) 'DEF') ┌→────────────┐ │┌→────┐ ┌→──┐│ ││1 2 3│ │DEF││ │└─────┘ └───┘│ └∊────────────┘ ⍴1 2 3 'DEF' 4 ⍴1 2 3 'D' 'E' 'F' 6 8⎕CR ((1 2) (3 4)) 2 3 ┌→────────────────┐ │┌→──────────┐ 2 3│ ││┌→──┐ ┌→──┐│ │ │││1 2│ │3 4││ │ ││└───┘ └───┘│ │ │└∊──────────┘ │ └∊∊───────────────┘ X←2 2⍴⍳4 Y←'HELLO' 8⎕CR (X Y) ⍝ Variables entered in vector form ┌→────────────┐ │┌→──┐ ┌→────┐│ │↓1 2│ │HELLO││ ││3 4│ └─────┘│ │└───┘ │ └∊────────────┘ ⍴X Y 2&lt;/quote&gt;
    &lt;head rend="h3"&gt;Variables and Indexing&lt;/head&gt;
    &lt;p&gt;Nothing new too.&lt;/p&gt;
    &lt;quote&gt;LIST←12 24 36 48 LIST[2] LIST[1]+LIST[4] ALF←'ABCDEFGHIJKLMNOPQRSTUVWXYZ' ALF[26 1 13 2 9 1] TABLE←10×2 4⍴⍳8 TABLE[1;4] TABLE[1;⍳4]+TABLE[2;⍳4] TABLE[1;]+TABLE[2;] (⍴TABLE[1;2 3])=(⍴1),⍴2 3 ALF[2 2⍴⍳4] ⍴TABLE[1;] ⍝ Rows indexed by scalar, result is vector ⍴TABLE[,1;] ⍝ Rows indexed by vector, result is matrix ⍴TABLE[1 1⍴1;] ⍝ Rows indexed by matrix, result is cube&lt;/quote&gt;
    &lt;head rend="h4"&gt;The Index (&lt;code&gt;⌷&lt;/code&gt;) function&lt;/head&gt;
    &lt;quote&gt;TABLE[1;2]=1 2⌷TABLE 2⌷⍳5 (⊂3 4)⌷⍳5 ⍝ Use a nested scalar for multiple index. TAB←2 5⍴⍳10 8⎕CR TAB 2 3⌷TAB 2 (2 3)⌷TAB ⍝ 2nd element of indexing vec is an enclosed vec ⍝ Nested 2-elts vector for multiple indexes. ⍝ Result is a submatrix of TAB located at ⍝ rows 1 2, columns 2 3. (1 2) (2 3)⌷TAB ⍝ An empty left argument is OK for index when ⍝ a scalar is the right argument. This returns ⍝ the scalar itself. (⍳0)⌷37&lt;/quote&gt;
    &lt;head rend="h3"&gt;Multiple Specification&lt;/head&gt;
    &lt;p&gt;Nothing new here as well.&lt;/p&gt;
    &lt;quote&gt;(A B C)←1 2 3 A ◊ B ◊ C (A B C)←5 A ◊ B ◊ C (A B C)←'HI' 'THERE' 'FOLKS' ⍴A ⍝ See that A received 'HI' only (A B C)←⊂'HI' 'THERE' 'FOLKS' ⍴A ⍝ All three variables received a vec of the three char vecs 8⎕CR A&lt;/quote&gt;
    &lt;head rend="h3"&gt;Selective Specification&lt;/head&gt;
    &lt;p&gt;Some functions in APL can be used to select portions of an array. When associated with assignment, they can be used to assign values to portions of such array.&lt;/p&gt;
    &lt;p&gt;Bracket indexing is the easiest example.&lt;/p&gt;
    &lt;quote&gt;TAB←2 3⍴⍳6 TAB[2;1]←8&lt;/quote&gt;
    &lt;p&gt; Let's assign the first three elements of a vector by using the Take (dyadic &lt;code&gt;↑&lt;/code&gt;) function.
&lt;/p&gt;
    &lt;quote&gt;VEC←⍳5 (3↑VEC)←'ABC' 8⎕CR VEC&lt;/quote&gt;
    &lt;quote&gt;┌→──────┐ │ABC 4 5│ └───────┘&lt;/quote&gt;
    &lt;p&gt; Let's use the Ravel (monadic &lt;code&gt;,&lt;/code&gt;) on a matrix to assign a new vector
value to it:
&lt;/p&gt;
    &lt;quote&gt;MAT←3 4⍴'ABCDEFGHIJKL' (,MAT)←'NEW DATAHERE' ⍝ Ravelled matrix appears as a vector 8⎕CR MAT ⍝ Assignment occurs in matrix itself&lt;/quote&gt;
    &lt;quote&gt;┌→───┐ ↓NEW │ │DATA│ │HERE│ └────┘&lt;/quote&gt;
    &lt;p&gt; Now let's combine Compression (dyadic &lt;code&gt;/&lt;/code&gt;) and Ravel (monadic &lt;code&gt;,&lt;/code&gt;) to
select all A's on the matrix, and replace them by asterisk:
&lt;/p&gt;
    &lt;quote&gt;(('A'=,MAT)/,MAT)←'*' 8⎕CR MAT&lt;/quote&gt;
    &lt;quote&gt;┌→───┐ ↓NEW │ │D*T*│ │HERE│ └────┘&lt;/quote&gt;
    &lt;p&gt; We can also combine Take (dyadic &lt;code&gt;↑&lt;/code&gt;) and Ravel (monadic &lt;code&gt;,&lt;/code&gt;) to replace
elements at the top-left 2×2 submatrix of &lt;code&gt;MAT&lt;/code&gt;:
&lt;/p&gt;
    &lt;quote&gt;(,2 2↑MAT)←'⎕⎕⎕⎕' 8⎕CR MAT&lt;/quote&gt;
    &lt;quote&gt;┌→───┐ ↓⎕⎕W │ │⎕⎕T*│ │HERE│ └────┘&lt;/quote&gt;
    &lt;p&gt; We can also use the Compression (&lt;code&gt;/&lt;/code&gt;) function for selection.
&lt;/p&gt;
    &lt;quote&gt;TABLE←3 4⍴⍳12 8⎕CR TABLE (1 0 1 0/TABLE)←3 2⍴100 8⎕CR TABLE&lt;/quote&gt;
    &lt;quote&gt;┌→─────────┐ ↓1 2 3 4│ │5 6 7 8│ │9 10 11 12│ └──────────┘ ┌→────────────┐ ↓100 2 100 4│ │100 6 100 8│ │100 10 100 12│ └─────────────┘&lt;/quote&gt;
    &lt;p&gt; In the next example, we have a vector &lt;code&gt;X&lt;/code&gt;. We want to replace the first
&lt;code&gt;⍴X&lt;/code&gt; elements of &lt;code&gt;DATA&lt;/code&gt; with the contents of &lt;code&gt;X&lt;/code&gt;.
&lt;/p&gt;
    &lt;quote&gt;DATA←⍳13 X←10×⍳3 8⎕CR DATA ((⍴X)↑DATA)←X 8⎕CR DATA&lt;/quote&gt;
    &lt;quote&gt;┌→────────────────────────────┐ │1 2 3 4 5 6 7 8 9 10 11 12 13│ └─────────────────────────────┘ ┌→───────────────────────────────┐ │10 20 30 4 5 6 7 8 9 10 11 12 13│ └────────────────────────────────┘&lt;/quote&gt;
    &lt;p&gt; Replace the first &lt;code&gt;X+2&lt;/code&gt; elements of &lt;code&gt;Y&lt;/code&gt; with the reverse of a vector
containing numbers &lt;code&gt;1&lt;/code&gt; up to &lt;code&gt;X+2:&lt;/code&gt;
&lt;/p&gt;
    &lt;quote&gt;Y←⍳10 X←3 8⎕CR Y ((2+X)↑Y)←⌽⍳X+2 8⎕CR Y&lt;/quote&gt;
    &lt;quote&gt;┌→───────────────────┐ │1 2 3 4 5 6 7 8 9 10│ └────────────────────┘ ┌→───────────────────┐ │5 4 3 2 1 6 7 8 9 10│ └────────────────────┘&lt;/quote&gt;
    &lt;p&gt; We can use Enlist (monadic &lt;code&gt;∊&lt;/code&gt;) to remove nesting from an array.
&lt;/p&gt;
    &lt;quote&gt;8⎕CR NEST←(2 2⍴⍳4) 'TEXT' (3 1⍴⍳3) (∊NEST)←0 8⎕CR NEST ⍝ Set specific position to number (6⌷∊NEST)←999 8⎕CR NEST ⍝ Set specific position to character vector (text). ⍝ For that, introduce extra nesting to the new text. (7⌷∊NEST)←⊂'TEXT' 8⎕CR NEST&lt;/quote&gt;
    &lt;quote&gt;┌→───────────────┐ │┌→──┐ ┌→───┐ ┌→┐│ │↓1 2│ │TEXT│ ↓1││ ││3 4│ └────┘ │2││ │└───┘ │3││ │ └─┘│ └∊───────────────┘ ┌→──────────────────┐ │┌→──┐ ┌→──────┐ ┌→┐│ │↓0 0│ │0 0 0 0│ ↓0││ ││0 0│ └───────┘ │0││ │└───┘ │0││ │ └─┘│ └∊──────────────────┘ ┌→────────────────────┐ │┌→──┐ ┌→────────┐ ┌→┐│ │↓0 0│ │0 999 0 0│ ↓0││ ││0 0│ └─────────┘ │0││ │└───┘ │0││ │ └─┘│ └∊────────────────────┘ ┌→─────────────────────────┐ │┌→──┐ ┌→─────────────┐ ┌→┐│ │↓0 0│ │0 999 ┌→───┐ 0│ ↓0││ ││0 0│ │ │TEXT│ │ │0││ │└───┘ │ └────┘ │ │0││ │ └∊─────────────┘ └─┘│ └∊∊────────────────────────┘&lt;/quote&gt;
    &lt;p&gt; The function First (monadic &lt;code&gt;↑&lt;/code&gt;) selects the first element of an
array. Here, we shall replace the first 2×2 matrix of &lt;code&gt;NEST&lt;/code&gt; by a
character vector.
&lt;/p&gt;
    &lt;quote&gt;(↑NEST)←'ABC' 8⎕CR NEST&lt;/quote&gt;
    &lt;p&gt;So, the sky is the limit. For more info, see this page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Binding Strengths&lt;/head&gt;
    &lt;p&gt;In general, APL evaluates from right to left. However, some elements can be said to have stronger binding.&lt;/p&gt;
    &lt;p&gt;Here is a descending list of binding strength.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Binding&lt;/cell&gt;
        &lt;cell role="head"&gt;Bound items&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Brackets &lt;code&gt;[]&lt;/code&gt;&lt;/cell&gt;
        &lt;cell&gt;Brackets to object to the left&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Specification &lt;code&gt;←&lt;/code&gt; left&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;←&lt;/code&gt; to object on its left&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Right operand&lt;/cell&gt;
        &lt;cell&gt;Dyadic operator to its right operand&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Vector&lt;/cell&gt;
        &lt;cell&gt;Array to array&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Left operand&lt;/cell&gt;
        &lt;cell&gt;Operator to its left operand&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Left argument&lt;/cell&gt;
        &lt;cell&gt;Function to left argument&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Right argument&lt;/cell&gt;
        &lt;cell&gt;Function to right argument&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Specification &lt;code&gt;←&lt;/code&gt; right&lt;/cell&gt;
        &lt;cell&gt;&lt;code&gt;←&lt;/code&gt; to object on its right&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;And parentheses can override the binding strength hierarchy.&lt;/p&gt;
    &lt;p&gt;For more info, see this page.&lt;/p&gt;
    &lt;head rend="h3"&gt;Pervasive Functions&lt;/head&gt;
    &lt;p&gt;There are Scalar and Mixed functions in APL. Scalar functions have the property of being pervasive, that is, they apply to all levels of nesting on the data.&lt;/p&gt;
    &lt;p&gt;Here are some scalar functions:&lt;/p&gt;
    &lt;quote&gt;+ - × ÷ | ⌈ ⌊ * ⍟ ○ ! ^ ∨ ⍲ ⍱ &amp;lt; ≤ = ≥ &amp;gt; ≠ Monadic ~ Monadic ?&lt;/quote&gt;
    &lt;p&gt;For more info, see this page.&lt;/p&gt;
    &lt;head rend="h3"&gt;OO, Classes and Inheritance&lt;/head&gt;
    &lt;p&gt;GNU APL does not support object orientation, therefore I will not be covering it. However, Dyalog APL does.&lt;/p&gt;
    &lt;p&gt;Object-oriented APL information can be found on this page.&lt;/p&gt;
    &lt;head rend="h2"&gt;Finishing&lt;/head&gt;
    &lt;quote&gt;⍝ Closes the script file. )OFF&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://luksamuk.codes/pages/learn-apl.html"/><published>2025-10-25T20:34:37+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706765</id><title>Project Amplify: Powered footwear for running and walking</title><updated>2025-10-25T23:32:25.259590+00:00</updated><content>&lt;doc fingerprint="d7d28bb7ec6b46bc"&gt;
  &lt;main&gt;
    &lt;div&gt;
      &lt;p&gt;Nike is unveiling Project Amplify: the world’s first powered footwear system for running and walking, designed to help everyday athletes go a little bit faster and farther — all with less effort.&lt;/p&gt;
      &lt;p&gt;Engineered to augment natural lower leg and ankle movement, the Project Amplify system breaks the perception of possibility by providing an unparalleled boost to anyone who wants to move, creating a new future for running, jogging and walking. &lt;/p&gt;
      &lt;p&gt;Built on motion algorithms informed by the Nike Sport Research Lab, the first-generation footwear system is comprised of a lightweight, powerful motor; drive belt; and rechargeable cuff battery that seamlessly integrate with a carbon fiber–plated running shoe that can be worn with or without the robotics system.&lt;/p&gt;
      &lt;p&gt;This makes it easier for everyday athletes to walk or run more often, for longer amounts of time, while having more fun — adding movement to their lives, extending their walking commute, or helping them to enjoy the run for another mile or two. &lt;/p&gt;
      &lt;p&gt;Each application reflects Nike’s unmatched commitment to solving problems for athletes, improving their experience and powering the future of sport. What’s more: Project Amplify represents one of four major technological advances Nike is unveiling this month, joining innovations across Air apparel, advanced cooling, and mind science in demonstrating the depth, breadth and impact of the brand’s commitment to athlete-centered innovation. &lt;/p&gt;
      &lt;p&gt;“Our job is to dream big while keeping athletes at the center,” says Michael Donaghu, VP of Create The Future, Emerging Sport and Innovation. “Project Amplify started with a single question: What if we could find a way to help athletes move faster and farther with less energy and a lot more fun? At its core, Project Amplify is about seamlessly adding a little more power to your stride. The fun comes from realizing you can do more than you thought you could — whatever ‘more’ means to you.”&lt;/p&gt;
      &lt;p&gt;Akin to how electric bikes have made it easier to ride farther and more frequently, revolutionizing urban commuting, Nike is developing Project Amplify to make slower running, jogging and walking easier and more fun, with a focus on athletes running between a 10- and 12-minute mile pace. &lt;/p&gt;
      &lt;p&gt;The first-generation product, created alongside robotics partner Dephy, isn’t designed for competitive, faster runners trying to shave seconds off their time; rather, it’s intended to serve athletes who want to go faster and farther with less effort by giving them more power for everyday movement — in effect, a second set of calf muscles.&lt;/p&gt;
      &lt;p&gt;That approach is backed by insights developed from NSRL testing involving athletes of all abilities and intensities, who have shared that the system feels like it’s part of their body and that it makes walking or running uphill feel like moving on flat ground. For some, wearing Project Amplify helps them go from a 12-minute mile to a 10-minute mile.&lt;/p&gt;
      &lt;p&gt;These learnings are the product of extensive testing over several years, both in outdoor environments and the NSRL. More than 400 athletes have covered over 2.4 million steps, the equivalent of roughly 12,000 laps around the NSRL’s 200-meter track, in more than nine different versions of the hardware — each iteration focused on refining a different element of the system. &lt;/p&gt;
      &lt;p&gt;“Is this new for Nike? Yes and no,” says Donaghu. “It’s obviously a new innovation, but the day Bill Bowerman poured rubber into the family waffle iron was the start of a journey to augment movement and create the future of sport. We’ve always believed movement is medicine, and Project Amplify is the next chapter in that story. It’s a bold leap forward, crossing a new threshold of putting power directly into your stride.”&lt;/p&gt;
      &lt;p&gt;With Project Amplify still in the testing stage, Nike is blending art and science to reach performance readiness and bring the footwear system to a broad consumer launch in the coming years. &lt;/p&gt;
      &lt;p&gt;* If you have a body, you are an athlete.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://about.nike.com/en/newsroom/releases/nike-project-amplify-official-images"/><published>2025-10-25T20:35:48+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706792</id><title>Show HN: Diagram as code tool with draggable customizations</title><updated>2025-10-25T23:32:24.562048+00:00</updated><content>&lt;doc fingerprint="2e583e5e3b2d53b2"&gt;
  &lt;main&gt;
    &lt;head class="px-3 py-2"&gt;oxdraw_demo.mov&lt;/head&gt;
    &lt;p&gt;The goal of &lt;code&gt;oxdraw&lt;/code&gt; is to make it easy to create and maintain high-quality diagrams using a declarative and reproducible syntax.
Charts are written in Mermaid syntax, while a web interface allows users to fine-tune positions connector paths, colors, and other styling components. Whenever a diagram is tweaked visually, the structural changes are persisted back to the source file as declarative code so that everything remains deterministic and versionable.
The changes are saved as comments in the mermaid file so it remains compatible with other Mermaid tools.
The repo is composed of the Rust CLI to compile &lt;code&gt;.mmd&lt;/code&gt; files into images and the React based web interface to editing the files.&lt;/p&gt;
    &lt;p&gt;The reason I started this project was I used Mermaid a lot in the past when making architecture diagrams or trying to understand large codebases through having AI tools generate .mmd files to visualize them. However what typically happened was since these diagrams couldn't be edited minutely for example cleaning up joints and chart organization, I would have to move over the diagrams I started to things like Lucidchart. So the big picture goal of this project is to unite the benefits of code generated diagramming like Mermaid with the customizability of diagram software like Lucidchart.&lt;/p&gt;
    &lt;code&gt;cargo install oxdraw&lt;/code&gt;
    &lt;code&gt;oxdraw --input flow.mmd  &lt;/code&gt;
    &lt;code&gt;oxdraw --input flow.mmd --edit&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Flag&lt;/cell&gt;
        &lt;cell role="head"&gt;Description&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-i, --input &amp;lt;PATH&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Read a Mermaid source file; pass &lt;code&gt;-&lt;/code&gt; to consume stdin instead.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-o, --output &amp;lt;PATH&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Write the rendered asset to a specific path; pass &lt;code&gt;-&lt;/code&gt; to stream SVG to stdout. Defaults to &lt;code&gt;&amp;lt;input&amp;gt;.svg&lt;/code&gt; (or &lt;code&gt;&amp;lt;input&amp;gt;.&amp;lt;format&amp;gt;&lt;/code&gt; if an explicit format is chosen) and &lt;code&gt;out.svg&lt;/code&gt; when reading from stdin.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--png&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Shorthand for &lt;code&gt;--output-format png&lt;/code&gt;&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--scale &amp;lt;FACTOR&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Scale multiplier for PNG rasterization (default &lt;code&gt;10.0&lt;/code&gt;); values must be greater than zero. Ignored for SVG output.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--edit&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Launch the interactive editor pointing at the supplied diagram instead of emitting an asset once.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--serve-host &amp;lt;ADDR&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Override the bind address used while &lt;code&gt;--edit&lt;/code&gt; is active (default &lt;code&gt;127.0.0.1&lt;/code&gt;).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;--serve-port &amp;lt;PORT&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Override the HTTP port while &lt;code&gt;--edit&lt;/code&gt; is active (default &lt;code&gt;5151&lt;/code&gt;).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;-b, --background-color &amp;lt;COLOR&amp;gt;&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Background fill passed to the renderer (currently SVG only). Applies to both one-off renders and the editor preview.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;-q, --quiet&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Suppress informational stdout such as the success message after rendering to disk.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Control&lt;/cell&gt;
        &lt;cell role="head"&gt;What it does&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Delete selected&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Removes the currently selected node or edge; available via the Delete/Backspace keys as well.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Node Fill/Stroke/Text pickers&lt;/cell&gt;
        &lt;cell&gt;Apply per-node color overrides; double-clicking a node clears its override.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Reset node style&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Remove all color overrides for the selected node.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge Color picker&lt;/cell&gt;
        &lt;cell&gt;Override the selected edge stroke color.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge Line selector&lt;/cell&gt;
        &lt;cell&gt;Toggle between solid and dashed stroke styles.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Edge Arrow selector&lt;/cell&gt;
        &lt;cell&gt;Choose arrow directions (forward/backward/both/none).&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;
          &lt;code&gt;Add control point&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Insert a new draggable waypoint on the selected edge to fine-tune routing.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;
          &lt;code&gt;Reset edge style&lt;/code&gt;
        &lt;/cell&gt;
        &lt;cell&gt;Drop edge-specific styling and revert to defaults; double-clicking an edge handle also clears its manual path.&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Canvas and editor interactions&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Drag nodes to update their stored positions with grid snapping and live alignment guides; Shift+Arrow nudges the selection in grid-sized jumps.&lt;/item&gt;
      &lt;item&gt;Drag edge handles (or the label handle) to reshape routes; double-click an edge to insert a handle and double-click a handle to remove overrides.&lt;/item&gt;
      &lt;item&gt;Drag an entire subgraph container to move all of its member nodes (and any edge overrides) together while maintaining separation from sibling groups.&lt;/item&gt;
      &lt;item&gt;The source panel mirrors the Mermaid file, auto-saves after short idle periods, and surfaces pending/saving/error states alongside the current selection.&lt;/item&gt;
      &lt;item&gt;Status text in the top toolbar signals loading, saving, and the currently edited file path.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head class="px-3 py-2"&gt;path_algo.mov&lt;/head&gt;
    &lt;p&gt;The path drawing algorithm is fun because there is a lot of ambiguity with what optimal behavior could be. Some prefer smooth lines because there is less total line but I prefer strong edges to make the diagram a bit more clear. Some prefer no overlapping lines but I sometimes prefer an overlap rather than letting the lines get super long and string out of the diagram very far. This is an example of using the delete key to remove one relationship and then using the arrow keys to move around one the nodes and seeing how the algorithm recomputes the positioning. There's definitely some improvements to be made to this algorithm so I imagine this will keep getting better :)&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/RohanAdwankar/oxdraw"/><published>2025-10-25T20:38:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706815</id><title>ARM Memory Tagging: how it improves C/C++ memory safety (2018) [pdf]</title><updated>2025-10-25T23:32:24.482412+00:00</updated><content/><link href="https://llvm.org/devmtg/2018-10/slides/Serebryany-Stepanov-Tsyrklevich-Memory-Tagging-Slides-LLVM-2018.pdf"/><published>2025-10-25T20:42:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706866</id><title>An Update on TinyKVM</title><updated>2025-10-25T23:32:24.280721+00:00</updated><content>&lt;doc fingerprint="343ac81d7d099be8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;An update on TinyKVM&lt;/head&gt;
    &lt;p&gt;Hey all. TinyKVM was open-sourced this february and since then I’ve been working on some things that are very much outside of the scope of the original implementation. Originally, it was intended to be for pure computation (and that is very much still possible, and is the default), but makes it hard to use TinyKVM outside of specialized use-cases. So, I’ve relented and implemented limited support for running unmodified executables in TinyKVM. Specifically, run-times like Deno, Python WSGI and similar run-times like Lune.&lt;/p&gt;
    &lt;p&gt;I would like to make a special shout-out to Laurence Rowe who championed KVM server, which has now become almost a de-facto CLI for TinyKVM servers. It’s very much work in progress, but give it a try if you’re interested in these kinds of things.&lt;/p&gt;
    &lt;p&gt;In order to achieve this I picked the very untraditional route of implementing system call emulation, but as poorly as possible. And as few system calls as possible. I think today there is 50 real system calls (gVisor has ~200 for comparison), and all of them will to some degree make shit up (for lack of a better term). The goal is to avoid accessing the (shared) Linux kernel when at all possible, but give sanitized access when permitted and appropriate. To give an example of what I mean by this: The only allowed ioctl operations are setting and getting non-blocking mode (FIONBIO), and reading the number of available bytes (FIONREAD). This minimalist system call API is currently able to run quite a few complex run-times unmodified. Programs are surprisingly good at handling failing system calls, or suspicious return values. If you put a jailer on top it should be good enough for production, but I do still recommend to use TinyKVM in pure compute mode. Something like Jailer + TinyKVM + Deno + per request isolation.&lt;/p&gt;
    &lt;head rend="h3"&gt;Per-Request Isolation&lt;/head&gt;
    &lt;p&gt;Per-request isolation is apparently not that common. I could not find any other production-level support other than in wasmtime (and previously Lucet). But, due to its lack of in-guest JIT support it will not be able to compete with Deno so I will just focus on the positives: It uses a clever lazy MADV_DONTNEED mechanism which delays the cost. You can go test wasmtime’s per-request isolation right now with the hello-wasi-http example.&lt;/p&gt;
    &lt;p&gt;In TinyKVM there are two reset modes, which together forms hybrid per-request isolation that is capable of maintaining a low memory footprint. Together, it makes the fastest per-request isolation that exists right now. It’s main mode will directly rewrite all touched pages in a VM fork back to their original contents and then leave pagetables (and TLBs) intact. This mode has turned out to be the fastest, but as it leaves the memory footprint untouched it can only grow memory usage for forked VMs. Forked VMs are tiny to begin with, but for large page rendering work it may be a concern, hence there’s a second mode triggered by a fork using memory above a limit. The second mode resets the entire VM with pagetables and everything, which happens when it uses working memory above a certain limit or an exception occurs during request handling. It’s not particularly expensive on its own, but if every VM fork would do it all the time the IPIs and coherency chatter would be a bottleneck.&lt;/p&gt;
    &lt;p&gt;So we ran a full Deno page rendering benchmark in TinyKVM and then also the very same (unmodified) benchmark natively. We made GC single-threaded in order to compare equally. It would normally run async in another thread, but you’d still have to pay the cost of doing it. What we found was that TinyKVM generally had lower p90+ latency, while native had better p50.&lt;/p&gt;
    &lt;p&gt;Now this is incredible. Per-request isolation is very very expensive. We are resetting an entire KVM VM every request back to its original state. And we’re doing it very close to native not doing it at all. We’re doing it with unmodified Deno, a big run-time, and with a full page rendering benchmark, a large piece of compute work that builds real memory pressure.&lt;/p&gt;
    &lt;head rend="h3"&gt;A new type of remote procedure call&lt;/head&gt;
    &lt;p&gt;One of the things not on my 2025 bingo card was creating a custom RPC mechanism. And, it’s not that great outside of its specific use-case.&lt;/p&gt;
    &lt;p&gt;I figured that if you loaded two binaries into the same address space, couldn’t you just call a function in the other just fine? Turns out yes, especially if you trap on the far jump (not a real far jump) and then switch a few important registers like the thread-pointer (FSBASE). So, if you have to ABI- or FFI-compatible programs you can essentially freely call functions in the other. Now, this sounds dangerous for sandboxing and kinda useless if you can just use a super-fast IPC like iceoryx2, but.. it turns out that super-fast IPC requires the other end to be always scheduled and crucially also requires that caller to not be adversarial and trample shared memory while you’re reading it. If both of those things are true, then go ahead and use fast IPC. Being able to directly call a remote party without depending on the scheduler it turns out is really really performant. A simple schbench benchmark will tell you all you need to know about what happens when the scheduler is busy. You can go do it on your own machine. It’s commonly a 2-digit number of milliseconds you can expect for p99. So, this new method is in fact the new king of this specific type of RPC. The only remaining part then is how do you deal with sandbox integrity? Turns out you can just not have the remote part mapped in at all, and then either:&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;Directly resume the remote VM with your caller VMs address space already mapped in. This means that the remote VM is “higher privileged”, sort of. And you need a dedicated VM for persistence per caller. This is fine with tiny VM forks.&lt;/item&gt;
      &lt;item&gt;Map in the remote VM just-in-time on the execution page fault, execute the remote function call, unmap it (and flush TLBs) on return (or any exception, timeout). This also means the remote VM is “higher privileged”.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;So, what is this then? Are these two programs the same tenant? What does this have to do with per-request isolation?&lt;/p&gt;
    &lt;p&gt;Per-request isolation doesn’t have persistence. The entire request VM gets wiped on every request. It would be great if we could maintain something under certain conditions. So, then either it would have to make an expensive call out to a remote service (ala Binder on Android). Or, we could solve two problems in one: Allow tenants to have a program that is persistent, and give them direct scheduler-free access to it. That is, the persistent program would inform the system which functions are callable, so you can’t just randomly jump to remote memory, but you can jump to any registered address directly, which immediately executes the remote function call. Example:&lt;/p&gt;
    &lt;code&gt;static void my_backend(const char*, const char*)&lt;lb/&gt;{&lt;lb/&gt;   alignas(64) char buffer[256];&lt;lb/&gt;   sys_storage_resume(buffer, sizeof(buffer));&lt;lb/&gt;   const char ctype[] = "text/plain";&lt;lb/&gt;   backend_response(200, ctype, sizeof(ctype)-1,&lt;lb/&gt;       buffer, __builtin_strlen(buffer));&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;Here’s a simple C++ request handler. Instead of jumping directly to a remote VM function, we choose to directly resume the remote VM, as it is running a complex run-time. Deno in fact.&lt;/p&gt;
    &lt;code&gt;while (true) {&lt;lb/&gt;  // Wait for a UInt8Array buffer from C&lt;lb/&gt;  const bufptr = drogon.symbols.wait_for_storage_task_paused();&lt;lb/&gt;  // View it as a Uint8Array of length 256&lt;lb/&gt;  const arrayBuffer = Deno.UnsafePointerView.getArrayBuffer(bufptr, 256);&lt;lb/&gt;  const buffer = new Uint8Array(arrayBuffer);&lt;lb/&gt;&lt;lb/&gt;  const redis_answer = await redisClient.get("test");&lt;lb/&gt;  // Copy redis_answer to buffer&lt;lb/&gt;  const response = "Hello from Deno storage inside TinyKVM, redis answer: " + redis_answer;&lt;lb/&gt;  ...&lt;lb/&gt;}&lt;/code&gt;
    &lt;p&gt;What’s omitted is encoding the answer back into the buffer zero-terminated. But maybe you got the gist of it: The buffer is zero-copy and we write directly into it. The only remaining thing to do after writing to the buffer is to go back to waiting.&lt;/p&gt;
    &lt;p&gt;While everything is zero-copy, you will have to duplicate anything that you want to persist. You can use allocators to allocate for the caller.&lt;/p&gt;
    &lt;p&gt;This feature currently executes safely on the order of 2 microseconds wherever I’ve benchmarked it. It’s cost is partly having to context switch twice per call, and partly having to flush TLBs. It can be improved with INVPCID and only flushing the remote side, but I haven’t done that yet.&lt;/p&gt;
    &lt;p&gt;Concurrent access to the remote is possible with an idea I’ve had in my head for a while: Create N threads in the remote VM and register them for use by callers. I think this is essentially how most people would expect/hope it would work. You’d have to lock and synchronize things normally. However, for now I am currently using serialized access to the remote VM. It’s also possible to fork it into many copies to avoid serializing access but that only helps you in certain cases like connection pooling to a database. That is of course supported already. If you want a single-source-of-truth then you probably also want to serialize access to the remote.&lt;/p&gt;
    &lt;p&gt;During remote calls the caller VM has to be paused. There’s no way around it, otherwise it can trample memory used by the remote VM and crash it. While zero-copy IPC exists where both can run at the same time, it’s fundamentally a question of trust and integrity. You simply can’t do that with two separate sandboxes talking to each other.&lt;/p&gt;
    &lt;p&gt;Anyway. I hope that was an introduction to the concept, at least. It’s not your everyday feature. It likely won’t solve your problems. I just think it’s a really cool idea. And I do use it, of course. For limited persistence with per-request isolation.&lt;/p&gt;
    &lt;head rend="h3"&gt;VM snapshots&lt;/head&gt;
    &lt;p&gt;The last topic of this post is VM snapshots. A feature that many have asked about for TinyKVM. Wouldn’t it be nice if you could snapshot a VM, transport it somewhere else, and resume it? Well, now you can. The feature is implemented by backing all of physical memory with a single file, and then adding some VM state on top and a user-provided section at the very end. This combines all state into a single file with holes.&lt;/p&gt;
    &lt;p&gt;For reference, a Deno JS hello world instance is 192MiB RSS after initializing the first time. If you save that state into a snapshot and resume it, the file is 135MiB on disk (2.4GiB logical), and RSS is 50MiB after starting with 32 VM forks.&lt;/p&gt;
    &lt;code&gt;$ du -h program/deno/deno.mem&lt;lb/&gt;135M program/deno/deno.mem&lt;/code&gt;
    &lt;p&gt;The startup time is 0.7ms with everything in page cache. Clearing the page cache is not a simple matter as you have to clear any caching on the disk as well. This typically means you’ll need a custom device. I don’t have all the answers right now, but I suspect it will be around 20ms to load the program from disk with everything cold. My guess is nothing other than that’s the worst number I’ve gotten so far.&lt;/p&gt;
    &lt;p&gt;We’re currently working on recording the actually accessed pages of a request and only preloading those. Combined with a full clear of all relevant caches we hope to see that it loads faster than any other alternatives in this space. Fast cold start is of course a crowded space, but you never know what you will find until you try. Because we will be able to know more or less the exact pages that are going to be used by the next request, we might be able to populate just the right pages and avoid loading pages that aren’t going to be used. Typically Linux will load ranges of pages optimistically based on faults. Avoiding that can save some time. We are also hosting just a single process. It’s just Deno, and nothing else. Of course, requests differ, but they should have many things in common.&lt;/p&gt;
    &lt;p&gt;I think I will end this post here. This is as far as I’ve gotten. Thanks for reading!&lt;/p&gt;
    &lt;p&gt;-gonzo&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fwsgonzo.medium.com/an-update-on-tinykvm-7a38518e57e9"/><published>2025-10-25T20:51:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706924</id><title>An Efficient Implementation of SELF (1989) [pdf]</title><updated>2025-10-25T23:32:23.977659+00:00</updated><content/><link href="https://courses.cs.washington.edu/courses/cse501/15sp/papers/chambers.pdf"/><published>2025-10-25T21:01:02+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45706938</id><title>How programs get run: ELF binaries (2015)</title><updated>2025-10-25T23:32:23.390185+00:00</updated><content>&lt;doc fingerprint="aba318d5a40737c8"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;How programs get run: ELF binaries&lt;/head&gt;
    &lt;quote&gt;Ready to give LWN a try?&lt;p&gt;With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features. We are pleased to offer you a free trial subscription, no credit card required, so that you can see for yourself. Please, join us!&lt;/p&gt;&lt;/quote&gt;
    &lt;p&gt;The previous article in this series described the general mechanisms that the Linux kernel has for executing programs as a result of a user-space call to execve(). However, the particular format handlers described in that article each deferred the process of execution to an inner call to search_binary_handler(). That recursion almost always ends with the invocation of an ELF binary program, which is the subject of this article.&lt;/p&gt;
    &lt;head rend="h4"&gt;The ELF format&lt;/head&gt;
    &lt;p&gt;The ELF (Executable and Linkable Format) format is the main binary format in use on modern Linux systems, and support for it is implemented in the file fs/binfmt_elf.c. It's also a slightly complicated format for the kernel to handle; the main load_elf_binary() function spans over 400 lines, and the ELF support code is more than four times as big as the code that supports the old a.out format.&lt;/p&gt;
    &lt;p&gt;An ELF file for an executable program (rather than a shared library or an object file) must always contain a program header table near the start of the file, after the ELF header; each entry in this table provides information that is needed to run the program.&lt;/p&gt;
    &lt;p&gt;The kernel only really cares about three types of program header entries. The first type is the PT_LOAD segment, which describes areas of the new program's running memory. This includes code and data sections that come from the executable file, together with the size of a BSS section. The BSS will be filled with zeroes (thus only its length needs to be stored in the executable file). The second entry of interest is a PT_INTERP entry, which identifies the run-time linker needed to assemble the complete program; for the time being, we'll assume a statically linked ELF binary and return to dynamic linking later. Finally, the kernel also gets a single bit of information from a PT_GNU_STACK entry, if present, which indicates whether the program's stack should be made executable or not.&lt;/p&gt;
    &lt;p&gt;(This article only focuses on what's needed to load an ELF program, rather than exploring all of the details of the format. The interested reader can find much more information via the references linked from Wikipedia's ELF article or by exploring real binaries with the objdump tool.)&lt;/p&gt;
    &lt;head rend="h4"&gt;Processing ELF binaries&lt;/head&gt;
    &lt;p&gt;Loading an ELF binary is handled by the load_elf_binary() function, which starts by examining the ELF header to check that the file in question does indeed look like a supported ELF format. The handler needs the whole of the ELF program header, whether it is within the first 128 bytes read into buf in linux_binprm or not, so it needs to read it into some scratch space.&lt;/p&gt;
    &lt;p&gt;The code now loops over the program header entries, checking for an interpreter (PT_INTERP) and whether the program's stack should be executable (from the PT_GNU_STACK entry). With this preparation done, the code needs to initialize those attributes of the new program that are not inherited from the old program; the Single UNIX Specification version 3 (SUSv3) exec specification describes most of the required behavior (and table 28-4 of The Linux Programming Interface gives an excellent summary of the attributes involved).&lt;/p&gt;
    &lt;p&gt;The process of setting up the new program starts with a call to flush_old_exec(), which clears up state in the kernel that refers to the previous program. Any other threads of the old program are killed so the new program starts with a single thread, and the signal-handling information for the process is unshared so that it can be safely altered later. Any pending POSIX timers for the old program are cleared, and the location of the executable file for the program (visible at /proc/pid/exe) is updated. The virtual memory mappings for the old program are released, which also kills any pending asynchronous I/O operations and frees any uprobes. Finally, the personality of the process is updated to remove any features that could affect security, as previously recorded in the per_clear field in linux_binprm. The main handler code also calls the SET_PERSONALITY() macro to set the thread flags appropriately for a new 64-bit program.&lt;/p&gt;
    &lt;p&gt;A corresponding call to setup_new_exec() now sets up the kernel's internal state for the new program. This function starts by determining whether the new program can generate a core dump (or have ptrace() attach to it); this is disabled by default for setuid or setgid programs. Dumping is also disabled when the program file isn't readable under the current credentials. A call to __set_task_comm() sets the current task's comm field to the basename of the originally invoked filename; this value is used as a thread name, and is accessible to user space via the PR_GET_NAME and PR_SET_NAME prctl() operations. A call to flush_signal_handlers() sets up the signal handlers for the new program; any signal handler that's not SIG_IGN gets set to the default SIG_DFL value (so any ignored signals are inherited by the new program). Finally, a call to do_close_on_exec() closes all of the old program's file descriptors that have the O_CLOEXEC flag set; other file descriptors will be inherited by the new program.&lt;/p&gt;
    &lt;p&gt;The virtual memory for the new program also needs to be set up. To improve security (by helping protect against stack overflow attacks), the highest address for the stack is typically moved downward by a random offset. An initial call to setup_arg_pages() then sets up the kernel's memory tracking structures, and adjusts for the new location of the stack. The code loops through all of the PT_LOAD segments in the program file and maps them into the process's address space, setting up the new program's memory layout. It then sets up zero-filled pages that correspond to the program's BSS segment. Also, additional special pages — such as the virtual dynamic shared object (vDSO) pages — need to be mapped, which is taken care of by a call to arch_setup_additional_pages(). An empty page may also be mapped at the zero address in the program's address space for backward-compatibility reasons (old SVr4 programs apparently assume that reading from a NULL pointer would return zeros rather than SIGSEGV).&lt;/p&gt;
    &lt;p&gt;Next, the credentials for the new program are set up via a call to install_exec_creds(). This function lets any active Linux Security Module (LSM) know about the change in credentials (through the bprm_committing_creds and bprm_committed_creds LSM hooks), and the inner commit_creds() function performs the assignment.&lt;/p&gt;
    &lt;p&gt;The final preparation for running the new program is to set up the rest of its stack (in its new randomized location), by calling the create_elf_tables() function; this is described in a separate section below.&lt;/p&gt;
    &lt;p&gt;All of the preparation has now been done, and the new program can be launched. An earlier article explained how the kernel's system_call entry point pushes the user-space CPU registers to the kernel stack before entering the main kernel code, and these registers are correspondingly restored when the system call completes. The area of the stack that holds the saved registers is cast to a pt_regs structure, and the saved user-space CPU registers can thus be overwritten with suitable values (zeroes) for the start of the new program. The call to the start_thread() function also sets the saved instruction pointer to the entry point of the program (or the dynamic linker), and the saved stack pointer to the current top of the stack (from the p field in linux_binprm). The zero return code from the handler indicates success, and the execve() syscall returns to user space — but to a completely different user space, where the process's memory has been remapped, and the restored registers have values that start the execution of the new program.&lt;/p&gt;
    &lt;head rend="h4"&gt;Populating the stack: the auxiliary vector, environment and arguments&lt;/head&gt;
    &lt;p&gt;The create_elf_tables() function adds more information to the new program's stack, below the argument and environment information added by the generic code, as two distinct chunks. An initial call to arch_align_stack() rounds down the existing stack position to a 16-byte boundary, and may also further randomize the stack position downward slightly.&lt;/p&gt;
    &lt;p&gt;The first collection of information forms the ELF auxiliary vector, a collection of (id, value) pairs that describe useful information about the program being run and the environment it is running in, communicated from the kernel to user space. To build this vector, the handler code first needs to push onto the stack any information that doesn't fit within a 64-bit value; for x86_64 this is a platform capability description (the string "x86_64") and 16 bytes of random data (to help seed user-space random number generators).&lt;/p&gt;
    &lt;p&gt;Next, the code assembles the (id, value) pairs for the auxiliary vector in the saved_auxv space within the mm_struct. An LWN article from Michael Kerrisk describes the contents of this vector, so here we just mention a few interesting entries:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The (architecture-specific) first entry in the vector is the AT_SYSINFO_EHDR value for x86_64; this indicates the location of the vDSO page, as referenced in an earlier article.&lt;/item&gt;
      &lt;item&gt;The AT_PLATFORM value is the location of the "x86_64" platform capability description pushed earlier.&lt;/item&gt;
      &lt;item&gt;The AT_RANDOM value is the location of the random data pushed earlier.&lt;/item&gt;
      &lt;item&gt;The AT_EXECFN value holds the location of the program filename that was pushed as the very first thing on the stack (and whose location was stored in the exec field of linux_binprm), above the arguments and environment values.&lt;/item&gt;
      &lt;item&gt;The AT_ENTRY value holds the entry point for the text segment, i.e. where program execution should start.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Once this auxiliary vector is created, the code now assembles the rest of the new program's stack. The required space is calculated, and then the entries are inserted from low addresses to higher ones:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The argc argument count is inserted first.&lt;/item&gt;
      &lt;item&gt;An array of argument pointers is inserted next, ending with a NULL pointer. This is where main()'s argv will eventually point.&lt;/item&gt;
      &lt;item&gt;An array of environment pointers is inserted next, ending with a NULL pointer. This is where environ will point.&lt;/item&gt;
      &lt;item&gt;The auxiliary vector is put at the highest address, just below the additional values it references.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Taken together, the top of the new program's address space will have contents like the following example (this page has a similar example):&lt;/p&gt;
    &lt;quote&gt;------------------------------------------------------------- 0x7fff6c845000 0x7fff6c844ff8: 0x0000000000000000 _ 4fec: './stackdump\0' &amp;lt;------+ env / 4fe2: 'ENVVAR2=2\0' | &amp;lt;----+ \_ 4fd8: 'ENVVAR1=1\0' | &amp;lt;---+ | / 4fd4: 'two\0' | | | &amp;lt;----+ args | 4fd0: 'one\0' | | | &amp;lt;---+ | \_ 4fcb: 'zero\0' | | | &amp;lt;--+ | | 3020: random gap padded to 16B boundary | | | | | | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -| | | | | | 3019: 'x86_64\0' &amp;lt;-+ | | | | | | auxv 3009: random data: ed99b6...2adcc7 | &amp;lt;-+ | | | | | | data 3000: zero padding to align stack | | | | | | | | . . . . . . . . . . . . . . . . . . . . . . . . . . .|. .|. .| | | | | | 2ff0: AT_NULL(0)=0 | | | | | | | | 2fe0: AT_PLATFORM(15)=0x7fff6c843019 --+ | | | | | | | 2fd0: AT_EXECFN(31)=0x7fff6c844fec ------|---+ | | | | | 2fc0: AT_RANDOM(25)=0x7fff6c843009 ------+ | | | | | ELF 2fb0: AT_SECURE(23)=0 | | | | | auxiliary 2fa0: AT_EGID(14)=1000 | | | | | vector: 2f90: AT_GID(13)=1000 | | | | | (id,val) 2f80: AT_EUID(12)=1000 | | | | | pairs 2f70: AT_UID(11)=1000 | | | | | 2f60: AT_ENTRY(9)=0x4010c0 | | | | | 2f50: AT_FLAGS(8)=0 | | | | | 2f40: AT_BASE(7)=0x7ff6c1122000 | | | | | 2f30: AT_PHNUM(5)=9 | | | | | 2f20: AT_PHENT(4)=56 | | | | | 2f10: AT_PHDR(3)=0x400040 | | | | | 2f00: AT_CLKTCK(17)=100 | | | | | 2ef0: AT_PAGESZ(6)=4096 | | | | | 2ee0: AT_HWCAP(16)=0xbfebfbff | | | | | 2ed0: AT_SYSINFO_EHDR(33)=0x7fff6c86b000 | | | | | . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . | | | | | 2ec8: environ[2]=(nil) | | | | | 2ec0: environ[1]=0x7fff6c844fe2 ------------------|-+ | | | 2eb8: environ[0]=0x7fff6c844fd8 ------------------+ | | | 2eb0: argv[3]=(nil) | | | 2ea8: argv[2]=0x7fff6c844fd4 ---------------------------|-|-+ 2ea0: argv[1]=0x7fff6c844fd0 ---------------------------|-+ 2e98: argv[0]=0x7fff6c844fcb ---------------------------+ 0x7fff6c842e90: argc=3&lt;/quote&gt;
    &lt;p&gt;Note that although there are two randomizations in the stack layout (the position of the top of memory and the size of the gap between the argument values and the auxiliary vector), the newly running program can still figure out where all of the information on the stack is. The SP register tells the program where the top of the stack is (i.e. the lowest address), and the command-line arguments are arranged upwards in memory from there, with a NULL pointer to mark where they end. The environment values are found next, again with a NULL pointer to terminate, and the auxiliary vector is found at the next consecutive addresses, closing with an AT_NULL ID. The values found within all of this information give the addresses of the argument strings, environment strings, and auxiliary data values, so no explicit information about the size of the random gap is needed.&lt;/p&gt;
    &lt;head rend="h4"&gt;Dynamically linked programs&lt;/head&gt;
    &lt;p&gt;So far we've assumed the program being executed is statically linked and skipped over steps that would be triggered by the presence of a PT_INTERP entry in the ELF program header. However, most programs are dynamically linked, meaning that required shared libraries have to be located and linked at run-time. This is performed by the runtime linker (typically something like /lib64/ld-linux-x86-64.so.2), and the identity of this linker is specified by the PT_INTERP program header entry.&lt;/p&gt;
    &lt;p&gt;To cope with a runtime linker, the ELF handler first reads the ELF interpreter file name into scratch space, then opens the executable file with open_exec(). The first 128 bytes of the file are read into the bprm-&amp;gt;buf scratch area, replacing the contents of the original program file and allowing access to the ELF header of the interpreter program — which must therefore be an ELF binary itself, rather than any other format.&lt;/p&gt;
    &lt;p&gt;After the program code has been loaded into memory as described previously, the ELF handler also loads the ELF interpreter program into memory with load_elf_interp(). This process is similar to the process of loading the original program: the code checks the format information in the ELF header, reads in the ELF program header, maps all of the PT_LOAD segments from the file into the new program's memory, and leaves room for the interpreter's BSS segment.&lt;/p&gt;
    &lt;p&gt;The execution start address for the program is also set to be the entry point of the interpreter, rather than that of the program itself. When the execve() system call completes, execution then begins with the ELF interpreter, which takes care of satisfying the linkage requirements of the program from user space — finding and loading the shared libraries that the program depends on, and resolving the program's undefined symbols to the correct definitions in those libraries. Once this linkage process is done (which relies on a much deeper understanding of the ELF format than the kernel has), the interpreter can start the execution of the new program itself, at the address previously recorded in the AT_ENTRY auxiliary value.&lt;/p&gt;
    &lt;head rend="h4"&gt;Compatibility with other architectures&lt;/head&gt;
    &lt;p&gt;As described previously, a modern 64-bit (x86_64) Linux system can also support running 32-bit binaries of two types: normal 32-bit binaries (x86_32), and x32 ABI programs (which can make use of additional x86_64 registers). So how does the kernel support these binaries?&lt;/p&gt;
    &lt;p&gt;The key file that provides support for these formats is compat_binfmt_elf.c, which is included in the kernel when the CONFIG_COMPAT_BINFMT_ELF config option is set. This file didn't appear in our earlier list of places that register binary handlers, because the file contains almost no code of its own. Instead, it includes the main binfmt_elf.c ELF handler code (using #include), and uses the preprocessor to redirect various internal functions and values to 32-bit compatibility versions. Other than these changes, the format handler therefore behaves the same as the normal ELF handler described above.&lt;/p&gt;
    &lt;p&gt;One set of changes uses 32-bit versions of the structures describing the layout of the ELF file; similarly, the appropriate constant values for 32-bit binaries are used, which ensures that the compatibility handler only claims support for the relevant ELF binary types. In particular, the elf_check_arch() call is replaced with a compat_elf_check_arch() version that checks for either x86_32 or (if configured) x32.&lt;/p&gt;
    &lt;p&gt;The preprocessor changes also redirect some of the inner functionality of the ELF handler code. The invocation of the SET_PERSONALITY() macro is redirected to set_personality_ia32() so that the relevant thread flags for the 32-bit architecture are set and, similarly, the arch_setup_additional_pages() function is replaced with a version that sets up a 32-bit vDSO. More significantly, the start_thread() function is replaced with compat_start_thread(), which maps to start_thread_ia32(). This alters the arguments to the inner start_thread_common() function so that the saved segment registers are initialized differently than for x86_64 binaries (and the ELF_PLAT_INIT() macro is also adjusted to match).&lt;/p&gt;
    &lt;head rend="h4"&gt;Epilogue&lt;/head&gt;
    &lt;p&gt;Every program that runs on a Linux system passes through the portal of execve(); as such it's a key piece of kernel functionality that's worth understanding in detail. Although the kernel natively supports script and other machine-code format programs, program execution on a modern Linux system eventually involves running an ELF binary. ELF is a complicated format, but fortunately the kernel can ignore most of that complexity — it only needs to understand just enough ELF to load segments into memory, and to invoke a user space run-time linker program to finish the job of assembling a complete running program.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="2"&gt;
        &lt;cell role="head"&gt;Index entries for this article&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="2"&gt;
        &lt;cell&gt;Kernel&lt;/cell&gt;
        &lt;cell&gt;exec()&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;GuestArticles&lt;/cell&gt;
        &lt;cell&gt;Drysdale, David&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt; Posted Feb 5, 2015 19:24 UTC (Thu) by Tara_Li (guest, #26706) [Link] (4 responses) http://www.muppetlabs.com/~breadbox/software/tiny/teensy.... The creation of a 45 byte ELF executable - admitted, all it does is return 42, but it *does* execute. Posted Feb 6, 2015 2:14 UTC (Fri) by vonbrand (subscriber, #4458) [Link] That one contains a nice discussion of checks that aren't made when launching an executable... any possible screwups by not checking? Posted Feb 6, 2015 13:34 UTC (Fri) by jzbiciak (guest, #5246) [Link] That was a fun read. :-) Posted Feb 7, 2015 14:05 UTC (Sat) by felixfix (subscriber, #242) [Link] (1 responses) Posted Feb 16, 2015 16:04 UTC (Mon) by bokr (guest, #58369) [Link] http://en.wikipedia.org/wiki/LGP-30 Likewise, the RPC-4000 was manufactured by Librascope, Posted Feb 7, 2015 4:01 UTC (Sat) by felixfix (subscriber, #242) [Link] (2 responses) Then I learned machine language for it, and delighted in knowing that 11 was add, 12 was subtract, while 21 was add immediate and 22 was subtract immediate (just reaching; those may not be correct!). My teacher and I began a contest to see who could get the most interesting program on a single 80 column card. I think he gave up when I got 120 digits of instruction with various nefarious overlaps. The program printed out THIMK over and over on the console typewriter. One sense switch would bypass a delay loop; a second halted the program. It couldn't print THINK because that M was the halt instruction. I think I learned for more about useful programming in that summer than any class since. Posted Feb 7, 2015 13:18 UTC (Sat) by vonbrand (subscriber, #4458) [Link] I remember the IBM 1620 had no proper FORTRAN II, but some cut-down dialect called PDQ FORTRAN. Posted Sep 8, 2018 2:23 UTC (Sat) by Since1969 (guest, #127103) [Link] 1* were the immediate instructions; 2* were the "storage-to-storage" ones. My first program was computing Hero's Formula using "FORTRAN with Format". Later we got Load and Go FORTRAN, which saved a lot of trees. But after a few FORTRAN programs, I learned SPS (assembler). One of the coolest tricks was coding loops of different lengths which produced tones in various pitches in a nearby FM radio. Great machine. Posted Feb 8, 2015 18:50 UTC (Sun) by kleptog (subscriber, #1183) [Link] Posted Feb 12, 2015 16:52 UTC (Thu) by nye (subscriber, #51576) [Link] (1 responses) I have an instinctive reaction that this sort of behaviour should have to be explicitly enabled via sysctl or something - it seems to violate the principle of least astonishment in a way that could have surprising implications, including security ones. Am I way off base here? Certainly I am working from a position of abject ignorance. Posted Feb 12, 2015 17:20 UTC (Thu) by drysdale (guest, #95971) [Link] Posted Feb 16, 2015 17:26 UTC (Mon) by nix (subscriber, #2304) [Link] &lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head/&gt; There's also The Story of Mel. &lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;LGP-30&lt;/head&gt;&lt;lb/&gt; deserves more credit than "The Story of Mel" gives.&lt;lb/&gt; which had become a division of General Precision by then, IIRC.&lt;lb/&gt; (I started work at Librascope Sept '59, and those were the&lt;lb/&gt; computers I cut my teeth on. It's been interesting -- and still is ;-)&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;lb/&gt; &amp;gt;space for backward-compatibility reasons (old SVr4 programs apparently assume&lt;lb/&gt; &amp;gt;that reading from a NULL pointer would return zeros rather than SIGSEGV).&lt;head/&gt; That behaviour does need to be explicitly enabled via the personality() syscall; of the pre-defined personality values, only PER_SRV4 and PER_UW7 set the MMAP_PAGE_ZERO bit that controls this behaviour. (The bit is also explicitly cleared when running a setuid/setgid binary.) &lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;head&gt;How programs get run: ELF binaries&lt;/head&gt;&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://lwn.net/Articles/631631/"/><published>2025-10-25T21:03:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45707194</id><title>Belittled Magazine: Thirty years after the Sokal affair</title><updated>2025-10-25T23:32:23.014313+00:00</updated><content>&lt;doc fingerprint="b7c9584d3ae18d91"&gt;
  &lt;main&gt;
    &lt;p&gt;Social Text still exists. In the spring of 1996, when the journal was the object of an enthusiastically publicized hoax by the physicist Alan Sokal, its survival seemed a bad bet. You published an essay arguing that gravity is a “social and linguistic construct?” Really? The mainstream media, hitherto unaware of the existence of this very little, very marginal magazine, were uncertain what exactly they were mocking. Was Social Text’s foolishness postmodern? Left wing? Cultural? Academic? They were certain, however, that what they smelled in the water was blood. On their side, and for a not insignificant portion of the left, jubilation. On the other side, humiliation. (I should know: I was the journal’s coeditor at the time.) We seemed like the stupidest people in the world, or the stupidest people who had been pretending to speak on behalf of the most avant-garde sociopolitical views. One friend of the journal suggested that we fall on our swords. If we owned no swords, swords could be made available.&lt;/p&gt;
    &lt;p&gt;The journal did not fold. One reason was that it had published a lot of good work, none of it remotely resembling Sokal’s gravity-is-a-construct nonsense, and those who cared about such things knew it. Edward Said’s “Zionism from the Standpoint of Its Victims” had come out in the first issue in 1979; for U.S.-based critiques of Zionism, 1979 was early. Other issues contained Eve Kosofsky Sedgwick’s “How to Bring Your Kids Up Gay” and Aijaz Ahmad’s Marxist critique of Marxist (and Social Text cofounder) Fredric Jameson.&lt;/p&gt;
    &lt;p&gt;Another reason why the journal didn’t fold was that, with that era’s culture wars in full swing, the pressure to be loyal to what you saw as your side was stronger than embarrassment at a dumb mistake: accepting an awkwardly written, citation-heavy article in which a physicist seemed to embrace an antirealist epistemology. Yes, errors had been made, and there had been innocent casualties (vulnerable students and junior faculty doing serious research in cultural studies) and not so innocent ones (I was briefly denied a promotion). But war was war. No one seemed ready to concede defeat. Some ingenious and some desperately unconvincing things were said in the journal’s defense.&lt;/p&gt;
    &lt;p&gt;Standing firm was arguably the preferable option. What was at stake was not a giddy worldview that denied the existence of physical reality. Considered sociologically and politically rather than philosophically, the “X is a construct” platform, thirty years ago, stood for solidarity with the political energies of the 1960s—above all, liberation movements in the name of race and gender. To say that gender was a construct was to make a political point. Ditto for maintaining that race was a construct. Stereotypes (that’s what they were called back then) that kept women and people of color in their place were not the verifiable truth about the world. Depictions of the non-Europeans to whom the imperial metropolis denied independence or whom it excluded from its borders were not the results of objective empirical observation; they were fictive generalizations that served unsavory interests. Circulating them perpetuated injustice. Behind constructionism, a project of denaturalizing categories of thought that were taken to be natural, there were large groups of people who had been trying to rectify how they were described and thus also their unjustifiable situation in the world, which the false descriptions enabled. Imagine the world differently, and you can make it better. Constructionism’s slogan was crude but politically mobilizing. Imagination is a form of politics.&lt;/p&gt;
    &lt;p&gt;Social science had put much of its authority behind the contrary assumption: “That’s their nature. We have studied the matter impartially. We know.” It was probably inevitable, especially in a moment when the shameful indifference of medical institutions to the HIV/AIDS crisis was still fresh in everyone’s mind, that constructionism would get hyperextended, that some would be willing to identify scientific knowledge, as such, with hegemonic power. That was not a position Social Text embraced—it’s not the argument of the other essays in the ill-fated “Science Wars” issue that included Sokal’s. By 1996, constructionism was already seen by many of the journal’s writers and readers as more of a problem than a solution. Diana Fuss had made the argument decisively seven years prior in her book Essentially Speaking. After all, who or what does the constructing? Patriarchy, racism, and capitalism are real historical agents, no? The journal’s origins were unapologetically Marxist. For Marxists, imagination is a force, yes, but it’s not imagined constructs all the way down.&lt;/p&gt;
    &lt;p&gt;Three decades later, an essay identifying science with power would probably fail to get the required votes. (Sokal’s essay got only four readings, but they were positive, and that, alas, was enough.) With the federal government aligning itself with anti-vaxxers and drill-baby-drill climate change deniers and exerting a heretofore unimaginable authority to defund ongoing research and push an antiscience agenda, you would have to be more foolish than Social Text’s collective to take science simply as an antagonist. And this is true even if you have your doubts about what has come to permeate common sense as constructionism has faded, like the body as a determining site of unquestioned truth and genetic and biochemical accounts of identity, which are easier to turn into someone’s tidy profits than sociohistorical ones.&lt;/p&gt;
    &lt;head rend="h3"&gt;Painting the Gown Red&lt;/head&gt;
    &lt;p&gt;A third and perhaps more important reason why Social Text did not disappear is that it was a little magazine. By the 1990s, it probably looked to many like just another academic journal, but it was never peer-reviewed (that issue came up of course apropos of the Sokal disaster), and it had started out thinking of itself as an organ of the left. Cofounder Stanley Aronowitz, who was born into the working class and came to the role of intellectual through the labor movement, was looking back over his shoulder at the littleness of Partisan Review, which seemed to define its newfound independence from the Communist Party. (John Brenkman, another founder, was thinking of Tel Quel, an even littler magazine.) Littleness was complicated: it could give the magazine a higher vocation, but it could also serve as self-protection, an excuse for not trying to be too political.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Littleness could give the magazine a higher vocation, but it could also serve as self-protection.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In “The Function of the Little Magazine,” first published as the introduction to a 1946 collection of pieces from Partisan Review, Lionel Trilling laments that, although politics had not been good for literature, little magazines had saved the day, managing to keep literature from being lowered by politics. Trilling begins by declaring that Partisan Review’s survival for ten years (with a readership of six thousand!) is a victory. It’s a victory because the journal has succeeded in refusing to give its readers what they want, which is a crude literature of political protest. For Trilling, other journals had mendaciously jacked up the excitement level with misplaced metaphors of weaponry and war (implicitly, class war). Partisan Review, however, does not pretend, most of the time, to write for “the many,” “the working masses.” In other publications, quality literature, which for Trilling means modernism, has been losing out both to politics and to the competition of radio and movies. Thus there has been a “general lowering of the status of literature,” a loss of literature’s social power. The little magazines have recognized, correctly, that literature needs a “cultivated” public. Partisan Review in particular has unashamedly addressed “the self-appointed few,” yet has somehow squared the circle: it has done so without surrendering its hold on politics. Perhaps a bit half-heartedly, he affirms that the magazine has been doing what needs to be done: showing how politics benefits from being mixed with “imagination and mind.” Trilling does not use the term, but what he is championing, in “imagination and mind,” is elitism.&lt;/p&gt;
    &lt;p&gt;Elitism seems a subject worth taking a fresh look at in regard both to Social Text’s survival and to what the Sokal hoax means today, if it means anything. The social movements of the 1960s, which gave birth to little magazines and/or academic journals like Social Text in the 1970s, may have been weak on class, but they did not like elitism; indeed, they took a lot of heat from the right for their supposed willingness to subvert proper intellectual standards in order to set aside entitlements based on race and gender. It was his unapologetic elitism that kept Trilling from expressing any enthusiasm for the 1960s protests. In the spring of 1968, when protesters shut Columbia University down (as the protesters in the spring of 2024 did not), students circulated a mock arrest warrant for Lionel “Trains” Trilling, identified as a “cultural imperialist.” At that time, elitism was cultural imperialism. There has been a reversal. In today’s culture wars, it is the anti-imperialists who are accused of elitism; we are advised by columnists like David Brooks to ignore collegiate protesters in the Gaza encampments because they are the privileged.&lt;/p&gt;
    &lt;p&gt;In the 1960s and after, the assumption was that “the Movement” was in revolt against a structure of elite power sustained by both the existing distribution of money and the existing organization of knowledge. As the word elitism functions in political discourse today, money and knowledge have come apart. Much of the time, of course, the word elite is used casually to refer to those at the top of whatever group is under discussion. When it is used with political deliberation, however, the word tends to aim instead, these days, at what Trilling called “imagination and mind.” What stands accused is not money or the power that money affords. On the contrary, elitism throws up a smokescreen behind which the power of money can hide. The explicit targets today are expertise and education, seen as sources of left-wing or “woke” power (which they are).&lt;/p&gt;
    &lt;p&gt;Looking back at the hullaballoo over the Sokal hoax, it’s surprising how muted the elitism issue appears now. All the pieces seemed in place for a full-blown class argument in the MAGA style that the Social Text collective and its allies were not just hypocrites (by virtue of their claim to speak for democracy) but also elitists (by virtue of their jargon and their educational privilege). Sokal made it clear that by being on the side of common sense, science was taking the side of the common man, and this was true no matter how inaccessible the language scientists spoke might be. The journalists who flocked to the hoax were happy to second that motion, which strengthened their bargaining position vis-à-vis the academy (though they neglected to recall the inaccessibility of much scientific language). Social Text was funded by a university. The hoax offered irresistible evidence that, as the Republicans would agree today, universities are out of touch, and the writing that comes out of them is deliberately incomprehensible. Conservative columnist George Will, unafraid to use big words of his own, described the journal as “smitten with gibberish,” full of “solecism and gaseous philosophical rhetoric, flecked with . . . political jargon.” Janny Scott of the New York Times complained of Social Text’s use of the word epistemological as part of its “impenetrable hodgepodge of jargon, buzzwords, footnotes.” She implied that journalists like her are properly impatient with anything but the common tongue. They are accountable to the public. Though they don’t use footnotes, they have nothing to hide.&lt;/p&gt;
    &lt;p&gt;One go-to reference at the time was Hans Christian Andersen’s tale of the emperor’s new clothes. (The tale was name-checked in the Los Angeles Times; the headline in the News-Press of Fort Myers, Florida, was “Social Scientists Wore No Clothes.”) In presenting Social Text as vain and deluded, like Andersen’s emperor, journalists were in turn presenting themselves as avatars of Andersen’s innocent child, too young to be intimidated by the emperor’s authority and thus unafraid to say exactly what he saw: not very fine clothes, but no clothes. The fable must have offered welcome relief from the consciousness of how beholden journalists in fact were to the power and ideology of the editors who had to sign off on their stories, and so on up the ladder. In a time when the prejudices of powerful figures in the newsroom (some with family members in the Israeli Defense Forces) have been visible all over New York Times coverage of Israel and Gaza, the idea of journalists as antiestablishment gadflies accountable to no one will sound like more of a fairy tale than Andersen’s. But the strangest thing about these Andersen references was the implication that Social Text was not merely ridiculous, but powerful—indeed, mysteriously comparable in power to an emperor. Even if Social Text was taken to stand for something bigger, like postmodernism or the cultural left, it was a stretch to think of it as somehow the voice of the ruling class, the elite. This was a very little magazine they were talking about. Unless there was more political potential there than anyone was ready to claim.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The fable must have offered welcome relief from the consciousness of how beholden journalists in fact were to power and ideology.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Like Trilling, Social Text was never unambivalent about its role, as a journal, in relation to politics in the everyday sense. Maybe the times called for politics to be refreshed and even reinvented? According to Stanley Aronowitz, in conversations that would lead to the founding of Social Text, he and Fredric Jameson discussed the argument then current on the left that politics was “no longer organized around political parties, but instead around journals.” It was a heady thing to believe, and maybe a bit self-congratulatory, but in my experience there was some truth to it. When Cornel West invited me to participate in editorial discussions in the fall of 1984, one thing I noticed immediately was a big difference from both standard academic practice and that of the little magazine as I understood it. West and Aronowitz—both figures who remained committed to politics at the level of parties—were not wary of repeating themselves in talks or in print. The point was not to produce original, standalone performances of argument or interpretation, as it so often is in the academy or for publications in the vein of the Partisan Review. What they were trying to do was to work out the right political line. It was a distinctive thing about West and Aronowitz: they repeated and refined and, when necessary, realigned what they had to say as circumstances changed. At the time, I was a young would-be scholar desperately trying to find a secure niche for myself, and all this repetition with a difference sometimes left me feeling uncomfortable. By the time I came to see the logic behind it, both Aronowitz and West were moving on, as was the journal. As Brent Edwards and Anna McCarthy, two editors at that time, note in their introduction to the one hundredth issue in 2009, the journal had stabilized and solved its funding and logistical issues, and as it did so any pretense that it could indeed function like a political party, or even in loose conjunction with party politics, was fast disappearing. I remember debates in the 1990s over whether to keep a red line along the edge of the cover. People laughed about the triviality, political engagement reduced to an issue of cover design, but the symbolism stood for something, and opinions were divided.&lt;/p&gt;
    &lt;p&gt;One way to describe the divided opinions is to ask: How little did people think the magazine should be? In the decade and a half that I worked on Social Text, there were two moments when I was tempted to take my toys and go home. One came near the end of my tenure there, when Sokal asked Social Text to publish his explanation for the hoax. I was the only person on the editorial collective who thought that, as first and foremost an organ of the American left, we had an obligation to publish the new Sokal piece. Yes, feelings had been bruised, and some thought (I didn’t) that the hoax was an unforgivable ethical violation. Sokal, too, belonged to the left, I argued, and many people of intelligence and good will thought the hoax in some sense a useful or well-deserved thing. We had to show we were taking them seriously. I lost that debate after two three-hour meetings. Sokal’s “Afterword” came out in Dissent in the fall of 1996. I drew the conclusion that my colleagues were content to fortify the journal in its littleness, preferring on this occasion at least not to see themselves as part of a wider left that included different epistemologies.&lt;/p&gt;
    &lt;p&gt;The other moment had come earlier when I proposed an essay I had written on Richard Rorty, violence, and human rights. The essay was rejected by the collective on the grounds that our readers were not interested enough in liberals like Rorty to justify publishing anything on him, however critical. In both cases, the implication seemed to be that we don’t need the liberals, we don’t even need to talk to the liberals. Which I translate, in the year of Zohran Mamdani (hopefully one of many years), as: We don’t have any chance of winning, so why try? That’s not who we are. Better not to bother with potential allies and the compromises that dialogue with them might entail. Better to hold fast to our purity, our righteousness, our littleness.&lt;/p&gt;
    &lt;p&gt;Seen from this angle, the littleness of the little magazine meant backing off from politics in the large sense—the sense Jameson was referring to when he likened journals to political parties. It meant the absence of an ambition, even a patient and well-sublimated ambition, to speak for the majority. The mass media were already doing that. In dark political times, it’s tempting to content oneself with seeking a refuge for the righteous counterculture, something like (as a friend of the journal proposed, half seriously) the retreat to the monasteries after the fall of Rome. Outside, the barbarians are going to rule. There is nothing we can do about that. Inside our walls, at least, a shred of civilization will perhaps survive. And thus the journal, walled up, can also survive.&lt;/p&gt;
    &lt;head rend="h3"&gt;Campus Grovel&lt;/head&gt;
    &lt;p&gt;It is perhaps somewhat unfair to suggest that Social Text (like other little publications of the 1970s) gradually opted out of politics in the messier, more public sense, favoring a protective self-marginalization. The journal remained a center of energetic political activities, some of them filling whole issues (as with an issue offering early support for the effort of academic workers to unionize) and some not. The journal maintained its record of engagement with the cause of justice for Palestine. My own engagement with the Palestinian cause began in earnest in 2002, when I had long stopped attending Social Text meetings. It came through Alan Sokal.&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The culture wars were neither the only wars out there nor the most important ones.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;In 2002, I received an email from Sokal asking my opinion of an “Open Letter of American Jews to Our Government” that he had drafted. Sokal and I were not friends. The fact that he had been perfectly civil in our handful of public debates did not lead me to seek his companionship. Still, I did not delete his “Open Letter.” I read it, and I thought it was good. I saw his (possibly unconscious) point in writing to me: together, we could demonstrate that people who disagreed about certain things could still come together on issues of basic ethical principle. I wrote back, proposing a few revisions. I passed it on to others, who did the same. One thing led to another, and by the spring the two of us found ourselves running a campaign to gather signatures from American Jews who did not accept the Israeli occupation of the West Bank, the outrages to decency and human rights attendant upon that occupation, or America’s unconditional support for the whole package. (This was before organizations like Jewish Voice for Peace became the force they are today.) In July 2002 we published a full-page ad in the New York Times with several thousand signatures, paid for by an avalanche of checks mailed in by American Jews who, as their handwritten notes told us over and over, felt unrepresented by lobbying groups like AIPAC and ADL that claimed to speak for the whole American Jewish community. The ad called for the United States to cut off all aid to Israel if Israel did not adhere to a two-state settlement. We got it translated into several languages, and we published it again four years later.&lt;/p&gt;
    &lt;p&gt;The introduction to the book The Sokal Hoax, published in 2000 and edited by the editors of Lingua Franca, observes that almost none of the sentiments about the hoax recorded in that volume “are conciliatory.” Conciliation was not the point of the project on which Sokal and I collaborated, but the project certainly illustrated how much common ground is to be found if you are willing to look. The culture wars were neither the only wars out there nor the most important ones. Nor did they dictate reliably what was worth fighting for.&lt;/p&gt;
    &lt;p&gt;After all, in some sense Social Text, too, was on the side of the elitists. Whatever it became, it was not at the outset an academic journal, and yet publication in its pages could make a professional difference to an academic career. In that sense, the invokers of the emperor’s new clothes were not wrong. This confusion—were we fighting the power, or were we an institutional part of it?—was probably the source of some post-hoax Schadenfreude. Many would-be writers no doubt assumed their submissions would be treated as contributions to the common cause, and then they received rejections framed not to comrades in arms, but to aspirants to that scarce professional privilege, respectable publication. Until the Sokal affair let them loose, I think we were unaware of the slow-burning frustrations we had provoked—the fact that in the eyes of many the journal wore the forbidding face of a gatekeeper. Hence the left-wing glee at our exposure. What better revenge than to see the judges judged and their imperfections so dramatically revealed?&lt;/p&gt;
    &lt;p&gt;Being a gatekeeper by maintaining high intellectual standards is not what public opinion would associate with Social Text, to say the least. Yet that is what the journal practiced, mainly. And it is a practice worth defending, however elitist it might look. All the more so because of how the Trump administration has weaponized both the idea of the hoax and the program of anti-elitism. We know who its targets are. We know what has befallen intellectual standards.&lt;/p&gt;
    &lt;p&gt;It is true that the Gaza demonstrators at Columbia, many of them recently expelled or suspended in obedience to the demands of, among others, the Republican Party, were probably more privileged on average than other Americans of their age group. But what they were speaking up for, in speaking against Israeli military violence in Gaza and American complicity with it, was not their privilege. They were taking advantage of critical thinking they had learned from the sort of education that ought to be available to anyone who desires it—more widely available than it is at present, as the demonstrators would be the first to say. And they were expressing principles of justice that are universal, not the property of any one class. They were trying to hold liberal institutions like Columbia, which have been notorious in their compliance or collusion with the Trump administration, to their own stated liberal doctrines. They were doing politics, in what has turned out to be a messy and personally expensive way, but they were also upholding standards of intellectual and moral consistency that the institutions around them were failing to uphold.&lt;/p&gt;
    &lt;p&gt;In a letter to the Columbia community in July, acting President Claire Shipman wrote that, as part of its new antisemitism initiative, the university “has not, and will not, recognize or meet with the group that calls itself ‘Columbia University Apartheid Divest’ (CUAD), its representatives, or any of its affiliated organizations.” Why not? “Organizations that promote violence or encourage disruptions of our academic mission are not welcome on our campuses and the University will not engage with them.” Like most of Shipman’s missives, this one sounds like it was written by generative AI. But perhaps generative AI would have caught the grammar mistake: “has not recognized, and will not recognize . . .” And perhaps it would have caught the small logical inconsistency. It appears that, in Shipman’s eyes, the Zionist supporters of the bombing of Gaza, with whom the university has engaged happily on a daily basis, doing their bidding at every opportunity, do not “promote violence.” Is this ChatGPT, or is it Orwell’s doublethink?&lt;/p&gt;
    &lt;p&gt;One way or the other, the president’s neglect of elite intellectual standards and her crass submission to the moneyed elite need to be called out, as do similar actions by her colleagues at other universities. My former coeditor Andrew Ross at Social Text took most of the flak for the Sokal affair (although it was Aronowitz, mentioned nineteen times in Sokal’s article either directly or in footnotes, who pushed hardest for the article’s acceptance). Ross’s main interest in science was, and remains, ecological. It is no surprise to anyone that in laying out the environmental costs of urban projects like supplying water to the city of Phoenix, he relied on the best scientific evidence available. Following an early involvement in the anti-sweatshop movement, Ross’s scholarly work came to focus on offshore labor (for which he was banned from the United Arab Emirates), academic labor, the labor of the incarcerated, debt refusal, and construction workers in Palestine. In December 2024, he was arrested during a Gaza demonstration at NYU; the response of the NYU administration was to declare him persona non grata and deny him access to classroom buildings. An NYU spokesman explained, with shameless and characteristic implausibility, “This was not a peaceful protest.” As far as I know, Ross and Sokal have not been in touch with each other in light of recent events, but Sokal has been writing strong statements in defense of the academic freedom that is being denied to Ross and so many others. These days, it’s clear that the academy is no more a refuge from political interference than the little magazines. As any Gazan could tell you, there are no safe spaces.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://thebaffler.com/salvos/belittled-magazine-robbins"/><published>2025-10-25T21:37:38+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45707575</id><title>NewPipe Is Turning 10</title><updated>2025-10-25T23:32:22.173015+00:00</updated><content>&lt;doc fingerprint="2fa2d611a3367077"&gt;
  &lt;main&gt;
    &lt;p&gt;Guess what? NewPipe just turned 10 &lt;del&gt;this month&lt;/del&gt; last month! Time just flew by. In one moment you hit ânew projectâ, and in the next there is a whole association, a group of maintainers, an uncountable amount of contributors, and millions of users!1 This is amazing. Last time we wrote about an important birthday, NewPipe had just turned five years old. Now itâs yet another five years later, and we still stand on the ground with both feet, running forward like there is no other direction!&lt;/p&gt;
    &lt;p&gt;NewPipe is 10 years old \o/, a double-digit digits number. Justâ¦ let that settle in for a moment.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking back&lt;/head&gt;
    &lt;p&gt;5 years ago, Schabi wrote a blog post for NewPipeâs birthday. We were right in the beginning of the second wave of the COVID-19 pandemic. Back then he wrote that âPeople keep working on it and organize the project like COVID-19 doesnât existâ. This is exactly what happened to us in the last five years, and we are so proud of ourselves. Since then many things happened. People from the Project founded NewPipe e.V., a German association to support NewPipe and other projects like it. We started our refactor/rewrite, with plans for new extractor design and a new player (NewPlayer).&lt;/p&gt;
    &lt;p&gt;The association on the other hand became a beast on its own. Its goal, to care for the donation money that came in from NewPipe, was far surpassed. In 2024 the association hired @Profpatsch and Schabi to work part-time on several topics regarding the NewPipe refactor. For this, the association built out a structure and process for hiring, which turned out successful. What does that mean for you? Well, NewPipe and hopefully other projects gain stability through this, since with paid personnel we can ensure continuous development, even for parts of the project where volunteering maintainers wouldnât have much fun with.&lt;/p&gt;
    &lt;head rend="h2"&gt;Lookingâ¦ now?&lt;/head&gt;
    &lt;p&gt;Today we are still in the rewrite phase of our app. There are a lot of open issues, which you maybe would like to take a look at, we are always happy to have new contributors. So come by, grab a coffee, have a chat with us (even in person if you are at SFSCon, 39C3 or FOSDEM), check out the code, and letâs go! :D&lt;/p&gt;
    &lt;p&gt;Profpatsch has been steadily working on rewriting the app alongside all the people doing it in their free time like Isira Seneviratne, Stypox and many more.&lt;/p&gt;
    &lt;head rend="h2"&gt;Looking forward&lt;/head&gt;
    &lt;p&gt;There are two views on the future. The bright and the dark one. Letâs start with the bright view, because why not: One day we will be done with the refactor, up to a point where NewPipe can rise out of the ashes once again, with a shiny new look and feel and new code, that should make new and exciting subsequent projects possible. Iâm talking Kotlin everywhere, Compose everywhere, and of course nice features without feature creep ;D. Eventually we also want to talk to video creators about the issue that NewPipe reduces their income, and start talking about a world beyond YouTube and Google.&lt;/p&gt;
    &lt;p&gt;Now to the topic no one wants to hear. The dark side: It becomes progressively more complicated to stay afloat. This is not generally bad, because we grow with the tasks we have to accomplish. Take for example the ever-growing and aging code base. A refactor is overdue, but as you know, we are still on it! Or take the fact that we are all step by step growing out of university and now have to face the question of how to keep NewPipe running with mostly post grads. We want to tackle this matter with the association and of course new contributors. So far itâs working. The engine keeps burning! But - there has to be one - lets talk about the elephant in the room: Google They would like to get rid of projects like ours. No question. In the past few years we had to witness that they try harder and harder to get rid of us. So far without success, neither on a legal base,2 or on a technical base. But it is clear that these challenges will only continue to get harder and more plentiful. With the latest and biggest challenge being that Google itself wants to get rid of Android projects that maybe get too creative for its taste, by making it harder to supply software through alternative stores like F-Droid. This, to be honest, is a big challenge, and should not be taken lightly. However, I (Schabi) am certain: we will also tackle this one. We have come up with cool and creative solutions in the past to circumvent technical difficulties. To be honest I am even excited to see what people will come up with. But people have to come up with something. So please if you can: Help! Anyway. As dark as this might sound. We have no intention on stopping. See it from the bright side. There are already solutions in the workings for the challenges we have to face, and we continuously ramp up speed on the refactoring. So I am pretty certain about where NewPipe is going:&lt;/p&gt;
    &lt;p&gt;To infinity and beyond!&lt;/p&gt;
    &lt;p&gt;Sincerely your:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Aayush Gupta&lt;/item&gt;
      &lt;item&gt;absurdlylongusername&lt;/item&gt;
      &lt;item&gt;AudricV&lt;/item&gt;
      &lt;item&gt;Fynn&lt;/item&gt;
      &lt;item&gt;litetex&lt;/item&gt;
      &lt;item&gt;Poolitzer&lt;/item&gt;
      &lt;item&gt;Profpatsch&lt;/item&gt;
      &lt;item&gt;Schabi&lt;/item&gt;
      &lt;item&gt;ShareASmile&lt;/item&gt;
      &lt;item&gt;Siddhesh Naik&lt;/item&gt;
      &lt;item&gt;Stypox&lt;/item&gt;
      &lt;item&gt;Taco&lt;/item&gt;
      &lt;item&gt;TheAssassin&lt;/item&gt;
      &lt;item&gt;TobiGr&lt;/item&gt;
      &lt;item&gt;wb9688&lt;/item&gt;
      &lt;item&gt;and many more&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Better known as Team NewPipe.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;You can check the number of downloads of F-Droidâs official repository over at fdroid-metrics.streamlit.app, however this does not include downloads from our own F-Droid repository.Â ↩&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;See the yt-dl DMCA or the DMCA against our website, which are both not directly an issue caused by Google though.Â ↩&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://newpipe.net/blog/pinned/announcement/newpipe-turns-10/"/><published>2025-10-25T22:46:46+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45707658</id><title>The Linux Boot Process: From Power Button to Kernel</title><updated>2025-10-25T23:32:21.739816+00:00</updated><content>&lt;doc fingerprint="a2b71910e515bfcd"&gt;
  &lt;main&gt;&lt;head rend="h1"&gt;The Linux Boot Process: From Power Button to Kernel&lt;/head&gt;- 15 mins&lt;head rend="h2"&gt;Part 1 — From power button to the kernel’s first breath&lt;/head&gt;&lt;p&gt;You press the power button. A second later a wall of text scrolls by, or a logo fades in, and eventually Linux appears. What happens in between is not magic. It is a careful handshake between tiny programs and a very literal CPU. This part follows that handshake until the very first line of C code inside the Linux kernel runs.&lt;/p&gt;&lt;head rend="h3"&gt;The very first instruction&lt;/head&gt;&lt;p&gt;When power stabilizes, the CPU resets itself to a tiny, old‑fashioned mode called real mode. Real mode dates back to the original 8086 chip. The rules are simple on purpose. Memory addresses are built from two values the CPU keeps in special fast storage called registers. You combine a segment and an offset like this:&lt;/p&gt;&lt;p&gt;&lt;code&gt;physical_address = (segment &amp;lt;&amp;lt; 4) + offset&lt;/code&gt;&lt;/p&gt;&lt;p&gt;If you see numbers like &lt;code&gt;0xFFFFFFF0&lt;/code&gt;, that is hexadecimal. Hex is base 16. We write &lt;code&gt;0x&lt;/code&gt; in front to make that clear. &lt;code&gt;0x10&lt;/code&gt; is 16 in everyday counting. &lt;code&gt;0x100000&lt;/code&gt; is 1 megabyte. Hex lines up nicely with how hardware stores bits, which is why you see it everywhere in low‑level code.&lt;/p&gt;&lt;p&gt;Right after reset the CPU jumps to a special address called the reset vector at &lt;code&gt;0xFFFFFFF0&lt;/code&gt;. Think of it as a permanent bookmark that says “start here.” There is room for almost nothing at that address, so manufacturers put a short jump there that passes control to the firmware on your motherboard.&lt;/p&gt;&lt;p&gt;Tiny explainer: register A register is a tiny slot inside the CPU. It holds a number the CPU is using right now. Names like CS and IP are register names. CS means “code segment,” which marks the current neighborhood for instructions. IP means “instruction pointer,” which marks which instruction comes next.&lt;/p&gt;&lt;head rend="h3"&gt;BIOS and UEFI&lt;/head&gt;&lt;p&gt;The firmware is a small starter program baked into your board.&lt;/p&gt;&lt;p&gt;BIOS stands for Basic Input Output System. It is the older style. BIOS does a quick health check called POST, looks at the boot order, and tries each device. If it finds a disk whose very first 512‑byte sector ends with the marker bytes &lt;code&gt;0x55&lt;/code&gt; and &lt;code&gt;0xAA&lt;/code&gt;, it treats that device as bootable. BIOS copies that sector to memory at &lt;code&gt;0x7C00&lt;/code&gt; and jumps there. That sector is tiny, so it usually knows only how to load the next, larger piece.&lt;/p&gt;&lt;p&gt;UEFI is the modern replacement. It still starts the machine, but it understands filesystems directly and can load bigger boot programs without the old “first sector” dance. UEFI also passes richer information to the operating system. Different path, same goal: hand control to a boot program that can load Linux.&lt;/p&gt;&lt;head rend="h3"&gt;Meet the bootloader&lt;/head&gt;&lt;p&gt;The bootloader is the usher that gets the operating system into place. GRUB is a popular choice on PCs. It reads its configuration, shows a menu if you installed one, and loads the Linux kernel into memory. The Linux kernel file actually contains two things:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;a small setup program that still runs in real mode&lt;/item&gt;&lt;item&gt;the larger compressed kernel that will be unpacked a little later&lt;/item&gt;&lt;/list&gt;&lt;p&gt;GRUB also fills out a small structure called the setup header with useful facts: where it placed the kernel, where the command line lives, where the initrd is if you have one. Then it jumps into the setup program.&lt;/p&gt;&lt;head rend="h3"&gt;The setup program makes a safe room&lt;/head&gt;&lt;p&gt;Before Linux can do anything interesting, the setup code creates a predictable workspace.&lt;/p&gt;&lt;p&gt;It lines up the segment registers so memory copies behave the same way every time. Names you’ll see here are CS for code, DS for data, and SS for stack. It also clears a single CPU bit called the “direction flag” so copy instructions move forward through memory.&lt;/p&gt;&lt;p&gt;It creates a stack. The stack is a last‑in, first‑out workbench where functions store temporary values. SS says which segment the stack uses. SP is the pointer to the current top of the stack.&lt;/p&gt;&lt;p&gt;It clears a region called BSS. BSS is where global variables that must start as zero live. C code assumes BSS is zero. The setup program writes zeros over that entire span to keep that promise.&lt;/p&gt;&lt;p&gt;If you passed &lt;code&gt;earlyprintk&lt;/code&gt; on the kernel command line, the setup code also programs the serial port so it can print very early messages. This is useful when graphics are not ready yet.&lt;/p&gt;&lt;p&gt;Finally the setup program asks the firmware “how much usable RAM do we really have and where are the holes.” On old BIOS this is a call people often nickname e820, which returns a simple list of usable and reserved ranges. The kernel will use that list to avoid stepping on the firmware’s toes.&lt;/p&gt;&lt;p&gt;With that done, the setup code calls its first C function, which is literally named &lt;code&gt;main&lt;/code&gt;. We are still in the small old real mode at this point. The next job is to leave it.&lt;/p&gt;&lt;p&gt;Tiny explainer: interrupt An interrupt is a hardware or software “excuse me” that pauses what the CPU is doing and runs a small handler for something urgent. A timer tick is an interrupt. A key press is an interrupt. There are two flavors here. Maskable interrupts follow your rules and can be temporarily blocked so they do not fire during delicate moments. Non‑maskable interrupts, often called NMI, always cut in because they usually report serious hardware issues. We will control both while switching modes so nothing surprises us halfway through.&lt;/p&gt;&lt;head rend="h2"&gt;Part 2 — Leaving real mode, stepping through 32‑bit land, and arriving in 64‑bit&lt;/head&gt;&lt;p&gt;Modern Linux on PCs runs in long mode, which is the 64‑bit mode of x86_64. You cannot jump there directly from real mode. The path is real mode to protected mode and then protected mode to long mode. This part covers that path and explains the vocabulary on the way.&lt;/p&gt;&lt;head rend="h3"&gt;Protected mode, without the jargon haze&lt;/head&gt;&lt;p&gt;Protected mode is the 32‑bit world introduced to get past the limits of the 1980s. It adds two central ideas.&lt;/p&gt;&lt;p&gt;The Global Descriptor Table, or GDT, is a short list of segment descriptions. A description says “this segment starts here, covers this much, and is allowed to do these things.” Linux keeps this simple. It uses a flat model, which means the base is zero and the size covers the whole 32‑bit space. When everything is flat, addresses look like plain numbers again.&lt;/p&gt;&lt;p&gt;The Interrupt Descriptor Table, or IDT, is a directory of “phone numbers” for emergency calls. If an interrupt arrives, the CPU looks up the entry in the IDT and jumps to the handler listed there. During the switch we load a tiny placeholder IDT because we are about to block interrupts anyway. The full‑featured IDT arrives later once the real kernel is in charge.&lt;/p&gt;&lt;head rend="h3"&gt;The careful switch&lt;/head&gt;&lt;p&gt;The setup code turns off the noisy parts first. It disables maskable interrupts with a single instruction. It quiets the old PIC chips so hardware interrupts are fully blocked for a moment. It opens the A20 line. This is a historical quirk. Early PCs made addresses wrap at 1 megabyte. Opening A20 removes that wrap so higher addresses work like you expect. It resets the math coprocessor so the floating point state is clean.&lt;/p&gt;&lt;p&gt;Then it loads a tiny GDT with only what we need right now and a tiny IDT. Finally it sets a single bit named PE in a control register named CR0 and performs a far jump. That jump reloads the code segment from the GDT and locks in protected mode. It reloads the data and stack segments and fixes the stack pointer to match the new flat world.&lt;/p&gt;&lt;p&gt;We are now in 32‑bit protected mode.&lt;/p&gt;&lt;p&gt;Tiny explainer: control registers The CPU has a few special registers for on off switches. CR0 turns on protected mode. CR3 holds the address of the top of the page tables, which we will need in a second. CR4 enables a set of extended features such as larger page table entries.&lt;/p&gt;&lt;head rend="h3"&gt;Why we still are not done&lt;/head&gt;&lt;p&gt;Linux wants 64‑bit. That is long mode. Two things are needed.&lt;/p&gt;&lt;p&gt;Paging must be on. Paging is the translator between virtual addresses and physical addresses. Programs use virtual addresses. The hardware reads and writes physical memory. Page tables map one to the other in fixed‑size chunks called pages. On PCs a normal page is 4 kilobytes. There are also bigger pages. Early in boot the kernel uses 2 megabyte pages to describe low memory quickly.&lt;/p&gt;&lt;p&gt;A single bit named LME in a special register called EFER must be set to allow long mode. EFER is a model specific register, which is a fancy way of saying “a register used for certain CPU features.”&lt;/p&gt;&lt;head rend="h3"&gt;Building just enough paging&lt;/head&gt;&lt;p&gt;The 32‑bit prologue builds a small set of page tables that say “for this region, virtual equals physical.” That is called an identity map. It is enough to flip paging on safely.&lt;/p&gt;&lt;p&gt;To make this work the code enables PAE in CR4 so larger entries are used. It builds a minimal set of tables that cover low memory in 2 megabyte chunks. It writes the address of the top table into CR3. Paging is now ready.&lt;/p&gt;&lt;p&gt;Finally it sets LME in EFER and performs a far return into a label that is written as 64‑bit code. Long mode is now active. Segments are still “flat,” but addresses and registers are 64‑bit wide.&lt;/p&gt;&lt;p&gt;Why all the extra care Switching modes while a live system runs is like changing a car tire while rolling. The code blocks interruptions, prepares the minimum needed tables, flips the bit, and only then invites interrupts back. Slow and steady prevents weird half‑switched states.&lt;/p&gt;&lt;head rend="h2"&gt;Part 3 — Unpacking the real kernel, fixing addresses, and why Linux sometimes moves itself&lt;/head&gt;&lt;p&gt;We have a 64‑bit CPU with paging on and a compressed kernel in memory. Now the small 64‑bit stub does the practical work: get out of the way if needed, unpack the kernel, fix addresses if the kernel is not at its default spot, and jump.&lt;/p&gt;&lt;head rend="h3"&gt;Clearing a path and setting safety nets&lt;/head&gt;&lt;p&gt;The stub first figures out where it is actually running. Early code is linked as if it lived at address zero and then computes its real base at runtime. If the planned destination for the decompressed kernel would overlap the stub, it copies itself to a safe place.&lt;/p&gt;&lt;p&gt;It clears its own BSS so global state starts clean.&lt;/p&gt;&lt;p&gt;It loads a minimal IDT with two handlers. One for page fault and one for NMI. A page fault happens when the CPU cannot find a mapping for a virtual address it just tried to use. In our early identity‑mapped world, the tiny page fault handler can add the missing mapping on the fly and continue. The NMI handler is there so a non‑maskable interrupt does not crash the machine while we are still bringing things up.&lt;/p&gt;&lt;p&gt;It also builds identity mappings for the regions it will touch next. That includes the future home of the kernel, the small boot parameters page the bootloader filled in, and the command line buffer.&lt;/p&gt;&lt;head rend="h3"&gt;Decompressing Linux…&lt;/head&gt;&lt;p&gt;A C function commonly named &lt;code&gt;extract_kernel&lt;/code&gt; takes over. It sets aside a tiny heap for temporary buffers, prints the classic line, and unpacks the kernel using whatever algorithm the kernel was built with. gzip, xz, zstd, lzo, and others all plug into the same wrapper.&lt;/p&gt;&lt;p&gt;When the bytes are out, the decompressor reads the kernel’s ELF headers. ELF, short for Executable and Linkable Format, is both a file format and a map. It says which chunks are code, which are data, and exactly where each chunk wants to live. The decompressor copies each chunk where it belongs.&lt;/p&gt;&lt;p&gt;If the kernel is being loaded at a different address than it was built for, the decompressor applies relocations. A relocation is a small fix‑up that adjusts a pointer or an instruction that contains an address. The decompressor walks a list of these and patches each place so it points to the right spot in the address space we are actually using.&lt;/p&gt;&lt;p&gt;When everything is in place, the decompressor returns the entry point of the real kernel and jumps there, passing a pointer to the boot parameters. From that moment you are in the full kernel. The first function you meet is &lt;code&gt;start_kernel&lt;/code&gt;, and the big initialization begins.&lt;/p&gt;&lt;head rend="h3"&gt;Why the kernel sometimes moves itself on purpose&lt;/head&gt;&lt;p&gt;You may see kASLR mentioned in kernel logs. That stands for Kernel Address Space Layout Randomization. The idea is simple. If attackers do not know where the kernel lives in memory, certain attacks get a lot harder.&lt;/p&gt;&lt;p&gt;Early in boot, if kASLR is enabled, the decompressor chooses two “bases” at random:&lt;/p&gt;&lt;list rend="ul"&gt;&lt;item&gt;a physical base, which is where the bytes will live in RAM&lt;/item&gt;&lt;item&gt;a virtual base, the starting virtual address the kernel will use once full paging is set up&lt;/item&gt;&lt;/list&gt;&lt;p&gt;How does it choose without breaking anything&lt;/p&gt;&lt;p&gt;It builds a do not touch list. That includes the decompressor itself, the compressed image, the initial ramdisk, the boot parameters page, and the command line buffer. It can also include ranges you reserve with a &lt;code&gt;memmap=&lt;/code&gt; option on the command line.&lt;/p&gt;&lt;p&gt;It scans the memory map from firmware to find large free regions. For each free region it counts how many aligned “slots” of the right size would fit. It draws a random number using the best early entropy source it has. On modern CPUs that might be a hardware random instruction. It reduces the number to the total number of slots and picks the matching slot. That becomes the physical base. The virtual base is chosen the same way, but within the kernel’s virtual address window.&lt;/p&gt;&lt;p&gt;If nothing suitable exists, the code falls back to the default addresses and prints a small warning. If you pass &lt;code&gt;nokaslr&lt;/code&gt; on the command line, the randomization step is skipped by design.&lt;/p&gt;&lt;head rend="h2"&gt;A quick glossary you can bookmark&lt;/head&gt;&lt;p&gt;Hexadecimal. Base 16 numbers written with &lt;code&gt;0x&lt;/code&gt;. &lt;code&gt;0x10&lt;/code&gt; is 16. &lt;code&gt;0x100000&lt;/code&gt; is 1 megabyte. Hex maps cleanly to bits, which is why low‑level code uses it.&lt;/p&gt;&lt;p&gt;Register. A tiny slot inside the CPU that holds a number right now. Examples: CS, DS, SS, IP, SP.&lt;/p&gt;&lt;p&gt;Segment and offset. The two pieces used to build real‑mode addresses. Physical address equals segment times 16 plus offset.&lt;/p&gt;&lt;p&gt;BIOS. Older firmware that starts the machine, checks hardware, and loads the first boot sector into memory.&lt;/p&gt;&lt;p&gt;UEFI. Modern firmware that understands filesystems and loads larger boot programs directly.&lt;/p&gt;&lt;p&gt;Bootloader. The usher that places the kernel in memory and passes facts about the system to it. GRUB is a common one.&lt;/p&gt;&lt;p&gt;Stack. A last‑in, first‑out workbench for functions. SS selects its segment. SP points at the current top.&lt;/p&gt;&lt;p&gt;BSS. A region where global variables that must start as zero live. The kernel setup code clears it before C runs.&lt;/p&gt;&lt;p&gt;Interrupt. A fast “excuse me” from hardware or software. The CPU pauses, runs a small handler, then resumes. Maskable interrupts can be blocked for a moment. NMI cannot.&lt;/p&gt;&lt;p&gt;GDT. Global Descriptor Table. Short list of segment descriptors. Linux sets it to a simple flat model.&lt;/p&gt;&lt;p&gt;IDT. Interrupt Descriptor Table. Directory of interrupt handlers. Early boot uses a minimal one. The full kernel installs the real one later.&lt;/p&gt;&lt;p&gt;A20 line. Historical switch that must be opened to address above 1 megabyte correctly on old PCs.&lt;/p&gt;&lt;p&gt;Protected mode. 32‑bit mode that introduces the GDT and IDT and allows paging.&lt;/p&gt;&lt;p&gt;Long mode. 64‑bit mode on x86_64. Requires paging and a bit named LME set in the EFER register.&lt;/p&gt;&lt;p&gt;Paging. The translator from virtual addresses to physical memory. Implemented with page tables.&lt;/p&gt;&lt;p&gt;Page tables. The data structure that maps virtual pages to physical pages. Early boot uses identity maps. Normal pages are 4 KB. Early boot often uses 2 MB pages to cover ground quickly.&lt;/p&gt;&lt;p&gt;CR0, CR3, CR4. Control registers. CR0 turns on protected mode. CR3 points to the top of the page tables. CR4 enables extended features such as PAE.&lt;/p&gt;&lt;p&gt;EFER. A model‑specific register that holds Long Mode Enable among other bits.&lt;/p&gt;&lt;p&gt;ELF. The kernel’s on‑disk format with a built‑in map of what belongs where.&lt;/p&gt;&lt;p&gt;Relocation. A fix‑up that adjusts addresses when code is loaded at a different base than it was built for.&lt;/p&gt;&lt;p&gt;kASLR. Randomizes kernel base addresses at boot to make exploitation harder.&lt;/p&gt;&lt;p&gt;Feedback is extremely welcomed! You can reach out to me on X @0xkato&lt;/p&gt;&lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.0xkato.xyz/linux-boot/"/><published>2025-10-25T23:04:23+00:00</published></entry></feed>