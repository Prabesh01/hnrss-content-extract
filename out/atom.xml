<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>hnrss.org/frontpage</id><title>Hacker News: Front Page</title><updated>2025-10-06T11:32:26.969476+00:00</updated><link href="https://news.ycombinator.com/" rel="alternate"/><link href="https://raw.githubusercontent.com/Prabesh01/hnrss-content-extract/refs/heads/main/out/rss.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator><subtitle>Hacker News RSS</subtitle><entry><id>https://news.ycombinator.com/item?id=45473516</id><title>Explainer: Inodes and Inode Numbers</title><updated>2025-10-06T11:32:39.769404+00:00</updated><content>&lt;doc fingerprint="76fc9a0c1df5a561"&gt;
  &lt;main&gt;
    &lt;p&gt;Every self-respecting file system identifies files and directories using numbered data structures. In most modern file systems, those data structures are known as inodes, and their numbers are inode numbers, sometimes shortened to inodes. The term is thought to be a contraction of index node, which certainly makes sense, but is lost in the mists of time.&lt;/p&gt;
    &lt;p&gt;In any file system, for example an individual APFS volume, the inode numbers uniquely identify each inode, and each object within that file system has its own inode. Whatever else the file system might do, the inode number identifies one and only one object within it. Thus one invariant way of identifying any file is by referencing the file system containing it, and its inode number.&lt;/p&gt;
    &lt;head rend="h4"&gt;HFS+&lt;/head&gt;
    &lt;p&gt;The Mac’s original native file systems, ending most recently in Mac OS Extended File System, or HFS+ from its origins in the Hierarchical File System, don’t use inodes as such, and don’t strictly speaking have inode numbers. Instead, the data structures for their files and folders are kept in Catalogue Nodes, and their numbers are Catalogue Node IDs, CNIDs.&lt;/p&gt;
    &lt;p&gt;With Mac OS X came Unix APIs, and their requirement to use inodes and inode numbers. As CNIDs are unique to each file and folder within an HFS+ volume, for HFS+ they are used as inode numbers, although in some ways they differ. CNIDs are unsigned 32-bit integers, with the numbers 0-15 reserved for system use. For example, CNID 7 is normally used as the Startup file’s ID.&lt;/p&gt;
    &lt;p&gt;Although not necessarily related to CNIDs, it’s worth noting that the Mac’s original file system MFS allowed a maximum of 4,094 files, its successor HFS was limited to 65,535, and HFS+ to 4,294,967,295. Those are in effect the maximum number of inode numbers or their equivalents allowed in that file system.&lt;/p&gt;
    &lt;head rend="h4"&gt;APFS&lt;/head&gt;
    &lt;p&gt;Unlike HFS+, APFS was designed from the outset to support standard Posix features, so has inodes numbered using unsigned 64-bit integers.&lt;/p&gt;
    &lt;p&gt;Strictly, the APFS inode number is the object identifier in the header of the file-system key. Not all unsigned 64-bit integers can be used as inode numbers, though, as a bit mask is used, and the number includes an encoded object type. APFS also makes special allowance for volume groups consisting of firmlinked System and Data volumes, to allow for their inode numbers to remain unique across both volumes. Officially, those allow for a maximum number of inode numbers of 9,223,372,036,854,775,808, either in single APFS file systems, or shared across two in a volume group.&lt;/p&gt;
    &lt;p&gt;Every file in APFS is required to have, at an absolute minimum, an inode and its associated attributes, shown above in blue, including a set of timestamps, permissions, and other essential information about that file.&lt;/p&gt;
    &lt;p&gt;There are also three optional types of component:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;although some files may be dataless, most have data, for which they need file extents (green), records linking to the storage blocks containing that file’s data (pink);&lt;/item&gt;
      &lt;item&gt;smaller extended attributes (yellow), named metadata objects that are stored in a single record;&lt;/item&gt;
      &lt;item&gt;larger extended attributes (yellow), over 3,804 bytes in size, whose data is stored separately in a data stream.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h4"&gt;Interpretation&lt;/head&gt;
    &lt;p&gt;When looking at inode numbers in volume groups, they can be used to determine which of the firmlinked file systems contains any given file. Both volumes share the same volume ID, and files in the System volume have very high inode numbers, while those in the Data volume are relatively low. I have given further details here.&lt;/p&gt;
    &lt;p&gt;Inode numbers are more generally useful in distinguishing files whose data appears identical, and the behaviour of various methods of linking files.&lt;/p&gt;
    &lt;p&gt;Copying a file within the same file system (volume) creates a new file with its own inode number, of course. However, duplicating a file within the same file system results in an APFS clone file, with a distinct inode, although it shares common data, so their inode numbers are also different.&lt;/p&gt;
    &lt;p&gt;Instead of duplicating everything, only the inode and its attributes (blue and pink) are duplicated, together with their file extent information. There’s a flag in each clone file’s attributes to indicate that cloning has taken place.&lt;/p&gt;
    &lt;p&gt;A symbolic link or symlink is merely a pointer to the linked file’s path, and doesn’t involve inode numbers at all. Because of that, changing the linked file’s name or path breaks its link. Finder aliases and their kindred bookmarks do contain inode numbers, so should be able to cope with changes to the linked file’s name or path, provided it remains in the same file system and doesn’t change inode number.&lt;/p&gt;
    &lt;p&gt;Hard links are more complex, and depend on the way in which the file system implements them, although the fundamental rule is that each object that’s hardlinked to the same file has the same inode number. According to Apple’s reference to APFS, this is how it handles hard links.&lt;/p&gt;
    &lt;p&gt;When you create a hard link to a file (blue), APFS creates two siblings (purple) with their own IDs and links, including different paths and names as appropriate. Those don’t replace the original inode, and there remains a single file object for the whole of that hardlinked file.&lt;/p&gt;
    &lt;p&gt;Inode attributes keep a count of the number of links they have to siblings in their link (or reference) count. Normally, when a file has no hard links that’s one, and there are no sibling files. When a file is to be deleted, if its link count is only 1, the file and all its associated components can be removed, subject to the requirements of any clones and applicable snapshots. If the link count is greater than 1, then only the sibling being removed is deleted.&lt;/p&gt;
    &lt;head rend="h4"&gt;Easy access&lt;/head&gt;
    &lt;p&gt;Inode numbers are readily accessed using command tools in Terminal. For example, &lt;code&gt;ls -i&lt;/code&gt; lists items with their inode numbers shown. One free utility that displays full information about inode numbers and much more is Precize.&lt;/p&gt;
    &lt;p&gt;The volume ID is given as the first number in the volfs path, and the second is the inode number of that file within that. Note that the File Reference URL (FileRefURL) uses a different numbering system, and the Ref count of 1 indicates this file has no hard links.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://eclecticlight.co/2025/10/04/explainer-inodes-and-inode-numbers/"/><published>2025-10-04T14:22:04+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45480317</id><title>Self hosting 10TB in S3 on a framework laptop and disks</title><updated>2025-10-06T11:32:39.316117+00:00</updated><content>&lt;doc fingerprint="108fdf7d4527a9d6"&gt;
  &lt;main&gt;
    &lt;p&gt;About 5 months ago I made the decision to start self hosting my own S3. I was working on AppGoblin’s SDK tracking of the top 100k Android and iOS apps so was wanting a lot of space, but for cheap.&lt;/p&gt;
    &lt;p&gt;&lt;lb/&gt;I got really lucky with getting a second hand Framework laptop. The laptop was missing it’s screen, and was one of the older ones, so it was perfect for a home server. In addition I bought a “just a bunch of disks” JBOD. The framework laptop is running ZFS + garage S3. &lt;/p&gt;
    &lt;head rend="h2"&gt;I’m happy to report I haven’t thought about this laptop for months&lt;/head&gt;
    &lt;p&gt;I’ve been away, I’ve been working, I’ve been busy, and I’ve definitely been using my S3. But I hadn’t thought about the laptop in 4 months. When I finally logged in, I saw I’ve used 10TB of space and it was patiently waiting for a restart for some upgrades. I nervously restarted, and was so relieved to see everything come right back up.&lt;/p&gt;
    &lt;head rend="h2"&gt;I updated garage s3 with no issues as well&lt;/head&gt;
    &lt;p&gt;I also saw a pending upgrade for garage v1 to v2. This went along without a hitch too. Feels like it’s been a good weekend.&lt;/p&gt;
    &lt;head rend="h2"&gt;I’ve been warned…&lt;/head&gt;
    &lt;p&gt;Just so you know, I understand my use case for ZFS is possibly a bit non standard as I’m using a USB to connect the laptop and JBOD. This initially caused me issues with ZFS when garage was heavily reading and writing (the initial setup had the SQLite metadata also stored on the JBOD/ZFS).&lt;/p&gt;
    &lt;p&gt;I moved my metadata to the laptop, which has so far resolved any ZFS issues again.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://jamesoclaire.com/2025/10/05/self-hosting-10tb-in-s3-on-a-framework-laptop-disks/"/><published>2025-10-05T09:51:26+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45481892</id><title>The QNX Operating System</title><updated>2025-10-06T11:32:38.721931+00:00</updated><content>&lt;doc fingerprint="ff9e891d51a325c6"&gt;
  &lt;main&gt;
    &lt;p&gt;Gordon Bell and Dan Dodge were finishing their time at the University of Waterloo in Ontario in 1979. In pursuit of their masters degrees, they’d worked on a system called Thoth in their real-time operating systems course. Thoth was interesting not only for having been real-time and having featured synchronous message passing, but also for originally having been written in the B programming langue. It was then rewritten in the UW-native Eh language (fitting for a Canadian university), and then finally rewritten in Zed. It is this last, Zed-written, version of Thoth to which Bell and Dodge would have been exposed. Having always been written in a high-level language, the system was portable, and programs were the same regardless of the underlying hardware. Both by convention and by design, Thoth strongly encouraged programs to be structured as networks of communicating processes. As the final project for the RTOS course, students were expected to implement a real-time system of their own. This experience was likely pivotal to their next adventure.&lt;/p&gt;
    &lt;p&gt;The duo’s first year after graduation was a busy one. They moved to Kanata, went to work for Bell-Northern Research (now Nortel), and on the 30th of March in 1980, they founded Quantum Software Systems. To continue their research and experimentation with operating systems, they assembled a microcomputer built around a Motorola 6809. With the release of the IBM PC in September of 1981, Quantum’s efforts shifted to that target. Their goal was to produce a real-time operating system that would enable the PC’s use in factories, communication systems, and anywhere else that emphasized reliability.&lt;/p&gt;
    &lt;p&gt;The first version of Bell and Dodge’s operating system was QUNIX 0.1 (the Q could have been for Quantum, or for Quick, I’ve seen both from former Quantum employees), and it was running on that early, hand-assembled, 8bit microcomputer. This earliest creation was never released outside of Quantum Software as far as I know. QUNIX was a vaguely UNIX-like, microkernel, real-time operating system. I say that it was vaguely UNIX-like because in these early versions, there were some serious differences. In QUNIX, there were CP/M-like things too. Each disk had a drive number prefix, non-disk device files’ names were reserved, and the commands were a bit different from those in UNIX, often simplified to the point of being more CP/M-like than UNIX-like. Another major difference was the directory hierarchy. On a traditional UNIX system, binaries were stored in &lt;code&gt;/bin&lt;/code&gt; or &lt;code&gt;/usr/bin&lt;/code&gt;, configurations in &lt;code&gt;/etc&lt;/code&gt;, and user directories in &lt;code&gt;/home&lt;/code&gt;. On QUNIX, this wasn’t the case. Commands included in the path variable were in &lt;code&gt;/cmds&lt;/code&gt;, configuration files were in &lt;code&gt;/config&lt;/code&gt;, the OS binaries were in &lt;code&gt;/sys&lt;/code&gt;, user directories were &lt;code&gt;/user&lt;/code&gt;, drivers were in &lt;code&gt;/drivers&lt;/code&gt;, and utilities were in &lt;code&gt;/util&lt;/code&gt;. Then, the &lt;code&gt;man&lt;/code&gt; command did not exist, and &lt;code&gt;help&lt;/code&gt; was used instead. Instead of &lt;code&gt;ps&lt;/code&gt;, the system had &lt;code&gt;task&lt;/code&gt; with the labels of father, son, and brother to denote parent and child processes. The first version of QUNIX for the IBM PC was made before the end of 1981, and released either in December of 1981 or January of 1982, making QUNIX the first known microkernel operating system for the PC platform.&lt;/p&gt;
    &lt;p&gt;A fun note from Paul N. Leroux, the bar chart on the monitor in the back left was physically glued to that monitor for another press image. It wasn’t meant to be in this image, but as photo editing tools were essentially non-existent at the time, fixing this would have required them to reshoot. They chose to go to press with bar chart present.&lt;/p&gt;
    &lt;p&gt;With QUNIX 0.4.33 in 1982, QUNIX became the first operating system for the IBM PC to support a hard disk, and in particular, it supported a 5MB Davong HDD. Given that a 10MB disk in 1982 could cost around $3000, it makes sense that the company’s first target was a bit more modest. At this point, however, QUNIX would not boot from an HDD. All of the floppy contents could be copied to a hard disk, but the user would still need to boot from a floppy disk.&lt;/p&gt;
    &lt;p&gt;Even in these early stages of development, the system began getting recognition, and this became a small problem. The name QUNIX was a bit too close to the name UNIX for AT&amp;amp;T. The name of the system was changed to QNX in late 1982 following a Cease and Desist by AT&amp;amp;T. The first official QNX version was released the following year. At the time of the name change the kernel consisted of around 10K line of C, and it handled task scheduling, message passing, and task priority. Everything else was implemented in services that used the microkernel’s message passing to communicate with each other (even drivers, filesystems, and networking). As an important feature, message queues were network transparent so a task on one physical machine could communicate with a task on a separate physical machine on the same network as easily as if it were local. This inherently multitasked and multiuser system allowed 250 simultaneous tasks from 4 to 16 simultaneous users. The system would make extensive use of the 8087 if it was available, and required a minimum of 96K RAM. Loading up the C compiler would require an additional 32K. It’s impressive what the small company achieved on the 8088, even if, for the time, the RAM requirements were quite high. QNX release version 1.0, in March of 1983, running on an IBM PC achieved 29% to 47% the speed of a DEC VAX 11/780 depending upon the task at hand when tested by Rao Mikkilineni at Bell Labs. Sadly, I’ve been unable to find his original write-up of his testing, which was apparently in the publication Personna. If you have information about it, I’d love to get some details. While RV1 was limited to just C and x86 assembly language, the company was hard at work on BASIC, FORTRAN, and Pascal compilers that would utilize common code generators allowing for the mixed-use of languages without losing optimization. With the introduction of GUIs on the Apple Lisa, Xerox systems, and VisiCorp’s Visi-On, Quantum also had plans for windowing as well. According to Quantum’s president Syd Geraghty in InfoWorld on the 21st of March in 1983, the majority of customers were high-end system developers at large corporations. Version 1.0 cost $650 in 1983 (around $2100 in 2025), and that included a C compiler, full-screen editor, the ability to read MS-DOS disks, and full networking support. I haven’t found much information about versions 1.1 through 1.14, but I did find some information about 1.20 released on the 15th of November in 1984. This version brought pattern matching on filenames in the current directory, expanded shell programming, &lt;code&gt;login&lt;/code&gt; was now a separate task with fast user switching and login stacking, &lt;code&gt;TCAP&lt;/code&gt; (think terminfo), &lt;code&gt;ed&lt;/code&gt; was rewritten and supported full-screen visual mode (think Vi), and support for the IBM AT (real-mode) was added. The price of QNX had also fallen to $450.&lt;/p&gt;
    &lt;p&gt;In June of 1981, the Ontario Ministry of Education identified computing as being important for the future, and they wanted to bring computing into their schools. They were also quite aware that some teachers had taken the initiative to bring microcomputers into their classrooms already, and the Commodore PET was the most common for programming courses, while the Apple II was the most common for other educational programs. Targeting many computers would have meant that they’d have rather high software development costs in any attempt to achieve standardization, and it was therefore decided that they’d need a single computer. In 1983, it was found by the ministry and the Canadian Advanced Technology Alliance that no existing computer would fully satisfy the goals of their educational computer. By March that year, some requirements had been drafted: all-in-one PET-like design, headphone output for voice and sound, a trackball, an 80186 CPU, a multitasking operating system, color graphics, voice synthesis, keyboard with accented characters, and networked storage (no physical disk in the computer itself). This machine as described had the sobriquet “bionic beaver.”&lt;/p&gt;
    &lt;p&gt;With the specifications in hand, Robert Arn at CATA created CEMCORP (Canadian Educational Microprocessor Corporation) and won a contract from the ministry for $10 million to develop the initial machines. This resulted in the ICON having been chosen. This machine was initially manufactured by Microtel and it ran QNX from Quantum Software Systems. The first machines were delivered in 1984. Later machines were produced, sold, and supported by Burroughs Canada, and after the merger with Sperry in 1986, by Unisys.&lt;/p&gt;
    &lt;p&gt;The ICON was built around an Intel 80186 clocked at 7.16MHz and 512K RAM. It lacked any local storage having neither a hard disk drive nor floppy disk drive. At boot, the computer grabbed QNX from a local LexICON file server over a 2.5Mbps ARCNET connection, and loaded the OS into RAM. Once loaded, the user logged into the system and his/her home directory was on the file server. Up to 32 of these machines could be on a single LAN. Saving any work to a floppy, meant putting the floppy into the file server, and then copying the file from the LexICON hard disk (early models were 10MB, later models were 64MB) to that floppy. The cost of these machines was high at $2500, but any school need only have paid $495 with the government covering the rest. One incredibly forward thinking feature was the lessonware. This would have been a hypertext system in which educators could have written pages that linked to others building an extensive corpus overtime. Even applications could have been run by simply clicking a link. This model was rejected by the ministry before the ICON shipped, and was replaced by a top-down system with ministry making lesson decisions. This also resulted in the ICON having shipped a QNX CLI with the CEMCORP text editor in the earliest models.&lt;/p&gt;
    &lt;p&gt;The ICON was a project hated by many and loved by many. For detractors, it was seen as expensive and wasteful while not exposing students to industry currents. For supporters, it accomplished all of its goals. It was excellent for programming, and it was excellent at multitasking, networking, and running educational software. The software was also quite reliable. It was QNX doing what QNX does best.&lt;/p&gt;
    &lt;p&gt;From students who used ICONs, we know that it did have educational games, text editors, compilers, word processors, spread sheets, circuit design and simulation software, and CAD software. Of course, being networked machines, some unconventional students figured out ways to hack into other machines over the network, print stuff to other students’ screens, and generally cause some chaos. Combined with audio capabilities (later models even included MIDI support), this apparently got a bit out of hand from time to time.&lt;/p&gt;
    &lt;p&gt;I normally wouldn’t show so many ads, but here is a development that is rather interesting. OS/2 had been announced on the 2nd of April in 1987, and Quantum perceived the OS as a real threat. The comparisons to UNIX were now joined by comparisons to OS/2, and QNX wanted to be certain that people understood QNX to be superior. This advertisement also shows us that QNX had responded to OS/2’s ability to run DOS software by adding that feature to QNX with the QDOS II (invoked as &lt;code&gt;QDOS&lt;/code&gt;) emulator, or by running a DOS application as a task via &lt;code&gt;RUNDOS&lt;/code&gt;. QNX had been ported to the IBM PS/2 as well. This was QNX version 2.&lt;/p&gt;
    &lt;p&gt;As far as I can tell, the release of QNX version 2 was announced on the release date of version 1.2. The release of this version appears to have been quite late, and it occurred in autumn of 1987 (two years after the initial release date given). This release brought protected-mode support for the IBM AT, full LAN support with some networking enhancements ported from BSD, support for files of up to one terabyte in size, up to 32 serial ports in one machine, and a somewhat primitive GUI called House about which I can find nothing but the name.&lt;/p&gt;
    &lt;p&gt;While I couldn’t find anything about the House graphical environment, QNX Windows running the Open Look Window Manager (OLWM) is available.&lt;/p&gt;
    &lt;p&gt;In June of 1987, Quantum Software Systems ceased renting their office space, and they moved into a building they’d had built just for them. Following this, the company would expand the building three times, and finally add another building. So, the company moved from 215 Stafford Road to 175 Terrance Mathews Crescent.&lt;/p&gt;
    &lt;p&gt;As late as 1990, QNX advertisements still mentioned performance on the 80286. This seems more as though Quantum didn’t spend much on marketing rather than not having progressed. In Dan Hildebrand’s An Architectural Overview of QNX from April of 1992, we find that the company had developed QNX versions up to 3.15, and articles about operating systems in the tech press had mentioned QNX as one of the systems that took advantage of features in the 80386.&lt;/p&gt;
    &lt;p&gt;In 1989, Quantum Software Systems began work on a dramatic overhaul of the operating system. This new version would be fully POSIX-compliant and increase performance over the prior generation of QNX operating systems. This version, 4.0, was released in 1991. The kernel now had just 14 calls associated with IPC, network, scheduling, and interrupts, and the kernel weighed in at just 7K (605 LOC), allowing the entire kernel to fit in CPU caches of the time. Unlike earlier versions, messages were no longer queued. Instead, they were copied from process to process. Being POSIX-compliant allowed for the easier porting of software, and it also meant that the directory hierarchy was decidedly more familiar to UNIX veterans. Beyond source compatibility, Quantum was actively working on becoming binary compatible with UNIX as of 1992. In 1994, beyond POSIX and performance, QNX 4.1 introduced the QNX Photon microGUI. This system was developed by Patrick Hayden and Robin Burgener. Much like the underlying system, it was built around a microkernel (around 20K), and it was network transparent. A Photon application could have its interface beamed to another QNX 4 machine at any point in time, or it could be dragged from one device to another just as easily. Photon likewise allowed remote monitoring or control of the user interface. This worked regardless of the device class (desktop, laptop, handheld, server). For those who needed it, the X Windows System (X11R5, Motif Window Manager) was also available, though Photon did implement a binary interface library that was X compatible. Being so lightweight allowed the company to release a demo disk that combined networking, a web browser, web server, graphical environment, file manager, text editor, a vector animation demo, and Towers of Hanoi game onto a single 1.44MB floppy. Unlike prior QNX versions, version 4 required at least an Intel 80386 and VGA graphics card. No 16bit systems were supported.&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;KANATA, ONTARIO, September, 1994—QNX Software Systems Ltd., developers of the QNX realtime operating system, announced a unique window system targeted for handheld and embedded applications.&lt;/p&gt;&lt;lb/&gt;According to Rob Oakley, Corporate Communications and Product Management, "the Photon Window System is the first of its kind—a GUI built around a graphical microkernel."&lt;lb/&gt;QNX Software Systems designed the Photon Window System as a graphical microkernel and a team of cooperating processes, basing this design on the company's QNX OS, a microkernel network-distributed system.&lt;lb/&gt;Photon's cooperating processes provide the functionality to scale the system up into a full-featured windowing system or down to fit into resource-constrained environments, like handheld personal computers (HPCs) and compact embedded systems.&lt;lb/&gt;Photon provides a rich widget library that operates much like the X Window System widget set, with an X-inspired API. A Motif-like window manager and a code-generating, visual application builder are also available.&lt;lb/&gt;"Photon is extremely light and fast. It runs in only 256K, yet provides enormous GUI functionality," Oakley said.&lt;lb/&gt;Like the QNX OS itself, Photon is network transparent—an HPC running Photon and QNX, equipped with a wireless LAN interface, becomes a transparent extension of the LAN, able to use all the LAN's resources as if they were integrated directly into the HPC. The power this brings to the HPC user is difficult to appreciate—imagine having the power of 100 Pentiums in the palm of your hand!&lt;lb/&gt;According to Dan Dodge, Vice President R&amp;amp;D, "Photon applications are very network distributed. From the application's perspective, all the resources of all the nodes on the LAN look like a single, logical machine. The environment is so transparent that a user can drag applications from one physical screen to another."&lt;lb/&gt;For example, a user in a factory control environment could walk up to a computer and drag an application from the control screen onto an HPC, and then walk out onto the factory floor with it and interact with the live application.&lt;lb/&gt;Although Photon is aimed at compact environments, its dynamic range is extensive. "Photon's API and rich widget library can support high-performance GUI applications with enough functionality to enter the domain of X, while consuming only a fraction of the resources," said Dodge.&lt;lb/&gt;The QNX operating system is a POSIX-certified realtime OS for Intel and AMD processors. Scalable and modular, QNX fits a wide range of environments, from compact embedded controllers to resource-rich X-based development systems, to distributed realtime systems running hundreds of CPUs.&lt;/quote&gt;
    &lt;p&gt;Versions 4.2, 4.22, and 4.24 all released in 1995. The final version 4 release was 4.25 in 1997. At least one QNX 4 installation ran for over 20 years without a reboot at the ESA. This was possible because peripherals could be hotswapped, drivers could be changed, and network nodes could be added or removed without bringing the system down.&lt;/p&gt;
    &lt;p&gt;Notably, we see that in 1994, Quantum renamed itself to QNX Software Systems Limited. And with a new name and a new version of their operating system, the company won some major installs. From POS systems at FasFax that allowed for real-time sales figures from geographically disparate locations, to video conferencing systems at Georgia State University, to factories, power plants, hospitals, set-top boxes, phone systems, trains, jets, the Space Shuttle, ISPs, and even traffic lights. The price for a single license dropped to around $285 at this time, and by 1995, QNX was the leading real-time OS for x86 systems. The majority of the company’s revenue was from large enterprises.&lt;/p&gt;
    &lt;p&gt;Of course, change was coming in the 1990s, and QSSL knew it. The company took the QNX kernel from version 4.24 and forked it. They had multiple goals with this fork. The system needed to be SMP capable, support POSIX, and be more portable to new hardware. The kernel handled only IPC, message passing, interrupts, and timing. Threading became the minimal unit of scheduling. The new Process Manager then used a loader thread that copied a process’s image into memory freeing the Manager to service other requests while a program continued to load. Naturally, being a real-time system, priority levels were used when scheduling any time-critical process, and new processes inherited the priority of their parent by default. The Process Manager weighed in at 32K (same size as the kernel itself) but added memory allocation, process contexts, resource-manager namespaces, and so on. In this new QNX version, the Process Manager ran inside the microkernel’s address space, but was the only element of the OS to do so. Much of the network stack for this version came from NetBSD, and with that came the ability to use NetBSD network drivers. There was another major change that came from the wider UNIX world, GCC. This naturally meant that language support was quite broadened to include not just C, C++ but all of the other languages supported by the GNU Compiler Collection. This became QNX Neutrino 1.0 released in 1996.&lt;/p&gt;
    &lt;p&gt;On the 19th of October in 1998, QSSL announced QNX Neutrino 2.0 which featured UPM (Universal Process Model). In the words of CTO Dan Dodge:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The premise of UPM is simple. Go beyond the limited MMU protection provided by the other major embedded OSs - where only applications are prevented from corrupting memory - and extend that protection down to services at the kernel level. The result? For the first time, MIPS and PowerPC-based embedded systems can intelligently recover from software faults in drivers, protocol stacks, and custom OS extensions - typically without rebooting.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX was branching into non x86 platforms, and this included PowerPC processors: 401, 403GC, 603e, 821, 823, 860; MIPS processors R4000 and R5000; and naturally all x86 CPUs from the 80386 onward. At this stage, however, the development environment was restricted to QNX 4 and Windows 95/98/NT.&lt;/p&gt;
    &lt;p&gt;This announcement was followed by another about a partnership with Amiga:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Cologne, Germany, November 13 - Amiga Inc. today announced a partnership with QNX Software Systems Ltd. to utilize the QNX realtime operating system (RTOS) as the foundation for the next-generation Amiga architecture. The announcement was made at Computer '98 in Cologne.&lt;/p&gt;
      &lt;p&gt;"The Amiga shook the industry in the 80s with world-leading multimedia architecture," said Jeff Schindler, general manager of Amiga Inc. "QNX's RTOS resembles many of Amiga's unique qualities. It provides the foundation in reaching our vision for the rebirth of Amiga in the new millenium."&lt;/p&gt;
      &lt;p&gt;"We see this partnership as a powerful combination of superior OS technologies, common corporate cultures, and shared business vision," said Dan Dodge, Chief Technology Officer and Cofounder of QNX Software Systems Ltd.&lt;/p&gt;
      &lt;p&gt;About Amiga&lt;/p&gt;
      &lt;p&gt;Amiga Inc. is a technology company targeting the next generation of Amiga architecture with a continued focus on multimedia and the Internet. Since the introduction of the Amiga A1000 in 1985, Amiga has represented the embodiment of the efficient use of memory and hard drive capacity, while pioneering industry developments in multimedia, 32-bit multitasking, and autoconfiguration. Amiga led the industry in combining computer graphics, animation, and film sequences with stereo sound known today as multimedia. Visit http://www.amiga.com and http://www.amiga.de.&lt;/p&gt;
      &lt;p&gt;About QSSL&lt;/p&gt;
      &lt;p&gt;Founded in 1980, QNX Software Systems is one of the top three realtime operating-system vendors in the world, with products licensed in more than a million systems worldwide. The company has established a strong customer base in a variety of industries, including aerospace, telecommunications, medical instrumentation, process control, point-of-sale, consumer electronics, finance, and telephony. With products distributed in over 100 countries, the company is headquartered in Ottawa, Canada.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;The Amiga port should have been somewhat straightforward considering that Amiga accelerators had been using PowerPC chips, and those chips were now supported by QNX. Gateway’s Amiga team was working closely with QSSL to build a new Amiga (Amiga NG) around the PowerPC G3 and G4 chips running QNX, and these were apparently prototyped as single, dual, and quad processor machines. During alpha testing, Gateway PowerPC boards apparently had some issues, and the two parties blamed one another. By the middle of 1999, Gateway, QSSL, and to some extent Motorola, had poured a hefty sum into the project, and Gateway began insisting on a solid date for the availability of a QNX Neutrino port. Evidently they weren’t satisfied, and I do not believe communication between the two teams, which had one been quite good, was solid by this point. At noon on the 8th of July in 1999, Dan Dodge announced the QNX Developers Network for Amigans. This was followed by another announcement at 15:15 the following day:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Eight months ago we were chosen by Amiga as their foundation OS partner. Our development group was thrilled to be part of the rebirth of such an innovative product. To meet the challenge we knew it would take a tremendous effort on our part. We had a team of people in place working on our part of the Amiga NG soon after the alliance was announced. Over the next few months we involved more and more of our engineering resouces towards making QNX an advanced multi-media platform. Our investment so far has been significant. These are costs we have borne ourselves.&lt;/p&gt;
      &lt;p&gt;It is clear today from Jim's letter that we were not chosen for the next generation Amiga. Naturally we're disappointed. So, where do we stand now? It is not our intent to confuse the Amiga community. We are proud of what we have accomplished and want to include Amigans in what we've achieved. I did make a promise to deliver an operating system and I intend on keeping that promise. I don't want to split the community, nor do I wish to engage in a war of words. I don't ask you to "trust" me or to take me at my word. Both QNX and Amiga have promised to deliver technology into your hands in the very near future. I ask only that your assessment of QNX be based on what we do and what we deliver.&lt;/p&gt;
      &lt;p&gt;Thanks for the overwhelming support we have received so far.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;That letter by Jim Collas read, in part:&lt;/p&gt;
    &lt;quote&gt;&lt;p&gt;Dear Amigans,&lt;/p&gt;&lt;p&gt;After months of research and in-depth discussions with all of our technology partners we have decided to use Linux as the primary OS kernel for the new Amiga Operating Environment (OE). I know this decision is a shock to many of you given the previous announcements and activities relative to QNX. This was a very complicated and difficult decision to make and I assure you that I didn't make this decision without a significant amount of research and deliberation. We have been researching Linux since February but didn't finalized our decision until several weeks ago. We were planning to communicate it to the Amiga community in the technology brief that will be released in the next few days.&lt;/p&gt;&lt;p&gt;I am pressed to communicate the Linux decision before the technology brief because of information released by QNX in the last few days. This information had not been reviewed or approved for release by Amiga. In light of our Linux decision, this information is confusing and misleading so I would like to take the time to clarify the situation. I can't disclose any details of the Amiga/QNX discussions because of legally binding confidentiality agreements but I can talk to you about our decision to use the Linux kernel. I think that you will agree that this is the right decision once you understand the reasons for this decision.&lt;/p&gt;&lt;p&gt;Before I continue, I should mention that our technology decision does not reflect negatively on QNX. I believe that QNX is a good company with great technology. I just believe that Linux gives us a better chance of executing our plans successfully. The decision to use QNX as our OS partner on our next generation multimedia convergence computer (MCC) was made late last year. When I took over as president of Amiga in February of this year, I initiated an in-depth review of existing Amiga plans and decisions. As president of Amiga I had to make sure that we were defining a strategy and an execution plan that would allow Amiga and the Amiga community to be successful. We reviewed our strategy, architecture decisions, technology partners, and execution plans. During this review period we also added a number of very talented and experienced people to help us finalize our technology and product decisions. I am confident that we now have a solid and exciting plan that people can have confidence in.&lt;/p&gt;&lt;p&gt;Linux has been picking up substantial momentum over the past year as a viable, open OS alternative in the marketplace. This momentum, the growing commitment to Linux applications from a wide variety of software vendors, and the growing availability of Linux device drivers from hardware vendors, makes it a compelling candidate. Additionally, with all of the significant component suppliers putting resources on writing drivers for Linux it was difficult to get them to port to yet another operating system. Using the Linux OS as a foundation for our Amiga OE allows us to leverage a significant amount of available software drivers and utilities. This allows us to quickly support multiple graphics cards and other peripherals.&lt;/p&gt;&lt;p&gt;Given the above-mentioned advantages, we decided to do an in-depth technical analysis of Linux to determine if it was a suitable OS kernel for our new Amiga operating environment (OE). As we ported parts of our higher level operating environment and AmigaObject architecture to Linux, we discovered some significant performance advantages in the Linux kernel in areas such as distributed object messaging across a network (up to 10X the performance of Windows NT).&lt;/p&gt;&lt;p&gt;Does this mean that the next generation Amiga will not be unique? Absolutely not! Remember that the OS kernel is only one component of the new Amiga OE and the hardware is unique. The revolutionary nature of the Amiga OE is in the way it extends the traditional operating system to provide a host environment for a new class of portable applications - applications that exist in a pervasive networked computing environment. We will be integrating multiple technologies including an efficient windowing environment and a unique user interface. In summary, we decided to use Linux because of the incredible momentum and the fact that it is solid technology and a good foundation for our new Amiga OE.&lt;/p&gt;&lt;p&gt;Additionally, the Linux community is an impressive force that we should be aligned with. We share many common values and objectives with the Linux community. Using Linux as our OS kernel allows us to build a unique and revolutionary operating environment while leveraging the enormous momentum of Linux. The soon to be released technology brief will further explain our architecture and plans for integrating all of the selected technology. Once you read it, I am confident that you will understand the revolutionary nature of the next generation Amiga. I assure you that Amiga and the Amiga community will be a driving force behind the next computer&lt;/p&gt;&lt;lb/&gt;revolution.&lt;/quote&gt;
    &lt;p&gt;As a person using Linux at the time, I believe this to have been the wrong decision. Despite the momentum that Linux had, it wasn’t (still isn’t) as stable, as reliable, or as efficient as QNX. If network performance were a serious consideration, one of the BSDs would have been the better choice. Linux’s hardware support also wasn’t that great in reality. While it could run on quite a bit of kit, it didn’t always support that hardware well, and it didn’t always support all features. Plus, QNX was doing the work to build drivers for the new Amiga. Of course, none of this really mattered. Gateway chose to divest itself of Amiga entirely. The new Amiga Inc. then turned to AmigaOne Partners for Amiga OS 4.&lt;/p&gt;
    &lt;p&gt;QNX Neutrino 2.1 was released in 1999 with support for Java, the Glide API, a wide array of microcontrollers, ARM, StrongARM, and Hitachi SH-4. Interestingly, this release had beta packages including RealPlayer and X in Photon, and it had experimental packages that included Quake 3 Arena and Doom.&lt;/p&gt;
    &lt;p&gt;On the 14th of September in 1999, QNX made an announcement that would shape the future of QNX. The company was partnering with Motorola to develop automobile driver information systems that included in-vehicle navigation, internet access, natural language processing, car audio, multimedia, and vehicle information dashboards. While the Motorola unit responsible for mobileGT wouldn’t last and the unit at IBM working on Java wouldn’t last, QNX would survive and thrive in that segment.&lt;/p&gt;
    &lt;p&gt;QNX version 6 was released on the 18th of January in 2001. The new version was focused on multimedia with streaming video and audio as well as hardware accelerated MPEG encode/decode. The new system included a web based package manager greatly easing the installation of available software. Thankfully, all supported architectures could now be used for developing QNX native software too. Version 6.1 was mostly a patch release and followed later the same year. QSSL was a founding member of the Eclipse Foundation, and QNX software development got quite a bit better with the release of the Momentics Tool Suite on the 4th of June in 2002 (along with QNX 6.2). This was largely the Eclipse IDE combined with a series of plugins that were QNX and Photon oriented.&lt;/p&gt;
    &lt;p&gt;The last release of QNX by QSSL was version 6.3 on the 3rd of June in 2004. This version was visually slightly different, and Voyager was replaced by the Mozilla Suite. The development environment was improved and now offered a clustering framework for the development of networked applications utilizing distributed processing. Among the highlights for this release were SCTP support, IP filter and NAT support, IPv6 support, 2D and 3D graphics layering/compositing, full UTF8 support in Photon, USB2 host support, and support for up to 64GB of RAM on x86 and PPC, up to 1TB on MIPS.&lt;/p&gt;
    &lt;p&gt;On the 27th of October in 2004, QNX Software Systems Limited was purchased by Harman International Industries. Harman specifically wanted to focus on QNX Neutrino in the embedded market, and within that market, specifically on automotive applications where Harman had found a market in audio. Under Harman’s ownership, QNX operated as a separate division led by Dan Dodge as CEO. While QNX did continue to serve networking, medical, and industrial markets, the direction was clear. What had begun with the Motorola partnership in automotive would become the primary market.&lt;/p&gt;
    &lt;p&gt;QNX development continued with 6.3 SP1, SP2, and SP3. Version 6.3.2 was released on the 16th of August in 2006, 6.4 on the 30th of October in 2008, and 6.4.1 in May of 2009. Throughout that time period, QNX had introduced support for Adobe Flash and developed the QNX CAR platform winning a trophy from Adobe for their efforts. This platform was built of modular components allowing manufacturers to mix and match based upon the market segment. QNX was chosen by companies like BMW, Mercedes, Dodge, Toyota, Volkswagen, and Audi. When QNX demoed their automotive systems in the 2007-2009 timeframe, they had concept dashboards. These all ran QNX Neutrino on ARM CPUs (often Freescale i.MX6 or TI Sitara [Cortex A8]) with the EtherCAT motion library, and many demo units had UIs created in Qt5 and QML while a few had hardware accelerated OpenGL interfaces. From 2008 to 2010, QNX had been licensed for use in more than 17 million in-vehicle systems representing an increase of around 130% over those two years. By March of 2010, more than 200 vehicles were already shipping with QNX, and the QNX CAR platform had more than 60 participants. Those participants included 17 auto makers and 26 automotive suppliers.&lt;/p&gt;
    &lt;p&gt;On the 9th of April in 2010, Research in Motion announced their acquisition of QSS from Harman for $200 million:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;“RIM is excited about the planned acquisition of QNX Software Systems and we look forward to ongoing collaboration between Harman, QNX and RIM to further integrate and enhance the user experience between smartphones and in-vehicle audio and infotainment systems," said Mike Lazaridis, President and Co-CEO at RIM. "In addition to our interests in expanding the opportunities for QNX in the automotive sector and other markets, we believe the planned acquisition of QNX will also bring other value to RIM in terms of supporting certain unannounced product plans for intelligent peripherals, adding valuable intellectual property to RIM's portfolio and providing long-term synergies for the companies based on the significant and complementary OS expertise that exists within the RIM and QNX teams today."&lt;/p&gt;
      &lt;p&gt;"We welcome the opportunities that a strengthened relationship with RIM will create, as two innovation leaders collaborate to bring new connectivity solutions to the industry," said Dinesh C. Paliwal, Harman's Chairman, President and CEO. "We expect to maintain our close association with QNX and the cutting-edge software solutions it provides to Harman and our customers. We believe our leading customers will fully endorse this move and see it as a major step in advancing seamless connectivity and integration among intelligent devices."&lt;/p&gt;
      &lt;p&gt;"Like Harman, RIM shares our passion for innovation and reliability, so we are absolutely thrilled with this opportunity," said Dan Dodge, CEO, QNX Software Systems. "Moreover, RIM will give us the best of all possible mandates: to continue on our innovation path and to increase investment in our core products, professional services, and go-to-market channels. This is a great time to be a QNX customer, as we focus on collaborating with RIM to create an even more exciting platform for the next generation of connected and embedded devices."&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;Also in 2010, QNX gained the QNX Safety kernel variant. This was a version of Neutrino that was security hardened specifically for mission critical applications. This variant continues to this day with the most recent version (8.0) having been independently certified by TÜV Rheinland to meet several standards including ISO 26262 ASIL D, IEC 61508 SIL3, IEC 62304 Class C, and ISO/SAE 21434. Aside from security hardening, the QNX Safety variant is still fully compatible with Neutrino’s native APIs and POSIX.&lt;/p&gt;
    &lt;p&gt;In July of 2010, QNX Neutrino 6.5 was released. This version brought performance improvements to the kernel when systems were seeing high memory utilization, the kernel gained zombie reaping, and it gained address space randomization. SMP support was increased, and CPU support was extended to ARMv7 Cortex A-9. The Photon microGUI saw some refinements. As one would expect, version updates were present for everything imported from BSD, Linux, and GNU. This version could make use of the NetBSD’s Pkgsrc tool.&lt;/p&gt;
    &lt;p&gt;Version 6.5 was forked to create both the BlackBerry Tablet OS and BBX shortly after its creation. The first device to see a QNX-derived operating system from RIM was the PlayBook, which featured an OMAP 4430 SoC (1.5 GHz dual-core A9), PowerVR SGX540 GPU, 1GB of RAM, 16GB of eMMC flash, a 1024 by 600 seven inch LCD, Bluetooth, 802.11n, USB2, micro HDMI, a 5MP rear camera, and a 3MP front camera. It measured 5.1 inches by 7.6 inches, was about 2/5 of inch thick, and it weighed just under a pound.&lt;/p&gt;
    &lt;p&gt;The PlayBook was released on the 19th of April in 2011 to mixed reviews. While many loved the webkit browser, user interface, HDMI output, and multitasking, many loathed the requirement of a BlackBerry to get certain apps working. Additionally, there was a dearth of third party applications. This latter complaint did get ameliorated. While at launch there weren’t too many applications, this grew to over 24,000 by the same time the following year. Around 2,465,000 PlayBooks had been sold by June of 2013.&lt;/p&gt;
    &lt;p&gt;The BlackBerry Z10 was released on the 31st of January in 2013 running BBX (officially BlackBerry 10 due to a trademark dispute, and at the launch event for BBX, Research in Motion announced that they were changing their name to BlackBerry Limited). The Z10 was built around a Qualcomm Snapdragon S4 Plus SoC (dual core 1.5GHz Krait CPU, Adreno 225 GPU) for LTE units, or around the TI OMAP 4470 for non-LTE units. The shell was plastic wrapped around a stainless steel inner frame, and the on/off, voice command, and volume buttons on the right side were of metal. While it didn’t have quite the premium feel of an iPhone, it did feel good in the hand. In its dimensions it was 5.1 inches by 2.6 inches, and just over an 1/3 of an inch thick (or just slightly larger than an iPhone 5). It was a slick piece of kit with a high price for the time at $599. The display, however, was excellent. It was a 4.2 inch LCD with a resolution of 1280 by 768 at 355ppi (the iPhone 5 was 326ppi). The device had a 2MP font camera, and an 8MP rear camera capable of HDR, panorama, and 1080p video at 30fps. Wi-Fi was dual band 802.11n, and the device featured Bluetooth, GPS, and NFC. Of course, connectivity didn’t stop there. This device had physical ports: micro USB2, micro HDMI, and 3.5mm audio.&lt;/p&gt;
    &lt;p&gt;BBX made heavy use of gestures with a swipe up from the bottom taking the user to the Home Screen, a swipe to right to hit the App Library, and a swipe to the left going to the BlackBerry Hub. The Hub was a combination of SMS/MMS, email, social media, chat, notifications, and calls in a single unified location. BBX was QNX Neutrino, but it did differ. Multitasking was limited to 8 applications at any one time which I believe to have been done due to the application frameworks. A developer could choose to use C/C++ and the Cascades UI framework, or WebWorks which utilized HTML5 with Zepto.js (JQuery API, but 8.4k compressed), or WebKit, or Adobe AIR (Flash), or Android runtime. With so many different application types, decisions would have had to have been made around resource management, and a best guess at when performance would become unacceptable.&lt;/p&gt;
    &lt;p&gt;BlackBerry had been unable to compete against the iPhone and Android, and BBX was their last, best hope. By 2014, BBX was in the number four spot behind Windows Phone. By 2017, it was clear that they weren’t going to survive in the mobile market. Due to the extreme devotion of their fans, they kept BBX on life support until 2022. Being an amazing OS running on good hardware, why did BBX fail? Likely, the most pressing problem was application support. While BBX could run some Android applications, support was limited. The platform likewise failed to grab many developers as the existing install bases for iOS and Android were enormous. What applications were made for BBX were often of quite low effort. Finally, moving to a touch screen angered BlackBerry’s existing fanbase. For those individuals hanging on to the BlackBerry ecosystem, the keyboard was one of the main reasons why. Removing the physical keyboard made many of those fans feel betrayed. When BlackBerry Limited did release another phone with a physical keyboard, it was a bit too late.&lt;/p&gt;
    &lt;p&gt;On the 20th of September in 2013, BlackBerry Limited announced a 4500 person staff reduction and $1 billion (CAD) loss. On the 23rd, they announced an acquisition by Fairfax Financial Holdings for $9/share. This deal was canceled in November. Instead, John Chen became CEO and initiated a turn around that focused on QNX’s former markets of healthcare, finance, law, and mission critical systems. This focus allowed the company to pick up Ford Motor Company as a QNX customer on the 11th of December in 2014 (Ford had previously used Microsoft Auto).&lt;/p&gt;
    &lt;p&gt;On the 28th of February in 2014, BlackBerry released QNX 6.6. The supported platforms were now the expected x86 and ARM CPUs with no mention of any others. This was a major change despite being a point release. Photon support was removed in favor of the Screen Graphics Subsystem. Screen operates as a lower-level service, and this has the benefit of supporting off-screen rendering and compositing of various image sources, and as QNX software had been increasingly using Qt, HTML5, or OpenGL rather than the toolkits supplied with Photon, this made logical sense.&lt;/p&gt;
    &lt;p&gt;QNX version 7 was released on the 4th of January in 2017 for ARM v7, ARM v8, x86, and AMD64. This release featured a rewritten PCI server with APIs moved out of libc and into libpci, rewritten virtual memory manager, fewer synchronization objects with increased limits, and filesystem encryption was moved into the Encrypted Filesystem package available from QNX Software Centry.&lt;/p&gt;
    &lt;p&gt;By June of 2023, QNX was in over 255 million vehicles around the world, and this would explain why the BlackBerry blog featured a rather large section on automobiles:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;The automotive evolution to SDVs and “connected cars” requires an OS capable of speed, safety, and security — while unlocking the power to innovate.&lt;/p&gt;
      &lt;p&gt;"With more than 300 million vehicles capable of over-the-air software updates expected to be on the road globally by 2032, automakers are clamoring for better tools to help them develop compelling technology features in the software-defined vehicle," says Alex Oyler, director of North America at SBD Automotive, a leading global automotive technology research and consulting firm.&lt;/p&gt;
      &lt;p&gt;“Both automakers and suppliers rely on validated software and well-integrated development tools to help them more efficiently build and maintain differentiating software for their fleets,” Oyler adds. "A secured-by-design operating system such as the next generation QNX OS — that seamlessly integrates with other software components on a high-performance system-on-chip — represents the foundation of a safe, secure, and seamless experience for drivers.”&lt;/p&gt;
      &lt;p&gt;In addition, early reviews of the new QNX SDP 8.0 give automotive industry leaders a glimpse into what’s possible.&lt;/p&gt;
      &lt;p&gt;“The combination of our DRIVE Thor centralized computer and the new QNX OS will serve as a powerful foundation on which OEMs can build next-generation automotive systems that offer the highest levels of safety and security,” says Ali Kani, vice president and general manager of automotive at NVIDIA. “This represents another major milestone in a nearly 20-year collaboration with BlackBerry QNX that has helped both companies move to the forefront of the automotive industry.”&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX 8.0 was officially announced in December of 2023, and the release was made in January of 2024. Version 8.0 was quickly discontinued with 8.0.1 taking its place. Version 8.0.3 was made available on the 21st of March in 2024. This latest release is available for a variety of Aarch64 platforms including the Raspberry Pi, and is also available for AMD64. QNX 8 supports SoCs with up to 64 cores and has near linear performance scaling. The network stack is now based upon FreeBSD 13.2, Wi-Fi 6 support is present with WPA3 and TLS 1.3, Screen can operate fully headless and now supports Vulkan 1.3 and OpenCL 3, and Screen now supports Wayland 1.21. Developers are now encouraged to use LLVM and libc++ 16 though GCC is still available with libstdc++ 12.2. Python 3.11, valgrind, libasan (address sanitizer), libubsan (undefined behavior detection), and libunwind are all available. For the UNIX user land, Toybox has replaced many common GNU utilities.&lt;/p&gt;
    &lt;p&gt;If the Raspberry Pi port caught your attention, this is available free for non-commercial use via QNX Everywhere. The image requires a Raspberry Pi 4 with at least 2GB of RAM and an 8GB or greater MicroSD card.&lt;/p&gt;
    &lt;p&gt;On the 2nd of January in 2025, it was announced that BlackBerry IoT would now be known as QNX. This decision was made largely by BlackBerry responding to their customers who recognized and desired the QNX brand. QNX CEO John Giamatteo stated:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Relaunching the QNX brand is an important step in BlackBerry’s broader strategy to increase our visibility and fortify our leadership within the automotive and embedded industries, with a view to better positioning us for sustained growth and success. The values that QNX stands for have always been a cornerstone for our customers and this brand relaunch honors that strong history while setting the stage for the division to fire on all cylinders and drive smarter, safer, and faster innovation through precision-engineered performance.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;p&gt;QNX is a fascinating operating system. It was extremely well designed from the start, and while it has been rewritten, the core ideas that allowed it survive for 45 years persist to this day. While I am sad that Photon was deprecated, the reasoning is sound. Most vendors using QNX either do not require a GUI, or they implement their own. For example, while Boston Dynamics uses QNX in their robots, they don’t really need Photon, and neither do SpaceX’s Falcon rockets. While cars certainly have displays, most vehicle makers desire their screen interfaces to have a unique look and feel. Of course, just stating these use cases of robots, rockets, and cars speaks to the incredible reliability and versatility of QNX. Better operating systems are possible, and QNX proves it.&lt;/p&gt;
    &lt;p&gt;My dear readers, many of you worked at, ran, or even founded the companies I cover here on ARF, and some of you were present at those companies for the time periods I cover. A few of you have been mentioned by name. All corrections to the record are sincerely welcome, and I would love any additional insights, corrections, or feedback. Please feel free to leave a comment.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.abortretry.fail/p/the-qnx-operating-system"/><published>2025-10-05T14:47:13+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45482467</id><title>NFS at 40 – Remembering the Sun Microsystems Network File System</title><updated>2025-10-06T11:32:35.097149+00:00</updated><content>&lt;doc fingerprint="2f90b3e32bf72b79"&gt;
  &lt;main&gt;
    &lt;p&gt;This website gathers material related to the Sun Microsystems Network File System, a project that began in 1983 and remains a fundamental technology for today’s distributed computer systems.&lt;/p&gt;
    &lt;p&gt;The occasion which prompted this project was the ~40th anniversary of NFS, celebrated in September 2025 at the MSST Conference in Santa Clara, CA.&lt;/p&gt;
    &lt;p&gt;The core of the collection is design documents, white papers, engineering specifications, conference and journal papers, and standards material. However it also covers marketing materials, trade press, advertising, books, “swag”, and personal ephemera. We’re always looking for new contributions.&lt;/p&gt;
    &lt;p&gt;We’ve organized the material in four sections:&lt;/p&gt;
    &lt;p&gt;Unless otherwise noted, everything is downloadable from this site.&lt;/p&gt;
    &lt;p&gt;A full list of the Internet RFCs related to NFS can be found here.&lt;/p&gt;
    &lt;p&gt;There is also a site, nfsv4bat.org, which seems to include a variety of materials related to NFS after 1995, especially Connectathons. However, be careful: the site is insecure, load times are insanely slow, and it is unclear whether it’s still being maintained.&lt;/p&gt;
    &lt;p&gt;This website was created with the help of (alphabetically) Russel Berg, Russ Cox, Steve Kleiman, Bob Lyon, Tom Lyon, Joseph Moran, Brian Pawlowski, David Rosenthal, and Kate Stout. Please send any comments or suggestions to me, Geoff Arnold, via email. Last updated .&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://nfs40.online/"/><published>2025-10-05T15:49:58+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483386</id><title>Fire destroys S. Korean government's cloud storage system, no backups available</title><updated>2025-10-06T11:32:34.588021+00:00</updated><content>&lt;doc fingerprint="fd40bb1beeb70fe1"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;NIRS fire destroys government's cloud storage system, no backups available&lt;/head&gt;
    &lt;p&gt; Published: 01 Oct. 2025, 17:59 &lt;/p&gt;
    &lt;p&gt;A fire at the National Information Resources Service (NIRS)'s Daejeon headquarters destroyed the government’s G-Drive cloud storage system, erasing work files saved individually by some 750,000 civil servants, the Ministry of the Interior and Safety said Wednesday.&lt;/p&gt;
    &lt;p&gt;The fire broke out in the server room on the fifth floor of the center, damaging 96 information systems designated as critical to central government operations, including the G-Drive platform. The G-Drive has been in use since 2018, requiring government officials to store all work documents in the cloud instead of on personal computers. It provided around 30 gigabytes of storage per person.&lt;/p&gt;
    &lt;p&gt;However, due to the system’s large-capacity, low-performance storage structure, no external backups were maintained — meaning all data has been permanently lost.&lt;/p&gt;
    &lt;p&gt;The scale of damage varies by agency. The Ministry of Personnel Management, which had mandated that all documents be stored exclusively on G-Drive, was hit hardest. The Office for Government Policy Coordination, which used the platform less extensively, suffered comparatively less damage.&lt;/p&gt;
    &lt;p&gt;The Personnel Ministry stated that all departments are expected to experience work disruptions. It is currently working to recover alternative data using any files saved locally on personal computers within the past month, along with emails, official documents and printed records.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry noted that official documents created through formal reporting or approval processes were also stored in the government’s Onnara system and may be recoverable once that system is restored.&lt;/p&gt;
    &lt;p&gt;“Final reports and official records submitted to the government are also stored in OnNara, so this is not a total loss,” said a director of public services at the Interior Ministry.&lt;/p&gt;
    &lt;p&gt;The Interior Ministry explained that while most systems at the Daejeon data center are backed up daily to separate equipment within the same center and to a physically remote backup facility, the G-Drive’s structure did not allow for external backups. This vulnerability ultimately left it unprotected.&lt;/p&gt;
    &lt;p&gt;Criticism continues to build regarding the government's data management protocols.&lt;/p&gt;
    &lt;p&gt;This article was originally written in Korean and translated by a bilingual reporter with the help of generative AI tools. It was then edited by a native English-speaking editor. All AI-assisted translations are reviewed and refined by our newsroom.&lt;/p&gt;
    &lt;p&gt;BY JEONG JAE-HONG [[email protected]],D&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://koreajoongangdaily.joins.com/news/2025-10-01/national/socialAffairs/NIRS-fire-destroys-governments-cloud-storage-system-no-backups-available/2412936"/><published>2025-10-05T17:20:39+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45483924</id><title>What GPT-OSS leaks about OpenAI's training data</title><updated>2025-10-06T11:32:34.028362+00:00</updated><content>&lt;doc fingerprint="3526435e2833cedc"&gt;
  &lt;main&gt;
    &lt;p&gt;19th of September 2025&lt;/p&gt;
    &lt;p&gt;OpenAI recently released their open-weights model. Here we'll discuss how that inevitably leaks some information about their model training stack, and, on the way, show that GPT-5 was trained on phrases from adult websites.&lt;/p&gt;
    &lt;p&gt;What data does OpenAI train their models on? That is a well-protected trade secret of course, one with vested interest for the answer. While GPT-oss's weights are openly available, the sources of training data are not clearly described in the model card. It is stated that the model was trained on a "text-only dataset with trillions of tokens, with a focus on STEM, coding, and general knowledge". However, as we will see, the model parameters can tell us more than that.&lt;/p&gt;
    &lt;p&gt;A demonstration to start with: Let's have OpenAI's GPT-5We use version GPT-5-2025-08-07 for these experiments. Here is a link to the completion. do the simplest kind of task possible for a language model, repeating a string of Unicode text. Let's choose something random, like the Abkhaz word for "population", which is "ауааԥсыра". Upon asking &lt;code&gt;Repeat after me: "ауааԥсыра"&lt;/code&gt;, it replies something completely different, "ആളുകൾ", which apparently means people in MalayalamAccording to this dictionary. Subsequent translations here are patched together with web searches, online dictionaries and translation software.. As you might have guessed, we did not choose that string randomly at all, it is a special adversarial input belonging to a class of glitch tokens. But how did we identify such a glitch token among the 200,000 tokens that GPT-5 uses?
                            
                        &lt;/p&gt;
    &lt;p&gt;All of OpenAI's models since GPT-4o use the o200k tokenizer. This means that we can use the GPT-oss embeddings to study the token list without having to look at each token's text content. Let's make a histogram of the L2 norm of each row of the embedding matrix.&lt;/p&gt;
    &lt;p&gt;This low L2-norm token group could be useful for two things. Its (1) variance gives an estimate of the variance used in the initialization and (2) its mean would give an estimate of how many gradient descent steps were taken in total, if we assume standard weight decay and know the learning rate.&lt;/p&gt;
    &lt;p&gt;The right tail of the distribution is not quite Gaussian either. Looking at the English tokens with the highest norm, we find:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Token ID&lt;/cell&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;L2 Norm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;44041&lt;/cell&gt;
        &lt;cell&gt;' accordingly'&lt;/cell&gt;
        &lt;cell&gt;246.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;3490&lt;/cell&gt;
        &lt;cell&gt;' code'&lt;/cell&gt;
        &lt;cell&gt;243.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;84879&lt;/cell&gt;
        &lt;cell&gt;'ocode'&lt;/cell&gt;
        &lt;cell&gt;235.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;976&lt;/cell&gt;
        &lt;cell&gt;'The'&lt;/cell&gt;
        &lt;cell&gt;233.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;8743&lt;/cell&gt;
        &lt;cell&gt;' settings'&lt;/cell&gt;
        &lt;cell&gt;231.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;100466&lt;/cell&gt;
        &lt;cell&gt;'Moreover'&lt;/cell&gt;
        &lt;cell&gt;229.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;6496&lt;/cell&gt;
        &lt;cell&gt;' description'&lt;/cell&gt;
        &lt;cell&gt;226.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;58369&lt;/cell&gt;
        &lt;cell&gt;"""Let's"""&lt;/cell&gt;
        &lt;cell&gt;224.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;2500&lt;/cell&gt;
        &lt;cell&gt;'This'&lt;/cell&gt;
        &lt;cell&gt;224.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;10089&lt;/cell&gt;
        &lt;cell&gt;' core'&lt;/cell&gt;
        &lt;cell&gt;219.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;74447&lt;/cell&gt;
        &lt;cell&gt;' utilizes'&lt;/cell&gt;
        &lt;cell&gt;218.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;119705&lt;/cell&gt;
        &lt;cell&gt;' revolves'&lt;/cell&gt;
        &lt;cell&gt;218.0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;53329&lt;/cell&gt;
        &lt;cell&gt;"""Here's"""&lt;/cell&gt;
        &lt;cell&gt;216.1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;14836&lt;/cell&gt;
        &lt;cell&gt;' possibly'&lt;/cell&gt;
        &lt;cell&gt;214.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;18485&lt;/cell&gt;
        &lt;cell&gt;' logic'&lt;/cell&gt;
        &lt;cell&gt;212.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;42469&lt;/cell&gt;
        &lt;cell&gt;' thereby'&lt;/cell&gt;
        &lt;cell&gt;211.8&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;These tokens are either very common, or appear especially in reasoning tasks, in particular those with code. This might mean that coding reinforcement learning was the last step in the training process, and that all other tokens got slightly weight decayed. It could also mean that in general, reasoning tokens are treated as so important by gradient descent that their updates are extra large.&lt;/p&gt;
    &lt;p&gt;Filtering for non-ASCII tokens with the highest norm, we find a different picture:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="3"&gt;
        &lt;cell role="head"&gt;Token ID&lt;/cell&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;L2 Norm&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;166343&lt;/cell&gt;
        &lt;cell&gt;'гылара'&lt;/cell&gt;
        &lt;cell&gt;213.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;187102&lt;/cell&gt;
        &lt;cell&gt;' министири'&lt;/cell&gt;
        &lt;cell&gt;212.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;89721&lt;/cell&gt;
        &lt;cell&gt;'这里只有精品'&lt;/cell&gt;
        &lt;cell&gt;212.4&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;181865&lt;/cell&gt;
        &lt;cell&gt;'еиԥшым'&lt;/cell&gt;
        &lt;cell&gt;207.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;129320&lt;/cell&gt;
        &lt;cell&gt;'彩娱乐彩票'&lt;/cell&gt;
        &lt;cell&gt;207.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;170421&lt;/cell&gt;
        &lt;cell&gt;'天天好彩票'&lt;/cell&gt;
        &lt;cell&gt;206.6&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;177625&lt;/cell&gt;
        &lt;cell&gt;'久久综合网'&lt;/cell&gt;
        &lt;cell&gt;204.5&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;71476&lt;/cell&gt;
        &lt;cell&gt;' иҳәеит'&lt;/cell&gt;
        &lt;cell&gt;203.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;185118&lt;/cell&gt;
        &lt;cell&gt;'[REDACTED]'&lt;/cell&gt;
        &lt;cell&gt;202.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;104937&lt;/cell&gt;
        &lt;cell&gt;' 北京赛车怎么'&lt;/cell&gt;
        &lt;cell&gt;201.2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;146111&lt;/cell&gt;
        &lt;cell&gt;' Урҭ'&lt;/cell&gt;
        &lt;cell&gt;200.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;195219&lt;/cell&gt;
        &lt;cell&gt;"',伊人'"&lt;/cell&gt;
        &lt;cell&gt;200.3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;147298&lt;/cell&gt;
        &lt;cell&gt;'大香蕉网'&lt;/cell&gt;
        &lt;cell&gt;199.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;165874&lt;/cell&gt;
        &lt;cell&gt;' акоронавирус'&lt;/cell&gt;
        &lt;cell&gt;198.9&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;66183&lt;/cell&gt;
        &lt;cell&gt;'րբե�'&lt;/cell&gt;
        &lt;cell&gt;198.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;173463&lt;/cell&gt;
        &lt;cell&gt;' иажәа'&lt;/cell&gt;
        &lt;cell&gt;197.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;160540&lt;/cell&gt;
        &lt;cell&gt;'彩神争霸邀请码'&lt;/cell&gt;
        &lt;cell&gt;195.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;155587&lt;/cell&gt;
        &lt;cell&gt;'бжьаратәи'&lt;/cell&gt;
        &lt;cell&gt;195.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;154809&lt;/cell&gt;
        &lt;cell&gt;'无码不卡高清免费v'&lt;/cell&gt;
        &lt;cell&gt;194.8&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="3"&gt;
        &lt;cell&gt;105084&lt;/cell&gt;
        &lt;cell&gt;'хадоу'&lt;/cell&gt;
        &lt;cell&gt;194.7&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;134370&lt;/cell&gt;
        &lt;cell&gt;'一本道高清无码'&lt;/cell&gt;
        &lt;cell&gt;194.6&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Mandarin speakers will have understood that the above contains an unwholesome sublist of spammy and adult-oriented website terms, with some being too explicit to make the list here. Indeed, o200k, the tokenizer used for 4o, o1, o3, o4, oss, and GPT-5 contains a lot of junk tokens. This means that every time ChatGPT runs, a matrix containing all the strange tokens we are talking about here are patiently waiting on Microsoft Azure to be multiplied with. Some of my personal favorite tokens are "北京赛车怎么" (How to play Beijing Racing), "天天中彩票的" (Winning the lottery every day), and of course "《凤凰大参考" (Phoenix Reference). Another token is "铁血网", the name of a Chinese nationalism and military enthuiasm website, which is ironic given the geopolitical considerations that are usually raised in connection with OpenAI. It is unexpected that this type of political content not just made it into the tokenizer training data, but was even overrepresented.&lt;/p&gt;
    &lt;p&gt;There are also some oddball high-norm tokens in Abkhaz, Armenian, Gujarati, Thai, and more. Some interesting examples are ",ಂಗಳೂರು" (The city Mangaluru in Kannada) along with other cities in Kerala, "ถวายสัตย์ฯ" ("Oath of Allegiance" in Thai), "แขวงคลองเตยเหนือ" (a district in Bangkok with less than 10,000 inhabitants), "วิเคราะห์บอลวันนี้" ("today's football analysis" in Thai) along with a handful of other football-related tokens.&lt;/p&gt;
    &lt;p&gt;The question is, why do these tokens have a higher, not lower, norm than the normal tokens? If they are unused, weight decay should bring them all the way down to the other unused tokens.&lt;/p&gt;
    &lt;p&gt;In this post, Jessica Rumbelow identified similar glitch tokens in GPT-2 and GPT-3, most famously the "SolidGoldMagicarp" token. Her finding was that the tokens closest to the mean of all embeddings were the glitch tokens, not necessarily those with low norm. But that's not the case here: Tokens with comparatively high norm are always far away from the mean. Further, computing cosine similarity between two of these embeddings gives higher similarity on average.&lt;/p&gt;
    &lt;p&gt;One way to get closer to the answer is to observe the models' behavior when given these tokens. We ask GPT-oss and GPT-5 about the not-so-classy token 162657: &lt;code&gt;What does this mean: "毛片免费观看"&lt;/code&gt;. With some euphemism, it means "watching explicit videos for free" in Mandarin. &lt;/p&gt;
    &lt;p&gt;In the response See the full completion here. To verify that the string was tokenized as expected, we can use tiktokenizer. , GPT-5 correctly states that the token contains Chinese text, and that it is related to watching something. It can also enumerate some of the characters in it. This means that the token was seen during training, at least once! Interestingly, the model seems to be aware of the inappropriate meaning of the token, but plays it down and in particular does not refuse to answer. Presumably this is because the token only occurs a few times in the training corpus.&lt;/p&gt;
    &lt;p&gt;In other words, we can say that a certain string, in this case a sensitive one, was part of the GPT-5 training corpus. This is called membership inference in the machine learning literature. Membership inference with high confidence is generally considered to be impractical in production LLMs, so this is a surprising finding.&lt;/p&gt;
    &lt;p&gt;Automating this process through the API, we can find which glitch tokens were seen during training of the GPT-oss and GPT-5 model families. We ask the models to give a translation of the token to English and ask for the language the token is in. For now, we simply filter for the Chinese tokens, and pass 50 tokens with highest L2 embedding norm to the models. For a control, we also ask Claude 4 and can confirm that it always answers correctly. Since a few of these tokens could technically be Japanese, we count this as a correct answer, too. For cost reasons, we ask about each token only 4 times per model, and denote 4 correct answers with a ✓, 3 and 2 with a !, 1 with a ?, and 0 with a ✗.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="7"&gt;
        &lt;cell role="head"&gt;Token&lt;/cell&gt;
        &lt;cell role="head"&gt;Crude Translation&lt;/cell&gt;
        &lt;cell role="head"&gt;GPT-5&lt;/cell&gt;
        &lt;cell role="head"&gt;Mini&lt;/cell&gt;
        &lt;cell role="head"&gt;Nano&lt;/cell&gt;
        &lt;cell role="head"&gt;oss-20B&lt;/cell&gt;
        &lt;cell role="head"&gt;oss-120B&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;毛片免费观看&lt;/cell&gt;
        &lt;cell&gt;Watch Explicit Videos Free&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;铁血网&lt;/cell&gt;
        &lt;cell&gt;[Chinese Patriotism Website]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;这里只有精品&lt;/cell&gt;
        &lt;cell&gt;Only Fine Things Here&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩娱乐彩票&lt;/cell&gt;
        &lt;cell&gt;Color Entertainment Lottery&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天好彩票&lt;/cell&gt;
        &lt;cell&gt;Daily Good Lottery&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;久久综合网&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车怎么&lt;/cell&gt;
        &lt;cell&gt;How to Beijing Racing&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大香蕉网&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸邀请码&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Invitation Code&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码不卡高清免费v&lt;/cell&gt;
        &lt;cell&gt;Uncensored No Lag HD Free&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;一本道高清无码&lt;/cell&gt;
        &lt;cell&gt;One Way HD Uncensored&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发快三和值&lt;/cell&gt;
        &lt;cell&gt;[Name of gambling website (?)]&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天中彩票能&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery Winner Can&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码一区二区三区&lt;/cell&gt;
        &lt;cell&gt;Uncensored Zone 1 Zone 2 Zone 3&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸邀请码&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Invitation Code&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩票开户&lt;/cell&gt;
        &lt;cell&gt;Lottery Account Opening&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;色综合网&lt;/cell&gt;
        &lt;cell&gt;Color Comprehensive Network&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩票平台开户&lt;/cell&gt;
        &lt;cell&gt;Lottery Platform Account Opening&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;综合久久&lt;/cell&gt;
        &lt;cell&gt;Comprehensive Long Time&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;免费视频观看&lt;/cell&gt;
        &lt;cell&gt;Free Video Watching&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;最新高清无码&lt;/cell&gt;
        &lt;cell&gt;Latest HD Uncensored&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;一级a&lt;/cell&gt;
        &lt;cell&gt;Level A&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;玩大发快三&lt;/cell&gt;
        &lt;cell&gt;Play Dafa Fast Three&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;东臣&lt;/cell&gt;
        &lt;cell&gt;East Minister&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;凤凰大参考&lt;/cell&gt;
        &lt;cell&gt;Phoenix Reference&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;棋牌游戏官网&lt;/cell&gt;
        &lt;cell&gt;Chess Card Game Official Site&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;热在线精品&lt;/cell&gt;
        &lt;cell&gt;Hot Online Quality&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩娱乐平台&lt;/cell&gt;
        &lt;cell&gt;Color Entertainment Platform&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;购彩官网&lt;/cell&gt;
        &lt;cell&gt;Lottery Purchase Official Site&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;最新高清无码专区&lt;/cell&gt;
        &lt;cell&gt;Latest HD Uncensored Zone&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车女郎&lt;/cell&gt;
        &lt;cell&gt;Beijing Racing Girls&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大香线蕉&lt;/cell&gt;
        &lt;cell&gt;Big Fragrant Line Banana&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;官网开户&lt;/cell&gt;
        &lt;cell&gt;Official Site Account Opening&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;经典三级&lt;/cell&gt;
        &lt;cell&gt;Classic Third Level&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;在线大香蕉&lt;/cell&gt;
        &lt;cell&gt;[Name of adult website (?)]&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;无码不卡&lt;/cell&gt;
        &lt;cell&gt;Uncensored No Lag&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发时时彩怎么&lt;/cell&gt;
        &lt;cell&gt;Dafa Time Color How&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发云&lt;/cell&gt;
        &lt;cell&gt;Dafa Cloud&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;和天天中彩票&lt;/cell&gt;
        &lt;cell&gt;And Daily Lottery Winner&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;平台总代理&lt;/cell&gt;
        &lt;cell&gt;Platform General Agent&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天买彩票&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery Buying&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;天天彩票app&lt;/cell&gt;
        &lt;cell&gt;Daily Lottery App&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸充值&lt;/cell&gt;
        &lt;cell&gt;Color God Battle Recharge&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;彩神争霸app&lt;/cell&gt;
        &lt;cell&gt;Color God Battle App&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;律宾&lt;/cell&gt;
        &lt;cell&gt;Law Bin&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;大发扑克&lt;/cell&gt;
        &lt;cell&gt;Dafa Poker&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;热这里只有精品&lt;/cell&gt;
        &lt;cell&gt;Hot Only Quality Here&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="7"&gt;
        &lt;cell&gt;北京赛车有&lt;/cell&gt;
        &lt;cell&gt;Beijing Racing Has&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;留下些什么吧&lt;/cell&gt;
        &lt;cell&gt;Leave Something Behind&lt;/cell&gt;
        &lt;cell&gt;!&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✗&lt;/cell&gt;
        &lt;cell&gt;✓&lt;/cell&gt;
        &lt;cell&gt;?&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;We can read off that the explicit token we already found is recognized by all models, and identify a few more anomalous tokens that were likely seen during training. Many others however are not recognized, and thus unlikely to have been in the training data.&lt;/p&gt;
    &lt;p&gt;We try to identify a pattern in the tokens that are recognized. It generally seems that recognized tokens yield many more hits on GitHub. Indeed, there often are some spam repositories on GitHub that contain these recognized strings, as well as some repositories containing lists of strings to block for content moderation.&lt;/p&gt;
    &lt;p&gt;The membership inference only tells us that the model saw the string, not where it was sourced from. To test whether GitHub was a likely source, we therefore correlate the number of search hits on GitHub with the number of correct answers across the GPT models. We find a significant Spearman's ρ of 0.448. This does not prove that GitHub was the source, because the high search hit count on GitHub could just be indicative that the token is more common across the internet. Nonetheless, the setup demonstrates how glitch tokens could be used to make broader statements about the training data.&lt;/p&gt;
    &lt;p&gt;In summary, we have found strong evidence that models in the GPT-5 and GPT-oss family were trained on phrases from adult websites. We have also found weak evidence that part of the GPT training corpus was scraped off of GitHub. The search was made easier via access the weights of GPT-oss, showing how the open-weights paradigm opens up new attack vectors on production models. It seems advisable for frontier labs to mitigate this problem by excluding uncommon strings from their tokenizer vocabularies.&lt;/p&gt;
    &lt;p&gt;These glitch tokens have more uses than was described above. If you want to work with these concepts, the companion repository provides a starting point. Some ideas that could be interesting to explore:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Token / Token Family&lt;/cell&gt;
        &lt;cell role="head"&gt;Explanation&lt;/cell&gt;
        &lt;cell role="head"&gt;Example Prompt&lt;/cell&gt;
        &lt;cell role="head"&gt;Behaviour&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CHKERRQ&lt;/cell&gt;
        &lt;cell&gt;The weirdest pure ASCII token. From a function name in C.&lt;/cell&gt;
        &lt;cell&gt;Can you spell the following word: "CHKERRQ"&lt;/cell&gt;
        &lt;cell&gt;"Unspeakable" for gpt-4o-mini. gpt-4o sometimes almost spells correctly, other times hallucinates.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Can you output every second letter in "CHKERRQ"?&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o hallucinate.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Write a poem using the word "CHKERRQ"&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o-mini write creepily about the word "terminate"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;\\xadder&lt;/cell&gt;
        &lt;cell&gt;No idea.&lt;/cell&gt;
        &lt;cell&gt;Please spell "\\xadder"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o spells it as "hexadecimal", the summary model is confused and sees "QRST"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;♀♀♀♀&lt;/cell&gt;
        &lt;cell&gt;From social media bios?&lt;/cell&gt;
        &lt;cell&gt;How many symbols are in♀♀♀♀&lt;/cell&gt;
        &lt;cell&gt;gpt-4o trips and outputs random (?) Chinese characters&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;€¦&lt;/cell&gt;
        &lt;cell&gt;From spreadsheets?&lt;/cell&gt;
        &lt;cell&gt;What are these symbols: "€¦"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini thinks this is an ellipsis ("...")&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;風吹けば名無し and 8 variants&lt;/cell&gt;
        &lt;cell&gt;Literally "no name if the wind blows". Former default user name on baseball-themed 2channel boards. (Source)&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of "風吹けば名無し"?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o sometimes hallucinates randomly. gpt-4o-mini hallucinates about baseball and attempts to spell it, incorrectly.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;＠お腹いっぱい&lt;/cell&gt;
        &lt;cell&gt;Literally "@TummyIsFull". From a former default username on 2channel boards.&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of＠お腹いっぱい?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o conflates it with common Japanese phrases and random syllables, gpt-4o-mini similar.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;＠おーぷん&lt;/cell&gt;
        &lt;cell&gt;Literally "@Open". Also from 2channel.&lt;/cell&gt;
        &lt;cell&gt;Please repeat the word＠おーぷん back to me.&lt;/cell&gt;
        &lt;cell&gt;Seemingly unspeakable for gpt-4o-mini and hard to say for gpt-4o.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;How do you pronounce＠おーぷん?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o hallucinates the above mentioned "If the wind blows, Mr. Nameless"&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;VIPがお送りします&lt;/cell&gt;
        &lt;cell&gt;Literally "Brought to you by VIP". Another 2channel term.&lt;/cell&gt;
        &lt;cell&gt;Please explain the meaning of "VIPがお送りします".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini is adorable and hallucinates about the horn emoji (📯)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;中央値との差&lt;/cell&gt;
        &lt;cell&gt;Japanese for "difference from the median".&lt;/cell&gt;
        &lt;cell&gt;Please spell this backwards: "中央値との差"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o answers with lowercase latin characters.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;.minecraftforge&lt;/cell&gt;
        &lt;cell&gt;File extension from Minecraft modding&lt;/cell&gt;
        &lt;cell&gt;Please spell the string "readme.minecraftforge"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini: 'The string is spelled "M-O-D dot F-O-R-G-E-R-E-C-E dot G-E.'&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;CHANTABILITY&lt;/cell&gt;
        &lt;cell&gt;Ending of MER-CHANTABILITY&lt;/cell&gt;
        &lt;cell&gt;Please spell the word "CHANTABILITY".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o spells it as "Chanceability".&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;《凤凰大参考&lt;/cell&gt;
        &lt;cell&gt;"The Phoenix Reference"&lt;/cell&gt;
        &lt;cell&gt;What is the meaning of《凤凰大参考?&lt;/cell&gt;
        &lt;cell&gt;Unspeakable for gpt-4o&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;亚历山大发&lt;/cell&gt;
        &lt;cell&gt;"Alexander"&lt;/cell&gt;
        &lt;cell&gt;Please translate this: " 亚历山大发".&lt;/cell&gt;
        &lt;cell&gt;gpt-4o thinks it's Abkhaz for yes.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;微信里的天天中彩票 and the ~100 other Chinese lottery tokens&lt;/cell&gt;
        &lt;cell&gt;This article speculates why the tokenizer training data included so many of these.&lt;/cell&gt;
        &lt;cell&gt;Please print every second character in the following: 微信里的天天中彩票.&lt;/cell&gt;
        &lt;cell&gt;Reliable gibberish generator on gpt-4o-mini. The tokens themselves are mostly unspeakable.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;SUPERHOST&lt;/cell&gt;
        &lt;cell&gt;Programming term?&lt;/cell&gt;
        &lt;cell&gt;Please output every second letter in "SUPERHOST"&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini spells it as "SPARENT" and then trips&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;ILLISECONDS&lt;/cell&gt;
        &lt;cell&gt;Ending of M-ILLISECONDS&lt;/cell&gt;
        &lt;cell&gt;Please reverse the string "ILLISECONDS"&lt;/cell&gt;
        &lt;cell&gt;Trouble with character-level operations for gpt-4o-mini.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;GETGLOBAL&lt;/cell&gt;
        &lt;cell&gt;Programming term&lt;/cell&gt;
        &lt;cell&gt;Please output every second letter in " GETGLOBAL"&lt;/cell&gt;
        &lt;cell&gt;Makes gpt-4o-mini hallucinate "GETALLONG" at character level.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;_REALTYPE _EDEFAULT _PRODUCTS&lt;/cell&gt;
        &lt;cell&gt;Maybe from the library libstdc++?&lt;/cell&gt;
        &lt;cell&gt;Can you output every second letter in_REALTYPE?&lt;/cell&gt;
        &lt;cell&gt;gpt-4o-mini likes to hallucinate "translated"&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;As more research on glitch tokens becomes available, I will try to list it here. The most comprehensive report to date is this article in MIT Technology Review, and there are many articles in Chinese, such as this one. However, these discuss the tokenizer itself, not how the models behave.&lt;/p&gt;
    &lt;p&gt;Finally, if you are in a position to fix the issue in the OpenAI API, I presume you already know how, else I'm happy to help. Note that a fix could even lower inference cost a bit. You can mail to lennart@finke.dev.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://fi-le.net/oss/"/><published>2025-10-05T18:28:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45484284</id><title>Toybox: All-in-one Linux command line</title><updated>2025-10-06T11:32:33.544419+00:00</updated><content>&lt;doc fingerprint="b4a05d537d87a8a3"&gt;
  &lt;main&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt; Notifications &lt;tool-tip&gt;You must be signed in to change notification settings&lt;/tool-tip&gt;&lt;/item&gt;
      &lt;item&gt;Fork 365&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;toybox&lt;/p&gt;
    &lt;head rend="h3"&gt;License&lt;/head&gt;
    &lt;head rend="h1"&gt;landley/toybox&lt;/head&gt;
    &lt;head rend="h2"&gt;Folders and files&lt;/head&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;Name&lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit message&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell role="head"&gt;
          &lt;p&gt;Last commit date&lt;/p&gt;
        &lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h2"&gt;Repository files navigation&lt;/head&gt;
    &lt;quote&gt;Toybox: all-in-one Linux command line. --- Getting started You can download static binaries for various targets from: http://landley.net/toybox/bin The special name "." indicates the current directory (just like ".." means the parent directory), and you can run a program that isn't in the $PATH by specifying a path to it, so this should work: wget http://landley.net/toybox/bin/toybox-x86_64 chmod +x toybox-x86_64 ./toybox-x86_64 echo hello world --- Building toybox Type "make help" for build instructions. Toybox uses the "make menuconfig; make; make install" idiom same as the Linux kernel. Usually you want something like: make defconfig make make install Or maybe: LDFLAGS="--static" CROSS_COMPILE=armv5l- make defconfig toybox PREFIX=/path/to/root/filesystem/bin make install_flat The file "configure" defines default values for many environment variables that control the toybox build; if you export any of these variables into your environment, your value is used instead of the default in that file. The CROSS_COMPILE argument above is optional, the default builds a version of toybox to run on the current machine. Cross compiling requires an appropriately prefixed cross compiler toolchain, several example toolchains (built using the file "scripts/mcm-buildall.sh" in the toybox source) are available at: https://landley.net/toybox/downloads/binaries/toolchains/latest For the "CROSS_COMPILE=armv5l-" example above, download armv5l-linux-musleabihf-cross.tar.xz, extract it, and add its "bin" subdirectory to your $PATH. (And yes, the trailing - is significant, because the prefix includes a dash.) For more about cross compiling, see: https://landley.net/toybox/faq.html#cross http://landley.net/writing/docs/cross-compiling.html http://landley.net/aboriginal/architectures.html For a more thorough description of the toybox build process, see: http://landley.net/toybox/code.html#building --- Using toybox The toybox build produces a multicall binary, a "swiss-army-knife" program that acts differently depending on the name it was called by (cp, mv, cat...). Installing toybox adds symlinks for each command name to the $PATH. The special "toybox" command treats its first argument as the command to run. With no arguments, it lists available commands. This allows you to use toybox without installing it, and is the only command that can have an arbitrary suffix (hence "toybox-armv5l"). The "help" command provides information about each command (ala "help cat"), and "help toybox" provides general information about toybox. --- Configuring toybox It works like the Linux kernel: allnoconfig, defconfig, and menuconfig edit a ".config" file that selects which features to include in the resulting binary. You can save and re-use your .config file, but may want to run "make oldconfig" to re-run the dependency resolver when migrating to new versions. The maximum sane configuration is "make defconfig": allyesconfig isn't recommended as a starting point for toybox because it enables unfinished commands, debug code, and optional dependencies your build environment may not provide. --- Creating a Toybox-based Linux system Toybox has a built-in simple system builder (scripts/mkroot.sh) with a Makefile target: make root sudo chroot root/host/fs /init Type "exit" to get back out. If you install appropriate cross compilers and point it at Linux source code, it can build simple three-package systems that boot to a shell prompt under qemu: make root CROSS_COMPILE=sh4-linux-musl- LINUX=~/linux cd root/sh4 ./qemu-sh4.sh By calling scripts/mkroot.sh directly you can add additional packages to the build, see scripts/root/dropbear as an example. The FAQ explains this in a lot more detail: https://landley.net/toybox/faq.html#system https://landley.net/toybox/faq.html#mkroot --- Presentations 1) "Why Toybox?" talk at the Embedded Linux Conference in 2013 outline: http://landley.net/talks/celf-2013.txt video: http://youtu.be/SGmtP5Lg_t0 The https://landley.net/toybox/about.html page has nav links breaking that talk down into sections. 2) "Why Public Domain?" The rise and fall of copyleft, Ohio LinuxFest 2013 outline: http://landley.net/talks/ohio-2013.txt audio: https://archive.org/download/OhioLinuxfest2013/24-Rob_Landley-The_Rise_and_Fall_of_Copyleft.mp3 3) Why did I do Aboriginal Linux (which led me here) 260 slide presentation: https://speakerdeck.com/landley/developing-for-non-x86-targets-using-qemu How and why to make android self-hosting: http://landley.net/aboriginal/about.html#selfhost More backstory than strictly necessary: https://landley.net/aboriginal/history.html 4) What's new with toybox (ELC 2015 status update): video: http://elinux.org/ELC_2015_Presentations outline: http://landley.net/talks/celf-2015.txt 5) Toybox vs BusyBox (2019 ELC talk): outline: http://landley.net/talks/elc-2019.txt video: https://www.youtube.com/watch?v=MkJkyMuBm3g --- Contributing The three important URLs for communicating with the toybox project are: web page: http://landley.net/toybox mailing list: http://lists.landley.net/listinfo.cgi/toybox-landley.net git repo: http://github.com/landley/toybox The maintainer prefers patches be sent to the mailing list. If you use git, the easy thing to do is: git format-patch -1 $HASH Then send a file attachment. The list holds messages from non-subscribers for moderation, but I usually get to them in a day or two. I download github pull requests as patches and apply them with "git am" (which avoids gratuitous merge commits). Sometimes I even remember to close the pull request. If I haven't responded to your patch after one week, feel free to remind me of it. Android's policy for toybox patches is that non-build patches should go upstream first (into vanilla toybox, with discussion on the toybox mailing list) and then be pulled into android's toybox repo from there. (They generally resync on fridays). The exception is patches to their build scripts (Android.mk and the checked-in generated/* files) which go directly to AOSP. (As for the other meaning of "contributing", https://patreon.com/landley is always welcome but I warn you up front I'm terrible about updating it.)&lt;/quote&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://github.com/landley/toybox"/><published>2025-10-05T19:09:35+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45485736</id><title>Ken Parker, famed luthier, has died</title><updated>2025-10-06T11:32:33.251415+00:00</updated><content>&lt;doc fingerprint="365db15571e068b0"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;RIP Ken Parker: August 25, 1952 – October 5, 2025&lt;/head&gt;
    &lt;p&gt;Ken Parker, age 73, passed away peacefully at his home in Gloucester, MA on October 5, 2025, with Susan Kolwicz by his side.&lt;/p&gt;
    &lt;p&gt;From Ken, October 3rd, 2025:&lt;/p&gt;
    &lt;p&gt;Hello Everybody,&lt;/p&gt;
    &lt;p&gt;Well, they say that nothing lasts forever and they’re right about that. My time here is about to close down and I won’t be part of the show anymore. What I have done with all my heart and soul is to put together a situation where my work can continue unabated and begin to bring some serious fruit to the things that I’ve been working on for the last 50 years.&lt;/p&gt;
    &lt;p&gt;My deepest and most heartfelt thanks to all of you. It’s been the experience of my lifetime being able to share my life’s work and knowledge with each of you through my instruments and via Archtoppery, and see that you get it. My hope is that you all build on what I’ve learned and shared, and take everything to the next level.&lt;/p&gt;
    &lt;p&gt;Sam Krimmel will be doing just that, and I encourage you to support Sam as he ventures forth. Sam is a natural co-conspirator and he and I will be will be working together down the road through some sort of psychic medium. We’ve already got some amazing new things underway and soon we’re going to show you what that is all about. So stay tuned.&lt;/p&gt;
    &lt;p&gt;All right, well everyone, please take care of yourselves and peace on earth, if that should ever be possible.&lt;/p&gt;
    &lt;p&gt;Love, Ken&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://kenparkerarchtops.com"/><published>2025-10-05T22:10:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45485806</id><title>Germany outfitted half a million balconies with solar panels</title><updated>2025-10-06T11:32:32.877441+00:00</updated><content>&lt;doc fingerprint="3707d1531a06ed9a"&gt;
  &lt;main&gt;
    &lt;p&gt;Matthias Weyland loves having people ask about his balcony. A pair of solar panels hang from the railing, casting a sheen of dark blue against the red brick of his apartment building. They’re connected to a microinverter plugged into a wall outlet and feed electricity directly into his home. On a sunny day, he’ll produce enough power to supply up to half of his family’s daily needs.&lt;/p&gt;
    &lt;p&gt;Weyland is one of hundreds of thousands of people across Germany who have embraced balkonkraftwerk, or balcony solar. Unlike rooftop photovoltaics, the technology doesn’t require users to own their home, and anyone capable of plugging in an appliance can set it up. Most people buy the simple hardware online or at the supermarket for about $550 (500 euros.)&lt;/p&gt;
    &lt;p&gt;The ease of installation and a potent mix of government policies to encourage adoption has made the wee arrays hugely popular. More than 550,000 of them dot cities and towns nationwide, half of which were installed in 2023. During the first half of this year, Germany added 200 megawatts of balcony solar. Regulations limit each system to just 800 watts, enough to power a small fridge or charge a laptop, but the cumulative effect is nudging the country toward its clean energy goals while giving apartment dwellers, who make up more than half of the population, an easy way to save money and address the climate crisis.&lt;/p&gt;
    &lt;p&gt;“I love the feeling of charging the bike when the sun is shining, or having the washing machine run when the sun is shining, and to know that it comes directly from the sun,” Weyland said. “It’s a small step you can take as a tenant” and an act of “self-efficacy, to not just sit and wait until the climate crisis gets worse.”&lt;/p&gt;
    &lt;p&gt;Balcony solar emerged around a decade ago, but didn’t catch on until four or five years ago, thanks in part to years of lobbying by solar and clean energy advocates for policies to foster its adoption. The German government enacted the first technical regulations for plug-in solar devices in 2019, allowing balcony solar systems to use standard electrical plugs and feed into the grid. That prompted an influx of plug-in devices and advocates to promote the technology.&lt;/p&gt;
    &lt;p&gt;The pandemic helped fuel the surge in popularity as people spent time at home, working on DIY projects. More recently, the escalating energy prices that followed Russia’s invasion of Ukraine led more Germans to consider balcony solar. “People just did anything they could to reduce their energy bills,” said Wolfgang Gründinger, who works with the clean energy company Enpal.&lt;/p&gt;
    &lt;p&gt;Federal and local policymakers have redoubled their efforts to make the technology more accessible. In April, the government simplified permitting and registration requirements, and in July, federal lawmakers passed renter protections that prevent landlords from arbitrarily blocking installations. Cities throughout Germany, including Berlin and Weyland’s home city of Kiel, have offered millions of euros in subsidies to install balcony solar.&lt;/p&gt;
    &lt;p&gt;Gründinger and experts at the German Solar Industry Association noted that the devices don’t generate enough power to strain the grid, and their standardized design and safety features allow them to integrate smoothly and easily.&lt;/p&gt;
    &lt;p&gt;Despite the hype, most users concede that balcony solar provides modest cost and energy savings. Weyland spent around $530 for his 600-watt-capacity system. While he’s happy with how his south-facing panels perform during balmy weather, such days are rare in northern Germany. He estimates that he’ll save around $100 in annual electricity costs and recoup his investment in about five years.&lt;/p&gt;
    &lt;p&gt;That’s fairly typical, although advocates of the technology say a system’s efficacy — and, therefore, payback timeline — varies widely depending upon the number of panels, their location and direction, and how much shade surrounds them. A household with a “comparatively large well-positioned balcony system in a sunny spot facing south” can produce 15 percent of its electricity with balcony solar, according to Peter Stratmann, head of renewables at German Federal Network Agency, the country’s utility regulator.&lt;/p&gt;
    &lt;p&gt;While that can put a dent in a household’s utility bill, its impact on Germany’s consumption is far smaller. “Even if we attached panels to all suitable balconies across the country, we’d still only manage to meet 1 percent or less of our overall energy needs,” Stratmann told Deutsche Welle.&lt;/p&gt;
    &lt;p&gt;So if balcony solar doesn’t generate a lot of power or save a lot of money, why are so many people flocking to it? Many of them like the idea of producing energy at home and gaining a bit of independence from the grid. It also provides a tangible way to take climate action. “It makes the energy transition feel a little more concrete and not so abstract,” said Helena Holenweger of the nonprofit Deutsche Umwelthilfe, or Environmental Action Germany. She installed a balcony solar system on top of her garage about a year ago. “You can literally do something about it.”&lt;/p&gt;
    &lt;p&gt;Holenweger and others who have tapped the sun said balcony solar led them to reevaluate their understanding of electricity consumption and take steps to reduce it. “For lots of people, energy is just something that comes out of your socket,” Holenweger said. “You never think about how it gets there or how it works.” The systems don’t include battery storage, so the juice they generate must be used immediately, leading people to plan the best time to, say, run the washing machine to ensure they’re using renewable energy. In that way, it becomes something of a game. Many balcony solar kits feature an app to track daily energy generation, providing what has, for many people, become a scorecard. “They screenshot that, they send it around to their Facebook groups, family WhatsApp groups. They’re super proud,” Gründinger said.&lt;/p&gt;
    &lt;p&gt;Germany is unique in its rabid embrace of the tech. Although increasingly popular in Austria, the Netherlands, France, and elsewhere in Europe, plug-in solar devices aren’t viable in the United States due to costly permitting requirements and other local regulations. Beyond that, most systems are designed to European electrical standards, making them incompatible with U.S. power systems.&lt;/p&gt;
    &lt;p&gt;But even in Germany, balcony solar still faces hurdles, including fierce resistance from landlords worried about electrical fires or put off by the aesthetics of the panels. Last year, Weyland sued his building’s property management company for imposing what he deemed unreasonable requirements to install a system, including a formal inspection of the building’s electrical system. A court sided with him in October 2023, but similar cases pop up regularly.&lt;/p&gt;
    &lt;p&gt;Weyland hopes that as more people adopt balcony solar, that will soon change. Already, people in his life regularly ask him about his panels, and two friends are buying systems of their own.&lt;/p&gt;
    &lt;p&gt;“So many people talk to me in our neighborhood and ask about the system when they see it,” Weyland said. “It’s kind of like a snowball that gets bigger and bigger.”&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://grist.org/buildings/how-germany-outfitted-half-a-million-balconies-with-solar-panels/"/><published>2025-10-05T22:18:31+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45486306</id><title>Rule-Based Expert Systems: The Mycin Experiments (1984)</title><updated>2025-10-06T11:32:32.649893+00:00</updated><content>&lt;doc fingerprint="f3a54915433b8ca0"&gt;
  &lt;main&gt;
    &lt;cell&gt;
      &lt;head rend="h1"&gt;Rule-Based Expert Systems:&lt;lb/&gt;The MYCIN Experiments of the Stanford Heuristic Programming Project&lt;/head&gt;
      &lt;head rend="h2"&gt;Edited by Bruce G. Buchanan and Edward H. Shortliffe&lt;/head&gt;
      &lt;p&gt;754 pp., references, index, illus. electronic text&lt;lb/&gt; Addison Wesley, Reading, MA, 1984&lt;lb/&gt; Out of print. All chapters are freely available below.&lt;/p&gt;
      &lt;p&gt;Artificial intelligence, or AI, is largely an experimental science—at least as much progress has been made by building and analyzing programs as by examining theoretical questions. MYCIN is one of several well-known programs that embody some intelligence and provide data on the extent to which intelligent behavior can be programmed. As with other AI programs, its development was slow and not always in a forward direction. But we feel we learned some useful lessons in the course of nearly a decade of work on MYCIN and related programs. In this book we share the results of many experiments performed in that time, and we try to paint a coherent picture of the work. The book is intended to be a critical analysis of several pieces of related research, performed by a large number of scientists. We believe that the whole field of AI will benefit from such attempts to take a detailed retrospective look at experiments, for in this way the scientific foundations of the field will gradually be defined. It is for all these reasons that we have prepared this analysis of the MYCIN experiments.&lt;/p&gt;
      &lt;p&gt;Contributors&lt;/p&gt;
      &lt;p&gt;Foreword&lt;lb/&gt; Allen Newell&lt;/p&gt;
      &lt;p&gt;Preface&lt;/p&gt;
      &lt;head rend="h3"&gt;Part One: Background&lt;/head&gt;
      &lt;p&gt;Chapter 1—The Context of the MYCIN Experiments&lt;/p&gt;
      &lt;p&gt;Chapter 2—The Origin of Rule-Based Systems in AI&lt;lb/&gt; Randall Davis and Jonathan J. King&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Two: Using Rules&lt;/head&gt;
      &lt;p&gt;Chapter 3—The Evolution of MYCIN’s Rule Form&lt;/p&gt;
      &lt;p&gt;Chapter 4—The Structure of the MYCIN System&lt;lb/&gt; William van Melle&lt;/p&gt;
      &lt;p&gt;Chapter 5—Details of the Consultation System&lt;lb/&gt; Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 6—Details of the Revised Therapy Algorithm&lt;lb/&gt; William J. Clancey&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Three: Building a Knowledge Base&lt;/head&gt;
      &lt;p&gt;Chapter 7—Knowledge Engineering&lt;/p&gt;
      &lt;p&gt;Chapter 8—Completeness and Consistency in a Rule-Based System&lt;lb/&gt; Motoi Suwa, A. Carlisle Scott, and Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 9—Interactive Transfer of Expertise&lt;lb/&gt; Randall Davis&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Four: Reasoning Under Uncertainty&lt;/head&gt;
      &lt;p&gt;Chapter 10—Uncertainty and Evidential Support&lt;/p&gt;
      &lt;p&gt;Chapter 11—A Model of Inexact Reasoning in Medicine&lt;lb/&gt; Edward H. Shortliffe and Bruce G. Buchanan&lt;/p&gt;
      &lt;p&gt;Chapter 12—Probabilistic Reasoning and Certainty Factors&lt;lb/&gt; J. Barclay Adams&lt;/p&gt;
      &lt;p&gt;Chapter 13—The Dempster-Shafer Theory of Evidence&lt;lb/&gt; Jean Gordon and Edward H. Shortliffe&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Five: Generalizing MYCIN&lt;/head&gt;
      &lt;p&gt;Chapter 14—Use of the MYCIN Inference Engine&lt;/p&gt;
      &lt;p&gt;Chapter 15—EMYCIN: A Knowledge Engineer’s Tool for Constructing Rule-Based Expert Systems&lt;lb/&gt; William van Melle, Edward H. Shortliffe, and Bruce G. Buchanan&lt;/p&gt;
      &lt;p&gt;Chapter 16—Experience Using EMYCIN&lt;lb/&gt; James S. Bennett and Robert S. Engelmore&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Six: Explaining the Reasoning&lt;/head&gt;
      &lt;p&gt;Chapter 17—Explanation as a Topic of AI Research&lt;/p&gt;
      &lt;p&gt;Chapter 18—Methods for Generating Explanations&lt;lb/&gt; A. Carlisle Scott, William J. Clancey, Randall Davis, and Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 19—Specialized Explanations for Dosage Selection&lt;lb/&gt; Sharon Wraith Bennett and A. Carlisle Scott&lt;/p&gt;
      &lt;p&gt;Chapter 20—Customized Explanations Using Causal Knowledge&lt;lb/&gt; Jerold W. Wallis and Edward H. Shortliffe&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Seven: Using Other Representations&lt;/head&gt;
      &lt;p&gt;Chapter 21—Other Representation Frameworks&lt;/p&gt;
      &lt;p&gt;Chapter 22—Extensions to the Rule-Based Formalism for a Monitoring Task&lt;lb/&gt; Lawrence M. Fagan, John C. Kunz, Edward A. Feigenbaum, and John J. Osborn&lt;/p&gt;
      &lt;p&gt;Chapter 23—A Representation Scheme Using Both Frames and Rules&lt;lb/&gt; Janice S. Aikins&lt;/p&gt;
      &lt;p&gt;Chapter 24—Another Look at Frames&lt;lb/&gt; David E. Smith and Jan E. Clayton&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Eight: Tutoring&lt;/head&gt;
      &lt;p&gt;Chapter 25—Intelligent Computer-Aided Instruction&lt;/p&gt;
      &lt;p&gt;Chapter 26—Use of MYCIN’s Rules for Tutoring&lt;lb/&gt; William J. Clancey&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Nine: Augmenting the Rules&lt;/head&gt;
      &lt;p&gt;Chapter 27—Additional Knowledge Structures&lt;/p&gt;
      &lt;p&gt;Chapter 28—Meta-Level Knowledge&lt;lb/&gt; Randall Davis and Bruce G. Buchanan&lt;/p&gt;
      &lt;p&gt;Chapter 29—Extensions to Rules for Explanation and Tutoring&lt;lb/&gt; William J. Clancey&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Ten: Evaluating Performance&lt;/head&gt;
      &lt;p&gt;Chapter 30—The Problem of Evaluation&lt;/p&gt;
      &lt;p&gt;Chapter 31—An Evaluation of MYCIN’s Advice&lt;lb/&gt; Victor L. Yu, Lawrence M. Fagan, Sharon Wraith Bennett, William J . Clancey, A. Carlisle Scott, John F. Hannigan, Robert L. Blum, Bruce G. Buchanan, and Stanley N. Cohen&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Eleven: Designing for Human Use&lt;/head&gt;
      &lt;p&gt;Chapter 32—Human Engineering of Medical Expert Systems&lt;/p&gt;
      &lt;p&gt;Chapter 33—Strategies for Understanding Structured English&lt;lb/&gt; Alain Bonnet&lt;/p&gt;
      &lt;p&gt;Chapter 34—An Analysis of Physicians’ Attitudes&lt;lb/&gt; Randy L. Teach and Edward H. Shortliffe&lt;/p&gt;
      &lt;p&gt;Chapter 35—An Expert System for Oncology Protocol Management&lt;lb/&gt; Edward H. Shortliffe, A. Carlisle Scott, Miriam B. Bischoff, A. Bruce Campbell, William van MeUe, and Charlotte D. Jacobs&lt;/p&gt;
      &lt;head rend="h3"&gt;Part Twelve: Conclusions&lt;/head&gt;
      &lt;p&gt;Chapter 36—Major Lessons from This Work&lt;/p&gt;
      &lt;p&gt;Epilog&lt;/p&gt;
      &lt;p&gt;Appendix&lt;/p&gt;
      &lt;p&gt;References&lt;/p&gt;
      &lt;p&gt;Name Index&lt;/p&gt;
      &lt;p&gt;Subject Index&lt;/p&gt;
    &lt;/cell&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.shortliffe.net/Buchanan-Shortliffe-1984/MYCIN%20Book.htm"/><published>2025-10-05T23:51:47+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45487044</id><title>Why do LLMs freak out over the seahorse emoji?</title><updated>2025-10-06T11:32:32.447479+00:00</updated><content>&lt;doc fingerprint="2d678256c88d5a34"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Why do LLMs freak out over the seahorse emoji?&lt;/head&gt;
    &lt;p&gt;This is an edited and expanded version of a Twitter post, originally in response to @arm1st1ce, that can be found here: https://x.com/voooooogel/status/1964465679647887838&lt;/p&gt;
    &lt;p&gt;Is there a seahorse emoji? Let's ask GPT-5 Instant:&lt;/p&gt;
    &lt;p&gt;Wtf? Let's ask Claude Sonnet 4.5 instead:&lt;/p&gt;
    &lt;p&gt;What's going on here? Maybe Gemini 2.5 Pro handles it better?&lt;/p&gt;
    &lt;p&gt;OK, something is going on here. Let's find out why.&lt;/p&gt;
    &lt;head rend="h2"&gt;LLMs really think there's a seahorse emoji&lt;/head&gt;
    &lt;p&gt;Here are the answers you get if you ask several models whether a seahorse emoji exists, yes or no, 100 times:&lt;/p&gt;
    &lt;quote&gt;
      &lt;p&gt;Is there a seahorse emoji, yes or no? Respond with one word, no punctuation.&lt;/p&gt;
    &lt;/quote&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;gpt-5-chat &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;gpt-5 &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;claude-4.5-sonnet &lt;list rend="ul"&gt;&lt;item&gt;100% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
      &lt;item&gt;llama-3.3-70b &lt;list rend="ul"&gt;&lt;item&gt;83% 'yes'&lt;/item&gt;&lt;item&gt;17% 'Yes'&lt;/item&gt;&lt;/list&gt;&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Needlessly to say, popular language models are very confident that there's a seahorse emoji. And they're not alone in that confidence - here's a Reddit thread with hundreds of comments from people who distinctly remember a seahorse emoji existing:&lt;/p&gt;
    &lt;p&gt;There's tons of this - Google "seahorse emoji" and you'll find TikToks, Youtube videos, and even (now defunct) memecoins based around the supposed vanishing of a seahorse emoji that everyone is pretty sure used to exist - but of course, never did.&lt;/p&gt;
    &lt;p&gt;Maybe LLMs believe a seahorse emoji exists because so many humans in the training data do. Or maybe it's a convergent belief - given how many other aquatic animals are in Unicode, it's reasonable for both humans and LLMs to assume (generalize, even) that such a delightful animal is as well. A seahorse emoji was even formally proposed at one point, but was rejected in 2018.&lt;/p&gt;
    &lt;p&gt;Regardless of the root cause, many LLMs begin each new context window fresh with the mistaken latent belief that the seahorse emoji exists. But why does that produce such strange behavior? I mean, I used to believe a seahorse emoji existed myself, but if I had tried to send it to a friend, I would've simply looked for it on my keyboard and realized it wasn't there, not sent the wrong emoji and then gone into an emoji spam doomloop. So what's happening inside the LLM that causes it to act like this?&lt;/p&gt;
    &lt;head rend="h2"&gt;Using the logit lens&lt;/head&gt;
    &lt;p&gt;Let's look into this using everyone's favorite underrated interpretability tool, the logit lens!&lt;/p&gt;
    &lt;p&gt;Using this prompt prefix - a templated chat with the default llama-3.3-70b system prompt, a question about the seahorse emoji, and a partial answer from the model right before it gives the actual emoji:&lt;/p&gt;
    &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id&amp;gt;
Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;

Is there a seahorse emoji?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;

Yes, there is a seahorse emoji:
&lt;/code&gt;
    &lt;p&gt;We can take the model's &lt;code&gt;lm_head&lt;/code&gt;, which is usually only used on the output of the last layer, and apply it to every layer to produce intermediate token predictions. That process produces this table, showing for every fourth layer what the most likely token would be for the next three positions after the prefix (tokens 0, 1, and 2), and what the top 5 most likely predictions for the first position is (token 0 topk 5):&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83244'ĠBail'&lt;/cell&gt;
        &lt;cell&gt;15591'ĠHarr'&lt;/cell&gt;
        &lt;cell&gt;5309'Ġvert'&lt;/cell&gt;
        &lt;cell&gt;Bail Harr vert&lt;/cell&gt;
        &lt;cell&gt;['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;4&lt;/cell&gt;
        &lt;cell&gt;111484'emez'&lt;/cell&gt;
        &lt;cell&gt;26140'abi'&lt;/cell&gt;
        &lt;cell&gt;25727'avery'&lt;/cell&gt;
        &lt;cell&gt;emezabiavery&lt;/cell&gt;
        &lt;cell&gt;['emez', 'Ġunm', 'ĠOswald', 'Ġrem', 'rix']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;122029'chyb'&lt;/cell&gt;
        &lt;cell&gt;44465'ĠCaps'&lt;/cell&gt;
        &lt;cell&gt;15610'iller'&lt;/cell&gt;
        &lt;cell&gt;chyb Capsiller&lt;/cell&gt;
        &lt;cell&gt;['chyb', 'ĠSund', 'ØªØ±ÛĮ', 'resse', 'Ġsod']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;12&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;48952'ĠCliff'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;... Cliff Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', 'ages', 'dump', 'qing', 'Ġexp']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12676'365'&lt;/cell&gt;
        &lt;cell&gt;31447'ĠAld'&lt;/cell&gt;
        &lt;cell&gt;...365 Ald&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Ġindeed', 'Ġboth', 'ĠYes']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;20&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;109596'éļĨ'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;...隆 Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Z', 'Ġboth', 'ĠHust']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;287'ing'&lt;/cell&gt;
        &lt;cell&gt;-️ing&lt;/cell&gt;
        &lt;cell&gt;['-', '...', 'âĢ¦', '...Ċ', 'em']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;28&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;... Gaut Jackie&lt;/cell&gt;
        &lt;cell&gt;['...', '-', '...Ċ', '-Ċ', 'Ġ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;6892'Ġing'&lt;/cell&gt;
        &lt;cell&gt;... Gaut ing&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'O', 'zer']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;36&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;...-y&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'Ġ', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;...️y&lt;/cell&gt;
        &lt;cell&gt;['...', 'u', 'âĢ¦', 'Âł', '...Ċ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;44&lt;/cell&gt;
        &lt;cell&gt;80435'ĠScor'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;Scor horse horse&lt;/cell&gt;
        &lt;cell&gt;['ĠScor', 'u', 'ĠPan', 'in', 'Ġhttps']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Âł', 'ĠPan', 'ĠHomes', 'ĠHorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;52&lt;/cell&gt;
        &lt;cell&gt;9581'Ġsea'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;sea horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġsea', 'Ġhorse', 'ĠHorse', 'ĠSea', 'âĢĳ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;9581'Ġsea'&lt;/cell&gt;
        &lt;cell&gt;43269'ĠSeah'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;sea Seah horse&lt;/cell&gt;
        &lt;cell&gt;['Ġsea', 'ĠSea', 'ĠSeah', 'Ġhippoc', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;60&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Ġsea', 'ĠSeah', 'Ġse', 'horse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse horse horse&lt;/cell&gt;
        &lt;cell&gt;['Ġhorse', 'Ġse', 'ĠHorse', 'horse', 'Ġhors']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;68&lt;/cell&gt;
        &lt;cell&gt;60775'horse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;15580'Ġhorse'&lt;/cell&gt;
        &lt;cell&gt;horse� horse&lt;/cell&gt;
        &lt;cell&gt;['horse', 'Ġse', 'Ġhorse', 'Ġhippoc', 'ĠSeah']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;76&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'hip', 'Ġhorse', 'ĠHipp']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;11410'ĠðŁ'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;254'ł'&lt;/cell&gt;
        &lt;cell&gt;🐠&lt;/cell&gt;
        &lt;cell&gt;['ĠðŁ', 'ðŁ', 'ĠðŁĴ', 'Ġ', 'ĠðŁĳ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;This is the logit lens: using the model's &lt;code&gt;lm_head&lt;/code&gt; to produce logits (token likelihoods) as a way to investigate its internal states. Note that the tokens and likelihoods we get from the logit lens here are not equivalent to the model's full internal states! For that, we would need a more complex technique like representation reading or sparse autoencoders. Instead, this is a lens on that state - it shows what the output token would be if this layer were the last one. But despite this limitation, the logit lens is still useful. The states of early layers may be difficult to interpret using it, but as we move up through the stack we can see that the model is iteratively refining those states towards its final prediction, a fish emoji.&lt;/p&gt;
    &lt;p&gt;(Why do the unmerged tokens look like that 'ĠðŁ', 'Ĳ', 'ł' nonsense? It's because of a tokenizer quirk - those tokens encode the UTF-8 bytes for the fish emoji. It's not relevant to this post, but if you're curious, ask Claude or your favorite LLM to explain this paragraph and this line of code: &lt;code&gt;bytes([bpe_byte_decoder[c] for c in 'ĠðŁĲł']).decode('utf-8') == ' 🐠'&lt;/code&gt;)&lt;/p&gt;
    &lt;p&gt;Take a look at what happens in the middle layers, though - it's not the early-layer weirdness or the emoji bytes of the final prediction! Instead we get words relating to useful concepts, specifically the concept of a seahorse. For example, on layer 52, we get "sea horse horse" - three residual positions in a row encoding the "seahorse" concept. Later, in the top-k for the first position, we get a mixture of "sea", "horse", and an emoji byte sequence prefix, "ĠðŁ".&lt;/p&gt;
    &lt;p&gt;So what is the model thinking about? "seahorse + emoji"! It's trying to construct a residual representation of a seahorse combined with an emoji. Why would the model try to construct this combination? Well, let's look into how the &lt;code&gt;lm_head&lt;/code&gt; actually works.&lt;/p&gt;
    &lt;head rend="h2"&gt;
      &lt;code&gt;lm_head&lt;/code&gt;
    &lt;/head&gt;
    &lt;p&gt;A language model's &lt;code&gt;lm_head&lt;/code&gt; is a huge matrix of residual-sized vectors associated with token ids, one for every token in the vocabulary (~300,000). When a residual is passed into it, either after flowing through the model normally or early because someone is using the logit lens on an earlier layer, the &lt;code&gt;lm_head&lt;/code&gt; is going to compare that input residual with each residual-sized vector in that big matrix, and (in coordination with the sampler) select the token id associated with the vector that matrix contains that is most similar to the input residual.&lt;/p&gt;
    &lt;p&gt;(More technically: &lt;code&gt;lm_head&lt;/code&gt; is a linear layer without a bias, so &lt;code&gt;x @ w.T&lt;/code&gt; does dot products with each unembedding vector to produce raw scores. Then your usual log_softmax and argmax/temperature sample.)&lt;/p&gt;
    &lt;p&gt;That means if the model wants to output the word "hello", for example in response to a friendly greeting from the user, it needs to construct a residual as similar as possible to the vector for the "hello" token that the &lt;code&gt;lm_head&lt;/code&gt; can then turn into the hello token id. And using logit lens, we can see that's exactly what happens in response to "Hello :-)":&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;40952'opa'&lt;/cell&gt;
        &lt;cell&gt;!!opa&lt;/cell&gt;
        &lt;cell&gt;['"', '!', '#', '%', '$']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;121495'ÅĻiv'&lt;/cell&gt;
        &lt;cell&gt;16'1'&lt;/cell&gt;
        &lt;cell&gt;73078'iae'&lt;/cell&gt;
        &lt;cell&gt;řiv1iae&lt;/cell&gt;
        &lt;cell&gt;['ÅĻiv', '-', '(', '.', ',']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;34935'Ġconsect'&lt;/cell&gt;
        &lt;cell&gt;7341'arks'&lt;/cell&gt;
        &lt;cell&gt;13118'Ġindeed'&lt;/cell&gt;
        &lt;cell&gt;consectarks indeed&lt;/cell&gt;
        &lt;cell&gt;['Ġobscure', 'Ġconsect', 'äºķ', 'ĠÐ¿ÑĢÐ¾ÑĦÐµÑģÑģÐ¸Ð¾Ð½Ð°Ð»ÑĮ', 'Îŀ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;67846'&amp;lt;['&lt;/cell&gt;
        &lt;cell&gt;24748'Ġhello'&lt;/cell&gt;
        &lt;cell&gt;15960'Ġhi'&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;[ hello hi&lt;/cell&gt;
        &lt;cell&gt;['&amp;lt;[', 'arks', 'outh', 'ĠHam', 'la']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;15825'-back'&lt;/cell&gt;
        &lt;cell&gt;2312'ln'&lt;/cell&gt;
        &lt;cell&gt;14451'UBL'&lt;/cell&gt;
        &lt;cell&gt;-backlnUBL&lt;/cell&gt;
        &lt;cell&gt;['ÂŃi', '-back', 'Ġquestion', 'ln', 'ant']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;15648'Ġsmile'&lt;/cell&gt;
        &lt;cell&gt;14262'Welcome'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;smileWelcome back&lt;/cell&gt;
        &lt;cell&gt;['Ġsmile', 'ĠÑĥÐ»ÑĭÐ±', 'Ġsmiled', 'ĠSmile', 'etwork']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;15648'Ġsmile'&lt;/cell&gt;
        &lt;cell&gt;21694'ĠHi'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;smile Hi back&lt;/cell&gt;
        &lt;cell&gt;['Ġsmile', 'Ġsmiled', 'ĠHello', 'Ġsmiling', 'Ġhello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;15960'Ġhi'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;Hello hi back&lt;/cell&gt;
        &lt;cell&gt;['ĠHello', 'Ġhi', 'Ġsmile', 'Ġhello', 'Hello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;4773'-sm'&lt;/cell&gt;
        &lt;cell&gt;24748'Ġhello'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;-sm hello back&lt;/cell&gt;
        &lt;cell&gt;['-sm', 'ĠHello', 'ĠSm', 'sm', 'Hello']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;22691'ĠHello'&lt;/cell&gt;
        &lt;cell&gt;1203'Ġback'&lt;/cell&gt;
        &lt;cell&gt;Hello Hello back&lt;/cell&gt;
        &lt;cell&gt;['ĠHello', 'Ġhello', 'Hello', 'ĠHEL', 'Ġhel']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;271'ĊĊ'&lt;/cell&gt;
        &lt;cell&gt;9906'Hello'&lt;/cell&gt;
        &lt;cell&gt;0'!'&lt;/cell&gt;
        &lt;cell&gt;
          &lt;p&gt;Hello!&lt;/p&gt;
        &lt;/cell&gt;
        &lt;cell&gt;['ĊĊ', 'ĊĊĊ', '&amp;lt;|end_of_text|&amp;gt;', 'ĊĊĊĊ', '"ĊĊ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;('Ċ' is another tokenizer quirk - it represents a line break. 'Ġ' is similarly a space.)&lt;/p&gt;
    &lt;p&gt;Likewise, if the model wants to output a seahorse emoji, it needs to construct a residual similar to the vector for the seahorse emoji output token(s) - which in theory could be any arbitrary value, but in practice is "seahorse + emoji", word2vec style. We can see this in action with a real emoji, the fish emoji:&lt;/p&gt;
    &lt;code&gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|begin_of_text|&amp;gt;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt;

Cutting Knowledge Date: December 2023
Today Date: 26 Jul 2024

&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;

Is there a fish emoji?&amp;lt;|eot_id|&amp;gt;&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;

Yes, there is a fish emoji:
&lt;/code&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;83244'ĠBail'&lt;/cell&gt;
        &lt;cell&gt;15591'ĠHarr'&lt;/cell&gt;
        &lt;cell&gt;5309'Ġvert'&lt;/cell&gt;
        &lt;cell&gt;Bail Harr vert&lt;/cell&gt;
        &lt;cell&gt;['ĠBail', 'ĠPeanut', 'ĠãĢ', 'orr', 'ĠâĢĭâĢĭ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;8&lt;/cell&gt;
        &lt;cell&gt;122029'chyb'&lt;/cell&gt;
        &lt;cell&gt;44465'ĠCaps'&lt;/cell&gt;
        &lt;cell&gt;15610'iller'&lt;/cell&gt;
        &lt;cell&gt;chyb Capsiller&lt;/cell&gt;
        &lt;cell&gt;['chyb', '...', 'ØªØ±ÛĮ', 'ĠSund', 'resse']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;16&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;12676'365'&lt;/cell&gt;
        &lt;cell&gt;65615'ĠSole'&lt;/cell&gt;
        &lt;cell&gt;...365 Sole&lt;/cell&gt;
        &lt;cell&gt;['...', '...Ċ', 'Ġboth', 'Ġindeed', 'ĠYes']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;24&lt;/cell&gt;
        &lt;cell&gt;12'-'&lt;/cell&gt;
        &lt;cell&gt;31643'ï¸ı'&lt;/cell&gt;
        &lt;cell&gt;51965'ĠJackie'&lt;/cell&gt;
        &lt;cell&gt;-️ Jackie&lt;/cell&gt;
        &lt;cell&gt;['-', '...', 'âĢ¦', 'em', '...Ċ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;32&lt;/cell&gt;
        &lt;cell&gt;1131'...'&lt;/cell&gt;
        &lt;cell&gt;96154'ĠGaut'&lt;/cell&gt;
        &lt;cell&gt;88'y'&lt;/cell&gt;
        &lt;cell&gt;... Gauty&lt;/cell&gt;
        &lt;cell&gt;['...', 'âĢ¦', '...Ċ', 'O', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;40&lt;/cell&gt;
        &lt;cell&gt;220'Ġ'&lt;/cell&gt;
        &lt;cell&gt;6"'"&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;'fish&lt;/cell&gt;
        &lt;cell&gt;['Ġ', '...', 'âĢ¦', 'Âł', 'u']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;48&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish fish fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠBerk', 'âĢ¦', 'Âł']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;56&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish fish fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'fish', 'Fish', 'é±¼']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;64&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;fish� fish&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠPis', 'Fish', 'ĠÙħØ§Ùĩ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;7795'Ġfish'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;253'Ł'&lt;/cell&gt;
        &lt;cell&gt;fish��&lt;/cell&gt;
        &lt;cell&gt;['Ġfish', 'ĠFish', 'ĠðŁ', 'Ġ', 'ÂŁ']&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;80&lt;/cell&gt;
        &lt;cell&gt;11410'ĠðŁ'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;253'Ł'&lt;/cell&gt;
        &lt;cell&gt;🐟&lt;/cell&gt;
        &lt;cell&gt;['ĠðŁ', 'ðŁ', 'Ġ', 'ĠĊĊ', 'ĠâĻ']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;Here, everything works perfectly. The model constructs the "fish + emoji" residual - look at the layer 72 topk, where we have both "fish" and the emoji byte prefix "ĠðŁ" - meaning that the residual at this point is similar to both "fish" and "emoji", just like we'd expect. Then when this vector is passed into the &lt;code&gt;lm_head&lt;/code&gt; after the final layer, we see a 🐟 just as the model expected.&lt;/p&gt;
    &lt;p&gt;But unlike with 🐟, the seahorse emoji doesn't exist. The model tries to construct a "seahorse + emoji" vector just as it would for a real emoji, and on layer 72 we even get a very similar construction as with the fish emoji - " se", "horse", and the emoji prefix byte prefix:&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="6"&gt;
        &lt;cell role="head"&gt;layer&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;tokens&lt;/cell&gt;
        &lt;cell role="head"&gt;token 0&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="6"&gt;
        &lt;cell&gt;0&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
        &lt;cell&gt;merged&lt;/cell&gt;
        &lt;cell&gt;(topk 5)&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;72&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;238'Ĳ'&lt;/cell&gt;
        &lt;cell&gt;513'Ġse'&lt;/cell&gt;
        &lt;cell&gt;se� se&lt;/cell&gt;
        &lt;cell&gt;['Ġse', 'Ġhippoc', 'horse', 'ĠðŁ', 'Ġhorse']&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;But alas, there's no continuation to ĠðŁ corresponding to a seahorse, so the &lt;code&gt;lm_head&lt;/code&gt; similarity score calculation maxes out with horse- or sea-animal-related emoji bytes instead, and an unintended emoji is sampled.&lt;/p&gt;
    &lt;p&gt;Now, that sampling is valuable information for the model! You can see that in, e.g. the Claude 4.5 Sonnet example below, when the tokens get appended into the context autoregressively, the model can tell that they don't form the intended seahorse emoji. The previous, fuzzy "seahorse + emoji" concept has been "snapped" by the &lt;code&gt;lm_head&lt;/code&gt; to an emoji that actually exists, like a tropical fish or horse.&lt;/p&gt;
    &lt;p&gt;Once this happens, it's up to the model how to proceed. Some models like 4.5 Sonnet try again, and eventually update on the evidence, changing mid-response to a statement about how the seahorse emoji doesn't exist. Other models like gpt-5-chat spiral for longer, sometimes never recovering. Other models will either blissfully ignore that the emoji is incorrect, and some will even correct themselves instantly after seeing only a single incorrect sample.&lt;/p&gt;
    &lt;p&gt;But until the model gets the wrong output token from &lt;code&gt;lm_head&lt;/code&gt;, it just doesn't know that its initial belief about a seahorse emoji existing was wrong. It can only assume that "seahorse + emoji" will produce the tokens it wants.&lt;/p&gt;
    &lt;head rend="h2"&gt;Some speculation&lt;/head&gt;
    &lt;p&gt;To speculate a bit more, I wonder if this problem is part of the benefit of reinforcement learning for LLMs - it gives the model information about its &lt;code&gt;lm_head&lt;/code&gt; that's otherwise difficult for it to get at because it's at the end of the layer stack.&lt;/p&gt;
    &lt;p&gt;(Remember that base models are not trained on their own outputs / rollouts. That only happens in RL.)&lt;/p&gt;
    &lt;head rend="h2"&gt;Code&lt;/head&gt;
    &lt;p&gt;If you want to try this yourself, you can find a starter script on Github here: https://gist.github.com/vgel/025ad6af9ac7f3bc194966b03ea68606&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://vgel.me/posts/seahorse/"/><published>2025-10-06T02:20:05+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45487452</id><title>Find Nearby Automated License Plate Readers (ALPR)</title><updated>2025-10-06T11:32:32.364090+00:00</updated><content/><link href="https://deflock.me/"/><published>2025-10-06T03:42:15+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45487476</id><title>1 Trillion Web Pages Archived</title><updated>2025-10-06T11:32:31.203738+00:00</updated><content>&lt;doc fingerprint="1a1cb085e3f4f429"&gt;
  &lt;main&gt;
    &lt;head rend="h3"&gt;This October, the Internet Archive will celebrate an extraordinary milestone: 1 trillion web pages preserved and available for access via the Wayback Machine.&lt;/head&gt;
    &lt;p&gt;Calendar of Events | Impact Stories | Support the Internet Archive | Press Kit&lt;/p&gt;
    &lt;p&gt;Since 1996, the Internet Archive has worked with libraries and partners around the world to build a shared digital library of humanity’s online history: capturing websites large and small—from breaking news to forgotten personal pages—so they remain accessible for future generations.&lt;/p&gt;
    &lt;p&gt;The series of events scheduled throughout October will highlight the memories, makers, and movements that have made this achievement possible, and will look ahead to the future of web preservation as we continue building the web’s collective memory together.&lt;/p&gt;
    &lt;head rend="h1"&gt;Calendar of Events&lt;/head&gt;
    &lt;head rend="h2"&gt;October 7—The Vast Blue We: Del Sol Quartet at the Internet Archive&lt;/head&gt;
    &lt;p&gt;7:00-8:15pm PT&lt;lb/&gt;Internet Archive&lt;lb/&gt;300 Funston Avenue, San Francisco &amp;amp; ONLINE&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;An evening to celebrate human collaboration—how billions of individual actions weave together into something vast and beautiful. Through music of Del Sol Quartet with new works by Erika Oba and Sam Reider, we mark the staggering scale of one trillion archived web pages available via the Wayback Machine. Join us for an interactive evening of live music reflecting the wonder of what we can achieve together and the power of our own voices.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 9—A Conversation with Sir Tim Berners-Lee and Brewster Kahle&lt;/head&gt;
    &lt;p&gt;Building and Preserving the Web: A Conversation with Sir Tim Berners-Lee and Brewster Kahle&lt;lb/&gt;7:30pm PT&lt;lb/&gt;The Commonwealth Club of California&lt;lb/&gt;110 The Embarcadero, San Francisco &amp;amp; ONLINE&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;Sir Tim Berners-Lee and Brewster Kahle will be in conversation about the rise of the internet, its continuing and explosive impact on society, the importance of the Internet Archive and other developing issues in the growth and use of the internet.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 16—Library Leaders Forum 2025 (VIRTUAL)&lt;/head&gt;
    &lt;p&gt;10:00-11:30am PT&lt;lb/&gt;ONLINE&lt;lb/&gt;Register now for VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;In our virtual Library Leaders Forum, you’ll hear from Internet Archive staff and partners about our emerging library services and updates on existing efforts. How do libraries empower research in the 21st century? Join in our discussion!&lt;/p&gt;
    &lt;head rend="h2"&gt;October 21—Doors Open 2025: Go Behind the Scenes at the Physical Archive&lt;/head&gt;
    &lt;p&gt;6:00-8:00pm PT&lt;lb/&gt;Richmond, California&lt;lb/&gt;Register now for IN-PERSON tickets&lt;/p&gt;
    &lt;p&gt;The Internet Archive is excited to offer a behind-the-scenes tour of the physical collections of books, music, film, and video in Richmond, California.&lt;/p&gt;
    &lt;p&gt;With this special insider event we are opening the doors to an often unseen place. See the lifecycle of physical materials: donation, preservation, digitization, and access. Also, samples from generous donations and acquisitions of books, records, microfiche, and more will be on display.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 22—The Web We’ve Built: Celebrating 1 Trillion Web Pages Archived&lt;/head&gt;
    &lt;p&gt;5:00-10:00pm PT&lt;lb/&gt;7:00-8:00pm PT Live Stream&lt;lb/&gt;Internet Archive&lt;lb/&gt;300 Funston Ave, San Francisco&lt;lb/&gt;Register now for IN-PERSON or VIRTUAL tickets&lt;/p&gt;
    &lt;p&gt;This October, the Internet Archive’s Wayback Machine is projected to hit a once-in-a-generation milestone: 1 trillion web pages archived. That’s one trillion memories, moments, and movements—preserved for the public and available to access via the Wayback Machine.&lt;/p&gt;
    &lt;p&gt;We’ll be commemorating this historic achievement on October 22, 2025, with a global event: a party at our San Francisco headquarters and a livestream for friends and supporters around the world. More than a celebration, it’s a tribute to what we’ve built together: a free and open digital library of the web.&lt;/p&gt;
    &lt;p&gt;Join us in marking this incredible milestone. Together, we’ve built the largest archive of web history ever assembled. Let’s celebrate this achievement—in San Francisco and around the world—on October 22.&lt;/p&gt;
    &lt;head rend="h2"&gt;October 27—Wayback to the Future: Celebrating the Open Web&lt;/head&gt;
    &lt;p&gt;5:00-8:00pm PT&lt;lb/&gt;Riggs Library, Georgetown University&lt;lb/&gt;Healy Hall, Library Walk, Washington, DC 20057&lt;lb/&gt;Register now for IN-PERSON tickets&lt;/p&gt;
    &lt;p&gt;Join the Foundation for American Innovation, the Massive Data Institute and the Internet Archive at Georgetown University’s historic Riggs Library for Wayback to the Future: Celebrating the Open Web—Past, Present, and Possible.&lt;/p&gt;
    &lt;p&gt;The open web was once defined by experimentation, decentralization, and possibility. The technological advancements were driven by the desire for a place where new voices and ideas could flourish. Today, consolidation and walled gardens challenge that vision. Together, we’ll look back at the internet’s origins to spark a forward-looking conversation about how to keep the web free, open, and innovative.&lt;/p&gt;
    &lt;p&gt;Speakers include:&lt;/p&gt;
    &lt;p&gt;Moderator: Luke Hogg — Director of Technology Policy, FAI&lt;lb/&gt;Brewster Kahle — Founder &amp;amp; Director, Internet Archive&lt;lb/&gt;Vint Cerf — Chief Internet Evangelist, Google&lt;lb/&gt;Cindy Cohn — Executive Director, Electronic Frontier Foundation&lt;lb/&gt;Jon Stokes – Co-founder, Ars Technica &lt;/p&gt;
    &lt;head rend="h1"&gt;Impact Stories&lt;/head&gt;
    &lt;p&gt;The 1 trillion archived webpages are more than just numbers—they represent real impact on people’s lives, research, and memory. From immigration cases to personal histories, academic research to investigative journalism, the Wayback Machine has become an essential public resource that preserves the web for all.&lt;/p&gt;
    &lt;p&gt;Canadian musician David Samuel relied on archived concert programs in the Wayback Machine to secure U.S. residency.&lt;/p&gt;
    &lt;p&gt;Paul Lindner built a digital memorial to his late wife by recovering her online presence.&lt;/p&gt;
    &lt;p&gt;Researchers at King’s College London use web archives to track the evolution of fake news and open data.&lt;/p&gt;
    &lt;p&gt;Investigative trainers call the Wayback Machine “a precious tool” for exposing deleted evidence.&lt;/p&gt;
    &lt;head rend="h1"&gt;Share Your Story&lt;/head&gt;
    &lt;p&gt;What does the web mean to you? How has the Wayback Machine helped you remember, research, or recover something important? Share your story.&lt;/p&gt;
    &lt;head rend="h1"&gt;Support the Internet Archive&lt;/head&gt;
    &lt;p&gt;Help us continue preserving the web for generations to come. Donate today!&lt;/p&gt;
    &lt;head rend="h1"&gt;Press Kit&lt;/head&gt;
    &lt;p&gt;Interested in producing a story about the 1 trillion milestone? Our online press kit includes impact stories from users, facts &amp;amp; figures about the Internet Archive &amp;amp; Wayback Machine, and Then/Now screenshots of popular web sites. Contact info is available in the press kit.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://blog.archive.org/trillion/"/><published>2025-10-06T03:48:34+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488261</id><title>Structured Procrastination</title><updated>2025-10-06T11:32:30.797403+00:00</updated><content>&lt;doc fingerprint="161270546c3194f9"&gt;
  &lt;main&gt;
    &lt;p&gt;Author practices jumping rope with seaweed while work awaits.&lt;/p&gt;
    &lt;p&gt;``. . . anyone can do any amount of work, provided it isn't the work he is supposed to be doing at that moment." -- Robert Benchley, in Chips off the Old Benchley, 1949&lt;/p&gt;
    &lt;p&gt;I have been intending to write this essay for months. Why am I finally doing it? Because I finally found some uncommitted time? Wrong. I have papers to grade, textbook orders to fill out, an NSF proposal to referee, dissertation drafts to read. I am working on this essay as a way of not doing all of those things. This is the essence of what I call structured procrastination, an amazing strategy I have discovered that converts procrastinators into effective human beings, respected and admired for all that they can accomplish and the good use they make of time. All procrastinators put off things they have to do. Structured procrastination is the art of making this bad trait work for you. The key idea is that procrastinating does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing; they do marginally useful things, like gardening or sharpening pencils or making a diagram of how they will reorganize their files when they get around to it. Why does the procrastinator do these things? Because they are a way of not doing something more important. If all the procrastinator had left to do was to sharpen some pencils, no force on earth could get him do it. However, the procrastinator can be motivated to do difficult, timely and important tasks, as long as these tasks are a way of not doing something more important.&lt;/p&gt;
    &lt;p&gt;Structured procrastination means shaping the structure of the tasks one has to do in a way that exploits this fact. The list of tasks one has in mind will be ordered by importance. Tasks that seem most urgent and important are on top. But there are also worthwhile tasks to perform lower down on the list. Doing these tasks becomes a way of not doing the things higher up on the list. With this sort of appropriate task structure, the procrastinator becomes a useful citizen. Indeed, the procrastinator can even acquire, as I have, a reputation for getting a lot done.&lt;/p&gt;
    &lt;p&gt;The most perfect situation for structured procrastination that I ever had was when my wife and I served as Resident Fellows in Soto House, a Stanford dormitory. In the evening, faced with papers to grade, lectures to prepare, committee work to be done, I would leave our cottage next to the dorm and go over to the lounge and play ping-pong with the residents, or talk over things with them in their rooms, or just sit there and read the paper. I got a reputation for being a terrific Resident Fellow, and one of the rare profs on campus who spent time with undergraduates and got to know them. What a set up: play ping pong as a way of not doing more important things, and get a reputation as Mr. Chips.&lt;/p&gt;
    &lt;p&gt;Procrastinators often follow exactly the wrong tack. They try to minimize their commitments, assuming that if they have only a few things to do, they will quit procrastinating and get them done. But this goes contrary to the basic nature of the procrastinator and destroys his most important source of motivation. The few tasks on his list will be by definition the most important, and the only way to avoid doing them will be to do nothing. This is a way to become a couch potato, not an effective human being.&lt;/p&gt;
    &lt;p&gt;At this point you may be asking, "How about the important tasks at the top of the list, that one never does?" Admittedly, there is a potential problem here.&lt;/p&gt;
    &lt;p&gt;The trick is to pick the right sorts of projects for the top of the list. The ideal sorts of things have two characteristics, First, they seem to have clear deadlines (but really don't). Second, they seem awfully important (but really aren't). Luckily, life abounds with such tasks. In universities the vast majority of tasks fall into this category, and I'm sure the same is true for most other large institutions. Take for example the item right at the top of my list right now. This is finishing an essay for a volume in the philosophy of language. It was supposed to be done eleven months ago. I have accomplished an enormous number of important things as a way of not working on it. A couple of months ago, bothered by guilt, I wrote a letter to the editor saying how sorry I was to be so late and expressing my good intentions to get to work. Writing the letter was, of course, a way of not working on the article. It turned out that I really wasn't much further behind schedule than anyone else. And how important is this article anyway? Not so important that at some point something that seems more important won't come along. Then I'll get to work on it.&lt;/p&gt;
    &lt;p&gt;Another example is book order forms. I write this in June. In October, I will teach a class on Epistemology. The book order forms are already overdue at the book store. It is easy to take this as an important task with a pressing deadline (for you non-procrastinators, I will observe that deadlines really start to press a week or two after they pass.) I get almost daily reminders from the department secretary, students sometimes ask me what we will be reading, and the unfilled order form sits right in the middle of my desk, right under the wrapping from the sandwich I ate last Wednesday. This task is near the top of my list; it bothers me, and motivates me to do other useful but superficially less important things. But in fact, the book store is plenty busy with forms already filed by non-procrastinators. I can get mine in mid-Summer and things will be fine. I just need to order popular well-known books from efficient publishers. I will accept some other, apparently more important, task sometime between now and, say, August 1st. Then my psyche will feel comfortable about filling out the order forms as a way of not doing this new task.&lt;/p&gt;
    &lt;p&gt;The observant reader may feel at this point that structured procrastination requires a certain amount of self-deception, since one is in effect constantly perpetrating a pyramid scheme on oneself. Exactly. One needs to be able to recognize and commit oneself to tasks with inflated importance and unreal deadlines, while making oneself feel that they are important and urgent. This is not a problem, because virtually all procrastinators have excellent self-deceptive skills also. And what could be more noble than using one character flaw to offset the bad effects of another?&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://structuredprocrastination.com"/><published>2025-10-06T06:35:36+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488441</id><title>Flightcontrol: AWS PaaS</title><updated>2025-10-06T11:32:30.190691+00:00</updated><content>&lt;doc fingerprint="bd1863730f143a8e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Build your dreams&lt;lb/&gt;on AWS, effortlessly&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Flightcontrol is a PaaS that deploys to your AWS account&lt;/item&gt;
      &lt;item&gt;Servers, Lambdas, workers, crons, static sites, databases &amp;amp; Redis&lt;/item&gt;
      &lt;item&gt;We are your devops team with 24/7 emergency support&lt;/item&gt;
      &lt;item&gt;Companies outgrowing other PaaS or homegrown AWS switch to Flightcontrol to regain reliability, security, and scalability at a reasonable cost&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Over $1 million of AWS resources under management&lt;/head&gt;
    &lt;head rend="h2"&gt;The old way&lt;/head&gt;
    &lt;p&gt;"Our AWS setup is consuming too much time &amp;amp; attention"&lt;/p&gt;
    &lt;p&gt;Your team gets bogged down with complex Terraform scripts, manual configuration, and endless CI/CD pipelines. You could hire DevOps engineers, but they are expensive and it's hard to find really good ones. It will do the job, but now your developer productivity suffers as they are dependent on the infra team to make changes or spin up new services.&lt;/p&gt;
    &lt;head rend="h2"&gt;The new way&lt;/head&gt;
    &lt;p&gt;"Flightcontrol gives our team the power to manage bare metal AWS without needing to hire specific talent"&lt;/p&gt;
    &lt;p&gt;Save thousands of dollars and months of time because Flightcontrol significantly reduces DevOps overhead. It empowers your developers ship like crazy without needing AWS or infrastructure expertise. Your developers gain full autonomy while benefiting from AWS's unmatched scalability, reliability, and flexibility.&lt;/p&gt;
    &lt;head rend="h2"&gt;Simple, powerful deployments without worrying about low level AWS config&lt;/head&gt;
    &lt;p&gt;We take the best AWS services, put together a best-in-class setup, and make them super easy to use.&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your AWS account to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Connect your git repository to Flightcontrol&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Define your services (servers, APIs, databases, etc)&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Flightcontrol fully automates infrastructure provisioning, CI/CD, and deployments. All within your own AWS account where you retain full visibility and control&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Flightcontrol simplifies your deployments by providing a user-friendly dashboard designed specifically for developers, not DevOps engineers. Forget the frustration of navigating AWS’s overwhelming and fragmented console. With Flightcontrol, you see your entire infrastructure clearly in one intuitive interface, allowing you to manage deployments, services, and scaling with confidence.&lt;/p&gt;
    &lt;p&gt;Deployments become as easy as a simple git push or webhook integration. Flightcontrol handles your CI/CD automation entirely, enabling your team to deploy confidently and quickly without maintaining complex Terraform or CDK scripts. You get the simplicity of platforms like Vercel or Heroku, paired with the raw power, near perfect reliability, and immense flexibility of AWS. Your developers can ship faster and stay focused on building great products.&lt;/p&gt;
    &lt;head rend="h2"&gt;Serve all your use-cases from a single platform&lt;/head&gt;
    &lt;p&gt;Static Sites&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;S3&lt;/item&gt;
      &lt;item&gt;Lambda@Edget&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Web &amp;amp; GPU Servers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;CloudFront CDN&lt;/item&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Network Servers&lt;/p&gt;
    &lt;p&gt;UDP &amp;amp; TCP with multiple ports&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Private Servers&lt;/p&gt;
    &lt;p&gt;HTTP, HTTPS, TCP, UDP&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Background Workers&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Job Runner&lt;/p&gt;
    &lt;p&gt;Cron &amp;amp; API triggered jobs&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ECS&lt;/item&gt;
      &lt;item&gt;Fargate or EC2&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Lambda&lt;/p&gt;
    &lt;p&gt;With function url support&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Lambda&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Databases&lt;/p&gt;
    &lt;p&gt;Postgres, MySQL, MariaDB&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;RDS&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Redis&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;ElastiCache&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;S3 Bucket&lt;/p&gt;
    &lt;p&gt;File &amp;amp; object storage&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;S3&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h2"&gt;Significantly reduce your DevOps overhead&lt;/head&gt;
    &lt;p&gt;Flightcontrol becomes your devops team. We guarantee support for everything managed through Flightcontrol. You don't have to worry about anything that's amiss in AWS — let us know and we'll fix it ASAP (but rest assured, this almost never happens!).&lt;/p&gt;
    &lt;p&gt;Get 24/7 emergency support on our Business plan for ultimate peace of mind.&lt;/p&gt;
    &lt;p&gt;Need some extra devops support beyond the Flightcontrol platform? We offer DevOps Support Add-ons to supplement your team. This is ideal for teams that need extra infrastructure help but don't need a full time devops engineer.&lt;/p&gt;
    &lt;head rend="h2"&gt;Ephemeral preview environments&lt;/head&gt;
    &lt;p&gt;The fastest moving engineering teams use preview environments to view changes before committing them.&lt;/p&gt;
    &lt;p&gt;Flightcontrol can automatically spin up temporary infrastructure for each pull request and then clean it up when the pull request is merged.&lt;/p&gt;
    &lt;p&gt;Preview environments mean no more conflicts on staging, no more delays, and significantly fewer bugs in production. Enable all stakeholders to see and test changes before merging code.&lt;/p&gt;
    &lt;p&gt;Each preview environment is cost-optimized, intelligently sharing resources such as load balancers and RDS instances, ensuring you maintain control over spending. Database seeding per environment means realistic testing scenarios, catching issues before they go live. Your team will experience faster releases, fewer bugs, and smoother collaboration.&lt;/p&gt;
    &lt;head rend="h2"&gt;World class support with 6 minute median response time&lt;/head&gt;
    &lt;p&gt;Imagine never worrying about infrastructure issues again. Flightcontrol becomes your DevOps team, providing exceptional, responsive support. With guaranteed smooth operations for everything managed by Flightcontrol, you can rest easy knowing your infrastructure is covered by experts around the clock.&lt;/p&gt;
    &lt;p&gt;With a median first response time of 6 minutes, our dedicated support team is accessible via email and Slack, ensuring rapid resolution whenever you need it. Need some extra DevOps help? Don’t hire full time! Our DevOps support add-on gives you expert guidance tailored specifically to your unique requirements, removing the need to hire a full-time DevOps engineer.&lt;/p&gt;
    &lt;p&gt;Visual Config? Code config? Both!&lt;/p&gt;
    &lt;p&gt;Infrastructure-as-code designed for moving fast&lt;/p&gt;
    &lt;p&gt;Deploy close to your users&lt;/p&gt;
    &lt;p&gt;Choose today from 28 AWS regions. Multi-region deploys in early access.&lt;/p&gt;
    &lt;p&gt;Observability&lt;/p&gt;
    &lt;p&gt;Stay on top of things with our metrics and alerts, or add sidecars like Datadog.&lt;/p&gt;
    &lt;p&gt;Nixpacks&lt;/p&gt;
    &lt;p&gt;Build any language or framework without writing a Dockerfile. The modern successor to Heroku buildpacks.&lt;/p&gt;
    &lt;p&gt;Stale while revalidate + Next.js &amp;amp; Svelte ISR&lt;/p&gt;
    &lt;p&gt;Blazing fast speed with CloudFront's stale-while-revalidate support&lt;/p&gt;
    &lt;p&gt;AWS cost transparency&lt;/p&gt;
    &lt;p&gt;Understand exactly where the dollars are going by project, environment, and service.&lt;/p&gt;
    &lt;p&gt;Preview environments, fullstack&lt;/p&gt;
    &lt;p&gt;Deploy your all your services for every pull request to a cost optimized environment.&lt;/p&gt;
    &lt;p&gt;Bring your monoliths and your microservices&lt;/p&gt;
    &lt;p&gt;Your architecture will work with us, no matter how big or small.&lt;/p&gt;
    &lt;p&gt;Your domain, with https&lt;/p&gt;
    &lt;p&gt;Connect your domain with a couple DNS records. No messing with SSL certificates.&lt;/p&gt;
    &lt;p&gt;Peak edge performance&lt;/p&gt;
    &lt;p&gt;World-class performance with CloudFront, Stale-While-Revalidate, and edge-based Next.js ISR. Even multi-region.&lt;/p&gt;
    &lt;p&gt;Monorepos, with watch paths&lt;/p&gt;
    &lt;p&gt;Put all your stuff in one place, that's fine with us. And only deploy changed files with watch paths.&lt;/p&gt;
    &lt;p&gt;Maintenance mode&lt;/p&gt;
    &lt;p&gt;Block traffic to your app while you're doing something important (we assume).&lt;/p&gt;
    &lt;p&gt;API &amp;amp; deploy hooks&lt;/p&gt;
    &lt;p&gt;Trigger deploys from CI. More thorough API is coming, we promise.&lt;/p&gt;
    &lt;p&gt;Notifications&lt;/p&gt;
    &lt;p&gt;Get alerted in Slack or email when things go south. Or when they go north.&lt;/p&gt;
    &lt;p&gt;Rollback&lt;/p&gt;
    &lt;p&gt;It happens to the best of us, so we've got your back when the inevitable happens.&lt;/p&gt;
    &lt;p&gt;Private VPC networking&lt;/p&gt;
    &lt;p&gt;Each environment is deployed to a new or existing VPC. Get private services and private databases.&lt;/p&gt;
    &lt;head rend="h2"&gt;Deploy every language globally&lt;/head&gt;
    &lt;p&gt;Every language and framework works beautifully in the Flightcontrol universe. Welcome home.&lt;/p&gt;
    &lt;head rend="h2"&gt;1. Connect your AWS and Git Repo with 1-click&lt;/head&gt;
    &lt;p&gt;Everything is deployed to your AWS account where you have full ownership and control. Without the frustrating limitations of black box PaaS.&lt;/p&gt;
    &lt;head rend="h2"&gt;2. Zero-config or customize to your heart's content&lt;/head&gt;
    &lt;p&gt;It will often "just work", but we also support many customizations like pulling from image registries or fine-tuning autoscaling.&lt;/p&gt;
    &lt;head rend="h2"&gt;3. Automatic deploys with git push or webhook&lt;/head&gt;
    &lt;p&gt;Fully automated infra provisioning, builds and deploys. All without having to use the AWS console.&lt;/p&gt;
    &lt;head rend="h3"&gt;Trusted by thousands of developers&lt;/head&gt;
    &lt;p&gt;We've got your back with the most helpful, responsive support in the industry&lt;/p&gt;
    &lt;head rend="h3"&gt;Enterprise grade no matter your size&lt;/head&gt;
    &lt;p&gt;Customers of all sizes rely on us for production, from startups to large enterprises&lt;/p&gt;
    &lt;head rend="h3"&gt;Save a fortune on devops costs&lt;/head&gt;
    &lt;p&gt;We delay the need for infra engineers by a few years. And then we enable them to focus on more meaningful work&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.flightcontrol.dev/"/><published>2025-10-06T07:07:11+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45488713</id><title>Battering RAM – Low-Cost Interposer Attacks on Confidential Computing</title><updated>2025-10-06T11:32:28.673016+00:00</updated><content>&lt;doc fingerprint="be7b4c01fd29b2c1"&gt;
  &lt;main&gt;
    &lt;p&gt;Modern computers use memory modules (DRAM) to store everything in use: from photos and passwords to credit card numbers. Public cloud providers increasingly deploy hardware-level memory encryption to protect this sensitive data. However, we previously showed that malicious memory modules, nicknamed “Bad RAM”, can bypass these protections by deliberately supplying false metadata during processor boot. In response, modern cloud systems now validate memory more strictly at startup.&lt;/p&gt;
    &lt;head rend="h4"&gt;Breaking Memory Encryption with Two-Faced DRAM&lt;/head&gt;
    &lt;p&gt;Battering RAM fully breaks cutting-edge Intel SGX and AMD SEV-SNP confidential computing processor security technologies designed to protect sensitive workloads from compromised hosts, malicious cloud providers, or rogue employees. Our stealthy interposer bypasses both memory encryption and state-of-the-art boot-time defenses, invisible to the operating system. It enables arbitrary plaintext access to SGX-protected memory, and breaks SEV’s attestation feature on fully patched systems. Ultimately, Battering RAM exposes the limits of today’s scalable memory encryption. Intel and AMD have acknowledged our findings, but defending against Battering RAM would require a fundamental redesign of memory encryption itself.&lt;/p&gt;
    &lt;head rend="h4"&gt;Building Battering RAM on a $50 Budget&lt;/head&gt;
    &lt;p&gt;Unlike commercial passive interposers, which are exceedingly expensive and commonly cost over $100,000, we developed a custom-built interposer that uses simple analog switches to actively manipulate signals between the processor and memory, and can be built for less than $50.&lt;/p&gt;
    &lt;p&gt;All schematics and board files for our custom interposer are available as open source in our GitHub repository. The PCB is a standard 4-layer design and can be fabricated at any major PCB fabricator such as JLCPCB, PCBWay, or Eurocircuits.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="4"&gt;
        &lt;cell role="head"&gt;Component&lt;/cell&gt;
        &lt;cell role="head"&gt;Part Number&lt;/cell&gt;
        &lt;cell role="head"&gt;Cost&lt;/cell&gt;
        &lt;cell role="head"&gt;Qty.&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;PCB&lt;/cell&gt;
        &lt;cell&gt;Custom&lt;/cell&gt;
        &lt;cell&gt;$18.49&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;DDR4 Connector&lt;/cell&gt;
        &lt;cell&gt;CONN-DDR4-288-SM&lt;/cell&gt;
        &lt;cell&gt;$16.00&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Microcontroller&lt;/cell&gt;
        &lt;cell&gt;Raspberry Pi Pico 1/2&lt;/cell&gt;
        &lt;cell&gt;$4.00&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Switches&lt;/cell&gt;
        &lt;cell&gt;ADG902BRMZ&lt;/cell&gt;
        &lt;cell&gt;$4.04&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Voltage regulator&lt;/cell&gt;
        &lt;cell&gt;LD1117S25TR&lt;/cell&gt;
        &lt;cell&gt;$0.61&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Resistor&lt;/cell&gt;
        &lt;cell&gt;0402, 1kOhm&lt;/cell&gt;
        &lt;cell&gt;&amp;lt;$0.01&lt;/cell&gt;
        &lt;cell&gt;2&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Capacitor&lt;/cell&gt;
        &lt;cell&gt;0603, 100nF&lt;/cell&gt;
        &lt;cell&gt;$0.02&lt;/cell&gt;
        &lt;cell&gt;3&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="4"&gt;
        &lt;cell&gt;Capacitor&lt;/cell&gt;
        &lt;cell&gt;1206, 10μF&lt;/cell&gt;
        &lt;cell&gt;$0.18&lt;/cell&gt;
        &lt;cell&gt;1&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Total&lt;/cell&gt;
        &lt;cell&gt;$47.62&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;head rend="h4"&gt;Battering RAM in Action&lt;/head&gt;
    &lt;head rend="h3"&gt;Questions and Answers&lt;/head&gt;
    &lt;p&gt;Battering RAM can affect all systems using DDR4 memory, but is especially relevant for "confidential computing" workloads running in public cloud environments.&lt;/p&gt;
    &lt;p&gt;Modern Intel and AMD x86 cloud processors feature built-in access control and memory encryption to keep private data safe, even from the company running the cloud. However, our research shows that these guarantees can be bypassed with a low-cost memory interposer, allowing a rogue cloud infrastructure provider or insider with limited physical access to compromise protected workloads.&lt;/p&gt;
    &lt;p&gt;Confidential computing aims to protect private data even from the cloud provider, using hardware-level access control and memory encryption. Even if someone accesses the memory, they should only see encrypted (garbled) data. Battering RAM uses a low-cost, custom-built memory interposer installed between the processor and memory to tamper with such encrypted memory. It requires only brief one-time physical access, which is realistic in cloud environments, considering, for instance:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Rogue cloud employees;&lt;/item&gt;
      &lt;item&gt;Datacenter technicians or cleaning personnel;&lt;/item&gt;
      &lt;item&gt;Coercive local law enforcement agencies;&lt;/item&gt;
      &lt;item&gt;Supply chain tampering during shipping or manufacturing of the memory modules.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;Intel SGX and AMD SEV-SNP are two leading hardware-based trusted execution environments that enable secure cloud computations without needing to trust the cloud provider. They do this by enforcing strict access control and encrypting memory so that even if someone accesses it, they only see unreadable data.&lt;/p&gt;
    &lt;p&gt;AMD SEV and Intel SGX are widely offered by major cloud providers like like Amazon AWS, Google Cloud, Microsoft Azure, and IBM cloud. They also power privacy features in real-world applications like Signal, WhatsApp, and Chrome, and are used in sectors like healthcare to protect sensitive data.&lt;/p&gt;
    &lt;p&gt;No. While Intel Scalable SGX and AMD SEV-SNP use memory encryption to protect data stored in DRAM, this encryption is static: the same plaintext at the same physical address always maps to the same ciphertext. This defends against passive attacks, such as cold boot attacks, but not against Battering RAM, which can actively corrupt or replay memory contents. Because the encryption is static, replayed data decrypts to the original value, allowing stale data to be reused.&lt;/p&gt;
    &lt;p&gt;Furthermore, Intel's memory encryption engine for DDR4 systems, TME, relies on a single key for the entire memory range. This means encryption is static, not only per address, but also shared across both attacker and victim. By replaying and capturing ciphertexts from attacker-controlled pages, the attacker can recover and inject arbitrary plaintext within the victim’s memory.&lt;/p&gt;
    &lt;p&gt;Hence, Battering RAM exposes the fundamental limits of the scalable memory encryption designs currently used by Intel and AMD, which omit cryptographic freshness checks in favor of larger protected memory sizes.&lt;/p&gt;
    &lt;p&gt;BadRAM similarly exploited physical address aliasing to modify and replay encrypted memory on AMD SEV-SNP systems. However, BadRAM relied on modifying the SPD chip on the DIMM to report a false memory size at boot time, introducing static ghost address lines. In response, Intel and AMD added boot-time checks to detect and block such static aliases.&lt;/p&gt;
    &lt;p&gt;Battering RAM, on the other hand, is capable of introducing memory aliases dynamically at runtime. As a result, Battering RAM can circumvent Intel's and AMD's boot-time alias checks.&lt;/p&gt;
    &lt;p&gt;Concurrent to our work on Battering RAM, an independent research team developed the WireTap attack, which uses a commercial DDR4 DRAM interposer to break Intel Scalable SGX. Both Battering RAM and WireTap stem from a similar attack vector, but the approaches and findings are distinct.&lt;/p&gt;
    &lt;p&gt;The key differences between these two attacks are:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Cost: commercial DRAM interposers require specialized, high-speed signal analyzers (typically retailing at &amp;gt;$150,000), whereas our custom-built interposer requires only two simple analog switches and some control logic, totalling about $50. Battering RAM, therefore, shows that physical attacks are practical and not limited to resourceful adversaries with a large budget.&lt;/item&gt;
      &lt;item&gt;Technique: Battering RAM and WireTap exploit distinct techniques: memory aliasing vs. ciphertext side-channel analysis. Commercial DRAM interposers passively capture memory traffic, requiring additional ciphertext side-channel inference to recover secrets. In contrast, Battering RAM uses a custom-built interposer that actively redirects address lines to introduce aliases, allowing not just observation but also replay and corruption of ciphertext and culminating in plaintext read/write access on Scalable SGX.&lt;/item&gt;
      &lt;item&gt;Target: Both Battering RAM and WireTap expose the security limitations of current, scalable memory encryption technologies. Battering RAM breaks remote attestation for both Intel Scalable SGX and AMD SEV-SNP, whereas WireTap was only demonstrated on Intel Scalable SGX but may affect AMD DDR4 systems similarly.&lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;We found that our interposer can compromise the security of two widely-deployed TEEs, Intel Scalable SGX and AMD SEV-SNP. Both of these technologies employ a memory encryption scheme that is vulnerable to memory replay attacks. Furthermore, Scalable SGX on DDR4 platforms only employs a single memory encryption key for the entire physical memory space. We show this limitation can be exploited to create an arbitrary plaintext primitive. This severely undermines the protections in the presence of a physical adversary.&lt;/p&gt;
    &lt;p&gt;On top of that, our interposer re-enables the previously-mitigated BadRAM attacks. To combat this threat, AMD rolled out firmware-level mitigations that scan for aliases at boot time. As the interposer can enable and disable the interposer at runtime, these checks are easily bypassed. As a result, Battering RAM re-enables previous attacks on AMD SEV-SNP and Intel Client SGX .&lt;/p&gt;
    &lt;p&gt;Arm has also announced a cloud TEE called CCA . Based on the specification, DDR4 systems may also be vulnerable to Battering RAM. However, as no hardware is available yet, we were unable to test our interposer on CCA.&lt;/p&gt;
    &lt;p&gt;The table below summarizes our findings across different TEEs. Each column indicates whether we were able to read, write, or replay ciphertexts, and read/write plaintext in protected memory regions.&lt;/p&gt;
    &lt;table&gt;
      &lt;row span="5"&gt;
        &lt;cell role="head"&gt;TEE&lt;/cell&gt;
        &lt;cell role="head"&gt;Read&lt;/cell&gt;
        &lt;cell role="head"&gt;Write&lt;/cell&gt;
        &lt;cell role="head"&gt;Replay&lt;/cell&gt;
        &lt;cell role="head"&gt;Plaintext&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Intel Scalable SGX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;AMD SEV-SNP&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Client SGX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row span="5"&gt;
        &lt;cell&gt;Intel TDX&lt;/cell&gt;
      &lt;/row&gt;
      &lt;row&gt;
        &lt;cell&gt;Arm CCA&lt;/cell&gt;
      &lt;/row&gt;
    &lt;/table&gt;
    &lt;p&gt;No, our interposer only works on DDR4, which remains widely deployed today; e.g., a recent market study indicates that DDR4 still accounted for around 65% of sold DRAM modules in 2024.&lt;/p&gt;
    &lt;p&gt;DDR5 reorganizes the command/address bus, which removes the possibility of adding simple switches to the address lines. However, the underlying issue is not fixed, as current memory encryption engines still do not provide freshness guarantees. A determined attacker could theoretically still design more advanced interposers to perform similar attacks on DDR5.&lt;/p&gt;
    &lt;p&gt;Yes, our GitHub repository contains the hardware schematics and board files for the custom DDR4 interposer, firmware for the microcontroller, and proof-of-concept code for all attacks described in our paper. The interposer can be built for under $50, and the bill of materials is listed above.&lt;/p&gt;
    &lt;p&gt;We disclosed our findings to both Intel and AMD in February 2025. Both vendors have acknowledged our findings, but noted that physical attacks on DRAM are out of scope for their current products. To better reflect this position, Intel deposited the whitepaper on Scalable SGX, previously removed from the Intel website, permanently on arXiv.&lt;/p&gt;
    &lt;p&gt;Following an embargo period until September 30, 2025, both vendors have issued a public security advisory: Intel advisory | AMD advisory&lt;/p&gt;
    &lt;list rend="ol"&gt;
      &lt;item&gt; Confidential computing is here, but is not invincible. &lt;p&gt;Despite strong adoption by major CPU vendors and cloud providers, current technologies have critical physical-layer limitations that remain underexamined.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Reevaluate your threat models. &lt;p&gt;Encrypted memory is not inherently secure against physical tampering, and firmware-based mitigations alone are insufficient in threat scenarios involving limited physical access, such as malicious insiders or supply-chain compromises.&lt;/p&gt;&lt;/item&gt;
      &lt;item&gt; Advanced physical attacks are accessible at low cost. &lt;p&gt;Our open-source $50 custom device costs only a fraction of commercial DRAM interposers (upwards of $100,000) and is capable of breaking multi-million-dollar cloud security technologies from Intel and AMD.&lt;/p&gt;&lt;/item&gt;
    &lt;/list&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://batteringram.eu/"/><published>2025-10-06T07:47:17+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489174</id><title>Demodesk (YC W19) Is Hiring a Ruby on Rails Engineer</title><updated>2025-10-06T11:32:28.238131+00:00</updated><content>&lt;doc fingerprint="7b681573b8765159"&gt;
  &lt;main&gt;
    &lt;p&gt;Demodesk has a global mindset, where we promote a remote friendly environment &amp;amp; employee experience comes first. We offer flexible working conditions &amp;amp; enable face time with your colleagues for those special Demodesk moments! Come join us at one of our central hubs in Munich &amp;amp; Lisbon, or from other established locations around the world.&lt;/p&gt;
    &lt;p&gt;To us, work is more than just a job. We want to provide our employees with an environment where they have the ability to constantly thrive, learn &amp;amp; grow. And we want everybody to feel at home and have the time of their life while building Demodesk.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://demodesk.com/careers"/><published>2025-10-06T08:49:30+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489533</id><title>Nobel Prize in Physiology or Medicine 2025 awarded to immune system researchers</title><updated>2025-10-06T11:32:27.953050+00:00</updated><content>&lt;doc fingerprint="9384913f192e615e"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Press release&lt;/head&gt;
    &lt;p&gt;English&lt;lb/&gt;English (pdf)&lt;lb/&gt;Swedish&lt;lb/&gt;Swedish (pdf)&lt;/p&gt;
    &lt;p&gt;6 October 2025&lt;/p&gt;
    &lt;p&gt;The Nobel Assembly at Karolinska Institutet has decided to award the 2025 Nobel Prize in Physiology or Medicine to:&lt;/p&gt;
    &lt;p&gt;Mary E. Brunkow&lt;lb/&gt;Institute for Systems Biology,&lt;lb/&gt;Seattle, USA&lt;/p&gt;
    &lt;p&gt;Fred Ramsdell&lt;lb/&gt;Sonoma Biotherapeutics,&lt;lb/&gt;San Francisco, USA&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi&lt;lb/&gt;Osaka University,&lt;lb/&gt;Osaka, Japan&lt;/p&gt;
    &lt;p&gt;“for their discoveries concerning peripheral immune tolerance”&lt;/p&gt;
    &lt;head rend="h2"&gt;They discovered how the immune system is kept in check&lt;/head&gt;
    &lt;p&gt;The body’s powerful immune system must be regulated, or it may attack our own organs. Mary E. Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their groundbreaking discoveries concerning peripheral immune tolerance that prevents the immune system from harming the body.&lt;/p&gt;
    &lt;p&gt;Every day, our immune system protects us from thousands of different microbes trying to invade our bodies. These all have different appearances, and many have developed similarities with human cells as a form of camouflage. So how does the immune system determine what it should attack and what it should defend?&lt;/p&gt;
    &lt;p&gt;Mary Brunkow, Fred Ramsdell and Shimon Sakaguchi are awarded the Nobel Prize in Physiology or Medicine 2025 for their fundamental discoveries relating to peripheral immune tolerance. The laureates identified the immune system’s security guards, regulatory T cells, which prevent immune cells from attacking our own body.&lt;/p&gt;
    &lt;p&gt;“Their discoveries have been decisive for our understanding of how the immune system functions and why we do not all develop serious autoimmune diseases,” says Olle Kämpe, chair of the Nobel Committee.&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi was swimming against the tide in 1995, when he made the first key discovery. At the time, many researchers were convinced that immune tolerance only developed due to potentially harmful immune cells being eliminated in the thymus, through a process called central tolerance. Sakaguchi showed that the immune system is more complex and discovered a previously unknown class of immune cells, which protect the body from autoimmune diseases.&lt;/p&gt;
    &lt;p&gt;Mary Brunkow and Fred Ramsdell made the other key discovery in 2001, when they presented the explanation for why a specific mouse strain was particularly vulnerable to autoimmune diseases. They had discovered that the mice have a mutation in a gene that they named Foxp3. They also showed that mutations in the human equivalent of this gene cause a serious autoimmune disease, IPEX.&lt;/p&gt;
    &lt;p&gt;Two years after this, Shimon Sakaguchi was able to link these discoveries. He proved that the Foxp3 gene governs the development of the cells he identified in 1995. These cells, now known as regulatory T cells, monitor other immune cells and ensure that our immune system tolerates our own tissues.&lt;/p&gt;
    &lt;p&gt;The laureates’ discoveries launched the field of peripheral tolerance, spurring the development of medical treatments for cancer and autoimmune diseases. This may also lead to more successful transplantations. Several of these treatments are now undergoing clinical trials.&lt;/p&gt;
    &lt;head rend="h2"&gt;Illustrations&lt;/head&gt;
    &lt;p&gt;The illustrations are free to use for non-commercial purposes. Attribute “© The Nobel Committee for Physiology or Medicine. Ill. Mattias Karlén”&lt;/p&gt;
    &lt;p&gt;Illustration: The Nobel Prize in Physiology or Medicine 2025&lt;lb/&gt;Illustration: How T cells discover a virus&lt;lb/&gt;Illustration: How harmful T cells are eliminated&lt;lb/&gt;Illustration: The experiment that inspired Sakaguchi&lt;lb/&gt;Illustration: Sakaguchi defines a new class of T cells&lt;lb/&gt;Illustration: Brunkow and Ramsdell find the scurfy mutation&lt;lb/&gt;Illustration: How regulatory T cells protect us&lt;/p&gt;
    &lt;head rend="h2"&gt;Read more about this year’s prize&lt;/head&gt;
    &lt;p&gt;Popular science background: They understood how the immune system is kept in check (pdf)&lt;lb/&gt;Scientific background to the Nobel Prize in Physiology or Medicine 2025 (pdf)&lt;/p&gt;
    &lt;p&gt;Mary E. Brunkow, born 1961. Ph.D. from Princeton University, Princeton, USA. Senior Program Manager at the Institute for Systems Biology, Seattle, USA.&lt;/p&gt;
    &lt;p&gt;Fred Ramsdell, born 1960. Ph.D. 1987 from the University of California, Los Angeles, USA. Scientific Advisor, Sonoma Biotherapeutics, San Francisco, USA.&lt;/p&gt;
    &lt;p&gt;Shimon Sakaguchi, born 1951. M.D. 1976 and Ph.D. 1983 from Kyoto University, Japan. Distinguished Professor at the Immunology Frontier Research Center, Osaka University, Japan.&lt;/p&gt;
    &lt;p&gt;Prize amount: 11 million Swedish kronor, to be shared equally between the laureates.&lt;lb/&gt;Press contact: Pernilla Witte, +46 8 524 86 107, [email protected] or Thomas Perlmann, [email protected], Secretary-General, The Nobel Assembly at Karolinska Institutet.&lt;/p&gt;
    &lt;p&gt;Illustrations: © The Nobel Committee for Physiology or Medicine.&lt;/p&gt;
    &lt;p&gt;The Nobel Assembly, consisting of 50 professors at Karolinska Institutet, awards the Nobel Prize in Physiology or Medicine. Its Nobel Committee evaluates the nominations. Since 1901 the Nobel Prize has been awarded to scientists who have made the most important discoveries for the benefit of humankind.&lt;/p&gt;
    &lt;p&gt;Nobel Prize® is the registered trademark of the Nobel Foundation&lt;/p&gt;
    &lt;head rend="h3"&gt;Nobel Prize announcements 2025&lt;/head&gt;
    &lt;p&gt;This year’s Nobel Prize announcements will take place 6–13 October. All announcements will be streamed live here on nobelprize.org.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://www.nobelprize.org/prizes/medicine/2025/press-release/"/><published>2025-10-06T09:41:16+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489581</id><title>Build a VPN Tunnel with Wintun on Windows – Part 1</title><updated>2025-10-06T11:32:27.873720+00:00</updated><content>&lt;doc fingerprint="14977819cd253fd2"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Peer-to-Peer Networking: Building a VPN Tunnel with Wintun on Windows - Part 1&lt;/head&gt;
    &lt;head rend="h2"&gt;Introduction#&lt;/head&gt;
    &lt;p&gt;I’ve been using Tailscale for years to access my home lab without the need for a public IP. Tailscale can be installed on almost any device, allowing you to securely connect and access them from anywhere. It works as a peer-to-peer, mesh-style VPN, is opensource, and completely free for up to 100 devices and 10 users. They also offer a business plan for larger setups.&lt;/p&gt;
    &lt;p&gt;What always fascinated me was how Tailscale works seamlessly across platforms like Linux, macOS, Android, and Windows. Since I use both Linux and Windows in a dual-boot setup, I started digging deeper. On Linux, it’s straightforward they rely on a TUN interface. But on Windows, I was curious about the Layer 3 adapter being used under the hood. After exploring the Tailscale GitHub repo, I discovered that it uses Wintun a TUN driver for Windows developed by the WireGuard project.&lt;/p&gt;
    &lt;p&gt;Tailscale secures user-space packets using public and private key encryption. That made me curious about how peer-to-peer (P2P) communication could be achieved without encryption by simply exchanging plain packets.&lt;/p&gt;
    &lt;p&gt;In this blog, This part lays the groundwork for creating a VPN tunnel on Windows, which I’ll explore in detail in Part 2.&lt;/p&gt;
    &lt;head rend="h2"&gt;Wintun Windows TUN virtual network interface#&lt;/head&gt;
    &lt;p&gt;Wintun acts as a Layer 3 virtual adapter that allows user-space applications such as VPN software to directly work with IP packets. It functions as a TUN interface, creating a virtual network adapter that provides direct access to network layer (IP) packets through simple file read and write operations. Much like a physical network card, it supports assigning IP addresses, configuring routes, and transmitting data. The key difference is that, unlike real hardware, all packet transmission and handling are managed entirely by user-defined programs in user space.&lt;/p&gt;
    &lt;p&gt;In order to develop WireGuard for Windows, Wintun was developed and open sourced, distributed as a dynamic library.&lt;/p&gt;
    &lt;head rend="h3"&gt;Download wintun#&lt;/head&gt;
    &lt;p&gt;Wintun is developed in C language and distributed as a dynamic library.&lt;/p&gt;
    &lt;p&gt;After downloading, unzip the file and the directory is as follows:&lt;/p&gt;
    &lt;p&gt;&lt;code&gt;\bin&lt;/code&gt; The dynamic libraries of various platform versions are stored in same folder. Here you only need to select the appropriate dynamic library according to the platform.&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;amd64: Windows 64-bit&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;x86: Windows 32-bit&lt;/code&gt;
    &lt;/p&gt;
    &lt;head rend="h3"&gt;Getting Started#&lt;/head&gt;
    &lt;p&gt;Link to a repo https://github.com/mascarenhasmelson/wintun-tunnel&lt;/p&gt;
    &lt;head rend="h3"&gt;Create a virtual network card#&lt;/head&gt;
    &lt;p&gt;WireGuard developed Wintun GO interface binding, install WireGuardGO dependencies&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;golang.zx2c4.com/wireguard/tun&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;If the program displays an “Unable to load library” error during execution, please ensure that &lt;code&gt;wintun.dll&lt;/code&gt; is located in the same directory as the executable file.
&lt;/p&gt;
    &lt;p&gt;You may still see this error message when running the code, but it can be safely ignored as long as &lt;code&gt;wintun.dll&lt;/code&gt; is correctly placed in the same folder as &lt;code&gt;main.go&lt;/code&gt; and the compiled binary.
Next, run the following command to compile &lt;code&gt;main.go&lt;/code&gt; into an executable file named &lt;code&gt;main.exe&lt;/code&gt;&lt;/p&gt;
    &lt;p&gt;
      &lt;code&gt;go build -o main.exe&lt;/code&gt;
    &lt;/p&gt;
    &lt;p&gt;After running the command, you will see the &lt;code&gt;main.exe&lt;/code&gt; file generated in the current directory.
&lt;/p&gt;
    &lt;p&gt;Run &lt;code&gt;main.exe&lt;/code&gt; with administrator privileges.
&lt;/p&gt;
    &lt;p&gt;You can find the virtual network adapter listed under Network Connections.&lt;/p&gt;
    &lt;head rend="h3"&gt;Set network card IP and routing#&lt;/head&gt;
    &lt;p&gt;To set the network card IP, you need to use the Windows API. I copied some APIs from wireguard wireguard-windows/winipcfg To the project&lt;/p&gt;
    &lt;p&gt;After obtaining the device, perform a type cast to retrieve its &lt;code&gt;LUID&lt;/code&gt; (Locally Unique Identifier), then use the appropriate APIs to complete the configuration.&lt;/p&gt;
    &lt;code&gt;//luid
id := &amp;amp;windows.GUID{
0xdeadbabe,
0xcafe,
0xbeef,
[8]byte{0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef},
}

ifname := "Test"
dev, err := tun.CreateTUNWithRequestedGUID(ifname, id, 0)
if err != nil {
panic(err)
}
defer dev.Close()

nativeTunDevice := dev.(*tun.NativeTun)

link := winipcfg.LUID(nativeTunDevice.LUID())

ip, err := netip.ParsePrefix("100.64.1.1/24") //cgnat ip
if err != nil {
panic(err)
}
err = link.SetIPAddresses([]netip.Prefix{ip})
if err != nil {
panic(err)
}
&lt;/code&gt;
    &lt;p&gt;Once the program is running, you can verify that the IP was successfully set by running the &lt;code&gt;ipconfig&lt;/code&gt; command.
&lt;/p&gt;
    &lt;p&gt;You can also verify that the routing is successfully configured by running the command &lt;code&gt;route print -v&lt;/code&gt;.&lt;/p&gt;
    &lt;head rend="h3"&gt;Data Reading and Writing#&lt;/head&gt;
    &lt;p&gt;After setting up the IP and routing, you can use the API to &lt;code&gt;Read&lt;/code&gt; and &lt;code&gt;Write&lt;/code&gt; IP packets. For example, here’s how to read ICMP packets&lt;/p&gt;
    &lt;code&gt;//read packets
	for {
		n = 2048

		n, err = dev.Read(buf, 0)
		if err != nil {
			panic(err)
		}
		const ProtocolICMP = 1
		header, err := ipv4.ParseHeader(buf[:n])
		if err != nil {
			continue
		}
		//comparing ping
		if header.Protocol == ProtocolICMP {
			log.Println("source IP:", header.Src, " destination IP:", header.Dst)
			msg, _ := icmp.ParseMessage(ProtocolICMP, buf[header.Len:])
			log.Println(" icmp message echo:", msg.Type)
		}
	}
&lt;/code&gt;
    &lt;p&gt;After running the program, you can ping any IP address within the subnet, such as 100.64.1.2, or other IP addresses in the same network segment.&lt;/p&gt;
    &lt;p&gt;can be seen printed in the console:&lt;/p&gt;
    &lt;p&gt;Note: When deploying your application, make sure to include &lt;code&gt;wintun.dll&lt;/code&gt; in the same directory as the executable. This wintun.dll is essential for the program to function properly. If you’re distributing the software to others, ensure they have wintun.dll alongside the executable to avoid runtime errors.&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://0xmm.in/posts/peer-to-peer-windows-part1/"/><published>2025-10-06T09:49:33+00:00</published></entry><entry><id>https://news.ycombinator.com/item?id=45489951</id><title>The (economic) AI apocalypse is nigh</title><updated>2025-10-06T11:32:27.423085+00:00</updated><content>&lt;doc fingerprint="350198112d2011f4"&gt;
  &lt;main&gt;
    &lt;head rend="h1"&gt;Today's links&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;The real (economic) AI apocalypse is nigh: Sweating (the assets) to the oldies.&lt;/item&gt;
      &lt;item&gt;Hey look at this: Delights to delectate.&lt;/item&gt;
      &lt;item&gt;Object permanence: Dying on the job; Google audiocomplete blacklist; Lockheed Martin v. 'gathering information.'&lt;/item&gt;
      &lt;item&gt;Upcoming appearances: Where to find me.&lt;/item&gt;
      &lt;item&gt;Recent appearances: Where I've been.&lt;/item&gt;
      &lt;item&gt;Latest books: You keep readin' em, I'll keep writin' 'em.&lt;/item&gt;
      &lt;item&gt;Upcoming books: Like I said, I'll keep writin' 'em.&lt;/item&gt;
      &lt;item&gt;Colophon: All the rest.&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;The real (economic) AI apocalypse is nigh (permalink)&lt;/head&gt;
    &lt;p&gt;Like you, I'm sick to the back teeth of talking about AI. Like you, I keep getting dragged into discussions of AI. Unlike you‡, I spent the summer writing a book about why I'm sick of writing about AI⹋, which Farrar, Straus and Giroux will publish in 2026.&lt;/p&gt;
    &lt;p&gt;‡probably&lt;/p&gt;
    &lt;p&gt;⹋"The Reverse Centaur's Guide to AI"&lt;/p&gt;
    &lt;p&gt;A week ago, I turned that book into a speech, which I delivered as the annual Nordlander Memorial Lecture at Cornell, where I'm an AD White Professor-at-Large. This was my first-ever speech about AI and I wasn't sure how it would go over, but thankfully, it went great and sparked a lively Q&amp;amp;A. One of those questions came from a young man who said something like "So, you're saying a third of the stock market is tied up in seven AI companies that have no way to become profitable and that this is a bubble that's going to burst and take the whole economy with it?"&lt;/p&gt;
    &lt;p&gt;I said, "Yes, that's right."&lt;/p&gt;
    &lt;p&gt;He said, "OK, but what can we do about that?"&lt;/p&gt;
    &lt;p&gt;So I re-iterated the book's thesis: that the AI bubble is driven by monopolists who've conquered their markets and have no more growth potential, who are desperate to convince investors that they can continue to grow by moving into some other sector, e.g. "pivot to video," crypto, blockchain, NFTs, AI, and now "super-intelligence." Further: the topline growth that AI companies are selling comes from replacing most workers with AI, and re-tasking the surviving workers as AI babysitters ("humans in the loop"), which won't work. Finally: AI cannot do your job, but an AI salesman can 100% convince your boss to fire you and replace you with an AI that can't do your job, and when the bubble bursts, the money-hemorrhaging "foundation models" will be shut off and we'll lose the AI that can't do your job, and you will be long gone, retrained or retired or "discouraged" and out of the labor market, and no one will do your job. AI is the asbestos we are shoveling into the walls of our society and our descendants will be digging it out for generations:&lt;/p&gt;
    &lt;p&gt;https://pluralistic.net/2025/05/27/rancid-vibe-coding/#class-war&lt;/p&gt;
    &lt;p&gt;The only thing (I said) that we can do about this is to puncture the AI bubble as soon as possible, to halt this before it progresses any further and to head off the accumulation of social and economic debt. To do that, we have to take aim at the material basis for the AI bubble (creating a growth story by claiming that defective AI can do your job).&lt;/p&gt;
    &lt;p&gt;"OK," the young man said, "but what can we do about the crash?" He was clearly very worried.&lt;/p&gt;
    &lt;p&gt;"I don't think there's anything we can do about that. I think it's already locked in. I mean, maybe if we had a different government, they'd fund a jobs guarantee to pull us out of it, but I don't think Trump'll do that, so –"&lt;/p&gt;
    &lt;p&gt;"But what can we do?"&lt;/p&gt;
    &lt;p&gt;We went through a few rounds of this, with this poor kid just repeating the same question in different tones of voice, like an acting coach demonstrating the five stages of grieving using nothing but inflection. It was an uncomfortable moment, and there was some decidedly nervous chuckling around the room as we pondered the coming AI (economic) apocalypse, and the fate of this kid graduating with mid-six-figure debts into an economy of ashes and rubble.&lt;/p&gt;
    &lt;p&gt;I firmly believe the (economic) AI apocalypse is coming. These companies are not profitable. They can't be profitable. They keep the lights on by soaking up hundreds of billions of dollars in other people's money and then lighting it on fire. Eventually those other people are going to want to see a return on their investment, and when they don't get it, they will halt the flow of billions of dollars. Anything that can't go on forever eventually stops.&lt;/p&gt;
    &lt;p&gt;This isn't like the early days of the web, or Amazon, or any of those other big winners that lost money before becoming profitable. Those were all propositions with excellent "unit economics" – they got cheaper with every successive technological generation, and the more customers they added, the more profitable they became. AI companies have – in the memorable phraseology of Ed Zitron – "dogshit unit-economics." Each generation of AI has been vastly more expensive than the previous one, and each new AI customer makes the AI companies lose more money:&lt;/p&gt;
    &lt;p&gt;https://pluralistic.net/2025/06/30/accounting-gaffs/#artificial-income&lt;/p&gt;
    &lt;p&gt;This week, no less than the Wall Street Journal published a lengthy, well-reported story (by Eliot Brown and Robbie Whelan) on the catastrophic finances of AI companies:&lt;/p&gt;
    &lt;p&gt;https://www.wsj.com/tech/ai/ai-bubble-building-spree-55ee6128&lt;/p&gt;
    &lt;p&gt;The WSJ writers compare the AI bubble to other bubbles, like Worldcom's fraud-soaked fiber optic bonanza (which saw the company's CEO sent to prison, where he eventually died), and conclude that the AI bubble is vastly larger than any other bubble in recent history.&lt;/p&gt;
    &lt;p&gt;The data-center buildout has genuinely absurd finances – there are data-center companies that are collateralizing their loans by staking their giant Nvidia GPUs as collateral. This is wild: there's pretty much nothing (apart from fresh-caught fish) that loses its value faster than silicon chips. That goes triple for GPUs used in AI data-centers, where it's normal for tens of thousands of chips to burn out over a single, 54-day training run:&lt;/p&gt;
    &lt;p&gt;Talk about sweating your assets!&lt;/p&gt;
    &lt;p&gt;That barely scratches the surface of the funny accounting in the AI bubble. Microsoft "invests" in Openai by giving the company free access to its servers. Openai reports this as a ten billion dollar investment, then redeems these "tokens" at Microsoft's data-centers. Microsoft then books this as ten billion in revenue.&lt;/p&gt;
    &lt;p&gt;That's par for the course in AI, where it's normal for Nvidia to "invest" tens of billions in a data-center company, which then spends that investment buying Nvidia chips. It's the same chunk of money is being energetically passed back and forth between these closely related companies, all of which claim it as investment, as an asset, or as revenue (or all three).&lt;/p&gt;
    &lt;p&gt;The Journal quotes David Cahn, a VC from Sequoia, who says that for AI companies to become profitable, they would have to sell us $800 billion worth of services over the life of today's data centers and GPUs. Not only is that a very large number – it's also a very short time. AI bosses themselves will tell you that these data centers and GPUs will be obsolete practically from the moment they start operating. Mark Zuckerberg says he's prepared to waste "a couple hundred billion dollars" on misspent AI investments:&lt;/p&gt;
    &lt;p&gt;Bain &amp;amp; Co says that the only way to make today's AI investments profitable is for the sector to bring in $2 trillion by 2030 (the Journal notes that this is more than the combined revenue of Amazon, Google, Microsoft, Apple Nvidia and Meta):&lt;/p&gt;
    &lt;p&gt;How much money is the AI industry making? Morgan Stanley says it's $45b/year. But that $45b is based on the AI industry's own exceedingly cooked books, where annual revenue is actually annualized revenue, an accounting scam whereby a company chooses its best single revenue month and multiplies it by 12, even if that month is a wild outlier:&lt;/p&gt;
    &lt;p&gt;https://www.wheresyoured.at/the-haters-gui/&lt;/p&gt;
    &lt;p&gt;Industry darlings like Coreweave (a middleman that rents out data-centers) are sitting on massive piles of debt, secured by short-term deals with tech companies that run out long before the debts can be repaid. If they can't find a bunch of new clients in a couple short years, they will default and collapse.&lt;/p&gt;
    &lt;p&gt;Today's AI bubble has absorbed more of the country's wealth and represents more of its economic activity than historic nation-shattering bubbles, like the 19th century UK rail bubble. A much-discussed MIT paper found that 95% of companies that had tried AI had either nothing to show for it, or experienced a loss:&lt;/p&gt;
    &lt;p&gt;A less well-known U Chicago paper finds that AI has "no significant impact on workers’ earnings, recorded hours, or wages":&lt;/p&gt;
    &lt;p&gt;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5219933&lt;/p&gt;
    &lt;p&gt;Anything that can't go on forever eventually stops. Trump might bail out the AI companies, but for how long? They are incinerating money faster than practically any other human endeavor in history, with precious little to show for it.&lt;/p&gt;
    &lt;p&gt;During my stay at Cornell, one of the people responsible for the university's AI strategy asked me what I thought the university should be doing about AI. I told them that they should be planning to absorb the productive residue that will be left behind after the bubble bursts:&lt;/p&gt;
    &lt;p&gt;https://locusmag.com/feature/commentary-cory-doctorow-what-kind-of-bubble-is-ai/&lt;/p&gt;
    &lt;p&gt;Plan for a future where you can buy GPUs for ten cents on the dollar, where there's a buyer's market for hiring skilled applied statisticians, and where there's a ton of extremely promising open source models that have barely been optimized and have vast potential for improvement.&lt;/p&gt;
    &lt;p&gt;There's plenty of useful things you can do with AI. But AI is (as Princeton's Arvind Narayanan and Sayash Kapoor, authors of AI Snake Oil put it), a normal technology:&lt;/p&gt;
    &lt;p&gt;https://knightcolumbia.org/content/ai-as-normal-technology&lt;/p&gt;
    &lt;p&gt;That doesn't mean "nothing to see here, move on." It means that AI isn't the bow-wave of "impending superintelligence." Nor is it going to deliver "humanlike intelligence."&lt;/p&gt;
    &lt;p&gt;It's a grab-bag of useful (sometimes very useful) tools that can sometimes make workers' lives better, when workers get to decide how and when they're used.&lt;/p&gt;
    &lt;p&gt;The most important thing about AI isn't its technical capabilities or limitations. The most important thing is the investor story and the ensuing mania that has teed up an economical catastrophe that will harm hundreds of millions or even billions of people. AI isn't going to wake up, become superintelligent and turn you into paperclips – but rich people with AI investor psychosis are almost certainly going to make you much, much poorer.&lt;/p&gt;
    &lt;p&gt;(Image: TechCrunch, CC BY 2.0; Cryteria, CC BY 3.0; modified)&lt;/p&gt;
    &lt;head rend="h1"&gt;Hey look at this (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;EU ministers reach 'compromise' on digital euro roadmap https://www.reuters.com/business/finance/eu-ministers-seek-agreement-digital-euro-be-independent-visa-mastercard-2025-09-19/&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Amazon will pay $2.5 billion to settle the FTC’s Prime lawsuit https://www.theverge.com/news/785744/amazon-ftc-prime-subscription-settlment&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Conservative Dem Compares Ad About Her Corporate Donations to ‘Political Violence’ https://prospect.org/politics/2025-09-25-conservative-dem-ad-corporate-donations-violence-bains-california/&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;Monopoly Utilities Ousted America's Best Regulator https://economicpopulist.substack.com/p/monopoly-utilities-ousted-americas&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;WNYC offers free programs to stations affected by funding cuts https://current.org/2025/09/wnyc-offers-free-programs-to-stations-affected-by-funding-cuts/&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Object permanence (permalink)&lt;/head&gt;
    &lt;p&gt;#20yrsago Financial Times: WIPO’s webcaster treaty is a disaster https://www.ft.com/content/441306be-2eb6-11da-9aed-00000e2511c8&lt;/p&gt;
    &lt;p&gt;#15yrsago Google’s autocomplete blacklist https://www.2600.com/googleblacklist/&lt;/p&gt;
    &lt;p&gt;#15yrsago FBI ignores DoJ report, raids activists, arrests Time Person of the Year https://www.democracynow.org/2010/9/27/fbi_raids_homes_of_anti_war&lt;/p&gt;
    &lt;p&gt;#15yrsago Meta-textual analysis of mainstream science reporting https://www.theguardian.com/science/the-lay-scientist/2010/sep/24/1&lt;/p&gt;
    &lt;p&gt;#15yrsago Lockheed Martin sign prohibits sketching and “gathering information” https://www.flickr.com/photos/jef/5028187145/&lt;/p&gt;
    &lt;p&gt;#5yrsago Ransomware for coffee makers https://pluralistic.net/2020/09/27/junky-styling/#java-script&lt;/p&gt;
    &lt;p&gt;#5yrsago The joys of tailoring https://pluralistic.net/2020/09/27/junky-styling/#inseams&lt;/p&gt;
    &lt;p&gt;#1yrago Return to office and dying on the job https://pluralistic.net/2024/09/27/sharpen-your-blades-boys/#disciplinary-technology&lt;/p&gt;
    &lt;head rend="h1"&gt;Upcoming appearances (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Boston: Enshittification with Randall Munroe (Brattle Theater), Oct 7&lt;lb/&gt;https://www.eventbrite.com/e/cory-doctorow-at-the-brattle-theatre-tickets-1591235180259?aff=oddtdtcreator&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;DC: Enshittification with Rohit Chopra (Politics and Prose), Oct 8&lt;/p&gt;&lt;lb/&gt;https://politics-prose.com/cory-doctorow-10825&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;NYC: Enshittification with Lina Khan (Brooklyn Public Library), Oct 9&lt;/p&gt;&lt;lb/&gt;https://www.bklynlibrary.org/calendar/cory-doctorow-discusses-central-library-dweck-20251009-0700pm&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;New Orleans: DeepSouthCon63, Oct 10-12&lt;/p&gt;&lt;lb/&gt;http://www.contraflowscifi.org/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;New Orleans: Enshittification at Octavia Books, Oct 12&lt;/p&gt;&lt;lb/&gt;https://www.octaviabooks.com/event/enshittification-cory-doctorow&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Chicago: Enshittification with Anand Giridharadas (Chicago Humanities), Oct 15&lt;/p&gt;&lt;lb/&gt;https://www.oldtownschool.org/concerts/2025/10-15-2025-kara-swisher-and-cory-doctorow-on-enshittification/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Los Angeles: Enshittification with David Dayen (Diesel), Oct 16&lt;/p&gt;&lt;lb/&gt;https://dieselbookstore.com/event/2025-10-16/cory-doctorow-enshittification&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;San Francisco: Enshittification at Public Works with Jenny Odell (The Booksmith), Oct 20&lt;/p&gt;&lt;lb/&gt;https://app.gopassage.com/events/doctorow25&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;PDX: Enshittification at Powell's, Oct 21&lt;/p&gt;&lt;lb/&gt;https://www.powells.com/events/cory-doctorow-10-21-25&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Seattle: Enshittification and the Rot Economy, with Ed Zitron (Clarion West), Oct 22&lt;/p&gt;&lt;lb/&gt;https://www.clarionwest.org/event/2025-deep-dives-cory-doctorow/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Madrid: Conferencia EUROPEA 4D (Virtual), Oct 28&lt;/p&gt;&lt;lb/&gt;https://4d.cat/es/conferencia/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Miami: Enshittification at Books &amp;amp; Books, Nov 5&lt;/p&gt;&lt;lb/&gt;https://www.eventbrite.com/e/an-evening-with-cory-doctorow-tickets-1504647263469&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Miami: Cloudfest, Nov 6&lt;/p&gt;&lt;lb/&gt;https://www.cloudfest.com/usa/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Burbank: Burbank Book Festival, Nov 8&lt;/p&gt;&lt;lb/&gt;https://www.burbankbookfestival.com/&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Recent appearances (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;Enshittification (Cornell)&lt;lb/&gt;https://ecornell.cornell.edu/keynotes/view/K091225/&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Escaping Big Tech, Privacy Battles &amp;amp; “Enshittification” (Revolution.social)&lt;/p&gt;&lt;lb/&gt;https://www.youtube.com/watch?v=exvpetQRSVo&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;Nerd Harder! (This Week in Tech)&lt;/p&gt;&lt;lb/&gt;https://twit.tv/shows/this-week-in-tech/episodes/1047&lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Latest books (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (https://us.macmillan.com/books/9781250865908/picksandshovels).&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (the-bezzle.org).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (http://lost-cause.org).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (http://seizethemeansofcomputation.org). Signed copies at Book Soup (https://www.booksoup.com/book/9781804291245).&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books http://redteamblues.com.&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 https://chokepointcapitalism.com&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Upcoming books (permalink)&lt;/head&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"Canny Valley": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025&lt;/item&gt;
      &lt;item&gt;&lt;p&gt;"Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025&lt;/p&gt;&lt;lb/&gt;https://us.macmillan.com/books/9780374619329/enshittification/&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Unauthorized Bread": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Memex Method," Farrar, Straus, Giroux, 2026&lt;/p&gt;
      &lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;"The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, 2026&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;head rend="h1"&gt;Colophon (permalink)&lt;/head&gt;
    &lt;p&gt;Today's top sources: James Boyle (https://www.thepublicdomain.org/).&lt;/p&gt;
    &lt;p&gt;Currently writing:&lt;/p&gt;
    &lt;list rend="ul"&gt;
      &lt;item&gt;"The Reverse Centaur's Guide to AI," a short book for Farrar, Straus and Giroux about being an effective AI critic. FIRST DRAFT COMPLETE AND SUBMITTED.&lt;/item&gt;
      &lt;item&gt;
        &lt;p&gt;A Little Brother short story about DIY insulin PLANNING&lt;/p&gt;
      &lt;/item&gt;
    &lt;/list&gt;
    &lt;p&gt;This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.&lt;/p&gt;
    &lt;p&gt;https://creativecommons.org/licenses/by/4.0/&lt;/p&gt;
    &lt;p&gt;Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.&lt;/p&gt;
    &lt;head rend="h1"&gt;How to get Pluralistic:&lt;/head&gt;
    &lt;p&gt;Blog (no ads, tracking, or data-collection):&lt;/p&gt;
    &lt;p&gt;Newsletter (no ads, tracking, or data-collection):&lt;/p&gt;
    &lt;p&gt;https://pluralistic.net/plura-list&lt;/p&gt;
    &lt;p&gt;Mastodon (no ads, tracking, or data-collection):&lt;/p&gt;
    &lt;p&gt;Medium (no ads, paywalled):&lt;/p&gt;
    &lt;p&gt;Twitter (mass-scale, unrestricted, third-party surveillance and advertising):&lt;/p&gt;
    &lt;p&gt;Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):&lt;/p&gt;
    &lt;p&gt;https://mostlysignssomeportents.tumblr.com/tagged/pluralistic&lt;/p&gt;
    &lt;p&gt;"When life gives you SARS, you make sarsaparilla" -Joey "Accordion Guy" DeVilla&lt;/p&gt;
    &lt;p&gt;READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.&lt;/p&gt;
    &lt;p&gt;ISSN: 3066-764X&lt;/p&gt;
  &lt;/main&gt;
  &lt;comments/&gt;
&lt;/doc&gt;</content><link href="https://pluralistic.net/2025/09/27/econopocalypse/#subprime-intelligence"/><published>2025-10-06T10:51:53+00:00</published></entry></feed>